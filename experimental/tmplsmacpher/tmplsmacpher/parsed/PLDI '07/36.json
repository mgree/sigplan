{"article_publication_date": "06-10-2007", "fulltext": "\n Pro.le-Driven Energy Reduction in Network-on-Chips Feihui Li, Guangyu Chen, Mahmut Kandemir Ibrahim \nKolcu Department of computer Science and Engineering Computation Department The Pennsylvania State University, \nUSA University of Manchester, UK {feli,gchen,kandemir}@cse.psu.edu ikolcu@umist.ac.uk Abstract Reducing \nenergy consumption of a Network-on-Chip (NoC) is a critical design goal, especially for power-constrained \nembed\u00added systems. In response, prior research has proposed several circuit/architectural level mechanisms \nto reduce NoC power con\u00adsumption. This paper considers the problem from a different per\u00adspective and \ndemonstrates that compiler analysis can be very help\u00adful for enhancing the effectiveness of a hardware-based \nlink power management mechanism by increasing the duration of communi\u00adcation links idle periods. The \nproposed pro.le-based approach achieves its goal by maximizing the communication link reuse through compiler-directed, \nstatic message re-routing. That is, it clusters the required data communications into a small set of \ncom\u00admunication links at any given time, which increases the idle periods for the remaining communication \nlinks in the network. This helps hardware shut down more communication links and their corre\u00adsponding \nbuffers to reduce leakage power. The current experimen\u00adtal evaluation, with twelve data-intensive embedded \napplications, shows that the proposed pro.le-driven compiler approach reduces leakage energy by more \nthan 35% (on average) as compared to a pure hardware-based link power management scheme. Categories and \nSubject Descriptors D.3.4 [Programming Lan\u00adguages]: Processors compilers; C.2.0 [Computer-Communication \nNetworks]: General General Terms Algorithms, Management, Experimentation Keywords Network-on-Chip, power, \ncompiler, routing 1. Introduction The increasing complexity of communication patterns in embedded applications, \nwhich are parallelized over multiple processing units, creates dif.culty for continued use of traditional \nbus-based on-chip communication techniques. Network-on-chip (NoC) architectures are rapidly replacing \ndedicated interconnects and buses in com\u00adplex System-on-Chip (SoC) architectures. An NoC can connect \nand manage communications among a variety of design elements and Intellectual Property (IP) blocks required \nby complex SoCs. Prior research of NoCs mainly focused on circuit/architectural level tech\u00adniques [2, \n5, 31] and task mapping related issues [1, 13]. While, in principle, communication strategies similar \nto those currently used for large off-chip networks can apply at the chip Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, \nUSA. Copyright c . 2007 ACM 978-1-59593-633-2/07/0006. . . $5.00 level, increasing on-chip power consumption \ndemands a power\u00adaware design and an optimization process. Recent research shows that using voltage/frequency \nscaling on communication links [24] and shutting down the idle links [27] can signi.cantly reduce NoC \npower consumption. Such techniques, while very effective in re\u00adducing power consumption in certain cases, \nwork best when com\u00admunication links have long idle periods, which allow compensation for performance/power \noverheads due to switching between volt\u00adage levels and between link shut-down/turn-on states. Speci.cally, \nlong idle periods are preferable from the viewpoint of maximizing power savings through link shutdown. \nMotivated by this preference, this paper proposes and evalu\u00adates a pro.le-driven compiler optimization \nfor increasing the length of idle periods of communication links for a two-dimensional, on-chip, mesh \nnetwork. The proposed compiler-directed approach achieves its goal by maximizing communication link reuse. \nThat is, this approach clusters the required data communications into a small set of links at any given \ntime, increasing the idle periods for the remaining communication links in the network. Clearly, this \nscheme needs to occur in a performance-sensitive manner. There\u00adfore the goal is to reduce network energy \nconsumption as much as possible without causing extra link contention and signi.cantly degrading network \nperformance. The targeted application domain is array/loop-intensive embed\u00added programs, and the targeted \nNoC is a two-dimensional mesh used by a single application at a time. Note that a large frac\u00adtion of \nembedded NoCs typically execute a single application and use static message routing for reasons such \nas energy ef.ciency and buffer space minimization [13]. This paper proposes a pro.le\u00addriven static message \nrouting scheme that maximizes link reuse between different execution states of a given application. Our \nap\u00adproach makes use of a novel data structure called the communica\u00adtion graph (which captures different \nnetwork states during applica\u00adtion execution) and a new abstraction: the link signature (which captures \nlink utilization caused by messages in a given network state). We implement our approach and test it \nusing twelve data\u00adintensive embedded applications. Analysis of the test results show that the proposed \npro.le-driven compiler approach reduces leak\u00adage energy by more than 35% on average, as compared to a \npure hardware-based link power management scheme. The remainder of this paper is organized as follows. \nSection 2 introduces our on-chip mesh architecture and hardware support for the compiler-directed message \nrouting. Section 3 explains how link signatures and the communication graph derive from an automated \ncompiler analysis and describes the link reuse optimization ap\u00adproach. Section 4 presents the experimental \nresults from our im\u00adplementation. Sections 5 and 6 describe related work and provide concluding remarks, \nrespectively.  2. Architectural Model 2.1 Network Abstraction Our research focuses on a mesh-based NoC \narchitecture, whose ab\u00adstract view appears in Figure 1. Each node in the mesh has a simple, single-issued, \nembedded core with a small amount of local mem\u00adory (32KB in our experiments). Each node is connected \nto its local switch through a network interface (NI) and thus communicates with other nodes through switches \nand communication links. Inter\u00adprocessor communication is done via message passing. The internal structure \nof a switch is shown in Figure 2. Each switch has an interface with its local processing unit. It also \nhas four input/output ports that interface with four neighboring switches. Input/output buffers in a \nswitch store the packets in transmission. A cross-bar decides to which output port a packet is to be \nsent. The default routing algorithm used by the switches is static X-Y routing [9], which passes each \npacket .rst exclusively in the X\u00addimension and then completely in the Y-dimension until reaching the \ndestination node. Figure 2. Switch structure. Based on prior research of power-aware networks [15, 27], \nwe employ a hardware-controlled link shutdown scheme. Each communication link in the network, as well \nas its corresponding buffers, can be turned off when they remain idle for a certain period of time. The \npowered-off components re-activate on demand, i.e., they turn on only when needed.  2.2 Hardware Support \nfor Compiler-Directed Message Routing Our goal is to determine the most appropriate routing for each \nmes\u00adsage at compilation time thereby allowing maximized link reuse across different messages. Thus, the \ncompiler must have a way of providing routing information, which may be different from the de\u00adfault X-Y \nrouting, to each message. We propose to let the compiler attach routing information to each message-send \noperation in the code, requiring the packets of all the messages issued by a message\u00adsend operation to \nfollow the same route (the message-send opera\u00adtions considered here are source level communication commands \nsuch as MPI Send in the MPI Library [29]). Please note that the selection of the communication library \nto use is orthogonal to the focus of this paper. To support the compiler-directed message routing, we \nextend the switch design to handle two types of routing schemes: de\u00adfault X-Y routing and compiler-directed \nrouting. The header of each packet contains a .ag bit, indicating which routing mechanism to use for \na given packet (0: X-Y routing; 1: compiler-directed rout\u00ading). A packet using the default X-Y routing \nhas the identi.cation (ID) of the destination node in its header, as shown in the upper part of Figure \n3. When a switch receives such a packet, it forwards the packet according to the X-Y routing algorithm. \n Figure 3. Fields in the header of a packet (Top: default X-Y routing; Bottom: compiler-directed routing). \nTable 1. Routing decisions based on orientation and routing command bits (N: North; S: South; W: West; \nE: East). Orientation 00 00 01 01 10 10 11 11     Routing command 0 1 0 1 0 1 0 1 Routing decision \nN E N W S E S W On the other hand, the header of a packet that employs the compiler-directed routing \ncontains three .elds (see the lower part of Figure 3): the hop counter (4 bits), the orientation (2 bits), \nand the routing command sequence (13 bits). Assuming that node, Pi, sends packet, p, to node, Pj , for \neach switch, Sk, on the path of this packet, a corresponding bit in the routing command sequence of the \npacket tells the switch to which output port to forward this packet. The meaning of a routing command \nbit, however, is inter\u00adpreted along with the value of the orientation .eld. This means that the compiler \ncan only choose an alternate path from among the set of possible shortest paths. Once the orientation \nof a path is known (Northwestern: 01; Southwestern: 11; Northeastern: 00; and Southeastern: 10), only \na single bit of the routing command, indicating the dimension (X: 1; Y: 0), can determine the routing \nde\u00adcision (North, South, West, or East). Table 1 provides the meaning of routing commands for different \nvalues of the orientation .eld. The node sending a given packet sets the value of the hop counter of \nthat packet. As the packet moves forward from one switch to an\u00adother, the hop counter number decreases \nby one. When the counter value becomes zero, the packet has arrived at its destination. Due to the limited \nnumber of bits available in a packet header in the current implementation, the compiler-directed routing \nmechanism is not applicable for a packet whose source and destination nodes are more than 13 hops apart. \nFor such a packet, the default X-Y routing mechanism applies.  3. Optimizing Link Reuse A high level \nview of our compiler-based approach appears in Fig\u00adure 4. This approach pro.les the parallel application \ncode to be optimized and builds a communication graph, which captures the communication pattern of the \nentire parallel program (elaboration of the concepts of link signature and communication graph appears \nlater in this section). Given a communication graph, a link reuse optimizer statically re-routes the \npre-determined message routing paths to increase link reuse. The output of the link reuse opti\u00admizer \nis a modi.ed communication graph. Subsequently, the code rewriter module annotates each message-send \noperation in the ap\u00adplication code with the determined message routing information and generates an optimized \nparallel code. Figure 4. Compiler-directed link reuse optimization scheme. Each vertex of the communication \ngraph captures a network state. 3.1 Network State and Link Signature Assume that a parallel program \nto be executed on the mesh-based NoC architecture consists of n parallel threads, P1, P2, ..., Pn,and \nthread Pp is scheduled to run on the p th mesh node. These threads send messages to each other using \ncommunication commands (send operations). We denote the set of communication commands in thread Pp using \nCp = {M1,p, M2,p, ..., Mk,p, ..., Mq,p}, where q is the total number of communication commands in the \nprogram code of thread Pp and Mk,p is the kth communication command in the code of Pp. For this study, \nall the messages sent by a given Mk,p follow the same route in the NoC. At a given point in execution, \nmultiple messages may be undergoing trans\u00admission on the mesh. Representing the network state using a \nset of message-send operations, Si,is: Si = {Mk,p | A message sent by Mk,p is in transmission over the \nmesh}. S0 =1 represents a state in which no message is in transmission. Given a speci.c network state, \na further determination of link utilization at this state is necessary. The link utilization vector (LUV) \nfor a given send operation, Mk,p, is a vector wuk,p,the jth element of which gives the number of packets \nsent by Mk,p and transferred through the jth communication link of the mesh. Thus, a link signature (LS), \nwsi, to represent the link utilization at a network state Si,is: X wsi = wuk,p, Mk,pESi P where denotes \nelement-wise vector addition operator. Given a vector, w (which can be either an LUV or an LS), func\u00adtion \ne(w )returns the set of links used by the message(s) captured by w . Figure 5 gives an example link signature \ncalculation. The net\u00adwork state S1 = {M1,0, M1,1, M1,2} in this example indicates a gather type of communication. \nThree concurrent 20-packet mes\u00adsages, m1,0, m1,1 and m1,2, are sent by commands M1,0, M1,1, and M1,2, \nrespectively, as shown in Figure 5(a). The .rst task is to obtain the LUVs for the corresponding send \noperations and then add them to compute the corresponding LS for this state, as shown in Figure 5(b). \nApplying function e to this link signature, we obtain e(ws1)={l0,1,l2,3,l1,3}, which means that this \nstate has only three links in use. From the resulting signature, one can also see that link l1,3 has \nthe highest communication load (40 packets).  3.2 Communication Graph The network state changes during \nthe course of execution. More speci.cally, the network transitions from a state, Si, to another state, \nSj, in two situations: A new message is sent by communication command, Mk,p.In this case, Sj =Si U{Mk,p}. \n A message sent by communication command Mk,p arrives at its destination node. In this case, Sj =Si \n-{Mk,p}.  A communication graph (CG) captures the communication be\u00adhavior of a program. A communication \ngraph is an undirected graph, in which each vertex corresponds to a network state and, each edge (Si,Sj)indicates \nthe transition between states, Si and Sj. Wi,j, the weight attached to edge, (Si,Sj), gives the number \nof transitions taking place between states, Si and Sj, during the execution of this program. We use pro.ling \nto build the CG of a parallel program. Specif\u00adically, we instrument the target program to notify a pro.ler \neach time a node sends a message or when a message arrives its desti\u00adnation node. The pro.ler keeps track \nof the current network state, Si. When the pro.ler receives a noti.cation from the instrumented program, \nit computes the new state, Sj, and increases the value of Wi,j, which represents the number of transitions \nbetween Si and Sj. After the program completes its execution, we construct its CG based on the computed \nnetwork states, the state transitions, and the values of Wi,j. Figure 6(a) illustrates an example communication \ngraph.  Figure 6. Two different approaches to traverse a CG (a shaded vertex at step k indicates that \nthe corresponding link signature is not modi.ed at this step).  3.3 Maximizing Link Reuse Based on the \nprevious de.nitions, we can re-express the problem of increasing link reuse as one of maximizing link \nreuse between adjacent vertices in a communication graph. That is, when going from one state to another \nat runtime, the desire is to reuse the same set of links as much as possible. Each vertex in a CG has \na default link signature, obtained using the default X-Y routing for messages sent by the communication \ncommands in that vertex. The compiler s task is to re-assign link signatures to those vertices, which \nwill maximize communication link reuse. 3.3.1 Traversing a Communication Graph It is necessary to determine \nan order in which we traverse network states to assign them new link signatures, as assigning a signature \nto a given vertex (network state) will affect the selection of the signatures for its neighbors in the \nCG. At least two different ways of traversing a CG exist. The .rst approach starts with the edge with \nthe largest weight and performs the signature re-assignment to the associated vertices. After that, this \napproach considers the edge with the next largest weight among the edges that are incident on the selected \nvertices. Since one of the vertices of the edge under consideration has an assigned signature, signature \nassignment is for the other vertex only. This step repeats until all the vertices are processed. This \napproach, referred to as Scheme I, expands the selected set of edges at each step by considering only \nthe neighbors. The second approach, referred to as Scheme II, starts the same way as Scheme I. However, \nafter selecting the edge with the largest weight and assigning new signatures to corresponding vertices, \nthe next edge selection considers all the remaining edges (i.e., not just those that are incident on \nthe previously selected vertices). To illustrate the differences between Scheme I and Scheme II, let \nus consider the example CG shown in Figure 6(a). The pairs of vertices considered by Scheme I and Scheme \nII at each step (for signature re-assignment) appear in Figure 6(b) and Figure 6(c), respectively. Figure \n7(a) and Figure 7(b) provide the pseudo-codes for the compiler algorithms that implement Scheme I and \nScheme II, respectively.  3.3.2 Optimizing Link Reuse Between Two Adjacent Network States 1) Routing \nFlexibility. Re-routing (the messages sent by) the com\u00admunication commands can achieve improvement in \ncommunica\u00adtion link reuse. In the present scheme, only the shortest paths are considered for re-routing \nmessages since this typically causes less energy consumption than using longer paths. Even with this \nrestric\u00adtion, in many cases a certain re-routing .exibility is available. Con\u00adsider a two-dimensional \nmesh where a message, m,istobe sent from a source node, (xs, ys), to a destination node, (xd, yd). If \nm = |xd - xs| and n = |yd - ys|, this message has Cm possi\u00ad m+n ble, unique, shortest paths. Recall from \nSection 3.1 that the de.ned link utilization vector represents the path taken by a message. Now, a set \nof alternate link utilization vectors (ALUV), Ai,p, can repre\u00adsent all the alternate (shortest) paths \navailable to a message sent by the communication command, Mi,p. Therefore, re-routing a mes\u00adsage can \nbe thought of as the replacement of the current LUV for an associated Mi,p, with a new LUV selected from \nthe correspond\u00ading ALUV set. The number of alternate link utilization vectors in an ALUV set (i.e., |Ai,p|) \nthus represents the routing .exibility for (the messages sent by) communication command, Mi,p. 2) Problem \nFormulation. Formulating the problem of optimiz\u00ading the communication link reuse between two neighboring \nvertices in a CG focuses on two vertices, Sa and Sb, as shown in Figure 8. Each communication command, \ne.g., Ma3,p3 in state Sa, has a set of alternate link utilization vectors, which represent the alternate, \nshortest paths for the corresponding message. A single commu\u00adnication command is likely to appear in \nmultiple network states. Input: A communication graph CG(V,E,W); Output: U ui,p for each Mi,p in the \nprogram; P the set of network states that have been processed; R the set of communication commands whose \nLUVs have been determined; C the set of candidate edges; P =\u00a2; R =\u00a2; C =\u00a2; while(P =V) { if(C =\u00a2) C \n={(Sx,Sy)}if Wx,y is maximum; select (Si,Sj )EC with maximum Wi,j ; call reroute(Si, Sj , R); P =P .{Si,Sj}; \n // states Si and Sj have been processed. R =R.Si .Sj; // the LUVs of the communication commands // \nin Si and Sj have been determined. C' ={(Sa,Sb)|Sa EP =Sb E(V -P)}; C =(C -{(Si,Sj )}).C'; } (a) Scheme \nI.  Input: A communication graph CG(V,E,W); Output: U ui,p for each Mi,p in the program; P the set \nof network states that have been processed; R the set of communication commands whose LUVs have been \ndetermined; C the set of candidate edges; P =\u00a2; R =\u00a2; C =E; while(P =V) { select a (Si,Sj )EC if Wi,j \nis maximum; call reroute(Si, Sj , R); P =P .{Si,Sj}; // states Si and Sj have been processed. R =R.Si \n.Sj; // the LUVs of the communication commands // in Si and Sj have been determined. C =C -{(Si,Sj)}; \n} (b) Scheme II. Figure 7. Pseudo codes for our two CG traversing schemes (Scheme I and Scheme II). However, \nwe can change the associated routing only once (i.e., all the messages sent by it are always transferred \nthrough the same path). Therefore, when optimizing states, Sa and Sb, the possibil\u00adity exists that some \ncommunication commands have already been assigned new routes during the previous steps (such as Ma4,p4 \nand Ma5,p5 in state, Sa,and Mb3,p3 in state, Sb) and these routes can\u00adnot be further changed. The goal \nis to choose a new LUV for each send operation (except those already assigned new LUVs) in Sa and Sb \nminimizing the number of unique links used in Sa and Sb (i.e., maximizing the link reuse). Selecting \nthe new utilization vectors should not degrade the per\u00adformance of the default routing scheme. However, \nselecting alter\u00adnate re-routings can increase the network contention. Therefore, some sort of performance \nconstraint should be introduced for se\u00adlecting the re-routings. In one network state, the communication \nlink with the highest load often heavily in.uences the latency of transmitting messages. The link with \nthe highest load corresponds  Figure 8. Link reuse optimization between two network states, Sa and Sb. \nto the largest entry in the link signature associated with a given state. The higher the value of the \nlargest entry, the more likely there will be severe link contention. Therefore, in optimizing link reuse, \nand in order to avoid degrading network latency, increasing the value of the largest entry in any original \nlink signature is un\u00addesirable (although the largest value may be permitted to shift to another link). \nFor example, given the default link signature (10, 40, 10, 10, 0, 0, 0, 0) of a network state, from the \nperformance per\u00adspective, an alternate signature such as (10, 50, 0, 10, 0, 0, 0, 0) is inexpedient. \nHowever, for another alternate signature (40, 20, 10, 0, 0, 0, 0, 0), the compiler has dif.culty judging \nits impact on latency as compared to the default, (10, 40, 10, 10, 0, 0, 0, 0). The cur\u00adrent implementation \naccepts this second alternate signature. Since the proposed approach is built within a compiler in a \nmodular fash\u00adion, it is very .exible. That is, if desired, one can easily explore more strict performance \nconstraints. We want to emphasize, how\u00adever, that judging the latency behavior of a network state based \non its signature at compile time is a very dif.cult problem in general. This is the reason for adopting \na simple compile-time heuristic, based on the assumption that the link with the largest load typically \nforms the main latency bottleneck. 3) Heuristic. We present a heuristic for calculating the routings \nfor (the messages sent by) the communication commands. The pseudo code for our heuristic is given in \nFigure 9. First, for each Mi,p unassigned with a new routing in network states Sa and Sb, we calculate \nits LUV and ALUV. Also, we obtain the link signatures for states, Sa and Sb. Based on the signatures, \nwe compute num links, the total number of the links used in Sa and Sb combined. The goal is to reduce \nthe value of this variable as much as possible under performance constraints. We sort the communication \ncommands in these two states into a sequence with ascending routing .exibilities (represented by |Ai,p|). \nWe start with the communication command that has the lowest routing .exibility and assign a proper route \nto it. The reason for starting with the command with the lowest .exibility is that deciding the routing \nof this command early in the optimization process is ultimately more bene.cial. Otherwise, due to its \nlimited routing .exibility, dif.culties may arise for assigning a new LUV to it after many other send \noperations have their routing paths .xed. We assign the appropriate routes to the communication commands, \none-by-one, until processing all commands in Sa and Sb is complete. The method for choosing a route for \na communication com\u00admand Mi,p (recall that all the messages sent by the same Mi,p follow the same path \nin the NoC) requires some explanation. With\u00adout losing generality, assuming that the send operation to \nbe re\u00adrouted belongs to state Sa, the heuristic selects a new LUV for op\u00aderation Mi,p by considering \nall the re-routing options captured in Ai,p. For each alternate re-routing, the heuristic algorithm checks \nwhether the performance constraint is satis.ed with respect to state Sa. If the performance constraint \nis met, the new link signature is  Input: Sa, Sb two network states; R the set of communication commands \nwhose LUVs have been determined Output: U LUV for each Mi,p E((Sa .Sb) -R). ui,p // determine the LUV \nfor each communication command // in states Sa and Sb if it has not been determined yet. procedure reroute(Sa, \nSb, R) { for each Mi,p E(Sa .Sb -R) { calculate Uui,p,the LUVof Mi,p, based on X-Y routing; calculate \nAi,p, the ALUV of Mi,p; calculate Usa, the link signature of state Sa; calculate Usb, the link signature \nof state Sb; num links = |B(Usa) .B(Usb)|; if(B(Usa) <B(Usb) nB(Usb) <B(Usa)) return; sort all Mi,p \nE(Sa .Sb -R) by the routing .exibility |Ai,p|for each Mi,p E(Sa .Sb -R){ for each Uv EAi,p {if Mi,p ESa \n=Mi,p ESb {calculate Usa new by using Uv as LUV of Mi,p calculate Uby using Uv as LUV of Mi,p sb new \nif(max(Usa new ) > max(Usa)) continue; if(max(Usb new) > max(Usb)) continue; if(|B(Usa new ) .B(Usb new)|.num \nlinks) continue; if(|B(Usa new ) .B(Usb new)|= num links= |B(Usa new ) nB(Usb new )|.|B(Usa) nB(Usb)|) \ncontinue; replace Uui,p with Uv; Usa = Usa new ; Usb = Usb new; num links = |B(Usa) .B(Usb)|; }else \n{ if(Mi,p ESa) {x = a; y = b; } else {x = b; y = a; } calculate Usx new by using Uv as LUV of Mi,p if \nmax(Usx new) >max(Usx) continue; if(|B(Usx new ) .B(Usy)|>num links) continue; if(|B(Usx new ) .B(Usy)|= \nnum links= |B(Usx new) nB(Usy)|.|B(Usa) nB(Usb)|) continue; replace LUV of Mi,p, i.e., Uui,p, with Uv; \nUsx = Usx new ; num links = |B(Usx) .B(Usy)|; }}}}} function max(Uv) {return the value of the largest \nentry of Uv; } Figure 9. Communication link reuse optimization heuristic.             computed \nfor state Sa. Subsequently, using this new signature, de\u00adnoted wsa new, and the current signature of \nstate Sb (wsb), the heuristic re-calculates the total number of links used by the messages in Sa and \nSb. This total number of links is num links. Among all the alternatives in the set, Ai,p, that satisfy \nthe performance constraint, the heuristic selects the one that leads to the minimum num links value. \nIf num links cannot be reduced with any alternate utiliza\u00adtion vector, the choice is for the alternate \nLUV that maximizes the number of links reused by the two states (i.e., |e(wsa) n e(wsb)| is maximized). \nThe utilization vector for this communication com\u00admand is then .xed, and the routing assignment for this \ncommand is complete at this point. Once a communication command is given a new LUV, this command is not \nconsidered again when process\u00ading the other vertex-pairs. When all the send operations have been assigned \nnew routes, the thread codes are annotated with the corre\u00adsponding LUVs. The computational complexity \nof the heuristic is O(N * K * Cm m+n),where N is the number of network states, K is the num\u00adber of send \noperations, and Cm represents the largest routing m+n .exibility in an m \u00d7 n mesh, as mentioned earlier. \n  3.4 Example This section provides an example to illustrate how the link reuse optimization scheme \nworks. Since the steps traversing a communi\u00adcation graph are relatively simple, we only present the link \nreuse optimization between two adjacent network states. The focus is on a four-by-four mesh network and \ntwo neighboring network states in a CG: Sa and Sb. The goal is to maximize link reuse between them, assuming \nthat Sa = {M1,3, M1,7, M1,11},and Sb = {M2,3, M2,7}. Figure 10(a) and Figure 10(b) illustrate the default \nroutings of the messages sent by these communication com\u00admands in Sa and Sb, respectively. We assume \nthat message mi,j is sent by the send operation Mi,j . For example, message m2,7 is sent by the send \noperation, M2,7, which is the second send op\u00aderation in the code of thread P7 that runs on mesh node \n7. The target node of this send operation is node 14. We further assume, for clarity of presentation, \nthe size of each message is 20 packets. One can calculate the LUV for each send operation and the LS \nfor each network state, as shown in Figure 10(d), under the default routings. The ALUV sets for the send \noperations are also calcu\u00adlated, although they are not shown here due to space limitations. However, \nthe routing .exibility, given within the parentheses asso\u00adciated with the corresponding message, appears \nin Figure 10(a) and Figure 10(b). The task is to select new LUVs for send operations, with the assumption \nthat no send operation in these two states has .xed its LUV in the previous optimization steps (i.e., \nwhen processing the other state pairs). Thus, considering all the operations in the two states, we start \nfrom M2,3, which has the lowest routing .exibility. With a .exibility of 1, it has no alternate LUV. \nConsequently, the route for this message is easily .xed, as shown in Figure 10(c) (this example uses \nthe routings of the corresponding messages to represent the selected LUVs). Next, M1,11 has a routing \n.exibility of 2. However, no bene.cial alternate LUV for this communication exists, and the approach \nmaintains its default LUV, as is shown in Figure 10(e). The next send operation to process is M2,7.Since \nusing any alternate LUV for it would violate the performance constraint in state Sb (for example, using \neither of the two alternate LUVs, link l7,11 would overload), this operation is also .xed with its default \nLUV. This step completes the processing of all the send operations in state Sb. For each communication \ncommand in state, Sb, our approach decides to employ the default LUV, and the resulting routings are \nthe same as those in Figure 10(b). Thus, we do not show the result of step III in Figure 10. In the following \ntwo steps, the heuristic returns bene.cial re-routings for operations M1,7 and M1,3, as illustrated in \nFigure 10(f) and Figure 10(g), respectively. Each step reduces the total number of links used in the \ntwo network states (i.e., improves link reuse). Figure 10(g) gives the .nal routings for all the communication \ncommands in state Sa. The modi.ed LUVs and LSs returned by this method are given in Figure 10(h). Clearly, \nthe total number of links used in states Sa and Sb decreases from 16 to 12.  3.5 Code Rewriter This \ncomponent of our approach (see Figure 4) is responsible for providing a version of the message send operation, \nwhich incor\u00adporates the compiler-determined routing information. The code fragments shown in Figure 11 \ncorrespond to the example in Fig\u00adure 10. After applying our algorithm, the default message send operations, \nsend1,3(12,mi) and send1,7(13,mi), are replaced with the operations including speci.c routing information, \ni.e., send1,3(12,mi,P1,3) and send1,7(13,mi,P1,7), respectively. These versions of send operations assemble \nmessage headers by inserting routing paths according to Figure 3 and Table 1. There\u00adfore, all the messages \nsent by operation send1,3 have the message header: 10110110001110000000; whereas all the messages sent \nby operation send1,7 have the header: 10100111010000000000. The other message send operations remain \nunchanged, i.e., for those remaining messages, the .ags in their message headers are zeros, and the default \nX-Y routing determines the routing paths. L1:for i = iL to iU L1:for i = iL to iU { ... send1,3(12,mi,P1,3); \n... }... L2:for j = jL to jU { ... send2,3(15,mj ); ... { ... send1,7(13,mi,P1,7); ... }... L2:for j \n= jL to jU { ... send2,7(14,mj ); ... L1:for i = iL to iU { ... send1,11(14,mi); ... }... } } (c) Code \nrunning on node 11. (a) Code running on node (b) Code running on node 3. 7. Figure 11. Code rewriting \nfor the example in Figure 10.  3.6 Handling Deadlocks An important issue that this scheme must address \nis how to han\u00addle possible deadlocks, as the re-routings change the behavior of the default X-Y routing \nscheme, which is a deadlock-free routing algorithm [6]. Dally and Seitz [6] proved that an acyclic chan\u00adnel \ndependency graph is the necessary and suf.cient condition for avoiding deadlocks. Thus, adding a simple \ndeadlock handling pro\u00adcedure (Figure 12) breaks the possible cycles within the channel de\u00adpendency graph \nby changing some messages routings. This proce\u00addure applies after using the rerouting algorithm in Figure \n9. Check\u00ading the routing paths within each state of the two network states in question identi.es a cyclic \nchannel waiting. If none exists, the procedure simply returns, indicating no possibility of deadlock. \nOn the other hand, if there exists cyclic channel waiting (possible dead\u00adlocks), the deadlock handling \nprocedure reviews all the messages causing cyclic channel waiting. For each message, the algorithm checks \nfor an alternate path breaking the cycle in the channel de\u00adpendency graph and, at the same time, without \nincreasing the num\u00adber of links used by the two network states. If such a path exists, it replaces the \noriginal path; if not, the algorithm simply returns.1 An important observation at this point is that, \nwhile the pre\u00adviously explained deadlock handling procedure helps reduce the 1 A better approach would \nbe to search for a path that eliminates the potential deadlock but does not necessarily use the same \nnumber of links. However, this would make the algorithm much more complex.  (a) Network state Sa. (b) \nNetwork state Sb. (c) Re-routing step I (state Sb). Links: l3,2 l2,1 l1,0 l0,4 l4,8 l8,12 l7,6 l6,5 l5,9 \nl9,13 l11,10 l10,14 l3,7 l7,11 l11,15 l6,10 ... ;u1,3: (20 20 20 20 20 20 0 0 0 0 0 0 0 0 0 0 ...) ;u1,7: \n(0 0 0 0 0 0 20 20 20 20 0 0 0 0 0 0 ...) ;u1,11: (0 0 0 0 0 0 0 0 0 0 20 20 0 0 0 0 ...) ;sa: (20 20 \n20 20 20 20 20 20 20 20 20 20 0 0 0 0 ...) ;u2,3: (0 0 0 0 0 0 0 0 0 0 0 0 20 20 20 0 ...) ;u2,7: (0 \n0 0 0 0 0 20 0 0 0 0 20 0 0 0 20 ...) ;sb: (0 0 0 0 0 0 20 0 0 0 0 20 20 20 20 20 ...) |e(;s)u e(;sb)| \n= |{l3,2,l2,1,l1,0,l0,4,l4,8,l8,12,l7,6,l6,5,l5,9,l9,13,l11,10,l10,14,l3,7,l7,11,l11,15,l6,10}| =16 a \n (d) The link utilization vectors and link signatures using default X-Y routing. Usa and Usb are the \nsignatures for state Sa and Sb, respectively. The total number of links used by the two states is 16. \nNote that the LUV entries not shown above explicitly are zero. (e) Re-routing step II (state Sa). (f) \nRe-routing step IV (state Sa). (g) Re-routing step V (state Sa). Links: l7,6 l9,13 l11,10 l10,14 l3,7 \nl7,11 l11,15 l6,10 l10,9 l15,14 l14,13 l13,12 ... ;u'1,3: (0 0 0 0 20 20 20 0 0 20 20 20 ...) ;u'1,7: \n(20 20 0 0 0 0 0 20 20 0 0 0 ...) ;u'1,11: (0 0 20 20 0 0 0 0 0 0 0 0 ...) ;s' a: (20 20 20 20 20 20 \n20 20 20 20 20 20 ...) ;u'2,3: (0 0 0 0 20 20 20 0 0 0 0 0 ...) ;u'2,7: (20 0 0 20 0 0 0 20 0 0 0 0 ...) \n;s'b: (20 0 0 20 20 20 20 20 0 0 0 0 ...) (;' (;' |esa)u esb)| = |{ l7,6,l9,13,l11,10,l10,14,l3,7,l7,11,l11,15,l6,10,l10,9,l15,14,l14,13,l13,12}| \n=12 '' (h) The link utilization vectors and link signatures after re-routing. sUa and sUb are the new \nsignatures determined by our approach for state Sa and state Sb, respectively. The total number of links \nbeing used by the two states is 12. Note that the LUV entries not shown above explicitly are zero. Figure \n10. An example that illustrates how our approach works. (a) and (g) represent the default routings and \ncompiler-determined routings of network state Sa, respectively. (b) represents the default routings of \nnetwork state Sb (the compiler does not change the routings of Sb in this example). probability of experiencing \na deadlock at runtime, it cannot com\u00adpletely eliminate deadlocks. This is because the rerouting algorithm \nis pro.le driven, and a new input to the application can change the execution behavior. As a result, \na runtime based, deadlock handling approach is needed. To ensure fully deadlock-free execution, we use \nthe dynamic, hardware-supported deadlock avoidance rule em\u00adployed by the Alpha 21364 network architecture \n[18]. This rule, based on a theory proposed by Duato [8], states that a cyclic chan\u00adnel dependency graph \ndoes not lead to deadlocks if packets can drain via a deadlock-free path. By using virtual channels (separate \nbuffer queues), logically distinct networks, which include an adap\u00adtive network and a deadlock-free network, \nare constructed. In this approach, for performance reasons, most bandwidths are assigned to the adaptive \nnetwork (formed by adaptive virtual channels with no routing limitation), while the deadlock-free network \n(formed by deadlock-free virtual channels with routing restriction) used to drain deadlocked packets \noccupies limited bandwidth. Since a deadlock handling procedure already runs after rerouting (as ex\u00adplained \nabove), a limited deadlock-free bandwidth is suf.cient for draining the infrequent deadlocks. The important \npoint is that this dynamic approach does not incur extra cycle costs or energy con\u00adsumption as long as \nno deadlocks occur at runtime. When dead\u00adlocks occur, however, draining the stuck messages results in \nboth extra latency and power consumption (due to leakage).  4. Experiments 4.1 Simulation Environment \nand Benchmarks To conduct the experiments, we implemented a .it-level on-chip in\u00adterconnection network \nsimulator. The network, parametrized sim\u00adilar to that in [5, 7], is in a .ve-by-.ve con.guration. The \nlink speed is set to 1Gb/sec. Each switch input port has a buffer that can hold 64 .its; each .it is \n128 bits wide (packet size is 16 .its). The communication links in this network can be shutdown inde\u00adpendently, \nusing a time-out based mechanism as described in [27]. The time-out counter threshold for the hardware-based \nscheme is set to 1.5\u00b5sec based on some preliminary analysis. The time taken to switch a link from the \npower-down state to the active state is set Input: Sa, Sb two network states; R the set of communication \ncommands whose LUVs have been determined U LUV for each Mi,p E (Sa . Sb) decided by ui,p the rerouting \nalgorithm in Figure 9. Output: U LUV for each Mi,p E ((Sa . Sb) - R). ui,p procedure handle deadlock() \n{if ( !HasCyclicWait(Sa ) = !HasCyclicWait(Sb )) {return; } else {calculate Usa, the link signature of \nstate Sa; calculate Usb, the link signature of state Sb; num links = |B(Usa) . B(Usb)|; for each Mi,p \nE D (D: minimal subset of (Sa . Sb) - R causing channel cyclic waiting) { calculate Ai,p, the ALUV of \nMi,p; for each Uv E Ai,p { calculate Usa new by using Uv as LUV of Mi,p calculate Usb new by using Uv \nas LUV of Mi,p if(|B(Usa new ) . B(Usb new )| = num links= !HasCyclicWait(Sa ) = !HasCyclicWait(Sb )) \nreplace Uui,p with Uv; }}}}}    Figure 12. Reducing potential deadlocks. as 1\u00b5sec, and the energy \noverhead of this switching is assumed to be 140\u00b5J, based on prior research [5, 27]. This study s simulator \nuses the on-chip, interconnection network power model proposed by Chen and Peh [5]. When a link is turned \noff, it consumes zero leakage energy. The network energy model employed is not a major contribution of \nthis paper and requires no further elaboration. Un\u00adder the simulation parameters mentioned earlier, the \nleakage energy (which includes the leakage in the links as well as in the switches) contributes to about \n41% of the total network energy consumption (leakage plus dynamic), on average, under the 65nm process \ntech\u00adnology. In order to accurately quantify the performance impact of this approach, we also connected \nthe network simulator to SIM-ICS [11]. Each node of the architecture is an 800 MHz, embedded in-order, \nCPU with 32KB instruction and data caches. The compiler component for this approach uses the Paradigm \ncompiler infrastructure [30]. We modi.ed the original front-end of the compiler to accept C codes (in \naddition to Fortran codes). In\u00adput code is optimized such that, for each loop nest, the outermost loop \nthat does not carry any loop-carried data dependencies is par\u00adallelized and the inter-processor communication \nis hoisted to the highest loop level possible using message vectorization. This is a well-known communication \noptimization. The communication li\u00adbrary used for generating communication calls is MPI [29]. Having \ndetermined the code fragment that will be executed by each pro\u00adcessor, invoking the approach discussed \nin this paper follows. This approach determines the link signatures, builds the communication graph, \nand performs message re-routing, as explained earlier. Both communication graph traversal schemes (Scheme \nI and Scheme II), discussed in Section 3.3.1, are implemented. The experimen\u00adtal methodology includes \nperforming experiments with three dif\u00adferent versions for each benchmark. The .rst version is the one \nthat employs the default routing, i.e., the X-Y routing and uses the underlying hardware-based link shutdown \nscheme, modeled af\u00adter the schemes described in [27, 15, 5]. In this implementation, parameters are selected \nsuch that the energy savings achieved by link shutdown are maximized without unnecessarily hurting net\u00adwork \nlatency. In the rest of this paper, this scheme with the default routing and link shutdown hardware is \nthe base scheme. The other two schemes evaluated for this study are Scheme I and Scheme II, as discussed \nearlier in Section 3.3.1. Both schemes run on top of the same link shutdown hardware used in the base \nscheme, and the main goal in this experimental evaluation is discovering how much additional energy savings \nour compiler-directed re-routing approach generates over that of the hardware-based link shutdown approach. \n The information about the applications used in this study ap\u00adpears in Table 2. A common characteristic \nof these benchmarks is their array/loop-intensive embedded application nature. The .rst .ve benchmarks \nare collected from different sources, the next four from [33] and the last three codes are the only array-based \ncodes in the MediaBench [16] and MiBench [17] suites. The second col\u00adumn shows a brief description of \neach benchmark. The code sizes of these benchmarks range from 63 to 8,612 C lines, while their dataset \nsizes are within the range of 68.9KB-1,866.4KB. The third and fourth columns present the number of nodes \nand edges in the communication graph the proposed approach builds for each benchmark. The table indicates \nthat the number of nodes is not excessively large. The .fth column gives the leakage energy con\u00adsumption \nin the network under the base scheme, as described ear\u00adlier. The values within the parentheses show the \nleakage saving per\u00adcentages achieved by this base scheme over an alternate scheme that does not perform \nany network power management. Finally, the sixth column indicates network latency of the base scheme \n(that is, the total number of cycles spent in the network). The values within parentheses in this column \nshow the percentage degradation in network latency as compared to a case with no power optimiza\u00adtion. \nThe .fth and sixth columns show that the base scheme saves 52.2% leakage power on an average, and incurs \n8.4% additional latency over a case with no power optimization. The energy and performance results presented \nin the rest of this section are with respect to the absolute values listed in the .fth and sixth columns \nof Table 2, respectively. That is, results are normal\u00adized with respect to the corresponding results \nof the base scheme that implements the hardware-based link shutdown. We want to emphasize that the presented \nperformance and energy results in\u00adclude all extra network overheads incurred by the proposed ap\u00adproach \n(e.g., those due to augmented message headers). The in\u00adcrease in compilation time due to our optimization \nranged between 89% (3Step-log) and Lame 236% (Lame), including time spent pro.ling. Since both pro.ling \nand compilation are essentially off\u00adline activities, these increases are within acceptable range. In \nnone of the experiments we conducted (even the ones with the different input sets than those used for \npro.ling), we observed any deadlock. That is, our static deadlock elimination technique was very effec\u00adtive \nin practice.  4.2 Results Figure 13 presents the average link utilization (the fraction of the cycles \nin which the links are used for transferring packets). The (a) Default routing. (b) Re-routing (Scheme \nI). Figure 14. Percentage reductions in leakage energy consumption. Table 2. Benchmarks from experiments \nand their important char\u00adacteristics. Energy values are in mJ, and the latency values are in million \ncycles. Benchmark Brief Name Description Morph2 Morphological operations Disc Speech/music discriminator \nJpeg Compression for still images Viterbi A graphical Viterbi decoder Rasta Speech recognition 3Step-log \nLogarithmic search motion est. Full-search Full search motion est. Hier Hierarchical motion est. CG Size \nNetwork Network Node Edge Energy Latency 338 1081 75.5(64.9%) 380.4(8.8%) 816 2937 99.2(46.3%) 123.6(6.9%) \n524 1729 92.7(55.8%) 445.1(10.3%) 622 2239 72.5(32.9%) 150.8(9.8%) 498 1424 118.1(50.7%) 219.5(6.2%) \n127 396 15.2(62.4%) 107.4(5.7%) 136 448 13.5(48.0%) 95.6(12.3%) 138 503 20.4(56.3%) 151.9(7.3%) Phods \nParallel hierarchical motion est. 128 440 16.7(66.6%) 111.3(10.4%) Epic Image data compression 1144 4516 \n103.9(30.7%) 420.4(6.1%) Lame MP3 encoder 2062 7526 80.1(55.0%) 272.1(9.0%) FFT Fast Fourier transform \n416 1747 87.2(55.9%) 253.3(7.4%) Figure 16. Percentage increases in network cycles and overall execution \ntime. average link utilization for the benchmarks varies between 10.6% and 32.3%, averaging 21.4%. In \nother words, link utilization is not very high. The main reason for this is that, as explained earlier, \nthe applications in our experimental suite are optimized through several source-level communication optimizations \nthat minimize inter-processor data communication. That is, the compiler is very successful in reducing \nthe amount of inter-processor communica\u00adtion. This, in turn, reduces the average link utilization in \nthe 5 \u00d7 5 mesh (a network that is not very large). The next set of results, presented in Figure 14, show \nthe percent\u00adage reduction in leakage energy consumption when using the pro\u00adposed approach. Each bar in \nthis bar-chart gives the leakage energy saving over the base scheme. Each application has two bars, one \nfor each edge selection scheme discussed in Section 3.3.1: Scheme I and Scheme II. From these results, \nthe average leakage energy savings, when applying the compiler-directed message re-routing, Figure 15. \nCDF for link idle periods. Figure 17. Leakage energy consumptions. are 37.30% and 39.56% for Scheme I \nand Scheme II, respectively. This means that both edge selection schemes are successful in re\u00adducing \nthe leakage energy consumption, with neither being clearly superior. These results clearly show that \nthe compiler-directed link reuse optimization can improve the behavior of the hardware-based link shutdown \nscheme. To explain why message re-routing brings further savings over the base scheme alone, Figures \n15(a) and (b) present the CDF (cumulative distribution function) curves for the link idle periods with \nthe base scheme and the compiler-directed message re-routing approach (Scheme I). An (x,y) point on a \ngiven curve in these graphs indicates that y*100 percent of the total link idle periods are equal or \nless than x cycles. One can see from these plots that the message re-routing increases the link idle \nperiods sig\u00adni.cantly. The resulting increase in idle times, in turn, allows the hardware-based link \nshutdown scheme to be used more effectively. The percentage increases in the network cycles (network \nla\u00adtency) and overall execution time over the base scheme are in Fig\u00adure 16 (the network latency increases \ndue to the base scheme it\u00adself appear in the last column of Table 2). From these results, the average \nnetwork latency increase with Scheme I and Scheme II (over the base scheme) are 1.21% and 1.29%, respectively. \nIn other words, the network overhead brought by the new approach, over the base scheme, is very small. \nThis overhead is attributable to the link contention created by the approach during the optimization \nof the link signatures. A very small fraction of this increase is also due to the additional latency \nimposed by the augmented message headers. Also observable from Figure 16 is that the average increase \nin over\u00adall execution time is less than 0.5% for both Scheme I and Scheme II. Figure 17 summarizes the \nnormalized leakage energy consump\u00adtions with the different schemes. The results are normalized with respect \nto a scheme that does not employ any power management. For each application, the .rst bar in this graph \ngives the best (mini\u00admum) possible leakage consumption. Best in this context means that a link and the \ncorresponding switch are turned off as soon as they become idle and turned on (without any penalty) upon \nthe next request. The second bar for an application gives the normal\u00adized leakage consumption from the \nbase scheme. The last two bars on the other hand are for this study s Scheme I and II. These re\u00adsults \nshow that the average normalized leakage consumption val\u00adues for the best case, the base scheme, Scheme \nI and Scheme II are 21.40%, 47.85%, 30.00% and 28.92%, respectively. That is, the base scheme, Scheme \nI and Scheme II reduce leakage energy consumption by 52.15%, 70.00% and 71.08%, respectively. This means \nthat Scheme I and II save signi.cant amounts of leakage energy as compared to the base scheme. When considering \nthe dy\u00adnamic energy as well (in addition to leakage), we found that the to\u00adtal (average) energy savings \nachieved by the base scheme, Scheme I and Scheme II are 21.37%, 27.49% and 27.94%, respectively, in\u00adcluding \nthe impact of augmented message headers. These total en\u00adergy savings resulting from the proposed schemes \nare quite signif\u00adicant, considering the fact that the best scheme can save, at most, 32.22% of the total \nnetwork energy. The graph in Figure 18 plots the leakage energy savings for Scheme I with different numbers \nof nodes. The default mesh used so far in the experiments has 25 (=5\u00d75) nodes. All the curves are normalized \nwith respect to the base case with a corresponding num\u00adber of nodes. The results from Scheme II are very \nsimilar to those presented in Figure 18, so they are omitted. The leakage energy savings obtained from \ndifferent mesh sizes are similar, mainly be\u00adcause these represent normalized results with respect to \nthe base case, which already adopts a leakage saving scheme (and thus takes advantage of the additional \nidle links introduced by a larger mesh). Still, as the number of nodes increases, slight increases in \nsavings occur. The .nal measurement is the input sets effect on energy sav\u00adings. Such an analysis is \nimportant because the proposed approach is pro.le-based and a different input set can generate different \nnet\u00adwork states than those obtained by the input set used in pro.ling. Figure 19 presents the results \nfrom Scheme I. In this graph, Input\u00ad1 through Input-5 correspond to the results of different input sets \n(Input-1 being the default used in pro.ling). These results show that savings are quite consistent as \ninputs change. This is because a different input does not signi.cantly affect the inter-processor com\u00admunication \npattern of a compiler-parallelized application, although it can sometimes change the control .ow of the \napplication. As a result, little variance results from the input used to execute the ap\u00adplication.  \n 5. Discussion of Related Work In recent years, several efforts have attempted to minimize energy consumption \nof the NoC based systems and chip-to-chip networks. For example, Simunic and Boyd [25] proposed a network-centric \npower management scheme for NoCs. Their experimental results demonstrate that this technique can predict \nfuture workloads more accurately than node-centric power management schemes. Sote\u00adriou and Peh [26, 27] \nexplored the design space for communication link turn-on/off, based on a dynamic power management technique. \n Figure 19. Sensitivity to the input size (Scheme I). The results with Scheme II are similar. They proposed \na design methodology for power-aware intercon\u00adnection networks. Worm et al [32] proposed an adaptive \nlow-power transmission scheme for on-chip networks. Their goal was to mini\u00admize the energy required for \nreliable communications, while satis\u00adfying a QoS constraint by dynamically varying the voltages of the \nlinks. Kim et al [15] designed a link shutdown scheme that min\u00adimized the number of active links while \nmaintaining the connec\u00adtivity of the network. They made use of an adaptive routing algo\u00adrithm, and presented \na detailed comparison of the proposed scheme with voltage scaling. Shang et al [23] proposed applying \ndynamic voltage scaling to communication links. They used a history-based policy to lower the voltages \nof the links with low utilization. In a sense, the present research is complementary to these previous \nefforts. Since this new approach increases link idle periods, the ex\u00adpectation is that any link shutdown \nor voltage scaling based hard\u00adware mechanism is more effective when used in conjunction with the proposed \nmethod. Another group of related work is power modeling for intercon\u00adnection networks. Eisley and Peh \n[10] proposed LUNA, a high\u00adlevel power analysis framework for on-chip networks. Wang et al [31] presented \nan architectural-level power-performance simulator for interconnection networks. Using this simulator, \ntheir paper eval\u00aduated different network architectures and the impact of different communication patterns \non energy consumption. Patel et al [21] fo\u00adcused on the power-constrained design of interconnection networks \nand proposed power models for routers and links. Raghunathan et al [22] presented a survey of energy-ef.cient \non-chip communi\u00adcation techniques that function across the different levels: circuit\u00adlevel, architecture-level, \nsystem-level, and network-level. In con\u00adtrast to these studies, the goal in this research is to explore \nthe role of a compiler in reducing the NoC energy consumption. Prior compiler work [28, 19] for chip \nmulti-processors focused mainly on improving performance. Jalabert et al [14] designed a tool called \nxpipes-Compiler, for instantiating application-speci.c NoCs. Shin and Kim [24] use different algorithms \nto explore de\u00adsign space for NoC systems. Hu and Marculescu [13] proposed an algorithm that maps a given \nset of IP blocks onto a regular NoC structure and constructed a routing function that minimized com\u00admunication. \nThe focus of these studies is to reduce energy con\u00adsumption via task mapping. Our approach is different \nfrom these others in that it focuses on reducing energy consumption through compiler-directed communication \nlink reuse. Chen et al [3] presented a compiler method that performed en\u00adergy ef.cient channel allocation \nunder performance bounds. Com\u00adpared to that static analysis, the proposed scheme uses pro.ling information \nto identify optimization opportunities. In addition, the approach can assign different routing paths \nto different message sending operations, while Chen et al assigns a single .xed path for each source-destination \nnode pair. In fact, their approach re\u00adduces the leakage energy consumption by about 20%, on average, \nover a hardware scheme that already performs link shutdown. As given in Section 4, the normalized leakage \nenergy consumption of our approach and the hardware link shutdown method are around 30% and 48%, respectively. \nThat is, the proposed scheme achieves a leakage energy reduction of about 37% over and above the hard\u00adware \nlink shutdown scheme, demonstrating the importance of se\u00adlecting routes based on individual send operations, \nrather than .x\u00ading it based on source-destination pairs (i.e., 37% saving versus 20% saving). Finally, \nChen et al [4] presents a compiler directed voltage scaling model which can be combined with the link \nshut\u00addown approach proposed in this paper to reduce NoC energy con\u00adsumption even further. Other recent \nsoftware-based techniques for NoCs include [12, 20].  6. Conclusions The main contribution of this research \nis a pro.le-driven compiler scheme that increases energy bene.ts obtained from a hardware\u00adbased communication \nlink shutdown mechanism. The proposed compiler-based approach achieves its goal by determining the routes \nof the communication messages at compile time in such a fashion that link reuse between messages is maximized \nwithout signi.cantly affecting network performance. In other words, the approach limits link usage, at \na given time, to a small set of links, and the remaining links shut down to save power. The experimen\u00adtal \nevaluation using twelve embedded applications shows that the proposed approach is quite successful in \npractice.  Acknowledgments We would like to thank Seth C. Goldstein and anonymous reviewers for their \nvaluable comments. This work is supported in part by NSF Career Award 0093082. References [1] G. Ascia, \nV. Catania, and M. Palesi. Multi-objective mapping for mesh-based NoC architectures. In Proc. International \nConference on Hardware/Software Codesign and System Synthesis, Sept. 2004. [2] L. Benini and G. D. Micheli. \nPowering networks on chips: energy\u00adef.cient and reliable interconnect design for SoCs. In Proc. the 14th \nInt. Symp. on Systems Synthesis, 2001. [3] G. Chen, F. Li, and M. Kandemir. Compiler-directed channel \nallocation for saving power in on-chip networks. In Proc. 33rd Annual Symposium on Principles of Programming \nLanguages, 2006. [4] G. Chen, F. Li, M. Kandemir, and M. J. Irwin. Reducing noc energy consumption through \ncompiler-directed channel voltage scaling. In Proc. the 2006 ACM SIGPLAN conference on Programming Language \nDesign and Implementation, pages 193 203, New York, NY, USA, 2006. ACM Press. [5] X. Chen and L.-S. Peh. \nLeakage power modeling and optimization in interconnection networks. In Proc. the Int. Symp. on Low Power \nand Electronics Design, Aug. 2003. [6] W. J. Dally and C. L. Seitz. Deadlock-free message routing in \nmultiprocessor interconnection networks. IEEE Trans. Comput., 36(5):547 553, 1987. [7] W. J. Dally and \nB. Towles. Route packets, not wires: on-chip interconnection networks. In Proc. the 38th Conf. on Design \nAutomation, 2001. [8] J. Duato. A new theory of deadlock-free adaptive routing in wormhole networks. \nIEEE Trans. Parallel and Distributed Systems, 4(12):1320 1331, 1993. [9] J. B. Duato, S. Yalamanchili, \nand L. Ni. Interconnection Networks. Morgan Kaufmann Publishers, 2002. [10] N. Eisley and L.-S. Peh. \nHigh-level power analysis of on-chip networks. In Proc. the 7th Int. Conf. on Compilers, Architectures \nand Synthesis for Embedded Systems, Sept. 2004. [11] P. S. M. et al. Simics: A full system simulation \nplatform. Computer, 35(2):50 58, 2002. [12] A. Hansson, K. Goossens, and A. Rdulescu. A uni.ed approach \nto constrained mapping and routing on network-on-chip architectures. In Proc. International Conference \non Hardware/Software Co-Design and System Synthesis, 2005. [13] J. Hu and R. Marculescu. Energy-and performance-aware \nmapping for regular NoC architectures. IEEE Trans. on Computer-Aided Design of Integrated Circuits and \nSystems, 24(4), Apr. 2005. [14] A. Jalabert, S. Murali, L. Benini, and G. D. Michieli. XpipesCom\u00adpiler: \nA tool for instantiating application speci.c Networks-on-Chip. In Proc. the Conf. on Design, Automation \nand Test in Europe, 2004. [15] E. J. Kim, K. H. Yum, G. Link, N. Vijaykrishnan, M. Kandemir, M. J. Irwin, \nM. Yousif, and C. R. Das. Energy optimization techniques in cluster interconnects. In Proc. the Int. \nSymp. on Low Power Electronics and Design, Aug. 2003. [16] http://cares.icsl.ucla.edu/MediaBench/. [17] \nhttp://www.eecs.umich.edu/mibench/. [18] S. S. Mukherjee, P. Bannon, S. Lang, A. Spink, and D. Webb. \nThe alpha 21364 network architecture. IEEE Micro, 22(1), Jan. 2002. [19] R. Nagarajan, D. Burger, K. \nS. McKinley, C. Lin, S. W. Keckler, and S. K. Kushwaha. Static placement, dynamic issue (SPDI) scheduling \nfor EDGE architectures. In Proc. International Conference on Parallel Architectures and Compilation Techniques, \nOct. 2004. [20] U. Ogras, J. Hu, and R. Marculescu. Key research problem in NoC design: A holistic perspective. \nIn Proc. International Conference on Hardware/Software Co-Design and System Synthesis, 2005. [21] C. \nS. Patel. Power constrained design of multiprocessor intercon\u00adnection networks. In Proc. the Int. Conf. \non Computer Design, Washington, DC, USA, 1997. [22] V. Raghunathan, M. B. Srivastava, and R. K. Gupta. \nA survey of techniques for energy ef.cient on-chip communication. In Proc. the 40th Design Automation \nConference, 2003. [23] L. Shang, L.-S. Peh, and N. K. Jha. Dynamic voltage scaling with links for power \noptimization of interconnection networks. In Proc. International Symposium on High-Performance Computer \nArchitecture, Feb. 2003. [24] D. Shin and J. Kim. Power-aware communication optimization for networks-on-chips \nwith voltage scalable links. In Proc. Intl. Conf. on Hardware/Software Codesign and System Synthesis, \n2004. [25] T. Simunic and S. Boyd. Managing power consumption in networks on chip. In Proc. the Conf. \non Design, Automation and Test in Europe, 2002. [26] V. Soteriou and L.-S. Peh. Dynamic power management \nfor power optimization of interconnection networks using on/off links. In Proc. Symposium on High Performance \nInterconnects, 2003. [27] V. Soteriou and L.-S. Peh. Design space exploration of power-aware on/off interconnection \nnetworks. In Proc. the 22nd Int. Conf. on Computer Design, Oct. 2004. [28] M. B. Taylor and et al. The \nRAW microprocessor: A computational fabric for software circuits and general purpose programs. IEEE Micro, \n22(2), 2002. [29] http://www-unix.mcs.anl.gov/mpi/. [30] http://www.ece.northwestern.edu/cpdc/Paradigm/Paradigm.html. \n[31] H.-S. Wang, X. Zhu, L.-S. Peh, and S. Malik. Orion: A power\u00adperformance simulator for interconnection \nnetworks. In Proc. the 35th Int. Symp. on Microarchitecture, Nov. 2002. [32] F. Worm, P. Ienne, P. Thiran, \nand G. D. Micheli. An adaptive low power transmission scheme for on-chip networks. In Proc. International \nSystem Synthesis Symposium, 2002. [33] N. D. Zervas, K. Masselos, and C. Goutis. Code transformations \nfor embedded multimedia applications: impact on power and performance. In Proc. ISCA Power-Driven Microarchitecture \nWorkshop, 1998.  \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Reducing energy consumption of a Network-on-Chip (NoC) is a critical design goal, especially for power-constrained embedded systems.In response, prior research has proposed several circuit/architectural level mechanisms to reduce NoC power consumption. This paper considers the problem from a different perspective and demonstrates that compiler analysis can be very helpful for enhancing the effectiveness of a hardware-based link power management mechanism by increasing the duration of communication links' idle periods. The proposed profile-based approach achieves its goal by maximizing the communication link reuse through compiler-directed, static message re-routing. That is, it clusters the required data communications into a small set of communication links at any given time, which increases the idle periods for the remaining communication links in the network. This helps hardware shut down more communication links and their corresponding buffers to reduce leakage power. The current experimental evaluation, with twelve data-intensive embedded applications, shows that the proposed profile-driven compiler approach reduces leakage energy by more than 35% (on average) as compared to a pure hardware-based link power management scheme.</p>", "authors": [{"name": "Feihui Li", "author_profile_id": "81452598307", "affiliation": "Pennsylvania State University, University Park, PA", "person_id": "PP14166102", "email_address": "", "orcid_id": ""}, {"name": "Guangyu Chen", "author_profile_id": "81408595968", "affiliation": "Pennsylvania State University, University Park, PA", "person_id": "PP39027714", "email_address": "", "orcid_id": ""}, {"name": "Mahmut Kandemir", "author_profile_id": "81100186744", "affiliation": "Pennsylvania State University, University Park, PA", "person_id": "P186192", "email_address": "", "orcid_id": ""}, {"name": "Ibrahim Kolcu", "author_profile_id": "81100495553", "affiliation": "University of Manchester, Manchester, United Kngdm", "person_id": "P464050", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250779", "year": "2007", "article_id": "1250779", "conference": "PLDI", "title": "Profile-driven energy reduction in network-on-chips", "url": "http://dl.acm.org/citation.cfm?id=1250779"}