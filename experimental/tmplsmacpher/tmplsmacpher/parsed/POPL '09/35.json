{"article_publication_date": "01-21-2009", "fulltext": "\n The Semantics of Progress in Lock-Based Transactional Memory Rachid Guerraoui Michal Kapalka EPFL, \nSwitzerland {rachid.guerraoui, michal.kapalka}@ep..ch Abstract Transactional memory (TM) is a promising \nparadigm for concur\u00adrent programming. Whereas the number of TM implementations is growing, however, little \nresearch has been conducted to precisely de.ne TM semantics, especially their progress guarantees. This \npa\u00adper is the .rst to formally de.ne the progress semantics of lock\u00adbased TMs, which are considered the \nmost effective in practice. We use our semantics to reduce the problems of reasoning about the correctness \nand computability power of lock-based TMs to those of simple try-lock objects. More speci.cally, we prove \nthat checking the progress of any set of transactions accessing an arbitrarily large set of shared variables \ncan be reduced to verifying a simple property of each individual (logical) try-lock used by those transactions. \nWe use this theorem to determine the correctness of state-of-the-art lock-based TMs and highlight various \ncon.guration ambiguities. We also prove that lock-based TMs have consensus number 2. This means that, \non the one hand, a lock-based TM cannot be implemented using only read-write memory, but, on the other \nhand, it does not need very powerful instructions such as the commonly used compare-and-swap. We .nally \nuse our semantics to formally capture an inherent trade-off in the performance of lock-based TM implementations. \nNamely, we show that the space complexity of every lock-based software TM implementation that uses invisible \nreads is at least exponential in the number of objects accessible to transactions. Categories and Subject \nDescriptors D.1.3 [Programming Tech\u00adniques]: Concurrent Programming; F.2.2 [Analysis of Algorithms and \nProblem Complexity]: Nonnumerical Algorithms and Prob\u00adlems General Terms Theory, Algorithms, Veri.cation \nKeywords Transactional memory, lock, try-lock, consensus num\u00adber, impossibility, lower bound, reduction, \nsemantics 1. Introduction Multi-core processors are predicted to be common in home com\u00adputers, laptops, \nand maybe even smoke detectors. To exploit the power of modern hardware, applications will need to become \nin\u00adcreasingly parallel. However, writing scalable concurrent programs is hard and error-prone with traditional \nlocking techniques. On the one hand, coarse-grained locking throttles parallelism and causes Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 09, January \n18 24, 2009, Savannah, Georgia, USA. Copyright c &#38;#169; 2009 ACM 978-1-60558-379-2/09/01. . . $5.00 \nlock contention. On the other hand, .ne-grained locking is usually an engineering challenge, and as such \nis not suitable for use by the masses of programmers. Transactional memory (TM) (Herlihy and Moss 1993) \nis a promising technique to facilitate concurrent programming while delivering comparable performance \nto .ne-grained locking imple\u00admentations. In short, a TM allows concurrent threads of an applica\u00adtion \nto communicate by executing lightweight, in-memory transac\u00adtions. A transaction accesses shared data \nand then either commits or aborts. If it commits, its operations are applied to the shared state atomically. \nIf it aborts, however, its changes to the shared data are lost and never visible to other transactions. \nWhile a large number of TM implementations have been pro\u00adposed so far, there is still no precise and \ncomplete description of the semantics of a TM. Indeed, a correctness criterion for TM, called opacity, \nhas been proposed (Guerraoui and Kapalka 2008a), and the progress properties of obstruction-free TM implementations \nhave been de.ned (Guerraoui and Kapalka 2008c). However, opacity is only concerned with safety it does \nnot specify when transactions need to commit. (For example, a TM that aborts every transac\u00adtion could \ntrivially ensure opacity.) Moreover, TM implementations that are considered effective (Ennals 2006), \ne.g., TL2 (Dice et al. 2006), TinySTM (Felber et al. 2008), a version of RSTM (Marathe et al. 2006), \nBartokSTM (Harris et al. 2006), or McRT-STM (Adl-Tabatabai et al. 2006) are not obstruction-free. They \ninternally use locking, in order to reduce the overheads of TM mechanisms, and do not ensure obstruction-freedom, \nwhich inherently precludes the use of locks. Lock-based TMs do ensure some progress for transactions, \nfor otherwise nobody would use them. However, this has never been precisely de.ned. The lack of such \na de.nition hampers the porta\u00adbility of applications that use lock-based TMs, and makes it dif\u00ad.cult \nto reason formally about their correctness or to establish whether any performance limitation is inherent \nor simply an arti\u00adfact of a speci.c implementation. This paper de.nes the progress semantics of lock-based \nTMs. We do so by introducing a new property, which we call strong pro\u00adgressiveness,1 and which stipulates \nthe two following requirements. 1. A transaction that encounters no con.ict must be able to com\u00admit. \n(Basically, a con.ict occurs when two or more concurrent transactions access the same transactional variable \nand at least one of those accesses is not read-only.) 2. If a number of transactions have only a simple \ncon.ict, i.e., on a single transactional variable, then at least one of them must be able to commit. \n The former property captures the common intuition about the progress of any TM (see (Scott 2006)). \nThe second property en\u00adsures that con.icts that are easy to resolve do not cause all con\u00ad 1 We call it \nstrong by opposition to a weaker form of progressiveness that we also introduce in this paper. .icting \ntransactions to be aborted. This is especially important when non-transactional accesses to shared variables \nare encapsu\u00adlated inside unit transactions to ensure strong atomicity (Blun\u00addell et al. 2006). Strong \nprogressiveness, together with opacity and operation-level wait-freedom,2 is ensured by state of the \nart lock\u00adbased implementations, such as TL2, TinySTM, RSTM, Bartok-STM, and McRT-STM.3 We use our strong \nprogressive semantics to reduce the prob\u00adlems of reasoning about the correctness and computability power \nof lock-based TMs to those of simple try-lock objects (Scott and Scherer III 2001; Jayanti 2003). We \n.rst show that proving strong progressiveness of a set of transactions accessing any number of shared \nvariables can be reduced to proving a simple property of every individual logical try-lock that protects \nthose variables. Ba\u00adsically, we prove that if it is possible to say which parts of a TM algorithm can \nbe viewed as logical try-locks (in a precise sense we de.ne in the paper), and if those logical try-locks \nare strong, then the TM is strongly progressive. Intuitively, a try-lock is strong if it guarantees that \namong processes that compete for the unlocked try\u00adlock, one always acquires the try-lock (most try-locks \nin the liter\u00adature that are implemented from compare-and-swap or test-and-set are strong). We illustrate \nour reduction approach on state-of-the-art lock-based TMs. We formally establish and prove their correctness \nwhile highlighting some of their con.gurations that, maybe unex\u00adpectedly, violate the progress semantics. \nThen, still using the try-lock reduction, we show that a lock\u00adbased TM has consensus number 2 in the \nparlance of (Herlihy 1991). The consensus number is a commonly used metric for the computational power \nof a shared-memory abstraction, and is ex\u00adpressed as the maximum number of processes that can solve a \nnon\u00adtrivial agreement problem (namely consensus (Herlihy 1991)) in a wait-free manner using this abstraction. \nThe fact that a lock-based TM has consensus number 2 means that such a TM cannot be im\u00adplemented using \nonly read-write memory instructions, but, on the other hand, powerful instructions such as compare-and-swap \nare not necessary to implement a lock-based TM. In fact, we give an implementation of a lock-based TM \nus\u00ading read-write and test-and-set instructions. This implementation might be interesting in its own \nright when compare-and-swap in\u00adstructions are not available or simply too expensive. Interestingly, we \nhighlight an alternative semantics we call weak progressive\u00adness which enables TMs with consensus number \n1 and can thus be implemented using only read-write memory. Intuitively, weak progressiveness requires \nonly that a transaction that encounters no con.icts commits. This might be considered a viable alternative \nto strong progressiveness for lightweight lock-based implementa\u00adtions. We .nally use our progress semantics \nto determine an inher\u00adent trade-off between the required memory and the latency of reads in lock-based \nTMs. This trade-off impacts the performance and/or progress guarantees of a TM but it was never formally \nestablished, precisely because of the lack of any precise semantics. We show that the space complexity \nof every lock-based TM that uses the in\u00advisible reads strategy4 is at least exponential in the number \nof vari\u00adables available to transactions. This might seem surprising, since it 2 Wait-freedom (Herlihy \n1991) requires threads executing operations on transactional data within transactions to make progress \nindependently, i.e., without waiting for each other. Maybe surprisingly, this property can easily be \nensured by lock-based TMs. 3 The source code of the implementations of BartokSTM and McRT-STM is not \npublicly available. We could thus verify strong progressiveness of those TMs only from their algorithm \ndescriptions in (Harris et al. 2006) and (Adl-Tabatabai et al. 2006), respectively. 4 With invisible \nreads, the reading of transactional variables is performed optimistically, without any (shared or exclusive) \nlocking or updates to is not obvious that modern lock-based TMs have non-linear space complexity. The \nexponential (or, in fact, unbounded) complexity comes from the use of timestamps that determine version \nnum\u00adbers of shared variables. TM implementations usually reserve a constant-size word for each version \nnumber (which gives linear space complexity). However, an over.ow can happen and has to be handled in \norder to guarantee correctness (opacity). As we ex\u00adplain in Section 6.3, this requires (a) limiting the \nprogress of trans\u00adactions when over.ow occurs and (b) preventing read-only trans\u00adactions from being completely \ninvisible. Concretely speaking, our result means that ef.cient TM implementations (the ones that use \ninvisible reads) must either intermittently (albeit very rarely) vio\u00adlate progress guarantees, or use \nunbounded timestamps. Summary of contributions. To summarize, this paper contributes to the understanding \nof TM design and implementations by present\u00ading the .rst precise semantics of a large class of popular \nTMs lock-based ones. We precisely de.ne the progress semantics of such TMs and propose reduction approaches \nto simplify their ver\u00adi.cation and computational study. We also use our semantics to study their inherent \nperformance bottlenecks. Roadmap. The rest of the paper proceeds as follows. First, in Section 2, we \ndescribe the basic model and terminology used to state our semantics and prove our results. Then, in \nSection 3, we de.ne the progress semantics of lock-based TMs. In Section 4, we show how to simplify the \nveri.cation of strong progressiveness. Next, in Sections 5 and 6, we establish the fundamental power \nand limitations of lock-based TMs. We also discuss in those sections the impact of weakening progress \nproperties. Finally, in Section 7, we discuss possible extensions of the results presented in this paper. \nRelated work. It is worth noting that there has been an attempt to describe the overall semantics of \nTMs (Scott 2006) (including lock\u00adbased ones). However, the approach taken there is very low-level the \nproperties are de.ned with respect to speci.c TM protocols and strategies. Our approach is more general: \nwe de.ne semantics that is implementation-agnostic and that is visible through the public interface of \na TM to a user. We also show how this semantics can be veri.ed. There have also been other attempts to \ndescribe the semantics of a TM, e.g., in (Vitek et al. 2004; Jagannathan et al. 2005; Abadi et al. 2008; \nMoore and Grossman 2008; Menon et al. 2008). Those papers, however, focus on safety, i.e., serializability. \nIn (Moore and Grossman 2008) there is a notion of progress, but it refers to deadlock-freedom of the \nwhole system (i.e., making sure at least one thread can execute a step at any given time) rather than \nprogress of individual transactions. 2. Preliminaries 2.1 Shared Objects and their Implementations We \nconsider an asynchronous shared memory system of n pro\u00adcesses (threads) p1, ..., pn that communicate \nby executing oper\u00adations on (shared) objects. (At the hardware level, a shared object is simply a word \nin shared memory with the instructions supported by a given processor, e.g., read, write, or compare-and-swap.) \nAn example of a very simple shared object is a register,5 which exports only read and write operations. \nOperation read returns the current state (value) of the register, and write(v) sets the state of the \nregister to value v. Hence, a register provides the basic read-write memory semantics. shared state. \nInvisible reads are used by most TM implementations and considered crucial for good performance in read-dominated \nworkloads. 5 Note that we use here the term register in its distributed computing sense: a read-write \nabstraction. Consider a single run of any algorithm. A history is a sequence of invocations and responses \nof operations that were executed by processes on (shared) objects in this run. A history of an object \nx is a history that contains only operations executed on x. (Note here that we assume that events executed \nin a given run can be totally ordered by their execution time; events that are issued at the same time, \ne.g., on multi-processor systems, can be ordered arbitrarily.) An object x may be implemented either \ndirectly in hardware, or from other, possibly more primitive, objects, which we call base objects. If \nIx is an implementation of an object x, then an imple\u00admentation history of Ix is a sequence of (1) invocations \nand re\u00adsponses of operations on x, and (2) corresponding operations on base objects (called steps) that \nwere executed by Ix (i.e., by pro\u00adcesses executing Ix) in some run. Hence, intuitively, a history of \nan object x represents what happened in some run at the (public) interface of x. An implementation history, \nin addition, shows what steps the implementation of x executed in response to the opera\u00adtions invoked \non x. In algorithms, for simplicity, we assume that base objects such as registers and test-and-set objects \nare atomic, i.e., lineariz\u00adable (Herlihy and Wing 1990). That is, operations on those objects appear \n(to the application) as if they happened instantaneously at some unique point in time between their invocation \nand response events. (For example, in Java, a volatile variable is an atomic reg\u00adister, while an object \nof class AtomicInteger is an atomic object that supports operations such as get, set, incrementAndGet, \netc.) However, assuming a weaker memory model does not impact our results: the progress properties we \nde.ne do not rely on atom\u00adicity, strong try-lock objects are not linearizable, and atomic reg\u00adisters \nof any size can be implemented out of 1-bit safe (the most primitive) registers (Lamport 1986). If E \nis an (implementation) history, then E|pi denotes the restriction of E to events (including steps) executed \nby process pi, and E|x denotes the restriction of E to events on object x and steps of the implementation \nof x. We assume that processes execute operations on objects sequentially. That is, in every restriction \nE|pi of an (implementation) history E, no two operations and no two steps overlap. We focus on object \nimplementations that are wait-free (Herlihy 1991). Intuitively, an implementation Ix of an object x is \nwait-free if a process that invokes an operation on x is never blocked indef\u00adinitely long inside the \noperation, e.g., waiting for other processes. Hence, processes can make progress independently of each \nother. More precisely: DEFINITION 1. An implementation Ix of an object x is wait-free, if whenever any \nprocess pi invokes an operation on x, pi returns from the operation within a .nite number of its own \nsteps. 2.2 Transactional Memory (TM) A TM enables processes to communicate by executing transactions. \nFor simplicity, we will say that a transaction T performs some ac\u00adtion, meaning that the process executing \nT performs this action within the transactional context of T . A transaction T may perform operations \non transactional variables, which we call t-variables for short. For simplicity, we assume that every \nt-variable x sup\u00adports only two operations: read that returns the current state (value) of x, and write(v) \nthat sets the state of x to value v. We discuss in Section 7 what changes when t-variables are arbitrary \nobjects, i.e., objects that have operations beyond read and write (e.g., incre\u00admentAndGet). Note, however, \nthat most existing TMs either pro\u00advide only read-write t-variables (e.g., word-based TMs), or effec\u00adtively \ntreat all operations on t-variables as reads and writes (e.g., without exploiting the commutativity relations \nbetween non-read\u00adonly operations). Each transaction has its own unique identi.er, e.g., T1, T2, etc. \nA transaction Tk may access (read or write) any number of t\u00advariables. Then, Tk may either commit or \nabort. We assume that once Tk commits or aborts Tk does not perform any further actions. In this sense, \nrestarting a transaction Tk (i.e., the computation Tk was supposed to perform) is considered in our model \nas a different transaction (with a different identi.er). We can treat a TM as an object with the following \noperations: treadk(x) and twritek(x, v) that perform, respectively, a read or a write(v) operation on \na t-variable x within a transaction Tk,  tryCk that is a request to commit transaction Tk,  tryAk that \nis a request to abort transaction Tk.  Each of the above operations can return a special value Ak that \nin\u00addicates that the operation has failed and the respective transaction Tk has been aborted. Operation \ntryCk returns value Ck if commit\u00adting Tk has been successful. Operation tryAk always returns Ak (i.e., \nit always succeeds in aborting transaction Tk). The above operations of a TM, in some form, are either \nexplic\u00aditly used by a programmer (e.g., in TL2, TinySTM, RSTM), or in\u00adserted by a TM-aware compiler (e.g., \nin McRT-TM, Bartok-STM). Even if the compiler is responsible for inserting those operations, the programmer \nmust specify which blocks of code are parts of transactions, and retains full control of what operations \non which t\u00advariables those transactions perform. Hence, in either case, this TM interface is visible \nto a programmer, and so are properties de.ned with respect to this interface. If H is an (implementation) \nhistory of a TM object, then H|Tk denotes the restriction of H to only events of transaction Tk. We say \nthat a transaction Tk is in a history H, and write Tk . H, if H|Tk is a non-empty sequence. Let H be \nany history and Tk be any transaction in H. We say that Tk is committed in H, if H contains response \nCk of operation tryCk. We say that Tk is aborted in H, if H contains response Ak of any TM operation. \nWe say that a transaction Tk follows a transaction Ti in a history H, if Ti is committed or aborted in \nH and the .rst event of Tk in H follows the last event of Ti in H. If neither Tk follows Ti in H, nor \nTi follows Tk in H, then we say that Ti and Tk are concurrent in H. We assume that every transaction \nitself is sequential. That is, for every history H of a TM and every transaction Tk . H, H|Tk is a sequence \nof non-overlapping TM operations. Clearly, operations of different transactions can overlap. We also \nassume that each transaction is executed by a single process, and that each process executes only one \ntransaction at a time (i.e., transactions at the same process are never concurrent). 2.3 Try-Locks All \nlock-based TMs we know of use (often implicitly) a special kind of locks, usually called try-locks (Scott \nand Scherer III 2001). Intuitively, a try-lock is an object that provides mutual exclusion (like a lock), \nbut does not block processes inde.nitely. That is, if a process pi requests a try-lock L but L is already \nacquired by a different process, pi is returned the information that its request failed instead of being \nblocked waiting until L is released. Try-locks keep the TM implementation simple and avoid dead\u00adlocks. \nMoreover, if any form of fairness is needed, it is provided at a higher level than at the level of individual \nlocks then more information about a transaction can be used to resolve con.icts and provide progress. \nEnsuring safety and progress can be effectively separate tasks. More precisely, a try-lock is an object \nwith the following oper\u00adations: 1. trylock, that returns true or false; and 2. unlock, that always returns \nok.  Let L be any try-lock. If a process pi invokes trylock on L and is returned true, then we say that \npi has acquired L. Once pi ac\u00adquires L, we say that (1) pi holds L until pi invokes operation un\u00adlock \non L, and (2) L is locked until pi returns from operation unlock on L. (Hence, L might be locked even \nif no process holds L when some process that was holding L is still executing operation unlock on L.) \nEvery try-lock L guarantees the following property, called mu\u00adtual exclusion: no two processes hold L \nat the same time. For simplicity, we assume that try-locks are not reentrant. That is, a process pi may \ninvoke trylock on a try-lock L only when pi does not hold L. Conversely, pi may invoke unlock on L only \nwhen pi holds L. Intuitively, we say that a try-lock L is strong if whenever several processes compete \nfor L, then one should be able to acquire L. This property corresponds to deadlock-freedom, livelock-freedom, \nor progress (Raynal 1986) properties of (blocking) locks. DEFINITION 2. We say that a try-lock L is strong, \nif L ensures the following property, in every run: if L is not locked at some time t and some process \ninvokes operation trylock on L at t, then some process acquires L after t. While there exists a large \nnumber of lock implementations, only a few are try-locks or can be converted to try-locks in a straightforward \nway. The technical problems of transforming a queue (blocking) lock into a try-lock are highlighted in \n(Scott and Scherer III 2001). It is trivial to transform a typical TAS or TATAS lock (Raynal 1986) into \na strong try-lock (e.g., Algorithm 4 in Section 5.2). 3. Progress of a Lock-Based TM Lock-based TMs are \nTM implementations that use (internally) mutual exclusion to handle some phases of a transaction. Most \nof them use some variant of the two-phase locking protocol, well\u00adknown in the database world (Eswaran \net al. 1976). From the user s perspective, however, the choice of the mecha\u00adnism used internally by a \nTM implementation is not very important. What is important is the semantics the TM manifests on its public \ninterface, and the time/space complexities of the implementation. If those properties are known, then \nthe designer of a lock-based TM is free to choose the techniques that are best for a given hardware platform, \nwithout the fear of breaking existing applications that use a TM. As we already mentioned, the correctness \ncriterion for TMs, in\u00adcluding lock-based ones, is usually opacity (Guerraoui and Kapalka 2008a). This \nproperty says, intuitively, that (1) committed trans\u00adactions should appear as if they were executed sequentially, \nin an order that agrees with their real-time ordering, (2) no trans\u00adaction should ever observe the modi.cations \nto shared state done by aborted or live transactions, and (3) all transactions, including aborted and \nlive ones, should always observe a consistent state of the system. The .rst two properties correspond, \nroughly, to the clas\u00adsical database properties: strict serializability (Papadimitriou 1979) and the strongest \nvariant of recoverability (Hadzilacos 1988), re\u00adspectively. The last property is unique to TMs, and needs \nto be ensured to prevent unexpected crashes or incorrect behavior of ap\u00adplications that use a TM. However, \nopacity is not enough. A TM that always aborts every transaction, or that blocks transactions in.nitely \nlong, could ensure opacity and still be useless from the user s perspective. In this section, we de.ne \nthe progress properties of a lock-based TM. These involve individual operations of transactions, where \nit is typical to require wait-freedom, and entire transactions, for which we will require our notion \nof strong progressiveness. 3.1 Liveness of TM Operations If a process pi invokes an operation (tread, \ntwrite, tryC, or tryA) on a TM, we expect that pi eventually gets a response from the operation. The \nresponse might be the special value Ak that informs pi that its current transaction Tk has been aborted. \nWe assume that each implementation of a TM is a wait-free object. That is, a TM ensures wait-freedom \non the level of its oper\u00adations. This property is indeed ensured by many current lock-based TMs: if a \ntransaction Tk encounters a con.ict, Tk is immediately aborted and the control is returned to the process \nexecuting Tk. Note that a TM may use a contention manager to decide what to do in case of a con.ict. \nA contention manager is a logically external module that can reduce contention by delaying or aborting \nsome of the transactions that con.ict. In principle, a contention manager could make transactions wait \nfor each other, in which case wait\u00adfreedom would be violated. However, such contention managers change \nthe progress properties of a TM signi.cantly and as such should be considered separately. Operation wait-freedom \nmay also be violated periodically by some TM mechanisms that handle over.ows. While those can be unavoidable, \nas we discuss in Section 6.3, they are executed very rarely. Moreover, one can easily predict when they \ncould start. In this sense, wait-freedom can be guaranteed except for some short periods that can be \nsignalled in advance to processes by, e.g., setting a global .ag. 3.2 Progress of Transactions Intuitively, \na transaction makes progress when it commits. One would like most transactions to commit, except those \nthat were explicitly requested by the application to be aborted (using a tryA operation of a TM). However, \na TM may be often forced to abort some transactions when the con.icts between them cannot be easily resolved. \nWe will call such transactions forcefully aborted. The strong progressiveness property we introduce here \nde.nes when precisely a transaction can be forcefully aborted. Intuitively, strong progressiveness says \nthat (1) if a transaction has no con.ict then it cannot be forcefully aborted, and (2) if a group of \ntransactions con.ict on a single t-variable, then not all of those transactions can be forcefully aborted. \nRoughly speaking, two or more transactions con.ict if they access the same t-variable in a con.icting \nway, i.e., if at least one of those accesses is a write operation. (It is worth noting that the notion \nof a con.ict can be easily generalized to t-variables with arbitrary operations, and to arbitrary mappings \nbetween t-variables and locks that may allow false con.icts. We discuss this in Section 7.) Strong progressiveness \nis not the strongest possible progress property. The strongest one, which requires that no transaction \nis ever forcefully aborted, cannot be implemented without throttling signi.cantly the parallelism between \ntransactions, and is thus im\u00adpractical in multi-processor systems. Strong progressiveness, however, still \ngives a programmer the following important advantages. First, it guarantees that if two in\u00addependent \nsubsystems of an application do not share any mem\u00adory locations (or t-variables), then their transactions \nare completely isolated from each other (i.e., a transaction executed by a sub\u00adsystem A does not cause \na transaction in a subsystem B to be forcefully aborted). Second, it avoids spurious aborts: the cases \nwhen a transaction can abort are strictly de.ned. Third, it ensures global progress for single-operation \ntransactions, which is impor\u00adtant when non-transactional accesses to t-variables are encapsu\u00adlated into \ntransactions in order to ensure strong atomicity (Blundell et al. 2006). Finally, it ensures that processes \nare able to eventu\u00adally communicate via transactions (albeit in a simpli.ed manner through a single t-variable \nat a time). Nevertheless, one can imag\u00adine many other reasonable progress properties, for which strong \nprogressiveness can be a good reference point. More precisely, let H be any history of a TM and Tk be \nany transaction in H. We say that Tk is forcefully aborted in H, if Tk is aborted in H and there is no \ninvocation of operation tryAk in H. We denote by WSetH (Tk) and RSetH (Tk) the sets of t-variables on \nwhich Tk executed, respectively, a write or a read operation in H. We denote by RWSetH (Tk) the union \nof sets RSetH (Tk) and WSetH (Tk), i.e., the set of t-variables accessed (read or written) by Tk in history \nH. We say that two transactions Ti and Tk in H con.ict on a t-variable x, if (1) Ti and Tk are concurrent \nin H, and (2) either x is in WSetH (Tk) and in RWSetH (Ti), or x is in WSetH (Ti) and in RWSetH (Tk). \nWe say that Tk con.icts with a transaction Ti in H if Ti and Tk con.ict in H on some t-variable. Let \nH be any history, and Ti be any transaction in H. We denote by CVarH (Ti) the set of t-variables on which \nTi con.icts with any other transaction in history H. That is, a t-variable x is in CVarH (Ti) if there \nexists a transaction Tk . H, k = i, such that Ti con.icts with Tk on t-variable x. Let Q be any subset \nof the set of transactions in a history H. We denote by CVarH (Q) the union of sets CVarH (Ti) for all \nTi . Q. Let CTrans(H) be the set of subsets of transactions in a his\u00adtory H, such that a set Q is in \nCTrans(H) if no transaction in Q con.icts with a transaction not in Q. In particular, if Ti is a transaction \nin a history H and Ti does not con.ict with any other transaction in H, then {Ti}. CTrans(H). DEFINITION \n3. A TM implementation M is strongly progressive, if in every history H of M the following property is \nsatis.ed: for every set Q . CTrans(H), if |CVarH (Q)|= 1, then some transaction in Q is not forcefully \naborted in H. 4. Verifying Strong Progressiveness Verifying that a given TM implementation M ensures \na given prop\u00aderty P might often be dif.cult as one has to reason about a large number of histories involving \nan arbitrary number of transactions accessing an arbitrary number of t-variables. This complexity is \ngreatly reduced if one can reduce the veri.cation task to some small subset of histories of M, e.g., \ninvolving a limited num\u00adber of t-variables or transactions. This approach has been used, e.g., in (Guerraoui \net al. 2008) to automatically check opacity, obstruction-freedom, and lock-freedom of TMs that feature \ncertain symmetry properties. In this section, we show how to reduce the problem of prov\u00ading strong progressiveness \nof histories with arbitrary numbers of transactions and t-variables to proving a simple property of each \nindividual (logical) try-lock used in those histories. Basically, we show that if a TM implementation \nM uses try-locks, or if one can assign logical try-locks to some parts of the algorithm of M, and if \neach of those try-locks is strong, then M ensures strong progres\u00adsiveness. Unlike in (Guerraoui et al. \n2008), we do not assume any symmetry properties of a TM. Our result is thus complementary to that of \n(Guerraoui et al. 2008), not only because it concerns a different property, but also because it uses \na different approach. Our reduction theorem is general as it encompasses lock-based TMs that use invisible \nreads, i.e., in which readers of a t-variable are not visible to other transactions, as well as those \nthat use visible ones. We show also how the theory presented here can be used to prove strong progressiveness \nof TL2, TinySTM, RSTM, and McRT-STM. Finally, we point out one of the ambiguities of ensuring strong \nprogressiveness with visible reads. 4.1 Reduction Theorem Let M be any TM implementation, and E be any \nimplementation history of M. Let E' be any implementation history that is ob\u00adtained from E by inserting \ninto E any number of invocations and responses of operations of a try-lock Lx for every t-variable x. \nWe say that E' is a strong try-lock extension of E, if the following conditions are satis.ed in E': STLE1. \nFor every t-variable x, E'|Lx is a valid history of a strong try-lock object; STLE2. For every process \npi and every t-variable x, if, at some time t, pi invokes trylock on Lx or pi holds Lx, then pi executes \nat t in E' a transaction Tk such that x . WSetE' (Tk); STLE3. For every process pi and every transaction \nTk . E'|pi, if Tk is forcefully aborted in E', then either (1) pi while executing Tk is returned false \nfrom every operation trylock on some try\u00adlock Lx, or (2) there is a t-variable x . RSetE' (Tk), such \nthat some process other than pi holds Lx at some point while pi executes Tk but before Tk acquires Lx \n(if at all). THEOREM 4. For any TM implementation M, if there exists a strong try-lock extension of every \nimplementation history of M, then M is strongly progressive. Proof. Assume, by contradiction, that there \nexists a TM implemen\u00adtation M , such that some implementation history E of M has a strong try-lock extension \nE', but E violates strong progressive\u00adness. This means that there is a set Q in CTrans(E), such that \n|CVarE(Q)|= 1 and every transaction in Q is forcefully aborted in E. Recall that Q is a subset of transactions, \nsuch that no trans\u00adaction in Q has a con.ict with a transaction outside of Q. Assume .rst that CVarE \n(Q)= \u00d8. But then no transaction in set Q has a con.ict, and so, by STLE1 2, no transaction in Q can fail \nto acquire a try-lock, or read a t-variable x such that try\u00adlock Lx is held by a concurrent transaction. \nHence, by STLE3, no transaction in Q can be forcefully aborted a contradiction. Let x be the t-variable \nthat is the only element of set CVarE (Q). Note .rst that if a transaction Tk in Q invokes opera\u00adtion \ntrylock on some try-lock Ly (where y is a different t-variable than x) then, by STLE2, no other transaction \nconcurrent to Tk in\u00advokes trylock on Ly or reads t-variable y. This is because no trans\u00adaction in Q con.icts \non a t-variable different than x. Assume .rst that no transaction in set Q acquires try-lock Lx. But \nthen, by STLE1 3, no transaction in Q can be forcefully aborted a contradiction. Let Tk be the .rst transaction \nfrom set Q to acquire try-lock Lx. By STLE3, and because Tk is forcefully aborted, there is a trans\u00adaction \nTi that holds Lx after Tk starts and before Tk acquires Lx. Clearly, by STLE2, x must be in WSetE(Ti), \nand so Ti must be in set Q. But then Ti acquires Lx before Tk a contradiction with the assumption that \nTk is the .rst transaction from set Q to acquire Lx. D 4.2 Examples We show here how our reduction theorems \ncan be used to prove the strong progressiveness of TL2, TinySTM, RSTM (one of its variants), and McRT-STM. \nNone of those TM implementations explicitly use try-locks, and so we need to show which parts of their \nalgorithms correspond to operations on logical try-locks for respective t-variables. We assume the use \nof a simple contention manager that makes each transaction that encounters a con.ict abort itself. Such \na contention manager (possibly with a back-off protocol) is usually the default one in word-based TMs. \nWe also assume that the mapping between t-variables and locks is a one-to\u00adone function (which is the \ndefault in RSTM). This assumption is revisited in Section 7. TL2. This TM uses commit-time locking and \ndeferred updates. That is, locking and updating t-variables is delayed until the com\u00admit time of transactions. \nThe TL2 algorithm is roughly the follow\u00ading (for a process pi executing a transaction Tk): 1. When Tk \nstarts, pi reads the read timestamp of Tk from a global counter C. 2. If Tk reads a t-variable x, pi \nchecks whether x is not locked and whether the version number of x is lower or equal to the read timestamp \nof Tk. If any of those conditions is violated then Tk is aborted. 3. Once Tk invokes tryCk, pi .rst \ntries to lock all t-variables that were written to by Tk. Locking of a t-variable x is done by executing \na compare-and-swap (CAS) operation on a memory word w(x) that contains, among other information, a locked \n.ag. If pi successfully changes the locked .ag from false to true, then pi becomes the exclusive owner \nof x and can up\u00addate x. If CAS fails, however, Tk is aborted. 4. Once all t-variables written to by \nTk are locked, pi atomically increments and reads the value of the global counter C. The read value is \nthe write timestamp of Tk. 5. Next, pi validates transaction Tk by checking, for every t\u00advariable x \nread by Tk, whether x is not locked by a transaction other than Tk and whether the version number of \nx is lower or equal to the read timestamp of Tk. Again, if any of those conditions is violated then transaction \nTk is aborted (and its locks released). 6. Then, pi updates all the states of the locked t-variables \nwith the values written by Tk and the write timestamp of Tk. 7. Finally, Tk releases all the locked \nt-variables.  It is easy to assign logical try-locks to the above algorithm of TL2, i.e., to build a \ntry-lock extension of every implementation history E of TL2. Basically, we put an invocation and response \nof operation trylock on a try-lock Lx around any CAS operation that operates on the locked .ag of any \nt-variable x. The response is true if CAS succeeds, and false otherwise. We also put an invocation and \nresponse of operation unlock on Lx around the write operation that sets the locked .ag of x to false. \nIt is straightforward to see that this way we indeed obtain a valid try-lock extension of any implementation \nhistory E of TL2: 1. Property STLE1 is ensured because a CAS on a word w(x) can fail only when some other \nCAS on w(x) already succeeded, and once a CAS on w(x) succeeds, no other CAS on w(x) can succeed until \nthe locked .ag is reset. Hence, the single CAS operation indeed implements a strong try-lock. 2. Property \nSTLE2 is ensured because a transaction Ti invokes CAS on a word w(x) only when (1) Ti wrote to t-variable \nx, and (2) Ti is in its commit phase. 3. To prove that TL2 ensures property STLE3, consider any force\u00adfully \naborted transaction Tk executed by some process pi (in some implementation history E of TL2). Assume \n.rst that a CAS operation executed by Tk (i.e., by pi while executing Tk) on some word w(x) fails. But \nthen (1) Tk could not have locked try-lock Lx before, and (2) Tk is immediately aborted after\u00adwards. \nHence, property STLE3 is trivially ensured. This means that Tk reads some t-variable x and either (1) \nw(x) has the locked .ag set to true when Tk reads x (and w(x) is not locked by Tk), or (2) the version \nnumber of x is larger than the read timestamp of Tk. In case (1) property STLE3 is trivially en\u00ad  sured. \nAssume then case (2). This means that some transaction Tm that has a write timestamp greater than the \nread timestamp of Tk wrote to x either (a) before Tk read x, or (b) after Tk read x and before Tk locked \nw(x). But then Tm must have ac\u00adquired its write timestamp, while holding try-lock Lx, after Tk acquired \nits read timestamp and before Tk locked Lx (if at all). Hence, STLE3 is ensured. We thus obtain the following \ntheorem: THEOREM 5. TL2 (with a one-to-one t-variable to try-lock map\u00adping) is strongly progressive. \nTinySTM. There are two major differences with TL2. First, TinySTM locks a t-variable x already inside \nany write operation on x, i.e., locking is not delayed until the commit time of trans\u00adactions. Second, \nif a transaction Tk reads a t-variable x that has a version number higher than the read timestamp of \nTk, then Tk tries to validate itself to avoid being aborted, instead of aborting itself immediately. \nTinySTM uses CAS for locking, in the same way as TL2. Hence, we can insert the invocations and responses \nof operations on logical try-locks into any implementation history of TinySTM in the same way as for \nTL2. It is worth noting, however, that the over.ow handling mecha\u00adnism, which can be turned on at compile \ntime, breaks strong pro\u00adgressiveness in very long histories. As we discuss in Section 6.3, this mechanism \nis necessary to overcome the complexity lower bound and still guarantee correctness. However, strong \nprogressive\u00adness is still ensured in histories with the number of transactions lower than the maximum \nvalue of the t-variable version number, or between version number over.ows. THEOREM 6. TinySTM (with \nthe over.ow handling mechanism turned off, and with a one-to-one t-variable to try-lock mapping) is strongly \nprogressive. RSTM. This TM is highly con.gurable: currently there are four TM backends to choose from, \nand each has a number of con.gura\u00adtion options. The two backends that are of interest here are LLT and \nRedoLock. LLT is virtually identical to TL2. RedoLock has object\u00adlevel lock granularity. That is, transactions \ncon.ict if they access (in a con.icting way) the same object, not necessarily the same memory location \n(i.e., t-variables in RSTM are objects, not single memory words as in TL2 and TinySTM). However, the \nalgorithm of RedoLock is, depending on the con.guration option, similar to either TL2 or TinySTM. The \nmain difference is in the validation heuristic that decides when a transaction needs to validate its \nread set, but this does not impact strong progressiveness (the heuristic does not by itself abort any \ntransaction it just determines when to validate the read set of a transaction). Like in TL2 and TinySTM, \nRedoLock uses CAS for locking, and so the same technique as for TL2 and TinySTM can be used to prove \nthat RSTM with RedoLock backend is strongly progressive. THEOREM 7. RSTM with the RedoLock backend is \nstrongly pro\u00adgressive. McRT-STM. The algorithm of McRT-STM (as described in (Adl-Tabatabai et al. 2006)) \nis essentially the same as the one of TinySTM, except that McRT-STM does not validate reads until the \ncommit time of a transaction (and so the timestamp-based read validation technique is not necessary). \nMcRT-STM also does not handle timestamp over.ows. Hence, as McRT-STM uses CAS for locking, it is immediate \nthat McRT-STM is strongly progressive. THEOREM 8. McRT-STM is strongly progressive. Visible reads. It \nmay seem that the simplest way of implement\u00ading a strongly progressive TM that uses visible reads is \nto use read-write try-locks. Then, if a transaction Ti wants to read a t\u00advariable x, Ti must .rst acquire \na shared (read) try-lock on x, and if Ti wants to write to x, Ti must acquire an exclusive (write) try\u00adlock \non x. However, this simple algorithm does not ensure strong progressiveness, even if the read-write try-locks \nare (in some sense) strong. Consider transactions Ti and Tk that read a t-variable x. Clearly, both transaction \nacquire a shared lock on x. But then, if both Ti and Tk want to write to x, it may happen that both get \naborted. This is because a transaction Tk cannot acquire an exclu\u00adsive try-lock on x if any other transaction \nholds a shared try-lock on x. A simple way to implement a strongly progressive TM with in\u00advisible reads \nis to use (standard) try-locks. Then, only the writing to a t-variable x requires acquiring a try-lock \non x. A transaction that wants to reads x simply adds itself to the list of readers of x (if the try-lock \nof x is unlocked). This list, however, is not used to imple\u00adment a read-write try-lock semantics, but \nto allow a transaction that writes to x to invalidate and abort all the current readers of x. Such a \nTM can be veri.ed to be strongly progressive using our reduc\u00adtion theorem. A separate reduction theorem, \nbased on read-write try-locks, is thus not necessary, and would probably be incorrect (trying to provide \nsuch a theorem allowed us to discover this ambi\u00adguity). 5. The Power of a Lock-Based TM In this section, \nwe use our semantics to determine the computa\u00adtional power of lock-based TMs. We use the notion of consensus \nnumber (Herlihy 1991) as the metric of power of an object. The consensus number of an object x is de.ned \nas the maximum num\u00adber of processes for which one can implement a wait-free consensus object using any \nnumber of instances of x (i.e., objects of the same type as x) and registers. A consensus object, intuitively, \nallows pro\u00adcesses to agree on a single value chosen from the values those pro\u00adcesses have proposed. More \nformally, a consensus object imple\u00adments a single operation: propose(v). When a process pi invokes propose(v), \nwe say that pi proposes value v. When pi is returned value v ' from propose(v), we say that pi decides \nvalue v '. Every consensus object ensures the following properties in every execu\u00adtion: (1) no two processes \ndecide different values (agreement), and (2) every value decided is a value proposed by some process \n(va\u00adlidity). According to (Herlihy 1991), if an object x has consensus num\u00adber k, then one cannot implement \nx using objects with consensus number lower than k. For example, a queue and test-and-set have consensus \nnumber 2, and so they cannot be implemented from only registers (which have consensus number 1). We prove \nhere that the consensus number of a strongly progres\u00adsive TM is 2. We do so in the following way. First, \nwe prove that a strongly progressive TM is computationally equivalent to a strong try-lock. That is, \none can implement a strongly progressive TM from (a number of) strong try-locks and registers, and vice \nversa. Second, we determine that the consensus number of a strong try\u00adlock is 2. The equivalence to a \nstrong try-lock is interesting in its own right. It might also help proving further impossibility results \nas a strong try-lock is a much simpler object to reason about than a lock\u00adbased TM. 5.1 Equivalence between \nLock-Based TMs and Try-Locks To prove that a strongly progressive TM is (computationally) equiv\u00adalent \nto a strong try-lock, we exhibit two algorithms: Algorithm 1 that implements a strong try-lock from a \nstrongly progressive TM object and a shared memory register, and Algorithm 2 that imple-Algorithm 1: \nAn implementation of a strong try-lock from a strongly progressive TM object (k is a unique transaction \nidenti.er generated for every operation call) uses: M TM object, x1,x2,... binary t-variables, V register \ninitially: x1,x2,... = false, V =1 1 operation trylock 2 v . V.read; 3 locked . M.treadk(xv); 4 if locked \n= Ak or locked = true then return false; 5 s . M.twritek(xv, true); 6 if s = Ak then return false; 7 \ns . M.tryCk; 8 if s = Ak then return false; 9 else return true; 10 operation unlock 11 v . V.read; 12 \nV.write(v + 1); 13 return ok; ments a strongly progressive TM from a number of strong try-locks and registers. \nBoth algorithms are not meant to be ef.cient or prac\u00adtical: their sole purpose is to prove the equivalence \nresult. The intuition behind Algorithm 1 is the following. We use an unbounded number of binary t-variables \nx1,x2,... (each initial\u00adized to false) and a single register V holding an integer (initialized to 1). \nIf the value of V is v, then the next operation (trylock or unlock) will use t-variable xv. If xv equals \ntrue, then the lock is locked. A process pi acquires the lock when pi manages to execute a transaction \nTk that changes the value of xv from false to true. Then, pi releases the lock by incrementing the value \nof register V , so that xv ' = false where v ' is the new value of V . (Note that in\u00adcrementing V in \ntwo steps is safe here, as only one process the one that holds the lock may execute lines 11 12 at a \ntime.) The implemented try-lock is strong because whenever several processes invoke trylock, at least \none of those processes will commit its trans\u00adaction (as the TM is strongly progressive) and acquire the \ntry-lock. Due to space constraints, the following lemma is proved in the extended version of this paper \n(Guerraoui and Kapalka 2008b). LEMMA 9. Algorithm 1 implements a strong try-lock. The intuition behind \nAlgorithm 2 is the following. We use a typical two-phase locking scheme with eager updates, optimistic \n(invisible) reads, and incremental validation (this can be viewed as a simpli.ed version of TinySTM that \nexplicitly uses strong try\u00adlocks). Basically, whenever a transaction Ti invokes operation write on a \nt-variable x for the .rst time, Ti acquires the corresponding try-lock Lx (line 13) and marks x as locked \n(line 21). Then, Ti may update the state of x in TVar[x] any number of times. The original state of x \nis saved by Ti in oldval[x], so that if Ti aborts then all the updates of t-variables done by Ti can \nbe rolled back (line 39). If, at any time, Ti fails to acquire a try-lock, Ti aborts. This ensures freedom \nfrom deadlocks. If Ti invokes operation read on a t-variable y that Ti has not written to before, Ti \nreads the current value of y (line 2) and validates itself (function validate). Validation ensures that \nnone of the t-variables that Ti read so far has changed or has been locked, thus preventing Ti from having \nan inconsistent view of the system. If validation fails, Ti is aborted. Because values written to any \nt-variable are not guaranteed to be unique, and because, in our Algorithm 2: An implementation of a strongly \nprogressive TM from strong try-locks and registers uses: Lx strong try-lock (for each t-variable x), \nTVar array of registers (other variables are local) initially: TVar[x] = (0, 0, false) for each t-variable \nx, rset = wset = \u00d8 1 operation treadk(x) 2 (v, ts, locked) . TVar[x].read; 3 if x . wset then return \nv; 4 if x/. rset then 5 readts[x] . ts; 6 rset . rset .{x}; if (not validate) or locked then abort; return \nAk; return v; 11 operation twritek(x, v) 12 if x /. wset then 13 locked . Lx.trylock; 14 if not locked \nthen 15 abort; 16 return Ak; 17 (v ' , ts, locked) . TVar[x].read; 18 if x /. wset then 19 oldval[x] \n. v ' ; 20 21 wset . wset . {x}; TVar[x].write(v, ts, true); 22 return ok; 23 operation tryCk 24 if \nnot validate then 25 abort; 26 return Ak; 27 for x . wset do 28 (v, ts, locked) . TVar[x].read; 29 TVar[x].write(v, \nts + 1, false); 30 Lx.unlock; 31 wset . rset . \u00d8; 32 return Ck; 33 operation tryAk 34 abort; 35 return \nAk; 36 function abort 37 for x . wset do 38 (v, ts, locked) . TVar[x].read; 39 TVar[x].write(oldval[x], \nts, false); 40 Lx.unlock; 41 wset . rset .\u00d8; 42 function validate 43 for x . rset do 44 (v, ts, locked) \n. TVar[x]; 45 if (locked and x/. wset) or ts = readts[x] then 46 return false; 47 return true; Algorithm \n3: An implementation of wait-free consensus from a strong try-lock in a system of 2 processes (code for \nprocess pi, i =1, 2) uses: L strong try-lock, V1, V2 registers 1 operation propose(v) 2 Vi.write(v); \n3 locked . L.trylock; 4 if locked then return v; 5 else return V(3-i).read; simpli.ed model, a try-lock \ndoes not have an operation that would read its state, we store with the state of each t-variable x a \n(unique) timestamp (version number) of x and a locked .ag that is set to true if x is being written to \nby some transaction. The timestamps and locked .ags are used for validation. To commit a transaction \nTi, the algorithm .rst validates Ti (line 24). Then, for each t-variable x written to by Ti, the timestamp \nof x is incremented by 1, the locked .ag of x is set to false (line 29), and .nally the try-lock Lx of \nx is unlocked (line 30). Aborting Ti requires rolling back all the updates done by Ti (line 39) and unlocking \nall the try-locks acquired by Ti (line 40). LEMMA 10. Algorithm 2 implements a strongly progressive TM. \nDue to space constraints, the proof of Lemma 10 is omitted. It can be found in the extended version of \nthis paper (Guerraoui and Kapalka 2008b). Note that strong progressiveness of Algorithm 2 is trivial \nto verify using our reduction theorem, because every im\u00adplementation history of this algorithm is its \nown try-lock extension (i.e., it ensures properties STLE1 3). From Lemma 9 and Lemma 10, we immediately \nobtain the fol\u00adlowing result (recall that an object x is (computationally) equiva\u00adlent to an object y, \nif y can be implemented from any number of instances of x and registers, and x can be implemented from \nany number of instances of y and registers): THEOREM 11. Every strongly progressive TM is equivalent \nto a strong try-lock. 5.2 Consensus Number of Strong Try-Locks To prove that the consensus number of \na strong try-lock is 2, we show that (1) a strong try-lock can implement consensus in a system of 2 processes, \nand (2) there is no algorithm that implements consensus using (any number of) strong try-locks and registers \nin a system of 3 (or more) processes. Algorithm 3 shows an implementation of consensus for two processes \n(p1 and p2) using a single strong try-lock (L) and two registers (V1 and V2). The process pi that acquires \nL is the winner: the value proposed by pi, and written by pi to register Vi, is decided by both p1 and \np2. Because L is a strong try-lock, if both processes concurrently execute operation propose, at least \none of them acquires L. Because no process ever unlocks L, at most one process acquires L. Hence, exactly \none process is the winner. Due to space constraints, the following lemma is proved in the extended version \nof this paper (Guerraoui and Kapalka 2008b). LEMMA 12. Algorithm 3 implements wait-free consensus in \na sys\u00adtem of 2 processes. To prove that there is no algorithm that implements consensus using strong \ntry-locks and registers in a system of 3 (or more) processes, we show in Algorithm 4 that a strong try-lock \ncan be Algorithm 4: An implementation of a strong try-lock from a test-and-set object uses: S test-and-set \nobject initially: S = false 1 operation trylock 2 locked . S.test-and-set; 3 return \u00ac locked; 4 operation \nunlock 5 S.reset; implemented from a single test-and-set object.6 Because a test\u00adand-set object has consensus \nnumber 2, the algorithm proves that a strong try-lock cannot have consensus number higher than 2. Note \nthat the presented algorithm is a non-blocking version of a simple and well-known TAS lock (Raynal 1986). \nThe following lemma is thus trivial to verify: LEMMA 13. Algorithm 4 implements a strong try-lock. From \nLemma 12 and Lemma 13, we immediately obtain the following result: THEOREM 14. A strong try-lock has \nconsensus number 2. Hence, by Theorem 11 and Theorem 14, the following theorem holds: THEOREM 15. Every \nstrongly progressive TM has consensus num\u00adber 2. COROLLARY 16. There is no algorithm that implements \na strongly progressive TM using only registers. 5.3 Weakening Strong Progressiveness Interestingly, \nnailing down precisely the progress property of a lock-based TM also helps consider alternative semantics \nand their impacts. We discuss here how one has to weaken the progress semantics of a lock-based TM so \nthat it could be implemented with registers only. We de.ne a property called weak progressive\u00adness that \nenables (lightweight) TM implementations with consen\u00adsus number 1. Intuitively, a TM is weakly progressive \nif it can forcefully abort a transaction Ti only if Ti has a con.ict with another transaction. More precisely: \nDEFINITION 17. A TM implementation M is weakly progressive, if in every history H of M the following \nproperty is satis.ed: if a transaction Ti . H is forcefully aborted, then Ti con.icts with some transaction \nin H. We correlate this notion with the concept of a weak try-lock: a try-lock which operation trylock \nexecuted by a process pi may always return false if another process is concurrently executing trylock \non the same try-lock object. That is, pi is guaranteed to acquire a weak try-lock L only if L is not \nlocked and no other process tries to acquire L at the same time. More precisely: DEFINITION 18. We say \nthat a try-lock L is weak if L has the following property: if a process pi invokes trylock on L at some \ntime t, L is not locked at t, and no process other than pi executes operation trylock on L at time t \nor later, then pi is returned true. 6 A test-and-set object has two operations: test-and-set, which atomically \nreads the state of the object, sets the state to true, and returns the state read, and reset, which sets \nthe state to false. Algorithm 5: An implementation of a weak try-lock using registers (code for process \npi) uses: R[1,...,n] array of registers initially: R[k]=0 for k =1,...,n 1 operation trylock 2 s . getsum; \n3 if s> 0 then return false; 4 R[i].write(1); 5 s . getsum; 6 if s =1 then return true; 7 R[i].write(0); \n8 return false; 9 operation unlock 10 R[i].write(0); 11 return ok; 12 function getsum 13 s . 0; 14 for \nk =1 to n do s . s + R[k].read; 15 return s; While we do not know of any existing implementation of a \nweak try-lock, such an implementation can be easily obtained from several well-known (blocking) mutual \nexclusion algorithms, e.g., those proposed in (Lamport 1985) that ensure at least the shutdown safety \nproperty introduced in the same paper. An example implementation of a weak try-lock using only reg\u00adisters, \nsimilar in concept to some of the lock implementations in (Lamport 1985), is given in Algorithm 5. The \nintuition behind the algorithm is the following. If a process pi invokes operation try\u00adlock on a try-lock \nL implemented by the algorithm, pi .rst checks whether any other process holds L (lines 2 3). If not, \npi announces that it wants to acquire L by setting register R[i] to 1 (line 4). Then, pi checks whether \nit is the only process that wants to acquire L (lines 5 6). If yes, then pi acquires L (returns true). \nOtherwise, pi resets R[i] back to 0 (so that future invocations of trylock may suc\u00adceed) and returns \nfalse. Clearly, if two processes execute trylock in parallel, then both can reach line 6. However, then \nat least one of them must observe that more than one register in array L is set to 1, and return false. \nLEMMA 19. Algorithm 5 implements a weak try-lock. Proof. Denote Algorithm 5 by A, and by L a try-lock \nobject implemented by A. First, it is straightforward to see that A is wait\u00adfree: it does not have any \nloops or waiting statements and all base objects used by A are wait-free. Assume, by contradiction, that \nA does not ensure mutual ex\u00adclusion. Hence, there is an implementation history E of A in which some two \nprocesses, say pi and pk, hold L at some time t. Consider only the latest trylock operations of pi and \npk on L before t. Both of those operations must have returned true. Process pi observes that R[k]=0 in \nline 5, and so pi reads R[k] before pk writes 1 to R[k] in line 4. Hence, pk reads R[i] (in line 5) after \npi writes 1 to R[i]. Thus, pk reads that R[i] and R[k] equal 1 and returns false in line 6 a contradiction. \nIt is easy to see that, for any process pi, if R[i]=1 then either pi holds L or pi is executing operation \ntrylock on L. Hence, if a process pi returns false from trylock, then either L is held by an\u00adother process \nor another process is executing trylock concurrently to pi. This means that L is a weak try-lock. D From \nLemma 19, we obtain the following result: THEOREM 20. A weak try-lock has consensus number 1. It is straightforward \nto see that using weak try-locks instead of strong ones in the TM implementation shown in Algorithm 2 \ngives a TM that ensures weak progressiveness. Hence, by Theorem 20, we immediately prove the following \nresult: THEOREM 21. Every weakly progressive TM has consensus num\u00adber 1. 6. Performance Trade-Off We \nprove that the space complexity of every weakly (and, a for\u00adtiori, strongly) progressive TM that uses \ninvisible reads is at least exponential with the number of t-variables available to transactions. The \ninvisible reads strategy is used by a majority of TM implemen\u00adtations (Dice et al. 2006; Marathe et al. \n2006; Harris et al. 2006; Adl-Tabatabai et al. 2006; Felber et al. 2008) as it allows ef.cient optimistic \nreading of t-variables. Intuitively, if invisible reads are used, a transaction that reads a t-variable \ndoes not write any infor\u00admation to base objects. Hence, many processors can concurrently execute transactions \nthat read the same t-variables, without inval\u00adidating each other s caches and causing high traf.c on \nthe inter\u00adprocessor bus. However, transactions that update t-variables do not know whether there are \nany concurrent transactions that read those variables. 6.1 Semantics of Invisible Reads We state our \nlower bound result assuming a simpli.ed de.nition of the notion of invisible reads. This is suf.cient \nfor our lower bound proof, and is in agreement with what is ensured by various TM implementations (Dice \net al. 2006; Marathe et al. 2006; Felber et al. 2008). Intuitively, we say that a TM implementation M \nuses invisible reads, if it does not modify the state of any base object when processing a read operation \non any t-variable. We capture this more precisely using the notion of a con.gura\u00adtion. A con.guration \nis the state of all base objects at a given point in time. Assuming that the initial state of base objects \nis .xed, and that base objects are deterministic, the con.guration after any im\u00adplementation history \nE can be precisely determined. Let E be any implementation history of a TM. We de.ne an operation execution \nof a process pi in E to be any pair of (a) an invocation of operation tread or twrite and (b) the subsequent \nre\u00adsponse of this operation in the sub-history E|pi. If e is an operation execution of some process pi \nin E, then every step in E|pi between the invocation and the response of e is said to be corresponding \nto e. DEFINITION 22. A TM implementation M uses invisible reads if, for every implementation history \nE of M, no step corresponding to an execution of operation tread in E changes the con.guration. 6.2 \nThe Lower Bound The size of a t-variable or a base object x can be de.ned as the number of distinct, \nreachable states of x. In particular, if x isa t\u00advariable or a register object, then the size of x is \nthe number of values that can be written to x. For example, the size of a 32-bit register is 232 . THEOREM \n23. Every weakly progressive TM implementation that uses invisible reads and provides to transactions \nNs t-variables of `\u00b4 size Ks uses O Ks Ns /Kb base objects of size Kb. Due to space constraints, we give \nhere only a sketch of the proof. The full proof can be found in the companion technical report (Guerraoui \nand Kapalka 2008b). Proof. (sketch) Let M be any weakly progressive TM implemen\u00adtation that uses invisible \nreads and provides to transactions Ns t\u00advariables x1,...,xNs of size Ks. Basically, the proof consists \nof constructing a set of implementation histories E1, ..., EL of M, such that the following conditions \nare satis.ed. `\u00b4 1. The number L of those histories is O Ks Ns . 2. Each history Ek is characterized \nby a pair of a base object b and a state w of b, such that (roughly speaking) base object b is never \nin state w within histories Ek+1, ..., EL.  This implies that M must use at least L/Kb base objects \nof size Kb (i.e., L base object-value pairs, each characterizing one imple\u00admentation history Ek). We \nexplain the construction of this set of histories in the following paragraphs. Consider an implementation \nhistory E of M in which process p1 executes a number of transactions, each of which writes to ev\u00adery \nt-variable. In parallel, process p2 tries to execute in E a single transaction T2 that reads every t-variable \n(i.e., takes a snapshot of all Ns t-variable values). Because (a) T2 executes only read oper\u00adations and \n(b) M uses invisible reads, process p2, while executing T2, cannot change the state of any base object \nuntil the commit time of T2. Hence, p1 has no way to determine that p2 is concur\u00adrently executing some \ntransaction in this sense T2 is effectively invisible to p1. Let Q be the set of con.gurations after \nevery transaction of p1. If p2 executes T2 entirely between some two transactions of p1, then p2 observes \nsome con.guration c from set Q. In this case, p2 cannot abort T2, because there is no transaction concurrent \nto T2 (and we assume M to be weakly progressive). Transaction T2 must then return the values (v1,...,vNs \n) written to t-variables by the latest transaction of p1 executed before T2. Conversely, if p2 deter\u00admines \nthat the current con.guration is c, then p2 cannot abort T2 and has to return to T2 values (v1,...,vNs \n). In this sense, the tuple (v1,...,vNs ) of t-variable values corresponds to con.guration c, and vice \nversa. (Note that there may be many con.gurations in set Q that correspond to a given tuple of values, \nbut at most one tuple of values can correspond to a given con.guration.) Process p2, in each step, can \nonly read the state of a single base object. However, between any two steps of p2, process p1 may execute \nany number of transactions and almost entirely change the con.guration. (This is because the system is \nasynchronous and process p1 is not aware of T2 until the commit time of T2.) Hence, if every step of \np2 falls in between two transactions executed by p1, then p2, while executing T2, may observe (almost) \nany combination of con.gurations from set Q. But opacity requires that T2 is returned values from one \nof the tuples written in E by the transactions of process p1. (Note that opacity requires that T2 is \nreturned a consistent snapshot of t-variable values regardless of whether T2 eventually commits or aborts). \nThat is, T2 cannot be returned values from any tuple s that is not written by transactions of p1 in E. \nTherefore, no combination of con.gurations from set Q can correspond to such an illegal tuple s. Let \nS = {s1,s2,...,sL} be the set of all possible tuples of t-variable values (L = Ks Ns ). That is, each \nvalue si in S is a tuple (v1,...,vNs ), where each vk is a value of t-variable xk. Let Si denote the \nsubset {si,...,sL} of S. The crux of the proof is to show that there exist a sequence of sets QL . QL-1 \n. ... . Q1 that have the following properties: 1. Every element of Q1 is a con.guration just after some \ntrans\u00adaction of p1 in some implementation history E of M in which p1 executes a sequence of transactions, \neach writing to all t\u00advariables. 2. Every set Qk contains at least one con.guration that corre\u00adsponds \nto tuple sk of t-variable values.  3. For every con.guration ci in any set Qk, we can .nd a non\u00adempty \nsequence Gi of transactions, each writing to t-variables the values from a tuple in set Sk, such that \nif the system is in con.guration ci and process p1 executes the sequence Gi, then the system is back \nto con.guration ci. That is, we can get from any con.guration in set Qk, which corresponds to a tuple \nfrom set Sk, back to the same con.guration by executing only transactions that write tuples from set \nSk. The main reason why we can prove that such a sequence of sets exists is the fact that the number \nof con.gurations is .nite (if it is in.nite, Theorem 23 trivially holds). This means that if process \np1 executes in.nitely many transactions, each writing values from a tuple in a set Sk, then some con.gurations \n(at least one corre\u00adsponding to each tuple in Sk) must appear in.nitely many times. The properties of \nsets Q1,...,QL imply that, for each set Qk, we can construct an implementation history Ek of M, in which \nprocess p1 executes transactions that write tuples from set Sk and process p2, while executing transaction \nT2 that reads all t-variables, observes an arbitrary combination c of con.gurations from set Qk (at least \nuntil the commit time of T2). Basically, whenever p2 is about to access a base object b, we let p1 execute \na sequence of transactions (each writing a tuple from Sk) that results in a con.guration in which the \nstate of b is the same as the state of b in (virtual) con.guration c. Clearly, a combination c of con.gurations \nfrom set Qk cannot correspond to any tuple from set S -Sk. Otherwise, T2 would read a snapshot of t-variable \nvalues that was never written by any trans\u00adaction of p1 in Ek, which would violate opacity. Therefore, \nwe can show that, for each set Sk, there must be a pair (blk ,wlk ), where blk is a base object and wlk \nits state, such that no con.guration in set Qk+1 has blk in state wlk . Hence, M needs L = Ks Ns such \npairs, i.e., Ks Ns /Kb base objects. D 6.3 Overcoming the Lower Bound Our lower bound relies on three \nproperties of a TM: weak pro\u00adgressiveness, operation wait-freedom, and invisible reads. It could seem \nthat weakening (reasonably) any of those properties would allow overcoming the lower bound. We explain \n(informally) in the following paragraphs why this is not the case, and what has to be done in order for \nthe lower bound not to hold. Consider the following progress property, which is strictly weaker than \nweak progressiveness: if a transaction Ti is force\u00adfully aborted, then there must be a transaction concurrent \nto Ti. We say that a TM that ensures this property is non-trivial indeed, this seems like a basic requirement \nfor a TM. However, non-trivial TMs do not overcome the complexity bound if they ensure oper\u00adation wait-freedom \nand use invisible reads. Basically, in the proof of Theorem 23, transactions executed by processes p1 \nand p2 are not aware of any concurrent transactions, and so they will not be forcefully aborted in a \nnon-trivial TM. Consider the following liveness property, which we call ter\u00admination: if a process pi \ninvokes an operation on a TM object, then pi eventually returns from the operation. Clearly, termination \nis strictly weaker than wait-freedom. Consider a TM that ensures weak progressiveness and termination, \nand that uses invisible reads. Again, the complexity lower bound holds for such a TM: as in the proof \nof Theorem 23 process p1 and p2 is not aware of the opera\u00adtions executed by the other process, no process \ncan block waiting for the other one to execute steps. Hence, in the particular execution used in the \nproof, termination would be suf.cient. Assume now that we allow a TM that uses invisible reads to update \nthe state of a constant number of base objects in the .rst operation of every transaction, even if this \noperation is a read. We say then that such a TM uses weak invisible reads. Hence, each transaction is \nallowed to announce its start. This means that, in the proof of Theorem 23, process p1 can be aware of \ntransaction T2 executed by process p2. However, if the transactions executed by p1 and p2 access not \nall but almost all t-variables (all except for a constant number), then p2 would not be allowed (in general) \nto forcefully abort its transactions, as there would be no guarantee that there is a con.ict between \nthose transactions and transaction T2. This means that to overcome the lower bound we need to weaken \nmore than one property of the TM. For example, TinySTM can be compiled with an option to enable a mechanism \nthat han\u00addles timestamp over.ows. (Without such a mechanism TinySTM can violate opacity in very long \nexecutions, as can TL2 or the LLT backend of RSTM.) Then, TinySTM uses weak invisible reads and may periodically \nviolate both strong progressiveness and operation wait-freedom. Roughly speaking, once a transaction \nover.ows a version number of a t-variable x, all transactions that access x are aborted, and all transactions \nthat start afterwards are blocked on a barrier. Once there is no running transaction, the version num\u00adber \nof x can be reset and transactions can proceed. This means that TinySTM ensures strong progressiveness \nand operation wait\u00adfreedom between timestamp over.ows, but when an over.ow hap\u00adpens the TM becomes only \nnon-trivial and its operation-level live\u00adness is reduced to termination. 7. Concluding Remarks The two \nmajor assumptions we made in this paper were that t\u00advariables support only read and write operations, \nand that the map\u00adping between t-variables and corresponding try-locks is a one-to\u00adone relation. We discuss \nhere how those assumptions can be re\u00adlaxed (at the price of increasing the complexity of the model and \nde.nitions). We also discuss the problem of model checking TMs for strong progressiveness. Arbitrary \nt-variables. Object-based TMs support t-variables of arbitrary type. However, most of them classify all \nthe operations of t-variables as either read-only or update ones. In those cases, there is no need to \nextend our simpli.ed model, because read\u00adonly operations are effectively reads, and update operations \nare effectively pairs of reads and writes. We can, however, imagine a TM that exploits the commutativ\u00adity \nrelations between some operations of t-variables of any type. In this case, one can extend the model \nof a TM to allow for arbi\u00adtrary operations on t-variables, and rede.ne the notion of a con.ict. Indeed, \noperations that commute should not con.ict. Consider for example a counter object and its operation inc \nthat increments the counter and does not return any meaningful value. It is easy to see that there is \nno real con.ict between transactions that concurrently invoke operation inc on the same counter: the \norder of those opera\u00adtions does not matter and is not known to transactions (it would be, however, if \ninc returned the current value of the counter). Once the notion of a con.ict is de.ned, our de.nitions \nof progress properties remain correct even for t-variables with arbi\u00adtrary operations. If we assume that \na TM must support t-variables with operations read and write (in addition to other t-variables), then \nalso the consensus number and complexity lower bound re\u00adsults hold for those TMs. However, the question \nof how to ver\u00adify strong progressiveness of TM implementations with arbitrary t-variables is an open \nproblem. Arbitrary t-variable to try-lock mappings. Many lock-based TMs employ a hash function to map \na t-variable to the corresponding try-lock. It may thus happen that a false con.ict occurs between transactions \nthat access disjoint sets of t-variables, and so, a pri\u00adori, strong progressiveness might be violated. \nHowever, it is easy to take the hash function h of a TM implementation M into account in the de.nition \nof strong progressiveness. Basically, when a transac\u00adtion Ti reads or writes a t-variable x in a history \nH of M, we add to, respectively, the read set (RSetH (Ti)) or the write set (WSetH (Ti)) of Ti not only \nx, but also every t-variable y such that h(x)= h(y). The de.nition of a con.ict hence also takes into \naccount false con\u00ad.icts between transactions, and the strong progressiveness property can be ensured \nby M. (Such a property could be called h-based strong progressiveness.) It is important to note, however, \nthat the hash function must be known to a user of a TM, or even provided by the user. Otherwise, strong \nprogressiveness (and, for that matter, any other property that relies on the notion of a con.ict) would \nno longer be visible, and very meaningful, to a user. Model checking. While our reduction theorem simpli.es \nprov\u00ading strong progressiveness of a TM implementation, it might still be dif.cult to verify this property \nin an automatic manner. Indeed, even when verifying histories from the perspective of individual try-locks, \nwe have to deal with an unbounded number of states. A solution would be to propose a reduction theorem \nalong the lines of (Guerraoui et al. 2008), assuming that a TM implementation has certain symmetry properties. \nTwo problems arise then. First, one has to express those properties in the .ne-grained model we use ((Guerraoui \net al. 2008) assumes operations like validate or com\u00admit to be atomic). Second, one has to prove that \na given TM im\u00adplementation ensures those properties, which is not always trivial (e.g., properties P6 \nand P7 in (Guerraoui et al. 2008)). Both prob\u00adlems remain open. Acknowledgments We would like to thank \nLeaf Petersen, Benjamin Pierce, and the anonymous reviewers for their invaluable help in improving the \ncontents and the presentation of this paper. We would also like to thank Aleksandar Dragojevi\u00b4c, Vincent \nGramoli, Seth Gilbert, and Jan Vitek for their helpful comments and discussions. References Mart\u00b4in Abadi, \nAndrew Birrell, Tim Harris, and Michael Isard. Semantics of transactional memory and automatic mutual \nexclusion. In Proceed\u00adings of the 35th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages \n(POPL), 2008. Ali-Reza Adl-Tabatabai, Brian T. Lewis, Vijay Menon, Brian R. Murphy, Bratin Saha, and \nTatiana Shpeisman. Compiler and runtime support for ef.cient software transactional memory. In Proceedings \nof the ACM SIGPLAN 2006 Conference on Programming Language Design and Implementation (PLDI), 2006. Colin \nBlundell, E Christopher Lewis, and Milo M. K. Martin. Subtleties of transactional memory atomicity semantics. \nIEEE Computer Architecture Letters, 5(2), 2006. Dave Dice, Ori Shalev, and Nir Shavit. Transactional \nlocking II. In Pro\u00adceedings of the 20th International Symposium on Distributed Computing (DISC), 2006. \nRobert Ennals. Software transactional memory should not be obstruction\u00adfree. Technical Report IRC-TR-06-052, \nIntel Research Cambridge Tech Report, Jan 2006. Kapali P. Eswaran, Jim N. Gray, Raymond A. Lorie, and \nIrving L. Traiger. The notions of consistency and predicate locks in a database system. Commun. ACM, \n19(11):624 633, 1976. Pascal Felber, Torvald Riegel, and Christof Fetzer. Dynamic performance tuning \nof word-based software transactional memory. In Proceedings of the 13th ACM SIGPLAN Symposium on Principles \nand Practice of Parallel Programming (PPoPP), Feb 2008. Rachid Guerraoui and Michal Kapalka. On the correctness \nof transactional memory. In Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice \nof Parallel Programming (PPoPP), 2008a. Rachid Guerraoui and Michal Kapalka. The semantics of progress \nin lock\u00adbased transactional memory. Technical Report LPD-REPORT-2008\u00ad015, EPFL, October 2008b. Rachid \nGuerraoui and Michal Kapalka. On obstruction-free transactions. In Proceedings of the 20th ACM Symposium \non Parallelism in Algorithms and Architectures (SPAA). ACM, June 2008c. Rachid Guerraoui, Thomas Henzinger, \nBarbara Jobstmann, and Vasu Singh. Model checking transactional memories. In Proceedings of the ACM SIGPLAN \n2008 Conference on Programming Language Design and Implementation (PLDI), 2008. Vassos Hadzilacos. A \ntheory of reliability in database systems. Journal of the ACM, 35(1):121 145, 1988. Tim Harris, Mark \nPlesko, Avraham Shinnar, and David Tarditi. Optimizing memory transactions. In Proceedings of the ACM \nSIGPLAN 2006 Con\u00adference on Programming Language Design and Implementation (PLDI), 2006. Maurice Herlihy. \nWait-free synchronization. ACM Transactions on Pro\u00adgramming Languages and Systems, 13(1):124 149, January \n1991. Maurice Herlihy and J. Eliot B. Moss. Transactional memory: Architectural support for lock-free \ndata structures. In Proceedings of the 20th Annual International Symposium on Computer Architecture, \npages 289 300, May 1993. Maurice Herlihy and Jeannette M. Wing. Linearizability: a correctness condition \nfor concurrent objects. ACM Transactions on Programming Languages and Systems, 12(3):463 492, June 1990. \nSuresh Jagannathan, Jan Vitek, Adam Welc, and Antony Hosking. A transactional object calculus. Science \nof Computer Programming, 57 (2):164 186, 2005. Prasad Jayanti. Adaptive and ef.cient abortable mutual \nexclusion. In Proceedings of the 22nd Annual ACM Symposium on Principles of Distributed Computing (PODC), \n2003. Leslie Lamport. The mutual exclusion problem part II: Statement and solutions. Journal of the ACM, \n33(2), 1985. Leslie Lamport. On interprocess communication part II: Algorithms. Distributed Computing, \n1(2), 1986. Virendra J. Marathe, Michael F. Spear, Christopher Heriot, Athul Acharya, David Eisenstat, \nWilliam N. Scherer III, and Michael L. Scott. Lowering the overhead of software transactional memory. \nIn 1st ACM SIGPLAN Workshop on Transactional Computing (TRANSACT), Jun 2006. Vijay Menon, Steven Balensiefer, \nTatiana Shpeisman, Ali-Reza Adl-Tabatabai, Richard L. Hudson, Bratin Saha, and Adam Welc. Practical weak-atomicity \nsemantics for java stm. In Proceedings of the 20th An\u00adnual Symposium on Parallelism in Algorithms and \nArchitectures (SPAA), 2008. Katherine F. Moore and Dan Grossman. High-level small-step operational semantics \nfor transactions. In Proceedings of the 35th ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages (POPL), 2008. Christos H. Papadimitriou. The serializability of concurrent database up\u00addates. \nJournal of the ACM, 26(4):631 653, 1979. Michel Raynal. Algorithms for Mutual Exclusion. The MIT Press, \n1986. Michael L. Scott. Sequential speci.cation of transactional memory se\u00admantics. In 1st ACM SIGPLAN \nWorkshop on Transactional Computing (TRANSACT), 2006. Michael L. Scott and William N. Scherer III. Scalable \nqueue-based spin locks with timeout. In Proceedings of the 8th ACM SIGPLAN Sym\u00adposium on Principles and \nPractice of Parallel Programming (PPoPP), 2001. Jan Vitek, Suresh Jagannathan, Adam Welc, and Antony \nHosking. A semantic framework for designer transactions. In Proceedings of the European Symposium on \nProgramming (ESOP), March 2004.    \n\t\t\t", "proc_id": "1480881", "abstract": "<p>Transactional memory (TM) is a promising paradigm for concurrent programming. Whereas the number of TM implementations is growing, however, little research has been conducted to precisely define TM semantics, especially their progress guarantees. This paper is the first to formally define the progress semantics of lockbased TMs, which are considered the most effective in practice.</p> <p>We use our semantics to reduce the problems of reasoning about the correctness and computability power of lock-based TMs to those of simple try-lock objects. More specifically, we prove that checking the progress of any set of transactions accessing an arbitrarily large set of shared variables can be reduced to verifying a simple property of each individual (logical) try-lock used by those transactions. We use this theorem to determine the correctness of state-of-the-art lock-based TMs and highlight various configuration ambiguities. We also prove that lock-based TMs have consensus number 2. This means that, on the one hand, a lock-based TM cannot be implemented using only read-write memory, but, on the other hand, it does not need very powerful instructions such as the commonly used compare-and-swap.</p> <p>We finally use our semantics to formally capture an inherent trade-off in the performance of lock-based TM implementations. Namely, we show that the space complexity of every lock-based software TM implementation that uses invisible reads is at least exponential in the number of objects accessible to transactions.</p>", "authors": [{"name": "Rachid Guerraoui", "author_profile_id": "81100348136", "affiliation": "EPFL, Lausanne, Switzerland", "person_id": "P1301028", "email_address": "", "orcid_id": ""}, {"name": "Michal Kapalka", "author_profile_id": "81100133264", "affiliation": "EPFL, Lausanne, Switzerland", "person_id": "P1301029", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480931", "year": "2009", "article_id": "1480931", "conference": "POPL", "title": "The semantics of progress in lock-based transactional memory", "url": "http://dl.acm.org/citation.cfm?id=1480931"}