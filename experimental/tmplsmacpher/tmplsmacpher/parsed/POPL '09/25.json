{"article_publication_date": "01-21-2009", "fulltext": "\n Compositional Shape Analysis by means of Bi-Abduction Cristiano Calcagno Imperial College, London \nccris@doc.ic.ac.uk Abstract This paper describes a compositional shape analysis, where each procedure \nis analyzed independently of its callers. The analysis uses an abstract domain based on a restricted \nfragment of sepa\u00adration logic, and assigns a collection of Hoare triples to each pro\u00adcedure; the triples \nprovide an over-approximation of data structure usage. Compositionality brings its usual bene.ts increased \npoten\u00adtial to scale, ability to deal with unknown calling contexts, graceful way to deal with imprecision \n to shape analysis, for the .rst time. The analysis rests on a generalized form of abduction (infer\u00adence \nof explanatory hypotheses) which we call bi-abduction. Bi\u00adabduction displays abduction as a kind of inverse \nto the frame prob\u00adlem: it jointly infers anti-frames (missing portions of state) and frames (portions \nof state not touched by an operation), and is the basis of a new interprocedural analysis algorithm. \nWe have im\u00adplemented our analysis algorithm and we report case studies on smaller programs to evaluate \nthe quality of discovered speci.ca\u00adtions, and larger programs (e.g., an entire Linux distribution) to \ntest scalability and graceful imprecision. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: \nSoftware/Program Veri.cation; D.3.4 [Programming Lan\u00adguages]: Processors; F.3.1 [Logics and Meanings \nof Programs]: Specifying and Verifying and Reasoning about Programs General Terms Veri.cation, Reliability, \nLanguages, Theory Keywords Program Analysis, Proof Theory, Abduction 1. Introduction The Case for Compositional \nShape Analysis. A shape analysis attempts to discover invariants that describe the data structures in \na program (e.g., [43, 3, 37, 21, 4]). We are interested in particular in the use of such analyses for \n(lightweight) program veri.cation. A shape analysis can in principle prove that programs do not commit \npointer-safety errors (dereferencing a null or dangling pointer, or leaking memory), without the user \nhaving to write loop invariants or even pre/post speci.cations for procedures; these are inferred during \nanalysis. To do this the analysis typically has to accurately identify (or distinguish) cyclic and acyclic \nlinked structures, nested lists, and so on. Recall that a semantic de.nition of a language is compositional \nif the meaning of a composite expression is de.ned in terms of Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 09, January 18 24, 2009, Savannah, Georgia, \nUSA. Copyright c &#38;#169; 2009 ACM 978-1-60558-379-2/09/01. . . $5.00 Dino Distefano Peter O Hearn \nHongseok Yang Queen Mary, University of London {ddino,ohearn,hyang}@dcs.qmul.ac.uk the meanings of its \nparts. Similarly, a program analysis is compo\u00adsitional if the analysis result of a composite program \n(or program fragment) is computed from the analysis results of its parts. Often, this de.nition is understood \nat the level of granularity of procedures or groups of recursive procedures. This paper is, to our knowledge, \nthe .rst to de.ne and evaluate a compositional shape analysis. Compositionality has well-known potential \nbene.ts, which line up directly with some of the outstanding problems in making shape analysis more practical. \n1. The ability to analyze program parts, without having the con\u00adtext. When an entire program is not available, \nor is very large, the user of a whole-program shape analysis must put in a sig\u00adni.cant amount of work \nbefore the analysis is run at all. This work consists in de.ning a fake main program which allo\u00adcates \ndata structures and calls the incomplete program s proce\u00addures, or it involves de.ning preconditions \nfor the procedures. Both are time consuming and possible sources of error. The very de.nition of compositional \npresupposes that an analysis makes sense for an incomplete program, without hav\u00ading its context (or a \nmain program) available. This is evidently relevant to the potential use of an analysis during program \ndevelopment, rather than only after a complete program has been written. 2. Potential to scale. Shape \nanalyses are notoriously expensive. After years of research and many papers, we have only recently seen \nthe accurate analysis of complete programs in the thou\u00adsands of lines of code (up to 10K LOC) [21, 23, \n30]. (Less ac\u00adcurate analyses, which typically cannot prove pointer safety on such programs, have been \nreported for larger code bases; e.g., [14, 22].) Papers in the .eld usually use test programs number\u00ading \nin only the hundreds or tens of lines of code. With a compositional analysis it becomes relatively easy \nto get meaningful (if partial) results for large code bases. There is a further bene.t that is worth \nmentioning: Paralleliza\u00adtion. If we can analyze groups of procedures independently, it is easy to run \nthe analysis in parallel and exploit the power of the multicore computers that are becoming mainstream. \n[Aside. Compositional analysis, by its nature, easily yields an incremental algorithm. When an analysis \nis .rst run its results can be stored to disk. Then, if a procedure (or recursive pro\u00adcedure group) is \nchanged, only it has to be re-analyzed; the old analysis results for independent procedures remain unchanged.] \n3. Graceful imprecision. There is no single existing shape domain that has been proposed which is appropriate \nto all of the kinds of data structures found in a large program (such as Linux): any known shape domain \nwill deliver uselessly imprecise results at some point, after which (in a whole program analysis) meaning\u00adful \nresults cease to be obtained even for portions of code which could be well treated, were a suitable precondition \nknown. If a compositional analysis is unable to get precise results for one procedure, due to limitations \nof its abstract domain, it can still obtain precise results for other procedures. This discussion motivates \nthe problem of de.ning and evaluating a compositional shape analysis. Compositional Shape Analysis by \nAbductive Inference. Charles Peirce introduced abductive inference inference of explanatory hypotheses \n in the early 1900 s in his writings on the scienti.c process [36]. Abduction was formulated to distinguish \nhypothesis formation from deductive and inductive inference patterns. Abduc\u00adtive inference has been widely \nstudied in philosophy, and it has been used in a number of ways in Arti.cial Intelligence, such as in \ndiagnosis and in planning. (The survey article [24] points to many formalizations and applications in \nthe AI literature.) The main contribution of this paper is conceptual in nature. We explain how abductive \ninference can be used to de.ne a composi\u00adtional, interprocedural shape analysis algorithm. We use abduction \nto generate preconditions, so that we can obtain a true Hoare triple for a procedure without knowing \nits calling context. This allows us to make a compositional, bottom-up program analysis, where callees \nare analyzed before callers. The basic idea is this. During an analysis run we might .nd that we do not \nhave enough information to perform an operation a procedure call, or a dereferencing. We then perform \nabductive inference to infer what is missing. We percolate this information back to the preconditions \nof procedures and, in the end, this allows us to synthesize Hoare triples without examining the calling \ncontext of a procedure. This use of abduction generalizes a method we described in [7] for generating \npreconditions in an intraprocedural (i.e., with\u00adout procedures) analysis. Abduction makes it possible \nto handle procedure calls. It is also more systematic: the method of .nding preconditions is seen as \npart of a more general scheme inference of missing hypotheses rather than an ad hoc method based on \npointer dereferencing faults (as was the case in [7]). A major part of our contribution involves de.ning \nan abductive inference algorithm for use with a shape analysis. We de.ne a new procedure for performing \nabductive inference for (certain) separation logic assertions which, following [5, 11], are used to de.ne \nthe abstract states in our analysis. In fact, to treat procedure calls we must deal with a more general \nproblem, which we call bi\u00adabduction, that infers frames describing extra, unneeded portions of state \nas well as the needed, missing portions (the anti-frames ). We have implemented our analysis algorithm \nand done a num\u00adber of case studies to evaluate it. These range from small programs operating over composite \nlist structures, through to a medium-sized program (a .rewire device driver), and on to larger code bases \n(in\u00adcluding complete distributions of Apache, OpenSSL, Linux). The small and medium-sized examples are \ndone to probe questions con\u00adcerning the quality of speci.cations discovered by our analysis, and the \nlarger ones to test scalability and graceful imprecision. 2. Bi-Abductive Inference for Speci.cation \nSynthesis In this section we explain informally how bi-abduction is used in our analysis. Subsequent \nsections develop the ideas formally. Abductive Inference. In standard logic, abduction can be set up \nas follows. Given: assumption A and goal G. To .nd: missing assumptions M making the entailment A . M \nf G true. Constraints are placed on what counts as a solution: that it be consistent, that it be expressed \nusing a restricted collection of abducible facts, and sometimes that it be minimal in some sense. In \nthis paper we will be solving a similar problem, but for separation logic rather than classical logic. \nSo, we will have to solve problems of the form A * ?? f G where we use the separating conjunction to \npartition the premises instead of, or in addition to, the usual additive conjunction of classical logic. \nGenerating Preconditions by Abduction. Suppose that during a program veri.cation we have an assertion \nA at a call site for a procedure, and the procedure has a precondition G. For example, def Procedure \nprecondition: G = list(x) * list(y), def Assertion at call site: A = x .0 Here the precondition says \nthat x and y point to acyclic linked lists occupying separate memory, while the assertion A says that \nx is a pointer variable containing 0 (so a list of length 1). The dif.culty we face is that the assertion \nA does not imply G; the call site and given precondition do not match up. One thing we can do is to give \nup on our veri.cation, or our program analysis, at this point. But we might also realize if only we had \nthe assertion list(y) as well, separately con\u00ad joined, then we would be able to meet the precondition. \nThe informal inference step expressed here is abductive in nature: it is about inferring a hypothesis. \nFormally, it involves solving a question of the form A * ?? f G. We can see the relevance of this to \ninterprocedural analysis using an example. Suppose we are given a procedure summary (here, a spec using \nHoare triples) of a procedure merge(x,y). The summary might have been computed previously in an analysis, \nor it might have been supplied manually by a user. We have an enclosing procedure p(y) which calls merge \nas follows. 1 lst_nd* p(lst_nd *y) { // Inferred Pre: list(y) 2 lst_nd *x; 3 x=malloc(sizeof(lst_nd)); \nx->tail = 0; 4 merge(x,y); // Obtained Post: list(x) 5 return(x); 6 } // Inferred Post: list(ret) 7 void \nmerge(lst_nd *x,lst_nd *y){//SUMMARY ONLY 9 // Given Pre: list(x) * list(y) 10 } // Given Post: list(x) \n Here is how we can synthesize the pre and post described at lines 1 and 6. We begin by executing p() \nwith starting symbolic heap emp, an assertion describing the empty heap. Just after line 3 we obtain \nthe assertion A = x .0. We call our abductive proof procedure, which tells us that list(y) is missing. \nSo we infer that we should have started execution with list(y) rather than emp, and record list(y) as \na missing precondition. We pretend that the analysis of the call at line 4 was successful, and continue \nthe analysis of p() with the postcondition list(x) of merge(x,y). At the end of procedure p() we obtain \nlist(ret) as the computed post, where ret is the value returned by the procedure. Notice that the speci.cation \nsynthesized for p() is not at all random: the precondition describes the set of states on which the procedure \ncan be safely run, presuming the given spec of merge(). Bi-Abduction. Abduction gives us a way to synthesize \nmissing portions of state. We also have to synthesize additional, leftover portions of state (the frame) \nby solving a more general problem which we term bi-abduction: A * ?anti-frame f G * ?frame. We illustrate \nthe use of bi-abduction with the following varia\u00adtion on the example above, using the same procedure \nsummary as before for merge(). 1 lst_nd* q(lst_nd *y) { // Inferred Pre: list(y) 2 lst_nd *x, *z; 3 x=malloc(sizeof(lst_nd)); \nx->tail=0; 4 z=malloc(sizeof(lst_nd)); z->tail=0; 5 // Abducted: list(y), Framed: z|->0 6 merge(x,y); \n// Obtained Post: list(x)*z|->0 7 merge(x,z); // Obtained Post: list(x) 8 return(x); 9 } // Inferred \nPost: list(ret) This time we infer anti-frame list(y) as before, but using bi\u00adabduction we also infer \nz.0 as the frame axiom that won t be needed by procedure call at line 6. That is, we obtain a solution \nof the bi-abduction question x.0 * z.0 * ?anti-frame f list(x) * list(y) * ?frame where ?anti-frame = \nlist(y), ?frame = z.0. We tack the frame on to the postcondition list(x) obtained from the procedure \nsum\u00admary, continue execution at line 7, and this eventually gives us the indicated pre/post pair at lines \n1 and 9. Again, the inferred pre/post spec talks about only those cells that the procedure accesses. \nSuch small speci.cations are useful to aim for when synthesizing pre-and postconditions, because (1) \nshape domains usually have an enormous number of states that might be used and (2) small speci.cations \ndescribe more general facts about procedures than big speci.cations , so that they lead to a more precise \nanalysis of callers of those procedures. The more general point we wish to make is that bi-abduction \ngives us a way to realize, in a program analysis, a key idea from [34], where speci.cations and proofs \nconcentrate on the cells ac\u00adcessed by a program rather than the entire global state of a system. Synthesis \nof frames allows us to use small speci.cations of heap portions by slotting them into larger states found \nat call sites, where abduction of anti-frames helps us to .nd the small specs.1 3. Symbolic Heaps Storage \nModel. We assume two disjoint sets of variables: a .nite set of program variables Var (ranged over by \nx, y, z, . . .) and a countable set of logical variables LVar (ranged over by a, b, c, . . .). Let Loc \nbe a countably in.nite set of locations, and let Val be a set of values that includes Loc. The storage \nmodel is as follows: def def Heap = Loc -.n Val Stack =(Var . LVar) . Val def State = Stack \u00d7 Heap 1 \nPrevious work has shown the bene.t of inferring frames [41, 17, 30], but not anti-frames, and the resulting \nprocedure summaries therefore describe larger portions of state than necessary. Symbolic Heaps. Symbolic \nheaps are special separation logic formulae [5, 11], interpreted over State, and de.ned as follows: E \n::= x | a | t(E,...,E) Expressions . ::= E=E | E =E | true | . . . Pure formulae B ::= ... Basic spatial \npredicates S ::= B | true | emp | S * S Spatial formulae . ::= . . S Quanti.er-free symb. heaps H ::= \n.aa. . Symbolic heaps Expressions are program or logical variables x, a. Or they are heap\u00adindependent \nterms t(E1,...,En) (e.g., 0). Pure formulae are com\u00adposed by the conjunction of equalities and disequalities \nbetween expressions, and describe properties of variables. The spatial for\u00admulae specify properties of \nthe heap. The predicate emp holds in the empty heap where nothing is allocated. The formula S1 * S2 uses \nthe separating conjunction of separation logic and holds in a heap h which can be split into two disjoint \nparts h1 and h2 such that S1 holds in h1 and S2 in h2. Symbolic heaps H have the form .aa. . . S, where \nonly some (not necessarily all) logical variables in . . S are existentially quanti.ed. The set of all \nsymbolic heaps is denoted by SH. B is a collection of basic spatial predicates. One instantiation is \nB ::= E.E | lseg(E, E) Here, the points-to predicate x.y denotes a heap with a single al\u00adlocated cell \nat address x with content y, and lseg(x, y) denotes a list segment from x to y (not included). For simplicity, \nwe describe our algorithms and results mainly using this instantiation, although they work equally well \nfor other more sophisticated instantiations [4, 9] after slight or no modi.cations; when some modi.cations \nare nec\u00adessary, we will explain what they are. In this paper, we overload the * operator, so that it \nalso works for . and H. For i =1, 2, let .i =.i . Si and Hi = .a i. .i where all bound variables are \ndistinct and they are different from free variables. We de.ne .1 * .2 and H1 * H2 as follows: def def \n.1 *.2 = (.1 ..2).(S1 *S2),H1 *H2 = .a 1aa2. .1 *.2. We overload -* S and . .- similarly: def def .i \n* S=.i . (S * Si),Hi * S= .a i. .i * S, def def . . .i = (. . .i) . Si, . . Hi = .a i. . . .i. 4. Abduction \nfor Separated Heap Abstractions In this section we describe an algorithm for inferring answers to the \nabduction question: Given . and H, .nd a symbolic heap M such that . * M f H. (1) The question, as put, \ncan be answered trivially, by returning a false assertion. In this paper, we propose a criterion for \njudging the quality of solutions of (1). The order M ; M', meaning that M is a better solution than M \n', is de.ned as follows def M ; M' .. (M' f M * true . M f M' * true) . (M' f M * true . M f M' * true \n. M' f M). Ideally, we would .nd solutions that are minimal w.r.t. ; and consistent. As a semantic question \nabout sets of concrete heaps (viewing an assertion as a set) the best solution always exists.2 2 Semantically, \nthe best solution is min({ (s, h) | . *{(s, h)}f H }), where min(M) is the predicate de.ned below: { \n(s, h) . M | for all subheaps h' of h, if {(s, h')}f M, then h' = h }. (. . S) * [M] CH . . S f.aa.. \n' . . . ' . emp f S ' remove (. . S) * [M] CH * (.aa. . ' . S ' ) (E0 =E1 . .) * [M ] C .ab. . ' .-match \n. * E.E0 * [.aa. E0=E1 . M] C .a ab. . ' * E.E1 (where ab n FreeLVar(E1)= \u00d8) . * [M] C .aa. . ' * lseg(E0,E1) \nlseg-right . * B(E, E0) * [M] C .aa. . ' * lseg(E, E1) (where B(E, E0) is E.E0 or lseg(E,E0)) (E=E0 . \n. * lseg(a, E0)) * [M] C .ab. . ' lseg-left . * lseg(E, E0) * [E=E0 . M] C .aab. . ' * E.a base-emp (. \n. emp) * [.aa. . ' . emp] C .aa. . ' . emp base-true . * [.aa. . . emp] C .aa. . . true . * [M] C . \n' . *.aa. B(E, E ' ) f false missing ' . ' . * [M *.aa. B(E, E )] C *.aa. B(E, E ' ) (where B(E, E ' \n) is E.E ' or lseg(E,E ' )) Figure 1. Proof Rules for Abductive Inference While this solution exists \ntheoretically, it is not easy to compute and can lead to additional expense in the analysis (see Example \n3 be\u00adlow). So, we present a more pragmatically-motivated procedure for abductive inference. The order \n; is used to inform design choices in the algorithm, rather than to identify the theoretically best solu\u00adtion. \nThis is just how in abstract interpretation analyses often do not implement the best abstract transformer \nfor pragmatic reasons. Proof System for Abductive Inference. We introduce a proof system for deriving \njudgments of the form . * [M] C H, where M, H are symbolic heaps and . is a quanti.er-free sym\u00adbolic \nheap. This judgment means that M is the missing anti-frame of the abduction question . * ?? f H, and \neach proof rule de\u00adscribes how to search for the solution of this question. The proof rules are presented \nin Figure 1. In the .gure, we assume that all the bound logical variables are different from one another \nand also from free logical variables. EXAMPLE 1. This example shows how our inference .nds a solu\u00adtion \nof the question x.y * [??] Cx.a * lseg(a, 0) * true. Note that in this case, the abduction should infer \nthat y is an instantiation of the logical variable a, in addition to the fact that lseg(a, 0) is the \nmissing predicate in the assumption. The inference algorithm .nds such an instantiation using the .-match \nrule: base-true (y=a . emp) * [emp] (y=a . emp) * [lseg(a, 0)] C C true lseg(a, 0) * true missing .-match \n x.y * [y=a . lseg(a, 0)] Cx.a * lseg(a, 0) * true The last step of the derivation shows that .-match \nis used to .nd the instantiation of a (i.e., y = a), and strengthens the assumption with this instantiation \ny=a. The other two steps move the remain\u00ading lseg(a, 0) predicate in the conclusion to the missing anti-frame \npart. This example shows how our proof method goes beyond previ\u00adous works on theorem proving with separation \nlogic. Indeed, it is possible to obtain a sound theorem prover for abduction by a sim\u00adple modi.cation \nof a usual theorem prover for separation logic [5]. An abduction question . * ?? f H is solved by attempting \nto show the entailment . f H and, when this proof attempt fails with one undischarged assumption emp \nf M, we conclude that the missing heap is M. This prover is not powerful enough to .nd out the instantiation \nof logical variables, as we have done here. For instance, in our example, it would fail to .nd y=a, and \nin\u00adfer x.a * lseg(a, 0) as a missing anti-frame. This means that the symbolic heap x.y *x.a *lseg(a, \n0) is a new enhanced assump\u00adtion by abduction, although it is an inconsistent formula. Certainly, this \nis not a desirable solution. D EXAMPLE 2. Next, we consider a slightly modi.ed version of the motivating \nexample from Section 2: x.z * [??] C lseg(x, z) * lseg(y, 0) * true The derivation below shows how our \ninference algorithm .nds a solution of this abduction question: base-true emp * [emp] C true missing \nemp * [lseg(y, 0)] C lseg(y, 0) * true remove emp * [lseg(y, 0)] C lseg(z, z) * lseg(y, 0) * true lseg-right \nx.z * [lseg(y, 0)] C lseg(x, z) * lseg(y, 0) * true The last step subtracts x.z from lseg(x, z), and \nthe second last step removes the result lseg(z, z) of this subtraction, be\u00adcause emp f lseg(z, z). The \nremaining steps move the predicate lseg(y, 0) from the conclusion to the anti-frame. In this derivation, \nthe application of the remove rule is crucial to obtain a better so\u00adlution. Without using the rule, we \ncould apply missing twice, once for lseg(z, z) and the next for lseg(y, 0), and this would give us x.z \n* [lseg(z, z) * lseg(y, 0)] C lseg(x, z) * lseg(y, 0) * true. Note that the inferred anti-frame is not \nas good as lseg(y, 0), because it has a bigger symbolic heap than lseg(y, 0). D EXAMPLE 3. Consider the \nabduction question: x . 3 * [??] f y . 3 * true Our algorithm .nds as a solution y . 3. It is not the \nbest solution: a better solution is the disjunction y . 3 . (y=x . emp). Although we can see how to compute \na best solution in this case, we do not do so for two pragmatic reasons. First, if we were to aim for \nthe best then we would end up creating large disjunctions that do case analysis on whether two pointers \nare equal or not (it would involve comparing the left sides of . or linked list assertions, pairwise). \nKeeping control of disjunctions is essential for performance [23]. Second, we have found in our experiments \nthat the loss of precision caused by this choice does not hurt us too much. See, in particular, the results \non the .rewire device driver in Section 7. This is a trade-off, which could be revisited. D Reading the \nProof System as an Algorithm. The proof sys\u00adtem for abductive inference, when read in the usual premises\u00adto-conclusion \nway, lets us easily see that the inferences we are making are sound. When read in the opposite direction, \nit can also be thought of as a speci.cation of an algorithm for .nding missing hypotheses M. The algorithm \nis obtained by reading the rules bottom-up, and by viewing the M parts as unknowns. There is also a pragmatically-motivated \norder to the application of the rules, which we describe. This reading of the proof rules leads im\u00admediately \nto a recursive program, which forms the basis of our implementation. The key point is that our proof \nrules have a special form . ' * [M ' ] CH ' Cond . * [M] CH Here Cond is a condition involving parts \nof . and H. The algo\u00adrithmic reading of this rule is the following. In order to answer the entailment \nquestion . * ?? f H, the side condition Cond is .rst checked, and if it holds, we make a recursive call \nto answer the smaller question . ' * ?? f H '. The solution M ' of this simpler question is then used \nto compute the solution M of the original question. For instance, the rule .-match .res when both the \nleft\u00adhand side and right-hand side have a points-to-fact involving E: . * E.E0 * ?? f.a ab. . ' * E.E1 \nThe inference engine then cancels out those facts, and continues the search for the solution with the \nreduced right-hand side .ab. . ' and the reduced left-hand side . after adding the equality E0 =E1 concerning \nthe contents of cell E. Later, when this new simpli.ed search gives a result M, we conjoin the assumed \nequality to the computed missing anti-frame M and existentially quantify logical variables a , which \ngives the result of the original search. Our abduction algorithm tries to apply the rules in Figure 1 \nin the order in which they appear in the .gure. It .rst attempts to use remove and eliminates a part \nof the symbolic heap on the right\u00adhand side of C that holds for the empty heap. Once this phase is complete, \nthe inference goes through each predicate on the right\u00adhand side and tries to simplify the predicate \nusing .-match, lseg\u00adright and lseg-left. When this simpli.cation process gets stuck, the algorithm applies \nmissing, base-emp and base-true, and moves the remaining predicates from the right-hand side to the missing \nanti\u00adframe part. By arranging the order of rule applications in this way, our in\u00adference tries to minimize \nthe size of the spatial part of the inferred missing anti-frame M. This is considered desirable according \nto the de.nition of ;. By trying the remove rule before missing, the inference prefers choosing the empty \nheap to moving a pred\u00adicate from the conclusion to the anti-frame part. For instance, given emp * [??] \nf lseg(x, x), the remove rule infers emp as the miss\u00ading anti-frame whereas the missing rule returns \nlseg(x, x). The in\u00adference algorithm returns emp between the two, because it tries remove before missing. \nAlso, the application of the simpli.cation rules (i.e., .-match, lseg-right and lseg-left) before the \nmissing rule ensures that the common parts between the assumption and the conclusion are cancelled out \nas much as possible, before trying to move predicates from the conclusion to the anti-frame part. A Framework \nof Abductive Inference for Inductive Predicates. For concreteness, in the description of the abductive \ninference system, we used a speci.c inductive predicate for list segments. We now describe a generalization \nthat deals with different classes of inductive de.nitions, such as those for doubly-liked lists, nested \nlists, trees and skip lists [40, 4, 9] which have been used for different abstract domains. For our generalization \nwe keep all the components of the abduction inference in the previous section, except for the four proof \nrules in Figure 1: .-match, lseg-left, lseg-right and missing. Suppose that we have an abstract domain \nwhose basic spatial predicates are ranged over by B(E, Ea). Recall that the abstract domain used throughout \nthe paper corresponds to a speci.c instan\u00adtiation: ' '' B(E, E ) ::= E.E | lseg(E,E ). The missing rule \nis generalized in the following way: . * [M] CH . *.aa. B(E, Ea) f false missing-gen . * [M *.aa. B(E, \nEa)] CH *.aa. B(E, Ea) Note that this rule is almost the same as missing, except for the changes required \nto re.ect the different sets of basic predicates. To generalize the other rules, we need to make an assumption \nabout the abstract domain: we assume that we are given a set of axioms involving basic special predicates, \nall of which have the form (.ay,ay) * S(az)) (x, aor B ' y. .(x,az) . B(x,ay,af z), .(x, az) . B(x, af \ny. B ' (x, ay) * S(az)). z)(.ay,a For example, the abstract domain of this paper has the axioms below: \n(.y. y = z . x.y * emp) f (x.z), (.y. lseg(x, y) * lseg(y, z)) f lseg(x, z), (2) x = z . lseg(x, z) f.y.(x.y) \n* lseg(y, z). Each of these axioms generates proof rules that replace .\u00admatch, lseg-left and lseg-right. \nFor each axiom of the .rst form (.ay,ay) * S(az)) B ' (x, az), y. .(x,az) . B(x,ay,af we de.ne the following \nrule for abduction: (.(E, aEC b. . ' * S( aE') E, a') . .) * [M ] .aE, a . * B(E, Ea) * [.aE, Ea' ) . \nM ] C .a ab. . ' * B ' (E, a' ) a. .(E, aE For each axiom of the second form .(x, az) . B(x, af y. B \n' (x, ay) * S(az)), z)(.ay,a we include the following proof rule for abduction: (.(E, Ea') . . * S(aa, \nEa')) * [M] C .ab. . ' (. * B(E, Ea')) * [.(E, Ea') . M] C .a ab. . ' * B ' (E,a ) The rules .-match, \nlseg-left and lseg-right presented earlier can be generated by following this recipe using the three \naxioms in (2). THEOREM 4. If all the assumed axioms are sound, the proof system for abduction is sound. \nThat is, if . * [M] CH is derivable, then . * M semantically implies H. 5. Bi-Abduction We now turn to \nthe more general bi-abduction question . * ?anti-frame f H * ?frame for quanti.er-free symbolic heaps \n. and normal symbolic heaps H.3 It would be possible to consider a mixed proof system for this problem, \nbut it turns out that there is a way to answer the question by appealing to separate frame inference \nand abduction procedures. Several frame inference procedures have been described in pre\u00advious papers \n[5, 32, 12]. Here we assume a given procedure Frame, which returns either a symbolic heap or an exception \nfail. Frame must satisfy Frame(H0,H1)= L(= fail)=. H0 f H1 * L indicating that if frame inference succeeds \nin .nding a leftover heap L then the indicated entailment holds. In Algorithm 1 we de.ne a further procedure \nAbduce, satisfying the speci.cation Abduce(.,H)= M(= fail)=. . * M f H meaning that it soundly .nds missing \nheap portions. The second step of Algorithm 1 relies on an ordinary theorem prover for sym\u00adbolic heaps. \n3 We consider bi-abduction between . and H here, instead of normal symbolic heaps, because it is the \nquestion asked by our analysis. However, it is not technically dif.cult to extend our algorithm to bi-abduction \nfor normal symbolic heaps. Algorithm 1 Finding a Missing Heap Portion def Abduce(.,H) = 1. Find a symbolic \nheap M such that . * [M] c H using the abduction algorithm from Section 4. If no such heap can be found, \nreturn fail. 2. If . * M is (provably) inconsistent, return fail. Otherwise, return M.  Algorithm 2 \nSynthesizing Missing and Leftover Heaps, Jointly def BiAbd(.,H)= M := Abduce(.,H * true); L := Frame(. \n* M, H); return(M, L) We can combine these two procedures to obtain the algorithm BiAbd described in \nAlgorithm 2. The use of -* true in the abduction question of the algorithm lets us ignore the leftover \nframe when computing the missing heap. By convention, the algorithm raises exception fail if either of \nits internal procedure calls does. THEOREM 5. BiAbd(.,H)=(M, F )=. . * M f H * F. Comparing Solutions. \nThe soundness property in Theorem 5 can be satis.ed trivially. We now de.ne an order . on potential solutions \nwhich was used to design our algorithm. def M ; M ' .. (M ' fM * true . M f M ' * true) . (M ' fM * true \n. M f M ' * true . M ' f M) def ' '' M M .. M ; M . M . M def ' '' (M, L) . (M ,L ' ) .. (M ; M ) . \n(M M . L f L ' ). The de.nition of . is a lexicographic ordering of the order M ; M ' de.ned for abduction, \nand ordinary implication for leftover heaps. The bias on the anti-frame part is due to our application: \nthe BiAbd algorithm is mainly used to infer preconditions of pro\u00adcedures. The missing anti-frame part \nis used to update the precon\u00addition being discovered by the analysis. The second disjunct means that \nif two solutions have the equally good missing anti-frames, the better one should have a logically stronger \nleftover frame. Our BiAbd algorithm .rst attempts to .nd a good missing anti\u00adframe M, and then tries \nto .nd a good frame L. This order of searching for a solution re.ects our emphasis on the quality of \nthe missing anti-frame part, as in the de.nition of .. EXAMPLE 6. We illustrate the intuition behind \n. using x.0 * M f lseg(x, 0) * lseg(y, 0) * L Consider the following three solutions of the question: \ndef def M = lseg(y, 0) L = emp ' L ' def def M = lseg(y, 0) * z.0= z.0 '' L '' def def M = lseg(y, 0) \n= true According to the order we have just de.ned, the best solution among the above three is (M, L), \nand it is what the algorithm BiAbd returns. It is better than (M ' ,L ' ), because its missing anti\u00adframe \nM is strictly better than M ' (i.e., M ; M ' and M M ') since it describes smaller heaps than M '. The \nsolution (M, L) is also better than (M '' ,L '' ) but for a different reason. In this case, the missing \nanti-frames M, M '' have the same quality according to our de.nition (i.e., M M ''). However, this time \nthe deciding factor is the comparison of the leftover frames of the solutions; L is stronger than L '' \n, so (M, L) . (M '' ,L '' ). D 6. Compositional Interprocedural Shape Analysis We illustrate our interprocedural \nshape analysis using a simple while language extended with procedure calls and parametrized by a collection \nof basic operations. Later we will instantiate the basic operations to be certain heap-manipulating commands. \ne ::= x | t(e1,...,en) Prog. Expressions b ::= \u00b7\u00b7\u00b7 Booleans A ::= \u00b7\u00b7\u00b7 Atomic Commands c ::= A | x:=f(ae) \n| c1; c2 | if bc1 c2 Commands | while bc p ::= \u00b7| f(ax){local ya; c; return e}; p Programs A program \np consists of a number of procedure de.nitions. For simplicity, we only consider procedures that return \na single value, and that do not access any global variables. The aim of our compositional shape analysis \nis to construct a spec table T (f) (or procedure summary [44]) for every procedure f in Proc. Spec tables \nare partial functions from symbolic heaps to sets of symbolic heaps: def T (f): Spec, where Spec = SH \n-P(SH). The domain of T (f) speci.es the preconditions we consider for procedure f. For each P in the \ndomain, the intended reading of T (f)(P )= {Q1,...,Qk} is that {P }f(ax){Q1 .\u00b7\u00b7\u00b7. Qk} is a true Hoare \ntriple. We will often write {P }f(ax){Q} . T to mean that T (f )(P )= Q, and we de.ne the set of spec \ntables as def AllSpecs = Proc . Spec. The analysis uses an abstract semantics [ c] IP : AllSpecs .P((SH\u00d7SH).{T}) \n.P((SH\u00d7SH).{T}) of commands that works on pairs (F, H) of the precondition part F and the current heap \nH. The transfer function for an individual statement can alter the H component, and add to the F component, \ngiving (F *M, H ' ), meaning that the statement can reach H ' if the missing part M is added to the start \nstate. We presume that we are given transfer functions [ A] IP for the atomic commands. Later, we will \nspell out one such collection. The pivotal part of our development is the semantics [ x := f(ae)]]IP \nof procedure call, which we describe .rst. 6.1 Abstract Semantics of Procedure Call Besides frames and \nanti-frames, our semantics must take into ac\u00adcount that, as in standard Hoare logic, all the logical \nvariables (el\u00adements of LVar) in a Hoare triple are implicitly universally quanti\u00ad.ed. For example, in \n{x.a ' * y.b ' }swap(x, y){ret=0 . x.b ' * y.a ' }. a ' and b ' are logical variables, and the spec means \nthat swap exchanges the contents of cells x and y. We will be using abduction to instantiate logical \nvariables, as well as to .nd missing heap portions. To see how this works, for the abduction question \nx . e * [??] f x . a our algorithm .nds e=a . emp as the solution, where e=a is the part telling us how \nto instantiate the logical variable. R := \u00d8; Let .aa..H be H; for all {P }f(ax){Q} . T ' (f) do P ' := \nP [ae/ax]; Q ' := Q[ae/ax]; if BiAbd(.H ,P ' )=(M, L)= fail, and Rename(.H , M, P ' , Q ' )=(ea' ,ab, \nM0)= fail then ' R := R.{(F * M0, .aa. (Q * L)[yea/retab]) | Q .Q ' } end if end for; return R IP Figure \n2. Abstract Semantics of [ y:=f (ae)]]T , (F, H) Let ab be FreeLVar(P, Q); Pick ea' disjoint from ab \nsuch that .H * M f e ' =b, aa but if cannot pick such ea' , return fail; Pick M0 disjoint from ab, a \nand program variables such that .H * M0 f .H * M[ea' /ab], but if cannot pick such M0, return fail; return \n(ea' ,ab, M0) Figure 3. Subroutine Rename(.H , M, P, Q) Figure 2 shows the details of the abstract semantics \nof the procedure call y:=f(ae). The abstract execution IP [ y:=f(ae)]]T , (F, H) goes through every spec \n{P }f(ax){Q} of f in T ' (f), and calls the BiAbd algorithm to check whether this spec can be used to \nupdate (F, H) appropriately. If BiAbd returns fail, the analysis ignores this spec, and moves on to the \nnext. Otherwise, it massages the anti-frame and .nds instantiations of parameters by a call to the Rename \nsubroutine from Figure 3. Rename performs essential but intricate trickery with variables, as is usual \nin Hoare logic treatments of procedures. Generally, the anti-frame M0 that it .nds will be expressed \nin terms of logical variables that are fresh or free in H. This is to ensure that it is independent of \nprogram variables that might be modi.ed between the start of a procedure and the point of discovery of \nM0, allowing it to be used later as a precondition. The vectors ea' and ab tell us how to instantiate \nlogical variables in the speci.cation, as discussed in the swap example at the beginning of this subsection. \nAlthough technical in nature, properly dealing with the issues tackled by Rename is essential for the \nprecision of speci.cation discovery. Many procedures will have logical variables in their speci.cations, \nand imprecise treatment of them would lead to an unacceptably imprecise analysis. EXAMPLE 7. We give \na full description of the abstract semantics [ v := swap(x, y)]]IP T , (F, H) def def F =(x=a . y=b . \na.c),H =(y=b . x.y * z.0) using the speci.cation given earlier in this section. The semantics .rst invokes \nBiAbd( y=b . x.y * z.0,x.a ' * y.b ' ) and infers M and L: def '' def M =(a =y . b =d . y.d),L = z.0. \nFrom this output, the analysis computes the three missing elements for analyzing the call v:=swap(x, \ny), which are a leftover frame z.0, a missing anti-frame y.d, and the instantiation a ' =y . b ' =d of \nlogical variables a ' ,b ' in the spec of swap. Rename then def a computes (ea' ,b',M0), where M0 =(b.d) \nis expressed in terms def def a' b ' of existing logical variable b and fresh d, e =(y, d) and a= (a \n' ,b ' ). These elements form the result of analyzing the call. The current precondition F is updated \nby *-conjoining the missing anti\u00adframe b.d: F * b.d .. x=a . y=b . a.c * b.d. The current heap H is mutated \naccording to the instantiated spec of swap with a ' =y . b ' =d and the leftover frame z.0, and becomes \nv=0 . x.d * y.y * z.0. Thus, the result of [ v := swap(x, y)]]IP T , (F, H) is the singleton set { (x=a \n. y=b . a.c * b.d, v=0 . x.d * y.y * z.0) }.D Our algorithm is different in an important respect compared \nto typical forwards interprocedural analysis algorithms. Usually, if a call is found to match with one \nof the speci.cations in a procedure summary, that speci.cation is used and others are ignored. The rea\u00adson \nis that, unless the abstract domain supports conjunction (meet), using more than one spec can only lead \nto decreased precision and ef.ciency. In our case, although our analysis is forwards-running, its primary \npurpose is to help generate preconditions (through ab\u00adduction): for this purpose, it makes sense to try \nas many of the speci.cations in a procedure summary as possible. EXAMPLE 8. To illustrate the use of \nmultiple specs consider the following example program: 1 void safe_reset_wrapper(int *y) { 2 // Inferred \nPre1: y=0 &#38;&#38; emp 3 // Inferred Pre2: y!=0 &#38;&#38; y|->\u00ad4 safe_reset(y); 5 } // Inferred Post1: \ny=0 &#38;&#38; emp 6 // Inferred Post2: y!=0 &#38;&#38; y|->0 7 void safe_reset(int *y) {// SUMMARY ONLY \n8 // Given Pre1: y=0 &#38;&#38; emp 9 // Given Pre2: y!=0 &#38;&#38; y|->\u00ad10 } // Given Post1: y=0 &#38;&#38; \nemp 11 // Given Post2: y!=0 &#38;&#38; y|->0 The analysis of safe reset wrapper starts with emp, meaning \nthat the heap is empty. When it hits the call to safe reset, the analysis calls the abduction algorithm, \nand checks whether emp is abducible to the preconditions of the two specs. It .nds that emp is abducible \nwith the precondition y=0.emp of the .rst spec. Instead of ignoring the remaining specs (like a standard \nforward analysis would), our analysis considers the abducibility of emp with the precondition y.-of the \nother spec. Since the analysis considers both specs, it eventually infers two preconditions: y=0 . emp, \nand y=0 . y.-. If the analysis had searched for only one applicable spec, it would not have been able \nto .nd the second precondition.D  6.2 Top-level Algorithm We write Proc for the set of procedure names \nde.ned in a program, and assume that Proc is partitioned into Proc0,..., Procn that satisfy the following \ncalling relationship: if f is in Proci and f calls g, procedure g belongs to Procj for some j = i. The \nanalysis starts by building spec tables T0 for procedures in Proc0. It infers preconditions for the procedures \nin Proc0 using an interprocedural precondition discovery, and then computes post\u00adconditions for the inferred \npreconditions by the forward interpro\u00adcedural shape analysis. Next, using the constructed T0, the analysis \nconsiders procedures in the next level Proc1, and builds tables T1 for them, again by the interprocedural \nprecondition discovery and the forward interprocedural shape analysis. This process is repeated for Proc2,..., \nProcn, and gives spec tables for all the procedures. The top-level analysis algorithm is given in Algorithm \n3, which follows the informal description in the previous paragraph. Note Algorithm 3 Top-level Analysis \nAlgorithm. def def AllSpecs = Proc . Spec AllPres = Proc .P(SH) local T :AllSpecs, P:AllPres, k:Nats; \nT := .f..P.unde.ned; P := .f.\u00d8; k := 0; while k = n do P := InferPre(Prock, T ); T := InferSpec(Prock, \nP, T ); k := k+1 end while; return T that the algorithm calls two subroutines: def def AllSpecs = Proc \n. Spec AllPres = Proc .P(SH) InferPre : P(Proc) \u00d7 AllSpecs . AllPres InferSpec : P(Proc) \u00d7 AllPres \u00d7 \nAllSpecs . AllSpecs The .rst subroutine InferPre(Prock, T ) is an interprocedural pre\u00adcondition discovery \nphase. Using the given spec tables T of called procedures, it discovers candidate preconditions for procedures \nin Prock. The second InferSpec(Prock, P, T ) is our interprocedural forward shape analysis, and it constructs \nspecs for procedures in Prock with respect to preconditions in P and adds them to T . The subroutine \nInferPre(Prock, Tin) discovers candidate pre\u00adconditions for every f in Prock, while using spec tables \nTin to handle procedure calls in the body of f. Concretely, this discov\u00adery is done by a .xpoint computation, \nwhich constructs (possibly unsound) spec tables T for procedures in Prock. T includes all the spec tables \nin Tin, but those tables of T do not change during the .xpoint computation. For each procedure f in Prock, \nthe subrou\u00adtine abstractly runs the body of f with respect to the initial (F, H), and uses the result \nof this abstract run to update the spec table T (f) for f. This updating is repeated until T does not \nchange, in which case the preconditions in T (f) are returned. The overall structure of the subroutine \nis described in Algorithm 4, where the abstract run of commands is speci.ed using the abstract semantics \n[ -] IP . Note that the algorithm uses two sets of logical variables for each procedure f: a for caching \nthe initial values of parameters ax, and a b for existentially quantifying the parameters and local \nvariables in the computed postconditions H for f. We remark that our implementation also uses optimizations \nfrom the RHS interprocedural analysis algorithm [39], which avoid a certain amount of re-computation. \nWe have, for simplicity, de\u00adscribed a less ef.cient algorithm in the paper.  6.3 InferSpec Phase After \nhaving run our interprocedural precondition-discovery algo\u00adrithm we go through one more phase to .nd \nthe .nal speci.cations for the procedures. This is a form of re-execution, which calculates postconditions \nfrom the given candidate preconditions, and also .l\u00adters out unsafe preconditions. As in [7], .ltering \nis needed because we are using abstraction to simplify preconditions, which is a po\u00adtentially unsound \nstep were we not to re-execute. The re-execution InferSpec takes three parameters. The .rst pa\u00adrameter \nProck is the set of procedure names whose summaries should be calculated; the second parameter Pin is \na map from the procedure names in Prock to their candidate preconditions to be .ltered; the .nal parameter \nTin is the initial spec table, which con\u00adtains the procedure summaries already computed (i.e., the sum\u00admaries \nof procedures in Procj with j<k). Given these param\u00adeters, InferSpec constructs an updated spec table \nT for Prock by a .xpoint computation. (Technically, T also contains summaries of procedures in Procj \nwith j<k, but this part of T does Algorithm 4 InferPre(Prock, Tin). local T : AllSpecs, R. SH\u00d7SH . {T}; \nT := Tin; R := \u00d8; repeat for all f . Prock do Let f(ax){local ay; c; return e} be the de.nition of f; \nPick fresh a with |a |=|ax|; R := [ c; ret:=e] IP({(ax=a . emp, ax=a . emp)}); T if T.R then Reports \nthe possibility of local memory errors at f end if; for all (F, H) .R do if (T (f)(F ) is unde.ned) then \nT (f)(F ) := {.ab.H[ab/axay] | fresh ab s.t |ab|=|axay|}; else T (f)(F ) := T (f )(F ) . {.ab.H[ab/axay] \n| fresh ab s.t |ab|=|axay|}; end if end for end for until T does not change; return .f. if (f . Prock) \nthen dom(T (f)) else \u00d8 Algorithm 5 InferSpec(Prock, Pin, Tin). local T : AllSpecs, Q: P(SH . {T}); T \n:= .f..P. if (f . Prock . P .Pin(f )) then \u00d8 else Tin(f)(P ); repeat for all f . Prock and P .Pin(f) \ndo Let f(ax){local ay; c; return e} be the de.nition of f; Pick fresh a with |a |=|axay|; Q := [ c; ret:=e] \nI ({P }); T if ((T.Q) . (T (f)(P ) is unde.ned)) then T (f)(P ) := unde.ned else T (f)(P ) := T (f \n)(P ) . {.aa.H[aa/axay] | H . Q} end if end for until T does not change; return T not change during the \n.xpoint computation.) The algorithm goes through every procedure f . Prock and every candidate precondi\u00adtion \nP .Pin(f), and calls a forward intraprocedural analysis [ -] I : AllSpecs .P(SH . {T}) .P(SH . {T}) for \nthe body of f. Then, the forward analysis gives the postcondi\u00adtion Q with {P }f(ax){Q}, which is used \nto update T . The .xpoint computation continues until T does not change. Algorithm 5 gives the details \nof InferSpec. As in the previous section, the most interesting case of our ab\u00adstract forward semantics \nis the procedure call. (The other cases are identical to those of the standard intraprocedural analysis.) \nSuppose that the forward analysis is analyzing procedure call y:=f(e) for a symbolic heap H under spec \ntable T '. For simplicity, we assume that neither H nor any preconditions of f in T ' (f) have existential \nquanti.cations. The abstract run of y:=f(e) searches for a collec\u00adtion of specs of f stored in T ' (f) \nthat can be used to transform the current symbolic heap H. That is, for each spec {P }f(x){Q} in T ' \n(f), it tries to match the precondition P with the assertion H at the call site. There is an important \nprecision consideration in the semantics of procedure call. In experiments we have often found an asser\u00adtion \nH that by itself does not imply any of the preconditions in the summary, even after frame inference, \nbut where H implies the dis\u00adjunction of several preconditions. This happens when H describes at once \nseveral possible situations which have been analyzed sepa\u00adrately during the construction of the spec \ntable. Our implementation uses abduction to determine the conditions under which each pre\u00adcondition is \nimplied. Technically, for each precondition Pi, we try to .nd a pure formula .i so that the entailment \n.i . H f Pi * true holds. Finally, when all the specs have been examined, the analyzer selects a minimal \ncollection of the recorded pairs (.1, Q1),..., (.n, Qn) such that the .j together cover every possible \ncase, which is to say that .1 . ... . .n is a tautology. The analysis result is the disjunction of the \nQi s. (The soundness of this case splitting can be justi.ed by the disjunction rule in Hoare logic.) \nWe make two further remarks on this semantics of function calls. First, when the abstract semantics .nds \nsuf.ciently many specs of f that are applicable (i.e., the disjunction of their precon\u00additions is implied \nby the current symbolic heap), it ignores other IP specs of f. This contrasts with [ y:=f(e)]]T , , which \nconsiders all specs of f. Second, if the analysis does not .nd any applicable spec, it does not attempt \nto add a new spec to f, unlike common global interprocedural analyses. This phase also needs a semantics \n[ A] I for the (so far unspeci\u00ad.ed) atomic commands. The basic fact is the following THEOREM 9. If the \nsemantics [ A] I of each atomic command is sound, then InferSpec returns true Hoare triples only. We \ncould state the result more formally, by identifying a concrete semantics, a concretization function, \nand so on. But, there is no deep reason for why this result holds. It is just that, if we are given sound \n[ A] I (wrt a given concrete semantics) then our treatment of procedures with [ -] I is sound as well, \nand this semantics is then used by InferSpec to weed out any preconditions from the previous phase that \ndo not guarantee safe execution.  6.4 Underlying Shape Analysis We now describe the missing de.nitions \nof the abstract semantics, which have been postponed in previous sections. Our description assumes one \nparticular instantiation of our programming language: b ::= e=e | e=e Booleans A ::= a[e] | a Atomic \nCommands a[e] ::= [e]:=e ' | free(e) | x:=[e] a ::= x:=e | x:=new(e) In this instantiation, we have two \nclasses of atomic commands. a[e] attempts to dereference cell e, updating it ([e1]:=e2), disposing it \n(free(e)), or reading its content (x:=[e]). The other atomic commands, denoted a, do not access existing \ncells. The forward abstract semantics [ -] I of commands is de.ned in three steps (as suggested in [43]), \nand implemented by functions: rearr(e): SH .P(SH . {T}), exec(A): SH .P(SH . {T}), abs : SH . SH. The \n.rst step is rearrangement,4 and it is implemented by the func\u00adtion rearr(e), which takes an abstract \nstate and attempts to concre\u00adtise the cell e that is accessed by the command in execution. If e is already \nexplicit then this step is simply the identity function. The 4 Rearrangement is the typical term used \nin separation logic based analyses. In [43], this step is called materialization of summary nodes. def \nRearr(e)(F, H)= let H = rearr(e)(H) and F = {(F, H ' ) | H ' .Hn SH}in if (T .H) then F elseif (H f e=a \nfor some a.LVar) and \u00ac(F *a.b f false for fresh b.LVar) then F.{(F * a.b, H * e.b)}else F . {T} def Exec(A)(F, \nH)= let H = exec(A)(H) in {(F, H ' ) | H ' . H}.{T | T . H} def Abs(F, H)=(abs(F ), abs(H)) Figure 4. \nRearrangement, Execution, Abstraction for [ A] IP . second step is execution, and it is de.ned by the \nfunction exec(A). This function symbolically executes the atomic command A in the rearranged heap. Finally, \nthe third step is abstraction (or canonical\u00adization), implemented by abs, which simpli.es symbolic heaps \nand allows the convergence of the .xpoint computation. For a function t : D .P(D . {T}), let t be a function \non P(D . {T}) de.ned by [ def t (X)= {T | T . X}. ({t(x) | x . (X n D)}). The forward abstract transfer \nfunctions of atomic commands are:5 def [ a[e]]]I (X)=(abs . exec(a[e]) . rearr(e) )(X) T def [ a] T I \n(X)=(abs . exec(a) )(X). The reader is referred to [11] for a detailed treatment of transfer functions \nde.ned in terms of rearr, exec and abs. The abstract semantics of the compound commands is standard: \ndef [ c1; c2] I (X) = ([[c2] I . [ c1] I )(X) T TT def [ if bc1 c2] I (X) = ([[c1] I . .lt(b))(X) U ([[c2] \nI . .lt(\u00acb))(X) TT T def [ while bc] I T (X)= .lt(\u00acb)(l.x .X ' .X U ([[c] I T . .lt(b))(X ' )) where \n.lt(b) is used to .lter out states that do not satisfy the boolean condition b. The semantics of function \ncalls is already given in Section 6.3. The abstract semantics [ -] IP used by the precondition discov\u00adery \nfollows the same pattern as the forward one [ -] I. The only difference is that it uses new versions \nof rearrangement, execution, abstraction functions that work on P((SH \u00d7 SH) . {T}): Rearr(e): SH \u00d7 SH \n.P((SH \u00d7 SH) . {T}), Exec(A): SH \u00d7 SH .P((SH \u00d7 SH) . {T}), Abs : SH \u00d7 SH . SH \u00d7 SH. These functions are \nde.ned in Figure 4. The major change is in the rearrangement function Rearr(e), which takes (F, H) and \ntries to expose a speci.ed cell e from H. The rearrangement function of the forward analysis rearr is \ninvoked to prove that a dereferenced cell e is allocated. The unusual step is that, in case this attempt \nfails, the subroutine adds the missing cell to the precondition and the current symbolic heap. A standard \nanalysis would have stopped, reporting a possible fault. Note that before adding the points-to relation \nto F , the expression e is rewritten in terms of a logical variable a to avoid con.icts with the program \nvariables that change during the computation. We also point out that in order to stop the precondition \nassertion from growing forever (and therefore making the analysis diverge) Abs abstracts F as well as \nH. 5 Here we view functions on SH as functions from SH to P(SH . {T}) that always return singleton sets. \n Program MLOC Num. Procs Proven Procs Procs Coverage % Time (1) Time (8) Linux kernel 2.6.25.4 2.473 \n101330 59215 58.4 6869.09 1739.28 Gimp 2.4.6 0.708 15114 6364 42.1 3601.16 1067.60 OpenSSL 0.9.8g 0.214 \n4818 2967 61.6 605.36 446.60 Sendmail 8.14.3 0.108 684 353 51.6 184.50 184.83 Apache 2.2.8 0.102 1870 \n881 47.1 294.67 104.48 OpenSSH 5.0 0.073 1135 519 45.7 142.56 30.24 Spin 5.1.6 0.019 357 197 55.2 772.82 \n253.96 Table 1. Case Studies with Larges Programs (timeout=1s). 7. Case Studies The compositional analysis \nalgorithm in this paper takes an abstract domain as an argument. We have implemented our algorithm in \nthe SPACEINVADER tool, giving us a version SPACEINVADER ABDUCTOR , or more brie.y, ABDUCTOR. This instantiation \nof our compositional analysis algorithm uses the composite abstract domain from [4] as the base shape \nanalysis. We used that domain because of its ability to deal with a variety of linear data structures. \nBut since our analysis is parametric in the abstract domain, we could plug in other abstract domains, \nsuch as those from [21, 30], and we would immediately obtain another compositional analysis. Small Examples. \nThis .rst case study gives us some basic in\u00adformation on the quality of the speci.cations inferred by \nthe com\u00adpositional algorithm. It is entirely possible, after all, to obtain a useless compositional analysis \nsimply by returning trivial speci.\u00adcations (the top of a lattice) for all procedures. Our .rst case study \nillustrates the treatment of recursion (and, thus, the interprocedural aspect), both cyclic and acyclic \nlists, and nested structures. The particular data structure was a cyclic singly\u00adlinked list, where each \nnode has a nested acyclic sub-list. We wrote recursive procedures for traversing, deleting, and inserting \ninto such structures. In each case ABDUCTOR found a precondition formula describing exactly this data \nstructure: it described only the cells accessed by the algorithms. That the algorithm found these preconditions \nfor algorithms performing nested traversals on nested data structures indicates that the analysis does \nnot only .nd trivial speci.cations: accurate analysis within loops and recursions, and within lists, \nis needed to .nd the resulting speci.cations.6 Medium Example. The IEEE 1394 (.rewire) Device Driver \nfor Windows is around 10K LOC, and it contains 121 procedures. It was analyzed in a top-down fashion \nin [23]. We sought to use the same abstract domain, to compare our bottom-up analysis. Our analysis was \nable to .nd consistent speci.cations (where precondition is not inconsistent) for all 121 of the procedures. \nNote that many of these procedures have to .t together with one another. If we found a completely imprecise \nspec of one procedure, then this might be inconsistent with another procedure s calling expectations. \nPut another way, our analysis has found proofs of the Hoare triples for higher-level procedures, which \nwould have been impossible if the specs discovered for sub-procedures were too imprecise for the relevant \ncall sites. More anecdotally, looking at top-level procedures we .nd that the speci.cations describe \ncomplex, nested structures (not neces\u00adsarily weakest liberal preconditions), which could only be found \nif the analysis was tracking traversals of these structures with some degree of precision. To take one \nexample, the analysis of top\u00adlevel procedure t1394Diag Pnp discovers preconditions with sev\u00aderal circular \nlinked lists, some of which have nested acyclic sub\u00adlists. This is as expected from [23]. But, some of \nthe precondi\u00ad 6 The source code of the small examples can be found at: http://www.dcs.qmul.ac.uk/~ddino/small \nexamples popl09 tions are unexpected. Usually, the .rewire driver collaborates with other lower-level \ndrivers, and this collaboration involves the deref\u00aderence of certain .elds of these lower-level drivers. \nSo, if a human (as in our previous work) writes preconditions for the driver, he or she normally speci.es \nthat the collaborating lower-level drivers are allocated, because otherwise, the preconditions cannot \nensure pointer safety. What the bottom-up analysis .nds is that these lower-level drivers are not necessarily \ndereferenced; dereferencing depends on the values of parameters. The preconditions discovered by ABDUCTOR \nthus clarify this dependency relation between the values of parameters and the dereference of lower-level \ndrivers. We stress that, to obtain these results for the .rewire driver, we had to slightly modify the \ncode analyzed in [23]. The problem is that the driver works over lists where the nodes contain back\u00adpointers \nto a common head node. When doing top-down analysis, with a given precondition, this common information \nis readily available. When going bottom-up, more general cases were con\u00adsidered by ABDUCTOR, that the \nabstract domain could not handle precisely. This is perhaps not surprising, as the domain from [23] was \ndesigned with top-down analysis in mind. But, it also illustrates that the bottom-up analysis places \ndifferent stresses on an abstract domain than does top-down. So, while we would claim that the better \nthe abstract domain .ts the data structures of a program the better are the triples discovered by our \ntechnique, we also emphasize that the problem of spec discovery might impact the design of abstract domains. \nLarge Programs and Complete Open Source Projects. In Table 1 we report case studies running ABDUCTOR \non larger open source projects (e.g. a complete Linux Kernel distribution). The purpose of these examples \nis not to test precision: rather, they probe scalability and graceful imprecision. The case studies were \nrun on a machine with two 2.66GHz Quad-Core Intel Xeon processors with 4GB memory. The number of lines \nof C code (LOC) was measured by instrumenting gcc so that only code actually compiled was counted. The \ntable reports for each test: the number of lines of code with unit one million (MLOC); the number of \nprocedures analyzed (Num. Procs); the number of procedures with at least one consistent spec (Proven \nProcs); the percentage of procedures with at least one consistent spec (Procs Coverage %); and the execution \ntime in seconds (Time) with the number of processor cores indicated in brackets (e.g. 8 cores is indicated \nas Time (8)). Running with a timeout of one second for each procedure, we observed that only a very low \npercentage of procedures timed out. More often our analysis failed to .nd a nontrivial spec (a spec with \na consistent precondition). The percentage of procedures analyzed is somewhat encouraging, and might \nbe improved by using better base abstract domains or human intervention. For the great majority of the \nprocedures relatively simple spec\u00adi.cations were found, which did not involve linked list predicates. \nThis is because a minority of procedures actually traverse data structures. (The analysis did many times \n.nd linked list structure, e.g., in procedure ap find linked module in Apache.) The point, for analysis, \nis that by combining abduction and frame inference we obtain speci.cations that (nearly) describe only \nthe cells accessed by a procedure. This modularity means that linked lists do not have to be threaded \nthroughout the speci.cations of all procedures. There is no deep reason for our scalability, except perhaps \nthat we attempt to discover small specs (hence reducing the number as well). We can easily employ a timeout \nstrategy because of compo\u00adsitionality: if one procedure times out, we can still get results for others. \nEven more importantly, we can analyze each .le indepen\u00addently of others: we do not have to load the entire \nsource program into memory to analyze it, which would quickly overspill the RAM and cause the analysis \nto thrash. To underline this independence we have reported parallel speedup in Table 1, for an implementa\u00adtion \nusing eight cores. Caveats. Our compositional algorithm is parametrized by the base abstract domain, \nand so an instantiation of it will inherit any limitations of the base domain. For our experiments we \nused the domain introduced in [4], which does not deal well with arrays and pointer arithmetic. These \nare treated as non-deterministic opera\u00adtions that are imprecise but sound for the goal of proving pointer \nsafety. Also, the analysis ignores concurrency. (Indeed, it may be that the compositional analysis gives \nnew methods that might be used in shape analysis for concurrency [18].) We have treated unknown library \nprocedures as non-deterministic assignments without side effects. In many cases this is a sound in\u00adterpretation, \nfor the purposes of pointer safety. However, we simply did not have the time to manually inspect all \nof the C libraries to provide specs for them. Note that this problem does not impact the scalability \naspect of our experiment, which is its primary pur\u00adpose. (Of course, we would be interested in combining \nour work with techniques designed to deal with libraries in binary [16].) Finally, our method does not \ndeal well with code pointers, a longstanding open problem. We have treated code pointers as if they are \nunknown procedures. This, in effect, assumes that a code pointer is part of an object with a different \nfootprint than the current procedure. One often sees this idiom, for example in the relation between \nthe Linux kernel and device drivers. Our position also calls to mind the hypothetical frame rule from \n[35]. However, signi.cant further work is needed in this direction. At the beginning of the paper we \nmade the case for examining a compositional shape analysis. We do not claim that compositional analyses \nare fundamentally superior to non-compositional ones. As we have argued in the introduction, they present \nseveral interesting properties. However, it is reasonable to envisage that, ultimately, effective and \naccurate analysis of large software will be done by considering a mix of techniques. An analysis might \nwork composi\u00adtionally most of the time, choosing where to employ more precise and perhaps non-compositional \nmethods. For instance, we might run an analysis bottom-up, interpreting callees before callers, but then \nemploy a top-down narrowing phase afterwards to improve precision on certain needed parts of the code. \n8. Related Work As we mentioned in the Introduction, we are interested in accurate heap analyses that \ncan be used to prove pointer safety. We use the term analysis to refer to methods that discover loop \ninvariants and pre-and postconditions, and con.ne our attention to such veri.ca\u00adtion methods in this \nsection.7 Of course, our method might be used in concert with static veri.ers that use user-supplied \nannotations. The kind of shape analysis done here is one that attempts to be accurate in the presence \nof deep heap update, where a heap mu\u00ad 7 For example, [25] refers to itself as a compositional heap analysis, \nbut it requires procedure summaries/specs to be provided by the user, so it performs a different task \nthan here. tation is made some undetermined length down a linked structure. The .rst such analysis was \npresented in [43], and there have been many subsequent works in search of ever better shape domains (e.g., \n[37, 6, 26, 28, 29, 4, 8]). Scalability is a signi.cant prob\u00adlem for these precise analyses. Several \npapers on deep update have reported whole-program analyses with experimental results on pro\u00adgrams in \nthe thousands of lines of code [21, 23, 30]. Other analyses sacri.ce precision in order to gain scalability \n[14, 22]; they cannot, for example, give precise results on device drivers. The techniques developed \nin this paper are in a sense comple\u00admentary to the ideas in all these works. Although we have used the \ndomain from [4, 23] in our experiments, the compositional analy\u00adsis algorithm is parametrized by the \nabstract domain and we might swap in one of the other abstract domains, or others that are devel\u00adoped \nin the future to obtain ever better compositional analyses. We do not claim that bi-abductive inference \nis the only possible way one might obtain a compositional shape analysis. Indeed, other approaches might \noccur more immediately to the reader: particularly, underapproximating backwards program analysis. De.ning \na backwards shape analysis with acceptable precision and ef.ciency is, as far as we are aware, an open \nproblem. Prior to our precursor paper [7], we formulated and implemented a back\u00adwards shape analysis \nof our own. It created an enormous number of abstract states, and when it took several seconds to analyze \na trivial list traversal program we abandoned the approach. Subsequently, several groups described ways \nto obtain precon\u00additions in shape analysis by going backwards [27, 38, 1]. None is formulated in an interprocedural \nmanner, and they report experi\u00admental results only for programs in the tens of lines of code. Further \nresearch is needed to develop or evaluate the ideas in these works. Previous works have treated procedure \ncalls in a local way, by passing only the reachable part of the abstract heap to a procedure [42, 17, \n30]. The method here is more strongly local; by using the idea of .nding/using small speci.cations that \nonly mention the footprints of procedures, we are able to be more aggressive and sometimes pass fewer \nthan the reachable cells. The general issues regarding compositional program analysis are well known \n[10], and for non-shape domains a number of compositional analyses have appeared (e.g. [45, 33, 13, 20, \n31]). They all use different techniques to those here. Giacobazzi has previously used abductive inference \nin the anal\u00adysis of logic programs [15]. The problem he solves is dual to that here. Given a speci.cation \nof a logic programming module and an implementation, the method of [15] infers constraints on unde.ned \nliterals in the module: it is top-down synthesis of constraints on literals referred to in open code. \nIn a procedural language the cor\u00adresponding problem is to start with a Hoare triple for an outer procedure, \nwhose body refers to another unknown procedure, and to infer a constraint on the unknown procedure. Here, \nwe infer the spec for the outer procedure, relying on previously-computed specs for procedures called \nin its body. It would be interesting to at\u00adtempt to apply abduction in Giacobazzi s way to procedural \ncode, to infer constraints from open code. Gulwani et al. [19] have used abduction to under-approximate \nlogical operators such as conjunction and disjunction in their work on program analysis for abstract \ndomains with quanti.cation. Their application of abduction is completely different to that here. 9. Conclusions \nThis paper has introduced the use of abductive inference to syn\u00adthesize heap speci.cations. We de.ned \none particular abductive proof procedure for use with separated heap abstractions, and we explained how \na more general notion of bi-abduction could be used to de.ne a compositional interprocedural shape analysis. \nBi-abduction displays abduction as, in a sense, an inverse to the frame problem. Frame inference is about \nsynthesizing leftover, extra portions of state. Abduction .nds needed, missing portions of state, which \nwe call anti-frames. The frames are not allowed to be updated, while the anti-frames can be. This informally-described \ninversion is curiously matched in our logical question A * ?anti-frame f G * ?frame. Furthermore, the \ntwo parts to the bi-abduction question play differ\u00adent but mutually supporting roles: the anti-frames \nhelp us .nd small speci.cations, that describe constrained portions of memory [34], while the frames \nallow us to use the small specs. We did case studies ranging from small and medium-sized ex\u00adamples to \ntest precision, to larger code bases, including Linux, OpenSSL and Apache. No previous shape analysis \nfor deep update has approached code bases of comparable size. The analysis results we obtain on the large \nprograms are partial, but this is another bene.t of our method. The analysis is able to obtain non-trivial \nHoare triples for collections of procedures, even when for other procedures it obtains imprecise results \nor takes too long. For the procedures we did not successfully analyze we could in principle consider \nusing other methods such as manually\u00adsupplied assertions to help the analysis along, interactive proofs, \nor even other abstract domains. In fact for the eventual aim of proving non-trivial properties (e.g., \nmemory safety) of entire large code bases it seems likely that a mixture of techniques, with different \ndegrees of automation, will be needed, and it is in easing their blending that compositional methods \nhave much to offer. Finally, it seems that our scheme of using abduction to infer preconditions could \nconceivably be used to de.ne compositional analyses for other abstract domains than shape domains. Acknowledgements. \nWewould liketothank JanTobiasM\u00a8uhlberg for providing the benchmarks which initially sparked this work, \nPaul Kelly for giving us access to his group s 8-core machine, and Wei-Ngan Chin for useful comments. \nThe authors acknowledge the support of the Smallfoot project funded by the UK EPSRC. Diste\u00adfano was supported \nby a Royal Academy of Engineering research fellowship. Calcagno, O Hearn and Yang were supported by EP-SRC \nAdvanced Fellowships. O Hearn acknowledges the support of a Royal Society Wolfson Research Merit Award. \nReferences [1] P.A. Abdulla, A. Bouajjani, J. Cederberg, F. Haziza, A. Rezine: Monotonic Abstraction \nfor Programs with Dynamic Memory Heaps. In CAV 08, pp. 341-354. [2] A.Podelski, A.Rybalchenko, and T.Wies. \nHeap assumptions on demand. In CAV, 2008. [3] I. Balaban, A. Pnueli, and L. D. Zuck. Shape analysis \nby predicate abstraction. In VMCAI 05, pp. 164-180. [4] J. Berdine, C. Calcagno, B. Cook, D. Distefano, \nP. O Hearn, T. Wies, and H. Yang. Shape analysis of composite data structures. In CAV 07. [5] J. Berdine, \nC. Calcagno, and P. O Hearn. Symbolic execution with separation logic. In APLAS 05, pp. 52-68. [6] A. \nBouajjani, P. Habermehl, A. Rogalewicz, and T. Vojnar. Abstract tree regular model checking of complex \ndynamic data structures. In SAS 06, pp. 52-70. [7] C. Calcagno, D. Distefano, P. O Hearn, and H. Yang. \nFootprint analysis: A shape analysis that discovers preconditions. In SAS 07. [8] B. Chang and X. Rival. \nRelational inductive shape analysis. In POPL 08, pp. 247-260. [9] B. Chang, X. Rival, and G. Necula. \nShape analysis with structural invariant checkers. In SAS 07, pp. 384-401. [10] P. Cousot and R. Cousot. \nCompositional separate modular static analysis of programs by abstract interpretation. In SSGRR 01. [11] \nD. Distefano, P. O Hearn, and H. Yang. A local shape analysis based on separation logic. In TACAS 06, \npp. 287-302. [12] D. Distefano and M. Parkinson. jStar: Towards Practical Veri.cation for Java. In OOPSLA \n08, pp. 213-226. [13] N. Dor, M. Rodeh, and M. Sagiv. CSSV: Towards a realistic tool for statically detecting \nall buffer over.ows in C. In PLDI 03, pp. 155-167. [14] R. Ghiya and . Hendren. Is it a tree, a DAG, \nor a cyclic graph? A shape analysis for heap-directed pointers in C. In POPL 96, pp. 1-15. [15] R. Giacobazzi. \nAbductive analysis of modular logic programs. In SLP 94, pp. 377-392. [16] D. Gopan and T. Reps. Low-level \nlibrary analysis and summarization. In CAV 07, pp. 68-81. [17] A. Gotsman, J. Berdine, and B. Cook. Interprocedural \nshape analysis with separated heap abstractions. In SAS 06, pp. 240-260. [18] A. Gotsman, J. Berdine, \nB. Cook, and M. Sagiv. Thread-modular shape analysis In PLDI 07, pp. 266-277. [19] S. Gulwani, B. McCloskey, \nand A. Tiwari. Lifting Abstract Interpreters to Quanti.ed Logical Domains. In POPL 08, pp. 235-246. [20] \nS. Gulwani and A. Tiwari. Computing procedure summaries for interprocedural analysis. In ESOP 07, pp. \n253-267. [21] B. Guo, N. Vachharajani, and D. August. Shape analysis with inductive recursion synthesis. \nIn PLDI 07, pp. 256-265. [22] B. Hackett and R. Rugina. Region-based shape analysis with tracked locations. \nIn POPL 05, pp. 310-323. [23] H.Yang, O.Lee, J.Berdine, C.Calcagno, B.Cook, D.Distefano, and P.O Hearn. \nScalable shape analysis for systems code. In CAV 08. [24] A. C. Kakas, R. A. Kowalski, and F. Toni. Abductive \nlogic programming. J. of Logic and Computation, 2(6):719-770, 1992. [25] V. Kuncak, P. Lam, and M. Rinard. \nRole analysis. In POPL 02. [26] T. Lev-Ami, N. Immerman, and M. Sagiv. Abstraction for shape analysis \nwith fast and precise transfomers. In CAV 06, pp. 547-561. [27] T. Lev-Ami, M. Sagiv, T. Reps, and S. \nGulwani:. Backward analysis for inferring quanti.ed preconditions. Tel Aviv University Tech Report TR-2007-12-01, \n2007. [28] S. Magill, J. Berdine, E. Clarke, and B. Cook. Arithmetic Strengthen\u00ading for Shape Analysis. \nIn SAS 07, pp. 419-436. [29] R. Manevich, J. Berdine, B. Cook, G. Ramalingam, and M. Sagiv. Shape analysis \nby graph decomposition. In TACAS 07, pp. 3-18. [30] M. Marron, M. Hermenegildo, D. Kapur, and D. Stefanovic. \nEf.cient context-sensitive shape analysis with graph based heap models. In CC 08, pp. 245-259. [31] Y. \nMoy. Suf.cient preconditions for modular assertion checking. In VMCAI 08, pp. 188-202. [32] H. Nguyen, \nC. David, S. Qin, and W.-N. Chin. Automated veri.cation of shape and size properties via separation logic. \nIn VMCAI 07. [33] E. Nystrom, H. Kim, and W. Hwu. Bottom-up and top-down context\u00adsensitive summary-based \npointer analysis. SAS 04, pp. 165-180. [34] P. O Hearn, J. Reynolds, and H. Yang. Local reasoning about \nprograms that alter data structures. In CSL 01, pp. 1-19. [35] P. O Hearn, H. Yang and J. Reynolds. Separation \nand information hiding. In POPL 04, pp. 268-280. [36] C. Peirce. Collected papers of Charles Sanders \nPeirce. Harvard University Press., 1958. [37] A. Podelski and T. Wies. Boolean heaps. In SAS 05, pp. \n268-283. [38] A.Podelski, A.Rybalchenko, and T.Wies. Heap assumptions on demand. In CAV 08, pp. 314-327. \n[39] T. Reps, S. Horwitz, and M. Sagiv. Precise interprocedural data.ow analysis via graph reachability. \nIn POPL 95, pp. 49-61. [40] J. C. Reynolds. Separation logic: A logic for shared mutable data structures. \nIn LICS 02, pp. 55-74. [41] N. Rinetzky, J. Bauer, T. Reps, M. Sagiv, and R. Wilhelm. A semantics for \nprocedure local heaps and its abstractions. In POPL 05. [42] N. Rinetzky, M. Sagiv, and E. Yahav. Interprocedural \nshape analysis for cutpoint-free programs. In SAS 05, pp. 284-302. [43] M. Sagiv, T. Reps, R. Wilhelm. \nSolving shape-analysis problems in languages with destructive updating. ACM TOPLAS, 20(1):1-50,1998. \n[44] M. Sharir and A. Pnueli. Two approaches to interprocedural data .ow analysis. In S. Muchnick and \nJ. Jones, editors, Program Flow Analysis: Theory and Applications. Prentice-Hall, 1981. [45] J. Whaley \nand M. Rinard. Compositional pointer and escape analysis for Java. In OOPSLA 06, pp. 187-206.  \n\t\t\t", "proc_id": "1480881", "abstract": "<p>This paper describes a compositional shape analysis, where each procedure is analyzed independently of its callers. The analysis uses an abstract domain based on a restricted fragment of separation logic, and assigns a collection of Hoare triples to each procedure; the triples provide an over-approximation of data structure usage. Compositionality brings its usual benefits -- increased potential to scale, ability to deal with unknown calling contexts, graceful way to deal with imprecision -- to shape analysis, for the first time.</p> <p>The analysis rests on a generalized form of abduction (inference of explanatory hypotheses) which we call <i>bi-abduction</i>. Bi-abduction displays abduction as a kind of inverse to the frame problem: it jointly infers anti-frames (missing portions of state) and frames (portions of state not touched by an operation), and is the basis of a new interprocedural analysis algorithm. We have implemented our analysis algorithm and we report case studies on smaller programs to evaluate the quality of discovered specifications, and larger programs (e.g., an entire Linux distribution) to test scalability and graceful imprecision.</p>", "authors": [{"name": "Cristiano Calcagno", "author_profile_id": "81100047402", "affiliation": "Imperial College London, London, United Kingdom", "person_id": "P1300996", "email_address": "", "orcid_id": ""}, {"name": "Dino Distefano", "author_profile_id": "81100325271", "affiliation": "Queen Mary, University of London, London, United Kingdom", "person_id": "P1300997", "email_address": "", "orcid_id": ""}, {"name": "Peter O'Hearn", "author_profile_id": "81332519314", "affiliation": "Queen Mary, University of London, London, United Kingdom", "person_id": "P1300998", "email_address": "", "orcid_id": ""}, {"name": "Hongseok Yang", "author_profile_id": "81100355747", "affiliation": "Queen Mary, University of London, London, United Kingdom", "person_id": "P1300999", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480917", "year": "2009", "article_id": "1480917", "conference": "POPL", "title": "Compositional shape analysis by means of bi-abduction", "url": "http://dl.acm.org/citation.cfm?id=1480917"}