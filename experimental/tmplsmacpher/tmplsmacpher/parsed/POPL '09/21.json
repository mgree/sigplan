{"article_publication_date": "01-21-2009", "fulltext": "\n A Combination Framework for Tracking Partition Sizes Sumit Gulwani Tal Lev-Ami * Mooly Sagiv Microsoft \nResearch Tel-Aviv University Tel-Aviv University sumitg@microsoft.com tla@post.tau.ac.il msagiv@post.tau.ac.il \n Abstract We describe an abstract interpretation based framework for proving relationships between sizes \nof memory partitions. Instances of this framework can prove traditional properties such as memory safety \nand program termination but can also establish upper bounds on us\u00adage of dynamically allocated memory. \nOur framework also stands out in its ability to prove properties of programs manipulating both heap and \narrays which is considered a dif.cult task. Technically, we de.ne an abstract domain that is parameterized \nby an abstract domain for tracking memory partitions (sets of mem\u00adory locations) and by a numerical abstract \ndomain for tracking rela\u00adtionships between cardinalities of the partitions. We describe algo\u00adrithms to \nconstruct the transfer functions for the abstract domain in terms of the corresponding transfer functions \nof the parameterized abstract domains. A prototype of the framework was implemented and used to prove \ninteresting properties of realistic programs, including pro\u00adgrams that could not have been automatically \nanalyzed before. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; \nF.3.1 [Logics and Meanings of Programs]: Specifying and Verifying and Reasoning about Pro\u00adgrams; F.3.2 \n[Logics and Meanings of Programs]: Semantics of Programming Languages Program analysis General Terms \nReliability, Veri.cation Keywords Combining Analyses, Set Analysis, Numerical Analy\u00adsis, Shape Analysis, \nTermination, Space Bounds, Memory Safety 1. Introduction The theme of this paper is to automatically \nestablish invariants re\u00adgarding sizes of memory partitions. Such invariants are crucial in order to bound \nthe size of dynamically allocated data (e.g., in em\u00adbedded systems). They are also necessary in order \nto infer the shape of the data in programs that manipulate both arrays and dynam\u00adically allocated data \nstructures, which is common in many imple\u00admentations of abstract data types such as hashing, skiplists, \nBTrees, * Supported by the Adams Fellowship Program of the Israel Academy of Sciences and Humanities. \nPart of this work was done while visiting University of California Berkeley supported by a donation from \nIBM and while visiting Cadence Berkeley Research Laboratory. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 09, January 18 24, 2009, Savannah, Georgia, \nUSA. Copyright c &#38;#169; 2009 ACM 978-1-60558-379-2/09/01. . . $5.00. and string implementations. \nMoreover, proving such invariants in these programs is required for proving their memory safety. We describe \nnew algorithms for establishing such invariants by combining two kinds of abstractions: (a) Abstractions \nthat parti\u00adtion the memory into (not necessarily) disjoint parts and (b) Nu\u00admerical abstractions that \ncan track relationships between numeric variables. Our algorithms are parameterized by both abstractions \nwhich allows to leverage existing shape abstractions (e.g., [33, 30, 12, 25]) and existing numerical \nabstractions (e.g., Polyhedra [8], Octagons [26], Intervals [6]). We call such an analysis a set cardi\u00adnality \nanalysis. We .rst formalize the notion of a set abstract domain that provides abstractions to partition \nthe memory into (not necessarily disjoint) parts called base-sets. We describe the interface that a set \ndomain should export in order for it to be combinable with a numerical domain (Section 3). A key component \nof such an interface is the Witness operator that relates a given base-set with other base-sets that \noccur in a given set-domain element. (This relationship is transformed into a numerical relationship \nover the cardinalities of the base-sets by the combination framework, and is the only window to communicate \nany information about the meaning of a base-set to the numerical domain, which otherwise views base-sets \nas uninterpreted and simply uses a fresh variable to denote the cardinality of each base-set). We show \nthat several popular heap/shape analysis domains can be easily made to support such an interface (Section \n3.3) this is one of the contributions of the paper. We then de.ne the notion of a set cardinality abstract \ndomain that is parameterized by a set domain and a numerical domain (Sec\u00adtion 4). An element of the set \ncardinality domain is a pair composed of a set-domain element and a numerical element. The interesting \npart here is our formalization of the pre-order between the elements in this domain, which de.nes the \nlevel of reasoning built into our set cardinality domain. The pre-order is de.ned constructively in terms \nof the partial orders of the individual domains. Hence, given a decision procedure for the set domain \nand a decision procedure for the numerical domain, our pre-order construction shows how to convert them \ninto a decision procedure for the set cardinality do\u00admain. Such a modular construction of the decision \nprocedure for the set cardinality domain is an independent contribution of the paper, and .ts in the \nstream of work on decision procedures for reasoning about sets and their cardinalities [21]. Though we \ndo not prove any completeness results here, the modular construction allows the use of existing set and \nnumerical domains and is demonstrated to be precise enough in practice. We then describe algorithms for \nthe transfer functions for the set cardinality domain. This is a key technical contribution of the paper. \nEach of the transfer functions for the set cardinality domain is described modularly in terms of the \ncorresponding transfer func\u00adtions of the constituent set domain and the numerical domain. We also prove \nthe soundness and completeness of these transfer func\u00adtions with respect to the pre-order. The basic \nidea behind the trans\u00adfer functions is to .rst apply the corresponding transfer function over the set-domain \nelements of the inputs to obtain the set-domain element of the output. Then, we use the Witness operator \nexported by the set domain to relate the base-sets in the outputs to the base\u00adsets in the inputs and \nstrengthen the numerical elements in the in\u00adputs with this information. We then apply the transfer functions \nover the numerical elements to obtain the .nal result. The exact de\u00adtails depend on the speci.c transfer \nfunction and are important to establish soundness and completeness of the transfer functions. We start \nby describing interesting applications of our frame\u00adwork, namely termination analysis, memory bounds \nanalysis, and memory safety and functional correctness (Section 2). Our frame\u00adwork enables veri.cation \nof desirable properties of real-world ex\u00adamples, which to our knowledge, have not been analyzed before. \nWe present experimental results illustrating the feasibility of our approach (Section 6.1). We also present \na case-study regarding how the choice of the constituent set domain and the constituent nu\u00admerical domain \naffects the precision of the set cardinality domain (Section 6). 2. Applications Our work has several \napplications that are mentioned below, and we present experimental results for each of these applications \nin Section 6.1. Proving Memory Safety as well as Data-structure Invariants. Often some numeric program \nvariables are related to size of data\u00adstructures, and are used to iterate over data-structures. Our anal\u00adysis \ncan automatically track these relationships between program variables and size of data-structures. These \nrelationships are im\u00adportant to prove memory safety. A common pattern in C where these relationships \narise is when lists are converted into arrays and are then iterated over in the same loop that iterates \nover the cor\u00adresponding array without having a null-dereference check. These relationships are also important \nto prove data-structure invariants. This happens frequently in object-oriented code wherein base class \nlibraries maintain length of data-structures like queues or lists. In Section 2.1, we present a procedure \nfrom Microsoft product code that illustrates the importance of tracking relationships between numeric \nvariables and sizes of data-structures for proving both memory safety and data-structure invariants. \nWe do not know of any existing technique that can automatically verify the correctness of assertions \nin this code. Bounding Memory Allocation. This involves bounding the sizes of the partitions corresponding \nto the allocation statements in the program. This is especially important in embedded systems, where \nwe would like to prove statically that the amount of memory that the system is shipped with is suf.cient \nto execute desired appli\u00adcations. We present examples of bounding memory allocation in terms of sizes \nof input data-structures for deep copy routines over a variety of data-structures in Section 6. Proving \nTermination. The oldest trick for proving termination of loops has been that of .nding a ranking function \n[34]. A ranking function for a loop is a function whose value decreases in each it\u00aderation and is bounded \nbelow by some .nite quantity. There has recently been a lot of work on discovering fancy forms of numeri\u00adcal \nranking functions (lexicographic polyranking functions [4], dis\u00adjunctively well-founded linear ranking \nfunctions [29]). However, for several programs based on iteration over data-structures, the ranking function \nis actually related to the cardinality of some par\u00adtition of the data-structure. Our technique can .nd \nsuch ranking functions and can in fact even prove a bound on the loop iterations by instrumenting a counter \nvariable in the loop and discovering in\u00advariants that relate the counter variable and sizes of partitions. \nWe illustrate this by means of the BubbleSort example in Section 2.2. We do not know of any existing \ntechnique that can prove even ter\u00admination of this example automatically. 2.1 String Buffer Example \nThis example illustrates the use of our analysis for proving memory safety as well as establishing data-structure \ninvariants. Consider the string buffer data-structure StringBuffer de\u00adscribed in Figure 1(a), as taken \nfrom Microsoft product code. A string buffer is implemented as a list of chunks (in reverse order, so \nthat appends are fast). A chunk consists of a character array content whose total size is size and its \nlen .eld denotes the total number of valid characters in the array. This program contains the following \nfeatures that make the task of analysis/veri.cation challenging: (i) The usage of dynamic memory and \npointers with destructive pointer mutations and (ii) The usage of arrays and arith\u00admetic. These features \nare common in C. Moreover, Java ADT im\u00adplementations, such as hash-maps, raise similar challenges. The \nRemove method over string buffer (Figure 1(b)) takes as input a non-negative start index startIndex and \na positive integer count and deletes count characters starting from startIndex. The .rst loop (Lines \n3-4) counts the total length of characters in\u00adside string buffer and stores it into the variable n. The \nsecond loop (Lines 8-9) .nds the .rst chunk endChunk from which characters are to be removed, while the \nthird for loop (Lines 11-12) .nds the last chunk startChunk from which characters are to be removed. \nBoth these loops have a memory safety assertion at lines 9 and 12 respectively. The loop condition for \neach of these loops indicates that m is positive; it does not explicitly indicate that y null. = However, \nthe assertions hold because there is a relationship be\u00adtween m and y, namely that the total number of \ncharacters in the string buffer before y is equal to m. Hence, if m> 0, it implies that y null. The framework \npresented in this paper can be = used to automatically discover such relationships between numer\u00adical \nprogram variables and sizes of appropriate partitions of data\u00adstructures. For this purpose, we require \na set domain whose base\u00adset constructor can represent the set of all characters in a chunk x and the \nchunks before it (referred to as R1(x) in Figure 1(c)). When coupled with a relational numerical domain \nthat can repre\u00adsent linear inequalities between numerical variables, our combina\u00adtion framework yields \na set cardinality analysis that can discover the required invariants (shown in Figure 1(c)). The next \nloop (Lines 21-23) slides down an appropriate number of characters in endChunk. The last loop (Lines \n25-26) counts the total number of characters in the string buffer and stores it in the variable n'. Line \n27 then asserts that n' (whose value is the total number of characters in the string buffer at the end \nof the Remove method) is less than n (whose value is the total number of charac\u00adters in the string buffer \nat the beginning of the Remove method) by an amount equal to count. The assertion holds because lines \n14-20 remove count characters from the string buffer by destructively up\u00addating the data-structure and \nadjusting the value of then len .eld of appropriate chunks. The approach presented in this paper can \nauto\u00admatically discover such relationships that relate the sizes of various partitions of data-structures. \nThese relationships along with the re\u00adquired invariants at other program points are shown in Figure 1(c). \nFigure 1(d) describes the effect of the Remove method over an example string buffer x. The .lled part \n(both dark .lled part and lightly .lled part) of each chunk represents the original characters in the \nstring buffer x. The solid .lled part represents the characters to be removed. The solid .lled part is \nidenti.ed by the second loop (Lines 8-9) and the third loop (Lines 11-12). Remove(StringBuffer * x, int \nstartIndex, int count) { 1 Assume(startIndex = 0 . count > 0); 2 n := 0; 3 for (y := x; y = null; y := \ny . previous) 4 n := n +(y . len); 5 if (n< startIndex + count) return; 6 endIndex := startIndex + count; \n7 y := x; m := n - (y . len); 8 for (; m> endIndex; m := m - (y . len)) 9 Assert(y = null); y := y . \nprevious;  10 endChunk := y; endChunkOff := m; 11 for (; m> startIndex; m := m - (y . len)) 12 Assert(y \n= null); y := y . previous; 13 startChunk := y; startChunkOff := m; 14 if (startChunk = endChunk) 15 \nendChunk . previous := startChunk; 16 startChunk . len := startIndex - startChunkOff; 17 tmp := endIndex \n- endChunkOff; 18 else 19 tmp := endIndex - startChunkOff; 20 endChunk . len := (endChunk . len) - tmp; \n21 for (i := 0; i< endChunk . len; i := i + 1) 22 := i + tmp; i ' 23 endChunk . content[i] := endChunk \n. content[i ' ]; 24 n ' := 0; 25 for (y := x; y = null; y := y . previous) 26 n ' := n ' +(y . len); \n27 Assert(n ' = n - count); 28 } (b) Method to remove count elements from string buffer x starting at \nlocation startIndex typedef struct {int len; int size; char* content; StringBuffer * previous; }* StringBuffer; \n(a) String Buffer data-structure p Interesting Invariants at program point p 4 n = |R1(x)| - |R1(y)| \n5 n = |R1(x)| 9 m = |R1(y)| - (y . len) . m > 0 12 m = |R1(y)| - (y . len) . m > 0 16 startChunkOff = \n|R1(startChunk)| - (startChunk . len) endChunkOff = |R1(endChunk)| - (endChunk . len) |R1(x)| = n - (endChunkOff \n- startChunkOff - (startChunk . len)) 20 (startChunk . len) = startIndex - startChunkOff |R1(x)| = n \n- (endChunkOff - startChunkOff - (startChunk . len)) 21 |R1(x)| = n - count 26 n ' = |R1(x)| - |R1(y)| \n27 n ' = |R1(x)| (c) Interesting invariants at various program points in the Remove method that are \nnecessary to prove the given assertions. The invariants given hold right before p is executed. (d) An \nexample of a string buffer x before and after the remove method. Figure 1. Remove method of StringBuffer \ndata-structure (adapted slightly from Microsoft product code). The method has 2 memory safety assertions \nand one assertion that relates the sizes of the string buffer at the entry and exit. 2.2 BubbleSort \nExample This example illustrates the use of our analysis for proving termina\u00adtion as well as computing \na bound on the number of loop iterations. Consider the BubbleSort procedure shown in Figure 2 that sorts \nan input array A of length n. Ignore lines 2 and 4 that update a counter variable c. The algorithm works \nby repeatedly iterating through the array to be sorted, comparing two items at a time and swapping them \nif they are in the wrong order (Line 8). The iteration through the array (Loop in lines 6-11) is repeated \nuntil no swaps are needed (indicated by the change boolean variable), which indicates that the array \nis sorted. Notice that establishing a bound on the number of iterations of the outer while-loop of this \nprocedure is non-trivial; it is not imme\u00addiately clear why the outer while loop even terminates. However, \nnote that in each iteration of the while loop, at least one new el\u00adement bubbles up to its correct position \nin the array (i.e., it is less or equal to all of its successors). Hence, the outer while loop terminates \nin at most n steps. The set cardinality analysis that we introduce in this paper can automatically establish \nthis fact by com\u00adputing a relationship between an instrumented loop counter c (to count the number of \nloop iterations of the outer while loop) and the number of elements that have been put in the correct \nposition. In particular, the set cardinality analysis computes the invariant that c is less than or equal \nto the size of the set of the array indices that hold elements at their correct position (provided the \nset cardinality analysis is constructed from a set analysis whose base-set construc\u00adtor can represent \nsuch a set). BubbleSort(int* A, int n) 1 change := true; 2 c := 0; 3 while (change) { 4 c := c +1; 5 \nchange := false; 6 for(j := 0; j<n - 1; j := j + 1) { 7 if (A[j] >A[j + 1]) { 8 Swap(A[j],A[j + 1]); \n9 change := true; 10 } 11 } 12 } 13 Figure 2. Bubblesort Routine. 3. Set Domain In this section, we \nformalize the notion of a set abstract domain. In particular, we describe the interface that a set domain \nshould support in order for it to be combinable with a numerical domain in our combination framework. \nA set domain P consists of set-domain elements that are related by some partial order .P. A set-domain \nelement P of a set domain should expose some bounded collection of (interpreted) base-sets, referred \nto as BaseSets(P ). Examples for base-sets are R1(z), where z is a program variable, as used in Section \n2.1. The numeri\u00adcal domain tracks relationships of the cardinalities of the base-sets in BaseSets(P ). \nA set domain exports all the standard operations needed to per\u00adform abstract interpretation (namely Join, \nWiden, Eliminate, PostPredicate, as de.ned in Section 5). Besides these opera\u00adtions, a set domain also \nneeds to support the following operations in order for it to be combinable with a numerical abstract \ndomain to enable tracking of numerical properties over cardinalities of base\u00adsets. 3.1 Witness Operator \nThe set domain P exports an operation WitnessP that takes as input a collection S of base-sets and a \nset-domain element P . Intuitively, Witness(S, P ) returns the interpretation of base-sets in S in terms \nof the base-sets that occur in P using the information from P . This is needed because base-sets are \ninterpreted. Thus, even if the base-sets in S are semantically identical to some base\u00adsets in BaseSets(P \n) (a common case in our setting), there is no way to infer this equality without the help of the set \ndomain. Without Witness, the numerical domain cannot infer anything about cardinalities of base-sets \nin S (even when it has information about cardinalities of base-sets that occur in P ). The result of \nWitness(S, P ) is in the form of normalized set\u00adinclusion relationships. A normalized set-inclusion relationship \n(implied by P ) between a collection T of base-sets is a relation\u00adship of the form  ' pi . pj i.I j.J \nwhere pi, p ' j . T (for all i . I, j . J) and P implies that pi s are all mutually disjoint (i.e., \nunder any concretization of P , the interpretations of pi s are mutually disjoint). Furthermore, I is \nmaximal and J is minimal. In practice, most of the relationships we get are of the form p = pi where \nthe pi s are mutually disjoint. EXAMPLE 1. Consider a simple set domain whose base sets are of the form \nqnk where n is a positive integer and k is a natural. We de.ne x . qnk iff (x mod n) = k. Let BaseSets(P \n)= {q30,q20} and S = {q60,q63,q40}. We have Witness(S, P )= { q60 . q63 . q30,q30 . q60 . q63, q60 . \nq20,q40 . q20 } Note that although q60 . q40 . q20, this relation is not part of the witness since q60 \nand q40 are not disjoint. The advantage of normalized set-inclusion relationships is that they can be \neasily translated into numerical relationship over car\u00addinalities of base-sets, which is something that \na numerical domain can understand. They will thus be used to relate the cardinalities of the base-sets \nbefore and after an abstract operation (see the P2N operation in Section 4). The soundness of the combination \nframework only requires that the base-sets of the left side of a normalized set-inclusion relationship \npi be all mutually disjoint in P . The soundness does not require I to be maximal or J to be minimal, \nand neither does it require the Witness operator to return all such relationships. However, a more precise \ncollection of such relationships leads to a more precise combined domain. 3.2 Generate Operator The \nset domain also has an interface GenerateP to generate in\u00adformation about the cardinality of any base-set \nin relation to any constant. The function GenerateP takes a set-domain element P , and returns a collection \nof inequalities of the form |p|= c or |p|= c (where p . BaseSets(P ) and c is some non-negative integer \nconstant) that are implied by P . In case the set-domain ele\u00adment is inconsistent (i.e., does not represent \nany concrete element), GenerateP simply returns false.  3.3 Examples of Set Domains In this section, \nwe show that several popular heap/shape analysis domains can be viewed as set domains. In particular, \nwe show that for each of these domains we can easily implement the required operations to be used in \nthe combination framework. In all three cases the domain is a powerset domain over some base domain. \nThe combination with the numerical domain is per\u00adformed at the level of the base domain. The construction \nof the powerset domain is done on top of the combined domain. 3.3.1 Canonical Abstraction Canonical Abstraction[33] \nis a powerful domain for shape analysis. The domain is a powerset of abstract shape graphs. Each abstract \nshape graph is based on equivalence classes of memory locations based on the unary predicates that hold \nfor them. These equivalence classes are called abstract nodes. Canonical abstraction maintains the invariant \nthat each abstract node . must represent at least one memory location. Canonical abstraction can maintain \nbinary information that holds universally on abstract nodes, i.e., formulas of the form .v1,v2 ..1(v1) \n. .2(v2) . p(v1,v2) where p is a binary predicate, vi ranges over memory locations and .i(vi) holds when \nvi is in the equivalence class de.ned by .i. Speci.cally, canonical abstraction can express the notion \nof an abstract node . that represents exactly one memory location using the formula unit(.)= .v1,v2 ..(v1) \n. .(v2) . v1 = v2. Required Operations The base-sets of an abstract shape graph are its abstract nodes. \nThus, def BaseSets(P )= {. | . . P } The WitnessCA operation is straightforward as the abstract nodes \nare based on equivalence classes. Thus, abstract nodes have canonical names, which allow to easily relate \nabstract nodes from different abstract shape graphs. Furthermore, because the base-sets are equivalence \nclasses of unary predicates, they are necessarily disjoint. The cardinality constraints arise from the \nnon-emptiness re\u00adquirement and the de.nition of unit, i.e., def GenerateCA (P )=({|.|= 1 | . . BaseSets(P \n)}. {|.| =1 | . . BaseSets(P ), unit(.) . P }) Finally, the canonical abstraction domain can easily interpret \ncardinality constraints of the form |.| =1 by asserting the formula de.ning unit(.). Note that although \nthis was not part of the standard interface for the canonical abstraction domain, there is an existing \nmechanism to easily support this constraint. We use this choice of set domain in our experiments in Section \n6.1. 3.3.2 Boolean Heaps The Boolean Heaps Domain [30] is a powerset domain over Boolean Heaps. As in \ncanonical abstraction, each Boolean heap is formed of equivalence classes of unary predicates. However, \nthere is no requirement for non-emptiness of abstract nodes and no extra binary information. Boolean \nheaps support predicates of the form v = t where t is a ground term. If such a unary predicate holds \non an abstract node, this node represents at most one mem\u00adory location. Thus, we shall de.ne unique(.) \nto hold for any . in which there is a predicate of the form v = t. Required Operations The base-sets \nof a Boolean heap are its abstract nodes. Thus, def BaseSets(P )= {. | . . P } The WitnessBH operation \nis very similar to that of canonical abstraction as both abstractions are based on equivalence classes \nof unary predicates. Because abstract nodes are equivalence classes of unary predicates, the resulting \nbase-sets are necessarily disjoint. Boolean heaps have the notion of a unique base-set but no requirement \nfor non-emptiness. Thus, GenerateBH is de.ned by: def GenerateBH (P )=({|.|= 0 | . . BaseSets(P )}. {|.|= \n1 | . . BaseSets(P ), unique(.)}) Given a cardinality constraint of the form |.| =0, the Boolean heap \ncan soundly remove . from the Boolean heap, thus reducing its size and complexity.  3.3.3 Separation \nDomain We use the separation domain of Distefano et al [12] as a represen\u00adtative of Separation Logic \n[31] based abstract domains. The sepa\u00adration domain is a powerset domain of symbolic heaps. A symbolic \nheap P is a separation logic formula of the form: .x1' ,...,xn' .(p) . ( * Q) Q.SP p..P .P is a set \nof equalities and dis-equalities between pointer vari\u00adables (and possibly nil). SP can contain either \n junk any non-empty memory,  x . y a memory that contains a single address x whose content is y, or \n ls(x, y) a non-empty singly-linked list starting at address x and whose last element points to the \naddress y 1.  The formula .1 *.2 holds on memories that can be decomposed into two disjoint parts s.t. \n.1 holds on one of them and .2 holds on the other. 1 ls(x, y) is de.ned recursively as x = y . (x . y \n..z. x . z * ls(z, y) Required Operations We use the members of SP (a.k.a. star conjuncts) as base-sets, \ni.e., def BaseSets(P )=SP The WitnessSL operation is computed by .nding which star conjuncts are subsets \nof other star conjuncts. Such algorithms al\u00adready exist in the domain for performing containment checks. \nThe locality of most operations (i.e., the fact that they modify only small parts of the memory each \ntime) means that most of the star con\u00adjuncts will appear verbatim. This allows for ef.cient implementa\u00adtion \nof the WitnessSL operation. Furthermore, the base-sets are star conjuncts, thus all base-sets of an abstract \nelement are disjoint. Because all star conjuncts represent non-empty sets and a star conjunct of the \nform x . y is of cardinality 1, GenerateSL is de.ned by: def GenerateSL (P )=({|.|= 1 | . . BaseSets(P \n)}. {|.| =1 | . . BaseSets(P ),. = x . y}) Finally, if the numerical domain discovers that |ls(x, y)| \n=1 then ls(x, y) can be strengthened to x . y. We use the syntax of separation logic in our examples2. \n4. Set Cardinality Domain In this section, we de.ne the notion of a set cardinality domain that is obtained \nby a combination of a set domain and a numeri\u00adcal domain. Given a set domain P and a numerical domain \nN, we de.ne their combination to be the set cardinality domain P N N whose elements are pairs (P, N), \nwhere P is some element that belongs to the set domain P and N is some element that belongs to the numerical \ndomain N. Furthermore, N uses some special variables, each of which denotes the cardinality of some base-set \nfrom BaseSets(P ). We denote the special variable corresponding to a base-set p by pp. In addition, we \nuse in our examples the short\u00adhand [p]A to mean A = p . We use the notation SpecialVars(N) to denote \nthe set of all special variables (i.e., non-program vari\u00adables that corresponds to the cardinality of \nsome base-set) that oc\u00adcur in N. For notational convenience, we overload the notation SpecialVars(P ) \nto denote the set of all special variables that de\u00adnote the cardinality of some base-set in P , i.e., \nSpecialVars(P )= {pp | p . BaseSets(P )} Hence, every element (P, N) that belongs to the domain P N N \nhas the property that SpecialVars(N) . SpecialVars(P ). Also, without loss of any generality, we assume \nthat for any two distinct elements (P1,N1) and (P2,N2), SpecialVars(P1) n SpecialVars(P2)= \u00d8 since we \ncan always rename the special variables that denote the cardinality of some base-sets. The pre-order \nP\"between two elements of the combined 'N domain is de.ned as follows: def (P2,N2) P\"= P P1 . N4 N N1 \n'N (P1,N1) P3 where (P3,N3)= Saturate(P2,N2) N4 = P2N(P3,P1,N3) The pre-order above has two important \ncomponents Saturate and P2N, which are described below. Saturate The Saturate function takes as input \nan element (P, N) from the combined domain and returns another element '' ' (P ,N ) from the combined \ndomain. P and N ' are obtained from P and N respectively by repeated sharing of information about 2 Note \nthat the join algorithm we use is a re.ned version of the one in [12] and uses the ideas in [24].  Figure \n3. Flowchart Nodes. relationships of base-set sizes with integral constants using the GenerateP interface \nexported by the set domain (as described in Section 3) and the GenerateN interface that can be provided \nby a numerical domain as follows: def GenerateN(N)= EliminateN(N, Vars(N) -{x}) x.U where U = SpecialVars(N) \nThe function EliminateN(N, V ) eliminates all variables in set V from the abstract element N. The function \nEliminateN is part of the standard abstract interpretation interface that the numerical domain N comes \nequipped with. Vars(N) denotes the set of all variables that occur in N. The Saturate function above \nis inspired by the Nelson-Oppen methodology of combining decision procedures for disjoint the\u00adories [27], \nwhere elements from different theories share variable equalities (since that is the only information \nthat can be understood by elements from both theories) until no more equalities can be shared. In our \ncase, the information that can be understood by the set-domain element as well as the numerical element \ninvolve re\u00adlating the size of any base-set with a constant. The Nelson-Oppen decision procedure terminates \nbecause the number of independent variable equalities that can be shared is bounded above by the num\u00adber \nof variables. In our case, the number of relationships that can be shared is potentially unbounded since \nthere is no limit on the size of the constants. To address this issue, we allow for sharing of only those \nrelationships that involve constants up to a bounded size, say 2. This is because, in practice, all instances \nof set domains can usually only make use of the information whether the size of a base-set is 0, 1, or \nmore than 1. Bounding the size of constants that can be shared during the saturation process guarantees \nef.cient termination of the Saturate function. We show below an example, where the Saturate function \nleads to repeated sharing of information between a set-domain element P and a numerical element N. EXAMPLE \n2. Consider a program that traverses two linked lists of the same length. One of the lists is pointed \nto by x and the other by y. Traversing the .rst list using the statement z = x . next will cause the \nset domain to perform a case split on whether x is a singleton list or not. The case in which x is a \nsingleton yields the element (P, N) where P is [x . nil]A * [ls(y, nil)]B . z = nil and N is A = B. Calling \nGenerateP(P ) results in A =1 . B = 1, which is used to strengthen N yielding A =1 . A = B. Finally, \nGenerateN(A =1 . A = B) is A =1 . B =1, i.e., |x . nil| =1 .|ls(y, nil)| =1. When used to strengthen \nP this yields x . nil *y . nil . z = nil. Thus, using the cardinality information we have discovered \nthat the second list is a singleton as well. Saturating the input abstract elements is the .rst step \nin all the abstract domain operations described in Section 5. However, in the examples there we use saturated \nelements as inputs to be able to concentrate on other interesting aspects of the algorithms. P2N Operator \nNote that the base-sets in P3 may have different names than those in P1, yet the base-sets in P3 might \nbe related to those in P1 since these are interpreted base-sets. The function P2N(P2,P1,N) performs the \nrole of relating the sizes of the base\u00adsets in P1 and P3 using the Witness operator, translating this \ninto a numerical relationship, and communicating this information to N. Given any two set-domain elements \nP , P ', and a numerical element N, the function P2N(P, P ' ,N) yields a numerical element that is more \nprecise than N and incorporates information about numerical relationships between sizes of base-sets \nin P ' and those in P . ' def P2N(P,P ,N)= PostPredicateN(N, S) where S is the conjunction of linear \ninequalities, one corre\u00adsponding to each normalized set-inclusion relationship in WS = Witness(BaseSets(P \n' ),P ).  S = {ppi =pp' | ( pi . pj ' ) . WS} j ij ij The function PostPredicateN(N, pred) strengthens \nN by as\u00adsuming the predicate pred. We require that the P2N operator satis.es the following transi\u00adtivity \nproperty. PROPERTY 1. For any set-domain elements P, P ' ,P '' and any numerical element N, if P P P \n' P P '', then '''' '' .V : P2N(P,P , P2N(P,P ,N)) = P2N(P,P ,N), where V = SpecialVars(P ' ). The operator \nP2N is used extensively in the implementation of the abstract domain operations for the combined domain \nto relate base-sets coming from different set-domain elements, and strengthen the given numerical element \nwith this information. THEOREM 1. The relation 'N de.ned above is, in fact, a pre- P\" order. The proof \nof Theorem 1 is given in the full version of the pa\u00adper [16]. To recap, the pre-order saturates the left \nelement to share information between the set domain and the numerical domain. It then uses P2N to relate \nthe base sets of the left element to those of the right element. The pre-order, as stated above, also \nde.nes the logic or formal\u00adizes the reasoning power of our combination framework. In that re\u00adgard it \nis related to decision procedures that have been described for logics that combine sets, and numerical \nproperties of their cardinal\u00adities. However, the two main differences are: (a) Our combination framework \nis modular wherein any set analysis can be combined with any numerical analysis, and (b) more importantly, \nwe show how to perform abstract interpretation of a program over such a logic. Performing abstract interpretation \nrequires many more trans- Soundness: E1 D E and E2 D E. fer functions besides a decision procedure (such \nas Join, Widen, Completeness: If E ' is such that E1 E ' and E2 E ' DD Eliminate, etc). and E ' D \nE, then E D E ' . 5. Abstract Interpreter for the Set Cardinality Domain Let P and N be any set domain \nand numerical domain respectively. In this section, we show how to ef.ciently combine the abstract interpreters \nthat operate over the abstract domains P and N to obtain an abstract interpreter that operates over the \nset cardinality domain P N N. Our combination methodology yields the most precise abstract interpreter \nfor the set cardinality domain P N N relative to the pre-order de.ned in Section 4. The key idea of our \ncombination methodology is to combine the corresponding transfer functions of the abstract interpreters \nthat operate over the domains P and N to yield the transfer functions of the abstract interpreter that \noperates over the domain P N N. An abstract interpreter performs a forward analysis on the pro\u00adgram computing \ninvariants (which are elements of the underlying abstract domain over which the analysis is being performed) \nat each program point. The invariants are computed at each program point from the invariants at the preceding \nprogram points in an iterative manner using appropriate transfer functions. We .rst describe our program \nmodel in Section 5.1. In the subsequent sections, we de\u00adscribe the construction of these transfer functions \nfor the set car\u00addinality domain P N N in terms of the transfer functions for the individual domains P \nand N. Further information including proofs can be found in the full version of this paper [16]. 5.1 \nProgram Model We assume that each procedure in a program is abstracted using the .owchart nodes shown \nin Figure 3. We allow for assume and assert program statements of the form assume(pred) and assert(pred), \nwhere pred is a predicate that is either understood by the set domain P, or it is a linear inequality \npredicate. The linear inequality predicate can be over program vari\u00adables and over special variables \nthat denote the cardinality of some base-set that can be speci.ed using some base-set constructors ex\u00adported \nby the set domain P. Since we allow for assume statements, without loss of general\u00adity, we can treat \nall conditionals in the program as non-deterministic (i.e., control can .ow to either branch irrespective \nof the program state before the conditional). A join node has two incoming edges. Note that a join node \nwith more than two incoming edges can be reduced to multiple join nodes each with two incoming edges. \nWe now describe the transfer functions for each of the .owchart nodes. For lack of space, we leave out \nthe description of the transfer function for Assert node, which is quite similar to the de.nition of \nthe pre-order. See full version [16] for more details. 5.2 Join Node The abstract element E after a \njoin node (Figure 3(a)) is obtained by computing the join of the elements E1 and E2 before the join node \nusing the join operator. E = JoinD(E1,E2) The join operator JoinD for a domain D takes as input two elements \nE1 and E2 from domain D and computes an optimal upper bound of E1 and E2 with respect to the pre-order \nD. The following de.nition makes this more precise. DEFINITION 1 (Join Operator JoinD). Let E = JoinD(E1,E2). \nThen, \"' Figure 4 shows how to implement the join operator JoinPN for the set cardinality domain P N \nN using the join operators JoinP and JoinN for the set and numerical domains in a modular fashion. The \nimplementation also makes use of the eliminate oper\u00adator EliminateN for the numerical domain, which is \ndescribed in Section 5.3. \"' EXAMPLE 3. We explain the implementation of the JoinPN op\u00aderator by considering \nthe example in Figure 4(b). This is a simpli\u00ad.ed example of a situation that occurs during an in-place \nreversal of a linked list. The .rst input (P1,N1) represents two disjoint lists, the list pointed to \nby x is of length 1 and the list pointed to by y is of length n - 1. The second input (P2,N2) also represents \ntwo dis\u00adjoint lists. Here, the list pointed to by y is of length 1 and the list pointed to by x is of \nlength n - 1. The .rst step in joining the input elements is to saturate both of them. Remember that \nin all the examples, we use saturated elements to be able to concentrate on the important issues. Thus, \nthe saturate operation has nothing to add. Now, the join of the set domain is performed yielding P , \nwhich represents two disjoint lists pointed to by x and y. The P2N operator is used to strengthen the \nnumerical element by relating the cardi\u00adnalities of the base-sets of P to the cardinalities of the base-sets \nin the original elements. This is done using the Witness operation, which interprets the base-sets of \nP using the base-sets of the orig\u00adinal elements3. For N1 this means that A = E and B = F and for N2 this \nmeans that C = E and D = F . Note that without P2N there will be no relation between the base-sets of \nthe two inputs and thus the numerical join would simply return n = 2. Next, the numerical join is performed. \nThe join loses the fact that one of the lists was a singleton, but retains the important information \nthat the sum of the lengths of the lists is n. Finally, the numerical variables corresponding to the \noriginal base-sets are eliminated to ensure that all the special variables in the numerical element come \nfrom the set-domain element. In case of polyhedra join, this has no effect as any information on the \noriginal special variables relates to only one of the inputs and is thus lost in the join. THEOREM 2. \nThe join operator described in Figure 4(a) satis.es both the soundness and the completeness property \nstated in De.ni\u00adtion 1 (provided the join operators for the base domains, JoinP and JoinN, satisfy these \nproperties, and the eliminate operator for the numerical domain, EliminateN, satis.es the respective \nsoundness and completeness properties stated in De.nition 2 on Page 8). The proof of Theorem 2 is available \nin the full-version of the paper [16].  5.3 Assignment Node The abstract element E ' after an assignment \nnode e := e (Fig\u00adure 3(b)) is the strongest postcondition of the element E before the assignment node \nwith respect to the assignment e := e. It is com\u00adputed by using an existential quanti.cation operator \nEliminateD as described below. E ' = EliminateD(E1,x ' ) where E1 = PostPredicateD(E[x ' /x],x = e[x \n' /x]) 3 Because any relation added by P2N is based on the Witness operation and the original elements \nare saturated, no new relationships will be added among the original base-sets. Inputs: P1 =[x . nil]A \n* [ls(y, nil)]B N((P1,N1), (P2,N2)) = JoinP \"' N1 = A =1 . B = n - 1 . B = 1 '' 1 (P1,N 1) := Saturate(P1,N1); \n P2 =[ls(x, nil)]C * [y . nil]D '' 2 (P2,N 2) := Saturate(P2,N2); N2 = D =1 . C = n - 1 . C = 1 '' 3 \nP := JoinP(P1,P 2); Trace of JoinPN((P1,N1), (P2,N2)): [ls(x, nil)]E * [ls(y, nil)]F \"' '' '' 4 N := \nP2N(P1, P, N 1); 1 '' '' P = 5 N2 := P2N(P2, P, N 2); '' '' '' N1 = A = E . B = F . A =1 . B = n - 1 \n. B = 1 N := JoinN(N1 ,N 2 ); N2 '' = C = E . D = F . D =1 . C = n - 1 . C = 1 7 V := SpecialVars(N) \n- SpecialVars(P ) N = E + F = n . E = 1 . F = 1 8 N ' := EliminateN(N, V ); N ' = E + F = n . E = 1 . \nF = 1 9 Output (P, N ' ); (a) Algorithm (b) Example Figure 4. This .gure describes the algorithm for \njoin transfer function for set cardinality domain P N N in terms of the join transfer functions for the \ndomains P and N along with an example. Inputs: P =[ls(x, z)]A * [ls(z, nil)]B N = A = 1 . B = 1 . A = \nn . B = k EliminatePN((P, N),e) \"' = \"' e = z 1 (P ' ,N ' ) := Saturate(P, N); Trace of EliminateP N((P, \nN),e): [ls(x, nil)]C P1 := EliminateP(P ' ,e); P1 = 3 N1 := P2N(P ' ,P1,N ' ); N1 = A + B = C . A = \n1 . B = 1 . A = n . B = k 4 V := {e}. SpecialVars(N1) - SpecialVars(P1) V = {z, A, B} 5 N2 := EliminateN(N1,V \n); N2 = C = n + k . n = 1 . k = 1 6 Output (P1,N2); (a) Algorithm (b) Example Figure 5. This .gure \ndescribes the algorithm for existential elimination for the set cardinality domain P N N in terms of \nthe existential elimination algorithms for the domains P and N along with an example. The post-predicate \noperator PostPredicateD is de.ned in Section 5.4. The existential quanti.cation operator EliminateD for \nany domain D takes as input an element E from D and an lvalue e, and produces the least element that \nis above E and does not get affected by any change to e. DEFINITION 2 (Eliminate Operator EliminateD). \nLet E ' = EliminateD(E, e). Then, Soundness: E D E ' and E ' does not get affected by any change to e. \n '' E '' Completeness: If E is such that E D and E '' does not get affected by any change to e, then \nE ' D E '' . Figure 5 shows how to implement the eliminate operator De.nition 2 (provided the eliminate \noperator for the base domains, EliminateP and EliminateN, satisfy these properties). The proof of Theorem \n3 is available in the full-version of the paper [16].  5.4 Assume Node The abstract element E ' after \nan assume node Assume(pred) (Fig\u00adure 3(c)) is obtained by using the post-predicate operator described \nbelow. E ' = PostPredicateD(E, pred) The post-predicate operator PostPredicateD for a domain D takes \nas input an abstract element E from domain D and a pred\u00ad icate pred and returns the most precise abstract \nelement E ' suchfor the set cardinality domain P N N using the \"' EliminatePN eliminate operators EliminateP \nand EliminateN for the set and that .D(E ' ) . .D(E) n .(pred), where . is the concretization numerical \ndomains in a modular fashion. operation. The following makes this more precise. EXAMPLE 4. We demonstrate \nthe implementation of the operator DEFINITION 3 (Post-predicate Operator PostPredicateD). Let ' = PostPredicateD(E, \npred). Let .D denote the concretiza- E \"' EliminatePN by the example in Figure 5(b). The example comes \nfrom appending two linked lists. The input is a list pointed to by x tion function for domain D. Then, \nwhose original length is n and a list pointed to by z whose length is ' Soundness: .D(E ) . .D(E) n \n.(pred). k. The second list has been appended to the .rst list. Now, we wish Completeness: If E '' is \nsuch that .D(E ' ) . .D(E)n.(pred),to existentially eliminate z. D E '' then E ' . First, we eliminate \nz from the set domain, yielding P1, a list pointed to by x, losing the information on where z pointed \nto. Figure 6 shows how to implement the post-predicate operator N for the set cardinality domain P N \nN using Next, we use P2N to express the cardinalities of the base-sets of \"' \"' PostPredicateP P in \nterms of the cardinalities of the base-sets of P1. In this case, the post-predicate operators for the \nset and numerical domains A + B = C, i.e., the sum of the lengths of the two parts of the (PostPredicateP \nand PostPredicateN) in a modular fashion. list in P is equal to the length of the list in P1. Next we \neliminate EXAMPLE 5. We demonstrate the PostPredicateP operator z and variables corresponding to the \noriginal base-sets from the numerical element. This loses the original partition of the list and retains \nthe important information that the length of the list is n + k. N by the example in Figure 6(b). We return \nto the example of a list of length n pointed to by x to which a list of length k pointed to by z has \nbeen appended. We wish to assume the predicate m = THEOREM 3. The Eliminate operator described in Figure \n5(a) sat-|ls(x, nil)|, i.e., that m is the length of the entire list pointed to by is.es both the soundness \nand the completeness property stated in x. Note that the predicate refers to a base-set that P can interpret \nPostPredicateP \"' N((P, N), pred) = Inputs: 1 if pred is an arithmetic predicate: [ls(x, z)]A * [ls(z, \nnil)]BP = V := SpecialVars(pred) - SpecialVars(P ); N = A = 1 . B = 1 . A = n . B = k N1 := PostPredicateN(N, \npred); N2 := P2N(P, V, N1); 5 N3 := EliminateN(N2,V ); 6 return (P, N3); 7 else // pred is set predicate: \n8 P1 := PostPredicateP(P, pred); 9 return (P1,N) (a) Algorithm pred = |[ls(x, nil)]C | = m Trace of \nPostPredicatePN((P, N), pred): V = {C}N1 = m = C . A = 1 . B = 1 . A = n . B = k N2 = A + B = C . m = \nC . A = 1 . B = 1 . A = n . B = k N3 = A = 1 . B = 1 . A = n . B = k . m = n + k (b) Example \"' Figure \n6. This .gure describes the algorithm for the post-predicate operation (transfer function for assume \nnode) in the set cardinality domain P N N in terms of the post-predicate operations for the individual \ndomains P and N along with an example. but is not in BaseSets(P ). The variable that represents the length \nof the list pointed to by x is C. First we assume that m = C. Next, P2N is used to interpret C in terms \nof the cardinalities of the base\u00adsets in P . In this case, C = A+B, i.e., the sum of the lengths of the \ntwo parts of the list. Finally, we eliminate the special variables that do not correspond to the base-sets \nin BaseSets(P ). In this case, C is eliminated, retaining the important information that m = n + k. \nSoundness: E1 D E and E2 D E.  Convergence: The sequence of widen operations converges in a bounded \nnumber of steps, i.e., for any strictly increasing sequence E0,E1,... (such that Ei D Ei+1 but Ei+1 D \nEi for all i) , if we de.ne E0 ' := E0, E1 ' := WidenD(E0' ,E1),  E '' 2 := WidenD(E1,E2),..., then \nthere exists i = 0 such that E '' j D Ei and Ei ' D Ej ' for all j>i. \"' Figure 7 shows how to implement \nthe widen operator WidenPN satis.es the soundness property stated in De.nition 3 (provided the for the \nset cardinality domain P N N using the widen operators post-predicate operators for the base domains, \nPostPredicateP WidenP and WidenN for the set and numerical domains in a mod\u00adand PostPredicateN, satisfy \nthe same soundness property, and ular fashion. the eliminate operator for the numerical domain, EliminateN, \nTHEOREM 4. The post-predicate operator described in Figure 6(a) EXAMPLE 6. We demonstrate the WidenPN \noperator by the ex\u00ad \"' satis.es the respective soundness property stated in De.nition 2). The proof of \nTheorem 4 follows simply from the observation that the concretization function for the combined domain \nis the inter\u00ad ample in Figure 7(b). This example is taken from a program that creates a list of length \nn. After the .rst iteration, the list pointed to by x is a singleton and the loop counter i =1. After \nthe second it\u00ad eration, the length of the list pointed to by x is between 1 and 2 and section of the \nconcretization functions of the set domain and the i equals the length of the list. Note that using Join, \nthe constant 2 numerical domain. However, note that the post-predicate operator will keep increasing \nwithout ever converging. The Widen operator described in Figure 6(a) does not necessarily satisfy the \ncomplete\u00ad for the set domain is equivalent to Join for this set domain and re\u00ad ness property stated in \nDe.nition 3 because the pre-order for the turns a non-empty list pointed to by x. The P2N operator expresses \ncombined domain only accounts for a limited (not neces- PN sarily complete) sharing of information between \nthe set domain and \"' the cardinalities of the original base-sets in terms of this new list. Eliminating \nthe special variables for the original base-sets yields numerical elements in which all the information \nis in terms of the new base-set. This elimination is necessary to ensure the widening the numerical domain. \nIn other words, our pre-order is not the best partial-order that corresponds to the concretization function \nfor the combined domain. '' '' operator precondition that N2 is weaker than N1 . Finally, the nu\u00admerical \nwiden operator loses the possible range of the length of the list, but retains the important information \nthat the length of the list equals the iteration number and that i = n, which will allow us to prove \nthat after the loop terminates the length of the list is n. The Widen operation described in Figure 7 \nclearly satis.es the  5.5 Fixed-point computation In presence of loops, the abstract interpreter goes \naround each loop until a .xed point is reached. A .xed point is said to be reached when the abstract \nelements E1,E2 over domain D at any program point inside the loop in two successive iterations of that \nloop represent the same set of concrete elements, i.e., E1 D E2 and E2 D E1. If the domains P or N have \nin.nite chains, then .xed point for a loop may not be reached in a .nite number of steps. In that case, \na widening operation may be used to over-approximate the analysis results at loop heads. A widening operator \nfor a domain D takes as input two elements from D and produces an upper bound of those elements (which \nmay not necessarily be the least upper bound). A widening operator has the property that it guarantees \n.xed point computation across loops terminates in a .nite number of steps even for in.nite height domains. \nA widen operator WidenD for a domain D takes as input two soundness property described above. It also \nsatis.es the conver\u00adgence property; as stated in the theorem below. THEOREM 5. The Widen operation described \nin Figure 7 satis.es the convergence property stated in De.nition 4 (provided the Widen operations for \nthe base domains, WidenP and WidenN, satisfy De.nition 4). PROOF: We give a brief sketch of the proof. \n(Details are in the full version of the paper [16].) Let (P1,N1), (P2,N2),... be any chain of elements \nin the set cardinality domain that arise at a given program point during successive loop iter\u00adations. \nLet (Q1,M1)=(P1,N1) and (Qi+1,Mi+1)= elements E1 and E2 from domain D and returns an element E with \n\"' WidenPN((Qi,Mi), (Pi,Ni)). Then, it can be shown that: the following property: (1) Qi P Qj for all \ni<j, and (2) If Qj P Qi for some i<j, then Mk N Mk+1s and Mk+1s N Mk for all DEFINITION 4 (Widening Operator \nWidenD). i = k<j (otherwise the .xed-point computation converges), Let E = WidenD(E1,E2). Then, where \ns is some bijective variable renaming. The result now Inputs: P1 =[x . nil]A N1 = A =1 . i =1 . i = n \n= WidenPN((P1,N1), (P2,N2)) P2 =[ls(x, nil)]B 1 (P1' ,N 1' ) := (P1,N1); N2 = B = 1 . B = 2 . i = B . \ni = n 2 (P2' ,N 2' ) := Saturate(P2,N2); Trace of WidenPN((P1,N1), (P2,N2)): \"' \"' 3 P := WidenP(P1' \n,P 2' ); '' '' P = 4 N1 := P2N(P1, P, N 1); '' '' '' [ls(x, nil)]C N := P2N(P2, P, N 2); N1 = C = A . \nA =1 . i =1 . i = n '' ''' '' ' 6 N1 := EliminateN(N1 , SpecialVars(N1) - SpecialVars(P )); ''' '' ' \n7 N2 := EliminateN(N2 , SpecialVars(N2) - SpecialVars(P )); ''' ''' 8 N := WidenN(N1 , N 2 ); 9 Output \n(P, N); (a) Algorithm N2 = C = B . B = 1 . B = 2 . i = B . i = n N1 ''' = C =1 . i = C . i = n N2 ''' \n= C = 1 . C = 2 . i = C . i = n N = C = 1 . i = C . i = n (b) Example Figure 7. This .gure describes \nthe algorithm for widening for set cardinality domain P N N in terms of the widening algorithms for the \ndomains P and N along with an example. follows from the observation that the length of the chain is bounded \nabove by the product of the number of times Qi can strictly increase and the number of times Mi can strictly \nin\u00adcrease up to variable renaming. D 6. Case Study The choice of which set analysis and which numerical \nanalysis to combine depends on what data-structures and what properties of those data-structures we want \nto analyze. Different data-structures typically require different base-set constructors, while different \noperations on the same data-structure typically require different numerical domains. We illustrate this \nby two sets of examples. Table 1 shows the loop invariants required to establish relation\u00adships between \nthe size of the output data-structure and the size of the input data-structure for Copy function. These \nexamples re\u00adquire different set domains, but the same numerical domain, namely Karr s linear equalities \ndomain, works for all of these examples. The base-set constructors given here are used to informally \ndemon\u00adstrate the type of invariants the set domain should be able to rep\u00adresent. The exact way that these \nbase-sets are de.ned changes ac\u00adcording to the set domain used. Table 2 shows the loop invariants required \nto establish relation\u00adships between the sizes of the output data-structure and the size of the input \ndata-structure on various functions for an acyclic list (see Table 1 for the de.nition of R(x, y)). These \nexamples require different numerical domains, but the same set analysis domain, namely one that provides \na reachability via next link base-set constructor, works for all of these examples. It is also interesting \nto note that in order to validate a given program, one can either choose a more precise set domain or \na more precise numerical domain. For example, consider proving the data-structure invariant for the list \ncopy example. The induc\u00adtive invariant required to prove that the size of the copied list is the same \nas the size of the input list can either be expressed as |R(x ' , null)| = |R(x, y)| (see Copy example \nin Table 2) or |R(x ' )| = |R(x)|-|R(y)| (see Acyclic List example in Table 1). The former is an element \nin the set cardinality domain built from a relatively more precise set domain (i.e., one that supports \nR(x, y) as a base-set constructor as opposed to simply supporting R(x)), but a relatively less precise \nnumerical domain (i.e., one that sup\u00adports variable equalities, as opposed to arbitrary linear equalities). \nThe above observations are not supposed to imply that for each program, we need to work with a different \ncombination of a set domain and a numerical domain. Certain set domains and certain numerical domains \nare more precise than several others; but pre\u00adcision comes at the cost of ef.ciency. Hence, we need to \nestimate the least precise set domain and the least precise numerical domain that would be good enough \nto reason about desired properties of desired programs. 6.1 Experimental Results We have implemented \nan instance of the combination framework by combining the TVLA system [22] with the Polyhedra abstract \ndomain [8] as implemented by the PPL library [2] using some extra widening heuristics. We chose these \ndomains as they can together handle all of the benchmarks described below. Using less precise domains \nit would be possible to prove some of these benchmarks with better ef.ciency. Table 3 summarizes the \nresults of running the tool on a set of benchmarks. In all cases, the properties speci.ed were proven \nwithout false alarms. The benchmarks were run on a 2.4GHz E6600 Core 2 Duo processor with 2 GB of memory \nrunning Linux. For each program we give the time, the overhead factor over running TVLA without cardinality \nsupport, and the total number of abstract shape graphs generated in the analysis. Note that the overhead \nis rather low with an average of 60%. In some cases, the analysis with cardinality is even faster, as \nit can prune some of the search space using the more precise domain. In some of the examples, running \nwithout cardinality support yields memory safety false alarms. The benchmarks are divided into the .ve \ncategories detailed below. StringBuffer We analyzed the two most challenging methods from among the methods \nsupported by the String Buffer class (as implemented in Microsoft product code): SBRemove (see Figure \n1) and SBToString. SBToString converts a StringBuffer to a single string by allocating an array of the \nappropriate size and copying the characters in the correct order. We prove memory safety and data structure \ninvariants on both examples. In SBRemove, we prove that the number of characters in the resulting StringBuffer \nis in sync with the number of characters removed. In SBToString, we prove that the size of the resulting \nstring equals the number of characters in the original StringBuffer. These examples combine recursively \nde.ned data structures with arrays and demonstrate how the domain can track non-trivial relationships \nbetween the heap and the numerical variables in the programs. Termination We prove termination of two \nnon-trivial examples: BubbleSort (see Figure 2) and Mark. The Mark example performs a DFS scan of a graph \nmarking nodes as they are visited and using a stack for pending nodes. The scan terminates when the pending \nstack is empty. Proving termination in this case is non trivial as the pending stack can grow as well \nas shrink in each iteration. Our technique is able to prove termination of this example by establishing \nthe inductive invariant that the instrumented loop List of Lists Program Loop Invariant Base-set Constructor \nAcyclic List Cyclic List Tree |R(x ' )| = |R(x)| - |R(y)| |R(x ' , y ' )| = |R(x, y)| |Rt(x ' )| = |Rt(x)| \nR(x) = \u00d8, if x = null = {x} . R(x . next), otherwise R(x, y) = \u00d8, if x = y = {x} . R(x . next, y), otherwise \nRt(x) = \u00d8, if x = null = {x} . Rt(x . left) . Rt(x . right), otherwise Rn(x) = Rn(x, 0, x . nrChild) \nn-ary Tree |Rn(x ' , 0, i)| = |Rn(x, 0, i)| Rn(x, low, high) = \u00d8, if x = null = {x} . low=k<high Rn(x \n. children[k]) List of Arrays (e.g., StringBuffer) Array of Lists (e.g., Hashtable) |Re(x ' )| = |Re(x)|-|Re(y)| \n|Ra(x ' )| = |Ra(x)|-|Ra(y)| |T (x ' , 0,i)| = |T (x, 0,i)| Re(x)= \u00d8, if x = null = R(x . list) . Re(x \n. nextL), otherwise A(x, l, h)= {x[k] | l = k< h}Ra(x)= \u00d8, if x = null = A(x . arr, 0,x . len) . Ra(x \n. next), otherwise  T (x, low, high)= R(x[k]) low=k<high Table 1. This table describes the loop invariants \n(and hence illustrates the choice of the set analysis domain) required to analyze the Copy routine of \nvarious data-structures. The property discovered is the relationship between the size of the output data-structure \nwith the size of the input data-structure. Program Loop Invariant Numerical Domain Copy |R(x ' , null)| \n= |R(x, y)| Variable Equalities Reverse |R(x ' , null)| = |R(x, y)| Variable Equalities Filter |R(x ' \n, null)| = |R(x, y)| Difference Constraints Merge |R(x ' , y ' )| = |R(x1, y1)| + |R(x2, y2)| Karr s \nDomain [20] (arbitrary linear equalities) Merge Without Duplicates ' , y ' Polyhedra Domain [8] (Linear \nInequalities) |R(x )|=|R(x1,y1)| + |R(x2,y2)| Table 2. This table describes the loop invariants (and \nhence illustrates the choice of the numerical analysis domain) required to analyze various routines of \nacyclic list data-structure. The property discovered is the relationship between the size of the output \ndata-structure with the size of the input data-structure. counter is bounded above by the cardinality \nof the set of nodes whose visited .ag has been set to true. Linked List Examples This includes all examples \nin Table 2. We prove memory safety and data-structure invariants for all examples. In Reverse we prove \nthat the length of the reversed list equals the length of the original list. In .lter we prove that the \nlength of the list is less or equal to the length of the original list. In Merge we prove that the length \nof the resulting list is the sum of lengths of the original lists. In MergeNoDups we prove that the length \nof the resulting list is less or equal to the sum of lengths of the original lists. Data Structure Copy \nThis includes all examples in Table 1. These examples illustrate the power of our technique for prov\u00ading \nbounds on memory allocation in terms of inputs. We prove that the size of the copied data-structure is \nequal to the size of the orig\u00adinal input data-structure. Note that since a deep copy is performed, the \nrelationship between the memory locations of the original data structure and the copied one cannot be \nexpressed using set compar\u00adison operators (like set equality or set inclusion). JDK Collections Library \nWe have used the tool to analyze most functions of the LinkedList and HashMap classes of JDK 5.0 [1]. \nThe LinkedList class implements a circular doubly-linked list and the HashMap class implements an array \nof disjoint singly-linked lists. These functions, listed in Table 3, include the ones used to add a single \nelement, add multiple elements and remove an element. We prove memory safety, data-structure invariants, \nand correct maintenance of the size .eld in all the examples (i.e., the size .eld corresponds to the \nnumber of elements in the collection). In addition, for HMPutAll we prove that the size of the resulting \nHashMap is greater or equal to the sizes of the original HashMaps, and less or equal to their sum. 7. \nRelated Work Combining Abstractions The seminal paper by Cousot and Cousot in [7] introduces different \nmethods for combining abstract domains including reduced prod\u00aduct, which can be used to explain our domain \nconstruction (see [9] for further elaboration on domain constructors). However, the prob\u00adlem of developing \nan effective procedure for computing abstract transformers for reduced products has been addressed only \nin spe\u00adci.c settings. Gulwani and Tiwari gave algorithms for constructing the transfer functions for \nreduced products for a special case of abstract domains (called logical abstract domains) with the further \nrestriction that the abstract domains being combined should be over convex theories with disjoint signatures \n[17]. Their methodology is not applicable in our setting since the abstract domains that we con\u00adsider \nin this paper, namely set domains and numerical domains, do not .t the required restrictions: the set \ndomain is not convex, and Table 3. Experimental results for the set cardinality benchmarks Category Program \nTime (secs) Over\u00adhead States String Buffer SBRemove 295.21 2.83 50,615 SBToString 79.53 3.15 10,176 Termination \nBubbleSort 3.57 0.54 886 Mark 2.44 3.02 1,530 Linked List Reverse 0.34 1.64 90 Filter 0.76 0.54 238 Merge \n1.08 1.88 341 MergeNoDups 4.06 2.53 1,838 Data Structure Copy AcyclicListCopy 0.39 1.44 74 CyclicListCopy \n4.54 1.20 155 TreeCopy 4.15 1.45 642 NaryTreeCopy 138.20 N/A 5,439 ListOfListsCopy 39.95 1.44 5,353 ListOfArraysCopy \n12.67 1.02 2,260 ArrayOfListsCopy 7.99 0.30 1,628 JDK Collections Library LLAdd 1.45 2.23 17 LLAddAll \n10.93 0.02 215 LLRemove 2.51 1.20 173 HMPut 9.45 1.02 3,132 HMPutAll 111.84 2.59 22,431 HMRemove 2.13 \n1.92 725 furthermore, the set domain and the numerical domain both share the cardinality function symbol. \nOur work thus extends the line of work on constructive synthesis of abstract transformers for reduced \nproduct domains (from the abstract transformers of individual do\u00admains) for an important class of domains. \nCombining Heap and Numerical Abstractions The idea to combine numeric and pointer analysis for establishing \nproperties of memory was pioneered by Alain Deutsch [10, 11]. Deutsch s abstraction deals with may-aliases \nin a rather precise way but loses most of the information when the program performs destructive memory \nupdates. In [19] a type and effect system is suggested for a variant of ML that allows to bound the size \nof memory used by the program with applications to embedded code. There, the type system allows verifying \nbounds on memory usage while our analysis can be used to infer the bound. Furthermore, their type system \nis for a func\u00adtional language while our analysis is appropriate for an imperative language with destructive \npointer updates. In [18] linear typing and linear programming based inference are used to statically \ninfer linear bounds on heap space usage of .rst-order functional programs running under a special memory \nmechanism. In contrast, our method handles imperative programs which use destructive updates. In [35] \nan algorithm for inferring sizes of singly-linked lists was presented. This algorithm uses the fact that \nthe number of uninter\u00adrupted list segments in singly-linked lists is bounded. This limits the applicability \nof the method for showing speci.c properties of singly-linked lists. Similar restrictions apply to [3, \n23]. A general method for combining numeric domains and canoni\u00adcal abstraction was presented in [14]. \nTheir method is orthogonal to ours, as it addresses the problem of abstracting values of numerical .elds. \nOn the other hand, our work is concerned with cardinalities of memory partitions. Combining the methods \ncan be very useful and is the subject of future work. Rugina [32] presents a static analysis that can \ninfer quantitative properties (namely height and skewness) of tree-like heaps. Rugina does not address \nthe issue of sizes of data structures and is limited to tree-like heaps. On the other hand, Rugina can \nhandle properties such as height, which are beyond the scope of this paper. In [5] a method is presented \nfor analyzing a memory allocator by interpreting memory segments as both raw buffers and struc\u00adtured \ndata. However, their method presents a limited way of treat\u00ading sizes of chunks of memory since they \nare limited to contiguous chunks of memory and cannot handle sizes of recursive data struc\u00adtures. In \n[15], a specialized canonical abstraction was applied to ana\u00adlyze properties of arrays. Arrays are partitioned \ninto the parts be\u00adfore, at, and after a given index. This gives a way to track sizes of speci.c partitions. \nHowever, it does so only in the special case of ar\u00adrays. Furthermore, it cannot track sizes of partitions \nother than the ones formed by index variables. Speci.cally, their method would not be able to handle \nexamples such as StringBuffer remove. Reducing Pointer to Integer Programs In [13, 3, 23] it was proposed \nto conduct pointer analysis in a pre\u00adpass and then to convert the program into an integer program to \nallow integer analysis to check the desired properties. This re\u00adduction based approach allows using different \ninteger analyzers on the resulting program. Furthermore, for proving simple prop\u00aderties of singly-linked \nlists it was shown in [3], that there is no loss of precision. However, it may lose precision in cases \nwhere the heap and numerics interact in complicated ways. Also, the re\u00adduction may be too expensive. \nOur transformers avoid these issues by iterating between the two abstractions and allowing information \n.ow in both directions. Furthermore, our framework allows for an arbitrary set domain (it is not restricted \nto domains that can rep\u00adresent only singly-linked lists). Finally, proving soundness in our case is simpler. \nDecision Procedures for Reasoning about Heap and Arithmetic One of the challenging problems in the area \nof theorem proving and decision procedures is to develop methods for reasoning about arithmetic and quanti.cation. \nIn [21] an algorithm for combining Boolean algebra and quanti\u00ad.er free Presburger arithmetic is presented. \nTheir approach presents a complete decision procedure for their speci.c combined do\u00admain. In contrast, \nour method supports set domains that go beyond Boolean algebra formulas and can thus express more complicated \ninvariants. More signi.cantly our approach provides an effective method for computing transformers for \nperforming abstract inter\u00adpretation, which their method does not. Fortunately, by careful de\u00adsign of \nthe interface between the abstract domains, we avoid solv\u00ading the complex constraints which their algorithm \nhandles. In [28] a logic based approach that involves providing an entail\u00adment procedure is presented. \nTheir logic allows for user-de.ned well-founded inductive predicates for expressing shape and size properties \nof data-structures. They can express invariants that in\u00advolve other numeric properties of data structures \nsuch as height of trees. However, their approach is limited to separation logic while ours can be used \nin a more general context. In addition their ap\u00adproach does not infer invariants, requiring a heavy annotation \nbur\u00adden, while our approach is based on abstract interpretation and can thus infer loop and recursive \ninvariants. Acknowledgements We would like to thank Nurit Dor, Denis Gopan, and Michal Segalov for reading \nan earlier draft of this paper. We thank De\u00adnis Gopan for his help with the implementation. Special thanks \nto Bruno Blanchet and the anonymous reviewers for their insightful comments and pointing of some errors \nand .xes in an earlier draft of this paper. References [1] Annotated outline of collections framework. \nSun Microsystems. Available at http://java.sun.com/j2se/1.5.0/docs/guide/collections/ reference.html. \n[2] R. Bagnara, P. M. Hill, and E. Zaffanella. The Parma Polyhedra Library: Toward a complete set of \nnumerical abstractions for the analysis and veri.cation of hardware and software systems. Science of \nComputer Programming, 2008. To appear. [3] A. Bouajjani, M. Bozga, P. Habermehl, R. Iosif, P. Moro, and \nT. Vojnar. Programs with lists are counter automata. In CAV, pages 517 531, 2006. [4] A. R. Bradley, \nZ. Manna, and H. B. Sipma. The polyranking principle. In ICALP, pages 1349 1361, 2005. [5] C. Calcagno, \nD. Distefano, P. W. O Hearn, and H. Yang. Beyond reachability: Shape abstraction in the presence of pointer \narithmetic. In SAS, pages 182 203, 2006. [6] P. Cousot and R. Cousot. Abstract interpretation: A uni.ed \nlattice model for static analysis of programs by construction or approximation of .xpoints. In POPL, \npages 238 252, 1977. [7] P. Cousot and R. Cousot. Systematic design of program analysis frameworks. In \nPOPL, pages 269 282, 1979. [8] P. Cousot and N. Halbwachs. Automatic discovery of linear restraints among \nvariables of a program. In POPL, pages 84 96, 1978. [9] A. Deutsch. On determining lifetime and aliasing \nof dynamically allocated data in higher-order functional speci.cations. In POPL, pages 157 168, 1990. \n[10] A. Deutsch. Operational Models of Programming Languages and Representations of Relations on Regular \nLanguages with Application to the Static Determination of Dynamic Aliasing Properties of Data. PhD thesis, \nLIX, The Comp. Sci. Lab of Ecole Polytechnique, 1992. \u00b4 [11] A. Deutsch. Interprocedural may-alias analysis \nfor pointers: Beyond k-limiting. In PLDI, pages 230 241, 1994. [12] D. Distefano, P. W. O Hearn, and \nH. Yang. A local shape analysis based on separation logic. In TACAS, pages 287 302, 2006. [13] N. Dor, \nM. Rodeh, and M. Sagiv. CSSV: towards a realistic tool for statically detecting all buffer over.ows in \nC. In PLDI, pages 155 167, 2003. [14] D. Gopan, F. DiMaio, N. Dor, T. W. Reps, and M. Sagiv. Numeric \ndomains with summarized dimensions. In TACAS, pages 512 529, 2004. [15] D. Gopan, T. Reps, and M. Sagiv. \nA framework for numeric analysis of array operations. In POPL, pages 338 350, 2005. [16] S. Gulwani, \nT. Lev-Ami, and M. Sagiv. A combination framework for tracking partition sizes. Technical Report MSR-TR-2008-158, \nMicrosoft Research, Oct. 2008. [17] S. Gulwani and A. Tiwari. Combining abstract interpreters. In PLDI, \npages 376 386, 2006. [18] M. Hofmann and S. Jost. Static prediction of heap space usage for .rst-order \nfunctional programs. In POPL, pages 185 197, 2003. [19] J. Hughes and L. Pareto. Recursion and dynamic \ndata-structures in bounded space: Towards embedded ML programming. In ICFP, pages 70 81, 1999. [20] M. \nKarr. Af.ne relationships among variables of a program. Acta Inf., 6:133 151, 1976. [21] V. Kuncak and \nM. C. Rinard. Towards ef.cient satis.ability checking for boolean algebra with presburger arithmetic. \nIn CADE, pages 215 230, 2007. [22] T. Lev-Ami and M. Sagiv. TVLA: A system for implementing static analyses. \nIn SAS, pages 280 301, 2000. [23] S. Magill, J. Berdine, E. M. Clarke, and B. Cook. Arithmetic strengthening \nfor shape analysis. In SAS, pages 419 436, 2007. [24] R. Manevich, M. Sagiv, G. Ramalingam, and J. Field. \nPartially disjunctive heap abstraction. In SAS, pages 265 279, 2004. [25] R. Manevich, E. Yahav, G. Ramalingam, \nand M. Sagiv. Predicate abstraction and canonical abstraction for singly-linked lists. In VMCAI, pages \n181 198, 2005. [26] A. Min\u00b4e. The octagon abstract domain. In WCRE, pages 310 319, 2001. [27] G. Nelson \nand D. Oppen. Fast decision procedures based on congruence closure. JACM, 27(2):356 364, Apr. 1980. [28] \nH. H. Nguyen, C. David, S. Qin, and W.-N. Chin. Automated veri.cation of shape and size properties via \nseparation logic. In VMCAI, pages 251 266, 2007. [29] A. Podelski and A. Rybalchenko. Transition invariants. \nIn LICS, pages 32 41, 2004. [30] A. Podelski and T. Wies. Boolean heaps. In SAS, pages 268 283, 2005. \n[31] J. C. Reynolds. Separation logic: A logic for shared mutable data structures. In LICS, pages 55 \n74, 2002. [32] R. Rugina. Quantitative shape analysis. In SAS, pages 228 245, 2004. [33] M. Sagiv, T. \nW. Reps, and R. Wilhelm. Parametric shape analysis via 3-valued logic. ACM TOPLAS, 24(3):217 298, 2002. \n[34] A. Turing. Checking a large routine. In The early British computer conferences, pages 70 72. MIT \nPress, Cambridge, MA, USA, 1989. [35] T. Yavuz-Kahveci and T. Bultan. Automated veri.cation of concurrent \nlinked lists with counters. In SAS, pages 69 84, 2002.    \n\t\t\t", "proc_id": "1480881", "abstract": "<p>We describe an abstract interpretation based framework for proving relationships between sizes of memory partitions. Instances of this framework can prove traditional properties such as memory safety and program termination but can also establish upper bounds on usage of dynamically allocated memory. Our framework also stands out in its ability to prove properties of programs manipulating both heap and arrays which is considered a difficult task. Technically, we define an abstract domain that is parameterized by an abstract domain for tracking memory partitions (sets of memory locations) and by a numerical abstract domain for tracking relationships between cardinalities of the partitions. We describe algorithms to construct the transfer functions for the abstract domain in terms of the corresponding transfer functions of the parameterized abstract domains. A prototype of the framework was implemented and used to prove interesting properties of realistic programs, including programs that could not have been automatically analyzed before.</p>", "authors": [{"name": "Sumit Gulwani", "author_profile_id": "81100315615", "affiliation": "Microsoft Research, Redmond, CA, USA", "person_id": "P1300981", "email_address": "", "orcid_id": ""}, {"name": "Tal Lev-Ami", "author_profile_id": "81100364974", "affiliation": "Tel-Aviv University, Tel-Aviv, Israel", "person_id": "P1300982", "email_address": "", "orcid_id": ""}, {"name": "Mooly Sagiv", "author_profile_id": "81100150928", "affiliation": "Tel-Aviv University, Tel-Aviv, Israel", "person_id": "P1300983", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480912", "year": "2009", "article_id": "1480912", "conference": "POPL", "title": "A combination framework for tracking partition sizes", "url": "http://dl.acm.org/citation.cfm?id=1480912"}