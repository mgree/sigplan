{"article_publication_date": "01-21-2009", "fulltext": "\n The Semantics of x86-CC Multiprocessor Machine Code Susmit Sarkar1 Peter Sewell1 Francesco Zappa Nardelli2 \nScott Owens1 Tom Ridge1 Thomas Braibant2 Magnus O. Myreen1 Jade Alglave2 1University of Cambridge 2INRIA \nhttp://www.cl.cam.ac.uk/users/pes20/weakmemory Abstract Multiprocessors are now dominant, but real multiprocessors \ndonotprovidethesequentiallyconsistent memorythatis as\u00adsumed by most work on semantics and veri.cation. \nInstead, they have subtle relaxed(or weak) memory models, usually described only in ambiguous prose, \nleading to widespread confusion. We develop a rigorous and accurate semantics for x86 multiprocessor \nprograms, from instruction decoding to re\u00adlaxed memory model, mechanised in HOL. We test the se\u00admantics \nagainst actualprocessors and thevendorlitmus-test examples, and give an equivalent abstract-machine charac\u00adterisation \nof our axiomatic memory model. For programs that are (in some precise sense) data-race free, we prove \nin HOL that their behaviour is sequentially consistent. We also contrast the x86 model with some aspects \nof Power and ARM behaviour. Thisprovides a solidintuitionforlow-levelprogramming, and asoundfoundationforfuturework \nonveri.cation,static analysis, and compilation of low-level concurrent code. Categories and Subject Descriptors \nC.1.2 [Multiple Data Stream Architectures (Multiprocessors)]: Parallel pro\u00adcessors; D.1.3 [Concurrent \nProgramming]: Parallel pro\u00adgramming; F.3.1 [Specifying and Verifying and Reasoning about Programs] General \nTerms Documentation,Reliability,Standardiza\u00adtion, Theory, Veri.cation Keywords Relaxed Memory Models, \nSemantics 1. Introduction Problem Multiprocessor machines, withmanyprocessors acting on a shared memory, \nhave been developed since the 1960s, but have suddenly become dominant in the last few years:laptops,desktops \nand serversnowroutinelyhave2,4, or 16 cores, and the trend to even more concurrency is set to continue. \nMeanwhile, the di.culty of programming con\u00adcurrent systems has given rise to extensive research over \nthe last40years onsemantics,programlogics, andsoforth.This work has almost always assumed that concurrent \nprocesses share a sequentially consistent memory[23],butinfact real multiprocessors typically exhibit \nrelaxed, or weak, mem\u00adory models. Internally, they use sophisticated techniques to Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage achieve high performance: \nhierarchies of local cache, write bu.ers, speculative execution, etc.The visible manifestation oftheseoptimisations,atthe \nassemblylanguagelevel,isthat individual reads and writes to memory may be reordered in surprising ways. \nFor example, consider the following x86 program. proc:0 proc:1 MOV [100]. $1 MOV [200]. $1 MOV EAX. [100] \nMOV ECX. [200] MOV EBX. [200] MOV EDX. [100] This consists of two straight-line programs running in \npar\u00adallel on two processors, proc:0 and proc:1. The instruction MOV[100]. $1 writes value 1 to memory \naddress 100; the instruction MOV EAX. [100] reads a value from memory address 100intoregisterEAX; and \nso on.Thereisarare,but possible, counter-intuitive execution, from an initial state with register and \nmemory values all 0, to a .nal state with proc:0EAX andproc:1ECXboth1(soeachprocessorhas seen its own \nwrite), but the proc:0 EBX and proc:1 EDX both 0,so eachprocessorhas seenthe valuethattherespec\u00adtive \nmemory location had before the other processor wrote it. In other words, proc:0 and proc:1 saw the writes \nto 100 and 200 in opposite orders to each other. This means that the read and write events cannot be \nconsistently embedded in a single linear order: x86 multi\u00adprocessors do not have a sequentially consistent \nsemantics, andlow-levelprogrammerscannotreasoninterms ofsimple notions of global time or causality. To \ncompound this di.culty, the reordering guarantees that are provided by multiprocessors are often poorly \nspec\u00adi.ed, usually only in natural-language documentation that leaveskeyquestions ambiguous.Thishasledto,forexample, \nrealuncertaintyaboutthecorrectness ofOS spinlockimple\u00admentations[3].Thereisaclearneedforprecisesemantics \nof real-world multiprocessors, both to inform the intuition of low-level programmers, and to provide \na sound foundation for rigorous reasoning about multiprocessor programs. Contribution Inthispaper wegive \na rigorous semantics for x86 multiprocessor programs, with an accurate relaxed memory model. Section2develops \nan axiomaticde.nitionofthememory model. Given a collection of memory and register read and write events, \nwe de.ne a valid execution to be a collection oflinear orders, oneperprocessor,oftheeventsthatitsees, \nsubject to a number of axioms constraining the allowable reorderings. We believe this to be the .rst \nsuch model for x86, though there is an extensive literature on models for and thatcopiesbearthisnoticeand \nthefull citationonthe .rstpage. other processors, discussed in Section 8. To copy otherwise, to republish, \nto post on servers or to redistribute Tosupportreasoningaboutprograms,thememory model to lists, requires \nprior speci.c permission and/or a fee. mustbeintegrated with a semanticsfor machineinstructions POPL \n09, January 18 24, 2009, Savannah, Georgia, USA. (aproblem whichhas usuallybeen neglectedinthe memory \nCopyright 2009ACM978-1-60558-379-2/09/01...$5.00 . model literature). In Section 3 we describe a semantics \nfor core x86 instructions. We parameterise the instruction semanticsover aninterfaceofcombinators(analogoustoa \nmonad),soasinglede.nition,with all theintricacies of .ag\u00adsetting, addressing modes,etc.,canbeused to \ngenerateboth an event-based semantics integrated with the \u00a72 memory model, and astate-based semanticsforsequentialprograms. \nWe also build an instruction decoding function, directly fromthevendordocumentation,tosupport reasoning \nabout concrete machine code. To develop con.dence in the semantics, we test it, with three tools described \nin Section 4. The .rst is an implemen\u00adtationofthe axiomaticmodel,calculating anddisplayingthe sets of \nvalid executions for small programs. This has been invaluable in building intuition for the consequences \nof the axioms. The second and third tools test the semantics em\u00adpiricallyagainstthebehaviourof actualhardware:focussing \non the memory model and the instruction semantics respec\u00adtively; the latter uses the sequential state-based \nsemantics. Anunderstandingofthememorymodeliscriticalforlow\u00adlevel multiprocessor programming, e.g. for \nimplementations of locks, software transactional memory, non-locking data\u00adstructures, garbage collectors, \nand compilers. For higher\u00adlevelprogramsthat arerace-free(orproperly synchronised) one would hope that \nit is sound to reason in terms of a sequentially consistent model. In Section 5 we prove a theorem to \nthis e.ect, for an x86-speci.c notion of race. The axiomatic style of de.nition is relatively easy to \nre\u00adlate to the informal documentation, and a good basis for some metatheory,butit canbehard to see the \nconsequences of the axioms with their global-time perspective. We there\u00adfore also develop an equivalent \noperational model, in Sec\u00adtion6: anabstractmachineofqueuesandbu.erswith step\u00adwisebehaviour(atpresent \nwithoutlockedinstructions). InSection7 wecontrastthex86behaviourwith some as\u00adpectsofPower andARMbehaviour,withtheirverydi.erent \nmemory models, and we conclude in Section 9. Our de.ni\u00adtions andproofs,exceptthe \u00a76proofs, aremechanisedinthe \nHOLproof assistant[21].Forlackofspace only key extracts areincludedhere,butthefulldetails arefreely available \non\u00adline[6],togetherwith additionaldiscussion oftheexamples, our experimental data, and some of our toolset. \n2. The x86-CC Axiomatic Memory Model 2.1 Scope, Criteria, and Sources The intended scope of our semantics \nis typical user code: using coherent write-back memory, without exceptions, mis\u00adaligned accesses, non-temporal \noperations(e.g.MOVNTI), self-modifying code, or page-table changes. Within that, we deal with a reasonable \nrange of instructions, as we describe in Section 3, and there should be no fundamental di.culty in covering \nthe rest of the instruction set. Within this scope, the semantics should be in some sense accurate. Processor \nvendors document architectures , such asIntel sIntel 64 andIA-32[5] andAMD sAMD64[4](we refer to the \ncommon core of these as x86 ). These are de\u00adscriptions of the behaviour that programmers may rely on \nfrom a class ofpast andpresent(andperhapsfuture) pro\u00adcessor families, each of which may contain many \nparticular devices. They tend to vary slowly, and to be loose speci.ca\u00adtions of the device behaviour, \nin order to admit more rapid variationinhowthedevices are actually implemented.Such variations might \nwell be observable by assembly programs, butsolong asthey arewithinthe architecture-allowablebe\u00adhaviour(anddevelopershaveinfactprogrammedto \nthat), they should be benign. Ideally, we would aim for our se\u00admanticstobesound with respecttothese architectures, \nand hence with respect to a broad range of devices. In practice, however, the architectures are described \nonly in informal prose and pseudocode, with a mixture of concepts from dif\u00adferentlevels of abstraction(mixingtheprogrammermodel \nand microarchitectural notions). As we shall see, they leave some key issues ambiguous. We can therefore \nonly aim to be consistent with the published documents and with the behaviour of some sample devices. \nIn the other direction, the semantics should not be substantially looser than the architecture, or it \nmight be too weak to verify programs. In addition to the documents cited above, our seman\u00adtics is based \non the Intel 64 Architecture Memory Ordering White Paper (IWP)[22],whichstates8 one-sentenceprin\u00adciples, \nillustrated by 10 small litmus-test example programs (whichwelabeliwpNN), andtheAMDdocumentation[4, vol.2,p.164.],whichgivessimilarprose \nand10largelyidenti\u00adcalexamples(which welabel amdNN).TheIWP examples have been added to recent versions \nof the Intel SDM [5, vol.3A, \u00a77.2.3], unchanged except that the proc:1 part of iwp2.3.b was removed. \nWe have bene.ted also from a num\u00adber of very helpful conversations with Intel sta., though of course \nany errors remain ours. The semantics represents our best understanding of the x86 architecture1; it \nis not a nor\u00admative de.nition from any vendor. 2.2 Basic Types TheexampleinSection1 showsthatwecannotusea \nsimple interleaving semantics, with a single transition relation over aglobal memory state,becausedi.erentprocessors \nmay see writesindi.erent orders.Instead,we axiomatisethepossible ordersinwhich eachprocessorseestheevents \nofacomplete execution. The semantics must be at the level of individual reads and writes,notinstructions \nasinglex86instruction, such asINC[100](whichincrementsmemorylocation 100) may comprise multiple individual \nreads and writes, and it is these that are the primitive atomic events of the semantics. For example, \ngiven the program inc-inc proc:0 proc:1 poi:0 INC [100] INC [100] with initial state [100]=0, it is \npossible to reach a .nal memory state[100]=1,after anexecutioninwhichbothINC instructions read 0 and \nwrote 1. Individual aligned memory accesses are guaranteed atomic, however. Wealsoincludeexpliciteventsforreads \nand writesofpro\u00adcessorregisters(incontrasttomostpreviouswork onrelaxed memory) sothatinformation .owdependenciesthroughreg\u00adisterscanbecalculatedinsteadof \nassumed.Wetake accesses tothe 32-bit registersand the1-bit status.agstobeatomic (it should be routine \nalso to cover 64, 16, and 8-bit opera\u00adtions). The registers are as follows: Xreg = EAX | EBX | ECX | \nEDX | ESP | EBP | ESI | EDI Xe.ags = X CF | X PF | X AF | X ZF | X SF | X OF reg = Reg32 of Xreg | Reg1 \nof Xe.ags | RegEIP We take types address and value tobothbethe 32-bit words, and take a location to be \neither a memory address or a register of a particular processor: location = Location reg of proc reg \n1 But see the addendum at the end of the paper, added in press. | Location mem of address These constructors \nare curried, so Location reg : proc . reg . location. To identify an instance of an instruction in an \nexecution, we specify its processor and its index in program order(i.e.,intheprogramwith anunfolding \nofall branches): iiid =.[proc : proc; program order index : num]D An actioniseitheraread orwriteofavalueatsomelocation: \ndirn = R | W action = Access of dirn location value Finally, an event has an instruction instance id, \nan event id (of typeeiid = num, unique per iiid), andan action: event =.[eiid : eiid; iiid : iiid; action \n: action]D The semantics of an instruction must also record any intra-instruction causality relationships \namong its events, e.g.,for INC[100],betweentheread ofavaluefrom [100] and the write of an incremented \nvalue. Furthermore, certain x86instructionscanbepre.xed with a LOCK byte,which guaranteesthat all the \naccesses oftheinstructiontakeplace atomically.Adding LOCKpre.xestotheprevious example: ensures that \nthe only possible .nal state has [100]=2. We therefore have to record which events belong to the same \nlocked instruction. Collecting this together, we de.ne an event structure E to comprise a set of processors, \na set of events, an intra\u00adinstructioncausality relation, and apartialequivalencerela\u00adtion(PER) capturing \nsets ofeventswhich must occur atom\u00adically: event structure =.[procs : proc set; events : event set; intra \n causality : event reln; atomicity : event set set]D subject to various well-formedness conditions which \nwe omit here. Note that, while these event structures are loosely inspiredbythoseofWinskel[30],they arenotexactlythe \nsame structure. The overall semantics will be factored into two parts: the instruction semantics de.nes, \nfor any program, a set of candidate event structures, and the axiomatic memory model de.nes, for each \nevent structure, its valid executions (ifany). For example, given the program with two unlocked INC s \nabove, one possible event structure is below. eiid:0 (of INC [100]) eiid:2 (of INC [100]) iiid: (proc:0;po:0) \niiid: (proc:1;po:0) R [100]=0 R [100]=0 iico iico eiid:1 (of INC [100]) eiid:3 (of INC [100]) iiid: (proc:0;po:0) \niiid: (proc:1;po:0) W [100]=1 W [100]=1 inc-inc: (event structure 1) Notetheintra-instructioncausality(iico)edges,andthecon\u00adcretevaluesintheevents.Herethe \natomicityPERisempty, whereas, for the locked INC example, there would be two atomicity equivalence classes, \ncontaining the events of the two instructions respectively. The semantics also includes a read and a \nwrite of the instruction pointer (or program counter)EIP, and writesofthestatus.ags,but wesuppress both \nin most diagrams for clarity. 2.3 View Orders Given an event structure, a candidate execution witness \nconsistsof aninitialstateconstraint and aprocessor-indexed family of view orders, together with other \ndata that we explain in the following subsections. type abbrev state constraint = location . value option \ntype abbrev view orders = proc . event reln execution witness = .[initial state : state constraint; vo \n: view orders; write serialization : event reln; lock serialization : event reln; rfmap : event reln]D \n Awell-formed view orderforprocessor pisalinear orderover all of its events together with all the memory \nwrite events of other processors (we write viewed events Ep for that union). The rest of this section \nis devoted to axiomatising when an execution witness is valid. For example, one valid execution for the \nprevious event structure is shown below, with the two view orders labelled vo:0 and vo:1 respectively \n(we return to the edge labelled P6 later).  2.4 Preserved Program Order Five oftheeightIWP[22] principles(whichwelabel \nP1 8)have a similar, and relatively straightforward, character: explicit assertions about what reorderings \nare or are not allowed. To make this paper self-contained we recall them here, together with their illustrative \nexamples, before for\u00admalising them; we see how this de.nition is used in \u00a72.7. P1. Loads are not reordered \nwith other loads. P2. Stores are not reordered with other stores. These are illustrated with a single \nexample, which, instan\u00adtiating symbolic registers and addresses to give a concrete program, and labelling \nwith program order indices po:N, is: 1.Iftheinitialstateis0everywhere(whichwe assumein all examples unless \notherwise stated), then in the .nal state it is required that if 1:EAX=1 then 1:EBX=1. Hence, the two \nproc:0 stores must have been seen by proc:1 in proc:0 s program order, and the two proc:1 loads must \nhave been performed in its program order. iwp2.1/amd1 proc:0 proc:1 po:0 po:1 MOV [100].$1 MOV [200].$1 \nMOV EAX.[200] MOV EBX.[100] Required: (1:EAX=1).(1:EBX=1) Thisstorestotwolocations, 100 and200, onprocessor0, \nand loads from those locations, in the other order, on processor  P3. Stores are not reordered with \nolder loads. iwp2.2/amd2 proc:0 proc:1 po:0 MOV EAX.[100] MOV EBX.[200] po:1 MOV [200].$1 MOV [100].$1 \nForbidden: 0:EAX=1 . 1:EBX=1 Thisisvery similartothepreviousexample: onprocessor0, thestoretolocation \n200cannotbereorderedbeforetheload from location 100, and, on processor 1, the write of location 100 cannot \nbe reordered before the read of location 200. P4. Loads may be reordered with older stores to different \nlocations but not with older stores to the same location. There are two examples here. The .rst is described \nas illustrating the case in which a load may be reordered with an older store, i.e. if the store and \nload are to di.erent non-overlapping locations . ipw2.3a/amd4 proc:0 proc:1 poi:0 MOV [100].$1 MOV [200].$1 \npoi:1 MOV EAX.[200] MOV EBX.[100] Allowed: 0:EAX=0 . 1:EBX=0 One can imagine a possible execution in \nwhich the proc:0 load from 200 is reordered before the proc:0 store to 100. Interestingly, however, the \nreordering of loads with older stores is not essential for this test to give the speci.ed outcome: in \nFig. 1 we show a valid execution in which each processor sees its own events in program order, and then \n.nally the memory write of the other processor. Below we give a newtest(n1)thatdoes requirethis reordering. \nproc:0 proc:1 proc:2 MOV [100].$2 MOV EAX.[200] MOV [200].$1 MOV [100].$1 MOV EBX.[100] MOV ECX.[100] \nAllowed: 0:EAX=0 . 2:EBX=1 . 2:ECX=2 (Consider the proc:0view order. By P1 the W [200]1 is be\u00adfore the \nW [100]1, andbyP6 below and theproc:2 observa\u00adtions, that must be before the W [100] 2. Then theR [200]0 \ncan only be inserted at the start, otherwise the rfmap con\u00additions below are violated.) Thesecond exampleforP4 \nshowsthat loadsmay notbe reordered with a prior store to the same location . iwp2.3.b proc:0 proc:1 po:0 \npo:1 MOV [100].$1 MOV EAX.[100] MOV [200].$1 MOV EBX.[200] Required: 0:EAX=1 . 1:EBX=1 P8. Loads and \nstores are not reordered with locked instructions. Herethere aretwoexamples,forloads and vo:0 eiid:0 \n(of MOV [100].$1) iiid: (proc:0;po:0) W [100]=1 eiid:1 (of MOV EAX.[200]) iiid: (proc:0;po:1) R [200]=0 \n vo:0 vo:1 ipw2.3a/amd4: Litmus test (event structure 1) Figure 1. An iwp2.3.a/amd4 execution without \nreordering stores respectively. They use an XCHG instruction, which exchanges two values and has an implicit \nLOCK pre.x.  Interestingly, it appears that P8 may be redundant. Ac\u00adcording totheInteldocumentation[5, \nvol.3A, \u00a77.1.2.2], the LOCK pre.x can only be prepended to particular instruc\u00adtions, all of which both \nread and write some memory lo\u00adcation. As those pairs of a read and write are atomic, no eventfrom any \notherinstructioninstancecancomebetween them.Hence, any third read orwriteispreventedfrombeing reordered \nwith the locked pair by P1. Formalising P1 4,8 Wecapturethe aboveprinciplesby identifyingthepairs ofevents(e1, \ne2)inprogram order,from an event structure E, that must not be reordered:  Figure 2. Tests iwp2.6, amd6, \niwp2.7/amd7, n2, and n3 preserved program order E = {(e1, e2)| (e1, e2). (po strict E). ((.pr.(loc e1 \n=loc e2). (loc e1 = Some (Location reg pr))). (mem load e1 . mem load e2). (mem store e1 . mem store \ne2). (mem load e1 . mem store e2). (mem store e1 . mem load e2 . (loc e1 = loc e2)). ((mem load e1 . \nmem store e1). locked Ee2). (locked Ee1 . (mem load e2 . mem store e2)))} Here po strict relates two \nevents on the same processor if the .rst strictly precedes the second in program order. The various auxiliaryfunctionsused \nshouldbeclear; wereferthe reader to the HOL for their formal de.nitions. We also have toconstrainregisterread \nand writeevents.The.rstdisjunct prevents reordering of reads or writes to the same register, which seems \nthe most conservative reasonable choice.  2.5 Reads-from Information Flow Our event structures do not \nconstrain the values of memory or register read events. Intuitively, one would expect the value read \nto be that of the most recent write to the same location, or that of the initial state if there is none \n where recent is with respect to the relevant view order. It turns out that to capture the appropriate \nnotion of causality (c.f. \u00a72.7 below) we need to consider not just the values but the intensional property \nof which write each read reads from. We de.ne the candidate reads-from maps for an event structure E, \neach rfmap identifying, for some of the read events, a write event to the same location with the same \nvalue. Other read events are taken to read from the initial state. reads from map candidates E rfmap \n= .(ew, er). rfmap. er . E.events . ew . E.events . .lv.(er.action = Access R lv). (ew.action = Access \nW lv) Two conditions check that these are consistent with a view order andinitialstate,ensuringthatthere \narenointervening writestothesamelocationbetween an(ew, er)reads-from pair, or before an er that reads \nfrom the initial state: check rfmap written E vo rfmap = .p . (E.procs). .(ew,er). (rfmap| ). (viewed \nevents Ep) .ew ' . (writes E). '' ' \u00ac(ew = ew ). (ew, ew ). (vo p). (ew ,er). (vo p) =.\u00ac(loc ew =loc \new ' ) check rfmap initial E vo rfmap initial state = .p . (E.procs). .er . (((reads E)\\ (range rfmap)) \nn viewed events Ep). .lv.(er.action = Access R lv). (initial state l = Some v). .ew ' . writes E. (ew \n' , er). (vo p)=.\u00ac(loc ew ' =loc er) 2.6 Total Store and Lock Orders The x86 has two global ordering \nproperties, P6 and P7. P6. In a multiprocessor system, stores to the same location have a total order. \nTest iwp2.6, in Fig. 2, illustrates the fact that writes by two di.erent processors to the same location \nmust be seen (by all processors) in the same order. This complements P2, which required writes by a single \nprocessor to any locations to be seen (by all processors) in program order. However, in the remaining \npossibility, of writes by two di.erent processors to two di.erent locations, these writes can be seen \nin di.erent orders. This is illustrated by the example of Section 1 (which is Test iwp2.4/amd9) in the \nspecial case where the writing and observing processors are the same, and by Test amd6 in Fig. 2 (essentially \nBoehm andAdve sIRIW[13]),inthespecialcasewherethey are di.erent. We formalise this by de.ning the candidate \nper\u00adlocation write serialisations: write serialization candidates E cand = (.(e1,e2). cand. .l.e1 . (get \nl stores El). e2 . (get l stores El)). (.l. strict linear order( cand|) (get l stores El ) (get l stores \nEl)) where get l stores El gives the memory write events to location l (and is emptyif l is not a memory \nlocation), and strict linear order RA i. R is a strict linear order over A. P7. In a multiprocessor system, \nlocked instructions have a total order. This is illustrated by Test iwp2.7/amd7, in Fig. 2, in which \nproc:2 and proc:3 have to see the two locked XCHG instructions in the same order. It is a property of \ninstruc\u00adtions, not events, so we formalise it by de.ning the candi\u00addate orders based on arbitrary linearisations \nof the locked instructions, projected down onto their events. lock serialization candidates E = let lin \nec = strict linearisations E.atomicity in {{(e1, e2)|.(es1, es2). lin.e1 . es1 . e2 . es2} | lin . lin \nec} The following condition checks that locked instructions re\u00adally are atomic, i.e. that there are no \nintervening events within each in any view order. check atomicity E vo = .p . (E.procs)..es . (E.atomicity). \n.e1 e2 . es.(e1, e2). (vo p)=. .e.(e1, e). (vo p). (e, e2). (vo p)=. e . es Thedocumentationissilent \nonthequestionofwhethera locked instruction and a write, on two di.erent processors, can be seen elsewhere \nin di.erent orders, as illustrated in Test n3 of Fig. 2, and we have received con.icting informal opinions.Wetherefore \noptforthemoreconservative(looser) alternative, permitting it. 2.7 Causality Treating causality correctly \nis the key issue in de.ning the semantics: without some causal consistency constraint, the semantics \nwould be much too liberal, with the view orders of di.erent processors allowed to vary wildly. However, \nthe prose vendor documentation is particularly ambiguous on this point. We have([22]): P5. In a multiprocessor \nsystem, memory order\u00ad ing obeys causality (memory ordering respects transitive visibility). and([4, vol.2,p.166]): \nDependent stores between di.erent processors appear to occur in program order [...] A globally consistent \nordering is maintained for such stores. but what causality , transitive visibility , or dependent stores \nmean is, a priori, unclear. Test iwp2.5/amd8 below shows transitivity in one speci.c case, from a reads-from \nrelationship to a preserved-program-order relationship. proc:0 proc:1 proc:2 MOV [100].$1 MOV EAX.[100] \nMOV [200].$1 MOV EBX.[200] MOV ECX.[100] Required: (1:EAX=1 . 2:EBX=1).(2:ECX=1) After much discussion, \nwe believe that x86 causality is also transitive through the write serialisation and lock serialisa\u00adtion \nrelations of \u00a72.6. Test n2 of Fig. 2 illustrates the for\u00admer: transitivity through preserved program \norder of the proc:0 andproc:1 events and thewriteserialisationfor[100] (which has W [100] 1 before W \n[100] 2 by the proc:2 ob\u00adservations). We also include the intra-instruction causality relation, e.g. \nto include the edge from an R [100]v to a W [100](v +1) of anINC[100]instruction,theintensional reads-from \ninformation .ow of \u00a72.5, and the preserved pro\u00adgram order of \u00a72.4. We propose the following de.nition \nof causality, for event structure E and execution witness X: happens before EX = E.intra causality . \n(preserved program order E). X.write serialization . X.lock serialization . X.rfmap This appears to \nmatch the vendors intentions. We require thatall view orders areconsistentwithhappens-before(im\u00adplicitly \ntransitively closed in the acyclic check): check causality E vo (happens before EX)= .p . (E. procs). \nacyclic((strict(vo p)). (happens before EX)) Note that there is a single happens-before relation which \nincludesthepreservedprogram orderedgesofallprocessors, and it may constrain events in the view order \nof one pro\u00adcessor via a transitive path through other processor s read events, which do not occur in \nthat view order. Models of architectures with weaker orders sometimes involvevisibilityof otherprocessors \nreads[7,11],butthis seemstobeunnecessaryforthefragment ofx86weconsider. Other models have sometimes also \nused the dual of our reads-from edges (e.g. [9]): suppose there is a reads-from edge from ew to er, and \nthere is some later (in the write serialisation order) ew ' to the same location, then one could think \nof a from-read edge from er to ew ' (with an eye to the cache coherency protocol of some implementation, \nin which cache-line ownership is transferred in a linear order). However, adding such edges to happens-before \nis inconsistent with the iwp2.4/amd9 test in \u00a71.  2.8 Valid Executions Finally, we can collect together \nthese conditions, de.ning the valid execution witnesses X for an event structure E: valid execution EX \n= view orders well formed EX.vo . X.write serialization . write serialization candidates E . X.lock \nserialization . lock serialization candidates E . X.rfmap . reads from map candidates E . check causality \nEX.vo(happens before EX). check rfmap written EX.vo X.rfmap . check rfmap initial EX.vo X.rfmap X.initial \nstate . check atomicity EX.vo We call this memory model x86 causal consistency, or x86-CC forshort.Itgivesthe \ncorrect resultsfor all thetests that we have seen, and is, to the best of our knowledge, consistent with \nall the published architecture documents. For.nitevalidexecutionsthereis anunambiguousnotion of .nal \nstate, with the .nal state for each memory location determinedbythelastwriteinitswriteserialisation, \nandthe .nal state for each register determined by the last write in the relevant view order. Note also \nthat, in a valid execution, the rfmap, write serialization, and lock serialization are uniquely determined \nby the view orders.  2.9 Nice Executions The axiomatic semantics was de.ned conservatively, taking care \nnot to impose restrictions absent from the documen\u00adtation. For example, register reads and writes on \ndi.erent registers can be arbitrarily reordered, and also reordered ar\u00adbitrarily with memory reads and \nwrites as long as the intra\u00adinstruction causality is respected. However, we can prove that some of this \nreordering is not observable to the pro\u00adgrammer, showing that the architecture is tighter than a naive \nreading would suggest, and providing a more conve\u00adnient model for future software veri.cation. One cannot \nrequire that all events of a processor are always seen by itself in an order consistent with program \norder, as Test n1 of \u00a72.4 shows that read speculation is observable, but one can require all events except \nmemory writes to be observed by the issuing processor in an order consistent with program order. nice \nexecution EX = .p . (E.procs). (po strict E)| . (X.vo p) (viewed events Ep \\ mem store) Theorem 1 (Validexecutions \ncan, w.l.g., be nice). .EX.(well formed event structure E . valid execution EX)=. '' ' .X . valid execution \nEX . nice execution EX . (X ' [vo :=(.p.{})]D = X [vo :=(.p.{})]D) HOL proof outline: For each processor, \nwe construct a new view order, which preserves the order of memory events and locked events, and gathers \nregister events into program order. The new view order is constructed inductively. At stage n, all register \nevents or local memory reads with program order n or less are ordered. Care must be taken to ensure that \nany local or foreign writes that are not compelled to appear at any particular stage appear somewhere \nin the new view order. All clauses of valid\u00adexecution are checked inductively; to check compatibility \nwith happens-before it su.ces to ensure there are no happens-before reverse edges at each stage. 2.10 \nInstruction Pointer Events, Branches, and Speculation The semantics deals smoothly with control .ow instructions \n(jumps, conditional branches, call, andreturn) without any special machinery. The axiomatic model treats \nthe instruc\u00adtionpointer(EIP) like any otherregister,whiletheinstruc\u00adtion semantics for a typical instruction \ngives event struc\u00adtures with an EIP read and a write of a suitably incre\u00admented value. These are linked \nby the intra-causality re\u00adlation,but(exceptfor CALL,RET,etc.) areunrelatedto other events of the instruction. \nA program-semantics con\u00addition ensures that the values of any EIP reads of an in\u00adstruction match its \naddress. The x86 allows very little local reordering(preserved program order is rather strong), but this \npermits a load to be reordered before a store to a dif\u00adferent address even across a branch, which we \nbelieve to be accurate(thedocumentationisunclear onthispoint). 2.11 Alignment The olderIntel andAMDdocuments \nonly discussprograms that do not make unaligned accesses, and for the moment that assumptionisbuiltinto \nourmodel.Butthismeansthat onecannotreasonatallaboutincorrect ormaliciouscode,so a more complete(butloose) \nspeci.cationishighlydesirable. We believe that it would be sound w.r.t. current devices to treatunaligned \naccesses as anunordered setofbyteaccesses, and it would be straightforward to add this to our model. \nThe currentIntelSDM[5, vol.3A, \u00a77.1.1] appears to state that, on P6 or later processors, unaligned 16-, \n32-, and 64\u00adbitaccesseswithinacacheline areatomic,butalso[\u00a77.2.3.1] that unaligned instructions may be \nimplemented with mul\u00adtiple accesses. The documents are also silent about aligned accesses to di.erent \naddresseswithinacacheline.Itmaybethatcurrent devices actually provide strong ordering for such accesses, \nand exposing this would permit algorithms to save the high cost oflockedinstructionsinsomecircumstances.It \ncouldbe modelledby taking writeserialisation ordersper(minimal\u00adsized) cache line, rather than per location. \n 2.12 Fences The x86 also includes fence instructions, or memory bar\u00adriers, LFENCE, SFENCE, and MFENCE. \nFor the co\u00adherent write-back fragment that we consider, without non\u00adtemporal operations,weunderstand \nthe .rsttwotobe(per\u00adhaps costly) no-ops. For MFENCE, the documentation is less clear, and so we did not \ninclude it in our HOL model. IWP [22] does not mention it, while the Intel SDM [5, vol.2A,p3-624;vol.3A,\u00a77.2.5]is \nambiguous(thetext couldbe read as asserting that MFENCEs ofdi.erentprocessors are globally serialised).The \nmost conservative(weakest)plausi\u00adble semantics is that an MFENCE simply ensuresthatpro\u00adgram orderispreserved \naroundit,preventing thereordering ofaloadbeforeastorethatwesawinTestiwp2.3.a/amd4of \u00a72.4.Test amd5(likeiwp2.3.a/amd4but \nwith an MFENCE after each store) con.rms this holds on AMD64, and infor\u00admal discussion suggests it also \ndoes on Intel 64/IA-32. It would be easy to add this to the model, strengthening the preserved program \norder de.nition of \u00a72.4. AMD64[4] includes one .naltest, amd10(an analogue of iwp2.3.1/amd4) which shows \na strictly stronger seman\u00adtics, but just how much stronger is unclear (consider, for example, analogues \nof Test amd6 in Fig. 2 with one or more MFENCEs). amd10 proc:0 proc:1 po:0 po:1 po:2 po:3 MOV [100].$1 \nMFENCE MOV EAX.[100] MOV EBX.[200] MOV [200].$1 MFENCE MOV ECX.[200] MOV EDX.[100] Forbidden: 0:EBX=0 \n. 1:EDX=0  2.13 Recovering Sequential Consistency In most cases, one would like to program in an idiom \nthat guarantees sequentially consistent behaviour, ensuring that the reorderings that the memory model \npermits are not observable. We return to this in \u00a75, but mention two ex\u00adtreme possibilities here. Contrary \nto what might be ex\u00adpected, addingan MFENCE between everyinstructiondoes not su.ce, according to the \nx86-CC semantics above: this would still permit processors to see di.erent store orders. However, programming \nexclusively with locked instructions would su.ce, as the lock serialization order would deter\u00admine an \nSC execution. 3. Instruction Semantics We now give the other half of the semantics: we de.ne the possible \nevent structures for a program; combining this with the memory model to give the possible event structures \nwith their valid executions. At present we cover the following instructions: data transfer MOV, CMOVE, \nCMOVNE, XADD, XCHG, CMPXCHG, LEA; binary op\u00aderations ADD, AND, CMP, OR, SUB, TEST, XOR, SHR, SAR, SHL; \nunary operations INC, DEC, NOT, NEG; stack operations POP, PUSH, PUSHAD, POPAD; and control transfers \nJUMP, CALL, RET, LOOP. We cover all the var\u00adious 32-bit addressing modes, including indexing, scaling, \netc. 3.1 Decoding The .rst step is to decode a machine code program, a code memory containing bytes, \nof type program word8 = address . word8 option, to an abstract syntax program, giving the instructions \nXinst (and their lengths) at each address: program Xinst =(address . (Xinst * num)option). Thevendordocumentationincludestableswith \noneto50 or so lines for each instruction, e.g. \" 8B /r | MOV r32, r/m32 \"; \" B8+rd id | MOV r32, imm32 \n\"; giving symbolic expressions for their opcodes. For example, B8+rd id represents an opcode with a \n.rst byte B8 added to a code for the 32-bit register r32, followed by a 4-byte immediate operand for \nthe imm32. To make the semantics scalable, without introducing many errors, we formalised the interpretation \nof these encodings inside the HOL logic, and built a HOL decoding function by directly copying the relevant \nlines from the manual into the HOL script. (We found oneerrorintheIntel manualintheprocess:the id in \nthesecondlineshownis actually omittedthere[5,vol.2A,p3\u00ad640], highlighting the need for testing.) 3.2 \nInstructions A single x86 instruction can involve a complex pattern of register and memory accesses.Inde.ning \nthepossibleevent structuresfor aninstruction,with therightintra-instruction causality relation among \nthese accesses, we have to avoid over-sequentialising them. For example, two independent reads should \nbe unrelated, whereas an [EAX] operand re\u00adsolves into a register read of EAX followed by a memory read \nofthat address.Moreover,thepattern of accesses(not justtheirvalues)candepend onthevaluesread, and tokeep \nthe semantics manageable we have to deal as uniformly as possible with all the various addressing modes \nand with the various binary and unary operations. We must also accom\u00admodate loose speci.cation of values, \nfor .ag values that are explicitly unde.ned in the architecture. We express the semantics in terms of \na small microcode language of combinators, analogous to a monad for a type constructor ' a M, but with \nboth sequential and parallel composition: seqT : ' a M . ( ' a . ' b M). ' b M parT : ' a M . ' b M . \n( ' a * ' b)M constT : ' a . ' a M failureT : unit M mapT :( ' a . ' b). ' a M . ' bM lockT : unit M \n. unit M write reg : iiid . Xreg . word32 . unit M read reg : iiid . Xreg . word32 M write eip : iiid \n. word32 . unit M read eip : iiid . word32 M write e.ag : iiid . Xe.ags . bool option . unit M read \n e.ag : iiid . Xe.ags . bool M write m32 : iiid . word32 . word32 . unit M read m32 : iiid . word32 \n. word32 M For example, for binary operation Xbinop binop name ds, with destination and source ds, at \ninstruction instance ii, and len byteslong,wehave(using various auxiliaries): x86 exec ii (Xbinop binop \nname ds)len =parT unit (seqT(read eip ii)(.x. write eip ii (x + len))) (seqT (parT(read src ea ii ds)(read \ndest ea ii ds)) (.((ea src, val src), (ea dest, val dest)). write binop ii binop name val dest val src \nea dest)) The event structure semantics implements the combinators for ' a M below (threading through \na gensym eiid state to make eiid s unique by construction). The seqT and parT combinators both build \nthe set of event-structure unions of pairs of event structures from their arguments, with seqT adding \nintra-causality edges. '' a M = eiid state . ((eiid state * a * event structure)set) 3.3 Sequential \nSemantics We also build a more directly executable semantics for se\u00adquentialprograms, simply re-implementing \nthe combinators for a state monad while keeping the body of the instruction semantics unchanged: ' a \nM = x86 state . ( ' a * x86 state)option x86 state = (Xreg . word32) *(word32) (*EIP *) *(Xe.ags . bool \noption) *(word32 . word8 option)  3.4 Programs Finally,tode.nethepossible event structuresfor adecoded \nprogram, we identify the well-formed run skeletons se\u00adquences(.nite or in.nite, anddownclosed) of addresses \nof instructions for each processor: proc . (program order index . address option) For each run skeleton, \nwe .rst calculate the sets of event structuresfor eachinstructioninstanceit contains, then take the event-structure \nunion of each possible choice thereof. Combining this with the axiomatic model to give valid exe\u00adcution \nwitnesses, the overall semantics has the type below. x86 semantics : program word8 . state constraint \n. (run skeleton * program Xinst *((event structure * (execution witness set))set))set This is signi.cantly \nmore involved than a typical sequen\u00adtially consistent interleaving semantics largely because the values \nread in a valid execution are constrained by the axiomatic memory model, which is in terms of the possible \norderings of all the events of a putative execution, instead of being values known at a particular time, \nthat one could simplyprovide to theinstruction semantics.Additional com\u00adplexity arises from dealing with \nconcrete located machine code rather than assembly language, which is necessary to build correct EIP \nvalues at call points. Theorem 2. The event structures built above are all well\u00adformed. [Proof: HOL, \nwitha large automated case analysis] 4. Testing the Semantics 4.1 Executing the axiomatic memory model \nIndevelopingthe axiomaticmemorymodelof \u00a72,it was vital to explore the consequences of the axioms for \nexample pro\u00adgrams.However,thisquickly becomestoo complextodoby hand. The litmus tests in \u00a72 have around \n6 10 instructions on p = 2 4 processors, which generate ne = 10 20 events, and the naive number of candidate \nexecution witnesses is roughly (ne !)p . We built a memevents tool to test the se\u00admantics,whichise.cient \nenoughtorun onall theexamples shown, and which con.rms their stated behaviours in the axiomatic model. \nIt also produces pictorial representations of the possible view orders and executions, as in the simple \nexample shown in Fig. 1. To test the impact of individual conditions of the axiomatic model, selected \nchecks can be turned o. one by one. The tool is written in OCaml. It is heavilyparameterised,both overthemicrocodelanguage \nof \u00a73.2,which canbeinstantiatedtoproduce anevent structure and a state monad semantics, and over the \nconcrete archi\u00adtecture, which can be instantiated with the x86 structures described here or with Power \nand ARM semantics, which are under construction. The OCaml code has been checked, by hand, to corre\u00adspond \nwith the HOL de.nition. In future work, we plan to instantiate the HOL de.nition with a third implementation \nof the microcode language, for symbolic execution, and to use the HOL code generation facilities to build \nthe checker core directly. 4.2 Validation of the memory model To validate the memory-model semantics \nagainst actual hardware, webuilt a litmus tool.Given a test speci.ed with a syntax similar to that used \nin this paper, this tool ini\u00adtialises the machine state (memory and registers), spawns the threads that \ncompose the test and compares the .nal state with the constraint speci.ed by the test. Care is taken \nto use memory locations in di.erent cache lines, to pre-.ll caches and writebu.ers, andtosynchronisethethreads, \nand each testis repeated many times,to maximisetheprobabil\u00adity of observing non-sequentially consistent \nbehaviours. Wetested thelitmustests of \u00a72 on several multiprocessor machines2. In all cases, the results \nwe observed were admit\u00adtedby oursemantics.Onall machines,weobserved thenon\u00adsequentially consistent behaviours \nof tests iwp2.3.a/amd4 and iwp2.4/amd9, e.g. between 5 and 5000 times out of 200000 runs for the latter. \nWe did not .nd witnesses for the reorderings of tests n1, amd6, and n3. It may be that these testswerenotrepeated \nsu.ciently, orthatthetooldoesnot stress the memory subsystemproperly tohighlight thesebe\u00adhaviours, but \nit may also be that the particular processors wetesteddonotexploitthesereorderings, evenifthey areal\u00adlowedby \nthe architecture(webelievethatmanyprocessors actually provide a much stronger TSO-based model). The gap \nbetween particular devices and the architecture means that one can conclude little from an absence of \nwitnesses.  4.3 Validation of the sequential semantics Tovalidatethedetails oftheinstructionsemantics(decod\u00ading, \narithmetic details, etc.), which are largely orthogonal to the memory model, we tested them against a \nPentium 4 processor.Fore.ciency,thisusesthesequentialsemantics of 2 One machine was equipped with two \nIntel Xeon CPUs, one with fourQuad-CoreAMDOpteron CPUs, one with4 Dual-Core AMDOpteronCPUs, and one with \nanIntelCore2QuadCPU. \u00a73.3; the checkingisdone entirely withinHOL,forhigh con\u00ad.dence. We implemented an \nx86sem tool that, given an x86 instruction, builds a valid assembler program that dumps the state of \nthe machine (including registers, .ags, stack, and memory) immediately before and after the instruction \nbeing tested. For a simple example, one instance of testing the instruction MOV EAX.EBX generated the \nfollowing HOL conjecture: (XREAD REG EBX s = 0x6F5BE65Bw)=. (XREAD EIP s = 0x804848Bw)=. (XREAD MEM 0x804848Bw \ns = Some 0x89w)=. (XREAD MEM 0x804848Cw s = Some 0xD8w)=. (XREAD REG EAX(the(X86 NEXT s))= 0x6F5BE65Bw). \n(XREAD REG EBX(the(X86 NEXT s))= 0x6F5BE65Bw). (XREAD EIP(the(X86 NEXT s))= 0x804848Dw) This states that, \nfor all s : x86 state, if the memory pointed by the instruction pointer contains the encoding of MOV \nEAX.EBX,i.e. 89D8, and EBX has the giveninitial state, the machine evolves in the \u00a73.3 semantics (function \nX86 NEXT) to a state where EAX contains the double word from EBX. Such conjectures can then be automati\u00adcally \nproved by the HOL automation, using an appropriate set of simpli.cation rules. Thetoolcovers alltheinstructionsde.nedinHOL(ex\u00adcept, \nat present, PUSHAD, POPAD, LEA, SHR, SAR, SHL), including direct and indirect memory addressing modes, \nand includes a random initialisation of the state of the machine, chosen to prefer corner cases. The \nseman\u00adtics has been tested on 4600 random instruction instances, also generatedfrom theopcodetables(about \n75perline). The tool highlighted several mistakes in the decoding func\u00adtions, but did not reveal inconsistencies \nbetween the HOL sequential semantics and the behaviour of the processor. 5. Data-race-free Programs To \nmake a relaxed-memory architecture usable for large\u00adscaleprogramming,itishighly desirable(perhaps essential) \nto identify programming idioms which ensure that one need only consider sequentially consistent executions. \nFor exam\u00adple, one can consider properly synchronised programs, in which shared accesses are protected \nby locks. Indeed, mem\u00adory modelshave sometimesbeende.nedintheseterms[8]. For a processor ISA, we prefer \nto de.ne a memory model that is applicable to arbitrary programs, to support reason\u00adingaboutlow-levelcode(includingimplementations \noflocks, forexample), andhaveresultsabout well-behavedprograms as theorems above it. Say a valid sequential \nexecution for an event structure E isalinear ordering so onitseventssuch that allinstructions in an atomic \ngroup appear uninterrupted, and such that the unique execution witness built from that order is valid \naccording to the axiomatic memory model. Such behaviours are manifestly sequentially consistent. sequential \nexecution E so = linear order so E.events . (.(es . (E.atomicity))(e1 . es)(e2 . es)e. (e1, e). so . \n(e, e2). so =. e . es) valid sequential execution E initial state so = sequential execution E so . \nvalid execution E(so to exec witness E initial state so) The .rst step is to show that if an execution \nis valid in the memory model then there is a similar valid sequential execution, as long as the former \nhas no data races (Theo\u00adrem3below).An executionhas adata raceif thereis apair of memory access events \nto the same location that can com\u00adpete, i.e. that are unrelated by happens-before. This is an intensional \nand x86-speci.c notion of data race: note that one event must be a read and the other a write two writes \nto the same memory location can never be a data race be\u00adcause of the write serialization ordering. Note \nalso that two locked events from di.erent instructions can never compete, and a write followed by a read \nof the same memory address in some view order must be related by happens-before, and so do not compete. \ncompetes EX = {(e1, e2)|\u00ac(e1 = e2). (loc e1 = loc e2). ((e1 . writes E . mem store e1 . e2 . reads E). \n(e2 . writes E . mem store e2 . e1 . reads E))} \\ ((happens before EX)+ . ((happens before EX)+)-1) \nrace free EX = .e1 e2 . (E.events). \u00ac((e1, e2). competes EX) Theorem 3 (Sequential Order). .EX. well \nformed event structure E . .nite E.events . race free EX . valid execution EX =..so. valid sequential \nexecution EX.initial state so . (happens before E(so to exec witness EX.initial state so)) . (strict \nso). (X.write serialization = so to write serialization so). (X.lock serialization = so to lock serialization \nE so). (X.rfmap = so to rfmap E so) HOL proof outline: Induction on the size of E. We remove a happens-before-maximal \nelement e from E, inductively sequen\u00ad ' tialise the rest as so ' , and add e to so as the maximal element.We \nrely ondata-racefreedom onlyin showingthat the resulting rfmap is unchanged (which in turn ensures that \ncheck rfmap written and check rfmap initial pass). To ensure that atomic events ap\u00adpear contiguously, \nwe choosefor e an event thatisin an atomicity set if and only if that entire set is happens-before-maximal, \nwith respect to outside instructions the lock serialization ordering ensures that this condition can \nalways be satis.ed. Two ways to strengthen Theorem 3 appear desirable at .rst sight, but are not true. \nConsider .rst whether each processor sview orderwhenrestrictedtolocalevents(i.e., not including others \nmemory writes) can have the same order as the sequential order. Test iwp2.3.a/amd4 provides a counter-example. \nThe sequential order also cannot be made to keep the events of non-atomic instructions adjacent (the \nINC/INC example of \u00a72 shows that in a racy situation, but it remains true even for race-free executions). \nIn a situation similar to iwp2.3.a/amd4,but wheretheboth events ofeachprocessor are in the same instruction, \nif neither read is to the initial state, then it is easy to check that neither possible instruc\u00adtion \natomic sequential execution preserves the rfmap (and is hence invalid since the written and initial values \ndi.er). One can set up such a situation in practice using PUSH instructions after setting the ESP register. \nTheorem 3 allows the existence of valid executions for an event structure to be established using sequential \nreasoning only after all data races have been ruled out with respect to the weak memory model.Theorem4below \nshows thatdata\u00adrace freedom can also be established using only sequential reasoning.An event structureis \nsequentially data-race free if allofitssequentialexecutions aredata-racefree.Becausewe are working in \nterms of a concrete event structure, we must also consider pre.xes of E. Otherwise, an event structure \nwith no sequential executions wouldbe trivially sequentially race free, and therefore by Theorem 4 sequentialisable, \na contradiction.Noticethatthe notion ofsequentialdata-race freedom does not depend on the view order \nof X. pre.xes EX = {E ' | sub event structure E ' E ..e1 e2. e2 . E ' .events . (e1, e2). (happens before \nEX)=. e1 . E ' .events} sequential race free EX = .(E ' . (pre.xes EX))so. valid sequential execution \nE ' X.initial state so =. .e1 e2.\u00ac((e1, e2). competes E ' (so to witness E ' X.initial exec state so)) \nTheorem 4 (Data race freedom). .EX. well formed event structure E . .nite E.events . sequential race \nfree EX . valid execution EX =. race free EX . [the conclusion of Thm. 3] HOLproof outline:Completeinduction \nonthe size of E, showing that if E is sequentially data-race free it is data-race free, then using Theorem \n3. For the .rst part, assume for a contradiction that there is a data race on two events e1 and e2 for \na particular execution witness. Consider the pre.x of E that consists of only those two events and those \nthat precede them in the happens\u00adbefore order. Call it E ' , and assume w.l.o.g. that e1 is the write. \nRemove e1 from E ' and by induction sequentialise the remainder ' as so (here we use the fact that a \npre.x of a sequentially data\u00adrace free program is still sequentially data-race free). Add e1 to the end \nof so as above and check that this is a valid sequential execution of E ' , with adata racebetween e1 \nand e2, contradicting the assumption of sequentialdata-racefreedom(againforpre.xes too). If e1 is in \nan atomicity set, it is necessary to ensure that no other element of the setin E ' happensbefore an element \nof E ' not in the set. This could fail if an instruction had some events inside an atomicity set and \nothers not inside an atomicity set. However, in the x86 architecture no instructions are partially atomic. \nUltimately, this result should be lifted to an interleaving transition-system semantics over the x86 \nstate of \u00a73.3, so that race freedom can be determined without reference to the event structures semantics \nat all. We have de.ned such a semantics, as a further instantiation of the microcode combinators, but \nleave the proof to future work. 6. The Abstract-Machine Memory Model Theglobalstyleofthe axiomaticmodel,intermsofpossible \norderings ofeventsinacompleteexecution, .tswell withthe informal statements of the vendor documentation, \nand with most previous work on relaxed memory. However, it is dif\u00ad.cult to relate it to operational intuitions \nof machines. We thereforedevelop analternativeabstract-machinecharacter\u00adisationofthe axiomaticmodel,with \nthesamesetofpossible behaviours. At present this covers non-locked instructions only, though we believe \nthat the extension to cover them is reasonably straightforward. GivenTheorem1 andpreserved program order, \nthe only reordering themachinemustpermitis ofmemory writes af\u00adterindependent reads.Memory writesfrom \nthe sameproces\u00adsor must be observed in program order, and memory writes to the same location must be \nobserved in the same write serialisation order. We capture this in the machine with two pieces of state: \npending FIFO queues of write operations Fpq,for writesissuedbyprocessor p to be seen on proces\u00adsor q, \nandper-location write serialisations Ga. On issuing a write, processor p enqueues the writes on each \nqueue Fp . The write is considered observed by q when it is dequeued from Fpq. Since there is a queue \nFpp, processor p may choosetodelayobservingitsownwrite.TheFIFO nature of the Fpq queue ensures that writes \nissuedby p are observed in the same order as they are issued. Dequeueing is subject to the constraint \nthat all Ga predecessorshave alreadybeen observed, and adds the current write to the global order Ga \nif it is not already present. Unfortunately, this alone does not su.ce to ensure that the transitive \nclosure of the happens-before relation is re\u00adspected.The easiest way todo sois tobuild up thehappens\u00adbefore \nrelation incrementally, and check that all happens\u00adbefore predecessor events have been observed as a \nprecon\u00addition of observing events. The machine is still operational, in the sense that it enjoys the \nprogress property below, and so backtracking is not required. However, it would still be fairly costly \nto implement, so this should be considered only a .rst step. Theorem 5 (Machine progress). For the transition \nsystem de.nedby the machinefor aprogram, either the machinehas a t transition, or it can make a visible \ntransition matching the event structure of the program, or no processor has any more events and the machine \nqueues are empty. It also matches the axiomatic model precisely. Theorem 6 (Machine correctness). 1. \nFor any .nite nice valid execution of the axiomatic semantics, there is a corresponding trace of the \nmachine. 2. The execution witnesses built from complete traces of the machine, for .nite well-formed \nE, are valid executions in the axiomatic semantics. Thedetailedoperationalsemantics ofthemachine(inHOL), \nand the(hand)proofsoftheaboveresults, areavailable[6]. Given such a machine, it should be feasible to \nbuild a demonic x86 emulator, with aggressive reordering, so that low-levelcode(e.g.lock-freedatastructureimplementations) \ncan be tested against the architecture, rather than just against particular devices. 7. Power and ARM \nContrasts To give a .avour of the large design space in which the x86 relaxed memory model lies, we contrast \nit brie.y with the behaviour of the Power and ARM multiprocessors (which have broadly similar memory \nmodels). Preliminary HOL de.nitionsofthesememory models areavailable[6]. First, the Power and ARM have \nweaker program-order preservation constraints. In the Power analogue of Test ipw2.1/amd1, we can observe(using \nour litmus tool) that a .nal outcome with the .rst register holding 1 and the second 0 is possible. By \nadding data.ow dependencies to one or other processor, we can con.rm that both load/load and store/storereorderings \narepossible.Wecanobservealso that loads from two addresses into the same register can be reordered. Second,transitivity, \nasin analogues ofTestiwp2.5/amd8, isexplicitlynotguaranteedforARM, asnotedbyChong and Ishtiaq[16], and \nwebelievealsoforPower. Third,theexistence ofduplicate(orshadow) registersin Power can be observed by \nthe programmer. For example, consider the test below, adapted from Adir et al. [7], with read and writtenvalues \nannotated.Onproc:1thereis(pre\u00adserved) data dependency from each instruction to the next, and similarly \non proc:0 between the lwz and mr, and be\u00adtween the li and stw. Because the mr r2.r1 and li r1.1 both \ninvolve r1, one might expect a preserved program or\u00adder between them, which would lead to a cycle in \nthe view orders.Inthe architecture(thoughwehavenotyetobserved this), the r1 used in the lwz and mr, and \nthe r1 used in the li and stw, can be two di.erent duplicates. proc:0 proc:1 {x=2} lwz r1.[x]{r1=2} {r1=2} \nmr r2.r1 {r2=2} li r1.1 {r1=1} {r1=1} stw r1.[y]{y=1} {y=1} lwz r3.[y] {r3=1} {r3=1} addi r3.r3, 1{r3=2} \n{r3=2} stw r3.[x] {x=2} Allowed: 0:r1=1 . 0:r2 =2 . 1:r3 =2 . x = 2 . y = 1 8. Related Work Reasonably \nprecise de.nitions of relaxed memory models were .rst studiedintheComputerArchitecturecommunity, e.g.with \ntheearly workofDuboisetal.[18] andCollier[17], and an extensive literature has developed since then. \nWe referthereadertothesurveysbyAdve andGharachorloo[8], Luchango[26],andHigham,Kawash, andVerwaal[25]for \nan overview; the latter relates several axiomatic and abstract\u00admachine(or operational) de.nitions. Manyofthesemodels \nareratheridealised with respectto actualprocessors: we arenotawareof any otherdetailed x86 model, or \na model integrated with a substantial instruction semantics. The Itanium and SPARC have vendor speci.\u00adcations \nin informal mathematics [1, 2] leading to Itanium work by Higham et al. [20] and Yang et al. [31], which \nbuilds an oracle from an axiomatic model. Park and Dill produced a speci.cation for SPARC RMO which could \nbe executed onlitmustestexamples[28].Adiretal.study the PowerPC[7], andthereisearly work on aHOLmodelfor \nAlphabyGordon[19].More recently, several authorshave considered model-checking of programs above simple \nweak memory models, e.g. in the work of Burckhardt and col\u00adleagues[15,14],respectivelyaboveTSO andaboveageneral \nrelaxed memory model. The latter is a conservative approx\u00adimation to several models, but does not admit \nthe di.erent views of the x86. Our x86 memory model is in a similar style to the causal memoriesofAhamadetal.[10], \nand ourdata-racefreedom theorem and proof have a similar structure to theirs. Their causal memories are \nweaker than the x86 model, lacking a (per memory address) global write serialisation and locked instructions, \nalthough they do discuss the possibility of addingadditional causality edges to support synchronisation \nconstructs. Another line of work addresses memory models for high-level programming languages such as \nJava, X10, and C++ [27, 12, 29, 13]. Here one must consider both the underlying architecture models and \ncompiler-optimisation reorderings, and the lack of clear de.nitions of the former has led to a need for \ndocuments such as Lea s JSR-133 Cookbook for Compiler Writers [24]. Our x86-CC model validates Boehm \nand Adve s WRC write-to-read causality property [13, Fig.5] (iwp2.5/amd8 is a fence-less x86 ana\u00adlogueoftheirtests) \nand theirCCproperty[13,Fig.7](again for a fence-less analogue). It does not validate their RWC read-to-write \ncausality test [13, Fig.6] without fences. We believeit still would notdosowith theMFENCE semantics sketched \nin \u00a72.12, but would if the fences were replaced by LOCK d instructions. There is, of course, also a great \ndeal of work on seman\u00adtics and architecturedescriptionforsequentialprocessorbe\u00adhaviour; space precludes \nan overview here. 9. Conclusion Our main contributionisasemanticsformultiprocessorx86 programs, with \nintegrated relaxed memory model, instruc\u00adtion semantics, and machine-code decoding. The key di.\u00adculty \nwas to go from the informal-prose vendor documenta\u00adtion, with its often-tantalising ambiguity, to a fully \nrigorous de.nition(mechanisedinHOL) that onecanbereasonably con.dent is an accurate re.ection of the \nvendor architec\u00adtures(Intel64 andIA-32, andAMD64).Wemadeparticular choices, e.g. in the treatment of \nevents and instructions, the structure of view orders, reads-from maps, etc., the de.ni\u00adtion of happens-before, \nand the precise axioms of \u00a72; based on a combination of the prose documentation, discussions with sources, \nand the testing of \u00a74. The modelprovides a necessaryfoundationfor soundrea\u00adsoning about low-level concurrent \nx86 code, in many con\u00adtexts:programlogics,algorithmveri.cation,static analysis, compilation, model-checking,proof-carrying \ncode, and so on. Itshouldalsoprovideasolidintuitionforlow-levelprogram\u00admers, and supportthedesignofhigh-levellanguagememory \nmodels.In \u00a75and \u00a76wetookthe .rst stepsintwodirections, with results on the behaviour of race-free programs \nand a machine characterisation of the memory model, and men\u00adtioned some speci.c items of future work, \nbut the existence of a sound semantics opens up many more opportunities. The architectures advertised \nby processor vendors are a key interface, between them and programmers. They must oftenbeloose speci.cations,topermitprocessorimplemen\u00adtations \nto change. It appears that the imprecision of infor\u00admal prose has sometimes been used as a deliberate \ntool for loose speci.cation, making it extremely hard for low-level programmers to understand the behaviour \nof their code. We have taken care in our semantics not to over-specify: to the best of our knowledge, \nthe semantics does not commit to anything that vendors should consider unreasonable, and thus it demonstrates \nthat it is feasible to have completely precise,butsu.cientlyloose,speci.cationsinthis area.The semantics \nalso provide a vocabulary for discussing subtle alternatives from the programmer s point of view, without \nreference to hardware implementation concepts. Acknowledgements We thank MichaelFetterman, AndyGlew, \nand Gil Neiger for invaluable discussions about Intel architec\u00adtures and devices; Nathan Chong and Samin \nIshtiaq for discus\u00adsions about the ARM; and Kathryn Gray, Mike Hicks, Warren Hunt, and Samin Ishtiaq \nfor comments on drafts. We acknowl\u00adedge the support of a Royal Society University Research Fel-lowship(Sewell),EPSRCgrantsGR/T11715,EP/C510712, \nand EP/F036345, and ANR grant ANR-06-SETI-010-02. References [1] A formal speci.cation of Intel Itanium \nprocessor family memory ordering. http://developer.intel.com/design/ itanium/downloads/251429.htm. [2] \nThe SPARC architecture manual, v. 9. http://developers. sun.com/solaris/articles/sparcv9.pdf. [3] Linux \nkernel tra.c, 1999. http://www.kernel-traffic. org/kernel-traffic/kt19991220_47.txt. [4] AMD64 Architecture \nProgrammer s Manual. Advanced Micro Devices, Sept. 2007. (3vols). [5] Intel 64 and IA-32 Architectures \nSoftware Developer s Manual. Intel Corporation, April (vol 1,2A,2B; rev.27), Feb.(vol.3A,3B; rev.26) \n2008. [6] The semantics of multiprocessor machine code, 2008. www.cl.cam.ac.uk/users/pes20/weakmemory. \n [7] A. Adir, H. Attiya, and G. Shurek. Information-.ow models for shared memory with an application \nto the powerpc architecture. IEEE Trans. Parallel Distrib. Syst.,14(5):502 515, 2003. [8] S. Adve and \nK. Gharachorloo. Shared memory consistency models: A tutorial. IEEE Computer, 29(12):66 76, Dec 1996. \n[9] M. Ahamad, R. A. Bazzi, R.John, P. Kohli, and G. Neiger. The power of processor consistency. In Proc. \nSPAA 93, 1993. [10] M. Ahamad, G. Neiger, J. Burns, P. Kohli, and P. Hutto. Causal memory: De.nitions, \nimplementation, and program\u00adming. Distributed Computing, 9(1):37 49, 1995. [11] ARM. ARM Architecture \nReference Manual (ARMv7-A and ARMv7-R edition). 2008. Available from ARM. [12] D. Aspinall and J. Sevcik. \nFormalising Java s data race free guarantee. In Proc. TPHOLs, LNCS, 2007. [13] H.-J. Boehm and S. Adve. \nFoundations of the C++ concurrency memory model. SIGPLAN Not., 43(6):68 78, 2008. [14] S. Burckhardt,R.Alur,andM.Martin.Checkfence:checking \nconsistency of concurrent data types on relaxed memory models. In PLDI, 2007. [15] S. Burckhardt and \nM. Musuvathi. E.ective program veri.cation for relaxed memory models. In Proc. CAV, LNCS 5123, 2008. \n[16] N. Chong and S. Ishtiaq. Reasoning about the ARM weakly consistent memory model. In Proc. MSPC, \n2008. [17] W. Collier. Reasoning about parallel architectures. Prentice-Hall, Inc., 1992. [18] M. Dubois, \nC. Scheurich, and F. Briggs. Memory access bu.ering in multiprocessors. In ISCA, 1986. [19] M. Gordon. \nMemory access semantics for a multiprocessor instruction set. Unpublished note(c.1993) www.cl.cam.ac. \nuk/ftp/hvg/papers/AlphaProg.ps.gz. [20] L. Higham, L. A. Jackson, and J. Kawash. Programmer\u00adcentric conditions \nfor itanium memory consistency. In Proc. ICDCN, 2006. [21] The HOL 4 system. http://hol.sourceforge.net/. \n[22] Intel. Intel 64 architecture memory ordering white paper, 2007. SKU 318147-001. [23] L. Lamport. \nHow to make a multiprocessor computer that correctly executes multiprocess programs. IEEE Trans. Comput., \nC-28(9):690 691, 1979. [24] D. Lea. The JSR-133 cookbook for compiler writers. gee.cs.oswego.edu/dl/jmm/cookbook.html. \n[25] L.Higham, J.Kawash, and N. Verwaal. De.ning and comparing memory consistency models. In PDCS, 1997. \n[26] V. M. Luchangco. Memory consistency models for high\u00adperformance distributed computing. PhD thesis, \nMIT, 2001. [27] J.Manson,W.Pugh, andS.Adve. TheJava memory model. In Proc. POPL, 2005. [28] S. Park and \nD. L. Dill. An executable speci.cation, analyzer and veri.er for RMO (relaxed memory order). In Proc. \nSPAA 95, 1995. [29] V. Saraswat, R. Jagadeesan, M. Michael, and C. von Praun. A theory of memory models. \nIn Proc. PPoPP, 2007. [30] G. Winskel. Event structures. In Advances in Petri Nets, LNCS 255, 1986. [31] \nY. Yang, G. Gopalakrishnan, G. Lindstrom, and K. Slind. Nemos: A framework for axiomatic and executable \nspeci.\u00adcations of memory consistency models. In IPDPS, 2004. Addendum, added in press This paper developed \na formal model, x86-CC, which is based on our understanding of the current published Intel and AMD speci.cations: \n. the Intel 64 Architecture Memory Ordering White Paper (IWP) [22]; . recent versions of the Intel SDM \n[5, vol.3A, \u00a77.2.3], both revision 26 (Feb. 2008) and revision 28 (Sept. 2008), which essentially incorporate \nIWP; and . the AMD documentation [4, vol.2,p.164.]. To thebestof our knowledge,itdoes accuratelyre.ect \nthese, and the mathematical and empirical results in the paper hold. However, whether these speci.cations \n(in either formal or informal versions) are useful descriptions of the actual processors, suitable for \nreasoning about x86 software, is in question. In onedirection,thespeci.cations arearguablytooweak (withrespect \nto actualprocessors).The di.cultyof imple\u00admenting the Java Memory Model above these speci.cations (recall \nthe weak guarantees provided by MFENCE, as dis\u00adcussed in \u00a72.12,2.13) seems to have motivated a change \nin the Intel and AMD speci.cations: we are told that future speci.cationsbybothIntel and AMDwill exclude \nthe amd6 (IRIW) exampleshowninFig.2.Thiswouldbringthemodel muchcloser toTSO, but, complicating the issue \nstill further, a draft revised speci.cation seems to admit some non-TSO (indeed, non-coherent) behaviour. \nIn the other direction, the speci.cations appear not to include some behaviour that actual processors \nmay exhibit. Consider the following example, due to Paul Loewenstein. n6 proc:0 proc:1 poi:0 poi:1 poi:2 \nMOV [100].$1 MOV EAX.[100] MOV EBX.[200] MOV [200].$2 MOV [100].$2 Forbidden: 0:EAX=1 . 0:EBX=0 . [100]=1 \n The .nal state is: . disallowed by our x86-CC formal model; . disallowed by any reasonable interpretation, \nas far as we can tell, of the current Intel and AMD published speci.cations; but . according to our preliminary \ntest results, allowed by at least one Intel processor (we .nd approximately one witness in 2 * 106 executions, \nreproducibly, on an Intel Core 2, with our litmus tool). It is also allowed by TSO. The situation is \nclearly unsatisfactory, and we hope to produce a more useful revised formal model as soon as possible. \nHowever, it does, ironically, illustrate the main point of the paper very well: there is a clear need \nfor precisespeci.cationsofmultiprocessorbehaviour, and those speci.cations mustbeexercisedin some way \n one should have little con.denceinaloosespeci.cation(evenifprecise) that is not exercised by testing \nor veri.cation with respect to the hardware, proof of metatheory, and a large body of concurrent programming. \nWe would like to thank David Christie, Dave Dice, Doug Lea, Paul Loewenstein, and Gil Neiger for their \nhelpful remarks.   \n\t\t\t", "proc_id": "1480881", "abstract": "<p>Multiprocessors are now dominant, but real multiprocessors do not provide the sequentially consistent memory that is assumed by most work on semantics and verification. Instead, they have subtle relaxed (or weak) memory models, usually described only in ambiguous prose, leading to widespread confusion.</p> <p>We develop a rigorous and accurate semantics for x86 multiprocessor programs, from instruction decoding to relaxed memory model, mechanised in HOL. We test the semantics against actual processors and the vendor litmus-test examples, and give an equivalent abstract-machine characterisation of our axiomatic memory model. For programs that are (in some precise sense) data-race free, we prove in HOL that their behaviour is sequentially consistent. We also contrast the x86 model with some aspects of Power and ARM behaviour.</p> <p>This provides a solid intuition for low-level programming, and a sound foundation for future work on verification, static analysis, and compilation of low-level concurrent code.</p>", "authors": [{"name": "Susmit Sarkar", "author_profile_id": "81392603911", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1301018", "email_address": "", "orcid_id": ""}, {"name": "Peter Sewell", "author_profile_id": "81100511814", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1301019", "email_address": "", "orcid_id": ""}, {"name": "Francesco Zappa Nardelli", "author_profile_id": "81100512653", "affiliation": "INRIA, Rocquencourt, France", "person_id": "P1301020", "email_address": "", "orcid_id": ""}, {"name": "Scott Owens", "author_profile_id": "81337492133", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1301021", "email_address": "", "orcid_id": ""}, {"name": "Tom Ridge", "author_profile_id": "81322504917", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1301022", "email_address": "", "orcid_id": ""}, {"name": "Thomas Braibant", "author_profile_id": "81392619239", "affiliation": "INRIA, Rocquencourt, France", "person_id": "P1301023", "email_address": "", "orcid_id": ""}, {"name": "Magnus O. Myreen", "author_profile_id": "81392605670", "affiliation": "Unviersity of Cambridge, Cambridge, United Kingdom", "person_id": "P1301024", "email_address": "", "orcid_id": ""}, {"name": "Jade Alglave", "author_profile_id": "81392617420", "affiliation": "INRIA, Rocquencourt, France", "person_id": "P1301025", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480929", "year": "2009", "article_id": "1480929", "conference": "POPL", "title": "The semantics of x86-CC multiprocessor machine code", "url": "http://dl.acm.org/citation.cfm?id=1480929"}