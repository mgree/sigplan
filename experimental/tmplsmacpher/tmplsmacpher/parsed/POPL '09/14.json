{"article_publication_date": "01-21-2009", "fulltext": "\n Lazy Evaluation and Delimited Control Ronald Garcia * Rice University ronald.garcia@rice.edu Abstract \nThe call-by-need lambda calculus provides an equational frame\u00adwork for reasoning syntactically about \nlazy evaluation. This paper examines its operational characteristics. By a series of reasoning steps, \nwe systematically unpack the standard-order reduction relation of the calculus and discover a novel abstract \nmachine de.nition which, like the calculus, goes under lambdas. We prove that machineevaluationis equivalent \nto standard-order evaluation. Unlike traditional abstract machines, delimited control plays a signi.cant \nrole in the machine sbehavior. In particular,the machine replaces the manipulation of a heap using store-based \neffects with disciplined managementoftheevaluationstackusing control-based effects. In short, state is \nreplaced with control. To further articulate this observation, we present a simulation of call-by-need \nin a call-by-value language using delimited control operations. Categories and Subject Descriptors D.3.1[Software]: \nProgram\u00adming Languages Formal De.nitions and Theory General Terms Languages, Theory Keywords call-by-need, \nreduction semantics, abstract machines, delimited continuations, lambda calculus 1. Introduction From \nearly on, the connections between lazy evaluation (Fried\u00adman and Wise 1976; Henderson and Morris 1976) \nand control operations seemed strong. One of these seminal papers on lazy evaluation (Henderson and Morris \n1976) advocates laziness for its coroutine-like behavior. Speci.cally, it motivates lazy evaluation with \na solution to the same fringe problem: how to determine if two trees share the same fringe without .rst \n.attening each tree and then comparing the resulting lists.Asuccessful solution to the problem traverses \njust enough of the two trees to tell that theydo not match. The same fringe problem is also addressed \nin Sussman and Steele s original exposition of the Scheme programming lan\u00adguage (Sussman and Steele Jr. \n1998). One of their solutions uses a continuation passing-style representation of coroutines. * Work \nconducted at Indiana University. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage.To copyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. POPL 09, January 18 24, 2009, Savannah, Georgia, USA. Copyright c . 2009ACM \n978-1-60558-379-2/09/01... $5.00 Andrew Lumsdaine Amr Sabry Indiana University {lums,sabry}@indiana.edu \nSame fringe is not the only programming problem that can be solved using either lazyevaluation or continuations.For \ninstance, lazy streams and continuations are also used to implement and reason about backtracking(Wand \nandVaillancourt 2004; Kiselyov et al. 2005). Strong parallels in the literature have long suggested thatlazyevaluationelegantly \nembodiesastylized useof coroutines. Indeed, we formalize this connection. Call-by-need evaluation combines \nthe equational reasoning ca\u00adpabilities of call-by-name with a more ef.cient implementation technology \nthat systematically shares the results of some compu\u00adtations. However, call-by-need s evaluation strategy \nmakes it dif\u00ad.cult to reason about the operational behavior and space usage of programs. To facilitate \nreasoning, semantic models (Launchbury 1993; Sestoft 1997; Friedman et al. 2007), simulations (Okasaki \net al. 1994), and tracing tools (Gibbons andWansbrough 1996) for call-by-need evaluation have been developed. \nManyof these arti\u00adfacts use an explicit store or store-based side-effects (Wang 1990) to represent values \nthat are shared between parts of a program. Stores, being amorphous structures, make it dif.cult to establish \nprogram properties or analyze program execution. The call-by-need lambda calculus was introduced by Ariola \net al. (1995) as an alternative to store-based formalizations of lazy evaluation. It is an equational \nframework for reasoning about call\u00adby-need programs and languages.Following Plotkin (1975), the au\u00adthors \npresent a calculus and prove a standardization theorem that links the calculus to a complete and deterministic \n(i.e. standard or\u00adder) reduction strategy. The calculus can be used to formally justify transformations, \nparticularly compiler optimizations, because any terms it proves equal are also contextually equivalent \nunder call\u00adby-need evaluation. Call-by-need calculi were investigated by two groups (Maraist et al. 1998; \nAriola and Felleisen 1997). The resulting two calculi are quite similar but their subtle differences \nyield trade-offs that are discussed in the respective papers. One notable feature of Ariola and Felleisen \ns calculus is its use of evaluation contexts within the notions of reduction. It has been observed that \nevaluation contexts correspond to continuations in some presentations of language semantics (Felleisen \nand Friedman 1986; Biernacka and Danvy 2007). It s not obvious, however, that the evaluation contexts \nin this calculus have anything to do with control operations: they re used to model variable references \nand demand-driven evaluation, not .rst-class continuations. This paper exposes how Ariola and Felleisen \ns call-by-need evaluation relates to continuations. By systematically unpacking the standard-order reduction \nrelation of the calculus, we discover a novel abstract machine that models call-by-need style laziness \nand sharing without using a store. Instead, the machine manipulates its evaluation context in a manner \nthat corresponds to a stylized use of delimited control operations. The machine s behavior reveals a \nconnection between control operations and laziness that was presentbut hiddenin the reduction semantics. \nTo directly interpret this connection in the terminology of de\u00adlimited control, we construct a simulation \nof call-by-need terms in the call-by-value language of Dybvig et al. (2007), which pro\u00advides a general \nframework for delimited continuations with .rst\u00adclass generative prompts. Our concrete speci.cations \nof the relationship between call-by\u00adneed and delimited control .rmly establish how lazy evaluation relates \nto continuations and other control-oriented language con\u00adstructs and effects. Implementations of both \nthe machine and the simulation are available at the following url: http://osl.iu.edu/~garcia/call-by-need.tgz. \n2. The Call-by-need Lambda Calculus The remainder of this paper examines Ariola and Felleisen s for\u00admalization \nof call-by-need (Ariola and Felleisen 1997). The terms of the calculus are standard: t ::= x | .x.t | \ntt The calculus highlights two particular subsets of terms. First, as is typical, lambda terms are considered \nvalues: v ::= .x.t The calculus also distinguishes a subset of terms called answers: a ::= v | (.x.a) \nt Answers are a syntactic representation of (partial) closures. Notice that an answer takes the form \nof a lambda term nested inside some applications. The surrounding applications simulate environment bindings \nfor free variables in the nested lambda term. This repre\u00adsentationmakesit possibleforthe calculustoexplicitly \naccountfor variable binding, in particular to syntactically model how call-by\u00adneed evaluation shares \nlazily computed values. Following the style of Felleisen and Hieb (1992), the calculus usesevaluation \ncontextsto indicate those locationsinanexpression that may be subject to reduction: E ::= . | Et | (.x.E[x]) \nE | (.x.E) t Call-by-need contexts are unusual in that theyare not merely induc\u00adtively de.ned. The third \ncontext production, (.x.E[x]) E,encodes a side condition and expands as follows: if E is a context and \nt is a term, then if there exists a context E. that does not capture x and t = E.[x], then (.x.t) E is \nalso a context. The calculus has three notions of reduction: (.x.E[x]) v .need (.x.E[v]) v (.x.a) t1 \nt2 .need (.x.a t2) t1 (.x1.E[x1]) ((.x2.a) t1) .need (.x2.(.x1.E[x1]) a) t1 As popularizedbyBarendregt(1981), \neach reduction assumesahy\u00adgiene convention. When combined with theevaluation contexts, the notions of \nreduction yield a deterministic standard order reduction relation(.-.sr)and its re.exive-transitive closure(.-. \nsr). De.nition 1. t1 .-.sr t2 if and only if t1 = E[tr], t2 = E[tc] and tr .need tc. Standard order reduction \nprovides us an effective speci.cation of call-by-needevaluation:if t isaprogram (i.e. closed term), then \nt call-by-need evaluates to an answer if and only if t .-. sr a for some answer a. 3. From Reduction \nSemantics to Machine Semantics Some reduction semantics have been shown to correspond directly to abstract \nmachine semantics, thereby establishing the equivalence of a reducer and a tail-recursive abstract machine \nimplementa\u00adtion (Felleisen and Friedman 1986; Felleisen and Flatt 2002). In particular, Danvy and Nielsen \n(2004) derive abstract machine se\u00admantics directly from reduction semantics using provably correct transformations. \nProceeding from a reduction semantics for call\u00adby-need to an accessible and informativetail-recursiveabstract \nma\u00adchine semantics is not, however, as straightforward as for call-by\u00adname or call-by-value. Call-by-need \nredexes require more computational effort to rec\u00adognize than either call-by-name or call-by-value. For \ninstance, given a term t, only a .xed number of terminal operations are required to detect whether t \nis a call-by-name redex: one to check if the term is an application, one to access the operator position, \nand one to check if the operator is an abstraction. Contrast this with the call-by-need redex (.x.E[x]) \n((.y.a) t). Given a call-by-need term tx, testing whether it matches this redex form requires an unpredictable \nnumber of operations: check if tx is an application; check if its operator position is a lambda abstrac\u00adtion; \ncheck, in an unpredictable number of steps, if the operator s body can be decomposed into E[x], where \nx is both free in E and boundby the operator; and .nally check,in an unpredictable num\u00adber of steps, \nif the operand has the inductive structure of an answer. To make matters worse, some terms can be decomposed \ninto the form E[x] in more than one way. For instance, consider the term (.x.(.y.y) x). It can be decomposed \nas both (.x.E1[y]) and (.x.E2[x]) where E1 = (.y..) x and E2 = (.y.y) .. As such, a recursive procedure \nfor decomposing a term cannot stop at the .rst variable it .nds: it must be able to backtrack in a way \nthat guarantees it will .nd the right decomposition E[x] and in turn the right redex if there is one. \nAstraightforward call-by-need reducer implementation na\u00a8ively decomposes a term into a context and a \nredex. Any application could be one of three different redexes, each of which is nontrivial to detect, \nso whenever the decompose function detects an applica\u00adtion, it sequentially applies several recursive \npredicates to the term inhopesof detectingaredex.Ifthetermisaredex,it returns;ifnot, it recursively decomposes \nthe operator position. In our experience, this implementation strategy sheds no light on how to produce \nan understandable tail-recursive implementation. Recallthatoneoftheevaluation contextshastheform (.x.E)t. \nThis means that redexevaluation can occur under binders (Moggi and Sabry 2004; Kameyama et al. 2008). \nAll three call-by-need notions of reduction shuf.e lambda abstractions about in unusual ways. Furthermore, \nwhile reducing a recursive routine, a call-by\u00adneed evaluator may end up performing reductions under multiple \ncopies of the same lambda abstraction. Call-by-name and call-by\u00advalueevaluators can addresshygiene concerns \nby using environ\u00adments and closures,buta call-by-need evaluator must prevent its evaluation context from \nincorrectly capturing free variable refer\u00adences. Anyevaluator that goes under lambdas must pay particular \nattention tohygiene (Xi 1997). 3.1 Towards an Abstract Machine To .nd call-by-need redexes tail-recursively, \nwe apply an insight from the CK abstract machine (Felleisen and Friedman 1986; Felleisen and Flatt 2002). \nThe CK machine implements an evalua\u00adtion strategy for call-by-value based onareduction semantics using \nthe (inside-out)evaluation contexts .,E[. t] and E[(.x.t) .].To .nd a redex, the machine iteratively \nexamines the outermost con\u00adstructorofatermandusestheevaluationcontextto rememberwhat has been discovered. \nTo illustrate this in action, we walk through an example. Con\u00adsider the program (.x.x) .y.y. Evaluation \nbegins with con.gura\u00adtion .[], (.x.x) .y.y.. Underlining indicates subterms that the ma\u00adchineknows nothing \nabout;atthebeginningofevaluation,itknows nothing about the entire term. On the .rst step of the reduction, \nthe machine detects that the term is an application (.x.x) .y.y.Toex\u00adamine the term further, the machine \nmust move its focus to either the operator or operand of this application. Since the machine is tail \nrecursive,itmustalsopushanevaluation contextto storethe as-yet uncovered structure of the term. The only \ncontext it can reliably push at this point is [. .y.y]:it cannot push[(.x.x) .] because it has not yet \ndiscovered that the operator position is a value. So the machine pushes the [. .y.y] context, which serves \nas a reminder that it is focused on the operator of an application. On the second step of the reduction, \nthe machine detects that the operator is an abstraction .x.x, and observes that the innermost context \nis [. .y.y]. In response, the machine pops the context, focuses on .y.y, and pushes the context [(.x.x) \n.], since the operator is now known to be a value. This context serves as a reminder that evaluation \nis currently focused on the operand of an application that canbe reduced once that operand becomesavalue. \nOn the third step, the machine detects the abstraction (.y.y), and remembers that the innermost context \nis [(.x.x) .]. At this point, the machine has deduced enough information to recognize the redex (.x.x) \n.y.y. This example illustrates how the CK ma\u00adchine uses a depth-.rst left-to-right search strategy to \ndetect call\u00adby-value redexes. Now consider the same term under call-by-need using a similar strategy. \nAs with call-by-value, the top-level application can be detected, the operand can be pushed onto the \nevaluation context, and the operator can be exposed as the abstraction .x.x. At this point behavior must \ndiverge from call-by-value because the body of the abstraction is still unknown and call-by-need does \nnot have [(.x.t).] contexts for arbitrary t. However,call-by-need does have contexts of the form [(.x..) \n.y.y]. Therefore, it is possible to proceed under the .rst lambda abstraction, push the context, and \nfocus on x. The term is exposed as a variable x, which combines with the context [(.x..) .y.y] to form \nthe term (.x.E[x]) .y.y (where E = .). At this point, enough information has been un\u00adcovered to push \nthe context [(.x..[x]) .] and focus on .y.y. The abstraction .y.y is recognized, and with that a call-by-need \nredex (.x..[x]) .y.y has been found. Success with this example suggests a promising strategy for implementing \ncall-by-need reduction tail-recursively.  3.2 An Initial Abstract Machine In this section, we elaborate \nthe above search strategy intoa simple but inef.cient tail-recursiveabstract machine.Wepresentit without \nproof and then by a series of correct transformations we derive an ef.cient machine that we prove correct. \nThis abstract machine uses the same terms, values, and answers as the calculus. However, it introduces \ntwo alternate notions. First, the machine uses a more versatile representation of evaluation contexts. \nAs observed in Danvy and Nielsen (2004), evaluation contexts canbe mathematically speci.edin more than \noneway.For optimal .exibility, we de.ne evaluation contexts as lists of frames, where the empty list \n[] and single-frame lists [f] are our simple units, andthe operator . stands for listconcatenation f \n::= . t | (.x.E) . | (.x..) t E ::= [ ] | [f] . E | E . [f] where E . [ ] = [ ] . E = E and E1 . (E2 \n. E3) = (E1 . E2) . E3 When two contexts are composed, the second context is plugged into the hole of \nthe .rst context: for example [. t2] . [. t1]= [(. t1) t2]. We call the frame [(.x..) t] a binder frame. \nIt represents a variable binding in the context. It can be read as [let x = t in .], but we use the former \nnotation to emphasize that call-by-need evaluation proceeds under lambdas. This observation motivates \nour analysisofhygienein Section 4.5. We callthe frame[(.x.E) .] a cont frame, in reference to con\u00adtinuations. \nThe construction (.x.E) is called a cont and replaces the metalinguistic term notation (.x.E[x]) from \nthe calculus.We use a different notation for conts than lambda terms to indicate that in the machine \nconts are distinct from terms (theyare of type Cont rather than type Term in an implementation). Conts \nindicate non\u00adtrivial structural knowledge that the machine retains as it searches for a redex. This distinction \nmatters when we establish continua\u00adtion semantics for machine states. As we shall see, a cont frame represents \na suspended variable reference. Finally we call the frame [. t] an operand frame, and it repre\u00adsents \na term waiting for an abstraction. The abstract machine also introduces a notion of redexes: r ::= at \n| (.x.E) a Redexes are distinguished from terms in the machine, meaning that in an implementation, the \ntype Redex is distinct from the type Term. This distinction suggests that conts (.x.E) are neither terms \nnor .rst-class entities in the call-by-need language: theyonly appear in evaluation contexts and in redexes. \nThe transition rules for the machine are staged into four distinct groups: refocus, rebuild, need, and \nreduce. Each machine con.gu\u00adration can be related to a term in the language of the calculus. The refocus \nrules examine the current term and push as manyoperand frames [. t] as possible.Arefocus con.guration \n.E,t.f represents the term E[t]. .E, t. (Refocus) f .E, x.f .. .E, [ ], x. n .E, .x.t.f .. .E, .x.t.b \n.E, t1 t2.f .. .E . [. t2], t1.f Upon reaching a variable, refocus transitions to the need rules; upon \nreaching a lambda abstraction, it transitions to the rebuild rules. The rebuild rules search up into \nthe context surrounding an an\u00adswer for the next applicable redex.Arebuild con.guration .E, a.b represents \nthe term E[a]. .E, a.b (Rebuild) .[],a.b .. a .E . [. t1],a.b .. .E,a t1.d .E . [(.x..) t1],a.b .. .E, \n(.x.a) t1.b .E1 . [(.x.E2) .],a.b .. .E1, (.x.E2) a.d These rules examine the current context and proceed \nto build a maximal answer-shaped term, progressively wrapping binder frames around the current answer. \nIf the entire context is consumed thenevaluationhas completedandthe entire programisan answer. Upon reaching \nan operand or cont frame, a redex has been found, and rebuild transitions to the reduce rules. These \nrules resemble the refocusaux rules of Danvy and Nielsen (2004). The need rules alsoexamine the context,but \ntheysearch for the binder frame that correspondstothevariable under focus.Aneed con.guration .E1,E2,x. \nn represents the term E1[E2[x]]. .E, E, x. n (Need) .E1 . [(.x..) t], E2, x. n .. .E1 . [(.x.E2) .], \nt.f .E1 . [f], E2, x. n .. .E1, [f] . E2, x. n where, [f] .= [(.x..) t] Since input programs are closed, \nthe associated binder must be somewhere in the context. Upon .nding the right binder frame, a cont frame \n[(.x.E) .] is pushed onto the context and evaluation proceeds to refocus on the operand from the associated \nbinder frame. The reduce rules simulate the notions of reduction from the calculus.Areduce con.guration \n.E, r.d represents the term E[r] where a cont .x.E represents the term .x.E[x]. .E, r.d (Reduce) .E1, \n(.x.E2) v.d .. .E1, (.x.E2[v]) v.f .E1, (.x1.E2) ((.x2.a) t).d .. .E1, (.x2.(.x1.E2[x1]) a) t.f .E, (.x.a) \nt1 t2.d .. .E, (.x.a t2) t1.f .E, (.x.t1) t2.d .. .E . [(.x..) t2],t1.f Each of the .rst two reduce rules \ntransforms a cont into a lambda abstractionbyplugging its context withaterm and abstract\u00ading itsvariable.As \nsuch, each reduce rule transformsa redex intoa pure term of the calculus and transitions to a refocus \ncon.guration, which searches for the next redex. The reduce rules also handle terms of the form (.x.t1) \nt2,even though suchterms are not call-by-need redexes. Including this rule gives the set of redexes greater \nuniformity: all terms of the form at are redexes, just like the terms of the form (.x.E) a. This symme\u00adtry \nis not exhibited in the call-by-need calculus. However, Ariola and Felleisen (1997) de.nes and uses an \nauxiliary let calculus that adds the reduction (.x.t1) t2 .need let x = t2 in t1 to the calculus and \nde.nes the other reductions in terms of the let expressions. The fourth reduce rule corresponds to this \nreduction rule. However, our presentation shows that an auxiliary let term, though compatible with this \nmodel, is not needed to specify call\u00adby-need: the syntax of pure calculus terms suf.ces. Furthermore, \nthe reduce rules are improved in the next section so that all reduce rules change their representative \nterms nontrivially. Machine evaluation of a program t begins with the refocus con\u00ad.guration .[],t.f and \nterminates if it arrives at an answer a. Its behavior in between can be summarized as follows: search \ndown\u00adwards until a value or variable reference is reached. If a variable reference is reached, store \na cont in the context to remember the variable referenceand proceedtoevaluateits binding.Ifan abstrac\u00adtionis \nreached, accumulatean answeruptothe innermostredex,or the top of the evaluation context if none is found. \nIn short, the ma\u00adchine performs a depth-.rst, left-to-right traversal in search of a call-by-need redex. \nAlong the way it uses the evaluation context to store and retrieve information about program structure, \npartic\u00adularly the location of variable bindings (using binder frames) and variable references (using \ncont frames). The refocus, rebuild, and need rules leave the term representation of their con.gurations \nun\u00adchanged (e.g. if .E1,t1.f .. .E2,t2.f then E1[t1] = E2[t2]),and the reduce rules embody the notions \nof reduction from the calculus. Our strategy for producing this machine generalizes the strategy of Danvy \nand Nielsen (2004), which does not account for terms like the call-by-need variable references, which \nare neither redexes nor values, yet cannot be decomposed. The following partial trace demonstrates how \nthis machine dis\u00adcovers the .rst redex for our running example (.x.x) .y.y: .\u00b8 .[], (.x.x) .y.y. .. [. \n.y.y], .x.x.. .\u00b8f .\u00b8f [. .y.y], .x.x.. [], (.x.x) .y.y.. .\u00b8b . d \u00b8 [(.x..) .y.y],x.. [(.x..) .y.y], [],x.. \n. f \u00b8. \u00b8n [(.x.[ ]) .], .y.y.. [(.x.[ ]) .], .y.y.. . f \u00b8b [], (.x.[ ]) .y.y d 4. Re.ning the Machine \nIn this section we study the behavior of the abstract machine and make some improvements based on our \nobservations. These changes lead us from the initial machine above to our .nal ma\u00adchine speci.cation. \n4.1 Grabbing and Pushing Conts The need rules linearly search the nearest context for a binder frame \nthat matches the variable under question. This process can be speci.ed as one step: .E1 . [(.x..) t] \n. E2,x. n .. .E1 . [(.x.E2) .],t.f where [(.x..) t] ./E2 This evaluation step accumulates a segment of \nthe current evalua\u00adtion context and stores it. In general, abstract machines that model control operators \nrepresent control capture in a similar manner. In this particular case, only part of the evaluation context \nis captured, and the amount of context captured depends on the dynamic loca\u00adtioninthe contextofa certain \nframe.As such, the need rules seem to perform some kind of delimited control capture. This analogy be\u00adcomes \nstronger upon further analysis of the .rst reduce rule from Section 3.2. The machine uses its structural \nknowledge of .x.E to construct the abstraction .x.E[v]. However, the resulting machine con.guration no \nlonger retains any of the structure that had pre\u00adviously been discovered. Recall our example execution \ntrace from Section 3.2. The machine reduces the redex found at the end of that trace as follows: .\u00b8 [], \n(.x.[ ]) .y.y.. .[], (.x..y.y) .y.y. df By returning to refocus following the reduction, the machine \nloses all structuralknowledgeofthe term.To continueexecution,it must examine the structure of the contractum \nfrom scratch.Fortunately, theevaluatorcanbesafelyimprovedsothatit retainsknowledgeof the contractum s \nstructure: Proposition 1. .E1, (.x.E2[v]) v.f .-. .E1 . [(.x..) v] . E2,v.b Proof. Corollary of .E1,E2[v].f \n.-. .E1 . E2,v.b, which is proven by induction on E2. This proposition justi.es replacing the .rst reduce \nrule with one that pushes the evaluation context embedded in the cont and proceeds to rebuild an answer: \n.E1, (.x.E2) v.d .. .E1 . [(.x..) v] . E2,v.b This short-circuit rule extends the current evaluation \ncontext with a binder frame and the context E2 that was inside the cont. The rule is suggestive of delimitedcontrol \nbecause machine models of control operators generally represent the reinstatement of delimited continuations \nby extending the current context with a piece of captured evaluation context. Of more immediate interest, \nthough, is how reduction of our example now proceeds: .\u00b8. \u00b8 [], (.x.[ ]) .y.y.. [(.x..)(.y.y)], .y.y \ndb All knowledge of the contractum s structure is retained, though much of it is now stored in the evaluation \ncontext. 4.2 Shifting Binder Frames The second and third reduce rules from Section 3.2 also discard \nstructural information. Speci.cally, theyboth transition to the for\u00adgetful refocus rule. However their \ninformation can be preserved. Proposition 2. .E, (.x.a t2) t1.f .-. .E . [(.x..) t1],a t2.d . Proof. \nCorollary of .E1,a.f .-. .E1,a.b, which is proven by induction on a. Proposition 3. If E2 does not capture \nx1 (Section 4.5), then .E1, (.x2.(.x1.E2[x1]) a) t.f .-. .E1 . [(.x2..) t], (.x1.E2) a.d . Proof. Corollary \nof .E1,a.f .-. .E1,a.b and .E1, (.x1.E2[x1]) t.f .-. .E1 . [(.x1.E2) .],t.f , which is proven by case \nanalysis and induction on E2. These propositions justify short-circuiting the respective eval\u00aduation \nrules. The new rules improve the behavior of the abstract machine. .E1, (.x1.E2) ((.x2.a) t).d .. .E1 \n. [(.x2..) t], (.x1.E2) a.d .E, (.x.a) t1 t2.d .. .E . [(.x..) t1],a t2.d Byfast-forwarding to reduce, \nthe rules retain the discovered term structure and thereby avoid retracing the same terms again. 4.3 \nAnswer = Binders \u00d7 Value The transition rules repeatedly create binder frames out of terms and reabsorb \nthose frames into answers. In this section we simplify this protocol. We distinguish answers from terms \nby providing them a separate representation: a ::= .E, v., where E = [(.xi..) ti] An answer is now represented \nas a tuple containing the nested lambda abstraction and the binder frames that are wrapped around them \nin the old presentation. This presentation bears strong similar\u00adity to calculi with explicit substitutions \n(Abadi et al. 1991), where each binder frame [(.x..) t] corresponds to a substitution [t/x]. An answer \ncan be seen as a lambda term nested inside a sequence of explicit substitutions, v[ti/xi]. The rebuild \nrules could be reformulated as a three place con\u00ad.guration, .E,E,v.b,but instead we immediately applythe \nsame improvement that we applied to the need rules in Section 4.1.For instance, the new transition rule \nfor rebuilding to a cont frame is: .E1 . [(.x.E2) .] . E3,v....E1, (.x.E2) .E3,v.. bd where E3 = [(.xi..) \nti] Returning to our running example, reduction from its most recent state (at the end of Section 4.1) \ntransitions to a .nal answer, signaling the end of execution: .\u00b8. \u00b8 [(.x..) .y.y], .y.y.. .[(.x..) .y.y], \n.y.y. b 4.4 Aggregate Reduction Now that answers explicitly carry their binders in aggregate, the reduce \nrules can be substantially consolidated. Currently, the sec\u00adond and third reduce rules iteratively remove \nthe top binder frame from an answer and push it onto the evaluation context. This pro\u00adcess repeats until \nthe answer is just a lambda abstraction. At that point, the second and third reduce rules defer to the \n.rst and fourth reduce rules respectively. This corresponds exactly with standard\u00adorder reduction (cf. \nDe.nition 1): Proposition 4. E[((.xn. ... ((.x1.((.x0.v) t0)) t1) ... ) tn) t] .-. sr E[((.xn. ... ((.x1.((.x0.v \nt) t0)) t1) ... ) tn)]. E[(.x.E[x]) ((.xn. ... ((.x1.((.x0.v) t0)) t1) ... ) tn)] .-. sr E[((.xn. ... \n((.x1.((.x0.(.x.E[x]) v) t0)) t1) ... ) tn)]. Proof. By induction on the structure of the answer term, \nusing the unique decomposition lemma of Ariola and Felleisen (1997). Using the new answer representation, \neach pair of associated reduce rules can be merged into one omnibus rule that moves all the binder frames \nat once and simultaneously performs a reduction using the underlying value. .E1, (.x.E2) .E3,v..d .. \n.E1 . E3 . [(.x..) v] . E2,v.b .E1, .E2, (.x.t1). t2.d .. .E1 . E2 . [(.x..) t2],t1.f As a result of \nthese transformations, both conts and answers contain evaluation contexts. Furthermore, conts and answers \nare not terms of the calculus, and the machine never reverts a cont or answer to a term. The rules that \ncreate them, rebuild for answers and need for conts, capture part of the evaluation context, and the \nrules that consume them, the reduce rules, reinstate the captured contexts. 4.5 Variable Hygiene Presentationsof \ncalculiofteninvokeahygieneconventionandfrom then on pay little attention to bound or free variables. \nIn this man\u00adner, calculidonot committoanyofthe numerouswaysthathy\u00adgiene can be enforced. Manyabstract \nmachines, however, use en\u00advironmentsorexplicit sourcesof fresh namesto guaranteehygiene and therebyprovideacloser \ncorrespondenceto concrete implemen\u00adtations. In this section, we augment the call-by-need machine with \nsimple measures to enforcehygiene. Our primaryhygiene concerns are thatevaluation occurs under binders \nand binders are shifted about in unusual ways. In order to ensure that binding structure is preserved \nthroughout evaluation, we need to be able to reason locally, within each machine con.gu\u00adration, about \nboundvariables.To make this possible, we make one lastchangetothe machine.Weaddalistof namestoeach machine \ncon.guration. X ::= xi Most of the machine rules simply pass the list of names along to the next transition. \nOne of the reduce rules manipulates the list of names. (D.2) .X | E1, .E2, .x.t1. t2.d .-.nam .. \u00b8 X, \nx. E1 . E2 . [(.x..) t2],t1[x /x]x ./X f When this rule goes undera lambda,itadds the nameof its bound \nvariable to the list X of variables. The notation X, x expresses adding a new name x to X. If the bound \nvariable x on the left hand side of the rule is already a member of X, then the variable is renamed as \npart of the transition. As such, X can be considered a set. Now each machine con.guration has one of \n.ve forms: .X | E, ?. ::= .X | .E, v..|.X | E, r.|.X | E,t. df |.X | E,v.|.X | E, x. bn We use the notation.X \n| E, ?. below to uniformlydiscuss all con\u00ad.guration types, where X refers to the list of names, E refers \nto the context, and ? referstothe termorredex.Fora .nal con.guration .X | .E, v.., ? refers to the answer \ns underlying value v, and E corresponds to the answer s binder frames E.We use the metavari\u00adable C to \nrangeover con.gurations when the internal structure does not matter. The call-by-need abstract machine \nuses the set X of names to keep track of active variables: any variable x whose binding instance has \nbeen pushed into a binder frame [(.x..) t]: AV ([]) = \u00d8 AV (E . [(.x..) t]) = AV (E) .{ x } AV (E . [. \nt]) = AV (E) AV (E . [(.x.E1) .]) = AV (E) .{ x }. AV (E1) Cont-bound variables are counted among the \nactive variables be\u00adcause machine evaluation must have gone under a binding to con\u00adstruct the cont frame. \nThe renaming condition on the (D.2) reduce rule ensures that active variables are mutually distinguishable. \nThis guarantees that the machine s need rule can never capture the wrong evaluation context and thus \nexecute the wrong bound expression. Renaming is not obviously suf.cient to ensure bound variable hygiene \nbecause of how the machine manipulates evaluation con\u00adtexts.For instance,even though the need ruleis \nguaranteedto only match a variable with the right binder frame, we have no guaran\u00adtee that the right \nbinder frame could never be trapped inside a cont frame and hidden from view while a need transition \nsearches for it. Werethistohappen,the machinewouldget stuck. Furthermore,the reduction rules .ip and \nshift evaluation contexts that might contain binder frames. If a binder frame were to end up below another \ncon\u00adtext frame that contains references to its bound variable, then those references would no longer \nbe bound in the context; the need rule would exhaust the evaluation context if it attempted to resolve \nany of these references. To establish that binder frames remain properly positioned, we de.ne a notion \nof well-formed evaluation contexts: X | E wf FV (t) . CV (E) \u00d8| [] wf X | (E . [. t]) wf X | E wf FV \n(t) . CV (E) x/. X X, x | (E . [(.x..) t]) wf X | (E1 . [(.x..)(.x.x)] . E2) wf X | (E1 . [(.x.E2) .]) \nwf which is used to de.ne a notion of well-formed machine con.gu\u00adrations: X | E wf FV (v) . CV (E) .X \n| .E, v.. wf X | (E1 . E3 . [(.x.E2) .]) wf FV (v) . CV (E1 . E3) .X | E1, (.x.E2) .E3,v..d wf X | (E1 \n. E2) wf FV (v) . CV (E1 . E2) FV (t2) . CV (E1) .X | E1, .E2,v. t2.d wf X | E wf FV (t) . CV (E) .X \n| E,t.f wf X | E wf FV (v) . CV (E) .X | E, v.b wf X | E wf { x }. CV (E) .X | E, x. wf n Both well-formedness \nrelations rely on straightforward notions of captured and free context variables: CV ([ ]) = \u00d8 CV ([E \n. (.x..) t]) = { x } . CV (E) CV ([E . . t]) = CV (E) CV ([E . (.x.E1) .]) = CV (E) F V ([ ]) = \u00d8 F V \n([(.x..) t] . E) = F V (t) . (F V (E) - { x }) F V ([. t] . E) = F V (E) . F V (t) F V ([(.x.E1) .] . \nE) = F V (E) . (F V (E1) - { x }) Well-formedness of an evaluation context guarantees that no binder \nframes interfere with each other: Lemma 1. If X | (E1 . E2) wf then AV (E1) n AV (E2)= \u00d8. Proof. By lexicographical \ninduction on the measure (k, n) of E2, where k is its total number of cont frames and n is its linear \nlength. Lemma 2. CV (E) . AV (E). Proof. By induction on the length of E. Well-formedness of con.gurations \ncombined with rule D.2 s name management ensures that machine evaluation respects vari\u00adable binding structure. \nTheorem 3. If t isaclosedtermofthe calculus,then .\u00d8 | [],t.f wf. Proof. \u00d8| [] wf and FV (t) . CV ([ ]) \n= \u00d8. Theorem 4. Let C1 and C2 be con.gurations. If C1 wf and C1 .-.nam C2 then C2 wf. Proof. By cases \non .-.nam. The cases are immediate except for two rebuild rules that transition to reduce con.gurations: \neach ensures by induction that the subsequent reduction step preserves hygiene. In short, well-formedness \nof the reduce con.gurations ensures that the reduce rules can be safely performed without anyimplicit \nrenaming. Since the machine preserves well-formedness, this prop\u00aderty persists throughoutevaluation.The \nrestofthis paperonly con\u00adsiders well-formed con.gurations.  4.6 An Abstract Machinefor Call-by-need \nPutting together our observations from the previous section, we now present the speci.cation of the abstract \nmachine. Figure 1 presentsits transitions rules.Wehave deriveda heap-less abstract machine for call-by-need \nevaluation. It replaces the traditional ma\u00adnipulationofaheapusing store-basedeffectswith disciplined \nman\u00adagement of the evaluation stack using control-based effects. In short, state is replaced with control. \nMachine evaluation of a program t begins with .\u00d8 | [],t.f and terminates at .X | .E, v... 5. Correctness \nof the Machine The previous section proves that the machine manipulates terms in a manner that preserves \nvariable binding. In this section, we prove that those manipulations correspond to standard-order call-by-need \nevaluation. Toproceed, we .rst establish correspondences between abstract machine con.gurations and call-by-need \nterms. As we havealluded to previously, abstract machine contexts correspond directly to calculus contexts: \nC[ []]] = . C[ [. t] . E] = C[ E] t C[ [(.x.E1) .] . E2] =(.x.C[ E1] [x]) C[ E2] C[ [(.x..) t] . E] =(.x.C[ \nE] ) t Redexes also map to call-by-need terms: C[ .E, v. t] =(C[ E] [v]) t C[ (.x.E1) .E2,v.] =(.x.C[ \nE1] [x]) (C[ E2] [v]) Given that terms map identically to terms, con.guration mapping is de.ned uniformly: \nC[ .X | E, ?.] = C[ E] [ C[ ?]] ] Since the calculus is de.ned over alpha equivalence classes, we reason \nup to alpha equivalence when relating terms to machine con.gurations. We now state our fundamental correctness \ntheorems. First we guarantee soundness, the property that every step of the abstract machine respects \nstandard-order reduction. Theorem 5. If t1 = C[ C1] and C1 .-.nam C2,thent1 .-. sr t2, for some t2 = \nC[ C2] . Proof. By cases on .-.nam. Only rules D.1 and D.2 are not immediate. The other rules preserve \nequality under C[ C] . Corollary6(Soundness). If t = C[ C] and C .-. nam .X | .E, v.., then t .-. sr \na, for some a = C[ .X | .E, v..] . Proof. By induction on the length of the .-. nam sequence. We also \nprove completeness, namely that abstract machine re\u00adduction subsumes standard order reduction. Theorem7(Completeness). \nIf t = C[ C] and t .-. sr a, then C .-. nam .X | .E, v.., with a = C[ .X | .E,v..] . Proof. This proof \nproceeds by induction on the length of .-. sr sequences.It utilizes Proposition4to acceleratethe .-.sr \nrules in accordance with .-.nam. It also relies on a number of lemmas to establish that .-.nam will.ndthe \nuniqueredexofatermfromany decomposition of a term into a context E and a subterm t. Theorem8 (Correctness). \nIf t = C[ C] , then t .-. sr a, if and only if C .-. nam .X | .E, v.., with a = C[ .X | .E, v..] . 5.1 \nDiscussion This abstract machine has nice inductive properties. The refocus rules always dispatch on \nthe outermost term constructor. The re\u00adbuild and need rules dispatch on a pre.x of the context, though \neach has different criteria for bounding the pre.x. The abstract machine s evaluation steps should not \nbe seen as merely a desperate search for a redex. Rather, the machine exposes the .ne-grain structure \nof call-by-need evaluation, just as the CK machine and the Krivine machine (Krivine 2007) model evaluation \nfor call-by-value and call-by-name respectively. Answers are the partial results of computations, and \nthe rebuild rules represent the process of reconstructing and returning a result to a reduction site. \nFurthermore, the need rules can be viewed as a novel form of variable-lookup combined with lazy evaluation. \nThe evaluation context capturesthe restof computation,butnotin order:variable references cause evaluation \nto skip around in a manner that is dif.cult to predict. The way that variables behave in these semantics \nreveals a con\u00adnection to coroutines. The reduction rule D.2 binds a variable to a delayed computation; \nreferencing that variable suspends the cur\u00adrent computation and jumps to its associated delayed computation. \nUpon completion of that computation, anynewlydelayed compu\u00adtations (i.e. binder frames) are added to \nthe evaluation context and the original computation is resumed. The standard-order reduction relation \nof the call-by-need lambda calculus de.nes an evaluator concisely but abstractly. Surely unique decomposition, \nstandardization,andhygiene ensure theex\u00adistenceofadeterministicevaluator,but these propertiesdo not spell \nout the details or implications. Based on a reasoned inspection of standard-order reduction, we expose \nits computational behavior and capture it in a novel abstract machine that has no store. The improvements \nto the initial machine produce a variant that effec\u00adtively assimilates computational information, explicitly \naccounts forvariablehygiene and thereby reveals the coarse-grained opera\u00adtional structure of call-by-need \nstandard-order evaluation. 6. Simulating Call-by-need Using Control As we allude to above, call-by-need \nmachine evaluation is highly suggestive of delimited control operations, but the connection is indirect \nand mixed with the other details of lazy evaluation. In this section, we directly interpret this connection \nin the terminology of delimited control. Based on the operational behavior of the abstract machine, we \nderive a simulation of call-by-need execution under call-by-value augmented with delimited control operators. \nIn particular,we trans\u00adlate call-by-need terms into the framework of Dybvig et al. (2007). First we overview \nthe language of delimited control operations. Then we describe how the abstract machine performs delimited \ncontrol operations. Next we present the simulation of call-by-need using delimited control. Finally we \nshow its correctness. 6.1 Delimited Control Operators Dybvig et al. (2007) de.nes a language with delimited \ncontrol operators.Weexplain these operators usinga machine semantics. .X | E, r.d (Reduce) (D.1) .X \n| E1, (.x.E2) .E3,v..d .-.nam .X | E1 . E3 . [(.x..) v] . E2,v.b (D.2) .X | E1, .E2, .x.t1. t2.d .-.nam \n.X, x. | E1 . E2 . [(.x. ..) t2],t1[x./x].f x. ./X .X | E, t.f (Refocus) (F.1) .X | E, x.f .-.nam .X \n| E, x. n (F.2) .X | E, .x.t.f .-.nam .X | E, .x.t.b (F.3) .X | E, t1 t2.f .-.nam .X | E . [. t2], t1.f \n .X | E, v.b (Rebuild) (B.1) .X | Eb,v.b .-.nam .X | .Eb,v.. (B.2) .X | E1 . [. t] . Eb,v.b .-.nam .X \n| E1, .Eb,v. t.d (B.3) .X | E1 . [(.x.E2) .] . Eb,v.b .-.nam .X | E1, (.x.E2) .Eb,v..d where Eb = [(.xi..) \nti] .X | E, x. (Need) n (N.1) .X | E1 . [(.x..) t] . E2,x. .-.nam .X | E1 . [(.x.E2) .],t.f n where \n[(.x..) t] ./E2 Figure 1. Call-by-need Machine t ::= x | v | t t | newPrompt | pushPrompt t t | withSubCont \nt t | pushSubCont t t v ::= .x.t | p | .M. E ::= . | E[. t] | E[(.x.t) .] | E[pushPrompt . t] | E[withSubCont \n. t] | E[withSubCont p .] | E[pushSubCont . t] M ::= [ ] | E : M | p : M p ::= N The language extends \nthe call-by-value untyped lambda calculus with the four operators newPrompt, pushPrompt, withSubCont, \nand pushSubCont as well as two new values: .rst-class prompts p, and .rst-class delimited continuations \n.M.. Its control structure is de.ned usingevaluation contexts E,and metacontextsM ,which are lists that \ninterleave prompts and contexts. Metacontexts use Haskell list notation. Prompts are modeled using natural \nnumbers. A program state comprises an expression t, continuation E, metacontinuation M , and fresh prompt \nsource p. The initial state for a program t is .[t], [], 0. E[(.x.t) v], M, p .. E[t[v/x]], M, p E[newPrompt], \nM, p .. E[p], M, p + 1 E[pushPrompt p1 t], M, p2 .. .[t], p1 : E : M, p2 E[withSubCont p1 .x.t],M1++(p1 \n: M2),p2 .. .[t[.E : M1. /x]],M2,p2 p1 ./M1 E[pushSubCont .M1. t],M2,p .. .[t],M1++(E : M2),p .[v],E \n: M, p .. E[v], M, p .[v],p1 : M, p2 .. .[v], M, p2 The four operators manipulate delimited continuations, \nor subcontinuations, which are part of an execution context. The withSubCont operator takes a prompt \nand a function; it captures the smallest subcontinuation that is delimited by the prompt and passesittothe \nfunction.The non-capturedpartofthe continuation becomes the new continuation. The prompt instance that \ndelimited the captured subcontinuationis discarded:it appearsin neitherthe captured subcontinuation nor \nthe current continuation. This opera\u00adtor generalizes F (Felleisen 1988) and shift (Danvy and Filinski \n1990). The pushSubCont operator takes a subcontinuation and an ex\u00adpression; it composes the subcontinuation \nwith the current contin\u00aduation and proceeds to evaluate its second argument in the newly extended continuation. \nThe pushPrompt operator takes a prompt and an expression; it extends the current continuation with the \nprompt and evaluates the expression in the newly extended continuation. The newPrompt operator returns \na distinguished fresh prompt each time it is called. These two operators generalize the delimiting operators \n# (Felleisen 1988) and reset (Danvy and Filinski 1990), which extend a continuation with a single common \ndelimiter. To illustrate these operators in action, we consider a program that uses arithmetic and conditionals: \nlet p = newPrompt in 2+ pushPrompt p if (withSubCont p (.k.(pushSubCont k False)+ (pushSubCont k True))) \nthen 3 else 4 Afresh prompt is bound top and pushed onto the continuation just prior to evaluation of \nthe if expression. withSubCont captures the subcontinuation [if . then 3 else 4],whichwas delimitedbyp,and \nbinds it to k.The subcontinuation k is pushed twice,given thevalue False the .rst time and True the second. \nThe result of evaluation is the expression 2+4+3 which yields 9.  6.2 Delimited Control Na\u00a8ively Simulates \nthe Machine The call-by-need abstract machine performs two different kinds of partial control capture. \nTo review, the rebuild and need rules of the abstract machine both capture some portion of the evaluation \ncontext. In particular, the rebuild rules capture binder frames. If only binder frames remain, thenexecutionis \ncomplete. When either of the other frames is found, then a reduction is performed. On the Let s bea distinguished \nidenti.er: P[ t] = runCC (let s = newPrompt in pushPrompt s K[ t]]) K[ x] = withSubCont x .k. .fth.do \nva . force fth in delay (return va) as x in pushSubCont k (return va) K[ t1 t2] = do va .K[ t1] in let \nxp = newPrompt in delay K[ t2] as xp in (va xp) K[ .x.t] = return .x.K[ t] return va = withSubCont s \n.ka. .ka,va. do x . t1 in t2 = let .ka,x. = pushPrompt st1 in pushSubCont ka t2 delay t1 as x in t2 = \nlet fk = pushPrompt xt2 in fk .().t1 force f = f () Figure 2. Translating CBN to CBV+Control other hand, \nthe need rule captures the evaluation context up to the binder that matches the variable whose value \nis needed. These actions of the abstract machine can be recast in the lan\u00adguage of delimited control \ncapture. First, the need rule uses the identity of its variable, which must be an active variable, to \ndelimit the context it captures. The well-formedness conditions from Sec\u00adtion 4.5 guarantee that each \nbinder frame binds a unique variable, so each active variable acts as a unique delimiter. Second, the \nre\u00adbuild rule uses the nearest non-binder frame to delimit the context it captures. This means that rebuild \noperates as though the operand frames, the cont frames, and the top of the evaluation context share a \ncommon delimiter. This guarantees that only binder frames are captured (as is stipulated in the rules). \nIn short, call-by-needevaluation captures partialevaluation con\u00adtexts. These partial evaluation contexts \ncorrespond to delimited continuations, and there are two different kinds of delimitation, redex-based \n(for rebuild) and binder-based (for need). It is useful to also consider how the machine manipulates \nthese delimited continuations. Each reduce rulein Figure1immediately pushes the context associated with \nan answer onto the current evaluation context. In this manner, binders are consistently moved above the \npoint of evaluation. The reduce rule then operates on the value part of the answer and the associated \ncont (for D.1)or term (for D.2). Although each reduce rule pushes binders onto the evaluation context, \nonly the D.2 rule creates new binders. The variable bound by the answer s underlying lambda abstraction \nmay already be a member of the set X,in which caseit mustbe alpha-convertedtoa fresh name with respect \nto the set X. Also note that if .x.t is alpha converted to .x..t[x ./x], the body under call-by-value \nsatis.es the equation t[x ./x]=(.x.t) x .. Since we are using the identi.ers x . as delimiters, and we \nnever turn the binder frame [(.x. ..) t] back into a term, we can replace fresh variables x . with fresh \nprompts. From these observations, we construct the simulation in Fig\u00adure 2. The simulation can be understood \nas a direct encoding of the abstract machine semantics for call-by-need.Toexecutea pro\u00adgram, P[ t] , \nthe transformation uses runCC to initiate a control\u00adbased computation, acquires a fresh prompt, and binds \nit to a dis\u00adtinguished variable s. This prompt is the redex prompt, which is used to delimit every continuation \nthat denotes a redex. To expose the conceptual structure of the simulation, we de.ne four syntactic macros, \ndo, return, delay, and force.We accord no formal properties to them: they merely simplify the presentation. \nThe return macro captures the nearest subcontinuation that is de\u00adlimitedby the redex prompt s. Since \nthe s delimiter appears before every reduction, the captured continuation is guaranteed to contain only \ncode equivalent to binder frames. The translation returns a tuple containing the subcontinuation and \nthe argument to return, whichmustbeavalue;thetuple representsananswer.Sothe trans\u00adlation rule for lambda \nabstractions, K[ .x.t] , literally simulates the rebuild rules. The do macro executes a term t1 under \nthe current continua\u00adtion extended with the redex prompt. If the term returns an answer .ka,x. it immediately \npushes the subcontinuation part and contin\u00aduesexecution, bindingthevalueparttothevariable x. As such, \nthe translation rule for applications, K[ t1 t2] , executes [ t1] and binds the resulting operator to \nva. The answer binders are pushed by the do macro, which starts the simulation of the D.2 rule. The remainder \nof the D.2 rule is subtle. In the abstract ma\u00adchine, binder frame variables delimit the need rules. Since \nthe de\u00adlimited continuation framework relies on prompts to delimit con\u00adtinuations, freshprompts literally \nsubstituteforvariables (Kiselyov et al. 2006). The translation uses newPrompt to acquire a fresh prompt \nxp and then uses the delay macro to simulate pushing a binder frame: the context delay t as x in . is \nanalogous to the binder frame [(.x..) t]. The delay macro anticipates that its body returns a function \nfk that expects the delayed argument, so it ap\u00adplies fk to a suspension of t. As we see below, the function \nfk is a cont (.x.E). In the context of delay, the simulation executes va xp. Since al\u00adpha conversion \nof .x.t can be written (.xp.t[xp/x]),the termvaxp is analogous to (.x.t) xp = t[xp/x]: it substitutes \na freshprompt for a fresh variable. The translation rule for variables, K[ x] , captures the continua\u00adtion \ndelimited by x (which had better be a prompt!) and returns a function .fth.... that closesover both x \nand the captured continu\u00adation k. This function is the cont .x.E, with x modeling the bound variable \nof the same name, and continuation k modeling E. The function expects the binder frame [(.x..) t], which \nis now at the top of the current continuation, to pass it the suspension .().[ t] . The simulation forces \nthe suspension, and the do macro pushes the resulting answer binders and binds va to the underlying value. \nPushing the answer binders begins the simulation of the D.1 rule. The simulation of D.1 delays a computation \nthat immediately returns the result va of evaluating the term t, pushes the continua\u00adtion k associated \nwith the cont, and returns va to the extended con\u00adtinuation.Nowanysubsequentevaluationof x immediately \nreturns the memoizedvalue va instead of recomputing t. This yields an an\u00adswer .ka,va. where ka is an \nempty subcontinuation. The value va is delayed exactly as before and is also returned from the properly \nextended continuation. This part of the translation bears close re\u00adsemblance to the paradoxical Y combinator \n(Curry and Feys 1958), suggesting that the simulation requires recursivetypes (Shan 2007). 7. Correctness \nof the Simulation We prove correctness of the simulation relative to the machine semantics. Since we \nalready proved correctness of the machine semantics relative to standard-order reduction, the result \nis a proof that our simulation provides a continuation semantics for call-by\u00adneed. The previous discussion \nprovides an informal justi.cation for the structure of the call-by-need simulation.To prove the correct\u00adness \nof the simulation, we appeal to the continuation semantics newP romptc = .......q.. q . (q + 1) withSubContc \n= .p..f.......f (. : .p) .0 .p .. pushP romptc = .p..t.......t .0 (p : . : .) pushSubContc = .....t....t \n.0 (..++(. : .)) .0 = .v....q.K(v, ., q) K(v, [],q)= v K(v, p : ., q)= K(v, ., q) K(v, . : ., q)= ..q \nFigure 3. Delimited Control Combinators for delimited control (Dybvig et al. 2007). This semantics is \ncom\u00adpletely standard for the terms of the lambda calculus. Figure 3 presents the interesting parts of \nthe semantics. All CPS terms take a standard continuation .,but the control combinators also take a metacontinuation \n., which is a list of continuations and prompts, and a global prompt counter q. The base continuation \n.0 delimits each proper continuation and directs evaluation up the metacontin\u00aduation, discarding anyintervening \nprompts. Given a CPS program t, the expression t.0 []0 runs it. To prove correctness, we compose K[ \u00b7] \nwith the delimited continuation semantics to produce a translation [ \u00b7] .\u00df. to the .\u00df. calculus.We alsogive \neach abstract machine con.guration and its constituentsa denotation(see Figures4through7). [ t] X =[.(xi,X)/xi] \n[ t] .\u00df. [ t] P = .0 (0 : [ ]) 1 .\u00df. [ t] .\u00df. = [ x] .\u00df. withSubContc x .kx..k1.k1 .fth..k2. pushPromptc \n0(fth ()) (. .ka,va.. pushSubContc ka (.k3. pushPromptc x (pushSubContc kx (withSubContc 0 .ka..k.k .ka,va.)) \n(.fk.fk (.().withSubContc 0 .ka..k.k .ka,va.) k3)) k2) = .k1.pushPromptc 0[ t1] .\u00df. [ t1 t2] .\u00df. (. .ka,va.. \npushSubContc ka (.k2. newPromptc .xp.pushPromptc xp (va xp) (.fk.fk (.(). ) k2)) [ t2] .\u00df. k1) [ .x.t] \n.\u00df. = withSubContc 0 .ka..k.k .ka, .x..t..\u00df. . Figure 4. Denotations forTerms Denotations of machine \ncon.gurations are constructed from their components: the con.guration s focus ?, context E, and list \nof names X. A machine con.guration denotes the translation of its focus applied to three arguments: the \nbase continuation .0 as its starting continuation, the denotation of its context, bounded by the redex \ndelimiter 0, as the metacontinuation, and the size |X| of X plus1as its initial prompt. The redex delimiter \nattached to the .(xi,X)= .(xi, [x1,x2,...,xi,...,xn]) = i |X| = |[x1,x2,...,xi,...,xn]| = n [ .X | E, \n?.] .\u00df. = [[?]]X .0 ([[E] X ++(0 : [ ])) (|X| + 1) Figure 5. Denotations for Names and Con.gurations \nmetacontinuation handles the case when an answer subsumes the entire context by returning the answer \nas the result. Our semantic translation takes advantage of X being a proper list of unique names. Free \nactive variables denote prompts in our translation, and since 0 is the redex delimiter, we assign to \neach variable its 1-based index in X. We use |X| +1 as the global prompt counter to ensure that no future \nprompts con.ict with the current activevariable denotations, thereby guaranteeinghygiene (see Section \n4.5). Each evaluation context frame denotes a two-element metacon\u00adtinuation consisting of a prompt and \na proper continuation. The prompt for a binder frame is the prompt translation .(x, X) of the bound variable \nx. The cont and operand frames have redex prompts 0. These prompts guarantee that answer building opera\u00adtions \nwill arrive at the innermost redex. Each continuation function specializes a subexpression of the CPS \ntranslation for terms [ \u00b7] X with the denotations of the context frame s parts. Compare, for in\u00adstance, \nthe denotation of an application, t1 t2, to that of an operand frame, [. t2]. The application term pushes \nthe global prompt, and executes t1 in the context of a continuation that receives an answer .ka,va.. \nThe denotation of the operand frame is a metacontinua\u00adtion containing the same prompt and continuation. \n[ E . [f]]]X = [[[f]]]X ++[ E] X [[[ ]]]X =[] [[[#]]]X = .0 :[] [[[. t2]]]X =0: k. :[] where k. = . .ka,va.. \npushSubContc ka (.k2. newPromptc .xp.pushPromptc xp (va xp) (.fk.fk (.().[ t2] X ) k2)) .0 [[[(.x..) \nt2]]]X = .(x, X): k. :[] where k. = .fk.fk (.().[ t2] X ) .0 [[[(.x.E) .]]]X =0: k. :[] where k. = . \n.ka,va.. pushSubContc ka (.k3. pushPromptc .(x, X) (pushSubContc [ E] X (withSubContc 0 .ka..k.k .ka,va.)) \n(.fk.fk (.().withSubContc 0 .ka..k.k .ka,va.) k3)) .0 Figure 6. Denotations for Evaluation Contexts Aredex \ndenotes a CPS ed term that closes over the denotations of its constituents and implements the corresponding \nreduction step. Tofacilitate ourproofof correctness,wemakea slight change to the machine semantics. In \nthe machine, composing an empty [ .x1.E1 .E2, .x2.t.] X = pushSubContc [ E2] X (.k3. pushPromptc .(x1,X) \n(pushSubContc [ E1] X (withSubContc 0 .ka..k.k .ka, .x2.. t.X .)) (.fk.fk (.().withSubContc 0 .ka..k.k \n.ka, .x2..t.X .) k3)) [ .E, .x.t1. t2] X = pushSubContc [ E] X (.k2. newPromptc .xp.pushPromptc xp ((.x.[ \nt1] X ) xp) (.fk.fk (.().[ t2] X ) k2)) Figure 7. Denotations for Redexes context with the current evaluation \nis an identity operation. The continuation semantics do not share this property. During execu\u00adtion,anempty \ncontinuationis denotedbythebase continuation .0. If a continuation is captured or pushed in the context \nof an empty continuation, then the empty continuation will be captured as part of the metacontinuation \nor pushed onto the current metacontinua\u00adtion before reinstating the pushed continuation. In short, the \ncall\u00adby-need machine semantics guarantees that E . [] = E,but the continuation semantics do not prove \nthat .0 : . = .. Dybvig et al. discuss the notion of proper tail recursion for delimited contin\u00aduations. \nTheir operational characterization of proper tail recursion corresponds to the latter equation. To remove \nthis mismatch, we add a ghost frame [#] to our de.nition of evaluation contexts. The ghost frame denotes \nthe metacontinuation .0 :[]. We also extend the unplug opera\u00adtion on evaluation contexts such that it \ndiscards ghost frames: C[ E . [#]]] = C[ E] . Finally, we alter the right hand side of tran\u00adsition rules \nthat grab and push continuations to pair ghost frames with composed evaluation contexts in a manner consistent \nwith the continuation semantics. For instance, the updated D.2 rule is as follows: (D.2) .X | E1, (.x.E2) \n.E3,v...-.nam d .X | E1 . [#] . E3 . [(.x..) v] . [#] . E2,v.b These modi.cations do not alter the observable \nbehavior of the machine while modeling the property that pushing empty frames has meaning in the continuation \nsemantics. Given these denotations, it is straightforward to prove correct\u00adness of the simulation relative \nto the abstract machine. Theorem 9. If t is a closed term, then [ t] P =[ .\u00d8 | [],t.] . f .\u00df. .\u00df. Proof. \n[ t] P =[ t] .0 (0:[])1= [ .\u00d8 | [],t.] . \u00d8 f .\u00df. .\u00df. Theorem 10. If C1 .-.nam C2 then [ C1] =[ C2] . \n.\u00df. .\u00df. Proof. By cases on .-.nam. The proof utilizes only beta and eta equivalences to establish correspondences. \n8. Conclusions In this paper, we expose and examine the operational structure of lazyevaluation as embodiedin \ncall-by-need semantics.We present this understanding in two ways: as an abstract machine whose op\u00aderational \nbehavior involves control capture, and as a simulation of call-by-need under call-by-value plus delimited \ncontrol operations. Delimited control canbe usedto simulate a globalheap,but our particular simulation \nuses delimited control operations to manage laziness locally, just like the calculus reduction rules. \nThe artifacts of this investigation provide new tools for increas\u00ading our understandingoflazyevaluationandits \nconnectionsto con\u00adtrol. The abstract machine could be used to establish connections to heap-based implementations \nof call-by-need, and possibly mod\u00adern graph-reduction based formulations (Peyton Jones and Salkild 1989). \nInfact it seems that the calculus and abstract machine may point out new structural and dynamic invariants \nthat are inherent to call-by-needevaluationbut are hiddenin the unstructured repre\u00adsentations of heaps. \nThe abstract machine and simulation might also provide new opportunities for reasoning about the correctness \nof transforma\u00adtions applied to call-by-need programs. Surely the calculus pro\u00advides the same equational \nreasoning powers as the abstract ma\u00adchine. However the machine may enable researchers to better in\u00adtuit \ntransformations and justi.cations that are not as easy to rec\u00adognize in the reduction semantics. Our \nsimulation might be con\u00adnected to that of Okasaki et al. (1994). The simulation might sug\u00adgest new mechanisms \nby which to embed call-by-need evaluation within call-by-value programs. One signi.cant difference between \nthe twoformulations of call\u00adby-need lambda calculi (Maraist et al. 1998; Ariola and Felleisen 1997) is \nthe status of variables. Maraist et al. consider variables to be values, whereas Ariola and Felleisen \ndo not. This paper sheds no light on the inclusion of variables among the values, however it demonstrates \nin stark detail the consequences of the latter design. In the abstract machine, the transition rules \nfor lambda terms, namely the rebuild rules, differ signi.cantly from the transition rules for variables, \nthe need rules.Asimilar distinction can be seen simply by observing the complexity of their respective \ntranslations. In short, our semantics interpret variables as memoized computations rather than values. \nOur results reveal that a proliferation of semantic frameworks is a boon and not a crisis. The reduction \nsemantics of call-by-need elegantly and mysteriously encode a rich semantics whose broad implications \ncan be seen in equivalent machine semantics and con\u00adtinuation semantics. As such, our work provides new \nperspectives from which to reason about call-by-need, delimited control, and their respective expressive \npowers. 9. Acknowledgements We thank Daniel P. Friedman, Roshan James, William Byrd, Michael Adams, and \nthe rest of the Indiana University Program\u00adming Languages Group, as well as Jeremy Siek, Zena Ariola, \nPhil Wadler, and anonymous referees for helpful discussions and feed\u00adback on this work. References Mart\u00b4in \nAbadi, Luca Cardelli, Pierre-Louis Curien, and Jean-JacquesL\u00b4 evy. Explicit substitutions. Journal of \nFunctional Pro\u00adgramming, 1(4):375 416, 1991. Zena M. Ariola and Matthias Felleisen. The call-by-need \nlambda calculus. Journal of Functional Programming, 7(3):265 301, May 1997. Zena M. Ariola, John Maraist, \nMartin Odersky, Matthias Felleisen, and PhilipWadler. Acall-by-need lambda calculus. In POPL 95: Proceedings \nof the 22ndACM SIGPLAN-SIGACT Sympo\u00adsium on Principles of Programming Languages, pages 233 246, NewYork,NY, \nUSA, 1995.ACM Press. ISBN 0-89791-692-1. HenkP. Barendregt. The Lambda Calculus, its Syntax and Seman\u00ad \ntics. North-Holland, Amsterdam, NL, 1981. Studies in Logic and theFoundationsof Mathematics. Malgorzata \nBiernacka and Olivier Danvy. Aconcrete framework for environment machines. ACM Transactions on Computa\u00adtional \nLogic, 9(1):6, 2007. ISSN 1529-3785. Haskell Brookes Curry and Robert Feys. Combinatory Logic, VolumeI.StudiesinLogicandtheFoundationsof \nMathematics. North-Holland, Amsterdam, 1958. Second printing 1968. Olivier Danvy and Andrzej Filinski. \nAbstracting control. In LFP 90: Proceedings of the 1990 ACM Conference on LISP and Functional Programming,pages \n151 160,NewYork,NY,USA, 1990.ACM. ISBN 0-89791-368-X. Olivier Danvy and Lasse R. Nielsen. Refocusing \nin reduction se\u00admantics.Technical Report RS-04-26, BRICS,DAIMI, Depart\u00adment of Computer Science, University \nof Aarhus, Aarhus, Den\u00admark, November 2004. R.KentDybvig, SimonPeyton Jones,andAmrSabry.Amonadic framework \nfor delimited continuations. Journal of Functional Programming, 17(6):687 730, 2007. ISSN 0956-7968. \nMatthias Felleisen. The theory and practice of .rst-class prompts. In POPL 88:Proceedingsof the 15thACM \nSIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 180 190, New York, NY, USA, 1988. \nACM. ISBN 0-89791\u00ad252-7. Matthias Felleisen and MatthewFlatt. Programming languages and lambda calculi. \nAvailable from http://www.cs.utah.edu/plt/publications/pllc.pdf, January 2002. Matthias Felleisen and \nDaniel P. Friedman. Control operators, the SECD-machine, and the .-calculus. In M.Wirsing, editor, Formal \nDescription of Programming Concepts, pages 193 217. North-Holland, 1986. Matthias Felleisen and Robert \nHieb.Arevised reporton the syntac\u00adtic theoriesofsequential controland state. Theoretical Computer Science, \n103(2):235 271, 1992. DanielP. Friedman andDavidS.Wise. CONS should notevalu\u00adate its arguments. In S. \nMichaelson andRobin Milner, editors, Automata, Languages and Programming, pages 257 284, Edin\u00adburgh, \nScotland, 1976. Edinburgh University Press. Daniel P. Friedman, Abdulaziz Ghuloum, Jeremy G. Siek, and \nOnnie Lynn Winebarger. Improving the lazy Krivine ma\u00adchine. Higher-Order and Symbolic Computation, 20(3):271 \n293, 2007. Jeremy Gibbons andKeithWansbrough. Tracing lazy functional languages. In Michael E. Houle \nand Peter Eades, editors, Pro\u00adceedings of Conference on Computing: The Australian The\u00adory Symposium, \npages 11 20,Townsville, January 29 30 1996. Australian Computer Science Communications. ISBN ISSN 0157-3055. \nPeter Henderson and James H. Morris, Jr. A lazy evaluator. In POPL 76: Proceedings of the 3rd ACM SIGACT-SIGPLAN \nSymposium on Principles of Programming Languages, pages 95 103,NewYork,NY, USA, 1976.ACM. Yukiyoshi Kameyama, \nOleg Kiselyov, and Chung-chieh Shan. Closing the stage: From staged code to typed closures. In PEPM 08: \nProceedings of the 2008 ACM SIGPLAN Symposium on Partial Evaluation and Semantics-based Program Manipulation, \npages 147 157, NewYork, NY, USA, 2008.ACM. ISBN 978\u00ad1-59593-977-7. Oleg Kiselyov, Chung-chieh Shan, DanielP. \nFriedman, and Amr Sabry. Backtracking, interleaving, and terminating monad trans\u00adformers: (functional \npearl). In ICFP 05: Proceedings of the TenthACM SIGPLAN International Conference on Functional Programming, \npages 192 203, New York, NY, USA, 2005. ACM. ISBN 1-59593-064-7. Oleg Kiselyov, Chung-chieh Shan, and \nAmr Sabry. Delimited dynamic binding. In ICFP 06: Proceedings of the eleventh ACM SIGPLAN international \nconference on Functional pro\u00adgramming, pages 26 37, New York, NY, USA, 2006. ACM. ISBN 1-59593-309-3. \nJean-Louis Krivine. A call-by-name lambda-calculus ma\u00adchine. Higher-Order and Symbolic Computation, 20(3):199 \n207, 2007. John Launchbury. A natural semantics for lazy evaluation. In POPL 93: Proceedings of the 20th \nACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 144 154, New York, NY, USA, \n1993. ACM. ISBN 0-89791\u00ad560-7. John Maraist, Martin Odersky, and Philip Wadler. The call-by\u00adneed lambda \ncalculus. Journal of Functional Programming,8 (3):275 317, May 1998. Eugenio Moggi and Amr Sabry. An \nabstract monadic semantics for value recursion. Theoretical Informatics and Applications, 38(4):375 400, \n2004. Chris Okasaki, Peter Lee, and David Tarditi. Call-by-need and continuation-passing style. Lisp \nand Symbolic Computation,7 (1):57 81, January 1994. Simon L. Peyton Jones and Jon Salkild. The spineless \ntagless G\u00admachine. In FPCA 89:Proceedingsof theFourth International Conference on Functional Programming \nLanguages and Com\u00adputer Architecture, pages 184 201,NewYork,NY, USA, 1989. ACM. ISBN 0-89791-328-0. Gordon \nD. Plotkin. Call-by-name, call-by-value and the .-calculus. Theoretical Computer Science, 1(2):125 159, \nDecember 1975. Peter Sestoft. Deriving a lazy abstract machine. Journal of Func\u00adtional Programming, 7(3):231 \n264, 1997. Chung-chieh Shan. Astatic simulation of dynamic delimited con\u00adtrol. Higher-Order and Symbolic \nComputation, 20(4):371 401, 2007. Gerald Jay Sussman and Guy L. Steele Jr. Scheme: An interpreter for \nextended lambda calculus. Higher Order Symbolic Compu\u00adtation, 11(4):405 439, 1998. ISSN 1388-3690. MitchellWand \nand DaleVaillancourt. Relating models of back\u00adtracking. In ICFP 04: Proceedings of the Ninth ACM SIG-PLAN \nInternational Conference on Functional Programming, pages 54 65,NewYork,NY,USA, 2004.ACM. ISBN 1-58113\u00ad905-5. \nChing-linWang. Obtaining lazyevaluation with continuationsin Scheme. Information Processing Letters, \n35(2):93 97, 1990. ISSN 0020-0190. Hongwei Xi. Evaluation under lambda abstraction. In PLILP 97: Proceedings \nof the Ninth International Symposium on Pro\u00adgramming Languages: Implementations, Logics, and Programs, \npages 259 273, London, UK, 1997. Springer-Verlag. ISBN 3\u00ad540-63398-7.   \n\t\t\t", "proc_id": "1480881", "abstract": "<p>The call-by-need lambda calculus provides an equational framework for reasoning syntactically about lazy evaluation. This paper examines its operational characteristics.</p> <p>By a series of reasoning steps, we systematically unpack the standard-order reduction relation of the calculus and discover a novel abstract machine definition which, like the calculus, goes \"under lambdas.\" We prove that machine evaluation is equivalent to standard-order evaluation.</p> <p>Unlike traditional abstract machines, delimited control plays a significant role in the machine's behavior. In particular, the machine replaces the manipulation of a heap using store-based effects with disciplined management of the evaluation stack using control-based effects. In short, state is replaced with control.</p> <p>To further articulate this observation, we present a simulation of call-by-need in a call-by-value language using delimited control operations.</p>", "authors": [{"name": "Ronald Garcia", "author_profile_id": "81100378849", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1300954", "email_address": "", "orcid_id": ""}, {"name": "Andrew Lumsdaine", "author_profile_id": "81100082403", "affiliation": "Indiana University, Bloomington, IN, USA", "person_id": "P1300955", "email_address": "", "orcid_id": ""}, {"name": "Amr Sabry", "author_profile_id": "81100016804", "affiliation": "Indiana University, Bloomington, IN, USA", "person_id": "P1300956", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480903", "year": "2009", "article_id": "1480903", "conference": "POPL", "title": "Lazy evaluation and delimited control", "url": "http://dl.acm.org/citation.cfm?id=1480903"}