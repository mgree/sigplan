{"article_publication_date": "01-21-2009", "fulltext": "\n The Theory of Deadlock Avoidance via Discrete Control * Yin Wang St\u00b4ephane Lafortune Terence Kelly \nManjunath Kudlur Scott Mahlke University of Michigan Hewlett-Packard Labs University of Michigan {yinw,stephane}@eecs.umich.edu \nterence.p.kelly@hp.com {kvman,mahlke}@umich.edu Abstract Deadlock in multithreaded programs is an increasingly \nimportant problem as ubiquitous multicore architectures force parallelization upon an ever wider range \nof software. This paper presents a the\u00adoretical foundation for dynamic deadlock avoidance in concurrent \nprograms that employ conventional mutual exclusion and synchro\u00adnization primitives (e.g., multithreaded \nC/Pthreads programs). Be\u00adginning with control .ow graphs extracted from program source code, we construct \na formal model of the program and then ap\u00adply Discrete Control Theory to automatically synthesize deadlock\u00adavoidance \ncontrol logic that is implemented by program instrumen\u00adtation. At run time, the control logic avoids \ndeadlocks by postpon\u00ading lock acquisitions. Discrete Control Theory guarantees that the program instrumented \nwith our synthesized control logic cannot deadlock. Our method furthermore guarantees that the control \nlogic is maximally permissive: it postpones lock acquisitions only when necessary to prevent deadlocks, \nand therefore permits maximal run\u00adtime concurrency. Our prototype for C/Pthreads scales to real soft\u00adware \nincluding Apache, OpenLDAP, and two kinds of benchmarks, automatically avoiding both injected and naturally \noccurring dead\u00adlocks while imposing modest runtime overheads. Categories and Subject Descriptors D.3.3 \n[Programming Lan\u00adguages]: Language Constructs and Features Concurrent program\u00adming structures General \nTerms Algorithms, Languages, Theory, Veri.cation Keywords Dynamic Deadlock Avoidance, Discrete Control \nThe\u00adory, Concurrent Programming, Parallel Programming, Multithreaded Programming, Multicore Processors \n1. Introduction The multicore revolution in computer hardware is precipitating a crisis in computer software \nby compelling performance-conscious developers to parallelize an ever wider range of applications, typ\u00adically \nvia multithreading. Multithreading is fundamentally more dif.cult than serial programming because reasoning \nabout concur\u00adrent or interleaved execution is dif.cult for human programmers, * The research of Wang, \nKudlur, Lafortune, and Mahlke is supported in part by NSF grants ECCS-0624821, CCF-0819882, and CNS-0615261, \nand by an HP Labs Open Innovation award. Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 09, January 18 24, 2009, Savannah, Georgia, USA. Copyright c &#38;#169; \n2009 ACM 978-1-60558-379-2/09/01. . . $5.00 and unforeseen execution sequences can include data races. \nPro\u00adgrammers can prevent races by protecting shared data with mu\u00adtual exclusion locks, but misuse of \nmutexes can cause deadlock. This creates yet another cognitive burden for programmers: Lock\u00adbased software \nmodules are not composable, and deadlock free\u00addom isa global program property that is dif.cult to reason \nabout and enforce. These considerations motivate recent interest in mutex alternatives such as atomic \nsections, which guarantee atomic and isolated execution and which may be implemented using transac\u00adtional \nmemory (Larus and Rajwar 2007) or conventional locks (Mc-Closkey et al. 2006). Major attractions of atomic \nsections include deadlock-freedom and composability. This paper considers a different approach to restoring \nthe com\u00adposability that locks destroy and relieving the programmer of the obligation to reason about \nglobal deadlock freedom. We show how to automatically eliminate deadlocks in conventional lock-based \nmultithreaded programs. Our strategy is to avoid deadlock through a combination of of.ine static analysis \nand runtime execution con\u00adtrol: We .rst generate the control .ow graph of a program, then enhance it \nand translate it into a formal model that captures salient features of possible program behaviors. Next, \nwe employ analy\u00adses from Discrete Control Theory to identify potential deadlocks in the model. Finally, \nwe use other Discrete Control Theory tech\u00adniques to synthesize feedback control logic that provably avoids \nthese deadlocks at runtime. The control logic is implemented by program instrumentation and lock function \nwrappers that postpone lock acquisitions as necessary to avoid deadlocks. Discrete Control Theory (DCT) \nis a branch of control theory that considers systems with discrete state spaces and event driven dynamics \n(Cassandras and Lafortune 2007). The analysis and con\u00adtrol synthesis techniques of DCT are model-based; \n.nite automata and Petri nets are the two most popular modeling formalisms. Petri nets date back to the \n1960 s (Petri 1962) and are widely used to model nondeterministic concurrent systems. DCT originated \nwith the seminal work of (Ramadge and Wonham 1987) on supervisory control of systems modeled by .nite \nautomata. A large body of theory has also been developed for controlling systems modeled by Petri nets \n(Holloway et al. 1997; Reveliotis 2005; Iordache and Antsaklis 2006). While classical control theory, \nwhich considers systems modeled by differential or difference equations, has been successfully applied \nto computer systems (Hellerstein et al. 2004), the application of DCT to computer systems problems is \nrelatively recent (Wang et al. 2007). Generally speaking, classical control the\u00adory is better suited \nto problems where the speci.cations are quan\u00adtitative in nature (e.g., throughput, delay, etc.). DCT \nis appropriate for problems with qualitative speci.cations, e.g., avoidance of un\u00addesirable system states; \nsuch speci.cations cannot be handled by classical control methods. The overall feedback control paradigm, \nhowever, is the same in DCT as in classical control: feedback con\u00adtrol logic is automatically designed \nsuch that the closed-loop sys\u00adtem, i.e., the original given system under the control of the feedback \ncontrol logic, satis.es the given speci.cations. offline online compileC program instrumented executable \n source code control control compile logic observe control control control flow graph logic observe \ntranslation control  control logic control control synthesis logic observe logic Petri net instrumentation \nFigure 1. Program control architecture. Our work uses the Petri net modeling formalism because Petri \nnets allow for a compact representation of system dynamics that avoids explicit state enumeration. Petri \nnets can furthermore con\u00adveniently express the nondeterminism and concurrency of multi\u00adthreaded programs. \nMost importantly, DCT control logic synthesis techniques for Petri nets are well suited to the problem \nof deadlock avoidance and these techniques facilitate concurrent control imple\u00admentations that do not \ncreate global performance bottlenecks. Our Petri net models of multithreaded programs have special properties \nthat allow us to customize a known control method for Petri nets to our special subclass to achieve deadlock \nfreedom and maximally permissive control. In the context of our problem, maximal permis\u00adsiveness means \nthat the control logic we synthesize postpones lock acquisitions only when necessary to avert deadlock \nin a worst-case future of the program s execution. With proper program modeling and control speci.cation, \nmaximal permissiveness maximizes run\u00adtime concurrency, subject to the deadlock-freedom requirement. The \nmain contribution of this paper is a detailed description of our customized control synthesis algorithm \nfor Petri nets that model multithreaded programs. We also formally characterize the proper\u00adties of programs \nto which our method has been applied, speci.cally, deadlock freedom and maximal permissiveness, all ensured \nby our methodology. For completeness, we brie.y summarize our proto\u00adtype implementation and experimental \nresults involving randomly generated programs and real software; full details are available in a preliminary \npublication (Wang et al. 2008b) and a separate pa\u00adper devoted to the prototype implementation and empirical \nevalua\u00adtion (Wang et al. 2008a). The remainder of this paper is organized as follows: Section 2 presents \nan overview of our approach and its characteristics. Sec\u00adtion 3 presents our main results on the automatic \nsynthesis of con\u00adtrol logic for deadlock avoidance, and Section 4 describes several extensions. Sections \n5 and 6 summarize our prototype implementa\u00adtion and experimental evaluations of its correctness, performance, \nand usability. Section 7 surveys related work, and Section 8 con\u00adcludes. 2. Overview Figure 1 illustrates \nthe architecture of our approach, which pro\u00adceeds in the following high-level steps: 1. Extract per-function \nControl Flow Graphs (CFGs) from pro\u00adgram source code. We enhance the CFGs to facilitate deadlock analysis \nby including information about lock variable declara\u00adtion and access, and lock-related functions and \ntheir parameters. 2. Translate the enhanced CFGs into a Petri net model of the whole program. The model \nincludes locking and synchronization op\u00aderations and captures realistic patterns such as dynamic lock \nselection through pointers. The model is constructed in such a way that deadlocks in the original program \ncorrespond to struc\u00adtural features in the Petri net.  3. Synthesize control logic for deadlock avoidance. \nBased on the special properties of our Petri net subclass, we customize a known Petri net control synthesis \nalgorithm for this step. The output of this step is the original Petri net model augmented with additional \nfeatures that guarantee deadlock avoidance in the original program. 4. Instrument the program to incorporate \nthe control logic. This in\u00adstrumentation ensures that the real program s runtime behavior conforms to \nthat of the augmented model that was generated in the previous step, thus ensuring that the program cannot \ndead\u00adlock. Instrumentation includes code to update control state and wrappers for lock acquisition functions; \nthe latter avoid dead\u00adlocks by postponing lock acquisitions at runtime.  Our approach decomposes the \noverall deadlock avoidance prob\u00adlem into pieces that play to the respective strengths of existing compiler \nand Discrete Control techniques. Step 1 leverages stan\u00addard compiler techniques, and Step 2 exploits \npowerful DCT results that equate behavioral features of discrete-event dynamical systems (e.g., deadlock) \nwith structural features of Petri net models of such systems. These correspondences are crucial to the \ncomputational ef.ciency of our analyses. The control logic synthesis algorithm we use inStep3iscalled \nSupervision Based on Place Invariants (SBPI) and is the subject of a large body of theory (Iordache and \nAntsaklis 2006). To avoid deadlocks, SBPI augments the original Petri net model with features that constrain \nits dynamic behavior. The instrumentation of Step 4 can embed these features, which im\u00adplement deadlock-avoidance \ncontrol, into the original program us\u00ading primitives supplied by standard concurrent programming pack\u00adages \n(e.g., the mutexes and condition variables provided by the POSIX threads library). The control logic \nembedded in Step 4 is furthermore highly concurrent because it is decentralized through\u00adout the program; \nit is not protected by a big global lock and there\u00adfore does not introduce a global performance bottleneck. \nOur approach brings numerous bene.ts. As shown in the re\u00admainder of this paper, it eliminates deadlocks \nfrom the given pro\u00adgram without introducing new deadlocks or global performance bottlenecks. It does \nno harm, except perhaps to performance, be\u00adcause it intervenes in program execution only by temporarily \npost\u00adponing lock acquisitions; it neither adds new behaviors nor disables functionality present in the \noriginal program. (If deadlock avoid\u00adance is impossible for a given program, our method issues a warn\u00ading \nexplaining the problem and terminates in Step 3.) Discrete Control Theory provides a uni.ed formal framework \nfor reasoning about a wide range of program behaviors (branching, looping, thread forks/joins) and synchronization \nprimitives (mu\u00adtexes, reader-writer locks, condition variables) that might otherwise require special-case \ntreatment. Because DCT is model-based, the modeling of Step 2 is a key step in our methodology. Once \nmodel\u00ading is done properly, the properties of the solution follow directly from results in DCT. The DCT \ncontrol synthesis techniques that we employ guarantee maximally permissive control with respect to the \nprogram model, i.e., the control logic postpones lock acquisitions only when provably necessary to avoid \ndeadlock. This property im\u00adplies that, given a good program model, our approach permits max\u00adimum concurrency \nat run time. The most computationally expensive operations in our approach are performed of.ine (Step \n3), which greatly reduces the runtime overhead of control decisions. In essence, DCT control logic syn\u00adthesis \nperforms a deep whole-program analysis and compactly en\u00adcodes prepackaged decisions that allow the runtime \ncontrol logic to adjudicate lock acquisition requests quickly, while taking into account both current \nprogram state and worst-case future execution possibilities. The net result is low runtime performance \noverhead. Like the atomic-sections paradigm that is the subject of much recent research, our approach \nensures that independently developed software modules compose correctly without deadlocks. However our \nmethods are compatible with existing code, programmers, li\u00adbraries, tools, language implementations, \nand conventional lock\u00adbased programming paradigms. The latter is particularly important because lock-based \ncode currently achieves substantially better per\u00adformance than equivalent atomic-sections-based code \nin some sit\u00aduations. For example, Section 6 shows that lock-based code can exploit available physical \nresources more fully than atomic-based equivalents if critical regions contain I/O. Our approach assumes \nfull responsibility for deadlock in pro\u00adgrams that it deems controllable, i.e., programs that admit dead\u00adlock \navoidance control policies. However, there can be a perfor\u00admance tradeoff. Our approach allows a programmer \nto focus on common-case program logic and write straightforward code with\u00adout fear of deadlock, but it \nremains the programmer s responsibility to use locks in a way that makes good performance possible. \n3. Control Synthesis: Main Results This section presents our main results on control logic synthesis. \nThroughout this section we illustrate our method using the dining philosophers program shown in Figure \n2, where the main thread creates two philosopher threads that each grab two forks in a differ\u00adent order. \nThe program deadlocks if each philosopher has grabbed one fork and is waiting for the other. void * philosopher(void \n* arg) { if (RAND_MAX/2 > random()) { /* grab A first */ pthread_mutex_lock(&#38;forkA); pthread_mutex_lock(&#38;forkB); \n} else { /* grab B first */ pthread_mutex_lock(&#38;forkB); pthread_mutex_lock(&#38;forkA); } eat(); \npthread_mutex_unlock(&#38;forkA); pthread_mutex_unlock(&#38;forkB); } int main(int argc, char *argv[]) \n{ pthread_create(&#38;p1, NULL, philosopher, NULL); pthread_create(&#38;p2, NULL, philosopher, NULL); \n} Figure 2. Dining philosophers program with two philosophers 3.1 Petri Net Preliminaries For the sake \nof completeness, we present a brief primer on Petri nets; see (Murata 1989) for a detailed discussion. \nPetri nets are bi\u00adpartite directed graphs with two types of nodes: circles represent places and solid \nbars represent transitions. Tokens in places are shown as dots. The marking (state) of the Petri net \nis the number of tokens in each place. Transitions model events in the system that change the marking. \nFigure 3 shows how to model common pat\u00adterns of program control .ow using Petri nets. The arcs connect\u00ading \nplaces to a given transition represent the pre-conditions that are necessary for the event associated \nwith that transition to occur. The arcs connecting places from a given transition represent the out\u00adcome \nof the event. For instance, transition t1 in Figure 3(a) can occur only if its input place p1 contains \nat least one token; in this case, we say that t1 is enabled. Similarly, t2 is enabled in this sim\u00adple \nPetri net that models an if/else branch in a program. If transi\u00adtion t1 occurs (or .res in Petri net \nterminology), then it consumes (a) branch (b) loop (c) fork/join (d) lock/unlock Figure 3. Basic Petri \nnet models one token from p1, and produces one token in its output place p2. In general, the .ring of \na transition consumes tokens from each of its input places and produces tokens in each of its output \nplaces; the token count need not remain constant. Petri nets may model loops, as in Figure 3(b), where \nthe .ring of t3 initiates another iteration of the loop. If two or more transitions are both enabled \nsuch that exactly one may .re, as with t1 and t2 in Figure 3(a), the Petri net does not specify which \nwill .re, nor when a .ring will occur. Petri nets are therefore well suited to modeling nondeterminism \ndue to branching and processor scheduling in multithreaded programs. Concurrency is also easily modeled \nin Petri nets. For example, in Figure 3(c), one can think of transition t1 as the thread create operation \nand t2 as the thread join operation. Firing t1 generates two tokens representing the original and the \nchild thread, in places p2 and p3, respectively. After t2, the child thread joins the original thread \nin place p4. In Figure 3(d), place L models a mutex lock, while t1 and t2 model lock acquisition and \nrelease operations, respectively. The token inside L represents the lock, whereas the token in p1 represents \nthe thread. After t1 .res, a single token occupies p2 and L is empty, meaning that the lock is not available \nand t1 is disabled. If a new thread arrives at p1 (via an arc not shown in Figure 3(d)), it cannot proceed. \nFiring t2 returns a token to L, which means that the lock is again available. Formally, we have the following \nde.nition. De.nition 1. APetri net N =(P, T, A, W, M0)is a bipartite graph, where P = {p1,p2, ..., pn} \nis the set of places, T = {t1,t2, ..., tm}is the set of transitions, A .(P \u00d7T ).(T \u00d7P ) is the set of \narcs, W :A .{0, 1, 2, ...}is the arc weight function, and for each p .P , M0(p)is the initial number \nof tokens in place p. The notation p denotes the set of input transitions of place p: p = {t|(t, p) . \nA}. Similarly, p denotes the set of out\u00adput transitions of p. The sets of input and output places of \na tran\u00adsition t are similarly de.ned by t and t . For example in Fig\u00adure 3(a), p1 =\u00d8, p1 ={t1,t2},and \nt1 ={p1}. This nota\u00adtion is extended to sets of places or transitions in a natural way. A transition \nt in a Petri net is enabled if every input place p in t has at least W (p, t)tokens in it. When an enabled \ntransition t .res, it removes W (p, t)tokens from every input place p of t, and adds W (t, p)tokens to \nevery output place p in t . By conven\u00adtion, W (p, t)=0when there is no arc from place p to transition \n t. Throughout this section, our models of multithreaded programs have unit arc weights, i.e., W (a)=1, \n.a .A. Such Petri nets are called ordinary in the literature.  We build the incidence matrix D of a \nPetri net as follows: D . Zn\u00d7m where Dij =W (tj,pi)-W (pi,tj )represents the net change in the number \nof tokens in place pi when transition tj .res. If the net has no self-loop, i.e., at least one of W (pi,tj \n)or W (tj,pi)is equal to zero, then: (i) a negative Dij means there is an arc of weight -Dij from pi \nto tj ; and (ii) a positive Dij means there is an arc of weight Dij from tj to pi. The incidence matrix \nof the Petri net in Figure 3(a) is t1 t2 23 p1 -1-1 D =p2 4 105 p3 01 The marking (i.e., state) of a \nPetri net, which records the number of tokens in each place, is represented as a column vector M of dimension \nn \u00d71with non-negative integer entries, given a .xed T order for the set of places: M =M(p1)\u00b7\u00b7\u00b7M(pn),where \nT denotes transpose. As de.ned above, M0 is the initial marking. For T example, the marking of the Petri \nnet in Figure 3(a) is 100 ; this is the number of tokens in the three places ordered as: p1, p2, T p3.If \nt1 .res, the marking becomes 010 . The reachable state space of a Petri net is the set of all markings \nreachable by transition .ring sequences starting from M0.This state space may be in.nite if one or more \nplaces may contain an unbounded number of tokens. Fortunately we need not consider the reachable state \nspace because we employ techniques from DCT that operate directly upon the relatively compact Petri net \nrather than its potentially vast state space. 3.2 Modeling Multithreaded Programs Our modeling methodology \nbegins with the set of per-function CFGs extracted from the target C program. We augment these CFGs such \nthat in addition to basic blocks and .ow information, lock variables and lock functions are also included. \nEach (aug\u00admented) CFG is a directed graph. To obtain a Petri net we .rst create a place for each node \n(basic block) of this graph. For each arc connecting two nodes in the graph, we create a transition and \ntwo arcs in the Petri net: one from the place corresponding to the originating node to the transition, \nand one from the transition to the place corresponding to the destination node. Overall, a basic block\u00adtransition-basic \nblock chain in the CFG is converted into a place\u00adarc-transition-arc-place chain in the corresponding \nmodel; see for example Figures 3(a) and 3(b). The execution of a thread is modeled as a token .owing \nthrough the Petri net. In order to model lock acquisition/release functions appropriately, we split a \nbasic block that contains multiple lock functions into a sequence of blocks such that each block has \nat most one lock function associated with it. Therefore, after model translation, each lock operation \nis represented by a single transition in the Petri net. Similarly, a basic block containing multiple \nuser\u00adde.ned functions is split such that each function call is represented by one place in the Petri \nnet. With this split, we can substitute the function call place with the Petri net model of the called \nfunction. A new copy of the called function s Petri net is substituted at each distinct call site. In \nother words, we build inlined Petri net models. Functions that do not invoke lock operations need not \nbe con\u00adsidered in the modeling phase. We further prune fractions of the inlined Petri net model that \nare irrelevant to deadlock analysis. Fi\u00adnally, if the program uses different sets of locks in different \nmod\u00adules, we decompose the Petri net and apply the control synthesis algorithm to each subnet separately. \nThese simple preprocessing techniques are highly effective in shrinking real program models to a manageable \nsize. Additional details are available in (Wang et al. 2008b). If recursions occur in the pruned Petri \nnet, we handle them in a similar way as we model program loops. Each recursion is substituted by exactly \none copy of every function involved in the recursion. Subsequent recursive calls inside these functions \nare linked back to themselves. Control synthesis treats these recursion (a) CFG (b) Translated Petri \nNet Figure 4. Modeling the Dining Philosopher Example loops as normal loops. Online instrumentation, \nhowever, must track recursive calls and know when the program leaves the recursion by augmenting parameters \nof functions involved in the recursion. Modeling multithreaded synchronization primitives using Petri \nnets has been studied previously in the literature; see (Kavi et al. 2002). We apply these known techniques \nto model locking primi\u00adtives. For example, thread creation and join are modeled as illus\u00adtrated in Figure \n3(c). To model mutex locks, we add a new place for each lock, called a lock place, with one initial token \nto repre\u00adsent lock availability. If a transition represents a lock acquisition call, we add arcs from \nthe lock place to the transition. If a transi\u00adtion represents a lock release call, we add arcs from the \ntransition to the lock place; see Figure 3(d). With these modeling techniques, we are able to build a \ncomplete Petri net model of a given concurrent program. Figure 4(a) is the control .ow graph of function \nphilosopher in the example in Figure 2. There are four basic blocks, representing start, if branch, else \nbranch and the rest of the function. Figure 4(b) is the translated Petri net model of the CFG. The structure \nis similar to the CFG, with lock places added. Basic blocks containing multiple lock functions are split \ninto sequences of places and transitions such that each lock function is represented by a single transition \nin the net, as annotated. 3.3 Controlling Petri Nets by Place Invariants The purpose of control logic \nsynthesis for Petri nets is to avoid un\u00addesirable or illegal markings. Appropriate formal speci.cations \nthat characterize these undesirable markings are needed. A com\u00admon form of speci.cation is the linear \ninequality lT M =b (1) where l is a weight (column) vector, M is the marking, and b is a scalar; b and \nthe entries of l are integers. Equation (1) states that the weighted sum of the number of tokens in each \nplace should be greater than or equal to a constant. We will show in Section 3.4 how to attack deadlock \navoidance using such speci.cations. Markings violating the linear inequality in Equation (1) must be \navoided by control as they are illegal; all other markings are permitted. It turns out that this condition \ncan be achieved by adding anew control place to the net with arcs connecting to transitions in the net. \nThe control place blocks (disables) its output transitions when it has an insuf.cient token count. This \nmethod is formally stated as follows. Theorem 1. (Iordache and Antsaklis 2006) If a Petri net N = (P, \nT, A, W, M0)with incidence matrix D satis.es b - lT M0 = 0 (2) then we can add a control place c that \nenforces Equation (1). Let Dc :T . Z denote the weight vector of arcs connecting c with the transitions \nin the net; Dc is obtained by Dc =lT D (3) The initial number of tokens in c is M0(c)=lT M0 - b = 0 (4) \n The control place enforces maximally permissive control logic, i.e., the only reachable markings of \nthe original net N that it avoids are those violating Equation (1). The above control technique is called \nSupervision Based on Place Invariants (SBPI). It maintains the condition in Equation (1) by building \na place invariant with the newly added control place. The place invariant guarantees that for any marking \nM in N s set of reachable markings, lT M - M(c)=b,where M(c)is the number of tokens in the control place \nc.Since M(c)is non\u00adnegative, the inequality in Equation (1) is satis.ed. Equation (2) states that Equation \n(1) must be satis.ed for M0, otherwise there is no solution. Equation (3) shows that SBPI operates on \nthe net structure (in\u00adcidence matrix) directly without the need to enumerate or explore the set of reachable \nmarkings of the net; this greatly reduces the complexity of the analysis. Equally importantly, SBPI guarantees \nthat the controlled Petri net is maximally permissive, i.e., a transi\u00adtion is not disabled (by lack of \ntokens in control place c) unless its .ring leads to a marking where the linear inequality is violated \n(Ior\u00addache and Antsaklis 2006). In other words, it enforces just enough control to avoid all illegal \nmarkings. SBPI is the basis for our deadlock avoidance control synthesis algorithm. Speci.cally, SBPI \neliminates potential deadlocks that we discover via siphon analysis. 3.4 Deadlocks and Petri Net Siphons \nTo achieve the objective of deadlock avoidance in a concurrent program using SBPI, we need to express \ndeadlock freedom using linear inequality speci.cations. This is done by means of siphon analysis. De.nition \n2. A siphon is a set S of places such that S . S . Intuitively, since the input transition set is a subset \nof the output transition set, if a siphon S becomes empty, every output transition in S is disabled and \ntherefore no input transition can .re. As a result, the set of places S will remain empty forever and \nthe transitions in S will never .re again. For example, the set of places {A, B, p6,p7}, marked by crosses \nin Figure 5, is a siphon. It becomes empty when each philosopher acquires one fork and waits for another. \nIn this situation, no place in the siphon ever gains any token; indeed, we have a deadlock. Our Petri \nnet models have special properties that allow us to identify deadlocks in the original program by identifying \nsiphons in the corresponding Petri net model. Recall from Section 3.1 that our Petri nets are ordinary \n(all arcs have unit weight). Let NG denote the Petri net model of a concurrent program. Let the part \nof NG that corresponds to the control .ow graph be denoted by NCFG; in other words, lock places are excluded \nin NCFG.By construction, all the transitions in NCFG have exactly one input place and exactly one output \nplace. Clearly, the only siphon in NCFG is the entire set of places, which cannot become empty during \nthe execution of the program. Therefore, any siphon in NG must include lock places. We build from the \nfollowing known result in the literature. Theorem 2. (Reisig 1985) A totally deadlocked ordinary Petri \nnet contains at least one empty siphon. In this theorem, total deadlock refers to a Petri net state in \nwhich no transition is enabled. In our analysis, we are interested in circular-mutex-wait deadlocks, \nnot total deadlocks. However, in our class of Petri net models, the presence of a circular-mutex-wait \ndeadlock implies that NG contains an empty siphon. To see this, consider a Petri net state that models \na program with a circular\u00admutex-wait deadlock. Consider only the subnet involved in the circular-mutex-wait \ndeadlock, and only the tokens representing the deadlocked threads. This subnet has no enabled transition. \nAccording to Theorem 2, it contains at least one empty siphon. This siphon is also empty in the original \nPetri net state. Consider next the reverse implication of Theorem 2: what if the net contains an empty \nsiphon in some reachable marking? An empty siphon cannot gain any token back and therefore the cor\u00adresponding \ntransitions are permanently disabled. Since an empty siphon in our Petri net model must include lock \nplaces, these lock places remain empty as well, meaning that the threads holding these locks will never \nrelease them. This could be due to a thread that simply acquires a lock and never releases it. We handle \nthe pre\u00adceding scenario separately in our control logic synthesis. For the purpose of the present analysis, \nwe assume that threads eventually release all the locks that they acquire. Under this assumption, empty \nsiphons that include lock places correspond to circular-mutex-wait deadlocks. Combining this result with \nTheorem 2, we have the fol\u00adlowing important result: Theorem 3. The problem of deadlock avoidance in a \nconcurrent program is equivalent to the problem of avoidance of empty siphons in its ordinary Petri net \nmodel NG. Theorem 3 establishes a relationship between deadlock, which is a behavioral property, and \nsiphons, which are structural features. The latter can be identi.ed directly from the incidence matrix \nwithout exploring the set of reachable markings (Boer and Murata 1994). In some cases, a siphon cannot \nbecome empty in any reachable marking. For example, places L and p2 in Figure 3(d) form a siphon. Once \nempty, they remain empty forever. But with an initial token in L, these two places will never become \nempty. In fact, a token will always occupy one of the two places in any reachable marking. When synthesizing \ndeadlock avoidance control logic, it is important to distinguish siphons that may become empty from those \nthat cannot. Control need only be synthesized to address the former; the latter may safely be ignored. \n 3.5 Control Logic Synthesis for Deadlock Avoidance Given Theorem 3, our objective is to control the \nPetri net model of a concurrent program in a manner that guarantees that none of its siphons ever becomes \nempty. For this purpose, it is suf.cient to consider only minimal siphons, i.e., those siphons that do \nnot contain other siphons. This goal is translated into speci.cations of the form in Equation (1) as \nfollows: The sum of the number of to\u00adkens in each minimal siphon is never less than one in any reachable \nmarking. SBPI adds a control place to the net that maintains Equa\u00adtion (1) for each minimal siphon. For \nexample, consider again the Petri net in Figure 5 (without the place and arcs that are dashed); to prevent \nthe minimal siphon {A, B, p6,p7} in this net from being emptied, we de.ne T l=000001111 ,b =1 (5) Figure \n5. Controlled Dining Philosophers Example where the order of the places for vectors M and lis: p1,...p7,A,B. \nIn this case, Equation (1) means that the total number of tokens in places p6, p7, A,and B should not \nbe less than 1. The incidence matrix of the net in Figure 5 is (with transitions ordered according to \ntheir subscripts): 2-1 -1 0 0 0 0 0 03 1 0 -1 0 0 0 0 0 6 7 6 0 1 0 -1 0 0 0 07 6 7 6 0 0 1 0 -1 0 0 \n07 6 7 D =6 0 0 0 1 0 -1 0 07 (6) 6 7 6 0 0 0 0 1 1 -1 07 6 6 0 0 0 0 0 0 1 -1 7 7 4 0 0 -1 0 0 -1 0 \n15 0 0 0 -1 -1 0 1 0 Applying Equatio ns (3 a nd 4), we have Dc = 00 -1 -10 01 0 ,M0(c)=1 (7) which \nmeans that the control place has output arcs to transitions t3 and t4, and an input arc from transition \nt7; all these arcs have weight one. The control place has one initial token. This control place and its \nassociated arcs are shown with dashed lines in Fig\u00adure 5. The Petri net including the control place is \ncalled the aug\u00admented net. From Theorem 1, we know that the place invariant lT M - M(c)=1always holds \nfor any reachable marking M, and therefore the siphon is never empty. It would be wrong to conclude from \nthis simple example that our approach simply coarsens locking or adds meta-locks. This is a reasonable \ninterpretation of the control place in Figure 5, but in general the control logic that our procedure \nsynthesizes admits no such simple characterization, as we shall see when we consider how our approach \nhandles real-world deadlock bugs in Apache and OpenLDAP. A dif.culty that arises in the preceding methodology \nis that the newly added control places (one per minimal siphon in the net) could introduce new siphons \nin the augmented net. Intuitively, SBPI avoids deadlocks at the last lock acquisition step, i.e., the \nlock acquisition that completes the circular wait. Sometimes this is too late. While the control place \nblocks the transition immediately leading to the deadlock, there may be no other transition the pro\u00adgram \ncan take. This is a deadlock introduced by the control place. Fortunately, this deadlock implies the \nexistence of a new siphon in the augmented Petri net that includes the control place. Therefore, Input \nPetri net NG that models the program Output Augmented NG with control places added Step 1 Let Rbe the \nset of places representing mutex locks Step 2 Find all minimal siphons in NG that include at least one \nplace in R and can become empty; if no siphon found, goto End Step 3 Add a control place for every siphon \nfound in Step 2 Step 4 Remove redundant control places added in Step 3;let Rbe the set of control places \nremaining; goto Step 2 End Output NG with all control places added Figure 6. Control Synthesis Algorithm \nwe can apply SBPI again and iterate until both the deadlocks in the original program and deadlocks introduced \nby control logic are avoided. The iterative procedure is de.ned in Figure 6. Step 4 refers to redundant \ncontrol places. Those are control places that achieve redundant control objectives as compared with control \nplaces added in earlier iterations. Details on how we check whether a siphon can become empty and how \nwe remove redundant control places are described in (Wang et al. 2008b). Combining the results of Sections \n3.3 and 3.4 with the proce\u00addure in Figure 6, we have the following corollary: Corollary 4. After the \niterative procedure of Figure 6, we know that the augmented Petri net with control places has no reachable \nempty siphon. If the arcs connecting the added control places to the transitions of the original net \nall have unit weight, then by The\u00adorem 3 we conclude that the augmented net models the deadlock\u00adfree \nexecution of the original multithreaded program. Moreover, by Theorem 1, the behavior of the augmented \nnet is the maximally\u00adpermissive deadlock-free sub-behavior of the original net. If a newly added control \nplace has a non-unit-weight arc to a transition of the original net, then deadlock in the multithreaded \nprogram does not necessarily imply an empty siphon in the net as Theorem 2 is not directly applicable. \nTheorem 2 can be general\u00adized to the case of non-unit arc weights; in this case liveness is not entirely \ncharacterized by empty siphons, but rather by the notion of deadly marked siphons from (Reveliotis 2005). \nIn this case, further behavioral analysis of the siphons is necessary; details are omitted here. In practice, \nin our experiments so far with the spe\u00adcial Petri net subclass modeling multithreaded programs, our iter\u00adative \nSBPI algorithm has converged quickly without introducing non-unit arc weights. This has been observed \non both randomly generated programs and real-world software including Apache and OpenLDAP. 3.6 Control \nLogic Implementation The output of the control logic synthesis algorithm is an augmented version of the \ninput Petri net, to which have been added control places with incoming and outgoing arcs to transitions \nin the original Petri net. An outgoing arc from a control place will effectively delay the target transition \nuntil a token is available in the control place; the token is consumed when the transition .res. An incoming \narc from a transition to a control place replenishes the control place with a token when the transition \n.res. Outgoing arcs from control places always link to lock acquisition calls, which are the transitions \nthat the runtime control logic controls. Incoming arcs originate at transitions corresponding to lock \nrelease calls or branches, which are the transitions the control logic must observe. A lock acquisition \ntransition that needs to be controlled has one or more incoming arcs from control places, as illustrated \nin (a) Transition to be controlled (b) Transition to be observed Figure 7. The control logic implementation \nproblem Figure 7(a), where L is the real lock in the program that has to be acquired, and C1,C2,...Cn \nare control places that link to the transition. A transition that needs to be observed has one or more \noutgoing arcs to control places, as illustrated in Figure 7(b). For the sake of generality, Figures 7(a) \nand 7(b) show several control places connected to a given transition. In practice, the number of control \nplaces connected to a transition is very small, typically only one. As Figure 7 suggests, control places \nresemble lock places, and therefore can be implemented with primitives supplied by standard multithreading \nlibraries, e.g., libpthread. Controlled Transitions For a lock acquisition transition that needs to be \ncontrolled, the control logic must check the token avail\u00adability of all input places to that transition. \nThese include the lock place in the original net model as well as all the control places that were added \nby the procedure in Figure 6, as depicted in Fig\u00adure 7(a). We replace the native lock-acquisition function \nwith our wrapper to implement the required test for these transitions. The wrapper internally uses two-phase \nlocking with global ordering on the set of control places to obtain the necessary tokens. If a control \nplace does not have enough tokens, the wrapper returns all tokens it has obtained from other control \nplaces, and waits on a condition variable that implements this control place; this effectively delays \nthe calling thread. Once the token becomes available, the wrapper starts over again to acquire tokens \nfrom all control places. Observed Transitions For a transition that needs to be ob\u00adserved, i.e., with \noutgoing arcs to control places as shown in Fig\u00adure 7(b), we insert a control logic update function that \nincreases the token count and signals the condition variables of the correspond\u00ading control places. Figure \n8 is the lock wrapper implementation for Figure 7(a) using the Pthread library. Each control place Ci \nis implemented as a three-tuple {n[i], l[i], c[i]},where n[i] is an integer representing the number of \ntokens in Ci, l[i] is the mutex lock protecting n[i],and c[i] is the condition variable used when a thread \nis waiting for token in the control place. The following theorem establishes that the above-described \nim\u00adplementation of control places does not introduce livelock into the instrumentation: Two or more threads \ncannot become permanently stuck executing the outer loop in the wrapper function code of Figure 8. Theorem \n5. With the implementation of Figure 8 and global order\u00ading of l[i], if a set of threads competes for \ntokens in control places, at least one thread will acquire all required tokens from the control places \nand succeed in .ring the corresponding transition. start: pthread_mutex_lock(&#38;L); /* acquire real \nlock */ for (i=1; i<=n; i++) { pthread_mutex_lock(&#38;l[i])); /* check Ci */ if (0 < t[i]) { /* has \ntoken in Ci */ n[i]--; /* take one token */ pthread_mutex_unlock(&#38;l[i])); } else { /* no token in \nCi */ pthread_mutex_unlock(&#38;L); /* release real lock */ for (j=i-1; j>=1; j--) { /* replenish all \ntokens */ pthread_mutex_lock(&#38;l[j]); n[j]++; pthread_cond_signal(&#38;c[j]); pthread_mutex_unlock(&#38;l[j]); \n} pthread_cond_wait(&#38;c[i], &#38;l[i]); /* wait on Ci */ pthread_mutex_unlock(&#38;l[i])); goto start; \n/* start over once signaled */ } } Figure 8. Lock wrapper implementation for the example of Fig\u00adure 7(a). \nA control place Ci is associated with integer n[i] repre\u00adsenting the number of tokens in it; lock l[i] \nand condition variable c[i] protect n[i]. These are global variables in the control logic implementation. \nProof. Assume TD = {T1,T2,...Tu} is the set of threads compet\u00ading for tokens in the set of control places \nCP = {C1,C2,...Cv }. Without loss of generality, let us also assume every thread in TD is at the start \nlabel of the lock wrapper in Figure 8, i.e., no thread has consumed any token in CP yet, and every other \nthread is ei\u00adther sleeping or waiting on some (real) lock. Then CP must have enough tokens for at least \none thread in TD to go through. Oth\u00aderwise all threads are permanently waiting and this is a deadlock, \nwhich is provably avoided by our control synthesis algorithm. Assume CP has enough tokens for T1 to get \nthrough. If T1 failed to get a token from a control place, say C1,some other thread in TD,say T2, must \nhave acquired the token in C1 before T1 attempted to acquire it. If T2 failed to get the token in a control \nplace, say C2, there are two cases: (1) C2 does not have any tokens at all to start with or (2) some \nother thread in TD has temporarily acquired it .rst. In the .rst case, T2 will sleep and not compete \nwith threads in TD anymore. Furthermore, T2 will release the token to C1 and wake up T1 before it goes \ninto sleep. Then we can repeat the analysis for T1 all over again. In the second case, the token in C2 \ncannot be temporarily acquired by T1 because of the assumed global ordering on control places. Assuming \nT3 has temporarily acquired the token in C2, we could follow the same analysis performed on T2. Eventually, \neither some thread in TD gets all tokens needed or every thread other than T1 goes to sleep, in which \ncase T1 will be awakened and obtain all tokens needed. As shown in Figure 8, our current controller implementation \ndoes not address the scheduling of threads onto locks; underly\u00ading infrastructure (threading library \nand OS) is responsible for this. Whether our control logic introduces scheduling issues (e.g., prior\u00adity \ninversion, starvation) depends on the semantics provided by the underlying infrastructure.  4. Control \nSynthesis: Extensions Section 3 presented the main results of our deadlock avoidance methodology for \nconcurrent programs. This section discusses ex\u00adtensions to the basic method and additional topics relevant \nto our problem domain. Figure 9. Reader-Writer Lock 4.1 Model Extensions Our control synthesis algorithm \nis not limited to circular-mutex\u00adwait deadlocks. Rather, it depends on what is included in the Petri \nnet model of the program. With the rich representation capabili\u00adties of Petri net models, it is relatively \neasy to model other mul\u00adtithreaded synchronization primitives and thereby to automatically address deadlocks \ninvolving them. We discuss a few examples. Semaphores A semaphore is essentially a lock with multi\u00adple \ninstances that can be acquired/released by different threads repeatedly through down/up operations. Therefore, \nsemaphores share the same model as locks except that the initial number of tokens in a semaphore place \nmay exceed one. Reader-Writer Locks Modeling reader-writer locks is illus\u00adtrated in Figure 9. The initial \nnumber of tokens in the lock place represents the maximum number of readers allowed. A reader can acquire \nthe lock as long as at least one token is available, while a writer must acquire all of the tokens. When \nthe maximum num\u00adber of readers is not speci.ed by the program, we can use a suf.\u00adciently large initial \nnumber of tokens, e.g., greater than the num\u00adber of threads allowed. Note that the right-hand arcs in \nFigure 9 both have weight n. Theorem 2 presented earlier requires unit arc weights as an assumption. \nAs was mentioned in Section 3.5, Theo\u00adrem 2 can be generalized to the case of non-unit arc weights. This \ncomplicates the procedure of generating the control logic for dead\u00adlock avoidance and is not discussed \nin this paper. Condition Variables Condition variable models include a place that models the signal variable \nand transitions that model wait, signal,and broadcast calls. We use a separate place, with no initial \ntoken, to represent each signal. The place gains tokens with signal/broadcast transitions and loses tokens \nwith wait transitions. In addition to the input arc from the signal place, the wait transition must represent \nthe fact that the mutex lock is released during wait and reacquired once the signal is available. In \naddition, a complete model should also include signal loss (when the thread to be awakened is not waiting \non the condition variable); see (Kavi et al. 2002) for further discussion. Condition variables are another \nmajor source of deadlocks in multithreaded programs, and it is very dif.cult to reason about them. However, \nonce condition variables are included in our Petri net models, condition-variable deadlocks can be identi.ed \nthrough siphon analysis in the same manner as mutex deadlocks are found. Figure 10 shows a condition \nvariable deadlock from the Apache bug database (Apache). This deadlock is introduced by a mutex together \nwith condition variables. The listener thread waits on a condition variable while holding the timeout \nmutex. The worker thread acquires then releases timeout, then signals the listener. If the listener thread \nis already waiting before the worker thread acquires timeout, the signal is never sent and the two threads \ndeadlock in the calls indicated by comments. Figure 11 is the Petri net model of the code in Figure 10. \nFor simplicity we show only basic signal operations. Details like the release and reacquisition of locks \nwith the wait call are not shown. Places marked by crosses form the siphon corresponding to the listener_thread(...) \n{ ... apr_thread_mutex_lock(timeout_mutex); ... rv = apr_thread_mutex_lock(queue_info->idlers_mutex); \n... rv = apr_thread_cond_wait(queue_info->wait_for_idler, queue_info->idlers_mutex); /**/ ... rv = apr_thread_mutex_unlock(queue_info->idlers_mutex); \n... apr_thread_mutex_unlock(timeout_mutex); ... } worker_thread(...) { ... apr_thread_mutex_lock(timeout_mutex); \n/**/ ... apr_thread_mutex_unlock(timeout_mutex); ... rv = apr_thread_mutex_lock(queue_info->idlers_mutex); \n... rv = apr_thread_cond_signal(queue_info->wait_for_idler); ... rv = apr_thread_mutex_unlock(queue_info->idlers_mutex); \n... } Figure 11. Simpli.ed Petri net model for the Apache deadlock, bug #42031. deadlock bug. The control \nplace added guarantees that the siphon will never empty. The control place prevents the listener thread \nfrom acquiring the timeout mutex until the worker thread has released it and is able to signal the listener. \nThis control logic is maximally permissive as it allows the listener thread to proceed after the worker \nthread releases the timeout mutex.  4.2 Partial Controllability and Observability So far, we have assumed \nthat every transition in the Petri net is controllable, i.e., it can be prevented from .ring if we append \na control place to its set of input places. Therefore, if a transition has an incoming arc from a control \nplace after the control synthesis procedure, the control logic effectively blocks that transition when \nldap_pvt_thread_rdwr_wlock(&#38;bdb->bi_cache.c_rwlock); /* LOCK(A) */ ... ldap_pvt_thread_mutex_lock( \n&#38;bdb->bi_cache.lru_mutex ); /* LOCK(B) */ ... ldap_pvt_thread_rdwr_wunlock(&#38;bdb->bi_cache.c_rwlock); \n/* UNLOCK(A) */ ... if ( bdb->bi_cache.c_cursize>bdb->bi_cache.c_maxsize ) { ... for(...){ ... ldap_pvt_thread_rdwr_wlock(&#38;bdb->bi_cache.c_rwlock); \n/* LOCK(A) */ ... ldap_pvt_thread_rdwr_wunlock(&#38;bdb->bi_cache.c_rwlock); /* UNLOCK(A) */ ... } } \n... ldap_pvt_thread_mutex_unlock(&#38;bdb->bi_cache.lru_mutex); /* UNLOCK(B) */ Figure 12. OpenLDAP deadlock, \nbug #3494. the control place has an insuf.cient token count. In our problem, however, not every transition \nis controllable. For example, transi\u00adtions representing if/else branches or loops are not controllable. \nWe cannot force the program to take one branch instead of the other. In our application, the only controllable \ntransitions are those representing lock acquisitions. Partial controllability refers to the situation \nwhere not every transition in the net is controllable. When a control place added by the control synthesis \nalgorithm has outgoing arcs to an uncon\u00adtrollable transition in the net, then the corresponding control \nlogic is not implementable. Synthesizing control logic for a partially con\u00adtrollable net in general requires \ncorrectness-preserving linear con\u00adstraint transformation (Iordache and Antsaklis 2006). The trans\u00adformed \nconstraints guarantee that control places added by SBPI have output arcs to controllable transitions \nonly, while satisfying the original linear inequality speci.cations. The synthesis of con\u00adtrol logic \nunder partial controllability is in general more conserva\u00adtive than under the case of full controllability. \nA version of maximal permissiveness can still be achieved in this case, in the sense that the control \nlogic should not block any transition unless the execu\u00adtion of that transition can lead to an undesired \nstate unavoidably, i.e., through a sequence of uncontrollable transitions. We illustrate the controllability \nissue with an actual OpenLDAP bug (OpenLDAP) shown in Figure 12, where clarifying comments are inserted. \nThe deadlock may occur if thread 1 locks A and B, then releases A. Before thread 1 reacquires A, thread \n2 executes the same code, which acquires A then B. Assuming full controllability, the control logic would \nallow thread 2 to enter and acquire lock A, then force thread 1 to jump out of the for loop if thread \n2 acquires A .rst. With partial controllability, the control logic immediately forbids other threads \nfrom entering once thread 1 is executing the code, even if lock A is available. If thread 1 branches \nover the body of the if,or if itleaves the for loop, the control logic knows that thread 1 cannot be \ninvolved in this deadlock bug and therefore permits other threads to enter. Another issue to consider \nin practice is that of partial observabil\u00adity. A transition is not observable if we cannot observe its \n.ring. If a synthesized control place has incoming arcs from an unobservable transition in the net, then \nthe control logic is not implementable as the control logic does not know when to replenish tokens in \nthe control place. In our application, one could in principle observe every transition by proper instrumentation \nof the program. How\u00adever, if source code modi.cations are not allowed, e.g., only bina\u00adries are available, \nwe can still control the program by the technique of library interposition, by intercepting all lock \nacquisition/release calls. In this case however, the evolution of the program is not fully observable. \nSynthesizing control logic for a partially observable Petri net can also be solved by the technique of \nconstraint transformation, as described in (Iordache and Antsaklis 2006). Transformed linear inequality \nconstraints guarantee that control places added have in\u00adcoming arcs from observable transitions only. \nThe control logic is in general more conservative than the one assuming full observ\u00adability. In the example \nof Figure 12, if we can observe only lock and unlock calls, the control logic must wait until the .rst \nthread releases lru mutex at the end before allowing another thread to en\u00adter this critical region, which \neffectively serializes the whole critical region. Assuming full observability, as discussed above, the \ncontrol logic allows another thread to enter as soon as the .rst thread jumps out of the for loop. 4.3 \nCurrent Limitations Our current prototype implementation does not perform alias or pointer analysis when \nbuilding the Petri net model of a concurrent program. We represent lock pointer variables by their type \nnames, i.e., the structure type that encloses the primitive lock variable. This approximation is adopted \nby a few static analysis tools as well (En\u00adgler and Ashcraft 2003). It may lead to conservative control \nlogic but does not miss any deadlock unless the program violates type safety conventions by illegal pointer \ncasting. More sophisticated pointer analysis methods, such as the one used in (Cherem et al. 2008), could \nbe incorporated into our framework, thereby resulting in more .ne-grained control logic. Another source \nof conservatism in our con\u00ad if (x) trol synthesis phase is the lack of data .ow in\u00ad lock(L) formation \nin our current prototype, which is also ... shared with static analysis tools. Figure 13 il-if (x) lustrates \nthe false paths problem (Engler and unlock(L) Ashcraft 2003). With only control .ow infor- Figure 13. \nmation, the control synthesis algorithm does not know that the two conditional branches are paired up \nif x is not modi.ed in between, and therefore it mistakenly concludes that this code might acquire the \nlock but not release it. The algorithm might respond by adding unnecessary control logic. This example \nillus\u00adtrates the fact that our control logic is maximally permissive with respect to the program model, \nas formalized by Theorem 1. More accurate program models, e.g., from data .ow analysis, can result in \nbetter control and improved performance by reducing instrumen\u00adtation overhead and by allowing more concurrency. \nSome deadlocks are simply unavoidable. For example, a thread may repeatedly lock a nonrecursive mutex. \nIn the terminology of DCT, such programs are uncontrollable, and SBPI responds to the corresponding Petri \nnet models by emitting negative coef.cients where positive ones are expected (e.g., for arc weights and \nmark\u00adings). Our prototype implementation issues warnings for uncontrol\u00adlable deadlocks. A different kind \nof uncontrollability problem can arise if our control logic prevents concurrent execution of two program \nfrag\u00adments that must run concurrently in order for execution to proceed. This can occur if one fragment \nenters a blocking call (e.g., a read on a pipe) whose return is contingent upon the other fragment (e.g., \na write to the same pipe). To address this problem, we must include in our program model all blocking \ncalls, including those whose re\u00adturn is triggered by phenomena not explicitly modeled. (Condition variable \nsignal/broadcast is modeled in our current prototype, but blocking system calls are not.) It is then \nstraightforward to iden\u00adtify cases where our control logic potentially precludes the return of blocking \ncalls and issue appropriate warnings. If our experience with real software is any guide, such scenarios \nare rare in practice: we have never observed deadlocks caused by a combination of con\u00adtrol logic and, \ne.g., interprocess communication. If a program does not merit one or another sort of uncontrolla\u00adbility \nwarning, we guarantee correct execution; our method never silently introduces deadlocks or disables program \nfunctionality. In general, our overall approach is well suited to languages that admit the static modeling, \nanalyses, and control synthesis that we require. Dynamic constructs do not preclude our approach but \nmay lead to conservatism, e.g., we handle function calls through pointers by assuming that the callee \nmay be any function with the appropriate type signature. Annotations help clarify the ambiguity caused \nby dynamic constructs. Our current C/Pthreads prototype implementation does not model setjmp()/longjmp(), \nexception handling, or signal handling.  5. Implementation We brie.y discuss in this section several \nissues regarding the im\u00adplementation of our methodology, which is the subject of a separate paper (Wang \net al. 2008a) devoted to our prototype and empirical evaluation. 5.1 Control Flow Graph We modi.ed the \nopen source compiler OpenIMPACT (OpenIm\u00adpact) to construct an augmented control .ow graph (CFG) for each \nfunction in the input program. Lock variables (globally declared, locally declared, or dynamically allocated) \nare included in the CFG. In addition, functions calls are listed in each basic block, together with their \nargument name and type information. We recognize the standard Pthread functions automatically. We use \nprogrammer an\u00adnotations to recognize wrapper functions, if such functions are used for the primitive \nPthread functions. Basic blocks that contain these wrapper functions are marked and will be handled appropriately \nduring the model translation phase. As discussed in Section 4.3, patterns like the one illustrated in \nFigure 13 may lead to spurious deadlock detection. Since our con\u00adtrol synthesis algorithm avoids all \npotential deadlocks, in large pro\u00adgrams, numerous false control .ow paths could result in very con\u00adservative \ncontrol logic. Appropriate user annotation alleviates this problem. We found that function level annotation \nis highly effec\u00adtive against false paths. The annotation marks whether a particular lock type is always \nor never held upon return from a particular function. We use a variant of lockset analysis (Savage et \nal. 1997) to identify ambiguous functions automatically. In practice, the set of ambiguous functions \nis very small and a programmer unfamiliar with the source can annotate a function in a few minutes. For \nexam\u00adple, the function enclosing the code in Figure 13 could be annotated to indicate that lock L is \nnever held after the function returns. Our experience with real-world programs suggests that path-sensitive \ndata .ow analysis tools could eliminate the need for most of the annotations we added. 5.2 Model Translation \nAs explained in Section 3.2, we translate each function CFG into a separate Petri net. Each place in \nthe function Petri net corresponds to a basic block in the function, and control transfer from one ba\u00adsic \nblock to another is represented by a transition. Lock places link lock acquisition/release transitions \nin these function Petri nets. All of these model translations are straightforward, but with real-world \nprograms the dif.culty lies in modeling common software prac\u00adtices that may obfuscate a program s locking \nbehavior, e.g., locks accessed through pointers and primitive lock data types enclosed in wrapper structures \nthat are passed to lock/unlock function wrap\u00adpers. With the lock name and type information in the augmented \nCFGs, as discussed in the previous subsection, we are able to identify whether the lock variable in a \nlock function argument is a static reference to a lock instance or a dynamic choice of a certain lock \ntype. A lock type is de.ned as its wrapper structure type, i.e., the type of the argument of the wrapper \nfunction. In the case of chained pointers/references as the function argument, we could either be conservative \nand consider only the type of the last node (the default setting), or take the whole chain as the lock \ntype. In the latter case, a false negative is possible when two different chains actually refer to the \nsame lock in the end. False negatives are unacceptable, so we prefer the former approach. When a lock \nvariable is a static reference, we model the lock instance as a lock place and link it to the acquisition/release \ntransi\u00adtions as discussed in Section 3.2. When a lock variable is a dynamic choice through pointers, \nwe approximate the model by using a lock place to represent the lock type rather than the actual instance. \nAll dynamic references of this lock type share the same lock place, and there is exactly one initial \ntoken in the place. If a lock is accessed by both static address reference and pointers, we still approximate \nthe model using a lock place to represent the lock type. In our ex\u00adperience, such mixed references are \nrare in practice. Since we model dynamically selected locks by their types, dif\u00adferent instances of the \nsame lock type could give false positives for deadlock, and the end result would be impaired performance. \nIn real programs, however, most deadlocks reported in bug databases and change logs involve cyclic wait \non different lock types (Lu et al. 2008), i.e., locking hierarchy violations as in the OpenLDAP bug of \nFigure 12. Cyclic wait on locks of the same type is uncommon. Our model simpli.cation matches this typical \ndeadlock pattern well. 5.3 Of.ine Control Synthesis The input to the of.ine control synthesis module \nis a set of Petri nets that represents each function in the program. Since a deadlock may cross function \nboundaries and involve different parts of the program, we need to inline these Petri nets for control \nsynthesis, as described in Section 3.2. However, whole program inlining is not practical for real programs \nbecause of the extensive use of function pointers and recursions. We instead inline only functions related \nto critical regions, i.e., functions that can be called by threads holding locks. In other words, we \ncollapse regions of the global inlined Petri net that contain no lock-related operations because they \nare irrelevant. With this correctness-preserving performance optimization, the inlined call depth is \ntypically no more than three. 5.4 Online Control We have two implementations of the control logic for \nonline con\u00adtrol of the program: library interposition and program instrumen\u00adtation. Library interposition \nintercepts library calls, typically lock acquisition/release functions, and postpones lock acquisition \ncalls whenever necessary. Library interposition does not modify pro\u00adgram source code, and therefore can \nwork directly with binaries. However, as explained in Section 4.2, the control synthesis algo\u00adrithm must \naccount for the partial observability problem, which possibly reduces concurrency because of the limited \nset of observ\u00adable transitions. Program instrumentation, on the other hand, inserts control logic code \ninto the program as needed, and therefore can in principle observe the complete program execution state. \nFor both implementations, we must correlate program execution state with corresponding Petri net state. \nThe current execution function and line number are not suf.cient as one function might be called at different \nlocations and therefore result in different control actions. We need the call stack to map the current \nprogram state to transitions in the Petri net. Our library interposition approach walks up the call stack \nfrom the intercepted library call and identi.es the current transition. With the program instrumentation \napproach, for reasons of performance and portability, we instead instrument functions as necessary with \nadditional parameters that encode the execution state.  6. Experiments This section summarizes experimental \nevaluations of our prototype implementation. Greatly expanded results on randomly generated programs, \nthe publish-subscribe benchmark, and OpenLDAP are available in (Wang et al. 2008b,a). Randomly Generated \nPrograms Our .rst test involved ran\u00addomly generated programs reminiscent of the dining philosophers problem. \nThese programs repeatedly acquire or release a randomly selected lock then sleep for a random interval; \nthey deadlock read\u00adily. After we apply our deadlock avoidance technique to them, how\u00adever, they run inde.nitely \nwithout deadlock. A comparison of our customized control synthesis algorithm with a na\u00a8ive application \nof standard SBPI shows that our approach offers scalability bene.ts in terms of the off-line computational \ncost of control synthesis (Wang et al. 2008b). Publish-Subscribe Benchmark Ournexttestinvolved a highly \nconcurrent network server benchmark. We implemented a simple multithreaded publish-subscribe server that \ncan be compiled in three ways: deadlock-free, deadlock-prone, and atomic-section. The .rst employs .ne-grained \nlocks correctly and the second ac\u00adquires locks out of order. The third is compiled using the Intel pro\u00adtotype \nsoftware transactional memory compiler (Intel). The server software must perform I/O within critical \nsections to satisfy an application-level consistency requirement. It runs on a machine with a dual-core \nCPU and four network cards connected to four client emulators. As expected, our deadlock avoidance technique \nautomatically eliminates deadlocks in the deadlock-prone variant. The main pur\u00adpose of the benchmark \ntest is to evaluate performance rather than correctness. From the clients, we measured throughput under \nheavy load (server saturation) and transaction response times under light load. Our .rst result is that \nour deadlock avoidance approach has a negligible effect on light-load response times and reduces satu\u00adration \nthroughput by roughly 18% compared to the deadlock-free variant. Our second result is that the atomic-sections \nversion suf\u00adfers far worse performance overheads: it achieves only about half of the heavy-load throughput \nof the dynamic-deadlock-avoidance version and suffers a 6\u00d7 increase in response times. This result ini\u00adtially \nsurprised us until we determined that all I/O was serialized in the atomic-sections version. This is \nnot a shortcoming in the In\u00adtel compiler but rather a fundamental consequence of atomic sec\u00adtions: atomic \nsections containing I/O must be serialized lest covert I/O channels violate isolation among them. Our \nresults show that locks sometimes permit better exploitation of available physical resources than atomic \nsections. Our dynamic deadlock avoidance technique preserves this bene.t of locks while eliminating dead\u00adlocks \nand restoring the composability that locks alone destroy. OpenLDAP We next applied our method to OpenLDAP, \na popular open-source implementation of the Lightweight Directory Access Protocol. We tested on OpenLDAP \nversion 2.2.20, which has a con.rmed circular-mutex-wait deadlock bug (OpenLDAP). The bug was .xed in \n2.2.21 but returned in 2.3.13 when new code was added. The whole program has 1,795 functions and 41 lock \ntypes (i.e., distinct types of structures that contain locks). We an\u00adnotated OpenLDAP s internal wrapper \nlock functions and six other pairs of lock/unlock functions that operate on .le or database locks or \ncall OpenLDAP s wrappers through pointers. Our implemen\u00adtation s .rst pass took a few seconds and reported \n25 ambiguous functions (i.e., the set of locks held on exit was ambiguous). We annotated 21 manually; \nthis took slightly more than an hour. The second pass reported four potential deadlocks: the known deadlock, \ntwo previously unreported ones, and a false positive that is due to limited data .ow analysis. We disabled \ndeadlock avoidance instru\u00admentation for the latter and enabled it for the three real deadlocks; control \nsynthesis terminated in a few seconds, after a single iter\u00adation. Performance tests involving three different \nsynthetic work\u00adloads initially showed negligible performance overheads. We had to modify the standard \nOpenLDAP server con.guration substan\u00adtially in order to trigger adverse performance consequences for \nthe server instrumented with deadlock-avoidance control logic. Worst\u00adcase overheads on client-measured \nthroughput and response times ranged from 3 10%, depending on the workload. Apache We also applied our \nmethod to the most recent release of Apache, version 2.2.8. This version of httpd contains 2,264 functions \nand twelve lock types. Our prototype s .rst pass found 28 functions containing false-paths ambiguities, \nnearly all of which involve error checking in lock/unlock functions (if the attempt to acquire a lock \nfails, they return immediately). After we appropri\u00adately annotate these functions, the second pass shows \nno circular\u00admutex-wait deadlock. This .nding is consistent with the Apache bug database, which reports \nno such deadlocks in version 2.2.8. When condition variables are included in the model, our analysis \nidenti.es the known deadlock bug in Figure 10 and automatically synthesizes the control logic depicted \nin Figure 11. 7. Related Work This section reviews prior research in Discrete Control Theory and in \natomic sections implemented with transactional memory and with conventional locks. See (Wang et al. 2008a) \nfor a detailed review of four traditional approaches to deadlock (static detection, static prevention, \ndynamic detection, and dynamic avoidance) and two new proposals ( healing and immunity ). Discrete Control \nTheory has matured rapidly since the seminal work of (Ramadge and Wonham 1987). Comprehensive textbooks \nfacilitate graduate-level education in Discrete Control (Cassandras and Lafortune 2007) as the research \ncommunity expands the fron\u00adtier of DCT results. The prior work closest our own involves dead\u00adlock avoidance \nin manufacturing systems (Li et al. 2008), which admit restricted models that facilitate analysis and \ncontrol synthe\u00adsis; however such models are inappropriate for concurrent software. Furthermore, much \nresearch in this area either fails to achieve max\u00adimal permissiveness or requires explicit exploration \nof the reach\u00adable state space. Our contributions are to leverage Discrete Con\u00adtrol as a principled foundation \nfor dynamic deadlock avoidance in general-purpose software, and to achieve both scalability and max\u00adimal \npermissiveness. Several recent approaches allow programmers to de.ne atomic sections that are guaranteed \nto execute atomically and in isolation. Transactional Memory (TM) implements atomic sections by opti\u00admistically \npermitting concurrency, detecting con.icts among con\u00adcurrent atomic sections and resolving them by rolling \nback exe\u00adcution (Larus and Rajwar 2007). Rollback is not an option if ir\u00adrevocable actions such as I/O \noccur within transactions, but such transactions can be supported as long as they are serialized (Welc \net al. 2008). This is the approach taken in the Intel prototype TM compiler (Intel). Unfortunately, such \nserialization can degrade per\u00adformance and can prevent software from fully exploiting available physical \nresources (Wang et al. 2008a). An alternative approach to implementing atomic sections uses conventional \nlocks rather than transactions and attempts to asso\u00adciate locks with atomic sections in such a way as \nto maximize con\u00adcurrency (McCloskey et al. 2006; Isard and Birrell 2007; Emmi et al. 2007; Cherem et \nal. 2008). In the simplest case, all locks associated with an atomic section are acquired upon entry \nof the section and released upon exit, which reduces concurrency. More .ne-grained locking strategies \nacquire locks lazily and/or release locks eagerly; however, lazy acquisition immediately prior to ac\u00adcesses \nof protected variables can imply incorrect lock ordering and thus deadlock. In contrast to the paradigm \nof atomic sections, our approach brings bene.ts to legacy lock-based code, imposes no performance penalty \non I/O within critical sections, and exploits detailed knowl\u00adedge of all possible whole-program behaviors \nto maximize concur\u00adrency. Locks provide a more nuanced language for expressing al\u00adlowable concurrency \nthan existing implementations of atomic sec\u00adtions, and our approach preserves this bene.t. At the same \ntime, our approach restores the composability that locks destroy and ensures deadlock freedom, just as \natomic sections do. 8. Conclusions This paper has demonstrated that Discrete Control Theory pro\u00advides \na formal foundation for dynamic deadlock avoidance in mul\u00adtithreaded software. We construct program models \nwith structural features (siphons) corresponding to undesirable runtime behaviors (deadlocks), and use \nDCT to synthesize runtime control logic that provably avoids the latter by constraining the former. Our \napproach effectively eliminates deadlocks from the original program with\u00adout silently introducing new \ndeadlocks or global performance bot\u00adtlenecks. The control logic that we synthesize is maximally per\u00admissive, \nensuring that runtime concurrency is maximized. Our ap\u00adproach furthermore reduces runtime overheads by \nperforming the most computationally expensive steps (siphon analysis and SBPI) of.ine, which minimizes \nthe online costs associated with our con\u00adtrol logic. In essence, DCT control logic synthesis performs \na deep whole-program analysis that compactly encodes context-speci.c foresight, allowing the runtime \ncontrol logic to adjudicate lock acquisition requests quickly, based on current program state and worst-case \nfuture execution possibilities. Extensive experiments with a C/Pthreads prototype con.rm that our approach \nscales to real software, eliminates both naturally oc\u00adcurring and injected deadlock faults, and adds \nnegligible to modest performance overhead. Like atomic sections, our approach restores composability \nand thereby reinstates the cornerstones of program\u00admer productivity, divide-and-conquer problem decomposition \nand software modularity. Unlike atomic sections, our approach is back\u00adward compatible with legacy code \nand programmers. Because it neither forbids nor penalizes arbitrary I/O in critical sections, it sometimes \nenables software to exploit available physical resources more fully than atomic sections.  Acknowledgments \nWe thank Eric Anderson, Hans Boehm, Pramod Joisha, Hongwei Liao, Spyros Reveliotis, and the anonymous \nreviewers for many helpful comments. References Apache. Apache bug database, 2008. https://issues.apache.org/ \nbugzilla/index.cgi. E. R. Boer and T. Murata. Generating basis siphons and traps of Petri nets using \nthe sign incidence matrix. IEEE Trans. on Circuits and Systems I, 41(4):266 271, April 1994. C. G. Cassandras \nand S. Lafortune. Introduction to Dsicrete Event Systems. Springer, second edition, 2007. S. Cherem, \nT. Chilimbi, and S. Gulwani. Inferring locks for atomic sections. In PLDI, June 2008. M. Emmi, J. S. \nFischer, R. Jhala, and R. Majumdar. Lock allocation. In POPL, 2007. D. Engler and K. Ashcraft. RacerX: \nEffective, static detection of race conditions and deadlocks. In SOSP, 2003. J. L. Hellerstein, Y. Diao, \nS. Parekh, and D. M. Tilbury. Feedback Control of Computing Systems. Wiley, 2004. L. Holloway, B. Krogh, \nand A. Giua. A survey of Petri net methods for controlled discrete event systems. Discrete Event Dynamic \nSystems: Theory and Applications, 7(2):151 190, 1997. Intel. Intel C++ STM Compiler, Prototype Edition, \nJanuary 2008. M. V. Iordache and P. J. Antsaklis. Supervisory Control of Concurrent Systems: A Petri \nNet Structural Approach.Birkh\u00a8auser, 2006. M. Isard and A. Birrell. Automatic mutual exclusion. In Proc. \n11th Workshop on Hot Topics in Operating Systems, May 2007. K. M. Kavi, A. Moshtaghi, and D. Chen. Modeling \nmultithreaded applica\u00adtions using Petri nets. International Journal of Parallel Programming, 30(5):353 \n371, October 2002. J. Larus and R. Rajwar. Transactional Memory. Morgan &#38; Claypool, 2007. Z. Li, \nM. Zhou, and N. Wu. A survey and comparison of Petri net\u00adbased deadlock prevention policies for .exible \nmanufacturing systems. IEEE Trans. on Systems, Man, and Cybernetics Part C, 38(2):173 188, March 2008. \nS. Lu, S. Park, E. Seo, and Y. Zhou. Learning from mistakes: a comprehen\u00adsive study on real world concurrency \nbug characteristics. In ASPLOS, 2008. B. McCloskey, F. Zhou, D. Gay, and E. Brewer. Autolocker: Synchroniza\u00adtion \ninference for atomic sections. In POPL, 2006. T. Murata. Petri nets: Properties, analysis and applications. \nProceedings of the IEEE, 77(4):541 580, April 1989. OpenImpact. OpenIMPACT, 2008. http://www.gelato.uiuc.edu/. \nOpenLDAP. OpenLDAP Issue Tracking System, 2008. http://www. openldap.org/its/. C. A. Petri. Kommunikation \nmit Automaten. PhD thesis, Bonn: Institut f\u00a8ur Instrumentelle Mathematik, Schriffen des IIM Nr.3, 1962. \nP. J. Ramadge and W. M. Wonham. Supervisory control of a class of discrete event processes. SIAM J. Control \nOptim., 25(1), 1987. W. Reisig. Petri nets. In EATCS Monographs on Theoretical Computer Science, volume \n4. Springer-Verlag, Berlin, 1985. S. A. Reveliotis. Real-Time Management of Resource Allocation Systems: \nA Discrete-Event Systems Approach. Springer, New York, NY, 2005. S. Savage, M. Burrows, G. Nelson, P. \nSobalvarro, and T. Anderson. Eraser: A dynamic data race detector for multithreaded programs. ACM TOCS, \n15(4):391 411, November 1997. Y. Wang, T. Kelly, and S. Lafortune. Discrete control for safe execution \nof IT automation work.ows. In EuroSys, 2007. Y. Wang, T. Kelly, M. Kudlur, S. Lafortune, and S. Mahlke. \nGadara: Dynamic deadlock avoidance for multithreaded programs. In OSDI, 2008a. Y. Wang, T. Kelly, M. \nKudlur, S. Mahlke, and S. Lafortune. The application of supervisory control to deadlock avoidance in \nconcurrent software. In Workshop on Discrete Event Systems, May 2008b. Adam Welc, Bratin Saha, and Ali-Reza \nAdl-Tabatabai. Irrevocable transac\u00adtions and their applications. In SPAA, June 2008.  \n\t\t\t", "proc_id": "1480881", "abstract": "<p>Deadlock in multithreaded programs is an increasingly important problem as ubiquitous multicore architectures force parallelization upon an ever wider range of software. This paper presents a theoretical foundation for dynamic deadlock avoidance in concurrent programs that employ conventional mutual exclusion and synchronization primitives (e.g., multithreaded C/Pthreads programs). Beginning with control flow graphs extracted from program source code, we construct a formal model of the program and then apply Discrete Control Theory to automatically synthesize deadlock-avoidance control logic that is implemented by program instrumentation. At run time, the control logic avoids deadlocks by postponing lock acquisitions. Discrete Control Theory guarantees that the program instrumented with our synthesized control logic cannot deadlock. Our method furthermore guarantees that the control logic is maximally permissive: it postpones lock acquisitions only when necessary to prevent deadlocks, and therefore permits maximal runtime concurrency. Our prototype for C/Pthreads scales to real software including Apache, OpenLDAP, and two kinds of benchmarks, automatically avoiding both injected and naturally occurring deadlocks while imposing modest runtime overheads.</p>", "authors": [{"name": "Yin Wang", "author_profile_id": "81327492356", "affiliation": "University of Michigan, Ann Arbor, MI, USA", "person_id": "P1300984", "email_address": "", "orcid_id": ""}, {"name": "St&#233;phane Lafortune", "author_profile_id": "81100196756", "affiliation": "University of Michigan, Ann Arbor, MI, USA", "person_id": "P1300985", "email_address": "", "orcid_id": ""}, {"name": "Terence Kelly", "author_profile_id": "81100523747", "affiliation": "Hewlett-Packard Labs, Palo Alto, CA, USA", "person_id": "P1300986", "email_address": "", "orcid_id": ""}, {"name": "Manjunath Kudlur", "author_profile_id": "81100105059", "affiliation": "University of Michigan, Ann Arbor, MI, USA", "person_id": "P1300987", "email_address": "", "orcid_id": ""}, {"name": "Scott Mahlke", "author_profile_id": "81100622742", "affiliation": "University of Michigan, Ann Arbor, MI, USA", "person_id": "P1300988", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480913", "year": "2009", "article_id": "1480913", "conference": "POPL", "title": "The theory of deadlock avoidance via discrete control", "url": "http://dl.acm.org/citation.cfm?id=1480913"}