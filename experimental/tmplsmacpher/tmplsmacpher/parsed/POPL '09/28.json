{"article_publication_date": "01-21-2009", "fulltext": "\n Local Rely-Guarantee Reasoning Xinyu Feng Toyota Technological Institute at Chicago Chicago, IL 60637, \nU.S.A. feng@tti-c.org Abstract Rely-Guarantee reasoning is a well-known method for veri.cation of shared-variable \nconcurrent programs. However, it is di.cult for users to de.ne rely/guarantee conditions, which specify \nthreads behaviors over the whole program state. Recent e.orts to combine Separation Logic with Rely-Guarantee \nreasoning have made it pos\u00adsible to hide thread-local resources, but the shared resources still need \nto be globally known and speci.ed. This greatly limits the reuse of veri.ed program modules. In this \npaper, we propose LRG, a new Rely-Guarantee-based logic that brings local reasoning and information hiding \nto concur\u00adrency veri.cation. Our logic, for the .rst time, supports a frame rule over rely/guarantee \nconditions so that speci.cations of pro\u00adgram modules only need to talk about the resources used locally, \nand the veri.ed modules can be reused in di.erent threads with\u00adout redoing the proof. Moreover, we introduce \na new hiding rule to hide the resources shared by a subset of threads from the rest in the system. The \nsupport of information hiding not only improves the modularity of Rely-Guarantee reasoning, but also \nenables the shar\u00ading of dynamically allocated resources, which requires adjustment of rely/guarantee \nconditions. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation \n Correctness proofs, Formal methods; F.3.1 [Logics and Meanings of Programs]: Specifying and Verifying \nand Reasoning about Programs General Terms Languages, Theory, Veri.cation Keywords Concurrency, Rely-Guarantee \nReasoning, Separation Logic, Local Reasoning, Information Hiding 1. Introduction With the development \nand wide use of multi-core processors, con\u00adcurrency has become a crucial element in software systems. \nHow\u00adever, the correctness of concurrent programs is notoriously di.cult to verify because of the non-deterministic \ninterleaving of running threads and the exponential size of state spaces. Compositionality is of particular \nimportance for scalable concurrency veri.cation. Rely-Guarantee reasoning (Jones 1983) is a well-known \nmethod for veri.cation of shared-variable concurrent programs. It lets each Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 09, January 18 24, 2009, Savannah, Georgia, \nUSA. Copyright .c2009 ACM 978-1-60558-379-2/09/01. . . $5.00 thread specify its expectation (the rely \ncondition) of state transi\u00adtions made by its environment, and its guarantee to the environment about \ntransitions made by itself. Since the rely condition speci.es all possible behaviors that might interfere \nwith the thread, we do not need to consider the exponential size of possible interleavings during the \nveri.cations. However, the rely/guarantee conditions are di.cult to formulate in practice, because they \nneed to specify the global program state and these global conditions need to be checked during the execution \nof the whole thread. Speci.cally, the compo\u00adsionality and applicability of Rely-Guarantee reasoning are \ngreatly limited by the following problems: The whole program state is viewed as shared resource and \nneed to be speci.edinthe rely/guarantee conditions, even if a part of the state might be privately owned \nby a single thread. The thread-private resource has to be exposed in the speci.cations.  As part of \nthe speci.cations of program modules, the rely and guarantee conditions need to specify all the shared \nresources, even if the module accesses only part of them locally. This lim\u00adits the reuse of veri.ed program \nmodules in di.erent applica\u00adtions with di.erent shared resources.  Since the shared resources need to \nbe globally known, it is dif\u00ad.cult to support the sharing of dynamically allocated resources, which are \nnot known until they are allocated.  Some resources might be shared only by a subset of threads, but \nthere is no way to hide them from the rest of threads in the system.  These problems are part of the \nreasons why Jones (2003) calls for a more compositional approach to concurrency. Recent works on SAGL \n(Feng et al. 2007) and RGSep (Vafeiadis and Parkinson 2007) have tried to combine the Rely-Guarantee \nrea\u00adsoning with Separation Logic (Ishtiaq and O Hearn 2001; Reynolds 2002) for better composionality. \nThey split the whole state into thread-private and shared parts. The partition of resources enforced \nby Separation Logic ensures that each thread cannot touch the pri\u00advate parts of others. The rely and \nguarantee conditions now only need to specify the part that is indeed shared. These combinations, however, \nonly address the .rst problem mentioned above. Since they also require the shared resources to be globally \nknown, the last three problems remain unsolved. In this paper, we propose a new program logic, LRG, for \nLocal Rely-Guarantee reasoning. By addressing all these open problems, our logic makes local reasoning \nand information hiding a reality in concurrency veri.cation. Our work is based on previous works on Rely-Guarantee \nreasoning and Separation Logic, and SAGL and RGSep in particular, but makes the following new contributions: \nAs an extension of Separation Logic, we introduce the sepa\u00adrating conjunction of rely/guarantee conditions. \nUnlike asser\u00adtions in Separation Logic, rely/guarantee conditions are binary relations of program states \nand they specify state transitions.  The new separating conjunction allows us to formalize two sub\u00adtransitions \nconducted over disjoint resources, which is the basis to bring in all the nice ideas developed in Separation \nLogic for local reasoning and modularity. Our logic, for the .rst time, supports a frame rule over rely \nand guarantee conditions so that the sharing of resources no longer needs to be globally known. Speci.cations \nof program modules only need to talk about the resource used locally, therefore the veri.ed modules can \nbe reused in di.erent contexts without redoing the proof.  We propose a new rule for hiding the shared \nresources from the environment. It allows the local sharing of resources among a subset of threads without \nexposing them to others in the system. In particular, using the hiding rule we can derive a more general \nrule for parallel composition such that a thread s private resource can be shared by its children without \nbeing visible by its siblings. The hiding rule also gives us a way to change the rely and guarantee conditions, \nso that the sharing of dynamically allocated resources can be supported.  In addition to these extensions, \nour work also greatly simpli.es SAGL and RGSep. We split program states conceptually into thread-private \nand shared parts, but do not need explicit distinc\u00adtion of them either syntactically in assertions (as \nin SAGL and RGSep) or semantically in program states and operational se\u00admantics (as in RGSep). This gives \nus a simpler semantic model and makes the logic more .exible to use.  Treating variables as resources \n(Parkinson et al. 2006), our work is very general and the same ideas work for traditional Rely-Guarantee-based \nlogics where only variables are used and heaps are not dealt with.  Our logic can also be viewed as \nan extension of the Concurrent Separation Logic (O Hearn 2007) with the more expressive Rely-Guarantee-based \nspeci.cations, but without sacri.cing its compositionality.  In the rest of this paper, we .rst give \nan overview of the tech\u00adnical background, and use an example to explain the problems and challenges in \nSec. 2. Then, before diving into the formal technical development, we explain informally our approaches \nin Sec. 3. We present the programming language in Sec. 4, the assertion language in Sec. 5 and the LRG \nlogic in Sec. 6. As an example, in Sec. 7 we show how the program presented in Sec. 2 can be veri.ed \nin our logic. We discuss related work and conclude in Sec. 8. 2. Background and Challenges In this section, \nwe give an overview of Rely-Guarantee reason\u00ading, Concurrent Separation Logic, and recent works on combining \nthem (Feng et al. 2007; Vafeiadis and Parkinson 2007). Then we use an example to show the problems with \nexisting approaches. 2.1 Rely-Guarantee Reasoning In Rely-Guarantee reasoning, each thread views the \nset of all other threads in the system as its environment. The interface between the thread and its environment \nis speci.ed using a pair of rely and guar\u00adantee conditions. The rely condition R speci.es the thread \ns expec\u00adtations of state transitions made by its environment. The guarantee G speci.es the state transitions \nmade by the thread itself. R and G are predicates over a pair of states, i.e., the initial one before \nthe transition and the resulting one after the transition. The speci.ca\u00adtion of a thread is a quadruple \n(p, R,G, q), where p and q are pre\u00adand post-conditions. A thread satis.es its speci.cation if, given \nan initial state satisfying p and an environment whose behaviors sat\u00adisfy R, each atomic transition made \nby the thread satis.es G and the state at the end satis.es q. Parallel Composition. To ensure two parallel \nthreads can collab\u00adorate without interference, we need to check that their interfaces are compatible \nin the sense that the rely condition of each thread is implied by the guarantee of the other. Below is \nthe rule for the parallel composition C1 .C2: C1 sat (p, R .G2,G1, q1) C2 sat (p, R .G1,G2, q2) C1 .C2 \nsat (p, R,G1 .G2, q1 .q2) It shows that, to verify C1 .C2, we can verify the children C1 and C2 separately. \nThe rely condition of each child captures the behavior of both its parent s environment (R) and its sibling \n(G1 or G2). It is easy to check that the rely and guarantee conditions for C1 and C2 are compatible, \ni.e., G1 .(R .G1)and G2 .(R .G2). Stability. Each thread is veri.ed with respect to its speci.cation \nin a similar way as the veri.cation of sequential programs in Hoare Logic, except that we also need to \nensure the behavior of every atomic operation satis.es the guarantee, and the precondition at each step \nis stable with respect to the rely condition. The stability means, if the current state satis.es the \nprecondi\u00adtion p and the current thread is preempted by its environment, p still holds when the current \nthread resumes its execution in a new state as long as the transition made by the environment satis.es \nits rely condition R. The stability check is essential to ensure the non-interference between the thread \nand its environment, but it re\u00adquires R to capture all possible behaviors of the environment, which makes \nR (and G)di.cult to de.ne and limits the compositionality of the Rely-Guarantee reasoning. 2.2 Separation \nLogic and Concurrency Veri.cation Separation Logic (Ishtiaq and O Hearn 2001; Reynolds 2002) is an extension \nof Hoare Logic with e.ective reasoning about memory aliasing. The separating conjunction p*p.in the assertion \nlanguage speci.es program states that can be split into two disjoint parts satisfying p and p.respectively. \nBecause of the separation, update of the part satisfying p does not a.ect the validity of p.over the \nother part. The frame rule, as shown below (with some side conditions elided), supports local reasoning \nof program modules: {p}C{q} {p *r}C{q *r} The speci.cations p and q for C need to only talk about states \naccessed locally by C.When C is composed with other modules in di.erent contexts, di.erent r can be added \nin the speci.cation by applying the frame rule, without redoing the proof. O Hearn has proposed Concurrent \nSeparation Logic (CSL), which applies Separation Logic to reason about concurrent pro\u00adgrams (O Hearn \n2007). Unlike Rely-Guarantee reasoning, CSL ensures non-interference by enforcing the separation of resources \naccessible by di.erent threads. The parallel composition rule in CSL isasfollows: {p1}C1{q1}{p2}C2{q2} \n{p1 *p2}C1 .C2{q1 *q2} Veri.cation of each sequential thread in CSL is the same as in Separation Logic. \nThe frame rule is also sound in CSL. CSL also allows threads to share resources, but only in conditional \ncritical regions that can be entered by only one thread at a time. The well\u00adformedness of shared resources \nis speci.ed using invariants, which need to be satis.ed when threads exit critical regions. 1 nd := 0; \n2 while (nd = 0) do { 3 lk := 0; 4 while (lk . 1) do { // acquire lock 5 .lk := [lhead]; if (lk = 1) \nthen [lhead] := 0;. 6 } 7 nd := [lhead + 1]; // .rst node 8 if (nd . 0) then {9 tmp := [nd + 2]; [lhead \n+ 1] := tmp // remove node 10 } 11 .[lhead] := 1.; // release lock 12 } 13 tmp := [nd]; tmp. := [nd+1]; \nx := cons(tmp,tmp.); 14 Cgcd Figure 1. GCD of Nodes on List 2.3 Combinations of the Two Approaches The \nrely and guarantee conditions in Rely-Guarantee reasoning specify state transitions, which are expressive \nand are suitable to reason about .ne-grained concurrent programs. On the other hand, the method views \nthe whole state as a shared resource among threads, which makes it less compositional. CSL has very nice \ncompositionality, but the limited expressiveness of invariants for shared resources makes it unsuitable \nfor .ne-grained concurrency. SAGL (Feng et al. 2007) and RGSep (Vafeiadis and Parkinson 2007) have tried \nto combine merits of both approaches. They split the whole state into thread-private and shared parts. \nSpeci.cations of threads are in the form of ((p,r),R,G,(q,r.)), where p and q are pre-and post-conditions \nspecifying the private resources of the thread, while r and r. for the shared part.1 Their rules for \nparallel composition are as follows: C1 sat ((p1,r),R .G2,G1,(q1,r1)) C2 sat ((p2,r),R .G1,G2,(q2,r2)) \n C1 . C2 sat ((p1 * p2,r),R,G1 .G2,(q1 *q2,r1 .r2) The partition of resources enforced by the separating \nconjunction ensures that each thread cannot touch the private parts of others. The rely and guarantee \nconditions now only need to specify the part that is indeed shared.  2.4 Problems and Challenges To \nsee the problems with all these approaches, we .rst look at a simple program shown in Figs. 1 and 2. \nThe program removes a node from a shared linked list and then computes the greatest common divisor (GCD) \nof the two numbers stored in the node. lhead ... The shared data structure is shown above. The global \nconstant lhead points to two memory cells. The .rst one contains a binary mutex, which enforces mutual \nexclusive accesses to the linked list pointed to by the pointer stored in the second memory cell. We \nuse .C. to mean C is executed atomically. x := [E] ( [E] := E. ) loads values from (stores values into) \nmemory at the location E. cons(E1,...,En) allocates n memory cells with initial values E1,...,En. The \nthread shown in Fig. 1 can be viewed as a consumer of a producer-consumer style program, where the pro\u00adducer \n(not shown here) generates random numbers and puts them onto the list. Code from line 1 to line 12 acquires \nthe lock, removes 1 RGSep uses p * r instead of (p,r). .t21 := [x + 1].; 1 .t11 := [x].; 2 .t12 := [x \n+ 1].; .t22 := [x].; while (t21 . t22) do{ 3 while (t11 . t12) do{ 4 if(t11 > t12) then { if(t21 > t22) \nthen { 5 t11 := t11 - t12; t21 := t21 - t22; .[x + 1] := t21.; 6 .[x] := t11.; 7 } } 8 .t12 := [x + 1].; \n.t22 := [x].; 9 } } Figure 2. Concurrent GCD a node from the list and then releases the lock. Line 13 \ncopies num\u00adbers in the node to newly allocated memory cells. The code Cgcd in Line 14 refers to the program \nin Fig. 2, where two threads collabo\u00adrate to compute the GCD of numbers pointed to by x. This is a very \nsimple program, but there is no clean and modular way to verify it using existing logics described in \nthe previous sections for the following reasons: 1. Cgcd shown in Fig. 2 is a .ne-grained concurrent \nprogram two threads share the memory without using locks. The correctness of the code is based on the \nfact that each thread preserves the value at the memory location where the other may update; and that \nall updates decreases the values and preserves the GCD. It is di.cult to verify the code using CSL because \nthe invariant of shared resources cannot express preservation and decrease of values without heavy use \nof auxiliary variables. 2. The functionality of Cgcd is self-contained. We want to verify it once and \nreuse it in di.erent contexts. However, both original Rely-Guarantee reasoning and recent extensions \ndescribed in Sec. 2.3 require the shared resource be globally known. As a result, when Cgcd is veri.ed, \nthe rely and guarantee conditions have to specify the shared list even if it is not accessed by Cgcd, \nnegating the very advantage of sequential Separation Logic. 3. The memory block pointed to by x is shared \nlocally by the two threads in Cgcd, but not used elsewhere. We should be able to hide it and make it \ninvisible outside when we specify the rely and guarantee conditions for the thread in Fig. 1. This is \nnot supported by existing work on Rely-Guarantee reasoning. 4. Even if we give up the third requirement \nand are willing to expose the local sharing inside Cgcd in the global rely and guarantee conditions, \nwe cannot do so because the memory block pointed to by x is dynamically allocated, whose location is \nunknown at the beginning.  Among these problems, the .rst one is with CSL, while the rest are with Rely-Guarantee \nreasoning, including SAGL and RGSep. Polymorphic Interpretations of Rely/Guarantee Conditions? It is \nimportant to note that using a polymorphic interpretation of rely and guarantee conditions does not automatically \nsolve these problems. For instance, we may want to interpret the validity of the rely condition R over \nstate transitions from s to s. in a way such that the following property holds: If (s,s.) |= R, s.s.., \nand s..s..,then (ss..,s.s..) |= R. Here we use s.s.. to mean s and s.. are disjoint, and use ss.. to \nmean the merge of disjoint states. Their formal de.nitions are shown in Sec. 5. Although this interpretation \ntakes care of the part of state that is not explicitly speci.ed in R, it does not support local speci.cation \nand cannot address the second problem mentioned above. Suppose we have veri.ed Cgcd with a local speci.cation \nof R that does not mention the shared list, the interpretation requires that the list be preserved by \nthe environment, which is too strong an assumption and cannot be matched with the actual rely condition \nfor the .rst 13 lines of code (and the consequence rule cannot be applied, which only allows strengthening \nof the rely condition). As a second try, let s consider a very weak interpretation that satis.es the \nfollowing property: If (s,s.) |= R, s.s.., and s..s...,then (ss..,s.s...) |= R. It says the part of the \nstate unspeci.ed in R might be changed arbi\u00adtrarily. This interpretation, however, is too weak for the \nguarantee condition G. So we probably need a di.erent interpretation for G, e.g., the .rst one. Using \ndi.erent interpretations for R and G makes the logic complicated. A more serious problem with this approach \nis that it does not allow the hiding of locally shared resources. In the parallel composition rule shown \nin Sec. 2.1, if we do not specify in R the resource locally shared by C1 and C2, the new rely condition \nR .G2 for C1 is then too weak to be useful. The variation of the rule in Sec. 2.3 has the same problem. \n3. Our Approach As in SAGL and RGSep, we also split program states into thread\u00adprivate and shared parts. \nEach thread has exclusive access of its own private resources. Rely/guarantee conditions only specify \nthe shared part. But we try to borrow more ideas from Separation Logic to address the remaining compositionality \nproblems. We .rst introduce the separating conjunction over actions, i.e., binary relations of states \nspecifying state transitions. Rely and guar\u00adantee conditions are all actions. Similar to the separating \nconjunc\u00adtion p *p. in Separation Logic, R *R. (or G *G.) means the two sub-actions R and R. (or G and \nG.) occur over disjoint parts of states. A formal de.nition will be given in Sec. 5. We can now extend \nthe frame rule in Separation Logic to sup\u00adport local rely and guarantee conditions: R,G .{(p,r)}C{(q,r.)} \nm stable with respect to R. ... R *R. ,G *G..{(p,r *m)}C{(q,r.*m)} Following SAGL and RGSep, here we \nspecify private and shared resources separately in pre-and post-conditions (but not in our formal development). \nWe use R,G .{(p,r)}C{(q,r.)} to represent the old judgment C sat ((p,r),R,G,(q,r.)) described in Sec. \n2.3. The frame rule says we can verify C with the local speci.cation ((p,r),R,G,(q,r.)). When C is executed \nin di.erent contexts with the extra shared resource speci.ed by m, we know C satis.es the bigger speci.cation \nwithout redoing the proof. The stability check that causes compositionality problems in Rely-Guarantee \nreasoning, as explained in Sec. 2.1, is no longer an issue here because we can prove r *m is stable with \nrespect to R *R. if r is stable with respect to R and m is stable with respect to R. (we actually need \nsome subtle constraints to prove this, which will be explained in Sec. 5). The simpler frame rule for \nprivate resources, as shown below, is supported in SAGL and RGSep and is sound in our logic too. R,G \n.{(p,r)}C{(q,r.)} R,G .{(p *m,r)}C{(q *m,r.)} Since the rely/guarantee conditions specify only the shared \nre\u00adsources, they do not need to be changed with the extension of the private predicates. To allow the \nhiding of the local sharing of resources by a subset of threads, we introduce a new hiding rule: R *R. \n,G *G..{(p,r *m)}C{(q,r.*m.)} [side-conditions omitted] R,G .{(p *m,r)}C{(q *m,r.)} (Expr) E ::= x |X \n|n | E + E |E -E |... (Bexp) B ::= true |false | E = E | E . E |... (Stmts) C ::= x := E | x := [E] |[E] \n:= E |skip | x := cons(E,...,E) |dispose(E) |C;C | if B then C else C |while B do C |C1 .C2 | atomic(B){C} \nFigure 3. The Language (Store) s . PVar ..n Int (LvMap) i . LVar ..n Int (Heap) h . Nat ..n Int (State) \ns . Store \u00d7LvMap \u00d7Heap (Trans) R,G.P(State \u00d7State) Figure 4. Program States This rule says if the resource \nspeci.ed by m and m.is shared locally inside C, and transitions over the resource is speci.ed by R.and \nG. , we can treat it as private and hide R. and G. in the rely/guarantee conditions so that it is invisible \nfrom the outside world. Although this rule only converts part of the shared resource into private and \ndoes not hide its existence in the pre-and post-conditions, it does hide the resource from other threads \nbecause rely/guarantee conditions are the interface between threads. At .rst glance, this rule seems \nto allow a thread to arbitrarily hide any shared resources so that it can cheat its environment. The \nthread, however, cannot abuse this freedom because the inappropri\u00adate hiding will be detected at the \npoint of parallel composition. We will explain this in detail in Sec. 6. The hiding rule is particularly \ninteresting when C is a parallel composition (C1 .C2). It allows us to derive a more general rule for \nparallel composition such that the children threads may share resources that appear to the outside world \nas private resources of the parent thread. This also solves the last problem described in Sec. 2.4. Sharing \nof dynamically allocated resources usually follows the pattern of C0;(C1 .C2), like the example in Sec. \n2.4. New resources are allocated by C0 and then shared by C1 and C2. Since they are unknown at the beginning \nof C0, we cannot specify them in the global R and G. Our new rule allows us to leave them unspeci.ed \nin the R and G outside of C1 .C2. Note that the rules shown in this section are used to illustrate our \nbasic ideas in a semi-formal way. The actual ones in the LRG logic are presented in Sec. 6 and are in \ndi.erent forms. In particular, we do not need the pairs (p,r) as pre-and post-conditions. 4. The Language \nThe syntax of the language is de.ned in Fig. 3. We use x and X to represent program variables (PVar) \nand logical variables (LVar) respectively. The expressions E and B are pure. The statement x := [E] ([E] \n:= E.) loads values from (stores the value E. into) memory at the location E. x := cons(E1,...,En) allocates \nn consec\u00adutive fresh memory cells and initializes them with E1, ..., En.The starting address is picked \nnondeterministically and assigned to x. dispose(E) frees the memory cell at the location E. The atomic \nblock atomic(B){C} executes C atomically if B holds. Otherwise the current process is blocked until B \nbecomes true. As pointed out by Vafeiadis and Parkinson (2007), it can be {.,...,.+k-1}ndom(h) = \u00d8 [[E1]](s,i) \n= n1 [[Ek]](s,i) = nk x .dom(s) [[Ej]](s,i) unde.ned (1 = j =k)or x . dom(s) (x := cons(E1,...,Ek),(s,i,h)) \n. (skip,(s{x . .},i,h {. . n1,...,.+k-1 . nk})) (x := cons(E1,...,Ek),(s,i,h)) . abort [[E]](s,i) = .. \n.dom(h) [[E]](s,i) unde.ned or [ E]](s,i) . dom(h) (dispose(E),(s,i,h)) . (skip,(s,i,h \\{.})) (dispose(E),(s,i,h)) \n. abort (C1,s) . (C1.,s.)(C1,s) . abort (skip;C,s) . (C,s) (C1;C2,s) . (C1.;C2,s.)(C1;C2,s) . abort (C1,s) \n. (C1.,s.)(C2,s) . (C2.,s.)(C1,s) . abort or (C2,s) . abort (C1 .C2,s) . (C1 ..C2,s.)(C1 .C2,s) . (C1 \n.C2.,s.)(C1 .C2,s) . abort [[B]]s = tt (C,s) .* (skip,s.) [[B]]s = tt (C,s) .* abort (skip .skip,s) . \n(skip,s) (atomic(B){C},s) . (skip,s.)(atomic(B){C},s) . abort (s,s.) .R (C,s) . (C.,s.)(C,s) . abort \nRR R -.(C,s.) .(C,s) -.abort (C,s) .(C,s) -.(C.,s.) . Figure 5. Operational Semantics used to model synchronizations \nat di.erent levels, such as a system\u00adwide lock or atomicity guaranteed by transactional memory. The use \nof atomic(true){C}can also be viewed as annotations of atomic machine instructions for .ne-grained concurrency \n(Parkinson et al. 2007). The other statements in Fig. 3 have standard meanings. Figure 4 presents the \nmodel of program states. The store s is a .nite partial mapping from program variables to integers; the \nlogical variable mapping i maps logical variables to integers; and the heap h maps memory locations (natural \nnumbers) to integers. The program state s is atripleof(s,i,h). State transitions Rand G are binary relations \nof states. The semantics of E and B are de.ned by [ E]]and [ B] respec\u00adtively. [ E] is a partial function \nof type Store \u00d7LvMap . Int . [[B] is a partial function of type Store \u00d7LvMap . {tt,ff}. Their de.nitions \nare straightforward and are omitted here. We treat program variables as resources, following Parkinson \net al. (2006). The semantic functions are unde.ned if variables in E and B are not assigned values in \ns and i. The single step execution of a process is modeled as a binary relation: .P((Stmts \u00d7State) \u00d7((Stmts \n\u00d7State) .{abort})) It is de.ned formally in Fig. 5. Given a statement C and a state s, we have three \ncases. First, C can execute one step. We have a new state s. and a remaining statement C.. In this case, \nwe have (C,s) . (C.,s.). If it is not safe to execute the next statement in the state s, wehave(C,s) \n. abort. In the third case, the program gets stuck, although s satis.es the safety requirements. Then \n(C,s) . is unde.ned. The third case occurs when C is skip, or it begins with an atomic statement atomic(B){C.}such \nthat B does not hold over sor C. does not terminate. The skip statement plays two roles here: a statement \nthat has no computation e.ects or a .ag to show the end of execution. .* is the transitive-re.exive closure \nof the single step transition relation. Semantics of the most common statements are elided and are presented \nin the extended version (Feng 2008).   (PVarList) O ::= | x,O (Assertion) p,q,r,I ::= B | emph | emps \n| Own(x) | E . .E | p *q | p -.q | ... (Action) a,R,G ::= p . q | [p] | a *a |.X.a | a .a| a .a | ... \nFigure 6. The Assertion Language We use R to represent the possible transitions made by the environment. \nThen the binary relation R -. ,as de.nedinFig. 5, represents one step of state transitions made either \nby the current process or by its environment characterized by R. Our treatment of the atomic block atomic(B){C}follows \nVafeiadis and Parkinson (2007): execution of the statement C appears to .nish in one step and cannot \nbe interrupted by the environment. 5. The Assertion Language The assertion language is shown in Fig. \n6. We use the Separation Logic assertions to specify program states. Following Parkinson et al. (2006), \nwe treat program variables as resources, but do not use fractional permissions, which are orthogonal \nto our technical development. Semantics of some assertions are shown in Fig. 7. The boolean expression \nB holds over a state only if it evaluates to true. It is important to note that, with program variables \nas resources, the boolean expression E = E does not always hold. It holds if and only if the store contains \nthe variables needed to evaluate E. The assertions emph and emps specify empty heaps and stores respectively. \nOwn(x) means the ownership of the variable x. E1 . . E2 speci.es a singleton heap with E2 stored at the \nlocation E1. It also requires that the store contain variables used to evaluate E1 and E2. The separating \nconjunction p *q means p and q hold over disjoint part of state. Here we use f .g to mean the two .nite \npartial mappings f and g have disjoint domains. The union of two disjoint states s1 and s2 is de.ned \nas s1 s2. The septraction p -.q, introduced by Vafeiadis and Parkinson (2007), means the state can be \nextended with a state satisfying p and the extended state satis.es q. The assertions O . p and emp are \nsyntactic sugars, (s,i,h) |=sl B i. [[B]](s,i) = tt (s,i,h) |=sl empsi. s = \u00d8 (s,i,h) |=sl emphi. h = \n\u00d8 (s,i,h) |=sl Own(x)i. dom(s) = {x}(s,i,h) |=sl E1 .. E2i. there exist . and n such that [ E1]](s,i) \n= .,[[E2]](s,i) = n, dom(h) = {.} and h(.) = n def f .g = dom( f ) ndom(g) = \u00d8 . ,i. def (s,i,h) (s,h.) \n= (s . s,i,h .h.)if s.s, h.h. , i = i. unde.ned otherwise s |=sl p1 * p2i. there exist s1 and s2 such \nthat s1 s2 = s, s1 |=sl p1 and s2 |=sl p2 s |=sl p -.q i. there exist s. and s.. such that s.. = s s.,s.|=sl \np and s.. |=sl q def x1,..., xn, . p = (Own(x1) *\u00b7\u00b7\u00b7*Own(xn)) . p def emp = emps .emph Figure 7. Semantics \nof Selected Separation Logic Assertions (s, s.) |= p . q i. s.i = s. .i,s |=sl p and s.|=sl q (s, s.) \n|= [p]i. s = s. and s |=sl p (s, s.) |= a *ai. there exist s1, s2, s. 1 and s. 2 such that s1 s2 = s, \ns. = s.. 1 s. ,(s1,s. ) |= a, and (s2,s. ) |= a 212 ((s,i,h),(s,i,h.)) |= .X.a i. there exist n and i. \nsuch that i. = i{X . n}, and ((s,i. ,h),(s,i. ,h.)) |= a (s, s.) |= a . ai. if (s, s.) |= a, then (s, \ns.) |= a... def def def Emp = emp . emp True = true . true Id = [true] def [[a]] = {(s, s.) | (s, s.) \n|= a} Figure 8. Semantics of Actions whose de.nitions are also shown in Fig. 7. O contains a set of program \nvariables, as de.ned in Fig. 6. We omit other assertions here, which are standard separation logic assertions. \nAs in Separation Logic, the precision of assertions is de.ned below. Informally, a predicate p is precise \nif and only if for any state there is at most one sub-state satisfying p. De.nition 5.1 (Precise Assertions) \nAn assertion p is precise, i.e., precise(p) holds, if and only if for all s, i, h, s1, s2, h1, h2,if \ns1 . s, s2 . s, h1 . h, h2 . h,(s1,i,h1) |=sl p and (s2,i,h2) |=sl p,then s1 = s2 and h1 = h2. Actions. \nWe use actions a to specify state transitions. As shown in Fig. 6, rely/guarantee conditions of threads \nare actions. Semantics of actions are de.ned in Fig. 8. The action p . q means the initial state of the \ntransition satis.es p and the resulting state satis.es q.[p] speci.es an identity transition with the \nstates satisfying p. a * a. means the actions a and a. start from disjoint states and [p] . p . p [p] \n. Id [emp] . Emp a . True a *Emp . a (p * p.) . (q *q.) . (p . q) *(p. . q.) a *a. . a. *a a1 . a. 1 \na2 . a. 2 a1 *a2 . a. 1 *a. 2 p . p. q . q. p . q . p. . q. Figure 9. Selected Proof Rules for Actions \nthe resulting states are also disjoint. Emp, True and Id are de.ned using these primitive actions, which \nrepresent empty transitions, arbitrary transitions and arbitrary identity transitions respectively. Weuse \n[ a] to represent the set of transitions satisfying a, and use (s, s.) |= a and (s, s.) . [[a] interchangeably \nin this paper. In Fig. 9, we show some selected proof rules for actions, which are sound with respect \nto the semantics of actions. Many proof rules for Separation Logic assertions can also be ported here \nfor actions. They are omitted due to space limits. Examples of actions are shown below. The following \nlemma shows the monotonicity of the action a *Id: Lemma 5.2 If (s1,s2) |= a * Id, s. = s1 . s.,and s. \n= s2 . s. , 12 then (s. 1,s. ) |= a *Id. 2 Stability. Next we introduce the concept of stability of an \nasser\u00adtion p with respect to an action a. De.nition 5.3 (Stability) We say p is stable with respect to \nthe action a, i.e., Sta(p,a) holds, if and only if for all s and s.,if s |=sl p and (s, s.) |= a,then \ns.|=sl p. Informally, Sta(p,a) means the validity of p is preserved by transitions in [ a]]. Examples \nof Sta(p,a) are shown below. Follow\u00ading RGSep (Vafeiadis and Parkinson 2007), the following lemma shows \nthe encoding of stability using the septraction p -.q. Lemma 5.4 Thefollowing aretrue: Sta(r, p . q) \nif and only if ((p -.r) .emp) *q . r;  If (p -.r) *q . r,then Sta(r, p . q);  Sta(r,(p . q) *Id) if \nand only if (p -.r) *q . r.  The separating conjunction a *a. over actions allows us to com\u00adpose disjoint \ntransitions into one. Naturally, we want the following property about stability to hold: If Sta(p,a) \nand Sta(p,a.),then Sta(p * p,a *a.). As explained in Sec. 3, this property is important to support local \nreasoning. Unfortunately, it is not true in general, as shown in the following example. The example also \nshows that we cannot get this property even with precise p and p. . Example 5.5 Let a = ([.1 ... n2 +1)), \ndef . n1]) . ((.2 . n2) . (.2 . def . def p = .= ([.2 ... n1+1)), and .1 . n1, a. n2]).((.1 . n1) . (.1 \n. def p. = .2 ..n2, and suppose .1 . .2, we can prove Sta(p,a)and Sta(p,a.), but Sta(p * p,a *a.) does \nnot hold. Here is a counterexample. Let the heap h be {.1 . n1,.2 . n2}, and h. be {.1 . n1 + 1,.2 . \nn2 + 1}. Then, for any s, s. and i, we have (s,i,h) |=sl p * p. and ((s,i,h),(s,i,h.)) |= a * a.,but \n(s,i,h.) |=sl p * p. does not hold. . I . aI . a. I . aI.. a. I . [I] I . (I . I) .. I . a .aI *I.. a \n*a Figure 10. Selected Rules for Fence (Assuming precise(I)) To establish the property, we seem to need \nsome concept of precise actions , similar to the requirement of precise assertions in Separation Logic. \nHowever, precision alone cannot address our problem. The following example shows that even if we have \nSta(p1,(r1 . r1)) and Sta(p2,(r2 . r2)) for precise p1,r1,r1, p2,r2 and r2, we do not necessarily have \nSta(p1 *p2,(r1 . r1)*(r2 . r2)). def def def Example 5.6 Let p1 = .= .= ..n2 +1, .1 .n1, r1 .2 .n2, r1 \n.2 def def def p2 == . = .1 . r1, r2 p1, r2 .n1+1, and suppose .1 . .2.We know Sta(p1,(r1 . r1)) and \nSta(p2,(r2 . r2)) are vacuously true, but Sta(p1 *p2,(r1 . r.) *(r2 . r.)) is false. . 12 The problem \nis, p and a may specify di.erent resources even if Sta(p,a) holds. To address this issue, we introduce \ninvariant-fenced actions and use an invariant to identify the speci.ed resource. Invariant-Fenced Actions. \nThe following de.nition says an ac\u00adtion a is fenced by a precise invariant I (represented as I . a)if \nand only if a holds over identity transitions satisfying [I], and I holds over the beginning and end \nstates of transitions satisfying a. De.nition 5.7 (Fence) I . a holds i. [I] .a, a .(I . I)and precise(I). \nIt is natural to ask a to hold over identity transitions so that stutter\u00ading steps of processes would \nalso satisfy it. The second requirement is important to determine the boundary of transitions a and a. \nin a *a.: the boundary can be uniquely determined if a or a.is fenced by a precise invariant I. Lemma \n5.8 If (s1 s2,s.) |= a *a, s1 |=sl I and I . a, then there exist unique s. and s. such that s. = s. 1 \ns.,(s1,s.) |= a and 12 21 (s2,s.) |= a. 2 From Lemma 5.8 we can derive the following frame property of \nthe action a *Id. Corollary 5.9 If (s1 s2,s.) |= a *Id, s1 |=sl I and I .a, then there exists s. 1 such \nthat s. = s. 1 s2 and (s1,s1.) .[[a]]. Figure 10 shows some selected proof rules for the fencing rela\u00adtion. \nThe following lemma shows that the property about stability discussed in the previous section holds given \nan action fenced by a precise invariant. Lemma 5.10 If Sta(p,a), Sta(p,a.), p .I and I . a,we have Sta(p \n*p,a *a.). Below we give two examples to show invariant fenced actions. In particular, Example 5.12 shows \nthat asking I in I .a to be precise does not prevent the action a from changing the size of the resource. \nExample 5.11 Let I = .1 . . *.2 . . , a1 = [.1 ..X *.2 ..Y], a2 = ((.1 ..2 ...2 . . X *.Y) .X > Y) . \n(.1 .X -Y *.Y), and a3 = ((.1 ..2 .Y) .X < Y) . (.1 .X *.We . X *...2 .Y -X). have I . a1, I . (a1 .a2), \nI . (a1 .a3), and I . (a1 .a2 .a3), but not I . a2 or I . a3. .  Example 5.12 We de.ne List(.,n) as \na linked list pointed to by . with length n: def List(.,0) = . = 0 .emp def List(.,n+1) = (emps .. . \n0 .(. .. *.+1 .List(.. ...)) *,n) Let I = .n. List(.,n), and a = (List(.,m) .m =n) . (List(.,n)). We \ncan prove that I . a holds. . 6. The LRG Logic As in SAGL/RGSep, we also split program states into private \nand shared parts, but the partition is logical and we do not change our model of states de.ned in Fig. \n4. Our logic ensures that each thread has exclusive access to its private resource. The rely/guarantee \nconditions only specify transitions over shared resources. If a statement C only accesses the private \nresource, it can be veri.ed as sequential programs using a set of sequential rules. The judgment for \nwell-formed sequential programs is in the form of {p}C {q}. The rules are mostly standard Separation \nLogic rules except that program variables are treated as resources, follow\u00ading Parkinson et al. (2006). \nThey are omitted due to space limits and can be found in the extended version of the paper (Feng 2008). \nNote that, to prove {p}C {q}, C cannot contain atomic statements and parallel compositions. 6.1 Rules \nfor Concurrency Veri.cation If the statement C shares resources with its environment, we need to consider \nits interaction with the environment and verify it using the set of rules for concurrency, shown in Fig. \n11. The judgment for well-formed statements C in a concurrent setting is in the form of R; G; I .{p}C \n{q}. R and G are rely/guarantee conditions. They are fenced by the invariant I. p and q are pre-and post\u00adconditions. \nR, G and I only specify shared resources, but p and q here specify the whole state. Unlike SAGL/RGSep, \nwe do not distinguish private and shared resources syntactically in assertions. Instead, their boundary \ncan be determined by the invariant I. The env rule allows us to convert the judgment {p}C {q}into the \nconcurrent form. If C only accesses the private resources and is well-behaved sequentially, it is well-behaved \nin a concurrent setting where there is no resource sharing. Here the rely/guarantee conditions are Emp \nand the invariant is emp, showing the shared resource is empty. This rule itself is not very useful since \nit does not allow resource sharing, but a more interesting rule can be derived from this rule and the \nframe rule shown below. The atomic rule .rst requires that the state contain the resource used to evaluate \nB (as explained in Sec. 5, B = B is no longer a tautology when variables are treated as resources). Since \nthe execution of C cannot be interrupted by the environment, we can treat the whole state as a private \nresource and verify C using the sequential rules. Outside of the atomic block, p and q need to be stable \nwith respect to R *Id, R for the shared resource and Id for the private (i.e., the environment does not \ntouch the private resource). The transition p . q consists of sub-transitions over shared and private \nresources. The one over shared needs to satisfy G,and the private one can be arbitrary (i.e., True). \nThe rule also requires that the shared resource be well-formed with respect to the invariant (i.e., p \n.q .I *true), and that R/G be fenced by I.Tohave a concise presentation, we use Sta({r,r.},R) as a short \nhand for Sta(r,R) .Sta(r,R), and I . {R,G}for (I . R) .(I . G). Similar representations are used in the \nremaining part of the paper. The p-seq rule for sequential composition is the same as in standard Rely-Guarantee \nreasoning and does not need explanation. In the rules p-while and p-if, we require that the resource \nneeded to {p}C {q} R; G; I .{p}C1 {q} R; G; I .{q}C2 {r} (env)(p-seq) Emp; Emp; emp .{p}C {q} R; G; \nI .{p}C1;C2 {r} p .B = B {p .B}C {q} Sta({p, q}, R *Id) p . q .G *True p .q .I *true I . {R,G} (atomic) \n R; G; I .{p}atomic(B){C}{q} p .(B = B) *IR; G; I .{p .B}C {p} p .(B = B) *IR; G; I .{p .B}C1 {q} R; \nG; I .{p .\u00acB}C2 {q} (p-while)(p-if) R; G; I .{p}while B do C {p .\u00acB} R; G; I .{p}if B then C1 else C2 \n{q} R .G2; G1; I .{p1 *r}C1 {q1 *r1} R .G1; G2; I .{p2 *r}C2 {q2 *r2} r .r1 .r2 .II . R (par) R; G1 \n.G2; I .{p1 *p2 *r}C1 .C2 {q1 *q2 *(r1 .r2)} R; G; I .{p}C {q} Sta(r, R.*Id) I.. {R. ,G.} r .I.*true \nR *R.; G *G.; I *I..{p}C {q} I . {R,G} (frame)(hide) R *R.; G *G.; I *I..{p *r}C {q *r} R; G; I .{p}C \n{q} R; G; I .{p}C {q} R; G; I .{p}C {q} R; G; I .{p}C {q}X not free in R,G, and IR; G; I .{p.}C {q.} \nR; G; I .{p.}C {q.}(p-ex)(p-conj)(p-disj) R; G; I .{.X. p}C {.X. q} R; G; I .{p .p.}C {q .q.} R; G; I \n.{p .p.}C {q .q.} p..pR..RG .G. q .qR; G; I .{p}C {q} p..q..I.*true I.. {R. ,G.} (csq) R.; G.; I..{p.}C \n{q.} Figure 11. Inference Rules for Concurrency evaluate B be available in p but disjoint with the shared \nresource in I, i.e., it is in the private part. Therefore, the validity of B would not be a.ected by \nthe environment. The par rule is similar to the one in RGSep shown in Sec. 2.3. The parent thread distribute \np1 and p2 to the children C1 and C2 respectively as their private resources. The resource r is shared \nby them. We require that r, r1 and r2 imply I, i.e., the shared resource is well-formed. Also R needs \nto be fenced by I. The frame rule allows us to verify C with local speci.cations, and reuse it in contexts \nwhere some extra resource r (i.e., the frame) is used. The frame r contains both private and shared parts. \nSince C does not access it, the validity of r is preserved at the end as long as r is stable with respect \nto R.*Id, R.for the shared part and Id for the private. We also require that R. and G. be fenced by the \n(precise) invariant I., and that the shared part in the frame satisfy I..Here G. is the thread s guaranteed \ntransition over the extra shared part. Since G. is fenced by I., we know the identity transition made \nby C over r indeed satis.es G.. This frame rule is more general than the two frame rules in Sec. 3 for \nshared and private resources. As we will explain later, they can be derived from this rule. If C knows \nthat the part of the shared resources speci.ed by R. , G. and I. is actually not accessed by the outside \nworld, it can leave this part unspeci.ed by applying the hide rule. The hide rule is sim\u00adilar to its \nprototype shown in Sec. 3. Note that we do not use two assertions for private and shared resources respectively \nand use the invariant to determine their boundary instead, therefore changing the invariant from I *I. \nto I introduces an implicit conversion of resources from shared to private. This conversion is explicit \nin the prototyping rule in Sec. 3. The advantage of not using two asser\u00adtions is that we can easily share \ninformation in the speci.cations for private and shared resources. As usual, the hiding rule also requires \nR and G be fenced by the precise invariant I. As mentioned in Sec. 3, a thread cannot abuse the freedom \nprovided by the hide rule by hiding the resources that are indeed shared. The inappropriate hiding can \nbe detected at the time of the parallel composition. From the par rule we can see that the private resource \np1 of C1 needs to be composed linearly using the separating conjunction with both the private (p2) and \nthe shared (r) resources used by C2.If C1 cheats by converting part of r into p1 using the hide rule, \nthe linearity would be broken and the precondition after parallel composition would be unsatis.able. \nThe p-ex rule introduces existential quanti.cation over speci.\u00adcations. The conjunction rule (p-conj) \nis sound in LRG. The p-disj rule is a standard disjunction rule. The consequence rule (csq)al\u00adlows adaptations \nof di.erent part of the speci.cations. It is important to note that, like RGSep, we do not have concur\u00adrency \nrules for primitive statements, therefore they either only ac\u00adcess the private resource or access the \nshared part inside the atomic block (where the shared resource has been converted into private). Derived \nRules. In Fig. 12, we show several useful rules that can be derived from the basic set of rules. The \nenv-share rule is similar to the env rule in Fig. 11, but allows resource sharing with the environment. \nIt is derived from the env rule and the frame rule. The rules fr-private and fr-share are frame rules \nfor private and shared resources respectively, similar to those shown in Sec. 3. They are derived from \nthe frame rule. To get fr-private,we simply instantiate R. and G. with Emp and I. with emp in the frame \nrule. The fr-share rule is similar to the frame rule, except r contains only shared resource. The par-hide \nrule is a generalization of the par rule. The parent thread has private resource p1 *p2 *m and shares \nthe resource r with its environments. p1 and p2 are distributed to C1 and C2 respectively as their private \nresources. m and r are sharedbythem. The guarantees about the use of m by the two processes are G. 1 \nand G. 2 respectively, which are fenced by I..Since m is private resource of the parent thread, the sharing \nbetween children threads does not need to be exposed to the environments. Thus R, G1 and G2 only specify \ntransitions over the resource speci.ed by r. They are fenced by I. Here we also require that r, r. and \nr.. all imply I;and that m, m. and m.. all imply I..Toderive the par-hide rule, we .rst apply the par \nrule, and then apply the hide rule to convert m to private {p}C {q} Sta(r,R *Id) I . {R,G} r .I *true \n(env-share) R; G; I .{p *r}C {q *r} R; G; I .{p}C {q} R; G; I .{p}C {q} Sta(r,R.) I.. {R. ,G.} r .I. \n(fr-private)(fr-share) R; G; I .{p *r}C {q *r} R *R.; G *G.; I *I..{p *r}C {q *r} (R .G2) *G. 2; G1 *G1.; \nI *I..{p1 *m *r}C1 {q1 *m1 *r1} (R .G1) *G. 1; G2 *G. 2; I *I..{p2 *m *r}C2 {q2 *m2 *r2} I . {R,G1,G2} \nI.. {G. 1,G. 2} r .r1 .r2 .Im .m1 .m2 .I. (par-hide) R; G1 .G2; I .{p1 *p2 *m *r}C1 .C2 {q1 *q2 *(m1 \n.m2) *(r1 .r2)} Figure 12. Useful Derived Rules and to hide G. 1 and G. 2. The derivation is shown in \nthe extended version (Feng 2008).  6.2 Semantics and Soundness The semantics for the judgment {p}C {q} \nis standard, and the soundness of sequential rules is formalized and proved following the standard way \nestablished in previous works on sequential Sep\u00adaration Logic (Yang and O Hearn 2002). .* De.nition 6.1 \n|= {p}C {q}i.,for any ssuch that s|=sl p,(C,s) . abort, and, if (C,s) .*(skip,s.), then s.|=sl q. Lemma \n6.2 (Seq-Soundness) If {p}C {q},then |= {p}C {q}. Before we de.ne the semantics for the judgment R; G; \nI . {p}C {q}, we introduce the non-interference property. De.nition 6.3 (Non-Interference) (C,s,R) =.0 \nGalways holds; (C,s,R) =.n+1 Gholds i. (C,s) .. abort, and, (1) for all s.,if(s,s.) .R, then for all \nk =n,(C,s. ,R) =.k G; (2) for all s.,if(C,s) . (C.,s.), then (s,s.) .Gand (C.,s. ,R) =.k Gholds for \nall k =n.  n So (C,s,R) =.Gmeans, starting from the state s, C does not interfere with the environment \ns transitions in Rup to n steps, and transitions made by C are in G. It also implies the parallel execution \nof C does not abort within n steps, as the following lemma shows. n Lemma 6.4 If (C,s,R) =.G, there does \nnot exist j such that R j < n and (C,s). -.jabort. The semantics of R; G; I .{p}C {q}is de.ned below. \nTheo\u00adrem 6.6 shows the soundness of the logic. De.nition 6.5 R; G; I |= {p}C {q}i.,for all s such that \ns |=sl p, thefollowing aretrue(where R= [[R *Id]] and G= [[G *True]]): R (1) if(C,s).*(skip,s.), then \ns.| -.=sl q; (2) for all n, (C,s,R) =.n G. Theorem 6.6 (Soundness) If R; G; I .{p}C {q},then R; G; I \n|= {p}C {q}. To prove the soundness, we .rst prove the following properties about the syntactic judgment. \nO . (x = X) .(x ..M,N) 1 .t11 := [x].; .t21 := [x + 1].; 2 .t12 := [x + 1].; .t22 := [x].; 3 while (t11 \n. t12) do{ while (t21 . t22) do{ 4 if(t11 > t12) then { if(t21 > t22) then { 5 t11 := t11 -t12; t21 := \nt21 -t22; 6 .[x] := t11.; .[x + 1] := t21.; 7 } } 8 .t12 := [x + 1].; .t22 := [x].; 9 } } O . .U. (x \n= X) .(x ..U,U) .(U = gcd(M,N)) where O = x,t11,t12,t21,t22, def def def R = Emp G = Emp I = emp Figure \n13. Example: Veri.cation of Concurrent GCD Lemma 6.7 If R; G; I .{p}C {q},then I . {R,G} and p .q . I \n*true. Proof. By induction over the derivation of R; G; I .{p}C {q}. . As in sequential Separation Logic, \nthe locality property (Yang and O Hearn 2002; Calcagno et al. 2007a) of primitive statements is essential \nto prove the soundness. In addition, in the concurrent setting, we need similar properties about the \nenvironment s behav\u00adior. Lemma 5.2 and Corollary 5.9 show the monotonic property and the frame property \nof R *Id. Theorem 6.6 is proved by induction over the derivation of R; G; I .{p}C {q}. We show some main \nlemmas used in the proof in Appendix A. More details can be found in the extended version of the paper \n(Feng 2008). 7. Examples In this section we show how the programs in Figs. 1 and 2 can be veri.ed modularly \nusing the LRG logic. Although the example is very simple and may be a bit contrived, it is very representative \nin that it involves both .ne-grained concurrency and lock-based pro\u00adtection of resources, it creates \nchildren threads that share dynami\u00adcally allocated resources, and it requires both local reasoning and \ninformation hiding. 7.1 Concurrent GCD We .rst show the veri.cation of the concurrent GCD program using \nlocal speci.cations. We show the program and the speci.cations in Fig. 13. The program is the same as \nin Fig. 2. In the example, the parent thread forks two threads. The .rst one (the one on the left) reads \nthe values [x] and [x + 1], but only p1 = x . x . def = X .(x .Y,Z) p2 def = X .(x .Y,Z) .Y < Z = x . \nx . def p= .Z. . x . x = X .(x ..Y,Z.) .Z. < Z .gcd(Y,Z) = gcd(Y,Z.) 2 def p3 = x . x = X .(x ..Y,Z) \n.Y > Z . def .Y..Y. p= . x . x = X .(x .,Z) .Y. < Y .gcd(Y,Z) = gcd(Y. ,Z) 3 def def R1 = (p1 . p1) .(p2 \n. p2) G1 = (p1 . p1) .(p3 . p3) def def R2 = G1 G2 = R1 I. def = x . x ..* x+1 .. r10 = .Z. x . x . def \n= X .(x . M,Z) .gcd(M,Z) = gcd(M, N) def p10 = (t11,t12 . emph) *r10 def p11 = (t11,t12 . t11 = M) *r10 \ndef .Y,Z.) .(Z =Z.) .(Y =Z .Z = Z.) .gcd(Y,Z.) = gcd(M, N) def r12 = .Z. . x . x = X .(x . p12 = .Y,Z. \n(t11,t12 . t11 = Y .t12 = Z) *r12 def p13 = p12 def p14 = .Y,Z. (t11,t12 . t11 = Y .t12 = Z .Y > Z) *r12 \ndef p15 = .Y,Z. (t11,t12 . t11 = (Y -Z) .t12 = Z .Y > Z) *r12 def def def p16 = p12 p17 = p12 p18 = p12 \ndef p19 = .Y,Z. (t11,t12 . t11 = Y .t12 = Z .Y = Z) *r12 Figure 14. Spec. and Intermediate Assertions \nfor the First Thread updates [x] if [x] > [x + 1]. The second one (the one on the right) does the reverse. \nThe variable x is shared by both threads. t11, t12, t21 and t22 are temporary variables used exclusively \nin one of the threads. We use .C. as the syntactic sugar for atomic(true){C}.In this .ne-grained concurrent \nprogram, we only put basic memory loads and stores into atomic blocks. Figure 13 shows in boxes the pre-condition \nbefore forking the two threads and the post-condition after their join. Recall that the assertion O . \np is de.ned in Fig. 7. The parent thread owns the variables and the memory cells at locations x and x \n+ 1as private resources. Here we use x .. . M, N as a short hand for x . M *x+1 . .N. At the end, we \nknow the value of x is preserved, and values of [x] and [x+1] are the GCD of their initial values. Recall \nthat capital variables are auxiliary logical variables. The shared resource of the parent thread is empty. \nIts R and G are simply Emp. The invariant fencing them is emp. To verify the parent thread, we need to \n.rst apply the par\u00adhide rule shown in Fig. 12. Temporaries (t11, t12, t21, t22)are distributed to the \nchildren as their private resources. The variable x and the memory cells pointed to by x are sharedbythem. \nThe precondition p10 for the .rst thread is speci.ed in Fig. 14, where r10 speci.es the shared resource. \nBecause of the symmetry between the .rst and the second threads, we elide speci.cations for the second \nthread. The rely and guarantee conditions of children threads are shown in Fig. 14. R1 is the .rst thread \ns assumption about the behavior of its environment containing the second thread. It says the environ\u00adment \npreserves the value of the shared variable x, and it either pre\u00adserves the value stored at x and x+1, \nor decrease the value at x+1 if its original value is bigger than the value at x, but the GCD of new \nvalues is the same as the GCD of original values. The guaran\u00adtee G1 is similar. Because of the symmetry, \nwe use G2 and R2 are simply R1 and G1.We use I. to fence them. It is easy to see that I. is precise and \nI.. {R1,R2,G1,G2}holds. In Fig. 14, we present all the intermediate assertions as a proof sketch for \nthe .rst thread. The assertion p1k is the post-condition def I = emps ..X. (lhead ..X) *(X = 1 .r .X \n= 0 .emph) r = . def ... (lheap+1 ..) *List(.) def List(.) = (. = 0 .emph) .(. . 0 .... . (. .., ,..) \n*List(..)) def def R = I . IG = I . I (O . emph) *I 1 nd := 0; (O . nd = 0 .emph .(nd .. , , )) *I 2 \nwhile (nd = 0) do { 3 lk := 0; (O . lk = 0 .emph .lk = 1 .r) *I 4 while (lk . 1) do { 5 .lk := [lhead]; \nif (lk = 1) then [lhead] := 0;. 6 } (O . r) *I 7 nd := [lhead + 1]; 8 if (nd . 0) then { 9 tmp := [nd \n+ 2]; [lhead + 1] := tmp 10 } (O . (nd = 0 .emph .(nd ..,, )) *r) *I 11 .[lhead] := 1.; (O . nd = 0 \n.emph .(nd ..,, )) *I 12 }(O . (nd . . ,, )) *I 13 tmp := [nd]; tmp. := [nd+1]; x := cons(tmp,tmp.); \n(O . .M, N. (nd .) *(x ..M, N)) *I . M, N, 14 Cgcd (O . .M, N,U. (nd .) *(x ..U,U) .gcd(M, N) = U) *I \n. M, N, Figure 15. Example: GCD of Nodes on List following the k-th line. The sub-assertion r1j speci.es \nthe shared resource. It is important to note that R1 and G1 specify the change and preservation of values \nin memory, which are crucial to verify the partial correctness. For instance, in p11 we know the value \nof t11 is consistent with the value at the memory location x because R1 ensures the environment does \nnot update [x]. Similarly, we can derive the relationship between the value of t12 and the value at the \nmemory location x+1in p12. We omit details of the veri.cation of the child thread, which have been shown \nseveral times before to illustrate Rely-Guarantee reasoning (Yu and Shao 2004; Feng and Shao 2005; Feng \net al. 2007). What is new here is our speci.cation for the parent thread, where the local sharing of \nmemory cells at x and x +1 is hidden from the environment since R, G and I are simply empty. 7.2 Veri.cation \nof the Thread in Fig. 1 We show the program again in Fig. 15 with speci.cations and in\u00adtermediate assertions. \nThe invariant I speci.es the well-formedness of the shared resource (recall its structure is illustrated \nin Sec. 2.4). The rely and guarantee conditions are simply I . I. The veri.cation of lines 1 13 simply \napplies the technique for ownership transfer in CSL (O Hearn 2007). Similar examples have been shown \nin Feng et al. (2007) and Vafeiadis and Parkinson (2007). Here we show some important intermediate assertions \nto demonstrate the sketch of the proof and do not explain the details. In each assertion, O speci.es \nthe ownership of variables used in the thread and its de.nition is omitted. The shared resource is always \nspeci.ed by I. The assertion following Line 13 shows that the allocated mem\u00adory block at the location \nx is treated as private resource, so it does not a.ect our speci.cation of R and G. The pre-and post-conditions \nfor Line 14 (Cgcd)are di.erent from the local speci.cations given in Fig. 13. To reuse our proof for \nCgcd in the previous section, we can prove it also satis.es the new speci.cation by applying the frame \nrule. 8. Related Work and Conclusions Rely-Guarantee reasoning has been a well-studied method since it \nwas proposed by Jones (Jones 1983). A comprehensive survey of related works can be found in the book \nby de Roever et al. (2001). Most of the works, however, have the same compositionality prob\u00adlems explained \nin the beginning of this paper. Reynolds et al. (Reynolds 2002; Ishtiaq and O Hearn 2001) pro\u00adposed Separation \nLogic for modular veri.cation of sequential pro\u00adgrams. O Hearn has applied the ideas of local reasoning \nand own\u00adership transfers in Concurrent Separation Logic (CSL) for concur\u00adrency veri.cation (O Hearn 2007). \nCSL is modular, but the limited expressiveness of the program invariants I makes it di.cult to rea\u00adson \nabout .ne-grained concurrency. This paper extends recent works on SAGL (Feng et al. 2007) and RGSep (Vafeiadis \nand Parkinson 2007) that have tried to combine merits of both Rely-Guarantee reasoning and Separation \nLogic. Many technical details are borrowed directly from RGSep, such as the use of the global atomic \nblock and the combination of small-step and big-step operational semantics to model atomicity, but the \ndi.erences between our work and SAGL/RGSep are also substantial. We de.ne the separating conjunction \nof rely/guarantee conditions, and introduce a frame rule and hiding rule in the logic. These extensions \nallow us to support local speci.cations of rely/guarantee conditions, to hide locally shared resources \nfrom global speci.cations, and to support sharing of dynamically created resources, which are all open \nproblems unsolved in SAGL/RGSep. One more important improvement over SAGL/RGSep is our assertion language \nfor pre-and post-conditions. SAGL uses two Separation Logic assertions to specify private and shared \nresources respectively. It is di.cult for them to share information. RGSep uses two level logics to address \nthis problem. Shared resources are speci.ed using boxed assertions in a new logic built over Separa\u00adtion \nLogic assertions. In LRG, all we need is just Separation Logic assertions. We do not need to specify \nprivate and shared resources separately. The boundary is interpreted logically by the asserter and is \nfenced by I. On the other hand, SAGL and RGSep do not need I. Our model of program states is also di.erent \nfrom RGSep. In RGSep the partition of private and shared resources is made phys\u00adically in the program \nstates. We do not follow this approach for several reasons. First, it is somewhat inconsistent with the \nphilos\u00adophy of ownership is in the eye of the asserter (O Hearn et al. 2004; O Hearn 2007), that is, \nthe change of the boundary between resources is purely logical and there should be no operational ef\u00adfects. \nTechnically, it makes the operational semantics depend on the assertion language because atomic blocks \nneed to be annotated with precise post-conditions to decide the new physical boundary of resources at \nthe exit. In addition, environments that are coop\u00aderative in this model might be ill-behaved in the traditional \nthread model with shared address spaces. Although this would not a.ect the soundness over closed programs \nin both models, the soundness of RGSep over programs with open environments does not hold in the traditional \nthread model. Vafeiadis (2007) extends RGSep with multiple atomic blocks for multiple regions of shared \nresources. He also supports local rely and guarantee conditions that specify only individual regions. \nHowever, the pre-/post and rely/guarantee conditions for di.erent regions need to be distinguished syntactically \nusing the names of regions, so the assertion language is even more complex than in RGSep. The partition \nof regions is also done physically in pro\u00adgram states. This allows him to avoid the problems shown in \nExam\u00adples 5.5 and 5.6, but has the same limitations as in RGSep explained above. We use the separating \nconjunction of actions to model sub\u00adtransitions over disjoint resources. There is no need of multiple \natomic blocks and physical regions. Regions in LRG are implicit, whose boundaries are determined logically \nby the resource invari\u00adants. The associativity of separating conjunction allows us to .exi\u00adbly merge \nand split regions. Our work can also be viewed as an extension of CSL with the more expressive rely/guarantee \nstyle speci.cations, but with\u00adout sacri.cing its modularity. Although not proved in this paper, we believe \nCSL can be shown as a specialized version of LRG in the sense that, given a CSL judgment {p}C{q}, we \ncan prove I.. I.; I.. I.; I..{p *I.}C {q *I.}in LRG. I. is in the form of (in atomic).emp.(not in atomic).I \n, and I is the invariant about the resource protected by the atomic block. Bornat et al. (2005) extend \nCSL with permission accounting, where the fractional permissions less than 1 represent read-only permissions. \nFor simplicity, we do not support fractional permis\u00adsions. Rely/guarantee conditions seem to have similar \nexpressive\u00adness to say some data is read-only. On the other hand, adding frac\u00adtional permissions to LRG \nmay further simplify speci.cations of rely/guarantee conditions. It would be interesting future work \nto study their relationships. Yang (2007) proposes a relational separation logic to verify equivalence \nof programs. He also uses assertions over a pair of program states and de.nes separating conjunction \nover these as\u00adsertions, but his assertions are used for very di.erent purposes instead of specifying \nstate transitions, they are used to relate pro\u00adgram states in di.erent programs. Benton (2006) has similar \nde.ni\u00adtion of separating conjunction of binary relations, which is used to reason about program equivalence \ninstead of modeling state tran\u00adsitions. Benton uses accessibility maps to determine the bound\u00adaries of \nregions of heap, similar to our use of invariants to fence rely/guarantee conditions. Dynamic Frames \nare also used (Kassios 2006) for similar purposes. The major limitation of LRG is the requirement of \nprecise resource invariants, which might be too restrictive to reason about programs that leak shared \nresources. In particular, there are simple lock-free algorithms that intentionally introduce memory leaks \nto avoid ABA problems (Herlihy and Shavit 2008). Their correctness depends on the existence of garbage \ncollectors (GC). We may not be able to verify them using LRG. On the other hand, these algorithms can \nbe instrumented using GC-independent techniques, e.g., hazard pointers (Michael 2004). We believe the \ninstrumented algorithms can be veri.ed using LRG, and will test our hypothesis in our future work. CSL \nhas the similar restriction to precise invariants, but it can be relaxed by using supported assertions \nas invariants and using intuitionistic assertions to specify private resources (O Hearn et al. 2004; \nBrookes 2007). It is unclear if we can have the same relax\u00adation. The di.culty is caused by the asymmetric \nextensions of R (to R*Id)and G (to G*True) in De.nition 6.5 and in the atomic rule. Suppose we have threads \nT1 and T2.The Id in T1 s rely con\u00addition R1 *Id speci.es the inaccessibility of T1 s private resources \nby the environment. The True in T2 s guarantee G2 *True speci.es T2 s exclusive access of its private \nresources. Therefore, to ensure the non-interference, G2 and R1 must have a uniform view of the shared \nresources, which is enforced by a precise invariant. A sup\u00adported invariant is not su.cient for this \npurpose. The asymmetric treatment of R and G results from our attempt to eliminate explicit distinctions \nbetween shared and private resources. Since RGSep and SAGL have the explicit distinctions, they do not \nneed a pre\u00adcise view of shared resources. Another limitation of LRG is that it only supports the veri.ca\u00adtion \nof safety properties (including partial correctness). Gotsman et al. (2009) extend RGSep to reason about \ncertain liveness proper\u00adties of non-blocking algorithms. It would be interesting to see if it is possible \nto extend LRG following similar approaches. Also, we do not discuss the issues about automated veri.cation \nin this pa\u00adper. Many works have been done to automate the Rely-Guarantee based veri.cation, e.g., Flanagan \net al. (2005) and Calcagno et al. (2007b). We would like to combine these techniques with the new LRG \nlogic in the future. In summary, we propose the LRG logic in this paper for local Rely-Guarantee reasoning. \nIntroducing separating conjunction of actions allows us to borrow the techniques developed in Separation \nLogic for local reasoning. Our LRG logic, for the .rst time, sup\u00adports a frame rule over rely/guarantee \nconditions and a hiding rule for hiding the local sharing of resources from the outside world. These \nrules allow us to write local rely/guarantee conditions and improve the reusability of veri.ed program \nmodules. Acknowledgments I would like to thank Matthew Parkinson for the inspiring discus\u00adsions and suggestions. \nIn particular, Matthew suggested to add the hide rule and showed that the par-hide rule, which was a \nbuilt-in rule in an earlier version of the paper, could be derived from the hide rule and the par rule. \nThanks to Viktor Vafeiadis, Zhong Shao, and anonymous referees for their suggestions and comments on \nearlier versions of this paper. References Nick Benton. Abstracting allocation : The new new thing. In \nProc. Computer Science Logic (CSL 06), volume 4207 of Lecture Notes in Computer Science, pages 182 196. \nSpringer, September 2006. Richard Bornat, Cristiano Calcagno, Peter W. O Hearn, and Matthew J. Parkinson. \nPermission accounting in separation logic. In Proc. 32nd ACM Symp. on Principles of Prog. Lang. (POPL \n05), pages 259 270. ACM Press, January 2005. Stephen Brookes. A semantics for concurrent separation logic. \nTheor. Comput. Sci., 375(1-3):227 270, 2007. Cristiano Calcagno, Peter W. O Hearn, and Hongseok Yang. \nLocal action and abstract separation logic. In Proc. 22nd Annual IEEE Symposium on Logic in Computer \nScience (LICS 07), pages 366 378. IEEE Computer Society, July 2007a. Cristiano Calcagno, Matthew J. Parkinson, \nand Viktor Vafeiadis. Modular safety checking for .ne-grained concurrency. In Proc. 14th Int l Sym\u00adposium \non Static Analysis (SAS 07), volume 4634 of Lecture Notes in Computer Science, pages 233 248. Springer, \nAugust 2007b. Willem-Paul de Roever, Frank de Boer, Ulrich Hanneman, Jozef Hooman, Yassine Lakhnech, \nMannes Poel, and Job Zwiers. Concurrency veri\u00ad.cation: introduction to compositional and noncompositional \nmethods. Cambridge University Press, 2001. Xinyu Feng. Local rely-guarantee reasoning (extended ver\u00adsion). \nTechnical Report TTIC-TR-2008-1, Toyota Technolog\u00adical Institute at Chicago, Chicago, IL, U.S.A., October \n2008. http://www.tti-c.org/technical reports/ttic-tr-2008-1.pdf. Xinyu Feng and Zhong Shao. Modular veri.cation \nof concurrent assembly code with dynamic thread creation and termination. In Proc. 2005 ACM Int l Conf. \non Functional Prog. (ICFP 05), pages 254 267. ACM Press, September 2005. Xinyu Feng, Rodrigo Ferreira, \nand Zhong Shao. On the relationship be\u00adtween concurrent separation logic and assume-guarantee reasoning. \nIn Proc. 16th European Symp. on Prog. (ESOP 07), volume 4421 of Lec\u00adture Notes in Computer Science, pages \n173 188. Springer, March 2007. Cormac Flanagan, Stephen N. Freund, Shaz Qadeer, and Sanjit A. Seshia. \nModular veri.cation of multithreaded programs. Theor. Comput. Sci., 338(1-3):153 183, 2005. Alexey Gotsman, \nByron Cook, Matthew J. Parkinson, and Viktor Vafeiadis. Proving that non-blocking algorithms don t block. \nIn Proc. 36th ACM Symp. on Principles of Prog. Lang. (POPL 09), page to appear. ACM Press, January 2009. \nMaurice Herlihy and Nir Shavit. The Art of Multiprocessor Programming. Morgan Kaufmann Publishers, March \n2008. Samin S. Ishtiaq and Peter W. O Hearn. BI as an assertion language for mutable data structures. \nIn Proc. 28th ACM Symp. on Principles of Prog. Lang. (POPL 01), pages 14 26. ACM Press, January 2001. \nCli. B. Jones. Tentative steps toward a development method for interfering programs. ACM Trans. Program. \nLang. Syst., 5(4):596 619, 1983. Cli. B. Jones. Wanted: a compositional approach to concurrency. In Programming \nMethodology, pages 5 15. Springer-Verlag, 2003. Ioannis T. Kassios. Dynamic frames: Support for framing, \ndependencies and sharing without restrictions. In Proc. 14th International Symposium on Formal Methods \n(FM 06), volume 4085 of Lecture Notes in Com\u00adputer Science, pages 268 283. Springer, August 2006. Maged \nM. Michael. Hazard pointers: Safe memory reclamation for lock\u00adfree objects. IEEE Transactions on Parallel \nand Distributed Systems,15 (6):491 504, 2004. Peter W. O Hearn. Resources, concurrency and local reasoning. \nTheor. Comput. Sci., 375(1-3):271 307, 2007. Peter W. O Hearn, Hongseok Yang, and John C. Reynolds. Separation \nand information hiding. In Proc. 31th ACM Symp. on Principles of Prog. Lang. (POPL 04), pages 268 280. \nACM Press, January 2004. Matthew J. Parkinson, Richard Bornat, and Cristiano Calcagno. Variables as resource \nin hoare logics. In Proc. 21st Annual IEEE Symposium on Logic in Computer Science (LICS 06), pages 137 \n146. IEEE Computer Society, August 2006. Matthew J. Parkinson, Richard Bornat, and Peter W. O Hearn. \nModular veri.cation of a non-blocking stack. In Proc. 34th ACM Symp. on Prin\u00adciples of Prog. Lang. (POPL \n07), pages 297 302. ACM Press, January 2007. John C. Reynolds. Separation logic: A logic for shared mutable \ndata structures. In Proc. 17th Annual IEEE Symposium on Logic in Computer Science (LICS 02), pages 55 \n74. IEEE Computer Society, July 2002. Viktor Vafeiadis. Modular Fine-Grained Concurrency Veri.cation.PhD \nthesis, University of Cambridge, July 2007. Viktor Vafeiadis and Matthew J. Parkinson. A marriage of \nrely/guarantee and separation logic. In Proc. 18th Int l Conf. on Concurrency Theory (CONCUR 07), volume \n4703 of Lecture Notes in Computer Science, pages 256 271, September 2007. Hongseok Yang. Relational separation \nlogic. Theor. Comput. Sci., 375(1-3): 308 334, 2007. Hongseok Yang and Peter W. O Hearn. A semantic basis \nfor local reason\u00ading. In Proc. 5th Int l Conf. on Foundations of Software Science and Computation Structures \n(FoSSaCS 02), volume 2303 of Lecture Notes in Computer Science, pages 402 416. Springer, April 2002. \nDachuan Yu and Zhong Shao. Veri.cation of safety properties for concur\u00adrent assembly code. In Proc. 2004 \nACM Int l Conf. on Functional Prog. (ICFP 04), pages 175 188. ACM Press, September 2004. A. Soundness \nProof for LRG Theorem 6.6 is proved by induction over the derivation of the judgment R; G; I .{p}C {q}. \nThe whole proof consists of the soundness proof for each individual rules. Here we show the main lemmas \nused to prove the soundness of frame, hide and par.More details are shown in the extended version (Feng \n2008).   A.1 Soundness of the frame rule Suppose the frame rule is applied to derive R * R. ; G * G. \n; I * I.. { p * r} C {q* r}. We want to prove R * R. ; G * G. ; I * I.|= { p * r} C {q* r}. By inversion \nof the frame rule we know R; G; I .{ p} C {q}, Sta(r,R.* Id), r . I.* true,and I. . {R. ,G.} hold. By \nthe induction hypothesis (of Theorem 6.6), we know R; G; I |= { p} C {q}.Also, by Lemma 6.7 we know I \n. {R,G} and p . I * true. Let R = [[R * Id]], R. = [[R * R.* Id]], G = [[G * True]], and G. = [[G * G.* \nTrue] . We can prove the following Lemmas A.1 and A.2. Soundness of the frame rule is shown in A.3. Lemma \nA.1 For all n, C, s1, s2 and s. ,if s1 |=sl I * true, R. s2 |=sl r,(C,s1,R) =. .n G,and (C,s1 . s2)-.n(skip,s. \n), then s. there exist s. and s. such that s. = 1 . s. 2, s2 .|=sl r,and 12 R (C,s1).1). -.n(skip,s. \n.n I * true,and s2 |=sl I.* true,then(C,s1 . s2,R. ) =. Lemma A.2 For all n, s1, s2 and C,if (C,s1,R) \n=G, s1 |=sl .n G. Lemma A.3 (Frame-Sound) If R; G; I |= { p} C {q},then R * R. ; G * G. ; I * I.|= { \np * r} C {q * r}. Proof. By De.nition 6.5, we need to prove that, for all s,if s |=sl p * r,we have R. \n(1) if(C,s). -.* (skip,s. ), then s.|=sl q * r; (2) for all n,(C,s,R. ) =.n G. .  By s |=sl p * r, \nwe know there exist s1 and s2 such that s = s1 . s2, s1 |=sl p,and s2 |=sl r.By R; G; I |= { p} C {q}, \nwe know: R (a) for all s.. ,if(C,s1).1 |=sl q;and-.* (skip,s.. ), then s.. 11 (b) for all n,(C,s1,R) \n=.n G. R. -.* (skip,s. ). From (b) and LemmaTo prove (1), suppose (C,s). A.1 we know there exists s. \nand s. such that s. = s1 .. s. 2, 12 R. s. 2 |=sl r,and (C,s1)-..* (skip,s. 1). By (a) we know s.|=sl \nq * r. The proof of (2) follows (b) and Lemma A.2. . A.2 Soundness of the hide rule Suppose the hide \nrule is applied to derive R; G; I .{ p} C {q}.We want to prove R; G; I |= { p} C {q}. By inversion of \nthe hide rule we know R * R. ; G * G. ; I * I..{ p} C {q} and I . {R,G}. By the induc\u00adtion hypothesis \n(of Theorem 6.6), we know R * R. ; G * G. ; I * I.|= { p} C {q}. Also, by Lemma 6.7 we know I * I. . \n{R * R. ,G * G.} and p . q . I * I.* true. Let R = [[R * Id]], R. = [[R * R.* Id]], G = [[G * True]], \nand G. = [[G * G.* True] . We can prove the following Lemmas A.4, A.5 and A.6. Soundness of the hide \nrule is shown in A.7. Lemma A.4 If I . R,(I * I. ) . (R * R. ), s |=sl I * I.* true,and (s,s. ) . [[R \n* Id]], then (s,s. ) . [[R * R.* Id]]. Lemma A.5 For all n, C, s and s. ,if s |=sl I * I.* true,(C,s,R. \n) =.n G. ,and R R. (C,s).. -.n(skip,s. ), then (C,s)-.n(skip,s. ). Lemma A.6 .n (C,s,R) =.n G. For all \nn, C and s,if s|=sl I * I.* true and (C,s,R. ) =G. ,then Lemma A.7 (Hide-Sound) If R * R. ; G * G. ; \nI * I.|= { p} C {q},then R; G; I |= { p} C {q}. The proof of Lemma A.7 is similar to the proof of Lemma \nA.3.  A.3 Soundness of the par rule Suppose the par rule is applied to derive R; G1 . G2; I .{ p1 * \np2 * r} C1 . C2 {q1 * q2 * (r1 . r2)} . We want to prove R; G1 . G2; I |= { p1 * p2 * r} C1 . C2 {q1 \n* q2 * (r1 . r2)} . By inversion of the par rule we know R . G2; G1; I .{ p1 * r} C1 {q1 * r1}, R . G1; \nG2; I .{ p2 * r} C2 {q2 * r2}, I . R,and r . r1 . r2 . I hold. By the induction hypothesis (of Theorem \n6.6), we know R . G2; G1; I |= { p1 * r} C1 {q1 * r1} and R . G1; G2; I |= { p2 * r} C2 {q2 * r2} . Also, \nby Lemma 6.7 we know I . {R . G2,G1,R . G1,G2}. Let R1 = [[(R . G2) * Id]], R2 = [[(R . G1) * Id]], R \n= [[R * Id]], G1 = [[G1 * True]], G2 = [[G2 * True]], and G = [[(G1 . G2) * True] . We can prove the \nfollowing Lemmas A.8 and A.9. Soundness of the par rule is shown in A.10. Lemma A.8 For all n, C1, C2, \ns1, s2, sr and s. ,if sr |=sl I, (C1,s1 . sr,R1) =.n G1, (C2,s2 . sr,R2) =.n G2, and R (C1 . C2,s1 . \ns2 . sr).1, s. -.n+1(skip,s. ), there exist s. 2 and s. r R1 such that s. = s1 .. s. 2 . sr. , s.|=sl \nI,(C1,s1 . sr).1 . s. ) -.n(skip,s. rr and (C2,s2 . sr).R22 . s. -.n(skip,s. ). r Lemma A.9 For all n, \nC1, C2, s1, s2, sr and s,if s = s1 . s2 . sr, sr |=sl I,(C1,s1 . sr,R1) =.n G1,and(C2,s2 . sr,R2) = .n \nG2,then(C1 . C2,s,R) =.n G. Lemma A.10 (Par-Sound) If R . G2; G1; I |= { p1 * r} C1 {q1 * r1}and R . \nG1; G2; I |= { p2 * r} C2 {q2 * r2},then R; G1 . G2; I |= { p1 * p2 * r} C1 . C2 {q1 * q2 * (r1 . r2)}. \nProof. By De.nition 6.5, we need to prove that, for all s,if s |=sl p1 * p2 * r,we have -.* (skip,s. \n), then s.|=sl q1 * q2 * (r1 . r2); (1) if(C1 . C2,s).R (2) for all n,(C1 . C2,s,R) =.n G.  By s |=sl \np1 * p2 * r we know there exit s1, s2 and sr such that s = s1 . s2 . sr, sr |=sl I, s1 |=sl p1,and s2 \n|=sl p2.By R . G2; G1; I |= { p1 * r} C1 {q1 * r1} we have (a1) for all s.. ,if (C1,s1 . sr).R1 -.* \n(skip,s.. ), then s.. |=sl q1 * r1; (b1) for all n,(C1,s1 . sr,R1) =.n G1. Similarly, we have: (a2) for \nall s.. ,if (C2,s2 . sr).R2 -.* (skip,s.. ), then s.. |=sl q2 * r2; (b2) for all n,(C2,s2 . sr,R2) =.n \nG2. By (b1), (b2) and Lemma A.8 we know there exist s. 1, s. 2 and s. r R1 such that s. = s. 2 . s.|=sl \nI,(C1,s1 . sr).1 . s. 1 . s. r, s. -.n(skip,s. ) rr R2 and (C2,s2 . sr).2 . s. -.n(skip,s. ). By (a1) \nand (a2) we know r s. 1 . s.|=sl q1 * r1 and s. 2 . s.|=sl q2 * r2.Since r1 . r2 . I and rr precise(I), \nwe have s. 1 . s. 2 . s.|=sl q1 * q2 * (r1 . r2). Thus (1) is r proved. The proof of (2) follows (b1), \n(b2) and Lemma A.9. .  \n\t\t\t", "proc_id": "1480881", "abstract": "<p>Rely-Guarantee reasoning is a well-known method for verification of shared-variable concurrent programs. However, it is difficult for users to define rely/guarantee conditions, which specify threads' behaviors over the whole program state. Recent efforts to combine Separation Logic with Rely-Guarantee reasoning have made it possible to hide thread-local resources, but the shared resources still need to be globally known and specified. This greatly limits the reuse of verified program modules.</p> <p>In this paper, we propose LRG, a new Rely-Guarantee-based logic that brings local reasoning and information hiding to concurrency verification. Our logic, for the first time, supports a frame rule over rely/guarantee conditions so that specifications of program modules only need to talk about the resources used locally, and the verified modules can be reused in different threads without redoing the proof. Moreover, we introduce a new hiding rule to hide the resources shared by a subset of threads from the rest in the system. The support of information hiding not only improves the modularity of Rely-Guarantee reasoning, but also enables the sharing of dynamically allocated resources, which requires adjustment of rely/guarantee conditions.</p>", "authors": [{"name": "Xinyu Feng", "author_profile_id": "81100140619", "affiliation": "Toyota Technological Institute at Chicago, Chicago, IL, USA", "person_id": "P1301007", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480922", "year": "2009", "article_id": "1480922", "conference": "POPL", "title": "Local rely-guarantee reasoning", "url": "http://dl.acm.org/citation.cfm?id=1480922"}