{"article_publication_date": "01-21-2009", "fulltext": "\n FormalCerti.cation ofCode-BasedCryptographicProofs GillesBarthe1,2 BenjaminGr\u00b4egoire1,3 SantiagoZanellaB\u00b4eguelin1,3 \n1 MicrosoftResearch -INRIAJointCentre,France 2 IMDEASoftware,Madrid,Spain 3 INRIASophiaAntipolis -M\u00b4editerran\u00b4ee,France \n Gilles.Barthe@imdea.org {Benjamin.Gregoire,Santiago.Zanella}@sophia.inria.fr Abstract As cryptographic \nproofs have become essentially unveri.able, cryptographers have argued in favor of developing techniques \nthat help tame the complexity of their proofs. Game-based techniques provide a popular approach in which \nproofs are structured as se\u00adquences of games, and in which proof steps establish the validity of transitions \nbetween successive games. Code-based techniques form aninstance of this approach that takes a code-centric \nview of games, and that relies onprogramminglanguagetheory tojustify proof steps. While code-based techniques \ncontribute to formalize the security statements precisely and to carry out proofs system\u00adatically, typical \nproofs are so long and involved that formal veri\u00ad.cation is necessary to achieve a high degree of con.dence. \nWe presentCertiCrypt, aframework that enables the machine-checked construction and veri.cation of code-based \nproofs. CertiCrypt is built upon the general-purpose proof assistant Coq, and draws on many areas,includingprobability, \ncomplexity, algebra, and seman\u00adtics ofprogramminglanguages. CertiCrypt provides certi.edtools to reason \nabout the equivalence of probabilistic programs, includ\u00ading a relationalHoarelogic, a theory of observational \nequivalence, veri.edprogram transformations, andgame-based techniques such as reasoning about failure \nevents. The usefulness of CertiCrypt is demonstrated through various examples, including a proof of semantic \nsecurity of OAEP (witha bound that improves upon ex\u00adisting published results), and a proof of existential \nunforgeability of FDH signatures. Our work provides a .rst yet signi.cant step towards Halevi s ambitious \nprogramme of providing tool support for cryptographicproofs. Categories and Subject Descriptors D.3.1 \n[Programming Lan\u00adguages]: Formal De.nitions and Theory; D.3.4 [Programming Languages]:Processors Compilers,Optimization; \nF.3.1[Logics andMeanings ofPrograms]:SpecifyingandVerifying andReason\u00ading aboutPrograms; F.3.2[Logics \nand Meanings of Programs]: Semantics of Programming Languages Operational semantics, Denotational semantics,Program \nanalysis. GeneralTerms Languages,Security,Theory,Veri.cation 1. Introduction Provable security [33], \nwhose origins can be traced back to the pioneeringwork ofGoldwasser andMicali[18], advocates a math- \nPermission to make digital or hard copies of all or part of this work for personal or classroomuseisgranted \nwithoutfeeprovided that copiesarenot madeordistributed forpro.tor commercial advantage andthat copiesbearthis \nnotice andthefull citation onthe .rstpage.Tocopy otherwise,torepublish,topostonserversortoredistribute \ntolists, requiresprior speci.cpermission and/or afee. POPL 09, January18 24,2009,Savannah,Georgia,USA. \nCopyright c . 2009ACM978-1-60558-379-2/09/01. . .$5.00 ematical approach based on complexity theory in \nwhich the goals and requirements of cryptosystems are speci.ed precisely, and where security proofs are \ncarried out rigorously and make all un\u00adderlying assumptions explicit. In a typical provable security \nset\u00adting, one reasons about effective adversaries, modeled as arbitrary probabilistic polynomial-time \nTuring machines, and about their probabilityof thwarting a security objective, e.g. secrecy.In a sim\u00adilar \nfashion, security assumptions about cryptographic primitives bound theprobability ofpolynomial algorithms \nto solvehardprob\u00adlems, e.g. computingdiscretelogarithms.The securityproofisper\u00adformed by reduction by \nshowing that the existence of an effective adversary with a certain advantageinbreaking securityimplies \nthe existence of an effective algorithm contradicting the security as\u00adsumptions. Although the adoption \nof provable security has signif\u00adicantly enhanced con.dence in security proofs, several published proofshavebeenfoundincorrect(cf.[30]),and \nthe cryptographic community isincreasingly wary thatthe .eld maybeapproaching a crisis of rigor[8,19]. \nThegame-playing technique[8,19,31]is ageneral method to structure and unify cryptographic proofs, thus \nmaking them less error-prone. Its central idea is to view the interaction between an adversary and the \ncryptosystem as a game, and to study transfor\u00admations that preserve security. In a typical game-based \nproof, one considers transitions of theform G,A.hG ' ,A ' , where Gand G ' aregames, Aand A ' are events, \nand his a monotonicfunction such that PrG[A] = h(PrG' [A ' ]). One can obtain an upper bound for theprobability \nof an event A0 in some initialgame G0 by succes\u00adsively re.ning G0,A0 into agame/eventpair Gn,An, G0,A0 \n.h1 G1,A1 . \u00b7 \u00b7\u00b7 .hn Gn,An and thenbounding theprobability of event An in Gn. Code-based techniques[8] \nis aninstance ofthegame-playing technique whose distinguishing feature is to take a code-centric view \nof games, security hypotheses and computational assump\u00adtions,that are expressed using(probabilistic,imperative,polyno\u00admial) \nprograms. Under this view, game transformations become programtransformations, andcanbejusti.ed rigorouslyby \nseman\u00adtic means; in particular, many transformations can be viewed as commonprogram optimizations, and \narejusti.edbyproving that the original and transformed programs are observationally equiva\u00adlent. Although \ncode-based proofs are easier to verify, they go far beyond established theories of program equivalence \nand exhibit a surprisingly rich and broad set of reasoning principles that draws on program veri.cation, \nalgebraic reasoning, and probability and complexity theory. Thus, despite the bene.cial effect of their \nun\u00adderlyingframework, code-basedproofs remaininherentlycomplex. Whereas Bellare and Rogaway [8] already \nobserved that code\u00adbasedproofs couldbe more easily amenable to machine-checking, Halevi [19] argued that \nformal veri.cation techniques should be used to improve trust in cryptographic proofs, and set up a pro\u00ad \ngrammeforbuildinga tool that couldbe usedby the cryptographic community to mechanize theirproofs. This \narticle reports on a .rst yet signi.cant step towards Halevi s programme. We describe CertiCrypt, a framework \nto construct machine-checked code-based proofs in the Coq proof assistant[34], supporting: Faithful and \nrigorous encoding of games. In order to be readily accessible to cryptographers, we have chosen a formalism \nthat is commonly used to describe games. Concretely, the lowest layer of CertiCrypt is the formalization \nofpWHILE, an imper\u00adative programming language with random assignments, struc\u00adtured datatypes, and procedure \ncalls. We provide a deep and dependently-typed embedding of the syntax; thanks to depen\u00addent types, the \ntypability of pWHILE programs is obtained for free. We also provide a small-step operational semantics \nusing the measure monad ofAudebaud andPaulin[4].The seman\u00adtics is instrumented to calculate the cost \nof running programs; this offers the means to de.ne complexity classes, and in par\u00adticulartode.neformally \nthe notion of effective(probabilistic polynomial-time) adversary. In addition, we also model non\u00adstandardfeatures, \nsuch aspolicies on variable accesses andpro\u00adcedure calls, and use them to capture many assumptionsleftin\u00adformalin \ncryptographicproofs. Exact security. Many security proofs establish an asymptotic be\u00adhavior for adversaries \nand show that the advantage of any ef\u00adfective adversaryis negligible w.r.t.a securityparameter(which \ntypicallydetermines thelength ofkeys or messages).However, the cryptographic community is increasingly \nfocused on exact security, a much more useful result since it gives hints as to how to choose system \nparameters in practice to satisfy a secu\u00adrityguarantee.Thegoal of exact securityis toprovide concrete \nbounds both for the advantage of the adversary and for its ex\u00adecution time. CertiCrypt supports the former(but \nfor the time being, not thelatter). Full andindependently veri.ableproofs. CertiCrypt adopts afor\u00admal \nsemanticist perspective and goes beyond Halevi s vision in two respects. First, it provides a uni.ed \nframework to carry outfullproofs; allintermediate steps of reasoning canbejus\u00adti.edformally,including \ncomplex side conditions thatjustify thecorrectness of transformations(aboutprobabilities,groups, polynomials, \netc).Second, one notablefeature ofCoq, andthus CertiCrypt, is to support independent veri.ability of \nproofs, which is an important motivation behind game-based proofs. More concretely, every proof is represented \nby a proof object, that canbechecked automaticallyby a(small and trustworthy) proof checking engine. \nIn order to trust a cryptographic proof, one only needs to checkits statement, and notitsdetails. Powerful \nand automated reasoning methods. CertiCrypt formal\u00adizes a Relational Hoare Logic and a theory of observational \nequivalence, and uses them as stepping stones to support the main tools of code-based reasoning through \ncerti.ed, re.ec\u00adtive tactics. In particular, CertiCrypt shows that many trans\u00adformations used in code-based \nproofs, including common op\u00adtimizations, are semantics-preserving. One of its speci.c con\u00adtributions \nis to prove formally the correctness of a variant of lazy sampling, which is used ubiquitously in cryptographic \nproofs.In addition,CertiCrypt supports methodsbased onfail\u00adure events(the so-calledfundamentallemma ofgame-playing). \nWe have successfully conducted nontrivial case studies that vali\u00addate our design, show the feasibility \nof formally verifying crypto\u00adgraphicproofs,and con.rmtheplausibility ofHalevi sprogramme. Contents The \npurpose of this article is to provide an overview of the CertiCrypt project, and to stir further interest \nin machine\u00adchecked cryptographicproofs.Additionaldetailsondesign choices, onformalizingthe semantics \nofprobabilisticprograms, and on case studies, will be provided elsewhere. In consequence, the paper is \norganized as follows: we begin in Section 2 with two introductory examples of game-based proofs, namely \nthe semantic security of ElGamal encryption, and the PRP/PRF switching lemma; in Sec\u00adtion 3 we introduce \nthe language we use to represent games and its semantics, and we discuss the notions of complexity and \nter\u00admination; in Section 4 we present a probabilistic relational Hoare logic thatforms the core of ourframework;inSections5 \nand6 we overview theformulation and automation ofgame transformations in CertiCrypt;inSection7 we report \non two signi.cant case stud\u00adies wehaveformalized in CertiCrypt: existential unforgeability of the FDH \nsignature scheme, and semantic security of OAEP; we .nish with adiscussion of related work and concluding \nremarks.  2. Basic examples This section illustrates the principles of CertiCrypt on two basic examples \nof game-based proofs: semantic security of ElGamal encryption and thePRP/PRF switchinglemma.Thelanguage \nused to represent games is formally introduced in the next section. We begin with somebasicde.nitions. \nThe Random Oracle Model is a model of cryptography exten\u00adsively used in security proofs in which some \ncryptographic primi\u00adtives, e.g.hashfunctions, are assumed tobeindistinguishablefrom random functions(despite \nthefact that no realfunction can imple\u00adment atruly randomfunction[13]).Suchprimitives are modeledby oracles \nthat return random values in response to queries. The sole condition is that queries are answered consistently: \nif some value isqueried twice,the same response mustbegiven.Ourformalism captures the notion of random \noracle using statefulprocedures that storequeries and their results, e.g. Oracle O(x): if .{0, 1}.; L \n. (x,y) x . dom(L)then y $:: L; return L[x] An asymmetric encryption scheme is composed of three algo\u00adrithms: \nkey generation KG(.), where . is the security parameter; encryption Enc(pk,m)where pk is a public key \nand m a plain\u00adtext; anddecryption not relevanthere.An asymmetric encryption schemeis saidtobe semantically \nsecure(equivalently, IND-CPA secure) if it is infeasible to gain signi.cant information about a plaintextgiven \nonly a corresponding ciphertext and thepublickey. Thisisformallyde.nedusingthefollowinggame, where A \nand A ' are allowedto share state viaglobal variables and thus are regarded as a single adaptive adversary: \nGame IND-CPA : (sk,pk). KG(.); (m0,m1).A(pk); b $ .{0, 1};. . Enc(pk,mb); b ' .A ' (pk,.) The game .rst \ngenerates a new key pair and gives the public key to the adversary, who returns two plaintexts m0,m1 \nof his choice. Then, the challenger tosses a fair coin b and gives the encryption of mb back to the adversary, \nwhose goal is to guess which message has been encrypted. The scheme is IND-CPA if for every effective \nadversary A,A ' , |PrIND-CPA[b = b ' ] - 21 | is negligible in the security parameter, i.e. the adversary \ncannot do much better than a blind guess. Formally, a function .:N . R is negligibleiff . c. . nc. . \nn. n = nc .|.(n)|= n -c . 2.1 The ElGamal encryption scheme ElGamal is a widely used asymmetric encryption \nscheme, and an emblematic example of game-based proofs, as it embodies many of the techniques described \nin Sections 4 and 5. The proof fol\u00ad (1) Game ElGamal2 : $. Zq; (m0,m1).A(gx); x . Zq; y $ z $ z . Zq; \n. . g; x  (4)  Figure1. Code-basedproof of ElGamal semantic security lows[31]; allgamesarede.nedinFig.1.Given \nacyclicgroup of order q, and agenerator g, wede.ne:1 def x $ Keygeneration: KG() = x . Zq; return (x,g \n) def y $ Encryption: Enc(a,m)= . Zq; return (gy,ay \u00d7 m) ElGamal is IND-CPA secure under the Decisional \nDif.e-Hellman (DDH)assumption, which states that it is hard to distinguish be\u00ad xyxyxyz tween triples \nof the form (g ,g,g)and (g ,g,g )where x, y, z are uniformly sampled in Zq. In our setting, DDH is formu\u00adlated \nprecisely by stating that for any polynomial-time and well\u00adformed adversary B, |PrDDH0 [d]- PrDDH1 [d]| \nis negligible in the securityparameter.Figure1presents ahighlevel view oftheproof: the squareboxes representgames, \nwhereas the rounded boxes rep\u00adresent proof sketches of the transitions between games; the tactics that \nappear in these boxes hopefully have self-explanatory names, but are explained in more detail in Section \n5. The rounded grey boxes represent proof sketches of side conditions that guarantee that the DDH assumption \nis correctly applied. Theproof proceeds by constructing an adversary B against DDH such that the distri\u00adbution \nofb = (i.e.d)after running the IND-CPA gameElGamal b ' is exactly the same as the distribution of d after \nrunning DDH0. Furthermore we show thattheprobabilityof dbeingtrue inDDH1 is 12 for the same adversary \nB. The proof is summarized by the following equations: |PrElGamal[b = b ' ]- 21 | = |PrElGamal0 [d]- \n1 | (1) 2 = |PrDDH0 [d]- 21 | (2) = |PrDDH0 [d]- PrElGamal2 [d]| (3) = |PrDDH0 [d]- PrElGamal1 [d]| (4) \n= |PrDDH0 [d]- PrDDH1 [d]| (5) 1The securityparameter,implicitinthispresentation,determinesthis cyclic \ngroup by indexing afamily ofgroups wherethe DDH problem isbelieved intractable. Equation(1)isjusti.edbecauseElGamal \nand ElGamal0 inducethe samedistribution on d(ElGamal .d ElGamal0).Toprove this, we inline the calls to \nKG and Enc, and then perform expression prop\u00adagation anddead code elimination(ep, deadcode). At this \npoint we are left with two almost identical games, except the sampling of y is done later in one game \nthan in the other. The tactic swap is used tohoistinstructions whenever ispossiblein order to obtain \na common pre.x, and allows us to hoist the sampling of y to the right place. We conclude by applying \neqobs in that decides ob\u00adservational equivalence of aprogram withitself.Equations(2) and (5)are obtained \nsimilarly, while(3)holdsbecause b ' isindependent from the sampling of bin ElGamal2.Finally, toprove \nequation(4) we begin by removing the common part of the two games with $ the exception of the instruction \nz . Zq (eqobs hd, eqobs tl). Wethen apply an algebraicproperty of cyclicgroups(mult pad): when multiplying \na uniformly distributed element of the group by another element, the result is uniformly distributed. \nThis allows to $$ prove that z . Zq; . . g z \u00d7 mb and z . Zq; . . g z induce the samedistribution on \n.. The proof concludes by applying the DDH assumption. We prove that the adversary B is strict probabilistic \npolynomial-time and well-formed(under the assumption that A and A ' are so).The proofof theformer conditionis \nautomatedin CertiCrypt.  2.2 ThePRP/PRFswitchinglemma In cryptographic proofs, particularly those dealing \nwith blockci\u00adphers, it is often convenient to replace a pseudo-random permuta\u00adtion (PRP) by a pseudo-random \nfunction (PRF). The PRP/PRF switching lemma establishes that such a replacement does not change signi.cantly \nthe advantage of an effective adversary. In a code-based setting, theSwitchingLemma states that q(q- \n1) [d]|= |PrGPRP [d]- PrGPRF 2.+1  Figure2. Code-basedproof of thePRP/PRF switchinglemma where games \nGPRP and GPRF give the adversary access to an oracle that represents a randompermutation and a randomfunction \nrespectively, and where q bounds the number of oracle queries madeby A. The proof is split in two parts: \nthe .rst part formalizes the intuition that the probability of the adversary outputting a given value \nis the same if a PRP is replaced by a PRF and no collisions are observed; it uses the Fundamental Lemma \nof game-playing (Lemma 2 in Sec. 6). The second part provides an upper bound to theprobability of a collision;it \nuseslazy sampling(Lemma1in Sec.5.2). Figure 2 provides a high-level view of the proof. To apply the Fundamental \nLemma, we introduce in the game GPRF a variable bad that is set to true whenever a collision is found; \nwe reformu\u00adlate GPRP accordingly to be syntactically equal until bad is set. Using deadcode to eliminate \nthe variable bad, we show that the resultinggames Gbad PRP arejust semanticspreserving re- PRF and Gbad \nformulations ofthegamesGPRF and GPRP respectively.Then, we apply the Fundamental Lemma to conclude that \nthe difference in the probability of d = true between the two games is at most the probability of bad \nbeing set to true ingame Gbad PRF. We then prove that the probability of bad being set to true in game \nGbad PRF is upper bounded by the probability of an element appearing twice in the range of L in GPRF. \nThe proof uses the Relational Hoare Logic and Lemma (=.. )of Section 4 with the following postcondition: \nif bad is set in Gbad PRF then some element appears twice in the range of L in GPRF. Next, we introduce \na gameGY PRF wheretheanswertothe .rst qqueries tothe oracle are sampled at thebeginning of thegame and \nstoredin alist Y.Using lazy sampling, weproveby induction on q that thegame GPRF is equivalent to GY \nPRF w.r.t L. Finally, we bound the probability of having a collision in L in GY PRF. To that end, we \nprove that any collision in L is also present in Y * provided the length of L is less than or equal to \nq (we useY * as a ghost variable to store the value of Y after being initialized). We conclude by bounding \nthe probability of sampling some value twicein Y by q(q-1) . 2.+1  3. Gamesasprograms The essence of \ncode-based cryptographic proofs is to express in a uni.ed semantic framework games, hypotheses, and results. \nThis semanticist perspective allows a precise speci.cation of the inter\u00adaction between the adversary \nand the challenger in a game, and to readily answer questions as: Which oracles does the adversary have \naccess to? Can the adversary read/write this variable? How many queries the adversary can make to a given \noracle? What is the length of a bitstring returned by the adversary? Can the adver\u00adsary repeat aquery?Furthermore, \nother notions such asprobabilis\u00adtic polynomial-time complexity or termination .t naturally in the sameframework \nand complete the speci.cation of adversaries and games. 3.1 ThepWHILE language Games are formalized in \npWHILE, a probabilistic imperative lan\u00adguage with procedure calls. Given a set V of variable identi.ers, \na set P of procedure identi.ers, a set E of expressions, and a set D of distribution expressions, the \nset of commands can be de.ned inductivelyby the clauses: I ::= V . E assignment | V $. D random sampling \n| if E then C else C conditional | while E do C while loop | V . P(E,. . . , E) procedure call C ::= \nnil nop | I; C sequence Ratherthan adoptingthe abovede.nition,weimposethatprograms inpWHILE aretyped.Thus, \nx . e is well-formedonlyifthetypes of x and e coincide, and if e then c1 else c2 is well-formed only \nif e is a boolean expression. In practice, we assume that variables and values are typed, and de.ne a \ndependently typed syntax of programs. An immediate bene.t of using dependent types is that the type system \nof Coq ensures for free the well-typedness of expressions and commands.Althoughtheformalizationis carefully \ndesignedforbeingextensible w.r.t.user-de.nedtypes and operators (andwe do exploit this in practice), \nit is suf.cient for the purpose of thispaper to consider an instance in which values are booleans, bitstrings, \nnatural numbers, pairs, lists, and elements of a cyclic group. Similarly, we instantiate D so that values \ncan be uniformly sampled from the set of booleans, natural intervals of the form [0..n], andbitstrings \nof a certainlength.Itisimportant to note that the formalization of expressions is not restricted to many-sorted \nalgebra: we make a critical use of dependent types to record the length of bitstrings. This is used e.g. \nin the de.nition of the IND-CPA gameforOAEP inSec.7.2to constrainthe adversaryto return twobitstrings \nof equallength. De.nition1 (Program). Aprogram consists of a command and an environment, which maps a \nprocedure identi.er to its declaration, consisting of its formal parameters, its body, and a return expres\u00adsion(we \nuse an explicit return when writinggames, though), def decl = {params : list V; body : C; re : E} . The \nenvironment speci.es the type of theparameters and the return expression, so thatprocedure calls are \nalways well-typed. In atypicalformalization,the environmentwillmapprocedures to closed commands, with \nthe exception of the adversaries whose codeis unknown, andthus modeledbyvariables oftype C.Thisis a standardtricktodealwithuninterpretedfunctionsin \nadeepembed\u00adding.Inthe remainder ofthis section we assume an environment E implicitlygiven. In the rest \nof this paper we let ci range over C; xi over V; ei over E;di over D;and Gi overprograms.The operator \n. denotes the bitwise exclusive or on bitstrings of equal length, and I the concatenation of twobitstrings. \n 3.2 Operational semantics Programs in pWHILE are given a small-step semantics using the measure monad \nM(X), whose type constructorisde.ned as def M(X) =(X . [0,1]). [0,1] and whose operators unit and bind \narede.ned as def unit : X . M(X)= .x..f.f x bind : M(X). (X . M(Y)). M(Y) def = .\u00b5..M..f.\u00b5(.x.M xf) The \nmonad M(X)wasproposed byAudebaud andPaulin[4]as a variant of the expectation monad usedbyRamseyandPfeffer[27], \nandbuilds on earlier workbyKozen[22].Theformalization ofthe semantics heavily relies on Paulin s axiomatization \nin Coq of the [0,1]real interval for our purposes, it has been necessary to add division to thelibrary. \nThe semantics of commands and expressions are de.ned rel\u00adative to a given memory, i.e. a mapping from \nvariables to val\u00adues. We let M denote the set of memories. Expressions are de\u00adterministic; their semantics \nis standard and given by a function [\u00b7]expr, that evaluates an expression in a given memory and re\u00adturns \na value. The semantics of distribution expressions is given by a function [\u00b7]distr. For a distribution \nexpression d of type T, we have that [d]distr : M. M(X), where X is the interpretation of type T. For \ninstance, in the previous section we have used {0,1}. to denote the uniform distribution on bit\u00adstrings \nof length . (the security parameter), formally, we have P def 1 [{0,1}.]distr = .m f. bs.{0,1}. 2. f(bs). \nThanks to depen\u00addent types, the semantics of expressions and distribution expres\u00adsionsis total.In thefollowing, \nandwhenever thereis no confusion, we willdropthe subscriptsin [\u00b7]expr and [\u00b7]distr. The semantics of \ncommands relates a deterministic state to a (sub-)probability distribution over deterministic states \nand uses a framestack todeal withprocedure calls.Formally,adeterministic stateis a triple consisting \nof the current command c : C, a memory m : M, and a frame stack F : list frame. We let S denote the set \nof deterministic states. One step execution [\u00b7]1 : S. M(S) is de.ned by the rules of Fig. 3. In the .gure, \nwe use a . b as a notation for [a]1 = b and loc and glob to project memories on local andglobal variables \nrespectively. We brie.y comment on the transition rules for calling a proce\u00addure(3rd rule)and returningfrom \na call(2nd rule).Upon a call, a new frame is appended to the stack, containing the destination variable, \nthe return expression of the called procedure, the contin\u00aduation to the call, and the local memory of \nthe caller.The state re\u00adsultingfrom the call contains thebody of the calledprocedure, the global part \nof the memory, a local memory initialized to map the formalparameters to the value of the actualparametersjustbefore \nthe call, and the updated stack. When returning from a call with a non-empty stack,thetopframeispopped,thereturnexpressionis \nevaluatedandthe resultingvalueis assignedtothedestination vari\u00adable after previously restoring the local \nmemory of the caller; the continuation taken from the frame becomes the current command. Ifthe stackisemptywhen \nreturningfrom acall,the execution ofthe programterminatesand the .nal stateisembeddedintothemonad usingthe \nunit operator. Usingthe monadic constructions, one cande.ne an n-stepexe\u00adcutionfunction [\u00b7]n: def def \n1 [s]0 = unit s [s]n+1 = bind [s]n [\u00b7] Finally, the denotation of a command c in an initial memory m \nis de.ned tobethe(limit)distributionof reachable .nalmemories: def [c] m : M(M)= .f. sup {[(c,m,[])]n \nf|.nal | n . N} where f|.nal :S. [0,1]isthefunction thatwhen appliedto a state (c,m,F)givesf(m)ifitisa \n.nalstateand0otherwise.Sincethe sequence [(c,m,[])]n f|.nal is increasing and upper bounded by 1, thisleastupperbound \nalways exists and corresponds to thelimit of the sequence. We have shown that the semantics is discrete, \nwe use this to applya variant ofFubini s theoremforprovingthe rules[R-Comp] and[R-Trans]in the next section. \nComputing probabilities The advantage of using this monadic semantics is that, if we use an arbitrary \nfunction as a continua\u00adtion to the denotation of a program, what we get (for free) as a result is its \nexpected value w.r.t. the distribution of .nal memo\u00adries. In particular, we can compute the probability \nof an event A in the distribution obtained after executing a command c in an initial memory m by measuring \nits characteristic function 1 A: def Prc,m[A]= [c] m 1 A. For instance, one can verify that the de\u00adnotation \nof x . [0..1]; y $m is $. [0..1]in the memory .f.14(f(m{0,0/x,y})+f(m{0,1/x,y}) +f(m{1,0/x,y})+f(m{1,1/x,y})) \nandconcludethattheprobabilityofthe event x = yafter executing the command aboveis 34.  3.3 Probabilisticpolynomial-timeprograms \nIngeneral, cryptographicproofs reason abouteffective adversaries, which can only use a polynomially bounded \nnumber of resources. The complexity notion that captures this intuition, and which is pervasive in cryptographic \nproofs, is that of strict probabilistic polynomial-time. Concretely, a program is said to be strict proba\u00adbilisticpolynomial-time(PPT)whenever \nthere exists apolynomial bound(on some securityparameter .) on the cost of each possi\u00adble execution, \nregardless of the outcome of its coin tosses. Other\u00adwise said, a probabilistic program is PPT whenever \nthe same pro\u00adgram, seen as a non-deterministicprogram, terminates andthe cost of eachpossible runisbounded \nbyapolynomial. Termination and ef.ciency are orthogonal. Consider, for in\u00adstance, thefollowingtwoprograms: \nb . true;while bdo b $ .{0,1} b $ .{0,1};if bthen while true do nil Theformer terminates withprobability1(it \nterminates within n iterations with probability 1 - 2-n), but may take an arbitrarily large number of \niterations to terminate. The latter terminates with probability 12, but when it does, it takes only a \nconstant time. We deal withtermination and ef.ciency separately. De.nition 2 (Termination). The probability \nthat a program c ter\u00adminates starting from an initial memory m is [c] m 1 true. We say that aprogram \nc is absolutely terminating, and note it lossless(c), iffit terminates withprobability 1in anyinitial \nmemory. To deal with ef.ciency, we non-intrusively instrument the se\u00admantics of our language to compute \nthe cost of running a pro\u00adgram. The instrumented semantics ranges over M(M\u00d7 N) in\u00adstead of simply M(M). \nWe recall that our semantics is implicitly (nil,m,[]) unit (nil,m,[]) (nil,m,(x,e,c,l):: F) unit (c, \n(l,m.glob){[e] m/x},F) (x . p(.e); c,m,F) unit (E(p).body,(\u00d8{[.e] m/E(p).params},m.glob),(x,E(p).re,c,m.loc):: \nF) (if e then c1 else c2; c,m,F) unit (c1; c,m,F) if[e] m = true (if e then c1 else c2; c,m,F) unit (c2; \nc,m,F) if[e] m = false ' ' (while e do c; c ,m,F) unit (c; while e do c; c ,m,F) if[e] m = true (while \ne do c; c ' ,m,F) unit (c ' ,m,F) if[e] m = false (x . e; c,m,F) unit (c,m{[e] m/x},F) (x $. d; c,m,F) \nbind ([d] m)(.v.unit (c,m{v/x},F)) Figure3. Probabilistic semantics ofpWHILE programs parametrized by \na securityparameter ., on which webase our no\u00adtion of complexity. De.nition 3 (Polynomially bounded distribution). \nWe say that a distribution \u00b5 : M(M\u00d7 N) is (p,q)-bounded, where p and q are polynomials, whenever for \nevery (m,n)occurring with non\u00adzero probability in \u00b5, the size of every value in the memory m is bounded \nby p(.)and the cost n is bounded by q(.). This notion is formally de.ned by means of the range predicate \nintroduced in Sec.4. De.nition 4 (Strict probabilistic polynomial-time program). A program c is strictprobabilisticpolynomial-time(PPT) \niffit ter\u00adminates absolutely, and there exist polynomial transformers F,G such that for every (p,q)-bounded \ndistribution \u00b5, the distribution (bind \u00b5[c])is (F(p),q + G(p))-bounded. We can recover someintuitionbytaking \n\u00b5 = unit (m, 0)inthe above de.nition. In this case, we may paraphrase the condition as follows:if the \nsize of values in m isbounded by somepolynomial p,and anexecution of theprogramin m terminates with non-zero \nprobabilityin memorym ' ,then the size of valuesin m ' isbounded by the polynomial F(p), and the cost \nof the execution is bounded by thepolynomial G(p).Itisin thislatterpolynomial that bounds the cost of \nexecuting theprogram that we are ultimatelyinterested. The increased complexity in the de.nition is required \nfor proving compositionality results (e.g. the sequential composition of two PPTprograms resultsin aPPTprogram). \nAlthough our formalizations of termination and ef.ciency rely on semantic de.nitions, it is not necessary \nfor users to reason di\u00adrectly about the semantics of a program to prove it meets those de.nitions. CertiCrypt \nimplements a certi.ed algorithm showing that every program without loops and recursive calls is lossless.2 \nCertiCrypt alsoprovides another algorithmthat,togetherwith the .rst, establishes that a program is PPTprovided \nthat, additionally, the program does not contain expressions that might generate val\u00adues of superpolynomial \nsize or take a superpolynomial time when evaluatedin apolynomiallybounded memory.  3.4 Adversaries In \norder to reasonformally about security, we make explicit which variables andprocedures are accessible \nto adversaries, andprovide a simple analysis to check whether an adversary respectsitspolicy. Given a \nset ofprocedure identi.ers O (theprocedures thatmay be called by the adversary), and sets of global variables \nGrw (those 2It is of course a weak result in terms of termination of probabilistic programs,butnevertheless \nsuf.cient asregardscryptographic applications. Extending our formalization to a certi.ed termination \nanalysis for loops is interesting, but orthogonal to our maingoals, andleftforfuture work. I . i:I ' \nI ' . c:O I . nil :I I . i; c:O Writable(x) fv(e). I Writable(x) fv(d). I I . x . e:I .{x} I . x . d:I \n.{x} $ fv(e). II . ci :Oi i =1,2 fv(e). II . c:I I . if e then c1 else c2 :O1nO2 I . while e do c:I fv(.e). \nI Writable(x) o .O I . x . o(.e):I .{x} fv(.e). I Writable(x) A .O .wf A I . x .A(.e):I .{x} Grw .Gro \n.AE.params .AE.body :O fv(AE.re). O .wf A def def Writable(x)= Local(x). x .Grw AE = E(A). Figure4. \nStatic analysisfor well-formedness of adversaries that can be read and written by the adversary) and \nGro (those that the adversary can only read), we say that an adversary A is well\u00adformedin an environment \nE ifthejudgment .wf A canbederived using the rules in Fig. 4. These rules guarantee that each time a \nvariable is written by the adversary, the adversary has the right to do so; and that each time a variable \nis read by the adversary, it is either aglobal variable in Grw .Gro or alocal variablepreviously initialized.A \nwell-formed adversary isfree to call oracles, but any otherprocedureit calls mustbe a well-formed adversaryitself. \nAdditional constraints may be imposed on adversaries. For ex\u00adample, exact securityproofs usuallyimpose \nan upper bound to the number of calls adversaries can make to a given oracle, whereas for someproperties \nsuch as IND-CCA2 there are some restrictions on theparameters with which the oracles maybe called.Likewise, \nsomeproofsimpose extra conditions such asforbidding repeated or malformedqueries.Thesekinds ofproperties \ncanbeformalized us\u00adinglists that record the oracle calls, and verifying aspostcondition that the calls \nwerelegitimate.  4. RelationalHoareLogic Shoup[31]classi.esproof stepsintothree categories:transitions \nbased on indistinguishability which typically involve applying a securityhypothesis, e.g. the DDH assumption \n; transitionsbased onfailure events whichtypically amounttobound theprobability of bad, as in the Switching \nLemma ; and bridging steps which correspond to replacing or reorganizing code in a way that is not observable \nby adversaries.In some circumstances, abridging tran\u00adsitionfrom G1 toG2 may replace aprogramfragment \nP byanother fragment P ' observationally equivalent to P.In general, however, P and P ' are only observationally \nequivalent in the context where the replacement is done. Such transitions are supported through a relational \nHoare logic, that generalizes observational equivalence throughpreconditions andpostconditions which \nweusetocharac\u00adterize the context where the replacement is valid. Besides, we use relationalHoarelogic \nto establish(in)equalitiesbetweenprobabili\u00adties oftwo events, as shownbythelemmas (=.. )and (=.. )below, \nand to establishprograminvariants, e.g.in theproof of theSwitch\u00adingLemmainSec.2.2. 4.1 ProbabilisticRelationalHoareLogic(pRHL) \nOur logic pRHL elaborates on and extends to probabilistic pro\u00adgrams Benton s Relational Hoare Logic [9]. \nBenton s logic uses judgments oftheform . G1 ~ G2 :. . F, and relates the eval\u00aduation of a program G1 \nto the evaluation of a program G2 w.r.t. a precondition . and a postcondition F, both de.ned as relations \nondeterministic states.Such ajudgment statesthatfor anyinitial memories m1 and m2 satisfying theprecondition \nm1 .m2,if the evaluations of G1 in m1 and G2 in m2 terminate with .nal mem\u00ad '' '' ories m1 and m2 respectively, \nthen m1 F m2 holds. In a proba\u00ad bilistic setting, the evaluation of aprogram w.r.t. aninitial memory \nyields a(sub-)distribution.In order togive a meaning to the above judgment, one therefore needs to lift \nrelations over memories into relations overdistributions.3 Wefollow early work onprobabilistic bisimulations[21].Thelifting \ntodistributions of a unarypredicate P and of abinary relation Fare respectivelyde.ned as def range P\u00b5 \n= .f.(.a.P a . fa =0) . \u00b5f =0 \u00b51 ~F \u00b52 def .\u00b5.p1(\u00b5)= \u00b51 . p2(\u00b5)= \u00b52 . range F\u00b5 = where theprojections \nof \u00b5arede.ned as def def p1(\u00b5)= bind \u00b5(.(x,y).unit x) p2(\u00b5)= bind \u00b5(.(x,y).unit y) This way of lifting \nrelations over memories to relations over dis\u00adtributions is a generalization to arbitrary relations of \nthe de.ni\u00adtion ofSabelfeld andSands[29].Theirde.nition applies only to PERs, whereas our de.nition applies \nto arbitrary relations. Never\u00adtheless, both de.nitions coincide for PERs as established by Jons\u00adson,Larsen \nandYi[21]. De.nition5 (pRHLjudgments). Programs G1 and G2 are equiv\u00adalent w.r.t.precondition .andpostcondition \nFiff def F G1 ~ G2 :. . F= . m1 m2.m1 .m2 . [G1] m1 ~F [G2] m2 Our approach slightlydepartsfromBenton \ns: rather thande.n\u00ading the rulesforpRHL andproving them sound w.r.t. the meaning ofjudgments, weplace \nourselvesin a semantic setting andderive the rules aslemmas.This allows to easily extend the systembyde\u00adriving \nextra rules, or even to resort to the semantic de.nitionif the system turns out tobeinsuf.cient. Figure5gathers \nsome representative derived rules.To improve readability, in the .gure and in the remainder of the paper \nwe let e(i) denote .m1 m2. [e] mi = true, where e is a boolean expression. As pRHL allows for arbitrary \nrelations, we freely use higher-orderlogic;inparticular,PER and SYM arepredicates over relations that \nstand for partial equivalence relation and symmetric relation respectively.There aretwopoints worth noting.First,most \nrules admit,in addition to their symmetrical version ofFig.5, one\u00adsided(left and right) variants, e.g.for \nassignments def m1 F ' m2 =(m1{[e1]m1/x1})Fm2 F E1,x1 . e1 ~ E2,nil :F ' . F 3Analternative wouldbetodevelop \nalogicinwhich .and Fare relations overdistributions.However,itis not clear whether such alogic would \nallow asimilarlevel ofproof automation.Thisisleftforfuturework. Second, some rules ofpRHLdo not appearinRHL,orgeneralize \nexisting rules.The rule[R-Case] allowstodo a case analysis onthe evaluation of an arbitrary relationin \ntheinitial memories.Together with simple rulesin the spirit of F E1,c1 ~ E2,c :. . e(1). F F E1,if e \nthen c1 else c2 ~ E2,c :. . e(1). F it subsumes[R-Cond] and allowstoprovejudgments that would otherwise \nnot be derivable, such as the equivalence between (if e then c1 else c2) and (if \u00ace then c2 else c1). \nWe also use [R-Case]toprove the correctness ofdata.ow analyses that exploit theinformationprovidedby \nenteringbranches. In addition, we often use the rule[R-Inv] thatgeneralizes the rule[R-Sym] toinverse \nof relations F G1 ~ G2 :. . F [R-Inv] F G2 ~ G1 :.-1 . F-1 and wemake an extensive use ofthe rule[R-Comp]thatgeneralizes \nthe rule[R-Tr] to composition of relations4 . F '' F G1 ~ G :. ' . F ' F G ~ G2 :. '' [R-Comp] . . '' \n. F '' F G1 ~ G2 :. ' . F ' Thebene.ts of the rule[R-Comp], as opposed to[R-Tr], are illus\u00adtrated by \nconsidering independent preconditions and postcondi\u00adtions of theform def def .= .xy ..1 x . .2 y F= .xy \n.F1 x . F2 y In orderto apply the rule[R-Tr] to G1 and G2, we are essentially forced to have .1 =.2 and \nF1 =F2, and furthermore we must also choose the same pre and postcondition for the intermediate game \nG.This constraint makes the rule[R-Tr]impractical, we use instead the rule[R-Comp] tointroduce intermediategames \nthatdo not satisfy the same speci.cation as G1 or G2. The rule[R-Rand] is also(obviously) notpresentinRHL.Let \ndef (.v.if x = v then 1 else 0), and de.ne the support of a distribution,supp([d] m),by the clause Ix \n= v . supp([d] m). [d] m Iv 0 = Finally,let[d1] m1 = g [d2] m2 iffthere existsa setX and abijec\u00adtion \ng : X . X such that supp([d1] m1)= supp([d2] m2)= X and [d1] m1 Ia = [d2] m2 I(ga) for all a in X. To \napply rule [R-Rand], it is necessary to exhibit a function f such that for all memories m1 and m2, [d1] \nm1 = fm1 m2 [d2] m2. Thus, if d1 = d2 = [0..n]for some constant n, and we take f to be the identityfunction, \nthepremise simpli.es to the expected, def m1 .m2 = . v . [0..n]. (m1{v/x1})F(m2{v/x2}) Section 5.3 shows \nthat the generality of the rule is required for applications such as optimistic sampling. It is often \nfruitful to understand pRHL judgments in terms of the inability of the postcondition to separate between \nthe two commands ofthejudgment. De.netwofunctions f and g to be equivalent w.r.t. apredicate Fiff def \nf =F g = . m1 m2.m1 Fm2 . f(m1)= g(m2) Thede.nition ofpRHLjudgments entails 9 F G1 ~ G2 :. . F = f =F \ng . [G1] m1 f = [G2] m2 g (=.. ) ; m1 .m2 4The machine-checked rule requires that F, F ' aredecidable, \nand uses Set\u00advalued existentialquanti.cation .Set in the compositionforpreconditions, def i.e. x (.. \n. ' )z = .Set y. x.y . y . ' z. '' . F '' F E1,c1 ~ E2,c2 :F . F ' F E1,c1 ~ E2,c2 :F ' F E1,nil ~ E2,nil \n:F . F[R-Skip][R-Seq] F E1,c1;c1 ' ~ E2,c2;c2 ' :F . F '' F E1,x1 . e1 ~ E2,x2 . e2 :(.m1 m2. (m1{[e1]m1/x1})F(m2{[e2]m2/x2})). \nF[R-Ass] def m1 .m2 = [d1]m1 = fm1 m2 [d2]m2 .. v . supp([d1]m1). (m1{v/x1})F(m2{fm1 m2 v/x2}) $$[R-Rand] \nF E1,x1 . d1 ~ E2,x2 . d2 :. . F .m1 m2.m1 .m2 . [e1] m1 = [e2] m2 F E1,c1 ~ E2,c2 :.. e1(1). F F E1,c1 \n' ~ E2,c2 ' :..\u00ace1(1). F [R-Cond] F E1,if e1 then c1 else c1 ' ~ E2,if e2 then c2 else c2 ' :. . F .m1 \nm2.m1 Fm2 . [e1] m1 = [e2] m2 F E1,c1 ~ E2,c2 :F. e1(1). F [R-Whl] F E1,while e1 do c1 ~ E2,while e2 \ndo c2 :F . F.\u00ace1(1) F G1 ~ G2 :. ' . F ' .m1 m2.m1 .m2 . m1 . ' m2 .m1 m2.m1 F ' m2 . m1 Fm2 [R-Sub] \n F G1 ~ G2 :. . F F G1 ~ G2 :. . F SYM(.) SYM(F) F G1 ~ G :. . F F G ~ G2 :. . F PER(.) PER(F) [R-Sym][R-Tr] \nF G2 ~ G1 :. . F F G1 ~ G2 :. . F F G1 ~ G2 :.. . ' . F F G1 ~ G2 :..\u00ac . ' . F [R-Case] F G1 ~ G2 :. \n. F Figure5. Selection ofderived rules ofpRHL By instantiating f and g to 1 , one can observe that observational \nequivalence enjoys someform of termination sensitivity (F G1 ~ G2 :. . F).m1 .m2 . [G1] m1 1 = [G2] m2 \n1 Thisinterpretation ofpRHLjudgmentsis stronglyconnectedtothe relationbetweenrelationallogicsandinformation \n.ow[3,9].We extensivelyuse (=.. ),andits variant(=.. )below,tofallbackfrom the worldofpRHLintothe worldofprobabilities,in \nwhichsecurity statements are expressed; 9 F G1 ~ G2 :. . F = f =F g . [G1] m1 f = [G2] m2 g (=.. ) ; \nm1 .m2 def where f =F g = . m1 m2.m1 Fm2 . f(m1)= g(m2). We conclude with an example that nicely illustrates \nsome $ of the intricacies of pRHL. Let c = b .{0,1} and de.ne def m1 F m2 = m1 b = m2 b. Then F c ~ c \n: true . F. Indeed, take \u00b5 such that \u00b5 1 .0,0. = \u00b5 1 .1,1. =1/2 and \u00b5 1 .0,1. = \u00b5 1 .1,0. =0. One can \ncheck that \u00b5 ensures [c] m ~F [c] m ' for all m and m ' . This example shows why theliftingofabinaryrelationinvolves \nan existentialquanti.cation, and why it is not possible to always instantiate \u00b5 as the product distributionin \nthede.nition of ~F (one cannotestablish the above judgment using the product distribution). Perhaps more \nsurpris\u00adingly, F c ~ c : true .\u00acF also holds. Indeed, take \u00b5 such that \u00b51 .0,0. = \u00b51 .1,1. =0and \u00b51 .0,1. \n= \u00b51 .1,0. =1/2.One can check that \u00b5 ensures [c] m ~\u00acF [c] m ' for all m and m ' . Thus, the obvious \nrule F G1 ~ G2 :. . F F G1 ~ G2 :. . F ' F G1 ~ G2 :. . F. F ' is unsound. While this example may seem \nunintuitive or even inconsistent if one reasons in terms of deterministic states, its intuitive signi.cance \nin a probabilistic setting is that neither of the relations F and \u00acF are enough to tell apart the two \n.nal distributions.  4.2 Observational equivalence Observational equivalence is derived as an instance \nof relational Hoarejudgmentsin whichpre andpostconditions are restricted to relations based on equality \nover a subset of variables. Given a set X of variables, wede.ne = X as def m1 = X m2 = . x . X. m1 x \n= m2 x Then, the observational equivalence of G1 and G2 w.r.t. an input set I and an output set O isde.ned \nas F G1 .I def O G2 = F G1 ~ G2 := I . = O Allderived rulesforpRHLcanbe specialized to the case of obser\u00advational \nequivalence. For example, wehave F e1 .I e2 F E1,c1 .IO E2,c2 F E1,c1 ' .I 2 ' O E2,c F E1,if e1 then \nc1 else c ' 1 .OI E2,if e2 then c2 else c2 ' where F e1 .I e2 ifffor every memories m1 and m2, m1 = I \nm2 implies [e1] m1 = [e2] m2. To support automation, CertiCrypt implements a calculus of variable dependencies \nand provides two functions, eqobsIn and eqobsOut, that given a command c and a set O (respectively I) \nof output(input) variables compute a set I (O) ofinput(output) variables such that F E1,c .I O E2,c. \nCertiCrypt also provides tacticsfortwo variants ofobservationalequivalence that are widely usedingame-basedproofs, \nnamely O G2 def F G1 ~ G2 : F. G1 .I == I . . . = O . . O G2 def F G1 ~ G2 : F.,F G1 .I == I . . . = \nO . F These tactics use a(soundbutincomplete) weakestprecondition calculusfor relationaljudgments.  \n5. Proof methodsforbridgingsteps CertiCrypt provides a powerful set of tactics and algebraic equiv\u00adalences \nto automate bridging steps. Most tactics rely on an imple\u00admentation of a certi.ed optimizer forpWHILE, \nwith the exception of lazy sampling which has an ad hoc implementation. Algebraic equivalences are provided \nas lemmas that follow from algebraic properties oftheinterpretation oflanguage constructs. 5.1 Certi.edprogramtransformations \nCertiCrypt provides automated support for transformations that consistinapplying compileroptimizations.Moreprecisely,it \nsup\u00adports transformations based on dependencies and data.ow analy\u00adses; we brie.y discuss them below. \nAdditionally, CertiCrypt pro\u00advides support for inlining procedure calls and performing register allocation(notdiscussedhere). \nTransformations based on dependencies The functions eqobsIn and eqobsOut presented inSec.4,provide thefoundations \nto sup\u00adport transformations such as dead code elimination, code motion, and common context elimination. \nFirst,CertiCrypt features afunction context that strips off two commands c and c ' their maximal common \ncontext relative to sets I and O of input and output variables. The correctness of context is expressedby \nthefollowing rule ''' '' context(I,c1,c2,O)=(I ,c 1,c 2,O ' ) F E1,c 1 .IO'' E2,c 2 F E1,c1 .I O E2,c2 \nUsing the sameidea, CertiCrypt provides algorithmsfor removing only a commonpre.x(eqobs hd)or suf.x(eqobs \ntl). Second, CertiCrypt provides a tactic thatgiven two commands repeatedly tries to hoist their common \ninstructions to obtain a maximal common pre.x5, which can then be eliminated using the previous rule.Its \ncorrectnessisbased on the rule F E,c1 .I1 E,c1 F E,c2 .I2 E,c2 modify(E,ci,Oi) O1 O2 O1 n O2 = \u00d8 I1 n \nO2 = \u00d8 I2 n O1 = \u00d8 F E,c1; c2 ~ E,c2; c1 := . = where modify(E,c,X)isasemanticpredicate expressingthatonly \nvariables in X are modi.ed by the command c in the environment E. This is formally expressed by . m. \nrange (.m ' .m = V\\X m ' )([E,c] m)which ensures that reachable .nal memories are equal to theinitial \none except maybe on variables in X.The tactic swap is based on the rule above and on an algorithm that \nover\u00adapproximates the set of modi.ed variables. Third,CertiCrypt allowsperformingdead code elimination \nrel\u00adative to a set O of output variables(deadcode).The algorithmbe\u00adhaves morelike an aggressive slicingalgorithm,i.e.it \nremovespor\u00adtions of code thatdo not affect variables in O, and performs at the same time branch prediction(replacing \nif true then c1 else c2 by c1),branchcoalescing(replacing if e then c else c by c), andself\u00adassignment \nelimination.Its correctness relies on the rule modify(E1,c,X) lossless(E1,c) fv(.)n X = \u00d8 F E1,c ~ E2,nil \n: . . . Optimizationsbased ondata.ow analyses CertiCrypt has built\u00adin, generic, support for such optimizations: \ngiven an abstract do\u00admain D (a semi-lattice)for the analysis, transfer functions for as\u00adsignment andbranching \ninstructions, and an operator transforming expressionsinthelanguageintotheir optimized versions(usingthe \nresult of the analysis), CertiCrypt automatically constructs the cer\u00adti.edoptimizationfunction optim \n: C. D . C\u00d7D.Whengiven a command c and an element d . D,thisfunctiontransforms c into its optimized version \nc ' assuming the validity of d. In addition, it returns an abstract postcondition d ' . D which is valid \nafter ex\u00adecuting c (orc ' ). We use these abstract postconditions to state the correctness of the optimization, \nand to apply the optimization re\u00adcursively. 5One could alsoprovide a complementary tacticthathoistsinstructionsto \nobtain a maximal common suf.x. The correctness of optim is proved using a mixture of the techniques of \n[9] and [10, 24]: we express the validity of the information contained in the analysis domain using a \npredicate Valid(d,m) that states the agreement between the compile time abstract values in d and the \nruntime memory m.Then, correctness is expressedin terms of apRHLjudgment: '' ' let (c,d ):=optim(c,d)in \nF E,c ~ E,c : .d ..d' def where m1 .d m2 = m1 = m2 . Valid(d,m1). The following useful ruleisderived \nusing[R-Comp] .m1 m2.m1 .m2 . Valid(d,m1) optim(c1,d)=(c1' ,d ' ) F E1,c 1 ' ~ E2,c2 :. . F [R-Opt] \nF E1,c1 ~ E2,c2 :. . F Ourcase studies extensivelyuseinstantiations of[R-Opt]to expres\u00adsion propagation(ep). \nIn contrast, we found that common subex\u00adpression eliminationis seldom used. 5.2 Lazy sampling Itis sometimes \nconvenient to defer random choices ingames until they are actually needed, or conversely, to make random \nchoices as early as possible. The lazy sampling technique, allows to delay the random sampling of a value \nuntil the point in the program whereitis .rst used.Conversely,eagersampling allowstochoose a random value, \nwhich would be otherwise sampled later, at the beginning of agame.These techniques arepresented in[8], \nwhere the authorsdiscuss some ofits subtleties.Inthis section wepresent a syntax-oriented criterionfor \nthe correctness oflazy sampling that can be applied provided the sampling is adequately guarded. Here \nbycontext we mean aprogram context with multipleholesthat may appear either in the main program or any \nof the procedures in the environment. Lemma 1 (Lazy/eager sampling). Let C[\u00b7] be a context, c1 and c2 \ncommands, e a boolean expression, d a distribution expression, and z a variable, such that C[\u00b7]does not \nmodify fv(e). fv(d)and does not use z.Assume $$$ 1. F z . d;c1;if e then z . d ~ z . d;c1 :(= . e(1)). \n= 2. F c2 ~ c2 :(= .\u00ace(1)). (=.\u00ace(1))  $ Let c = if e then z . d;c1 else c2 and c ' = if e then c1 \nelse c2. $$ Then, F C[c];if e then z . d ~ z . d;C[c ' ]:(= . e(1)). = Intuitively, in the above lemma \ne indicates whether z has not been usedinthegame sinceitwaslastsampled.Ifithas notbeen used,thenitisperfectly.neto \nresampleit.The .rsttwohypotheses ensure that e has exactly this meaning, c1 must set it to false if it \nhas usedthe value sampledinz, and c2 must not reset e ifitisfalse. The .rsthypothesisistheonethatallowstoswap \nc1 with z $ . d, provided the value of z is not used in c1.Note that,for clarity, we have omitted environments \nin the above lemma, and so the second hypothesis is not as trivial as it may seem because both programs \nmayhavedifferent environments. Suppose we want to eagerly sample the answer that a random oracle Ol(x)= \n. dom(L)then y $:: L; def if x/. d; L . (x,y)return L[x] gives to aparticularquery x ' ,i.e. we want \nto transform Ol into def Oe(x)= if x/. dom(L)then if x = x ' then y . y ' else y $ . d; L . (x,y):: L \nreturn L[x] def '' $ De.neOl' (x)= if x ./dom(L)then y . d;Oe(x)else Ol(x), def ' O ' e(x)= if x ./dom(L)then \nOe(x)else Ol(x), both return\u00ading L[x]. Oracles Ol and Oe result semantically equivalent to Ol ' and Oe' \n, respectively. Lemma 1 can be applied taking e = x ' ./dom(L), z = y ' , and c1 = Oe(x),c2 = Ol(x)to \nsafely replace oracle Ol by oracle Oe in the environment of aprogram, sampling y ' atthebeginning.Whenever \naboundforthe number ofqueriesto a random oracle is known in advance, the above trick can be iter\u00adatively \napplied to completely remove randomness from the oracle code, asitisdoneintheproof oftheSwitchingLemmainSec.2.2. \n 5.3 Algebraic equivalences Bridging steps frequently use algebraic properties of language op\u00aderators. \nThe proof of semantic security of ElGamal uses the fact thatin a cyclic multiplicativegroup, multiplication \nby a uniformly sampled element acts as a one-timepad: $\u00d7 \u00df .{a} y $ F x . Zq;a . g x . Zq;a . gy In theproof \nof security of OAEP we use optimistic sampling: F x .{0,1}k . x . z .{z} .{0,1}k ;x . y. z $;yy $ {x,y,z} \nandincremental sampling modulo apermutation f: $ F x .${0,1}k-. ;y .${0,1}. ;z . f(xIy).{z} z .{0,1}k \nWe show the usefulness of [R-Rand] by sketching the proof of optimistic sampling, as promised in Section \n4. For readability, we lete|i denote [e] mi.De.ne def def .= z|1 = z|2 F= x|1 = x|2 . y|1 = y|2 . z|1 \n= z|2 def Let F ' =F{x|1 . z|1/y|1,y|2 . z|2/x|2}.Then,by[R-Ass] we have F y . x . z ~ x . y. z :F ' \n. F def Now take fm1 m2 v = v . z|2,and apply[R-Rand] and[R-Sub] to obtain F x . ~.{0,1}k :. . F ' . \n${0,1}k y $ Note that the precondition we obtain after applying [R-Rand] is equivalent to . because f \nis a bijection on {0,1}k, and because .v. F ' {v/x|1,v . z|2/y|2} is equivalent toz|1 = z|2 by algebraic \nproperties ofthe . operator.We conclude by applying[R-Seq].  6. Proof methodsforfailureevents A technique \nused very often to relate two games is based on what cryptographers call failure events.Thistechnique \nrelies on a funda\u00admentallemma that allowstobound thedifferenceintheprobability of a given event in two \ngames: one identi.es a failure event and argues that both games behave identically until this event occurs. \nOne can then bound the difference in probability of another event bytheprobability of occurrence of thefailure \neventin eithergame. Lemma2(Fundamentallemma). LetG1 and G2 be twogames,A an event de.ned on G1, B an \nevent de.ned on G2 and F an event de.ned inbothgames.If PrG1 [A.\u00acF]=PrG2 [B .\u00acF], and PrG1 [F]= PrG2 \n[F] then |PrG1 [A]- PrG2 [B]|= PrG2 [F]. 6 In code-based proofs, the failure condition is generally indicated \nby setting aglobal .ag variable(usually called bad)to true. This specialization allows to de.ne a syntactic \ncriterion for deciding whethertwogamesbehave equivalently uptothe raise ofthefailure condition: we say \nthat two games G1 and G2 are equal up to bad and noteit uptobad(G1,G2)wheneverthey are syntactically \nequal up to every point where the bad .ag is set to true and they do not resetthe bad .agto false afterward.Forinstance,games \nGbad PRP and 6The second hypothesis is usually omitted in the literature under the as\u00adsumption that both \ngames are absolutely terminating. In that case, either G1 or G2 willdoontheright-hand side. Game EUFDH \n: Oracle H(m): Oracle Sign(m): L . []; S . []; if m . dom(L)then S . m :: S (m, x). A(); r $. {0,1}k; \nr . H(m); h . H(m) L . (m, r):: L return f-1(r) return L[x] Figure6. Initialgamein theproof of FDH unforgeability \nGbad PRF in Fig. 2 satisfy this condition. We have used this syntactic criterion to implement a specialization \nof the fundamental lemma forgame-basedproofs. Lemma3 (Syntactic criterionforfundamentallemma). . G1 G2 \nA.uptobad(G1,G2) . PrG1 [A.\u00acbad]=PrG2 [A.\u00acbad] The .rst hypothesis in Lemma 2 may be proved automatically \nby using this syntactic criterion. To prove the second hypothesis it suf.ces to show that game G2 is \nabsolutely terminating, for which we already have implemented a semi-decision procedure (seeSec.3.3). \n 7. Case studies The purpose of this section is to announce the successful comple\u00adtion of two experiments \nthat validate the design and usability of CertiCrypt. A detailed presentation of these works will be \ngiven elsewhere. 7.1 Existential unforgeability of FDH TheFullDomainHash(FDH)schemeis ahash-and-sign \nsignature scheme based on the RSA family of trapdoor permutations, and in which the message is hashed \nonto the full domain of the RSA function. However, the same construction and the reduction that proves \nits security remains valid for any family of trapdoor per\u00admutations. We have proved that FDH is existentially \nunforgeable under adaptive chosen-message attacksinthe random oracle model fortheimprovedboundin[15].Theproofis \nabout3,500lineslong. We will consider a generic family of trapdoor permutations f (andtheirinverses f-1)indexed \nby the securityparameter, and an ideal hash function H : {0,1} * .{0,1}k, which we model as a random \noracle.Theinitialgame of theproofis showninFig.6. De.nition6 (Trapdoor permutation security). We say \nthat a trap\u00addoorpermutation is (t,o)-secureif aninverter running within time t(k), when given a challenge \ny uniformly drawn from {0,1}k succeeds in .nding f-1(y) with probability at most o(k), i.e. if for any \nwell-formed adversary B running within time t(k)in Gf f-1(y) $ we have PrGf x = = o(k), where Game Gf \n: y . {0,1}k; x .B(y). Theorem1(FDH exact security). Assumethe underlyingtrapdoor permutation is (t ' \n,o ' )-secure. Then, a forger that makes at most qhash and qsign queries to the hash and signing oracles \nrespectively and runs withintime t(k)= t ' (k)-(qhash(k)+qsign(k)+1)O(Tf), succeeds in forging a signature \nfor a new message different from the ones asked to the signing oracle withprobability at most qsign(k) \n'' o(k)= o (k) exp(1) qsign(k)o (k) )qsign(k)+1 qsign(k)+1 (1- 1 i.e. for a well-formed adversary A \nrunning within t(k)we have [h = f(x)]= o(k). PrEUFDH 7.2 Semantic security of OAEP OAEP is a padding \nscheme whose history perfectly illustrates the dif.culty in achieving a correct proof. Indeed, it was \ninitially believed that OAEP was IND-CCA2 secure [7], but it was later discovered it was only IND-CCA1 \nsecure[30], a weaker security notion(where the adversarydoes nothave access to thedecryption oracle after \nreceiving the challenge). Itispossible to recover IND-CCA2 security by using it together with a suitable \nencryption scheme, asitisthe caseforRSA-OAEP [17].Here wefocus onthe game-basedproofof[8]which shows \nIND-CPA security of OAEP in the random oracle model. The de.nition of OAEP is parametrized by a trapdoor \none\u00adway permutation f : {0,1}k .{0,1}k, and two hash functions G : {0,1}. .{0,1}k-. and H : {0,1}k-. \n.{0,1}. . OAEP adds randomnessinto theplaintext m and uses thefunctions Gand H to mask it before applying \nf to the result, as formalized by the straightforward codefor encryption: .{0,1}.R $;S . G(R). m;T . \nH(S). R;return f(SIT) Wehaveprovedthat OAEP isIND-CPA secure.Theproofis about 3,000lineslong. Theorem \n2 (OAEP semantic security). For well-formed adver\u00adsaries A and A ' making together at most qG queries \nto G, '1 -1qG b = b - |= PrGf x = f(y)+ |PrIND-CPAOAEP 22. f-1 where PrGf x =(y) is the probability \nof an adversary in\u00adverting f on a random element ofits codomain, asinDe.nition 6. Our sequence ofgamesdiffersfrom[8]:intheirinitial \ntransi\u00adtions, Bellare and Rogaway use the fundamental lemma, whereas we use lazy sampling. As a result, \nour bound for OAEP is tighter than theboundpublishedin[8], which alsoinvolves the number qH of calls \nto H: ' 1 -1 2qG qH|PrIND-CPAOAEP b = b - |= PrGf x = f(y)+ + 22. 2k-. We considerthatourproof of OAEP \nishighlyemblematic,because ofits complexity anditshistory.In retrospect, thebound weprove, which is independent \nof qH, shows that formalizing proofs some\u00adtimes leads to improvements on previous results (to the best \nof our knowledge). However, cryptographers are really interested in a proof of IND-CCA2, and thus our \nnext objective is to machine\u00adcheck the results of[17].  8. Related work Cryptographicprotocolveri.cationis \nan established area offormal methods, and a wealth of automated and deductive methods have been developed \nto the purpose of verifying that protocols provide the expected level of security [25]. Traditionally, \nprotocols have been veri.ed in a symbolic model, for which effective decision procedures existunder suitablehypotheses.Although \nthe symbolic model assumesperfect cryptography, soundness results such as[1] relate the symbolic model \nwith the computational model,provided the cryptographic primitives are secure. It is possible to combine \nsymbolic methods and soundness proofs to achieve guarantees in thecomputational model,asdone e.g.in[5,32].Onedrawback \nof this approachisthatthe securityproof relies onintricate soundness proofs. Besides, it is not clear \nwhether computational soundness results will always exist to allow factoring veri.cation through symbolic \nmethods.Consequently, some authors attempt toprovide guaranteesdirectlyat the computationallevel[11,23,28]. \nIn contrast, the formal veri.cation of cryptographic functional\u00aditiesis an emergingtrend.An early work \nofBarthe,Cederquist and Tarento[6]provesthe security of ElGamal in Coq, but the proof relies on thegeneric \nmodel, a very specialized andidealized model that elides many of the issues that are relevant for cryptography. \nCorin anddenHartog[14] alsoprove ElGamal semantic security, using aprobabilistic(non-relational) Hoarelogic.However,their \nformalism is not suf.ciently powerful to express precisely the se\u00adcurity goals: notions such as well-formed \nand effective adversary are not modeled. BlanchetandPointcheval[12]wereamong the .rsttousever\u00adi.cation \ntools to carry out game-based proofs of cryptographic schemes. They used CryptoVerif to prove exact security \nof the FDH signature scheme, for a bound weaker than the one given in Section 7.1. More recently, Courant \net al [16] have developed a form ofstrongestpostcondition calculusthat can establish automat\u00adically asymptotic \nsecurity(IND-CPA and IND-CCA2)of schemes that use one-wayfunctions and random oracles.They show sound\u00adness \nandprovide aprototype implementation that covers many ex\u00adamples of theliterature,including OAEP+.Webelieve \nthe two ap\u00adproaches are complementary to ours: compiling CryptoVerif se\u00adquences ofgames and embedding \nthetype system of[16] in Cer\u00adtiCrypt, areinteresting researchdirections. In parallel, several authors \nhave initiated formalizations of game-based proofs in proof assistants, and shown the security of basic \nexamples. Nowak [26] gives a game-based proof of ElGa\u00admal semantic security in Coq. Nowak uses a shallow \nembedding to model games; as a result, its framework ignores complexity is\u00adsues, andhaslimited supportforproof \nautomation:becausethereis no special syntax for writing games, mechanizing syntactic trans\u00adformations \nbecomes very dif.cult. Affeldt et al [2] formalize a game-based proof of the switching lemma in Coq. \nHowever, their formalization is tailored towards the particular example they con\u00adsider, which substantially \nsimpli.es their task and hinders gener\u00adality.Theydeal with a weak(non-adaptive) adversary model and ignore \ncomplexity. All in all, both works appear like preliminary experiments that are notlikely to scale. Leavingthe \nrealm ofcryptography, CertiCrypt relies ondiverse mathematical concepts and theories that have been modeled \nfor their own sake. It is not possible to report on these developments here, so we limit ourselves to \nsingling out Paulin s formalization of the measure monad, which we use extensively in our work, and the \nwork ofHurd et al.[20], whodeveloped a mechanized theory in theHOLtheoremproverfor reasoning aboutpGCLprograms, \na probabilistic extension ofDijkstra sguarded commandlanguage. 9. Conclusion Summary and perspectives \nCertiCrypt is a fully formalized framework that supports machine-checked game-based proofs; we have validated \nits design through formalizing standard cryp\u00adtographicproofs.Our work shows that machine-checked proofs \nof cryptographic schemes is not only plausible but indeed feasible. However, constructing machine-checked \nproofs requires a high\u00adlevel of expertise in formal proofs and remains time consuming despite thehighlevelof \nautomationprovidedby CertiCrypt.Thus, CertiCrypt only provides a .rst step towards the completion of \nHalevi s programme, in spite of the amount of work invested so far(theprojectwasinitiatedinJune2006).Amedium-term \nob\u00adjective would be to develop a minimalist interface that eases the writing ofgamesandprovidesa .xed \nsetof mechanisms(tactics, proof-by-pointing)toprove somebasic transitions,leaving the side conditions \nas hypotheses. We believe that such an interface would help cryptographers ensure that there are no obvious \n.aws in their de.nitions and proofs, and to build sketches of security proofs. In fact, it is our experience \nthat the type system and the automated tacticsprovide valuableinformationindebuggingproofs. Future work \nNumerous research directions remain to be ex\u00adplored. Our .rst objective is to strengthen our result for \nOAEP. It would also be useful to formalize cryptographic meta-results such as the equivalencebetween \nIND-CPA and IND-CCA2 underplain\u00adtext awareness. Another objective would be to formalize proofs of computational \nsoundness ofthe symbolic model, see e.g.[1] and proofs of automated methods for proving security of primitives \nandprotocols,seee.g.[16,23].Finally,itwould alsobeworth\u00adwhile to explore applications of CertiCrypt outside \ncryptography, inparticular to randomized algorithms and complexity.  Acknowledgments We would like \nto acknowledge Romain Janvier and Federico Olmedo for their enthusiastic participation in the project, \nChris\u00adtine Paulin for the support provided in using her library, and the anonymous reviewersfor theirinsightful \ncomments. References [1] M. Abadi and P. Rogaway. Reconciling two views of cryptography (the computational \nsoundness of formal encryption). Journal of Cryptology, 15(2):103 127, 2002. [2] R. Affeldt, M. Tanaka, \nand N. Marti. Formal proof of provable security by game-playing in a proof assistant. In Proceedings \nof International Conference on Provable Security, volume 4784 of Lecture Notesin Computer Science,pages151 \n168.Springer,2007. [3] T.Amtoft,S.Bandhakavi, andA.Banerjee. Alogicforinformation .ow in object-oriented \nprograms. In Proceedings of the 33rd ACM Symposium onPrinciples ofProgrammingLanguages,pages91 102. ACMPress,2006. \n[4] P. Audebaud and C. Paulin-Mohring. Proofs of randomized algorithmsinCoq. Science of Computer Programming,2008. \n [5] M. Backes and P. Laud. Computationally sound secrecy proofs by mechanized .ow analysis. In Proceedings \nof the 13th ACM Conference on Computer and Communications Security, pages 370 379.ACMPress,2006. [6] \nG. Barthe, J. Cederquist, and S. Tarento. A machine-checked formalization of the generic model and the \nrandom oracle model. In 2nd International Joint Conference on Automated Reasoning, pages385 399.Springer-Verlag, \n2004. [7] M.BellareandP.Rogaway. Optimal asymmetricencryption How to encrypt withRSA. In AdvancesinCryptology \nEUROCRYPT 94, volume 950 of Lecture Notes in Computer Science, pages 92 111. Springer-Verlag, 1995. [8] \nM. Bellare and P. Rogaway. The security of triple encryption and a framework for code-based game-playing \nproofs. In Advances in Cryptology EUROCRYPT 06, volume 4004 of Lecture Notes in Computer Science,pages409 \n426,2006. [9] N. Benton. Simple relational correctness proofs for static analyses and program transformations. \nIn Proceedings of the 31th ACM Symposium on Principles of Programming Languages, pages 14 25. ACMPress,2004. \n[10] Y.Bertot,B.Gr\u00b4egoire,andX.Leroy.Astructured approachtoproving compiler optimizations based on data.ow \nanalysis. In International Workshop onTypesforProofsandPrograms, volume3839 of LNCS, pages66 81.Springer-Verlag, \n2006. [11] B.Blanchet.Acomputationally sound mechanizedproverforsecurity protocols. In IEEESymposium \nonSecurity andPrivacy, pages 140 154,2006. [12] B. Blanchet and D. Pointcheval. Automated security proofs \nwith sequences of games. In Advances in Cryptology CRYPTO 06, volume4117 of Lecture Notes in Computer \nScience, pages537 554. Springer-Verlag, 2006. [13] R. Canetti, O. Goldreich, and S. Halevi. The random \noracle methodology, revisited. J.ACM,51(4):557 594, 2004. [14] R. Corin and J. den Hartog. A probabilistic \nHoare-style logic for game-based cryptographic proofs. In Proceedings of the 33rd International Colloquium \non Automata, Languages and Programming, volume4052 of LNCS,pages252 263,2006. [15] J.-S.Coron.Ontheexact \nsecurity ofFullDomainHash.In Advances in Cryptology, volume 1880 of Lecture Notes in Computer Science, \npages229 235.Springer-Verlag, 2000. [16] J.Courant,M.Daubignard,C.Ene,P.Lafourcade, andY.Lakhnech. Towards \nautomated proofs for asymmetric encryption in the random oracle model. In Computer and Communications \nSecurity. ACM Press,2008. [17] E.Fujisaki,T.Okamoto,D.Pointcheval, andJ.Stern. RSA-OAEPis secure under \nthe RSA assumption. Journal of Cryptology, 17(2):81 104,2004. [18] S. Goldwasser and S. Micali. Probabilistic \nencryption. J. Comput. Syst. Sci.,28(2):270 299,1984. [19] S. Halevi. A plausible approach to computer-aided \ncryptographic proofs.Cryptology ePrintArchive,Report2005/181,2005. [20] J.Hurd,A.McIver,andC.Morgan.Probabilisticguarded \ncommands mechanized inHOL. Theor.Comput.Sci.,346(1):96 112, 2005. [21] B. Jonsson, K. G. Larsen, and \nW. Yi. Probabilistic extensions of process algebras. In Handbook of Process Algebra,pages 685 711. Elsevier, \n2001. [22] D.Kozen.Semanticsofprobabilisticprograms. J.Comput.Syst.Sci., 22:328 350, 1981. [23] P.Laud. \nSemantics andprogram analysis of computationally secure information .ow. In EuropeanSymposium onProgramming, \nvolume 2028 of Lecture Notes in Computer Science, pages 77 91. Springer\u00adVerlag,2001. [24] X. Leroy. Formal \ncerti.cation of a compiler back-end, or: pro\u00adgramming a compiler with a proof assistant. In Proceedings \nof the 33rdACMSymposiumPrinciples ofProgramming Languages,pages 42 54.ACMPress,2006. [25] C. Meadows. \nFormal methods for cryptographic protocol analysis: Emerging issues and trends. IEEE Journal on Selected \nAreas in Communications, 21(1):44 54,2003. [26] D. Nowak. A framework for game-based security proofs. \nIn Information and Communications Security, volume 4861, pages 319 333.Springer-Verlag, 2007. [27] N.Ramsey \nandA.Pfeffer.Stochasticlambdacalculusand monadsof probability distributions. InProceedings of the29thACMSymposium \non Principles of Programming Languages, pages 154 165. ACM Press,2002. [28] A. Roy, A. Datta, A. Derek, \nand J. C. Mitchell. Inductive proofs of computational secrecy. In European Symposium On Research In Computer \nSecurity, volume 4734 of Lecture Notes in Computer Science,pages219 234.Springer-Verlag, 2007. [29] A.Sabelfeld \nandD.Sands. Apermodel of secureinformation .ow in sequential programs. Higher-Order and Symbolic Computation, \n14(1):59 91, 2001. [30] V. Shoup. OAEP reconsidered. In Advances in Cryptology CRYPTO 01, volume 2139 \nof Lecture Notes in Computer Science, pages239 259.Springer-Verlag, 2001. [31] V. Shoup. Sequences of \ngames: a tool for taming complexity in securityproofs.Cryptology ePrintArchive,Report2004/332,2004. [32] \nC.Sprenger andD.Basin. Cryptographically-soundprotocol-model abstractions. In Proceedings of CSF 08, \npages 115 129. IEEE Computer Society,2008. [33] J.Stern. Whyprovable security matters? In Advances in \nCryptology EUROCRYPT 03, volume 2656 of Lecture Notes in Computer Science. Springer-Verlag, 2003. [34] \nThe Coq development team. The Coq Proof Assistant Reference Manual v8.1,2006.Available at http://coq.inria.fr \n.  \n\t\t\t", "proc_id": "1480881", "abstract": "<p>As cryptographic proofs have become essentially unverifiable, cryptographers have argued in favor of developing techniques that help tame the complexity of their proofs. Game-based techniques provide a popular approach in which proofs are structured as sequences of games and in which proof steps establish the validity of transitions between successive games. Code-based techniques form an instance of this approach that takes a code-centric view of games, and that relies on programming language theory to justify proof steps. While code-based techniques contribute to formalize the security statements precisely and to carry out proofs systematically, typical proofs are so long and involved that formal verification is necessary to achieve a high degree of confidence. We present Certicrypt, a framework that enables the machine-checked construction and verification of code-based proofs. Certicrypt is built upon the general-purpose proof assistant Coq, and draws on many areas, including probability, complexity, algebra, and semantics of programming languages. Certicrypt provides certified tools to reason about the equivalence of probabilistic programs, including a relational Hoare logic, a theory of observational equivalence, verified program transformations, and game-based techniques such as reasoning about failure events. The usefulness of Certicrypt is demonstrated through various examples, including a proof of semantic security of OAEP (with a bound that improves upon existing published results), and a proof of existential unforgeability of FDH signatures. Our work provides a first yet significant step towards Halevi's ambitious programme of providing tool support for cryptographic proofs.</p>", "authors": [{"name": "Gilles Barthe", "author_profile_id": "81100111668", "affiliation": "Instituto Madrile&#241;o de Estudios Avanzados, Madrid, Spain", "person_id": "P1300935", "email_address": "", "orcid_id": ""}, {"name": "Benjamin Gr&#233;goire", "author_profile_id": "81381590776", "affiliation": "Institut National de Recherche en Informatique et en Automatique, Sophia Antipolis, France", "person_id": "P1300936", "email_address": "", "orcid_id": ""}, {"name": "Santiago Zanella B&#233;guelin", "author_profile_id": "81418594739", "affiliation": "Institut National de Recherche en Informatique et en Automatique, Sophia Antipolis, France", "person_id": "P1300937", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480894", "year": "2009", "article_id": "1480894", "conference": "POPL", "title": "Formal certification of code-based cryptographic proofs", "url": "http://dl.acm.org/citation.cfm?id=1480894"}