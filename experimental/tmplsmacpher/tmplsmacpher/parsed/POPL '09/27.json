{"article_publication_date": "01-21-2009", "fulltext": "\n Unifying Type Checking and Property Checking for Low-Level Code Jeremy Condit Brian Hackett Microsoft \nResearch Stanford University jcondit@microsoft.com bhackett@cs.stanford.edu Abstract We present a uni.ed \napproach to type checking and property check\u00ading for low-level code. Type checking for low-level code \nis chal\u00adlenging because type safety often depends on complex, program\u00adspeci.c invariants that are dif.cult \nfor traditional type checkers to express. Conversely, property checking for low-level code is challenging \nbecause it is dif.cult to write concise speci.cations that distinguish between locations in an untyped \nprogram s heap. We address both problems simultaneously by implementing a type checker for low-level \ncode as part of our property checker. We present a low-level formalization of a C program s heap and \nits types that can be checked with an SMT solver, and we provide a decision procedure for checking type \nsafety. Our type system is .exible enough to support a combination of nominal and structural subtyping \nfor C, on a per-structure basis. We discuss several case studies that demonstrate the ability of this \ntool to express and check complex type invariants in low-level C code, including several small Windows \ndevice drivers. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation \nGeneral Terms Languages, Veri.cation 1. Introduction Despite the availability of safe, high-level languages, \nmany of our most critical software systems are still written in low-level lan\u00adguages such as C and C++. \nAlthough these languages are very ex\u00adpressive and can be used to write high-performance code, they do \nnot enforce type and memory safety, which makes them much less robust and much harder to analyze than \nhigher-level languages. In addition, these languages lend themselves to complex program in\u00advariants that \nare dif.cult for programmers to verify. Existing approaches to these problems, including type checking \nand property checking, have encountered a number of key chal\u00adlenges. Sound type checking for low-level \ncode is challenging be\u00adcause type safety often depends on subtle, program-speci.c invari\u00adants. Although \nprevious low-level type systems can be quite ex\u00adpressive [17, 29, 31], they are typically designed for \na .xed set of programming idioms and are hard to adapt to the needs of a par\u00adticular program. Similarly, \nproperty checking tools, which verify Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 09, January 18 24, 2009, Savannah, Georgia, USA. Copyright c &#38;#169; \n2009 ACM 978-1-60558-379-2/09/01. . . $5.00 Shuvendu K. Lahiri Shaz Qadeer Microsoft Research Microsoft \nResearch shuvendu@microsoft.com qadeer@microsoft.com assertions in programs annotated with preconditions \nand postcon\u00additions, are dif.cult to apply to low-level code. Although these tools can be quite powerful \nand general, they typically ignore types for soundness [15, 22] or rely on unproven type safety assumptions \nin order to achieve the necessary level of precision [8, 24]. In this paper, we address these challenges \nby implementing a uni.ed type checker and property checker for low-level C code. The type checker can \nuse the full power of the property checker to express and verify subtle, program-speci.c type and memory \nsafety invariants that are beyond the capabilities of existing type checkers for low-level code. Meanwhile, \nthe property checker can rely on the type checker to provide structure and disambiguation for the program \ns heap, enabling more concise and more powerful type\u00adbased speci.cations. Our approach makes use of a \nfully automated Satis.ability Modulo Theories (SMT) [36] solver, which means that the programmer s only \nduty is to provide high-level type and property annotations as part of the original program s source. \nTo implement our uni.ed type and property checker, we provide a low-level model of types as predicates \nover the program state (similar to foundational proof-carrying code [5]) along with an explicit type \nsafety invariant. Our tool models the C program s heap using two maps that represent the data in the \nprogram s heap and the types at which each heap location was allocated: Mem : int . int Type : int . \ntype  Our checker also de.nes a predicate called HasType, which indicates whether a given value corresponds \nto a given type, and we use this predicate to state the type safety invariant for the heap: .a : int.HasType(Mem[a], \nType[a]) By asserting and checking this simple invariant at each program point, we can use the property \nchecker to verify type safety in a .ow-sensitive and path-sensitive manner. We also provide a deci\u00adsion \nprocedure for the resulting type safety assertions. This approach to type checking and property checking \nhas many bene.ts. First, the programmer can provide additional information about program-speci.c type \ninvariants using the language of the property checker. Second, our tool can use information in the Type \nmap in order to identify and distinguish structure .elds that are important for checking higher-level \nproperties of the code. In fact, when checking C structures, we can effectively choose between a nominal \nand a structural de.nition of type equivalence on a per\u00adstructure basis. Finally, because we encode the \nmeaning of types directly in our translated program instead of relying on rules for deriving type judgments, \nour system does not require a prede.ned set of type rules or a complex, of.ine proof of soundness. We \nimplemented this technique as part of the HAVOC property checker [2], and we have applied it to a number \nof microbench\u00admarks and to several small Windows device drivers, which can be struct list { list *next; \nlist *prev; } struct record { int data1; list node; int data2; } #define container(p) ((record*)((int*)(p) \n-1)) void init_record(list *p) { record *r = container(p); r->data2 = 42; } void init_all_records(list \n*p) { while (p != NULL) { init_record(p); p = p->next; } } Figure 1. Example C code. The diagram shows \ntwo record struc\u00adtures in a linked list, with the embedded list shown in gray. veri.ed, modulo a handful \nof unchecked assumptions, in about one minute each. This technique has allowed us to check complex spa\u00adtial \ntype and memory safety properties (i.e., safety in the presence of pointer arithmetic, casts, and linked \ndata structures) that previ\u00adous tools were incapable of expressing or checking; in addition, our property \nchecker is now capable of exploiting concise, type-based annotations in proving properties of low-level \ncode. The contributions of this paper are: A low-level encoding of a C program s heap and types that \nallow automated veri.cation of strong type safety properties.  A semantics for C types that can be used \nin speci.cations for a sound property checker.  A decision procedure for the type safety assertions \ngenerated by our encoding.  Case studies evaluating the effectiveness of this technique on real C code, \nincluding small Windows device drivers.  In the next section, we present an example that demonstrates \nour technique in more detail. Then, we present the formal translation, our decision procedure, and extensions \nfor certain C features. Fi\u00adnally, we present case studies, discuss related work, and conclude. 2. Overview \nIn this section, we provide an overview of our technique using the sample code shown in Figure 1, which \ndemonstrates a C language idiom commonly found in code such as the Windows kernel. The structure list \nrepresents a doubly-linked list with prev and next pointers, and it is intended to be embedded in the \nmiddle of a larger structure, such as the record structure. When initializing the elements of the list \n(init record and init all records), the programmer must use pointer arithmetic and trusted type casts \nto compute the address and type of the enclosing record for each list node (as encapsulated by the container \nmacro). let Mem : int . int let Type : int . type let ctor Int : type let ctor Ptr : type . type let \nctor List : type let ctor Record : type let Match : int \u00d7 type . bool Match(a, Int) . Type[a]= Int Match(a, \nPtr(t)) . Type[a]= Ptr(t) Match(a, List) . Match(a, Ptr(List)) . Match(a +1, Ptr(List)) Match(a, Record) \n. Match(a, Int) . Match(a +1, List) . Match(a +3, Int) let HasType : int \u00d7 type . bool HasType(v, Int) \n. true HasType(v, Ptr(t)) . v =0 . (v> 0 . Match(v, t)) pre (.a : int.HasType(Mem[a], Type[a])) pre \n(HasType(p, Ptr(List))) post (.a : int.HasType(Mem[a], Type[a])) fun init record(p : int): unit = let \nr : int in r := p - 1; assert .a : int.HasType(Mem[a], Type[a]); assert HasType(p, Ptr(List)); assert \nHasType(r, Ptr(Record)); Mem[r + 3] := 42; assert .a : int.HasType(Mem[a], Type[a]); assert HasType(p, \nPtr(List)); assert HasType(r, Ptr(Record)); Figure 2. Translated BPL code for init record. The diagram \nat the top of Figure 1 illustrates a typical use of these data structures. In the diagram, we have two \nrecord objects in a list, with their embedded list objects shown in gray. Note that next and prev point \nto the embedded list objects, not the containing record objects. The init record function computes the \npointer r from the pointer p using the container macro. There are two challenges presented by this example: \n1. Type checking. Because of the arithmetic performed by the container macro, it is not obvious to a \nnaive type checker that this code is well-typed; in fact, the well-typedness of this code relies on an \nunstated precondition about the lists that can be passed to init all records. Existing tools for enforcing \ntype safety in C programs would have dif.culty reasoning about this code because it relies on a program-speci.c \ninvariant. 2. Property checking. If a property checker wanted to prove that init all records does not \nalter the contents of .eld data1, it would need to prove that the data1 and data2 .elds of two structures \ncan never be aliased. This fact is hard to prove with\u00adout enforcing a strong type invariant throughout \nthe program.  This section will present a step-by-step example showing how we address these challenges. \nOur technique translates the original C code (plus some optional user-supplied annotations) into a lower\u00adlevel \nlanguage called BPL (a simpli.ed version of BoogiePL [9]) that is suitable for input to a property checker. \nBPL has no notion of a heap or of C types, so this translation must model these constructs explicitly \nin BPL. Once the BPL code is generated, a property checker can be used to verify all assertions in this \ncode. 2.1 Translating from C to BPL Figure 2 shows the BPL translation produced for the init record function. \nThis BPL code makes use of four built-in sorts: int, which represents values in the original C program, \ntype, which represents types in the original C program, bool, which represents formulas, and unit, which \nis used by functions that do not return a value. The core of our translation involves the maps Mem and \nType, which are de.ned at the top of Figure 2. As mentioned in Section 1, Mem models the C program s \nheap as a map from integer addresses to integer values, and Type models the program s allocation state \nas a map from integer addresses to types. Our translation will enforce type safety by explicitly asserting \nthe following type safety invariant at every program point: .a : int.HasType(Mem[a], Type[a]) This type \nsafety invariant says that for every address a in the program s heap, the value at Mem[a] corresponds \nto the type at Type[a] according to the predicate HasType. In order to de.ne HasType, we must .rst discuss \nhow our trans\u00adlation models C types. As shown in Figure 2, our translation de.nes nullary type constructors \nInt, List, and Record, which correspond to the built-in integer type and the user-de.ned list and record \ntypes. We also de.ne the unary type constructor Ptr, which is used to construct pointer types such as \nPtr(Int). Each type expression created by applying these constructors has a unique value. Some of these \ntype constants represent types that consume one word in memory (Int and Ptr(t)), whereas others consume \nmore than one word in memory (List and Record). Since Type gives the type for each individual word in \nmemory, we de.ne a new predicate, Match(a, t), that holds if and only if the values of Type starting \nat address a match the layout of type t. In other words, Match lifts Type to types that may span multiple \naddresses. In our model, integers and pointers span only a single address in the heap, so Match for integers \nand pointers simply checks that Type has the appropriate value at address a. For List and Record, we \nde.ne Match inductively by checking each .eld of the structure using its declared type. For example, \nMatch(a, Record) holds if and only if the values of Type[a] through Type[a + 3] correspond to the declared \ntypes for the .elds of the structure record. Finally, we must de.ne HasType itself. Since HasType only \napplies to types that span a single address, we de.ne it only for Int and Ptr. For integers, all values \nare considered valid values of type Int. For pointers, the valid values include zero (the null pointer) \nand positive heap addresses that match the pointer s base type, as de.ned by Match. Now that we have \nformalized the program s heap, the pro\u00adgram s types, and our notion of type safety, we can translate \nthe init record function itself. The translated function has two pre\u00adconditions: .rst, the type safety \ninvariant holds on entry to the func\u00adtion, and second, the argument variable p has its declared type. \nThis function also has a single postcondition, which simply says that the type safety invariant holds \non exit as well. Inside the body of the function, we declare a variable r corre\u00adsponding to the variable \nin the original C program, and we translate the arithmetic and assignments in the C program into the \ncorre\u00adsponding operations on r and Mem. Note that all type casts have been eliminated during this translation. \nHowever, at every program point, we re-assert the type safety invariant, and we also assert that our \nlocal variables, r and p, still have their declared types.  2.2 Checking the Program Now that we have \na complete translation, we use a standard Floyd-Hoare veri.cation condition generator, and we pass the \nveri.cation condition to our SMT solver. Unfortunately, the code shown in Figure 2 has a problem: after \nexecuting the statement r := p-1, the assertion HasType(r, Ptr(Record)) does not hold. Moreover, the \nnext statement, which assigns to Mem[r+3], would violate the type safety invariant, since we cannot deduce \na value for Type[r+3] and thus cannot prove that HasType(42, Type[r + 3]). To address this problem, \nthe programmer needs to provide more type information in the form of an extra precondition in the C code: \npre(hastype(container(p), record*) &#38;&#38; container(p) != 0)  This precondition is then translated \ninto BPL as the following additional precondition on init record: pre (HasType(p - 1, Ptr(Record)) . \np - 1 = 0) Note that this precondition is completely consistent with the existing preconditions, because \nthe record type contains a list type at offset 1. With this precondition, we can prove that r has type \nPtr(Record) after it is initialized. In addition, we can prove that HasType(42, Type[r + 3]) using the \ntype safety invariant and the de.nition of Match for Record. So, by allowing the programmer to supply \nadditional type in\u00adformation in the form of a precondition that refers to our HasType predicate, we have \nallowed the user to explain why their code is type-safe, and we have proved mechanically that type safety \nholds when given this precondition. Although this example uses a very simple precondition, our technique \nexposes the full power of the SMT solver to the type checker. For example, when annotating init all records, \nwe must not only state that the argument p points to a list embedded inside a record, but that all list \nobjects reachable from p by following a next pointer also have this property. We can state this precondition \nin the C program as follows: pre(forall(q, reach(p, next), q != 0 ==> hastype(container(q), record*) \n&#38;&#38; container(q) != 0))  Essentially, our technique allows us to describe complex program\u00adspeci.c \ninvariants that are needed to prove the code to be type-safe. 2.3 Field Sensitivity So far, we have \nfocused on type safety alone; however, this tech\u00adnique also has many advantages for the property checking \ntool it\u00adself. Let s say that we want to prove that the data1 .elds of the record structures are untouched \nby init all records. Unfortunately, because we represent C s heap as a single array of integers, such \nassertions are notoriously dif.cult to prove. For example, our theorem prover has no way to prove that \nthe data1 .eld does not happen to overlap with data2 of some other record, and since data2 is modi.ed \nby init record, we might inadver\u00adtently modify another record s data1 .eld as well. To address this problem, \nwe allow the programmer to use a .eld\u00adsensitive translation that introduces a new type constant for each \nword-sized .eld in the program. Our translation in Figure 2 would be extended with the following de.nitions: \nlet ctor Data1 : type let ctor Data2 : type Match(a, Data1) Type[a]= Data1 Match(a, Data2) Type[a]= Data2 \nMatch(a, Record) Match(a, Data1) . Match(a +1, List) . Match(a +3, Data2) HasType(v, Data1) HasType(v, \nInt) HasType(v, Data2) HasType(v, Int) Now we have two new type constants, Data1 and Data2, which represent \nthe two integer .elds of the record structure. Their Types (one word) Types (general) t s ::= ::= int \n| s* t | t L-expressions Expressions l e ::= ::= | *e | l.f x | n | l | &#38;l e1 op e2 | e1 .n e2 | \n(t ) e Commands c ::= |||| skip | c1; c2 | x := new s x := f(e) | x := e | l := e if e then c while e \ndo c let x : t in c | return e Type de.nitions Procedures d p ::= ::= type t = {f1 : s1; . . . ; fn : \nsn}pre e1 post e2 f(x : tx) : tf = c Figure 3. Our C-like input language. HasType de.nition is the same \nas the de.nition for Int, so they can still hold the same set of values. However, the Match de.nition \nfor Record is altered so that Type must specify Data1 and Data2 at the appropriate offsets instead of \njust Int. The next and prev .elds could also be made .eld-sensitive in the same way. With this change, \nwe can now prove that Data1 is not modi.ed by these functions, because we can show that the only heap \nloca\u00adtions that are updated are locations a such that Type[a]= Data2. This level of precision is extremely \nimportant for proving higher-level properties of C programs. For languages such as Java, disambiguation \nby .eld is taken for granted using the Burstall-Bornat memory model [12]; our technique makes .eld disam\u00adbiguation \nfeasible in C programs as well. Furthermore, by tying disambiguation to our type safety invariant, we \nhave a convenient way to enforce our invariant throughout the program, making use of the programmer s \noriginal type declarations. From the type safety point of view, .eld sensitivity represents nominal type \nequivalence as opposed to structural type equiva\u00adlence. In our original translation, any structure with \nthe same layout as record would have matched that location, which corresponds to structural type equivalence; \nhowever, in the .eld-sensitive transla\u00adtion, only record structures may match that location. Both disci\u00adplines \nhave their uses in C programs, and our technique allows the user to select the appropriate one on a per-structure \nbasis. Now that we have provided an overview of our technique and the associated contributions, the rest \nof this paper will de.ne our translation formally, show that the resulting veri.cation conditions are \ndecidable, and provide extensions that can help the programmer address many common idioms in real C programs. \n3. Translation In this section, we will formally de.ne our translation from C to our property checker \ns input language, BPL. 3.1 Languages First, we de.ne our input and output languages. The input lan\u00adguage, \nshown in Figure 3, is a simpli.ed version of the C language. The key C features modeled by this language \nare pointer types, structure types, the address-of operator (&#38;), pointer arithmetic on a pointer \nto a type of size n (.n), and type casts ((t) e). We have three primitive types: integer types (int), \npointer types (s*), and named structure types (t). The non-terminal t stands for all types whose run-time \nrepresentation .ts in a single word Sorts s ::= int | bool | unit | type | s 1 \u00d7 s 2 | s 1 . s 2 Expressions \ne ::= x | M[ e] | n | C( e1,..., e n) | e 1 binop e 2 Formulas b ::= true | false | e 1 relop e 2 | \nP( e1,..., e n) |\u00ac b | b1 . b2 |.x : s.b Commands c ::= skip | c 1; c2 | x := call f( e) | x := e | x[ \ne1]:= e2 | if e then c | while e do c | let x : s in c | return e | assert b | assume b | havoc x Procedures \np ::= pre b1 post b2 fun f(x : s): s = c Figure 4. BPL, our output language. (integers and pointers), \nand the non-terminal s represents all types. For simplicity, we assume that the size of a word is 1. \nNext we have l-expressions1 and expressions, which include pointer dereference, .eld reference, address-of, \npointer arithmetic, and casts. The symbol op represents binary operations, including both arithmetic \nand boolean operations. Commands include alloca\u00adtion, function call, assignment, and variable declaration. \nAt the top level, we have type de.nitions and procedures. Type de.nitions allow users to create named \nstructure types that can be referenced within s. Procedures take a single argument with a word-sized \ntype, and they return a single value with a word-sized type. We annotate procedures with preconditions \nand postcondi\u00adtions that use expressions drawn from the same language; postcon\u00additions can refer to the \nreturn value via a special variable, r. For the time being, we omit several other C features, such as \nscalar types of various sizes (e.g., char, short), union types, function pointers, and memory deallocation. \nWe will revisit these features in Section 5. We disallow taking the address of local variables; in practice, \nour front-end replaces any local variables whose address is taken with an equivalent heap-allocated object. \n(More accurate modeling of the stack frame is possible, but we would lose some precision and ef.ciency \nin our property checker.) We do not mention global variables, but they are a trivial addition to our \ntranslation. Our output language, BPL, is shown in Figure 4. This language has four built-in sorts, the \nmost important of which are int and type. We also include product sorts and function sorts, which are \nused to give types to maps and predicates such as Mem and HasType. Constructors and destructors for these \nsorts are omitted where unnecessary for this paper. Expressions in BPL are of sort int or type, and include \nvariable reference, map lookup (M[ e]), integer constants (n), type construc\u00adtors (C), and binary operations \non integers. Maps (M) include Mem and Type. Type constructors (C) typically include nullary type con\u00adstants \nsuch as Int as well as the unary type constructor Ptr. Formulas are of sort bool and contain relational \noperators on in\u00adtegers, predicate symbols (P), negation, conjunction, and universal quanti.cation. Predicate \nsymbols P typically include HasType and Match, which are used to de.ne our notion of type safety. This \nlan\u00adguage allows relatively unrestricted use of quanti.ers, but in prac\u00adtice, our translation will be \nlimited to a subset of these uses. 1 L-expressions are expressions that evaluate to locations and can \ntherefore appear on the left-hand side of an assignment. T (int) T (t *) T (t) L(*e) L(l.f) E(x) E(n) \nE(l) E(&#38;l) E(e1 op e2) E(e1 .n e2) E((t ) e) C(G, skip) C(G,c1; c2) C(G,x := new s) C(G,x := f \n(e)) C(G,x := e) C(G,l := e) C(G, if e then c) C(G, while e do c) C(G, let x : t in c) C(G, return e) \n.. pre e1 post e2 P .f(x : tx): tf .= c = Int = Ptr(T (t )) = T = E(e) = L(l)+ Offset(f) = x = n = \nMem[L(l)] = L(l) = E(e1) op E(e2) = E(e1)+ n * E(e2) = E(e) = skip = C(G,c1); C(G,c2) = havoc x; assume \nHasType(x, Ptr(T (s))) = x := call f(E(e)); assert HasType(x, T (tf )) = x := E(e); assert HasType(x, \nT (G(x))) = Mem[L(l)] := E(e); assert .a:int.HasType(Mem[a],Type[a]) = if E(e) then C(G,c) = while E(e) \ndo C(G,c) = let x : int in C(G[x . t],c) = return E(e) pre (E(e1) . HasType(x, T (tx)). .a : int.HasType(Mem[a], \nType[a])) = post (E(e2) . HasType(r, T (tf )). .a : int.HasType(Mem[a], Type[a])) fun f(x : int): int \n= C(\u00d8[x . tx],c) Figure 5. Translation from C to BPL. Commands contain assignment and control .ow, plus \nassume b, assert b, and havoc x, the latter of which scrambles the value of x. The most important differences \nbetween C and BPL are: 1. BPL has no notion of heap allocation. Thus, we model the C heap as a map Mem \nfrom integer addresses to integer values, and we use select-update reasoning to model reads and writes \nto the heap. 2. BPL has no notion of pointer types or structure types. Instead, BPL provides the sorts \nint and type, which we use to represent the original program s values and types, respectively. That is, \nall word-sized values in the original program map to values of sort int, and all C types in the original \nprogram map to values of sort type.  Figure 5 shows our translation from C to BPL. We assume that the \ninput program is well-typed in the original C type system. The translation involves .ve functions, one \nfor each syntactic category. The .rst function, T , maps C types to BPL expressions of sort type. Note \nthat each named type t in the C program is mapped to a distinct constant T in the BPL program. L and \nE map l-expressions and expressions to BPL expressions of sort int. L yields integers that stand for \nheap locations, so E translates the expression l as a memory reference and &#38;l as the lo\u00adcation itself. \nNote that C s binary operations map to a BPL operator in op = binop . relop. Field references and pointer \narithmetic are De.nitions for Int Match(a, Int) Type[a]= Int (A) HasType(v, Int) true (B) De.nitions \nfor Ptr(t) Match(a, Ptr(t)) Type[a]= Ptr(t)(C) HasType(v, Ptr(t)) v =0 . (v> 0 . Match(v, t)) (D) De.nitions \nfor type t = {f1 : s1; ... ; fn : sn} p Match(a, T) i Match(a + Offset(fi),T (si)) (E) Figure 6. De.nition \nof HasType and Match for a, v of sort int and t of sort type. compiled down to integer arithmetic; casts \nare compiled away en\u00adtirely. Offset(f) is a compile-time function giving the offset of .eld f in its \nstructure; we assume .eld names are unique. C and P map commands and procedures in C to their respec\u00adtive \nconstructs in BPL. C takes an additional argument, G, that maps C variables to C types. Also, we assume \nthat tf is the de\u00adclared return type of function f, that the variable r in a postcondi\u00adtion refers to \nthe function s return value, and that procedure calls scramble all of Mem. Ignoring the assumptions and \nassertions in gray boxes, which will be discussed in the next section, this transla\u00adtion is a straightforward \nmodeling of C s operational semantics. For simplicity, allocation is modeled conservatively by scrambling \nthe value in x; however, our implementation models allocation more precisely, as discussed in Section \n5.5. After this translation, we can compute a veri.cation condition from the BPL program using standard \ntechniques [11, 20]. Then we can pass it to our SMT solver, which indicates whether the program fails \nany of the assertions. 3.2 Modeling Type Safety We now discuss our approach to enforcing type safety, \nwhich in\u00advolves the assumptions and assertions shown in gray boxes in Fig\u00adure 5. First, however, we must \ndiscuss our representation of the heap and of C types in BPL. We assume the presence in BPL of the following \ntwo maps: Mem : int . int Type : int . type As described earlier, Mem[a] represents the value in the \nheap at address a, and Type[a] represents the type at which address a was allocated. Although Mem is \nmutable, Type is .xed at allocation time and cannot later be changed. C types are modeled in BPL as inductive \ndata types with sort type. We have a nullary constructor Int for integer types as well as a unary constructor \nPtr(t) for pointer types. We also introduce nullary constructors T for every user-de.ned type name t. \nNow, we must assign a meaning to these types, and we do so by introducing two new predicates: Match :(int \n\u00d7 type) . bool HasType :(int \u00d7 type) . bool As described earlier, the Match predicate lifts Type to \ntypes that span multiple addresses. Formally, for address a and type t, Match(a, t) holds if and only \nif the Type map starting at address a matches the type t. The HasType predicate gives the meaning of \na type. For a word-sized value v and a word-sized type t, HasType(v, t) holds if and only if the value \nv has type t. The de.nitions of Match and HasType are given in Figure 6. For Match, the de.nitions are \nstraightforward: if a given type is a word-sized type, we check Type at the appropriate address, and \nfor structure types, we apply Match inductively to each .eld. For HasType, we only need de.nitions for \nword-sized types. For integers, we allow all values to be of integer type, and for pointers, we allow \neither zero (the null pointer) or a positive address such that the allocation state (as given by Match) \nmatches the pointer s base type. HasType is the core of our technique, since it explicitly de.nes the \ncorrespondence between values and types. Now that we have de.ned HasType, we can state our type safety \ninvariant for the heap: .a : int.HasType(Mem[a], Type[a]) In other words, for all addresses a in the \nheap, the value at Mem[a] must correspond to the type at Type[a] according to the HasType axioms. We \ncan also extend this type safety invariant to local variables by saying that for all locals x with compile-time \ntype tx, HasType(x, T (tx)) must hold, where T is our translation from C types to BPL terms. Our translation \nenforces this invariant at all program points via the gray boxes shown in Figure 5. P adds the type safety \ninvariant to the preconditions and postconditions of each procedure. C asserts the type safety invariant \nafter every update to a local variable or a heap location, and it assumes the type safety invariant for \nany newly allocated heap location. There are several interesting things to note about this trans\u00adlation. \nFirst, the Type map s contents are never given explicitly; rather, the assumptions regarding HasType \nwill indirectly restrict the contents of Type. Second, the translation does not capture the fact that \ndynamic allocation yields a new, unaliased object; how\u00adever, this fact is typically not required to prove \ntype safety, and it can be speci.ed separately if it is deemed necessary to prove other facts about the \nprogram. Third, this translation effectively encodes the standard type preservation invariant as assertions \nto be checked on a per-program basis by a property checker. Progress is ensured by the original C type \nchecker, which is invoked prior to translation.  3.3 Field Sensitivity In addition to proving type safety \nfor our input program, we would also like to check properties that are speci.ed by the user as pre\u00adconditions \nand postconditions for each function. Property checking in the presence of heap-allocated structures \noften requires us to be able to distinguish between two .elds of a structure; for example, in Figure \n1, we would like to be able to show that writing to data2 does not affect the values in the next, prev, \nand data1 .elds of other records in the program s heap. As described in Section 2, our approach to this \nproblem is to introduce a new type constant for every word-sized structure .eld in the program. In effect, \nwe re.ne the types stored in Type so that it captures information about speci.c structure .elds in addition \nto the types of those .elds. For example, we introduce constants Data1 and Data2, and we use these constants \nin Type to correspond to the data1 and data2 .elds. The de.nition of HasType for these .elds is the same \nas that of the underlying type, Int, which means that the type safety invariant provides the same amount \nof information about the values stored in these .elds as it did before. However, because the Type map \nnow differs for these two .elds, our property checker knows that the data1 and data2 .elds of two different \nstructures cannot overlap in memory. We can perform the same re.nement on next and prev as well. Even \nthough we have only changed the translation of word\u00adsized .elds, the bene.ts extend to most structure \ntypes as well. For example, the record structure must contain data1 and data2 at known offsets, which \nmeans that no other structure can overlap with record at these locations. In fact, if we wanted to ensure \nthat a structure type was never overlapped by another structure type, we could .atten it into word-sized \n.elds at compile time, which means that each word of the structure would get a unique tag in Type. Using \nthis .eld-sensitive translation involves a trade-off be\u00adtween precision and .exibility. On the one hand, \n.eld sensitivity provides a stronger invariant to the theorem prover, which can of\u00adten be useful in distinguishing \none heap location from another. On the other hand, .eld sensitivity restricts the ways in which two C \nstructures can overlap in the heap. This trade-off corresponds to the trade-off between nominal and structural \ntype systems. In the .eld-sensitive translation, equiva\u00adlence between structure types is determined by \nthe name of that structure (or, more precisely, by the names of its .elds). In the original .eld-insensitive \ntranslation, equivalence is determined by structure that is, by the types of the .elds alone. Our translation \ndoes not require the user to choose nominal (.eld-sensitive) or structural (.eld-insensitive) behavior \nfor the en\u00adtire program. Rather, the programmer is free to choose a .eld\u00adsensitive or .eld-insensitive \ntranslation on a .eld-by-.eld basis. This .exibility is useful when checking C programs, since many C \nprograms use a combination of these two approaches. For ex\u00adample, structural subtyping is useful for \ncases where programmers overlay two structures that are known to have similar layouts, such as two distinct \nstructure types that share a common header. Also, structural subtyping is useful when programmers take \nthe address of a .eld of a structure, since we want the type of the resulting pointer to be independent \nof the enclosing structure. However, in most other cases, programmers treat two structure types that \nhap\u00adpen to have the same layout as distinct types, which corresponds to nominal subtyping. Because nominal \nsubtyping is the most com\u00admon case, we treat it as the default, and we allow programmers to manually \nspecify .elds or structures that should be handled using the .eld-insensitive translation. 4. Decision \nProcedure After translating C to BPL, we must check each of the assertions in the resulting code by generating \na veri.cation condition and then passing that veri.cation condition to a Satis.ability Modulo Theories \n(SMT) solver such as Z3 [19]. Looking at the translation, we can see that each problem posed to the SMT \nsolver will have a particular form: given the type safety invariant and the de.nitions of Match and HasType, \nall of which are universally quanti.ed, decide whether a given HasType predicate holds. Unfortunately, \nuniversally quanti.ed assumptions can cause such a problem to be undecidable, because it is dif.cult \nto know how and when to instantiate those assumptions correctly. In this section, we address this challenge \nby providing a deci\u00adsion procedure for the type safety assertions generated by our trans\u00adlation. We begin \nby describing the decision problem formally, and then we provide an algorithm for reducing this problem \nto an equiv\u00adalent quanti.er-free problem. Finally, we prove the correctness of this algorithm. Our decision \nprocedure only applies to type safety assertions generated by our translation; any user-provided asser\u00adtions \nabout other properties of the code will be checked separately, but with the use of any available facts \nconcerning Mem and Type. 4.1 Decision Problem The veri.cation conditions resulting from our translation \nfall within the logic shown in Figure 7. This logic is the quanti.er-free combi\u00adnation of three theories \nuninterpreted functions, arithmetic, and inductive data types with disjoint sets of symbols. Updates \nto Mem have already been compiled away by introducing case-splits to model the select-update reasoning \nfor arrays. Our goal is to de\u00adcide the satis.ability of a formula in this logic given the type safety \ninvariant and the background axioms from Figure 6. b . BoolConst = {false, true}c . I ntConst = {..., \n-1, 0, 1,...}t . I T ypeConst = {Int, List, Record,...}d . T ypeConst . I T ypeConst w . BoolV ar x . \nI ntV ar y . T ypeV ar . ::= b | w | p<p | p = p | Match(p, q) | HasType(p, q) | \u00ac. | . . . p ::= c | \nx | p + p | p - p | Mem[p] q ::= d | y | Ptr(q) | Type[p] Figure 7. Grammar for veri.cation conditions \ngenerated by our translation. Our logic contains three sorts: bool, int, and type. Terms of these sorts \nare generated by the non-terminals ., p, and q, re\u00adspectively. BoolConst, the set of constants of sort \nbool, and I ntConst, the set of constants of sort int, are de.ned in the usual way. I T ypeConst is the \nset of (interpreted) type constants that occur in the program and which are referred to in the de.nitions \nof the predicates Match and HasType in Figure 6. For example, I T ypeConst = {Int, List, Record} for \nour running example from Figure 2. T ypeConst is the set of all type constants of sort type and is a \ncountably in.nite set that contains I T ypeConst. A formula in our logic is evaluated in a model that \nprovides a domain for each sort (bool, int, and type). The domains for the sorts bool and int are standard. \nThe domain for the sort type is the unique in.nite set whose elements are in one-to-one cor\u00adrespondence \nwith the least set of terms containing all type con\u00adstants in T ypeConst and closed under the application \nof Ptr. In this interpretation, each type constant in T ypeConst is interpreted as a distinct type value \nand Ptr is interpreted as a one-one map from type into type whose range is disjoint from the interpreta\u00adtions \nof the type constants in T ypeConst. Let PtrT ypeV als = type\\TypeConst be the set of all type values \nthat are in the range of Ptr. Let U T ypeConst = TypeConst \\ I T ypeConst be the set of (uninterpreted) \ntype constants that do not occur in the pro\u00adgram. Then, the disjoint union I T ypeConst l U T ypeConst \nl PtrT ypeV als equals type. In addition, a model also provides an interpretation for con\u00adstants, variables, \nand functions. The interpretation of the arithmetic and Boolean terms is standard. Functions Mem and \nType are in\u00adterpreted as arbitrary maps from int to int and int to type, respec\u00adtively. Predicates Match \nand HasType are interpreted as maps from int \u00d7 type to bool. Given a model M, we denote the interpretation \nof a symbol s in the signature of our logic as M(s). For simplic\u00adity, we often use s rather than M(s) \nfor those symbols, such as +, whose interpretation does not vary from one model to another. A model M \nis well-typed if it satis.es the following conditions: 1. M(Match) and M(HasType) are consistent with \nthe de.ni\u00adtions of Match and HasType in Figure 6. 2. For all a . int, the evaluation of HasType(Mem[a], \nType[a]) in M returns true.  A model M satis.es a formula . if . evaluates to true in M. Each of the \ntheories represented in our logic (uninterpreted functions, arithmetic, and inductive data types) is \nstably in.nite2 2 A theory is stably in.nite if any satis.able formula in the theory has a countably \nin.nite model. and individually decidable. Hence, their combination is also decid\u00adable using the Nelson-Oppen \nmethod [33] of theory combination. Satis.ability Modulo Theories (SMT) solvers such as Z3 [19] can be \nused to ef.ciently check whether there exists a model of .. How\u00adever, deciding the existence of an arbitrary \nmodel of . does not suf.ce; instead we need to determine whether there exists a well\u00adtyped model of .. \nConjoining the type-invariant and the de.nitions of Match and HasType to . as universally-quanti.ed axioms \nis unlikely to work well because the performance of SMT solvers on formulas with quanti.ers is unpredictable \nand typically bad. To get good performance, we have designed a new decision procedure that conjoins a \nsmall number of instantiations of the universally\u00adquanti.ed facts to . to get a quanti.er-free formula \n. with the following property: There is a well-typed model satisfying . iff there is a model satisfying \n.. Thus, it suf.ces to feed . to an SMT solver. We now show how to construct . from . by instantiating \nthe universally-quanti.ed axioms on a suf.cient set of terms. 4.2 Quanti.er Instantiation Let P (.) \ndenote the set containing the constant 0 and every term p in . such that for some term q either HasType(p, \nq) or Match(p, q) is present in .. Let Q(.) denote the set containing I T ypeConst ' and every term \nof the form Ptr(q) in .. We will use the terms in P (.) and Q(.) to instantiate the de.nitions A, B, \nC, D, E from Figure 6. First, we preprocess each de.nition E so that every use of Match on the right \nside of the de.nition is expanded out by the application of other such de.nitions. Note that this expansion \nwill terminate because the de.nition of Match follows the hierarchi\u00adcal structure of types in a C program \nand is consequently non\u00adrecursive. After each de.nition of Match has been expanded out, we proceed to \nconjoin the following formulas with .: 1. HasType(Mem[p], Type[p]) for each term Mem[p] in .. 2. Instantiations \nof de.nitions A, B, and E on each term in P (.). 3. Instantiations of de.nitions C and D for each term \np and q such that p . P (.) and Ptr(q) . Q(.).  Let the resulting formula be .. Since the size of P \n(.) and Q(.) is bounded by |.|, we generate at most |.|2 conjuncts, each of constant size. Therefore \n|.|. O(|.|2). If the solver concludes that . is unsatis.able, then . does not have a well-typed model \nbecause we only added facts related to the characterization of well-typed models to . to get .. We now \nargue that if the solver concludes that . is satis.able, then . has a well-typed model. The following \nproperty of . is crucial for the correctness of this claim: LEMMA 1. If either Match(p, q) or HasType(p, \nq) is aterm in ., then p . P (.). 4.3 Model Construction A satisfying assignment of . is a map W from \nterms in . to a value of the appropriate sort (bool, int, or type) such that evaluating . ac\u00adcording \nto W returns true. A satisfying assignment W of . is min\u00adimal if for all terms q of sort type in ., either \nW(q) . TypeConst '' or W(q)= W(Ptr(q)) for some term Ptr(q) in .. We assume that if the SMT solver returns \nsatis.able, it provides a minimal sat\u00adisfying assignment W for .. This assumption essentially requires \nthe solver to not create any fresh Ptr terms while creating a model for ., which is reasonable because \ntypical SMT solvers only create fresh constants during model generation. We will extend W to a well-typed \nmodel M satisfying .. Consider the set of integers a . int such that W does not pro\u00advide an assignment \nto Type[a]. There exists a one-to-one map from this set into U T ypeConst because U T ypeConst is countably \nin\u00ad.nite. We use this map to complete the assignment of Type in M. The interpretation of Match depends \nonly on the interpre\u00adtation of Type. For all integers a and for all type values t . I T ypeConst . PtrT \nypeV als, we evaluate Match(a, t), start\u00ading from t . P trT ypeV als and then for the t . I T ypeConst \nin a bottom up fashion. To complete the assignment for Match, for all integers a and for all type values \nt . U T ypeConst, we assign true to Match(a, t) everywhere it is not de.ned by W. The de.nition of HasType \ndepends only on the de.nition of Match. For all integers v and for all type values t .{Int}. PtrT ypeV \nals, we evaluate HasType(v, t) bottom up, as with the evaluation of Match. To complete the assignment \nfor HasType, for all integers v and for all type values t . T ypeConst \\{Int}, we assign true to HasType(a, \nt) everywhere it is not de.ned by W. Our method of extending HasType yields the following lemma: LEMMA \n2. For each t . type, there exists v . int such that HasType(v, t) is assigned true. This property will \nhelp us complete the assignment for Mem. If Mem is not de.ned for some a . int, extend the assignment \nof Mem at a to some integer v such that HasType(v, Type[a]) is assigned true. LEMMA 3. M is a model satisfying \n. and hence satis.es .. PROOF. To prove this lemma, it suf.ces to show that the assign\u00adments to Match \nand HasType in M are consistent with the as\u00adsignments in W. The assignments to Type and Mem in M simply \nextend W by our de.nition of M. Here we present the proof for Match only, omitting the proof for HasType, \nwhich is similar. We prove by contradiction that the assignment to Match(a, t) obtained under M is consistent \nwith W. If not, then there ex\u00adists a term Match(p, q) in . such that W(p)= a, W(q)= t, and W(Match(p, \nq)) is inconsistent with the evaluation of M(Match(a, t)). Since W is a minimal satisfying assignment, \neither W(q) . T ypeConst or W(q)= W(Ptr(q ' )) for some term Ptr(q ' ) in .. Since M extends W for any \nt . U T ypeConst (by de.nition), we can strengthen the .rst case to W(q) . I T ypeConst. In either case, \nwe get q . Q(.). Since Match(p, q) is present in ., we also get p . P (.). Therefore . contains an in\u00adstantiation \nfor the de.nition of Match(p, q). Because Match(p, q) is de.ned in . and W satis.es ., M(Match(a, t)) \nmust be con\u00adsistent with W(Match(p, q)), which is a contradiction; thus M satis.es .. Since . is a conjunct \nin ., M satis.es . too. D M is also well-typed, which yields our main theorem: THEOREM 1. M is a well-typed \nmodel satisfying .. The complexity of checking the satis.ability of . is NP\u00adcomplete [33]. Since the \ntranslation from . to . results in at most a quadratic blowup, the complexity of checking whether . has \na well-typed model is also NP-complete. 5. Extensions In this section, we discuss a number of extensions \nto our translation that address additional features of the C language or additional requirements for \nverifying type safety in existing C code. Except where noted, these extensions were implemented and used \nin the case studies described in Section 6. 5.1 Unions C s union types allow .elds of several unrelated \ntypes to be stored at the same location in memory, with only one such .eld in use at a given time. Unfortunately, \nC does not provide any mechanism for keeping track of which .eld is currently in use, which means that \nthe programmer could easily violate type safety by storing a value in one .eld and retrieving it from \nanother .eld of a different type. The use of unions varies widely from program to program. In some cases, \neach instance of a given union type uses only one .eld for the entire lifetime of the union; that is, \nthe dynamic type of the union is .xed at allocation time. In other cases, a given instance of a union \ntype uses many .elds over its lifetime, and the dynamic type of that union cannot be .xed at allocation \ntime. Because the use of unions varies so widely, our approach is to leave unions completely unde.ned \nduring translation. That is, our translation says nothing about the meaning of HasType or the value of \nType for a union type. If the programmer wishes to use unions safely, they must introduce additional \nassertions that state the appropriate invariants explicitly. For example, consider the following C code: \nunion foo { int n; int *p; } int getnum(foo *f, tag t) { return (t == 1) ? f->n : *f->p; }  In this \nexample, we have a union containing two types, int and int*, which means that the foo* argument is either \nan int* or an int**. Our translation does not indicate which .eld is selected, so the user must specify \na precondition on this function, such as: pre((t == 1) ==> hastype(f, int*)) &#38;&#38; (t != 1) ==> \nhastype(f, int**)))  Here, we have extended C s syntax with an implication operator (==>) and a predicate \nhastype that will be translated into HasType in the input to the theorem prover. This precondition provides \nenough information to verify that the body of getnum is well-typed. 5.2 Function Pointers The translation \ndescribed in Section 3 only allows calls to known functions; however, most C programs use function pointers \nto in\u00advoke functions indirectly. Many property checking tools model function pointers by associating \neach function in the program with a distinct integer value, and then they model function pointer invo\u00adcation \nas a case split on the integer representing the function pointer or as nondeterministic choice. However, \nwhen checking large C programs, it is often dif.cult, if not impossible, to know at compile time all \nfunctions that might be invoked at a given call site. Instead, we address this problem by adding a function \ntype to our language. Our approach is similar to the one used by R\u00b4 egis-Gianas and Pottier in the context \nof functional languages [34]. We extend our input language with a function type and an indirect function \ncall: t ::= ... | t1e1 . t2e2 c ::= ... | x := y(e) The function type t1e1 . t2e2 represents a function \nfrom type t1 to type t2 that has precondition e1 and postcondition e2. Naturally, the precondition e1 \ncan refer to the argument x, and the postcondition e2 can refer to the argument x and the return value \nr. Note that by allowing the programmer to refer to expressions in function types, we have introduced \na form of dependent type. In the indirect call, we invoke a function stored in the variable y. We extend \nBPL with a new data type constructor: Func :(type \u00d7 int \u00d7 type \u00d7 int) . type We also extend the translation \nas follows: T (t1e1 . t2e2)= Func(T (t1),f(E(e1)),T (t2),f(E(e2))) C(G,x := y(e)) = x := call stubt (E(e)) \nwhere y has type t The .rst part of this translation maps an annotated C function type to its BPL representation. \nThe f function is a one-to-one func\u00adtion from BPL expressions to integers, which is created by assign\u00ading \na unique integer to every expression in the program text; this function allows us to encode the precondition \nand postcondition of a BPL function as integer arguments to Func. The second part of the translation \nimplements a call to y by call\u00ading the stub corresponding to y. If the type of y is t = t1epre . t2epost, \nthen stubt is declared as follows: pre E(epre) . HasType(x, t1) post E(epost) . HasType(r, t2) fun stubt \n(x : int): int This stub summarizes the entire class of functions represented by the function type t1epre \n. t2epost. Thus, by calling this stub, we will check the preconditions given the argument e2, and we \nwill assume the postcondition on the caller s return variable x. Note that we do not need to perform \nany checking on stubt itself; it exists solely to represent function pointer invocations. A subtle but \nimportant point is that the translation of function pointer invocations depends upon the types assigned \nby the orig\u00adinal (unsound) C type system. However, because we enforce the declared type of y in our translation, \nwe can use it to translate this function call. The .nal piece of the translation is the HasType and Match \naxioms for the Func constructor. In order to de.ne HasType, we associate a unique integer with every \nfunction in the program. For a given function type Func(...), we de.ne HasType as the set of integers \ncorresponding to all functions of that type. This set necessarily includes all such functions that are \nvisible in the current compilation unit; however, it is not limited to those functions, since we may \nbe calling a function of that type in a different compilation unit. For Match, we provide a de.nition \nthat corresponds directly to the de.nitions for other word-sized types, since the function type is itself \na word-sized type. So, by associating preconditions and postconditions with C function types, and by \nusing these preconditions and postconditions in the translation of C function calls, we can correctly \ntranslate and type-check C programs that use function pointers, even without knowing all possible values \nfor every function pointer.  5.3 Parametric Polymorphism Many existing C programs can be more effectively \ntype-checked if the programmer is allowed to indicate code that uses parametric polymorphism. Consider \nthe following example program: typedef void *arg_t; // Type variable! typedef void (*fn_t)(arg_t a); \nvoid create_thread(fn_t f, arg_t a); void thread1(int n) { ... } void thread2(foo *p) { ... } foo *p \n= ...; create_thread(thread1, 42); // arg_t = int create_thread(thread2, p); // arg_t = foo* In this \nexample, we declare a function called create thread that takes two arguments: a pointer to a function \nthat should be ex\u00adecuted on the new thread, and an argument to pass to that function. We then de.ne two \nadditional functions, thread1 and thread2, which represent the main functions for two different threads. \nFi\u00adnally, we invoke create thread on each of these functions with different arguments; one takes an int \nand the other takes a foo*. Although the type of arg t is given as void* in this example, this type is \nactually being treated as a type variable. That is, for a particular call to create thread, the programmer \ncan consider arg t to be any word-sized type, as long as the thread function and its argument have consistent \ntypes. This code is an example of how C programmers frequently use concepts from higher-level type systems \neven in lower-level code. In our translation, we can provide polymorphism by explicitly passing the \ntype for any type variables involved in the function call. For example, the above code would be translated \ninto: pre HasType(f, Func(t, . . .)) pre HasType(a, t) fun create thread(t : type,f : int,a : int)= ... \nassume HasType(thread1, Func(Int,...)) assume HasType(thread2, Func(Ptr(Foo),...)) assume HasType(p, \nPtr(Foo)) call create thread(Int, thread1, 42) call create thread(Ptr(Foo), thread2,p) Note that both \ncalls to create thread satisfy the two precondi\u00adtions on the types. In the .rst call, we pass a function \nthread1 that has a type whose .rst argument is Int, and we pass 42, which can be determined to have type \nInt according to the HasType axioms. The second call satis.es the preconditions for a similar reason. \nIn practice, our translator allows the programmer to identify types that should be treated as type variables. \nWhen these types appear in the arguments or return types of a function being invoked, we compare the \nformal types to the actual types to determine an appropriate substitution, and then we pass the substituted \ntypes as arguments to the translated function. Similarly, when translating a function with arguments \nof polymorphic type, we add a suitable number of formal type parameters to the translated function. As \nwith function pointers, we have found this feature to be quite useful in establishing type safety for \nexisting C code due to exam\u00adples like the one above. This example is particularly noteworthy be\u00adcause \nour type invariant allows us to state an important fact about the arguments to create thread (i.e., that \nf will only be called with a as an argument) that would be dif.cult to state succinctly in a more traditional \nproperty checking tool. Our decision procedure can be extended to handle polymorphic types by treating \nthe type variable t as a new, opaque type constant. 5.4 User-De.ned Types and Dependent Types In addition \nto the above extensions, we also allow the programmer to introduce new type constants with user-provided \nHasType de.\u00adnitions. For example, a programmer could use this feature to de.ne a non-null type. Although \nthis invariant could also be expressed by writing preconditions and postconditions on functions, it is \nof\u00adten convenient to be able to add such global invariants to the type safety invariant, which is implicitly \nenforced at each program point. When providing user-de.ned types, it is often convenient to have HasType \ndepend upon Mem in addition to Type. Types that are de.ned in this manner can be considered a form of \ndependent type, since their meaning depends upon values stored in the heap. For example, consider the \nfollowing structure: struct string { char *buf; int len; } This structure represents a string, where \nlen is the number of characters appearing in char. However, our default type de.nition does not express \nthis invariant: HasType(v, Ptr(String)) v =0 . (v> 0 . Match(v, String)) However, if HasType can depend \non Mem, we can write a much stronger de.nition: HasType(v, Ptr(String), Mem) v =0 . (v> 0 . Match(v, \nString). .i : int.0 = i< Mem[v +1] =. HasType(Mem[v]+ i, Ptr(Char), Mem)) This new de.nition is more \npowerful than the previous one, but it comes with several costs. First, we must rely on the programmer \nto create type de.nitions that preserve the completeness guaran\u00adtees discussed in Section 4. Second, \nthese types place an additional burden on the theorem prover, which can impact performance. Fi\u00adnally, \nthese complex types impose an additional annotation burden elsewhere in the program. For example, our \ntranslation of function calls conservatively assumes that any memory location may have been changed during \nthe call, which makes it dif.cult to preserve memory-based type invariants on local variables across \nsuch calls; for this reason, we typically assume (unsafely) that memory is un\u00adchanged across function \ncalls when using user-de.ned types.  5.5 Allocation and Sub-Word Access Currently, our translation models \nmemory allocation by scrambling the target variable and assuming the appropriate type. We can im\u00adprove \nprecision by introducing two additional maps: Alloc, which keeps track of whether each word of memory \nhas been allocated or deallocated, and Base, which maps each allocated word to the base address for that \nallocation. These maps provide additional preci\u00adsion for our property checker, and they also allow us \nto express and check temporal type and memory safety properties, such as the lack of dangling pointers. \nAnother imprecision is our assumption that each word in mem\u00adory is of size 1. To model a 32-bit machine, \nwe can set the word size to 4 and allow Mem to map byte addresses to values. We maintain an additional \nmap, Span, to keep track of how many byte addresses a given value spans. For example, when writing word\u00adsized \nvalues to address a, we will assert that Span(a)=4 and that Span(a +1) = Span(a +2) = Span(a +3) = 0. \nOur current prototype implements Alloc and Base, but it does not implement Span, and we do not check \nfor dangling pointer er\u00adrors. These features are explained in more detail in an accompany\u00ading technical \nreport [2] and will be explored further in future work. 6. Evaluation Here we present several case studies \nthat demonstrate the effective\u00adness of our technique on real code, including property examples and experiments \nwith type checking in Windows device drivers. We implemented the combined type and property checking \ntool described in this paper inside HAVOC [2], a property checker for C code that plugs into Microsoft \ns Visual C compiler. After HAVOC translates C code to BPL, we use Boogie [9] to generate a veri.\u00adcation \ncondition, which we check using the Z3 SMT solver [19]. HAVOC previously supported reasoning about linked \nlists [26] and arrays using SMT solvers. 6.1 Property Checking To evaluate the usefulness of adding \ntypes to a property checker, we have applied our tool to a set of small to medium-sized C bench\u00admarks \nin the HAVOC regression suite [26]. These examples range between 10 and 100 lines of code, and they include \nvarious low\u00adlevel list algorithms (e.g., adding or removing elements from a dou\u00adbly linked list, reversing \nor sorting a list) and various array sort\u00ading algorithms (e.g., insertion sort, bubble sort). The list \nroutines use the list structure from Figure 1. For each of these examples, we proved partial correctness \nproperties (e.g., bubble sort yields a sorted array, reversing a list preserves the list), in addition \nto the type safety assertions. Execution times ranged from a few seconds on the smaller examples to around \n8 minutes on the largest exam\u00adple. In the absence of types, earlier veri.cation of these examples included \nad-hoc annotations to obtain disambiguation. We use one of the examples list appl to illustrate the bene.ts \nof using types in the annotations. The example (about 100 lines) contains two circular doubly-linked \nlists hanging off a parent ob\u00adject; each node in the two lists has a pointer to the parent. The objects \nin the two lists have distinct C types and have different data structure invariants. The example performs \nvarious operations such as initializing the lists, inserting into and deleting from the lists, and updating \nthe data values in the lists. The data structures in the example are fairly representative of low-level \nsystems code. The main challenge in this example is to preserve the global invariants of the lists despite \nupdates to the heap. To do so, we must ensure that the set of addresses in the two lists are disjoint, \nand we must have .eld-based disambiguation in order to show that certain .elds are not updated. Previously, \nstating these invariants required us to construct a set for the addresses of each of the .elds in the \ntwo lists and specify pairwise disjointness of these sets. These speci.cations were very cumbersome and \nrequired a quadratic number of annotations in the number of .elds. In contrast, our .eld-sensitive type \nsafety assertion ensures that the .elds of two different types do not alias. To state that the two lists \nare disjoint, we simply state an invariant for each list describing the type of the object in which the \nlist is embedded. The speci.cations are local to each list and hence grow linearly in the number of lists. \nThe conciseness of speci.cation is crucial for verifying larger systems programs where multiple lists \ncan be associated with parent objects that have a few hundred .elds. We are currently working on using \ntype safety assertions to improve the soundness of property checking for real-world code. Among these, \nwe are working towards justifying the .eld disam\u00adbiguation that was assumed when HAVOC checked complex \nsyn\u00adchronization protocols in a 300 KLOC Windows component [7]. 6.2 Type Checking We applied our tool \nto several Windows device drivers for the pur\u00adpose of verifying type safety. These device drivers (cancel, \nevent, kbfiltr, and vserial) are publicly-available sample drivers in\u00adcluded with the Windows Driver \nKit (WDK) 1.7 [28] that demon\u00adstrate several common idioms in Windows device drivers. The process of \nannotating a driver is iterative, much like the traditional edit-compile-debug cycle. We ran our tool \non the un\u00admodi.ed driver, and we added annotations, introduced new types, or otherwise modi.ed the code \nin order to resolve the reported type errors. We also modi.ed the WDK header .les where appropriate, \nand we had HAVOC automatically add non-null assumptions for all pointers. Each conversion took approximately \n1-2 hours. When Boogie fails to prove an assertion in the translated code, it indicates to HAVOC which \nassertion caused the failure, and since HAVOC knows why each assertion was introduced, it can produce \nan appropriate error message and line number in terms of the original code. These error messages are \nhelpful in isolating the cause of type errors, though frequently some knowledge about the type safety \ninvariant is required to determine an appropriate .x. 6.2.1 Advantages and Limitations In this section, \nwe discuss several cases encountered in these drivers where HAVOC was capable of checking code that previous \ntools for type-checking legacy C code [17, 31] would have been unable to verify without program-speci.c \ncustomizations. These examples demonstrate the ability of our technique to capture im\u00adportant program-speci.c \ninvariants in a general-purpose tool. We also discuss some limitations of our technique. Our .rst example \nis the LIST ENTRY structure, which is em\u00adbedded in other structures to form a linked list as demonstrated \nin Figure 1. This idiom appears commonly in Windows code, includ\u00ading two of the four drivers tested, \nand it can be successfully handled using the approach demonstrated in Section 2. A second example is \nthe dispatch mechanism used by the kernel to invoke drivers. A simpli.ed version of the code is as follows: \nvoid MyRead(Driver *driver) { MyContext *ctx = (MyContext*) driver->ctx; ... } void MyWrite(Driver *driver) \n{ MyContext *ctx = (MyContext*) driver->ctx; ... } void MyInit(Driver *driver) { MyContext *ctx = ...; \ndriver->ctx = (void*) ctx; driver->read = MyRead; driver->write = MyWrite; } In this example, our driver \nde.nes two dispatch routines, MyRead and MyWrite, and an initialization function, MyInit. Each routine \nis called with a kernel object of type Driver* representing the driver. This kernel object contains a \nctx .eld of type void* that is used by each driver to store the driver s private data. In the MyRead \nand MyWrite functions, the driver casts this pointer to a MyContext* in order to access its private data. \nWe would like to prove this cast safe, but we cannot simply add a precondition to MyRead and MyWrite \nsaying that the type of the ctx .eld is MyContext*, since the caller (i.e., the kernel) does not know \nabout the internals of each driver and could not prove this precondition. In fact, the real precondition \nfor MyRead is driver->read == self, where self is a special keyword representing the current function \n(i.e., MyRead). In other words, the invariant is that the kernel will only call the driver->read function \nwith driver itself as an argument, which is a common invariant in low-level type systems for object-oriented \ncode. Since we can prove that driver->read == MyRead, we can use the read .eld as a tag indicating the \nrun-time type of ctx; that is, we add a global invariant that says that a driver whose read .eld is MyRead \nmust also have a ctx of type MyContext*. A .nal example where we made use of this technique is in the \nvserial driver. Several complicated routines that read and write buffers of data required preconditions \nand loop invariants in order to prove that all array references were in bounds. Because we can express \nthe necessary invariants directly using the property checker, we did not require any customized type \nannotations, as other type checking tools would require. On the other side of the coin, our technique \nhas several limita\u00adtions. First, it has dif.culty dealing with examples where the same address is reused \nwith different types (e.g., in custom allocators), as such code may require making the Type map mutable. \nSecond, sup\u00adport for deallocation and sub-word access is limited, as discussed in Section 5.5. Third, \nwe do not reason about concurrency. Finally, the use of strong, memory-dependent type invariants as discussed \nabove can impose a signi.cant annotation burden on the rest of the program in order to maintain the relevant \ninvariants.  6.2.2 Results The results of our driver experiments are shown in Table 1. The columns in \nthis table show the results for each driver, the results for the common header .les, and the totals. \nThe .rst two rows show the number of lines of code in each example (not counting whitespace and comments) \nand the number of procedures checked. The third row shows the time it took for each example to be checked \non a 2.67 GHz Intel Core 2 Duo with 4 GB of RAM running Windows Vista SP1. Each driver contains 400 900 \nnon-comment, non-blank lines of code and takes about 1 minute to be checked using our tool. Because our \ntool is completely Table 1. Results from our Windows device driver experiments, including the size of \nthe test cases, the amount of time required for checking, and the number and kinds of annotations used. \nLines of code excludes whitespace and comments. cancel event kb.ltr vserial headers total Lines of code \n447 487 494 903 2331 Procedures checked 13 9 12 22 56 Time to check (sec) 57 61 49 52 219 Function pre \n&#38; post Loop invariants Field sensitivity (\u00a73.3) User-def. types (\u00a75.4) Type variables (\u00a75.3) Type \nchanges 22 17 20 15 1 1 1 3 2 3 3 24 12 3 14 2 1 5 5 75 5 8 36 3 27 Code changes 4 5 8 2 17 36 Assumptions \n9 15 8 3 1 36 Total changes 76 55 37 31 27 226 modular, we expect this .gure to scale in proportion \nto the number of lines of code; however, more complex annotations may result in more signi.cant slowdowns. \nAt these speeds, it is feasible to run our type checker occasionally during development, though not at \nevery compilation; however, we believe that there is still a signi.cant amount of room for optimization. \nThe next section of Table 1 shows the number and kind of changes to the program, roughly amounting to \nthe number of lines changed or added. Changes are broken down according to the features used, with a \nreference to a section of the paper where relevant. Type changes refers to any re.nement of the program \ns existing types (e.g., changing void* to something more speci.c), and code changes refers to any changes \nto the code itself. The .rst six rows represent good annotations that add more precision to the existing \nC code. The most frequently used annota\u00adtions are the function annotations, which specify function types \nand contracts. User-de.ned types are also used frequently in cancel and event, primarily for specifying \nprivate device data structures containing linked lists; this feature is very effective at representing \nthe necessary invariants for these data structures, but it also requires stronger default assumptions \nat external function calls (as described in Section 5.4). Overall, there are 153 good annotations for \n2,331 lines of code, or 6.6%. The last two rows represent bad or undesirable annotations, including changes \nto the code and unchecked assumptions. Most code changes were the result of gaps in our C analysis infrastruc\u00adture, \nand assumptions were typically made when types were deter\u00admined by obscure rules that were dif.cult to \nformalize succinctly without deep knowledge about driver invariants. An example of the latter case is \nthe IRP data structure s Tail.Overlay.ListEntry .eld, which is part of a union that has no obvious tag \nindicating its current type. (Such unions were responsible for about half of the unchecked assumptions.) \nThese assumptions, though unchecked, serve a valuable purpose in .agging code for future review. We also \nbelieve that further annotation effort could reduce the number of unchecked assumptions signi.cantly. \nThese bad changes ac\u00adcounted for 71 annotations, or 3.0% of the lines of code, and do not include the \nautomatically-generated non-null pointer assumptions or assumptions about Mem for user-de.ned types at \nfunction calls. Overall, these results demonstrate that our translation is an ef\u00adfective tool for expressing \nand checking important type invariants in C code without customizing the tool to a particular code base. \nThere is still additional room for improvement in terms of infer\u00adence and expressiveness so that we minimize \nthe need for explicit good annotations and eliminate the bad ones. 7. Related Work 7.1 Proof Carrying \nCode Proof-carrying code [30] combines type checking for Java-like lan\u00adguages with an SMT solver. For \nexample, Touchstone [32] com\u00adpiles Java into native x86 code along with a proof that the result\u00ading code \nis type and memory safe, which is generated by an SMT solver with specially-designed decision procedures. \nHowever, the type system formalized in PCC was based on a set of axiomatized type rules, whereas our \nlower-level approach explicitly de.nes the set of values that correspond to each type. Also, we provide \na much lower-level model of the program s semantics (e.g., using the Mem map instead of more abstract \nobjects), and we expose a signi.cant portion of this model to the programmer by allowing the program\u00admer \nto write preconditions, postconditions, and custom types. Foundational proof-carrying code [4] takes \na lower-level ap\u00adproach to proof-carrying code, wherein types are de.ned as predi\u00adcates on the state \nof the underlying machine [5]. Instead of relying on a speci.c type system that may or may not have an \nof.ine proof of soundness, foundational proof-carrying code allows the user to bundle the higher-level \nproof of type safety along with a proof that the underlying type system is sound. Our work provides a \nnew for\u00admulation of types as predicates that works well for low-level C programs and that can be handled \nef.ciently by a fully automated decision procedure for an NP-complete logic. Generally speaking, foundational \nPCC provides a more general and more expressive ap\u00adproach to the problem of proving code safe, whereas \nour approach is more automated. The original work on foundational PCC applied to functional code, but \nfurther work extended it to imperative code and recursive types [3, 6]. Our approach differs from this \nwork in that it de.nes the Mem and Type maps along with an explicit, global type safety invariant that \nrelates these two maps. Because this invariant is enforced at top level , most of our type de.nitions \n(all but Section 5.4) do not need to refer to Mem, which allows us to handle mutation and recursive types \ncleanly and ef.ciently. Further work on low-level PCC has allowed users to combine many proof techniques \nin the context of a single tool [14, 21] and has explored ways to expose a powerful logical framework \nin the context of a programming language [18]. These tools are typically quite powerful and quite general, \nwhereas our work focuses specif\u00adically on type checking legacy C code using an SMT solver in a scalable \nand automated way.  7.2 Type Checking CCured [31] provides strong type checking for C by inferring re\u00ad.ned \npointer kinds and instrumenting the program appropriately, and Deputy [17] uses dependent types in place \nof CCured s pointer annotations. Both systems use compile-time and run-time checks to enforce type safety. \nUnfortunately, CCured and Deputy provide only a .xed set of types, so it is dif.cult to check programs \nthat make use of C idioms not covered by these types. We provide a much more .exible annotation system \nthat is based on our property checking tools; as a result, it is often easier for users to explain to \nthe type checker why an existing program is safe. We have found that stating preconditions, postconditions, \nand type invariants can often be simpler and more .exible than using dependent types. Cyclone [25] provides \na sound C-like type system that can handle a wide range of existing C idioms. Our approach requires less \nporting effort and has more expressive types, but we are also less scalable. Semantic type quali.ers \n[16] allow C types to be re.ned using type rules whose soundness is checked at compile time. As with \nour system, this approach allows the user to extend C types to express common program invariants. Our \napproach gains additional expressiveness at the cost of some scalability. Dependent ML [39] and Xanadu \n[38] provide dependent types for functional and imperative programs, respectively. These types provide \na clean mechanism for re.ning ML types to provide ad\u00additional information about properties such as array \nbounds. How\u00adever, these type systems have limited ability to reason about updates to mutable state. Our \napproach overcomes the problem of mutable state by modeling it directly in our translation; our SMT solver \nhan\u00addles these updates cleanly through the use of standard select-update reasoning. Also, we have found \nthat specifying preconditions and postconditions of functions can be a useful alternative to specifying \nthese properties using dependent types. 7.3 Property Checking ESC/Java [23] and Spec# [10] add checked \ncontracts to Java and C# in the same style as our work. However, such contracts are more dif.cult to \nwrite in C due to its lower-level memory model. Enforcing type safety in C bridges this gap, enabling \nhigher-level property checking even in the context of a low-level language. Property checking tools for \nC fall under two categories. Sound veri.ers for C such as Compcert [27] and VCC [37] take a low-level \nview of C s memory model ignoring types, and use higher-order theorem provers (e.g., Coq [1]) in conjunction \nwith SMT solvers to discharge the veri.cation conditions. Although these tools offer more expressiveness \ncompared to our work for the property lan\u00adguage, they place signi.cant annotation burden on the users \nto ex\u00adpress disambiguation of the heap and to guide the theorem prover through the proof construction \nprocess. On the other hand, several property checking tools for C as\u00adsume type safety to perform scalable \nanalysis of low-level code, thereby introducing unsoundness in the analysis. SLAM [8] and BLAST [24] \nuse predicate abstraction to check control-oriented properties (e.g., lock usage) on device drivers. \nCaduceus [22] is a modular veri.er for C that assumes .eld disambiguation to par\u00adtition the heap. Yang \net al. [40] prove memory-safety of programs manipulating linked lists, but require unsound assumptions \nfor ar\u00adrays and pointer arithmetic. Our work shows that these tools require a .eld-sensitive type safety \ninvariant to justify the .eld disambigua\u00adtion used in these tools. Most of these works are aimed at inferring \nannotations and can be seen complementary to our work. Using these techniques in the context of our low-level \nmemory model would reduce the annotation burden in our tool. 7.4 Separation Logic Separation logic [35] \nprovides a way to state and reason about assertions on heap-based data structures. For example, Calcagno \net al. [13] use separation logic to check memory safety of low\u00adlevel code that manipulates linked lists, \nthough they have limited expressivity regarding the properties we check in this work. In our experience, \ntype-based speci.cations and separation logic speci.cations are complementary. Types provide a coarse \nbut natural abstraction for specifying disjointness, whereas separa\u00adtion logic can provide disjointness \nin a more precise fashion among different instances of a single type. For example: void foo(record *x, \nrecord *y) { y->data2 = 42; x->data1 = 5; assert(y->data2 == 42); } Types enable us to prove this assertion \nwithout any additional annotations, whereas with separation logic, we would need to ex\u00adplicitly specify \nthat &#38;x->data1 != &#38;y->data2. On the other hand, if this example modi.ed y->data1 instead of y->data2, \ntypes would be of no use; we would need to use separation logic to indicate that &#38;x->data1 != &#38;y->data1. \n8. Conclusion This paper has presented a technique for checking types and prop\u00aderties in tandem on low-level \ncode. Using a property checker to implement a type checker gives us the power to express and check program-speci.c \ntype invariants. In addition, proving type safety for low-level code allows us to provide disambiguation \nbetween heap locations that is required by the property checker. Our results suggest that this approach \nis an effective way to improve the power and expressiveness of veri.cation tools for low-level code. \nAcknowledgments We would like to thank Juan Chen, Chris Hawblitzel, and Galen Hunt for their valuable \ncomments and suggestions. References [1] The Coq proof assistant. http://coq.inria.fr/. [2] The HAVOC \nproperty checker. http://research.microsoft. com/projects/havoc/. [3] A. J. Ahmed, A. W. Appel, and R. \nVirga. A strati.ed semantics of general references embeddable in higher-order logic. In Logic in Computer \nScience (LICS), 2002. [4] A. W. Appel. Foundational proof-carrying code. In Logic in Computer Science \n(LICS), 2001. [5] A. W. Appel and A. P. Felty. A semantic model of types and machine instructions for \nproof-carrying code. In Principles of Programming Languages (POPL), 2000. [6] A. W. Appel and D. McAllester. \nAn indexed model of recursive types for foundational proof-carrying code. Transactions on Programming \nLanguages and Systems (TOPLAS), 23(5), Sep 2001. [7] T. Ball, B. Hackett, S. K. Lahiri, and S. Qadeer. \nAnnotation-based property checking for systems software. Technical Report MSR-TR\u00ad2008-82, Microsoft Research, \n2008. [8] T. Ball, R. Majumdar, T. D. Millstein, and S. K. Rajamani. Automatic predicate abstraction \nof C programs. In Programming Language Design and Implementation (PLDI), 2001. [9] M. Barnett, B.-Y. \nE. Chang, R. DeLine, B. Jacobs, and K. R. M. Leino. Boogie: A modular reusable veri.er for object-oriented \nprograms. In Formal Methods for Components and Objects (FMCO), 2005. [10] M. Barnett, K. R. M. Leino, \nand W. Schulte. The Spec# programming system: An overview. In Construction and Analysis of Safe, Secure, \nand Interoperable Smart Devices (CASSIS), 2004. [11] M. Barnett and R. Leino. Weakest-precondition of \nunstructured programs. In Program Analysis for Software Tools and Engineering (PASTE), 2005. [12] R. \nBornat. Proving pointer programs in Hoare logic. In Mathematics of Program Construction (MPC), 2000. \n[13] C. Calcagno, D. Distefano, P. W. O Hearn, and H. Yang. Beyond reachability: Shape abstraction in \nthe presence of pointer arithmetic. In Static Analysis Symposium (SAS), 2006. [14] B.-Y. E. Chang, A. \nChlipala, G. C. Necula, and R. R. Schneck. The Open Veri.er framework for foundational veri.ers. In Types \nin Language Design and Implementation (TLDI), 2005. [15] S. Chatterjee, S. K. Lahiri, S. Qadeer, and \nZ. Rakamaric. A reachability predicate for analyzing low-level software. In Tools and Algorithms for \nthe Construction and Analysis of Systems (TACAS), 2007. [16] B. Chin, S. Markstrum, and T. Millstein. \nSemantic type quali.ers. In Programming Language Design and Implementation (PLDI), 2005. [17] J. Condit, \nM. Harren, Z. Anderson, D. Gay, and G. Necula. Dependent types for low-level programming. In European \nSymposium on Programmig (ESOP), 2007. [18] K. Crary and J. C. Vanderwaart. An expressive, scalable type \ntheory for certi.ed code. In International Conference on Functional Programming (ICFP), 2002. [19] L. \nde Moura and N. Bj\u00f8rner. Z3: An ef.cient SMT solver. In Tools and Algorithms for the Construction and \nAnalysis of Systems (TACAS), 2008. [20] E. W. Dijkstra. Guarded commands, nondeterminacy and formal derivation \nof programs. Communcations of the ACM, 18, 1975. [21] X. Feng, Z. Ni, Z. Shao, and Y. Guo. An open framework \nfor foundational proof-carrying code. In Types in Language Design and Implementation (TLDI), 2007. [22] \nJ.-C. Filli atre and C. March\u00b4e. The Why/Krakatoa/Caduceus platform for deductive program veri.cation. \nIn Computer Aided Veri.cation (CAV), 2007. [23] C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson, \nJ. B. Saxe, and R. Stata. Extended static checking for Java. In Programming Language Design and Implementation \n(PLDI), 2002. [24] T. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre. Lazy abstraction. In Principles \nof Programming Languages (POPL), 2002. [25] T. Jim, G. Morrisett, D. Grossman, M. Hicks, J. Cheney, and \nY. Wang. Cyclone: A safe dialect of C. In USENIX Annual Technical Conference, 2002. [26] S. K. Lahiri \nand S. Qadeer. Back to the future: Revisiting precise program veri.cation using SMT solvers. In Principles \nof Programming Languages (POPL), 2008. [27] X. Leroy. Formal certi.cation of a compiler back-end, or: \nProgram\u00adming a compiler with a proof assistant. In Principles of Programming Languages (POPL), 2006. \n[28] Microsoft. Windows driver kit. http://www.microsoft.com/ whdc/devtools/wdk/default.mspx. [29] G. \nMorrisett, D. Walker, K. Crary, and N. Glew. From System F to typed assembly language. Transactions on \nProgramming Languages and Systems (TOPLAS), 21:3, 1999. [30] G. C. Necula. Proof-carrying code. In Principles \nof Programming Languages (POPL), 1997. [31] G. C. Necula, J. Condit, M. Harren, S. McPeak, and W. Weimer. \nCCured: Type-safe retro.tting of legacy software. Transactions on Programming Languages and Systems (TOPLAS), \n27(3), May 2005. [32] G. C. Necula and P. Lee. The design and implementation of a certifying compiler. \nIn Programming Language Design and Implementation (PLDI), 1998. [33] G. Nelson and D. C. Oppen. Simpli.cation \nby cooperating decision procedures. Transactions on Programming Languages and Systems (TOPLAS), 1(2), \n1979. [34] Y. R\u00b4egis-Gianas and F. Pottier. A Hoare logic for call-by-value functional programs. In Mathematics \nof Program Construction (MPC), 2008. [35] J. C. Reynolds. Separation logic: A logic for shared mutable \ndata structures. In Logic in Computer Science (LICS), 2002. [36] Satis.ability Modulo Theories Library \n(SMT-LIB). Available at http://goedel.cs.uiowa.edu/smtlib/. [37] W. Schulte, S. Xia, J. Smans, and F. \nPiessens. A glimpse of a verifying C compiler. In C/C++ Veri.cation Workshop, 2007. [38] H. Xi. Imperative \nprogramming with dependent types. In Logic in Computer Science (LICS), 2000. [39] H. Xi and F. Pfenning. \nDependent types in practical programming. In Principles of Programming Languages (POPL), 1999. [40] H. \nYang, O. Lee, J. Berdine, C. Calcagno, B. Cook, D. Distefano, and P. O Hearn. Scalable shape analysis \nfor systems code. In Computer Aided Veri.cation (CAV), 2008.     \n\t\t\t", "proc_id": "1480881", "abstract": "<p>We present a unified approach to type checking and property checking for low-level code. Type checking for low-level code is challenging because type safety often depends on complex, program-specific invariants that are difficult for traditional type checkers to express. Conversely, property checking for low-level code is challenging because it is difficult to write concise specifications that distinguish between locations in an untyped program's heap. We address both problems simultaneously by implementing a type checker for low-level code as part of our property checker.</p> <p>We present a low-level formalization of a C program's heap and its types that can be checked with an SMT solver, and we provide a decision procedure for checking type safety. Our type system is flexible enough to support a combination of nominal and structural subtyping for C, on a per-structure basis. We discuss several case studies that demonstrate the ability of this tool to express and check complex type invariants in low-level C code, including several small Windows device drivers.</p>", "authors": [{"name": "Jeremy Condit", "author_profile_id": "81100200251", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1301003", "email_address": "", "orcid_id": ""}, {"name": "Brian Hackett", "author_profile_id": "81320490544", "affiliation": "Stanford University, Stanford, CA, USA", "person_id": "P1301004", "email_address": "", "orcid_id": ""}, {"name": "Shuvendu K. Lahiri", "author_profile_id": "81100338283", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1301005", "email_address": "", "orcid_id": ""}, {"name": "Shaz Qadeer", "author_profile_id": "81100286660", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1301006", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1480881.1480921", "year": "2009", "article_id": "1480921", "conference": "POPL", "title": "Unifying type checking and property checking for low-level code", "url": "http://dl.acm.org/citation.cfm?id=1480921"}