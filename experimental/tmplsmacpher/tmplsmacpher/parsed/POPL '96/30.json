{"article_publication_date": "01-01-1996", "fulltext": "\n The reflexive CHAM and the join-calculus C6dric Fournet Georges Gonthier Cedric .Fournet@inria. fr Georges \n.Gonthi.er@inria .fr INRIARocquencourt * 78153 Le Chesnay Cedex FRANCE Abstract By adding reflexion to \nthe chemical machine of Berry and Boudol, we obtain a formal model of concurrency that is con\u00ad sistent \nwith mobility and distribution. Our model provides the foundations of a programming language with functional \nand object-oriented features. It can also be seen as a process calculus, the join-calculus, which we \nprove equivalent to the w-calculus of Milner, Parrow and Walker. Introduction There is a mismatch between \ncalculi for concurrent processes and languages for programming distributed and mobile sys\u00ad tems. Calculi \nsuch as CCS or the ~-calculus [16, 19] intro\u00ad duce a small number of constructs, and have a thoroughly \nstudied metatheory. However, they are mostly based on atomic non-local interaction (typically reruiez-vous), \nwhich is difficult to implement fully in a distributed setting. Pro\u00ad gramming languages such as Actors \n[1] or Obliq [8] have separate primitives for transmission and synchronization, for instance remote procedure \ncall and semaphores. However, they also have a much larger set of constructs, usually in\u00ad cluding imperative \nprimitives, and this hinders their formal investigation. To bridge this gap, we introduce a new elementary \nmodel of concurrency, the reflexive chemical abstract machine. We both use this model as the basis for \na practical program\u00ad ming language design, and study this model formally using a process calculus, the \njoin-calculus. The reflexive CHAM model 1s obtained from the generic CHAM [6] by imposing locality and \nadding reflexion Local\u00ad ity is achieved by barring non-linear reaction patterns; this implies that each \nreaction rule or molecule can be associated with a single reaction site. Reflexion is added by letting \nre\u00ad actions extend a machine with new kinds of molecules along with their reaction rules; this lets our \nmodel be computa\u00ad tionally complete. Our model IS more effective than the generic CHAM: molecules travel \nto their reaction site, in\u00ad stead of having to mix and match. It also turns out that the *This work is \npartly supported by the ESPRIT Basic Research Action 6454-CONFER Permission to make digitallhard copies \nof all or part of this material for personal or classroom use is grsnted without fee provided that the \ncopies are not made or distributed for profit or commercial advantsge, the copy\u00adright notice, the title \nof the publication and its date appear, and notice is given that copyright is by permission of rhe ACM, \nInc. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires specific \npermission and/or fee. POPL 96, St. Petersburg FLA USA @ 1996 ACM 0-89791-769-3/95/01. .$3.50 sequential \ndeterministic subset of our model is basically the continuation-passing style J-calculus; hence we can \nembed the A-calculus using any CPS transform. Our language design extends a higher-order sequential language \nwith parallelism in expressions (with fork calls) and m function patterns (with join patterns). Jointly \nde\u00adfined functions provide the same synchronization capabili\u00adties as synchronous channels or concurrent \nobjects. More\u00adover, jom patterns are more consistent with lexical scope: they statically bind (joint) \nfunction calls to a body of code, whereas the binding of messages to receptors is dynamic. The join-calculus \nis simply the syntactic description of the reflexive CHAM molecules. It is quite similar to the T\u00adcalculus, \nexcept that it combines restriction, reception, and replication in a single (joint) receptor defimtion. \nOur main theorem states that the ~-calculus and the join-calculus have the same expressive power, up \nto weak barbed congruence; it is obtained by exhibiting fully abstract encodings in each direction. As \na result we can expect most of the T-calculus metatheory to carry over directly to the join-calculus. \n2 Overview Most process calculi are based on synchronous channels. A channel is an abstraction of the \ncommunication media on which data is excharmed: send and receive operations on u, channels provide a \nconcise denotation for the transmission, routing, and synchronization that actually occur in a concur\u00ad \nrent system. The ~-calculus [19, 17] has demonstrated that, in combination with an elegant scope management \ntech\u00ad nique, channel operations are computationally complete. The PICT experiment [21, 24, 23] has further \nshown that the m-calculus, more specifically its asynchronous fragment, can be used as the basis of a \nuseful higher-order concurrent language, in a non-distributed setting. In a distributed settinz. 4 however, \nchannels introduce atomic interaction between distant emitters and receivers (communication m the ether \n[16]). This can be difficult to implement, even more so if recovery from local fadures is also supported: \nunless the channel implementation includes a sophisticated fault-tolerant consensus protocol, some of \nthe implementation details wdl be revealed by failures. This problem occurs even in the asynchronous \nsetting, as there is interaction between distant receivers, through contention. On the other hand, channels \nare not absolutely required for high-level distributed programmmg. For instance) they are not primitive \nin object-based languages [1, 8]; unfortu\u00ad nately, these languages lack an abstract foundation as sim\u00adple \nand precise as the n-calculus. It is such a model that we purport to develop in this paper. Our starting \npoint will be the chemical abstract machine, which can be regarded as the computational model of the \nn-calculus, Litterally, CHAM interaction is local, since molecules simply move around in a solution, \nuntil they meet in match\u00ading pairs and react; but the random motion in this descrip\u00adtion is not very \neffective. Assuming that the chemical rules have disjoint domains, the CEIAM also has a more opera\u00adtional \ninterpretation: all molecules travel to a reaction site associated to their rule, where they are sorted, \nmatched, and made to react (figuratively, reactions are (catalyzed at the sites). Under this interpretation, \nhowever, the CHAM is not very concurrent: communication is centralized in a fixed set of sites (catalyzers \nare bottlenecks), and the management of each site is complex, as the number of different expected molecule \nshapes can grow arbitraly (catalyzers clog up). It would be much better to have a larger number of sites \nwith simpler matching instead, and this is exactly what the re\u00adflexive CHAM modifications bring in, by \nallowing dynamic creation of sites and restricting reaction patterns. We now sketch the basic mechanisms \nof the reflexive CHAM; the formal definition is exposed in section 3. Our model operates on higher-order \nsolutions 7? E M compris\u00ading two multisets. The molecules M represent the processes running in parallel; \nthe reactions 72 define the current re\u00adduction rules. Names are the only values in our model, as in the \n~-cal\u00adculus. They have a twofold usage: port names, and trans\u00admitted values. We write z(y) to mean that \nthe name y is sent on the name z. An atom is a pending message z(y). A compound molecule consists of \nseveral sub-molecules, glued by the join operator ([ . Molecules can be ,heated into smaller ones, in \na reversible way. As a first example, we consider a print spooler with two ports: available printers \nlike laser send their name on the port named ready, while users send the file\u00adnames 1, 2 to be printed \non the port named job. There are three atoms in solution on the first line, versus one atom and one compound \nmolecule on the second line, where the molecule joins the laser-printer and the file 1. The structural \nequivalence = relates these two solutions, wit bout reactions yet. O t-ready (laser), job(l), job(2) \n* 0 k ready (laser) I job(l), job(2) Denoted D or J D P, a reaction consumes compound molecules that \nhave a specific join pattern J, and produces new molecules in the solution that are copies of P where \nthe formal parameters of J have been instantiated to the transmitted values. This corresponds to reduction \nsteps on the whole solution (%? E M) -+ (%? } M ). Continuing our example, we add a reaction that matches \nprinters and jobs, then sends the filename to the printer: D = ready (printer) I job(flle) ~ printer(file) \n We now add this chemical reaction in our solution, and we use it to reduce our previous molecule and \ngenerate a new atom, Notice that non-determinism comes from =, and is just committed by the reaction. \nD 1-ready (laser) I job(l), job(2) ---+ D } laser(l), job(2) Our model is reflexive, meaning that reactions \ncan be dy\u00adnamically created. This is done by our last kind of molecule. The defining molecule def D in \nP can be heated in two parts, a new reaction D and a molecule P. In this case, the newlv . defined Dorts. \ncan be used in both L? and P. The solution we just considered could have come from a single molecule, \nwith the structural rules: 0 E def D in ready (laser) / job(1) I job(2) = D k ready (laser) I job(1) \nI job(2) = D E ready (laser) I job(l), job(2) A more realistic spooler would send the name job to its \nusers, and the name ready to its printer drivers. This corresponds to the well-known scope-extrusion \nof the x-calculus. How\u00adever, our definitions have a strict lexical discipline: the be\u00adhaviour of ready \nand job may not be deterministic, but it is statically defined. Other processes that receive these names \nmay send messages, but they cannot add new reactions for them. This essential restriction to reflexion \nlets us extend the language safely. For instance, special names used only in &#38;rules may be added \nto the machine without special care, while in the ~-calculus any process may mistakenly alter their behaviour. \nIn section 4, we expand the model into a simple pro\u00adgramming language with mobility, and we illustrate \nsome of its features. From the programmer s point of view, it is a high-level concurrent language with \nlexical scope and asyn\u00adchronous messages. We identify function calls as a special case of message passing \nwith CPS: we analyze two reduction strategies for the A-calculus, then we define some convenient syntactic \nsugar for sequential control. The language also has object-oriented features. Ele\u00admentary objects are \ndefined by new names and new reac\u00adtion rules: methods are the names that are returned, be\u00adhaviors are \ndeclared in the rules, states are held in messages on internal names. Elaborate synchronization schemes \ncan be expressed among these concurrent objects by pattern\u00admatching on their rules. Our firm commitment \nto lexical scoping makes our objects very static, meaning that more imperative features such as cloning \nmust be explicitly en\u00adcoded In sections 5 and 6 .we explore the properties of the join\u00adcalculus and its \nrelation to the ~-calculus. The join-cal\u00adculusis the process calculus induced by the reflexive CHAM. \nWe first define the observational equivalence, then we use it as a basis to compare the relative expressive \npowers of dif\u00adferent calculi. Our translations between calculus are proved fully abstract with regards \nto weak barbed congruence; in that sense, our technical results are precise up-to substitu\u00adtion of encodings \nin any context of the host calculus. In section 5, we strip the join-calculus of convenient but un\u00adnecessary \nfeatures: recursion, join patterns including more than two messages, polyadic messages, defimtions with \nsev\u00aderal clauses, and we obtain a core join-calculus that retain the expressive power of our model. In \nsection 6, we compare this core join-calculus and the asynchronous n-calculus [11]. In spite of significant \ndifferences, both calculi provide ex\u00adactly the same expressive power. However, their scoping conventions \nmakes the accurate encodings surprisingly com\u00adplex. We present both simple and accurate encodings, and \nwe discuss their characteristics, which illuminate what sep\u00ad arates the two calculi. We conclude the \npaper with a few words on future work. An implementation is under way, to evaluate our language in practice, \nand we mention the extensions to support types, explicit distribution, failure-detection and migration. \nIn the annexes A and B, we sketch the proofs of full abstraction for the two encodings between the fi-cal-CUIUS \nand the join-calculus that are described in section 6. These results are obtained using auxiliary encodings \nand bisimulation-based techniques, in particular weak bisimula\u00adtion up-to expansion as proposed in [25]. \n 2.1 Related work To our knowledge, BanStre [5] was the first to suggest <multi-functions as primitives \nfor synchronization. They correspond to a first-order version of our jom definitions, in a procedural \nand synchronous language. Our work is more directly related to the recent asynchronous trend of the T-calculus \n[11, 10, 7], and from its first applications [23, 21]. Our calculus focuses on mobility in a minimal \nsetting. This contrast with extensions for concurrency from an object-oriented or a functional kernel \n[1, 9, 8]. Likewise, distributed systems built on the actor paradigm [1, 2] pro\u00adposed a two-layered architecture \nwith a functional kernel wrapped in an imperative extension for communication. Other calculi introduce \nconcurrency and/or distribution using different primitives. Instead of directed communica\u00adtion with a \nfunctional flavour, they rely for instance on uni\u00adfication and broadcast. This is the case for Oz [26], \nand for linear objects [4]. 3 The reflexive chemistry We first give the syntax of processes, and the \nscope for their names. Then we present the reflexive chemical machine, and we illustrate it on a few \nsimple examples. 3.1 Names, Processes, Definitions Values in the reflexive CHAM are only names, as this \nis the case in the m-calculus. Let N be an infinite set of names; we use name variables in lowercase \nletters z G N to denote its elements. In the following, ~ is a notation for a tuple of name variables \nxl, x2, z~. The following grammar defines processes, join-patterns and definitions. A process P is an \nemission of an asyn\u00adchronous polyadic message z(O, a definition of new names, or a parallel composition \nof processes. A definition D con\u00adsists of one or several elementary definitions .JbP that match patterns \nJ joining messages to guarded processes P, con\u00adnected by the A operator. It entirely describe the behaviour \nof its defined names. P ++f z(;) J = z(q D =f J.P def Din P JIJ DAD PIP Names that appear in a process \nP maybe captured by an enclosing definition. The only binder is the join pattern J, but the scope of \nits names depends of their position in mes\u00adsages. The formal parameters that are received are bound in \nthe corresponding guarded process. The defined port names are bound in the whole defining process, that \nis, the main process and recursively all the guarded processes. Received variables mJ(J), defined variables \ndw(J) and dv(D), and free variables fv(D) and fv(P) are specified by structural in\u00adduction. Notice the \nsyntactic restriction for processes: No received variable may appear twice in the same pattern J. This \nrules out any comparison on names, and guarantees that join patterns remain linear. Lfcf T-r)(Z(q) \n{u E ;} dcf rv(J]J ) TV(J) k. T-v(J ) dcf  dv(z(i)) {z} d.f dv(JIJ ) dv(J) U dv(J ) def dv(Jb P) \n= dv(J)  d.f dv(D A D ) dv(ll) U dw(D )  def fv(JDP) = A(J) U (fv(P) T-w(J)) Lfef frJ(D A D ) = fv(D) \nU fv(D ) fv(x(q) def {Z}u{ueq ~v( def D in P) ~ (fv(P) U fv(D)) -dv(ll) dcf fv(P[P ) f7J(P) u fv(P ) \nA name is fresh with regards to a process or a solution when it is not free m them, In the following, \nwe use substi\u00adtutions a and { /V}, with possibly implicit a-renaming on non-free variables to avoid name \nclashes. While this is not needed in the join-calculus, we will as\u00adsume that for any given name variable \nthe number of ar\u00adguments is the same in every message and in every join\u00adpattern. Formally, this amounts \nto use a recursive sort dis\u00adcipline and to consider only well-sorted processes, as for the r-calculus[18, \n22].  3.2 Operational semantics We extend the chemical approach of Berry and Boudol [6] with reflexion. \nWe first give some heating/cooling re\u00adversible rules fi, This corresponds to the underlying struc\u00adtural \nequivalence on processes, and includes reflexion. Once molecules have been suitably dissolved, the single \nreduction rule + expresses the mechanism of communication in a much simpler way than for the n-calculus. \nRules operate on higher-order solutions 7? E A-4, On the right-hand-side, active processes are molecules \nin the multiset M, on the left-hand-side, active definitions are (re\u00adactions in the multiset Ii?, For \nthe sake of simplicity, we only mention the elements of both multisets that participate in the rule, \nseparated by commas. (str-jo,n) 1-PIQ = + P,Q (str-and) D A E 1-+ D,E t\u00ad (str--def) k def D in P + Dud. \nk Pu~. (red) JDP b J~,. --+ JDP t-Pu,. Side-conditions for substitutions: (str-def) aa. instantiates \nthe port variables cZW(D) to distinct) fresh names: Dom(adv) n (fv(%?t-M)) = 0 (red) a, substitutes the \ntransmitted names for the distinct received variables T-w(J).  The first two structural rules express \nthat 1 and A are commutative and associative. (str-def) describes the heat\u00ading of a molecule that defines \nnew names. The restriction on ad, is reminiscent of the restriction prefix v in the n-cal\u00adculus, with \nregards to scope extrusion, and at the same time enforces a strict static scope for the definitions. \n(red) is a meta reduction rule that associates the actual reduction rule to each reaction in %?. In one \ncomputation step, such reduc\u00adtions consume any molecule with a given port, pattern, make a fresh copy \nof their guarded process, substitute its received parameters for the sent names, and release the process \nas a new floating molecule. 3.3 Some examples We now give examples of processes and definitions, along \nwith an intuitive description of their meaning. The formal treatment of observations is deferred until \nsection 5. def z(u) D y(u) in P (1) clef y(u) D z(u) in def x(u) b y(u) in ~ (2) def zl(u)lzz(v) D Z(U, \nV) in P (3) def z(v) ly(sc) D K(V) in P (4) defsoDPA soDQ in so (5) def onceoly(v) D z(rJ) in y(l) \\y(2)\\y(3)]onceo \n(6) def loopo D PIZoopo in loopo[Q (7) The simpler definitions perform some wiring between names: in \n(1) messages on the local name z in P are forwarded to the outside as messages on y; in (2) the leftmost \nz is a free name, while the rightmost one is locally bound in P, and will require renaming; however, \nmessages on the local z are still forwarded in two steps on the external one; (3) performs multiplexing \nof messages on z whose parts are sup\u00adplied on ZI and zz; (4) was introduced as a print spooler in the \noverview, but it more generally models n-calculus-like channels, as values are sent on z and requests \nfor values are sent on y, to me matched in the definition; (5) and (6) both express internal non-determinism \nP + Q using a compound definition, and z(1) + z(2) + x(3) using the message on once as a lock; (7) replicates \nthe process P, starting a new copy each time the definition is used. We finish our series with a longer \nexample that illustrates both higher-order and the use of internal messages to store some local state. \nA reference cell abstraction is defined as: ( def get(~) is(v) D K,(v) Is(v) def rnkce~l(vo, KCI) D A \nSet(u, s$)ls(v) D KOIS( U) in s(rJo) [ tco(get, set) ) Each mkcell message triggers the external definition, \nwhich in turn defines three fresh names get, set, s. The first two are sent back on KO for later access \nor update to the new cell, Thanks to lexical scoping, the last name s remains local, and the initial \nmessage S(VO) together with the two internal rules guarantee the invariant of the cell: there is exactly \none message on s, which contains the current value, 4 Programming in the join-calculus We now use the \nreflexive CHAM as the foundation of a con\u00adcurrent programming language. While our model already provides \nenough expressive power, its features are too low\u00adlevel for actual programming. For instance, there is \nno con\u00advenient way to express sequential control in a process, which strongly suggest the use of some \nsyntactic sugar. We first study the embedding of higher-order functional program\u00adming. using continuation-passing \nstyles, we encode two re\u00adduction strategies for the ~-calculus in clear-cut subsets of the join-calculus. \nThen we describe a toy concurrent lan\u00adguage based on these ideas, and we give some programming examples. \nWe finally discuss object-oriented features. pro\u00adgramming. 4.1 Two encodings of the A-calculus Definitions \nof the form def ~(x) D P in Q seems to be very similar to the let ~(x) = E in E statement in functional \nprogramming. In particular, they share the same static scoping discipline, The major difference comes \nfrom asynchrony in our model, meaning that we must explicitly create and send continuations. For a given \nCPS, we encode J-terms as processes that can be triggered, and we compare their respective behaviour, \nWith minor adaptations, we obtain results of adequacy sim\u00adilar to those for the n-calculus [17]: The \nterms and their translations converge or diverge accordingly. Our purpose here is to illuminate the tight \nconnection between func\u00adtions and join-definitions, which makes our encodings sim\u00adpler than [17, 7]. \nOur syntax for the J-calculus is as usual: Call-by-name: in this reduction strategy, A-terms are reduced \nin leftmost-order and no reduction may occur under a J. Our encoding is: Intuitively, the process [Z \n]V sends its value on v, a value is a process that serves evaluation requests sent on K, and requests \nsupply two names: x to send requests for the value of the argument, and w to eventually return a value \nwhen evaluation converges. The image of the translation is exactly the determin\u00adtstzc subset of the join-calculus, \ndefined as the set of pro\u00adcesses that contain no parallel composition, and neither join\u00adpattern nor A \nin definitions. As expected, reductions for processes in this subset are entirely sequential. Parallel \ncall-by-value: the A-term (TU) can be re\u00adduced as soon as both T and U have been reduced to values, thus \nallowing the function and the argument to be evaluated in parallel. Again, no reduction may occur under \na J. Using a larger subset of the join-calculus, we encode this confluent but non-determmistic reduction \nstrategy: Again, the encoding [T]v sends its value on w and a value is a process that serves evaluation \nrequests sent on K, but evaluation requests now supply the value of the parameter along with a name for \nthe value of the term. The image of the translation now uses parallel compo\u00adsition to capture the non-determinism \nof the strategy. The symmetry between the evaluation of the function and of the argument is apparent, \nbacked by the two symmetries, on the fork of evaluation requests and on the join of their results. 4.2 \nA language with sequencing In our basic model, synchronization happens only as molecules are consumed, \nand this suffices to express con\u00adtrol flow. In practice however, the resulting programs would contain \nmany explicit continuations and would be difficult to understand. Instead, we make the sequential control \nap\u00ad parent: we fix a CPS, and provide it as syntactic sugar in the language. To this end, the new grammar \nextends the syntax in two steps Names are split in two families: synchronous and asyn\u00adchronous Processes \ncan consist of series of instructions {1 } that are executed sequentially asynchronous message {I*} sequence \nof instructions PIP parallel composition def ~ = P [and J = P ] recursive ciefinition let. i7=V nameci \nvalues run P asynchronous process do ~(~) synchronous call If V th~n 1 [else 1] conditional return V \nto f implicit continuation v value (name,. ) f(v) synchronous call x(0 asynchronous message f (q x (a \nsynchronous message JIJ join of several messages As in the calculus, Awnchronous names x are defined \nand used for asynchronous-messages; Synchronous names f are names that implicitly transmit a continuation \nin every message. We extend the sort discipline to distinguish names consistently. Whenever a message \nis sent to a synchronous name, a continuation channel is defined as the remaining part of the current \ninstruction sequence, and the continua\u00adtion is added to the message. Whenever such a message is received \nas part of a join pattern, the continuation is bound in the corresponding guarded process, and may be \nused to send back results using the return instruction. Briefly, let binds names from synchronous calls; \ndo does the same when the result is a synchronisation signal (); run asynchronously forks a process; \nreturn (asynchronously) sends results back on the continuation that was received on f Finally, any value \nmay contain nested synchronous calls. The formal translation is omitted. While the underlying model is \nthe same, this smoothly merges in a declarative style some non-deterministic pro\u00adgramming in a functional \nframework. For definitions with only one message in their pattern, as is particular for contin\u00aduations, \nthe substitution lemma holds, as the instantiated body can be substituted for the calling message, as \nin any functional language. In our examples, synchronous names are capitalised; for instance the mkcell \nexample IS the compilation of the pro\u00adgram def MKCELL (vO) = { def GET() I s(v) = s(v) I {return v to \nGET} and SET(u) I s(v) = s (u) I {return to SET} run s(vO) return (GET, set ) to MKCELL } The second \nexample elaborates on the print spooler of the overview, in an imperative style. Now, the user select \na printer and a format, and files are pre-processed accordingly before printing. The channels PRINT and \nENSCRIPT are synchronous calls to the library. At run-time, the files letter and note are transcripted \nand laser-printed, then the current printer is changed, then the file drawing is printed in colour. { \ndef NEWPRINTER(PRINT, f ormat ) I current (.,. ) = { run current (PRINT, f ormat ) return to NEWPRINTER \n} and JOB(file) I current (PRINT, format)) = { run current (PRINT, format) do PRINT (ENSCRIPT(flle, format)) \nreturn to JOB } run current(LASER,ps) do JOB(letter) do JOB(note) do NEWPRINTER(colour,pscolour) do JOB(drawing) \n} While this style mostly comes from the design of PICT [24], the functional syntax for emissions and \nthe static def\u00adinition of receptions make it more direct and allow a finer control. The main drawback \nis that whenever a PICT chan\u00adnel is actually used with several emitters and several recep\u00adtors in parallel, \nit must be compiled mto a join-definition (see example 4); fortunately, this E uncommon in program\u00adming \nexamples. Our approach also offers more declarative\u00adness-than o-bject-based-languages, since there is \nno need to mutate svstematicallv the receDtor. Conc&#38;ning the ~mplement~tion, the set of rules that \ncomes from adefinitionis independent from any other defini\u00adtion. Taking advantage of asynchrony, these \nrules are man\u00adaged locally by queues for messages, and by an automaton that matches them with join patterns \nand forks accordingly the guarded processes. To this end, well-known compila\u00adtion techniques are available \n[15]. Besides, the embedding of large functional-style definitions can be made reasonably efficient using \ntail-recursion-like optimizations. Finally, con\u00adcrete values and built-m functions can easily be added. \nThe behaviour of their reserved names is given by specific 6-rules that describe the consumption of their \nmessages, and are implemented as low-level function calls. 4.3 Concurrent objects and synchroniza\u00adtion \npatterns Our model provides the essential features of objects, as IS already the case for the n-calculus \n[28]. First, we consider primitive objects that are already present in the language: Using message-passing \nand pattern-matchingin our defini\u00adtions, we encode objects as servers that receive requests to execute \ntheir methods. The design of a full-fledged object-oriented language would require some more encoding: \nFor instance, inheri\u00ad tance (or cloning) is not primitive. Wesketch some features to support more general \nobjects with dynamic definitions and inheritance. 4.3.1 Primitive objects Objects are created in definitions, \nwhose port names may be either returned and made public, or kept private in the body of their definition. \nIn that sense, our cell example is a simple primitive object. We identify names and methods, definitions \nand active concurrent objects. The current state of an object can be split into several components held \non in\u00adternal messages, according to the critical sections. Besides, the interface may feature several \nstates with different syn\u00adchronization capabilities. The declarative pattern-matching on join messages \nis much more expressive than the serial\u00adization of method calls: It contains the expressiveness of coloured \nPetri nets, and can even be dynamically expanded. We illustrate the combination of concurrency and syn\u00adchronization \non the example of priority queues (figure 2): def MK_PRIORITY_QUEUE() { def EMPTY() I noneo = { run \nnoneo return TRUE to EMPTY } and EMPTY() I some(x,E,A,R) = { run some(x,E,A,R) return FALSE to EMPTY \n} and ADD(x) I noneo = { return to ADD let E,A,R = MK.PRIORITY.QUEUE() } run some(x,E,A,R) } and ADD(x) \nI some(y,E,A,R) = { return to ADD do A(MAX (X,y)) run some(MIN(x,y),E,A,R) } and REMOVEOI some(x,E,A,R) \n= { return x to REMOVE if 10 then run noneo else run some(R(),E,A,R) } none () return EMPTY,ADD,REMOVE \nto NEW_PRIORITY.WEUE } Our priority queue features three synchronous methods EMPTY, ADD, REMOVE with \nthe expected meaning; REMOVE re\u00adtrieves the smallest value, or blocks until a value is avail\u00adable. There \nare two internal states, noneo when empty, and some(x,E,A,R) when containing the smallest value x in \nits head and another priority queue with methods E,A,R in its tail. Statically, we can check that there \nis always exactly one state message available for each definition. Values can be concurrently tested, \nadded, and removed; in particular, a new some message is released after at most one compar\u00adison when \na new value is added, while the update propa\u00adgates toward thetail in parallel. When thetail is eventually \nreached, a new, empty priority queue is created using the recursive definition MKIRIORITY.QUEUE, which \nreturns three fresh methods on an empty priority queueto be stored in the last-but-one some message. \n 4.3.2 Class-based objects and inheritance Our primitive objects lack dynamicity, because the lexical \nscope of their definitions forbids overloading or cloning. It is well-known that inheritance and synchronization \nfor con\u00adcurrent objects do not merge gracefully; in our case, we can recover ad-hoc dynamicity using \nindirections. In our spooler example, a dynamic method to print files is implemented by two static methods, \njob for invocation and newprinter for overriding, while the current name associated with the method is \nkept in the internal state currentprinter. Likewise, one can substitute state overwriting for method \noverriding in many cases, and mix freely static and dynamic components within the same objects. While \nour solution seems better than the traditional object-as-server encoding, it requires more than some \nlocal syntactic sugar. An alternative approach consists in com\u00adplementing the join-calculus with new \nfeatures, e.g. with more general records, to obtain richer primitive objects. 5 The join-calculus The \njoin-calculus is simply the set of molecules of the re\u00adflexive CHAM. In this section, we study in more \ndetails its properties as a process calculus: we first give another, equivalent definition of a variant \nof the join-calculus. then we briefly discuss observation, and we identify observational equivalence \nas a barbed bisimulation congruence; finally, we use this tool to precisely reduce the join-calculus \nto its es\u00adsential features. Our reflexive chemical machine entirely defines the syn\u00adtax (molecules as \nprocesses), the structural congruence (%), and the reduction relation (e ---+= ). Any chemical SO\u00adlution \ncan be cooled down into a single process, wrapping all the reactions in a big definition header. Thus, \njoin-cal\u00adculus processes provide another presentation of our model as a first-order rewriting system \nmodulo structural equiva\u00adlence. This more syntactic approach is especially useful to compare our model \nto other calculi (several subsets of the join-calculus in this section, and the n-calculus in the next \none). 5.1 Thejoin-calculuses a process calculus The core (recursive) join-calculuses arestriction of \nthe full calculus with simpler definitions, join patterns and mes\u00adsages, Its syntax is given by the grammar: \nP ~f z(u) \\ P,[P, I def z(u)ly(v)DPI in PZ As before, the scope of u,v is PI) whereas the scope of z,y \nextends to the whole definition. The structural congru\u00adence = is the smallest relation such that for \nall processes p,Q,ll,,S, for all definitions D, D suchthatdv(D), dv(D ) contain only fresh names, PIQ \ns QIP (PIQ)IR - P[(Q]R) Pldef DinQ = defDin PIQ defD in defD in P = defD in defD in P PEmQ =+ p~Q \nPEQ ==+ PIRGQIR R?S,PFQ ~ defJPRinP? defJDsinQ We now define the reduction relation as the r-transitions \nof a labelled transition system ~, where 6 ranges over {D)u {-r). Ourtransition relation is the smallest \nrelation such that for every definition D=z( u)ly(v)D~, z(s)ly(t) ~R{s/u,t/v} and for every transition \nP ~ P , PIQ ~ P IQ de fDin P~def Din P if fw(D) n drJ(6)= 0 de f6in P~def6in P ifrS#T if P= P and Q=Q \nQ~ Q Lemma 1 The structural congruence z is the smallest con\u00ad gruence that contains all pazr of processes \nP, Q such that t-Pe* t-Q. The reduction relation L contazns exactly the pairs of processes P, Q up to \nE such that t-P +1-Q  5.2 Observation While the observation of concurrent processes is difficult in \ngeneral, the join-calculus benefits from the experience gained from CCS and from the m-calculus. After \nan informal discussion of observation criteria, we introduce the equiva\u00adlence among processes as the \nlargest congruence with a few suitable properties, thus following the approach proposed in [12, 13] for \nthe w-calculus. This provides an accurate basis for comparisons with other calculi. 5.2.1 What is observable? \nThe only way for a process to communicate with the out\u00adside is to export some names in messages on its \nfree names, and to wait for an answer from an enclosing definition. We distinguish processes accordingly: \nTo each free name z, we associate an asynchronous, output-only barb &#38; , which tests the ability of \nprocesses to emit anything on z. In the fol\u00adlowing, ---+* stands for any sequence of ~ and &#38;, P&#38;~ \nzGfv(F ) A 3ti,7?/, M, OEP+* Rk M,z(@ 5.2.2 Observational congruence The congruence between processes \nis the largest equivalence relation % that is a refinement of the output barbs $Z, that is weak-reduction-closed, \nand that is a congruence for defi\u00adnitions and parallel compositions: VP, Q, if P = Q, then 1.VxcN, PJJCimplies \nQ&#38; 2. P -+ P implies 3Q , Q ---i Q and P z Q 3.VD, de fDln P = de fDin Q 4. VR, RIP z R\\Q In most \nproofs, we also need a finer, auxdiary ezpun\u00adsion relation, and we apply the bwimulation up to exPan\u00adsion \ntechnique [25]: the expansion between processes is the largest relation < that verifies properties hke \n1-4, and such that VP,Q, ifP~Q, then Q ---+ Q implies P ~ Q or 3P , P ---i P ~ Q For example we have: \nfv(P) = 0 * P Fz o (1) PEQ~P 7s Q (2) x (u) # Y(u) (3) def z(t) D t(u) in ;(z) ~ def z(t) D t(u) in z(y) \n(4) z(x) # z(y) (5) def u(z) b w(z) in z(u) = z(w) (6) In (1) no process has any barb, and reductions \nare simulated by no reduction on the other side; in (3) and (4), the two processes don t have the same \nbarbs; in (5) the two names z and y can be distinguished in contexts as in (4); in (6), two distinct \nnames are sent on x, but their behaviour is the same in every context (although an internal reduction \nis needed to relay values from u to v), Despite technical differences in their definitions, H is also \nthe congruence over all contexts that is obtained from the weak, barbed bisimulation whose barbs are \n&#38;, as defined for the n-calculus in [20]. Such barbed congruences can be defined for many process \ncalculi, independently of their syn\u00adtaxes, and we take advantage of this common framework to obtain precise \nresults. 5.2.3 Full abstraction In all the following, we assess the relative expressive powers of miscellaneous \ncalculi from the existence of fully-abstract encodings between them, Definition 1 Let F l, Pz be two \nprocess calcula, wzth respec\u00adtwe equivalences WI C PI X PI, %Z C P2 X Pz. Tz is more expressive than \nPI when there ZS a fully ab\u00adstract encochng [ ]I+z from PI to P,: for all P, Q in P,, we have P =, Q \n~ [P]l_, =, ~Q]l+, PI and PZ have the same expressive power when each one as more ezpressave than the \nother. We use observational congruence as the reference equiv\u00adalence for each process calculus, meaning \nthat our full ab\u00adstraction results are up to observation in any context, This seems to be the finest \nresults one could expect between dif\u00adferent, process calculi.  5.3 Internal encodings The reflexive \nCHAM model corresponds to a join-calculus that IS convergent as the kernel of a programming language. \nHowever, it is possible to reduce it further to simpler prim\u00aditives. To this end, we successively remove \nrecursive scope, definitions with several clauses D A D, Join-patterns with more than two messages, and \nmessages with several trans\u00admitted values. We replace them by internal encodings, which we prove to be \nfully abstract, Our purpose here is to isolate the essential features of the join-calculus, and to give \nsome useful examples. Of course, all the derived features would be taken as primitives in a realistic \nimplementation. Theorem 1 The core join-calculus has the same ezpresstve power than the full jozn-calculus \nup to congruence; ~n par\u00adticular, there r.s a fully-abstract encodzng [ ]0 from the full calculus to \nthe core calculus: for all processes Q, R of the full join-calculus, Q=12 = [Q],%[R]o l% actual proof \nconsists of successive internal encod\u00adings of redundant features; in each part of this section, we explain \na stage of the encoding. We omit the proofs. Please note that the following encodings have been chosen \nfor their accuracy with regards to observation, and for their simplic\u00adity of exposition; as a result, \nthey may use busy-waiting, andintroduce in finite sequences ofinternal reductions; they are not meant \nto be used in practice to implement the fea\u00adtures that we remove from the join-calculus. Indeed, we plan \nto implement efficiently the full calculus directly from its reflexive machine specification. 5.3.1 Recursive \nbinding The non-recursive variant of the join-calculus is defined by restricting the scope of defined \nvariables in def D in P to P only, so that guarded processes inside of D cannot re\u00adfer to them. To get \nrid of the recursive usage of names in definitions, ourencoding simply shift the binding variables from \ndefinition to reception, Another name p is defined to hold formerly recursive names, and a message containing \nthe recursive names is always available on it. In particular the received variable PI is always bound \nto p each time a molecule is received. Lemma 2 Let ; be the vector of variables frJ(Q) n dv(J), and p, \npl be fresh vartables. We have: def JDQ inP < def Jlp(z, PI) > QIPl(~, Pl) in PIP(2, P)    5.3.2 \nComplex definitions We compile every complex definition with n-way join pat\u00adterns and/or multiple clauses \nconnected by A into several simpler definitions with only one pattern that joins at most two atoms. For \nthat purpose, we implement an invisible layer between the emitters and the guarded processes of the definition, \nthat makes explicit the automaton that matches messages and patterns. For clarity, we use the syntactic \nsugar developed for our language to present our encoding, except use the z(v) not ation to indicate as \nyncronous names, rather than capi\u00adtalization as in Section 4. We encode the definition D = JID PIA. . \n. J. D P.. Up to a-conversion, we may assume that patterns Jk joins messages of the form z, (~). Then, \nthe translation of def D in Q is: def getolset(;, Z) =return 3, fi to get let S,t = geto def x,(Z) = \nrun set(ii U {i}, ti{ti/~~ }) if zG 3then run z,(v, ) { . 1 let 3,Z = geto if s-kC Z def pk () = then \nrun ~klset(F S-k, Z) else run set(~, U) run ph () [ } run ph () The translation consists of a simple \ntwo-way-join defini\u00adtion that matches internal actions to an internal state (~, ~ that caches the current \npending messages on each of the defined names ~~ of D: ~ represents the set of names of avail\u00adable messages, \nand ; cent ains one of the pending values for these names, if any. For each Jk, the auxiliary process \ndefinition pk repeat\u00adedly checks whether the current state s contains all the de\u00adfined variables sk of \nJk, and triggers the guarded process l k when successful. For each xi, the new definition inserts values \nof messages in the current state. Notice that if another message is al\u00adready present, it is removed and \nre-sent on z,; this makes sure that the choice of messages that are present in the cache ~ can freely \nbe reconsidered until they are actually sent to apk. Lemma 3 If DQ as the translation dejined above, \nthen de fDin Q<DQ Hence, if [P] is defined as the join-term obtained from P by applying the above translation \nto all compound definitions m P, then [ ] M fully abstract. 5.3.3 Polyadic messages As in the -r-calculus, \nwe communicate tuples of names on auxiliary private names; we first describe the protocol for pairs: \nthe process OZ(U,ti) sends the pair u, v on z; the con\u00ad text I~U,ti)[P] extracts a pair u, v from a pair \nname p, then executes P. On the sender s side, an internal state w holds the next value to be returned \nto rw. Again, we use the syntactic sugar of the language to hide continuations: def rolw(z) =return z \nto r run w(u) d.f let z = ro Oz(u,.) = def rwo = run w(v) { return z to r-w }} I run x(rw) let u = to \nqu,.)[p] def = [ let v = to \\ (run P ) The translation of well-sorted polyadic processes is de\u00adfined \ninductively on processes; after a first encoding of tuples as nested pairs, we only have to describe \nthe translations for dyadic messages and definitions: [Z(U, v)] %f o Z(ti, u) [ def r(u, v)ly(w, z) D \nP in Q] def z (r) ly (t) = J{v,v, [If~,.)[[F lll def def z(r) = I~U,V)[O=I(ti,ti)l . def y(t) = Ifw,z)[OvJ(w,:)] \n{ run IQ] This encoding may appear redundant, as pairs are en\u00adcoded and decoded twice! However, this \nensures that only valid pairs are involved in the actual join-definition. With only one level of encodings, \nsome contexts that do not com\u00ad run set(O, 6) ply with our protocol may interfere, as is the case in the \nrun Q following example, where P H Q but C[P] # C[Q] . does not appear elsewhere in the terms. This \nmay involve P % def z(u)v)ly(w, z) Db(b) in z(z)lz(a, a)ly(a, a) Q % def z(u, v) IY(w, z) D b(b) in x(z) \nlb(b) C[ ] ~ def z(a) D(def t(~)bo in z(t))in [] Lemma 4 The encodtng [ ] 2s ~uily abstract. The core \nmonadic and the core polyadzc varzants of the ~om-calculus have the same expressive power. 6 A comparison \nwith the n-calculus Despite their syntactic differences, the join-calculus can be considered as an offspring \nof the ~-calculus, in the asyn\u00adchronous branch of the family. The latter was introduced independently \nin [7] as the (mini) asynchronous ~-calculus, and in [10] as the v-calculus. Both authors suppress the \nguards on emission, and compare the result to the original x-calculus. Going further in that direction, \nthe join-calculus is an asynchronous ~-calculus with the strong restrictions: e the three binders (scope \nrestriction, reception, repli\u00adcated reception) are syntactically merged in a single construct: the definition; \ne communication occurs only on defined names; a for every defined name, there is exactly one, replicated \nreception. There are several reasons to be interested in a formal comparison between the two calculi \nthe ~-calculus has been thoroughly studied; it is a reference calculus, and many results relate other \nformalisms or implementations to it [3, 17, 26, 28] Therefore, it is appealing to translate such results \nautomatically to the join-calculus. On the other hand, some issues are best addressed in the join-calculus, \nas for instance locality, implementation purposes, and explicit distribution. Besides. this also movides. \na deeD. insuzht into what is common and what is different in the join-calculus and in the n-calculus. \nBoth encodings that are used to get our most precise results are complex, but their underlying Ideas \nare simple. In particular, much simpler encodings can be obtained in less general settings; for instance, \nprograms written in PICT and programs in the language presented in section 4 would use very similar implementation \ntechniques, Using the results of the previous section, we consider the recursive, polyadic join-calculus \nwith at most two-way-join definitions as the target calculus to encode the m-calculus, and its monadic \nvariant for the reverse encoding, We first recall the definition of the asynchronous n-cal\u00adculus; then \nwe encode the n-calculus in the join-calculus, The first, naive encoding replaces each channel of the \nmcal-CUIUS by a two-way definition; however, some more work is needed to achieve full abstraction. We \npresent our approach based on [fireballs in detail, but we defer the presentation of the proof to annex \nA. In the same manner, we then en\u00adcode the join-calculus in the ~-calculus using the straight\u00adforward \ntranslation of definitions into sco~e-restriction and . replicated reception. Using the same approach, \nwe also need to refine the encoding. The sketch of the proof can be found in annex B. In all our encodings, \nwe will assume that every name that is introduced in the translation rules is a fresh name that some \na-conversion. 6.1 The asynchronous n-calculus To study this relationship, we precisely compare the jom\u00adcalculus \nto the asynchronous ~-calculus. We use the syntax of MiIner in [18]. Without loss of generahty, we allow \nonly monadic messages, and replicated input instead of more gen\u00aderal recursion. P ~f P\\Q I VU.P I EU \nI z(u).P I !z(u).P Following the observational approach of [10, 11, 13], the congruence %. is defined \nfor the w-calculus as the asyn\u00adchronous barbed congruence whose barbs are the emissions on free channels. \nTheorem 2 The join-calculus and the summatton-free asynchronous ~-calculus have the same expressive power, \nup to their weak output-only barbed congruences. 6.2 Asynchrony, Relays and Equators Our encodings essentially \nrely on the properties of the asyn\u00adchronous reduction-based n-calculus as discussed in [11, 12], and \non similar properties of the join-calculus. In both calculi, it is not possible to observe the reception \nof a message; for instance we have Z(U) .ZU X7 O, and it is not possible either to distinguish between \ntwo different names that have the same external behaviour. We Illustrate the latter with a defimtion \nof equators between names: M Z>v :f !Z(u),ljul!y( v).?ik This process repeatedly receives values from \nz and forwards them to y and vice-versa, so that no matter which name z or y is used to send a value, \nit can always be made avadable for reception on the other name in one internal reduction: Lemma 5 FOT \nall 7r-processes P, Q 6.3 Encoding the r-calculus 6.3.1 Naive structural definition To each channel \nz of the n-calculus, we associate two names XO for output, x, for input, and an enclosing definition \nthat matches output and input The emitter simply sends values on zo; the receiver defines a name for \nits continuation, and sends it as a reception offer on z,: For example, we translate the following ~-process \nand its reduction vz. (?talillz(u) @L) -+ v.z.(~al~b) to the join-process and the series of reductions \ndef zO(VO, v,) Iw(K) D K(vO, w,) in ~o(%,~i)l~o(%?~l) I def K(UO,U;) Dyo(uo,u,) in z,(m) def K(uo, w) \n~ yo(%, ut) ++ in def z~(v~,v~)lz,(~) D K(vO, W) in zO(aO, a,)lyO(bO, b,) In the same manner, any reduction \non a bound name in the ~-calculus can be simulated by a join-reduction followed by a deterministic reduction \nin the join-calculus, and conversely any reduction in a join-calculus translation belongs to one of these \ntwo cases, and can be simulated in at most one reduction in the m-calculus. 6.3.2 Full abstraction of \nthe encoding Unfortunately, the previous encoding does not reflect the behaviour of processes of the \n~-calculus when placed in an arbitrary join-calculus context: the protocol relies on the presence of \nspecific definitions for every free name, while the context may define them in some other way. For example, \nthe translation [?ial~b[z(ti) .VU] = cannot re\u00adduce anymore, because there is no englobing Pm, Worse, \n[Z(U) .ZU]= exhibits a barb on z, that reveals the presence of an input for x, and allows a context to \ndistinguish this pro\u00adcess from O. And because of mobility, it would not be enough to supply a correct \ndefinition of go, z, for every translated free name, since a context would still be able to forge a Notation: \nWhenever a context defined with a name index appears without this index, it stands for the ap\u00adplication \nof the context for at least all the free variables in the ~-term, and for a definition for p. For instance, \n&#38;[[zy]*] =f A4[tz[t,[[zy]=]]. Theorem 3 For all processes Q, R m the n-calculus, Q X. R ~ &#38;[[Q]~] \nw S[[R]X] Note that E catches all the free variables of PIQ. In the proof, we also give an auxiliary \nencoding that is strictly compositional.  6.4 Encoding the join-calculus The reverse translation is \nsimpler, because the join-calculus is somehow the T-calculus with restrictions on communica\u00adtion patterns. \nHowever, a careful encoding is needed to pre\u00advent contexts of the ~-calculus from read~ng messages from \nthe names they receive from the translation. 6.4.1 Structural definition [Ql~lj = [Qlj IIRI1 [z(v)], \n= - o [clef z(u)ly(v) D Q in R]j A vzy.(!x(u).y(v), [Q]j\\[R]j) message XO (z, t)from some of its own \nnames .z, t with arbi\u00adtrary definitions. To protect the translation from hostile contexts, the names \nresulting from the free channels of the ~-term must set -up a %rewall that enforces the protocol. We \nrefine our first idea: each channel z is now represented as several pairs z., Z. from the naive encoding \nthat cannot be distinguished from the outside. Two pairs are merged by repeatedly com\u00admunicating their \npending messages to one another. New pairs are defined at run-time according to the following se\u00adcure \nprotocol: e Whenever a pair of names is received from the outside, the firewall defines a new, correct \npmmy pair, merges it to the external pair, and transmits the new pair instead. Whenever a pair of names \nis sent to the outside, a new firewall is inserted to setup proxies for future messages on this pair. \n As a result, the translation and the context never exchange names from a syntactic point of view. We \nuse the following contexts to build the firewall on top of the naive translation: For every free name \nz, P. encodes the creation of a new proxy for its output. E. does the same, and also exports the proxy \non a conventional free name z.. Finally, M recur\u00adsively defines the proxy creator p for the whole translation. \nReductions in n-calculus translations correspond exactly to the reception of messages in join-patterns. \nIn the trans\u00adlation, we loose the symmetry between z and y and the atomicity of their join-reduction, \nbut it does not matter as scope restriction and [ ]J guarantee that these details cannot be observed. \nAgain, the translation reveals too much about the source process, as a context of the n-calculus could \nstart reading values on names bound in the translation of definitions, In\u00addeed, if we were translating \nthe join-calculus into an asyn\u00adchronous ~-calculus extended with a type system with polar\u00adities [22], \nwe could specify write-only types for every chan\u00adnel that is communicated inside of the translation, \nand the (typed) previous encoding would already be fully-abstract. 6.4.2 Full abstraction To obtain \nour second full abstraction result, we also need to build a firewall. The interface recursively sets \nup one\u00adway relays for every name that crosses the boundary. It is built from the following terms, with \nthe same convention on !z(7J).7we .(Fw=vpjwe) m-.!r(~,ze).RZZCl[ ]) VZ(RZ=.111) R is a global definition \nfor the translation, which sets up one-way relays Rzze or Rzz, from the first to the second of its argument. \nWhen a relay forwards a message, it also sets up a relay going in the reverse direction for the trans\u00admitted \nvalue. There is no syntactic scope extrusion of the translations of definitions, and their synonym can \nalways receive messages. We use the same notation convention as before: S [P]J stands for the application \nof 7? followed by applications of &#38;l for at least all free variables of ~ of P. Theorem 4 For all \nprocesses Q, R in the join-calculus, Q s R -&#38; [[Q],] X= &#38;*[[R],] 7 Future work Many interesting \nissues on the join-calculus are outside the scope of this paper. They include actual implementation techniques, \ntype systems and in particular linear types for the names that represent continuations, as in [22, 14, \n27], extensions of the calculus with records for a better support of object-oriented programming. Observation \nand equiva\u00adlences also deserve a more detailed treatment, as well as a comparison with their counterparts \nin the asynchronous 7r-calculus. To conclude, we briefly mention our current usage of the reflexive CHAM \nand of the join-calculus in a programming language design where resources and environments are ex\u00adplicitly \ndistributed, while the details of the network and its connectivity remain hidden. In a practical distributed \nset\u00adting where some sites may fail, the atomicity of each inter\u00adaction must be specified accurately [3], \nin a way that can be implemented locally. The join-calculus relieves us of many difficult issues: As \nsynchronization can only happen on def\u00adinitions, it is sufficient to require each definition to be an\u00adnotated \nwith some location, that is shared by all its names and guarded processes. Likewise, the actual allocation \nof re\u00adsources for a definition such as waiting queues, automaton, and closures, happens locally as the \ndefinition is activated using the chemical rule (str-def). In that setting, messages are forwarded to \ntheir definition asynchronously, then han\u00addled locally. We currently study extensions of the reflexive \nCHAM and of the language that provide explicit control of the localization of definitions on several \nsites, and possibly their imperative migration from one site to another. This would make intensive interaction \nmore local, and would pro\u00adtect it from local failure. A distributed prototype is under way, to assess \nthe feasibility and the interest of a distributed implementation of process calculi. Acknowledgments \nThis works started from a seminar on distributing the n\u00adcalculus held in 1995 at INRIA, with the participation \nof Damien Doligez, Florent Guillaume, Jean-Jacques L6vy, Luc Maranget, and Didier Remy. We also thank \nRoberto Ama\u00addio, Gerard Boudol, Xavier Leroy, Benjamin Pierce, Da\u00advide Sangiorgi, and David Turner for \nfruitful discussions and comments. References [1]G. Agha, 1, Mason, S. Smith, and C. Talcott. A foun\u00addation \nfor actor computation. Technical report, UIUC, 1993. [2] G. A. Agha. Actors: a Model of Concurrent Compu\u00adtation \nin Distributed Systems. MIT Press, Cambridge, MA, 1986. [3] R. Amadio and S. Prasad. Localities and failures. \nFoun\u00addations of Software Technology and Theoretical Com\u00adputer Science, 14, 1994. [4] J.-M. Andreoli and \nR. Pareschi. Communication as fair distribution of knowledge. In Proceedings O OP-SLA 91, ACM SIGPLAN \nNotices, pages 212 229, Nov. 1991. Published as Proceedings OOPSLA 91, ACM SIGPLAN Notices, volume 26, \nnumber 11. [5] J.-P. Baniitre, M. Ban&#38;tre, and F, Ployette. Distributed system structuring using \nmulti-functions, Rapport de Recherche 694, INRIA Rennes, June 1987. [6] G. Berry and G, Boudol. The chemical \nabstract ma\u00adchine. Theoretical Computer Sczence, 96:217 248, 1992, [7] G. Boudol, Asynchrony and the \nn-calculus (note). Rap\u00adport de Recherche 1702, INRIA Sophia-Antipolis, 1992 [8] L. Cardelli. A language \nwith distributed scope. Com\u00adput~ng Systems, 8(1)27-59, Jan. 1995, A preliminary version appeared in Proceedings \nof the 22nd ACM Sym\u00adposium on Principles of Programming Languages. [9] A. Giacalone, P. Mishra, and S. \nPrasad. FACILE: A symmetric integration of concurrent and functional pro\u00adgramming. International Journal \nof Parallel Progr-am\u00admmg, 18(2):121 160, 1989. Also in TAPSOFT 89, ed. J. Diaz and F. Orejas, pp. 184-209, \nSpringer-Verlag, Lecture Notes in Computer Science 352 (1989).  [10] K. Honda and M. Tokoro. An object \ncalculus for asynchronous communication. In P, America, editor, Proceedings ECOOP 91, LNCS 512, pages \n133-147, Geneva, Switzerland, July 15-191991. Springer-Verlag. [11] K. Honda and M Tokoro, On asynchronous \ncommuni\u00adcation semantics. In P. W. M. Tokoro and O. Nierstrasz, editors, Proceedings of the ECOOP ~91 \nWorkshop on Object-Based Concurrent Computtng, LNCS 612, pages 21 51. Springer-Verlag, 1992. [12] K. \nHonda and N. Yoshida. On reduction-based pro\u00ad cess semantics. Foundations of Software Technology and \nTheoretical Computer Sczence, 13, 1993 [13] K. Honda and N, Yoshida, Combinatory representation of mobile \nprocesses. In Proceedings POPL 9~, 1994. [14] N. Kobayashi, B. C Pierce, and D. N. Turner, Linearity \nand the pi-calculus. In Proceedings POPL 96, 1996. [15] L. Maranget. Two techniques for compiling lazy \npattern matching. Research report 2385, INRIA, 1994, [16] R, Milner. Communtcat~on and Concurrency. Prentice \nHall, New York, 1989. [17] R. Milner. Functions as processes. In Automata, Lan\u00adguages and Programming \n17th Int. Coil., volume 443 of LNCS, pages 167 180. Springer Verlag, July 1990 [18] R. Mdner. The polyadic \n~-calculus: a tutorial. In F. L. Bauer, W. Brauer, and H. Schwichtenberg, ed\u00aditors, Logic and Algebra \nof Specification. Springer Ver\u00adlag, 1993.  [19] R. Milner, J. Parrow, and D. Walker. A calculus of \nmo\u00adbile processes, parts I and II. Information and Compu\u00adtation, pages 1-40 &#38;41-77, Sept. 1992. [20] \nR. Milner and D. Sangiorgi. Barbed bisimulation. In Proceedings ICALP 92, LNCS 623, pages 685-695, Vi\u00adenna, \n1992. Springer-Verlag. [21] B. C. Pierce, D. R&#38;my, and D. N. Turner. A typed higher-order programming \nlanguage based on the pi\u00adcalculus. In Workshop on Type Theory and its Appli\u00adcation to Computer Systems, \nKyoto Universityj July 1993. [22] B. C. Pierce and D. Sangiorgi. Typing and subtyping for mobile processes. \nMathematical Structures in Computer Science, 1995. To appear. A summary was presented at Hcs 93. [23] \nB. C. Pierce and D, N. Turner. Concurrent objects in a process calculus. In T. Ito and A. Yonezawa, editors, \nTheory and Practice of Parallel Programming (TPPP), Sendai, Japan (Nov. 199~), number 907 in Lecture \nNotes in Computer Science, pages 187 215. Springer-Verlag, Apr. 1995. [24] B. C. Pierce and D. N. Turner. \nPitt: A programming language based on the pi-calculus. Technical report in preparation, 1995. [25] D. \nSangiorgi and R. Milner. The problem of weak bisimulation up to . In W. R. Cleaveland, editor, Proceedings \nof CONCUR 92, LNCS 630, pages 32-46. Springer-Verlag, 1992, [26] G. Smolka. A foundation for higher-order \nconcurrent constraint programming. In J.-P. Jouannaud, editor, Ist International Conference on Constraints \nin Com\u00adputational Logzcs, Lecture Notes in Computer Science, vol. 845, pages 50 72, Miinchen, Germany, \n7 9 Sept. 1994. Springer-Verlag. [27] D. N. Turner. The ~-calculus: Types, polymorphism and Implementation. \nPhD thesis, LFCS, University of Edinburgh, 1995. In preparation. [28] D. Walker. Objects in the pi-calculus. \nInformation and Computation, 116(2):253-271, 1995. A Sketch of the proofs of section 6 Notation: In all \nthe diagrams that follow, we use the usual conventions : for all relations on plain lines, there exists \nrelations on dotted lines, and stars denotes the reflexive\u00adtransitive closure of a relation.  A.1 Su \njm is fully-abstract A.1.l Combining translations and con\u00adtexts We first prove the direct implication \nby studying how a translation can interact with an arbitrary join-calculus con\u00adtext. This is performed \non an auxiliary translation that is very similar to [ ]T: Definition 2 The translation [ ] maps x-processes \nto Join\u00adprocesses using the same structural definition that for [ jr, except for scope restriction (so \nthat output always leads to the creatzon of a new proxy pair), and for unguarded outputs (where the definition \nof XO is unfolded): [VZ.P] 2 P.[[P]] [EU] % P. [zt(z~, Z,)[[M~,ti]=] (when unguarded) Definition 3 Hybr~d \nterms are terms of the Join-calculus that are structurally equivalent to some 7 [El [Q]], where E is \na ~oin-calculus process, Q is a ~-calculus process, and P is an header of definitions such that for all \nfree names x in Q, Pz appear-s in P, and such that every message on xl channels matches some xl (vO, \nv, ) where P. appear-s m P. In particular, the processes &#38; [[Q]] that appear in the theorem are hybrid \nterms. We now study reductions inside of hybrid terms. These reductions can be: 1.reductions that use \nthe join-definition of some Z1, Z;, which correspond to reductions in the ~-calculus; 2. reductions that \nmanipulate pairs of synonyms, or trig\u00adger continuations K, which are induced by the encod\u00ading; 3. reductions \ninside of E, which are independent of the translation.  We are mostly interested in the first family \nof reductions. To get rid of the details of the encoding, we first define two auxiliary expansions to \nrelate hybrid terms that differ only because some deterministic reduction hasn t been performed yet, \nor because some extra synonyms have been introduced for pairs zO, z,. Then we use the weak bisimulation \nup-to expansion technique [25]. Lemma 6 Let +de~ be the relation on ~otn-processes that contains all \npairs of determanzstic reductions; ~~c, ~~f (_+&#38;~ )*; <~., ~sf~~,~,. Then ~~.,, is a barbed expansion. \nLemma 7 Let +,.,,~. relates hybr%d terms with one addz\u00adtaonal pair of synonyms on the left-hand-sxde: \nPP.,V [E[~Q]l[M;,Y]T] +,,,.,., PP. [E[[Q]] { /,} d, < _r,lcrge = (-k)- . Then <,..,.. is a barbed expansion. \nLemma 8 E [[Q].] = 2 [IQ]] Lemma 9 The reductions m the ~-calculus can be mim\u00adicked on thew translat~ons: \nif Q --+* Q , then P [[Q]] +* (~~,,~,,,.,.,. )*P [[Q ]] Lemma 10 For all pair of hybrid terms P [El [Q]], \nP [EIIR]] , if Q % R, then P [EIIQ]] x P [EIIR]] Proofi Let the relation B contains all the pairs of \nhybrid terms that are obtained from congruent m-processes: VQ =m R. PIEIIQ]] B P [EIIR]] We establish \nthat B C =. To this end, we distingmsh among the reactions that may happen on the left-hand-side hybrid \nterm, and in each case simulate it on the right-hand\u00adside. We consider four cases: Reduction outside \nof the translation: they are the same on both sides. Reduction inside of the translation: a communication \noccurs bet ween a reception offer and an output; it corre\u00adsponds to a communication in the original ~-term, \nexcept that as the value is received, a new proxy is created, and that several deterministic reductions \nmay be necessary to reach an hybrid term. On the right side, we use Q == R to obtain a sequence of reductions \n1? ~ R , and we mimic them in the translation. * i I I Intrusion of a pair of channels from the environment \ninto the translation: The receiving m-term Q is of the form vti. (Q \\x(z). Q ), whale there is a correct \npending value ZI (z., z,) in the join-calculus and a definition to match them. We first use an auxiliarv \n. commutative dia~ram to msh. the emission under the translation. Using our lemma, we can then build \nreductions for the right term, and with a few de\u00adterministic reductions on the bottom left, we get a \nnew pair in B. On both sides, we use our expansions on hybrid terms to switch Z1 (zO, z,) and ~Zz]. zz@.(Q \n\\z(z).Q ) =--?iz\\R it v;.(Q ]Q ) --.::.. R I  I_ * > - . ----P [El[vz.(Q lQ )jl -~------+ Extrusion \nof a pair of channels from the translation to the environment: the emitting n-term is of the form Q = \nvu (Q I?iy), where possibly u = y. If 1, u are fresh names, we get a similar emission for R by applying \nthe congruence Q == R to the context O [ ] % ~ulz(y).l(u),Lf~Zl [ ] : CJ [rm.(Q lzy)] = O [R] ,I In the \ndiagram, the reductions on the right can be reordered as internal reductions in R, followed by the two \nreductions on z, 1 with O From the first ones, we build the correspond\u00ading reductions from the translation \non the right to a term that is an expansion of vu . (R lM~,, ). P [E [x, (~)] IIvu.(Q IZY)]] ~ P [E [z,(.)] \nIIR]] I * P [E [/c(z., z,)] IIvu.(Q IM;,Z)]] ~-~------+ From the previous diagrams, and as ~ 1? z IS \na congru\u00adence and respects the barbs, we obtain by defimtion of x that (~ B X) c s, and in particular \nB c x 0 A.1.2 Correctness We need yet another translation that is fully compositional: each term is \nwrapped in a protective context, at each step of the structural definition; conversely, the names of \neach subterm must be made synonym for the names in the current term: Definition 4 The translation [ ] \nmaps ~-processes to jotn\u00adcalculus processes: with the followzng defintt~ons (and wath the convention \non tndtces) Z catches exported synonyms for channels in the scope of the context. ~ prevents extension, \nthus providing locality, Lemma 11 VQ, [Q] % S[Q] Proof: In each case of the structural induction, we \nuse variants of the relatlon &#38;ml~&#38;* [P] ~~,.+, ~,,,., g, E. [P]. We present two significant cases \nE To obtain a bisimilar hybrid term on the other side, we Proof: x S[R]} is a barbed congruence in {( \nQ,~), &#38;[Ql the r-calculus: The congruence follows from the previous result and the congruence property \nof %. &#38;[C [Q]] = [C [Q]] = ([C]) [[Q]] R ([C]) [8[Q]] The asynchronous barbs are the same: They can \nbe in\u00ad dividually tested in simple contexts. The bisimulatlon is obtained from previous lemmas. 0  A.2 \n&#38;n u 13 is fully-abstract In this part, we use conventions for names: In the ~-calculus, Z~ is a \nfree variable of the translation, that corresponds to the external name z. In the join-calculus, we introduce \nfor each name z another name, ~, that may appear at most once in a process, and only as the port name \nof an unguarded message ~(y); we note P a process that may contain these messages. Such messages will \nkeep track of internal names y that have been exported to the context; to this end, we adapt [ ]J to \ntranslate them into incoming relays. Definition 5 A hybrid term is a term of the x-calculus that ts structurally \nequivalent to wheTe ~ M any context oj the fi-caicuhso~ the form ufi(l?~[ ]), and where ~ is a jom-pr-ocess \nwith possibly some unguarded messages Z(Z), such that its fr-ee variables ar-e m {~, ~}. Lemma 13 Lemma \n14 Let ~J_r be the largest expanston between the ~-calculus and the ~om-calculus that respects barbs. \nThen for all ~om-process P we have P ~J_~ [P],. Lemma 15 The relation that contains all pairs of hybrid \nterms whose extended ~oin-pr-ocesses are congruent is a barbed congruence m the r-r-calculus. Proofi \nThe congruence property is obvious; the bisimula\u00adtion requires a case analysis, which will also establishes \nthat barbs are preserved. We study in more details the inter\u00adactions between the translation and its \n~-context, and the set-up of new relays. Four kinds of reductions may occur: External communication: \napply the same one on the other side. Intrusion of an external message is received on an incom\u00admg relay: \nthe messages is withdrawn from the m-calculus context, and committed to an internal usage; except from \nthe first step which prevents the input of the message in the context, the following steps are deterministic, \nand lead to a new hybrid term. use the join-calculus context: 0,[ ] ~f def ~(z) D ~(z) in def ~(z) P \nz(u) l~(z) in [ ] Both join-processes have a barb on ~ that is necessarily a single, unguarded message \nConsuming ~ on both sides leads to a pair of congruent processes. We then discard the useless definition \nof ~(z), and wrap both processes as a new pair of related hybrid terms. Internal reduction on the translation \nof a definition: us\u00ading x in the join-calculus, we obtain a sequence of reductions on the left side, \nand mimic it in the translation. Some de\u00adterministic reductions ma be needed on both sides to reach a \nhybrid term. Extrusion by internal reduction on an export relay: in a few deterministic reductions, messages \non translations of free variables are exported to their public n-calculus name:  c p;p[z(x)]],] +;et \nc [Vz(z+;[q;(z)]],] We use the following context CIe to obtain an adequate sequence of reductions on \nthe right side: the first emission on .zJ is handled in a special way, while the next ones are silently \ntransmitted. def eo D O in def a(u)l10 D u() in def z (z) D z(z) 0. [ ] : in def z(x)[c(R) D K(z) Ic(z \n) in def Kl(x) D ~(z)la(e) in c(~l)la(d)[lo [ ]  (9. [F[z(z)]]--=-0. [q 3] * + ~+ .-. . ------.  P[2U]% \nL Q @ has no barb on c; we can reorder the reductions on the right to defer interaction with the context \nO=, to obtain a sequence of reductions to mimic in the translation. 0 Lemma 16 for all P, Q m the ~otn-calculus, \nPxQ a S [P] , XT &#38; [Ql, Definition 6 We use the compositional encodtng [ ]3 where D = z(u) ly(v) \nD Q to obtain the second half of the theorem: [QIRI, 2 [Q], l[Rlj  [X(v)]j ~f I&#38;[qv, )] [ def D \nin R]j :f vzy.((!z(u).y(v) .[Q]J)l[R]3) Lemma 1 7 For every join-process Q with free varzables ~, [Q], \nx (5;[Q]j We conclude verse translation. using the same argument that for the re\u00ad  \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "C&#233;dric Fournet", "author_profile_id": "81100547450", "affiliation": "INRIA Rocquencourt, 78153 Le Chesnay Cedex, France", "person_id": "PP14190246", "email_address": "", "orcid_id": ""}, {"name": "Georges Gonthier", "author_profile_id": "81100568047", "affiliation": "INRIA Rocquencourt, 78153 Le Chesnay Cedex, France", "person_id": "P96170", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.237805", "year": "1996", "article_id": "237805", "conference": "POPL", "title": "The reflexive CHAM and the join-calculus", "url": "http://dl.acm.org/citation.cfm?id=237805"}