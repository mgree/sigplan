{"article_publication_date": "01-01-1996", "fulltext": "\n Revisiting Catamorphisms over Datat-ypes with Embedded Functions (or, Programs from Outer Space) Leonidas \nFegaras Tim Sheard llepartment of Computer Science and Engineering Oregon Graduate Institute of Science \n&#38; Technology 20000 N,W. Walker Road P.O. Box 91000 Portland, OR 97291-1000 {fegaras,sheard} &#38;se \n.ogi.edu Abstract sively with the cat amorphlsm. The anamorphism is nec\u00adessary if a recursive datatype \ndefinition has contravariant We revisit the work of Paterson and of Meijer &#38; Hutton, occurrences \nof the type being defined. The purpose of the which describes how to construct catamorphisms for recur-anamorphism \nis to undo what the catamorphism does . sive datatype definitions that embed contravariant occur-The \ninverse-like relationship of f and g is necessary to rences of the type being defined. Their construction \nre-correctly handle the contravariance of the datatype defini\u00adquires, for each catamorphism, the definition \nof an anamor-tion. This approach requires a proof of the inverse-like re\u00adphism that has an inverse-like \nrelationship to that cata-lationship between ~ and g. In general there is no known morphism. We present \nan alternative construction, which automatic way to obtain such a proof. replaces the stringent requirement \nthat an inverse anamor-Our trick involves inventing a particularly simple inverse\u00adphism be defined for \neach catamorphism with a more lenient like function to take the place of the anamorphism. This restriction. \nThe resulting construction has a more efficient method is simple, not only because it does not require \nan implement ation than that of Paterson, Meij er, and Hutton actual definition of the inverse-like function \ng, but also be\u00adand the relevant restriction can be enforced by a Hindley-cause it gives g a highly efficient \nimplemental ion. The trick Milner type inference algorithm. We provide numerous ex-does not always apply, \nbut we present a type system that amples illustrating our method. determines statically when it is applicable. \nIn this paper we give numerous examples illustrating the usefulness of being able to define catamorphisms \nover Introduction datat ypes with embedded functions, as well as showing how to define functions as catamorphisms. \nFunctional programmers often use catamorphisms (or fold functions) as an elegant means of expressing \nalgorithms over algebraic dat atypes. Catamorphisms have also been used  2 Structures with Functional \nare Useful by functional programmers as a medium in which programs can be calculated from specifications \n[7, 6, 5] and as a good In this section, we present several examples of data struc\u00adintermediate representation \nof programs that supports op-tures with embedded functions. We define catamorphisms timization [14, 3, \n4, 1]. It is, thus, truly ironic that these over these structures and give many examples of their use. \nfunctions apply only to first order datatypes. We informally introduce our method and explain how it \nUntil recently, it was not known how to express catamor-works. Our first example is an evaluation function \nover a phisms for datatypes with embedded function types. The datatype that represents closed terms in \na simple lambda work by Paterson [10] and Meij er &#38; Hutton [8] finally pro-calculus. This representation \nis interesting because the eval\u00advided a method for doing so. While elegant and theoretically uation function \ndoes not need an environment mapping vari\u00adsound, their solution suffers from the disadvantage of being \nables to values. The second example is the expression of the somewhat inefficient. This paper extends \ntheir technique us-parametricity theorem for any polymorphic function. The ing a simple t n ck that results \nto more efficient programs and third example is the expression and manipulation of circular turns out \nto also have several other interesting applications. lists in a functional language, and the last example \nis the Meijer and Hutton point out that in order to express a expression and manipulation of graphs. \nAll the functions function ~ as a catamorphism over an arbitrary datatype in these examples can be expressed \nsuccinctly as catamor\u00adit is necessary to express another function g as an anamor-phisms. phism (or unfold \nfunction) which is defined mutually recur\u00ad 2.1 Meta-programming Permission to make digitallhard copies \nof all or pafi of this material for personal or classroom use is granted wi~out fee provided hat the \ncopies 2.1.1 Lambda Calculus are not made or distributed for profit or commercial advantage, the copy\u00adright \nnotice, the title of the publication and its date appear, and notice is Our first example of a function \nover a data structure withgiven that copynght is by permission of the ACM, Inc. To copy otherwise, to \nrepublish, to post on servers or to redistribute to lists, requires specific embedded functions is an \nevaluation function for a datatype permission andfor fee. POPL 96, St. Petersburg FLA USA @ 1996 ACM \n0-89791-769-3/95/01. .$3.50 that represents closed terms in a simple lambda calculus. We represent terms \nas structures with embedded functions in a manner similar to the higher-order abstract syntax rep\u00adresent \nation of programs by Pfenning and Elliot [12] (all our examples are written in Standard ML (SML) [11]): \ndatatype Term = Const of int I Succ / Appl of Term x Term I Abs of Term + Term For example, the lambda \nterm (kc.1 + z) 1 is represented by the Term construction Appl(Abs(fn x ~ Appl(Succ,x)),Const 1) This \nterm representation can be traced back to Church s seminal work on the lambda calculus [2], in which \nuniversal quantification VZ.A is modeled by the addition of a con\u00adst ant II and by writing II ( Jz. A). \nThis representation is also similar to the higher-order abstract syntax representation of programs, formulas, \nand rules by Pfenning and Elliot [12], and is also related to the work of Nadathur and Miller [9] on \nhigher-order logic programming. The datatype definition for Term differs from most in that in most lambda \nterm representations, lambda abstrac\u00adtions are constructed by value constructors oft ype varia ble x \nTerm + Term, and most representations also include con\u00adst ruct ors like Var of type variable -+ Term. \nIn such repre\u00adsentations, an operation over lambda terms needs to handle variables explicitly. For example, \na lambda-calculus evalua\u00adtor typically needs to build and manipulate an environment to bind variables \nto values. In our representation the ab\u00adstraction mechanism of the meta-language (SML) is used to represent \nabstraction in the object language of lambda terms and thk completely finesses the bound-variable nam\u00ading \nproblem, Our evaluator is thus spared the difficulties and complex\u00adit y associated with the explicit \nrepresent at ion of variables, since all the necessary variable plumbing, in beta reduction, etc., is \nhandled implicitly by the evaluation engine of SML in which our evaluator is expressed. But the benefit \nof our approach is more than just pedagogical: one can experiment with various types of evaluators without \nworrying about the details of names and variable binding. Representations like this have been avoided \nbecause of the difficulty of expressing cert tin kinds of computations. The Paterson/Meijer/Hutton Approach \nWe now present an evaluator for terms in the style of Pa\u00ad terson [10], and Meijer &#38; Hutton [8]. We \nuse explicit recur\u00ad sion instead of catamorphisms to make it clear how it works and to illustrate the \ninefficiencies of this approach. Our ap\u00ad proach, which improves this method, is described in detail in \nthe next subsection. The value domain of our evaluator is datatype Value = Num of int I Fun of Value \n+Value The value domain itself uses embedded functions to rep\u00adresent the meaning of functional terms \nin the lambda cal\u00adculus. The lambda term evaluator is a function of type Term -+ Value and could be expressed \nas: fun eval(Const n) = Num n I Q al(s cc) = Fu. (fn N.m n =+-N.m(n+l)) I eval(Appl(f,e)) = (case eval(f) \nof Fun(g) + g(eval(e))) I eval(Abs f) = Fun(g?) But it is not obvious what g? in the last clause should \nbe. The type of g? should be Value + Value. The function f of type Term + Term must somehow be manipulated \ninto a value of type Value + Value. Based on type considerations alone, one might attempt to construct \ng? as a composition of f with a function oft ype Term + Val ue on the left and a func\u00adtion of type Value-+ \nTerm on the right. The obvious choice for the first function is eval. The second function, which we call \nreify, translates values into terms. The function reify should be the right inverse of eva I on the range \nof eva 1, i.e., for all z in the range of eval the identity eval(reify(x)) = x should hold. Without this \nrestrict ion, eva I would fail to eval\u00aduate even the simplest abstraction, namely Abs(fn x + x), into \nthe correct result Fun (fn x + x). Since term evaluation is not an isomorphism in general, we have many \ndifferent choices for reify. As a first pass at a definition of reify, we might reasonably try: fun eval(Const \nn) = Num n I eval(Succ) = Fun(fn Num n ~ Num(n+l)) I eval(Appl(f,e)) = (case eval(f) of Fun(g) + g(eval(e))) \nI eval(Abs f) = Fun(eval o f o reify) and reify(Num n) = Const n I reify(Fun f) = Abs(reify o f o eval) \n Notice the symmetry between eva I and reify. In particular, the way reify handles the embedded function \ninside FLJn is the mirror image of the way eva I handles the embedded function inside Abs, It is instructive \nto visualize the process that occurs when an Abs term is evaluated. An abstraction is built that will \nbe placed within a Fun constructor. This abstraction, when applied, will reify its argument to get a \nTerm, then apply f to get another Term, and finally evaluate this term to get a Value. For example, the \nevaluation of the term (k. x + 1) 1 proceeds as follows: eval(Appl(Abs(fn x ~ Appl(Succ,x)),Const 1)) \n= case eval(Abs(fn x + Appl(Succ,x))) of Fun(g) ~ g(eval(Const 1)) = case Fun(fn x a eval(Appl(Succ, \nreify x))) of Fun(g) ~ g(eval(Const 1)) The abstraction in the case is eventually applied to a term, \nwhich must itself be evaluated. The above thus equals eval(Appl(Succ, reify (eval(Const l)))) = eval(Appl(Succ, \nreify(Num l))) = eval(Appl(Succ, Const 1)) = case Fun(fn Num n ~ Num(n+l)) of Fun(g) a g(eval(Const l)) \n= (fn Num n ~ Num(n+l)) (Num 1) = Num 2 We can see that there is some computational redundancy in the \nevaluator. Some terms, such as Const 1, are evalu\u00ad ated only to be reified later on. In general, if we \nreduce Appl(Abs(f),e), where e is a complex term, then we get eval (f(reify(eval (e)))). That is, the \nterm e is evaluated into a value, and then this is reified into a term, then this term (after reduction \nby f) is evaluated again into a value by the out er occurrence of eva 1. This is the general scheme within \nthe eva I-reif y example: reify will undo what eval has done, eva I will partially redo what has been \nundone, and so on. This problem becomes increasingly worse with the complex\u00ad ity of function f. For example, \nto define a printer print for Term, which is a function from Term to string, it is neces\u00ad sary to define \na parser parse from string to Term with the needed. property print (parse(x) )=x. The computational \ncomplexity datatype a Term = Const of int I Succ of the parser is linear in the size of the input string. \nBut, I Appl of CYTerm x ~ Term as we will see next, in many cases, an approximate right \\ Abs of a Term+ \nCYTerm inverse of print with constant time complexity is all that is \\ Place of C2 These dual mutually \nrecursive definitions have been ex\u00adplored by Paterson [10] and Meijer &#38; Hutton [8]. They use a pair \nof generic dual functions, cat amorphism and anamor\u00adphism, to capture recursion schemes similar to the \none in the eval-reif y example: a catamorphism will reduce a value of type T into a value of type S while \nan anamorphism will generate a value of type T from a value of type S. Our Approach. To avoid the computational \nredun\u00addancy of eval and to find a way around the problem of find\u00ading a right inverse for eva 1, we return \nto the initial problem of expressing g? as eval o f o h?. In particular, the crucial property of h? with \ntype Value -+ Term is that it satisfies eval o h? = Ax.x. In addition, this should happen with no computational \noverhead. One way to accomplish this is to take h? to be a value constructor and to add the defining \nequation eval (h? x) = x for eval. That is, we can change the domain, Term, of eval to accommodate a \nnew construc\u00adtor and then add an extra clause to the definition of eva 1. With these ideas in mind, we \nmodify the datatype def\u00adinition of Term by adding a value constructor Place that implements h?: datatype \nTerm = Const of int I Succ I Appl of Term x Term I Abs of Term --+Term I Place of Value The evaluator \nis also extended accordingly: fun eval(Const n) = Num n I eval(Succ) = Fun(fn Num n a Num(n+l)) I eval(Appl(f,e)) \n= (case eval(f) of Fun(g) ~ g(eval(e))) I eval(Abs f) = Fun(eval o f o Place) I eval(Place x) = x Under \nthis definition of eva 1, the previous example evaluates as follows: eval(Appl(Abs(fn x a Appl(Succ,x)),Const \n1)) = case eval(Abs(fn x s Appl(Succ,x))) of Fun(g) + g(eval(Const 1)) = case Fun(fn x ~ eval(Appl(Succ, \nPlace x))) of Fun(g) % g(eval(Const 1)) = eval(Appl(Succ, Place(Num 1))) = case Fun(fn Num n a Num(n+l)) \nof Fun(g) ~ g(eval(Place(Num l))) = (fn Num n a Num(n+l)) (Num 1) = Num 2 Notice that Const 1 is evaluated \nonly once into N urn 1 and it remains in that form protected by the PI ace constructor until it is used \n(this justifies the name Place, which acts as a placeholder). In a way, Place partially satisfies the \nrequirements needed from reify. We will see that this partial satisfaction is good enough in many cases \nand its lack can be statically detected. The technique of using a value constructor to approxi\u00admate the \nright inverse of a function can be applied to compu\u00adtations over Term other than eval. To be completely \ngeneral, it is necessary to generalize the type definition of Term by abstracting over the domain of \nPI ace with a new type vari\u00adable a; after all, not all computations over Terms return Values: This allows \nany a object to be a subtype of Term, and Place plays the role of an injection function. One appropriate \ngeneralization of eval is the catamor\u00adphlsm. The cat amorphism operator for Term replaces each value \nconstructor (Const, Succ, Appl, and Abs) in an instance of Term with a corresponding function (fc, fs, \nfp, and fa): fun cataT(fc,fs,fp,fa) (Const n) =fcn \\ cataT(fc,fs,fp,fa) Succ = fs \\ cataT(fc,fs,fp,fa) \n(Appl(a,b)) = fp( cataT(fc,fs,fp,fa) a, cataT(fc,fs,fp,fa) b ) I cataT(fc,fs,fp,fa) (Abs f) = fa(cataT(fc,fs, \nfp,fa) o f o Place) I cataT(fc,fs,fp,fa) (Place x) = x Operator cataT has the following signature: That \nis, the abstracted type variable a (the domain of Place) is bound to the type of the result of cataT. \nWe may express the evaluator eva I as a cat amorphism as follows: cataT( Num, Fun(fh Num n ~ Num(n+l)), \nfn (Fun(f),e) sfe, Fun ) A printer for a term is: cataT(makestring, SUCC , fn (a,b) + a~ ~b, fn f * \nlet val n = newnameo in (fn ~n~ + ~(fn) ~ ) end) where new name returns a string that represents a new \nvari\u00ad able name and ~ is string concatenation. As another example of using a catamorphism over Term, \nwe present a type inference algorithm. Types can be defined as follows: datatype Type = Int I Arrow of \nType -+ Type A type inference algorithm for terms is a mapping from Term to Type: cataT( fn -+ Int, \nArrow(fn Int + Int I _ a type_erroro), fn (Arrow(f),t) + f(t) I _ a type.erroro, Arrow ) Type errors \nare reported when the inferred type is printed (since most calls to type-error are suspended in closures). \nIn light of code reuse issues, it is generally not advis\u00adable to extend type definitions by adding-new \nconstructors. Such extensions can cause non-exhaustive case analyses in pre-existing code. In our example, \nthe existence of the Place construct or is problematic for additional reasons. If the user constructs \na Term with Place, then the type of the term will not be fully parametric. That is, the type variable \na will be bound to some type, t, and the given term would no longer be acceptable as an input to a catamorphism \nthat produces a value of some type other than t.In addition, since Place plays the crucial role as the \napproximate right inverse of the catamorphism, it is not at all clear what consequences the user-construct \ned Terms using PI ace will have for the seman\u00adtics of cataT. The solution to this problem is to hide \nthe Place con\u00adstructor from the programmer. If Place does not appear in the input of cataT, then it will \nnot appear in the output of cataT either. To see why, consider the case of cataT over Abs(f ). This is \nthe only situation in which Place is intro\u00adduced by cataT, and it produces the term: fa( fn x + cataT(fc,f.,fp,fa) \n(f (Place x)) ) If f ignores its argument, then Place will disappear; otherwise cat aT will eventually \nreduce all occurrences of Place in the input that have type Term including occurrences in terms like \n(Place z), which will reduce to z. Therefore, Place will not appear in the output. The above observation \nsuggests that if the catamorphism operator were a primitive in the programming language, then just one \nPlace constructor would be needed. This spe\u00adcial constructor, Place, could then be used by every cata\u00admorphism, \nregardless of which type it traverses. The imple\u00admentation of catamorphisms as primitives would guarantee \nthat Place is the right inverse of each catamorphism. The Place constructor is completely hidden from \nprogrammers in the same way that programmers cannot access closures; it is strictly an internal implementation \ndetail. The Restriction on Place. The primitive place constructor, Place, is only an approximation to \nthe right in\u00adverse of cataT, Where does this approximation break down? To answer this question, consider \napplying eval to the term Abs(fn x > case x of Const n a Const n Iz a Const O) This yields Fun(fn y \n~ eval(case (Place y) of Const n + Const n I z * Const O)) Not every instance of a Term can be traversed \nby eval (ex\u00adpressed as a catamorphism), because the function f embed\u00added in Abs(f ) does not know how \nto handle the Place con\u00adst ruct or, as the example above shows. If f merely pushes its argument aroun&#38;, \nthings will be ok, but if f attempts to analyze its argument with a case expression to look inside , \nas the example above does, things can go wrong. Our proposed solution to this problem is to statically \ndetect when it occurs and to report a compile-time error. We need to statically detect when a function \nembedded in a value construction performs a case analysis over its argu\u00adment. This is not always problematic; \nit only becomes a difficulty if there exists a catamorphism over this particular construction. Our strategy \nis to extend the type system to detect such cases. We investigate e such a type system fur\u00adther in Section \n3. The type-checking algorithm is simple and can be implemented efficiently. It reports an error only \nfor invalid terms. This restriction is not substantial in our encoding of terms, since any term construction \nusing regular term en\u00adcoding (i.e., by representing lambda variables explicitly) can be mapped directly \ninto our term representation without the above mentioned problem. The problem appears when we go beyond \nthe typical encoding of terms.  2.1.2 The Paramet ricit y Theorem As another example of representing \nterms by structures with embedded functions, we construct the parametricit y theo\u00adrem for a polymorphic \nfunction. To understand this section, the reader must be familiar with Wadler s theorems-for-free paper \n[15]. Any function ~ of type ~ satisfies a parametricity the\u00adorem, which is derived directly from the \ntype r. For first\u00adorder functions, this theorem states that any strict polymor\u00adphic function is a natural \ntransformation. Theorem 1 (Parametricity Theorem) Anu strict func\u00adtton f : -r satisjies [7]($, f), where: \n[basic](r,s) + r = s [a](r,s) + r = a(s) [b a. ~](r, s) + Va : [7](?-,s) ~T1x ~2](r, s) + [~l](ml(r), \n~l(s)) A [T2](n~(r), T2(s)) [7-I -+72] (r, s) -+ v x, g : [TI](x, g) * [-r2](9-(x), s(g)) [T(7-)](r, \ns) + Vf, x : ~ r](.f(z), x) * r = map~(~)s That is, for each type variable a, we associate a function \nQ (of type al+ cvz, where al and az are instances of a). To avoid the name capture problem, we need to \npass an envi\u00adronment through [~] ( r,s ) that maps type variable names to function names. This environment \nis not necessary if we use structures with embedded functions. To illustrate Theorem 1, we derive the \nparametricit y the\u00adorem for the list catamorphism, fold : Va.V,B. (cz+ /3 +,6) -+ ~ -+ list(a) --+ ~ \n(The construction is accomplished in four simple steps): [b J.Vc.J-+s](r,s) -+ va,e,z,y : [q(z, y) * \n[e](r(z), s(y)) -+ VJ,e,z, y : x = J(g) * r(z) = E(s(g)) or V6, E:ro6=Eos [VJ.Ve.VV. 6 -+e+ n](r, s) \n+ VJ, e, ~, z, g : [J](z, g) + [s-+ q](r(z), s(g)) + VJ,E,V,Z,Y:Z =6(V) *r(z) oc=q Os(v) or V&#38;, \ne, V,y, z: r(Jy)(c Z)= V(s Yz)  [k a. list (a)] (r, s) 4 Va, ~,z : $(z) = a(z) * r = maplist (f)s or \nVa :r= map (a) s  As was pointed out to the authors by Ross Paterson, the parametricity theorem can \nbe easily extended to parametrize over type constructors by associating to each free type con\u00adstructor \nT : * + + a function T of type (al +cra) +TI (a I) + Ta (aa ), where T1 and Tz are instances of T. This \nextension is useful when we want to express laws about operations fun parametricity tp = All(fn fnc ~ \ncataT(fn (r,s) + Eq(r,s),  fn (a,b) ~ fn (r,s) + And( a(Apl(Pil,r),Apl( Pil,s)), b(Apl(Pi2,r),Apl( Pi2,s)) \n), fn (a}b) + fn (r,s) + All(fn x + All(fn y + lmpi(a(x,y),b(Apl( r,x),Apl(s,y))))), fn f + fn (r,s) \n+ All(fn x + f(fn (r,s) ~ Eq(r,Apl(x,s))) (r,s)), fn (n,a) + fn (r)s) + All(fnf + All(fn x + Impl( a(Apl(f,x),x), \nEq(r,Apl(Map(n, f),s)) )))) tp (fnc,fnc)) Figure 1: Generation of the Parametricity Law parametrized \nby type constructors. For example, the oper\u00adation cata of type VTVW : (T cr + a) + VT+ a satisfies the \nproperty q50(Ta) = ao~ ~ (cata 4) o (YT) = cro(cata ~), where the functions cata here may be parameterized \nover different type construct ors. The construction of the predicate of Theorem 1 requires some variable \nplumbing when we introduce universal quan\u00adtification (to avoid name capture, etc.). In addition, a func\u00adtion \nis associated to each type variable and this binding should be carried through the whole construction. \nWe can avoid the variable binding problems by using structures with embedded functions to capture universal \nquantification. Our algorithm takes a type construction of type T and returns a predicate of type E: \ndatatype T = Basic IProd of T x T ]Arrow of T x T I U.,. of T~T I Defof string x T datatype E= Pill Pi21Aplof \nEx EIEqof ExE lAndof ExE/lmplof ExE IAHof Ea E \\Map of string x E Following the same routine as before, \n(i.e., by adding the new constructor Place to type T, etc.), we arrive at the fol\u00adlowing catamorphism \nover types: fun cataT(b,p,a,u,d) Basic [ cataT(b,p,a,u,d) (Prod(x,y)) G :( cataT(b,p,a,u,d) x, cataT(b, \np,a, u,d) y ) I cataT(b,p,a,u,d) (Arrow(x,y)) = a( cataT(b,p,a,u,d) x, cataT(b. p,a, u,d) y ) I cataT(b,p,a,u,d) \n(Univ f) = u(cataT(b, p,a, u,d) o f o Place) I cataT(b,p,a,u,d) (Def(n,x)) = d( n, cataT(b,p,a,u,d) x \n) ] cataT(b,p,a,u,d) (Place x) = x The algorithm that generates the predicate of the para\u00ad metricit y \ntheorem for a function f nc of type t p is the hlgher\u00ad order catamorphism presented in Figure 1. When \nthis func\u00ad tion operates over U niv(g), it lifts g.T -+ T into f:(Ex E+ E)+(Ex E~E) The input to f should \nbe fn (r,s) + Eq(r,Apl(x,s)), that is, it should be the rule for handling the type variable x (the second \nrule in Theorem 1). Notice that there is no need to use a gem ym function to generate new variable names \nsince the variable scoping is handled implicitly by the execution engine of SML in which this function \nis expressed. The Pat erson-Meijer-Hut t on approach would have failed to cap\u00ad ture this function, since \nthere is no obvious function E d T that is a right inverse of the parametricity function (described in \nFigure 1). 2.2 Circular Structures In this section we present two more example of datatypes with embedded \nfunctions. We are interested in expressing computations over infinite structures that always terminate. \nCatamorphisms over finite structures have this property. We would like to extend this property to graph-like \ndata struc\u00adtures. To do this, we need to represent such structures by finite algebraic datatypes. One \nway to do this is to use em\u00adbedded functions. 2.2.1 Circular Lists Lazy functional languages support \ncircular data structures. For example, the following Haskell definition circ = O.l:circ constructs the \ninfinite list O : 1 : 0 : 1 : . by using a cycle. One way to construct infinite lists in SML is to use \nlazy lists (also known as streams), which use an explicit thunk for the tail of a list to obtain tail \nlaziness [11]: datatype a Clist = Nil I Cons of a x (unit+ a Clist) For example, the list circ=Ol :circ \nis expressed as follows: let fun circo = Cons(O,fn () * Cons(l,circ)) in circo end Even though many circular \nstructures can be defined this way, many operations over them need to explicitly carry a list of visited \nnodes in order to avoid falling into an infinite loop. Identifying which nodes have been visited is, \nhowever, also problematic, since there is no pointer equality in the pure functional subset of SML. Furthermore, \nthe construc\u00adtion of these circular structures requires the use of recursive function definitions (such \nas the circ above), which we want to avoid when we define catamorphisms (after all, a cata\u00admorphism is \nsupposed to be an alternative to recursion). A better definition for circular lists is obtained by recon\u00adsidering \nthe previous Haskell definition, which is equivalent to Y(fn x ~ O 1 x), where Y is the fixpoint operator \nof type (a+ a)+ CYsatisfying Y ~ = ~(Y f). This expression too does not terminate in strict languages \nsuch as SML. One solution is to suspend the application of Y and unroll the fixpoint explicitly during \nan operation only when this is un\u00ad avoidable, as is done implicitly in lazy languages. We can accomplish \na similar effect in strict languages by encapsulant ing the recursion inside a value constructor, Rec, \nwith a type similar to the type (~ list+ CY list) + a list of the Y combinator. This leads to the following \ntype definition for circular lists: datatype a Clist = NII I Cons of @ x d Clist I Rec of a Clist + \na Clist We can now express the list O :1:0:1: . . . as Rec(fn x + Cons(O,Cons(l,x))) Functions that \nmanipulate such structures will need to un\u00adroll the implicit fixpoint in Rec explicitly. The following \nare two such functions: fun head(Cons(a,r)) = a I head(Rec f) = head(f(Rec f)) fun nth(Cons(a,r),O) = \na / nth(Cons(a,r),n) = nth(r,n-1) I nth(Rec f,n) = nth(f(Rec f),n) For example, if circ = Rec(fn x ~ \nCon.(O,Cons(l,x) )), then nth(circ,100) = O and nth(circ,lOl) = 1. To express catamorphisms cataC ( b,f \n,g) over Clist, we add an extra type variable /3 and a constructor Place to Clist datatype (a,~) Clist \n= Nil I Cons of a X (a,,B) Clist I Rec of (o,/?) Clist~ (a,/3) Clist / Place of ~ Then cataC(b,f,g) \nis: fun cataC(b,f,g) NII I cataC(b,f,g) (Cons(a,r)) E !( a, cataC(b,f,g) r ) ] cataC(b,f,g) (Ret h) \n= g( catac(b,f,g) o h o place ) I cataC(b,f,g) (Place x) = x Notice that cataC does not unroll the fixpoint \nin Rec h. It does not need to. Instead, it lifts h into a function of type /3 -+/3 and it is up to g \nto decide what to do with it. To illustrate this, consider the map ma pC ( h ) over circular lists: fun \nmapC(h) = cataC( Nil, fn (a,r) ~ Cons(h(a),r), Rec ) In this case, g = Ret, and g will tie a new knot \nfrom the lifted function h, which results in a new circular list. Working through the example, mapC(fn \nx + x+1) (Rec(fn x ~ Cons(O,Cons(l,x) ))) will compute a circular list equivalent to Rec(fn x ~ Cons(l,Cons(2,x))) \n The Haskell definition x = 1: (map(l+) x) that computes theinfinite list l: 2:3:4:... is represented \nby the circular list Rec(fn x + Consul, mapC(fn y % y+l) x)). For exam\u00ad ple, nth( Rec(fn x + Cons(l,mapC(fn \ny + y+l) x)), 100 ) = 101 But consider the following evaluation: mapC(fn z a 2*z)(Rec(fn x + Consul, \nmapC(fn y * Y+l) x))) = Rec(fn x =+ mapC(fn z b 2*z) (Cons(l,rnapC(fn y * y+l)(Place x)))) = Rec(fn x \n% Cons(2,mapC(fn z a 2*z) (mapC(fn y * y+l)(Place x)))) = Rec(fn x a Cons(2,mapC(fn z % 2*z) x)) which \nrepresents the infinite list 2 : 4 : 8 : 16 : . . .. This result is incorrect. We should have computed: \nRec(fn x + Cons(2,mapC(fn z + Z+Z) x)) which represents the infinite list 2 : 4 : 6 : 8 : 10 : . . .. \nBut why did we get this error? The problem is that the Place constructor in this example was intended \nto be used for the outer occurrence of mapC, not the inner. Instead it cancelled the inner occurrence \nof ma pC. If we had followed the Paterson-Meijer-Hutton approach, we would have used mapC(fn z ~ z/2), \nthe right inverse of mapC(fn z + 2*z), instead of Place. In that case, we would have derived the correct \nresult. In a situation like this. where a function is invertible, the Paterson-Meijer-Hut ton approach \nclearly wins over ours, since it is more expressive. Even though nt h works fine over the above construction, \nthe problem is that this construction cannot be traversed bv another cataC in our model because of the \ncase analysis implied by the application of rnaPC to the argument x. Fortunately, cases like this are \nautomatically discovered by the type inference system to be discussed in Section 3. This restriction \nis not as severe as it might first appear. For example, all planar graphs defined in the next section \ncan be encoded into our representation without any prob\u00adlem. This is because graph cycles are captured \nby a con\u00adstruction of the form Rec(fn x ~ f(x)). If we want to con\u00adstruct a backward edge from a graph \nnode inside the graph construction f(x) to the beginning of f(x), we simply refer\u00adence x. That is, this \nconstruction does not need to analyze or traverse x in f(x) any time. Problems may occur when we want \nto capture structures whose patterns of recursion are not constant (such as the list of natural numbers). \n  2.2.2 Graphs Graphs can be represented in a manner similar to the way in which circular lists are \nrepresented. Such a representa\u00adtion allows terminating computations over graphs such as the computation \nof the spanning tree of a graph to be expressed as catamorphkms. The most common way to represent graphs \nin a functional language is to use a vector of adjacency lists. But, this approach is not really different \nfrom using pointers in a procedural language, since permits ad-hoc constructions and manipulations of \ngraphs. In [13] a graph type is defined as: datatype a graph = Graph of a + o list Here a graph consists \nof a function that computes the suc\u00adcessors of each node. This definition requires special care while \nprogramming to guarantee program termination. Our graph representation is based on the idea of using \nembedded functions in a manner similar to the way we did it for circular lists. We start with a datat \nype that can repre\u00adsent trees, which have nodes supporting arbitrary branching levels. We call such a \ntree a rose.tree and define it by datatype a rose-tree = Node of cv x ~ rose-tree list Now, we think \nof a graph as a generalization of rose trees with cycles and sharing: datatype a graph = Node of a x \no graph list I Rec of a graph ~ a graph I Share of (a graph ~ a graph) x a graph Here, Rec plays the \nrole of the Y combinator in expressing cycles, while Share plays the role of a function application. \nox z2 1  (fAQ Y Figure 2: Graph with three nodes O, 1,2 and five edges That is, Share(f,e) is unrolled \nas f e. All free occurrences of x in u in the term Share(fn x + u, e) are bound to e, i.e., all x in \nu share the same subgraph e. The function Rec(fn x ~ Share(fn z ~ Node(O,[z, Rec(fn y a Node(l,[y,z]))]), \nNode(2,[x]))) for example, describes the graph in Figure 2. By following the same routine as for circular \nlists, i.e., by adding the new constructor Place, etc., the graph catamorphism cataG becomes: fun cataG(f,g,k) \n(Node(a,r)) = f( a, map(cataG(f,g,k)) r ) I cataG(f,g,k) (Ret(h)) = g( cataG(f,g,k) o h o Place ) I cataG(f,g,k) \n(Share(h,n)) = k( cataG(f,g,k) o h o Place, cataG(f,g, k) n ) I cataG(f,g,k) (Place x) =x The following \nare examples of graph manipulations that use cata G: val listify = cataG( fn (a,r) ~ a::(flatten r), \nfn f % f [ ], fn (f,r) > fr) val sum = cataG( fn (a, r) > cata(op +) ra, fn f 5 f O, fn (f,r) * fr) fun \nmapG(g) = cataG( fn (a, r) ~ Node(g a,r), Ret, Share ) Iistify flattens a graph into a list, sum computes \nthe sum of all node values, and ma pG is the map over a graph. The following is another datat ype for \ngraphs. Here we have merged the roles of the Share and the Rec constructors by using a list in the domain \nof Ret: datatype a graph = Node of Q x a graph Ilst I Rec of int x (a graph list ~ a graph list) Under \nsuch a graph representation, the graph in Figure 2 is constructed by Rec( 3, fn [x,y,z] +. [Node(O,[y,z]), \nNode(l,[y,z]),Node( 2,[x])] Ix * error ) In general, any set of n mutually recursive Haskell defini\u00adtions \nof the form x, = ~,(zl, . . ..z~). 1 < i < n, can be represented by Rec(n, fn[zl, . . ..z~] +[~l(zl, \n. . ..x~). ~~(zl, (zl, . . .,z~)] \\ x * error) The interpretation of Rec(n ,f ) is hd (Y f). For practical \nrea\u00adsons, both the input and the output list of f must have the same size, n, in order for the closure \nY f to execute with no run-time error. By following the same routine as before, i.e., by adding the new \nconstructor Place, etc., the graph catamorphism becomes: fun cataG(fn,fr) (Node(a, r)) = fn( a, map(cataG(fn,fr)) \nr ) I cataG(fn,fr) (Rec(rn,f)) = fr( m, map(cataG(fn,fr)) o f o (map Place) ) I cataG(fn,fr) (Place x) \n= x For example, the following computes the adjacency list of a graph: cataG( fn (a, r) + [(a, map(#l) \n(flatten r))], fn (n,f) =+-flatten(f(f(ncopies n [ ]))) ) where ncopies n a creates a list of n copies \nof a. If we had flatten (f(ncopies n [ ])) in the second parameter of cataG, we would have obtained an \nempty adjacency list for each node. In each of the examples above, it was necessary to use the trick \nof extendimz the datatv~e. . definition with an additional constructor Place, adding to the datatype \na type variable to hold the type of the result of a catamorphism, and writing the catamorphism function \nby hand. Unfortunately, in none of these cases is there a guarantee that the programs written obeyed \nthe restriction described in Section 2.1.1. In the next section we define a language in which our trick \nis implemented implicitly. That is, the Place construc\u00adtor and the catamorphism function become primitives \nof the language, but because Place is hidden, it is impossible for the user to construct programs that \nuse Place. The result\u00ading language also supports a type system that enforces the above mentioned restriction. \nType inference rules for this type system are also presented. 3 The Formal Framework In this section \nwe define a language that allows the def\u00adinition of new datatypes and implicitly supplies the trick we \nhave used in the examples of Section 2. The expres\u00adsion sub-language includes the catamorphlsm operator \nfor any datatype as a primitive. Syntactically, the user writes cata T, where T is the name of a user-defined \ndatatype. The semantics of the catamorphism primitive is given as an implicit case analysis over the \ndatatype traversed by the catamorphism and need not be supplied by the user. This semantics accommodates \nthe Place constructor only as an internal implementation detail. In the interest of simplicity, the language \ndoes not use explicit value construct ors, as do most functional languages. Inst cad, it uses binary \nsum and product types. The resulting notation renders the underlying theory easier to explain be\u00adcause \nfewer rules are needed to express our algorithms, but, unfortunately, also makes programs hard to understand. \nFor clarity, we will explicitly describe the correspondence be\u00adtween functional languages and our language \nas we proceed through this section. 3.1 Terms Terms e in the language are generated by the following \ngram\u00ad mar: (term) e ::= xl ()\\ee[Az. el(e, e)\\inTelinL[inR I cataTe I AinT.z. e \\ J(x, z). e I JinLz. \neflinRx. e  where z denotes a variable. The term i n~ is the value con\u00adstructor for the recursive type \nassociated with the type def\u00adinition T (to be explained in detail later). The constructors i nL and inR \nare the left and right injectors of the sum type. The function cataT is the catamorphism operator for \nT. The in-abstraction AinT x. e is defined by (JinT z. e) (inTu) = (kz. e) u, and the pair-abstraction \nA(z, y). e is defined by: (~(z, v). ~(~)g))(el, e2) = f(el, e2) The sum-abstraction AinLzl. e] OinRzz. \nez, when applied to inL u, computes (JZI. el) u and, when applied to inRu, computes (AZZ. ez ) u. As \nexplained above, our language does not contain value constructors. The value constructors of a type can \nbe de\u00adfined in terms of other operators and these definitions can be generated automatically. For example, \nfor SML lists defined as: datatype a list = Nil I Cons of a x a list the value constructors Ni I and \nCons could be defined as: Nil = inList(inL()) Cons(a, r) = inList(inR(a, r)) Traditional languages use \ncase statements to decompose val\u00adues. Our term language can capture any case analysis over a value construction \nby using sum-and in-abstractions. For example, case eof Nil ~ el \\Cons(a, r) + ez can be expressed by \nthe following composition of operators: (AinList x. (AinLy. el DinRg. (A(a, r). e2) g) z) e  3.2 Types \nOur types are generated by the following grammar: (type-definition) T ::= A(z, z). T I ~ (type) 7 ::=zlo17X~l~+~l~~~l \nE (type-use) E ::= # TIE (r, ~) (tag) w ::= x I cased [ folded A type definition consists of a number \nof type abstractions followed by a type. Each type abstraction A(x, g). r intro\u00adduces two type variables: \na positive (+) x and a negative ( ) g. A positive (resp., negative) variable should only appear in a \npositive (resp., negative) position in a type. This condition is implicitly checked by the rules guarantee\u00ading \nwell-formedness of types, given in Figure 3. Under this condition, a and 6 appear in a positive position \nin the type (a -+/3) ~~-+d, while ~ and -y in a negative. The rules in Figure 3 check the well-formedness \nof types using the following definitions: (kind) k::= zl+l (kind-assignment) p ::= {}\\ p{x : k} A type \nT = A(xo, z~) . . . . A(z~, z~).r must satisfy p{xo : +,zj: ,..., z~:+, x~}1}r::+,+, Atypedefinition \nT must have at least one type abstraction A (ZO, ), which is zj used when constructing the fixpoint \np T of T. The w tag in p is used during type-checking and is hidden from pro\u00adgrammers. The fixpoint type \nconstructor p is a primitive and satisfies the equation &#38;T(n,r{)...(~n,rL) = T((,u T (n, r[). .(rn,~~)),(P@T(~/,~l)o \nc .(r~, ~n))) (T,, T;)... (Tn, J/J That is, ,uWT is the fixpoint of T, where both the argu\u00adments of \nthe first abstraction of T are fixed to VW T. We will see later that any type definition T that meets \nthe well\u00adformedness criteria of Figure 3 is a functor that is covariant in its positive arguments and \ncontravariant in its negative arguments, that is, (T(~I,.fi) ~~(jm~;)) o (T(gl, gi) . (gn, g~)) = T(flogl, \ng[of; )... (fnogn, g; of;) The following are examples of type definitions: Bool = A(z, Y) ()+ () Nat \n= A(z) t/). () +x List = A(x, y). A(a, c/). () +@ X x Rose-tree = A(z> y). A(cx, a ). A(/3, fl ). ()+ \n(a+~ X (&#38;Llst (z, v))) Clist = A(x, g). A(a, a ). () + (a X x+-(g+z)) Ctype = A(z7 y). A(a, a ). \n(a -+cz) +-(v+-z) The inductive list type definition datatype list(a) = Nil I Cons of Q xlist(a), for \ninstance, is derived by applying the fixpoint operator to List to obtain list (a) = pW List (a, a) Note \nthat types that do not include embedded functions such as the familiar List, Nat and Bool make no mention \nof their negative type variables. 3.3 The Semantics of Catamorphism The semantics of the catamorphism \ncataT over a type defi\u00adnition T can be given as an implicit case analysis over T. A type definition T \n= A(zo, xl).. . A(z~, xL). r is associated with a combinator, which we will prove is a functor. The type \nmapping part of the functor is the polymorphic type T itself. The function mapping part of the functor \nis de\u00ad fined by T (.fot f{) ~~ (.f~, $:) = MK~l, where each function ~, (resp., f:) is associated with \nthe type variable X, (resp., X[ ). The term M [~] is derived by a case analysis over the M~p S (7,,~[) \n. . (7m,~&#38;)] = maps (M~71j, M~r~]). . . (M[r~], M[~&#38;]) where for the combinator S = A(zo, x:) \n. . . A(z~, zL). r we have (mws(fl, fo(fm, fk)) Oins = inso (S(maps(fl, i[). (f~, fA), mws(f{, fl) ~~~(fA, \nfro)) (.fl, f;)  (.fm) ~A)) p+rl::k, pl-r2::k pkrl::k, p~rz::k pl-()::k pkrlxrz::k pt-Tl+Tz::k p!_ \nTI+Tz::k Figure 3: Well-formedness of Types (Definition: ~(+) = and -I(-) =+) Theorem 2 For T = A(zo, \nz~) A(z~, z~).T, the combz\u00adnator T (fo, f:) . (fn, f~) = M[T] is a functor, i,e., it sat\u00ad isjies Thk \ntheorem can be proved by induction over the structure of ~ in kt~~]. Let &#38;fl[~] = T(.fo, .fi) (.f~,.f~), \nM2[T] = ~(go,g~).(g~,g~), and M3[Tll= ~(foogo,giofd)(f~o gn, g~ o f;). It suffices to prove that, for \nany type T, if {} E ~ :: +, then Ms[r] = Ml~~] o M2U7], and otherwise MS [T] = M2 [~] o M 1[~]. For illustration \npurposes, we present only one case of this proof where ~ = T1 ~ T2 and ~ is positive; the proofs in the \nremaining cases are similar. MI IT] o M2UT] = (M. Ax. Ml[T2](h(Mlu711 (~)))) O(M. Ax. M2[T2](h(M2[71] \n(z)))) = Ah. Ax. (M, [T2](M2[T2](h(M2 [7-l] (Ml[T,](z)))))) = Ah. AZ. (M3[T2](h(M3[Tl] (z)))) = Ma[r] \n0 The catamorphism over any datatype T is defined in terms of the combinator ZT, which is equal to the \nfunctor T with all but its first two arguments fixed at the identity: According to Theorem 2, tT satisfies \nthe law ~T(ft, f-)o#(g+, g-)=&#38; T(f+ Og+, g-of-) According to our previous discussion, to define \nthe cata\u00admorphism over T, we need to extend T with a new value construct or PI ace and a new type variable \n~. We get Here Place is equal to inT o in FL The resulting catamor\u00adphism over T is (cataT ~) o inT = \nAinL z. 4(ET (cataT ~, inT o inR) z) o inRy. y But here the Place constructor is transparent to program\u00admers. \nTo hide it, we need to introduce the special term Place. Definition 1 (Catamorphism) The catamorphism \nfor a type T is cataT : (T(a, a) ~ a) -+ p T ~ a, defined as follows: cataT ~ (inTz) = @(tT (cata~ 4, \nPlace) z) cataT ~ (Place z) = x According to, this definition, the catamorphism for circular lists is \ncatac] st ~, given by catacllst ~ (inCl x) = q$((AinL g. inL y [inll.y. inR((JinLz. inL((J(a, r). (a, \ncataclis ~r)) z) DinRh. inR(Aw. catacl @(h(Place w))) )Y))x) cat acL $t ~ (Place z) = z If we had \nexpressed the first case of this definition in a func\u00adtional language with value constructors and pattern \nmatch\u00ading, we would have cata cl s ~ (inc] z) = @(case z of Nil ~ Nil \\ Cons (a, r) * Cons (a, catacl \ns ~ r) ] Rec (~) ~ Rec ((catacl t ~) o f o Place)) where Nil = inL(), Cons (a, r) = inL(inR(a, r)), \nand Ret (f) = inR(inR(j)). For example, the following pro\u00adgram computes mapC(g), the map over Clist: \ncat acl st (AinLy. inLg DinRg. inR((~inLz. inL((A(a, r). (ga, r)) z) UinRh. inR(h)) y)) Meijer and Hutton \n[8] define a catamorphism cataT in conjunction with its dual, the anamorphism anaT, as fol\u00adlows: cata~ \n#1@ (inTz) = #(tT (cataT ~ 4, anaT #*) z) alla $5+ x = inT(S~ (ana~ @@, cataT ++) (+ z)) That is, both \ncat aT and anaT should take two functions, ~ and @. The first, ~, is used in the catamorphism and the \nother, ~, is be used in the anamorphlsm. This dual pair of cata-ana should satisfy the law (cataT @V!J)o \n(anaT #1~) = id in order to be useful. This implies that 40 ~ = id. To complete the explication of the \nrelationship between our work and that of Meijer and Hut ton s, we show that the notion of anamorphlsm \nis dual of that of cat amorphism. Definition 2 (Anamorphism) The anamorphwm for a type T is anaT : (cI+T(cY, \na))+ a+p T, defined as follows: One of the advantages of using catamorphisms instead of general recursion \nis that they satisfy nice properties. In particular, .the~ satisfy an important property known as the \nfusion law, which can be used for fusing any strict function with a cat amorphism to yield another catamorphism. \nThe fusion law for a catamorphism of type T is given by the following theorem. Theorem 3 (Fusion Law) \nFor any strict fzmctzon g: go(p = ~ oST (g, id) g o cataT #J = cataT + Proof: Since Place is internal \nto each cataT, we will consider only the case where the input is inT (external uses of Place are detected \nand ruled out by our type system). We have gocataT ~oinT = go# o&#38;T (cataT ~,Place) = ~ o t~ (g, id) \no # (cata~ 4, Place) = @o2T (g ocataT 4, Place oid) = @ o ~T (cataT @, Place) cataT ~ o inT !3 Type-checking \n The grammar for the term language gives syntactic rules for valid term constructions, but not all such \nterms have meaning. Traditionally, a type system is used to discover invalid terms by attempting to assign \ntypes to terms. Here we will use the type system to distinguish both the ill-typed terms and terms with \nillegal uses of catamorphisms. Since our language support polymorphic data types, we will need a Hindle \ny-Milner style type-inference algorithm. Here we will only give the typing rules for the type-inference \nsystem. Figure 4 presents the typing rules for our A-calculus. We add to the usual rules the rules (CATA), \n(IN), and (OUT). To simplify these rules, we assume that a type definition T has only one type abstraction, \ni.e., we assume that T con\u00adtains one positive and one negative variable. If we ignore the w s in the \nRule (IN), then the type of inT e is the fix\u00adpoint of the functor T and the type of e is T with both \nits positive and negative arguments fixed to the fixpoint of T. In addition, Rule (IN) propagates the \nw flag only to the neg\u00adative part of T. Rule (OUT) is in some sense the opposite of Rule (IN) since JinT \nz. e is a function from the fixpoint of T to the type of e. Rule (OUT) also sets the w flag of the negative \npart of T to cased. Rule (CATA) sets the w tag of jAW to folded. If a term of type pW T is examined by \nthe term AinT x. e, then Rule (OUT) sets the w tag to cased, which is propagated through the negative \npart of T. If the w tag reaches a catamorphism, then pca ed T and pfo]ded T will not unify and the type-checking \nwill fail. To illustrate how the typing rules in Figure 4 detect er\u00adrors, consider the term cata Cli \n~ (Rec(Ainc* x. e)) where Rec(~) = incliS (inR(inR( .f))). This term is not well-typed, since (Jinc \ni t X. e) is of type Pca edclist + T! the term incl st will propagate the type of its negative in\u00adput, \n,uCased Clist, to its output, and finally the resulting type pcased Clist will not unify with the type \nLJf lded Clist in Rule (CATA). On the other hand, cata is C#J(Cons(a, (Aincl z. e) r)) where Cons(a, \nr) = inc* (inR(inL(a, r))), is well-typed, since Rule (OUT) will bind the p tag of the negative part \nof T to cased. Since the type of the constructor Cons does not use the negative part of T, this binding \nwill not be propagated. A type-checking system that is based on the typing rules in Figure 4 needs a \nunification algorithm. A slight variation of the usual unification algorithm can be used. The only special \ncase it needs to consider is the case of unifying ,UWI T with another IJW2 S, since this is the case \nwhere an error occurs if a program does not satisfy the restrictions. The type p T will unify with p \n T (denoted as .uW T s P T) unless either .uf ]ded T # pcased T or Pf id d T # Pf ld d T. We have already \npresented an example in which the first case occurs and in which the type checker should therefore report \nan error. An example in which the second case occur was given in Section 2.2.1 by mapC(~z. 2 * x)( Rec(Xr. \nCons(l, mapC(kr. z + 1)x))) The outer mapC is a catamorphism over the infinite list 1:2:3: . . . Since \nthe inner mapC is a catamorphism too, the folded tag will be propagated all the way through the input \nof the outer mapC. As we have seen, this program is invalid and it should be ruled out by the type-checker. \n4 Conclusion We have presented a new method for defining catamorphisms over datatypes with embedded functions. \nOur approach can be useful even when the approach outlined by other recent proposals fails, since it \ndoes not require the existence of inverse functions. Our method has a more efficient imple\u00ad mentation \nand is often easier to use and understand since it does not require programmers to explicitly develop \nthe inverse functions. We have characterized exactly when we can trade the restrictive condition about \nthe existence of an inverse for another, more useful, condition that we can statically test. We have \ndemonstrated how to use datatypes with em\u00ad bedded functions in two large and useful domains: meta\u00ad programming \nand circular structures. We have demonstrated that structures with embedded functions provide a natural \nway to express meta-programming and program manipula\u00ad tion of languages with binding constructs like \nlambda ab\u00ad straction, because there is no renaming problem or need for a gens~m-like solution. Therefore, \nour approach is pureIy functional and do not require us to resort to the well-known stateful monad tricks. \nThe other domain of examples was on structures with cycles. It is well known that implementations of \nfunctional languages use pointers and cycles, but these are hidden im\u00ad plement ation details. They are \nexactly the mechanisms pro\u00ad grammers would like to use to implement graphs, but can\u00ad not. We have developed \na mechanism that allows program\u00ad mers to get a better hold of these implementation details in a manner \nwhich is still safe. (VAR) akz: a(z) (INL) aFinL:rl-+rl +72 al-cl :71-+7z, a+ez:~l (APPL) ut-elez:rz \nat-el:rl, ukez:rz (PROD) crt-(el,ez):~lx-rz aEe:T(T,r)~T (CATA) u E cataT e : pfolded T+~ ul-e:T(&#38;T, \npW2T) (IN) ukinTe:&#38;T Figure 4: Typing Rules (where a Acknowledgments The authors would like to thank \nPatty Johann, Erik Mei\u00adjer, Ross Patterson, Doaitse Swierstra, Andrew Tolmach, and the anonymous referees \nfor extensive comments on ear\u00adlier drafts of this paper. Leonidas Fegaras is supported in part by the \nNational Science Foundation under grant IRI-9509955, and by contract by the Advanced Research Projects \nAgency, ARPA order number 18, monitored by the US Army Research Laboratory under contract DAAB-07\u00ad91-C-Q518. \nTim Sheard is supported by the USAF Air Ma\u00adterial Command under contract # F19628-93-C-O069. References \n[1] R. Bird and O. de Moor. Solving Optimisation Prob\u00ad~ems with Catamorphisms. In Matlsemcstzcs oj Program \nConstruction, pp 45-66. Springer-Verlag, LNCS 669, June 1992. [2] A. Church. A Formulation of the Simple \nTheory of Types. Journal of Symbolic Logic, 5:56-68, 1940. [3] L. Fegaras, T. Sheard, and T. Zhou. Improving \nPro\u00adgrams which Recurse over Multiple Inductive Struc\u00adtures. In ACM SIGPLAN Workshop on Partial Evalu\u00adation \nand Semantics-Based Program Manipulation, Or\u00adlando, Florida, pp 21-32, June 1994. [4] J. Launchbury and \nT. Sheard. Warm Fusion. Seventh Conference on Funct~onal Programming Languages and Computer Architecture, \nLa Jolla, California, pp 314\u00ad 323, June 1995. [5] G. Malcolm. Data Structures and Program Transforma\u00adtion. \nScience of Computer Programming, 14:255-279, 1990. [6] G. Malcolm. Homomorphisms and Promotability. In \nMathematics of Program Construction, pp 335-347. Springer-Verlag, LNCS 375, June 1989. (UNIT) 0} ():() \n(INR) aEinR:~z-+r1+~2 a{z:~l}+e:~z (ABS) ~t-~x.e:rl-+rz a{zl : ,1 ,zz:~z}+e:r (xABS) aEA(zl,sz).e:~l \nx-rz +-r O{Z1 : ~1} I-cl : 7, a{zz : ~2}be2:~ (+ABS) al-( JinLxl. ellinRz2. e2) : ~1+~2~T a{z :T (pWT, \n~c d T)} ~~:~ (OUT) ukAinTx. e:p d T -+ r type-assignment is u ::= {} I a{x : ~}) [7] E. Meijer, M. \nFokkinga, and R. Paterson. Functional Programming with Bananas, Lenses, Envelopes and Barbed Wire. In \nProceedings of the 5th ACM Confer\u00adence on Functional Programming Languages and Com\u00adputer Architecture, \nCambridge, Massachusetts, pp 124\u00ad 144. Springer-Verlag, LNCS 523, August 1991. [8] E. Meijer and G. Hutton. \nBananas in Space: Extending Fold and Unfold to Exponential Types. Seventh Con~er\u00adence on Functional Programming \nLanguages and Com\u00adputer Architecture, La Jolla, California, June 1995. [9] G. Nadathur and D. Miller. \nHigher-Order Logic Pro\u00adgramming. In D. Gabbay, C. Hogger, and A. Robinson, editors, Handbook of Logic \nin Artificial Intelligence and Logic Programming. Oxford University Press, 1995. To appear. [10] R. \nPaterson. Control Structures from Types. Un\u00adpublished draft. Available by anonymous ftp from ftp-ala. \ndoc .ic .ac .uk/pub/papers/R .Paterson/folds .dvi, 1994. [11] L. Paulson. ML for the working programmer. \nCam\u00adbridge University Press, 1991. [12] F. Pfenning and C. Elliott. Higher-order Abstract Syntax. Proceedings \nof the ACM SIGPLA N 88 Sym\u00adposium on Language Design and Implementation, At\u00adlanta, Georgia, pp 199-208, \nJune 1988. [13] C. Reade. Elements of Functional Programming. Ad\u00addison Wesley, 1989. [14] T. Sheard and \nL. Fegaras. A Fold for All Sea\u00adsons. Sixth Conference on Functional Programming Languages and Computer \nArchitecture, Copenhagenj Denmark, pp 233-242, June 1993. [15] P. Wadler. Theorems for Free! Fourth Conference \non Functional Programming Languages and Computer Ar\u00adchitecture, Imperial College, London, September 1989. \n \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "Leonidas Fegaras", "author_profile_id": "81452616878", "affiliation": "Department of Computer Science and Engineering, Oregon Graduate Institute of Science & Technology, 20000 N.W. Walker Road P.O. Box 91000, Portland, OR", "person_id": "PP14161009", "email_address": "", "orcid_id": ""}, {"name": "Tim Sheard", "author_profile_id": "81331504269", "affiliation": "Department of Computer Science and Engineering, Oregon Graduate Institute of Science & Technology, 20000 N.W. Walker Road P.O. Box 91000, Portland, OR", "person_id": "PP39068150", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.237792", "year": "1996", "article_id": "237792", "conference": "POPL", "title": "Revisiting catamorphisms over datatypes with embedded functions (or, programs from outer space)", "url": "http://dl.acm.org/citation.cfm?id=237792"}