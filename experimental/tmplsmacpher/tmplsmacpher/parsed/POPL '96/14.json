{"article_publication_date": "01-01-1996", "fulltext": "\n From Region Inference to von Ne~lmann Inference ~~achines via Region Representation Lars Birkedal, Carnegie \nMellon Magnus University* Vejlstrup, Mads Tofte, NKT Elektronik~ University of Copenhagen Abstract Region \nInference is a technique for implementing program\u00adming languages that are based on typed call-by-value \nlambda calculus, such as Standard ML. The mathematical runtime model of region inference uses a stack \nof regions, each of which can contain an unbounded number of values. This paper is concerned with mapping \nthe mathematical model onto real machines. This is done by composing region infer\u00adence with Region Representation \nInference, which gradually refines region information till it is directly implementable on conventional \nvon Neumann machines. The performance of a new region-based ML compiler is compared to the perfor\u00ad mance \nof Standard ML of New Jersey, a state-of-the-art ML compiler. 1 Introduction It has been suggested that \nprogramming languages which are based on typed call-by-value lambda calculus can be im\u00adplemented using \nregions for memory management[l 7]. At runtime, the store consists of a stack of regions. All values, \nincluding function closures, are put into regions. Region inference, a refinement of Milner s polymorphic \ntype disci\u00adpline, is used for inferring where regions can be allocated and where they can be deallocated. \nFor each expression which directly produces a value (such as a constant, a tuple expression or a lambda \nabstraction), region inference also infers a region in which the value should be put. Experi\u00adments with \na proto-type implementation of region inference and an instrumented interpreter have suggested that often \nit is possible to achieve very economical use of memory re\u00adsources, even without garbage collection[17]. \nThe potential benefits of region inference are: Work done while at University of Copenhagen Current address: \nSchool of Computer Science, Carnegie Mellon Unlverslty, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA, \nemall b1rkedalt2cs cmu,edu, tAddress: Department of Computer Science (DIKU), University of Copenhagen, \nUnlversitetsparken 1, DK-21OO Copenhagen 0, Den\u00admark, email tofte@diku dk, Work done while at University \nof Copenhagen emad MGV-at_NKTJ3LEKTRONIK@) dscc, dk Permission to make digital/bard copies of all or \npart of this material for personal or classroom use is granted witbout fee provided that the copies sre \nnot made or distributed for profit or commercial advantage, the copy\u00adright notice, the title of the publication \nand its date appear, and notice is given that copyright is by permission of the ACM, Inc. To copy otherwise, \n;O~publish, to post on servers or to redistribute to tists, requires specific >ermission andlor fee. \nPOPL 96, St. Petersburg FLA USA ~ 1996 ACM 0-89791-769-3195101, .$3.50 1. Region inference reclaims memory \nvery eagerly and could hence lead to a (much desired) reduction in space requirements; 2. The region \ninformation inferred by the region infer\u00adence algorithm might be useful to programmers who are interested \nin obtaining guarantees about maximal storage use and maximal lifetimes of data, as is the case with \nembedded systems; 3. If region inference is used without ~arba~e collection (as ~e have done so far) \nit eliminates ~idde~ time costs: all memory management operations are inserted by the compiler and are \nconstant-time operations. This could be important for real-time programming.  The purpose of this paper \nis to report the results of ongoing efforts to study whether and how this potential can be re\u00adalised. \nBased on experience with developing a new Standard ML compiler which uses regions for memory management, \nwe propose a way to map the conceptual regions of region in\u00adference onto real machines. With the techniques \nwe present below, we have found that 1. Region inference can result in significant space savings on non-trivial \nprograms, in comparison with a state\u00adof-the-art system which uses garbage collection; 2. Region-based \nevaluation of ML programs can compete on speed with the garbage-collection-based execution of a state-of-the-art \nML system; 3. In practice, a high percentage of all memory alloca\u00adtions can take place on a traditional \nruntime stack  On the downside, it has to be said that region inference occasionally does not predict \nlifetimes with sufficient accu\u00adracy and that tail recursive calls tend to require special pro\u00adgrammer \nattention. Thus we had to make minor changes to programs to make them run well with regions. We are currently \nbuilding an ML compiler to explore region inference; it is called the ML Kit with Regions, since it is \nbuilt on top of Version 1 of the ML Kit[4].1 The purpose of this paper is not to describe the Kit, but \nto describe solutions to key problems which presented themselves, when we tried to compile with regions. \nThese solutions are in the form of additional type-based analyses which refine the information gained \nwith region inference in ways which are 1For brevity, we shall refer to It as simply the Kit , from now \non. 171 essential when the target machine has a conventional linear address space of fixed size words \nand a number of registers. The operational region-based semantics presented in [17] treats all values \nand regions uniformly: all values are put into regions and all regions have a potentially unbounded size. \nHowever, we have found that a key factor in achieving good results with region inference is making more \ncareful distinctions between different kinds of regions according to how they should be represented and \naccessed. The following three kinds of regions fit naturally with common machine architectures: 1. Regions \nthat are used for holding values of a type which fits naturally in a register or a machine word; such \nregions are not needed at runtime and can hence be eliminated. This situation arises for regions that \nhold integers and booleans, for example. 2. Rezions for which one can infer a finite maximum size  \n. at compile time; such regions are conveniently placed on the runtime stack. This situation often applies \nto regions that hold a tuple or a closure. 3. Regions for which it is not possible to infer a size stati\u00adcally, \nSuch a region can be represented by a linked list of fixed size pages. This situation typically arises \nwhen a region contains a list, a tree or some other value of a recursive datatype. The first analysis \nwe propose is rrzultiplzc!ty wsjererrce, which infers for each region an upper bound on how many times \na value is put into that region. A bo.rmg analysts then elimi\u00adnates regions as described above. Next, \nstorage mode analy\u00ad sis infers for each value allocation whether the value should be put at the top of \nthe region (the normal case) or whether it is possible to store the value at the bottom, thereby over\u00ad \nwriting any value which the region may already contain. The storage mode analysis involves a region abusing \nanaly\u00ad sts. The storage mode analysis is essential for handling tail recursion. Multiplicity information \nand representation information can then be used in physzcal size tn~er-ence which calculates an upper \nbound on the physical size of every region. A key difference between different kinds of regions (be\u00ad \nsides their sizes) is the way in which they are allocated and accessed. This plays a central r61e in \nall the analyses. We use the term Region Repr-esentutton Inference for the analyses starting with multiplicity \ninference and ending with physi\u00ad cal size inference. The Kit has an Abstract Machine (called the KAM) \nwhich models a RISC architecture except that it has in\u00ad finitely many registers. After Region Representation \nInfer\u00ad ence, compilation into the KAM is straightforward. Els\u00ad man and Hallenberg[6] have recently completed \na backend from KAM to HP PA-RISC assembly language using proven techniques such as intraprocedural register \nallocation based on graph colouring. A backend generating ANSI C is also available. The ML Kit currentlv \ncomDiles all of Core ML (including recursive datatypes, ~efere~ces, exceptions and higher-order functions); \nan implementation of Modules is under consideration. In the rest of the paper we describe the new region\u00ad \nspecific program analyses, from multiplicity inference to KAM code generation. Sections 2 and 3 consist \nmainly of a review of previous work. We start out by presenting the language of region-annotated terms. \n2 Source Language Let Var be a denumerably infinite set of program variables, ranged over by x and j. \nThe language of source expressions, e, is defined by: e::= true Ifalse Iz Ikr. e ]elez I if ethen eelse \ne I letz=eine end I letrec ~(r) = e in e end Although source expressions appear untyped, region infer\u00adence \nis only possible for expressions that are well-typed ac\u00adcording to Milner s type discipline[13,5]. We \nshall use the following program as a running example: letrec j(z) = letrec facacc(p) = let n=fst pin \nlet acc=snd p in if n=O then p else facacc(n-i , n*cscc) end end in (Ay. facacc y, ~acacc(z+3 ,1)) end \nin (fst(f 7) )(8,1) end Here we have taken the liberty to extend the skeletal language with pairs, projections \n(fst and snd), integer con\u00adstants, and infix binary operations on integers (+, =, -, *). Also, we use \nparentheses for grouping. The above expression evaluates to the pair (O, 8!) = (O, 40320). 3 Region-Annotated \nTerms Tofte and Talpin[17] describe a type-based translation from source expressions to region-annotated \nterms (called target terms in [17]). These region-annotated terms cent ain only that type information \nwhich is needed for the evaluation of such expressions, namely region annotations. However, in this paper \nwe use the region-annotated expressions as source expressions for further type-based transformations, \nso it is useful also to have an explicitly typed version of the language. We therefore present both, \ntogether with an erase function from explicitly typed to untyped expressions. When convenient, we shall \npresent both an untyped and an explicitly typed version of our intermediate languages; the untyped version \ncontains only the information which is used in the dynamic semantics of the language, while the explic\u00aditly \ntyped expression contains information which is used for further translation. 3.1 Untyped Region-Annotated \nTerms Let RegVar be a denumerably infinite set of regaon variables, ranged over by p. For any syntactic \nclass, c, let Z denote the syntactic class defined by We now introduce syntactic classes of allocation \ndzrec\u00adtzves, a, regzon binders, b, and expressions, e, by a ::= at p b::= p e ::= truect I falsect ] \nz I (Xz. e)u / elez if ethen eelse e letz=ei.ne end letregion b in e end letrec ~[~](z)a = e in e end \nf [d]a This language of expressions will be used as our untyped language throughout, but we shall gradually \nrefine the defi\u00adnitions of allocation directives and region binders to provide more information. Let \nus briefly review theevaluation ofregion-annotated terms. (Details and an operational semantics are found \nin [17]. ) An expression letregion p in e end is evaluated thus: first a region is allocated and bound \nto p; then e is evaluated (probably using the region for storing and re\u00adtrieving values) and then, when \nend is reached, the region is deallocated. Anannotation of the format p indicates that thevalue of the \nexpression preceding the annotation should be put into the region bound to p. Writing a value into a \nregion adds the valueat the one end (referred to as the top) of the region, increasing the number of \nvalues held in that region by one. A function ~ bound by letrec is region-polymorphic: it has a (perhaps \nempty) list of formal region parameters and may be applied to different actual regions at different call \nsites. An expression j [d 1 atp creates a function closure in region p, in which the formals of ~ have \nbeen bound to the actual regions ii. We write letregion ~ in e end for letregion pl in letregion pk in \ne end . . . end when ~=pl, . . .. pk. Further, f[pl, . . ..pk] a abbreviates f[atpl,. ... atp~] a. Expressions \nof the form letregion p in $[pl, . . ..p~lat p (e) end (where p @ {pi,.. .,pk} and pdoes not occur free \nin e) are so common that we abbreviate them to just f[pl, . . ..pk] e. A region-annotated expression \ncorresponding to the source expression in Section 2 is shown in Figure 1. Aiken, Fahndrich and Levien[l] \nhave developed an analy\u00adsis which seeks to do the actual region allocation in letregion p in e end as \nlate as possible after the letregion and which seeks to do the region de-allocation as early as possible \nbe\u00adfore the end. In some cases they achieve asymptotic memory savings over plain region inference (where \nallocation is done at letregion and de-allocation is done at end), and the re\u00adsult can never be worse \nthan without their analysis. 3.2 Typed Region-Annotated Terms The type system presented in this section \nis essentially the one of [17]. The system has its roots in work on effect in\u00ad ference [9, 11,12,16], \nwhich is also used in connection with concurrency [14]. For the region type system, we assume a denumerably \ninfinite set TyVar of type variables, ranged over by a, and a denumerably infinite set EffectVar of eflect \nvariables, ranged over by c. An eflect, p, is a finite set of atomic effects. An atomic effect, q, is \neither a token of the form get(p) or put(p), or it is an effect variable. Types, r, types and places, \np, simple letregion pe, in letric f[po, p~, ps ,p9, plO, PII , P12$p13 ,p14>p151 ($) at p6= letreC fCScaCC[P16 \n,P17 ,f-hS] (p) at P7= let n=fst p in let ace= snd p in letregion p19 in if letregion p21 in (n = Oat \np21) at plg end then p else faCCSCC[p16 ,p17 ,p181 (letr_egion pz4 in (n -iat p24) at ,016 end, (n*acc)at \nplT)at plt3 end end end in ((~y. facacc[p13 ,P14 ,m51 y)at P12, facacc [P9 ,PIO ,plll (letregion p27 \nin (z +3at p27) at pll end, 1 at pIO) at pg) at pb end h letregion p28 ,p29 ,p30 ,p31 Pp32 in (letregion \np33 ,p34 ,p35 ,P36 in fst(letregion p3T in f [p37 $p31 ,p33 $p34 ,p3.5 ,p36 , P32 ,P2S ,p23 ,P30] T \nat p37 end) end) (8 at p30, 1 at p29) d p28 end end end Figure 1: A Region-annotated Expression type \nschemes, r, and compound type schemes, rr, take the form: p ::= (7-, p) u ::= r-I Vo .a I Ve.u An object \nof the form c.p (formally a pair (c, p)) on a function arrow p ~ p is called an arrow eflect. Here p \nis the effect of evaluating the body of the function. A finite map is a map with finite domain. The domain \nand range of a finite map ~ are denoted Dom(j) and Rng(j), respectively. When ~ and g are finite maps, \nf+g is the finite map whose domain is Dom(~) U Dom(g) and whose value is g(z), if z E Dom(g), and ~(z) \notherwise. ~ J A means the restriction of .f to A, and .f ~ .4 means .f restricted to the complement \nof A. A type environment, TE, is a finite map from program variables to pairs of the form (a, p) or (rr, \np). A substitution S is a triple (S , St, Se), where S is a finite map from region variables to region \nvariables, St is a finite map from type variables to types and Se is a finite map from effect variables \nto arrow effects. Its effect is to carry out the three substitutions simultaneously on the three kinds \nof variables. For any compound type scheme TE(f) = (~, P ) and type T , we say that T is an instance \nof ~ (vza S), m > ~ via S p = {get(p ), put(p)} written T z #, if there exists a substitution (9) TE\\ \nf,[(S) at P : (T, P), P such that S(7) = r . Similarly for simple type schemes. The instance lzst of \nS, written z1(S), is the triple More generally, we refer to triples of above form as instance lists and \nuse ii to range over them. Instance lists decorate applied (i. e., non-binding) occurrences of program \nvariables. We now present a type system for explicitly typed region\u00adannotated terms. It allows one to \ninfer sentences of the form TE !-e : p, y. Formally, an explicitly typed region-annotated term is a term \ne, for which there exist L and y such that TE + e : p, V. For given TE and e there is at most one such \nu and ~ (and at most one derivation proving TE 1-e : p, p). The type system is essentially the same as \nthe one in [17], except that we have dropped the source expressions and added type, region and effect \nannotations on terms. Region-Annotated Terms - (1) TE H true at p : (bool, ,0), {put(p)} (2) TE t-false \nat p : (bool, p), {put(p)} (3) TEI-el : (p --$Jp,p), pl, pl TEI-ez : p ,pz 9 = f40 UPI UP2 U{ C} U{get(P)} \n (5) TEFe1e2:p, p TE 1-el : (bool, p), pl TE1-e2:p, p2 TEFeg:p,pJ TE+ if el then ez else e3 : P, {get(p)} \nU PI U 91 U W3 (6) TE+el : (TI, PI), YI ~1 = VCZ?.71 fv(ti,~ nfv(TE, pl) = 0 TE+{z*[al.ol)}Ee2:u,~Q (7) \nTEI-let x:(uI, pI) = el in e2 &#38;d:y, plU~2 r = v~z.z 7/ = vG.7r fv(zi,j ,~) nfv(TE, pl) =0 TE+ {f-(~, \np)} E (A 9 z : pz.el)at p : (T, p), pI TE+ {f% (T , P)} r e2 : p,% TE 1-letrec f :(n , p)(z) = el in \nez end :p,pl Up2  (8) TE F e : p,p fv(~ ) nfv(TE, p) = 0 (10) TE k letregion p in e end :p, y \\ p For \nany semantic object A, frv(A) denotes the set of region variables that occur free in A, ftv(A) denotes \nthe set of type variables that occur free in A, fev(A) denotes the set of effect variables that occur \nfree in A and fv (A) denotes the union of all of the above. The erasure of an explicitly typed region-annotated \nex\u00ad pression e, written er(e), is an untyped, region-annotated expression obtained by erasing type and \neffect information. We show a couple of the defining equations: er(letregion p in e end) = letregion \nfrv p in er(e) end er(letrec ~ : (V@.r, p) (x) =el in ez end) = letrec ~ [~] atp=er(el) in er(ez) end \ner(f(_,IP,, ,P,l,-)at p) = ~CPl S.. .jpd at P 4 Multiplicity Inference Multiplicity Inference is concerned \nwith inferring for each region, how many times a value is put into that region. We introduce a syntactic \nclass of multzplzcttzes, ranged over by m: m::= 011 [03 Addition of multiplicities is defined by: o ifml=rnz=O; \nmlemz= 1 if ml = OA m2 = 1or vice versa { cm otherwise The maximum of ml and mz, written max(ml, mz), \nand the product of ml and mz, written ml @ m2, are defined similarly. 4.1 Untyped Multiplicity-Annotated \nTerms We modify the class of region binders to become: b::=p:m Let us assume that every region variable \np is only bound once in any given expression. We then define the multiplicity Of P, written red(p), to \nbe the multiplicity which occurs in the binder which binds p, and m otherwise (i.e., if p is free). Evaluation \nof multiplicity-annotated expressions can be defined using an operational semantics which has two region \nstacks, namely a stack of regions each of which can accept at most one write and a stack of regions each \nof which can ac\u00adcept an unbounded number of writes. (The dynamic seman\u00adtics for region annotated terms \nin [17] has only the second kind of region stack.) In an expression of the form letregion p : m in e \nend the multiplicity m is an upper bound on the number of times a value is put into the region which \nwill be bound to p at runtime. Thus, if m = m we allocate a region on the stack of unbounded regions \nand otherwise on the stack of write-once regions. In an expression letrec f[.. .,p:m ,.. .I (*) a=el \nine2 the multiplicity m is an upper bound on how many times the evaluation of the body of ~ (i.e., el) \nputs a value into p including calls that ~ may make to other functions or to itself. Consider a reference \nto f (in e] or in ez ) . f[...,, ] ...] . It is possible to have mul(p) < cm and rnul(p ) = m, signi\u00adfying \nthat f contributes a finite number of allocations to an unbounded region. Also, $ is polymorphic in multiplicities, \nin the sense that if we have some other call of ~: ~~~ f[...,, ,...] ~~~ we need not have mzd(p ) = \nrnul(p ). This flexibility was found to be important in practice without it, too many re\u00adgions were \nascribed multiplicity m. However, it means that the dynamic region environment has to map region variables \nto pairs of the form (r, m), where r is a region name (iden\u00adtifying the region) and m is the multiplicity \nof the region. At runtime, the multiplicity of a region is determined by the letregion expression which \ngenerates it and it never changes, so (r, m) can be regarded as a region name r with a multiplicity attribute \nm. When storing a value into a letrec-bound pit is now nec\u00adessary to test at runtime to see what kind \nof store operation should be performed. Allocation in the two kinds of regions is done differently; for \nunbounded regions we first have to allocate new space within the region, but for write-once re\u00ad gions, \nwe can write directly knowing that there will be space for one write. .  4.2 Typed Multiplicity-Annotated \nTerms A multiplicity effect is a finite map from atomic effects to multiplicities; we use @ to range \nover multiplicity effects. The extension of @ to a total map which is O outside the domain of ~ is denoted \n++. Let @I and 4Z be multiplicity effects. The sum of @l and ~2, written @l @ @2, is the multiplicity \neffect which has domain Dom(~l ) u Dom(~2 ) and values (01 @ !J2)(V) = ti:(n) @ 0/(7) Similarly, the \nmaximum of rJl and qJ2, written ma.z(@l, @2), is defined by (max(il, 42))(v)= ma~(+f(v), n(v)) Finally, \nwhen ~ is a multiplicity effect and m is a multiplic\u00adity, the scalar product, m Q $, is the multiplicity \neffect with the same domain as #J and values (m@ +)(q) = m @ (~(q)). The semantic objects of typed multiplicity-annotated \nterms are as those for typed region-annotated terms, except that effects are replaced by multiplicity \neffects everywhere. We shall also use r, S etc. to range over semantic objects with multiplicities, and \nthen use vertical bars (Irl, ]Sl, . . .) to refer to the semantic objects obtained by replacing every \nmulti\u00adplicity effect with its domain, which is an effect, We write + z @ to mean /+ ] = I@/ and ~ (~) \n~ +(q), for all v e Dom(dr). The typjng rules for multiplicity-annotated terms are: Multiplicity-Annotated \nTerms TE 1-e op @ ~ TE + true at p : (bool, p), {put(p) F-+ 1} (11) TE ~ false at p : (bool, p), {put(p) \n++ 1} (12) TE(.c) = TEE (ajp) Z,/(s) u : (r, > ~viaS P),{} (13) TE+{z+~l}l-e:p2, ~ @@?J =?/ TEt-(A J \nz :pl.e)atp: (fll ~ P2, P), {Put(P) + 1} (14) TE 1-el : (bool, p), @l TE k ez : IL,42 TEI-\u00ad ez : P,413 \nTE k if el then e2 else e3 : P){get( p) +-+ 1} @ 41 @ maz(@2, @3) (16) TEFel :(rl, pi), ~l aI = Vd?.rl \nfv(d, ?) n fv(TE, @l) = IJ TE+{z+(al, p1)}ke2:P, ~2 (17)TEt-let x:(aI, pI) = el in e2 end:,u, @l @@2 \n T = v;;.~ 7r = Vci . ir fv(d, ~, 7) nfv(TE, v,) = 0 TE+ {f* (n, p)} 1-(A + z : ~~.el)atp : (T, p), \n@I TE+ {f w (~ , p)} t-e2 : P,ti2 TE t-letrec ~ : (x , P)(x) = el in e2 end : p,@l @42 (18) TE(f) = (~,/) \nm > r via S @ = {get(p ) ++ l,put(p) * 1} (19) TE Ef,~(sl at P:(T,P),TJ TEE e : p,@ fv(~ ) (T fv(TE, \n~) = o (20) TEE letregion ~ in e end: p,@ ~ I@ 1 TEt-e:p, $ @ 2ti (21)TEt-e:p, $ Note that union of \neffects has turned into sum of mul\u00adtiplicity effects, except at the conditional, where maximum is used. \nA more substantial change is in the definition of what it means to apply substitutions (rules 13 and \n19 rely on this) A (multiplicity) substitution is a triple S = (Sr, S , S ), where St is a map from type \nvariables to types, S r is a map from region variables to region variables and Se is a map from effect \nvariables to multiplicity arrow effects (~.~). Each of these finite maps extend to total maps in the \ncase of Se by mapping each effect variable e outside the domain of S to the multiplicity y arrow effect \n6.{}. We define S (?J) = !@{put(s (p)) +-O(put(p)) I Put(P) E 141} @ @{get(S (p)) * d(get(p)) Iget(p)Gltfl} \n@ ~ J EffectVar S (IJ) = 4 [ Effectvar EE @{w8({f +-1} @ lb )I Moreover, define Se(c,@) = 6 .(+ 63 S \n(?J)) where c . # = Se(c). Finally, we define (S , S , S )(A) = S (Se(S (A))) where A can be an arrow \neffect, a type or a type and place. Substitutions can also be applied to type schemes, after re\u00adnaming \nof bound variables to avoid capture, when necessary. Finally, a substitution can be applied to a type \nenvironment TE by applying it to every pair (a, p) or (rr, p) in the range of TE.  We say that a multiplicity-annotated \nexpression e is well\u00adannotated in TE if there exists a p and a ~ such that TE b e : p, @. For given TE \nand e, there exists at most one such p and ~. Multiplicity Inference is the following problem: given \nTE,e,pand pwith TEt-e:p:paccording torules ( 1)-(10) and given a multiplicity type environment TE with \nITE I = TE, find a multiplicity-annotated term e which is well-annotated in TE and satisfies \\e I = e. \nWhen e is closed, there is a trivial solution to the Multi\u00adplicity Inference Problem: choose all multiplicities \nto be co. The object is of course to choose multiplicities as small as possible. Vejlstrup s M. SC. thesis[l \n8] contains a multiplicity infer\u00adence algorithm and a proof that it is correct and always ter\u00adminates. \nThe algorithm does not always find minimal mul\u00adtiplicities. One problem is that substitution and maximum \ndo not commute; in general one only has S (maZ(@I, 42 )) z rnaz(Se(~l ), Se(@2)). In particular, if a \nlambda-bound vari\u00adable, ~, occurs in two different conditionals, unification on the type of of ~ during \nthe multiplicity inference of the sec\u00ad ond conditional can increase the effect of the first condi\u00adtional: \nc, {Pllt(~2jj ,(int, p2), P3). Jf : ((int, pl) let z = if true then 1 at p2 else ~(1 at pl) in if true \nthen (~~,1 at pz) at 03 else ~ Here the effect of evaluating z will end up having two put effects on \np2, although one would be sound. Judging from experience, however, the algorithm is usu\u00adally good at \ndetecting finite regions (see Section 9). Erasure of a typed multiplicity-annotated term gives an untyped \nmultiplicity-annotated term. We show some of the defining equations: er(letregion V in e end) = letregion \nbl...bk in er(e) end where {pI, . .,p~} = frv(~) and b, = p, : ~+(put(pt)) fori=l. ..k. er(letrec ~ \n: (m , p)(z) = el in e2 end) = letrec ~[bl ,, ., b~]atp=er(el) in er(ej) end where m = Vpl,. ... pkd(fi]i] \nQLL2) and b, = p, : #+(put(p,)), z = l.. k.  4.3 Removal of get-regions Consider a declaration of the \nform letrec ~[~] (z) a = e in e end Write ~intheform pl:ml, . . ..p~. rnIfp~{ pl,ljp~}jp~} is such that \nthere is no put(p) anywhere in the type of ~, then ~ does not really need p: putting a value into a region \nrequires region information, but reading a value does not. Such region variables are called get-regions \n(of ~). They can be eliminated from the list of region formals, provided the corresponding actual arguments \nin calls of ~ are removed too. letregion fJ6 :1 in letrec j[@:i, @:l, @:~, ~lo:~,pll:~, P12:I, P13:0, \nP14:0, P15:O] ($) at f6 = letrec &#38;acc[/216 :~ ,~17 :@3, ~18 :@] (~) at P7= let n=fstpin let acc =snd \npin letregion p19 :1 in if letregion p21 :1 in (n = Oat p21) at p19 end then p else ~acacc[/?16 ,p17 \n,p18] (letregion p24: 1 in (n -Iat p24) at ~lg end, (n * ace) at p17) at ~16 end end end in ((J y. facacc[p13 \n,,014 ,p151 y) at p12, (*l*) facacc [pg , pIO ,pII] (letregion p2i: 1 (z +sat p2i ) at fhl end, 1 at \nplo) at pg) at ps end in letregion p2s:@, p2g:C0, p3!3:~, p3~ :1, p32:i in (letregion p33 : 1,p34 :~, \np35 :~ ,p36 :@ in fst(letregion p37: i in f [p31 ,p33 $p34 ,p35 ,p36 , p32 ,p28 ,p29 ,p30] 7 at p37 end) \nend) (8 at 030. 1 at ozg) at PM end end end Figure 2: After Multiplicity Inference and elimination of \nget-regions In what follows, we always use the more aggressive erase operations which removes both type \ninformation and get\u00adregions. The erasure of a typed multiplicity-annotated ex\u00adpression which corresponds \nto the region annotated exam\u00adple in Figure 1 is shown in Figure 2. Notice that most re\u00adgion binders have \nbeen given finite multiplicity and that ~ has had the get-region PO removed. The ly.facacc y in line \n (*I*) is put into a write-once region ( p3Z ), which eventually is stack-allocated, even though the \nclosure escapes . 5 Unboxed Values In the plain region inference scheme[17], every value is repre\u00adsented \nboxed , i.e., by a pointer to the actual value, which resides in a rezion. However, it is not necessary \nto box val\u00adues whose natural size is not bigger than what a register can hold. Let us refer to such values \nas word-sized. In the ML Kit, the word-sized values are conservatively defined to be precisely the integers \nand the booleans. Storing a word\u00adsized value allocates no space in memory; it just stores the value in \na register, Let r be a region at runtime. If all put operations on r are putting word-sized values, then \nno values at all are put into r, and r could be eliminated altogether. Z hZs holds, even if there are \nrnultzple put operations to the region. For every storage operation vat p in the program, enough of the \ntype of v is known statically to decide the appropriate repre\u00adsentation (boxed/unboxed). This relies \non the fact that v is a syntactic value. Detecting whether all storage operations to p store word-sized \nvalues requires a simple region flow analysis, which we describe in this section. If p is a formal parameter \nof some letrec-bound function, $, and all stores to p are stores of word-sized values, then p is removed \nfrom the list of formal parameters of ~, and all the corresponding actuals in applications of ~ are removed \ntoo. l hs zs true even if the rnultzplicity zn the binder of p is not finite. This removes many region \nparameters in practice. In ML, all functions take one argument; multiple ar\u00adguments are represented by \na tuple which in the Kit always is a boxed tuple. This is simple but inefficient. No doubt, careful data \nrepresentation analysis[10,15,8] would be very useful with regions. This has not yet been explored, how\u00ad \never. 5.1 Modified Syntax We extend allocation directives to become a ::= at p \\ ignore In examples, \nwe abbreviate v ignore to v. In the dynamic semantics, evaluating v ignore just re\u00adsults in v without \nperforming any allocation in any region. 5.2 Boxity Constraints Let RegionTyVar be a denumerably infinite \nset of region type vartables, ranged over by r. We introduce region types rt rt::=ll word I T I r Ground \nregion types are ordered by J_~ word ~ T. In\u00adtuitively, a region can be given type word if all the values \nstored in it are word-sized. (The region need not have finite multiplicity. ) Top (T) stands for all \ntypes that are not of word size, e.g., record types and function types. Bottom ( l-) is the type of region \nvariables p for which no atp occurs in letregion p6 :1 in letrec f[p~:i,ps:~,pg:~, ,012:1, P13:O] (Z) \nd. p6 = letrec faWX[p16 : ~] (~) at P7 = let n=fstpin let ace= snd pin ifn=Othenp else ~@XZcc[p16] ((n \nl, n*acc)at p16) end end in (( Ay. facacc[p131 y) at p12, facacc[pg] ((~ + 3, l)atPg))atP6 end in letregion \np2s :~ ,p31 :1 ,p32 :1 in (letregion p33 :1 ,pw :ca in fSt(f [p31 ,pst ,p,~ ,p32 ,p28] 7) end) ((8, 1)at \np2/3) end end end Figure 3: After elimination of word-typed regions the program. (Get-regions of region-polymorphic \nfunctions have region type 1, if they are not removed.) The type system of region types is monomorphic \nin that every region variable is assigned a ground region type. The analysis which assigns region types \nto region binders is a simple constraint-based analysis. A constraint takes one of the two forms r~ rt \nor r~r . A finite set of constraints has a minimal solution (with respect to Q). It can be shown that \nthis solution can be found in time which is linear in the number of constraints in the set. Constraints \nare generated as follows: every binder p : m is associated with a fresh region type variable, written \nr(p). For every subexpression tyue at p or false at p of e, we generate a constraint r(p)~word. For all \nother at p in e we generate a r(p)~T constraint. Furthermore, if f is declared by letrec $[p~ :rnl, . \n. ..pj :rnk] (z) at p = el in e2 then for every reference to ~: f_bI). ... Pkl at P we generate the \nk constraints r(p,)~r(p~ ), 1 < ~ < ~. Once the minimal solution has been found, every region binder \np : m which has been assigned region type word or less is removed from the program, thus reducing the \nnum\u00adber of letregions and the number of parameters to region\u00adpolymorphic functions. Furthermore, all \nallocation direc\u00ad tives at p (for the p in question) are changed into ignore. When a formal region parameter \nis removed, all correspond\u00ading actuals must of course be removed too. The result of removing word regions \nfrom Figure 2 is shown in Figure 3. Notice that by now, all letregion-bound region variables with infinite \nmultiplicity, except p2s and P34, have been eliminated. At runtime, there will be just two infinite regions. \n6 Storage Mode Analysis The purpose of storage mode analysis was explained in the Introduction. It operates \nwith the following allocation di\u00adrectives and binders .. a .. atp I attopp I atbotp I satp In the input \nexpression, all allocation directives take the form atp; in the output, every at has been turned into \nattop, atbot or sat. The idea is that one can transform at p into atbot p at some program point p, if \nand only if, whenever p is reached during evaluation, the rest of the eval\u00ad uation does not use a value \nwhich has already been stored into the region to which p is bound. Storage mode attop should be used \nwhen it is certain that the region will contain live values; sat ( somewhere at ) should be used when \nthe decision about storage mode should be delayed till runtime (typically when p is letrec-bound). Storage \nMode Analysis is based on statically inferred Iiveness properties. Liveness analysis has to take tempo\u00adrary \nvalues into account. Inspired by the A-Normal Form of Flanagan et al[7], we shall therefore assume that \nthe in\u00adput expression to the storage mode analysis conforms to the following grammar of regzon annotated \nK-Normal Form ex\u00adpressions: .. e .. Xd I Va I X2i~d I .ftf[~l m Zd I if $,1 then e else e I letz:(cr, \np)=eine I letrec .f : (m, pII)[~I (x) aO = e in eend I letregion b in e end v ::= true I false I Az : \ny.e The key idea is that every intermediate result of the com\u00ad putation is bound to a variable. The type \ninformation (a,x and ~) in K-Normal Forms is provided by region inference. Transformation into K-Normal \nForm can be done in linear time and does not affect the runtime behaviour of the ex\u00ad pression. (Unlike \nFlanagan et al we do not linearise let bindings, as this would affect region inference in a negative \nway. ) To enable region polymorphic functions to be applied in contexts that allow different degrees \nof region overwriting, we pass the storage mode itself along with the region at runtime. Thus we have \nnot only multiplicity polymorphism (Section 4) but also storage mode polymorphism (since we found that \nnot having it made too many regions too big). At runtime, a region may be accessible via more than one \nregion variable, if it is passed as actual argument to a region polymorphic function. This is called \nregzon abasing. Storage Mode Analysis must take region aliasing into ac\u00ad count. We propose the following \nglobal, higher-order region flow analysis. A directed graph G is built. There is one node in G for every \nregion variable and every effect variable which occurs in the (K-normalised) program. (Thus, we can identify \nvariables with nodes. ) Whenever the program has a letrec-bound program variable ~ with type scheme and \nwhenever there is an applied occurrence of ~: there is an edge from p, to P; and from c~ to .c$. Similarly \nfor let-bound variables. Finally, for every effect c.p occur\u00adring anywhere in the program, there is an \nedge from ( to every region and effect variable which occurs free in ~. In the graph that arises thus, \nletregion bound variables are always leaf nodes and region variables only lead to region variables. For \nevery node n in G, let (n) denote the set of variables that are reachable in G starting from n, including \nn itself. Let p be a region variable and let e be a region annotated expression which first binds p and \nthen refers to p. The stor\u00adage mode analysis depends on a distinction between whether there is a A between \nthe binder of p and the use of p, or not. To be able to make this distinction precise, we introduce three \nkinds of contexts. Two of these are local, meaning that they do not allow going under lambda (or letrec). \nA local expression context, L, takes the form L ::= [] ] if z,~ then L else e, I if tit then e2 else \nL \\ let x:(a, p) = L in ez I let r:(cr, p) = el in L I letrec ~ : (iT, po)[;] (z) ao = el in Lend I letregion \nb in L end Next, local allocation contexts, R, are given by R ::= L[v []] I L[~,l[al,..., al,[], a,+l,l, \na~l, a~l aox,{] I L[f,i [d] [ ] x ,1] I L[letrec .f : (rr, pO)[;l (x) [] = e, in e2 end] The last of \nthe three kinds of context is a (global) expression context, which allows one to single out an arbitrary \nsubex\u00adpression: E ::= L I L[let x : (alp) = (Ax : p.E)a in e end] I L[letrec f : (n-, p) [;] (z) a. = \nE in e2 end] Given a local context L we say that a program variable z is live at the hole of the conted \nif it is a member of the set LV(L), defined by: LV([ ])= 0 LV(if Zzl then L else e~) = LV(L) LV(if Z,l \nthen .2 else L) = LV(L) LV(let z : (CT,p) = L in e2 end) = LV(L) U (FV(eZ) \\ {z}) LV(let x : (a, p) \n= el -in L end) = LV(L) LV(letrec ~ : (~, po)[b] (z) ao = el in L end) = LV(L) LV(letregion b in L end) \n= LV(L) Here FV(e) means the set of program variables that occur free in e.   f([...p],[?],[?e;[...e; \n9;...]) The definition is extended to local allocation contexts, R, as follows: LV(L[V []]) = FV(V) \nU LV(L) (22) LV(L[~,i [al, . . . . a,_l, [], a,+I, . . . ,a~] ao z,,])= LV(L) (23) LV(L[f,l[d] [] Ztl]) \n= {f, z} U LV(L) (24) LV(L[letrec ~ : (r, po)[~] (z) [] =elin ez end]) = (FV(eI) \\ {~, z}) U (FV(ez) \n\\ {~}) uLV(L) Intuitively, a variable is live at a hole in a local context, if the variable is in scope \nat the hole and is used by the compu\u00adtation up to end of the context. In (22), v can be a lambda abstraction; \nthe free variables of v are considered live at the allocation Doint. since thev must be Dut into the \nclosure for v after memory for the cl&#38;ure has ~een allocated. In (23), the set of live variables \nis just LV(L), since the storage mode which is passed to ~ indicates whether the region contains values \nthat are used after f returns. In (24).,/ however. . .f \\ is considered live at the allocation point: \nat runtime, first space for the closure is allocated and then the closure is cre\u00adated by appling ~ to \nthe actual regions. ) Similarly, in the case for letrec. f is not considered live at the hole. since \nthe space for the region closure representing ~ is allocated before the closure is created. Let e be \nan expression in K-normal form. For simplic\u00adity, we assume that e has no free program variables, that \nall bound program variables are distinct and that every region-polymorphic function has at precisely \none region pa\u00adrameter. (The generalisation to many region parameters is straightforward. ) Let z be a \nprogram variable which oc\u00adcurs in e. Let (T, p) be the type annotation of the binding occurrence of x \nj where T takes one of the forms ~, a or m, de\u00adpending on how x is bound (see the definition of K-normal \nforms). We define the Zive region variables of z, written h-v(z), to be the set {(p) I p c frv(T, p)} \nU {(c) (l RegVar I c c fev(T)}. Next, when X is a set of variables occur\u00adring in e we define b-v(X) = \nU{hw(z) I z c X}. Let C be an allocation context of the form E[R]. We say that a region variable p is \nbound non-locally m G , if C cannot be written in the form E [letregion p : m in R end] or E [letrec \n~ : (m, PO) [p : m] (z)u=R in ez end] for any E and R . (In other words, p is bound non-locally in C, \nif there is an incomplete A or letrec between the binder of p and the hole of the context. ) The following \nrules make it possi\u00adble to change every atp occurring in e into attop p, atbot p or sat p. p @ h-v(LV(R)) \n(25) E[letregion p : m in R[at p] end] + E[letregion p : m in R[atbot p] end] p G bw(LV(R)) (26) E[letregion \np : m in R[at p] end] + E[letregion p : m in R[attop p] end] lrv(LV(R)) n (p) = 0 (27) E[letrec f[p : \nm] (z)a=R[at p] in ez end] + E[letrec f[p : m] (z)a=R[sat p] in ez end] b.J(Lv(R)) n (P) # 0 (28) E[letrec \nf[p : m] (z)a=R[at p] in ez end] ~ E[letrec f[p : m] (z)a=R[attop p] in ez end] letregion p6 :1 in letrec \nf[@ :i$ps:i,pg:~, P12 : i,p13 :0] (Z) atbot p6 = letrec facacc[p16: m] (p) sat pT = let n=fst p in let \nace= snd p in ifn= O then p else ~acacc[sat p16] ((n-l, n*acc) sat p16) end end  (*:) (( Ay. facacc[attop \np131y)sat p12, (*2*) facacc[sat p9] ((z + 3, I)sat pg) ) at P8 end in letregion pz6 : ~ ,p31 : i, p32 \n:1 in (letregion p33 :1 ,p34 : co in fst(f [atbot p31 , atbot PSS, (*3*) atbot p3J , atbot p32 , atbot \npza] 7) (*4*) end) ((8, i) attop pza) end end end Figure 4: After storage mode analysis p bound non-locally \nin E[R] (29) I?[R[at p]] + EIR[attop p]] For brevity, we have shortened f : (n, PO) to f in (27) and \n(28). In (25), atbot is justified by the fact that no value which is used up to the point where the region \nis de-allocated resides in p. (Here it is essential that R is a local context. ) In (27), sat is justified \nby the fact that neither p nor any region with which it may be aliased contains a value which is needed \nby the rest of the body of $. Finally, in (29), we conservatively use attop, if p is bound outside the \nclosest surrounding function. Rules 25-29 have been implemented and tested in the Kit, but not proved \ncorrect. Figure 4 shows the result of applying storage mode anal\u00adysis to the expression in Figure 3. \nAt line (*I*) notice that we get attop p13, by (29). Thus pairs will pile up in p26 during the evaluation \nof the application in line (*Q*). By contrast, we get sat P9 in line (*z?*), by (27). In line (*s*), \np34 k passed as region actual corresponding to p9. This happens with mode atbot, using (25), so that \nthis in\u00adfinite region P3A will only ever hold one pair. 7 Physical Size Inference At every value allocation \nv@p (where @ c {attop, atbot, sat}), the size of the value can be computed statically. (Every function \nis represented by a flat closure which contains the values of the free variables of the function.) Also, \nthe multiplicity of the region is known. In case the multiplicity is finite, the physical size of the \nregion is to be the maxi\u00admum size of values that may be stored at p or at any region variable with which \np can be aliased. This maximum can be found using the graph G computed in Section 6. .*lu u /, Kit, s \nNJ93, sg~ \u00ad 8 The Kit Abstract Machine life I 376 I 1,952 I 24% The KAM has a runtz me stack, an infinite \nnumber of reg\u00adu-ters and a region heap. The operations of the KAM are similar to those of Appel[2], extended \nwith operations for allocating and deallocating regions and for allocating mem\u00adory in regions. Region \nnames (Section 4.1) are represented as 32 bit words, with the two low order bits being used for storing \nthe region size (finite/infinite) and the storage mode (attop/atbot). The KAM has operations for setting \nand testing these bits. The region operations are implemented by a runtime system written in C. A region \nof unbounded size is represented by a linked list of fixed-size blocks of contiguous memory in the region \nheap. Regions with finite size are implemented on the run\u00adtime stack. That is, upon evaluating letregion \np : k in e end, where k is a finite physical size, the variable p is bound to the current stack pointer \nwhich is then increased with k words. Then e is evaluated and the stack ~ointer decreased by k words. \n!3 Experimental Results The purposes of the experiments were (a) to assess the feasi\u00ad bility of region-based \nexecution by comparing the time and space requirements of object programs produced by the Kit to time \nand space requirements of object programs produced by a first-rate ML compiler, namely Standard ML of \nNew Jersey, and (b) to assess the importance of multiplicity in\u00ad ference and storage mode analysis. The \nbenchmarks fall into two categories: (1) small pro\u00adgrams designed to exhibit extreme behaviour (fib, \nreynolds2, reynolds3, dangle and tailloop); and (2) non-trivial pro\u00adgrams based on the Standard ML of \nNew .Tersey distribution benchmarks (life, mandelbrot, knuth-bendix and simple); the largest benchmark \nis simple (approx. 1150 lines of SML). The smallest benchmarks are shown in Section 9.3. In tables, we \nseparate small benchmarks from other bench\u00admarks by a horizontal line. All benchmarks were executed as \nstand-alone programs under the ML Kit (using the PA-RISC code generator) and Standard ML of New Jersey[3], \nversion 93 on an HP PA-RISC 9000s700 computer, All running times are in seconds (user time, measured \nby the UNIX time program). Space is maximum resident memory in kilobytes (measured by the UNIX top program). \n9.1 Comparison with Standard ML of New Jersey The numbers presented here must be read with caution, since \nthe two compilers are very different. Howeverj the numbers do give a rough indication of the feasibility \nof region\u00ad based execution. Figure 5 shows a comparison of space usage. There can be dramatic differences \nbetween using region inference and using a ( reference tracing) garbage collector. These differ\u00ad ences \nwill be explained in Section 9.3. Figure 6 shows running times in seconds, still on the HP PA-RISC 9000s700. \nThe numbers are Unix user time . The relatively poor performance of the Kit on simple is probably due \nto the fact that this benchmark makes inten\u00ad mandelbrot 352 852 41% knut h-bendix 4)000 2,300 174% simple \n2,100 I 95% I I ~,~oo fib I 92 I 1,000I 9% reynolds2 96 1,212 8% reynolds3 40,000 1,204 3,322% dangle \n224 45,000 0.5% taiiloop 96 880 I 11 % Figure 5: Comparison of space between the ML Kit and SML/NJ version \n93. All numbers are in kilobytes and indi\u00adcate maximum resident memory used. t*loo% Kit, t NJ93, tg~ \nlife 14.2 12.3 115!4 % mandelbrot 43.4 24.9 174.370 knuth-bendix 32.4 27.8 116.5 ~0 simple 62.2 17.4 \n357.570 f lb 10.8 27.9 38.7 % reynolds2 16.7 29.2 57.2% reynolds3 23.8 27.7 85.9% dangle 1.56 14.4 10.8% \ntailloop 4.79 1.96 244 % Figure 6: Comparison of running times (in seconds) sive use of floating point \nnumbers, which are implemented very inefficiently in the Kit. Considering that the Kit compiles programs \nvery naively, apart from everything that has to do with regions, it ap\u00adpears that neither the extra cost \nassociated with allocating into multiple regions nor the overhead of runtime region pa\u00adrameters are prohibitive \nin practice.  9.2 Region Representation Inference Figure 7 summarises the static results of region representa\u00adtion \ninference. In all the benchmarks, except tailloop, at least three out of four region variables were found \nnot to belong on the region heap. letregions word stack heap life 469 23% 56 % 2070 mandelbrot 112 Zyyo \n58 % 14% knuth bendix 1014 17% 66 % 16% simple 2648 21% 66 % 11% fib 14 72% 28% 0% reynolds2 85 21% 58 \n% 20% reynolds3 85 20% 57 % Zzyo dangle 13 38% 46 % 15% tailloop 9 0 z. 6670 33 % Figure 7: For each \nprogram, the table shows how many le\u00adtregion binders the region-anuotated program contains, and the partitioning \nof these according to how they will be allo\u00adcated at runtime. Figure 8 shows the distribution of allocations \namongst stack and heap at runtime. In all cases, except dangle, at least 85% of allocations were stack \nallocations. Remarkably, the largest of the programs, simple, had more than 99 % of 180 all allocations \nhappen on the stack. The difference between Space, .m.~~~% lime, ~m*~~~% the number of heap allocations \nfor -$CO s tm t reynolds2 and reynolds3 shows that the static frequency of life 548 138% 50.4 355% infinite \nletregionsis not necessarily a good indication ofdy-mandelbrot 9,988 2,837~o 514% I ~~3 I namic behaviour \n(compare Figure 7). Notice that although Irnuth-bendix 6,612 165% 77.9 240% reynolds3 spaceleaks in the \nKit, thespaceleak ison the simple 3,860 I 184% I 296 I 476% heap and the vast majority of allocations \narestill stack al-f lb 116 I 32.4 I 300% 129% I locations and cause no space problems. This fits with \nour reynolds2 120 125% 50.4 301% general experience that space leaks with region inference reynolds3 \n40,000 100% 86.8 365% tend to stem from fewisolated spotsin the program. (This dangle 1,732 687% 4.83 \n310% experience is based on the fact that we have built a region tailloop 96 100% 10.2 208% profiler \nwhich can trace region sizes, ) Figure 9: Space and time used in the Kit when all multi-To assess the \nimportance of multiplicity inference, the plicities are set to cm. The numbers are compared with the \nbenchmarks were also compiled and run on a version of the ~esults from Figures 5 and 6. Kit in which \nall multiplicities were set to infinity (while all other analyses were left enabled), see Figure 9. For \nall the benchmarks, multiplicity inference gives speedups of more s~*loo$% tT*loo Yo tT  than 200Yo: \nallocation into a region of finite multiplicity is t cheaper than allocation into a region of unbounded \nmulti\u00ad 14.8 104 0  --%7% 45.9 106% plicity. Multiplicity inference does not always yield big space \n100% savings; it depends on whether many regions exist at the 116% 38.3 118% same time. 76.2 101% 123% \nTo assess the importance of storage mode analysis, the -11.4 105 0 benchmarks were then compiled and \nrun on a version of the 100% 18.5 111% Kit in which all storage modes were selected to attop (while 100% \n25.2 106% all other analyses were left enabled), see Figure 10. With 107% 1.70 109% storage mode analysis \nenabled, tailloop runs in constant ~ space, but without storage mode analysis, a memory over\u00adflow occurs. \nFor life, the storage mode analysis ensures Figure 10: Space and time used in the Kit when all storage \nthat at most two generations of the game are alive at the modes are set to attop. The numbers are compared \nwith same time. (Without storage mode analysis, all generations the results from Figures 5 and 6. tailloop \ncrashes with pile up in the same regions. ) That there are many cases memory overflow. where storage \nmode analysis does not bring down the max\u00ad imal space usage is not surprising: maximal space usage is \nnot necessarily reached by the kind of iterative computations most obvious candidate is to allow more \nthan one function for which storage mode analysis is intended. argument register and more than one function \nresult reg- Multiplicity inference appears to give significant time ister. Also, the Kit (quite unnecessarily) \nrepresents every savings, across all benchmarks. Storage mode analysis is function by a closure, even \nwhen all the call sites are known. more erratic: it serves an important purpose for some iter-Finally, \nimproved in-lining might help. The Kit evaluates a ative computations, but these do not necessarily dominate \ncomparison like i=O by building a tagged tuple, passing it to overall space usage. the equality function \nof the prelude, which takes apart the Judging from the very high proportion of allocations that tuple, \ncalls the polymorphic equality function in the runtime happen on the stack in the Kit, optimisations \nthat move system, which eventually returns an integer, which is then stackable regions into registers \ncould be very important. The compared against an integer, resulting in a branch and store in a register. \nWe believe that this could be improved. stack al\u00ad 9.3 Discussion of extreme behaviour loca\u00ad tions, S \nIn this section we analyse some of the small benchmarks, life 28,269,922 which were designed to exhibit \nextreme behaviour. Here is mandelbrot 158,376,021 340 > 99.9% reynolds2: Irnuth bendi.x 51,962,334 8,684,852 \n86% simple 96,903,575 728,713 99.2% dat at ype a tree = fi.b 1 o 1000 Lf reynolds2 25,165,846 91 > 99.9% \nI Br of a * a tree * a tree reynolds3 42,991,640 4,194,393 91% dangle 2,002,002 4,007,008 33% fun mk.tree \nO = Lf tailloop 4,004,004 4,004,006 50% I rnk.tree n = let val t = mk_tree(n-1) * in Br(n, t,t) Figure \n8: For each ~ro~ram, the table shows how manv end .W . allocations of objects were done in total at runtime \n(not including objects of runtime type word) and the partitioning fun search p Lf = false of these according \nto whether they were done on the stack I searchp (Br(x, tl, t2)) = or the heap. if p x then true else \nsearch (fn y => y=x orelse p y) tl orelse \\ndone\\n ) search (fn y => y=x orelse p y) t2 in output(std_ \nout, val it = search (fn _ => false) (mlr.tree 20) \\nlooping.. .\\n ); output(std_out , The program reynolds3 \nis obtained by replacing the search loop (maxint,maxint )) function ofreynolds2 by: end; fun member(x, \n[]) = false Integers themselves are unboxed, but without storage mode I nrernber(x,x ::rest) = analysis, \nthe integer pairs fill up the memory. x=~~ orelse rnernber(~, rest) fun search p Lf = false 10 Conclusion \nI searchp (Br(x,tl,t2)) = We have presented a series of region-based analyses for map\u00ad if member(x,p) \nthen true ping an abstract stack ofregions onto real machines. All of else search (x: :p) tl orelse search \n(x::p) t2 these analyses were devised tosolve needs which became ev\u00adident from practical experiments. \nThe combination of anal- Irrespective of whether region inference or garbage collection ysespresented \nhere often works well in practice, but we have is used, the running time is exponential in n, where n \nis also shown examples whichsuggest that it mightbe useful to the argument to mk_tree. (n is 20 in the \nexample. ) In provide garbage collection as a supplement to region infer\u00adreynolds2, the polymorphic recursion \nof region inference ence, to handle those cases where the various static analyses separates the lifetimesofp \nand (fn y => y=x orelse p y). cannot cope. (Such cases will always exist, forundecidablity In reynolds3, \nhowever, p and x::p are put in the same reasons. ) It is noteworthy, however, that all the benchmarks \nregion, for region inference does not distinguish between a we tried from the SML/NJ test suite could \nbe made to run list and its tail. With region inference, space consumption relatively well, even without \ngarbage collection and without is linearin running time with reynolds3 and logarithmicin many of the \noptimisations one expects to find in a mature running time with reynolds2. With garbage collection, it \ncompiler. is logarithmic in both cases. Here is dangle: Acknowledgements fun mklist O = [] I mklist n \n= n :: mklist(n-1) We wish to thank Martin Elsman and Niels Hallenberg for their work on the Kit, Raph \nLevien for finding mistakes fun cycle(p as (m,f)) = in earlier versions of the storage mode analysis \nand Greg if m=O then p Morrisett for good advice on code generation. This work else cycle(m-1, is funded \nby the Danish National Research Council, in the let val x = [(m, mkli.st 2000)] form of a Ph.D. scholarship \nfor the first author and the DART in fn () => #l(hd x) + fo grant for the second author. end ) val r \n= cycle(1000, fno => O); References Region inference ensures that the list lproducedbymklist [1] Alexander \nAiken, Manuel Fahndrich, and Raph Levien. 2000 is discarded immediately after the closure for fn () Better \nstatic memory management: Improving region\u00ad=> #l(hd x) + fo is produced; note that the function will \nbased analysis of higher-order languages. In Proc. of not access 1 in fact the closure will contain \na dangling the ACM SIGPLAN 95 Conference on Programming pointer[17]. In garbage collected systems which \ndo not allow Languages and Implementation (PLDI), pages 174-185, dangling pointers, the space usage is \nO(rn x n), where m and La Jolla, CA, June 1995. ACM Press. n are the arguments to cycle andmklist, respectively \n(here [2] Andrew W. Appel. Compding with Continuations. m = 1000 and n = 2000). With region inference, \nthe space Cambridge University Press, 1992. usage is just O(m). Finally, here is tailloop: [3] Andrew \nW. Appeland David B. MacQueen. A Stan\u00addard ML compiler, In Gilles Kahn, editor, Functional val x= Programming \nLanguages and Computer Arclutecture, let ACM) Springer-Verlag, Sept 1987. val maxint = 2000 val zero \n= (0,0) [4] Lars Birkedal, Nick Rothwell, Mads Tofte, and fun is_zero(O,O) = true David N. Turner. The \nML Kit (Version I). Technical I is_zero _ = false Report DIKU-report 93/14, Department of Computer fun \nsub (m,n) = Science, University of Copenhagen, Universitetsparken if n=O then (m-l, maxint) 1, DK-2100 \nCopenhagen, 1993. else (m, n-1) fun loop (x as (m,n)) = [5] L. Damas and R. Milner. Principal type schemes \nfor if is.zero x then x functional programs. In Proc. 9th Annual ACM Symp, else loop(sub x) on Principles \nof Programming Languages, pages 207 fun loop p = (loop p; 212, Jan. 1982. [6] Martin Elsman and Niels \nHallenberg. An optimizing backend for the ML Kit using astack of regions. Stu\u00addent Project, Department \nof Computer Science, Uni\u00adversity of Copenhagen (DIKU), July 5 1995. [7] Cormac Flanagan, Amr Sabry, Bruce \nF. Dubs, and Matthias Felleisen. The essence of compiling with con\u00adtinuations. In Proc. of the A CM SIGPLAN \n93 Confer\u00adence on Programming Language Deszgn and Implemen\u00adtation (PLDI), June 1993. [8] Fritz Henglein \nand Jesper J@rgensen. Formally opti\u00admal boxing. In Conference Record of POPL 94: 21st .4 CM SIGPLAN-SIGA \nCT Symposium on Principles of programming Languages, pages 213-226. ACM Press, January 1994. [9] P. Jouvelot \nand D.K. Gifford. Algebraic reconstruction of types and effects. In Proceedings of the 18th ACM Symposium \non Princ~ples of Programming Languages (POPL), 1991. [10] Xavier Leroy. Unboxed objects and polymorphic \ntyp\u00ading. In Conference Record of the Nineteenth Annual ACM SIGPLAN-SIGA CT Symposium on Principles of \nProgramming Languages (POPL), pages 177-188. ACM Press, January 1992. [II] J. M. Lucassen. Types and \nEffects, towards the zntegra\u00adtton of functional and imperative programming. PhD thesis, MIT Laboratory \nfor Computer Science, 1987. MIT/LCS/TR-408. [12] J.M. Lucassen and D.K. Gifford. Polymorphic effect systems. \nIn Proceedings of the 1988 ACM Conference on Principles of Programming Languages, 1988. [13] R. Milner. \nA theory of type polymorphism in program\u00adming. J. Computer and system Sciences, 17:348-375, 1978. [14] \nHanne Riis Nielson and Flemming Nielson. Higher\u00adorder concurrent programs with finite communication topology. \nIn Conference Record of POPL 94: 21st A CM SIGPLAN-SIGA CT Symposium on Principles of Pro\u00adgramming Languages, \npages 84 97. ACM Press, Jan\u00aduary 1994. [15] Zhong Shao. Compiling Standard ML for E@cient Ex\u00adecution \non Modern Machines. PhD thesis, Princeton University, 1994. (Also available as Research Report CS-TR-475-94). \n[16] Jean-Pierre Talpin and Pierre Jouvelot. Polymorphic type, region and effect inference. Journal of \nFunctional Programming, 2(3), 1992. [17] Mads Tofte and Jean-Pierre Talpin. Implementing the call-by-value \nlambda-calculus using a stack of regions. In Proceedings of the fist ACM SIGPLAN-SIGA CT Symposium on \nPrinciples of Programming Languages, pages 188-201. ACM Press, January 1994. [18] Magnus Vejlstrup. Multiplicity \ninference. Master s the\u00ad sis, Dept. of Computer Science, Univ. of Copenhagen, September 1994, \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "Lars Birkedal", "author_profile_id": "81100622053", "affiliation": "School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA", "person_id": "PP17010344", "email_address": "", "orcid_id": ""}, {"name": "Mads Tofte", "author_profile_id": "81100142765", "affiliation": "Department of Computer Science (DIKU), University of Copenhagen, Universitetsparken 1, DK-2100 Copenhagen &#248;, Denmark", "person_id": "PP39029504", "email_address": "", "orcid_id": ""}, {"name": "Magnus Vejlstrup", "author_profile_id": "81392599877", "affiliation": "NKT Elektronik", "person_id": "P186040", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.237771", "year": "1996", "article_id": "237771", "conference": "POPL", "title": "From region inference to von Neumann machines via region representation inference", "url": "http://dl.acm.org/citation.cfm?id=237771"}