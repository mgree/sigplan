{"article_publication_date": "01-01-1996", "fulltext": "\n Functional Computation as Concurrent Computation Joachim Niehren* German Research Center for Artificial \nIntelligence (DFKI) Stuhlsatzenhausweg 3, 66123 Saarbrucken, C+ermany niehren@dfkl. uni-sb. de Abstract \nWe Investigate functional computation as a special form of concurrent computation. As formal basis, we \nuse a uniform\u00ad ly confluent core of the n-calculus, which is also contained in models of higher-order \nconcurrent constraint programming. We embed the call-by-need and the call-by-value J-calculus into the \nn-calculus. We prove that call-by-need complexi\u00ad ty is dominated by call-by-value complexity. In contrast \nto the recently proposed call-by-need A-calculus, our concur\u00ad rent call-by-need model incorporates mutual \nrecursion and can be extended to cyclic data structures by means of con\u00ad straints. Introduction We investigate \nconcurrency as umfying computational paradigm in the spirit of Milner [Mi192] and Smolka [Smo94, Smo95b]. \nWhereas the motivations for both approaches are quite distinct, the resulting formahsms are closely re\u00ad \nlated: The n-calculus [MPW92] models communication and synchronisation via channels, whereas the p-calculus \n[NS94, Smo94, NM9.5]1 uses logic variables or more generally con\u00ad straints as inspired by [Mah87, SRP91]. \nOur motivation in concurrent calculi lies m the design of programming languages Concurrency enables us \nto in\u00ad tegrate multiple programming paradigms such as function\u00ad al [Mi192, Smo94, Nie94, Iba95, PT95b], \nobject-oriented [Vas94, PT95a, HSW95, Wa195], and constraint program\u00ad ming [JH91, SS W94]. All these \nparadigms are supported by the programming language Oz [Smo95a, Smo95b]. In this paper, we model the \ntime complexity of eager and lazy functional computation in a concurrent calculus The importance of complexity \nis three-fold: 1. Every Implementation-oriented model has to reflect complexity. In the case of lazy \nfunctional program\u00adming, the consideration of complexity leads to a call\u00adby-need model in contrast to \na call-by-name model. *The research reported herein has been supported by the Bun\u00addesmlnlster fiir Bddung, \nW1ssenschaft. Forschung und Technolog%e (FTZ-ITW-9105), the Esprit Project ACCLAIM (PE 7195), and the \nEspr,t Working Group CCL (13P 6028) Permission to make digifalihard copies of all or part of thk material \nfor personal or claaamom use is granted without fee provided that the copies are not made or distributed \nfor pro~t or co~ercial advantage, the copy\u00adright notice, the title of the publication and Its date appear, \nand notice is given that copyright is by permission of the.ACM, Inc. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requites specific permission and/or fee. POPL 96, St. \nPetersburg FLA USA @ 1996 ACM ()..89791_769-3 /95\\Ol ..$3.50 2. A functional programmer has to reason \nabout the com\u00adplexity of his programs [San95], Denotational seman\u00adtics are too abstract in general. ., \n3Based on the notion of uniform confluence, complexity arguments provide for powerful proof techniques. \nOur main technical result M that call-by-need complexity is dominated by call-by-value and call-by-name \ncomplexity, i.e. for all closed A-expressions NJ: cneed(~~) < rnm{&#38;lue (~), Cname (Jl) } These two \nestimations can be interpreted as follows: Call\u00adby-need reduction shares the evaluation of functional \nargu\u00adments and evaluates only needed arguments, As a formal basis, we use a uniformly confluent applica\u00adtive \ncore of a concurrent calculus that we call &#38;-c,alculus, This is a proper subset of the polyadlc asynchronous \nm\u00adcalculus [Mi191, HT91, Bou92] and of the p-calculus [NM95, Smo94], the latter being a foundation of \nhigher-order con\u00adcurrent constraint programming. The choice of 60 has the following advantages: 1. Delay \nand triggering mechanisms as needed for pro\u00adgramming laziness are expressible within r10. 2. Mutually \nrecursive definitions are expressible m a call\u00adby-value and a call-by-need manner. 3. Cyclic data structures \nand the corresponding equali\u00adty relations are expressible in an extension of C!Owith constraints, the \np-calculus.  The &#38;calculus IS defined via expressions, structural con\u00adgruence, and reduction. Expressions \nare formed by abstrac\u00adtion, application, composition, and declaration: E,F ::= z:ij/E I z~ I EIF I (v.z)E \nIn the terminology of the n-calculus, abstractions are replicated input-agents and applications are output-agents. \nOnce-only input-agents as in the ~-calculus are not provid\u00aded, nor constraints or cells as in the p-calculus. \nWe identify expressions up to the structural congruence of the n-calculus. Reduction in C$OE defined \nby the following application axiom. (z:j/E) I z= + (.z:;/E) I E[5/j] 10riginally, Smolka s ~-calculus \n[Smo94] and the p-calculus [NS94] have been techrucally distm.t In [NM95], they have been combined ,n \na refined version of the p-calculus We note that Smolka s y-calculus and Boudol). ~ caladu. [B OU8SI] \nare completely unrelated, We do not allow for reduction below abstraction. In terms of the A-calculus, \nthis means that we consider standard re\u00adduction only We embed the call-by-value and the call-by-name \n~\u00adcalculus Into JO, the latter with call-by-need complexity. This 1s done in two steps: We first extend \n60 by adding mechamsms for single assignment, delay, and triggering. We obtain a new calculus that we \ncall J-calculus. Surprisingly d can be embedded mto JO Itself. The idea is to express single assignment \nby forwarders. In the second step, we encode the above mentioned J-calculi into 6 Formulatmg these embed\u00adding \nmto J rather than into 60 is motivated by our belief that the abstraction level of d is relevant for \nprogramming, theory, and implementation. The notion of single assignment we use in d is known from a \ndirected usage of logic variables [Pin87], as for instance in the data-flow language Id [ANP89, BNA91]. \nAlternative\u00adly, we could express single assignment wa equational con\u00adstraints, but these are not avadable \nm the n-calculus. In fact, the chrected single assignment mechanism in this pa\u00adper IS motivated by a \ndata-flow discussion for polymorphic typing a concurrent constraint language [Mu195] The approach of \nthis paper is based on the idea of uni\u00ad form confluence [Nie94, NS94]. This is a simple crlterlon that \nensures complexity is independent of the execution or\u00ad der. Unfortunately, we can not even expect confluence \nfor do. This is due to expressions such as z y/E I z: y /F that we consider mconslstent Inconsistencies \nmay arise dynam\u00ad ically. We can however exclude them statically by a lin\u00ad ear type system. In fact, the \nrestriction of JO to well-typed expressions is umformly confluent and sufficiently rich for embeddmg \n}-calcull. We note that a well-typed first-order restriction of JO has been proved confluent in [SRP91]. \nWe base all our adequacy proofs for embedding on a novel techmque that combines uniform confluence and \nshort\u00ad ening simulations [Nie94, NS94] Shortening simulations are more powerful than bmrnulatlons, once \nuniform confluence is available. Nevertheless, the defimtions of concrete short\u00ad ening simulations in \nthis paper are strongly inspired by Mil\u00ad ner s bisimulatlons in [M1192]. We are able to compare the complexity \nof call-by-need and call-by-value in 6, since up to our embedding, every call-by-need step 1s also a \ncall-by-value step. In particular, we do not require in 6 that a call-by-value function evalu\u00ad ates its \narguments before application. This additional free\u00ad dom compared to the call-by-value ,\\-calculus does \nnot affect complexity. This is a consequence of the uniform confluence of the well-typed restriction \nof J. Related Work. Many call-by-need models have been pro\u00ad posed over the last years but none of them \nhas been fully sat isfactory. Our call-by-need model is closely related to the call-by\u00ad need A-calculus \nof Ariola et al. [AFMOW95]. We show how to embed the call-by-need ,\\-calculus into d such that complexity \nis preserved (but not vice versa). The main dif\u00ad ference between both approaches 1s the level on which \nlazy control is defined. In the case of the call-by-need A-calculus, laziness is defined on meta level, \nby evaluation contexts. In the case of the &#38;calculus, laziness is expressible within the language \nitself. In other words, the call-by-need A-calculus is more abstract, or, the cf-calculus is more general \nThe disadvantage of the abstraction level of the call-by-need J\u00ad calculus is that mutual recursion and \ncyclic data structures are difficult to define. On the other hand side, 6 is abstract enough for hiding \nmost implementation details. We dlus\u00adtrated this fact by simple complexity reasoning based on shortening \nsimulations and uniform confluence. This tech\u00adnique is again more general than the specialised J-calculus \ntechnique in [AFMOW95]. The setting of the call-by-need A-calculus is quite slmdar to Yoshlda s A,t -calculus \n[Yos93]. She proves that a call-by\u00adneed reduction strategy is optimal for weak reduction, but she does \nnot compare call-by-need to call-by-name Embedding of the call-by-value and the call-by-name X calculus \ninto the r-calculus have been proposed and proved correct by Milner [Mi192]. A embeddmg of the call-by-need \nA-calculus mto the T-calculus lS proved correct m [B095]. The advantage of the here presented embedding \nis that they do need not make use of once-only input channels, which are incompatible with umform confluence \nEmbedding of the call-by-value and the call-by-name A\u00adcalculus mto the p-calculus are presented in [Smo94], \nthe latter with call-by-need complexity. These embeddmgs mo\u00adtivated those presented here. The difference \nhes in the us\u00adage of constraints for single assignment and triggering. In [Smo94] no proofs are given, \nbut the call-by-value embed\u00adding is proved correct in [Nie94]. There, most of the proof techniques presented \nin this paper have been introduced. An abstract big-step semantics for call-by-need has been presented \nby Launchbury [Lau93] It is complexity sensitive, since computation steps are reflected in proof trees. \nLaunch\u00ad bury s correctness result however does not cover complexity. This is a consequence of using a \nproof techmque based on denotatlonal semantics Many other attempts for call-by-need have been present\u00ad \ned To our knowledge, all of them are qmte Implementation oriented such that they suffer from low-level \ndetails We note the approaches based on explicit substitutions [PS92, ACCL91] and on graph reduction \n[Jef94] Structure of the Paper. As a first example we discuss the square function in a concurrent setting \nWe define CYOin Sec\u00adtion 3. We then introduce the notion of uniform confluence and discuss its relationship \nto complexity and confluence In Section 5, we prove uniform confluence for a subset of 130 In Section \n6, we define the d-calculus. Following, we discuss umform confluence for 6 In Sections 8 and 9. we embed \nthe call-by-value, the call-by-name, and the call-by\u00adneed A-calculus into 6 We introduce a hnear type \nsystem in Section 10 and prove that our embeddmgs fall mto the uni\u00adformly confluent subset of 6. In SectIon \n11, we show how to encode single assignment and triggering in C!O. We introduce the simulation Droof \ntechruaue m Section 12 and aDDlv It for .. . proving the adequacy our calculus embedding m Sections 13 \nand 14. 2 The Square Function: An Example We informally introduce the ~-calculus by representing the \nsquare function m call-by-value and call-by-need manner. This motivates our embedding of A-calcuh into \nJ and indi\u00ad cates the adequacy results we can expect We assume a infinite set of variables ranged over \nby z, y, z, s, and t, Sequences of variables are written as Z, j, and integers are denoted with n, m, \nand k In a concurrent setting, we consider functions as relatlons y=2*3) Figure 1: Square Function: Call-by-Value \n(Vy)(vt)(s ytz I t.y=2*3) S (2*3) + 4.* (2*3)*(2*3) (W)(~=Y*U I Y=2*3) 3 #h 6*(2*3) (2*3)*6 \\/ I 6*6 \n+ 36 z=36 2 Figure 2: Square Function: Call-by-Name versus Call-by-Need with an explicit output argument, \nfor example: rightmost computation in Figure 1, where the square func\u00adtion is applied before its argument \nhas been evaluated. s = Ax.x*x versus s:xz/z=x*z For defining a call-by-need square function in a concur\u00adrent \nsetting, we need a delay and a triggering mechanism. The expression on the right-hand side is a call-by-value \ndef-For this purpose, we introduce two new expressions t.E and inition of the square function in the \nJ-calculus. The formal tr(t). We say that E is delayed in t. E until t is triggered. parameter z is the \nexplicit output argument. The expression This behaviour can be provided by following triggering ax- Z=Z*Z \nis syntactic sugar for an application of a predefine iom: ternary relation *. We assume the following \napplication ax- t.E I tr(t) + E \\ tr(t) iom for all integers n, m, k and variables z: Note that multiple \ntriggering is possible. A call-by-need x=n*m + x=k ifk=n*m version of the square function can be defined \nas follows, For forwarding values in equations z=n, we copy them into s :ztz/(z=z*z I tr(t)) those positions \nwhere they are needed This kind of adminis\u00adtration is definable in many different manners, for instance: \nThis function can be applied with a delayed argument z waiting on tto be triggered. Figure 2 presents \ncall-by-name (Vy) (y=n / E) + E[7z/y] and call-by-need computations of the square of 2*3. Both call-by-name \ncomputations have length 4, since the func- Figure 1 illustrates the call-by value evaluation of the \nsquare tional argument 2*3 is evaluated twice. If we ignore trigger\u00adof 2*3 in the A-calculus and the \ncLcalculus. If we ignore for\u00ad ing and forwarding steps, then our call-by-need computation warding steps, \nthen all possible computations in Figure 1 has length 3, This illustrates that call-by-need complexity \nhave length 3. In other words, our call-by-value embedding is dominated by call-by-name and by call-by-value \ncomplex\u00adof the square function preserves time complexity measured ity. In this example, the first estimation \nis proper (raised in terms of application steps. Ignoring forwarding is correct in the sense that the \nnumber of forwarding steps in com-2Here, + stands a forwarding followed by an application step: putations \nof functional expressions is linearly bounded by (Uy) (2=y*y I y=6) -) .z=6*6 + ,=36 the number of application \nsteps. We do no prove this claim 3Here, + consists of an application and a triggering step. formally. \n(ut)(s gtz I t v=2*3) + (ut)(z=uw/tr(t) I t v=2*3) It is interesting that call-by-value evaluation in \n$ is more + Z=Y*Y I y=2.3 I (vt)(tr(t)) flexible than in the ~-calculus, as shown by an additional The \ngarbage expression (ut)is omitted in Figure 2 (tr(t))call-by-value computation in our example. This is \nin the Variables X,y, z,s, t := Expressions E,F := z~/E I zj I EIF I (wr)E Reduction z: G/E 1 Z~ +A Z \ng/E 1 E[z/@ Figure 3 The 60-Calculus. Structural Congruence EIFEFIE El I (Ez I E3) = (El I E2) ] E3 (u,r)(uv)E \nE (vy)(Lw)E (ZJZ)E I F s (uz)(E I F) if.. @ V(F) E=F ,fE=,.y F Contextual Rules Figure 4. Structural \nCongruence and Contextual Rules by sharing), whereas the second is not (since the argument variant under \nstructural congruence and closed under weak of the square function 1s needed). contexts This means that \nreduction is apphcable below dec- We note that our call-by-need computation in Figure 2 laration and \ncomposition, but not mslde of abstraction In has a direct relatlve in the call-by-value case, the rightmost \nterms of A-calcuh, this means that consider standard reduc\u00adcomputation m Figure 1 This statement holds \nm general tions only and enables us to compare call-by-need and call-by-value complexity in the d-calculus \nExample 3.1 (Continuation Passing Style) The iden\u00adtify function 1 = ,\\z. z can be defined m 60 in continuation \npassing style: z zy/yx. An application let z= I in ii re\u00ad 3 The Applicative Core of the n-Calcu!us ferred \nto by z is definable as follows: We define c10 as the applicative core of the polyadic asyn\u00ad(@(i: zy/?Jx \nI (Uy )(l,y I y c/zc))chronous n-calculus [Mi191, HT91, Bou92] and the p\u00adcalculus [NM95, Smo94]. Interestmgly, \n60 as formulated here In composition with i:zy/yz we obtain the following com\u00adis part of the Oz computation \nmodel [Smo94] and the Pitt putation computation model [PT95b], which have been developed in\u00addependently \n(Vy )( My I y c/zc) +~ (Uy )( &#38; i I y , c/zc) We define the calculus JO wa expressions, structural \ncon\u00adgruence, and reduction. The definition is given in Figures 3 +~ 22 I (uy )(?J :c/z.c) and 4. Expressions \nare abstractions, applications, composi\u00adtions, or declarations An abstr-actaon .r. ~/E is named by x, \nExample 3.2 Explicit Recursion The computation of the following recursive expression does not terminate:has \nformal arguments j and body E. An appltcatton XQ of r has actual arguments ij. In the standard ~-notation, \nab\u00ad~$# I X:y/Zy +A %$1 I X.y/Xy +A ,,, stramhons are replicated input-agents and applications asyn\u00adchronous \noutput-agents. Bound varmbles are introduced as formal arguments of Compared to the asynchronous ~-calculus \n[Mi191, BOU92) abstractions and by declaration, The set of free variables HT91], i$o does not provide \nfor non-replicated input-agents, of an expression E is denoted by V(E) We write E =. F These are not \nneeded for functional computation and are in\u00adif E and F are equal up to consistent renammg of bound compatible \nwith uruform confluence lf not restricted hnearly variable. As usual for J-calculi, we assume all expressions \nto [KPT96]. In absence of once-only inputs, it is not clear if be a-standardised and omit freeness conditions \nthroughout the unary restriction of Jo is Turing complete. the paper. The structural congruence ~ of \nC$Ocoincides with that 4 Uniform Confluence of the n-calculus. It is the least congruence on expres\u00adsions \nsatlsfymg the axioms m FlgUre 4 With respect to the We formalise the notions of a calculus, complexity, \nand uni\u00adstructural congruence, bound variables can be renamed con-form confluence as m [Nie94, NS94] \nand discuss their rela\u00ad sistently, composition 1s associative and commutative, and tionships. These simple \nconcepts wdl prove extremely useful declaration E equipped with the usual scoping rules m the sequel \nThe reductton -+ synonymously denoted by -+~ is defined The notion of a calculus that we will define \nextends by a single axiom for appltcatzon, The application axiom Klop s abstract rewrite systems [K1087] \nby the concept of uses the simultaneous substitution operator [z/~], which re-a congruence A calculus \nIS a triple (~, ~, +), where S is a p~aces the components of J elementwise by Z. We implicitly set, = \nan equivalence relation, and + a binary relation on assume in case of application of [z/~] that the sequence \nv is &#38;. Elements of &#38; are called ezpresszons, s congruence, and linear and of the same length \nas 5. Note that reduction M in-+ reductzon of the calculus. We require that reduction 1s Figure 5: Uniform \ntnvartant under congruence, i.e., (~ o + o ~) ~ +. Typi\u00adcal calculi are: 60, T, p, J-calculi, abstract \nrewrite systems, Turing machines, etc. A derivation in a calculus is a finite or infinite sequence of \nexpressions such that E, + E,+l holds for all subsequent elements, A derzvatton of an expression E is \na derivation, whose first element is congruent to E. A cornputatton of E is a maxzmal derivation of E, \ni.e. an infinite derwation or a finite one, whose last element ]s n-reducible. The least transitive relation \ncontaining + and -is denoted with +* The length of a finite derivation (E, )~=o is n and the length of \ninfinite derivation is cm. We call an expression E untform with respect to complexity (and termination), \nif all its computations have the same length We define the complexity C(E) of a uniform expression E \nby the length of its computations We call a calculus wuform if all its expressions are uniform. We call \na calculus unzformly confluent, if its reduction and congruence satisfy the following condition wsualised \nin Figure 5 (+0+) g ((+0 +--)U E) Typically, J-calculi equipped with standard reductions are uniformly \nconfluent, subject to weak contexts, Proposition 4.1 A unzformly confluent calculus M conflu\u00ad ent and \numform wtth respect to complexity. Proof. By a standard inductive argument [Nie94] as for the notion \nof strong confluence [Hue80] (which is weaker than uniform confluence), !3 5 Uniform Confluence for c10 \nIn this Section, we distinguish a uniformly confluent subcal\u00adcuius of JO that is sufficient for functional \ncomputation. We call a do-expression znconsutent, if it is of the form: x:v/E [ z jj/F where E $ F. A \ntypical example for non-confluence m the case of inconsistencies is to reduce the expression z z in composition \nwith z: y/s y I z:y/t y: 82 A+ X2+A t~ These results are irreducible but not congruent under the assumption \ns # t. We call E admtsstble, if there exists no expression F con\u00adtaining an inconsistency and satisfying \nE +* F. The advan\u00adtage of this condition is that it is very simple. Unfortunately, it is undecidable \nif a given expression E is admissible, since admissibility depends on the result of a Turing complete \nsystem This failure 1s harmless, since we can prove admis\u00ad sibility for all functional expression of \nd with the help of the linear type system in Section 10. Confluence Theorem 5.1 The restrzct?on of Jo \nto admtsstble expres\u00adsions M untformly confluent. Together with Proposition 4,1 this implies that all \nadmis\u00adsible expressions E of 60 are uniform with respect to com\u00adplexity such that C(E) is well-defined \nProof of Theorem 5.1. Let E be an admissible Jo\u00adexpression. Every application step on E can be performed \non an arbitrary prenex normal form of E (compare [Nie94] for details). Since declarations are not involved \nduring appli\u00adcation, we can assume that E is a prenex normal form with an empty declaration prefix, On \nsuch E, reduction amounts to rewriting on multisets of abstractions and apphcatlons, Let F1 and Fz be \nexpressions such that F1 ~+ E +A Fz, There exists an application ZI z reduced during the apphcatlon step \nE +A F1 and an application X2 ~ reduced during E +A FZ. If these applications are distinct, then we can \njoin F1 and Fz by reducing the respective other one. If both applications coincide then x 1 = 22 Hence, \nthe applied abstractions have to be congruent by admissiblhty such that F1= F2, 0 6 Single Assignment \nand Triggering We extend 60 with directed single assignment and trigger\u00ading. The resulting calculus is \ncalled 6. We do not exclude multiple assignment syntactically This is a matter of the linear type system \nin Section 10. For our extension, we need three new types of expressions and two additional reduction \naxioms. A dwected equataonl ~=y is used for Single assignment directed from the right to the left. A \nsynchronzser ~ E delays the computation of E until tis triggered. A trzgger ezpresszon tr(t) triggers \na delayed computation waking on t. The structural congruence of J coincides with that of Jo. Its reduction \n+ is a union of three relatlons, application +~, forwarding +F, and trtggerarw +T: + = -+~u+,uu-+~ Each \nof these relatlons is define by the corresponding axiom in Figure 6 and the contextual rules in Figure \n4. Example 6.1 (Single Assignment Style) The identity function I = k r can be expressed in d by z ry/y=x \nConl\u00adpared to Example 3,1 we use single assignment instead of continuation passing. An application let \n/.=1 in (i?) z re\u00adferred to by z M represented in J as follows: (vL)(2:zy/lJ=.r I (Uy )(,,y / IJ ,.z)) \nlThe original version of the J-calculus [N1e!14] uses symmet kIC equations instead of dmected ones This \nchoice does not mattel for well-typed expressions Expressions E)F ::= z:j/E I zv I 1? F I (vz)E [ z=y \nI tr(t) I t.E Figure 6 The In composition with i zy/y=z we obtain the following com\u00adputation (Uy )( iiy \nI y iz) +~ (Vy )( # mi I y zz) + r (uy )(y .%!/y=z I y i~ ) +~ .w=i / (vy )(y . zy/y=z) --+p z:xy/y=x \nI (urJ )( .) Example 6.2 (Call-by-Need Selector Function) The call-by-need selector function F = ky. \no can be represent\u00aded in d by the abstraction f:ztzytvz/(z=z I tr(tz)). The symbols t. and tv stand for \nordinary variables Their usage is for triggering the computations of z and y respectively. A call-by-need \napplication ~ (it) (Z t) has the form: (vz)(~tz)(uY)(~tg) (fztz Ytyz I tm.itz \\ tv.izy) In composition \nwith the abstractions named i and ~, we obtain the following computation: (~z)(~~z)(~Y)(%)( JW%Y$KZ I \nL z~x I ty.tty) +~ (vz)(vtz)(z=z I tr(fz) ] te.it% ) I (uy)(~tv)(tu.tzy) +T (xr)(vtz)( wwv I tr(tz) I \n{{x ) I (uy)(utv)( ..) -+ z:xy/y=x I (Vy)(utv)( uz)(utz)( ) The resulting expression is irreducible. \nWe note that only the needed first argument has been evaluated The synchro\u00ad mser tv. zz y for the second \nargument suspends forever. 7 Uniform Confluence for d For proving a uniform confluence result for J, \nwe have to consider how umform confluence behaves with respect to a union of calculi. We first present \na variation of the Hindley- Rosen Lemma [Bar84] for uniform confluence and then apply it to the J-calculus \nBut the general results of this Section are also apphcable to other unions of calcuh such as the call\u00ad \nby-need J-calculus [AFMOW95] and the p-calculus [NM95]. The unwm of two calculi (&#38;, =, +1) and (&#38;, \n~, +2) is defined by (S, ~, +1 U +2). We say that the relatlons +1 and +2 commute, if (1+ o -+) ~ (+1 \no ~+). Lemma 7.1 (Hindley-Rosen) The unzon of two unz\u00adformly confluent calculz wath commut~ng reductions \nu unz\u00adfo.mly confluent. The proof is straightforward Note that Lemma 7.1 im\u00adplies the classical Hindley-Rosen \nLemma, since a relation is confluent, if and only If Its reflexive transitive closure is umformly confluent. \nThe next lemma allows us to ignore ad\u00administrative steps such as forwarding and triggering in the case \nof 6: 6-Calculus Lemma 7.2 (Administrative Steps) Let (Z, ~, +1) be a uniformly confluent calculus and \n(&#38;, =, -+2) a confluent and term$natmg calculus such that +-1 and -+2 commute If E M an ezpresszon \nm &#38;, then every computation of E m the unaon (&#38;, =, +1 U +2) contatns the same number of +1 steps. \nProof. The idea is to apply Proposition 41 to ( 5, =, +; 0+, 0+;). This calculus is uniform but not uniformly \nconfluent. This deficiency can be remedied by replacing ~ with (~+ U +2)* The details can be found m \n[Nie94]. 0 Next, we apply the above results to the d-calculus. We first note that the notion of admissibility \ncarries over from JO to 6 without change Proposition 7.3 The relattons +F and +T terminate. The relatton \n+* as untformly confluent and +-F M un%form\u00adly confluent when restricted to admassable ezpresstons. The \nrelatlons +A, +-p, and +T commute patrwise Proof. Termination is trivial, since +F decreases the num\u00adber \nof directed equations and +T the number of synchronis\u00aders. All other properties can be established by \nthe normal form technique used in the proof of Theorem 5.1. 0 Theorem 7.4 The restrtctton of the d-calculus \nto admtsst\u00adble expressions M uniformly confluent Proof. Follows from Theorem 51, Proposition 73, and \nLemma 7.1. 0 Theorem 7.5 If E is admzssable, then all computations of E contatn the same number of appltcataon \nsteps. Proof. Follows from Theorem 5.1, Proposition 7.3, and Lemma 7.2 0 Definition 7.6 We define the \nA-complexn%y CA (E) of an adm~sszble ct-expression E as the number of +A steps tn computations of E. \nTheorem 7.5 ensures that A-complexity is well defined, We consider forwarding and triggering steps as \nadministrative steps and Ignore them m favour of simpler complexity state\u00adments and adequacy proofs However, \nwe could prove for all functional expressions (but not in general) that the number of administrative \nsteps is linearly bound by the number of +~ steps. This would requu-e showing stronger mvariants in adequacy \nproofs. Expressions Af, N := r I V I AIN V ::= Ax.M Reduction (k.M)V +Val M[V/z] (Ax.M)N -i,,a,,,, M[N/z] \nContextual Rules M MN +Val +Val M M N N MN --+Val N -+val MN M MN -+_. +,,.,,,. M M N Figure 7: The \nCall-by-Value and the Call-by-Name J-Calculus Figure 8. Call-by-Value and 8 Functional Computation in \n6 We embed the call-by-value and the call-by-name J-calculus into the A-calculus, the latter with call-by-need \ncomplexity. The call-by-value and the call-by-name A-calculus are re\u00advisited in Figure 8. Note that we \nconsider standard reduc\u00adtion only. A congruence allowing for consistent renaming of bound variables is \nleft implicit as usual. Proposition 8.1 The call-by-value and the call-by-name A\u00adcalculus are unaformly \nconfluent. The statement for call-by-name is trivial, since call-by-name reduction is determmistic. The \nproof for call-by-value can be done by a simple induction on the structure of J-expressIons. Proposition \n8.1 allows us to define the call-by-value complez\u00adtty Cal (Af) and the call-by-name complexzt y C~~n,, \n(M) of a J-expression M by the length of its computations in the respective A-calculus. Given an arbitrary \nvariable z, Figure 8 presents an em\u00ad bedding Al ~ z=. M of the call-by-value J-calculus into 6. The \ndefinition of z=. M is given up to structural congruence. All variables introduced during this definition \nare supposed to be fresh. Theorem 8.2 For all closed A-expressions M and vartables z the call-by-value \ncomplexity of M and the A-complexity of z= M comczde: Cal(M) = CA(z=~M) A complete proof based on the \ntechniques of Section 12 is presented in [Nie94]. It makes heavy use of uniform conflu\u00adence for covering \nthe additional freedom provided by call\u00adby-value reduction in J. An embedding z + z=. M of the call-by-name \nA-calculus into 6 is given in Figure 8. It is symmetric to our call\u00adby-value embedding and provides for \ncall-by-need complex\u00adit y. Our definition of a J-expression z =~ M makes sense for closed M only and \ngoes through intermediate J-expressions containing pairs yotv. For instance: Z=. AX. X Y z:xt=y/y=nxot. \n~ Z:xtZy/(y=z I tr(tz)) As we will show in the next Section, our embedding of the call-by-name A-calculus \nprovides m fact for call-by-need complexity In thcs sense, the next theorem states that call\u00adby-need \ncomplexity is dominated by call-by-value and by call-by-name complexity Call-by-Need in the J-Calculus \nTheorem 8.3 Let M be a closed A-ezpress~on and z a var~\u00adable. C all-by-name reductton of M terminates \ntf and only tf d-reduction of z=~M terminates. Furthermore. CA(Z=~M) < mm{ C.~l(Af), C,,a,ne(M)} The \nmost difficult statements of Theorem 8.3 are proved in Sections 12, 13, and 14. These are the adequacy \nwith respect to termination and the estimation CA (z=~ M) < C,.a,,,e (A4). The estimation C(z=mM) < C.al(M) \ncan also be established by the simulation technique of Section 12. It is sufficient to relate the expressions \nz=U M and z=. M. For applying the simulation technique, we need the admissibility of these expressions \nas proved in Section 10, It is straightforward to express mutual recursion in 6, both m a call-by-value \nand in a call-by-need manner: z=.letrec z=M in N E (uz)(z=,, ~ I z= UN) z=nletrec ii=~in N -(uz)(z@(i.z=~Af \nO I z=~NO) where 6 = [Eoi/ii]. We do not claim a correctness result for mutual recursion m this paper. \n9 Embedding the Call-by-Need J-Calculus We show that the A-complexity of z=. M equals to the com\u00ad plexity \nof Lf in the call-by-need A-calculus. The defimtlon of the call-by-need ~-calculus [AF-MOW95] is revisited \nin Figure 9. Again, we only consider standard reduction, The reduction +,,eed of the call-by-need J-calculus \nis a union of four relations: +,,ee~ = +1 U +r, U +An. U +C The latter three relations are of administrative \ncharacter, whereas +1 steps correspond to /3-reduction steps Proposition 9.1 The call-by-need A-calculus \nas detern~ln\u00ad zsttc and hence unaformly conjlaent. The proof is simple. Applying Proposition 9.1, it \nmakes sense to define the call-by-need complexity C,,e,d (L) of an expression the call-by-need J-calculus \nby the number of +1 steps in the computation of L. We extend the mapping M + G=. M to an embedding L \n-z=~ L of the call-by-need A-calculus into J, defining z=mlet .r=L2 in L,l S (vx)(z=. LJ I Z=. L1) Expressions \nL:=?J~v LIL2 I let x=L2 in LI V ::= ,XX.L Answers A ::= V ] let Evaluation Contexts E = Reduction (. \nAz.LI)Lz +1 let Z=LZ in L1 let z=V in E[z] -+V let z=l in E[V] let y=(let z=L in A) in E[Y] +An~ let \nz=L in (let y=A in E[Y]) (let .z=L, in A)Lz +C let r=Ll in ALz L+L E[L] + E[L ] Figure 9: The Call-by-Need \nJ-Calculus The following Theorem states the adequacy of the extended Lemma 10.1 If E M well-typed and \nE + F, then F M embeddmg, and that our embedding of the call-by-name J-well-typed. An z-nconszstent expression \nM not well-typed. calculus into J yields in fact call-by-need complexity: The first property is often \ncalled subject reduction property Theorem 9.2 If L M a closed ,\\-expression and z a vartable It can be \nchecked by induction on derivations of Judgments then C,,e,d(L) = CA(Z=,, L) The second property is straightforward. \nLemma 101 imme\u00addiately Implies the following corollary This can be shown by a complexity simulation (Section \n12). Corollary 10.2 Well-typed ezpressaons are adm~sstble 10 Linear Types for Consistency Proposition \n10.3 All ezpress~ons z=UM and z=n L are well-typedWe define a linear type system for 6 that statically \nexcludes inconsistencies It tests for single assignment and determines Proof. We can check by induction \non the structure of M the data flow of a J-expression via input and output modes. that the following \njudgments are derivable with the rules We assume an infinite set of type vartables denoted by a in Figure \n10, where q is arbitrary. and use the following recursive types a internally annotated with modes ~: \nin ~out z: pcv, (a ), {z} D z=u~ u ::= (7) I @!.T I o! I tr, T:,= o? in z: pa (c? tr CUout), {z} D z=. \nL q :.= in I out 11 Encoding J in 60 Our type systems distinguishes two classes of variables, trig\u00adger \nand single assignment variables. We use tr as type for Directed single assignment and triggering can \nbe expressed trigger variables. A single assignment variable has a proce\u00adin CIO. For technical simplicity, \nwe formalise this statement dural type (7), where 7 is a sequence of argument types, For for n-ar-y d-expressions, \nI.e. those containing n-ary abstrac\u00ad in ~out instance, the variable z m z=U ibf is typed by pa. (a tions \nand applications only. This is sufficient to carry over ) This recursive type expresses that a call-by-value \nfunction our A-calculus embeddings from 6 to JO, since z=. M and is a binary relatlon, which inputs a \ncall-by-value function in z=~L are binary and ternary respectively. An embedding first position and outputs \na call-by-value function in second of n-ary d-expressions into C$Ois given in Figure 11 and position. \ndO(E) = E for all expressions E of JO A type erunronment 17 is a sequence of type assumptions Theorem \n11.1 For all well-typed n-ary h-ezpresstons E,x: a with scoping to the right. A variable z has type a \nZn 60(E) M admtsstble and termmates tf and only af E termi\u00ad17, wr,tten r(z) = o, if there exists f 1 \nand I Z such that nates. r = 171, Z. T, rz and z does not occur in 17z The domain of an environment r \nis the set of all variables typed by r The proof is omitted, but can be done with the simulation We identify \nenvironments rl and rz If they have the same technique of Section 12. Adequacy with respect to termina\u00addomam \nand 171(z) = T2 (x) for all z m this domain. The tion follows from the fact that the embeddmg preserves \nthe output variables O(ij: 67) m a sequence of annotated types length of computations up to a factor \nof 2 (which is needed are defined as follows, where ~ = (Y.)S=I, 6 = (a,)~=l, and for triggering). This \ndoes however not impl~-the adequacy V = (W);=l with respect to complexity measured in terms of application \nsteps This is the only point where Ignoring +F and +T O(V: 67) = {y, I q,=out and a,#tr} steps weakens \nour results. A ywdyement for E is a triple r; O b E, where 17 1s an en\u00adwronment and O M a set of variables. \nAn expression E is 12 Complexity Simulations and Uniformity well-typed, if there exists a judgement for \nE derivable with the rules in Figure 10. If r; O D E is derivable, then O Milner [Mi192] uses bmrnulatlons \nfor proving the adequacy contains those single assignment variables, to which an ab-of J-calculus embeddmgs \ninto the ~-calculus We show that straction may be assigned cfurmg a computation of E. simulations are \nsufficient for uniform calculi I ; ODE r; 01 b El rjo2b E2 Ol~oz=O r; o\\{x} b (vz)E r;oluoz DEIIE2 r,t:trj \nr,t:tr; O O F E b t.E r,X: r,q:~;o (Fi); {z} bE D X:~/E 0< o(~: E;) r,t, tr; @ b tr(t) r,.r: (7), u: \n(~); {z} b Z=y r,z: (6 F), J: 5; O b r~, O(ij: Bfi) ~ O Figure 10. Linear Type Checking &#38;(t E) ~ \n(Uy)(ty [ y:/do(E)) f30(tr(t)) Figure 11 Embeddmg Let (&#38;, -s, +s) and (G, -g, +g) be two uniform \ncalculi with expressions ranged over by E and G respectively, We omit the indices S and ~ whenever they \nare clear from the context. We call a function @ : &#38; + ~ an embeddzng of &#38; tnto ~, if @ is invariant \nunder congruence. Definition 12,1 A shortening simulation for an embeddtng @ : E + L7 M a relataon S \non E x ~ satisfying the ~ollowang conddtons for all E, E , and G: (Shol) (E, O(E)) E S. (Sho2) If E M \nwreductble and (E, G) c S, then. G as zrre\u00adduczble. (Sho3) If E --+ E and (E, G) c S, then eztsts E and \nG wtth C(E ) > C(E ), (E , G ) c S, and G + G , We call a shortening stmudatzon complexity simulation \nif It satzsfies (Sho3) wzth C(E ) = C(E ) znstead of C(E ) ~ C(E ). Theorem 12.2 Let @ : E --+ ~ be an \nembeddmg between unaform calcuk. If there exzsts a shortening samulatton fqr @, then @ preserves termination \nand tmproves complemty, i.e. C(@(E)) < C(E) for all E. If there exzsts a complexity szmulatzon for @, \nthen @ preserves complemty C(@(E)) = C(E) for all E. Proof. We assume a shortening simulation S for @ \nand (E, G) c S. First, we claim C(G) < C(E) if C(E) # m by induction on C(E). Second, we claim C(G) < \nC@) if C(E) = co. This can be shown by proving C(G) ~ n inductively for all n > 0. The theorem follows \nfrom these claims and condition ( Shol). 0 13 A Shortening Simulation for Call-by-Need We sketch the \nadequacy proof for our embedding of the call\u00adby-name J-calculus into 6 as stated in Theorem 8.3. We prove \nthat the embedding M + z=nM preserves termi\u00adnation such that CA (z=~ JIf) < C,,a,,,e (M) for all closed \nA\u00adexpressions M. For reflecting A-complexity, we consider the alternative reduction -0 +A o c-+ where \nc-+= (+F U +T) *. Restrict\u00aded to admissible expressions, this reduction yields a uniform calculus by \nTheorem 7.5. By Proposition 10,3, Corollary 102, and Proposition 8.1, it is sufficient to apply Theorem \n= t:y/y 60(z=Y) ~ X:;/YZ , length(~) = ~ n-ary J-expressions in 60 12.2 once we have constructed a shortening \nsimulation for the embedding M + z=n M. As syntactical convenience. we write let lj=~ in N for the ~-expression \nN[M~ /.y~] [Ml /YI] where U = (h ):=1 and ~ = (Af, )~=l Before formally defining a shortening simulation \n(see Section 14) we illustrate it by a simple ex\u00adample We first consider a call-by-name reduction step \nof (II) I with I = Ax.x: (II) I let yl=f .zI=I ~~m~fz~ z2=I y3=yzZZ in y3  --+,1.1 ,e let ?Jl=~ ZI=l \n~~=$~ ~2=1 Y3=Y2Z2 in y3 let yl=I z1=I yz=I ZZ=I y3=yzzz in y3 In the corresponding cLreduction steps, \nwe omit top-level declarations and write E x F if E ~ (VZ) F. y3=n(II) I % yl=n~ I tl. zl=nl \\ yl@l W! \nI t2. z2=n I I y2z2t2y3 +A ul=n~Iti.~1%] \\$O=n~lQtlItz. zz=n I I y2Zt2y3 +2-yl=~~ I a=~~ I yz=s~ I tr(tl) \nI fz.zz=,,I I y~zzfzys +F yl=ml I zl=nl I y2=n1 I tr(tl) I tz.zz=.I I yzzztzy3 The correspondence in \nthis example is very close when ig\u00adnoring +F and +T steps2. A more interesting example comes with sharing, \nwhen reducing z=~(kz. (z~y..r)) (11). In this case, we can formulate the relationship via strong /l-reduction: \nWe write Lf +l,.,,,. M if M reduces to M by application of the /3-axiom at any position in M, Lemma 13.1 \n(The Invariant) There ezzsts a relatwn S between closed A-ezpresstons and admasszble d-ezpress~ons satlsjyzng \n(Shol) and (Sho2) and the followang property: If (M, E) c S and M +l,.,,,, A4 , then there eztsts M and \nE , such that Af +~a,,,. Af , E c--+ o --+A o + E , and (M , E ) E S. The proof is sketched in Section \n14. Lemma 131 implies the existence of a shortening simulation for the embedding M + z=nM. To verify \ncondition (Sho3) we make use of Lemma 13.2: Lemma 13.2 If M +~a,,,e AI , then C,,a,,,e(M ) > c ,Ia,l,e(iw \n). Proof. This is a reformulation of Plotkin s standardisation theorem [P1075]. The number of -p and \n-T step. En comput~tions of L13=,, M is bounded by 3 times the number of +A steps This CaII be proved \nwith a simulation for an amortised cost analysls 14 Proof of Lemma 13.1 Our Idea for defining a shorting \nsimulation is to make sub\u00adstitutions exphcit as m [Mi192, ACCL91] and to reflect lazy control by a notion \nof needed variables. Exphcit subst~utions are already introduced in the def\u00admltlon of let ~=M i n N. \nFor defining needed variables, we write ~< for the sequence (PJ )~~~, if ,ii = (pj )~~1 is a se\u00adquence \nof variables or expressions. Definition 14.1 (Needed Variables) A vamable x> needed in let V=M in N, \nzf the ~udgement ti(z, let ~=.bf in N) M derzvable by the followzng rules: AI (z, N,) N(z, N) _ N(z, \nIV] ATZ) N(z, let jj=~ in N) N(x, let V< =M<2 in M,) N(y,, N) N(z, let ij=~ in N) For instance in let \nyI=l gz=yl yl ys=yl YZ in Y3 , the vari\u00ad ables ys and yl are needed whereas yz is not needed. Definition \n14.2 (Representation) A representation for (M, E) ZS a fi~e-tuple (n, ~, j, i, D), where ~ = (A4.)~=1, \nj = (y,)~=l, t = (t,)~=l, and D ~ {yl,. .y~} called the delay set, such that the followtng properties \nhold for all i c {1,, (s1) (s2) (s3) There erxsts (E, )~=l, Q, and ~ such that + M a compo\u00adsafaon of \ntrvgger expressions {tr(j) I yj @ D}, E% E1l.../En 141,  0 as the substztutton [jjoi/~], and. (s4) If \ny, $? D and M, M an applicat~on then Aft M an u Ppl~cat%On of vamables, (s5) If y, is needed an let G=M \nin yn, then y, @ D. (S6) If y, M not needed m let ~=~ in y~, then y, ~ D or A{, as an abstraction. (s7 \n) The composed sequence iji M lznear Definition 14.3 (Simulation S) The relakon S M the set of all patrs \n(M, E) for which a representation ezasts. Lemma 14.4 (Correctness of S) The relahon S satLsfies the condtttons \nof Lemma 13.1 15 Conclusion We have presented a simple execution model for eager and lazy functional \ncomputation. We have applied concurren\u00adcy for integration of programming paradigms. We have presented \nthe concurrent ~-calculus, which features useful abstractions for programmmg, implementation, and theory. \nWe have worked out a powerful proof technique based on uniform confluence and complexity simulations, \nAcknowledgements. I am deeply in debt to Gert Smolka, who initiated this work and contributed ideas during \nmany discussions. It s my pleasure to thank to Martin Muller for daily comments on concepts and related \nwork, and for extremely helpful discussions on notations and details I would like to thank Kal Ibach, \nMartin Miiller, Peter Van Roy, Christian Schulte, and Gert Smolka, for their comments on the final version \nand the complete Oz team for continuous support and interest. References [ACCL91] Martin Abadi, Luca \nCardelli, P.-L. Cur,en, and Jean-Jaques L4vy. Explicit substitutions. Jour\u00adnal of Functional Programming, \n1 (4) 375 416, 1991. (AFMOW951 Zena M. Arlola, Matthias Fellelsen, John Maraist, Martin Odersky, and \nPhilip Wadler. A call-by-need lambda calculus In POPL, pages 233-246 1995. [ANP89] Arvind, R.S. Nikhil, \nand K.K. Pmgali. I\u00adstructures Data-structures for parallel comput\u00ading ACM Transactions on Programmmg \nLan\u00adguages and Systems, 4(11):598-632, 1989 [Bar84] Henk P. Barendregt. The Lambda Calculus. Its Syntaz \nand Semantzcs, volume 103 of Studzes tn Log$c and the Foundations of Mathematics El\u00adsevier, 1984. [BNA91] \nPaul S. Barth, Rlshiyur S Nikhil, and Arvmd M-structures: Extending a parallel, non-strict, functional \nlanguage with state. In Functional Programming Languages and Computer Archi\u00adtecture, number 523 m LNCS, \npages 538 568, 1991 [B095] Simon Brook and Gerald Ostheimer Process semantics of graph reduction In Stxth \nIrLt er\u00adnataonal Conference on Concurrency Theory, pages 238-252, August 1995 [Bou89] G&#38;ard Boudol \nTowards a J-calculus for con\u00adcurrent and communicating systems In Theory and Pract~ce an Software Development, \nnumber 351 in LNCS, pages 149-161 1989. [Bou92] G&#38;-ard Boudol Asynchrony and the mcalculus (note). \nRapport de Recherche 1702, INRIA, Sophla Antipolis, France, 1992 [HSW95] Martin Henz, Gert Smolka, and \nJorg Wurtz. Object-oriented concurrent constraint program\u00ading m Oz In V Saraswat and P. Van Henten\u00adryck, \neditors, Prtnctples and Practtce of Con\u00ad stra~nt Programming, chapter 2, pages 27 48 The MIT Press, 1995. \n [HT91] Kohei Honda and Mario Tokoro. An object cal\u00adculus for asynchronous commumcation. In Pro\u00adceeding \nof the European Conference on Ob~ect-Ortented Programming, number 512 in LNCS, pages 133 147, 1991. [Hue80] \n[Iba95] [Jef94] [JH91] [K1087] [KPT96] [Lau93] [Mah87] [Mi191] ~Mi192] [MPW92] [Mu195] [Nie94] [NM95] \nG&#38;-ard Huet. Confluent reductions: Abstract properties and applications to term rewriting systems. \nJournal of the ACM, 27(4):797-821, 1980. Kai Ibach. OzFun: Eine funktlonale Spache fur gemischte Eager-und \nLazy-Programmierung, Universltat des Saarlandes, Fachbereich Infor\u00admatik October 1995. Alan Jeffrey. \nA fully abstract semantics for con\u00adcurrent graph reduction. In Proceedings of the Logm m Computer Sctence \nConference, pages 8~-91, 1994, Sverker Janson and Seif Harldi. Programming paradigms of the Andorra Kernel \nLanguage. In Proceedings of the International Sympostum on Logzc Programmmg, pages 167-186, 1991. Jan \nWillem Klop. Term rewriting systems: A tutorial. Bullet~n of the European Assocaatzon of Theoretical \nComputer Saence., 32:143-182, 1987. Naoki Kobayashi, Benjamin Pierce, and David N. Turner. Linearity \nand the pi-calculus. In POPL. January 1996. John Launchbury. A natural semantics for lazy evaluation. \nIn POPL, pages 144 154, 1993. Michael J. Maher. Logic semantics for a class of committed-choice programs. \nIn Logzc Program\u00adming, Proceedings of the Fourth Inter-natzonal Conference, pages 858-876. 1987. Robin \nMilner. The polyadic x-calculus A tu\u00ad torial. ECS-LFCS Report Series 91 180, Lab\u00ad oratory for Foundations \nof Computer Science, University of Edinburgh, 1991. Robin Milner. Functions as processes. Journal of \nMathematical Structures m Computer Sczence, 2(2):119-141, 1992. Robin Milner, Joachim Parrow, and David \nWalker. A calculus of mobile processes. Jour\u00ad nal of Information and Computation, 100:1 77, 1992. Martin \nMuller. Polymorphic types for con\u00adcurrent constraints. DFKI Saarbrucken, Ger\u00admany, http:llps-www .dfki. \nuni-sb. dei, 1996, submitted. Joachim Niehren. Fun.kt~onale Berechnung m einem unzform nebenlaufigen \nKalknIl md logts\u00adchen Varvablen. Doctoral Dissertation. Umver\u00adsitat des Saarlandes, Technische Fakultat, \nSaar\u00adbriicken, Germany, December 1994. Joachim Niehren and Martin Mriller. Con\u00ad straints for Free in \nConcurrent Computation. In Astan Computmg Sczence Conference, LNCS, December 1995. [NS94] [Pin87] [P1075] \n[PS92] [PT95a] [PT95b] [San95] [Smo94] [Smo9.5a] [Smo95b] [SRP91] [SSW94] [Vas94] [Wa195] [YOS93] Joachim \nNiehren and Gert Smolka. A conflu\u00adent relational calculus for higher-order program\u00adming with constraints. \nIn I tInternational Ccm\u00adference on Constraints an Computational Logtcs, volume 845 of LNCS, pages 89 \n104, 1994. Keshav K. Pingali. Lazy Evaluation and the Logic Variable. Technical report, Cornell Uni\u00adversity, \nProceedings of the Institute on Declar\u00adative Programming 1987. Gordon D Plotkm. Call-by-name, call-by-value \nand the A-calculus Journal of Theoretical Com\u00adputer Sczence, 1:125-159, 1975. S Purushothaman and Jill \nSeaman An ade\u00adquate operational semantics of sharing in lazy evaluation. In European Symposaum on Pro\u00adgramming, \nvolume 582 of LNCS. 1992. Berqamin C. Pierce and David N. Turner. Con\u00adcurrent objects in a process calculus \nIn Theory and Practtce of Parallel Programm~ng, number 907 in LNCS, pages 187-215. April 1995. BenJamm \nC. Pierce and Dawd N. Turner Pitt: A programming language based on the pi\u00adcalculus Techmcal report in \npreparation; avad\u00adable electronically, 1996 D. Sands. A Naive Tmre Analysis and lts Theory of Cost Equivalence. \nThe Journal of Logzc and Computat~on, page 48 pages, 1995+. Gert Smolka. A foundation for concurrent \ncon\u00adstraint programming. In Constraints ?m Com\u00adputational Logzcs, volume 845 of LNCS, pages 50-72.1994. \nGert Smolka. An Oz primer. Oz documentation series, DFK1 Saarbriicken, Germany, 1995. Gert Smolka. The \nOz programming model In Jan van Leerrwen, editor, Current Trends cn Computer Sctence, LNCS, vol. 1000. \n1995 Vijay A. Saraswat, Martin Rinard, and Prakash Panangaden. Semantic foundations of concur\u00adrent constraint \nprogramming. In POPL, pages 333-352. 1991. Christian Schulte, Gert Smolka, and Jorg Wurtz Encapsulated \nsearch and constraint pro\u00ad gramming in Oz. In Second Workshop on Przn\u00ad czples and Pract~ce of Constraint \nPragramnung, volume 874 of LNCS, pages 134 150. 1994. Vasco T Vasconcelos. Typed concurrent ob- Jects. \nIn 8th Proceedings of the European Confer\u00ad ence on Ob~ect Or-tented Programm~ng, volume 821 of LNCS, \npages 100-117 1994. David Walker. Objects m the ~-calculus. Jour\u00ad nal on Information and Computation, \n116:254 273, 1995. Nobuko Yoshida Optimal reduction m weak J\u00adcalculrrs with shared environments In Confer\u00adence \non Functional Programming Languages and Computer Architecture, 1993. \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "Joachim Niehren", "author_profile_id": "81100448425", "affiliation": "German Research Center for Artificial Intelligence (DFKI), Stuhlsatzenhausweg 3, 66123 Saarbr&#252;cken, Germany", "person_id": "PP31042693", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.237801", "year": "1996", "article_id": "237801", "conference": "POPL", "title": "Functional computation as concurrent computation", "url": "http://dl.acm.org/citation.cfm?id=237801"}