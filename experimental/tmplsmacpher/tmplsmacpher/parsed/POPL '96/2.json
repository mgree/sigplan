{"article_publication_date": "01-01-1996", "fulltext": "\n Points-to Analysis in Almost Linear Time Bjarne Steensgaard Microsoft Research One Microsoft Way Redmond, \nWA 98052, USA rusardresearc h.microsoft. com Abstract We present m interprocedural flow-lnsensltlve points-to \nrmalysls based on type ]nference methods with an almost hneart ime cost complexity To our knowled~e, \nthis is the asymptotically fastest non-trlwzd lnterprocedural points-to analysis algorlthm yet described \nThe al,gotnthm IS bmedona non-standard type system. The type Inferred for any wmable l-epl-esents a set \nof locations and includes a type which in turn represents a set ot locations possibly pointed to by the \nvariable. Thetype inferred for a function variable l-epre\u00adsents a set of functions It may point to and \nIncludes a type signature for these functions Theresults ztre equivalent tothoseof a flow\u00adinsensitive \nalias analysis (and control flow analysls) that assumes alias relations arereflexlve andtransltive. This \nwork makes three contributions The first isatype system for describing a umversally valid storage shape \ngraph for a program in linear space. The second is a constraint system which often leads to bettel-l-esults \nthan the obvious constraint system for the gyven type system The third is an almost llneal-time algolnthm \nfor points-to analysls by solwng a constraint system Introduction Modern optimizing compilers and program \nunderstanding and brows\u00ad ing tools for pointer languages such as C [KR88] are dependent on semantic reformation \nobtained by either an alias analysis or a po]nts-toanalysls. Ahasanalyses cornput epairso fexpressions(or \naccess paths) that may be abased (e.g., [LR92, LRZ93]). Points\u00adto analyses compute a store model using \nabstract locations (e.g, [CWZ90, EGH94, WL95, Ruf95]) Most current compilel-s and programming tools use \nonly in\u00adtraprocedural analyses, asthepolynomlal tlmeand space complex-Ity of the common data-flow based \nanalyses pi-events the use of interprocedural analyses for large programs. Intel-procedural analy - \nslslsbecoming increasingly important, asitlsnecessary to support whole-program optimization and various \nprogram understanding tools. Previously published Interprocedural analysis algorithms have not been \nreported to have been successfully applied to pro\u00adgrams around 100,000 lines of C code (the published \nresults are practically all forless than 10,0001 inesof Ccode). Permission to make digital/hard copies \nof all or part of this mriterial for personal or claasroom use ia granted witbout fee provided that the \ncopies arenotmade or distributed forprofit orcommercial advrmtage, the copy\u00adright notice, the title of \nthe publication and its date appear, and notice is given that copyright is byperrnission of the ACM, \nInc. Tocopy other-wise, torepubtish, to post on servers orto redistribute to lists, requires specifrc \npermission and/or fee. POPL 96, St. Petersburg FLA USA @ 1996 ACM 0-89791-769-3/95/01. .$3.50 We present \na flow-insensitive interprocedural points-to analysis algol-ithm that has a desirable linear space and \nalmost linear time complexity and is also very fast in practice. The algorithm is easily apphcable to \nprograms with many hundreds of thousands of Ilnes of code. The analysis results are often not as accurate \nas those obtained by flow-sensitive analyses However, the results are roughly com\u00adparable to those of, \ne g , the cubic time complexity flow insensitive analysls of [Wei80] The algorithm, which is inspired \nby Henglein s blndlng time analysis by type infel-ence [Hen9 1]. uses anon-standard type system to describe \nthe store usage at runtime by using types to construct a storage shape graph [CWZ90]. While we describe \nthe principles behind the algorithm in terms of types and typing rules, we also provide a detailed description \nof the algorlthm which can be used almost directly to implement the olgorithm in a compiler In Section \n2 we state the source language for which we describe the algorithm The language captures the essential \nparts of a lan\u00adguage like C. In Section 3 we define the non-standard set of types we use to model the \nstorage use, and in Section 4 we state a set of typing rules for programs The typing rules impose constraints \non the relationships of types of program variables. Finding a typing of the program that obeys these \nconstraints amounts to performing a points-to analysis In Section 5 we show how to efficiently infer \nthe minimal typing that obeys the constraints In Section 6 we report on practical experience with the \nalgorithm in a C programming en\u00advil-onment. In Section 7 we describe related work, and m SectIon 8 we \npresent our conclusions and point out dmections for future wol-k 2 The source Iang,uage We describe \nthe points-to analysis for a small Imperative pointer language which captures the impel-tant properties \nof languages like C [KR88] The language Includes pointers to locations, pointers to functions, dynamic \nallocahon, and computing addresses of vari\u00adables Since the analysis is flow insensitive, the control \nstruckues of the language are irrelevant The abstract syntax of the relevant statements of the language \nis shown in Figure 1. The syntax for computing the addresses of variables and for pointer indirection \nis borrowed from the C progl-amming language [KR88]. All variables are assumed to have umque names. The \nop( ) expression form IS used to describe prlmltlve computations such as al-itbmetic operations and computing \noffsets into aggregate objects The allocate(y) expression dynamically allocates a block of memory of \nsize y Funchons are constant values described by thefun( )+( ),S expression form). The f, variables are \nformal parametel-s (some\u00ad We have gemxal]zed fmctdetimt]ons to allow tunctlons wltl] mult$ple IoI) ,etu,n \nvldum, a teatal-e not found In C s ,:= X=y I x=&#38;y I x=*y ] X=op(y,... y,,) I x = allocate(y) I *x=y \n\\ x =fun(fl,. .f,,)+(r[ r,n) $ I X,... x,n=p(yyl)yl) Figul-e 1 Abstract syntax of the t-elevan[ statements, \nS, of the source Ianyt.lge X, y. f, r, and p range over the (unbounded) set of variable names and constwrts, \nop ranges over the set of primitive operator names S* denotes o sequence of statements. The control structures \nof the language are irrelevant for the purposes of this paper. fact = fun(x)-+(r) if Iessthan(x 1) then \nr=l else xminusone = subtract(x 1) nextfac = fact(xminusone) r = multiply(x nextfac) fi result = fact(l \nO) Figure 2: A program In the source language that computes facto\u00adi-ial(l O), tlrnes called in parameters). \nand the r, variables are return pa\u00adrameters (sometimes called ouf parurneters). Function calls have call-by-value \nsemantics [ASU86]. Both formal and return parame\u00adter variables may appear in left-hand-side position \nin statements m the function body. Formal and return parameter variables as well as local valiables may \nnot occur in the body of another function; this is always true for C programs, which are not allowed \nto contain nested function definitions Figure 2 shows an implementation of the factorial function (and \na call of s,~me) in the abstract syntax of the source language. We assume that programs areas well-behaved \nas (mostly) portable C programs. The analysls tracks flow of pointer values, so the anal\u00adysis algorithm \nmay produce wrong results for programs that con\u00adstruct pointers from scratch (e.g., by bitwlse duplication \nof pointers) and for non-portable programs (e.g., programs that rely on how a specific compiler allocates \nvariables relative to each other). How\u00adever, the analysis algorithm as presented below will deal with, \ne.g., excluslve-or operations on pointer values, where there is a real flow of values Types For the \npurposes of performing the points-to analysis, we define a non-standal-d set of types describing the \nstore. The types have nothing to do with the types normally used in typed imperative languages (c~,g., \ninteger, float, pointer, struct). We use types to model how storage is used in a program at runtime (a \nstorage model), Locations of variables and locations created bydynamic allocation arealldescribed by \ntypes. Each type describes a set of locations as well as the possible runtime contents of those locations. \nA type cun be viewed m a node In a storage shape graph [CWZ90]. Each node may have edges to other nodes, \nwhich is modelled in the type system by letting types have type components. The storage shape graph may \nbe cyclic for some programs, so the types may also be recursive. The set of types inferred for the variables \nof a program represents a storage shape graph which is valid at all program points. The storage shape \ngraph conservatively models all the points-to relations that mayholdatruntlrne Alias relations canalso \nbe extracted from the storage shape graph [EGH94]. Our goal is a points-to analysis with an almost linear \ntime cost complexity. The size of the storage shape graph represented by types must therefore be linear \nin the size of the input program Consequently, the maximum number of graph nodes must be linear in the \nsize of the input program. Additionally, each graph node may not have more than a fixed number of out-going \nedges, meaning that each type may only have a fixed number of component types, We describe the locations \npointed to by a pointer variable by a single type. For composite objects (such as s true t objects in \nC). we also describe all the elements of the object by a single type. Describing each element in a composite \nobject by separate types would, for most imperative languages, imply that the size of the storage shape \ngraph could potentially be exponential in the size of the input program (e g , by extreme use of t ypedef \nands true t in C). Describing the elements of composite objects by separate types may slill be desirable, \nas the sum of sizes of variables is unlikely to be exponential in the size of the input program. Extending \nthe type system to do so is not addressed in the present paper, The source language allows pointers to \nfunctions Function pointer values are described by signature types describing the types of the argument \nand result values. Values may be (or include) pointers to locations and pointers to functions. The type \nof a value must therefore accommodate both types of pointers. In our type system, a value type is therefore \na pair including a location type and a function signature type. The non-standard set of types used by \nour points-to analysis can be described by the following productions: o! ::= rxA r ::= L I ref(~) A := \n1 /lam(ctl . ..~n)(CE., +i . ..an+m)  The a types describe values, the T types describe locations (or \npointers to locations), and the.\\ types describe functions (or pointers to functions), Types may be recursive, \nand it may therefore be impossible to write out the types directly. The types can be written out by using \ntype variables. Two types are not equal unless they either both are 1 or are described by the same type \nvariable. Note that this is different from the usual structural equality criterion on types. We could \nuse the structural equality criterion if we added a tag to the -r and A types 4 Typing rules In this \nsection we define a set of typing rules based on the set of non-standard types defined in the previous \nsection. The typing rules specify when a program is well-typed. A weI1-t yped program is one for which \nthe static storage shape graph indicated by the types is a safe (conservative) description of all possible \ndynamic (runtime) storage configurations. Before stating the typing rules, we argue for using inequalities \nrather than equalities in the typing rules and argue for the way we have defined the typing rule for \nstatements with primitive operations. Each location in the program IS descr]bed by a single type, A pointer \nto a location is described by the type of the Iocatlon pointed to. If several locations may contain a \npointer to the same location, then the types of these locations must all have the same location type \ncomponent. This requirement must be reflected in the typing rules. Consider a simple assignment statement, \nx = y Assume that x has type i-z (meaning that the location allocated to hold the value of x has type \n~z) and that y has type ~Y If a locatlon pointer value may be assigned to x when executing the statement, \nthen the locatlon component of both -rX and Tv must be TP, where TP is the type describing the pointer \nvalue being assigned to x If a function pointer value may be assigned, then T. and TV must have the same \nt unction s]gnature component, The obvious typing rule for simple assignment statements would be A \nEx ref(a) A ky : ref(a) A bvelltypeci(x = y) This rule states that this part of the program is well-typed \nunder type enwronment .4 if the contents of variables x and y are described by the same type(s), Previous \nwork has used this typing rule for simple assignment [Ste95a], The above typing rule is, however, too \nstrict This IS illustrated by the following sequence of stsrtements a=d X=a y=a Using the above rule, \nthe content components of the types for a, X, and y must all be the same. That is not strictly necessary, \nas no pointer value is ever assigned. If x and y are used in other parts of the program to hold pointers \nto disjoint locations, the above statements would unnecessarily force all the pointed-to locations to \nbe described by the same type. Furthermore, if x is used in another part of the program to hold a pointer \nvalue, the analysis results will Indicate that both y and a may hold the same pointer value, even if \nthey are only assigned Integer values In the program Given an assignment statement x = y, the content \ncomponent types for x and y need only be the same if y may contain a pointer In order to state this requwement \nin a typing rule, we Introduce a partial order on types defined as follows t]gt2.a (t, =l)v(t, =t2) (t, \nx tz)g (t, xt,) @ (t, g t,)A (t, g t,) Given that non-pointers are represented by type J_, the requirement \ncan now by expressed by the following typing rule: A kwell~ped(x = y) The rule states that each component \ntype of CM must be either 1 or equal to the corresponding component type of al, In statements of the \nform x = Op(yl yn ), the Op operation may be a comparison, a bit-wise operation, an addition, etc. Con\u00adsider \na subtraction of two pointer values. The result is not a pointer value, but either of the two operand \npointer values can be recon\u00adstituted from the result (given the other pointer value). The result must \ntherefore be described by the same type as the two input pointer values TheI-e are operations from which \nargument pointer values cannot be reconstituted t rom the result (e g , comparisons: <, #, etc ), For \nsuch operations, the result is not required to be described by the same type as any input pointer values \nFor the purposes of this paper, we wdl treat all prlmitlve operations identically, In Figure 3 we state \nthe typing rules for the relevant parts of the source language. A program is well-typed under typing \nenviron\u00adment A if all the statements of the program are well-typed under A The typing environment A associates \nall variables with a type, The typing rule for dynamic allocation Implies that a location type is required \nto describe the value stored in the variable assigned to. The type used to describe the allocated location \nneed not be the type of any variable m the program. The type of the allocated location is then only Indirectly \navailable through the type of the vari\u00adable assigned to, All locations allocated in the same statement \nwill have the same type, but locations allocated by different allocation statements may have different \ntypes. Figure 4 contains an example program and a typing of all the variables occurring in the program \nthat obeys the typing rules of Fig\u00adure 3 Variables x and z must be described by the same type variable, \nas a single type variable must represent the locations pointed to by all the pointers possible stored \nin the locatlon for variable y, 5 Efficient type inference The task of performing a points-to analysis \nhas now been reduced to the task of inferring a typing enwronment under which a program is well-typed, \nMore precisely, the typing environment we seek is the minimal solution to the well-typedness problem, \n~,e,, each location type variable in the typing environment describes as few locations as possible, In \nthis section we state how to compute such a minimal solution with an almost linear time complexity The \nbasic principle of the algorithm is that we start with the assumption that all variables are described \nby different types (type variables) and then proceed to merge types as necessary to ensure well-typedness \nof different parts of the pl-ogram. Merging two types means replacing the two type variables with a single \ntype variable throughout the typing environment. Joining is made fast by using fast unionlfind data structures. \nWe first describe the initialization and our assumptions about how the program M represented. Then we \ndescribe how to deal with equalities and inequalities in the typing rules in a manner ensuring that we \nonly have to process each statement m the program exactly once, Finally we argue that the algorithm has \nhnear space complexity and almost linear time complexity. 5.1 Algorithm stages In the first stage of \nthe algorithm, we provide a typing environment where all variables are described by different type variables \nA type variable consists of a fast union/find structure (an equivalence class representative (ECR)) with \nassociated type information, The type of each of the type variables in the typing environment is initially \nref(l x 1), We assume that the program is represented in some program representation where name resolution \nhas occurred, so we can encode the typing environment in the program representation and get constant \ntime access to the type variable associated with a variable name In the next stage of the algorlthm, \nwe process each statement exactly once Type variables arejolned as necessary to ensure well\u00adtypedness \nof each statement (as described below). When joining two type variables, the associated type information \nis unified by computmg the least upper bound of the two types, joining compo\u00adnent type variables as necessary. \nJoimng two types will never make a statement that was well-typed no longer be well-typed When all program \nstatements are well-typed, the program 1s well-typed. .4 kx ref(al) A t-x: ref(ref(_) x _) A }y : ref(a2) \nA t-welltyped(x = allocate(y)) a2a al .4 kwellt);ed(x = y) A +x : ref(ref(a, ) x _) A Ey : ref(az) A \n+x :ref(7 x _) Cq g C/] .4ky:T A FwelltyI~ecl(*x = y] A kwelllyped(X = &#38;y) A bx : ref(_ x Iam(al \nG)(CG,+I CUt+,n)) A }x ref(a, ) A l-f, : ref(a, ) A Ry ref(ref(crz) x _) A t-r, ref(an+, ) o!~ g al V \ns 6 S : A t-welhyped(s) .4 Fwel[typed(X = *y) A +welltyped(X = fun(fl . . . fn)+(ri. . r,n) $) A +x : \nref(a) A t-x7 ref(a~+j ) A Ky, : ref(a, ) A t-p ref(_ x Iam(al CI~)(CV~+I a,t+,~)) v,e[l rd~ts~ A t-y, \n: ref(ao .4 }we[ltyped(x = Op(yI Y,t)) vLe[l. ../z]:cY:gaL Vj G[1 .m] :%+3 g a :+, A l-welltyped(Xl. \nX~ = P(Y1. y,,)) Figul-e 3. Type rules for the relevant statement types of the source language. All variables \nare assumed to have been associated with a type In ~he type ~~vlronment .4, (Distinct variables a~e assumed \nto have di~tin~t names, so the type environment can describe all variables in all scopes ~~multaneously. \n) _ is a wild-card value in the rules. imposing no restrictions on th~ ~ype component it rePresents a=&#38;x \n a: -r] = ref(~~ x l-) b=&#38;y b: T2 = ref(~5 x -1) if p then c: 73= ref(~j x 1) y = &#38;z; x: TJ= \nref(l x 1) else y: 75 = ref(7-~ x J-) y=&#38;x fi c=&#38;y Figure 4 Example program, a typing of same \nthat obeys the typing rules, and graphical representation of the corresponding storage shape graph Note \nthat variables x and z are described by the same type Even though types -i-l and -T-Sare structurally \nequivalent (as are -JZand -rs, and r~ and ~fi ), they are not considered the same types. It type variables \nare only joined when necessary to ensure well\u00adtypedness, the final solution will be the minimal solution \nwe are seeking. 5.2 Processing constraints If lhe typing rules for a statement impose the constraint \nthat two types are identical, then the corresponding type variables must be joined to obey the constraint. \nAn inequality constraint(Q) between two types is slightly more difficult as it may not always be possible \nto determine, at the time of processing a statement, whether the two types should be joined. If the left \nhand side type variable is associated with a type other than 1, then the two type variables must be joined \nto meet the constraint. Assume that the left hand side type variable is associated with the type _L at \nthe time a statement is processed. At this point, there is no need 10Join the two type variables, The \ntyping rule for another statement may subsequently force a change of the type associated with the type \nvariable implying that the type variable should be joined with the type variable on the right hand side \nof the current constraint. To deal with this, we associate each type variable with type 1 with a set \nof other type variables to join with, should the type ever become anything other than 1. If an inequality \nrelahon must hold between two type variables, then we perform a conditional join of the two. If the left \nhand side type variable has type 1, then we add the right hand side type variable to the set associated \nwith the left hand side type variable. If the left hand side type variable has a type other than 1, then \na real join of the two type variables is performed Whenever the type associated with a type variable \nchanges from 1, either because of a typing rule or because of unification, the type variable must be \njoined with the type variables in the associated set. The precise rules for processing each statement \nof the program are given in Figure 5. The details of the join and unification opera\u00adtions are given in \nFigure 6. 5.3 Complexity We argue that the algorithm has a linear space and almost linear time complexity \nin the size of the input program, The space cost of the algorithm is determined by the total number of \nECRS created and the number of join operations performed. The initial number of ECRS is proportional \nto the number of variables in the program. The number of ECRS created during the processing of a single \nstatement is either bounded by a small constant or, m the case of a procedure call, at worst proportional \nto the number X=y x= fun(fl fn)+(r, r,n) S let ref(-r] x ,\\ I ) = type(ecr(x)) let ref(_ x A) = type(ecr[x)) \n ref(~j x Jz) = type(ecr[y)) in If type(~) = 1 then if TI # r? then CjOin(~l, TZ) settype(~, lam(al an)(G+I \nctn+,m)) if}] # AZ then cjoin(~l, Az) where ref(a, ) = type(ecr(ft)), for i S ~ x=&#38;y ref(a, ) = type(ecr(r, \nn)), for z > n let ref(Tl x _) = type(ecr(x)) else -r! = ecr(y) in let Iam(al an)(CEn+I an+~) = type(~) \nin If n # TS then join(~(, T?) fori 6[1 n]do x= *y let~l x Al =a, let ref(71 x AI) = type(ecr(x)) ref(~z \nx Az) = type(ecr(f,)) in ref(~z x _) = type(ecr(y)) in if TI # T2 then join(m, TI) if type(~z) = L then \nif Al # .\\z then join(~z, AI) settype(rj, ref(~l x AI)) forz~[l. ..m]do else let -rI x AI = an+, let \nref(~s x J3) = type(~z) in ref(Tz x Az) = type(ecr(rz)) in if 71 # T3 then cjoin(~l, T3) if ~1 # T2 then \njoin(~l, T2) If ,\\j # .\\a then cjoin(~l, ,]3) if AI # A2 then join(~l, AZ) x = Op(yl yn). xl .X,n = \np(yl. y,.): fori~[l. ..n]do let ref(_ x A) = type(ecr(p)) In let ref(-r x AI) = type(ecr(x)) if type(J) \n= 1 then ref(T~ x Az) = type(ecr(y, )) in settype(A, lam(al %)(G+l ~n+n)) if rI # r? then CjOin(~l, \n~?) w hel-e if J! # AZ then cjoin(Al, J?) CL!L= TLX~L [T,) \\,] = MakeECR(2) let lam(al CVn)(CVn+I \nan+,n) = type(~) in x = allocate(y) let ref(T x _) = type(ecr(x)) In if @pe(T) = ~ then forz~[l. ..n]do \nletTIxAI= a, let [cl, ez] = MakeECR(2) In ref(~z x &#38;) = type(ecr(y, )) m settype(~, ref(el x ej) \n) if TI # T2 then cjoin(Tl, Tl) *x=y if .\\ I # AZ then cjoin(~l, h)let ref(T, x _) = type(ecr(x)) fori \nC[1 m] do ref(~z x Az) = type(ecr(y)) letTI x A] = an+, lf type(~l) = 1 then ref(Tz x Az) = type(ecr(x, \n)) in settype(r[, ref(Tz x h)) if TI # T2 then cjoin(~z, TI ) else If AI # ,X2then cjoin(~j, JI) let \nref(-r~ x A3) = type(~l) in If r? # ~3 then cjoin(Ts, ~z) If ~2 # )3 then cjoin(~~i Jz)  Figure 5. Inference \nrules corresponding to the typing rules given in Figure 3 ecr(x) is the ECR representing the type of \nvariable X, and type(E) 1s the type associated with the ECR E cjoin(z, y) performs the conditional join \nof ECRS x and y, and settype(E, X) associates ECR E with type .Y and forces the conditional joins with \nE. MakeECR(a) constructs a list of z new ECRS, each associated with the bottom type, 1 settype(e, t): \njoin(el, ez): type(e) +-t let tl= type(el) for z G pending(e) do join(e, z) tz= type(ez) e = ecr-union(ej, \ne!) In iftl = lthenc,join(el, e~). type(e) +-tz if type(ez) = _L then iftz = 1 then else pending + \n{e! } U penrling(e~) pending(e) +-pending(el) U pending else for z c pending(el ) do join(e, z) ,join(eljel) \nunify (ref(~l x AI), r-ef(7z x h)): elseif Tl # T? then join(r[, T2) type(e) +-tl if ,\\l # ~! then join(.\\l, \n.12) it t2= 1 then for r c pending do join(e, z) unify (lam(al G,, )(c4, +I CY,L+7n, ) elseIam(a{ a~,)(a{,+) \na~z+,,z)) unify(tl, t?) fori E/1. ..(n+n)]do let~l x Al =Qt I-:xA?= a; In if 71 # 72 then .jOin(7i, \nr~) It ,\\l # ,\\: then join(~i, ,\\?)  Figure 6 Rules for unification ot two types represented by ECRS, \nWe assume that ecr-union performs a [fast unionhnd) join operation on its ECR wgurnents and returns the \nvalue of a subsequent find operation on one of them of variables occurlng in the statement. The number \nof ECRS is consequently proportlorml to the size of the input program. The number ofjoln operations is \nbounded by the total number of ECRS. The spoce cost of a Join operation amounts to the (constant) cost \nof the ecr-union operation. The cost of unifying/joining component type ECRS can be attributed to those \njoins, The cost of performing a condltionzd join or a join of two type variables with type L is constant \nif we use a binary tree structure to represent the pending sets The time cost of the algorithm is determined \nby the cost of traversing the statements of the program, the cost of creating ECRS and types, the cost \nof performing join operations, and the cost of (fast union/find) find operations on ECRS, The cost of \ntraversal and creation of ECRS and types is clearly proportional to the size of the input program, The \ncost of performing join operations IS a constant plus the cost of ECR find operations. The average cost \nof ,V ECR find operations are O(NCY(N, N)), where a is a (very slowly Increasing) reverse Ackermann s \nfunction [Tar83], The time cost complexity of the algorithm is consequently O(NQ(N, N) ), where N is \nthe size of the Input program (almost linear in the size of the input program) Experience We have implemented \na slightly improved version of the above al\u00adgorithm in our prototype programming system based on the \nValue Dependence Graph [WCES94] and implemented in the program\u00adming language Scheme [CR9 1]. Tbe implementation \nuses a weaker typing rule than presented above for primitive operations return\u00ading boolem values and \nuses predetermined transfer functions for dil-ect calls of librsrry functions (the algorithm is thus \ncontext\u00ad sensltlve/polymorhpic for calls to library functions) The analysis algorithm is routinely applied \nto the C p rograms processed by the system, Two implementations of an earlier type inference based points\u00ad \n 10 armlysis algorithm [Ste95a] have been performed at University of Callforma, San Diego: one in C [Mor95] \nand one in Scheme [Gri95]. Both implementations have been augmented to model slots of structured objects \nindependently Our earlier algorithm was based on the same non-standard type system as used in the present \nalgorithm but used stricter typing rules, implying that the results are more conservative than they need \nbe. Our implementation demonstrates that running time of the al\u00adgol-ithm is roughly linear in the size \nof the input program on our test-suite of around 50 programs. Using our own implementation, we have performed \npoints-to analysis of programs up to 75,000 lines of codes (an internal Microsoft tool). The running \ntime for the algorithm on the 75,000 line C program is approximately 27 sec\u00adonds (15 seconds process \ntime) on an SGI Indigo2 workstation, or roughly 4 times the cost of traversing all nodes in the program \nrep\u00adresentation. For a 25,000 line C program (LambdaMOO available from Xerox PARC) the running time is \napproximately 8 seconds (5.5 seconds process time). The analysis is performed as a separate stage after \nthe program representation has been built. Morgenthaler s implementation of our previous algorithm per\u00adforms \nthe processing of statements during parsing of the program, He found the parse time to increase by approximately \n50% by adding points-to analysis to the parser. Counting only the extra time for performing the analysis, \nemacs (127,000 non-empty lines of code) could be analyzed in approximately 50 seconds, and FE1t (273,000 \nnon-empty lines of code) could be analyzed m approximately 82 sec\u00adonds on a SparcStation 10 [Mor95]. \nThe present algorithm can also easily be implemented to process the statements during parsing. The running \ntimes of the previous and the present algorithm are roughly the same (only minor fluctuations). Table \n1, Table 2, and Table 3 illustrate the distribution of pro\u00adgram variables per type variable for a number \nof benchmark pro\u00adgrams. The programs are from BI1l Landi s and Todd Austin s benchmark suites for their \nanalyses [LRZ93, ABS94] as well as the SPEC 92 benchmark suite. LambdaMOO is a large C program available \nfrom Xerox PARC (we used version 1.7. 1). Table 1 gives the raw distribution for the total analysis solution \nwhen performed on an (almost) unoptimized version of the program representation. Most of the type variables \ndescribe the locatlon At the ttnw of wnong, this is the kugest pqyam Ieplesented USIII: the VDG profy \nom Ieplesentzttion of variables whose addresses are never taken. The type variables descnb]ng zero program \nvariables represent non-l types describing user functions and locations allocated by the runtlme system \n(e.g . the Iocatlons for the argv and argc arguments to main). Table 2 gives the dlstrlbutlon for those \ntype variables that occur as location components of other types In the solutlon of the analysls performed \non an (almost) unoptimized version of the progyam rep\u00adI-esentatlon These type variables represent program \nvariables that are pointed to by other variables They do not necessai-lly repre\u00adsent ill the program \nvarmbles that are pointed to in the program, as minor optimization are performed on the VDG program repre\u00adsentation \nas It is being built; some of these optimization elimlnate storing values in variables if this is trivial \nto avoid, as described in [WCES94] The number of type variables describing more than one program location \nis reduced relative to Table 1 The reduction is mostly c~used by eliminating type variables for values \npassed to functions but never pointed to by a pointer. The values would not have been grouped In the \nfirst place, if a polymorphic analysis had been used. Table 3 gives the distribution for the locatlon \ncomponent type variables in the solution of the analysis performed on an optimized version of the program \nrepl-esentatlon The ophmizations performed on the program representation include a local transformation \nelimi\u00adnating all local variables whose address is never taken These type variables describe the program \nvariables that are the hardest to get good analysis results for. The program variables are all pointed \nto by other program variables which cannot be eliminated by local transl ormatlons. Many of the program \nvariables described by a type variable representing no other program variables are candidates for global \noptimization such as being represented by a register rather than a memory location The distributions \nshown in the tables demonstrate that there are a considerable number of type variables describing only \na single program variable, even for those type variables describing pointed to program variables. Most \nother type variables describe a small number of program variables, There are a couple of major excep\u00adtions: \ntype variables describing sevel-al hundred program locations However, for most of the programs, the locations \ndescribed by these exceptional type variables are all global constant strings For example, for the LambdaMOO \nprogram, the program locations de\u00adscribed by the largest single type variable are all strings passed \nas argument to user defined logging and tracing procedures. Any context-insensitive analysis is bound \nto show a similar number of possible pointer values for the formal parameters of these logging and tracing \nprocedures. Our subjective evaluation of the quality of the analysis results is that they are pretty \ngood, given that the contents of all the slots of structured variables are represented by a single value \ntype How\u00adever, many programs use data structures such as trees and lists as central data structures. \nFor these programs the inabillty to distin\u00adguish between structure elements is a serious loss. 7 Related \nwork Hengleln used type inference to perform a binding time analysis In almost hnear time [Hen91 ], His \ntypes represent binding time values He presents a set of typing rules, extract constraints from the typing \nrules, and finally solve the constraints by using fast umon/find data structures Our points-to analysis \nalgorithm was inspired by Henglein s type inference algorithm. The points-to analysls that closest resembles \nour analysls is Welhl s [Wei80], His analysis is also flow-insensitive, interpro\u00adcedural, and deals with \npointers to functions, His algorithm does not assume that ahas relations are reflexlve and transitive, \nand WIII Table 1, Number of type variables describing a given number of program variables for ~he unoptlmized \nprogram re~resentation For example, for Iandi. allroots, there are 67 type variables each describ\u00ading \nthe location of a single program variable.    . . ; -, 3 k ~ ; 3 5 Table 2 Number of type variables \ndescribing a given number of Table 3: Number of type variables describing a given number of pointed to \nprogram variables for the unoptim-ized program repre\u00ad pointed to program variables for the optimized \nprogram representa\u00ad sentation tion. therefore in some cases produce better results than our algorithm. \nOn the other hand, his algorithm does not distinguish between one or several levels of pointer Indirection \nAdditionally, his algorithm works best lf a call graph ]s avmlable. and it does not deal elegantly with \nrecursive functions His rdgorithm has a time cost complexity that is cubic in the size of the input program \nwhereas our algorlthm has an almost linear time cost complexity More precise polrrts-to analysis exist, \ne.g., [CWZ90, EGH94, WL95, Ruf95] These analyses we all flow-sens]tlve ]nterprocedu\u00adral dara flow analyses \nBoth Chase s algorithm [CWZ90] and Ruf s algol-ithm [Rul 95] are context-insensitive and have polynomial \ntime complexity. The two other algorithms are context-sensltlve, mean\u00ading that the algorithm distinguishes \nbetween effects of different calls of the same funchon instead of computing just one effect that is valid \nfor all calls of the functionq. The algorithm by Emaml, et. al., [EGH94] has a exponential time complexity, \nas it performs a vlr\u00adtuai unfolding of all non-recursive calls. The algorithm by Wilson and Lam [WL95] \nalso has exponential time complexity but IS likely to exhibit polynomial time complexity in practice \nas it uses partial transfer functions to summarize the behavior of already armlyzed functions and procedures, \nWhereas a points-to analysis builds and maintains a model of the store during analysis, an alias analysis \nbuilds and maintains a list of access path expressions that may evaluate to the some Iocatlon (in other \nwords: they are aliased). The most relevant alias analysis algorithms are [LR92, LRZ93] The length of \naccess-paths are k-Ilmited, using a relahvely simple truncation mechanism to eliminate extra path elements. \nDeutsch presents an alias analysls for an imperative subset of ML [Deu92] Access paths are defined in \nterms of monomial rela\u00adtions (a kind of multi-variable polynomial expl-ession with structure accessol-s \nas the variables) The analysls M thel-efore only relevant for strongly typed languages such as ML and \nstl-ongly typable pro\u00adgrams written in weakly typed languages such as C (as shown in [Deu94]). Access \npaths are combined by unification A higher order (context-sensitive) points-to analysis by type inference \nhas been developed by Tofte and Talpin for the purposes of creating an ML interpreter without a garbage \ncollector [TT94] The analysis is based on polymorphic type inference over a non\u00adstandard set of types \nThey assume a runtime model that makes allocation regions explicit, where allocation regions resemble \nthe storage shape graph nodes of our algorithm. Their algorithm does not deal with objects that may be \nupdated after being assigned an initial value (as IS normal for imperative programs), Whether their work \ncan be generalized to work for general imperative programs is an open question. Andersen defines context-sensitive \nand context-msensltlve anal\u00adyses that are flow-insensitivel points-to analysis in terms of con\u00adstraints \nand constraint solving [And94]. The context-sensitive al\u00adgorithm distinguishes between immediate calling \ncontexts in a 1\u00adlimited version of the static program call graph, effectively taking two layers of context \ninto consideration, The values being con\u00adstrained are sets of abstract locations. Andersen s algorithm \nallows an abstract locatlon to be a member of non-identical sets. Our algo\u00adrithm only allows an abstract \nlocation to be described by one type representing a set of abstract locations. The size of the solution \nof hls context-insensitive algorithm is 0(A2), and the size of the solution of his context-sensitive \nalgorithm is 0(.4i), where A is the number of abstract locations, which in turn IS O(exp N), where N \n30UI ,IIMIYSIS IS context-] menwt!ve became [he type sy$tem IS monomol-phic If wehxl wwci LIpolymcmph]c \ntype system WK1polymorpluc type Infelence, the dgonthm would Ih:lve t3een context-sems]uve 4Anderstm \nuses the telm ]t]tl-,[.p[oced~l[,ll to Incdn cot)text-][]hti>hltlve md tbe ten>> i!]tel-ploccdural to \n!IMU1 context-sen sltlve M the size of the programs In contrast, the size of the solution of our algorithm \nIS O(N). Chol et al present both flow-sensltlve and flow-rnsensitive anal\u00ad yses [CBC93] The flow-lnsensltlve \nanalysis algorithm IS described in more detail in [BCCH95] Their algorithm computes alias infor\u00admation \nrather than points-to information but uses a representation that shares many properties with the storage \nshape graph The rep\u00adresentation allows abstract locations to be members of non-identical sets Their algorithm \nis based on Iterated processing of the program statements and lt thus IIkely to be slower than a similar \nconstraint based algorithm (such as Andersen s context-sensltlve algorithm but only considering one level \nof calling context). The algorlthm presented in this paper is an extension of another almost linear points-to \nanalysis algorithm [Ste95a]. Bill Landi has independently arrived at the same earlier algorithm [Lan95]. \nBar\u00adbara Ryder and Sean Zhang are also working on a version of the earlier algorithm with the extension \nthat elements of composite ob-Jects are represented by separate type components [Zha95]. 8 Conclusion \nand Future Work We have presented a flow-insensitive, interprocedural, context\u00adinsensitlve points-to \nanalysls based on type reference methods with an almost linear time complexity. The algorithm has been \nimple\u00admented and shown to be very efficient in practice, and we have found the results to be much better \nthan the results of intraprocedu\u00adml analyses A problem with the analysis as presented is that It does \nnot disambiguate information for different elements of structured ob\u00adjects The type system can be extended \nto do so, but the resulting analysis algorithm will not have an almost linear time complexity. The algorithm \nwill still be asymptotically faster than other exist\u00ading algorithms that does distinguish between different \nelements of structured objects Our main interest has been developing efficient interprocedural points-to \nanalysis algorithms for large programs. We would like to develop efficient algorithms yielding greater \nprecision than the algorithm presented in this paper, Given the algorithm presented in this paper, there \nare two possible directions to investigate. One way to obtain improved results is to develop an efficient \nflow-sensitive algorithm, The results from the algorithm presented in the present paper can be used to \nprime a data flow analysis algorithm or otherwise reduce the amount of work to be done by the algorithm. \nOne possible method is splitting of functional stores as suggested in [Ste95b]. Another way to obtain \nImproved results is to develop an efficient flow-insensitive, context-sensitive algorithm. This can be \ndone using types to represent sets of locations, as in the almost linear time algorithm, but using polymorphic \ninstead of monomorphic type inference methods. We are currently pursuing both directions of research. \nAcknowledgements Roger Crew, Michael Ernst, Erlk Ruf, Ellen Spertus, and Damel Weise of the Analysts \ngroup at Microsoft Research co-developed the VDG-based programming environment without which this work \nwou~d not have come into existence, Members of the Analysts group also commented on and proofread versions \nof this paper, The au\u00adthor also enjoyed interesting discussions with David Morgenthaler, William Griswold, \nBarbara Ryder, Sean Zhang, and Bill Landi on To be ta{r, A IS probably propoltlonJ to IV In prfict]ce \n various points-to analysis algorithms with almost linear time com-[Hen91 ] Fritz Henglein. Efficient \ntype inference for higher-order plexity, We would IIke to thank Bill Landl and Todd Austin for sharing \ntheir benchmark suites with us. References [ABS94] Todd M Austin, Scott E Breach, and Gurindw S Sohi. \nEfficient detechon of all pointer and array access er\u00adrors In SIGPLAN 94: Conferelwc cm Programming Lcmgl{age \nDesign cmd lilzlj[ej]leiztatlolz, pages 290-301, June 1994, [And94] Lars Ole Andersen. Program i:atiolz \nfor the C Progra}n]}iing sis, Department of Computer Copenhagen, May 1994. Analysis cmd Special-Language. \nPhD the-Science, University of [ASU86] Alfred V. Aho, Ravi man. Compi[ers-Principles, Addison-Wesley, \n1986 Sethi, and Jeffrey D. UII-Techniques, and Tools. [BCCH95] Michael Burke, Paul Carini, Jong-Deok \nChoi, and Michael Hind Flow-insensitive interprocedural alias malysls in the presence of pointers In \nProccedmgs from the 7th International Workshop on Languages znd Compilers for Parallel Computing, volume \n892 of Lecture Notes in Compater Science, pages 234-250. Springer-Verlag, 1995. Extended version published \nas Research Report RC 19546, IBM T.J. Watson Research Center, September 1994. [CBC93] Jong-Deok Choi, \nMichael Burke, and Paul Carini. Ef\u00adficient flow-sensitive interprocedural computation of pointer-induced \naliases and side effects. In Proceed\u00adings of the Twentieth Annaal A CM SIGPLAN-SIGA CT Symposium o1? \nPrinciples of Programmin,g Languages, pages 232-245, Charleston, South Carolina, January 1993, [CR91 \n] William Clinger and Jonathan Rees (editors), RevisedJ report on the algorithmic language Scheme, November \n1991. [CWZ90] David R. Chase, Mark Wegman, and F. Kenneth Zadeck Analysis of pointers and structures. \nIn Pro\u00adceedings of the SIGPLAN 90 Conference on Program\u00adming Language Design and Implementation, pages \n296 3 10, June 1990. [Deu92] Alain Deutsch A storeless model of aliasing and its abstractions using firrite \nrepresentations of right-regular equiwdence relations. In Internat~ona/ Conference on Cowpater Languages, \npages 2 13 IEEE. April 1992. [Deu94] Alain Deutsch. Interprocedural may-alias analysis for pointers Beyond \nk-limiting. In SIGPLAN 94: Con\u00adference on Programming Language Design and [ntp!e\u00admentation, pages 23G241, \nJune 20-241994. [EGH94] Maryam Emami, Rakesh Ghiya, and Laurie J. Hendren. Context-sensitive interprocedural \npoints-to analysis in the presence of function pointers, In SIGPLAN 94: Conference on Programming Language \nDesign and Im -/,/eme/ttation, pages 242 256, June 20-241994. [Gri95] William G Griswold Useofalgorithmfrom \n[Ste95a] in a program restructuring tool. Personal communication at pLD1 95. June 1995. [KR88] [Lan95] \n[LR92] [LRZ93] [Mor95] [Ruf95] [Ste95a] [Ste95b] [Tar83] [TT94] [WCES94] Wei80] WL95] [Zha95] binding-time \nanalysis. In Functional Programming and Computer Architecture, pages 448-472, 1991. Brian W. Kernighan \nand Dennis M, Ritchie. The C Programming Language, Second edition. Prentice Hall, 1988, William Landi. \nAlmost linear time points-to analyses. Personal commumcatlon at POPL 95, January 1995 William Landi and \nBarbara G. Ryder. A safe approx\u00adimate algorithm for interprocedural pointer aliasing. In Proceedings \nof the SIGPLAN 92 Conference on Programtning Language Design and I]tl]?lejlzetztcltiotz, pages 235 248, \nJune 1992. William A. Landi, Barbara G. Ryder, and Sean Zhang. Interprocedural modification side effect \nanalysis with pointer aliasing. In Proceedings of the SIGPLAN 93 Corzfet ence on Programmmg Language \nDesign and [m\u00adplementat~on, pages 56 67. June 1993. David Morgenthaler. Poster presentation at PLDI 95, \nJune 1995. Erik Ruf. Context-insensitive alias analysis reconsid\u00adered In SIGPLAN 95 Conference on Programming \nLangaage Design and [wrplementation, pages 13 22, June 1995. Bjarne Steensgaard. Points-to analysls in \nalmost lin\u00adear time. Technical Report MSR-TR-95-08, Microsoft Research, March 1995. Bjarne Steensgaard. \nSparse functional stores for im\u00adperative programs. In A CM SIGPLAN Workshop on In\u00adtermediate Representations \n(IR 95), pages 62 70, San Francisco, CA, January 22 1995. Proceedings appear as March 1995 issue of SIGPLAN \nNotices. Robert E. Tarjan. Data structures and network flow algorithms. In Regional Conference Series \nin Applied Mathematics, volume CMBS 44 of Regional Confer\u00adence Series in Applied Mathematics. SIAM, 1983. \nMads Tofte and Jean-Pierre Talpin. Implementation of the typed call-by-value A-calculus using a stack \nof re\u00adgions. In Proceedings 21st SIGPLAN-SIGACT Sympo\u00adsium on Principles of Programming Languages. pages \n188 201, January 1994. Daniel Weise, Roger F, Crew, Michael Ernst, and Bjarne Steensgaard. Value dependence \ngraphs: Rep\u00adresentation without taxation. In Proceedings 21st SIGPLAN-SIGA CT $wtposiutn on Principles \nof Pr-o\u00adgramming Languages, pages 297 3 10, January 1994. William E. Weihl. Interprocedural data flow \nanalysis in the presence of pointers, procedure variables, and label variables. In Conference Record \nof the Seventh An\u00adnual ACM Symposium on Principles of Programming Languages, pages 83-94, January 1980. \nRobert P. Wilson and Monica S. Lam. Efficient context\u00adsensitive pointer analysis for C programs. In SIG-PLAN \n95 Conference on Programtning Latlguage De\u00adsign and /l?t/~letnelztatiorz, pages 1-12, June 1995. Sean \nZhang. Poster presentation at PLDI 95, June 1995.  \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "Bjarne Steensgaard", "author_profile_id": "81100440791", "affiliation": "Microsoft Research, One Microsoft Way, Redmond, WA", "person_id": "P30938", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.237727", "year": "1996", "article_id": "237727", "conference": "POPL", "title": "Points-to analysis in almost linear time", "url": "http://dl.acm.org/citation.cfm?id=237727"}