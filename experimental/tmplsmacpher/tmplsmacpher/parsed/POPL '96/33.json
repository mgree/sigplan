{"article_publication_date": "01-01-1996", "fulltext": "\n Proving the Correctness of Reactive Systems Using Sized Types John Hughes Lars Pareto* Amr Sabry Department \nof Computer Science Chalmers University 41296 Goteborg { rjmh, pareto, sabry Abstract We have designed \nand implemented a type-based analysis for proving some baaic properties of reactive systems. The analysis \nmanipulates rich type expressions that contain in\u00adformation about the sizes of recursively defined data \nstruc\u00adtures. Sized types are useful for detecting deadlocks, non\u00adtermination, and other errors in embedded \nprograms. To establish the soundness of the analysis we have developed an appropriate semantic model \nof sized types. Embedded Functional Programs In a reactive system, the control software must continu\u00adously \nreact to inputs from the environment. We distin\u00adguish a class of systems where the embedded programs \ncan be naturally expressed as functional programs manipulat\u00ading streams. This class of programs appears \nto be large enough for many purposes [2] and is the core of more ex\u00adpressive formalisms that accommodate \nasynchronous events, non-determinism, etc. The fundamental criterion for the correctness of pro\u00adgrams \nembedded in reactive systems is Jwene.ss. Indeed, before considering the properties of the output, we \nmust en\u00adsure that there is some output in the first place: the program must continuous] y react to the \ninput streams by producing elements on the output streams. This latter property may fail in various ways: \ne the computation of a stream element may depend on itself creating a black hole, or e the computation \nof one of the output streams may demand elements from some input stream at different rates, which requires \nunbounded buffering, or o the computation of a stream element may exhaust the physical resources of the \nmachine or even diverge. Supported by NUTEK ( Swedish National Board for InrILIst rid and Technical Development \n) grant 5321-93-2833. Permission to make digitallhard copies of all or part of this material for personal \nor classroom use is granted without fee provided that the copies are not made or distributed for profit \nor commercial advantage, the copy\u00ad right notice, the title of the publication and its date appear, and \nnotice is given that copyright is by permission of the ACM, Inc. To copy otherwise, to republish, to \npost on servers or to redktribute to lists, requires specific permission andlor fee. POPL 96, St. Petersburg \nFLA USA @ 1996 ACM 0.89791 -769_3/95/01 . .$3.5f) }(Qcs, chalmers. se To support the use of high-level \nfunctional languages in embedded systems we have developed an analysis that checks the fundamental correctness \nproperty of an embed\u00added functional program, t. e., that the computation of each stream element terminates. \nThe main component of our analysis is a (non-standard) type system that can express bounds on the sizes \nof recursive data structures. Experience with the implementation indicates that the system works remarkably \nwell for small but realistic programs. The next section motivates the use of sized types for reasoning \nabout reactive systems. Section 3 introduces the syntax and semantics of a small functional language \nwith sized types. The next two sections present the type inference rules, establish their soundness wit \nh respect to our semantic model of types, and give some examples that illustrate some of their strengths \nand weaknesses. Sections 6 and 7 deal wit h the details of the implementation and our experience in using \nit. Before concluding we review related work. 2 Sized Types Various basic properties of reactive systems \ncan be estab\u00ad lished using a notion of sized types. We informally moti\u00ad vate this notion and its use \nin reasoning about stream com\u00ad putations using some examples. 2.1 Productivity In a conventional lazy \nfunctional language, the dat atype of streams of natural numbers would be defined as: data ST = Mk NAT \nST. The declaration introduces a new constructor M k which, given a natural number and a stream produces \na new stream, t.e., it has type NAT + ST + ST. Two sample programs that use this datatype are: head (Mkns) \n= n of type ST -+ NAT tuzl(Mkns) = S of type ST + ST A more interesting program is: letrec ones = Mk \n1 ones in ones which computes an infinite stream of 1 s. In other words, for any natural number Z, a \nrequest for the first i elements 410 of the stream is guaranteed to be processed in finite time: is \napparent that such a claim can only be justified if we can theprogram isproduckve [5,17]. A slight modification \nof the program to: Ietrec ones = Mkl (tadones ) in ones is not productive; it cannot compute the first \ni elements of the stream for any i > 1. To understand the problem, W\u00adsume that after unfolding the recursion \ni times, we obtain a stream s with i + 1 elements. The recursive call then com\u00adputes (tads) which has \ni elements and adds one element to produce a stream that has i + 1 elements: each recursive call is attempting \nto construct a stream with no more elements than the previous call and no new elements are added to the \nstream after the first one. Our intuitive analysis of the behavior of the programs can be formalised \nusing a (non-standard) type system. The system includes a new family of types ST (streams with at least \ni elements), which can express the more informative type Vi. NAT -i ST; + ST ~+1 for the constructor \nM k. Con\u00ad sequently, for the previous programs, we get the intuitive types Vi. STi+l -i NAT and Vi. ST \n+l 4 ST for head and tad respectively. The type of ones is Vi. ST which indicates that it is a stream \nwith an infinite number of elements. The program ones is (rightly) rejected.  2.2 Memory Leaks Using \nsized types, we can not only guarantee that some streams are productive, but also establish that some \nfunc\u00adtions are unsafe w their computation requires unbounded space. For example, consider the program: \nIetrec jil (Mk nl (Mk n, s)) = Mk (avgm nz) (fits) in Js.stream-add (fits) (fil (jil s)) The function \nfil represents an idealised digital filter and should have type Vi.ST2i ~ ST since it requires two ele\u00adments \nfrom its input stream to compute one element of its output stream. Using the following diagram, we can \ninfor\u00admally calculate lower bounde on the sizes of all the streams used in the program: The figure reveals \nthat for every i output elements, we need 4i input elements. These latter elements are all consumed along \nthe bottom path. However only 2i elements are con\u00adsumed along the top path and the remaining 2i elements \nmust be buffered. The size information reveals that the pro\u00adgram would be unsafe in a reactive system \nas it is impossible to implement a buffer of size 2i for all i. 2.3 Termination In the above example, \nwe claimed that the type of jd is b i. ST2 -+ STi. In other words, we claimed that given 2 elements, \nthe function jil is gum-anteed to produce one ele\u00adment in finite time. By inspection of the definition \nof jil it prove that the function avg terminates! In general we might have to prove that an arbitrary \nfunc\u00adtion of the natural numbers terminates. To this end our system must include approximations NAT~ \nto the datatype NAT of natural numbers. Intuitively an approximation NAT; represents numbers with at \nmost i constructors. 1 Using this new family of sized types, we can prove that the type of aug is Vkl.N-&#38; \nrZ~ -+ NATZt + NATk+t. Not only does such a type guarantee the termination of the function, but it also \nprovides useful information. 3 Syntax &#38; Semantics For the purpose of presentation, we restrict our \nattention to a small prototypical lazy functional language, 3.1 Syntax A program consists of a number \nof global declarations of user-defined datatypes followed by a term. We distinguish two kinds of datatype \ndeclarations: data D~ = Conlfi+. ..+ Conm~ codata D~ = Conl~+. ..+ Conmfi Each declaration introduces \na datatype name D possibly parametrised by a vector of type variables F. The right hand side of the declaration \nintroduces a number of term constructors for the dat at ype Con 1, ..., Con ~ and specifies the types \nof their arguments. For example, possible decla\u00adrations for natural numbers, streams, and lists are: \ndata NAT = Zero + Succ NAT data FSTREAM t= FMk t(FSTREAM t) codata STREAM t= Mk t(STREAM t) data LIST \nt = Nil + Cons t(LIST t) codata ILIST t= lNil + lCons t(ILIST t) Intuitively a data declaration signals \nthat the user is inter\u00adested in the finzte elements of the datatype. In contra&#38; a codata declaration \nsignals that the user is also interested in the injhute elements of the datatype. Thus NAT is the set \nof natural numbers, FSTREAM is the set of all finite streams (the empty set!), STREAM is the set of all \nfinite and infinite streams, LIST is the set of all finite lists, and ILIST is the set of all finite \nand infinite lists. With each datatype name, e.g., NAT or STREAM, our system associates a family of types, \ne.g., NATO, NAT1, . . . . NATO or STREAMO t,STREAM1 t,....STREAMU t.The types with natural indices represent \nthe elements of the datatype with the given size bound. The types with the special in\u00addex w represent \nthe [limit of the natural approximations. For example, the type NATS represents the natural numbers {O, \n1,2} and NATti represents the entire set of natural num\u00adbers. Similarly the type STREAM3 trepresents \nall streams with at least 3 elements of type t and STREAMti trepresents all infinite (productive) streams \nwith elements of type t. 1During our current experiments, we use the inductive definition of the natural \nnumbers (built from O and Succ) and prove the termination of arithmetic functions, e.g., addition, from \nbasic principles. In future versions of the system, we intend to provide a library of the common arithmetic \nfunctions with their appropriate types. The precise set of type expressions is inductively gener\u00adated \nover infinite sets of dat atype names D, type variables t G 7 Var and size variables i c 5 VaK ff ::= \nVt.a I via / 7-(Type Schemes) T ::= tlT+Tl Dsfi[Dsfil D@7ii[mm In addition to the usual quantification \nover type variables, type schemes may quantify over size variables. Type expres\u00adsions T include type \nvariables, function types, and indexed datatype names. The size indices S can either be the special index \nw or some function of size variables. To get precise types, it is tempting to allow arbitrary functions \nof size variables. For example a precise type for factorial would be Vi. NAT? -+ NAT;!. However to get \na workable system we will restrict ourselves to linear relationships among size variables. Restriction \n3.1 The size indices can only be linear func\u00ad tions of the st.ze varaables: S::= 71 GN[i[S+Sln*S Thus \nthe best type we can express for the factorzal function is Vi. NATi -+ NATti. Finally, the set of terms \nis inductively generated over infinite sets of variables z E Var, and constructors Con &#38; Con: M ::= \niz[Az. MI MM ICon M.. .M [ case Mof(P+iW) . ..(P+M) \\ letrec .=MinM P ::= Conxl . ..xn (Patterns) The \nfull language also allows mutually recursive definitions but we do not consider them in the remainder \nof this pa\u00adper. We require that the patterns in a case-expression are exhaustive. The language has more \ncontext-sensitive restric\u00adtions that will be introduced and motivated during the de\u00advelopment of the \nsemantics.  3.2 Semantics of Expressions We specify the semantics of the terms using a conventional \ndenotational model. The universe U of denotations is iso\u00admorphic to the (coalesced) sum of the following \ndomains: z UJEConL@ [UJ+U]@ [UJx UJ]L@ [lLJ-+UJ]L The domain ConL is the flat domain of constructors. \nThe definitions of the domain operations 1 (lifting), + (separated sum), @ (coalesced sum), x (cartesian \nproduct), and + (continuous function space) are standard. We will use n\u00ad ary pro ducts as abbreviations \nof sequences of binary ones. The symbol ~ denotes the approximation ordering on the universe of values. \nGiven the universe of values, the semantic function &#38; that maps a term, and an environment to an \nelement of U. Environments map variables to denotations. 2 Most semantic models of types include an element \nwrong that formalises run-time errors. We exclude this element from our universe of values because our \ntype system rejects strictly more expressions than a conventional one, t. e., i t cannot accept any expression \nwhose evaluation causes rumtime errors. Figure 1: Sample Semantic Types Definition 3.1 (Meaning Function \nE) The dejinztzon is st andard:3 &#38;: MxEnv -+ U Env :Vam -+ U E[(CorI M, .Mn)]p = (Con, EIMl]p,. . \n. . E[M~]p) E[z]p = p(z) E[(Xz.M)]p = f e ~ -+ UJ] where f(u) = E[M]p[u/z] E[(M N)jp = app(EIMllp, E[iV]p) \nEuletrec z = M in N]p = E[N]p[u/z] where u = U,>. mi(f, ~) and f(~) = &#38;[ M]p[u/z] app:UJx UJ + U \nf(u) tff 6[u -+u] ww(f,u) = ~ o th erwzs e { w (f,U) = U\u00ad app + (~, u) = j(app (f, u))  3.3 The Universe \nof Types A type is a subset of U with special properties. To moti\u00advate these special properties we examine \nthe meaning of the stream ones. According to the semantics in the previous section, the denotation of \nthe stream of 1 s is the limit of the following chain: ones =1 C STO u (Mk,l, L) C STO, ST1 L! (Mk, l,(Mk, \nl, l)) G STO, ST1, STz ... ... In a conventional semantics for types, there would be one set corresponding \nto the stream dat at ype, and this set would include all the elements that appear in the chain. For our \npurposes, we have a family of sets corresponding to each of the types STi, and each set only contains \npart of the chain. For example the set ST must not include 1 or (M k, 1, 1) as we cannot compute the \nsecond element of either of these streams in finite time. A consequence of this property is that not \nall types in\u00ad clude 1, which immediately invalidates the standard seman\u00ad 3 In the definition, we onut \nthe clause for case-expressions as well ss the explicit isomorphisms mapping elements of the summands \ninto the universe and vice-versa. tics of types based on ideals [11, 12], or intervals [3].4 In contrast \nto these systems, we define the universe of types UJT to be the collection of all upward-closed subsets \nof U. A set ~ is upward-closed if whenever z G 7_ then for every y 2 z, we have y G T. For example Figure \n1 illustrate both the approximations to the data and codata declarations of natural numbers. Proposition \n3.1 The unwerse of types UT is a complete latttce ordered by the subset relation; the least upper bound \noperation is the set-theoretic union, and the greatest lower bound operation is the set-theoretic intersection. \nIn order to give a semantics to type expressions we must associate an upward-closed set with each type \nexpression in the language. For composite type expressions, e.g., func\u00adtions, sums, and products, we \nintroduce corresponding type operations on the universe of types: H , E , and E The set T1 T~ is defined \nto be {(O, U) I u 6 T1}U{(l, U) [ u ~ r,}. The operation E is the regular cartesian prod\u00aduct. The set \nT1 B Tz is defined to be {j GU I Vx G TI. app(i, x) G T,}. 3.4 Continuity and Ordinals Given the precise \ndefinition of the universe of types and its associated operations, we can now study the semantics of \nuser-defied datatypes. To motivate the definitions we will first examine the semantics of the following \nthree datatypes: data NAT = Zero + Succ NAT codata ST = Mk NAT ST data SP tltz = Null + Put t2 (SP tlt2) \n+ Get (t]-+(SP t]tz)) The first two datatypes should be familiar. The datatype SP is the datatype of \nstream processors from the Fudgets library [6]. This datatype describes three kinds of stream processors: \n1. the N UII processor, 2. the processor (Put tz(SP tlt~))that can output an element of type tz and \nthen becomes a new stream processor, and 3. the processor (Get (tl-+ (SP tl tz)))that expects a value \nof type tIand then becomes a new stream pro\u00adcessor.  For each datatype D we must associate a set with \neach of its approximations O, 1,2, . . . and w. The conventional way of explaining the meaning of recursive \ndatatype declarations is by taking the fixed point of a functional over the universe of types. The functional \nare easily derivable from the dec\u00adlarations using a function D whose definition is omitted. D[NAT] = \nF. ~[sT] = F. D[SP] TI Tz = Fp 4Semantic models based on retracts [16] are not appropriate for an\u00adother \nreason, they do not support the form of implicit polymorphism common in the programming languages that \nwe are using. where: F.(T) = {Zero} E ({ Succ} H T) F.(T) = {Mk}~N xr~ T FP(T) = {Null} E ({Put} E I-2 \nE T) H ({Get} H ( T] B T)) We can now calculate for each datatype the meaning of its approximations O, \n1,2, . . . in a straightforward manner. Simply put, the meaning of the ith approximation to D is the \ni-fold application of the functional D[D] to either the bottom element (fJ) or the top element (U.J)of \nthe lattice of types. The choice of the initial element depends on whether the datatype was declared \nas a data or codata. Thus the meaning of NATZ is (ignoring injections and tags): F;(o) = Fn(Fn(0))  \n F.({Zero} E ({ SUCC} lXl 0)) . Fn({Zero} QI 0) .  Fn({Zero})  {Zero} E ({ Succ} H {Zero}) = {Zero, \n(Succ, Zero)}  We invite the reader to trace the calculation of F; (W) which is the meaning of ST2. \nAt this point, one might expect that the meaning of the wth approximation to the datatype is simply the \nleast (for data) or greatest (for codata) fixed point of the correspond\u00ading functional. However in a \ncomplete lattice such as our lat\u00adtice of types, the fixed point of a functional F is calculated as follows: \n1. If the functional F is not monotone, then the limit may not exist. 2. If the functional F is monotone \nbut not continuous, then the least fixed point of F is F&#38;(0) for some ordinal 6 where [4:p. 106, \nEx. 4.13]:  FO(u) = U Fi+l (u) = F(F (u)) FA (u) = Uj<~ FJ (u) (A is a limit ordinal) The greatest \nfixed point is calculated by a similar ar\u00adgument using the dual lattice. 3. If the functional F is continuous \nthen the ordinal 6 in the previous case is the first limit ordinal w. In other words we should not expect \nthe meaning of the wth approximation to coincide with the least or greatest fixed point of F unless F \nis continuous. In our running examples, the two functional F. and Fs are indeed contin\u00aduous and the meanings \nof NAT. and ST can be computed as lJ~<U Fj (0) and ok<. F: (UJ) respectively. In contrast the functional \nFp is monotone but not contin\u00ad uous and its wth approximation does not correspond to its least fixed \npoint. This rather technical point has important practical consequences. Example: Consider the term: \nletrec rid n = case n of Zero -+ Null Succ p + Put p (ridp) in Get (An. rid n) which represents a stream \nprocessor that when given a num\u00adber n, outputs n elements and then becomes the Null proces\u00adsor. Although \nthe evaluation of the stream processor clearly terminates when given an argument of type NATW, our sys\u00adtem \ncannot handle such a term w the following argument shows. First we note that in our example the stream \nprocessors manipulate natural numb ers so the types oft he construct ors are as follows (where we abbreviate \n(SPi NAT. NATO) as SPNi). Null :: v i. SPNi+I Put :: Vi.NATu 4 SPNi -+ SPN,+I Get :: Vi. (NATti -+ SPN, \n) + SPN,+I Given these types, we note that the meaning of SPNI = {Null}. In general the meaning of SPNi \nis the set of stream processors that terminate after at most (i 1) Put and Get operations. The set SPNW \nis the union of all the sets SPN?. In other words it is the set of processes that terminate within a \nfixed number of operations regardless oj the inputs they recetve. Clearly (Get (An.rid n)) is not in \nthe set SPN . On the other hand for each n c NATU, (d n) is in SPNW. It follows that (Get (Jn. rid n)) \nis in SPNU+I. Because the functional Fp is not continuous SPNU+I is not identical to SPNU. k%! We now \nhave a few alternatives: 1. Allow the declaration of the datatype SP and accept the term (Get (An. rid \nn)). This means that we must be prepared to handle indices that range over ordinals. 2. Allow the declaration \nof the datat ype SP but reject any programs that would require ordinal indices, t. e., reject the term \n(Get (An. rid n)). 3. Reject the declaration of the datatype SP because it defines a non-continuous \nfunctional.  For simplicity reasons, we have opted for the third alter\u00adnative. This choice demands that \nwe find simple syntactic criteria that ensure that all datatype declarations yield con\u00adtinuous functional. \nWe begin by identifying the problem\u00adatic positions in a declaration. Definition 3.2 A type expression \nT occurs in a non-U-con\u00ad tinuous poszt%on af: (Ul) -r occurs in either argument to --) , (U2) T occuTs \nm an argument to a codata name, or (U3) r occurs in argument r~ to a data name D and r, occurs m a non-~-continuous \nposttton in the right hand szde oj the declaration of D. Samilary a type expression T occurs in a non-0-continuous \npositaon %f: (11) T occurs in the left argument to +, (12) r occurs in argument r% to a data or codata \nname and ri OCCUTS m a non-~-continuous position in the rzght hand side of the declar-atton of the name. \nThe restriction on datatype declarations is now simple. Restriction 3.2 In a data declaration the declared \ntype cannot occur in a non-U-continuous poshon. In a codata declaration the declared type cannot occur \nin a non-~-con\u00adtinuous posxtzon. We can easily verify our previous claims regarding the continuity of \nNAT, ST, and SP. For more interesting exam\u00adples, consider the following declarations: data ORD = Zero \n+ Succ ORD + Lim (STREAM ORD)  data TREE t= Leaf t+ Node (LIST (TREE t)) data LIST t= Nil + Cons t(LIST \nt) In the first declaration, ORD occurs as an argument to a codat a name thus violating condition (U2) \nabove. Indeed ORD k a canonical non-continuous type. In the declaration of TREE, the declared type (TREE \nt)is passed as an argu\u00adment to LIST potentially violating condition (U3). To ensure that the condition \nis not violated we check that tdoes not occur in non-LJ-continuous position in the right hand side of \nthe declaration of LIST. Although ORD and SP are not ac\u00adcepted when declared as data, they would be accepted \nwhen declared as codata. This means that although we cannot reason about the termination of stream processors, \nwe can prove that they do not deadlock. The major consequence of our restriction is that we can now treat \nall (infinite sizes as identical to w. In other words, we can use identities like w = w + 1 when reasoning \nabout programs.  3.5 Semantics of Types We can now speci~ the precise semantics of type expres\u00adsions. \nDefinition 3.3 (Type Semantics) The jlnctton Z maps a type expression and two environments @ and ~ to \na se\u00admantic type: Z:ux Envlx Env2 + UT Envl : TVar + UT Env2 :SVar + N where in the last J clauses 1 \nn the value of the size expression S in the environment ~ and F is the functional comespond\u00admg to the \ndatatype name D, ?.e., F = D[D] ~[rk]~~. Proposition 3.2 The function Z is well-defined. Proof Sketch. \nIt is easy to verify that each of the type constructors E , E , and ~ maps upward-closed sets to upward-closed \nsets. E 3.6 Testing for 1 A major property of our semantic model is that it is possible to test whether \n1 is included in a type, which is crucial if we are to reject programs that may diverge. Given that types \nare upward-closed sets, the test of whether a type 7 includes 1. is quite simple: 1 G ~ if and only if \n-r = U. We define two mutually recursive predicates empty and all that decide whether the denotation \nof type expression -r is the empty set or the universe u respectively: all (Do) all (7-I + m) if all \n(~z) or empty (_rI) empty (Do) empty (71 -+ m) if empty (-r~) and notempty (T1) notempty (Ds) notempty \n(D ) notempty (T1 + 72) if notempty (m) or empty (-n) The predicates are sound (but not complete) with \nrespect to our semantic model.  3.7 w-Types When a value is too large for its size to be expressed in \nour restricted language, we give it a size of w. For example, the type we can actually give factorial \nis Vi.NAT, -+ NAT@. But now we face a problem if we want to compute fur\u00ad ther with the result. Suppose \nfor example we want to type factorial (factor?al n). To type the outer application of fac\u00adtorial we need \nto give it the type NATti + NATti, instan\u00adtiating i to w as it were. But our size variables range only \nover naturals, so it is not valid to do so! Yet in this case the result is clearly sound. Our goal then \nis to extend the system to allow the in\u00adstantiation of size variables to w. To this end, let us define \nsubstitution of w for a size variable i. The interesting cases are: Do if i GFV(S) Ds [w/i] = Ds otherwise \n{ D if i GIW(S) Ds[w/z] = Ds otherwise{ Thus we simpli~ sizes involving w directly to w; this is justi\u00adfied \nsince our size expressions can only express strictly mono\u00adtonic functions of their free variables. We \nimmediately encounter a problem: it is not always sound to instantiate size variables to w. For example, \nsup\u00adpose f has the type Vi. STREAM NAT, + UNIT. Then we know that f terminates for every bounded sequence. \nBut to give f the type STREAM NATW ~ UNIT we must show that it terminates for ever-y sequence. This need \nnot be the case: consider the function that searches for the first element whose value is less than its \nposition in the stream. We aim therefore to find syntactic conditions on types that guarantee that our \nproposed extension is sound. Let Ti be a type expression indexed by a size variable i and ab\u00ad breviate \nn~ [w/i] as TW. We want to guarantee that (Vi.ni) D no. Or semantically speaking we want to guarantee \nthat (n; ~,) ~ rti. If this is the case we say m, is w-in.tantzable. We say rri is monotonic if i < j \nimplies r~ ~ -irJ, and anti-monotonic in the dual case. These can be recognised easily: ni is monotonic \nif i only occurs positively, and anti\u00admonotonic if i only occurs negatively. The definitions of positive \nand negative occurrences are as usual, with the ex\u00adtension that an occurrence in the size of a data type \nis con\u00adsidered positive, and an occurrence in the size of a codata type is considered negative. Clearly \nmonotonic types are w-instantiable, because the w instance is bigger than all the finite ones, but this \nis hardly interesting. More interesting are the anti-monotonic exam\u00ad ples, such as STREAM; BOOL, or those \nwhich are mixed, such as STREAM; NATi or NATi -+ NATz,. Monotonicity is much too strong a condition to \nimpose. We will therefore define a slightly stronger condition than w-instantiability, which we can use \nsuccessfully as an induction hypothesis. Definition 3,4 An indexed type r, is w-undershooting zf Ui fljzi \nTf G ~ti ~l~ew~seT; u w-overshooting if ~~ c  uin,>,~~. Intuitively, while w-instantiability says that \nthe sequence of nis tends below TU, w-undershooting says that the same holds for every suffix of that \nsequence. Clearly: o w-undershooting types are w-instantiable, m monotonic types are w-undershooting. \nThe converse is not necessarily y true: for example STREAMi B 00L is w-undershooting even though it is \nnot monotonic, anti-monotonic types are w-overshooting. Again the converse is not true: NATi is w-overshooting \nbut it is not anti-monotonic,  constant types, e.g., the set cent aining Zero, type vari\u00adables, and \nthe datatype UNIT are w-undershooting and w-overshooting, and  o sums and products of w-overshooting \nand undershoot\u00ading types are respectively w-overshooting and under\u00adshooting. These definitions were motivated \nby the following result. Proposition 3.3 If z% is w-overshooting and T; is w-under\u00adshooting, then Xi \n~ n: is w-undershooting. proof. We show that if f c (J,flj ~,rj ~ nj then f E nti ~ nj. Take an arbitrary \nz E mm: we must show that f z ~ m:. But n, is w-overshooting, so z c nj ~,= TJ for some in. We also know \nf Gfl ~kit XJ~~~ for some if. SOf x G n;, and therefore since m; is w-undershooting 17j2ma~~,.,tf~ we \nhave f x~r~.~ Thus to check that a function type is w-instantiable, we need only check that its argument \ntypes are w-overshooting and its result type is w-undershooting. For example, NATZ ~ NAT2, and NAT, + \nSTREAM t-+tare both w-inst antiable. ~~ D ~j (j in contravariant position) DkTl . .. TnDDk T. . .. &#38; \nr, D r: (i in covariant position) Figure 2: The subtyping relation One might expect a dual result to \nhold for w-overshooting function types, but it does not. The type NAT. -+ NAT i is not w-overshooting \nsince (Ji (lj ~~ (NAT. + NATi) is the set of all bounded functions, but NAT. -+ NAT. also contains the \nunbounded ones. We settle for anti-monotonicity as a sufficient condition for function types to be u-overshooting; \nit is possible to weaken the requirement for function types with finite domains, but we do not consider \nit worthwhile to do SO. It remains to find general conditions for data and co\u00addata types to have these \nproperties. Let F, be the functional on types which is iterated to define the semantics of the data or \ncodata type in question. This functional F, can very well depend on i: for example if the type is STREAM \nNAT; then F;(7) = {Mk} Rl NAT, El ~. All F~ expressible in our lan\u00adguage have the following property \nwhich is needed to prove Proposition 3.5. Lemma 3.4 Fi(X) fl Fj(Y) = F;(X n Y) n FI(X n Y). Let #i be \na size expression possibly involving i. Then ~ is either constant or strictly monotonic. We can prove \nthe following propositions. Proposition 3.5 For any famzly of types n,, %f: xi u-undershooting amplzes \nFi (ni) w-undershooting then F? (0), F$i (U), Uj F:(0) and nJ F! (U) are also w\u00adundershootmg. Proposition \n3.6 For any famzly of types r,, zf: n, w-overshooting impltes FL (n, ) u-overshooting then F~; (0) and \nl_J7F; (0) are atso w-overshooting. These results give us a simple way to check that a data or codata \ntype is w-undershooting, or that a data type is w-overshooting. The size is irrelevant; we simply check \nthat all components have the same property, assuming that re\u00adcursive occurrences of the data or codata \ntype have it. For example, NAT~ and LIST, NAT, are both w-over-and -under\u00adshooting, as is any other type \nbuilt only from data types. Likewise STREAM NAT ~ is w-undershooting, but we cannot conclude that it \nis w-overshooting. And indeed it is not STREAMJ NATj is the set of productive streams Muinjz$ whose \nelements are eventually less than their position in the stream, which is not a superset of STREAM NATti, \nthe set of all productive streams. We fall back on anti-monotonicity as a sufficient condition for a \nco dat a type to be w-overshooting, and we doubt that any much weaker condition can be found. 4 Type \nSystem Before presenting the type inference rules, we present a sub\u00adtype relation crl D UJ. The motivation \nis that since we infer bounds on sizes, it should always be possible to re\u00adlax the current bound to a \nless accurate one. Without such flexibility it would be impossible to type programs like (if M then s \nelse (Mk 1 s)), as the two branches would have sizes that differ by 1. The relation D is defined in Figure \n2. It is straightfor\u00adward to show that the semantic count erp art of the subt yping relation is the subset \nrelation. Lemma 4.1 If al D 02 then for all environments ,B and ~, qal],6 7 G qm]B7. The main innovation \nin our type inference system is the rule for typing recursive declarations. Before presenting the entire \nset of rules, we first discuss a simple version of the letrec rule that does not include the generalisation \nof free type variables. The type environment r maps variables and constructors to type expressions: all \n(-r[O/i]) r t-k.kf: vz.7 + di+ I/Zl ru{Z,b i.T}&#38;~:T~ i @ Fv(r) r E(letrec z= M in N) :T1 The rule \nhae three premises. The main one (in the middle) states that a functional defining a recursive value \nought to make progress at each recursive call by producing values of the next size. Depending on whether \nthe size variable i in\u00ad dexes a data declaration or a codata declaration, the nex\u00ad t size could be a \nbigger or smaller set respectively. Thus the same typing rule can be used to both prove that com\u00ad putations \nusing data objects terminate and computations using codata objects are productive. The first premise \n(the bottom check ) ensures that we can start the iteration of r+~:rl +72 (Var) u{x 71}k M:T (Abs) r \nE N : (App)ru{~:a}k~:a r + (XMVf) : n + 72 rtMN:~z r+ c.n, ~con con) rkM:Tl &#38;pat (~z, Tl) : r, rurzt \nMi:72 z c l n}) (Case) r+case Mof(Pl+Ml). ..(Pn +Mn):~J rEM: J t f2 Fv(r) (Gen) ;:::::;] n ) r t-M: w.g \nr+kf:~ i g v(r) (GenS) :::::;] n ) rFM:v2.cJ rt-M:lT~ r t M : Vi.rr~ D 2 (Coer) Ti is w-undershooting \n(u)rkM:u. rl-M:7r. all (T II)/z]) r ~ k.~~: Vi.T -+ T[i+ I/i] r u {X: Vi~.V~.T} ~ N: T1 i @ w(r), I,Z \ng ~v(T)\\~v(r) (Ret) r 1-(letrec z = M in ~) : T] Figure 3: Rules for Type Inference the functional in \nthe first place. The last one concludes (us\u00ading an implicit induction principle) that the recursive object \ncan be safely used at any size. To motivate the importance of the bottom check we present the following \nexample which illustrates that the rule becomes unsound if we omit it. Example: Consider the term: s \n= if heads then Mk True s else Mk False s It is easy to verify that the program diverges (z. e., the \nstream s is not productive). However assuming that s is of type ST;+*, the right hand side is of type \nST +2. In other words, the functional is making progress at each recursive call as required by the main \npremise of the letrec rule. The fail\u00adure of the bottom check (1 @ ST1 ) guarantees that the program would \nbe correctly rejected. The rules for type inference are in Figure 3. The rules for variables, procedures, \napplications, constructors, gener\u00adalisation and instantiation of type variables do not exploit nor affect \nthe sizes and are standard. The notation ~Con refers to the type of the constructor Con as inferred from \nthe corresponding datatype declaration. The rule for case\u00adexpressions uses an auxiliary judgement defined \nas follows: ZnSt(CTCon)=T( +...~~~+~ l-Pat ((con zl. ..zn)r):): {xl :T{,...,~n :~k} where inst provides \na generic instance of a type scheme. The rest of the inference rules rely on the size annota\u00ad tions. \nFirst we can generalise and instantiate size variables in the natural way as in (GenS) and (InstS) respectively. \nSecond we can coerce any type to a less precise type by relaxing the bounde on the sizes (Coer). Third \nwe can in\u00ad stantiate size variables that index w-undershooting type ex\u00ad pressions to w. Finally when \ntyping recursive declarations (Ret), we must ensure that the resulting computations are terminating and/or \nproductive. The main technical result of the paper is the soundness of the type system. Theorem 4.2 (Type \nSoundness) If we can prove that M has type u, then the denotation of M is indeed an element of the type \ndenoted by c. Proof. The proof proceeds by induction on the height of the type derivation and proceeds \nby case analysis on the last rule. The inductive hypothesis states that: If r + M : a then for all p,,6,~ \nsuch that the relation IR(17, p, ~, -y) holds, &#38;[M]p c Z[u]@~. The relation R is defined as: iqr, \np, p, ~) if V{Z: CT} ~ r.g[~]p E z[a]p~. Most of the cases in the proof are standard. The subtyping \ncase follows by Lemma 4.1. The soundness of the typing rule for the case-expression requires that that \nthe patterns are exhaustive. The soundness of the w-instantiation rule was sketched in Section 3.7. We \npresent the let rec case in detail: Assume r E (letrec % = Jf in IV) : T, and I-@, p, ~, 7) for some \np, ,8, and ~. We want to show that: &#38;[(letrec z = M in N)]p = s[N]p[u/z] where u = l-i~f ~(l), and \n~ = i$[kE. M]p G Z[T1]67 By the inductive hypothesis, we get: f = qk.qp G Z~i.7 + ~[i + l/i]]/3~ 6 nk \nz[7],B7[k/i] El ~WJ7[~ -+ 1/4 (*) We now claim that: VI%G N.fk (1) e z[T]p~[k/i] (t) e Modulo the \nobligation to prove the claim (t), we can estab-The right hand side of reverse s definition has the type \nLIST~+I t + LIST,+l t which satisfies the main premise lish our result as follows. Let u = LIk fk (1), \nthen: of the typing rule for recursion. u g f~(J-) for all k . . u E z[T]p~[k/i] for all k, since types \nare upward closed . . u 6 nk T[T],@y[k/i] .. ~(r u {Z, Vi. T}, P[U/Z]) p,~) . . &#38;[N]g+4/z] c qhlnh \ninductive hypothesis To complete the argument we must prove our claim (t). The proof proceeds by induction \non k. If k = O then the claim reduces to 1 G zllr16-d O/ii which is an immediate consequence of the botto~ \nch~ck. Ifk=j+l then: induct ive hypothesis f (J-) ~ ~[~lP7[~/4 . . f(.f (1)) E 417-]@y[j+ I/i] property \n(*) and definition of ~ Ea 5 Using the Type System Before talking about the actual implementation, we \nwill at\u00adtempt to gain some intuition about the strengths and weak\u00adnesses of our system using some small \nexamples. 5.1 Primitive Recursion: Reverse Our system is strong enough to prove termination or produc\u00adtivity \nof functions in primitive recursive form. For example, assuming that the append function for lists can \nbe given the type (cf. Section 6): -i LISTJ+I t -+ LIST,+j tappend:: Vij.Vt. LHT% t we can prove that \nthe naive reverse function can be typed as follows: reverse :: Vi. Vt. L1sT~ t 4 LIST, t Tevers e xs \n= case xs of Nil + Nil Cons y ys + append (~eweme ys) (Cons y Nil) The derivation of the type proceeds \nas follows: 0 Assume reverse :: LIST, t+ LISTi t. e Assume m :: LIST,+] t. e Check that the Nil branch \nhas type LISTL+l t(direct). e Assume y :: tand ys :: LIST; t. e Conclude reverse ys :: LISTi t. e Conclude \n(Cons y Nil) :: LIST~ t (not LIST1 tasyou might expect it has two constructors). a Instantiate the type \nof append, and conclude that: append (Teve~se YS) (Cons y Nil) :: LIST,+] t asrequired. Notice that if \nwe had given append a less precise type, omitting the f+ 1 , we would have been unable to draw this conclusion. \n* The bottom check: verify all (LISTO t-iLISTO t). It holds because empty (LISTO t) holds. 5.2 Ackerman \ns Function Indeed, any function defined by a primitive recursion scheme is accepted by our type system. \nThis includes higher-order primitive recursion, so in particular we can type Ackerman s fimction. But \nwe are obliged to rewrite it in primitive re\u00adcursive form. Consider first the usual first-order definition: \nackxy = case x of Zero -+ Succ y Succ z 4 case yof Zero ~ ack z (Succ Zero) Succ y + ockz (ack z y ) \nWe cannot type this recursion as it stands because there is no argument which gets smaller in every recursive \ncall. We have to reformulate the definition, so that it corresponds to the structure of a termination \nproof. Ackerman s function can be proved terminating by a double induction, first on z, and then, for \na fixed z, on y. We therefore re-express it using two recursive functions, one recurring on x, and the \nother (higher-order) recurring on y. ackz = case x of Zero -+ Succ Succ z + h (ack z ) hfy= caseyof Zero \n-+ ~ (Succ Zero) SUCCy ~ ~(hf y ) These definitions can be given the types: ack :: Vk.NAT~ + NAT. ~ NAT. \nh :: Vk. (NATti --+ NATti) + NATk + NATO Of course, since our size expressions can only express linear \nfunctions we cannot do better than give the result a size w. Notice that in order to type the application \nof h in ack, we have to instantiate k to w.  5.3 Shuffling Lists If we could only accept definitions \nin primitive recursive form, our type system would not be very interesting. The following example shows \nthat we can accept a wider class of definitions. It defines a function that shuffles a list: shuf)le \nxs z case xs of Nil+ Nil Cons z m -+ Cons z (shuffle (reverse XS )) This definition is not in primitive \nrecursive form because the argument of the recursive call of shufie is not m . But it is the same size \nas zs , and the type of reverse is strong enough to tell us that. We can therefore give shujj le the \ntype: shufj7e :: Vi. dt. bs ri t + LISTi t which is accepted by our system.  5.4 A Problem: Accumulating \nParameters 6 Implementation We showed above how to typecheck naike r-ever-se, but in To get an algorithm \nasserting type correctness of programs, reality of course we want to use the efficient linear definition \nwith an accumulating parameter: reverse xs = rev xs Nil rev xs ys = case xsof Nil+ ys Cons z 3s + rev \nzs (Cons z ys) The types we would like to give these definitions are: rev ers e :: Vi. Vt. LIsTi t+ LIST, \nt rev :: Vij.Vt.LrsT, t+ LISTJ+I t+ LIsTi+j t Unfortunately this type for rev is not accepted by our \nsystem! To see why, we trace through the typing of rev: Assume rev :: LIST~ t + LISTj+I t + LISTi+l \nt.  Assume m :: LIST;+l t and ys :: LIST3+I t.  In the Cons branch, assume xs :: LCST~ t.  Conclude \n(Cons z ys) :: LISTJ+Z t  NOW the application of rev is well-typed only if ~ + 2< j +1! This constraint \nis unsatisfiable and the program is rejected.  These definitions can be typed, but only SS: reverse \n:: #i. Vt. LIsT~ t -+ LISTti t rev :: Vi. Vt.L1sT, t-+LISTU t-+LISTti t But with this type for reverse, \nthe definition of shufle above cannot be typed! The solution seems to be to allow a limited form of poly\u00admorphic \nrecursion: over sizes, but not types. Thus when typing the body of rev, we would assume the typing: rev \n:: Vj. LIST~ t -+ LISTj+l t + LIST~+j t and then type the recursive call by instantiating 1 toj+ 1. The \ntype of the result, LISTi+J+I t, matches the i + 1st instance of the declared type of rev, and typechecking \nwould therefore succeed. We plan to extend our implementation to allow this kind of polymorphic recursion. \nIt is necessary to do so: similar problems will arise whenever an accumulating parameter is used, and \nthis is an important programming technique which we must be able to type accurately.  5.5 Array Bounds \nCheck Our sized types can also be used to guarantee that array indices are never out of bounds. We view \nan array as a function from indices to contents. For example an array oft with 6 elements has type NAT \n6 + t.Our type system guar\u00adantees that an array with this type has at least 6 elements and is accessed \nwith indices which are less than 6. we must complement our deduction rules rules with a proof strategy. \nIf we want type inference, our algorithm must include an equation system solver. If we want subtype in\u00adference, \nit must solve systems of inequations. We distinguish type inference algorithms from those for type checking \nin that the latter rely on type annotations and do not address minimality of a typing. We have implemented \na type checker for our sized type system. It requires all let-bound variables of a program to be annotated \nwith sized type signatures, but infers the types for all other expressions. Its proof strategy is simple. \nUses of (Var), (Abs), (App), (Con), (Case) and (Ret) are structurally determined by the program. Other \nrules are used as follows: (Inst),(InstS) Are used together with (Var) and (Con). (Gen),(GenS) Are used \nat (Letrec) and at the topmost expression. (Coer) Is used at (App), (Con) and (Case). The systems of \ninequations arising in our type system are predicates of the form V;.(SISS~A..ASn5SA) where sj ,s$ are \nsize expressions. Such a constraint system is said to be solvable if there exists a substitution under \nwhich the system holds. In general, the above constraint system formulation is not the only conceivable \none. Nothing in our semantic model stops us from using arbitrarily complicated constraint lan\u00adguages. \nThe restriction lies in our abilities to solve the cor\u00adresponding constraint systems. Our work does not \naddress the problem of constraint solving. Instead, we exploit recent developments in con\u00adstraint solving \ntechnology via the omega calculator [9, 13]. The formulation of our constraint systems is to a large \nex\u00adtent determined by the capabilities of the omega calculator. The reason for implementing a type checker \nrather than a type inference algorithm is twofold: First, if we want to do type inference, a minimal \ntype must exist for every typeable program. It is easy to for\u00admulate a constraint language for which \nthis does not hold. Furthermore, as we suggested above, the prospects of con\u00adstraint solving strongly \ndepend on the expressiveness of our constraint language. If our constraint language is too pow\u00aderful, \nthe type inference algorithm will be hopelessly incom\u00adplete. Finding the right compromise might be tedious, \nso one of our design choices is to let the constraint language reflect the best available constraint \nsolver regardless if the language can express minimal types or not. Second, inference for the (Letrec) \nrule is tricky. In the general case we have to solve an equation system with func\u00adtions of size variables \nw unknowns, the solution has to re\u00adspect our constraint language and it must be minimal. By letting the \nprogrammer introduce the unknown function us\u00ading a type signature, these problems disappear. Although \ninitial experiments with letrec-inference looked promising we found the additional complications too \ndistracting to be worthwhile. 6.1 Technical overview Size inference There are three major steps in the \nalgorithm: Hindley Milner Inference We check that the program is type correct in terms of ordinary types. \nSize Inference We typecheck the program with our sized type system under the assumption that all type \nsigna\u00adtures are correct. Constraint solving We solve all the constraints and verify that our inferred \ntypes match the type signatures. The result of the algorithm is the syntax tree annotated with sized \ntypes and a set of error messages. The first is useful in interpreting the latter. 6.2 Example We proceed \nthrough the algorithm step by step and examine the typechecking of the append function on lists. letrec \napp : : f orall k 1 a. Llst#k a -> Lie.t#l+i ~ -> List#k+l a appxs ys = case xs of N,l -> ys Cons x xs \n-> Cons a (app x. ys) in app We will refer to the nodes of the syntax tree using the names in the figure \nbelow. We write e.a for the annotation a of node e. Hindley Milner inference The first step is to do \nstandard (Hindley Milner) type infer\u00ad ence. We motivate this as follows. The erasare 5 of a sized type \nscheme o is defined by dropping the size quantifiers and size variabl~s from a to get an ordinary type. \nThis notion extends to r and r t-e: o-. Now, if we erme every judgement in a sized proof tree, then we \nget a Hindley Milner proof tree. During inference, we annotate every node of the syntax tree with its \nHindley Milner type e. hm. For the subtree elo of our example we get elo. hm = LISTCX -+ LISTOj eu.hrn \n= LISTa-+LISTa-+LISTa els. hm = LISTa The next step is size inference. First we extend our ordi\u00adnary \ntypes to sized types: A fresh size variable is added to every type constructor of the type annotations. \nWe refer to the sized type annotations as e.sz which for our example becomes: elo.sz = LISTkQo a + LISTk \nZI a e32.sz = LISTMZ a + LISTW3 a + LISTk~4 (2 els. sz = LISTM a Then, we infer our sized types: We \ntraverse the syntax tree and collect equalzty constraints on our extended types to make them appear as \nin the corresponding proof tree. Consider the typing rule for (App): rkitf:rl+ m rt-fv:T1 To make our \nsyntax tree annotations match this rule we must unify the codomain type of el~ .SZ with the type elo. \nsz. Hence we get: LISTk20 a -i LISTk21 a = Listkzz a -+ LIsTkz4 a at the node elo. As we coerce at (App) \nwe add an inequality rather than an equality between the domain type of eI z and the type of els : The \nnodes elz and els are both variables so we expect a lookup in r possibly followed by an instantiation \nwith fresh variables. At both nodes the type environment r includes: {ZS: !$15, a p~: LISTk,o a-+ LISTk3,+, \na-+ LISTk30+k,, (1} so we will simply unify elj .SZ and e13 .SZ with the corre\u00ad sponding types in R \nLISTk30 a + LISTk31+l o! + LISTk30+k31 a = LISTk22 a + LISTkZ3 a + LISTW a LISTk15 a = LISTkM a The \ntyping of constructors, case expressions and lambda expressions are all variations on the same theme \nand we do not consider their details. More interesting is letrec. First recall its typing rule: all (r[O/i]) \ni fz m(r), R g FV(T)\\FV(r) r t-XZ. M : vi. r + T[i+ I/i] r u {z : W7.T} t-N :7-1 r t-(letrec z = M in \nN) :TI Note that the letrec rule has a built in (Gen) rule. To under\u00ad stand the strategy of the algorithm, \nwe must consider some general properties of subtype inference: Whenever a con\u00ad strained type is generalised \nwe must capture its constraints. At instantiation, the captured constraints are added to the constraint \nset of the typing instantiating it. Now, if we simplify our constraints before generalisation, we will \navoid unnecessary constraint inst antiations. This is a good thing as constraint manipulation is costly. \nAlthough many poly\u00ad morphic subtype systems have expression forms for bounded quantification, for example \nu where C where C is a con\u00ad straint system [I], our type system does not. As a conse\u00ad quence, simplification \nmust eliminate all constraints, other\u00ad wise we can not express the type. The (Letrec) rule for the implementation \nhas a slightly dif\u00adferent appearance than the deduction rule: ru{x:r}+itf:r I U{x:x.sia]t N:r, r t-(letrec \nz = M in IV) :m T--T = instjft) ft = Vi. Vk.V~.T -+ r~+ /,] di.v~. di.T = Z.Sig au = (c, Fv(r), T + 7- \n, ft) Here inst is the polymorphic instantiation function, using fresh variables for all quantifiers. \nIt is used to instantiate ft which is the type scheme used to type the recursion ap\u00adproximator. Note \nthat this formulation of letrec has fused the uses of (Gen) and (Lambda) for the approximator judge\u00adment \ninto the rule. The type scheme ft represents the type family used in our induction proof. It is defined \nusing the type signature x.sig of the variable x. The most striking differences of the (Letrec) deduction \nrule vs. its implementation is the missing conditions for bot\u00adtom check and generalisation. The reason \nis simple -they are not checked during size inference. Instead we build an annotation assumption aa, \nwhich encapsulates everything needed to check these conditions later. An annotation as\u00adsumption contains: \nThe set of coercions C collected during the proof of i14, the free variables of r, the inferred type \nfor the recursion approximator and the correspondhg type created from the type signature. We will come \nback to the proofs of annotation assumptions. Another major difference is that the type signature z. \nsig is used in the typing of the term N. Hereby, we can continue the inference process assuming that \nany error lies in the implementation of the function failing to type, not in its specification. Our little \nexample gives us the following annotation as\u00adsumption, here updated with the solution to the system of \nequalities. (C, 0, t ,s) where c = {LISTklo+la -+ LISTWY -i LISTWW < LISTkM+Id -+ LISTkz5+ld + LISTkz4+]+kz5a \n, LISTk24+1CY -+ LISThZ5+Id + LISTkz4+l+kz5d < LISTk~o+Ick + LISTk4a + LISTMCY, LISTkIoCI ~ LISTkMCY, \nLlsTk4a < LISTkz5+l a , Cu<a , LISTk~4+kz5cl < LISTWCY, LISTk28+1~ < LISTk6CU, LISThACY < LISTk@} i? \n= (LISTk24CY + LISTkZ5+IO! + LIsTk24+k25cv ) -+ LISTklo+la -i LISTk4a + LISTMCI s = v/C~.b U.(LISTk U \n+ LIsT~+la -+ LISTk+~a) 4 LISTk+l U -+ LrsT~+la + LIsTk+l+la  Note that the first two constraints form \nan equality on types. Type equalities added at letrec nodes occasionally involve equalities on size expressions. \nWe use the constraint solving pass to handle such equations. There are six other con\u00adstraints, two for \nthe alternatives in the case rule, two for the constructor arguments and one for each of the two other \napplications. Constraint solving The constraint systems emerging from our proofs are linear inequalities \non natural numbers. The core of our constraint solving pass is the omega calculator [9, 13], a tool for \nma\u00adnipulating Presburger formulas. Given a constraint system of integer linear inequations it solves \nthe system and rejects it if unsolvable. The constraint solving pass has 7 stages: Translation Coercions \nbetween types are translated to size constraints using a straightforward implementation of the relation \nD. Omega test The omega tester either rejects a constraint system or presents a solution to it. A solution \nconsists of a substitution and a simplified constraint system which -in the ideal case-will be empty. \nSimplification From our experience, the elimination of re\u00addundant constraints in the omega tester needs \nto be completed with some simple heuristics. Substitution The resulting substitution is applied to all \nannotation assumptions. Annotation check To prove that an assumption about an annotation is correct we \nunify the type signature with the (pseudo) inferred type, then generalise all variables of the latter \nwith respect to the saved free variables and finally check that the two type schemes are identical. Bottom \ncheck Finally, we bottom check the annotation using a straightforward implementation of the predi\u00adcate \nall. There are three possible origins for a constraint. Most are due to the coercions during size inference \nbut some are due to type equivalences. The annotation check equates the body of the annotation with the \ninferred type by adding two dual coercions to the type constraints. Finally, as our constrained size \nvariables range over naturals rather than integers, we must constrain them to be positive if they are \nto be solved by the omega calculator. Let us return to our example. We had 8 coercions in our annotation \nassumptions, two of them were due to the equivalence in letrec. To equate the annotation with the inferred \ntype we add another two. Translating this set gives us 23 constraints over 8 size variables i.e. 31 constraints \nin all: {O<= k24, O<= klO, O<= k25, O<= k4, O <= k6, O <= k28J O<=k, 0 <=1, k24+l<=k10+l, , k25+l<=k4 \nk6<= k24+1+ k25 k10+l<=k24+l, k4<=k25+l k24+l+k25<=lc6, k4<=l+1 k10<= k24, k4<= k25+1 k24 + k25 <= k28, \nk28 + 1<= k6 k4<=k6, k<=k24, li-l<=k25+l k24+k25<=k+l, klO+l<=k+l k+l+J<=k6, k24<=k, k25i-1<=1-tl k+l<=k24+k25, \nk+l<=klO+l l+l<=k4, k6<=k+l+l} From this constraint system the omega calculator derives the following \nsolution: [k, 1>k, k, 1, 1+1, k+l+l, k+l / k,l, k24, klO, k25, k4, k6, k28] Applied to our annotation \nassumption we get (C, O,t , s) where C is the solved constraint system t =( LIsT~d +LISTL+Id -+ LIST~+iQ \n) + LIST~+ICI + LISTl+Ia + LIST~+l+IQ .S= Vkl.Va.(L1sT~a ~ LIST1+la -+ LIST~+~a) -+ L1s r~+la ~ Lrs rl+la \n-+ LIST~+I+la As there are no free variables captured by our annotation assumption we generalise all \nsize variables in t i.e. k, 1which are the same as in the signature. Hence we are finished with the annotation \ncheck. Remaining is the bottom check. The O-instantiated type is LISTOG -+ LISTl+la -+ LISTia for which \nthe bottom check holds as the domain type is empty. 7 Using the Implementation The concrete syntax of \nour language is similar to the syntax of Haskell [7]. To express our richer set of type expressions, \nwe use $ to refer to w and # to index both data and codata declaration names. 7.1 Modularity As with \nall type-based analyses, our analysis need not ma\u00ad nipulate the entire program at once. It is possible \nto anal\u00ad yse modules separately and summarise the types of their exported functions in an interface file. \nFuture uses of the functions in the module need only look up the types in the interface file. We have \nimplemented such a rudimentary module system which we illustrate with a small example. Assume that the \nmodules Nat and Stream include defi\u00ad nitions of typical functions like add, tail, and zap Wtth. At some \nprevious time, the system has checked the contents of these modules, and summarised the types of their \ntop level definitions in an interface file: add :: Vij.NAT, ,-+ NATj H NATt+j tad :: bt.Va .ST%+~a + \nST CY   Zlp With :: vi.va py.(a -+ /3+7) + ST%CY+ STi,6 -+ STiy Then we can write the following module: \nmodule Fib where import Nat --defines add import Stream --def inei? tall, zipWith surnl :: f orall k. \nStr.am#k Nat$ -> Stream#k Nat$ -> Stream#k Nat$ suml = zipWith add fibl :: forall k. Stream#k Nat$ fibl \n= Mk O (Mk 1 (suml fibl (tall fibl))) f ib2 :: f orall k. Stream#k Nat$ fib2 :: f orall k. Stream#k Nat$ \nfib2 = Mk O fib2 flb2p = Mk 1 (suml fib2 fib2 ) Figure 4: Finite impulse response filter When processing \nthe module, jib 1 is rejected as the system can not prove that the application (tad jib) will succeed. \nThis is because the structure of the definition does not match the structure of the termination proof \nfor fibl. Rewriting the example using two mutually recursive definitions as in jib2 produces a program \nthat our system accepts. 7.2 Correctness of A Digital Filter Digital filters are often implemented as \na weighted sum of the n last samples of the input signal. Figure 4 illustrates such a filter whose implementation \nin our language is: module Filter where Import Stremn --defines tail, map, zipWith import Nat --defines \nadd, mu12, mu16, mu19 suml :: f orall k .f orall a b. Stream#k Nat#a -> Stre.am#k Nat#b -> Stream#k Nat#a+b \nsuml = zipWlth add 20 :: f orall k .f orall a. Stream#k+3 a -> Stream#k a ZI :: forall k. forall a. Stream#k+2 \na -> Stream#k a 22 :: forall k. forall a. Streamtik+l a -> Stream#k a 23 :: forall k. forall a. Stream#k \na -> Stream#k a 20 = \\x -> tail (tail (tail z)) 21 = \\x -> tail(tall x) 22 = tall z3=\\x->x a2 :: f orall \nk 1. Stream#k Nat#l -> Straam#k Nat#2*l a6 :: f mall k 1.Stream#k Nat#l -> Stream#k Nat#6*l a9 :: f orall \nk 1. Stream#k Nat#l -> Stream#k Nat#9*l a2 = map mu12 a6 = map mu16 a9 = map mu19 fir :: f orall k 1. \nStream#k+3 Nat#l -> Stream#k Nat#18*l fir = \\i -> (suml (a2 (23 i)) (suml (a6 (Z2 l)) (suml (a9 (z1 \ni)) (20 1)))) Our system accepts the program. The type off ir estab\u00adlishes several points. First the \noutput stream is productive. Second the elements of the output stream are bounded to be no more than \n18 times larger than the elements in the input stream. Finally the program will not work unless the environment \nsupplies at least three elements of the input stream. 8 Related Work The formal notion of productivity \nis due to Sijtsma [17]. He presents a calculus for proving the productivity y of recursive definitions \nof streams but no automatic analysis. The closest analyses to ours are two recent ones for the estimation \nof ex\u00adecution times in parallel languages [8, 14]. Both our system and Reist ad and Gifford s [14] include \nsimilar notions of size and subtyping but nevertheless differ significantly regard\u00ading our two main technical \ncontributions. First, our system is the only one that includes a semantic interpretation of the sizes \nand a proof of soundness. Second, the languages support ed by the two systems are different. Reist ad \nand Gifford s system can handle imperative constructs but not user-defined recursive procedures. From \nour experience, the extension to user-defined recursive procedures is a maJor one that affects the entire \nsystem. In contrast the extension to imperative constructs appears to be straightforward. Our system \nis also related to several approaches for the formal development of reactive systems using synchronous \nlanguages, temporal logics, process calculi, etc [10]. Our system is distinguished by two major properties: \nproduc\u00adtivity y and modularity. Indeed in a recent comparison of 18 formal methods for the development \nof a simple production cell [1 O], only 6 or 7 implementors could prove the liveness (productivity) of \nthe production cell and only 3 or 4 used a modular solution. Furthermore only 1 system (Fo CUS) com\u00adbined \na proof of liveness with a modular solution but only for the speczjicatzon of the program and not for \nthe actual executable code. On the mathematical side, our approximations to sizes of recursive data structures \nare apparently related to some hierarchies of recursive functions [15] though the connection is not evident \nat this point. Conclusion We have designed and implemented an analysis that guar\u00adantees termination \nand Iiveness of embedded functional pro\u00adgrams. Moreover our analysis can sometimes detect space leaks. \nOur immediate goal is to use the analysis to reason about realistic reactive systems written in realistic \nfunctional lan\u00adguages for real-time programming [2, 18]. The analysis is based on a new notion of sized \ntypes and its associated semantic model which we expect to be appli\u00adcable in other contexts such as array \nbounds checking. We believe the same theory and type checking technology can be applied to other programming \nlanguages and extended to verify bounds on the run times of computations. Our longer term goals are to \nintegrate the analysis with a complete compiler so that it can yield more concrete in\u00adformation about \nthe run-time behavior of programs. References [1]AIKEN, A. S., AND WIMMERS, E. L. Type inclu\u00adsion constraints \nand type inference. In Functional Pro\u00adgramming @ Computer Architecture (June 1993), ACM Press, pp. 31-41. \n[2] BROY, M., ET AL. The design of distributed systems an introduction to Focus. Tech. Rep. S FB-Bericht \nNr. 342/2-2/92 A, Technische Universitat Munchen, 1992. [3] CARTWRIC~T, R. Types as intervals. Tech. \nRep. TRS4\u00ad5, Rice University, 1984. [4] DAVEY, B. A., AND PRIESTLEY, H. A. Introduction to Lattzces and \nOrder. Cambridge University Press, 1990. [5] DLJKSTRA, E. W. On the productivity of recursive def\u00adinitions. \nPersonal not e E WD 749, University of Texas at Austin, 1980. [6] HALL~REN, T., AND CARLSSON, M. Programming \nwith Fudgets. In Advanced Functional Programmmg (1995), J. Jeuring and E. Meijer, Eds., Springer Verlag, \nLNCS 925, pp. 137-182.  [7] HUDAK, P., PEYTON JONES, S., AND WADLEFL, P. Re\u00adport on the programming \nlanguage Haskell, a non-strict purely functional language (version 1.2). Szgplan No\u00adtices (1992). [8] \nHUELSBERGEN, L., LARUS, J. R., AND AIKEN, A. Using the run-time sizes of data structures to guide parallel-thread \ncreation. In Proceedings of the ACM Conference on Lisp and Functional Prograrnmmg (1994), pp. 79-90. \n [9] KELLY, W., ET AL. The Omega Library (version 0.91): Interface Guzde. University of Maryland at \nCollege Park, 1995. [10] LEWERENTZ, C., AND LINDNER, T. Formal Devel\u00adopment of Reactive Systems: G ase \nStudy Production Cell. Lecture Notes in Computer Science 891. Springer-Verlag, 1995. [11] MACQUEEN, D., \nPLOTKIN, G., AND SETHI, R. An ideal model for recursive polymorphic types. Znformu\u00adtion and Control 71, \n1/2 (1986), 95-130. [12] MAC QUEEN, D., AND SETHI, R. A semantic model of types for applicative languages. \nIn Proceedings of the ACM Conference on Lasp and Functional Programmmg (1982), pp. 243-252. [13] PUGH, \nW. The Omega test: .4 fast and practical in\u00adteger programming algorithm for dependence analysis. Communications \nof the ACM 8 (1992), 102-114. [14] REIDSTAD, B., AND GIFFORD, D. K. Static dependent costs for estimating \nexecution time. In Proceedings of the ACM Conference on Ltsp and Functional Program\u00admmg (1994), pp. 65 \n78. [15] ROYER, J. S., AND CASE, J. Subrecurswe Program\u00adming Systems: Complexity and Succinctness. Boston: \nBirkhauser, 1994. [16] SCOTT, D. Data types as lattices. SIAM Journal on Computmg 5, 3 (1976), 522-587. \n[17] SIJTSMA, B. On the productivity of recursive list defi\u00adnitions. ACM Thansactaons on Programming \nLanguages and Systems 11, 4 (1989), 633 649. [18] TRUVE, S. A new H for real-time programming. Un\u00adpublished \nManuscript, 1995.  \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "John Hughes", "author_profile_id": "81100166325", "affiliation": "Department of Computer Science, Chalmers University, 41296 G&#246;teborg", "person_id": "PP40024464", "email_address": "", "orcid_id": ""}, {"name": "Lars Pareto", "author_profile_id": "81321488341", "affiliation": "Department of Computer Science, Chalmers University, 41296 G&#246;teborg", "person_id": "P168886", "email_address": "", "orcid_id": ""}, {"name": "Amr Sabry", "author_profile_id": "81100016804", "affiliation": "Department of Computer Science, Chalmers University, 41296 G&#246;teborg", "person_id": "P16266", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.240882", "year": "1996", "article_id": "240882", "conference": "POPL", "title": "Proving the correctness of reactive systems using sized types", "url": "http://dl.acm.org/citation.cfm?id=240882"}