{"article_publication_date": "01-01-1996", "fulltext": "\n Optimization and Relaxation in Constraint Logic Languages Kannan Govindarajan Bharat Jayaraman Surya \nMantha Dept. of Computer Science Dept. of Computer Science Corporate Research &#38; Technology SUNY at \nBuffalo SUNY at Buffalo Xerox Corporation Buffalo, NY 14260 Buffalo, NY 14260 Webster, NY 14580 govin-ktlcs. \nbuf f alo. edu bharat@cs buffalo. edu mantha@wrc. xerox. com Abstract Optimization and relaxation are \ntwo important operations that naturall~ arise inmany applications involving constraints, e.g., engineering \ndesign, scheduling, decision support, etc. In optimization, we are interested in finding the optimal \n(i.e., best) solutions to a set of constraints objective function. In many applications, may be difficult \nor impossible to obtain, interested in finding suboptimal solutions, the constraints or relaxing the \nobjective tribution of this paper lies in providing with respect to an optimal solutions and hence we \nare by either relaxing function. The con\u00ada logical framework for performing optimization and relaxation \nin a constraint logic programming language. Our proposed framework is called preference logic programming \n(PLP), and its use for optimization was discussed in [8]. Essentially, in PL P we can designate certain \npredicates as optimization predicates, and we can specify the objective function by stating preference \ncriteria for determining the optimal solutions to these pred\u00adicat es. This paper extends the P L P paradigm \nwith facilities to formulate relaxation problems in a natural manner. We introduce the concept of a relaxation \ngoal, and discuss its use for preference I elaxation. Our model-theoretic semantics of relaxation is \nbased on simple Essentially, each world in the a preference logic program is of the program, and an \nordering mined by the objective function. expressed as truth in strongly concepts from modal logic: possible-worlds \nsemantics for a model for the constraints over these worlds is deter-Optimization can then be optimal \nworlds, while relax\u00ad ation becomes truth in suitably-defined suboptimal worlds. We also present an operational \nsemantics for relaxation as well as correctness results. Our conclusion is that the con\u00adcept of preference \nprovides a unifying framework for formu\u00adlating optimization as well as relaxation problems. Permission \nto make dtgital/hard copies of all or part of this material for persoml or classroom use is grsnted without \nfee provided that the copies are not made or dkitributed for profit or commercial advantage, the copy\u00adright \nnotice, the title of the publication and its date appear, and notice is given that copyright is by permission \nof $s ACM, Inc. To copy otherwise, to republish, to post on servera or to redwtribute to lists, mquirws \nspecific permission andlor fee. POPL 96, St. Petersburg FLA @ 1996 ACM &#38;89791 .769_3/95/01 USA ..$3.50 \n1 Motivation and Approach Constraint optimization and relaxation are practical tech\u00adniques for solving \nproblems arising in various applications, such as engineering design, document layout, interactive graphics, \nscheduling, and decision support. In these set\u00adtings one is interested in finding the optimal solutions \nto constraints with respect to some objective function; and, if the optimal solutions are impossible \nto obtain, one is inter\u00adested in finding suboptimal solutions either by relaxing the objective function \nor by relaxing the constraints themselves. While optimization and relaxation are important in practice, \nthey are meta-level operations as they require comparing alternative solutions and choosing the best \none and there\u00adfore they fall outside the standard constraint logic program\u00adming (CLP) framework [10, \n11]. While several approaches (discussed in section 2) have been proposed in the literature to address \nthese problems, they do not provide a unified, log\u00adical treatment of both optimization and relaxation, \nnor do they provide the flexibility of our proposed approach. The tout ribution of this paper is t we-fold: \nWe present a principled extension of the CLP franle\u00adwork for declaratively specifying optimization and \nre\u00adlaxation problems. We provide logical constructs to specify in a modular way which predicate is to \nbe op\u00adtimized and the criterion for optimization, as well as which (optimization) predicate is to be \nrelaxed and the criterion for relaxation. These criteria are understood using the concept of preference, \nhence the resulting programming paradigm is called preference logic pro\u00adgramming (PLP). We formalize \nthe declarative semantics of optimization and relaxation using concepts from modal logic. We give a possible-worlds \nsemantics for a PLP program in which each world stands for a certain subset of feasible solutions. The \nordering among worlds-determined from the preferences explicitly conveys the ordering among solutions. \nOptimization is then expressed as truth in strongly optimal worlds, while relaxation be\u00adcomes truth in \nsuitably-defined suboptimal worlds. We briefly illustrate our proposed programming constructs. The following \nCLP clauses for the predicate path (X, Y, C, P) computes P as a path (list of edges) with cost, C from \nnode X to Y in a directed graph: path(X,Y,C, [e(X,Y)]) + edge(X,Y,C). path(X,Y,Cl+C2, [e(X,Z)lLl]) * \nedge(X,Z,Ci), path(Z,Y,C2,Ll). To illustrate the constructs for optimization in PLP, a log\u00adical specification \nof the shortest-path problem can be given as follows (we present another solution to this problem in \nsection ?): sh-path(X,Y,C,P) -path(X,Y,C,P). sh_path(X,Y,Cl,Pl) < sh.path(X,Y,C2,p2) = C 2 < cl. Thefirst \nclauseis called anorhimization clause, andshmath is called an optimization predicate. Its space of fe~sible \nsolutions is some subset of the solutions for path (hence the use of a clause). The second clause is \ncalled an arbiter clause and it states the criterion for optimization: given two solutions for sh.path, \nthe one with lesser cost is preferred. The symbol s is to be read as is less preferred than . To illustrate \nthe constructs for relaxation in PLP, sup\u00adpose that we want to use the above definition of sh_path to \ncompute the shortest path between a and b that does not go through c. Note that the query ?-sh-path(a,b,C,P), \nnot inpath (c, P) will not fully accomplish our objective: If all the shortest paths between a and b \npass through c, the above cluery fails and we obtain no answer. Hence we in\u00adtroduce a relaxat~orz goat \nto solve our stated problem, as follows: ?-RELAX sh_path(a,b,C,P) WRT notinpath(c,p) The goal that follows \nthe keyword RELAX must be someop\u00adtimization goal, and the criterion for relaxing this goal is st,ated \nafter the WRTkeyword (read as with respect to ). The intended meaning of the relaxation goal is as follows: \nIf the best solutionsto sh_path(a,b,C,P )satisfynotinpath (c,P), then those are the solutions to the \nrelaxation goal. Other\u00adwise, the intended solutions are got by restricting the fea\u00adsible solution space \nof sh-.path(a ,b, C, P) by treating the predicate notinpath(c, P) as an additional constraint that sh-path(a, \nb, C,P) has to satisfy, and then finding the op\u00adtimal solutions in this restricted space. This example \nil\u00adlustrates what we call preference relaxation. We also show that the PLP paradigm subsumes the notion \nof constraint relcsxationas defined in HCLP [24]. The mocleLtheoretic semantics for PLPisgiven in terms \nof posszble worlds where each world is a model for the def\u00adinite clauses of the program, and the ordering \namong the worlds is determined by the preferences. We are interested in the preferential consequences \nof a program, or truth in strongly optimal worlds. This is in constrast with logical consequence which \nrefers to truth in all worlds. To provide semantics for relaxation goals, we consider only the worlds \nsatisfying the relaxation criterion to determine the best so\u00adlution: thus we effectively relax our preferences \nfor those worlds that do not satisfy this criterion. We introduce the notion of rekmedpr-efererztial \nconseqrsence to refer to truth in the corresponding strongly optimal worlds. We also pro\u00advide operat~onal \nsemantics for optimization and relaxation, and show that appropriate correctness results are obtained. \nThe operational semantics of optimization is given in terms of Pruned-Tree SLD (PTSLD) derivations. To \ncompute the relaxed preferential consequences of a program, we first per\u00adform a program transformation \non the definitions of theop\u00adtimization predicates that must be relaxed, and then use a variation of the \noperational semantics for PLP to compute the relaxed preferential consequences. Therernainder ofthispaper \nis organized as follows: Sec\u00adtion 2 compares our work with related approaches to opti\u00admization and relaxation. \nSection 3 presents the syntax of programs and several paradigmatic examples to show the power and flexibility \nof the paradigm. Section 4 gives the declarative semantics of PLP in terms of the preferential consequences \nof a program, i.e., truth in strongly optimal worlds. Section 5 provides the operational semantics of \nPLP programs in terms of Pruned-Tree SLD (PTSLD) deriva\u00adtions, states the main correctness results, and \noutlines their proofs. 2 Related Work As noted earlier, related approaches have dealt either with optimization \nor relaxation but, have not provided a unified framework for both. Our aDrxoach also offers advantages \n.. over these approaches both from a programming as well as semantic viewpoint. In the area of optimization, \nMaher and Stuckey [16] dis\u00adcuss how to incorporate optimization queries into a CLP system by mapping \nthe solutions of a query to a partial order; Fages [3] describes a semantics for optimization pred\u00adicates \nin CLP languages based on Kunen-Fitting s semantics for negation; and Marriott and Stuckey [18] discuss \nthe se\u00admantics of constraint logic programs with optimization by translating the optimization predicates \ninto predicates with negation. The key distinguishing feature of our approach is that it allows the programmer \nto program the prefer\u00adence criteria to suit the application at hand, In contrast, [18, 3] only provide \noptimization predicates that can be ex\u00adpressed as maximizing or minimizing some objective func\u00adtion. \nFages et al [4] allow the programmer to program the ordering among solutions but the semantics of optimization \nis rmovided via ne~ation, CornDared with the negation-based approaches [18, 3, 4], the advantage of our \napproach is that it gives an explicit treatment of the ordering among solutions, which results in a simple \nand direct way of formalizing both optimization and relaxation. Our notion of optimization is closely \nrelated to the notion of first-order aggregate operations (such as mzn and ma.z) in the field of deductive \ndatabases, where there has been a con\u00adsiderable recent interest in providing the semantics for ag\u00adgregation. \nA program with such aggregate operations has an equivalent first-order formulation using negation. Ganguly \net al [5] considered fisrt-order aggregates and showed that under certain mouotonicity conditions, the \nfirst-order equiv\u00adalent program has a total well-founded model [23] that can be computed using a greedy \nfixed-point procedure. There has also been interest in more general aggregate operations, such count, \nsum, etc. Kemp and Stuckey [13] examined programs with recursion through aggregation. To give se\u00admantics \nfor programs with aggregation, they extended two well-known semantics for programs with negation, namely, \nwell-founded models and stable models [6]. Ross and Sa\u00adgiv [20] provide semantics for aggregation where \nthe domain over which the aggregation is performed is a complete lattice and the program is monotonic. \nBy Tarski s theorem, we are guaranteed the existence of a least fixed-point for the aggreg\u00adate operation. \nSudarshan et al [21, 22] provide semantics for a class of aggregate operators that includes operations \nsuch as the kth-best solution, using valid models for normal programs. Our formulation of preference \nrelaxation enables the user to program such operations in aver flexible manner. In the area of relaxation, \nMantha et al [I] introduced Re\u00adlaxable Horn Clauses, where a relaxable clause is a definite clause with \na partial order over the goals in the body; the partial order dictates the order in which the goals are \nto be relaxed if all the goals in the body are not satisfiable. How\u00adever, stating the relaxation criteria \nin this way, i.e., in terms of goals local to a clause, provides only limited expressive\u00adness for our \nintended applications. Wilson and Borning [24] propose Hierarchical CLP (HCLP), a paradigm in which a \nconstraint may be optionally tagged with a weight (such as required, strong, weak, etc. ) that indicates \nthe importance of a constraint relative to other constraints and serves to or\u00adganize all constraints \nthem into linear hierarchy. The notion of a comparator is introduced in order to compare and order alternative \nsolutions to the required constraints by deter\u00admining how well they satisfy the remaining (i.e., relaxable) \nconstraints. Given a constraint hierarchy, the solutions of interest are those that satisfy the required \nconstraints and are optimal according to the comparator. \\\\ e show that the notion of optimization in \nPLP is powerful enough to capture the notion of relaxation in HCLP. PLP is more powerful than HCLP because \nthe latter does not provide a general support for optimization or preference relaxation. Our formulation \nof optimization and relaxation offers the benefits of having a simple declarative semantics, providing \nmodularity, and being amenable to an efficient implemen\u00adtation. We illustrate the first two points in \ndetail in this paper, but demonstration of the last point (efficient imple\u00admentation) is beyond the scope \nof this paper. Finally, we note that this paper extends our earlier work [8] in that the latter only \ntreats optimization (not relaxation). We gave an initial formulation of relaxation in [9] which did not \npermit relaxation goals in bodies of clauses; they were permitted only as top level goals. This paper \nextends our earlier work in providing a more comprehensive account of optimization and relaxation. 3 \nProgramming Paradigms in PLP 3.1 The PLP Framework A preference logic program may be thought of as cent \naining two parts: a first-order theory and an arbiter. The first\u00adorder theory consists of clauses each \nof which can have one of two forms: 1. H -BI, . . . . B~, (n > O), i.e., definite clauses. Each B, is \nof the form p(i) where p is a predicate and f is a sequence of terms. In general, some of the B,s could \nbe constraints as in CLP [10, 11]. 2. H-Cl,..., Cl I II I,. . . ,Bm, (l)m > O), i.e., opt2\u00admtzat~on \nclauses. CI, . . . . CI are constraints as in CLP [10, 11] that must be satisfied for this clause to \nbe ap\u00adplicable to a goall ; they are to be read as antecedents of the implication.  Moreover, the predicate \nsymbols can be partitioned into three disjoint sets depending on the kinds of c~auses used to define \nthem: lNote that the variables that appear only on the RHS of the \u00adclause are existentially quantified, \nnot universally quantified The intended meamng of this clause IS that the set of solutlons to the head \nIS some subset of the set of solutmns to the body 1. C-predicates appear only in the heads of definite \nclauses and the bodies of these clauses contain only other G \u00adpredzcates ( C stands for core). 2. O-predicates \nappear in the heads of only optimization clauses ( O stands for optimization). For each ground instance \nof an optimization clause, the instance of the O-predicate at the head is a candidate for the opti\u00admal \nsolution provided the corresponding inst ante of the body of the clause is true. The constraints that \na,p\u00adpear before the I in the body of an optimization clause are referred to as the guard and must be \nsatisfied in order for the head H to be reduced. 3. D-predicates appear in the heads of only definite \nclauses and at least one goal in the body of at least one such clause is either an O-predicate or a D-predtcate. \n(D stands for derzveri from O-predicates. )  The arbiter part of a preference logic program, which \nspec\u00adifies the optimization criterion for the O-predicates, has clauses of form: p(i) < p(ii)-Ll, . . \n..Ln (n> o) where p is an O-predicate and each L, is an atom whose head is a C-predicate or a constraint \nas in CLP. In essence this form of the arbiter states that p(i) is less preferred thcm p(ti)if Ll, . \n. ..L~. A relaxation goal has the form RELAX P(5 WRT c(ii), where p is an O-predicate and c is a C-predicate \nor a con\u00adstraint as in CLP. The predicate p is said to be a relaxable predicate and c is said to be the \nrelaxation criterion of the relaxation goal. The semantics provided in this paper also captures the meaning \nof relaxation goals where c is any O-predicate that is not defined in terms of p. However, in this paper, \nwe will only deal with relaxation goals where c is a C-predicate, A relaxation goal may appear in the \nbody of an O-predicate, a D-predicate or in a toplevel query. A pref\u00aderence logic program is a triple \nof the form (Tc, TO, A) where TG is made up of the definition of the e-predicates, To con\u00adsists of the \ndefinitions of the O-predicates and D-predicates, and A consists of the arbiter clauses in the program. \n 3.2 Programming Paradigms We now present representative examples of optimization and relaxation in PLP. \nWe first present an example of dynamzc programming, followed by an example of a greedy heuris\u00adtic. We \nthen consider a preference grammar, which illus\u00adtrates the use of arbiter clauses for ambiguity resolution. \nWe also show how the use of weighted constraints and com\u00adparat ors for constraint, relaxation in HCLP \ncan be expressed in PLP, and finally illustrate preference relaxation (or re\u00adlaxation goals) with an \nexample from scheduling and the nt .shortespathth problem. Dynamic Programming: The program below is \na dynamic-programming formulation of the shortest-path prob\u00adlem. sh-dist(X, X, N,O) . sh.dist(X, Y,l, \nC) -+ X <> Y I edge(X, Y, C). sh_dk.t(X, Y, N+l, Cl+C2) -N > 1, X <> Y [ sh-dist(X, Z,l, Cl), sh.dist(Z, \nY, N, C2). sh-dist(X,Y,N,Cl) ~ sh-dist(X,Y,N,C2) * C2< cl. (We show only the computation of the shortest \ndistance; the the associated path can be computed with the aid of an extra argument). This program explicitly \nexpresses the optimal sub-pro blernpropertyof a dynamic-programming al\u00adgorithm: each call tosh_dist uses \nonly theoptirnalsolutions to subsequent recursive calls on sh_dist. Thus pruning of suboptimal solutions \noccurs at each recursive call. In the previous fo~mulation of this problem (in section 1), domain knowledge, \nsuch as the monotonicity of +, would be nece\u00adsary to achieve a similar effect. This example also shows \nthe need for the guard: the conditions X <> Y and N > 1, X <> Y should be read as antecedents of the \nimplication. Heuristics: Preferences can also be used to formulate greedy algorithms, or heuristics, \nwhich are useful in obtain\u00ading acceptable solutions to combinatorially hard problems such as the traveling \nsalesman problem (TSP). Heuristics are used in these problems to make the search space poly\u00adnomial in \nsize, without completely compromising the quality of the solution. In many cases, it may be possible \nto specify such heuristics by comparing partial solutions and prefer\u00adring one partial solution over the \nother, as illustrated below for the nearest neighbor heuristic for TSP [14]. tsp(Tour,Cost) t\u00adget_vertices(V), \ntsp(V, [l,Tour,O,Cost).  tsp([],T,T,C,C). tsp([HIT], [],Tour,Cin,Cout) \u00adtsp(T, [H],Tour,Cin,Cout) . \ntsp(List, [CitylTour],T,Cin,Cout) * closest(City,List ,Next,Rest,Cost) , tsp(Rest, [Next ,CitylTourI,T \n,Cin+Cost,Cout) . closest (City,List,Next ,Rest,Cost) + select (L.ist,Next,Rest) , edge(City,Next,Cost). \n closest(A,_,-,-,Cl) < closest(A,_,_,_,C2) +-\u00adc1 > C2. Thetop-level predicate, tsp, computes the best \ntour and its cost, by making use of the optimization predicate, closest, which ~ncorpora,tes the nearest-neighbor \nheuristic. (The clef\u00ad initions of the predicates get-vertices, select, and edge are straightforward and \nhence omitted. ) ?reference Grammars: The concept of preference also provides a general means for specifying \nthe selection criteria for choosing among alternative solutions to a goal. A good useofthi scalability \nis ambiguity resolution which may be viewed as a form of optimization in programming language and natural \nlanguage grammars. We illustrate with a well-known example: ifstmt ::= if cond then stmtseq I if cond \nthen stmtseq eke stmtseq This grammar exhibits the famous dangling else ambi\u00adguity (the nonterminals \ncond and stmtseq have their usual definitions). Anatural waytoresolve thearnbiguit yistoex\u00adpress our \npreference that each else pairs up with the closest plevious unmatched then. The resulting solution, \nshownbe\u00adlow using dejinzte clause gramnzars (DCG) [19], is far more succinct than rewriting the grammar \nto avoid ambiguity: ifstmt(if(C,T)) ifstmt(if(C,T,E)) ifstmt(if(Cl,if(C2,T),E) -> --> strnts [if], [if], \neq(T), ) cond(C), [then], stmtseq(T) cond(C), [then], [elsel, stnrtseq(E). ~ . ifstmt(if (Cl,if(C2,T,E) \n)). The first two productions are the usual grammatical rules of adefinite clause grammar. The argument \nterms if(C, T) and -if(C, T,E) represent the constructed parse trees for the corresponding grammar rules. \nThe third clause is a gram\u00admatical arbiter clause, and it specifies in a modular and cleclarative manner \nthe criterion that each else pairs up with the closest previous unpaired then. We refer to this extension \nof definite clause grammars as preference logic grammars (PLGs) [7]. There is a straightforward transla\u00adtion \nfrom PLGs into PLPs; thescherneis analogous to that from DCGS into definite clause programs. Since the \ntwo DCGrules have a common prefix, namely, [if], cond(C), [then], strntseq(T),it should be possible to \nobtain aneffi\u00adcient parsing scheme (e.g., using memorization) for efficiently performing the disambiguation. \nConstraint Relaxation: We show how constraint relaxation in HCLP [24] can be simulated in PLP. A con\u00adstraint \nc is a relation over an appropriate domain, and ala\u00adbeled constraint 1 cis a constraint c with strength \n1, where the strengths of constraints are taken from a totally-ordered domain. A constraint hierarchy \nHisafinite collection ofla\u00adbeled constraints, The constraints in H can be partitioned according to their \nstrengths. If H, is the collections of con\u00adstraints with strength i, we write H = (Ho, H1, . . .. Hn). \nwhere Ho is the set of required constraints in the constraint hierarchy. A HCLP scheme is parametrized \nboth by the domain of the constraints and the comparator to be used in determining the optimal answer. \nWe can systematically translate a HCLP program into a PLP program. Essen\u00adtially, the albiter clauses \nof the PLP program enforce the same ordering among the solutions that the comparator in the HCLP program \nenforces. Therefore, in PLP the com\u00adparator can be programmed to suit the application. The translation \nschemeissimilar to the translation from definite clause grammars to definite clause programs. For example, \nconsider the following HCLP program adapted from [24]: b(X) a(X), weakX > 6. a(X) t--strong X = 1. a(X) \nF required X > 0, required X < 10, X<4. In accordance with the operational semantics of HCLP [24], given \natop-levelq ueryq)t hetranslatedP LPProgram collects all relaxable constraints arising from q into a \nlist, and processes them after all required constraints arising from g have been satisfied. For example, \nthe above HCLP program is translated as follows: b(X, [weak X>6 !1],0) -a(X, I,O). a(X, [strong X = \n1 I 01,0). a(X, [required X > 0, requi,red X < 10, weak X<4 I 0] ,0). Given aHCLP query g(f), the translated \nquery would be: q(i, L,[]), hclp(L, Ervor-Sey), The definition of the predicate help is independent \nof the HCLP program to be translated, and depends only on the parameters of the scheme, in particular, \nthe comparator be\u00ading used. hclp(L, Er-rorSeq) + cornpute-error( L, ErrorSeq). hclp(L,ErrorSeql )< hclp(L, \nErrorSeq2) -ErrorSeq2 <ErrorSeq~. The help predicate computes an error-sequence for the relaxable constraints. \nThe specific comparator used in the HCLPscheme is incorporated in the definition of thepred\u00adicate compute-error. \nThe Z h entry in the sequence is the aggregate error for the relaxable constraints at the Lth level of \nthe hierarchy. The error measures how well the relax\u00ad able constraints satisfy a particular solution \nto the required constraints. The comparison of two error-sequences is done lexicographically. Preference \nRelaxation: In many scheduling prob\u00ad lems, reassociate costs with schedules andwe are interested in schedules \nwith the least cost. For instance, suppose we wanted to schedule m jobs to n processors and we are in\u00ad \nterested in minimizing the time taken to finish all the jobs. Such problems can be expressed in the PLP \nframework as follows. 13elow, NO, Nl, and N2arenodes that contain sched\u00adules; P is a processor; S, S1, \nand S2 are schedules; and T is a task. opt-schedule(S) + schedule(S). optschedule(S2) ~ opt.schedule(Sl) \n\u00adsamejobs(Sl,S2), lesscost(Sl,S2). schedule(S) t initial(N), schedule(N,S). schedule(N,N) ~ alltasksdone(N). \nschedule(N0,N2) v step(NO,Ni), schedule(Nl,N2). The toplevel predicate isopt_schedule (S). Thesteppredi\u00adcatetakes \naschedule in node NO as input and produces anew schedule in node N1 after selecting and scheduling a \npartic\u00adular task to a processor. The definitions of step, initial, alltasksdone, samejobs, and lesscost \nare omittedas their intended meanings should be clear in this example. In such a scenario, it is natural \nto subject, the optimal schedule to additional requirements wtthout explicitly changing the clef\u00adinttton \nof opt.schedule, i.e., we seek a modular solution to the problem. For instance, if some processor (say \npl~ fails, we would then want the best schedule that does not involve this processor. This requirement \ncan be expressed by a relaxation goal such as RELAX opt_schedule(S) WRT free(pl,S), where we define \nfree(P,S) to be true if in schedule S, no job has been assigned to processor P. Our second example illustrates \nuse of a relaxation goal in the body of a, clause to compute the path with the ntb-lowest cost between \nany two nodes in a graph: n.sh_path(l,X,Y,C,P) * sh.path(X,Y,C,P). n-sh-path(N+l,X,Y,C,P) -n_sh_path(N,X,Y,D,-), \nRELAX sh-path(X,Y,C,P) WRT C > D. Given aquery, ?-n.sh_path(2,a,b,C,P), the computed an\u00adswer for C will \nbe the second-lowest cost between a and b. The only relaxation goal that is called is: RELAX sh-path(i,a,b,C,P) \nWRT C > CO, where CO is already the cost of the shortest path between a and b. The above program gives \na modular and declarative specification of the problem. It might appear at first that the above program \nincurs slot of recomputation because of repeated calls tothesh.path predicate. However, by making use \nof memorization or an equivalent method, we can avoid this potential problem. 4 Declarative Semantics \nWe first review the model theory of simple preference logic prograrns(without relaxation goals in bodies \nof clauses) [8], and then extend it to preference logic programs with relax\u00adation goals in the bodies \nof clauses. 4.1 Model Theory of Optimization Preference logic programs are viewed as theories in the \nmodal logic of preference [17], and hence the model theory for pref\u00aderence logic programs uses ideas \nfrom modal logic. We pro\u00advide a possible world semantics for preference logic programs where each world \nis amodel for the program and an ordering among the worlds is enforced by the arbiter clauses. We thereview \nof thernodel theory starting with a brief introduction to the modal logic of preference [17]. The syn\u00adtax \nof this logic extends the syntax of first-order logic by adding a new modal operator Pf with the associated \nrule of formation: If F is a formula then so is PjF. We treat each dejinite preference clause p(f) ~ \nT(Z) + Ll,..., L~ in a preference logic program as a formula p(i)- Pj(p(ri) A LI A . . . A Ln) Inthetraditiou \nofrnodallogic, [17] provides apossibleworkls semantics for this logic. A preference frame Fis an or\u00addered \npair of the form (W, a), where W is anon-empty set of possible worlds and < is a binary relation over \nW. A preference model M ~ a preference frame Yaloug with a valuation function V that determines the truth \nof atoInic formulae at individual worlds. The semantics of preference formulae of the form PfF is given \nas follows:z *fiPfF iff (Vo EW)[(~~F)-(t. ~v)]. Informally, PfF is true in a world w in a, preference \nmodel iff every world v where F is true is related to w by the relation w s v. If PfF is true at a world \nw then F is said to be aprejerence crlterionat world w. In other words, any world u where F is true is \nat least as good as w. A preference model M is said to be supported if, for any two 2We write I=fi G \nto mdlcate that the formula G IS asmgned the truth value true atthe world w In the preference model M \nworlds u, and v, if u) ~ v then there is a formula PfA such that I=fi PfA and +~ A. A supported preference \nmodel is also the preference model that minimizes the relation +. Given apreference model M = (W, ~, \nV), a world w: W_&#38; said to be strongly optimalif thereis no world w different from 7L, such that \nw ~ w .  4.2 Models for Preference Logic Programs We build models for preference logic programs in \nstages. We assign ordinal levels to the O-precZzcates in the program such that, if an O-predicate Oz \nappears in the body of a clause defining another O-predicate 01, the ordinal assigned t,o 02 is less \nthan the ordinal assigned to 013. Suppose the number of levels of O-predicates in the program is n, and \nthey are numbered 1, . . . . n. The model is constructed in n stages as follows: 1. The O-predicates \nat level 1 are defined only in terms of C-predicates (or other O-predicates at level 1 in a mutually \nrecursive mannerj. Since the C-predicates are defined using only definite clauses, they have a unique \nminimal model. Each world in the preference moclel at level 1 extends the minimal model of the L \u00adyi-eclicates \nwith instances of O-predicates at level 1 so that it becomes a model for the clauses defining the O-predmztes \nat level 1 in the program. The ordering among these worlds is enforced by the arbiter clauses over O-predicates \nat level 1. The intended prefer\u00adence model at level 1 contains all the possible worlds that can model \nthe clauses defining the O-predicates at level 1. The set of preferential consequences of the program \nat level 1 is the set of atoms that are true in some strongly optimal world in the preference model at \nlevel 1. -. The worlds in the preference model at level k + 1 ex\u00ad tend the set of preferential consequences \nof the pref\u00ad erence model at, level k with instances of O-pred~cates at level k + 1 so that each world \nbecomes a model for the clauses defining the O-predicates at level k + 1. The intended preference model \nat level k + 1 con\u00ad tains all those worlds that model the clauses defining the O-predicates at level \nk + 1. The ordering among the worlds is enforced by the arbiter clauses for the O-predicates at level \nk + 1. The reader is referred to [8] for examples and a more de\u00adtailed description of the model theory. \nGiven a preference logic program P with n levels of O-predicates, the intended preference model of P \nis the intended preference model at level n. Given a preference logic program P with n levels of (1-predicates \nwhose Herbrand Base4 is BP and an atom A c Bp, we say that A is a preferential consequence of the program \n(written P ~ A) if A is a preferential consequence of the preference model at level n. The declarative \nse\u00admantics, Dp, is defined to be the set {A c BP I P &#38; A}. Given a preference logic program P and \na goal G, a valu\u00adation d is said to be a correct optimal valuation for P and G if GO is a preferential \nconsequence of P. 3\\Ve can construct the predicate call graph among the O-predicates and topologlcally \nsort lt .411 the prechcates m a cycle get assigned the same ordinal 41n the presence of constraints, \nthis refers to the generahzed Her\u00ad bra,,cl Base [12] In the above approach, the worlds constructed at \ndiffer\u00adent levels are different. This enables us to obtain the opti\u00admal solutions at one level without \nregard to the orderings enforced by arbiter clauses at higher levels. If we main\u00adtained one set of worlds \nfor all levels as in [2], the orderings enforced by arbiter clauses at one level might conflict with \nthose at a lower level, thereby disallowing optimal solutions to O-predicates at the lower level. Furthermore, \nthe stage\u00adwise model construction captures the notion of hierarchic] optimization because only the optimal \nsolutions at level k contribute to the solutions at level k + 1. 4.3 Model Theory of Relaxation We first \ndevelop to preference logic goals in bodies ory to programs clauses too. the model programs of clauses. \nthat have theory for the relaxation that, do not have any We then extend the relaxation goals in the \nqueries relaxation model the\u00adbodies of  4.3.1 Relaxation Queries We begin with the following plausible \ndefinition for a correct valuation of a relaxation query. Definition 1 Given a preference logzc program \nP and a re\u00adlaxation query G such that the set of correct valuat~ons to G LS empty, 8 is said to be a \nnaive relaxed correct valua\u00adtion if there zs a world w zn the intended preference model for P such that \nw ~ CW and v3w 3 ((w + GO ) A (w ~ w ) A (0 # 0 }). Intuitivelyj @ is a nazve relaxed correct valuation \nto a relax\u00adable query G, if there is a world w where Go occurs and there is no better world w than w \nwhere there is an occur\u00adrence of Gtl for some substitution b different from 0. This definition of relaxation, \nthough intuitively appealing, suffers from a pathological problem as illustrated by the following proposition. \nProposition 4.1 Gzven a preference logic program P and a relaxation query G = RELAX p(t~ WRT C(Z) such \nthat the set of correct optzmalvaluattons to p(~ A C(Z) wzth respect to P zs empty, and there are at \nleast two solutzons for p(o that sattsfy C( u). Then the set of naive relaxed correct valuatz. ns to \nG wzth respect to P w also empty. Proof Sketch: Suppose 81 is the optimal solution of p(~); clearly, \n01 does not satisfy c(u,). Suppose further that 62 and 93 are two nomoptimal solutions for p( ~ that \nsatisfy c(U). Assume without loss of generality that .91 is the solution that pruned both of them. Since \np is defined using an optimiza\u00adtion ( -) clause, there are worlds in the intended preference model that \ncontain the following instances of p(~: 1. w, ~ {p(i)o, , p(~#2}. 2. w~ ~ {p(f)@l , p(q6 3}. The solution \n62 is not a relaxed correct valuation because in world UQ which is better than any WO1M wit h the th \ninstance-the only solution to the relaxable query is L93. By similar reasoning, $3 is also not a relaxed \ncorrect valuation. Furthermore, notice that this argument would hold irrespec\u00adtive of the number of substitutions \nt), such that both p(~d, and C( ii)O, are satisfiable. In order to obtain a satisfactory definition, \nwe need to re\u00admove the worlds that have instances of the O-predicate that are not solutions of the C-predicate. \n Definition z .4 preference frame F1 is sad to be a sub\u00adfranle OJ a preference frame Fz if the set of \nworlds zn F1 w <I subset of the set o,f worlds in F2 and the relation among the worlds among the worlds \nin FI is a restr~ctzon of the relntzon among the worlds ~n FI to the worlds m FI. Definition 3 Gtuen \na preference logic program P and a re\u00adkwulde query G= RELAXp(~ WRT c(z), the relaxecl pref\u00aderence nloclel \nfor P and G is a sub-frame M, of the in\u00ad tended jJreference modelM for P such that M, contains all the \nWOVICIS in M such that the only instances ofp(t) that appear ZII each (oorla correspond to valuat~ons \nthat satisfy c(u). Theorenl 1 Given aprejerence logic program P and a re\u00adlaxation query G, the relaxed \nintended preference modeiex\u00adists and is unique. Proof Sketch: For any preference logic program P, its \nin\u00adtendecl preference moclel is unique [8]. The relaxed intended preference model is constructed from \nthe intended prefer\u00adence model. Since the C-predicatein the relaxation goal is interpreted uniformly \nacross the worlds, the set of worlds in the relaxed intended preference model is well defined. For example, \nconsider the shortest path program from sec\u00adtionland the relaxation query?-RELAX sh-path(a, b, C,P) WRT \nnotinpath(c, P). The worlds in the relaxed intended mode] will contain only those instances of sh-path \n(a ,b, C ,P) such that notinpath(c, P) is also true. The instances of sh-path(a, b, C,P) that are true \nin strongly optimal worlds in the relaxed preference model will correspond to shortest paths between \na andb that do not pass through c. 4.3.2 Programs with Relaxation Goals We now extend the model theory \npresented above to pro\u00adgrams where relaxation goals occur in the bodies of clauses. The difficulty in \nproviding a model theory for preference logic programs with relaxation goals in the bodies is that each \ntnstance of the clause with a relaxation goal in the body might, need to consult a different relaxed \npreference model to ascertain the truth of the relaxation goal. As before, we assign ordinal levels to \nthe O-predicates and D-predicates in the program and construct the model in stages. Let us assume that \nany O-predicate 01 that appears in a relaxation goal in the body of a clause defining an O\u00ad~Jredwate \nOz is such that the level of 01 is less than the level than that of 02. The semantics presented here \ncan be easily extendecl to the case when the O-predicate that appears in a relaxation goal is at the \nsame level as the O-predicate at the head. However, if a D-predicate (or an O-predicate) is de\u00adfined \nm terms of a relaxation goal containing an O-predicate of level n, it is assigned a level that is at \nleast n + 1. 31e O\u00adpredicates at level 1 do not have any relaxation goals in the bodies of clauses defining \nthem. Therefore the semantics at level I is the same as before, i.e., each world is constructed by extending \nthe least model for the core predicates with instances of the O-predicates and D-predicates so that it \nbe\u00adcomes a model for the definitions of the predicates at level 1 in the program. Given a preference \nlogic program P without relaxation goals in bodies of clauses, but with only one level of O\u00adpredzcates, \nand a relaxation query G = RELAX P(9 WRT c(ti], the relaxed preference mode] for P and G is a sub\u00adframe \nM, of the intended preference model 3( for P such that M,. contains all the worlds in M such that the \nonly instances of p(f) that appear in each world are those for which the corresponding instances of C(U) \nare also present (if c is a constraint, the instances of p(f) should correspond to valuations such that \nC(Z) is satisfiable). The set of atonls that are true in some strongly optimal world in the relaxed preference \nmodel of a program P and a relaxation query G ale the relaxed consequences of P and G . The O-prediccdes \nand D-predicates at higher levels may be defined in terms of relaxation goals. In geuerai, the re\u00adlaxed \nconsequences of a program (with relaxation goals in the bodies of clauses) and a relaxation query with \nan O\u00adpreclicate at any level can be defined once the intended pref\u00aderence model at that level has been \ndefined. We define the intended preference model at a level by defining the worlds and showing how the \narbiter orders the worlcls. Once the iutendecl preference model at level k has been defined, we can determine \nthe various relaxed preference models with respect to relaxation goals whose O-predicates are of level \nk. IVhen constructing the intencled model at level k + 1, the relaxed preference models of relaxation \nqueries up to level k are used to define the worlds at level k+ 1. We now illustrate the above process \nby describing the semantics at level 2 in greater detail. For defining the preference model at level \n2, we need to know the relaxed consequences for O.predicates whose level is at most 1. Since the clauses \ndefining ~redi\u00ad ., . cates at level 1 cannot have any relaxation goals in the body, we can determine \nthe relaxed preference models as outlined in the previous paragraph. In order to keep track of the relaxation \ngoals that may be used in the definitions of D-and O-predicates at level 2, the structure of each world \nin the preference model at level 2 is a pair (S, R.) where S is a subset of the base of the programs \nand R is an indexed set of sets, where each member of R is a set, denoted as R(P(r),C(ti)), where (P(~j, \nc(Z)) is the index, p is an O-predicate at level 1, and c is a C-predzcate (or a constraint as in CILP \n). The set S is an extension of the set of preferential consequences at level 1 of the program P. A set \nI?(P( ~),.~ ~)) belongs to R if p(i) is an instance (not necessarily ground) of an O-predicate (at level \n1) and c(ii) is an instance of a C-predicate (or a constraint, as in CLP)6 and R(r( t),ctti)) is the \nset of instances of p(f) that are relaxed consequences of P and the relaxation query RELAX p(fi WRT C( \nii,), Definition 4 Suppose q is an O-predicate in the program (at level 2) defined by a clause (w~th \nm ordinary and n re\u00ad laxation goals) of the form: A world w = (S, R) M sazd to satisfy such a clause \nif the followtng holds: For every ground instance q(~)~ (where 0 is a valuation that satisfies dl(til \n), . . . . dl(tit )) of the head to belong to S, if q(Z)O belongs to S, then there exzst II, , 1 =1... \nmandul, ~= l... n such that the conjunction ~%pb(Fc)8vL A Al rj (U3 )OuJ is satisfiable, i.e., ,for all \nj, J Zs a valuation such that rJ (VJ)6UJ belows to the set in R Based on the pre-mterpretatlon that Interprets \nthe constraint symbols, rather than the Herhrand pre-mterpretat]on, 61t should be noted that the semantics \npresented here M power\u00adful enough to capture the meaning of programs where the relaxation crlterlon M \nan O-vredtcate that IS at a lower level than the relaxable pred]cate We h;ve, however, not discussed \nsuch programs in this paper indexed by (r] (vj )19, Cl(ii] )$), and, for all i, q, is a valuation such \nthat p,(~, )$q, is a member of S. Definition 5 Suppose q M an D-predicate in the program (at level 2) \ndefined by a clause (wzth m ordtnary and n re\u00adlaxation goals) of the form: q(~) *pl(:tl),RELAXrl(til) \nWRT CI(Z1),. ... p,,,(~~),RELAX r~(fi~) WRT c~(ti~). A world w = (S, R) is satd to satisfy such a clause \nif the followzng holds: For every ground instance q(i)$j q(I)O be\u00ad lon~s to S Zf there exist valuations \nv,, a = 1 . . . m and u], j = I . . . IL stdch .t}tat the con~unction ~,p%(%,)$~, A ~, r,(tij)$aj is \nsatzsfiablel where, for all] ~1 is a valua\u00ad tlon such that r] (VJ)8C3 belongs to the set in R indexed \nby (rj(fij)(i, C,(.ii,)t))j and, for all k, I), is a valuatzon such that p,(~t)d?l, M a member of S. \nThe valuations must be consistent in that if a variable oc\u00adcurs in two clifferent goals in the body of \nthe clause, the corresponding valuations have to assign the same value to the variable. In other words, \nto determine whether a world (S, R) satisfies a clause, the truth of the ordinary goals in the body is \ndetermined by consulting the set S and the truth of the relaxation goals is determined by consulting \nthe set in R that is indexed by the relevant instance of the relaxation goal. The example later in the \nsection illust~ates that the instance r~ (ti~ )0 (or CJ(iiJ )0) is not necessarily ground. Definition \n6 The preference model at level 2 consists of all possible worlds (S, R) that satisfy the clauses definzng \npredicates at level 2 such that the relation among the worlds as supported by the arbiter. The ordering \namong the worlds as determined by the instances of O-predicates in the set S. Definition 7 The set of \npreferential consequences at level 2 M the set of atoms that are members of the set S zn some strongly \noptimal world (S, R) in the preference model atlel~el 2. Once the preference model at level 2 has been \ndetermined, the various relaxed preference models of the program with respect to relaxation queries with \nO-predicates of level 2 can also be determined. Essentially the relaxed models for P and a relaxation \ngoal G (whose O-predicate is of level 2) are sub-frames of the preference model at level 2 such that \nthe set S in each world contains onlv. those instances of the relaxable predicate of G such that corresponding \ninstances of the relaxation criterion of G are also present (satisfiable) in S. Now at level k, each \nworld has access to the relaxed con\u00adsequences of O-predicates of level at most k 1. Each world (S, Ii) \nin the preference model at level k is such that it satzs\u00adfies the clauses defining predicates at level \nk. If a preference logic program has n levels of predicate symbols, the relaxed intendecl preference \nmodel is the preference model at level n as described above. For example, consider the n-sh.path program \nwith the edges {edge (a, b,5) , edge(b, c,lO) , edge(a, c,25)}. The set of preferential consequences \nat level 1 is: {edge (a, b,5), edge(b, c,l O), edge(a, c,25)} U {path(a,b,5, [e(a,b)]), path(b, c,lO, \n[e(b, c)]), path(a, c,25, [e(a, c)]), path(a, c,i5, [e(b, c), e(a,b)])} U {sh-path(a,b,5, [e(a,b)]), \nsh.path(b, c,lO, [e(b, c)]), sh-path(a, c,15, [e(a, b) ,e(b, c)l)} Since there are no O-predzcatesat \nlevel 2, there is only one world (S, R) in the intended preference model at level 2. The set of instances \nof n-sh-path that are present in S are: { n-sh-path(l, a, b,5, [e(a,b)]), n-sh-path(l,b,c, 10, [e(b,c)] \n), n-sh-path(l,a,c, 15, [e(a,b) ,e(b,c)]), n_sh.path(2,a,c,25, [e(a,c)] )} Notice thatforthe instance \nn.sh_path(2 ,a,c,25, [e(a,c)] ) to be present, we need to determine the truth of the the re\u00adlaxable goal \nRELAX sh-path(a,c,C,P) WRT C > 15. In the corresponding relaxed intended preference model, the only optimal \nvaluation for sh-path(a,c,C,P) is C = 25, P = [e(a,c)]. Thesetinllindexed by (sh_path(a,c,C,P), C > 15 \n)is{sh_path(a,c,25, [e(a,c)] )}. Definition Gzvenapreference logzcprogram P, aground aton~A M satd to \nbe arelaxed preferential consequence of P (written P ~ A) zf A belongs to the set S tn some strongly \noptimal world (S, R) ~n themtendedprejerence model of P. Theorem 2 Foranypreference logic program P \nwzth relax\u00adable goals zn the body, the relaxed intended preference model exzsts and IS unkque. The proof \nis similar to the case for preference logic programs without relaxation goals [17, 8]. 5 Operational \nSemantics After briefly reviewing the operational semantics of prefer\u00adence logic programs without relaxation \ngoals [8], we present an extension of the operational semantics for programs with relaxation goals in \nthe bodies of clauses. 5.1 Operational Semarrtics of Optimization We now briefly review a derivation \nschernecalled PTSLD\u00adderivation, which stands for Pruned Tree SLD-derivation, for efficiently computing \nthe optimal valuattonsto queries p~esented in [8]. Below we assume that the program con\u00adsists of definite \nand optimization clauses without constraints in the sense of [10, 11]; we subsequently describe how this \nscheme can be extended to the case where the program com tains constraints as goals in bodies of clauses. \n 5.1.1 l? TSLD-Derivations Let P be a definite clause program and G a positive goal. A partial SLD-tree \nfor Pu {G}, is a finite SLD-tree, not all of whose branches are successful or failed derivations of Pu \n{G}. Because every edge inthe SLD-tree is labeled by a substitution, we associate with each node in the \nSLD-tree a substitution which is the composition of the substitutions found on the path from the node \nto the root of the tree. Definition Given two partial SLD-trees TI cmd Tz jor Pu{G}, we define TI + \nTz to mean that Tz is derived from Tl by choosing a non-empty leaf 1 =+ Al,.. ., An,, . . . . Ah o,f \nT1 , Am bezng the selected goal, and creating chddren of 1 o,f the form: (A, ,..., A,,, B,,,, Bq, Arn+,,n,Ak)$., \nAk)$ for every clause A +-BI, .,., B, in P such that 0 M the most general unifier of Am and A, The leaf \n1 is said to be expanded in TI to get T2. Let P be a definite clause program and G be a goal. A Tree \nSLD-derivation (TSLD deraoation) of P u {G} is a finite or tnflnite sequence To = {i, TI, of partial \nSLD-trees for P U {G} such that for all i, TL + T,+l. Given a Preference Logic Program P = (7c, To, A), \nand a cluery C;, a, TSLD derivation for P U {G} is an TSLD\u00adderivation for Tc-A TO. 11 hen the head of \nthe selected goal in the node to be expanded is an O-predzcate p, we assume that every ground instance \nof an O-predzcate is supported by at most one _ clause. This restriction only simplifies the description \nof the operational semantics and the proofs; otherwise, if instance of an O-predicate unifies with the \nheads of multiple -clauses, then it is a candidate for the optimal answer only if the appropriate instances \nof the bodies of each of the clauses succeed. Since the variables that appear only on the right hand \nsides of clauses are existentially quantified, and in view of the above restriction, we can treat the \n clause exactly as we would treat a P clause for the purpose of creating the children of a node. Furthermore, \nin order to achieve sounclness, an O-predicate p must be invoked with unbound variables at those argument \npositions where the pair of in\u00adstances of p in any arbiter clause differ. This requirement is needed \nbecause the values at these positions are computed by the body of the optimization clause and made use \nof by the arbiter to prefer one solution over another. If this requirement is not met at run-time, we \nsimply replace the argument to the goal instance of p being considered by an unbound variable for the \npurpose of solving for p, and we enforce the original binding at this argument position by back unification. \nDefinition 10 Given a partzal SLD-tree T for P U {G}, a node nl =-Al, ..., A, in T is said to be pruned \nif there exz.sts a node n~ = B1 , . . . . Bk and an internat node n =-Dl, . . .. D.~, ..., Dn, such that \nnl and nz are descendants of IL, where Dn. is p t)where p is an O-predicate, and zs sub~ ect to an arbiter \nof ~~e form. p(ti) < p(fi)+L1, . . ..Ln In addition t+ and 02 are the substitutions associated with \nnodes nl and n2 such that p(~OI is an instance of p(d), p(~tt2 is an instance of p(iil ) and the following \nconstraint is satisfiable: {p(i)@, = P(ti) , p(7)&#38; = p(z)} U U,{ L#Itl Z} The substitution Oz as \nsaid to be better than $1. Definition 11 Given a preference log~c program P, a Prunecl TSLD-derivation \n(F TSLIl-derivation) is a TSLD-derivation irk whzch, at each step, the leaf to be expanded as not a cle\u00adscenda,nt \nof a prwned nocle. A tree occuring in a PTSLD derivation is said to be com\u00adplete if all its paths are \neither successful, failed or pruned. A PTSLD-derivation To, . . . . T, is complete if it ends in a complete \ntree. T, is said to be the result of the complete PTSLD-derivation. Definition 12 Given a program P and \na goal G, 0 is said to be a correct optimal answer to G wtth respect to P, ~f P ~ GO. Gzven P and a complete \nPTSLD-dertvatton ,for P U {G} with result T., let @ = {6114 is the composition o,f the swb.stztutions \nalong a successful path in T. restricted to the vc{r~ab/es zn G}. El is sa~d to be the set of computed \noptimal answers to the query G with respect to the program P. We wrzte P ~ Gd zf0 c6. Theorem 3 (Soundness) \nGiven a preference logic program P cmd a goal G, suppose $ zs a computed optimal answer for G wzth respect \nto P, then 0 u a correct optimal answer to G wdh respect to P. Proof Sketch: By induction on the levels \nof the PTLSD search tree and the soundness and completeness of SLD\u00adclerivations for definite clauses \n[15]. All the solutions to O\u00adpredicates are considered as the ~ clauses are interpreted exactly as the \n clauses by the operational semantics. Since O-predicates have to be sufficiently uninstantiated when \nin\u00advoked, we can show that the pruning is sound. Given a preference logic program P, a goal G, and a \ncor\u00adrect optimal answer 9 of G with respect to P, we say that the operational semantics is complete if \nthere exists a computed optimal answer q and a substitution -y such that .9 = q~. However, PTSLD derivations \nare not complete for arbitrary preference logic programs. Incompleteness can arise because the PTSLD \nderivation for some goal cannot be completed, and this can happen when the PTSLD search tree emanat\u00ading \nfrom an optimization goal is infinite but there is a well\u00addefiued correct optimal answer to the goal. \n 5.1.2 Stratified Preference Logic Programs It turns out that even when the PTSLD search tree is finite, \nincompleteness can arise because the optimization predi\u00adcates are not stratified. A preference logic \nprogram P is said to be stratified if the following holds: There is a map\u00adping ~ from the set of O-predicates \nto the set {1, . . . . n}, for some least n, such that if an instance of an O-predicate PI appears in \nthe body of a ~ clause defining an O-predtcate JQZ, then f(l 1) < ~(p..). For any O-predzcate P, its \nrank is defined to be f(P). Stratified preference logic programs presented above are restrictive in that \nthey do not allow recursive definitions of O-predicates. However, there are many programs, such as the \ndynamic programming formulation of shortest, path, that need recursive definitions of O-predicates. Hence \nwe are interested in locally stratified programs, described below. Definition 13 A preference logic progrclm \nP is said to be locally stratified if the following two conditions hold: There is a mappzng f from the \nset of O-predicates to {1, . . . . n} for the least n such that zf an instance of an O-predicate P1 appears \nin the body of a -clause defining an O-predicate P2, then f (Pl ) < f (P2 ). There M a well-founded ordertng \n+k over the set of ground znstunces of all O-predicates of rank k, defined as follows: (i) ground tnstances \nof base facts of O\u00ad predkcates of rank k all map to the 1 of the order?ng +~: and (ZZ) ground znstances \nof optzmtzatton clauses hale the property that each instance of an O-pred~cate of rank k that appears \nin the body is +~ the instance o,f the O-predtcate of rank k that appears in the head. Note that in defining \n<k we consider only those argument positions of a ground instance that are not used by the ar\u00adbiter clauses \nto prefer one solution over another. Theorem 4 PTSLD derlwcttions are complete for locally strati\u00adfied \npreference logic programs with finite search trees. Proof Sketch: By induction on the rank of O-predicates, \nthe ordering <k defined on the ground instances of O-predicates of each rank and soundness and completeness \nof SLD-resolution. Y\\Te no~v briefly describe the operational semantics when the first-order theory \nis a constraint logic program. The main difference from the definite clause case is that each node in \nthe tree is not labeled by a single substitution but by a set of constraints. Pruning is accomplished \nby adding constraints to the node that rule out the pruned solution. Since the set of constraints associated \nwith a node can have multiple solutions, it is possible that one solution to the set of constraints prunes \nanother solution. Definition 14 Gtven a CLP program P, a goal G and two purhal SLD-trees TI and T2 for \nP U {G}, we define T1 + T2 tomean that T2 is derived from T1 by choosing a non-empty kflf /=({ Al,.. \n., A,n, Ak}, {Cj})Cj}) of T1 , choosing a goal Am (whose head is a C-predtcate or ct D-predicate,), a \nclause A ~ C;, ....c;, Bl, ....Bq in P, and creating chitdren of 1 of the form: ({ Al, . . .. A.l,Bl,l, \nBq, A~+l,~+l, . . .. Ah}. {CJ}U{C}U {c:}) z.f {c~} u {C} U {cl} is soivable7j where {C} is the set of \nconstraints generated bg the equation Am = A, and the C~s tn the body of the clause are constraints. \nThe leaf 1 as sazd to be expanded in T1 to get T2. De firlition 15 Gtven a lJartial SLD-tree T for P \nU {G}, a nodenl =({ Al, . . .. AJ}. {C~, }), arsodenz =({ f?l, . . .. Bk}. {C,,,}) and an znternal node \nn = ({Dl, . . . ,Dm,. ,Dn, }, {Cn]], such that n, and n, are descendants of n, where Dm w p(t)where p \nM an O-predicate, and is subject to an ar\u00adbiter of the form: p(z) ~ p(~) ---LI, ., ., Ln. In addition \nsuppose the constraint {p(i) = p(z)} u {p(~) = p(?@} u~,{L,} U {Cn, } U {Cn, ) zs satzsj$abie by the \nsubstitution q such that the projection (?1 Of v to the var~a~les in {cn~ } zs such that P(~)-Y M an \ninstance o,fp(ii) and the projection to the variables tn {Cn, }, o, is such that p(F)a is an tnstance \nof p(~). We then update the constraint set {C~l } of node nl to {C,., ) U {~-j}, where {-Iy} is a constraint \nthat states that y M not a solution. The solution ~ is said to be pruned, and a node in the tree is sazd \nto be pruned zf all the solutions to the constraints of the node get pruned. 7\\Ve use {C}, {Cj}, etc \n, to stand for a set of constraints F n a variant of i obtained by renammg those argument positions of \ni where Z and al chffer with new vamables Each nocle m a SLD-tree in the CLP framework has a com straint \nassociated with it which may be satisfiable in more than one way. Therefore each node in the SLD-tree \nin the CLP framework abstracts a set of solutions. The addition of a constraint {m-y} blocks the solution \n-y. Note further that the nodes n I and nz in the definition need not be different nodes, i.e. one solution \nto the set of constraints may block another solution to the set of constraints. Using the two definitions \nabove, we can define PTSLD\u00adderivations for preference logic programs with constraints in the bodies in \na manner similar to PTSLD derivations for preference logic programs without constraints in bodies of \nclauses. Definition 16 Given a preference logic program P and a goal G, a computed optimal valuation \nto G wzth respect to P tsis a vuluatzon @ that satisfies the constraints at a successful node zn a tree \nT at the end of a PTSLD derzvatzon for P crnd G. We can also formulate soundness and completeness theorems \nin a manne~ similar to the definite clause case, Theorem 5 Given a preference logzc program P and u goal \nG, suppose $ M a computed optimal valuation for G wzth respect to P, then 0 is a correct optzmal answer \nto G wtth respect to P. The proof is similar to the definite clause case. Theorem 6 Given a stratified \npreference logic program P and a goal C; such that the PTSLD derivation emanatmg from P and G is finite, \nthen tf 8 M a correct optzmal answer to G wzth respect to P, then there is a successful node in the successful \nPTSLD tree that is satisfied by an valuat~on u such that there exasts a substitution q such that $ = \ncrq. The proof is similar to the clefinite clause case.   5.2 Operational Semantics of Relaxation We \nnow present an extension of PTSLD-derivations to con~\u00adpute the relaxed correct optimal valuations to \nqueries. Definition 17 Gkuen a preference logic program P and a relaxation query G = RELAX p(t>WRT c(u), \nthe function relwr(p(i), c(z)) returns the set of relaxed clauses for p iy tncluding, for every clause \np(i) p~(~~), . . . ,p,, (,tn] for p, the followzng pair of clauses: 1. reluz-p-cv(z) --+ Z = t I pI(ZI)i \n. . . ,pn(in), c(ii) 2. relux_p_ca(%) -Z #i I p,(Tl),... )p(En)n)  Furthermore, for every c,rbzter \nclause of p of the form p(fl ) 3 p(i2) LI, . . . . L,,, retax(p(i), c(i)) znclucles the followzng arbiter \nclauses: relax -p~-cn(~$l) ~ relaz-p~.cz(% z) - Llalcmj. . . ,J5,1U11T2, C(W1), C(IW2), where @l and \nOZ are variable renamtng substitutions such that i81 and @2 do not share any common vari\u00ad ables. The \nsubstitutions al zs the most general unifier of ?I and fQI , and crz is the most genera! unljier of F2 \nand Ft+z. relax_pF_ca(Fl) s retax_pF_cQ(fz) Ll, . . . . L,l, (t # flv E#f2). 100 The relaxeci query \ncorresponding to G is relax.p(f). For example, given the query ?- RELAX sh_dj.st(a,b,C,p) WRT notinpath(c,p), \n re~u~(sh_dist(a,b, C, P), notinpath(c, P)) returns the follow\u00ading set of clauses: 1. relax_sh_dist( \na,bC,P)_noti npath(C,c)(X, y C,P) \u00ad(X, Y) = (a, b) 1 path(X,Y, ,C,P), not: npath(c,P) j, relax_sh-dist(a,b,~,Pl_notinpathLc,c~(X,y \nC,P) (X, Y)#(a, b) lpath(X,Y,C,P). .1. relax-sh-dist(a,b,~,p~notinpathtc,~)(a,b ,C1,P1) ~ relax-sh-dist(.,b,~,p)-notinpa \nthf.,~j(a,b ,C2,F 2) C2 < Cl, notinpath(c,Pl), notinpath(c,P2). 4. relax_sh_dist(G,b,C,p)notinpath(C,~~(X \n,Y,C1,P1) ~ relaxsh.dist(a,b,c,p)notlnpa thfc,c)(x ,y,C2,p2) -C2< Cl, (X, Y) # (a, b). The set relaz(p(t), \nc(ti)) introduces a new O-pred/cate rela. ~_pt_cti into the program, the clauses for which are ob\u00adtainecl \nfrom the clauses forp. Every clause forp that is ap\u00adplicable to p(aint herelaxation goal is modified \nby adding C(U) to the body; clauses for p that are not applicable to p(f) are not modified. If some instance \nof a clause for p is applicable to p(t~ then we obtain two clauses in the relaxed \\,ersion, one that \nis applicable to ~with the body containing c(z), and the other that isnot applicable toiwith thebody \nas before. The key difference between our presentation here and the presentation in ~] is the following. \nSince we now allow re\u00adlaxation goals to occur in the bodies of clauses, the relaxed version of the O-prechcafe \ngets a very specific name depend\u00ading on the exact arguments with which it is invoked. [9] did not allow \nrelaxation goals to occur in the bodies of clauses and therefore the operational semantics described \nthere did not rec[uire the name of the relaxed version of an O-predicate to beso specialized. FVeextend \nPTSLD-derivations by enabling them toang\u00adment the program when a relaxation goal is encountered. This \nis captured by presenting the derivation as a deriva\u00adtion of pairs of program and partial SLD-trees. \nDefinition 18 Aprograrn-tree pair lsapairof the form (C , T) where Cisacollection ofclauses and Tis apartial \nPTSLD-tree. Thepair(C,+l, T,+l) wclerived from thepazr (C,, T,), lfthe following holds: 1. If the selected \ngoal in the leaf to be e.rpandedin T, is not a relaxalde goal, C,+l = C% and T% + T,+l with respect to \nclauses in C %. >. ~ If the selected goal in the leaf to be erpanded in T, is a relaxable goal RELAX \np(~) WRT c(fi), C,+l = C; U relux(p(i), c(ti)), the relatable goal is replaced by relaz_pr_cU(t>, and \nT, + T,+l with respect to the clauses in C,+. I. Definition 19 Given a preference logic program P and \na qoalG , a relatable PTSLD-derivation 2s a sequence of pairs (P, G), (CI, TI), . . ..{ C., T,),... where \nC, is a set of clause. and T, is a partial PTSLD-tree and each (C,+l, T,+l ) is derived from (C,, T,). \nA relaxed PTSLD-derivation is said to be successful if there is a pair (C, T) at the derivation, where \nT is a successful PTSLD tree. Definition 20 Given a preference logtc program P and a goal G, a relaxed \ncomputed optinlal valuation to G with respect to P is is a valuation @ that satdsfies the con\u00adstraints \nat a successful node in T where (C, T) is a pair at the end of a relaxed PTSLD derivation ]. Lemuna 1 \nGiven a preference logic program P and a relax\u00ad ation goal G = RELAX p(t~ WRT c(z), p(t~@ is a rela~ed \nprefer\u00ad ential consequence of P and G, if and only af relaz_pF_cti(Qb is a relaxed preferential consequence \nof PU relaz(p(~, C( u,)). Proof Sketch: By induction on the levels of the O-predicates in the program \nP. For the base case the number of levels of O-predicates in the program is 1. Suppose there is an instance \nrelax _pF_cfi (1)8 in a world in the intended prefer\u00adence model for P U r-eluz(p(~), C( ii )). Clearly, \nthe instance p(~tl belongs to a world in the relaxed intended preference model of P and G as c(~)t) is \ntrue. Similarly, we can show that if an instance p(fja occurs in any world in the relaxed intended preference \nmodel of P and G, then the instance relax _yi_cti (t)a occurs in some world in the intended prefer\u00adence \nmodel of P U relrsx(p(t], c(z)). The arbiter clauses for relux_pi_cz enforce the same ordering when the \nsolutions to p satisfy C. Essentially the same argument works for the inductive case too. Theorem 7 (Soundness) \nIf P is a preference Jogic pro\u00adgram and G is a goal such that .$ is a relaxed computed op\u00ad timal valuation \nthen P ~ GO. Proof Sketch: The proof is by induction on the levels of the O-predicc~tes in the program. \nIt makes use of the lemma above for soundness of answers computed for relax\u00adation goals that appear in \nbodies of clauses. Lemma 2 Given a stratified preference iogic program P and a relaxation query G such \nthat the relaxecl PTSLD-derivation emanat~ng from P and G is finite, suppose GO is a relaxed preferential \nconsequence of P, then there is a successful nocle in the successful PTSLD tree at the end of the relaxed \nPT-SLD derivation such that 8 is a valuation that satzsfies the constraints at the node and furthermore, \n0 = 8 1) jor some substitution q. Proof Sketch: By induction on the level of the O-predicates in the \nprogram. For the base case: Suppose the relaxation query G was RELAX p(f) WRT c(ii). Furthermore, by \nour assumptions and PTSLD-derivations are complete for the program P and the cluery p(~ as there are \nno relaxation goals in bodies of clauses defining O-predicates. Therefore an answer at least as general \nas any correct optimal answer for the query p(F) is computed by the operational seman\u00adtics. Consider \nthe relaxed program P U relaz(p(f), C(Z)), the search tree emanating from c(ii) is finite (the original \nprogram was such that the operational semantics was com\u00adplete). Therefore, the operational semantics \nis capable of computing all the potential answers to rela.t.p; .cti( ~ and the arbiter prunes the sub-optimal \nanswers. Therefore if the operational semantics was complete for the original pro\u00adgram, it is complete \nfor the transformed program. Since the declarative semantics of the transformed program coincides with \nthe relaxed intended preference model as far as answers to the relaxable query ale concerned, we have \nour desired result. The inductive case is similar. 101 Theorem 8 (Conlpleteness) If P ZS cz stratzj$ed \nprefer-References ence logic program with selaxatton goals in bodzes of clauses ond C; is a goal such \nthat the relaxed PTSLD-derivation em\u00ad [1] anating from it w finite, then if O is a valuation such that \nG@ is a relaxed preferential consequence of P, then there is a successful node zn the PTSLD tree at the \nend of the PT- SLD derivation emanating from P and G such that 8 is a valuation that satisfies the constraints \nat the node and there ts a valuation Ij such that Q = tl q. [2] Proof Sketch: The proof is by induction \non the levels of the O-predtcatesin the program. It makes use of thelemrna above. [3] 6 Conclusions The \nconcept of preference provides a unifying approach to formulating problems requiring optimization and \nrelaxation. [4] In earlier work [8], we showed how optimization problems can be specified declaratively \nin the paradigm of preference logic programming. This paper extends our previous work @ showing how the \nparadigm can also capture the notion of relaxation. [5] Motivated by practical considerations, we introduced \nthe notion of preference relaxation in this paper. Essentially, given a query RELAX p(f) WRT c(ii), where \np is an O-predtcate and c is a C-predicate, we want the best answer for p that satisfies c. However, \nthe best answer for p on its own may [6] not satisfy c and we must consider sub-optimal answers for p \nto answer the cluery. We provided model theoretic and oper\u00ad ational semantics for such relaxations and \nwe introduced the notion of relaxed preferential consequence. The operational semantics consisted of \ni,ransforming the original program by [7] changing the clefinition of p. The changes to the ~ clauses \ndefining p ensure that PTSLD-derivations with respect to the resulting program are sound for computing \nrelaxed pref\u00ad erential consequences. The changes to the arbiter clauses [8] for p ensure that if PTSLD-derivations \nwere complete for the program to start with, they are also complete for the transformed program for computing \nrelaxed preferential con\u00ad sequences. [9] We are investigating conditions under which the opera\u00ad tloual \nsemantics for preference relaxation can be made more efficient. Given a relaxable goal RELAX p(f) WRT \nC(U), the operational semantics pushes C(V) into the definition of p so that the solutions to p(~ that \ndo not satisfy C(Z) do not [10] succeed. However, if p is defined recursively, we can try to gain better \nefficiency by pushing c(ti) into the recursive call, Intuitively, this is possible when the C-predicate \nin the re\u00ad [11] laxable query distributes over the structure that is passed to it. For example, the predicate \nnot inpath distributes over paths, because a node c is not in some path P in a graph [12] if and only \nif it is not in any sub-path of P. We cannot em force evenlength for every sub-path as there are even \nlength paths that are composed of paths of odd length. Therefore, a constraint such as evenlength does \nnot distribute over [13] paths. Jle programs with relaxation goals in bodies of clauses considered in \nthis paper can be termed stratified relaxation [14] programs as the level of the O-predicate present \nin a re\u00ad laxation goal in the body of a -clause had to be strictly lower than the level of the O-predicate \nat the head. We are investigating the semantics when we allow the level of the O-predicates in relaxation \ngoals in bodies of the -clauses [15] to be the same as the level of the O-predicate at the head. A. \nBrown, S. Mantha, and T. Wakayama. Logical Reconstruction of Constraint Relaxation Hierarchies in Logic \nProgramming. In Proc. of 7th Intl. Symp. on Methodologies for Intelligent Systems, LNAI 689, Trondheim \nNorway, 1993. A. Brown, S. Mantha, and T. Wakayama. Prefer\u00adence Logics: Towards a Unified Approach to \nNon-Monotonicity in Deductive Reasoning. Annuls of Afath\u00adematacs and .4rtificzal Intelligence, 10:233 \n280, 1994. F. Fages. On the Semantics of Optimization Predicates in CLP Languages. In Proc. 1.9th Conf. \non Foundations of Software Technology and Theoretical Computer Sci\u00adence, 1993. F. Fages, J. Fowler, and \nT. Sola. Handling Preferences in Constraint Logic Programming with Relational Op\u00adtimization. In Proc. \n6th Intl. Symposium PLILP 94, LNCS 844, 1994. S. Ganguly, S. Greco, and C. Zaniolo. Minimum and Maximum \nPredicates in Logic Programming. In Proc. 10th ACM Symp. on Principles of Database Systems, pages 154-163, \n1991. M. Gelfond and V. Lifschitz. The stable model seman\u00adtics for logic programming. In Robert A. Kowalski \nand Kenneth A. Bowen, editors, Proc. 5th ,Jo~nt Interna\u00adtional Conference and Symposzum on Logzc Progranz\u00adming, \npages 1081 1086, 1988. K. C+ovindarajan, B. Jayaraman, and S. Mantha. Pref\u00aderence Logic Grammars. Technical \nReport 94-27, Dept. of Computer Science, SUNY at Buffalo, 1994. K. Govindarajan, B. Jayaraman, and S. \nMantha. Pref\u00aderence Logic Programming. In Proc. 12th Intl, Conf. on Logic Programming, pages 731 745, \n1995. K. Goviudarajan, B. Jayaraman, and S. Ma,ntha. Re\u00adlaxation in Constraint Logic Languages. Technical \nRe\u00adport 95-22, Dept. of Computer Science, SIJNY at Buf\u00adfalo, 1995. J. Jaffar and J. L. Lassez. Constraint \nLogic Program\u00adming. In Proc. Idth A Chf Symp. on Principles of Pro\u00adgramming Languages, pages 111-119, \n1987. J. Jaffar and M. J. Maher. Constraint Logic Program\u00adming: A Survey. Journal of Logic Programming, \n1994. P. C. Kannelakis, G. M. Kuper, and P. Z. Revesz. Con\u00adstraint Query Languages. In Proc. ACM SYmp. \non Prznczples of Database Systems, pages 299-313, 1990. D. B. Kemp and P. J. Stuckey. Semantics of Logic \nPrograms with Aggregates. In Proc. International Log2c Programming Symposium, 1991. E. L. Lawler, J. \nK. Lenstra, A. H. G. R.innooy I<an, and D. B. Shmoys (eds. ). The Traveling Salesman Problem: a Guzded \nTour of Combinatorial Optimization. Wiley and Sons, Chichester, United Kingclorn, 1985. J. W. Lloyd. \nFoundations of Logic Programming. Springer-verlag, 1987. 102 [16] M. J. Maher and P. J. Stuckey. Expanding \nQuery Power in Constraint Logic Programming Languages, In E. L. Lnsk and R. A. Overbeek, editors, Proc. \nNorth Amer\u00ad~can Conference on Logic Progrcammingj pages 20 36, 19,39 [17] S. Mantha. First-Order Preference \nTheories and their Appltcutions. PhD thesis, University of Utah, Novem\u00adber 199]. [18] Ii. Marriott and \nP. J. Stuckey. Semantics of (30n\u00ad st,ra,int Logic Programs with Optimization. Letters on Programming \nLanguages and Systems, 2(1-4):181 196, 1993. [19] F. (2. N. Pereira and D. H. D. Warren. Definite Clause \nC+rammars for Language Analysis -A Survey of the For\u00admalism and a Comparison with Augmented Transition \nNetworks. Artificial Intell~gencej 13:231 -27 8, 1980. [ZU] K. A. Ross and Y. Sagiv. Monotonic Aggregation \nin De\u00adductive Databases. In Proc. ACM Symp. on Principles [If Database Systems, pages 114 126, 1992, \n[21] S. Sndarshan and R. Ramakrishnan. Aggregation and Relevance in Deductive Databases. In Proceedings \nof the International Conference on Verg Large Databases, 1991. [ ?] S. Sudarshan, D. Srivast ava, R. \nRamakrishnan, and (0. Beeri. Extending the Well-Founded and Valid Se\u00admantics for Aggregation. In Pro.. \nInternational Logic Programming Symposium, pages 590-608, 1993. [23] A. van Gelder, K. Ross, and J.S. \nSchlipf. Unfounded Sets and Well-Fonnded Semantics for General Logic Programs. JACM, 38(3):620-650, 1991. \n[24] M. Wilson and A. Borning. Hierarchical Constraint Logic Programming. Journal of Logic Programming, \n1G:277-318. 1993. 103 \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "Kannan Govindarajan", "author_profile_id": "81100039390", "affiliation": "Dept. of Computer Science, SUNY at Buffalo, Buffalo, NY", "person_id": "PP31077976", "email_address": "", "orcid_id": ""}, {"name": "Bharat Jayaraman", "author_profile_id": "81100267004", "affiliation": "Dept. of Computer Science, SUNY at Buffalo, Buffalo, NY", "person_id": "P30164", "email_address": "", "orcid_id": ""}, {"name": "Surya Mantha", "author_profile_id": "81100269218", "affiliation": "Corporate Research & Technology, Xerox Corporation, Webster, NY", "person_id": "P271815", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.237735", "year": "1996", "article_id": "237735", "conference": "POPL", "title": "Optimization and relaxation in constraint logic languages", "url": "http://dl.acm.org/citation.cfm?id=237735"}