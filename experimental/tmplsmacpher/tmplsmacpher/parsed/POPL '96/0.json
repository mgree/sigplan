{"article_publication_date": "01-01-1996", "fulltext": "\n Is it a Tree, a DAG, or a Cyclic Graph? A Shape Analysis for Heap-Directed Pointers in C * Rakesh C4hiya \nand Laurie J. Hendren School of Colmputer Science, McGill University Montr6al, Qu6bec, CANADA H3A 2A7 \n{ghiya,hendren}ocs ,mcgill. ca Abstract This paper reports on the design and implementa\u00adtion of a practical \nshape analysis for C. The pur\u00adpose of the analysis is to aid in the disambiguation of heap-allocated \ndata structures by estimating the shape ( Ike, DA G, or Cyclic Graph) of the data structure ac\u00adcessible \nfrom each heap-directed pointer. This shape information can be used to improve dependence test\u00ading and \nin parallelization, and to guide the choice of more complex heap analyses. The method has been implemented \nas a context\u00adsensitive interprocedural analysis in the McCAT conl\u00adpiler. Experimental results and observations \nare given for 16 benchmark programs. These results show that the analysis gives accurate and useful results \nfor an important group of applications. 1 Introduction and Related Work Pointer analyses are of critical \nimportance for optinliz\u00ading/parallelizing compilers that support languages like C, C++ and FORTRAN90. \nThe pointer analysis prob\u00adlem can be divided into two distinct subproblems: (i) analyzing pointers that \npoint to statically-allocated ob\u00ad jects (typically on the stack), and (ii) analyzing point\u00aders that point \nto dynamically-allocated objects (typi\u00adcally in the heap). Pointers to stack objects are usu\u00adally obtained \nusing the address-of (&#38;a) operator, while *This work supported by NSERC, FCAR, and the EPPP project \n(financed by Industry Canada, Alex Parallel Conlput\u00aders, Digital Equipment Canada, IBM Canada and the \nCentre de recherche inforrnatique de Mcmtr6al). Permission to make digitallhard copies of all or part \nof thk material for personal or claasroom use is granted without fee provided that the copies are not \nmade or distributed for profit or commercial advantsge, the copy\u00ad right notice, tbe title of the publication \nand ita date appear, and notice is given rha~ copyright is by permission of the ACM, Inc. To copy otherwise, \nto repubhsh, to post on servers or to redistribute to tista, requnes specific permission and/or fee. \nPOPL 96, St. Petersburg FLA USA @1996 ACM ()..89791_769_3 /95/()l ..$3.50 pointers to heap-objects are \nobtained using a memory allocating function like malloc ( ). Henceforth we will refer to these analyses \nrespectively as stack analysis and heap analysis. A considerable amount of work has been done in both \nof these areas. Initially, the focus was on heap analysis alone, for languages like Lisp and Scheme or \nfor toy im\u00adperative languages that did not include all of the com\u00adplexities of C [3, 4, 5, 12, 17, 18, \n19,20,22,23,27, 30]. A recent trend has been to actually implement pointer analyses in real C and FORTRAN90 \ncompilers, and to examine if practical and useful solutions can be obtained. The most recently proposed \n(and imple\u00admented) approaches [1, 6, 26, 29, 32, 33], mostly fo\u00adcus on the stack problem and only give \nconservative estimates for the heap problem. These approaches ex\u00adploit the fact that pointer targets \non the stack always possess a compile-time name. Using this property stack pointer relationships are \naccurately captured as points\u00adto pairs [6] of the form (p, x) (denoting pointer variable p points to \nthe data object x), or alternatively as alias pairs [26] of the form (*p, x ) (denoting *p and x are \naliased). Unfortunately heap objects do not have any fixed name during their lifetime, as they are dynamically \nallocated and are inherently anonymous. Hence var\u00adious schemes are used to name them: naming them ac\u00adcording \nto the place (statement) in the program where they are allocated [3, 26, 29] or further qualifying these \nnames with procedure strings to distinguish between objects allocated at the same statement but along \ndif\u00adferent calling chains [1, 33]. These naming schemes can give the same name to completely unrelated \nheap ob\u00adjects, and hence tend to provide conservative results, and they cannot compute shape information. \nInstead of adapting heap analysis to an abstraction actually designed for stack analysis (by naming heap \nobjects), our approach is to decouple the two analy\u00adses and provide heap analyses that approximate rela\u00adtionships \nand attributes of heap-directed pointers. In our McCAT compiler we first perform a stack analy\u00adsis called \npoints-to analysis [6, 8] that resolves pointer relationships on the stack. It uses one abstract lo\u00adcation \ncalled heap for all heap locations and reports all heap-directed pointers to be pointing to it. De\u00adpending \non the characteristics of the program under analysis, we can then apply the appropriate heap anal\u00adysis \nwhich gives more precise information about the relationships between heap-directed pointers. For pro\u00adgrams \nwith few uses of the heap, the level-O or points\u00adto analysis is enough. For programs that use a number \nof dynamically-allocated arrays and/or non-recursive structures, the level-l or connection analysis is \nused which identifies if two heap-directed pointers point, to the same structure [10, 11]. Scientific \napplications writ\u00adten in C typically exhibit this feature, as they use a number of disjoint dynamically-allocated \narrays. This paper focuses on the /evcL2 heap analysis: shape analysis. The goal of shape analysis is \nto esti\u00admate the shape of the data structure accessible from a given heap-directed pointer: is it tree-like, \nDAG-like or a general graph containing cycles? More specif\u00adically, our focus is on identifying unaliased \ntree-like and acyclic DAG-like data structures built by the pro\u00adgram, and provide conservative estimates \notherwise. Shape analysis is designed for programs that primarily use recursive data structures, or a \ncombination of ar\u00adrays and recursive data structures. Shape information can be gainfully exploited to \nparallelize such programs [12, 17,22, 24], or to apply optimizing transformations like loop unrolling \n[15] and software pipelining [16] on them. Much of the previous work on heap analysis also pri\u00admarily \nfocused on some variation of the ploblem of shape estimation [3, 5, 17, 19, 21, 23, 28, 30]. In gem eral, \nall of these approaches use a more complex ab\u00adstraction than the one given in this paper, and as a result \nthey may find a more precise answer. Rather than look for a complex abstraction, our approach is to start \nwith simple abstractions that can be inlple\u00admented in real compilers and examine the usefulness of these \nsimple abstractions with respect to a set of rep\u00adresentative benchmark programs. Thus, the main con\u00adtribution \nof our work is the design and implementation of practzcal abstractions to perform shape analysis for \nan important class of C programs. We believe we are the first to implement such a method in an optinliz\u00ading/parallelizing \nC, compiler and collect empirical re\u00ad sults for real C programs. Our results indicate that our shape \nanalysis provides accurate results for programs that build tree-like and DAC,-like data structures in \na compositional manner. The rest of the paper is organized as follows. In Section 2 we give a high-level \noverview of the analy\u00adsis rules assuming a simple model where stack-directed pointers and heap-directed \npointers are clearly sepa\u00adrated. The method has been fully implemented in the McCAT compiler as a context-sensitive \ninterprocedu\u00adral analysis for C programs. In Section 3 we give a brief overview of our implementation \nof this method and discuss the most pertinent features. We present some empirical data in Section 4, \nto evaluate the cost and effectiveness of shape analysis. Conclusions and some future directions are \ngiven in Section 5. 2 Analysis Rules The shape analysis is actually composed of three store\u00ad/ess [4] \nabstractions that work together and are com\u00adputed together for each program point. For each heap\u00addirected \npointer, we approximate the attribute shape, and for each pair of heap-directed pointers we approx\u00adimate \nthe direction and interference relationships be\u00adtween them. These three abstractions are defined for\u00admally \nas follows. Definition 2.1 Gtven any heap-directed pointer p, the shape attribute p. shape is Tree, if \nin the data struc\u00adture accessible from p there is a unique (possibly empty) (access) path between any \ntwo nodes (heap objects) be\u00adlongtng to d. It is considered to be DAG (dtrected acyclic graph), if there \ncan be more than one path be\u00adtween any two nodes an this data structure, but there is no path from a \nnode to itself (i. e, ii is acyclic). If ibis data structure contatns a node having a path to itself, \np. shape ts considered to be Cycle. Note that, as lists are a spectal case of tree data structures, their \nshape is also considered as Tree. Definition 2.2 Given any two heap-dtrected pointers p and q, direction \nmatrix D captures the followtng re\u00adlattonshlps between them: o II [p, q] = I : An access path possibly \nexists in the heap, from the heap object pointed to by pointer p, to the heap object potnted to by pointer \nq. In this case, we szmply state that pointer p has a path to pointer q. e I) [p, q] = o : No access \npath extsts from the heap object poznted to by p, to the heap object pointed to byq. Definition 2.3 Gzven \nany two heap-directed pointers p and q, interference matrix I captures the following relattonslups between \nihem: e I Cp, q] = I : A common heap object can be pos\u00ad sibly accessed, starting from poznters p and \nq. In thus case, we state that p and q can interfere. e I Ip, q] = O : No common heap object can be ac\u00ad \ncessed, starting from pointers p and q. In this case, we state that p and q do not interfere. Direction \nrelationships are used to actually estimate the shape attributes, while interference relationships are \nused for safely calculating direction relationships. .(~-y -~ \u00ad i u   t w-. r n . e------\\ s ) h \n\\ R: \\ I AL w -i\u00ad jLRR~~ (a) Heap Structure Pqrst~, Pqrstu, 1 1000 0 10000 q ,q P P1 o10000 110000 ro010(1o \nro01101 so01110 so01111 to00010 to00 1 10 uo01001 uo01 101 (b) Direction Matrix (c) Interference Matrix \nFigure 1: Example Direction and Interference Matrices 2.1 Illustrative Examples Figure 2, initially we \nhave both p. shape and q. shape as Tree. Further D [q, p] is one, as there exists a path We illustrate \nthe direction and interference abstrac\u00ad from q to p through the next link. The statement tions in Figure \n1. Part (a) shows the heap structure p->prev = q, sets up a path from p to q through the at a program \npoint, while parts (b) and (c) show the prev link. From direction matrix information we know direction \nand interference matrices for it. that a path already existed from q to p, and now a In Figure 1, an \naccess path exists from pointer p to path is being set also from p to q. Thus we can deduce q, and also \nfrom pointer s to t, so the entries D [p, q] the creation of a cycle between heap objects pointed to \nand D [s, t] are set to one. No access path exists from by p and q. Thus, after the statement, D [p, \nq] = 1, pointer q to p, or from pointer r to t, so the entries D[q,p] = 1, p. shape = Cycle and q. shape \n= Cycle. D Cq, pl and D [r, t] are set to zero. Further, no path It should be noted that for a heap-directed \npointer p,exists from pointer s to u and vice versa, so both the p. shape only abstracts the shape of \nthe data structure entries D [s, u] and D Cu, s] are set to zero. However accessible from p and not the \noverall shape of the data starting from both u and s the heap object pointed to structure pointed to \nby p. For example, in Figure 3, by r can be accessed. To indicate this, the interference the overall \nshape of the data structure pointed to bymatrix entries I [s, u] and I [u,s] are set to one. This p and \nq is DA G. However, if only the part of the dataexample also illustrates that: (i) direction ~elationships \nstructure accessible from p or q is considered, its shape are not symmetric, (ii) interference relationships \nare is Tree. So we have both p. shape and q. shape as Tree. symmetric, and (iii) interference relationships \nform a superset of direction relationships. The second prop-Knowledge about the shape of the data structure \nac\u00aderty is used to reduce the storage requirement for the cessible from a heap-directed pointer, provides \ncrucial interference matrix by half, in the actual implenlenta-information for disambiguating heap accesses \noriginat\u00adtion. The third property follows from the fact that if ing from it. For a pointer p, if p. shape \nis Tree, then any an access path exists from pointer p to q, then they two accesses of the form p->f \nand p >g will always lead can also both access the object pointed to by q. to disjoint subpieces of the \ntree (assuming f and g are We now demonstrate how direction relationships distinct fields). If p. shape \nis DA G, then two distinct help estimate the shape of heap data structures. In field accesses p->f->f \nand p->g can lead to a com\u00ad rI /.-/.\u00ad next p->prev = q next prev P\\ P\\ \\ .  qlav ~ R A4 ~. J-4 J Figure \n2: Example Demonstrating Shape Estimation y. Additionally, we have the attribute matrix A, where for \na pointer p, A [p] gives its shape attribute. The attribute matrix after the statement is represented \naa A,,. . For each statement, we compute the sets of direc\u00adtion and interference relationships it kills \nand gener-P \\ ates. Using these sets, the new matrices Dn and In are \\ ~ la. computed as shown in Figure \n5(c). Note that the ele\u00adments in the gen and kill sets are denoted as D(p ,q) for direction relationships, \nand I(p ,q) for interference rela\u00adtionships. Thus a gen set of the form{ D(x,y), D(y,z) }, indicates \nthat the corresponding entries in the output Figure 3: Estimating Shape with uccesszbthiy Criterion direction \nmatrix (Dn [x,y] and D,, [y,z]) should be set to mon heap object, as in Figure 4. However, if a dag-like \none. We also compute the set of pointers H$, whose structure is traversed using a sequence of links, \nevery shape attribute can be modified by the given state\u00ad subsequence visits a distinct node. This information \nment. Another attribute matrix Ac is used to store the can be used to disambiguate heap accesses in different \nchanged attribute of pointers belonging to the set H.. iterations of a loop, or different recursive calls, \ntravers-The attribute matrix A,, is then computed using the ing such a data structure. Finally, if p. \nshape happens matrices A and AC as shown in Figure 5(c). to be Cycle, we have effectively no information \nto dis-Let H be the set of pointers whose relation\u00ad ambiguate heap accesses originating from p. ships/attributes \nare abstracted by matrices D, I and Thus, the goal of shape analysis is to identify tree-A. Assume that \nthese pointers can only point to heap like and dag-like data structures, and to retain this objects or \nto NULL. Further assume that updating an information as long as possible, during the analysis, interference \nmatrix entry I [p ,q], implies identically up- We now present the rules to calculate direction and dating \nthe entry I[q,p]. This assumption is rendered interference matrix abstractions, and to estimate shape \nvalid due to the symmetric nature of interference rela\u00adinformation using them. tionships. The actual \nanalysis rules can be divided into three groups: (1) allocations, (2) pointer assignments, and 2.2 Analysis \nof Basic Statements (3) structure updates. In the following subsections we The McCAT compiler translates \ninput C programs discuss the three rules. into a structured and compositional intermediate form called \nSIMPLE [31] . Using this form, there are eight 2.2.1 Allocating new heap cells basic statements that \ncan access or modify heap data structures as listed in Figure 5(a). Variables p and p = malloco : Pointer \np points to a newly allocated q and the field f are of pointer type, variable k is of heap object. All \nits existing relationships get killed. integer type, and op denotes the + and -operations. Pointer p \nnow has an empty path to itself and and it The overall structure of the analysis is shown in Fig-also \ninterferes with itself. This statement can change ure 5(b). Given the direction and interference matrices \nthe attributes of only pointer p. Since the newly allo-D and I at program point x, before the given statement, \ncated object pointed to by p has no incoming or out\u00adwe compute the matrices Dn and 171 at program point \ngoing links, its shape attribute is Tree. This can be ~. . ..@f-JJ- -p-p P Figure 4: Acyclicity Allocations \nl.p = malloco; Potnter Assignments 2.p=q;  3.p =q->f; 4.p = k(q->f); 5.p=qopk;  6.p =NULL; Structure \nlJpdate.s 7.p->f =q; 8. p->f = NULL; (a) Basic statements I (b) Analysis Structure Fi,gure5: The Overall \nsummarized with the following rule. D_kill-set={D(p,s) [s EHAD[p,s]}u { D(s,p) IS E H A D[s,p] } I_kill._set \n= { I(p,s) I s E H A I[p,s] } D_gen_set={D(p,p)} I-gen-set={I(p,p)} H, = {p} AC[p]= Tree  Note that \nhaving D(p,p) in thegen set here simply implies that p presently points to a heap object. It does not \nimply that a cyclic data structure becomes accessible fromp after this statement. In that, case, we would \nalso have AC[p] = Cycle. 2.2.2 Pointer assignnwnts The next five basic heap statements (p = q,p = q->f, \np = &#38;(q->f), p = q op kandp = NULL) updatethe stack-resident pointer p, and make it point to a new \nheap object. They kill all existing relationships ofp, and can only change the shape attribute of pointer \np. So the kill set and the set H, for all these statements, are same as that for the statement p = malloc \n( ). Be\u00adof Dag Data Structures Build the new matrzces V r,s E H, D~[r,s] = D[r,s], I~[r,s] = I[r,s] b \ns c H, An[s] = A[s] Delete killed relationships V entries D(r,s) E D.kill=et, Dn [r,s] = O V entries \nI(r,s) E I-kill-set, In[r,s] = O Add generated relationships V entries D(r,s) c D.gen-set, Dn [r)s] = \n1 V entries I(r,s) c I-gen.s.et, In[r,s] = 1 Update shape attributes of affected pointers Compute H, \nand Ac V s E H,, /ln[S] = &#38;[s] I (c) General Form of Analysis Rules Structureo ftheAnalysis low, \nwe present the rules to calculate the gen set and the matrix Ac for these five statements, p=q: Pointer \np now points to the same heap object as q. It simply inherits the relationships and the shape attribute \nof pointer q. III case q presently points to NULL, p would also point to NULL after the statement. So \nwe have D(p,p) and I(p,p) in the gen set, only if D[q,q] and I[q,q] are presently set to one (implying \nthat q does not point to NULL). We have the following overall rule for the statement p = q. D-gen-set-from \n= { D(s,p) ] s G H A s # p A D[s,q] } D-genset-to ={D(p,s) [s cHAs#pAD[q,s] }U { D(p,p) I D[q,q] } I-.gen_set \n= { I(p,s) Is ~ H A s# p A I[q,s] } U { I(p,p) I I[q,ql } D-gen_set == D_gen-set.from U D_gen_set.to \nH, = {p} AC[p] = A[q] For purposes of our analysis we consider a pointer pointing to a specific field \nor at a specific offset of a heap object, to be pointing to the object itself. With this assumption, \nthe statements p = &#38;(q->f ) ancl p = D-gen-set-to = { D(p,s) \\ s 6 H A s #q As+p Aq op k are equivalent \nto the statement p = q for shape D[q,s] } U { D(p,q) I A[q] = Cycle}analysis and are analyzed using the \nsame rule. U { D(p,p) I D[q,q] The statement p = NULL kills all relationships of p } and does not generate \nany new relationships. Since p The overall D-gen-set is obtained by unioning thepoints to NULL after \nthe statement, shape attribute is from and to sets. not relevant to it. As a default case, it is set \nas Tree. = Iq->f : This statement makes pointer p point to P the heap object accessible from pointer \nq through the link f, as shown in Figure 6.1 It generates following types of relationships: (i) new direction \nrelationships because of pointer p having a path from/to other point\u00aders, and (ii) new interference relationships \nwith respect, to pointer p. From Relationships : After the statement p = q->f, p will have a path from \nall pointers that presently have a path to q (u, v and q in Figure 6). Further, p can potentially also \nhave a path from: (i) pointers to which q has a path to (pointer 1 in Figure 6), and (ii) pointers which \nin\u00adterfere with q (pointer t in Figure 6). It is because of the second possibility that we abstract interference \nrelationships. Note that due to these two possibilities, a number of spurious relationships can be generated. \nFor example in Figure 6, we will generate the spuri\u00adous relationships D(r,p) and D(s, p), as q also has \na path to r and p, besides I. As all pointers q has paths from/to, also interfere with q, the set of \n~rom direction relationships can be stated as follows. D.gen_set.from = { D(s,p) I s E H A s # p A I[s,q] \n} To Relationships : Pointer p will have a path to all pointers q has a path to via the link f. ~Fronl \nthe direction matrix, we can find all the pointers q has a path to, but cannot identify the pointers \nq has a path to via a specific link. So we conservatively assume p to be having a path to aii the pointers \nq has a path to. In Figure 6, after the statement, p is reported to be having paths to pointers 1, r \nand s, where the path from p to s is spurious. Note that q has a path to itself, so according to the \n above assumption p should also be reported to have a path to q after the statement. Ho\\vever, if the \ndata structure accessible from q is acyclic (i.e. A[q] = Tree or Dag), p cannot have a path bacli to \nq. Iu Figure 6, A[q] is Tree, hence p is not, reported to be having a path to q. Thus, the set of fo \ndirection relatioushil]s can be summarized as: 1In this Figure, for sake of clarit y we have simply labelecf \neach node with the stack-resident pointer that points to it, imteacl of explicitly representing the stack. \nInterference Relationships : After the statement, pointer p can potentially interfere with all the pointers \nq presently interferes with. So we have the following set of newly generated interference relationships: \nI-gell-set =={ I(p,s) \\s 6 H A s # p A I[q,s] } U { I(p,p) I I[q,q] } Despite potentially introducing \nseveral spurious re\u00adlationships, this statement does not affect the shape of the data structure accessible \nfrom q. It only gives a new name to one of the heap objects belonging to this data structure. Since the \ndata structure accessible from p is a subpiece of the data structure accessible from q, it is safe to \nassign p the shape attribute of q, giving the following attribute matrix AC: AC[p] = A[q] It is possible \nthat A[q] is Cycle, while the shape of the structure accessible from q via the f link is Tree. However, \nwe cannot detect this from the information available, and must conservatively say that An [p] is a Cycle. \nBut if A[q] is Tree, we do not lose the tree at\u00adtribute, and if it is Dag we still preserve the acyclic \nproperty of the data structure accessible from p. Note that if we simply deduce the shape attribute of \np from its direction relationships after the statement, we may lose its Tree or Dag attribute. Thus, \nseparately ab\u00adstracting the shape attribute proves to be critical in identifying tree-like and dag-like \ndata structures. 2.2.3 Structure Updates Structure updates are of the form p->f = NULL and p->f = q. \nThese are the nasty statements for shape analysis in imperative programs because such state\u00adments can \ndrastically change the shape and connectiv\u00adity of heap structures. The goal is to get accurate kill and \ngen information without using an overly complex abstraction. The choice we have made in this prac\u00adtical \ntechnique is to use our simple abstractions and live with overly conservative gen and kill sets for these \ntypes of statements. However, using a combination of our three abstractions, we are still able to perform \nac\u00adcurate shape estimation in many important cases. We discuss the analysis of the two statements in \ndetail be\u00adlow. Q P Q P Figure 6: Analyzing Basic p->f = NULL : This statement breaks the link f enla\u00adnating \nfrom the heap object pointed to by p. After the statement, p should no longer have paths to pointers, \nit presently has paths to exclusively via the link f. As already discussed, this information cannot, \nbe obtained from direction/interference matrices. So no relation\u00adships can be killed. Further, the statement \ndoes Ilot generate any new relationships. The shape attribute of pointer p may change, if this statement \ndisconnects the subpiece of the data struc\u00adture, due to which A[p] is Dag or Cycle. But the di\u00adrection/interference \ninformation does not suffice to de\u00adtect such cases, and we err conservatively leaving the attributes \nunchanged. Note that due to the lack of precise kill information for this statement, if a tree-like structure \ntemporarily becomes dag-like or cyclic, and becomes a tree again (e.g. when swapping the children of \na tree), our analysis would cent inue to report its shape as Dag or Cycle. p->f = q : This statement \nfirst breaks the link f, and then resets it thereby linking the heap object pointed to by p, to the heap \nobject pointed to by q, as shown in Figure 7. As already discussed, the relationships killed on breaking \nthe link f, cannot be obtained with the information available. However, resetting the link f results \nin generating some new relationships and nlod\u00adifying the attributes of several pointers, as discussed \nbelow. All pointers having a path to p (including p itself), will now have a path to q via the link f. \nFurther, these pointers will have paths to all pointers q has paths to. In Figure 7, pointers u, v and \np will have paths to pointers q, r and s after the statement. Thus, the set of direction relationships \ngenerated cau be summarized as follows: D.gen-set = { D(r,s) I r,s ~ H A D[r,p] A D[q,s] } In Figure \n7, pointer q interferes with pointer t, be- Heap Statement p = q->f fore the statement. After the statement, \npointers u, v and p will also interfere with t. This demonstrates that all pointers having a path to \np, can potentially interfere with all pointers q interferes with. Thus we get the following set of new \ninterference relationships: I-gen-set = { I(r,s) I r,s 6 H A D[r,p] A I[q,s] } This statement can considerably \naffect the shape at\u00adtribute of pointers, which have direction relationships with pointers p and q. We \ncan have the following situ\u00adations, depending on the current attributes and direc\u00adtion relationships \nof pointers p and q: Pointer q already has a path to p (D[q,p] = 1) : After the statement p->f = q, p \nwill also have a path back to q. Thus, a cycle will be generated between p and q. We have already illustrated \nthis case in Figure 2. Fur\u00adther, this cycle will also be accessible from all point\u00aders that presently \nhave a path to p or q (including p and q themselves), and the shape attribute of all these pointers will \nbecome Cycle. We summarize this case as follows: H, = { SISGHA(D[s,q] VD[s,p]) } V s E Hs, D[q,p] =+ \nAc[s] = Cycle If the above situation does not arise, we have the following possibilities: A[q] = Tree \n: In this case another tree-like structure becomes accessible from all the pointers that presently have \na path top. If the data structures pointed to by p and q are initially completely disjoint, then the \nstate\u00adment simply connects a tree substructure to the data structure pointed to by p and does not affect \nthe shape attribute of any pointer. Figure 7 illustrates this case. Otherwise the shape attribute of \npointers that initially have a path to p and also interfere with q, becomes Dag (if it is presently Tree). \nPointers u and v in Figure 8 fall in this category. Finally, if the shape attribute of such a pointer \nis already Dag or Cycle, it remains un\u00adchangecl. In other words, the shape attribute of these Q P j/ \nfg Q P Q P P v f t OP fg s (3?$ 1 Figure 7: Analyzing Basic Heap Statement p->f = q Figure 8: Direction \nRelationships Impacting Shape Attribute pointers, becomes the merge of their current attribute LFrom \nthe rules presented above, it can be noticed and the Dag attribute, where the merge operator w for that \na considerable number of spurious direction and the shape attribute is defined as follows: interference \nrelationships can be introduced during the analysis. However, empirical results presented in Sec\u00adtion \n4, indicate that our analysis provides effective shape information for a broad range of programs in an \nefficient manner. This case can be formally summarized as follows: 3 Implemen~in~ ~1-mpe Analysis in \nthe McCAT C Compiler Hs= {S Is CHA(I[s,q] AD[s,p]) } V s c Hs, ((7 D[q,p]) A (A[ql = Tree)) + Shape \nanalysis has been implemented aa a context\u00ad A.[s] = A[s] M Dag sensitive interprocedural analysis in \nthe McCAT op\u00adtimizing/parallelizing C compiler. It is a flow-sensitive A[q] # Tree : In this case, the \nshape attribute of all analysis and collects program-point-specific informa\u00adpointers that have path to \np is merged with the shape tion. The analysis is performed on the SIMPLE in\u00ad attribute of q. This is \nrequired because the data struc\u00adtermediate representation which is a simplified, com\u00ad ture accessible \nfrom q, will also become accessible from positional subset of C [7, 13, 31]. Shape analysis is all these \npointers after the statement. 1~ e summarize performed after points-to analysis [6, 8] and focuses the \ncase as follows: only on the subset of pointers reported to be pointing H,={s[sc HA D[s,P]} to heap by \npoints-to analysis. This reduces the stor-V s e H,, ((~ D[q,p]) A (A[q] # Tree)) 5 age requirements for \nthe abstractions, and makes the A.[s] = A[s] w A[q] implementation easier as well as more efficient. \nThe overall analysis framework is similar to that used for points-to analysis. It should be noted, however, \nthat other dataflow frameworks could also use the basic abstraction and rules presented in the previous \nsec\u00adtion. Our particular implementation is structured as a simple analysis for each basic statement of \nthe form presented in Section 2, a compositional rule for each control construct, and a context-sensitive \napproach for handling procedure calls. While presenting the basic analysis rules in Section 2.2, we did \nnot consider the presence of stack-directed pointers. However, we take them into account in the actual \nimplementation, and this requires some addi\u00adtional checks. The subtle point is that references of the \nform p->f may refer to the stack, the heap, or to both the stack and heap. For example, in one calling \ncontext, p may point to a stack-allocated object, that has a name, while in another calling context, \np may point to a heap-allocated object. Consider a statement of the form p->f = q. If p points to a stack-allocated \nobject with the name x, then the appropriate analysis rule is x. f = q, whereas if p points to a heap-allocated \nobject, the appropriate rule is p->f = q. Thus, our im\u00adplementation first uses points-to information \nto resolve all references of the form p->f into a set of possible stack and heap locations, and then \napplies the appro\u00adpriate simple shape analysis rules, merging the results of all the outputs. Our strategy \nfor handling control constructs is illus\u00adtrated in Figure 9, which gives the analysis rule for the while \nstatement. It also defines the merge opera\u00adtors for our three abstractions. The merge operator for the \ndirection and interference relationships is simply the logical OR (V) operation, as they are both possi\u00ad \nble (or may) relationships. The merge operator x for the shape attribute has already been defined in \nSection 2.2.3. Also note that we consider the loop condition as a simple assignment, when feasible. For \nexample, when it involves a pointer equality test like (p == NULL) or (P = @ To accurately handle procedure \ncalls, we use the interprocedural analysis framework built by points-to analysis [6, 8, 14]. It provides \nus the complete invoca\u00adtion graph of the program which is constructed by a simple depth-first traversal \nof the invocation structure of the program. Since the invocation structure is not known statically for \nrecursive and indirect calls, they are handled in a special manner. Recursive calls are represented by \nspecial pairs of recursive and approxi\u00admate nodes, where the approximate node represents all possible \nunrolling of recursion. Indirect calls through function pointers are represented by nodes indicating \nthe possible set of functions invocable from the given call-site (resolved during points-to analysis). \nBased on the above framework, we use the context\u00adsensitive interprocedural strategy depicted in Fig\u00ad \n/ * DII, A : Input matrices, H : Set of pointers * abstracted, ign : Current invocation graph node */ \nfun process-while(cond, body, D, I, A, H,ign) = do prevD = D; prevI = I; prevA = A; [D1,I1,A1] = process-basic-strnt(ccmd,D,I,A,H); \n[D2,12,A2] = process_stmt(body, Dl,Il,Al,H,ign); D = Merge(D,D2); I = Merge(I,12); A = Merge(A,A2); \nwhile ((D != prevD) and (I != prevI) and (A != prevA)); return([D,I,A]); Merge(D,Dl) ~ V r,s c H, D[r,s] \n= D[r,s] V Dl[r,s] Merge(I,Il) ~ V r,s c H, I[r,s] = I[r,s] V Il[r,s] Merge(A,Al) a V s E H, A[s] = A[s] \nM Al[s] Figure 9: Analyzing a while Statement ure 10. Complete rules for our interprocedural analysis \nscheme are described in [11]. Here we briefly discuss only the most pertinent issues. The general idea \nis that, first, the three matrices (for direction, interference and attribute abstractions) at the call-site \nare mapped to prepare the input matrices for the called procedure. Next, the body of the procedure is \nanalyzed with these input matrices, and the output matrices obtained are unmapped and returned to the \ncall-site. With this ap\u00adproach, every time a procedure call is analyzed for some call-chain, there exists \na unique invocation graph node corresponding to it. Recursive calls are handled via an iuterprocedural \nfixed-point computation, using the spe\u00adcial recursive and approximate nodes in the invocation graph. \nIndirect calls are handled by separately analyz\u00ading each invocable procedure from the given call-site, \nand then merging all outputs. F;f>l g(x) ; { Function Anal ysis } Unmap Process Figure 10: The Interprocedural \nStrategy The main issue related with map and unmap pro\u00ad cesses, is identifying the set of pointers whose \nat\u00ad tributes/relationships can be modified by the proce\u00ad dure call. This set includes pointers which \nare: (i) global in scope, (ii) not in the scope of the callee but are accessible via m indirect reference \n(Invisible variables), and (iii) not at all accessible in the callee, but have a direction/interference \nrelationship with some pointer accessible in the callee (tnaccesszble variables). Spe\u00adcial symbolic names \nmust be generated to represent, all invisible and inaccessible variables and capt,ure their attributes/relationships \nin the calling context Points-to analysis already generates symbollc names for znvzsible variables, and \nwe simply reuse them For Inaccessible variables we generate two symbolic names for each parameter or \nglobal that is related to some inaccessible variable(s). If the name of the parameter or global variable \nis x, then we use the name O x to represent all inaccessible pointers that have paths to x, and the name \nO+x to represent all inaccessible pointers that have paths from x or interfere with x. For each procedure \ncall a mapping is stored between names in the calling context and names in the called context (globals, \nparameters and symbolic names), and is used while unmupptng. Completed escriptiouofthe rules for map \nand unmup processes can be fouudin [11]. Finally, inorder to get the full context-sensitivity at a reduced \nprice, we have implemented a simple memo\u00adrization scheme. Every time we finish analyzing a proce\u00addure \ncall, we store the currently computed pairs of in\u00adput and output matrices, in the invocation graph node \ncorresponding to it. When this call is re-analyzed along this call-chain, we simply use the stored output \nfrom its invocation node, if the current input is identical to the stored input. We are also currently \nexploring other techniques to optimize our interprocedural algorithm, which include: (i) excluding the \nfunctions from the in\u00advocation graph, which neither update nor access heap\u00addirected pointer variables, \n(ii) building the invocation graph in a lazy manner, as the demand for different invocation contexts \narises during the analysis [9], and (iii) performing more extensive memorization by trying to memoize \nall calls to a procedure (except the first one) irrespective of the call-chain they appear on 4 Experimental \nResults 4.1 Benchmarks We have collected a number of small and medium sized benchmarks from a variety \nof sources. Table 1 summa\u00adrizes the characteristics of the benchmark programs. The first section gives \nthe source lines including com\u00adments, counted using the wc utility, and the number of statements in the \nSIMPLE intermediate representa\u00ad tion (this number gives a good estimate of program size from the analysis \npoint of view). The second section gives the minimum, maximum and average number of variables abstracted \nby the direction/interference m~]\u00adtrices over all functions in the program (this includes symbolic variables \nintroduced by OUI analysis). These numbers indicate the size of the abstractions and the memory requirements \nof the analysis for a given pro\u00adgram. Note that the average varies from 7 (sianford) to 83 ( szm), which \nis quite reasonable with respect, to space requirements (we use bit matrices). The third section gives \nthe total number of indirect references in the program, and the number of indirect references where the \ndereferenced pointer can point to a stack lo\u00adcation] to a heap location and to both a stack and a heap \nlocation (this typically happens when a formal parameter receives a stack-directed pointer in one in\u00advocation \nof the function and a heap-directed pointer in another). All the benchmarks in Table 1 have substan\u00adtial \nnumber of indirect references, with majority of the indirect references refering to heap locations (except \nfor the two benchmarks: assembler and loader). Thus the given benchmark set is well suited for evaluating \na heap analysis for C. 4.2 Results We estimate the effectiveness of shape analysis for this set, using \nthe following measurements (Table 2(a)): Refs: The number of heap-related indirect references in the \nbenchmark. T, D, C : These three columns respectively give the number of heap-related indirect references \nin the program, where the dereferenced pointer, say p, points to a tree-like, dag-like or cyclic data \nstruc\u00adture: i.e. A[p] = Tree, DAG or Cycle, where A is the attribute matrix at the given program point. \nThe multi-columns labeled *a/ (*a) . b and a [i] (where a itself is a heap-directed pointer) in Table \n2(a), sep\u00adarately give the above measurements for indirect ref\u00aderences of the respective form.2 The multi-column \nla\u00adbeled Overall gives the overall statistics for the given program. Further, in Table 2(b) we compare \nthe ac\u00adtual shape of data structure(s) a program builds with that reported by the analysis and we observe \nif the shape information would be useful in improving de\u00adpendence information and/or parallelization. \nBoth ta\u00adbles have the programs divided into 2 groups. The top group corresponds to programs that build \ntree-like data structures, and are thus good candidates for our shape analysis. In 9 of these 11 programs, \nwe can determine that the structures are in fact Trees and this informa\u00adtion is useful. In the remaining \n2 programs, reverse and s im, we conservatively find that the structures are DA GS, so our shape information \nis only slightly use\u00adful. The bottom group of programs build structures that are inherently dag-like \nor graph-like, and so even zNote that an access of the form x = a[i] is simply consid\u00ad ered a pointer \nreference (and not an indirect reference) when a [i] is a pointer, but a itself is not a pointer. Indirect \nrefer\u00ad ences of the form x = * ( a [i ] ) are counted as indirect references of the form *a because \nof our simplification which expresses this as { temp = a[i] ; x = *temp; }. For this reason, benchmarks \nusing arrays of pointers may not always have indirect references of type a[i]. 10 Program Source SIh \nIPLE Min Max Avg Ind To To Stack/ Lines Stints vars vars vars Refs Stack Heap Heap bintree 351 342 4 \n23 10 50 10 40 0 l~g xref 153 204024 31 0 31 0 misr 277 235 210 847 39 35 27 PO chomp 430 476 27 22 127 \n45 82 0 stanford 885 880 414 7 28 0 28 0 hash 257 110 461114 7 7 0 power 681 641 16 23 18 180 29 151 \n0 reverse 123 49 9 1812 16 0 16 0 assembler 3361 3071 22 36 24 718 666 52 0 loader 1539 1055 13 28 17 \n170 106 64 0 sim 1422 1760 76 111 83 374 34 340 0 paraffins 381 180 6 31 21 37 2 35 0 blocks2 876 1070 \n56 82 61 373 98 275 0 nbody 2204 703 24 36 27 134 24 116 6 1495 sparse 2859 24 60 32 468 3 465 0 !Jp \npug 2400 2089 153 48 822 147 688 13 Table 1: Benchmark Characteristics when our shape analysis gives \ncorrect, shape ( 4 of the 5 Just before statement S4 both oldnode and neunode programs), the shape information \nis not really clet ailed have a path to q. Statement S4 kills the path from enough for improving dependence \ntesting and/or paral- oldnode to q (which is via the link f), and sets a lelization. The shape information \nis useful, however, as path from oldnode to newnode. Our analysis can\u00ad a way of automatically determining \nthat, a higher-level not detect the kill information, and finds oldnode to heap analysis should be applied. \nhave an additional path to q via newmode (which is now actually the only path). So it reports its shape \nat\u00adtribute as DA G. If further insertions are done into this 4.3 Observations apparently dag-like structure, \nanalysis becomes overly conservative and reports its final shape attribute as Cy- Based on the data presented \nin Tables 2(a) and 2(b), cle. This case applies to benchmarks sire, blocks2 and and our examination of \nthe benchmark programs, we nbodg. make the following observations. If a data structure temporarily becomes \ndag-like or If a program builds a tree-like data structure in such cyclic and then becomes tree-like \nagain, shape analysis a manner, that a new node is always appended at the cannot detect this, and continues \nto report its shape as beginning/end of the existing structure, then shape dag-like or cyclic. The benchmark \nreverse that recur\u00ad analysis always successfully infers the shape of this data sively swaps a binary \ntree represents this case. structure as Tree. This happens because in this case the Shape analysis abstracts \nall pointers from an array of data structure does not even temporarily lose its tree pointers, say a[lo] \n, as one pointer a. So the relation\u00ad attribute. In our benchmark set, bzafree, .rrcf, stanford ships \nand attribute of this pointer, represent the merge and chomp build binary trees by appending the new \nof the relationships and attributes of all the pointers it node to a leaf node, while hash, mtsr, loader \nand M\u00addenotes (all pointers a [i]). If the shape attribute of sem bier build linked lists by appending \na new item at such a pointer is reported to be Tree, one is guaran\u00ad the beginning/end of the list. The \nshape attribute for teed that all array indices point to tree-like structures, these programs is accurately \nestimated. completely disjoint from each other (if the structures If a tree or dag-like data structure \nis built (or nlod\u00adpointed to by two array indices, say a [i] and a[jl ified) by inserting new nodes between \nexisting nodes, share a node, the shape attribute for a is reported as shape analysis provides conservative \nestimates and re\u00adD.4 G or Cycle). ports the shape to be dag-like or cyclic. The following In our benchmark \nset, hash uses an array of pointers code fragment illustrates this case: to linked lists, and power implements \na power network tree [2, !25] witl~ its root having an array of pointers to Si : vld_nvde >f = q; disjoint \nsubtrees. We get the shape attribute of these S2: ner.r_node = newNode ( ) ; arrays as Tree. For example, \nthe simplified version of S3: new-node->f = q; the loop that builds the power tree is as follows: S4: \nold_node-M = new_node; Program *a/ (*a). b a[i] Overall Refs T D c Refs T D c Refs T D c bintree 36 \n36 0 0 4 4 0 0 40 40 0 0 ~ xref 29 29 0 0 2 0 0 31 31 0 0 misr 35 35 0 0 0 0 0 0 35 35 0 0 chomp 56 56 \n0 0 26 26 0 0 82 82 0 0 stanforcl 28 28 0 0 0 0 0 0 28 28 0 0 hash 7 -7 0 0 u o 0 0 7 7 0 0 power 147 \n147 0 0 4 4 0 0 151 151 0 0 reverse 16 11 5 u o 0 0 0 16 11 5 0 assembler 45 45 0 0 7 7 0 0 52 52 0 0 \nloader 55 55 0 0 9 9 0 0 64 64 0 0 sim 96 29 67 0 244 221 23 0 340 250 90 0 paraffins 26 8 18 0 9 3 6 \n0 35 11 24 0 bloclw2 119 16 37 66 156 64 43 49 275 80 80 115 nbody 74 22 0 52 42 14 0 28 116 36 0 80 \nsparse 384 14 0 370 0 0 0 0 384 14 0 370 pug 514 16 0 498 174 1 0 173 688 17 0 671 (a) Enlpiricz+l h~e~isurements \nfor Shape Analysis Program Actual Data Structure(s) Built, Shape Shape Shape Info. Reported Correct Useful \nbintree A binary tree Tree yes yes xref A binary tree with a linked list hanging from each node Tree \nyes yes misr A linked list Tree yes yes chomp A game tree and a linked list Tree yes yes stanford A binary \ntree for tree-sort Tree yes yes hash A hash table using an arrayof linkedlists Tree yes yes power A tree \nimplementing a power net]vork Tree yes yes reverse A binary tree which is recursively s~rapped DA G no \nslightly assembler A linked list Tree yes yes loader A linked list Tree yes yes sim An array of linked \nlists DA G no slightly paraffins 3 arrays of interconnected linked lists (DAG) DA G yes slightly blocks2 \nA constraint graph data structure (DAG) DA G/Cycle partially slightly nbody A leaf-linked octree (DAG) \nCycle no no sparse Sparse matrix using linked lists (cyclic) Cycle yes no pug A COIml>le.X CYCliC structure \ncycle yes no (b) Accuracy and t]sefulness of Shape Information Tab]e 2: Experimental Results t = (struct \nroot*) malloco; for (i =O;i<=N; i=i+ ~) { temp-1= (i * 10); 1 = build-lateral(temp_l,20); temp-2 = (* \nt).feeders; temp_2[il = 1; In the above loop, the functiouc allbui.ld-lateral returns a tree in each \niteration, which is then connected to the tth index of the pointer array temp-z. Since in each iteration \na disjoint tree is connected, the overall shape of the pointer array temp-2 is deduced as Trte. Further, \nmost of the computation in this benchmark, is performed in a loop which iterates o~er this array. The \nimportant segment of this loop in the simpl~jic d format is as follows: for (i=O; i<=N; i=i+ 1) { temp_O \n= (* r).feeders; 1 = temp-O[il; theta_R = (* r).theta_R; theta_I = (* r).theta_I; a = Compute_Lateral(l,theta-R,theta_I \n, theta_R,theta.-I) ; ... } For this loop, we know from shape information that in each iteration pointer \n1 points to a disjoint tree, which is then operated upon by the function compute~ateral. Thus this loop \ncan be effectively parallelized provided there are no dependencies due to other variables (there are \nnone in this case). This demonstrates how shape analysis can provide critical inforrnatiou for dependence \naualysis and parallel iza\u00adtiou. The benchmark pizrafins also uses arrays of pointers to linked lists. \nHowever these lists share some Hodes, and consequently the shape gets reported as D.-l G. The benchmarks \nsparse and pug use inherently cyclic data structures with back pointers. So majority of inclirect references \nfor them fall in the Cycle category. The ones in the Tree category represent newly allocated nodes, before \nthey are connected to the main data structure of the program. Besides shape information, direction and \ninterferenc(~ relationships can also be useful on their own. For ex\u00adample, to identify if data structures \naccessible from two pointers say p and q share a node, one needs to sinl\u00adply check if the interference \nmatrix entry I [p, q] is set to one. Similarly, direction matrix information can aid the programmer in \nsafely deallocating melnory. At, a call-site like free (p), if any (live) pointer can have a path to \np, then it may not he a safe deallocation. We are currently exploring the effectiveness of diYec\u00adtiou \nand interference inforlnation, for these slid othel applications. 4.4 Interprocedural Measurements Shape \nanalysis is a context-sensitive interprocedural analysis. In Table 3, we present the invocation graph \ncharacteristics of the benchmarks. The first three columns in this table, give the total number of func\u00adtions \nactually called in the program, the total number of call-sites in the program, and the total number of \nnodes in its invocation graph. The last three columns give the nurnberofrecursive and approximate nodes, \nand the number of nodes per call-site. In Table 4 we present some dynamic interprocedu\u00adrzd measurements \nfor shape analysis. The first three columns give the total number of procedure calls an\u00adalyzed, the number \nof procedure calls that get mem\u00adoized, and the actual number of procedure calls that get analyzed. The \nlast three colurnnsgivethe average number of procedure calls actually analyzed (given in the column labeled \nAct) per function, per call-site and per invocation graph node. These averages arecalcu\u00adlated by dividing \nthe number in the Act column, with the appropriate nulnber from the first three columns in Table 3. Program \nfns call ig I Rec I App I nodesj sites call-site bintree 17 31 32 2 4 1.03 mef 81415 2 4 1.07 misr 5 \n770 0 1.00 chomp 20 47 98 7 7 2.09 stanford 8 4 1.08 1213 2 hash 5 880 0 1.00 power 18 31 53 6 6 1.71 \nreverse 5 10 11 2 4 1.10 assembler 52 263 642 0 0 2.44 loader 30 82 125 2 2 1.52 sin) 14 2 8 1.70 Q6 \n44 pa~affhs 7 6 7 0 0 1.16 blocks? ~o 28 28 1 2 1.00 ubody 34 67 118 2 2 1.76 spa~se 28 76 121 0 0 1.59 \npug 41 69101 0 0 1.46 Table3: Static Interprocedural Measurements There are several interesting observations \nto be made from the results in Tables 3 and 4. The first is that for these benchmarks, the size of the \ninvocation graph does not, explode, and we can do a complete context\u00adsensit,ive analysis with reasonable \ncost. There are, how\u00adever, other benchmarks that do have very large invoca\u00adtion graphs, so we are exploring \nmore aggressive memo\u00adrization techniques for handling these programs, as dis\u00adcussed in Section 3. It \nis also interesting to note that a large number of procedure calls get memoized, even with our simple \nscheme, that only reuses output values when the same invocation node is visited with aprevi\u00adously computedinput. \nFinally, it can be observed from Table 3 that majorityof the benchmarks, have recur\u00ad Program Calls Analyzed \nAvf AYC A\\ i Tot Mem Act 12 47 ~,~~ xref 60 13 47 5.88 3.36 3.13 bintree 59 1.51 1.-17 !11 [11 11 misr \n7 010 1.40 1.00 1.00 II 111111 chomp 390 196 194 II 9.70 4.13 I 1.98 stanford 36 6 30 3.75 2.50 2.31 \n1[I 1[1 11 hash 11 1 10 2.00 1.25 1.25 ,[II11 11 power 112 \\ 49 I 63 3.50 2.03 1.19 reverse 16 36 3.60 \n5? 7,2(J ~,~~ l,~lj l,jg paraffins 9 0 9 1.50 nbody 252 42 210 6.17 3.13 1,78 assembler 1057 221 836 \n16.08 3.18 1.30 Table4: Dyllalllic Illterproced~lral hIeasuremr]lts sive and approximate invocation \ngraph nodes. SIuC.e most of these programs use recursive data structures, they also employ recursion \nas traverse and modify them. useful, any shape aualysis must analysis, and it must handle safe and accurate \nmarmer, the control structure to This implies that to be handle interprocedural recursive programs iu \na 5 Conclusions and Future Work In this paper we have preseuted an analysis that al.>\u00ad proximate the \nshape of dynamic data structures in C programs. Shape analysis is part of a hierarchy of pointer analyses \nimplemented in the Mc(3AT C c,onl\u00adpiler, and it is directed at programs that use simple recursive data \nstructures that are built ally. The analysis has been completely and tested on 16 benchmark programs. \nmental results show that it does provide sults for the those programs that build structures. Thus, for \nprograms building composition implemented The experi\u00adaccurate re\u00adsimple data lists, trees, and arrays \nof lists or trees, we can often providt; useful information for optimization and parallelizatiou. For \nprograms that make major structural changes to the data structure, our shape abstraction is uot pow\u00aderful \nenough to give accurate results, although the re\u00adsults will be safe. Other aualyses can haudle solne \nof these cases [3, 5, 17, 30], but they are substantially more complicated and more difficult, to implement \niu real compilers. Our approach is to use the cheapest and simplest analysis possible for each program \nunder consideration, Thus, if the program fits into the target class for our shape analysis, we will \nuot apply a 111oM expensive or complex analysis. We plan to level-3 analysis tion abstraction on the \npath ces [17]) and that abstracts extend our shape analysis to create the in our hierarchy by enriching \nthe direc\u00ad to keep information about the first link (a partial implementation of path matri\u00adby using \na more complex attribute matrix tbe shape of the data structure with re\u00ad spect to certain links. It \nis hoped that this analysis will be able to handle structures like leaf-linked trees, trees with parent \npointers, and to also improve upon the accuracy of the information in the face of structural updates \nby giving better kill information. Based on the positive results from the experiments presented in this \npaper, we also plan to apply all of our heap analyses to larger programs and to continue our development \nof more efficient interprocedural strate\u00adgies, References [1] J. Choi, M. Burke, and P. Carini. Efficient \nflow-sensitive interprocedural computation of pointer\u00adinduced aliases and side-effects. In Conference \nRecord of the Twentieth Annual ACM SIGPLAN-SIGACT Symposzurn on Principles of Programming Languages, \npages 232-245, January 1993. [2] A. Rogers, M. C. Carlisle, J. H. Reppy, and L. J. Hendren. Supporting \ndynamic data structures on distribated-mernory machines. A CM Transactions on Programming Languages March \n1995. [3] D. R. Chase, M. Wegman, of pointers and structures. PLAN 90 Conference on sign and implementation, \nund Systems, 17(2):231-263, and F. K. Zadeck. Analysis In Proceedings of the SIG- Programming Language \nDe\u00ad pages 296 310, June 1990. [4] A. Deutsch. A storeless model of aliasing and its ab\u00adstractions using \nfinite representations of right-regular equivalence relations. In Proceedings of the 1992 ln\u00adternationol \nConference on Computer Languages, pages 2 13, April 1992. IEEE Computer Society Press. [5] A, Deutsch. \nInterprocedural may-alias analysis for pointers: Beyond k-limiting. In Proceedings of the .4 CM SIGPLA \nN 94 Conference on Programming Lan\u00adguage Deszgn and Implementation, pages 230 241, June 1!)94. [6] M. \nEmami, R. (lhiyaj and L. J. Hendren. Context\u00adsensitive iuterprocedural points-to analysis in the pres\u00adence \nof function pointers. In Proceedings of the ACM SIGPL.4 N 94 Conference on Programming Language Deszgn \nand Implementation, pages 242-256, June 1994. [7] A. M. Erosa and L. J. Hendren. Taming control flow: \nA structured approach to eliminating goto statements. In Proceedings of the 19.$14International Conference \non [:onlPtlter Languages, Pages \u00ad~29 240, May 1994. [8] VI. Emami. A practical interprocedural alias \nanalysis fol au optimizing/parallelizing C compiler. Master s thesis, McGill University, July 1993. \n[9] E. Gagnon. A fast-forward and lazy points-to analysis, ACAPS P~oject Report 19$)5,622 B,03, hIc(iill \n(lnl\\Jer\u00adsity, May 1995. [10] R. Ghiya and L. J. Henrlren, Connection analysis: A practical interprocedural \nheap analysis for C. In Proceedings of the Etght Workshop on Lungucrgesund Compilers for Parallel Cotllptlting,Allgt{st \n1995. [11] R. Ghiya. Practical techniques for interprocedural heap analysis. Master s thesis, School \nof Computer Science, McGill University, May 1995. [12] W. L. Harrison III. The interprocedural analysis \nand automatic parallelization of Scheme progralns, Lwp and Symbolzc Computatzors, 2(3/4):179 396, 1989, \n[13] L. Heudren, C. Douawa, hI. Emami, Cr. Gao, Jus\u00adtiani, and B, Sriciharau. Desiguillg the klccAT conL\u00adpiler \nbased on a family of structured interlllediat,e rep\u00adresentations. In Proceedings oj the 5thInternc{tr \no~~al Workshop on Languages and Compders for Parallel Computing, number 757in Lecture NotesinConll>ute~ \nScience, pages 406 420, August 1[)92. Springer-t;ellag. Published in 1993. [14] L. J. Heudren, M. Emami, \nR. Ghiya, and C. \\~er\u00ad brugge. A practical context-sensitive interprocednral analysis framework for C \ncompilers, .4 C,4PS Technical Memo 72, School of ComputerScience, illc(;illITni\\e~\u00adsity, July 1993. \n[15] L. J. Hendren and G. R. Gao. Designing piogrammiug languages for analyzability: A fresh look at \npointer data structures. In Proceedings of the 1992 I!lterna\u00adtional Conference on Computer Languages \njpages?42\u00ad251, April 1992. IEEE Computer Society Press. [16] L. J. Hendren, J. E. Hummel, and A. Nicolau. \nAb\u00adstractions for recursive pointer data structures: In~\u00adproving the analysis and transformation of imperative \nprograms. In Proceedings of the .4CM SIG PL.4N 92 Conference on progr anzm~ng Language De.s&#38;gn ctnd \nII)(,. plernerstation, pages 249 260, June 1992. [17] L. J. Hendren and A. Nicolau. Paralleliziug programs \nwith recursive data structures. IEEE Tran.sactlons on Parallei and Distrzbated Sgstems, 1(1)::15-17, \n.lanuary 1990. [18] S. Horwitz, P. Pfeiffer, and T. Reps. Dependence anal\u00adysis for pointer variables. \nIn Proceedings of the SIG -PLAN 89 Cortfevence on Programming L[lnguageDe \u00adstgn and Implementation, pages \n28 40, June 1989. [19] N. D. Jones and S. S. Muchnick. Program Flow .4 nal~\u00adsis, Theorg and Applications, \nchapter 4, Flow Analysis and Optimization of LISP-like Structures, pages IL)2 131. Prentice-Hall, 1981. \n [20] N. D. Jones and S. S. M uchnick. A flexible approach to interprocedural data flow analysis and \nprogralus \\vit h recursive data structures. In C~onference Record of the Ninth Annual ACM SgmposIunl \non Pr(nczples of Programming Languages, pages 66-74. .January 1982. ACM SIGACT and SIGPLAN. [ 1] N. Klarlund \nancl M. Schwartzbach. C+raph types. In Conference Record of the Twentieth An naal A (7h1 SIGPL.4 N-SIGA \nCT .$gmpostum on Principles of Pro\u00adgramming Languages, pages 196 205, January 1993. [~Q J. R, Larus. \nCompiling Lisp programs for parallel exe\u00adcution. Lisp and Symbolic Computation, 4:29 99, 1991. p~] J. \nR. Larus and P. N. Hilfiuger. Detecting conflicts between structure accesses. In Proceedings of the SIG\u00adPL.4 \nN 88 Conference on Programming Language De\u00adstgn and Implementation, pages 21 34, June 1988. [24] J. R. \nLarus and P. N. Hilfinger. Restructuring Lisp programs for concurrent execution. In Proceedings of the \n.4 CM/SIGPLA N PPEA LS 1988 Parallel Pro\u00adgramming: Experience with Applications, Languages ancl Systems, \npages 100 110, July 1988. [25] S. Lummetta, L. hlurphy, X. Li, D, Culler, and 1. Khalil. Decentralized \noptimal power pricing. In Pro\u00adceechngs of Supercomputtrrg 93, pages 243 249, Novem\u00adber 1993. [26] W. \nA. Landi and B. G. Ryder. A safe approximate algorithm for interprocedural pointer aliasing, In Pro\u00adceedings \nof the ACM SIGPLA N 9.2 Conference on Programming Language Desi~n and Implementation, pages 235 248, \nJune 1992. [27] J. Plevyak, A. Chien, and V. Karamcheti. Analysis of dynamic structures for eflicient \nparallel execution. In Proceedings of the 6th International Workshop on Lan\u00adguages and Compilers for \nParallel Computing, number 768 in Lecture Notes in Computer Science, pages 37\u00ad56, August 1993. Springer-Verlag. \nPublished in 1994. [28] T. Reps. Shape analysis as a generalized path problem. In Proceedings of the \nACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Ma\u00adnipulcdion (PEPM), pages 1 \n11, June 1995. [29] E. Ruf. Context-insensitive alias analysis reconsidered. In Proceedings of the ACM \nSIGPLA N 95 Conference on Programming Language Design and Implementat\u00adion, pages 13-22, June 1995, [30] \nM, Sagiv, T. Reps, and R. Wilhelm. Solving shape\u00adanalysis problems in languages with destructive updat\u00ading. \nIn Conference Record of the Twenty Third Annual ACM SIGPLAN-SIGA CT Symposium on Principles of Programming \nLanguages, January 1996. [31] B. Sridharan. An analysis framework for the McCAT compiler. Master s thesis, \nMcGill University, Septem\u00adber 1992. [32] B. Steensgaard. Points-to analysis in almost linear time. In \nConference Record of the Twenty Third An\u00adnual .4 Cilf SIGPL.4 N-SIGA CT Symposium on Princi\u00adples of Programming \nLanguages, January 1996. [:33] R. P. Wilson and M. S. Lam. Efficient context-sensitive pointer analysis \nfor C programs. In Proceedings of the ACM SIGPLA N 95 Conference on Programming Lan\u00adguuge Design and \nImplementation, pages 1 12, June 1995,  \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "Rakesh Ghiya", "author_profile_id": "81100605741", "affiliation": "School of Computer Science, McGill University, Montr&#233;al, Qu&#233;bec, Canada H3A 2A7", "person_id": "P238209", "email_address": "", "orcid_id": ""}, {"name": "Laurie J. Hendren", "author_profile_id": "81100646110", "affiliation": "School of Computer Science, McGill University, Montr&#233;al, Qu&#233;bec, Canada H3A 2A7", "person_id": "P169482", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.237724", "year": "1996", "article_id": "237724", "conference": "POPL", "title": "Is it a tree, a DAG, or a cyclic graph? A shape analysis for heap-directed pointers in C", "url": "http://dl.acm.org/citation.cfm?id=237724"}