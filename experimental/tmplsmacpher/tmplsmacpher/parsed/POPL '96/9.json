{"article_publication_date": "01-01-1996", "fulltext": "\n On the complexity of beta-reduction Andrea Asperti Dipartimento di Matematica P.zza di Porta S. Donato \n5, Bologna, Italy asperti@cs. unibo.it Abstract We prove that the complexity of Lamping s optimal graph \nreduction technique for the A-calculus can be ex\u00adponential in the number of L6vy s family reductions. \nStarting from this consideration, we propose a new mea\u00adsure for what could be considered as the intrinsic \ncom\u00adplexity of A-terms.  Introduction Twenty years ago, L&#38;Jy [Le78] introduced the notion of redez \nfamikj to formalize the intuitive idea of optimal sharing in the J-calculus (see also [Le80, AL93]). \nAs a main consequence, the length of the family reduction would provide a lower bound to the intrinsic \ncomplexity of A-term reduction, in any possible implementation. In 1990, Lamping [Lam90] discovered a \ncomplex graph reduction technique that was optimal in L&#38;Ty s sense (that is, all sharable redexes \nhad a unique graphical rep\u00adresentation, and could be reduced in a single atomical step). However, Lamping \ndid not establish any com\u00adplexity relation between his algorithm and the lenght of the corresponding \nfamily reduction. In this paper, we prove that Lamping s technique can be exponential with respect to \nthe number of redex families reduced along the computation. This fact does not con\u00adtradict neither the \noptimality of the algorithm, nor its relevance in view of an actual implementation (as a mat\u00adter of fact, \nthe examples where Lamping s algorithm is exponential, are also the examples where it works better with \nrespect to more traditional implementation tech\u00adniques). On the contrary, we claim that the lenght of \nthe family reduction is not a reasonable lower bound to the intrinsic complexity of J-terms, and we shall \npropose a different complexity measure. Permission to make digital/hard copies of all or part of ttda \nmaterial for peraoml or classroom use is granted without fee provided that the copies are not made or \ndtatributed for profit or commercial advantage, the copY\u00ad right notice, the title of the publication \nand its date appear, and notice is given that ~opyright is by permission of the ACM, Inc. To copy orheruk% \nto republish, to post on servers or to redistribute to lists, requires apecitic permission andlor fee. \nPOPL 96, St. Petersburg FLA USA @ 1996 ACM @89791 _769-3195\\Ol ..$3 .5(3 2 Lamping s graph reduction \ntechnique Lamping s graph rewriting rules can be naturally clas\u00adsified in two main groups: 1. the rules \ninvolving application, abstraction and sharing nodes (fan), that are responsible for ~\u00adreduction and \nduplication (we shall call this group of rules the abstract algorithm); 2. some rules involving control \nnodes (square brackets and croissants), wh~ch are merely required for the correct application of the \nfirst set of rules.  More precisely, the first set of rules requires an oracle to discriminate the correct \ninteraction rule between a pair of fan-nodes; the second set of rules can be seen as an effective implementation \nof this oracle. This distinction looks particularly appealing since all different translations proposed \nin the literature after Lamping [GAL92a, GAL92b, As94, As95] differ from each other just in the way the \noracle is implemented (in the sense that all of them perform exactly the same set of abstract reductions). \nIn this paper, we shall prove that Lamping s technique can be already exponential in its abstract algorithm, \nwithout considering the extra work required by the or\u00ad acle. For this reason, we shall introduce here \nLamping s tech\u00adnique without mentioning the possible solution to the effective implementation of the \noracle. 2.1 Initial translation Initially, in the optimal graph reduction technique, a A-term is essentially \nrepresented by its abstract syntax tree (like in ordinary graph reduction). There are two main differences, \nhowever: 1. we shall introduce an explicit node for sharing; 2. we shall suppose that variables are \nexplicitly con\u00adnected to their respective binders.  110 For instance, the graph in Figure l.(l) is \nthe initial representation of the A-term M = (two 6), where two= Jz.Ay. (z(zg)) and6=Az.(m z). The triangle \n(we shall call it fun) is used to express the sharing between different occurrences of a same variable. \nAll variables are connected to their respective binders (we shall always represent this connection on \nthe left of the connection to the body). Since multiple occurrences of a same variable are shared by \nfans, we shall have a single edge leaving a J towards its variables. So, each node in the graph (Cl, \nJ and fan) has exactly three dis\u00adtinguished sites (ports) where it will be connected with other ports. \n 2.2 Reduction We shall now illustrate the main ideas of Lamping s optimal graph reduction technique \nby showing how a simplified version of the algorithm would work on our sample term (two @. As we shall \nsee, a crucial issue will remain unresolved. This is exactly where the oracle comes in: however, since \nthe complexity of the oracle is not necessary to prove the exponential nature of Lamp\u00ading s algorithm, \nwe shall not discuss this complex topic here. Lamping s algorithm consists of a set of local graph rewriting \nrules. At a given stage of the computation, we can usually have several reducible configurations in the \ngraph. In this case, the choice of next rule to ap\u00adply is made non-deterministically. This does not mat\u00adter \nthat much, since the graph rewriting system is an Interaction Net in Lafont s sense [Laf90], and it satis\u00adfies \na one-step diamond property (that implies not only confluence but also that, if a term has a normal form, \nall normalizing derivations have the same length). In particular, we shall usually choose the next rule \nin our example of reduction according to a didactical criterion (and sometimes for graphical convenience). \nThe most important of the graph rewriting rules is obvi\u00adously /3-reduction: (ku.itf N) + M [N/z]. In \ngraph re\u00adduction, substituting a variable z for a term iV amounts to explicitly connect the variable \nto the term N. More\u00adover, the value returned by the application before the redex is fired (the link above \nthe application) becomes the (instantiated) body M of the function. Since the portions of graph representing \nM and N do not play any role in the graph reduction corresponding to the@ rule, this reduction can be \nexpressed by the completely local graph rewriting rule in Figure 2. By firing the outermost /3-redex \nin (two 6), we get the graph in Figure 1.(2). Since the next redex involves a shared ~-expression, we \nmust eventually proceede to the duplication of 6. In ordinary graph reduction, this du\u00ad (1) (2) (3) k \nA ~ (6)(4) (5) I ! / / .... ,, .. ,,, ~,, ;, / $ ...... Y 7 Yf ..... ~, A,,, $,, ; :b: t:, ., ,,? \n%... J !!? (9)(7) (8) Figure 1: Graph reduction of (two 6) Figure 2: the @-rule plication would be \nperformed as a umque, global step on the shared piece of graph. On the contrary, the op\u00adtimal graph reduction \ntechnique proceedes in a more lazy way, duplicating the external A but still sharing its body. However, \nsince the binder has been duplicated, we are forced to introduce another fan on the edge lead\u00ading from \nthe binder to the variable. In a sense, this fan works as an %nsharing) operator (fan-out, usually de\u00adpicted \nupside-down ), that is to be paired against the fan(-in) sharing the body of the functionl. Since the \nbody of the function Ax .M does not play any role in this reduction, it can be formally expressed as \na local interaction between a fan and a }, as described in Figure 3. Let us now proceede in the analysis \nof our example. Figure 3: Fan-A interaction By applying the fan-a interaction rule, we get the graph \nin Figure 1.(3). Now, two /?-redexes have been created, and by their firing we are lead to the graph \nin Figure 1.(5). We have no more ,@redexes in the graph, and no fan-a interactions, so we must proceede \nin the dupli\u00adcation process, but we must be very carefully here. In particular, the following graph rewriting \nrule is strictly x-w Figure 4: not optimal duplication of the application forbidden, in the optimal imlementation \ntechnique (al\u00adthough semantically correct ). The intuition should be clear: since the shared application \ncould be involved in some redex, its duplication would imply a double exe\u00adcution of the redex. The only \nother possible interaction is between the two fans inside the dotted region. This is another crucial \n1 Although there is no operational distinction between a fan-in and a fan-out, their intutive semantics \nis quite different; in partic\u00adular, keep in mind that a fan-out is always supposed to be paired with \nsome fan-in in the graph, delimiting its scope and annihilat\u00ad ing its sharing effect. The way the correct \npairing bet ween fans is determined is a crucial point of the optimal graph reduction technique, solved \nby the oracle . Obviously, in order to give a precise definition of the abstract algorithm we should \nprovide the formal definition of the oracle, that is very complex and would just obscure the intuitive \nnatnre of the abstract rules. In particu\u00ad lar, the obvious and naive idea of labeling fans does not work \n(see [Lam89]). point of the optimal graph reduction technique. As we shall see, this interaction must \nbe handled in a differ\u00adent way form the similar interactions in Figure 1. ( 7). Note in particular that \nthe two fans in Figure 1.(5) are not paire&#38;: the fan-in is a residual of the shared vari\u00adable of \n6, while the fan-out is a residual of the shared variable of two, in the process of duplicating 6. Since \nthe two fans have nothing to do with each other, they must duplicate each other, according to the rule \nin Fig\u00adure 5.(2). Now (see Figure l.(6)), we have a fan-out absb #b . . e dcd cd cd [1) (2) Figure 5: \nfan-annihilation rule in front of the function-port of the application. In this case, we can apply the \nfollowing rule: Intuitively, this Figure 6: fan-@ interaction rule is correct from the point of view \nof optimal sharing since such a configuration already implies the existence of two unshakable (class \nof) redexes for the application. After firing this rule, we get the graph in Figure l.(7). In this case, \nboth pairs of fans are paired: they both be~ long to the same duplication process , that has been now \n(locally) completed. So, the obvious rule, in this case, is to annihilate the paired fans, according \nto Fig\u00adure 5.(l). The problem of deciding which rule to apply when two fans meet each other (that is \nthe question of how theii pairing is established) is the crucial point of the optimal implementation \ntechnique (solved by the oracle). By a double application of this rule, we get the graph in Figure 1.(9), \nthat is in normal form w.r. t. Lamping s algorithm. 3 complexity Before discussing the complexity of \nLarnping s ah: stract algorithm, we should start by fixing a few pre\u00adliminary assumptions. First of all, \na typical feature of optimal techniques is that of anticipating work that could become usefull only later \non in the computation. A reasonable way to take into account this extra work is that of restricting the \nanalysis to A-terms whose nor\u00admal form is an atomic constant (or, if you prefer, a variable). This hypothesis \nalso allows us to avoid some obviously degene~ate examples. Consider for instance the term P = Az.Ay. \n(y z z). If we apply P to a closed term M in normal form, M gets fully duplicated, and the cost of the \n@redex would seem proportional to the size of M. However, this reasoning does not seem convincing, since \nin duplicating M we also duplicated all its A and application nodes (its prerequisite chains, in Lamping \ns terminology), which (whenever turned to redexes), would eventually belong to distinguished fam\u00adilies! \nSo, we just anticipated work that had to be done in any casez. Our second assumption will be to consider \nonly terms of the ~-I calculus. The reason, here, is that the cor\u00adrect handling of garbage collection \nin optimal reduction techniques is still a subject of investigation (in particu\u00adlar, Lamping s approach \ndoes not seem to be completely satisfactory). We shall now provide an example of a A-term satisfying \nour assumptions, whose abstract reduction (i.e. with\u00ad out considering the extra cost of the oracle) \nis already exponential in the number of family reductions. Since the example is quite complex, we shall \nproceede by con\u00adsidering a few auxiliary terms. Let us start with a simple case. In Figure 7 is a pos\u00adsible \nrepresentation of the Church Integer two in shar\u00ading graphs, obtained by reducing the l-term two = kc.~y. \n(h.(z(z y)) ~w.(z w)). Let us now consider the application of two to itself. Recall that the application \n(n m) of two church integers n and m gives the church integer mn, so the expected result is (a representaion \nof) the church integer four. The reduction is shown in Figure 8. The two first reduction steps are ,d-redex. \nAfter these reductions we are left with the term in Fig\u00adure 8.(3), where the sub term Jy. (z(z y)) is \nshared by means of the two copies of the fan marked a . Now, this subterm is fully duplicated. This \nprocess requires: 2 steps for duplicating the A and the application; 2 steps for duplicating the fans; \n3 steps for effacing all residuals of fans marked with a . After these 7 steps we are left with the \ngraph in Fig\u00adure 8.(4), where a new ~-redex has been put in evi\u00addence. Firing this redex, we obtain the \nfinal config\u00aduration in Figure 8.(5). Summing up, we executed 3 2The idea of considering only those rules \nwhich are needed to put in evidence new redexes gives some problems due to the un\u00adpredictable disposition \nof fans inside a virtual redex: again, if all copies of prerequisite chains generated by the duplication \nare not fired along the computation, we could perform some (appar\u00adently) useless work. Figure 7: two \n: a representation of Church s integer two   //&#38;~ two two (1) (2) (3) (4) (5) Figure 8: the reduction \nof (two two ) /3-reductions (actually, family reductions), and 7 fan-fans marked with a is now fully \nduplicated. This du\u00ad interactions. Note moreover that the final configuration plication requires: 2 steps \nfor duplicating the A and the has the same shape of the initial one. application; 2n steps for duplicating \nfans; n+2 steps for Let us now generalize the previous example. As should effacing fans. This gives a \ntotal of 4 + 3n operations. be clear, the church integer 2n can be represented by the After these reductions, \nwe get the configuration in Fig\u00adgraph in Figure 9, where we have exactly a sequence of ure 11. A new \nfl-redex has been created. 13y firing this the term (g n) is Figure 9: a representation of 2n fan-in \nof length n and a corresponding out of the same length. Let us now apply this term to itself. outermost \n~-redexes we get the term sequence By firing in Figure of fan\u00adthe two 10. As Figure 11: the reduction \nof (2n 2n) redex we obtain the graph in Figure 12. Now, this graph has the same shape of the graph in \nFigure 10, and we can iterate our reasoning. In particular, the duplication of the innermost part of \nthe graph will now require 4 + 3* (2n) operations. Then, we shall have a new /3-redex, and by its firing, \nwe shall get a graph of the same shape of Figure 12 but where the innermost sequences of fans have length \n4n (this length is doubled at every iteration of the process), while the length of the outermost se\u00ad \nquences is decremented by one. Figure 10: the reduction of (2n 2n) Summing given by. up, the total number \nof fan-interactions is in the case of two, the portion of graph inside the two ({4+3n)+(4+3*(2n) )+(4+3 \n*(4n))+. . .+(4+3 *(2n- n))) f(rl)=9+3*n+~bi i=o Finally, let us consider the number of fan-interactions. \nFor each application of (6 ai), we have 1 + 4 + 3 * bi in\u00adteractions for duplicating a,, plus bi + 3 \n* b,+l operations in the reduction of (a~ ai) (recall that b~+l = bi * 2b~). Moreover, we have one single \noperation internal to two , 5 * (n 1] operations for creating all copies of 6, and bn final operations \nof fan-effacement when we apply the external parameters. Summing up, the number c(n) of fan-interactions \n(for n > 0) is given by the formula n-1 n c(n)= 10*n 4+4*~bi+ 3*~bi+bn i=O i=l n 1 = 10*n+7* ~bi+4*b. \n>4 *b. Figure 12: the reduction of (2n 2n) 2=1 Note now that 2~::01 b = b.. So, n-1 = 4n+3n*~2i =4n+3n*(2 \n1)= n*(3*2n+l) i=o For n z 3, it is easy to show that 29+3 < 2s*bn. Hence: In contrast, we have executed \njust n @-reductions in the 2f(nJ < 28* b: < 24* c(n)z. main loop, plus two at the very beginning, for \na total of n + 2 family reductions. and finally (for any n z 3) Our final problem consists in providing \nan example based on the terms above which satisfies our auxiliary assumptions mentioned at the beginning \nof this section (i.e. it should be a term of the J-I-calculus, whose nor-We can also easily prove that, \nfor any n, c(n) s 2f(n~. mal form is an atomic constant). O% ;ne side we have 2ff l > 29* b~. On the \nother side, The term we consider is: g = An. (n 6 two 1 q), where ~i~O hi 5 h. and obviously n s b., \nso 6 = Az.(fiz), two = kz.Ag, (Az. (z(z y)) Aw. (m w)), I is the identity and q is some constant. If \nn is a church in-c(n) < 21 *bn < 29 *b~ < 2f(n) teger, (g n) obviously reduces to q. The term (n 6 two \n) is a real monster , from the complexity point of view. 3.1 The Bologna Optimal Higher-order As a function \nof n, it corresponds to the church integer Machine an, in the succession ao = 2; ai+l = a~i. For instance, \na3 = 256256. Let us now consider the number of family The previous formulas have been also experimentally \nreductions. When we apply g to the Church integer O, confirmed by our prototype implementation of (a \nvari\u00adwe perform 9 family reductions (one for the application ant of) Lamping s algorithm: the Bologna \nOptimal of g, two for the application of O, three internal to two , Higher-Order Machine (BOHM)3. BOHM \n[AGN95] is and three for the extra-identities). These operations are a simple interpreter written in \nC. Its source language is constant for each input n of the function g. Let us now a sugared A-calculus \nenriched with booleans, integers, compute the cost for each application of (6 ai). This is lists and \nbasic operations on these data types. The ex\u00ad1 plus the number of family reductions for (ai ai) com-tension \nof Lamping s technique to this language is essen\u00adputed in the previous section, namely 2 + log(ai). Note \ntially based on Asperti and Laneve s work on Interaction that the succession b~ = Jog(u, ) can be equally \ndefined 3 BOHM is available by anonymous ftp at ftp .cs.unibo.it, in the asb. = l; bi+l = bi*2b; . directory \n/pub/ asperti. Get the file BOHMI .O.tar.Z (compressed Summing up, the number of family reductions ~(n) \nfor tar format). Systems [AL93b]. In particular, all syntactical opera\u00adtors are represented as nodes \nin a graph. These nodes are divided into constructors and destructors, and re\u00adduction is expressed as \na local interaction (graph rewrit\u00ading) between constructor-destructor pairs. BOHM is lazy (in the sense \nthat it always reduces the fumily of the leftmost outermost redex) and weak (that is, it stops computing \nas soon as the top node in the graph is a constructor). As a consequence, BOHM sup\u00adports lazy data structures, \nsuch as streams. Due to its prototyping nature, BOHM has been espe\u00adcially designed to provide a large \nnumber of experimen\u00adtal data relative to each computation (user and system time, total number of different \nkinds of interactions, storage allocation, garbage collection, and so on). The results of the computation \nof the function g of the pre\u00advious section are shown in figure 13. The four columns Input user tot. inter. \nfam. fan-inter. (g zero) 0.00 s. 38 9 2 (g one) 0.00 s. 64 13 18 (g two) 0.00 s. 200 18 66 (g three) \n15.90 s. 2642966 29 8292 Figure 13: The function g in the table are, respectively, the user time required \nby the computation (on a Spare-station 5), the total num\u00adber of interactions (comprising the oracle ), \nthe length of the family reduction (app-lambda interactions), and the total number of fan-interactions. \nIt is also possible to find examples of exponential ex\u00adplosion whith respect to a /inear grow of the \nnumber of family reductions. An interesting case is provided by the J-term h = Jn.(n two two 1 q). Using \nthe same technique of the previous section, it is easy to prove that, for this function, the number of \nfamily re\u00adductions ~(n) grows linearly in its input n (in particular, ~(n) = 9 + 3 * n), while the number \nof fan-interactions c(n) is given by the formula c(n)= 12*n 2+4*2 In particular, for any n, In the table \nof Figure14, you will find the experimental results in BOHM. In this case, we also make a compar\u00adison \nwith two standard (respectively, strict and lazy) implementations such as CamI-Light and Yale Haskell. \nCamlLight [LM92] is a bytecoded, portable implementa\u00adtion of a dialect of the ML language (about 100K \nfor the runtime system, and another 100K of bytecode for the compiler, versions for the Macintosh and \nIBM PC are also available) developed at the INRIA-Rocquencourt (France). In spite of its limited dimensions, \nthe per\u00adformance of CamlLight is quite good for a bytecoded implementation: about five times slower than \nSML-NJ. We used CamlLight v. O.5. Yale Haskell [Ya94] is a complete implementation of the Haskell language \ndeveloped at Yale University. The Haskell compiler is written in a small Lisp dialect similar to Scheme \nwhich runs on top of Common Lisp. Haskell programs are translated into Lisp, and then compiled by the \nunderlying Lisp Compiler. We used Yale Haskell Y2 .3b-v2 built on CMU Common Lisp 17f. The results of \nthe test should give a gist of the power of the optimal graph reduction technique. In general, the relative \namount of fan-interaction rules with respect to the number of family reductions in a computation looks \nrelated to the amount of sharing in the term. So, the cases where Lamping s algorithm is exponential \nin the number of family reductions are also the cases where the performance of BOHM is so amazingly better \nwith respect to convential implemen\u00adtations. The worse cases for BOHM are when Lamping s abstract algorithm \nis /znear in the number of families. However, also in these cases, its performance is not as bad as one \ncould expect: BOHM is always five to ten times better than the Yale Haskell interpreter, and it is often \ncomparable with the Yale Haskell compder. As an example, in Figure 15 we give the experimental re\u00adsults \nabout the computation of the Fibonacci function, defined in the obvious way. In this case, the number \nof family reductions is the total number of constructor\u00addestructor interactions. For Haskell, the fibonacci \nfunc\u00adtion has been compiled. 4 Discussion We proved that the complexity of Lamping s algo\u00adrithm can \nbe exponential in the number of family re\u00adductions. We conjecture that, under our assumptions (terms \nof the M-calculus reducing to a constant), this value should also also provide an upper bound to the \ncomplexity of what we called the abstract algorithm. More precisely, if ~ is the number of family reductions \nrequired for normalizing the term, we conjecture that the total number of reductions rules required by \nLamp\u00ading s abstract algorithm is alwasy less than 2f. This result looks difficult to prove, since nothing \nis known about the structure of graphs along a reduction (so, it is not clear how to use induction). \nHowever, in our opinion, the real issue is of a differ\u00adent nature. In particular, the number of family \nreduc\u00adtions does not seem to provide a reasonable lower bound to the intrinsic complexity of a A-term. \nIntuitively, Input (h one) (h two) (h three) (h four) (h five) (h six) (h seven) (h eight) (h nine) (h \nten) user 0.00 s. 0.00 s. 0.00 s. 0.00 s. 0.00 s. 0.02 s. 0.07 s. 0.26 S. 1.01 s. 4.04 s. BOHM tot. inter. \n67 119 204 414 1054 3274 11534 43394 168534 664554 fam. 12 15 18 21 24 27 30 33 36 39 fan-inter. 18 38 \n66 110 186 326 594 1118 2154 4214 Carol-Light user 0.00 s. 0.00 s. 0.00 s. 1.02 s. ?? Haskell user 0.00 \ns. 0.02 s. 0.18 S. 51.04 s. ?? Figure 14: The function h -- Input (fib 4) (fib 8) (fib 12) (fib 16) (fib \n20) user 0.00 s. 0.02 s. 0.13 s. 0.80 S. 4.78 S. BOHM tot. inter. fam. 265 75 1991 506 13822 3462 94913 \n23723 650719 162594 fan-inter. 190 1485 10360 71190 488125 Carol-Light user 0.00 s. 0.00 s. 0.01 s. 0.03 \ns. 0.23 S. Haskell user 0.00 s. 0.01 s. 0.06 S. 0.38 S. 3.63 S. Figure 15: Fibonacci Lamping s abstract \nalgorithm does not seem to perform any useless operation. Our claim is that the total numb\u00ad er of these \nrules, instead of the number of family reduc\u00adtions, would provide a more reasonable and interesting measure \nof the intrinsic complexity of a A-term. More precisely, we propose to count the total number of anni\u00adhilation \nrules between fans (plus the number of family reductions). Note that, under our assumptions, the two \ncomplexity measures above turn out to be equivalent (if the term reduces to a constant, all fan, application \nand ~ nodes have to be annihilated, soon or later). More precisely, consider a normalizing computation \nfor a term M of the M-calculus that reduces to a constant. Let ~ be the number of family reductions in \nthe derivation, d be the number of duplication rules, e be the number of fan-annihilation rules, and \nIikf I be the total number of application, abstraction and fan nodes in M. Then, obviously, @fl+2*d 2*e-2*~=() \nSo, e+j=d+~. There are several motivations to support our claim. First of all, as it was remarked in \n[GAL92a], J and application nodes can be assimilated to fans, and the ~-reduction rule can be seen as \nan annihilation rule be\u00adtween a pair of fans. From this respect, there is no clear reason for giving \na special status to /?-redexes. The second point is subtler. Using context semantics, it is possible \nto prove that the annihilation rules between fans are in bijective correspondence with the number of \ndiscriminants for different @-cycles in the kterm4. [AL93, ADLR94]. Rouglhy, a @-cycle is a particular \nkind of looping path inside the argument of an applica\u00adtion. Now, every time we have a discriminant for \nsuch a cycle (i.e. the cycle is shared), we also have an extra and unavoidable operation that amounts \nto choose the proper discriminant when coming back from the loop. Following [DR95], this extra operation \n(that essentially amount to save a suitable return information in presence of a possible looping situation), \ncan be easily recognised in other typical implementation techniques, such as en\u00ad 4 The proof of the bijective \ncorrespondence between fan\u00adannihilations and discriminants for different @l-cycles will be the subject \nof a forthcoming paper in collaboration with Cosimo Lan\u00adeve. Not e that, in this way, we relate a dynamic \nnotion (an in\u00ad teraction) to a static one (et path), This result looks particularly relevant in view \nof complexity issues: computing the number of different paths of this kind is not easy, but it still \nlooks simpler than directly computing the number of fan-armihilat ions. vironment machines. Our complexity \nmeasure has been confirmed so far by all the tests we made on many available implementations of functional \nlanguages.  Conclusions There are a lot of interesting open problems related to optimal reductions. \nFirst of all, it looks important to provide a definite upper bound to the complexity of Lamping s abstract \nalgorithm in terms of family re\u00adductions. Secondly, we should understand the complex\u00adity of what we called \nthe oracle . The complexity of this part of the algorithm is actually very different in all the reduction \ntechniques proposed so far (see [As95] for a discussion), and it is still a subject of research. As you \ncan see by the few examples in BOHM (that is now quite sophisticated from this respect), the complexity \nof the oracle is one of the crucial issues of Lamping s technique. Although, in BOHM, it is clearly not \nlinear w.r. t. the number of applications of abstract rules, we have found no evidence so far of an exponential \nexplo\u00adsion of its complexity. Finally, from the implentative point of view, the big problem is to understand \nif and how Lamping s algo\u00adrithm could be compiled. Acknowledgements We would like to thank Cosimo Laneve \nfor many in\u00adteresting discussions on the subject of this paper. References [As94] A. Asperti. Linear \nLogic, Cornonads, and Opii\u00admal Reductions. Fundamental In formaticae, Special Issue devoted to Categories \nin Computer Science, Vol. 22, n.1, pp.3-22. 1995. [As95] A. Asperti. 60!E = 1: @timzzinO OPtimal J-calculus \nimplementations. Proc. of the Sixth Conf. on Rewriting Techniques and Applications, (RTA 95), Kaiserlautern, \nGermany. 1995. [AGN95] A. Asperti, C. Giovannetti, A. Naletto. The Bologna Opt imal Hzgher-order Machine. \nTechni\u00adcal Report UBLCS-95-9, Laboratory for Computer Science, University of Bologna. To appear in the \nJournal of Functional Programming. [AL93] A. Asperti, C. Laneve. Paths, Computations and Labels in the \nJ-calculus. To appear in Theo\u00ad retical Computer Science, Special issue devoted to RTA 93, Montreal. June \n1993. [AL93b] A. Asperti, C. Laneve. Interaction Systems II: the practice of opitmal reductions. Technical \nRe\u00adport UBLCS-93-12, Laboratory for Computer Sci\u00adence, University of Bologna. To appear in Theoret\u00ad ical \nComputer Science. [ADLR94] A. Asperti, V. Danos, C. Laneve, L. Reg\u00adnier. Paths in the A-calculus: three \nyears of com\u00admunications wzthoui understandings. Proceedings of LICS 94. Paris. 1994. [DR95] V. Danos, \nL. Regnier. Reversible and ir\u00adreversible Computations: GOI and J-machines. Draft. 1995. [GAL92a] G. Gonthier, \nM. Abadi, J.J. L&#38;ry. The geom\u00adetry of optimal lambda reduction. Proc. of the 19th Symposium on Principles \nof Programming Lan\u00adguages (POPL 92). 1992. [GAL92b] G. Gonthier, M. Abadi, J.J. L4vy. Linear Logic without \nboxes. Proc. of the 7th Annual Sym\u00adposium on Logic in Computer Science (LICS 92). 1992. [Laf90] Y. Lafont. \nInteraction Nets. Proc. of the 17th Symposium on Principles of Programming Lan\u00adguages (POPL 90). San \nFrancisco. 1990. [Lam89] J. Lamping. An algorithm for optimal lambda calculus reductions. Xerox PARC \nInternal Report. 1989. [Lam90] J. Lamping. An algordhm for optimal lambda calculus reductions. Proc. \nof the 17th Symposium on Principles of Programming Languages (POPL 90). San Francisco. 1990. [Le78] J.J.Levy. \nReductions correctes et opttmales duns le lambda-calcv,l. Th&#38;se de doctorat d &#38;at, Univer\u00adsit~ \nde Paris VII. 1978. [Le80] J. J. L&#38;y. Optzmal reductions m the lambda\u00adcalculus. In J.P. Seldin and \nJ.R. Hindley, editors, To H.B. Curry, Essays on Combmatory Logic, Lambda Calculus and Formalism, pages \n159-191. Academic Press. 1980. [LM92] X. Leroy, M. Mauny. The Carol Light system, release 0.5. Documentaiton \nand user s manual. IN-RIA Technical Report. September 1992. [Ya94] The Yale Haskell Group. The Yale Haskel/ \nUsers Manual. Yale University. October 1994. \n\t\t\t", "proc_id": "237721", "abstract": "", "authors": [{"name": "Andrea Asperti", "author_profile_id": "81100182775", "affiliation": "Dipartimento di Matematica, P.zza di Porta S. Donato 5, Bologna, Italy", "person_id": "PP39031355", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/237721.237742", "year": "1996", "article_id": "237742", "conference": "POPL", "title": "On the complexity of beta-reduction", "url": "http://dl.acm.org/citation.cfm?id=237742"}