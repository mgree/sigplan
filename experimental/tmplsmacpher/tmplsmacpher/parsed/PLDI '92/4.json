{"article_publication_date": "07-01-1992", "fulltext": "\n The Design a:nd Implementation of HoME Kazuhiro Ogat a, Satoshi Kurihara, Mikio Inari and IVorihisa \nDoi Department of Computer Science Grad uat e School of Science and Technology Keio University 3-14-1 \nHiyoshi, Kohoku-ku, Yokohama 223 Japan +81-45-561-2739 {ogata, kurihara, inari, doi}@doi.cs.keio. ac.jp \nAbstract HoME is a version of Smalltalk which can be efficiently executed on a multiprocessor and can \nbe executed in parallel by combining a Smalltalk process with a Mach thread and executing the process \non the thread. HoME is nearly the same as ordinary Sm alltalk except that multiple processes may execute \nin parallel. Thus, al\u00admost all applications running on ordinary Smalltalk can be executed on HoME without \nchanges in their code. HoME was designed and implemented based on the following fundamental policies: \n(1) theoretically, an in\u00adfinite number of processes can become active; (2) the moment a process is scheduled, \nit becomes active; (3) no process switching occurs; (4) HoME is equivalent to ordinary Smalltalk except \nfor the previous three poli\u00adcies. The performance of the current implernentation of HoME running on OMRON \nLUNA-88K, which had four processors, was measured by benchmarks which execute in parallel with multiple \nprocesses. In all benchmarks, the results showed that HoME s perfor\u00admance is much better than HPS on \nthe same worksta\u00adtion. Introduction Smalltalk [8] is not only an object-oriented pro\u00adgramming language, \nbut also a graphical, interactive programming environment. The concept of object\u00adoriented programming \nis very useful in developing soft\u00adware. It is well known that developing software in the Smalltalk environment \ncan increase its productiv- Permission to copy without fee all or part of this material is granted provided \nthat the copies are not made or distributeal for direct commercial advantage, the ACM copyright notice \nand the titla of the publication and its date appeer, and notice is given that copying is by permission \nof tha Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or \nspecific permission. ACM SIGPLAN 92 PLD1-6/92/CA @ 1992 ACM 0.8979 J.476-7/92/0006 J004.4... $J .!50 \nity. In ParcPlace Smalltalk-801 Version 2.5 and Re\u00adlease 4, which are both generally called HPS, the \nCPU directly executes the machine-code by translating byte\u00adcode into machine-code (n-code) during execution \n[6], resulting in high performance. Although processor technology, including processing speed, has been \nmaking steady advances, it seems dif\u00adficult to make a far reaching improvement in the speed of a single \nprocessor due to physical limitations. Such a far reaching improvement has been attempted by con\u00adnecting \nmultiple processors and load balancing, that is, making a workstation into a multiprocessor. Mul\u00adtiprocessor \nworkstations have already appeared in the marketplace. Operating systems in which multiproces\u00adsor workstations \ncan be efficiently used have been de\u00adveloped. Typical multiprocessor operating systems are Mach [18] \ndeveloped at CMU, and the V distributed operating system [4] developed at Stanford university. [n this \npaper, the design and implementation of a version of Smalltalk, called HoME (HPS on Mach En\u00advironment) \n[13], which can be efficiently executed on a multiprocessor are described. The multiprocessor used is \nthe shared-memory multiprocessor OMRON LUNA\u00ad88K. Mach is used as the underlying operating system and \nthe HPS of Smalltalk-80 Version 2.5 is used as the base Srnalltalk. It is necessary to introduce concur\u00adrency \ninto Smalltalk so that Smalltalk can be efficiently executed on a multiprocessor. The class Process is \npro\u00advided as the framework of concurrent programming in Sma!lta!k. An instance of the class Process, \nor a pro\u00adcess, is the basic unit of execution in Smalltalk. The con cept fight-weight process denotes \nmultiple threads of control within a single ordinary process. In Mach, light-weight processes are called \nthreads and the Mach kernel adopts threads as units of scheduling. Units of concurrent execution are \nthreads and multiple threads may execute in parallel on a multiprocessor. Since a Smrdlt alk process \nclosely resembles a light-weight pro\u00ad cess, it can be combined with a Mach thread, and con\u00adcurrent execution \nis realized by having the thread exe\u00ad . Smalltalk-80 is a trademark of ParcPlace Systems. cute the \nprocess. HoME is nearly the same as orcinary Smalltalkex\u00adcept that multiple processes maJ execute in \nparal\u00adlel. Thus, almost all applications mnning on ordinary SmaUt alk can be executed on HoME without \nchanges in their code. Section 2 briefly describes concurrent programming in Smalltalk. In section 3, \nfour fmndarnenttd design policies for HoME are given and kheir meanings are stated. In section 4, the \nimplemmt at ion details are explained: namely, synchronization bet ween threads, management of regions \nfor n-code, garbage collecticm, modified and newly added methods and so on. Sec\u00adtion 5 shows performance \nmeasurements of the current implementation of HoME running cm OMRON LUNA\u00ad88K and compares them with those \nof HPS on the same workstation. Section 6 discusses work related to this research and compare HoME with \nother concur\u00adrent Smallt alk. Concurrent programming in HoME is discussed in section 7. Section 8 states \nthe future wcmk and lastly the conclusions are stated. 2 Concurrent Programming in Smalltalk The classes \nProcess and Semaphore can be used to program concurrency in Smalltalk [7]. In this section these classes \nare explained and a simple program is il\u00adlustrated. 2.1 Class Process In Smalltalk, the class which represents \nindependent threads of control is Process. Processes are created by sending a fork, forkAt:, newProcess \nor newProcess- With: message to a block expression (which is enclosed by [ and ] ). A process created \nby fork or forkAt: is placed in a scheduled state, while one created by new-Process or newProcess With: \nis placed in a suspended state. A suspended process is scheduled by sending it a resume message. There \nis only one process which can actually execute at a given time, and it is said to be active. Processor, \nwhich is the only instance of the class ProcessorSched\u00aduler, is used to select one of the scheduled processes \nand make it active. An FCFS (First-Come-First-Serve) ready queue with priorities is used for selecting \nan ac\u00adtive process. More precisely, a multi-queue scheduling algorithm which uses an FCFS ready queue \nfor each priority is adopted. That is, the higher the priority of a process, and the longer it has waited \nfor a processor, the sooner it becomes active. Once a process becomes active, it stays active unless \na process with higher pri\u00adority is scheduled or it yields the processor itself. When a process with higher \npriority than an active process is scheduled, the newly scheduled process preempts the processor. 2.2 \nClass Semaphore The class Semaphore is used for synchronizing multiple processes. A semaphore is created \nby sending a new or forMut ualExclusion message to the class Semaphore. A semaphore created by new has \nO as its semaphore value, and one created by forMut ualExclusion has 1. The P-operation is performed \nby sending a wait mes\u00adsage to a semaphore and the V-operation is done by sending a signal message. Since \na semaphore is a count\u00ading semaphore whose value is a non-negative integer, when a V-operation is performed \nbefore a P-operation, the semaphore value is recorded. When a wait message is sent to a semaphore, if \nthe semaphore value is positive, the value is simply decre\u00admented. If the value is zero, a process executing \nthe wait method, the active process, is appended to the tail of the semaphore queue and an appropriate \nprocess among the scheduled processes is made active. When a signal message is sent to a semaphore, if \nthe semaphore queue is empty, the semaphore value is simply incre\u00adment ed. If the queue cent ains one \nor more processes, the process with the highest priority and the longest waiting time in the queue is \ndequeued and is sched\u00aduled. 2.3 Example A program which creates two processes, where one prints the \nstring DOG 20 times and the other prints the string CAT 20 times, is as follows: I lock I lock + Semaphore \nforMutualExclusion. [20 timesRepeat: [ lock wait. Transcript show: DOG . lock signal. ]] fork. [20 timesRepeat: \n[ lock wait. Transcript show: CAT . lock signal. ]] fork   3 Design Policy HoME was designed and implemented \nbased on the following fundamental policies: 1. Theoretically, an infinite number of processes can become \nactive. 2. The moment a process is scheduled, it becomes active. 3. No process switching occurs.  \n4. HoME is equivalent to ordinary Smalltalk except for the three policies described above, The first \npolicy implies that a great number of pro\u00adcesses can run in parallel, and there is no limit to the number \nof processes. Only one process can actually execute at one time in ordinary Smalltalk, while the number \nof processes actually executing at one time is unlimited in HoME. In ordinary Smalltalk, when a suspended \nprocess is sent a resume message, it may not start executing im\u00admediately. The process is usually placed \nin a sched\u00aduled state. The scheduled and active states are differ\u00adent states in ordinary Smalltalk. On \nthe other hand, in HoME, the scheduled and active states denote the same state. As soon as a suspended \nprocess is sent a resume message, it can start executing independently and con\u00adcurrently with other running \nprocesses. From the first and second policies, no concept of priority of processes exists. All processes, \nsuch as those for managing in\u00adputs from a keyboard and a mouse, for monitoring real time, for monitoring \na region for objects in the vir\u00adtual machine (object memory), and those that users create by sending \na fork, forkAt:, newProcess or new-Process With: message to block expressions, are treated equally. The \nexecution of a process will not be stopped as the result of scheduling a new process. In short, process \nswitching does not occur. Once a process is scheduled, it cannot yield the processor until it terminates. \nHoME is equivalent to ordinary Smalltalk except that multiple processes can actually execute concur\u00adrently. \nA process starts immediately executing when scheduled, and process switching does not occur. That is, \nalmost all applications developed on ordinary Smalltalk can be executed on HoME without changes in their \ncode, and if the application can be executed in parallel with multiple processes, it can be done more \nquickly than on ordinary Smalltalk. Concurrent execution in HoME is realized by having a Mach thread \nexecute a Smalltalk process. As Mach threads can be thought of as processors and theoreti\u00adcally an infinite \nnumber of threads can be created and execute in parallel, an infinite number of processors can be thought \nto exist in HoME. Since an infinite number of processes can run simultaneously, the moment a pro\u00adcess \nis scheduled, it can start executing and there is no need for process switching.  Implementation This \nsection describes the techniques used in the im\u00adplementation of HoME. 4.1 Spinlockrng As OMRON LUNA-88K \nis a shared-memory multipro\u00adcessor workstation, and the regions to be protected critical sections are \nrelatively small, synchronization between threads is done by using busy-waiting spin\u00adlocking. OMRON LUNA-88K \nuses an MC881OO RISC microprocessor as its CPU. In MC88 100, there is an in\u00addivisible exchange instruction \n(xmem) for implement\u00ading spinlocking [11{. Various queue-based spinlocking methods [1] [9] were implemented \non OMRON LUNA\u00ad88K, but none showed good performance. It has been reported that simply by introducing \ndelay, the simple test &#38; set spinlockimg could improve in performance [1]. In multiprocessors where \nthe coherency of the cache is guaranteed, the cathed value can be tested. Rather than executing the test \n&#38; set instruction each time, it can be executed only when the test of the cached value succeeds. \nThis type of spinlocking is called a test, test &#38; set spinlocking. MC881OO adopts the snoop cache \nfor maintaining the coherency of the cache. In LUNA-88K, the test, test &#38; set ~pinlocking showed \nbetter perfor\u00admance than the simple test &#38; set spinlocking. There\u00adfore, we used the test, test&#38; \nset spinlocking with delay, which resulted in better performance than the test &#38; set with delay. \n 4.2 Region for N-code High performance is achieved in HPS by dynamically translating byte-code into \nmachine-code (n-code) and having the CPU directly execute the machine-code. The region in which n-code \nis stored is allocated on heap as with object memory. As the size of the region is finite, if there is \nno space for storing newly translated n-code, an operation similar to garbage collection must be performed \nto make space. Since access to n-code oc\u00adcurs frequently, a cache is used to access n-code at high speed. \nIn HoME, because a region and a cache for n-code are given to each process, it is not necessary to synchronize \nthreads executing processes when they access these re\u00adsources. In other words, when n-code is written \ninto a region, or a cache is read or written, it is not necessary to synchronize the threads. A thread \nexecuting a pro\u00adcess can scavenge the region for n-code independently and concurrently with other processes \nwhen there is no space in the region to allocate n-code. The other pro\u00adcesses can continue their private \nwork independently and concurrently with the scavenging of the region. If a region for n-code containing \nno n-code is given to a newly created process, this causes a decline in performance. This is because \nthe high performance of HPS greatly depends on the reusability of a translated n-code. So, in HoME, when \na process terminates, the region and the cache for n-code used by it are appended to the head of a list \nfor unused regions without doing anything. The next time a new process is created, the region and the \ncache for n-code which are at the head of the list are removed and given to it. Since a new pro\u00adcess \ncan reuse an n-code which was translated by older processes, the overhead due to translation becomes \nlow and the overall performance is improved. 4.3 Object Allocation There is only one object memory, \nwhich is the reg,ion for allocating objects, and it is global to the system. In HPS, the automatic storage \nmanagement uses Genera\u00adtion Scavenging, which is a stop-and-copy scheme. The allocation of an object \nusing this scheme is quite fast it amounts to little more than incrementing a pointer. So, object allocation \nis serialized by using spinlocking. 4.4 Garbage Collection In HPS, two garbage collectors, the Generation \nScav\u00ad enging collector and the mark and sweep collector, are used. Garbage collection is ordinarily done \nonly within the new space by using Generation Scavenging. When the old space becomes full, an overall \ngarbage collec\u00adtion is done on the object memory by using the mark and sweep collector. Since processes \nexecute only sequentially in HPS, when a process starts collecting garbage, it does not need to be concerned \nabout the other processes. In HoME, however, since multiple processes may be run\u00adning simult aneouslyj \ngarbage collection cannot be done in the same way. There is a special thread for execut\u00ad ing Generation \nScavenging, and it is different from the threads executing Smallt alk processes. This thread is usually \nsuspended. When Generation Scavenging must be carried out, it starts by resuming the thread. The thread \ndoes the following: 1. When Generation Scavenging starts, all processes must be suspended, so it is necessary \nto suspend threads executing processes. Execution of a pro\u00adcess, however, cannot be stopped at any given \ntime because the instance variable suspendedContext of the process must contain a context which is the \nactivation record used when the process starts ex\u00adecuting again. Thus, the Generation Scavenging thread \nnotifies all processes currently executing to suspend. Each process has a private flag in the virtual \nmachine layer, and it is notified to suspend for Generation Scavenging by setting a bit in the flag. \nProcesses can know if there is a need to sus\u00adpend for Generation Scavenging by checking the flag periodically. \nIt is possible to decide if a ]pro\u00adcess is currently running by checking whether or not the thread executing \nthe process is currently running. All threads executing the notified pro\u00ad cesses are registered in the \narray suspendThreads. 2. The Generation Scavenging thread checks whether there is a running process. \nIf a process is still running and the thread executing the process is not registered in suspendThreads, \nthe Generw t ion Scavenging thread notifies the process to sus\u00adpend and registers the thread executing \nit in sus\u00adpendThreads. If the thread executing the process has already been registered in suspendThreads, \nthe Generation Scavenging thread does nothing. The Generation Scavenging thread does so repeat\u00adedly until \nall processes are suspended. 3. After all processes are suspended, Generation Scavenging actually starts. \n 4. When Generation Scavenging is finished, only pro\u00adcesses corresponding to the threads registered in \nsuspendThreads and suspended for Generation Scavenging resume their processing. Not all pro\u00adcesses notified \nto suspend for Generation Scaveng\u00ading actually suspend because of it. This is because after a process \nis notified, it may suspend by ex\u00adecuting the suspend method of the class Process or the w~ t method \nof the class Semaphore. The Generation Scavenging thread is suspended until the next scavenging.  Mark \nand sweep is done when the old space becomes full during Generation Scavenging or when users exe\u00adcute \nthe garbageCollect method of the class SystemDic\u00adtionary. There is no problem with the former because \nall processes are suspended. When the garbageCoJ\u00adlect method is executed, the thread corresponding to \nthe process executing the method plays a role similar to the Generation Scavenging thread described above. \nThe thread has the same function as the Generation Scavenging thread except that it does not suspend \nthe process corresponding to itself. 4.!5 Stack In Smalltalk, an activation record (context in Smalltalk \nterminology) is created whenever a message is sent. Most of the contexts are never referred to as objects \nduring their lifetime, however, resulting in most of the contexts being allocated as frames on activation \nstacks in HPS. Contexts allocated on stacks are called volatile contexts. When contexts are treated as \nob\u00ad jects, they are allocated in the object memory and are called stable contexts. Contexts which are \nallocated on stacks, but have a header as an object, are called hybrid contexts. Volatile contexts are \nconverted to hybrid contexts when they are referred to as objects, for example, when a message is sent. \nIn HoME, each process manages stacks for allocating contexts suitable for execution (i.e., volatile contexts). \nA different stack for executing functions written in C, such as those for primitive methods, translating \nbyte\u00adcode into n-code and so on, is also given to each process. 4.6 Input from Keyboard and Mouse Input \nfrom a keyboard or a mouse is treated by using a UNIX2 signal. Input from a keyboard or a mouse causes \nthe SIGIO signal, so a signal handling routine is used. When SIGIO occurs, usually it is necessary to \nredraw windows, such as when moving and resizing a window or outputing characters from a keyboard. If \na thread executing a process is interrupted and redraws a window, the execution of the process is tem\u00adporarily \nstopped. Therefore in HoME there is a spe\u00adcial thread for treating signals so that an interrupted thread \ndoes not have to handle the interruption. So, all the signal handling routine has to do is to notify \nthe thread of the SIGIO signal. The Mach system call msg_sendo is used for notifying the thread of sig\u00adnals, \nand the system call msg.receiveo for receiving the notification. This thread can handle signals other \nthan SIGIO, for instance SIGALRM. The thread sends the signal message to the semaphore where the pro\u00adcess \nhandling input is queued when SIGIO occurs, and where the process monitoring real time is queued when \nSIGALRM occurs. 4.7 Request to Window Server The X 11 window system is used for the visual interface. \nThe current version of the Xl 1 window system can\u00adnot support concurrency with multiple threads. When \nmultiple threads make requests to a window server si\u00ad multaneously, since these requests are not processed \natomically and the response of the window server for the requests are interleaved, a consistent result \nis not achieved. Thus, requests to a window server are serial\u00adized by using spinlocking.  4.8 Process \nStructure in the Virtual Machine Layer The process structure in the virtual machine layer is de\u00adfined \nby using C s structure. The structure contains the id number of the thread executing the process, pointers \nto the region and cache for n-code, a field for managing stacks that allocate volatile contexts, a pointer \nto the stack for executing C functions, and so on. The struc\u00adture does not contain an object pointer \nto the process because the pointer may change whenever Generation Scavenging is performed. The process \nstructure in the virtual machine layer can correspond to the process 2UNIX is a trademark of AT &#38; \nT Bell Laboratories. in the virtual image layer by using the id number of the thread executing the process. \nThis is realized by adding a new inst ante variable cent aining the id num\u00adber of the thread to the class \nProcess. The structures are registered in the global hash table IfoMEPtable. 4.9 Method The modified \nmethods are as follows: the instance methods resume and suspend in the class Process, the instance methods \nwait and signal in the class Semaphore, and the inst ante methods activeProcess and yield in the class \nProcessorScheduler. A new instance method kilJ is added to the class Proces\u00adsorScheduler and is used \nin the instance method new-Process in the class BlockClosure. 1 Process> >resume When a resume message \nis sent to a process, and a thread and other resources (region and cache for n-code et al.) are not allo\u00adcated \nto the process, then the resources (a pro\u00adcess structure in the virtual machine layer) are allocated \nto it, the structure is registered in the HoM13PTable, and the process starts executing by executing \nthe thread. If the resources are already allocated to the process, the process is resumed by resuming \nthe thread. The existence of an allo\u00adcated resource is determined by checking whether or not the structure \ncorresponding to the process is already registered in the HoMEPTable. 2. Process> >suspend When a suspend \nmessage is sent to a process, if the process receiving the message is the same process that actually \ncarries out the suspend method, then the process is sus\u00adpended by suspending the thread corresponding \nto it at that time. If the process receiving the message is different from the process actually exe\u00adcuting \nthe suspend method, the process executing the suspend method does not immediately suspend the thread \ncorresponding to the process receiving the message. A thread corresponding to a process cannot be suspended \nat any given time because the instance variable suspendedContext of the process must contain the context \nbeing executed when the process is suspended. So, the process executing the suspend method notifies the \nprocess receiving the message to suspend. The notification is carried out in the same way as in Generation \nScavenging. That is, a process is notified to suspend by setting a bit in its private flag. A process \nchecks the flag periodically, and if the suspend bit is set, it sus\u00adpends by suspending the thread corresponding \nto it. 3. Semaphore> >wait When a wait message is sent to a semaphore, if the instance variable excessSig\u00ad \n  nals of the semaphore is positive, then excessSig\u00adnals is decremented. If excessSignals is zero, the \nprocess executing the wait method is appended to the tail of the semaphore queue and the cor\u00adresponding \nthread is suspended. 4, Semaphore> >signal When a signal message is sent to a semaphore, if the semaphore \nqueue is empty, then excessSignals is incremented. If the queue contains one or more processes, the head \nof the queue is dequeued and resumed by resuming the corresponding thread. 5. ProcessorScheduler >>activeProcess \n When an activeProcess message is sent to Processor, which is the only instance of the class ProcessorSchled\u00aduler, \nin ordinary Smallt alk the value of the in\u00adst ante variable activeProcess is returned. Only one active \nprocess can exist at one time, and the instance variable activeProcess points to the ac\u00adtive process. \nIn HoME, the activeProcess metlhod has been modified to return the process which ex\u00adecutes it, So, this \nmethod is implemented absa primitive method, unlike ordinary Smalltalk. 6. ProcessorScheduler> >yield \n In ordinary Smallt alk, the yield method is used so that the ac\u00adtive process can give the other processes \na chance to execute. In HoME, as all processes can run si\u00admultaneously, this method has been modified \nso as to do nothing. 7. ProcessorScheduler> >kill This method has been added so that resources allocated \nto a lpro\u00adcess can be released. When a process executes this met hod, it releases its resources, that \nis, removes the structure in the virtual machine layer from the HoMEPTable and appends it to the head \nof the list for unused resources, and terminates itself by suspending the thread executing the process. \n 8. BlockClosure>>newProcess In ordinary Smallt alk this method uses the terminateActive method in the \nclass ProcessorScheduler for termi\u00adnating an active process. In HoME, however, the kili method is used \ninstead of the terminateActive method.   4.10 Modification in VI A new instance variable thread is \nadded to the class Process so that a process in the virtual image layer can correspond to the process \nstructure in the virtual machine layer. The inst ante variable thread of a pro\u00adcess contains the id number \nof the thread execu~ting it. A hash table for registering scheduled processes (running processes) is \nrepresented by a newly added instance variable hoMEProcessList in the class Proces\u00ad sorScheduler. In \norder to point to the next process in the hoi W3ProcessList, a new inst ante variable nextPro\u00ad cess is \nadded to the class Process. When the activeProcess message is sent to the Pro\u00ad cessor, the process executing \nthe activeProcess method is returned. The following are carried out in the active- Process method: 1. \nGet the id number of the thread executing the ac\u00adtiveProcess method by using the Mach system call thread~elfo. \n 2. Find the process corresponding to the id number in the instance variable hoMEProcess,List of the \nProcessor, and return it.  The wait and signal method in the class Semaphore are critical sections \nsince multiple processes may run si\u00admultaneously. If the methods are protected by a global lock variable, \nprocesses may wait even when there is no need to be mutually excluded. For example, suppose there are \ntwo different semaphores semi and sem2, and two different processes send the wait or signal messages \nto semi and sem2 respectively. One process must wait until the other process finishes executing the wait \nor signal method though there is no need for mutual ex\u00adclusion. So, a private lock variable sem.Lock \nis added to the class Semaphore as an inst ante variable to protect the semaphore itself. This can remove \nany unnecessary waiting. The inst ante variables activeProcess and quiescent-ProcessLists in the class \nProcessorScheduler are not used in HoME. 4.11 Snapshot and Booting The snapshot is done in the same \nway as when the garbageCollect method in the class SystemDictionary is executed. That is, when the snapshot \nis taken, all processes excluding the process executing the snapshot are suspended. In ordinary Smalltalk, \nall scheduled processes are enqueued, according to their priority, to the ready queue in the instance \nvariable quiescentPro\u00ad cessLists of the Processor, and an active process which is the process executing \nthe snapshot is pointed to by the inst ante variable activeProcess of the Processor. So, when Smalltalk \nis booted, only the process pointed to by the activeProcess starts executing. In HoME, the quiescentProcessLists \nand the activeProcess are not used, and all scheduled (running) processes are regis\u00adtered in the instance \nvariable hoMEProcessList in the Processor. So, when HoME is booted, all processes which are registered \nin the hoMEProcessList must start executing. Since a thread that executes a process may change after \nboot ing, the inst ante variable thread of all processes existing in object memory must be ini\u00adtialized. \n 5 Performance This section describes the results of the performance of HoME currently running on OMRON \nLUNA-88K. The results of the performance of HPS on the same workstation are shown and compared with the \nresults of HoME. The OMRON LUNA-88K which was used for the measurement carries four MC881OO RISC mi\u00ad \ncroprocessors and has a main memory of 64 megabytes. The size of the creation space and the region for \nn-code were both 1 megabyte in HPS and HoME. 5.1 Benchmark The benchmarks used for the measurement of \nHoME s performance are the computation of factorial, Quick\u00ad sort, Boyer theorem-proving, Multi Lisp interpreter, \nand fuzz y information retrieval system. The algorithm for the computation of factorial was odd-even \ndivide &#38; conquer factorial [2]. Suppose a function f is defined as follow: .f(n, m) = if mz nthen \nn else f(n, 2m) * f(n m, 2m) The factorial of n (n!) can be then computed by n! = ~(n, 1). When computing \nfactorial in parallel, a new process is forked in the topmost recursive call and it computes a subproduct. \nFor example, when the facto\u00adrial of n is computed in parallel by four processes, the four processes compute \nf (n,4), f (n 2, 4), f(n 1, 4) and .f(n 3, 4) respectively and the four subproducts are multiplied. \nQuicksort is an algorithm which sorts by dividing a sorting partition into two subpartitions where one \ncon\u00adtains numbers less than a particular number and the other contains those not less than it. So, quick \nsort can also be done in parallel like the computation of factorial described above. The divided subpartitions \nmay not be balanced very well depending on the di\u00adviding number and sorting may not be efficiently done \nin parallel by multiple processes, Thus, for balancing subpartitions the middle number of the first 10~0 \nof a sorting partition is found by find, and it is divided into two subpartitions by using that number. \nBoyer theorem-proving is a modified version of the one which is used in [15] as MS s benchmark. In MS, \na newly scheduled process does not start exe\u00adcuting immediately when the number of running pro\u00adcesses \nis the same as the number of replicated inter\u00adpreters. In HoME, however, as a newly scheduled process \nstarts executing immediately independently of other processes, HoME cannot efficiently execute the Boyer \nbenchmark used in [15]. So, in HoME, the fol\u00adlowing decision was adopted: when a subproblem is to be \nprocessed, if the number of running processes is less than a certain number, a new process is forked \nand the subproblem is executed by it concurrently with other subproblems; if not, the subproblem is executed \nsequentially within the process in which it occurs. The Multi Lisp interpreter is a Lisp interpreter \nwhich can evaluate Lisp expressions in parallel with multiple processes. The number of simultaneously \nrunning pro\u00adcesses can be specified when evaluating Lisp expres\u00adsions. Fuzzy information retrieval is \na modified version of the proposed method in [12]. In [12], fuzzy information retrieval is designed based \non object-oriented concur\u00adrent languages, and the units of concurrent execution are objects. In HoME, \nfuzzy information retrieval is redesigned so that processes are units of concurrent execution and the \nnumber of running processes simul\u00adtaneously is limited as in the Boyer benchmark. 5,2 Result Table 1 \nshows the execution time for the bench\u00admarks. Labels in table 1 are as follows: Fact Computation of the \nfactorial of 2000. Sort Sort of a sequence of 100,000 real numbers by Quicksort. Boyer Boyer theorem-proving \nbenchmark used in [15]. Lisp Evaluation of the Fibonacci number 17 by Multi Lisp interpreter. FIR Retrieval \nof documents by fuzzy information re\u00adtrieval system where the depth of inference is 14. The execution \ntime was measured for the five bench\u00admarks described above with a single process in HPS, and with 1, \n2, 4, 8, 16, 32 and 64 processes in par\u00adallel in HoME. Executing with a single process means executing \nsequentially. 5.3 Evaluation Table 2 shows the normalized execution time for bench\u00admarks based on HPS. \nIn the simple benchmarks Fact and Sort, overhead from introducing concurrency in HoME is not found. In \nthe more complex benchmarks Boyer, Lisp and FIR, however, overhead is found 8y0 to 30?Z0. In every benchmark, \nthe results of exe\u00adcuting concurrently with multiple processes in HoME are better than HPS. In the complex \nbenchmarks, how\u00adever, when the number of processes is excessive, HoME is slower than HPS. In Boyer, the \nresult of executing with 64 processes in HoME is five times slower than HPS. Since the amount of the \nwork which a single pro\u00adcess executes in Boyer is much smaller than in the other benchmarks, the overhead \nfor creating processes Fact Number of Processes Fact Sort Boyer Lisp FIR 1 HPS 36.50 52.08 5.00 72.05 \n276.63 Table Number of processes 1 HPS Sort Boyer Lisp FIR becomes relatively large executing concurrently \ntion OMRON LUNA-88K four CPUS. In Fact, Sort achieved with more than HoME s performance 1.00 1.00 1.00 \n1.00 1.00 12 HoME HoME 36.52 24.35 52.10 31.10 5.87 5.50 77.83 59.11 ~ 359.17 230.41 1: Execution time \n2 1 HoME HoME 1.00 0.6ir 1.00 0.60 1.17 1.10 1.08 0.82 1.30 0.83 HoME HoME 22.16 22.10 21.41 21.18 \n3.66 4.47 52.26 64.06 186.88 179.36 (in seconds) for 48 HoME HoME 0.61 0.61 0.41 0.41 0.73 0.89 0.73 \n0.89 0.68 0.65 Table 2: Normalized benchmark time based on HPS when the number of processes becomes large. \nThe workst~ used in these evaluations h ad and FIR a better result was four processes on four CPIUS. \nis much better than HPS if ap\u00ad plications can be executed in parallel with multiple pro\u00adcesses. 5.4 \nGeneration Scavenging In HoME, when Generation Scavenging starts, all running processes are suspended \nand Generation Scav\u00adenging is executed. The execution time for an applica\u00adtion in a state where Generation \nScavenging does not occur is compared with one in a normal state (where Generation Scavenging occurs) \nso that the rate of Gen\u00aderation Scavenging in executing the application can be examined. In order for \nGeneration Scavenging not to occur, the size of creation space must be large. The size of creation space \nwas enlarged from 1 to 30 megabytes so that Generation Scavenging would not occur during the execution \nof benchmarks. The benchmarks used in the examination are as fol\u00adlows: Lisp2 Evaluation of the Fibonacci \nnumber of 12 by Multi Lisp interpreter. FIR2 Retrieval of documents retrieval system, where Table 3 \nand 4 show the megabytes of creation space by the fuzzy information the depth of inference is 9. execution \ntimes for 30 size (no GS (in seconds)), 4 8163264 HoME 22.12 20.58 9,21 76.92 219.61 HoME 22.15 20.87 \n15.54 78.92 291.62 HoME 22.22 21.20 25.67 82.93 336.89 benchmarks 16 HoME 0.61 0.40 1.84 1.07 0.79 32 \nHoME 0.61 0.40 3.11 1.10 1.05 64 HoME 0.61 0.41 5.13 1.15 1.22 \\ the execution time for 1 megabyte \nof creation space size (with GS (in seconds)), the-time exhausted for Gener* tion Scavenging (GS time \n(in seconds)) and the rate of Generation Scavenging (GS rate) for Lisp2 and FIR2 respectively. In both \nLisp2 and FIR2, the rate of Generation Scavenging shows the same tendency. When the bench\u00admarks are executed \nsequentially (with a single pro\u00adcess), the rate in which Generation Scavenging occurs in HoME is approximately \nthe same as HPS. The rate of executing with a couple of processes is a little greater than executing \nwith a single process in HoME, but the rates are little different. When executing more than four processes, \nthe rate exhausted by Generation Scav\u00adenging is much larger than when executing with a single process. \nHowever, the rate of Generation Scavenging does not become very large when the number of pro\u00adcesses becomes \nlarge. The rates exhausted by Genera\u00adtion Scavenging with 4, 8, 16, 32 and 64 processes are approximately \nsame in both Lisp2 and FIR2. The av\u00aderage is 16.99Y0. The difference between the rate of a single process \n(the average of Lisp2 and FIR2 with a single process in HoME: 3.41) and multiple processes is 13.58%, \nwhich is the rate of the overhead exhausted by suspending all running processes for Generation Scav\u00ad \nenging. This means that suspending all running pro\u00ad cesses is not a big load when st artiug Generation \nScav\u00ad enging when a great number of processes are running. Number of 1 1 2 4 8 16 32 64 processes HPS \nHoME HoME HoME HoME HoIvfE HoME HoME No GS 6.21 6.92 4.91 4.33 4.37 5.54 5.84 6.78 With GS 6.38 7.10 \n5.06 4.97 5.33 6.59 7.03 8.21 GS time 0.17 0.18 0.15 0.64 0.96 1.85 1.19 1.43 GS rate(%) 2.66 2.54 2.96 \n12.88 18.01 19.$9 16.93 17.42 Table 3: Rate of GS S overhead for Lisp2 Number of 1 1 2 4 8 16 32 64 processes \nHPS HoME HoME HoME HoME HoME HoME HoME No GS 6.39 7.40 4.83 3.59 3.57 3.78 4.30 6.25 With GS 6.65 7.73 \n5.09 4.31 4.38 4.49 5.21 7.49 GS time 0.26 0.33 0.26 0.72 0.81 0.71 0!91 1.24 GS rate(%) 3.91 4.27 5.11 \n16.71 18.49 15.81 17.47 16.56 Table 4: Rate of GS S overhead for FIR2  Related Work Examples of Smalltalk \nwhich have introduced concur\u00adrency are MultiprocessorSmalltalk (MS) [14][15] and ConcurrentSmalltalk \n(CST) [21]. MS is an example of Smalltalk where processes (units of execution) execute in parallel like \nHoME, and it is a system which implements Berkeley Smalltalk [19] on the FireFly multiprocessor [17] \nwith the V distributed operating system [4]. Berkeley Smalltalk is a type which unlike HPS interprets \nbyte-code. In MS, con\u00adcurrent execution is realized by replicating the inter\u00adpreter and having the same \nnumber of interpreters as the number of physical processors. The ready queue for processes is not replicated. \nThere is only one ready queue in MS. Each interpreter gets the next process to be executed from the queue, \nand interprets the byte\u00adcode corresponding to the process. The Smalltalk used in HoME is a type which \ndy\u00adnamically translates byte-code into machine-code dur\u00ading execution, and the CPU directly executes \nthe code. In MS, concurrent execution is realized by replicating the interpreter. It is realized by executing \na Smalltalk process on a Mach thread in HoME. The number of processes running simultaneously is dependent \non the number of replicated interpreters in MS, in contrast with the number in HoME being unlimited. \nTable 5 shows a comparison of HoME with MS. In MS, the interpreter is replicated up to the num\u00adber of \nphysical processors for efficiency of processing speed. This method does not seem to be suitable for \nall applications which are executed in parallel. For ex\u00adample, when Fact, Sort and FIR are executed in \npar\u00adallel by HoME on a multiprocessor, these are finished more quickly using more than 4 processes, than \nwith 4 processes, without changing the number of physical processors. In CST, concurrent execution is \nrealized by provid\u00ading concurrent constructs and atomic objects. Objects in CST unify the concepts of \nordinary objects and pro\u00adcesses, and are called concurrent objects. Synchroniza\u00adtion between concurrent \nobjects is done by atomic ob\u00adjects. Atomic objects execute only one message at a time. That is, when \nan atomic object is sent messages by more than one object simultaneously, the atomic object handles these \nmessages one by one. Concurrent execution units in HoME are processes, in contrast with being objects \nin CST. CST is thus an object-oriented concurrent language [22]. HoME is just an object\u00adoriented language \nin which processes can be executed in parallel. CST is implemented on a uniprocessor, not a multiprocessor. \nExamples of Smalltalk which can be used on a dis\u00adtributed environment are [3] [5] [16]. These systems \nallow objects on different machines to be connected by a network for sending and responding to messages. \nWe did not design HoME on the premise that HoME can be executed on a distributed environment. 7 Concurrent \nProgramming in HoME Section 2 discussed concurrent programming in Smalltalk and illustrated it with a \nsimple example. When the program in 2.3 is executed in ordinary Smallt alk, the two processes do not \nrun simultaneously. The process created second waits until the process cre\u00adated first terminates; in \nshort, first DOG is printed 20 times and then CAT is printed 20 times. The yield MS HoME Base a type \nwhich a type which dynamically translates Smalltalk interprets byte-code byte-code into machine-code \nConcurrent replicating interpreters executing a Smalltalk process execution as the same nu~mber of CPU \nwith a Mach thread Number of processes the number of no limit of the number running simultaneously replicated \ninterpreters of running processes Table 5: Comparison of MS with HoME method in the class ProcessorScheduler \nneeds to be used so that the processor is alternately allocated to multiple processes. When problems \nwhich include crm\u00adcurrency are programmed in Smallt alk, in addition to modeling units of concurrent \nexecution in the problems as processes, it is necessary to consider where the yield method is to be used, \nbut this is not the essence of the problem. In HoME, since all processes can execute indepen\u00addently and \nconcurrently with other processes, there is no need for such considerations. That is, the problem can \nbe programmed simply by considering its essence. When the program in 2.3 is executed in HoME, because \nthe two processes can run simultaneously, the strings DOG and CAT are printed in random order on the \nTranscript. In ordinary Smalltalk, when writing concurrent pro\u00adgrams, even if an object is shared by \nmultiple processes, there are cases where it does not have to be protected with semaphores. For example, \nin program 2.3, Tran\u00adscript is shared by two processes, but it does not have to be protected in ordinary \nSmalltalk. However, in HoME, since all processes execute in parallel, objects which are shared by multiple \nprocesses must be pro\u00ad tected with semaphores. Future Work Clsss BitBlt has the role of drawing windows \non a display in Smalltalk. Window display management in SmaHt alk is very simple, as Bit Blt just draws \nthe whole window when the window is to be drawn or redrawn on a display. When multiple processes can \nexecute concur\u00adrently as in HoME, multiple processes should be able to draw and redraw multiple windows \nsimultaneous sly. In the window display management of Smalltalk, how\u00adever, since Bit Blt would draw and \nredraw all these win\u00addows simultaneously, this cannot be done consistently. So, the window system must \nbe redesigned or newly designed on the premise that multiple processes exe- S~ parcplace Smalltdk-SO \nRelease 4, since a window in Smalltalk is represented as a window of Xl 1, thk may not kappen. cute simultaneously. \nFor example, a window display management method based on rectangles could be in\u00adtroduced into the window \nsystem in HoME. Also, the window control manager in Smalltalk is not designed on the premise that multiple \nprocesses access it simulta\u00adneously. So, the synchronization of multiple processes must be done when \nthey access the resources of the window control manager, such as a list of controllers. As the debugger \nin Smalltalk is not designed and implemented for supporting concurrent programming, a debugger based \non parallel debugging techniques [10] or a newly designed debugger should be implemented for debugging \nconcurrent programs easily. In the present implementation of HoME, each pro\u00adcess has a region for n-code, \nand an object memory is shared with all processes. We have nearly completed the design of sharing a region \nfor n-code with all pro\u00adcesses and Generation Scavenging when each process is given a new space. We plan \nto incorporate them into HoME in the near future. 9 Conclusion The design and implementation of a version \nof Smallt alk (HoME) which can be efficiently executed on a multiprocessor were described. HoME can be \nexecuted in parallel by having processes as execution units. This is done by mapping a Smalltalk process \nonto a Mach thread and having the thread execute the process so that HoME can be executed efficiently \non a multiprocessor. In all benchmarks measured, if an ap\u00adplication is processed concurrently with multiple \npro\u00adcesses, HoME can finish the application more quickly than HPS. From the implementation of HoME, the \nfollowing can be concluded: The overhead for suspending all running processes for Generation Scavenging \nis acceptable.  Some applications can be executed more efficiently with processes numbering more than \nthe number of physical processors rather than processes whose number is the same as physical processors. \n  Since Smalltalk is designed and implemented on the premise that Smalltalk executes sequentially on \nuniprocessors, some systems in Smalltalk must be redesigned and newly designed when introduc\u00ading concurrency \ninto Smalltalk. Examples are the window system and the debugger. 10 Acknowledgments The authors would \nlike to thank OMRON Corpora\u00ad tion for supporting this research. Kazuki Yasumatsu, Fusayuki Minamoto, \nand Mineharu Yokoyama of Fuji Xerox Co., Ltd. made useful suggestions.  References [1] Thomas E. Anderson, \nThe Performance of Spin Lock Alternatives for Shared-Memory Multiproces\u00adsors, IEEE Tran. on Parallel \nand Distributed Sys\u00adtems, Vol. 1, No. 1, 6-16, 1990. [2] Hans Boehm, Odd-even divide &#38; conquer factorial, \nPersonal communication, March 1992. [3] John K. Bennett, The Design and Implementa\u00adtion of Distributed \nSmalltalk, Proc. of 00 PSLA 87, 318-330, 1987. [4] David R. Cheriton, The V kernel: a software base for \ndistributed systems, IEEE Soft ware, 1 (2), April 1984. [5] Dominique Decouchant, Design of a Distributed \nObject Manager for the Smalltalk-80 System, Proc. of 00 PSLA 86, 444-452, 1986. [6] Peter Deutch and \nAllan Schiffman, Efficient Imple\u00adment ation of the Smalltalk-80 System, Proc. of 1 lth ACM POPL, 297-302, \n1984. [7] Norihisa Doi and Kiyoshi Segawa, On the con\u00adcurrent programming in Smalltalk-80, Advances in \nSoftware Science and Technology, Vol. 1, Academic Press, 187-207, 1989. [8] Adele Goldberg and David \nRobson, Smalltalk-80: The Language and tts Implementation, Addision-Wesley, 1983. [9] John M. Mellor-Crummey \nand Michael L, Scott, Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors, ACM Tran. \non Computer Systems, Vol. 9, No. 1, 21-65, 1991. [10] Charles E. McDowell and David P. Helmbold, De\u00adbugging \nConcurrent Programs, ACM Computing Surveys, Vol. 21, No. 4, 593-622, 1989 [11] Motorola, MC881OO RISC \nMICROPROCESSOR USER S MANUAL SECOND EDITION, Prentice Hall, 1990. [12] Kazuhiro Ogata and Norihisa Doi, \nKnowledge Representation and Inference An Approach from Object-Oriented Computing and Fuzzy Theory , \nProc. of PRICAI 90, 729-734, 1990. [13] Kazuhiro and Norihvironment, isa Ogata, Doi, Proc. Satoshi HoME: \nSof TOOLS Kurihara, malltalk on Pacific 91, M ikio Inari Mach En\u00ad153-161, 1991. [14] Joseph Pallas \nand David Ungar, Multiprocessor Smalltalk: A Case Study of a Multiprocessor-Based Programming Environment, \nProc. of SIGPLAN 88, 268-277, 1988. [15] Joseph Pallas, Multiprocessor Smalltalk: Imple\u00admentation, Performance, \nand Analysis, PhD thesis, Stanford Univ., 1989. [16] Marcel Schelvis and Eddy Bledoeg, The Imple\u00admentation \nof a Distributed Smalltalk, Proc. of ECOOP 88, 212-232, 1988. [17] Charles P. Thacker and Lawrence C. \nStewart, Firefly: a multiprocessor workstation, Proc. of AP-SLOS II, Computer Society Press of the IEEE, \n164\u00ad172, October 1987. [18] Avadis Tevanian, Jr. and Richard F. Rashid, MACH: A Basis for Future UNIX \nDevelopment, CMU-CS-87-139, 1987. [19] David M. Ungar and David A. Patterson, Berke\u00adley Smalltalk: Who \nknows where the time goes?, In Smalitaik-80: Bits of Histoy, Words of Advice, Glen Krasner (Ed), Addison-Wesley, \n189-206, 1983. [20] David Ungar, Generation Scavenging: a nondis\u00adrupt ive high performance storage reclamation \nalgo\u00adrithm, Software Engineering Symposium on Practi\u00adcal Software Development Environments, 157-167, \n1984. [21] Yasuhiko Yokote and Mario Tokoro, The Design and Implementation of ConcurrentSmalltalk, Proc. \nof 00 PSLA 86, 331-340, 1986 [22] Akinori Yonezawa and Mario Tokoro, Object-Oriented Concurrent Programming, \nThe MIT Press, 1987.  \n\t\t\t", "proc_id": "143095", "abstract": "<p>HoME is a version of Smalltalk which can be efficiently executed on a multiprocessor and can be executed in parallel by combining a Smalltalk process with a Mach thread and executing the process on the thread. HoME is nearly the same as ordinary Smalltalk except that multiple processes may execute in parallel. Thus, almost all applications running on ordinary Smalltalk can be executed on HoME without changes in their code.</p><p>HoME was designed and implemented based on the following fundamental policies: (1) theoretically, an infinite number of processes can become active; (2) the moment a process is scheduled, it becomes active; (3) no process switching occurs; (4) HoME is equivalent to ordinary Smalltalk except for the previous three policies.</p><p>The performance of the current implementation of HoME running on OMRON LUNA-88K, which had four processors, was measured by benchmarks which execute in parallel with multiple processes. In all benchmarks, the results showed that HoME's performance is much better than HPS on the same workstation.</p>", "authors": [{"name": "Kazuhiro Ogata", "author_profile_id": "81100139881", "affiliation": "", "person_id": "PP31089080", "email_address": "", "orcid_id": ""}, {"name": "Satoshi Kurihara", "author_profile_id": "81100170769", "affiliation": "", "person_id": "PP43124612", "email_address": "", "orcid_id": ""}, {"name": "Mikio Inari", "author_profile_id": "81332506127", "affiliation": "", "person_id": "P200841", "email_address": "", "orcid_id": ""}, {"name": "Norihisa Doi", "author_profile_id": "81100266549", "affiliation": "", "person_id": "P210046", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143095.143117", "year": "1992", "article_id": "143117", "conference": "PLDI", "title": "The design and implementation of HoME", "url": "http://dl.acm.org/citation.cfm?id=143117"}