{"article_publication_date": "07-01-1992", "fulltext": "\n Probabilistic Register Allocation Todd A. Proebsting and Charles N. Fischer* University of Wisconsin-Madisont \nAbstract A new global register allocation technique, probabilistic register allocation, is described. \nProbabilistic register allocation quantifies the costs and benefits of allocat\u00ading variables to registers \nover live ranges so that excel\u00adlent allocation choices can be made. Local allocation is done first, and \nthen global allocation is done iteratively beginning in the the most deeply nested loops. Be\u00adcause local \nallocation precedes global allocation, prob\u00adabilistic allocation does not interfere with the use of well-known, \nhigh-quality local register allocation and instruction scheduling techniques. 1 Introduction The dominant \nparadigm in modern register alloca\u00adtion is graph coloring ([CAC+81], [CH90], [BCKT89], [LH86]). Unfortunately, \ngraph coloring does not re\u00adally address the issue of register allocation, but rather a related issue \nregister assignment. That is, graph coloring tells us how to assign registers so that simul\u00adt aneously \nlive values aren t assigned the same regis\u00adter. The harder problem which values to put in some register \nis not directly addressed. Hence there is al\u00adways a spilling heuristic that reduces register demand until \ncoloring (register assignment ) can succeed. A famous political maxim states that All politics is local, \nand we believe that much the same is true for register allocation. Ultimately, when an operand is actually \nused it must be in a register, and once a value *This work was supported by NSF grant CCR-8908355. t \nAuthor s address: Dept. of Computer Sciences, 1210 W. Dayton St., Madison, WI .53706. Email: {todd,fischer}@cs \n.wisc .edu Permission to copy without fee ell or part of this material is grented provided that the \ncopies ere not made or distributed for direct commercial edvantage, the ACM copyright notice and the \ntitle of the publication end its date appaar, and notice is given that copying is by permission of the \nAssociation for Computing Machinery. To copy otherwisa, or to republish, requires a fee and/or specific \npermission. ACM SIGPLAN 92 PLD1-6/92/CA @ 1992 ACM 0-89791 -476 -7/92 /000610300 . . ..$1 .50 is in a \nregister, it is easy to reuse within a basic block. Simple, fast and nearly optimal local register alloca\u00adtors \nare known [HFG89]. Once local register needs are met, the effects of global allocation can be estimated \n([Bea74], [Mor91]), In particular, a good global alloca\u00adtion improves upon good local allocation by eliminat\u00ading \nunnecessary loads at the entrance to a basic block and by eliminating unnecessary stores at the exit \nfrom a basic block. An initial load of v is unnecessary if all predecessors exit with v in a register, \nand a terminal store of w is unnecessary if w is dead or all succeed\u00ading loads of w can be replaced with \na reference to w s register. Of course we do not initially know which values will ultimately be allocated \nto registers, so we take a prob\u00adabilistic approach. At the basic block level, we know values loaded locally \ninto a register and not overwrit\u00adten have a 100% probability of exiting in a register, The probability \nof other values residing in a register on exit depends on their probability of residing in a register \nupon entrance and the number of unused reg\u00adisters in a block. The probability that a value will be in \na register upon entrance to a block depends on the probabilities it will exit in a register from all \npredeces\u00adsor blocks. Once initial estimates of the probability of register allocation are made, these \nestimates are weighted by the net benefit gained by allocating a given value to a register and the most \npromising candidate is allocated to a register. Probabilities are recomputed and again the most promising \ncandidate is allocated to a register. This continues until all registers are allocated. The resulting \ntechnique is simple and fast (no backtracking ever occurs) and yet identifies those values that can readily \nand profitably reside in a register. 2 Graph Coloring Allocators For most of the last decade, global \nregister allo\u00adcation research has concentrated on graph color\u00ad ing techniques ([CAC+81], [Cha82], [CH90], \n[LH86], [BCKT89], [CK91]). These techniques allocate regis\u00adters by attempting to solve the related problem \nof as\u00adsigning registers. The basic graph coloring technique involves creating a register interference \ngraph and then pruning nodes from that graph that can be trivially colored (assigned a physical register). \nGiven enough registers to color all register candidate values, this technique works well. However, once \nthe interference graph is reduced to a graph for which the node prun\u00ading heuristic blocks, each technique \nmust act so that register assignment may continue. Various graph col\u00adoring techniques differ precisely \nin what they do when pruning blocks. Chaitin s techniques ([CAC+81], [Cha82]) take the simplest approach \nto handling such pruning blocks. A node (register candidate) is picked based on a cost measure, removed \nfrom the graph, and assigned per\u00admanently to a memory location. All subsequent refer\u00adences to that value \nmust be from memory. Priority based coloring ([CH90], [LH86]) also builds an interference graph and attempts \nto color it by prun\u00ading nodes. If this pruning blocks, a heuristic is em\u00adployed to split large, costly \nlive ranges into smaller ranges in an attempt to produce a graph that can be further pruned. Complex \nheuristics are used to split live ranges to minimize the costs of spilling and reload\u00ading the values \nacross the boundaries to the new, smaller live-ranges. This mechanism is repeated until the all register \ncandidates are assigned registers, Callahan and Koblenz allocate registers globally by doing graph coloring \nhierarchically [CK91], They treat the program as a hierarchy of nested tiles, Tiles may be basic blocks, \nconditionals, or loops. They as\u00adsign registers using graph pruning techniques, but start by assigning \nregisters in innermost tiles and progres\u00adsively assigning registers in enclosing tiles, This tech\u00adnique \nsucceeds in isolating some local register needs from global register usage so that variables referenced \nwithin deeply nested loops will be assigned a register before a variable that is not referenced within \nthe loop. If, however, within a tile, the graph pruning algorithm fails to find a coloring, their technique \nresorts to the graph-coloring spill techniques outlined in [BCKT89]. Therefore, while succeeding in biasing \nregister alloca\u00adtion within a loop to variables used within that loop, spill decisions must still be \nmade via ad hoc heuristic methods, None of these graph coloring techniques do local (basic block level) \nregister allocation as well as estab\u00adlished algorithms ([HFG89], [Fre74], [FL88]) because local register \nallocation techniques are able to use in\u00adformation about the simple sequential nature of regis\u00adter usage \nin the block to minimize local spill code. This information is lost when register allocation is cast \nas a graph coloring problem. 3 Probabilistic Register Allocation Our technique, Probabilistic Register \nAllocation, uti\u00adlizes graph coloring techniques to assign registers, not to allocate them. Allocation \nis done prior to assign\u00adment based on quantified measures of the costs and benefits of having particular \nvalues in registers. Sepa\u00adrating allocation from assignment allows our algorithm to concentrate on the \nimportant problem of determin\u00ading which values will profitably be held in registers at different points \nin the program. Probabilistic global allocation follows local alloca\u00adtion. Global allocation proceeds \nfrom inner loops to outer loops so that values used within a loop are rou\u00adtinely allocated a register \nfor that loop. 3.1 Local Register Allocation &#38; Probabilities Most local register allocators share \nthe basic principle of deciding what should stay in a register (or when a spill is necessary) by checking \nthe closeness of the next use of the values already in registers ([HFG89], [Fre74], [FL88]), If a value \nin a register has only distant next uses then it will be spilled before a value to be used sooner. The \nintuitive explanation for such a heuristic is simple: the farther a potential use of a value is from \na program point, the less likely the value is to remain in a register all the way to that use, thereby \ndecreas\u00ading the expected value of retaining register residence. The likelihood of a value being able \nto stay register\u00adresident can be viewed as roughly inversely propor\u00adtional to the distance that value \nwould have to stay register-resident. Therefore, heuristics choose to spill the value that seems likely \nto lose its register anyway. Conversely, one can view retaining a register allocation over a long distance \nas more likely to result in spills of other register values another motivation for spilling those values \nwith only distant uses. The terms less likely and inversely proportional come from probability. To avoid \nthe NP-Complete problems of optimal local register allocation, such heuristics use a simpler, probabilistic \nsummary of the local circumstances to drive register allocation and spill decisions. We believe that \na formal character\u00adization of these algorithms as probabilistic has been ignored because in straight-line \ncode, distance is al\u00adways directly related to the probability of either being spilled or causing other \nvalues to be spilled. Instr # 2 3 4 5 6 7 8 9 10 11 Proba 1-  Block Instruction Local A-F load load \nadd load load add add store load add store Needs B A,V1 1 z B,v2 2 i* v1,v2,V3 1 ~ C,V4 2 o D,v5 3 v4,v5,V6 \n2 v3, v6, vI 1 v7,A 1 E,v8 2 v7,v8,V9 1 1 I v9.B 0 1 = lity Value in Register 1 - Figure 1: A-Probabilities \n(3 Registers 3.2 Global Register Allocation &#38; Probabili\u00adties The use of probabilistic summary information \nto drive global register allocation haa not been previously stud\u00adied, Probabilities present the foundation \nfor a global register allocator that combines the advantages of ex\u00adcellent local allocation with fast \nand effective global allocation. Probabilistic register allocation avoids the problems of live-range \nsplitting that plague graph\u00adcoloring techniques [Cha82], [BCKT89], [CH90] by im\u00adplicitly (and automatically) \nsplitting ranges where the probability and benefit of residing in a register are low. 3,2.1 Calculating \nGlobal Register Probabili\u00adties The probability that a register value will continue to exist in that register \nat a more distant point in straight\u00adline code can be seen as inversely proportional to the distance to \nthat point. This is not exact, but is intu\u00aditively plausible. Approximating global probabilities requires \nthe abil\u00adity to handle control flow. Loops and conditionals com\u00adplicate matters because a (variable s) \nvalue in a regis\u00adter may originate in many different locations and reach many different uses there is \nnot necessarily a unique next use or a single defining point. Simple data-flow analysis can determine \nall of the definitions that reach a particular use. The question to answer is What is the probability \nthat the value will remain in a register over all paths reaching a particular use from all the reaching \ndefinitions? A simple estimate of the probability can be derived by extending our local, basic block \nheuristic count the total number of intervening instructions on all of the paths from definitions to \nthe use in question. (No L m iies c D 2/3 2/3 1/2 1/2 1 1 1 1 ~ 1 1/2 1/2 1 1 1 1 1 1 2/3 2/3 1 1 ~ \n~ Comments E 2/3 1/2 1 II is dead 1 B is dead 0 All registers in use Reuse either V4 or V5 Reuse V3 \nS register 1 Reuse V6 S register 2/3 1 2/3 available for locals and globals) instruction should be \ncounted twice, even if it appears on paths from two different definitions,) Unfortunately, in practice \nthis yields a relatively poor measure of probability because not all interven\u00ading instructions equally \naffect the probability that a register will need to be spilled. In addition, global reg\u00adister values \nneed only be spilled when there are too few registers for both local needs and live global values. If \nalong some path from a definition to a use the local allocator requires all of the registers, it would \nbe im\u00adpossible for the global value to be in a register along that path and hence the probability of \nthe value being in a register at the use would be O. The global probability that a value will reside \nin a register at a given use (load) is computed from the local A-probabilities for that variable in the \nblocks that reach the load, A-probabilities are computed locally (for each live variable) based on local \nallocations and live variable analysis. A-probabilities are computed on a per instruction basis, and \nindicate the probability that a variable s value will continue to reside in a regis\u00adter after that instruction \ns register needs are resolved zf the value had been in a register upto that instruction. The example \nin Figure 1 illustrates how local allo\u00adcation, liveness analysis and probabilities interact for potential \nregister variables. (It is based on the pro\u00ad gram whose flow graph example assumes that to be allocated \namong block temporary values. local allocation requires ters must be allocated is shown in Figure 3,) \nThe there are 3 registers available the 5 variables and the intra- After the first instruction, 1 register, \nso 1 of the 3 regis\u00adto A at this point, and only of the remaining 3 registers will keep their values \non entry. Therefore, the others (B E) have a 2/3 chance of retaining a register. (We assume that if a \nvalue is live on entry, then it may be in a register, and we must ran\u00ad Block Y Instr # Instruction Local \nA-Probabilities Comments NeedsABc D E 12 load B, v1O 1 2/3 1 2/3 2/3 2/3 13 load E, v1l 2 1/2 ~ 1/2 1/2 \n1 1~ 14 add v1O,vii, v12 1 1 1 1 0 Eis dead (global info) 15 store v12, A o II 1-Probabtiltv Value in \nRegister 1 1 1/3 1/3 o Block Z Instr # Instruction Local A-Probabilities Comments NeedsA Bc D E 16 load \nA, v13 1 1* 2/3 2/3 2/3 2/3 17 loadC,v14 2 1 1/2 1 1/2 1/2 18 add v13, v14, v15 1 2/3 2/3 2/3 2/3 1* \n19 store v15, E o 11 111 Probability y Value in Register 2/3 2/9 2/3 2/9 4 Figure 2: A-Probabilities \n(3 Registers available for locals and globals) domly choose one to give up its register when the local \nallocator needs an extra register. For simplicity, in the algorithm as implemented, we do not take distance \nto next use into account when calculating spill proba\u00adbilities,) A l* indicates that the variable was \neither loaded or calculated into a register at this instruction and therefore must exist in a register. \nA bold-face 1 indicates that the value has been allocated a register through that instruction. The next \ninstruction (#2) requires another register, so one of the remaining variables must be spilled but not \nA because the local allocator keeps it in a register for a local use (#3). Because #2 requires 1 of the \n2 remaining registers to be spilled, each candidate has a 1/2 chance of retaining a register. Instruction \n#3 does not lower the probability of any live variable because the local allocator recognizes that A \ns value is dead and therefore reuses the register allocated to A for the result of the addition. Of course, \nA s probability is O at this point because the local allocator has reallocated its register. It is impossible \n(probability = O) for E to be register-resident at #5 because the instruction sequence # 1 5 requires \nall 3 registers. The bottom row of the table in Figure 1 indicates the probability that a variable will \nbe in a register on exit. These values were calculated by multiplying together all the A-probabilities \nof the variable from the last point it was certain to be in a register to the end of the block. It is \nalso possible to calculate the conditional prob\u00adabilities for variables that are not referenced within \na basic block. If such a variable is in a register on en\u00adtry to a block, the product of the A-probabilities \nfor the entire block is the probability that it will be in a register on exit. Figure 2 gives two example \nbasic blocks with such pass-through values. In the top example (Block Y), the exit probabilities for \nA, B, and E are absolute proba\u00adbilities (because the variables are referenced within the block). The \nprobabilities for C and D are conditional they are the probability that the value will still be in a \nregister on exit if it was in a register on entry. The computation of the A-probabilities at #14 (Fig\u00adures \n2 and 3) demonstrates the powerful interaction of local allocation and global data flow analysis. Global \ndata-flow analysis indicates that the value of E is dead after #14, and, therefore, the local allocator \nmay real\u00adlocate its register to hold the value of the computation (A). Because no additional registers \nwere needed by the local allocator, the A-probabilities of B, C, and D are 1, reflecting no competition \nfor registers (at that instruction). Given the A-probabilities for each variable at each instruction, \nit is a simple matter to determine the prob\u00adability that a variable will be available in a register at \na particular use. That probability is the product of all the A-probabilities for that variable along \nall the paths from the points of definition that reach the use. Al\u00adthough the same instruction may appear \nalong more than one path, its A-probability should only be fac\u00adtored in once. The inner loop in Figure \n3 has been annotated with global probabilities of register residence at each load assuming there are \n3 registers available. (Blocks X, Y, and Z are given in Figures 1 and 2.) For instance, the probability \nof C being in a register at #4 is equal to Pze-Header x 1.load A,V1 { 67%, 100} 2. load B; V2 i 15%; \nlooj 3. add vI, v2, V3 4. load C, V4 { 22%, 100] 5. load D, V5 { 1%, 100} 6, add v4, v5, V6  7. add \nv3, v6, V7 8. store v7, A  9. load E, V8 { o%, 100} 10. add v7, v8, V9 11. store v9, B  Yz 12. \nload B, v1O { 100%, 50} 16. load A, v13 { 67%, 100} 13. load E, v1l { 44%, 50] 17. load C, v14 { 7%, \n100} 14. add v1O, Vllr v12 18, add v13, v14, v15 15. store v12, A 19. store v15, E  Post-Exit I I \nFigure 3: Sample Inner Loop with Global Probabilities (Assuming3 Registers). The loads are annotated \nwith {probability, benejit} pairs, the product of the A-probabilities for #18, #19, #1, probability are \ngiven the greatest register allocation #2, and #3 (the path from the last register use of C priority. \nis at #17, and we assume the variable can be placed The benefit of allocating a register to a use (and \nin a register from the Pre-Header if necessary). The hence toallthe paths reaching that use) is determined \nprobability is, therefore, byestimating howoften the use will be executed, and hence how many cycles \nmay be saved if the value is ac\u00ad2/3*1*2/3$1/2+1=2/9=22% cessed froma register rather than from memory. \nThis can be determined heuristically from loop and condi-The load of C at #4 has a greater global probability \ntional nesting levels, or empirically through profilingthan the load ofB at #2 even though it follows#2 \ninformation from previous executions of the programin the basic block. This can be explained intuitively \nIBL92], by observing that B must be register-resident through Once a particular use has been allocated \na register, more of the loop (#13-19, #l)than C (#18 19, #l there is no need to do a load of the variable \nat that 3). use, thus saving time and space, Allocating a register The extremely low probability (l%) \nfor the load causes the probabilities for many of the other inter- D, v5\u00b0 at #5 is a consequence the \nfact that forD to lock variables to change. This follows from the ob\u00ad be available in a register at that \nlocation, it must be servation that if a register becomes allocated at some in a register for the entire \nloop. point in the program, it must have a probability of 1 at that point. To make room for this fixed \nprobabil\u00ad 4 Using Probabilities to Guide Global Regis\u00ad ity (1), the probabilities of any competing candidates \nter Allocation must change. Our global register allocation algorithm uses local If, for example, B and \nE in block Z become allocated, probabilities combined with a measure of benefit to then after the load \nof A at #16 all three of the registers determine which variable uses should be globally al-will be in \nuse. Therefore the probability that C could located registers. Uses with large benefit and high be in \na register at #17 must drop to O. Because E is dead at #17, its register will be allocated to C when \nC is loaded. Because the probabilities and allocations interact, global allocation is done iteratively. \nA greedy algo\u00adrithm finds the best candidate for register allocation based on both its probability and \nbenefit, and allo\u00adcates a register to that use. We combine probability and benefit by multiplying them \ntogether to get a fig\u00adure of merit for removing a particular load. Then the probabilities are recalculated, \nand another register is allocated. This process is repeated until there are no remaining uses with probability \ngreater than O. 4,1 Improving Probabilistic Register Alloca\u00adtion Probabilistic register allocation carefully \ndetermines which candidates for registers show the greatest promise to benefit the program. Additional \ntech\u00adniques complete the register allocation process. Our algorithm allocates registers inside-out, from \nthe most deeply nested regions to the outermost, thereby em\u00adphasizing allocation in the code most likely \nto be ex\u00adecuted often. The algorithm assumes that all vari\u00adables initially reside in memory until they \nare allo\u00adcated a register. After local allocation, the algorithm locates loads that can be removed by \nallocating a reg\u00adister along all paths from reaching definitions to the chosen load. After loads are \nremoved, it is possible that some stores may be removed those whose values are no longer referenced from \nmemory. In addition, some loads and stores may be removed from a loop by placing them outside the loop \nin a pre-header or post\u00adexit to increase loop speed. Local allocation, followed by load and store removal, \nprovides a mechanism for global allocation that avoids the difficulties of splitting live-ranges or isolating \nspill candidates. 4.2 Example The example in Figure 3 illustrates a simplified version of our algorithm \n(again, assuming 3 registers), Loads will be examined for removal in order of benefit and probability. \nThe second number of each tuple is the benefit of removing the load a value of 100 indicates the load \nwill be executed on all of the 100 iterations of the loop whereas a value of 50 represents an estimate \nthat that branch of the conditional will only execute half as often. (We assume that the probability \nthat a value resides in a register from the Pre-Header is 100% because that can be made so by adding \na load of the value there.) Because #12 has a 100% probability of finding B in a register, its consideration \ncould be deferred indefinitely-it is certain to be in a register! This 100 ZO chance is easily deduced \nby recognizing that block Y has only X as a predecessor, and #10 (in X) left B in a register. (This is \ninformation that a graph col\u00ad oring algorithm could not readily provide,) Delaying allocation (and the \nsubsequent removal of the load) would, however, contribute spurious A-probabilities to the calculation \nof global probabilities for other uses; we therefore remove it immediately.1 The loads of A at #1 and \n#16 will be removed next because they have the highest probabilities (67%) of those loads with a benefit \nof 100 (and hence the highest merit value of 67). In order to remove the load at #1, it is necessary \nto insure that A s value will be in a register on the incoming control-flow arc from the Pre-Header by \nputting a load of A there. After registers have been allocated in order to re\u00admove these three loads \n(#1, #12, #16), the proba\u00adbilities for the remaining loads are recalculated, The new A-probabilities \nare given in Figure 4, and the new global probabilities (calculated using these A s) are given in Figure \n5. The A-probabilities for block Y of Figure 4 have un\u00addergone a dramatic change after the allocation \nof a reg\u00adisters for A and B. Because A is allocated a register upon entry, and because A is dead at #13, \nthe register alloca\u00adtor can reuse that register for the load of E, Therefore, the A-probabilities for \nC and D are 1 throughout the block, The summary Probability Value in Register seems to indicate that \n4(!) values have a 1007o prob\u00adability of being in a register at the end of the block. This result can \nbe explained by recognizing that the probabilities for C and D are conditional the value of C (or D) \nk in a register on exit oniy i? it is in a regis\u00adter on entry, Since at most one of the two could have \nbeen in a register upon entry, we have not erroneously calculated that 4 values could fit in 3 registers. \nNow, four remaining loads have the highest figure of merit (25) for removal: three loads with benefit \nof 100 and a probability of 25% (# 4?(B), #4(c), and #17(C)), and one load with benefit of 50 and a probability \nof 50% (#13(E)). For simplicity, we will arbitrarily choose to allocate a register to c at #4 this too \nrequires an initial load of C in the Pre-Header, After this allo\u00adcation, the remaining probabilities \nchange again only two of the remaining load instructions have probabil\u00adity greater than O: #13 and #17. \nFortunately, both of these loads can be removed. It is useful to recognize how probabilities could de\u00adtermine \nthat D could not be in a register at #5 after removing the load of C at #4. It might appear that 1All \nloads with 100~o probability of register allocation are removed immediately, regardless of their benefit. \nOnly this sit\u00aduation of 100% probability (certainty) is special-cased and it is done to insure accurate \nA-probability computations. Instr # 1 2 3 4 5 6 7 8 9 10 11 Prol B1 Instruction Local Needs o load B, \nV2 1 add v1OO, v2, V3 1 load C, V4 2 load D, V5 3 add v4, v5, V6 2 add v3, v6, v1OO 1 store VIOO, A 1 \nload E,v8 2 add v1OO, v8, v200 1 store v200, B 0 ,bihty Value in Register kX A-T ities T -E\u00ad 1/2 1 \n1 * 1;2 1 1 1 1/2 1 ~ 1/2 1 1 0 1 1/2 1 ~ = Comments Removed A is dead B is dead  Block Y Instr+% I \nInstruction Local A-Probabilities Comments .! Needs A B c DE 12-0~~---Removed 13 load E, v1l 1 0 1 \n1 11 Ais dead 14 add v200,vii,v1OO o 1 ~ 1 1 0 E is dead 15 storev1OO,A o L 1 1 1 - Probability Value \nin Register 1 L 1 1 0 Block Z  Instr # Instruction Local A-Probabilities Comments Needs AI BIC IDIE \nII 4 ~_--. 17 load C, v14 1 ~ 1/2 1* 1/2 1/2 18 add v1OO,v14, v15 1 1 1/2 1/2 1/2 1 19 storev15,E o \n~1 1 1 1 Probability Value in Register ~ 1/4 1/2 1/4 I 16- 0 Removed Figure 4: A-Probabilities after \n2 Allocations for A (v1OO), and 1 allocation for B (v200). only 2 of the 3 registers are allocated at \nthe entrance analysis indicated that the value stored at #11 would to block X (for registers A and C), \nbut prior to loading be available at #12 in a register, so the load could be D it is necessary to load \nB without destroying A or C removed. (Graph coloring algorithms do not indicate and this uses all three \nregisters. Similarly, B cannot be this level of register availability information.) in a register at \n#2 because all three registers must be After allocation, C were effectively al\u00ad register A and in use \nat the end of block Z holding the values of A, C, located registers for the inner region, and a load \nof B and E thus preventing the value of B from being held was removed. In total, 5 of 8 loads and 2 of \n4 stores in a register over that control flow path. were removed from the loop. Figure 6 gives the code \nas After the loads are removed, simple data flow anal-it would appear after allocation and assignment \nwith ysis indicates that further improvements can be made the register contents after each instruction \ngiven in by removing the stores of A (at #8 and #15). If A is parenthesis. live on exit to the loop, \na store of A must be added to Our implementation actually gives a better alloca\u00ad the Post-Exit. tion \nthan the one described above by removing instruc- Note that removal of the load B, vIO at #12 was tions \n#1, 2, 8, 11, 12, 13, 15, and 16 for an estimated possible without allocating a register to B for its \nentire cost of 50 fewer instruction. The better allocation was live-range. B must be stored at #11 so \nthat it may be found because the implementation chose to remove in\u00adloaded at #2 in a subsequent iteration, \nbut probability struction #2 whereas the previous (hand-calculated) Pre-Header Iload A, v1OO I 2. load \n3. add B, vI, V2 v2, V3 { 25%, 100} 4. load 5. load C, D, V4 V5 { { 25%, 3%, 100} 100] 6. add v4, v5, \nV6 7. add v3, v6, v1OO 8. store v1OO, A 9. load E, V8 { o%, 100} 10. add v1OO. v8. v200 11. store v200, \nB z 12. 16. 13. load E, v1l { 50%, 50) 17. load C, v14 { 25%, 100} 14. add v200, vii, v1OO * 18. add \nv1OO, v14, v15 15. store v1OO, A 19. store v15, E --t~ Figure5: Global Probabilities after 3 Allocations \nPze-Header load A, rl load C, r2 {$ ;: =1 x + 1. (A; C, -) 2. load B, r3 (A, C, B) 3. add rl, r3, r3 \n(A, C, A+B) 4. 5. load D, rl (D, C, A+B) 6. add r2, rl, rl (C+D, C, A+B) 7. add 8. r3, rl, rl (A, C, \nA+B) 9. load 10. add E, rl, r3 r3, r3 (A, (A, C, C, E) B) 11. store r3, h (A; c; B) z 12. (A, C, B) 16. \n(A, C, B) 13. load E, rl (E, C, B) 17. 14. add r3, rl, rl (A, C, B) m 18. add rl, r2, r3 (A, C, E) 15. \n19. store r3, E (A, C, E) P.St-Ex~t I store rl, A (A, C, E) I Figure 6: Code After Register Allocation \nand Assignment (Register Assignments in Parenthesis) 307 example chose #4. The implementation simply \nhap\u00adpened to break the tie among the candidates of merit 25 differently. 4.3 Probabilities Improve Beatty \ns Algorithm Our algorithm is an improvement to Beatty s register allocation scheme [Bea74]. His algorithm \ndoes local al\u00adlocation followed by global allocation through the re\u00admoval of loads and stores to loop \npre-header and post\u00adexits. Our algorithm differs from his in two important ways: ours uses probabilities \nto provide better global allocation, and ours separates register assignment from register allocation. \nBeatt y s algorithm uses only bene\u00adfit analysis (estimates of execution count) to determine which global \nentities are good candidates for register allocation. Absolutely no attempt is made to quan\u00adtify the \neffects of allocating a register to a particular set of paths leading to a use. Probabilities directly \nmeasure the costs of allocating a register in a partic\u00adular code region; a low probability indicates \nthere is great competition for registers in the region, a high probability indicates less competition. \n(A probability of 1 indicates absolutely no competition, and hence a free allocation,) Probabilistic \ncost measures improve Beatty s algorithm by guiding it to make good alloc~ tion decisions by balancing \nbenefit and cost estimates. Our probabilistic register allocator works in three phases (in order): local \nregister allocation, global reg\u00adister allocation, and register assignment. Local al\u00adlocation is done \nby the simple, effective scheme of spilling (only when necessary) that value whose next use is most distant. \nGlobal allocation is done as out\u00adlined in the previous sections. Beatty s algorithm com\u00adbines global \nallocation and register assignment into one phase (much as graph coloring algorithms do). Keep\u00ading allocation \nseparate from assignment simplifies and improves the register allocation/assignments that can be found, \nOnce registers have been allocated to live-ranges, it is necessary to assign registers to them. The previ\u00adous \nallocation phases guarantee that there will never be a point in the program that is over-allocated, but \nso far no legal assignment haa been found (or even shown to exist). All of the variables that have been \nallocated registers are assigned registers using graph\u00adcoloring techniques [Cha82], [BCKT89], [CH90]. \nAn important difference between using graph-coloring for allocation (as other algorithms do) and for \nassignment (as we do) is that failure to find a legal coloring (un\u00adlikely) does not necessitate spilling \na value; we must simply insert code to change register assignments or duplicate a code fragment with \na new set of register assignments. 5 Implementation Results A prototype probabilistic register allocator \nhas been built as part of an experimental code generator for an ANSI C compiler ( lcc [FH91b] [FH91a]). \nThe code generator produces MIPS R2000 assembler. The table in Figure 7 summarizes the results of run\u00ad \nning the compiler on the Stanford benchmarks suite. Each program was run with three different register \ncon\u00adfigurations for both integer and floating point registers. For integer registers the configurations \nwere 19 regis\u00adters (9 caller-saved, 10 callee-saved), 12 registers (6, 6), and 6 registers (3, 3). For \nfloating point, the con\u00adfigurations were 11 registers (5, 6), 8 registers (4, 4), and 4 registers (2, \n2). The numbers of loads and stores in the table represent dynamic execution counts. The columns labeled \nOptimal represent the actual number of loads and stores that could possibly have been re\u00admoved by register \nallocation had there been an unlim\u00adited number of registers. z The results do not include the cost of \nsaving and restoring callee-saved registers. This cost is negligible in all but the recursive procedures \n(eg. towers.c and puzzle. c), and is modest and essentially unavoidable in those. The great number of \nlocally removed loads and stores is the result of the fact that all basic block level temporaries that \nare used more than once are treated like local variables via a single initializing store fol\u00adlowed by \nsubsequent loads. The local register allocator is responsible for their removal. The Stanford Benchmarks \nthat are not listed all had 100% of the possible loads removed at all regis\u00adter levels. The sub-optimal \n(and identical) results for intmm.c, queens.c, and fft. c (floating) at the two great\u00adest register levels \nare due to charging for the unavoid\u00adable loads of parameters passed on the stack 100% of the other loads \nwere removed at both register levels. The identical (sub-optimal) results for towers,c at 12 and 19 registers \nstem from an implementation bug that created a load of a local variable at the beginning of a procedure \n(its pre-header) because a definition-free path existed from the beginning of that procedure to the potentially \nuninitialized use of that variable. Ex\u00adcept for this additional load, all other possible loads were removed \nfrom towers. c at 12 and 19 registers. Our algorithm removed virtually all of the loads/stores in the \nStanford Benchmarks. We expect to get similar results on industrial strength bench\u00ad 2For a few programs \n(eg. intmm.c), the number of possible loads that may be removed is overstated because the statistics \ndo not reflect the fact that an initial load of a parameter passed on the stack is unavoidable. This, \nof course, results in an un\u00adderstatement of our algorithm s effectiveness. Load Removal (Execution Counts) \nStore Removal (Execution Counts) II Program Registers I Optimal I Locally I Globally I Percent Globally \nI pe~cent 1 Removed Removed intmm.c 19 977854 521726 454528 99.8 12 977854 521726 454528 99.8 6 977854 \n457726 200128 67.3 queens.c 19 696950 220450 465200 98.4 12 696950 220450 465200 98.4 61 696950 I 220450 \n288100 73.0 quick.c 19 II 734725 ] 273098 461627 100.0 12 734725 273098 461627 100.0 6 734725 257468 \n414742 towers.c 19 614192 458887 138908 12 614192 458887 138908 6 614192 450696 138908 fft.c 19 2036794 \n1598413 438221 12 2036794 1598413 392001 2036794 1352023 303859 (floating; fft!c  ii 11090 5170 5895 \n8 11090 5170 5895 4 11090 5170 5850 Figure 7: Results on Selected marks such as the SPEC Benchmarks \nwhen we do more exhaustive tests of the code generator. Unfortu\u00adnately, lcc does not do any global optimizations \nsuch as aliaa analysis or global common subexpression elim\u00adination that would create many additional \ncandidates for global register allocation and, therefore, test our techniques more strenuously. (Lee \nonly considers tem\u00adporaries, and scalar local variables and parameters as candidates for register allocation.) \nWe have, therefore, chosen to create a similar register scarcity artificially by lowering the number \nof available registers. While not a perfect measure of how the algorithm would do in an optimizing compiler, \nthe numbers are impressive nonetheless. 5.1 Compiler Performance The current register allocator is a \nprototype imple\u00admentation that slows lCC S compilation rate from over 1000 lines/see. to about 10 lines/see. \nModestly tun\u00ading this prototype implementation would certainly in\u00adcrease compilation speed by 20 to 50 \ntimes. The naive implementation recomputes dataflow and A-probability information for the current loop \nafter each load is removed. Doing this recomputation in\u00adcrementally would likely increase the allocation \nspeed dramatically, Alternatively, a quicker, but less accurate, alloca\u00adtion heuristic could be built \nthat would not recompute these values, but would instead use a static snapshot of the probabilities. \nThis would avoid recomputing 91.5 97.3 97.3 96.0 99.9 97.7 81.3 99.8 99.8 99.6 80245 100!0 75445 74.7 \n177751 100.0 183401 5650 177751 100.0 183401 5650 155151 87.7 213785 101453 112332 100.0  +%-l-+% + \n213785 101453 + 112332 100.0 +%-l--=+4-=-i 311413 180258 131155 100.0 311413 180258 114772 94.7 479938 \n401267 78491 99.9 479938 401267 73191 98.9 479938 360181 67849 89,2 d=446 98.3 446 98.3 425 96.7 --E_E \n=ti Stanford Benchmarks. the A-probabilities after each load is removed. The static initial probabilities \nwould still serve as an accu\u00adrate metric of the relative scarcity of registers faced by each register \ncandidate. 6 Other Uses for Probabilities Register probabilities are graph-coloring algorithms range. \nFor instance, presently prune the interference graph general enough to help site spills and split live\u00adgraph \ncoloring heuristics by making the trivial ob\u00ad servation that any live range with fewer conflicts than \navailable registers can be removed from the graph and subsequently assigned a register. Probability y \nanaly\u00adsis can additionally indicate, for those live ranges with too many conflicts, which will probabiy \nbe allocated a register thus intelligently directing further pruning of the interference graph. Similarly, \nprobabilistic register allocation could be used after graph-coloring techniques have exploited all the \ntrivial pruning opportunities available. If the prun\u00ading stage fails to allocate registers to every node \nin the graph, our probabilistic algorithm could be used to al\u00adlocate registers among the (presumably) \nmany fewer remaining register candidates. 7 Conclusion Using probabilities to guide global register allocation \nafter a local allocation phase provides a simple and ef\u00ad fective algorithm that avoids complex graph-coloring \nspill heuristics, It focuses attention on the prob\u00ad lem of allocating registers over assigning registers \na weakness inherent to previous graph coloring schemes. Graph coloring algorithms awkwardly handle splitting \nlive-ranges when registers are exhausted, but proba\u00adbilistic global allocation completely subsumes this \ncon\u00adcern. Finally, because of the clean separation between local allocation and global allocation, our \nprobabilis\u00adtic algorithm allows existing excellent local register al\u00adlocation and instruction scheduling \nalgorithms to run unconstrained by global allocation policies. S Acknowledgements David Callahan, Chris \nFraser, Robert Henry, and Brian Koblenz provided comments content and accuracy of this paper, References \n[BCKT89] Preston Briggs, Keith Kennedy, and Linda heuristics for register ceedings of the SIGPLA that \nimproved the D, Cooper, Ken Torczon, Coloring allocation. In Pro-N 89 Conference on Programming Language \nDesign and plementation, pages 275-284, 1989. Im\u00ad [Bea74] J. C. Beatty. Register assignment algorithm \nfor generation of highly optimized object code. IBM Journal of Research and Devel\u00adopment, 18(1):20 39, \nJanuary 1974. [BL92] Thomas Ball and James R. Lams. Opti\u00admally profiling and tracing programs. In Proceedings \nof the 19th Annual Symposium on Principles of Programming Languages, pages 59-70, January 1992. [CAC+81] \nG. J. Chaitin, M. A. Auslander, A. K. Chandra, J. Cooke, M, E. Hopkins, P. W. Markstein. Register allocation \ngraph coloring. Computer Languages, 57, January 1981, [CH90] Fred C. Chow and John L. Hennessy, and via \n6:47- The priority-based coloring approach to register allocation. ACM Transactions on Program\u00adming Languages \nand Systems, 12(4):501\u00ad536, January 1990, [Cha82] G. J. Chaitin. Register allocation&#38; spilling via \ngraph coloring. In Proceedings of the ACM SIGPLAIV 82 Symposium on Com\u00adpiler Construction, pages 98 101, \nJune 1982. [CK91] [FH91a] [FH91b] [FL88] [Fre74] [HFG89] [LH86] [Mor91] David Callahan and Brian Koblenz. \nReg\u00adister allocation via hierarchical graph col\u00adoring. In Proceedings of the SIGPLAN 91 Conference on \nProgramming Language De\u00adsign and Implementation, pages 192-203, 1991. Christopher W. Fraser and David \nR. Han\u00adson. A code generation interface for ANSI c. Software-Practice and Experience, 21(9):963-988, \nSeptember 1991. Christopher W. Fraser and David R, Han\u00adson. A retargetable compiler for ANSI C. SIGPLAN \nNotices, 26(10), October 1991. Charles N. Fischer and Richard J. Leblanc, Jr. Crafting a Compiler. Ben\u00adjamin/Cummings, \nMenlo Park, California, 1988. R. A. Freiburghouse, Register allocation via usage counts. Communications \nof the ACM, 17(11), November 1974, Wei-Chung Hsu, Charles N. Fischer, and James R. Goodman. On the minimization \nof loads/stores in local register allocation, IEEE Transactions on J ofiware Engineer\u00ad ing, 15(10):1252-1260, \n1989. J. R. Larus and P. N. Hilfinger. Register al\u00adlocation in the SPUR lisp compiler. In Pro\u00adceedings \nof the SIGPLAN 86 Symposium on Compiler Construction, pages 255-263, 1986. W. G. Morris, CCG: A prototype \ncoag\u00adulating code generator, In Proceedings of the SIGPLAN 91 Conference on Program. ming Language Design \nand Implementa\u00adtion, pages 45 58, 1991. \n\t\t\t", "proc_id": "143095", "abstract": "<p>A new global register allocation technique, <italic>probabilistic register allocation</italic>, is described. Probabilistic register allocation quantifies the costs and benefits of allocating variables to registers over live ranges so that excellent allocation choices can be made. Local allocation is done first, and then global allocation is done iteratively beginning in the most deeply nested loops. Because local allocation precedes global allocation, probabilistic allocation does not interfere with the use of well-known, high-quality local register allocation and instruction scheduling techniques.</p>", "authors": [{"name": "Todd A. Proebsting", "author_profile_id": "81100592757", "affiliation": "", "person_id": "P283229", "email_address": "", "orcid_id": ""}, {"name": "Charles N. Fischer", "author_profile_id": "81100312451", "affiliation": "", "person_id": "P43394", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143095.143142", "year": "1992", "article_id": "143142", "conference": "PLDI", "title": "Probabilistic register allocation", "url": "http://dl.acm.org/citation.cfm?id=143142"}