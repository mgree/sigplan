{"article_publication_date": "07-01-1992", "fulltext": "\n Compiler Support for Garbage Collection in a Statically Typed Language* Amer Diwan Eliot Moss Richard \nHudson ~ Object Systems Laboratory Department of Computer Science University of Massachusetts Amherst, \nMA 01003  Abstract We cortsidertheproblemof supportingcompactinggarbage collectioninthepresenceof moderncompileroptimizations. \nSinceourcolleetormaymove anyheapobject,it mustac\u00adcuratelylocate, follow, and updateall pointersand vahtes \nderivedfrompointers.To assist the collector,we extendthe compilerto emittablesdescribinglive pointers,andvalues \nderivedfrompointers,at eachprogramlocationwherecol\u00adlectionmay occur. Significant results include identification \nof a number of problems posed by optimizations, solutions to those problems, a working compiler, and \nexperimental data concerning table sizes, table compression, and time overhead of decoding tables during \ncollection. While gc support can affect the code produced, our sample programs show no sig\u00adnificant changes, \nthe table sizes are a modest fraction of the size of the optimized code, and stack tracing is a small \nfrac\u00adtion of total gc time. Since the compiler enhancements are atso modest, we conclude that the approach \nis practical, 1 Introduction As part of ongoing efforts to implement orthogonal persis\u00adtence [1] and \ngarbage collection for Modula-3 [2], we have designed and implemented compiler techniques to assist the \ngarbage collector and the persistent memory manager. Our work has been done in the context of Modula-3, \nbut is appli\u00adcable to other statically typed languages.l In the remainder of this section we describe \nthe requirements we had to meet to support garbage collection in our context. * this projectis supportedby \nNationalScience Foundation Grant CCR\u00ad8658074, Digital Equipment Corporation, Apple Computer, and GTE \nLaboratories, t t he authors can be reachedelectronicallyvia Intemetaddresses {diwan,moss,hudson}@cs.umass.ectu. \n1-t heM~UIa.3 tYP system allows some dynamism, but type s~etY of all constructs (except those permitted \nchecked at compile time. Permission to oopy without fee granted providad that tha copies direct commercial \nadvantage, the oniy in UNSAFE modules) can be all or part of +is material is ara not mada or distributed \nfor ACM copyright notice and the title of the publication and its data appear, and notice is given that \ncopying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, \nraquires a fea and/or specific permission. ACM SIGPLAN 92 PLD1-6/92/CA 01992 ACM 0-89791 -476-7 /921000610273 \n. ..$1 .50 With regards to persistence, our scheme must allow objects to be moved, and possibly removed \nfrom main memory al\u00adtogether, for buffer management [3, 4] purposes. Moreover, since orthogonality allows \nany object to become persistent, all objects need to be movable. This requirement is also es\u00adsential \nfor fully compacting garbage collection (cf. [5, 6]), which yields good locality and fast object allocation \ntime. Portability to a wide variety of hardware and software platforms is one of the key goals for Persistent \nModula-3. Therefore our scheme must not rely on any special hardware support (such as hardware pointer \ntags). Our scheme must have minimal impact on run-time per\u00adformance, Our work is being done in the context \nof a highly\u00adoptimizing compiler.2 Thus we must not defeat or disallow any compiler optimization. This \nis a challenge since the compiler and optimizer are not bound by the rules of the source language and \nmay introduce complex pointer manip\u00adulations. We also want to avoid tagging objects except when explicitly \nrequired by the language. In a statically typed language, the compiler knows which global variables contain \npointers. It also knows which stack locations and registers contain pointers at any point in a pro\u00adgram. \nIn the following seetions we describe a teehnique that exploits this compile-time knowledge to assist \nthe garbage collector in locating and updating pointers in the stack and in the registers, and at the \nsame time meets our requirements: the alility to move objects, portability, and minimal impact on performance. \nAfter describing the scheme, we present some experimental results. 2 Basic Problems Unambiguous full \ncopying collection (cf. [8, 5, 6]) must be able to determine if an objeet is reachable from other live \nobjects or from the roots. Moreover, the garbage collector must be able to find all pointers to a given \nobject so that they may be updated when the object is moved. These require\u00adments trartslate to a number \nof low level requirements on the collecto~ (i) it must be able to determine the size of heap atloeated \nobjects, so that they can be copied; (ii) it must be 20ur compiler is based on gcc 2.0 and uses its optimizer \n[7], able to locate pointers contained in heap objects, so they they can be both traced and update@ \n(iii) it must be able to locate pointers in global variables; (iv) it must be able to find all references \nin the stack and in the registers at any point in the program at which collection may occuu (v) it must \nbe able to find objects that are referred to by values created as a result of pointer arithmetic; (vi) \nand it must be able to update these vatues when the objects involved are moved. Modula-3 requires type \ndescriptors in heap objects which makes it straightforward to determine the size of heap allo\u00adcated objects \nand to find pointers within them. Thus it is easy to trace the heap. Since Modula-3 is a statically typed \nlan\u00adguage, compile-time location of pointers in globat variables is also simple. Locating pointers in \nthe stack and in registers is more difficult, because the stack layout and register assign\u00adments may \nvary even within a procedure. We must also be able to handle compiler temporaries containing pointers, \nin the stack and in registers. Updating and following pointers is complicated if pointers do not always \npoint directly to objects. We say a pointer is tidy if it points at the object header (or some standard \nfixed offset from the header), Untidy pointers may be intro\u00adduced by language features or by compiler \noptimizations. In Modula-3, pointers to the interior of objects are created by the VARparameter passing \nmechanism, by the WITH state\u00adment, and by SUBARRAY expressions. Here are examples of optimization that \ncreate untidy pointers:3 Strength Reduction: The body A[i] := 13; INC (i); of an array initialization \nloop can be turned into *p+ + = 13, with p appropriately initialized. Virtual Array Origin: If A is an \narray of type ARRAY [7. .13 ] OF INTEGER, the obvious method of ac\u00adcessing A[i ] is: *(&#38;A [7] + (i \n-7) * sizeof (int)) The subtraction can be avoided by creating an (untidy) pointer to A [ O] and using \nit to index into the array. Common Subexpression Elimination: The code A[i, j] := 10; A[i, k] := 20; \nmay be compiled into t = &#38;A[i]; *(t + j * sizeof (int)) = 10; *( c + k * sizeof (int)) = 20; if the \noptimizer can determine that t is being computed twice and that i is not updated. Srnour ~XmpIeSwe p~sent \nsource cede in Modula-3 md com\u00adpiler/optimizer output in C. Note, though, that our ModuIa-3compilergen\u00aderatesassemblycode. \nDouble Indexing: The code A[i.] := 1; B[i-] := 2; may be optimized to tl = &#38;AIO] + (i * sizeof(int)); \nt2 = &#38;BIO] -&#38;AIOl; *tl =1; *(tl +t2) =2; which is useful on machines that have ad&#38;essing \nmodes with two or more index registers, such as the SPARC. We use the term derived value for any value \ncreated by pointer arithmetic, and the term base value for any value participating in the derivation. \nNote that a derived value may bean untidy pointer to the interior of an object (strength reduction example), \nan untidy pointer that points outside the object to which it refers (virtual array origin example), or \neven a non-pointer value (double indexing example), and the examples given above may not exhaust the \npossibilities. In Section 3, we describe a scheme that handles a broad class of pointer arithmetic, which \nincludes all optimization perfOlllX3d by gee.  3 solutions We construct tables at compile time to assist \nthe collector in locating and updating all pointers in the stack and in the registers. We construct one \nset of tables per gc-point. A gc-point is a program point where a collection might occur? An attennative \nis to use tags or type descriptors in the stack. We decided against tagging stack allocated objects because \nthe stack layout is relatively static, and thus amenable to tab\u00adular description, and stack frames are \ncreated and destroyed at a high rate, so the overhead of maintaining any kind of descriptors in the stack \nis likely to be unacceptable. We construct three kinds of tables for each gc-point in a procedure stack \npointers, register pointers, and deriva\u00adtions. The stack pointers table encodes the locations in the \nprocedure s stack frame that contain live tidy pointers at the gc-point. Likewise, the register pointers \ntable encodes the registers that contain live tidy pointers at that gc-point. The derivations table describes \nthe derivation of all derived val\u00adues live at the gc-point. In this section we concentrate on the conceptual \ncontents and usage of the tables, and defer consideration of implementation issues to Section 5. At garbage \ncollection time, the first task is to locate the tables for each frame on the stack. This is done by \nextract\u00ading return addresses from frames and using them to search a table that maps gc-points to gc tables. \nWe can use the stack pointers table directly. Using the register pointers table requires additional information \nabout which registers were 4we givede~ilsOnchmsing tk.t?points~ wtion 5. Base Location Relation a - \nbl + b2 b3 + Figure 1: Derivations table for a at program point p saved at each call point, so that \nthe register contents can be reconstructed as of the time of the call, The derivations tables are needed \nfor updating derived values when their base values change. At each gc-point, each live derived location \nis associated with a table that describes its derivation at that point. For example, Figure 1 shows the \nderivation table for a variable a whose value is derived as: a := bl + b3 -b2+E where E is some integer \nexpression that does not use pointers or derived vatues. There are two steps to updating the derived \nvalues. The first step occurs immtilately after aIl the tables have been located. In this step, the value \nof E is calculated and stored in a. To calculate E we adjust a by applying the inverse operation for \neach base value of a: a :=a-bl-b3+b2 Note that the order in which derived values are updated is crucial: \na derived value must be updated before any of its base values. Thus, if a base value is a derived value \nitself, then its value must be adjusted ajter that of any vatues derived from it and bejiore any values \nfrom which it is derived. We take two measures to ensure this ordering. First, we visit the derivations \ntable of a callee before that of its caller. Second, the derivations tables for a given gc-point are \nordered such that the derivations table of a derived value comes before the derivations tables of its \nbase values. Note that circular dependencies cannot occur because derivations are always made from previously \ncalculated base values. The second step of the update occurs after garbage collec\u00adtion has completed. \nIts purpose is to reconstruct the derived values from the updated bases. This step uses the new base \nvalues tore-derive a. In the above example the new values of bl and b3 are added to a while that of b2 \nis subtracted, Once again the order in which updates occur is importan~ a value needs to be updated before \nany values derived from it. This order is exactly the reverse of that required in the previous step. \nWe have made two assumptions in the design of the deriva\u00adtions table. Fkst, we assume that the base values \nare live whenever values derived from them are live. This is nec\u00adessary for us to be able to update the \nderived values. In Section 4 we show how we ensure this property. As a side effect of this requirement, \nwe never need to follow derived values to find reachable objects. This is because we require the lifetime \nof a base value to include that of its derived values. Hence, any object reachable via a derived value \nis also reachable via anon-derived value. Second, we assume that the operations used in the derivation \n(+ and in this example) have inverses. Invertibility allows us to use the technique outlined above to \nadjust a derived value if one (or more) of its base values change as a result of collection. In the above \nexample, invertibility allowed us to update a given only the base values; no information about E was \nneeded. Our current implementation handles two kinds of operations in a derivation (+ and -),5 but it \ncan easily be extended to handle other invertible operations as well. Thus, we currently handle all deriving \nexpressions of the form: Ep~-Xqj+E i 3 where pi and qi are pointers or derived values, and E does not \ninvolve either pointers or derived values. To handle non\u00adcommutative operations, we would need to be \ncareful about the order of the base wdues in the table for each derivation. To handle non-invertible \noperations the tables would have to be redesigned to allow the entire deriving expression to be recomputed \nat run time. 4 Some Complications The job of the compiler would be simple if it could correctly, statically, \nand unambiguously identify the base values for each derived value at any given point in the program. \nUn\u00adfortunately, this is not the case for at least three scenarios: (i) when a base vatue dies before \na value derived from it, (ii) when multiple derivations of a value reach a gc-point, and (iii) when \nindirect references are used as base values in a derivation. In this section we describe each of these \nproblems and present our solutions to them.  The following example illustrates the Dead Base problem: \nSOURCE A: REF ARRAY [1. .10] OF INTEGER; FOR i. := 1 TO LAST (A ) DO s := s +A-[i]; END ; OPTIMIZED \nfor (i =1; i<=10; i++) { s =s +*A++; <gc-point> } 5~e~e are me onlYowmtions exploited by tbe 9CC op~i~r. \n If data flow analysis can determine that A h dead after the loop, then the compiler may use A to efficiently \nstep through the array. In this code, A s base value (the original value of A) k not available to the \ncollector inside the loop. Hence, if collection is triggered at gc -point then the collector will be \nunable to update A. We solve this problem by making our compiler consider a use of a derived value as \na use of each of its base values.b This forces the compiler to retain the base values for the lifetime \nof the values derived from them. While this can affect perfor\u00admance by increasing the lifetime of variables, \nwhich in turn can increases register pressure, we try to minimize its impact by careful selection of \nbase values. When multiple copies of a base value are available, we give preference to stack allocated \nbase values over register allocated ones (to reduce register pressure), and to values in user declared \nvariables over values in compiler temporaries (to shorten temporary lifetimes). The problem of Ambiguous \nDerivations occurs when mul\u00adtiple derivations of a derived value reach a program point. This is illustrated \nin the following example: SOURCE i := 1; WHILE ( cond) IF (inv) THEN PRINT (P[i]); ELSE PRINT (Q[i]); \nEND ; INC (i); END ; OPTIMIZED i=l; if (inv) t = &#38;P[o] + 1; else t = &#38;QIO] + 1; while ( cond) \nPRINT (*(t + i++)); If inv is invariant in the loop, the optimizer may hoist the conditional out of the \nloop causing t s derivation to be am\u00adbiguous inside the loop; t is derived from either&#38;P [ O] or \n&#38;QIO]. We solve this problem by introducing path variables for each ambiguously derived value. The \npath variable encodes which one of the possible derivations actually happened. The following code segment \nillustrates it for the example above 6we needtodofii~onlyif~ederived value is live at some later &#38;W-P~~ \ni=l; if (inv) { t = <path 1 taken> t = &#38;P[o] + 1; 1 else { t . <path 2 taken> t = &#38;QIO] + 1; \n } while (cond) PRINT (*(t + i++)); When our compiler detects an ambiguous derivation, it emits tables \nfor each possible derivation; the appropriate deriva\u00adtions table is chosen at run time based on the value \nof the path variable. An alternative solution to the ambiguous derivations prob\u00adlem is to use Path Spliffing \nsimilar to Chambers and Ungar [9]. Figure 2 demonstrates this technique. In Figure 2, the body of the \nloop is duplicated such that the derivation of t in each copy of the loop body is unambiguous. Currently \nwe use the path variable scheme to disambiguate derivations. Both solutions have overheads. The path \nvari\u00adable technique adds assignments to the program; the path splitting technique increases the code \nsize rmd is also more complicated than the path variable scheme. We selected the path variable scheme \nbecause it is simpler rmdwe believe am\u00adbiguous derivations are rare, and thus the run-time overhead is \nnot significant. The problem of lndirecr References occurs when the loca\u00adtion of a base value is not \nknown at compile time. This can happen if the base value is obtained by an indirect reference. SOURCE \na: REF ARIVAY [1..5] OF REF ARRAY [ 5 ..9] OF INTEGER; foo (an[21A [61); COMPILED foo ( *(a + sizeof \n(int)) + sizeof (int) ) In the example, if the parameter to f oo is passed by ref\u00aderence, then the expression \npushed on the stack is derived from the value in memory location a + si zeof ( int ). Hence, we cannot \ndetermine the location of the base value at compile time. We solve this problem by preserving the internwdate \nreference in a stack slot or register, thus causing the derivation to refer to a value in a compile-time \nknown location. Indirect references pose a problem only for ma\u00adchines with complicated addressing modes. \nWe expect that this problem will not arise for load/store architectures. II t=&#38;P[o] + 1 t= &#38;QIO]+ \n1 PRINT (*t + i++) 1 Figure 2 Dkwtbiguating 5 Implementation Issues The organization of the tables and \nthe selection of gc-points might have a significant impact on the performance of our scheme. The tables \nshould be as small as possible but at the same time the collector must be able to extract the information \nit needs efficiently; compactly encoded tables are likely to have higher decodhg overhead. Since tables \nare emitted at each gc-point, the number of gc-points affects the space overhead of our scheme. Selection \nof gc-points is especially relevant in a pre-emptive multi-threaded environment. Since a thread switch \ncan occur at any time, we must be prepared to handle a collection when a thread is not at a gc-point. \nIn Sections 5.1,5.2, and 5.3, we survey some possible solutions to these concerns and justify the choices \nwe have made. 5.1 Table Organization Storing a list of all live tidy pointers in the stack at each gc\u00adpoint \nin a procedure is likely to be expensive. We expect that the variation in stack layout at different gc-points \nis usually small and thus we consider using delta tables at gc-points. A delta table encodes how the \ninformation at a given gc-point differs from the information in some other table (called its ground table). \nOur implementation uses a scheme called &#38;main. In the 6-main scheme, each procedure has a main table \nwhich describes all slots in the frame of that procedure that contain pointers at some gc-point. Given \nthis, a delta table merely describes which entries of the main table are valid at the gc-point. Since \nthe delta table needs to contain only liveness information, only one bit per entry in the main table \nis needed per gc-point. Our current implementation uses the 6-main main scheme for stack allocated non-derived \npointers only, The registers table has 1 bit per hard register; any attempt to compact this information \nfurther is likely to yield little or no improvement. Wedonotuseadeltaschemeforthederivations tablebecause \nin our experience derived values are rar~ moreover, they tend to have short lifetimes and thus the information \nvaries I I t= &#38;P[o]+1 derivations by path splitting 7 0 ~ Continuation Figure 3: Packing words \ninto bytes. widely between gc-points. For instance, an important source of derived vahtes in Modula-3 \nis call-by-reference, which creates derived values that are live at only one gc-point (the call). We \ntherefore store full information for derived values at each gc-point. In our measurements we observed \nthat delta and registers tables for adjacent gc-points are often identical. Also, many registerx tables, \nmany delta tables, and most derivations ta\u00adbles are empty. We keep a descriptor at each gc-point which \nindicates if any of the tables at that gc-point are empty, or if they are identical to the table at the \npreceding gc-point. 5.2 Compressing the tables Despite the compact representation provided by the if-main \nscheme, we found that the tables were unacceptably large about45% of the size of optimized code (see \nSection 6.1), In this section, we describe the packing techniques that we use to reduce the table sizes \nto about 16% of the optimized code size. The stack tracing tables are generated in two phases. The tint \nphase produces tables of 32 bit words. Each memory location is encoded into a word, and the delta tables \nand register pointers tables occupy an integral number of words. The second phase goes through the table \nof words and packs 7~e num~rof WOrdSused for a delta ora register pointers table depends on either the \nnumber of entries iu the ground table or the number of hard registera. 7 10 Continuation Base Register \nFigure4: Aground table entry that fitsintol byte. them into bytes. Thehigh bitofeach bytedetermines ifitis \nthe last byte in the encoding of a word or if the following byte is also part of the word (see Figure \n3). The bytes are stored from most-to least-significant, and the first byte is sign\u00adextended, since many \noffset (and hence many word values) are negative. Each entry in a ground table encodes a stack location \nthat is live at some point in the procedure. The low two bits of the encoding identify the base register \n(FP, SP, or AP, for the VAX), The remaining bits are the offset (in words) from the base register. Most \nentries in the ground table fit into one byte each (see Figure 4). Each entry in a derivation table encodes \neither a register or a memory location. This encoding is more involved than that of the ground table \nbecause entries in this table are not restricted to {FP, SP, AP} + offset. Thus, most entries in the \nderivations table require 2 bytes. The register pointers table contains 1 bit per hard registe~ most \nof these tables compact to 1 or 2 bytes each. The delta table contains 1 bit per entry in the ground \ntable. Most of our procedures had fewer than 8 stack allocated pointers, al\u00adlowing most delta tables \nto be compressed to 1 byte. Besides the above mentioned tables, we have a descriptor at each gc-point \nthat encodes whether any of the tables at the current gc-point are empty or are identical to those at \nthe previous gc-point. This information packs into 1 byte per gc-point, At each gc-point we find the \nappropriate tables by us\u00ading a mapping from program counter values to gc tables. We compress this by \nusing distances between gc-points in conjunction with the start address of the enclosing module, instead \nof using 32 bits for the program counter value at each gc-point. The distances are not available until \nlink time our compiler assumes that distances between adjacent gc points can fit in two bytes. If the \ndistances had been available to our compiler, we would have been able to compress most distances to 1 \nbyte, yielding an additional savings of 1 byte per gc-point. There is one important consideration that \nour current im\u00adplementation does not handle each pointer contained in an array is treated as a separate \nvariable. We have no way of indicating patterns (e.g., starting from address a, the next 200 stack location \nare pointers). We have a design for compact descriptions of arrays, and it will be simple to add it to \nthe implementation. Our benchmarks did not use any such ar\u00adrays, so adding this space optimization would \nnot affect the result we report here. 5.3 Selecting GC-Points Selecting gc-points in a single threaded \nenvironment is easy: all calls can be considered gc-points since all allocation is done via a call and \nhence collection will never be triggered at a non-call Point.g Of course, some calls do not need to be \ngc-points. If the compiler performs inter-procedural analysis then it can determine that some procedures \nnever allocate any heap storage and thus calls to them need not be gc-points. In our current implementation \natl calls except for ones to non-allocating procedures are considered gc-points. The non-allocating procedures \nare statically determined (for instance run-time error reporting routines) rather than via inter-procedural \nanalysis. We may explore refinements in future work. Selecting gc-points in a multi-threaded environment \nwith pre-emptive scheduling is more challenging since collection may be triggered while threads are suspended \nat non-gc\u00adpoints. In our approach, if a thread triggers collection then the suspended threads that are \nnot at gc-points are resumed and allowed to run until they all reach gc-points. We accomplish this by \nensuring that resumed threads reach (and block on) a gc-point in a bounded amount of time, and that they \ndo not do any allocations. Ensuring that a resumed thread does not atlocate any memory before it reaches \na gc-point requires that most calls be gc-points. To avoid an unbounded wait for threads to become ready \nfor collection, we insert a gc-point in all loops that do not have a guaranteed gc-point in them. A loop \nhas a guaranteed gc-point if an allocating-procedure or a nested loop is executed at each iteration of \nthe loop, regardless of the path taken through loop. In addition to gc-points at calls and in loops, \nwe need gc-points at places where a thread can block.9 6 Results This paper is not about a fast garbage \ncollection technique. It is about how garbage collection can be assisted by compile\u00adtime acquisition \nof information, and have minimum impact on compiler optimizations. As such, our results are not tim\u00adings \nfor the garbage collectou they are measurements of the sizes of the compile-time tables generated, the \neffect our schemes have on compiler optimizations, and the time re\u00adquired to decode the generated tables. \nIn Section 6.1 we give the table sizes for each of our benchmarks, in Section 6.2 we describe the effects \nof our scheme on the quality of gener\u00adated code, and in Section 6.3 we report the time required to decode \nthe tables at garbage collection time. smi~MII~Ot~O&#38;if~l[~ationis done inline, in which case we.must \ninclude inIine akeations as gc-points. 9k most ~Ystcmsthese points are call points sotheydonotneedsweial \ntreatment. 6.1 Table Sizes decodhg overhead of &#38;main, However, our measurements We measured table \nsizes for 4 Modula-3 programs: typereg, FieldList [10], takl [11] and destroy [12]. typereg implements \ntype registration and type com\u00adparisons using structural equivalence for our Modula-3 run\u00adtime system, \nFieldLi st implements command parsing for a UNIX shell. We considered t ypereg and FieldLi st to be good \nprograms to use for our measurements for two reasons. First, they are rest programs rather than synthetic \nbenchmarks. Second, they consist of a number of short rou\u00adtines with frequent calls. Since we consider \nmost calls as gc-points, we felt that this would represent a worst case sce\u00adnario. We chose takl because \nit is a well known benchmark. We chose dest roy because it is heavily recursive and trig\u00adgers garbage \ncollection frequently, and thus stresses the code that decodes the tables at garbage collection time. \nIn Table 6.1 we list relevant data about each of the bench\u00admark programs. (The -opt suffix indicates \nthat compiler optimizations were turned on.) In Table 6.1 we give the cor\u00adresponding table sizes, under \nboth the full information and the &#38;main schemes, with and without each of byte and identical\u00adto-previous \ncompression. Here is the key for interpreting the columns of these tables: Size Program size in bytes. \nNGC Number of gc-points that had non-empty tables. NPTRS Totat number of pointers. NDEL Number of delta \ntables emitted. NREG Number of register pointers tables emitted. NDER Number of derivations tables emitted. \nPlain Table sizes as a percentage of code size with no com\u00adpression. Previous Table sizes as a percentage \nof code size when a descriptor is used to indicate that a table is identicat to that at the previous \ngc-point. Packing Table sizes as a percentage of code size when byte level packing is used. PP Table \nsizes as a percentage of code size when both Pre\u00advious and Packing are used. None of our benchmarks had \nany ambiguous derivations and therefore the compiler introduced no path variables. From Table 6.1 it \ncan be seen that storing full information at each gc-point (with packing) generally produces larger tables \nthan those produced by &#38;main (with packing). However the difference is not great. 6-main is based \non the assumption that procedures have many non-empty gc-points and many live stack atlocated pointers \nat each gc-point. If this is not the case, then storing full information at each gc-point can yield table \nsizes comparable to 6-main without the extra run-time indicate that the run-time overhead of decoding \nthese tables is small, so there is little practical benefit to storing full information at each gc-point \n(see Section 6,3), For the 6-main scheme, both Packing and Previous tend to reduce table sizes. Applying \nboth Packing and Previous reduces the table size from about 45 %oof the size of the optimized code to \nabout 16%. 6.2 Effects on the optimized code Our schemes have no effect on the optimized code produced \nfor any of our benchmarks. There are, however, some in\u00adstructions introduced in the unoptimized code. \nMost of the differences result from needing to preserve indirect refer\u00adences at gc-points. There are \n12 cases where this occurs in typereg for the VAX and 32 cases in FieldLi st for the VAX; here is a typicat \ncase Without gc restrictions add12 (r7) , rO With gc restrictions movl (r7) , rl add12 rl, rO Our solution \nto the dead basepointerproblem adds two moves to the unoptimized FieldLi st; both are inserted to pre\u00adserve \na clobbered base value. Note that gc-safety, as proposed by Boehml [13], encoun\u00adters the same requirement, \nso this is a basic safety concern rather than a result of our approach. Also, this particular code effect \nis not likely to occur on load/store architectures, Compiler support for garbage collection may have \nother ef\u00adfects on the generated code besides the ones described above. In particular, most generationat \nschemes perform sfore checks [14] when pointers might be written into heap locations. This is a property \nof the garbage collection schemel 1and therefore we do not charge this overhead to our scheme, 6.3 Timings \nWhile good compression of the gc tables is important for our scheme to be practical, the time to decode \nthose tables must also be reasonable. We do not yet have a complete implementation of the garbage collection \nrun-time, but we have an initiat version of stack tracing which we timed on the destroy benchmark. destroy \nbuilds a complete tree of specified branching factor and depth. It then repeatedly builds a new subtree \nat some fixed intermediate depth, and 10Aet~anY, Boehmdoesnot appear to have recognized the indirect \nref\u00aderence problem in the work we cite above, He focused on situations that extend the lifetime of a \nderived pointer but did not address cases where the lifetime of a base pointer might be shortened, e.g., \nby its being overwritten in the heap. 11For~s~ce, pagetripscouldbeusedinsteadofstorechecksto imPk.\u00adment \ngenerational schemes. Program Size NGC NPTRS NDEL NREG NDER typereg 3154 59 87 58 26 3 typereg-opt 2289 \n52 122 39 41 0 FieldList 4594 51 103 45 18 11 FieldList-opt 3330 82 319 61 70 11 takl 457811860 tald-opt \n437 9 18 6 9 0 destroy 1240 12 14 11 2 0 destroy-opt 552 14 18 4 13 0 Table 1: Statistics of each of \nthe benchmark programs Full Info &#38;main Program Plain Packing Plain Previous Packing PP typereg 45.5 \n14.3 35.0 28.2 12.3 10.6 typereg-opt 51.4 17.2 41.6 35.5 16.0 14.0 FieldList 30.3 11.1 16.4 14.8 6.1 \n5.6 FieldLkt-opt 64,7 22.9 53.0 47.6 20.8 18.7 takl 51.6 17.9 41.1 34.1 16.0 14.2 takl-opt 55.8 19.7 \n43.9 37.5 17.6 15.6 destroy 17.1 5.9 17.1 15.2 6.6 6.1 deStrOV-ODt 46.4 17.4 42.8 38.4 18.1 16.5 Table \n2: Table sizes as a percentage of code size replaces a randomly chosen subtree of the same height with \nthe new subtree. We ran destroy in our Smalltalk system, which uses the accurate scavenging scheme [15] \nwe plan to install in the Modula-3 run-time. We found that collections averaged 280 ms of elapsed time. \nWe coded the benchmark in Modula-3 as similarly as possible, and caused collec\u00adtions at approximately \nthe same points, To determine stack tracing costs, we ran two versions of the Modula-3 program, one with \ncollection being a stack trace, the other with col\u00adlection being a null call, and calculated stack tracing \nto take 470 ps per collection, However, the difference between the runs was small, and the variance significant \neven with many repetitions in a system running in single-user mode, so the 90% confidence limit is that \nstack tracing takes less than 1710 ps per collection for this program. The corresponding num\u00adbers per \nstack frame traced are 27 KSand 98 #s, respectively. We ran these tests on a VAXStation 3500, which is \ngenerally rated at 3 to 5 VAX MIPS, suggesting that our current code executes on the order of 100 to \n400 VAX instructions per frame traced. We believe we can tighten this up measurably. Whether one uses \nthe 470 ps per collection figure or the 1710 IM one, there are two additional factors to take into account \nin comparing stack tracing overhead with overall gc time. First, the destroy benchmark is unusually gc \nintensive. Programs that create a lot of objects, but where most do not survive to the next collection, \nexhibit something like five times lower gc cost. Also. a Modula-3 collector may be faster than a Smalltalk \ncollector since for Modula-3 we can generate type-specific routines for tracing heap objects, and avoid \nSmalltalk s object and pointer decoding overhead. We will be generous and atlow a factor of two speed \nup for Modula-3, though we doubt the advantage is really that great. Thus, in less gc-intensive Modula-3 \nprograms, we estimate the ratio of stack tracing time to total gc time to be less than 1710/28000 = 6% \n(470/28000= 1.7%). We conclude that stack tracing overhead is only a small part of gc time, even in a \nhigh performance scavenging collector. 7 Related Work Algol-68 implementations were the first to produce \ncompiler generated routines to assist in garbage collection. In the Branquart and Lewi scheme [16], tables \nare produced that map stack locations to the appropriate garbage collection routine. Unlike our scheme, \nthese tables have to be updated every time a reference to the heap is created on the stack. Goldberg \ns compiler [17] produces stack tracing routines. The return address in a call is used to locate a routine \nthat knows how to trace the frame of the caller. His work is not done in the context of an optimizing \ncompiler and thus he does not address many of the issues we handle. Boehm [13, 18] is currently incorporating \ngarbage collec\u00adtion support in a C compiler. He is using an ambiguous roots collector and his main concern \nis ensuring that atl live ob\u00adjects have at le%t one pointer to their headers (i.e., there are no live \nobjects that are reachable only from derived values). This problem is similar to our dead base pointer \nand indirect references scenarios described in Section 4. Since he never moves objects he does not need \nto deal with the issues in updating derived vatues. Exception handling implementations in CLU, Trellis, \nand Modula-3 atso use compiler generated tables. In our Modula\u00ad3 implementation [19] tables are generated \nfor each point where an exception may be raised. The tables contain the addresses of handlers for the \nexceptions that can be raised at that point. Zurawski and Johnson [20] emit compile-time tables to allow \nthem to construct the unoptimized state of the program from the optimized state. Like us, they have to \ncleat with the effects of pointer arithmetic introduced by the optimizer. Their focus, however, is on \ndebugging; some optimization are disallowed to make debugging possible. There is a gen\u00aderal similarity \nbetween the simpler kinds of information we need for garbage collection and what is needed for symbolic \ndebugging in the presence of optimization. Debuggers do not need to update values or handle the derived \nvatue cases that we do, however. 8 Conclusions We have described and evaluated compiler techniques for \nsupporting fully compacting garbage collection in a statically typed language. We started with the following \nrequirements: the ability to move any object, portability, and low run-time overhead. We met these requirements \nby mtilng extensive use of the information available to the compiler, While we are not the first to recognize \nthe availability of the compile\u00adtime information, we believe that we are the first to exploit it so thoroughly \nin a highly optimizing compiler, 9 Acknowledgements Tony Hoskkg provided us with gaxbage collection measure\u00adments \nfrom the UMass SmaJltalk system. We would also like to thank Chuck Lins for his extensive comments on \na draft of the paper. References [1] M. Atkinson, K. Chisolm, and P. Cockshott, PS-Algol: an Algol with \na persistent heap: ACM SIGPLANNot., VOi. 17, pp. 24 31, July 1982. [2] G. NeIson, cd., Systems Programming \nin ModuIa-3. New Jersey: Prentice Hatl, 1991. [3] J. E. B. Moss, Implementing persistence for an object \noriented language< COINST&#38;hnicat Report 87-69, University of Massachusetts, Amherst, MA 01003, Sept. \n1987. [4] A. L. Hosking, Main memory management for persistencefl Get. 1991, Position paper for 00PSLA \n91 Workshop on Garbage Collection. [5] J. F. Bartlett, Compacting garbage collection with ambiguous roots: \nResearch Report 88/2, Western Research Laboratory, Digitat Equipment Corporation, Feb. 1988. [6] J. F. \nBartlett, Mostly-copying garbage collection picks up generations and C++: Technical Note TN-12, Western \nResearch Laboratory, Digitat Equipment Corporation, Pato Alto, CA 94301, Oct. 1989. [7] R. M. Statlman, \nGCC. Free Software Foundation, Cambridge, MA. [8] H.-J. Boehm and M. Weiser, Garbage collection in an \nuncooperative environment, Sofrware: Practice and Experience, vol. 18, pp. 807-820, Sept. 1988. [9] C. \nChambers and D. Ungar, Maldng pure object oriented languages practical in Proceedings of the Conference \non Object-Oriented Programming Systems, Languages, and Applications, (Phoenix, Arizona, Ott. 1991), pp. \n1-15, ACM SIGPLAN Not. 26, 11 (NOV.1991). [10] S. Harbison. Personal Communication, 1992. [11] R. P. \nGabriel, Performance and Evaluation of Lisp Systems. Cambridge, MA: MIT Press, 1985. [12] A. L. Hosking, \nJ. E. B. Moss, and D. Stefanovid, A comparative performance evaluation of write barrier implementations, \nSubmitted for publication, Feb. 1992. [13-JH.-J. Boehm, A proposal for GC-safe C compilation Ott. 1991. \nPosition paper for 00PSLA 91 Workshop on Garbage Collection. [14] D. Ungar, Generation scavenging: A \nnon-disruptive high performance storage reclamation algorithm; in Proceedings of the ACM SIGSOFTISIGPLAN \nSoftware Engineering Symposium on Practical Software Development Environments, (Pittsburgh, Pennsylvania \nApr. 1984), pp. 157-167, ACM SIGPLAN Not. 19,5 (May 1984). [15] R. L. Hudson, J. E. B. Moss, A. Diwan, \nand C. F. Weight, A language-independent garbage collector toolkit: COINS Technical Report 91-47, University \nof Massachusetts, Amherst, MA 01003, Sept. 1991. Submitted for publication. [16] P. Branquart and J. \nLewi, A scheme for storage allocation and garbage collection in Algol-68; in Algol 68 Implementation \n(J. E. L. Peck, cd.), North-Holland Publishing Company, 1971. [17] B. Goldberg, Tag-free garbage collection \nin strongly typed programming languages: in Proceedings ofrhe ACM SIGPLAN 91 Conference on Programming \nLanguage Design and Implementation, (Toronto, Ontario, Canada, June 1991), pp. 165-176, ACM SIGPLANNot. \n26,6 (June 1991). [18] H.-J. Boehm, Personal communication July 1991. [19] A. Diwan, Exception handling \nin Modula-3. Internal 00S Document, 1990. [20] L. W. Zurawski and R. E. Johnson, Debugging optimized \ncode with expected behavior; ACM Trans. Programming Languages and Systems, To appear.  \n\t\t\t", "proc_id": "143095", "abstract": "<p>We consider the problem of supporting compacting garbage collection in the presence of modern compiler optimizations. Since our collector may move any heap object, it must accurately locate, follow, and update all pointers and values derived from pointers. To assist the collector, we extend the compiler to emit tables describing live pointers, and values derived from pointers, at each program location where collection may occur. Significant results include identification of a number of problems posed by optimizations, solutions to those problems, a working compiler, and experimental data concerning table sizes, table compression, and time overhead of decoding tables during collection. While gc support can affect the code produced, our sample programs show no significant changes, the table sizes are a modest fraction of the size of the optimized code, and stack tracing is a small fraction of total gc time. Since the compiler enhancements are also modest, we conclude that the approach is practical.</p>", "authors": [{"name": "Amer Diwan", "author_profile_id": "81100202872", "affiliation": "", "person_id": "PP15025608", "email_address": "", "orcid_id": ""}, {"name": "Eliot Moss", "author_profile_id": "81406593781", "affiliation": "", "person_id": "PP31087662", "email_address": "", "orcid_id": ""}, {"name": "Richard Hudson", "author_profile_id": "81100566849", "affiliation": "", "person_id": "P242190", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143095.143140", "year": "1992", "article_id": "143140", "conference": "PLDI", "title": "Compiler support for garbage collection in a statically typed language", "url": "http://dl.acm.org/citation.cfm?id=143140"}