{"article_publication_date": "07-01-1992", "fulltext": "\n Alphonse: Incremental Computation as a Programming Abstraction Roger Hoover* The more things change, \nthe more they remain the same. Alphonse Karr [Kar49] Abstract Alphonse is a program transformation system \nthat uses dy\u00adnamic dependency analysis and incremental computation techniques to automatically generate \nefficient dynamic im\u00adplementations from simple exhaustive imperative program specifications. Overview \n In most computer applications there are numerous proper\u00adties that the underlying algorithms maintain \nas the program data changes. Consider, for example, an application that utilizes a search tree. After \nadditions or deletions to this tree s data, an efficient search algorithm may require the property that \nthe tree be balanced. The Alphonse system described in this paper automates the maintenance of such properties \nusing procedurally coded specifications. These computational properties typically can be estab\u00adlished \nby a straightforward eduaustive algorithm that exami\u00adnes and adjusts all of the relevant data. For example, \na bi\u00adnary tree can be balanced with a simple recursive pass over the tree. We could execute the exhaustive \nalgorithm after each change to the data, but this would be unnecessarily in\u00adefficient. In a dynamic or \ninteractive setting where the prop\u00aderty must be maint ained after each of many small data mod\u00adifications, \na complex algorithm is typically used to avoid the redundant computation inherent to many repeated invoca\u00adtions \nof this exhaustive algorithm. The Alphonse program transformation system generates efficient dynamic \nimple\u00admentations from simple exhaustive program specifications. It transforms these programs to use dynamic \ndependency analysis and incremental evaluation techniques in order to automatically maintain the Alphonse \nproperties. Alphonse can be used with programs written in a con\u00adventional imperative language. The Alphonse \nproperties *IBM T.J. Watson, P.O. Box 704, Yorktown Heights, NY 10598, rhoover@watson.ibm.com Permission \nto copy without fee all or part of this material is granted provided that the copies are not made or \ndistributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand ita date appear, and notice is given that copying is by permission of the Association for Computing \nMachinery. To copy otherwise, or to republish, requires a fea and/or specific permission. ACM SIGPLAN \n92 PLD1-6/92/CA @ 1992 ACM O-8979~-476.7/92/0006/026J ...$1.50 are also written in this language, with \nprocedures and data associated in an object oriented style. Pragmas are used to indicate the procedures \nthat comprise the Alphonse prop\u00aderties. While these program specifications would produce the correct \nresult if compiled by a traditional compiler, they would be inefficient due to the repeated evaluations \ninduced by running the exhaustive algorithm at every step. The Alphonse system translates these inefficient \nprograms into efficient ones that dynamically analyze the dependencies be\u00adtween the operations of the \nexhaustive algorithm and iracre\u00adnaeratallyexecute the portions of the computation that are different \nhorn those executed before recent data modificm tions. The advantage of this approach is that program \nspeci\u00adfications are substantially simpler, making them easier to program, debug, prove correct, understand, \nmtint sin, and modify. In large interactive applications, where program\u00admers have difficulty reasoning \nabout the complex dependen\u00adcies that arise from the interaction of several algorithms over a set of changing \ndata, Alphonse takes on this re\u00ad sponsibility, allowing the construction of more sophisticated software \nsystems. In addition, the dependency informa\u00adtion maintained by Alphonse programs enables a host of other \nbenefits including eager evaluation, sophisticated de\u00adbugging, and parallel execution. This paper is \norganized as follows: Section 2 de\u00adscribes how incremental computation techniques are used in Alphonse. \nSection 3 discusses the language used for Alphonse and gives an example. Our dynamic analysis technique \nis covered in Section 4 and Section 5 gives the program transformations that adapt Alphonse programs \nto perform this dynamic analysis. A number of optimization are given in Section 6. Section 7 gives three \nexamples. Our implement ation effort is described in Section 8, Section 9 analyzes time and space requirements. \nFinally, Section 10 compares Alphonse with similar systems.  2 Incremental Computation The model of \nincremental computation is as follows: First, a computation is performed to establish some property. \nThen, a small change is introduced to the program or data, requiring a slightly different computation. \nThe previous computation needs subsequent alterations in order to re\u00adflect the result dictated by this \nchange. Incremental computation is used in Alphonse between two parts of the program: The mutator M a \nnormal im\u00adperative program that performs arbitrary imperative oper\u00adations. The Maintained portion is \nan imperative exhaustive program that establishes a property P on the program data. The interface between \nthese two parts consists of a set of Alphonse procedures called by the mutator, along with a collection \nof storage locations that are referenced by both portions. The mutator performs modifications to the \nstate of these storage locations, and the Maintained portion re\u00ad acts to these changes to re-est ablish \nproperty P. The mu\u00ad tator accesses the results of the Alphonse computation by performing calls to the \nAlphonse procedures. While the Maintained portion specifies a property that must hold when a given Alphonse \nprocedure returns, this property is not necessarily established upon the call to the Alphonse procedure. \nIfthestate change introduced by the mutator does not affect the property specified by the given Alphonse \nprocedure, no computation is required. Other\u00adwise, the programmer specified evaluation tnethodis used. \nWith eager evakmtion,thecornputation maybe performed at any time after the state change. Even when using \nde\u00adman.devaluation, which lazily updates the procedures, some or even all of the computation may have \nbeen performed earlier in time in order to maintain some other Alphonse property. Well established increment \nal computation techniques are used to maint sin Alphonse properties. We use a combina\u00adtion of two such \ntechniques, quiescence propagation and function caching2 [Pug88, PT89]. Quiescence propagation is an \nincremental update tech\u00adnique that allows the reuse of large networks of interrelated computations that \nare expressed as directed graphs. Each node of the graph represents an intermediate step of the en\u00adtire \ncomputation and directed edges connect two interme\u00addiate computation nodes u and v if v uses data computed \nby u. After a change to the computation graph, interme\u00addiate computation steps are performed beginning \nat the change points and continuing toward dependent computa\u00adtions. Propagation becomes quiescent when \nthe new result of intermediate computations matches the old value cached from before the computation \ngraph change. The amount of computation is minimized when done in a topological order with respect to \nthe graph, and much research has been di\u00adrected at algorithms to compute this order in the presence of \ngraph changes. Function caching is a technique that captures the compu\u00adtation of individual function \ncalls for later reuse. A table is kept for each function with an entry for each different func\u00adtion call, \nindexed by the argument values. Subsequent calls with identical arguments are not re-computed a cached \nre\u00adturn value is used instead. The technique requires that the functions be deterministic as well as \nbe combinators (that is, depend only upon their argument s). In Alphonse, we make two contributions to \nincremental computation research: First, we give program transforma\u00adtions that adapt an imperative program \nto automatically maintain the graph structure necessary for quiescence prop\u00adagation. Second, we combine \nfunction caching with quies\u00adcence propagation to allow functions that are not combina tors (i.e., functions \nthat examine global state). We compare Alphonse with other incremental systems in Section 10. Specification \nLanguage Alphonse programs are written in an imperative language L that has been extended with pragmas \nto form A/phonse\u00adJ3.While we make a few reasonable assumptions about this 1Referred to as change propagation \nin [Rep84]. 2Also known as memoizing. base language L in Section 3.1, all L programs are valid Aiphonse-L \nprograms. Alphonse properties are also written in L, but are denoted by pragmas. 3.1 Base Language Alphonse \ncan be used in conjunction with any imperative programming language with the following properties: o \nRecord ty es (we will refer to instances of record types .? as objects ), with: Data fields,  Pointer \nfields (we assume that pointers are well behaved), and  Procedure valued fields (which we apply to the \ncent aining objects and refer to as methods);  o Dynamic Allocation (for object creation); and . Pragmas \n(which are used to indicate which procedures and methods comprise Alphonse properties). By well behaved, \nwe mean that we can create, derefer\u00adence, and assign pointers. We do not allow pointer con\u00adstants and \npointer arithmetic such as in C as they signif\u00adicantly complicate the automatic detection of change re\u00adquired \nto maintain Alphonse properties. (It is possible that static analysis techniques for pointers, or a safe \nsubset of C, could reduce the need to track changes at potentially every memory location and allow its \nuse with Alphonse. ) We refer to functions and variables accessible to the outer language scope as top-level. \nWhile we assume dynamic allo\u00adcation, one can perform maintained property comput ations in this system \nwithout the ability to dynamically create objects. This limit ation, however, severely reduces express\u00adibility. \nOne would want to provide a standard facility to dynamically allocate objects out of a fixed array or \nheap. 3.2 Language I Notat ion We will use the following notation in our examples.4 . Object types are \ndeclared as follows. TYPE SubType = SuperType OBJECT Fieldl : FTypel; ... rmrmror)s Methodl (arg, . ..) \n: MTypel := MProcl; ... OVEFLRmES Overridel := OProcl; ... END This notation declares an object type \n(called Sub Type here), that inherits both fields and methods from SuperType and contains Fieldl, . . \n. as new fields. In addition, methods Methodl, . . . are added to the type with implementations provided \nby procedures MProcl, . . .. Overrides replace the implementations of inherited methods. 9Although we \nuse the terminology of object oriented pro\u00adgramming, we are assuming nothing more than what is explicitly \nstated here. 4This is Modula-3 [Ne191]. . Objects of type T are dynamically allocated through TYPE Tree \n= OBJECTleft, right: Tree; the use of the NEW statement: METHODS(*MAINTAINED*)height := Height; NEW(T) \n . Pragmas are denoted: (*PRAGNfA~Am3 AND ARGuMBNT5*) 3.3 Alphonse Notation Alphonse properties are \nspecified as procedures (including functions) in the base imperative language L. There are two pragmas \nthat are used to distinguish Alphonse procedures from the remainder of the program. 1. Inserting the \n(*MAINTAINED*)pragma before method or override declarations indicates that these proce\u00addures are not \nto be executed if they produce results identical to their previous executions. 2. The (*CACHED*) pragma \nis placed before a procedure decla~ation to denote-a procedure whose return value is to be remembered \nand returned for future calls to the procedure with identical arguments. Note that if the procedure has \naccessed nonlocal storage, muta\u00adtions of this storage may require updating the cache (see Section 4.2). \nAdditional pragma arguments allow the specification of the caching technique, cache size, and the replacement \nalgorithm. An optional argument to the maintained and cached pragmas allows the programmer to specify \nthe evaluation strategy. With DEMANDevaluation, the value of a proce\u00addure is updated lazily upon calls \nto that procedure. EAGER evaluation updates values before subsequent procedure call requests, and is \nuseful in applications with computation cy\u00adcles available due to input/output, etc. Let p be a procedure \ncall proc(ao,.. ., ak), where proc is a cached procedure, or proc implements a maintained method call \nao.m(al, . . . . a~). We call p an incremental procedure instance and define R(p), the set of referenced \narguments of p, to be the set of all values external to proc that are accessed (both read and write) \nby the call. This set includes any incremental procedure instances or top-level variables that are transitively \nreferenced through nonincremental procedure calls. Procedure parameters ai are not included in R(p) if \npassed by value, but storage pointed to by VARand pointer parameters must be included in R(p) if it is \ndereferenced.c  3.4 Example As an example of how Alphonse is used, consider Algo\u00adrithm 1. We use the \nobject type Tree and the maint sined method height to maintain the property that the height in the tree \nis computed for each node of a binary tree. A single object of type TreeNil is pointed to by tree nodes \nwith less than two children. Implemented by the procedure Height, the height method computes the height \nin the tree from the bottom up. Begin\u00adning with a height of O for the TreeNil object at the leaves, the \nheight at each node is computed as the maximum child height plus one. 6We discuss methods for limiting \nthe set of referenced argu\u00adments in Section 6.4. END; TYPE TreeNil = Tree OBJECT OVERRJDES(*MAINTAINED*)height \n:= HeightNil; END; PROCEDUREHeight(t : Tree) : INTEGER= BEGIN RETURNw@t.left .heighto, tright .heighto)+l \nENDHeight; PROGEDUREHeightNil(t : Tree) : mTEGER= BEGINRETURNO END HeightNil; Algorithm 1: Maintained \nHeight Tree Let subtree(t) be the subtree rooted at vertex t. As the procedure that implements the height \nmethod calls itself re\u00adcursively to perform its computation, non-incremental ex\u00adecution of t height requires \n0( Isubtree(t)l ) time. When the method is maintained, 0( 1.w&#38;tree(t)I) time is used for the first \ncall. Subsequent height calls on t or any of its de\u00adscendants, however, will require O(1) time, since \nthe result values are cached. Changes to a child field pointing to node z in the tree will require O(height \n) time (plus the bookkeep\u00ading cost of the quiescence propagation algorithm) to update all of the cached \nvalues on the new and former paths from z to the tree root. Changes to many pointers in the tree, how\u00adever, \nare batched by the evaluation algorithm and result in O(IAFFECTEDI) (plus quiescence propagation bookkeep\u00ading) \ncomputations, where AFFECTED is the set of height values that are different. Examples of the notation \nin the previous subsection: The dynamic allocation of an object t of type Tree will result in the creation \nof an incremental procedure instance, t.heighto. The referenced argument set R(t.heighto) in\u00adcludes t.lefi \nt.left.heighto, t.righ~ and t.right.heigh{). R(n.heighto) = 0 where n is the TreeNil object. 3.5 Restrictions \nWe place the following restrictions on each Alphonse pro\u00adcedure p. DET p must implement a deterministic \nfunction. That is, when called with the same formal and referenced ar\u00adguments, it must have the same \nbehavior and return the same value. This restriction is necessary to insure that p s result will be identical \nif executed under iden\u00adtical conditions, the essential property that allows us to avoid subsequent executions \nof p until predicated by change. DET precludes Alphonse procedures from true non-deterministic behavior \nor the use of internal static state to simulate it (as in pseudorandom number generators). TOP p must \nbe a top-level procedure and may access only top-level or local data. TOP insures that p is always available \nfor execution by the evaluator and that the data accessed by p changes only by assignment and not through \nthe pushing and popping of automatic stack variables. We can relax this restriction if the compiler generates \nthe code necessary to perform cache invali\u00addation at the end of a variable s lifetime. OBS If p has an \neager evaluation strategy in program P, p may not produce side effects such that spurious execu\u00adtions \nof p (at procedure call boundaries) can affect the result of P s computation. OBSlimits the side effects \nproduced by an eager procedure p so that the eager evaluation of p is not observed in the program out\u00adput, \nor through program anomalies that would abort or infinitely delay the execution of P. The above restrictions \nare not automatically enforced by the Alphonse compiler. Instead, we require the program\u00admer to prove \nthat the Alphonse procedures are compliant (A proof example is given in Section 7.3). While it is pos\u00adsible \nto insure that these restrictions are not violated by imposing simple conservative assumptions (e.g. \n(no eager side affects )+ OBS), it is not decidable in general whether or not a given program P obeys \nthese restrictions. Traditional input (output ) is modeled as the removal from (concatenation to) a top-level \nstream variable contain\u00ading the input (output) string, and obviously violates the OBS restriction if \nincluded in eager procedures. We model other 1/0, such as pointer device input and bit mapped display, \nas reads from (or writes to) special top-level variables and these actions can often be incorporated \nin eagerly evaluated procedures. 3.6 Expressibility While the Alphonse L language retains the exact \nseman\u00adtics oft he imperative language L, the efficiency provided by increment al evaluation gives rise \nto enhanced ezpressibilitg despite the restrictions of the previous section. Because the programmer is \nfree from reasoning about the explicit order\u00ading of computation steps, he or she can specify the computa\u00adtion \nmore clearly and succinctly. While these programs can be executed by L without Alphonse, the difference \nin exe\u00adcution speed can be large enough that these algorithms are not practical wit bout increment al \nevaluation. Thus, incre\u00admental computation has effectively extended the language to allow a declarative \nstyle of programming that specifies what to compute without giving the precise execution order.  4 Dynamic \nAnalysis In order to maintain Alphonse properties with quiescence propagation, it is important that we \nknow about change and dependence as it relates to the Maintained portion. Change becomes relevant when \nmodifications are made to variables examined by all Alphonse procedures. These changes must be made known \nto the computation in or\u00adder to update Alphonse procedures (transitively) dependent upon the change. \nDependence between Alphonse proce\u00addures and the program state must therefore also be known. In this Section, \nwe give our dynamic dependence analysis technique. Section 5 details the program transformations that \nare used insert this algorithm into the Alphonse pro\u00adgram. It is important to note why dynamic analysis \nis nec\u00adessary in Alphonse, given that other incremental systems [Yeh83, RT88, Hud86, HK89] utilize static \ndependency analysis. These systems are based on grammars and have the property that for any given intermediate \ncomputation, only a small fixed set oft he program state can be examined. Alphonse procedures, on the \nother hand, are not limited to a local set of references. Instead, these procedures may tra\u00adverse data \nstructures, examine global data, and call other functions. A static determination of the exact set of \nref\u00aderenced arguments is, in general, undecidable. Thus, we are limited to two choices: a conservative \napproximation to this set, or an exact, dynamically maintained, set. With the inclusion of pointer types \nin the imperative language, conservative approximations become unacceptly imprecise using existing static \nanalysis techniques [CWZ90, Hen90]. We use dynamic analysis with static optimization when appropriate \n(see Section 6). 4.1 Klepenclence Dependence information in Alphonse is stored in a depen\u00addency graph.. \nNodes of this graph are created to represent each incremental procedure instance, as well as each global \nvariable location accessed by these procedure inst antes. Edges of this graph connect nodes w to v if \nthe procedure in\u00adstance represented by v depends on the procedure instance or variable represented by \nu. Thus, SZJCC(U),the successor set of u, would cent ain v. We also maintain the reverse edges, with \nu ~ pred(v). The cached variable or proce\u00addure return value is stored in value(u). The boolean field \nconsistent(u) stores the cache status. 4.2 Caching with Propagation We integrate quiescence propagation \nand function caching through the use of dependency graph nodes to represent both maintained methods and \ncached procedures. In the following, let p be an incremental procedure instance (that is, a maintained \nmethod call o.m(al, . . . . ak) or a cached procedure cdl f(al, . . . . ak)), represented by dependency \ngraph node u. Edges to u in th~ dependency graph come from the nodes representing elements of l?(p). \nSince R(p) does not cent ain al, .... Uk, the dependence of p upon any given a; is not represented by \ndependency graph edges. Instead, calls to the given method or procedure ( o.m or f) are stored in a table \nknown as the argument table. This table contains all nodes that represent calls to p, one for each distinct \nargument vector (al, ... ,ak), and is indexed by this vector. (For efficiency, the argument table can \nbe eliminated if k = O. While cached procedures of zero arguments are rare, methods with zero arguments \nare quite common). Changes in an element of R(p) result in the propagation of change to p for both cached \nprocedures as well as main\u00adtained methods. Changes of argument value (say u: instead of ai ) between \nsuccessive executions of a given call, on the other hand, result in the remapping of edges from (u + \nn) to (u -+ n), where u represents the incremental procedure instance with arguments (al, . . . a~-1, \na;, a;+l, ak). The advantage of this organization is that it eliminates the combinator restriction of \ntraditional function caching (Section 2). As all of the state accessed by a cached pro\u00adcedure is encoded \nin R(p) and (al, , , ., ak), a change to r, r c R(p), can be effectively translated into an update of \nthe cached return value. 4.3 Recording Dependence In order to record the dependence between Alphonse \nproce\u00addures and the storage that they access, we need to be able to represent the correspondence between \nthese runtime ob\u00adjects and their dependency graph nodes. We do this by allocating pointer fields that \nrelate storage and procedures with their dependency graph nodes (and vice versa) as fol\u00adlows: Wereferto \neach typed storage location allocated for the executing program as an abstract location. We provide a \ndependency graph pointer field for each top-level abstract location l,theaddress ofwhich isobtained bynodeptr(l). \nThis address is ndifl does not represent top-level storage. Procedures aremapped into dependency graph \nnodes with pointer field, the address of which is returned by tablet, where p is an Alphonse procedure. \ntablept~p) evaluates to nil if the procedure is not cached or maintained. The ex\u00adpression re~n) gives \na pointer back to the corresponding abstract location or procedure represented by dependency graph node \nn. Dependencies are dynamically recorded as follows. A stack, CaWhc~ stores the graph nodes of currently \nex\u00adecuting Alphonse procedures. top( CallStack) is the graph node representing the most recently called \nincremental pro\u00adcedure inst ante, and is nil at other times when no such procedures are executing. Upon \na call to an incremental procedure instance p, p s dependency graph node is pushed on CalL$tac~ and is \nremoved upon the completion of p. At the point of call to an Alphonse procedure p or a refer\u00adence to \nnonlocal storage s, a check is made to top( CallStack) to see if an Alphonse procedure is currently executing. \nIf the stack is not ndit will contain a graph node v represent\u00ading this procedure. Let u be the graph \nnode that represents the accessed storage s orcrdled procedure (wecreateuif it does not exist). An edge \nis then added fromu tov. Note that p is dependent upon storage s that is wrztterzas well as read should \ns be rewritten in the future, a subsequent execution ofp must have the effect of setting it back. Ifphas \nbeen executed previously, it has a set ofdepen\u00addent edges from Alphonse procedures and storage locations \nthat were accessed during the previous execution. These edges (contained in the pred(v) set) are removed \nbefore sub\u00adsequent executions. Thus, the dependency graph contains a snapshot of all dependencies that \ninfluenced the result of the most recent computation of the Maintained portion of the program. 4.4 Change \nChange in the Alphonse computation must be accurately tracked, since quiescence propagation assumes that \nprevi\u00adous results of procedures are still valid if their input did not change. The set of storage changes \nthat could po\u00adtentially affect the computation are those that have been accessed (directly or transitively) \nby Alphonse procedures. Bythedependency graph construction above, each of these variables will have an \nassociated dependency graph node. We therefore check nodept~v)t upone veryoperation that writes a variable \nv that is potentially accessible to Alphonse procedures. If nodept~v)f= nd(ornode(v) =ndifv hap\u00adpens \nnot to be top-level), program execution proceeds in the conventional manner. Otherwise, if node(v) 1= \nu, the procedures represented by succ(u) could perform operations that are different from their previous \nexecutions. Ifthe new value of v is different from the previously cached value in value(w), u is placed \ninto a global inconsistent set. 4.5 Evaluation Upon subsequent calls to Alphonse procedures, a check \nis made for dependency graph nodes in the inconsistent set. If this set is not empty, program execution \nis preempted by the evaluation routine. Inconsistent nodes are removed and processed until the inconsistent \nset is empty. An element u is processed as follows: . If u represents a storage location, all elements \nof SUCC(U)are added to the inconsistent set. . If u represents a demand incremental procedure in\u00adstance, \nif corzsistem(u) is true, then we set it to false and add all elements of succ(u) to the inconsistent \nset. . If u represents an eager incremental procedure instance p,pis re-executed. IftheresuIt value \nis different from value(u), all elements of SUCC(U)are added to the in\u00adconsistent set.  The selection \nof u from the set is done usirur an abrorithm such as [Hud86, Ho086, Ho087, AHR+90]. -Note t-hat the \nevaluation routine should be called whenever cycles are available (input/output, etc) and can be preempted \nwhen necessary.  5 Transformations We capture the relevant activities of imperative languages with the \nfollowing operations: access(v), where v is an expression that can be resolved to a variable location, \nreturns the value of that variable. rnocli~l, v), where 1 is an expression that can be resolved to a \nvariable location and v is some value, updates 1 to contain value v. call(p, al, . . . . a~), where p \nis a procedure or method valued expression with k arguments, returns the result of the procedure. Program \ntransformations are used to insert these opera\u00adtions into the base language program as follows: . Each \nread access to storage 1 is replaced by acces<v), if i is top-level (or cannot be statically determined \nto not be top-level). Pointer dereferencing (including the dereferencing of VAR parameters) counts as \na read ac\u00adcess to the pointer storage. . Each assignment to storage 1 of value v is replaced by rnodifg(l, \nv), if 1 is top-level (or cannot be statically determined not to be top-level). . Each non-method procedure \ncall p(al, . . . . ak) is re\u00adplaced with call(p, al, . . . . ak ), if p is top-level (or can\u00adnot be statically \ndetermined not to be top-level). . Each method call o.rrz(al,..., a/e) is replaced with call(o.m, al, \n. . . . ah).  We illustrate this translation here with an example (Algo\u00adrithm 2). Note that pointers \nmust be accessed twice, once for the pointer once for the location it points to. In addi\u00adtion, observe \nthe difference in treatment in the call to p2 for a (local), b (top-level), and c (formal parameter). \nWe transform the program further by replacing each access, modify, and call operation by the code template \nshown in Algorithms 3, 4, and 5 respectively. The transfor\u00admation can be done either at the compiler \nlevel, or by using a source to source translation. The nodeptr and tableptr fields can either be generated \nby a modified compiler, or alternatively at the expense of a level of indirection, addi\u00adtional transformations \ncan be used to change each variable type into a record structure with two fields, one for the real storage \nlocation, the other for the dependency graph node PROCEDUREPI(c: INTEGER): INTEGER= BEGIN FOR a:=l TO \n10 DO ~~t := p2(a+b+c, Y~) RET&#38;RNpt END becomes: PROCEDUREpl(c: INTEGER): INTEGER= BEGIN FOR IK=l \nTO 1L3DO modify (access(p), call(p2, a+access(b)+c, access(access(y )))) END; RETURNaccess(access(p)) \nEND Algorithm 2: Transformed Program access(v) -+ IF nodeptr(v) # NIL THEN IF top(CallStack) # NIL THEN \n m nodeptr(v)~ = NIL THEN node~tr~v) t := NEW(DepGraph); ref(nodeptr(v)t) := v END; CreateEdge(top( CallStack), \nnodeptr(v)t) END END; RETURNV Algorithm 3: Access Transformation access pointer. Likewise, the code \nfor access, rnodifi, and call can be emitted directly by the code generator, or they can encoded as procedures, \ncustomized for each variable type and procedure signature. The result of this algorithm is the dynamic \nconstruction and maintenance of a dependency graph for program P. Theorem 5.1 Given an Alphonse program \nP, Alphonse execution of P will produce the same output as a conven\u00adtional execution of P. Proof: If \nthe Alphonse execution of P produces different output from a conventional execution of P, theneither: \n1, At some point in the Alphonse execution there exists a first expression e = z whose value is different \nthan the expression s , * # z computed in the conventional execution, or modify (l, v) A access(l); 1 \n:= v; IF nodeptr(l) # NIL THEN m nodeptr(l)~ # NIL THEN m value(nodeptr(l)t) # v THEN SetAdd(Inconsistent, \nnodeptr(l)t) END END END; Algorithm 4: Modify Transformation 266 call(p, al, . . ..a~+-+ m tableptr \np = NIL THENRETURNp(al, . . . a~) END; [1 IF tableptr p ~ = NIL THEN tableptr(p)t := ~w(ArgTable) END; \nn := TableFind(tableptr( p)T, (al, . . . . u~)); IFn. NIL THEN n := TableAdd(tableptr p)t, (al, . . . \n. ak)); \\ref(n) := p; consistent(n := FALSE ELSE m SetSize(Inconsistent) >0 T~N Evaluate(Inconsistent) \nEND END; IF top(CallStack) # NIL THEN CreateEdge(top( CallStack), n) END; IF consistent(n) THENRETURNvalue(n) \n.. ELSE RemovePredEdges(n); StackPush(CallStack, n); COIISiStC!nt(II) := TRm ; rdvd := P(UI, . . . Uk); \nvalue(n) := re-tval; StackPop(CallStack); RETUiii retv?d END; Algorithm 5: Call Transformation 2. The \nAlphonse execution produced a program anomaly (e.g. infinite, loop, run time exception, etc.) that the \nconventional execution did not (or vice versa). Case 1: Expression e must be the result of a procedure \ncall or a memory read, since Alphonse affects only proce\u00addure calls, memory reads, and memory writes, \nSay e is a procedure call p. If p was executed upon the evaluation of e and returned a value x, than \neither restriction DET has been violated, or there was a prior expression that evalu\u00adated differently \nprior to e. If, instead, z was the cached value for p, restriction TOP and the inconsistent marking of \nthe Alphonse algorithm insure that all subexpressions computed by p were consistent and the above holds \nas well. Assume e is a r.qadof abstract memory location 1contain\u00ading the value z. The Alphonse execution \nmust have either (a) failed to write z to 1, or (b) caused some spurious write to set 1to be z. Case \nla: Since the only stat ements that Alphonse avoids are incremental procedure executions whose referenced \nar\u00adguments are consistent, the write to 1 must be in an Alphonse procedure call p that had been executed \nprevi\u00adously. DET requires p to have written i in the prior execu\u00adtion if a second execution of p would \nwrite ?. Thus, 1 must have been overwritten by some other assignment. However, 1 is in R(p), 1 would \nbe marked inconsistent, and p would have been re-executed. Case lb: The write to 1 must have been caused \nby the execution of an incremental procedure p. Demand proce\u00addures are only executed when called (thus \nthe conventional execution would also write 1), and the writing of 1 by an eager procedure violates OBS. \nCase 2: Either the (missing) program anomaly must be in an avoided Alphonse procedure (like case la), \nor the (extra) program anomaly was introduced by an Alphonse procedure (like case lb). E 6 Optimizations \nThere are a number of optimizations that are necessary to facilitate the efficient application of dynamic \ndependence analysis in conjunction with imperative programs. We dis\u00adcuss these techniques in this section. \n6.1 Limiting Runtime Checks Each access, modify, and call operation, as expanded in Sec\u00adtion 5, performs \nseveral checks to determine whether or not a variable or procedure is involved in an Alphonse computa\u00adtion. \nThe uniform application of these tests would result in a substantial performance decrease. We use dat \naflow analy\u00adsis to identify the many variables and procedures where the results of these tests are statically \nknown. These optimiza\u00adtion are of vital importance for embedded applications, as much of the computation \nwill be independent of the Main\u00adtained portion and should not be penalized by the Alphonse overhead. \n6.2 Static Graph Construction Production based incremental systems, such as attribute grammar systems, \nhave low dependency graph manipula\u00adtion overhead due to statically computed dependency sub\u00adgraphs for \neach production. The dependency graph is in\u00adferred from the composition of these subgraphs dictated by \nthe production interconnectivity. As the referenced argument set for many Alphonse pro\u00adcedures is static, \nthe compiler could generate a similar sub\u00adgraph. Our dependency graph structure can be extended to allow \nthis representation.  6.3 Graph Partitioning With eager quiescence propagation, one does not blindly \nkeep the dependency graph consistent after every change. Unless extra CPU cycles are available, the set \nof inconsis\u00adtent nodes accumulates. This delay allows multiple changes to be batched and re-evaluated \ntogether. If, upon the call to an Alphonse procedure, this set is not empty, we must suspend the caller \nand force propagation. However, the inconsistencies represented in the inconsis\u00adtent set do not necessarily \naffect the requested value. In some cases, if the dependency graph is not fully connected, this value \nmay not even be dependent upon the changes. To avoid waiting in this case, we maintain the dependency \ngraph as a set of unconnected components, each represent\u00ading a separate instance of quiescence propagation. \nThe first division is achieved using static analysis. First, we construct a connectivity graph of types \ndeclared by the program. Each type tis represented by a node C(t), and directed edges are added from \nnodes C(tl ) to C (~2) if tl has a pointer field that can point to an object of type tz. Second, we augment \nthis graph nodes C (p) for each pro\u00adcedure call site p that could be an incremental procedure instance. \nEdges are then added from C(p) to C(t) for each type tthat could be potentially accessed by p. The resulting \nconnectivity graph is separated into dis\u00adconnected components. Upon the creation of a new depen\u00addency \ngraph node for a top-level variable or incremental procedure, it is statically placed in a dependency \ngraph par\u00adtition based upon the location of the representative node in this divisions A further refinement \nis possible using a dynamic analysis. For each of the above dependency graph partitions, we keep disjoint \nsets of unconnected nodes using the unionffind al\u00adgorithm [AHU74]. New dependency graph nodes are placed \nin their own unique set. Upon adding an edge from c to y, we perform a union between the sets that cent \ntin z and y. The result of this analysis is many small dependency graphs, each with their own inconsistent \nset. This will de\u00adcrease the likelyhood that eager evaluation will be forced due to irrelevant changes \nand thus will allow more incon\u00adsistencies to be batched. 6.4 Reducing the Argument Set The programmer \nsometimes has semantic knowledge that is not derivable by the system, but can be utilized to im\u00adprove \nthe efficiency of the computation. This is manifested in Alphonse by referenced arguments of a procedure \nthat the programmer knows cannot affect the value of the com\u00adput ation. For example, consider a lookup \nprocedure in a balanced search tree, where the programmer can often show that the lookup is dependent \nupon the found item, but not depen\u00addent upon the log(n) access operations needed to locate it. We provide \nan additional pragma, (*UNCHECKED*),to al\u00adlow this knowledge to be specified on an expression basis, \neliminating these dependencies from the Alphonse compu\u00adtation.  7 Examples We illustrate the power of \nAlphonse programming with three examples. 7.1 Attribute Grammars In this section, we show how all attribute \ngrammars can be represented as Alphonse data types. We also give an example of this translation. Attribute \ngrammars [Knu68] are defined in terms of a context free grammar. For each nonterminal in a given production, \nequations are used to define attributes as a function of other attributes of other nonterminals of the \nproduction. NO ::=NI . ..N~ Nno.ao = f(Nnl. Z.l, . . . . N~h. Uk) There are two types of attributes. \nAttributes defined for left hand side nonterminals (No) are synthesized. Attributes defined for right \nhand side nonterminals (NI . . . NTI)are in\u00ad herited. We represent each production P in the grammar with \nan object type T, which we name after the left hand side nonterminal. This type contains: . A pointer \nto the parent production, . Pointers to objects of the types representing each right hand side nonterminal \np(NJ), . Fields representing the values of right hand side ter\u00adminal symbols, and  6It is possible \nthat static pointer analysis techniques [LH88, Hen90, CWZ90] might make this analysis less conservative. \nROOT ::= EXP ROOT.v?due = EXP.value EXP.env = Empt yEnvo EXPO::= EXP1 + EXP2 EXPO.v?dUe = EXPI.value-i-EXPz.Vahe \nEXP1.env = EXPO.env EXP2.env = EXPO.env EXPO::= let ID = EXPI in EXPZ ni EXPO.Vtdue = EXP2.VahIe EXP1.env \n= EXPO.env EXP2.env = Update13nv(Exp0 .env,m ,EXPIvalue) EXP ::= ID EXPvalue = LookupEnv(ExP .env,~ \n) EXP ::= INT EXP.Value = INT Algorithm 6: AG Expression Trees o Methods implementing all attribute \nequations in pro\u00adduction P. A dynamically allocated instance O of type T represents a production instance \ngenerated by the grammar. To complete the construction, we must show how to con\u00adstruct the attribute \nequations. We directly translate each equation into an imperative procedure, replacing each at\u00adtribute \nreference (N~, a;) by a method call to the method O.p(N~).aio. Synthesized attribute equations are repre\u00adsented \nby methods with no arguments, implemented by this procedure. Inherited attributes, however, require us \nto determine the context of the right hand nonterminal inheriting the value. Say N is a nonterminrd appearing \none or more times on the right hand side of production P. We represent all attribute equations for N,a \nin a single method with one argument. The object representing the right hand side production is passed \nas the argument and a case analysis is done to de\u00adtermine the appropriate context of N. Each arm of this \ncase analysis contains the code for the given nonterminal context. The above translation is illustrated \nby the attribute grammar example shown in Algorithm 6. We assume a rep\u00adresentation of environments with \nEmptyEnv, UpdateEnvj and LookupEnv operations. The result of the translation is as follows. First, we \nas\u00adsume integers for our value type Val, and assume .&#38;w, a translation of the environment type and \nrelated operations that were unspecified in the attribute grammar. Produc\u00adtions Prod are objects with \na production parent. An ex\u00adpremion production Exp is a production with maintained methods for value vako \nand environment envo. As de\u00adscribed above, the inherited attribute env is translated into a method with \na single argument to distinguish the nonter\u00adminal context. These basic types are illustrated in Algo\u00adrithm \n7. Each production is then written as a subtype of Exp, adding right hand side nonterminals and terminals \nas well as overriding the value( ) and en<) methods. These types are shown in Algorithm 8 and the method \nimplementations TOther than the object O. SThat is, ~ keyed set, of (identifier,value) Pairs. TYPE Val \n= INTEGER; TYPEhv =...; TYPE Prod = OBJECTparent : Prod; END; TYPE Exp = Prod OBJEGT ~THODS *MAINTAINED* \nvalueo : Val; *MAINTAINED* env(c : Exp) : Env; [) END; Algorithm 7: Basic Types TYPE RootExp = Exp \nOBJECTexp : Exp; OVERRIDES *MAINTAINED* value := ExpVal; [1 *MAmTAINED* env := NullEnv; END; TYPE PlusExp \n= Exp OBJECTexpl, exp2 : Exp; OVERRIDES *~A~TA~D* value := SumVal; *MAINTAINED* env := PassEnv; [1 END; \nTYPE LetExp = Exp OBJECT expl, exp2 : Exp; id : TEXT; OVERRIDES *MAINTAINED* value := Exp2Val; *MAINTAINED* \nenv := LetEnv; [I END; TYPE IdExp = Exp OBJECTid : TEXT; OVERRIDES(*MAINTAINED*)value := IdVal; END; \n TYPE IntExp = Exp OBJEGTint : INTEGER; OVERRIDES(*MAINTAINED*)value := IntVal; END; Algorithm 8: Types \nfor Productions are given in Algorithm 9. Note that the procedure LetEnv illustrates the technique for \nencoding inherited attributes for a given nonterminal context. 7.2 Spreadsheet We can extend the previous \nattribute grammar into a spreadsheet as follows. First, we define a Cell object con\u00adsisting of an expression \ntree oft ype Exp (from Section 7.1), and a maintained method value that simply returns the value of the \nexpression tree. An array of Cell objects rep\u00adresents the spreadsheet. In order to allow the cell functions \nto reference the values of other cells, we add a CellExp production to our expres\u00adsion trees. This production \nuses two integer valued terminal fields to select another cell in the array and return the re\u00adsult of \nits value method. The program for this is shown in Algorithm 10. Note that this example shows the use \nof top-level data references and illustrates how one Alphonse program can be used to construct another. \n7.3 Dynamic Data Structures PROCEDUREExpVrd(o : Exp) : Val = BEGINFIETURNo.exp.valueo ENDExpVal; PROCEDURENullEnv(o,c \n: Exp) : Env = BEGIN RETURNEmptyEnvo END NullEnv; PROCEDURBSumVal(o : PlusExp) : Val = BEGIN RETURNo.expl.vrdueo+o. \nexp2.valueo ENDSumVal; PROCEDUREPassEnv(o,c : Exp) : Env = BEGIN RETURN o.parent.env(o) ENDPassEnv; PROCEDUREExp2Val(o \n: Ph@xp) : Val = BEGINRETURNo.exp2.vrdueo END Exp2Val; PROCEDURELetEnv(o,c : Exp) : Env = BEGIN IP C=o.expl \nTHENRETURNO.parent.env(o) ELSElU3TURNUpdateEnv(o.parent. env(o), id,o.expl,valueo) END ENDLetEnv;  PROCEDUREIdVal(o \n: IdExp) : Val = BEGIN RETURNLookupEnv(o.parent .env(o),id) ENDIdVal; PROCEDUREIntVal(o : IntExp) : Vd \n= BEGINllETuRN o.int ENDIntVal; Algorithm 9: Method Implementations TYPE Cell = OBJECTfunc : Exp; METHODS(*MAINTAINED*)valueo \n:= ExpVal; END; PROCEDUREExpVal(o : Cell) : Val = BEGINRETURNo.exp.vrdueo END ExpVal; cells : ARRAY [1..100], \n[1..100] of Cell; TYPE CellExp = Exp OBJECT x,y : INTEGER; OVERRIDES(*MAINTAINED*)value := CellVs,l; \nEND; PROCEDURECellVal(o : CellExp) : Val = BEc31NRETURr.ICells[O.X,O.y].vIdueo END Cellvd Algorithm 10: \nSpreadsheet Another powerful use of Alphonse is the construction of dynamic data structures. For example, \na balanced search tree insertion routine can be thought of as an algorithm that takes a balanced tree \nand produces a new balanced tree con\u00ad taining the added element. Of course, an efficient insertion algorithm \nwti produce incrementally only the changes nec\u00ad essary to derive the output from the input. These changes \nare then applied to the input structure. In this section, we illustrate how Alphonse can be used to implement \ndy\u00ad namic data structures by showing a simple implementation of AVL binary search trees [AVL62, HS82]. \n(AVL trees are balanced binary trees where, for every node z, the height of the children of x differs \nby at most one.) We begin by extending the Tree data type of Algorithm 1 with an additional maintained \nmethod, balance, resulting in the Aul data type shown in Algorithm 11. As in the Wee data type, a special \nsubtype is used to represent missing leaf pointers balance here simply returns the object. For interior \nnodes, however, the balance method performs the tree rotations necessary to balance the subtree (according \nto the AVL definition). Thus, balance on the tree root will result in a balanced tree. Not shown, are \nprocedures for lookup, insert, and delete. However, since the data structure is self balancing, these \noperations are exactly the same as for an unbalanced binary tree. The programmer is simply required to \ncall the balance method prior to performing a search operation, in order to insure that the tree is balanced \nand guarantee O(log n) behavior. Note that the recursion in Balance admits to the pos\u00adsibilityy of multiple \nchanges. Thus, the algorithm allows arbitrary operations (e.g. splitting, joining, subtree inser\u00adtion) \nas well as multiple change operations between each tree balancing. The programmer simply must ensure \nthat the structure is in fact a tree and the nodes are ordered as required. Thus, the algorithm is both \nan ofl-line as well as on-line algorithm. Theorem 7.1 Algorithm 11 as an Alphonse program. Proof: We \nneed to show that Algorithm 11 obeys the restrictions of Section 3.5. DET There is no static local storage \nnor any nondetermin\u00adistic language constructs used in the program. TOP All procedures are top-level and \nno local storage is passed via pointer or VAR parameters. OBS Balance is the only Alphonse procedure \nthat causes side effects, namely the tree rotations. Since these rotations preserve the tree order, tree \nsearches will re\u00adturn the same result regardless of when Balance is exe\u00adcuted. We must also show that \nthe enclosing program uses AVL trees only for searching and does not have behavior that depends upon \nthe structure of the tree (height, relative node positions, etc.).  8 Implement at ion We are currently \nbuilding an implementation of Alphonse\u00adModula-3, using source to source translation: The program TYPE \nAvl = Tree OBJECT METHODS(*MAINTAINED*) balance := Balance; END; TYPE AvlNil = Avl OBJECT OVERRIDES *MAINTAINED* \nheight := HeightNil; *MAINTAINED* balance := BalanceNil; { 1END; PROCEDURE Balance(t : Avl) : Avl = \nBEGIN t.left := t.left.balanceo; tright := t.right .balanceo; m Diff(t) > 1 THEN IP Diff(t) = 2 AND \nDiff(t.left) = 1 THEN t.left := RotateLeft(t.left) END ; t := RotateRight(t). balanceo ELSIFDiff t) < \n1 THEN m Diff(t = 2 AND Diff tright = 1 THEN \\ tright := RotateRight [{t,right END ; t := RotateLeft(t).balanceo \nEND; RETURNt END Balance; PROCEDURE BalanceNil(t : Avl) : Avl = BEGINRETURNt ENDBalanceNil; PROCEDURE \nDiff(t : Avl) : mTEGER= BEGIN FIETURN t.Ieft.heighto-t right .heighto ENDDiff PROCEDURE RotateRight(t \n: Avl) : Avl = VAR s,b : Avl; BEGIN s := t.left; b := s.right; s.right := t; t.left := b; RETURNS ENDRot \nateRight; PROCEDURE RotateLeft(t : Av1) : Av1 = VAR s,b : Avl; BEGIN s := t.right; b := s.left; s.left \n:= t; t.right := b; RETURNS END Rot ateLeft; Algorithm 11: AVL Trees is parsed and an abstract syntax \ntree is generated contain\u00ading nodes for the Alphonse pragmas. Program transforma\u00adtions are then applied \nto the tree to insert the call access, and modify operations as described in Section 5, while re\u00admoving \nthe Alphonse pragmas. Unparsing the syntax tree will then yield a pure Modula-3 program cent aining the \ncode fragments of Section 5 and references to evaluation routines contained in an auxiliary module. We \nare also considering a second implementation in an object oriented database system. 9 Analysis There \nare two ways to compare the resources required by an Alphonse program A to those required by conventional \npro\u00adgrams. We can either compare the space and time required by A to the time and space required by an \nequivalent pro\u00adgram to A designed to run efficiently in the conventional model, or we could compare A \nto the time and space re\u00adquired by a conventional execution of A. Making concrete statements about a \ncomparison of A to an equivalent efficient conventional program is difficult, as there is nothing to \nlimit the programmer from constructing a program that uses all of the applicable Alphonse tech\u00adniques \nas well as other techniques that apply only to the problem at hand. Alphonse is not designed to compete \nwith programmers willing to embed detailed caching strate\u00adgies in their code. Alphonse is for programmers \nwho seek the efficiency of incremental computation, but are unwill\u00ading to embrace the high cost of incremental \nprogramming. Instead, we must examine each application and ask how A relates to the program that the \nprogrammer would be likely to write. Consider the example from Algorithm 1. When faced with the problem \nof maintaining the height at each node, an ambitious programmer might create a height field in each node, \nand upon each pointer change in the tree, travel to the root of the tree updating all pointers on the \npath. While this is roughly what the Alphonse program A would do (and is what the dependencies dietate), \nA would have the advantage of Batching the computations spurred by each change, Performing the batched \noperations together to avoid duplicate updates at nodes that are ancestors of mul\u00ad tiple changes, and \nComputing the updates with different threads of con\u00ad trol to utilize computing cycles available before \nthe next request for the height of a node. While the programmer could choose to add any of these items \nto the competing code, the result would be substantial complication and the increased opportunity for \nerrors. The Alphonse program A yields these benefits safely. The cost of executing A is made up of the \ncost of the dy\u00adnamic translation plus the cost of performing the incremen\u00adtal evaluation. We will refer \nthe reader to the appropriate literature for the cost of applying the underlying incremen\u00adtal techniques \n[Rep84, Hud86j Ho086, Ho087, AHR+ 90], and focus on the costs of translating the algorithm into the incremental \nintermediate form. Thus, we consider the time and space required by the dynamic dependence analy\u00adsis \n(Section 4) as compared to the time and space required to run the program under the conventional execution \nmodel. 9.1 Space 10 Related Research Let kf be the maximum amount space required by an Alphonse program \nwhen executing under the conventional (that is, non-incremental) execution model. We analyze the space \nneeded in terms of M. We require space for the call stack of incremental proce\u00addure instances, as well \nas space for the dependency graph, both nodes and edges. The procedures on the call stack are a subset \nof the conventional procedure call stack, and therefore require O(lkf) space. Dependency graph nodes \n(and node pointers) are required for top-level variables and incremental procedure instances. If we assume \na constant sized cache foreach cached procedure, this toocan be stored in O(M) space. The edges of the \ndependency graph, however, could re\u00adquire 0(M2 ) space if dependencies between top-level vari\u00adables and \nincremental procedure instances grows dense. While it is easy to exhibit this behavior (each Alphonse \nprocedure scans O(M) data, it is our experience that such dense dependence is not encountered in applications \nthat can benefit from incremental computation. In the O(lkf2 ) case, essentially every part of the computation \nis depen\u00addent upon the entire computation. Thus, every change will trigger the re-execution of O(M) incrementally \nmaintained procedures resulting in zero speedup with incremental eval\u00aduation. In many Alphonse applications, \nthe Alphonse procedures have constant sized referenced argument sets, and thus an O(M) space requirement. \nMaintaining properties that perform search operations in balanced trees would require O(M log M) space, \nbut this could be reduced to O(M) space usage through the use of the techniques of Section 6.4. 9.2 Time \nLet T be the time required to execute an Alphonse algo\u00adrithm under the conventional, non-incremental \nexecution model. We argue that dynamic dependence analysis can be performed in 0(77). If we assume that \nobject creation is a constant time op\u00aderation, then clearly, creation of dependency graph nodes upon \nthe first access to a top-level variable or incrementally maintained procedure does not add to asymptotic \nrunning time of the program. Likewise, since individual edges are added upon the access of data, the \ncreation of edges falls within this bound. We must show, however, that the edge removal at proce\u00addure \ncalls in Algorithm 5 is constant time per edge. This is the case if we use a doubly linked list of bidirectional \nedges to represent successors and predecessors in the dependency graph. Thus, the 0(1 ) cost of removing \neach edge can be charged to the edge creation. If the dynamic dependency graph partitioning algorithm \nof Section 6.3 is used, the time bound is slightly increased to O(T x G(ilf)), where G() is the inverse \nAckermann s func\u00adtion. We expect the actual performance of the algorithm to be substantially faster than \nO(T), due to the performance gains of incremental computation. The exact performance, of course, will \ndepend upon the amount of computation reuse with the programmers partitioning of the problem into incrementally \nmaintained procedures. The major goal of Alphonse is to improve the construc\u00adtion, understanding, and \ncorrectness of incremental algo\u00adrithms by automatically generating much of the intricate algorithm detail. \nRAPTS [Pai86] is another program trans\u00adformation system with a similar goal. However, our ap\u00adproaches \nare quite different. RAPTS uses a specification terms of high level abstract operations such as set manipu\u00adlation. \nThis program is transformed into an efficient imple\u00admentation through the automatic substitution of efficient \nprecanned low level algorithms for these abstract opera\u00adtions. In contrast, the focus of Alphonse is \non the construc\u00adtion of such low level algorithms, which are impossible to efficiently write in RAPTS. \nAlphonse is much closer in spirit with other automatic in\u00adcremental systems, which generate incremental \nimplemen\u00adtations that automatically perform the bookkeeping nec\u00adessary to track change and dependence. \nSuch systems in\u00adclude attribute grammar systems such as the Synthesizer Generator [RT88], the graph grammar \nsystem of [Kap86], the message passing framework of [DRZ85], as well as the boxes and cables method of \n[ACR+ 88] and its implementa\u00adtion in the Cactis object oriented database system [HK89]. We briefly describe \nAlphonse s advantages and contribu\u00adtions over these systems. Most of these systems are based upon grammars, \nwhich place practical limit ations upon their applicability in many applications. In addition, grammar \nbased systems suffer from the local communication and aggregation problems [RMT86, Ho086, Ho087]. The \nspecification languages used by the above systems tend to be somewhat unusual, and the runtime environment \nimposes additional limitations (i.e. the Synthesizer Generator uses an editing paradigm, Cactis, a database \nparadigm). As a result, it is difficult to embed their progra~s inside conventional ones. When com~ared \nto other incremental systems, Alphonse has the following advantages: . Alphonse subsumes grammar based \nlanguages (see Section 7.1). . The language is a familiar one, especially for object\u00adoriented programmers. \n . It is not limited to local communication. Incrementally maintained procedures are allowed to look \nat global information and navigate arbitrary data structures. Thk ability also side steps the aggregation \nproblem. . It uses the conventional compile/execute runtirne en\u00advironment. . Incremental subproblems \ncan be embedded inside ar\u00ad  bitrary programs with a consistent, procedure call and data structure interface. \n While it is beyond the scope of thk paper, the dynamic dependence information gathered by Alphonse can \nalso be used for additional advantage, such as in debugging and scheduling parallel execution. 11 Conclusions \nThe Alphonse system presents a powerful new programming technique. Through the use of dynamic analysis \nand the in\u00adtegration of quiescence propagation and function caching, it advances the automatic specification \nof incremental al\u00ad gorithms. It is systems of this type that will deliver the benefits of incremental \ncomputation to the general purpose programming community. I would like to thank John Field, Martin Odersky, \nTom Marlowe, and Dan Yellin for invaluable conversations that helped to shape Alphonse.  References \n [ACR+88] B. Alpern, A. Carle, B. Rosen, P. Sweeney, and K. Zadeck. Graph attribution as a spec\u00adification \nparadigm. In Proceedings of the ACM SIGSOFT/SIGPLA N Software Engm.eer\u00ading Syrnposzum on Practical Software \nDevel\u00adopment Environments, pages 121-129, Boston, Massachusetts, November 1988. [AHR+90] B. Alpern, R. \nHoover, B. Rosen, P. Sweeney, and K. Zadeck. Incremental evaluation of com\u00adputational circuits. In Proceedings \nof the First Annual A CM-SIAM Symposium on Discrete Al\u00adgorithms, pages 32 42, San Francisco, Califor\u00adnia, \nJanuary 1990. [AHU74] A. Aho, J. Hopcroft, and J. Unman. The Design and Analysis of Computer Algorithms. \nAddison-Wesley, Reading, Massachusetts, 1974. [AVL62] G. Adel son-Velskii and Y. Landis. An algo\u00adrithm \nfor the organization of information. DokL Akad. Nauk SSSR, 146:263-266, 1962. English translation in \nSoviet Math. Dokl. 3, pp. 1259 1262. [CWZ90] D. Chase, M. Wegman, and F.K. Zadeck. Anal\u00adysis of pointers \nand structures. In Proceed\u00adings of the SIGPLA N 988 Conference on Pro\u00adgramming Language Design and Implementa\u00adtion, \npages 296 310, White Plains, New York, June 1990. [DRZ85] A. Demers, A. Rogers, and F. Zadeck. At\u00adtribute \npropagation by message passing. In Pro\u00adceedings of the ACM SIGPLA N 85 Symposium on Language Issues in \nProgramming Environ\u00adments, pages 43-59, Seattle, Washington, June 1985. [Hen90] L. Hendren. Paralleltzing \nPrograms with Recur\u00adsive Data Structures. PhD thesis, Cornell Uni\u00adversity, Ithaca, New York, April 1990. \n[HK89] S. Hudson and R. King. Cactis: A self-adaptive, concurrent implementation of an object-oriented \ndatabase management sys\u00adtem. ACM Transactions on Database Systems, 14(3):291-321, September 1989. [HO086] \nR. Hoover. Dynamically bypassing copy rule chains in attribute grammars. In Proceedings of the Thirteenth \nAnnual ACM Symposium on Principles of Programming Languages, pages 14 25, St. Petersburg, Florida, January \n1986. [Ho087] R. Hoover. Incremental Graph Evaluation. PhD thesis, Cornell University, Ithaca, New York, \nMay 1987. [HS82] [Hud86] [Kap86] [Kar49] [Knu68] [LH88] [Ne191] [Pai86] [PT89] [Pug88] [Rep84] [RMT86] \n[RT88] [Yeh83] E. Horowitz and S. Sahni. Fundamentals of Data Structure. Computer Science Press, Rockville, \nMaryland, 1982. S. Hudson. A User Znterface Management Sys\u00adtem Winch Supports Direct Manipulation. PhD \nthesis, University of Colorado, August 1986. S. Kaplan. Incremental attribute evaluation on graphs. Technical \nReport UIUC-DCS-86-1309, University of Rlinois, Urbana-Champaign, Rli\u00adnois, December 1986. A. Karr. Les \nGu6pes, Janvier 1849. Plus ga change, plus c est la m~me chose. D. Knuth. Semantics of context-free languages. \nMathematical Systems Theory, 2(2):127 145, June 1968. J. Larus and P. Hilfinger. Restructuring lisp programs \nfor concurrent execution. In Proceed\u00adings of the A CM/SIGPLA N Parallel Program\u00adming: Experience with \nApplications, Languages and Systems, pages 100 1 10, New Haven, Con\u00adnecticut, July 1988. G. Nelson, editor. \nSystems Programming with Modu{u-3. Prentice-Hall, Englewood Cliffs, New Jersey, 1991. R. Paige. Programming \nwith invariants. IEEE Software, 3(1):56-69, January 1986. W. Pugh and T. Teitelbaum. Incremental com\u00adputation \nvia function caching, In Proceedings of the Sixteenth Annual ACM Symposium on Prin\u00adciples of Programming \nLanguages, pages 315\u00ad328, Austin, Texas, January 1989. W. Pugh. Incremental Computation and the Incremental \nEvaluation of Functzon Programs. PhD thesis, Cornell University, Ithaca, New York, August 1988. T. Reps. \nGenerating Language-based Environ\u00adment. MIT Press, Cambridge, Massachusetts, 1984. T, Reps, C. Marceau, \nand T. Teitelbaum. Re\u00admote attribute updating for language-based ed\u00aditors. In Proceedings of the Thirteenth \nAnnual ACM Symposium on Principles of Programming Languages, pages 1 13, St. Petersburg, Florida, January \n1986. T. Reps and T. Teitelbaum. The Synthesizer Generator. Springer-Verlag, Berlin, Heidelberg, New \nYork, 1988. D. Yeh. On incremental evaluation of ordered attributed grammars. BIT, 23:308-320, 1983. \n \n\t\t\t", "proc_id": "143095", "abstract": "<p>Alphonse is a program transformation system that uses dynamic dependency analysis and incremental computation techniques to automatically generate efficient dynamic implementations from simple exhaustive imperative program specifications.</p>", "authors": [{"name": "Roger Hoover", "author_profile_id": "81332504824", "affiliation": "", "person_id": "PP31081920", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143095.143139", "year": "1992", "article_id": "143139", "conference": "PLDI", "title": "Alphonse: incremental computation as a programming abstraction", "url": "http://dl.acm.org/citation.cfm?id=143139"}