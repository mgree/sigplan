{"article_publication_date": "01-26-1981", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1981 ACM 0-89791-029-X $5.00 (c) Context sensitive generation of alterna\u00ad tive concrete representations, \neither for ltpretty-printingW or to repair structural i,nconsi.stencies such as discussed in (b) above. \nFor example, from the A%tracL syntactic struc\u00adture above, using semantics, one can automati\u00adcally generate \nthe ~ display if Boolean-expression then begin if Boolean-expression then statement end else statement \n (d) Incremental translation. This allows interactive debugging and execution even of incomplete programs, \nwith no compilation delay. (e) Incremental global data-flow analysis [1,71. For example, such classical \ncode optim\u00adization techniques as definition-use chaining can be used in an interactive debugger to answer \nqueries about static program structure.  Because of its importance, the problem of enforcing consistent \nvariable declarations and vari\u00adable uses will be our primary motivating example. However, the method \ndeveloped in this paper is applicable to each of the areas mentioned above. Our ultimate goal is to use \nit to integrate all static program analysis and translation tools into an interactive program development \nsystem. 3. Semantic analyais in the Cornell Pro\u00adgram Synthesizer The full-screen display editor of the \nCornell Program Synthesizer [17,18,191 detects semantic errors with each incremental step during the \ndevelopment of a program. As a program is edited, a modification at one location may introduce errors \nat other locations in the program; simultaneously, it may correct errors at still other locations. Errors \nin the program are tolerated, but are highlighted on the screen until they are corrected. The user is \nconstantly reminded visually about what is correct and what is incorrect. One derives a program using \nthe editor by inserting either a ~ or a ~ into an existing partially developed program at the position \nof a nonterminal symbol. A template is a formatted pattern for a language construct, essentially the \nright-hand side of a production in the grammar. For example, one of the declaration templates is: DECLARE \n( list-of-variables ) FLOAT; A template ia inserted by command, and may be mani\u00ad pulated only as a unit. \nIt is immutable, meaning that one is not allowed to alter the keywords or punctuation. A phrase i.s a \npiece of text for one of the grammatical units of the language, and i.s inserted manually by typing the \ntext. One example of a phrase is the assignment statement temp= m;n, another is the list-of-variables \n!m, n!!. By insert\u00ading the latter into the above template, one builds the declaration statement: DECLARE \n( m, n ) FLOAT; This editing discipline prevents errors from being introduced into a program. In fact. \nan ini\u00adtial goal of the Synthesizer was to guarantee that programs were completely correct at every stage \nof their development. Any modification that introduced an error was to be prevented. Experience forced \nus to retreat from that position. For example, consider the problem of changing the type of a program \nvariable. Because a keyword such as MFIXEDW cannot be changed by itself> the natural way to do this is \nto delete the declaration and insert another. However, the implemented dialect of PL/I requires that \nall variables be declared; deleting the declaration would introduce undeclared-variable errors in every \nphrase referenc\u00ading the variable. Rather than have a separate mechanism to make such modification atomic \noperations, the insistence on perfect correctness was relaxed. Thu S, the moment a declaration ia deleted. \nall phrases con\u00adtaining the undeclared variable are highlighted. When the new declaration is inserted, \nall are redisplayed in the normal font. To illustrate this, consider what happens when the declaration \nof the variable temp is deleted from: DECLARE ( temp ) FIXED; DECLARE ( m, n ) FLOAT; temp= m; m= n; \nn= temp;  Errors are introduced in the first and third assign\u00adment statements because they use temp, \nso they are highlighted. DECLARE ( m, n ) FLOAT; = m= n; - Internally the following actions are taken: \na) temp is removed from the symbol table (undoing a previous semantic action). b) The program tree is \ntraversed in preorder and phrases are checked for semantic errors. Any phrase using temp is now semantically \ninvalid and is marked as such. c) The screen is reprinted --invalid phrases are displayed in highlighted \nfont. When temp is redeclared, uses of temp become correct and are again displayed in the normal font. \nDECLARE ( m, n, tamp ) FLOAT; temp= m; m= n; n= temp;  Internally, a procedure is invoked on each insertion \nto perform semantic actions: another pro\u00adcedure is invoked on each deletion to !!undo~~ seman\u00adtic actions. \nEach of these procedures must traverse and possibly update the program tree to maintain semantic consistency. \nIn a modular editor specification system, we could let the editor-designer provide a specialized semantic \nprocedure and a specialized undoing pro\u00adcedure for each production in the grammar. The former would be \ncalled for program expansions, the latter for deletions. Each procedure would do its own tree-walk, examining \nand updating nodes. There are several objections to this approach, The semantics are expressed imperatively, \nencoded in procedures with side effects. In addition, the specification is not modular. Though associated \nwith a single production, each procedure controls a tree-walk, and thus may depend on the structure of \nthe entire tree. Consequently, information from many of the other productions must he hard-coded into \nit. To avoid these problems, we sought a different specification mechanism. 4. Attribate granars Attribute \ngrammars [12] allow the semantics of a language to be specified along with its syntax. Underlying an \n~ ~ is its context-free grammar G (VN, V , P, ROOT), where VN is the set of nonterminal sym%01s, VT is \nthe set of terminal symbols, P is the set of productions, and ROOT e VN is the start symbol. The ~ M \nof G are defined inductively as follows: a) A node labeled ROOT is a derivation tree, b) Ifp:Xo+X1..~\\ \nis a production in P, and T IS a derivation tree with leaf node no labeled Xo, then the tree T? obtained \nfrom T by adding sons n S*O. S labeled 1s a derivation tree. ~  ~s reape:tively,~ at O The k+l tuple \nof nodes <n , n ,..., ~> in the preceding definition is cane ~ a ~roducm ~ ~ g in T?; it &#38;@,Y@2 nodes \nn ,..., and is k ~ ~ node no. The JM+&#38;.&#38;&#38; of production instance the production instance \nt;}t k;iij~d%;o a;~d the production instances derived from n ,.. , nk. A derivation if allo~ itsleavea \nare labeled with terminal symbols; it is ~ otherwise. tree is ~ With each terminal or nonterminal symbol \nwe associate two finite disjoint sets: a set of .S.XLC and a set of ~ dJZ.&#38; .b!ALQ%. With each \nproduction p: X. + X associate a set of Mz@tl&#38;c &#38;UtiQIE. $i:~ k: tic function defines a value \nfor a synthesized attribute of X or an inherited attribute of X., I<iSk, in terms of attributes of X \n, X ,.**s and ~. Thus, we define the set Out(p), ?he lQL@@. ~ -of P, to consist of the synthesized attributes \nof x together with the inherited attri.b.utes of larly, we def i.ne the aet In(p), the of p, to consist \nof the i.nheri. ted attributes of together the synthesized attributes of X~.; .,\\. .F~~t~revity, the \nargu\u00ad ments of the semantic function defining the value of attribute b are referred to as the arguments \nof b. A derivation tree node labeled X definea a set of ~ corresponding to the attri\u00ad butes of X. A \n~ LILW is a derivation tree together with an assignment of either a value or the special token aall to \neach attribute instance of the tree. To determine the meaningw of a string, one first constructs ita \nsemantic tree with an assignment of null to each attribute instance. and then evaluates the semantic \nfunctions of as many attribute instances as possible. The latter process is termed a&#38;@b.uk . The \norder in which attributes are evaluated is arbitrary, subject to the constraint that a particular semantic \nfunction can be evaluated only when all of the argument attributes are ~ , that is, non-aull. Using these \ndefinitions, we can state the method of [121 for evaluating a semantic tree T as the following iterative \nalgorithm scheme: EVALUATE(T) : while there are unavailable attribute instances in T that have available \narguments do choose such an attribute instance b evaluate(b) od A semantic tree ia ful&#38; &#38;@iht&#38;l \nif a value is associated with each of its attribute instances; it is ~ at.Lributed if the value of at \nleast one attribute instance is unavailable. An attribute grammar is &#38;L1-~ if every complete derivation \ntree can be fully attributed. The relationships among attributes in a given derivation tree T are represented \nby its &#38;QMQQL@ ~u, D, defined as follows: a) Each node b! of D corresponds to an attri\u00adbute instance \nb of T. b) D has a directed edge from node b to node Ct if the semantic function for c has b as an argument. \n An edge from b? to c? has the meaniug: b! is used to determine the value of ct. -of the compound dependency \ngraph are nodes with no incoming edges. In particular. attribute instances defined by O-ary semantic \nfunctions produce roots. An attribute grammar is ~ if the com\u00ad pound dependency grapha of all possible \nderivations are acyclic. Without leas of generality, any non\u00ad circular attribute grammar can be put into \na BQXU@ ~ in which every semantic function defines a value for an output attribute in terms of zero or \nmore input attributes [91. In this paper, we con\u00adsider only well-formed, noncircular attribute gram\u00ad \nmars in normal form. An attribute grammar can be used to specify semantics in a system for generating \nsyntax-directed editors. This approach has several advantages over the procedural approach of the previous \nsection. The semantics is expressed applicatively. Propaga\u00adtion of semantic attributes through the tree \nis implicit in the formalism and need not be specified imperatively, on a case-by-case basis. In addition, \nthe specification is modular; the arguments to each semantic function are local to one production. The \nnext few sections of this paper show how an attribute grammar also specifies how to nullify Wundot! semantic \nactionso semantic attributes, i.e., A syntax-directed editor can use these properties to maintain semantic \nconsistency during program modifi\u00ad cations. 5. An example We now present an example from [2] that demon\u00adstrates \nhow an attribute grammar may be used to enforce block structure and declaration-before-use in a programming \nlanguage. The underlying grammar is: 1) <program> + <block> 2) <block> + <decl list> <stint list> 3) \n<decl list> + <decl list> <id decl> 4) + <id decl> 5) <stint list> +-<stint list> <stint> 6) + <stint> \n7) <stint> + <ex stint> 8) + begin <block> end  The productions, attributes, and semantic functions \nare depicted in Figure 1. Dotted lines represent context-free derivations, and solid lines represent \nsemantic functions. The attributes have the follow\u00ading meanings: is an synthesized attribute of <id decl>. \nIts value ie a symbol table entry. .. is an inherited attribute of <decl list> whose value is a partially \ncon\u00adstructed symbol ta~le. upda.kd is a synthesized attribute of <decl list> whoee value ia the original \nsymbol table with a new entry appended. ti is an inherited attribute of <block>, <stint list>, <ex stint>, \nand <stint>. Its value is a symbol table that contains all of the variables that are legal at the nonterminal. \n The attributes ~ and ~ are threaded through the declarations to construct a symbol table from the attributes. \nThe symbol table is broadcast to every node of the program tree within the scope via the A attribute. \nFigure 2 shows the semantic tree and compound dependency graph of the following sample program. <id decl> \n<ex stint> begin <id decl> ~ex stint> end <ex stint>  We will return to this example later in the paper \nto illustrate the utility of attribute gram\u00admars for syntax-directed editing. 6. Incremental attribute \nevaluation The creation of a program using a syntax\u00addirected editor entails growing a derivation tree \none step at a time. During program development. the derivation tree is partial, but we wish to perform \nas much semantic analysis as possible incrementally. In the example discussed in the previous sec\u00adtion, \nthe declarations of variables are made avail\u00adable throughout their scope by threading a symbol table \nattribute through the program tree. An unex\u00adpanded nonterminal <decl liet> would sever this chain of \ninformation. making it impossible to verify incrementally that declaration and uses of vari\u00adables were \nconsistent. To maximize the amount of semantic analysis that can be performed incrementally, we require \na X + L for each nonteminal symbol X. The completing production X + L should not be confused with the \nproduction X -+ c; the syrs\u00adbol J. (read bottomw) denotes unexpandedn and defines the semantics of a \nmissing subtree. By con\u00advention, an occurrence of an unexpanded nonterminal is considered to have derived \n.L. By this device, all partial derivation trees (from the user s viewpoint) are considered complete \nderivation trees (from the editor s viewpoint). Thus, as a program is derived incrementally, tbe partial \nderivation trees may be fully attributed. In the attribute grammar from the previous sec\u00adtion, completing \nproductions can preserve the chain of symbol table attributes by passing along the, sym\u00adbol table unchanged. \nFor example: <declaration list> original updated I I : Let T be a fully attributed semantic tree and \nU be a subtree of T with root node n labeled X. U is QXJAUJQ from T by deleting all descendants of n \nand assigning mull to the synthesized attribute instances of n. Let U? be a free-standing attri\u00adbuted \nsemantic tree. with root n! also labeled X. U! is ~ onto T at leaf n labeled X by assign\u00ading the inherited \nattribute values of n to the inherited attribute instances of nr and then replac\u00ading n by U! in T. We \ndefine SQJQQ.e~of U by U! as the pruning of U followed by the grafting of U! in ita place. An entire \nediting session is viewed by the edi\u00adtor as a succession of replacement operations start\u00ading from the \nfully attributed, complete semant. c tree ROOT I I I J. Each insertion of subtree U! at unexpanded nonterm \nnal labeled X is viewed internally as the replace\u00adment of an instance of the completing production of \nX by U!. Each deletion of a subtree U (with root X) is viewed internally as the replacement of U by an \ninstance of the completing production of X. The task of an ~ is to establish correct attribute values \nthroughout T in conjunction with each subtree replacement operation. Of course, an off-line algorithm \ncould be applied to completely reevaluate the tree; the goal of an incremental algorithm is to minimize \nwork by confining the scope of reevaluation required by each subtree replacement. Two approaches will \nbe considered: (a) a two pass process consisting of nullification followed by evaluation, and (b) a one \npasa process that propagates changes of attribute values. 7. A two pass iacreasental ewaluator 7.1* Stability \nand consistency To characterize partially attributed semantic trees, we introduce the notions of stability \nand consistency. In this section, let T be a partially attributed semantic tree for an attribute grammar \nG, and let D be the compound dependency graph of T. We say an attribute instance b of T is ~ if: a) b \nis available and all of its arguments are available, or b) b is unavailable and at least one of its arguments \nis unavailable. 1) <program> 5) <stint list> used # F .-g\\ .,1, > / <stint list> used <s;mt> used \n2) <block> used 6) <stint list> used i .~ ~:. ./ / , -. % II J / <decl list> original updated <stint \nlist> used <stint> used 3) <decl list> original updated 7) <stint> used f  0 &#38;yz Fp ..~,.; I I\\ \ni4 <decl list> original updated <id decl> declaration <ex stint> used 4) <decl list> original updated \n8) <stint> used \\ t ,+. \\ \\ concatenation /1 m/ \\ P I --\\\\ \\<id decl> declaration be~in <block> used \nend _ 1: Productions, attributes, and semantic functions <program> 1 I I I <block> used .> 7:.. > k. \n% <decl list> orig up <stint llst> used I I Y .-= 9\\ L-.&#38;.-., <stint list> use~ -sLmcz uses II \n>_I / .  / I. #\u00ad -( ~sed ,I <stint list> use / --l\\ \\I/ / \\ / / 1 //I / I\\\\ . <st&#38;> U! d  I /i \n<block> USL. \\ I/I /,4 \\ // \\ L\\ \\ / 0,/ N\\ I /./~ \\ r \\ ( % [ <decl list> orig up <stint list> used \n\\ I I \\f I 1\\I 1\\ / I/I I\\/[d 1 rI \\ <stint> us-cd I II I\\ I II 1. I <id decl> decl <ex stint> u~ \nd be~in <id decl> decl \\T ll \\ <ex stint> used end <ex stint> used -~: Semantic tree and compound dependency \ngraph 109 Thus. there are two ways fOr b to be unstable: a) When b is unavailable and all of its argu\u00adments \nare available, we say that b is U d&#38;UL. b) When b is available and at least one of its arguments \nis unavailable, we say that b is ~. Notice that the criterion for stability is agreement of availabilities; \nnothing is implied about agree\u00adment of values. Wesay b is ~ if: a) b is available, and b) all of bts \narguments are available, and c) b s value is not equal to its semantic function applied to the arguments. \n In all other cases, we say b is ~. Note that consistency is simply the absence of manifest errors; for \nexample, an attribute instance b is con\u00adsistent if it is available but one of its arguments is unavailable. \nWe extend the definitions of stability and con\u00adsistency to cover related concepts in production instances, \nsemantic trees, and compound dependency graphs as follows: A production instance p is stable if all the \noutput attribute instances of p are stable. An unstable production instance is deficient if it has any \ndeficient output attribute instances; it is excessive if there are any excessive output attri\u00adbute instances. \nNote that only output attributes determine the stability of a production instance, and it is possible \nfor a production instance to be deficient and excessive at the same time. We say p is consistent if all \noutput attribute instances of p are consistent. A semantic tree T is said to be stable if each of its \nproduction instances is stable, and con\u00adsistent if it does not contain an inconsistent pro\u00adduction instance. \nWe say that a node of a compound dependency graph is etable, deficient, excessive, or consistent according \nto whether the corresponding attribute instance in tbe semantic tree is stable. deficient, excessive, \nor consistent, respectively. Intuitively, a stable tree has as many avail\u00adable attribute values as possible. \nThis observation leads to the following theorem. ~ 1: If T is stable and complete, then T is fully attributed. \n=: Let T be stable and complete. Since T is complete, the roots of D correspond to attribute instances \nof T defined by nullary semantic functions and are therefore available. For each node n of D, let ma~depth(n) \nbe the length of a longest path from a root to n. Suppose T is not fully attri\u00adbuted, then there exists \nat least one unavailable node in D. Let c be an unavailable node of D with minimum max_depth. Since c \ncannot be a root, it has a predecessor node b. Because T is stable, b must also be unavailable. But max_depth(b) \n< max.-depth(c) contradicting our choice of c. Thus, D can have no unavailable nodes and T must be fully \nattributed. D We can now give an algorithm scheme for stabil\u00adizing a semantic tree T. For any attribute \ninstance b, define the operation update(b) to make b stable. by evaluating it if it is deficient or by \nnullifying it if it is excessive. Extend this definition to production instances by letting update(p) \napply update to each output attribute instance of p. The following algorithm generalizes EVALUATE by \ntreating attribute evaluation and attribute nullification uniformly. STABILIZE(T) : while T is not stable \ndo choose an unstable production instance p update(p) .od Like several previously published attribute \nevaluators ~1,0,3], STABILIZE achieves space effi\u00adciency by operating at the level of production instances \nrafiher than individual attribute instances. For time efficiency, it is tgreedy, w updating as many attributes \nas possible at each pro\u00adduction instance before moving to the next. We now make some observations about \nthe behavior of STABILIZE. Although the algorithm operatea on production instances, and the theorems \nare stated in terms of T, the proofs make use of D, as it is usually easier to reason about attribute \ngrammars in terms of the compound dependency graphs than tbe semantic trees. However, we emphasize that \nthe compound dependency graph is not a data struc\u00adture used in the algorithm; it is merely a concep\u00adtual \ndevice used in the proofs. ~ 2: STABILIZE(T) terminates. =: We prove termination by exhibiting a positive \nintegral function w(D) whose value is reduced by each iteration of STAEILIZE. Let each node n of D have \na label v(n), where v(n) = 1+ z v(m) (*) me{sons of n] The function w is defined as: w(D) = E v(n) ne{unstable \nnodes of D]  Each iteration of STABILIZE(T) updates an unstable production instance of T, so at least \none node of D is stabilized. When a node n of D is stabilized, all of its sons may be made unstable, \nbut the new value of w(D) is bounded by: [w(D)]new S [W(D)]Old -v(n) + 2 v(m) me{sons of n} Substituting \n(*) into the right-hand side, we have: [w(D)] < [w(D)]old -1 new Since each iteration of STABILIZE reduces \nthe value of w(D), STABILIZE(T) terminates after at most w(D) steps. II A correct and efficient implementation \nof STA-BILIZE requires the notion of uniformity, defined as follows. Tis~ if it does not contain both \ndeficient and excessive attribute instances; it is ~ if it is uniform and contains no deficient attribute \ninstances; it is UR&#38;xmlYti @ if it is uniform and contains no excessive attribute instances. As before, \nwe extend this 110 definition to compound dependency graphs in the obvious way. In each of the arguments \nbelow, let k be the maximum number of attributes of any symbol of G. WUDLI 1: Let n be a node of D. If \nn is excessive, updating n may cause some successors of n to become excessive, but affects no other nodes. \nSimilarly, if n is deficient, updating n may cause some succes\u00ad sors of n to become deficient, but affects \nno other nodes. l!r.@i: Immediate from the definitions of excessive and deficient attribute instances \nand the definition of update. D L@UWI 2.: If T is uniformly excessive (resp. defi\u00adcient) and T! is obtained \nby applying update(*) to any production instance of T, then T? ia uniformly excessive (reap. deficient). \nH: BY assumption. all unstable attribute instances of T are excessive (resp. deficient). By at most k \napplications of Lemma 1, no deficient (resp. excessive) attribute inetances are introduced when update(*) \nis applied to a production instance. D L@tuaii 1: If T is uniform and consistent, and T! is obtained \nby applying update(*) to any production instance of T, then Tt is uniform and consistent. =: Tt is uniform \nby Lemma 2. Applying update(*) to a production instance requires updating at most k attribute instances. \nBy Lemma 1, updating attribute instances preserves uniformity; thus, it is suffi\u00adcient to show that updating \neach attribute instance preeerves consistency. Let b be an attribute instance that ia updated. There \nare two cases to consider. ~ 1: b was excessive and is nullified. Clearly, nullification cannot introduce \nincon\u00adsistencies. ~ 2: b was deficient and is evaluated. It is sufficient to show that every attribute \ninstance dependent on b was unavailable and therefore remains consistent. Since b was ini\u00adtially a deficient \nattribute instance in a uni\u00adform tree, the tree contained no excessive attribute instances. Since b was \ninitially unavailable. every attribute instance dependent on b must also have been unavailable, as other\u00adwise \nit would have been excessive. Cl Xh@zxeM3: If T is initially uniform and consistent, then T is stable \nand consistent on termination of STABILI?2 E(T) . ~: Immediate from Theorem 2 and Lemma 3. !3 ~ 4: If \nT is uniform, then STABILIZE ter\u00adminates after 0( ITI) iterations. &#38;Q$&#38;: Using Lemmas 1 and 2S \nwe can eaaily show that each attribute instance is changed at most once dur\u00ading execution of STABILIZE(T). \nIn addition, STABIL-IZE changes at least one attribute instance on each iteration, so the number of iteration \nis 0( ID I). However, IDI =#of attribute instances of T<klTl Hence the number of iteration of STABILIZE(T) \nis 0( ITI). D Let T be a nonuniform semantic tree of the form: The uniformity restriction is necessary \nfor the linear time bound on STABILIZE, as the following example demonstratea. Let G be: x i Sa 1! s \nt a x i a(null) . . . S a(1) I ; a(mlll) 1 ; where parenthesized quantities represent attribute values. \nIf we always choose to update the unstable node of minimum height, the time required to stabil\u00ad ize T \nsatiafies: T(h) T(h-1) + h where h is the height of T. Thus, T(h) is qua\u00addratic. For each production \ninstance p, there is a con\u00adstant bound on the time required to test the stabil\u00adity of p, and a constant \nbound on the number of com\u00adputation steps and semantic function applications performed by update(p). \nThus, the running time of STABILIZE ia governed by the efficiency of the implementation of choose. A \nstraightforward way to perform the choose operation efficiently ia to maintain a set S of unstable production \ninstances waiting to be updated. 1: Stabilizing an attributed derivation tree T given an initial set \nS of unstable production instances. STABILIZE (S, T): while S is not empty do select and remove a production \ninstance p from S update(p) for each neighboring production instance p of pdo if not stable(p ) then \ninsert P? into S od od Set insertion and deletion can be done in unit time using standard techniques. \nThus, the worst case running time of this algorithm is linear in the size of the tree. As an incremental \nevaluator, it will usually be much better; the running time will be proporti~nal to the number of attribu[e \ninstances actually changed. 7.2. An algorithm for subtree replacement Recall that an editing session \nis a sequence of subtree replacements, where a subtree replacement consists of a pruning step followed \nby a grafting step. The goal of an incremental attribute evalua\u00ad tor is to produce a consistent, fully-attributed \ntree after each subtree replacement. In general, the result of grafting together two consistent trees \nwill not be consistent. However, if the two trees are stable as well as consistent, then the result of \ngrafting them together is guaranteed to be con\u00ad sistent (though not necessarily stable). The fol\u00ad lowing \nalgorithm is based on this observation. ~ ~: Subtree replacement. REPLACE(T, U, U!): (* replace subtree \nU of T by U *) (* where T and Ut are stable *) (* and consistent *) let n the root of U p . the production \ninstance that derived n in T q . the production instance derived  from the root of Ut in prune U from \nT STABILIZE({p}, T) graft U onto T at n STABILIZE({p,q}, T) end lhQZEUI 5: If T and U are stable consistent \ntrees, then execution of REPLACE(T, U, U!) leaves T stable and consistent. &#38;cuzL: Because T is initially \nconsistent, the result of pruning U from T is uniform and consistent. By Theorem 3, the first call to \nSTABILIZE leaves T stable and consistent. If we can show that the result of grafting U! onto T is consistent \nand uni\u00adformly deficient, the desired result will follow by a second application of Theorem 3. Let T! \nbe the result of grafting U? onto T. Because both T and U! are stable before the grafting step, the arguments \nof any available attribute instance of T or Ut are available in T or Ut, respectively. Thus the arguments \nof any available attribute instance of T! are available in Tt. T~ contains no excessive attribute instances, \nso it is uniformly deficient. Finally, since T and U! were consistent, Tt is consistent. D As an illustration \nof subtree replacement, Fig\u00adures 3 and 4 portray the effects of the two calls to STABILIZE on the sample \nsemantic tree of figure 2 when the declaration is deleted from the inner scope. When the declaration \nis deleted, its subtree is replaced by an instance of the completing produc\u00ad tion for <decl list>. A \nbox around an attribute in Figure 3 means that it was nullified during the first call to STABILIZE; a \nbox around an attribute in Figure 4 means that it was evaluated during the second call. One can see that \nstabilization is lim\u00ad ited to the inner scope in both calls, and that the rest of the attributes of the \ntree are unaffected. One does not usually wish to discard pruned subtrees. For example, a frequent restructuring \noperation in a tree editor is to move a subtree from one location to another. The implementation of this \nis straightforward: Let p be the production instance derived from n, the root of U. When U is pruned, \nwe make the inherited attributes at n una\u00advailable, and app lY STAB ILIZE({p]S U). Upon termination, \nTheorem 3 guarantees that U is stable and consistent, thus ready to inserted into the program tree by \nanother subtree replacement. Again, the total time spent is proportional to the number of attributes \nchanged. 7.3. Implementation of the two pass incre\u00admental ewaluator Not only is a two pass evaluator \nefficient in space usage, it has a simple implementation as well. The primary data structures are: a) \na semantic tree for the program under development, b) a stack for unstable production instances. and \nc) a aet of matricea that represent attribute dependencies in the semantic functions. In each production \np, we may number the input attributes 1 . . lIn(p)l, and the output attributes 1 . . Iout(p)i. Attribute \ndependencies of p are recorded in ADM , the ~ . TSlaiXiXof p, boc?lean dimensions ]Out(p)~ x ]In(p)l, \nin w~;~~l~ach row represents the dependence of an output attribute on the input attributes. An element \nof the matrix is defined by: true if input attribute j is an argument of ADMp(i,j) = output attribute \ni { 1 Ealse otherwise During stabilization, input and output attri\u00adbute availabilities in a production \ninstance r can be represented by two bit vectors, IAV and OAV , respectively, where trae means available \na~d false means unavailable. A vector POAV , that represents potential output attribute ava~labili\u00adties, \nis calculated by: PoAV := -t ( ADM * *IAV r P. r) where -I denotes bitwise complement, and * denotes \nBoolean matrix multiplication. The expres\u00adsion means that an output attribute instance is not potentially \navailable unless all of the input attri\u00adbute that it depends on are available. The predi\u00adcate for stability \ncan be expressed: stable(r) s (OAVr = POAVr) For tbe operation update(p), it is necessary to know the \nexcessive and deficient output attribute instances. A vector representing excessive output attribute \ninstances is calculated by: (OAV= A _IPOAVr) A vector representing deficient output attribute instances \nis calculated by: <pro ram> f <block> used . .H+ ;:=,.ed <decl list> orig up f i I I 1 [ <stint lisE> \nused i I \\ I / / / 1 I 1 I Ii Ii I <stint> se I / I/ //1 I /{I I J ( /II\\ <id decl> decl <ex stint> \nused begin <ex stint> used end ~ex stint> used d Semantic tree and compound dependency graph after pruning \nof <id decl> Eiul= ~: <program> i <bl~ck> used *+  -e -. ~ x <decl list> orig up <stint list> used \n/ / / I I I / I J I I <id decl> -4: Semantic tree and compound dependency graph after grafting 1 (-tOAVr \nA POAV,) The bit vectors IAV and OAV need not be stored in the tree. Onlyrattributervaluea need be stored, \nand IABK and OAVK reconstructed when neces\u00adsary. By accepting the runtime overhead of computing stability, \nconsiderable simplicity is achieved. For the work we plan to do, speed is not a particularly important \nconcern because the editing is done in a stand-alone microprocessor and can use computing power that \nwould otherwise be wasted. Most impor\u00ad tant for our application, the representation of the grammar is \nextremely compact --one dependency matrix per production of the grammar. This imple\u00admentation is similar \nto that of [16], and contrasts with the machines of [3], which may require encoding an exponential number \nof graphs. 7.4. Change propagation Rather than our two pass process of nullifica\u00adtion followed by reevaluation, \none might consider attempting to propagate changes of attribute values in a single pass. This approach \nis appealing because if a new attribute value is identical to the old one, the value need not be propagated \nany further. This often happens, because many program\u00adming language constructs merely transmit attributes \nwithout change. A similar approach is used for evaluation of circular attribute grammars in [16]. Change \npropagation can considerably reduce the cost of certain editing operations, such as when a pruned subtree \nis reinserted at a location where the attributes are identical. However, change propaga\u00adtion may require \nnonlinear time, and its performance is quite sensitive to the order in which nodes are chosen for evaluation. \nIn particular, a depth-first strategy can lead to exponential behavior, as the following example illustrates. \nLet G be: It is easy to see that the derivation trees of G have compound dependency graphs of the form: \n. . . Beginning with a change at the rightmost leaf, and using a depth-first search strategy that always \nvisits a node labeled a in preference to a node labeled c, the time required for the change to pro\u00adpagate \nthroughout the tree satisfies the recurrence relation: T(h) = 2T(h-1) + C where h is the height of the \nderivation tree. Thus , T(h) is exponential in the worst case. The ability to avoid unnecessary recomputations \nof attribute values, which is the principal advan\u00adtage of change propagation, can easily be incor\u00adporated \ninto the (asymptotically linear) two-pass algorithm. The nullification pass is altered so that old values \nare not discarded but merely marked. The definition of stability is altered to treat marked attribute \ninstances as unavailable. When a recomputed attribute value coincides with the origi\u00ad nal value, dependent \nattributes are not recomputed. Like Algorithm 2, the new algorithm converges to the consistent and fully \nattributed tree after a linear number of semantic function applications. Asymptot\u00ad ically it is no better \nthan Algorithm 2; however, it may be a useful optimization in practice. 7.5. Adapting the algoritiu to \nactual sys\u00adtems The subtree replacement algorithm given above is suitable for syntax-directed editors \nin which the unit editing operation is a single subtree replace\u00adment, such as EMILY [8] and MENTOR [4,5]. \nThe underlying idea of stabilization is also applicable to systems in which the unit editing operation \nis more complex. The PDEIL editor [14] allows one to insert or delete arbitrary sized pieces of text, \nand an incre\u00admental parser determines what parts of the progrmn tree need to be restructured [22]. Instead \nof a single subtree replacement, there are multiple sub\u00adtree replacements. In order to update the tree \nto be consistent and fully attributed, Algorithm 2 must he modified so that STABILIZE is passed all of \nthe unstable production instances instead of just the one or two involved in a single subtree replacement. \nIn the Cornell Program Synthesizer, if a modif\u00adication to a program would introduce non-local errors. \nthe user is first warned, and has the options of overriding the warning or aborting the modification. \nIf the latter is chosen, the tree must be put back in the original state. This requires either a multipass \nalgorithm for subtree replacement or a minor modification of change propa\u00ad gation. 8. Relation to previous \nwork All previous attribute evaluators we know of have been off-line algorithms for compilers, and may \nbe viewed as instances of the EVALUATE scheme of Section 4. Because STABILIZE is a generalization of \nEVALU-ATE, we can use it for off-line evaluation as well. We simply start with a tree in which all attribute \ninstances are unavailable. The corresponding com\u00ad pound dependency graph must have at least one node \nwith in-degree O; so somewhere there is a semantic rule of the form: a= constant expression As a consequence, \nthe tree is uniformly deficient, and can be attributed by calling STAB ILIZE(S, T) where S is the set \nof all deficient production instances. Clearly S can be computed in linear time (e.g. by depth-first \nsearch), ao by Theorems 3 and 4 the tree is consistent and fully attributed after O(IT[) steps. For noncircular \nattribute grammars, this algorithm is identical to the evaluator of [16], and similar to that of [61. \n A different approach is to build a determinis-References tic evaluator by analyzing the attribute dependen\u00adcies \nin the grammar E1o,3I. Taking advantage of ths fact that a production instance can become deficient only \nafter one of its neighbors is evaluated, a plan is compiled for each production. One form for a plan \nis a finite state machine where each state is labeled by a set of available attributes. The state transitions \nof the machine represent attribute evaluation commands and control transfers. During evaluation, each \nproduction instance in the tree of type p is tagged with the local state of the machine for production \np. A single machine is active, and it controls which attributes are evaluated, as well as how control \nia transferred to the machine of a neighboring production insta,nce. These constructions yield time efficient \nevaluators --linear in the size of the tree. However, they are not well suited for use in syntax-directed \nedi\u00adtors because they are geared for evaluation. and do not generalize easily to allow attribute nullifica\u00adtion. \nIt is known that off-line attribute evaluation can be done in time linear in the number of attri\u00adbute \ninstances by computing the compound dependency graph for the semantic tree, performing a topologi\u00ad cal \nsort, and evaluating attribute instances in the resulting order [13,111. Not surprisingly, this algorithm \ncan be extended to do incremental evalua\u00adtion. This approach haa great conceptual simpli\u00adcity, requires \nvery little analysis of the grammar, and is asymptotically linear in the number of attri\u00adbute instances \n affected. However, the overhead is great; in particular, the space required to etore the compound dependency \ngraph can be an order of magnitude greater than the space required by our method. 9. Smary and concluaiona \nWe are interested in building programming language editors that enforce the syntax of the language as \na program is developed. This ia a dif\u00adficult task becauae a modification to one part of a program may \nintroduce a semantic error in another part of the program; conversely, a modification may eliminate a \nsemantic error in another part of the program. To avoid placing an unreasonable burden on the user, the \neditor must detect such effects and inform the user, but must allow semantic errors to be introduced \ninto the program. at least tem\u00adporarily. , Non-context-free constraints in a language may be described \nin an applicative and modular fashion by attribute grammars. We have presented a tech\u00adnique that should \nmake it practical for syntax\u00addirected editors to use attribute dependencies to update a semantic tree \nincrementally and to find semantic errors. The algorithm is adaptive --the evaluator visits as many or \nas few nodes as neces\u00ad. sary. The incremental viewpoint, and consequent concern with reevaluating attributes. \nsets this work apart from other work on attribute grammars; the general scheme for semantic analysis \nsets the work apart from other work on syntax-directed editors. 1. Babich, W.A. and Jazayeri, M. The \nmethod of attributes for data flow analysis. part I: exhaustive analysis, part II: demand analysis. Acts \nInfonnatica 10, 3 (October 1978), 245-272. 2. Bochmann, G.V. Semantic evaluation from left to right. \nCACM 19, 2 (February 1976), 55-62. 3. Cohen, R. and Harry, E. Automatic generation of near-optimal linear-time \ntranslators for non-circular attribute grammars. Conference Record of the Sixth ACM Symposium on Principles \nof Programming Languages, January 1979, 121\u00ad 134.  4. Donzeau-Gouge, V., Huet. G., Kahn, G.. Lang B., \nand Levy, J.J. A structure-oriented program editor. Technical Report, IRIA-LA80RIA, France 1975. 5. \nDonzeau-Gouge, V., Huet, G., Kahn, G., and Lang B. Programming environment based on struc\u00adtured editors: \nthe MENTOR experience. Techni\u00adcal Report, INRIA, France, Msy 1980.  6. Fang, I. FOLDS, a declarative \nformal language definition system. Tech. Report No. STAN-CS\u00ad72-329s Computer Science Dept.. Stanford \nUniversity, December 1972. 7. Farrow, R.W. Attributed grammar models for data flow analysis. Ph.D. Thesis, \nRice Univer\u00adsity, Houston, Texas, May 1977. 8. Hansen, W. Creation of hierarchic text with a computer \ndisplay. Ph.D Thesis, Computer Sci\u00adence Dept., Stanford University, June 1971. 9. Jazayeri, M. On attribute \ngrammars and the semantic specification of programming languagea. Ph.D. Thesis, Comp. and Info. Sci. \nDept., Case Western Reserve University, 1974. 10. Kennedy, K. and Warren, S.K. Automatic genera\u00adtion \nof efficient evaluators for attribute grammars. Conference Record of the Third ACM Symposium on Principles \nof Programming Languages, January 1976, 32-49. 11. Kennedy. K. and Rsmanathan, J. A deterministic attribute \ngrammar evaluator based on dynamic sequencing. ACM Trans. on Prog. Lang. and Sya. 1, 1 (July 1979) 142-160. \n 12. Knuth, D.E. Semantics of context free languages. Math. Systems Theory J. 2, 2 (1968), 127-145. \n 13. Lewis, P.M., Rozenkranz, D.J., and Stearns, R.E. Attributed translations. J. of Comp. and Systems \nSciences 9. 3 (December 1974), 279-307.  14. Mikelsons, M. and Wegman. M.N. PDEIL: The PLIL program \ndevelopment environment principles of operation. Research report RG8513, IBM Watson Research Centez, \nYorktown Heights, November 1980. 15. Reps, T. The Synthesizer Editor Generator. In preparation. 16. \nSkedzeleski, S.K. Definition and use of attri\u00adbute reevaluation in attributed grammars. Technical Report \n340, Computer Sciences Depart\u00adment. University of Wisconsin-Madison. October 1978. 17. Teitelbaum, T. \nThe Cornell Program Syn\u00adthesizer: a microcomputer implementation of  PLi CS. Tech. Report No. TR79-370, \nDept. Com\u00adputer Science, Cornell University, June 1979. 18. Teitelbaum, T. The Cornell Program Syn\u00adthesizer: \na tutorial introduction. Tech. Report No. TR79-381, Dept. Computer Science, Cornell University, July \n1979, Revised June 1980. 19. Teitelbaum, T. and Reps. T. Tbe Cornell Pro\u00adgram Synthesizer: a syntax-directed \nprogramming environment. Tech. Report No. TR80-421, Dept. Computer Science, Cornell University, May 1980. \n 20. Warren, S.K. The efficient evaluation of attribute grammars. M.A. Thesis, Rice Univer\u00adsity, Houston, \nTexas, April 1975. 21. Warren, S.K. The coroutine model of attribute grammar evaluation. Ph.D. Thesis, \nRice Univer\u00adsity, Houston, Texas, April 1976. 22. Wegman, M.Ii. Parsing for structural editors. Conference \nRecord of the Twenty-first annual Symposium on Foundations of Computer Science, October 1980, 320-327. \n  \n\t\t\t", "proc_id": "567532", "abstract": "A syntax-directed editor is a tool for structured program development. Such an editor can enforce syntactic correctness incrementally by restricting editing operations to legitimate modifications of the program's context-free derivation tree. However, not all language features can be described by the context-free formalism. To build editors that enforce non-context-free correctness, a more powerful specification technique is needed. In this paper we discuss the advantages of attribute grammars as a specification technique for a syntax-directed editing system. We also present an efficient algorithm for incrementally evaluating attributes as a program tree is derived.", "authors": [{"name": "Alan Demers", "author_profile_id": "81100529925", "affiliation": "Cornell University, Ithaca, NY", "person_id": "P12363", "email_address": "", "orcid_id": ""}, {"name": "Thomas Reps", "author_profile_id": "81100117392", "affiliation": "Cornell University, Ithaca, NY", "person_id": "PP40023877", "email_address": "", "orcid_id": ""}, {"name": "Tim Teitelbaum", "author_profile_id": "81100391906", "affiliation": "Cornell University, Ithaca, NY", "person_id": "P282428", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567532.567544", "year": "1981", "article_id": "567544", "conference": "POPL", "title": "Incremental evaluation for attribute grammars with application to syntax-directed editors", "url": "http://dl.acm.org/citation.cfm?id=567544"}