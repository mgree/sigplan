{"article_publication_date": "01-26-1981", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1981 ACM 0-89791-029-X $5.00 arrays introduce new idioms into APL, and current idioms do not generalize \nnaturally to a recursive data structure. This paper presents an alternative to nested arrays, the carrie.c \nIn extending an aU4.Y. idiom-rich language such as APL, an important goal is conserving its idioms. We \ncall this the principle of idiomatic similitude . The development of the carrier array has been driven \nby an attempt to generalize existing APL idioms. For example, how can APL be extended to allow ((VIV)=IPV)/V \nto mean the removal of duplicate words from a word list? And what extensions would enable the idiom to \nremove duplicates from many vectors in parallel? The carrier array ia an abstraction which permits both \ngeneralizations; it is a ragged array with an associated partition which allows the programmer to view \nan array as a collection of word lists, and to apply functions to each list independently. Carrier arrays \nare designed to facilitate both the representation of non-scalar data and the parallel application of \nfunctions. An examination of many APL programs has shown carrier arrays preserve APL idioms and the economical \nAPL style while greatly increasing the power of the language. The limitations of current APL are discussed \nin the next section, and section 3 presents the nested array alternative. Carrier arrays and the accompanying \nchanges to the APL primitive functions are motivated and defined in sections 4 through 6. Section 7 discusses \nmechanisms for controlling the parallel application of functions, and section 8 examines the redefinition \nof the primitive functions in more detail. In section 9 we present the small number of changes in APL \nsyntax required by carrier arrays. Several examples of carrier APL programs are given in section 10, \nand we end the paper with a discussion of implementation issues. 2. Problems with APL As an informal \nintroduction to carrier arrays and the problems they address, we consider the idiom ((VtV)=tPV)/V in \nmore detail. As mentioned in the introduction, we would like to extend the idiom in two directions: to \noperate on non-scalar data and to remove duplicates from many vectors in parallel. In this section we \nexamine ,by means of annotated examples the limitations of current APL which make these extensions difficult. \n((V~V)=IpV)/V removes duplicates from a vector. VIV maps each element of V to the index of its first \noccurence in V. ~PV gives the index of each element of V. Comparing these two values, we can identify \nand remove all but the first occurence of each element of V. For example: v + !~Ac~~! (vIv) * 12I 426 \nlpv 123456 (Vlv)=lpv : 1 1 01 01 ((vlv) lPv)/v ++ ABCF 2.1. Non-scalar Data Conaider removing duplicate \nentries from a list of worda. We first represent the word list as a rectangular APL array; this is most \neasily done by padding the shorter words with blanks, and storing each word as a row of a matrix. (Note \nthis is not an adequate solution for storing a list of arbitrary text strings, for the padding character \nmust not occur in the string.) We now adapt the functions in our idiom to this new data structure. We \ncan use the inner product operator to derive the function A.= which tests for equality between vectors. \nHowever we cannot derive a variant of dyadic iota (I) which uses A.= as its teat for equality. Thus we \nmust discard our current idiom and develop a new combination of primitives to identify the first occurence \nof each row of the matrix. R+(I l@\\VA.=@V)/[l]V V* APL R+ ApL BASIC BASIC APL COBOL COBOL FORTRAN BASIC \nFORTRAN pv-f57 pR*47 2.2. Parallel Application We now consider removing duplicates from many vectors \nin parallel. We represent the vectors as rows of a matrix, padding the shorter vectors appropriately. \nTo apply our idiom to the matrix, the primitives functions in the idiom must extend .. row-wise , operating \non each row of the matrix independently. However, of the primitives functions used in the idiom, only \nthe scalar function !=! extends to a matrix row by row, testing equality between the elements of corresponding \nrows. The other functions extend to a matrix in various ways: Compression (/) and dyadic iota (I) apply \na vector left argument independently to each row of a matrix right argument. A matrix left argument is \nnot permitted. -Shape (p) is not a decomposable function; it gives the shape of the matrix, not of the \nrows which compose it. -Monadic iota (t) is only defined for scalars; it does not extend to vectors or \nmatrices. To extend our idiom to apply independently to the rows of a matrix, we must rewrite it with \na new collection of primitives. In the code below, the first line creates the mask MO which identifiea \nfor every row the firet occurence of each element in the row. The next three lines use this mask to select \nthe corresponding elements from V. 2 MO+l 2 24<\\1 2 L++/MO Ml+L..2lr/L R+(PMl)P(,Ml)\\ JfO)/,V V * ~ACBF \nFFAC ABBAC pV +36 Note this program can be extended to non-scalar data by making further changes to the \ncode: using the inner product A.= in line 1, and restructuring the ravel of V on line 4.  2.3. Analysis \nThe two extensions of th e remove-duplicates idiom demonstrate the three limitations of the language \nmentioned in the introduction: -Rectangular arrays are inadequate for representing ragged structures. \n-APL functions do not easily extend to non-scalar data. -APL functions cannot be independently applied \nto the rows of a matrix. Notice the laat two problems are partially a consequence of the first. Since \nnon-scalar data cannot be represented naturally, the primitive functions cannot easily manipulate it. \nSimilarly, many APL functions applied independently to the rows of a matrix would produce non-rectangular \nresults. For example, in his first published definition of APL [8], Iverson allowed a boolean matrix \nto compress another conformably shaped matrix; each row of the boolean matrix compressed a corresponding \nrow in the right argument. The compressed rows could have varying length, for there was no restriction \non the boolean matrix; they could not be stored as rows of a rectangular array. Therefore the result \nrows were catenated into one vector. This catenation, however, atops subsequent parallel function application, \nfor the row structure which guides the application is lost. This extended compression was eliminated \nin later definitions of the language; it is essentially incompatible with rectangular arrays. 3. Nested \nArrays The APL community has proposed two new functions for creating and manipulating nested arrays: \nenclose (<) and disclose (>) [3, 71. Enclose converts an array into a scalar, and disclose is the inverse \noperation which recovers the original array, i.e. ><A * A for all arrays A. A mapping operator ( ) called \n itemwise or each haa alao been proposed; it is similar to the MAPCAR function of LISP. If a function \nf is applied itemwise to an array A, each element of A is in turn selected and disclosed, the function \nf applied to the disclosed element, and the result of the application of f is enclosed and stored in \nthe result array. NO order for the selection of elements of A is specified. More formally, if R+F A \nthen R[i] + <F>A[i] for all valid indices i. Note that these additions to APL do not change the meaning \nof any current APL program operating on non-nested arrays. Thus the remove-duplicates idiom remains valid \nfor vectors of simple scalars. We will now examine how to extend the idiom using nested arrays.   3.1. \nNon-scalar Data To remove duplicates from a word list, we first create a vector V of enclosed character \nvectors. Each element of V represents a word in the word list. The definition of dyadic iota is extended \nto enclosed arrays by adopting a recursive definition of equality: two non-simple scalars are equal if \ntheir discloses have equal shape and equal elements in corresponding locations. The other primitives \nin our idiom are indifferent to the type of the elements of V. Thus using nested arrays, the idiom extends \nto non-scalar data with no changes. Ri-((vIv)=~pv)/v  iEiiiiGm iEiiiiiiiii 13AimllmRzRAu pv*7 pv*4 \n3.2. Parallel Application To apply our idiom to several vectors in parallel, we enclose each vector and \natore the resulting scalars in a new vector V. We then apply each function in the idiom itemwiae to V. \nR +((V IV) = I pv) / V v++ JJumBELm~   Ri-+ lAB.!wwlABGl pve4 Note this solution will also \nremove duplicates from multiple word lists in parallel. V must be constructed with two levels of nesting; \nitemwise will cause the functions to descend one level and operate on each word list independently. 3.3. \nAnalyais Nested arrays remedy the three limitations of APL outlined in the introduction. Ragged structures \nare represented as vectors of enclosed vectors; primitive functions are defined to manipulate enclosed \narraya; and itemwise provides a mechanism for parallel function application. In the extensions above, \nthe nested array serves two purposes. In the extension to non-scalar data, it is a data structure for \nrepresenting a collection of character atrings. In the extension to parallel application, it is (adapting \nIverson s terminology [3]) a frame -for the application of functions with itemwise. Note it is not used \nto create a recursive structure; the deepest nesting is the three level structure used in the combination \nof the two extensions. A three level structure is a natural one for parallel function application. The \nlowest level holds the data. the words. The middle level contains the structures being manipulated, the \nword lists. The top level provides the structure to pemit parallel application; it is an array of word \nlists. A more deeply nested structure is not often needed for parallel function application. The itemwise \noperator provides a uniform means of applying functions to several enclosed vectors in parallel. This \nallows the programmer to circumvent the ad hoc extension of APL primitives to higher rank arrays. Notice \nin our example that when the itemwiae operator ia used it is applied to every function in the idiom. \nIf the nested array was not such a radical change to the APL data structures, perhaps the itemwise operator \ncould be implicitly incorporated into the application of the primitives. 4. The Carrier Concept Carrier \narrays are modeled on the relationship between scalar functions and arrays of scalars in current APL. \nThe scalar functions are defined on scalars [4], and they extend componentwise to higher rank arrays. \nThis extension is natural since the elements of an APL array coincide with the domain and range of the \nbase definitions of the scalar functions. In carrier APL we extend this identity by viewing an array \nas a carrier of base arguments to a function, an array of subarrays. A function has ~ -if the snape \nof a function s argument(s) determines the shape of a functions result. For example, reversal has uniform \nshape; if A+@B, the shape of A is determined by the shape of B (and is in fact identical to it). Reshape \ndoes not have uniform shape; the value of the left argument to reshape determines the shape of the result. \nIverson has noted [3, 9, 101 that an array argument to a function of uniform shape can be viewed as a \nframe, or carrier, of subarrays, and the function can be .. applled Independently to each subarray. Since \nthe function has uniform ahape, the results will all fit in a rectangular array. For example, ravel can \nbe applied independently to the submatrices of A* 3 2 4P124 giving a rank two result R * 3 8pz24. In \nIversonts terminology, the first dimension of A is a one-dimensional frame holding three two-dimensional \n cells . To get R from A, we apply ravel to each cell, keeping the frame conetant. The problem with Iverson~s \napproach is that he introduces a special operator to indicate how the array should be partitioned into \nframes and cells. The current definitions of the APL primitives do not allow the partitioning to be implicit. \nConsider redefining the APL primitives so that they are defined as a mapping on a aet of arrays with \na characteristic rank (two sets for dyadic functions). This mapping is called the W of the function. \nFor example scalar plus is defined to add scalars (rank O arrays). Grade up ia defined to sort vectors \n(rank 1 arrays). Catenate is defined to join vectors. With a few exceptions, all the primitive functions \ncan be defined as mappings of scalars and vectors to scalars and vectors. The definition of each function \ncan be characterized by a rank vector. For a dyadic function, the vector has three components: the rank \nof the left argument, the rank of the right argument, and the rank of the result. For monadic functions \nonly two components are necessary: the rank of the left argument and the rank of the result. We call \nthis vector the w-of the function. Dyadic scalar functions have base rank O 0 O; gradeup 1 1; catenate \n1 1 1; etc. When a function is applied to an array, the array is partitioned into a frame, or ULIX&#38;.L, \nof b.af3&#38; ~. and the function is applied independently to each. The programmer need not indicate \na partition; it is determined by the base rank of the primitive functions. Conaider a dyadic function \nf with base rank a b c. It is applied to two arrays X and Y with ranks r and s respectively. For X and \nY to be conformable, there must exist a j20 such that: r=a+j s=b+j X and Y are partitioned into carriers \nof rank j and the function f is applied independently to corresponding subarrays of rank a and b respectively. \nThe results are accumulated in Z; Z will have rank c+j. We call the first j dimensions of X, Y, and Z \na ~. The j-carriers of X and Y must have the same ahape (except for scalar extension, see section 7.1), \nbut other conformability constraints are determined independently for each pair of base arguments. To \nmaintain independence between the parallel evaluations, we allow the results to vary in shape and in \ntype. Thus, when the carrier partitioning is removed, the basic data structure is a heterogeneous ragged \narray. For example, consider the generalized matrix compression R+B/M mentioned above (see section 2.3). \nB is a boolean matrix, and M ie an equal shaped matrix. Compression has base rank 1 1 1. Both B and M \nare partitioned into l-carriers of vector arguments. Corresponding vectors in B and M are paired, and \nthe compression performed independently on each. The results are stored in a l-carrier R. When the partitioning \nis removed, R is a ragged matrix. R+B/M B++l ()11 M+ BCD R + ACD 0110 EFGH FJ? 1000 IJKL I We illustrate \nthe carrier concept by extending the remove-duplicates idiom to apply to several vectors in parallel. \nSuppose the base definitions of the primitive functions in the idiom have the following characteristic \nranks: dyadic I 111 = 000 monadic I 01 / 111 monadic p 10  Then (( VIV)=IpV)/V removes duplicates independently \nfrom the rows of a matrix (or an arbitrary rank array) . Dyadic iota is defined on vectors; it is applied \nindependently to each vector in its argument. It produces vectors, which are assembled in a result array \nof the same rank. Shape is defined to give the length of a vector. Applied to a rank n array, itwill \nreturn a rank n-1 array of lengths. Monadic iota is defined on scalars; it is applied to each scalar \nits argument. It produces vectors; applied to a rank n array, it produces an array of rank n+l. M ABACBF \nFFAC ABBAC 1 2 1 426 1134 12215  pv* 645 lpv ++ 123456 1234 12345 (Vlv)=lpv -1 1 01 on 1o11 11001 \n((vlv)=lPv)/v * ABCF FAC ABC 5. Non-Scalar Data How can non-scalar data be represented without the introduction \nof a new data type (e.g., string, tree, or nested array)? Ragged arrays allow non-rectangular structures \nto be represented, but the primitive functions must still manipulate the structures piecemeal. What is \nneeded is a mechanism for indicating which of the last axes of an array represent one structure, and \nshould be treated aa a unit. Enclose serves this purpose in the nested array system. In carrier APL, \nwhen a function is applied, a Q _ is specified. The datum rank indicates the rank of the data structures \nrepresented in the array. If we apply function f with datum rank k to a rank n array x (i.e., f{k]X), \nthen X is treated as a rank n-k array with data elements of rank k. Most APL functions have natural generalizations \nto non-scalar data. The restructuring and selection functions are indifferent to the type of data they \nmanipulate. Equality and its related functions have obvious extensions of meaning. For example, we say \ntwo ragged structures are equal if they have the same shape and corresponding elements are equal. More \nformally A={k]B+ (A/,(pA)={k-l}pB) A A/(,A)={O},B where k equals the rank of A and B. Recall the shape \nof a ragged array of rank n is a rank n-1 ragged array of the lengths of each vector along the last axis. \nRavel (,) flattens any ragged array into a vector. Equality for datum rank O is defined as the current \nAPL equality between scalars; thus the recurrence has a well-defined base case. The extended definitions \nof the APL primitives will be discussed at length in section 8. Two matrices can be tested for equality \nin three different ways. We can compare them as matrices of scalars, as vectors of vectors, or as scalars \ncontaining matrices. For example: V1 + COBOL 172 % ALGOL COBOL COBOL V1={O}V2 -00011* 11111  V1={1}V2 \n-01 V1={2}V2 -0 We can extend the remove-duplicates idiom to word lists by adding the appropriate datum \nrank to the code. Dyadic iota, shape, and compression view their arguments as vectors of non-scalar data \n(only the right argument for compression). The other functions are applied with the default datum rank \nof o. ((vl{l}v) =lp{l)v)/{l}v V* APL BASIC APL COBOL BASIC FORTRAN pv++67 (Vl{l)v) + 121426 P{l}v ++ \n6 lP{l}v + 123456  (VI{lIV)=lP{lIV -1 1 0 1 0 1 ((VI{l]V)=tP{l}V)/{l}V + APL BASIC COBOL FORTRAN  6. \nCarrier Arrays Note that the code in the above example will remove duplicates from several word lists \nin parallel if each word list is represented as a matrix in a three-dimensional array. Each primitive \nfunction ia applied using its base definition, and the array V is partitioned into a three-level structure: \na frame of lists of words. A carrier ~isa ragged array with an associated three level partitioning; it \nis similar to the three-level nested array used to remove duplicates from multiple word lists (see sections \n3.2 and 3.3). Unlike nested arrays, the structure is dynamically imposed when a function is applied to \nan array, and removed when the application is completed. A carrier array exists only during a function \napplication; the basic APL data structure is a heterogeneous ragged array. The process is analogous to \nthe execution of machine code. No type is associated with a machine word; it is imposed on the word when \nit is fetched and an operation performed, and the type is forgotten when the word is stored. How do we \ncharacterize a ragged array? We define a uniform-deut h ~ to be a tree where all paths from root to leaf \nhave the same length; we call this length the depth, or rank, of the tree. A cOmDlet e ~ is a tree with \nuniform branching at each level. Note that an array i s a complete, uniform-depth tree. We define a ~~tobe \na uniform-depth tree. An empty subarray is represented by associating a rank with a leaf node in the \ntree, and including this rank in determining the length of the path from root to leaf. A carrier array \nmust be described within the context of a function application. Consider a monadic function f applied \nwith datum rank k to a rank n array A, i.e. f{k]A. Let f have base rank i j. When the function is applied, \nA is partitioned into a three-level carrier array. Each level in a carrier consists of a number of contiguous \ndimensions in the array; this number is the rank of the level. The lowest level is the d.al.!u l.exel; \nit cOntains the data structures manipulated by the function. When f is applied to A with a datum rank \nof k, the last k dimensions of A are implicitly enclosed and treated as a single datum. The middle level \nis the m ~; it consists of arguments to the base definition of the function being applied. The size of \nthe base level is i, determined by the base rank of the function f. The top level is the carrier m; it \nis a frame carrying the base arguments to the applied function. The size of the carrier level is m=n-(i+k), \nthe difference between the rank of the array A and the s urn of the base rank of the function and the \ndatam rank k. This difference cannot be negative (an exception is described in section 7.1); if it is \nzero we have a scalar carrier. A is an m-carrier for f with datum rank k.  For example, reversal is \napplied with datum rank 2 to a rank 5 array A: 0{2}A, where A has rectangular shape 2 3 4 5 6. A is partitioned \ninto a 2-carrier of base arguments; the 2-carrier has rectangular shape 2 3. Each base argument is partitioned \ninto a vector of matrices; the base level vectors have length 4, and the datum level matrices have rectangular \nshape 5 6. Each base level vector is reversed, and the results are assembled in a new carrier array. \nThe partitioning is then removed from both A and the new array; the net result is equivalent to the reversal \nof A on the third dimension in current APL (i.e. @[3]A). Any ragged array with rank large enough to permit \nthe partitioning described above is a valid carrier array for f with datum rank k. As noted in section \n4, for a dyadic function applied to two arrays (e.g. AgB), the j-carriera of A and B must have the same \n(not necessarily rectangular) shape, but all other conformability restrictions, for both monadic and \ndyadic functions, are determined independently during the application of the function to its base arguments \nin the array(s). The uniform rank of the primitive functions assures the results of each application \ncan be assembled in a new carrier array. So we see, by appropriately substituting values of the datum \nrank, the remove-duplicates idiom will remove duplicates independently from many vectors of rank-k objects. \n7. Application Forms The concept of an array as a carrier of function arguments and the definition of \nprimitive functions on arrays of characteristic rank permit a great freedom in the pairing of functions \nwith arguments. Much of the control flow of a program can be subsumed into operators which control the \ndistribution of functions throughout carrier arrays of arguments. Throughout the paper we have assumed \nfunctions were applied . componentwise . : a monadic function is applied independently to each base argument \nin a carrier array; a dyadic function is applied independently to base arguments in corresponding locations \nof two carriers. We call this componentwise application scalar Droduct. For monadic functions, scalar \nproduct is perhaps the only reasonable application form. For dyadic functions, however, other possibilities \nexist. As noted in section 4, arrays in current APL are carriera of arguments to scalar functions. This \npermits APL to offer a rich aet of operators to apply scalar functions to arrays. Along with the default \napplication form of scalar product, scalar functions can be applied using inner and outer product, reduction, \nand scan. In this section we examine how these application forms can he extended to carrier APL.  7.1. \nScalar Product A useful addition to the concept of componentwise ... aPpllcatlon 1s scalar extension. \nConsider a dyadic function f applied to two arrays A and B. Assume A ia partitioned into a j-carrier, \nand B into a O-carrier. The one baae argament in B is paired with each of the j base argaments in A, \nand the function is applied independently to each; the O-carrier is extended to conform with the j-carrier. \nTwo arrays are conformable under scalar product if each is partitioned into a j-carrier, or if one (or \nboth) is a O-carrier. For example, suppose we wanted to cross reference a list of variable namea with \nthe text of an APL function, reporting for each variable the lines it appears on. Assume the variable \nnames are all one character (as they too frequently are in APL programs). We can represent the variables \nin a vector V, and the function in a matrix F, one line per row. (We do not include the function header \nin F.) We then wish to apply the APL membership function between V and each row of F. This is simply \nVCF. Membership has base rank 1 1 1. F is partitioned into a l-carrier; V becomes a O-carrier which can \nbe applied with scalar extension. Each row of the result is a boolean mask indicating which variables \nare present in the corresponding row of the function, i.e., (VeF)[i;] ++ V~F[i;]. v +-+ ZSALYH F ++ \nA+(1 =s, )/ll+ps L+-l +A-O , 1 +A Y+(sz~ 1)/s H+L$ .2l[/Y Z+(PH)P(SH)\\Y VCF*O11OOO 001100 010010 rectangular \n000 1 1 1 shape: 56 1 000 1 1 What if V was a scalar in the above example (e.g. v++ !A~)? Membership \nrequires a vector left argument. A scalar V is implicitly promoted to a vector. It can then be partitioned \ninto a O-carrier, and the computation proceeds as described above. 7.2. Outer Product When a function \nis applied as an outer product to two ragged arrays, a full carteaian product of the base arguments in \nthe two carriers is formed, and the function is applied independently to each pair. We define outer product \nusing the concept of scalar extension. Consider the outer product form XO.f{k]Y, where f is being applied \nas an outer product with datum rank k to the two arrays X and Y. Let f have rank abc, and Xand Yhave \nranka m and n respectively. When f is applied, X is partitioned into an i-carrier, and Y a j-carrier, \nwhere i=m-(a+k) and j=n-(b+k). The i-carrier is the frame for the application. Each base argument in \nX is applied using scalar product to the entire j-carrier of Y (e.g., for every base argument b in X \nwe evaluate b f{k}Y), and the result ia stored in a corresponding location of a new i-carrier. For example, \nA-10203O B-l 4050 34 AOO+B +-+ 11 41 1314 4344 21 51 2324 5354 31 33 34 where the two planes of the result \nare displayed adjacently for convenience. Recall the cross-reference example discussed above. Suppose \nwe want to separately cross reference the formal parameters and the other variablea used in a function. \nV is now a matrix; the formals in the first row, the other variables in the second. We want to test each \nrow of V with every row of F. This is expressed V..EF. Membership has base rank 1 1 1, so both V and \nF are partitioned into l-carriers. The result is a 2-carrier containing vector base arguments; it is \nalso a rank 3 ragged array. v * ZSA F same as above LYH VO.CF++O 1 1 000 001 100 010 0 1 0 rectangular \n000 111 shape: 253 100 011 Assume we wanted to cross-reference two functions in parallel. Ignoring the \ndistinction between formal parameters and other variables, V is now a matrix, each row corresponding \nto the name-list for a function. F is rank 3 array, each submatrix representing a function. Note scalar \nextension is not applicable here; V is no longer a O-carrier. To perform the cross reference, we take \nan outer product, making all possible membership tests, and select the relevant results with a rank reducing \ntranspose: v i-+ ZSAI,YH XYZ ~ -A+(f l=S,l )/tl+PS L+-l +A-O , 1 +A Y+(s:! )/s H+LO.>1[/Y Z+(PH)P(,H)\\Y \n X+-2 3 ,!+p415 .2pf\\ 1 Y+O 1+8 9P21 z+((pY)xl+px)pl 3 2 4QX[Y;;I l12@/o.eF*O11000 001100 010010 000111 \nragged shape: 1 000 1 1 66666 333 100 010 111 The combination of outer product and transpose is very \npowerful, and it occurs frequently. Unfortunately, in most APL implementations it is a wasteful computation, \nfor the entire outer product is calculated before the transpose is performed. Abrams has noted [11 that \nthe transpose can be regarded as a further specification of the pairing of arguments requested by the \nouterproduct, and the superfluous pairs can be discarded before the function ia applied. Unfortunately, \nin the presence of side-effects, this merging of transpose and outer product is not equivalent to a sequential \ninterpretation of the two functions. The desirability of this optimization has been hotly debated the \nAPL community for years [1. 2. 2A.1~5]. In carrier APL we allow the programmer to determine how a transpose, \nouter product combination should be evaluated. If the transpose is to be a guide in the pairing of arguments \nto the outer product, the transpose vector can be included in the outer product form; e.g, we write VO.1 \n1 2cF. If a full evaluation of the outer product followed by the transposition is desired, we write 1 \n1 2@V0.6F. 7.3. Reduction Reduction is a mechanism for sequentially applying a function to pieces of \nan array [191. Reduction is defined for vectors of rank k datum (k~O), and is extended to higher rank \narrays -row-wise -. The simplest definition is recursive, as suggested by Jenkins and Michel [111. Let \nf be a dyadic function, and V a rank k+l array. We define (l+{k}v)f f/(l+{k]V if 2Sp{k}V f/{k}V ++ V \nif l=p{k}V identity or error if O=pV Since APL is right associative, this definition is equivalent to \nplacing f between every rank-k subarray in V (if 2Sp{k]V) followed by the evaluation of the resulting \nexpression. Note that k is @ the datum rank of f; it is a specification for a partition of V. A separate \ndatum rank for f can be specified as in f{m]/{k}V, and f{m] is substituted for f in the above definition. \nFor convenience, if no partition is indicated in the reduction form, V is partitioned into the base arguments \nof f. This default is well-defined only if the left and right base arguments of f have equal rank, i.e., \nthe base rank of f is of the form aab. For example, catenate reduction can effect a limited ravel. Catenate \nhas base rank 1 1 1. Let M be a character matrix, one word per row. ,/ catenates each word of M into \none vector. M+ THE APL IDIOM LIST ,/M.  ++ THEAPL IDIOM LIST If Misa rank 3 array, it is a 2-carrier \nfor catenate. Thus ,/M independently ravel. each submatrix of M. Note the definition of reduction places \nno constraints on f; any dyadic form can be used. In particular, an outer product form is valid. For \nexample, 0.,/{2}111N prints out the first N! numbers in the factorial number system. IIN forms .. a \nragged matrix. s ravels each datum in an array; since the datum rank is zero, each scalar is promoted \nto a vector. The outer product produces a cartesian product of the submatrices, e.g. : 113 -1 12 123 \n 0.,/{2};I13 * 1 0., 1 0., 1 22 3 -111 121 112 1 2 2 rectangular 113 123shape: 1233   7.4. Scan Scan \nis best defined in terms of reduction. Let f be a dyadic function and V a ragged array with rank k+l \n. If the reduction of f is defined on a vector V, then the scan of f is: f\\{k}V* f/{k}(~p{k]V)+{k}V \nRecall p{k}V gives the length of the l-carrier of V. Take has base rank O 1 1; thus , using scalar extension, \nthe l-carrier V is paired with each element of the index vector lo{k]V, and the appropriate prefix is \nselected. Reduction is applled to each row of the resulting ragged matrix. Scan extends to higher rank \narrays row-wise . As for reduction, the rank of the function is used as a default partition of V. For \nexample, ~IN creates a 1 column matrix containing the index vector, and scan is applied to combine the \nrows. .. ,13 ++ 1 2 -4+ ,\\ ;IN 1 12 123 Similarly ,\\~Npl creates a triangular form. ,\\ ;NP1 * 1 11 \n111  7.5. Inner Product Inner product is essentially a macro expanding into an appropriate combination \nof reduction, outer product, and transpose. We do not extend its definition here. 8. Primitive Functions \nIn this section we present the base definitions of the APL primitive functions, and discuss how they \ncan be extended to non-scalar data. A few APL functions have no natural fixed rank definition; they will \nbe defined separately as special forms.  8.1. Base Definitiona We define each primitive function by \nrestricting its current APL definition to arrays of specific rank. (Here we aasume a datum rank of zero.) \nThe base ranks of the primitive functions are: monadic dyadic scalars P O 0 10 , .. 111 001 .. , 00 4 \n011 11 / 111 $ 11 \\ 111 1 01 + 011 + 011 1 111 E 111 1 110 T 101 Note the restriction in rank changes \nthe effect of many functions when they are applied to higher rank arrays. For example, take (+) has base \nrank O 1 1, and 2 3tM, where M is a matrix with two rows, creates a ragged structure, selecting two elements \nfrom the first row and three from the second. We introduce distinct functions for catenate (,) and laminate \n(~). Catenate has base rank 1 1 1; it joins vectors into a longer vector. Laminate has base rank O 0 \n1; it makes a vector out of two scalars. A new ravel called raven (~) is introduced; it is defined below \nin the context of non-scalar data. 8.2. Extended Definitiona We now extend the base definitions of the \nprimitive functions to non-scalar data. All the primitive functions defined here are uniform with respect \nto datum rank; the datum rank of the argument(s) determines the datum rank of the result. For many :~;~~cturing \nfunctions (such as compression or only the right argument is permitted to carry non-scalar data; the \nleft argument is a boolean or numeric guide to the rearrangement of the data. For these functions, any \nexplicit datum rank supplied in an application form refers only to the right argument. Other functions \n(such as encode) are defined only for scalar data, and a datum rank other than zero in an application \nform is an error. In the table below we give the permissible datum ranks of the argument(s) of each primitive \nfunction, and the corresponding datum rank of the result. An n in the table represents any integer greater \nthan or equal to zero. monadic dyadic scalars n n nnn . . P nO nnra .. 9 nl i Onn nn /Onn : nn \\ Onn \n1 00 + Onn + Onn 1 nnO e nnLl 1 000 T 000 the arithmetic scalars, the relations, the restructuring functions, \nand the functions without obvious extens ions. We will examine each group in turn. 8.2.1. Arithmetic \nScalars The arithmetic scalars are applied to non-scalar data by leaf . For monadic functions there \nis no conformability constraints; the function is applied to each element of the ragged array comprising \nthe datum. For dyadic functions the two ragged arrays must have the same rank and ahape, else an error \noccurs. If conformable, the corresponding elements of the two arrays are paired, and the function applied. \n 8.2.2. Relations The relational scalars treat a non-scalar datum as single entity. Equality was defined \nin section ;. The definition builds recursively on the current APL scalar equality: two ragged arrays \nare equal if they have the same shape and equa 1 elements in corresponding locations. The other relational \n(<,S,>,2) are defined to determine a lexicographic order. For example, we define < to be: A<{k}B &#38; \nT1 V T2 where k is the rank of A and B T1 + 1+(+/A\\l l@A..={k-l]B)+l l@Ao.<{k-l]B T2 + ((p{k-l}A)<p{k-l]B) \nA A\\l l&#38;?AO.={k-l}B We use the current APL definition of < for scalar data (k=O); thus the recurrence \nhaa a well-defined base case. The definitions of dyadic iota and membership extend naturally to non-scalar \ndata given a generalized definition of equality. Similarly the above definition of < gives an extended \ndefinition of grade up (4) and grade down (?).  8.2.3. Restructuring Functions The restructuring functions \nrearrange the elements of an array; they are indifferent to the type of the elements. Thus they extend \nnaturally to non-scalar data. As mentioned above, many restructuring functions have a boolean or numeric \nleft argument which guides the rearrangement of the data; non-scalar data is not allowed in these guides. \nThe restructuring functions are reversal (@)s raven (~), catenate (,), laminate (~), expand (\\) , compress \n(/), take (+), drop (~), and rotate (q) . Shape (p), which gives the structure of a ragged array, will \nbe discussed in the context of the special form reshape. Raven (;) is unique among this group; it restructures \nthe data carried in the array. Raven has base rank O 0 and datum rank n 1; it flattens each datum in \nan array into a vector, selecting the elements in row-major order. In giving the extended definitions \nof the primitive Overtake and expand require a fill character. The functions, we split the functions \ninto four groups: fill character is a singleton with rank equal to the datum rank of the base array. \nIf all the leaves of the data in the base array are numeric, the base array is of type numeric, and the \nsingleton will contain a zero. Otherwise, the type is character or mixed, and the singleton will contain \na blank. For example, M % APL 1 1 0 l\\{l}M *APL BASIC BASIC COBOL COBOL ragged shape: 3 5 1 5  8.2.4. \nFunctions without Obvious Extensions Encode and decode have no obvious extensions to non-scalar data. \nWe are considering generalizing these functions through their relationship to array indexing. Monadic \niota would become the odometer function described by Abrams and others [1, 26], but the corresponding \nextensions to encode and decode are not as obvious. 8.3. Special Forms Special forms are used to define \nprimitive functions which cannot be independently distributed across a carrier of subarrays. These functions \ncannot be applied using the application forms described in section 7. The argument arrays are not partitioned \ninto carriers before the function is applied. The function definition determines how the array arguments \n) should be partitioned, and the function applied to subarrays. The functions defined as special forms \nare ravel (,), transpose (b), indexing, and reshape (P). We discuss each in turn. 8.3.1. Ravel Ravel \nis defined as in current APL; it flattens an arbitrary array into a vector. If a datum rank of k is given \n(e.g. ,{k}A), the result is a vector of rank k data.  8.3.2. Transpose Transpose is defined for a vector \nleft argument, and an arbitrary rank right argument. Consider Vb{k}A, where the length of V is i and \nthe rank of A is j. A is partitioned into an m-carrier of rank i subarrays, each containing rank k data, \nwhere m=j-(i+k) . V is applied to each rank i subarray independently, using the definition of transpose \nin current APL. The results are assembled in a new m-carrier. If i>j-k, an error is given. 8.3.3. Indexing \nIndexing is defined as in current APL. Consider AII;. ..;J]. A is partitioned into an array of rank 1 \nplus the number of semicolons in the form; the remaining dimensions, if any, are enclosed and treated \nas non-scalar data. Indices are computed from the index list as in current APL; if a non-existent element \nia indexed, an error occurs. 8.3.4. Reshape A ragged array introduces a new concept of shape into APL. \nThe shape (p) of a rank n ragged array is an array of rank n-l, each element containing the length of \nthe corresponding vector in the original array. We call this the additive shape, for tile number of \nelements in an array equals the sum of the elements in its shape. Rectangular arrays have traditionally \nhad a multiplicative shape. The multiplicative shape of a rank n rectangular array is a length n vector; \neach element of the vector giving the length of the corresponding dimension in the array. Thus the number \nof elements in an array is the product of the elements in its multiplicative shape. Note that the multiplicative \nshape of any non-empty rectangular array can be calculated from its additive shape: RectShape + p{k}A \nn k+l is the rank of A, k20 i=k-l to1 RectShape +-RectShape, [/,P{i}A for For any ragged array with \nno empty subarrays, the above code gives the shape of the smallest rectangular array which contains it. \nWe define reshape (p) in terms of additive shape. Consider Sp{k}A, where S is an additive shape, and \nA an arbitrary array of rank n. A is partitioned into a frame of rank k subarrays, and the frame is reshaped \nto have shape S. The elements of the frame are selected in row-major order, recycling to the beginning \nof the array if necessary. 2 3p16 * 12 345 23p{l)12 ++ 12 12 1212 12  9. A Word on Syntax Carrier APL \nrequires no significant additions to the APL syntax. Braces are included to indicate datum rank. A new \nfunction token (~) with monadic (raven) and dyadic (laminate) valence is introduced. Additional primitive \nfunctions may be applied with reductiOn. and a transpose vector may be included in an outer product form. \nNote that the axis operator of current APL is dropped. Datum rank captures its usage with reversal, catenate, \nlaminate, compress, expand, and rotate. An explicit transpose is necessary to replace its use with reduction \nand scan. 10. Some Examples 10.1. Key Word in Context The key-word-in-context problem described by Parnas \nhas often been used to portray programming techniques and style [20, 13, 22, 181. The problem is: Given \na list of book titles, produce a sorted list of titles keyed by each word in the title; a title appears \nonce for each word in it. Perlis gives an 18 line ApL solution [22], which is complicated by the need \nto manipulate non-scalar data (words and titles) using APL! S scalar primitives. The algorithm, however, \nis quite simple, and can be expressed naturally with the extended primitives of carrier APL. We give \na four line solution below. The book list is represented as a rank-3 ragged array. Each submatrix is \na title, and each row is a word. Line one ravels A into a vector of words, and stores in S the indices \nwhich will alphabetize this vector. Line two is a standard APL idiom; for each element i of S, it calculates \nthe index of the title containing the word associated with i. Line three calculates the offset of each \nword in its title; these offsets will be used to rotate each word to the front of its title. Line four \nsorts the titles and performs the rotation; the result is then ravened for output. S+i. {l], {l]A 1+1++/S0 \n. >+\\ N+P{l IA R+, l+~N KWIC+:{2}(R[SIO{1}A[I;; 1,{1}! 11),1 ~ A++ Structured The A Programming APL \nProgramming Idiom Language List Si+ 745962813 -f++ 322321312 R++ 012231100 KWIC * A Programming Language \nI APL Idiom List I The Idiom List I The APL Language I A Programming List I The APL Idiom Programming \nI Structured Programming Language I A Structured Programming I The APL Idiom List I  10.2. Tokenizing \nStrings The input data structure A in the above example can be easily constructed from a character vector \nof titles, each delimited by a carriage return or other special character. A common APL idiom (called \nMakearray in the APL Idiom List [221) breaks a character vector of strings separated by delimiters into \na matrix, one string per row. The idiom coded in carrier APL appears below. We assume there are no adjacent \ndelimiters in the input vector 1, and that I is terminated by a delimiter. Line 1 creates a mask M marking \nthe delimiters D in I, and line 2 stores their indices in L. Line 3 calculates the length of each string \nin I and stores the lengths in S; S is the additive shape of the desired result. In line 4 we construct \nthe result. reshaping the input vector with the delimiters removed. Mi-I.sD L,+-M/I PM S+-l+L-O,-l+L \nA+-Sp( -M)/A This program generalizes without changes to tokenize arrays of character vectors independently. \nTo produce the input array for the key-word-in-context program we apply the Makearray idiom twice. First, \nusing carriage return as the delimiter, we produce a matrix of titles from the input stream. We then \napply Makearray again, with blank as the delimiter, tokenizing each title in parallel. 10.3. Symbol Table \nUpdate Consider the symbol table update problem presented in theAPL Idiom List [22]. Two structures, \nA and B, comprise the symbol table. A is a list of symbols; B is an associated usage count list. X is \na new symbol to be added to the table. If X is in A, the appropriate element of B should be incremented. \nIf X is not in A, it should be appended to A, and a count of one appended to B. An elegant solution can \nbe written in APL if we assume each symbol can be represe nted as a single character. A and B are then \nvectors, and X is a scalar: A+-A,(&#38;X<A)/X B+-(B,M/O)+AEX This solution extends immediately to add \nseveral symbols to the table in parallel. X is now a vector of symbols; we assume it contains no duplicates. \nIn this example, the data structures A,B,X, and M are all vectors. Membership, catenate, and compression \nare all evaluated in the restricted domain of their base definition in carrier APL. Thus the evaluation \nof this program using the semantics of carrier APL is identical to its evaluation in current APL . However, \nby aPPrOprlately inserting datum rank, we can extend the program to non-scalar symbols. A+A,{l}(M+-X6{l}A)/{l)X \nB+(B,M/O)+AE{l]X All the functions in this program are applied using scalar product; thus this program \nwill update multiple symbol tables in parallel. Consider the evaluation of M/O in this parallel case. \nMiss ragged matrix, each row representing the additions to a symbol table. O is a scalar; during carrier \npartitioning it is promoted to a vector. The vector is a O-carrier, and it is applied to each row of \nM using scalar extension. In each application, the base definition of compression extends O to conform \nwith the row of M. This natural generalization of APL programs is the essence of idiomatic similitude. \n11 11. Implementation Issues AchQLd4~1 Much of a carrier APL implementation is identical Alan Perlis \nsuggested to me the problem of to an implementation of current APL. The tokenizer extending idioms to \nhigher rank arrays, and the and syntax analyzer are essentially unchanged. The notion of a carrier \narray is his. Carrier APL base definitions of the primitive functions are a has been developed under \nhis direction. Dana subset of current definitions. There are two Angluin and Steve Wood made helpful \ncriticisms of research areas in the implementation current ly earlier drafts of this paper. being investigated: \n1) new possibilities for streaming computation, and 2) efficient I would like to thank the organizers \nof the 1980 representation of carrier arrays. APL workshop in Minnowbrook for allowing me to present \na preliminary version of this paper. The carrier concept of parallel computation along the dimensions \nof an array allows a straightforward streaming of base argument evaluations. Consider the remove duplicates \nexample discussed above (see sections 4 and 5). When removing duplicates from the rows of a matrix, the \ninterpreter can process one row entirely before starting another, with significant savings in temporary \nstorage and loop REFERENCES overhead. Moreover, base argument streaming allows the more ambitious APL \noptimizations proposed by [11 Abrams, Philip S. An APL Machine. Abrams, Perlis, and others [1, 21, 6, \n12, 15] to be applied largely within base argument Technical Report SLAC-114 UC-32 (MISC), computations, \ne.g. removing duplicates from a Stanford Linear Accelerator Center, single row of a matrix. On this restricted \ndomain, February, 1970. these optimizations may prove more successful. [21 Abrams, Philip S. To represent \ncarrier arrays we need a ragged, What s Wrong with APL. heterogeneous data structure which is easily \nIn APL 75, pages 1-8. STAPL, June, 1975. partitioned into the three level carrier structure. The data \nstructure must permit fast access and easy [31 Bernecky, Bob and Kenneth E. Iverson. manipulation of \nthe base level of the partition, to Operators and Enclosed Arrays. which the functions are applied. We \ntentatively Presented at A Standard APL Workshop, choose to represent a carrier array as a nested Minnowbrook \nConference Center, September vector, i.e. a matrix is a vector of vectors, a 30 -October 3, 1980. rank-3 \narray is a vector of vectors of vectors, etc. The basic storage object is a homogeneous [41 Falkoff, \nA. D., and D.L. Orth. vector of one of three storage classes: character, Development of an APL Standard. \nnumber, or pointer. Each vector has a length and &#38;!?L_ Q@ 9(4-part 2):409-453, June, storage class \nassociated with it, along with other 1979. type information required for efficient execution of the primitives. \nPerhaps additional links in the [51 Ghandour, Ziad, and Jorge Mezei. nested structure will be required \nfor fast General Arrays, Operators and Functions. traversal of the tree. m&#38;k!u.mdti~a DeYAwwL 17(4):335-352, \nJuly, 1973. [61 Guibas, Leo J., and Douglas K. Wyatt. 12. Conclusion Compilation and Delayed Evaluation \nin APL. In NW Proceedings, pages 1-8. POPL , In our eyes, the major strength of APL is the January, 1978. \ndata-driven semantics of the primitive functions and operators, the replacement of explicit looping [71 \nGull, W. E., and M.A. Jenkins. with the parallel flow of function application Recursive Data Structures \nin APL. along the planes of an array. Carrier APL is a GA(2I 22(1):79-96, January, 1979. natural generalization \nof this data-driven control flow. The rank structure of the array, which [81 Iverson, Kenneth E. permits \nthe implicit iteration, is maintained, but ~~a.in, ~. the constraints of rectangularity and homogeneity \nJohn Wiley and Sons, Inc., New York, 1962. are removed. Primitive functions are redefined to make their \nparallel application more uniform. The [91 Iverson, Kenneth E. carrier array is not as general a data \nstructure as Q=.Lcu= ti Function~. a nested array. It does not yet have a Technical Report RC 7091, IBM \nThomas mathematical theory defining its semantics. (More J. Watson Research Center, 1978. has developed \na rich theory of nested arrays [16, 17].) But it introduces no radically new [101 Iverson, Kenneth E. \nconcepts that are difficult to integrate into the Operators. language. Carrier APL is an attempt to make \nAPL IQELA.S 1(2):162-176, October, 1979. better at what it is already good at; it is a conservative extension \nto APL. [111 Jenkins, M.A., and Jean Michel. Operators in an APL Containing Nested Arrays. APL QuQ&#38;Q$.@ \n9(2):8-20, December, 1978. 12 [121 Johnston, Ronald L. The Dynamic Incremental APL Ouote Q@ 9(4-Part \nCompiler 1):82-87, of APL\\3000, June, 1979, [131 Kernighan, Brian SQf&#38;?XQ m. Addison-Wesley. W. and \nP.J. Plauger. Reading,Massachusetts* 1976. [141 Mezei, J.E. Uses of General In tiln. ternationa~ pages \n334-348. Arrays and Operators. A.EL! w s QUl&#38;Ume* APL Userts, May, 1974. [151 Miller, Terrence. Tentative \nCompilation: Compiler. AILQ.LQ&#38;ti 9(4-Part A Design 1):88-95, for an June, APL 1979,, [161 More, \nTrenchard, Jr. Axioms and Theorems for l,BM~9-flLese arch 17(2):135-175, March. a Theory @ ~ 1973. of \nArrays. [171 More, Trenchard, Jr. The Nested Rectangular Data. lQQuQLQQasl 9(4-part Array as 1):55-735 \na Model June, of 1979. [181 Morris, James H., Eric Schmidt, Walder. Experience with an Applicative Processing \nLanguage. In ~~ &#38;-oce~di~&#38;, pages January, 1980. and String 32-46. Phi ip POPL, [191 Morrow, \nPrivate Alex. Communication, Oct. 1980. [201 Parnas, D.L. On the Criteria To Be Used in Decomposing Systems \ninto Modules. U 15(12):1053-1058, December, 1972. [211 Perlis, ~~k~~ Technical 1975. Alan J. Report 24, \nYale -Updated. University, March, [22] Perlis, Alan J., Xhf2AP.Lld&#38;211m. Technical Report 1977. and \nSpencer Rugaber. 87, Yale University, April, [23] Perlis, Alan Programming A$!.L@Q$&#38;Q!d 1979. J., \nand Spencer Rugaber. with Idioms in APL. 9(4-part 1):232-235, June, [24] Wiedmann, Clark. The APL Workshop \nSession of APL Systems. AIL Q.uQQ&#38;%d 8(2):15-17, on Standardization December, 1977. [25] Wiedmann, \nClark. APL Problems with Order AJ!L@Q&#38;m 8(3):25-29, of Execution. March, 1978. [26] Zaks, Rodney. \nAM.icronrOg.ra~ed Sybex, Berkeley, APL Ca., ~. 1978. 13   \n\t\t\t", "proc_id": "567532", "abstract": "The idiomatic APL programming style is limited by the constraints of a rectangular, homogeneous array as a data structure. Non-scalar data is difficult to represent and manipulate, and the non-scalar APL functions have no uniform extension to higher rank arrays. The carrier array is an extension to APL which addresses these limitations while preserving the economical APL style. A carrier array is a ragged array with an associated partition which allows functions to be applied to subarrays in parallel. The primitive functions are given base definitions on scalars and vectors, and they are extended to higher rank arrays by uniform application mechanisms. Carrier arrays also allow the last dimensions of an array to be treated as a single datum; the primitive functions are given extended definitions on scalars and vectors of this non-scalar data.This paper defines the carrier array and gives the accompanying changes to the definitions of the APL primitive functions. Examples of programming with carrier arrays are presented, and implementation issues are discussed.", "authors": [{"name": "P. Geoffrey Lowney", "author_profile_id": "81332513329", "affiliation": "Yale University, New Haven, Connecticut", "person_id": "PP43123348", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567532.567533", "year": "1981", "article_id": "567533", "conference": "POPL", "title": "Carrier arrays: an idiom-preserving extension to APL", "url": "http://dl.acm.org/citation.cfm?id=567533"}