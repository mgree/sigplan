{"article_publication_date": "01-26-1981", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1981 ACM 0-89791-029-X $5.00 way as their low-level, equivalents. The only necessary change is the addition \nof the machinery required to enforce the constraints on the con\u00adstructs use. By employing this strategy, \nwe have developed a computationally efficient abstract alternative to the most common disciplined use \nof impure operations in LISP: selectively updating (destruc\u00adtively modifying) unshared data objects. \nAlthough we will discuss the new construct in the limited context of manipulating LISP S-expressions, \nour ideas easily generalize to arbitrary recursive data structures as defined by Hoare [5] and McCarthy \n[6]. 2. The Critical Role of Impure Operations in LISP It is noteworthy that all practical dialects \nof LISP (such as LISP 1.6 and MACLISP) include a multitude of impure operations (e.g. rplaca, rplacd) \nwhich directly modify the pointer and record structures representing S-expressions. The semantics of \nthese operations cannot be described at the abstract level of S-expressions; they have meaning only at \nthe level of the underlying imple\u00admentation. Despite the logical complexity of impure operations, they \nare indispensable in many practi\u00adcal applications because they enable the program\u00admer to write much more \nefficient programa. As an illustration, consider the problem of maintaining a queue in Pure LISP. The \nstandard solution is to store the queue aa a linear list, inserting new elements at the end and removing \nelements from the front. The operations of inspecting and removing the first element require only constant \ntime. Inserting an element at the end of the list, how\u00ad ever, requires time proportional to the length \nof the list. By ueing more sophisticated data structures and algorithms, it ia possible to reduce the \nasymptotic time bound, but the result\u00ad ing programs are much more complicated.l k If we split the queue \ninto two separate lists so that both the head and the tail are accessible In constant time, we can reduce \nthe cost of n queue operations from 0(n2) to O(n). A single operation, however, can still require O(n) \nsteps. In particular, removing an element from the queue when the head list is empty involvea replacing \nthe On the other hand, if we allow impure (des\u00adtructive) operations, we can improve the efficien\u00adcy of \nthe simple linear list solution so that all operations take only constant time. The modifica\u00adtion is \nobvious: maintain a pointer to the last record of the list representation and use the pointer to destructively \nupdate the list (using rplacd) when inserting a new element. It is not only more efficient than the Pure \nLISP solutions, but it seems logically simpler as well. Neverthe\u00adless, it is difficult to prove that \nthe impure solution actually implements a queue. The Pure LISP solutione have simpler proofs because \nthey are expressed at a much higher level of abstrac\u00ad tion. In comparison to proofs involving abstract \ndata objects, pointer-and-record proofs are long and complex because a pointer variable can refer\u00adence \nany record in the associated record class. Hence, changing the contents of some field of a record potentially \nmodifies the dereferenced value of every pointer associated with the record class. In other words, a \ndereferenced pointer is a possi\u00adble alias for any other dereferenced pointer be\u00ad longing to the same \nclasa. In spite of their pathological semantics, im\u00adpure operations are commonly used in LISP to per\u00adform \nthe simple operation of updating variables with unshared values i.e. values represented by pointer-and-record \nstructures that are not part of the repreaentations of any other values. In this situation, a pointer \nserves as an abstract index, analogoua to an array index, identifying a partic\u00ad ular location within \nthe variable-s value. By US\u00ad ing impure operations, the LISP programmer can efficiently replace the structure \nat the specified location by a new structure, thereby modifying the value of the variable. In this limited \ncontext, low-level destructive operations have a simple abstract interpretation: they update a value \nat an head list by the reverse of the tail list a linear time operation. At the cost of adding several \nmore lists to the representation and further complicating the definition of the queue operations, we \ncan reduce the cost of every opera\u00adtion to constant time (producing a real time- im plementation[7 ]). \nThe trick is to distribute the work done in reversing the tail list over a number of operationa. abstract \nlocation within the value. In the The two functions are defined as follows: remainder of the paper, we \nwill develop an { return the value in at v } abatract, yet efficient alternative to using { the end \nof path <sl, . . ..sn> } generalized As the first pointers as indices. extract ( v : S-expr, <sl, . . \n. , Sn> : path ) step in this process, we must precisely define if n=O abstract locations and create \noperations for v, extract(car(v), <s , . . . , s >), if S1=CAR 2n manipulating them.  [(-tr-t(cdr(v),<s2, \n.. ..sn>). if S1=CDR 3. Paths as Abstract Locationa { A natural description for a location within a \n return the value of v with the value at the recursive data structure is a sequence of selector end of \n<s . . . ,Sn> replaced by new_part 1 names specifying the path from the root to the lo\u00ad } cation. We \ncall such a sequence a path. In ac\u00ad update ( v : S-expr, <sl, . . . , Sn> : path, cordance with typical \nnotation for sequences, we new part : S-expr )  denote the path consisting of the sequence of new part, \nif n=O selector names 1 s2  sn by sl 2 cona(update(car(v) , . . . ,Sn>. The empty path is denoted \nby <>. In the <s2, . ..$sn > , new part), special case of LISP S-expressions, the elements cdr(v)), \nIf S1=CAR of the path are taken from the two element set 1   {CAR, CDR}.2 For example, in the list \n(A B C) the cons(car(v), path <CDR, CAR> refers to the second element B, update(cdr(v), while the path \n<CDR> refers to the tail (B C). <s2 , .. ..sn >, Like array indices, paths can be used either new_part)), \nif S1=CDR \\ to extract values from composite values or to up- Note that update is a function; it does \nnot modify date them. The function the value v as a side effect. extract : S-expr X path ~ S-expr We \nnow define three functions for manipulat\u00ading paths: extend, last, and retract. They extracts values \nfrom within S-expressions and the correspond to the standard cons, car, and cdr function operations on \nlists except that they operate on update: S-exprx path XS-expr ~ S-expr the tail of a sequence rather \nthan the head. extend(<sl, . . . , Sn> : path, f : field-sel) replaces values within S-expressions. \nFor exam\u00ad= <sl, . . ..sn.f> ple, extract((A B C), <CDR, CAR>)=B last(+l, . . . ,Sn> : path) extract((A \nB C), <CDR>)=(B C) extract((A B C), <CDR, CDR>) =(C) =S n update((A B C), <CDR, CAR>, D)=(A D C) retract(<sl, \n. . . ,Sn> : path) update((A B C), <CDR>, (A))=(A A) update((A B C), <CDR, CDR, CDR>, (D))=(A B C D) \n(abbreviated t<sl, . . ..sn>) ~ sl  sn-l> For the sake of convenience, we also define a con\u00adcatenation \noperator * , which behaves much like the append function in LISP: The selector names CAR and CDR are \ncapitalized . . ..sn>*(tl. . . ..tm> <sl , to distinguish them from the selector functions car and cdr. \nIn other words, capitalization = sl  sn tl  tin> serves aa our quoting convention. The concatenation \noperator is recursively defin\u00adable in terms of extend, last, retract, and equal\u00ad ity; the definition \nis essentially identical to the usual recursive definition of LISP append. To support imperative programming \nwhere vari\u00ad ables and assignment are present, we introduce a path selection mechanism analogous to array \nselec\u00ad tion. Modeling our notation after array selection in ALGOL, we let VIPI specify the global location \n(within the entire program state) at the end of path p in variable v. Adopt ing the terminology of Kernighan \nand Ritchie [8], we will call global locatione 1\u00ad values. We also adopt the usual convention that l-values \nare implicitly dereferenced (coerced) in right-hand contexts (e.g. within an expression). As a result, \npath selections may freely appear in both left and right-hand contexts just like array selections. In \nother words, a path selection v[p] can be used within an expression to extract the value at location \np within v, or it can be used as the target (left-hand-side) of an assignment statement to update v at \nlocation p. For example, is equivalent to the simple assignment vl:=update(vl, pl, extract(v2, P2)). \n 4. Restrictions to Facilitate Efficient Xmplemen\u00adtatioll To implement paths efficiently, we must im \npose some restrictions on their use. In this sec\u00adtion, we describe the necessary restrictions and present \na table (Figure 1) summarizing the new no\u00adtation that we introduce. 4.1. Built-in Patha With any variable \nof type S-expression the programmer can associate a built-in path. All variables of type struct consist \nof a pair con\u00adtaining a value part and a path part. Specifical\u00adly, if v is a struct variable, then v.value \n is the S-expression associated with v, and v.path ia its path. By using the built-in path v.path, the \nprogrammer can efficiently access and update the corresponding S-expression variable v.value. To avoid \ncumbersome notation for l-values involv\u00ading built-in paths, we use the abbreviation vi in place of \nv.value[v.path] to denote the 1\u00advalue at the end of v.path within v.value, and vL*P in place of v.value[v.path* \np] to denote the l-value at the end of v.path*p within v.value. To accommodate fast accessing and updating \nof S-expreesions through built-in paths, we force every struct v to obey the following invariant: the \nbuilt-in path v.path must specify a valid lo\u00ad cation within v.value. We enforce the invariant by imposing \nthe following restrictions on updating atruct v. A speared node in v is any node ex cept the last one \n on the path described by 3 v.path within v.value. If v.path is empty, for example, then no node in v.value \nis speared. To preserve the invariant, we prohibit assignments to v.value that replace speared nodes. \nSimilarly, we __ prohibit assignments either to v.path or to the entire structure that would falsify \nthe invariant. Both restrictions are designed specifically to maintain the invariant. Assignments to \nv.value that replace speared nodes can falsify the invari\u00adant because they modify structure traversed \nby v.path. For example, if v.value=(A B C) and v.Path=CCDR, CDR, CDR>, (i.e. V1=NIL) then the assignment \nv.value[<CDR>] :=(A) would yield v.value=(A A), but v.path would be invalid because cdr(cdr(cdr(A A))) \ndoes not exist. The most straightforward solution to this problem is to ban the potentially offending \nassignments. We will discuss possible liberalizations of this policy in g6.2. With the addition of built-in \npaths, our im\u00adplementation includes three basic kinds of paths: (1) path constants sequences of selectors \nusing the angle-bracket notation as in <sl , . . ..sn >. Path constants can be given namea by declaring \nthem with a const attribute. 3 They are called speared because the path im\u00adpales them. The path goes \nto but not through the last one; hence it ia not sp~red. (2) built-in paths the path part (s. path) \nof a struct variable s. (3) general path variables variables whose t.path -\u00ad the built-in path of struct \nt values are sequences of selectors. t.value -\u00ad the value part of struct t In general, operations involving \nbuilt in VIPI -\u00ad the location in v at the end of paths can be performed much more efficiently than path \nexpression p the corresponding general path operations. For tl -\u00ad t.value[t.path], the location tunately, \nbuilt-in variables seem to suffice for in t at the end of its path most situations that arise in practice. \nMoreover, PI*P2 -- PI extended by p2 in many cases (such as the queue example) the path tl*p -\u00ad t.value[t.path* \np], the location is intuitively an integral part of the data struc\u00ad in t at the end of t.path*p ture, \nmaking the use of built-in paths particular\u00ad tP -\u00ad retract(p) ly appropriate. We believe that paths independent \nof particular S-expression variables should be Figure 1: Summary of Path Notation available in the programming \nlanguage, but the programmer must be warned that their implementa\u00ad tion is costly in comparison to built-in \npaths. 4.4. Two Examples In the next two sub-sections, we describe two important operations involving \nbuilt-in paths that To illustrate the use of built-in paths, in that have efficient implementations. \nFigure 2 we present a solution to the queue prob\u00ad lem discussed earlier. A queue q is a struct 4.2. Shrinking \nS-expression =,here q.value is a list of the queue Shrinking is an operation that replaces a elements, \nhead first. A path to the NIL value at struct variable by a substructure of itself. In the tail of q.value \nis kept in q.path. this operation, the path associated with the structure is truncated at the front so \nthat it {return the first element of q} refers to the same value within the structure function Qfront(q \n: strnct) after the operation as before. Operation shrink return car(q.value) is defined aa follows: \nend Qfront shrink(s : struct) = {delete the first element of q} s value := s.value[<sl>]; procedure Qdelete(var \nq : strnct) s.path := <s2, . . ..s> n shrink(q) end Qdelete where s.path has old value sl ....sn >. \n{addv to the tail of q} 4.3. Growing procedure Qinsert(var q : struct, v : S-expr) Growing is an operation \nthat replaces a ql:=cons(v, NIL); struct variable by a superstructure of itself. As q.path:=q.path *<CDR> \nwith shrink, the built-in path is modified so that end Qinsert it refers to the same value after the \ngrowing operation as before. Grow is defined as follows: Figure 2: A Solution to the Queue Problem grow(s \n: struct, f : field-sel, newval : S-expr) = s value := update(newval, <f>, s.value); s. path := <f>*s.path \nIn Figure 3 we implement three operations on a binary search tree: Search, Insert, and Delete. Note that \nthe value newval[<f>] has no effect on A binary tree node is a list the outcome of the operation; it \nis simply a (keyValue lefttree righttree), where any keyvalue placeholder that is filled by the old s.value. \nin lefttree is less than keyvalue, which in turn is less than any keyvalue in righttree. Assume 18 key, \nleftson, and rightson are path constants de\u00adclared as follows: const key = <CAR> const leftson = (CDR, \nCAR) const rightson = <CDR, CDR, CAR> A binary search tree T will be a stmct S-expression. If T.path \nis a path to some tree node, then T1 is a tree and Tl*key is the key\u00advalue of its root. Similarly, Tl*leftson \nand Tl*rightson are T1-s (possibly empty) subtrees. 5. Implementation We represent recursive data structures \nby standard pointer-and-,record list structures in\u00adcluding reference count fields for storage manage\u00adment. \nWith the exception of a single Boolean flag (the speared flag described below), no additional fields \nare required to support the implementation of paths. Since flag bits are usually available in the low \norder bits of record pointers, there is no space penalty beyond the space required for reference counts \n involved in supporting paths. In discussing the implementation of paths we will restrict our attention \nto the special case of built-in paths.4 An efficient implementation of paths must perform primitive path \noperations (with the exception of a few pathological cases) in time independent of path length. Otherwise, \nalgorithms expressed in terms of path operations will be asymptotically less efficient than the correspond\u00ading \nalgorithms employing impure pointer Opera\u00adtions. For example, if adding an element v to the end of a \nqueue q, q.!. :=cons(v, NIL), takes time proportional to the length of the built-in path, q.path, then \nthe queue implementa\u00ad tion presented in Figure 2 is no faster (asymptot\u00ad ically) than the most straightforward \nPure LISP implementation. On the other hand, if the assign\u00ad ment is performed in constant time, then \nthe path solution matches the asymptotic efficiency of the pointer solution. We assume that general \npaths are implemented in an obvious brute-force fashion so that as\u00adsignments and value extractions using \ngeneral paths require time proportional to the length of the path. { extend T.path down to the tree with \nkeyvalue v, if v is in T; otherwise extend it to the empty tree where v should be J procedure Search \n(var T: struct, v : S-expr) T.path:=<>; do .null(Tl) A v<(Tl*key) ~ T.path:=T.path * leftson o=null(Tl) \nA v>(Tl*key) ~ T.path:=T.path *rightson od {null(T~) V v=(T~*key)} end Search { add value v to tree T \n(if it is not already there) } procedure Insert (var T : struct, v : S-expr) Search(T, v); if null(Tl) \n~ Tl:=list(v,.NIL, NIL) Dotherwfse ~ skip {v is already inT} fi end Insert { remove v from T if v is \nin T otherwise error } procedure Delete (var T: struct, v : S-expr) local rtree : S-expr; Search(T, v); \nif null(T~) ~ error Dotherwise ~ {v is keyvalue of Tl} {save T1-s right subtree} rtree:=Tl*rightson; \n{replace T1 by its left subtree} Tl:=Tl*leftson; {add saved tree as the rightmost subtree of Tl} do =null(T~) \n~ T.path:=T.path *rightson od ; T~:=rtree fi end Delete Figure 3: Binary Search Tree Operations To perform \npath operations in constant time, we need a representation of paths that allows us to extract and update \nlist structures without traversing them. An obvious way to approach this problem is to represent a built-in \npath v.path as a pointer to v~. More precisely, since an update must change a field in the father of \nvL, a built\u00adin path representation must contain the pair [pointer to the father, field selecting the \naon]. For example, suppose v.value=(A (B C)) and v.path=<CDR, CAR, CDR> as illustrated in Figure 4. V.path \nis represented by the pair [pointer to node 3, CDR]. After the statement v1:=(D E), the CDR field of \nnode 3 is changed to point to (D E) (i.e. node 5). V.path remains unchanged. We call the last node speared \nby a built-in v the \\ 1 built-in m ~~ path v.path c NfL (a) before V1 := (DE) v 5 \\ 1 A2 3 NIL m B m \n* E NIL (b) after V1 := (D E) Figure 4: Implementation of v1:=(D E) path (node 3 in the example in Figure \n4), the tar\u00ad get node of the path. Since the address of the target node is stored in the path representation, \nwe say that a built-in path points to its target node. TO implement assignment efficiently and to \nutilize space effectively, it is imperative that the implementation avoid recopying list structure whenever \npossible. However, we must ensure that updating a variable sharing list structure with other variables \ndoes not modify the other variables. In order to avoid the side effects when updating at the end of a \nbuilt-in path, we must check that the speared nodes are not shared. Since we cannot explicitly check \nthe appropriate reference counts in constant time, we simply prohibit the sharing of speared nodes. All \npath operations must maintain this invariant. In par\u00ad ticular, extend must recopy the new target node \nif it is shared. As a result, we can safely imple\u00adment path updates by destructively modifying the target \nnode. Using this approach, an update operation usually takes only constant time. In the unlikely event \nthat the new components root is a speared node, the update operation must recopy all of the speared nodes \nof the new com\u00adponent. Each node has an . is speared bit so that it is manifest whether or not a node \nis speared. To implement the cons operation efficiently, we employ a reference counting scheme for storage \nmanagement instead of garbage collection. Although real-time garbage collection is feasi ble [9], reference \ncounting is a simpler, more elegant solution in the case of path operations. Since all destructive operations \non variables in\u00advolving paths have semantic definitions in terme of non-destructive operations (pure \nfunctions and simple assignment), it is impossible to form cir\u00ad cular list structures. Consequently, \na pure reference counting scheme can effectively manage storage without recourse to garbage collection. \nIn fact, reference counting seems ideal for this particular situation because some form of refer\u00adence \ncount information is necessary to implement paths efficiently. Without reference counts, we cannot tell \nwhether or not a particular piece of list structure is shared, precluding the implemen\u00adtation of update \nby destructively modifying the target node. In a conventional reference counting storage management \nsystem, freeing a node can force the reclamation of an unbounded number of nodes (all descendants of \nthe freed node that become inacces\u00ad sible after the node is freed). Hence, any opera\u00ad tion that frees \na node has unbounded running time. Fortunately, there is a simple modification to conventional reference \ncounting (suggested by Bak\u00ad er [9]) that evenly distributes the cost of storage reclamation over subsequent \nnode alloca\u00ad tions. The modified scheme, called lazy free-list . management, does not propagate the \ndecrementing of reference counts generated by freeing a node until the node is reallocated. Since the \nreference count of a speared node is 1, we can use the reference count field of speared nodes as a back \npointer. The back pointer supports the efficient implementation of the re\u00adtraction operation. 6. Removing \nRestrictions In g4 we placed three restrictions on the use of paths to facilitate efficient implementation: \n(1) Only one path can be associated with a struct variable. (2) Update operations cannot replace speared \nnodes. (3) To admit efficient implementation, path variables must be associated with a par\u00adticular struct \nvariable.  We now sketch how these restrictions can be re\u00ad laxed or eliminated by making minor changes \nto the implementation presented in Fj5. 6.1. Multiple Paths In some cases, it is advantageous to associ\u00adate \nmore than one path with a structure. A good example is the problem of swapping two disjoint substructures \nwithin a variable. The natural, ef ficient way to perform this task is to embed two built-in paths within \nthe variable. Fortunately, we can accommodate multiple built-in paths in\u00adcluding block-structured allocation \nand dealloca\u00ad tion by making only minor modifications to the Implementation. In order to maintain an \naccurate record of the speared status of nodes, we must keep a target count for each node, recording \nthe number of built-in paths pointing to that node. Without target count information, the retract function \ncannot determine whether the unspeared target node is still speared by other built-in paths. (The target \nnode remains speared if any of its children are speared or if any other built-in paths point to it.) \nSince target counts greater than 2 are un\u00ad likely to arise much in practice, a space\u00ad efficient implementation \ncould use 2 bits to record the count and handle overflows either by storing the information in a hash \ntable or by creating a dummy father node (accessible via the back pointer stored in the reference count \nfield) to hold the oversize count and a back-pointer to the real father node. The efficient implementation \nof the shrink and grow operations requires the use of phantom nodes in the event that the replaced node \nis a also a target node. The replaced target node be\u00adcomes a phantom node containing a pointer to the \ncorrect path-ending node. The first time a path pointing to a phantom is referenced, it is fixed up to \npoint to the proper target node. Phantom nodes eliminate the need to search all paths asso\u00adciated with \na structure to find the ones that need fixing up after a shrink or grow operation. 6.2. Updates at Speared \nNodes In g4, we outlawed updates that replace speared nodes because they could make a structure inconsistent \nwith the path (or paths if multiple built-in paths are allowed) embedded within it. If we want to remove \nthis restriction, we must formulate a policy on how to handle paths embedded within replaced structure. \nThere are three basic choices: (1) All such paths become undefined (in\u00advalid. ) (2) Each such path is \nembedded in the new structure, if possible. Otherwise it be\u00adcomes undefined. (3) Each such path is \nembedded in the result\u00ading structure on demand. Any attempt to dereference the path embeds it in the \nstructure. In the meantime, extensions and retractions are permitted.  We will show how to implement \nthe first alterna\u00adt ive. The other choices require more complicated (but not more enlightening) implementations. \n When an update operation attempts to replace a apeared node, all paths pointing to nodes in the replaced \nlist structure must be invalidated. Since the target nodes corresponding to invalid paths are much easier \nto find than the path variablea themselves, we indirectly invalidate the appropri\u00adate path variables \nby searching the replaced structure and marking all the target nodes as in\u00advalid . In the process, we \nfree all speared nodes that are not target nodes and lazily reclaim the unspeared nodes. In addition, \nif the location of the update is not the target of some built-in path, then the update must unspear any \nspeared nodes that are no longer on a valid path. Whenev\u00ader a path variable pointing at an invalid node \nis either deallocated or assigned a valid value, we decrement the node s target count. When an in\u00advalid \nnode-s target count reaches zero, the node is returned to the free-list. Updates at speared nodes are \nclearly less efficient than updates at unspeared nodes; instead of constant time, they take time proportional \nto the number of speared nodes that are either unspeared or freed by the update. 6.3. Unbound Paths In \nthe context of compiling programs with paths, we suspect that it is often possible to np\u00adtimize the implementation \nof a general path vari\u00adable by embedding its representation in one or more value variables (just like \na built-in path). Moreover, a compiler should be able to optimize the implementation of built-in paths \nin contexts where some operationa (such as retract) are not needed. Global optimization of path programa \nis one of our chief research interests. 7. Reasoning About Path Operations Since patha are ordinary sequences \nand path operations (other than assignment) are pure func\u00adtions without side effects, it is straightforward \nto develop a simple first-order axiomatization including a structural induction schema for a data domain \nconsisting of paths and recursive data structures. A previous paper [10] describes how to generate such \nan axiomatization. Within this for\u00admal system, we can treat recursive function defin\u00aditions (as in Pure \nLISP) over the data domain as logical definitions extending the system [11]. Using this approach, we \ncan prove theorems about paths and recursive data structures by using natural structural induction arguments \nlike those in the Boyer-Moore LISP theorem prover [12], and the Stanford Typed Lisp verifier [13] [14]. \nIn Appendix I we illustrate the approach by proving three sample theorems. 8. Reasoning About Procedural \nPrograms Involving Paths To reaaon about imperative programs (programa involving assignment) using patha, \nit is suffi\u00ad cient to apply Hoare style proof rules [15] or Dijkstra s predicate transformers [16] to \nreduce the correctness of an asserted program to the truth of a collection of sentences in the first \norder system described in the previous section. The only extension required ia the development of proof \nrules or predicate transformers to handle explicit and implicit (e.g. shrink) path-indexed assignment \nstatements. To solve the problem, we simply treat path-indexed assignments like indexed assignments to \nordinary arrays [17] [18]. The predicate transformer substitutes an entire updat\u00ad ed value for the aggregate \nvariable on the left hand side. Of course, the exact form of the predicate transformer for path-indexed \nassignments depends on the particular restrictions placed on paths by the language implementation. We \nwill restrict our attention to general and built-in paths in the context of S-expressions where each \nstruct variable is limited to a single built-in path. Let valid: patha X S-expreasiona ~ Boolean be a \nrecursively defined function where valid(p, v) is true if and only if p is a valid path in v. Then, explicit \npath assignments to ordinary vari\u00ad ables obey the predicate transformer: WP( V[P] :=E , R(V)) =valid(p, \nv) A R(update(v, p,E)) . Path-indexed assignment to struct variables are slightly more complicated because \nthey must maintain an invariant. In this case the predicate transformer must include an additional precondi\u00ad \n 9. ConcluaiOntion that asserts that the invariant holds: Paths are abstract data objects that wp( v.value[p] \n:=E , R(v)) correspond to the disciplined use of pointers in = valid(p, v) A updating recursive data \nstructures, just as while reinitial segment(p, v.path) A R(struct~update(v.value, p, E), v.path)).  \nloops correspond to the disciplined use of go to-s in performing indefinite iteration. Although mostInitial \nsegment : path X path ~ Boolean is a paths are implemented with pointers, their seman\u00ad recursively defined \nBoolean function that is true tics are defined in terms of simple abstractif and only the first path \nis a proper initial operations on recursive data structure. We be segment of the second one. Hence, initial \nsegment lieve they constitute a positive step toward the(p, v.eath) iS t~e if and only if the root node \nof development of efficient very-high-level program\u00adv.value[p] is speared. ming languages. Implicit path-indexed \nassignments performed by the shrink and grow procedures are treated in References the same way as their \nekplicit counterparts. Each [1] Naur, P., Ed. Revised Report on the Algo\u00ad procedure is equivalent to \na simple assignment rithmic Language ALGOL 60. Comm. ACM 6, 1  statement. The call (Jan. 1963), 1-17. \n[2] Jensen, K. and Wirth, X. PASCAL: User Manual shrink(s) and Report. Springer Verl-w =, 1974.  where \ns is a strwct variable is semantically [3] McCarthy, J., et al. LISP 1.5 Programmer-a . Manual. MIT P~s~ \nCambridge, Mass., 19657identical to the assignment: [4] Kennedy, K. and Schwartz, J. An Introduction \ns:= struct(s.value[head(e.path) ], tail(s.path)) to the Set Theoretical Language SETL. Comp. and Maths. \nwith Appls. 1, 1, 97-119. where head and tail are car and cdr operations for [5] Hoare, C.A.R. Recursive \nData Structures. CS paths, and struct is a constructor that forms a Report Stan-CS-73-400, Stanford U., \n1973. structure object from a path and a value. Simi\u00ad[6] McCarthy, J. A Baeis for a Mathematical larly, \nTheory of Computation, in Computer Program\u00adming and Formal Systems, P. Brafford and D. . Hirschberg Eds. \nNorth-Holland, Amsterdam,  grow(s, f, t) 1963, pp. 33-70. where e is a struct, t is an S-expression, \nand f [7] Hood, R. and Melville, R. Real Time Queue Operations in PURE LISP. CS Report TR80-433, is \na field-selector, is equivalent to: Cornell U., 1980. s:= struct(update(t, f, s.value), <f>*e.path) . \n[8] Kernighan, B. and Ritchie, D. The C Program\u00ad ming Language. Prentice-Hall, ~l~wood cliffs, 1978. \nHence the predicate transformers for shrink and 9] Baker, H. List Processing in Real Time on a grow \nare: Serial Computer. Comm. ACM 21, 4 (April 1978), 280-~ wp(shrink(s), R(s))= 10] Cartwright, R. A \nConstructive Alternative to s.path#<> A Axiomatic Data Type Definitions. LISP R(struct(s.value[head(s.path) \n], Conference Proceedings, August 1980. tail(s.path))) 1111. . Cartwrixht R. and McCarthv. ., J. First \nOrderwp(grow(s, f,t), R(s))= Program~ing Logic. POPL Conference Proceed\u00ad matom(t) A ings, January 1979. \n R(struct(update(t, f, s.value),<f>*s.path) ) [12] Boyer, R. and Moore, J. Proving Theorems To demonstrate \nhow easy it is to reason about about LISP Functions. J. ACM 22, 1, 122-144.  paths, we prove in Appendix \nII that the path solu\u00ad [13] Cartwright, R. User-Defined Data Types as tion to the queue problem is equivalent \nto the Aid to Verifying LISP Programs, in Automata, Languages, and Programming, S. Michelson andinefficient \nPure LISP solution. R. Milner, ~. Edinburgh Press, Edinburgh. 23 [14] Cartwright, R. A Practical Formal \nSemantic Definition and V~rification System for Typed LISP. AI M= 77-296, Stanford U., 1976. [15] Hoare, \nC.A.R. An Axiomatic Approach to Com\u00adputer Programming. Comm. ACM 12, 10 (Oct. 1969), 332-329. [16] Dijkstra, \nE. A Discipline of Programming. Prentice-Hall, New York, 19%. [17] Cartwright, R. and Oppen, D. Unrestricted \nProcedure Calls in Hoare s Logic. POPL Conference Proceedings, Jan. 1978. [18] Gries, D. and Levin, G. \nAssignment and Pro\u00adcedure Call Proof Rules. To appear in Trans. on Prog. Lang. and Sys. Appendix I Proof \nof Sample Theorems about Paths Let front, is queue, delete, and insert be speci fied by the following \nlogical definitions: (a) front(z:list) ~ car(z) (b) is_queue(q:struct) = q.value:list points to end(q.value, \nq.path) . (c) points_to_end(z:list, p:psth) = if null(z) then p=<> else (p+<>) /l first(p) =CDR A \npoints_to_end(cdr(z) ,rest(p)) (d) delete(z:list) ~ cdr(z) (e) insert(z:list, v:S-expr) ~ if null(z) \nthen cons(v, NIL) else cons(car(z),inaert(cdr(z) ,v))  where first and rest are the usual sequence opera\u00ad \ntions defined by: first(<sl, . . . ,sn>) = S1 rest(<sl, . . ..sn>) = (s2, . ..sn> We will prove: (1) \nVz:list, p:path z+() A is_queue(struct(z, p)) ~ is queue(struct(z[first(p)], rest(p))) ~z[first(p)] \n=delete(z) (2) Vz:list, p:path,v:S-expr is queue(struct(z, p)) * ~s_queue(struct(update(z, p, cons(v, \nNIL)), P*<CDR> ) ) (3) vz:list, p:path, v:S-expr is_queue(struct(z, p)) ~  update(z, p, cons(v, NIL)) \n=insert(z, v) Proof of (l). The proof is a simple symbolic evaluation argument. Let z:list, p:path. Applying \nsymbolic evaluation to tbe hypothesis yields: z+() A is_queue(struct(z, p)) ~z+() A z:list A points_to_end(z, \np) ~z#() ~ p#<> A first(p) =CDR A points_to_end(cdr(z), rest(p)) . In this context, applying symbolic \nevaluation to the conclusion produces: is_queue(struct(z[<first(p)>] , rest(p))) A z[<first(p)>] =delete(z) \ne is_queue(struct(cdr(z), rest(p) )) A cdr(z)=cdr(z) * cdr(z):list A pointa_to_end(cdr(z) ,rest(p)) \n * true Q.E.D. Proof of (2). The proof proceeds by induction on z. Base case: z = (). Let p:path, v:S-expr. \nApplying symbolic evaluation to the hypothesis yields: is_queue(struct(z,p)) ~ ():list A points_to_end(z, \np) 63 p=<> Hence, applying symbolic evaluation to the conclusion produces: is_queue(struct(update(z, \np, cons(v, NIL)), p*<cDR>)) ~ is_queue(struct(cona(v, NIL) ,<CDR>)) * cons(v, NIL):list A points_to_end(cons \n(V, NIL),<CDR>) H true ~ <CDR>+<> A first(<CDR>)=CDR A points_to_end ((),<>) ~ true  24 Induction step: \nInstantiating the induction hypothesis with Let z:list. P =rest(p), V =v yields: Given the induction \nhypothesis: is_queue(struct(z, rest(p)))+ Vp :peth, v-:S-expr is_queue(struct(update(z, rest(p), is_queue(struct(z, \np-)) ~ cons(v, NIL)), is_queue(struct(update(z, p-, rest(p) *<CDR>)) cons(v-, NIL)), which (by symbolic \nevaluation) reduces to: P *<CDR>)), is_queue(struct(update(z, rest(p), we must show: (ii) cons(v, NIL) \n), Vu:S-expr, p:psth, v:S-expr { rest(p)*<CDR>) ) is queue(struct(cons(u, z),p)) + is_queue(struct(update(cons(u, \nz),p, Lemma: Vpl, p2:path cons(v, NIL)) , p1+<>+rest(p1*p2) =rest(p1)*p2 p*<CDR>)) . Let u:S-expr, p:path, \nv:S-expr. Proof of Lemma: The proof is a very easy induc- Applying symbolic evaluation to the tion on \nthe structure of PI. The details hypothesis gives: sre left to the reader. Q.E.D. cons(u, z):list /l \npoints to end(cons(u, z),p) By the lemma, the induction hypothesis (ii) e reduces to: is_queue(struct(cons(u, \nz),p)) update(z, rest(p), cons(v, NIL)):list A e points_to_end(update(z ,rest(p), p#<> A first(p) =CDR \nA cons(v, NIL)), points_to_end(z, rest(p)) . reat(p)*<CDR>) Similarly, applying symbolic evaluation to \nproving the conclusion (i). the conclusion yields: Q.E.D. update(cons(u, z), p,cons(v, NIL)):list A points_to_end(update(cons(u, \nz),p, Proof of (3). cons(v, NIL)), The proof proceeds by induction on the p*<cDR>) structure of the list \nz. Base case: z = (). cons(u, update(z, rest(p), Let p:path, v:S-expr. cons(v, NIL))):list A As in the \npreceding proof, symbolically p*<CDR>#<> A first(p) =CDR A evaluating the hypothesis yields: points_to_end(update( \nz, rest(p), is_queue(struct(l, p)) cons(v, NIL)), * rest(p*<CDR>)) p=<> e As a result, symbolically evaluating \nthe update(z, rest(p), cons(v, NTL)):list A conclusion gives: (i) points_to_end(update(z ,rest(p), update(z, \np,cons(v, NIL)) cons(v, NIL)), =insert(z, v) { rest(p) *<CDR>) . * cons(v, NIL) =insert(NIL, v) * true \n Induction step: Let z:list. Given: Vp-:path, v :S-expr is_queue(struct(z ,p-)) ~ update(z, p , cons(v, \nNIL) =insert(z, v ), we must show: Vu:S-expr, p:path ,v:S-expr is_queue(struct(cons(u, z),p)) + update(cons(u, \nz), p, cons(v, NIL)) =insert(cons(u, z),v) . Let u:.s-expr, p:path, v:S-expr . As in the preceding proof, \nthe hypothesis reduces to p#<> A first(p) =CDR A points to end(z, rest(p)) . . Applying symbolic evaluation \nto the conclusion produces: cons(u,update(z, rest(p), cons(v, NIL))) =cons(u,insert(z, v)) * update(z, \np, cons(v, NIL)) =insert(z, v) Instantiating the induction hypothesis with p-=rest(p) and V =V yields \n(after symbolic evaluation) update(z, rest(p), cons(v, NIL)) =fnsert(z, v) proving the theorem. Q.E.D. \nAppendix 11 Proof of Correctness of Queue Implementation The queue implementation annotated with formal \nspecifications appears below: function Qfront(q : struct) pre: true post: result = front(q.value) return \ncar(q.value) eud Qfront procedure Qdelete(var q : struct) logical z:list, p:path pre: is_queue(q) A \n q.value+() A q=struct(z, p) post: is_queue(q) A q= struct(delete(z) ,rest(p)) shrink(q) end Qdelete \nprocedure Qinsert(var q : struct, v : S-expr) logical z:list, p:path pre: is_queue(q) A q=struct(z,p) \npost: is_queue(q) A q=struct(insert(z ,v), P*<CDR>) ql:=cons(v, NIL); q.path:=q.path *<CDR> end Qinaert \n The specification primitives front, is queue, and insert, and delete are defined in Appendix I. To prove \nthe correctness of the implementa\u00ad tion we must prove the verification condition pre+wp(body,post) for \nQfront, Qdelete, and Qinsert operation. Hence we must prove: (1) vq:stnlct true =+  wp( return car(q.value) \n, result = front(q.value)) . (2) kfq:struct, z:llst, p:path q.value+() A is_queue(q) A q=struct(z, p) \n~ wp( shrink(q) ,  is_queue(q) A q= struct(delete(z), rest(p))) .  (3) Vq:struct, v:S-expr, z:liat, \np:path is_queue(q) A q=struct(z,p)~ wp( ql:=cons(v, NIL);  q.path:=q.path* <CDR> , is queue(q) A q= \nstruct(inaert(z, v), p*<CDR>) ) . Proof of verification condition (l). Since we( return car(q.value) \n, result = front(q.value)) + car(q.value) = front(q.value), formula (1) reduces to: Tjq:struct car(q.value) \n=front(q.value) which is a trivial consequence of definition (a) of Appendix 1. Q.E.D. Proof of verification \ncondition (2). Proof of verification condition (3). Since wp( shrink(q) , is_queue(q) A Since wp( q~:=cons(v, \nNIL); q=struct(delete(z), rest(p)) q.path:=q.path *<CDR> , e is_queue(q) A q= struct(insert(z, v), is_queue(struct(q.value[first(q.path) \n], p*<CDR>) ) rest(q.path))) A e struct(q.value[first(q.path) ], is_queue(struct(update(q.valua,q.path, \nrest(q. path)) cons(v,NIL)), = struct(delete(z), rest(p)) (ii) q.path*<CDR>)) A e struct(update(q.value,q.path,cons(v,NIL)), \nis_queue(struct(q.value[first(q.path) ], q.path*<CDR>) rest(q.path))) A { = struct(insert(z, v), P*<CDR>), \n(i) q.value[first(q.path)] = delete(z) A formula (3) reduces to: { rest(q.path) = rest(p), Vq:struct, \nv:S-expr, z:list, p:peth formula (2) raduces to: is_queue(q) A q=struct(z,p)+ (ii). ffq:struct, z:list, \np:path Applying the second hypothesis yields: q.value+() A is_queue(q) A Vv:STr, z:liat, p:peth q=struct(z, \np) + (i) . is_queue(struct(z,p)) =+ Applying the third hypothesis yields: ie_queue(atruct(update(z,,p,cons(v,NIL)), \nYz:list, p:path p*<CDR>)) A is_queue(struct( z,p)) A z+()+ update(z,p,cons(v,NIL)) = insert(z,v) is_queue(atruct(z[first(p) \n], which ie the conjunction of theorems (2) and (3) rest(p))) A of Appendix I. z[firet(p)] = delete(z) \nA Q.E.D. rest(p) = rest(p) e $fz:list, p:path is_qaeue(atruct(z,p)) A z+()+ ls_queue(struct<z[firat(p) \n], rest(p))) A zlfirst(p)] = delete(z) which is theorem 1 of Appendix I. Q.E.D.   \n\t\t\t", "proc_id": "567532", "abstract": "This paper introduces the path, a new programming language construct designed to supplant the use of pointers to access and destructively update recursive data structures. In contrast to the complex semantics and proof rules for pointers, the semantics and proof rules for paths are simple and abstract. In fact, they are easily formalized within a first-order theory of recursive data objects analogous to first-order number theory. We present a number of sample programs, including implementations of queues and binary trees, utilizing the new construct and prove that they are correct.", "authors": [{"name": "Robert Cartwright", "author_profile_id": "81406592800", "affiliation": "Rice University", "person_id": "PP43116956", "email_address": "", "orcid_id": ""}, {"name": "Robert Hood", "author_profile_id": "81332504708", "affiliation": "Cornell University", "person_id": "PP43124528", "email_address": "", "orcid_id": ""}, {"name": "Philip Matthews", "author_profile_id": "81100545683", "affiliation": "University of Toronto", "person_id": "PP14189682", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567532.567534", "year": "1981", "article_id": "567534", "conference": "POPL", "title": "Paths: an abstract alternative to pointers", "url": "http://dl.acm.org/citation.cfm?id=567534"}