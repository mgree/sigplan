{"article_publication_date": "01-26-1981", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1981 ACM 0-89791-029-X $5.00 conventional programming languages (e.g. PASCAL , C, PL/1, FORTRAN). The \ndata objects and operations supported by conventional languages are too machine oriented to describe \ncomputations simply and abstractly. As a result, conventional language specifications are often more \ndifficult to read and to understand than the programs they purport to document. In these cases, the practi \ncal value of program verification is dubious; it merely establishes that the programs satisfy incomprehensible \nspecifications, not that they are intuitively correct. In this paper, we develop a practical alter\u00adnative \nto program verification - called formal program testing --with similar, but less ambi tious goals. Like \na program verification system, a formal testing system takes a program annotated with formal specifications \n(invariant assertions) as input, generates the corresponding verification conditions, and passes them \nthrough a simplifier. A fast simplifier incorporating sophisticated, computationally efficient decision \nprocedures such as the Stanford PASCAL Simplifier [Nelson and Oppen 79] will reduce many verification \nconditions to true. After the simplification step, formal testing systems and formal verification systems \nfollow divergent pathe. Instead of trying to prove the remaining verification conditions, a formal testing \nsystem simply tests each one by evaluating it on a representative set of data valuea. If no errors are \ndetected, the tested verification conditions are accepted as true statements. Formal testing provides \nstrong evi dence that a program is correct, but does not guarantee it. The strength of the evidence depends \non the adequacy of the test data; we will discuss this issue in depth in Section 6. 2. Specification \nLanguages for Program Testing Since formal program testing ie applicable only to formally annotated programs, \nits viability as a practical tool depends on the development of concise, readable specification languages. \nIn addition, formal program testing imposes a special constraint on program specifications: all of the \noperations appearing in program assertions must be computable. Otherwise, it is not possible to evaluate \nthe program verification conditions on test data values. As a result of this constraint, specification \nmethods that rely on the axiomatic definition of abstract operations are not applica\u00ad ble to formal \nprogram testing. As a solution to the specification problem, we advocate using a separate very high level, \napplicative programming language --including a constructive abstract data type definition facil\u00adity -as \nthe specification language. The presence of a data type definition facility is critical because it allows \nprogram specifications to be written at a high level of abstraction --omitting irrelevant, machine-oriented \ndetails. To accommo\u00ad date formal testing, abstract data type defini\u00ad . tions must provide an effective \ndefinition~ for every primitive operation. Axiomatic data type definitions such as algebraic specifications \n[Gut\u00adtag and Horning 78; Goguen 77] do not satisfy this criterion because they fail to provide algorithms \n(either implicitly or explicitly) for evaluating the primitive operations. In particular, it is impossible \nto compute whether or not two data objects (ground terms) from an axiomatically defined data domain are \nequal; the problem is undecidable. To support this approach to program specifi\u00ad cation, we have designed \na very-high-level pro\u00ad gramming language called TTL, based on the the TYPED LISP language described in \n[Cartwright 76]. In comparison with its predecessor, TTL includes a much richer constructive data type \ndefinition facility and a more comprehensive collection of built-in types. In addition to abstract data \ntypes , all of the machine oriented data types in conventional procedural programming languagea such \naa PASCAL, FORTRAN, and ADA are easily defined in TTL . A description of the salient feature of the constructive \ndata type definition facility used in TTL appears in [Cartwright 80]. As a programming language, TTL \nresembles Pure LISP generalized to a rich, extensible data 2 If an operation is partial (undefined for \nsome inputs), the effective definition may diverge on arguments that lie outside of the domain of the \noperation. For example, an effective definition of integer division must either diverge or return an \nerror object when given an argument list of the form (X,o). domain. As in Pure LISP, new operations \n(other than primitive operations implicitly defined by data type definitions) are introduced by recursive \ndefinitions. Since all of the primitive opera\u00adtions in TTL are continuous, recursive definitions in TTL \nare always well-defined. The meaning of a recursively defined function is the least fixed point of the \ncorresponding functional. The semantics of TTL have a natural formali\u00adzation within conventional first \norder predicate logic. A TTL program composed of type defini\u00adtions and recursive definitions of operations \ngen crates a corresponding first order theory includ\u00ading axioms for all of the defined operations. The \ndomain and functions of the generated theory are simply the data domain snd the defined operations of \nthe TTL program. Each recursive type defini\u00adtion in the program generates a collection of axioms analogous \nto Peano-s (first-order) axioms for the natural numbers. Similarly, each recursive definition of a TTL \noperation generates a corresponding recursion equation. This approach to formalizing the semantics of \napplicative pro\u00adgramming languages ia described in more depth in [Cartwright and McCarthy 79], and [Cartwright \n80]. In contrast to conventional specification languages, TTL enables the programmer to describe the \nprogram clearly and concisely. In fact, we believe that formally documenting programs in TTL is worthwhile \neven when a formal program testing system is not available. the behavior a program and its subparts in \nformal, yet concise, 3. Specification aa Formal Documentation A specification language like TTL constitutes \na formal system for documenting programs. As [Liskov and Berzins 79] have argued, formal specifications \nare superior to informal ones in several respects. First, formal documentation enables the programmer \nto describe program behavior in mathematically precise terms. Every symbol appearing in a program has \na well-defined mathematical interpretation. Expressing program documentation in appropriate formal notation \nforces the programmer to clarify his explanations. When someone tries to read formally documented code, \nhe can determine exactly what each program component is supposed to do by reading the annota\u00adtion. In \ncontrast, informal specifications writ\u00adten in English or other natural language are inherently imprecise \nand ambiguous. A good illus\u00adtration of this phenomenon is the widely ack\u00adnowledged inadequacy of informal \ndefinitions of programming language semantics. A second advantage of formal documentation is that it \nforces the programmer to use standardized notation; the documentation must obey formal syn\u00adtactic rules. \nA programming language parser can check that program documentation is well-formed, just as it checks \nthat program text is syntacti\u00adcally correct. As a result, many clerical errora in program documentation \nthat would otherwise go undetected will be found and corrected. The advantages of formal documentation, \nhow\u00adever, are academic if program specification are difficult to write and to understand. Unless we develop \nand promote concise, very high level specification languages, the potential benefits of formal program \ndocumentation will go unrealized. 4. A Comparison with Conventional Testing Methods Conventional program \ntesting attempta to establish the reliability of software by the fol\u00adlowing principle of inductive inference: \nif the program works for a representative set of teat inputs, then it should work in nearly all other \ncases. The programmer is responsible for select\u00ading the test data and inspecting the output for each \ntest caae to verify that it is correct. Aa a tool for validating software, conventional testing is saddled \nwith several significant liabilities. First, in the abaence of formal specifications, it is often impossible \nto tell whether a particular program output is correct. For example, how does one determine whether the \noutput of a compiler is correct? Without a formal definition of the source and target languagea (e.g. \nan abstract interpreter for each written a formal specifica\u00adtion language), the whole question of correctness \nia moot. In some cases it may be feaaible for the programmer to write a test program that verifies that \neach test output ia correct . In this caae, the test program indirectly serves as a formal program specification. \nUnfortunately, this form of implicit specification does not constitute a concise, readable description \nof program behavior. A second problem with conventional program testing is selecting a reprentative set \nof test inputs. Recently, [Budd, DeMillo, Lipton, and Say\u00adward 80] have developed an ingenious method \n-\u00adcalled mutation analysis --for evaluating the adequacy of test data. To evaluate the quality of his \ntest data, the programmer feeds his program and test data sets to a mutation analyzer, which generates \na large collection of mutant programs and runs them on all of the test data sets. Each mutant program \nis identical to the original except that it contains a minor syntactic change mimick\u00ading a program error. \nThe mutant analyzer exhaus\u00adtively checks each mutant program on the test data sets until it produces \nan output that distin\u00adguishes it from the original program. Of course, some mutants may be semantically \nindistinguishable from the original program. The programmer must manually verify that every indistinguishable \nmutant is equivalent to the original program. If not, then the test data are inadequate and the programmer \nmust devise test cases to distinguish the mutant from the original. The philosophical motivation for \nmutation analysis is that the ori\u00adginal program is correct except for a few minor clerical errors. Budd, \net. al. report excellent results in detecting program errors when using conventional testing augmented \nby mutation analysis. The pri\u00admary drawback to mutation analysis is that it requires large expenditures \nof programmer and machine resources. The mutant analyzer must run a very large collection of mutant programs \non the test data and the programmer must check that mutants duplicating the original program-s behavior \nare in fact semantically equivalent to the original program. A final disadvantage of conventional program \ntesting is that it attacks program correctness on a global rather than a local basis. A small change \nin a single program subroutine necessitates retesting the entire program. An individual sub routine cannot \nbe rigorously tested in isolation of the subroutines that it calls (directly or indirectly). Moreover, \nsmaller program building blocks such as loop bodies usually cannot be tested as independent units because \ntheir input and output states are too complex for the program\u00ad mer to check reliably. With the exception \nof generating representa\u00ad tive test data, formal testing overcomes the pit\u00adfalls of conventional testing. \nSince it relies on constructive formal specifications, there is no question whether a particular test \noutput is 3 correct. Furthermore, since verification condi\u00ad tions correspond to distinct linear paths \nin a program, formal testing is inherently local. Changing one statement in a program only requires retesting \nthe verification condition for the path containing the etatement --assuming that the specifications for \nthe path remain unchanged. Furthermore, when formal testing detects an error, it is easy to locate because \nit must occur within the path producing the erroneous test. 5. Generating Test Data Automatically choosing \na representative set of test data is a difficult problem that warrants further study. In many respects, \nautomatic test data generation resembles automatic theorem prov\u00ad ing. For each program path S with pre-assertion \nP, the test data generator must find sets of bind\u00ad ings for the free variables of P and S that satisfy \nP. Nevertheless, we believe that automat\u00ad ically generating test data for a program segment is a more \ntractable problem than automatically proving the corresponding verification condition. Programmers certainly \nfind it much easier to gen\u00ad erate test data than to prove programs correct. Furthermore, unlike program \nverifiers, test case generators do not have to attain a very high level of competence before they are \nuseful in practice. When a test generator fails, the programmer can simply revert to generating the data \non his own -\u00ad a task he must perform anyway if an automatic sys\u00ad tem in not available. 3 Unless the \noutput assertion involves an embed\u00added, unbounded quantifier. In this case, the for\u00admal testing system \nmust resort to testing the out\u00adput assertion on a representative set of values for the quantified variable. \nIn practice, embed\u00added, unbounded quantifiers are rarely necessary. One possible approach to generation \ntest data for a verification condition ie to symbolically evaluate the condition deferring the binding \nof every variable until the last possible moment. At each predicate forcing a variable binding, the generator \nmakea a non-deterministic choice for the binding from a small aet of heuristically gen\u00ad > crated values \nbased on the particular predicate. If the variable belongs to inductively defined type T, then the base \ncases and first level con\u00ad structions of T are obvious choices for members of the set. The generation \nof teat cases proceeds by backtracking until all possible non-deterministic choices have been tried (given \nthe generator sets a small bound on the maximum recursion depth allowed in evaluating recursively defined \npredi\u00ad cates and functions in the specification language). For verification conditions involving repeated \noccurrences of complex expressions, it may help to generalize the verification condition (as in the Boyer-Moore \ntheorem prover [Boyer and Moore 75]) before generating teat values and then invert the substitutions \n(if possible) to produce test values for the original formula. In fact, much of the analysis that Boyer \nand Moore perform to determine their stategy in proving a formula could be profitably applied to the \nautomatic gen\u00ad eration of test cases. For example, the induction variable chosen by their analysis probably \nwar\u00ad rants a proportionally larger number of test values than the other variablee appearing in a verification \ncondition. Another obvious heuristic for generating test values is to uae the output test values from \neach path as test inputs to sub\u00ad sequent paths. A sophisticated formal testing system should do more \nthan generate test data for the program and check that every test caae satisfiea the corresponding verification \ncondition. Tt must also show that the generated data ia sufficiently diverse to establish that the program \nis almost certainly correct. In the next section, we ahow how to adapt the concept of mutation analysis \nto formal program testing. 6. Hutation Analysia in the Context of Formal Program Testing To evaluate \nthe adequacy of test data gen\u00aderated for a particular verification condition, we simply apply mutation \nanalysis to the correspond\u00ading program fragment. Specifically, we apply mutant operators to the program \nfragment S produc\u00ad ing a set of program fragments which are identical to S except for minor clerical \nerrors. We accept a aet of test data as adequate for path S if for each mutant S\u00ad that is not semantically \nequivalent 4 to s, it includes an input value that falsifies the verification condition for S . We believe \nthat mutant analysis in the con\u00adtext of formal testing has several potential advantages over the original \nscheme proposed by [Budd et. al. 80]. First, since the analysis is local rather than global, the cost \nof testing mutants is much lower; only a ehort program frag\u00adment containing the mutation is executed \nrather than the entire program. Second, conventional testing in conjunction with mutant analyais will \nnot necessarily detect a systematic error (such as a consistent off-by-one mistake) since no muta\u00ad \ntion corrects more than a single occurrence of the error. None of error-correcting mutants will necessarily \nbehave correctly on a larger class of inputs than the original program. On the other hand, in formal \ntesting each program path corresponding to a verification condition is independently teeted. If some \npath contains only a single occurrence of the systematic error, then 5 mutant analysis will almost surely \ndiscover it. Finally, the presence of program annotation improves the prospects for automatic detection \nof equivalent mutants. Determining whether or not a mutant is equivalent to the original program (or \nfragment) is one of the most time-consuming parts of mutation analysis and a possible source of error \nif it is done manually. In the context of formal program testing, proving that a mutant ia 4A program \nfragment S is semantically equivalent to the annotated program fragment {P} S {Q} iff the formulas {P} \nS-{Q} and {P} S {Q} are logically equivalent. If the single occurrence of the systematic er\u00adror is the \nonly-error on the path and-the error is corrected by some mutant operator, then mutant equivalent to \nthe original fragment reduces to proving that the mutant-s verification condition is equivalent to the \noriginal one. Instead of proving two large programa are equivalent, the system only has to prove two \nprogram fragments are equivalent. Of course, even in the latter case, it is unrealistic to expect that \nan automatic detection system will work most of the time, since the competence of existing automatic \ntheorem provers is limited. 7. An Extended Example To illustrate how a formal testing system based on \nTTL might work, we present an example taken from [Luckham and Suzuki 79]. The following extended PASCAL \nprocedure annotated in TTL main tains an event queue --a linear list of records each containing a key \nand count. The procedure takes an event queue and a key as input, incre\u00adments the count field of the \nrecord corresponding to the key in the queue, and moves that record to the front of the list. If no record \ncorresponding to the key exists, the procedure creates one at the front of the list. To eliminate annoying \nspe\u00ad cial caaes, the list includes header and trailer records containing no data. For the sake of nota\u00ad \ntional clarity, we have augmented PASCAL with Dijkatra-s guarded command control structures. Specification: \ntype event_queue = msp[int,int] function Abatr(head,tail: int): event queue = global event#claas; (* \nevent#class-ia the *) (* heap array for *) (* record type event *) let first = headt.next; if first= \ntail then empty else {(firstt.key,firstt.count)} Abstr(firstt.next,tail); funcc%on Add event(q: event \nqueue, e: int): event queue s if e Domain(q) then q(e ; q[e~+l) (* ( q -{(e,q[el)} )U {(e,q[e]+l)} *) \nelse qU {(e,l)}; Program: type ref event = = tevent; record key: count: next: int; int; ref end procedure \nSearch(ref : Head, Tail; int : X); logical var Q:event queue; pre : Abstr(Head, Tail): event queue A \nAbstr(Head,Tail) =Q; post: Abatr(Head,Tail)=Add_event(Q,X) ; var P,R : ref; begin P:=Head; Tailt.key:=X; \ninvariant: Abstr(Head, Tail)=Q A X4 Domain(Abstr(Head, Pt.next) ) do Pt.nextt.key#X + P:=Pt.next od; \nif Pt.next=Tail + neu(R); Rt. next :=Headt.next; Rt.count:=l; Rt.key :=X; Headt.next:=R; D P~.next #Tail \n+ R:=Pt.next; Rt.count:=Rt .count+l; Pt.next :=Rt.next; Rt. next :=Headt.next; Headt.next:=R; fi end \nSearch The data type definitions in the Specification section preceding the Program do not include the \ndefinitiona either of built-in TTL types such as polymorphic sets and maps or concrete PASCAL types \ndefined in the program. Every PASCAL typedefini tion implicitly generates a corresponding TTL type definition \n--formalizing PASCAL data objects and operations within TTL. The program specification uses an abstraction \nfunction (a concept introduced by [Hoare 72]) written in TTL to define the abstract data object (a map \nfrom int into int) corresponding to a low-level event-queue represen\u00adtation. If we ignore the issue of \ntermination, the verification conditions for the program are: analysis ia guaranteed to find it. 1. \n~Head, Tail, P:ref, Q:event_queue Abstr(Head, Tail): event_queue A Abstr(Head,Tail) =Q + wp( P:=Head; \nTailt.key:=X , X~Domain(Abstr(Head, Pt.next)) A Abstr(Head, Tail) =Q ) 2. ~Head, Tail, P:ref, Q:event_queue \nX@ Domain(Abstr(Head,Pt.next)) A Abstr(Head, Tail)=Q /l PT.nextt.key~X + wp( P:=Pt.next , X~Domain(Abstr(Head, \nPt.next)) A Abstr(Head, Tail) =Q ) 3. VHead, Tail, P:ref, Q:event_queue X $Domain(Abstr(Head,Pt.next)) \nA Abstr(Head, Tail)=Q /l Pt.nextt.key=X + (Pt.next Tail+ wp( new(R); Rt. next :=Headt.next; Rt.count:=l; \nRt.key :=X; Headt.next:= R , Abstr(Head,Tail) =Add_event(Q,X)) )A (Pt.next # Tail+ wp( R:=PT.next; Rt.count:=Rt \n.count+l; Pt. next :=Rt.next; Rt. next :=Headt.next; Headt.next:= R , Abstr(Head, Tail) =Add_event(Q, \nX)) ) where wp(S,R) denotes the weakest pre-condition of program seqment S and post-assertion R. Each \noccurrence of the notation wp(S,R) in the verifi\u00adcation conditions above is equivalent to a pure formula \nR where R-is R modified by a substitu\u00adtion corresponding to the sequence of assignments s. We prefer \n wp notation to explicit substitu\u00adtions for assignment statements because it is easier to read. It aleo \nhappens to be a con\u00advenient form for the purposes of evaluation and mutation analysis. Given test values \nfor the universally quanti\u00adfied variables, a TTL interpreter (supporting PAS-CAL data objects and operations) \nclearly could evaluate the above verification conditions. On the other hand, automatically generating \nsatisfac\u00adtory test values is a subtle problem. For exam\u00adple, consider the problem of generating test \ndata for verification condition 1. If we follow the strategy proposed in section 5, we can easily fall \ninto an infinite recursion in evaluating Abstr(Head,Tail) if we happen to bind Headt.next and Head to \nthe same pointer value and bind Tail to a different one. Placing a bound on maximum recursion depth is \nan obvious ..brute force . SOIU\u00adtion to this problem, but it rigidly limits the complexity of test cases \nthat can be generated. 8. Directions for Forther Work Since formal program verification is far too expensive \nand time-consuming to be practical in most applications, formal program testing appears to be a promising, \ncost-effective alternative. Nevertheless, the succees of formal testing depends on the willingness of \nprogrammers to docu\u00adment their programs with formal specifications. Unfortunately, the bulk of recent \nresearch in for\u00admal specifications has concentrated on axiomatic descriptions of program data and operations \n--an approach that is incompatible with formal testing. The specification language TTL described in this \npaper is a first attempt at developing a specifi cation language to support formal testing. We hope others \nwill study the problem. Since the sub\u00adject is still in its infancy, the prospects for significant advances \nin specification language design are bright. We are currently building a formal testing system for PASCAL \nto evaluate the viability of formal testing and the utility of TTL as a specif\u00ad ication language. We \nwill report on the results in a subsequent paper. 9. References [Boyer and Moore 75] Boyer, R.S., and \nMoore, J S.; Proving Theorems About LISP Functions, ~. ~ 22, 1 (Jan. 1975), pp. 129-144. [Boyer and \nMoore 79] Boyer, R.S., and Moore, JS. ~ Computational 131 Logic, Academic Press, New York, 1979. [Brand \n76] Brand, D.; ;Proving Programs Incorrect, Proceedings Third International Colloquium on Automata, Languages \nand Programming, Edi~ burgh U. Press, Edinbu~h, 1976, pp. 201-227. [Brand 78] Brand, D.; Path Calculus \nin Program Verifi\u00adcation, J. ACM 25(4), pp. 630-651. [Budd et. al. 80] Budd, T., R. DeMillo, R. Lipton, \nand F. Say ward; Theoretical and Empirical Studies on Using Program Mutation to Test the Functional \nCorrectness of Programs, Proceedings Seventh Annual ACM Symposium on Principles of Pro\u00ad =ng~anguages, \n pp~213-233. . [Cartwright 76a] Cartwright, R.S.; User-Defined Data Types as an Aid to Verifying LISP \nPrograms, Proceed\u00adings Third International Colloquium on Auto\u00ad . ~,~uages and Programming, Edinburgh \nU. Press, Edinburgh~976, pp. 228-256. [Cartwright 76bl Car~wright~ R.S.; ~ Practical Formal Semantic \nDefinition and Verification System for TYPED ~, Sta~rd Artificial Intelligence Laboratory Memo AIM-296, \nStanford University, 1976. [Cartwright 80] Cartwright, R.S.; A Constructive Alternative to Axiomatic \nData Type Definitions, Proceed\u00adings of 1980 LISP Conference, Stanford . Univers~ty, August 1980, pp. \n46-55. [Earley 73] Earley, J.; High Level Operations in Automatic Programming , Computer Science Department, \nTechnical Report 22, University of California, Berkeley, 1973. [Earley 74] Earley, J.; High Level Iterators \nand a Method for Automatically Designing Data Structure Representation , Electronics Research Laboratory, \nMemorandum No. ERL-M425, University of California, Berkeley, 1974. [Gerhart 75] Gerhart, S.L.; Correctness \nPreserving Pro\u00ad gram Transformations , Proceedings of the . Second ACM Symposium on Principles of Pro\u00ad \n=ng~ang.ages, PP. 54-66. [Goguen 77] Goguen, J., Thatcher, J., Wagner, E., and Wright, J.; Initial Algebra \nSemantics and Continuous Algebras, JACM 24, pp. 68 95. [Guttag and Horning 78] Guttag, J.V. and JJ. \nHorning; The Algebraic Specification of Abstract Data Typea, Acts Informatica ~, pp. 27 52. [von Henke \nand Luckham 74] von Henke, F. and D.C. Luckham; Automatic Program Verification III: A Methodology for \nVerifying Programs, Stanford Artificial Intelligence Project Memo AIM-223. [Hoare 72] Hoare, C.A.R.; \nProofs of Correctness of Data Representation , Acts Informatica~, 271-281. [Hoare 75] Hoare, C.A.R. \nRecursive Data Structures, International Journal of Computer and Infor\u00admation Science~pp~105-132. ~ \n[Igarashi, London and Luckham 75] Igarashi, S., London; R.L., and Luckham, D.C.; Automatic Program Verification \nI: Log\u00adical Basis and Its Implementation, Acts Informatica 4_, pp. 145-182. [Kennedy and Schwartz 75] \nKennedy, K. and Schwartz, J.T. An Introduc\u00ad tion to the Set Theoretical Language SETL, and Math. with \nApplications -1 . ti97% :p: 97-119. [Liskov and Zillea 75] Liskov, B. and S. Zilles; Specification Techniques \nfor Data Abstractions, IEEE Tran\u00ad sactiona on Software Engineering, Vol. SE-1, pp. 7-19. [Liskov and \nBerzins 80] Liskov, B. and V. Berzins; An Appraisal of Program Specifications, in Research Direc\u00adtions \nin Software Technology, P. Wegner (cd.), MIT Press, pp. 276-302. [Luckham and Suzuki 79] Luckham, D.C., \nand Suzuki, N.; Verification of Array, Record, and Pointer Operations in Pascal, TOPLAS 1 (1979), pp. \n226-244. [McCarthy 63] McCarthy, J.; A Basis for a Mathematical Theory of Computation, in Computer Program \nming and Formal Systems, Braffort and Hirsch\u00ad berg, eds., North-Holland, 1963. [Nelson and Oppen 79] \nNelson, G. and D. Oppen: Simplification by Cooperating Decision-Procedure~, ACM TOPLAS 1(2), pp. 245-257. \n [Schwartz 79] Schwartz, J.; Personal communication. [Warren and Pereira 77] Warren, D. and Pereira, \nL.; PROLOG: The Language and Its Implementation Compared with LISP, Proceedings of the ACM Symposium \non Art. Intel. and Prog. Lang., SIGART/SIGPLAN  132 \n\t\t\t", "proc_id": "567532", "abstract": "This paper proposes a practical alternative to program verification -- called formal program testing -- with similar, but less ambitious goals. Like a program verifier, a formal testing system takes a program annotated with formal specifications as input, generates the corresponding verification conditions, and passes them through a simplifier. After the simplification step, however, a formal testing system simply evaluates the verification conditions on a representative set of test data instead of trying to prove them. Formal testing provides strong evidence that a program is correct, but does not guarantee it. The strength of the evidence depends on the adequacy of the test data.", "authors": [{"name": "Robert Cartwright", "author_profile_id": "81406592800", "affiliation": "Rice University", "person_id": "PP43116956", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567532.567546", "year": "1981", "article_id": "567546", "conference": "POPL", "title": "Formal program testing", "url": "http://dl.acm.org/citation.cfm?id=567546"}