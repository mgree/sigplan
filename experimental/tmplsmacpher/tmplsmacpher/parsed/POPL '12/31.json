{"article_publication_date": "01-25-2012", "fulltext": "\n Abstractions from Tests Mayur Naik Hongseok Yang Ghila Castelnuovo Georgia Institute of Technology, \nUSA University of Oxford, UK Tel-Aviv University, Israel naik@cc.gatech.edu hongseok.yang@cs.ox.ac.uk \nghila.castelnuovo@gmail.com Mooly Sagiv Tel-Aviv University, Israel mooly.sagiv@gmail.com Abstract We \npresent a framework for leveraging dynamic analysis to .nd good abstractions for static analysis. A static \nanalysis in our frame\u00adwork is parametrised. Our main insight is to directly and ef.ciently compute from \na concrete trace, a necessary condition on the param\u00adeter con.gurations to prove a given query, and thereby \nprune the space of parameter con.gurations that the static analysis must con\u00adsider. We provide constructive \nalgorithms for two instance analyses in our framework: a .ow-and context-sensitive thread-escape anal\u00adysis \nand a .ow-and context-insensitive points-to analysis. We show the ef.cacy of these analyses, and our \napproach, on six Java pro\u00adgrams comprising two million bytecodes: the thread-escape analy\u00adsis resolves \n80% of queries on average, disproving 28% and prov\u00ading 52%; the points-to analysis resolves 99% of queries \non average, disproving 29% and proving 70%. Categories and Subject Descriptors D.2.4 [SOFTWARE EN-GINEERING]: \nSoftware/Program Veri.cation; F.3.2 [LOGICS AND MEANINGS OF PROGRAMS]: Semantics of Programming Languages \nProgram analysis General Terms Languages, Veri.cation Keywords Parametrised Static Analysis, Testing, \nThread-Escape Analysis, Points-to Analysis, Necessary-Condition Problem 1. Introduction Static analyses \nbased on the Abstract Interpretation technique [6] are guaranteed to be sound: if such an analysis reports \nthat a given query holds for a given program, it must indeed hold. In practice, however, the analysis \nmay not be cheap enough to apply to the program, or it may not be precise enough to prove the query. \nThis problem is inherent with the undecidability of static analysis. One of the most interesting questions \nin static analysis concerns how to specialise a given static analysis to prove a given query. The idea \nis to make the analysis cheap yet precise by tailoring it to prove a speci.c query. Counterexample-guided \nabstraction Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n12, January 25 27, 2012, Philadelphia, PA, USA. Copyright c &#38;#169; 2012 ACM 978-1-4503-1083-3/12/01. \n. . $10.00 re.nement (CEGAR) [1, 5, 13, 19] aims to solve this problem. The idea is to gradually re.ne \nthe abstraction until either a concrete counterexample is found or the query is proven. Despite many \nadvances, the CEGAR approach includes many limitations which hinder its practicality: it is costly and \nmay fail due to limitations of the theorem prover, the inability to appropriately re.ne the abstraction, \nthe huge size of the counterexample, and the cost of the static analysis to compute the intermediate \nabstractions. This paper takes a radically different approach: it uses dynamic analysis to compute good \nabstractions for static analysis. The static analysis is parametrised, and the space of parameter con.gurations \nis typically large, e.g., exponential in program size or even in.nite. Given a query, a set of parameter \ncon.gurations, and a concrete trace, our dynamic analysis computes a necessary condition on the parameter \ncon.gurations for proving the query. Our limited experience shows that this condition can be used to \nchoose, from among the remaining parameter con.gurations, one that yields an abstraction that is cheap \nenough to drastically cut the cost of the static analysis yet precise enough to prove the query. One \nadvantage of our approach is that the necessary condition is inferred ef.ciently and directly from the \nconcrete trace without the need to run the static analysis on the whole program, which may be infeasible. \nAdditionally, our method can be seen as an auditing procedure for static analysis: when an abstraction \nfails to satisfy our condition, it can neither prove nor disprove the query, independently of the existence \nof the counterexample. This means that some abstractions are pruned even before they are computed, which \nis in contrast to the CEGAR approach. We do not provide a general algorithm to compute the necessary \ncondition from a given trace. Instead, we provide a formal, non\u00adconstructive de.nition of the necessary-condition \nproblem, and algorithms that compute the condition directly from the trace for two instance analyses: \na .ow-and context-sensitive thread-escape analysis, and a .ow-and context-insensitive points-to analysis. \nWe have evaluated our approach on six real-world Java pro\u00adgrams comprising two million bytecodes in total, \nthe largest being 500K bytecodes. For thread-escape analysis, our approach resolves 80% of queries on \naverage, disproving 28% and proving 52%. For points-to analysis, it resolves 99% of queries on average, \ndisprov\u00ading 29% and proving 70%. The fact that the vast majority of queries are resolved and, more signi.cantly, \nproven shows that our ap\u00adproach is precise in practice. It is also scalable: despite being top\u00addown, \ninter-procedural, and fully .ow-and context-sensitive, our thread-escape analysis takes only 7 seconds \non average over 1,750 invocations, with a maximum of 20 seconds. To summarise, the key contributions \nof this paper are as follows: 1. We present a novel approach for using concrete traces in order to obtain \ngood abstractions in certain cases for static analysis. 2. We present a formulation of a necessary condition \nfor an ab\u00adstraction to be precise enough for a given concrete trace. 3. We provide constructive algorithms \nto compute the necessary condition from a concrete trace for two static analyses (thread\u00adescape analysis \nand points-to analysis). 4. We provide empirical evidence that our approach can be ef.\u00adciently implemented \nand that the resulting static analysis is both precise and scalable.  2. Example In this section, we \nprovide the reader a .avour of our approach using thread-escape analysis. 2.1 The thread-escape analysis \nproblem We introduce the thread-escape analysis problem using the example Java program in Figure 1. Object \nallocation sites have unique labels h1, h2, and so on, and we elide all types. Variables u, v, and w \nare locals and g is a global (i.e., static .eld). The program is multi\u00adthreaded: in each iteration of \nthe loop, the main thread executes the statement u.start(), which calls the start() method of class java.lang.Thread, \nwhich asynchronously starts a new thread corresponding to the object pointed to by u. Thus, after the \ncall, the main thread proceeds to the next loop iteration while the freshly started child thread runs \ncode not shown in the .gure. The graph at the top of Figures 1(a) (c) (ignoring the dotted boxes) shows \nthe concrete data structure created just before pro\u00adgram position pc in any iteration i = 1 of the loop. \nFor conve\u00adnience, each object is labeled with the site at which it was cre\u00adated (h1, h2, etc.). The clear \nnodes denote thread-local objects and the shaded nodes denote thread-escaping objects. An object is thread-local \nif it is reachable from at most one thread, and thread\u00adescaping otherwise. An object becomes reachable \nfrom multiple threads if it is assigned to a global or if the start() method of class java.lang.Thread \nis invoked on it: in the former case, the object becomes reachable from all threads in the program, while \nin the latter case, the object becomes reachable from at least the parent thread and the freshly started \nchild thread. Moreover, any object reachable in the heap from a thread-escaping object is also thread-escaping. \nFinally, once an object thread-escapes, it remains thread-escaping for the rest of the execution. In \nour example, the statement g = new h3 which writes to global g causes the freshly created object to thread-escape \n(depicted by the shaded object la\u00adbeled h3). Likewise, the call u.start() causes the object pointed to \nby u to thread-escape (depicted by the shaded object labeled h1 from an earlier iteration). Moreover, \nthe object pointed to by w is reachable from this object in the heap via .eld f2; hence, that ob\u00adject \nalso thread-escapes (depicted by the shaded object labeled h4 from an earlier iteration). We formulate \nthe thread-escape analysis problem in the form of program queries. The query we focus on in our example \nis qlocal(pc, w), which is true if, whenever any thread reaches program position pc, the object pointed \nto by local variable w in that thread s environment is thread-local. It is easy to see that this query \nis true in our example: the only thread that reaches pc is the main thread, and whenever it does, w points \nto the object most recently created at site h4, which is thread-local (note that this object thread-escapes \nonly after the following statement u.start() is executed). Many clients in veri.cation, testing, optimisation, \nand program under\u00adstanding for multi-threaded programs can bene.t from answering such queries. For instance, \nproving our example query enables a static race detector to prove that .eld id is race-free. 2.2 Parametrised \nthread-escape analysis A key challenge in proving thread-escape analysis queries lies in choosing a heap \nabstraction that separates thread-local objects from thread-escaping objects. One class of heap abstractions \ninvolves partitioning all objects based on some static program property. A natural way is to use a separate \npartition for all objects created at the same allocation site. But even this simple heap abstraction \ncan be too costly when applied to a large program with procedures. Our goal is to derive cheaper heap \nabstractions that in most cases are still precise enough to prove the given query. The .rst step in our \napproach is to parameterise the static anal\u00adysis in a manner that admits a large (possibly in.nite) family \nof abstractions, and cast the problem as a search for a good pa\u00adrameter con.guration to use for proving \na given query. Examples of such analyses abound: a safety model checker can be viewed as parametrised \nby a set of program predicates that dictates the predicate abstraction it computes, shape analysis is \nparametric in which predicates to use as abstraction predicates, and cloning\u00adbased points-to analyses \n(k-CFA, etc.) are parametrised by a vector of integers that dictate the degree of context-and object-sensitivity \nthe analysis must use for each call site and each allocation site. Our thread-escape analysis uses heap \nabstractions with two par\u00adtitions, denoted L and E, that summarise de.nitely thread-local objects and \npossibly thread-escaping objects, respectively. The analysis is parametrised by the partition to be used \nfor summarising objects created at each allocation site. A parameter con.guration . thus maps each allocation \nsite in the program to either L or E. Each object created at a particular site starts in the partition \ndictated by . for that site, and may subsequently migrate from L to E but not vice versa. The analysis \nsucceeds in proving a query qlocal(pc, x) if variable x does not point to an object summarised by the \nE partition in any abstract state at program position pc. Our goal in the parametrised analysis setting \nis to ef.ciently .nd a parameter con.guration that is cheap yet precise enough to prove a given query. \nIn practice, most con.gurations yield abstractions that are not cheap enough to apply to the given program, \nor not precise enough to prove the given query. Moreover, proving differ\u00adent queries can require different \ncon.gurations. We next illustrate the dif.culty in ef.ciently .nding good con.gurations. We begin by \nnoting that enumerating and testing con.gurations is infeasible due to the large space from which they \ncan be chosen. Consider the trivial .1 in Figure 1(a), which maps each site to L. The analysis using \n.1 computes at position pc the abstract state shown at the bottom of the .gure, with the corresponding \nconcrete state shown above it. This analysis fails to prove our query because variable w points to partition \nE in the abstract state at position pc, despite all objects starting in partition L. This is because \nstatement g = new h3 pollutes the L partition since .1 maps h3 to L (recall that objects can migrate \nfrom partition L to partition E). This leads us to .2 in Figure 1(b), which is similar to .1 but maps \nh3 to E. The analysis using .2 proves our query, but it is not the cheapest con.guration. Our analysis \nreasons about reads from objects that are summarised by the L partition and so it tracks outgoing .elds \nfrom such objects. Being fully .ow-and context\u00adsensitive, the analysis is exponential in the number of \nsuch .elds. Hence, it is cheapest to map as few sites as possible in . to L, and thereby limit the number \nof such .elds. In particular, it is not necessary to map h2 to L, which causes .eld f to be tracked. \nThis leads us to .3 in Figure 1(c) which is the cheapest con.g\u00aduration that proves our query. Note that \nfurther coarsening it fails to prove the query: mapping h4 to E clearly fails because query variable \nw is allocated at site h4, but mapping h1 to E also fails because variable u is allocated at site h1 \nand statement u.f2 =w will pollute the L partition.  // u, v, w are local variables // g is a global \nvariable // start() spawns a new thread for (i=0; i<*;i++){ u = new h1; v = new h2; g = new h3; v.f =g; \nw = new h4; u.f2 = w; pc: w.id = i; u.start(); } .2 =[h1 . L, h2 . L,.3 =[h1 . L, h2 . E, thread-escape \nquery: qlocal(pc, w)  h3 . E, h4 . L] h3 . E, h4 . L] (b) proves query but not cheapest (c) proves query \nand cheapest  Figure 1. Example Java program and abstract states computed by our thread-escape analysis \nat pc using different parameter con.gurations. 2.3 Parameter con.gurations from tests We have seen that \nchoosing a good parameter con.guration for a given query requires striking a delicate balance between \npreci\u00adsion and scalability. The key insight in our work is to directly and ef.ciently infer from a concrete \nprogram trace a necessary con\u00addition on the parameter con.gurations for proving the query. Our work does \nnot provide a general algorithm for computing the nec\u00adessary condition but it serves as a principle for \ndesigning good ab\u00adstractions. We provide constructive algorithms using the principle for two instance \nanalyses: a thread-escape analysis and a points\u00adto analysis. We also prove that these algorithms indeed \ncompute a necessary condition: any parameter con.guration not satisfying the condition will fail to prove \nthe query. In the case of our thread-escape analysis, the necessary condi\u00adtion is computed using an algorithm \nwe call backward pointer reachability: Given a query qlocal(pc, x) and a concrete program state (., p, \ns) at location pc, where . and p are the environments providing the values of local and global variables \nrespectively and s is the heap, this algorithm dictates that any parameter con.gura\u00adtion that can prove \nthis query must map the allocation site of each object from which the object .(x) is reachable in s to \nL. For our example query, this algorithm outputs [h1 . L, h4 . L]. This is because, whenever program \nposition pc is reached, variable w points to an object allocated at site h4, and the only other object \nfrom which that object is reachable in the heap is the one pointed to by variable u, which is allocated \nat site h1. Note that the con.guration output by the algorithm does not constrain the values of h2 and \nh3. Moreover, many allocation sites in the program may not even be visited in the trace. Since it is \ncheaper to summarise objects using the E partition instead of the L partition (recall that the analysis \ntracks outgoing .elds of only objects in the L partition), we simply map all unconstrained sites to E. \nThus, our approach yields con.guration .3 shown in Figure 1(c), which is the cheapest con.guration that \nproves the query. Our backward pointer reachability algorithm is not the only al\u00adgorithm that satis.es \nour necessary condition principle. In the ex\u00adtreme, one could envision an algorithm that also infers \na condition that is suf.cient for the given trace. Such an algorithm, for instance, would map h3 to E \n(recall from Figure 1(a) that any con.gura\u00adtion that maps h3 to L fails to prove the query). However, \nthere is a trade-off between the amount of computation that the dynamic analysis does and the quality \nof the con.guration it infers, and the motivation underlying our backward pointer reachability algorithm \nis to strike a good balance. 3. Necessary-condition problem In this section, we explain the formal setting \nof our result. In par\u00adticular, we de.ne the necessary-condition problem, whose solution plays a crucial \nrole in our approach. DEFINITION 1. A transition system is a triple (S,T,I) where T . S\u00d7S and I .S.A \nquery q on a transition system (S,T,I) is a function from S to {true, false}. Intuitively, S de.nes the \nstate space of the transition system, T all the possible state changes, and I the set of initial states. \nA query q speci.es a particular safety property of the transition system. We assume that a transition \nsystem (S,T,I) and a query q are given as input to a static analysis. The goal is to prove that the query \nis true in all reachable states: .s . T * (I).q(s)= true. We solve this problem by using a dynamic analysis \ntogether with a parametrised static analysis. A dynamic analysis here is simply a run of the given transition \nsystem from some initial state. In our combination, this dynamic analysis is run .rst, and it either \ndisproves the query or discovers a condition on the parameters of the static analysis, which should hold \nin order for the analysis to prove the query at all. In the latter case, this condition is converted \nto a particular parameter setting, and the static analysis is run with this setting to attempt to prove \nthe query. The transition system used by the dynamic analysis is often instrumented to track extra information \nabout program execution in its states. One example is to record in each object the timestamp of its creation. \nThen, just looking at a single state provides the order of creation of objects in the state. Note that \n.nding such an order in a standard semantics requires looking at a concrete trace. The instrumentation \ntransforms such trace properties to state properties, which can be better exploited by our dynamic analyses. \nIn the following subsections, we describe our parametrised static analysis and how we combine dynamic \nand static analyses in detail. We .x a transition system (Sc,Tc,Ic) and a query qc, and call this transition \nsystem the concrete program. 3.1 Parameterised static analysis We remind the reader of a standard de.nition \nof a sound static anal\u00adysis and a well-known consequence of the soundness condition: DEFINITION 2. A \nstatic analysis is a tuple (D,T ,I ,.) of a complete lattice D, a monotone function T : D.D, an element \nI .D representing the set of initial states, and a monotone function . : D.P(Sc). We call the function \n. concretisation map, and it gives the meaning of elements in D as sets of states in the concrete program. \nA static analysis is sound iff Ic . .(I) ..d .D.Tc(.(d)) . .(T(d)). LEMMA 3. If a static analysis (D,T \n,I ,.) is sound, every pre\u00ad * .xpoint of .d. I u T (d) overapproximates the set Tc (Ic) of reachable \nstates in the concrete program: .d .D. (I u T (d)) d =. Tc * (Ic) . .(d). We consider static analyses \nwith multiple parameters. We for\u00admalise the domain of parameter settings as follows: DEFINITION 4. A \ndomain PCon.g of parameter con.gurations is a set of functions from a set Param of parameters to a set \nPVal of parameter values. The domain does not necessarily contain all such functions, and it is ranged \nover using symbol .. Intuitively, parameters p in Param decide parts of the analysis to be controlled, \nsuch as the abstract semantics of a particular mem\u00adory allocation in the given program. A parameter con.guration \n. maps such p s to elements in PVal, which determine an abstraction strategy to employ for the p part \nof the analysis. We allow the possi\u00adbility that multiple parameter con.gurations essentially express \nthe same abstraction strategy, and we make this duplication explicit as\u00adsuming an equivalence relation \n~ on PCon.g. DEFINITION 5. A parametrised static analysis is a family of static analyses {(D.,T. ,I. \n,..)}..PCon.g indexed by parameter con.gurations in some (PCon.g, ~). We require that equivalent components \nof the analysis satisfy the condition: . ~ .' =.{..(d) | d .D.} = {.. (d) | d .D. }. A parametrised static \nanalysis is sound if all of its component analyses are sound.  3.2 Problem description Assume that we \nare given a sound parametrised static analysis {(D.,T. ,I. ,..)}..PCon.g. We now formulate the necessary\u00adcondition \nproblem for this parametrised static analysis. A solution extracts useful information for a parametrised \nstatic analysis from results of a dynamic analysis, and it forms the main component of our combination \nof dynamic and static analyses. We say that a .nite subset Sd of Sc validates the query qc when qc(s)= \ntrue for every s . Sd. In our setting, such a validating set Sd of states is obtained from multiple runs \nperformed during dynamic analysis, and it carries information potentially useful for the following static \nanalysis. One example of such information is formalised by our predicate cannotProve(., Sd) on parameter \ncon.gurations . . PCon.g:1 cannotProve(., Sd) .. '' (.d .D..Sd . ..(d)=..s. ..(d).qc(s)= false). Intuitively, \nthe predicate holds for ., when the .-component anal\u00adysis cannot separate Sd from states violating the \nquery qc. As a result, cannotProve(., Sd) implies that the . component cannot 1 The cannotProve predicate \nis related to so called supervaluation of ab\u00adstract elements. The formula \u00accannotProve(., Sd) holds iff \nthere is an abstract element d in D. overapproximating Sd and containing only those concrete states where \nqc evaluates to true. The latter property of d is the de.nition of qc having the super-truth at d. prove \nthat the query holds for all the states in Sd. Using this predi\u00adcate, we describe our necessary-condition \nproblem: Necessary-condition problem (in short, NC problem). Find an algorithm that takes a .nite set \nSd validating the query qc and returns a set N . Param \u00d7 PVal satisfying the conditions below: for all \n. . PCon.g, ' '' \u00ac(... PCon.g.. ~ ...(p, v) . N. .(p)= v) .. cannotProve(., Sd) (1) The left-to-right \nimplication implies that if . is not equivalent to any parameter con.guration that realises all the parameter \nbindings (p, v) in N, we can skip the option of setting parameters to ., because the resulting . analysis \ncannot prove the query. Hence, to have any hope for proving the query with the static analysis, we should \nensure that some parameter con.guration equivalent to our setting . respects all the bindings (p, v) \nin N. The phrase necessary condition mirrors this property of N. The other right\u00adto-left direction is \na completeness requirement, and it asks the algorithm to discover all the binding pairs that can be used \nto detect the satisfaction of cannotProve(-,Sd). We make two further remarks on the NC problem. First, \nif every parameter con.guration . . PCon.g satis.es cannotProve(., Sd) so that no parameter settings \ncan make the static analysis prove the query, the problem requires that the algorithm should return an \nun\u00adsatis.able set N up to the equivalence ~: for every ., no .' equiv\u00adalent to . follows all the bindings \nin N. This usually happens when N contains two different bindings (p, v) and (p, v') for the same parameter \np. Second, even if some parameter con.guration equiva\u00adlent to . respects all the bindings in N, the analysis \nwith . can fail to prove the query. According to the equivalence, such . satis.es \u00accannotProve(., Sd), \nbut this just means that the .-component analysis has an abstract element in D. that can overapproximate \nSd without including bad states (i.e., those violating the given query). In practice, however, we found \nthat \u00accannotProve(., Sd) is a good indicator of the success of the analysis with ., especially when states \nSd are instrumented and carry additional information about concrete traces. A solution to the NC problem \nenables an interesting combina\u00adtion of a dynamic analysis and a parametrised static analysis. In this \ncombination, a dynamic analysis is .rst run, and it gives a set of states s1,...,sn that are reachable \nfrom some initial states in Ic. If the given query qc does not hold for some si, we have found a counterexample, \nand the combined analysis terminates with this counterexample si. Otherwise, the solution to the NC problem \nis run for s1,...,sn, and then it computes a set N. The combined analysis then checks the unsatis.ability \nof N as follows: ''= v' .p . Param. .v, v. PVal. (p, v) . N . (p, v) . N . v . If the check goes through, \nthe analysis stops and returns impossi\u00adble to prove . Otherwise, it picks one element v0 from PVal (which \nnormally makes the static analysis run fast), and constructs a pa\u00adrameter con.guration .N as follows: \n.N (p)= if ((p, v) . N for some v) then v else v0. (2) The element v0 is chosen carefully so that .N \nbelongs to PCon.g. Finally, the analysis with the parameter setting .N is run on the given program. In \nwhat follows, we explain how to solve the NC problem for instance analyses. 4. Generic solution We have \ndeveloped solutions to the NC problem for two instance analyses. This section is a prelude of the description \nof these solu\u00adtions, where we explain their commonalities. In particular, we clar\u00adify an assumption made \nby both solutions on parametrised static analyses and queries, and describe a recipe for developing an \nal\u00adgorithm for the NC problem, called generic solution, from which the solutions can be derived. This \nrecipe can also be used for other instance analyses. As in the previous section, we assume a .xed concrete \nprogram (Sc,Tc,Ic) and a .xed query qc on Sc. Our generic solution requires that a parametrised static \nanaly\u00adsis {(D.,T. ,I.,..)}..PCon.g should have coupled components, which means that the following three \nconditions hold: 1. The component static analyses use the same abstract domain. That is, D.0 = D.1 for \nall .0,.1 . PCon.g. We let D be this common abstract domain. Note that we do not impose a similar requirement \non .. and component analyses can, therefore, use different concretisation maps. This means that although \nthe components share the same set D of abstract representations, they can still have different abstract \ndomains, because they might interpret these representations differently. 2. For all .0,.1 . PCon.g and \nall d .D,  (.s . ..0 (d).qc(s)= true) .. (.s . ..1 (d).qc(s)= true). Note that both sides of the equivalence \nare the same except the subscripts .0 and .1. The common part .s . .-(d).qc(s)= true (3) means that query \nqc holds for all states abstracted by d. Hence, if the static analysis with a certain parameter con.guration \nreturns such d, it can prove that query qc holds for all the reachable states of the given concrete program. \nFor this reason, we call d satisfying formula (3) a good abstract element. Because of the equivalence \nabove, the identi.cation of such good abstract elements does not depend on the choice of a parameter \ncon.guration ., and we use some . . PCon.g and de.ne the set of good elements Dg as follows: Dg = {d \n|.s . ..(d).qc(s)= true} 3. There are a .nite lattice Auxs, and monotone functions Fs : Auxs . Auxs and \nGs : Auxs .P(Param \u00d7 PVal) for each s .Sc, such that the equivalence below holds for all .nite subsets \nSd .Sc: (.d . Dg.Sd . ..(d)) .. .. ' .. ~ . ' . (.s . Sd. .a . Auxs. (Fs(a) a) ..(p, v) . Gs(a).. ' (p)= \nv). The left side of the equivalence means that the static analysis with . can use a good abstract element \nd . Dg to abstract a given set of states Sd. Hence, it can at least separate Sd from bad states where \nquery qc gets evaluated to false. According to the equivalence, this property on . can be checked using \nF and G. That is, we iterate over all parameter con.gurations . ' equivalent to ., and do the following. \nFor every state s . Sd, we compute some pre-.xpoint of Fs over Auxs, map this pre-.xpoint to a subset \nN0 of Param \u00d7 PVal using Gs, and check whether . ' respects all the bindings in N0. If the check succeeds, \nwe stop the iteration, and return yes . If the iteration .nishes without any successful check, we return \nno . Assume that we are given a sound parametrised analysis that has coupled components. Our generic \nalgorithm for solving the NC problem is given in Figure 2. Given a .nite set Sd validating query qc, \nthe algorithm iterates over every element s . Sd, and computes the least .xpoint leastFix Fs, which is \nmapped to a subset Ns of Param \u00d7 PVal by Gs. The resulting subsets Ns from iterations are combined, \nand become the result N = s.Sd Ns. Input: a .nite subset Sd .Sc such that .s . Sd.qc(s)= true Output: \nthe .nite subset N . Param \u00d7 PVal computed by  N = {Gs(a) | s . Sd . a = leastFix Fs} Figure 2. Generic \nalgorithm for solving the NC problem. Note that the least .xpoint of Fs exists and can be computed by \nthe standard method (which generates .,Fs(.),Fs(Fs(.)),... until the .xpoint is reached), because Auxs \nis a .nite lattice (hence complete) and Fs is monotone. THEOREM 6. Our generic algorithm solves the NC \nproblem. Proof: Let N be the result of our algorithm when it is given a set Sd of states as the input. \nWe need to prove that for every parameter con.guration . . PCon.g, cannotProve(., Sd) holds if and only \nif we cannot .nd . ' equivalent to . such that . ' (p)= v for all (p, v) . N. We will discharge this \nproof obligation by showing: '' ' \u00accannotProve(., Sd) .. .. .. ~ . ..(p, v) . N. . (p)= v. We .rst transform \nthe left side of the equivalence by unrolling the de.nition of cannotProve and using the .rst condition \nof hav\u00ading coupled components, which says that D. = D for all .: \u00accannotProve(., Sd) .. \u00ac(.d .D.Sd . \n..(d)=..s ' . ..(d).qc(s ' )= false) .. .d .D.Sd . ..(d) ..s ' . ..(d).qc(s ' )= true. In the .rst equivalence, \nwe unroll the de.nition of cannotProve and replace D. by D in the result of unrolling. The second equiva\u00adlence \nis the standard one from classical logic. Next, we use the second condition of having coupled compo\u00adnents, \nwhich allows us to de.ne the set Dg of good abstract ele\u00adments independently of a parameter con.guration \n.: .d .D.Sd . ..(d) ..s ' . ..(d).qc(s ' )= true .. .d .D.Sd . ..(d) . d . Dg .. .d . Dg.Sd . ..(d) .. \n.. ' .. ~ . ' ..d . Dg.Sd . .. (d) (4) The .rst equivalence uses the de.nition of Dg, and the second \nequivalence and the left-to-right implication of the third follow from standard reasoning in classical \nlogic. The remaining right\u00adto-left implication in the last equivalence relies on the following condition \non ~: . ~ . ' =.{..(d) | d . D} = {.. (d) | d . D} as well as the fact that if ..(d)= .. (d ' ), then \nboth d and d ' belong to Dg, or neither does so. Finally, we use the last condition of having coupled \ncomponents to reach the property on the result N of our generic algorithm. By the third condition of \nhaving coupled components, the property in (4) is equivalent to ~ . '' .. ' ,. '' .. ~ . ' . . ' . (.s \n. Sd..a . Auxs.Fs(a) a ..(p, v) . Gs(a).. '' (p)= v). Since ~ is an equivalence relation, the property \nabove means the same as the following condition: '' ' .. .. ~ . ..s . Sd..a. Fs(a) a ..(p, v) . Gs(a).. \n(p)= v. In what follows, we transform the second conjunct of the condition until we reach our target \nproperty for N: (.s . Sd. .a. Fs(a) a ..(p, v) . Gs(a).. ' (p)= v) .. .s . Sd. .(p, v) . Gs(leastFix \nFs).. ' (p)= v .. .(p, v) .{Gs(leastFix Fs) | s . Sd}.. ' (p)= v .. .(p, v) . N. . ' (p)= v. The last \ntwo equivalences are standard equivalence-preserving steps from logic. The right-to-left direction of \nthe .rst equivalence holds, because Fs(leastFix Fs) leastFix Fs. Now, it remains to show the left-to-right \ndirection of the same equivalence. To do so, we pick s . Sd, and assume that for some a0 . Auxs, Fs(a0) \na0 ..(p, v) . Gs(a0)..(p)= v. (5) Since Fs is monotone on a complete lattice, leastFix Fs is the least \nelement in Auxs satisfying Fs(a) a. Hence, leastFix Fs a. (6) Furthermore, since Gs is monotone, Gs(leastFix \nFs) is a subset of Gs(a). This subset relationship and the second conjunct of the property (5) for a0 \nimply that .(p, v) . Gs(leastFix Fs)..(p)= v (7) We get the right side of the second equivalence from \n(6) and (7). D 5. Instance analyses Following our general recipe for solving the NC problem, we have \ndeveloped algorithms for solving the problem for two instance analyses. In this section, we describe \nthese algorithms. We start with a model of concrete program states. This storage model is used by both \ninstance analyses, as it is or in a slightly adjusted form. Our storage model de.nes a set of concrete \nstates of a given heap-manipulating program. It assumes the nonempty set PC of program positions in the \ngiven program. Also, the model assumes .ve nonempty disjoint sets: a .nite set LVar for local variables, \nanother .nite set GVar for global variables, yet another .nite set Fld for .elds, and two countable sets, \nLoc for objects and AllocSite for allocation sites2. The formal de.nition of our model is given by these \nequations: ILoc = AllocSite \u00d7 Loc Val = ILoc .{nil} Local = LVar . Val Global = GVar . Val Heap = ILoc \n\u00d7 Fld -.n Val Sbase = {(pc, ., p, s) . PC \u00d7 Local \u00d7 Global \u00d7 Heap | there are no dangling pointers in \n., p and s} Intuitively, (h, o) . ILoc means an object o instrumented with its allocation site h. Such \ninstrumented objects and nil form the set of values. The storage model de.nes states as tuples of four \ncomponents. 3 The .rst is the current program position pc, and the other two, denoted . and p, hold the \nvalues of local variables and global variables, respectively. The last component is the heap s with .nitely \nmany allocated objects. Note that we treat local and global variables separately. This separation helps \nformulate one of our instance analyses below. We consider two analyses over the storage model: 2 Although \nthere are in.nitely many values for denoting allocation sites, only a .nite subset of them are used in \na given program, because the program includes only .nitely many instructions for memory allocations 3 \nThe formal statement of the absence of dangling pointers is: range(.) . range(p) . range(s) .{l |.f. \n(l, f) . dom(s)}.{nil}. 1. Thread-escape analysis: It attempts to prove that at a given program position \npc, a particular local variable x never stores an object that is reachable from any global variable. \nNote the use of our separation of local variables from global variables. 2. Points-to analysis: This \nanalysis tries to show that program variables x and y always point to different heap objects at all program \npositions.  The objectives of both analyses have the same format, and de\u00admand the proof that a certain \nquery should hold for all reach\u00adable program states. We denote these queries by qlocal(pcq,xq) and qnoalias(xq,yq). \n5.1 Thread-escape analysis Our .rst instance analysis is a fully .ow-and context-sensitive thread-escape \nanalysis. It answers the query qlocal(pcq,xq), which asks whether, at program position pcq, local variable \nxq never points to an object that is reachable from global variables. The thread-escape analysis summarises \nobjects in a program state using two abstract locations L and E, such that L abstracts nil and a set \nof objects that are not reachable from global variables, and E abstracts the set of all remaining objects \nin the state. Thus, E includes all objects reachable from any global variable, and possibly more. The \nabstract domain tracks outgoing .elds from objects summarised by L, and it is de.ned as follows: Val \n= {L, E} Local = LVar .P(Val ) Heap = Fld .P(Val ) D = PC . Local \u00d7 Heap An abstract heap is a map from \n.elds to sets of abstract locations. This map concerns only the objects summarised by L, and overap\u00adproximates \nthe values stored in the .elds of these objects. Note that we do not track values stored in global variables \nor objects sum\u00admarised by E. This is our intentional choice based on the following observation: if an \nobject is reachable from a global variable, it usu\u00adally remains so, and as a result, tracking what are \nstored in such escaping objects does not normally help improve precision of the analysis. The thread-escape \nanalysis is an instance of our parametrised static analysis that has coupled components. Its parameters \nare de.ned as follows: Param = AllocSite PVal = {L, E} PCon.g = Param . PVal . ~ . ' .. . = . ' Parameters \nare allocation sites, and parameter con.gurations . map them to one of the abstract locations L and E. \nSetting an allocation site h to v . PVal entails that objects allocated at h are summarised initially \nby v. This initial membership of a newly created object can change, but only in a limited manner: an \nobject can move from L to E but not vice versa. In this way, a parameter con.guration controls how objects \nare abstracted using L and E, and it affects the precision and scalability of the analysis, because the \nanalysis generally tracks information about L more precisely but at a higher cost. Finally, the thread-escape \nanalysis does not have symmetry among component analyses, so that the equivalence relation on parameter \ncon.gurations is simply the equality. The intuition described so far on the analysis is formalised by \nour concretisation map .., which we will now explain. For a set L .P(ILoc) of objects, let absL : Val \n. Val be the following function, which abstracts concrete values in Val: absL(v)= if (v . L .{nil}) then \nL else E. The subscript L here provides the meaning of the abstract location L, which our abstraction \nfunction abs exploits in a standard way to abstract concrete values. Using this value abstraction, we \nde.ne concretisation maps .. : D.P(Sbase) as follows: (pc, ., p, s) . ..(d) .. .. ,s .d(pc)=(. ,s ) \n. (.L .P(ILoc). (.x . LVar. absL(.(x)) . . (x)) . (.(l, f) . (L \u00d7Fld) n dom(s). absL(s(l, f)) . s (f)) \n. (.(l, f) . (ILoc \u00d7 Fld) n dom(s).s(l, f) . L =. l . L) . (.g . GVar.p(g) . L) . (.(h, a) . L. .(h)= \nL)). This de.nition requires that the abstract location L should have an appropriate interpretation as \na set L of objects, with respect to the abstract stack . and heap s at pc. By the word appropriate , \nwe mean that L should satisfy the .ve conjuncts given above. The .rst two of these conjuncts express \nthat . and s overapproximate values that are stored in local variables and in .elds of objects in L. \nThe next two are concerned with L containing only objects that are unreachable from global variables. \nThey say that L is closed under backward pointer reachability and it does not contain any object stored \nin any global variable. Hence, when these conjuncts hold, no object in L can be reached from global variables. \nFinally, the last conjunct says that all objects in L are allocated at sites mapped by . to L. Equivalently, \nit says that L never contains objects from sites mapped by . to E. This is the place where the concretisation \ndepends on the parameter con.guration ., and the conjunct describes a unique property of the .-component \nanalysis, which holds because objects from sites mapped to E are abstracted using E and this membership \nin E never changes during the analysis. We order P(Val ) using the subset relation, and Local and Heap \nby the pointwise extension of this subset order. Then, from these order relations of Local and Heap , \nwe construct the order on our abstract domain D, again using a standard pointwise exten\u00adsion for the \nproduct and function spaces. LEMMA 7. The abstract domain D is a complete lattice. Further\u00admore, .. is \nmonotone for every . . PCon.g. 5.1.1 NC algorithm Assume that we are given a query qlocal(pcq,xq) for \nsome program position pcq and a local variable xq. Our NC algorithm for this query takes a .nite set \nSd .Sbase such that every state s . Sd satis.es the query. Then, the algorithm computes a subset N of \nParam \u00d7 PVal, which describes a necessary condition for proving the query, as formulated by the equivalence \n(1) in Section 3. Our algorithm works as follows. Given an input Sd, it iterates over every state s =(pc, \n., p, s) . Sd with pc = pcq, and cal\u00adculates backward pointer reachability, starting from the queried \nobject .(xq). Concretely, the backward reachability .rst looks up the object stored in variable xq in \nthe state s, then it computes all the objects that reach object .(xq) via .elds in the state, and .nally \nit takes the allocation sites As of the resulting objects and builds the set of parameter binding Ns \n= {(h, L) | h . As}. Once all the iterations are completed, the algorithm gathers the Ns s and returns \n their union N = Ns as a result. s.Sd Formally, the NC algorithm is an instantiation of the generic solution \nin Figure 2, with the following data speci.c to the thread\u00adescape analysis: 1. The .rst datum is the \nsub-domain Dg .D of good ab\u00adstract elements, whose concretisations do not contain bad states violating \nqlocal(pcq,xq). This property of abstract elements should hold regardless of what parameter con.guration \n. is chosen to do the concretisation. Such a sub-domain Dg ex\u00adists for the thread-escape analysis, and \nit has the de.nition: Dg = {d |..,s . (d(pcq)=(. ,s ) ..x. . (x)= \u00d8)=. . (xq)= {L}}. 2. The second datum \nis a .nite lattice Auxs for each state s = (pc, ., p, s) .Sbase. In the case of the thread-escape analysis, \nAuxs = P({l |.f . Fld. (l, f) . dom(s)}.{nil}). 3. The remaining data are monotone functions Fs : Auxs \n. Auxs and Gs : Auxs .P(Param \u00d7 PVal) for all s .Sbase:  F(pc,.,p,s)(L)= {.(xq) | pc = pcq}. L .{l |.f \n. Fld. (l, f) . dom(s) . s(l, f) . L} G(pc,.,p,s)(L)= {(h, L) |.o. (h, o) . L}.{(h, E) |.o, g. (h, o) \n. L . (h, o)= p(g)} The .rst function Fs comes from the query qlocal(xq, pcq) and a condition on L in \nthe concretisation .., which says that L should be closed under backward pointer reachability. The function \ncomputes one-step backward closure of the set L, and extends the result with the object .(xq) stored \nin xq. The sec\u00adond function Gs(L) collects all the allocation sites appearing in L, and turns them to \nconditions that those sites should be mapped to L. When L contains an object (h, o) stored in some global \nvariable (so the object .(xq) is escaping), Gs(L) adds both (h, L) and (h, E), so that no parameter con.gurations \ncan satisfy all the bindings in Gs(L). The computation of the .x\u00adpoint of Fs and its conversion via Gs \nare the formal implemen\u00adtation of the backward reachability calculation alluded to in our informal explanation \nof the algorithm above. LEMMA 8. The data Dg, Auxs,Fs,Gs satisfy the conditions in Section 4. Hence, \nour parametrised thread-escape analysis has coupled components. Also, the induced NC algorithm solves \nthe NC problem for the thread-escape analysis. 5.1.2 Construction of a parameter con.guration The result \nN of our NC algorithm needs to be converted to a speci.c parameter con.guration, so that our parametrised \nthread\u00adescape analysis can be instantiated with that con.guration. We use a simple conversion described \nat the end of Section 3. If N contains two different bindings for a single allocation site, we return \nimpossible to prove. Otherwise, we construct a parameter con.guration .(h)=(if (h, v) . N then v else \nE). Note that in the construction, we chose E as a default value. Usually, setting an allocation site \nto L makes the analysis more precise, but slower as well. Hence, our choice of E corresponds to using \nthe most abstract and also cheapest component of the analysis, which can still separate good states Sd \nobtained by the dynamic analysis from bad states violating the query qlocal(pcq,xq).4  5.2 Points-to \nanalysis Our second instance analysis is a .ow-and context-insensitive points-to analysis. It answers \nthe query qnoalias(xq,yq), which asks whether program variables xq and yq point to different objects \nat all program positions. Our version of the points-to analysis uses parameter con.gura\u00adtions to optimise \nan existing .ow-and context-insensitive points-to analysis. The purpose of looking for such optimisation \nis not to im\u00adprove the existing analysis. It is well-known that the existing anal\u00adysis scales. Rather, \nour purpose is to test whether our approach of combining dynamic and static analyses can produce a cheap \nab\u00adstraction that is still good enough for proving a given query. 4 Our thread-escape analysis .nds a \nminimal abstraction for proving a given query in the following sense. Consider a partial order L, E de.ned \nby L r E, and extend this order to parameter con.gurations pointwise. A successful run of our analysis \ncomputes a minimal parameter con.guration according to this extended order. If one accepts that this \norder correctly compares the degree of abstractions of parameter con.gurations, she or he can see that \nthe computed parameter con.guration is also a minimal abstraction. Our points-to analysis abstracts \nobjects using three abstract lo\u00adcations P1, P2 and P3. These abstract locations form a partition of all \nobjects, and they are used to describe aliasing relationships among program variables and .elds that \narise during program exe\u00adcution. Based on this intuition on abstract locations, we de.ne the abstract \ndomain of our points-to analysis: Loc = {P1, P2, P3} Var = LVar . GVar Stack = Var .P(Loc ) Heap = Loc \n\u00d7 Fld .P(Loc ) D = Stack \u00d7 Heap An abstract state (p ,s ) conservatively describes all objects stored \nin program variables and .elds. Note that a program po\u00ad sition is not a part of an abstract state. This \nomission implies that our abstract state (p ,s ) speci.es a .ow-insensitive property of a given program, \nas expected for any .ow-insensitive static analyses. Our points-to analysis is parametrised by maps from \nallocation sites to abstract locations: Param = AllocSite PVal = Loc PCon.g = {. : Param . PVal |.l . \nLoc . .h. .(h)= l } . ~ . ' .. (k . . = . ' for some bijection k on PVal) A parameter con.guration . \n. PCon.g decides, at each allocation site, which abstract location to use to summarise objects created \nat the site. Since there are only three abstract locations, all sites are partitioned into three groups, \neach of which is summarised us\u00ad ing one abstract location. Unlike the thread-escape analysis, once an \nobject is summarised by an abstract location, say P1, this sum\u00ad mary relationship never changes during \nthe analysis, so the object never becomes summarised by P2 or P3 later. For each parame\u00ad ter con.guration \n. . PCon.g, we care only about how . parti\u00ad tion allocation sites into three groups, not about the names \nof these groups. Whether groups are named (P1, P2, P3) or (P2, P3, P1) does not matter for the behavior \nof the analysis. This independence on names is made explicit by our equivalence relation ~ on param\u00ad \neter con.gurations above. The way that parameter con.gurations control the analysis here can be seen \nin our concretisation map .., which we present next. For sets of objects L1,L2 . ILoc with L1 nL2 = \u00d8, \nlet absL1,L2 : Val .P(Loc ) be the following function that abstracts concrete values: absL1,L2 (v)= if \n(v = nil) then {} else (if v . L1 then {P1} else (if v . L2 then {P2} else {P3})) Note the role of subscripts \nL1 and L2. They give the meaning of P1 and P2, and guide the function to abstract concrete objects according \nto this meaning. These subscripts are usually constructed by taking the inverse image from a parameter \ncon.guration: (L.,L.)=({(h, a) | .(h)= P1}, {(h, a) | .(h)= P2}). 12 Another thing to notice is that \nthe concrete value nil gets abstracted to the empty set. Hence, every abstract value v .P(Loc ) repre\u00adsents \na non-empty set of concrete values, which contains nil. Using both the value abstraction and the subscript \ngeneration explained so far, we de.ne the concretisation map .. as follows: (pc, ., p, s) . ..(p ,s \n) .. (.x . LVar. abs(.(x)) . p (x)) . (.g . GVar. abs(p(g)) . p (g)) . (.(l, f) . (L1 . \u00d7 Fld) n dom(s). \nabs(s(l, f)) . s (P1,f)) . (.(l, f) . (L2 . \u00d7 Fld) n dom(s). abs(s(l, f)) . s (P2,f)) . (.(l, f) . ((ILoc \n- L1 . - L2 .) \u00d7 Fld) n dom(s). abs(s(l, f)) . s (P3,f)) We omit the subscripts L. 1 ,L. 2 from absL.,L. \nto avoid clutter. The 12 .rst two conjuncts ensure the sound abstraction of objects stored in local \nand global variables. The remaining ones guarantee that s overapproximates the concrete heap s, according \nto the partitioning scheme dictated by the parameter con.guration .. We order elements in D in a standard \nway, by extending the subset order for P(Loc ) pointwise over the function space .rst and the product \nspace next. LEMMA 9. The abstract domain D is a complete lattice. Further\u00admore, for all . . PCon.g, their \nconcretisation maps .. are mono\u00adtone, and satisfy the following condition: . ~ . ' =.{..(d) | d .D.} \n= {.. (d) | d .D. }. 5.2.1 NC algorithm Given a set Sd of states from the dynamic analysis, our NC algo\u00adrithm \nfor the points-to analysis .rst computes the following sets Hx and Hy: Hx = {h |.(pc, ., p, s) . Sd. \n.o. (. l p)(xq)=(h, o)}, Hy = {h |.(pc, ., p, s) . Sd. .o. (. l p)(yq)=(h, o)}. The .rst set Hx consists \nof allocation sites of xq-pointed objects that appear in some states of Sd. Similarly, the second Hy \nis made from allocation sites of yq-pointed objects appearing in some s . Sd. Next, our algorithm converts \nHx,Hy to a set N of parameter bindings: N = {(h, P1) | h . Hx}.{(h, P2) | h . Hy}, which is returned \nas a result of the algorithm. Our algorithm is a solution to the NC problem for the points-to analysis. \nThis is because it is an instance of the generic solution in Section 4 with the following data: 1. The \n.-independent set Dg of good elements exists, and it is: Dg = {(p ,s ) | p (xq) n p (yq)= \u00d8}. 2. For \neach state s, we let Xs = P({l |.f. (l, f) . dom(s)}. {nil}), and de.ne Auxs = Xs \u00d7 Xs. Hence, Auxs consists \nof pairs (L1,L2), where Li is a set of allocated locations in s or nil. 3. The remaining data are the \nfollowing functions Fs and Gs for every s =(pc, ., p, s) .Sbase:  F(pc,.,p,s)(L1,L2)=(L1 .{(. l p)(xq)},L2 \n.{(. l p)(yq)}) G(pc,.,p,s)(L1,L2)= {(h, P1) |.o. (h, o) . L1}.{(h, P2) |.o. (h, o) . L2} The function \nFs simply adds the value of xq to the .rst set, and that of yq to the second. Hence, the .xpoint of Fs \nis just ({(. l p)(xq)}, {(. l p)(yq)}), which will be computed by one .xpoint iteration. From this .xpoint, \nthe function Gs gets the bindings of allocation sites to P1 or P2. LEMMA 10. The data Dg, Auxs,Fs,Gs \nsatisfy the conditions in Section 4. Hence, our parametrised points-to analysis has coupled components. \nAlso, the induced NC algorithm solves the NC prob\u00adlem for the points-to analysis. 5.2.2 Construction \nof a parameter con.guration From the result N of the NC algorithm, we construct a parame\u00adter con.guration \n. . PCon.g to be used by our static points\u00adto analysis. Our construction follows the method described \nat the end of Section 3 with only a minor adjustment. As before, if the same allocation site is bound \nto P1 and P2 at the same time by N, our combined dynamic and static analysis stops and re\u00adturns impossible \nto prove. Otherwise, it chooses mutually distinct h1,h2,h3 . AllocSite that do not appear in a given \nprogram nor N, and de.nes N ' = N .{(h1, P1), (h2, P2), (h3, P3)}. Choos\u00ading such hi s is possible since \nAllocSite is an in.nite set and the given program uses only .nitely many allocation sites in AllocSite. \nThen, our analysis uses P3 as a default parameter value, and con\u00adstructs a con.guration .N (h)=(if (h, \nv) . N ' then v else P3). Using P3 as a default value is our decision choice based on the ob\u00adservation: \nwhatever parameter con.guration . is used, the resulting .-component points-to analysis is very cheap, \nhence it is wise to go for the option that maximises precision, which is precisely to use P3 as a default \nvalue. We point out that .N belongs to PCon.g since N ' includes the bindings (h1, P1), (h2, P2) and \n(h3, P3). 6. Experimental evaluation In this section, we evaluate the effectiveness of the two instance \nanalyses of our framework: the thread-escape analysis and the points-to analysis. We implemented these \nanalyses and applied them to the six multi-threaded Java programs described in Table 1, including four \nfrom the DaCapo benchmark suite [4].5 All exper\u00adiments were done using IBM J9 VM 1.6.0 on a Linux machine \nwith two Intel Xeon 2.9 GHz six-core processors and 32GB RAM (though the experiments were run in a single \nthread and the JVM was limited to use up to 4GB RAM). We next evaluate the precision of these analyses \n(Section 6.1), their scalability (Section 6.2), and the quality of the computed abstractions (Section \n6.3). 6.1 Precision In this section, we evaluate the precision of our thread-escape and points-to analyses. \nFigure 3 shows the precision of our thread\u00adescape analysis. Each query to this analysis is a pair (pc, \nx) where pc is the program position of a statement that accesses an instance .eld or an array element \nof an object denoted by local variable x: pc : y = x.f; pc : y = x[i]; pc : x.f = y; pc : x[i]= y; Such \nqueries may arise from any analysis of multi-threaded pro\u00adgrams that desires to reason only about instructions \nthat possibly access thread-shared memory, such as a static race detection tool or a software transactional \nmemory runtime. The top of each column shows how many queries were consid\u00adered for each benchmark, that \nis, queries where program position pc was reached at least once in a concrete trace of the benchmark \non a single supplied input. It shows both the absolute number of considered queries and what fraction \nthey constitute of the queries reachable in a static 0-CFA call graph. The latter provides a mea\u00adsure \nof the coverage achieved by each trace (29 60%). The con\u00adsidered queries are classi.ed into three categories: \nthose disproven by our dynamic analysis of the trace ( Escaping ), those proven by our static analysis \nusing the parameter con.guration inferred by the dynamic analysis ( Local ), and those neither disproven \nnor proven ( Unknown ). On average, 80% of the queries in each benchmark are either disproven (28%) or \nproven (52%), highlighting the effec\u00adtiveness of our approach using only a single trace. Also, note that \nour approach does not preclude the use of multiple traces, which would only further improve both coverage \nand precision. Figure 4 shows the precision of our points-to analysis. Each query to this analysis is \na tuple (pc1, x, pc2,y) where (pc1,x) and (pc2,y) are identical to the queries described above for our \nthread-escape analysis, with the additional constraint that they both 5 Among all benchmarks in dacapo-2006-10-MR2, \ndacapo-9.10-beta0, and dacapo-9.12, we excluded single-threaded benchmarks (bloat, chart, antlr, fop, \netc.), and multi-threaded benchmarks with little concurrency (batik, pmd, etc.), because one of our instance \nanalyses is thread-escape analysis. We also excluded luindex because it is too similar to lusearch, which \nwe include (both are built atop Apache Lucene). We tried the remain\u00ading four benchmarks in our experiments. \n Figure 3. Precision results for our thread-escape analysis.  Figure 4. Precision results for our points-to \nanalysis. access array elements or they both access the same instance .eld, and at least one of them \nis a write. Such queries may be posed by, for instance, a static race detection client to determine whether \nthe statements at pc1 and pc2 can be involved in a race. The top of each column shows how many queries \nwere con\u00adsidered for each benchmark, that is, queries where both program positions pc1 and pc2 were reached \nat least once in the single trace. The traces cover 7 51% of all statically reachable queries. The av\u00aderage \ncoverage is lower for queries of this analysis compared to that of our thread-escape analysis (21% vs. \n37%). This is because the points-to analysis requires both pc1 and pc2 to be reached for a query to be \nconsidered whereas the thread-escape analysis requires a single program position pc to be reached. The \nconsidered queries are classi.ed into three categories: (1) those disproven by our dynamic analysis of \nthe trace ( Aliased ), namely, those where x and y pointed to objects created at the same allocation \nsite at least once; (2) those proven by our static analysis using the parameter con.guration inferred \nby the dynamic analysis ( Not Aliased ); and (3) those neither disproven nor proven ( Un\u00adknown ). Note \nthat category (1) includes not only queries that are false concretely but also queries that might be \ntrue concretely but are impossible to prove using an object allocation site abstraction. Almost all queries \n(99% on average) are either disproven or proven. This result suggests that, in practice, a .ow-and context-insensitive \npoints-to analysis based on object allocation site abstraction for Java does not require representing \nobjects allocated at each site using a separate abstract location; merely three abstract locations (albeit \nspecialised to the query) suf.ce. hedc weblech lusearch sun.ow avrora hsqldb description web crawler \nfrom ETH website download/mirror tool (version 0.0.3) text indexing and search tool (dacapo-9.12) photo-realistic \nrendering system (dacapo-9.12) microcontroller simulation/analysis tool (dacapo-9.12) relational database \nengine (dacapo-2006-10-MR2) # classes app total 44 355 57 579 229 648 164 1,018 1,159 1,525 199 837 # \nmethods app total 234 2,062 311 3,295 1,510 3,893 1,327 6,652 4,245 5,980 2,815 6,752 # bytecodes (KB) \napp total 16 161 20 237 100 273 117 480 223 316 221 491 # alloc. sites 1,587 2,636 2,879 5,170 4,860 \n4,564 Table 1. Benchmark characteristics. The # classes column is the number of classes containing reachable \nmethods. The # methods column is the number of reachable methods computed by a static 0-CFA call-graph \nanalysis. The # bytecodes column is the number of bytecodes of reachable methods. The total columns report \nnumbers for all reachable code whereas the app columns report numbers for only application code (excluding \nJDK library code). The # alloc. sites column is the number of object allocation sites in reachable methods. \npre-process time dynamic analysis static analysis time (serial) time # events hedc weblech lusearch sun.ow \navrora hsqldb 18s 33s 27s 46s 36s 44s 6s 8s 31s 8m 32s 35s 0.6M 1.5M 11M 375M 11M 25M 38s 74s 8m 74m \n41m 86m Table 2. Running time of our thread-escape analysis.  6.2 Scalability In this section, we evaluate \nthe scalability of our thread-escape analysis. Table 2 provides the running time of the analysis. The \npre-process time column reports the time to prepare the bench\u00admark for analysis (resolving re.ection, \ncomputing a call graph, etc.). The dynamic analysis column reports the running time of our dynamic analysis, \nwhich includes the time to instrument the benchmark and run it on a single supplied input. It also reports \nthe length of the trace that was analyzed. The trace includes a separate event for each execution of \neach object allocation instruction, each instance .eld or array element access, and each thread-escaping \ninstruction (i.e., a write to a static .eld or a call to the start() method of class java.lang.Thread). \nWe tried multiple different inputs for each benchmark but found only marginal improvements in coverage \nand precision. This suggests that the truthhood of most queries, and the abstractions for proving them, \nare not sensitive to program inputs, which in turn plays into our approach s favour.6 For each reachable \nquery, the dynamic analysis either disproves the query or provides a parameter con.guration that is used \nby the subsequent static analysis. The static analysis column reports the serial running time of all \ninvocations of the static analysis, one per set of queries for which the same parameter con.guration \nis inferred by the dynamic analysis. Note that these invocations do not share anything and could be run \nin an embarrassingly parallel manner on a multi-core machine or a cluster; hence, we next study the running \ntime of each invocation. Figure 5 provides the cumulative distribution function (CDF) of the running \ntimes of individual invocations of the static analysis for each of our four large benchmarks (all from \nthe DaCapo suite). The blue curve (-.-) shows the CDF of an optimised version of the static analysis \nwhile the red curve (-\u00d7-) shows the CDF of the naive version (we explain the difference between the two \nversions shortly). The CDFs have a separate point for each different running time; the x-intercept of \nthe point denotes that time while 6 We conjecture that the input insensitivity happens, because thread-escape \nanalysis and pointer analysis concern heap structure and pointer connectiv\u00adity, which is less sensitive \nto the speci.c data values in different program inputs (e.g., different keywords to be searched by lusearch, \ndifferent SQL queries to be answered by hsqldb, etc.). the y-intercept of the point denotes the number \nof invocations that took at most that time. The optimised version of the analysis takes almost constant \ntime across different invocations for each benchmark, suggesting that our approach is effective at tailoring \nthe abstraction to each query (Section 6.3 provides more statistics about the computed abstractions). \nSpeci.cally, it takes an average of 7 seconds per invocation and a maximum of 20 seconds over all 1,743 \ninvocations for all benchmarks. The naive version, on the other hand, takes an average of 30 seconds \nper invocation and runs out of memory for the 18 invocations (14 for hsqldb and 4 for sunflow) that are \ndenoted by the points taking 300 seconds the timeout we used for those invocations. The optimised and \nnaive versions of our static thread-escape analysis differ only in how they compute method summaries, \nwhich we explain next. Let (pc ,. ,s ) denote the incoming abstract state for a method. Recall that . \nprovides the incoming abstract value of each formal argument of the method, and s is the in\u00adcoming abstract \nheap. If the incoming abstract value of none of the formal arguments contains abstract location L (i.e., \n.x. L ./. (x)), then the analysis of that method will never read the incoming ab\u00adstract heap s . The \noptimised version of our analysis exploits this observation and analyzes the method in context (., \u00d8) \n(i.e., using an empty incoming abstract heap), whereas the naive version still analyzes it in context \n(. ,s ). In practice, we observed that our top-down inter-procedural analysis repeatedly visits methods \nwith the same incoming abstract environment satisfying the above con\u00addition, but with different incoming \nabstract heaps. Thus, the naive version results in signi.cantly lesser reuse of summary edges than the \noptimised version, evident from the CDFs plotted in Figure 6. These CDFs have a separate point for each \ndifferent number of summary edges that was computed for any method in the bench\u00admark in any invocation \nof the analysis; the x-intercept of the point provides that number while the y-intercept of the point \nprovides the fraction of methods for which at most that many summary edges were computed in any invocation. \nNote that while in both versions, only under a handful of summary edges is computed for the vast majority \nof methods, there are outliers in the naive version for which vastly more summary edges are computed \nthan in the op\u00adtimised version, for all four benchmarks. These outliers cause the 18 invocations described \nabove to run out of memory. It is worth emphasizing that sophisticated optimizations have been proposed \nto ef.ciently compute and concisely represent method summaries over abstract heaps (e.g., [20]). While \nthose op\u00adtimizations are hard to understand and implement, ours is relatively simple yet highly effective \nin practice. Notice that the only reason why our optimization is enabled is due to the unique capability \nof our dynamic analysis to map only a few necessary allocation sites to L and the vast majority of allocation \nsites to E in the parameter con.gurations with which the static analysis is invoked (see Sec\u00adtion 6.3); \nwithout this capability, many methods would be analyzed with incoming abstract environments containing \nL in the abstract Figure 5. CDF of the running time (secs.) of invocations of the optimised and naive \nversions of our static thread-escape analysis.  values of formal arguments, which in turn would prevent \nthe opti\u00admised version of our analysis from ignoring the incoming abstract heap and drastically hurt \nsummary reuse.  6.3 Abstraction quality This section evaluates the quality of the abstractions computed \nby our thread-escape analysis. The key question we want to answer is: how hard is the thread-escape analysis \nproblem to justify using query specialisation and dynamic analysis? We experimented with various purely \nstatic strawman ap\u00adproaches and found that they were not precise or scalable enough. Below, we describe \ntwo such approaches. Strawman 1. The goal of this strawman was to determine how much .ow and/or context \nsensitivity matters for precision. We implemented a .ow-and context-insensitive analysis based on object \nallocation site abstraction, and found that it proved only 13\u00ad34% of the queries for our benchmarks, \nwith an average of 27.5%. In contrast, the combined dynamic-static approach presented in this paper, \nwhich is .ow-and context-sensitive, proves 38-72% of the queries, with an average of 52%. This shows \nthat .ow and/or context sensitivity is likely important for precision. Figure 6. CDF of summary sizes \nof methods in invocations of the optimised and naive versions of our static thread-escape analysis. Strawman \n2. The goal of this strawman was to determine whether a trivial parameter con.guration is precise and \nscalable enough. We used the static thread-escape analysis presented in this paper, but invoked it with \na parameter con.guration that simply sets each allocation site in the program to L, instead of using \nour dynamic analysis to obtain parameter con.gurations tailored to individual queries. We found the resulting \nanalysis to be highly unscalable it ran out of memory on all our six benchmarks but highly precise on \nmuch smaller benchmarks (not shown) that it was able to successfully analyze. This shows that: (1) even \nthough the above trivial parameter con.guration is not the most precise in principle, it is likely very \nprecise in practice; and (2) the ability of our dynamic analysis to avoid unnecessarily mapping sites \nto L is critical in practice for scalability. Lastly, we would like to answer the question: if a few \nallocation sites must be mapped to L for scalability, how small is that number to justify an approach \nas sophisticated as backward pointer reacha\u00adbility, and how different are the allocation sites for different \nqueries to justify query specialisation? We next answer these questions. Figure 7 shows the CDF of the \nnumber of allocation sites that were mapped to L for each query by the dynamic analysis. Recall Figure \n7. CDFs of the number of allocation sites mapped to L in each parameter con.guration, for all queries \nconsidered by our static thread-escape analysis and for just those that were proven.  that these are \nthe sites the dynamic analysis has determined must be mapped to L: mapping any of them to E is guaranteed \nto make the static analysis fail to prove the query. The red curve (-\u00d7-) shows the CDF for all queries \nthat were considered by the static analysis whereas the blue curve (-.-) shows the CDF for only queries \nthat it ended up proving. For each point shown, the x-intercept denotes the number of sites that were \nmapped to L for some query, and the y-intercept denotes the fraction of queries that needed at most those \nmany sites. The relative shapes of the two curves are expected: as the number of sites needed to be mapped \nto L by a query grows, the chance that our dynamic analysis will miss some needed site due to lack of \ncoverage and thereby cause our static analysis to fail to prove the query increases. The CDFs show that, \nwhile just 1-2 sites are needed to prove around 50% of the queries for each benchmark, at least a handful \nof sites are needed to prove another 40%, and tens of sites are needed to prove the remaining 10%. On \naverage, 4.8 sites are needed for all queries that the static analysis attempts to prove, with the highest \nbeing 195 sites for avrora. Figure 8. CDF of the number of queries in each invocation of our static \nthread-escape analysis. Figure 8 shows the CDF of the number of queries in each invocation of our static \nthread-escape analysis for which the same parameter con.guration is inferred by the dynamic analysis. \nFor each point shown, the x-intercept denotes the size of at least one such query set, and the y-intercept \ndenotes the fraction of query sets of at most that size. On average, an invocation of the static analysis \nconsiders 14 queries, with some outliers considering over hundred queries each. This shows that the abstraction \nneeded for proving each query is neither too unique nor too generic. 7. Related work Our approach is \nrelated to techniques for client-driven abstraction specialisation and to techniques for combining dynamic \nand static analyses. We next survey each of these kinds of techniques. Client-driven abstraction specialisation. \nIn the client-driven spe\u00adcialisation problem, a program and a query (assertion) are given and the goal \nis to .nd either a counterexample program trace showing a violation of the query, or an abstraction which \nis cheap yet precise enough for the analysis to ef.ciently prove the query on the pro\u00adgram. There are \ntwo natural solutions to this problem: abstraction re.nement, which starts with a coarse abstraction \nand re.nes it, and abstraction coarsening, which starts with a precise abstraction and coarsens it. The \nCEGAR approach (e.g., [1, 3, 5, 13, 19]) falls in the .rst category, and re.nes the abstraction guided \nby false coun\u00adterexample traces. Besides the CEGAR approach, there are other approaches to re.ne abstractions \nthat are based on a dependence analysis that relates unproven queries to sources of imprecision such \nas .ow-, context-, or object insensitivity in the abstraction [12, 14, 18]. In more recent work, Liang \net al. [15] present ran\u00addomised algorithms to .nd a minimal abstraction that are based on both abstraction \nre.nement and coarsening. A fundamental difference between our approach and all the above techniques \nis that we utilise the concrete trace in order to avoid performing the static analysis at all. This can \nbe handy in cases where the static analysis is exploring too many paths and considering too many con.gurations. \nInterestingly, our method could be combined with abstraction re.nement, e.g. by computing an initial \nabstraction which respects the necessary condition and then applying re.nement if necessary. Combining \nstatic and dynamic analyses. Recent work com\u00adbines static and dynamic analyses in interesting ways. The \nYogi project [2, 9, 10, 17] exploits a dynamic analysis to improve the performance of the abstraction-re.nement \nstep of a static analysis. A form of concolic testing is used to reduce the number of theorem prover \ncalls and case splits due to pointer aliasing, which a static analysis considers during re.nement. Gupta \net al. [11] uses a dynamic analysis to simplify non-linear constraints generated during inference of \nprogram invariants. Yorsh et al. [22] uses a static analysis to construct a concrete trace that is then \nused by an automated theorem prover to check if it covers all executions. It proves safety properties \nif the check passes on the concrete trace and produces a counterexample that can be used to generate \nnew traces if the check fails. One of the interesting questions for a program analysis is how to infer \nthe right invariants to prove a query. One potential idea which is similar to ours is to start from a \ngiven concrete trace and then generalise it. McMillan [16] uses interpolants to perform generali\u00adsation. \nThis approach is interesting but it requires computing inter\u00adpolants which is not yet feasible for many \nprogramming language features. Also, like CEGAR this approach fails to generalise from multiple paths. \nIn contrast we simplify the problem by assuming that the abstract domains already provide generalisation, \nand use the concrete trace to trim inadequate abstractions. Techniques combining random test generation \nand concrete ex\u00adecution with symbolic execution and model generation have been explored [7, 8, 21]. They \nuse symbolic methods to direct tests to\u00adwards unexplored paths to .nd errors faster. But they do not \nuse ab\u00adstraction and in general cannot .nd proofs in the presence of loops. To our knowledge, our technique \nis unique in that it uses a dy\u00adnamic analysis for computing necessary conditions on abstractions, and \nalso for directly providing a static analysis with an abstraction that is specialised to a given query \nand which in most cases suc\u00adceeds in proving the query. 8. Conclusion Ef.ciently .nding good abstractions \nis a long-standing problem in static analysis. Parametrised static analyses offer the .exibility to specialise \nthe abstraction to a given query but also pose a hard search for a suitable parameter con.guration. We \nhave presented a novel solution to this problem: using a dynamic analysis to compute a necessary condition \non the parameter con.gurations for proving a given query. We have given constructive algorithms for two \nin\u00adstance analyses: thread-escape analysis and points-to analysis. We have proven that these algorithms \nindeed compute necessary condi\u00adtions and shown that, in practice, these algorithms are ef.cient and the \nresulting static analyses are both precise and scalable. Acknowledgments We thank Percy Liang for technical \ndiscus\u00adsions on thread-escape analysis and the necessary-condition prob\u00adlem, and Peter O Hearn and the \nanonymous referees for helpful comments on the paper. Yang acknowledges support from EPSRC. References \n[1] T. Ball and S. Rajamani. The slam project: Debugging system software via static analysis. In POPL, \npages 1 3, 2002. [2] N. E. Beckman, A. V. Nori, S. K. Rajamani, and R. J. Simmons. Proofs from tests. \nIn ISSTA, pages 3 14, 2008. [3] D. Beyer, T. A. Henzinger, R. Majumdar, and A. Rybalchenko. Path invariants. \nIn PLDI, pages 300 309, 2007. [4] S. M. Blackburn, R. Garner, C. Hoffman, A. M. Khan, K. S. McKin\u00adley, \nR. Bentzur, A. Diwan, D. Feinberg, D. Frampton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, \nJ. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4 c, T. VanDrunen, D. von Dincklage, and B. Wiedermann. The \nDaCapo benchmarks: Java benchmarking development and anal\u00adysis. In OOPSLA, pages 169 190, 2006. [5] E. \nM. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith. Counterexample-guided abstraction re.nement for \nsymbolic model checking. JACM, 50(5), 2003. [6] P. Cousot and R. Cousot. Abstract interpretation: A uni.ed \nlattice model for static analysis of programs by construction of approxima\u00adtion of .xed points. In POPL, \npages 238 252, 1977. [7] C. Csallner and Y. Smaragdakis. Check n Crash: combining static checking and \ntesting. In ICSE, pages 422 431, 2005. [8] P. Godefroid, N. Klarlund, and K. Sen. Dart: directed automated \nrandom testing. In PLDI, pages 213 223, 2005. [9] P. Godefroid, A. Nori, S. Rajamani, and S. Tetali. \nCompositional may\u00admust program analysis: unleashing the power of alternation. In POPL, pages 43 56, 2010. \n [10] B. S. Gulavani, T. A. Henzinger, Y. Kannan, A. V. Nori, and S. K. Rajamani. Synergy: a new algorithm \nfor property checking. In SIGSOFT FSE, pages 117 127, 2006. [11] A. Gupta, R. Majumdar, and A. Rybalchenko. \nFrom tests to proofs. In TACAS, pages 262 276, 2009. [12] S. Guyer and C. Lin. Client-driven pointer \nanalysis. In SAS, pages 214 236, 2003. [13] T. Henzinger, R. Jhala, R. Majumdar, and K. McMillan. Abstractions \nfrom proofs. In POPL, pages 232 244, 2004. [14] P. Liang and M. Naik. Scaling abstraction re.nement via \npruning. In PLDI, pages 590 601, 2011. [15] P. Liang, O. Tripp, and M. Naik. Learning minimal abstractions. \nIn POPL, pages 31 42, 2011. [16] K. McMillan. Relevance heuristics for program analysis. In POPL, pages \n145 146, 2008. [17] A. V. Nori, S. K. Rajamani, S. Tetali, and A. V. Thakur. The yogi project: Software \nproperty checking via static analysis and testing. In TACAS, pages 178 181, 2009. [18] J. Plevyak and \nA. Chien. Precise concrete type inference for object\u00adoriented languages. In OOPSLA, pages 324 340, 1994. \n[19] J. P. Quielle and J. Sifakis. Speci.cation and veri.cation of concurrent systems in cesar. In Proceedings \nof the 5th International Symposium on Programming, pages 337 350, 1982. [20] N. Rinetzky, J. Bauer, T. \nReps, M. Sagiv, and R. Wilhelm. A semantics for procedure local heaps and its abstractions. In POPL, \npages 296 309, 2005. [21] K. Sen, D. Marinov, and G. Agha. Cute: a concolic unit testing engine for c. \nIn FSE, pages 263 272, 2005. [22] G. Yorsh, T. Ball, and M. Sagiv. Testing, abstraction, theorem proving: \nBetter together! In ISSTA, pages 145 156, 2006.   \n\t\t\t", "proc_id": "2103656", "abstract": "<p>We present a framework for leveraging dynamic analysis to find good abstractions for static analysis. A static analysis in our framework is parametrised. Our main insight is to directly and efficiently compute from a concrete trace, a necessary condition on the parameter configurations to prove a given query, and thereby prune the space of parameter configurations that the static analysis must consider. We provide constructive algorithms for two instance analyses in our framework: a flow- and context-sensitive thread-escape analysis and a flow- and context-insensitive points-to analysis. We show the efficacy of these analyses, and our approach, on six Java programs comprising two million bytecodes: the thread-escape analysis resolves 80% of queries on average, disproving 28% and proving 52%; the points-to analysis resolves 99% of queries on average, disproving 29% and proving 70%.</p>", "authors": [{"name": "Mayur Naik", "author_profile_id": "81100223912", "affiliation": "Georgia Institute of Technology, Atlanta, GA, USA", "person_id": "P2991423", "email_address": "naik@cc.gatech.edu", "orcid_id": ""}, {"name": "Hongseok Yang", "author_profile_id": "81100355747", "affiliation": "University of Oxford, Oxford, United Kingdom", "person_id": "P2991424", "email_address": "hongseok.yang@cs.ox.ac.uk", "orcid_id": ""}, {"name": "Ghila Castelnuovo", "author_profile_id": "81392612902", "affiliation": "Tel-Aviv University, Tel-Aviv, Israel", "person_id": "P2991425", "email_address": "ghila.castelnuovo@gmail.com", "orcid_id": ""}, {"name": "Mooly Sagiv", "author_profile_id": "81100150928", "affiliation": "Tel-Aviv University, Tel-Aviv, Israel", "person_id": "P2991426", "email_address": "mooly.sagiv@gmail.com", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103701", "year": "2012", "article_id": "2103701", "conference": "POPL", "title": "Abstractions from tests", "url": "http://dl.acm.org/citation.cfm?id=2103701"}