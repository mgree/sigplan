{"article_publication_date": "01-25-2012", "fulltext": "\n An Abstract Interpretation Framework for Termination Patrick Cousot CNRS, \u00c9cole Normale Sup\u00e9rieure, \nand INRIA, France Courant Institute *, NYU, USA cousot@ens.fr, pcousot@cims.nyu.edu Abstract Proof, veri.cation \nand analysis methods for termination all rely on two induction principles: (1) a variant function or \ninduction on data ensuring progress towards the end and (2) some form of induction on the program structure. \nThe abstract interpretation design principle is .rst illustrated for the design of new forward and backward \nproof, veri.cation and analysis methods for safety. The safety collecting semantics de.ning the strongest \nsafety property of programs is .rst expressed in a constructive .xpoint form. Safety proof and checking/veri.cation \nmethods then immediately follow by .xpoint induction. Static analysis of abstract safety properties such \nas invariance are constructively designed by .xpoint abstraction (or approximation) to (automatically) \ninfer safety properties. So far, no such clear design principle did exist for termination so that the \nexisting approaches are scattered and largely not comparable with each other. For (1), we show that this \ndesign principle applies equally well to po\u00adtential and de.nite termination. The trace-based termination \ncollecting semantics is given a .xpoint de.nition. Its abstraction yields a .xpoint de.nition of the \nbest variant function. By further abstraction of this best variant function, we derive the Floyd/Turing \ntermination proof method as well as new static analysis methods to e.ectively compute approxima\u00adtions \nof this best variant function. For (2), we introduce a generalization of the syntactic notion of struc\u00adtural \ninduction (as found in Hoare logic) into a semantic structural induc\u00adtion based on the new semantic concept \nof inductive trace cover covering execution traces by segments, a new basis for formulating program prop\u00aderties. \nIts abstractions allow for generalized recursive proof, veri.cation and static analysis methods by induction \non both program structure, con\u00adtrol, and data. Examples of particular instances include Floyd s handling \nof loop cut-points as well as nested loops, Burstall s intermittent asser\u00adtion total correctness proof \nmethod, and Podelski-Rybalchenko transition invariants. Categories and Subject Descriptors D.2.4 [Software/Program \nVeri.cation]; D.3.1 [Formal De.nitions and Theory]; F.3.1 [Spec\u00adifying and Verifying and Reasoning about \nPrograms]. General Terms Languages, Reliability, Security, Theory, Veri.ca\u00ad tion. Keywords Abstract Interpretation, \nInduction, Proof, Safety, Static analysis, Variant function, Veri.cation, Termination. 1. Introduction \nFloyd/Turing program proof methods for invariance and termination [24, 40, 59] have inspired most sound \nstatic analysis methods. For static invariance analysis by abstract interpretation [19, 21], a key step \nis to express the strongest invariant as a .xpoint and next to approximate this strongest invariant to \nautomatically infer an abstract inductive invariant using the constructive .xpoint approximation methods. \nFor static termination analysis, the discovery of variant functions is either decidable in limited cases \n[54] or else is based on the Floyd/Turing idea of variant functions into well-founded sets * Work supported \nin part by the CMACS NSF Expeditions in Computing award 0926166. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 12, January 25 27, 2012, Philadelphia, \nPA, USA. Copyright &#38;#169;c2012 ACM 978-1-4503-1083-3/12/01. . . $10.00 Radhia Cousot CNRS, \u00c9cole \nNormale Sup\u00e9rieure, and INRIA, France rcousot@ens.fr obtained by observing quantities that strictly \ndecrease within loops while remaining lower-bounded, or dually. So most termination analysis methods \nindirectly reduce to a relational invariance analysis hence can reuse classical static analysis methods. \nThe abstract interpretation design principle is instantiated with suitable abstractions for safety and \ntermination analysis, proof, and checking/veri.cation (either potential termination or de.nite termination \nfor nondeterministic systems). The .rst main idea for termination is that there exists a most precise \nvariant function that can be expressed in .xpoint form by abstract interpretation of a termination collecting \nsemantics itself abstracting the program operational trace semantics. This yields new static analysis \nmethods automatically inferring abstractions of that variant function by the constructive .xpoint approximation \nmethods of abstract interpretation. The second main idea introduced in this paper both for safety and \ntermination is that of semantic structural induction, including termination proofs, over trace segment \ncovers and their abstractions. Trace segments are more powerful than binary relations between states \nwhich have been used traditionally in program termination proofs (for example, the transition invariants \nused in [53] are binary relation abstractions of the set of trace segments). Examples include structural \ninduction on the program syntax (including loop invariants \u00e0 la Floyd [40]), induction on data, \u00e0 la \nBurstall [3], the covering of the transition relation closure by well-founded relations, \u00e0 la Podelski-Rybalchenko \n[53], their combinations and generalizations. 2. Fixpoints, .xpoint induction, abstraction, and approximation \nWe express semantics as .xpoints of maps f . A . A i.e. elements x . A such that x = f (x). We let lfp[af \nbe the least .xpoint of f . A . A on the poset (A, [) greater than or equal to a . A, if any. The dual \nnotion is that of greatest .xpoint gfp[af . We write lfp[ f if a is the in.mum of A, and lfp f if the \npartial order [ is clear from the context. By Tarski/Pataria s .xpoint theorem [50, 58], lfp[f = n{P \n. A | a [ P . f (P) [ P} exists for f increasing1 a on a complete lattice (A, [, a, T, u, n) 2 or on \na cpo (A, [, a, u) 3. The .xpoint iterates are f 0 . a, .n . N : fn+1 = f ( fn), f . . n.N fn which is \nlfp[af when a [ f (a) is a pre-.xpoint and f is continuous4,5,6. If f is increasing but not continuous, \ntrans.nite iterations may have to be used [22]. 1 f . A . A is increasing (also monotone, isotone, ...) \non a poset (A, [) if and only if .x, y . A :(x [ y) =. ( f (x) [ f (y)) [36]. 2A complete lattice (A, \n[, ., T, u, n) is a poset s. t. any subset has a least upper bound (lub) u, hence a greatest lower bound \n(glb) n, . = u\u00d8, T = n\u00d8. 3A complete partial order (cpo) (A, [, ., u) is a poset (A, [) such that any \nincreasing chain C . A such that .x, y . C : x [ y . y [ x has a least upper bound (lub) uC, hence has \nan in.mum . = u\u00d8 for the empty chain. 4 f . A . A is continuous on a poset (A, [, u) if and only if for \nall increasing chains C . P(A) such that its lub uC does exist then the lub u f [C] exists and is such \nthat u f [C] = f (uC). 5 P(X) or 2X is the powerset of X i.e. the set of all subsets of a set X. 6 The \npost-image (or image) of X . P(A) by a map f . A . B is f [X] . { f (x) | x . X}. P(B).  Fixpoint induction \nfollows immediately as a sound (.=) and complete (=.) proof method since for all S . A, lfp[f [ S .. \n.P . A : a [ P . f (P) [ P . P [ S . a S is called a speci.cation or invariant and P is an inductive \ninvariant. The idea is that to prove an invariant S , one has to check (in checking/veri.cation methods), \nto guess (in proof methods) or to compute (in analysis methods) a stronger inductive invariant P. Following \n[19, 21], abstraction is formalized by Galois connec\u00adtions7 (A, [) - -. (B, :) between posets (A, [) \nand (B, :) meaning -- .a. that a . A . B, . . B . A and .x . A : .y . B : a(x) : y .. . . x [ .(y). \nWe write (A, [) - - . --- (B, :) when the abstraction a is a . . - - surjective (hence the concretization \n. is injective), (A, [)- --(B, a. . . - - :) when a is injective (hence . is surjective), and (A, [) \n- - . (B, a :) when a is bijective. Given a concrete .xpoint characterization lfp[af of program properties \non complete lattices or cpos (A, [) with a [ f (a) and -- an abstraction (A, [) .. .(B, :), the su.cient \ncommutation - -a condition a . f = f . a (respectively semi-commutation condition a . f :.f . a)8 implies \nthe .xpoint abstraction a(lfp[af ) = lfp:a(a) f (resp. .xpoint approximation a(lfp[a(a) f ) [21]. The \nf ) : lfp:[semi-]commutation condition can be restricted to the iterates of f from a or to the elements \nof A which are [-less that or equal to lfp[af . The result also holds when a is continuous [13]. In absence \nof existence of a best abstraction, similar results can be obtained using only one of the abstraction \nor concretization functions [26]. a 3. Transition semantics We consider a programming language with nondeterministic \npro\u00adgrams P. The set of all states of P is S[P]. The transition relation t[P] . P(S[P] \u00d7 S[P]) describes \nthe possible transitions between a state and its immediate successor states during program execu\u00adtion \n[11, 21]. The program small-step operational semantics is the transition system (S[P],t[P]). When restricting \nto initial states I[P] . P(S[P]), we write (S[P], I[P],t[P]). The termination/block\u00ading states are \u00dft[P] \n{s . S[P] |.s'. S[P] : (s, s') r t[P]). For brevity we write X for X[P] e.g. (S,t), (S, I,t), or \u00dft . \n4. Trace semantics 4.1 Traces We let Sn (S0 \u00d8), S+ = n.N Sn , S * S+ .{e}, S8 , S+8 S+ . S8, and S*8 \nS *. S8 be the set of all .nite traces of length n . N , non-empty .nite, .nite, in.nite, non-empty .nite \nor in.nite, and .nite or in.nite traces over the states S where e is the empty trace. We de.ne the following \noperations on traces, writing |s| for the length of the trace s . S+8 , s[n, m], 0 : n : m for the subtrace \nsn, sn+1, ..., smin(m,|s|-1) of s, and ss' for the concatenation of s, s'. S*8 (with se = es = s and \nss' = s when s . S8). We de.ne the following operations on sets of traces writing S for the set of traces \n{s . S1 | s0 . S } made of one state of S . P(S) (for example, the termination states \u00dft {s . S |.s'. \nS : (s, s') r t} can also be understood as traces of length one {s . S1 |.s . S : (s0, s) r t}), t for \nthe set of traces {s . S2 |(s0, s1). t} made of two consecutive states of the relation t . P(S \u00d7 S), \nT+ T n S+ for the selection of the non-empty .nite traces of T . P(S*8), T 8 T n S8 for the selection \nof the in.nite traces of 7 [21] also introduced formalizations of abstraction using closure operators, \nideals, congruences, etc. and showed all of them to be equivalent to Galois connections. 8. [ is the \npointwise extension of a partial order [ to maps f [.g .x : f (x) [ g(x). T , TT'{ss'| s . T . s'. T'} \nfor the concatenation of sets of traces, and T 9 T'{sss'| s . S . ss . T . ss'. T'} for the sequencing \nof sets of traces T, T'. P(S*8). 4.2 Partial and complete / maximal trace semantics The partial trace \nsemantics T+8[P] . P(S+8[P]) of a program P is a set of non-empty execution traces. In particular, the \npartial trace +8 semantics generated by a transition system (S,t) is t \u00a8[P] such that9 n\u00a8 t [P] {s . \nSn .i . [0, n - 1) : (si,si+1). t[P] }, n ? 0 t8{s . S8 .i . N : (si,si+1). t[P] } [P] +\u00a8 n\u00a8+\u00a88+\u00a8 t ttt \n[P][P], [P][P] . t8[P] . n>0 n The complete or maximal trace semantics tnaM (t \u00a8[P]), [P] ++8 t+= aM \n(t \u00a8[P]) and t+8aM (t \u00a8[P]) are obtained by [P][P] .M .----- the abstraction (P(S+8), .) ---- . (P(S+8), \n.) where aM (T ) {s . T aM n Sn sn-1 . \u00dft[P] } . T8 n.N eliminates those .nite partial computations that \nare not terminated.  4.3 Fixpoint trace semantics The partial trace semantics of a program P can be \ngiven in .xpoint form [28]. .-. +\u00a8- +\u00a8.+\u00a8-8 t = lfp.\u00d8 ft = lfp.\u00d8 ft t8= gfp. S8 f [P][P][P], [P] t [P] \n... +\u00a88- +\u00a8-8 - +\u00a88 t = lfp. f[P] . gfp. f= lfp[f \u00d8 t S8 S8 t [P] t [P][P] . .- +\u00a8-+\u00a8 fSf S t [P]T t \n[P]T 1 . T 9 t[P] 1 . t[P]9 T .- t 8[P]T .- t +\u00a88[P]T 1 ffS t[P]9 T u t[P]9 T where (P(S*8), [, ,, u, \nn) is a complete lattice for the S8 S * computational order (T1 [ T2) (T+ . T+) . (T8. T 8) and 12 12 \n(T1 u T2) (T + . T +) . (T 8n T 8). The .xpoint complete trace 12 12 semantics of a program P is calculated \nby abstraction with aM . .- + .. t+8= lfp\u00d8. ft [P] . gfpS.8 -f8 = lfpS[8 -f+t 8[P] where [P] t [P] .-ft \n+[P]T \u00dft[P] . t[P]9 T, and .-ft +8[P]T \u00dft[P] u t[P] T .9 5. Properties Following [19, 21], properties \nare represented by the set of elements which have these properties. So the properties of programs which \nsemantics are sets of traces in P(S+8) are sets of sets of traces in P(P(S+8)). The collecting semantics \n{T+8[P]) . P(P(S+8)) is the strongest program property10 of a program with trace semantics T+8 [P]. The \ntrace property abstraction of program properties is (P(P(S+8)), .T --- .) .- --.(P(S+8), .) such that \naT aT(P) P and .T(Q) P(Q) . The traditional safety/liveness program properties are relative to the trace \nproperty abstraction of the collecting semantics T+8 aT({T+8[P]}) = [P] . P(S+8). Some program properties \nare not trace properties [5]. An exam\u00adple is all program executions are deterministic which is {{s} \n9[n, m] {n, n + 1,..., m} is the closed interval, \u00d8 when m < n, while [n, m) {n, n + 1,..., m - 1} is \nleft closed and right opened, \u00d8 when m : n. 10 strongest in that the collecting semantics implies all \nother program properties (where logical implication A =. B is interpreted as A . B).  s . S+8) . P(P(S+8)) \n11. The corresponding trace property abstrac\u00adtion is aT({{s} s . S+8)) = . P(S+8) which would allow S+8 \nany non-deterministic behavior so that determinism in the concrete domain P(P(S+8)) is completely lost \nin the abstract domain P(S+8). For safety and termination and from now on, we only have to consider trace \nproperties, which form a complete Boolean lattice (P(S+8), ., \u00d8, S+8 , ., n, \u00ac) where the partial order \n. is logical S+8\\ X 12 implication and the complement is \u00acX . 6. Safety trace semantics We now illustrate \nthe classical abstract interpretation framework by generalizing invariance veri.cation and static analysis \nto arbitrary safety properties. Safety properties are abstractions of program trace properties (essentially \nforgetting about liveness properties). 6.1 Safety abstraction The pre.x abstraction of aset T of traces \nis the topological closure13 pf(s) {s '. S+8.s '' . S*8 : s = s ' s '' ) pf(T ) {pf(s) s . T ) . The \npre.x abstraction expresses the fact that program executions can only be observed for a .nite period \nof time (.T : e r pf(T )). The limit abstraction of a set of traces is the topological closure lm(T) \nT . {s . S8|.n . N : s[0, n] . T ) . The limit abstraction expresses the fact that when observing program \nexecutions for .nite periods of time it is impossible to distinguish between non-terminating and unbounded \n.nite executions. The safety abstraction of a set of traces is the topological closure sf lm . pf = pf \n. lm . pf . The safety abstraction provides the strongest program property resulting from .nite observations \nof program executions (excluding the observation of in.nite executions). (Topological) closures . . A \n. A on a poset (A, :) are abstrac\u00ad 1A . tions14 (A, :) - -- . ---- (.[A], :). . 6.2 Safety trace properties \nThe safety trace properties are SF sf[P(S+8)] = {sf(P) | P . P(S+8)) = {P . P(S+8) | sf(P) = P) . We \nhave the Galois isomorphism lm . - -- (SF, .) - -- . (pf+[P(S+)], .) pf+ where pf+(T ) = pf(T )+ and \nso safety trace properties can equiva\u00adlently be represented by their .nite pre.xes in Sect. 6.4 and 6.5. \n 6.3 Safety semantics The safety semantics of a program P is its strongest safety property tsf+\u00a88+\u00a88 \nsf(t ' pf+ . sf(t [P][P]) [P]) . 6.4 Fixpoint safety semantics It follows, by .xpoint abstraction, that \nthe safety semantics of a program P with operational semantics (S,t) is 11 Assuming inputs, if any, to \nbe part of the states. 12 X \\ Y {x . X | x r Y} is the set di.erence. 13 A topological closure on a poset \n(A, :, .) with partial-order : and lub ., if any, is a map . . A . A which is extensive .x . A : x : \n.(x), idempotent .x . A : .(.(x)) = .(x), and .nite lub-preserving .x, y . A : .(x.y) = .(x)..(y). This \nimplies that . is increasing.A closure is extensive, idempotent, and increasing. 14 1A is the identity \nmap (respectively relation) on the set A mapping any element x . A to itself 1A(x) = x (resp. 1A {(x, \nx)| x . A}). .. tsff-sf - sf = lfp. = lfp. fwhere \u00d8\u00d8 [P] t [P] t [P] . f-sf P T Sforward trace transformer \nt 1 . T 9 t[P] . fSbackward trace transformer. - sf t [ P] T 1 . t[P]9 T  6.5 Proofs in the safety trace \ndomain By .xpoint induction, one immediately gets new forward and backward sound and complete safety \nproof methods15 generalizing invariance [37, 40, 48, 49]. For all safety speci.cations S . SF, tsf[P] \n. S .. .P . SF : S1 . P . t[P]9 P . P . P . S .. .P . SF : S1 . P . P 9 t[P] . P . P . S . Observe that \nforward and backward safety semantics and proof methods are respectively equivalent. This property is \npreserved by relational abstractions in next Sect. 7, but this is not the general case (e.g. with abstractions \nof Sect. 7.6). [42] is an example of static analysis in the safety trace domain. 7. Invariance / reachability \nsemantics Invariance/reachability is an abstraction of safety and so invariance proof methods are abstractions \nof safety proof methods. 7.1 Relational abstraction .R .---- The relational abstraction (SF, .) - -- \n. (P(S \u00d7 S), .) such that aR aR(T) (s0,sn-1)| n > 0 . s . Sn n T ) (1) .R(R) { s . Sn | n > 0 .(s0,sn-1). \nR)abstracts traces by a relation between their initial and .nal states (so that intermediate computations \nare lost in that abstraction). 7.2 Relational invariance / reachability abstraction Applied to a safety \nsemantics which is pre.x-closed, the relational abstraction provides a relation between initial and current \nstates (where, in particular, initial can be any state). The abstraction aR . sf is therefore equal to \nthe relational .R* .----- reachability abstraction (P(S+8), .) - --- . (P(S \u00d7 S), .) such aR* that aR* \n(T ) (s0,si)|.n :0 : i < n . s . Sn n T ) .R* (R) { s . Sn | n > 0 ..i . [0, n): (s0,si). R )abstract \ntraces by a relation between their initial and current states. 7.3 Relational invariance / reachability \nsemantics The relational invariance/reachability semantics of a program P is its strongest relational \nreachability property tR P aR(t+8 [P]) tR* aR(t+\u00a88aR* (t+8aR(tsfaR* (tsf [ P] [P]) = [P]) = [P]) = [P]) \n.  7.4 Fixpoint relational invariance / reachability semantics The commutation condition applied to \nthe transformer of the safety semantics tsf[P] yields the .xpoint characterization of the relational \nreachability semantics of a program P with operational semantics (S,t) .-. tR* f R*- R* = lfp. = lfp. \nf \u00d8 t \u00d8 t [P][P][P] where16 15 In case a temporal logic is used for expressing the inductive safety invariant, \nthis is relative completeness subject to an expressivity hypothesis of the temporal logic ensuring P \n. SF to be expressible in the logic, see e.g. [10]. 16 The post-image (or right-image) of X . P(A) by \na relation r . P(A \u00d7 B) is r[X] {y |.x . X : (x, y). r} also written post[r]X.  f-R* . P (R) forward \ntransformer t 1S . R . t[P] . - R* fbackward transformer. t [ P] (R) 1S . t[P] . R  7.5 Relational invariance \n/ reachability proof methods Applying .xpoint induction to the .xpoint relational reachability semantics, \nwe get sound and complete forward and backward proof methods for a speci.cation S . P(S \u00d7 S) [23], respectively \ngeneralizing [40, 49] and [37, 48]. tR* [P] . S .. .R . P(S \u00d7 S): 1S . R . R . t[P] . R . R . S .. .R \n. P(S \u00d7 S): 1S . R . t[P] . R . R . R . S .  7.6 Variations on invariance / reachability proof methods \nFurther abstractions yield other classical proof methods. It is pos\u00ad .I .---- sible to restrict to the \ninitial states I . P(S), (P(S \u00d7 S), .) ----. aI (P(S \u00d7 S), .) where aI(R) {(s, s ') | s . I .(s, s ') \n. R} (2) .F .---- and the .nal states F . P(S), (P(S \u00d7 S), .) - -- . (P(S \u00d7 S), .) aF where aF(R) {(s, \ns ') | (s, s ') . R . s . F} . (3) It is also possible to use an invariant so as to restrict to the reachable \n.r . states (P(S \u00d7 S), .) - -- . ---- (P(S), .) where ar ar(R) {s '|(s, s ') . R} . (4) Combining (2) \nand (4) we get forward invariance [40, 49] while (3) and the inverse of (4) yield backward invariance \n(called subgoal induction in [48]). Proofs by reductio ad absurdum [23, 35] are obtained by (P(S \u00d7 . \na .--- (P(S \u00d7 S), .) where aa(R) \u00acR. S), .) - - . a a 8. Termination trace collecting semantics Our \nobjective is now to apply the abstract interpretation methodol\u00adogy of Sect. 2, as illustrated in Sect. \n6 7 for the safety properties and their invariance abstractions, to termination. Starting from a collecting \ntrace semantics, we de.ne termina\u00adtion properties by abstraction, derive .xpoint charaterizations by \n.xpoint abstraction, conceive proof and veri.cation methods by .xpoint induction, and design static analysis \nmethods by .xpoint approximation using widening [19]. 8.1 Termination property The termination property \nstates either that all executions in the trace semantics T+8[P] of a program P must always be .nite T+8S+ \n. de.nite termination [P][P]or that the trace semantics T+8[P] may be .nite (hence must not always be \nin.nite) T+8 \" \u00d8 potential termination. [P] n S+ [P] The in.nite extension abstraction a.(T ) T .{s1s2 \n. S8| s1 . S+ . (.s ' 2 . S8 : s1s2 '. T . .s ' 2 . S * : s1s ' 2 r T)} .. .---- is a topological closure \nand so (P(S+8), .) - -- . (a.[P(S+8)], a. .) where .. is the identity. We have t+8. S+.. a. (t+8 P ) \n. S+ [P][P][P], t+8.. a. (t+8 [P] n S+[P] \" \u00d8 [ P] ) n S+ [P] \" \u00d8 and so, if necessary, we only need \nto consider semantics closed by a. . 8.2 Termination trace abstraction The termination trace abstraction \neliminates the program execution traces not starting by a state from which execution may/must terminate. \nExample 1. Consider the example of the non\u00addeterministic program b:[ l:loop [] e:skip ] with states {b, \nl, e}, transitions {(b, l), (b, e), (l, l)} and complete trace semantics {be, e, bllll ..., llll ...}. \n 8.2.1 Potential termination trace abstraction The potential termination or may-terminate trace semantics \nelimi\u00adnates in.nite traces. Example 2. The potential termination trace semantics of program b:[ l:loop \n[] e:skip ] in Ex. 1 is {be, e} since an execution start\u00ading in state b may terminate (by choosing a \ntransition to state e). The corresponding potential termination abstraction is (P(S+8), .mt ' mt . .----- \n.----- (P(S+ ), .) where .) - --- . (P(S+ ), .) and (P(S+8), [) - --- . amt amt amt(T ) .mt(S ) ' mt(S \n) T n S+ , S . S8 and . S . The abstraction forgets about non-terminating executions. This ab\u00adstraction \ncorresponds to Dijkstra s weakest liberal/angelic precondi\u00adtion [37]. It is considered in [11] (together \nwith backward reachabil\u00adity) to automatically compute necessary conditions for termination (in example \n1, this analysis would yield the potential termination states {b, e} proving de.nite non-termination \nin state l). 8.2.2 De.nite termination trace abstraction The de.nite termination or must-terminate trace \nsemantics elimi\u00adnates all traces potentially branching, through local non-determinism, to non-termination. \nExample 3. The de.nite termination trace semantics of program b:[ l:loop [] e:skip ] in Ex. 1 is {e} \nsince in state b there is a possibility of non-termination (by choosing a transition to state l). A trace \nis in the de.nite termination semantics if and only if it is .nite, independently of the potential non-deterministic \nchoices along that trace. The corresponding de.nite termination abstraction is aMt(T ) {s . T+ | pf(s) \nn pf(T 8) = \u00d8} aMt .(P(S+8), [) \". (P(S+), .) is a retract17 and onto but not continuous18. However, \non the following we consider only transition closed semantics [35] i.e. generated by a transition system \n(see counter example 5). Example 4. If T = {ab, aba, ba, bb, ba.} then amt(T ) = {ab, aba, ba, bb} and \naMt(T ) = {ab, aba} since pf(s) n pf(ba.) = \u00d8 for s = ab, aba. This abstraction corresponds to Dijkstra \ns weakest/demonic precondition that is to the de.nite termination analysis we are mostly interested in \nfor transition systems.  8.3 Termination trace semantics The potential termination collecting semantics \nof a program P is therefore de.ned as 17 A retract r .(A, [) \".(B, :) where B . A is increasing and idempotent. \nWe write r .(A, [) \". (B, :) when it is onto. 18 Consider the [-increasing chain Tn {0}.{0i. | i ? n}, \nn ? 0. We have n>0 aMt(Tn) = \u00d8 while nn>0{0i. | i ? n} = \u00d8 so that aMt(n>0 Tn) = aMt({a}) = {a}.  tmtamt(t+8 \npotential termination semantics [P][P]) while the de.nite termination collecting semantics of a program \nP is de.ned as tMtaMt(t+8 de.nite termination semantics. [P][P])  8.4 Fixpoint termination trace semantics \nBy abstraction of the .xpoint trace semantics of Sect. 4.3, the strongest termination property of a program \nP with operational semantics (S[P],t[P]) and termination states \u00dft[P] is . tmt- mt = lfp.\u00d8 ft potential \ntermination [P][P] . - mt f t [P]T \u00dft[P] . t[P]9 T . tMt- Mt = lfp.\u00d8 ft de.nite termination [P][P] . \n- Mt f t [P]T \u00dft [P] . (t[P]9 T n\u00ac(t[P]9 \u00acT )) where the term \u00ac(t[P]9 \u00acT ) eliminates potential transitions \ntowards non-terminating executions.  8.5 Proofs in the termination trace domain Fixpoint induction provides \nformal methods to check .xpoint [P] . S tMt[P] . S . over-approximations, either tmtor Over\u00adapproximations \nyield necessary but not su.cient termination con\u00additions which may introduce spurious in.nite traces \nfor which the proof cannot be done. The proof method is therefore useful to prove invariance under termination \nassumptions19 but not for may/must termination. On the contrary, termination proofs require .xpoint under\u00adapproximations \nS . tmt[P] or S . tMt[P]. Under-approximations yield su.cient but not necessary termination conditions \nand so may eliminate some termination cases for which the termination proof could have been done automatically. \nFixpoint under-approximation proof methods have been proposed e.g. by [15, Sect. 11] and would yield \nthe requested termination proof methods. More classically, we will favor over-approximations for static \nanalysis. 9. Termination domain Programs may not always potentially/de.nitely terminate in all states. \nSo one problem is to determine for which states I . P(S) do executions starting from these states may/must \nterminate. 9.1 Termination domain abstraction This potential/de.nite termination domain semantics is \nprovided by .w --- the weakest precondition abstraction (P(S+8), .) .- --.(P(S), .) aw of the termination \ntrace semantics, such that aw(T ) {s0 | s . T } precondition abstraction. 9.2 Termination domain semantics \ntwmtaw(tmt potential termination [P][P]) twMtaw(tMt de.nite termination. [P][P]) Using Dijkstra s notations \n[37], twmtwlp[P]true and twMtwp[P]true. [P] = [P] =  9.3 Fixpoint termination domain semantics By .xpoint \nabstraction of the termination trace semantics in Sect. 8.4 using transformer commutation, we get Dijkstra \ns .xpoint weakest (liberal) termination precondition semantics [38]20 19 e.g. for Ex. 1, {b, e, l} is \ninvariant, {b, e} is invariant under potential termination hypothesis, and {e} is invariant under de.nite \ntermination hypothesis. 20 The pre-image of Y . P(A) by a relation r . P(A \u00d7 B) is r-1[Y] {x |.y . Y \n: (x, y). r} also written pre[r]Y while \u00acr-1[\u00acY] {x |.y : y . Y =pre[r]Y. .(x, y). r} is r twmtf-wmt \n= lfp.\u00d8 .t weakest liberal termin. precond. [P][P] . f-wmt -1[R] t [P](R) \u00dft[P] . t[P] twMtf-wMt = lfp.\u00d8 \n.t weakest termination precondition [P][P] f-wMt -1[R] n . -1[\u00acR]) . t [P](R) \u00dft[P] . (t[P]\u00act[P] 9.4 \nProof and static analysis in the termination domain As was the case in Sect. 8.5, .xpoint induction is \nuseful for over\u00adapproximations, which can be automatically inferred by static analy\u00adsis [11, 12]. On \nthe contrary, termination proofs require under\u00adapproximations [15, Sect. 11] proof methods. Although \nstatic under\u00adapproximation analysis is possible (e.g. [34]), this is not the termi\u00adnation proof technique \nwhich is used in practice [38]. 10. Termination proofs for the trace semantics generated by a transition \nsystem In practice a termination proof is decomposed in two parts. First a necessary termination condition \nis found by over-approximating twmt[P] or twMt[P]. Then this necessary termination condition is shown \nto be su.cient by Floyd/Turing variant function method (e.g. [17]) or inversely (e.g. [8]). This corresponds \nto di.erent abstractions, speci.c to the trace semantics generated by a transition system, that we now \nelaborate. 10.1 Transition-based termination proofs A program which trace semantics is generated by a \ntransition system (S,t) de.nitely terminates if and only if the program transition relation is well-founded21. \nt+8.. (S,t) is well-founded. [P] . S+[P] In practice one considers traces starting from initial states \nI . P(S), e.g. I is the termination domain of Sect. 9. In that case a program which trace semantics is \ngenerated by a transition system (S,t)de.nitely terminates for traces starting from initial states I \n. P(S) if and only if the program transition relation restricted to reachable states is well-founded. \nai(I)(t+8[P]) . S+[P] .. (ar(ai(I)(t+8[P])),t) is well-founded .i(I) . where the initialization abstraction \n(P(S+8), .) - ------- (P(S+8), . ai(I) .) is ai . P(S) . (S+8 . S+8) initialization abstraction ai(I)T \n{s . T | s0 . I) .r --- and the reachable states abstraction (P(S+8), .)- --(P(S), .) . a.r is . S*8 \n: sss ' ar(T ) {s |.s . S * ,s '. T ) reachability abstraction. The transition-based termination proof \nmethod is sound and com\u00adplete. As noticed in Sect. 9, the precondition I can be inferred au\u00adtomatically \nby static analysis. Moreover, an over-approximation R . ar(ai(I)(t+8[P])) = t[P] *[I] 22 of the reachable \nstates can be computed by classical abstract interpretation algorithms [19]. 21 A relation -. P(W \u00d7 W) \non a set W is well-founded if and only if there is no strictly decreasing in.nite chain x0 > x1 > ... \n> xn > xn+1 > ... of elements x0, x1,..., xn, xn+1,... of W. (W, -) is called a well-founded set. A (total) \nwell-order is well-founded (total) strict order relation -. The set of all well-founded relations in \nP(W \u00d7 W) is written Wf(W \u00d7 W). 22 t* is the re.exive transitive closure of a binary relation t.  10.2 \nTransition abstraction If the program semantics T+8[P] is not generated by a transition -a (T+8. system \nwe might consider the transition abstraction (S, [P])) - . . .--- where the transition abstraction (P(S+8), \n.) - -.(P(S \u00d7 S), .) - . a is -' s '. a (T ) {(s, s ') | .s, s ' : sss . T} transition abstraction but \nthe following counter-example shows that the condition is su.cient but not necessary. Counter-example \n5. Let T {ab, ba} be a trace semantics. The - . corresponding transition relation ta (T) = {(a, b), (b, \na)}generates the in.nite trace abababa ... and so the transition relation t restricted to the reachable \nstates {a, b} is not well-founded. Another counter-example is fairness [35]. In the following, we consider \ncomplete/maximal trace semantics T that are transition . closed (also generated by a transition system) \nthat is -a (T) = T or equivalently T is closed by elimination of strict pre.xes, closed by extension \nby fusion, and closed by limits [35, Th. 2.6.8]. 11. Variant semantics It remains to design veri.cation \nand static analysis methods to show that (R,t) is well-founded where R . ar(ai(I)(t+8[P])) = t[P] *[I] \nover-approximates the reachable states. There are two important remarks. 1. If t . r and (R, r) is well-founded \nthen (R,t) is well-founded. 2. (R,t) is well-founded if and only if there exists a variant function \n. . S .e W 23 into a well-founded set (W, -) which domain is R 24.  So for the traces generated by a \ntransition system, termination can be proved by mapping invariant states to a well-founded relation which \nis the principle of Floyd/Turing variant function method. 11.1 Variant function A variant function . \n.e S . W is a partial function from the set of states into a well-founded set (W, -) where -is a well\u00adfounded \nrelation on the set W (and . is its non-strict version). With appropriate hypotheses on states and the \ntransition relation, the co\u00addomain of the variant function can be .xed a priori and the variant function \ncan be found by constraint solving e.g. [17, 54]. However, these methods are not as general as Floyd/Turing \ns method. In mathematics, the ordinals provide a standard well-founded set thanks to ranking functions \nmapping each element of a well\u00adfounded set to its ordinal rank. So, up to a ranking function, the well-founded \nset (W, -) can always be chosen as the class (O,<)of ordinals. The intuition is that any execution s \nstarting in a state s0 . dom(.) must terminate in at most .(s0) execution steps while an execution s \nstarting in a state s0 r dom(.) might not terminate. We have t . {(s, s ') . S2 | s . dom(.) . .(s) > \n.(s ')}and this relation is well-founded on states, proving termination. 11.2 Variant abstraction A variant \nfunction is an abstraction of a set of .nite traces. It is a partial function which domain is the set \nof terminating states. Its 23 A .e B (resp. A . B) is the set of partial (resp. total) maps from set \nA into set B. We write dom( f ) for the domain of a partial function f . A .e B and codom( f ) for its \nco-domain. If f . A . B then dom( f ) = A. 24 For a proof, take (W, -) to be the ordinals (O,<) and . \nto be the ordinal rank of elements of R for the well-founded relation t. value is an upper bound of the \nremaining number of steps to termination. It may be trans.nite for unbounded non-determinism with unbounded \nexecution trace lengths. Let us de.ne ark . P(S \u00d7 S) . (S .e O) ranking abstraction ark(r)s 0 when .s \n'. S : (s, s ') r r ark(r)s '' sup {ark(r)s + 1 s . dom(ark(r)) .(s, s ') . r }25 . ark(r)s extracts \nthe well-founded part of relation r and provides the rank of the elements s of its domain. av(T ) does \nthe same for the transition relation by abstracting the set T of .nite traces av . P(S+) . (S .e W) variant \nabstraction av(T ) . s .ark(- . a (T))s . ' mt . .v . .-------- It follows that the abstraction (P(S+8), \n[) - ------ . (S . W, [v) e av . amt holds for potential termination and (P(S+8), [) . (S .e W, [v)for \nde.nite termination. These abstractions state, by def. of [, that adding .nite execution traces or suppressing \nin.nite traces can only, by def. of [v, augment the termination domain and, maybe, increase execution \ntimes. It follows that the computational variant order is . [v . ' dom(.) . dom(. ' ) ..x . dom(.): .(x) \n. . ' (x) . 11.3 Variant semantics A variant function can always be found by abstraction of the termination \nsemantics into a variant semantics tmv av(tmt PP ) potential termination variant tMvav(tMt de.nite termination \nvariant. [ P] [ P] ) This yields new termination proof methods and static analysis methods by abstraction \nof this .xpoint de.nition. 11.4 Fixpoint variant semantics By .xpoint abstraction of the .xpoint termination \ntrace semantics of Sect. 8.4, we get the .xpoint characterization of the variant semantics26,27 . tmv- \nmv = lfp[.v ft potential termination [P] \u00d8 [P] . -fmv t [P](.)s ( s . \u00dft[P] ? 0 : sup {.(s ') + 1 ' s \n. dom(.) .(s, s ') . t[P] } ) tMv. = lfp[.v -fMv t de.nite termination [P] \u00d8 [P] . -fMv t [P](.)s ( s \n. \u00dft[P] ? 0 : sup {.(s ' ) + 1 s '. dom(.) .(s, s ') . t[P] . '' '' .s : (s, s '') . t[P] =. s . dom(.) \n} ) . Example 6. Consider the trace semantics as rep\u00adresented on the right. We have represented below \nthe .xpoint iterates for the corresponding potential and de.nite variant functions. Unlabelled states \nare outside the variant function domain. 25 This can be generalized from (O,<) to well-orders (W, -) \nusing succ(x) {y . W | x < y . $z . W : x < z < y} and sup is an upper-bound. For ordinals succ(x) = \n{x + 1} is the successor ordinal and sup is the lub. 26 The partial map . .e O is totally unde.ned and \nhas dom(.\u00d8. \u00d8. S\u00d8) 27 The conditional is ( true ? a : b ) a and ( false ? a : b ) b.  De.nite termination \nThe potential variant can be used as a run-time check of de.nite non-termination (since beyond 4 execution \nsteps termination is inevitable). This general observation is not in contradiction with the fact that \ntermination is not checkable at runtime since here it relies on a prior static analysis considering all \npossible executions. . - Mv Example 7. The de.nite termination variant semantics lfp[\u00d8.v ft [P] of the \nfollowing program P int main () { int x; while (x > 0) { x = x -2; }} . is the limit .. of the iterates \n.n , n . N of -fMv[P] from \u00d8.. t Considering only one loop head control point so that the state can be \nreduced to the value x of x, we have . - Mv f( x : 0 ? 0 : sup { .(x - 2) + 1 | x - 2 . dom(.)} ) . t \n[P](.)x The program being deterministic, the potential termination equation . . = -fmv[P](.) is similar. \nThe .xpoint iterates are28, 29 t .0 = \u00d8. .1 = . x . [-8, 0] .0 .2 = . x . [-8, 0] .0 ... x . [1, 2] .1 \n.3 = . x . [-8, 0] .0 ... x . [1, 2] .1 ... x . [3, 4] .2 ... .n = . x . [-8, 0] .0 ... x . [1, 2 \u00d7 (n \n- 1)] .(x + 1) \u00f7 2 ... .. = . x . [-8, 0] .0 ... x . [1, +8] .(x + 1) \u00f7 2 . 11.5 Termination proof method \nThe variant semantics is sound and complete to prove termination of a program P for initial states I \nsince ai(I)(t+8[P]) . S+[P] .. I . dom(tMv[P]) . .. .. . S . O : lfp[v -fMv . . I . dom(.) e \u00d8.t [P] \n[v ai(I)(t+8[P]) n S+[P] \" \u00d8 .. I . dom(tmv[P]) . .. .. . S . O : lfp[v -fmv . . I . dom(.) e \u00d8.t [P] \n[v Applying .xpoint induction to check for the least .xpoint over\u00adapproximation, we get a termination \nproof method. We have . O : tMv .. . S e. [P] [v . ... : lfp[v -fMv . (.xpoint semantics of Sect. 11.4S \n\u00d8.t [P] [v . ... : .. ' :.. '. -fMv t [P]. '[v . '[v . (.xpoint ind.S \u00d8[v . . ' . ... ' : -fMv t [P]. \n'[v . ' (def. [v and choosing . = . ' S ... : . s . ( s . \u00dft[P] ? 0 : sup{.(s ' ) + 1 |.s ' : (s, '' \n' s ') . t[P] . s . dom(.) ..s : (s, s ') . t[P] =. s . . dom(.)} ) [v . (def. -fMv t ... : . s .sup{.(s \n' ) + 1 |.s ' : (s, s ') . t[P] . s '. dom(.) ..[Ps]S' : (s, s ') . t[P] =. s '. dom(.)}[v . (since .s \n: .(s ') ? 0 and .s ' : (s, s ') . t[P] implies s r \u00dft[P]S ... : dom(. s .sup{.(s ' ) + 1 |.s ' : (s, \ns ') . t[P] . s '. dom(.) ..s ' : (s, s ') . t[P] =. s '. dom(.)}) . dom(.) ..s . dom(.): sup{.(s ' ) \n+ 1 |.s ' : (s, s ') . t[P] . s '. dom(.) ..s ' : (s, s ') . t[P] =. s '. dom(.)} : .(s)  28 . . joins \npartial functions with disjoint domains f1 ..f2(x) f1(x) if x . dom( f1) and f1 ..f2(x) f2(x) if x . \ndom( f2) where dom( f1) n dom( f2) = \u00d8. 29 \u00f7 is the integer division. (def. [v for ordinalsS '' ... : \n.s . dom(.): (.s . dom(.): (s, s ') . t[P]) =. (.s : ' (s, s ') . t[P] =. s . dom(.) . .(s ' ) <.(s)) \n(def. supS . .(W, -) : .. . S e'. dom(.): (s, . W : .s . dom(.): (.s '' s ') . t[P]) =. (.s : (s, s ') \n. t[P] =. s . dom(.)..(s ') \u00ad .(s)) (since an ordinal is the order type of a well-founded setS ..I . \nP(S): .(W, -) : .. . S e'. I : (s,. W : .s . I : (.s '' s ') . t[P]) =. (.s : (s, s ') . t[P] =. s . \nI . .(s ' ) -.(s)) (choosing I = dom(.).S This calculational design yields the following de.nite termination \ninduction principle .. ai(I)(t+8[P]) . S+[P] de.nite termination proof .I . P(S): .(W, -) : .. . S e. \nW : I . dom(.) ..s . I : ' (.s . I : (s, s ') . t[P]) =. '' (.s : (s, s ') . t[P] =. s . I . .(s ' ) \n-.(s)) . A similar calculational design, yields the potential termination induction principle ai(I)(t+8[P]) \nn S+[P] \" \u00d8 potential termination proof .. .I . P(S): .(W, -) : .. . S e . W : I . dom(.) ..s . I : ' \n(.s . I : (s, s ') . t[P]) =. (.s '' . I : (s, s '') . t[P] . s '' . I . .(s '' ) -.(s)) . Observe that \nthe .xpoint variant semantics of Sect. 11.4 is calculated backwards (the variant function increases on \nprevious steps) but that the termination induction principles proceed forward (the variant function decreases \non next steps). Example 8. A similar induction principle is proposed in [35, Ch. 5.2.3] for relational \ninevitability proofs (a state must be reached that relates to the initial state as given by a speci.cation \nrelation .). The following example is used in [35, Ch. 5.2.5] to show that, the invariant and variant \nfunction must also be relational, that is relate the current and initial state: S {1, 2, 3}, I {1, 2}, \nt {(x, x + 1)| x, x + 1 . S}, . t. We can prove termination with assertions, no relational invariants \nbeing needed. For the above example, choose I =S, (W, -) = (S,<), .(1) = 2, .(2) = 1, .(3) = 0. This \nexample shows that termination proofs are simpler than inevitability proofs. Example 9. For the program \nof Ex. 7, the de.nite termination proof for the simpli.ed transition system t[P] {(x, x ') | x > 0 . \nx ' = x + 1} requires guessing I = Z, (W, -) = (N,<), . = . x .( x : 0 ? 0 : (x + 1) \u00f7 2 ) and proving \n.x, x '. Z :(x > 0 . x ' = x + 1) =. (.x '' : x '' = x + 1 =. .(x '') <.(x)). Because Turing/Floyd method \nuses the reachability abstraction ar of (4), it is not possible to directly relate states occurring at \ndi.erent times during computations. This is why the program is transformed by using auxiliary variables \nto relate the current values of the variables to their past values. This induces a transformed transition \nsystem, which under the reachability abstraction ar is equivalent to the relational abstraction of the \noriginal transition system by the relational abstraction (1). Example 10. Continuing Ex. 9, the program \nis transformed into int main () { int x, x0; while (x > 0) { x0 = x; x = x -2; }} which consists in \nreasoning on the transformed transition system  t0[P] {((x0, x), (x0' , x ')) | x ' = x .(x, x ') . \nt[P]} . 0 .0 --- This is an abstraction (P(S \u00d7S), .)- --(P(S2 \u00d7S2), .) such that .. a0 a0(t) {((x0, \nx), (x ' ')) | x ' = x .(x, x ') . t} . 0, x 0 The bene.t is that a relational abstraction aR used with \nt is equiva\u00adlent to a non-relational reachability abstraction ar for a0(t). How\u00adever, in both cases, \na limitation is that, for a given control point, it is only possible to refer to one past instant of \ntime when control is at that program point, which is a limitation when compared to the more .exible reasoning \nby induction on traces (see Sect. 15.3). 12. Variant abstraction analysis We get a termination static \nanalysis by abstracting the variant seman\u00adtics. We need an abstraction (S e.. .(A, [) of functions. -- \n . O, [v) - - a Many abstractions of functions have been proposed e.g. [20, 30] that can be reused for \ntermination static analysis. As a simple example, we consider a piecewise linear variant abstraction. \nThe purpose of this new abstract domain is to illustrate the abstraction of .xpoint de\u00ad.nitions of variant \nfunctions with widening, many more abstractions being necessary to cover all practical cases. 12.1 Piecewise \nlinear variant abstraction Let us consider a program with integer variables X = x1,..., xn, n > 0. We \n.rst apply an abstraction of states extracting the numerical variables in the form of an environment \naX . S . (X . Z) so that, by composition, we are left with an abstraction ((X . Z) e[v) -- (A, [). Encoding \nthe partial map by a total . O, .. . - -a map (using . for unde.ned/not in the domain and abstracting \nhigher-order ordinals by T ( unknown/in.nite , e.g. in case of non-termination or unbounded nondeterminism), \nwe can choose (X . Z) . N . {., T}. There is no loss of information for bounded determinism and unbounded \nexecutions are still allowed but disregarded by the abstraction. We can now further abstract by piecewise \nlinear functions. The values xi of each variable xi . X, i . [1, n] are segmented into e1 = -8 < \u00b7\u00b7\u00b7 \n<e ji < \u00b7\u00b7\u00b7 <emi =+8. This provides a partition i ii of the space Zn of values x1,..., xn of the variables \nx1,..., xn. The blocks of the partition are therefore [eiji ,eiji+1), i . [1, n], ji . [1, mi). In practice \nmachine integers are bounded, in which case -8 and +8 are the smallest and largest machine integers. \nThe number of blocks in the partitions can also be limited by widening thus favoring e.ciency of the \nabstract domain to the detriment of precision. 12.1.1 The abstract domain of piecewise linear variants \nThe positive value of the variant function for elements xx = x1,..., xn of each block [eiji ,eiji +1) \nof the partition is a linear expression j1 ji jn e ...e ...e n xa 1 i .xx of the form 30 j1 jijn j1 jijn \nj1 jijn j1 ji jn e ...e ...en e ...e ...en e ...e ...en e ...e ...en 1 i 1 i 1 i 1 i ax1 + ... + a xi \n+ ... + a xn + a 1 i nn+1 j1 ji jn e ...e ...e 1 in where the coe.cients ak . Q, k . [1, n + 1] are rationals \n(or ./T). For example, in two dimensions e1 = -8 e2 e3 e4 =+8 m1 = 4 1 111 -8 = e21 e12e2 e12e2 e12e2 \n 222 e2 ax1 + ax2 + a 2 123 e3 2 m2 = 4 + 8 = e24 j1 ji jn e ...e ...e 30 More rigorously, we should \nwrite the dot product xa 1 in \u00b7 (xx, 1) . The abstract domain is therefore (omitting the case of blocks \nwith . for not in the domain and T for unknown ) ej1 ji jn ...e ...e 1 in A {. xx . Zn . n( e ji : xi \n<eji+1 ? xa .xx : . ) ii 1 i.[1,n], ji.[1,mi) .i . [1, n]: e1 = -8 < \u00b7\u00b7\u00b7 <eji < \u00b7\u00b7\u00b7 <emi =+8. i ii e \nj1 ji jn ...e ...e xa 1 in . Qn+1 . e j1 ji jn ...e ...e 1 in . ji . [1, mi), xi . [eiji ,e ji+1) : xa \n.xx ? 0 } . i 1 When the eiji . Q, i . [1, n], ji . [1, mi) are rationals, this abstrac\u00adtion essentially \nreuses the classical abstractions of intervals [18, 19], linear inequalities [31] and segmentation [33]. \nAn immediate gen\u00aderalization consists in using consecutive segments with symbolic bounds as done in [33] \nfor array content analysis. A further general\u00adization consists in using decision trees [32] instead of \na segmentation of the domain of the abstract variant function. 12.1.2 Piecewise linear variant abstract \ntransformers - . f.mv The abstract transformer [P] abstracting the concrete trans\u00ad .t - mv former f[P] \nof Sect. 11.4 is applied blockwise by computing t the abstract pre-image of each block by assignments \nor tests. The condition in tests may split the block into sub-blocks for which the condition is true \nor false. Example 11. Here is an example of .rst iteration of the backward termination analysis of an \nexit preceded by a test. The initialization of the .xpoint iterates by . x . [-8, +8] .. indicates potential \nnon\u00adtermination. The exit enforces termination in 0 steps. The test splits the block [-8, +8] into [-8, \n0] and [1, +8]. /* . x . ( x . [-8, 0] ? 0 : x . [1, +8] ? . ) */ if (x <= 0) { /* . x . [-8, +8] . 0 \n*/ exit; /* . x . [-8, +8] . . */ } else { /* . x . [-8, +8] . . */ ... } An assignment backward propagates \nthe linear variant functions by blocks which are incremented by 1 step, but for those corresponding to \nnon-termination. Example 12. Assuming -8 - 2 = -8 and +8 + 2 =+8, the backward termination analysis of \nthe following assignment is /* . x . ( x . [-8, 2] ? 1 : x . [3, +8] ? . ) */ x = x -2; /* . x . ( x \n. [-8, 0] ? 0 : x . [1, +8] ? . ) */ 12.1.3 Piecewise linear variant abstract order The abstract order \n[v .rst uni.es segments of the domain into a common re.ned partition by segmentation of each variable \n(as in [33, Sect. 11.4: Segmentation uni.cation]) and then compares the linear expressions blockwise, \nassuming . is the in.mum and T is the supremum (so that the domain comparison of Sect. 9 is done implicitly \nby the fact that the unde.ned . is used outside this domain). Example 13.  12.1.4 Piecewise linear \nvariant abstract join .v Similarly, the join .1 u .2 .rst uni.es blocks of the partitioned domains of \n.1 and .2 into a common re.ned partition. Then the linear expressions are joined blockwise. This blockwise \njoin u v is j1 ji jn xa.x de.ned for each block e1 ...ei ...en , i . [1, n], ji . [1, mi] of ji ji +1 \n'. Qn+1 the partition such that .i . [1, n], .xi . [ei ,ei ], .xa , j1 ji jn ...e ...e a e 1 in j1 ji \njn x.x : xa.x e ...e ...en '' xa 1 i .x : xa .x =. xa.x : xa .x . Example 14. A coarser partition \ncan also be used in the join (as in [33, Sect. 11.4: Segmentation uni.cation]) which is less precise \nbut enforces faster convergence. 12.1.5 Piecewise linear variant abstract widening Finally, the widening \n.1 V.v .2 follows the idea introduced in [20] of widening functions by widening the domain of their parameters \nwith a domain widening V.dv and then their results with a range widening .v Vr . So the blocks of the \npartitioned domains of .1 and .2 are .rst widened using e.g. interval widening V.dv (possibly with thresholds) \nof the blocks with respect to their neighbors in all directions. Example 15. An interval widening for \na two-dimensional domain (x, y). Z2 yields Then the range-widening V.rv increases the gradient (i.e. \nslope in two dimensions) of the variant function of each block in the directions of its domain-widened \nneighbors to over-approximate their respective variants functions (extended to the widened domains). \nExample 16. To enforce convergence, the widening may have to skip to .nitely many given thresholds of \ngradients before abandoning the constraint to T. Example 17. We use two loop unrollings to stabilize \niterations before widening [56]. .0 A = . x . [-8, +8] . . .1 = . x .( x . [-8, 0] ? 0 : x . [1, +8] \n? . ) A .A 2 = . x . [-8, 0] .0 ... x . [1, 2] .1 ... x . [3, +8] .. . '3 = . x .( x . [-8, 0] ? 0 : \nx . [1, 2] ? 1 : x . [3, 4] ? 2 : x . [5, +8] ? . ) .3 = .2 V.v . ' 3 A AA A x . '4 = . x .( x . [-8, \n0] ? 0 : x . [1, 2] ? 1 : x . [3, +8] ? + 1 ) A 2 .4 = .3 AA . The over-approximation of . in Ex. 7, \nby .A is as follows . Notice that the domain of termination is widened which is an over\u00adapproximation \nwhich might include non-termination cases. However, the iterates with widening stop at a post-.xpoint \n.A .- f mv v .A t [P](.A) [ which, by de.nition of the abstract partial order [v ensures that .A is decreasing \non blocks for which it is de.ned. Termination is therefore proven for blocks with either 0 or a strictly \ndecreasing variant. By undecidability, there might be blocks which variant value is T indicating insu.cient \nprecision to conclude. 12.2 Non-linear variant abstraction Besides classical linear relational abstractions \n(e.g. octagons [46], polyhedra [31], etc.) which can be used pointwise as in Sect. 12.1, the variant \nfunction in each block of the partition can also be non\u00adlinear (e.g. polynomials [47], exponentials [39], \netc.). 13. Relational variant semantics To use relational abstractions for static termination analysis, \nwe can further abstract variant functions into relations. 13.1 Relational variant abstraction A variant \nfunction . can be abstracted as the pair of an abstraction of its domain dom(.) by a set abstraction \n(such as e.g. intervals) and an abstraction of its value by (a relational abstraction of) the down\u00adclosed \nrelation r which over-approximates the variant function on its domain that is .s . dom(.), w . S : (s, \nw). r =. w .(s). The abstraction is therefore (the .rst component is redundant but useful for static \nanalysis) arv(.) (dom(.),a.({(s,.(s))| s . dom(.)})) where the down-closure of a relation r . P(S \u00d7 W) \nis a.(r) {(s, w ') | .w : w ' w .(s, w). r} . Observe that the e.ect of the down-closure is to replace \nequalities by inequalities for which numerous abstract domains are available. Moreover, an over-approximation \nof the .rst component is known by Sect. 9 but for correction we either need an under-approximation or \nprove termination for this over-approximation, which is the usual option. For the second component, an \nover-approximation is correct (this over-estimates the termination time). We have31 .v --- (S e..(P(S) \n\u00d7 a.[P(S \u00d7 W)], . \u00d7 .) . . W, [v) - -- av 13.2 Relational variant semantics The relational variant semantics \nof a program P is tmrv arv(tmv P potential termination relational variant [P]) tMrvarv(tMt de.nite termination \nrelational variant. [ P] [P]) ' 31 : \u00d7[ is the componentwise partial order (x, y) : \u00d7[(x , y ') .. x \n: ' x '. y [ y .  13.3 Fixpoint relational variant semantics By .xpoint abstraction of the .xpoint variant \nsemantics of Sect. 11.4, we get, by calculational design, the .xpoint de.nite and potential relational \nvariant semantics32. tmrvlfp.\u00d7. .- mrv = \u00d8.ft potential termination [P][P] . - mrv flet D ' = -1[D] in \nt [P](D, r) D . \u00dft[P] . t[P] (D ' , {(s, 0)| s . \u00dft[P]}. a.({(s,. + 1)| ..s ' : (s, s ') . t[P] . s '. \nD .(s ' ,.). r })) tMrv.- Mrv = lfp.\u00d7. fde.nite termination .t [P] \u00d8 [P] . - Mrv ft [P]((D, r))s let \nD ' = D . \u00dft [P] . (t[P]-1[D] n t[P]-=1[D]) in (D ' , {(s, 0)| s . \u00dft[P]}.{(s,. + 1)|..s ' : (s, s ') \n. t[P] . s '. D .(s ' ,.). r ..s ' : (s, s ') . t[P] =. s '. D ... ' : (s ' ,. ') . r}) . The over-approximation \nof D is classical in static analysis [19, 21] so we concentrate on the over-approximation of the relational \nvariant r. 14. Transition-based termination analysis We consider the case when states s . S consist of \na pair (., \u00b5) of a control state . (used for state or trace partitioning) and a memory state \u00b5. The memory \nstate maps variables x . X to numerical values \u00b5(x) . Z (for simplicity all other types are ignored in \nthe examples). We consider a relational abstraction (a.[P(S \u00d7 W)], .)- -(A, [) -- .a. . of the .xpoint \nrelational variant semantics of Sect. 13.2. In practice, we choose W = N and adjoint an extra variable \n# to contain the value of .. We can use octagons [46], polyhedra [31], polynomials [47], exponentials \n[39], their numerous variants, possibly partitioned on states [12], traces [56], or conditions of decision \ntrees [32]. Example 18. Consider the program of Ex. 7, where a forward interval analysis has determined \nthe invariants given as comments. int main () { int x; /* x:[-2147483648, 2147483647] */ while (x > 0) \n{ /* x:[1, 2147483647] */ x = x -2; /* x:[-1, 2147483645] */ } /* x:[-2147483648, 0] */ } The abstraction \nof the .xpoint equations of Sect. 13.3 is given below in logical form (representing a set by its characteristic \npredicate) with restriction to the reachable states over-approximated by the interval analysis. ' , # \n' r(x, #) .= (-2147483648 : x : # = 0) . (.x : x . [1, 2147483647] . x ' = x - 2 . # : # ' + 1 . r(x \n' , # ')) . Inverting the assignment yields the classical simpli.cation r(x, #) .= (-2147483648 : x : \n# = 0) . (.# ' : x . [1, 2147483647] . # : # ' + 1 . r(x - 2, # ')) . Partitioning into r1(x, #) = r(x, \n#).x : 0 and r2(x, #) = r(x, #).x > 0, the iterates for r1(x, #) immediately converge while the iterates \nfor r2(x, #) abstracted with octagons [46] are 32 The dual pre-image of Y . P(A) by a relation r . P(A \n\u00d7 B) is r-=1[Y] \u00acr-1[\u00acY] also written pre[r]Y. r 0 r2(x, #) = false 1 .# ' r2(x, #) = : x . [1, 2147483647] \n. # : # ' + 1 . r1(x - 2, # ' ) = x = 1 . # : 1 2 .# ' r2(x, #) = : x . [1, 2147483647] . # : # ' + 1 \n. (r1(x - 2, # ' ) . r21(x - 2, # ' )) = (x = 1 . # : 1) . (x = 3 . # : 2) = 1 : x : # : 2 octagon abstraction \nof . r23(x, #) = .# ' : x . [1, 2147483647] . # : # ' + 1 . (r1(x - 2, # ' ) . r22(x - 2, # ' )) = (x \n= 1 . # : 1) . (2 : x : # + 1 . # : 3) = 1 : x : # : 3 octagon abstraction of . = 1 : x : # . x : 2147483647 \nwidening with r22(x, #) r24(x, #) = r23(x, #) proving termination since # strictly decreases around the \nloop and remains positive. Of course direct resolution methods [17, 54] would .nd the same result. However \ntests are excluded within loops in [54] while the presence of tests is not impairing the above octagon \nabstraction or the piecewise linear variant abstraction of Sect. 12.1. For example, the loop body if \n(odd (x)) { x = x -1; } else {x =x-2} with state partitioning on the conditional branches yields the \nsame results. 15. Semantic structural induction Semantic structural induction is by induction on the \nstructure of computations as opposed to transitional veri.cation based on an induction on the program \nsteps as in Floyd/Turing method [40, 59]. This point of view generalizes syntactic structural induction \non program syntax as in Hoare logic [43], replacing the syntactic by a semantic point of view using the \nconcept of structural inductive cover. We start by the simple case of structuring states in next Sect. \n15.1 before generalizing to the more concrete trace computations in Sect. 15.3 and their abstractions \nin Sect. 16. 15.1 Inductive state cover Many inductive formal de.nitions and veri.cation methods can \nbe formalized in a language-independent way by an inductive cover of the set S of states (examples are \ngiven in next Sect. 15.2). De.nition 1. An inductive state cover of a non-empty set . . P(S) of states \nis tree encoded as a set C . C(.) of (.nite) sequences S of non-empty members B . P(.) \\ {\u00d8} such that \n1. if SS '. C then S . C (pre.x-closure) 2. if S . C then .S ' : S = .S ' (root) 3. if S BB'. C then \nB . B' (well-foundedness) 4. if S BB'. C then B . B' (cover).  S BB'.C By the pre.x-closure condition \nDef. 1.1, the inductive cover is a tree (so that proofs based on the cover C are by case analysis on \nthe tree width and induction on the tree depth). By the root condition Def. 1.2, the tree is rooted at \n. (which ensures that inductive proofs based on the cover C are valid for .). By the strictly-decreasing \ncondition Def. 1.3, the sequences S are necessarily .nite so the immediate component relation between \na node of the tree and its sons is well-founded. It follows that proofs on states can be done by induction \non this well-founded relation. And, by the covering condition Def. 1.4, the states in a node are covered \nby the join of the states in its sons (which ensures that proofs based on the cover C do not forget any \npossible case). Inductive state covers are abstractions of inductive trace covers introduced in forthcoming \nSect. 15.3 but are introduced .rst for simplicity. An example is [45].  15.2 Examples of semantic structural \ninduction 15.2.1 Loop invariants and variants In Floyd s total correctness proof method, one typically \nprovides a loop invariant and a loop variant function for termination. It is not necessary for the variant \nfunction to strictly decrease at each program step but only once around each loop iterate. This corresponds \nto a cover of the states of the loop according to their control component which induces a decomposition \nof executions into trace segments for the loop containing trace segments for the loop body considered \nas one step in the inductive reasoning on loop iterations.  Moreover a di.erent variant function is \nused for each loop so that this decomposition is applied recursively for nested loops. 15.2.2 Hoare logic \nInductive de.nition/veri.cation in the form of structural induction on the program syntax originates \nfrom axiomatic semantics [43], denotational semantics [57], and operational semantics [51]. Hoare logic \nfor a structured imperative language [43], and its extension to total correctness [44], can be understood \nas the inductive state cover based on the control states of a command (ignoring its memory states). For \nexample, a while loop can be covered by the states which control is in the condition and the states which \ncontrol is in the loop body. The states of the loop body can themselves be covered recursively, by structural \ninduction on the program syntax. This structural induction on the program syntax can be understood as \ninduction on a state cover which itself induces a cover of the execution traces by segments which states \nare in a block of the state cover. A termination proof by structural induction on the program syntax \n[44] has the advantage, a.o., to be able to handle unbounded non-determinism without requiring trans.nite \nordinals (equivalent to a lexicographic ordering on nested loops).  { P, PF, PL, PLE, PLD, PLDB, PLDC \n} 15.2.3 Burstall intermittent assertion proof method Burstall s total correctness proof method [3, 29] \ncan be understood as an inductive reasoning by recurrence on data (as well as control as in Floyd/Turing \nand Hoare s methods). Although Burstall s proof method [3] is equivalent in power to Floyd/Turing s method \n[25], it is much easier to use in practice. The formalization of Burstall s total correctness proof method \n[3] in [25] can be understood as a tree cover on both control and data. The example below shows how hand-simulation/symbolic \nexecution (HS ) and lemmas (L1, L2) apply to a particular execution trace. The inductive cover contains \nthe pro\u00ad gram P, the hand-simulation/symbol\u00adic execution blocks P HS 1, P HS 2, P HS 3, and two lemmas \nwith re\u00ad L.-1 spective blocks PL1 . , PL. 1 1 , .... PL. L.-1 \u00b7\u00b7\u00b7 L0 and PL2. , PL. L.-1, 111 22 L.-1 \nL0 ..., PL. \u00b7\u00b7\u00b7 corresponding to 22 2 proofs by recurrence on the data with respective ranks . and .. \nObserve that the termination analysis method of [9] can be seen as implicitly relying on Burstall s proof \nmethod. 15.3 Trace-based semantic structural induction The previous examples of Sect. 15.2 show the need \nto go beyond purely syntactic, language-dependent induction and that induction on states can be generalized \nto induction on trace segments. Con\u00adsequently, we introduce a general form of inductive reasoning on \nthe semantic structure of computations, .rst starting by induction on blocks of trace segments and then \ntheir abstractions in Sect. 16. 15.3.1 Trace segment abstraction We .rst observe that considering segments \nof traces is an abstraction. --- The segment abstraction (P(S+8), .)- --(P(S+8), .) . a.++ . a+(T ) \n{s . S+8|.s '. S * ,s '' . S*8 : s ' ss '' . T } is the set of segments of traces of T . If T, T '. P(S+8), \nwe de.ne T . T ' T . a+(T ' ) = .s . T : .s ' ,s '' : s ' ss '' . T ' to mean that all traces of T are \nsegments of the traces of T '. We de.ne the join Ti .+( Ti) = {si1 ...sin |.k . [1, n]: sik . Tik }i \n. . i . . to be the set of all the traces made out of segments in the Ti, i . .. 15.3.2 Inductive trace \nsegment cover De.nition 2. An inductive trace segment cover of a non-empty set . . P(S+8) of traces is \na set C . C(.) of sequences S of members B of P(a+ (.)) such that 1. if SS '. C then S . C (pre.x-closure) \n 2. if S . C then .S ' : S = .S ' (root) 3. if S BB'. C then B \u00b1 B' (well-foundedness) 4. if S BB'. \nC then B . B ' (cover).  S BB'.C Example 19. An example of inductive trace segment cover is trace partitioning \n[56]. Example 20. A variant function . e . S . N de.nes a trivial inductive trace cover. Each value v \n. codom(.) de.nes segments starting with states s such that .(s) = v of length at most v. The following \nde.nitions are classical for trees C . C(.). root(C) . '' leaves(C) {B . P(.) |.S : SB . C ..S : S BS \nr C}'' inner(C) {B . P(.) |.S, B ' , S : S BB ' S . C} nodes(C) leaves(C) . inner(C) '' sonsC (B) {B \n'. nodes(C) |.S, S : S BB ' S . C} .  The immediate component relation B' .CB B'. sonsC (B) = .S : S \nBB'. C is well-founded, so that proofs on segments can be done by induction on this well-founded relation. \nThe component relation .C * is its re.exive transitive closure. The blocks of a cover C are nodes(C) \n{B . P(S) | B .C * S}. 15.4 State cover induced by an inductive trace cover Given an inductive trace \ncover C . C(.), . . P(S+8) of Def. 2, de.ne the abstractions ats(C) {ats(S ) | S . C} C . P((P(a+(.)))+ \n) ' ) ats(S )ats(S ' ) ' ats(SS S, S . (P(a+(.)))+ ats(B) {ats(s) | s . B} B . P(a+(.)) ats(s) {si | \ni . [0, |s|- 1]} s . a+(.) . Then ats(C) is an inductive state cover in the sense of Def. 1. 15.5 Trace \ncover induced by a inductive state cover Inversely, given an inductive state cover C . C(.), . . P(S) \nof Def. 1, de.ne .st(C) {.st(S ) | S . C} C . P((P(.))+ ) .st(S ).st(S ' .st(SS ' ) ' ) S, S . (P(.))+ \n.st(B) B+ B . P(.) .st --- We have (P((P(S+))+), .) .- --.(P((P(S))+), .) and .ts(C) is an ats inductive \ntrace cover of .+ . 15.6 Syntactic trace cover Similarly one can de.ne the inductive state cover induced \nby the syntax of commands of a programming language by considering the states which control is in a given \ncommand. This in turns induces a trace cover which is the basis for e.g. Hoare logic or structural static \nanalysis by induction on program commands, as opposed to induction on program transitions as in data.ow \nanalysis. 15.6.1 Inductive proof method We have a sound and complete inductive proof method of a semantic \nproperty T+8[P] n . .P for an inductive trace cover C . C(.) T+8 [P] n B .P, B . leaves(C) basis .B'. \nsonsC (B): T+8.P [P] n B' , B . inner(C) induction T+8 [P] n B .P In particular, for termination t+8[P] \n. S+[P] with a trace cover C . C(S+8[P]), we get T+8 [P] . B . S+ , B . leaves(C) basis .B'. sonsC (B): \nT+8. S+ [P] . B' , B . inner(C) induction T+8 [P] . B . S+ Example 21. Another form of decomposition \nof reasonings on termination is proposed by the transition invariants proof method of Podelski-Rybalchenko \n[53] based on a relational semantics [15]. The transition invariants proof method of [53] can be seen \nas the aR abstraction of the above inductive proof method based on an inductive trace cover of height \n1 with root S+ [P] and sons a+(T1), ..., a+(Tn) where T1,..., Tn . P(S+[P]) such that T+8 [P] . S+[P] \n.. .i . [1, n]: T+8[P] n Ti . S+ . The generalization by inductive trace covers is both on the use of \ntrace segments (instead of their relational abstraction of Sect. 7.1), and the possibility of recursive \napplication of the method by induction, including on data, \u00e0 la Burstall [3]. 16. Abstract semantic structural \ninduction Assume that we can prove a program trace property in the concrete using an inductive trace \ncover. Can we prove an abstract program property using the abstraction of the inductive trace cover? \nWe have seen an example in Sect. 15.5. The question is whether this observation is general. 16.1 Abstract \ninductive cover De.nition 3. An inductive abstract cover of a trace semantics . . P(S+8) is an element \nC . AC of an abstract domain AC such that .at --- (P((P(S+))+), .) .- --.(AC , [C ) ata and .ts(C) is \nan inductive trace cover of .. A standard way to de.ne such inductive abstract covers is to follow the \nexample of Sect. 15.5 generalized to a block abstrac\u00ad .at tion (P(S+), .)--- [B). We get the cover abstraction \n..(AB,- -- ata .at (P((P(S+))+), .) .- ----- .(P((AB)+), .) by generalizing ata to se\u00ad ata quences of \nabstract blocks and sets of such abstract sequences as follows ' ) .at(S ).at(S ' ) ' .at(SS S, S . (AB)+ \n.at(C) {.at(S ) | S . C} C . P((AB)+). Then AC is chosen to be the set of elements C . P((AB)+) of sequences \nS of members B of AB such that 1. if SS '. C then S . C (pre.x-closure) ' aat(.)S ' 2. if S . C then \n.S : S = (root) 3. if S BB'. C then .at(B) \u00b1 .at(B') (well-foundedness) 4. if S BB'. C then .at(B) \n. .at(B ' ) (cover).  S BB'.C It follows that any C . AC is an inductive abstract cover of the trace \nsemantics . . P(S+8) in the sense of Def. 3. Example 22. The transition invariant proof method of [53] \nfollows .at --- from the relational abstraction (P(S+ ), .)- --(P(S \u00d7 S), .) [15] . ata.where ata(B) \n{(s0,sn - 1)| n > 0 . s . B n Sn} is limited to the trace covers of the form given in Ex. 21. 16.2 Abstract \ninductive proof The inductive proof method of Sect. 15.6.1 can be abstracted as follows. aat(T+8 B . \nleaves(C) basis [P]) [CB, .B'. sonsC (B): aat(T+8 [P]) [CB' , B . inner(C) induction aat(T+8 [P]) [CB+ \nThe proofs aat(T+8[P]) [CB can be done in the abstract by .xpoint induction using a .xpoint abstraction \nof the .xpoint de.nition of the trace semantics T+8 [P]. 17. Related work Most directly relevant work \nhas been cited in the text. For programs with unbounded executions, any .nite homomorphic abstraction \nmust introduce a loop so that .nite model-checking [4] or bounded model-checking [2] are unapplicable \n(or unsound) to prove termina\u00adtion (or non-termination). Nevertheless, predicate abstraction [41] remains \napplicable since it is a .nite encoding of an in.nite ab\u00adstract interpretation [16]. With predicate abstraction \nthe end-user is left with the hard problem of providing candidate variant func\u00adtions [14], as in [1]. \nMoreover [27] shows that in.nitary abstractions with widening/narrowing, as considered in this paper, \nare de.nitely strictly more powerful than .nite abstractions. The computation of variant functions by \nabstraction is new, and di.erent from the counter-example guided ways to .nd disjunctive ranking functions, \nused in tools like Terminator [7] and derivatives.  18. Conclusion Abstract interpretation has established \nconstructive principles for reasoning about semantics. A semantics is a .xpoint so proving a semantic \nproperty at some level of abstraction consists in verifying properties of abstract .xpoints which have \nto be checked (in checking/veri.cation methods), guessed (in proof methods), or automatically inferred \nor approximated (in static analysis methods). This principle was mainly applied in the past to invariance \nand indirectly to termination by reduction to invariance. We have shown that the abstract interpretation \nprinciple directly applies to both safety (generalizing invariance) and termination. Moreover we have \ngeneralized the classical syntactic structural induction into the language-independent semantic concept \nof seman\u00adtic structural induction based on (abstractions of) inductive trace covers which includes induction \non syntax, control states, mem\u00adory states, and execution trace segments and thus generalizes all veri.cation \nand static analysis methods. This methodology allowed us to establish new principles for proving termination \nby abstract interpretation of a termination semantics. It remains to design a suitable collection of \nabstract domains beyond the examples proposed in this paper and the corresponding implementations. The \npresent abstract interpretation termination framework has to be extended to liveness [6, 53] and more \ngenerally to inevitability under fairness hypotheses [35, 52, 55]. References [1] I. Balaban, A. Pnueli, \nand L. Zuck. Modular ranking abstraction. Int. J. Found. Comput. Sci., 18(1):5 44, 2007. [2] A. Biere, \nA. Cimatti, E. Clarke, O. Strichman, and Y. Zhu. Bounded model checking. Advances in Computers, 58:118 \n149, 2003. [3] R. Burstall. Program proving as hand simulation with a little induction. Informa\u00adtion \nProcessing, 308 312. North-Holland, 1974. [4] E. Clarke, O. Grumberg, and D. Peled. Model Checking. MIT \nPress, 1999. [5] M. Clarkson and F. Schneider. Hyperproperties. Journal of Computer Security, 18(6):1157 \n1210, 2010. [6] B. Cook and E. Koskinen. Making prophecies with decision predicates. POPL, 399 410, 2011. \n[7] B. Cook, A. Gotsman, A. Podelski, A. Rybalchenko, and M. Vardi. Proving that programs eventually \ndo something good. POPL, 265 276, 2007. [8] B. Cook, S. Gulwani, T. Lev-Ami, A. Rybalchenko, and M. Sagiv. \nProving conditional termination. CAV, LNCS 5123, 328 340, 2008. [9] B. Cook, A. Podelski, and A. Rybalchenko. \nSummarization for termination: no return! Form. Methods Syst. Des., 35:369 387, 2009. [10] S. Cook. Soundness \nand completeness of an axiom system for program veri.ca\u00adtion. SIAM J. Comput., 7:70 80, 1978. [11] P. \nCousot. M\u00e9thodes it\u00e9ratives de construction et d approximation de points .\u00ad xes d op\u00e9rateurs monotones \nsur un treillis, analyse s\u00e9mantique de programmes. Th\u00e8se d \u00c9tat \u00e8s sciences math., USMG, Grenoble, 1978. \n[12] P. Cousot. Semantic foundations of program analysis. Program Flow Analysis: Theory and Applications, \nch. 10, 303 342. Prentice-Hall, 1981. [13] P. Cousot. The calculational design of a generic abstract \ninterpreter. M. Broy and R. Steinbr\u00fcggen, eds., Calculational System Design. NATO ASI Series F. IOS Press, \nAmsterdam, 1999. [14] P. Cousot. Partial completeness of abstract .xpoint checking. SARA, LNCS 1864, \n1 25, 2000. [15] P. Cousot. Constructive design of a hierarchy of semantics of a transition system by \nabstract interpretation. TCS, 277(1 2):47 103, 2002. [16] P. Cousot. Veri.cation by abstract interpretation. \nProc. Int. Symp. on Veri.cation Theory &#38; Practice, LNCS 2772, 243 268, 2003. [17] P. Cousot. Proving \nprogram invariance and termination by parametric abstrac\u00adtion, Lagrangian relaxation and semide.nite \nprogramming. VMCAI, LNCS 3385, 1 24, 2005. [18] P. Cousot and R. Cousot. Static determination of dynamic \nproperties of programs. Proc. 2nd Int. Symp. on Programming, 106 130. Dunod, Paris, 1976. [19] P. Cousot \nand R. Cousot. Abstract interpretation: a uni.ed lattice model for static analysis of programs by construction \nor approximation of .xpoints. POPL, 238 252, 1977. [20] P. Cousot and R. Cousot. Static determination \nof dynamic properties of recursive procedures. Formal Description of Programming Concepts, 237 277. North-Holland, \n1977. [21] P. Cousot and R. Cousot. Systematic design of program analysis frameworks. POPL, 269 282, \n1979. [22] P. Cousot and R. Cousot. Constructive versions of Tarski s .xed point theorems. P. J. of \nMath., 82(1):43 57, 1979.  [23] P. Cousot and R. Cousot. Induction principles for proving invariance \nproperties of programs. Tools &#38; Notions for Program Construction: an Advanced Course, 75 119. Cambridge \nUniversity Press, Cambridge, UK, 1982. [24] P. Cousot and R. Cousot. \u00c0 la Floyd induction principles \nfor proving in\u00adevitability properties of programs. Algebraic methods in semantics, 277 312. Cambridge \nUniversity Press, Cambridge, UK, 1985. [25] P. Cousot and R. Cousot. Sometime = always + recursion = \nalways, on the equivalence of the intermittent and invariant assertions methods for proving inevitability \nproperties of programs. Acta Informatica, 24:1 31, 1987. [26] P. Cousot and R. Cousot. Abstract interpretation \nframeworks. JLC, 2(4):511 547, 1992. [27] P. Cousot and R. Cousot. Comparing the Galois connection and \nwidening/nar\u00adrowing approaches to abstract interpretation. PLILP, LNCS 631, 269 295, 1992. [28] P. Cousot \nand R. Cousot. Inductive de.nitions, semantics and abstract interpre\u00adtation. POPL, 83 94, 1992. [29] \nP. Cousot and R. Cousot. \u00c0 la Burstall intermittent assertions induction principles for proving inevitable \nability properties of programs. TCS, 120(1): 123 155, 1993. [30] P. Cousot and R. Cousot. Higher-order \nabstract interpretation (and application to comportment analysis generalizing strictness, termination, \nprojection and PER analysis of functional languages). Int. Conf. on Comp. Lang., 95 112, 1994. [31] P. \nCousot and N. Halbwachs. Automatic discovery of linear restraints among variables of a program. POPL, \n84 97, 1978. [32] P. Cousot, R. Cousot, and L. Mauborgne. A scalable segmented decision tree abstract \ndomain. Time for Veri.cation, Essays in Memory of A. Pnueli, LNCS 6200, 72 95, 2010. [33] P. Cousot, \nR. Cousot, and F. Logozzo. A parametric segmentation functor for fully automatic and scalable array content \nanalysis. POPL, 105 118, 2011. [34] P. Cousot, R. Cousot, and F. Logozzo. Precondition inference from \nintermittent assertions and application to contracts on collections. VMCAI, LNCS 6538, 150 168, 2011. \n[35] R. Cousot. Fondements des m\u00e9thodes de preuve d invariance et de fatalit\u00e9 de programmes parall\u00e8les. \nTh\u00e8se d \u00c9tat \u00e8s sciences math., INPL, Nancy, 1985. [36] B. Davey and H. Priestley. Introduction to Lattices \nand Order, 2nd Edition. Cambridge University Press, 2002. [37] E. Dijkstra. Guarded commands, nondeterminacy \nand formal derivation of programs. CACM, 18(8):453 457, 1975. [38] E. Dijkstra. A Discipline of Programming. \nPrentice-Hall, 1976. [39] J. Feret. The arithmetic-geometric progression abstract domain. VMCAI, LNCS \n3385, 42 58, 2005. [40] R. Floyd. Assigning meaning to programs. Proc. Symp. in Applied Math., Vol. 19, \n19 32. Amer. Math. Soc., 1967. [41] S. Graf and H. Sa\u00efdi. Construction of abstract state graphs with \nPVS. CAV, LNCS 1254, 72 83, 1997. [42] M. Heizmann, J. Hoenicke, and A. Podelski. Re.nement of trace \nabstraction. SAS, LNCS 5673, 69 85, 2009. [43] C. Hoare. An axiomatic basis for computer programming. \nCommunications of the Association for Computing Machinery, 12(10):576 580, 1969. [44] Z. Manna and A. \nPnueli. Axiomatic approach to total correctness of programs. Acta Inf., 3:243 263, 1974. [45] K. McMillan \nand L. Zuck. Invisible invariants and abstract interpretation. SAS, LNCS 6887, 249 262, 2011. [46] A. \nMin\u00e9. The octagon abstract domain. HOSC, 19:31 100, 2006. [47] D. Monniaux. Automatic modular abstractions \nfor template numerical con\u00adstraints. Logical Methods in Comp. Sci., 6(3), 2010. [48] J. Morris and B. \nWegbreit. Subgoal induction. CACM, 20(4):209 222, 1977. [49] P. Naur. Proofs of algorithms by general \nsnapshots. BIT, 6:310 316, 1966. [50] D. Pataria. A constructive proof of Tarski s .xed-point theorem \nfor DCPO s. Reported by M.H. Escard\u00f3 in Joins in the frame of nuclei , Applied Categorical Structures \n11 (2) 117 124, 2003. [51] G. Plotkin. A structural approach to operational semantics. Technical Report \nDAIMI FN-19, Aarhus University, 1981. [52] A. Pnueli, A. Podelski, and A. Rybalchenko. Separating fairness \nand well\u00adfoundedness for the analysis of fair discrete systems. TACAS, LNCS 3440, 124 139, 2005. [53] \nA. Podelski and A. Rybalchenko. Transition invariants. LICS, 32 41, 2004. [54] A. Podelski and A. Rybalchenko. \nA complete method for the synthesis of linear ranking functions. VMCAI, LNCS 2937, 239 251, 2004. [55] \nA. Podelski and A. Rybalchenko. Transition predicate abstraction and fair termination. POPL, 132 144, \n2005. [56] X. Rival and L. Mauborgne. The trace partitioning abstract domain. TOPLAS, 29(5), 2007. [57] \nD. Scott and C. Strachey. Towards a mathematical semantics for computer languages. Tech. rep. PRG-6, \nOxford Univ. Comp. Lab., 1971. [58] A. Tarski. A lattice theoretical .xpoint theorem and its applications. \nP. J. of Math., 5:285 310, 1955. [59] R. Turing. Checking a large routine. Con. on High Speed Automatic \nCalculating Machines, Math. Lab., Cambridge, UK, 67 69, 1949.     \n\t\t\t", "proc_id": "2103656", "abstract": "<p>Proof, verification and analysis methods for termination all rely on two induction principles: (1) a variant function or induction on data ensuring progress towards the end and (2) some form of induction on the program structure. The abstract interpretation design principle is first illustrated for the design of new forward and backward proof, verification and analysis methods for safety. The safety collecting semantics defining the strongest safety property of programs is first expressed in a constructive fixpoint form. Safety proof and checking/verification methods then immediately follow by fixpoint induction. Static analysis of abstract safety properties such as invariance are constructively designed by fixpoint abstraction (or approximation) to (automatically) infer safety properties. So far, no such clear design principle did exist for termination so that the existing approaches are scattered and largely not comparable with each other.</p> <p>For (1), we show that this design principle applies equally well to potential and definite termination. The trace-based termination collecting semantics is given a fixpoint definition. Its abstraction yields a fixpoint definition of the best variant function. By further abstraction of this best variant function, we derive the Floyd/Turing termination proof method as well as new static analysis methods to effectively compute approximations of this best variant function.</p> <p>For (2), we introduce a generalization of the syntactic notion of struc- tural induction (as found in Hoare logic) into a semantic structural induction based on the new semantic concept of inductive trace cover covering execution traces by segments, a new basis for formulating program properties. Its abstractions allow for generalized recursive proof, verification and static analysis methods by induction on both program structure, control, and data. Examples of particular instances include Floyd's handling of loop cutpoints as well as nested loops, Burstall's intermittent assertion total correctness proof method, and Podelski-Rybalchenko transition invariants.</p>", "authors": [{"name": "Patrick Cousot", "author_profile_id": "81100592699", "affiliation": "CNRS, &#201;cole Normale Sup&#233;rieure, and INRIA, France and Courant Institute, NYU, USA, Paris and New York, USA", "person_id": "P2991389", "email_address": "cousot@ens.fr, pcousot@cims.nyu.edu", "orcid_id": ""}, {"name": "Radhia Cousot", "author_profile_id": "81100592574", "affiliation": "CNRS, &#201;cole Normale Sup&#233;rieure, and INRIA, France, Paris, France", "person_id": "P2991390", "email_address": "rcousot@ens.fr", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103687", "year": "2012", "article_id": "2103687", "conference": "POPL", "title": "An abstract interpretation framework for termination", "url": "http://dl.acm.org/citation.cfm?id=2103687"}