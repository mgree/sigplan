{"article_publication_date": "01-25-2012", "fulltext": "\n Formalizing the LLVM Intermediate Representation for Veri.ed Program Transformations * Jianzhou Zhao \nSantosh Nagarakatte Milo M. K. Martin Steve Zdancewic Computer and Information Science Department, University \nof Pennsylvania jianzhou@cis.upenn.edu santoshn@cis.upenn.edu milom@cis.upenn.edu stevez@cis.upenn.edu \nAbstract This paper presents Vellvm (veri.ed LLVM), a framework for rea\u00adsoning about programs expressed \nin LLVM s intermediate repre\u00adsentation and transformations that operate on it. Vellvm provides a mechanized \nformal semantics of LLVM s intermediate representa\u00adtion, its type system, and properties of its SSA form. \nThe frame\u00adwork is built using the Coq interactive theorem prover. It includes multiple operational semantics \nand proves relations among them to facilitate different reasoning styles and proof techniques. To validate \nVellvm s design, we extract an interpreter from the Coq formal semantics that can execute programs from \nLLVM test suite and thus be compared against LLVM reference implementa\u00adtions. To demonstrate Vellvm s \npracticality, we formalize and ver\u00adify a previously proposed transformation that hardens C programs against \nspatial memory safety violations. Vellvm s tools allow us to extract a new, veri.ed implementation of \nthe transformation pass that plugs into the real LLVM infrastructure; its performance is competitive \nwith the non-veri.ed, ad-hoc original. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: \nSoftware/Program Veri.cation -Correctness Proofs; F.3.1 [Logics and Meanings of Programs]: Spe.cying \nand Verifying and Reasoning about Programs -Mechanical veri.cation; F.3.2 [Log\u00adics and Meanings of Programs]: \nSemantics of Programming Lan\u00adguages -Operational semantics General Terms Languages, Veri.cation, Reliability \nKeywords LLVM, Coq, memory safety 1. Introduction Compilers perform their optimizations and transformations \nover an intermediate representation (IR) that hides details about the tar\u00adget execution platform. Rigorously \nproving properties about these IR transformations requires that the IR itself have a well-de.ned formal \nsemantics. Unfortunately, the IRs used in main-stream pro\u00adduction compilers generally do not. To address \nthis de.ciency, this * This research was funded in part by the U.S. Government. The views and conclusions \ncontained in this document are those of the authors and should not be interpreted as representing the \nof.cial policies, either expressed or implied, of the U.S. Government. Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 12, January 25 27, 2012, Philadelphia, \nPA, USA. Copyright c &#38;#169; 2012 ACM 978-1-4503-1083-3/12/01. . . $10.00  Figure 1. The LLVM compiler \ninfrastructure paper formalizes both the static and dynamic semantics of the IR that forms the heart \nof the LLVM compiler infrastructure. LLVM [19] (Low-Level Virtual Machine) uses a platform\u00adindependent \nSSA-based IR originally developed as a research tool for studying optimizations and modern compilation \ntech\u00adniques [16]. The LLVM project has since blossomed into a ro\u00adbust, industrial-strength, and open-source \ncompilation platform that competes with GCC in terms of compilation speed and per\u00adformance of the generated \ncode [16]. As a consequence, it has been widely used in both academia and industry. An LLVM-based compiler \nis structured as a translation from a high-level source language to the LLVM IR (see Figure 1). The LLVM \ntools provide a suite of IR to IR translations, which pro\u00advide optimizations, program transformations, \nand static analyses. The resulting LLVM IR code can then be lowered to a variety of target architectures, \nincluding x86, PowerPC, and ARM (either by static compilation or dynamic JIT-compilation). The LLVM project \nfocuses on C and C++ front-ends, but many source languages, in\u00adcluding Haskell, Scheme, Scala, Objective \nC and others have been ported to target the LLVM IR. This paper introduces Vellvm for veri.ed LLVM a \nframe\u00adwork that includes a formal semantics and associated tools for mechanized veri.cation of LLVM IR \ncode, IR to IR transforma\u00adtions, and analyses. The description of this framework in this paper is organized \ninto two parts. The .rst part formalizes the LLVM IR. It presents the LLVM syntax and static properties \n(Section 2), including a variety of well-formedness and structural properties about LLVM s static single \nassignment (SSA) representation that are useful in proofs about LLVM code and transformation passes. \nVellvm s memory model (Section 3) is based on CompCert s [18], extended to han\u00addle LLVM s arbitrary bit-width \nintegers, padding, and alignment issues. In developing the operational semantics (Section 4), a sig\u00adni.cant \nchallenge is adequately capturing the nondeterminism that arises due to LLVM s explicit undef value and \nits intentional underspeci.cation of certain erroneous behaviors such as reading from uninitialized memory; \nthis underspeci.cation is needed to justify the correctness of aggressive optimizations. Vellvm there\u00adfore \nimplements several related operational semantics, including a nondeterministic semantics and several \ndeterministic re.nements to facilitate different proof techniques and reasoning styles. The second part \nof the paper focuses on the utility of for\u00admalizing the LLVM IR. We describe Vellvm s implementation \nin Coq [10] and validate its LLVM IR semantics by extracting an exe\u00adcutable interpreter and comparing \nits behavior to that of the LLVM reference interpreter and compiled code (Section 5). The Vellvm framework \nprovides support for moving code between LLVM s IR representation and its Coq representation. This infrastructure, \nalong with Coq s facility for extracting executable code from constructive proofs, enables Vellvm users \nto manipulate LLVM IR code with high con.dence in the results. For example, using this framework, we \ncan extract veri.ed LLVM transformations that plug directly into the LLVM compiler. We demonstrate the \neffectiveness of this technique by using Vellvm to implement a veri.ed instance of Soft-Bound [21], an \nLLVM-pass that hardens C programs against buffer over.ows and other memory safety violations (Section \n6). To summarize, this paper and the Vellvm framework provide: A formalization of the LLVM IR, its static \nsemantics, memory model, and several operational semantics;  Metatheoretic results (preservation and \nprogress theorems) re\u00adlating the static and dynamic semantics;  Coq infrastructure implementing the \nabove, along with tools for interacting with the LLVM compiler;  Validation of the semantics in the \nform of an extracted LLVM interpreter; and  Demonstration of applying this framework to extract a veri.ed \ntransformation pass for enforcing spatial memory-safety.  2. Static Properties of the LLVM IR The LLVM \nIR is a typed, static single assignment (SSA) [13] lan\u00adguage that is a suitable representation for expressing \nmany com\u00adpiler transformations and optimizations. This section describes the syntax and basic static \nproperties, emphasizing those features that are either unique to the LLVM or have non-trivial implications \nfor the formalization. Vellvm s formalization is based on the LLVM release version 2.6, and the syntax \nand semantics are intended to model the behavior as described in the LLVM Language Refer\u00adence,1 although \nwe also used the LLVM IR reference interpreter and the x86 backend to inform our design. 2.1 Language \nsyntax Figure 3 shows (a fragment of) the abstract syntax for the subset of the LLVM IR formalized in \nVellvm. The metavariable id ranges over LLVM identi.ers, written %X, %T, %a, %b, etc., which are used \nto name local types and temporary variables, and @a, @b, @main, etc., which name global values and functions. \nEach source .le is a module mod that includes data layout information layout (which de.nes sizes and \nalignments for types; see below), named types, and a list of prods that can be function declarations, \nfunction de.nitions, and global variables. Figure 2 shows a small example of LLVM syntax (its meaning \nis described in more detail in Section 3). Every LLVM expression has a type, which can easily be deter\u00admined \nfrom type annotations that provide suf.cient information to check an LLVM program for type compatibility. \nThe LLVM IR is not a type-safe language, however, because its type system allows arbitrary casts, calling \nfunctions with incorrect signatures, access\u00ading invalid memory, etc. The LLVM type system ensures only \nthat the size of a runtime value in a well-formed program is compati\u00adble with the type of the value a \nwell-formed program can still be stuck (see Section 4.3). 1 See http://llvm.org/releases/2.6/docs/LangRef.html \n %ST = type { i10 , [10 x i8*] } define %ST* @foo(i8* %ptr) { entry: %p = malloc %ST, i32 1 %r = getelementptr \n%ST* %p, i32 0, i32 0 store i10 648, %r ; decomposes as 136, 2 %s = getelementptr %ST* %p, i32 0, i32 \n1, i32 0 store i8* %ptr, %s ret %ST* %p } Figure 2. An example use of LLVM s memory operations. Here, \n%p is a pointer to a single-element array of structures of type %ST. Pointer %r indexes into the .rst \ncomponent of the .rst element in the array, and has type i10*, as used by the subsequent store, which \nwrites the 10-bit value 648. Pointer %s has type i8** and points to the .rst element of the nested array \nin the same structure. Types typ include arbitrary bit-width integers i8, i16, i32, etc., or, more generally, \nisz where sz is a natural number. Types also include .oat, void, pointers typ*, arrays [ sz \u00d7 typ ] that \nhave a statically-known size sz . Anonymous structure types { typjj }contain a list of types. Functions \ntyp typjj have a return type, and a list of argument types. Here, typjj denotes a list of typ components; \nwe use similar notation for other lists throughout the paper. Finally, types can be named by identi.ers \nid which is useful to de.ne recursive types. The sizes and alignments for types, and endianness are de.ned \nin layout. For example. int sz align0 align1 dictates that values with type isz are align0-byte aligned \nwhen they are within an aggregate and when used as an argument, and align1-byte aligned when emitted \nas a global. Operations in the LLVM IR compute with values val, which are either identi.ers id naming \ntemporaries, or constants cnst com\u00adputed from statically-known data, using the compile-time analogs of \nthe commands described below. Constants include base values (i.e., integers or .oats of a given bit width), \nand zero-values of a given type, as well as structures and arrays built from other con\u00adstants. To account \nfor uninitialized variables and to allow for various program optimizations, the LLVM IR also supports \na type-indexed undef constant. Semantically, undef stands for a set of possible bit patterns, and LLVM \ncompilers are free to pick convenient values for each occurrence of undef to enable aggressive optimizations \nor program transformations. As described in Section 4, the pres\u00adence of undef makes the LLVM operational \nsemantics inherently nondeterministic. All code in the LLVM IR resides in top-level functions, whose \nbodies are composed of block bs. As in classic compiler represen\u00adtations, a basic block consists of a \nlabeled entry point l, a series of f nodes, a list of commands, and a terminator instruction. As is usual \nin SSA representations, the f nodes join together values from a list of predecessor blocks of the control-.ow \ngraph each f node takes a list of (value, label) pairs that indicates the value chosen when control transfers \nfrom a predecessor block with the associated label. Block terminators (br and ret) branch to another \nblock or return (possibly with a value) from the current function. Terminators also include the unreachable \nmarker, indicating that control should never reach that point in the program. The core of the LLVM instruction \nset is its commands (c), which include the usual suite of binary arithmetic operations (bop e.g., add, \nlshr, etc.), memory accessors (load, store), heap opera\u00adtions (malloc and free), stack allocation (alloca), \nconversion operations among integers, .oats and pointers (eop, trop, and cop), comparison over integers \n(icmp and select), and calls (call). Modules mod, P :: = layout namedt prod Layouts layout :: = bigendian \n| littleendian | ptr sz align0 align1 | int sz align0 align1 | .oat sz align0 align1 | aggr sz align0 \nalign1 | stack sz align0 align1 Products prod :: = id = global typ const align | de.ne typ id(arg){b}| \ndeclare typ id(arg) Floats fp :: = .oat | double Types typ :: = isz | fp | void | typ*| [ sz \u00d7 typ ] \n|{ typjj }| typ typjj | id Values val :: = id | cnst Binops bop :: = add | sub | mul | udiv | sdiv | \nurem | srem | shl | lshr | ashr | and | or | xor Float ops fbop :: = fadd | fsub | fmul | fdiv | frem \nExtension eop :: = zext | sext | fpext Cast op cop :: = fptoui | ptrtoint | inttoptr | bitcast Trunc \nop trop :: = truncint | truncfp Constants cnst :: = isz Int | fp Float | typ * id | (typ*) null | typ \nzeroinitializer | typ[ cnstjj ] |{ cnstjj } | typ undef | bop cnst1 cnst2 | fbop cnst1 cnst2 | trop cnst \nto typ | eop cnst to typ | cop cnst to typ | getelementptr cnst cstjj | select cnst0 cnst1 cnst2 | icmp \ncond cnst1 cnst2 | fcmp fcond cnst1 cnst2 Blocks b :: = l f c tmn f nodes f :: = id = phi typ [valj , \nlj ] j Tmns tmn :: = br val l1 l2 | br l | ret typ val | ret void | unreachable Commands c :: = id = \nbop( int sz)val1 val2 | id = fbop fp val1 val2 | id = load (typ*)val1 align | store typ val1 val2 align \n| id = malloc typ val align | free ( typ * ) val | id = alloca typ val align | id = trop typ1 val to \ntyp2 | id = eop typ1 val to typ2 | id = cop typ1 val to typ2 | id = icmp cond typ val1 val2 | id = select \nval0 typ val1 val2 | id = fcmp fcond fp val1 val2 | option id = call typ0 val0 param j | id = getelementptr \n( typ * ) val valj Figure 3. Syntax for LLVM. Note that this .gure omits some syntax de.nitions (e.g., \ncond the comparison operators) for the sake of space; they are, of course, present in Vellvm s implementation. \nSome other parts of the LLVM have been omitted from the Vellvm development; these are discussed in Section \n5. Note that a call site is allowed to ignore the return value of a func\u00adtion call. Finally, getelementptr \ncomputes pointer offsets into structured datatypes based on their types; it provides a platform\u00adand layout-independent \nway of performing array indexing, struct .eld access, and pointer arithmetic.  2.2 Static semantics \nFollowing the LLVM IR speci.cation, Vellvm requires that every LLVM program satisfy certain invariants \nto be considered well formed: every variable in a function is well-typed, well-scoped, and assigned exactly \nonce. At a minimum, any reasonable LLVM transformation must preserve these invariants; together they \nimply that the program is in SSA form [13]. All the components in the LLVM IR are annotated with types, \nso the typechecking algorithm is straightforward and determined only by local information.The only subtlety \nis that types themselves must be well formed. All typs except void and function types are considered \nto be .rst class, meaning that values of these types can be passed as arguments to functions. A set of \n.rst-class type de.nitions is well formed if there are no degenerate cycles in their de.nitions (i.e., \nevery cycle through the de.nitions is broken by a pointer type). This ensures that the physical sizes \nof such typs are positive, .nite, and known statically. The LLVM IR has two syntactic scopes a global \nscope and a function scope and does not have nested local scopes. In the global scope, all named types, \nglobal variables and functions have different names, and are de.ned mutually. In the scope of a function \n.d in module mod, all the global identi.ers in mod, the names of arguments, locally de.ned variables \nand block labels in the function .d must be unique, which enforces the single-assignment part of the \nSSA property. The set of blocks making up a function constitute a control\u00ad.ow graph with a well-de.ned \nentry point. All instructions in the function must satisfy the SSA scoping invariant with respect to \nthe control-.ow graph: the instruction de.ning an identi.er must dominate all the instructions that use \nit. Within a block insn1 dominates insn2 if insn1 appears before insn2 in a program order. A block labeled \nl1 dominates a block labeled l2 if every execution path from the program entry to l2 must go through \nl1. The Vellvm formalization provides an implementation of this dominator analysis using a standard \ndata.ow .xpoint computa\u00adtion [14]. It also proves that the implementation is correct, as stated in the \nfollowing lemma, which is needed to establish preservation of the well-formedness invariants by the operational \nsemantics (see Section 4). LEMMA 1 (Dominator Analysis Correctness). The entry block of a function dominates \nitself.  Given a block b2 that is an immediate successor of b1, all the strict dominators of b2 also \ndominate b1  These well-formedness constraints must hold only of blocks that are reachable from a function \ns entry point unreachable code may contain ill-typed and ill-scoped instructions. 3. A Memory Model for \nVellvm 3.1 Rationale Understanding the semantics of LLVM s memory operations is crucial for reasoning \nabout LLVM programs. LLVM developers make many assumptions about the legal behaviors of such LLVM code, \nand they informally use those assumptions to justify the correctness of program transformations. There \nare many properties expected of a reasonable implemen\u00adtation of the LLVM memory operations (especially \nin the absence of errors). For example, we can reasonably assume that the load instruction does not affect \nwhich memory addresses are allocated, or that different calls to malloc do not inappropriately reuse \nmem\u00adory locations. Unfortunately, the LLVM Language Reference Man\u00adual does not enumerate all such properties, \nwhich should hold of any reasonable memory implementation. On the other hand, details about the particular \nmemory man\u00adagement implementation can be observed in the behavior of LLVM programs (e.g., you can print \na pointer after casting it to an integer). For this reason, and also to address error conditions, the \nLLVM speci.cation intentionally leaves some behaviors unde.ned. Exam\u00adples include: loading from an unallocated \naddress; loading with im\u00adproper alignment; loading from properly allocated but uninitialized memory; \nand loading from properly initialized memory but with an incompatible type. Because of the dependence \non a concrete implementation of memory operations, which can be platform speci.c, there are many possible \nmemory models for the LLVM. One of the challenges we encountered in formalizing the LLVM was .nding a \npoint in the design space that accurately re.ects the intent of the LLVM documentation while still providing \na useful basis for reasoning about LLVM programs. In this paper we adopt a memory model that is based \non the one implemented for CompCert [18]. This model allows Vellvm to ac\u00adcurately implement the LLVM \nIR and, in particular, detect the kind of errors mentioned above while simultaneously justifying many \nof the reasonable assumptions that LLVM programmers make. The nondeterministic operational semantics \npresented in Section 4 takes advantage of this precision to account for much of the LLVM s under-speci.cation. \nAlthough Vellvm s design is intended to faithfully capture the LLVM speci.cation, it is also partly motivated \nby pragmatism: building on CompCert s existing memory model allowed us to re\u00aduse a signi.cant amount \nof their Coq infrastructure. A bene.t of this choice is that our memory model is compatible with Com\u00adpCert \ns memory model (i.e., our memory model implements the CompCert Memory signature). This Vellvm memory \nmodel inherits some features from the CompCert implementation: it is single threaded (in this paper we \nconsider only single-threaded programs); it assumes that point\u00aders are 32-bits wide, and 4-byte aligned; \nand it assumes that the memory is in.nite. Unlike CompCert, Vellvm s model must also deal with arbitrary \nbit-width integers, padding, and alignment con\u00adstraints that are given by layout annotations in the LLVM \nprogram, as described next.  3.2 LLVM memory commands The LLVM supports several commands for working \nwith heap\u00adallocated data structures: malloc and alloca allocate array-structured regions of mem\u00adory. \nThey take a type parameter, which determines layout and padding of the elements of the region, and an \nintegral size that speci.es the number of elements; they return a pointer to the newly allocated region. \n free deallocates the memory region associated with a given pointer (which should have been created \nby malloc). Memory allocated by alloca is implicitly freed upon return from the function in which alloca \nwas invoked.  load and store respectively read and write LLVM values to memory. They take type parameters \nthat govern the expected layout of the data being read/written.  getelementptr indexes into a structured \ndata type by com\u00adputing an offset pointer from another given pointer based on its type and a list of \nindices that describe a path into the datatype.  Figure 2 gives a small example program that uses these \noper\u00adations. Importantly, the type annotations on these operations can Figure 4. Vellvm s byte-oriented \nmemory model. This .gure shows (part of) a memory state that might be reached by calling the function \nfoo from Figure 2. Blocks less than 40 were allocated; the next fresh block to allocate is 40. Block \n5 is deallocated, and thus marked invalid to access; fresh blocks (= 40) are also invalid. Invalid memory \nblocks are gray, and valid memory blocks that are accessible are white. Block 11 contains data with structure \ntype {i10, [10 x i8*]} but it might be read (due to physical subtyping) at the type {i10, i8*}. This \ntype is .attened into two byte-sized memory cells for the i10 .eld, two uninitialized padding cells to \nadjust alignment, and four pointer memory cells for the .rst element of the array of 32-bit i8* pointers. \nHere, that pointer points to the 24th memory cell of block 39. Block 39 contains an uninitialized i32 \ninteger represented by four muninit cells followed by a pointer that points to the 32nd memory cell of \nblock 11.  be any .rst-class type, which includes arbitrary bit-width integers, .oating point values, \npointers, and aggregated types arrays and structures. The LLVM IR semantics treats memory as though it \nis dynamically typed: the sizes, layout, and alignment, of a value read via a load instruction must be \nconsistent with that of the data that was stored at that address, otherwise the result is unde.ned. This \napproach leads to a memory model structured in two parts: (1) a low-level byte-oriented representation \nthat stores values of basic (non-aggregated) types along with enough information to in\u00addicate physical \nsize, alignment, and whether or not the data is a pointer, and (2) an encoding that .attens LLVM-level \nstructured data with .rst-class types into a sequence of basic values, comput\u00ading appropriate padding \nand alignment from the type. The next two subsections describe these two parts in turn. 3.3 The byte-oriented \nrepresentation The byte-oriented representation is composed of blocks of memory cells. Each cell is a \nbyte-sized quantity that describes the smallest chunk of contents that a memory operation can access. \nCells come in several .avors: Memory cells mc :: = mb(sz, byte) | mptr(blk, ofs, idx) | muninit The \nmemory cell mb(sz, byte) represents a byte-sized chunk of numeric data, where the LLVM-level bit-width \nof the integer is given by sz and whose contents is byte. For example, an integer with bit-width 32 is \nrepresented by four mb cells, each with size parameter 32. An integer with bit-width that is not divisible \nby 8 is encoded by the minimal number of bytes that can store the integer, i.e., an integer with bit-width \n10 is encoded by two bytes, each with size parameter 10 (see Figure 4). Floating point values are encoded \nsimilarly. Memory addresses are represented as a block identi.er blk and an offset ofs within that block; \nthe cell mptr(blk, ofs, idx) is a byte-sized chunk of such a pointer where idx is an index identifying \nwhich byte the chunk corresponds to. Because Vellvm s implementation assumes 32-bit pointers, four such \ncells are needed to encode one LLVM-pointer, as shown in Figure 4. Loading a pointer succeeds only if \nthe 4 bytes loaded are sequentially indexed from 0 to 3. The last kind of cell is muninit, which represents \nuninitialized memory, layout padding, and bogus values that result from unde\u00ad.ned computations (such \nas might arise from an arithmetic over\u00ad.ow). Given this de.nition of memory cells, a memory state M = \n(N, B, C) includes the following components: N is the next fresh block to allocate, B maps a valid block \nidenti.er to the size of the block; C maps a block identi.er and an offset within the block to a memory \ncell (if the location is valid). Initially, N is 1; B and C are empty. Figure 4 gives a concrete example \nof such a memory state for the program in Figure 2. There are four basic operations over this byte-oriented \nmemory state: alloc, mfree, mload, and mstore. alloc allocates a fresh memory block N with a given size, \nincrements N, .lls the newly allocated memory cells with muninit. mfree simply removes the deallocated \nblock from B, and its contents from C. Note that the memory model does not recycle block identi.ers deallocated \nby a mfree operation, because this model assumes that a memory is of in.nite size. The mstore operation \nis responsible for breaking non-byte sized basic values into chunks and updating the appropriate mem\u00adory \nlocations. Basic values are integers (with their bit-widths), .oats, addresses, and padding. Basic values \nbv :: = Int sz | Float | blk.ofs | pad sz Basic types btyp :: = isz | fp | typ* mload is a partial function \nthat attempts to read a value from a memory location. It is annotated by a basic type, and ensures compatibility \nbetween memory cells at the address it reads from and the given type. For example, memory cells for an \ninteger with bit-width sz cannot be accessed as an integer type with a different bit-width; a sequence \nof bytes can be accessed as .oating point values if they can be decoded as a .oating point value; pointers \nstored in memory can only be accessed by pointer types. If an access is type incompatible, mload returns \npad sz, which is an error value representing an arbitrary bit pattern with the bitwidth sz of the type \nbeing loaded. mload is unde.ned in the case that the memory address is not part of a valid allocation \nblock.  3.4 The LLVM .attened values and memory accesses LLVM s structured data is .attened to lists \nof basic values that indicate its physical representation: Flattened Values v :: = bv | bv, v A constant \ncnst is .attened into a list of basic values according to it annotated type. If the cnst is already of \nbasic type, it .attens into the singleton list. Values of array type [ sz \u00d7 typ ] are .rst .attened element-wise \naccording to the representation given by typ and then padded by uninitialized values to match typ s alignment \nrequirements as determined by the module s layout descriptor. The resulting list is then concatenated \nto obtain the appropriate .attened value. The case when a cnst is a structure type is similar. The LLVM \nload instruction works by .rst .attening its type annotation typ into a list of basic types, and mapping \nmload across the list; it then merges the returned basic values into the .nal LLVM value. Storing an \nLLVM value to memory works by .rst .attening to a list of basic values and mapping mstore over the result. \n. LLVMND LLVMInterp LLVMD ; LLVM DFn * ; LLVM DB *  Figure 5. Relations between different operational \nsemantics. Each equivalence or inclusion is justi.ed by a proof in Vellvm. This scheme induces a notion \nof dynamically-checked physical subtyping: it is permitted to read a structured value at a different \ntype from the one at which it was written, so long as the basic types they .atten into agree. For non-structured \ndata types such as integers, Vellvm s implementation is conservative for example, reading an integer \nwith bit width two from the second byte of a 10\u00adbit wide integer yields undef because the results are, \nin general, platform speci.c. Because of this dynamically-checked, physical subtyping, pointer-to-pointer \ncasts can be treated as the identity. Similar ideas arise in other formalizations of low-level language \nsemantics [24, 25]. The LLVM malloc and free operations are de.ned by alloc and mfree in a straightforward \nmanner. As the LLVM IR does not explicitly distinguish the heap and stack and function calls are implementation-speci.c, \nthe memory model de.nes the same se\u00admantics for stack allocation (alloca) and heap allocation (malloc) \nboth of them allocate memory blocks in memory. However, the operational semantics (described next) maintains \na list of blocks allocated by alloca for each function, and it deallocates them on return. 4. Operational \nSemantics Vellvm provides several related operational semantics for the LLVM IR, as summarized in Figure \n5. The most general is LLVMND , a small-step, nondeterministic evaluation relation given by rules of \nthe form con.g f S -S' (see Figure 6). This sec\u00adtion .rst motivates the need for nondeterminism in understanding \nthe LLVM semantics and then illustrates LLVMND by explain\u00ading some of its rules. Next, we introduce several \nequivalent de\u00adterministic re.nements of LLVMND LLVMD , LLVM * DB , and LLVM * DFn each of which has \ndifferent uses, as described in Sec\u00adtion 4.4. All of these operational semantics must handle various \nerror conditions, which manifest as partiality in the rules. Sec\u00adtion 4.3 describes these error conditions, \nand relates them to the static semantics of Section 2. Vellvm s operational rules are speci.ed as transitions \nbetween machine states S of the form M , S, where M is the memory and S is a stack of frames. A frame \nkeeps track of the current function .d and block label l, as well as the continuation sequence of commands \nc to execute next ending with the block terminator tmn. The map . tracks bindings for the local variables \n(which are not stored in M ), and the list a keeps track of which memory blocks were created by the alloca \ninstruction so that they can be marked as invalid when the function call returns. 4.1 Nondeterminism \nin the LLVM operational semantics There are several sources of nondeterminism in the LLVM se\u00admantics: \nthe undef value, which stands for an arbitrary (and ephemeral) bit pattern of a given type, various memory \nerrors, such as reading from an uninitialized location. Unlike the fatal errors, which are modeled by \nstuck states (see Section 4.3), we choose to model these behaviors nondeterministically because they \ncorre\u00adspond to choices that would be resolved by running the program with a concrete memory implementation. \nMoreover, the LLVM op\u00adtimization passes use the .exibility granted by this underspeci.city to justify \naggressive optimizations. Con.gurations: Fun tables . :: = v . id Globals g :: = id . v Con.gurations \ncon.g :: = mod, g, . Nondeterministic Machine States: Value sets V :: = {v | F(v)} Locals . :: = id . \nV Allocas a :: = [] | blk,a Frames S :: = .d, l, c, tmn, .,a Call stacks S :: = [] | S, S Program states \nS :: = M , S con.g f S -S ' evalND (g, ., val)= LV J .ndfdef (mod, ., v)= Lde.ne typ .d ' (arg){(l ' \n[]c ' tmn ' ), b}J v . V initlocals (g, ., arg, param)= L. 'J c0 =(option id = call typ val param) NDS \nCALL mod, g, . f M , ((.d, l, (c0, c), tmn, .,a), S) -M , ((.d' , l' , c ' , tmn ' , .' , []), (.d, \nl, (c0, c), tmn, .,a), S) evalND (g, ., val)= LV J c0 =(option id = call typ val param) freeallocas (M \n,a ' )= LM 'J NDS RET '' ' mod, g, . f M , ((.d, l, [], ret typ val, .',a'), (.d, l, (c0, c), tmn, .,a), \nS) -M , ((.d, l, c, tmn, .{id . V },a), S) evalND (g, ., val)= LV J true . V .ndblock (mod, .d, l1)=(l1f1c1tmn1) \ncomputephinodesND (g, ., l, l1,f1)= L. 'J NDS BR TRUE mod, g, . f M , ((.d, l, [], br val l1 l2, .,a), \nS) -M , ((.d, l1, c1, tmn1, . ' ,a), S) evalND (g, ., val)= LV J v . V c0 =(id = malloc typ val align) \nmalloc (M , typ, v, align)= LM ' , blkJ NDS MALLOC mod, g, . f M , ((.d, l, (c0, c), tmn, .,a), S) -M \n' , ((.d, l, c, tmn, .{id .{blk.0}},a), S) evalND (g, ., val)= LV J v . V c0 =(id = alloca typ val align) \nmalloc (M , typ, v, align)= LM , blkJ NDS ALLOCA mod, g, . f M , ((.d, l, (c0, c), tmn, .,a), S) -M \n' , ((.d, l, c, tmn, .{id .{blk.0}}, (blk,a)), S) evalND (g, ., val1)= LV1J evalND (g, ., val2)= LV2J \nevalbopND (bop, sz , V1, V2)= V3 NDS BOP mod, g, . f M , ((.d, l, (id = bop( int sz)val1 val2, c), \ntmn, .,a), S) -M , ((.d, l, c, tmn, .{id . V3},a), S) Figure 6. LLVMND : Small-step, nondeterministic \nsemantics of the LLVM IR (selected rules). Nondeterminism shows up in two ways in the LLVMND seman\u00adtics. \nFirst, stack frames bind local variables to sets of values V ; second, the -relation itself may relate \none state to many possible successors. The semantics teases apart these two kinds of nonde\u00adterminism \nbecause of the way that the undef value interacts with memory operations, as illustrated by the examples \nbelow. From the LLVM Language Reference Manual: Unde.ned val\u00adues indicate to the compiler that the program \nis well de.ned no matter what value is used, giving the compiler more freedom to optimize. Semantically, \nLLVMND treats undef as the set of all values of a given type. For some motivating examples, consider \nthe following code fragments: (a) %z = xor i8 undef undef (b) %x = add i8 0 undef %z = xor i8 %x %x \n (c) %z = or i8 undef 1 (d) br undef %l1 %l2  The value computed for %z in example (a) is the set of \nall 8-bit integers: because each occurrence of undef could take on any bit pattern, the set of possible \nresults obtained by xoring them still includes all 8-bit integers. Perhaps surprisingly, example (b) \ncom\u00adputes the same set of values for %z: one might reason that no mat\u00adter which value is chosen for undef, \nthe result of xoring %x with itself would always be 0, and therefore %z should always be 0. However, \nwhile that answer is compatible with the LLVM language reference (and hence allowed by the nondeterministic \nsemantics), it is also safe to replace code fragment (b) with %z = undef. The reason is that the LLVM \nIR adopts a liberal substitution prin\u00adciple: because %x = undef would be a legitimate replacement for \n.rst assignment in (b), it is allowed to substitute undef for %x throughout, which reduces the assignment \nto %z to the same code as in (a). Example (c) shows why the semantics needs arbitrary sets of values. \nHere, %z evaluates to the set of odd 8-bit integers, which is the result of oring 1 with each element \nof the set {0,..., 255}. This code snippet could therefore not safely be replaced by %z = undef; however \nit could be optimized to %z= 1 (or any other odd 8-bit integer). Example (d) illustrates the interaction \nbetween the set-semantics for local values and the nondeterminism of the -relation. The control state \nof the machine holds de.nite information, so when a branch occurs, there may be multiple successor states. \nSimilarly, we choose to model memory cells as holding de.nite values, so when writing a set to memory, \nthere is one successor state for each possible value that could be written. As an example of that interac\u00adtion, \nconsider the following example program, which was posted to the LLVMdev mailing list, that reads from \nan uninitialized memory location: %buf = alloca i32 %val = load i32* %buf store i32 10, i32* %buf ret \n%val The LLVM mem2reg pass optimizes this program to program (a) below; though according to the LLVM \nsemantics, it would also be admissible to replace this program with option (b) (perhaps to expose yet \nmore optimizations): (a) ret i32 10 (b) ret i32 undef  4.2 Nondeterministic operational semantics of \nthe SSA form The LLVMND semantics we have developed for Vellvm (and the others described below) is parameterized \nby a con.guration, which is a triple of a module containing the code, a (partial) map g that gives the \nvalues of global constants, and a function pointer table . that is a (partial) map from values to function \nidenti.ers (see the top of Figure 6). The globals and function pointer maps are initialized from the \nmodule de.nition when the machine is started. The LLVMND rules relate machine states to machine states, \nwhere a machine state takes the form of a memory M (from Section 3) and a stack of evaluation frames. \nThe frames keep track of the (sets of) values bound to locally-allocated temporaries and which instructions \nare currently being evaluated. Figure 6 shows a selection of evaluation rules from the development. Most \nof the commands of the LLVM have straight-forward in\u00adterpretation: the arithmetic, logic, and data manipulation \ninstruc\u00adtions are all unsurprising the evalND function computes a set of .attened values from the global \nstate, the local state, and an LLVM val, looking up the meanings of variables in the local state as needed; \nsimilarly, evalbopND implements binary operations, computing the result set by combining all possible \npairs drawn from its input sets. LLVMND s malloc behaves as described in Section 3, while load uses the \nmemory model s ability to detect ill-typed and uninitialized reads and, in the case of such errors, yields \nundef as the result. Function calls push a new stack frame whose initial local bindings are computed \nfrom the function param\u00adeters. The a component of the stack frame keeps track of which blocks of memory \nare created by the alloca instruction (see rule NDS ALLOCA); these are freed when the function returns \n(rule NDS RET). There is one other wrinkle in specifying the operational se\u00admantics when compared to \na standard environment-passing call\u00adby-value language. All of the f instructions for a block must be \nexecuted atomically and with respect to the old local value map\u00adping due to possibility of self loops \nand dependencies among the f nodes. For example the well-formed code fragment below has a circular dependency \nbetween %x and %z blk: %x = phi i32 [ %z, %blk ], [ 0, %pred ] %z = phi i32 [ %x, %blk ], [ 1, %pred \n] %b = icmp leq %x %z br %b %blk %succ If control enters this block from %pred, %x will map to 0 and \n%z to 1, which causes the conditional branch to succeed, jumping back to the label %blk. The new values \nof %x and %z should be 1 and 0, and not, 1 and 1 as might be computed if they were handled sequentially. \nThis update of the local state is handled by the computephinodesND function in the operational semantics, \nas shown, for example, in rule NDS BR TRUE.  4.3 Partiality, preservation, and progress Throughout the \nrules the lift notation f(x)= LvJ indicates that a partial function f is de.ned on x with value v. As \nseen by the frequent uses of lifting, both the nondeterministic and deterministic semantics are partial \nthe program may get stuck. Some of this partiality is related to well-formedness of the SSA program. \nFor example, evalND (g, ., %x) is unde.ned if %x is not bound in .. These kinds of errors are ruled out \nby the static well\u00adformedness constraints imposed by the LLVM IR (Section 2). In other cases, we have \nchosen to use partiality in the oper\u00adational semantics to model certain failure modes for which the LLVM \nspeci.cation says that the behavior of the program is unde\u00ad.ned. These include: (1) attempting to free \nmemory via a pointer not returned from malloc or that has already been deallocated, (2) allocating a \nnegative amount of memory, (3) calling load or store on a pointer with bad alignment or a deallocated \naddress, (4) trying to call a non-function pointer, or (5) trying to execute the unreachable command. \nWe model these events by stuck states because they correspond to fatal errors that will occur in any \nrea\u00adsonable realization of the LLVM IR by translation to a target plat\u00adform. Each of these errors is \nprecisely characterized by a predi\u00adcate over the machine state (e.g., BadFree(con.g,S)), and the allowed \nstuck states are de.ned to be the disjunction of these predicates: Stuck(con.g,S) = BadFree(con.g,S) \n. BadLoad(con.g,S) . ... . Unreachable(con.g,S) To see that the well-formedness properties of the static \nseman\u00adtics rule out all but these known error con.gurations, we prove the usual preservation and progress \ntheorems for the LLVMND seman\u00adtics. THEOREM 2 (Preservation for LLVMND ). If (con.g, S) is well formed \nand con.g f S -S ', then (con.g, S ') is well formed. Here, well-formedness includes the static scoping, \ntyping prop\u00aderties, and SSA invariants from Section 2 for the LLVM code, but also requires that the local \nmappings . present in all frames of the call stack must be inhabited each binding contains at least one \nvalue v and that each de.ned variable that dominates the current continuation is in . s domain. To show \nthat the . bindings are inhabited after the step, we prove that (1) non-undef values V are singletons; \n(2) unde.ned values from constants typ undef contain all possible values of .rst class types typ; (3) \nunde.ned values from loading uninitialized memory or incompatible physical data contain at least paddings \nindicating errors; (4) evaluation of non-deterministic values by evalbopND returns non-empty sets of \nvalues given non-empty inputs. The dif.cult part of showing that de.ned variables dominate their uses \nin the current continuation is proving that control\u00adtransfers maintain the dominance property [20]. If \na program branches from a block b1 to b2, the .rst command in b2 can use either the falling-through variables \nfrom b1, which must be de.ned in . by Lemma 1, or the variables updated by the fs at the be\u00adginning of \nb2. This latter property requires a lemma showing that computephinodeND behaves as expected. THEOREM \n3 (Progress for LLVMND ). If the pair (con.g, S) is well formed, then either S has terminated successfully \nor Stuck(con.g,S) or there exists S such that con.g f S -S ' . This theorem holds because in a well-formed \nmachine state, evalND always returns a non-empty value set V ; moreover jump targets and internal functions \nare always present. 4.4 Deterministic re.nements Although the LLVMND semantics is useful for reasoning \nabout the validity of LLVM program transformations, Vellvm provides a LLVMD , a deterministic, small-step \nre.nement, along with two large-step operational semantics LLVM * DB . DFn and LLVM * These different \ndeterministic semantics are useful for several reasons: (1) they provide the basis for testing LLVM programs \nwith a concrete implementation of memory (see the discussion about Vellvm s extracted interpreter in \nthe next Section), (2) proving that LLVMD is an instance of the LLVMND and relating the small\u00adstep rules \nto the large-step ones provides validation of all of the semantics (i.e., we found bugs in Vellvm by \nformalizing multiple semantics and trying to prove that they are related), and (3) the small-and large-step \nsemantics have different applications when reasoning about LLVM program transformations. Unlike LLVMND \n, the frames for these semantics map identi\u00ad.ers to single values, not sets, and the operational rules \ncall deter\u00administic variants of the nondeterministic counterparts (e.g., eval instead of evalND ). To \nresolve the nondeterminism from undef and faulty memory operations, these semantics .x a concrete inter\u00adpretation \nas follows: undef is treated as a zeroinitializer  Reading uninitialized memory returns zeroinitializer \n These choices yield unrealistic behaviors compared to what one might expect from running a LLVM program \nagainst a C-style run\u00adtime system, but the cases where this semantics differs correspond to unsafe programs. \nThere are still many programs, namely those compiled to LLVM from type-safe languages, whose behaviors \nun\u00adder this semantics should agree with their realizations on target platforms. Despite these differences \nfrom LLVMND , LLVMD also has the preservation and progress properties. Big-step semantics Vellvm also \nprovides big-step operational se\u00admantics LLVM * DFn , which evaluates a function call as one large step, \nand LLVM * DB , which evaluates each sub-block i.e., the code between two function calls as one large \nstep. Big-step se\u00admantics are useful because compiler optimizations often transform multiple instructions \nor blocks within a function in one pass. Such transformations do not preserve the small-step semantics, \nmaking it hard to create simulations that establish correctness properties. As a simple application of \nthe large-step semantics, consider trying to prove the correctness of a transformation that re-orders \nprogram statements that do not depend on one another. For exam\u00adple, the following two programs result \nin the same states if we con\u00adsider their execution as one big-step, although their intermediate states \ndo not match in terms of the small-step semantics. (a) %x = add i32 %a, %b (b) %y = load i32* %p %y = \nload i32* %p %x = add i32 %a, %b The proof of this claim in Vellvm uses the LLVM * rules DB to hide the \ndetails about the intermediate states. To handle mem\u00adory effects, we use a simulation relation that uses \nsymbolic eval\u00aduation [22] to de.ne the equivalence of two memory states. The memory contents are de.ned \nabstractly in terms of the program operations by recording the sequence of writes. Using this tech\u00adnique, \nwe de.ned a simple translation validator to check whether the semantics of two programs are equivalent \nwith respect to such re-orderings execution. For each pair of functions, the validator en\u00adsures that \ntheir control-.ow graphs match, and that all correspond\u00ading sub-blocks are equivalent in terms of their \nsymbolic evaluation. This approach is similar to the translation validation used in prior work for verifying \ninstruction scheduling optimizations [32]. Although this is a simple application of Vellvm s large-step \nsemantics, proving correctness of other program transformations such as dead expression elimination and \nconstant propagation fol\u00adlow a similar pattern the difference is that, rather than checking that two \nmemories are syntactically equivalent according to the symbolic evaluation, we must check them with respect \nto a more semantic notion of equivalence [22]. Relationships among the semantics Figure 5 illustrates \nhow these various operational semantics relate to one another. Vel\u00adlvm provides proofs that LLVM * DFn \nand that DB simulates LLVM * LLVM * DFn simulates LLVMD . In these proofs, simulation is taken to mean \nthat the machine states are syntactically identical at cor\u00adresponding points during evaluation. For example, \nthe state at a function call of a program running on the LLVM * semantics DFn matches the corresponding \nstate at the function call reached in LLVMD . Note that in the deterministic setting, one-direction sim\u00adulation \nimplies bisimulation [18]. Moreover, LLVMD is a re.ne\u00adment instance of the nondeterministic LLVMND semantics. \n These relations are useful because the large-step semantics in\u00adduce different proof styles than the \nsmall-step semantics: in partic\u00adular, the induction principles obtained from the large step seman\u00adtics \nallow one to gloss over insigni.cant details of the small step semantics. 5. Vellvm Infrastructure and \nValidation This section brie.y describes the Coq implementation of Vellvm and its related tools for interacting \nwith the LLVM infrastructure. It also describes how we validate the Vellvm semantics by extracting an \nexecutable interpreter and comparing its behavior to the LLVM reference interpreter. 5.1 The Coq development \nVellvm encodes the abstract syntax from Section 2 in an entirely straightforward way using Coq s inductive \ndatatypes (generated in a preprocessing step via the Ott [27] tool). The implementation uses Penn s Metatheory \nlibrary [4], which was originally designed for the locally nameless representation, to represent identi.ers \nof the LLVM, and to reason about their freshness. The Coq representation deviates from the full LLVM \nlanguage in only a few (mostly minor) ways. In particular, the Coq represen\u00adtation requires that some \ntype annotations be in normal form (e.g., the type annotation on load must be a pointer), which simpli.es \ntype checking at the IR level. The Vellvm tool that imports LLVM bitcode into Coq provides such normalization, \nwhich simply ex\u00adpands de.nitions to reach the normal form. In total, the syntax and static semantics \nconstitute about 2500 lines of Coq de.nitions and proof scripts. Vellvm s memory model implementation \nextends CompCert s with approximately 5000 lines of code to support integers with ar\u00adbitrary precision, \npadding, and an experimental treatment of casts that has not yet been needed for any of our proofs. On \ntop of this extended memory model, all of the operational semantics and their metatheory have been proved \nin Coq. In total, the development rep\u00adresents approximately 32,000 lines of Coq code. Checking the en\u00adtire \nVellvm implementation using coqc takes about 13.5 minutes on a 1.73 GHz Intel Core i7 processor with \n8 GB RAM. We expect that this codebase could be signi.cantly reduced in size by refac\u00adtoring the proof \nstructure and making it more modular. The LLVM distribution includes primitive OCaml bindings that are \nsuf.cient to generate LLVM IR code ( bitcode in LLVM jar\u00adgon) from OCaml. To convert between the LLVM \nbitcode repre\u00adsentation and the extracted OCaml representation, we implemented a library consisting of \nabout 5200 lines of OCaml-LLVM bindings. This library also supports pretty-printing of the AST s; this \ncode was also useful in the extracted the interpreter. Omitted details This paper does not discuss all \nof the LLVM IR features that the Vellvm Coq development supports. Most of these features are uninteresting \ntechnically but necessary to support real LLVM code: (1) The LLVM IR provides aggregate data operations \n(extractvalue and insertvalue) for projecting and updating the elements of structures and arrays; (2) \nthe operational semantics supports external function calls by assuming that their behavior is speci.ed \nby axioms; the implementation applies these axioms to transition program states upon calling external \nfunctions; (3) the LLVM switch instruction, which is used to compile jump tables, is lowered to the normal \nbranch instructions that Vellvm supports by a LLVM-supported pre-processing step. Unsupported features \nSome features of LLVM are not supported by Vellvm. First, the LLVM provides intrinsic functions for extend\u00ading \nLLVM or to represent functions that have well known names and semantics and are required to follow certain \nrestrictions for example, functions from standard C libraries, handling variable ar\u00adgument functions, \netc. Second, the LLVM functions, global vari\u00adables, and parameters can be decorated with attributes that \ndenote linkage type, calling conventions, data representation, etc. which provide more information to \ncompiler transformations than what the LLVM type system provides. Vellvm does not statically check the \nwell-formedness of these attributes, though they should be obeyed by any valid program transformation. \nThird, Vellvm does not support the invoke and unwind instructions, which are used to implement exception \nhandling, nor does it support variable argu\u00adment functions. Forth, Vellvm does not support vector types, \nwhich allow for multiple primitive data values to be computed in parallel using a single instruction. \n 5.2 Extracting an interpreter To test Vellvm s operational semantics for the LLVM IR, we used Coq s \ncode extraction facilities to obtain an interpreter for execut\u00ading the LLVM distribution s regression \ntest suite. Extracting such an interpreter is one of the main motivations for developing a deter\u00administic \nsemantics, because the evaluation under the nondetermin\u00adistic semantics cannot be directly compared against \nactual runs of LLVM IR programs. Unfortunately, the small-step deterministic semantics LLVMD is de.ned \nrelationally in the logical fragment of Coq, which is con\u00advenient for proofs, but can not be used to \nextract code. Therefore, Vellvm provides yet another operational semantics, LLVMInterp, which is a deterministic \nfunctional interpreter implemented in the computational fragment of Coq. LLVMInterp is proved to be bisim\u00adilar \nto LLVMD , so we can port results between the two semantics. Although one could run this extracted interpreter \ndirectly, doing so is not ef.cient. First, integers with arbitrary bit-width are induc\u00adtively de.ned \nin Coq. This yields easy proof principles, but does not give an ef.cient runtime representation; .oating \npoint operations are de.ned axiomatically. To remedy these problems, at extraction, we realize Vellvm \ns integer and .oating point values by ef.cient C++ libraries that are a standard part of the LLVM distribution. \nSecond, the memory model implementation of Vellvm maintains memory blocks and their associated metadata \nas functional lists, and it converts between byte-list and value representations at each memory access. \nUsing the extracted data-structures directly incurs tremendous performance overhead, so we replaced the \nmemory op\u00aderations of the memory model with native implementations from the C standard library. A value \nv in local mappings d is boxed, and it is represented by a reference to memory that stores its content. \nOur implementation faithfully runs 134 out of the 145 tests from the LLVM regression suite that lli, \nthe LLVM distribution inter\u00adpreter, can run. The missing tests cover instructions (like variable arguments) \nthat are not yet implemented in Vellvm. Although replacing the Coq data-structures by native ones inval\u00adidates \nthe absolute correctness guarantees one would expect from an extracted interpreter, this exercise is \nstill valuable. In the course of carrying out this experiment, we found one severe bug in the semantics: \nthe br instruction inadvertently swapped the true and false branches. 6. Veri.ed SoftBound SoftBound \n[21] is a previously proposed program transformation that hardens C programs against spatial memory safety \nviolations (e.g., buffer over.ows, array indexing errors, and pointer arithmetic errors). SoftBound works \nby .rst compiling C programs into the LLVM IR, and then instrumenting the program with instructions that \npropagate and check per-pointer metadata. SoftBound main\u00adtains base and bound metadata with each pointer, \nshadowing loads and stores of pointer with parallel loads and stores of their associ\u00adated metadata. This \ninstrumentation ensures that each pointer deref\u00aderenced is within bounds and aborts the program otherwise. \n The original SoftBound paper includes a mechanized proof that validates the correctness of this idea, \nbut it is not complete. In par\u00adticular, the proof is based on a subset of a C-like language with only \nstraight-line commands and non-aggregate types, while a real Soft-Bound implementation needs to consider \nall of the LLVM IR shown in Figure 3, the memory model, and the operational semantics of the LLVM. Also \nthe original proof ensures the correctness only with respect to a speci.cation that the SoftBound instrumentation \nmust implement, but does not prove the correctness of the instru\u00admentation pass itself. Moreover, the \nspeci.cation requires that ev\u00adery temporary must contain metadata, not just pointer temporaries. Using \nVellvm to verify SoftBound This section describes how we use Vellvm to formally verify the correctness \nof the Soft-Bound instrumentation pass with respect to the LLVM semantics, demonstrating that the promised \nspatial memory safety property is achieved. Moreover, Vellvm allows us to extract a veri.ed OCaml implementation \nof the transformation from Coq. The end result is a compiler pass that is formally veri.ed to transform \na program in the LLVM IR into a program augmented with suf.cient checking code such that it will dynamically \ndetect and prevent all spatial memory safety violations. SoftBound is a good test case for the Vellvm \nframework. It is a non-trivial translation pass that nevertheless only inserts code, thereby making it \neasier to prove correct. SoftBound s intended use is to prevent security vulnerabilities, so bugs in \nits implementation can potentially have severe consequences. Also, the existing Soft-Bound implementation \nalready uses the LLVM. Modi.cations to SoftBound since the original paper As de\u00adscribed in the original \npaper, SoftBound modi.es function signa\u00adtures to pass metadata associated with the pointer parameters \nor returned pointers. To improve the robustness of the tool, we transi\u00adtioned to an implementation that \ninstead passes all pointer metadata on a shadow stack. This has two primary advantages. The .rst is that \nthis design simpli.es the implementation while simultaneously better supporting indirect function calls \n(via function pointers) and more robustly handling improperly declared function prototypes. The second \nis that it also simpli.es the proofs. 6.1 Formalizing SoftBound for the LLVM IR The SoftBound correctness \nproof has the following high-level structure: 1. We de.ne a nonstandard operational semantics SBspec \nfor the LLVM IR. This semantics builds in the safety properties that should be enforced by a correct \nimplementation of SoftBound. It uses meta-level datastructures to implement the metadata and meta-level \nfunctions to de.ne the semantics of the bounds checks. 2. We prove that an LLVM program P, when run \non the SBspec semantics, has no spatial safety violations. 3. We de.ne a translation pass SBtrans(-) \nthat instruments the LLVM code to propagate metadata. 4. We prove that a program if SBtrans(P )= LP \n' J then P , when run on the LLVMD , simulates P running on SBspec.  The SoftBound speci.cation Figure \n7 gives the program con.g\u00adurations and representative rules for the SBspec semantics. SBspec behaves \nthe same as the standard semantics except that it creates, propagates, and checks metadata of pointers \nin the appropriate in\u00adstructions. Nondeterministic rules: Metadata md :: = [v1, v2) Memory metadata \nMM :: = blk.ofs . md Frames S :: = .d, l, c, tmn, ., \u00b5, a  Call stacks S :: = [] | S, S Local metadata \n\u00b5 :: = id . md Program states S :: = M , MM , S evalND (g, ., val)= LV J v . V c0 =(id = malloc typ val \nalign) malloc (M , typ, v, align)= LM ' , blkJ \u00b5 ' = \u00b5{id . [blk.0, blk.(sizeof typ \u00d7 v))} SB MALLOC \n '' mod, g, . f M , MM , ((.d, l, (c0, c), tmn, ., \u00b5, a), S) -M , MM , ((.d, l, c, tmn, .{id .{blk.0}},\u00b5 \n,a), S) evalND (g, ., val)= LV J v . V c0 =(id = load (typ*)val align) .ndbounds(g, \u00b5, val)= LmdJ checkbounds(typ, \nv, md) load (M , typ, v, align)= Lv ' J if isPtrTyp typ then \u00b5 ' = \u00b5{id . .ndbounds (MM , v)} else \u00b5 \n' = \u00b5 SB LOAD ' mod, g, . f M , MM , ((.d, l, (c0, c), tmn, ., \u00b5, a), S) -M , MM , ((.d, l, c, tmn, \n.{id . {|v '|}},\u00b5 ,a), S) evalND (g, ., val1)= LV1J v1 . V1 evalND (g, ., val2)= LV2J v2 . V2 c0 =(store \ntyp val1 val2 align) .ndbounds(g, \u00b5, val2)= LmdJ checkbounds(typ, v2, md) store (M , typ, v1, v2, align)= \nLM ' J if isPtrTyp typ then MM ' = MM {v2 . md} else MM ' = MM SB STORE mod, g, . f M , MM , ((.d, l, \n(c0, c), tmn, ., \u00b5, a), S ) -M ' , MM ' , ((.d, l, c, tmn, ., \u00b5, a), S ) Deterministic con.gurations: \nFrames s :: = .d, l, c,tmn,d, \u00b5,a s :: = [] | ss :: =Call stacks s, Program states M , MM ,s Figure 7. \nSBspec: The speci.cation semantics for SoftBound. Differences from the LLVMND rules are highlighted. \nA program state S is an extension of the standard program state S for maintaining metadata md, which \nis a pair de.ning the start and end address for a pointers: \u00b5 in each function frame S maps temporaries \nof pointer type to their metadata; MM is the shadow heap that stores metadata for pointers in memory. \nNote that al\u00adthough the speci.cation is nondeterministic, the metadata is de\u00adterministic. Therefore, \na pointer loaded from uninitialized memory space can be undef, but it cannot have arbitrary md (which \nmight not be valid). SBspec is correct if a program P must either abort on detecting a spatial memory \nviolation with respect to the SBspec, or preserve the LLVM semantics of the original program P ; and, \nmoreover, P is not stuck by any spatial memory violation in the SBspec (i.e., SBspec must catch all spatial \nviolations). DEFINITION 1 (Spatial safety). Accessing a memory location at the offset ofs of a block \nblk is spatially safe if blk is less than the next fresh block N , and ofs is within the bounds of blk: \nblk <N . (B(blk)= LsizeJ. 0 = ofs < size) The legal stuck states of SoftBound StuckSB (con.g,S ) in\u00adclude \nall legal stuck states of LLVMND (recall Section 4.3) except the states that violate spatial safety. \nThe case when B does not map blk to some size indicates that blk is not valid, and pointers into the \nblk are dangling this indicates a temporal safety error that is not prevented by SoftBound and therefore \nit is included in the set of legal stuck states. Because the program states of a program in the LLVMND \nse\u00admantics are identical to the corresponding parts in the SBspec, it is easy to relate them: let S .. \nS mean that common parts of the SoftBound state S and S are identical. Because memory instruc\u00adtions in \nthe SBspec may abort without accessing memory, the .rst part of correctness is by a straightforward simulation \nrelation be\u00adtween states of the two semantics. THEOREM 4 (SBspec simulates LLVMND ). If the state S .. \nS, and con.g f S -S ', then there exists a state S ', such that con.g f S -S ', and S ' .. S ' . The \nsecond part of the correctness is proved by the following preservation and progress theorems. THEOREM \n5 (Preservation for SBspec). If (con.g, S ) is well formed, and con.g f S -S ', then (con.g, S ') is \nwell formed. Here, SBspec well-formedness strengthens the invariants for LLVMND by requiring that if \nany id de.ned in . is of pointer type, then \u00b5 contains its metadata and a spatial safety invariant: all \nbounds in \u00b5s of function frames and MM must be memory ranges within which all memory addresses are spatially \nsafe. The interesting part is proving that the spatial safety invariant is preserved. It holds initially, \nbecause a program s initial frame stack is empty, and we assume that MM is also empty. The other cases \ndepend on the rules in Figure 7. The rule SB MALLOC, which allocates the number v of ele\u00adments with typ \nat a memory block blk, updates the metadata of id with the start address that is the beginning of blk, \nand the end address that is at the offset blk.(sizeof typ \u00d7 v) in the same block. LLVM s memory model \nensures that the range of memory is valid. The rule SB LOAD reads from a pointer val with runtime data \nv, .nds the md of the pointer, and ensures that v is within the md via checkbounds. If the val is an \nidenti.er, .ndbounds simply returns the identi.er s metadata from \u00b5, which must be a spatial safe memory \nrange. If val is a constant of pointer type, .ndbounds returns bounds as the following. For global point\u00aders, \n.ndbounds returns bounds derived from their types because globals must be allocated before a program \nstarts. For pointers con\u00adverted from some constant integers by inttoptr, it conservatively returns the \nbounds [null, null) to indicate a potentially invalid memory range. For a pointer cnst1 derived from \nan other constant pointer cnst2 by bitcase or getelementptr, .ndbounds re\u00adturns the same bound of cnst2 \nfor cnst1. Note that {|v ' |} denotes conversion from a deterministic value to a nondeterministic value. \nIf the load reads a pointer-typed value v from memory, the rule .nds its metadata in MM and updates the \nlocal metadata mapping \u00b5. If MM does not contain any metadata indexed by  Figure 8. Simulation relations \nof the SoftBound pass v, that means the pointer being loaded was not stored with valid bounds, so .ndbounds \nreturns [null, null) to ensure the spatial safety invariant. Similarly, the rule SB STORE checks whether \nthe address to be stored to is in bounds and, if storing a pointer, updates MM accordingly. SoftBound \ndisallows dereferencing a pointer that was converted from an interger, even if that integer was originally \nobtained from a valid pointer. Following the same design choice, .ndbounds returns [null, null) for pointers \ncast from integers. checkbounds fails when a program accesses such pointers. THEOREM 6 (Progress for \nSBspec). If S 1 is well-formed, then ei\u00adther S 1 is a .nal state, or S 1 is a legal stuck state, or there \nexists a S 2 such that con.g f S 1 -S 2. This theorem holds because all the bounds in a well-formed SBspec \nstate give memory ranges that are spatially safe, if checkbounds succeeds, the memory access must be \nspatially safe. The correctness of the SoftBound instrumentation Given SB\u00adspec, we designed an instrumentation \npass in Coq. For each func\u00adtion of an original program, the pass implements \u00b5 by generating two fresh \ntemporaries for every temporary of pointer type to record its bounds. For manipulating metadata stored \nin MM , the pass ax\u00adiomatizes a set of interfaces that manage a disjoint metadata space with speci.cations \nfor their behaviors. Figure 8 pictorially shows the simulation relations .. between an original program \nP in the semantics of SBspec and its trans\u00adformed program P ' in the LLVM semantics. First, because P \n' needs additional memory space to store metadata, we need a map\u00adping mi that maps each allocated memory \nblock in M to a mem\u00adory block in M ' without overlap, but allows M ' to have additional blocks for metadata, \nas shown in dashed boxes. Note that we as\u00adsume the two programs initialize globals identically. Second, \nbasic values are related in terms of the mapping between blocks: pointers are related if they refer to \ncorresponding memory locations; other basic values are related if they are same. Two values are related \nif they are of the same length and the corresponding basic values are related. Using the value simulations, \n.. de.nes a simulation for mem\u00adory and stack frames. Given two related memory locations blk.ofs and blk \n' .ofs ', their contents in M and M ' must be related; if MM maps blk.ofs to the bound [v1, v2), then \nthe additional metadata ' '' space in M must store v1 and v2 that relate to v1 and v2 for the location \nblk ' .ofs '. For each pair of corresponding frames in the two stacks, . and . ' must store related values \nfor the same temporary; if \u00b5 maps a temporary id to the bound [v1, v2), then . ' must store the related \nbound in the fresh temporaries for the id. THEOREM 7. Given a state s 1 of P with con.guration con.g \n'' ' and a state s1 of P with con.guration con.g ', if s 1 .. s1, and con.g f s 1 -. s 2, then there \nexists a state s2' , such that ''' ' con.g f s1 -. * s2, s 2 .. s2.  Figure 9. Execution time overhead \nof the extracted and the C++ version of SoftBound Here, con.g f s 1 -. s 2 is a deterministic SBspec \nthat, as in Section 4, is an instance of the non-deterministic SBspec. The correctness of SoftBound THEOREM \n8 (SoftBound is correct). Let SBtrans(P )= LP ' J denote that the SoftBound pass instruments a well-formed \nprogram P to be P '. A SoftBound instrumented program P ' either aborts on detecting spatial memory violations \nor preserves the LLVM se\u00admantics of the original program P . P ' is not stuck by any spatial memory violation. \n 6.2 Extracted veri.ed implemention of SoftBound The above formalism not only shows that the SoftBound \ntrans\u00adformation enforces the promised safety properties, but the Vellvm framework allows us to extract \na translator directly from the Coq code, resulting in a veri.ed implementation of the SoftBound trans\u00adformation. \nThe extracted implementation uses the same underlying shadowspace implementation and wrapped external \nfunctions as the non-extracted SoftBound transformation written in C++. The only aspect not handled by \nthe extracted transformation is initial\u00adizing the metadata for pointers in the global segment that are \nnon-NULL initialized (i.e., they point to another variable in the global segment). Without initialization, \nvalid programs can be incorrectly rejected as erroneous. Thus, we reuse the code from the C++ imple\u00admentation \nof the SoftBound to properly initialize these variables. Effectiveness To measure the effectiveness of \nthe extracted im\u00adplementation of SoftBound versus the C++ implementation, we tested both implementations \non the same programs. To test whether the implementations detect spatial memory safety violations, we \nused 1809 test cases from the NIST Juliet test suite of C/C++ codes [23]. We chose the test cases which \nexercised the buffer over\u00ad.ows on both the heap and stack. Both implementations of Soft-Bound correctly \ndetected all the buffer over.ows without any false violations. We also con.rmed that both implementations \nproperly detected the buffer over.ow in the go SPEC95 benchmark. Fi\u00adnally, the extracted implementation \nis robust enough to success\u00adfully transform and execute (without false violations) several ap\u00adplications \nselected from the SPEC95, SPEC2000, and SPEC2006 suites (around 110K lines of C code in total). Performance \noverheads Unlike the C++ implementation of Soft-Bound that removes some obviously redundant checks, the \nex\u00adtracted implementation of SoftBound performs no SoftBound\u00adspeci.c optimizations. In both cases, the \nsame suite of standard LLVM optimizations are applied post-transformation to optimize the code to reduce \nthe overhead of the instrumentation. To deter\u00admine the performance impact on the resulting program, Figure \n9 reports the execution time overheads (lower is better) of extracted SoftBound (leftmost bar of each \nbenchmark) and the C++ imple\u00admentation (rightmost bar of each benchmark) for various bench\u00admarks from \nSPEC95, SPEC2000 and SPEC2006. Because of the check elimination optimization performed by the C++ implemen\u00adtation, \nthe code is slightly faster, but overall the extracted imple\u00admentation provides similar performance. \n Bugs found in the original SoftBound implementation In the course of formalizing the SoftBound transformation, \nwe discov\u00adered two implementation bugs in the original C++ implementation of SoftBound. First, when one \nof the incoming values of a f node with pointer type is an undef, undef was propagated as its base and \nbound. Subsequent compiler transformations may instantiate the unde.ned base and bound with de.ned values \nthat allow the checkbounds to succeed, which would lead to memory viola\u00adtion. Second, the base and bound \nof constant pointer (typ*) null was set to be (typ*) null and (typ*) null+sizeof (typ), allowing dereferences \nof null or pointers pointing to an offset from null. Ei\u00adther of these bugs could have resulted in faulty \nchecking and thus expose the program to the spatial violations that SoftBound was designed to prevent. \nThese bugs underscore the importance of a formally veri.ed and extracted implementation to avoid such \nbugs. 7. Related Work Mechanized language semantics There is a large literature on formalizing language \nsemantics and reasoning about the correct\u00adness of language implementations. Prominent examples include: \nFoundational Proof Carrying Code [2], Foundational Typed As\u00adsembly Language [11], Standard ML [12, 30], \nand (a substantial subset of) Java [15]. Veri.ed compilers Compiler veri.cation has a considerable his\u00adtory; \nsee the bibliography [18] for a comprehensive overview. Other research has also used Coq for compiler \nveri.cation tasks, includ\u00ading much recent work on compiling functional source languages to assembly [5, \n8, 9]. Vellvm is closer in spirit to CompCert [18], which was the .rst fully-veri.ed compiler to generate \ncompact and ef.cient assembly code for a large fragment of the C language. CompCert also uses Coq. It \nformalizes the operational semantics of CompCert C, sev\u00aderal intermediate languages used in the compilation, \nand assembly languages including PowerPC, ARM and x86. The latest version of CompCert also provides an \nexecutable reference interpreter for the semantics of CompCert C. Based on the formalized seman\u00adtics, \nthe CompCert project fully proves that all compiler phases produce programs that preserve the semantics \nof the original pro\u00adgram. Optimization passes include local value numbering, constant propagation, coalescing \ngraph coloring register allocation [6], and other back-end transformations. CompCert has also certi.ed \nsome advanced compiler optimizations [32 34] using translation valida\u00adtion [22, 26]. The XCERT project \n[29, 31] extends the CompCert compiler by a generic translation validator based on SMT solvers. Other \nmechanization efforts The veri.ed software tool-chain project [3] assures that the machine-checked proofs \nclaimed at the top of the tool-chain hold in the machine language program. Typed assembly languages [7] \nprovide a platform for proving back-end optimizations. Similarly, The Verisoft project [1] also attempts \nto mathematically prove the correct functionality of systems in auto\u00admotive engineering and security \ntechnology. ARMor [37] guaran\u00adtees control .ow integrity for application code running on embed\u00added processors. \nThe Rhodium project [17] uses a domain speci.c language to express optimizations via local rewrite rules \nand pro\u00advides a soundness checker for optimizations Validating LLVM optimizations The CoVac project [36] \ndevel\u00adops a methodology that adapts existing program analysis tech\u00adniques to the setting of translation \nvalidation, and reports on a prototype tool that applies their methodology to veri.cation of the LLVM \ncompiler. The LLVM-MD project [35] validates LLVM op\u00adtimizations by symbolic evaluation. The Peggy tool \nperforms trans\u00adlation validation for the LLVM compiler using a technique called equality saturation [28]. \nThese applications are not fully certi.ed. 8. Conclusion Although we do not consider it in this paper, \nour intention is that the Vellvm framework will serve as a .rst step toward a fully\u00adveri.ed LLVM compiler, \nsimilar to that of Leroy et al. s Comp-Cert [18]. Our Coq development extends some of CompCert s libraries \nand our LLVM memory model is based on CompCert s memory model. The focus of this paper is the LLVM IR \nsemantics itself, the formalization of which is a necessary step toward a fully\u00adveri.ed LLVM compiler. \nBecause much of the complexity of an LLVM-based compiler lies in the IR to IR transformation passes, \nformalizing correctness properties at this level stands to yield a signi.cant payoff, as demonstrated \nby our SoftBound case study, even without fully verifying a compiler. Acknowledgments This research was \nfunded in part by the U.S. Government. The views and conclusions contained in this document are those \nof the authors and should not be interpreted as representing the of.cial policies, either expressed or \nimplied, of the U.S. Government. This research was funded in part by DARPA contract HR0011-10-9\u00ad0008 \nand ONR award N000141110596. This material is based upon work supported by the National Sci\u00adence Foundation \nunder Grant No. CNS-1116682, CCF-1065166, and CCF-0810947. Any opinions, .ndings, and conclusions or \nrec\u00adommendations expressed in this material are those of the author(s) and do not necessarily re.ect \nthe views of the National Science Foundation. References [1] E. Alkassar and M. A. Hillebrand. Formal \nfunctional veri.cation of device drivers. In VSTTE 08: Proceedings of the 2nd International Conference \non Veri.ed Software: Theories, Tools, Experiments, 2008. [2] A. W. Appel. Foundational proof-carrying \ncode. In LICS 01: Pro\u00adceedings of the 16th Annual IEEE Symposium on Logic in Computer Science, 2001. \n[3] A. W. Appel. Veri.ed software toolchain. In ESOP 11: Proceedings of the 20th European Conference \non Programming Languages and Systems, 2011. [4] B. Aydemir, A. Chargu\u00b4eraud, B. C. Pierce, R. Pollack, \nand S. Weirich. Engineering formal metatheory. In POPL 08: Proceedings of the 35th Annual ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, 2008. [5] N. Benton and N. Tabareau. Compiling functional \ntypes to relational speci.cations for low level imperative code. In TLDI 09: Proceedings of the 4th International \nWorkshop on Types in Language design and Implementation, 2009. [6] S. Blazy, B. Robillard, and A. W. \nAppel. Formal veri.cation of co\u00adalescing graph-coloring register allocation. In ESOP 10: Proceed\u00adings \nof the 19th European Conference on Programming Languages and Systems, 2010. [7] J. Chen, D. Wu, A. W. \nAppel, and H. Fang. A provably sound TAL for back-end optimization. In PLDI 03: Proceedings of the ACM \nSIGPLAN 2003 Conference on Programming Language Design and Implementation, 2003. [8] A. Chlipala. A veri.ed \ncompiler for an impure functional language. In POPL 10: Proceedings of the 37th Annual ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, 2010.  [9] A. Chlipala. A certi.ed type-preserving \ncompiler from lambda cal\u00adculus to assembly language. In PLDI 07: Proceedings of the ACM SIGPLAN 2007 \nConference on Programming Language Design and Implementation, 2007. [10] The Coq Proof Assistant Reference \nManual (Version 8.3pl1). The Coq Development Team, 2011. [11] K. Crary. Toward a foundational typed assembly \nlanguage. In POPL 03: Proceedings of the 30th ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages, 2003. [12] K. Crary and R. Harper. Mechanized def\u00adinition of standard ml (alpha release), \n2009. http://www.cs.cmu.edu/ crary/papers/2009/ mldef-alpha.tar.gz. [13] R. Cytron, J. Ferrante, B. K. \nRosen, M. N. Wegman, and F. K. Zadeck. Ef.ciently computing static single assignment form and the control \ndependence graph. ACM Trans. Program. Lang. Syst., 13:451 490, 1991. [14] G. A. Kildall. A uni.ed approach \nto global program optimization. In POPL 73: Proceedings of the 1st Annual ACM SIGACT-SIGPLAN Symposium \non Principles of Programming Languages, 1973. [15] G. Klein, T. Nipkow, and T. U. M\u00a8unchen. A machine-checked \nmodel for a Java-like language, virtual machine and compiler. ACM Trans. Program. Lang. Syst., 28:619 \n695, 2006. [16] C. Lattner and V. Adve. LLVM: A Compilation Framework for Life\u00adlong Program Analysis \n&#38; Transformation. In CGO 04: Proceedings of the International Symposium on Code Generation and Optimiza\u00adtion: \nFeedback-directed and Runtime Optimization, 2004. [17] S. Lerner, T. Millstein, E. Rice, and C. Chambers. \nAutomated sound\u00adness proofs for data.ow analyses and transformations via local rules. In POPL 05: Proceedings \nof the 32th ACM SIGPLAN-SIGACT Sym\u00adposium on Principles of Programming Languages, 2005. [18] X. Leroy. \nA formally veri.ed compiler back-end. Journal of Auto\u00admated Reasoning, 43(4):363 446, 2009. [19] The \nLLVM Reference Manual (Version 2.6). The LLVM Development Team, 2010. http://llvm.org/releases/2.6/docs/LangRef.html. \n[20] V. S. Menon, N. Glew, B. R. Murphy, A. McCreight, T. Shpeisman, A.-R. Adl-Tabatabai, and L. Petersen. \nA veri.able SSA program rep\u00adresentation for aggressive compiler optimization. In POPL 06: Pro\u00adceedings \nof the 33th ACM SIGPLAN-SIGACT Symposium on Princi\u00adples of Programming Languages, 2006. [21] S. Nagarakatte, \nJ. Zhao, M. M. K. Martin, and S. Zdancewic. Soft-Bound: Highly compatible and complete spatial memory \nsafety for C. In PLDI 09: Proceedings of the ACM SIGPLAN 2009 Conference on Programming Language Design \nand Implementation, 2009. [22] G. C. Necula. Translation validation for an optimizing compiler. In PLDI \n00: Proceedings of the ACM SIGPLAN 2000 Conference on Programming Language Design and Implementation, \n2000. [23] NIST Juliet Test Suite for C/C++. NIST, 2010. http://samate.nist.gov/SRD/testCases/suites/Juliet-2010-12.c.cpp.zip. \n [24] M. Nita and D. Grossman. Automatic transformation of bit-level C code to support multiple equivalent \ndata layouts. In CC 08: Proceed\u00adings of the 17th International Conference on Compiler Construction, 2008. \n[25] M. Nita, D. Grossman, and C. Chambers. A theory of platform\u00addependent low-level software. In POPL \n08: Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, \n2008. [26] A. Pnueli, M. Siegel, and E. Singerman. Translation validation. In TACAS 98: Proceedings of \nthe 4th International Conference on Tools and Algorithms for Construction and Analysis of Systems, 1998. \n[27] P. Sewell, F. Zappa Nardelli, S. Owens, G. Peskine, T. Ridge, S. Sarkar, and R. Strnisa. Ott: Effective \ntool support for the working semanticist.. In ICFP 07: Proceedings of the 9th ACM SIGPLAN International \nConference on Functional Programming, 2007. [28] M. Stepp, R. Tate, and S. Lerner. Equality-Based translation \nvalidator for LLVM. In CAV 11: Proceedings of the 23rd International Con\u00adference on Computer Aided Veri.cation, \n2011. [29] Z. T. Sudipta Kundu and S. Lerner. Proving optimizations correct using parameterized program \nequivalence. In PLDI 09: Proceedings of the ACM SIGPLAN 2009 Conference on Programming Language Design \nand Implementation, 2009. [30] D. Syme. Reasoning with the formal de.nition of Standard ML in HOL. In \nSixth International Workshop on Higher Order Logic Theorem Proving and its Applications, 1993. [31] Z. \nTatlock and S. Lerner. Bringing extensibility to veri.ed compilers. In PLDI 10: Proceedings of the ACM \nSIGPLAN 2010 Conference on Programming Language Design and Implementation, 2010. [32] J.-B. Tristan and \nX. Leroy. Formal veri.cation of translation valida\u00adtors: a case study on instruction scheduling optimizations. \nIn POPL 08: Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Sympo\u00adsium on Principles of Programming \nLanguages, 2008. [33] J.-B. Tristan and X. Leroy. Veri.ed validation of lazy code motion. In PLDI 09: \nProceedings of the ACM SIGPLAN 2009 Conference on Programming Language Design and Implementation, 2009. \n[34] J. B. Tristan and X. Leroy. A simple, veri.ed validator for soft\u00adware pipelining. In POPL 10: Proceedings \nof the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan\u00adguages, 2010. [35] J.-B. \nTristan, P. Govereau, and G. Morrisett. Evaluating value-graph translation validation for llvm. In PLDI \n11: Proceedings of the ACM SIGPLAN 2011 Conference on Programming Language Design and Implementation, \n2011. [36] A. Zaks and A. Pnueli. Program analysis for compiler validation. In PASTE 08: Proceedings \nof the 8th ACM SIGPLAN-SIGSOFT Work\u00adshop on Program Analysis for Software Tools and Engineering, 2008. \n[37] L. Zhao, G. Li, B. De Sutter, and J. Regehr. ARMor: Fully veri.ed software fault isolation. In EMSOFT \n11: Proceedings of the 9th ACM International Conference on Embedded Software, 2011.    \n\t\t\t", "proc_id": "2103656", "abstract": "<p>This paper presents Vellvm (verified LLVM), a framework for reasoning about programs expressed in LLVM's intermediate representation and transformations that operate on it. Vellvm provides a mechanized formal semantics of LLVM's intermediate representation, its type system, and properties of its SSA form. The framework is built using the Coq interactive theorem prover. It includes multiple operational semantics and proves relations among them to facilitate different reasoning styles and proof techniques.</p> <p>To validate Vellvm's design, we extract an interpreter from the Coq formal semantics that can execute programs from LLVM test suite and thus be compared against LLVM reference implementations. To demonstrate Vellvm's practicality, we formalize and verify a previously proposed transformation that hardens C programs against spatial memory safety violations. Vellvm's tools allow us to extract a new, verified implementation of the transformation pass that plugs into the real LLVM infrastructure; its performance is competitive with the non-verified, ad-hoc original.</p>", "authors": [{"name": "Jianzhou Zhao", "author_profile_id": "81435599390", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P2991442", "email_address": "jianzhou@cis.upenn.edu", "orcid_id": ""}, {"name": "Santosh Nagarakatte", "author_profile_id": "81435608524", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P2991443", "email_address": "santoshn@cis.upenn.edu", "orcid_id": ""}, {"name": "Milo M.K. Martin", "author_profile_id": "81100426086", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P2991444", "email_address": "milom@cis.upenn.edu", "orcid_id": ""}, {"name": "Steve Zdancewic", "author_profile_id": "81384616728", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P2991445", "email_address": "stevez@cis.upenn.edu", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103709", "year": "2012", "article_id": "2103709", "conference": "POPL", "title": "Formalizing the LLVM intermediate representation for verified program transformations", "url": "http://dl.acm.org/citation.cfm?id=2103709"}