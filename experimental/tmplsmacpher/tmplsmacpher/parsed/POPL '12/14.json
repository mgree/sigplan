{"article_publication_date": "01-25-2012", "fulltext": "\n Multiple Facets for Dynamic Information Flow Thomas H. Austin Cormac Flanagan taustin@uscs.edu cormac@ucsc.edu \nUniversity of California, Santa Cruz Abstract JavaScript has become a central technology of the web, \nbut it is also the source of many security problems, including cross-site scripting attacks and malicious \nadvertising code. Central to these problems is the fact that code from untrusted sources runs with full \nprivileges. We implement information .ow controls inFirefoxtohelpprevent violations of data con.dentiality \nand integrity. Most previous information .ow techniques have primarily re\u00adlied on either static type \nsystems, which are a poor .t for JavaScript, or on dynamic analyses that sometimes get stuck due to problem\u00adatic \nimplicit .ows, even in situations where the target web applica\u00adtion correctly satis.es the desired security \npolicy. We introduce faceted values, a new mechanism for providing information .ow security in a dynamic \nmanner that overcomes these limitations. Taking inspiration from secure multi-execution, we use faceted \nvalues to simultaneously and ef.ciently simulate multiple executions for different security levels, thus \nproviding non-interference with minimal overhead, and without the reliance on the stuck executions of \nprior dynamic approaches. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language \nConstructs and Features; D.4.6 [Operating Systems]: Security and Protection Information .ow controls \nGeneral Terms Languages, Security Keywords Information .ow control, dynamic analysis, JavaScript, web \nsecurity 1. Introduction JavaScript has helped to usher in a new age of richly interactive web applications. \nOften times, developers build these sites by including JavaScript code from a number of different sources. \nWith minimal effort, a web developer can build an impressive site by composing code from multiple sources. \nUnfortunately, there are few restrictions on the included code, and it operates with the same authority \nas the web developer s own code. Advertising has been a particular source of malicious JavaScript. There \nare a wide array of security measures used to de\u00adfend against these problems, but the bulk of them tend \nto rely on competent web developers. Given the mercurial nature of security challenges, even a conscientious \nweb developer has dif.culty keep\u00ading up with the latest trends and best practices. Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 12, January 25 27, \n2012, Philadelphia, PA, USA. Copyright c . 2012 ACM 978-1-4503-1083-3/12/01. . . $10.00. Another option \nis to bake security controls into the browser itself. This strategy has been part of browser design since \nnearly the beginning, but the controls have tended to be fairly minimal. Information .ow analysis offers \nthe promise of a systematic solution to many of these security challenges, but to date it has not achieved \nits potential, largely because much research on static information .ow type systems is an awkward .t \nfor dynamically typed JavaScript code. Additionally, there has been a folklore that dynamic information \n.ow analysis is not sound in the presence of implicit .ows. This folklore is not true, however, and proposed \nmechanisms for dealing with implicit .ows include the no-sensitive-upgrade semantics [39, 5] and the \npermissive-upgrade semantics [6]. Both semantics guarantee the key correctness property of termination\u00adinsensitive \nnon-interference (TINI), which states that private inputs do not in.uence public outputs. (Private information \ncan in.uence termination, but this channel is limited to a brute force attack [1]). Despite this correctness \nguarantee, neither semantics provides an ideal foundation for JavaScript security since both suffer from \nthe same weakness: in the presence of subtle implicit .ows that are hard to track, the semantics halts \nexecution in order to avoid any (potential) information leak. Note that this fail-stop is not caused \nby the web application violating a security policy; instead it is a mechanism failure causedbythe inability \nof the dynamic infor\u00admation .ow analysis to track implicit .ows. Thus, these dynamic analyses reject \nvalid programs that conform to the security policy. An interesting solution to these mechanism failures \nis to si\u00admultaneously execute two copies of the target program: a high\u00adcon.dentiality (H) process that \nhas access to secret data, and a low-con.dentiality (L) process that sees dummy default values in\u00adstead \nof the actual secret data [9, 13]. This multi-process execution cleanly guarantees non-interference since \nno information .ow is permitted between the two processes, and it also avoids mechanism failures. Unfortunately, \nfor a web page with n principals (roughly, URL domains), we may require up to 2n processes, one for each \nelement in the powerset lattice for these principals. In this paper, we combine the bene.ts of multi-process \nexecu\u00adtion with the ef.ciency of single-process execution. The key tech\u00adnical novelty is the introduction \nof a faceted value, which is a pair of two raw values that contain low and high con.dentiality infor\u00admation, \nrespectively. By appropriately manipulating these faceted values, a single process can simulate the two \nprocesses (L and H) of the multi-execution approach. The primary bene.t of this approach is that, for \nmost data, the two raw values in a faceted value are iden\u00adtical, in which case we collapse the two simulated \nexecutions on identical data into a single execution, drastically reducing the over\u00adhead. In the presence \nof multiple principals and a complex security lattice, a faceted value can contain many raw values, rather \nthan just two. In this situation, the semantics of tracking information .ow is a little more complex, \ncosting some run-time performance overhead. However, our experimental results suggest that faceted evaluation \noutperforms multi-process execution as the number of principals increases.  This paper includes a formal \ndescription of the faceted value approach to dynamic information .ow analysis, and a proof that it achieves \ntermination-insensitive non-interference. We also present a projection theorem showing that a computation \nover faceted val\u00adues simulates 2n non-faceted computations, one for each element in the powerset security \nlattice. We have implemented this mech\u00adanism inside the Firefox browser (using the Zaphod plug-in [26]) \nin order to validate its utility in a web browsing context. Addition\u00adally, we have used this implementation \nto compare the performance of faceted values against multi-process execution. Finally, we dis\u00adcuss declassi.cation \nand how it relates to faceted values, noting this feature as an additional point of distinction with \nmulti-process execution. 1.1 Overview of Faceted Evaluation To motivate the need for faceted values in \ndynamic information .ow, we start by considering the classic problem of implicit .ows, such as those \ncaused by a conditional assignment: if (x) y =true The central insight of this paper is that the correct \nvalue for y after this assignment depends on the authority of the observer. For example, suppose initially \nthat x = true and y = false,and that x is secret whereas y is public. Then after this assignment: A \nprivate observer that can read x should see y = true.  A public observer that cannot read x should see \ny = false, since it should not see any in.uence from this conditional as\u00adsignment.  Faceted values represent \nexactly this dual nature of y, which should simultaneously appear as true and false to different observers. \nIn more detail, a faceted value is a triple consisting of a principal k and two values VH and VL, which \nwe write as: (k ? VH : VL ) Intuitively, this faceted value appears as VH to private observers that can \nview k s private data, and as VL to other public observers. We refer to VH and VL as private and public \nfacets, respectively. This faceted value representation naturally generalizes the tra\u00additional public \nand private security labels used by prior analyses. A public value V is represented in our setting simply \nas V itself, since V appears the same to both public and private observers and so no facets are needed. \nA private value V is represented as the faceted value (k ? V : .) where only private observers can see \nV , and where public or unau\u00adthorized observers instead see . (roughly meaning unde.ned). Although the \nnotions of public and private data have been well explored by earlier dynamic information .ow analyses, \nthese two security labels are insuf.cient to avoid stuck executions in the pres\u00adence of implicit .ows. \nAs illustrated by the conditional assignment considered above, correct handling of implicit .ows requires \nthe in\u00adtroduction of more general notion of faceted values (k ? VH : VL), in which the public facet VL \nis a real value and not simply ..In particular, the post-assignment value for y is cleanly represented \nas the faceted value (k ? true : false) that captures y s appearance to both public and private observers. \nBased on this faceted value representation, this paper develops a dynamic analysis that tracks information \n.ow in a sound manner at runtime. Our analysis is formulated as an evaluation semantics for the target \nprogram, where the semantics uses faceted values to track security and dependency information. This evaluation \nsemantics is designed to avoid leaking infor\u00admation between public and private facets. In particular, \nif C[ ] is any program context, then the computation C[(k ? VH : VL )] ap\u00adpears to behave exactly like \nC[VH ] from the perspective of a pri\u00advate observer, and behaves exactly like C[VL ] to a public observer \n(under a termination-insensitive notion of equivalence). This pro\u00adjection property means that a single \nfaceted computation simulates multiple non-faceted computations, one for each element in the se\u00adcurity \nlattice. This projection property also enables an elegant proof of termination-insensitive non-interference, \nshown in Section 3.2. Faceted values may be nested. Nested faceted values naturally arise during computations \nwith multiple principals. For example, if k1 and k2 denote different principals, then the expression \n(k1 ? true : .) &#38;&#38; (k2 ? false : .) evaluates to the nested faceted value (k1 ? (k2 ? false : \n.) : .) since the result false is visible only to observers authorized to see private data from both \nk1 and k2; any other observer instead sees the dummy value .. As a second example, the expression (k1 \n?2:0) + (k2 ?1:0) evaluates to the result (k1 ? (k2 ?3:2) : (k2 ?1:0)) Thus, faceted values form binary \ntrees with principals at interior nodes and raw (non-faceted) values at the leaves. The part of this \nfaceted value tree that is actually seen by a particular observer depends on whose private data the observer \ncan read. In particular, we de.ne the view of an observer as the set of principals whose private data \nthat observer can read. Thus, an observer with view {k1,k2} would see the result of 3 from this addition, \nwhereas an observer with view {k2} would see the result 1. When a faceted value in.uences the control \n.ow, in general we may need toexplore the behavior of theprogram under both facets1. For example, the \nevaluation of the conditional expression: if ( (k ? true : false) ) then e1 else e2 evaluates both e1 \nand e2, and carefully tracks the dependency of these computations on the principal k. In particular, \nassignments performed during e1 are visible only to views that include k, while assignments performed \nduring e2 are visible to views that exclude k. After the evaluations of e1 and e2 complete, their two \nresults are combined into a single faceted value that is returned to the continuation of this conditional \nexpression. That is, the execution is split only for the duration of this conditional expression, rather \nthan for the remainder of the entire program.  1.2 Handling Implicit Flows The key challenge in dynamic \ninformation .ow analysis lies in handling implicit .ows. To illustrate this dif.culty, consider the code \nin the .rst column of Figure 1, which is adapted from an example by Fenton [16]. Here, the function f(x) \nreturns the value of its boolean argument x, but it .rst attempts to launder this value by encoding it \nin the program counter. We consider the evaluation of f on the two secret arguments (k ? false : .) and \n(k ? true : .) (analogous to the more traditional falseH and trueH ) to determine if the argument in \nany way in.uences any public component of the function s result. For the argument (k ? false : .) shown \nin column 2, the local variables y and z are initialized to true. The conditional 1 The semantics is \noptimized to avoid such split executions where possible.  Function f(x) x = (k ? false : .) x = (k ? \ntrue : .) All strategies Naive NSU Permissive-Upgrade Faceted Evaluation y = true; z = true; if (x) y \n= false; if (y) z = false; return z; y = true z = true - - pc = {}z = false - y = true z = true pc = \n{k}y = (k ? false : .)- - - y = true z = true pc = {k}stuck y = true z = true pc = {k}y = (k ? false \n: *)stuck y = true z = true pc = {k}y = (k ? false : true)pc = {k}z = (k ? true : false)- Return Value: \nfalse true branch on x when x = (k ? false : .) is split into separate branches on false and .. The \n.rst test if(false) ... is clearly a no-op, and so is the second test if(.) ... since if is strict in \n..Since y remains true, the branch on y is taken and so z is set to false. Thus, the function call f((k \n? false : .)) returns false. We now consider the evaluation of f((k ? true : .)) under different dynamic \ninformation .ow semantics. While the prior se\u00admantics that we discuss here have no notion of facets, \nexplaining them in terms of faceted values is illuminating. Naive An intuitive strategy for handling \nthe assignment y=false that is conditional on the private input x is to simply set y to (k ? false : \n.) to re.ect that this value depends on private inputs. Unfortunately, this approach is not sound, since \nit loses the critical information that a public observer should still see y = true. The next conditional \nbranch on y exploits this confusion. Since y is (k ? false : .), the branch is not executed, so z remains \ntrue,and so f((k ? true : .)) returns true, as illustrated in column 3. Thus, this naive strategy fails \nto ensure TINI, since the public output of f leaks the contents of its private input. Various prior approaches \nattempt to close this information leak without introducing full faceted values, with mixed results. No-Sensitive-Upgrade \nWith the no-sensitive-upgrade check [39, 5], execution halts on any attempt to update public variables \nin code conditional on private data. Under this strategy, the assignment to the public variable y from \ncode conditional on a private variable x would get stuck, as shown in the NSU column of Figure 1. This \nstrategy guarantees TINI, but only at the expense of getting stuck on some implicit .ows. Permissive-Upgrade \nA more .exible approach is to permit the implicit .ow caused by the conditional assignment to y,but to \nrecord that the analysis has lost track of the correct (original) public facet for y.The Permissive-Upgrade \nrepresents this lost information by setting y to the faceted value (k ? false : *),where * denotes that \nthe public facet is an unknown, non-. value.2 This permissive upgrade strategy accepts strictly more \nprogram executions than the no-sensitive-upgrade approach, but it still re\u00adsorts to stuck executions \nin some cases; if the execution ever de\u00adpends on that missing public facet, then the permissive upgrade \nstrategy halts execution in order to avoid information leaks. In par\u00adticular, when y is used in the second \nconditional of Figure 1, the execution gets stuck. 2 The original paper [6] used the falseP to represent \n(k ? false : *), where the superscript P denotes partially leaked . (k ? true : false) Faceted Evaluation \nAs shown in the last column of Figure 1, faceted values cleanly handle problematic implicit .ows. At \nthe conditional assignment to y, the faceted value (k ? false : true)simultaneously represents the dual \nnature of y, which appears false to private observers but true to public observers. Thus, the conditional \nbranch if (y) ... is taken only for public observers, and we record this information by setting the program \ncounter label pc to {k}. Consequently, the assignment z=false updates z from true to (k ? true : false). \nCritically, this assignment updates only the public facet of z, not its private facet, which stays as \ntrue. The .nal result of the function call is then (k ? true : false). Comparing the behavior of f on \nthe arguments (k ? false : .) and (k ? true : .), we see that, from the perspective of a public observer, \nf always returns false, correctly re.ecting that f(.) returns false, and so there is no information leak \non this example, despite its problematic implicit .ows. Conversely, from the perspective of a private \nobserver authorized to view f s actual output, f exhibits the correct behavior of returning its private \nboolean argument.  2. A Programming Language with Facets We formalize faceted evaluation for dynamic \ninformation .ow in terms of the idealized language .facet shown in Figure 2. This lan\u00adguage extends the \n.-calculus with mutable reference cells, reactive I/O, a special value ., and a mechanism for creating \nfaceted val\u00adues. Despite its intentional minimality, this language captures the essential complexities \nof dynamic information .ow in more real\u00adistic languages, since it includes key challenges such as heap \nal\u00adlocation, mutation, implicit .ows, and higher-order function calls. In particular, conditional tests \ncan be Church-encoded in the usual fashion. Expressions in .facet include the standard features of the \n.\u00adcalculus, namely variables (x), constants (c), functions (.x.e), and function application (e1 e2). \nThe language also supports mutable reference cells, with operations to create (ref e), dereference (!e), \nand update (e1:= e2) a reference cell. To model JavaScript s in\u00adteractive nature, .facet also supports \nreading from (read(f))and writing to (write(f, e)) external resources such as .les. The expression (k \n? e1 : e2) creates a faceted values where the value of e1 is considered secret to principal k; observers \nthat cannot see k s private data will instead see the public facet produced by e2. We initially use the \nterms label and principals as synonyms and focus primarily on con.dentiality Section 5 later introduces \nintegrity labels in the context of robust declassi.cation. The . value is used to represent nothing , \nmirroring Smalltalk s nil and JavaScript s undefined. It is primarily used as the public facet in a faceted \nvalue (k ? V : .), which denotes a value V that is private to principal k, with no corresponding public \nvalue.  Figure 3: Standard Semantics Runtime Syntax a . Address s . store =(Address .p value . File \n. value * ) . . subst = Var .p value v . value ::= c | a | (.x.e, .) |. w . value * Evaluation Rules: \ns,., e . s',v [S-CONST] s, .,c . s, c [S-VAR] s,., x . s, .(x) [S-FUN] s, ., (.x.e) . s, (.x.e, .) s, \n.,e1 . s1, (.x.e, .') s1,., e2 . s2,v' s, .'[x := v'],e . s',v [S-APP] s, ., (e1 e2) . s',v s, .,e1 \n. s1, . s1,., e2 . s',v [S-APP-BOT] s, ., (e1 e2) . s', . s, .,e . s',v a . dom(s') [S-REF] s, ., (ref \ne) . s'[a := v],a s,., e . s',a [S-DEREF] s, ., !e . s',s'(a) s, .,e . s', . [S-DEREF-BOT] s, ., !e \n. s', . s, ., e1 . s1,a s1,.,e2 . s2,v [S-ASSIGN] s,., e1:= e2 . s2[a := v],v s, .,e1 . s1, . s1,.,e2 \n. s2,v [S-ASSIGN-BOT] s, .,e1:= e2 . s2,v s(f)= v.w [S-READ] s, ., read(f) . s[f := w],v s, .,e . s' \n,v [S-WRITE] s, ., write(f, e) . s'[f := s'(f).v],v [S-BOT] s, ., .. s, . Syntax: e ::= x, y, z c k, \nl f x c .x.e e1 e2 ref e !e e:= e read(f) write(f, e) (k ? e1 : e2) .  Standard encodings: true false \nif e1 then e2 else e3 if e1 then e2 let x = e1 in e2 e1 ; e2 def = def = def Term variable constant abstraction \napplication reference allocation dereference assignment .le read .le write faceted expression bottom \nVariable Constant Label (aka Principal) File handle .x..y.x .x..y.y =(e1 (.d.e2)(.d.e3)) (.x.x) def = \nif e1 then e2 else 0 def =(.x.e2) e1 def = let x = e1 in e2,x . FV (e2) 2.1 Standard Semantics of .facet \nAs a point of comparison for our later development, we .rst present a standard semantics for .facet that \ndoes not handle faceted expres\u00adsions. In this semantics, values include constants, addresses, clo\u00adsures, \nand ., as shown in Figure 3. A closure (.x.e, .) is a pair of a .-expression and a substitution . that \nmaps variables to val\u00adues. Each reference cell is allocated at an address a, and the store s maps addresses \nto values. The store also maps each .le f to a sequence of values w. Weuse thesyntax v.w and w.v to indicate \na list of values with v as the .rst or last value, respectively, and use \u00d8 to denote both the empty store \nand the empty substitution. We formalize the standard semantics via a big-step relation s,., e . s',v \nthat evaluates an expression e in the context of a store s and a sub\u00adstitution ., and which returns the \nresulting value v and the (possibly modi.ed) store s'. This relation is de.ned via the evaluation rules \nshown in Figure 3, which are mostly straightforward. For example, the rule [S-APP] evaluates the body \nof the called function, where the notation .[x := v] denotes the substitution that is identical to . \nexcept that it maps x to v. The only unusual aspect of this semantics concern the value ., which essentially \nmeans nothing or no information . Operations such as function application, dereference, and assignment \nare strict in .;ifgiven a . argument they simply return . via the vari\u00adous [S-*-BOT] rules. This semantics \nfor . facilitates our later use of . in faceted values, since, for example, dereferencing a faceted address \n(k ? a : .) operates pointwise on the two facets to return a faceted result (k ? v : .) where v = s(a). \n   3. Faceted Evaluation Having de.ned the standard semantics of the language, we now extend that semantics \nwith faceted values that dynamically track information .ow and which provide noninterference guarantees. \nFigure 4 shows the additional runtime syntax needed to sup\u00adport faceted values. We use Initial Capitals \nto distinguish the new metavariable and domains of the faceted semantics (V . Value, S . Store, T . Subst) \nfrom those of the standard semantics (v . value, s . store, . . subst). Values V now contain faceted \nvalues of the form (k ? VH : VL ) which contain both a private facet VH and a public facet VL.For instance, \nthe value (k ?42 : 0) indicates that 42 is con.dential to the principal k, and unauthorized viewers instead \nsee the value 0. Often, the public facet is set to . to denote that there is no intended publicly visible \nfacet. Implicit .ows introduce public facets other than .. We introduce a program counter label called \npc that records when the program counter has been in.uenced by public or private facets. For example, \nconsider the conditional test if ((k ? true : false)) then e1 else e2 for which our semantics needs to \nevaluate both e1 and e2.During the evaluation of e1,we add k to pc to record that this computation depends \non data private to k. Conversely, during the evaluation of e2,we add k to pc to record that this computation \nis dependent on the corresponding public facet. Formalizing this idea, we say that a branch h is either \na principal k or its negation k,and that pc is a set of branches. Note that pc can never include both \nk and k, since that would re.ect a computation dependent on both private and public facets. The following \noperation (( pc ? V1 : V2 )) creates new faceted values, where the resulting value appears like V1 to \nobservers that can see the computation corresponding to pc, and appears like V2 to all other observers. \ndef (( \u00d8 ? Vn : Vo )) = Vn def (( {k}. rest ? Vn : Vo )) = (k ? (( rest ? Vn : Vo )) : Vo) def (( {k}. \nrest ? Vn : Vo )) = (k ? Vo : (( rest ? Vn : Vo ))) For example, (( {k} ? VH : VL )) returns (k ? VH \n: VL ), and this operation generalizes to more complex program counter labels. We sometimes abbreviate \n(( {k} ? VH : VL )) as (( k ? VH : VL )). We de.ne the faceted value semantics via the big-step evalua\u00adtion \nrelation: S, T,e . pc S ' ,V that evaluates an expression e in the context of a store S, a sub\u00adstitution \nT, and a program counter label pc, and which returns the resulting value V and the (possibly modi.ed) \nstore S ' . Rule [F-SPLIT] shows how evaluation of a faceted expression (k ? e1 : e2) evaluates both \ne1 and e2 to values V1 and V2, with pc updated appropriately with k and k during these two evaluations. \nThe two values are then combined via the operation (( k ? V1 : V2 )). As an optimization, if the current \ncomputation already depends on k-private data (i.e., k . pc), then rule [F-LEFT] evaluates only e1, thus \npreserving the invariant that pc never contains both k and k. Conversely, if k . pc then [F-RIGHT] evaluates \nonly e2. Function application (e1 e2) is somewhat tricky, since e1 may evaluate to a faceted value tree \nwith closures (or .)at the leaves. Tohandlethissituation,therule [F-APP]evaluateseach ei to a value Vi \nand then delegates to the auxiliary judgement: S, (V1 V2) . pc S ' ,V ' This auxiliary judgement recursively \ntraverses through any faceted values in V1 to perform the actual function applications. If V1 is a closure, \nthen rule [FA-FUN] proceeds as normal. If V1 is a facet (k ? VH : VL), then the rule [FA-SPLIT] applies \nboth VH and VL to the argument V2, in a manner similar to the rule [F-SPLIT] discussed above. Rules [FA-LEFT] \nand [FA-RIGHT] are optimized versions of [FA-SPLIT] for cases where k or k are already in pc. Finally, \nthe unde.ned value . can be applied as a function and returns . via [FA-BOT](muchliketheearlier [S-APP-BOT]rule). \nAs an example, consider the function application (f 4) where f is a private function represented as (k \n?(.x.e): .).The rules [F-APP] and [FA-SPLIT] decompose the application (f 4) into two separate applications: \n((.x.e)4) and (. 4). The .rst appli\u00adcation evaluates normally via [FA-FUN] to a result, say V ,and the \nsecond application evaluates to . via [FA-BOT], so the result of the call is (k ? V : .), thus marking \nthe result of the call as private. The operand of a dereference operation (!e) may also be a facetedvaluetree.Inthiscase,therule \n[F-REF]usesthehelperfunc\u00adtion deref(S,Va, pc) to decompose Va into appropriate addresses, retrieve the \ncorresponding values from the store S, and to combine these store values into a new faceted value. As \nan optimization, any facets in the address Va that are not consistent with pc are ignored. Inasimilarmanner,therule \n[F-ASSIGN]usesthehelperfunction assign(S, pc, Va , V ) to decompose Va into appropriate addresses and \nto update the store S at those locations with V , while ensuring that each update is only visible to \nappropriate principals that are consistent with pc, to avoid information leaks via implicit .ows. The \nfaceted semantics of I/O operations introduces some addi\u00adtional complexities since it involves communication \nwith external, non-faceted .les. Each .le f has an associated view view(f)= {k1,...,kn} describing which \nobservers may see the contents of that .le. The following section de.nes when a computation with program \ncounter label pc is visible to a view L, and also interprets L to project a faceted value V to a non-faceted \nvalue v = L(V ). We use these two concepts to map between faceted computations and external non-faceted \nvalues in .les. A read operation read(f) may be executed multiple times with different pc labels. Of \nthese multiple executions, only the single execution where pc is visible to view(f) actually reads from \nthe .le via [F-READ]; all other executions are no-ops via [F-READ-IGNORE]. The non-faceted value v read \nfrom the .le is converted to a faceted value (( pc ' ? v : .)) that is only visible to view(f),where \npc ' is the program counter representation of that view. An output write(f, e) behaves in a similar manner, \nso only one execution writes to the .le via the rule [F-WRITE]. This rule uses the projection operation \nv = L(V ) where L = view(f) to project the faceted value V produced by e into a corresponding non-faceted \nvalue v that is actually written to the .le. For simplicity, we Church-encode conditional branches as \nfunc\u00adtion calls, and so the implicit .ows caused by conditional branches are a special case of those \ncaused by function calls and are appro\u00adpriately handled by the various rules in Figure 4. To provide \nhelp\u00adful intuition, however, Figure 5 sketches alternative direct rules for evaluating a conditional \ntest if e1 then e2 else e3. In particular, if e1 evaluates to a faceted value (k ? VH : VL), the if statement \nis evaluated potentially twice, using facets VH and VL as the condi\u00adtional test by the [F-IF-SPLIT]rule. \n 3.1 The Projection Property Recall that a view is a set of principals L = {k1,...,kn}.This view de.nes \nwhat values a particular observer is authorized to see. In particular, an observer with view L sees the \nprivate facet VH in avalue (k ? VH : VL) only when k . L, and sees VL otherwise. Thus, each view L serves \nas a projection function that maps each faceted value V . Value into a corresponding non-faceted value \n S . Store =(Address .p Value) . (File . Value * ) T . Subst = Var .p Value R . RawValue ::= c | a | \n(.x.e, T) |. V . Value ::= R |(k ? V1 : V2) h . Branch ::= k | k 2Branch pc . PC =  Evaluation Rules: \nS, T,e . pc S ' ,v S, T,e . pc S ' ,V ' [F-CONST] S, T,c . pc S,c a . dom(S ' ) V = (( pc ? V ' : .)) \n[F-REF] S, T, (ref e) . pc S ' [a := V ],a [F-VAR] S, T,x . pc S, T(x) S, T,e . pc S ' ,V V ' = deref \n(S ' , V , pc) [F-DEREF] S, T, !e . pc S ' ,V ' [F-FUN] S, T, (.x.e) . pc S, (.x.e, T) S, T,e1 . pc \nS1,V1 S, T,e1 . pc S1,V1 S1, T,e2 . pc S2,V ' S1, T,e2 . pc S2,V2 S ' = assign(S2 , pc, V1 , V ' ) [F-ASSIGN] \n S2, (V1 V2) . pc S ' ,V ' S, T,e1:= e2 . pc S ' ,V ' [F-APP] S, T, (e1 e2) . pc S ' ,V ' S(f)= v.w \nL = view(f) k . pc S, T,e1 ' . pc.{k} S1,V1 pc visible to L pc = L .{k | k . L} [F-READ] k . pc S1, \nT,e2 . pc.{k} S2,V2 S, T, read(f) . pc S[f := w], (( pc ' ? v : .)) [F-SPLIT] S, T, (k ? e1 : e2)..pc \nS2, (( k ? V1 : V2 )) pc not visible to view(f) [F-READ-IGNORE] k . pc S, T,e1 . pc S ' ,V S, T, read(f) \n. pc S, . [F-LEFT] S, T, (k ? e1 : e2)..pc S ' ,V S, T,e . pc S ' ,V pc visible to view(f) k . pc S, \nT,e2 . pc S ' ,V L = view(f) v = L(V ) [F-WRITE][F-RIGHT] S, T, (k ? e1 : e2)..pc S ' ,V S, T, write(f, \ne) . pc S ' [f := S ' (f).v],V S, T,e . pc S ' ,V pc not visible to view(f) [F-BOT] [F-WRITE-IGNORE] \nS, T, ...pc S, . S, T, write(f, e) . pc S ' ,V Application Rules S, (V1 V2) . pc S ' ,V ' S, T[x := \nV ],e . pc S ' ,V ' k . pc S, (VH V2) . pc S ' ,V [FA-FUN] [FA-LEFT] S, ((.x.e, T) V ) . pc S ' ,V ' \nS, ((k ? VH : VL) V2) . pc S ' ,V k . pc S, (VH V2) . pc.{k} S1,VH ' k . pc S, (VL V2) . pc S ' ,V [FA-RIGHT] \nS ' k . pc S1, (VL V2) . pc.{k} ,VL ' S, ((k ? VH : VL) V2) . pc S ' ,V [FA-SPLIT] S, ((k ? VH : VL) \nV2) . pc S ' , (( k ? VH ' : VL ' )) [FA-BOT] S, (. V ) . pc S, .  Auxiliary Functions deref : Store \n\u00d7 Value \u00d7 PC . Value deref (S, a, pc) =S(a) deref (S, ., pc)= . . . deref (S, VH) if k . pc deref (S, \n(k ? VH : VL), pc)= deref (S, VL) if k . pc . (( k ? deref (S, VH): deref (S, VL) )) otherwise assign \n: Store \u00d7 PC \u00d7 Value \u00d7 Value . Store assign(S, pc, a, V ) = S[a := (( pc ? V :S(a) ))] assign(S, pc, \n., V ) = S assign(S, pc, (k ? VH : VL), V ) = S ' where S1 = assign(S, pc .{k}, VH, V ) and S ' = assign(S1 \n, pc .{k}, VL , V )  S, T,e1 . pc S1, true S1, T,e2 . pc S ' ,V S, T, if e1 then e2 else e3 . pc S ' \n,V [F-IF-TRUE] S, T,e1 . pc S1, false S1, T,e3 . pc S ' ,V S, T, if e1 then e2 else e3 . pc S ' ,V [F-IF-FALSE] \nS, T,e1 . pc S ' , . S, T, if . then e2 else e3 . pc S ' , . [F-IF-BOT] S, T,e1 . pc S1, (k ? VH : VL)eH \n= if VH then e2 else e3 eL = if VL then e2 else e3 S1, T, (k ? eH : eL)..pc S ' ,V S, T, if e1 then e2 \nelse e3 . pc S ' ,V [F-IF-SPLIT] of the standard semantics: L : Value . value L(V1) if k . L L((k ? \nV1 : V2))= L(V2) if k . L L(c)= c L(a)= a L(.)= . L((.x.e, T)) = (.x.L(e),L(T)) We extend L to also project \nfaceted substitutions T . Subst and stores S . Store into non-faceted substitutions and stores of the \nstandard semantics. A .le f is visible only to view(f), and appears empty (E) to all other views. L : \nSubst . subst L(T) = .x. L(T(x))  L : Store . store L(S) = .a. L(S(a))   S(f) if L = view(f) . .f. \nE otherwise We also useaview L to operate on expressions, where this opera\u00adtion eliminates faceted expressions \nand also performs access con\u00adtrol on I/O operations by eliminating accesses to .les that are not authorized \nunder that view: L : Expr (with facets) . Expr (without facets) L(e1) if k . L L((k ? e1 : e2))= L(e2) \nif k . L read(f) if L = view(f)L(read(f)) = . otherwise  write(f, L(e)) if L = view(f)L(write(f, e)) \n= L(e) otherwise L(... )= compatible closure Thus, views naturally serve as a projection from each domain \nof the faceted semantics into a corresponding domain of the standard semantics. We now use these views-as-projections \nto formalize the relationship between these two semantics. A computation with program counter label pc \nis considered visible to a view L only when the principals mentioned in pc are consistent with L, in \nthe sense that: .k . pc,k . L .k . pc,k . L We .rst show that the operation (( pc ? V1 : V2 )) has the \nexpected behavior, in that from the perspective of a view L,it appears to return V1 only when pc is visible \nto L, and appears to return V2 otherwise. Lemma 1. If V = (( pc ? V1 : V2 )) then V1 if pc is visible \nto L L(V )= V2 otherwise We next show that the auxiliary functions deref and assign exhibit the expected \nbehavior when projected under a view L. First, if deref (S, V ) returns V ' , then the projected result \nL(V ' ) is a non-faceted value that is identical to .rst projecting the store L(S), projecting the target \naddress L(V ), and then dereferencing the projected store at the projected address L(S)(L(V )). Lemma \n2. If V ' = deref (S, V , pc) then L(V ' )= L(S)(L(V )). Next, from the perspective of any view L,if \npc is visible to L then the operation assign(S, pc, V1 , V2 ) appears to update the address L(V1) appropriately. \nConversely, if pc is not visible to L, then this operation has no observable effect. Lemma 3. If S ' \n= assign(S, pc, V1 , V2 ) then ' L(S)[L(V1):= L(V2)] if pc is visible to L L(S )= L(S) otherwise A consequence \nof Lemma 3 is that evaluation with a pc that is not visible to a view L produces no observable change \nin the store. Lemma 4. Suppose pc is not visible to L and that S, T,e . pc S ' ,V Then L(S) = L(S ' ). \nProof. In the auxiliary material for this paper. We now prove our central projection theorem showing \nthat an evaluation under the faceted semantics is equivalent to many evaluations under the standard semantics, \none for each possible view for which pc is visible. Theorem 1 (Projection Theorem). Suppose S, T,e . \npc S ' ,V Then for any view L for which pc is visible, L(S),L(T),L(e) . L(S ' ),L(V ) Proof. In the auxiliary \nmaterial for this paper. Consequently, if pc is initially empty, then faceted evaluation simu\u00adlates 2n \nstandard evaluations, where n is the number of principals. 3.2 Termination-Insensitive Non-Interference \nThe projection property enables a very simple proof of non\u00adinterference; it already captures the idea \nthat information from one view does not leak into an incompatible view, since the projected computations \nare independent. To formalize this argument, we start by de.ning two faceted values to be L-equivalent \nif they have iden\u00adtical standard values for view L. This notion of L-equivalence natu\u00adrally extends to \nsubstitutions (T1 ~L T2) and stores (S1 ~L S2): (V1 ~L V2) iff L(V1)= L(V2) (T1 ~L T2) iff L(T1)= L(T2) \n(S1 ~L S2) iff L(S1)= L(S2) Together with the Projection Theorem, this notion of L-equivalence enables \nus to conveniently state and prove the standard correctness property of termination-insensitive non-interference. \n (( ? : )) : PC \u00d7 Value \u00d7 Value . Value (( \u00d8 ? Vn : Vo )) = Vn (( {k}. rest ? (k ? Va : Vb) : (k \n? Vc : Vd))) = ( k ? (( rest ? Va : Vc )) : Vd )(( {k}. rest ? (k ? Va : Vb) : (k ? Vc : Vd))) = ( k \n? Vc : (( rest ? Vb : Vd )) ) (( pc ? (k ? Va : Vb) : (k ? Vc : Vd))) = ( k ? (( pc ? Va : Vc )) : (( \npc ? Vb : Vd )) ) where k< head(pc) (( {k}. rest ? (k ? Va : Vb) : Vo )) = ( k ? (( rest ? Va : Vo )) \n: Vo ) where k< head(Vo) (( {k}. rest ? (k ? Va : Vb) : Vo )) = ( k ? Vo : (( rest ? Vb : Vo )) ) where \nk< head(Vo) (( {k}. rest ? Vn : (k ? Va : Vb))) = ( k ? (( rest ? Vn : Va )) : Vb ) where k< head(Vn) \n(( {k}. rest ? Vn : (k ? Va : Vb))) = ( k ? Va : (( rest ? Vn : Vb )) ) where k< head(Vn) (( {k}. rest \n? Vn : Vo )) = ( k ? (( rest ? Vn : Vo )) : Vo ) where k< head(Vn) and k< head(Vo) (( {k}. rest ? Vn \n: Vo )) = ( k ? Vo : (( rest ? Vn : Vo )) ) where k< head(Vn) and k< head(Vo) (( pc ? (k ? Va : Vb) : \nVo )) = ( k ? (( pc ? Va : Vo )) : (( pc ? Vb : Vo )) ) where k< head(Vo) and k< head(pc) (( pc ? Vn \n: (k ? Va : Vb))) = ( k ? (( pc ? Vn : Va )) : (( pc ? Vn : Vb )) ) where k< head(Vn) and k< head(pc) \nTheorem 2 (Termination-Insensitive Non-Interference). Let L be any view. Suppose S1 ~L S2 S1, T1,e . \n\u00d8 S ' 1,V1 T1 ~L T2 S2, T2,e . \u00d8 S ' 2,V2 Then: S ' 1 ~L S ' 2 V1 ~L V2 Proof. By the Projection Theorem: \nL(S1),L(T1),L(e) . L(S ' 1),L(V1) L(S2),L(T2),L(e) . L(S ' 2),L(V2) The L-equivalence assumptions imply \nthat L(T1)= L(T2) and L(S1)= L(S2). Hence L(S ' 1)= L(S ' 2) and L(V1)= L(V2) since the standard semantics \nis deterministic. This theorem can be generalized to computations with arbitrary program counter labels, \nbut then non-interference holds only for views for which that pc is visible.  3.3 Ef.cient Construction \nof Faceted Values The de.nition of the operation (( pc ? V1 : V2 )) presented above is optimized for \nclarity, but may result in a suboptimal representation for faceted values. For instance, the operation \n(( {k} ? (k ?1:0) : 2 )) returns the faceted value tree (k ? (k ?1:0) :2) containing a dead facet 0 that \nis not visible in any view. We now present an optimized version of this operation that avoids introducing \ndead facets. The essential idea is to introduce a .xed total ordering on principals and to ensure that \nin any faceted value tree, the path from the root to any leaf only mentions principals in a strictly \nincreasing order. In order to maintain this ordering, we introduce a head function that returns the lowest \nlabel in a value or program counter, or a result 8 that is considered higher than any label. head : Value \n. Label .{8} head((k ? V1 : V2))= k head(R)= 8 head : PC . Label .{8} head({k}. rest)= k if .k ' or \nk ' . rest .k<k ' head({k}. rest)= k if .k ' or k' . rest .k<k ' head({})= 8 Figure 6 rede.nes the facet-construction \noperation to build values respecting the ordering of labels. The de.nition is verbose but straightforward; \nit performs a case analysis to identify the smallest possible label k to put at the root of the newly \ncreated value. The revised de.nition still satis.es the speci.cation provided by Lemma 1.  4. Comparison \nto Prior Semantics Prior work presented the no-sensitive-upgrade (NSU) seman\u00adtics [39, 5] and the permissive-upgrade \n(PU) semantics [6] for dynamic information .ow. In this section, we adapt both of these semantics to \nour notation to illustrate how faceted evaluation ex\u00adtends both of these prior techniques. For clarity, \nin this section we assume that there is only a single principal k and omit I/O oper\u00adations, since the \ntwo prior semantics were formalized under these assumptions. Finally, we use the optimized facet-construction \nop\u00aderation from Figure 6 in order to avoid reasoning about dead facets. 4.1 Comparison to No-Sensitive-Upgrade \nSemantics We formalize the NSU semantics via the evaluation relation S, T,e .pc S ' ,V de.ned by the \n[NSU-*] rules in Figure 7. These rules are somewhat analogous to the faceted evaluation rules of Figure \n4, but with some noticeable limitations and restrictions. In particular, the NSU semantics marks each \nraw value R as being either public or private: V ::= R public values |(k ? R : .) private values The \nNSU semantics cannot record any public facet other than .. The faceted value (k ? R : .) is traditionally \nwritten sim\u00adply as Rk in prior semantics, denoting that R is private to prin\u00adcipal k, with no representation \nfor a corresponding public facet. This restriction on values means that the NSU semantics never needs \nto split the computation in the manner performed by the ear\u00adlier [F-SPLIT] and [FA-SPLIT] rules. Instead, \napplications of a pri\u00advate closure (k ?(.x.e, T ' ): .) extends the program counter pc with the label \nk during the call, re.ecting that this computation is dependent on k-private data. Thus, under the NSU \nsemantics, the program counter label is simply a set of principals, and never con\u00adtains negated principals \nk. Label pc . PC =2 After the callee returns a result V , the following operation (k)pcV creates a faceted \nvalue semantically equivalent to (k ? V : .), with  NSU Evaluation Rules: S, T,e .pc S ' ,V [NSU-CONST] \nS, T,c .pc S,c [NSU-VAR] S, T,x .pc S, T(x) [NSU-FUN] S, T, (.x.e) .pc S, (.x.e, T) [NSU-BOT] S, T, ..pc \nS, . S, T,e .pc.{k} S ' ,V , (k)pc [NSU-LABEL] S, T, (k ? e : .) .pc S ' V S, T,e1 .pc S1, (.x.e, T \n' ) S1, T,e2 .pc S2,V ' S, T ' [x := V ' ],e .pc S ' ,V [NSU-APP] S, T, (e1 e2) .pc S ' ,V S, T,e1 .pc \nS1, . S1, T,e2 .pc S2,V ' [NSU-APP-BOT] S, T, (e1 e2) .pc S ' , . S, T,e1 .pc S1, (k ?(.x.e, T ' ): \n.) S1, T,e2 .pc S2,V ' S, T ' [x := V ' ],e .pc.{k} S ' ,V , (k)pc [NSU-APP-K] S, T, (e1 e2) .pc S ' \nV S, T,e .pc S ' ,V ' a . dom(S ' ) V = (( pc ? V ' : .)) [NSU-REF] S, T, (ref e) .pc S ' [a := V ],a \nS, T,e .pc S ' ,Va V = deref (S ' , Va , pc) [NSU-DEREF] S, T, !e .pc S ' ,V S, T,e1 .pc S1, . S1, T,e2 \n.pc S2,V  [NSU-ASSIGN-BOT] S, T,e1:= e2 .pc S2,V S, T,e1 .pc S1,a S1, T,e2 .pc S ' ,V pc = label(S ' \n(a)) V ' = (( pc ? V : .)) [NSU-ASSIGN] S, T,e1:= e2 .pc S ' [a := V ' ],V S,.,e1 .pc S1, (k ? a : .) \nS1, T,e2 .pc S ' ,V pc .{k}. label(S ' (a)) V ' = (( pc ? V : .)) [NSU-ASSIGN-K] S, T,e1:= e2 .pc S \n' [a := V ' ],V Figure 8: Permissive Upgrade Semantics (extends Figure 7) PU Evaluation Rules: S, T,e \n.pc S ' ,V S, T,e1 .pc S1,a S1, T,e2 .pc S ' ,V V ' = (( pc ? V : *)) [PU-ASSIGN] S, T,e1:= e2 .pc S \n' [a := V ' ],V S,., e1 .pc S1, (k ? a : .) S1, T,e2 .pc S ' ,V V ' = (( pc ? V : *)) [PU-ASSIGN-K] \nS, T,e1:= e2 .pc S ' [a := V ' ],V the optimization that the label k is unnecessary if it is subsumed \nby pc or if it is already in V : (k){k} V = V (k){} R = (k ? R : .) (k)pc (k ? R : .) = (k ? R : .) \n(This optimization corresponds to the [FA-LEFT] and [FA-RIGHT] rules of the faceted semantics.) In order \nto preserve the NSU restriction on values, the NSU semantics needs to carefully restrict assignment statements. \nEs\u00adsentially, the NSU evaluation rules for assignment statements halt execution in exactly those situations \nwhere the faceted semantics would introduce a non-trivial public facet. These rules use the fol\u00adlowing \nfunction to extract the principals in a value: label : Value . PC label((k ? R : .))= {k}label(R)= \u00d8 \nThe rule [NSU-ASSIGN] checks that pc is equal to the label on the original value S ' (a) of the target \nlocation a. If this condition holds, then the value (( pc ? V : .)) stored by [NSU-ASSIGN] is actually \nequal to the value (( pc ? V :S ' (a) )) that the faceted semantics would store. Thus, this no-sensitive-upgrade \ncheck detects situa\u00adtions where the NSU semantics can avoid information leaks without introducing non-. \npublic facets. The rule [NSU-ASSIGN-K] handles assignments where the target address is private (k ? a \n: .) in a similar manner to [NSU-ASSIGN]. Because of these no-sensitive-upgrade checks, the NSU seman\u00adtics \nwill get stuck at precisely the points where the faceted value semantics will create non-. public facets. \nAn example of this stuck execution is shown in the NSU column of Figure 1. When the value for y is updated \nin a context dependent on the con.dential value of x, execution gets stuck to prevent loss of information. \nIf the NSU semantics runs to completion on a given program, then the faceted semantics will produce the \nsame results. Theorem 3 (Faceted evaluation generalizes NSU evaluation). If S, T,e .pc S ' ,V then S, \nT,e . pc S ' ,V . Proof. In the auxiliary material for this paper. 4.2 Permissive Upgrades The limitations \nof the NSU semantics motivated the development of a more expressive permissive upgrade (PU) semantics, \nwhich reduced (but did not eliminate) stuck executions [6]. Essentially, the PU semantics works by tracking \npartially leaked data, which  S, T,e . pc S ' ,V UP . pc V ' = downgradeP (V ) [F-DECLASSIFY] S, T, \ndeclassifyP e . pc S ' ,V ' (l ? downgradeP (V1): downgradeP (V2)) Downgrade Function downgradeP : Value \n. Value downgradeP (R) = R downgradeP ((SP ? V1 : V2)) downgradeP ((UP ? V1 : V2)) downgradeP ((l ? V1 \n: V2)) = = = (UP ? (SP ? V1 : V2) : V1)(( UP ? V1 : downgradeP (V2) )) we represent here as a faceted \nvalue (k ? R : *).3 V ::= R public values |(k ? R : .) private values |(k ? R : *) partially leaked values \nSince the public facet is not actually stored, the PU semantics can never use partially leaked values \nin situations where the public facet is needed, and so partially leaked values cannot be assigned, in\u00advoked, \nor used as a conditional test. In particular, PU computations never need to split executions, and so \navoid the complexities and expressiveness of faceted evaluation. We formalize the PU semantics by extending \nthe NSU evalua\u00adtion relation S, T,e .pc S ' ,V with the two additional rules shown in Figure 8. The new \nassignment rules leverage faceted values to handle the complexity involved in tracking partially leaked \ndata. Speci.cally, if values are stored to a public reference cell in a high\u00adsecurity context, the data \nis partially leaked, and a new faceted value with a non-. public facet is created. Critically, there \nare no rules for applying partially leaked func\u00adtions or assigning to partially leaked addresses, and \nconsequently execution gets stuck at these points, corresponding to the explicit checks for partially \nleaked labels in the original PU semantics [6]. Faceted values subsume the permissive upgrade strategy. \nThe permissive upgrade strategy gets stuck at the points where a faceted value with a non-. facet is \neither applied or used in assignment. Theorem 4 (Faceted evaluation generalizes PU evaluation). If S, \nT,e .pc S ' ,V ,then S, T,e . pc S ' ,V . Proof. In the auxiliary material for this paper. Again, the \nconverse to this theorem does not hold, since Figure 1 shows an execution that gets stuck under the permissive \nupgrade semantics but not under the faceted semantics.   5. Facet Declassi.cation For many real systems, \nnon-interference is too strong of a restric\u00adtion. Often a certain amount of information leakage is acceptable, \nand even desirable. Password checking is the canonical example; while one bit of information about the \npassword may leak, the sys\u00adtem may still be deemed secure. Declassi.cation is this process of making \ncon.dential data public in a controlled manner. 3 In [6], these partially leaked values were represented \nas RP , with a superscript P denoting partially leaked. In the context of multi-process execution [13], \ndeclassi.cation is rather challenging. The L and H processes must be coordinated in a careful manner, \nwith all of the attendant problems involved in sharing data between multiple processes. Additionally, \nallow\u00ading declassi.cation may re-introduce timing channels and the ter\u00admination channel, losing major \nbene.ts of the multi-execution ap\u00adproach. In contrast, faceted evaluation makes declassi.cation fairly \nstraightforward. The public and con.dential facets are tied together in a single faceted value during \nexecution, so declassi.cation sim\u00adply requires restructuring the faceted value to migrate information \nfrom one facet to another. Providing a declassi.cation operation with no restrictions in\u00advalidates most \nsecurity guarantees. For instance, an attacker could declassify a user s password, or overwrite data \nthat would be de\u00adclassi.ed later by legitimate code. In this manner, valid code in\u00adtending to declassify \nthe result of a password check might instead be duped into declassifying the password itself. To provide \nmore reliable security guarantees in the presence of declassi.cation with faceted values, we show how \nto perform ro\u00adbust declassi.cation [40], which guarantees that an active attacker, able to introduce \ncode, is no more powerful than a passive attacker, who can only observe the results. (We use robust declassi.cation \nas an illustrative example, but faceted values could also support other approaches to declassi.cation.) \nRobust declassi.cation depends on a notion of integrity,which in turn requires that we distinguish between \nthe terms label and principal. In particular, we introduce a separate notion of principals (P ) into \nour formalism. A label k then marks data as being secret (SP ) or as being low-integrity or untrusted \n(UP ), both from the perspective of a particular principal P 4. P . Principal SP k . Label ::= secret \nto P | untrusted by P UP In the context of a principal P , we now have four possible views or projections \nof a computation, ordered by the subset relation.  To help reason about multiple principals, we introduce \nthe notation LP to abbreviate L n{SP , UP },sothat LP is one of the four views from the above combined \ncon.dentiality/integrity lattice. Note that in the absence of declassi.cation, the projection theorem \nguaran\u00adtees that each of these views of the computation are independent; there is no way for values produced \nin one view s computation to in.uence another view s computation. We introduce an additional expression \nform declassifyP e for declassifying values with respect to a principal P .The rule [F-DECLASSIFY]inFigure9performstheappropriate \nrobustdeclas\u00adsi.cation. Declassi.cation cannot be performed by arbitrary unau\u00adthorized code, or else \nattackers could declassify all con.dential data. Moreover, it is insuf.cient to allow code owned by P \nto perform declassi.cation, since attackers could leverage that code to declassify data on their behalf. \nHence, the rule [F-DECLASSIFY] checks that the control path to this declassi.cation operation has not \nbeen in.uenced by untrusted data, via the check UP . pc. Robust declassi.cation allows data to move from \nthe {SP } view to the {} view, but never from the {SP , UP } view to the {UP } view. 4 This security \nlattice could be further re.ned to indicate which other prin\u00adcipal was distrusted by P , which would \npermit more .ne-grained decisions.  Lemma 5. For any value V and view L: L(V ) if LP = {} L(downgradeP \n(V )) = L ' (V ) if LP = {},where L ' = L .{SP } Proof. In the auxiliary material for this paper. In \nthe presence of declassi.cation, the projection theorem does not hold for the public trusted view {} \nsince that view s computa\u00adtion may be in.uenced by declassi.ed data. However, the projec\u00adtion theorem \nstill holds for other views. To prove this relaxed ver\u00adsion of the projection theorem, we extend the \nstandard semantics to treat declassi.cation as the identity operation: [S-DECLASSIFY] s, .,e . s ' ,V \ns, ., declassifyP e . s ' ,V Theorem 5 (Projection Theorem with Declassi.cation). Suppose S, T,e . pc \nS ' ,V For any view L for which pc is visible, and where LP = {} for each P used in a declassi.cation \noperation, we have: L(S),L(T),L(e) . L(S ' ),L(V ) Proof. In the auxiliary material for this paper. As \na result, non-interference also holds for these same views. Theorem 6 (Termination Insensitive Non-Interference \nwith De\u00adclassi.cation). Suppose LP = {} for each P used in a declas\u00adsi.cation operation and S1 ~L S2 \nS1, T1,e . \u00d8 S ' 1,V1 T1 ~L T2 S2, T2,e . \u00d8 S ' 2,V2 Then: S ' 1 ~L S ' V1 ~L V2 2 Proof. Follows from \nTheorem 5 via a proof similar to Theorem 2.  6. JavaScript Implementation in Firefox We incorporate \nour ideas for faceted evaluation into Firefox through the Narcissus [15] JavaScript engine and the Zaphod \n[26] Firefox plugin. The ZaphodFacets implementation [4] extends the faceted semantics to handle the \nadditional complexities of JavaScript. Exceptions are particularly tricky, and we halt execu\u00adtion if \nan exception may leak information. We added two new primitives to the language. The makePrivate function \nturns a value into a faceted value with a public facet of undefined 5. This approach allows developers \nto specify a differ\u00adent public value through the JavaScript idiom for specifying default values. The \nfollowing code sets x to a faceted value of (k ?42 : 0). The high value of x is set to 42, since (42 \n|| 0) === 42;the low value will be 0, since (undefined || 0) === 0. var x = makePrivate(42) || 0; The \nsecond primitive is a getPublic function that extracts the public value of its input. For example, with \nthe above code de.ning x, getPublic(x) would return 0. Generally, the browser s security 5 A string specifying \nthe principal can be given as the second argument if multiple principals are required. policy should \nuse these two functions (or variants) on all input/out\u00adput boundaries of the system in order to appropriately \nlabel data as it comes in and to appropriately monitor data as it goes out. To track information .ow \nthrough the Document Object Model (DOM), our implementation uses the dom.js DOM implementa\u00adtion written \nin JavaScript [17], to preventing the attacker from san\u00aditizing data by writing it to the DOM and later \nrereading it. Our im\u00adplementation is available online with some examples [4], including the code from \nFigure 1. 6.1 Cross-Site Scripting (XSS) Example To illustrate how our controls can be useful for enforcing \npractical defenses, we consider an example of a webpage with an XSS vulnerability. Our controls do not \nprevent XSS attacks. Rather, they provide an additional layer of defense, reducing an attack s power. \nWe specify a simple policy that the value of all password ele\u00adments should be treated as con.dential. \nFurthermore, any attempts to load .les from a different origin should use the public facet; the server \nhosting the website, however, should see the true value. In our example, the web developer is making \nuse of a library for hashing passwords on the client side. The library is benign, but an attacker uses \nan XSS vulnerability in the page to wrap the hashing library and export the password to evil.com, a site \nunder the attacker s control. The injected code is given below: var oldHex = hex_md5; hex_md5 = function(secret) \n{ var baseURL = \"http://evil.com/\"; var img = document.getElementById(\"spock\"); var title1 = document.getElementById(\"title1\"); \ntitle1.setAttribute(\"class\", secret); var newVal = document.getElementsByTagName (\"h1\")[0] .getAttribute(\"class\"); \nimg.setAttribute(\"src\", baseURL + newVal + \".jpg\"); return oldHex(secret); } The attack attempts to leak \nthe password by loading an image from evil.com, incorporating the password into the name of the requested \nimage. However, in an attempt to evade our controls, it .rst writes the password to the class attribute \nof the title1 element and then rereads it from the .rst h1 element. Without knowledge of the DOM structure \nof the page, it is not possible to know whether this code leaks information. However, with dom.js we \npersist the different facets of secret to the DOM so that no security information is lost. While the \npage can only render a single facet, it is critical that we maintain other views of the document. With \nthis example, evil.com sees only the public facet of secret, not the true password. Trusted same-origin \nsources do see the true value, and therefore work correctly with the page. While our example policy is \nfar from complete, we use it to illustrate how our mechanism can enforce different information .ow policies. \nA richer policy could specify a variety of .elds and potential output channels. Furthermore, we imagine \nthat browsers would wish to allow web developers to specify application-speci.c sensitive .elds, such \nas credit card numbers, and allow users to protect information that they considered con.dential (for \ninstance, restricting the release of geolocation information).  6.2 Performance Results Our approach \nis similar to Devriese and Piessens s work on secure multi-execution [13]. To understand the performance \ntradeoff be\u00adtween these two approaches we also implemented both sequential and concurrent versions of \nsecure multi-execution in Narcissus, and compared their performance to faceted execution. Our tests were \nperformed on a MacBook Pro running OS X ver\u00adsion 10.6.8. The machine had a 2.3 GHz Intel Core i7 processor \nwith 4 cores and 8 GB of memory. For our benchmark, we used  Times in ms Secure multi-execution Faceted \n#principals sequential concurrent execution 0 273, 774 283, 450 310, 561 1 513, 561 283, 503 348, 725 \n2 961, 357 332, 303 387, 121 3 1, 783, 609 597, 595 421, 566 4 3, 324, 480 1, 093, 951 461, 543 5 * 1, \n981, 927 503, 364 6 * * 540, 618 7 * * 575, 100 8 * * 614, 150  A result of * indicates a test that \nran for more than one hour. the crypto-md5 test from the SunSpider [38] benchmark suite. We modi.ed \nthis program to include 8 hashing operations with some inputs marked as con.dential. Our test cases involve \n0 through 8 principals. In each case, every principal marks one element as pri\u00advate; additional hash \ninputs are public. For example, test 1 hashes 1 con.dential input and 7 public inputs. Test 8 hashes \n8 con.dential inputs, each marked as con.dential by a distinct principal, and has no public hash inputs. \nOur results are summarized in Figure 10. Our results highlight the tradeoffs between the different ap\u00adproaches. \nThe sequential variant of secure multi-execution had the most lightweight infrastructure of the three \napproaches, re.ected in its good performance when there are 0 principals. However, it can neither take \nadvantage of multiple processors nor avoid unneces\u00adsary work. As a result, once even a single principal \nwas involved, it was the worst performer. The time required roughly doubles with each additional principal. \nConcurrent secure multi-execution outperforms our faceted evaluation implementation when the number of \nprincipals is small. However, as the number of principals increases, faceted evalua\u00adtion quickly becomes \nthe more ef.cient approach, since under se\u00adcure multi-execution the number of processes increases exponen\u00adtially \ncompared to the number of principals. With three principals, faceted evaluation outperforms concurrent \nsecure multi-execution in our tests. Beyond this point execution time for concurrent secure multi-execution \nroughly doubles with each added principal, as the elements in the lattice now outnumber the available \ncores.  7. Related Work A few publications have discussed performing multiple executions to guarantee \nsecurity properties. Capizzi et al. s shadow execu\u00adtions [9] develop an approach similar to faceted values \nfor use in securing information for desktop applications; they run both a pub\u00adlic and a private copy \nof the application. The public copy can com\u00admunicate with the outside world, but has no access to private \ndata. The private copy has access to all private information but does not transmit any information over \nthe network. With this elegant solu\u00adtion, con.dentiality is maintained. Devriese and Piessens [13] ex\u00adtend \nthis idea to JavaScript code with their secure multi-execution strategy, using a high and a low process \nto protect con.dentiality in a similar manner. Our approach is similar in spirit, though we avoid overhead \nwhen code does not depend on con.dential data. Kashyap et al. [23] clarify some properties of secure \nmulti-execution. Our semantics are closely related to work by Pottier and Si\u00admonet [28]. While they prove \nnon-interference statically for Core ML, their proof approach involves a Core ML2 language that has expression \npairs and value pairs, analogous to our faceted expres\u00adsions and faceted values. Our work departs from \ntheirs in that we evaluate labeled expressions and values to dynamically guarantee non-interference, \nrather than using them to make static guarantees. Kolbitsch et al. [25] use a similar technique in Rozzle,a \nJavaScript virtual machine for symbolic execution designed to detect malware. Rozzle uses multi-execution \n(not to be confused with secure multi-execution) to explore multiple paths in a sin\u00adgle execution, similar \nto faceted evaluation. Their technique treats environment-speci.c data as symbolic, and explores both \npaths whenever a value branches on a symbolic value. The principal dif\u00adference, besides the application, \nis that faceted values represent a lattice of different views of data, while Rozzle s symbolic heap val\u00adues \nrepresent a range of possible values for different environments. Other research has previously studied \ninformation-.ow anal\u00adysis for JavaScript. Vogt et al. [36] track information .ow in Firefox to defend \nagainst XSS attacks. Russo and Sabelfeld [30] study timeout mechanisms. Russo et al. [32] discuss dynamic \ntree structures, with obvious applications to the DOM. Bohannon et al. [8] consider non-interference \nin JavaScript s reactive environ\u00adment. Chugh et al. [11] create a framework for information .ow analysis \nwith holes for analyzing dynamically evaluated code. Dhawan and Ganapathy [14] discuss JavaScript-based \nbrowser ex\u00adtensions (JSEs). Jang et al. [21] give an excellent overview of how JavaScript is used to \ncircumvent privacy defenses. Information .ow analysis largely traces its roots back to Den\u00adning [12]. \nVolpano et al. [37] codify Denning s approach as a type system, and also offer a proof of its soundness. \nHeintze and Riecke [19] design a type system for their purely functional SLam Calculus, which they extend \nto include mutable reference cells, concurrency, and integrity guarantees. Sabelfeld and Myers [33] offer \nan extensive survey of other research on information .ow. Myers [27] discusses JFlow, a variant of Java \nwith security types to provide strong information .ow guarantees. JFlow was the basis for Jif [22], a \nproduction-worthy language with information .ow controls. Birgisson et al. [7] show how capabilities \ncan guarantee information .ow policies. Hunt and Sands [20] describe a .ow\u00adsensitive type system. Russo \nand Sabelfeld [31] discuss the trade\u00adoffs between static and dynamic analyses in some depth. Le Guer\u00adnic \net al. [18] examine code from branches not taken, increasing precision at the expense of run-time performance \noverhead. Shroff et al. [34] use a purely-dynamic analysis to track variable depen\u00addencies and reject \nmore insecure programs over time. Zdancewic [40] uses integrity labels to provide robust declassi\u00ad.cation. \nAskarov and Myers [2] consider checked endorsements. Chong and Myers [10] use a framework for application-speci.c \ndeclassi.cation policies. Askarov and Sabelfeld [3] study a declas\u00adsi.cation framework specifying what \nand where data is released. Vaughan and Chong [35] infer declassi.cation policies for Java programs. \nAskarov et al. [1] highlight complications of interme\u00addiary output channels. Rafnnson et al. [29] buffer \noutput to reduce data lost from intermediary output channels and termination behav\u00adior. King et al. [24] \nstudy false alarms caused by implicit .ows.  8. Discussion Information .ow non-interference is a tricky \nsecurity property to enforce via dynamic monitoring, since it is a 2-safety property: non-interference \ncan be refuted only by observing two executions (cmp. Theorem 2). Conversely, a 1-safety property can \nbe refuted by observing a single execution, and so 1-safety properties are more amenable to dynamic enforcement. \nFrom this perspective, various prior techniques dynamically enforce a 1-safety property that conservatively \napproximates the desired 2-safety property of non-interference, but this conservative approximation introduces \nfalse alarms on implicit .ows. Interestingly, our projection property (Theorem 1) is a 1-safety property \nthat suf.ces to prove non\u00adinterference (Theorem 2) without introducing false alarms.  Acknowledgements \nWe thank the anonymous POPL reviewers for their constructive feedback on this paper. We would also like \nto thank Brendan Eich, Andreas Gal, and Dave Herman for valuable discussions on information .ow analysis, \nand David Flanagan and Donovan Preston for their help working with the dom.js project. This work was \nsupported by NSF grant CNS-0905650.  References [1] Aslan Askarov, Sebastian Hunt, Andrei Sabelfeld, \nand David Sands. Termination-insensitive noninterference leaks more than just a bit. In ESORICS 08, pages \n333 348. Springer-Verlag, 2008. [2] Aslan Askarov and Andrew Myers. A semantic framework for declassi.cation \nand endorsement. In ESOP, pages 64 84, 2010. [3] Aslan Askarov and Andrei Sabelfeld. Tight enforcement \nof information-release policies for dynamic languages. In IEEE Com\u00adputer Security Foundations Symposium, \npages 43 59, Washington, DC, USA, 2009. IEEE Computer Society. [4] Thomas H. Austin. ZaphodFacetes github \npage. https://github. com/taustin/ZaphodFacets, 2011. [5] Thomas H. Austin and Cormac Flanagan. Ef.cient \npurely-dynamic information .ow analysis. In PLAS 09: Proceedings of the ACM SIGPLAN Fourth Workshop on \nProgramming Languages and Analysis for Security, pages 113 124, New York, NY, USA, 2009. ACM. [6] Thomas \nH. Austin and Cormac Flanagan. Permissive dynamic information .ow analysis. In Proceedings of the 5th \nACM SIGPLAN Workshop on Programming Languages and Analysis for Security, pages 1 12. ACM, 2010. [7] Arnar \nBirgisson, Alejandro Russo, and Andrei Sabelfeld. Capabilities for information .ow. In PLAS 11: Proceedings \nof the ACM SIGPLAN Fourth Workshop on Programming Languages and Analysis for Security. ACM, 2011. [8] \nAaron Bohannon, Benjamin C. Pierce, Vilhelm Sj\u00a8oberg, Stephanie Weirich, and Steve Zdancewic. Reactive \nnoninterference. In ACM Conference on Computer and Communications Security, pages 79 90, 2009. [9] R. \nCapizzi, A. Longo, V.N. Venkatakrishnan, and A.P. Sistla. Preventing information leaks through shadow \nexecutions. In ACSAC, pages 322 331, dec 2008. [10] Stephen Chong and Andrew C. Myers. Security policies \nfor downgrading. In CCS 04: Proceedings of the 11th ACM conference on Computer and communications security, \npages 198 209, New York, NY, USA, 2004. ACM. [11] Ravi Chugh, Jeffrey A. Meister, Ranjit Jhala, and Sorin \nLerner. Staged information .ow for javascript. In PLDI, pages 50 62, 2009. [12] Dorothy E. Denning. A \nlattice model of secure information .ow. Communications of the ACM, 19(5):236 243, 1976. [13] Dominique \nDevriese and Frank Piessens. Noninterference through secure multi-execution. Security and Privacy, IEEE \nSymposium on, 0:109 124, 2010. [14] Mohan Dhawan and Vinod Ganapathy. Analyzing information .ow in javascript-based \nbrowser extensions. In ACSAC, pages 382 391, 2009. [15] Brendan Eich. Narcissus JS implemented in JS. \nAvailable on the web at https://github.com/mozilla/narcissus/. [16] J. S. Fenton. Memoryless subsystems. \nThe Computer Journal, 17(2):143 147, 1974. [17] Andreas Gal, David Flanagan, and Donovon Preston. dom.js \ngithub page. https://github.com/andreasgal/dom.js, accessed October 2011, 2011. [18] Gurvan Le Guernic, \nAnindya Banerjee, Thomas P. Jensen, and David A. Schmidt. Automata-based con.dentiality monitoring. In \nASIAN, pages 75 89, 2006. [19] Nevin Heintze and Jon G. Riecke. The SLam calculus: Program\u00adming with \nsecrecy and integrity. In Symposium on Principles of Programming Languages, pages 365 377, 1998. [20] \nSebastian Hunt and David Sands. On .ow-sensitive security types. In POPL, pages 79 90, 2006. [21] Dongseok \nJang, Ranjit Jhala, Sorin Lerner, and Hovav Shacham. An empirical study of privacy-violating information \n.ows in javascript web applications. In ACM Conference on Computer and Communications Security, pages \n270 283, 2010. [22] Jif homepage. http://www.cs.cornell.edu/jif/, accessed October 2010. [23] Vineeth \nKashyap, Ben Wiedermann, and Ben Hardekopf. Timing\u00adand termination-sensitive secure information .ow: \nExploring a new approach. In IEEE Security and Privacy, 2011. [24] Dave King, Boniface Hicks, Michael \nHicks, and Trent Jaeger. Implicit .ows: Can t live with em, can t live without em. In International Conference \non Information Systems Security, pages 56 70, 2008. [25] Clemens Kolbitsch, Benjamin Livshits, Benjamin \nZorn, and Christian Seifert. Rozzle: De-cloaking internet malware. Technical Report MSR-TR-2011-94, Microsoft \nResearch Technical Report, 20011. [26] Mozilla labs: Zaphod add-on for the .refox browser. http: //mozillalabs.com/zaphod, \naccessed October 2010. [27] Andrew C. Myers. JFlow: Practical mostly-static information .ow control. \nIn Symposium on Principles of Programming Languages, pages 228 241, 1999. [28] Franc\u00b8ois Pottier and \nVincent Simonet. Information .ow inference for ML. Transactions on Programming Languages and Systems, \n25(1):117 158, 2003. [29] Willard Rafnsson and Andrei Sabelfeld. Limiting information leakage in event-based \ncommunication. In PLAS 11: Proceedings of the ACM SIGPLAN Fourth Workshop on Programming Languages and \nAnalysis for Security. ACM, 2011. [30] Alejandro Russo and Andrei Sabelfeld. Securing timeout instructions \nin web applications. In IEEE Computer Security Foundations Symposium, 2009. [31] Alejandro Russo and \nAndrei Sabelfeld. Dynamic vs. static .ow\u00adsensitive security analysis. In IEEE Computer Security Foundations \nSymposium. IEEE Computer Society, 2010. [32] Alejandro Russo, Andrei Sabelfeld, and Andrey Chudnov. Tracking \ninformation .ow in dynamic tree structures. In ESORICS, pages 86 103, 2009. [33] Andrei Sabelfeld and \nAndrew C. Myers. Language-based information-.ow security. Selected Areas in Communications, IEEE Journal \non, 21(1):5 19, Jan 2003. [34] Paritosh Shroff, Scott F. Smith, and Mark Thober. Dynamic dependency monitoring \nto secure information .ow. In CSF, pages 203 217, 2007. [35] Jeffrey Vaughan and Stephen Chong. Inference \nof expressive declassi.cation policies. In IEEE Security and Privacy, 2011. [36] Philipp Vogt, Florian \nNentwich, Nenad Jovanovic, Engin Kirda, Christopher Kr\u00a8ugel, and Giovanni Vigna. Cross site scripting \nprevention with dynamic data tainting and static analysis. In NDSS, 2007. [37] Dennis Volpano, Cynthia \nIrvine, and Geoffrey Smith. A sound type system for secure .ow analysis. Journal of Computer Security, \n4(2-3):167 187, 1996. [38] Webkit.org. SunSpider JavaScript benchmark. http://www. webkit.org/perf/sunspider/sunspider.html, \naccessed Oc\u00adtober 2011. [39] Stephan Arthur Zdancewic. Programming languages for information security. \nPhD thesis, Cornell University, 2002. [40] Steve Zdancewic. A type system for robust declassi.cation. \nIn 19th Mathematical Foundations of Programming Semantics Conference, 2003.  \n\t\t\t", "proc_id": "2103656", "abstract": "<p>JavaScript has become a central technology of the web, but it is also the source of many security problems, including cross-site scripting attacks and malicious advertising code. Central to these problems is the fact that code from untrusted sources runs with full privileges. We implement information flow controls in Firefox to help prevent violations of data confidentiality and integrity. Most previous information flow techniques have primarily relied on either static type systems, which are a poor fit for JavaScript, or on dynamic analyses that sometimes get stuck due to problematic implicit flows, even in situations where the target web application correctly satisfies the desired security policy. We introduce faceted values, a new mechanism for providing information flow security in a dynamic manner that overcomes these limitations. Taking inspiration from secure multi-execution, we use faceted values to simultaneously and efficiently simulate multiple executions for different security levels, thus providing non-interference with minimal overhead, and without the reliance on the stuck executions of prior dynamic approaches.</p>", "authors": [{"name": "Thomas H. Austin", "author_profile_id": "81435602959", "affiliation": "University of California, Santa Cruz, Santa Cruz, CA, USA", "person_id": "P2991369", "email_address": "taustin@ucsc.edu", "orcid_id": ""}, {"name": "Cormac Flanagan", "author_profile_id": "81100538763", "affiliation": "University of California, Santa Cruz, Santa Cruz, CA, USA", "person_id": "P2991370", "email_address": "cormac@ucsc.edu", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103677", "year": "2012", "article_id": "2103677", "conference": "POPL", "title": "Multiple facets for dynamic information flow", "url": "http://dl.acm.org/citation.cfm?id=2103677"}