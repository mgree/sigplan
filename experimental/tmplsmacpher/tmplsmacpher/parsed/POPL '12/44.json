{"article_publication_date": "01-25-2012", "fulltext": "\n An Executable Formal Semantics of C with Applications * Chucky Ellison Grigore Ros, u University of \nIllinois {celliso2, grosu}@illinois.edu Abstract This paper describes an executable formal semantics \nof C. Being ex\u00adecutable, the semantics has been thoroughly tested against the GCC torture test suite \nand successfully passes 99.2% of 776 test programs. It is the most complete and thoroughly tested formal \nde.nition of C to date. The semantics yields an interpreter, debugger, state space search tool, and model \nchecker for free . The semantics is shown capable of automatically .nding program errors, both statically \nand at runtime. It is also used to enumerate nondeterministic behavior. Categories and Subject Descriptors \nD.3.1 [Programming Lan\u00adguages]: Formal De.nitions and Theory Semantics General Terms Languages, Standardization, \nVeri.cation. 1. Introduction C provides just enough abstraction above assembly language for programmers \nto get their work done without having to worry about the details of the machines on which the programs \nrun. Despite this abstraction, C is also known for the ease in which it allows programmers to write buggy \nprograms. With no runtime checks and little static checking, in C the programmer is to be trusted entirely. \nDespite the abstraction, the language is still low-level enough that programmers can take advantage of \nassumptions about the underlying architecture. Trust in the programmer and the ability to write non-portable \ncode are actually two of the design principles under which the C standard was written [14]. These ideas \noften work in concert to yield intricate, platform-dependent bugs. The potential subtlety of C bugs makes \nit an excellent candidate for formalization, as subtle bugs can often be caught only by more rigorous \nmeans. In this paper, we present a formal semantics of C that can be used for .nding bugs. Rather than \nbeing an on paper semantics, it is executable, machine readable, and has been tested against the GCC \ntorture tests (see Section 5). The semantics describes the features of the C99 standard [13], but we \noften cite the text from the proposed C1X standard [15]. We use the C1X text because it will eventually \nsupersede the C99 standard, and because it o.ers clearer wording and more explicit descriptions of certain \nkinds of behavior. Our semantics can be considered a freestanding implementation of C99. The standard \nde.nes a freestanding implementation as * Supported in part by NSA contract H98230-10-C-0294 and by (Romanian) \nSMIS-CSNR 602-12516 contract no. 161/15.06.2010. Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 12, January 25 27, 2012, Philadelphia, PA, USA. Copyright \n&#38;#169; 2012 ACM 978-1-4503-1083-3/12/01. . . $10.00 a version of C that includes every language feature \nexcept for _Complex and _Imaginary types, and that includes only a subset of the standard library. Our \nsemantics is the .rst arguably complete dynamic semantics of C (see Section 2). Above all else, our semantics \nhas been motivated by the desire to develop formal, yet practical tools. Our semantics was developed \nin such a way that the single de.nition could be used immediately for interpreting, debugging, or analysis \n(described in Section 6). At the same time, this practicality does not mean that our de.nition is not \nformal. Being written in a subset of rewriting logic (RL), it comes with a complete proof system and \ninitial model semantics [18]. Brie.y, a rewrite system is a set of rules over terms constructed from \na signature. The rewrite rules match and apply everywhere, making RL a simple, uniform, and general formal \ncomputational paradigm. This is explained in greater detail in Section 3. Our C semantics de.nes 150 \nC syntactic operators. The de.ni\u00adtions of these operators are given by 1,163 semantic rules spread over \n5,884 source lines of code (SLOC). However, it takes only 77 of those rules (536 SLOC) to cover the behavior \nof statements, and another 163 for expressions (748 SLOC). There are 505 rules for dealing with declarations \nand types, 115 rules for memory, and 189 technical rules de.ning helper operators. Finally, there are \n114 rules for the core of our standard library. The semantics itself is described in more detail in Section \n4, and is available in its entirety at http://c-semantics.googlecode.com/. Contributions The speci.c \ncontributions of this paper include: a detailed comparison of other C formalizations;  the most comprehensive \nformal semantics of C to date, which is executable and has been thoroughly tested;  demonstrations as \nto its utility in discovering program .aws;  constructive evidence that rewriting-based semantics scale. \n Features Our semantics captures every feature required by the C99 standard. We include a partial list \nhere to give an idea of the completeness, and explain any shortcomings in Section 7. All aspects related \nto the below features are included and are given a direct semantics (not by a translation to other features): \n Expressions: referencing and dereferencing, casts, array index\u00ading (a[i]), structure members (-> and \n.), arithmetic, bitwise, and logical operators, sizeof, increment and decrement, assign\u00adments, sequencing \n(_,_), ternary conditional (_?_:_);  Statements: for, do-while, while, if, if/else, switch, goto, break, \ncontinue, return;  Types and Declarations: enums, structs, unions, bit.elds, initializers, static storage, \ntypedefs, variable length arrays;  Values: regular scalar values (signed/unsigned arithmetic and pointer \ntypes), structs, unions, compound literals;  Standard Library: malloc/free, set/longjmp, basic I/O; \n Conversions: (implicit) argument and parameter promotions and arithmetic conversion, and (explicit) \ncasts.   2. Comparison with Existing Formal C Semantics There have already been a number of formal \nsemantics written for C. One might (rightfully) ask, Why yet another? We claim that the de.nitions so \nfar have either made enough simplifying assumptions that for many purposes they are not C, or have lacked \nany way to use them other than on paper. While paper semantics are useful for teaching and understanding \nthe language, we believe that without a mechanized de.nition, it is di.cult to gain con.dence in a de.nition \ns appropriateness for any other purpose. Below we highlight the most prominent de.nitions and explain \ntheir successes and shortcomings in comparison with our work. Gurevich and Huggins (1993) One of the \nearliest formal descrip\u00adtions of ANSI C is given by Gurevich and Huggins [11], using abstract state machines \n(ASMs) (then known as evolving algebras). Their semantics describes C using four increasingly precise \nlayers, each formal and analyzable. Their semantics covers all the high\u00adlevel constructs of the language, \nand uses external oracles to capture the underspeci.cation inherent in the de.nition of C. Their seman\u00adtics \nwas written without access to a standard, and so is based on Kernighan and Ritchie [17]. However, many \nbehavioral details of the lowest-level features of C are now partially standardized, including details \nof arithmetic, type representation, and evaluation strategies. The latter has been investigated in the \ncontext of ASMs [36], but none are present in the original de.nition. Based on our own ex\u00adperience, the \ndetails involving the lowest-level features of C are incredibly complex (see Section 3.2), but we see \nno reason why the ASM technique could not be used to specify them. Their semantics was never converted \ninto an executable tool, nor has it been used in applications. However, their purpose and context was \ndi.erent from ours. As pointed out elsewhere [22, p. 11], their semantics was constructed without the \nbene.t of any mechanization. According to Gurevich,1 their purpose was to discover the structure of C, \nat a time when C was far beyond the reach of denotational semantics, algebraic speci.cations, etc. Cook, \nCohen, and Redmond (1994) Soon after the previous de.nition, Cook et al. [5] describe a denotational \nsemantics of C90 using a custom-made temporal logic for the express purpose of proving properties about \nC programs. Like us, they give semantics for particular implementation-de.ned behaviors in order to have \na more concrete de.nition. These choices are then partitioned o. so that one could, in theory, choose \ndi.erent implementation-de.ned values and behaviors. They have given at least a basic semantics to most \nC constructs. We say at least without malicious intent although their work was promising, they moved \non to other projects before developing a testable version of their semantics and without doing any concrete \nevaluation.1 Additionally, no proofs were done using this semantics. Cook and Subramanian (1994) The \nrelated work of Cook and Subramanian [4, 33] is a semantics for a restricted subset of C, based loosely \non the semantics above. This semantics is embedded in the theorem prover Nqthm [2] (a precursor to ACL2). \nThey were successful in verifying at least two functions: one that takes two pointers and swaps the values \nat each, and one that computes the factorial. They were also able to prove properties about the C de.nition \nitself. For example, they prove that the execution of p = &#38;a[n] puts the address of the nth element \nof the array a into p [4, p. 122]. Their semantics is, at its roots, an interpreter it uses a similar \ntechnique to that described by Blazy and Leroy [1] to coax an interpreter from recursive functions but \nthere is no description in their work of any reference programs they were capable of executing. As above, \nit appears the work was terminated before it was able to blossom. 1 Personal communication, 2010. Norrish \n(1998) The next major semantics was provided by Nor\u00ad rish [22], who gives both static and dynamic formal \nsemantics inside the HOL theorem proving system for the purpose of verifying C pro\u00adgrams (later extended \nto C++ [23]). His semantics is in the Structural Operational Semantics (SOS) style, using small-step \nfor expressions and big-step for statements. One of the focuses of his work is to present a precise description \nof the allowable evaluation orders of expressions. His semantics still stands as a precise representation \nof evaluation in C. In Section 6.3 we demonstrate how our de.nition captures the same behaviors. Working \ninside HOL provides an elegant solution to the under\u00adspeci.cation of the standard Norrish can state facts \ngiven by the standard as axioms/theorems. To maintain executability, we chose instead to parameterize \nour de.nition for those implementation\u00adde.ned choices. In that respect, our de.nitions conceptually comple\u00adment \neach other his is better for formal proofs about C, while ours is better for searching for behaviors \nin programs (see Section 6.3.1). Proofs of program correctness [31] as well as semantics-level proofs \n[8] have already been demonstrated in the framework used by our semantics, but we have not yet applied \nthese techniques to C. Norrish uses his de.nition to prove some properties about C itself, as well as \nto verify some strong properties of simple (= 5 line) programs, but was unable to apply his work to larger \nprograms. His semantics is not executable, so it has not been tested against actual programs. However, \nthe proofs done within the HOL system help lend con.dence to the de.nition. Papaspyrou (2001) A denotational \nsemantics for C99 is described by Papaspyrou [24, 25] using a monadic approach to domain construction. \nThe de.nition includes static, typing, and dynamic semantics, which enables him not only to represent \nthe behavior of executing programs, but also check for errors like rede.nition of an identi.er in the \nsame scope. Papaspyrou, Norrish, and Cook et al. each give a typing semantics in addition to the dynamic \nsemantics, while we and Blazy and Leroy (below) give only dynamic semantics. Papaspyrou represents his \nsemantics in Haskell, yielding a tool capable of searching for program behaviors. This was the only semantics \nfor which we were able to obtain a working interpreter, and we were able to run it on a few examples. \nHaving modeled expression non-determinism, and being denotational, his semantics evaluates a program \ninto a set of possible return values. However, we found his interpreter to be of limited capability in \npractice. For example, using his de.nition, we were unable to compute the factorial of six or the fourth \nFibonacci number. Blazy and Leroy (2009) A big-step operational semantics for a subset of C, called Clight, \nis given by Blazy and Leroy [1]. While they do not claim to have given semantics for the entirety of \nC, their semantics does cover most of the major features of the language and has been used in a number \nof proofs including the veri.cation of the optimizing compiler CompCert. To help validate their semantics, \nthey have done manual re\u00adviews of the de.nition as well as proved properties of the semantics such as \ndeterminism of evaluation. They additionally have veri.ed semantics-preserving transformations from their \nlanguage into sim\u00adpler languages, which are easier to develop con.dence in. Their semantics is not directly \nexecutable, but they describe a mechanism by which they could create an equivalent recursive function \nthat would act as an interpreter. This work has not yet been completed. Clight does not handle non-determinism \nor sub-expressions with side e.ects. However, since publication, they have added a new front-end small-step \nde.nition called CompCert C that does handle these features, and is also being used to handle goto.3 \n2 Personal communication, 2010. 3 Personal communication, 2011.  De.nition Feature GH CCR CR No Pa BL \nER Bit.elds Enums Floats String Literal Struct as Value (0 0 0 0 (0 0 0 0 0 0 0 0 0 0 0 0 (0 0 0 0 \n 0 Arithmetic Bitwise Casts Functions Exp. Side E.ects (0 0 (0  (0  0 0 (0 0 0 0 (0  (0   0 Break/Continue \nGoto Switch (0 (0 (0 0 (0 0 0 0 0  0 (0 Longjmp Malloc Variadic Funcs. 0 0 0 0 0 0 0 0 0 0 0 0 0 \n0 0 0 0 0 Feature GH CCR CR No Pa BL ER : Fully Described (0: Not Described 0: Partially Described GH \nrepresents Gurevich and Huggins [11], CCR is Cook et al. [5], CR is Cook and Subramanian [4], No is Norrish \n[22], Pa is Papaspyrou [25], BL is Blazy and Leroy [1], and ER is our work. Figure 1. Dynamic Semantics \nFeatures We condense our study of related works in Figure 1. For interested parties, this chart may be \ncontentious. However, we believe that it is useful, both for developers of formal semantics of C and \nfor users of them, to give a broad (though admittedly incomplete) overview of the state of the art of \nthe formal semantics of C. Also, it may serve as an indication of the complexity involved in the C language, \nalthough not all features are equally di.cult. We did our best to give the authors the bene.t of the \ndoubt with features they explicitly mentioned, but the other features were based on our reading of their \nsemantics. We have also discussed our views with the authors, where possible, to try and establish a \nconsensus. Obviously the categories are broad, but our intention is to give an overview of some of the \nmore di.cult features of C. We purposefully left o. any feature that all de.nitions had fully de.ned. \nFinally, there are a number of other emergent features, such as multi-dimensional arrays, that are di.cult \nto discern correctness through simple inspection of the formal semantics (i.e., without testing or verifying \nit). It is also di.cult to determine if feature pairs work together for example, does a de.nition allow \nbit.elds inside of unions? We decided to leave most of these features out of the chart because they are \nsimply too hard to determine if the semantics were complete enough for them to work properly. 3. Background \nIn this section we give a little background on the C standard, including some important de.nitions. We \nadditionally explain the rewriting formalism we use to give our semantics of C. 3.1 C Standard Information \nThe C standard uses the idea of unde.ned and partially de.ned behaviors in order to avoid placing di.cult \nrequirements on imple\u00admentations. It categorizes the particular behaviors of any C imple\u00admentation that \nare not fully de.ned into four categories: unspeci.ed, implementation-de.ned, unde.ned, and locale-speci.c \nbehavior. For the purposes of this paper, we focus on three of these [15, \u00a73.4]: unspeci.ed behavior \nUse of an unspeci.ed value, or other behav\u00adior [with] two or more possibilities and [. . . ] no further \nrequire\u00adments on which is chosen in any instance. implementation-de.ned Unspeci.ed behavior where each \nimple\u00admentation documents how the choice is made. unde.ned behavior Behavior, upon use of a non-portable \nor erro\u00adneous program construct or [data, with] no requirements. An example of unspeci.ed behavior is \nthe order in which the argu\u00adments to a function are evaluated. An example of implementation de.ned behavior \nis the size of an int. An example of unde.ned behavior is referring to an object outside of its lifetime. \nTo put these de.nitions in perspective, for a C program to be maximally portable, it shall not produce \noutput dependent on any unspeci.ed, unde.ned, or implementation-de.ned behavior [15, \u00a74.5]. This is called \nstrictly conforming . However, programmers use C for many inherently non-portable tasks, such as writing \ndevice drivers. The standard o.ers another level of conformance (called conforming ) where the program \nmay rely on implementation\u00adde.ned or even unspeci.ed (but never unde.ned) behavior. Based on this, our \nde.nition is parametric in implementation-de.ned be\u00adhaviors, and uses symbolic computation to describe \nunspeci.ed behaviors. As much as possible, this behavior is kept separate from the semantics underlying \nthe high-level (de.ned for all implemen\u00adtations) aspects of the language. More details about our parame\u00adterization \nare described in Section 4.5, and about our use of sym\u00ad bolic values in Section 6.2.2.  3.2 Why Details \nMatter It is tempting to gloss over the details of C s arithmetic and other low-level features when giving \nit a formal semantics. However, C is designed to be translatable to machine languages where arithmetic \nis handled by any number of machine instructions. The e.ects of this overloading are easily felt at the \nsize boundaries of the types. It is a common source of confusion among programmers, and so a common source \nof bugs. Here we give a few examples that reveal even apparently simple C programs can involve complex \nsemantics. For the purposes of these examples, assume that ints are 2 bytes (capable of representing \nthe values -32768 to 32767) and long ints are 4 bytes (-2147483648 to 2147483647). Also, unless speci.ed, \nin C a type is assumed to be signed.4 In the following program, what value does c receive [34, Q3.14]? \nint a = 1000, b = 1000; long int c = a * b; One is tempted to say 1000000, but that misses an important \nC\u00adspeci.c detail. The two operands of the multiplication are ints, so the multiplication is done at the \nint level. It therefore over.ows (1000 * 1000 = 1000000 > 32767), which, according to the C standard, \nmakes the expression unde.ned. What if we make the types of a and b unsigned (0 to 65535)? unsigned int \na = 1000, b = 1000; long int c = a * b; Here, the arithmetic is again performed at the level of the operands, \nbut over.ow on unsigned types is completely de.ned in C. The result is computed by simply reducing the \nvalue modulo one more than the max value [15, \u00a76.3.1.3:2]. 1000000 mod 65536 gives us 16960. One last \nvariation signed chars are one byte in C (-128 to 127).5 What does c receive? signed char a = 100, b \n= 100; int c = a * b; 4 Except chars and bit.elds, whose signedness is implementation-de.ned. 5 Bytes \nare only required to be at least 8 bits long.  Since the chars are signed, then based on the .rst example \nabove the result would seem unde.ned (100 * 100 = 10000 > 127). However, this is not the case. In C, \ntypes smaller than ints are promoted to ints before doing arithmetic. There are essentially implicit \ncasts on the two operands: int c = (int)a * (int)b;. Thus, the result is actually 10000. While the above \nexamples might seem like a game, the conclu\u00adsion we draw is that it is critical when de.ning the semantics \nof C to handle all of the details. The semantics at the higher level of functions and statements is actually \nmuch easier than at the level of expressions and arithmetic. These issues are subtle enough that they \nare very di.cult to catch just by manually inspecting the code, and so need to be represented in the \nsemantics if one wants to .nd bugs in real programs. Even though errors related to the above details \ncontinue to be found in real compilers [35], previous semantics for C either did not give semantics at \nthis level of detail, or were not suit\u00adable for identifying programs that misused these features. This \nis one of our primary reasons for wanting an executable semantics. We give some of the rules associated \nto binary arithmetic in Section 4.4.4.  3.3 Rewriting Logic and K To give our semantics, we use a rewriting-based \nsemantic framework called K [28], inspired by RL [18]. In particular, our semantics is written using \nthe K-Maude tool [32], which takes K rewrite rules and translates them into Maude [3]. Maude is a rewriting-logic \nengine that provides facilities for the execution and analysis of rewriting-logic theories. RL organizes \nterm rewriting modulo equations (namely associa\u00adtivity, commutativity, and identity) as a logic with \na complete proof system and initial model semantics. The central idea behind using RL as a formalism \nfor the semantics of languages is that the evo\u00adlution of a program can be clearly described using rewrite \nrules. A rewriting theory consists essentially of a signature describing terms and a set of rewrite rules \nthat describe steps of computation. Given some term allowed by signature (e.g., a program together with \ninput), deduction consists of the application of the rules to that term. This yields a transition system \nfor any program. A single path of rewrites describes the behavior of an interpreter, while searching \nall paths would yield all possible answers in a nondeterministic program. For the purposes of this paper, \nthe Kformalism can be regarded as a front-end to RL designed speci.cally for de.ning languages. In K, \nparts of the state are represented as labeled, nested multisets, as seen in Figure 2. These collections \ncontain pieces of the program state like a computation stack or continuation (e.g., k), environments \n(e.g., env, types), stacks (e.g., callStack), etc. As this is all best understood through an example, \nlet us consider a typical rule for a simple imperative language (see Section 4.4.2 for the equivalent \nrule in C) for .nding the address of a variable: ( &#38;X \u00b7\u00b7\u00b7)k (\u00b7\u00b7\u00b7 X . L \u00b7\u00b7\u00b7)env L We see here two \ncells, k and env. The k cell represents a list (or stack) of computations waiting to be performed. The \nleft-most (i.e., top) element of the stack is the next item to be computed. The env cell is simply a \nmap of variables to their locations. The rule above says that if the next thing to be evaluated (which \nhere we call a redex) is the application of the referencing operator (&#38;) to a variable X, then one \nshould match X in the environment to .nd its location L in memory. With this information, one should \ntransform the redex into that location in memory, L. This example exhibits a number of features of K. \nFirst, rules only need to mention those cells (again, see Figure 2) relevant to the rule. The rest of \nthe cell infrastructure can be inferred, making the rules robust under most extensions to the language. \nSecond, to omit a part of a cell we write \u00b7\u00b7\u00b7 . For example, in the above k cell, we are only interested \nin the current redex &#38;X, but not the rest of the context. Finally, we draw a line underneath parts \nof the state that we wish to change in the above case, we only want to evaluate part of the computation, \nbut neither the context nor the environment change. This unconventional notation is actually quite useful. \nThe above rule would be written out as a traditional rewrite rule like this: (&#38; X r .)k (.1, X . \nL,.2)env .(L r .)k (.1, X . L,.2)env Items in the k cell are separated with r , which can now be seen. \nThe . and .1, .2 take the place of the \u00b7\u00b7\u00b7 above. The most important thing to notice is that nearly the \nentire rule is duplicated on the right\u00adhand side (RHS). Duplication in a de.nition requires that changes \nbe made in concert, in multiple places. If this duplication is not kept in sync, it leads to subtle semantic \nerrors. In a complex language like C, the con.guration structure is much more complicated, and would \nrequire actually including additional cells like control and local (Figure 2). These intervening cells \nare automatically inferred in K, which keeps the rules more modular. Going back to K, we use \u00b7 to represent \nthe unit element of any algebraic lists or sets (including the r list). We also use  to stand for a \nterm that we do not care to name. Finally, in order to get the redexes to the top of the k cell (i.e., \nin order to identify which positions in the syntax tree can be reduced next), the grammar of C is annotated \nwith additional strictness annotations. For example, for addition, we say that Exp ::= Exp + Exp [strict] \nmeaning that either argument of the addition operator can be taken out for evaluation, nondeterministically. \nIn contrast, the if construct looks like this: Stmt ::= if (Exp) Stmt [strict(1)] indicating that only \nthe .rst argument can be taken out for evaluation. The two annotations above cause the following six \nrules to be automatically generated: ( E1 +E2 \u00b7\u00b7\u00b7)k ( E1 +E2 \u00b7\u00b7\u00b7)k ( if (E)S \u00b7\u00b7\u00b7)k E r if (o)S E1 r o+E2 \nE2 r E1 +o ( V r o+E2 \u00b7\u00b7\u00b7)k ( V r E1 +o \u00b7\u00b7\u00b7)k ( V r if (o)S \u00b7\u00b7\u00b7)k V +E2 if (V)S Here, E1, E2, and E represent \nunevaluated expressions and V represents an evaluated expression (i.e., a value). While these are the \nrules generated by K-Maude, in the theory of Kthey can apply anywhere (not just at the top of the k cell). \nThere are additional annotations for specifying more particular evaluation strategies, and can be found \nin documentation on K [28]. We also give names to certain contexts that are evaluated di.erently. For \nexample, the left\u00adhand side (LHS) of an assignment is evaluated di.erently than the RHS. The use of this \nis described in Section 4.4.1. E1 +V 4. The Semantics of C in K In this section, we describe the di.erent \ncomponents of our de.ni\u00adtion and give a number of example rules from the semantics. 4.1 Syntax We use \nthe FrontC parser, with additions made and included in CIL [19], an o.-the-shelf C parser and transformation \ntool. FrontC itself parses only ANSI C (C90), but CIL extended it with syntax for C99. We use only the \nparser here, and none of the transformations of CIL; we give semantics directly to the abstract syntax \ntree generated by the parser. The FrontC parser (with C99 extensions) is used by a number of other tools, \nincluding CompCert [1] and Frama-C [6]. 4.2 Con.guration (Program + State) The con.guration of a running \nprogram is represented by nested multisets of labeled cells, and Figure 2 shows the most important cells \nused in our semantics. While this .gure only shows 17 cells,  (K)k(Map)env (Map)types (Map)structs \n(List)loopStack (Bag)locsWrittenTo (K)currFunction(List)callStack control local (Map)genv (Map)gtypes \n(Map)gstructs (Map)mem (Map)malloced (Map)gotoMap T Figure 2. Subset of the C Con.guration we use over \n60 in the full semantics. The outer T cell contains the cells used during program evaluation: at the \ntop, a k cell contains the current computation itself and a local cell holds a number of cells related \nto control .ow, and below, there are a number of cells dealing with global information. In the local \ncell, there is a callstack used for calling and returning from functions, and a control cell which gets \npushed onto the call stack. Inside the control cell, there is a local variable environment (env), a local \ntype environment (types), local aggregate de.nitions (structs), a loop stack, a record of the locations \nthat have been written to since the last sequence point (Section 4.6), and the name of the current function. \nThe cells inside the control cell were separated in this manner because these are the cells that get \npushed onto the call stack when making a function call. Outside the local cell are a number of global \nmappings, such as the global variable environment (genv), the global type environment (gtypes), global \naggregate de.nitions (gstructs), the heap (mem), the dynamic allocation map (malloced), and a map from \nfunction\u00adname/label pairs to continuations (for use by goto and switch).  4.3 Memory Layout Our memory \nis essentially a map from locations to blocks of bytes. It is based on the memory model of both Blazy \nand Leroy [1] and Ros, u et al. [30] in the sense that the actual locations themselves are symbolic numbers. \nHowever, it is more like the former in that the actual blocks of bytes are really maps from o.sets to \nbytes. Below we see a snippet of a memory cell, holding four bytes: (\u00b7\u00b7\u00b7 32 . obj (4, (0 . 7, 1 . 23, \n2 . 140, 3 . 4)) \u00b7\u00b7\u00b7)mem This says that at symbolic location 32, there is an object whose size is 4 bytes; \nthose bytes are 7, 23, 140, and 4. All objects are broken into individual bytes, including aggregate \ntypes like arrays or structs, as well as base types like integers. Our pointers are actually base/o.set \npairs, which we write as sym(B) + O, where B corresponds to the base address of an object itself, while \nthe O represents the o.set of a particular byte in the object. We wrap the base using sym because it \nis symbolic despite representing a location, it is not appropriate to, e.g., directly compare B < B' \n(Section 6.2.2). It is better to think of the 32 above as representing object 32 , as opposed to location \n32 . When looked up, the bytes are interpreted depending on the type of the construct used to give the \naddress. The simplest example possi\u00adble is dereferencing a pointer sym(32)+ 2 of type unsigned char*, \nwhich would simply yield the value 140 of type unsigned char. Looking up data using di.erent pointer \ntypes requires taking into account a number of implementation-de.ned details such as the use of signed \nmagnitude, one s, or two s complement representation, or the order of bytes (endianness). These choices \nare made para\u00admetric in the semantics, and can be con.gured depending on which implementation a user \nis interested in working with (Section 4.5). When new objects (ints, arrays, structs, etc.) get allocated, \neach is created as a new block and is mapped from a new symbolic number. The block is allowed to contain \nas many bytes as in the object, and accesses relative to that object must be contained in the block. \nWe represent information smaller than the byte (i.e., bit.elds) by using o.sets within the bytes themselves. \nWhile it might seem that it would be more consistent to treat memory as mappings from bit locations to \nindividual bits, bit.elds themselves are not addressable in C, so we decided on this hybrid approach. \n 4.4 Semantics We now give the .avor of our semantics by examining a few of the 1,163 rules. For the \nrules below, recall that in Kwhat is above the line is considered the LHS of the rule, while what is \nbelow the line is considered the RHS. Parts of a rule without a line at all are considered to be on both \nsides of the rule. 4.4.1 Lookup and Assignment We .rst consider one of the most basic expressions the \nidenti\u00ad.er. According to the standard, An identi.er is a primary expres\u00adsion, [. . . ] designating an \nobject (in which case it is an lvalue) or a function (in which case it is a function designator) [15, \n\u00a76.5.1:2]. Although in informal language an lvalue is an expression that appears on the LHS of an assignment, \nthis is not the case according to the C standard. An lvalue can be more accurately thought of as any \nexpression that designates a place in memory; a footnote in the standard suggests it might better be \ncalled a locator value [15, \u00a76.3.2.1:1]. We denote lvalues with brackets; an lvalue that points to location \nL which is of type T is denoted by [L]: T . With this in mind, here then is our lookup rule: ( X \u00b7\u00b7\u00b7)k \n(\u00b7\u00b7\u00b7 X . L \u00b7\u00b7\u00b7)env (\u00b7\u00b7\u00b7 X . T \u00b7\u00b7\u00b7)type [L]: T This rule is actually very similar to the example address-of \nrule we gave in Section 3.3. It says that when the next thing to evaluate is the program variable X, \nboth its location L and its type T should be looked up (in the env and type cells), and the variable \nshould be replaced by an lvalue containing those two pieces of information. We distinguish between objects \nand functions based on type. In almost all contexts, this lvalue will actually get converted to the value \nat that location: Except when it is the operand of the sizeof operator, the unary &#38; operator, the \n++ operator, the --operator, or the left operand of the . operator or an assignment operator, an lvalue \nthat does not have array type is converted to the value stored in the designated object (and is no longer \nan lvalue) [13, \u00a76.3.2.1:2]. We call these contexts reval , for right evaluation. Here is the rule for \nsimplifying lvalues in the right value context: reval([L]: T) where \u00ac(isArrayType(T) . isFunctionType(T)) \nread(L, T) The rule for read then does the actual read from memory. Its evaluation involves a series \nof rules whose job is to determine the size of the type, pull the right bytes from memory, and to piece \nthem together in the right order to reconstruct the value. There are over 10 highly technical rules de.ning \nread , just for integer types alone. This process results in a normal value, instead of an lvalue, which \nwe represent simply as V : T .  4.4.2 Reference and Dereference We can now take a look at the rule for \nthe &#38; operator: ( &#38;([L]: T ) \u00b7\u00b7\u00b7)k L : pointerType(T) This rule says that when the next computation \nto be performed is taking the address of an lvalue, it should simply be converted into a true value holding \nthe same address, but whose type is a pointer type to the original type. We can expect to .nd an lvalue \n as the argument because the reval context does not include the arguments of the address operator. The \nrule for dereference is similarly simple: ( *(L : pointerType(T)) \u00b7\u00b7\u00b7)k where T * void checkDerefLoc(L) \nr [L]: T This will .rst make sure that the location L is allowed to be dereferenced (e.g., it is valid \nmemory), and will then evaluate to an lvalue of the same location. As with lookup, no memory is read \nby default. Notice that checkDerefLoc is blocking the top of the k cell. As long as it stays there, no \nrules that match other constructs on the top of k can apply. If checkDerefLoc succeeds, it will simply \nevaluate to the unit of the rconstruct and disappear. This is called dissolving . Our rule for checkDerefLoc \nis: ( checkDerefLoc(sym(B) + O) \u00b7\u00b7\u00b7)k (\u00b7\u00b7\u00b7 B . obj(Len, ) \u00b7\u00b7\u00b7)mem \u00b7 where O < Len Here we match the constituent \nparts of a location, B and O, or base and o.set as explained in Section 4.3. We then match the base part \nof the pointer in the memory cell, giving us an object, and check that the o.set is within the bounds \nof the object. If this is the case, we dissolve the checkDerefLoc task.  4.4.3 Structure Members The \nstandard says, A post.x expression followed by the . operator and an identi.er designates a member of \na structure or union object. The value is that of the named member, and is an lvalue if the .rst expression \nis an lvalue [15, \u00a76.5.2.3:3]. Here is the rule for when the .rst expression is an lvalue: ( ([L] : structType(S)).F \n\u00b7\u00b7\u00b7)k (\u00b7\u00b7\u00b7 S . (F . (O.set, T) ) \u00b7\u00b7\u00b7)structs [L + O.set]: T This rule .nds the o.set O.set and type T \nof the .eld F in struct S and simply adds the o.set to the base address L of the struct to evaluate the \nexpression. The result is another lvalue of the type of the .eld. In contrast, the rule for when the \n.rst expression is not an lvalue cannot simply work with pointers: ( (V : structType(S)).F \u00b7\u00b7\u00b7)k (\u00b7\u00b7\u00b7 \nS . (F . SD ) \u00b7\u00b7\u00b7)structs extractField(V, SD, S, F) One situation in which this arises is when a function \nreturns a struct, and the programmer uses the function call to access a particular .eld, as in the expression \nfun().field. The call to fun() will result in a struct value, represented in the rule above by V : structType(S \n). The helper function extractField will look at the bytes of the struct (represented by V) and read \na value of the appropriate type (SD contains the o.set and type of the .eld). There are many rules shared \nby the extractField and read helpers, since both have to piece together bytes in implementation-de.ned \norders to make new values. The semantics for the arrow operator (p->f) is identical to that of the dot \noperator above after dereferencing the .rst subexpression: E -> F . (*E).F There are similar rules as \nabove for union, where all o.sets of a union s .elds are 0. 4.4.4 Multiplication (and Related Conversions) \nAs mentioned in Section 3.2, the rules for arithmetic in C are non\u00ad trivial. To show this in more detail, \nhere we give many of the rules related to integer multiplication. Here is the core multiplication rule: \n(I1: T ) * (I2: T ) where hasBeenPromoted(T ) arithInterpret(T, I1 *Int I2) This rule matches when multiplying \nvalues with identical, promoted types (more on promotion shortly). It then uses a helper operator arithInterpret \nto convert the resulting product into a proper value: arithInterpret(T, I) where min(T) = I . max(T ) \n= I I : T arithInterpret(T, I) where isUnsignedIntType(T) arithInterpret(T, I -Int (max(T) +Int 1)) . \nI > max(T) arithInterpret(T, I) where isUnsignedIntType(T) arithInterpret(T, I +Int (max(T) +Int 1)) \n. I < min(T) The .rst rule creates a value as long as the product is the range of the type. The next \ntwo rules collapse out-of-range unsigned products into range [15, \u00a76.3.1.3:2]. By not giving rules to \nout-of-range signed types, we catch signed over.ow here. With the above rules de.ned, the question becomes \nhow to promote and convert the types of the operands so that the core multiplication rule can take e.ect. \nFirst, all arithmetic in C takes place at or above the size of ints. This means smaller types need to \nbe coerced into int or unsigned int. (( : T ) * \u00b7\u00b7\u00b7)k where \u00achasBeenPromoted(T ) promote(T ) The above \nrule (and its commutative partner) cause unpromoted multiplication operands to be promoted. Of the actual \npromotion, the standard says, If an int can represent all values of the original type [. . . ], the value \nis converted to an int; otherwise, it is converted to an unsigned int [15, \u00a76.3.1.1:2]: promote(T) where \nmin(int) = min(T) . max(int) = max(T) int promote(T) where \u00ac(min(int) = min(T) . max(int) = max(T)) unsigned \nint Finally, in order to perform the multiplication, the types of the operands have to be identical. \nIf the types are not identical, an implicit conversion takes place to convert the di.erent types to a \ncommon type. There are eight rules for this given in the standard. To give an idea of their .avor, we \ngive a few of the rules for integer conversions here. First, the rule to enable conversion: '' ( I1: \nT * I2: T \u00b7\u00b7\u00b7)k where T * T cast(t, I1: T) cast(t, I2: T ') . t = arithConv(T, T ' ) The standard says, \nif both operands have signed integer types or both have unsigned integer types, the operand with the \ntype of lesser integer conversion rank is converted to the type of the operand with greater rank [15, \n\u00a76.3.1.8:1]: arithConv(T, T ') where hasSameSignedness(T, T ) maxType(T, T ' ) Rank is a partial ordering \non integer types based on their ranges and signedness, e.g., rank(short int) < rank(int). Additionally, \nthe ranks of unsigned integer types equal the ranks of the corresponding signed integer types [15, \u00a76.3.1.1:1]. \nContinuing with the conversion rules, Otherwise, if the operand that has unsigned integer type has rank \ngreater or equal to the rank of the type of the other operand, then the operand with signed integer type \nis converted to the type of the operand with unsigned integer type [15, \u00a76.3.1.8:1]: isUnsigned(T ) ( \narithConv(T, T ') \u00b7\u00b7\u00b7)k where . isSigned(T ' ) T . rank(T ) = rank(T ' ) and similarly for the commutative \ncase. The above equations use a number of helper operators in the side conditions the de.nitions for \nmin and max are given in Section 4.5; the other operators are de.ned as expected.  4.4.5 Malloc and \nFree Here we show our semantics of malloc and free. These are functions from the standard C library that \nperform dynamic memory allocation and deallocation. The declarations of these functions are: void *malloc(size_t \nsize); void free(void *ptr); where size_t is an unsigned integer type that is implementation de.ned. \nWhen a programmer calls malloc(), an implementation can return a new pointer pointing to a new block \nof memory the size speci.ed by the programmer, or it can return NULL (e.g., if there is no memory available). \n Here is the rule for a successful call to malloc: ( malloc(N : size_t) \u00b7\u00b7\u00b7)k (\u00b7\u00b7\u00b7 \u00b7 \u00b7\u00b7\u00b7)malloced alloc(L, \nN) r L : pointerType(void) L . N where L is fresh If the user requests N bytes, the semantics will schedule \nthat many bytes to be allocated at a new location and record that this memory was dynamically allocated \nin the malloced cell. Here is the related rule for a failed called to malloc: ( malloc( ) \u00b7\u00b7\u00b7)k NullPointer \n: pointerType(void) This rule is usually only useful when searching the state space. A call to free is \nmeant to deallocate space allocated by malloc. Its rule is also straightforward: ( free(L : ) \u00b7\u00b7\u00b7)k (\u00b7\u00b7\u00b7 \nL . N \u00b7\u00b7\u00b7)malloced (\u00b7\u00b7\u00b7 L . obj(N, ) \u00b7\u00b7\u00b7)mem \u00b7\u00b7 \u00b7 When the user wants to free a pointer L, it is removed \nfrom both the malloced and mem cells. By matching these cells, the rule ensures that the pointer has \nnot already been freed, and once applied, ensures no other rules that use that address can match into \nthe memory.  4.4.6 Setjmp and Longjmp Finally, we show our semantics of setjmp and longjmp. These are \nfunctions from the standard C library that perform complex control .ow. They are reminiscent of call/cc, \nand are often used as a kind of exception handling mechanism in C. The declarations of these functions \nare: int setjmp(jmp_buf env); void longjmp(jmp_buf env, int val); where jmp_buf is an array type suitable \nfor holding the information needed to restore a calling environment. A call to setjmp saves its calling \nenvironment [. . . ] for later use by the longjmp function. Additionally, the call to setjmp evaluates \nto zero [15, \u00a77.13.1]. Here is our rule for setjmp: ( setjmp(L : jmp_buf) r .)k (C)local write(L, C (.)k \n) r 0 : int Because jmp_buf is an array type, it will evaluate to an address L. In the rule above, we \nmatch the remaining computation . (similar to a continuation), as well as the local execution environment \nC. This includes cells like the call stack and the map from variables to locations (which we also call \nthe environment). The rule then causes this information to be written at the location of the jmp_buf. \nA call to longjmp restores the environment saved by the most recent invocation of [setjmp] with the corresponding \njmp_buf argument [15, \u00a77.13.2]. When the user calls longjmp, this address is read to .nd that previous \ncontext: ( longjmp ( L : T , ) \u00b7\u00b7\u00b7)k longjmp-aux read(L, T ) and it is then restored: ( longjmp-aux((C \n(.)k : ), I : int) r )k ( )local (if I = 0 then 1 else I .) : int . C This function returns the val \nthat the user passes, unless this is a 0, in which case it returns 1. It should be clear that these rules \noperate on the con.guration itself, treating it as a .rst-class term of the formalism. The fact that \nK allows one to grab the continuation . as a term is what makes the semantics of these constructs so \neasy to de.ne. This is in sharp opposition to semantic formalisms like SOS [27] where the context is \na derivation tree and not directly accessible as an object inside a de.nition.  4.5 Parametric Behavior \nWe chose to make our de.nition parametric in the implementation\u00adde.ned behaviors (and are not the .rst \nto do so [1, 5]). Thus, one can con.gure the de.nition based on the architecture or compiler one is interested \nin using, and then proceed to use the formalism to explore behaviors. This parameterization allows the \nde.nition to be .eshed out and made executable. For a simple example of how the de.nition is parametric, \nour K-Maude module C-SETTINGS starts with: numBytes(signed-char) . 1 numBytes(short-int) . 2 numBytes(int) \n. 4 numBytes(long-int) . 4 numBytes(long-long-int) . 8 numBytes(.oat) . 4 numBytes(double) . 8 numBytes(long-double) \n. 16 These settings are then used to de.ne a number of operators: numBits(T) . numBytes(T) * bitsPerByte \nwhere \u00acisBit.eldType(T) min(int) .-Int(2numBits(int)-Int 1) max(int) . 2numBits(int)-Int1 -Int 1 Here \nwe use a side condition to check when a type is not a bit.eld. Finally, the above rules are used to de.ne \nhow an integer I of type T is cast to an unsigned integer type T ' : cast(T , I : T) . (I %Int (max(T \n) +Int 1))) : T where isIntegerType(T) . isUnsignedIntType(T ) . I > max(T ) Here we use helper predicates \nin our side conditions to make sure this rule only applies when casting from integer types to unsigned \ninteger types. There are similar equations used to de.ne other cases.  4.6 Expression Evaluation Strategy \nand Unde.ned Behavior The C standard allows compilers freedom in optimizing code, which includes allowing \nthem to choose their own expression evaluation order. This includes allowing them to: delay side e.ects: \ne.g., allowing the write to memory required by x=5 or x++ to be made separately from its evaluation or \nuse;  interleave evaluation: e.g., A + (B * C) can be evaluated in the order B, A, C.  At the same \ntime, the programmer must be able to write programs whose behaviors are reproducible, and only allow \nnon-determinism in a controlled way. Therefore, the standard makes unde.ned certain situations where \nreordering creates a race condition . The latest treatment of this restriction is given by the C1X standard: \nIf a side e.ect on a scalar object is unsequenced relative to ei\u00ad ther a di.erent side e.ect on the same \nscalar object or a value computation using the value of the same scalar object, the behavior is unde.ned. \nIf there are multiple allowable order\u00ad ings [...], the behavior is unde.ned if such an unsequenced side \ne.ect occurs in any of the orderings [15, \u00a76.5:2]. This means that if there are two writes, or a write \nand a read to the same object that are unsequenced (i.e., either is allowed to happen before the other), \nthen the expression is unde.ned. Examples of expressions made unde.ned by this clause include (x=0)+(x=1) \nand (x=0)+x and x=x++ and *p=x++, for int x and int* p=&#38;x. This relation is related to the concept \nof sequence points , also de.ned by the standard. Sequence points cause the expressions they fall between \nto be sequenced. The most common example of a sequence point is the semicolon, i.e., the end of an expression-statement. \nAll previous evaluations and side e.ects must be complete before crossing sequence points. A hasty read \nof the standard may wrongly indicate that detecting this kind of unde.ned behavior is an easy problem \nthat can be checked statically. In fact, it is undecidable statically; moreover, one needs to use the \nentire semantics in order to check it dynamically. Consider the following example:  int x, y, *p = &#38;y; \nint f(void){ if (guard) { p = &#38;x; } return 0; } int main(void){ return (x = 5) + (*p = 6) + f(); \n} The unde.nedness of this program is based on what happens in the call to f(). If f is called before \nthe other subexpressions in main are evaluated, and if the guard expression (which could be arbitrarily \ncomplex) is true, then the remaining expression e.ectively becomes (x = 5) + (x = 6), which is unde.ned. \nThe possible complexity of the guard is a witness to the (static) undecidability of this problem. The \nevaluation of the guard may make arbitrary use of the entire C language, so the entire semantics is needed \nin order to determine whether this program is unde.ned. Based on this, note that: when two expressions \nare unsequenced, it means that evaluation can happen in any order. Thus, it is natural to map unsequenced \nbehavior into nondeterministic behavior. This way, we can use state space exploration as a single mechanism \nto .nd unsequenced behavior. To identify this kind of unde.ned behavior naively can be incredibly computationally \nexpensive; some optimizations are necessary to make this feasible. We o.er two such optimizations below. \nFirst, with a little case analysis of the de.nition of the sequencing relation, it is clear that there \ncan be no sequenced write before a read of the same object with no intervening sequence point. This means \nthat if in searching the semantic state space, we .nd an execution in which the write of a scalar object \nhappens before a write or read of the same object with no intervening sequence point, then we can conclude \nthat this write/write or write/read pair is unsequenced. Whenever a write is made, its location is recorded \nin the locsWrittenTo cell, which is emptied whenever a sequence point is crossed. This cell is .rst checked \nwhenever a read or write is made to ensure that there is no con.ict. This strategy has the added bene.t \nthat some unde.ned behaviors of this kind can be detected even during interpretation (where only a single \npath through the state space is explored). It is similar to the strategy used by Norrish [22]. Second, \nit turns out that a large subset of allowed orderings do not need to be considered in order to detect \nunde.ned behavior or possible nondeterministic behaviors. Because we are looking for writes before other \nevents, we can take the liberty of applying side e.ects immediately instead of delaying them. What would \nit mean for there to exist an expression whose de.nedness relied on whether or not a side e.ect (a write) \noccurs later instead of earlier? There must be three parts to the expression: a subexpression E generating \na side e.ect X, and, for generality s sake, further subexpressions E' and E''. The particular evaluation \nwhere we do sidee.ects immediately would look like EXE' E''. Because this is always a possible execution, \nand we assume it does not show a problem, we can conclude neither E' nor E'' reads or writes to X. If \nthere is a problem only when we delay the side e.ect, it can be seen in a path like EE' XE''. For this \nto be di.erent than applying the changes to X immediately, it means there must be some use of X in the \nevaluation of E'. But this contradicts the previous assumption. This shrinks the state space dramatically, \nwhile at the same time not missing any unde.ned behavior. Our semantics does capture the appropriate \nstate space, as seen in Section 6.3.1.  4.7 KCC Using a simple frontend that mimics the behavior of \nGCC [9], C programs are parsed and translated into a Maude term, then reduced using the rules of our \nformal semantics. For de.ned programs, this process produces indistinguishable behavior from the same \nC program run as native code. We call this interpreter, obtained automatically from our formal semantics, \nKCC. As we will show in Section 6, KCC is signi.cantly more than an interpreter in addition to simple \ninterpretation, it is also capable of debugging, catching unde.ned behaviors, state space search, and \nmodel checking. Once KCC is installed on a system, compilation of C programs generates a single executable \n.le (an a.out ) containing the semantics of C, together with a parsed representation of the program and \na call to Maude. The output is captured by a script and presented so that for working programs the output \nand behavior is identical to that of a real C compiler. To emphasize the seamlessness, here is a simple \ntranscript: $ kcc helloworld.c $ ./a.out Hello world While it may seem like a gimmick, it helped our \ntesting and debugging tremendously. For example, we could run the de.nition using the same test harness \nGCC uses for its testing (see Section 5). It also means people with no formal background can get use \nout of our semantics simply by using it as they would a compiler. 5. Testing the Semantics No matter \nwhat the intended use is for a formal semantics, its actual use is limited if one cannot generate con.dence \nin its correctness. To this aim, we ensured that our formal semantics remained executable and computationally \npractical. 5.1 GCC Torture Tests As discussed in the previous section, our semantics is encapsulated \ninside a drop-in replacement for GCC, which we call KCC. This enables us to test the semantics as one \nwould test a compiler. We were then able to run our semantics against the GCC C-torture\u00adtest [10] and \ncompare its behavior to that of GCC 4.1.2, as well as the Intel C++ Compiler (ICC) 11.1 and Clang 3.0 \nr132915 (C compiler for LLVM). We ran all compilers with optimizations turned o.. We use the torture \ntest for GCC 4.4.2, speci.cally those tests inside the testsuite/gcc.c-torture/execute directory. We \nchose these tests because they focus particularly on portable (machine independent) executable tests. \nThe README.gcc for the tests says, The torture tests are meant to be generic tests that can run on any \ntarget. We found that generally this is the case, although there are also tests that include GCC-speci.c \nfeatures, which had to be excluded from our evaluation. There were originally 1093 tests, of which we \nexcluded 267 tests because they used GCC\u00adspeci.c extensions or builtins, they used the _Complex data \ntype or certain library functions (which are not required of a freestanding implementation of C), or \nthey were machine dependent. This left us with 826 tests. Further manual inspection revealed an additional \n50 tests that were non-conforming according to the standard (mostly signed over.ow or reading from uninitialized \nmemory), bringing us to a grand total of 776 viable tests. In order to avoid over.tting our semantics \nto the tests, we ran\u00addomly extracted about 30% of the conforming tests and developed our semantics using \nonly this small subset (and other programs dis\u00adcussed in Section 5.2). After we were comfortable with \nthe quality of our semantics when running this subset, we ran the remaining tests. Out of 541 previously \nuntested programs, we successfully ran 514 (95%). After this initial test, we began to use all of the \ntests to help develop our semantics; we now pass 770 (99.2%) of the 776 compliant tests. Torture Tests \nRun (of 776) Compiler Count Percent GCC 768 99.0 ICC 771 99.4 Clang 763 98.3 KCC 770 99.2 The 776 tests \nrepresent about 23,500 SLOC, or 30 SLOC/.le.  Correctness Analysis Our executable formal semantics performed \nnearly as well as the best compiler we tested, and better than the others. We incorporated the passing \ntests into our regression suite that gets run every time we commit a change. This way, upon adding features \nor .xing mistakes, our accuracy can only increase. Three of the six failed tests rely on .oating point \naccuracy problems. Two more rely on evaluating expressions inside of function declarators, as in: int \nfun(int i, int array[i++]) { return i; } which we are not handling properly. The last is a problem with \nthe lifetime of variable length arrays. Coverage Analysis In order to have some measure of the e.ective\u00adness \nof our testing, we recorded the application of every semantic rule for all of the torture tests. Out \nof 887 core rules (non-library, non-helper operator), the GCC torture tests exercised 805 (91%). In addition \nto getting a coverage measure, this process suggests an interesting application. For example, in the \nGCC tests looked at above, a rule that deals with casting large values to unsigned int was never applied. \nBy looking at such rules, we can create new tests to trigger them. These tests would improve both con.dence \nin the semantics as well as the test suite itself.  5.2 Exploratory Testing We have also tested our \nsemantics on programs gathered from around the web, including programs of our own design and from open \nsource compilers. Not counting the GCC tests, we include over 17,000 SLOC in our regression tests that \nare run when making changes to the semantics. These tests include a number of programs from the LCC [12] \nand CompCert [1] compilers. We also execute the C Reference Manual tests (also known as cq.c),6 which \ngo through Kernighan and Ritchie [17] and test each feature described in about 5,000 SLOC. When these \ntests are added to the GCC tests described above, it brings our rule-coverage to 98% (867/887 rules). \nWe can successfully execute Du. s Device [7], an unstructured switch statement where the cases are inside \nof a loop inside of the switch statement itself, as well as quines (programs whose output are precisely \ntheir source code), and a number of programs from the Obfuscated C Code Contest [21]. All of these test \nprograms, as well as our semantics, are available from our project webpage: http://c-semantics.googlecode.com/. \n6. Applications Formal Semantics is Useful! Here we describe applications of our formal semantics, which \nare in addition to the interpreter already mentioned. These tools are automatically derived from the \nsemantics changes made to the semantics immediately a.ect the tools. We are permitted this luxury because \nwe take advantage of general purpose tools available to RL theories, of which our semantics is one. Contrast \nthis to the nearly universal strategy of writing analysis tools independently of semantics. Instead of \ndeveloping a di.erent model for each tool, a plethora of tools can be created around a single semantic \nde.nition. These tools are essentially wrappers, or views, of the semantics. 6.1 Debugging By introducing \na special function __debug that acts as a break\u00adpoint, we can turn the Maude debugger into a simple debugger \nfor C programs. This provides the ability to step through interesting parts of execution to .nd out what \nrules of semantics are invoked in giving meaning to a program. In the semantics, we handle this function \nby giving a labeled rule that causes it to evaluate to a void value. It is essentially equivalent 6 We \nhave been unable to determine the author or origin of this test suite. Please contact us with any information. \nto void __debug(int i) { }. If this function is called during execution, it starts a debugger that allows \nthe user to inspect the current state of the program. One can step through more rules individually from \nthere, or simply note the information and proceed. If the __debug call is inside a loop, the user will \nsee a snapshot each time it reaches the expression. For example: int main(void){ for (int i = 0; i < \n10; i++){ __debug(i); } printf(\"done!\\n\"); } We can run or debug the program above as follows: $ kcc \ndebug.c $ ./a.out # run the program normally done! $ DEBUG=1 ./a.out # or run it in the debugger Debug(1)> \nwhere . (__debug(0 : int) \u00b7\u00b7\u00b7)k (\u00b7\u00b7\u00b7 i . L \u00b7\u00b7\u00b7)env \u00b7\u00b7\u00b7 Debug(1)> resume . (__debug(1 : int) \u00b7\u00b7\u00b7)k (\u00b7\u00b7\u00b7 \ni . L \u00b7\u00b7\u00b7)env \u00b7\u00b7\u00b7 The user can use this to see what the value of the __debug argument is each time through \nthe loop, as well as the entire state of the program when the breakpoint was reached. The state presented \nto the user includes all of the cells of the language (Figure 2). This elided state is represented by \nthe ellipses above. In addition to the where and resume commands, there is also a step command to step \nthrough the application of a single semantic rule [3, \u00a722.1].  6.2 Runtime Veri.cation There are two \nmain avenues through which we can catch and identify runtime problems with a program: catching unde.ned \nbehavior, and symbolic execution. 6.2.1 Unde.ned Behavior The .rst mechanism is based around the idea \nthat when something lacks semantics (i.e., when its behavior is unde.ned according to the standard) then \nthe evaluation of the program will simply stop when it reaches that point in the program. We use this \nmechanism to catch errors like signed over.ow or array out-of-bounds. In this small program, the programmer \nforgot to leave space for a string terminator ('\\0'). The call to strcpy() will read o. the end of the \narray: int main(void) { char dest[5], src[5] = \"hello\"; strcpy(dest, src); } GCC will happily execute \nthis, and depending on the state of memory, even do what one would expect. It is still unde.ned, and \nour semantics will detect trying to read past the end of the array. Because this program has no meaning, \nour semantics gets stuck when exploring its behavior. It is through this simple mechanism that we can \nidentify unde.ned programs and report them to the user. By default, when a program gets stuck, we report \nthe state of the con.guration (a concrete instance of that shown in Figure 2) and what exactly the semantics \nwas trying to do at the time of the problem. We have also begun to add explicit error messages for common \nproblems here is the output7 from our tool for this code: $ kcc buggy_strcpy.c ; ./a.out ERROR encountered \nwhile executing this program. Description: Reading outside the bounds of an object. Function: strcpy \nLine: 3 7 Here and elsewhere in this section, we take the liberty to slightly simplify the output to \nmake it .t in less vertical space.  6.2.2 Symbolic Execution Through the use of symbolic execution, \nwe can further enhance the above idea by expanding the behaviors that we consider unde\u00ad.ned, while maintaining \nthe good behaviors. Symbolic execution is straightforward to achieve using a rewriting-based semantics: \nwhether a term is concrete or abstract makes no di.erence to the theory. Rules designed to work with \nconcrete terms do not need to be changed in order to work with symbolic terms. As we explained in Section \n4.3, we treat pointers not as concrete integers, but as symbolic values. These values then have certain \nbehavior de.ned on them, such as comparison, di.erence, etc. This technique is based on the idea of strong \nmemory safety, which had previously been explored with a simple C-like language [30]. In this context, \nit takes advantage of the fact that addresses of local variables and memory returned from allocation \nfunctions like malloc() are unspeci.ed [15, \u00a77.20.3]. However, there are a number of restrictions on \nmany addresses, such as the elements of an array being completely contiguous and the .elds in a struct \nbeing ordered (though not necessarily contiguous). For example, take the following program: int main(void) \n{ int a, b; if (&#38;a < &#38;b) { ... } } If we gave objects concrete, numerical addresses, then they \nwould always be comparable. However, this piece of code is actually unde\u00ad.ned according to the standard \n[15, \u00a76.5.8:5]. Symbolic locations that are actually base/o.set pairs allow us to detect this program \nas problematic. We only give semantics to relational pointer com\u00adparisons where the two addresses share \na common base. Thus, eval\u00aduation gets stuck on the program above: $ kcc bad_comparison.c ; ./a.out ERROR \nencountered while executing this program. Description: Cannot apply '<' to different base objects. Function: \nmain Line: 3 Of course, sometimes locations are comparable. If we take the following code instead: int \nmain(void) { struct { int a; int b; } s; if (&#38;s.a < &#38;s.b) { ... } } the addresses of a and b \nare guaranteed to be in order [15, \u00a76.5.8:5], and in fact our semantics .nds the comparison to be true \nbecause the pointers share a common base. Another example can be seen when copying a struct one byte \nat a time (as in a C implementation of memcpy()); every byte needs to be copied, even uninitialized .elds \n(or padding), and no error should occur [15, \u00a76.2.6.1:5 7]. Because of this, our semantics must give \nit meaning. Using concrete values here would mean missing some incorrect programs, so we use symbolic \nvalues that allow reading and copying to take place as long as the program never uses those uninitialized \nvalues in unde.ned ways.  6.3 State Space Search We can also use our semantics to do both matching-based \nstate search and explicit state model-checking with linear temporal logic (LTL). The basic examples below \nshow how our semantics captures the appropriate expression evaluation semantics precisely. 6.3.1 Exploring \nEvaluation Order To show our semantics captures the evaluation orders of C expres\u00adsions allowed by the \nspeci.cation, we examine some examples from related works. The results given below are not just theoretical \nresults from our semantics, but are actual results obtained from executing the tools provided by our \nsemantic framework. To start with a simple example from Papaspyrou and Ma\u00b4co [26], we take a look at \nx+(x=1) in an environment where x is 0. This expression is unde.ned because the read of x (the lone x) \nis unsequenced with respect to the write of x (the assignment). Using our semantics to do a search of \nthe behaviors of this expression .nds this unsequenced read/write pair, and reports an error. Norrish \n[22] o.ers the deceptively simple addition expression (x=0) + (x=0), which in many languages would be \nvalid. How\u00adever, in C it is again a technically unde.ned expression due to the unsequenced assignments \nto x. Our semantics reports an error for this expression as well. Another example in the literature is \ngiven by Papaspyrou [25], which shows how C can exhibit nondeterministic behavior while staying conforming. \nThe driving expression is the addition of two function calls. In C, function evaluation is not allowed \nto interleave [15, 6.5.2.2:10], so the behavior of this program is determined solely on which call happens \nlast: int r = 0; int f (int x) { return (r = x); } int main(void){ f(1) + f(2); return r; } If f() is \ncalled with the argument 2 last, then the result will be 2, and similarly for 1. Searching with our \nsemantics gives the behaviors {r=1} and {r=2}, which are indeed the two possible results. As a last example, \nwe look at a more complex expression of our own devising: f()(a(b(), c(d()))). Except for f(), each function \ncall prints out its name and returns 0. The function f(), however, prints out its name and then returns \na function pointer to a function that prints e . The function represented by this function pointer will \nbe passed results of a(). We elide the actual function bodies, because the behavior is more easily understood \nby this tree:  This tree (or Hasse diagram) describes the sequencing relation for this expression. That \nis, it must be the case that d happens before c, that b and c happen before a, and that f and a happen \nbefore e. Running this example through our search tool gives precisely the behaviors allowed by the standard: \n$ kcc nondet.c ; SEARCH=1 ./a.out 15 solutions found bdcafe bdcfae bdfcae bfdcae dbcafe dbcfae dbfcae \ndcbafe dcbfae dcfbae dfbcae dfcbae fbdcae fdbcae fdcbae  6.3.2 Model Checking In addition to the simple \nstate search we showed above, one can also use our semantics for LTL model checking. For example, consider \nthe following program: typedef enum {green, yellow, red} state; state lightNS = green; state lightEW \n= red; int changeNS() { switch (lightNS) { case(green): lightNS = yellow; return 0; case(yellow): lightNS \n= red; return 0; case(red): if (lightEW == red) { lightNS = green; } return 0; } } ... int main(void) \n{ while(1) { changeNS() + changeEW(); } } This program is meant to represent two orthogonal tra.c lights \n(lightNS and lightEW) at the same intersection. It provides an implementation of an algorithm to change \nthe state of the lights from green to yellow to red and back. We elide the nearly identical changeEW() \nfunction. The program takes advantage of the unspeci.ed order of evaluation of addition in the expression \nchangeNS() + changeEW() to nondeterministically choose the order in which the lights are changed.  There \nare a number of properties one might like to prove about this program, including safety and liveness \nproperties. One safety property is that it should always be the case that at least one of the lights \nis red, or D((lightNS == red) . (lightEW == red)). We have added a special #pragma8 allowing the programmer \nto write and name LTL formulae. If we call the above formula safety , then we can invoke the model checker \nas follows: $ kcc lights.c ; MODELCHECK=safety ./a.out result Bool: true Similarly, it is important that \nthe lights always make progress, i.e., that it is always the case the lights will eventually become green. \nIf we try to check D<(lightNS == green), we .nd that it does not hold of the above program: $ kcc lights.c \n; MODELCHECK=progress ./a.out result ModelCheckResult: counterexample ... The reason this property is \nnot veri.ed is that the algorithm is wrong! Because the calls to changeNS() and changeEW() can occur \nin any order, it is possible for either of the lights to get stuck on red. The program starts with ns=gre, \new=red. Consider the following execution: changeNS, changeEW => ns=yel, ew=red changeEW, changeNS => \nns=red, ew=red changeNS, changeEW => ns=gre, ew=red By alternating evaluation orders, the program can \nchange the N/S light without ever changing the E/W light. This evaluation order is highly implausable \nin most C compilers, but the se\u00admantics allows it. If we .x an evaluation order by changing changeNS() \n+ changeEW(); to changeNS(); changeEW();, then the property holds: $ kcc lights.c ; MODELCHECK=progress \n./a.out result Bool: true 7. Limitations and Future Work Here we delineate the limitations of our de.nition \nand explain their causes and e.ects. There are two main ways in which semantics can be incomplete under-de.nedness \nand over-de.nedness. Typically when one thinks of incompleteness, one thinks of failure to give meaning \nto correct programs. However, because we want to be able to identify incorrect or unportable programs, \nthe semantics must be balanced appropri\u00adately between de.ning too much or too little. It is equally important \nnot to give semantics to programs that should be unde.ned. In the .rst case, we are not missing any features \nwe have given semantics to every feature required of a freestanding implementation of C. With this said, \nour semantics is not perfect. For example, we still are not passing 100% of our test cases (see Section \n5). Also, our semantics of .oating point numbers is particularly weak. During execution or analysis, \nwe simply rely on an IEEE-754 implementation of .oating point arithmetic provided to us by our de.nitional \nframework (K). This is .ne for interpretation and explicit state model checking, but not for deductive \nreasoning. In the second case, although our semantics can catch many bad behaviors other tools cannot \n(e.g., we have not found any other tool that catches the unde.ned programs in Sections 6.2.2 or 6.3.1), \n8 A conforming way to add implementation-de.ned behavior to C. there is still room for improvement. For \none, our semantics aligns all types to one-byte boundaries. This means we cannot catch unde.ned behavior \nrelated to alignment restrictions. Note that others have worked on formalizing alignment requirements \n[20], but it has never been incorporated into a full semantics for C. We also do not handle type quali.ers \n(like const or volatile); we simply ignore them. This is safe to do when interpreting correct programs, \nbut it means we are not detecting problems related to those features in incorrect programs. It also means \nthat we are missing possible behaviors when searching programs that use volatile. We have not yet used \nour C de.nition for doing language or program level proofs, even though the KFramework supports both \nprogram level [31] and semantics level proofs [8]. To do so, we need to extend our semantics with support \nfor formal annotations (e.g., assume, assert, invariant) and connect it to a theorem prover. This is \nalready being done for a subset of the C language [29], and we intend to apply those techniques to actual \nC in the future. We still do not cover all of the standard library headers. So far, we have added library \nfunctions by need in order to run example programs, which is why we have semantics for library functions \nlike malloc(), longjmp(), parts of printf(), variadic functions, and over 30 others. We intend on covering \nmore libraries in the future, but for now, one could supplement what we provide by using implementations \nof libraries written in C. In our current semantics, only some of the implementation\u00adde.ned behaviors \nare available the most common ones. By mak\u00ading the semantics parametric, we hope others can add or change \nimplementation-de.ned rules to suit their needs. Finally, we should mention the speed of our system. \nWhile it is not nearly as fast as C compiled natively, it is usable. Of the GCC torture test programs \ndescribed listed in Section 5, our semantics ran over 93% of these programs in under 10 seconds (each). \nAn additional 4% completed in 2 minutes, 2% in 5 hours, and 1% further in under 3 days. In comparison, \nit takes GCC about 0.05s for each test. The reader should keep in mind that this is an interpreter obtained \nfor free from a formal semantics. In addition, the search and model checking tools su.er the same state \nexplosion problems inherent in all explicit-state model checking. 8. Conclusion It is a shame that, despite \nthe best e.orts of over 40 years of re\u00adsearch in formal programming languages, most language design\u00aders \nstill consider the di.culties of de.ning formal semantics to outweigh the bene.ts. Formal semantics and \npracticality are not typically considered together. When C was being standardized, the standards committee \nexplored using formal semantics, but in the end decided to use simple prose because, Anything more ambitious \nwas considered to be likely to delay the Standard, and to make it less accessible to its audience [14, \n\u00a76]. This is a common sentiment in the programming language community. Indeed, startlingly few real languages \nhave ever been completely formalized, and even fewer were designed with formal speci.cation in mind. \nBased on our experience with our semantics, the development of a formal semantics for C could have taken \nplace alongside the development of the standard. Within roughly 6 person-months, we had a working version \nof our semantics that covered more of the standard than any previous semantics. The version presented \nin this paper is the result of 18 person-months of work. To put this in perspective, one member of the \nstandards committee estimated that it took roughly 62 person-years to produce the C99 standard [16]. \nWe are not claiming that we have done the same job in a fraction of the time; obviously writing a semantics \nbased on the standard is quite di.erent than writing the standard itself. We are simply saying that the \ne.ort it takes to develop a rewriting-based semantics is quite small compared to the e.ort it took to \ndevelop the standard.  The reluctance of the language community towards formal methods has not been \nwithout reason it is not always clear that having a formal semantics earns the designer anything tangible \nfor her e.ort. Commonly mentioned bene.ts like improving the understanding of the language or providing \na model in which sound arguments about the language can be made are relatively intangible; to be accepted \nby the general language community, semantics needs to be shown to have concrete value beyond that of \nprose. The time has come to start building analysis tools directly on for\u00admal models. Instead of building \nanalysis tools for di.erent languages and di.erent versions of each language, the analysis infrastructure \nsurrounding the semantics could be maintained independently so that one could derive tools for multiple \nlanguages simply by swap\u00adping out the semantic rules. We o.er our work as one small step in this direction; \nwe are not alone, and there are other tools including pluggable analysis architectures like Frama-C [6] \nand formal tools like CompCert [1] that share part of this vision. Our semantics and its automatically \ngenerated tools have already found one serious application. Csmith [35] is a C program test generator \nthat generates random conforming programs from a large, expressive subset of the C language. These tests \nare then used to perform di.erential testing among C compilers to .nd compilation bugs. To date, the \nCsmith team has found more than 325 bugs in common compilers like GCC and Clang. The programs Csmith \ngenerates are almost always too large (many between 1,000 and 10,000 SLOC) to submit as bug reports and \nneed to be reduced. The reduction process is semi-automatic, but is riddled with the possibility of introducing \nunde.ned behavior. Until now, these tests would have to be carefully examined by hand for unde.ned behavior, \nbecause any such behavior would render the tests invalid. Our semantic tools are being used by the Csmith \nteam to detect this unde.ned behavior and have allowed them to more completely automate the process and \nreduce the tests more aggressively. References [1] S. Blazy and X. Leroy. Mechanized semantics for the \nClight subset of the C language. J. Automated Reasoning, 43(3):263 288, 2009. [2] R. S. Boyer and J. \nS. Moore. A Computational Logic Handbook. Academic Press, second edition, 1998. [3] M. Clavel, F. Dur\u00e1n, \nS. Eker, J. Meseguer, P. Lincoln, N. Mart\u00ed-Oliet, and C. Talcott. All About Maude, A High-Performance \nLogical Framework, volume 4350 of LNCS. Springer, 2007. [4] J. V. Cook and S. Subramanian. A formal semantics \nfor C in Nqthm. Technical Report 517D, Trusted Information Systems, November 1994. [5] J. V. Cook, E. \nL. Cohen, and T. S. Redmond. A formal denotational semantics for C. Technical Report 409D, Trusted Information \nSystems, September 1994. [6] P. Cuoq, J. Signoles, P. Baudin, R. Bonichon, G. Canet, L. Correnson, B. \nMonate, V. Prevosto, and A. Puccetti. Experience report: OCaml for an industrial-strength static analysis \nframework. SIGPLAN Not., 44: 281 286, August 2009. [7] T. Du.. On Du. s device, 1988. URL http://www.lysator.liu. \nse/c/duffs-device.html. Msg. to the comp.lang.c Usenet group. [8] C. Ellison, T. F. S, erb.,.,u. A rewriting \nlogic approach anuta, and G. Rosto type inference. In 19th Intl. Wkshp. on Algebraic Development Techniques \n(WADT 08), volume 5486 of LNCS, pages 135 151, 2009. [9] FSF. GNU compiler collection, 2010. URL http://gcc.gnu.org. \n[10] FSF. C language testsuites: C-torture version 4.4.2, 2010. URL http://gcc.gnu.org/onlinedocs/gccint/C-Tests.html. \n[11] Y. Gurevich and J. K. Huggins. The semantics of the C programming language. In Computer Science \nLogic, volume 702 of LNCS, pages 274 308, 1993. [12] D. R. Hanson and C. W. Fraser. A Retargetable C \nCompiler: Design and Implementation. Addison-Wesley, 1995. [13] ISO/IEC JTC 1, SC 22, WG 14. ISO/IEC \n9899:1999: Programming languages C. Technical Report n1256, Intl. Organization for Stan\u00addardization, \nDecember 1999. [14] ISO/IEC JTC 1, SC 22, WG 14. Rationale for international standard programming languages \nC. Technical Report 5.10, Intl. Organization for Standardization, April 2003. [15] ISO/IEC JTC 1, SC \n22, WG 14. ISO/IEC 9899:201x: Programming languages C. Technical Report n1570, Intl. Organization for \nStan\u00addardization, August 2011. [16] D. M. Jones. The New C Standard: An Economic and Cultural Commentary. \nSelf-published, December 2008. URL http://www. knosof.co.uk/cbook/cbook.html. [17] B. W. Kernighan and \nD. M. Ritchie. The C Programming Language. Prentice Hall, second edition, 1988. [18] J. Meseguer. Conditional \nrewriting logic as a uni.ed model of concurrency. Theoretical Computer Science, 96(1):73 155, 1992. [19] \nG. C. Necula, S. McPeak, S. P. Rahul, and W. Weimer. CIL: Intermedi\u00adate language and tools for analysis \nand transformation of C programs. In Intl. Conf. on Compiler Construction, pages 213 228, 2002. [20] \nM. Nita, D. Grossman, and C. Chambers. A theory of platform\u00addependent low-level software. In 35th ACM \nSymposium on Principles of Programming Languages (POPL 08), 2008. [21] L. C. Noll, S. Cooper, P. Seebach, \nand L. A. Broukhis. The international obfuscated C code contest, 2010. URL http://www.ioccc.org/. [22] \nM. Norrish. C formalised in HOL. Technical Report UCAM-CL-TR\u00ad453, University of Cambridge, December 1998. \n[23] M. Norrish. A formal semantics for C++. Technical report, NICTA, 2008. URL http://nicta.com.au/people/norrishm/ \nattachments/bibliographies_and_papers/C-TR.pdf. [24] N. S. Papaspyrou. A Formal Semantics for the C Programming \nLanguage. PhD thesis, Natl. Technical University of Athens, 1998. [25] N. S. Papaspyrou. Denotational \nsemantics of ANSI C. Computer Standards and Interfaces, 23(3):169 185, 2001. [26] N. S. Papaspyrou and \nD. Ma\u00b4 co . A study of evaluation order semantics in expressions with side e.ects. J. Functional Programming, \n10(3): 227 244, 2000. [27] G. D. Plotkin. The origins of structural operational semantics. J. Logic and \nAlgebraic Programming, 60:60 61, 2004. [28] G.Ros,uandT.F. S,erb.,a.AnoverviewoftheKsemanticframework. \nanut. J. Logic and Algebraic Programming, 79(6):397 434, 2010. [29] G. Ros,u and A. S, tef.anescu. Matching \nlogic: A new program veri.cation approach (NIER track). In 30th Intl. Conf. on Software Engineering (ICSE \n11), pages 868 871, 2011. [30] G. Ros,u, W. Schulte, and T. F. S, erb.,a. Runtime veri.cation of C anut.memory \nsafety. In Runtime Veri.cation (RV 09), volume 5779 of LNCS, pages 132 152, 2009. [31] G. Ros,u, C. Ellison, \nand W. Schulte. Matching logic: An alternative to Hoare/Floyd logic. In 13th Intl. Conf. on Algebraic \nMethodology and Software Technology (AMAST 10), volume 6486 of LNCS, pages 142 162, 2010. [32] T. F. \nS, erb..,u. K-Maude: A rewriting based tool for anut,a and G. Rossemantics of programming languages. \nIn 8th Intl. Wkshp. on Rewriting Logic and its Applications (WRLA 09), volume 6381 of LNCS, pages 104 \n122, 2010. [33] S. Subramanian and J. V. Cook. Mechanical veri.cation of C programs. In ACM SIGSOFT Wkshp. \non Formal Methods in Software Practice, January 1996. [34] S. Summit. C programming FAQs: Frequently \nasked questions, 2005. URL http://www.c-faq.com/. [35] X. Yang, Y. Chen, E. Eide, and J. Regehr. Finding \nand understanding bugs in C compilers. In 32nd Conf. on Programming Language Design and Implementation \n(PLDI 11), pages 283 294, 2011. [36] W. Zimmermann and A. Dold. A framework for modeling the semantics \nof expression evaluation with abstract state machines. In Abstract State Machines, volume 2589 of LNCS, \npages 391 406, 2003.    \n\t\t\t", "proc_id": "2103656", "abstract": "<p>This paper describes an executable formal semantics of C. Being executable, the semantics has been thoroughly tested against the GCC torture test suite and successfully passes 99.2% of 776 test programs. It is the most complete and thoroughly tested formal definition of C to date. The semantics yields an interpreter, debugger, state space search tool, and model checker \"for free\". The semantics is shown capable of automatically finding program errors, both statically and at runtime. It is also used to enumerate nondeterministic behavior.</p>", "authors": [{"name": "Chucky Ellison", "author_profile_id": "81442594500", "affiliation": "University of Illinois, Urbana, IL, USA", "person_id": "P2991302", "email_address": "celliso2@illinois.edu", "orcid_id": ""}, {"name": "Grigore Rosu", "author_profile_id": "81100069676", "affiliation": "University of Illinois, Urbana, IL, USA", "person_id": "P2991303", "email_address": "grosu@illinois.edu", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103719", "year": "2012", "article_id": "2103719", "conference": "POPL", "title": "An executable formal semantics of C with applications", "url": "http://dl.acm.org/citation.cfm?id=2103719"}