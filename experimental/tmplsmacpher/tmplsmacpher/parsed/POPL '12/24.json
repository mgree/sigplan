{"article_publication_date": "01-25-2012", "fulltext": "\n Run Your Research On the Effectiveness of Lightweight Mechanization Casey Klein1 John Clements2 Christos \nDimoulas3 Carl Eastlund3 Matthias Felleisen3 Matthew Flatt4 Jay A. McCarthy5 Jon Rafkind4 Sam Tobin-Hochstadt3 \nRobert Bruce Findler1 PLT 1Northwestern University, Evanston, IL 2California Polytechnic State University, \nSan Luis Obispo, CA 3Northeastern University, Boston, MA 4University of Utah, Salt Lake City, UT 5Brigham \nYoung University, Provo, UT Abstract Formal models serve in many roles in the programming language community. \nIn its primary role, a model communicates the idea of a language design; the architecture of a language \ntool; or the essence of a program analysis. No matter which role it plays, however, a faulty model doesn \nt serve its purpose. One way to eliminate .aws from a model is to write it down in a mechanized formal \nlanguage. It is then possible to state theorems about the model, to prove them, and to check the proofs. \nOver the past nine years, PLT has developed and explored a lightweight version of this approach, dubbed \nRedex. In a nutshell, Redex is a domain-speci.c language for semantic models that is embedded in the \nRacket programming language. The effort of creating a model in Redex is often no more burdensome than \ntypesetting it with LaTeX; the difference is that Redex comes with tools for the semantics engineering \nlife cycle. In this paper we report on a validation of this form of lightweight mechanization. The largest \npart of this validation concerns the for\u00admalization and exploration of nine ICFP 2009 papers in Redex, \nan effort that uncovered mistakes in all nine papers. The results suggest that Redex-based lightweight \nmodeling is effective and easy to integrate into the work .ow of a semantics engineer. This experience \nalso suggests lessons for the developers of other mech\u00adanization tools. Categories and Subject Descriptors \nD.3.1 [Programming Lan\u00adguages]: Formal De.nitions and Theory Semantics General Terms Design, Reliability, \nTheory Keywords Lightweight Semantics Engineering 1. The Role of Language Models Programming language \nresearchers use formal models to commu\u00adnicate ideas in a concise manner. Many of their models explain \na small piece of language design, perhaps a new linguistic construct or a new type system. Other models \nexpress the essence of a com\u00adpiler transformation, the software architecture of an IDE tool, or the workings \nof a program analysis. For decades researchers have Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 12, January 25 27, 2012, Philadelphia, PA, USA. Copyright \n&#38;#169; 2012 ACM 978-1-4503-1083-3/12/01. . . $10.00 used paper and pencil to develop these models. \nPaper-and-pencil models come with .aws, however. Since .awed models can lead to miscommunications, researchers \nstate and prove theorems about models, which forces them to debug the model. Some .aws nevertheless survive \nthis paper-only validation step, and others are introduced during typesetting. These mistakes be\u00adcome \nobstacles to communication. For example, Martin Henz from National University of Singapore recently shared \nwith one of this paper s authors his frustration with a historic paper (Plotkin 1975): The readability \nis not helped by the fact that there are lots of typos, e.g. page 134, Rule II 1: M = N should be M = \nM. The rule II 3 on page 136 is missing the subscript 1 above the bar. [personal communication, 6/4/2011] \n Once the reader understands a model, .xing such typos is straight\u00adforward. But during the initial struggle \nwith the paper, .awed rules may pose seemingly insurmountable obstacles to the reader. In con\u00adtrast, \nauthors who have spent months or years exploring the intrica\u00adcies of their model are prone to discount \nthe signi.cance of typos and small mistakes even if readers report extreme frustration. Over the past \ndecade, mechanized theorem proving has come into its own as one alternative to the paper-and-pencil approach \n(Ay\u00addemir et al. 2005). In this world, researchers program their models in formal languages, state theorems, \nand create machine\u00adchecked proofs. We consider this kind of theorem proving heavy\u00adweight, because it \nrequires more explicit details than programming. An alternative is to program models in functional languages \nsuch as Haskell: creating interpreters, typecheckers, etc. This ap\u00adproach provides important mechanical \nscrutiny, but the gap be\u00adtween the program and what appears in a paper s .gures tends to make the task \nlaborious and reduces the strength of the validation. With these considerations in mind, PLT has developed \nRe\u00addex (Matthews et al. 2004; Felleisen et al. 2010), an ex\u00adecutable domain-speci.c lan\u00adguage for mechanizing \nseman\u00adtic models. The philosophy of Redex is to treat semantic mod\u00adels as software artifacts just like \nplain software systems. As such, semantic models have a life cycle, and the life cycle idea  for semantic \nmodels is similar to the one of software systems. Using Redex a semantics engineer for\u00admulates the syntax \nand semantics of the model; creates test suites;  (define-language .c (e (e e ...) x (. (x ...) e) call/cc \n+ number) (x variable-not-otherwise-mentioned)) (define-extended-language .c/red .c (e .... (A e)) \n(v (. (x ...) e) call/cc + number) (E (v ... E e ...) hole)) Figure 1: .-calculus plus call/cc (define \nred (reduction-relation .c/red #:domain e (--> (in-hole E (A e)) e \"abort\") (--> (in-hole E (call/cc \nv)) (in-hole E (v (. (x) (A (in-hole E x))))) (fresh x) \"call/cc\") (--> (in-hole E ((. (x ..._1) e) v \n..._1)) (in-hole E (subst e (x v) ...)) \"\u00dfv\") (--> (in-hole E (+ number ...)) (in-hole E (S number ...)) \n\"+\"))) Figure 2: The .c reductions runs random tests on conjectures; uses graphical tools for visualiz\u00ading \nexamples and debugging; and automatically renders the model as a PDF snippet. It is our hypothesis that \nsmall Redex efforts quickly pay off for the working semantics engineer. To validate our hypothesis, we \nconducted two case studies, and this paper presents the results of these studies. The .rst shows how \nRedex helps test a language implementation with a language model. The second shows that the Redex methodology \napplies to a broad spectrum of contemporary research papers. Speci.cally, the authors encoded nine ICFP \n2009 papers in Redex; equipped the models with unit tests; translated formal and informal claims into \ntestable conjectures; and checked their validity. In the process, we found mistakes in all of the papers, \nincluding one whose essential result had been veri.ed in Coq. The next section reviews the Redex modeling \nlanguage and tool suite. From there, the paper covers ten case studies. Our experience suggests lessons \nfor the authors of semantic models as well as the designers of validation tools; we discuss these lessons \nin the paper s .nal sections, along with related work. 2. Welcome to Redex Semantics engineers use the \nRedex language to write down the grammar, reductions, and metafunctions for calculi or transition systems. \nThe language is a domain-speci.c language embedded in Racket. Redex programmers inherit the DrRacket \nIDE, a large standard library, and a large set of user-contributed libraries. The Redex toolkit covers \na variety of tasks related to executing seman\u00adtics de.nitions: a stepper for small-step operational semantics; \nin\u00adspectors for reduction graphs; a unit testing framework; a tool for randomized testing \u00e0 la QuickCheck \n(Claessen and Hughes 2000); and automatic typesetting support. From a linguistic perspective, Redex \nis a strict functional lan\u00adguage with a powerful pattern matcher and domain-speci.c con\u00adstructs supporting \noperational semantics. This section illustrates Redex with a model of the .-calculus, extended with call/cc. \n2.1 Grammars The left-hand side of .gure 1 shows the grammar of the language and the corresponding Redex \ncode. The latter binds the Racket\u00adlevel variable .c to a Redex language, a series of non-terminals and \nalternatives. In this case, there are two non-terminals, and . The  non-terminal has six alternatives. \nThe .rst, application expressions, uses an ellipsis to indicate repetition. In this case, the ellipsis \namounts to insisting that each application expression consist of at least one sub-expression. Similarly, \nthe third alterna\u00adtive uses an ellipsis to indicate that . expressions can bind an ar\u00adbitrary number \nof variables. The fourth and .fth alternatives are constants,  and , leaving   and , two other non\u00adterminals. \nThe non-terminal is built-in and matches arbi\u00adtrary Racket numbers. The production for  uses the special \nkey\u00adword variable-not-otherwise-mentioned. It matches any symbol except , , and  because they are used \nas termi\u00adnal symbols elsewhere in the grammar.  To give a reduction semantics to .c, we add an alternative \nto and de.ne two extra non-terminals. The right-hand side of .gure 1 shows both the mathematical extension \nand the Redex code.  The .rst position in a define-extended-language form names the new language and \nthe second names to the to-be\u00adextended language. Non-terminals appearing in the body of define\u00adextended-language \nreplace those of the same name in the old language, unless a .... appears, in which case the non-terminal \nis extended. In this case, we extend with the expression form , which we use to give a reduction semantics \nfor continuations.  The other non-terminals, v and E, for values and evaluation contexts, respectively, \nare used to formulate standard reduction rules. The de.nition of E uses hole, a pattern matching construct \nthat represents the hole in a context. Our running example uses two alternatives for evaluation contexts: \nthe .rst mandates a left-to-right order of evaluation by insisting that evaluation can only take place \nto the right of values; the second says that a context can be a hole.  2.2 Reduction Relations and Metafunctions \nFigure 2 contains the reductions for .c on the left and the corre\u00adsponding Redex source code on the right. \nA reduction relation is de.ned as a series of rules of the form (--> pat_1 pat_2) where any expression \nmatching pat_1 is transformed into pat_2. The #:domain keyword speci.es a contract, in this case declaring \nthat red relates terms matching the pattern e. With (in-hole E e) a Redex programmer speci.es a context \ndecomposition, , meaning the .rst rule aborts the computation by dropping the context around expressions. \nThe second rule of red rewrites  into an application of to a function that behaves like a continuation. \nThe (fresh x) annotation in the rule demands that the parameter of the new function does not appear anywhere \nelse in the rewritten expression. The left-hand side of the third rule uses ellipses with subscripts \n(..._1) to specify that the lengths of the two sequences must match, thus restricting the rule to applications \nwithout arity errors. The rule s right-hand side appeals to the metafunction subst, which Redex requires \nto be de.ned explicitly. The define-metafunction keyword de.nes a metafunction; the .rst two positions \nspecify a language and a contract, followed by the cases of the function, each enclosed in a pair of \nsquare brack\u00adets. The subst function recurs on a list of bindings, repeatedly ap\u00adplying a single-variable \nsubstitution function: (define-metafunction .c/red subst : e (x v) ... -> e [(subst e (x_1 v_1) (x_2 \nv_2) ...) (subst-1 x_1 v_1 (subst e (x_2 v_2) ...))] [(subst e) e]) The single-variable substitution \nfunction is de.ned as usual.1 The .nal rule appeals to a S metafunction. This metafunction exploits Redex \ns embedding in Racket: (define-metafunction .c/red S : number ... -> number [(S number ...) ,(foldr + \n0 (term (number ...)))]) The right-hand side begins with an unquote (written as a comma), meaning that \nit is evaluated in Racket, and the Racket expression is expected to return a term that is the result \nof the metafunction. In this case, the function exploits the representation of .c s numbers as Racket \nnumbers to compute their sum. The expression (term (number ...)) produces a list of the numbers supplied \nas argu\u00adments to S. In general, term behaves like quote, but also picks up the bindings of pattern variables \n(number in this case) and supports ellipses to indicate repetition. Finally, Redex provides apply-reduction-relation \nto ex\u00adperiment with reduction relations. It accepts a relation and a term and returns a list of all contractions \nof the term: > (apply-reduction-relation red (term (+ 1 (A (+ 2 3))))) ((+ 2 3))  2.3 Exploring Examples \nRedex provides visualization tools for exploring the behavior of examples. The traces function accepts \na reduction relation and a term and shows the entire reduction graph of the term. To demon\u00adstrate the \nvalue of these tools, we adjust our reduction system to model an unspeci.ed order of evaluation in the \nspirit of C:2 1 In this case, it is an exact copy of the example model s substitution function from the \nRedex website: http://redex.racket-lang.org/. 2 Scheme s unspeci.ed order of evaluation is more sophisticated \nthan C s, but Redex is up to the task (Matthews and Findler 2005; Sperber et al. 2007). (define-extended-language \nany-which-way-.c .c/red (E (e ... E e ...) hole)) This extension replaces the non-terminal entirely, \nallowing re\u00adductions to occur in any position inside an application expression. Next, we use extend-reduction-relation \nto replace the language of the reduction relation (without adding any reductions): (define any-which-way-red \n(extend-reduction-relation red any-which-way-.c)) That is, this extension merely re-interprets the existing \nrules with the new de.nition of . This extended language does not satisfy the Church-Rosser property, \nas a quick experiment with traces shows: > (traces any-which-way-red (term (+ 1 (call/cc (. (k) (+ (k \n2) (k 3))))))) Figure 3 displays a screenshot of the resulting window. Each box contains a term that \nthe original reduces to and the arrows are labeled with the reduction rule s name that connects the two \nterms. The arrows connected to the term underneath the mouse cursor are darkened to make them easier \nto pick out.  2.4 Randomized Testing Redex s randomized testing support follows QuickCheck. A pro\u00adgrammer \nwrites down a property with redex-check (Klein and Findler 2009) and Redex generates instances of the \nproperty in an attempt to falsify it. Speci.cally, (redex-check Gne) tests the boolean-valued expression \ne, interpreted as a predicate universally quanti.ed over n, by evaluating it at random terms generated \nfrom the non-terminal n of the grammar G. For example, we can test the property that every expression \nin .c is a value or reduces to another expression. To check whether an expression is a value, we use \nredex-match, which tests whether a particular term matches a given pattern; to check whether an expression \nreduces, we check whether apply-reduction\u00adrelation s result is non-empty: > (redex-check .c/red e (or \n(redex-match .c/red v (term e)) (cons? (apply-reduction-relation red (term e))))) counterexample found \nafter 9 attempts: S Of course, there are a number of stuck states and Redex quickly .nds a simple one, \nnamely a free variable. If we add an explicit reduction to error as a way to signal an error for a free \nvariable: (--> (in-hole E x) error \"free variable\") and then iteratively run the test above, .xing errors \nas they are discovered, redex-check eventually .nds all of the (known) stuck states in the model.  2.5 \nTypesetting Redex provides automatic typesetting support which transforms a language, reduction relation, \nmetafunction, or a term into PostScript or PDF to be included in a paper. Indeed, all of the typeset \nversions of elements of the .c model shown in this paper are generated automatically using Redex. This \nexample shows Redex s vanilla support for rendering a reduction relation:  The main difference between \nthis rendering of the reduction rela\u00adtion and the one shown on the left in .gure 2 is that the rules \nare oriented vertically instead of horizontally. Adjusting the orienta\u00adtion is a matter of passing a \n.ag to control the basic layout option. In addition, the substitution function is shown here using Redex \ns default typesetting for metafunctions, . Redex also provides hooks for tuning the rendering of calls \nto metafunc\u00adtion, which may be used to render substitution in the conventional style, . When a reduction \nrelation or a metafunction escapes to Racket, Redex renders the Racket code in a monospaced font but \nwith a pink background so it stands out: > (render-metafunction S) Redex programmers can then set hooks \nto adjust how such frag\u00adments are typeset. 3. Redex Models for Production Systems Redex can help language \ndesigners validate their implementations against their speci.cations with low cost. To demonstrate this \nthe\u00adsis, we conducted a case study using the model of delimited control by Flatt et al. (2007). Figure \n4 shows the model s complete internal syntax, including forms left out of the original paper s presentation. \nAt the time of the publication of that paper, the model s authors had implemented a Redex model,3 built \na thorough test suite, and mechanically generated their paper s .gures from the Redex de.\u00adnitions. They \ndid not, however, employ randomized testing; Redex had no built-in support for it at the time. This section \nexplains how we revisited that model to see if randomized testing could .nd more issues in a well-tested \nmodel. It did: we found mistakes in both the implementation and speci.cation of delimited control. 3.1 \nRandomized Testing in Redex The obvious use of randomized testing is to check a paper s claims. Flatt \net al. do not explicitly state any theorems, but all is not lost they do imply that the model is a faithful \nabstraction of the production Racket implementation. We can therefore test the claim that the implementation \nproduces the result predicted by the model: (redex-check delim-cont-grammar e (equal? (model-eval (term \ne)) (racket-eval (term e)))) In this claim, model-eval uses Redex to reduce its argument to a value \nand racket-eval evaluates the term via Racket. 3 Available online: http://www.cs.utah.edu/plt/delim-cont/ \n  Figure 4: The syntax of the delimited control model. Unlike in QuickCheck, where users specify test \ngenerators for the data types they de.ne, Redex derives naive test generators au\u00adtomatically from the \nlanguage s grammar. In this case, the derived generator has two immediate problems. First, Redex s grammar \nspeci.cations do not address variable binding. As a result, the gen\u00aderator often produces expressions \nwith free variables, which Racket statically rejects. Second, the non-terminal in .gure 4 includes non-surface \nsyntax such as that Racket programmers cannot write directly. Since our goal is not to prove a proposition \nbut to falsify it, we begin with simple solutions to these problems.  3.2 A Weak Attempt One possibility \nis to discard test expressions that contain free vari\u00adables and to avoid non-surface forms entirely: \n(redex-check delim-cont-grammar e (with-handlers ([free-var-exn? (. (_) #t)]) (equal? (model-eval (term \ne)) (racket-eval (term e)))) #:prepare drop-non-surface) ; drop-non-surface : expr -> expr (define (drop-non-surface \ne) --) This revision discards open expressions by catching unbound iden\u00adti.er errors with an exception \nhandler that reports the test as a suc\u00adcess. It eliminates uses of non-surface forms in the generated \nex\u00adpression by rewriting them using drop-non-surface, which re\u00adplaces non-surface expressions with one \nof their sub-expressions or a random constant if there are no sub-expressions. This approach is naive, \nbut it reveals three previously unknown errors, one in the portion of the semantics shown in the published \npaper and two in elided de.nitions: 1. The error visible in the paper s .gures4 is in the de.nition of \nevaluation contexts , reproduced in .gure 4. A prompt ex\u00adpression has three sub-expression: a tag used \nby the other control operators to identify the prompt, a body, and a handler expression that receives \nvalues thrown by ex\u00adpressions within the dynamic extent of the body. The expres\u00adsions should be evaluated \nfrom left to right, but the de.nition of lacks evaluation contexts corresponding to the .rst and third \n 4 See p. 174 of the 2007 ICFP proceedings. sub-expressions. For example, this omission causes evaluation \nof the following expression to get stuck: > (model-eval (% (+ 1 2) 3 (. (x) x))) stuck 2. The model de.nes \nfunction application with a rule like this one: (--> ((. (x ...) e) v ...) (subst* (x ...) (v ...) e) \n\"beta\") Unlike the corresponding rule in section 2.2, the ellipses have no subscripts. Thus, the rule \nalso applies to expressions with arity mismatches, e.g., . Reducing this expression with Redex raises \na meta-level error because the formal param\u00adeters and actual arguments cannot be paired. 3. The reduction \nrule for expressions may also raise a meta-level exception. The model s Redex encoding, which rep\u00adresents \nnumbers as Racket numbers and primitive operators like as Racket symbols, appeals to Racket s zero? \nfunction to re\u00adduce redexes. But the zero? function carries a con\u00adtract that restricts its application \nto numbers, making reduction of the expression , for example, raise a meta-error instead of producing \n.  3.3 Re.ning the Test Generator Despite our initial success, there is good reason to explore more \nsophisticated test generation strategies. To start, in one sample of 10,000 expressions produced by Redex \ns naive generator, only 1,220 contain no free variables, and only 599 of those are not val\u00adues. We can \navoid discarding so many tests by supplying a function close that replaces unbound variables with random \nbound ones or constants when none are bound: (redex-check delim-cont-grammar e (equal? (model-eval (term \ne)) (racket-eval (term e))) #:prepare (compose close drop-non-surface)) ; close : expr -> closed-expr \n(define (close e) --) For this particular model, though, we do not discover any new errors this way. \nRedex s test coverage tool suggests another improvement, how\u00adever. Executing one round of 10,000 random \ntests fails to exercise 20 of the 30 reduction rules even once. Three more rules, including the \u00dfv rule \nshown in section 3.2, .re only a few times each. To exercise these rules, the test generator must make \nseveral fortuitous choices. In the case of the \u00dfv rule, the generator must .rst choose to place an application \nexpression in a position that will ultimately be evaluated. Second, in the application s operator position, \nthe generator must construct an expression that evaluates to a function. Third, in the operand positions, \nthe generator must construct expressions that do not result in runtime errors or discard the continuation \ncontaining the application. Fourth, the generator must choose to construct the right number of operands. \nWe can encourage these choices by providing redex-check the hint that it should occasionally use the \nrules left-hand sides instead of the more general pattern e as its basis for test generation. The left-hand \nside of the \u00dfv rule, for example, directly addresses the second and fourth choices above. Many of the \npatterns in the rules left-hand sides, however, re\u00adfer to non-surface forms, and so we must .rst replace \nthe pass that removes non-surface expressions with one that transforms them into equivalent surface expressions. \nFor example, expressions equivalent to values can be constructed from  (prompt), , and . We implement \nthis transformation, as well as ones for the other non-surface forms for which it is possible (see section \n3.4), using a function transform-non-surface and supply it to redex-check, along with the hint to use \nthe delim\u00adcont-rules reduction relation. (redex-check delim-cont-grammar e (equal? (model-eval (term \ne)) (racket-eval (term e))) #:prepare (compose close transform-non-surface) #:source delim-cont-rules) \n; transform-non-surface : expr -> expr (define (transform-non-surface e) --) This technique .nds six \nmore previously unknown errors. Two of these six are mistakes in the model made available with the paper, \nthough they did not appear in the publication: 1. The model includes a semantics for continuation marks, \na feature for associating name-value pairs with continuation frames (Clements et al. 2001). The expression \nmarks the active continuation frame with key and value then applies the thunk . The expression collects \nall marks for key on frames up to the nearest enclos\u00ading prompt tagged with . The model s reduction rule \nfor appeals to a metafunction that traverses the delimited context to construct a list of its mark values. \nThis metafunction, however, lacks a case for contexts of the form , making mark collection unde.ned within \nthe dynamic extent of the test position of ex\u00adpressions. For example, evaluation of the following expression \nraises a meta-level error: (% 0 (call/cm 1 #t (. () (if (first (current-marks 1 0)) 2 3))) (. (x) x)) \n2. The model s de.nition of capture-avoiding substitution is wrong. To perform the substitution , the \nmodel takes care to rename  to a variable not free in , but it fails to avoid choosing or the free variables \nof . The remaining four errors are in the implementation of Racket (version 5.0.2). These errors eluded \na hand-crafted test suite and years of production use, but randomized testing .nds them quickly: 3. Continuation \nmarks are not represented directly on continua\u00adtion frames. Instead, a stack of marks is kept in parallel \nwith the stack that represents the continuation. Delimited continuations therefore capture parts of the \nmark stack, and different slices of the stack involve different base offsets. While restoring part of \na continuation to execute a  pre-/post-thunk, one of the offsets is installed incorrectly. The resulting \ncrash would only happen for a pre-/post-thunk that is captured in a continuation that is itself captured \nas an extension of a com\u00adposed continuation, possibly with a few more ingredients we have yet to identify. \n 4. This error is similar to the previous one. Like continuation marks,  frames are kept in a separate \nstack that is synchronized with the continuation stack. An offset connect\u00ading the two stacks is forced \nto an incorrect value when com\u00adposing continuations in certain cases. The mistake produces a crash only \nafter one more round of continuation capture and invocation. 5. Non-composable continuations store a \nprompt tag and, when they are invoked, the implementation checks that the current continuation includes \na prompt with the same tag. Composable continuations come without a tag. The two kinds of continua\u00adtions \nshare much of the implementation infrastructure, however, and this shared implementation incorrectly \nstores and checks prompt tags for composable continuations. 6. This error is similar to the previous \none. The implementation also performs a prompt-tag check after each the application of each  pre-thunk \nduring the process of apply\u00ading a non-composable continuation. For composable continu\u00adations, the implementations \nshould not perform such prompt\u00adtag checks, but once again, the shared implementation performs these checks \nfor both kinds of continuations. At the time of writing, we still do not fully understand the behavior \nof the test that discovered the .rst of these four errors, making the prospect of manually devising a \ntest like it appear dismal. Fortunately, the repair was clear from the resulting core dump. The implementation \ns hand-crafted test suite contains tests that get close to .nding these errors, but the suite s author \ndid not have the patience to construct tests of the necessary complexity. Patience aside, .nding these \nerrors seems to require a degree of uninhibited creativity that is dif.cult to achieve. Hanford (1970), \none of the .rst to apply randomized testing to the implementation of programming languages, observes \nabout his test generator for PL/1 dubbed syntax machine that [a]lthough as a writer of test cases, the \nsyntax machine is certainly unintelligent, it is also uninhibited. It can test a [language] processor \nwith many combinations that would not be thought of by a human test case writer.  3.4 Unwelcome Errors \nIn addition to these nine errors, we found many more which we would have preferred to avoid errors in \nthe speci.cation relating the model to its implementation and errors in the post-generation passes. We \nmention their discovery not as successes of randomized testing but as a reminder of its cost. Formalizing \nthe relationship between the model and its imple\u00admentation with enough precision to test it is a non-trivial \ntask. The primary challenge is to decide which non-surface expressions from .gure 4 are well-formed. \nFor example, the grammar includes con\u00adtinuation frames that contain two marks at a single key, but such \ncon.gurations should not occur. Developing a speci.cation that includes these invariants takes some effort. \nWe used randomized testing to .nd expressions where violations of unknown invariants yield different \nbehaviors in the model and implementation. There is no guarantee that this sort of randomized test-driven \ndevelopment results in a complete speci.cation, but we are satis.ed as long as the working draft avoids \nfalse positives in our tests. The source of most unwelcome errors was our implementation of the passes \nthat enforce well-formedness of non-surface expres\u00adsions, transform well-formed ones into surface expressions, \nand remove free variables. Together, these passes comprise 259 non\u00adcomment, non-whitespace lines of code. \n 4. An Empirical Study of ICFP Papers To improve our understanding of how lightweight metatheory mechanization \ncan help authors with their papers, we used Re\u00addex to explore nine papers from the ICFP 2009 proceedings. \nThe papers were chosen because we considered them suitable for mech\u00adanization in Redex, but some turned \nout to be challenges. The nine papers include two which had already been mecha\u00adnized. We chose two such \npapers not really expecting to .nd errors, but to see if we would learn something about Redex when imple\u00admenting \npapers that already had a signi.cant mechanized metathe\u00adory effort put into them. We found mistakes in \nall nine papers, with less effort in each case than exhibited in section 3. We explain most of the er\u00adrors \nwe found below, in the order in which the papers appear in the 2009 proceedings. We omit some uninteresting \nerrors com\u00admon to multiple systems (e.g., confusing the particular object\u00adlanguage variable x with the \nmeta-variable V that ranges over object-language variables). The authors of the papers we stud\u00adied have \ncon.rmed the errors described here. The Redex models are available online: www.eecs.northwestern.edu/~robby/ \nlightweight-metatheory/ 4.1 Safe functional reactive programming through dependent types by Neil Sculthorpe \nand Henrik Nilsson Sculthorpe and Nilsson (2009) de.ne a functional reactive pro\u00adgramming language embedded \nin Agda (Norell 2007). The embed\u00added language s dependent type system rules out domain-speci.c errors \nsuch as loops with immediate feedback and uses of uninitial\u00adized signals. Its operational semantics, \ngiven as an Agda function de.ning discrete evaluation steps, carries a machine-checked proof of type \nsafety since Agda accepts the function as total. The paper does not show the Agda de.nition; it instead \npresents the semantics in the usual inference rules notation for big-step semantics. Encoding the paper \ns formulation in Redex revealed one error, introduced in the manual translation of the Agda code to nearly \nthree full pages of .gures. Speci.cally, the conclusion of the f1-DSW-EV rule in the paper s .gure 6 \napplies to switch expressions; it should apply to dswitch expressions. This paper has since been revised \n(Sculthorpe 2011). 4.2 Causal commutative arrows and their optimization by Hai Liu, Eric Cheng, and \nPaul Hudak Liu et al. (2009) de.ne a class of recursive arrows that they call causal commutative arrows \n(CCA) and show how they can be compiled into a single imperative loop. Our focus was the portion of the \ntransformation that they describe formally, a procedure for computing an ef.cient normal form they call \ncausal commutative normal form (CCNF). The procedure takes the form of a normalization relation . that \nreduces expressions bottom-up using a relation . based on the standard arrow axioms (Hughes 2000). For \nexample, the normal\u00adization rule for sequential compositions e1 \u00bb e2 normalizes the sub-expressions, \nreduces the result, then normalizes the contrac\u00adtum. e1 . el e2 . el (e1 l \u00bb e2l ) . ee . el 12 e1 \u00bb \ne2 . el Using randomized testing to check whether . is indeed a func\u00adtion with the claimed domain and \ncodomain found two problems: 1. In addition to arrow constructors, the language on which . is de.ned \nincludes functions and pairs; consequently, some arrow\u00adtyped expression do not have arrow constructors \nat their roots. The proof in the paper s appendix mentions that such expres\u00adsions must .rst be \u00df-reduced, \nbut there are no corresponding steps in the . de.nition. 2. Reduction via the . relation creates arrows \nbuilt from the loopB combinator, de.ned in terms of the primitive CCA con\u00adstructors. To account for loopB \nexpressions, the . relation in\u00adcludes the following rule: f . f l loopB if l . ee . el loopB if . el \nFor some f, loopB i f l is already in normal form. In these cases there is no e such that loopB i fl \n. e, leaving the rule s second premise unsatis.able (and the implied procedure stuck). This paper has \nsince been revised (Liu et al. 2011).  4.3 Partial memoization of concurrency and communication by Lukasz \nZiarek, KC Sivaramakrishnan, and Suresh Jagannathan Ziarek et al. (2009) show how memoization can be \napplied in a concurrent language with synchronous message-passing primitives. To show that memoization \npreserves meaning, they de.ne two evaluators for a concurrent language, one that uses memoization and \none that does not. Encoding these systems in Redex exposed two mistakes: 1. The paper s theoretical result \nis a safety theorem guaranteeing that when memoized evaluation takes a state P to a state Pl, then non-memoized \nevaluation takes T [P] to T [Pl], where the meta-function T erases the extra structure used for memoiza\u00adtion. \nAs randomized testing quickly discovers, this theorem is false. It fails to exclude states in which the \nmemo table incor\u00adrectly predicts the behavior of some function. The correspon\u00addence appears to hold for \nexecutions beginning with the empty table (the important case), but the proof s inductive structure requires \na generalized claim about states with non-empty but well-formed tables. A proof typically gives this \ngeneralization explicitly, since well-formedness conditions for such accumu\u00adlated data structures tend \nto be complex. 2. The non-memoizing evaluator operates on program states P taken from the following \ngrammar, in which t ranges over thread identi.ers and e ranges over expressions:  P ::= P I P | t[e] \nBecause a state P contain sat least one thread, the following communication rule cannot apply in the \nabsence of a third thread: P = PlI t[E[send(l, v)]] I tl[El[recv(l)]] P -. PlI t[E[unit]] I tl[El[v]] \nThe same problem exists with the memoizing evaluator.  4.4 A concurrent ML library in Concurrent Haskell \nby Avik Chaudhuri Chaudhuri (2009) describes a way to implement the Concurrent ML primitives (Reppy 1999) \nin a language that supports only .rst\u00adorder message passing, such as Concurrent Haskell (Jones et al. \n1996). He builds an abstract machine that abstracts the message\u00adpassing model common to Concurrent Haskell \nand other concurrent systems and then shows how programs using the Concurrent ML primitives may be compiled \ninto terms in his abstract machine, while preserving safety, progress, and fairness. We encoded this \nabstract machine, source language, and com\u00adpiler in Redex. In addition to writing test cases by hand, \nwe used randomized testing to check a weak variant of the paper s correct\u00adness theorem. Randomized testing \ndid not produce any counterex\u00adamples to the theorem, but it did lead us to programs for which the abstract \nmachine consumes unbounded resources where proper Concurrent ML implementations would not. For example, \nconsider the following source expression, in which c is a fresh channel: select(in c, out c) This expression \npermanently blocks any thread that evaluates it because select cannot perform either communication. In \nCon\u00adcurrent ML, garbage collection reclaims this thread because no other thread can reach the channel; \nthe abstract machine, on the other hand, performs in.nitely many steps for this expression effectively \nbusy waiting for an event that cannot occur. This error also shows up in the released implementation \nof the Concurrent ML library for Concurrent Haskell based on the abstract machine.  4.5 Automatically \nRESTful web applications: marking modular serializable continuations by Jay McCarthy McCarthy (2009) \nextends a technique for implementing .rst\u00adclass continuations via continuation marks (Pettyjohn et al. \n2005), adding support for source programs that themselves use contin\u00aduation marks. Despite a pencil-and-paper \nproof of correctness, a combination of manual and randomized testing found .ve errors in the translation \ns speci.cation, as well as three errors in the seman\u00adtics of its source and target languages: 1. The \ntranslation consists of four mutually recursive functions: one for translating values and expressions \nthat would be values if not for a variable in some component, one for redexes, one for evaluation contexts, \nand a driver function that either defers to the values translation or decomposes the input and applies \nthe translations for redexes and evaluation contexts. This schema relies on a unique decomposition lemma \nthat turns out not to hold, due to four mistakes in the grammars for redexes and evaluation contexts. \n 2. The source and target languages are variants of A-normal form (Flanagan et al. 1993), but the translation \nof evaluation contexts inserts applications in a position that does not allow them. Adapting translation \nto preserve A-normal form seems to require abandoning the invariant that evaluation contexts trans\u00adlate \nto evaluation contexts rather than more general contexts, which the translation for continuation values \nassumes. In prac\u00adtice, there is no need to translate such values anyway, since they do not appear in \nthe source text of realistic programs. 3. In translated programs, call/cc produces a procedure that \ndis\u00adcards the current continuation using abort then calls a function resume for rebuilding the captured \ncontinuation from a data representation of its frames. A mistake in the de.nition of re\u00adsume, however, \ncauses it to leave some frames out of the rebuilt continuation. 4. The translation s handling of continuation \nmarks in the original program involves installing an additional mark on each frame. This mark holds a \ndata structure that records all of the other marks on the associated frame. To maintain this cumulative \nmark, the translated program .rst fetches its current value using c-w-i-c-m ( call with immediate continuation \nmark ), which has the following signature:  c-w-i-c-m: key (a -> \u00df) a -> \u00df This function examines the \nactive frame s marks and calls the provided function with the value associated with the given key or \nthe provided default value if there is no such mark. The trans\u00adlation s c-w-i-c-m call forgets the mandatory \nthird argument. 5. The translation lacks recursive calls for two of the three posi\u00adtions inside the (w-c-m \ne e e) form, used for installing con\u00adtinuation marks. 6. Instead of including an explicit form for dereferencing \nstore pointers, the source language semantics has two rules for each form that demands its operand. For \nexample, in addition to the usual \u00dfv rule, there is a rule that applies when the function position holds \na pointer s:  S/E[(s v)] -.SL S/E[e[x . v]] where S(s)=(. (x) e) But with the usual de.nition of store-lookup \n(the author s in\u00adtention), this strategy does not handle pointers to pointers to functions. 7. The source \nlanguage semantics lacks a rule like the following, for indirect continuation application. S/E[(s v)] \n-.SL S/El[v] where S(s)= ..El 8. The source and target languages provide a form (c-c-m e ...) for collecting \ncontinuation marks. This form is simi\u00adlar to the current-marks operator explained in section 3.3, but \nthere are two differences. First, c-c-m has no prompt-tag operand, since the source and target languages \ndo not provide delimited control. Second, c-c-m collects the marks for several keys at once. Its result \nshould be a list of lists, in which the inner lists contain the marks on each continuation frame; as \nde.ned in the semantics, however, the marks for the .nal frame become the list s tail instead of its \nlast element. 4.6 Control-.ow analysis of function calls and returns by abstract interpretation by Jan \nMidtgaard and Thomas P. Jensen Midtgaard and Jensen (2009) systematically derive a tail-call sen\u00adsitive \ncontrol-.ow analysis using abstract interpretation and then prove that their analysis is equivalent to \na CPS-based one from ear\u00adlier work. We discovered two problems with the paper: 1. The CPS transformation \ns domain contains expressions with constants, but there is no case in the transformation functions to \ndeal with the constants. This leads to a problem in lemma 5.1, which states that transforming a program \nto CPS and then transforming it back results in the original program. As stated, this lemma is only true \nfor programs that contain no constants. 2. The paper de.nes = to be the least equivalence relation on \nexpressions satisfying these two equations:  let x = t in s = s letx=t0t1ins = s and the analysis result \nincludes a mapping from representa\u00adtive elements of this equivalence class to the values that the corresponding \nexpressions have at runtime. This de.nition of = breaks the equivalence of the direct-style and CPS analysis \n(theorem 5.1). Speci.cally, the direct-style analysis imprecisely predicts that id2 might be returned \nby the term let W = fn N. (N N) in let id1 = fn x1. x1 in let id2 = fn x2. x2 in let J = (fn t. id2) \nid1 let d = (W W) in id2 but the CPS analysis correctly predicts that it never returns. The problem \nis, the equivalence relation equates the two oc\u00adcurrences of id2 in the above program but should not. \nThis paper has since been revised (Midtgaard and Jensen 2012).  4.7 Implementing .rst-class polymorphic \ndelimited continuations by a type-directed selective CPS-transform by Tiark Rompf, Ingo Maier, and Martin \nOdersky Rompf et al. (2009) describe an implementation of delimited con\u00adtinuations for Scala. They de.ne \na type system that distinguishes expressions with control effects, allowing continuations to be im\u00adplemented \nby a selective CPS transformation that leaves expres\u00adsions in direct style when they do not reify their \ncontinuations. As we discovered while encoding the system in Redex, the pa\u00adper merely sketches the typing \nand transformation rules. A modest Redex model can close the gap between a sketch and a consistent description, \nand our model uncovered a signi.cant omission in the paper s explanation. The de.nition of the transformation \nfunction [.] neglects necessary recursive calls on sub-expressions (e.g., on the operand of shift). We \ndid discover one inaccuracy not arising from the rules infor\u00admal nature. The transformation, which operates \non expressions in A-normal form, distinguishes two classes of non-tail calls that reify their continuations \nthose where the expression e following the call also rei.es its continuation (a behavior indicated in \ne s type) and those where e does not. In the latter case, the transformation has an optimization opportunity. \nIn an attempt to exploit the oppor\u00adtunity, the de.nition of [.] mistakenly dispatches on the type of \n[e]instead of the type of e, causing it to apply the optimization even when it is unsound.5 4.8 A Theory \nof typed coercions and its applications by Nikhil Swamy, Michael Hicks, and Gavin M. Bierman Swamy et \nal. (2009) de.ne a proof system for validating partic\u00adular program rewritings and give conditions under \nwhich various program-rewriting systems operate unambiguously. For all results except the ones on rewriting \nusing polymorphic coercions, they provide Coq proof scripts.6 We discovered two problems with an example \nin the section ex\u00adplaining polymorphic coercions. First, one instantiation of a poly\u00admorphic coercion \nis missing. Second, the example is based on the assumption that the rewriting process will leave one \nparticular ex\u00adpression alone when, in fact, it might be rewritten. 4.9 Complete and decidable type inference \nfor GADTs by Tom Schrijvers, Simon Peyton Jones, Martin Sulzmann, and Dimitrios Vytiniotis Schrijvers \net al. (2009) de.ne a type system for generalized alge\u00adbraic datatypes (GADTs), giving both a declarative \nspeci.cation and a sound and complete inference algorithm. Encoding the algo\u00adrithm in Redex uncovered \nthree .aws in the paper s de.nition: 1. The type system that Schrijvers et al. consider most natural \nfor GADTs is undecidable. Their key insight is that decidability can be recovered by designating sets \nof uni.cation variables called untouchables that may not be uni.ed to solve certain constraints. The \nrules for let expressions, typed-annotated let expressions, and individual case clauses introduce these \nvari\u00adables, which stand for unknown types. The third of these three rules, however, designates the wrong \nvariables as untouchable. 5 In an email exchange (Feb. 2, 2011 Mar. 3, 2011), the paper s lead author \nstated that they did not intend their model as a precise description. He also explained that they meant \nfor the [.] function to be applied by a driver function whose operation accounts for the absent recursive \ncalls. The paper does not mention this driver. This author also reported that the Scala implementation \ndoes not make the same optimization mistake as the transformation sketch. 6 Available online: http://research.microsoft.com/~nswamy/ \npapers/coercion-proofs.tgz 2. The rule for entire case expressions correctly insists that all of its \nclauses produce a result of the same type \u00df. But instead of assigning the entire case the type \u00df, the \nrule gives it the type a, a meta-variable that does not appear anywhere else in the rule though the notation \na does appear. 3. The constraint solving algorithm lacks a rule for arrow types.  \u00a7 Tests LOC Props \n  4.10 Our Effort 4.1 24 1196 1Our case studies required two 4.2 10 8495kinds of efforts. First, each \nin\u00ad4.3 32 1197 5vestigator had to understand his 4.4 55 1445 4assigned paper to a suf.cient 4.5 105 1548 \n3degree so that he could formu\u00ad4.6 148 1159 8late a paper-and-pencil model. 4.7 97 1223 5Second, the \ninvestigator had to 4.8 57 1335 3implement the model in Redex. 4.9 67 1143 1The adjacent table quanti.es \nthe Mean 66 1233 3.88 second kind of effort. Each row shows the number of lines of code, the number \nof test cases, and the number of properties tested for each of the models in the above subsections. On \nthe average, a model consists of 1,200 lines of code, including 66 tests and three or four claims. 5. \nLessons Learned Our experience suggests lessons for the authors of programming languages papers, for \nus as the developers of Redex, and for the developers of other validation tools. 5.1 Lessons for Authors \nRedex supports mechanization in a form that accommodates time\u00adpressed semantics engineers and still uncovers \ncommon errors. Although we do not have precise effort logs for the case study of section 4, we estimate \nthat encoding and testing each model required less time than understanding the content of the paper. \nAs our case studies show, lightweight mechanization reduces the number of mistakes in a model and thus \nincreases its value as a communication vehicle. Flaws aside, we would not have managed to understand \nthese papers without their models. Prose is too imprecise and frequently too brief to build more than \na super.cial understanding. For exam\u00adple, one of the authors of the present paper would have rated him\u00adself \nan expert reviewer for the paper in section 4.5, having seen the semantics for continuation marks many \ntimes and having worked with continuation-based web servers. Despite this preparation, he failed to understand \nthe paper s intuitive explanation of the system until he studied its formal model. In such cases, where \nthe reader primarily relies on the model for explanation, typos even ones obvious to experts in hindsight \ncan become signi.cant barriers to communication. Lightweight mechanization enables interactive exploration, \nex\u00adpanding the means with which authors and readers communicate. In the case of every paper, we found \nthat executing examples im\u00adproved our understanding even after we had already understood enough of the \nsystem to encode at least part of it in Redex. When we were unsure if we understood a de.nition or if \nits implications appeared problematic, we ran examples. Often the ones we choose would have been too \ntedious or too error-prone to work out by hand. Sometimes the experiment con.rmed our hypothesis; other \ntimes it revealed a mistake in our reasoning. Either way, the exercise im\u00adproved our understanding of \nthe system.  5.2 Lessons for Redex Our experience suggests that Redex is a mature technology but also \nhighlights gaps in its ecosystem. Redex offers little support for handling binding constructs in object \nlanguages. It provides a generic function for obtaining a fresh variable but no help in de.ning capture-avoiding \nsubstitution or a-equivalence. Three of the nine papers in section 4 require de.nitions of one these \nconcepts, and de.nitions of these concepts facilitate testing in two other papers and the model of section \n3. In one case (section 4.4), managing binding in Redex constituted a signi.cant portion of the overall \ntime spent studying the paper. Redex should bene.t from a mechanism for dealing with binding, starting \nfrom the recently studied approaches (Gabbay and Pitts 2002; Lakin 2010; Pottier 2005; Sewell et al. \n2010). Next, Redex lacks direct support for non-algorithmic relations such as the coercion-insertion \ntheory of Swamy et al. and the declarative typing rules of Schrijvers et al. When we modeled these systems, \nwe were forced to escape to Redex s host language or to adopt an elaborate encoding, which we would not \nexpect a ca\u00adsual Redex user to be comfortable with. Extending Redex with support for logic programming, \nas in Typol (Despeyroux 1984), Twelf (Pfenning and Sch\u00fcrmann 1999), aProlog (Cheney and Ur\u00adban 2004), \nor aML (Lakin 2010) should solve this problem. At present, Redex also provides no mechanism for specifying \nstructural congruence. This gap complicates the encoding of transi\u00adtion rules such as those Ziarek et \nal. and Chaudhuri de.ne on con\u00adcurrent programs. We hope to adapt Maude s (Clavel et al. 2003) associative-commutative \nmatching to Redex s notion of patterns. Finally, while is often a boon that Redex s random test case \ngen\u00aderators require little programmer intervention, sometimes they are not as effective as they could \nbe. The generator derived from the grammar in section 3, for example, requires substantial massaging \nto achieve high test coverage. This de.ciency is especially press\u00ading in the case of typed object languages, \nwhere the massaging code almost duplicates the speci.cation of the type system.7 The dynamic-monitoring \ntechnique behind Korat (Boyapati et al. 2002) may be effective in automatically constructing tests from \nthe orig\u00adinal speci.cation. Alternatively, aProlog s counterexample-search strategies (Cheney and Momigliano \n2007) are possibilities with the addition of more declarative support for binding speci.cations and inference \nrules.  5.3 Lessons for Developers of Other Tools Last but not least, our case study suggests several \nlessons that should apply to all validation tools, regardless of how much they differ from Redex. First, \nthe lessons for authors concern developers too, since au\u00adthors require tool support to apply the lessons. \nIn particular, sup\u00adport for execution enables interactive exploration, bene.ting au\u00adthors and readers \nalike. Second, tests complement proofs. We encountered .ve papers in which explicitly claimed theorems \nare false as stated. In three cases (section 4.2, section 4.6, and section 4.9), we could .x the problems; \nin the others (section 4.3 and section 4.5), we were unable to .nd and verify a .x in a modest time frame. \nIn every case, though, rudimentary testing discovered errors missed with pencil\u00adand-paper proofs. Indeed, \nwe claim that tests complement even machine-checked proofs. As one example, two of the POPLmark solutions \nthat con\u00adtain proofs of type soundness use call-by-name beta in violation of the speci.cation (Crary \nand Gacek, personal communication). We believe unit testing would quickly reveal this error. 7 See Klein \net al. (2010, section 7) for another example. aML aProlog K Ott Redex Ruler Execution . . . . . . Unit \nTests . . Automated Tests . . . Typesetting Binding Visualization . . . . . . . . . .  Figure 5: A comparison \nof lightweight semantics engineering tools Even better, one can sometimes test propositions that cannot \nbe validated via proof. Our experience with the model of Racket s de\u00adlimited control operators provides \none example, as no formalization currently exists of the more than 230,000 lines of C and assem\u00adbly in \nthe Racket implementation. Testing also removes another obstacle to proof, the requirement that we .rst \nstate the proposi\u00adtion of interest. Due to its exploratory nature, testing can inadver\u00adtently falsify \nunstated but desired propositions, e.g., that threads block without busy waiting (section 4.4). This \nis especially true for system-level and randomized testing. To some degree, the same is true of proving, \nbut testing seems to be more effective at covering a broad space of system behaviors. Many other validation \ntools pro\u00advide some level of support for executing examples without requir\u00ading an algorithm to be speci.ed \nseparately; aProlog and Isabelle go so far as to provide tools for automatically falsifying conjectures. \nThird, mechanized typesetting avoids many transcription errors. Given the apparent frequency with which \nwe observed typos in ICFP papers and their potential impact on communication, mechan\u00adically generating \n.gures from a source subjected to some form of mechanical scrutiny seems justi.ed. Ott (Sewell et al. \n2010) and Isabelle (Nipkow et al. 2011) already support this work.ow. Fourth, example visualization aids \ndebugging. We relied ex\u00adtensively on Redex s visualization features while investigating the .aws described \nin section 4, as well as the many more introduced by the manual process of translating .gures to Redex. \nThe features have been similarly useful in other efforts, e.g., the formalization of Typed Racket (Tobin-Hochstadt \nand Felleisen 2008, section 3.4). We conjecture that all validation tools would bene.t from visual\u00adization \ncomponents. 6. Related Work The closest form of related work would be other studies that at\u00adtempt to \nvalidate semantics engineering tools on published formal models, but we are unaware of any such studies. \nAccordingly, this section focuses on tools that could be used for such studies, large formal models that \nhave been subjected to lightweight forms of val\u00adidation, and studies of the validity of research results \nin general. Other tools. The development of Redex draws inspiration from Alloy (Jackson 2002), a system \ndesigned to provide software engi\u00adneers with a lightweight alternative to theorem proving. With Alloy, \nsoftware engineers build models of software systems and explore them with mechanical support. Redex seeks \nto provide a similar experience to semantics engineers. The Typol system for natural semantics supports \na range of tools, providing execution by compilation to Prolog (Despeyroux 1984), a debugger and mechanized \ntypesetting (Despeyroux 1988), and a bridge from lightweight to heavyweight validation (Terrasse 1995). \nThese features and more survive in Redex and other con\u00adtemporary tools. Figure 5 provides a comparison \nbetween Redex and other mod\u00adern lightweight semantics engineering tools. All of aML (Lakin 2010), aProlog \n(Cheney and Urban 2004), K (Rosu and Serbanuta 2010), Ott (Sewell et al. 2010), Redex, and Ruler (Dijkstra \nand Swierstra 2006) provide support for executing de.nitions, though in the case of Ott, the precise \nlevel of support depends on the particular proof assistant chosen as the backend. aProlog features an \nautomated testing tool similar to redex-check but based on bounded-exhaustive search rather than randomized \ntesting. Simi\u00adlarly, K can exploit s Maude s model checker to check predicates. K, Ott, Redex, and Ruler \nall support mechanized typesetting, but Redex s approach to .ne-tuning the output differs users write \nRacket code to transform Redex parse trees instead of annotating de.nitions with LaTeX snippets. aML, \naProlog, K, and Ott provide the sort of binding support Redex lacks. Only Redex provides a li\u00adbrary of \ndomain-speci.c constructs for unit-testing and interactive visualization, but K users can write jUnit \ntests. Thanks in part to the impetus of the POPLmark Challenge (Ay\u00addemir et al. 2005), semantics engineers \nincreasingly use proof as\u00adsistants (Nipkow et al. 2011; Norell 2007; Pfenning and Sch\u00fcrmann 1999; Slind \nand Norrish 2008; The Coq Development Team 2010) to validate semantic models. These tools have various \nlevels of sup\u00adport for executing examples, but none share Redex s beginning-to\u00adend support for the semantics \nengineering life cycle yet. Testing Language De.nitions. Several groups report success with testing techniques \nwhere proof systems fail. For example, Fox (2003), Hardin et al. (2006), Sarkar et al. (2009), and Fox \nand Myreen (2010) check that they have de.ned correct models of various assembly and machine languages \nby comparing their models answers to the answers produced by actual hardware or by off-the-shelf compilers. \nEllison and Rosu (2011) employ similar techniques for C using K. Some of their efforts exploit random\u00adized \ntesting. Klein et al. (2010) also use a randomized technique to compare a model of the Racket virtual \nmachine to the produc\u00adtion implementation. The formal model of the R6RS (Sperber et al. 2007) helped \ncatch bugs in the informal, prose speci.cation. Research Validity. This paper reveals mistakes in our \nown work and the work of our colleagues. While we did not discover any .aws that invalidate the essential \ncontributions of any of the pa\u00adpers we studied, others have done so. Dwyer et al. (2006) examine several \nbug-.nding systems and invalidate a number of published claims on lowering the search cost; their basic \ninsight is that fac\u00adtors outside the control of an investigator e.g., the search order for path-sensitive \nbug-.nding tools may heavily in.uence the perfor\u00admance of such tools. Similarly, Arcuri and Briand (2011) \nconduct a systematic review of the use of randomized algorithms in se\u00adlected software engineering venues \nin 2009 [and] show that ran\u00addomized algorithms are used in a signi.cant percentage of papers but that, \nin most cases, randomness is not properly accounted for. This casts doubts on the validity of most empirical \nresults assess\u00ading randomized algorithms . Further a.eld, studies concerning the quality of research \nresults are common in the biomedical commu\u00adnity. Young et al. (2008), for example, write that an empirical \neval\u00aduation of the 49 most-cited papers on the effectiveness of medical interventions, published in highly \nvisible journals in 1990 2004, showed that a quarter of the randomised trials and .ve of six non\u00adrandomised \nstudies had already been contradicted or found to have been exaggerated by 2005. 7. Conclusion Our validation \nproject con.rms the lightweight mechanization conjecture. Speci.cally it establishes Redex as an effective \ntool that can uncover mistakes in mathematical models of programming languages. The two case studies \ncontribute two different insights. With the survey of nine ICFP papers we validate the folklore claim \nthat all mathematical papers contain mistakes. Our conclu\u00adsion is not to blame the ICFP authors or reviewers \nfor these mis\u00adtakes but to suggest the routine use of lightweight tools to write such papers. Every mistake \nin a published model narrows the com\u00admunication channel between authors and readers; conversely, we can \nwiden this channel when we equip papers with executable lightweight models that readers can easily explore \ninteractively. With the case study of delimited continuations in production systems we illustrate how \nan implementor can bene.t from the designers lightweight model. Redex can help expose errors in an implementation, \neven a heavily-tested one, merely by testing the correspondence between it and a model. This aspect of \nsemantics engineering is overlooked and deserves more attention, especially for large languages that \nevolve over many years. Acknowledgments Thanks to Gavin Bierman, Avik Chaudhuri, Michael Hicks, Suresh \nJagannathan, Thomas Jensen, Hai Liu, Jan Midtgaard, Tiark Rompf, Neil Sculthorpe, and Dimitrios Vytiniotis \nfor patient and candid discussions of their work. Thanks also to Henrik Nilsson for helpful comments \non a draft of this paper. The authors gratefully acknowledge support for this research from the NSF, \nDARPA, and AFOSR. Bibliography Andrea Arcuri and Lionel C. Briand. A practical guide for using statistical \ntests to assess randomized algorithms in software engineering. In Proc. Intl. Conf. Soft. Eng. , pp. \n1 10, 2011. Brian E. Aydemir, Aaron Bohannon, Matthew Fairbairn, J. Nathan Foster, Benjamin C. Pierce, \nPeter Sewell, Dimitrios Vytiniotis, Geoffrey Wash\u00adburn, Stephanie Weirich, and Steve Zdancewic. Mechanized \nmetatheory for the masses: the POPLMark Challenge. In Proc. Intl. Conf. Theorem Proving in Higher Order \nLogics, Lecture Notes in Computer Science volume 3603, pp. 50 65, 2005. Chandrasekhar Boyapati, Sarfraz \nKhurshid, and Darko Marinov. Korat: automated testing based on Java predicates. In Proc. Intl. Symp. \nSoft. Testing and Analysis, pp. 123 133, 2002. Avik Chaudhuri. A concurrent ML library in Concurrent \nHaskell. In Proc. ACM Intl. Conf. Functional Programming, pp. 269 280, 2009. James Cheney and Alberto \nMomigliano. Mechanized metatheory model\u00adchecking. In Proc. Intl. Conf. Principles and Practice of Declarative \nProgramming, pp. 75 86, 2007. James Cheney and Christian Urban. aProlog: a logic programming lan\u00adguage \nwith names, binding, and a-equivalence. In Proc. Intl. Conf. Logic Programming, Lecture Notes in Computer \nScience volume 3132, pp. 269 283, 2004. Koen Claessen and John Hughes. QuickCheck: a lightweight tool \nfor ran\u00addom testing of Haskell programs. In Proc. ACM Intl. Conf. Functional Programming, pp. 268 279, \n2000. Manuel Clavel, Francisco Dur\u00e1n, Steven Eker, Patrick Lincoln, Narciso Mart\u00ed-Oliet, Jos\u00e9 Meseguer, \nand Carolyn Talcott. Maude 2.0 system. In Proc. Intl. Conf. Rewriting Techniques and Applications, Lecture \nNotes in Computer Science volume 2706, pp. 76 87, 2003. John Clements, Matthew Flatt, and Matthias Felleisen. \nModeling an alge\u00adbraic stepper. In Proc. Euro. Symp. Programming, pp. 320 334, 2001. Thierry Despeyroux. \nExecutable speci.cation of static semantics. In Proc. Intl. Symp. Semantics of Data Types, Lecture Notes \nin Computer Sci\u00adence volume 173, pp. 215 233, 1984. Thierry Despeyroux. Typol: a formalism to implement \nnatural semantics. INRIA, Research Report No. 94, 1988. Atze Dijkstra and S. Doaitse Swierstra. Ruler: \nprogramming Type rules. In Proc. Intl. Symp. Functional and Logic Programming, Lecture Notes in Computer \nScience volume 3945, pp. 30 46, 2006. Matthew B. Dwyer, Suzette Person, and Sebastian G. Elbaum. Controlling \nfactors in evaluating path-sensitive error detection techniques. In Proc. ACM Symp. Foundations of Soft. \nEng. , pp. 92 104, 2006. Chucky Ellison and Grigore Rosu. An Executable Formal Se\u00admantics of C with Applications. \nUniversity of Illinois, http://hdl.handle.net/2142/25816, 2011. Matthias Felleisen, Robert Bruce Findler, \nand Matthew Flatt. Semantics Engineering with PLT Redex. MIT Press, 2010. Cormac Flanagan, Amr Sabry, \nBruce F. Duba, and Matthias Felleisen. The essence of compiling with continuations. In Proc. ACM Intl. \nConf. Functional Programming, pp. 237 247, 1993. Matthew Flatt, Gang Yu, Robert Bruce Findler, and Matthias \nFelleisen. Adding delimited and composable control to a production programming environment. In Proc. \nACM Intl. Conf. Functional Programming, pp. 165 176, 2007. Anthony Fox. Formal speci.cation and veri.cation \nof ARM6. In Proc. Intl. Conf. Theorem Proving in Higher Order Logics, Lecture Notes in Computer Science \nvolume 2758, pp. 25 40, 2003. Anthony Fox and Magnus O. Myreen. A trustworthy monadic formaliza\u00adtion \nof the ARMv7 instruction set architecture . In Proc. Intl. Conf. In\u00adteractive Theorem Proving, Lecture \nNotes in Computer Science volume 6172, pp. 243 258, 2010. Murdoch J. Gabbay and Andrew M. Pitts. A new \napproach to abstract syntax with variable binding. Formal Aspects of Computing 13(3 5), pp. 341 363, \n2002. Kenneth V. Hanford. Automatic generation of test cases. IBM Systems Journal 9(4), pp. 244 257, \n1970. David S. Hardin, Eric W. Smith, and William D. Young. A robust machine code proof framework for \nhighly secure applications. In Proc. Intl. Wksp. ACL2 Theorem Prover and its Applications, pp. 11 20, \n2006. John Hughes. Generalizing monads to arrows. Science of Computer Pro\u00adgramming 37(1 3), pp. 67 111, \n2000. Daniel Jackson. Alloy: a lightweight object modelling notation. ACM Trans. Software Enginering \nand Methodology 11(2), pp. 256 290, 2002. Simon Peyton Jones, Andrew Gordon, and Sigbjorn Finne. Concurrent \nHaskell. In Proc. ACM Symp. Principles of Programming Languages, pp. 295 308, 1996. Casey Klein and Robert \nBruce Findler. Randomized testing in PLT Redex. In Proc. Scheme and Functional Programming, pp. 26 36, \n2009. Casey Klein, Matthew Flatt, and Robert Bruce Findler. The Racket vir\u00adtual machine and randomized \ntesting. 2010. http://plt.eecs. northwestern.edu/racket-machine/ Matthew R. Lakin. An Executable Meta-Language \nfor Inductive De.nitions with Binders. PhD dissertation, University of Cambridge, 2010. Hai Liu, Eric \nCheng, and Paul Hudak. Causal commutative arrows and their optimization. In Proc. ACM Intl. Conf. Functional \nProgramming, pp. 35 46, 2009. Hai Liu, Eric Cheng, and Paul Hudak. Causal commutative arrows. J. Functional \nProgramming 21(4-5), pp. 467 496, 2011. Jacob Matthews and Robert Bruce Findler. An operational semantics \nfor R5RS Scheme. In Proc. Scheme and Functional Programming, pp. 157 165, 2005. Jacob Matthews, Robert \nBruce Findler, Matthew Flatt, and Matthias Felleisen. A visual environment for developing context-sensitive \nterm rewriting systems. In Proc. Intl. Conf. Rewriting Techniques and Appli\u00adcations, Lecture Notes in \nComputer Science volume 3091, pp. 301 311, 2004. Jay McCarthy. Automatically RESTful web applications: \nmarking modu\u00adlar serializable continuations. In Proc. ACM Intl. Conf. Functional Pro\u00adgramming, pp. 299 \n309, 2009. Jan Midtgaard and Thomas P. Jensen. Control-.ow analysis of function calls and returns by \nabstract interpretation. In Proc. ACM Intl. Conf. Functional Programming, pp. 287 298, 2009. Jan Midtgaard \nand Thomas P. Jensen. Control-.ow analysis of function calls and returns by abstract interpretation. \nInformation and Computa\u00adtion, 2012. http://www.cs.au.dk/~jmi/ANF-CFA Tobias Nipkow, Lawrence C. Paulson, \nand Markus Wenzel. Isabelle/HOL A Proof Assistant for Higher-Order Logic. Springer Verlag, 2011. Ulf \nNorell. Towards a Practical Programming Language Based on Depen\u00addent Type Theory. PhD dissertation, Chalmers \nUniversity of Technol\u00adogy, 2007. Greg Pettyjohn, John Clements, Joe Marshall, Shriram Krishnamurthi, \nand Matthias Felleisen. Continuations from generalized stack inspection. In Proc. ACM Intl. Conf. Functional \nProgramming, pp. 216 227, 2005. Frank Pfenning and Carsten Sch\u00fcrmann. System description: Twelf a meta-logical \nframework for deductive systems. In Proc. Intl. Conf. Au\u00adtomated Deduction, pp. 202 206, 1999. Gordon \nD. Plotkin. Call-by-name, call-by-value, and the .-calculus. Theo\u00adretical Computer Science 1(2), pp. \n125 159, 1975. Fran\u00e7ois Pottier. An overview of Caml. In Proc. ACM SIGPLAN ML Wksp. , Electronic Notes \nin Theoretical Computer Science volume 148, pp. 27 52, 2005. John H. Reppy. Concurrent Programming in \nML. Cambridge University Press, 1999. Tiark Rompf, Ingo Maier, and Martin Odersky. Implementing .rst-class \npolymorphic delimited continuations by a type-directed selective CPS\u00adtransform. In Proc. ACM Intl. Conf. \nFunctional Programming, pp. 317 328, 2009. Grigore Rosu and Traian Florin Serbanuta. An Overview of the \nK Semantic Framework. J. Logic and Algebraic Programming 79(6), pp. 397 434, 2010. Susmit Sarkar, Peter \nSewell, Francesco Zappa Nardelli, Scott Owens, Tom Ridge, Thomas Braibant, Magnus O. Myreen, and Jade \nAlglave. The se\u00admantics of x86-CC multiprocessor machine code. In Proc. ACM Symp. Principles of Programming \nLanguages, pp. 379 391, 2009. Tom Schrijvers, Simon Peyton Jones, Martin Sulzmann, and Dimitrios Vytiniotis. \nComplete and decidable type inference for GADTs. In Proc. ACM Intl. Conf. Functional Programming, pp. \n341 352, 2009. Neil Sculthorpe. Towards Safe and Ef.cient Functional Reactive Program\u00adming. Ph.D. dissertation, \nUniversity of Nottingham, 2011. Neil Sculthorpe and Henrik Nilsson. Safe functional reactive programming \nthrough dependent types. In Proc. ACM Intl. Conf. Functional Program\u00adming, pp. 23 34, 2009. Peter Sewell, \nFrancesco Zappa Nardelli, Scott Owens, Gilles Peskine, Thomas Ridge, Susmit Sarkar, and Rok Strni a. \nOtt: effective tool sup\u00adport for the working semanticist. J. Functional Programming 20(1), pp. 71 122, \n2010. Konrad Slind and Michael Norrish. A brief overview of HOL4. In Proc. Intl. Conf. Theorem Proving \nin Higher Order Logics, Lecture Notes in Computer Science volume 5170, pp. 28 32, 2008. Michael Sperber, \nR. Kent Dybvig, Matthew Flatt, Anton van Straaten, Richard Kelsey, William Clinger, Jonathan Rees, Robert \nBruce Findler, and Jacob Matthews. Revised [6] report on the algorithmic language Scheme. Cambridge University \nPress, 2007. Nikhil Swamy, Michael Hicks, and Gavin M. Bierman. A Theory of typed coercions and its applications. \nIn Proc. ACM Intl. Conf. Functional Programming, pp. 329 340, 2009. Delphine Terrasse. Encoding natural \nsemantics in Coq. In Proc. Intl. Conf. Algebraic Methodology and Software Technology, Lecture Notes in \nComputer Science volume 936, pp. 230 244, 1995. The Coq Development Team. The Coq Proof Assistant Reference \nManual. Version 8.3, 2010. http://coq.inria.fr/ Sam Tobin-Hochstadt and Matthias Felleisen. The design \nand implementa\u00adtion of Typed Scheme. In Proc. ACM Symp. Principles of Programming Languages, pp. 395 \n406, 2008. Neal S. Young, John P.A. Ioannidis, and Omar Al-Ubaydli. Why Current Publication Practices \nMay Distort Science. PLoS Med 5(10), pp. 1418 1422, 2008. Lukasz Ziarek, KC Sivaramakrishnan, and Suresh \nJagannathan. Partial memoization of concurrency and communication. In Proc. ACM Intl. Conf. Functional \nProgramming, pp. 161 172, 2009.   \n\t\t\t", "proc_id": "2103656", "abstract": "<p>Formal models serve in many roles in the programming language community. In its primary role, a model communicates the idea of a language design; the architecture of a language tool; or the essence of a program analysis. No matter which role it plays, however, a faulty model doesn't serve its purpose.</p> <p>One way to eliminate flaws from a model is to write it down in a mechanized formal language. It is then possible to state theorems about the model, to prove them, and to check the proofs. Over the past nine years, PLT has developed and explored a lightweight version of this approach, dubbed Redex. In a nutshell, Redex is a domain-specific language for semantic models that is embedded in the Racket programming language. The effort of creating a model in Redex is often no more burdensome than typesetting it with LaTeX; the difference is that Redex comes with tools for the semantics engineering life cycle.</p>", "authors": [{"name": "Casey Klein", "author_profile_id": "81470648816", "affiliation": "Northwestern University &#38; PLT, Evanston, IL, USA", "person_id": "P2991397", "email_address": "clklein@eecs.northwestern.edu", "orcid_id": ""}, {"name": "John Clements", "author_profile_id": "81100279419", "affiliation": "California Polytechnic State University &#38; PLT, San Luis Obispo &#38; PLT, CA, USA", "person_id": "P2991399", "email_address": "clements@brinckerhoff.org", "orcid_id": ""}, {"name": "Christos Dimoulas", "author_profile_id": "81413601733", "affiliation": "Northeastern University &#38; PLT, Boston, MA, USA", "person_id": "P2991400", "email_address": "chrdimo@ccs.neu.edu", "orcid_id": ""}, {"name": "Carl Eastlund", "author_profile_id": "81413593126", "affiliation": "Northeastern University &#38; PLT, Boston, MA, USA", "person_id": "P2991401", "email_address": "cce@ccs.neu.edu", "orcid_id": ""}, {"name": "Matthias Felleisen", "author_profile_id": "81100323458", "affiliation": "Northeastern University &#38; PLT, Boston, MA, USA", "person_id": "P2991402", "email_address": "matthias@ccs.neu.edu", "orcid_id": ""}, {"name": "Matthew Flatt", "author_profile_id": "81100490544", "affiliation": "University of Utah &#38; PLT, Salt Lake City, UT, USA", "person_id": "P2991403", "email_address": "mflatt@cs.utah.edu", "orcid_id": ""}, {"name": "Jay A. McCarthy", "author_profile_id": "81329490606", "affiliation": "Brigham Young University &#38; PLT, Provo, UT, USA", "person_id": "P2991404", "email_address": "jay@cs.byu.edu", "orcid_id": ""}, {"name": "Jon Rafkind", "author_profile_id": "81435610641", "affiliation": "University of Utah &#38; PLT, Salt Lake City, UT, USA", "person_id": "P2991405", "email_address": "rafkind@cs.utah.edu", "orcid_id": ""}, {"name": "Sam Tobin-Hochstadt", "author_profile_id": "81319502825", "affiliation": "Northeastern University &#38; PLT, Boston, MA, USA", "person_id": "P2991406", "email_address": "samth@ccs.neu.edu", "orcid_id": ""}, {"name": "Robert Bruce Findler", "author_profile_id": "81100028925", "affiliation": "Northwestern University, Evanston, IL, USA", "person_id": "P2991398", "email_address": "robby@eecs.northwestern.edu ___amp___#38; PLT", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103691", "year": "2012", "article_id": "2103691", "conference": "POPL", "title": "Run your research: on the effectiveness of lightweight mechanization", "url": "http://dl.acm.org/citation.cfm?id=2103691"}