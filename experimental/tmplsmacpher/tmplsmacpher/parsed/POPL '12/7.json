{"article_publication_date": "01-25-2012", "fulltext": "\n Information Effects Roshan P. James Indiana University rpjames@indiana.edu Abstract Computation is \na physical process which, like all other physical processes, is fundamentally reversible. From the notion \nof type iso\u00admorphisms, we derive a typed, universal, and reversible computa\u00adtional model in which information \nis treated as a linear resource that can neither be duplicated nor erased. We use this model as a semantic \nfoundation for computation and show that the gap between conventional irreversible computation and logically \nre\u00adversible computation can be captured by a type-and-effect system. Our type-and-effect system is structured \nas an arrow metalanguage that exposes creation and erasure of information as explicit effect operations. \nIrreversible computations arise from interactions with an implicit information environment, thus making \nthem a derived notion, much like open systems in Physics. We sketch several appli\u00adcations which can bene.t \nfrom an explicit treatment of information effects, such as quantitative information-.ow security and \ndifferen\u00adtial privacy. Categories and Subject Descriptors D.3.1 [Formal De.nitions and Theory]; F.3.2 \n[Semantics of Programming Languages]; F.3.3 [Studies of Program Constructs]: Type structure General \nTerms Languages, Theory Keywords Arrows, Linear logic, Quantum computing, Reversible logic. 1. Introduction \nTuring hoped that his abstracted-paper-tape model was so simple, so transparent and well de.ned, that \nit would not depend on any assumptions about physics that could conceivably be falsi.ed, and therefore \nthat it could become the basis of an abstract theory of computation that was independent of the underlying \nphysics. He thought, as Feynman once put it, that he understood paper. But he was mistaken. Real, quantum-mechanical \npaper is wildly different from the abstract stuff that the Turing machine uses. The Turing machine is \nentirely classical, and does not allow for the possibility the paper might have different symbols written \non it in different universes, and that those might interfere with one another. [11, p.252] The above \nquote by David Deutsch, originally stated in the con\u00adtext of quantum computing, stems from the observation \nthat even Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n12, January 25 27, 2012, Philadelphia, PA, USA. Copyright c &#38;#169; 2012 ACM 978-1-4503-1083-3/12/01. \n. . $10.00 Amr Sabry Indiana University sabry@indiana.edu the most abstract models of computation embody \nsome laws of Physics. Indeed, conventional classical models of computation, in\u00adcluding boolean logic, \nthe Turing machine, and the .-calculus, are founded on primitives which correspond to irreversible physical \nprocesses. For example, a nand gate is an irreversible logical op\u00aderation in the sense that its inputs \ncannot generally be recovered from observing its output, and so is the operation of overriding a cell \non a Turing machine tape with a new symbol, and so is a \u00df\u00adreduction which typically erases or duplicates \nvalues in a way that is destructive and irreversible. Our main thesis is that by embodying irreversible \nphysical prim\u00aditives, conventional abstract models of computation have also inad\u00advertently included some \nimplicit computational effects, which we call information effects. As a consequence of this approach, \nmany applications in which information manipulation is computationally signi.cant are put beyond the \nreach of our conceptual model of computation. Such applications include quantitative information\u00ad.ow \nsecurity [42], differential privacy [14], energy-aware comput\u00ading [29, 48], VLSI design [30], and biochemical \nmodels of compu\u00adtation [9]. In more detail, in Physics, the fundamental laws describe pro\u00adcesses in closed \nsystems where every action is reversible. Open systems, which allow irreversible processes, are a derived \nnotion they can be considered as a subsystem of a closed system which treats the rest of the system as \na global environment. Pushing the analogy to computation, and as the remainder of the paper formal\u00adizes, \nan irreversible computation can therefore be considered as one that interacts with some global environment \nvia implicit com\u00adputational effects. Put differently, irreversible computational mod\u00adels like the .-calculus \nembody some implicit computational effects which, following the tradition of programming language research, \nwe .nd useful to expose and study as .rst-class entities. Structure and Main Results. We develop a pure \nreversible model of computation that, un\u00adlike many other models, does not pre-suppose an existing irre\u00adversible \nmodel. Our model is obtained from the type isomor\u00adphisms and categorical structures that underlie models \nof linear logic and quantum computing. Technically, the model treats in\u00adformation as a linear resource \nthat can neither be erased nor duplicated in a way that is reminiscent of forbidding contrac\u00adtion and \nweakening in linear logic and the no-cloning and no\u00addeleting theorems of quantum mechanics.1  We develop \nan arrow metalanguage that layers effects on top of the pure reversible model above using an arrow abstract \ntype [24]. These arrow effects consist of an explicit erase operation that can be used to discard values \nand an explicit create operation which can be used to introduce and duplicate  1 An embedding of our \nreversible programming model in Haskell along with several examples can be downloaded from http://www.cs.indiana. \nedu/~sabry/papers/Pi.hs.  values. This construction has the immediate bene.t that the information effects \nare exposed and tracked by the type system. We show how to translate a Turing-complete .rst-order func\u00adtional \nlanguage with loops to our reversible model. The transla\u00adtion exposes the implicit erasure and duplication \nof information in the source language as explicit computational effects. The translation and its associated \ncorrectness proof constitute the main technical contribution of the paper.  We establish connections \nto, and explore how, the explicit treat\u00adment of information effects can bene.t applications such as quantitative \ninformation-.ow security and differential privacy.  2. Logical Reversibility and Information We review \nthe notion of logical reversibility and its connection to information. 2.1 Reversible Logic Toffoli s \npioneering work on reversible models of computation [44] established the following fundamental theorem. \nTHEOREM 2.1 (Toffoli). For every .nite function f : boolm . booln there exists an invertible .nite function \nfR : boolr+m . boolr+m, with r = n, such that f(x1,...,xm)=(y1,...,yn) iff r . m+r-n R. f(x1,...,xm, \nfalse,..., false)=( ... ,y1,...,yn) The proof of the theorem is constructive. Intuitively, the function \nf is compiled to a reversible function fR which takes extra argu\u00adments and produces extra results. When \nthe extra arguments are each .xed to the constant value false and the extra results are ignored, the \nreversible function behaves exactly like the original function. For example, the function and : bool2 \n. bool can be compiled to the function to.oli : bool3 . bool3 which behaves as follows: to.oli(v1,v2,v3)= \nif (v1 and v2) then (v1,v2, not(v3)) else (v1,v2,v3) A quick examination of the truth table of the to.oli \nfunction shows that it is reversible. Moreover, we can check that: to.oli(v1,v2, false)= if (v1 and v2) \nthen (v1,v2, true) else (v1,v2, false) which con.rms that we can recover and if we ignore the .rst two \noutputs. Toffoli s fundamental theorem already includes some of the basic ingredients of our results. \nSpeci.cally, it establishes that: it is possible to base the computation of .nite functions on reversible \nfunctions;  irreversible functions are special cases of reversible functions which interact with a global \nheap (which supplies the .xed constant values) and a global garbage dump (which absorbs the undesired \nresults); and  it is possible to translate irreversible functions to reversible functions to expose \nthe heap and garbage.  In this context, our results can be seen as extending Toffoli s in the following \nways: Instead of working with truth tables, we work with a rich type structure and use (partial) bijections \nbetween the types;  We introduce term languages for irreversible and reversible computations and develop \na type-directed compositional trans\u00adlation;  We extend the entire framework to deal with in.nite functions, \ne.g., on the natural numbers.  We establish that the manipulations of the heap and the garbage constitute \ncomputational effects that can be tracked by the type system. 2.2 Thermodynamics of Computation and \nInformation Toffoli s work was performed in the context of the work of Lan\u00addauer [28] and Bennett [7] \nthat established the remarkable result, known as the Landauer principle, relating irreversible computa\u00adtions \nto increase in information uncertainty (entropy). DEFINITION 2.2 (Entropy of a variable). Let b be a \n(not neces\u00adsarily .nite) type whose values are labeled b1,b2 ,.... Let . be a random variable of type \nb that is equal to bi with probability pi. b The entropy of . is de.ned as - pi log pi. DEFINITION 2.3 \n(Output entropy of a function). Consider a func\u00adtion f : b1 . b2 where b2 is a (not necessarily .nite) \ntype whose values are labeled b12,b22,.... The output entropy of the function is b given by - qj log \nqj where qj indicates the probability of the output of the function to have value b2j . DEFINITION 2.4. \nWe say a function is information-preserving if its output entropy is equal to the entropy of its input. \nFor example, consider a variable . of type bool \u00d7 bool. The information content of this variable depends \non the probability distribution of the four possible bool \u00d7 bool values. If we have a computational situation \nin which the pair (false, false) could occur with probability 1/2, the pairs (false, true) and (true, \nfalse) can each occur with probability 1/4, and the pair (true, true) cannot occur, the information content \nof . would be: 1/2log2 + 1/4log4 + 1/4log4 + 0log0 which equals 1.5 bits of information. If, however, \nthe four possible pairs had an equal probability, the same formula would calculate the information content \nto be 2 bits, which is the maximal amount for a variable of type bool \u00d7 bool. The minimum entropy 0 corre\u00adsponds \nto a variable that happens to be constant with no uncertainty. Now consider the bool . bool function \nnot. Let pF and pT be the probabilities that the input is false or true respectively. The outputs occur \nwith the reverse probabilities, i.e., pT is the probability that the output is false and pF is the probability \nthat the output is true. Hence the output entropy of the function is -pF log pF - pT log pT which is \nthe same as the input entropy and the function is information-preserving. As another example, consider \nthe bool . bool function constT (x)= true which dis\u00adcards its input. The output of the function is always \ntrue with no uncertainty, which means that the output entropy is 0, and that the function is not information-preserving. \nAs a third example, con\u00adsider the function and and let the inputs occur with equal probabil\u00adities, i.e., \nlet the entropy of the input be 2. The output is false with probability 3/4 and true with probability \n1/4, which means that the output entropy is about 0.8 and the function is not information\u00adpreserving. \nAs a .nal example, consider the bool . bool \u00d7 bool function fanout (x)=(x, x) which duplicates its input. \nLet the input be false with probability pF and true be probability pT . The output is (false, false) \nwith probability pF and (true, true) with probability pT which means that the output entropy is the same \nas the input entropy and the function is information-preserving.  2.3 Logical Reversibility We are now \nready to formalize the connection between reversibility and entropy, once we de.ne logical reversibility \nof computations. DEFINITION 2.5 (Logical reversibility [49]). A function f : b1 . b2 is logically reversible \nif there exists an inverse function g : b2 . b1 such that for all values v1 . b1 and v2 . b2, we have: \nf(v1)= v2 iff g(v2)= v1.  The main proposition that motivates and justi.es our approach is that logically \nreversible functions are information-preserving. PROPOSITION 2.6. A function is logically reversible \niff it is infor\u00admation-preserving. Looking at the examples above, we argued that constT , and are not \ninformation-preserving and that not, fanout are information\u00adpreserving. As expected, neither constT nor \nand are logically re\u00adversible and not is logically reversible. The situation with fanout is however subtle \nand deserves some explanation. First, note that the de.nition of logical reversibility does not require \nthe functions to be total, and hence it is possible to de.ne a partial function fanin that is the logical \ninverse of fanout. The function fanin maps (false, false) to false, (true, true) to true and is unde.ned \noth\u00aderwise. Arguing that partial functions like fanin are information\u00adpreserving requires some care. \nLet the inputs to fanin occur with equal probabilities, i.e., let the entropy of the input be 2. Disre\u00adgarding \nthe partiality of fanin, one might reason that the output is false with probability 1/4 and true with \nprobability 1/4 and hence that the output entropy is 1 which contradicts the fact that fanin is logically \nreversible. The subtlety is that entropy is de.ned with re\u00adspect to observing some probabilistic event: \nan in.nite loop is not an event that can be observed and hence the entropy analysis, just like the de.nition \nof logical reversibility, only applies to the pairs of inputs and outputs on which the function is de.ned. \nIn the case of fanin this means that the only inputs that can be considered are (false, false) and (true, \ntrue) and in this case it is clear that the function is information-preserving as expected. Intermezzo. \nLinear logic [18] is often used as a framework for controlling resource use. Linearity however must not \nbe confused with the criterion of information preservation presented here. Con\u00adsider constT '(x)= if \nx then true else true which is exten\u00adsionally equivalent to the constant function constT (x)= true above. \nIn a linear type system that tracks the syntactic occurrences of variables, constT ' would be deemed \nacceptable because x is linearly used. However as shown above the function constT is not information-preserving. \nDespite this difference, there does however appear to be some deep connections between linear logic and \nthe physical notions of reversible and quantum computing. Indeed as Girard explains [18, pp. 6,17], linear \nlogic embodies a simple and radical change of viewpoint from other logics and this change has a physical \n.avor. 3. Bijections: . Building on the insights of Toffoli, we now turn our attention to de.ning a logically \nreversible language with a type structure and a term language. A natural starting point for such a language \nis the notion of type isomorphisms. In this section, we restrict ourselves to isomorphisms between .nite \ntypes and show that they naturally lead to a simple programming language which we call .. In addition \nto presenting the syntax, type system, and semantics of ., we establish that . is universal for reversible \ncombinational circuits. 3.1 Types The set of .nite types b is constructed using sums and products of \nthe primitive type 1. We have the following syntax for types and values: value types,b ::= 1 | b + b \n| b \u00d7 b values,v ::= () | left v | right v | (v, v) The type 1 has exactly one inhabitant called (). \nSums allow us to create values that we can distinguish using left and right constructors and pairs allow \nthe encoding of tuples. Thus we have the type judgements: f v1 : b1 f v2 : b2 f () : 1 f (v1,v2): b1 \n\u00d7 b2 f v : b1 f v : b2 f left v : b1 + b2 f right v : b1 + b2 Two types b1 and b2 are isomorphic if \nwe can construct a bijective map between their values. The set of sound and complete isomorphisms for \n.nite types is the congruence closure of the following primitive isomorphisms [15]: b1 + b2 . b2 + b1 \nb1 +(b2 + b3) . (b1 + b2)+ b3 1 \u00d7 b . b b1 \u00d7 b2 . b2 \u00d7 b1 b1 \u00d7 (b2 \u00d7 b3) . (b1 \u00d7 b2) \u00d7 b3 (b1 + b2) \u00d7 \nb3 . (b1 \u00d7 b3)+(b2 \u00d7 b3) These isomorphisms are already familiar to us from arithmetic or logic (reading \n1 as true, \u00d7 as conjunction, and + as disjunction). Note however that the isomorphisms do not include \nsome familiar logical tautologies, in particular: b \u00d7 b . b b1 +(b2 \u00d7 b3) . (b1 + b2) \u00d7 (b1 + b3) Even \nthough these identities are expected in propositional logic, they are not satis.ed in standard arithmetic \nnor in any logic that accounts for resources like linear logic.  3.2 Syntax and Semantics We turn the \nabove isomorphisms into a programming language by associating primitive operators corresponding to the \nleft-to-right and right-to-left reading of each isomorphism. We gather these operators into the table \nbelow: swap + : b1 + b2 . b2 + b1 : swap + assocl+ : b1 +(b2 + b3) . (b1 + b2)+ b3 : assocr + unite :1 \n\u00d7 b . b : uniti swap \u00d7 : b1 \u00d7 b2 . b2 \u00d7 b1 : swap \u00d7 assocl\u00d7 : b1 \u00d7 (b2 \u00d7 b3) . (b1 \u00d7 b2) \u00d7 b3 : assocr \n\u00d7 distrib :(b1 + b2) \u00d7 b3 . (b1 \u00d7 b3)+(b2 \u00d7 b3): factor Each line of this table is to be read as the \nde.nition of one or two operators. For example, the third line declares the two operators unite :1 \u00d7 \nb . b and uniti : b . 1 \u00d7 b. Each of the two cases of commutativity de.nes one operator that is its own \ninverse. Now that we have primitive operators we need some means of composing them. We construct the \ncomposition combinators out of the closure conditions for isomorphisms. Thus we have program constructs \nthat witness re.exivity id, symmetry sym, and transitivity 9, and two parallel composition combinators, \none for sums and one for pairs. c : b1 . b2 c1 : b1 . b2 c2 : b2 . b3 id : b . b sym c : b2 . b1 c1 9 \nc2 : b1 . b3 c1 : b1 . b3 c2 : b2 . b4 c1 : b1 . b3 c2 : b2 . b4 c1 + c2 : b1 + b2 . b3 + b4 c1 \u00d7 c2 \n: b1 \u00d7 b2 . b3 \u00d7 b4  DEFINITION 3.1. (Syntax of .) We collect our types, values, and combinators, to \nget the full language de.nition. value types,b ::= 1 | b + b | b \u00d7 b values,v ::= () | left v | right \nv | (v, v) comb. types,t ::= b . b iso ::= swap + | assocl+ | assocr + | unite | uniti | swap \u00d7 | assocl\u00d7 \n| assocr \u00d7 | distrib | factor comb., c ::= iso | id | sym c | c 9 c | c + c | c \u00d7 c By design, every \nprogram construct c : b1 . b2 has an adjoint c : b2 . b1 that works in the other direction. Given a \nprogram c : b1 . b2 in ., we can run it by supplying it with a value v1 : b1. The evaluation rules cv1 \n. v2 for the primitive isomorphisms are given below: + swap (left v) . right v + swap (right v) . left \nv assocl+ (left v1) . left (left v1) assocl+ (right (left v2)) . left (right v2) assocl+ (right (right \nv3)) . right v3 + assocr (left (left v1)) . left v1 + assocr (left (right v2)) . right (left v2) + assocr \n(right v3) . right (right v3) unite ((),v) . v uniti v . ((),v) \u00d7 swap (v1,v2) . (v2,v1) assocl\u00d7 (v1, \n(v2,v3)) . ((v1,v2),v3) \u00d7 assocr ((v1,v2),v3) . (v1, (v2,v3)) distrib (left v1,v3) . left (v1,v3) distrib \n(right v2,v3) . right (v2,v3) factor (left (v1,v3)) . (left v1,v3) factor (right (v2,v3)) . (right v2,v3) \nThe semantics of composition combinators is: c v1 . v2 c1 v1 . vc2 v . v2 id v . v (sym c) v1 . v2 (c1 \n9 c2) v1 . v2 c1 v1 . v2 c2 v1 . v2 (c1 + c2)(left v1) . left v2 (c1 + c2)(right v1) . right v2 c1 v1 \n. v3 c2 v2 . v4 (c1 \u00d7 c2)(v1,v2) . (v3,v4) The use of the sym constructor uses the adjoint to reverse \nthe program. We can now verify that the adjoint of each construct c is its inverse in the sense that \nthe evaluation of the adjoint maps the output of c to its input. This property is a strong version of \nlogical reversibility in which the inverse of a program is simply obtained by the adjoint operation. \nPROPOSITION 3.2 (Logical Reversibility). cv . v ' iff c v ' . v.  3.3 Expressiveness There are several \nuniversal primitives for conventional (irreversible) hardware circuits (for example, nand and fanout). \nIn the case of reversible hardware circuits, the canonical universal primitive is the to.oli gate (mentioned \nin Sec. 2.1) which we can express in . as shown below. Let us start with encoding booleans. The type \n1+1 is the type of booleans with left () representing true and right () representing false. Boolean negation \nnot is simply swap +. The Toffoli gate takes three boolean inputs: if the .rst two inputs are true then \nthe third bit is negated. Even though . lacks conditional expressions, they are expressible using the \ndistributivity laws as we demonstrate. Given any combinator c : b . b we can construct a combinator called \nifc : bool \u00d7 b . bool \u00d7 b in terms of c, where ifc behaves like a one-armed if -expression. If the supplied \nboolean is true then the combinator c is used to transform the value of type b. If the boolean is false, \nthen the value of type b remains unchanged. We can write down the combinator for ifc in terms of c as \ndistrib 9 ((id \u00d7 c)+ id) 9 factor. Let us look at the combinator pictorially as if it were a circuit \nand values are like particles that .ow through this circuit. The diagram below shows the input value \nof type (1 + 1) \u00d7 b processed by the distribute operator distrib, which converts it into a value of type \n(1 \u00d7 b) + (1 \u00d7 b). In the left branch, which corresponds to the case when the boolean is true (i.e. the \nvalue was left ()), the combinator c is applied to the value of type b. The right branch which corresponds \nto the boolean being false passes along the value of type b unchanged. We will be seeing many more such \nwiring diagrams in this paper and it is useful to note some conventions about them. Wires indicate a \nvalue that can exist in the program. Each wire, whenever possible, is annotated with its type and sometimes \nadditional information to help clarify its role. When multiple wires run in parallel, it means that those \nvalues exist in the system at the same time, indicating pair types. When there is a disjunction, we put \na + between the wires. Combinators for distribution distrib and factoring factor are represented as triangles. \nOther triangles may be used and, in each case, types or labels will be used to clarify their roles. Finally, \nwe don t draw boxes for combinators such as id, commutativity, and associativity, but instead just shuf.e \nthe wires as appropriate. The combinator ifnot has type bool \u00d7 bool . bool \u00d7 bool and negates its second \nargument if the .rst argument is true. This gate ifnot is often referred to as the cnot gate. If we iterate \nthis construction once more, the resulting combinator ifcnot has type bool \u00d7 (bool \u00d7 bool) . bool \u00d7 (bool \n\u00d7 bool). The resulting gate checks the .rst argument and if it is true, proceeds to check the second \nargument. If that is also true then it will negate the third argument. Thus ifcnot is the required Toffoli \ngate. 4. Partial Bijections: .o We extend . with recursive types and a family of looping opera\u00adtors. \nThe resulting language, .o, is still a language of bijections but, because it can express in.nite loops, \nthe bijections may be par\u00adtial. Despite this extension, the strong version of logical reversibil\u00adity \n(Prop. 3.2) still holds for .o . 4.1 Isorecursive Types and Trace Operators We extend . in two dimensions: \n(i) by adding recursive types and (ii) by adding looping constructs. The combination of the two extensions \nmakes the extended language, .o, expressive enough to write arbitrary looping programs, including non-terminating \nones. DEFINITION 4.1. (Syntax of .o) We extend Def. 3.1 as follows: value types,b ::= ... | \u00b5x.b | x \nvalues,v ::= ... |(v) combinator types,t ::= b . b isomorphisms, iso ::= ... | fold | unfold combinators,c \n::= ... | trace c The remainder of this section explains the new additions in detail. First, as we illustrate \nbelow, it is possible to write in.nite loops in .o  Isorecursive Types. sive types \u00b5x.bfold and unfold \nfold : have a value of type b \u00b5x.x is \u00b5x.1+ x1+(\u00b5x.1+ x) and then (right (left fact, the type \u00b5x.1+ and \nunfold (v) . v. Trace Operators. c : b1 + b2 b1 trace c : b2 b Intuitively, we are given a computation \nc type b1 + b2 and we build a looping version a value of type b2is injected into the sum type b1 + b2 \nconstructor. The tagged value is passed to cvalue that is tagged with leftsoon as a value tagged with \nright as the .nal answer of the trace c express this semantics as follows: (c 9 loop)(right v1) . v2 \n(c 9 loop)( cc (trace c) v1 . v2 loop(left c loop(right v) . v c where for each c, loopc reversible. \nPROPOSITION 4.2 (Logical Reversibility). cv'' Proof. The operators fold and and unfold The adjoint of \ntrace c is trace c .  4.2 Expressiveness expressiveness of .o Partiality. The combinator just : b \n1+ b below injects a value into a larger type. This combinator is signi.cant because it shows that .o \nadmits non-terminating computations as the adjoint of just diverges on left (): Using just, we can conveniently \nwrite add1 and sub1 as add1 = just 9 fold and sub1 = sym add1. (The de.nition implies that sub1 0 diverges.) \nWe can also create, for any particular value v, a constant function returning v. For example, we can \ntrivially write functions that introduce the values false and true as: introF , introT :1 bool introF \n= just introT = just 9 not Given these functions, we can inject a value into a left or right summand. \nFor example, injectR : aa + a injectR = uniti 9 (introF \u00d7 id) 9 distrib 9 (unite + unite) We can introduce \n0 as follows: introZ :1 nat introZ = trace (swap + 9 fold 9 injectR) Similarly, we can also introduce \nan empty list of any type. More precisely, let the encoding of lists be [b] = \u00b5x.1+ b \u00d7 x. Given a type \nb and a combinator introConstb to introduce a constant of type b, we can write introNil :1 [b] which \nintroduces an empty list of type [b]. Adding an element to a list can be achieved using a construction \nthat is similar to add1; accessing the head and tail of a list can be realized using constructions that \nare similar to sub1. 5. Source Language Having designed .o as a language that embodies the physical idea \nof reversibility, we now wish to demonstrate how irreversible pro\u00adgramming language constructs correspond \nto open systems which implicitly communicate with a global heap and garbage dump. To make this idea concrete, \nwe need a canonical irreversible language.  We use for that purpose a simply-typed, .rst-order functional \nlan\u00adguage with sums and pairs and for loops. The language is fairly conventional and is presented without \nmuch discussion. We present this language as two fragments: the .rst of these, LET, is strongly normalizing, \nand the second, LETo, includes natural numbers and for loops for iteration. The syntax of LET is given \nbelow: Base types,b =1 | b + b | b \u00d7 b Values,v = () | left v | right v | (v, v) Expressions,e = () | \nx | let x = e1 in e2 | left e | right e | case e x.e1 x.e2 | fst e | snd e | (e, e) Type environments, \nG= E | G,x : b Environments,. = E | .; x = v The most interesting aspect of LET is that expressions may \nfreely erase and duplicate data in irreversible ways. The extended language, LETo, includes additionally \nnats, op\u00aderations on nats and a for loop: Base types,b = ... | nat Values,v = ... | n Expressions,e = \n... | n | add1 e | sub1 e | iszero? e | for x = e1 if e2 do e3 The most interesting aspect of the extended \nlanguage LETo is that it admits partial functions. Its type system is entirely conventional except for \nthe rule below: G f e1 : b G,x : b f e2 : bool G,x : b f e3 : b G f for x = e1 if e2 do e3 : b Here is \nan example of iterative addition of two numbers n and m in this syntax: snd (for x =(n, m) if not (iszero?(fst \nx)) do (sub1 (fst x), add1 (snd x))) The not operator over the type bool = 1+1 can be macro encoded as \nnot x = case x [y.right ()] [y.left ()]. For the semantics, we say evallet (e)= v if (e, E) . * let v \nac\u00adcording to a conventional big-step relation mapping closed expres\u00adsions and environments to values, \nof which we show a few repre\u00adsentative cases below: .(x)= v (e1,.) .let v1 (e2,.; x = v1) .let v2 (x, \n.) .let v (let x = e1 in e2,.) .let v2 (e, .) .let left v1 (e1,.; x = v1) .let v (case e x.e1 x.e2,.) \n.let v (e1,.) .let v1 (e1,.) .let v (e2,.) .let v2 (e2,.; x = v) .let false ((e1,e2),.) .let (v1,v2) \n(for x = e1 if e2 do e3,.) .let v (e1,.) .let v (e2,.; x = v) .let true i (for x = e3 if e2 do e3,.; \nx = v) .let v i (for x = e1 if e2 do e3,.) .let v 6. Metalanguages and Translations: An Overview The \ntechnical goal of the next four sections (Secs. 7 to 10) is to translate the source language LETo with \nirreversible primitives to the target information-preserving language .o . Arrow Metalanguage. The .rst \nimportant point is that the trans\u00adlation is de.ned via a metalanguage for information effects. This metalanguage \nisolates the typing and semantics of the effects from the remainder of the language, thus playing a role \nsimilar to Moggi s monadic metalanguage [36] in the translation of conven\u00adtional computational effects \n(e.g., control operators [22]). Our met\u00adalanguage is de.ned, not by extending the .-calculus with monadic \ncombinators, but by extending .o with arrow combinators. Start\u00ading with .o instead of the .-calculus \nis expected since .o plays the role of the pure effect-free language in our setting, just like the .-calculus \nplays the role of the pure effect-free language in the con\u00adventional setting. The choice of using the \narrow combinators rather than the monadic combinators is because the notion of information effects does \nnot appear to be expressible as a monad. For the pur\u00adposes of presentation, the metalanguage is de.ned \nin two stages: ML. in Sec. 7 which is used to compile the strongly-normalizing subset of the source language \nusing two effect combinators create and erase, and ML.o in Sec. 10.1 which is used to compile the full \nsource language using an additional effect combinator traceA. Thus, Secs. 7, 8 and 9 focus on the translation \nfrom LET to . and Sec. 10 handles the translation from LETo to .o . Translation from Source to Metalanguage. \nThe translation from the source language to the metalanguage essentially exposes the implicit erasure \nand duplication of environment bindings. For ex\u00adample, the evaluation rule of a pair (see Sec. 5) duplicates \nthe en\u00advironment which can only be done in the metalanguage using ex\u00adplicit occurrences of the create \neffect combinator. Similarly, the evaluation of a variable projects one value out of the environment, \nimplicitly erasing the rest of the environment, which again can only be done using explicit occurrences \nof the erase effect combinator. Technically, we de.ne two translations T1 : LET =. ML. and T1 o : LETo \n=. ML.o . The .rst maps the strongly-normalizing subset of the source to ML. (Sec. 8) and the second \nis an extension that handles the full source and targets ML.o (Sec. 10.2). Translation from Metalanguage \nto Target. This translation es\u00adsentially needs to compile the effect combinators to the target lan\u00adguage. \nThe basic scheme is based on Toffoli s idea described in Sec. 2.1: an irreversible function of type a \n. b is translated to a bijection (h, a) . (g, b) where h is the type of the heap that sup\u00adplies the constant \nvalues and g is the type of the garbage that ab\u00adsorbs the un-interesting and un-observable outputs. Once \nthe primi\u00adtive effect combinators have been translated, the arrow combinators then thread the heap and \ngarbage through more complex compu\u00adtations. Technically, we again have two translations: one for the \nstrongly-normalizing subset of the source language and one for the full source language. The .rst translation \nT2 :: ML. =. . (Sec. 9) selects particular values for the heap and garbage to em\u00adbed the irreversible \neffects into bijections.2 The second translation T2 o :: ML.o =. .o (Sec. 10.3) works for the full language. \nIt has an important difference which arises from the fact that there is an inherent asymmetry between \ncreate and erase: the operator create is always used to create a known constant while erase is used to \nerase information that is only known at run time. This inher\u00adent asymmetry of the operators is a consequence \nof the fact that the source language is (forward) deterministic, but lacks backward de\u00adterminism. As \nwe saw in Sec. 4.2, .o can express the creation and erasure of constants and we leverage this to completely \neliminate the heap in favor of using traceA.3 7. Arrow Metalanguage ML. To construct our arrow metalanguage \nML., we simply add the generic arrow combinators to . and add the particular operators that model the \ninformation effects we wish to model. In particular, 2 This idea has been the basis of translations similar \nto ours [5]. The literature also includes translations for other languages [2, 12, 19, 23, 26, 41, 49] \nthat share some of the intuition of the translation we present but differ signi.cantly in the technical \ndetails. 3 If LETo had an operation that introduced values unknown at compile time, such as an input \noperation or a random number generator, we would have to re-introduce the heap.  we add two operators \ncreate and erase which correspond to the creation and erasure of information that is implicit in the \nsemantics of LET. These operators are not isomorphisms and hence cannot have . types. They can only have \narrow types. DEFINITION 7.1. (Syntax of ML.) The sets of value types, values, and isomorphisms are identical \nto the corresponding sets in . (see Def. 3.1). The extended combinator types and arrow computations are \nde.ned as follows: types,t ::= b . b | b . b arrow comp., a ::= iso | a + a | a \u00d7 a | a 9 a | arr a | \na \u00bb a | first a | left a | createb | erase The type b1 . b2 is our notion of arrows. The three operations \narr, \u00bb , and first are essential for any notion of arrows. The operation left is needed for arrows that \nalso implement some form of choice. The two operators createb and erase model the particular effects \nin the information metalanguage. The types of the arrow combinators in ML. are similar to their original \ntypes in the traditional arrow calculus except that arr lifts . types to the abstract arrow type . instead \nof lifting regular function types to the abstract arrow type: a : b1 . b2 a1 : b1 . b2 a2 : b2 . b3 arr \na : b1 . b2 a1 \u00bb a2 : b1 . b3 a : b1 . b2 a : b1 . b2 first a : b1 \u00d7 b3 . b2 \u00d7 b3 left a : b1 + b3 . \nb2 + b3 createb :1 . b erase : b . 1 The semantics is speci.ed using the relation .ML which refers to \nthe reduction relation . for .. We only present the reductions for the arrow constructs: av1 . v2 a1 \nv1 .ML v2 a2 v2 .ML v3 (arr a) v1 .ML v2 (a1 \u00bb a2) v1 .ML v3 av1 .ML v2 (left a)(left v1) .ML left v2 \n(left a)(right v) .ML right v av1 .ML v2 (first a)(v1,v3) .ML (v2,v3) erase v .ML () createb() .ML f(b) \nThe operator erase at type b takes any value of type b and returns () which contains no information. \nFor any type b, createb returns a .xed (but arbitrary) value of type b which we call f(b) and which is \nde.ned as: f(1) = () f(b1 \u00d7 b2)=(f(b1),f(b2)) f(b1 + b2)= left (f(b1)) The two operators createb and \nerase, along with the structure provided by the arrow metalanguage, are expressive enough to im\u00adplement \na number of interesting idioms. In particular, it is possible to erase a part of a data structure (as \nshown using fstA below); it is possible to inject a value in a sum type (as shown using leftA below); \nit is possible to forget about choices (as shown using join The symmetric combinator rightA can be de.ned \nsimilarly. ' ' ' ' ' ' Forgetting about choices (join). We de.ne an operator join : b + b . b that takes \na value of type b tagged by either left and right and removes the tag. The de.nition converts the input \nb + b to (1 + 1) \u00d7 b and then erases the .rst component: ((arr uniti) . (arr uniti)) \u00bb (arr factor) \u00bb \nsndA Copying values (cloneb). As the following lemma shows, it is possible, for any type b, to de.ne \nan operator cloneb that can be used to copy values of that type. LEMMA 7.2 (Cloning). For any type b, \nwe can construct an oper\u00adator clone of type b . b \u00d7 b such that: clone v .ML (v, v) Proof. We proceed \nby induction on the type b: = fstA : b1 \u00d7 b2 . b2 fstA = second erase \u00bb arr (swap \u00d7 9 unite) where second \na =(arr swap \u00d7) \u00bb first a \u00bb (arr swap \u00d7). The combinator sndA that deletes the .rst component of a pair \nis This combinator clones b1 and then applies leftA to one of the de.ned symmetrically. copies. Let us \ncall this combinator a1 ' : b1 . b1 \u00d7(b1 +b2). We can do the same with b2, except that we apply rightA, \nresulting in combinator a2 ' : b2 b2 \u00d7 (b1 + b2). The required com\u00adbinator a can be constructed by applying \nthese in parallel and factoring out the results, i.e., a =(a1 ' . a2' ) \u00bb (arr factor) 8. Translation \nfrom LET to ML. The translation T1 maps a closed term of type b in LET to an ML. combinator c :1 b. As \nthe translation is type-directed, it must also handle terms with free variables that are supplied by \nan environment. 8.1 Environments A LET type environment G is translated to an ML. type as follows: [E]\u00d7 \n=1 [G,x : b]\u00d7 = [G]\u00d7 \u00d7 b A value environment . :G is translated to a value v. :G\u00d7: [E]\u00d7 = () [., x = \nv]\u00d7 = ([.]\u00d7 ,v) LEMMA 8.1 (Lookup). If G f x : b and G\u00d7 is the encoding of G, then there exists a combinator \nalookup(x) :G\u00d7 b that looks up x in G\u00d7 . Proof. The required combinator a depends on the structure of \nG: Case E: This cannot arise because G must contain x.  Case G ' ,x ' : b ' and x ' = x: Then a = sndA \n' : b ''  Case G ' ,x and x = x: Then we know that the required x must be bound in G ', i.e. G ' f \nx : b. Thus by induction there exists a ' : [G ' ]\u00d7 b. So the required combinator is a =(a ' . id) \u00bb \nfstA.  8.2 The Translation T1 We translate a LET judgment of the form G f e : b to an ML. combinator \na :G\u00d7 b in such a way that the execution of the resulting ML. term simulates the execution of the original \nterm. Because the evaluation of LET expressions requires an environ\u00adment ., the evaluation of the translated \ncombinator must be given a value v. of type G\u00d7 denoting the value of the environment. LEMMA 8.2 (T1 and \nits correctness). For any well typed LET ex\u00adpression G f e : b, T1[G f e : b] gives us a combinator a \nand a type G\u00d7 in ML. such that: 1. a :G\u00d7 b 2. . (. : G), . (v : b). if (e, .) . * v then a [.]\u00d7 . * \n let ML v. We simultaneously present the translation and prove its correctness: Case (): G f () : \n1 --+ erase :G\u00d7 1 We have that erase v. .ML ().  Case x:  G(x)= b G f x : b --+ alookup(x) :G\u00d7 b Case \nlet x = e1 in e2: G f e1 : b1 --+ a1 :G\u00d7 b1 G,x : b1 f e2 : b2 --+ a2 :G\u00d7 \u00d7 b1 b2 G f let x = e1 in e2 \n: b2 --+ a :G\u00d7 b2 To construct the required a we .rst clone G\u00d7. We can apply a1 to one of the copies \nto get b1. The resulting value of type G\u00d7 \u00d7 b1 is the input required by a2 which returns the result of \ntype b2: = = = = = = Here we have cloned G\u00d7 and constructed b1 +b2 using one copy of G\u00d7 and a1. We then \ndistributed G\u00d7 over b1 +b2 and resulting in two possible environments G\u00d7 \u00d7 b1 or G\u00d7 \u00d7 b2. At this point, \nwe can apply a2 and a3 to these environments resulting in b3 + b3 which we can join to get the desired \nresult b3. Thus we have: a = cloneG\u00d7 \u00bb (left c1) \u00bb (arr distrib) \u00bb ((arr swap \u00d7) . (arr swap \u00d7)) \u00bb (a2 \n. a3) \u00bb join 9. Translation from ML. to . The translation T2 maps an ML. combinator a : b1 b2 to an isomorphism \nh \u00d7 b1 . g \u00d7 b2. The types h and g are determined based on the structure of the combinator a and are \n.xed by the translation T2. The translation is set up such that when we supply f(h) for the heap along \nwith the given input value of type b1, the compiled combinator produces some unspeci.ed value for g and \nthe value for b2 that the original arrow combinator would have produced.  LEMMA 9.1 (T2 and its correctness). \nFor any ML. combinator a : b1 b2, T2[a : b1 b2] gives us c, h and g in . such that: c : h \u00d7 b1 . g \u00d7 \nb2  . (v1 : b1), . (vg : g), (v2 : b2) if av1 . * v2 then  ML c (f(h),v1) . * (vg,v2). As before, we \npresent the translation along with the proof of cor\u00adrectness. arr a: a : b1 . b2 == = == = == = ' '' \n= ' '' ' '' ' '' ' ' ' ' '' '' '' '' '' The de.nition of c '' takes the value of type b3 and constructs \na value of type b2 + b3 using leftSwap and swap +. Given the construction of c ' and c '' we can construct \nthe required c as: c : h \u00d7 (b1 + b3) . g \u00d7 (b2 + b3) \u00d7 ''' c = swap 9 distrib 9 (c \u00d7 c ) 9 factor create: \ncreate :1 b --+ c : h \u00d7 1 . g \u00d7 b We choose h = b and g =1 and we have c = swap \u00d7. The de.nition of create \nis simple because we have taken care to correctly thread a value of type h and create simply rei.es this \nvalue. erase: erase : b 1 --+ e : h \u00d7 b . g \u00d7 1 We choose h =1 and g = b and we have c = swap \u00d7. Note \nthat this is operationally the same as create. The difference is in the types. Since we have set up the \nrest of the computation to thread the value of type g through and never expose it, to erase a value we \nsimply have to move it to the garbage. 10. Translation from LETo to .o The required translation T o is \nfactored into T1 o : LETo =. ML.o and T2 o : ML.o =. .o where the intermediate language ML.o extends \nML.. 10.1 Arrow Metalanguage : ML.o The arrow metalanguage, ML.o , extends ML. with natural num\u00adbers \nand loops. DEFINITION 10.1 (Syntax of ML.o ). base types,b =1 | b \u00d7 b | b + b | nat values,v = () | (v, \nv) | left v | right v | n types,t ::= bb | b-b arrow comp., a ::= iso | a + a | a \u00d7 a | a 9 a | trace \na | arr a | a \u00bb a | first a | left a | traceA a | createb | erase The types extend the .nite types with \nnat which is an abbreviation for \u00b5x.1+ x. In addition to the usual .nite values, we also include natural \nnumbers n which are abbreviations for sequences of right\u00adapplications that end with left (). The arrow \ntype -is analogous to of ML.: we use a different symbol to emphasize that the un\u00adderlying bijections \nare partial. The set of underlying isomorphisms extends the ones for .nite types with unfold : nat 1+ \nnat : fold. We de.ne f(nat)=0 and hence createnat =0. Finally, the language includes one additional arrow \ncombinator traceA with the typing rule:  a : b1 + b2 -b1 + b3 traceA a : b2 -b3 In contrast to trace \nwhich de.nes looping computations whose bodies are (partial) bijections, traceA can be used to de.ne \nloop\u00ading computations whose bodies may create and erase information. The semantics of traceA is similar \nto that of trace but with an important technical difference. The body of the traceA-loop may -- -- = \n- = = Conceptually, each iteration of the traceA is determined by the result of a2. If the conditional \nis true then the iteration causes a3 to be executed. 10.3 Translation T2 o from ML.o to .o Translation \nT2 o is similar to T2. As discussed in the overview (Sec. 6) the signi.cant difference comes from the \nfact that .o can create constants hence eliminating the need for an input heap type. The translation \nonly needs to track the garbage produced by combinators. PROPOSITION 10.4. For any type b of ML.o we \ncan construct createConstb :1 b such that createConstb () .ML fb. LEMMA 10.5 (T2 o and its correctness)). \nFor any ML.o combina\u00adtor a : b1 -b2, T2 o[a : b1 -b2] gives us c and g in .o such that: c : b1 g \u00d7 b2 \n . (v1 : b1), . (vg : g), (v2 : b2). if av . * ML v2 then cv1 . * (vg,v2).  The interesting cases to \nconsider are: Case arr c: The required combinator is c 9 uniti : b1 1 \u00d7 b2 where the garbage is 1. \n Case createb: The required combinator is createConstb  9 uniti :1 1 \u00d7 b with g =1. Case erase: The \nrequired combinator is uniti 9 swap \u00d7 :1 b \u00d7 1 with g = b.  Case traceA a:  a : b1 + b2 -b1 + b3 --+ \nc : b1 + b2 g \u00d7 (b1 + b3) traceA a : b2 -b3 --+ c1 : b2 g ' \u00d7 b3 As shown in Sec. 4.2, we can create \nand manipulate empty lists of any given type in .o. The diagram below is the required combinator c1 with \ng ' =[g], i.e., the resulting garbage is the list of garbage values produced at each step in the iteration, \nof type g. 11. Applications The technical contribution of the paper was devoted to designing a semantic \nfoundation of computation which treats information as a computational resource. We now brie.y explore \nthe application of such a framework to security and privacy. 11.1 Quantitative Information Flow Research \nin the domain of quantitative information-.ow security is aimed at tracking the amount of information \nleakage through a computation [10, 32, 33]. Instead of devising ad hoc analyses, one can in our framework \nsimply observe the program s types and see how much information has been erased.  As an example, consider \na password checker, check : bool \u00d7 bool . bool, which takes a 2-bit user input and has access to a 2-bit \nsecret password. The type bool \u00d7 bool has 4 inhabitants. With probability 1/4 an attacker guesses the \nreal password (log 4 bits learned) and with probability 3/4 guesses wrong thus eliminating one candidate \npassword (log 4 - log 3 bits learned), making the average information gained 1/4log4 + 3/4(log 4 - log3) \n= 0.8. One call to the password checker has thus hidden 1.2 bits of information from the attacker. The \nLandauer principle implies that the 1.2 bits dissipated by check must be accounted for by some logically \nirreversible erasure of 1.2 bits. And indeed, the minimum any .o implementation of check must erase is \n2 bits which would manifest itself by a use of erase at type bool \u00d7 bool. The fact that ML.o types indicate \na lower bound on a program s intrinsic secrecy deserves further investigation. Further, a .ner analysis \nallowing us to capture the exact erasure of fractional bits, may be achieved by enriching the type system \nof ML.o to track the probability of disjunctive branches, such as in the probabilistic .-calculus [39]. \n 11.2 Orthogonality and Differential Privacy Physical processes operate on physical representations of \nvalues which exist in space and have associated costs (e.g. amount of energy). Physical processes must \nnot only be reversible but they must do so in a way that respects this additional structure. Toffoli \nand Fredkin [16] captured this additional restriction on physical processes using what they called Conservative \nLogic in which values can only be shuf.ed around by computation. This guarantees that processes maintain \nwhatever cost is associated with the values they operate on. In quantum mechanics, this additional restriction \nis modeled in a different way using the mathematical structure of Hilbert spaces. Speci.cally, the fundamental \nbuilding blocks of quantum computation are that (i) quantum states are equipped with an inner product \nthat induces a norm (i.e., a metric), and that (ii) quantum transformations must be unitary, i.e., must \nbe reversible transformations that preserve the norm induced by the inner product. They key de.nition \nis the following. DEFINITION 11.1 (Isometry). Given a metric dt on values of type t, a function f : t1 \n. t2 is said to be an isometry iff dt2 (f(x),f(y)) = dt1 (x, y) for all x, y . t1. In an apparently unrelated \ndevelopment, Reed and Pierce [40] introduce a calculus for differential privacy. The fundamental build\u00ading \nblocks of their calculus are (i) that types are equipped with a metric that de.nes what it means for \nvalues to be close, and that (ii) functions must preserve distances between the values. They key de.nition \nis the following. DEFINITION 11.2 (c-sensitive function). Given a metric dt on values of type t , a function \nf : t1 . t2 is said to be c-sensitive iff dt2 (f(x),f(y)) = c \u00b7 dt1 (x, y) for all x, y . t1. In other \nwords, the distance between the values x and y in the domain of the function cannot be magni.ed by more \nthan a factor c. Clearly quantum evolution is restricted to the special case of 1\u00adsensitive functions. \nTo further investigate this connection would require us to extend our model by associating a metric with \neach type. However, unlike previous work, the introduction of the metric in our case would be justi.ed \nby additional physical considerations. 12. Conclusions and Future Work Starting with the notion that \nclosed physical systems are the purest, we have developed a pure language in which computa\u00adtions preserve \ninformation. We show that even what are often called pure functional languages exhibit computational \neffects related to the creation and deletion of information. This development re\u00adasserts the fact that \ninformation is a signi.cant computational re\u00adsource that should, in many situations, be exposed to programmers \nand static analysis tools. One of our main contributions therefore is in bridging the information theoretic \nanalysis of computations (for example in the domain of quantitative information .ow security) and the \ntraditional world of type and effect systems. The main thesis of the paper is that the study of programming \nlanguages, their typing, their semantics, their computational ef\u00adfects, and even their security properties \ncan tremendously bene.t from taking the physical aspect of computation seriously. Our pa\u00adper provides \nthe conceptual foundation for such investigations. Reversible Computing. Our pure language is logically \nreversible and hence shares some common features with previously devel\u00adoped reversible languages [6, \n34, 37, 47] although none are based on the simple notion of isomorphisms between types [8]. The prac\u00adtice \nof programming languages is replete with ad hoc instances of reversible computations such as database \ntransactions, mecha\u00adnisms for data provenance, checkpoints, stack and exception traces, logs, backups, \nrollback recoveries, version control systems, reverse engineering, software transactional memories, continuations, \nback\u00adtracking search, and multiple-level undo features in commercial applications. A possible application \nof our work is that, in principle, such reversible programs could be automatically derived from com\u00admon \nirreversible programs (which are typically easier to write) by translations similar to the one we presented. \nSimilarly, our wiring diagrams could be directly realized as hardware circuits and pave the way for speculative \nexecution and backtracking infrastructure in CPUs that are inherently reversible and use minimal bookkeep\u00ading \nresources [20]. Quantum Computing. Many programming models of quantum computing start with the .-calculus \nas the underlying classical language and add quantum features on top of it [5, 13, 43, 45]. This strategy \nis natural given that the .-calculus is the canonical classical computational model. However, since quantum \nevolution is reversible, this strategy complicates the development of quantum languages as it forces \nthe languages to devise complicated ways to restrict their implicit information effects. A simpler strategy \nthat loses no generality is to build the quantum features on top of a reversible classical language. \nOptimality and Equivalence Preservation. For our purpose of establishing a semantic connection, we have \nmade no attempt to optimize the types h and g generated by the translation to the re\u00adversible target \nlanguage. For applications concerned with the im\u00adplementation of .o circuits, optimizations like in Toffoli \ns original paper will need to be developed. Also, equivalent source terms may be translated to terms \nof different types, as the types h and g are chosen by the translation based on the syntax of the input \nterms. The situation is similar to the closure conversion translation of a compiler which exposes the \ntype of the environment and the .x should follow the same general strategy [4, 35]. Higher-Order Functions. \nAs the development of lambda calculi with linear [27, 46] and bunched types [38] shows, controlling the \ncreation, duplication, and sharing of resources is largely orthogonal to higher-order functions. Furthermore, \nexisting work suggests that adding higher-order functions to a language like .o can be done in a systematic \nway as shown for example by the Int construction of Joyal, Street and Verity in the context of traced \nmonoidal cate\u00adgories [25], or by Abramsky [1, 3] and Mackie [31] in the context of the geometry of interaction \nand Ghica [17] in the context of the geometry of synthesis. These constructions need to explored in the \ncontext of .o .  Acknowledgments We thank Amal Ahmed, Esfandiar Haghverdi, and Erik Wennstrom for helpful \ndiscussions. We also thank the anonymous reviewers for their helpful comments and suggestions. This project \nwas partially funded by Indiana University s Of.ce of the Vice President for Re\u00adsearch and the Of.ce \nof the Vice Provost for Research through its Faculty Research Support Program. We also acknowledge support \nfrom Indiana University s Institute for Advanced Study. References [1] S. Abramsky. Retracing some paths \nin process algebra. In U. Monta\u00adnari and V. Sassone, editors, CONCUR, volume 1119 of Lecture Notes in \nComputer Science, pages 1 17. Springer, 1996. [2] S. Abramsky. A structural approach to reversible computation. \nTheor. Comput. Sci., 347:441 464, December 2005. [3] S. Abramsky and R. Jagadeesan. New foundations for \nthe geometry of interaction. Inf. Comput., 111:53 119, May 1994. [4] A. Ahmed and M. Blume. Typed closure \nconversion preserves obser\u00advational equivalence. In ICFP, pages 157 168. ACM, 2008. [5] T. Altenkirch \nand J. Grattage. A functional quantum programming language. In P. Panangaden, editor, LICS, pages 249 \n258. IEEE Computer Society Press, June 2005. [6] H. G. Baker. NREVERSAL of fortune -the thermodynamics \nof garbage collection. In Proceedings of the International Workshop on Memory Management, pages 507 524. \nSpringer-Verlag, 1992. [7] C. H. Bennett. Logical reversibility of computation. IBM J. Res. Dev., 17:525 \n532, November 1973. [8] W. J. Bowman, R. P. James, and A. Sabry. Dagger Traced Symmetric Monoidal Categories \nand Reversible Programming. In Workshop on Reversible Computation, 2011. [9] L. Cardelli and G. Zavattaro. \nOn the computational power of biochem\u00adistry. In Third International Conference on Algebraic Biology, \n2008. [10] D. Clark, S. Hunt, and P. Malacaria. A static analysis for quantifying information .ow in \na simple imperative language. J. Comput. Secur., 15:321 371, August 2007. [11] D. Deutsch. The Fabric \nof Reality. Penguin, 1997. [12] A. Di Pierro, C. Hankin, and H. Wiklicky. Reversible combinatory logic. \nMSCS, 16:621 637, August 2006. [13] R. Duncan. Types for quantum computation. PhD thesis, Oxford University, \n2006. [14] C. Dwork. Differential privacy. In ICALP (2) 06, pages 1 12, 2006. [15] M. Fiore. Isomorphisms \nof generic recursive polynomial types. In POPL, pages 77 88. ACM, 2004. [16] E. Fredkin and T. Toffoli. \nConservative logic. International Journal of Theoretical Physics, 21(3):219 253, 1982. [17] D. R. Ghica. \nGeometry of synthesis: a structured approach to VLSI design. In POPL, pages 363 375. ACM, 2007. [18] \nJ.-Y. Girard. Linear logic. Theor. Comput. Sci., 50:1 102, 1987. [19] R. Gl\u00a8uck and M. Kawabe. Revisiting \nan automatic program inverter for Lisp. SIGPLAN Not., 40:8 17, May 2005. [20] L. Hammond, M. Willey, \nand K. Olukotun. Data speculation support for a chip multiprocessor. In ASPLOS, pages 58 69, New York, \nNY, USA, 1998. ACM. [21] M. Hasegawa. Recursion from cyclic sharing: Traced monoidal cate\u00adgories and \nmodels of cyclic lambda calculi. In TLCA, pages 196 213. Springer-Verlag, 1997. [22] J. Hatcliff and \nO. Danvy. A generic account of continuation-passing styles. In POPL, pages 458 471. ACM, 1994. [23] L. \nHuelsbergen. A logically reversible evaluator for the call-by-name lambda calculus. InterJournal Complex \nSystems, 46, 1996. [24] J. Hughes. Generalising monads to arrows. Sci. Comput. Program., 37(1-3):67 111, \n2000. [25] A. Joyal, R. Street, and D. Verity. Traced monoidal categories. Math. Proc. Camb. Philos. \nSoc., 119(3):447 468, 1996. [26] W. E. Kluge. A reversible SE(M)CD machine. In International Workshop \non Implementation of Functional Languages, pages 95 113. Springer-Verlag, 2000. [27] Y. Lafont. The linear \nabstract machine. Theor. Comput. Sci., 59:157 180, July 1988. ISSN 0304-3975. [28] R. Landauer. Irreversibility \nand heat generation in the computing process. IBM J. Res. Dev., 5:183 191, July 1961. [29] X. Ma, J. \nHuang, and F. Lombardi. A model for computing and energy dissipation of molecular QCA devices and circuits. \nJ. Emerg. Technol. Comput. Syst., 3(4):1 30, 2008. [30] E. Macii and M. Poncino. Exact computation of \nthe entropy of a logic circuit. In Proceedings of the 6th Great Lakes Symposium on VLSI, Washington, \nDC, USA, 1996. IEEE Computer Society. [31] I. Mackie. Reversible higher-order computations. In Workshop \non Reversible Computation, 2011. [32] P. Malacaria. Assessing security threats of looping constructs. \nIn POPL, pages 225 235. ACM, 2007. [33] J. L. Massey. Guessing and entropy. In Proceedings of the IEEE \nInternational Symposium on Information Theory, page 204, 1994. [34] A. B. Matos. Linear programs in a \nsimple reversible language. Theor. Comput. Sci., 290:2063 2074, January 2003. [35] Y. Minamide, G. Morrisett, \nand R. Harper. Typed closure conversion. In POPL, pages 271 283, New York, NY, USA, 1996. ACM. [36] E. \nMoggi. Notions of computation and monads. Inf. Comput., 93: 55 92, July 1991. [37] S.-C. Mu, Z. Hu, and \nM. Takeichi. An injective language for reversible computation. In International Conference on Mathematics \nof Program Construction, pages 289 313, 2004. [38] P. O hearn. On bunched typing. J. Funct. Program., \n13:747 796, July 2003. [39] A. D. Pierro, C. Hankin, and H. Wiklicky. Probabilistic lambda\u00adcalculus and \nquantitative program analysis. J. Log. Comput., 15(2), 2005. [40] J. Reed and B. C. Pierce. Distance \nmakes the types grow stronger: a calculus for differential privacy. In ICFP, pages 157 168. ACM, 2010. \n[41] B. J. Ross. Running programs backwards: The logical inversion of imperative computation. Formal \nAspects of Computing, 9:331 348, 1997. [42] A. Sabelfeld and A. Myers. Language-based information-.ow \nsecu\u00adrity. IEEE Journal on Selected Areas in Communications, 21(1):5 19, 2003. [43] P. Selinger and B. \nValiron. A lambda calculus for quantum computa\u00adtion with classical control. MSCS, 16(3):527 552, 2006. \n[44] T. Toffoli. Reversible computing. In Proceedings of the Colloquium on Automata, Languages and Programming, \npages 632 644. Springer-Verlag, 1980. [45] A. van Tonder. A lambda calculus for quantum computation. \nSIAM Journal on Computing, 33(5):1109 1135, 2004. [46] P. Wadler. Linear types can change the world! \nIn M. Broy and C. Jones, editors, IFIP TC 2 Working Conference on Programming Concepts and Methods, pages \n347 359. North Holland, 1990. [47] T. Yokoyama, H. B. Axelsen, and R. Gl\u00a8uck. Principles of a reversible \nprogramming language. In Conference on Computing Frontiers, pages 43 54. ACM, 2008. [48] H. Zeng, C. \nS. Ellis, A. R. Lebeck, and A. Vahdat. Ecosystem: managing energy as a .rst class operating system resource. \nSIGPLAN Not., 37(10):123 132, 2002. [49] P. Zuliani. Logical reversibility. IBM J. Res. Dev., 45:807 \n818, November 2001.     \n\t\t\t", "proc_id": "2103656", "abstract": "<p>Computation is a physical process which, like all other physical processes, is fundamentally reversible. From the notion of type isomorphisms, we derive a typed, universal, and reversible computational model in which information is treated as a linear resource that can neither be duplicated nor erased. We use this model as a semantic foundation for computation and show that the \"gap\" between conventional irreversible computation and logically reversible computation can be captured by a type-and-effect system. Our type-and-effect system is structured as an arrow metalanguage that exposes creation and erasure of information as explicit effect operations. Irreversible computations arise from interactions with an implicit information environment, thus making them a derived notion, much like open systems in Physics. We sketch several applications which can benefit from an explicit treatment of information effects, such as quantitative information-flow security and differential privacy.</p>", "authors": [{"name": "Roshan P. James", "author_profile_id": "81351604488", "affiliation": "Indiana University, Bloomington, IN, USA", "person_id": "P2991343", "email_address": "rpjames@indiana.edu", "orcid_id": ""}, {"name": "Amr Sabry", "author_profile_id": "81100016804", "affiliation": "Indiana University, Bloomington, IN, USA", "person_id": "P2991344", "email_address": "sabry@indiana.edu", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103667", "year": "2012", "article_id": "2103667", "conference": "POPL", "title": "Information effects", "url": "http://dl.acm.org/citation.cfm?id=2103667"}