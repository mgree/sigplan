{"article_publication_date": "01-25-2012", "fulltext": "\n Playing in the Grey Area of Proofs Kry.stof Hoder Laura Kov\u00b4acs Andrei Voronkov University of Manchester \nTU Vienna University of Manchester krystof.hoder@gmail.com lkovacs@complang.tuwien.ac.at andrei@voronkov.com \n Abstract Interpolation is an important technique in veri.cation and static analysis of programs. In \nparticular, interpolants extracted from proofs of various properties are used in invariant generation \nand bounded model checking. A number of recent papers studies in\u00adterpolation in various theories and \nalso extraction of smaller in\u00adterpolants from proofs. In particular, there are several algorithms for \nextracting of interpolants from so-called local proofs. The main contribution of this paper is a technique \nof minimising interpolants based on transformations of what we call the grey area of local proofs. Another \ncontribution is a technique of transforming, under certain common conditions, arbitrary proofs into local \nones. Unlike many other interpolation techniques, our technique is very general and applies to arbitrary \ntheories. Our approach is implemented in the theorem prover Vampire and evaluated on a large number of \nbenchmarks coming from .rst-order theorem prov\u00ading and bounded model checking using logic with equality, \nunin\u00adterpreted functions and linear integer arithmetic. Our experiments demonstrate the power of the \nnew techniques: for example, it is not unusual that our proof transformation gives more than a tenfold \nreduction in the size of interpolants. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: \nFormal Methods; F.3.1 [Logic and Meanings of Programs]: Assertions; I.2.3 [Arti.cial Intelligence]: Deduction, \ninference en\u00adgines, resolution General Terms Theory, Veri.cation, Experimentation Keywords Program veri.cation, \ntheorem proving, interpolation 1. Introduction Interpolants extracted from proofs have several applications \nin ver\u00adi.cation and static analysis, see e.g. [3, 6, 12, 15, 21]. Although interpolants are guaranteed \nto exist in some theories (for example, those having quanti.er elimination), interpolants extracted from \nproofs turn out to be smaller and more useful than those obtained by general interpolation algorithms, \nsee, e.g. [16]. For this reason, recent papers [5, 9, 11, 14, 18, 19, 21] consider the problem of ob\u00adtaining \nsmall interpolants for various theories. In this paper we consider two related problems: extracting in\u00adterpolants \nfrom proofs and minimising such interpolants. Papers [18, 20] de.ne algorithms for extracting interpolants \nfrom so-called Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. POPL 12, January 25 27, 2012, Philadelphia, PA, USA. Copyright c &#38;#169; 2012 ACM 978-1-4503-1083-3/12/01. \n. . $10.00 local proofs. Roughly, in local proofs some symbols are colored in the red or blue colors \nand others are uncolored. Uncolored symbols are said to be grey. A local proof cannot contain an inference \nthat uses both red and blue symbols. In other words, colors cannot be mixed within the same inference. \nHowever, building local proofs may require substantial changes to a .rst-order theorem prover or an SMT \nsolver. In addition, local proofs do not necessarily exist. One of the contributions of this paper is \na technique for changing proofs into local ones under some conditions. The ideas of this technique can \nbe traced to an observation made in [17, 18] that existential quanti.cation of constants results in an \ninterpolant. We prove a simple result showing that this technique is correct and can be applied to translate \nnon-local proofs with colored constants into local proofs. When we already have a local proof, one can \nextract an inter\u00adpolant from it. This interpolant is a boolean combination of (some) formulas occurring \nin the proof, if one uses the algorithm of [18]. More exactly, the interpolant is obtained as a boolean \ncombination of conclusions of some symbol-eliminating inferences: an inference having at least one colored \npremise and a grey conclusion. The in\u00adterpolation extraction theorem of [18] is not restricted to any \npar\u00adticular theory. Essentially the only condition on proofs is inference soundness, that is, the conclusion \nof any inference is a logical con\u00adsequence of its premises. This generality gives one a lot of freedom \nsince one does not have to follow rules of any speci.c calculus (such as resolution and superposition) \nin building local proofs. In this paper, we exploit the generality of [18] by considering proof transformations \nthat preserve both inference soundness and locality. It is interesting that such transformations can \ndrastically change the shape and the size of the extracted interpolant. The transformations we consider \nare always applied to grey formulas in the proof, which inspired the title of this paper. While the class \ntransformations we consider (cutting off a grey formula) obviously preserve inference soundness, they \ncan violate locality. To preserve locality, we create a SAT problem whose solutions encode all local \nproofs obtained by a sequence of cut\u00adoffs. Further, we create a linear expression over the variables \nof the SAT problem that expresses some numeric characteristics of the interpolant, for example, the number \nof different atoms in it. Thus, we are interested in the solutions of the problem that minimise the linear \nexpression: any such solution can be used to build a proof giving a smaller (in some sense) interpolant. \nThese solutions can be found using an SMT solver or a pseudo-boolean optimisation tool. The main contributions \nof our paper are summarised below. c We present a new method of producing smaller interpolants from local \nproofs. The methods is based on transformation of the grey area of proofs. It uses the idea that proof \nlocality can be expressed by a set of propositional formulas whose mod\u00adels represent all local proofs \nobtained by such transformations (Sections 5.1-5.2).  c We present a method for changing proofs into \nlocal ones. This method is applicable to all proofs in which all colored symbols are uninterpreted constants \n(Section 4). c We de.ne a transformation of interpolant minimisation prob\u00adlems into the problem of solving \npseudo-boolean constraints (Section 5.4). Minimality is de.ned with respect to various measures of the \nsize of interpolants. c We implemented our minimisation algorithm in the Vampire theorem prover [24]. \nIt uses the Yices SMT solver [10] for sol\u00adving pseudo-boolean constraints (Section 6.1). As Vampire can\u00adnot \nyet ef.ciently handle the combination of various theories, we generate proofs over SMT problems using \nZ3 [8]. c We show experimentally that our method improves [18] by generating considerably better/smaller \ninterpolants in the size, the total weight and the number of quanti.ers (Section 6). The rest of this \npaper is structured as follows. Section 2 overviews relevant de.nitions and properties of .rst-order \nlogic and interpolation. In Section 3 the notion of colored and local proofs are introduced. Our result \non translating non-local proofs into local ones is formulated in Section 4. Section 5 details our approach \nto minimising interpolants. We present experimental re\u00adsults in Section 6 and overview related work in \nSection 7. Section 8 concludes the paper. 2. Interpolation We consider the standard .rst-order predicate \nlogic with equality. We allow all standard boolean connectives and quanti.ers in the language. We assume \nthat the language contains the logical con\u00adstants T for always true and . for always false formulas. \nThroughout this paper, we denote formulas by A, B, C, D, G, R, terms by r, s, t, variables by x, y, z, \nconstants by a, b, c and func\u00adtion symbols by f, g, possibly with indices. Let A be a formula with free \nvariables x\u00af, then .A (respectively, .A) denotes the for\u00admula (.x\u00af)A (respectively, (.x\u00af)A). A formula \nis called closed, or a sentence, if it has no free variables. We call a symbol a predi\u00adcate symbol, a \nfunction symbol or a constant. Thus, variables are not symbols. We consider equality = part of the language, \nthat is, equality is not a symbol. A formula or a term is called ground if it has no occurrences of variables. \nA formula is called universal (respectively, existential) if it has the form (.x\u00af)A (respectively, (.x\u00af)A), \nwhere A is quanti.er-free. We write C1,...,Cn f C to denote that the formula C1 . ... . Cn . C is a tautology. \nNote that C1,...,Cn,C may contain free variables. A signature is any .nite set of symbols. The signature \nof a formula A is the set of all symbols occurring in this formula. For example, the signature of b = \ng(z) is {g, b}. The language of a formula A, denoted by LA, is the set of all formulas built from the \nsymbols occurring in A, that is formulas whose signatures are subsets of the signature of A. We recall \nthe following theorem from [7]. THEOREM 2.1 (Craig s Interpolation Theorem). Let A, B be closed formulas \nand let A f B. Then there exists a closed formula I .LA nLB such that A f I and I f B. In other words, \nevery symbol occurring in I also occurs in both A and B. Every formula I satisfying this theorem will \nbe called an interpolant of A and B. We call a theory any set of closed formulas. If T is a theory, we \nwrite C1,...,Cn fT C to denote that the formula C1 .....C1 . C holds in all models of T . In fact, our \nnotion of theory corresponds to the notion of axiomatisable theory in logic. When we work with a theory \nT , we call symbols occurring in T interpreted while all other symbols uninterpreted. As proved in [18], \nCraig s interpolation also holds for theories in the following sense: THEOREM 2.2. Let A, B be formulas \nand let A fT B. Then there exists a formula I such that 1. A fT I and I f B; 2. every uninterpreted \nsymbol of I occurs both in A and B; 3. every interpreted symbol of I occurs in B.  Likewise, there \nexists a formula I such that 1. A f I and I fT B; 2. every uninterpreted symbol of I occurs both in \nA and B; 3. every interpreted symbol of I occurs in A.  The proof of this theorem in [18] uses compactness, \nwhich is guaranteed when T is axiomatisable. In the sequel we will sometimes be interested in the interpo\u00adlation \nproperty with respect to a given theory T . We will use fT instead of f and relativise all de.nitions \nto T . To be precise, we call an interpolant of A and B any formula I such that A fT I, I fT B, and every \nuninterpreted symbol of I occurs both in A and B. If E is a set of expressions (for example, formulas) \nand con\u00adstants c1,...,cn do not occur in E, then we say that c1,...,cn are fresh for E. We will less \nformally simply say fresh constants when E is the set of all expressions considered in the current context. \nWe call a reverse interpolant of A and B any formula I such that A fT I, I,B fT ., and every uninterpreted \nsymbol of I occurs both in A and B. Reverse interpolants for A and B are exactly interpolants of A and \n\u00acB. Moreover, when B is closed, reverse interpolants are exactly interpolants in the sense of [20, 21]. \nReverse interpolants are convenient when we use a refutation-based inference system, such as resolution, \nfor .nding a proof of A . B that can give us an interpolant: in this case one can search for a refutation \nfrom the set of formulas A, \u00acB instead. 3. Local Proofs In this section we recall some terminology related \nto inference systems. Inference systems are commonly used in the theory of resolution and superposition \n[1, 22]; however we do not restrict ourselves to the superposition calculus. The material of this section \nis based on [18], adapting the terminology of [18] to our setting. We also introduce the notion of local \nproofs and recall results on extracting interpolants from local proofs as proved in [18]. DEFINITION \n3.1. An inference rule is an n-ary relation on formu\u00adlas, where n = 0. The elements of such a relation \nare called infer\u00adences and usually written as A1 ... An . A The formulas A1,...,An are called the premises \nof this inference, whereas the formula A is the conclusion of the inference. An inference system I is \na set of inference rules. An axiom of an inference system is any conclusion of an inference with 0 premises. \nAny inferences with 0 premises and a conclusion A will be written without the bar line, simply as A. \nA derivation in an inference system I is a tree built from inferences in I. If the root of this derivation \nis A, then we say it is a derivation of A. A derivation of A is called a proof of A if it is .nite and \nall leaves in the derivation are axioms. A formula A is called provable in I if it has a proof. We say \nthat a derivation of A is from assumptions A1,...,Am if the derivation is .nite and every  leaf in it \nis either an axiom or one of the formulas A1,...,Am.A formula A is said to be derivable from assumptions \nA1,...,Am if there exists a derivation of A from A1,...,Am.A refutation is a derivation of .. 0 Note \nthat a proof is a derivation from the empty set of assumptions. Any derivation from a set of assumptions \nS can be considered as a derivation from any larger set of assumptions S' . S. Let us now .x two sentences \nR (red) and B (blue). In the sequel we assume R and B to be .xed and give all de.nitions relative to \nR and B. Denote by L the intersection of the languages of R and B, that is the set LR nLB. We call signature \nsymbols occurring both in R and B grey, symbols occurring only in R red and symbols occurring only in \nB blue. A symbol that is either red or blue is also called colored. For a formula C, we say that C is \ngrey if C .L, otherwise we say that C is colored. In other words, grey formulas contain only grey symbols \nand every colored formula contains at least one red or blue symbol. A colored formula that only contains \nred and grey symbols, is called a red formula. Similarly, a blue formula is a colored formula containing \nonly blue and grey symbols. In the rest of this paper, red formulas will be denoted by R, blue formulas \nby B, and grey formulas by G, possibly with indices. DEFINITION 3.2 (RB-derivation). Let us call an RB-derivation \nany derivation . satisfying the following conditions. (RB1) For every leaf C of . one of the following \nconditions holds: 1. R fT .C and C .LR or 2. B fT .C and C .LB . (RB2) For every inference C1 ... Cn \nC of . we have .C1,..., .Cn fT .C. We will refer to property (RB2) as soundness. 0 We will be interested \nin .nding reverse interpolants of R and B. The case LR .LB is obvious, since in this case R is a reverse \ninterpolant of R and B. Likewise, if LB .LR, then \u00acB is a reverse interpolant of R and B. For this reason, \nin the sequel we assume that LR .LB and LB .LR, that is, both R and B contain at least one colored symbol. \nWe are mostly interested in a special kind of derivation intro\u00adduced in [14] and called local (or sometimes \ncalled split-proofs). The de.nition of a local derivation is relative to formulas R and B. DEFINITION \n3.3 (Local RB-derivation). An inference C1 ... Cn C in an RB-derivation is called local if the following \ntwo conditions hold. (L1) Either {C1,...,Cn,C}.LR or {C1,...,Cn,C}.LB. (L2) If all of the formulas C1,...,Cn \nare grey, then C is grey, too. A derivation is called local if so is every inference of this derivation. \nIn other words, (L1) says that inferences cannot mix colors: no inference contains both red and blue \nsymbols. Condition (L2) is natural (inferences should not introduce irrelevant symbols) but it is absent \nin other works. Condition (L2) is however essential for us since without it the proof of Theorem 3.4 \ndoes not go through [18]. Note that standard derivations produced by theorem provers often contain inferences \nviolating (L2), especially, in instantiation rules: (.x)A(x) , A(r) where r is a red term. However, such \ninferences can be removed from derivations without violating (L1). We will now formulate one of the main \ntheorems of [18] on the extraction of interpolants from local proofs and explain the structure of interpolants \nobtained by the algorithm of [18]. Consider any RB-derivation .. Note that by the soundness condition \n(RB2) we can replace every formula C occurring in this derivation by its universal closure .C and obtain \nan RB-derivation .' where inferences are only performed on closed formulas. We will call such derivations \n.' closed and assume, for simplicity, that we are dealing only with closed derivations. We call a symbol-eliminating \ninference any inference that is 1. either a grey leaf G of . such that R fT G. 2. or has the form  \nA1 \u00b7\u00b7\u00b7 An , G such that G is grey and and at least one of the formulas A1,...,An is colored. Any such \ninference eliminates at least one colored symbol. One could also call such inferences color-eliminating. \nThe following theorem is proved in [18]: THEOREM 3.4. Let . be a closed local RB-refutation. Then one \ncan extract from . a reverse interpolant I of R and B. This reverse interpolant is a boolean combination \nof conclusions of symbol\u00adeliminating inferences of .. 0 The proof of Theorem 3.4 in [18] gives an algorithm \nfor extracting an interpolant from a refutation. By a close inspection of the algorithm of [18], we noted \nthat not all conclusions of symbol-eliminating inferences occur in the ex\u00adtracted interpolant. To characterise \nthe set of all formulas occurring in the interpolant, in this paper we introduce a new notion, called \nthe digest of a refutation, as given below. DEFINITION 3.5 (Digest). Consider any conclusion G of a symbol\u00adeliminating \ninference. If the inference eliminates a red symbol, then it has the form: \u00b7\u00b7\u00b7 R0 \u00b7\u00b7\u00b7 G Consider the \npath from G to the bottom formula of the refutation: \u00b7\u00b7\u00b7 R0 \u00b7\u00b7\u00b7 G . . . . . We say that G belongs to \nthe digest of the refutation if either all formulas on the path are grey or the .rst (closest to G) colored \nformula on the path is blue. Likewise, for a blue symbol eliminating inference: \u00b7\u00b7\u00b7 B0 \u00b7\u00b7\u00b7 G . . . . \n. G belongs to the digest of the refutation if at least one formula on the path is colored and the .rst \n(closest to G) colored formula on the path is red. 0  Note the slight asymmetry in De.nition 3.5 between \nred and blue symbol eliminating inferences, which is due to the interpolant generation algorithm of [18]. \nUsing the notion of digest, we can now re.ne Theorem 3.4 as follows: THEOREM 3.6. Let . be a closed local \nRB-refutation. Then one can extract from . a reverse interpolant I of R and B. This reverse interpolant \nis a boolean combination of the formulas in the digest of .. 0 In what follows we will refer to the interpolant \nobtained from a refutation as described in Theorem 3.6 as the interpolant extracted from .. 4. Proof \nLocalisation Extracting interpolants from proof requires a special interpolating prover, or a prover \nproducing local proofs. While, as reported in [13], the theorem prover Vampire can search for local proofs \nonly and hence the algorithm of [18] can be used in .rst-order resolution proofs, most provers and SMT \nsolvers do not necessarily generate local proofs. One of the main motivations of this paper was to check \nhow our minimisation technique works on real-life examples taken from static analysis of software. Although \nsuch benchmarks exist, they can only be solved using an SMT solver, which in general produces non-local \nproofs. In is interesting that in real-life examples, especially those taken from bounded model checking, \nall the colored symbols are nor\u00admally uninterpreted constants representing state variables from in\u00adtermediate \nstates. In this section we show that for such examples one can transform arbitrary proofs into local \nones, at the cost of quantifying some formulas in the proof. This idea has already ap\u00adpeared in [17, \n18], see Lemma 4.1 below. The downside of this approach is that a ground refutation can become a non-ground \none, thus, the extracted interpolant may con\u00adtain quanti.ers. Once we have a local proof, the number \nof such quanti.ers can be reduced using the technique of Section 5 (line 18 of Algorithm 1). LEMMA 4.1. \n[17, 18] Consider two formulas A1(a) and A2 such that A1(a) fT A2 and a is an uninterpreted constant \nnot occurring in A2. Then, A1(a) f (.x)A1(x) and (.x)A1(x) f A2. This lemma can be used to localise non-local \nderivations by quan\u00adtifying away colored constants that result in mixing colors. THEOREM 4.2. Given two \nformulas R and B such that R . B and all the colored symbols of R and B are uninterpreted constant symbols. \nThen any proof . of R . B can be translated into a local proof .l. PROOF. Let us take a non-local refutation \n. of R . B. This means, that . contains at least one inference that violates condi\u00adtions (L1)-(L2) of \nDe.nition 3.3. The proof is by induction on .. We will eliminate all color con.icts one by one, starting \nfrom the bottom of the proof. Thus, for every con.icting inference, we can assume that the derivation \nbelow it is already local. In particular, the conclusion of the violating inference cannot mix colors. \nCon\u00adsider the case when the conclusion is blue (other cases are similar). Then the violating inference \nhas the form R1 \u00b7\u00b7\u00b7 Rn A1 \u00b7\u00b7\u00b7 Am , A where A, A1,...,Am are either grey or blue and R1,..., Rn are red. \nLet r1,...,rk be all the red constants occurring in this inference and formulas Ri ' are obtained from \nRi by replacing r1,...,rk by fresh variables x1,...,xk. Note that all of the R ' i are either grey or \nblue. The above non-local inference can then be replaced by: (.x1 ...xk)(R1 ' . ... . R ' ) A1 \u00b7\u00b7\u00b7 Am \nn , A This inference does not contain the red color, and we are done. Note that the premises of the formula \n(.x1 ...xk)(R ' 1 . ... . R ' ) are n given by the union of the premises of R1,..., Rn. The correctness \nof the transformation is guaranteed by Lemma 4.1. The above transformation can also be applied on inferences \nwhere a premise contains both a red and a blue symbol. The non\u00adlocal inference is replaced by a local \ninference at the cost of using existential quanti.ers over the premise with colored symbols. 0 This theorem \ngives us an algorithm for changing any non-local refutation to a local one, provided that the condition \non colored symbols is satis.ed. Figure 1 illustrates how the non-local proof given in Figure 1(a) is \ntranslated into the local proof listed in Figure 1(b). 5. Playing in the Grey Area This section presents \nthe main idea of this paper. It is based on the following observation. One can change, sometimes considerably, \nthe grey areas (that is, areas consisting of grey formulas) of the proof without violating locality. \nIn addition, such proof transfor\u00admations can change the extracted interpolant. We will only consider \none kind of proof transformations, called here grey slicing. Other proof transformations can be proposed \nas well, but are beyond the scope of this paper. DEFINITION 5.1 (Grey slicing). Consider any derivation \n. con\u00adtaining a subderivation . of the form An+1 \u00b7 \u00b7 \u00b7 Am A1 \u00b7 \u00b7 \u00b7 An A , A0 (1) where n = 0. We say \nthat a derivation . ' is obtained from . by slicing off A in . (or simply, slicing off A) if . ' is obtained \nfrom . by replacing the subderivation . by A1 \u00b7\u00b7\u00b7 An An+1 \u00b7\u00b7\u00b7 Am A0 (2) When A is a grey formula, we \nwill refer to this transformation as grey slicing. 0 Apparently, grey slicing preserves properties (RB1)-(RB2) \nof De.nition 3.2, so it transforms an RB-derivation into an RB\u00adderivation. It is also easy to see that \ngrey slicing can violate the locality conditions (L1) of De.nition 3.3. For example, slicing off G1 in \nR0 B0 G1 G0 yields a non-local derivation B0 R0 . G0 Consider now an example showing that grey slicing \ntransforma\u00adtions can change the digest, and hence the extracted interpolant.  (.x1)(p(x1) . q(x1,r1)) \n\u00acp(b1)(.x2)(s(x2) .\u00acq(x2,r1)) \u00acs(b1)(.x1)(p(x1) . q(x1,r1)) (.x2)s(x2) .\u00acq(x2,r1)  q(b1,r1) \u00acq(b1,r1)(.y)(.x1)(p(x1) \n. q(x1,y)) . (.x2)(s(x2) .\u00acq(x2,y))\u00acp(b1)  . (.y)q(b1,y) . (.x2)(s(x2) .\u00acq(x2,y))\u00acs(b1) (.y)q(b1,y) \n.\u00acq(b1,y) . (a)(b) Figure 1. Proof localisation of proof (a) into proof (b). EXAMPLE 5.2. Take the following \nrefutation .: R1 G1 B1 G2 G3 G4 G5 R3 G6 R4 G7 . The digest of this refutation is {G4,G7} and the extracted \nreverse interpolant is G4 . G7. Slicing off G4 in . results in the refuta\u00adtion .1: R1 G1 G3 B1 G2 G5 \nR3 G6 R4 G7 . with the digest {G5,G7} and the extracted reverse interpolant G5 . G7. Slicing off now \nG5 in .1 results in .2: R1 G1 G3 B1 G2 R3 G6 R4 G7 . with the digest {G6,G7} and the extracted reverse \ninterpolant G6 . G7. We can slice off G7 in .2 and obtain the refutation: R1 G1 G3 B1 G2 R3 G6 R4 . with \nthe digest {G6}, and the reverse interpolant \u00acG6. However, if we slice off G3 in the original derivation \n., we obtain the refutation: B1 G2 R1 G1 G4 G5 R3 G6 R4 G7 . in which slicing off G4 would violate the \nlocality of the resulting refutation. Example 5.2 gives us the following observations: 1. grey slicing \ncan change the extracted interpolant, and some\u00adtimes considerably (compare G4 . G7 and \u00acG6). 2. a grey \nslicing step can prevent other grey slicing steps, thus preventing previously possible interpolants. \n The main question we are going to answer in this section is how to use grey slicing to obtain smaller, \nand even minimal, in some sense, interpolants. To this end we will use the following ideas. First, we \nwill introduce a set V. of propositional variables express\u00ading some properties of refutations obtained \nby grey slicing from a given proof .. Next, we will de.ne propositional formulas P. of the variables \nV. that express locality. Thus, every refutation ob\u00adtained from . by grey slicing is local if and only \nif it satis.es P.. This means we can use a SAT solver to compute all local refuta\u00adtions that can be obtained \nfrom . by grey slicing. Finally, we in\u00adtroduce propositional formulas expressing the digest of refutations. \nThis set of propositional formulas allows us to use an SMT solver or a pseudo-boolean optimisation tool \nto .nd refutations minimis\u00ading the digest in various ways. Let us now formalise this idea. In the rest \nof this section, when we speak about a formula from a derivation, we will normally mean a concrete node \nin the derivation containing this formula (note that a tree-like derivation may contain more than one \nnode with the same formula). Later we will also discuss derivations in the dag form. Nonetheless, for \nsimplicity, for the moment we prefer to deal with trees instead of dags. The .rst thing to note is that \nevery derivation is also a set of nodes occurring in it and slicing off simply removes one node from \nthis set. This means that a sequence of slicing off transformations removes a subset of nodes. Every \nremoved node G, at the point of removal, is replaced by a set of other nodes occurring in the derivation \n(namely, the premises of G at that point). Each of the nodes in this set can in turn be removed (and \nreplaced by other nodes) etc., so eventually the place of any removed node will be taken by a set of \nnodes occurring in the .nal derivation. We will call this set a trace of F and de.ne it formally below. \nDEFINITION 5.3 (Trace). Let S =.0,..., .k be a sequence of derivations such that each member in the sequence \nexcept .0 is obtained by slicing off a single grey node from the previous one. For every grey node G \nin .0 we de.ne a set of formulas, call trace of G (with respect to S), as follows: 1. If G was never \nsliced off, that is, it occurs in .k, then def trace(G)= {G}. 2. Suppose G was sliced off at some point, \nthat is, G is the formula def A as in De.nition 5.1. Then trace(G)= trace(An+1) . ... . trace(Am). Denote \nany sequence S of slicing off transformations with the initial derivation . and .nal derivation . ' by \n. --+ . '. It is not hard to argue that the following lemma holds. LEMMA 5.4. The trace of a node does \nnot depend on the sequence of transformations S but only depends on the initial and the .nal derivation \nin S. That is, for every two derivations of the form . --+ . ' with the same initial derivation . and \n.nal derivation . ', and for every grey node G in ., the trace of G is the same in both derivations. \n0  In the rest of this section we will normally assume a .xed initial derivation . and various sequences \n. --+ . '. In view of this lemma we will simply speak about the trace of G in . ' . Suppose . --+ . ' \nis a sequence of transformations. Let us introduce some propositions characterising the behaviour of \ngrey nodes in . on this sequence. cs(G): G was sliced off; cr(G): the trace of G contains a red formula; \ncb(G): the trace of G contains a blue formula; cg(G): the trace of G contains only grey formulas; cd(G): \nG belongs to the digest of . ' . We de.ne the set V. of propositional variables as consisting of all \nthe variables s(G),r(G),b(G),g(G),d(G) denoting these propo\u00adsitions. Later we will add to V. more variables. \nThen, for every sequence of transformations . --+ . ' and every grey node G in ., each of the above propositions \nis either true or false on this sequence. Therefore, if we take any propositional formula built from \nthese propositions, it is also either true or false on this sequence. 5.1 Expressing the Digest Our next \naims are to write down a propositional formula that expresses that . ' is local, and also represent the \ndigest of any local refutation. To this end we will .rst introduce propositional variables and formulas \nover grey nodes, then write down further formulas of these propositions that are satis.ed when . ' is \nlocal, and .nally show that satis.ability of these propositions implies locality of . ' . Propositions \nrc and bc. Take a local derivation . with . --+ . ' . For each grey node G in . we .rst introduce the \npropositions rc(G) and bc(G) expressing that G is not sliced off and is a conclusion of a symbol-eliminating \ninference in . with at least one red (respectively, blue) premise. The propositional variables rc(G) \nand bc(G) are added to V.. We will only de.ne rc(G), since the case of bc is symmetric. Consider the \nfollowing cases depending on the inference intro\u00adducing G in .. 1. G is introduced by an inference with \nonly grey premises: G1 \u00b7\u00b7\u00b7 Gm , G We then write: rc(G) . (\u00acs(G) . (r(G1) . ... . r(Gm))). (3) The conditions \non the traces of G1,...,Gm ensure that G can be written as the conclusion of a symbol eliminating inference \nwith at least one red premise. Namely, if r(Gi) holds, then by slicing off Gi and some of the grey nodes \nfrom its derivation, G becomes the conclusion of a symbol eliminating inference with at least one red \npremise. 2. G is introduced by an inference with at least one red premise: R1 \u00b7 \u00b7 \u00b7 Rn G1 \u00b7 \u00b7 \u00b7 Gm G \n. We then have: rc(G) . \u00acs(G). (4) 3. G is introduced by an inference with at least one blue premise \nB1 \u00b7\u00b7\u00b7 Bn G1 \u00b7\u00b7\u00b7 Gm . G Due to the locality of derivations, we write: \u00acrc(G). (5) Equations (3)-(5) are \nadded to the set of propositional formulas P. over V.. Propositions rf and bf . We introduce the propositions \nrf (G) and bf (G) for every grey node G, and add the corresponding vari\u00adables to V.. These propositions \nare closely related to the de.nition of digest. The proposition rf (G) holds iff on the path from G to \nthe root of . either (i) all nodes are grey, or (ii) the .rst colored node is a blue one. Likewise, the \nproposition bf (G) expresses that on the path from G to the root of ., there exists a colored node and \nthe .rst colored node is a red one. We will only write down properties of rf , the case of bf is similar. \nWe de.ne rf inductively , starting from the root (the bottom formula) of the derivation .. 1. If the \nsuccessor of G in . is a red formula, then we write \u00acrf (G). (6) 2. If the successor of G in . is a \nblue formula, then we write rf (G). (7) 3. Finally, if the successor of G in . is a grey node G1, then \nwe write  rf (G) . (rf (G1) . bc(G1)) .\u00acrc(G1). (8) Equations (6)-(8) are added to P.. Proposition d. \nBy straightforward inspection of the de.nition of digest, it is not hard to argue that d(G) can be expressed \nas follows: d(G) . (rc(G) . rf (G)) . (bc(G) . bf (G)). (9) We add (9) to P..  5.2 Expressing Locality \nTake a local derivation . and a grey node G in it. Depending on the inference introducing G, there are \nfour possible cases: 1. G is a leaf of .; 2. G is introduced by an inference with grey premises; 3. \nG is introduced by an inference with at least one red premise; 4. G is introduced by an inference with \nat least one blue premise. In this case, due to the locality of ., all premises in the deriva\u00adtion tree \nof G are either blue or grey.  For each of these cases, we will show how to write down formulas expressing \nthat . --+ . ' results in a local derivation, that is, . ' is local. Each below listed propositional \nformulas is added to P.. General properties of grey nodes. Note that, if a node G is not sliced off, \nthen its trace is {G}, so we have g(G): \u00acs(G) . g(G). (10) We also know that a node which is sliced off \ncannot belong to the digest: s(G) .\u00acd(G). (11)  Observe that equations (10)-(11) do not make use of \nthe as\u00adsumptions that . is local. That is, (10)-(11) hold for arbitrary derivations. Further, note that \nfor local derivations the properties b, r and g are mutually exclusive. Therefore, for every grey node \nnode G we add the following properties expressing mutual exclusion: def color(G)= (b(G) . r(G) . g(G)) \n. (b(G) .\u00acr(G) .\u00acg(G)) . (12) (r(G) .\u00acb(G) .\u00acg(G)) . (g(G) .\u00acr(G) .\u00acb(G)). G is a leaf. In this case, \nG cannot be sliced off and we have: def (13) leaf (G)= \u00acs(G) . g(G) G is introduced by an inference with \ngrey premises: G1 \u00b7\u00b7\u00b7 Gm . G The locality of . --+ . ' implies that if the trace of any G1,...,Gm contains \na red (respectively, blue) formula, then the traces of G1,...,Gm cannot contain a blue (respectively, \nred) for\u00admula. To further reason about the trace of G, consider the following cases. (i) If G is never \nsliced off in . --+ . ', then the trace of G is clearly grey. Whether G is a conclusion of a symbol eliminat\u00ading \ninference only depends on whether the trace of some of the G1,...,Gm contains either a blue or a red \nformula. (ii) If G is sliced off, then the color of the formulas in the trace of G depend on the color \nof the formulas from the traces of G1,...,Gm.  Based on the above reasoning, we introduce the following \nfor\u00admula capturing the properties of the trace of G: def grey(G)=(r(G1) . ... . r(Gm) .\u00acb(G1) . ... \n.\u00acb(Gm)) . (b(G1) . ... . b(Gm) .\u00acr(G1) . ... .\u00acr(Gm)) . (s(G) . (r(G1) . ... . r(Gm)) . r(G)) . (s(G) \n. (b(G1) . ... . b(Gm)) . b(G)) . (s(G) . g(G1) . ... . g(Gm) . g(G)) . (\u00acs(G) . g(G)). (14) G is introduced \nby an inference with at least one red premise: R1 \u00b7\u00b7\u00b7 Rn G1 \u00b7\u00b7\u00b7 Gm . G In this case the locality of . \nimplies that the trace of G can contain only red and grey formulas. Moreover, the color of the formulas \nfrom the trace of G only depends on whether G is sliced off, as follows. (i) If G is sliced off, then \nthe trace of G depends on the traces of R1,...,Rn, G1,...,Gm, and hence the trace of G contains at least \none red formula. Also note, that if G is sliced off, then G cannot belong to the digest of . ' . (ii) \nIf G is not sliced off, then trace(G)= {G}. Hence, the trace of G only contains grey formulas. Moreover, \nnote that G is the conclusion of symbol eliminating inference. Thus, G also belongs to the digest of \n. ' .  We therefore introduce the below formula for G, capturing the properties of the trace of G: def \nred(G)= \u00acb(G1) . ... .\u00acb(Gm) . (s(G) . r(G)) . (15) (\u00acs(G) . g(G)). G is introduced by an inference with \nat least one blue premise: B1 \u00b7\u00b7\u00b7 Bn G1 \u00b7\u00b7\u00b7 Gm . G Similarly to the previous case, we introduce the following \nformula: def blue(G)= \u00acr(G1) . ... .\u00acr(Gm) . (s(G) . b(G)) . (16) (\u00acs(G) . g(G)). This completes our \nconstruction of the propositional variables and formulas explained in the beginning of this section. \nNamely, the set of variables V. consists of all variable s(G), r(G), b(G), g(G), rc(G), bc(G), rf (G), \nbf (G) and d(G), and the set P. of formulas are all formulas (3) (16). Our construction clearly implies \nthe following result. THEOREM 5.5. Let . be a local derivation. Then a sequence . --+ . ' satis.es all \nformulas (8)-(16) from P. if and only if . ' is local. Moreover, the propositions r(G), b(G), g(G), rc(G), \nbc(G), rf (G), bf (G) and d(G) have their intended meaning, in particular, in every model . ' of these \nformulas G belongs to the digest of . ' if and only if d(G) holds on . ' .  5.3 Derivations as Dags \nRefutations found by theorem provers are normally dags. Trans\u00adforming a dag to a tree can result in an \nexponential growth in size. Therefore, it is desirable to change our technique to deal with dags. The \nmodi.cation is quite simple: we allow a formula in a dag to be sliced off only if all the tree derivations \ncorresponding to the result\u00ading dag are local. Note that this may result in a smaller choice of grey \nslicing transformations as compared to refutations as trees and hence larger interpolants. Nonetheless, \nexpanding dags to trees may turn to be unfeasible. Therefore, our implementation uses dags. To build \npropositional formulas expressing locality on dags, one should only modify the propositions rf (G) and \nbf (G). Propositions rf and bf for dags. The proposition rf (G) holds iff on all paths from G to the \nroot of . either (i) all nodes are grey, or (ii) the .rst colored node is a blue one. Likewise, the proposition \nbf (G) expresses that on all paths from G to the root of ., the .rst colored node is a red one. The axiomatisation \nof these propositions is given below, and (6)-(8) are replaced by the below formulas in P.. We will only \nde.ne rf , since the axiomatisation of bf is sim\u00adilar. It is de.ned inductively starting from the root \n(the bottom formula) of the derivation .. 1. Suppose at least one of the successors of G is a red formula. \nIn this case we write: \u00acrf (G). (17) 2. Otherwise, all the successors of G are either grey or blue: \n G . G1 \u00b7\u00b7\u00b7 Gm B1 \u00b7\u00b7\u00b7 Bk In this case we write rf (G) .((rf (G1) . bc(G1)) . ... . (rf (Gm) . bc(Gm)). \n(18) \u00acrc(G1) . ... .\u00acrc(Gm)).  5.4 Minimising Interpolants in Local Proofs Theorem 5.5 shows how one \nexpresses locality and digest using the propositional formulas P.. This allows us to introduce various \nmeasures of quality of interpolants and use these measures, to\u00adgether with an SMT solver, to .nd local \nproofs giving interpolants that are better in these measures.  As usual, we de.ne a clause to be a disjunction, \npossibly empty, of literals, that is, atomic formulas and their negations. Since most theorem provers \nand SMT solvers present proofs as dags of clauses, apart from some preprocessing deriving a set of clauses \nfrom R, B and the theory, we assume that the digest of a proof is a set of clauses. If such a clause \ncontains free variables, it is assumed to be implicitly universally quanti.ed. We know that the interpolant \nex\u00adtracted from a proof is a propositional combination of clauses oc\u00adcurring in this proof. If a particular \nclause is a propositional combi\u00adnation of smaller formulas, then the interpolant can be considered a \npropositional combination of these smaller formulas. The smallest formulas of this form are well-studied \nin the automated deduction community and called components. We will take a slightly modi\u00ad.ed de.nition \nof components from [23]. DEFINITION 5.6 (Component). A component of a clause C is ei\u00adther c a ground \natomic formula occurring in C, or c a non-ground clause C1 such that C has the form C1 .C2, both C1 and \nC2 are non-empty, and the only component of C1 is C1 itself. A clause C is said to be a g-atom if C is \nthe only component of itself. For example, the clause p(x) . a =2 . q(x) has two components: p(x) . q(x) \nand a =2. Note that we have the following equiva\u00adlence: .x(p(x) . a =2 . q(x)) =.x(p(x) . q(x)) .\u00ac(a \n= 2). In general, the universal closure of every clause is a boolean combination of the universal closures \nof its components. Therefore, the extracted interpolant is a boolean combinations of g-atoms, which are \ncomponents of the formulas in the digest. The problem of generating minimal interpolants can be thus \nreduced to the problem of minimising, in some sense, the set of g-atoms used in the interpolant. As minimality \nof interpolants is not well-understood, we introduce various measures for minimising the size of interpolants. \nNamely, we are interested in minimising interpolants with respect to (i) the number of g-atoms and (ii) \nthe total weight of g-atoms, counted as a number of symbols. One can also argue that ground interpolants \nare more useful than those containing quanti.ers, so in addition, when the refutation is non\u00adground, \nwe can also minimise (iii) the number of quanti.ers in the g-atoms. For doing so, we use the fact that \nthe digest of a derivation can be expressed using propositional variables d(G) over grey nodes G and \ntransform the minimisation problem to solving a pseudo\u00adboolean optimisation problem over V. as explained \nbelow. We consider a local refutation .. For every component g of a grey clause G of ., we introduce \na distinct propositional variable v(g). Intuitively, this variable will denote that g occurs in the digest \nof the transformed proof . ' . For every grey node G in ., let g1,...,gk be all g-atoms of G. We then \nintroduce the following axiom: d(G) . v(g1) . ... . v(gk). (19) In what follows, let g1,...,gm be all \ng-atoms occurring in all grey nodes of .. Let w1,...,wm be the total weights of these atoms, respectively. \nWe denote by q1,...,qm the number of quan\u00adti.ers used, respectively, in g1,...,gm. The problem of minimising \ninterpolants is then reduced to the problem of minimising (one of) the following sums: def atomcost = \nv(g1)+ ... + v(gm). (20) def weightcost = w1v(g1)+ ... + wmv(gm). (21) def quanti.ercost = q1v(g1)+ ... \n+ qmv(gm). (22) Each of these sums is expressed as a pseudo-boolean constraint over the g-atoms g1, . \n. . .gm. A solution to the minimisation problem of the left-hand side of (20)-(22) gives us a subset \nof {g1,...,gm}, such that the interpolant constructed from the boolean combinations of the formulas in \nthis subset is a smallest interpolant among all interpolants that can be extracted from the various local \n. ' resulting from grey slicing. Minimisation of atomcost gives the smallest interpolant in the number \nof distinct g-atoms. Likewise, the minimal values of weightand quanti.ercorrespond to the interpolant \nwith cost cost the smallest total weight and the smallest number of quanti.ers, re\u00adspectively. Algorithm \n1 puts together the algorithm for minimising interpolants. ALGORITHM 1. Minimising Interpolants Input: \nClosed formulas R and B such that R .\u00acB, and a refutation . from R, B. Output: Minimised interpolants \nIatom, Iweight, Iquant of R and \u00acB Assumption: All colored symbols of R and B are uninterpreted constants \n1 begin I. Proof Localisation. 2 Compute local proof .l from ., using Theorem 4.2. II. Expressing locality. \n 3 G := {},P. := {} 4 for each grey node G in .l do 5 Express d(G). Let P. := P..{(3), (4), (5), (17), \n(18), (9)}. 6 Express general properties. Let P. := P..{(10), (11), (12)}. 7 If G is a leaf, P. := P. \n.{(13)}. 8 If G is introduced by an inference with only grey premises, P. := P. .{(14)}. 9 If G is introduced \nby an inference with a red premise, P. := P. .{(15)}. 10 If G is introduced by an inference with a blue \npremise, P. := P. .{(16)}. 11 Compute G = g1 .\u00b7 \u00b7\u00b7. gk, where gi are g-atoms. 12 G = G.{g1,...,gk} 13 \nendfor 14 P. := P. .{(19)} 15 endfor III. Minimising Interpolants. 16 min atomcost := {gi1 ,...,gin } \n := min{gi1 ,...,gin }v(gi) . P. gi.G 17 min weightcost := {gi1 ,...,gin } := min{gi1 ,...,gin }gi.G \nwiv(gi) . P.where wi denotes the weight of gi  18 min quantcost := {gi1 ,...,gin } := min{gi1 ,...,gin \n} gi.G qiv(gi) . P. where qi denotes the number of quanti.ers uses in gi 19 Iatom = InterpolantR,B (min \natomcost) 20 Iweight = InterpolantR,B (min weightcost) 21 Iquant = InterpolantR,B(min quantcost) 22 return \n{Iatom,Iweight,Iquant}. 23 end Algorithm 1 uses the result of Theorem 4.2 and starts with translating \nthe input refutation . of R, B into a local one .l (line 2). Note that this step is only applied when \n. is non-local, more precisely, when the non-local steps of . contain colored constants. Further, the \nset G of g-atoms from .l and the set P. of (pseudo-boolean) constraints expressing locality of .l are \nini\u00adtialised (line 3). Next, for each grey node G in .l the constraints expressing locality conditions \nover the digest and inferences of .l are constructed, (lines 5-10). Note that the propositional formulas \nrf (G) and bf (G) are expressed based on the dag-representation of proofs. The set of g-atoms of G is \nextracted and added to G (lines 11-12). Then, the property whether G is in the digest of .l is expressed \nin terms of g-atoms and added to the constraint set P. (line 14). As a result of these steps, at the \nend of line 15 of Al\u00adgorithm 1, the constraint set P. is expressed as a set of clauses ensuring the locality \nof .l (Theorem 5.5). Next, minimal inter\u00adpolants wrt to the number of g-atoms (line 16), the total weight \nof g-atoms (line 17), and the number of quanti.ers in the g-atoms (line 18) are derived by solving a \npseudo-boolean optimisation problem over g-atoms. To this end, the interpolation procedure InterpolantR,B \n(... ) of [18] is called to generate interpolants as boolean combinations of the derived minimal set \nof g-atoms (lines 19-21). THEOREM 5.7. Algorithm 1 is correct. That is, given two formulas R and B and \na refutation ., Algorithm 1 returns the minimal interpolants of R and \u00acB wrt the imposed measures (20)-(22) \namong all interpolants extracted from proofs obtained by grey slicing of .. We next show that .nding \nminimal interpolants by Algorithm 1 is NP-hard. THEOREM 5.8. Given two formulas R and B and a refutation \n. of R, B ... Extracting a minimal reversed interpolant from . by grey slicing is an NP-hard optimisation \nproblem. PROOF. We use a reduction from .nding a maximal independent set of a graph G(V, E) with a set \nof vertices V = {v1,...,vm}and a set of edges E = {(u1,w1),..., (un,wn)}, which is known to be NP-hard. \nTo ful.l conditions of Theorem 2.2, we .rst .x a background theory T . For each vertex v . V we introduce \na propositional grey variable, also denoted by v, of weight 1. Further, for each edge (u, v) . E we add \nu . v to the theory T . Introduce also a blue propositional variable b and a red proposi\u00adtional variable \nr. De.ne B to be the blue formula v1 .\u00b7\u00b7\u00b7. vm . b and R to be the red formula \u00acv1 .\u00b7 \u00b7\u00b7.\u00acvm . r. Further, \nfor each edge (u, w) . E we introduce the following derivation .u,w: B u w Note that this derivation \nis sound in the underlying theory T . We next construct the proof tree . to be: Table 1. Minimisation \nresults on 6577 TPTP problems with non\u00adtrivial interpolants. BB u1 un w1 ... wn R . where the weight \nof . is considered to be zero. Observe that . is a valid refutation of R, B. Also note that building \na minimal interpolant from . reduces to .nding a derivation . ' obtained from . by grey slicing with \na minimal number of g-atoms. Let . ' be any derivation obtained from . by grey slicing. Denote by D ' \nthe digest of . '. For every edge (u, w) . E, the subderivation .u,w either remains a subderivation of \n. ' , or u gets sliced off. In the .rst case we have u . D ', in the second case w . D '. Therefore, \neither u . V - D ' , or w . V - D ', which implies that V - D ' is an independent set. Using similar \narguments, one can prove that every independent set S of vertices is a subset of V - D ' for some digest \nD ' of a derivation obtained from . by grey slicing. As each set V -D ' is an independent set as well, \nfor every maximal independent set S there exists a digest D ' such that S is equal to V -D '. Therefore \n.nding a digest of the minimal size is equivalent to .nding a maximal independent set. 0 Let us .nally \nnote that our method can be extended with other proof transformations and optimisation criteria (e.g., \n[9, 16]), to improve the quality of interpolants. For example, many approaches use templates to identify \npredicates desirable to be used in invari\u00adants or interpolants. Algorithm 1, thanks to its generality, \ncan easily be modi.ed to give preference to predicates matching prede.ned templates. We therefore believe \nthat our method is of an indepen\u00addent value, since one can .rst minimise the interpolant and then try \nto make it semantically better using other methods. Another impor\u00adtant feature of our algorithm is that \nit optimises the proof globally: that is, the optimal solution is not necessarily a sum of optimal so\u00adlutions \ngiven by local proof transformations. We believe this a very essential property of the algorithm not \nshared by other known ap\u00adproaches to minimising interpolants. 6. Experimental Results 6.1 Implementation \nWe implemented our interpolant minimisation method in C++ and integrated it in version 1.8 of the Vampire \ntheorem prover [24]. For minimising the set of pseudo-boolean constraints we used version 1.0.29 of the \nSMT solver Yices [10]. Due to the lack of realistic veri.cation benchmarks, that is ex\u00adamples coming \nfrom some industrial project, we evaluated our method on the following two classes of problems. First, \nwe took a collection of examples over .rst-order logic with equality from the TPTP library [25]. We minimised \ninterpolants in the .rst-order proofs generated by Vampire. Second, we considered SMT bench\u00admarks from \nthe SMT-Lib library [2] that come from bounded model checking. We analysed proofs generated by the Z3 \nSMT solver [8]. We used version 2.19 of Z3 without any modi.cation. However, for minimising interpolants \nfrom Z3 proofs, we implemented a parser for processing and translating Z3 proofs into local proofs. To \nthis end, we used our algorithm for proof localisation (see proof of The\u00adorem 4.2).  0 < 5 5 - 9 10 \n- 19 20 - 49 50 - 99 100 - 199 = 200 Before 3055 530 1099 1578 2035 991 260 84 After 3441 522 1225 1557 \n1882 766 166 73 0 <5 5-9 10-19 20-49 50-99 100-199 =200 Symbolspre 112 3 149 150 82 90 321 1216 Symbolspost \n112 5 168 158 56 87 323 1214 g-atoms 112 1558 303 114 9 0 0 0 Quanti.ers 464 279 291 367 394 157 123 \n48 Table 2. Number of symbols in TPTP benchmark interpolants, before and after minimisation. All experiments \nreported in this paper were carried out using a 64-bit 2.33 GHz quad core Dell server with 12 GB RAM. \n 6.2 First-Order Problems For this part of the experiments, we took a collection of .rst-order problems \nfrom the TPTP library. We started with annotating these problems with coloring information, using the \nfollowing coloring strategies. (1) We order symbols by the number of their occurrences in the problem, \nand starting with the symbols occurring the least number of times, we attempt to assign colors to them. \nA color can be assigned to a symbol if the symbol does not occur in a formula with a symbol that was \nalready assigned with the opposite color. The colors are being assigned in an alternating manner. If \nthe last assigned color was red, we .rst attempt assigning blue to the next symbol, and try to assign \nred only if this the blue color ended in an unsuccessful assignment (i.e. an input formula with two different \ncolored symbols is obtained). We stop when we have attempted to assign a color to all the symbols. (2) \nThe previous assignment strategy is more or less random. To use interpolants in a more logical way, we \nused the following idea. Typically, TPTP problems come with annotations classifying formulas from a problem \ninto axioms, conjectures and hypotheses. We have to prove the conjecture from the axioms and hypotheses. \nIt is commonly the case that axioms axiomatise some theory, so we have to prove that the hypotheses imply \nthe conjecture in the theory given by the axioms. This gives us the following way of coloring the problem \nsymbols. We assign blue color to symbols appearing only in the formulas of the conjecture (i.e. formula \nB), and red color to symbols occurring only in hypothesis (i.e. formula R). The symbols shared by the \nconjecture and the hypotheses are considered grey, as well as the symbols occurring only in the axioms. \n Local proofs for the colored TPTP problems were generated us\u00ading the interpolation mode of Vampire \n[13]. Altogether, we eval\u00aduated our minimisation method on 9632 colored TPTP examples. Out of the 9632 \nproblem instances, 3055 problems had trivial in\u00adterpolants, that is the interpolant was either T or .. \nThis left us with 6577 problems with non-trivial interpolants. We were inter\u00adested to see how our minimisation \nalgorithm performs on these problems. To this end, for each of the 6577 problems, our min\u00adimisation method \ntook the corresponding local proof generated by Vampire and derived the smallest interpolants by minimising \n(i) the number of symbols (i.e total weight) and (ii) the number of g-atoms in the interpolant. Table \n1 gives a summary on how the size of the interpolant decreases after minimisation, as compared to the \ninterpolant extracted from the original proof. Rows 1 and 2 of Table 1 show respectively the changes \nin the interpolant size af\u00adter minimising the number of symbols, respectively the number of g-atoms in \nthe interpolant. For each imposed measure, column 1 of Table 1 lists the number of examples where the \nsize of the inter\u00adpolants has decreased only by a small amount. The numbers shown in column 2 (resp. \nin column 3, column 4, and column 5) corre\u00adspond to the number of those examples whose interpolants became \n2-4 (resp. 4-6, 6-8, and more than 8) times smaller after minimisa\u00adtion. Column 6 gives the number of \nexamples whose interpolants became trivial after minimisation, even though the non-minimised interpolants \nwere non-trivial. Table 3. Minimisation results on 2123 SMT benchmarks. In Table 2 we report on the number \nof symbols in the inter\u00adpolants before (row 1) and after (row 2) minimisation. Each col\u00adumn of Table \n2 gives the number of interpolants whose number of symbols satisfy the numeric constraint given in the \n.rst cell of the column. That is, column 1 gives the number of trivial interpolants (the number of symbols \nis 0), column 2 shows the number of in\u00adterpolants with less than 5 symbols, column 3 reports shows the \nnumber of interpolants that contain between 5 and 9 symbols etc. By analysing the results of Table 1, \nwe note that for 854 (re\u00adspectively 694) examples the number of symbols (respectively, the number of \ng-atoms) of the interpolant decreased by at least a fac\u00adtor of 2. However, we also note that for 4354 \n(respectively 4971) problems out of the 6577 examples we tried minimisation did not improve the size: \nthese examples are omitted in Table 1. As the qualitative studies of interpolants is a challenging topic, \nwe believe that the experimental results reported in Table 1 show the potential of our method in generating \nbetter interpolants. In Figures 2 and 3 we show a colored proof of a TPTP prob\u00adlem before and after minimization. \nFormulas appearing in the in\u00adterpolant are given in bold, while other consequences of symbol eliminating \ninferences in italic. Red symbols in the proof are un\u00adderlined, whereas blue symbols are underbraced. \nFigures 4 and 5 show the proof before and after minimisation in a tree form. As mentioned, formulas denoted \nby R (resp. by B or G) refer to red (resp. blue or grey formulas). The formulas G814 and G41 appear in \nthe original interpolant, but when G815, G45 and G41 are sliced off by the minimisation algorithm, the \nnew interpolant formulas are G853 and G86. This is because the formula G853 is eliminating red symbols \nfrom the premises it received as a result of the slicing. The formula G86 now appears in the interpolant \nbecause it is an ances\u00adtor of a red symbol eliminating formula. Even though we still have two formulas \nin the interpolant, its size decreased because G853 is a trivial formula .. When compared to Figure 4, \nnote that the num\u00adber of grey formulas in Figure 5 has decreased due to grey slicing.  6.3 Experiments \nwith SMT Problems We used a set of SMT-Lib benchmarks coming from bounded model checking. Variables in \nthese problems correspond to state variables representing various unrolling steps of loops. These vari\u00adables \nare typically indexed by integer constants, where the integer index expresses the unrolling step to which \nthe state variable be\u00adlongs to. Translating and localising Z3 proofs. We generated proofs of SMT problems \nby using Z3. Z3 proofs are expressed in the sequent calculus, while our proof localisation and minimisation \nalgorithms work with resolution-style proofs. We therefore parsed and trans\u00adlated Z3 proofs into our \nframework by using a simple Lisp parser. To this end, we replaced conditionalised Z3 formulas of the \nform A1,...,An f F by implications (A1 . ... . An) . F . The coloring strategy we used for the SMT benchmarks \nwas as follows. Except the state variables, all other symbols were colored grey. We divided the set of \nstate variables into three parts. State variables corresponding to the middle loop unrolling step were \nleft grey, variables from earlier states were marked red and those from later states were colored blue. \nIn our experiment this coloring strategy turned out to be successful, in 95% of all examples we   853. \n. [815,86] 815. \u00ac udl(sK0,rl(sK0)) [814,45] 814. \u00ac udl(x0,rl(x1)) .\u00ac udl(x0,x1) [813,17] 813. \u00ac udl(x0,x1) \n. lcl(x0,x1) .\u00ac udl(x0,rl(x1)) [15,17] 86. udl(x0,rl(x0)) [79,49] 79. udl(x9,x7) .\u00ac udl( ptp(x7,x8),x9) \n[61,42] '-v\" 61. udl(x7, ptp(x6,x8)) .\u00ac udl(x7,x5) . udl(x5,x6) [57,33] '-v\" 57. \u00ac udl(x5, ptp(x6,x7)) \n. udl(x5,x6) [33,43] '-v\" 49. udl( ptp(rl(x3),x4),x3) [38,43] '-v\" 45. udl(sK0,rl(rl(sK0))) [30,41] 43. \n\u00ac udl( ptp(x1,x2),x1) [25,24] '-v\" 42. \u00ac udl(x0,x0) [25,27] 41. udol(sK0,rl(sK0)) [6,7] 38. udl(x0,rl(x1)) \n. udl(x0,x1) [input] 33. udl(x1,x2) .\u00ac udl(x0,x1) . udl(x0,x2) [input] 30. \u00ac udol(x0,x1) . udl(x0,rl(x1)) \n[input] 27. eld(x0,x0) [input] 25. \u00ac udl(x0,x1) .\u00ac eld(x0,x1) [input] 24. eld( ptp(x1,x0),x1) [input] \n'-v\" 17. \u00ac lcl(x0,x1) [input] 15. \u00ac udl(x0,x1) . lcl(x0,x1) .\u00ac udl(x0,rl(x1)) . lcl(x0,rl(x1)) [input] \n7. \u00ac edol(sK0,rl(sK0)) [input] 6. udol(x0,x1) . edol(x0,x1) [input] Figure 2. Proof of the GEO269+3 problem \nfrom the TPTP library. tried input formulas have been translated into formulas colored by at most one \ncolor. However, the usage of colors yielded non-local Z3 proofs in more than 90% of all examples we tried. \nWe translated non-local Z3 proofs into local ones by applying our proof localisation algorithm. To this \nend, we always used existential quanti.cation to eliminate red symbols from non-local inferences. As \nthe size of generated interpolants depends on the introduced quanti.ed formulas, we believe that a dynamic \nanalysis over the colored symbols to be eliminated, for example eliminate blue symbol instead of a red \none, is an interesting topic for further examination. The result of proof localisation was further used \nto minimise interpolants. Minimising local SMT proofs. Altogether, we used 4347 SMT benchmarks. Out of \nthese 4347 examples, we generated inter\u00adpolants for 2123 problems. We analyse these interpolants below \nand summarize our results in Table 3. The remaining 2224 SMT problems we could not fully process. This \nwas due to a 60s time limit which we imposed as the pro\u00adcessing time of one problem, including proof \ntranslation, coloring and localisation. In 102 cases the run was terminated by reaching the time limit \nin translating and coloring Z3 proofs, in 1580 cases the timeout was reached in the proof localisation \nphase, and for 542 benchmarks the time limit was reached during the minimiza\u00adtion phase (in constructing \nand minimising the set of propositional formulas). Among the 2123 interpolants, 112 interpolants were \ntrivial, and 1659 contained existential quanti.ers introduced by proof locali\u00adsation. The number of symbols \nin the interpolants was decreased by our minimisation algorithm for 331 interpolants, out of which 14 \ninterpolants had a decrease by more than two times. The num\u00adber of g-atoms in the interpolant decreased \nfor 83 interpolants, whereas the number of quanti.ed variables was minimised for 7 853. . [814,86,30,6,7] \n814. \u00ac udl(x0,rl(x1)) .\u00ac udl(x0,x1) [813,17] 813. \u00ac udl(x0,x1) . lcl(x0,x1) .\u00ac udl(x0,rl(x1)) [15,17] \n86. udl(x0,rl(x0)) [79,49] 79. udl(x9,x7) .\u00ac udl( ptp(x7,x8),x9) [61,42] '-v\" 61. udl(x7, ptp(x6,x8)) \n.\u00ac udl(x7,x5) . udl(x5,x6) [57,33] '-v\" 57. \u00ac udl(x5, ptp(x6,x7)) . udl(x5,x6) [33,43] '-v\" 49. udl( \nptp(rl(x3),x4),x3) [38,43] '-v\" 43. \u00ac udl( ptp(x1,x2),x1) [25,24] '-v\" 42. \u00ac udl(x0,x0) [25,27] 38. udl(x0,rl(x1)) \n. udl(x0,x1) [input] 33. udl(x1,x2) .\u00ac udl(x0,x1) . udl(x0,x2) [input] 30. \u00ac udol(x0,x1) . udl(x0,rl(x1)) \n[input] 27. eld(x0,x0) [input] 25. \u00ac udl(x0,x1) .\u00ac eld(x0,x1) [input] 24. eld( ptp(x1,x0),x1) [input] \n'-v\" 17. \u00ac lcl(x0,x1) [input] 15. \u00ac udl(x0,x1) . lcl(x0,x1) .\u00ac udl(x0,rl(x1)) . lcl(x0,rl(x1)) [input] \n7. \u00ac edol(sK0,rl(sK0)) [input] 6. udol(x0,x1) . edol(x0,x1) [input] Figure 3. Transformed proof of Figure \n2 by slicing off formulas using weight minimization. interpolants. Table 3 shows the distribution of \nthe number of sym\u00adbol occurring in interpolants before (row 1) and after minimization (row 2). The distribution \nof the number of g-atoms (row 3) and quanti.ers (row 4) in interpolants is shown only before minimiza\u00adtion, \nbecause the effect of minimisation on these values was not sig\u00adni.cant. Each column of Table 3 gives \nthe number of interpolants whose number of size/g-atoms/quanti.ers are bounded by the nu\u00admeric value \ngiven in the .rst cell of the column. That is, for exam\u00adples, the number of symbols in 168 (row 2, column \n3) interpolants is between 5-9 after minimisation. The numbers given in column 1 of Table 3 correspond \nto the number of trivial interpolants. The experiments show that our minimisation algorithm is not very \nef.cient on this benchmark suite compared to the .rst-order benchmarks. We believe that the problem is \nnot in the method but in the way Z3 produces proofs (since the produced proofs were not intended for \ninterpolation). It was often the case that the proofs contained very large formulas, sometimes mixing \ncolors in these formulas. The formulas are then quanti.ed by other algorithm and cannot further be removed \nfrom the proof, thus spoiling the minimi\u00adsation statistics. These formulas are normally large conjunctions \nor if-then-else expressions, which can also be represented as conjunc\u00adtions and could have been split \ninto smaller ones. This would not only replace large formulas by smaller one, but also improve col\u00adoring \nof proofs and reduce (or eliminate) the necessity to quantify formulas in them. We believe that our technique \nwill work very well if SMT solvers are modi.ed to obtain proofs of a better qual\u00adity. Moreover, once \na proof is found, post processing can also be done and one may try to change non-local parts of the proof \nagain by theorem proving. 7. Related Work Interpolation has a number of application in formal veri.cation, \nranging from approximating the set of reachable sets in predicate abstraction [14, 16] to invariant generation \nof loops [21]. Formal veri.cation thus crucially depends to which extent good inter\u00adpolants can be automatically \ngenerated.  G25 B24 B43 G33 R6 R7 R15 R17 B57 G33 G25 G27 G25 B24 G41 G30 R813 R17 B61 G42 B43 G38 G45 \nG814 B79 B49 G815 G86 G853 Figure 4. Proof tree for Figure 2. General criteria for comparing interpolants \ncan be de.ned by the logical strength of the interpolant, see e.g. [9, 16]. The ap\u00adproach described in \n[16] reorders the sequence of resolution steps in a proof to strengthen the derived interpolants. The \nmain heuris\u00adtic used for proof transformation is to make resolution steps on red/blue variables before \nthose on grey variables. The work of [9] extends [16] and gives a theoretical investigation on the logi\u00adcal \nstrength of propositional interpolants extracted from resolution proofs. The approach uses the notion \nof labeling functions, which essentially label literals by red, blue or grey labels. The differences \namong the labeling functions come from how grey literals are la\u00adbeled (red, blue, or grey). The strength \nof the various labeling func\u00adtions is compared, and weaker or stronger interpolants are derived by changing \nthe deployed labeling functions and swapping some nodes in the derivation. Examples of [9] emphasise \nthat weaker interpolants might lead to better performance, whereas experimental results of [16] show \nthat stronger interpolants can speed up the convergence of a soft\u00adware model checker based on predicate \nabstraction. Optimising in\u00adterpolants by only using the logical strength of the interpolant as a selection \ncriteria is thus not always the best way to go in designing ef.cient interpolation algorithms. The logical \nstrength of the interpolant is also evaluated in [14, 21], in the context of veri.cation of programs \nwith loops. Although one can derive various program properties by unwinding loop itera\u00adtion, the resulting \nset of program properties is a diverging sequence of non-inductive formulas. In [14] interpolants are \ngenerated by searching the proof space and avoiding divergence by deeper un\u00adwindings of loop iterations. \nThe method is further extended in [21] to infer quanti.ed interpolants. It is shown that by bounding \nthe behavior of the interpolating prover (e.g. delaying inferences over colored or grey symbols), divergence \nis prevented and an induc\u00adtive invariant is eventually produced from quanti.ed interpolants. A somehow \nrelated approach is presented in [13, 18], where quan\u00adti.ed interpolants are extracted from .rst-order \nlocal proof. These techniques generate interpolants by taking the boolean combina\u00adtions of the grey conclusions \nof the largest colored subderivations. The works of [4, 5, 11, 19] evaluate the quality of interpolants \nby using, in some sense, a different selection criteria. These meth\u00adods are motivated to generate interpolants \nthat are small in the num\u00adber of their components, and describe interpolation procedures for the theory \nof linear integer arithmetic w/o uninterpreted function and predicate symbols. The approach of [4] computes \nground inter\u00adpolants that are exponential in the size of the proofs. The method is improved in [19] by \nrestricting the logical power of the inter\u00adpolating prover, and is further extended in [5] by handling \nunin\u00adterpreted function and predicate symbols. To this end, [5] shows that quanti.ed interpolants are \nneeded. However, by using guarded quanti.ers and divisibility predicates, the quanti.ed interpolants \ncan be translated into equivalent quanti.er-free formulas. A similar problem is addressed and solved \nin [11], where ceiling functions are used to avoid quanti.ed interpolants and generate quanti.er\u00adfree \ninterpolants of quanti.er-free formulas in linear integer arith\u00admetic. Ceiling functions are handled \nin the interpolating prover by replacing every non-variable ceiling term by a fresh integer vari- G25 \nB24 B43 G33 B57 G33 G25 G27 G25 B24 R15 R17 B61 G42 B43 G38 R813 R17 B79 B49 R6 R7 G30 G814 G86 G853 \nFigure 5. Proof tree for the minimized proof of Figure 3. able. Inequality constraints over the newly \nintroduced integer vari\u00adables are added to capture the semantics of ceiling terms. Whereas [4, 5, 11, \n19] show good performance on experiments, due to the lack of realistic benchmarks, it is hard to draw \nbroad conclusions whether the interpolants generated by these works are the best in size and expressiveness. \nContrary to all aforementioned works, we de.ne a set of pseudo-boolean constraints over the grey formulas \nof the proof. Any solution to this set of constraints gives a different interpolant, and any interpolant \ncan be expressed as a solution of the constraint set. The proof transformations carried out in our approach \nuse only slicing off formulas that are logical consequences of other formu\u00adlas. Furthermore, we evaluate \nthe logical strength of interpolants by minimising the size, the total weight and the number of quan\u00adti.ers. \nUnlike [4, 5, 9, 11, 14, 16, 19], our method can generate and minimise interpolants of quanti.ed formulas. \nWhen compared to [13], our experiments show that we get better interpolants then the ones of [13] extracted \nfrom the largest colored subderivations. More generally spoken, our minimisation algorithm can be applied \nto any input proof, provided that the input proof can be translated into an equivalent local proof. A \nspecial case of such proofs are those whose only colored symbols are uninterpreted constants. Al\u00adthough \nsuch a condition might sound severe, it turns out that in practice a large class of examples satisfy \nthis imposed restriction: interpolation benchmarks in the combined theory of uninterpreted functions, \npredicates and linear integer arithmetic coming from the SMT community satisfy this coloring constraint \n[4, 5, 11, 19]. 8. Conclusion We described how interpolants extracted from arbitrary proofs can be obtained \nand minimised in various ways giving smaller inter\u00adpolants. Our method (1) takes an arbitrary refutation \nproof, (2) translates it into a local one, provided that all colored symbols are uninterpreted constants, \n(3) applies minimisation based on analysis of grey areas in the refutation, and (4) computes a minimal \ninter\u00adpolant by using pseudo-boolean optimisation. Our method is very general and can be used with any \ntheory and in conjunction with any theorem prover that outputs refutation proofs of interpolation problems. \nThe evaluation of our method on .rst-order and SMT bounded model checking benchmarks shows that, in many \ncases, minimisation considerably decreases the inter\u00adpolant size. We intend to integrate our method into \nconcrete veri.cation tools and evaluate our approach on more realistic veri.cation benchmarks. An interesting \nquestion we plan to address in the future is how the quality of minimised interpolants effects the ef.\u00adciency \nof interpolation-based veri.cation methods. Using a highly optimised pseudo-boolean solver instead an \nSMT solver is left for further experiments. We believe that our method opens a new avenue on research \nin interpolation-based methods. Indeed, other proof transformation methods can be used as well. For example, \nwe can quantify away not only red, but sometimes also blue symbols or slice off colored formulas. In \naddition, as we pointed out in Section 6 better proofs can considerably improve the quality of interpolants. \n Acknowledgments We acknowledge funding from the University of Manchester and an EPSRC Path.nder grant \n(Hoder), the FWF Hertha Firnberg Re\u00adsearch grant T425-N23 and the FWF National Research Network RiSE \nS11410-N23 (Kov\u00b4 acs), and an EPSRC grant (Voronkov). References [1] L. Bachmair and H. Ganzinger. Resolution \ntheorem proving. In A. Robinson and A. Voronkov, editors, Handbook of Automated Reasoning, volume I, \nchapter 2, pages 19 99. Elsevier Science, 2001. [2] C. Barrett, A. Stump, and C. Tinelli. The Satis.ability \nModulo Theories Library (SMT-LIB). www.SMT-LIB.org, 2010. [3] D. Beyer, T. A. Henzinger, and G. Th\u00b4eoduloz. \nLazy Shape Analysis. In Proc. of CAV, pages 532 546, 2006. [4] A. Brillout, D. Kroening, P. R\u00a8ummer, \nand T. Wahl. An Interpolating Sequent Calculus for Quanti.er-Free Presburger Arithmetic. In Proc. of \nIJCAR, pages 384 399, 2010. [5] A. Brillout, D. Kroening, P. R\u00a8ummer, and T. Wahl. Beyond Quanti.er-Free \nInterpolation in Extensions of Presburger Arithmetic. In Proc. of VMCAI, pages 88 102, 2011. [6] A. Cimatti, \nA. Griggio, A. Micheli, I. Narasamdya, and M. Roveri. Kratos -A Software Model Checker for SystemC. In \nProc. of CAV, pages 310 316, 2011. [7] W. Craig. Three uses of the Herbrand-Gentzen Theorem in Relating \nModel Theory and Proof Theory. Journal of Symbolic Logic, 22(3):269 285, 1957. [8] L. de Moura and N. \nBjorner. Z3: An Ef.cient SMT Solver. In Proc. of TACAS, pages 337 340, 2008. [9] V. D Silva, D. Kroening, \nM. Purandare, and G. Weissenbacher. Interpolant strength. In Proc. of VMCAI, pages 129 145, 2010. [10] \nB. Dutertre and L. de Moura. A Fast Linear-Arithmetic Solver for DPLL(T). In Proc. of CAV, pages 81 94, \n2006. [11] A. Griggio, T. T. H. Le, and R. Sebastiani. Ef.cient Interpolant Generation in Satis.ability \nModulo Linear Integer Arithmetic. In Proc. of TACAS, pages 143 157, 2011. [12] T. A. Henzinger, R. Jhala, \nR. Majumdar, and K. L. McMillan. Abstractions from Proofs. In Proc. of POPL, pages 232 244, 2004. [13] \nK. Hoder, L. Kovacs, and A. Voronkov. Interpolation and Symbol Elimination in Vampire. In Proc. of IJCAR, \npages 188 195, 2010. [14] R. Jhala and K. L. McMillan. A practical and complete approach to predicate \nre.nement. In Proc. of TACAS, pages 459 473, 2006. [15] R. Jhala and K. L. McMillan. Array Abstractions \nfrom Proofs. In Proc. of CAV, pages 193 206, 2007. [16] R. Jhala and K. L. McMillan. Interpolant-Based \nTransition Relation Approximation. Logical Methods in Computer Science, 3(4), 2007. [17] D. Kapur, R. \nMajumdar, and C. G. Zarba. Interpolation for Data Structures. In SIGSOFT FSE, pages 105 116, 2006. [18] \nL. Kovacs and A. Voronkov. Interpolation and Symbol Elimination. In Proc. of CADE, pages 199 213, 2009. \n[19] D. Kroening, J. Leroux, and P. R\u00a8ummer. Interpolating Quanti.er-Free Presburger Arithmetic. In Proc. \nof LPAR-17, pages 489 503, 2010. [20] K. L. McMillan. An Interpolating Theorem Prover. Theor. Comput. \nSci., 345(1):101 121, 2005. [21] K. L. McMillan. Quanti.ed Invariant Generation Using an Interpolat\u00ading \nSaturation Prover. In Proc. of TACAS, pages 413 427, 2008. [22] R. Nieuwenhuis and A. Rubio. Paramodulation-based \ntheorem proving. In Handbook of Automated Reasoning, volume I, chapter 7, pages 371 443. 2001. [23] A. \nRiazanov and A. Voronkov. Splitting without Backtracking. In Proc. of IJCAI, pages 611 617, 2001. [24] \nA. Riazanov and A. Voronkov. The Design and Implementation of Vampire. AI Communications, 15(2-3):91 \n110, 2002. [25] G. Sutcliffe. The TPTP Problem Library and Associated Infrastruc\u00adture. J. Autom. Reasoning, \n43(4):337 362, 2009.  \n\t\t\t", "proc_id": "2103656", "abstract": "<p>Interpolation is an important technique in verification and static analysis of programs. In particular, interpolants extracted from proofs of various properties are used in invariant generation and bounded model checking. A number of recent papers studies interpolation in various theories and also extraction of smaller interpolants from proofs. In particular, there are several algorithms for extracting of interpolants from so-called local proofs. The main contribution of this paper is a technique of minimising interpolants based on transformations of what we call the \"grey area\" of local proofs. Another contribution is a technique of transforming, under certain common conditions, arbitrary proofs into local ones.</p> <p>Unlike many other interpolation techniques, our technique is very general and applies to arbitrary theories. Our approach is implemented in the theorem prover Vampire and evaluated on a large number of benchmarks coming from first-order theorem proving and bounded model checking using logic with equality, uninterpreted functions and linear integer arithmetic. Our experiments demonstrate the power of the new techniques: for example, it is not unusual that our proof transformation gives more than a tenfold reduction in the size of interpolants.</p>", "authors": [{"name": "Krystof Hoder", "author_profile_id": "81464676841", "affiliation": "University of Manchester, Manchester, United Kingdom", "person_id": "P2991392", "email_address": "krystof.hoder@gmail.com", "orcid_id": ""}, {"name": "Laura Kovacs", "author_profile_id": "81363603362", "affiliation": "TU Vienna, Vienna, Austria", "person_id": "P2991393", "email_address": "lkovacs@complang.tuwien.ac.at", "orcid_id": ""}, {"name": "Andrei Voronkov", "author_profile_id": "81100590116", "affiliation": "University of Manchester, Manchester, United Kingdom", "person_id": "P2991394", "email_address": "andrei@voronkov.com", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103689", "year": "2012", "article_id": "2103689", "conference": "POPL", "title": "Playing in the grey area of proofs", "url": "http://dl.acm.org/citation.cfm?id=2103689"}