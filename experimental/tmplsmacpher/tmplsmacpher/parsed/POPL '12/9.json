{"article_publication_date": "01-25-2012", "fulltext": "\n Probabilistic Relational Reasoning for Differential Privacy GillesBarthe BorisK\u00a8opf FedericoOlmedo \nSantiagoZanellaB\u00b4eguelin IMDEASoftwareInstitute,Madrid,Spain {gilles.barthe,boris.koepf,federico.olmedo,santiago.zanella}@imdea.org \nAbstract Differential privacy is a notion of con.dentiality that protects the privacy ofindividuals while \nallowing useful computations on their private data. Deriving differential privacy guarantees for real \npro\u00adgrams is a dif.cult and error-prone task that calls for principled approaches and tool support.Approachesbased \nonlineartypes and static analysishave recently emerged;however, anincreasing num\u00adber of programs achieve \nprivacy using techniques that cannot be analyzedbythese approaches.Examplesincludeprogramsthat aim for \nweaker, approximate differential privacy guarantees, programs thatusetheExponentialmechanism, and randomizedprogramsthat \nachievedifferentialprivacy without using any standard mechanism. Providingsupportfor reasoning abouttheprivacy \nof suchprograms hasbeen an openproblem. We report on CertiPriv, a machine-checked frameworkfor rea\u00adsoning \naboutdifferentialprivacybuilt ontop ofthe Coq proofassis\u00adtant.The central component of CertiPriv is aquantitative \nextension of a probabilistic relational Hoare logic that enables one to derive differential privacy guarantees \nfor programs from .rst principles. We demonstrate the expressiveness of CertiPriv using a number of examples \nwhose formal analysis is out of the reach of previ\u00adoustechniques.Inparticular,weprovidethe .rst machine-checked \nproofs ofcorrectness oftheLaplacian andExponential mechanisms and of the privacy of randomized and streaming \nalgorithms from the recentliterature. Categories and Subject Descriptors D.3.1 [Programming Lan-guages]:FormalDe.nitionsandTheory; \nF.3.1[Logics andMean\u00adings of Programs]: Specifyingand Verifying and Reasoning about Programs; F.3.2[Logics \nand Meanings of Programs]: Semantics ofProgrammingLanguages Operational semantics,Denotational semantics,Program \nanalysis. GeneralTerms Languages,Security,Theory,Veri.cation Keywords Coq proof assistant, differential \nprivacy, relational Hoarelogic 1. Introduction When dealing with private data one is faced with con.icting \nre\u00adquirements: on the one hand, it is fundamental to protect the pri\u00advacy of individuals; on the other \nhand, the desire is to maximize the utility of the data by mining and releasing partial or aggregate \nPermission to make digital or hard copies of all or part of this work for personal or classroomuseisgranted \nwithoutfeeprovided that copiesarenot madeordistributed forpro.tor commercial advantage andthat copiesbearthis \nnotice andthefull citation onthe .rstpage.Tocopy otherwise,torepublish,topostonservers ortoredistribute \ntolists, requiresprior speci.cpermission and/or afee. POPL 12, January25 27,2012,Philadelphia,PA,USA. \nCopyright c &#38;#169; 2012ACM978-1-4503-1083-3/12/01. . .$10.00 information, e.g.for medicalstatistics, \nmarket research, ortargeted advertising.Differentialprivacy[17]is aquantitative notion ofpri\u00advacy that \nachieves an attractive trade-off between these two con\u00ad.icting requirements:itprovides strong con.dentialityguarantees, \nyetitispermissive enoughto allowfor useful computations onpri\u00advate data. The key advantages of differential \nprivacy over alterna\u00adtivede.nitions ofprivacy areitsgood behavior under composition andits weak assumptions \naboutthepriorknowledge of adversaries. Foradiscussion of theguaranteesprovidedby differentialprivacy \nand theirlimitations, see[21,22]. As the theoretical foundations of differential privacy become well-understood, \nthere is momentum to prove privacy guarantees for real systems. Several authors have recently proposed \nmethods for reasoningaboutdifferentialprivacy onthebasis ofdifferentlan\u00adguages and models of computation, \ne.g.SQL-likelanguages[24], higher-order functional languages[29], imperative languages[9], theMapReduceframework[30], \nandI/O automata[35].The unify\u00adingbasis ofthese approaches aretwokeyresults:(i)the observation thatone \ncan achieveprivacybyperturbingthe output of adetermin\u00adisticprogramby asuitable amount of noise[17]and(ii) \ntheorems that establish privacy bounds for sequential and parallel composi\u00adtion ofdifferentiallyprivateprograms[24].In \ncombination,both resultsform thebasisfor creating and analyzingprogramsby com\u00adposingdifferentiallyprivatebuildingblocks. \nWhile approaches relying on composing building blocks ap\u00adply to an interesting range of examples, they \nfall short of cover\u00ading the expanding frontiers of differentially private mechanisms and algorithms.Examples \nthat cannotbehandledbyprevious tech\u00adniques include mechanisms that aim for weaker guarantees, such as \napproximatedifferentialprivacy[16], or randomized algorithms that achieve differential privacy without \nusing any standard mech\u00adanism[18].Dealing with such examplesrequires .ne-grained rea\u00adsoning aboutthe \ncomplex mathematical andprobabilistic computa\u00adtions that programs perform on private input data. Such \nreasoning isparticularlyintricate and error-prone, and callsforprincipled ap\u00adproaches and tool support. \nIn this paper we revisit the foundations of differential pri\u00advacy and provide a framework for .ne-grained \nreasoning about an expressive class of con.dentialitypolicies,including(approx\u00adimate) differential privacy \nand probabilistic non-interference. Our framework, coined CertiPriv, is built on top of CertiCrypt [3], \na machine-checked framework to verify cryptographic proofs in the Coq proofassistant[34]. CertiPriv goesbeyondthe \nstate-of-the-art in three fundamental aspects. First, CertiPriv takes a foundational approach that allows \nreasoningdirectly about the outcome ofprob\u00adabilistic computations. This is key to its .exibility: rather \nthan being limited to a .xed set of building blocks, one can de.ne and use arbitrary blocks. Second, \nCertiPriv allows to construct proofs from .rstprinciples.Thisiskeytoitsprecision:proofsinCertiPriv can \nrely on sophisticated machinery, without any limitation other thanbeing elaboratedfrom .rstprinciples.Third, \nCertiPriv inher\u00adits the generality of the Coq proof assistant and allows modeling and reasoning about \narbitrary domains and datatypes. This is key to its expressiveness: instead of being con.ned to a .xed \nset of datatypes, CertiPriv canbe extended ondemand(e.g. withtypes and operators for graphs). Accessorily, \nCertiPriv requires that all intermediate reasoning steps arejusti.edformally, sothatproofs can be veri.ed \nindependently and automatically by the Coq type checker.  In order to illustrate the applicability of \nCertiPriv, we present the .rst machine-checked proofs of three representative examples: (i) we prove \nthe correctness of the Laplacian and Exponential mechanisms,(ii) weprove theprivacy of a randomized approxima\u00adtion \nalgorithmfortheMinimumVertexCoverproblem[18], and (iii)we prove the privacy of randomized algorithms \nfor continual release of aggregate statistics ofdata streams[8].Takentogether, these examples demonstrate \nthe generality and versatility of our approach. The starting point of our technical development is the \nobser\u00advation that differential privacy can be construed as a quantitative 2-property [11, 33]. Informally, \na probabilistic computation c is (o,d)-differentially private iff, given two initial memories m and m \n' that are suf.ciently close, the outputdistributionsgenerated by c are related up to a multiplicative \nfactor exp(o)and an additive term d. More formally, a computation c satis.es (o,d)-differential privacy \nwith respect to a relation . on memories ifffor everypair of memories m,m ' relatedby .andfor every event \nE: [] Pr[c,m : E]= exp(o)Prc,m ' : E+ d where Pr[c,m : E]denotes the probability of event E in the dis\u00adtribution \nobtained by running c on initial memory m. This formu\u00adlation ofdifferentialprivacy is slightly moregeneral \nthan the stan\u00addard de.nition; however, the latter is recovered by letting the pre\u00adcondition . capture \nadjacency of memories, i.e. letting . relate memories at distance at most 1 for some adequate notion \nof dis\u00adtance. Our de.nition of differential privacy has two natural readings. The .rst reading is as \nan information .ow property. Indeed, if . is an equivalence relation and o = d =0, the de.nition states \nthat the output distributions obtained by executing c in two related memories m and m ' coincide, entailing \nthat an adversary who canonly observethe .naldistributionscannotdistinguishbetween the two executions. \nThe second reading of the de.nition is as a continuity property: in case . models adjacency between initial \nmemories, the de.nition states that c is a continuous mapping between metric spaces, with the understanding \nthat the universally quanti.ed inequality above provides a measure of closeness of the two outputdistributions.Inthispaper, \nweleverage onbothreadings to provide a fresh foundation for reasoning about differentially private computations. \nAs a .rst step in our formalization, we introduce the notion of a-distance. a-distance generalizes statistical \ndistance with a skew parameter a and enables us to cast (o,d)-differential privacy as a continuityproperty.Inparticular, \nweshowthat acomputation c is (o,d)-differentially private w.r.t. a pre-condition . iff d is an up\u00adper \nbound of the exp(o)-distance between the output distributions obtainedby running c on two memories m \nand m ' satisfying .. As a second step, we de.ne an approximate probabilistic Re\u00adlationalHoareLogic(apRHL),following \nBenton s seminal use of relationallogicstoreasonaboutinformation .ow[7].Judgmentsin apRHLhave theform \nc1 ~a,d c2 :. . F and capture that d is an upper bound on the a-distance of the probability distributions \ngenerated by two probabilistic programs c1 and c2, modulo relational pre-and post-conditions . and F \non program states. For the special case where F is the identity on states, c1 = c2 = c, and a = exp(o),the \nabovejudgment entails that the output distributions obtained by executing c starting from two initial \nmemories related by . are at a-distance at most d, and hence thatc is (o,d)-differentiallyprivate w.r.t. \n.. As further detailed in Section 5.2, this intuitive understanding of apRHL judgments extends to the \nimportant case where F is an equivalence relation; suchjudgmentsgeneralize simultaneously differentialprivacy \nandinformation .owand canbeused tomodel con.dentiality for a large class of adversaries, under the view \nthat the equivalence relation captures their observational capabilities. For the general case, the interpretation \nof apRHL judgments is based on the novel notion of (a,d)-lifting of relations on states to relations \non distributions. The de.nition crisply generalizes ex\u00adisting notionsfromprobabilisticprocess algebra[12,20,32] \nand enjoys good closure properties from which we derive the sound\u00adness of the apRHLlogic. Summary of \ncontributions Our contributions are twofold. On the theoretical side, we lay the foundations for reasoning \nfor\u00admally about an important and general class of approximate rela\u00adtional properties of probabilistic \nprograms. Speci.cally, we intro\u00adduce the notions of a-distance and (a,d)-lifting, and an approx\u00adimate \nprobabilistic relational Hoare logic. On the practical side, wedemonstrate the applicability of our approach \nbyproviding the .rst machine-checked proofs of differential privacy properties of fundamental mechanisms \nand complex approximation algorithms from the recentliterature. Organization of the paper The remainder \nof this paper is struc\u00adtured asfollows.InSection2weillustratethe application of our ap\u00adproachto an example \nalgorithm;Section3introduces the represen\u00adtation of distributions and basic de.nitions used in the remainder. \nSection4presentsthesemanticfoundations of apRHL,whileSec\u00adtion5presentsthe coreproof rules ofthelogic.Section6 \nreports on case studies.We surveyprior art and concludeinSections7 and8. The Coq development containing \nmachine-checked proofs of the results and examples presented here, and an extended version of this paper \nwith pencil-and-paper proofs of the key results can be obtainedfrom http://certicrypt.gforge.inria.fr/certipriv/ \n  2. IllustrativeExample In this section we illustrate the applicability of our results by ana\u00adlyzingadifferentiallyprivate \napproximation algorithmfortheMin\u00adimum(Unweighted)VertexCoverproblem[18]. A vertex cover of an undirected \ngraph G =(V,E)is a set of vertices S . V such that for any edge (v,w) . E, either v . S or w . S.TheMinimumVertexCoverproblemistheproblem \nof .nding a vertex cover S of minimal size.In theprivacy-preserving version of the problem the goal is \nto output a good approxima\u00adtion of a minimum cover while concealing thepresence or absence of edges in \nthe graph. Contrary to other optimization algorithms wheretheprivatedata onlydeterminesthe objectivefunction(i.e. \nthe size of a minimum cover), in the case of the Minimum Ver\u00adtex Cover problem the edges in the graph \ndetermine the feasible solutions.This means that noprivacy-preserving algorithm can ex\u00adplicitlyoutput \na vertex cover of sizelessthan n-1for agraphwith n vertices,for otherwise anypair of vertices absentfromthe \noutput reveals the absence of an edge connecting them. To overcome this limitation, the algorithm that \nwe analyze outputs animplicit repre\u00adsentation of a cover as a permutation of the vertices in the graph. \nThis output permutation determines an orientation of the edges in the graph by considering each edge \nas pointing towards the end\u00adpointappearing lastin thepermutation.A vertex cover can thenbe  p =[b,g,e,h,l,k,j,i,f,d,c,a] \nFigure1. Aminimum vertex cover(verticesingray) andthe cover givenbyapermutation pofthe verticesinthegraph(verticesinside \nthe shaded area).The orientation of the edgesisdeterminedby p. recovered(presumablyin aprivacy-preservingdistributed \nmanner) by takingfor each edge the vertexitpoints to(Fig.1). The algorithm thatwe study, showninFig.2,isbased \non a ran\u00addomized, albeit not privacy-preserving, approximation algorithm from[27]thatachievesaconstant \napproximationfactorof2.(Itis conjectured that no ef.cient approximation algorithm for theMin\u00adimumVertexCoverproblem \ncan achieve a constant approximation factorbetterthan2.)Theideabehindthis algorithmistoiteratively pick \na random uncovered edge and add one of its endpoints to the cover set, both the edge and the endpoint \nbeing chosen with uni\u00adform probability. Equivalently, this iterative process can be seen as selecting \na vertex at random with probability proportional to its uncovered degree. The privacy-preserving algorithm \nin Fig. 2 is obtained from this base algorithm by perturbing the distribution according to which vertices \nare sampled by a carefully calibrated weightfactorthatgrows asmoreverticesareappended totheout\u00adputpermutation.Inthealgorithminthe \n.gure,ateachiterationthe instruction v . choose(V,E,o,n,i) $chooses a vertex v from V withprobabilityproportional \nto dE(v)+wi, where dE(v)denotes thedegree of v in E and 4 n wi = on - i Putotherwise,the expression \nchoose(V,E,o,n,i)denotes thedis\u00adcretedistribution over V whosedensityfunction at x is dE(x)+wi L dE(y)+wi \ny.V Consider twographs G1 =(V,E)and G2 =(V,E.{(t,u)}) with the same set of vertices but differing in \nexactly one edge. To prove that the above algorithm is o-differentially private it is suf.cient to show \nthat the probability of obtaining a permutation p of the verticesinthegraph whentheinputis G1 differs \nat most by a multiplicative factor exp(o)from theprobability of obtaining p when the input is G2. We \nshow this using the approximate relational Hoare logic that we present in Section 5. We highlight herethekey \nstepsintheproof; amoredetailed account appearsin Section6.3. To establish the o-differentialprivacy of \nalgorithmVERTEX-COVER itsuf.ces toprove the validity of thefollowingjudgment: |= VERTEXCOVER(V,E,o)~eo \n,0VERTEXCOVER(V,E,o):. . F function VERTEXCOVER(V,E,o) 1 n .|V|; p . nil; i . 0; 2 while i<n do 3 v . \nchoose(V,E,o,n,i); $ 4 p . v :: p; 5 V . V \\{v}; E . E \\ ({v}\u00d7 V); 6 i . i+1 7 end Figure2. Adifferentiallyprivateapproximation \nalgorithmforthe MinimumUnweightedVertexCoverproblem where . def = V(1) = V(2). E(2) = E(1).{(t,u)} F \ndef = p(1) = p(2) Assertions appearingin apRHLjudgments,like . and F above, are binary relations on program \nmemories. We usually de.ne as\u00adsertions using predicate logic formulas involving program expres\u00adsions. \nWhen de.ning an assertion m1 F m2, we denote by e(1) (resp. e(2)) the value that the expression e takes \nin memory m1 (resp.m2). For example, the post-condition F above denotes the relation {(m1,m2): m1(p)= \nm2(p)}. Toprove thejudgment above, we showprivacyboundsfor each iteration of the loop in the algorithm. \nProving a bound for the i\u00adth iteration boils down to proving a bound for the ratio between theprobability \nof choosing aparticular vertexin theleft-hand side program and the right-hand side program, and its reciprocal. \nWe distinguish three different cases, and use the fact that for a graph L (V,E), y.V dE(y)=2|E| and theinequality \n1+ x = exp(x) toderive upperboundsin each case: (a) thechosenvertexisnot oneof t,u and neither t nor \nu arein p. L Pr[v(1) = x](dE(1)(x)+wi)y.V (dE(2)(y)+wi) = L Pr[v(2) = x](dE(2)(x)+wi)y.V (dE(1)(y)+wi) \n(dE(1)(x)+wi)(2|E(1)| +(n - i)wi+2) = (dE(1)(x)+wi)(2|E(1)| +(n - i)wi) () 22 = 1+ = exp (n - i)wi (n \n- i)wi Pr[v(2) = x] = 1 Pr[v(1) = x] (b) the vertex v chosen in the iteration is one of t,u. We analyze \nthe case where v = t, the other caseis similar. Pr[v(1) = t] = 1 Pr[v(2) = t] Pr[v(2) = t](wi + dE(1)(t)+1)(2|E(1)| \n+(n - i)wi) = Pr[v(1) = t](wi + dE(1)(t))(2|E(1)| +(n - i)wi +2) -1 -1 = 1+wi = 1+w0 = exp(o/4) (c) either \nt or u is already in p,in which case both executions are observationally equivalent anddo not addtotheprivacybound. \nPr[v(1) = x] Pr[v(2) = x] = =1 Pr[v(2) = x] Pr[v(1) = x]  Case(a) can occur at most (n - 2) times, while \ncase(b) occurs exactly once.Thus, multiplying thebounds over all n iterations, n-3 L Pr[VERTEXCOVER(G1,o): \np = iv]2 = exp Pr[VERTEXCOVER(G2,o): p = iv](n - i)wi i=0 = exp(o) Pr[VERTEXCOVER(G2,o): p = iv] = exp(o/4) \n= exp(o) Pr[VERTEXCOVER(G1,o): p = iv] The above informal reasoning is capturedby aproof ruleforloops \nparameterizedby aninvariant and astableproperty of theproduct stateofboth executions(i.e.a relationthatonce \nestablished remains true).We usethefollowinginvariant(notethatifpre-condition . above holds, the invariant \nis established by the initialization code appearingbefore theloop): (t . p(1). u . p(1) =. E(1) = E(2)). \n(t/. p(1). u/. p(1) =. E(2) = E(1).{(t,u)}). V(1) = V(2). p(1) = p(2) and thefollowing stableproperty: \nt . p(1). u . p(1) The application ofthisproofrule requirestoprove threejudgments aspremises, corresponding \nto each one of the casesdetailed above; wedetail theminSection6.3.  3. Preliminaries 3.1 ProbabilitiesandReals \nInthe course ofour Coq formalization, wehavefounditconvenient to reason about probabilities using the \naxiomatization of the unit interval [0,1] provided by the ALEA library of Audebaud and Paulin [1]. Their \nformalization supports as primitive operations addition, inversion, multiplication, and division, and \nproves that the unit interval [0,1] can be given the structure of a .-cpo by taking as order the usual \n= relation and by de.ning an operator sup thatcomputestheleast upperbound of monotonic [0,1]-valued sequences. \nIn order to manage the interplay between the formalizations of the unit interval and of the reals, we \nhave axiomatized an embed\u00adding/retractionpair between them andbuilt an extensive library of results about \nthe relationship between arithmetic operations in the two types, e.g.: Addition: x +[0,1] y = minR(x \n+R y,1); Inversion: -[0,1]x =1-R x; Multiplication: x \u00d7[0,1] y = x \u00d7R y; Division: if y 0, then x/[0,1]y \n= minR (x/Ry,1). = 3.2 Distributions We view a distribution \u00b5 over a set A as a function that maps a \nunit-valued random variable (a function in A . [0,1]) to its expected value[1,28]: when applied to an \nevent E . A repre\u00adsentedbyits characteristicfunction 1E : A . [0,1], \u00b5(1E)corre\u00adsponds to theprobability \nof E.When applied to an arbitrary func\u00adtion f : A . [0,1], \u00b5(f)gives the expectation of f w.r.t. \u00b5. For \ndiscretedistributions \u00b5, \u00b5(1a)corresponds to theprobability den\u00adsity of \u00b5at a, and wedenoteit using the \nshorthand \u00b5(a).The con\u00adnectionbetweendensity and expectationisgivenby thefollowing equation. L \u00b5(f)= \n\u00b5(a)f(a) a.A Formally, adistribution over Ais afunction \u00b5of type (A . [0,1]) . [0,1] together withproofs \nof the(universallyquanti.ed)properties: Monotonicity: f = g =. \u00b5f = \u00b5g; Compatibility withinverse: \u00b5(1 \n- f)= 1- \u00b5f, where 1 is the constantfunction 1; Additivelinearity: f = 1 - g =. \u00b5(f + g)= \u00b5f + \u00b5g; Multiplicativelinearity: \n\u00b5(k\u00d7 f)= k\u00d7 \u00b5f; Continuity: if F : N . (A . [0,1]) is monotonic, then \u00b5(sup F)= sup (\u00b5. F) Note that \nwe do not require that \u00b5 1 =1, and thus, strictly speaking, our de.nition corresponds to sub-probability \ndistribu\u00adtions. This provides an elegant means of giving semantics to run\u00adtime assertions andprograms \nthatdo notterminate withprobability one. We let D(A) denote the set of distributions over A and \u00b50 denote \nthe nulldistribution. Distributions can be given the structure of a monad; this monadic view eliminates \nthe need of cluttered de.nitions and proofs involving summations, and allows to give a continuation\u00adpassing \nstyle semantics to probabilistic programs. Formally, we de.ne the unit and bind operators asfollows: \ndef unit : A .D(A)= .x..f.f x bind : D(A). (A .D(B)).D(B) def .\u00b5..M..f.\u00b5(.x.M xf) = Theunit operator \nmaps x . AtotheDiracdistributionthat assigns probability1to x and 0to all other elements of A, while \nbind takes a distribution on A and a conditional distribution on B given A, and returns the corresponding \nmarginaldistribution on B. In the remainder we use thefollowing operations and relations: range P\u00b5 def \n.f.(.a.P a . fa = . \u00b5f =0 = =0) = p1(\u00b5) def bind \u00b5(.(x,y). unit x) = def p2(\u00b5)= bind \u00b5(.(x,y). unit y) \n' def ' \u00b5 = \u00b5 = .f.\u00b5f = \u00b5f The formula range P\u00b5 states that elements of A with a non-null probability \nw.r.t. \u00b5 satisfy predicate P. For a distribution \u00b5 over a product type A \u00d7 B, p1(\u00b5)(resp.p2(\u00b5))de.nes \nits projection onthe .rst(resp.second) component.Finally, = de.nes a natural order on D(A).  4. FirstPrinciples \n 4.1 SkewedDistanceofDistributions In this section we de.ne the notion of a-distance, aparameterized \ndistance between distributions. We show how this notion can be used to express o-differential privacy, \n(o,d)-differential privacy, and statisticaldistance. Webeginbyaugmentingthe standarddistancebetweentwo \nreal numbers a and b(de.nedas |a - b| = max{a - b,b- a})with a skewparameter a = 1.Namely, wede.nethe \na-distance .a(a,b) between a and bby def .a(a,b) = max{a - ab,b- aa,0} Note that .a is non-negative by \nde.nition and that .1 coincides with the standard distance between reals. We extend .a to a dis\u00adtancebetweendistributions \nasfollows. De.nition 1 (a-distance). The a-distance .a(\u00b51,\u00b52) between twodistributions \u00b51 and \u00b52 in D(A)isde.ned \nas: def .a(\u00b51,\u00b52) = max .a(\u00b51 f,\u00b52 f) f:A.[0,1]  Thede.nition ofa-distancequanti.es universally over \nall unit\u00advalued functions. The next lemma shows that for discrete distri\u00adbutions this de.nition is equivalent \nto an alternative de.nition in which quanti.cation ranges only over Boolean-valued functions, i.e. those \ncorresponding to characteristicfunctions of events. Lemma 1. For alldistributions \u00b51 and \u00b52 over adiscrete \nset A, .a(\u00b51,\u00b52)=max .a(\u00b51 1E,\u00b52 1E) E.A An immediate consequence of Lemma 1 is that .1 coincides with \nthe standard notion of statisticaldistance,i.e., .1(\u00b51,\u00b52)= max |\u00b51 1E - \u00b52 1E| E.A Differential privacy \nis a condition on the distance between the outputdistributionsproducedby a randomized algorithm.Namely, \nfor a given metric on the input space, differential privacy requires that for any pair of inputs at distance \nat most 1, the probability that an algorithm outputs a particular value differs at most by a multiplicative \nfactor exp(o). Approximate differential privacy relaxes this requirement by additionally allowing for \nan additive slack d. The following de.nition captures these requirements in terms of a-distance; Lemma \n1 establishes the equivalence to the originalde.nition[16]. De.nition 2 (Approximate differential privacy). \nLet d be a met\u00adric on A. A randomized algorithm M : A .D(B) is (o,d)\u00addifferentiallyprivate(with respect \nto d)iff '' ' .a,a . A.d(a,a )= 1=. .exp(o)(M a,M a )= d Notice that (o,0)-differential privacy corresponds \nto vanilla o\u00addifferentialprivacy[13]. Itisfolklore thatfordiscretedomains thede.nition ofdifferen\u00adtialprivacyis \nequivalent toitspointwise variant where onequanti\u00ad.es over characteristicfunctions of singleton sets \nrather than those of arbitrary sets; however, this equivalence breaks when consid\u00adering approximatedifferentialprivacy[16].Thefollowinglemma \nprovides a way to establish bounds for a-distance(and hence for approximate differential privacy) in \nterms of characteristic func\u00adtions of singleton sets.Note that theinequalityis strictingeneral. Lemma \n2. For alldistributions \u00b51 and \u00b52 over adiscrete set A, L .a(\u00b51,\u00b52)= .a(\u00b51(a),\u00b52(a)) a.A We conclude \nthis section by stating some important properties of a-distance;theseproperties are usedfor reasoning \nabout approx\u00adimateliftingandproving the soundness of ourlogic.Allproperties areimplicitly universallyquanti.ed. \nLemma 3 (Properties ofa-distance). 1. 0 = .a(\u00b51,\u00b52)= 1 2. .a(\u00b5,\u00b5)=0 3. .a(\u00b51,\u00b52)=.a(\u00b52,\u00b51) 4. .aa' \n(\u00b51,\u00b53)= a ' .a(\u00b51,\u00b52)+.a' (\u00b52,\u00b53), or else .aa' (\u00b51,\u00b53)= .a(\u00b51,\u00b52)+a.a' (\u00b52,\u00b53)  5. a = a ' =. .a' \n(\u00b51,\u00b52)= .a(\u00b51,\u00b52) 6. .a(bind \u00b51 M,bind \u00b52 M)= .a(\u00b51,\u00b52)  Most of the above properties are self-explanatory; \nwe brie.y highlight the mostimportant ones. Property(4)generalizes the tri\u00adangleinequality with appropriate \nskewfactors;(5) statesthat a\u00addistance is anti-monotonic with respect to a;(6) states thatproba\u00adbilistic \ncomputationdoes notincreasethedistance(whichis a well\u00adknownfactfor statisticaldistance). 4.2 ApproximateLiftingofRelationstoDistributions \nThelogic wepresentinthe nextsection canbe used to establish as\u00adsertions aboutprobabilisticprograms w.r.t.pre-andpost-conditions \nonstates.Inordertogivemeaningtothesejudgments, weneed to interpret post-conditions as relations between \ndistributions over states rather than as relations between states. To this end, we de\u00ad.ne the (a,d)-lifting \nof a relation to distributions. Intuitively, two distributions\u00b51 .D(A)and \u00b52 .D(B)are relatedby the (a,d)\u00adlifting \nof R . A \u00d7 B, whenever there exists a distribution over A\u00d7 B whose supportis containedin Rand whose .rst \nand second projections are atmost at a-distance d of \u00b51 and \u00b52, respectively. R=1 De.nition 3 (Lifting). \nLet a . and d . [0,1]. The (a,d)-lifting of a relation R . A \u00d7 B is a relation over D(A)\u00d7D(B)de.ned asfollows: \n. . range R\u00b5 \u00b51 ~a,d def R \u00b52 = .\u00b5. p1 \u00b5 = \u00b51 . p2 \u00b5 = \u00b52 . .a(p1 \u00b5,\u00b51)= d . .a(p2 \u00b5,\u00b52)= d We say that \na distribution \u00b5 satisfying the above conditions is a witness for thelifting. The notion of (a,d)-liftinggeneralizesprevious \nnotions oflift\u00adings, such as the lifting from [20] which is obtained by taking a =1 and d =0, and d-lifting[12,32] \nwhichis obtainedby taking a =1. The next lemma shows that (a,d)-lifting is mono\u00adtonic w.r.t. the slack \nd, the skew factor a, and the relation R. An immediate consequence is that for a> 1, (a,d)-lifting is \nmore permissive than thepreviouslyproposed notions oflifting. Lemma4. For all 1 = a = a ' and d = d ' \n, and relations R . S, \u00b51 ~a,d . \u00b51 ~a ' ,d ' \u00b52 =\u00b52 RS We nextpresentafundamentalproperty of (a,d)-lifting, \nwhich is central to the applicability of apRHL to reason about a-distance (and hence differential privacy). \nNamely, two distributions related by the (a,d)-lifting of R yield probabilities that are within a\u00addistance \nd when applied to R-related functions. We say that two functions f : A . [0,1] and g : B . [0,1] are \nrelated by a relation R . A\u00d7 B, and write f = R g, iff for every a . A and b . B, Rab implies fa = gb. \nTheorem 1 (Fundamental Propertyof Lifting). Let \u00b51 .D(A), \u00b52 .D(B), and R . A \u00d7 B. Then, for any two \nfunctions f1 : A . [0,1]and f2 : B . [0,1], \u00b51 ~a,d =. .a(\u00b51 f1,\u00b52 f2)= dR \u00b52 . f1 = R f2 Inparticular,if \nA = B and R is theidentity relation(=), \u00b51 ~a,d = \u00b52 =. .a(\u00b51,\u00b52)= d Theorem 1 provides an interpretation \nof (a,d)-lifting in terms of a-distance.Next wepresenttwo resultsthat enable usto actually construct \nsuchliftings. The .rstresultistheconverseofTheorem1forthespecial case of R being the identity relation: \nwe prove that two distributions are related by the (a,d)-lifting of the identity relation if their a\u00addistanceis \nsmallerthand.This resultis usedtoprovethe soundness of thelogic rulefor random assignmentsgivenin the \nnext section. Theorem 2. Let \u00b51 and \u00b52 be distributions over a discrete set A. If .a(\u00b51,\u00b52)= d, then \n\u00b51 ~a,d \u00b52. = The proof is immediate by considering as a witness for the liftingthedistribution with \nthefollowingdensityfunction: ' min(\u00b51(a),\u00b52(a)) if a = a ' \u00b5(a,a )= ' 0 if a = a  The second result \nshows that (a,d)-liftings compose. This re\u00adsult allowstoderive ajudgment relating twoprograms c1 and \nc2 byintroducing anintermediateprogram c andproving the validity ofjudgments relating c1 and c on one \nhand, and c and c2 on the other. This approach is used in the examples of Section 6.2, and more extensivelyin \ncryptographicproofs, see e.g.[3]. Theorem 3. Let \u00b51, \u00b52 and \u00b53 be distributions over discrete sets A, \nB, and C, respectively. Let R . A\u00d7 B and S . B \u00d7 C. For all a,a ' . R=1 and d,d ' . [0,1], ,d '' \u00b51 ~a,d \n,d ' . \u00b51 ~aa ' \u00b52 . \u00b52 ~a ' \u00b53 =\u00b53 RS R.S where d '' def max(d + ad ' ,d ' + a ' d) and . denotes relation \n= composition. For the proof, let \u00b5R and \u00b5S be witnessesfor thejudgments on the left-hand side of the \nimplication. Then, the distribution \u00b5 de.nedbythefollowingdensityfunctionis a witnessforthelifting on \nthe right-hand side: L \u00b5R(a,b)\u00b5S(b,c) \u00b5(a,c)= \u00b52(b) {b.B|\u00b52 (b) =0} We conclude this section with an \nobservation on (a,d)-lifting for equivalence relations.Jonsson,Yi, andLarsen[20] showthat for equivalence \nrelations, their de.nition of lifting coincides with the moreintuitive notion that requires the twodistributionstoyield \nequal probabilities on all equivalence classes. Formally, if R is an equivalence relation over adiscrete \nset A, then \u00b51 ~1,0 R \u00b52 .. .a . A.\u00b51 1[a] = \u00b52 1[a] where [a]denotes the R-equivalence class of a . \nA. This charac\u00adterization extends naturally to arbitrary aand d =0: \u00b51 ~a,0 R \u00b52 .. .a . A..a(\u00b51 1[a],\u00b52 \n1[a])=0 The characterization for arbitrary d is more involved and is pre\u00adsentedin the extended version. \n5. ApproximateRelationalHoareLogic This sectionintroducesthe centralcomponent of CertiPriv, namely an \napproximate probabilistic relational Hoare logic that is used to establishprivacyguaranteesofprograms.We \n.rstpresentthepro\u00adgramming language and its semantics. We then de.ne relational judgments and show that \nthey generalize differential privacy. Fi\u00adnally, wede.ne aproof systemforderiving validjudgments. 5.1 \nProgramming Language CertiPriv supports reasoning aboutprograms that are writteninthe typed,procedural,probabilisticimperativelanguage \npWHILE.For\u00admally, the set of commands isde.nedinductively by thefollowing clauses: I ::= V.E assignment \n| V.DE random sampling $ | if E then C else C conditional | while E do C whileloop | V.P(E,..., E) procedure \ncall | assert E runtime assertion C ::= skip nop |I; C sequence Here, V is a set of variable identi.ers, \nP is a set of procedure names 1, E is a set of expressions, and DE is a set of distribution 1For the \nsake of readability, we omit procedure calls from most of the exposition; we keep them in the description \nof the language because we use them to describe the algorithm SMARTSUM in Fig. 9 and modularize its analysis. \n[skip] m = unit m [i; c] m = bind ([i] m)[c] [x . e] m = unit (m {[e] m/x}) [assert e] m = if [e] m = \ntrue then (unit m)else \u00b50 [x . \u00b5] m = bind ([\u00b5] m)(.v.unit (m{v/x})) $ [c1] m if[e] m = true [if e \nthen c1 else c2] m= [c2] m if[e] m = false [while e do c] m = .f.sup(.n.[[while e do c]n] mf) where [while \ne do c]0 = skip [while e do c]n+1 = if e then c;[while e do c]n Figure3. Semantics of pWHILE programs \nexpressions. The signi.cant novelty of CertiPriv (compared to CertiCrypt), besides the addition of runtime \nassertions, is that the interpretation of distribution expressions may depend on the program state. This \nallows to express programs that sample from dynamically evolving probability distributions, such as the \none presentedinSection2. The semantics ofprogramsisde.nedintwo steps.First,wegive aninterpretation [T] \nto all object types T these are types that are declared in CertiPriv programs, such as the graph type \nin the ex\u00adample in Section 2 and we de.ne the set M of memories as the set of mappings from variables \nto values. Then, we implement de\u00adpendentlytyped evaluators thatgive the semantics of an expression e \nof type T, adistribution expression \u00b5of type T, and a command c, respectively, asfunctions of thefollowing \ntypes: [e] : M. [T][\u00b5] : M.D([T]) [c] : M.D(M) Informally, the semantics of an expression e takes a memory \nand returns a value in [T], the semantics of a distribution expression \u00b5 takes a memory and returns a \ndistribution over [T], and the semantics of a program c takes an initial memory and returns a distribution \nover .nal memories. The semantics of programs complies withthe expected equations;Figure3provides an \nexcerpt. 5.2 Validity andPrivacy apRHL is an approximate probabilistic relational Hoare logic that supports \nreasoning aboutdifferentiallyprivate computations.Judg\u00admentsin apRHL are of theform c1 ~a,d c2 :. . F \nwhere c1 and c2 are programs, . and F are relations over mem\u00adories, a . R=1 is the skew, and d . [0,1] \nis the slack. In our formalization we use a shallow embedding for logical assertions, allowing ustoinheritthe \nexpressiveness ofthe Coq language when writingpre-andpost-conditions. An apRHL judgment is valid if for \nevery pair of memories related by the pre-condition ., the corresponding pair of output distributionsis \nrelatedbythe (a,d)-lifting of thepost-condition F. De.nition4 (Validity). Ajudgment c1 ~a,d c2 :. . F \nis valid, written |= c1 ~a,d c2 :. . F,iff . ([c1] m1)~a,d .m1 m2.m1 .m2 =F ([c2] m2) Thefollowinglemmaisadirect \nconsequence of thefundamen\u00adtalproperty oflifting(Theorem1)applied toDe.nition4.It shows thatstatements \naboutprogramsderived using apRHLimplybounds on the a-distance of their outputdistributions.  Lemma 5. \nIf |= c1 ~a,d c2 :. . F, then for all memories m1,m2 and unit-valued functions f1,f2 : M. [0,1], m1 .m2 \n. f1 =F f2 =. .a([c1] m1 f1,[c2] m2 f2)= d The statement of Lemma 5 can be specialized to a statement \nabout thedifferentialprivacy ofprograms. Corollary1. Let dbe a metric on M and .an assertion express\u00ading \nthat d(m1,m2) = 1. If |= c ~exp(o),d c :. .=, then c satis.es (o,d)-differentialprivacy. Corollary1is \nthe central resultforderiving differentialprivacy guarantees in apRHL. Using Theorem 2, one can prove \nthe con\u00adverse to Corollary 1, yielding a characterization of approximate differentialprivacy. The logic \napRHL can also be used to reason about more tradi\u00adtional information-.ow properties, such as probabilistic \nnoninter\u00adference. To see this, let . be an arbitrary equivalence relation on initial states and let = \nbe the identity relation on .nal states. A judgment|= c ~1,0 c :. .= entails that two initial states \nin\u00adducethesamedistributionof .nal stateswheneverthey arerelated by ..Inparticular, thisimplies that an \nadversary who can observe (or even repeatedlysample) the output of c will onlybe able tode\u00adterminetheinitialstate \nuptoits .-equivalence class.Inthis way, . can be used for expressing .ne-grained notions of con.dentiality, \nincludingprobabilistic noninterference[31].Ourinterpretation of apRHLjudgmentsgeneralizes to arbitrary \nequivalence relations as post-conditions. In this way, one can capture adversaries that have onlypartial \nviews on the system, as required fordistributeddiffer\u00adentialprivacy[5]. We .nally show how apRHL can \nalso be used for deriving generalized Lipschitz-conditions of probabilistic programs. As a .rst step, \nwe showthat valid apRHLjudgmentsimply statements forinputdistributions that are relatedby (a,d)-lifting. \nLemma 6. If |= c1 ~a,d c2 :. . F, then for all distributions \u00b51 and \u00b52 ofinitial memories wehave: \u00b51 \n~a ' ,d ' \u00b52 =. (bind \u00b51 [c1] )~aa ' ,d+d ' (bind \u00b52 [c2]) .F By instantiating pre-and post-conditions \nin Lemma 6 to the identity relation on memories = and applying Theorems 1 and 2, one obtainsthefollowinggeneralizedLipschitz-conditionforprob\u00adabilisticprograms \non randominputs. Corollary 2. If |= c1 ~a,d c2 : =.=, then .a' (\u00b51,\u00b52)= d ' =. .aa' (bind \u00b51 [c1],bind \n\u00b52 [c2])= d+d ' 5.3 Logic This section introduces a set of proof rules to support reasoning aboutthevalidity \nof apRHLjudgments.Inordertomaximize .ex\u00adibility and to allow the application of proof rules to be interleaved \nwith other forms of reasoning, the soundness of each proof rule is proved individually as a Coq lemma. \nNevertheless, we retain the usualpresentation of the rules as aproof system. We present the core apRHL \nrules in Figure 4; all rules gener\u00adalize their pRHL counterpart, which can be recovered by setting a \n=1 and d =0. (Any valid pRHL derivation admits an im\u00admediate translationinto apRHL.)Webeginby describing \nthe rules corresponding tolanguage constructs. The [skip], [assert] and [assn] rules are direct transpositions \nof thepRHL rules.Rule[rand]states that for any two distribution expressions \u00b51 and \u00b52 oftype A,the random \nassignments x1 . \u00b51 $ $ and x2 . \u00b52 are (a,d)-related w.r.t. pre-condition . and post\u00ad condition x1(1) \n= x2(2), provided the a-distance between the distributions[\u00b51] m1 and [\u00b52] m2 is smallerthan d whenever \nm1 and m2 are related by .. The soundness of rule [rand] follows fromTheorem2. Rule[seq] has tight connections \nto composition theorems for differentially private algorithms, as further developed in Sec\u00adtion5.4. Rule[cond]states \nthat branching statements are (a,d)-related w.r.t.pre-condition . andpost-condition F,provided that thepre\u00adcondition \n. ensures that the guards of both statements are equiv\u00adalent, and that the true and false branches are \n(a,d)-related w.r.t. pre-conditions .. b(1) and ..\u00acb(1), respectively. The rule for loops may be best \nunderstood by taking d =0. In this case,the rule[while]statesthattwoboundedloopsthat execute in lockstep \nare n ln(a)-differentially private when their bodies at each iteration are ln(a)-differentially private \nand n is an upper boundfor the number ofiterations.The rule[while] is suf.cient for proving differential \nprivacy of examples like the k-median from [18], where the skew remains unchanged at each iteration. \nOther examples,like the onesdiscussedin the next section, require applying more sophisticated rules in \nwhich the skew and the slack may vary acrossiterations.Forinstance,the rule[gwhile] shown in Figure 5 \nallows for a .ner-grained case analysis depending on a predicate P on program memories whose validity \nis preserved acrossiterations.Assume that when P does nothold, theiterations of each loop can be related \nwith a privacy factor of a1(i)in case P does not hold after their execution, and with a privacy factor \nof a2 in case it does. Furthermore, assume that the iterations are observationally equivalent when P \nholds initially. Then, the two loops are related with a privacy factor of ( a1(i)) a2. i=1..n Intuitively, \nas long as P does not hold, the iterations of each loop are ln(a1(i))-differentiallyprivate, whilethe \nsingleiteration where the validity of P may be established (this occurs necessarily at the same time \nin both loops) incurs an ln(a2) privacy penalty; the remaining iterations preserve P and do not add to \nthe privacy bound. We continuebyexplainingthe structural rulesgiveninFigure4. The rule[case]allows one \nto perform a case analysis in the pre\u00adconditionof ajudgment.Theweakening rule[weak] generalizes the rule \nof consequence of(relational) Hoarelogicby allowing to increase the skew and slack;its soundness followsfromLemma4. \nThecomposition rule[comp]permits to structure proofs byintro\u00adducing intermediate programs (as in the \ngame-playing technique for cryptographic proofs [3]); its soundness follows from Theo\u00adrem 3. Together \nwith rule [transp], it yields a rule for the case when . and F arepartial equivalence relationswhich,specialized \nto a = =1, reads: a ' |= c1 ~1,d c2 :. . F |= c2 ~1,d' c3 :. . F |= c1 ~1,d+d' c3 :. . F Finally, the \n[frame] rule allows one to strengthen the pre-and post-condition with an assertion T whose validity is \npreserved by executing the commands of the judgment. (In the .gure, the notation \u00d7 is used todenote theproduct \nof twodistributions.) 5.4 SequentialandParallelCompositionTheorems Composition theorems play an important \nrole in the construction and analysis of differentially private mechanisms. A central re\u00adsult states \nthat an o-differentially private query followed by an o ' \u00addifferentially private query to the same dataset \ncorresponds to a single (o+o ' )-differentiallyprivatequery[24].Animportant vari\u00adant of this result deals \nwith the case in which both queries access disjointpartsof thedataset.Thisso-calledparallel composition \nof queries leads to a stronger, max{o,o ' }-privacy bound[24]. Both composition results admit a naturalinterpretationin \napRHL, which wepresentbelow. We begin by introducing additional notation that allows us to express independence \nof computations and observational capabil\u00adities of adversaries. For a set of variables Z .V, we de.ne \nthe  def m1 .m2 =(m1 {[e1] m1/x1})F(m2 {[e2] m2/x2}) .m1 m2.m1 .m2 =. .a([\u00b51] m1,[\u00b52] m2)= d [assn] \n$$[rand] |= x1 . e1 ~1,0 x2 . e2 :. . F |= x1 . \u00b51 ~a,d x2 . \u00b52 :. . x1(1) = x2(2) .=. b(1)= b ' (2)|= \nc1 ~a,d c2 :. . F ' |= c1 ' ~a' ,d' c2 ' :F ' . F [assert][seq] |= assert b ~1,0 assert b ' :. . .. b(1)|= \nc1;c1 ' ~aa' ,d+d' c2;c2 ' :. . F |= c1 ~a,d c1 ' :. . b(1). F |= c2 ~a,d c2 ' :. .\u00acb(1). F. =. b(1)= \nb ' (2) [skip][cond] |= skip ~1,0 skip :. . .|= if bthen c1 else c2 ~a,d if b ' then c1 ' else c2 ' :. \n. F |= c ~a,d c ' :.. b(1). b ' (2). .. b(1)= b ' (2).m1 m2.m1 .m2 =. [while bdo c] m1 = [[while bdo \nc]n] m1 [while] |= while bdo c ~an,nd while b ' do c ' :. . b(1)= b ' (2). ..\u00acb(1).\u00acb ' (2) |= c1 ~a,d \nc2 :. . T . F |= c1 ~a,d c2 :. .\u00acT . F |= c1 ~a,d c2 :. . F |= c2 ~a,d' c3 :. ' . F ' [case][comp] |= \nc1 ~a,d c2 :. . F |= c1 ~aa' ,max(d+ad' ,d' +a' d) c3 :.. . ' . F. F ' |= c1 ~a' ,d' c2 :. ' . F ' . \n. . ' F ' . F a ' = ad ' = d |= c2 ~a,d c1 :.-1 . F-1 [weak][transp] |= c1 ~a,d c2 :. . F |= c1 ~a,d \nc2 :. . F |= c1 ~a,d c2 :. . F .m1 m2.m1 Tm2 =. range T([c1] m1 \u00d7 [c2] m2) [frame] |= c1 ~a,d c2 :.. \nT . F. T Figure4. Coreproof rules of the approximate relationalHoarelogic F=. (b1(1)= b2(2). P1(1)= P2(2). \ni(1) = i(2)) .m1 m2.m1 Fm2 =. [while b1 do c1] m1 = [[while b1 do c1]n] m1 |= c1; assert (\u00acP1)~a1(j),0 \nc2; assert (\u00acP2):F . b1(1). i(1) = j .\u00acP1(1). F. i(1) = j+1 |= c1; assert (P1)~a2 ,0 c2; assert (P2):F. \nb1(1). i(1) = j.\u00acP1(1). F. i(1) = j+1 |= c1 ~1,0 c2 :F . b1(1). i(1) = j. P1(1). F. i(1) = j+1 . P1(1) \n [gwhile]|= while b1 do c1 ~.a+n while b2 do c2 :F . i(1) = a . F.\u00acb1(1) (a1(i))\u00d7a2 ,0 i=a Figure5. \nGeneralized ruleforloops . relations = Z and = Z asfollows: m ' def .y . Z. my = m ' y = Z m = . ' def \n' m = Z m = .z . Z. m = (Z\\{z}) m . Note that m = Z m ' corresponds to dZ(m,m ' ) = 1, where dZ measures \nthe number of variables in Z in which two memories differ, i.e. their Hamming distance. Using this notation, \nwe can interpretjudgments of theform . |= c ~exp(o),0 c := X . = Y as a de.nition of a computation c \non variables in X that is o\u00addifferentially private w.r.t. adversaries that can only observe vari\u00adablesin \nY.Similarly, we caninterpretjudgments of theform . |= c ~exp(o),0 c := X . = X' . = Y as ade.nition of \nafamily(indexedby X ' )of computations c on variablesin X that are o-differentiallyprivate w.r.t. adversariesthat \ncan only observe variablesin Y.To emphasize the roles of the sets X, Y, and Y ' we say that c is a computation \nfrom X to Y that is parameterizedbyY ' .Finally, weinterpretpremises of theform .. |= c ~1,0 c := X . \n= X |= c ~1,0 c := X . = X as a statement that c does not modify variablesin X.Note that this reading \nofpremisesissound,but strongerthantheactual semantics. The sequential composition theorem is a direct \napplication of rule [seq] andis capturedby the rule: .. |= c ~exp(o),0 c := X . (=Y . = X) '' . |= c \n~exp(o' ),0 c :(=Y . = X). = (Y .Y' ) '' . |= c;c ~exp(o+o' ),0 c;c := X . = (Y .Y ' ) With theintuitive \nreadingintroduced above, the rule states that the composition of an o-differentially private computation \nc from X to Y, with a parameterized o-differentially private computation c ' fromX to Y ' is an (o+o \n' )-differentiallyprivate computation c;c ' from X to Y . Y ' , provided that c ' does not modify variables \nin Y, and c does not modify variablesin X. Theparallel composition theoremis capturedby the rule: . |= \nc ~exp(o),0 c :( = X . = X' ). = (Y .X' ) .. |= c ~1,0 c :(=X . = X' ). (=Y . = X' ) '' . |= c ~exp(o' \n),0 c :(=Y . = X' ). = (Y .Y' ) '' ' |= c ~1,0 c := (Y .X' ) . = (Y .Y' ) X n X = \u00d8 '' . |= c;c ~exp(max(o,o' \n)),0 c;c := X.X' . = (Y.Y ' ) With the intuitive reading introduced above, the rule states that the composition \nof an o-differentially private computation c from X to Y, with a parameterized o-differentially private \ncomputation ''' ' c from X to Y , where X is disjoint from X,is a max(o,o ' )\u00ad ' '' differentiallyprivate \ncomputation c;c fromX. X to Y . Y .As aprerequisite we requirethat c does notmodify variablesin X ' and \nis non-interfering w.r.t. input variables X and output variables Y, and that c ' does not modify variables \nin Y and is non-interfering  w.r.t.input variables X ' and output variables Y ' . 6. CaseStudies We \nillustrate the versatility of our framework by formalizing two prominent mechanisms, namely theLaplacian \nand theExponential mechanisms, andprovingtheir correctnessfrom .rstprinciples.We then apply these mechanismstoprovedifferentialprivacyforsev\u00aderal \nstreaming algorithms. Finally, we detail the proof of differen\u00adtialprivacy of theMinimum VertexCover \nalgorithm introduced in Section2. 6.1 Exponential andLaplacianMechanisms Many algorithms for statistics \nand data mining are numeric, i.e. they return(approximations of) real numbers.TheLaplacian mech\u00adanism \nofDwork et al.[17] is afundamental toolfor making such computations differentiallyprivate. This is achieved \nby perturbing the algorithm s true output with noisedrawnfrom aLaplacedistri\u00adbution. The density function \nat x of the Laplace distribution cen\u00adtered around r with scalefactor s isproportional to () |x - r| exp \n- s To transform a deterministic computation f: A . R into a differentially private computation, one \nneeds to set r to the true output of the computation and choose s (i.e. the amount ofnoise) according \nto the sensitivity of f. Informally, the sensitivity is a Lipschitz-parameter that captures how far apart \nf maps nearby inputs. Formally, the sensitivity Sf is de.ned relative to a metric don Aasfollows: def \n' Sf = max |fa - fa | a,a ' |d(a,a ' )=1 Thejusti.cationfor theLaplacian mechanismis a result that states \nthat for a function f : A . R, the randomized algorithm that on input a returns a value sampled from \ntheLaplaciandistribution centered around f(a)with scalefactor s = Sf/oiso-differentially private[17]. \nOnelimitation of theLaplacian mechanismis thatitis con.ned to numerical algorithms.TheExponential mechanism[23]is \nagen\u00aderal mechanism for building differentially private algorithms with arbitrary (but discrete) output \ndomains. The Exponential mecha\u00adnism takes as input a base distribution \u00b5 on a set B, and a scor\u00ading function \ns : A \u00d7 B . R=0; intuitively, values b maximizing s(a,b)are the most appealing outputfor aninput a.TheExponen\u00adtial \nmechanismis a randomized algorithm that takes a value a . A and returns a value b . B that approximately \nmaximizes the score s(a,b), where thequality of the approximation isdetermined by a parameter o> 0.Formally, \ntheExponential mechanism Eo maps s,\u00b5 every elementin Ato adistributionin B whosedensityfunction at bisgivenby: \nexp(os(a,b))(\u00b5b) Eo s,\u00b5(a)b = L exp(os(a,b))(\u00b5b) b.B The de.nition implicitly assumes that the sum in \nthe denominator isboundedfor alla . A.McSherry andTalwar[23]showthat Eo s,\u00b5 is2oSs-differentiallyprivate, \nwhere Ss is the maximum sensitivity of s w.r.t. a,for all b. In our proofs, the Exponential and Laplacian \nmechanisms are de.ned as instances of a general construction (\u00b7). that takes as R=0 input a function \nf : A . B . and returns a function f. : A .D(B)such thatfor every a . Athedensity function of f. a at \nbisgivenby: . f ab fab = L f ab b.B We derive the correctness of the Laplacian and Exponential mechanisms \nas a consequence of thefollowinglemma. Lemma 7. Let B be a discrete set and consider a function f : A \n. B . R=0 ' such that f. is well de.ned. Let a,a . A, . = 0 be such for all b, f(a,b) = .f(a ' ,b) and \nf(a ' ,b) = .f(a,b).Then, .. ' ..2 (fa,fa )=0 LL ' If moreover f ab = fab, then b.Bb.B .. ' ..(fa,fa \n)=0 Using the construction (\u00b7). de.ned above, the Exponential mechanism for a scoring function s, base \ndistribution \u00b5 and scale factor oisde.ned as def . Eo s,\u00b5 =(.ab. exp(os(a,b))(\u00b5b)) whereas the Laplacian \nmechanism with mean value r and scale factor s isde.ned as (()). def |b- a| L(r,s)= .ab. exp- r s The \nprivacy guarantees for the Exponential and the Laplacian mechanisms are stated as the rules [lap] and \n[exp] in Figure 6; their soundness is a corollary ofLemma7 above. Observe that thepremise of rule [lap]requires \ntoprove that the values around which the mechanismis centered are withindistance k.Thisisthe case when \nthese values are computedby a k-sensitive function starting from adjacent inputs, which corresponds to \nthe usual interpretation of the guarantees provided by the Laplacian mechanism[17]. As a further illustration \nof the expressive power of CertiPriv, we have also de.ned a Laplacian mechanism Ln for lists; given s \n. R+ and a vector a . Rn, the mechanism Ln outputs a vector inRn whose i-th componentisdrawnfromdistribution \nL(a[i],s). Moreformally, wehaveprovedthe soundness of thefollowing rule L m1 .m2 =.|[a[i]] m1 - [a[i]] \nm2|= k 1=i=n $k .Lnk |= x .Ln(a, o )~exp(o),0 y $(a, o ):. . x(1)= y(2) which we refer to as[lap * ]. \n6.2 Statistics over Streams Inthissectionwepresentan analysisof algorithmsforcomputing private and continual \nstatistics in a data stream [8]. As in [8], we focus on algorithms for private summing and counting. \nMore sophisticated algorithms, e.g. computing heavy hitters in a data stream,canbebuiltusing sums and \ncounters asprimitiveoperations andinherit theirprivacy and utilityguarantees. We consider streams of \nelements in a bounded subset D . R, i.e. with |x - y|= b for all x,y . D. This setting is slightly moregeneralthanthe \none consideredbyChan et al.[8], where only streams over {0,1} are considered. On the algorithmic side, \nthe generalization to bounded domains is immediate; for the privacy analysis, however, one needs to take \nthe bound b into account becauseitconditions the sensitivity of computations. This requires a carefulde.nition \nof metrics andpropagation ofbounds, whichis supportedby CertiPriv. Although in our implementation we \nformalize streams as .\u00adnite lists, we use array-notation in the exposition for the sake of  m1 .m2 =.|[r] \nm1 - [r] m2|= k exp(o)= am1 .m2 =. d([a] m1,[a] m2)= k exp(2kSso)= a [lap] [exp] kk $ $ .Eo .Eo |= x \n.L(r, o .L(r, o ):. . x(1) = y(2)|= x (a)~a,0 y $(a):. . x(1) = y(2) )~a,0 y $ s,\u00b5s,\u00b5 Figure6. Rulesfor \ntheLaplacian andExponential mechanisms readability. Given an array a of n elements in D, the goal is \nto release, for every point in time 0 = j<n the aggregate sum c[j]= Lji=0 a[i] in a privacy-preserving \nmanner. As observed in[8],therearetwoimmediatesolutionstotheproblem.The .rstis to maintain an exact aggregate \nsum c[j]and output at eachiteration a curated version c[j] $ .L(c[j],b/o)of that sum. The second so\u00adlution \nis to maintain and output a noisy aggregate sum c [j], which is updated atiteration j+1 according to \na[j+1] $c[j+1] . a[j+1] .L(a[j+1],b/o); c[j]+ The stream c[0]\u00b7\u00b7\u00b7 c[n - 1] offers weak, no-differential \npri\u00advacy, because every element of a may appear in n different ele\u00adments of c, each withindependent noise.However, \neach c[j]offers good accuracy because noise is added only once. In contrast, the stream c [0]\u00b7\u00b7\u00b7 c [n \n- 1] offersimproved, o-differentialprivacy, be\u00adcause each element of a appears onlyin one o-differentiallyprivate \nquery.However, as shownin[8], the sum c [j]yieldspoor accuracy because noiseis added jtimesduringits \ncomputation. One solution proposed by Chan et al. [8] is a combination of both basic methods of releasing \npartial sums that achieves a good compromise between privacy and accuracy. The idea is to split the stream \na into chunks of length q, where the less accurate (but more private)method is used to compute the sum \nwithin the current chunk, and the more accurate (but less private) method is used to compute summaries \nof previous chunks. Formally, let L st = q-1 a[tq + i]be the sum over the t-th chunk of a and i=0 $ let \nst .L(st,b/o)be the corresponding noisy version. Then, for each j= qr+ k, with k<q, we compute r-1 k \nLL c [j]= st + a[qr+ i] t=0 i=0 The sequence c [0]\u00b7\u00b7\u00b7 c [n - 1] offers 2o-differential privacy, intu\u00aditively \nbecause each element of a is accessed twice during com\u00adputation. Moreover, c [j] also offers improved \naccuracy over c [j] because noise is added only r + k times rather than j = qr + k times. We will now \nturn the above informal security analysis into a formal analysis of program code. The code for computing \nst is given as the function PARTIALSUM in Figure 7, the code for computing c isgiven asthefunction PARTIALSUM \ninFigure8, and the code for computing c isgiven as thefunction SMARTSUM inFigure9(we omit the codefor \ncomputing c and the proof of its privacy bound). We next sketch the key steps in our proofs of differentialprivacy \nboundsforeach of these algorithms.Forall of our examples, we use thepre-condition . def . = length(a(1))= \nlength(a(2)). a(1) = a(2). .i.0 = i< length(a(1))=.|a[i](1)- a[i](2)| = b which relates twolists a(1) \nand a(2) whenever theyhave the same length,differin at most one element, and thedistancebetween the elements \nat the sameposition at each arrayis upper-bounded by b. PARTIALSUM Theproofofdifferentialprivacy ofPARTIALSUM \nproceedsintwokey steps.First, weprove(using thepRHLfrag\u00adment of apRHL) that |= c1-5 ~1,0 c1-5 :. .|s(1)- \ns(2)| = b function PARTIALSUM(a) 1 s . 0; i . 0; 2 while i < length(a) do 3 s . s + a[i]; 4 i . i+ 1; \n5 end; 6 s . L(s,b/o) Figure7. A simple o-differentiallyprivate algorithmfor summing overlists where \nc1-5 corresponds to the code in lines 1-5 in Figure 7, i.e. the initialization and the loop. We apply \nthe rule [lap]that gives a bound for theprivacyguarantee achieved by theLaplacian mecha\u00adnism(see Figure6) \nto c6 = $ s .L(s,b/o)(the instruction inline 6) andderive |= c6 ~exp(o),0 c6 : |s(1)- s(2)| = b . s(1) \n= s(2) Using the rule for sequential composition, applied to c1-5 and c6, we derive the following statement \nabout PARTIALSUM, which implies thatits output s iso-differentiallyprivate. |= PARTIALSUM(a)~exp(o),0 \nPARTIALSUM(a):. . s(1) = s(2) PARTIALSUM Ourimplementation ofPARTIALSUM inFig\u00adure 7 differs slightly \nfrom the description given above in that we .rst add noisetothe entire stream(line1),before computing \nthe partial sums of the noisy stream(lines2-6).This modi.cation al\u00adlows us to take advantage oftheproof \nrulefor theLaplacian mech\u00adanism on lists. By merging the addition of noise into the loop, our two-passimplementation \ncanbe turnedinto an observationally equivalent one-passimplementation suitableforprocessing streams ofdata. \nTheproof ofprivacyforPARTIALSUM proceedsinthefol\u00adlowingbasic steps.First, we apply the rule[lap * ] to \nthe random assignmentinline1(noted as c1)of PARTIALSUM .We obtain |= c1 ~exp(o),0 c1 :. . a(1) = a(2) \ni.e.the outputa iso-differentiallyprivate atthispoint.Forlines2-6 (denotedbyc2-6), weprove(usingthepRHLfragmentof \napRHL) that |= c2-6 ~1,0 c2-6 : a(1) = a(2). s(1) = s(2) Thisis straightforwardbecause ofthe equalityappearinginthepre\u00adcondition; \nthis result can be derived using the apRHL rules, but is also an immediate consequence of the preservation \nof a-distance byprobabilistic computations(seeLemma3). Finally, we apply the rule for sequential composition \nto c1 and c2-6 and obtain |= PARTIALSUM (a)~exp(o),0 PARTIALSUM (a):. . s(1)= s(2) whichimpliesthatthe \noutput s of PARTIALSUM is o-differentially private. SMARTSUM Our implementation of the smart private \nsum in Figure9 makes useofPARTIALSUM andPARTIALSUM asbuild\u00adingblocks, which enables us to reuse the aboveproofs. \nIn addition, our implementation makes use of a procedure OFFSETCOPY that given two lists s and x, a constant \nc and non\u00adnegativeintegers i,q,returns alist whichisidenticalto s,but where  function PARTIALSUM (a) \n1 a $. Ln(a,b/o); 2 s[0] . a[0]; i . 1; 3 while i < length(a) do 4 s[i] . s[i- 1] + a[i]; 5 i . i+ 1; \n6 end Figure 8. An o-differentially private algorithm for partial sums overlists function SMARTSUM(a,q) \n1 i . 0; c . 0; 2 while i< length(a)/qdo 3 b . PARTIALSUM(a[iq..i(q+ 1) - 1]); 4 x . PARTIALSUM (a[iq..i(q+ \n1) - 1]); 5 s . OFFSETCOPY(s,x,c,iq,q); 6 c . c + b; 7 i . i+ 1; 8 end Figure 9. A smart 2o-differentially \nprivate algorithm for partial sums overlists the entries s[i]\u00b7\u00b7\u00b7 s[i+(q- 1)]arereplacedby the .rst qelements \nof x,plus a constant offset c,i.e. s[i+j]= x[j]+c for0 <= i<q. We obtain F s. OFFSETCOPY(s,x,c,i,q)~1,0 \ns. OFFSETCOPY(s,x,c,i,q): = {s,x,c,i,q} . s(1) = s(2) We combinethis result with thejudgmentsderivedfor \nPARTIAL-SUM and PARTIALSUM using the rulefor sequential composition, obtaining |= c4-7 ~exp(2o),0 c4-7 \n:. . s(1) = s(2) where c4-7 denotes thebody of theloopinlines4-7.To conclude, we apply the rule for while \nloops in Fig. 5 with a1(i) =1 and a2 = exp(2o). This instantiation of the rule states that a loop that \nis non-interfering in all but one iteration is 2o-differentially private, if the interfering loop iteration \nis 2o-differentially private. More technically, the existence of a single interfering iteration is builtintothe \nrule using apair of stable eventsfor each command. In our case, the critical iteration corresponds to \nthe one in which the chunk contains thepositionin which the twolistsdiffer. 6.3 MinimumVertexCover We \nconclude this section with a moredetailed account of theproof ofdifferentialprivacy oftheMinimumVertexCover \napproximation algorithm ofSection2.The main step oftheproofis an application of the ruleforloopsinFig.5 \nwithparameters () () 2 o a1(i)= exp a2 = exp, (n - i)wi 4 thefollowinginvariant F (t . p(1). u . p(1) \n=. E(1) = E(2)). (t/. p(1). u/. p(1) =. E(2) = E(1).{(t,u)}). V(1) = V(2). p(1) = p(2), and stableproperties \nP1 = P2 = t . p. u . p. The .rstand second equivalencesappearinginthepremisesof the rule are of theform: \n|= c1;assert P ~a,0 c2;assert P :. . F Foreach of them,we .rsthoisttheassertionimmediately afterthe random \nassignment. At this point the expression in the assertions becomes (t,u ./(v :: p)) in the case of the \n.rst premise and (t . (v :: p). u . (v :: p)) in the case of the second. We then compute the weakest \npre-condition of the assignments that nowfollowthe assertions.The resultingjudgments simplify, after \napplying the [weak] and [frame] rules, tojudgments of theform |= c ~a,0 c :. . v(1) = v(2) where def \n.= E(2) = E(1).{(t,u)}. V(1) = V(2). t,u/. p . i(1) = i(2) = j. p(1) = p(2) Forthe .rstpremisewehave \na = a1(j)and $ c = v . choose(V,E,o,n,i); assert (t,u/. (v :: p)) whereasfor the secondpremise wehave \na = a2 and $ c = v . choose(V,E,o,n,i); assert (t.(v :: p). u.(v :: p)) To establishthe validityofbothjudgments, \nwe cast the codefor c as a random assignment where v is sampled from the interpreta\u00adtion of choose(V,E,o,n,i)restricted \nto v satisfying the condition onthe assertion.Inthe .rst case,the restriction amountsto v = u,t whereas \nin the second it amounts to v = t . v = u. For each one of these cases, we apply the rule for random \nassignments and are thusleft toprove that the a-distance of the corresponding distribu\u00adtionsis null.In \nview ofLemma2, thisin turn amounts to verifying for each element x in the support of the distribution \nthat the ratio betweentheprobability of v being equal to x in the left-hand side (resp.right-handside)program \nand theright-hand side(resp.left\u00adhand side)programisbounded by a, whichdirectly translatesinto the inequalities \nappearing inSection 2. Technically, these inequal\u00adities areprovedby appealing to a variant ofLemma7. \nThe proof in apRHL yields a bound of 5o/4 rather than the o boundfrom[18].Thisdifferenceisdue to the \nsymmetric nature of our logic. We believe that the optimal bound can be proved in apRHL at the cost of \na more complicated proof by using rule [comp] to introduce intermediate programs or, more elegantly, \nby using an asymmetric version of apRHL. See the appendix for a discussion on what it would take to build \nan asymmetric logic and how it could be used to improve the privacy bound from 5o/4 to justo. 7. RelatedWork \nOur workbuilds uponprogram veri.cation techniques, and inpar\u00adticular(probabilistic and relational)programlogics,to \nreason about differentialprivacy.Webrie.yreview relevant workin these areas. Differentialprivacy There \nis a vast body of work on differential privacy. We refer to recent overviews, see e.g. [14, 15], for \nan account of some of the latest developments in the .eld, and focus on language-based approaches to \ndifferential privacy. The Privacy IntegratedQueries(PINQ)platform[24]supports reasoning about theprivacyguarantees \nofprogramsin a simpleSQL-likelanguage. The reasoning is based on the sensitivity of basic queries such \nas Select and GroupBy, the differential privacy of building blocks such as NoisySum and NoisyAvg, and \nmeta-theorems for their sequential andparallel composition. AIRAVAT [30]leverages these buildingblocksfordistributedcomputationsbased \nonMapReduce. Thelineartypesystem of[29] extends sensitivity analysisto a higher-order functional language. \nBy using a suitable choice of metric and probability monads, the type system also supports rea\u00adsoning \nabout probabilistic, differentially private computations. As in PINQ, the soundness of the type system \nmakes use of known composition theorems and relies on assumptions about the sen\u00adsitivity/differential \nprivacy of nontrivial building blocks, such as arithmetic operations, conditional swap operations, or \nthe Lapla\u00adcian mechanism.While the type system canhandlefunctionaldata structures, it does not allow \nfor analyzing programs with condi\u00adtional branching. Work on the automatic derivation of sensitiv\u00adity \nproperties of imperative programs [9] addresses this problem and can (in conjunction with the Laplacian \nmechanism) be used to derive differential privacy guarantees of programs with control .ow.Althoughthisapproach \nsupports reasoning aboutprobabilistic computations, the reasoningis restricted toLipschitz-conditions. \n In contrast to[9,24,29], CertiPriv supports reasoning about differential privacy guarantees from .rst \nprinciples. In particular, CertiPriv enabled ustoprove(ratherthanto assume) the correct\u00adness ofLaplacian \nandExponential mechanisms, andthedifferential privacy of complexinterleavings of(not necessarilydifferentially \nprivate)probabilistic computations. Arecent approach considersthe veri.cationofprivacyproper\u00adtiesbased \nonI/O-automata[35].There, thefocuslies on the veri.\u00adcation ofthe correct use ofdifferentiallyprivate \nsanitization mecha\u00adnisms withininteractive systems, where the effect of a sanitization mechanism is soundly \nabstracted using a single, idealized transi\u00adtion. An early approachtoquantitative con.dentiality analysis[26] \nuses the distance of output distributions to quantify information .ow.Their measure is closely related \nto (0,d)-approximate differ\u00adentialprivacy, which can be reasoned about in CertiPriv. More re\u00adcent approachestoquantitativeinformation-.owfocus \non measures of con.dentiality based on information-theoretic entropy. Tech\u00adniques for code-based structural \nreasoning about these measures aredevelopedin[10].For an overview and adiscussion of the re\u00adlationship \nbetween entropy-based measures of con.dentiality and differentialprivacy, see[2]. Probabilistic and relational \nprogram veri.cation Program log\u00adics have a long tradition and have been used effectively to reason about \nfunctional correctness of programs. In contrast, privacy is a 2-safetyproperty[11,33],thatis, a(universallyquanti.ed) \nprop\u00aderty about two runs of aprogram. Therehavebeen severalpropos\u00adalsfor applyingprogramlogics to2-safety,but \ntheseproposals are con.ned todeterministicprograms andimpractical. A seminalpaper[7] develops a relationalHoarelogic(RHL) \nfor a coreimperativeprogramminglanguage and showshowit can be used to reason about information .ow properties \nof programs. Thisline of workhasbeengeneralized to aprobabilistic settingby CertiCrypt [3], which formalizes \nan extension of RHL for proba\u00adbilistic programs. CertiPriv builds upon and signi.cantly extends CertiCrypt \n[3]. The most outstanding difference between the two frameworksisthatCertiPriv supports reasoning about \na wide range of quantitative relational properties, whereas CertiCrypt is con\u00ad.ned to baseline information \n.ow properties. Although we make a modest use of this feature, CertiPriv supports(for a richerlan\u00adguage) \nthe certi.edprogram transformations that areimplemented inCertiCrypt.Thanks to a recentdevelopment, the \nconstruction of game-playing proofs[6] in CertiCrypt can be achieved ef.ciently using EasyCrypt [4],afront-endthatgenerates \nautomaticallyprob\u00adabilisticRHLderivations usingSMT solvers and a veri.cation con\u00additiongenerator.There \nare excitingopportunitiesto exploitthe syn\u00adergies between CertiPriv, CertiCrypt and EasyCrypt, as further \ndiscussedinSection8. Thereis also agrowing body of work that usesproof assistants for reasoning about \nproperties of probabilistic algorithms. For in\u00adstance,Hurd and co-workers[19] formalizedintheHOL system \natheoryforreasoning aboutaprobabilisticextension ofDijkstra s guardedcommandlanguage, and usedittoprove \nthe correctness of theMiller-Rabinprimality test. 8. FutureWork andConclusions CertiPriv is a machine-checked \nframework that supports .ne\u00adgrained reasoning about an expressive class of privacy policies in the Coq \nproof assistant. In contrast to previous language-based approaches to differential privacy, CertiPriv \nallows to reason di\u00adrectly about probabilistic computations and to build proofs from .rst principles. \nAs a result, CertiPriv achieves .exibility, expres\u00adsiveness, and reliability, and appears as a plausible \nstarting point forcapturingand analyzingformally newdevelopmentsinthe .eld ofdifferentialprivacy. An \nimmediate objective for future work is to use the game\u00adplayingtechniquefrom[3]for verifyingin CertiPriv \ntheprivacy of multi-party computation algorithms, where one is concerned with ensuring privacy against \n(computationally bounded) adversaries thatonlyhaveapartial view of thestate,concretely thelocal state \nof corruptparticipants[5,25].This objectiveis within reach, since CertiPriv inheritsfrom CertiCrypt aformalization \nofprobabilistic polynomial-time algorithms, andcan already capturethis variant of differentialprivacy. \nAnother exciting avenue for further research is to automate the veri.cation of differentially private \ncomputations. There are three facets to this work: building an automated checker for apRHL derivations, \nautomatically inferring relational loop invariants, and implementing a precise dependency analysis for \nan optimal usage of existing composition theorems. EasyCrypt [4]provides an ex\u00adcellent startingpointfor \nthese tasks. 9. Acknowledgments This work waspartially funded by European ProjectsFP7-256980 NESSoS and \nFP7-229599 AMAROUT,Spanish project TIN2009\u00ad14599 DESAFIOS 10, Madrid Regional project S2009TIC-1465 PROMETIDOSandFrenchprojectANRSESUR-012SCALP. \nReferences [1] P.AudebaudandC.Paulin-Mohring.Proofsof randomized algorithms inCoq. Sci.Comput. Program.,74(8):568 \n589, 2009. [2] G.BartheandB.K\u00a8opf.Information-theoreticboundsfordifferentially private mechanisms. In \n24rd IEEE Computer Security Foundations Symposium, CSF 2011, pages 191 204, Los Alamitos, 2011. IEEE \nComputer Society. [3] G.Barthe,B.Gr\u00b4egoire, andS.ZanellaB\u00b4eguelin. Formal certi.cation of code-based \ncryptographicproofs.In 36thACMSIGPLAN-SIGACT symposium on Principles of Programming Languages, POPL 2009, \npages90 101,NewYork,2009.ACM. [4] G. Barthe, B. Gr\u00b4egoire, S. Heraud, and S. Zanella B\u00b4eguelin. Computer-aided \nsecurityproofsfortheworking cryptographer.In Ad\u00advancesinCryptology CRYPTO2011, volume6841 of LectureNotes \nin Computer Science,pages71 90,Heidelberg, 2011.Springer. [5] A.Beimel,K.Nissim,andE.Omri.Distributedprivatedataanalysis: \nSimultaneously solving how and what. In Advances in Cryptology CRYPTO 2008, volume 5157 of Lecture Notes \nin Computer Science, pages451 468,Heidelberg, 2008.Springer. [6] M. Bellare and P. Rogaway. The security \nof triple encryption and a framework for code-based game-playing proofs. In Advances in Cryptology EUROCRYPT \n2006, volume 4004 of Lecture Notes in Computer Science,pages409 426,Heidelberg, 2006.Springer. [7] N.Benton.Simplerelational \ncorrectnessproofsforstaticanalysesand programtransformations. In31stACMSIGPLAN-SIGACTsymposium onPrinciples \nofProgramming Languages,POPL2004,pages 14 25, NewYork,2004.ACM. [8] T.-H.H.Chan,E.Shi, andD.Song. Private \nand continual release of statistics. In 37th International colloquium on Automata, Languages and Programming, \nICALP 2010, volume 6199 of Lecture Notes in Computer Science,pages405 417,Heidelberg, 2010.Springer. \n[9] S.Chaudhuri,S.Gulwani,R.Lublinerman,andS.Navidpour.Proving programs robust. In8thjoint meeting of \ntheEuropeanSoftwareEngi\u00adneering Conference and theACMSIGSOFTInternationalSymposium onFoundationsofSoftwareEngineering,ESEC/FSE \n11.ACM,2011.  [10] D.Clark,S.Hunt,andP.Malacaria. Astatic analysisforquantifying information .ow in \na simple imperative language. Journal of Com\u00adputer Security,15(3):321 371, 2007. [11] M. R. Clarkson \nand F. B. Schneider. Hyperproperties. Journal of Computer Security, 18(6):1157 1210, 2010. [12] J.Desharnais,F.Laviolette, \nandM.Tracol. Approximate analysis of probabilistic processes: Logic, simulation and games. In 5th Interna\u00adtionalConference \nonQuantitative Evaluation ofSystems,QEST2008, pages264 273.IEEEComputerSociety,2008. [13] C.Dwork. Differentialprivacy. \nIn 33rd International Colloquium on Automata, Languages and Programming, ICALP 2006, volume 4052 of LectureNotes \ninComputer Science,pages1 12,Heidelberg, 2006. Springer. [14] C. Dwork. Differential privacy: A survey \nof results. In Theory and Applications ofModels ofComputation, volume4978 of LectureNotes inComputer \nScience,pages1 19,Heidelberg, 2008.Springer. [15] C. Dwork. A .rm foundation for private data analysis. \nCommun. ACM,54(1):86 95, January2011. [16] C.Dwork,K.Kenthapadi,F.McSherry,I.Mironov,andM.Naor.Our data,ourselves:Privacy \nviadistributed noisegeneration. In Advances inCryptology EUROCRYPT2006, volume4004 of Lecture Notesin \nComputer Science,pages486 503,Heidelberg, 2006.Springer. [17] C. Dwork, F. McSherry, K. Nissim, and A. \nSmith. Calibrating noise to sensitivity in private data analysis. In 3rd Theory of Cryptography Conference, \nTCC 2006, volume 3876 of Lecture Notes in Computer Science,pages265 284,Heidelberg, 2006.Springer. [18] \nA. Gupta, K. Ligett, F. McSherry, A. Roth, and K. Talwar. Differen\u00adtially private combinatorial optimization. \nIn 21st Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2010, pages 1106 1125. SIAM,2010. [19] \nJ.Hurd,A.McIver,andC.Morgan. Probabilisticguarded commands mechanized inHOL. Theor.Comput. Sci.,346(1):96 \n112, 2005. [20] B. Jonsson, W. Yi, and K. G. Larsen. Probabilistic extensions of process algebras. In \nJ. Bergstra, A. Ponse, and S. Smolka, editors, Handbook of Process Algebra,pages 685 710. Elsevier, Amsterdam, \n2001. [21] S. P. Kasiviswanathan and A. Smith. A note on differential privacy: De.ning resistance to \narbitrary side information. Cryptology ePrint Archive,Report2008/144,2008. [22] D. Kifer and A. Machanavajjhala. \nNo free lunch in data privacy. In 2011International conferenceonManagement ofData,SIGMOD 11, pages193 \n204.ACMPress,2011. [23] F. McSherry and K. Talwar. Mechanism design via differential pri\u00advacy. In 48th \nAnnual IEEE Symposium on Foundations of Computer Science, FOCS 2007, pages 94 103, Washington, 2007. \nIEEE Com\u00adputerSociety. [24] F. D. McSherry. Privacy integrated queries: an extensible platform for privacy-preserving \ndata analysis. In 35th SIGMOD international conference on Management of Data, SIGMOD 2009, pages 19 30, \nNewYork,2009.ACM. [25] I. Mironov, O. Pandey, O. Reingold, and S. Vadhan. Computational differential \nprivacy. In Advances in Cryptology CRYPTO 2009, volume 5677 of Lecture Notes in Computer Science, pages \n126 142, Heidelberg, 2009.Springer. [26] A. D. Pierro, C. Hankin, and H. Wiklicky. Approximate non\u00adinterference. \nJournal ofComputerSecurity, 12(1):37 82, 2004. [27] L. Pitt. A simple probabilistic approximation algorithm \nfor vertex cover. Technical ReportTR-404,YaleUniversity,1985. [28] N.Ramsey andA.Pfeffer. Stochasticlambdacalculus \nand monadsof probabilitydistributions. In29thACMSIGPLAN-SIGACTsymposium on Principles of Programming \nLanguages, POPL 2002, pages 154 165,NewYork,2002.ACM. [29] J. Reed and B. C. Pierce. Distance makes the \ntypes grow stronger: a calculus fordifferentialprivacy. In 15thACMSIGPLANinternational conference on \nFunctional programming, ICFP 2010,pages 157 168, NewYork,2010.ACM. [30] I.Roy,S.T.V.Setty,A.Kilzer,V.Shmatikov,andE.Witchel.Airavat: \nsecurity and privacy for MapReduce. In 7th USENIX conference on Networked Systems Design and Implementation, \nNSDI 2010, pages 297 312,Berkeley, 2010.USENIXAssociation. [31] A. Sabelfeld and D. Sands. Probabilistic \nnoninterference for multi\u00adthreaded programs. In 13th IEEE workshop on Computer Security Foundations, \nCSFW2000,pages200 215,LosAlamitos,2000.IEEE Computer Society. [32] R. Segala and A. Turrini. Approximated \ncomputationally bounded simulation relations for probabilistic automata. In 20th IEEE Com\u00adputer Security \nFoundations symposium, CSF 2007, pages 140 156, 2007. [33] T. Terauchi and A. Aiken. Secure information \n.ow as a safety prob\u00adlem. In 12th International Symposium on Static Analysis, SAS 2005, volume 3672 of \nLecture Notes in Computer Science, pages 352 367, Heidelberg, 2005.Springer. [34] The Coq development \nteam. The Coq Proof Assistant Reference ManualVersion8.3.Online http://coq.inria.fr ,2010. [35] M.C.Tschantz,D.Kaynar,andA.Datta.Formalveri.cationofdiffer\u00adentialprivacyforinteractive \nsystems. Electronic Notes in Theoretical Computer Science, 276:61 79,2011. A. AsymmetricLogic Asymmetric \nversions of apRHL can be obtained by re-de.ning a\u00addistance as def .a(a,b) = max(b- aa,0) anddropping \ninDe.nition3 either of theinequalities .a(p1 \u00b5,\u00b51)= d .a(p2 \u00b5,\u00b52)= d Droppingthe secondinequalityyields \nalogicfor whichthe validity of ajudgment c1 ~a,d c2 :. . F implies onlythatfor m1,m2 s.t. m1.m2 and f1,f2 \ns.t. f1 =F f2, [c1] m1 f1 = a([c2] m2 f2)+d Application to the Minimum Vertex Cover Problem An asym\u00admetric \nversion of thelogic would allow toprovein anindependent waythatfor anypermutationiv, exp(o)is aboundforboth,the \nratio Pr[VERTEXCOVER(G1,o): p = iv] (1) Pr[VERTEXCOVER(G2,o): p = iv] and its reciprocal. Each ratio \ncould be bounded by applying an asymmetric version of the rule for while loops shown in Figure 5, and \neach application wouldin turn require toindependently bound for eachiteration the ratios Pr[v(2) = x] \nPr[v(1) = x] and Pr[v(1) = x] Pr[v(2) = x] This would allow to choose tighter values for the parameters \na1 and a2 in each case. E.g., when bounding (1), one could take a1(i)= exp(2/(n - i)wi)and a2 =1,whereas \nwhenbounding its reciprocal one could take a1(i)=1and a2 = exp(o/4).   \n\t\t\t", "proc_id": "2103656", "abstract": "<p>Differential privacy is a notion of confidentiality that protects the privacy of individuals while allowing useful computations on their private data. Deriving differential privacy guarantees for real programs is a difficult and error-prone task that calls for principled approaches and tool support. Approaches based on linear types and static analysis have recently emerged; however, an increasing number of programs achieve privacy using techniques that cannot be analyzed by these approaches. Examples include programs that aim for weaker, approximate differential privacy guarantees, programs that use the Exponential mechanism, and randomized programs that achieve differential privacy without using any standard mechanism. Providing support for reasoning about the privacy of such programs has been an open problem.</p> <p>We report on CertiPriv, a machine-checked framework for reasoning about differential privacy built on top of the Coq proof assistant. The central component of CertiPriv is a quantitative extension of a probabilistic relational Hoare logic that enables one to derive differential privacy guarantees for programs from first principles. We demonstrate the expressiveness of CertiPriv using a number of examples whose formal analysis is out of the reach of previous techniques. In particular, we provide the first machine-checked proofs of correctness of the Laplacian and Exponential mechanisms and of the privacy of randomized and streaming algorithms from the recent literature.</p>", "authors": [{"name": "Gilles Barthe", "author_profile_id": "81100111668", "affiliation": "IMDEA Software Institute, Madrid, Spain", "person_id": "P2991349", "email_address": "gilles.barthe@imdea.org", "orcid_id": ""}, {"name": "Boris K&#246;pf", "author_profile_id": "81325489012", "affiliation": "IMDEA Software Institute, Madrid, Spain", "person_id": "P2991350", "email_address": "boris.koepf@imdea.org", "orcid_id": ""}, {"name": "Federico Olmedo", "author_profile_id": "81442617541", "affiliation": "IMDEA Software Institute, Madrid, Spain", "person_id": "P2991351", "email_address": "federico.olmedo@imdea.org", "orcid_id": ""}, {"name": "Santiago Zanella B&#233;guelin", "author_profile_id": "81418594739", "affiliation": "IMDEA Software Institute, Madrid, Spain", "person_id": "P2991352", "email_address": "santiago.zanella@imdea.org", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103670", "year": "2012", "article_id": "2103670", "conference": "POPL", "title": "Probabilistic relational reasoning for differential privacy", "url": "http://dl.acm.org/citation.cfm?id=2103670"}