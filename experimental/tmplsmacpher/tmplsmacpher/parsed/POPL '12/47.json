{"article_publication_date": "01-25-2012", "fulltext": "\n Self-Certi.cation Bootstrapping Certi.ed Typecheckers in F* with Coq Pierre-Yves Strub Nikhil Swamy \nMSR-INRIA Microsoft Research pierre-yves@strub.nu nswamy@microsoft.com Abstract Well-established dependently-typed \nlanguages like Agda and Coq provide reliable ways to build and check formal proofs. Several other dependently-typed \nlanguages such as Aura, ATS, Cayenne, Epigram, F*, F7, Fine, Guru, PCML5, and Ur also explore reliable \nways to develop and verify programs. All these languages shine in their own regard, but their implementations \ndo not themselves en\u00adjoy the degree of safety provided by machine-checked veri.cation. We propose a general \ntechnique called self-certi.cation that al\u00adlows a typechecker for a suitably expressive language to be \ncerti.ed for correctness. We have implemented this technique for F*, a de\u00adpendently typed language on \nthe .NET platform. Self-certi.cation involves implementing a typechecker for F* in F*, while using all \nthe conveniences F* provides for the compiler-writer (e.g., partial\u00adity, effects, implicit conversions, \nproof automation, libraries). This typechecker is given a speci.cation (in F*) strong enough to ensure \nthat it computes valid typing derivations. We obtain a typing deriva\u00adtion for the core typechecker by \nrunning it on itself, and we export it to Coq as a type-derivation certi.cate. By typechecking this deriva\u00adtion \n(in Coq) and applying the F* metatheory (also mechanized in Coq), we conclude that our type checker is \ncorrect. Once certi.ed in this manner, the F* typechecker is emancipated from Coq. Self-certi.cation \nleads to an ef.cient certi.cation scheme we no longer depend on verifying certi.cates in Coq as well \nas a more broadly applicable one. For instance, the self-certi.ed F* checker is suitable for use in adversarial \nsettings where Coq is not intended for use, such as run-time certi.cation of mobile code. Categories \nand Subject Descriptors D.3 [Programming Languages]: Formal De.nitions and Theory; F.3.1 [Specifying \nand Verifying and Rea\u00adsoning about Programs]: Speci.cation techniques. General Terms Veri.cation, Languages. \nKeywords Certi.cation, Dependent Types, Re.nement Types. 1. Introduction Well-established dependently-typed \nlanguages like Agda (Norell 2007) and Coq (2011) provide highly reliable ways to build and check formal \nproofs. Researchers have also developed many other dependently-typed programming languages, with different \ndesign trade-offs, such as Cayenne (Augustsson 1998), ATS (Xi 2003), Epigram (McBride 2004), Aura (Jia \net al. 2008), Fable (Swamy Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. POPL 12, January 25 27, 2012, Philadelphia, PA, USA. Copyright c &#38;#169; \n2012 ACM 978-1-4503-1083-3/12/01. . . $10.00 C\u00b4edric Fournet Juan Chen Microsoft Research Microsoft Research \nfournet@microsoft.com juanchen@microsoft.com et al. 2008), F7 (Bengtson et al. 2008), Guru (Stump et \nal. 2008), Fine (Swamy et al. 2010), F* (Swamy et al. 2011), PCML5 (Avijit et al. 2010), Ur (Chlipala \n2010b), etc., and more are in the works, such as Trellys (Casinghino et al. 2011). All these languages \nshine in their own regard, but their imple\u00admentations do not themselves enjoy the degree of formal safety \ntheir authors advocate. Even with full-.edged mechanized theo\u00adries in Coq, for instance, new language \nimplementations are of\u00adten ad hoc and disconnected from the formalized systems. One may choose to write \na core typechecker for one of these languages within Coq, and possibly extract it to another language \nwith a simi\u00adlar semantics (Letouzey 2008), but this involves programming com\u00adpiler internals in an impoverished \nlanguage of pure total functions, and a correspondingly large interactive proof obligation. Besides, \nCoq is not a panacea for all automated veri.cation tasks. For ex\u00adample, when dealing with hostile code \nat run-time, more special\u00adized, defensive veri.ers may be simpler and safer. They may, for instance, \n.t on a smartcard or address non-functional aspects of the Coq checker, such as parsing, formatting, \nand error handling. We aspire to formal certi.cation within general-purpose pro\u00adgramming languages and \nsystems. To this end, we propose a boot\u00adstrapping path that allows the implementation of a core typechecker \n(for such a language) to be mechanically certi.ed for correctness using an external, independent tool \nsuch as Coq. Traditionally, bootstrapping refers to the process of compiling a compiler with itself (Hart \nand Levin 1962) and, more usefully, of compiling a series of increasingly complex variants of a compiler \nwith themselves, until a .xpoint is reached (see e.g. Appel 1994). The main bene.t of bootstrapping is \nto reduce dependencies on ex\u00adternal languages and tools, and thus provide .exibility as the com\u00adpiler \nevolves. For instance, one may start with a core compiler for a subset of the language on a simple architecture, \nthen gradually add language features, compiler optimizations, and target architectures. Another bene.t \nis to provide reasonably complex sample code for testing, and thus gain con.dence in the resulting compiler. \nAt .rst sight, the bene.ts of bootstrapping for formal veri.cation are lim\u00adited, due to incompleteness \nresults. Instead, a common architecture is to separate a trusted, minimal core veri.er that just checks \nthe proofs produced (and often already veri.ed) by more complex, ex\u00adtensible, interactive tools. The \nmain contribution of this paper is a new, general method named self-certi.cation (as opposed to self-validation; \nsee e.g. Barras 2010 for Coq) that allows a typechecker for a suitably\u00adexpressive typed language to be \ncerti.ed for correctness. In com\u00adbination with a mechanized theory that ensures type safety, self\u00adcerti.cation \nguarantees that all programs accepted by the type\u00adchecker will be safe, without further use of external \nformal tools. We implement this technique for F*, a dependently-typed pro\u00adgramming language for the .NET \nplatform primarily used to verify the security of distributed programs and protocols. Brie.y, to self\u00adcertify \nF*, we carry out the following tasks:  (1) We program a core typechecker for F* in F*, while making \nuse of all of the conveniences that F* provides for the compiler\u00adwriter (e.g., partiality, effects, implicit \nconversions, proof au\u00adtomation, libraries, etc.). Our typechecker takes a program and its candidate type \nand returns a detailed typing derivation or reports an error. (2) We equip it with a speci.cation (using \nF* types) strong enough to ensure that it returns (at most) valid typing derivations. Thus, informally, \nour typechecker is correct by typing. (3) We run our typechecker on itself: we thus produce a (large) \ncerti.cate for its own typing, which we export to Coq. (4) We import and typecheck this certi.cate within \nCoq and apply the F* metatheory (also mechanized in Coq) to formally deduce .rst that our typechecker \nis correct, and then that its termination implies the safety of any program it accepts. (5) Once certi.ed \nin this manner, the F* typechecker is emanci\u00adpated from Coq. We can use it independently of Coq, with \nes\u00adsentially the same formal guarantees for the programs it ac\u00adcepts. Going further, we can erase the \nproduction of typing\u00adderivation certi.cates, treated as irrelevant proofs.  Self-certi.cation leads \nto an ef.cient certi.cation scheme after bootstrapping, we no longer depend on verifying certi.cates \nin Coq as well as a more broadly applicable one. The self-certi.ed F* checker is suitable in adversarial \nsettings where Coq is not in\u00adtended for use, for instance to verify and then load mobile code at runtime. \nWe plan to use F* to certify reference implementations of security-critical infrastructure, such as TLS \n(Dierks and Rescorla 2008). Meanwhile, we may already certify properties previously checked by typing \nfor security protocols coded in F7 or F* for se\u00adcure multiparty sessions (Bhargavan et al. 2009), identity \nmanage\u00adment systems (Bhargavan et al. 2010), and data protection APIs (Acar et al. 2010) by running our \nself-certi.ed typechecker on pro\u00adgrams much larger than itself. An F* primer We brie.y review F*, a variant \nof ML with a simi\u00adlar syntax and dynamic semantics but with a more expressive type system. F* enables \ngeneral-purpose programming with recursion and effects; it has libraries for concurrency, networking, \ncryptog\u00adraphy, and interoperability with other .NET languages. After type\u00adchecking, F* is compiled to \n.NET bytecode, with runtime support for proof-carrying code. F* has been applied mostly to secure dis\u00adtributed \nprogramming; it subsumes F7 and Fine, two prior lan\u00adguages using types for security veri.cation. It has \nbeen used to pro\u00adgram and verify more than 30,000 lines of code, including security protocols, web browser \nextensions, and distributed applications. Its main typechecker, compiler, and runtime support are coded \nin F#. The main technical novelty of F* is a kind system to keep track of different fragments of the \nlanguage and control their interaction. By default, program terms (with kind *) may have arbitrary effects. \nWithin these programs, proof terms (with kind P) remain pure and terminating, and thereby provide a logically \nconsistent core. Besides, af.ne resources (with kind A) may be used for modular reasoning on stateful \nproperties. Finally, ghost terms (with kind E) may be used only in speci.cations, to selectively control \nthe erasure of proof terms, when the proofs are irrelevant or unavailable (for instance, when calling \nlegacy code or using cryptography). F* is also parametric in the logic used to describe program prop\u00aderties \nand proofs. This provides support for custom logics (e.g., for expressing authorization policies) and \nenables integration with SMT solvers, which is important for proof automation when de\u00adveloping large \nprograms. Thus, F* calls Z3 (de Moura and Bj\u00f8rner 2008) during typechecking, to prove logical properties \nspeci.ed as type re.nements and to decide type equivalences. Figure 1. Self-Certi.cation for an F* checker \nwritten in F* The type system of F* has 4 main mutually-recursive judgments and 67 rules. Its theory \nhas been formalized in Coq, showing substitutivity and subject reduction. (By design, F* provides only \nvalue dependencies and is inadequate for this sort of interactive theorem proving.) Typechecking F* in \nF* Figure 1 outlines our method for self\u00adcertifying F*, which involves developments in F#, in F*, and \nin Coq. The rest of the paper provides a more precise, syntactic ac\u00adcount of the developments in F* and \nCoq. Its central component is our new core typechecker, programmed in F* using mutual recursion and exceptions \nfor error-handling, state for name generation, as well as external .NET functions for I/O. Including \nthe type de.nitions for the language and its type system, as well as basic library functions (mostly \noperations on lists and other functional data structures), our candidate certi.ed program has 5,139 LOCs. \nWe adapt the F* compiler and main typechecker (in F#, on the left-hand-side) so that, after parsing and \ntyping a given source pro\u00adgram, it passes a typed abstract syntax tree for core typechecking certi.cation, \nusing a datatype shared between F# and F*. This F# code is signi.cantly larger (35,000 LOCs). Thus, for \na given F* program, we can call the F* compiler and obtain a typechecking certi.cate for (a desugared \nvariant of) this program. In particular, we can call the core typechecker on itself and after .xing any \nerrors produce its own typechecking certi.cate. Core typecheck\u00ading is fast (a few minutes), but exporting \nthe self-typechecking cer\u00adti.cate in a format suitable for Coq veri.cation then takes several hours, \nand still yields 7 GB of Coq source .les. Two theories of F* in Coq To relate the F* and Coq developments, \nwe crucially rely on a well-identi.ed fragment of F* (tracked by its P kind) that coincides with a fragment \nof the inductive types of Coq. To this end, we build tools that take F* types and values and emit them \nin the concrete syntax of Coq. In the picture, we label these de.nitions with both a .fst for F* and \na .v for Coq. Thus, the de.nitions of the F* syntax, and (with some care) its core type system, are speci.ed \nusing value-dependent mutually\u00adrecursive inductive types in the shared fragment. This enables us, in \nparticular, to emit a typing certi.cate in F* and typecheck it as a valid typing certi.cate in Coq. We \nintend to formally reason about our F* typechecker running on an F* program within Coq, so we emit surface \nde.nitions (for the typechecker and its type), embedded de.nitions (for its program parameter and its \ntype, both typed as surface F* values), and embedding functions between the two. Conversely, we prove \nthat, at least for the inductive types we use to represent typing derivations, the existence of an embedded \nvalue implies the existence of a surface value (Theorem 4).  Our shared de.nition of the F* type system \nis convenient for programming and typechecking, but not for developing its metathe\u00adory. Instead, we use \nanother, co.nite de.nition of the type system (based on the same F* syntax), we prove subject-reduction \nfor the co.nite system (Theorem 2), and we prove the adequacy of the shared system with regards to the \nco.nite system (Theorem 1). With these results in hand, we can complete our bootstrap\u00adping within Coq. \nWe load and typecheck the 7 GB self-typing certi.cate despite many optimizations, this task still takes \nseveral machine-weeks then we apply adequacy and subject reduction on complete runs of the typechecker \napplied to its own embedding as an F* term and its candidate type. This yields a valid embedded typing \ncerti.cate for the embedded typechecker. Finally, we apply our Theorem 4 relating embedded and surface \nvalues and obtain a valid proof of its typing (Theorem 5). Limitations Our path to certi.cation depends \non the correctness of the following components: (1) The Coq kernel. We use a custom build of Coq with \ntwo exten\u00adsions: a compact representation of strings for typechecking our typing certi.cates, and SSREFLECT \nfor the metatheory and all interactive proofs. (2) Some of our tools for parsing, translating, and embedding \nspec\u00adi.cations between F* and Coq. Except for the concrete syntax, these are almost identities. The situation \nis similar to the use of notations within Coq careful printing and manual inspection is required to interpret \nthe formal theorem statements (Pollack 1998), although their proofs can be safely ignored. (3) Z3. We \nsee the certi.cation of SMT deductions as an impor\u00adtant, independent issue. We plan to adapt prior work \non prede\u00adcessors of F* (Chen et al. 2010) to extract valid F* proof terms from Z3 deductions. We may \nalso rely on other veri.ed SMT solvers (Armand et al. 2010; Moskal 2008). (4) The F* back-end compiler \nand its .NET runtime with regards to our formal dynamic semantics. This trust assumption is rather large. \nOn the other hand, we run our certi.ed programs on the same platform, so we may as well trust it for \ntypechecking. Still, in future work, it would be interesting to compile and run F* using a smaller TCB. \n We should also note that we certify only the partial correctness of our typechecker. This is consistent \nwith our usage of F*, which al\u00adready relies on Z3, an incomplete prover. Pragmatically, bootstrap\u00adping \nand many other F* examples provide adequate coverage for completeness. Related Work To our knowledge, \nour self-certi.cation approach for bootstrapping veri.ed typecheckers is new. Self-veri.cation Milawa/ACL2 \n(Davis 2009) provides an inter\u00adesting example of veri.cation bootstrapping for a .rst-order proof system, \nstarting from a minimal checker (coded in Lisp) and grad\u00adually adding self-veri.ed features, but does \nnot formalize or certify its core checker. Jitawa (Myreen and Davis 2011) further provides a concrete \nx86 runtime for Milawa, veri.ed using HOL4. Coq implementation with extraction Several large developments \nof certi.ed programs have been achieved using Gallina, the spec\u00adi.cation language of Coq, with or without \nextraction, notably for certi.ed compilers (Chlipala 2010a; Leroy 2011). In comparison, our method does \nnot rely on extraction. Languages embedded in Coq Another method to obtain a reliable implementation \nis to embed a language within a trusted veri.er. Hence, Nanevski et al. (2008) develop Ynot, a language \nfor veri.ed imperative programming, as a Coq library. While this method is arguably simpler than building \na separate self-certi.ed compiler from scratch, it also retains some of the limitations of its host language. \nFor example, using Ynot to certify hostile code carries the same pitfalls as a direct deployment of Coq. \nAdditionally, while Ynot, like F*, provides support for recursion and effects, it retains Coq s interactive \nproof style with explicit conversions. Re.ection Many recent works show how to ef.ciently verify large \ncerti.cates in Coq using re.ection (Armand et al. 2010; Keller and Werner 2010). We use re.ection in \nour metatheory. However, as explained in \u00a77, the soundness of self-certi.cation limits the extent to \nwhich re.ection can be used when checking certi.cates. Nevertheless, \u00a77.2 describes how even our limited \nuse of re.ection yields signi.cant reductions in the size of certi.cates. Contents \u00a72 introduces our \nmethod and main notations by certi\u00adfying an F* typechecker for the simply-typed . -calculus (STLC). \u00a73 \nreviews the main features of F* and its type system. \u00a74 presents our two theories of F* in Coq and discusses \nthe sharing of induc\u00adtive de.nitions and values between F* and Coq. \u00a75 continues our example and shows \nhow to certify an STLC typechecker in F* . \u00a76 presents the main development of the paper, self-certifying \nthe core typechecker for F* . \u00a77 provides implementation details and ex\u00adperimental results. \u00a78 concludes \nand discusses future work. A link to the latest core typechecker, its speci.cation, and its meta-theory \nin Coq is available from the F* website at http://research. microsoft.com/fstar. 2. Warming up: a certifying \ntypechecker for the simply-typed .-calculus We begin by introducing self-certi.cation and illustrate \nits key elements in a simple setting: the problem of formally certifying the type safety of STLC programs. \nWe describe three solutions with increasing degrees of emancipation: We may construct typing certi.cates \nfor each . -term in an ad hoc manner, for instance by programming a typechecker for STLC in ML, and then \nverify the typing certi.cates it produces using Coq. This approach is illustrated in Figure 2 and discussed \nin the remainder of this section.  We may implement a similar STLC typechecker in F*, and give this \nprogram an F* speci.cation that ensures it only constructs valid STLC typing derivations. We then build \na single F* typing certi.cate for the typechecker program and check this certi.\u00adcate in Coq. We run Coq \njust once, rather than for each . -term we wish to typecheck. We discuss this approach in \u00a75.  We may \nimplement an F* core typechecker in F*, and give this program a speci.cation that ensures it only constructs \nvalid F* typing derivations. We then build a certi.cate for the core typechecker and check this certi.cate \nin Coq. This allows us to run Coq once for all F* programs. Once certi.ed, we may run our core typechecker \nto certify any other program, including our STLC checker, without running Coq anymore. We discuss this \napproach in \u00a76.  2.1 Formalizing STLC in Coq A .rst step to certify the safety of STLC terms is to \nbuild a formal model of STLC in Coq. This model involves de.ning a speci.\u00adcation of STLC syntax and typing \njudgments. We give below our sample Coq de.nitions for the syntax of STLC. Definition Lbvar := string. \nInductive Ltyp : Type := | LTyp_unit : Ltyp | LTyp_fun : Ltyp .Ltyp .Ltyp.   Figure 2. A traditional \ncertifying typechecker for the STLC Inductive Lexpr : Type := | LExpr_unit : Lexpr | LExpr_var : Lbvar \n.Lexpr | LExpr_fun : Lbvar .Ltyp .Lexpr .Lexpr | LExpr_app : Lexpr .Lexpr .Lexpr. Definition Lenv := \nseq (Lbvar * Ltyp). These inductive types are just ML datatypes, so we can share our speci.cation of \nthe syntax between the formal development in Coq and our STLC implementation in ML. As such, these de.nitions \nare depicted in Figure 2 by the box labeled STLC syntax[.ml|.v] . When sharing such de.nitions, we prove \na theorem that for every value of the shared type in one language, there exists a correspond\u00ading value \nof the shared type in the other language. Next, we de.ne the typing judgments of the STLC as an induc\u00adtive \ntype in Coq we give below the rule for functions (. x:t.e). Inductive LTyping : Lenv .Lexpr .Ltyp .Type \n:= ... | LTyping_fun : forall g x t e t , LTyping ((x,t)::g) et .LTyping g (LExpr_fun x t e)(LTyp_fun \nt t ) The inductive type LTyping is the reference speci.cation of the type system, depicted by the box \nlabeled STLC typing.v . Our de.nitions are given in the style used in the rest of the paper (notably \nfor the F* type system), which is convenient for use in the implementation of a typechecker in a real \ncompiler. For instance, we use concrete strings to represent STLC variables. Although natural for programming, \nthe reference type system is not ideal for conducting metatheory. To this end, we give a second speci.cation \nof the type system that uses co.nite quanti.cation in a (named) locally nameless style to represent variables \n(Aydemir et al. 2008) see also \u00a74.2. This speci.cation is depicted by the box labeled STLC CoF typing.v \n. We also prove an adequacy result in Coq (the box STLC Adequacy.v ) that relates the two speci.cations. \nAdequacy states that, for every valid derivation in the reference system, there is a corresponding derivation \nin the co.nite system. We may then develop a standard co.nite theory for STLC, including a dynamic semantics \nand a type safety theorem.  2.2 Programming a certifying STLC typechecker in ML Given a metatheory in \nCoq, a common approach to building a certi\u00ad.ed typechecker would be to implement it as a Coq function \nand to prove that it constructs valid typing derivations. The function can then be extracted to ML and \nrun. This task is trivial for STLC, but for more complex languages (e.g., ML itself, or F*), implementing \nthe typechecker within Coq can be quite challenging: Coq func\u00adtions must be pure and total, whereas typechecking \nroutinely uses general recursion; state for environments, uni.cation, and symbol generation; and exceptions \nfor error handling. Additionally, for this approach to work, one must prove the typechecking function \ncor\u00adrect in Coq, which involves interactive proofs on a large program. To sidestep these dif.culties, \nwe implement the type checker in a general-purpose programming language with .rst-class support for features \nlike effects that are hard to handle in Coq. As shown in the following sections, we can both use these \nfeatures for program\u00adming our typechecker and formally ensure that it is correct. To begin with, we program \nthe typechecker in ML as a partial function stlc typing given the signature below. type LTypingML = ... \n| LTyping fun of Lenv * string * Ltyp * Lexpr * Ltyp * LTypingML val stlc typing: Lenv .Lexpr .Ltyp .LTypingML \nThe type LTypingML shown above is an ML data type for rep\u00adresenting STLC typing derivations. This type \nis similar but much less precise than our reference speci.cation LTyping there exist values in LTypingML \nthat do not correspond to valid reference typ\u00adings. Using just this ML type as a speci.cation, we have \nno way of showing that stlc_typing computes valid typing derivations. Still, whenever the ML term stlc \ntyping g e t computes a derivation d:LTypingML, we can attempt to translate d into a Coq value of type \nLTyping. Within Coq, if d typechecks, then from the rest of the metatheory we may conclude that the STLC \nprogram e is type safe. We need not trust the programs that produce the derivation d and translate it \nfrom ML to Coq all we care about is that the resulting certi.cate is a valid typing for the source term \ne. We do, however, care that the translated certi.cate is a valid typing for the program e, and not some \nother term. However, since the source term is a type Lexpr shared between ML and Coq, the translation \nfrom the abstract syntax of our ML implementation to Coq is simply the identity. The method we have described \nso far is standard for a certifying compiler many such instances exist in the literature (Colby et al. \n2000; Morrisett et al. 1999). However, it requires running Coq on every compilation run. It is preferable \nto certify the STLC checker itself, that is, prove that any certi.cate it produces will always be typeable \nin Coq. Given such a proof, we would not have to run Coq on each compilation, and, furthermore, unless \nthere were some other need for it, we need not produce the derivation value. To achieve this, \u00a75 and \n\u00a76 illustrate how to program the typechecker in F*, a call-by-value language (like ML) with higher-order \nfunctions, state, effects, and recursion, but with a veri.cation system based on dependent typing that \napproaches Coq in expressive power. 3. A review of F* Before proceeding towards self-certi.cation, we \nbrie.y present the syntax and semantics of F*; we refer to Swamy et al. (2011) for a complete presentation \nand examples. The syntax is shown below. Values, expressions, types, kinds, signatures, and environments \nv ::= x | . x:t.e | .a::..e | Dt\u00afv\u00af| vl values e ::= v | ev | et | assume f | let x = e in e'| terms \n' match x with D a\u00afx\u00af. e else ef ,t ::= a | T | x:t . t'|.a::..t | tv | tt'| types . x:t.t'| .a::..t \n| x:t{f }| \u00a1t c ::= * | P | A concrete kinds b ::= c | E base kinds . ::= b | x:t . . | a::. . .' kinds \nS ::= \u00b7| T ::.{D:t}| S,S' signature G ::= \u00b7| x:t | a::. | v1 = v2 | t1 = t2 | G,G' type env. A ::= \u00b7| \nf | l | l | A , A ' dynamic log Values include variables, . -abstractions over values and types, and \nfully applied n-ary data constructors. The value vl is a techni\u00adcal device used to prove the soundness \nof af.ne typing and can be ignored for our present purposes. The notation a stands for a .nite sequence \nof elements a1,...,an for arbitrary n.F* adopts a (par\u00adtially) let-normalized view of the expression \nlanguage e, in par\u00adticular requiring function arguments to always be values this is convenient when using \nvalue-dependent types, since it ensures that expressions never escape into the level of types. The only \nother non-standard expression form is assume f , which is used in the se\u00admantics of ghost re.nements \nand is not discussed further we do not make use of it in our core typechecker.  Types are ranged over \nby meta-variables t and f we use f for types that stand for logical formulas. Types include variables \na, constants T , dependent functions ranging over values whose do\u00admain may be values (x:t . t ') or types \n(.a::..t), types applied to values (tv) and to types (tt '), type-level functions from values or ' types \nto types (. x:t.t and .a::..t), ghost re.nements x:t{f}, and .nally coercions to af.ne types \u00a1t. This \nlast modal operator serves to qualify the type of a closure that captures an af.ne assumption. Kinds \n. include the four base kinds *, P, A, and E discussed previously F* distinguishes the .rst three of \nthese as concrete kinds, since E is used to characterize erasable speci.cations. As at the type level, \nF* has kinds for dependent function spaces whose range are types and whose domain may be either values \n(x:t . .) or types (a::. . .'). Stratifying the language into terms, types, and kinds allows F* to place \nkey restrictions (discussed below) that facilitate automated veri.cation, and to compile ef.ciently to \n.NET. However, strati.cation does come at a cost several pieces of technical machinery are replicated \nacross the levels. Signatures S are .nite lists of mutually recursive datatypes. Each de.nition T ::.{D:t} \nintroduces a set of type constants T1::.1,...,Tn::.n and all their data constructors D1:t1, ..., Dm:tm. \nWe do not need a .xpoint form in the expression language since these types allow us to encode recursive \nfunctions. The addition of mutual recursion is an enhancement over our prior formalization of F*, where \nit was left out for simplicity. Here, we make heavy use of mutual recursion in the formalization of the \ntype system of F* in F* and so include it in our core theory. A characteristic feature of the F* type \nsystem is that the kind of a type indicates whether or not values of that type are pure. In par\u00adticular, \nfunctions in the universe of P-kinded types are guaranteed to be total, whereas those in the *-universe \nmay diverge or have other effects. This allows us to embed a logically consistent sub\u00adlanguage (namely \nthe P-fragment) within F*. (The meaning of the other two kinds is beyond scope for this paper.) To ensure \nthat terms given P-kinded types are strongly normalizing, a well-formedness condition on signatures imposes \na positivity constraint on induc\u00adtive de.nitions for P-kinded types. In addition, the kinding rules for \nfunction arrows are such that the kind of a function type is de\u00adtermined by the kind of its co-domain, \ni.e., the kind of x:t . t ' is the kind of t '. Intuitively, since F* is a call-by-value language, the \ndomain of a function consists of fully evaluated terms, and hence it is the co-domain that determines \nwhether or not a function is total. These and other restrictions (e.g., on cross-universe elimination) \nallow us to place the P-fragment of F* in close correspondence with Coq, where inductives are also positive. \nSpeci.cally, P-kinded types in F* correspond to a fragment of the Type universe in Coq rather than Prop, \ni.e., P-terms in F* need not be computationally irrelevant. We exploit (a limited version of) this correspondence \nin an essential way in the main development of the paper, via our data embedding theorem (Theorem 4). \nTyping judgments The F* type system has several mutually-re\u00adcursive judgments. The judgments are given \nwith respect to typing environments G that track in-scope value variables (x with type t), type variables \n(a with kind .), and equivalences between values (v1 = v2) and types (t1 = t2) introduced when checking \nmatch ex\u00adpressions. These equalities enable implicit conversions, a distinc\u00adtive feature of F* with regard \nto a system like Coq, where all type conversions must be performed by equality-witnessing coercions. \nThe four central judgments are as follows: (1) well-formedness of kinds: S;G f . ok(b), where the well-formedness \nis indexed by a base kind b; (2) kinding of types: S;G f t :: .; (3) typing for values: S;G;X fmv : t, \nand (4) typing for expressions S;G;X fme : t. Note, unlike our presentation of the STLC, F* separates \nvalue and expression typing, which are the two most interesting judgments. They state that a value v \n(resp. expression e) has type t, under signature S, environment G, and an af.ne environment X ::= \u00b7| \n' l | x | X,X', where X,Xdenotes disjoint union of sets of names. The context X represents a set of available \naf.ne assumptions, and usual context splitting rules apply to X when typing the subterms of an expression. \nThe index m on the turnstile represents two possible modes that distinguish the typing of terms that \nappear at the type level from those that appear at the term level the former are subject to less stringent \nrestrictions on af.nity. We give only two sample rules, for value-typing . -abstractions and for expression-typing \napplications, which we also use for ex\u00adamples in the next sections. S; G f t::cS; G,x:t;X,x fme : t ' \nWFV-Fun S; G; X fm . x:t.e : Q(X,x:t . t ' ) ' 'fm S;G;X fme :?x:t . tS; G;Xv : t WFE-App S;G;X, X'fmev \n: t ' [v/x] In WFV-Fun, the .rst premise requires that the argument type t have a concrete kind. The \nsecond premise types the body expres\u00adsion e in a context and an af.ne environment both extended with \nx (so that x may be used once if t is af.ne, e.g. c is A). Finally, the introduced function type is tagged \nwith the af.ne modality (us\u00ading Q(X,t)= \u00a1t, when X is non-empty, and t otherwise) if the function closure \ncaptures an af.ne assumption. In WFE-App, the two premises type e and v as a function and its argument, \nrespec\u00adtively, using disjoint parts X, X' of the af.ne environment. We write ?x:t . t ' to range over \nthe types x:t . t ' and \u00a1x:t . t ', thereby capturing the elimination of both standard and af.ne functions \n(re\u00adspectively) in a single rule. Finally, the result type is obtained by substituting v for x in t ' \n. In addition to these four judgments, F* has several auxiliary judgments, including judgments for subkinding, \nsubtyping, well\u00adformedness of signatures and environments, and the like. We elide these here, since they \ndo not play a central role in the remainder of our presentation. However, one judgment is worth mentioning: \nlogic derivability. The F* type system is parametrized by an external logic, where derivability in this \nlogic is characterized by the judgment S; G |= f . The introduction of ghost re.nements (as well as certain \nimplicit conversions) are governed by this judgment. In effect, the value typing S;G;X fmv : x:t{f } \nrequires deriving S;G |= f[v/x] in the external logic. As such, F* places various admissibility constraints \non this judgment (e.g., that it be closed under substitution; that it be a congruence on equality etc.). \nThe soundness of the F* type system is modulo the soundness of the logic meeting these conditions, and \nwe rely on this for our embedding theorem in \u00a74.3. This approach gives us the .exibility to use F* with \nan external theorem prover, like Z3, where we often instantiate the external logic in question to .rst-order \nlogic with theories. However, instead of trusting the external logic, it is also possible to extract \nproof terms from a decision procedure from the logic and have them checked in pure F*. This is an approach \nfollowed by Chen et al. (2010) in the context of Fine, a predecessor of F* . 4. Formalizing F* in Coq \nA prerequisite for self-certifying F*, and indeed certifying any F* program such as our STLC checker, \nis to formalize F* in Coq. There are three aspects to this formalism. First, we develop a reference speci.cation \nof the F* type system. Next, we develop a co.nite version of the reference type system, prove an adequacy \ntheorem relating the two, and prove the F* type system sound. The third and .nal aspect involves developing \nmetatheory (currently by hand) that relates F* and Coq in a way that justi.es sharing certain inductive \ntypes between the two systems. We consider each of these aspects in turn, returning (in \u00a74.3) to the \nsetting of our STLC checker for illustrative examples.  4.1 A reference speci.cation of the F* type \nsystem in Coq Our reference speci.cation begins with a model of F* syntax. We show a fragment of this \nsyntax below, starting with type de.nitions for the various kinds of names used in our formalization. \nWe have iname for inductive type names; cname for data constructors; vlname for free value names; tyname \nfor free type names; and bvar for bound (value or type) names. Each of these is represented using a string \ntype with decidable equality, the same representation as in the F* implementation of the F* typechecker. \nDefinition iname := String. Definition cname := String. Definition vlname := String. Definition tyname \n:= String. Definition bvar := String. We have four mutually inductive types, for kinds, types, values \nand expressions. We list a representative fragment of these types below, starting with the variant type \ngvar that we use to distinguish bound names and free names in the syntax. We have the four base kinds, \nwhere BK_Comp corresponds to the *-kind of \u00a73. Inductive gvar (T : Type): Type := GV_Bound : bvar .gvar \nT | GV_Free : T .gvar T. Inductive basekind : Type := BK_Comp | BK_Prop | BK_Erase | BK_Afn. Inductive \nkind : Type := | K_Base : basekind .kind | K_ProdK : bvar .kind .kind .kind | K_ProdT : bvar .typ .kind \n.kind with typ : Type := ... | T_Var : gvar tyname .typ | T_Ind : iname .typ | T_VApp : typ .value .typ \n| T_Prod : bvar .typ .typ .typ | T_Ref : bvar .typ .typ .typ | T_Ascribe : typ .kind .typ with value \n: Type := ... | V_Var : gvar vlname .value | V_Fun : bvar .typ .expr .value | V_Const : cname .seq typ \n.seq value .value | V_Ascribe : value .typ .value with expr : Type := ... | E_Value : value .expr | E_App \n: expr .value .expr | E_Ascribe : expr .typ .expr. The abstract syntax closely follows the informal syntax \nof \u00a73. The one addition is the presence of type-and kind-ascription forms at each level, e.g., we use \nT_Ascribe to give a type a kind, which make (core) typechecking more syntax-directed. The reference type \nsystem is formalized as a 4-way mutually recursive inductive type. We show the signatures of these types \nbelow: wfK is the judgment for well-formedness of kinds, wfT is the kinding judgment for types, value_ty \nis value typing, and expr_ty is expression typing. Inductive wfK : icompartment .environment .bindings \n. kind .basekind .Type := ... with wfT : icompartment .environment .bindings . typ .kind .Type := ... \nwith value_ty : icompartment .environment .bindings . seq bvar .mode .value .typ .Type := ... with expr_ty \n: icompartment .environment .bindings  .seq bvar .mode .expr .typ .Type := ... . Each judgment is given \nwith respect to an environment that con\u00adtains three compartments for binding various kind of names. First, \ncorresponding to signature S in \u00a73, an icompartment is a sequence of records, one for each family of \nmutually recursive inductive types. Each record contains the names of the de.ned type constants, their \nkinds, and their constructors. Record constructor : Type := mkConstructor { ct_name : cname; ct_type \n: typ }. Record ikind : Type := mkIKind { it_name : iname; it_kind : kind }. Record inductive : Type \n:= mkIndType { it_ikind : seq ikind; it_constructors : seq constructor }. Definition icompartment : Type \n:= seq inductive. Next, G is split into two parts. The environment compartment is a sequence recording \nfree value and type names. The free names are kept separate from local bindings and equality assumptions \nin\u00adduced by pattern matching. We show the de.nitions of both below. Separating these two compartments \nsimpli.es our adequacy proof, inasmuch as only the local names are subject to a-conversion and implicit \ntype conversion. We include value and type equali\u00adties (EB_VlName and EB_TyName) in the environment as \nthey become necessary in the co.nite system of \u00a74.2 these constructors are not used in the reference \nsystem. Inductive ebinding : Type := | EB_VlName : vlname .typ .ebinding | EB_TyName : tyname .kind .ebinding. \n| EB_VlEq : value .value .locbinding | EB_TyEq : typ .typ .binding. Definition environment : Type := \nseq ebinding. Inductive locbinding := | LB_BvarTy : bvar .typ .locbinding | LB_BvarKind : bvar .kind \n.locbinding | LB_VlEq : value .value .locbinding | LB_TyEq : typ .typ .binding. Definition bindings := \nseq locbinding. Value and expression typing judgments (value_ty and expr_ty) take two additional arguments, \ndiscussed in \u00a73: a sequence of bound names that represents the af.ne compartment and a mode. With these \nde.nitions in hand, we give a .avor of the value_ty and expr_ty judgments by showing the rules for . \n-abstractions and applications, respectively. Note the intensional use of concrete names throughout the \nsystem. | WFV_Fun : forall I G B X m t bt u x body Q, ConcreteKind bt .AQual X (T_Prod x t u) Q .wfT \nI G B t bt . expr_ty I G ((LB_BvarTy x t) :: B)(x :: X) m body u . value_ty I G B X m (V_Fun x t body) \nQ  | WFE_App : forall I G B X X1 X2 m e v x t u tv tres, Split X X1 X2 .StripQual tv (T_Prod x t u) \n. SubstTV u x v tres . expr_ty I G B X1 m e tv . value_ty I G B X2 m v t . expr_ty I G B X m e v tres \n The rules use auxiliary predicates: ConcreteKind identi.es the sub\u00adclass c of kinds; Split speci.es \nX = X1 . X2; Aqual speci.es Q(X,t); StripQual speci.es ?x:t . t '; and SubstTV speci.es value substitutions \nin types. All of these predicates are de.ned as induc\u00adtive types in Coq; for instance, ConcreteKind is \nde.ned as: Inductive ConcreteKind : basekind .Type := | CK_Star : ConcreteKind BK_Comp | CK_Aff : ConcreteKind \nBK_Afn | CK_Prop : ConcreteKind BK_Prop. One may wonder why we do not use functions to de.ne ConcreteKind, \nSubstTV, etc. This is a key point related to the soundness of self-certi.cation, discussed in detail \nin the coming sections. Keeping in mind that we aim to share these de.nitions between F* and Coq, one \nreason for using inductive predicates uni\u00adformly is that F*, being a value-indexed language, does not \nhave function applications within types.  However, our reference type system is not entirely free of \nfunc\u00adtion applications. For example, in de.ning the well-formedness of typing environments, we use the \nfollowing predicate for non\u00admembership in a sequence. Inductive NotMem : A .seq A .Prop := | NotMem_nil \n: forall x, NotMem x [::] | NotMem_cons : forall x y ys, x != y .NotMem x ys .NotMem x (y::ys). In writing \nx != y above, we make use of re.ection and decidable equality on names: the type x != y is a function \napplication that reduces in Coq to the type true=true. We permit such decidable (dis-)equalities in our \nreference speci.cation and show in \u00a74.3 how to model them in F* using ghost re.nements.  4.2 F* metatheory \nin Coq The reference speci.cation of the type system conforms to the in\u00adformal presentation of F* and \nto its compiler implementation. How\u00adever, due to the usage of the for-one locally nameless representation \nof binders (Leroy 2007), this formulation is a poor one for conduct\u00ading metatheory. As explained above, \nwe provide a second speci.\u00adcation of the F* type system, this time making use of the for-all representation \nof binders with the co-.nite quanti.cation optimiza\u00adtion (Aydemir et al. 2008). We prove a correspondence \nbetween the two, and prove a subject reduction result for the second system. We give a .avor of the co.nite \nsystem, still using the rule for . \u00adabstraction. As in the reference system, we have a 4-way mutually \ninductive type for the main judgments of the type system. Inductive pname : Type := TermName : vlname \n.pname | TypeName : tyname .pname. Definition pnames := seq pname. Inductive coF_wfK : ... := ... with \ncoF_value_ty:icompartment .environment .acontext . mode .value .typ .Type := | ... | CoF_WFV_Fun : forall \nI G X m t bt u x body Q (L : pnames), concretekind bt .aqual X (T_Prod x t u) Q .coF_wfT I G t bt .(forall \ny, TermName y ./L . coF_expr_ty I ((EB_BvarTy y t)::G) ((ValueName y)::X) m (subst_e body x y)(subst_t \nu x y)) . coF_value_ty I G X m (V_Fun x t body) Q  The major difference between the two systems is \nin their treat\u00adment of binders. Rule CoF_WFV_Fun requires that the typing of body be insensitive to the \nparticular choice of bound variable name. This is modeled by requiring the body to be typeable for a \nco.nite set of names, that is, those not in the set L. We type the body by substitut\u00ading the bound name \nx for the chosen free name y. As such, in this formulation, there is no need for the local binding context \nthe free names in environment suf.ce. A relatively super.cial difference is in the modeling of the af.ne \nenvironment, which in the co.nite sys\u00adtem is a sequence of value names, whereas in the reference system, \nit is a sequence of bound variables. A signi.cant stylistic difference is that we make liberal use of \nfunctions and type-level reduction provided by Coq in the co.nite system. For example, concretekind is \nnow a boolean function, given below. The co.nite system is not shared with F* and is thus not subject \nto the value-indexed restriction imposed on the reference system. Definition concretekind (b : basekind): \nbool := match b with | BK_Comp | BK_Afn | BK_Prop . true | BK_Erase . false end. Our .rst theorem is \nadequacy of the reference system with regards to the co.nite system. It is stated below for expression \ntyping, but of course its proof requires a 4-way mutual induction on the main judgments. THEOREM 1 (Adequacy). \nforall I G X m e t, expr_ty I G [::] Xmet .coF_expr_ty I G X m e t. Next, we give our main subject-reduction \ntheorem. To simplify the presentation in this paper, we consider a specialization of our subject reduction \ntheorem to programs that, .rst, make no use of af.nity; and, second, have no dynamic assumptions for \nintroducing ghost re.nements. We consider reduces: icompartment .expr . expr .Type, an inductive de.nition \nspecializing the general reduc\u00adtion relation for F* . THEOREM 2 (Subject Reduction, specialized). forall \nI G e e t, coF_expr_ty I G [::] Term_level e t . reduces I e e . coF_expr_ty I G [::] Term_level e t. \n In the rest of the paper, we only rely on the following corol\u00adlary, obtained by composing the adequacy \ntheorem with subject reduction and an induction on the sequence of reduction steps evaluates is a transitive \nclosure of reduces followed by matching on E_Value. COROLLARY 3 (Subject Reduction to Values). forall \nI G e v t, expr_ty I G [::] [::] Term_level e t . evaluates I e v . coF_value_ty I G [::] Term_level \nv t.  For convenience, we use abbreviations for typing closed terms, de.ned as follows: Definition val_ty \ni v t := value_ty i [::] [::] [::] Term_level v t. Definition exp_ty i e t := expr_ty i [::] [::] [::] \nTerm_level e t. Definition coF_val_ty i v t := coF_value_ty i [::] [::] Term_level v t.  4.3 Sharing \nde.nitions and embeddings Inductive types in F* are nearly as expressive as inductive types in Coq. In \nthis section, we give an embedding result, Theorem 4, which allows us to soundly treat certain inductive \ntypes in Coq as if they were also inductive types in F*, and vice versa. We exploit this result to give \nstrong speci.cations to typecheckers (and other programs) implemented in F*, ensuring, for example, that \nthey only compute valid derivations. Theorem 4 then allows us to conclude that these derivations are \nalso valid reference typings in Coq. We illustrate this approach using the STLC reference speci.ca\u00adtion \nas an example. In \u00a72, we argued informally that the syntax of STLC terms can be shared between ML and \nCoq, whereas the in\u00adductive type specifying the typing judgment could not, since ML inductive types are \nnot suf.ciently precise not so for F*. We can express both the syntax and the reference typing for STLC \nas in\u00adductives in F*, in a module STLC (outlined below) in close corre\u00adspondence with our Coq de.nitions. \nmodule STLC type Ltyp :: P= | LTyp unit : Ltyp | LTyp fun : Ltyp .Ltyp .Ltyp type Lexpr :: P= | LExpr \nunit : Lexpr | LExpr var : string .Lexpr | LExpr fun : string .Ltyp .Lexpr .Lexpr | LExpr app : Lexpr \n.Lexpr .Lexpr.  type Lenv = seq (string * Ltyp) type LTyping :: Lenv . Lexpr . Ltyp . P= ... | LTyping \nfun : g:Lenv .x:string .t:Ltyp .t :Ltyp .e:Lexpr .LTyping ((x,t)::g) et .LTyping g (LExpr funxte)(LTyp \nfuntt ) Formally, sharing between F* and Coq is justi.ed by an em\u00adbedding theorem (explained below). \nPragmatically, resolving dif\u00adferences in concrete syntax is easily automated we provide some basic support \nfor this, although we often manually transcribe def\u00adinitions from F* to Coq. Less super.cially, we have \nimplemented pretty printers that allow F* values and type de.nitions to be printed as values in the abstract \nsyntax of F* in Coq. This is essential for importing large certi.cates and we use this tool extensively. \nWe describe the correspondence between inductive types in F* and Coq using examples from the STLC development. \nFor every F* .le, say STLC.fst, containing the type de.nitions in the STLC module, we have a Coq .le, \nSTLC.v, with the following elements. Surface de.nitions We have Coq de.nitions such as Inductive Lexpr \n: Type := ... (listed in \u00a72.1) that mirror STLC de.nitions such as LExpr. We apply this super.cial translation \nonly to the F* induc\u00adtive types that can be viewed soundly as Coq inductives, namely those that meet \nthe P-restriction formalized below. In addition to the basic inductive types we have seen so far, P-restricted \ntypes also include inductive types with ghost re.nements, where the re\u00ad.nement formulas correspond to \nthe use of re.ection for computing decidable equalities. For example, the type in F* corresponding to \nthe de.nition of NotMem from \u00a74.1 is NotMem, shown below. type tag = D:tag type NEq v1 v2 =:tag{v1 != \nv2} type NotMem :: a . seq a . P= | NotMem nil : x:a .NotMem x [] | NotMem cons : x:a .y:a .tl:seq a \n.NEq x y .NotMem x tl .NotMem x (y::tl) Whereas in Coq we use the function application x!=y, in F* we \nuse a type re.ned with the formula x!=y. In general, any F* ghost re.nement formula can be embedded in \nCoq using re.ection, provided we have a corresponding function in Coq that can decide the formula. In \nprinciple, we could use this embedding to specify the entire type system of F* using ghost re.nements, \nbut this would require having a function in Coq to decide typing which, of course, renders moot building \na certi.ed typechecker for F* in the .rst place. As such, we restrict our use of re.ection in the reference \nsystem to trivially decidable equalities. We show how to relate these formally below. Embedded signatures \nWe also embed the F* inductives as terms in our Coq formalization of F*. Speci.cally, we generate a Coq \nvalue of type icompartment that represents our formalization of these F* inductive de.nitions in Coq. \nAll F* inductive types can be embedded in this manner, whether they meet the P-restricted condition or \nnot. For instance, for the Lexpr inductive we generate: Definition iLexpr: inductive := mkIndType [:: \nmkIKind \"Lexpr\" (K_Base BK_Prop)] [:: mkConstructor \"LExpr_App\" (T_Prod \"\" (T_Ind \"Lexpr\") (T_Prod \"\" \n(T_Ind \"Lexpr\")(T_Ind \"Lexpr\"))); ... ]. Definition iSTLC: icompartment := [:: expr ; ... ]. Type embedding \nfunctions For each P-restricted inductive type T of kind a1::.1 . ... . an::.n . x1:t1 . ...xm:tm . P, \nwe have a Coq function tembed_T of type typ .... .typ .value .... . value .typ, for n typs and m values. \nFor instance, for the Lexpr and LTyping inductives of STLC, we generate: Definition tembed_Lexpr := (T_Ind \n\"Lexpr\"). Definition tembed_LTyping (get:value) := (T_VApp (T_VApp (T_VApp (T_Ind \"LTyping\") g) e) t). \nValue embedding functions For values of shared inductive types, we have functions in Coq that produce \nterms in the value inductive that represents F* values in Coq. For instance, we have a function from \nsurface to embedded STLC expressions: Fixpoint embed_Lexpr (e: Lexpr): value := match e with ... | LExpr_App \ne0 e1 . V_Const \"LExpr_App\" [::] [:: embed_Lexpr e0; embed_Lexpr e1 ]. Using these value embedding functions, \nwe de.ne analogs of the type embedding functions that allow us to combine the type and value embeddings. \nFor example, we de.ne the following wrapper around tembed_LTyping: Definition tembed_LTyping get := tembed_LTyping \n(embed_Lenv g)(embed_Lexpr e)(embed_Ltyp t). Finally, we have pretty-printers from F* values to Coq values \nrepresenting F* abstract syntax. For instance, we print the F* value LExpr App (LExpr var \"x\")(LExpr \nVar \"y\"): Lexpr as the Coq value LExpr_App (LExpr_var \"x\")(LExpr_Var \"y\"): Lexpr To this end, the F* \ncode generator injects a ToString method into each .NET class that represents an F* data constructor. \nBy calling ToString on any (.rst-order) F* value and printing the result, we get the representation of \nthat value as a value of type value, the type of F* values, in Coq. This tool is in effect an (untrusted) \nF* primitive function, string of any : a .string. Formal embedding Our theorem states that the existence \nof an embedded F* proof for a given inductive type implies the existence of a Coq proof for that type. \nWe .rst de.ne a restriction on induc\u00adtive types such that our theorem applies. The purpose of the restric\u00adtion \nis .rst to exclude non-P-fragment types: types that live in F* s *-universe, for instance, need not have \nany analog in Coq. Second, F* expressions, even in the P-fragment, employ constructs that do not translate \ndirectly to Coq notably implicit conversions intro\u00adduced by pattern matching, which must be made explicit \nin Coq. For this reason, the P-restriction also excludes types whose values may contain (non-value) sub-expressions, \nin particular . -terms. We still allow some limited use of ghost re.nements in P-restricted types, notably \nfor types re.ned by formulas speaking about decid\u00adable, syntactic equality on F* values. A type t is \nP-restricted when it is a type variable whose kind is P-restricted; or NEqv 1v 2; or T a x where T is \nP-restricted.  A kind . is P-restricted when it is of the form a::. . x:t . P where each .i and each \nti is P-restricted.  An inductive type T de.ned by T ::.{D:t} is P-restricted when the kind . is P-restricted \nand each constructor D:t has a type t of the form a::. . x:t . T a x where each .i and each ti is P-restricted. \n THEOREM 4 (Embedding). Let S be a signature and i its embed\u00adding in Coq. Let T be a P-restricted inductive \ntype of S with kind a::. . x:t . P and let T be the Coq surface-level inductive type for T. We have . \n(a : .)(x : t) (v: value), coF_val_ty i v (tembed_T a x) .T a x. The statement of this (meta) theorem \nis not expressible in Coq, since it involves quantifying over Coq inductive types, so we prove it by \nhand. However, we can easily express in Coq instances of the theorem for speci.c type constructors. We \nwill later formally ad\u00admit some of these instances for types such as LTyping for STLC. In future work, \nwe anticipate mechanizing the proofs of speci.c instances of the data embedding theorem in Coq, rather \nthan ad\u00admitting them via the meta theorem.  Figure 3. Certifying an STLC checker in F* Our hand proof \nrelies on a structurally inductive function that translates F* types and values to Coq. We show that \nthis trans\u00adlation preserves types. This proof, in most cases, appeals to a more general lemma relating \narbitrary P-fragment terms (including those with reducible expressions) to terms in the Type fragment \nof CiC (Swamy et al. 2011). The one case not handled by the general lemma is for embedding the F* type \nNEq v1 v2 =:tag{v1 != v2}. For this case, we use the premise coF_val_ty i v (T_Ref _ _ (embed v_1)!= \n(embed v_2))), which introduces a ghost re.nement. As dis\u00adcussed in \u00a73, the introduction of ghost re.nements \noccurs via a judgment in an external logic, formally represented in the metathe\u00adory of F* as a predicate \nLogicEntails. We thus have LogicEntails i [::] ((embed v_1)!= (embed v_2)). One of several admissibility \nre\u00adstriction on this judgment ensures that it soundly decides primitive (dis-)equalities, from which \nwe conclude v_1 != v_2. In effect, this captures our assumption that the F* runtime system properly im\u00adplements \nsyntactic comparison of values, and that type-safety in F* is modulo the soundness of the external logic. \n5. From certifying to certi.ed: STLC in F* We now return to the problem of certifying an STLC typechecker. \nFigure 3 illustrates the architecture we use, and \u00a76 shows an instan\u00adtiation of this architecture to \ncertify a typechecker for F* itself. The process begins at the top right of the .gure, depicting our \nformalization of F* in Coq (in addition to the formalization of STLC). Next, in contrast to Figure 2, \nsince we program in F* , we share both the de.nitions of the STLC syntax and its reference type system \nbetween F* and Coq. We also share the de.nitions of the F* syntax. We implement the STLC checker in F* \nand give it a strong speci.cation, stating that it computes (at most) valid STLC typings. We let F* typecheck \nit and produce its typing certi.cate then, as in \u00a72 for STLC typings, we translate the certi.cate to \nCoq and typecheck it there, against the reference speci.cation of F* and the embedding as an icompartment \nof the STLC syntax and reference typing. We then complete the certi.cation of our checker from its speci.cation \nand the F* metatheory. Programming and verifying the STLC checker Our STLC checker in F* is a partial \nfunction with the following signature: stlc checker: g:Lenv .e:Lexpr .t:Ltyp .Partial (LTyping g e t) \nAs discussed in \u00a73, the F* kind system distinguishes partial and total functions. Since we intend stlc \nchecker to be partial (possibly throwing exceptions), we wrap its co-domain with a type construc\u00adtor \nPartial, de.ned below, to lift the P -kinded LTyping g e t into the *-universe of general computations. \ntype Partial :: P . *= P2S : .a ::P. a .Partial a We can run our checker to compute certi.cates for sample \nSTLC programs, such as . x.x, as follows: let id: Lexpr =(LExpr Fun \"x\" LTyp unit (LExpr Var \"x\")) let \nt: typ =(LTyp Fun LTyp unit LTyp unit) let (P2S (pf : LTyping [] id t)) = stlc checker [] id t Now, \ninstead of translating and checking each such pf using Coq, as in \u00a72, we want to certify stlc checker \nonce and then run it repeatedly on STLC programs without further reliance on Coq. The process of certifying \nstlc checker involves several steps, some of which we have already seen. (1) We share the de.nitions \nin the F* module STLC with Coq to obtain a Coq module STLC. As we have seen in \u00a72 and \u00a74.3, this module \ncontains the reference speci.cation of the STLC type system in Coq, as well as various embeddings of \nSTLC into F* abstract syntax within Coq. Module STLC. Inductive Ltyp : Type := ... Inductive Lexpr : \nType := ... Definition Lenv := seq (Lbvar * Ltyp). Inductive LTyping : Lenv .Lexpr .Ltyp .Type := ... \n... Definition iLexpr: inductive := ... Definition iLTyping : inductive := ... Definition iSTLC : icompartment \n:= [:: iLexpr; iLTyping...]. ... Definition tembed_Ltyp : typ := (T_Ind \"Ltyp\"). Definition tembed_Lexpr \n: typ := (T_Ind \"Lexpr\"). Definition tembed_LTyping g e t : typ := (T_VApp (T_VApp (T_VApp (T_Ind \"LTyping\") \ng) e) t). ... Fixpoint embed_Ltyp (t: Ltyp): value := ... Fixpoint embed_Lexpr (e:Lexpr): value := ... \nFixpoint embed_Lenv (e:Lenv): value := ... ... Definition tembed_LTyping get := ... (2) We print the \nabstract syntax of stlc checker as an expr in Coq. The process of verifying stlc checker involves trusting \na parser and pretty printer (implemented in F#), since the main theorem will speak about the reduction \nto a value of this term. However, this degree of trust is no more that the trust one already places in \nCoq to be con.dent that one has proved the theorem that one set out to prove, one must be careful to \nhave Coq print the statement of the theorem that was proven, with notations and implicit coercions disabled, \nand to manually inspect that the theorem proven was what was intended a recipe prescribed by Pollack \n(1998), among others. Definition stlc_checker : expr := (E_Value (V_Fun ... )) . (3) We verify stlc checker \nby building a typing derivation for it with respect to the F* reference type system. The means by which \nthis derivation is produced is irrelevant any valid typing will do. We may, for example, run an (uncerti.ed) \nF* typechecker implemented in F#, have it construct a derivation, print the resulting derivation, and \ncheck it in Coq using the embedded types listed below. (Eventually, using the self-certi.ed F* type\u00adchecker \nof \u00a76, we need not even check this certi.cate in Coq.) Definition asVal (x:string) := V_Var (GV_Bound \nx). Definition wf_iSTLC : wfEnv iSTLC [::] [::] := ... . Definition stlc_checker_typing : expr_ty iSTLC \nstlc_checker (T_Prod \"g\" tembed_Lenv (T_Prod \"e\" tembed_Lexpr (T_Prod \"t\" tembed_Ltyp (T_App (T_Ind \n\"Partial\") (tembed_LTyping (asVal \"g\")(asVal \"e\")(asVal \"t\")))))) := (* pretty-printed certificate *) \n (4) Within Coq, we prove a lemma stating that the F* function stlc_checker applied to any F* values \ng of type tembed_Lenv, e of type tembed_Lexpr, and t of type tembed_Ltyp is an F* ex\u00adpression of type \nembed_LTyping g e t. The proof follows from three applications of the function-application rule (WFE_App) \nof the F* reference type system. Definition embed_check g e t := (E_App (E_App (E_App stlc_checker (embed_Lenv \ng)) (embed_Lexpr e)) (embed_Ltyp t)). Lemma embed_check_ty : forall (g:Lenv)(e:Lexpr)(t:Ltyp), expr_ty \niSTLC (embed_check g e t) (tembed_Partial (tembed_LTyping get)). (5) We admit an instance of Theorem \n4 applied to LTyping. Rather than relying on this hand-proved theorem, we could, in princi\u00adple, formally \nprove this instance by inversion of the embedded\u00adtyping assumption. Axiom LTyping_data_embedding: forall \n(g:Lenv)(e:Lexpr)(t:Ltyp)(r:value), coF_val_ty iSTLC r (tembed_LTyping get) .LTyping g e t. (6) We also \nhave a speci.c instance of a canonical forms lemma from the F* metatheory applied to the Partial type \nconstructor. This provides us with a convenient inversion principle to reason about the result of stlc \nchecker. Lemma Partial_inv: forall r t, coF_val_ty iSTLC r (T_App (T_Ind \"Partial\") t) .(exists v, coF_val_ty \niSTLC v t). (7) To complete the proof of certi.cation for stlc checker, we apply Corollary 3 (subject \nreduction to value) to embed_check_ty, followed by Partial_inv and LTyping_data_embedding. Theorem partial_correctness_of_stlc_checker \n: forall (g:Lenv)(e:Lexpr)(t:Ltyp)(r:value), evaluates iSTLC (embed_check g e t) r .LTyping g e t. Thus, \nwe reach our stated goal the F* program stlc checker (par\u00adtially) decides the type safety of STLC expressions. \nGoing further, we may rely on the metatheory of STLC to replace LTyping g e t with runtime safety for \ne. 6. Emancipation through self-certi.cation The certi.cation method of \u00a75 is clearly not speci.c to \nSTLC the formal development generalizes naturally to F* itself. We apply this method to F*, as outlined \nin Figure 1, and obtain a certi.ed F* core typechecker that can be used to check and certify all F* programs \nindependently of Coq. We .rst explain the steps that lead to the main theorem of the paper. We then discuss \nsome of the subtleties behind the proof, the impact of the P-restriction, and some aspects of our adequacy \nresult. 6.1 Self-certifying F*: the main development The .rst step in our development is to share the \ninductive types for the F* abstract syntax and reference type system between F* and Coq this corresponds \nto step 1 in \u00a75. All the de.nitions of \u00a74.1 are expressed as F* inductive types in a CoreTyping module, \nand these de.nitions are also embedded in Coq within the F* theory. For example, we have mutually-recursive \njudgments in F*: type wfK :: icompartment . environment . bindings . kind . basekind . P = ... and wfT \n:: icompartment . environment . bindings . typ . kind . P= ... and value ty :: icompartment . environment \n. bindings . acontext . mode . value . typ . P= ... and expr ty :: icompartment . environment . bindings \n . acontext . mode . expr . typ . P = ... embedded, e.g., as Definition i_mutual_ty : inductive := mkIndType \n[:: (mkIKind \"wfK\" ...); ... ;(mkIKind \"expr_ty\" ...)] [:: ...]. Definition iCoreTyping : icompartment \n:= [:: ...; i_mutual_ty ]. In the rest of this section, we focus on expression typing and omit the details \nfor the other mutually-recursive functions. We implement a core typechecking algorithm, an F* partial \nfunction with the following signature: val etyping: i:icompartment .g:environment .b:bindings . a:acontext \n.m:mode .e:expr .t:typ . Partial (expr tyigbamet)  The de.nition of etyping relies on several other \ntop-level let bindings de.ned in the CoreTyping module. We use an existing F# implementation of the F* \ntypechecker to compile and verify CoreTyping. This F# typechecker is not certi.ed, nor does it actually \nproduce typing derivations that can be certi.ed. Once built, we run the etyping function on (the abstract \nsyntax of) the top-level let bindings in CoreTyping, each a value in the shared inductive type expr, \nincluding etyping itself. We print the abstract syntax of each let binding as a Coq value, corresponding \nto step 2 in \u00a75. In the case of etyping, this is: Definition etyping : expr := (E_Value (V_Fun ...)). \nThe function etyping applied to each let binding in CoreTyping produces a typing derivation d of type \nexpr ty, the reference speci.\u00adcation of expression typing in the F* type system. Since this deriva\u00adtion \nis a value in a shared type, we print the derivation as a Coq value (step 3 of \u00a75). For etyping, this \nis: Definition etyping_cert : expr_ty iCoreTyping env [::] [::] Term_level etyping (T_Prod ...):= (* \nlarge certificate from F**) It is not strictly necessary to run etyping on CoreTyping to pro\u00adduce the \ncerti.cates any means of producing the certi.cate will do. However, by running a typechecked program \non itself, we gain con.dence that the resulting certi.cate will also typecheck in Coq. Indeed, once we \nhad set up the infrastructure and typechecked a few certi.cates on small programs, the remaining 7 GB \nof certi.cates were typechecked in Coq slowly, but steadily. Running etyping on itself also provides \na useful test of its completeness. The certi.cate above provides a typing of etyping in a context env. \nThe context includes assumptions for each top-level let bind\u00ading that etyping depends on. After checking \ncerti.cates for these let bindings, we compose them using a substitution lemma from the F* metatheory \nto obtain the following lemma, where etyping is a closed term obtained by substituting each of the free \nvariables in etyping with their corresponding value. Lemma etyping_typing : coF_expr_ty iCoreTyping etyping \n(T_Prod ...). Next, we de.ne an auxiliary function to abbreviate the applica\u00adtion of etyping to its embedded \narguments and we show that it is well-typed by successive applications of WFE_App. Definition embed_check_etyping \ni g b a m e t := E_App (E_App etyping (embed_icompartment i) ...)(embed_typ t). Then, we admit an instance \nof Theorem 4 for expr_ty, and use Partial_inv and Corollary 3 to conclude the formal proof for the main \nresult of this paper: if the core typechecker applied to (embeddings of) the parameters of the expr_ty \njudgment returns any certi.cate r, then the judgment is valid. THEOREM 5 (Self-certi.cation). Theorem \npartial_correctness_of_etyping: forall i g b a m e t r, evaluates iCoreTyping (embed_check_etyping i \ng b a m e t) r .expr_ty i g b a m e t.  With this theorem, the F* typechecker is emancipated from Coq. \nWe may use etyping to check any F* source program for instance our STLC checker and, if it succeeds in \nconstructing a derivation, we can be sure that this program is type-correct. We may also use it to bootstrap \nmore sophisticated F* typecheckers. Of course, if the type system were to evolve, we would still have \nto conduct the metatheory of F*v2 in Coq, but, as long as the changes can still be expressed in F*, we \ncan implement and certify F*v2 using our initial self-certi.ed F* checker, without the need to generate \nand check large Coq certi.cates ever again.  6.2 Some technical aspects of the development We discuss \ntwo technicalities in this section, starting with an anal\u00adysis of the P-restriction of \u00a74.3 and then \nconsidering the treatment of substitutions, a-conversion, and uniqueness of names. Analyzing the P-restriction \nUsing P-restricted types to de.ne the F* type system gives us a convenient way (via Theorem 4) to reason \nabout the adequacy of the speci.cation of our core type\u00adchecker. However, the P-restriction also imposes \nsome dif.culties which require particular care. We have already seen in \u00a74.2 that we cannot use function \napplications (like concretekind) in our refer\u00adence system, since this falls outside the expressive power \nof F* s value-dependent type system. There are also well-formed, poten\u00adtially useful P-types in F* that \nare not P-restricted. For example, while the basic idea of co.nite quanti.cation can be easily expressed \nin value-dependent F*, an inductive type of the form shown below is not P-restricted, since its values \ncontain function-typed subterms. type value ty :: = ... | WFV Fun : x:bvar .t:typ .e:expr .L:seq pname \n. (y:vlname .NotMem (TermName y) L .expr ty ... ) . value ty ... (V Funxte)  Although such types are \nexpressible in F*, we avoid them in our speci.cations for two reasons. Consider the shape of an F* typing \ncerti.cate using the value above, say WFV Fun ... (.y.e) .... To share this certi.cate with Coq, we must \nsomehow translate the closure . y.e to a Coq lambda: this involves breaking the closure, inspecting its \ncode, and printing it in effect a form of higher\u00adorder marshalling. Further, the language of F* expressions \ndoes not correspond syntactically to the language of Coq terms: typing the body of the closure may require \nthe use of implicit conversions and these have to translated to explicit equality-witnessing coercions \nin Coq, i.e., even after breaking closures, we need a type-directed translation to marshall them to Coq. \nThe P-restriction conveniently sidesteps these problems. As pointed out earlier, implementing a compiler \nwith co.nite quanti.cation is undesirable anyway. For the few cases where we might use function types \nin our speci.cation (e.g., when using negations), we rely on the correspondence be\u00adtween ghost re.nements \nand re.ection provided by Theorem 4. Substitution, a-conversion, and adequacy In order to show its adequacy \nwith regards to the co.nite system, we carefully restrict the (re-)use of names in the reference system: \nin particular, in any term, we require that any sequence of nested binders always bind distinct names. \nFor instance, the value . x.. x.x is not well-formed in our reference system. Our core typechecker rejects \nsuch programs outright, since it relies on the F* front-end to introduce unique names. How\u00adever, it must \nalso maintain the invariant, notably as it applies substitutions. Consider typing the expression f .y:t.y \nin a con\u00adtext that binds f to the type x:(a:t .t) .y:t .t x. All these terms meet our unique-binding \nrequirement, but after the substitution (y:t .t x) [(y:t .t / x)] the resulting type y:t .t (y:t .t) \nbinds y twice and would be rejected by the reference type system. (Such a type and substitution are usually \nconsidered well-formed, inasmuch as there is no name capture.) To prevent such instances, substitu\u00adtions \nin our reference system are, essentially, partial functions that are unde.ned whenever they would produce \na term that breaks our invariant. For this reason also, it is convenient to specify sub\u00adstitutions using \ninductive types (relations) rather than functions. To type the expression above, our typechecker .rst \nexplicitly a\u00adconverts the type of f, renaming its bound variable y, then applies the substitution. 7. \nProgramming and verifying the F* checker The new self-certi.ed typechecker, CoreTyping, is only a small \npart of the F* compiler. The concrete syntax of F* is parsed by modules implemented in F#, the parse \ntree is desugared into a minimal AST which is then typed by another, ad hoc source typechecker that im\u00adplements \nvarious heuristics, including a form of bidirectional local type inference. This main typechecker makes \ncalls to Z3 to prove re.nement properties, and then builds a fully annotated core AST for the program, \nthat is, a value in the shared inductive type expr. This AST is then passed to CoreTyping to build a \nreference typ\u00ading. This section discusses the design of CoreTyping and presents several experimental \naspects of the self-certi.cation process. 7.1 The design of CoreTyping The .rst dif.culty in implementing \nCoreTyping is to make F* typ\u00ading syntax-directed. We use the source typechecking pass for this: every \nuse of subtyping and subkinding in the AST is annotated with an explicit type-or kind-ascription form, \nserving as an indicator to the core typechecker to apply the subtyping judgment. This sim\u00adpli.es core \ntyping, but does not make it fully syntax-directed, for two reasons. First, the signature of etyping \nshown in the previous section is for a pure typechecking algorithm it requires the con\u00adtext to provide \nthe expected type of every subterm. Instead, we im\u00adplement a function etyping aux that computes and returns \nthe type of an expression (relying on ascriptions etc.) with its certi.cate. The function etyping is \nsimply a top-level wrapper of etyping aux that checks that the computed type matches the type provided \nby the caller. A second dif.culty in implementing etyping aux is the splitting of af.ne contexts. The \nreference type system features non\u00addeterministic context splits (as it should), but this is not directly \nimplementable. Instead, etyping aux implements a bottom-up com\u00adputation of used af.ne names to provide \na precise split of the af.ne context. The signature of etyping aux follows: val etyping aux: i:icompartment \n.g:environment .b:bindings . a:seq bvar .m:mode .e:expr . (t:typ * used:seq bvar * unused:seq bvar * \nSplit a used unused * expr tyigbusedmet)  This function returns a type t, a partition of the af.ne \ncontext a into two fragments used and unused, and a derivation for the typing of the expression e in \nthe af.ne context used at the type t. Note that the default tuple constructor in F* (encoded using an \ninductive type of the kind a ::*. (a . *) . *) constructs types in the *-universe. As such, the F* kinding \nrules treat etyping aux as a partial function, without the need for an additional Partial wrapper. Pattern \nmatching and implicit conversions The most complex part of the typechecker deals with pattern matching. \nOne distinctive feature of F* (as compared, say, to Coq) is its support of implicit type conversions \nand type re.nements using equalities introduced in the context due to pattern matching. These conversions \nare par\u00adticular convenient for programming in F*, and our core typechecker makes heavy use of them, with \n196 conversions at various places. In contrast, Coq programmers must explictly apply conversions, al\u00adthough \nrecent work alleviates some of this burden (Sozeau 2010). Uni.cation, state, and exceptions The implementation \nof pattern matching relies on an algorithm to .nd a substitution that uni.es the type of the scrutinee \nwith the type of the pattern. We implement this algorithm .rst in an ad hoc manner, by making use of \nrecursion (without providing any termination proof), state, exceptions and the like, and in doing so \ncompute a candidate substitution. We then im\u00adplement a certi.cation pass that builds a proof of validity \nfor the candidate substitution. Programming in this style is convenient and is enabled by F* s liberal \nsupport of recursion in its *-fragment, but it is not particularly ef.cient. In the future, we hope to \ndirectly certify the substitution built by an ef.cient, stateful uni.cation al\u00adgorithm. We also use state \nand exceptions elsewhere in CoreTyping, for generating names, for performing I/O, and .agging errors; \nF* s value-dependency makes it easy to cope with these features.  7.2 Engineering the certi.cation \nprocess As a .rst attempt, we simply printed the F* certi.cates into text .les in the Coq syntax. Although \nthe internal representation of certi.cates in F* is compact, their printing is rather verbose. For instance, \nfully printing a certi.cate for 6 lines of code generates a 480 MB Coq source .le, which is too large \nto verify. Instead, we implement a fairly sophisticated, compact format that enables Coq to check all \nthe certi.cates that we produce. Thankfully, we need not trust the code that prints the bulk of our certi.cates. \nAs discussed in \u00a75, we depend only on the statement of etyping cert in Coq, but this part of the certi.cate \nis relatively small, so it can be printed verbatim and inspected manually. Source-level splitting Our \nmethod lends itself naturally to incre\u00admental, modular veri.cation: we generate separate certi.cates \nfor each top-level let binding in the typechecker and compose these to obtain our certi.cation result. \nThis allows us to split our certi.ca\u00adtion into 215 typing judgments. Formally, this approach is justi.ed \nby the mechanized F* metatheory. Given a sequence of top-level bindings let x1 = e1 ...let xn = en, we \ntypecheck each ei in an envi\u00adronment that includes locbindings for each of x1 ...xi-1 at their cer\u00adti.ed \ntypes. Our adequacy and substitutivity theorems ensure that the closure of the .nal function etyping \nobtained by substituting each xi with ei is well-typed in the co.nite system. Hash consing We share common \nsub-terms in certi.cates by hoisting them into sequences of Coq Definitions. (Coq also im\u00adplements hash \nconsing but does not do any memoization while type-checking, so hoisting still helps.) Aggressive hash \nconsing may cause terms to be lifted out of their context, thereby breaking Coq inference for their implicit \ntype arguments, so we implement a partial hash consing that keeps enough context around those terms. \nRe.ection A large portion of our certi.cates are devoted to trivial proofs of properties such as list \nmembership and disjointness of lists. We print proofs of these properties by re.ection, relying on Coq \nfunctions to show the existence of the corresponding proof terms. We rely on six such Coq functions. \nFor example, an F* proof of NotMem x xs for some closed values substituted for x and xs may involve many \nnested constructors, but its Coq proof is just notmemP x xs (refl_equal true) relying on a simple re.ection \nlemma: Lemma notmemP : forall (A : eqType)(x : A)(xs : seq A), notmem x xs = true .NotMem x xs. where \nnotmem x xs is a Coq boolean function deciding if x is not a member of xs. When x is indeed not a member \nof xs, notmem x xs reduces to true, leading to notmem x xs = true being con\u00advertible to true = true. \nHence, providing a trivial re.exivity proof (refl_equal true) is suf.cient to have Coq check NotMem x \nxs. Compact identi.ers The default Coq representation of strings where each 8-bit character is coded \nas a sequence of eight booleans is inadequate for large certi.cates, especially as all our identi.ers \nare coded as strings. Instead, we check certi.cates using a custom\u00adbuilt Coq version with native support \nfor a compact representation of arrays (Armand et al. 2010). Coq-level splitting and opacity Even after \nsplitting, hash-consing and re.ection, some certi.cates remain too large for Coq to han\u00addle. Our largest \ncerti.cate is 214 MB. Thus, we perform another level of certi.cate splitting into sequences of de.nitions \nat most 10,000 lines a piece; this keeps the size of each resulting piece be\u00adlow 1 MB, faster for Coq \nto process. Coq checks one piece at a time, with all the previous pieces for the same certi.cate loaded \nas libraries. Such loading is very time-and memory-consuming, es\u00adpecially for large certi.cates. To optimize \nloading, subgoals of the previous parts are generated as opaque lemmas, allowing Coq to load just their \ntypes and not their proofs for checking the fol\u00adlowing pieces. However, all our de.nitions and lemmas \nare at the top-level. Thus, due to the transitive nature of the loading mech\u00adanism of Coq, it is not \npossible to load one speci.c subgoal of a previously checked part without loading the statements of the \nde.\u00adnitions and subgoals of all previous parts. Hence, checking a piece may spend several minutes just \non loading.  7.3 Performance CoreTyping consists of 5,139 lines of F* source code. We organize the checker \ninto 11 modules. (Although F* has a module system that resembles F# s, we make no essential use of it \nin CoreTyping, since this module system is outside the scope of our formalization.) For each module, \nthe table below gives the number of lines of F* source code; the time taken to certify the module within \nF*; the number of Coq certi.cates generated; the time taken to print them; their total size; and, .nally, \nthe time taken to check them in Coq. Module LOC tc(s) # certs pp(s) size (MB) Coq Prims 57 4.7 16 8 5.4 \n3m Util 131 0.7 9 10 9.8 6m FiniteSet 344 3.7 30 90 71.8 1h Terms 248 0.6 7 12 15.0 9m Env 254 2.4 12 \n43 42.4 32m FreeNames 417 14.3 12 204 197.0 3h Binders 333 9.3 7 144 156.0 2h Subst 482 21.1 11 232 246.0 \n3h Unify 118 4.3 7 22 70.3 19m Z3Interface 25 1.9 3 1 53.6 2m Typing 2730 860.2 101 7641 6426.6 23d Total \n5139 15m 23s 215 2h 20m 7s 7.3GB 24d The table begins with several smaller modules. Prims is the stan\u00addard \nprelude for F*; Util provides auxiliary functions such as zip and map, typed with their precise speci.cations. \nFiniteSet provides sets and sequences with predicates for set membership, partition, and permutation. \nWe use these to represent typechecking environ\u00adments. Terms de.nes the core F* syntax, and corresponds \nto the in\u00adductive types for F* abstract syntax shared with Coq, i.e., kind, typ, value, expr etc. Env \nde.nes various types also shared with Coq, such as icompartment and environment. FreeNames provides functions \nto collect free term-level and type-level variables. Binders de.nes bindings of term-level and type-level \nvariables. Subst provides both an axiomatization of type and value substitutions as an inductive predicate \nand functions that do the substitutions and build proofs of their predicates. Unify is used to compute \nthe set of equalities when typing pattern matching. Typing, the main module, contains the shared de.nitions \nof the reference type system, and implements functions that compute derivations for expression typing \n(etyping), value typing, subtyping, type conversion, and well-formedness checks on the environment. CoreTyping \nalso includes a small module Z3Interface, which, for the moment, simply admits Z3 queries, since these \nhave already been performed on the source AST. This last point is a signi.cant lim\u00aditation of our current \nimplementation, although not a fundamen\u00adtal one. We plan to integrate CoreTyping with prior work on Fine \nand DCIL, a predecessor of F*, that extracts and type checks SMT proofs from Z3 (Chen et al. 2010), thus \nremoving it from the TCB.  Overall, it takes the F* compiler over 15 minutes to internally produce a \nreference typing for the CoreTyping module. This in\u00adcludes the time taken by the source typechecker, \nthe calls to Z3 that it makes, followed by the translation into the core AST, and .nally the time taken \nfor CoreTyping to typecheck itself. Compressing and printing the 7 GB of certi.cates takes longer roughly \n2 hours and 20 minutes. We ran this experiment on a 6 core 3.2GHz Intel Xeon workstation, with 16 GB \nof RAM, running Windows 7. Checking the certi.cates in Coq takes much longer. To give an idea of the \nimpact of our optimizations, we turn them off one at a time and report the checking time for a sample \nmodule (Env) on the workstation. Re.ection greatly helps as we heavily rely on list properties; it also \nreduces certi.cate size by 65%. To our surprise, Coq is much faster on certi.cates split into smaller \npieces. Opacity reduces the memory footprint but has less impact on time. base time -re.ection -strings \n-splitting -opacity 13m 27s 35m 4s 37m 54s 25m 23s 14m 14s Overall, checking all certi.cates for CoreTyping \ntook 24 machine\u00addays, spread across 6 machines. Beside the workstation, we used .ve dual core 2.8 GHz \nIntel Xeon machines with 24GB of RAM running Windows 7. On all the machines we used a 64-bit build of \nCoq for Linux running under Oracle Virtual Box. Fortunately, with self-certi.cation complete, we never \nhave to export a certi.cate again. F* has been emancipated. 8. Conclusions In summary, we have presented \nself-certi.cation, a general method by which a certifying typechecker in a language of suitable expres\u00adsive \npower can be bootstrapped into a certi.ed typechecker. We have implemented this technique for F*, a dependently \ntyped pro\u00adgramming language for .NET, and relied on a formalization of the theory of F* in Coq to prove \nour methodology sound. With an ef.cient certi.ed typechecker in place, we aim to use it for a number \nof applications. Re.ecting the security-oriented focus of prior work on F*, we hope to write applications \nthat dynamically receive, load, core-typecheck, and run mobile code, possibly along the lines of code-carrying \nauthorization (Maffeis et al. 2008). Also, in work currently underway, we use F* to build certi.ed execution \nengines for various authorization logics. We conclude with some perspective: mechanized metatheories \nfor programming languages are gaining popularity, and rightly so. However, until now, these mechanization \nefforts have only served to increase the reliability of formal results, without much impact on the status \nof language implementations. Self-certi.cation provides a path to build a certi.ed core checker with \nan effort that compares favorably with mechanizing the metatheory in the .rst place. We hope other language \ndesigners will give it a try. References T. Acar, C. Fournet, and D. Shumow. Design and veri.cation of \na crypto\u00adagile distributed key manager. Technical report, MSR, 2010. A. W. Appel. Axiomatic bootstrapping: \na guide for compiler hackers. ACM TOPLAS, 16, November 1994. M. Armand, B. Gr\u00b4egoire, A. Spiwack, and \nL. Th\u00b4ery. Extending Coq with imperative features and its application to SAT veri.cation. In ITP, 2010. \nL. Augustsson. Cayenne: A language with dependent types. In ICFP, 1998. K. Avijit, A. Datta, and R. Harper. \nDistributed programming with dis\u00adtributed authorization. In TLDI, 2010. B. Aydemir, A. Chargu\u00b4eraud, \nB. C. Pierce, R. Pollack, and S. Weirich. Engineering formal metatheory. In POPL, 2008. B. Barras. Sets \nin coq, coq in sets. J. Formalized Reasoning, 2010. J. Bengtson, K. Bhargavan, C. Fournet, A. D. Gordon, \nand S. Maffeis. Re.nement types for secure implementations. In CSF, 2008. K. Bhargavan, R. Corin, P.-M. \nD\u00b4enielou, C. Fournet, and J. Leifer. Cryp\u00adtographic protocol synthesis and veri.cation for multiparty \nsessions. In CSF, 2009. K. Bhargavan, C. Fournet, and A. D. Gordon. Modular veri.cation of security protocol \ncode by typing. In POPL, 2010. C. Casinghino, H. D. Eades, G. Kimmell, V. Sj\u00a8oberg, T. Sheard, A. Stump, \nand S. Weirich. The preliminary design of the Trellys core language. In PLPV, 2011. J. Chen, R. Chugh, \nand N. Swamy. Type-preserving compilation of end-to\u00adend veri.cation of security enforcement. In PLDI, \n2010. A. Chlipala. A veri.ed compiler for an impure functional language. In POPL, 2010a. A. Chlipala. \nUr: statically-typed metaprogramming with type-level record computation. PLDI, 2010b. C. Colby, P. Lee, \nG. C. Necula, F. Blau, M. Plesko, and K. Cline. A certifying compiler for Java. In PLDI, 2000. J. Davis. \nA self-verifying theorem prover. PhD thesis, U.T. Austin, 2009. L. de Moura and N. Bj\u00f8rner. Z3: An ef.cient \nSMT solver. In TACAS, 2008. T. Dierks and E. Rescorla. The Transport Layer Security (TLS) Protocol Version \n1.2, 2008. T. Hart and M. Levin. The new compiler. AI Memo 39, MIT, 1962. L. Jia, J. Vaughan, K. Mazurak, \nJ. Zhao, L. Zarko, J. Schorr, and S. Zdancewic. Aura: A programming language for authorization and audit. \nIn ICFP, 2008. C. Keller and B. Werner. Importing HOL Light into Coq. In ITP, 2010. X. Leroy. A locally \nnameless solution to the POPLmark challenge. Re\u00adsearch report 6098, INRIA, Jan. 2007. X. Leroy. The CompCert \nveri.ed compiler, software and commented proof, Mar. 2011. P. Letouzey. Coq extraction, an overview. \nIn LTA 08, volume 5028 of Lecture Notes in Computer Science. Springer-Verlag, 2008. S. Maffeis, M. Abadi, \nC. Fournet, and A. D. Gordon. Code-carrying authorization. In ESORICS 08, 2008. C. McBride. Epigram: \nPractical programming with dependent types. In Advanced Functional Programming School, 2004. G. Morrisett, \nD. Walker, K. Crary, and N. Glew. From System F to typed assembly language. ACM Trans. Program. Lang. \nSyst., 21(3), 1999. M. Moskal. Rocket-fast proof checking for SMT solvers. In TACAS, 2008. M. O. Myreen \nand J. Davis. A veri.ed runtime for a veri.ed theorem prover. In Interactive Theorem Proving, Aug. 2011. \nA. Nanevski, G. Morrisett, A. Shinnar, P. Govereau, and L. Birkedal. Ynot: dependent types for imperative \nprograms. In ICFP, 2008. U. Norell. Towards a practical programming language based on dependent type \ntheory. PhD thesis, Chalmers Institute of Technology, 2007. R. Pollack. How to believe a machine-checked \nproof. In G. Sambin and J. Smith, editors, Twenty-Five Years of Constructive Type Theory. 1998. M. Sozeau. \nEquations: A dependent pattern-matching compiler. LNCS, 6172, 2010. A. Stump, M. Deters, A. Petcher, \nT. Schiller, and T. Simpson. Veri.ed programming in Guru. In PLPV, 2008. N. Swamy, B. J. Corcoran, and \nM. Hicks. Fable: A language for enforcing user-de.ned security policies. In S&#38;P, 2008. N. Swamy, \nJ. Chen, and R. Chugh. Enforcing stateful authorization and information .ow policies in Fine. In ESOP, \n2010. N. Swamy, J. Chen, C. Fournet, P.-Y. Strub, K. Bhargavan, and J. Yang. Secure distributed programming \nwith value-dependent types. In ICFP, Sept. 2011. See also the full paper at MSR-TR-2011-37. The Coq Development \nTeam. The Coq Proof Assistant Reference Manual -Version 8.3. INRIA, 2011. At URL http://coq.inria.fr/. \nH. Xi. Applied type system: Extended abstract. In Types for Proofs and Programs, pages 394 408, 2003. \n    \n\t\t\t", "proc_id": "2103656", "abstract": "<p>Well-established dependently-typed languages like Agda and Coq provide reliable ways to build and check formal proofs. Several other dependently-typed languages such as Aura, ATS, Cayenne, Epigram, F*, F7, Fine, Guru, PCML5, and Ur also explore reliable ways to develop and verify programs. All these languages shine in their own regard, but their implementations do not themselves enjoy the degree of safety provided by machine-checked verification. We propose a general technique called self-certification that allows a typechecker for a suitably expressive language to be certified for correctness. We have implemented this technique for F*, a dependently typed language on the .NET platform. Self-certification involves implementing a typechecker for F* in F*, while using all the conveniences F* provides for the compiler-writer (e.g., partiality, effects, implicit conversions, proof automation, libraries). This typechecker is given a specification (in~F*) strong enough to ensure that it computes valid typing derivations. We obtain a typing derivation for the core typechecker by running it on itself, and we export it to Coq as a type-derivation certificate. By typechecking this derivation (in Coq) and applying the F* metatheory (also mechanized in Coq), we conclude that our type checker is correct. Once certified in this manner, the F* typechecker is emancipated from Coq.</p> <p>Self-certification leads to an efficient certification scheme---we no longer depend on verifying certificates in Coq---as well as a more broadly applicable one. For instance, the self-certified F* checker is suitable for use in adversarial settings where Coq is not intended for use, such as run-time certification of mobile code.</p>", "authors": [{"name": "Pierre-Yves Strub", "author_profile_id": "81488661455", "affiliation": "MSR-INRIA, Orsay, France", "person_id": "P2991313", "email_address": "pierre-yves@strub.nu", "orcid_id": ""}, {"name": "Nikhil Swamy", "author_profile_id": "81342513197", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P2991314", "email_address": "nswamy@microsoft.com", "orcid_id": ""}, {"name": "Cedric Fournet", "author_profile_id": "81100547450", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P2991315", "email_address": "fournet@microsoft.com", "orcid_id": ""}, {"name": "Juan Chen", "author_profile_id": "81100119052", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P2991316", "email_address": "juanchen@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103723", "year": "2012", "article_id": "2103723", "conference": "POPL", "title": "Self-certification: bootstrapping certified typecheckers in F* with Coq", "url": "http://dl.acm.org/citation.cfm?id=2103723"}