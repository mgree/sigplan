{"article_publication_date": "01-25-2012", "fulltext": "\n Veri.cation of Parameterized Concurrent Programs By Modular Reasoning about Data and Control Azadeh \nFarzan Zachary Kincaid University of Toronto * azadeh,zkincaid@cs.toronto.edu Abstract In this paper, \nwe consider the problem of verifying thread-state properties of multithreaded programs in which the number \nof ac\u00adtive threads cannot be statically bounded. Our approach is based on decomposing the task into two \nmodules, where one reasons about data and the other reasons about control. The data module computes thread-state \ninvariants (e.g., linear constraints over global variables and local variables of one thread) using the \nthread interference in\u00adformation computed by the control module. The control module computes a representation \nof thread interference, as an incremen\u00adtally constructed data .ow graph, using the data invariants provided \nby the data module. These invariants are used to rule out patterns of thread interference that can not \noccur in a real program execu\u00adtion. The two modules are incorporated into a feedback loop, so that the \nabstractions of data and interference are iteratively coars\u00adened as the algorithm progresses (that is, \nthey become weaker) un\u00adtil a .xed point is reached. Our approach is sound and terminat\u00ading, and applicable \nto programs with in.nite state (e.g., unbounded integers) and unboundedly many threads. The veri.cation \nmethod presented in this paper has been implemented into a tool, called DUET. We demonstrate the effectiveness \nof our technique by veri\u00adfying properties of a selection of Linux device drivers using DUET, and also \ncompare DUET with previous work on veri.cation of pa\u00adrameterized Boolean program using the Boolean abstractions \nof these drivers. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program \nVeri.cation Assertion Checkers, Cor\u00adrectness Proofs; F.3.1 [Logics and Meanings of Programs]: Spec\u00adifying \nand Verifying and Reasoning about Programs Invariants, Assertions; D.3.1 [Programming Languages]: Formal \nDe.nitions and Theory Semantics; D.4.6 [Operating Systems]: Security and Protection Veri.cation General \nTerms Veri.cation, Algorithms, Reliability Keywords Concurrency, Abstract Interpretation, Compositional \nReasoning, Data Flow Graphs, Parameterized Programs, Thread Invariants * Both authors were partially \nsupported by an National Science and Engi\u00adneering Research Council (NSERC) Discovery Grant for this work. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n12, January 25 27, 2012, Philadelphia, PA, USA. Copyright c &#38;#169; 2012 ACM 978-1-4503-1083-3/12/01. \n. . $10.00 1. Introduction Concurrent programs are notoriously hard to verify. Veri.cation of concurrent \nsystems has been a very active area of research in the past few years. There has been signi.cant progress \nwith testing and bug .nding techniques, but due to a huge number of possible sched\u00adules (even with a \n.xed input), it is hard to provide useful coverage guarantees. Standard model checking techniques provide \ncoverage, but suffer from the state explosion problem. Static analysis tech\u00adniques [7, 14, 26, 27, 31, \n32] have been successful in checking simple generic properties such as race and deadlock freedom. There \nis a large class of concurrent programs that are designed to be executed by an arbitrary number of clients \n(for example, de\u00advice drivers, concurrent data structure libraries, and .le systems). This class of programs, \ncommonly called parameterized concur\u00adrent programs, are more dif.cult to verify than concurrent pro\u00adgrams \nwith a .xed number of threads. The veri.cation problem for parameterized systems has been studied extensively \n[2, 3, 6, 10, 12, 13, 16, 20, 21, 23, 29, 30]; however, the focus has mostly been on verifying protocols. \nThese protocols (for example, Lamport s Bak\u00adery protocol [24] and Peterson s mutual exclusion algorithm) \nare often small programs, but the reasoning behind their correctness is usually complicated (see Section \n7 for a more detailed discussion), specially when functional correctness is the goal (e.g. mutual ex\u00adclusion). \nIn contrast, we are interested in large programs such as device drivers and .le systems, where the reasoning \nbehind their correctness is more straightforward. In these programs, undesired inter-thread interference \nis usually prevented by simple synchro\u00adnization mechanisms, and the majority of the veri.cation effort \nis spent in reasoning about the sequential behaviour of each thread. Moreover, we are interested in proving \nprogram assertions, which is easier to handle than proving functional correctness of proto\u00adcols. Program \nassertions are boolean combinations of program ex\u00adpressions that relate shared variables to local variables \nof a speci.c thread at a location in that thread. They are expressive enough to in\u00adclude interesting \nproperties of concurrent programs such as the ab\u00adsence of null pointer dereferences or out of bounds \narray accesses. We believe that this combination of programs and properties is a good candidate for automated \nveri.cation in the parameterized set\u00adting, and is the target of the work presented in this paper. We \npropose a static analysis technique that separates the veri.\u00adcation task into a data module and a control \nmodule. This separa\u00adtion achieves both precision and scalability for proving assertions correct in concurrent \nprograms with unboundedly many threads. The data module, using an abstract interpreter, computes data \nin\u00advariants for each program location. These invariants are guaranteed to be consistent with the most \nrecent information about inter-thread interference, provided by the control module. The control module, \nusing a deduction system, determines the pattern of inter-thread in\u00adterference by using the most recent \ninformation from the data mod\u00adule about data invariants. The two modules are combined into a feedback \nloop to collaboratively compute a solution to the veri.\u00adcation problem. This strategy can be used to \ngenerate thread-state invariants for program locations, i.e. invariants that do not refer to the local \nvariables of more than one thread. These invariants can be used for proving the absence of program assertion \nfailures.  One of the enabling ideas of our modular approach is to use a data .ow graph as a program \nrepresentation for performing ab\u00adstract interpretation. In data .ow graphs, only the .ow of data is modelled; \ncontrol constructs (which are irrelevant to a data analy\u00adsis) are abstracted away. Data .ow graphs offer \na convenient way to represent the interference between threads: for example, if one thread writes to \na global variable at some location u which is sub\u00adsequently read by another thread at location v, then \nu and v are connected by a data .ow edge. Also, since each program location (regardless of the number \nof threads in the system) is represented by one vertex in the data .ow graph (i.e. there is no explicit \nrepre\u00adsentation for threads), it is possible to use them to analyze data in parameterized systems. Computing \ndata invariants over a data .ow graph is mostly as straightforward as abstract interpretation for se\u00adquential \nprograms; the idea is that the structure of a data .ow graph captures the interference among threads, \nand therefore, one only needs to focus on how data .ows through this structure. The .gure on the right \nillustrates the idea behind our approach. We start by assuming no interference among threads (as if threads \nare running sequen\u00adtially), and through ab\u00adstract interpretation com\u00adpute the .rst set of data invariants \n(per program location). At this stage, the data .ow graph only contains data .ow edges that correspond \nto the sequen\u00adtial executions of program threads. Then, the data invariants are passed to a deduction \nsystem, which uses them to compute a new set of data .ow edges. The deduction system uses the data invari\u00adants \nto reason about what patterns of inter-thread interference are feasible, and adds the corresponding data \n.ow edges, which capture these new interference patterns, to the data .ow graph. These new data .ow edges \nmay result in computing weaker data invariants in the next round. These weaker invariants may trigger \nthe addition of more data .ow edges (coarsening the data .ow graph). This loop continues until a .xed \npoint is reached. The analysis we use for computing data .ow edges is semi\u00adcompositional. Inter-thread \ndata .ow is a property that intuitively involves two threads: one that writes to a global variable, and \none that reads from it. Ideally, one would like to reason about the exis\u00adtence of data .ow edges by considering \nonly two threads at a time. However, it is not generally sound to reason using only two threads, since \na program path (e.g. from a write to a read) may involve many threads synchronizing with each other. \nWe overcome this problem by using data invariants (from the data invariant generation mod\u00adule) to soundly \napproximate the effects of other threads that may contribute to a data .ow path being realizable. An \ninvariant associ\u00adated with a program location corresponds to an overapproximation of the values of the \nprogram variables when at least one thread is at that location. Therefore, we may reason about data .ow \npaths that may require the participation of arbitrarily many threads while considering only two threads \nat a time. We call our approach semi\u00adcompositional (in contrast to fully compositional) because our rea\u00adsoning \nmethod over two threads is non-compositional (all pairs of locations are considered), while every other \nthread in the system is accounted for in a compositional manner. We implemented our approach in a tool \ncalled DUET and eval\u00aduated it on a set of 15 Linux device drivers. DUET can prove a total of 1312 (out \nof 1597) of array bounds and integer over/un\u00adder.ow assertions safe in 13 minutes. We also compared DUET \nagainst two recent tools that deal with parameterized concurrent Boolean programs, namely Geta.x [22], \nand the dynamic cutoff detection (DCD) algorithm of [19], which are both based on model checking. We \ncompared against DCD [19] and Geta.x [22] on the set of benchmarks provided by the authors, which are \nBoolean ab\u00adstractions (generated by the SatAbs [9] tool) of the aforementioned Linux device drivers. \nDUET has the clear advantage of being di\u00adrectly applicable to the drivers (as opposed to their Boolean \nab\u00adstractions), but we performed these experiments to show that it does outperform these tools even at \nthe level of Boolean programs. Our experiments shows that DUET substantially outperforms Geta.x, by proving \n2505 (compared to 1382 for Geta.x) Boolean programs correct. DUET also outperforms DCD by proving 58 \nprograms safe in contrast to only 19 programs that DCD can prove safe. 1.1 Motivating example In concurrent \nprograms, threads communicate using many different methods. They may communicate through synchronization \nprimi\u00adtives such as locks or wait/notify, which can be viewed as con\u00adtrol type primitives that only affect \nthe feasible control paths in a thread, and not the data. Threads may also communicate via read\u00ading from \nand writing to shared memory, which are data type prim\u00aditives. In the presence of both patterns of communication \namong threads, precise reasoning about the program often involves rea\u00adsoning about both data and control \nsimultaneously. But, doing so can be very expensive, specially for a programs with an unbounded number \nof threads. In this paper, we present a scalable approach to reason about data and control in separate \nbut collaborating mod\u00adules. In this section, we use an example that includes both modes of communication \namong threads (through both data variables and locks) to provide a high level understanding of our approach. \nFigure 1 illustrates a simpli.ed concurrent producer-consumer example. Let us assume that each statement \nis executed atomically, and that initially no thread holds any locks, and counter is 0. The producer \ncan produce items one-by-one or in batch mode, and keeps track of the number of produced items waiting \nto be con\u00adsumed using the global variable counter. Two producers cannot produce items simultaneously, \nbut a consumer can run in parallel with a producer in batch mode. The consumer, if there are items to \nprocess, consumes them one-by-one, by decrementing counter. The assertion at v6 states a correctness \nproperty for the consumer: the number of items waiting to be consumed must be nonnegative. At position \nu10 in the producer, the value of counter is always zero, so the assignment at u10 does not add any behaviour, \nbut it helps us demonstrate an interesting point. This program demonstrates the use of both synchronization \nprimitives (locks in this case), and conditional statements to rule out undesired interference from other \nthreads. For example, if the goal is to prove that the assertion at v6 holds, then one must prove that \nthe zero value assigned to counter at u10 cannot reach the decrement at v5, and consequently falsify \nthe assertion. In other words, we need to rule out a pattern of thread interference in order to prove \nthe desired invariant at v5 and v6. The interesting aspect of this example is that the reverse is also \ntrue: since the locations u10 and v5 are not protected by a common lock, in order to rule out the undesired \ninterference, one needs to rely on the fact that at v5, the value of counter is always strictly positive. \nIn this scenario, if one starts from a weak invariant at v5, one cannot rule out interference from u10, \nand (reversely), if one starts by assuming the interference from u10 may occur, one cannot prove the \ndata invariant needed to rule out this interference.  Here, we explain how our algorithm operates on \nthe program in Figure 1 at a high level. In Section 5 (in Example 5.1), we will revisit this example \nand explain it in more detail. First, we assume that Producer and Consumer are executed sequentially \nf with no interaction, and compute a sequential data .ow graph P1 . f Next, a set of data invariants \nis generated from P1 . This analysis determines that the Consumer threads cannot reach location v5 and \nthat in Producer threads, location u4 is unreachable. Using the previously computed data invariants, \nthe interference deduction f unit computes new data .ows, and adds the appropriate edges to P1 f to get \na data .ow graph P2 . For example, this analysis determines that the value of counter from u12 may reach \nthe beginning of the Producer and Consumer threads, and so adds the edges u12 . v4 and u12 . u3. The \ninterference deduction unit uses the fact that counter=0 is an invariant at u10 to infer that the value \nof counter from u10 cannot .ow to v5 without passing through v4, and therefore, does not add an edge \nfrom u10 to v5. Data invariants f are then generated for the data .ow graph P2 , which determines that \nu4 and v5 are now reachable, and that counter . [0, 8) at u1. The subsequent interference analysis computes \nnew data .ow edges, for example u4 . u1, which is possible as the result of u1 s new (weaker) invariant. \nThe invariants are still strong enough to prove that there is no data .ow from u10 to v5. These edges \nare ff added to P2 to get a new data .ow graph P3 . The data analysis runs f on P3 , but does not produce \nweaker invariants, and consequently, the subsequent interference analysis does not produce any new data \n.ow edges. The algorithm then terminates, having computed a set of invariants that soundly approximate \nthe dynamic behaviours of the program. These invariants are strong enough to prove that the assertion \nat v6 never fails. The rest of this paper is organized as follows. In Section 2, we de.ne our program \nmodel. We de.ne the data .ow graphs in Section 3, and discuss how data invariants can be computed by \nabstract interpretation of data .ow graphs; this constitutes the data portion of our analysis. We then \ndiscuss construction of the data .ow graphs in Section 4 where we explain how data invariants are used \nto infer new data .ow edges. The complete algorithm as an iterative framework is presented in Section \n5. Section 6 presents our experiments, Section 7 discusses related work, and Section 8 concludes. 2. \nNotation and the program model We de.ne a program to be a 4-tuple P = (H, GV, LV, L[\u00b7]), where H = (Loc, \nCF) is a .nite control .ow graph (CFG) whose vertices we call locations, GV is a .nite set of global \nvariables, LV is a .nite set of local variables, and L[\u00b7] assigns to each control location a transition \nrelation. For the rest of this section, we will formalize this program model and introduce notation to \nbe used in the rest of the paper. We will identify threads with natural numbers, where the be\u00adhaviour \nof an individual thread is given by the control .ow graph H = (Loc, CF) together with the semantic function \nL[\u00b7]. The ini\u00adtial vertex of H, which is assumed to have no control .ow prede\u00adcessors, is denoted by \ninitloc. The behaviour of the program P is de.ned to be that of the in.nite parallel composition of all \nthreads n . N. Since we are interested in thread invariants, we can restrict ourselves to .nite executions, \nin which only .nitely many threads can participate. Thus, for proving thread invariants, our program \nmodel is equivalent to the parameterized model in which P is taken to be the .nite parallel composition \nof all threads up to some k . N, where k is a parameter. We also note that we lose no generality in assuming \nthat every thread n . N executes the same code, since several code segments can be simply combined into \none. int Producer(int batch) void Consumer() { { u1: acquire(lock2) v1: lock(lock1) u2: acquire(lock1) \nwhile(*) { if (*) { v2: unlock(lock1) u3: assume(counter>0) v3: lock(lock1) u4: counter++ } u5: unlock(lock1) \nv4: assume(counter>0) u6: unlock(lock2) v5: counter-\u00ad u7: return 1 v6: assert(counter>=0) } else { v7: \nunlock(lock1) u8: assume(counter<=0) } u9: unlock(lock1) u10: counter = 0 while(*) { u11: assume(batch>0) \nu12: counter++ u13: batch-\u00ad } u14: assume(batch<=0) u15: unlock(lock2) u16: return batch } } Figure \n1. Producer-Consumer Example. We will assume that GV, LV, and N\u00d7 LV are pairwise disjoint (a pair (n, \nx). N\u00d7 LV is conceptually thread n s copy of the local variable x) and de.ne the set of variables Var \n= GV . LV. For simplicity, we will assume that all variables are of type integer. A global state is a \npair s = (senv,sloc) consisting of a global environment senv . GEnv =(GV . N \u00d7 LV) . Z and an assignment \nof a control location to each thread sloc : N . Loc. A thread state is a mapping e . TEnv = Var . Z from \nvariables to values. For a given thread n . N and global state s, the thread state of n in s, which we \ndenote by s[n], and which is de.ned by senv(x) if x . GV s[n](x)= senv((n, x)) otherwise The function \nL[\u00b7] : Loc . TEnv \u00d7 TEnv associates a tran\u00adsition relation on thread states to every location. We call \na pair a = (n, (v, v')) consisting of a thread n . N and a control .ow edge (v, v'). CF an action. If \nthe target v' of the con\u00adtrol .ow edge (v, v') is understood from the context or irrele\u00advant, we simply \nwrite (n, v). We use A[a] to denote the (global state) transition relation associated with the action \na, which is ob\u00adtained by lifting L[v] from thread states to global states as follows: (s, s').A[(n, (v, \nv'))] .. .(e, e').L[v] such that '' s[n]= e and s[n]= e '' sloc(n)= v and sloc(n)= v  .n' . N\\{n}. \nsloc(n')= s'loc(n')  .n' . N\\{n}, .x . LV . senv((n',x))= senv'((n',x)).  Given a sequence of actions \n. and a subset N . N, the projection of . onto N, denoted .|N , is the subsequence of . consisting of \nall actions whose thread identi.ers belong to N.A trace s is a .nite sequence of actions such that, when \nprojected onto a single thread, corresponds to a path in the CFG H beginning at the initial location \ninitloc. For a trace s, the post states of s (denoted s ) is the set of .nal states of that execution. \nA trace t is feasible if t is nonempty. For a trace s and a thread n . N, we use endloc(s, n) to denote \nthe end location of the CFG path s|{n}. Note that endloc has the property that .s . s , .n . N,  sloc(n)= \nendloc(s, n). A thread-state property is an assertion . with free variables in Var. We will denote the \nset of such formulae by F(Var) (and more generally, F(V ) will denote .rst-order formulae with free variables \nin V ). For a thread state e, we write e |= . to denote that e satis.es .. To provide some intuition \non our program model, we will de\u00adscribe how to represent locking. A lock is represented by a global variable \nlock . GV. Let acq be a location where lock is to be ac\u00adquired, and let rel be a location where it is \nto be released. Then we can de.ne L[acq] = {(e, e[lock . 1]) : e(lock)=0} L[rel] = {(e, e[lock . 0]) \n: e(lock)=1}Note that, given a feasible trace t, the fact that t is nonempty implies that there is no \npoint along t in which two threads hold the same lock. Our program model does not support conditional \nbranching, but this can be simulated with nondeterministic branching and assume actions, where L[assume(c)] \n= {(e, e) : e |= c}. Programs that depend on the initial state satisfying some property . can be simulated \nby de.ning L[initloc] as L[assume(.)]. Although our algorithm (and our implementation) handles dynamic \nthread creation, we omit it from this presentation for the sake of simplicity. 3. Data .ow graphs Data \n.ow graphs (DFGs) are a program representation that explic\u00aditly represents the .ow of data in a program, \nrather than the .ow of control as in a control .ow graph. Our analysis uses DFGs to com\u00adpute program \ninvariants by interpreting each edge of the DFG as a constraint and then computing an overapproximation \nof the least solution to this constraint system via abstract interpretation.1 A DFG for a program P is \na directed graph P f = (Loc, DF), where DF . Loc \u00d7 Var \u00d7 Loc is a set of directed edges labeled by program \nvariables, and where we assume that Loc contains an additional location uninit (with no incoming or outgoing \nedges in the control .ow graph of P ). We will use u .x v to denote the triple (u, x, v). Loc \u00d7 Var \u00d7 \nLoc. We de.ne the collecting semantics of a DFG P f = (Loc, DF)to be the least solution to the following \nset of equations: VAL(u, x)= {e(x): e . OUT(u)} IN(v)={e . TEnv : .u .x v . DF.e(x) . VAL(u, x)} x.Var \nTEnv if v = uninit OUT(v)= {e ' : .e . IN(v).(e, e ' ).L[v]} otherwise Consider the example in Figure \n2. This .gure depicts a program with two code segments, each of which may be executed by ar\u00adbitrarily \nmany threads. Variable c is global, and variable incr is local. Each vertex (except the special vertex \nuninit) has at least one incoming edge for each variable. Each of these incoming edges provides a value \nfor a particular variable. For example, the edge u2 .c v2 represents the constraint that any value for \nc after ex\u00adecuting u2 is a possible value for c before excuting v2 (that is, {e(c): e . IN(v2)}.{e(c): \ne . OUT(u2)}). The two edges from uninit to initloc indicate that any value is possible for incr and \nc at initloc, the location at which both threads begin execution. The vertex initloc sets the initial \ncondition of the program, acting as assume(c =0 . incr = 0). Thus, edges originating at initloc 1 For \na similar use of data-.ow graphs, see for example [17]. incr c Global: c Local: incr  incr u1: incr \n=1 u2: c = c + incr u1: incr=1 // v1: incr = -1  incr incr v2: assert(c > 0) c c Figure 2. A program \nand a data .ow graph representing it. indicate that a particular variable may get its value from the \nini\u00ad .incr tial state. The fact that v1 u2 does not belong to this graph indicates that the value of \nincr at v1 is not observable at u2. Intuitively, a DFG for a program P represents a trace s if it has \nenough edges to ensure that any thread state reached by s belongs to IN(v) for some v. The remainder \nof this section formalizes this notion. We will assume the existence of a function mod : Loc . P(Var) \nthat maps every control location to the set of variables modi.ed at that location. We require that mod \nsatis.es the follow\u00ading: for any x . Var, if there exists some (e, e ' ).L[v] with e(x) e ' (x), then \nx . mod(v). A notable feature of the mod = we use in practice is that a location of the form assume(.) \nis con\u00adsidered to be a modi.cation of every variable occuring in .. This allows us to take advantage \nof information at conditional branches that otherwise would not be possible in a data .ow graph. For \na trace s, variable x, and thread n, we de.ne latest(s, x, n) to be the location of the last action to \nwrite to the variable x along s (or thread n s copy of x, if x is local). More formally, if x is a global \nvariable, latest(s, x, n) is the unique location v such that s = p(m, v). (for some m . N) and where \nno action (of any thread) along . modi.es x if such a v exists, and uninit otherwise. Similarly, if x \nis a local variable, latest(s, x, n) is the unique location v such that s = p(n, v). and no action of \nthread n along . modi.es x if such a v exists, and uninit otherwise. DEFINITION 3.1 (Witness). Let u, \nv be locations, x be a variable, and s be a trace. We say that s is a witness for the data .ow edge u \n.x v if there exists some thread n . N such that latest(s, x, n)= u and endloc(s, n)= v. Conceptually, \ns is a witness for u .x v if, on s, u sets a value for x which is not changed until the end of the trace, \nwhere some thread is at v. We are now ready to de.ne a representation condition for traces and program. \nDEFINITION 3.2 (Representation). A DFG P f = (Loc, DF) rep\u00adresents a trace s iff for every u, v . Loc \nand x . Var, if some subtrace (not necessarily proper) s ' of s is a witness for u .x v, then u .x v \n. DF. P f represents a program P if it represents t for every feasible trace t of P . The relationship \nbetween the collecting semantics of a DFG and the traces it represents is given by the following: THEOREM \n3.3 (DFG Soundness). Let s be a trace and let P f be a DFG such that P f represents s. Then the collecting \nsemantics of P f overapproximates the set of thread states reached by s. Formally, for all s . s , for \nall n . N, we have that s[n] . IN(sloc(n)).  Proof sketch Let P f = (Loc, DF) be a DFG and let s be \na trace represented by P f. We proceed by induction on s. Base case: follows from the fact that for all \nx, uninit .x initloc . DF (since P f represents c) and the fact that for all x, VAL(uninit,x)= Z. Inductive \nstep: suppose s is a trace such that P f represents s, let n . N, and let v = endloc(s, n). We need to \nshow that s[n] . IN(sloc(n)). To prove this, it is suf.cient to show that .x . Var, .u . Loc such that \nu .x v . DF and s[n](x) . VAL(u, x). Let x be a variable, and take u to be latest(s, x, n). Then u .x \nv . DF because s witnesses this data .ow and P f represents s. If u = uninit, we are done since VAL(uninit,x)= \nZ. If u = uninit, it follows that s = p(m, u). for some thread m . N, trace p, and sequence of actions \n. such that x is not modi.ed along . (by the de.nition of latest(s, x, n)). Moreover, ' p '' we must \nhave that there is some s . such that .s with (s ' ,s '' ).A[(m, u)] and s '' [n](x)= s[n](x). By the \ninduction hypothesis, s ' [m] . IN(u), so s '' [m] . OUT(u) and s[n](x)= '' '' s [n](x)= s [m](x) . VAL(u, \nx). D We also note that, unlike typical de.nitions of data .ow graphs, we require that each location \nhas inputs for every variable, rather than just the variables read by that location. This is a technical \nconvenience that simpli.es the presentation of our algorithm. 3.1 Abstract interpretation of data .ow \ngraphs In this section, we discuss how invariants are computed over a data .ow graph. For clarity of \nthis presentation, we will assume a con\u00adcrete representation of an abstract domain as a subset of F(Var). \nThe semantics of program locations is given by an abstract tran\u00adsition relation L[\u00b7]f : Loc .F(Var) .F(Var) \nthat overap\u00adproximates the strongest postcondition (i.e., (e, e ' ).L[v] im\u00adplies e ' |= f(e)). An annotation \nfor a DFG P f is a map L[v] . : Loc .F(Var) that assigns each location v . Loc a thread\u00adstate formula \n.(v). We de.ne an inductiveness condition for anno\u00adtations that follows the structure of the collecting \nsemantics, and which holds when the annotation overapproximates the collecting semantics of the DFG. \nDEFINITION 3.4. An annotation . is inductive for a data .ow graph (Loc, DF) if: .(uninit)= true  For \nall v . Loc,  L[u]f(.(u)) x. .(v) x.Varu.xv.DF where L[u]f(.(u)) x denotes the formula obtained from \nthe formula L[u]f(.(u)) by existentially quantifying every variable except x. Standard techniques can \nbe used to compute inductive anno\u00adtations from a DFG (inductive annotations correspond to post\u00ad.xpoint \nsolutions in the terminology of abstract interpretation). For example, in our implementation, we use \na variation of the well\u00adknown worklist algorithm. The following is a consequence of The\u00adorem 3.3 and \nthe fact that inductive annotations overapproximate the collecting semantics: COROLLARY 3.5. Let s be \na trace, let P f be a data.ow graph that represents s (De.nition 3.2), and let . be an inductive annotation \nfor P f (De.nition 3.4). Then for all states s . s , and all threads n . N, s[n] |= .(sloc(n)) (i.e., \nthe thread state of thread n in the global state s is overapproximated by the annotation at the location \nof thread n). Note that in the collecting semantics, and therefore in inductive annotations, the values \nof different variables cannot be correlated. For example, if v is a location, x and y are variables, \nand e, e ' . IN(v) are reachable thread states such that e(x)= e(y)=0 '' '' and e (x)= e (y)=1, then \nthere exists an e . IN(v) in '' '' which e (x)=0=1= e (y). This suggests that DFGs are most appropriate \nfor analyses based on non-relational abstract domains, such as intervals, signs, or the even/odd domain, \nwhich are also incapable of representing relationships between variables. In Section 5.1, we will discuss \na variation of DFGs which are more appropriate for relational abstract domains. 4. Interference analysis \nWe now address the problem of how to compute a DFG that rep\u00adresents a program. We start by de.ning a \nsubset of traces, called .\u00adfeasible traces (where . is a given annotation), and then develop an interference \nanalysis that computes the set of data .ow edges that are witnessed by .-feasible traces. The de.nition \nof .-feasibility is such that if . is a weak enough annotation, then every feasible trace is .-feasible. \nWith such an annotation ., every edge which is witnessed by a feasible trace will also be witnessed by \nan .-feasible trace, and thus will be found by our interference analysis. Our interference analysis relies \non a .nite domain of data invari\u00adants, which is de.ned using .nite set of observable conditions.2 An \nobservable condition is a predicate c with free variables in GV. In the remainder of this section, we \nassume a .xed .nite set of ob\u00adservable conditions, which we denote by C. We de.ne the set of observable \nformulae Ff(GV) .F(GV) to be the set of formulae t . that can be expressed as a conjunction i .i, where \nfor each i, .i .C or \u00ac.i .C. An annotation . : Loc .F(Var) (along with the set of observ\u00adable conditions \nC) determines an abstract annotation .f : Loc . Ff(GV) that assigns to each location u . Loc an observable \nfor\u00admula . that is implied by .(u) and which is at least as strong as any other observable formula with \nthis property. Thus, going from concrete to abstract (and using . to denote is more precise than ), we \nhave IN(v) . .(v) . .f(v) for any location v. The set of observable conditions C determines an enabling \ncon\u00addition enabled : Loc .Ff(GV) where .e ' .(e, e ' ).A[v] . (e, v)|= enabled(v) and enabled(v) is at \nleast as strong as any other observable formula with this property. We are now ready to state our de.nition \nof .-feasibility: DEFINITION 4.1. Let s be a trace and . be an annotation. Then s is .-feasible if: \ns = c, or  s = s ' (n, v), where s ' is an .-feasible trace, and for all m . N, .f(endloc(s ' ,m)) . \nenabled(v) is satis.able.  Note that the condition for extending an .-feasible path s by an action (n, \nv) depends only on the annotations at the end locations of each thread, rather than on the states in \ns . EXAMPLE 4.2. Consider the trace s = (0,u1)(0,u2)(0,u3)of the program in Figure 1. This trace is not \nfeasible, because every state in ((0,u1)(0,u2)) has counter = 0, so (0,u3)is not enabled. However, assuming \nthat .(u2)= counter = 0 . lock1 =1, .(u1)= counter = 0, and C = {counter > 0, lock1 =0, lock2 =0} (which \nimplies .f(u1)= true, .f(u1)= \u00ac(lock1 = 0), and enabled(u3)= counter > 0), this trace is .-feasible. \nTo illustrate how .-feasibility depends on ., consider the infeasible trace (0,u1)(0,u2)(1,v1). This \ntrace is 2 This .niteness condition is not strictly necessary, but makes for a more ef.cient analysis. \n COREACH-SYM COREACH-STEP INIT-COREACH coreachable(u, v) coreachable(u0,v) enabled(u0,.f(v)) (u0,u1). \nCF coreachable(initloc, initloc) coreachable(v, u) coreachable(u1,v) MAYREACH-BASE coreachable(u0,v) \nx . mod(u0) enabled(u0,.f(v)) (u0,u1). CF mayReach(u, x, u0,v) MAYREACH-STEPL mayReach(u0, x, u1,v) \nx/. mod(u1) enabled(u1,.f(v)) (u1,u2). CF mayReach(u0, x, u2,v) MAYREACH-STEPR MAYREACH mayReach(u0, \nx, u1,v0) x/. mod(v0) enabled(v0,.f(u1)) (v0,v1). CF mayReach0(u0, x, u1,v) mayReach(u0, x, u1,v1) u0 \nx v Figure 3. Interference analysis. .-feasible if .(u3)= counter = 0 . lock1 =1, and .-infeasible if \n.(u3)= .(u8)= counter = 0 . lock1 =1 . lock2 =1. By combining the de.nition of .-feasibility with the \nde.nition of a witness of a data .ow edge, we arrive at the following: DEFINITION 4.3. Let s be a trace, \n. be an annotation, u and v be locations, and x be a variable. Then s is an .-feasible witness of the \ndata .ow u .x v if s is .-feasible and witnesses the data .ow u .x v (that is, s simultaneously satis.es \nde.nitions 3.1 and 4.1). A key property of our notion of .-feasibility is that it is preserved under \nprojections; that is, for any ., if s is an .-feasible trace, then for any sets of threads N . N, s|N \nis also .-feasible. The following lemma states a projection result that forms the basis of our semi\u00adcompositional \nalgorithm for interference analysis. It implies that, in order to compute the set of data .ow edges that \nare witnessed by .-feasible traces, it is suf.cient to consider only traces that involve two threads. \nLEMMA 4.4 (Projection). Let . be an annotation, u, v be loca\u00adtions, and x be a variable. Let s be an \n.-feasible witness for the data .ow u .x v. Then there exists m, n . N such that s|{m,n}is an .-feasible \nwitness for u .x v. Proof sketch We will .rst prove that for any N . N and any .\u00adfeasible trace s, s|N \nis an .-feasible trace, by induction on s. The base case is obvious. For the inductive step, let s(n, \nv) be an .-feasible trace, and assume that s|N is .-feasible. If n ./N, then s(n, v)|N = s|N , and the \nresult is immediate from the induction hypothesis. If n . N, then s(n, v)|N = s|N (n, v). In this case, \nwe need to show that for all m . N, .f(endloc(s|N ,m)) . enabled(v) is satis.able. Let m . Nand distinguish \ntwo cases: m . N: then endloc(s|N ,m)= endloc(s, m), and the fact that .f(endloc(s|N ,m)) . enabled(v) \nis satis.able follows from the fact that s(n, v) is .-feasible.  m/. N: then endloc(s|N ,n)= initloc. \nSince s is .nite, only .nitely many threads execute actions in s, so there exists a thread i . N that \ndoes not execute actions in s. Since s(n, v)is .-feasible, .f(endloc(s, i)) . enabled(v) is satis.able. \nSince endloc(s, i)= initloc = endloc(s|N ,m), we are done.  Now, we must prove that the property of \nbeing a witness is preserved by projections. Let u, v be locations and x be a variable, and let s by \na witness of the data .ow u .x v. We assume that x is a global variable the case of local variables \nis similar. It follows from De.nition 3.1 that there exists some m, n . N, a trace p, and a sequence \nof actions . such that s = p(n, u). such that x . mod(u), x is not modi.ed by any action along ., and \nv = endloc(s, m). It is easy to check that s|{m,n} witnesses u .x v. D 4.1 Inferring data .ow edges \nOur algorithm for inferring data .ow edges is stated declaratively in Figure 3 as a set of deduction \nrules for .-feasible witnesses. For u, v . Loc and x . Var, we write u .x v iff an .\u00adfeasible witness \nfor the data .ow u .x v exists. These proof rules are sound and complete for determining whether a witness \nfor an inter-thread data .ow edge exists intra-thread data .ows can be computed independently using \na standard sequential reaching de.nitions analysis. The rules use an input relation enabled(u, .) which \nholds iff . . enabled(u) is satis.able. Additionally, two auxiliary relations are used: coreachable(u, \nv) holds iff there is some .-feasible trace s such that u = endloc(s, 0) and v = endloc(s, 1).  mayReach(u, \nx, v, w) holds iff there is some .-feasible trace s such that u = latest(s, x, 0), v = endloc(s, 0) and \nu = endloc(s, 1).  Since the set of locations and the set of variables are .nite, coreachable, mayReach, \nand . all must be .nite. As a result, we may compute all members of . in .nite time by iteratively applying \nthese rules until no new members of any relation are de\u00adduced (i.e., until a .xed point is reached). \nMoreover, the fact that these relations are all .nite allows us to leverage ef.cient propo\u00adsitional techniques, \nfor example representing relations by binary decision diagrams. LEMMA 4.5 (Interference analysis soundness \n&#38; completeness). Let u, v . Loc and x . Var. There exists an .-feasible trace that witnesses data \n.ow the u .x v iff there exists a single-threaded witness, or if u x. v belongs to the least .xpoint \nsolution of the system of interference rules in Figure 3. Note that this lemma implies that, although \nwe lose information in our interference analysis by going from feasible traces to .\u00adfeasible traces, \nwe do not lose information by going from n-thread .-feasible traces to 2-thread .-feasible traces. The \nrules in Figure 3 are a simpli.ed version of the ones we im\u00adplementin DUET. DUET handlessomeadditionallanguagefeatures \n(thread creation and atomic blocks) and has several optimizations   .1 .2 .3 initloc true true true \nu3 counter=0 counter=0 counter=0 u4 counter=0 counter=0 counter=0 u8 counter=0 counter=0 counter=0 u10 \ncounter=0 counter=0 counter=0 u11 counter=0 counter=0 counter=0 v4 counter=0 counter=0 counter=0 v5 false \ncounter>0 counter>0 v6 false counter=0 counter=0 Figure 4. COARSEN computation on the program in Figure \n1. to make it more ef.cient. However, all the essential ideas of the analysis are present in the rules \nof Figure 3. 5. Iterative coarsening In Section 3, we gave a method for computing an annotation for a \ndata .ow graph; in Section 4, we gave a method for comput\u00ading data .ow edges given an annotation. By \nincorporating both components into a feedback loop, we obtain our main algorithm, COARSEN (Algorithm \n1). Given a parameterized multi-threaded program, COARSEN computes a DFG that represents that program \nas well as an annotation that is inductive for that DFG. Given a program P , COARSEN begins by computing \na data .ow graph P1 f with only intra-thread (sequential) data .ow edges. It then computes an inductive \nannotation .1 for P1 f as discussed in Section 3. This annotation .1 is used as input to the interference \nanalysis of Section 4, which computes the set of .1-feasible data .ow edges and adds them to P1 f to \nobtain a DFG P2 f. After adding these edges, a new (possibly weaker) annotation is computed that is inductive \nfor P2 f. This process continues until a .xed point is reached; that is, until we reach some k such that \nP f = P f . At kk+1this point, Pkf represents the program P and .k is inductive for Pkf , and therefore \n.k overapproximates the reachable thread states of P by Theorem 3.3. This algorithm makes use of several \nauxiliary functions, which are de.ned below. SequentialDFG(P ) computes a sequential data .ow graph \nfor P . This computation is a standard sequential reaching de.ni\u00adtions analysis. This graph contains \nall intra-thread data .ow edges, including all those for local variables, and all those orig\u00adinating \nfrom uninit.  ExtractCond(P ) computes a set of observable conditions for P by mining the program for \nlocks and predicates q such that q only uses global variables and assume(q) occurs in P .  Invariants((Loc, \nDF)) computes an annotation that is inductive for the DFG (Loc, DF) using a modi.cation of the standard \nworklist algorithm, as discussed in Section 3.  AbstractAnnotation(., C) computes an observable formula \n.f(v) for every location v that is implied by .(v) and is at least as strong as any other observable \nformula with that property.  FeasibleData.ows(P, .f) computes the relation . through a bottom-up evaluation \nof the logic program given in Figure 3. EXAMPLE 5.1. Consider the program in Figure 1. Figure 4 depicts \nhow the DFG and annotation computed by COARSEN evolve on this program. For simplicity, we show only information \nthat is rele\u00advant to the counter variable. In particular, the DFG contains only vertices that modify \nor block on counter and all the counter\u00adlabeled edges between them, and the annotation is restricted \nto re\u00adfer only to the variable counter. A special vertex X appears in the DFG to improve readability \nby factoring edges; it does not represent a real DFG vertex. An edge u . X from some arbitrary vertex \nu to X represents four edges: u . initloc, u . u8, u . u3 and u . v4. The vertex initloc is the initial \nlocation of the program where every thread begins its execution, and which has u1 and v1 as its control \n.ow successors. Its action is to assume the condition of the initial state, as in: assume(counter =0 \n. lock1 =0 . lock2 =0 . batch = 0) The solid edges in Figure 4 are added in the .rst round, the dashed \nedges are added in the second round, and the dotted edges are added in the third round. The columns labeled \n.1, .2, and .3 represent the annotation of the corresponding location in the .rst, second, and third \nrounds. Note that there is no edge from u10 to v5. This is very important for proving the assertion at \nv6. Since the invariant at u10 always remains counter=0, the interference analysis can infer that there \nis no feasible path of the program witnessing this edge. Any feasible path of the program that visits \nu10 has to go through a counter increment (u11) or an assume statement (v4) before it can reach v5, and \nsince each of those paths contains a location modifying counter in the segment from u10 to v5, they cannot \nbe witnesses for a data .ow edge from u10 to v5. Finally, the correctness condition of Algorithm 1 is \nstated in the following theorem: THEOREM 5.2 (Soundness). For any program P , COARSEN com\u00adputes an annotation \n. and a DFG P f such that P f represents P , and for every reachable state s of P and thread n, s[n] \n|= .(sloc(n)). Proof sketch Let . and P f be the be the annotation and data .ow graph computed by COARSEN. \nThe termination condition  Algorithm 1 COARSEN Input: A program P = ((Loc, CF), GV, LV, L[\u00b7]) Output: \nA sound annotation for P (Loc, DF). SequentialDFG(P ) C. ExtractCond(P ) DF' .\u00d8 repeat DF . DF . DF' \n. . Invariants((Loc, DF)) .f . AbstractAnnotation(., C) DF' . FeasibleData.ows(P, .f) until DF' . DF \nreturn . of COARSEN implies that . is inductive for P f and every .-feasible trace of P is represented \nin P f. We .rst prove that every feasible trace t of P is .-feasible by induction on t . The base case \nis trivial, since c is .-feasible for any .. For the induction step, assume that t (n, v) is a feasible \ntrace and t is .\u00adfeasible; we must prove that t(n, v) is .-feasible. Since t (n, v) is feasible, there \nmust exist some s . t and s ' . State such that (s, s ' ).A[(n, v)]. By the de.nition of enabled(v), \nwe have that s |= enabled(v). We note that for a formula . with free variables in GV, the meaning of \ns |= . is unambigious since senv assigns a single value to each global variable x . GV; moreover, we \nnote that if . s free variables are in GV then s[n] |= . iff s |= ., since s[n] and s agree on the values \nof all global variables. Let m . Nbe an arbitrary thread. Since t is .-feasible, t is rep\u00adresented by \nthe DFG (Loc, DF). Since . is inductive for (Loc, DF)and s . t , we have that s[m] |= .(sloc(m)) by Corollary \n3.5. It follows from the de.nition of .f that s |= .f(sloc(m)), and thus s |= .f(sloc(m)) . enabled(v). \nSince this holds for all m, t(n, v)is .-feasible (noting that sloc(m)= endloc(t,m)). Since every feasible \ntrace is an .-feasible trace, and every .\u00adfeasible trace is represented by P f, every feasible trace \nis repre\u00adsented by P f, and so P is represented by P f. Finally, let s be a reachable thread state and \nlet n . N be a thread. Then there exists some feasible trace t such that s . t . Since t is .-feasible \n(by the above argument), it follows that t is represented by P f. Finally, since t is represented by \nP f and . is inductive for P f, we have that s[n] |= .(sloc(n)) by Corollary 3.5. D 5.1 Relational abstract \ndomains We have discussed only the use of non-relational (also known as independent attribute) abstract \ndomains up to this point. Although such domains are typically very ef.cient, the fact that they can\u00adnot \nencode relationships between variables limits their expressive power. In our framework, it is possible \nto use relational domains, such as octagons and polyhedra, by modifying the data .ow graph. Instead having \ndata .ow graph edges labeled with a single variable, we allow sets of variables as labels, indicating \nthat the value of ev\u00adery variable in this set .ows from the source to the target. Since a value for each \nx . X .ows along such an edge u .X v, relation\u00adships between variables in X can be maintained. A particularly \nsimple instance of this idea is to create a partition P of the set of variables Var into semantically \nrelated sets. Intu\u00aditively, we can think of each cell X . Pas a record-typed variable, with one .eld \nfor each x . X. For a given partition P of Var, the collecting semantics for a relational DFG (Loc, DF) \nwith P-labeled edges is given by the following: VAL(u, X)= {e ' : .e . OUT(u)..x . X.e(x)= e ' (x)} IN(v)= \n{e . TEnv : .u .X v . DF.e . VAL(u, X)} X.P TEnv if v = uninit OUT(v)= {e ' : .e . IN(v).(e, e ' ).L[v]} \notherwise Using the collecting semantics as a guideline, it is straightfor\u00adward to de.ne inductive invariants \nfor relational DFGs. The inter\u00adference analysis of Section 4 must then be adapted to infer rela\u00adtional \ndata .ow edges. Towards this end, we rede.ne mod to act on cells rather than variables as follows: modP(v)= \n{X . P : mod(v) n X = \u00d8} By re-instantiating the interference analysis in Figure 3 with modP in place \nof mod, we obtain our algorithm for calculating data .ows in a relational DFG. Since nonrelational analyses \nand relational analyses operate on different data .ow graphs, it is not generally true (as in the case \nof sequential analyses) that a relational analysis is necessarily more accurate than a non-relational \nanalysis. There is a positive side and a negative side to grouping variables when it comes to concurrent \nprogram analysis. On the positive side, grouping variables together makes it possible to infer relationships \nbetween variables, which results in a more precise analysis. On the negative side, grouping variables \ntogether may create additional interference edges (result\u00ading in a less precise analysis), as modP(v) \nis generally larger than mod(v) (for v . Loc). For example, if batch and counter are grouped together \nin the relational DFG construction for Figure 1, then the interference analysis will infer the {batch, \ncounter}\u00adlabeled edges v5 . u13 and u13 . v5. With these edges present, the invariant that counter = \n0 at v5 can no longer be proved, be\u00adcause the inductiveness condition for annotations implies that there \nis no lower bound for counter at v5. In our experiments in Sec\u00adtion 6, there are cases when interval \nanalysis succeeds in proving a property correct when octagon analysis fails, and vice versa. In Section \n6.1, we brie.y discuss the simple algorithm that we use to partition variables into semantically related \nsets. While sim\u00adple, this algorithm performs fairly well on our benchmarks. How\u00adever, we believe that \nthere is considerable room for improvement with a better variable grouping algorithm. 6. Experiments \nThe approach presented in this paper is implemented into a tool called DUET.3 We used a benchmark suite \nof 15 Linux device drivers to evaluate DUET. Additionally, we ran DUET on the set of Boolean programs \ngenerated by SatAbs [9] from these Linux drivers to compare DUET with two recent techniques on veri.ca\u00adtion \nof parameterized Boolean programs. 6.1 Implementation DUET is written in OCaml, and makes use of the \nCIL front-end for the C language [28] and the goto program front-end distributed with CBMC [8]. Our abstract \ninterpreter uses the APRON library [5] for its numerical abstract domains. We use the BDD-based Datalog \nimplementation bddbddb[33] to perform the interference analysis described in Section 4. Currently, DUET \naccepts three types of inputs: (1) C programs using pthreads library for thread operations, (2) Boolean \nprograms in the input language of Boom [19] as an input, or (3) goto programs, as produced by the goto-cc \nC/C++ frontend (part of the CPROVER project [1]. 3 For more information on this tool, see http://duet.cs.toronto.edu \n Device Drivers #assertions DUET: Interval Analysis DUET: Octagon Analysis safe time safe time i8xx \ntco 90 75 1m51s 71 1m25s ib700wdt 75 64 30s 64 20s machzwd 87 73 39s 67 14m44s mixcomwd 91 72 22s 74 \n25 pcwd 240 147 2m43s 145 23m48s pcwd pci 204 187 2m18s 188 2m59s sbc60xxwdt 91 77 28s 69 11m27s sc520 \nwdt 85 71 28s 65 13m20s sc1200wdt 77 66 34s 66 33s smsc37b787 wdt 93 80 47s 80 47s w83877f wdt 92 78 \n29s 72 13m24s w83977f wdt 101 90 34s 82 34s wdt 99 88 25s 86 25s wdt977 88 77 27s 75 28s wdt pci 84 67 \n33s 66 5m33s total 1597 1312 13m9s 1277 90m21s Table 1. DUET s Performance on Parameterized Integer \nPrograms, run on an 3.16GHz Intel(R) Core 2(TM) machine with 4GB of RAM. Our implementation currently \ninlines all function calls and then performs an intraprocedural analysis. Alias Analysis. We use a type-based \nalias analysis to handle pointers. For each variable whose address is not taken, we assign a memory location \nwhich receives strong updates. For every type in the program, we assign a memory location which receives \nweak up\u00addates, and each access path of that type (other than variables whose address is not taken) is \nconsidered to be a reference to that mem\u00adory location. The interference analysis implemented in DUET \noper\u00adates on these memory locations rather than variables. This scheme is sound under the assumption \nthat pointer-typed expressions are never cast. For the benchmark suite used in Section 6.2, aliasing \nis not particularly important for proving array bounds and integer over.ow properties. Therefore, we \nexpect the consequences of our unsound and imprecise alias analysis to be negligible. We use Algorithm \n2 to partition variables into semantically related sets for our implementation of octagon analysis. While \nsimple, it seems to be effective in practice when performing an octagon analysis on Boolean abstractions \nof Linux device drivers. Algorithm 2 Variable partitioning algorithm Input: A set of program locations \nLoc, a set of local variables LV and global variables GV Output: A partition of Var //Pis a disjoint \nset data structure P . {{x} : x . Var}for v . Loc do if v is an assignment statement then vs . mod(v) \n. ref(v) if |vs| =2 . (vs . LV . vs . GV) then Merge the partitions of each x . vs end if else if v \n= assume(p) then if vars(v) . LV . vars(v) . GV then Merge the partitions of each x . vars(v) end if \nend if end for return P  6.2 Evaluation Below, we provide the results of experimenting with DUET on \na collection of Linux device drivers and on Boolean abstractions of those drivers. Since a driver may \nhave arbitrary many clients, it is important to verify these drivers in a parameterized setting. Parameterized \nInteger Programs. Table 1 presents the result of running DUET on a collection of 15 Linux device drivers. \nThese drivers are all written in C, and include in.nite data (such as integer types). We know of no other \ntool that can verify numerical properties of such large programs with arbitrarily many threads,4 and \ntherefore we present the result of running DUET on these integer benchmarks without comparison with other \ntools. DDVerify and goto-cc are used to (automatically) process each driver into a fully-inlined goto \nprogram annotated with assertions checking array bounds and integer over.ows/under.ows. With an inverval \nanalysis, DUET manages to prove most of the assertions correct (1312 out of a total 1597), and does so \nin 13 minutes. DUET s performance using an octagon analysis is slightly worse, proving 1277 assertions \ncorrect in 90 minutes. Most false positives for DUET appear to be caused by one of two reasons: imprecision \nin the abstract domain, and imprecision in how DUET handles the treatment of spinlocks in goto programs. \nIn particular, many drivers use traverse zero-terminated arrays as in the snippet below: for (i=0; array[i]; \ni++) { ... } Since our abstraction of arrays has no special representation for zero-terminated arrays, \nDUET .ags this as an array bound error (since no upper bound for i can be inferred). Our handling of \nspin\u00adlocks is imprecise because goto programs model them as pointers to integers (which take value either \n0 or 1, depending on whether the lock is acquired), access to which is protected by atomic blocks. Due \nto our imprecise alias analysis, lock acquisitions can only weakly update this integer .eld, which means \nthat two threads can 4 It is possible to run Boom on the integer benchmarks by .rst extracting Boolean \nprograms with SatAbs. However, SatAbs is designed for sequential programs rather than concurrent ones, \nand the Boolean programs extracted by the version of SatAbs that was available at the time we ran our \nexperi\u00adments produced poor results: the combined SatAbs+Boom procedure took 2 days and did not prove \nany assertions correct.  Device Drivers #programs safe unsafe LI unknown timeout DUET: Octagon Analysis \nsafe unsafe timeout DUET: Interval Analysis safe unsafe timeout i8xx tco 338 214 14 0 110 259 79 0 198 \n140 0 ib700wdt 181 109 13 0 59 124 56 1 91 90 0 machzwd 255 56 24 94 81 182 70 3 148 105 2 mixcomwd 178 \n103 24 0 51 117 59 2 81 95 2 pcwd 100 81 1 0 18 74 16 10 44 50 6 sbc60xxwdt 174 92 23 0 59 113 60 1 79 \n94 1 sc1200wdt 247 138 13 0 96 178 67 2 138 107 2 sc520 wdt 186 15 23 97 51 123 61 2 89 95 2 smsc37b787 \nwdt 340 154 13 0 173 272 65 3 151 187 2 w83877f wdt 230 15 23 97 95 150 77 3 98 128 4 w83977f wdt 389 \n147 13 0 229 322 65 2 144 243 2 wdt 230 109 17 0 104 161 59 10 108 114 8 wdt977 351 139 13 0 199 282 \n67 2 132 218 1 wdt pci 217 10 34 4 169 146 69 2 146 69 2 total 3416 1382 248 292 1494 2503 870 43 1647 \n1735 34 Table 2. Comparison with linear interfaces [22] for Parameterized Boolean Programs. Average \ntime per benchmark was 16.9s for LI and 3.4s for DUET. Benchmarks were run on an 3.16GHz Intel(R) Core \n2(TM) machine with 4GB of RAM. acquire the same lock. Neither of these sources of imprecision is due \nto a fundamental limitation of the analysis technique proposed in this paper (or related to concurrency), \nand we expect that our false positive rate to drop considerably with the core algorithm un\u00adchanged. Parameterized \nBoolean Programs. Although Boolean programs are not the target of this work, we experimented with them \nfor two reasons: (1) two recent approaches [19, 22] for veri.cation of pa\u00adrameterized concurrent programs \nonly accept Boolean programs as their input, and (2) there is no aliasing present in Boolean programs, \nwhich limits the scope of implementation-related imprecisions for a better evaluation of the core method. \nDUET does not require a predicate abstraction phase to handle Linux device drivers, but to present a \nmore fair comparison with the existing tools [19, 22], we also ran DUET on the Boolean abstractions. \nWe compare DUET against two recent algorithms that handle parameterized Boolean programs: dynamic cutoff \ndetection (DCD) from [19], as implemented in Boom, and linear interfaces (LI) from [22], as implemented \nin Geta.x. We compared these tools against our own on the benchmarks used in the papers (as provided \nby the authors). The programs were generated by SatAbs from a set of Linux device drivers. The input \nformats of Boom and Geta.x are slightly different, so we report the results separately. The ib700wdt \nand mixcomwd benchmarks were generated from the same device drivers, but refer to a different set of \nBoolean programs in Tables 2 and 3. Each LI benchmark consists of a server and a client thread template, \nwhere the client template is replicated arbitrarily many times. The client thread template is the device \ndriver code, and the server thread template simulates the OS interacting with the drivers. In the DCD \nbenchmarks, there is a single thread template that is replicated. All benchmarks were run with a timeout \nof 5 minutes. Table 2 presents the results of comparison with the LI algorithm on the set of Boolean \nprograms used in [22]. In the LI algorithm, the system is tested under 4 rounds of scheduling to look \nfor a counter example, and if one is not found then an adequacy checker is exe\u00adcuted that may succeed \nin proving the program safe for arbitrarily many threads and rounds of scheduling. The safe columns refer \nto the number of instances that were proved safe (for each analysis). The unsafe column for LI refers \nto the instances for which LI found a counterexample (a con.rmed bug), while in DUET, it refers to the \ninstances where assertions could not be proved safe.5 The timeout column for LI refers to instances where \nLI cannot .nish checking the program under 4 rounds, or cannot .nd a counterexample un\u00adder 4 rounds and \nthe adequacy checker times out while trying to prove the program safe. The timeout column for DUET refers \nto all the instances that DUET cannot prove safe within the timeout limit. The unknown column for LI \nrefers to the instances that no coun\u00adterexample is found, and the adequacy checker .nishes but fails \nto prove the program safe for arbitrary number of threads. In almost all benchmarks (other than pcwd), \nDUET can prove many more instances safe (and for pcwd, it is close: 74 vs. 81). DUET can prove many of \nthe unknown and timeout instances of LI safe. The small table below presents a different view of the \nsame results (not distinguishing among individual drivers). LI safe unsafe timeout unknown OCT safe 1320 \n0 267 916 unsafe 60 247 25 538 timeout 2 1 0 40 The above table compares the results of the octagon \nanalysis in DUET with LI. DUET can prove an additional 1183 (267+916) programs correct compared to LI. \nThere are 60 instances that DUET reports a con.rmed false positive (a program that is known to be safe, \nbut DUET fails to prove safe). There are a total of 2503 (1320+267+916) programs that are proved safe \nby DUET, and 247 programs that are correctly declared unsafe, and therefore DUET generates a total of \n2750 correct answers. This puts the percentage of incorrect answers out of the total number of con.rmed \ncorrect and incorrect answers for DUET at 2.1% (60/(2750+60)). Table 3 presents the results of comparison \nwith the DCD algo\u00adrithm on the set of Boolean programs used in [19]. In the DCD algorithm, there is only \none thread template which is increasingly replicated until a counterexample or a cutoff point is found \n(a cut\u00adoff point is a number of threads n such every thread state that is reachable with m = n threads \nis also reachable with n threads). For the subset of these benchmarks where DCD does not time out, the \ncutoff is at most 3 threads. DUET s interval and octagon analy\u00adsis substantially outperforms DCD in proving \nprograms correct. In 5 Note that since our approach is not complete, failure to prove an assertion does \nnot imply that the assertion is necessarily false.  Device Drivers #programs DCD DUET: Octagon Analysis \nDUET: Interval Analysis safe unsafe timeout safe unsafe timeout safe unsafe timeout ib700wdt 132 10 102 \n20 16 113 3 28 101 3 mixcomwd 138 9 108 21 16 118 4 27 107 4 Table 3. Comparison with dynamic cutoff \ndetection (DCD) [19] for parameterized Boolean programs. Average time per benchmark was 24.9s for DCD \nand 8.2s for DUET. Benchmarks were run on an 800MHz AMD Opteron(tm) machine with 32 GB of RAM. particular, \nDUET can prove a total 58 programs correct (with inter\u00adval and octagon analysis combined) in contrast \nto 19 for DCD, and there are no programs which DCD proves safe and which DUET cannot. 7. Related Work \nVeri.cation and analysis of concurrent programs has been vastly studied. Here, we focus on veri.cation \nof parameterized concurrent programs and systems which is more relevant to our work. Extensive research \nhas been done in the area veri.cation of parameterized protocols. These include (but are not limited \nto) split invariants [10], regular model checking [6, 20], parameterized model checking [12], network \ninvariants [16, 21], and exploiting symmetry [13] in the Murf tool [16]. Counter abstraction [3, 30] \nhas been a useful technique in verifying replicated components, al\u00adthough bounded. As discussed in Section \n1, we believe that proving functional correctness of a protocol is much more involved com\u00adpared to proving \nprogram assertions correct in program such as a device driver (the focus of our work). For example, the \ncorrectness of Lamport s Bakery protocol [24] requires complex global invari\u00adant with quanti.ers. In \ncontrast, we expect driver code to use signif\u00adicantly simpler invariants to enforce synchronization, \nsuch as a .ag being set or a lock being held. Moreover, global program properties (such as mutual exclusion) \nare part of the correctness of a protocol (such as Bakery), whereas we focus on program assertions, which \nare not expressive enough to relate the states of different threads to each other. To the best of our \nknowledge, the body of work on veri.ca\u00adtion of parameterized protocols (some of it mentioned above) does \nnot contain a single tool that can, for example, effectively verify numerical properties of Linux device \ndrivers with unboundedly many threads. Recently, two new approaches [19, 22] have been proposed for veri.cation \nof parameterized Boolean programs that target Boolean abstractions of Linux device drivers, and are more \nclosely related to our work. In [19], a cutoff detection algorithm is proposed to determine a bound on \nthe number of threads needed to explore all thread states. In [22], an under approximation method based \non limiting the number of scheduler rounds (as opposed to context-switches) and the use of linear interfaces \nto summarize in\u00adterference in a round is proposed. We compare against both these algorithms in our experiments \nin Section 6. The most important advantage of our framework is that we handle unbounded data do\u00admains \nsuch as integers, whereas these other techniques are limited to Boolean programs. Based on our experiments, \nit is a signi.cant advantage to be able to apply directly to integer programs, since predicate abstraction \ndoes not make any considerations for threads (a very recent work [11] takes a .rst step towards closing \nthis gap by making predicate abstraction symmetry-aware). In [4], an abstract domain construction was \npresented which can represent invariants of the form .t..(t), where t is a variable rep\u00adresenting a thread \n.(t) is an abstract value in some base domain. Since such an invariant is an assertion about all threads \nrather than some .xed set, this technique is applicable to parameterized pro\u00adgrams. The authors apply \ntheir construction to a shape domain and successfully verify linearizability for a number of concurrent \ndata structures, a property that is more complex than the type we con\u00adsider in this paper. However, computation \nof abstract transformers for quanti.ed domains is potentially very expensive. Moreover, our computation \nof thread interference using traces is potentially more accurate than their method, which is state-based. \nThere are a few recent approaches in concurrent program veri\u00ad.cation [15, 18, 25] which assume a .xed \nnumber of threads (and therefore not applicable to parameterized programs and not directly comparable \nto our work), but are worth mentioning here. The work in [15] uses predicate abstraction to automatically \ngenerate envi\u00adronment abstractions for threads in a rely-guarantee based proof method. They attempt to \n.nd a modular proof (where the environ\u00adment of every thread refers only to global variables) if one exists, \nand generate a non-modular one (local variables can occur every\u00adwhere) otherwise. They can prove more \nsophisticated properties (such as correctness of Bakery algorithm) than DUET, but only for a small .xed \nnumber of threads (2-4); therefore, it is hard to draw any fair comparison between the two tools. The \nwork in [18] is based on abstract interpretation, where they re.ne the transaction graphs which model \ninterference among threads, using abstract in\u00adterpretation. At a high level, our work is similar to the \napproach in [25]; however, there are signi.cant differences (besides the fact that our approach deals \nwith parameterized programs). Our notion of interference is quite different, and our need to iterate \nour analy\u00adsis until convergence is for a different reason. In particular, in [25], the notion of interference \nis static in the sense that the structure of the data.ow equations do not change from one round to the \nnext; only the abstract values involved change. 8. Conclusion and future work We propose a solution to \nthe problem of verifyinbg thread invari\u00adants for parameterized multithreaded programs. Our approach is \nbased on an iterative framework consisting of a feedback loop be\u00adtween two components: one that computes \ndata invariants using a data .ow graph representation of the program and another that uses the data invariants \nto infer new data .ow edges and update the data .ow graph. Our algorithm is sound and terminating, and \nis applicable to programs with in.nite state (e.g., unbounded in\u00adtegers) and unboundedly many threads. \nWe have implemented our approach into a tool, called DUET, and applied it to a selection of Linux device \ndrivers and a large suite of Boolean programs. Our ex\u00adperiments demonstrate the effectiveness of the \napproach in proving properties of parameterized concurrent programs in terms of both speed and precision. \nAliasing is a big obstacle for any program veri.cation method, and more speci.cally for concurrency veri.cation. \nIn our frame\u00adwork, distinguishing two global variables as non-aliases can po\u00adtentially have a huge impact \non the patterns of interference among threads, and make or break a proof of correctness. Also, naturally, \ninformation about data invariants and thread interferences can re\u00adsult in a more precise alias analysis \nfor concurrent programs. We believe that combining alias analysis inside the feedback loop in our framework \nis an interesting research question for future work. As discussed in Section 5.1, a more intelligent \nalgorithm for com\u00adputing variable groups for relational analyses will also de.nitely improve the precision \nand scalability of our analysis.  Acknowledgments We wish to thank Andreas Podelski for his signi.cant \nrole in im\u00adproving the presentation of this paper. We would also like to thank Patrick and Radhia Cousot \nfor their comments on an earlier ver\u00adsion of this paper. Finally, we thank Alexander Kaiser and Gennaro \nParlato for providing the Boolean programs and for their help with running Boom and Geta.x. References \n[1] J. Alglave, D. Kroening, N. He, A. Ranjan, N. Seghir, and M. Tautschnig. CPROVER project, Nov. 2011. \nURL http://www.cprover.org/. [2] T. Arons, A. Pnueli, S. Ruah, J. Xu, and L. D. Zuck. Parameterized veri.cation \nwith automatically computed inductive assertions. In CAV, pages 221 234, 2001. [3] G. Basler, M. Mazzucchi, \nT. Wahl, and D. Kroening. Symbolic counter abstraction for concurrent software. In CAV, pages 64 78, \n2009. [4] J. Berdine, T. Lev-Ami, R. Manevich, G. Ramalingam, and M. Sagiv. Thread quanti.cation for \nconcurrent shape analysis. In CAV, volume 5123 of LNCS, pages 399 413. 2008. [5] J. Bertrand and A. Min\u00b4e. \nApron: A library of numerical abstract domains for static analysis. In CAV, pages 661 667, 2009. [6] \nA. Bouajjani, B. Jonsson, M. Nilsson, and T. Touili. Regular model checking. In CAV, pages 403 418, 2000. \n[7] J. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, and M. Sridha\u00adran. Ef.cient and precise datarace \ndetection for multithreaded object\u00adoriented programs. SIGPLAN Not., 37:258 269, 2002. [8] E. Clarke, \nD. Kroening, and F. Lerda. A tool for checking ANSI-C programs. In K. Jensen and A. Podelski, editors, \nTools and Algorithms for the Construction and Analysis of Systems (TACAS 2004), volume 2988 of Lecture \nNotes in Computer Science, pages 168 176. Springer, 2004. ISBN 3-540-21299-X. [9] E. M. Clarke, D. Kroening, \nN. Sharygina, and K. Yorav. Satabs: Sat\u00adbased predicate abstraction for ansi-c. In TACAS, pages 570 574, \n2005. [10] A. Cohen and K. S. Namjoshi. Local proofs for linear-time properties of concurrent programs. \nIn CAV, pages 149 161, 2008. [11] A. F. Donaldson, A. Kaiser, D. Kroening, and T. Wahl. Symmetry\u00adaware \npredicate abstraction for shared-variable concurrent programs. In CAV, pages 356 371, 2011. [12] E. A. \nEmerson and V. Kahlon. Model checking large-scale and pa\u00adrameterized resource allocation systems. In \nTACAS, pages 251 265, 2002. [13] E. A. Emerson and A. P. Sistla. Symmetry and model checking. Form. Methods \nSyst. Des., 9:105 131, 1996. [14] D. Engler and K. Ashcraft. Racerx: effective, static detection of race \nconditions and deadlocks. SIGOPS Oper. Syst. Rev., 37:237 252, 2003. [15] A. Gupta, C. Popeea, and A. \nRybalchenko. Predicate abstraction and re.nement for verifying multi-threaded programs. In POPL, pages \n331 344, 2011. [16] C. N. Ip and D. L. Dill. Verifying systems with replicated components in murf;, 1997. \n[17] R. Johnson and K. Pingali. Dependence-based program analysis. In PLDI, pages 78 89, 1993. [18] V. \nKahlon, S. Sankaranarayanan, and A. Gupta. Semantic reduction of thread interleavings in concurrent programs. \nIn TACAS, pages 124 138, 2009. [19] A. Kaiser, D. Kroening, and T. Wahl. Dynamic cutoff detection in \nparameterized concurrent programs. In CAV, pages 645 659. 2010. [20] Y. Kesten, O. Maler, M. Marcus, \nA. Pnueli, and E. Shahar. Symbolic model checking with rich assertional languages. In CAV, pages 424 \n435, 1997. [21] Y. Kesten, A. Pnueli, E. Shahar, and L. D. Zuck. Network invariants in action. In CONCUR, \npages 101 115, 2002. [22] S. La Torre, P. Madhusudan, and G. Parlato. Model-checking param\u00adeterized concurrent \nprograms using linear interfaces. In CAV, pages 629 644. 2010. [23] S. K. Lahiri and R. E. Bryant. Predicate \nabstraction with indexed predicates. ACM Trans. Comput. Logic, 9, 2007. [24] L. Lamport. A new solution \nof dijkstra s concurrent programming problem. Commun. ACM, 17(8):453 455, 1974. [25] A. Mine.\u00b4Static \nanalysis of run-time errors in embedded critical parallel c programs. In ESOP, pages 398 418, Berlin, \nHeidelberg, 2011. Springer-Verlag. ISBN 978-3-642-19717-8. [26] M. Naik and A. Aiken. Conditional must \nnot aliasing for static race detection. SIGPLAN Not., 42:327 338, 2007. [27] M. Naik, A. Aiken, and J. \nWhaley. Effective static race detection for Java. SIGPLAN Not., 41:308 319, 2006. [28] G. C. Necula, \nS. McPeak, S. P. Rahul, and W. Weimer. Cil: Intermedi\u00adate language and tools for analysis and transformation \nof c programs. In CC, pages 213 228, 2002. [29] A. Pnueli, S. Ruah, and L. D. Zuck. Automatic deductive \nveri.cation with invisible invariants. In TACAS, pages 82 97, 2001. [30] A. Pnueli, J. Xu, and L. D. \nZuck. Liveness with (0, 1, 8)-counter abstraction. In CAV, pages 107 122, 2002. ISBN 3-540-43997-8. [31] \nP. Pratikakis, J. S. Foster, and M. Hicks. Locksmith: context-sensitive correlation analysis for race \ndetection. SIGPLAN Not., 41:320 331, 2006. [32] N. Sterling. Warlock -a static data race analysis tool. \nIn USENIX Winter, pages 97 106, 1993. [33] J. Whaley and M. S. Lam. Cloning-based context-sensitive pointer \nalias analysis using binary decision diagrams. SIGPLAN Not., 39:131 144, June 2004. ISSN 0362-1340. \n   \n\t\t\t", "proc_id": "2103656", "abstract": "<p>In this paper, we consider the problem of verifying thread-state properties of multithreaded programs in which the number of active threads cannot be statically bounded. Our approach is based on decomposing the task into two modules, where one reasons about data and the other reasons about control. The data module computes thread-state invariants (e.g., linear constraints over global variables and local variables of one thread) using the thread interference information computed by the control module. The control module computes a representation of thread interference, as an incrementally constructed <i>data flow graph</i>, using the data invariants provided by the data module. These invariants are used to rule out patterns of thread interference that can not occur in a real program execution. The two modules are incorporated into a feedback loop, so that the abstractions of data and interference are iteratively coarsened as the algorithm progresses (that is, they become weaker) until a fixed point is reached. Our approach is sound and terminating, and applicable to programs with infinite state (e.g., unbounded integers) and unboundedly many threads. The verification method presented in this paper has been implemented into a tool, called Duet. We demonstrate the effectiveness of our technique by verifying properties of a selection of Linux device drivers using Duet, and also compare Duet with previous work on verification of parameterized Boolean program using the Boolean abstractions of these drivers.</p>", "authors": [{"name": "Azadeh Farzan", "author_profile_id": "81350568899", "affiliation": "University of Toronto, Toronto, ON, Canada", "person_id": "P2991408", "email_address": "azadeh@cs.toronto.edu", "orcid_id": ""}, {"name": "Zachary Kincaid", "author_profile_id": "81472649374", "affiliation": "University of Toronto, Toronto, ON, Canada", "person_id": "P2991409", "email_address": "zkincaid@cs.toronto.edu", "orcid_id": ""}], "doi_number": "10.1145/2103656.2103693", "year": "2012", "article_id": "2103693", "conference": "POPL", "title": "Verification of parameterized concurrent programs by modular reasoning about data and control", "url": "http://dl.acm.org/citation.cfm?id=2103693"}