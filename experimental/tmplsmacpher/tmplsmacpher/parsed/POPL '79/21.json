{"article_publication_date": "01-01-1979", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1979 ACM 0-12345-678-9 $5.00 Predicate Path Expressions Stwt Andler Department of Computer Science Carnegie-Mellon \nUniversity Pittsburgh, PA 15213 Abstract: Path expressions are a tool for synchronization of concurrent \nprocesses. They are an integral part of the data abstraction mechanism in a programming language, and \nspecify synchronization entirely in terms of the allowable sequences of operations on an object of the \nabstract data type. This paper describes an attempt to push the path expression synchronization construct \nalong three dimensions ~Pecific~tion, verification, and implementation -into a useful theoretical and \npractical tool. We define Predicate Path Expressions (PPEs), which allow for a more convenient specification \nof many synchronization problems. The predicate is a powerful extension to path expressions that increases \ntheir expressiveness. We formally define the semantics of PPEs by a transformation to a corresponding \nnondeterministic program, thus allowing the use of known verification techniques for nondeterrninistic \nprograms to be used for proving properties of the PPE and the data abstraction of which it is a part. \nWe also describe our existing Implementation, in Algol 68, of a data abstraction mechanism that incorporates \nPPEs. 1. Introduction Path expressions (PEs) [Habermann 73, Campbell and Habermann 74] allow us to express \nsynchronization of operat~p~~ on data objects. The PE is an integral part of the data abstraction, and \nrestricts the allowable sequences of operations on an object, independent of the actual code in the bodies \nof the operations. This raises the abstraction level of synchronization, and also supports the use of \ndata abstractions. This work was supported in part by the Defence Advanced Research Projects Agency under \ncontract F44620-73\u00adC-0074, and in part by Chalmers University of Technology, Gothenburg, Sweden. However, \nPEs in the pure form do not allow convenient specification of many typical synchronization problems. \nSeveral suggestions for constructs that would increase the expressiveness of the PE have appeared [Habermann \n75, Flon ancl Habermann 76], each to solve one particular part of the problem. There are also no established \nmethods for proving the correctness of concurrent programs using PEs in their more general form, except \nin isolated cases [Flon and Habermann 76]. We need a method that will make it easier to form invarinnts \nand pre -and postconditions to prove integrity of the data structure ancl adherence to specifications. \nWe also need formal methods for proving the absence of deadlock and starvation as well as other properties \nof the solution. * Finally, there are few previous implementations of PEs available [Habermann et al \n78] to prove that they are practical in real systems. Especially, there is none that integrates PEs with \na data abstraction mechanism in a multi-processing environment. We thu? see three ways in which the PEs \ncan be improved and made into a useful theoretical and practical tool. -S_p~cificati~. By increasing \nthe expressive power of PEs we can make them into a tool that allows for easier specification of common \nsynchronization problems. -y rfi&#38;rJ-@&#38;. By finding a constructive verification technique for \nPEs we will aid in the construction of programs where sheer size or reliability requirements were major \nobstacles. The verification techntque should build on the satne principles as the ones used for verification \nof data abstractions in sequential programs. -hmp~mentation. By making an efficient implementation of \nPEs available we will provide a proving grouncl for the proposed implementation techniques and an assurance \nthat important aspects are not overlooked. accomplished, or hope to accomplish, along the three lines \nof improving PEs. But first we will look at path expressions in their simplest form in section 2, followed \nby an introduction in seclic)n 3 to the proposed PPEs in the form that we currently see them. Section \n4 defines the semantics of the PPEs. 2. Path expressions in their pure form Path expressions are a high-level \nsynchronization construct that specifies synchronization at the level of the data abstraction, i.e., \nin the type definition. A mechanism for data abstraction will contain the specification of a representation \nfor the abstract data type as well as definitions of all operations that can reapplied to objects of \nthat type. The PE then determines synchronization by specifying the allowable sequences of operations \non an object of the type. Suppose we want to define an abstraction for a single-slot buffer between concurrent \nproducer and consumer processes. We first clescribe the properties of the communication slot as an abstract \ndata type buffer, and then cleclare our particular buffer to be an object (instance) of the defined iype. \nThe type definition will contain: The data representation: message The operations: wrlte(buffer, message) \nand r.eo,d(buffer) -> message The synchronization: path (wr/te;read)* The path expression defrnes the \nallowable sequences of operations On a particular object by a regular expression. If we declare ourselves \na buffer b, the PE allows the following sequence of operations on 6: writdb,m); read(b); write(b,m); \nread(6); write(b,m~ ... Operations on other buffers will be restricted to a similar sequence, but will \nbe completely independent of the operations on the buffer b. The operators in the simplest form of PEs \nare sequencing (;), selection (+), and repetition (*). The execution of all operations in the PE are \nmutually exclusive. 0.;1) allows the execution of a strictly followed by the execution of b 0.+6 allows \nan execution of either a o r 6 O.* allows zero or more executions of a following each other Since path \nexpressions were first introduced by Habermann and Campbell they have been refined or altered in several \nsubsequent papers [Habermann 75, Flon and Haberrnann 76, Lauer and Campbell 74, Campbell and Miller 78]. \nThe basic set of operators in the pure PEs has been augmented by parallel paths , braces , conditional \npath element , priority operator , connected path , parallel operator , numerical path element , and \nothers. They are all , basically introduced to allow (1) the specification of parallelism in the path, \nor (2) finer control of when a particular operation can be applied. We want to bring the number of constructs \ndown, while providing the expressiveness offered by most of tlWm. We have kept the parallel operators \nintroduced by Habermann [Habermann 75] for (1), but have replaced all the operators in group (2) by a \nsingle cxtens. ion, the predicate. 3.1. Tho predicato We have allowed finer control over the application \nof operations by introducing predicates into the PE, which gave rise to the name PPE (predicate PE). \nThe operators for sequencing (;), selection (+), and repetition (*) are unchanged, but predicates can \nbe attached to any path element. The predicate restricts the language that can be generated by the re~ular \nexpression of the PPE in that the path element can only be used if the predicate is true, For the purpose \nof the predicate, the application of an operation ~ is further broken up into four parts, reqf (request), \nactf (aclivatign), (f (execution), and termf (termination), which are events with the implied ordering \nreq f < act f ~ Cf < termf in time. The predicate specifies a par tial ordering between actfand other \nelements in the execution history. The predicates are expressed entirely in terms of implicit counters, \nreq(g), oct(~), and term(g), on the number of events reqg, Octg, and termg (any g) [Robert and Verjus \n77] that prececie act$, and specify that actf can occur only if the predicate is true. The predicate \nis any Boolean expression involving only constants and the implicit counters mentioned above. 3.1.1. \nDiscussion As already mentioned, the purpose of introducing a ~redicate into the PE was to eliminate \nthe need for a number of od hoc operators and path elements that have been introduced to remecly specific \nshortcomings of the pure PE. Several papers have suggested synchronization scheme: basecl on the use \nof counters [Schmid 76, Robert and Verjus 77, Gerber 77], and the specific choice of counters of the \nnumber of requests, activations, and terminations was influenced by a discussion in the Operating Systems \nReview [Gerber 77, Andier et al 78, Gerber 78]. For efficiency reasons [Schmid 76] the predicate can \nbe restricted to linear relation expressions connected by the boolean operators not, and, and or. A linear \nrelational expression can be written in a normal form: alvl + a2v2 + ... + anvn + an+l s O, where al, \naz, .... an+l are integer constants, and VI, V2, .... Vn are the implicit counters req($f ), Qct(f ), \nand term(~ ) on any function ~ in the path expression. The appropriateness of counters and linear relational \nexpressions as compared to arbitrary data structures or arbitrary Boolean expressions is still under \ninvestigation. As we see it, path expressions have the following advantages: -They are part of a data \nabstraction mechanism -Synchronization is specified in one place only for each data abstraction -Simple \nsynchronization relationships are easily expressed as regular expressions -The path expression is a complete \ndescription Of possible sequences of operations, i.e., the code of the operations need not be inspected \nto determine the effect of the PE The PPEs preserve these advantages while adding the power of synchronization \nwith counters, which makes it especially easy to express solutions to problems involving fixed priorities, \nresource accounting, etc. 3,1.2. Example A shared bounded stack is an example where the pure PE is not \npowerful enough, without resort to additional constructs like a conditional or numerical path element. \nThe predicates tnake the PPE very simple in this case: init (int n) def ptr = oct(pu.sk) -terrn(pop) \npath (puslc[ptr<n] + (pop+ top)[ptr>O])* The init-clause describes the fact that each instance of a \nstack will have a constant integer (n, viz. the size) associfiteci with it at creation time, and the \nclef-clause specifies an explicit counter in terms of the implicit counters uct(push) and term,(pop). \nThe path expression describes the mutual exclusion of pu$h, pop, and top operators. H also specifies \nthat push can only be app{ied when ptr (the number of usecl slots in the stack) is less than the maximum \nsize n, and pop and top (which both inspect the top element of the stack, although only pop changes the \ncontents of the stack) can only be applied when there are elements in the stack, i.e., ptr is greater \nthan zero. 3.2. Tha data abstraction mechanism T-o allow experimenting with the PPEs, we have extended \nAlgol 68 with a clata abstraction mechanism. The mechanism has the following format: type <typencvne> \n= <data representation> init <parameters> <initialization> def <counter def{nition$> path <path expression> \nwi!h <<~/tared de~l~ratiolz$> %peratiorts> epyt Suppose we have declared the type stack with the operations \npush ancl pop. The following is an example of the declaration and use of stack objects: stack s = new \n.stack(size); push(s, 3.5); prhzt(pop(s)); The mechanism will be illustrated by a complete example, \naccepted by the current implementation. We choose an array implementation of a bounded stack. . The program \nis explained in detail below. 1. mode elem = real; 2. type stack = struct(int tos, ref [] elem eO 3. \ninit (int n.): (O, heap [l:rz]-elem) 4. def ptr = o,ct{push) -terrn(pop) 5. . paih (,nush[ptr<tt] + \n(pop+ top)[ptr>O])*; 6. with 7. export proc pu.$h = (stack s, real -s) void: 8. (Id of ,!s)[tos of \n!s +:= 1] := z;  9 export proc pop = (stack J) real: 1 0. (el of ?s)[(tos of !s -:= 1) + 1] 11, export \nproc top = (stack s) real: 12. (et of ?s)[tos of ?s] 13. epyt; 14. stack s = new stat/c(lO); 15. push(s, \n3.5); print(pop(s))  Line 1 defines the type of the elements in the stack, and lines 2-13 comprise the \ntype definition. The data part of the type is given after the equals sign in line 2 as a record with \ntwo fields. The integer tos IS the index of the top element of the sfack (f_op-gf-~tack), and et is a \npointer to an array (of unspecified size) containing the elements of the stack. In line 3, of which the \nfirst part has been described earlier, the initialization of each instance of a stack is given. The integer \ntosis initialized to zero, and et is made to point to an element array of the specified size generated \non the heap. The three operaticlns push, pop, and top, which were alreaciy mentioned coond construct \nspecifies ~ ordering between the are therefore defined as exported procedures in lines 7-12. The bodies \nof the procedures are trivial using the increment (i-:=) and clecrement (-:=) operators of Algol 68. \nWe have introduced the ! and ? operators as the means for accessing the internal data structure of an \ninstance of the data type being clefined; !s yielcls a reference to the value of s (which can Iherefore \nbe changed), while ?s returns the value itself. Line 14 is an example of a declaration of a stack The \nconstant s is a reference to a newly created instance of stack (c rested by new stack, which by convention \ninvokes the iniilalizatfon in line 3), with room for 10 elements. Although s cannot be changed (i.e., \nmade to refer to another stack object ), the contents of the stack object can be changed and inspected \nas in line 15 by the operations defined in the type definition. 4. Definition of semantics for PPEs A \nrigorous definition of the semantics of a programming construct is important both for understanding of \nthe construct itself and for verification of programs using it. The definition given here primarily serves \nas the basis (or the verification technique proposed in section 6, but should also clarify the exaii~ples \nin sections 3.1.2 and 5.3. The followinE is a list of the constructs currently included or proposed in \nthe PPE. regular operators .f+g selection f K/ sequence f* repetition pr~dicate ~ [B] restriction parallel \nOperators J g collateral {t} braces We will now define the semantics of a PPE in terms of the restrictions \nthat it imposes on the partial ordering in time of particular instances of (calls to) the operations \nmentioned in the f2Pl~. To do this, we first introduce the transformation C that transforms a PPE p into \na corresponding nondeterministlc program C(p). An execution of the program C(p) will define a partial \norciering in time between the executions of operations on a particular object. The program notation for \nthe program C(p) is Dijkstra s guarded commands [Dijkstra 76], augmented by a parallel construct cotwgin \n\u00ad coend. When the guards of more than one guarded command in an if or do construct is true, there is \na nondeterministic choice of one of those commancls, The do construct tertminaies when none of the guarcls \nare true. The semicolon separator (;) specifies a total order in time between the constituents. C(@g) \n= if true -> C(f) I true -> C(g) fi C(f ;g) = C(f h c(g) C(~ *) = if true -> skip I true -> C(th C(J*) \nfi  Here we have introduced recursion, which will result in an infinite program. An alternative is to \nuse iteration only, by introducing a ghost variable: C(~*)=goofz := true; do goon -> goon := false [ \ngoon ->c(f) od  Next, we define the expansion for the predicate B: C(~ [B]) = if B -> C(~) I not B -> \nbait fi  B is a W relational expression in recf(tl), aCWl), term(fl), req(fz), etc. Some of the paths \ndefined by this program maybe halted because thepredicate does nothotd. The parallei constructs require \ntheuseof cobegin-coend: C(fig) = cobegin CV ) // C(g) coand C({~ ]) = if -> C(~) I ->cobegin C(i)  \n  // C({f)) coend fi  This last example again contains a recursion. If we introduce another construct \nfor creating and terminating processes, fork and join, we can use an iterative statement here also. The \nfork statement names a procedure invocation and a process class. It wiii allow the execution of the named \nprocedure invocation in parallel with the main process, and assigns it to the given process ciass. The \njoin statement names a process ciass, and will cause the main process to wait for completion of all processes \nin the specified class. C({.f ]) = goon := true; do goon ->. C(~ k goon := tal.se j goon -> fork C(.f \n) in X od join k Finally, we define the expansion for the operations themselve~ in terms of the events \nactf and term$, C(jl = C12ctf); ff; C (tefmf) The symbol c~ signifies an empty action, that corresponds \nto an execution of the body of operation f, H serves the dual purpose of defining the partial order between \nsuch executions of ~ and allowing us to generate invariants over the bocly of ~ The events reqf , actf,and \nterrnf are expanded in the following way, where the square brackets indicate that the events are indivisible: \nC (reqf) = [req(f ) +:= 1] request C (actf) = [Oct(.f ) +,= 1] activation C (terrnf) = [terrrt(~ ) +:= \n1] termination Note that the event reqf is not restricted by the path expression but only serves to \nupdate a counter value. Also note that for simplicity we have not mentioned the identity of the object \noperated upon. Thus the above definitions of C and C apply only for the case where we bhly have one object \nof the type for which the path expression was given. For the case with more than one object we can take \nthe object identity into account by superscripting the events and counters with the creation number of \nthe object, We can now ciefine ttle semantics of a Predicate Path Expression p in terms of the partial \norderings generated by c(p). Each possible execution of C(p) generates a partial ordering of the events \n<$1, ff2, .... ~~n, where ~1, ~2, .... fn are the operations mentioned in the PPE. The execution history \nelt e~j ...$ em is said to satisfy the ppE p<~l, ~2, .... ,fn> M el, e2, .... em restricted Q 6 fl fz \n 7 fn is a subset of the partial ordering of events generated by ~m~ cotmput alien of C(p<tl, f2, ...r \npn>). Note that by the definition of the events, we will have the following axiom for a particular instance \nof an operation E req < act f~ f~ < f~ < ern fi 5. Specification of synchronization The majcjr tasks \nof solving a programming problem are specific at ion, implementation, and verification. The first task \nconsists of analyzing the problem and specifying the requirements of the solution. The second task involves \nfincflng the proper algorithms, choosing the data representations, ancl constructing the program. The \nmore suited the specification method is *O the problem and the programming lanEuage, the easier we will \nmake the implementation. At the extreme, if the specification language were also the programming language, \nwe have eliminated the second task. This section deals with the question of how close to this extreme \nwe can get. The third task is to verify, formalty or informally, that the implementation accomplished \nexactly the intent of the specifications. A suitable semantic definition of the proeramrning language \nconstructs will simplify the verification task, especially if it lends itself to atomization. Section \n6 will deal with that aspect of the problem. In investigating the use of pure path expressions and the \nextensions introduced to solve various problems that were very hard to solve without them, we have found \nat least two areas irr which PPEs need improvement. One is the specification of desirable parallelism \nbetween operators in the FE. This is already possible to some extent by using rnn[~~ p~~ but we feel \nthat certain classes of problems require other constructs. The other is the weak power of regular expressions \nin specifying complex sequencing. We need the power of a context free language to describe the relations \nbetween operations on a stack, for example. Synchronization takes places between two or more concur~em \nprocesses that are operating on one or more Q~qlg~_ @_a objects. The sharing of a data object is essential, \nsince otherwise there would be no need for synchronization. We need to insure the integrity of the shared \ndata object, and the correct operation of the proce~ses, which can be expressed as basically two separate \nsynchronization problems, -Exclusion: To insure that data is consistent, .- certain classes of operations \non the object must exclude other classes of operations from simultaneous access tothe data. -~o~eration: \nTo insure the proper func~ioning of operations on a shared object, they must be able to communicate information \nabout availability of resources, etc. Scheduling of processes is not a synchronization problem, and \nshould therefore not be built into the synchronization primitives. It is of interest that scheduling \ncan be expressed . examples, but we do not want to introduce any discipline on the handling of waiting \nlists other than an assumption of fair scheduling . 5.1. Exclusion One type of exclusion, mutual exclusion, \nis already built into the PE. The semantics of PEs specify that all evaluations of the path state are \nmutually exclusive, and further that constructs joinecl by the sequencing fi), selection (+), or repetition \n(*) operators are mutually exclusive. To specify weaker exclusion we must be able to detect the execution \nof classes of operations, and be able to restrict the execution of other classes of operations. In section \n3.1 we viewed an operation f as consisting of three events, req~, actf, and termt. We say that between \nreq~ and actf, f is w-, and between actf and term~, ~ is executing. We can now express exclusion of f \nby g as follows: ~ [act(g) -term(g) = O], where f [p] means that ~ can only execute if the predicate \np holds. The braces construct can also be used to relax, the mutual exclusion in PEs, see the readers/writers \nproblem in section 5.3. 5.2. Cooperation Certain types of sequencing can be specified directly in tha \nPE, hut in the fieneral case we need to be able to detect the presence of resources, etc., in fhe shared \ndata object. In a producer/consumer problem with a finite buffer, the messages are produced by deposit \nand consumed by remoue while slots are produced by remove and consumed by deposit. If n is the initial \nnumber of slots, we can express the synchronization as follows: def rrzsgs = term(cfeposit) -act(remove), \nslots = n + term(rernove) -act(deposit) pat h (deposit[slots~O] + rernoue[rnsgs>O])* There are other \nways of expressing a solution to the bounded buffer problem without predicates, but the shared stack \nproblem of section 3.1.2 is an example where they are necessary. 5.3. Scheduling There is no scheduling \nimplied for the queues maintained by the PPE implementation except for the basic fair scheduling requirement. \nInformally, this means that no operation allowed by the PE will be delayed indefinitely. However, the \npredicates and counters give a powerful tool for specifying certain kinds of scheduling with the PEs \nthemselves. In particular, fixed-priority scheduling is [Courfois et al 71]: Readers and writers access \nthe same data base, TO insure integr~ty of data, no readers or writers should be able to access the data \nbase while a writer is changing its content. Mu{ ual exclusion of readers and writers is one obvious \nway of doing this. 1. Mutual exclusion: path (read + r.urite)* However, we can relax this by allowing \nconcurrent access by readers, to get 2. Weak reader preference: path {{read} + rurite)* Note tflat we \nnow have introduced the possibility of starvation of writers. If it is essentiaf that the data is kept \nup-to-date, we coufd give writers priority, which leads to 3. Writer preference: def ww = req(write) \n-act(wrtte) path ({read[ww=O]] + write)* In this solution, any waiting writers wilf inhibit reader activatitm. \nAnother alternative follows the paradigm that it is better to kead stafe information than nothing at \nall, i.e., we fet waiting readers inflibit writer activation. 4. ~trong reader preference: def wr = req(reacf) \n-act(read) path ({read) + write[wr=O])* The next solution fets afl readers in as long as they keep coming, \nthen allows writers until no more are arriving, etc. This is so because the predicate in this case applies \nto the braces, i.e. waiting writers can only inhibit &#38;e start of the first reacfer. Once no writers \nare waiting, alj readers can be activatecl. In this solution, both readers and writers can indefinitely \novertake each 6ther. 5. Alternating solution: def ww = req(write) -act(wrke) path ({read} [ww=O] + write)* \n E3y simply inserting a ei~pie pradicate d varioua places in the PPE we have acflieved the sofutions \nto most pubfished variations on the RW probfem. However, solutions 2-5 all contain the starvation problem. \nTO specify the 6th solution, which maintains the order in which the requests arrive, we need to resort \nto multiple levels of path expressions or introducing some other way of specifying the FIFO order. In \na sense we introduce a concept of variable priority, where the priority is determined by arrival time. \nOne possibility. is to introduce a strongly coupled selection , @, which will cause a strict FIFO order \nbetween the elements in the selection. The justification of such an operator is still to be determined. \n6. Fair solution: path ({read} @ wrLte)* 6. Verification of solutions to synchronization problems We \nwill look at synchronization problems as just a special case of data abstraction. When we prove the correctness \nof an abstract data type we first prove weak correctness or the consistency of the abstraction, This \ncan be done by separately verifying integrity of the data structure (by showing invarianis) and adherence \nto specifications (by pre\u00adand postconditions for each operation). Second, we want to prove strong correctness \nby showing that each operation terrnina(es. In the concurrent case, however, strong correctness also \nrequires us to show the absence of deadlock and starvation (and possibly scheduling properties if part \nof the problem), and for the weak correctness we concentrate on verifying data integrity. Any verification \ntechnique needs a rigorous specification of the semantics of programming constructs, and to some extent \nit is influenced by the way this specification is done. The first attempt to formally specify the semantics \nof PEs can be found in [Lauer and Campbell 74, Berzins 77]. We are relying on another technique for formally \ndefining our PPEk, a technique that makes it possible to directly apply existing verification techniques \nfor sequential programs. We will now try to describe how the semantic description in section 4 can be \nused in the verification process. (An overview of different synchronization primitives and some proof \ntechniques that have been proposed with them can be found In [Andler 78]).  6.1. Weak corractnwa Weak \ncorrectness involves proving the consistency of the data abstraction, i.e., the integrity of the data \nstiwcture and the adherence to specifications for operations on the abstracl data type. The transformed \npath expression is nowin a more suitable form for standard verification techniques, e.g. Dijkstra s method \nof weakest priectmdition [Dijkstra 76, Flon 77, Flon and Suzuki 78] or l-toare s inductive assertion \nmethod [Floyd 67, Hoare 69]. 6.1.1. Invariants We use invariants to specify conditions that will always \nbe true about a data abstraction, conditions that guarantee the i_r~~z=rity of the data structure. The \ninvariants are shown to hold prior to and after all operations, which guarantees that each operation \nwill restore the data structure to a consistent state. In the concurrent case, invariants will sometimes \ncontain predicates to guarantee exclusion, etc. Recall the transformation of an operation in the PPE: \nC(fl = C (QCtf); (f; C (termf) Since the body of operation ~ will be executed between actf and terjrif(infact \nwe have already said that c~ corresponds to such an execution), we can now make the following observation: \nAny statement that can be shown to be true at {fin C(p) will be invariant over the body of ~, 6.1.2. \nPre-and postconditions The specifications for an abstract data type include pre\u00adand postconclitions for \neach operation. The task of verifying adherence to specifications for data abstraction involves showing \nthat the postcondition will be implied by the precondition in conjunction with the body of the operation. \nIn the absence of parallel operators, the predicates of the PPE will serve as preconditions for the operations. \n6,2. Strong correctness Verifying strong correctness, or total correctness, for a program can involve \nproving that the program is deadlock free or starvation free. These concepts have, been formally defined \nin [Flon and Suzuki 78], based on a model of parallel program execution in terms of a nondeterministic \nprogram. For each operation ~ on the abstract datti type, that is mentioned in. a program, we can informally \ndefine absence of deadlock and starvation in the foltowing way: -A program is deadlock f= for operation \n$, ~ from each execution state there is m execution path that either halts or permits ~ to execute. \n232 -A program is starvation !&#38;Q for operation ~ ~ from each execution state M execution paths either \nhalt or permit ~ to execute. [f a program is starvation free, it is also deadlock free. We can prove \nsuch properties of the PPE by looking at executicln sequences (paths) of the corresponding nondeterministic \nprogram C(p)l and interpret the above conditions. Aparticular initial pafh(esp. theemptypath)is -deadlock \nfree for F If al least some path with this initial path contains ~~ -starvation free for, fi If w p&#38; \nwith this Initial path contains ~~ Flon and Suzuki give axioms, inference rules, and theorems to allow \nthe verification of these properties in a model that closely resembles our transformed PPE C(p). We hope \nto be able to use these or similar rules to prove the absence of deadlock and starvation in the path \nexpression or the program that uses it. 7. lrnpkmentation of path expressions and data abstraction in \nAlgal 68 In order for PPEs to be a practical programming tool, there must exist efficient implementation \ntechniques. An actual implementation will also put the proposed implementation techniques to a test, \nand make sure that they are technically feasible. For several reasons we chose to implement the PPEs \nin Algol 68S, a subset of Algol 68 implemented on the C.rnmp multiprocessor at Carnegie-Mellon University \nby Peter Hibbarcl et. al. .[!-tibbard et al 76]. The language supports multiprocessing and type (mode) \ndefinitions and the availability of the implementors was a major advantage. Algol 68 supports type checking, \nbut not information hiding and other features that we associate with data abstraction. Since we also \nneed a syntactical means for associating PEs with the type definition, we decided to add a data abstraction \nmechanism to Algol 68S, The implementation, which is described separately [Andler and Hibbarcl 77], is \nmade flexible by the use of a preprocessor that translate sthe type definition into a slightly extended \nAlgol 68S, and runtime support routines for access to the internal representation of data objects and \nfor synchronization. It implements the PPEs as described in section 3 with the following exceptions: \n-the parallel operators are not implemented (as a consequence, the event counters act(f) and ter-rn(jbe \nby a single counter) )can replaced -the cdunter req(~ ) is not implemented The effect of parallel operators \nand the req(f ) counter can be simulated by dummy procedures in a straightforward way. The preprocessor \nworks at the Iexeme level of the compiler, i.e., it uses the lexical scanner of the compiler, does the \ntransformations on the stream of Iexemes, and feeds the new stream of Iexemes directly to the coinpiler. \nThe parts of the implementation that deals with PPEs are: 1. F arsing of the PPE 2!. Algorithms for reducing \nstates and removing ambiguities 3. Runtime routines (pro-and epilogues) to support synchronization. \n 7.1. Parsing the PPE The parsing stage builds up a graph representation of the finite automaton corresponding \nto the path expression. Each operation in the PE will be an arc in the gr$ph. The nodes in the graph \nwill be identified by the set of arcs that originate et the node (see figure 1). The set of arcs associated \nwith each node thus clescribes the set of operations that can be ., epplied in that state. The tteztstate \nfunction gives the state that each given arc will lead to. The set of arcs can be conveniently represented \nas bit-vectors, and the test for eligibility of an operation is then a simple bit operation arc 4 (d) \narc OP nextstate 1I path (a; (b+c~ d)* Figure }: Implementation graph and transition table between the \nset of arcs on which the operation can be applied and the set of arcs that can lead from the current \n.// -=- ~ ._ state. In other words, the eligibility of an operation can be  /,/ \\ determined by inspecting \nthe intersection between the eli~ible-~~m~ in the current state and the possible ~ for the requested \noperation. If this intersection is nonempty, the operation i$ feasible. If the intersection contains \nonly one eletnent, the next state is uniquely determined. 7.2. Ambiguities and reduction If the graph \nthat was generated by the parsing step is such that one or more intersections between the eligible arcs \nin some state ancl the possible ~ for sotne operation contains more than one element, we have an ambiguity \n(i.e., two or more arcs with the same operation are leading out of the same state and we thus don t know \non which arc the operation will execute). Such ambiguities can be removed by ~tandard techniques for \ntransforming nondeterministic finite automata into deterministic ones [t-topcroft and Unman 69]. The \nimplementation also contains algorithms for collapsing equivalent states. 7.3. Prologues and epilogues \nWith the resulting graph from the previous steps, we now have enough information to implement the synchronization \nrestrictions with the simple inclusion of a call to a common prologue and epilogue at the beginning and \nend of each prOcedure mentioned in the PE. The prologue takes as parameter the set of possible arcs for \nthe operation, and returns as value the uniclue arc on which the operation will execute. If the intersection \nbetween eli~ible ~ and possible. a= is empty, the process invoking the operation waits in the prologue \n~until the intersection becomes nonernpty. The e~ilo~ue takes as parameter the unique arc on which the \noperation executed and finds the next state from a table associated wi ththedala object (see figure 2). \n7.3.1. Prologues for predicates This simple implementation scheme will work for PEs containing the sequencing \n(;), selection (+), and repetition (*) operators. When we add predicates to the PE, the implementation \nchanges slightly. We now have to inckde counters in the data fields of the object, and In the transition \ntable indicate which counters should be updated, and how. The prologue will have to first make sure thaf \nthe , intersection of eligible arcs ancl possible arcs is nonempty, and then evaluate and test the predicate. \nlf the predicate is false, the process is put on a waiting list a&#38;l ~ test are retried after the \nexecution of a procedure that could change the outcome of the predicate [Gerber 77] k current state: \n{4J owaiting list: 0 transition table: . . .~- ~~ waiting processes \\   - J Figure 2:Tw0 instances \nof an abstract data type A possible layout is shown in figure 3. In a situation where efficiency is required, \nthe instructions for updating counters that are now stored in the transition table could be compiled \ninto the code of each function. 8. Conclusion This paper shows that it is feasible to improve path expressions \nin several respects, to make them a theoretical and practical tool for the programmer of concurrent systems. \nWe have proposc?dto move along three directions: -~_p~cification. By aclcling the predicate to PEs, \u00adand \nanalyzing the need for parallel Constructs, we will increase the expressive power of the PE. This will \nallow direct specification of most cotnmonly occurring synchronization problems, and greatly simplify \nsolutions to others. -~erification By formally specifying the semantics of path expressions in a tractable \nway, we allow the use of well-known verification techniques for sequential programs. This makesit possibie \nto verify consistency of a data abstraction, and absence of deadlock and starvation in the synchronization \nscheme expressed by the PPE. -!mpj~mentafion Supplying an implementation of PPEs in a multiprocessing \nenvironment will provide a proving ground for implementation techniques and promote the practical test \nof the F PEs. The emphasis of the research is on the first two points, specification and verification. \nWe believe that the research will contribute in the following ways: -Combining the use of predicates \nand the regular expressions of PEs in a way that allows for easy verification and efficient implementation. \n-Formally specifying the semantics of PPEs in such a way as to allow the use of well-known verification \nmethods for sequential prog~ams. Givtng a method for verifying properties about synchronization by the \npath expression without taking into account the actual code of the operations that are synchronized. \n-Specifying the algorithms for, and the theoretical backgroundof -parsing the PPEs, building a graph \n-reducing the graph and removing ambiguities -the runtime routines proandepi -Providing an implemdntaiion \nin terms of a preprocessor that interacts with the compiler at the Iexeme level. 9. Acknowledgements \nThe author wants to thank Nico Habermann for encouragement and criticism on the ideas presented in this \npaper, Peter Hibbard for providing insight into Algol 68, and Paul Hilfinger for constructive ideas on \nthe ssmantic specification. References [Andler 78] Andler, S. Synchronization Primitives and the Verification \nof Concurrent Programs. In Proceedings of the Second International Symposktm o~Operatbzg Systems. lRIA, \nLe trt: Chesnay, France, Oct. 1978, cnt 1: [Andter and Hibbard 77] cnt 2: Andler, S., and Hi~bard, P.G. \nTypes in Algol 68, [ In Proceedkgs of the Fifth Annual III Conferertca on the Implementation and Design \nof ALgorWznttcL. wtguages,pages 124-144. IRiA, Le Chesnay, France, May 1977. [Andler et al 78] Andler, \nS., Feiler, P., Habermann, A.N., Prasad, V.R., and Tichy, W. Letter to the Editor, . I ... II :- Operattn \ngSystem sf7evie w12(l):6-ll,Jan. 1978. [Berzins 77] 13erzins, V. _ . Denotational and Axiomatic Definitions \nfor Path Q&#38;La.c Expressions. / - f I (f)l ewb Computatio nStructure sGroupMemo 153-1, Laboratory \nfor Computer Science, M.I.T,, Can~bridge, Mass., Nov. 1977. [Campbell ancl Habermann 74] Campbell, R.H. \nand Habermann, A.N, The Specification of Process Synchrsmizationby Path Expressions. In Gelenbe and Kaiser, \neditors, Lecture rVotesln Computer Science, Vol. 16: Operating Systems, pages 89-102. Springer Verlag, \n1974. increment instructions w [Campbell anti Miller 78] Campbell, R.H., and Miller, T,J, Figure 3: \nThe transition table for a PPE A Path Pascal Language. Draft, Department of Computer Science, University \nof Illinois at Champaign-Urbana, Urbana, Illinois, April 1978. [Courtois et al 71] [Habermann et al \n78] Courtois, P.J., Heymans, F., and Parnas, D.L. Concurrent control with reader: and writers ~, Ccwnrnu@catiorzs \nof the ACM 14( 1@):667-668, Och 1971. [Dijkstra 76] Dijkstra, E.W. A Disciplirse of Programming. Prentice \nHall, Englewoods Cliffs, New Jere ey, 1976.  [Flon 77] Flon, L. on the Design and Verification of U@&#38;atbsg \nSystems. PhD thesis, Department of Computer Science, Carnegie-Mellon University, Pittsburgh, PA; May \n1977. [Flon and Habermann 76] Flon, L. and Habermann, A.N. Toward the Construction of Verifiable Software \nSystems. Proceedings of the ACM Conference on Oata: Abstraction, Definition and Structure, SIGf LAN Notices \n1 l(Special issue) :141-148, March 1976. [Flon and Suzuki 78] Flon, L. and SLIZLIki, N. Consi~tent ancl \nComplete Proof Rules for the Total Correctness of Parallel Programs. In Proceedings of the Nineteenth \nAnnual IEEE Conference on the Foundations of Computer Science. Ann Arbor, Michigan, Oct. 1978. [Floyd \n67] Floyd, R.W, Assigning Meanings to Programs. [n J.T, Schwartz, editor, Mathematical Aspects o! Computer \n~cience, VOL j 9, pages 19-32. American Mathematical Society, Prov iltence, R.I., 1967.  [Gerber 77] \nGerber, A.J. Process Synchronization by Counter Variables, Operatirzg Systems Review 11(4):6-17, Oct. \n1977. [Gerber 78] Gerber, A.J. Letter to the Editor. Operwting Systems Review 12(3):5-10, July 1978. \n[Habermann 73] Habermann, A.N. Operations on shared data controUed by function modules in type definitions. \nDepartment of Computer Science, Carnegie-Mellon Unive rsit y, Pittsburgh, PA, Sept. 1973. [Habermann \n751 Habermann, A.N. Path Expressions. Technical Report, Department of Computer Science, Carnegie-Mellon \nUniversity, Pittsburgh, PA, June 1975. Habermann, A. N., Flon, L., Cooprider, L., Feiler, P., Guarino, \nL., and Schwanke, R.S. Modularization and Hierarchy in a Family of Operating Systems. Technical Repori \nCM(.H%-78-101, Department of Compute,r Science, Carnegie-Mellon University, Pittsburgh, PA, Feb. 1978. \n [Hibbard et al 76] Hibbard, P.G., Knueven, P: and Leverett, E3.W. A Stackless Run-time Implementation \nScheme. In Proceedings of the International Conference on Algorithmic Lang@ges, pages 176-192. Courant \nInstitute, New Yo~k, 1976. [Hoare 69] Hoare, C.A.R. An Axiomatic Basis for Computer Programming. Communications \nof the ACM 12(10):576-580,583, Oct. 1969. [Lauer and Campbell 74] Lauer, P.E., and Campbell, R.H. A \nDescription of Path Expremions by Petri Nets. Technical Report, Computing Laboratory, University of Newcastle \nUpon Tyne, Newcastle Upon Tyne, Great Britain, May 1974. [Robert and Verjus 77] Robert; P., and Verjus, \nJ.-P. Toward Autonomous Descriptions of Synchronization Modules. In B. Gilchrist, editor, information \nProcessing 77, IFIF , pages 981-986. North-Holland Publ. Co., 1977. [Schmici 76] Schmid, H.A. On the \nEfficient Implementation of Conditional Critical Regions and the Constructions of Monitors. Acts In formatica \n6:227-249, 1976.  \n\t\t\t", "proc_id": "567752", "abstract": "Path expressions are a tool for synchronization of concurrent processes. They are an integral part of the data abstraction mechanism in a programming language, and specify synchronization entirely in terms of the allowable sequences of operations on an object of the abstract data type. This paper describes an attempt to push the path expression synchronization construct along three dimensions - specification, verification, and implementation - into a useful theoretical and practical tool. We define Predicate Path Expressions (PPEs), which allow for a more convenient specification of many synchronization problems. The predicate is a powerful extension to path expressions that increases their expressiveness. We formally define the semantics of PPEs by a transformation to a corresponding nondeterministic program, thus allowing the use of known verification techniques for nondeterministic programs to be used for proving properties of the PPE and the data abstraction of which it is a part. We also describe our existing implementation, in Algol 68, of a data abstraction mechanism that incorporates PPEs.", "authors": [{"name": "Sten Andler", "author_profile_id": "81100214701", "affiliation": "Carnegie-Mellon University, Pittsburgh, PA", "person_id": "P267717", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567752.567774", "year": "1979", "article_id": "567774", "conference": "POPL", "title": "Predicate path expressions", "url": "http://dl.acm.org/citation.cfm?id=567774"}