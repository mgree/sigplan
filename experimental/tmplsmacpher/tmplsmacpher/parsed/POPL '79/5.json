{"article_publication_date": "01-01-1979", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1979 ACM 0-12345-678-9 $5.00 THE EVOLUTION OF LIST-COPYING ALGORITHMS and The Need for Structured Program \nVerification Stanley Lee* Willem P. deRoever* ** Susan L. Gerhart*** Computer Science Division Computer \nScience Division USC/Information Sciences Inst. University of California University of California 4676 \nAdmiralty Way Berkeley CA 94720 Berkeley CA 94720 Marina del Rey CA 90291 1. INTRODUCTION How can one \norganize the understanding of complex algorithms? People have been thinking about this issue at least \nsince Euclid first tried to explain his innovative greatest common divisor algorithm to his colleagues, \nbut for current research into verifying state of-the-art programs, some precise answers to the question \nare needed. Over the past decade the various verification methods which have been introduced (inductive \nassertions, structural induction, least-fixedpoint semantics, etc.) have estab\u00adlished many basic principles \nof program verifi\u00adcation (which we define as: establishing that a pro9ram text satisfies a given pair \nof input\u00adoutput specifications) . However, it is no coin\u00ad cidence that most published examples of the \napplication of these methods have dealt with toy programs of carefully considered simplicity. Experience \nindicates that these first generation principles, with which one can easily verify a three-line greatest \ncommon divisor al\u00adgorithm, do not directly enable one to verify a 10,000 line operating system (or even \na 50 line list-processing algorithm) in complete detail. To verify complex programs, additional techni~es \nof organization, analysis and manipulation are required. (That a similar situation exists in the writing \nof large, correct programs has long been recognized --structured programming being one solution.) This \npaper examines the usefulness of cor\u00adrectness-preserving program transformations (see [6]) in structuring \nfairly complex correctness proofs. Using our approach one starts with a simple, high-level (or abstract \n) algorithm which can be easily verified, then successively refines it by implementing the abstractions \nof the initial algorithm to obtain various final, detailed algorithms. In Section 2 we introduce the \ntechnique by deriving the Deutsch--Schorr\u00ad *Partially supported by NSF grant MCS 78-00673 **present affiliation: \nDept. of Computer ScienCe, Univ. of Utrecht, Budapestlaan 8, Postbus 80-012, 3508TA Utrecht, The Netherlands \n***Re~earch conducted in part under Defense Advan ced Research Projects Agency contract DAHC 15-72-C0308; \nalso. partially supported by NSF grant MCS Waite list-marking algorithm [14]. Our main ex\u00adample is the \nmore complex problem of verifying bounded-workspace list-copying algorithms: Sec\u00adtion 3 defines the issues, \nSection 4 presents the key intermediate algorithm in detail and Section 5 considers three of the most \ncomplex (published) implementations of list-copying, one of which is discussed in detail. In Section \n6 we make some general remarks on program verification and the relevance of our results to the (larger) \nfield of program correctness; Section 7 mentions some related work. 2. FIRST EXAilPLE: LIST MARKING \n 2.1 Problem specification and the initial algorithm We wish to define list marking in general terms, \napplicable to anY Particular implementation. AS list marking is a special case of computing the reflexive-transitive \nclosure of a relation, we let (1) Mem denote a non-empty set, (2) R denote a binary relation between \nelements of Mere, and  (3) z denote some element of Mere.  Then (2) and (3) define our input assertion \nas ZCMemAR cMemXMem , and the goal is to con\u00adstruct the s=t R*(Z) , defined as the smallest set, m, satisfying \nZ C m A R(m) ~m . Interpreting Mem as the (finite) set of all memory cells, R as: aRb w b is directly \nreachable from a (a points to b), and z as the root cell of some list structure, we conclude that Input-M: \nZ~MemAR$MemXMem m= R*(z) A z, Output-M: R, Mem unchanged are appropriate implementation-independent (~!ab\u00adstract \n) specifications of the task of construct\u00ading the set m of all cells reachable from cell Z. (As we use \nidentifiers beginning with capital let\u00ad ters exclusively for constants, the second half of Output-M will \nbe left implicit.) Our initial marking algorithm is MA-O (see top of next page) . In MA-O (and throughout \nthis paper) we use R(p) to denote {q: pRq}, i.e. those nod= directly reachable from p. Note that the \nwhile statement, delimited by loop . . . endloop , includes its invariant assertion. The semantics of \nthe Select statement are defined as follows: MA-o: Assert Input-M: Z~MemAR~MemXMem m := {z} ; loop asserting \nInvar-MO: Z E m A m G R*(Z) while m c R*(Z) do Select p in . m satisfying not R(p) ~m ; m:=mU R(P) S!?sww \nAssert Output-M: m = R*(Z) P+3yE S: Q(y) {P] Select z in s satisfying Q(z) {PAzCSAQ(Z)} . for predicates \nP and Q not containing z as a free variable. Thus the Select statement is non-deter\u00administic, in that \nany element of set S satisfying Q may be assigned to z . When a transformation replaces a Select statement \nwith a deterministic program segment, any implementation may be chosen which meets the above semantic \ndefinition. This, along with differing implementations of abstract data structures, will enable us to \ngenerate dif ferent final algorithms from a common ancestor. A formal proof of (partial) correctness \nfor MA-O with respect to assertions Input-M, Output M is obtained by proving that 1) Invar-MO is invar\u00adiant \nfor the while loop, and 2) [Invar-MO A~(mc R*(Z))]+ m = R*(Z) . Both proofs are straightforward, requiring \nthe use of various properties of the domain in question, here finite sets. (2) trivially follows from \n[a~bA- (aCb)]= a=b, (1) requires several properties of sets, e.g. a E R*(b) + R(a) ~ R*(b) . Termination \nof MA-O is proven with the variant function IR*(Z) -ml whose value decreases at each iteration.  2.2 \nTransformations yielding the archetype We apply our first correctness-preserving program transformation \nto MA-O in order to remove the reference to R*(Z) from the loop exit test. By using the transformation \nschema TS1 (Figure 1) and the domain property: [a~b Ab~ R*(a)]= (R(b)~b) ~ (b= R*(a)) we can change while \nm c R*(Z) do . .. in MA-O to while not R(m) ~ m do . .. , a~the above set property ensures tha~the premise \nof TS1 is satis fied. Our next transformation introduces a new variable to increase the efficiency of \nthe exit test. If u (for unsure ) denotes a subset of m satisfying R(m u) 5 m , then only cells in u \ncan (possibly) point to new cells not already in m, allowing us to ignore cells in (m u) when eval\u00aduating \nnot R(m) ~ m . Employing transformation schemata TS1, TS2 and TS3 (see Figure 1) yields a new algorithm, \nMA-1: MA-1 , Assert Input-M m := {Z}; u:={z}; loop asserting Invar-Ml: Invar-MO AuqmAR(m-u).qm while \n. not R(u) ~ m do. Select p in . u satisfying not R(p) Sm ; m := m U R(p) ; u := new U endloo~ Assert \nOutput-M where new u satisfies the premise of TS2 (i.e., maintains the invariance of Invar-Ml) . We \nrefer to MA-1 as an archetypal algorithm for list marking --that is, different marking al\u00adgorithms can \nbe obtained from MA-1 (via transfor\u00admations) depending on how set u is implemented. In the remainder \nof Section 2 we shall derive the Deutsch-Schorr Waite (DSW) algorithm from MA-1; by derivations omitted \nhere, one can also obtain Algorithms A, B and C of [10] from archetype MA-1.  2.3 Intermediate marking \nalgorithms In deriving DSW we interpret u as the set of just those cells in m with any unexamined poin\u00adters \n--hence u := new u in MA-1 becomes u := (u -{p}) UR(P) , which satisfies the premise of TS2. As u will \nbe implemented with a data structure not allowing random access (e.g. a stack rather than an array) , \nour next algorithm, MA-2, removes the condition on the Select statement: MA-2: Assert Inwut-M m:={Z}; \nu:={Z}; loop asserting Invar-Ml while u+$do Select pin u; . if not R(p) ~m . then m := mUR(p) ; u := \n(u -{P}) U R(P) else u := u-{p} fi endloop Assert Output-M where ~ denotes the empty set and Select p \nin u abbreviates Select . . . satisfying true. No= that while the loop invariant is unchanged from algo\u00adrithm \nMA-1, the variant function necessary to prove termination is now IR*(Z) -(m -u) I . The transformation \nschema used is TS4. As the system of basic transformation schemata that we use has been formally presented \nelsewhere [61, [7], we discuss in what follows only the intermediate al\u00adgorithms, since in this paper \nthey, and not the transformations themselves, are our chief interest. Name of transfor- Original program \nPremise(s) for mation segment transformation New program segment TS1 -\u00adexit test replacement TS2 -\u00adaddition \nof loop variable TS3 --Select stint set restriction TS4 --Select stint condition elimination Assert \nP loop asrt. Invar -ile B do s endloop Assert Q Assert P {P] v:=eO {Pi} loop asrt. Invar  {Invar AP1 \nAB} while B d(> .. S; v:=el {Invar API} s endloop v not free in P,Q or Invar Assert Q v doesn t appear \nin S Select x in a bCaA sat~fyinq P(x) ~ ~: y ~ (a-b) + ~P(Y) Assert P [Invar(a) Aa#@  122Psx?. Invar(a) \n while X =ZI: B(x) do A yE a Select xin a A -B(Y)] * satisf~ B(x) ; Invar(a-{y}) s endloop Assert Q \nAssert P loop asrt. Invar ~ile Bg do s endloop Assert Q Assert P v := eO ; loop asrt. Invar A P1 ~i~B \ndo S ; v== el endloop Assert Q Select x in b sat~fying P(x) Assert P loop asrt. Invar(a) a+~ do while \nSelect x in= ; if B(x) t~n S .. else a:= a-{x} fi endlo~ Assert Q FIGURE 1 -- A Few Correctness-Preserving \nProgram Transformation Schemata Next we partition the set u into currently under examination and all \nthe denoted bv U1 -\u00adsubstituting UI (J {P} MA-2 we o~tain the new algor~thm ~-3~ MA-3: cell rest , for \np u in The set U1 can now be directly implemented as a stack, which,we denote by t . We then separate \nthe single while loop of MA-3 into two inner loops, each corresnondinq to one branch of the conditional \nstatement, to get our next algorithm MA-4 (see top of next page). In the invariant Invar-M4, t* denotes \nthe set of nodes contained in stack t . Assert Input-M Our next algorithm modifies MA-4 in two ways: \nm := loop {Z} ; asserting p :=Z ; Invar-M3: ul :=+ ; 1) To ped off element avoid re-calculating the stack \nin loop 2, a pair: <node, set R(p) for we make of nodes> each node each stack , and in pop\u00adloop while \n. p, Z~mAm~R*(Z) AR(m\u00ad(UI U{p}))5m Aul~m-{p} not (ul = $ A R(p) ~m) ~ 1 push p together with its (possibly) \nunmarked des\u00adcendants R(p) -{q} onto stack t . 2) To avoid unnecessary pop-push sequences we move the \nexit test for the main loop so that it follows loop 2, and unfold loop 1 once. (In the following if. \n not R(p) ~ m algorithm the syntax then Select q in R(p) loop asserting A: S1; while  B do S2 endloop \nsa=sfying not. q E m ; could equivalently be expressed m := m U {q} ; Ll: S1 ; U1 := P- q. U1 u {p} \n; L2: if n; . . . not B ~oto then LI goto L2 ; ) else. Select p in U1 ; Applying the appropriate \ntransformations yields fi . UI := U1 -{p} algoritkm MA-5 2.4 Implementing (Figure 2a). Deutsch-Schorr-Waite \n-Assert Output-M MA-5 algorithms is an archetype fo~ stack-based (including DSW) which differ marking \nPrincipally MA-4: Assert Input-M m := {z} ; p := Z ; Create/Stack(t) ; ~ asserting Invar-M4: p,z ~mAm~R*(Z) \nAR((m {p}) -t*) ~m At*~m-{p] while not (empty(t) A R(p) ~m) do . . --loop 1 2s.92 assertinq Invar-M4 \nwhile not R(p) ~ m do . Select q in R(p) sa=sfying not q E m ; m := mU{q} ; push (t,p) ; .=P-q endloop \n; ~ asserting Invar-M4 --loop 2 while R(p) ~ m and. not empty(t) do P := pop(t) endloop endloop Assert \nOutput-N in their implementation of stack t . The arche\u00adtype has a down phase --loop 1 -which follows \npointers to unmarked nodes, and a backup phase -\u00adloop 2 --which pops already-marked nodes off stack t \nin search of pointers to unmarked nodes. Obtaining DSW from MA-5 requires making four ad\u00additions: 1) \nSpecify the node structure by defining each node to contain four fields: mark, atom, a and b. For any \nnode p, p.mark is the mark bit of the node; p.atom = false indicates p is non atomic and pa, p.b contain \nleft-and right-link pointers, respectively (if p.atom = true then pa, p.b are disregarded as p is an \natom). Since memory cells corresponding to atoms are not marked in DSW, we implement R by interpreting \nR(p) as Ra(p) uRb(p), Ra(p) = if p.a.atom then @ else {pa} . ~(p~= if p.b.atom then $ ~ {p.b} . The \natom and mark fields correspond to abstract functions Atom, Mark: Mem + {true, false] res pectively. \n2) Implement set m by interpreting p E m as equivalent to p.mark = true. 3) Implement Select q in R(p) \nsatisfying not q E m (where ~ R(P) gm hoi-) by assigning th~alue if not p.a.mark then p.a else p.b to \nq. Thus . the left link of a node is followed in the trav\u00ad ersal before its right link (if possible) \n. 4) Implement stack t as a reversed-pointer linked list within the original list structure (see [12]), \nApplying transformations to MA-5 to add the above four features produces the DSW marking al\u00adgorithm MA-6 \n(Figure 2b). The following general observations about MA-6 also apply to the list\u00adcopying implementations \nof Section 5. TWO new types of assertions appear in the loop invariant Invar DSW. SameStack(t,tp) and \nm = {y: y.mark} are equivalence assertions which define the correspondence between the abstract and \nimplemented data structures. Note that m and t are, in MA-6, auxiliary or ghost variables, as the equivalence \nassertions have enabled the loop tests to be expressed independently of the abstract variables. We can \nnow remove the statements in italics from MA-6, and preface Invar-DSW with , =Jm, t: ,, ; the correctness \nof the resulting (non-italic) Deutsch-Schorr-Waite algorithn and invariant follows from the correctness \nof MA-6 by  the Ghost Variable Theorem (see [8]). Mod(aptr,bptr,atombit,tp,p) = (Ra,Rb,Atom) is a perturbation \nassertion which is necessary as a result of the in situ stack implementation. This  assertion defines \nthe changes made in the original list structure which pointers are reversed - and makes it possible \nto guarantee at termination that all pointers (and atom flags) have been re\u00adstored to their original \nvalues, in other words, (aptr,bptr,atombit) = (Ra,Rb,Atom) . (See Ap\u00adpendix Al for texts of assertions \nSameStack, Mod.)  3. LIST COPYING: SPECIFICATION AND INITIAL ALGORITHM In a fashion similar to Sec. \n2.1, we now con\u00adstruct a pair of input/output specifications for list copying by considering the general \ncase of extending a relation to produce an isomorphic mapping between elements. With Mern, R as in Sec. \n2.1, let s denote a subset of Mere, c denote a set disjoint from Mere, and equal in size to S, and D \ndenote a pairing of elements from S and c; then we wish to extend R to u such that R c o A (o -R) EC \nX C and o(D(y)) = {D(x): x ~ u(y)} for every y in S. Then, interpreting s as R*(Z), c as a set of IR*(Z) \nI cells (disjoint from the original set Mere) used for the copy of R*(Z), D as a one-to-one mapping from \ncells in the original list structure to cells in the copy, and u R as the set of all pointers in the \nnew list structure, we obtain Input-C: Input-M A C n Mem = (p A D: R*(Z) +C A D is a bijection output-c: \nR~UA(O-R)CCXC A Vy ~ R*(Z): u(~(y)) = D(O(y)) A Z,RrMem,C,D unchanged as our general copying specifications. \n(In Output C D(O(y)) denotes {D(x) : x E u(y)} and D is a bijection abbreviates D(y) = D(x) +X = y A \nrange(D) = C ) . We use original list structure,, and old cell in referring to R*(z) , and rrcopy list \nstructure and new cell to refer to (0 -R)*(D(Z)). Assert Input-M: Z ~ Mem A R C Mem x Mm Assert Input-DSW: \nInput-M A R = Ra UW Aaptr=Ra Abptr=~ ~ atombit = Atom A nil.atom A markbit .M~ X {false} {Z}; Z.mark \n:= true ; p := Z ; m := {2}, p:=z; m := Create/Stack(t) ; tp := nil ; Create/Stack(t) ; loop asserting \nInvar-M5: &#38;aSSertin~ Invar-DStJ: Invar-M5 A m = {y: y.mark} p,ZGm fi, m$ R*(Z) ~R((m-{p})-t*) ~m \n A SameStack(t,tp) A DefStack (t) A Mod(aptr,bptr,atombit,tp,p)=(Ra,~,Atom) loop asserting Invar-M5 \n@2p aSSerkinq Invar-DSW while not R(p) Cmdo . . while not((p.a.mark or p.a.atom) and (p.b.mark orp.b.atom)) \ndo . Select q in R(p) . if not (p.a.mark or p.a.atom) sat=fying not q E m ; then q:=p.a else q:=p.b ~ \n; m :=mU{q}; m := m U {q} ; q.mark := true ; pws%(t, <p=l?(p)-{ql> ) ; ~ q = p.a then p.atom,p.a,tp := \ntrue,tp,p push(t, <P,R(P) - {q}>) ; * p.b,tp z= tp,p g; Pq:= Pq:= endloop endloop -{p} loop asserting \nInva&#38;M5m-$] ~ asserting Invar-DSI/ m while tp # nil canal ((not tp.atom) or while (not empty(t)) \ncanal . t2Cmdo (tp.b.mark ~tp.b.atom)) &#38; pop(t) pop(-t) ; if tp.atom then tp. atom := false ; p,tp.a,tp \n:= tp,p,tp.a else p,tp.b,tp := tprprtp.b fi endloop endloop while tp # nil do while not empty(t) do \n Select q in t2 q := tp.b ; sat=fying not q E m ; m:=mu{q}; m :=mu {q}; q.mark := true ; Replace Top-of \nt with <tl, 1:2-{q] > ; =Top-o~twZth <tl, t2-{q} > ; tp. atom := false ; prtp.b,tp.a := tp.b,tp.arp \n; := Pq:* Pq endloop endloop . Assert Output-DSW: Output-M Assert Output-M: m = R*(Z) A {q: q.mark} \n= R*(Z) A (aptr,bptr,atombit) = (Ra,RbrAtom) Notation: tn ~ (top(t))n for n=l,2 cptr ~ {<Y,Y.C>: y in \nmemory A .y.atom t* ~ if empty(~) =$ else . tl U (pop(t))* ~ A .-y.c.atom] for c = a,b DefStack(t) S \nempty(t) V [tl~m A t2 C R(tl) C t2Um fbit ~ {<y,y.f>} for f = atom, mark A Def~tack(po~(t))] (see App. \nAl for SameStack, Mod) FIGURE 2a -- Algorithm MA-5 FIGURE 2b -- Algorithm MA-6 Although R*(z) appears \nin the assertion Input-C, the final copying algorithm start with only z and R given, and must traverse \nthe original graph (i.e. construct R*(Z)) in order to coPY it. If we assume for the moment that values \nof the function D are known a priori, we can obtain our initial list-copying algorithm CA-O: CA-O: Assert \nInput-C: Input-M (la) Acfl Mem=$A D:R*(Z)+C (lb) A D a bijection m :={z} ; (2) 0 := R UCOPY(Z) ; ~ \nasserting Invar-CO: Invar-MO ~ R C o (3) A(o-R)~cxcA o-R=c~py(m)  while m C R*(Z) do . Select p in \nm sat=fyinq not R(p) ~m ; m:=mUR(p); (4) 0 := O U COPY(R(P)) endloop Assert Output-C: Output-M (5a) \nARCOA(CJ-R)CCXC (5b) A a(D(F))=D(C7(Y)) ~~R*(z): by applying a transformation to w-O in order to add \nthe lines numbered above. In line (2) copy(Z) denotes {~(Z),D(y)>: y ~ R(Z)} i.e. the set of copies \nof edges from nade Z (speaking of the list structure as a 9raph); in lines (3) and (4), copy(w) is U \nCOPY(Y): y E w for w equal to m or R(p) respectively. Hence in CA-O, the edges from each node y are copied \nas y is added to m (encountered in the traversal) . Given a verification of ~-0, to verify CA-O with \nrespect to Input-C, Output-C we need only check that the premises of the applied transformation are satisfied, \nby 1) establishing the invariance of line (3) and 2) noting that Invar-CO A Output-M = Output-C. The \nproof of ter mination uses the same variant function as for MA-o . 4. THE ARCHETyPAL LIST-COPyING ALGORITHM \n(ALCA) 4.1 Motivation of the archetype Three new issues relevant to list copying (but not list marking) \ninfluence our derivation of the copying archetype ALCA from CA-O. 4.1.1 Generating the bijection D In \nthe final target copying algorithms a pre existent D, or old cell/new-cell pairing, is not supplied; \nthus ALCA constructs a mapping which satisfies CA-O s Input C assertion. This results in a multi-pass \nstructure for the archetypal (and final) algorithms: one traversal of the graph to define a D (and identify \nR*(Z)), followed by a second traversal to do the copying. 4.1.2 Specifying traversal/copy order The \ntarget algorithms of interest to us oper\u00adate under a bounded workspace constraint --i.e. only a small, \nfixed amount of additional storage is available to the algorithm apart from the orig\u00adinal and copy list \nstructures. As a result, im\u00adplementing the abstract data structures of CA-O (and the copying archetype) \nwill involve consider\u00adable re-arrangement of the original list contents, which must nonetheless be restored \nto their ini\u00adtial values once the copying is complete. Veri fying that this is accomplished requires \nspecifi\u00ad cation of the exact traversal order in the invari\u00ad ant, and to this end the archetypal algorithm \nde\u00ad fines a spanning tree for the original digraph, greatly simplifying the assertions necessary for \ndefining the traversal and copying order. 4.1.3 Edge-oriented copying and traversal In CA-O, all edges \nfrom any node p are copied simultaneously (e.g. at line (4), for p # Z) . In the final algorithms of \nSection 5, however, edges (pointers) from a given cell are in general copied at different times. This \nsuggests an edge-ori\u00ad ented copying process for ALCA, since once copying is postponed for some edges, \nthe set m of visited nodes can no longer fully characterize how much copying has been done, as it does \nin CA-O. Insteadr the assertions in Pass 2 of ALCA, where the copy\u00ad ing is done, define the set of edges \ncopied in dependently of m, and all loop tests and traversal assertions are expressed in terms of edges \nrather than nodes.  4.2 The copying archetype in detail As Section 2 presented an extended example \nof the use of correctness-preserving program trans\u00ad formations, we omit here the intermediate algorithms \n(several of them similar to MA-1 through MA-5) lying between CA O and ALCA. Pass 1 of the arche\u00adtype \n(Figure 3a) is a proper extension of MA-5; Pass 2 (Figure 3b) , which is derived from CA O in\u00addependently \nof Pass 1, has a very similar struc\u00adture. The additions and changes to MA-5 (re\u00adflecting the comments \nof Sec. 4.1) are discussed below. 4.2.1 Bijection generation (Pass 1) The copy-area assertion Input-ALCA \nguarantees that the set avail --those cells initially avail\u00adable for constructing the copy - contains \na sub\u00adset which can satisfy Input C of algorithm CA O. For each node in the original graph encountered \nduring the Pass 1 traversal, a new cell is trans\u00adferred from avail to c via a Select/Move statement (an \nabbreviation for Select n in avail; avail := avail -{n}; c := c U7n}) and the pairing is added to the \nconstructed bijection H (now re\u00ad ferred to as (the lowercase) u to distinguish it from the constant D \nof CA-O). A new clause in the inVariant --Bijection (U,m,c) --asserts u to be a bijection from m to c; \nthus upon termination of Pass 1, p maps R*(Z) onto c, satisfying the a -bijectiOn assertion Of Input \nc.  4.2.2 Defining the spanning tree (Pass 1) The only other extension of Pass 1 beyond MA-5 is a standard \npartitioning of the eflges of the list structure into sets (s and b) of spanning tree and back edges, \nrespectively, as asserted by SpanTree(s,b,m) . While not all final copying algO rithms implement sets \ns and b, their presence (if only as ghost variables) greatly simplifies our proofs of correctness, since \nthe spanning tree (defined by) s is a recursively-describable struc\u00ad Assert Input-ALCA: In ut-M A avail \nflklem = ~ Assert Input-ALCA2: Output-ALCAl A Ze2 = Z A availl ~ IR*(Z)I m := {Z] ; p :=Z ; Create/Stack(t) \n; C:=l$; Select/Move n from avail to c ; T lJ:={<Z, n>}; s:=$; b :=$; ~ asserting Invar-ALCAl: Invar-M5 \nA Iavaill ~ [R*(Z) -ml \\ Bijection(N,m,c) A SpanTree(s,b,m) ~ asserting Invar-ALCAl while not R(p) Cm \ndo . Select q in R(p) sat~fying notq~m; m :=mU{q}; push(t, <P,R(P) -{q}>) ; s := s u {<p,q>} ; Select/Move \nn from avail to c ; . p := ~U {<q,n>} ; Pq := endloop b := b U {<p,ql>: ql GR(P)} ; ~ assertin g Invar-ALCAlm-$} \nwhile (-empty(t)) ~t2 ~m do b :=b U{<tl,ql>: ql ~t2} ; Pp (t) endloop while not empty(t) do . Select \np in t2 satisfying not p 6 m ; . m:= mU{p} ; Replace Top-of t ~<tl,t2 -{p}> ; s := s u {<tl,p>} ; Select/Move \nn from avail to c ;  P := ~ U {<p,n>} ; endloo~  Assert Output-ALCAl: Output-M A Bijection(P,R* (Z),c) \nA SpanTree(s,b,R* (Z)) (see Appendix A2 for Bijection, SpanTree) FIGU~ 3a --Pass 1 of ALCA ture with \nrespect to which traversal order can be statically defined: e.g., Pass 1 traverses the spanning tree \nin preorder , to paraphrase a typical assertion from Section 5. Such invariants become more complex when \nthey must be expressed solely in terms of traversal order over a (possibly cyclic) digraph. 4.2.3 Edge-copying \nand -traversal (Pass 2) In parallel with the ~nodef notation used So far we now define A R as als~ a \n~et of cages, each e = <e 1 e2> in R representing a directed edge from (node) el to (node) e2 et :={Ze} \n; e :=Ze; Create/Stack(tt) ; G:=R; ~ asserting Invar-ALCA2: Ze, e~ et Aet ~ I*(Ze) A I((et-{e}) -tt*) \n~ et A DefttStack(e,tt) A Input-ALCA2 A a -R = copyof(et -{Ze}) ~assertinq Invar-ALCA2 while I(e) ns#@ \ndo Select e ~ I(e) satisfying e =s; et := etU{e } ; 0 := 0 U copyof(e ) ; push(tt, <e,I(e) -{e }>) ; \ne :=el endloop et := etUI(e) ; c1 := u lJcopyof(I(e)) ; ~ ~ et-ieJ ~assertinq Invar-ALCA2 et while (not \nempty(tt)) ~ tt2ns=4 do et :=et Utt2 ; o := Uu copyof(tt2) ; pop ( tt) endloop while ~ empty(tt) * Select \ne in tt2 satisfying e=s; Replace ToP -of tt with ~ttl,tt2 -{e}>) > et :=etU{e} ; Is := 0 U copyof(e) \nendloop Assert Output-ALCA2: 0 -R = copyof(I+(Ze)) Notation: copyof(e) is { <U(e1),p(e2)>l copyof(eset) \nis U copyof(e G eset) (see App. A2 for DefttStack) FIGURE 3b --Pass 2 of ALCA I as a relation between \nedges defined by: eIe * e is incident upon e (or e2 e l = in terms of nodes) ; hence I ~ R x R, and \nZe as an auxiliary initial edge incident uPon node z, the root; thus I(Ze) = edges out of the root of \nthe list structure. Like Pass I, the second pass is a transitive clo\u00adsure algorithm: it copies I+(Ze), \nthe set of all edges of the graph (not I*(Ze) since Ze is ficti\u00adtious), just as Pass 1 traverses R*(Z), \nall the nodes of the graph. Pass 2 has a down and a backup loop just as .MA-5 and Pass 1 do. The loop-exit \ntests in Pass z ao not refer to membership in et, the set of edges ~raversed (compare while not . R(p) \n= m ..71 in pass 1) , the but use only spanning tree ~efined in Pass 1 to guide traversal: tree 59 edges \nare copied and followed, back edges are mere\u00adly copied. Showing that this results in only un\u00adcopied edges \nbeing added to et in loop 1 (hence termination) requires a more complex stack asser\u00adtion, DefttStack, \nthan in Pass 1 (see Appendix A2). Since edges are pushed onto the stack in Pass 2 rather than nodes, \nwe now refer to the stack as tt . 5. THE ROBSON LIST-COPYING ALGORITRM [11] Below we present the Robson \ncopying algorithm (RCA) as one implementation of our copying arche\u00adtype. 5.1 Overview of implementation \nof abstract data stfutttires   5.1.1 Node structure and relation R Each node p considered by RCA contains \ntwo fields p.L, p.R which contain either pointers to other nodes, or the nil pointer. SOR=R1UR2, Rl(p) \n=if P.L = nil then $ else {p.L} R2(p) =~p.R = nil then @else {P.R}  5.1.2 Set m RCA uses four pointer \nvalues -called MARK-i flags for i=0,1,2,3 which are distin\u00ad guishable from any pointer in the original \nlist structure. The Rlink of each original node is overwritten with one of these flags when the node \nis first encountered, so we interpret p ~ m+p.R = MARK-i, i.e. m = {y: y.R = MARK-i for i=0,1,2,3}. \n5.1.3 Stack t RCA implements t just as DSW does, with a re versed-pointer linked list. Thus if the current \nnode p lies in the left (right) subtree of some node y on the stack, then the Llink (Rllnk) field of \nyts left (right) descendant in the spanning tree points back to y. 5.1.4 Set avail RCA obtains cells \nfor the copy list structure from a free-list (i.e. heap allocation) --so Select/Move n from avail to \nc is implemented by a . . statement such as new(n)~ to use Pascal terminol oSIY .  5.1.5 Function u \nRCA puts a forwarding address , or FAddrr which points to the corresponding new cell, into the Llink \nof each old cell thus ALCA S u := ~ U {<p,n>} is implemented by p.L := n . 5.1.6 Sets s and b RCA uses \nrne four values of Che MAKK-i flags to indicate which of a node s two fields contain tree-or back-edge \npointers (nil is considered a back-edge pointer): odd value MARK-i flags indi cate tree edge Rlinks, \nflags valued 2 or 3 indicate tree edge Llinks. So in the implementation Llinks in s = {<p,p.L>: p contains \na MARK-2 or 3 flag], Rlinks in s = {<p,p.R>: p contains a MARK-1 or -3 flag}, where p.L, p.R denote the \noriginal pointer values.  5.2 Overview of program execution We now describe in general terms the two \npasses of RCA details are covered when the in\u00advariant assertions for the Robson algorithm are considered \nin Sections 5.3 -5.6 . The discussion below refers to intermediate algorithms RCA1-A and RCA2 (Figures \n4ar 6 respectively), which roughly correspond in their degree of refinement to algo rithm MA-6 except \nthat stack t remains unimplemen\u00adted. The reversed-pointer stack implementation appears in algorithm RCA1-B \n(Figure 4b)r as dis\u00adcussed in section 5.7 . 5.2.1 Pass 1 (Figure 4a ) As each old node, p, is first encountered \nin loop 1, a new cell n = U(P) is obtained (as in 5.1.4 above) and p s original pointer values are stored \nin the Llink and Rlink fields of n. Fields p.L and p.R are then overwritten with a FAddr and MARK-O \nflag respectively (5.1.5, 5.1.2). Figure 5b illustrates this stage in the pro\u00adcessing of p. Traversal \nthen continues just as in DSW (MA-6) , with the addition that whenever a pointer in p is followed to \nan unmarked node, the MARK-i flag in p.R is incremented by one (two) in\u00addicating that p s Rlink (Llink) \nis a tree edge (5.1.6). No other processing (e.g, copying) is performed during Pass 1, so at its conclusion \nwe have: a) defined p (via FAddrs) for every node in the original list, b) classified every edge as in \ns or b (via MARK-i flags), c) not copied any edges, and all original pointers are accessible (stored \nin corre\u00adsponding new cells) , exactly as in ALCA Pass 1. In addition, a depth\u00adfirst numbering of the \nnodes of the original list structure is defined by means of an abstract func tion called df#. This is \nan auxiliary function introduced solely to facilitate the correctness proofs - see Section 5.6.2 .  \n5.2.2 Pass 2 (Figure 6 ) The main traversal tests of Pass 2 whether a given edge is a spanning-tree \nedge --are imple\u00admented using the MARK-i flags. In general pointers are copied in loop 2, during backup \nphase, by placing the appropriate FAddr (of the cell pointed to) into the copy cell (see Fig. 5f ) . \nThe corre spending old pointer is restored to its original cell field at the same time; thus a FAddr \n(MARK-i flag respectively) is lost each time a Llink (Rlink) pointer is copied. In loop 1 Rlinks are \nfollowed before Llinks when possible, in opposite order to Pass 1 -this is crucial to the algo rlthm \ns success, as explained in Section 5.6. 5.3 Structuring the assertions One important benefit of using \nthe transforma\u00adtional method of program proving is the assistance it provides in organization of the \ninvariant assertions. That these assertions will be of con siderable length for any but the simplest \nof pro grams, cannot be denied --but this need not be fatal to verification efforts, provided assertions \n Assert Input-RCAl-A: Input-ALCA A R = R1 U R2 Assert Input-RCAl-B: Input-RCAl-A A Rj~~j ~Memx (Mere \nU{nil}) --without MARl@et 1 MARKset n Ma = $ asserv5<on In := {Z} ; p := Z ; Create/Stack(t) ; f:=Z; \ngf:=nil; OC1, (3C2, C := $ ; ~ := {<nil, nil>] ; 4; sl, s2, bl, b2 := 01,02 := X1,X2 ; new(MARK-0) ; \nnew(MARK-1) ; df# := { <2,1>} ; dnum := 2 ; new(MARK-2) ; new(MARK-3) ; ~ asserting Invar-RCAl-A loop \nasserting Invar-RCAl-B -asserting Invar-RCAl-A loop asserting Invar-RCAl-B Select/Move n from avail to \nc ; new(newf) ; p := p U {<p,n>} ; Ucl(n),0c2(n) := ol(p) ,02(p) ; newf.L,newf.R := f.L,f.R ; a (P) \n, a2 (P) := n,MARK-O ; f.L,f.R := newf,MARK-O ; while not (marked(Ocl(n)) and while not (marked(newf.L) \nand  marked(Oc2(n))) d= marked(newf.R)) ~ if not marked(Ocl(n)) ~ if not marked(newf.L) then q := (Jcl(n) \n; addmark(p,2) ; s := newf.L ; addmark(f,2) ; push(t, <p,0c2(n)>) ; newf.Ltgf := gf,f ; S1 := S1 u { \n<P,q>] * q := 0c2(n) ; addmark(p,l) ; else s := newf.R ; addmark(f,l) ; push(t, P,@>) ; newf.R,gf := \ngf,f ; 52 := 52 u {<p,q>l ; bl := bl U {<p,Ocl(n)>} ~ ; m := mU{q}; df# := df# U {<q,dnum>}; dnum:=dnum+l \n; :=  P~ f:=s endloop endloop bj := bj U {<p,acj (n)>} --for J-=1,2 ~nvar_RCA1_Am-{p} ~nvar_RcAl_Bm-{f} \n~ assertinq ~ asserting m m while (not empty(t)) canal while gf # nil qa@ marked(gf.L.R) @ (t2 = $ ~ \nmarked(t2)) ~ if odd(MARK(gf)) then . if t2 # @ then b2 := b2 U {<tl,t2>} ~ ; gf,newf.R := newf.R,s else \ngf,newf.L := newf.L,s ~ ; pop(t) endloop srfrnewf := frgf,gf.L endloo~ while not empty(t) do . while \ngf # nil ~ P := t2 ; m := m U {p} ; addmark(tl,l) ; f := newf.R ; addmark(gf,l) ; Replace Top-of t with \n<tl, 4 > ; newf.L,newf.R := s,newf.L S2 := S2 u { <tl,t2>} endloop endloop Assert Output-RCAl-A: Output-ALCA-l \nAssert Output-RCAl-B: Output-RCAl-A A R*(Z) = {y: 3-Eric(y)} ~ RCA-l-j for j=i to v variables in Notation: \nMARKset ~ {MARK-i: i = 0,1,2,3} RCA1-A -B marked(y) _ if y=nil then true f father P else U2(y) C MARKset \ns son q tl gf grandfather addmark(y,n) increments the MARK-i flag n newf V(p) in IS2(y) into a MARK-(i+n) \nflag f(p) := x for any function f denotes see Appendix A3 for invariants f := (f-{<p,f(p)>}) u {<P,X>} \nsee Figure 7a for invariants FIGURE 4b --AlgOrlthm RCA1 BFIGURE 4a --Algorithm RCA1 -A FIGURE 4 61 original \nnode y: copy node u(Y): .. contents contents ,.. FIGURE al(y), 02(y) Ocl(p(y)), lsc2(u(y)) ... first \nencoun\u00ad -tery / .. Y 5a) O-EnC(y) ~ I Ir 5b)y=pin 2A ~ loop 1 ,.. tI t second en-.. ... 5c) l-Eric(y) \n., ~ counter y / I II 5d) 2-Eric(y) 11(y) f ~ ,,~~ 5e) 3-Eric(y) xl (y) E2 (y) ...... ........ ~ ... \nI third en\u00ad .. counter y ,.. (above) Pass 1 -f is father of y in spanning tree / ;:,: ?, (below) Pass \n2 FIGURE 5f .. .. .. .. ... .. .. . .. .. E2 (y) O-EnC(y) I xl(y) .. . . &#38; A. ~. ~ ! .............. \n... ,,, ,, .,. ,. l-Eric(y) FIGURE 5g --. ....... indicates  ~ Pass 1 traversal 2-Eric(y) \\f \\ lJ(~2(Y))l \n~ 3-Eric(y) ~  FIGURE 5 are not thought of and produced as formless ex-n-Enc(y) is true just when y \nhas been encountered pressions in first-order predicate 109ic. Asser (in the DSW sense) n times. tions \nbecome much more manageable when their struc- Virtually all of the new invariant clauses for ture clearly \nreflects (one s understanding of) the the Robson algorithm not present in ALCA are of the functioning \nOf the program which they describe. form n-Enc(y) * . .. . This format for the asser We feel this is \na property shared by our invariants, tions clarifies the description of exactly how RcA by virtue of \ntheir incremental construction in the first builds up (in Pass 1) , then dismantles (in context of increasingly-refined \nalgorithms. Pass 2) its in situ implementations of ALCA S copy\u00ad . The concept we use to organize the \nassertions related abstractions U, s and b. In the DSW im\u00adneeded for the final copying algorithms is \nnode plementation (MA 6) of MA-5, in contrast, only the status. A natural way to describe, in the course \ninvariant Mod(. .. )=(Ra,Rb,Atom) is needed to of Pass 1 or Pass 2, how much processing a node has define \nthe progression of the single in place im\u00adundergone is to refer to how many times the node plementation \n(of stack t) which must be removed has been encountered thus far in the traversal. before termination \nof the algorithm. Since RCA uses Deutsch-Schorr-Waite traversal, the possibilities are O, 1, 2 or 3 encounters \n(see 5.4 On verifying Pass 1 Figure 5g ). Correspondingly we employ four pre\u00addicates to partition the \nnodes of the original The invariant clauses for Passes 1 and 2 of graph --referring to the abstract traversal \nstack RCA appear in tabular form in Figures ? a, 7b re\u00adt, we define spectively. This figure is read as, \nthe n-Enc(y) predicate beginning each row implies (the conjunc\u00adO-Eric(y) as -(y 6 m ) tion of) all the \nentries in that row. Each column l-Eric(y) as y ~ t* A t2-Of(y,t) # $ comprises a Single assertion, of \none of the types (perturbation, equivalence) introduced in Section 2-Eric(y) as y 6 t* A t2-Of(y,t) = \n$ 2.4. Thus reading across a row defines the state 3-Eric(y) as y6rn A~(y6t*) of, e.9.r all l-Eric nodes; \nreading down ? column illustrates the stages that, say, MARK-i flags gowhere m denotes m -{p} in loop \n1 of Pass 1, m in through in a given pass. Note in particular that loop 2. (For Pass 2 interpret m as \n since at the end of Pass 1 every node in R*(z) is a{z} u {e2: e~ (etlls)}, and replace t with tt -\u00ad3 \nEric node (obvious since by the outer loop exit see Appendix A5). Given that node y is on stack t, test \nempty(t) holds, and also m = R*(Z), an old t2-of(y, t) is the set of nodes (in Pass 2, edges) friend \nby now) , keading across the bottom row of pushed onto t along with y. Thus , intuitively, Figure 7a \nyields the copying part of the RCA Pass 1 62 Output assertion. As every node of the graph is a9ain O-Eric \nat the start of Pass 2 by definition of n Enc, the top line of Figure 7kI is identical to the bottom \nline of Figure 7a, i.e. Output-RCAl * Input-RCA2, as desired. For the most part the copying assertions \n(col\u00adumns Invar-RCAl-i through -v) for Pass 1 of RCA simply reiterate Figures 5a e. RCA1-i says origi\u00adnal \npointer values are stored in the corresponding copy cell. We use (the constant) Z1(Y), Z2(Y) for the \noriginal Llink, Rlink values of node y, rather than Rar Rb as in the DSW assertions< as a reminder that \nthe Robson pointer relations are subsets of Mem X (Mere U {nil}) , and extensions of ALCA S R c Mem x \nMere. This is why uci(y) is used to de\u00adno~e the pointer value of a copy node y (rather than o -R as in \nALCA); Gi is used to refer to current pointer values in the original list struc\u00adture (similarly to aptr, \nbptr of DSW). Note that if, for example, both of p s pointers are nil, loop 1 of the implemented algorithm \nis exited. This is one case of the abstract condition R(p) ~ m, since R(p) (as defined in 5.1.1) is empty \nwhen p.L = p.R = nil. Of the four remaining equivalence assertions, m-MARK and V-FAddr(RCAl ii, -iii) \nare self-ex\u00adplanatory; the sb-MARK assertion (RCA1-iv) indi\u00adcates how the information content of the \nMARK-i flag increases as first a node s Llink, then Rlink are examined during Pass 1 traversal; and the \nt-MARK assertion (RCA1-V) defines the possible values of the MARK-i flags for each n-Enc group. This \nassertion is needed in Pass 1 since the flag s value is incremented each time a tree edge is dis\u00adcovered \n-it is unnecessary in Pass 2 and does not appear in Figure 7b.  5.5 The need for availability assertions \nWe use the term availability assertions in referring to Pass 2 s equivalence assertions, to indicate \nthe role played by these invariant clauses in establishing the correctness of the second pass. The need \nfor these invariants is a straightforward consequence of the bounded-workspace constraint on the Robson \nalgorithm --since FAddrs and MARK-i flags are removed during Pass 2, our assertions must be strong enough \nto prove that at every ap\u00ad pearance of a u(Y) or e E s in algorithm RCA2 the necessary FAddr or MARK-i \nflag is still present. Availability assertions are unnecessary for the copying archetype, since in ALCA \nthe abstract data structures p, s and b are present throughout the course of the algorithm. Note also \nthat in the implementation of DSW (algorithm MA-6) availability assertions are not used because stack \nt can only be accessed through the variable tp (cf. comments made about MA-3). There is, however, no \nsimple restric tion on when any given node s FAddr or MARK-i flag will be needed in Pass 2 --thus ~, \ns and b are represented as sets in ALCA and must be implemented as (approximately) random-access data \nstructures. The next section explains, using availability as\u00adsertions, the precise extent of that approximation. \n 5.6 On verifying Pass 2 Note that instead of referring to a current edge e in the traversal, as in Pass \n2 of ALCA, we write p and q in RCA2 for (the head and tail nodes respectively of) ALCA S e . Correspondingly \nAssert Input-RCA2: Output-RCAl-A := nil, Z; etl,et2 := {<%P>} , $ ; Create/Stack(tt) ; --see App. A4 \nSIJP % assertin9 Invar-RCA2 k22Q ===tin9 Inv-RcA2 * _l while E(p) ns#@ do *_l if E2(P) ~S2 ~ et2 := \net2 UE2(P) ; push(tt, <P,El(p)>) ; cI*P := p,z2(p) else etj := etj U Ej(p) ; push(tt, p,@>) ; **-1 02(P),0C2(U(P) \n) := X2(P),P(X2(P)) ; cIfP := p,zl (p) Q endloop etj := et: u E](p) ; push(tt, p,@>) ; cson := v xl(p)) \n; **_2 02(p),oc2 u (P) ) := X2(J?),!J(X2(P)) ; ~ assertinq Invar-RCA2et~{e} A cson = U(rson(ttl)) while \n(not *-2 iftt2 # **-3 c12(ttl),17c2(p(ttl)) := z2(ttl),u(z2(ttl )fi; etl := etl U El(ttl) ; cson = \nU(ttl) ; **-4 ul(ttl), (scl(p( ttl)):=xl(ttl) U(xl(ttl)); pop (tt) endloop while g empty(tt) Q etl := \netl U El(ttl) ; **_5 cJ2(ttl),crc2 (u(ttl)) ,= z2(ttl),p(z2(ttl)); := ttl,xl(ttl) ; Replace Top-of tt \n~ <ttl, @ > endloop Assert Output-RCA2: y G R*(Z): Oj(y) = ~j(y) A ocj (~(y)) = U(~j (y)) qrP Notation: \nrson(ttl) ~ if l-Enc(ttl) then ~2(ttl) * Zl(ttl) each assignment stint S containing a j . . denotes \nS; ; S; FIGURE 6 --Algorithm RCA2 the first component of each stack element in RCA2 is written as a \nnode. This essentially notational change in stack tt is made in order to simplify the implementation \nas\u00adsertions, since in RCA2 it is more convenient to think of implementation values (FAddrs, etc.) as \nstored in the current node rather than in (the head of) the current edge. Recall that in Pass 2 of ALCA, \nnodes are not mentioned to emphasize that 4 63 rJ\u00ad m . ( 4 . r-l .rl r-? 3. I r < < I i m I w o w R \ns N 0 111 G .r! w 64 the transitive closure of the ~dge-incidence rela-ered to be an exainple of formal \nverification, but tion is being copied. rather an exposition on some methods useful in In algorithm RcA2, \nloop tests and assignment\u00adstatement right hand sides are still expressed ab\u00adstractly; the next transformation \nto be applied will replace E(p) (I s # $ with MARK(p) > 0 r, P := ~2(p) with p := p.L.R , etc. In the \ndis\u00adcussion below the intermediate algorithm referred to may be either RCA2 or its successor (omitted \ndue to lack of space) --the availability asser\u00adtions for the two are the same. 5.6.1 MARIC-i flag availability \nEvery implementation of an e ~ s test in Pass 2 (marked by (*) in Figure 6) is applied to an edge from \neither a O-Eric node (node p at (*-l)) , or a l-Eric node (node ttl in statement (*-2) , since the test \nis only made if tt2 # ~, implying l-Enc(ttl)). Thus by the availability assertion Invar-RCA2-iv (which \ncould be paraphrased as O Eric(y) v l-Eric(y) + Y.R is a valid ~RK-i fla9 ), the implemented version \nof the tree edge test is correct. The invariance of RCA2-iv is an immediate consequence of the fact that \nthe only edge possibly copied in loop 1 ( going down ) is the back-edge Rlink of a node y (if it has \none), after which y is a 2-or 3-Eric node (depending on whether or not y s Llink is found to be a tree \nedge). 5.6.2 FAddr availability Here the assertions must imply that when any edge, e, is copied by a \nstatement marked (**) in RCA2, that the needed p value for e - i.e. P(zi(P)) Or lJ(~i(ttl)) --is available. \nFor tree edges (**-3,4,5) this is accomplished by using in loop 2 an extra variable cson (~opy son) \n, along with a corresponding invariant clause stating that cson stores the FAddr of the node up from \nwhich we are returning. Since all tree edges are copied in backup phase , and each node F.as a unique \ntree ancestor, the single variable suffices. For back edges the case is more complex, as an arbitrary \nnumber of back edges, from any node in the list, may point to a given node y. As the FAddr-availability \nassertion (RCA2 iii) states: O-Eric(y) V l-Eric(y) V 2-Eric(y) O1(Y) = U(Y), we may (indirectly) demonstrate \nthe validity of (**-1,2,4) by establishing (1) 3-Eric(y) *lI({e Eb: e2 = Y}) Qoc where OC denotes the \nset Gcl U clc2 of edges in the copy list structure. The invariance of (1) is a consequence of Pass 2 \ns traversing the list struc\u00adture in reverse order (Rlink before Llink) from Pass 1. A detailed argument \nof (1) s invariance is greatly facilitated by the presence of df# and the Depth-First assertion (see \nAppendix A5), which enable a simple case argument (omitted here for lack of space) to be made. Note that \nwe certainly do not claim the above discussions to be proofs of the invariance of RCA2-iv or assertion \n(1) above; they are merely intuitive arguments to that end. In this article we emphasize the construction \nand nature Of the invariant assertions themselves, and have delib\u00ad erately omitted formal proofs of their \ninvariance. For that reason this article should not be consid\u00ad formal verification --see Section 7.1 \n.  5.7 The final transformations Applying a transformation to algorithm RCA1-A to implement stack t \n(just as with the WA-5/MA-6 transformation) yields RCA1-B (Figure 4b ), in which we revert to Robson \ns original variable names. (The correspondence with RCA1-A S vari\u00ad ables is noted in the accompanying \ntable.) This is done both to facilitate comparison with the program as originally presented in [11] and \nbecause Robson s mnemonics are more suggestive once the DSW stack is introduced. Given the assertions \nof RCA1-B, together with some elementary path analysis, one can then apply to RCAI-B the final transformation, \nobtaining Pass 1 of the Robson algorithm exactly as originally presented. That version bears approximately \nthe relationship to RCA1-B that MA-3 has to MA-4, since each pass of Robson s program is written as \na conditional statement within a single while loop. Pass 2 of the Robson program is obtained from RCA2 \nvia an identical sequence of transformations. 5.8 Beyond the Robson algorithm One advantage of the Robson \ncopying algorithm is its adaptability to any system of copy-cell al\u00adlocation. In some applications, this \nis an impor\u00adtant consideration --if, in the presence of gar\u00adbage collection, say, all free cells must \nbe or\u00adganized as a free-list. However, more efficient algorithms can be obtained by implementing ALCA \nS storage pool by means of a contiguous region of memory, addressed by values greater than Amin, for \nexample. This seemingly minor implementation re\u00adstriction has a significant effect on the effic\u00adiency \nof the resulting algorithms, as it eliminates the need for traversal flags. (Forwarding addres\u00adses are \nrecognizable a s pointers whose values exceed Amin, and thus by their presence mark vi\u00adsited cells.) \nThe extra workspace made available by this double use of the forwarding addresses is utilized in two \nways. 1) All copying need no longer be postponed until.Pass 2. Consider Figure 5b --once the MARK flag \nbecomes unnecessary, only the node s Llink must be saved in the copy cell; thus one new pointer for the \ncopy list structure can now be inserted in Pass 1. 2) Different types of traversal may be used, as follows. \nThe Fisher copying algorithm, pre\u00adsented in [5], can be otained from algorithm CA-O by a derivation which, \nat the transformation corresponding to the One producing algorithm MA-4 in Section 2.2, organizes the \nset, u1, of cells containing unexamined pointers, as a queue rather than as a stack. Subsequent transformations \nthen ~PIOY the contiguous copy region as an array in order to implement the traversal queue. The principal \nintermediate algorithm in this derivation is, apart from its use of a queue, essentially the same as \nALCA. The Clark list-copying algorithm, from [3], is the current state-of-the-art in terms of execution \ntime. As its traversal method is stack-oriented, its derivation parallels that of RCA up to and including \nthe archetypal algorithm. However, in subsequent refinements, both Pointers of the current node are always \nexamined in loop 1. Only those nodes containing two tree edges are pushed onto the stack, thus speeding \nup traversal of the original list structure. Our unpublished work on the Fisher and Clark algorithms \nadds support to the opinion t{at the refinement approach is particularly advantageous when verifying \na family of related algorithms. 6. PHILOSOPHY In assessing the significance of program\u00adcorrectness research, \nwe think it important to present some personal philosophy. By demonstra\u00adting program correctness we mean \nestablishing that a given program does what we want it to do , or more precisely, increasing our confidence \nthat a given program does what we want it to do . This is the desired end, which can be attained by a \nvariety of means: 1. There are empirical methods, such as pro\u00adgram testing, by which we increase our \nconfidence in a program s behavior. Since this increase results from an inductive inference based on \na particular experimental result, testing by itself is not the ultimate solution to problas of program \ncorrectness: testing cannot detect the absence of bugs, only their presence as the proverb goes. 2. \nThere are logical methods, such as program verification, which ~PloY (either formal or in. formal) arguments \nthat a program does what we in\u00adtend . The advantage of an informal method is that is deals directly with \nour intuitive notions of what the program should accomplish; however, a verbal analysis cannot take full \nadvantage of cur\u00adrent logical techniques of program verification, such as fixedpoint induction or our \ntransformation\u00adal approach. Once we express our arguments com\u00adpletely within a formal system (e.g. predicate \ncalculus) , however, we face the problem of trans lating our original intentions as to what we want the \nprogram to do into mathematically precise formal specifications. This problem of formal specification \nof real-world programs is a concern separate from the issues which we address in the current article. \nDespite our optimism about the progress being made (by others and ourselves) in the area of machine checkable \nproofs of large pro\u00adgrams, we grant that further progress in formal specification techniques is necessary \nbefore The Day arrives (if ever) that formal verification,  alone, can claim to solve the problem of \nestab lishing program correctness. 7. CONCLUSION ANO RELATED WORK  7.1 Conclusion We see our version \nof the transformational method as making three contributions: 1. As presented in this paper, it can \nbe used as an aid to informal verification: Sections 3, 4 and 5 argue the correctness of the final copying \nalgorithm by using our framework of ab stractions and implementations to motivate the invariance of the \nloop assertions. That (verbal) reasoning does not formally verify the Robson algorithm, but we feel that \nexplaining an algo\u00ad rithm in terms of its high-level structure is a more effective way of persuading \noneself of the algorithms correctness than is considering only the final program text. Also, the use \nof inter mediate algorithms reduces the complexity (and hence increases the credibility) of the individual \ncomponents of the correctness argument. 2. The axiomatic definition of our trans\u00adformation schemata as \npresented in full in [7] es\u00adtablishes the correctness-preserving property of the transformations - thus \nthe correctness of al\u00adgorithm MA-6 is a function solely of the validity of the application of the transformations \nused in its derivation, and the correctness of our initial algorithm, MA-O. This fact may be used to \nfor\u00admally verify MA-6 without ever having to indepen\u00addently establish the invariance of any loop as\u00adsertions \n(except that of the initial algorithm) . In verifying large programs, this may be an easier approach \nthan the traditional method of proving, in one stroke, the invariance of the final, extremely complex \nloop assertion. 3. Any formal verification should closely reflect one s understanding of why an algorithm \nworks. Our methodology both reflects and supports that opinion, and provides another counterexample to \nmuch-propagated and hence commonly held belief that there is an antagonism between rigour and for\u00admality \non the one hand and understandability on the other as Dijkstra says in [4].  7.2 Related work While \nin this summary of our initial efforts with list-copying algorithms we have spoken in terms of larger-scale \nprogram transformations than those described in [6], [7], this larger scale is particularly important \nwhen the intermediate al\u00ad gorithms are first formulated for complex programs. Blikle [1] considers some \ncorrectness-preserving program transformations defined in terms of an algebra of binary relations, and \nuses them to de\u00ad rive a small but highly-optimized square root al\u00ad gorithm. Topor [15] was the first \nto prove correctness of the Deutsch-Schorr-Waite algorithm. Yelowitz was among the first to apply the \nrefinement tech\u00adnique to verifying list-marking algorithms - see Yelowitz and Duncan [16] for an alternate, \nmore formal definition of the abstractions of Section 2. Various implementations of an abstract back\u00adtracking \nalgorithm are considered by Gerhart and Yelowitz in [9]. The very elegant program trans\u00adformation work \nof Burstall and Darlington in [2] is comparable in spirit to our approach; however, their technique appears \nbest suited to (algorithms processing) recursive data structures such as trees, in a simple applicative \nframework. The imperative features required to handle pointer manipulation and digraphs dictate a more \ncomplex memory formalism --obtained in our method by starting out with an abstract memory representa \ntion (cf. the o function of algorithm CA-O), and then implementing it in later transformations. De Roever \nin [12] presents proofs of correct\u00adness, employing (both least and greatest) fixed\u00adpoint techniques, \nof a group of bounded-workspace traversal and backtracking algorithms, including that of Deutsch Schorr-Waite, \nand focuses on the similarity in their proofs without using trans\u00ad formations (see [13] for termination \nproofs for the algorithms). It was the attempt to extend this work to some difficult list-copying algorithms \nwhich brought out the importance of using the explicitly structured techniques of the current paper. \nACKNOWLEDGEMENT S We wish to warmly thank the University of Utrecht for its generous support of the interna\u00adtional \ncollaboration involved in the writing of this paper. The Tuesday Afternoon Club, especially E. W. Dijkstra, \nprovided many valuable comments on an earlier version of this paper. Thanks also to Emmy Busch and Sandy \nfor their typing; and to Stephanie for moral support. * APPENDIX Discussion of assertions omitted for \nlack of space. Al. Alg. MA-6 SameStack(t,tp) _ empty(t)Atp=nil V [kl=tpA [(tp.atomAt2=tp.bASameStack(pop(t) \n,tp.a)) U (t2= @ ASameStack(pop(t),tp.b) )]] Mod(aptr,bptr,atombitrtp,p) =def if tp=nil then (aptr,bptr,atombit) \nelse if tp.atom then Mod((aptr-{< tp,tp.a>})U{<tp,p>~t~ (atombit-{<tp,tp.atom>})u{<tp,false>} ,tp.a,tp) \nelse Mod(aptr, (bptr-{<tp,tp.b>})U{<tp,p>} , atombit,tp.b,tp tp.b,tp) fi A2. ALCA Bijection(p,w,c) ~ \np:w+c A l~(a)=p(b)~ a=b A {y: %Gw: p(V)=y} = c where w = m,R*(Z) SpanTree(s,b,w) ~ {e2:e6s}={e2:e GsUb}=w-{Z} \nA bfls= @ Alsl=lwl -1 A I(E(m-{p})-t*)~ (s Ub)~I+(Ze) DefttStack(e,tt) ~ empty(tt) V [ttl G et A Ib(ttl)~tt2~ \nI(ttl)~et Utt2 where Is(e)= A (tt2UIIs*(tt2fls)) flet = @ I(e) fl a for A e= Is(ttl) a = s,b ~ DefttStack(ttl,pop(tt))] \n A3. Alg. RCA1 DefStackRl(p,t) Z empty(t)v[tlcm A [(t2=Z2(tl) A <tl,p>Gsl) v(t2= @ A <tl,p>cs2 A Zl(tl)=m)] \nA DefStackRl(tl,pop(t))] Invar-RCAl-B ~ jm,t,~,s,b: Invar-RCAl-A A Same-StackRCA(t,gf) where i) Ocj in \nRCA-i is replaced by Oc j, def d. by (Uc l,Oc 2)=ModRCA(Ocl,Uc2 ,gf,f) ii) SameStackRCA, ModRCA are virtually \nidentical to DSW assertions in App. Al. A4. Alg. RCA2 DefStackR2(p,tt) ~ empty(tt) V [<sinv(ttl),ttl> \nGet ~[(tt2=El(p) A <ttl,p>Gs2 net A--(tt2q et) A tt2c sl+IIs*(tt2) net=$) V(tt2= @ A <ttl,p>-~slflet \nA E2(ttl)~ et)] A DefStackR2(ttl,pop(tt))] where <sinv(ttl),ttl>Gs. A5. Robson invariants O-Eric(y) Z \n-.(y Cm ) l-Eric(y) ~ y ~ stk* A t2-of(y,stk) # @ 2-Eric(y) E y G stk* A t2-of(y,stk) = $ 3-Eric(y) = \ny Cm A-(YG stk*) , where m , stk = m-{p}, t in Pass 1 = {Z} U{e2: e~(et-{e})fls}, tt in Pass 2 and t2-of(y,stk) \n= ~ y=(top(stk))l ~ (top(stk))2 _else t2-of(y,pop(stk)) Depth-First (df#,w) E Bijection(df#,w,{j: lsj<lwl}) \nA df#(Z) = 1 A <X,y>~Sl -df#(y) = df#(x) + 1 A<x,y>es2 *df#(y) = df#(x)+\\ s*(ll(x))l+l A<x,y>Gbl *df#(y)~ \ndf#(x) A<x,y>Cb2 *df#(y)S df#(x) V y~S*(~l(X)) where w = m, R*(Z) and s*(q) is the set of nodes in the \nsubtree rooted at the node q (including q). CopyOrder ~ df#(y) >df#(p) A -(yes (p)) ~ P(E(Y)) ~SC = df#(y) \n>df#(ttl) *1.l(E(Y)) ~UC , in loops 1 and 2 respectively. REFERENCES [1] Blikle, A. Towards Mathematical \nStructured Programming, in Formal Deac~<pt<ons Of l?rogramning Concepts, E.J. Neuhold (cd.), North-Holland \nPub\u00adlishing Co., 1978. [2] Burstall, R.M. and J. Darlington. A Trans\u00adformation System for Developing \nRecursive Programs. JACM 24 (Jan. 1977), pp. 44-67. [3] Clark, D.W. A Fast Algorithm for Copying List \nStructures. CACM 21 (May 1978), PP. 351-7. . [4] Dijkstra, E.W. Finding the Correctness Proof of a Concurrent \nPrograln. Proc. Koninklijke Neder\u00adlandse Akademie van Wetenschappen, Amsterdam, A 81 (June 9, 1978), \npp. 207-15. [5] Fisher, D.A. Copying Cyclic List Structures in Linear Time Using Bounded Workspace. CAC!M \n18 (MaY 1975), PP. 251-2. [6] Gerhart, S.L. Correctness-Preserving Program Transformations. Proc. Second \nPOPL Symp., Palo Alto (1975), pp. 54-66. [7] Gerhart, S-L. Proof Theory of Partial Cor\u00ad rectness Verification \nSystems. SIAM J. Comp. ~ (Sept. 1976), pp. 355-77. [8] Gerhart, S.L. Two Proof Techniques for Trans\u00adferal \nof Program Correctness, (forthcoming) . [9] Gerhart, S.L. and L. Yelowitz. Control Struc\u00adture Abstractions \nof the Backtracking Programming Technique. Proc. Second Intl. Conf. on Software Eng., San Francisco (Oct. \n1976). [10] Knuth, D.E. The Art of Computer Programing, vol. 1: Funckvnental Algorithms, Addison-Wesley, \n1973, Section 2.3.5. [11] Robson, J.M. A Bounded Storage Algorithm for Copying Cyclic Structures. CACM \n20 (June 1977), pp. 431-3. [12] deRoever, W.P. On Backtracking and Greatest Fixedpoints, in @oc. Fourth \nInt~, Conf. O% Auto\u00admata, Languages and .Progm??imhg, A. Salomaa (cd.) , Springer-Verlag, 1977. [13] \ndeRoever, W.P. An Essay on Trees and Iter\u00adation. Report RUU-CS-78-6, Dept. of COmp. Sci., University \nof Utrecht, 1978. [14] Schorr, H. and W.M. Waite. An Efficient Machine-Independent Procedure for Garbage \nCollec\u00adtion in Various List Structures. CACM ~ (Aug. 1967), pp. 501-6. [15] Topor, R. Correctness of \nthe Schorr-Waite List Marking Algorithm. Memo M1P-R-104, School of Artificial Intelligence, Univ. of \nEdinburgh, 1974. [161 Yelowitz, L. and A.G. Duncan. Abstractions, Instantiations, and Proofs of Marking \nAlgorithms. Proc. Symp. on Artificial Intelligence and Prog. Lang., SIGPLAN 12 (Aug. 1977), pp. 13-21. \n  \n\t\t\t", "proc_id": "567752", "abstract": "How can one organize the understanding of complex algorithms? People have been thinking about this issue at least since Euclid first tried to explain his innovative greatest common divisor algorithm to his colleagues, but for current research into verifying state-of-the-art programs, some precise answers to the question are needed. Over the past decade the various verification methods which have been introduced (inductive assertions, structural induction, least-fixedpoint semantics, etc.) have established many <i>basic principles</i> of program verification (which we define as: establishing that a program text satisfies a given pair of input-output specifications). However, it is no coincidence that most published examples of the application of these methods have dealt with \"toy programs\" of carefully considered simplicity.Experience indicates that these \"first generation\" principles, with which one can easily verify a three-line greatest common divisor algorithm, do not directly enable one to verify a 10,000 line operating system (or even a 50 line list-processing algorithm) in complete detail. To verify complex programs, additional techniques of organization, analysis and manipulation are required. (That a similar situation exists in the <i>writing</i> of large, correct programs has long been recognized -- structured programming being one solution.)This paper examines the usefulness of correctness-preserving program transformations (see [6]) in structuring fairly complex correctness proofs. Using our approach one starts with a simple, high-level (or \"abstract\") algorithm which can be easily verified, then successively refines it by implementing the abstractions of the initial algorithm to obtain various final, detailed algorithms. In Section 2 we introduce the technique by deriving the Deutsch-Schorr-Waite list-marking algorithm [14]. Our main example is the more complex problem of verifying bounded-workspace list-copying algorithms: Section 3 defines the issues, Section 4 presents the key intermediate algorithm in detail and Section 5 considers three of the most complex (published) implementations of list-copying, one of which is discussed in detail. In Section 6 we make some general remarks on program verification and the relevance of our results to the (larger) field of program correctness; Section 7 mentions some related work.", "authors": [{"name": "Stanley Lee", "author_profile_id": "81545138356", "affiliation": "University of California, Berkeley CA", "person_id": "PP45025644", "email_address": "", "orcid_id": ""}, {"name": "Willem P. deRoever", "author_profile_id": "81100003125", "affiliation": "University of California, Berkeley CA and Univ. of Utrecht, Budapestlaan 8, Postbus 80-012, 3508TA Utrecht, The Netherlands", "person_id": "P383280", "email_address": "", "orcid_id": ""}, {"name": "Susan L. Gerhart", "author_profile_id": "81100085035", "affiliation": "USC/Information Sciences Inst., Marina del Rey CA", "person_id": "P325980", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567752.567758", "year": "1979", "article_id": "567758", "conference": "POPL", "title": "The evolution of list-copying algorithms and the need for structured program verification", "url": "http://dl.acm.org/citation.cfm?id=567758"}