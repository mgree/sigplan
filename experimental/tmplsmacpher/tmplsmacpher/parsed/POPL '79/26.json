{"article_publication_date": "01-01-1979", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1979 ACM 0-12345-678-9 $5.00 CERTIFYING INFORMATION FLOW PROPERTIES OF PROGRAMS: AN AXIOMATIC APPROACH \n Richard P. Reitman Syracuse University Gregory R. Andrews Cornell University Abstract Interesting program \nproperties other than func\u00adtional correctness can be addressed and proved using axiomatic logic. An information \nflow logic that de\u00adfines the flow semantics of a parallel programming language is presented. Proofs in \nthis logic can be used to certify programs with respect to information security policies. The flow logic \ncan also be com\u00ad bined with correctness logics to form an even more powerful deductive system. Keywords \nand Phrases: information flow, computer security, policy certification, program validation, proof rules, \nconcurrency, synchronization. CR categories: 4.32, 4.35, 5.21, 5.24. 1.0 Introduction The importance \nof certifying the security of programs, especially operating systems and data bases, has long been recognized. \nTo solve the prob\u00adlem, three topics must be addressed. First, direct access to objects must be controlled \nso that a pro\u00adgram takes only authorized actions. Second, the flow of information between objects must \nbe con\u00ad trolled so that a program cannot acquire private in\u00ad formation even if it takes valid actions. \nThird, the functional correctness of critical system al\u00ad gorithms, such as those identifying users or \nmanipu\u00ad lating file directories, must be proved so that a program cannot circumvent the access and informa\u00ad \ntion control mechanisms. This paper examines the information flow prob\u00adlem. We first present a model \nof information, dis\u00adcuss what it means for a program to be secure with respect to an information policy, \nand consider pos\u00adsible methods for certifying information policy security. We then present a new approach \nto certi\u00adfication that utilizes a program flow proof con\u00adstructed by applying flow axioms. =ewlting method \nis powerful enough to prove flow properties of programs containing arrays, procedures, classes, processes, \nand monitors as well as the usual assign\u00adment and control statements. In the remainder of the paper we \npresent our axiomatic logic for reason\u00ading about information flow, illustrate its use for This research \nwas supported by NSF grant MCS 77\u00ad 07554. certifying information security, and examine its relation to \naxiomatic logics for program correct\u00ad ness.  2.0 Certifying Information Flow Policies Our focus is on \ninformation flow in programs, specifically parallel programs. Our goal is to cer\u00adtify a given program \nwith respect to a given infor\u00admation policy. In terms of information flow, a program consists of three \ncomponents: (1) variables that contain information, (2) an information state consisting of the current \nclassification (i.e. degree of sensitivity) of each variable, and (3) statements that modify the variables \nand hence alter the state.  A policy specifies the acceptable classifications of va-s, that is, the \nset of acceptable states. Certification is the problem of ensuring that a given program adheres to a \ngiven policy, namely that all modifications to the state are acceptable. To characterize the sensitivity \nof information, we assume, as do others [4,5,10], that each variable has a classification. We further \nassume that the set of security classes is finite, partially ordered (by ~), has a least element (low), \nand has a least upper bound operator (~). A particularly useful classification scheme, which is used \nin the remain\u00ad der of the paper, is the powerset of variable classes. In this scheme, each variable having \nan initial value is assigned a unique class, constants are assigned class low, @ is set union, and < \nis set containment. If v is a variable, we use v to denote the class of v. If E is an expression; the \nclass of the expression, ~, is by definition the least upper bound of the class of each element in the \nexpression. TO certify a program, we must first specify our security policy and then ensure that the \nprogram ad\u00adheres to the policy. A natural and useful way to specify an information policy is as an assertion \nabout acceptable variable classifications, namely as an assertion describing acceptable information states. \nIn practice policies are of the form {v < C}, which indicates that the classification of t~e information \ncontained in v may not exceed C. In this context, s is the partial ordering operator on security classes \nand C is a specific classification, such as top secret. TWO types of policies, final value and high-water \nmark, are of particular interest. A final value policy is an assertion that must be true when a program \nterminates. A high-water mark policy is an assertion that must be true at each stage of program execution \n(it is invariant through\u00adout the program). A program can be certified in one of two ways: (1) by monitoring \nits execution at run-time, or (2) by validating its specification at compile\u00adtime. Run-time mechanisms \ncheck all accesses to in\u00adformation to ensure that a given security policy is not violated. Specific mechanisms \nhave been pro\u00adposed by Denning [4], Fenton [6], Gat [7] and Jones and Lipton [8]. Although each proposal \nis suffi\u00adciently powerful to solve a variety of problems, all run-time mechanisms have several serious \ndrawbacks. First, since violations are not deleted until a pro\u00adgram executes, partial program execution \nresulting in inconsistent files or data bases may occur. Second, time and space requirements are increased \nby introducing security checks. Finally, diagnostic information concerning the cause of the violation \nis often minimal because the diagnostic itself may transmit sensitive information.  Compile time certification \nmechanisms do not suffer these drawbacks since they allow programs to be validated prior to execution. \nIf object classi\u00adfications are static, validation consists of ensur\u00ading that any information stored into \nan object is consistent with (i.e., no greater than) the object s classification. Andrews [1], Jones \n[8] and Millen [11] describe various ways to validate a,program as long as any object that is altered \nis at least as classified as every object that is read. Denning and Denning [5] have generalized these \napproaches by devising a technique that examines the flow of control of statements in order to determine \nthe specific subset of examined objects that could af\u00adfect each altered object. The basic problem with \neach of these domain restriction approaches is that they are too restrictive if the classifications of \nobjects can change, for example, when a file is erased and hence declassified or when a sort pro\u00adgram \nis applied to different classes of input. When the classification of objects is permit\u00adted to vary dynamically, \nsecurity validation re\u00adquires reasoning about the information state trans\u00adformations produced by executing \na program. Cohen [3] has used an information theoretic approach to develop a formal system for reasoning \nabout infor\u00admation transmission in sequential programs; how one could use his method in practice is an \nopen ques\u00adtion. In London [10], the techniques of data flow analysis are applied to sequential programs \nto pro\u00adduce, for every object, an upper bound on the set of inputs that could transmit information to \nit. Cohen s approach has not been applied to parallel programs and London was not successful in dealing \nwith parallel programs. Since information security is of greatest interest in parallel systems such as \ndata bases and operating systems, a more powerful technique is required. In the remainder of the paper, \nwe present and analyze a new method for program validation that utilizes flow proofs constructed by applying \ninfor\u00admation flow axioms. The advantages of this approach are that it is applicable to parallel as well \nas sequential programs, that it is of use with dynamic as well as static classifications, that it allows \none to certify a program with respect to a variety of flow policies, and that it captures flows aris\u00ading \nfrom failure to terminate. In addition, it combines readily with correctness proofs to yield a powerful \nsystem for reasoning about information flow. The flow proof method has in fact been used to certify a \nfairly large (6 page) Concurrent Pascal program [14].  3.0 Flow Proofs A flow proof specifies a program \ns effect on the information state; it is derived by applying flow axioms. These axioms capture the information \n~=ics of program statements in the same way that correctness axioms capture the effect of program statements \non the values of variables. We use logical assertions about the classification of variables to describe \na set of possible information states. If P and Q are assertions about variable classifications and S \nis a program statement, the notation {P} S {Q} denotes that if the information state satisfies P prior \nto the execution of S, then the information state will satisfy Q after the execution of S, pro\u00advided \nthat S terminates. 3.1 Flow in Sequential Programs Assume for now that we have a simple language with \nthe following three kinds of statements: (1) assignment x:= E (2) alternation if B then S else S l \n 2 (3) iteration while B do S  The information contained in variables can only be changed as a result \nof an assignment statement. Information flows to the assigned variable in two ways. First, there is always \na direct flow from the assigned expression E. Second, information may be transmitted indirectly by virtue \nof the fact that the statement x:= E was executed conditionally. For example, the statement if x = Othen \ny:= Oelse y:= 1 sets y to O if and only if x = O. In the assign\u00adment y:= O, y receives a direct flow \nfrom O and an indirect flow from the guard (Boolean expression) x = O since the execution of y:= O is \nconditional on the value of x. Indirect flows are also produced by iteration statements. Since the body \nof a while loop is exe\u00adcuted only if the guard (Boolean expression) B is true, there is an indirect transmission \nof informa\u00adtion from B to any variable modified within the body S. In addition, since there may be statements \nthat are executed only if the loop terminates, there is a potential flow of information from the guard \nto all subsequently executed statements. For example, in the program segment y:= 1; while x # O do skip \n; y:.0 one can deduce information about x by examining y. If the loop terminates, x and y are both zero; \nif the loop fails to terminate, y is 1 which indicates that x is not O. When the effect of conditional \nexecution is con\u00adfined to the body of a statement, we say that the in\u00addirect flow is local. When conditional \nexecution af\u00adfects all subsequent statements, as is the case with iteration, we say that the flow is \nglobal. To re\u00adpresent these flows in assertions about the informa\u00adtion state we use the auxiliary variables \nlocal and global. The flow axiom for an assignment statement x:= E must capture both direct flows from \nE to x and the local and global flows to x. Let P be an asser\u00adtion that is to be true after executing \nx:= E, then the flow axiom for assignment is: {P[~+&#38; @ local @ global]] x:= E [P} where the pre-condition \nis P with E @ local @ global syntactically substituted f~r x. If the variable assigned is an array element \nA[i], an additional flow of information occurs. After the assignment statement A[i]:= E, the value of \ni may be ascertained by searching the array A for the value E. In addition, since in our logic we can\u00adnot \ndistinguish between different array elements, the classification of an array cannot be decreased by the \nmodification of one of its elements. Accordingly, we propose the following axiom for assignment to an \nar\u00adray element: {P[~+&#38; @ ~ @ ~ @ local @ global]} A[i]:= E {P} The alternation statement produces \nan indirect flow from the guard B to both S1 and S2. Consequent\u00ad ly, any local flow present at the start \nof the alter\u00adnation statement (as a result of statement nesting) is temporarily increased by B. Let V \nbe an assertion about the classes of program variables only, let L and L! be assertions about auxiliary \nvariable local, and let G and Gt be assertions about auxiliary vari\u00ad able global. Then the axiom for \nalternation is: {v,L ,GI sl {v ,L ,G }, {V,LI,G} s2 {v ,L ,G }, V,L,G ~L [local + local @ ~] {V,L,G} \nif B then S1 else S2 {V ,L,G ] where the comma in assertions means conjunction. If the local flow initially \nsatisfies L, and L after substituting local @ B for local can be derived from the initial state, then \nwithin S1 and S2, L is a valid constraint on the local flow. As a result of executing S1 and S2, V may \nchange to V and G may change to G ; but after the alternation statement, the local flow once again satisfies \nL. The effect of the iteration statement is to cause both a local flow into the body S and a global \nflow to subsequent statements. To capture the inde\u00adfinite repetition of the while loop, we also need \nan assertion, called the invariant, that is true before and after executing S. Using the same notation \nas above, the axiom for iteration is therefore: {v,L ,G} s {v,L ,GI, V,L,G ~L [local + local @ ~], V,L,G \n~G [global + global @ local @ ~] {v,L,G} while B do s {V,L,G ] Note that V and L are unchanged by iteration \nand that G is derived from V, L, and G; because of the properties of @, G never decreases. In addition \nto the above three statements, we also need to allow statement composition (begin S \u00ad 1 . . ..Sn ~) and \nto have an axiom capturing its ef\u00ad feet. It is also necessary to have a rule of conse\u00ad quence for assertions. \nThese two additional rules, as well as the above three, are summarized in Figure 1. They are both analogous \nto the correspond\u00ad ing rules for correctness proofs. 3,2 Flow in Parallel Programs In sequential programs, \ninformation is trans\u00admitted either directly through assignment or indi\u00adrectly as a result of conditional \nexecution. The same types of flow arise in parallel programs; how\u00adever, they are more subtle because \nof simultaneous execution and synchronization. Let us add the fol\u00adlowing statements to our simple sequential \nlanguage: (1) parallel execution cobegin Sll I..llSn coend (2) semaphore wait wait (S) (3) semaphore \nsignal signal (S).  Owicki and Gries [12] have shown that executing pro\u00ad cesses in parallel is the same \nas executing them sequentially provided that their proofs are inter\u00ad ference-free. The same notation \napplies to the flow of information in parallel processes: as long as the flow proofs of two processes \ndo not interfere, the flows into variables are the same as if each process were executed sequentially. \nThe flow proofs of two processes are interfer\u00adence-free if no statement within one process invali\u00addates \nan assertion about the information state of the variables within the other processes (the local and global \nflows within one process are independent of those within any other). Accordingly, we propose the following \ndefinitions: (1) Givena flow proof {V,L,G} S {v ,L,G } and a statement T with pre-condition pre(T), \nT does not interfere with the proof if: (a) {V .~re[T)} T {V } and (bj For-~ny-statement within S with \nprecondi\u00adtion {U,L,G}, {U,pre(T)} T {u). (2) Let Tbe a statement within Si. The flow proofs {Pl] S1 {Ql} \n,.. .,{pn] in {Qn] are inter\u00ad ference-free if for all j, j # i, T does not interfere with {Pj] Sj {Qj]. \nAssignment [P[x+E@ local @ global]} x:= E {P] {P[~+~@ ~ @ ~ @ local @ global]} A[i]:= E {P] Alternation \n{v,L G} sl {V ,L ,G }, {v,L ,GI s2 {V ,L ,G }, V,L,G ~L [local + local @ ~] {V,L,G] if B then S1 else \nS2 {V ,L,G } Iteration [v,L ,G} s {v,L ,G}, V,L,G ~L [local + local @ ~], V,L,G ~G [global +-global \n@ local @ ~] {v,L,G} while B do s {v,L,G I Composition {P} S1 {Pi},...,{pl}l} Sn{Q} {P} begin S1; ..,;SI, \nend {Q} Consequence {P } S {Q }, p ~P ,Q ~Q {P} S {Q} Concurrent Execution {Vi,L,G] Si{V~>L>G }> are \ninterference-free lSiSN {VIA. ..AVN ,L,G] cobegin S1\\\\. ..l\\SN coend {V;A...AV~jL,Gr} Semaphores {P [~+: \n@ {P [S + s @ glob~l + ~ @ local local local @ @ @ global]] global, global]] signal(S) wait(S) {P} {P} \n As long as a set of processes are interference\u00adfree, their combined effect on the variable state is \nthe conjunction of their individual effects. Since a cobegin statement terminates only if each of its \nconstituent processes terminates, the global flow caused by a cobegin is at least as great as that caused \nby each process. Accordingly, we propose the following flow proof rule for cobegin: {Vi,L,G} si {Vj,L,G \n}, l<i<N are interference-free ,$ {Vl ,...,VN,L,G} cobegin S1 1I . . . I ISN coend {V; ,.. .,V~,L,} } \nAs with other statements, the local flow after cobe\u00adgin is the same as that before. A semaphore S is \na non-negative integer acces\u00ad sible only via the wait and signal operations. The effect of the signal \noperation is to increase the value of S by 1 (S:= S + 1). Although no additional information in a process \nexecuting signal(S) flows directly into S, information can flow indirectly as a result of conditional \nexecution, specifically from the auxiliary variables local and global of the exe\u00adcuting process. The \naxiom for signal(S) is there\u00adfore similar to that for assignment: {P[~+~ @ local @ global]} signal(S) \n{P} The wait(S) operation decrements the value of S by 1, when it is positive. If S is not positive, \nhowever, the process executing wait(S) may be de\u00adlayed. The decrement produces a flow of information \nsimilar to that in the assignment S:= S -1. The possible delay results in a potential increase in the \nglobal flow of the process executing wait(S) be\u00adcause the execution of subsequent statements depends \non another process executing signal(S). These con\u00ad siderations result in the fol= axiom for wait: {P[~+~ \n@ local @ global, wait(S) {P}. global i-~ @ local @ global]} These three rules for parallel execution \nand sema\u00adphore synchronization are summarized in Figure 1. 3.3 An Example To illustrate how information \ncan flow indirect\u00adly from one process to another as a result of syn\u00adchronization, consider the following \nprogram frag\u00adment: var S: semaphore initial (0); cobegin processl: begin var i,x:integer; read into x; \ni:= O; while i <xdo begin signal(S); i:= i+l end end II process2: begin var j:integer; j:= 0; while true \ndo begin wait(S); j:= j+l end end coend This program transmits the value of x (if x z O) from processl \nto variable j in process2 by using semaphore S as a counter. This occurs since (1) the execution of signal(S) \nin processl is condi\u00ad tional on i s x, and (2) the execution of j:= j+l in process2 is conditional on \ntermination of wait(S). The flow in the above program is typical of the types of flow that can occur \nas a result of iteration and synchronization. To capture the pro\u00adgram s effect, we can construct a flow \nproof using our flow axioms. An outline of a proof is shown in Figure 2. The proof shows that if x s \nC for some classification C, then j S C. Note that the class of S cannot be bounded ~y any class less \nthan C if one is to construct interference-free proofs for processl and process2. Note also that the \nproof is valid even though process2 deadlocks after processl terminates; if j can be examined, information \nabout x can be determined. 3.4 Other Flow Axioms Although not illustrated here, we have also developed \nflow axioms for other, more powerful pro\u00ad gram statements, including all those in Concurrent Pascal . \nIn particular, rules for arrays, procedures, other types of iteration, mess?ge passing, critical regions, \nclasses, and monitors are developed and illustrated in [2,14]. AS with the above axioms, they are similar \nto the corresponding rules for correctness proofs. The main concepts needed for all of the rules are \nthe classification scheme and the auxiliary variables local and global: In fact, capturing the effect \nof -y lndlrect flows within local and global is the key to fairly simple axioms and the ability to axiomatize \nflows resulting from iteration and synchronization. 4.0 CertifYintz ProErams Recall that an information \npolicy is an asser\u00adtion that indicates the acceptable information clas\u00adsifications of variables. Two \ntypes of policies are commonly used. A final value policy is an assertion that must be true when a program \nterminates; it cor\u00adresponds to a correctness assertion stating the de\u00ad sired post-condition of a program. \nA high-water mark policy is an assertion that must be true at every stage of a program; it is used when \nintermedi\u00adate results must be secure, for example when a pro\u00adgram is executed interactively or may not \nterminate. Given a flow proof and a policy P, a program can be readily certified. First, every point \nin the program where the policy must hold is identified. Second, for every assertion A that is valid \nat the points in the program identified in the first step, one must prove A ~ P. For example, the program \nand proof shown in Figure 2 can be certified with re\u00ad spect to the high-water mark policy [j s but X] \nnot with respect to the policy {j = low}. Note that a flow proof is useful only if it allows a program \nto be certified. Just as proofs of correctness should be guided by the correctness assertion, proofs \nof flow should be guided by the policy. This mechanism for validating programs by using flow proofs is \nmore general than the domain restric\u00adtion approaches alluded to in Section 2. It cap\u00adtures flows more \naccurately than either the static approach of Denning and Denning [5] or the dynamic approach of London \n[10], since these approaches dis\u00adregard the possibility of global flows. Since flow proofs are independent \nof.policies, a given proof may be utilized in the certification of several pol\u00adicies. In addition, this \ntechnique is applicable to a much wider range of computer programs, including those containing parallel \nexecution and process syn\u00adchronization. 5.0 Flow Proofs and Correctness Proofs We have developed an \naxiomatic logic for infor\u00admation flow that is similar to, and was in fact mo\u00adtivated by, an axiomatic \nlogic for correctness. This leads one to wonder to what extent the flow and correctness logics differ. \nTo certify a program, one must prove that variables are related only in ways authorized by a given flow \npolicy. Since a flow proof places an upper bound on the flows in a program, it can be used readily for \ncertification. If the proof cannot be used to certify the program, one then tries to find a stronger \nproof that can be. A FLOW PROOF OUTLINE var S: semaphore initial (0); {S s low, local s low, global \ns low} 1\u00ad{~< C, local s low, global s low} cobegin processl: begin var i,x: integer; read information \nof class s C into x; i:= O; {S <C, ~<C, i <low, local <low, global < low] ~ {S <C, ~<C, i <C, local <low, \nglobal< low] . while i 5xdo {S sC, x<C, i sC, local SC, global slow} begin signal(S); i:= i+l {S SC, \nx<C, i sC, local SC, global Slow} . end {S SC, xSC, i SC, local slow, global <C} II process2: begin \nvar j : nteger; j:=() {s <c, ~ = low, local = low, global = low} \\ {;< c, ~< C, local = low, global \n< Cl while true do . {S sC, j <C, local Slow, global <C} begin wait(S); j:= j+l {S s C, j s C, local \ns low, global sC} end {S sC, j sC, local ~low, global sC} . end coend {Es C, local s low, global s \nC) By contrast, in a correctness proof one normally {(X> O=>Y=l)A(XSO=> y=-l)}inaproofof proceeds in \nthe other direction, that is, one is the above statement. Even so, this does not tell us normally interested \nonly in those relations between what we really want to know, namely that the class variables that aid \nin proving the correctness as-of y is the same as the class of x, regardless of sertion. In order to \nuse a correctness proof for their values. certification, however, one must capture all rela\u00adtions between \nvariables that could affect certifica-In parallel programs, there are additional dif\u00adtion. This requires \nthat the correctness proof make ficulties in using correctness logics for security the strongest possible \nassertion about the program certification. Many parallel programs, such as state. Specifically, given \na pre-condition and those found in operating systems, provide continu\u00adstatement, the strongest possible \npost-condition ous serv ice and are not intended to terminate; must be derived (a problem that is not \nsolvable in others may willingly run the risk of deadlock to in\u00adgeneral). For example, suppose we have \nthe state-crease efficiency. The possibility of non-termina\u00adment tion and deadlock limit the utility \nof correctness techniques in certifying information security since if x > 0 then y:= 1 else y:= -1. correctness \nassertions cannot explicitly indicate the occurrence of global flows. In order to capture the fact that \nx and y are re\u00adlated, namely that they tell us something about each Although we feel that flow proofs \nare a viable, other, we must use a post-condition such as attractive way to reason about information \nflow, they do have weaknesses. First, a flow proof cap-To illustrate how the combined logic allows one \ntures all the flows in a program, even those that do to prove a stronger assertion than is possible using \nnot occur because of conditional statement execution the flow logic alone, consider the following program \n(e.g., alternation statements that always choose one that zeros an array: alternative or loops that always \nterminate). Second, flow proofs cannot differentiate different array i:= O; elements in general because \nthe element referred to while i <n do by A[i] depends on the value of i whereas a flow . proof only \ndeals with the class of i. However, we begin i:= i+l; can overcome these difficu~ by using a combined \nA[i]:= Oproof system that allows assertions about both class and values. end The state in the combined \nsystem is the cross-Given that n s low, a desirable final-value policy product of the information state \nand program state. for this pr~gram is {Vi(l s i Sn=>A[i] s low)}, The rules for sequential statements \nin the combined that is, the sub-secti~n A[l], . . ..A[n] of the arraysystem are summarized in Figure \n3. Combined proof A has been declassified. rules for parallel programming statements are simi\u00adlar; they \neach have a value part and a classifica\u00adtion part. Figure 3 COMBINED PROOF RULES simple assignment {P[x+e, \n~+~ @ local @ global]} x:= e {P} array assignment* {P[A[i] + e, A[i] -+~ @ > @ local @ global]] A[i]:= \ne {P} alternation {v A B,L ,G] S1 {v ,L, ,G }, [V A -B, L ,G] S2 {V ,L ,G }, V,L,G ~L [local + local \n@ B] iteration {VA B,L ,G} S {V,L ,G}, V,L,G ~L [local + local @ ~], V,L,G ~G [global + global @ local \n@ ~] _ _ {V,L,G} while B do S{V A =B,L,G } composition {P} S1 {P1},{P1} S2 {P2}, . . ..{P1}1} SN{Q] {P} \nbegin S1;S2; . . ..SNe@ {Q} consequence {p ] S{Q }, P 1P , Qt ~Q {P} S [Q] * For simplicity, we assume \nthat the subscript expression i does not refer to A. A PROOF USING THE COMBINED LOGIC Let I ~j(l Sj Si \n=>A[j] Slow) Ai Slow An< low An SOA i ~n, local slow, global slow {n 2 0 A n s low, local s low, global \n< low} i:= O; {i=f)A~<lowAn>l)A ~SIOW, lOCalSIOW, global < low} ~ {I} while i <n begin {1 Ai <n] i:= \ni+l; A[i]:= O {1} end {IAi2n}F{IAi=n]t-{V,(lsj Sn=>~s low] J The above program can be certified using \nthe 5. Denning, D.E. and Denning, P.J. Certification combined logic by showing that the assertion of \nprograms for secure information flow. Comm. ACM 20, 7(July 1977), 504-513. {Vj(l~j ~i=>A[j]~ low) Ai~lowAiSnA \nn < low, local s low, global s low} 6. Fenton, Journal J.S. Memoryless 17, 2(May 1974), subsystems. \n143-147. Computer is of in to a valid loop invariant. An outline of the proof this program using the \ncombined logic is given Figure 4. Note that the actual value assigned A[i] in the loop is unimportant \nas long as its 7. Gat, I. Security aspects Ph.D. Thesis, Technion-Israel Technology, June 1973. of computer \nInstitute systems. of classification is low. 8. Jones, A.K. Protection in programmed systems. Ph.D. Thesis, \nCarnegie-Mellon University, 6.0 Summary June 1973. Starting have considered tion policies for developing \nfrom a model of information flow, we the problem of certifying informa\u00adand have presented an axiomatic \nlogic flow proofs and certifying programs. 9. Jones, A.K. and Lipton, of security policies for ings Fifth \nSymposium on ciples (Nov. 1975).-. R.J. The enforcement computation. Proceed-Operating System Prin- When \ncombined with correctness a powerful, useful means for validating information flow logics, reasoning \nproperties this yields about and of programs, 10. London, T.B. Ph.D. Thesis, The semantics of Cornell \nUniversity, information January flow. 1977. including parallel cently addressed means of axiomatic programs. \nSince the access control proof techniques others problem [11,13], have by all re\u00ad 11. Millen, practice. \nJ.K. Security Comm. ACM kernel validation 19, 5(May 1976), in 243-250. three aspects of the security \nproblem (access con\u00adtrol, information flow, functional correctness) can be addressed in the same way. \nThis should increase the likelihood that we see significant progress on 12. Owicki, S. and Gries, D. \nAn axiomatic proof technique for parallel programs I. Acts Infor\u00ad matica 6(1976), 319-340. the entire \nsecurity problem. 13, Popek, G.J. and Farber, D.A. A model for veri- Bibliomavhv fication Comm. of data \nsecurity in ACM 21, 9(Sept. 1978), operating 737-749. systems. 1. Andrews, computer Washington, G.R. \nCOPS--a protection systems. Ph.D. Thesis, July 1974. mechanism University for of 14, Reitman, R.P. Proving \nsecure an axiomatic approach. Ph.D. Univesrity, August 1978. information flow: Thesis, Cornell 2. Andrews, \nG.R. and Reitman, R.P. An axiomatic approach to information flow in parallel pro. grams. Department of \nComputer Science, Cornell University, November 1978. 3. Cohen, E. Information transmission in computa\u00ad \ntional systems. Proceedings of Sixth Symposium on Operating Systems Principles (Nov. 1977), 133-139. \n 4. Denning, D.E. A lattice model of secure infor\u00admation flow. Comm. ACM 19, 5(May 1976), 236\u00ad 243. \n \n\t\t\t", "proc_id": "567752", "abstract": "Interesting program properties other than functional correctness can be addressed and proved using axiomatic logic. An information flow logic that defines the flow semantics of a parallel programming language is presented. Proofs in this logic can be used to certify programs with respect to information security policies. The flow logic can also be combined with correctness logics to form an even more powerful deductive system.", "authors": [{"name": "Richard P. Reitman", "author_profile_id": "81332522919", "affiliation": "Syracuse University", "person_id": "PP42052501", "email_address": "", "orcid_id": ""}, {"name": "Gregory R. Andrews", "author_profile_id": "81100029241", "affiliation": "Cornell University", "person_id": "PP14022985", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567752.567779", "year": "1979", "article_id": "567779", "conference": "POPL", "title": "Certifying information flow properties of programs: an axiomatic approach", "url": "http://dl.acm.org/citation.cfm?id=567779"}