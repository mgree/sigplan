{"article_publication_date": "01-01-1979", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1979 ACM 0-12345-678-9 $5.00 PRINCIPLES OF PROVING,CONCURRENT PROGRAMS IN GYPSY Donald I. Good Richard \nM. Cohen James Keeton-Williams CERTIFIABLE MINICOMPUTER PROJECT Institute for Computing Science and Computer \nApplications The University of Texas at Austin Austin, Texas 78712 ABSTRACT Concurrency in Gypsy is based \non s unique, formal approach to specifying and proving systems of concur~ent processes. The specification \nand proof methods are+designed so that proofs of individual processes are totally independent, even when \noperating concurrently. These methods can be applied both to terminating and non-terminating processes, \nand the proof methods are well suited to automated verification aid.$. The basic principles of these \nmethods and their interaction with the design of Gypsy are described. Keywords: program verification, \nprogram proving, concurrency, parallel programs, formal specifications, message buffers. CR Categories: \n4.2o, 4.22, 5.24 1.0 INTRODUCTION The primary objective of Gypsy is to provide an effective, practical \nlanguage for developing operational software systems substantial size (1000 -2000 lines ofcod$ that are \nformally verified. This goal has been attained by developing GYPSY [Good, 781 from Pascal [Jensen, 74] \nin parallel with an integrated set of formal specification and verification methods. Both programs and \ntheir formal specifications are expressed directly in Gypsy, and methods for specifying, implementing, \nand verifying systems of concurrent processes have been a major part of this development. Gypsy has been \nused successfully in two major experimental applications involving significant amounts of concurrency. \n[Wells, 76] describes a complete message switching network of 16 concurrent processes involving a total \nof approximately 1500 lines of specifications and 1000 l@es of code. [Horn, 77] gives a 900 line specification \nof a system of processes that will be used experimentally in conjunction with the ARPANET. In both aP@ications, \nall parts of the systems involving concurrency were formally verified. These verifications have contributed \nStrongly to attaining high quality system design. Methods for specifying, implementing, and verifying \nsystems of concurrent processes in Gypsy have attained several important objectives that are necessary \nfor verifying sizeable, real systems: 1. A general method for specifying systems of concurrent processes \nhas been developed. Such formal specifications are an absolute prerequisite for formal Verification, \n 2. Systems of concurrent processes can be refined into well defined subsystems so that the proofs of \nthe system and each of its subsystems are mutually independent. This mechanism for operational abstraction \nis necessary for decomposing the proof of a large system into tractable subproofs. 3. Nonterminating \nprocesses can be  formally specified and proved. Nonterminating processes commonly occur in real systems. \n 4. Effective algorithms for mechanically constructing all of the necessary verification conditions have \nbeen defined. Automatic verification condition generation is a practical necessity for all except very \nsmall programs. The first three ~bje~ti~es are significant advances toward proving systems of concurrent \nprocesses. The methods used to attain these objectives in Gypsy have several distinctive characteristics: \n1. process coordination is done strictly through message buffers. 2. Formal specifications are stated \nin terms of buffer transaction histories. 3. Buffer operation restrictions are used to simplify the \nspecifications and proofs. 4. The cobegin statement that supports concurrent execution is highly disciplined \nand well structured.  The following sections describe the basic principles of proving systems of concurrent \nprocesses in Gypsy . Major concepts are introduced one at a time. We first describe the formal specification \nmethods for concurrent processes, and then define the Independence Principlett that has been maintained \nbetween specifications and implementations of routines throughout Gypsy to provide independent provability \nof routines. We then describe proof methods for the various Gypsy program statements involving message \nbuffers and concurrency. Next we turn our attention to the special problem of specifying and proving \nnon-terminating processes. Finally, these methods are compared with other related work. 2.0 SPECIFICATIONS \nTextually, Gypsy has the appearance of a Pascal-like programming language with embedded formal specification \nfacilities. These specification facilities are incorporated into the language so that they provide the \nnecessary bases for program proofs and so that Gypsy can be used strictly as a formal specification language \nif desired. We shall not attempt to provide a complete description of the Gypsy specification language, \nbut rather we shall concentrate primarily on specifications for routines (procedures and functions) because \nof their direct relation to concurrency. 2.1 External And Internal Specifications The specifications \nfor a routine may be either external or internal. External specifications are potentially visible to \ncallers of the routine; internal ones are not. External specification of routines consist of two parts: \na required interface specification and an optional functional specification. The interface specification \ndefines the interface between the routine and its caller. It consists of the routine header which defines \nthe name of the routine and its formal parameters. The only non-local data objects to which a Gypsy routine \nmay refer are formal parameters and globally defined constanta. Therefore, the formal parameter list \ngives a complete description of the interface between the routine and its calling environment. Functional \n.gpecifications are stated as entry and exit assertions that are interpreted as weak pre-and post-conditions \nfor the routine. Essentially, functional specifications are boolean expressions that may refer OnlY \nto global constants or formal parameters in the interface specification. For example, the external specifications \nof a simple producerlconsumer procedure that moves objects from one sequence to another might be written \nas: procedure PRO_CON(var R: OBJ_SEQ; S: OBJ_SEQ) = begin exit R.S; end; type OBJ_SEQ . sequence(MAXSIZE)of \nobject; const MAXSIZE . 100; type OBJECT = .... The interface specification of procedure PRO_CON is \nthe header: which precedes the = sign, and the functional specification is defined by the exit specification. \nThe pre-condition true is assumed if no explicit entry specification is given. (Note: In Gypsy, unit \ndeclarations (procedures, functions, types, constants] may be given in any order.) Internal specifications \nare specifications describing the internal operation of a routine. The most common form is the assert \nspecification, typically used in inductive assertion proofs. Because these specifications may refer to \nlocal variables and therefore, might reveal information about a particular implementation of a routine, \nGypsy does not permit them to be visible outside the routine in which they appear. This is consistent \nwith the conventional use of inductive assertions.  2.2 Message Buffers Message buffers are the sole \nprocess coordination mechanism used in Gypsy. The address space of each active process in a Gypsy program \nis disjoint from the address space of every other active process. All inter-process communication is \nvia message buffers. Buffers may be declared locally or passed as parameters. Any number of procedures \nmay share access to a buffer created in a common ancestor and passed downward in the calling structure \nvia parameter passage. A process can communicate with another concurrently active process only through \na common buffer passed as an actual parameter when the processes were created. Buffers are a predefine \nstructure in Gypsy and closely resemble those defined in [Brinch Hansen, 73]. A typical buffer declaration \nis type OBJ_BUF = buffer(MAXSIZE)of object; Buffers are strictly first-in, first-out queues upon which \nlanguage-defined send and receive operations are mutually excluded in time. A buffer may be declared \nto have a maximal number of elements (as was done with MAXSIZE in the preceding example). If a routine \nattempts to 2.3 Buffer Histories send to (receive from) a full (empty) buffer, it TimedAllFrom(B) = TimedInFrom(B,MYID) \nis blocked until some element is received from TimedAllTo(B) = TimedOutTo(B,mID) (sent to) the buffer. \nAllFrom(B) = InFrom(B,FffID) AllTo(B) = OutTo(B,MYID)  Since all process communication must be done \nvia message buffers, the complete history of process interactions can be analyzed by examining the histories \nof message traffic among processes. Every buffer B has two predefine history sequences. TimedInFrom(B,A) \nis a time stamped ~!local input history that records the sequence of all objects received from buffer \nB by a procedure activation A; similarly, TimedOutTo(B,A) is a time stamped local output history that \nrecords all objects sent to buffer B by procedure activation A. A stamped history for a buffer of type \nOBJ_BUF, as defined above, is an object of type timed_stamped_history = sequence of transaction; type \ntransaction = record (message: object; time: integer); Whenever an object X is received from (sent to) \na buffer B by procedure activation A, a new transaction is recorded on the TimedInFrom(B,A) (TimedOutTo(B,A)) \nhistory. The transaction that is recorded has X as its message field and T# as its time field, where \nT# is the time at which A acquires (releases) mutually exclusive access to B. Note that successive time \nstamps on a given history must be strictly increasing, because each individual procedure activation performs \nbuffer operations strictly in sequence. These time stamped local histories are the basis for defining \nseveral other important histories and functions on buffers. The local unstamped histories are defined \nimplicitly by InFrom(B,A)[i] . TimedInFrom(B ,A)[i].message OutTo(B,A)[i] = TimedOutTo(B ,A)[i].message \nfor all elements in the timed histories. The unstamped histories record all messages in the same order \nas the stamped histories, but time stamps are not included. If a buffer can be referred to by a procedure, \nthe buffer must be either a formal parameter or a local variable. If buffer variable B is declared local \nto a procedure P, then a new buffer is created For eacn activation of P. Every procedure has an implicit \nformal parameter MYID of type activationid, which names each distinct activation of the procedure. Because \nB is local to P, only the activation of F and routines called by P can manipulate B. Therefore, all transactions \non B are recorded on the local histories with respect to procedure P. Therefore, we define stamped and \nunstamped global ! histories for B as TimedAllFrom(B) (TimedAllTo(B)) records all receiving (sending) \ntransactions on B by procedure P and any routines activated by P. Note that successive time stamps on \nthe global histories also will be StriCtlY increasing because only mutually exclusive access is provided \nfor B. The sequence of objects currently residing in a buffer B is denoted by content(B) and is defined \nimplicitly by AllTo(B) . AllFrom(B) @ content(B) (Gypsy notation: @ is sequence append. Content(B) is \nthe sequence of objects sent to but not yet received from B. The fullness or emptyness of a buffer is \ndefined in terms of its content. ) empty(B) iff size (content(B))O full(B) iff size (content(B)) . N \nwhere N is the declared maximal size of B. Gypsy requires N > 0 so that not (full(B) and empty(B)) for \nall buffers B. The buffers used to Communicate among procedures running concurrently must be passed as \nparameters to those procedures. The functional external specifications for these procedures normally \ndescribe the effect of an activation of that procedure on the local histories of its buffer parameters. \nFor example, a procedure that moves N objects from a sequence to a buffer can be specified as procedure \nGET(var B: OBJ_BUF; S: OBJ_SEQ ; N: integer) = begin entry N in [0. .MAXSIZE] and size(S) ge N; exit \nOutTo(B,MYID)SII. .N]; end; type OBJ_SEQ = sequence (MAXSIZE) of object; (GYPSY notation: [0. .MAXSIZEI \nis the set of integers from O to MAXSIZE. MYID is the implicit const parameter Of type activationid. \nS[l..N] is subsequence sII], . . ..s[NI. The elements of all sequences are numbered beginning with One.) \nThe exit specification states that what is sent to B by procedure GET is exactly the sequence sII], . \n. ..S[N]. It says nothing about what other concurrently operating procedures might be sending to B. These \nother objects are not recorded on the local history of GET. They are, however, recorded on the global \nhistory AllTo(B). Nor does the exit specification say 3.0 INDEPENDENCE PRINCIPLEanything about what \nmay be received from B by GET . Should we want to show that nothing is received from (sent to) a buffer, \nwe may state this in the exit specification. For example, we could extend the exit specification of GET \nto say exit OutTo(B,MyID) z S[l..N] and InFrom(B,MYID) = null(OBJ_SEQ); (Gypsy notation: Null(OBJ_SEQ) \nis an empty sequence whose type is OBJ_SEQ.) This approach to stating that nothing was received from \n(sent to) a buffer, h~wever, quickly becomes cumbersome in both specification and proof. It requires \nextra uninteresting statements in the specifications and these extra statements require extra steps in \nthe proofs. To eliminate these extra steps, Gypsy allows the programmer (or specifier) to declare operation \nrestrictions on buffers. A buffer may be declared as an $~input~~ buffer upon which send operations are \nnot allowed, or as an ffoutputf~ buffer upon which receive operations are not allowed. Consider the \nfollowing specification for a GET and a companion PUT procedure. procedure GET(var B: OBJ_BUF <output>; \nS: OBJ_SEQ; N: integer) = begin entry N in [0. .MAXS1ZE] and size (S) ge N; exit OutTo(B,MyID) = S[l. \n.N]; end; procedure PUT(var R: OBJ_SEQ; var B: OBJ_BUF <input>; N: integer) . begin entry N in [0. .MAXSIZEI; \n exit R = InFrom(B,MYID) and size(R) = N; end; Buffer B in GET is output restricted; no object may be \nreceived from it. This implies that InFrom(B,MYID) is empty upon exit. Similarly in PUT, OutTo(B,MYID) \nis empty by virtue of the input restriction. Using operation restrictions eliminates a significant number \nof lines of specl.fications. These restrictions are designed to be checked statically. A routine may \nnot use an input (outPut) buffer in a send (receive) operation. The parameter passage rules of Gypsy \nrequire a formal parameter to be at least as restricted as its corresponding actual. An unrestricted \nactual may correspond to a restricted formal, but not vice versa. This information can be used effectively \nto construct Verification conditions in a aimplier fOrUI than would otherwise be possible. The independence \nprinciple for routines has had a major influence on the design of Gypsy. The proof of a routine may only \ndepend upon its own specifications and implementation, and upon the e~ specifications of the routines \nto which it textually refers. This principle is the basis upon which the proof of a sizeable program \ncan be decomposed into manageable subproofs. Every routine can be proved independently of every other \nroutine. This principle is not new; it has been generally adhered to in previous developments of proof \nmethods for sequential programs such as the Pascal procedure call rule. However, it is important to recognize \nthis principle as one of the keys to proving sizeable, complex programs. It is necessary to break a large \nprogram into pieces small enough and sufficiently simple to permit construction and unde~standing of \nthe individual proofs. From a large program we can expect a large number of small pieces. If the proofs \nof N pieces are completely interdependent (each interacts with all of the others), we have N*N possible \ninteractions. This is intolerable for all but the smallest values of n. The independence principle insures \nthat the implementation of one routine cannot interfere with the proof of any other routine. Because \nconcurrent systems are usually more complex than sequential systems, the use of the independence principle \nis even more important in concurrent systems; we know of no other proof methods for concurrent systems \nthat adhere to this principle. As the following sections will show, this principlethas been rigidly adhered \nto in developing the mechanisms for specifying and implementing concurrent programs in Gypsy. Two major \nfactors in this design are the local histories and the oobegin statement.  4.0 PROGRAMS A Gypsy procedure \nis implemented by a sequence of statements that refer to its formal parameters and local data objects. \nThe send and receive statements manipulate buffers directly. Buffers may also be manipulated as actual \nparameters in procedure calls. The proof methods for these ace described in terms of the local histories. \nThe fundamental characteristic of buffer parameters is that each reference to a particular buffer has \na potentially different value, because the buffer may be manipulated by external processes. Since these \nexternal manipulations are not recorded on the local histories, complete descriptions of the local histories \ncan be made independently for each routine. We will begin with the most fundamental concepts, then introduce \none new concept at a time. These concepts are illustrated by an  4.1 Send And Receive Statements Send \nstatements enqueue objects to a buffer; receive statements dequeue objects from a buffer. Both statements \nalso append the object to the appropriate local history. The send statement send Xto B is semantically \nequivalent to the assignment statement TimedOutTo(B,MYID) :. TimedOutTo(B,MYID) <: [time: T#; message: \nX] (Gypsy notation: The expression S <: E denotes the sequence S extended by adding the element E at \nthe end.) The [...] notation is used to denote the corresponding buffer transaction. Similarly, the \nreceive statement receive M from B is semantically equivalent to M := Mi[; TimedInFrom(B;MYID) := TimedInFrom(B,MYID) \n<: [time: T#; message: M#]  where M# denotes some arbitrary value of the same type as M. (Informally, \nM# is the first element of content(B)). When a procedure attempts a send operation, it first tests whether \nthe buffer is full. If it is full, the procedure blocks until some other process performs a receive from \nthe buffer. Similarly, a procedure attempting a receive operation on an empty buffer is blocked until \nsome other process performs a send to that buffer. Below is a full definition of the procedure GET introduced \nin section 2.3. procedure GET(var B: buf_obj<output>; S: OBJ_SEQ; N: integer) . begin entry N in [0.. \nMAXSIZE] and size(S) ge N; exit OutTo(B,MYID) = SII. .N]; var K: int := O; loop assert OutTo(B,MYID) \n= SII..K] and K in [0,.N]; if K = N then leave end; K :=K+I; send S[K] to B; end; end; (Gypsy notation: \nAll compound statements in Gypsy end with the key word lend!!. A !Ileave$t statement causes control to \nleave the innermost loop containing the leave statement. ) The proof rule for the send statement within \nthe loop is that of the equivalent assignment statement defining the new local history. The induction \ntheorem that results from the loop assertion is OutTo(B,MYID) = SII..K] and K in [0. .size(S)-l] -> \nOutTo(B,MYID) <: SIK+I] SII. .K+I] The theorem says, in essence, that equal sequences, each extended \nby appending the same element, remain equal. The procedure exit specification follows directly from the \nloop assertion. Note that the specifications and proof rely only upon the history of local buffer transactions. \n 4.2 Sequential Procedure Call The procedure call allows operational abstraction. A code segment is encapsulated \nin a routine definition with its effects on its parameters described by its external specifications. \nWithin a procedure, the effect of any send or receive operation on a buffer parameter (i.e., a non-local \nbuffer) is recorded on the local buffer histories for that procedure. The semantics of the sequential \nprocedure call in Gypsy would be similar to the procedure call in Pascal if we disallowed Pascal s global \nvariables. There is an additional rule that describes how the local buffer histories of the called procedure \nrelate to the local histories in the calling procedure, Suppose procedure P (with activationid MYID) \nissues a procedure call !Q(. ..,B)l!.)l! where B is an actual buffer parameter. This call is equivalent \nto TIH := TimedInFrom(B,MYID); TOH := TimedOutTo(B,MYID); Q(...,B ,.. .,Q#); TimedInFrom(B,MYID) :. TIH \n@ TimedInFrom(B,Q#); TimedOutTo(B,MYID) :. TOH @ TimedOutTo(B,Q#); where TIH and TOH are fresh, uniquely \nnamed temporary variables and Q{/ is a unique activationid that is the actual parameter corresponds to \nthe implicit formal parameter MYID of procedure q. The effect of the procedure call is that local histories \nof the called procedure are appended to the corresponding local histories of the calling procedure. As \nan example of the use of this rule, let us write a simple object mover using the procedures GET and PUT \nof Section 2.3. procedure PRO_CONl(var R: OBJ_SEt?; S: OBJ_SEQ) = begin entry size(S) le MAXSIZE; exit \nR = S; var B: OBJ_BUF; GET (B,S,size(S)); PUT (R,B,size(S)); end; The procedure PRO_CONl contains nc~ \nsend or receive statements. It invokes procedure GET, which copies the sequence S to the buf fer B, and \nthen invokes procedure PUT, which coPies the contents of buffer B into sequence R. This fcopyingf! action \nis described in thte external specifications of GET and PUT. The procedure call rule requires us to verify \nthe procedure entry specifications, and then allows us to assume the procedure exit specifications. Thus \n, for procedure GET, we must verify that size(S) in [0. .MAXSIZE] and size (S) ge size(S) which follows \ndirectly from the entry condition for procedure PRO_CON1. The entry condition for procedure PUT follows \nfrom the entry of PRO_CONl similarly. We can rewrite the body of PRO_CONl as the semantically equivalent \nform TIH := TimedInFrom(B,MYID); TOH := TimedOutTo(B,MYID); GET(B,S,size(S),GET#); PUT(R,B,size(S) ,PUT#); \nTimedInFrom(B,MYID) := TIH @ TimedInFrom(B,GET#) @ TimedInFrom(B,PUTl}); TimedOutTo(B,MYID) := TOH @ \nTimedOutTo(B,GET1/) @ TimedOutTo(B,PUTl#); Because B is output restricted in GET, the history TimedInFrom(B,GET \n) is null, reducing the second input history assignment to TimedInFrom(B,MYID) := TIH @ TimedInFrom(B,PUT \n). Similarly, because B is input restricted in procedure put, we get TimedOutTo(B,MYID) := TOH @ TimedOutTo(B,GET \n) Further, since all local histories are initially null (before a procedure has begun execution), TIH \nand TOH are both null histories. We now get the verification condition HI . size(S) le MAXSIZE H2 . TimedInFrom(B,MYID) \n= TimedInFrom(B,PUT#) H3 . TimedOutTo(B,~ID) TimedOutTC~(B,GET~~) H4 . OutTo(B,GET#) = S H5 . InFrom(B,PUT#) \n= R H6 . size(R) = size(S) -> Cl. R=S (Hypothesis HI is the entry condition of PRO_CON1. H2 and H3 describe \nthe buffer histories local to PRO_CONl, H4, H5, and H6 are the exit specifications from procedures GET \nand PUT.) Froof Outline. H2 and H3 describe the time stamped histories, but equality of the time stamped \nhistories implies equality of the unstamped histories. Since buffer B is local to PRO_CONl, we can use \nthe global history axiom OutTo(B,MYID) = InFrom(B,MYID) @ content(B)  to show the content(B) is null. \nBy equalities Hti , H5, H6, and properties of the append operator, we conclude that R = S, qed. 4.3 \nConcurrent Procedure Calls The cobegin statement is a strict generalization of the sequential procedure \ncall that may create several procedure activations which run concurrently. The only statements that may \nappear within a cobegin are sequential procedure calls. Thus, cobegin QI(. ..,B) ;..); Qn(. ..,B) ;..); \nend;  is equivalent to TIH := TimedInFrom(B,MYID) TOH := TimedOutTo(B,MYID) Ql(. ..,B, Ql#);l#); ,.. \nQn(. ..,B, Qn#);n#); TimedInFrom(B,MYID) := TIH(MYID,B) @ MIH; TimedOutTo(B,MYID) := TOH(MYID,B) @ MOH; \n where MIH = TimeMerge (TimedInFrom(B,Qli}) ,... . . ..TimedInFrom(B.Qn#) ) MOH = TimeMerge(TimedOutTo(B \n,Ql#), . . . . . ..TimedOutTo(B ,Qn#))  The TimeMerge function merges time stamped histories according \nto their time stamps. Each merge is done on the same buffer B. Each time stamp on each stamped history \nin the merge is unique because of mutual exclusion, and therefore, the merge function is comr)letelv \ndeterministic. As in the sequential procedure call, the effect of a cobegin is to append a new hi,gtory \n(MIH or MoH) to the local history. The new history is a time deterministic merge of histories produced \nby each of the called procedures. The TimeMerge function also has the property TimeMerge(null(trans_SEQ),H) \n= H where type trans_SEQ = sequence of transaction and H is a time stamped history. Thus , if a cobegin \ncalls only a single procedure, say Q, we get MIH . TimedInFrom(B,Q#), and MOH = TimedOutTo(B,Q#) and \nthe effect of the cobegin is identical to a sequential call of Q. Gypsy does not allow dangerous aliasing \nin procedure calls. No actual var parameter in a procedure call may name an object that contains or is \npart of another actual parameter in the same procedure call. This rule applies to concurrent procedure \ncalls, as well. In a cobegin, the requirement is that no actual (non-buffer) var parameter overlap any \nof the other actual parameters of ~ of the procedure calls under the cobegin. This, together with the \nfact that operations on buffer var parameters are exclusive in time, allows procedures with var parameters \nto execute concurrently without interference. f,hus we can rewrite procedure PRO_CON using a concurrent \nprocedure call. procedure PRO_CON2(var R: OBJ_SEQ; S: OBJ_SEQ) = begin entry size(S) le MAXSIZE; exit \nR S; var B: OBJ_BUF; cobegin GET(B,S,size(S)); PUT(R,B,size(S)) end; end Changing the sequential procedure \ncalls to concurrent procedure calls changes the assignment TimedInFrom(B,MYID) :. TIH @ TimedInFrom(B,GET \n) @ TimedInFrom(B,PUT) to TimedInFrom(B,MYID) :. TIH @ TimeMerge (TimedInFrom(B,GET), TimedInFrom(B,PUT) \n) The change only affects how the two subhistories are merged. In the sequential case, we know that all \nbuffer transactions in GET precede those in PUT, and so, the TimeMerge reduces to the append function. \nThe VC for PRO_CON2 is directly analogous to that for PRO_CONl, with the TimeMerge function substituted \nfor the append operator. The proof remains basically the same. Instead of using the reduction Timedh \n@ null(trans_SEQ) . Timedh we use TimeMerge(Timedh, null(trans_SEQ)) = Timedh. 5.0 NON-TERMINATION Both \nthe traditional weak and strong interpretation of entry and exit specifications are ineffective for non-terminating \nprocesses because a weak exit is to hold ~ a Process terminates and a strong exit requires that the process \nW terminate. Specifications for non-terminating processes that have buffer parameters can be stated in \nGypsy with a block specification. The block specification must hold whenever a process is fully blocked \nawaiting access to a buffer. This blockage point, in effect, defines a temporary halting point. The block \nspecification is interpreted in a weak sense; it must hold H the process is blocked. Potential blockage \npoints in a procedure are sends, receives, (sequential and concurrent) procedure calls, and await statements. \nSend and receive statements are defined as calls to predefine send and receive procedures. These procedures \nhave blockage specifications that their buffer parameter is full or empty, respectively. Thus the potential \nblockage points are basically procedure calls. A procedure call is blocked is all of its procedure activations \nare blocked. Ultimately, a procedure may block only because it invokes (perhaps indirectly) the send \nor receive procedures. Thus, only procedure calls passing buffer parameters may potentially block. The \nawait statement is a buffer polling mechanism. It is a non-deterministic case statement with send and \nreceive operations as guards for the cases. The await is blocked if all of the buffer operations are \nblocked. If the await is not blocked, it behaves as a non-deterministic case statement, selecting between \nthose cases whose guards are not blocked. Thus the await blocks as multiple sends and receives would, \nand executes as a single send or receive. The procedure blockage specification must be proven at each \npotential blockage point. It must be provable from the information available from the internal program \nassertions in the normal inductive assertion technique, together with any knowledge we may gain about \nthe blockage. For example, blocking at a receive statement implies that the buffer is empty (due to the \nblock specification of receive). Under a sequential procedure call, we know the single procedure activation \ncreated has blocked, and so may assume that procedures block specification. Blockage at a concurrent \nprocedure call, however, is more vague. At least one of the procedure activations must be blocked, but \nthe rest may either be blocked or have already terminated. TO express this, we define a predicate, ISBLOCKED(A), \nwhich is true if the procedure activation A is blocked. Thus, if a procedure is blocked at the cobegin \nstatement cobegin Ql(. ..); Qn(l..) end then we deduce that if ISBLOCKED(Ql#) then Ql_BLOCKAGE else \nQl_EXIT fi and . and if ISBLOCKED(Qn#) then Qn_BLOCKAGE else Qn_EXIT fi and (ISBLOCKED(Qlil) or . . . \n. . . or ISBLOCKED(Qn#)), where Ql#, . . ..Qn# are the activationids corresponding to the procedure \nactivations under the cobegin, and Qi_BLOCKAGE and Qi_EXIT represent the blockage and exit specifications \n(respectively) for procedure Qi. At the blockage point the local histories are updated as they are after \na procedure call. (Intuitively, the local histories are extended by whatever transactions were performed \nby the called procedures before blockage.) Thus the updated local histories will usually appear in the \nconclusion of a blockage VC. We can rewrite PRO_CON once again, this time as system of two non-terminating \nconcurrent processes (a producer and a consumer). procedure PRO_CON3(var BIN: OBJ_BUF; var BOUT: OBJ_BUF) \nbegin block not full(BOUT) -> empty(BIN) and OutTo(BOUT,MYID) = InFrom(BIN,MYIl>) exit false; {explicitly \nassert non-termination, var B: OBJ_BUF; cobegin TRANSFER(BIN,B) ; TRANSFER(B,BOUT) end; end; procedure \nTRANSFER (var X: OBJ_BUF<input>; var Y: OBJ_BUF<output>) . begin block not full (Y) -> empty (X) and \nInFrom(X,MYIl)) = OutTo(Y,MYID); exit false; {explicitly assert non-termination] var M: OBJECT; loop \nassert OutTo(Y,MYID) InFrom(X,MYID); receive M from X; send Mto Y; end; end; Verification of procedure \nPRO_CON3 requires proof of two verification conditions: one corresponding to termination of the cobegin, \nthe other corresponding to blockage at the cobegin. The termination VC for this example is false -> false \nwhich is trivially true. The blockage VC for PRO_CON3 is HI. if ISBLOCKED(T#l) then not full(B) -> empty(BIN) \nand OutTo(B,T#l) InFrom(BIN,T#l) else false fi H2 . if ISBLOCKED(T#2) then not full(BOUT) -> empty(B) \nand 0utTo(BOUT,T#2) = InFrom(B,T#2) else false fi H3 . ISBLOCKED(T#l) or ISBLOCKED(T#2) H4 . TimedAllTo(B) \n= TimeMerge(TimedOutTo(B ,T#l); null(TRANS_SEQ) ) H5 . TimedAllFrom(B) = TimeMerge( null(TRANS_SEQ) , \n(TimedInFrom(B,T#2)) -> cl . not full(BOUT) -> empty(BIN) and InFrom(BIN,T#2) = OutTo(BOUT,T#l) where \nT# 1 and T#2 are activationids corresponding to the two activations of TRANSFER. Hypotheses H1 and H2 \nare the instantiated block and exit specification of activations T#l and T#2. Hypothesis H3 states that \nat least one of the two processes is blocked and not yet terminated. Hypotheses H4 and H5 describe how \nthe histories ofB in T#l and T#2 merge to form the histories of B in PRo_coN3. The conclusion is the \nblock specification for PRO_CON3 with InFrom(BIN, T$l) substituted for InFrom(BIN, MYID) and OutTo(BOUT, \nT#2) substituted for OutTo(BOUT, MYID) . These substitutions are required because of the new values assigned \nto the buffer histories after the cobegin. ~roof Outline. The proof breaks into three cases, depending \non the truth values of the ISBLOCKED predicates (H3). The two cases in which a procedure activation is \nassumed to have terminated (i.e., is not blocked) are trivial because hypothesis HI or H2 reduces to \nfalse. TRANSFER are blocked. Thus we can immediately reduce HI and H2 to simple implications. We can \nalso eliminate the references to TimeMerge in H4 and H5 because merging with a null history is an identity \nfunction. The VC is of the form P-> (Q-> R) which can be rewritten as P and Q-> R. Thus Inot full(BOUT)l! \nbecomes a new hypothesis. Using this new hypothesis and the reduced H2, we can apply modus j)onens to \ndeduce empty(B) and 0utTo(BOUT,T#2) = InFrom(B,T#2). By the axioms of buffers, empty(B) -> not full(B). \nThus we can use_ Donens on HI to deduce empty(BIN) and OutTo(B,T#l) = InFrom(BIN,T#l). The VC now has \nthe form HI . empty(BIN) H2 . OutTo(B,T#l) InFrom(BIN,T#l) H3 . empty(B) Hb . OutTo(BOUT,T#2) . InFrom(B,T#2) \nH5 . TimedAllTo(B) . TimedOutTo(B,T#l) H6 . TimedAllFrom(B) . TimedInFrom(B,T#2) H7 . not full(BOUT) \n-> cl , empty(BIN) C2 , InFrom(BIN,T#l) = OutTo(BOUT,T#2) Conclusion Cl matches Hl, so only C2 remains \nto be proven. Using H2 and H4 we reduce C2 to C2 . OutTo(B,T#l) = InFrotn(B,T#2). Hypotheses H5 and \nH6 imply A1lTo(B) OutTo(B,T#l) and AllFrom(B) . InFrom(B,T#2). From empty(B) we can deduce that content(B) \nis null and, using the definition of content, obtain AllTo(B) . AllFrom(B). C2 follows by transitivity \nof equality. qed. 6.0 RELATED WORK The cobegin is a generalization of the sequential prooedure call \nstatement. It invokes several procedures concurrently and schedules these subprocesses nondeterministically \nand fairly. Only procedures can be invoked by a cobegin, and a cobegin of just one procedure is exactly \nequivalent to a sequential procedure call. Procedures (and also functions) in Gypsy may not refer to \nnon-local variables, hence al 1 variables that are used to communicate between procedures must appear \nexplicitly as parameters. Buffers are the only variables that may be actual var parameters to several \nprocedures operating concurrently. The cobegin structure is the basis for decomposing systems into independently \nverifiable subsystems. This decomposition is possible even in the presence of distributed processing. \nThe similarity of the cobegin to a procedure call is in direct contrast to Concurrent Pascal [Brinch \nHansen, 75] and Modula [Wirth, 771. In these languages, processes are initialized and then run forever. \nRestricting the cobegin only to call procedures also is substantially different from [Owicki, 76], which \nallows arbitrary statement lists as the subprocesses of a cobegin. The await statement is similar to \nthe guarded command of [Dijkstra, 75] where the guards are buffer operation statements (send, receive) \nand the commands are arbitrary Gypsy statement lists. The await waits until it can select (nondeterministically) \nsome guard that is not blocked, does the buffer operations and the statement list, then exits the await. \nProcess coordination in Gypsy is done strictly by means of message buffers [Brinch Hansen, 73], as opposed \nto semaphores [Dijkstra, 681, monitors [Hoare, 741, or conditional critical regions [Owicki, 75]. The \nbuffers are strictly FIFO queues upon which send and receive operations are excluded in time. Similar \nsynchronization mechanisms have been used in the RC4000 operating system [Brinch Hansen, 73] and Hydra \n[Wulf, 751; but, as far as we know, message buffers have not been used previously as a basis for specification \nand proof. The Gypsy message buffers are predefine types with predefine axiomatic properties. This is \nin direct contrast to the monitors of [Hoare, 74] and [Howard, 761 as well as the conditional critical \nregions of [Owicki, 75] in which axiomatic properties of each shared object must be specified and proved. \nTransaction histories have been used in most approaches to specifying and proving properties of systems \nof concurrent processes and shared objects ([Habermann, 72]; [Hoare, 741 ; [Owicki, 76]; [Howard, 76]). \nThese approaches, however, have used the installation of Ighosttt variables to record transaction histories \nin an ~ M way. In Gypsy, the histories and the ways in which buffer transactions are recorded are predefine \nby the language, and the semantics of the buffer operation statements are defined in terms of these histories. \nAn important and unique aspect of Gypsy is the distinction between global and local histories. Global \nhistories record all transactions on a given buffer. The local histories record the effects of a given \nprocedure activation on a given buffer: This is the basis for isolating the effects of a procedure so \nthat it can be specified and proved independently of all other procedures. The time stamped buffer histories \nat e being used as a basis for formal specifications of real-time constraints [Cohen, 781. Specifications \nfor procedures that manipulate buffers can be stated in terms of entry and exit assertions about the \nlocal buffer histories. The technique for nonterminating processes is similar to the intermittent assertions \nof [Manna, 78]. A block specification can be stated that is to hold U a procedure is blocked awaiting \nits mutually exclusive access to a buffer. The block specifications also can be verified independently \nfor each procedure. Operation restrictions may be declared on a buffer. A buffer may be declared to \nbe used strictly for input or for output . These restrictions are in the spirit of [Jones, 78] and are \nenforced statically. These restrictions reduce the size of specifications, and their static enforcement \nsignificantly simplifies proofs. The proofs are done by an extension of the inductive assertion method. \nAssertions may refer to buffers and their respective transaction histories. Verification conditions are \nconstructed and proved independently for each procedure. All consideration of the interactions of procedures \nrunning concurrently is isolated to the verification conditions for the cobegin. It is never necessary \nto consider simultaneously ~ processes running concurrently, as in [Habermann, 72], or to prove noninterference, \nas in [Owicki, 75]. 7.0 SUMMARY This paper has described the basic principles for specifying and proving \nsystems of concurrent processes in Gypsy including automatable methods for both terminating and nonterminating \nprocesses. These methods are based on message buffers for process coordination and a cobegin statement \nthat is a generalization of a sequential procedure call. Proofs of concurrent Gypsy processes are independent \nin that the implementation of one process cannot affect the proof of another. The Gypsy language has \nseveral more advanced aspects of concurrency that have not been described. These include structures (e.g., \narrays) of buffers and the ability to activate arrays of procedure activations within a cobegin. The \nbasic principles described here, however, can be extended to cover these more complicated systems, Such \nadvanced facilities have proven successful in the trial applications listed in the introduction. ACKNOWLEDGEMENTS \n The mechanisms for specifying, programming, and verifying systems Of concurrent. processes in Gypsy \nhave been developed over a four-year period. We gratefully acknowledge the significant contributions \nmade during this period by Allen L. Ambler, John H. Howard, Robert W. Wells, Michael K. Smith, Charles \nG. Hoch, and James C. BrOWne. BIBLIOGRAPHY [Brinch Hansen, 731 Per Brinch Hansen. 9~e at ~ ~vsttema \nPrinciDlea, pre~ti~~-Hall, 1973. [Brinch Hansen, 75] Per Brinch Hansen. !I fhe Purpose of Concurrent \nPascal , in proceedings Internat,W. Conference m aeliable iiQC@&#38;E$2, 1% 5. [Cohen, 781 R.M. Cohen. \nFor~l SpeCifications for Real-Time Systems in Seventh Texas Conference on Computing Systems, October, \n1978.  Di.jkstra. IfCooperating [Dijkstra, 68] E.W. Sequential Processes , in programming Languages, \nAcademic Press, 1968. [Di.jkstra, 751 W.Q. Di.jkstra. ItGuarded Commands, Nondeterminancy and Formal \nDerivation of Programs , CACM 18,8 (1975). Hoch ,[Good, 781 D.I. Good, R,NJ, Cohen, C.G. L.W. Hunter, \nD.F. Hare. ItReport on the Language GYPSY, Version 2.0 , ICSCA-CMP-1O, Certifiable Minicomputer Project, \nICSCA, The University of Texas at Austin, May, 1978. [Habermann, 721 A.N. Hab~~rmann~ Synchronizing \nof Communicating Processes l in J2A12M2 15-3) March, 1972 llMonitorg -an [Hoare, 74] C.A.R. Ho are. \nOPerating System Structuring Concept?!, In L7Ju3117-10, October, 1974. [Horn, 771 Gary R. Horn. SPecificati~~w~k,,a \nSecure Computer communications ICSCA-CMP-8, The University of Texas a: Austin, 1977. Howarcl. !Iproving \nMonitors Correct , In= 19-5, 1976. [Howard, 761 J. Wirth. Pascal ~ Manual A .ReDort, Springer Verlagy \n1974. [Jensen, 741 K. Jensen and N IIA [Jones, 781 A.K. Johes and B.~~r iskov Language Extensicm Express~ng \nConstraints on Data Access , CACM, 21, 5, May, 1978. llIs Waldinger. Sometimes better than Always ? , \nCACM, 21, 2, February, 1978. [Manna, 781 Z. Manna and R. Techniques for Parallel Programs!!, PhD Thesis, \nCornell University, Ithaca, N.Y., August, 1975. llAn [Owicki, 76] S.S. Owicki, D. Gries. Axiomatic Proof \nTechnique for Parallel Programs 1 1, Acts Informatica, vol. 6, 1976. [Wells, 761 R.E. Wells. !Specification \nand Implementation of a Verifiable Communications System , Masterts Thesis, The University of Texas at \nAustin, December, 1976. [Wirth, 77] N. Wirth. Modula: a Language for Modular Multiprogramming f, in \nSoftware practice &#38; ExDerien?l, VOl 7, 3-35, 7977. [Wulf, 75] W.A. Wulf, R. Levin, C. Pierson. I!Overview \nof the Hydra Operating SYstem Development f. In Proceedings of the Fifth Svnmosium on ODeratinR Svstems \nPrinciples, 1975.  \n\t\t\t", "proc_id": "567752", "abstract": "Concurrency in Gypsy is based on a unique, formal approach to specifying and proving systems of concurrent processes. The specification and proof methods are designed so that proofs of individual processes are totally independent, even when operating concurrently. These methods can be applied both to terminating and non-terminating processes, and the proof methods are well suited to automated verification aids. The basic principles of these methods and their interaction with the design of Gypsy are described.", "authors": [{"name": "Donald I. Good", "author_profile_id": "81100090507", "affiliation": "The University of Texas at Austin, Austin, Texas", "person_id": "PP14042135", "email_address": "", "orcid_id": ""}, {"name": "Richard M. Cohen", "author_profile_id": "81100145896", "affiliation": "The University of Texas at Austin, Austin, Texas", "person_id": "P333245", "email_address": "", "orcid_id": ""}, {"name": "James Keeton-Williams", "author_profile_id": "81100662676", "affiliation": "The University of Texas at Austin, Austin, Texas", "person_id": "P383277", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567752.567757", "year": "1979", "article_id": "567757", "conference": "POPL", "title": "Principles of proving concurrent programs in Gypsy", "url": "http://dl.acm.org/citation.cfm?id=567757"}