{"article_publication_date": "01-01-1979", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1979 ACM 0-12345-678-9 $5.00 AUTOMATIC GENERATION OF NEAR-OPTIRAL LINEAR-TIME TRANSLATORS FOR NON-CIRCULARATTRIBUTE \nGRAMMARS by Rina Cohen and Eli Harry TECHNION -Israel Institute of Technology ABSTRACT Attribute grammars \nare an extension of context\u00adfree grammars devised by Knuth as a formalism for specifying the semantics \nof a context-free language along with the syntax of the language. The syn\u00adtactic phase of the translation \nprocess has been extensively studied and many techniques are available for automatically generating efficient \nparsers for context-free grammars. Attribute grammars offer the prospect of similarly automat\u00ading the \nimplementation of the semantic phase. In this paper we present a general method of construct\u00ading, for \nany non-circular attribute grammar, a deterministic translator which will perform the semantic evaluation \nof each syntax tree of the grammar in time linear with the size of the tree. Each tree is traversed in \na manner particularly suited to the shape of the tree, yielding a near optimal evaluation order for that \ntree. Basically, the translator consists of a finite set of Local Control Automata , one for each production; \nthese are ordinary finite-state acyclic automata augmented with some special features, which are used \nto regulate the evaluation process of each syntax tree. With each node in the tree there will be associated \nthe Local Control Automaton of the production applying at the node. At any given time during the translation \nprocess all Local Control Automata are inactive, except for the one associated with the currently processed \nnode, which is responsible for directing the next steps taken by the translator until control is finally \npassed to aneighbour node, reactivating its Local Control Automaton. The Local Control Automata of neighbour \nnodes communicate with each other. The construction of the translator is custom tailored to each individual \nattribute grammar. The dependencies among the attributes occurring in the semantic rules are analysed \nto produce a near-optimal evaluation strategy for that grammar. This strategy ensures that during the \nevaluation process, each time the translator enters some subtree of the syntax tree, at least one new \nattribute evaluation will occur at each node visited. It is this property which distinguishes the method \npresented here from previously known methods of generating translators for unrestricted attribute grammars, \nand which causes the trans\u00adlators to be near-optimal. INTRODUCTION. Attribute grammars are an extension \nof context free grammars devised by Knuth [K1] for specifying the semantics of languages along with the \nsyntax. Each grammar symbol has.an associated set of attributes specifying the various compon\u00adents of \nits meaning , and each production is provided with semantic rules, defining the attributes of symbo ls \nin the production in terms of other attributes associated with the produc\u00adtion. To find the meaning of \na string, first we construct its syntax tree and then we determine the values of all the attributes of \nsymbols in the tree, a process which is called semantic evaluation of the tree. An attribute grammar \nis non-circular if the system of semantic definitions given by the grammar avoids circularity in all \npossible instances. The problem of detecting circularity in an attribute grammar, first solved by Knuth \nin [K1,2], was shown in [J&#38;O&#38;R] to be of inherent exponential complexity. Since their definition, \nattribute grammars have attracted widespread interest in the area of programming languages. They have \nbeen used by investigators in fields such as natural language recognition and question answering systems \n[P], program optimization ([N&#38;A]),[J2]) and the theory of program correctness [G]. But their most \nimportant contribution was toward:; the formal definition of programming languages and automatic design \nof compilers. Two high-level programming languages, namely SIMULA and PL360, were fully defined and implemented \nusing the attribute grammar model ([Wi],[D]). When an attribute grammar is used to specify the translation \nand code generation performed by a compiler, the attributes may represent such things as data types of \nexpressions, symbol table records forusein translating identifiers, register usage information or machine \ncode generated for a statement. The definition of aprogramrnin glanguag.e and its compilation process \nby means of an attri\u00adbute grammar offers the following advantages: (i) The semantics is given in a declarative, \nnon\u00adprocedural way, and is independent of any parsing scheme. (ii) The semantic description is modular, \ngiven on a production by production basis, which makes the definitions more understandable and facilitates \nthe addition and removal of features from the language. (iii) The context sensitive features of the language \ncan be nai;urally expressed. (iv) The description of the language can be checked for consistency and \nused for automatic compiler generation.  Despite these advantages, attribute grammars have not become \na widely used tool for compiler generation because of the difficulty in obtaining implementations efficient \nenough for practical use. Until now, efficient translation algorithms INTRODUCTION (cent d) have been \ndeveloped only for restricted classes of attribute grammars ([L&#38;R&#38;sl ,2], [A&#38;U2,3],[B],[Jl], \n[K&#38;W]). A general framework for studying determin\u00adistic implementation of attribute grammars was \ndeveloped in [W]. In this paper we present a general scheme for automatically constructing a near-optimal \nlinear\u00adtime deterministic translator for any non-circular attribute grammar. The translator will traverse \neach parse tree of the grammar in a manner which is particularly suited to the shape of the tree, yielding \na near-optimal evaluation order for the tree. As a result, our translator will never wander around aimlessly \nin the tree before reaching a place where new attributes can be computed. Instead, it is guaranteed that \neach time the trans\u00adlator enters some subtree of the syntax tree, at least one new attribute evaluation \nwill occur at each of the nodes visited. The construction of the translator is custom tailored to each \nindividual attribute grammar. The dependencies among the attributes in the grammar are analyzed to produce \na near-optimal evaluation strategy for that grammar. Basically, the translator consists of a finite set \nof Local Control Automata , one for each production. These are finite-state acyclic automata augmented \nwith some special features, which are used to regulate the translation process of each given parse tree. \nWith each interior node of the tree is associated the Local Control Automaton of the production apply\u00ading \nat the node. During the translation process, whenever control reaches the particular node, its Local \nControl Automaton is reactivated, starting from the state in which it was last suspended. The automaton \nis responsible for directing the evalua\u00adtion process while control is at the node. When finally control \nis passed to a neighbor node (along with some parameter), the currently active Local Control Automaton \nis suspended, and the Local Control Automaton associated with the neighbor node will be reactivated. \nThis goes on until eventually the Local Control Automaton associated with the root of the tree enters \na final state, at which point the translation process is complete. ATTRIBUTE GRAMMARS. An attribute grammar \nis a context-free grammar augmented with attributes and semantic functions. Formally, an attribute ~consists \nof the followin9: 1. Underlying grammar: A context free grammar G= (VN,VT,P,S), where V is the setof \nnon terminals, N VT is the set of terminals, P is the set of productions and SCV.N is the the start symbol. \nWe assume that there are no useless nonterminals and that S appears on the left hand side ofa unique \ninitial production Po, and does not appear on the right side of any production. Let V stand for VNUT. \nA production p~P is written in the following form p: xo+xlx~ . . . Xn where np~l,xo EVN andxk~v for l~k~np. \nFor p convenience, we sometimes Wite p[k]tomean X fork=O,l . ..n . P,.l.e. PKI denotes the k th symbol \n/from VO appearing in production p. 2. Attributes: For each symbol XEV, there are two finite disjoint \nsets, ~-the inherited attributes of X, and ~ -the synthesized attributes of X. For X = S and for X&#38;VT, \nwe require that I(X) = ~. Wewrite~ for I(X) U s(x). A production P: o+xlx2  n P has the attribute occurrence \n(a~), O<k<n if P aEA(Xk). 3. Semantic functions: For each production PCP there is a finite set of semantic \nfunctions as follows : for every synthesized attribute occurrence (a,k)wit h k = O, and for every inherited \nattribute occurrence (a,k) with 1 s k s np, there is a semantic function which defines the value fp (a,k) \nof attribute occurrence (a,k) from the values of other attribute occurrences appearing in the same production. \nThe value of an attribute occurrence defined by a semantic function is taken from a given set (possibly \ninfinite) of attribute values. The semantic functions usually involve simple operators like assignment, \nBoolean operators, numerical sums, etc. Example 1: The following is an example of an attribute grammar: \nN  {S,A B} T = {a,b} I(S) = @ s(s) = {s,} I(A) = {ill S(A) = {S1,S2 I(B) = {i1,i2} S(B) = {S1] Production \nSemantics O: S+abA (s., o) = 5,>3) + (s2,3) (i1,3) = ,3) 1 ~: A+aAbB (sl,O) = S,,2) (s2,0) = 52,2) + \n(s, ,4) (i2,4) = (i, ,0) (i1,4) = 1 (i1,2) = 1 2: A+abb (s,,0) = 1 (s2,0) = 1 3: A+ab (s,,0) = T (S290) \n= (il,O) 4: B+ab (sl,O) = (il,O) 5; B7ba (s150) = (iz,o) Evaluation of Attribute Grammars: A parse tree \nof an attribute grammar is a derivation tree of the underlying context free grammar, i.e. a finite tree \nwhose nodes are label led with symbols from V. For each interior node N there is a production p&#38;P \nsuch that N is label led with the symbol p[O], has np sons, and for each k, I<k<n the k-th P son of N \nis labelled with p[k]. In this case we say that production p applies at node N. By the k-th neighbor \nof node N, for O<k<n , we shall P mean the father of N in case k = O, or the k-th son ofNincasel<k<n \n. A parse tree with root X, is a pafie fie~ in which the root is label led x= N;ontermina, x by A semantic \ntree of an attribute grammar is a parse tree augmented with attributes; i.e. each node labelled with \nXeV is a structured variable whose field selectors are the elements of A(X). Jn order to determine the \nmeaning or translation of a string generated by the underlying context-free grammar, we first parse the \nstring and build the semantic tree. Then we have to fill in the fields of each node by computing the \nattribute values according to the semantic functions. This process is called evaluation of the semantic \ntree. An algorithm which accepts as input~semantic tree generated by a given attribute grammar G and \nevaluates it is called a translator(or evaluator) for G. The only restriction imposed on the translator \nis that at any point in time during the evaluation process it can only evaluate an attribute occurrence \nwhose semantic function is ready to evaluate; that is, all attribute occurrences which are arguments \nof the semantic function have been previously evalu\u00adated. Thus the translator will move in the tree from \nnode to node, at each node evaluate some attri\u00adbutes which are ready to evaluate until all attri\u00adbute \noccurrences in the tree have been evaluated. Consider the attribute grammar of Example 1 and the semantic \ntree of Fig.1. The fields have been filled in as prescribed by the semantic functions. Note, for example, \nthat il of node 11 cannot be evaluated before S1 of the same node is evalu\u00adated, which in turn demands \npre-evaluation of S1 of node 6. In later sections we shall describe how to sys\u00adtematically construct \nan efficient translator for each attribute grammar. The construction of the translator will be carried \nout once and for all at construction time. Once the translator for the attribute grammar has been constructed, \nthe eval\u00aduation process for each semantic tree, as described above, will take place at run time. The \nDependency Graph: Let p be the production p: XO +X1X2 . . . A convenient tool for +lp describing production \np and its semantic dependen\u00ad cies is the dependency graph of produc~ p, denoted DD. The nodes of DD are \nthe attribute occurrenC~s of p. There is a directed arc from node (a , k ) to. node (a~k) if (a, k) depen~s \non (a , k ) i.e. he emantlc unctlOn P(a,k) Ses a k ) as argu\u00ad ment. This means that Dp reflects the \ndependencies among attribute occurrences imposed by the semantic functions of p. Fig.2 shows the dependency \ngraph of production 1 of Example 1. In order to represent the semantic dependencies of a whole semantic \ntree rather than a single pro\u00adduction, we define the (compound) dependency graph of a semantic tree T, \ndenoted ~). This graph is constructed by pasting together copies of the Dp s for the productions occurring \nin the tree. Each one of the Dp s is selected according to the production p applying at the interior \nnode of the tree. Fig.3 shows the compound dependency graph of the tree of Fig.1. Circularity: The compound \ndependency graph of a semantic tree reflects the flow of information among the attributes in the tree. \nIn the semantic tree there is a f low of information from the root towards the leaves by the inherited \nattributes, and from the leaves towards the root by the synthesized attributes. Since information may \nflow in both directions, a cyc le may be created. An attribute grammar is said to be circular if there \nexists at least one semantic tree whose dependency graph con\u00adtains a cycle. Circular grammars are clearly \nill\u00addefined in that there is at least one semantic tree which cannot be evaluated. Knuth [kl,2] has presented \nan algorithm which tests an attribute grammar for circularity. The time taken by the algorithm is exponential \nin the size of the grammar. A faster but still exponential algorithm appears in [J&#38;O&#38;R], where \nit was also established that the circularity problem for attri\u00adbute grammars is of inherent exponential \ntime complexity. A Normal Form for Attribute Granu: In the general definition of attribute grammar for \neach productionp, every SemantiC fUnCtiOn f~(a,k) may be defined in terms of all other attribute occur\u00adrences, \nexcluding (a,k) itself. Without loss of g~nerality we may assume that a semantic function does not use \nas argument an attribute (a,k# occur ence, which is defined in the same production. This leads to the \nfollowing normal form [Jl]. Definition: An attribute grammar is said to be in normal form if it satisfies \nthe following restric\u00adtions. For each production p: X. + Xl . ..Xn : (a) A synthesized attribute occurrence \np (s,0), SES (Xo), may depend onlYon: (1) ~nj:[~ty~ attribute occurrences (i ,0), (2) Synthe~ized attribute \noccurrences (s ,k), SES(Xk), l:k~np; (b) An inherited attribute occurrence (i ,k), icI(Xk), l~k~np, \nmay depend only on: (1) :n~~~~erj ,attribute occurrences (i ,0), (2) Synthes~zed attribute occurrences \n(s,k), scS(Xk), l~k~np.  There is no loss of generality in imposing the above restrictions, provided \nthere is no local circularity for any production p in the grammar. Local circularity means that the dependency \ngraph Dp of production p contains a cycle, and its exist\u00adence clearly implies circularity. THE CHARACTERISTIC \nGRAPHS. We now construct for each nonterminal of the attribute grammar a collec\u00ad tion of directed graphs, \ncalled the characteristic graphs of the nonterminal. These graphs play a major role in Knuth s test for \ncircularity [Kl]and are essential for the understanding of the evalua\u00ad tion process and translator construction \nto be described in subsequent sections. Definition: For each semantic tree Tx with root X, the root dependency \ngraph of the tree TX is derived from the compound dependency graph of TX by pro\u00adjecting the attribute \ndependencies on the root X as follows. The set of nodes of the root dependency graph is A(X), and there \nis an arc from inherited attribute i to synthesized attribute s if the compound dependency graph of TY \nhas a path from i ,. to s. Figure 4 shows the root dependency graph of the subtree rooted at node 4 of \nthe tree in Fig. 1. ( . o - -n . La N K 2 N , --i---i ///-- -. -. N w W IH Observing the compound dependency \ngraph of Fig. 3, ponds at least one semantic tree with root X. From one can 4 to i2 see that of node \nthere is a 8 continuing path to from s of il of the node the same node now tree on, the T will root dependency \nbe referred to graph as the of a semantic characteristic and ending in S2 of node 4. This lath yields \nthe arc graph of the tree T. from il to s2 in Fig. 4. The root dependency graph of a semantic tree Tx \nreflects the dependencies among the attribute occur\u00adrences of the root X induced by the tree Tx. Since \nthe node set is A(X), there can be only finitely many distinct root dependency graphs for trees with \nroot X. In the evaluation process of semantic trees to be described in the following sections, each subtree \nof the semantic tree will be characterized by its root dependency graph. Define acharacteristic @ of \nnonterminal X to be any graph Cwith node set A(X). s.t. C is the root dependency graph ofat least one \nsemantic tree T with root X. LetCx = {C, ,C7,. ... Cmvl denote the set of all characteris\u00ad tic g;aphs \nofAnonterminal X. Definition: Let Do be the dependency graph for production p: Xo +X~X~ . . . Xnp> and \nlet Gl,G2,. ..,Gn ~ be any given set of directed graphs s.t. for each k = 1 ,...,n , the nodes of Gk \nare the elements of A(Xk). Then the merged gr~, denoted DP[G1,G2,. . .,Gnnl, is the directed graph obtained \nfrom D by addi~g an arc from (a,k) to (a ,k ) when\u00adever t~e graph Gk has an arc from a to a . The above \ndefinition is illustrated in Fig. 5. Let Dp be the graph of production A+ aAbBin Fig.2, let G2 and G4 \nbe the graphs shown in Fig.5 (on top) and let G1 and G3 be the empty graphs (corres\u00ad ponding to the terminals \na and b with noattr%butes). The merged graph Dp[Gl,G2,G3,G4] is shown in Fig.5. for instance, the arc \nfrom (il,2) to (s1,2) origin\u00ad ates from the arc from il to S1 in Gz. Algorithm 1 -Construction of the \nSets of Characteristic Graphs: (i) Initialization: For each XCVN let CX be the empty set, and for each \nXCVT let Cx contain a single graph whose nodes are A(X) and which has no arcs. (ii ) Repeat until no \nmore graphs can be added to any of the sets Cx: For each production p: xo+x,x2. ..xn and for every choice \nof np graphs n ~k c Cx for k = l,. ..,np, form the  C1 . 4D s.t. k graph C with node set A(X ), s.t. \nC has an arc from node i, i &#38;l(XO), to jode s, SSS(XO), whenever the merged graph DD[C1,C2,. ..,Cn_] \nhas a path from (i,O) to (s,0). 1} C is not P yet in Cx then addit toC x o It is cle~r that the above \nprocess must ultim\u00adately terminate with no more graphs created since there exist only finitely many such \ngraphs. Fig.6 shows the sets of characteristic graphs generated by Algorithm 1 for the attribute grammar \nof Example 1. Knuth has shown that for each nonterminal X the set CX constructed in Algorithm 1 is precisely \nthe set of all characteristic graphs of X. Thus, for every semantic tree T with root X, there is in Cx \na corresponding characteristic graph of X(which coincides with the root dependency graph of T), and \nvice-versa, for each graph in Cx there corres- AN OVERVIEWOF THE EVALUATION PROCESS. Given a semantic \ntree witlh root S (the start symbol), the evaluation proces:s consists of evaluating the semantic functions \nof the attribute occurrences in the tree. Sometimes the goal of the evaluation pro\u00adcess is defined to \nbe the evaluation of some distinguished attribute of the root S. Herewe shall consider evaluation to \nbe complete only when all attribute occurrences in the tree have keen evaluated. The evaluation process \nis carried out in two phases, The first phase serves as a preparation for the evaluation itself, which \ntakes place in the second phase. The first phase consists of a depth-first left to right postfix traversal \nof the semantic tree. The computation in each node takes place after all of its sons have been computed. \nDuring this phas,e, the translator will compute for each node NX (label led by X e V) of the semantic \ntree, the char\u00adacteristic graph clf the subtree rooted at Nx. This characteristic graph belongs to the \nset Cx of char\u00adacteristic graphs of X, and represents the depen\u00addencies among the attributes of Nx imposed \nby the structure of the subtree of Nx. During the second phase the translator will again process the \ns=ic tree; however, this time the order in which the nodes are processed is not known a priori, but is \ndetermined dynamically at runtime according to the individual structure of the tree. We may view the \nsecond phase as a processor with control that always points to some current node of the semantic tree. \nWhile at a node Nx, the pro\u00ad cessor may perform one of the following types of elementary actions (or \ninstructions): (i) CALL(a,k) -call for the evaluation of semantic function fp ,,where p is the production \napplying (a,k) at the node Nx. (ii ) TRANSFERDOWN-transfer control down to a specific son of the current \nnode Nx.  (ii i ) TRANSFERUP -transfer control up to the father of the current node.  Starting with \ncontrol pointing to the root of the semantic tree, the translator will process the tree until all attribute \noccurrences in the tree have been evaluated, at which point control returns. Let us examine the evaluation \nprocess from the point of view of an individual node N . During evaluation control is moving around t \nhe tree, and in the meanwhile the processor computes new attri\u00adbute values. From the point of view of \nour node Nx, nothing seems to happen until for the first time control arrives at Nx from above Some semantic \nfunctions associated with the prc)duction applying at NX may then be evaluated, and afterwards control \nleaves Nx in some clirection. Later on control re\u00adturns from the same direction it left, perhaps some \nmore attribute occurrences are evaluated, and again control leaves the node. This goes on until eventu\u00adally \nall attribute occurrences of the production applying at Nx have been computed and control leaves Nx going \ntowards the root, never to return. Thus from a local point of view, evaluation consists of comings and \ngoings of control, interspersed with evaluations of attributes performed while at our node. We shall \nrefer to a part of the evaluation process from the point control leaves our node NX towards its k-th \nneighbour, and until the next time control returns to our node, as a visit to the k-th neighbour of Nx. \nAt each stage of the above evaluation process, the choice of the next elementary action to be taken by \nthe evaluator at the particular node Nx may depend on the following: (a) The production p which applies \nat the node Nx, and its associated semantic functions; (b) The current state ofaffairs of the evaluation \nprocess, as regards our node NX, i.e. the set of attribute occurrences of the pro\u00ad duction p applying \nat Nx, which are currently available; (c) The dependencies among the attri\u00adbutes of Nx, which are induced \nby the subtree rooted at Nx; these dependencies are represented by the characteristic graph of this subtree, \nwhich has been computed during the first phase. To keep track of the sets of available attributes and \nto regulate the evaluation process at the par\u00adticular node Nx, the Local Control Automaton, ~) Al for \nproduction p is introduced. The Local Con\u00ad trol Automaton is an ordinary finite state automaton augmented \nwith some special features in its transi\u00adtion function. Each state of the Local Control Automaton represents \na set of attribute occurrences of production p, which are available upon entering this state. Each transition \nin the automaton rep\u00adresents an instruction of one of the types CALL (a, k), TRANSFERDOWNor TRANSFERUP. \nAssociated with each node of the semantic tree is the Local Control Automaton ~of the production p which \napplies at the node. The LCAAJ is respon\u00ad sible for directing control when it arrives at the node, and \nit calls for the evaluation of the sem\u00adantic functions of production p. Whenever control arrives at a \nnode, it (re-)activates its LCA; ifit is the first time control reaches this node, then the LCA starts \nfrom its initial state; otherwise it resumes action from the state in which it left off . In our translator \ncontrol must be capable of passing parameters among the various LCA S. This passing of parameters serves \nas a means of commu\u00adnication between the LCA S of neighbour nodes and is used for two main purposes: \n(a) When control is transferred down toason of the current node, the translator has to inform the receiving \nLCA what activities took place while the latter was inactive. Specifically, the parameter passed down \nis a set of inherited attributes of the receiving node, which are currently available. These inherited \nattributes are used bythe receiv\u00ading LCA to determine its next move, and their values may be used by \nthe translator as arguments in computing semantic functions. (b) When control is transferred up in the \ntree, the translator has to inform the father s LCA about the activities which took place in the subtree \njust visited. Specifically, the parameter returned to the father is the set of synthesized attributes \nof the son just visited, which are currently available. In both cases, we see that the parameter carried \nalong by control is a set of currently available attributes of thenode visited. Such parameters will \nbe called transmitted sets. The evaluation process described above uses the LCA S as basic building \nblocks. In order to obtain a translator for a given attribute grammar, a finite set of LCA S, one for \neach production, will have to be constructed. LOCAL CONTROLAUTOMATA. As mentioned above, an LCA.4D will \nbe associated with each production pof the ~tribute grammar. At runtime, to each node of the semantic \ntree there will be attached the LCA of the production applying at the node. Whenever con\u00adtrol reaches \na particular node, the LCA of the node will be reactivated, and will dictate the next elementary actions \nto be taken by the translator. When eventually control is transferred to a neigh\u00adbour node, the LCA will \nbe suspended and will send along with control a parameter -the transmitted set. Definition: Consider \na production p: Xo+XlX2.. .X . P Let ~denote the set of all attribute occurr\u00adences of p. For each k = \nO,l,. ..,np, define: (a) For each set of attributes T < A(Xk) T* k={(a,k)\\asT}. (b) For each set of \nattribute occurrences A < A(p)  if k = O then asS(Xk) A/k ={a I (a,k) CA if l~k~np then ?IE~(Xk) ) The \noperator * transforms a set of attributes of onto the corresponding set of attribute occurr-+ ences of \nproduction p, while the operator / maps a set of A of attribute occurrences of production p onto a set \nof A/k of attributes ofXk. Note that for k = O, A/k contains only synthesized attributes, while for 1 \n< k < n A/k contains only inherited P attributes. A/k will be called the k-th projection of A. Definition: \nA Local Control Automaton (~) ~for production X. + XlX2. ..Xn is an ordinary finite state automaton augmentedpwith \nsome features in its transition function. The set of states is divided into two subsets: (a) Active states. \nEach active state is labelled with a set of attribute occurrences A~A(p). No two active states are labelled \nwith the same set A. An active state will therefore be identified by its label A, and will be denoted \nby [A]p (the super\u00adscript p will be omitted when p is understood. (b) SUSPENDstates. Each suspend state \nis labelled by a pair: (k,A), where O~k<n and A GA(p) as above. For each pair (k,A) therep is at most \none SUSPENDstate labelled with this pair. We shall denote this state by SUSk[A]p (with the superscript \np omitted when p is understood).  During the evaluation process, whenever LCA ~ is found in an active \nstate [A] or enters a SUSPEND state SUSk[A] (O~k~np), then A is precisely the set of attribute occurrences \nof production p which have been evaluated so far. There are severaltypes of transitions in an LCA: Transitions \nleaving Active states: Each transition leavina an active state corres~onds to one of the following three \ntypes of instructions: (i) CALL(a,k) -call for the evaluation of semantic  unction ~a, k) ; (ii ) TRANSFERO-transfer \ncontrol up to the O-th neighbour (i.e. father) of the current node;  (ii i ) TRANSFERk (1 ~ k~no) -transfer \ncontrol down  to the k-th neighbour (i .e, k-th son) of the current node. Every active state [A] may \nhave precisely one of the following three types of exits: (i) CALL transition -Exit from [A] leading \nto another active state [A]. Such a transition is labelled by CALL(a,k), where (a,k)EA(p)-A and A = A \nU {(a,k)}. There can be no other transition leav\u00ading state [A]. A transition CALL(a,k) represents an \ninstruction for evaluating the semantic function fp (a, k) :~~,d storing the result in the appropriate \nof the semantic tree. Such an instruction is executable only if the semantic function fp(a,k) s ready \nto evaluate. Therefore we shall impose the additional requirement that whenever transition CALL(a,k) \nleaves state [A]p, all attri\u00adbute occurrences (a ,k ) which are used as argu\u00ad are contained in A. Figure \n7 ents n ~a, k) illustrates a CALL transition; note that the active states are represented by circles. \n (ii) Unconditional TRANSFERTransition -A transi\u00adtion from active state [A] to a SUSPENDstate SUSk[A], \nwhere O < k~n and XkcV The transi\u00ad P N tion is labelled with TRANSFERk and represents an instruction \nto the translator to transfer control to the k-th neighbour LCA. Again this is the only transition leaving \nstate [A]. Fig. 8 illustrates an unconditional TRANSFERtransition. Note that the SUSPENDstates are represented \nby squares. (iii) Conditional TRANSFERTransitions -A set of t+l exits (for some 1 < t < np) from active \nstate [A], leading to t+l dislinct suspend states SUS. [A], SUS. [A] ,.. .,SUSi [A], SUSOIA] (same A \nas 1 2 t for the active state), wherel~ il <i2<...<it~ n~ and Xj is a nonterminal for j = il,i2,. ..,it~ \nTie transition into state SUSj[A] is labelled by the pair (TRANSFERj,C(J)), where C(J) is a subset of \nCx., the set of characteristic graphs of nonterminal J The last transition into state SUSOIA] is j labelled \nby TRANSFEROonly. Figure 9 illustrates a set of conditional TRANSFERtransitions. The above set of conditional \nTRANSFERtransitions leaving state [A] has the following meaning. During the evaluation process of a given \nsemantic tree, if LCA.40 is associated with node Nxn, and An enters ,. r state [A], the exit to be taken \nfrom [A] depends on the characteristic graphs of the sons of NXO in the tree. Specifically, for each \nj = il,i2,. ..,i+, the conditional TRANSFERtransition labelled by \u00ad (TRANSFER., C(j)) will be called \nadmissible iff the J characteristic graph attached to the j-th son of Nx in the semantic tree belongs \nto C(j). As we shall 0 see below, a transition (TRANSFER,i,C(J)) is admis\u00ad sible precisely when the corresponding \nvisit to the j-th son of the current node Nxo is guaranteed to produce at least one new synthe~ized attribute \nof the j-th son. Therefore when the LCA of node Nxo enters state [A], the conditional TRANSFER transitions \nleaving state [A] will be checked one by one until the first admissible transition is en\u00adcountered; this \nwill be the transition to be taken. If, however, none of the first t transitions is admissible, then \nthe TRANSFEROtransition will be taken. Thus control will be transferred up to the father of Nx only if \nin the current situation, no more attribu?e occurrences can be evaluated for production p, not even after \nsome more processing of the subtree of Nxo. Before any further evalua\u00ad tion at Nx can take place, some \nnew inherited attributes of Nx must become available. o Transmitted Sets. Whenever a TRANSFERk instruction \n(either conditional or unconditional) leading into state SUSk[A] is executed, a transmitted set T is \npassed as parameter to the k-th neighbour LCA along with control. Specifically, this set is T = A/k \u00adthe \nprojection of A on the k-th neighbour. For k=O this set T consists of all synthesized attri\u00adbutes of \nXo, which are currently available, and for k=l,2,. ..,n T consists of all inherited attributes ofp Xk \nwhich are currently available. Transitions Leaving SUSPENDStates. Every state s = SUSkiA] may have several, \nsay ! > 1, exits, each labelled with a distinct set T., l<i< !, of attributes of Xk, s.t. Ti * k $ A. \nlLet~h~e exits be denoted by E(s,T1),E(s,T2),. ..,E(s,TL). If k=O then Ti is a set of inherited attributes \nof the L.h.s. Xo, and if k > 0 then T. is a set of synthe\u00adsized attributes of the son Xk.l The exit labelled \nby E(s,Ti) will lead to the active state [A UTi*k]. Since b.y assumption Ti * k4A , no transition leav\u00ad \ning sta~e SUS~[Al will lead~into state rAl aaain. ,. -Fig. 10 illustrates the exits from a SU~P~ND state. \nTo explain the meaning of the sets Ti, recall that during runtime, when the LCAAP attached to node Nxo \nenters state SUSk[A], a TRANSFERk instruc\u00ad tion leading into this state is executed. The LCA of node \nNxo is then suspended, and control is transferred to the k.=th neighbour LCA. After some activities take \nplace in other regions of the tree, control finally returns to the node Nxofrom its k-th neighbour, carrying \nwith it a transmitted set T. At this point tlhe LCAAP at Nxo is reactivated, starting from the same state \nSUSk[A]. The exit taken from this state is chosen according to the transmitted set T received; namely, \nit will be precisely the exit whose label T. coincides with T. In this way, the transmitted setlreturned \nby the k-th neighbour determines the next move of the LCA after it resumes action in state SUSk[A]. The \nsets Ti labelling the exits from SUS [A] represent all possible transmitted sets, whit k can be returned \nby any k-th neighbour LCA in any particular situation. Initial and Final S =. (1) Each LCA has precisely \none initial state, a state with no in-arcs, which is~state SUS.[A1 . - (for some set A). (2) Each LCA \nhas at least one terminal state, a state with no out-arcs. Every terminal state is a state SUSOIA] (for \nsome set A). Let us now summarize the structural properties of LCA S: 2 G4 1 2 1 2 Q O A1 z~u{(a,k)} \n d Figure 7 DprG, ,G2,G3,G41 (il,O) (s, ,0) (s2,0) TRANSFERk SUSk[A]A o---+ Figure 8. Figure 5 0s1 1 \n Figure 9 A /0 2 1 Lo :9 El <d  c 1 A =A U{(a, k), (b, k]} A 2 1T A =A U{(a, k) ,(d, k)] Figure 6. \nA = AU{(b, k), (c, k)} Figure 10 (1) Each LCA is acyclic. This is because for every path in the LCA, \nthe sets of attributes A labelling both active and SUSPENDstates along the path must be ordered by inclusion, \nand no more than two con\u00adsecutive states can be label led by the same set. (2) Every SUSPENDstate SUSk[A] \n(excluding the ini\u00adtial state) has precisely one in-arc (from the active state with same label [A]), \nwhile there may be several in-arcs for any active state.  Figure 11 illustrates a complete set of LCA \nS for the attribute grammar of Example 1. Each state is given a number, C is an abbreviation for CALL \ntran\u00adsitions, the set A of available attribute occurrences and the label TRANSFERkwere omitted. HOWTO \nEVALUATE A SEMANTIC TREE WITH A GIVEN SET OF LCA S. Suppose that we are given a trarislator for some \nnoncircular attribute grammar, The translator is made up of a finite set of LCA S, one for each production. \nIn order to carry out the evaluation process, two variables will be associated with each node NX of the \nsemantic tree: (1) A variable indicating one of the characteristic graphs Ci of non-terminal X, namely \nthe characteris\u00adtic graph of the subtree rooted at node Nx. This variable is computed during the first \nphase of the evaluation process. (2) A variable which, during the second phase, will store the state \nof the LCA of Nx at the time it is suspended, while control wanders in other regions of the semantic \ntree. When control returns to Nx, the LCA of NX will be reactivated, starting from this state. This vari\u00ad \nable is initialized during the first phase. The First Phase: The first phase consists of a depth-first \nleft to right postfix traversal of the semantic tree. During this traversal, with each node of the tree, \nthere will be associated the characteristic graph of the subtree rooted at the node. The characteristic \ngraph associated with a terminal node Nt, t s VT, will be the trivial graph with node set A(t) and no \narcs. Due to the postfix manner of traversal, when the translator reaches a nonterminal node NX to compute \nits characteristic graph, the characteristic graphs of all sons of NX have already been computed. Let \nus describe the construction of the char\u00adacteristic graph for node Nx, where the production applying \nat the node is p: Xo~ X1X2... Xn ,and X=Xo. Let the characteristic graphs associated with nodes Nx , \ni = 1,2. ..,np, be Di. Form a graph i C whose nodes are A(XO) such that C has an arc, from inherited \nattribute i to synthesized attri\u00ad bute s whenever the merged graph DP[D1,D2>.Dn ] has a path from (i,O) \nto (s,0). ... D C is precisely the characteristic graph of node XN. To avoid the need for storing characteristic \ngraphs as part of the translator, and then al; runtime comparing the characteristic graph C con\u00adstructed \nabove against all graphs in the set Cx , some kind of Goedel numbering for graphs can o be used. Edch \ngraph will be identified by its Goedel number (which will constitute the first  variable of the node \nNx) and during runtime compar\u00adison will take place only between the Goedel numbers, An alternative way \nfor obtaining the characteris\u00adtic graph C would Ibe to use a look up table, which gives for each production \np and for each set of characteristic gral~hs {D1,D2,. ..,Dn } as above, the P corresponding chariicteristic \ngraph C. Such a look up table can be prepared once and for all at con\u00adstruction time, while computing \nthe characteristic graphs. When using this method there is no need for Goedel numbering and each graph \nwill be represented simply by its inde;( in the set Cx . The graphs o themselves need not be kept in \nmemory, but the look up table will have to be stored as part of the translator. After determining the \ncharacteristic graph of NX and the appropriate LCAAD according to the production p applying at nod: Nx, \nthe second vari\u00ad able of the node is initialized to the initial state ofA. P The Second Phase. The manner \nin which the semantic tree is traversed during the second phase is custom tailored to the individual \nstructure of the tree. Evaluation begins by sending control to the root LCA A Control begins executing \nthe instructions Po of A which after a while transfers control downto P. one of its sons. Thus control \nwill start wandering in the tree from node to node in an order dictated by the LCA S, and by the characteristic \ngraphs associated with the nodes. At each point in time during the evaluation process, all LCA S of the \ntree are dormant except for one which is active. The active LCA may call for the evaluation of seman\u00adtic \nfunctions, or it may direct control to one of its neighbour LCA S. Eventually, when all subtrees of the \nsemantic tree have been evaluated, control will return for the last time to the root LCA, which (possibly \nafter executing a few CALL instruc\u00adtions) will enter its final state SUSOIAI, and control will leave \nthe tree from above. Evaluation is then complete. Algorithm 2 -Evaluation of a Semantic Tree (1) Perform \nthe first phase. (2) Transfer control to the initial state of the root LCA A along with an empty transmitted \nset. P.  (3) Repeat-until a terminal state of ~p is entered: o  Let the currently active LCA Ap be \nin state s = SUSk[A] and let T be the transmitted set received upon reactivation of this LCA. (i) Take \nthe exit from s label led by T: let t be the active state entered. (ii) Execute the instructions Of \nA , starting from the state t, until a SUSPENDstate,p say SUS,,,[A], is reached.  (iii) Transfer control \nto the k -th neighbou~ LCA along with the transmitted set A /k . Reactivate the k -th neighbour LCA, \nstarting from the SUSPEND state stored in the second variable of the k -th neighbour node. Figure 12 \nillustrates the evaluation process of a semantic tree of the grammar of Ex. 1 according to Algorithm \n2, using the set of LCA S in Fig.11. 6 2 35 1 I 0 Suso + 2 3 o I Suso 0 I Suso + $ 1 1 2 2 3 3 4 Figure \n11: A Complete Set of LCA S 5 I o Sus i 3 Susn 1ns + ns Figure 12 + a Evaluation Process 130 Parse \nTree Starting from the root, control moves down to node 2 (due to entering state 3 in LCAAO), then down \nto node 3; for each node visited, the attributes evaluated at the node are indicated in the figure; e.g. \nat node 3, S1 and S2 are evaluated and then control moves up back to the root. After evaluat\u00ading the \ninherited attribute il of node 2, control moves down again, this time to node 4; after evalu\u00adating S1 \nfor node 4, then S2 of node 2, con:trol returns to the root, and evaluation is complete. We see that \nevery visit to every node in the tree pro\u00adduces at least one new attribute value, To ensure that step \n3(i) in Algorithm 2 can always be carried out, the set of LCA S must satisfy the following condition. \nThe Closure Condition: Whenever at runtime, control is transferred to an LCA A with transmitted set T, \nthe resumed SUSPENDstate in Ap must have an exit labelled by T. The above Closure Condition assures us \nthat Algorithm 2 will always terminate upon entering a final SUSO state of the root LCAA ., P. Theorem \n1: If the set of LCA S for attribute grammar G satisfies the Closure Condition, then Algorithm 2 terminates \nfor each semantic tree T after executing O(ITI) elementary operations (where ITl indicates the size of \nT). The Completion Attribute: To guarantee that the above evaluation aglorithm will result in the com\u00adplete \nevaluation of every semantic tree, a slight modification of the attribute grammar has to be made. A new \ndummy synthesized attribute, called the completion attribute, is added to each non\u00adterminal. For each \nproduction p: Xo+Xl . . . Xn , the completion attribute of X. is defined in p terms of~ inherited attributes \nof X. and of all synthesized attributes (including the completion attribute) of all sons Xk, l~k~n . \nAn attribute grammar to which a !ompletion attri\u00adbute as above has been added for each nonterminal will \nbe called an augmented attribute grammar. In an augmented grammar, the completion attribute is dummy \nin the sense that it is not computed at run\u00adtime. However, this attribute enables us to construct such \ntranslators in which the complete evaluation of every semantic tree will be enforced. For this reason \nwe add to the definition of LCA S the following condition: Completion Condition: For each terminal state \nSuso [A]p 0 of the root LCA A , the set A must P. contain the completion attribute of the start symbol \nS. Theorem 2: For every augmented attribute grammar G and for every set of LCA S for G which satisfies \nboth the Closure Condition and the Completion Condi\u00adtion, Algorithm 2 fully (and correctly) evaluates \neach semantic tree of G in time proportional to the size of the tree. THE CONSTRUCTIONOF A TRANSLATORFOR \nA GIVEN ATTRIBUTE GRAMMAR In this section we describe informally how a complete set of LCA S satisfying \nthe Closure Condi\u00adtion and the Completion Condition can be systemati\u00adcally built for each non-circular \nattribute grammar. The LCA S are constructed in parallel, state by state and transition by transition, \nuntil all of them are complete. The construction is based on simulation of all possible situations that \ncan arise at runtime. Before starting the actual construction of LCA S, the set of characteristic graphs \nCx for each non\u00adterminal X is constructed. After this preliminary computation the construction mocess \nis initialized by defining fo~ e~ch production an LCA consisting of the initial st,~te alone. As the \nalgorithm pro\u00adceeds the LCA S are expanded by adding new states and new transitions in a specific order, \nso as to ensure that the C losure Condition will be always satisfied. For this reason, whenever we add \nto LCA.4P a TRANSFERk transition leading into state SUSk[A], we must be able to identify all SUSPEND \nstates in all LCA S, which at runtime might be reactivated as a consequence of executing this TRANSFERk \ninstruction; each of these SUSpEND states must have an exit labelled by the trans\u00ad mitted set T = A/k. \nDefinition: For every non-initial SUSPENDstate SUSk[A]p in LCAAF,, define the set REACTIVATE(S) to be \nthe set of all SUSPEND statics in all LCA S to which, under certain conditions at runtime, control might \nbe transferred as conse\u00ad quence of suspending LCAAP in state SUSk[A]. The states in REACTIVATE(SUSk[A]p) \nmaY below to anY LCAAP,, which, in some semantic tree, interacts with LCAAP as its k-th neighbor . Therefore \nif k # O then p[k] must coincide with P [0] and if k = O then PIO] must coincide with one of the sons \nof p . The next definition enables us to keep track of the states in which the neighbour LCA S were left \nafter the most recent visit. Definition: For each exit E[s,T] from a SUSPEND state s = SUSk[A]p, define \nthe set SOURCE(E[s,~l) to be the set of all SUSPENDstates SUSkl[A ]p in all LCA S, which at runtime may \npass control to LCAAP and cause it to be reactivated in state s and take the exit IEIs,T]. Clearly SOURCE(EIS,T]) \n, will consist only of states of the form SUSkl[A lp whose transmitted !;et A /k coincides with T. Moreover, \nif k = O, then p [k ] = p[O], while if k+ O then p[k] = p [0]. Thus each SUSPENDstate s is associated \nwith its REACTIVATE set, and each transition E[s,T] leaving a SUSPENDstate s is associated with its \nSOURCE set SOURCE(EIS,T]), These sets are kept in memory and updated during the construction Process. \nA central role in the construction process is played by the queu;! Q. Q consists of couples of the form: \n(E[sp,Tj,sp ), where Sp and Sp are SUSPENDstates in .4p and Ap, respectively and E[sP,T] is an exit from \nsp labelled by T. processing the queue Q is entered. Unfortunately, a The meaning of such a couple appearing \nin Q is that full presentation of the Construction Algorithm exit E[sP,T] has to be created in Ap (unless \nalready requires quite a few additional technical defini\u00ad there), and state Sp must be added to SOURCE \n (E[SP,T]). Note that by definition of the SOURCEset it follows that T must be precisely the transmitted \nset of sp . The construction process is based on retrieval and processing of couples from Q, one at a \ntime. The pro\u00adcessing of a couple (E[SP,T],SPL) consists of creat\u00ad ing the exit E[sP,T] and adding Sp \nto its SOURCE set. The exit will lead to an appropriate active state [A U T * k] which must also be added \nif absent. This new active state will then be developed , which in turn may cause the addition of some \nnew couples to Q. The process goes on until eventually Q remains empty, at which point construction is \ncompleted. Developing an Active State. Recall that an active state [A]p may have three types of exits: \na single CALL(a,k) transition, a single unconditional TRANS- FERk transition, or a set of conditional \nTRANSFER transitions. In developing the active state [A]p, we first try to construct a CALL(a,k) transition \nout of this state, for some attribute occurrence (a,k) of production p s.t. (a,k) 4A. Such a tran\u00ad sition \ncan be created only if the semantic function is ready to evaluate, i.e. depends only on ~a,k) attribute \noccurrences in A. If such an exit is indeed created, it leads into another active state [Au {(a,k)}] \nand we proceed to develop this new state (unless this state already existed before in Ap). In case no \nCALL(a,k) exit out of state [A]p can be created, we attempt to construct an unconditional TRANSFERkexit \nfor some k = l,. ..,np. If this turns out to be impossible as well, a set of con\u00ad ditional TRANSFERtransitions \nwill be constructed. Processing a New SUSPENDSTATE. When a new SUSPENDstate s is created, it is not developed \nin the usual sense, i.e. no exits from it are constructed right away. Instead, the REACTIVATE set of \ns is computed, giving rise to a set of couples to be entered into the queue Q. These couples represent \nthe need to construct new exits (label led with the transmitted set of s) from all SUSPENDstates in REACTIVATE(s). \nIt follows that exits from SUSPENDstates are created only via retrieving and processing couples from \nthe queue Q, and different exits from the same SUSPENDstate are created at different times. The Construction \nAlgorithm uses a subroutine Develop ([A]p) for developing an active state. After computing the characteristic \ngraphs and initializing the queue Q and the LCA S, a loop for tions and is therefore omitted here. The \nreader is referred to [C&#38;H] for a complete formal description of the algorithm, including a proof \nof the following theorem: Theorem 3: For every augmented non-circular attri\u00adbute grammar, the Construction \nAlgorithm terminates with a set of LCA S which have the structure described above and which satisfy both \nthe Closure Condition and the Completion Condition. MAIN THEOREM: For every augmented non-circular attribute \ngrammar, there can be constructed a translator, based on a set of LCA S, which will perform the complete \nevaluation of each semantic tree (using Algorithm 2) in time proportional to the size of the tree and \nin a near-optimal fashion. RELATION TO PREVIOUS WORK: The first implementation of attribute grammars \nis due to Fang [F], who used parallel processes, one for each semantic function. A deterministic approach \nwas first developed by Lewis, Rosenkrantz and Stearns [L&#38;R&#38;Sl] and by Bochman [B], who introduced \nan algorithm which traverses the tree in a depth-first left-to-right fashion, performing evaluation of \nall attributesin a single pass. Because of this restriction, the class of attribute grammars for which \nthis method applies (named L-attributed in [L&#38;R&#38;Sl ,2]) is rather limited. To increase the class \nof attribute grammars that can be efficiently evaluated, Bochman proposed to allow evaluation to occur \nIn several left-to-right passes such that on each pass the attributes evaluated by previous passes can \nalso be used. Jazayeri [Jl], observing that not all programming language features are amenable to evaluation \nfrom left to right, extended Bochman s method by intro\u00adducing the Alternating Semantic Evaluator that \nalternately makes left-to-right, then right-to-left passes. Jazayeri showed that certain left-recursive \nsituations could be evaluated by a single right-to\u00adleft pass, even though no fixed number of left-to\u00adright \npasses was sufficient. Kennedy and Warren [K&#38;W] noted that Jazayeri s extension still leaves many \nattribute grammars which cannot be evaluated by any fixed number of alternating passes. They exhibited \nan example of an attribute grammar with a left-recursive rule B+Bb, such that the first visit to a B-node \nson cannot be made until during the second visit to its B-node father. No method of evaluation in passes \ncan handle such a grammar, for which nested passes are required. Kennedy and Warren were the first to \ndevelop a deterministic approach in which the traversal o,rder is not deter\u00admined a priori, but is tailored \nto given attribute grammars by analyzing their dependency constraints. Their treewalk evaluator works \nlike a recursive routine with a tree node to visit as parameter; while at a node, the evaluator may evaluate \nsemantic functions or call itself recursively to visit sons. Their construction works only for a restricted \nclass of attribute grammars -the absolutely noncircular grammars. For a grammar in this class, the evalua\u00adtor \ns action at a node need not depend on the structure of the node s subtrees. In our terminol\u00adogy, the \nabsolutely noncircular attribute grammars are the ones for which our translator construction will yield \nLCA S without any conditional transfer instructions. For such grammars the evaluation algorithm can be \nsignificantly simplified by eliminating altogether the first phase, because in REFERENCES: this case \nthe characteristic graphs of the subtrees need not be computed. In [Wa] Warren introduced a general model \nfor deterministic evaluation of attri\u00adbute grammars, called the coroutine evaluator , and developed general \nmethods for constructing such evaluators. However, both the treewalk evaluator and the coroutine evaluator \n, are not near-optimal, because they may wander in the tree making a lot of futile visits to subtrees \nbefore finally reaching a node where a new attribute value can be procluced. In this paper, following \nthe deterministic approach suggested in [K&#38;W] and [W], we have pre\u00adsented a general construction \nof a near-optimal translator for any non-circulator attribute grammar. By introducing the characteristic \ngraph as the main tool for analysing (and representing) dependencies among attribute occurrences in a \nsemantic tree, we have been able to obtain a near-optimal evaluation strategy which takes into account \nthe structure of the subtrees of the node being processed. The trans\u00adlators introduced in this paper \nwill usually be smaller than the ones constructed in [W], dueto some reduction techniques used here (implicitly) \nwhich produce minimal LCA S (as opposed to the tree shaped evaluators in [W] which tend to be redundant). \nBecause of this and due to their being near optimal, our translators will be by far more efficient. COMPLEXITY \nISSUES: The translators constructed in this paper all work in linear time w.r.t. the size of the parse \ntree, provided that one unit of timeis charged for the evaluation of a semantic function, and assuming \na random access memory. In fact, as was noted in [L&#38;R&#38;Sl], one could always produce a linear-time \nevaluation strategy for each individual parse tree by analysing the dependencies in the tree at runtime; \none would then construct the compound dependency graph of the tree and perform a topolo\u00adgical sort on \nthat graph. By the method presented here the dependency analysis is done once ancl for all for each grammar \nduring the translator ccmstruc\u00adtion, thus saving us a considerable runtime cwerhead. As for the time \ncomplexity of the translator construction, admittedly, it may grow exponentially with the size of the \ngrammar. In fact, this is unavoidable in view of the inherent exponential complexity of the circularity \nproblem [J&#38;O&#38;R]l, as our construction will also detect circularity. The size of the translators \nmay also be exponential, as the set of characteristic graphs may be of exponent\u00adial cardinality (which \nis precisely what accounts for the exponentiality of Knuth s circularity test). A similar situation occurs \nwith respect to parser construction. For instance, it is a well known fact that LR(k) parsers can have \nnumber of states which is exponential with the size of the grammar. Moreover, the problem of determining \nwhether an arbitrary context-free grammar is LR(k) (with k unspecified) was shown to be NP-complete when \nk is expressed in unary (complete for non-deterministic exponential time when k is expressed in binary) \n[H&#38;S&#38;U]. Nevertheless, both the parser and the translator may be worth constructing once and \nfor all for each attribute grammar, to be later on jointly used for the efficient implementation of the \nentire transla\u00adtion process. Furthermore, both can be generated automatically when an attribute grammar \nspecifying a programming language and its translation is given as input to a compiler generating system. \n [A&#38;Ul ] Aho, A.V. and Unman J.D. Properties of Syntax Directed Translations . J. Corn uter Systems \nSc~., No. 3, pp. 319-364, * [A&#38;U2] Aho, A.V. and Unman, J.D. The Theory of Parsin g, Translation, \nand Compiling, Vol. 2, Prentice-Hall, Englewood Cliffs, N.J. (1973). [A&#38;U3] Aho, A.V. and Ullrnan, \nJ.D. Translationson a Context Free Grammar . Inform. Contr. 19,5, pp. 439-475, (1971). [B] Bochman , \nJ.V. Semantic Evaluation from Left to Right . Comm. of the Acut. Vol. 19, No.2, pp. 55-62,11976). [C&#38;H] \nCohen, R. and Harr, E. Automatic Genera\u00adtion of Near-Optimal Linear-Time Translators for Non-Circular \nAttribute Grammars , Technical Report #120, Dept. of Computer Science, Technion, Israel, March 1978. \n[D] Dreisbach, T.A. A Declarative Semantic Definition of PL360. UCLA-7289, Computer Science Dept. UCLA \n(1972). [F] Fang, 1. FOLDS, a Declarative Formal Language Definition System. STAN-72-329, Computer Science \nDept., Stanford Univer\u00adsity (1972). [G] Gerhart, S. Correctness -Preserving Pro\u00adgram Transformations \n. Proc. Second SIGACT-SIGPLAN Symp. on Principles of Programming Languages, Palo Alto, pp. 54-66 (1975). \n[Jl] Jazayeri, M. On Attribute Grammars and the Semantic Specification of Programming Languages. Ph.D. \nThesis, Computer and Inf. Sci. Dept. Case Western Reserve University (1974). [J2] Jazayeri, M. Live Variable \nAnalysis, attri\u00adbute Grammars, and Program Optimization: Draft, Depl;. of Comp. Sci., University of N. \nCarolina, Chapel Hill, N.C. (1975). [J&#38;o&#38;R] Jazayeri, M., Ogden, W.F. and Rounds, W.C. The Intrinsically \nExponential Complexity of the Circularity Problem for Attribute Grammars . Comm. of theACM, Vol. 18, \nNo.lZ pp. 697-706 (1975). [Kl] Knuth, D.E. Semantics of Context Free Languages . ~., No. 2, pp. 127-145 \n(1968). [K2] Knuth, D.E. Semantics of Context Free Languages: Correction . Theory J., No. 5, p. 95 (1971 \nv [K3] Knuth, D.E. Examples of Formal Semantics , Symp. on Semantics of Algorithm Lanuages, Lecture \nnotes in Mathematics, Vo. 188, Springer-Verlag, New York (1971). [K&#38;W] Kennedy, K. and Warren, S.K. \nAutomatic Generation of Efficient Evaluations for Attribute Grammars. Proc. of the 3rd ACM Symp. on POPL. \n[L&#38; R&#38;Sl] Lewis, P. M., Rosenkranz, D.J. and Stearns, R.E. Attributed Translations . J. of Comp. \nand S stem Sciences, vol. 9, No. 3, pp. 279-307 ~ 1974 [L&#38; RM2]Lewis, P. M., Rosenkranz, D.J. and \nStearns, R.E. Corn iler Design Theory. Addison Weslev + 1976). [L&#38;S] Lewis: P.M. and Stearns, R.E. \nSyntax directed Translations , JACM, vol. 15, No. 3, pp. 654-683 (1968). [N&#38;A] Neel, D. and Armichahy, \nM. Removal of Invariant Statements from Nested Loops in a Single Effective Compiler Pass . SIGPLAN Notices, \nvol. 10, No. 3, pp. 87-96~ REFERENCES(cent d) [P] Petrick, S.R. Semantic Interpretation in ;~~7:~QUEST \nSystem. IBM Res. Report, RC-4457 [w] Warre~, S.K. The Coroutine Model of Attri\u00ad bute Grammary Evaluation. \nPh.D. Thesis, Rice University, Houston, Texas (1976). [H&#38;S&#38;U]Hunt III, H.B. Szymanski, T.G. \nand Unman, J.D. On the Complexity of LR(k) Testing . ~, vol. 18, !Io. 12, pp. 707-726 (1975). \n\t\t\t", "proc_id": "567752", "abstract": "Attribute grammars are an extension of context-free grammars devised by Knuth as a formalism for specifying the semantics of a context-free language along with the syntax of the language. The syntactic phase of the translation process has been extensively studied and many techniques are available for automatically generating efficient parsers for context-free grammars. Attribute grammars offer the prospect of similarly automating the implementation of the semantic phase. In this paper we present a general method of constructing, for any non-circular attribute grammar, a deterministic translator which will perform the semantic evaluation of each syntax tree of the grammar in time linear with the size of the tree. Each tree is traversed in a manner particularly suited to the shape of the tree, yielding a near optimal evaluation order for that tree. Basically, the translator consists of a finite set of \"Local Control Automata\", one for each production; these are ordinary finite-state acyclic automata augmented with some special features, which are used to regulate the evaluation process of each syntax tree. With each node in the tree there will be associated the Local Control Automaton of the production applying at the node. At any given time during the translation process all Local Control Automata are inactive, except for the one associated with the currently processed node, which is responsible for directing the next steps taken by the translator until control is finally passed to a neighbour node, reactivating its Local Control Automaton. The Local Control Automata of neighbour nodes communicate with each other.The construction of the translator is custom tailored to each individual attribute grammar. The dependencies among the attributes occurring in the semantic rules are analysed to produce a near-optimal evaluation strategy for that grammar. This strategy ensures that during the evaluation process, each time the translator enters some subtree of the syntax tree, at least one new attribute evaluation will occur at each node visited. It is this property which distinguishes the method presented here from previously known methods of generating translators for unrestricted attribute grammars, and which causes the translators to be near-optimal.", "authors": [{"name": "Rina Cohen", "author_profile_id": "81100145877", "affiliation": "TECHNION - Israel Institute of Technology", "person_id": "PP14061328", "email_address": "", "orcid_id": ""}, {"name": "Eli Harry", "author_profile_id": "81100197775", "affiliation": "TECHNION - Israel Institute of Technology", "person_id": "P383276", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567752.567764", "year": "1979", "article_id": "567764", "conference": "POPL", "title": "Automatic generation of near-optimal linear-time translators for non-circular attribute grammars", "url": "http://dl.acm.org/citation.cfm?id=567764"}