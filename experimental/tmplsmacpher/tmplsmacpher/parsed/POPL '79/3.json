{"article_publication_date": "01-01-1979", "fulltext": "\n An Permission to make digital or hard copies of part or all of this work or personal or classroom use \nis granted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1979 ACM 0-12345-678-9 $5.00 Efficient Way to Find the Side Effects of Procedure Calls and the Aliases \nof Variables ~ John P. Banning + Stanford Linear Accelerator Center ~tanford, California 94305 Introduction \nOften when we are analyzing a pro\u00ad gram, for instance to gather information for optimizing transformations, \nwe need to know the effect of executing some element of the program on the program s variables. In the \nsimplest case, we might want to know what variables might be modified or referenced by the execution \nof a state\u00ad ment. The presence of procedures and pro\u00ad cedure calls in a language complicates this analysis \nin two ways. The first and most obvious way is that it is not apparent from looking at a call on a procedure \nwhat effect executing that call will have on variables. This is determined by the procedures which might \nbe executed as a result of making the call. Thus the execution of a procedure can have a side effect \non variables at the point from ah the procedure is called. The second way is that the parameter passing \nmechanisms associated with proce\u00addure calls can cause two distinct varia\u00ad bles to refer to the same location \nat the same time, in which case we say the the variables are aliases. The most common way this can occur \nis when a global varia\u00adble is passed by reference to a parameter of some procedure. During the execution \nof the procedure, the global variable and the reference parameter will refer to the same location. As \na result, a modifica\u00adtion or reference to one will be a modifi\u00adcation or reference to the other. The \nmain result of this paper in\u00advolves two methods, the first for finding side effects of procedure calls \nand the second for finding the possible aliases of variables. In their basic form these me- XThis work \nwas supported in part by the United States Department of Energy under contract EY-76-C-03-0515 and in \npart by Amdahl Corporation. + Author s present address: Amdahl Corpora\u00ad tion, 1250 East Arques Avenue, \nSunnyvale, California 94086. thods will find, using one pass over the text a program, flow insensitive \nside ef\u00adfects (defined below) and @ssible ali\u00adases. They will do this p~ecisely up to symbolic execution \nfor block-structured programs which have recursion and refer\u00adence parameters. The basic methods can be \nextended to cover flow sensitive side ef\u00adfects (with some 10ss of precision), exits from procedures (at \nthe expense of an ad\u00additional pass over the program), procedure parameters (with some restrictions), \nand a number of other features and constructs including dynamic naming, structured vari\u00adables, and certain \nkinds of pointer varia\u00adbles. We will discuss flow sensitive side effects here; the remaining extensions \nare covered in [BAN781. The basic method for finding side ef\u00adfects involves solving a flow problem on \ns graph. The graph s nodes correspond to procedures and the edges to calls between procedures. Associated \nwith each edge is a function which describes how the calling procedure s side effect depends on the side \neffect of the called procedure. By solving this problem (by any of a number of well known methods used \nin global flow analysis -see [uLL751) we assign to each procedure a generalized side effect for the corresponding \nprocedure. The side ef\u00adfects of a call on a procedure can easily be derived from the procedure s general\u00adized \nside effect. The basic method for finding aliases, which is completely separate from the side effect \ncalculation, involves a single global computation which finds all pairs of possible aliases. As explained \nin Sec\u00adtion 1.3, pairs of aliases are either trivial (e. g. x is an alias of x) or they derive from another \npair of aliases through the action of a call. The heart of the method is a recursive routine which, given \na pair of variables which are possible aliases, finds all the other pairs of possible aliases which are \ncre\u00adated from the original pair (and calls it\u00ad self with these new pairs). The routine is started by \ncalling it with all the trivial pairs of aliases. As well as requiring only one pass over a program s \ntext (regardless of the order of procedures) these algorithms tend to be computationally efficient because \nthey take advantage of the lack of connec\u00adtivity of programs. For instance the side effect algorithm \nw.i~.l. tend to be _faster than a transitive closure a l-~ithm such as Barth s [BAR781 because it takes \nadvan\u00adtage of the fact that the call graph of a program is usually very sparsely con\u00adnected. The alias \nalgorithm grows in the number of actual bindings of aliased vari\u00adables and considers only calls and parame\u00adters \nthat are actually related to alias pairs. The side effects with. which we will be concerned are as follows \nfor some statement s (perhaps a procedure call): MOD(s) is the set of variables whose value may be modified \nby an execution of s. REF(s) is the set of variables whose value may be inspected or referenced by an \nexecution of s. USE(s) is the set of variables whose value may be inspected by an execu\u00adtion of s before \nbeing defined by an execution of s. !2LE..@ is the set of variables hose value must be defined by every \nexecu\u00adtion of s. For the method presented here, an im\u00adportant characteristic of each side effect type \nis how the side effect of a collec\u00adtion of statements is derived from the el\u00adements of the collection. \nConsider the two statements X and Y in Figure 1. Both are composed of the same statements, A and B, but \nX requires B to executed after A and Y requires one or the other of A and B to be executed. Note that \nMOD(X) and MOD(Y) are both the same: MOD(A) + MOD(B). In other words the variables which may be modified \nby X (or Y) are just those that may be modified either by A or by B. Because of this we say that MOD \nis flow insensitive. USE and DEF, however, are different. The statement Y may use whatever variables \nA OrB use, but the statement X requires that A not define the variable tha;o~ ;I~s if X-is to use them. \nSimilarly # -. the--statement Xc defines what either A or B defines, but Y defines only those varia\u00adbles \nthat both A and B defines. Because USE and DEF depend on the flow through a piece of code as well as \nupon its constit\u00ad uents, we say that they are flow sens i\u00ad~. x:~ Y: AB B $Q 9 MOD(X) = MOD(Y) = MOD(A) \n+ MOD(B) REF(X) = REF(Y) = REF(A) + REF(B) USE(X) = USE(A) + (USE(B) -DEF(A)) USE(Y) = USE(A) + USE(B) \nDEF(X) = DEF(A) + DEF(B) DEF(Y) = DEF(A) * DEF(B) Figure 1: Composition of Side Effects . The important \nconsequence of this distinction is that, for a flow insensi\u00adtive side effect, the side effect of the \nwhole can be determined by first process\u00ading the whole and later determining the side effects of the \nparts and taking their union. If one of the parts is a call on a procedure which has not yet been scanned, \nthen the ability to defer determining the call s side effect is very useful. For flow sensitive side \neffects, however, this cannot be done. If determination of the side effect of a part is to be deferred, \nthen flow information about the whole must be retained so that the contribution of the part to the side \neffect of the whole can be determined later. The-computation of flow insensitive side effects and aliases \ngiven in this pa\u00adper yields the most precise results Possi\u00adble under the assumption that any path through \na procedure can be taken when the procedure is called and that the path taken is independent of the call \nwhich in\u00advoked the procedure. F1OW sensitive side effects are found with less precision in ways that \nare discussed below. In the following sections we present a model for the kind of programs these me\u00adthods \nhandle and use this model to show that the methods are correct. , .Block Structured Proqrams This section \ndevelops a simple model of a typical block structured program and its execution. The model is needed \nto provide a foundation for talking nlore pre\u00adcisely about aliases and side effects and for proving the \nmethods of finding them. The model encompasses only those aspects of programs which are needed here. \nFOr the present we will consider block struc\u00adtured programs with nesting of procedures, parameter passing \nby reference, and recur\u00ad s ive calls. Notions of flow through a procedure are discussed later; GOTO s \nout of procedures and procedure parameters are considered in [BAN78]. A block structured program contains \na set of procedures which are arranged as nodes of a rooted tree. The root of the tree is called the \nmain procedure. The direct descendants of any proce%re node are those procedures which-are directly declared \nin that procedure. Within each procedure is declared a set of variables each variable either be\u00ading a \nsimple variablel or reference param\u00ad . ~. We s3 ay that these-var~ab iies are local to the procedure. \nThe variables contained in all the ancestors of proce\u00addure are qlobal to that procedure, and the local \nand global variables of a procedre together are the visible variables for that procedure. Likewise, the \nprocedures which are directly contained in a given procedure or its ancestors are visible to that proce\u00addure. \nEach procedure also contains a number of statements which can modify or refer\u00adence variables and which \ncan call other procedures. Any variabies which are af\u00adfected by a procedure s statements must be visible \nto that procedure. The effect on variables of statments which lie on some path through a procedure is \nsummarized by a number of immediate side effects of the _ procedure. These immediate side effects exclude \nthe effects of any called proce\u00addures. Thus the immediate modification side effect, IMOD(p) , gives the \nvariables modified by statments contained in proce\u00addure p. Statements which call other proce\u00addures, refered \nto as call sites, designate two things. First, they designate a pro\u00adcedure to be called. This procedure \n(the called procedure) must be visible to the procedure containing the call site (the calling procedure). \nSecond, for each ref\u00aderence parameter of the called procedure, the call site must designate an actual \npa\u00adrameter to be bound to the reference pa\u00adrameter. This actual parameter must be a variable which is \nvisible to the calling procedure. \\ Figure 2 gives an example of a PASCAL program and Figure 3 shows \nthe correspond\u00ading program model. Given the idea of call sites, we can introduce the notion of a call \nchain, which is a sequence of call s-each of which calls the procedure containing the 1 The term simple \nvariable is used here to distinguish them from reference parame\u00adters rather than to suggest lack of structure. \nPROGRAM p; @ x, Y, z: int.ager; PROCEDURE p3 (VAR x3, Y3: integer); BEGIN IFx=y THEN x3:=5 ~ y3 := 5; \nx := y3; ~; PROCEDURE pl (VAR yl: integer); +?#kRxl, zl:=teger; PROCEDURE p2 (VAR x2: integer); VAR \ny2: int-ezr; BEG= IF Z1 = Z THEN p1(x2); {s7} EILSE Pi(Z); {s8} y2 := xl; ~; BEGIN {pi) IF X1=5 -P2(Z) \n{s4} fiSE IF Xl > 5 THEN {s5} . p2(y1) p3(yl,y) ; {s6} xl := yl; ~; BEGIN Pi(Y) ; {s1} pi(x); {s2} p3(y,z); \n{s3} END . . Figure 2: Example PASCAL Program simple x, y, z calls sl, s2, S3 parameters x3, y3 parameter \nyl simple xl, yl calls s4, s5, S6 parameter x2 calls s7, s% call called binding site procedure actual \nformal S1pl yl Y S2 pl xyl S3 p3 Yx3 z y3 S4 p2 zx2 S5 p2 ylx2 S6 p3 ylx3 y3 S7 pl x2yl S8 pl zyl Y \nFigure 3: Program Moclel for Example Program next. Thus the sequence of call sites S1. ..sn is a call \nchain iff for every i, l<i<n, Si calls the procedure containing Si+l . We insist that we be able to \nreach every starting words a call call in that chain site via a sequence the main procedure. for every \ncall s there S1. ..sn such that sl of calls In other must be is con\u00ad tained in the main procedure and \ns = Sn. This captures the static structure of a program; now we need to look at how such a Pro9ram can \nbe executed. The key components in the execution of a program are a set of activations in which procedures \nexecute and a set of lo\u00adcations to which variables are mapped?n each ~ctivation. We can think of these \nlocations as containing values for the variables. The set of activations is also arranged in a tree structure \nand is con\u00ad structed from the executed program as fol\u00adlows. We start with an activation in which the \nmain procedure will execute. This activation is the root of the tree and within it we map each of the \nmain procedure s local variables to a unique location. Any activation already in the tree is given a \ndescendant activation for every call site that can execute in it. (A call site can execute in an activa\u00adtion \nif it is contained in the proce\u00addure executing in that activation. ) This descendant activation is said \nto be called by the call site from the original activation and the descendant and all its descendants \nare said to be the descendants of the original activa\u00adtion due to the call site. The proce\u00addure ~c~is \nexecuted in this new ac\u00adtivation is the one called by the call site. The mappings for the variables visible \nto this procedure are con\u00adstructed as follows. Simple local var\u00adiables are mapped to new unique loca\u00adtions. \nReference parameters are mapped to the same location as their actual parameters in the ancestor activation. \nGlobal variables are mapped to the same location as they wer~ in the immediate ancestor activation. \n2This mapping of global variables does not exactly follow the semantics of block structured languages. \nIn fact we should find the static nest activation and use its mappings. What we are doing here is exactly \nequivalent, however, because ev\u00adery activation betwen the static nest activation and the newly created \nactiva- Figure 4 gives a fragment of the ac\u00adtivation tree for the program of Figure 2. This tree of \nactivations can be thought of as a skeleton in which all executions of the associated program could be \nembedded. Execution would proceed as follows: Start with the execution of the main procedure in the root \nactivation. Every time a call site is executed by some procedure in some activation t, the called procedure \nstarts executing in that immediate descendant activation which the call si$e calls. All loca\u00ad tions mapped \nto by simple local varia\u00adbles in the new activation are allo\u00adcated just prior to beginning execu\u00ad = tO \nprocedure p mapping x~ll Y ~12 Z 13 cl t2 t3 called by S1 called by S2 called by SZ procedure pl procedure \npl proced-jre p: mapping mapping mapping x 11 x~ll x~ll Y 12 Y 12 Y ~12 z~13 z~13 Z 13 xl~14 x1--+.16 \nx3-+-12 yl 12 yl +11 y3~13 z 1 15 z 1 17 t4t5 t6 called by S4 called by S5 called by S6 procedure p2 \nprocedure p2 procedure p3 mapping mapping mapping x~ll X n X n Y 12 Y 12 Y 12 Z 13 z~13 z 13 X1 14 x \n1 14 x3 12 yl 12 y1~12 y3 12 Z1 15 z1~15 x2~13 X2 12 y2_18 y2 19 ~igure 4: Part of the Activation Tree \nfol the Example Program tion must map these global variables to the same location. This is proved in \n[BAN78] . When a procedure returns from ex\u00adecuting in an activation, all locations allocated in the activation \nare freed and their values lost. Execution re\u00adsumes in the immediate ancestor activa\u00adtion. Finally, when \na procedure execut\u00ading in an activation modifies or refer\u00adences a variable, the value in the lo\u00ad cation \nmapped to by that variable is modified or referenced. Some ideas that will be usefull in talking about \nthis model are an activation chain, realization, and passing of varia\u00adbles. An activation chain is a \nsequence of activations, each ~ich is the di\u00adrect descendant of the previous one. We can think of any \nactivaion chain which starts with the Koot activation as being a snapshot of the activation record stack \nduring some execution of the program. We note that for every activation chain there is a corresponding \ncall chain which is constructed by taking, in order, the call sites which called each of the activations. \nThe activation chain is said to be a realization of the corresponding call chain. We note some easily \nproved properties of call chains and activation chains: 1. Each activation chain realizes a unique call \nchain. 2. Every call chain is realized by at least one activation chain. 3. In any activation t in \nwhich a call site s can execute, there is a realization of any call chain starting with s whose first \nactivation is a direct descendant of t.  Finally, a call site s is said to ~ a variable x to a variable \ny iff 1. variables x and y are the same variable and are global to the procedure called by s, or 2. \ncall site s binds x as an actual parameter to reference parameter  Y. This definition is motivated \nby the fact that reference parameters and global variables in an activation receive their mappings from \nthe immediate ancestor acti\u00advation. In other words, if call s passes variable x to variable y, then in \nany ac\u00adtivation called by S, y will map to the same location that x does in that activa\u00adtion s immediate \nancestor. Similarly, if a variable x maps to the same location in activation k as variable y does in \nt s im\u00admediate ancestor, then the call site which called t must pass y to x. Aliases The first use of \nthis model is a more precise definition of alias. Definition. Two variables are aliases in some activation \nif the are both mapped to the same location in that activation. Two variables are possible gliases if \nthere is some activation in which they are aliases. The first result about aliases (which is proved in \n[BAN78]) is, that if two vari\u00adables are possible aliases, then for every procedure in which both variables \nare visible, there is some activation for that procedure in which the variables are ali\u00adases. Thus the \nfact that two variables are possible alises affects every proce\u00addure in which both variables are visible. \nWe call this the principle of universality of alias. Although this helps us in applying possible alias \ninformation, it doesn t tell us how to find it. In order to fig\u00adure out how to find possible aliases, \nwe will start by seeing how they arise. First we note that if two variables, x and y (x # y), are aliases \nin some acti\u00advation, then neither can be a simple local variable, as these are mapped to unique locations. \nThus they must be either global variables or local reference param\u00adeters. If x and y are aliases in some \nac\u00adtivation, this means that the call which created that activation must have passed variables x and \ny to x and y, and x and Y must be aliases in the immediate ances\u00adtor activation. Lx and y could have \nbeen the same variable, in which case we say the variable is a trivial alias of it\u00ad  self.) This is \na necessary and sufficient condition for two distinct variables to be aliases in an activationlr and \nit forms the basis for a necessary and sufficient con\u00addition for two distinct variables to be possible \naliases. Two variables x and y (x # y) can be possible aliases iff there is a call site s and possible \naliases x and y such that s passes x to x and y to y. To establish x and y as possible aliases what we \nmust find is a chain of possible alises leading to x and y from some x and y whibh are the same variq\u00ad \nble. The following theorem states this fact. Theoreg (Alias). For two variables, x and y, to be possible \nalises, it is necessary and sufficient that there exist a sequence of calls, sl. ..sn~ and a sequence \nof pairs of variables, (Xo,yg) . . . (Xn,yn) ~ such that Xa = YOt Xn =X, Yn = Y,, and for every i, l<l<nr \ncall i passes i.ql tO Xi and yi_l tO yi. Proof. PROCEDURE Visit (xry: variables); Sufficiency. We will \nprove by induc\u00adtion that all pairs of variables in the chain are possible aliases. Clearly X. and yo, \nbeing the same variable, are pos\u00ad sible aliases. If xi_l and yi_~ are pOS\u00ad sible aliases, then the universality \nof alias tells us that there is some activa\u00adtion t for the procedure containing call in which and yi_l \nare aliases. i i-1 Because Si passes to xi and Yi-1 0 i-1 Yi, the activation called by si from t must \nmap xi and yi to the same location as xi_l and yi-l. Thus Xi and yi are possi\u00ad ble alises. Necessity. \nWe have some activation t in which x and y map to the same location. We can construct the sequence of \ncalls and pairs of variables in a backwards direc\u00adtion (from n to 1) in the following way. Start with \nXn = x and Yn = y. Because Xn and yn map to the same location in activa\u00ad tion t, one of the following \nmust hold: 1. Variables Xn and yn are the same variable (in which case we have constructed our chain \nand are done) . 2. Neither nor Yn is a local  n simple variable of the procedure executing in activation \nt. (If . one were: the fact t15at it map\u00adped to the same same location as the other would force the first \ncase to be true.) If the first case does not hold, then we take Sn to be the call which called t and \nto be the variables and yn-l n-1 which are passed to Xn and yn by call Sn. These variables must maD \nto the same loca\u00adtion in the immediate ancestor of t and thus we can repeat the same argument given for \nxn and yn. If we continue back in the ancestors of activation t, we must eventu\u00adally come to an activation \nin which the first case holds and we are done. If we did not reach such an activation, we would eventually \ncome to the activation for the main procedure, in which every variable is local and simple. Given this \nresult, there is a fairly straightforward way to find all pairs of possible alises: use a recursive proce\u00addure \nto do a depth first search of all the chains of pairs of possible aliases, starting with the trivial \npairs. The pro\u00adcedure Visit, which follows, does just this. BEG IN IF (xfy) are not marked as possible \naliases THEN BEGIN Mark (xry) as possible aliases; FOR every (x ,y ) # (x,y) for which there is a call \ns that passes xto x and yto y DO visit(x ~y ); END ; END: (* Visit *)  FOR every variable x DO Visit(x,x); \nThus Visit is called with arguments and y once it has been established that X. and y are possible aliases. \nIf Visit finds that x and y have not yet been vis\u00adited it marks them as possible aliases and searches \ndeeper in the chain they are on. In order to implement Visit, we must give careful consideration to its \nmain loop. We start by noting that there are three cases for the relationship between (X,y) and (x ,y \n) and the call site s. these are as follo~s: 1. x is bound as an actual to x by s and y is bound as an \nactual to Y by S. 2: y and y are a single variable which is global to the procedure called-by s and s \nbinds x as an actual to reference parameter x . 3. x and x are a sing le variable which is global to \nthe procedure called by s and s binds y as an actual to reference parameter Y . These three cases give \nrise to the following three loops as an implementation of the main loop of Visit: FOR every (x ,y ) # \n(xry) for which there is a call which binds x to x and yto y DO Visit(x /y ); FOR every (x ,y) for \nwhich there is a call which binds x to x and which calls a procedure to which y is global DO Visit(x \n,y); FOR every (x,y ) for which there is a call which binds y to y and which calls a procedure to which \nx is global DO Visit(x,y ); Aliases and Side Effects Figure 5 shows how visit would proc\u00ad ess the program \nof Figure 2 with these i7isit With Derived From Duplicate three loops. :alled Alias Via Alias Call on \nFrom Pair Call Pair Visit Line . Before considering the question of how to find the side effects of \ncalls, we should consider how this information is to be used, as it will have an effect on ex\u00adactly what \nwe want to look for. What we often want to do is to determine if the execution of two pieces of code \ncan con\u00adflict in some way. Consider the following example: VAR a,b: integer; PROCEDURE p (VAR x: integer); \nBEGIN ....= a 5; ... ... b/3 ... END; ... p(a); ... p(b); ... We might want to know if there is any \nac\u00ad tivation of procedure p in which an execu\u00ad tion of a:=5 will modify a location which is referenced \nby an evaluation of b/3 . (Perhaps we are trying to do com\u00ad mon sub-expression elimination and a:=5 lies \non a path between two evaluations of b/3 .) Because locations and activations are runtime entities, \nwe try to answer the question of conflict by associating sets of affected variables with each statement \nand checking the sets for common members. In doing this we must be carefull, how\u00ad ever. The set of variables \nwhich may be modified by a:=S is {a,x} (because of the call p(a) ). The set of variables which may be \nreferenced by b/3 is {b,x] (because of the call p(b) ). If we were to compare these two sets, we might \ncon\u00ad clude that there is a conflict between a:=5 and b/3 . This is not correct, however, for a and b, \nbeing simple varia\u00ad bles, can never refer to the same loca\u00ad tion. Thus there is no activation of p in \nwhich a:=5 can modify a location refer\u00ad enced by b/3 . This same problem arises if we replace a:=5 with \na procedure call which modifies a and b/3 with a proce\u00ad dure call which references b. What we need is \na tighter definition of the side effct of a piece of code (such as a proceaure call) . The definition \nshould include only variables which are potentially affected in every activation (x,x) ;; -\u00ad2 (yl,x) \n(x,x) 2 (X2,X) S5 (yl,x) * 2 (yl,x) S7 (x2,x) 2 (x3,x) S6 (yl ,x) (YJY) ;; -\u00ad 2 (x3,y) (y#Y) 2 (yl,y) \nS1 (Y,Y) 1 ~~~:~y) S6 (yl,y) 2 S5 (yl,y) * 2 (yl,y) S7 (X2,Y) * 2 (x3,Y) S6 (yl,y) 2 (y3,y) S6 (Y,Y) \n(2,2) ;; -\u00ad2 (X2,2) (2,2) 2 (yl,z) S7 (X2,2) * 2 (X2,2) S5 (yl,z) 2 (x3,2) S6 (yl,z) 3 (yl,x2) ;: (yl,z) \n2 (y3,z) (2,2) 2 (Y1,Z) S8 (2,2) (Xl,xl) ---\u00ad (yl,yl) ;; -\u00ad2 (x2,yl) (yl,yl) * (21,21) -\u00ad -\u00ad (X2,X2) \n-\u00ad -\u00ad (y2,y2) -\u00ad -\u00ad (X3,X3) -\u00ad -\u00ad (y3,y3) -\u00ad -- Figure 5: Alias Run Against the Example Program while \nincludino enouqh variables to cover every potentia~ly af~ected location in ev\u00adery activation. We call \nsuch a side ef\u00adfect a direct s~de effect (as it essen\u00adtially excludes indirect side effects due to aliases) \nand define it for modification as follows. Definition. The direct modification side effect for a statement \ns (denoted DMOD(s~) met of variables which meets the fol\u00ad lowing two criteria: 1. For every activation \nt in which s can execute and every location 1 which the execution of s can potentially modify in t, there \nis some variable in DMOD(S) which maps to location 1 in ac\u00adtivation t. 2. For every variables x in DMOD(S) \nand every activation t in which s can execute, an execution of s in t must potentially modify the location \nmapped to by x in t.  In order to establish a potential conflict between two statements, we take their \ndirect side effects and see if there is a variable in one that is a possible alias of a variable in \nthe other. That this does find conflicts is stated for DMOD in the following theorem. The same result \nis shown in the same way ~or any combination of direct side effects. Theorem (Conflict). Given two statements, \nsl and S2, in the same procedure, for an execution of S1 and S2 to conflict in some activation, it is \nnecessary and sufficient that there is a variable V1 in DMOD(S1) and a variable V2 in DMOD(S2) such that \nVI and V2 are possible aliases. Proof. Necessity. If S~ and S2 conflict, then there is an activation \nt and a loca\u00ad tion 1 such that both sl and Sn may modify 1 in t. By the definition of DMOD there must \nbe some variable V1 in DMOD(sl) and variable V2 in DMOD(S2) which both map to location 1 in activation \nt. Because VI and V2 map to the same location, they are possible aliases and the result follows. Sufficiency. \nAssume variable VI is in DMOD(S1) and variable V2 is in DMOD(S ) 2 with VI and V2 being possible aliases. \nBy the universality of alias we know that there is an activation t in which V1 and V2 both map to the \nsame location and in which sl and S2 can execute. By the defi\u00ad nition of DMOD it follows that both S1 \nand S2 can modify this common location and thus conflict. u The remaining question for calls is just \nwhat does it mean for a call site to modify a location when executed in some activation? When a call \nsite is executed in some activation, the (directly and indirectly) called procedures will execute in \nthe des\u00ad cendants of that activation due to the 3This concept is usefull only for side ef\u00ad fects which \ntalk about what could poten\u00ad tially happen (e.g. MOD, REF, usE). It could be applied to side effects \nsuch as DEF which talk about what must happen for every execution in every environment, but 13;3::T) \nwould always be the same as . call site. In each of these descendant activations, locations may be modified. \nThose locations which are not freed by the time we return to the original activation are considered to \nhave been modified by that execution of the call site. (Those locations which are modified but freed \nbe\u00ad fore returning to the original activation have no effect in that activation and are ignored.) This \nleads to the following definition: Definition. A call site s g modify lo\u00adcation 1 when executed in activation \nt if there is an activation chain tl...tn such that s calls tl frOm t, 1 can be modified in tnr and 1 \nis not allocated in any of tl through tn. Side Effects Now that we know just what we are looking for, \nwe can try to find a condi\u00adtion for a variable to be in a c 11 site s f direct modification side effect. \nTo get a handle on this problem, we use two ideas introduced above: 1. Call chains are used to track \ndown the procedures which might be called indirectly as a result of making a call, and  2. passing of \nvariables is used to follow variables which are visible in the calling proce\u00addures to variables modifi~d \nin called procedures.  We start by generalizing from single calls to call chains the idea Of-passing \nvaribles. A call chain S1...sn i? said to PS?.E.E variable x to variable Y iff there is a sequence of \nvariables Xfl. ..xn such that x = XD, y = Xnr and for every i, l<i<n, Si - to xi. In other words, each \n asses i-1 successive call in the call chain passes a successor to the original variable one step farther \non. As we noted before, if variable x is passed to variable y by call site s, then the mapping of y in \nany activation called by s will be the same as the mapping of x in that activation s immediate ancestor. \nA similar phenomenon occurs for variables passed by a call chain. Take tl... tn to be an activation chain \nwhich realizes a call chain S1. ..sn. If S~...Sn passes a 4 This section will consider the modifica\u00adtion \nside effect explicitly; exactly the same considerations apply to the refer\u00adence side effect. variable \nx to a variable y, then the map\u00adping of y in activation tn is the same as the mapping of x in the immediate \nancestor of t~. This is.easily proved by induction given the result for passing variables by a single \ncall. It induction) and v location is for in also that, which tn true if v as u there is (and mapped \nis in easily are varito the shown ables the saimmediate by u me ancestor of tl, then S1...sn must pass \nu to v. This result gives rise to a fairly straightforward condition for DMOD which is stated in the \nnext theorem. Theorem (DMOD). The definition of DMOD(S) for call site s is satisfied by the set of all \nvariables x for which there is a call chain c = s~...sn and variable y such that s~ = S, cpasses xto \ny, and ymay be im\u00ad mediately modified by the procedure called by Sn. Proof. First, given an activation \nt and lo\u00adcation 1 such that s modifies 1 in t, we must show that the set defined by the theorem contains \na variable x which maps to 1 in t. If we have such an activation and location, then there must be an \nacti\u00advation chain tl...tn such that s calls tl from t and 1 may> be modified in tn. Take c = S1...sn \nto be the call chain realized by tl... tn and y to be the variable which maps to 1 in tn. Clearly c \npasses x to y and y may be immediately modified by the procedure called by Sn. Thus the result holds. \nN(?Xt, given a variable x in the set defined by the theorem, we must show that for every activation t \nin which s can ex\u00adecute, executing s in t may directly mod\u00adify the location mapped to by x in t. If we \ntake the realization t~... tn of the call chain c such that s calls tl from t, we note that the variable \ny will map to the same location in tn that x maps to in t and that this location may be modified in tn. \nFurther the location cannot be al\u00ad located in tl... tn as only locations not mapped to in the ancestors \nof an activa\u00adtion can be allocated in the activation. Given this condition, how do we find all the variables \nwhich meet it? Finding eve ry call chain and all the variables passed allong each to a modifying proce\u00addure \nwill be prohibitively expensive un\u00adless there is some way to find lots of them at the same time. In fact \nthere is such a way: Global flow analysis on the reverse calls graph of a program. A program s reverse \ncalls graph has a node correspondi~ each procedure in the program and a directed edge from node p to \nnode q for every call in procedure q which calls procedure p (thus the reverse of the calls graph). A \npath in this graph is a series of edges, el. ..en, such that ei is directed towards the node that ei+l \nis directed away from (for all i, l~i<n). The path is said to lead from the node which el is di\u00ad rected \nfrom and to the node that en is di\u00ad rected towards. What we use this graph for is to help us assign to \neach procedure node a gener\u00adalized side effect from which we can cal\u00adculate the direct side effect of \nany call on that procedure. The direct side effect of any call on a procedure is the set of all variables \nwhich are passed by the call to some variable in the procedure s gener\u00adalized side effect. In order to \nfind these generalized side effects, we construct a $1OW problem for the reverse calls graph. This flow \nproblem involves doing two things to the reverse calls graph. The first is to as\u00adsign to eac~_ procedure \nnode the set of varibles immediately modified by that pro\u00adcedure (IMOD(P)). This can be thought of as \nan initial approximation to the gener\u00adalized side effect. The second element. is to assign to the edge \nfor a call site s a function for that call site which maps sets of varia\u00adbles into sets of variables \nas follows: f5(X) = {PASS(S,X) I X ~ X*GLOPARM(S)} where PASS(S,X) is the variable passed to x by call \nsite s and GLOPARM(S) is the set of variables global to the procedure called by s or reference parameters \nof This is also called p;~g~at;g:er things) an information problem [GRA761, a global flow problem [ROS781, \nor a path problem on a directed graph [TAR75]. See [uLL751 for a survey of these problems and their solution \nme\u00ad thods. [ROS781 looks the most like what is done here. [BAN78] shows how the problem can be stated \nin terms of the formalism of [GRA76]. that procedure.6 Figure 6 shows the reverse calls graph and edge \nfunctions for the program of Figure 2. With a function associated with each edge, we can define a &#38; \nfunction fE fOr any path E = el...en as follows: o of =fel ... en., E What we want to do is find the \nmeet over all paths solution to this flow prob-Z This solution assigns to each node p the union of fE(IMOD(q)) \nfor every path E to node p from any node q. We will call the set assigned to node p by this solu\u00adtion \nGMOD(P) and will show that it is in fact the generalized side effect mentioned above. (The meet over \nall paths solution to the flow problem of Figure 6 is shown in Figure 7.) In showing this we first note \nthat the path function for a given path maps variables to variables in the same way that the corresponding \ncall chain passes variables to variables. This gives us the following two lemmas. Lemma If there is a \ncall chain s~...sn which passes variable x to variable y and a set of variables Y which contiains y, \nthen x is in fE(Y) where fE is the path function for the path corresponding to S1. ..sn. Lemma If variable \nx is in fE(X) for some path function fE and set of variables X, then the call chain S1...sn corresponding \n to path E must pass x to some variables in x. Both of these lemmas have straight\u00ad forward induction \nproofs which are based on establishing the obious correspondence between calls in the call chain with \nedge functions in the path function. Given these lemmas, we can easily show that DMOD(S) can be calculated \nfrom the general side effect of the procedure called by s. 61t can be shown [BAN78] that these func\u00adtions \nare members of a set Of functions which is distributive with respect to union and is closed under union \nand com\u00adposition. This is important from the point of view of solving the global flow analysis problem. \nUnfortunately, these functions are not fast in the sense of Graham and Wegman [-6]. fl(x) = PAss(sl,x) \nI X e X*GLOPARM (s1)} =x* {x,Y,z} +IF Y1exTHEN {y} f2(X) = {PASS(S2,X) I X e X*GLOPARM(S2)} =X* {x,y,z} \n+IF yl eXTHEN {X) f3(X) = {PASS(S3,X) I X e X*GLOPARM(S3)} =x* {x,Y,z} +IF X3 e xTHEN {y} +IF y3exTHEN \n{Z} f4(X) = {PASS(S4,X) I X e X*GLOPARM(S4)} = x * {X,y,z,xlryl,zl}} +IF X2 e xTHEN {Z} f5(X) = {PASS(S5,X) \n] X e X*GLOPARM(S5)} = x * {X,y,z,xl,yl,zl} + IF X2 e X THEN {yl} f6(X) = {PASS (S6,X) I x e X*GLOPARM(S6)} \n= x * {x,Y,z] + IF X3 e x THEN {Y1} + IF y3 eXTHEN {Y} f7(X) = {PASS(S7,X) [ X ~ X*GL0PARM(S7)} = X \n* {x,y,z} + IF yl ~ X THEN {x2] f8(x) = {PASS(S8,X) I x e X*GLOPARM(S8)} =X* {X,y,Z} +IF yl eXTHEN {Z] \nFigure 6: Flow Problem for the Example Program GMOD(Q) = {} GMOD(P3) = {x,x3rY31 GMoD(p2) = {x,yrx2,z} \nGMOD(P1) = {x,YrYl,z} DMOD sl ) = {X,y,zl MOD(S1) = {x,y,Z] DMOD S2 ) = {X,y,z] MOD(S2) = {Xry,zl DMOD \nS3 ) = {X,y,z} MOD(S3) = {X,y,zl DMOD 54) = {X,Y,ZI MOD(S4) = {X,Y,Z,YII DMOD 55) = {X,y,yl} MOD(S5) \n= {yrY,Yl} DMOD s6) = {x,Y,Y1} MOD(S6) = {X,Y,Z,YII DMOD(S7) = {X,Y,Z,X2} MOD(S7) = {x,y,z,x21 DMOD(S8) \n= {X,Y,Z} MOD(S8) = {X,Y,Z,K21 1 Figure 7: Solution to the Flow Problem Theorem For a call site s, the \ndefinition of DMOD(S) satisfied by the set fs(GMOD(p)), w~~re fs is the edge function for call s, p \nis the procedure called by s, and GMOD(p) is the meet over all paths solution to the above global flow \nanalysis problem. Proof. The above two lemmas and the defini\u00adtion of meet over all paths solution es\u00adtablish \nthat GMOD(p) contains the set of variables immediately modified by p and all variables x for which there \nis a call chain S1...sn and variable y such that sl is contained in P, s.l. ..sn passes x to y, and y \nis immediately modified by the pro\u00adcedure called by Sn. Given this and the definition of fs, the DMOD \ntheorem estab\u00ad lishes that fs(GMOD(p)) satisfies the def\u00ad inition of DMOD. ~ Flow Sensitive Side Effects \nUnlike MOD and REF , the side effects DEF and USE deDend on the flow through a procedure as weil as the \nstatements in the procedure. For this reason the method of this paper cannot find these side effects \nprecisely, although it can find a safe ap\u00adproximation. In order to apply the present method we must find \nsummary information about flow through each of the procedures in a program. This summary information \nmust be of a nature that it can be used in the generalized side effect calculation with\u00adout disrupting \nthe standard solution me\u00adthods. For DEF we collect the following quantities for each procedure p: IDEF(P) \nis the set of variables defined by statements directly contained in p along every path through p. The \nef\u00adfects of procedures called by p are excluded. Thus every variable in IDEF (p) will be defined by some \nstatement in p sometime during every execution of p. MCALL(P) is the set of procedures which must be \ncalled during every execution of p. It is not required, however~ that the call be via the same call site \nevery time. MBIND (p ,v) is defined for exactly those variables v which are reference pa\u00adrameters of \nprocedures called by p. MBINEf(P,v) contains those variables which will be bound to v by some call from \np during every execution of p( but not necessarily by the same call each time). Thus IDEF corresponds \nto IMOD in the basic model and MCALL and MBIND hold the limited flow information that will be used. Figure \n8 gives an example of IDEF, MCALL, and MBIND for a procedure p. The systematic derivation of IDEF, MCALL, \nand MBIND information requires the use of global flow analysis on each procedure (see [ULL75]). Ficlure \n8 also shows the kind of side effect information which is lost because of the limited flow information. \nIf pro\u00adcedure q4 defines y, for instance, then y will be defined along both branchs of the IF statement \nin p and thus p will define Y. However this fact is not reflected in the saved flow information (y is \nnot in IDEF ahd q4 is not in MCALL), and thus this method will not discover it. A simi\u00adlar difficulty \ninvolving two procedure calls exists if p3 and p4 both define y. In this case y is defined bv P, but \nthe fact is missed because neith&#38;r-p3 nor p4 is in MCALL. VAR u, w , x, y ,z: Integer; PROCEDURE \nql (VAR xl: Integer); BEGIN ... ~~ PROCEDURE q2; BEGIN . . . ~; PROCEDURE q3 (VAR x3: Integer); BEGIN \n... _Ew PROCEDURE q4; BEGIN . . . ~; PROCEDURE p (VAR a, b: Integer); BEGIN w := 5; j_F ? THEN BEGIN \nql(x); q2; q3(x): := :=5; z:=5; a 5; END ~--BEGIN Y ql:~); q:(x): qb; z ;:=5 ; END; ~; IDEF(p) = {w,z] \nMCALL(P) = {al, q3} MBIND(P,x1) = {} M131ND(p,x3) = fx~ Figure 8: Example of Elements of Prograri Model \nfor DEF A second imprecision was discussed in Section 1.3 and arises if reference param\u00adeters a and \nb are aliases during some ex\u00adecution of p. In this case, they are both defined by p, but only for that \ncall which causes them to be aliases. To deal with these problems precisely, one must turn to a much \nmore complicated method, such as that of Rosen [ROS79]. Given the quantities IDEF, MCALL , and MBIND, \nwe construct a slightly different reverse calls graph, and assign different functions to each edge. The \ngraph still contains all the program s procedures as nodes, but the edges are different. There is a single \nedge from procedure p to pro\u00adcedure q iff p is in MCALL(q). Thus we have the reverse must call graph. \nThe initial assignment of sets of variables to nodes assigns IDEF(p) to each node p (just as IMOD(P) \nwas assigned be\u00adfore) . The function assigned to an edge from pto qis (x) = Pq {MPASS(q,p,x) \\ X ~ X*GLOPARM(P)} \n where MPASS(q,p,x) is {x} if x is global to procedure p and is MBIND(q,x) if x is a reference parameter \nof p. GLOPARM(p) is the set of variables which are global to procedure p or reference parameters of p. \nThe meet over all paths solution to this problem is found just as before, yielding a generalized defines \nside ef\u00ad fect, m. For any call site s which calls procedure p, we can find DEF(s) as before by applying \nthe edge function for call s (from the GMOD calculation) to GDEF(p): DEF(s) = Fs(GDEF(P)). This method \nis based on the fact that DEF talks about what must happen every time a call is made. Thus we look only \nat what is defined, called, or bound during every execution of a procedure, and propa\u00adgate side effects \naccording to these re\u00adstrictions. The proof of this method (which can be found in [BAN78]) follows the \none for MOD, using must call chains and the idea that such a ~n must ~ a variable x to a variable y. \nFor the side effect USE, we use a similar process, except that we must col\u00adlect more complex information \ndue to USE S dependence on DEF. The summary informa\u00adtion for USE is collected in two steps. In the first \nstep, during the pass over a program s text, we collect information about variable uses vtithout knowing \nthe defines side effects of calls. This in\u00ad formation is collected using the same in\u00ad traprocedural flOw \nanalySiS use to find DEF summary information. Once we have finished the DEF calcu\u00ad lation, we combine \nthis information with DEF(s) for all call sites to get the fol\u00adlowing information: IUSE(P) is the set \nof variables which may be referenced by statements di\u00ad rectly contained in procedure p with\u00ad out first \nbeing defined by statements in p. The effect of called proce\u00ad dures is only taken into account for defines. \n PDEF(s) is the set of variables always defined by statements in the proce\u00ad dure containing call site \ns before s is executed. This includes defini\u00ad tions due to other call sites in the procedure. The graph \nwe use to find GUSE (the generalized usage side effect) is the same as that used for GMOD (because we \nare con\u00ad sidering what may happen) . The initial assignment of variables to node p is IUSE(p) and the \nfunction associated with the edge for call s is fs(X) = PDEF(s) * fs(X) where fs is the edge function \nfor call s used in the GMOD calculation. Once the meet over all paths solution to this flow problem has \nbeen found, DUSE (the direct usage side effect) is calculated from GUSE just as DMOD iS frOm GMOD: DUSE(S) \n= fs(GMOD(p)) where p is the procedure called by call site s. The correctness proof of this method is \nalso found in [BAN1 8]. The thing to note here is that once DEF is known and taken into account, USE \nbehaves very much like a flow insensitive side effect and can, thus be handled much like MOD. The imprecision \nin this calculation all comes from the involvement of DEF and is re\u00ad flected in the quantities IUSE and \nPDEF. If IUSE and PDEF were known precisely, then the subsequent calculation of GUSE would be precise. \n~tionsh~ to Past Work Spillman [SP1711, Hecht and Shaffer [HEC75], Barth [BAR781, and Aho and Unman \n[AH077] all give methods of finding the possible aliases of variables using some form of transitive ClOSL.Ire \n(with Barth giving the most accurate results) . None of these is as accurate as the method given here, \nalthough Spillman s is more general, covering almost all of the fea\u00ad tures of PL/I. Spillman [SP1711 \ngives an algorithm for calculating MOD which uses iterative calculation in a large bit array. The me\u00adthod \nencompasses more language features than the one given here, but is much slower and less precise and does \nnot seem to extend to more complex side effects such as DEF or USE. Allen [ALL74a] and Allen and Schwartz \n [ALL74b] give a method for interprocedural flow analysis which requires scanning pro\u00adcedures in a particular \norder (reverse in\u00advocation order) . They do not treat the problem of finding aliases or exits from procedures \n(they assume this is known). The ordering of procedures makes this al\u00adgorithm more difficult to implement \nand results in less precision in the presence of recursion. Rosen [ROS79] gives the only method which \nis precise up to symbolic execution for complex side effects like DEF and USE, but the method is much \nmore complicated than the one given here and is probably much slower. For iMOD and REF and the kinds \nof language mechanisms considered here it gives no more precise results than the present method at the \nexpense of a great deal of additional work. (It may, however, be capable of handling a wider range of \nvariable mapping mechanisms. ) Lome t [LOM771 gives a simpler but less precise version of Rosen s algorithm \nbut does not recognize the possibility of us\u00adi ng standard flow analysis techniques. Lomet also has an \nextensive discussion of the use of side effect information given the existence of aliases. Neither Rosen \nnor Lomet gives an algorithm for finding aliases. Hecht and Shaffer [HEC75] and Aho and Unman [AH0771 \nboth present methods of finding side effects which are similar to the one given here, but for languages \nwithout nesting of procedures. Neither give any indication that the method can be generalized to full \nblock structured lan\u00adguages or that standard flow analysis techniques can be applied. Barth [BAR78] gives \na method which is based on forming transitive closures of various relationships. The method suffers \nfrom a lack of precision due to the way the interaction between reference parame\u00ad ters and scope is handled. \nIt also tends to be much slower than the present method for large programs since its executon time increases \nas the cube of the number of procedures. Acknowledgments At one time or another F. Allen, J. Barth, \nF. Baskett, S. Owicki, B. Peuto, anti B. Rosen have made helpfull comments about the ideas expressed \nhere or their presentation. Their help and the help of V. Brewer is gratefully acknowledged. References \n[AH077] [ALL74a] [ALL74bl [Bm78] [BAR78 1 [GRA76 1 [HEC75] [L0M771 [ROS781 [ROS791 [SP1711 [TAR75 1 [uLL751 \nAho, A. V. and Ulman, J. D. Principles of compiler WV Addison Wesl~, 1977. Allen, F. E; Interprocedural \nData Flow Analysis. Proceedings IFIP Congress ~, North Holland ~ishing Company, Amsterdam, 398-402. Allen, \nF. E. and Schwartz, J. T. Determining the Data Relation\u00adships in a Collection of Proce\u00addures. Computer \nScience Report RC 498?, IBM Thomas J. Watson Re\u00adsearch center, (Aug. 1974). Banning, J. P. A Method for \nDe\u00adtermining the Side Effects of Procedure Calls. Ph.D. Thesis, Stanford University. Report No. 213, \nStanford Linear Accelerator Center (Aug. 1978). Barth, J. A Practical Inter-J procedural Data Flow Analysis \nAl\u00ad~orithm. CACM 21, 9-(Sept. 1978) 724-73~ Graham, S. L. and Wegman, M. A Fast and Usually Linear Algorithm \nfor Global Flow Analysis. JACM 23, 1 (Jan. 1976), 172-202. ~=cht, M. S. and Shaffer, J. B. Ideas on the \nDesign of a Quad Improver for SIMPL-T, Part I: Overview and Intersegment Analy\u00adsis. Computer Science \nTechnical Report TR-405, University of Ma\u00adryland, College Park, Maryland (Aug. 1975). Lomet, D. B. Data \nFlow Analysis in the Presence of Procedure Calls. IBM Journal of Research and Deve~ment ~, 6 (Nov. m7)~59-571. \nRosen. B. K. O Monoids for Rapid Flow Analysis. Computer Scie~ce Report RC 7032, IBM Thomas J. Watson \nResearch Center, Yorktown Heights (March 1978), 59 pp. Rosen, B. K. Data Flow Analysis for Procedural \nLanguages. To appear JACM. Also Computer Sci\u00adence Report RC 5948, IBM Thomas J. Watson Research Centert \nYork\u00adtown Heights (April 1976), 50 PP. Spillman, T. C. Exposing Side-Effects in. a PL/I Optimizing COm\u00adpiler. \nProceedings lFIP Confer\u00adence 1971, North Holl~P_\u00ad%C~~ny, Amsterdam, 376-381. Tarjan, R. E. Solving Path \nProblems on Directed Graphs. Report STAN-CS-75-582 , Computer Science Department, Stanford Uni\u00adversity \n(Nov. 1975), 45 pp. Unman, J. D. A Survey of Data Flow Analysis Techniques. Pro\u00adceedings Second ,USA-Japan \n~\u00adputer C&#38;nference, Tokyo (Aug. 1975), 335-342. \n\t\t\t", "proc_id": "567752", "abstract": "", "authors": [{"name": "John P. Banning", "author_profile_id": "81100106243", "affiliation": "Stanford Linear Accelerator Center, Stanford, California and Amdahl Corporation, Sunnyvale, California", "person_id": "P383278", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567752.567756", "year": "1979", "article_id": "567756", "conference": "POPL", "title": "An efficient way to find the side effects of procedure calls and the aliases of variables", "url": "http://dl.acm.org/citation.cfm?id=567756"}