{"article_publication_date": "10-01-1998", "fulltext": "\n A Type System for Object Initialization In the Java Bytecode Language* Stephen N. F reund John C. Mitchell \nDepartment of Computer Science Stanford University Stanford, CA 94305-9045 {freunds, mitchell}@cs.stanford.edu \nAbstract In the standard Java implementation, a Java language program is compiled to Java bytecode. This \nbytecode may be sent across the network to another site, where it is then interpreted by the Java Virtual \nMachine. Since bytecode may be written by hand, or corrupted during network transmission, the Java Virtual \nMachine con-tains a bytecode vetifier that performs a number of con- sistency checks before code is interpreted. \nAs illustrated by previous attacks on the Java Virtual Machine, these tests, which include type correctness, \nare critical for sys- tem security. In order to analyze existing bytecode ver-ifiers and to understand \nthe properties that should be verified, we develop a precise specification of statically- correct Java \nbytecode, in the form of a type system. Our focus in this paper is a subset of the bytecode lan-guage \ndealing with object creation and initialization. For this subset,, we prove that for every Java bytecode \nprogram that satisfies our typing constraints, every ob- ject is initialized before it is used. The type \nsystem is easily combined with a previous system developed by Stata and Abadi for bytecode subroutines. \nOur anal-ysis of subroutines and object initialization reveals a previously unpublished bug in the Sun \nJDK bytecode verifier. 1 Introduction The Java programming language is a statically-typed general-purpose \nprogramming language with an imple- mentation architecture that is designed to facilitate transmission \nof compiled code across a network. In *Supported in part by NSF grants CC R-9303099 and CCR- 9629754, \nONR MURI Award N00014-97-1-0505, and a NSF Graduate Research Fellowship. Permlsston to make dtg!fal 0, \nhard copes of all 0, part of th,s work for personal 0, classroom use IS granted wthout fee prowded that \ncOpk?s are not made 0, distributed for profIt o, comme,c,al advan- tage and that copes bear this notxe \nand the full cntatnn on the fwst page. To copy otherwse, to republish. to post on se,ve,s o, to redtstribute \nto kts. reqwres pr~o, specafic pernwss~on sndlor a tee. OOPSLA 98 10198 Vancouver. B.C. 0 1998 ACM l-581 \n13.005.8/98/0010...$5.00 the standard implementation, a Java language pro-gram is compiled to Java bytecode \nand this bytecode is then interpreted by the Java Virtual Machine. While many previous programming languages \nhave been im- plemented using a bytecode interpreter, the Java archi- tecture differs in that programs \nare commonly transmit-ted between users across a network in compiled form. Since bytecode may be written \nby hand, or corrupted during network transmission, the Java Virtual Machine contains a bytecode verifier \nthat performs a number of consistency checks before code is interpreted. Fig-ure 1 shows the point at \nwhich the verifier checks a program during the compilation, transmission, and ex-ecution process. After \na class file containing Java byte- codes is loaded by the Java Virtual Machine, it must pass through \nthe bytecode verifier before being linked into the execution environment and interpreted. This protects \nthe receiver from certain security risks and var- ious forms of attack. The verifier checks to make sure \nthat every opcode is valid, all jumps lead to legal instructions, methods have structurally correct signatures, \nand that type con-straints are satisfied. Conservative static analysis tech-niques are used to check \nthese conditions. As a result, many programs that would never execute an erroneous instruction are rejected. \nHowever, any bytecode pro-gram generated by a conventional compiler is accepted. The need for conservative \nanalysis stems from the un-decidability of the halting problem, as well as efficiency considerations. \nSpecifically, since most bytecode is the result of compilation, there is very little benefit in de- veloping \ncomplex analysis techniques to recognize pat- terns that could be considered legal but do not occur in \ncompiler output. The intermediate bytecode language, which we re- fer to as JVML, is a typed, machine-independent \nform with some low-level instructions that reflect specific high-level Java source language constructs. \nFor exam-ple, classes are a basic notion in JVML, and there is a form of local subroutine call and return \ndesigned Ajava A.class I 1 I I class A { Java Virtual Machine void f() { netwo+ * r - B .class I I . \n. I I I : I I class file I I I I I J I L I Untrusted Code : Trusted Code Figure 1: The Java Virtual \nMachine to allow efficient implementation of the source language try-f inally construct. While some amount \nof type in- formation is included in JVML to make typechecking possible, there are some high-level properties \nof Java source code that are not, easy to detect in the resulting bytecode. One example is the last-called \nfirst-returned property of the local subroutines. While this property will hold for every JVML program \ngenerated by compil- ing Java source, some effort is required to confirm this property in bytecode programs \n[SA98]. Another example is the initialization of objects be-fore use. While it is clear from the Java \nsource language statement A x = new A((parameters)) that the A class constructor will be called before \nany methods can be invoked through the pointer x, this is not obvious from a simple scan of the resulting \nJVML program. One reason is that many bytecode instruc-tions may be needed to evaluate the parameters \nfor the call to the constructor. In the bytecode, these will be executed after space has been allocated \nfor the object and before the object is initialized. Another reason, dis- cussed in more detail in Section \n2, is that the structure of the Java Virtual Machine requires copying of point- ers to uninitialized \nobjects. Therefore, some form of aliasing analysis is needed to make sure that an object is initialized \nbefore it is used. Several published attacks on early forms of the Java Virtual Machine illustrate the \nimportance of the byte- code verifier for system security. To cite one specific example, a bug in an \nearly version of Sun s bytecode verifier allowed applets to create certain system objects which they \nshould not have been able to create, such as class loaders [DFW96]. The problem was caused by an error \nin how constructors were verified and resulted in the ability to potentially compromise the security \nof the entire system. Clearly, problems like this give rise to the need for a correct and formal specification \nof the bytecode verifier. However, for a variety of reasons, there is no established formal specification; \nthe primary specification is an informal English description that is occasionally at odds with current \nverifier implementa-tions. Building on a prior study of the bytecodes for local subroutine call and return \n[SA98], this paper develops a specification of statically-correct bytecode for a frag- ment of JVML that \nincludes object creation (alloca-tion of memory) and initialization. This specification has the form \nof a type system, although there are sev- eral technical ways in which a type system for low-level code \nwith jumps and type-varying use of stack locations (or registers) differs from conventional high-level \ntype systems. We prove soundness of the type system by a traditional method using operational semantics. \nIt follows from the soundness theorem that any bytecode program that passes the static checks will initialize \nev-ery object before it is used. We have examined a broad range of alternatives for specifying type systems \ncapa- ble of identifying that kind of error. In some cases, we found it possible to simplify our specification \nby being more or less conservative than current verifiers. How- ever, we generally resisted the temptation \nto do so since we hoped to gain some understanding of the strength and limitations of existing verifier \nimplementations. In addition to proving soundness for the simple lan- guage, we have structured the main \nlemmas and proofs so that they apply to any additional bytecode com-mands that satisfy certain general \nconditions. This makes it relatively straightforward to combine our anal- ysis with the prior work of \nAbadi and Stata, showing type soundness for bytecode programs that combine ob- ject creation with subroutines. \nIn analyzing the interac- tion between object creation and subroutines, we have identified a previously \nunpublished bug in the Sun im- plementation of the bytecode verifier. This bug allows a program to use \nan object before it has been initialized; details appear in Section 7. Our type-based framework also \nmade it possible to evaluate various repairs to fix this error and prove correctness for a modified system. \nSection 2 describes the problem of object initializa-tion in more detail, and Section 3 presents JVML;, \nthe language which we formally study in this paper. The operational semantics and type system for this \nlan- guage is presented in Section 4. Some sound extensions to JVMLi, including subroutines, are discussed \nin Sec- tion 6, and Section 7 describes how this work relates to Sun s implementation. Section 8 discusses \nsome other projects dealing with bytecode verification, and Sec-tion 9 gives directions for future work \nand concludes. 2 Object Initialization As in many other object-oriented languages, the Java implementation \ncreates new objects in two steps. The first step is to allocate space for the object. This usually requires \nsome environment-specific operation to obtain an appropriate region of memory. In the second step, user-defined \ncode is executed to initialize the object. In Java, the initialization code is provided by a constructor \ndefined in the class of the object. Only after both of these steps are completed can a method be invoked \non an object. III the Java source language, allocation and initial- ization are combined into a single \nstatement. This is illustrated in the following code fragment. Point p = new Paint(3); p.Print(); The \nfirst line indicates that a new Point object should be created and calls the Point constructor to initialize \nthis object. The second line invokes a method on this object and therefore can be allowed only if the \nobject has been initialized. Since every Java object is created by a statement like the one in the first \nline here, it does not seem difficult to prevent Java source language pro-grams from invoking methods \non objects that have not been initialized. While there are a few subtle situations to consider, such \nas when a constructor throws an ex- ception, the issue is essentially clear cut. It is much more difficult \nto recognize initialization-before-use in bytecode. This can be seen by looking at the five lines of \nbytecode that are produced by compiling the preceding two lines of source code: 1: new #1 <Class Point> \n2: dup 3: iconst-3 4: invokespecial #4 <Method Point(int)> 5: invokevirtual #5 <Method void Print () \n> The most striking difference is that memory allocation (line 1) is separated f rom the constructor \ninvocation (line 4) by two lines of code. The first intervening line, dup, duplicates the pointer to \nthe uninitialized object. The reason for this instruction is that a pointer to the object must be passed \nto the constructor. A convention of parameter passing for the stack-based architecture is that parameters \nto a function are popped off the stack before the function returns. Therefore, if the address were not \nduplicated, there would be no way for the code creating the object to access it after it is initialized. \nThe second line, iconst-3 pushes the constructor argument 3 onto the stack. If p were used again after \nline 5 of the bytecode program, another dup would have been needed prior to line 5. Depending on the \nnumber and type of constructor arguments, many different instruction sequences may appear between object \nallocation and initialization. For example, suppose that several new objects are passed as arguments \nto a constructor. In this case, it is necessary to create each of the argument objects and initialize \nthem before passing them to the constructor. In gen- eral, the code fragment between allocation and initial- \nization may involve substantial computation, including allocation of new objects, duplication of object \npoint-ers, and jumps to or branches from other locations in the code. Since pointers may be duplicated, \nsome form of alias- ing analysis must be used. More specifically, when a constructor is called, there \nmay be several pointers to the object that is initialized as a result, as well as point- ers to other \nuninitialized objects. In order to verify code that uses pointers to initialized objects, it is therefore \nnecessary to keep track of which pointers are aliases (name the same object). Some hint for this is given \nby the following bytecode sequence: 1: new #1 <Class Point> 2: new #1 <Class Point> 3: dup 4: iconst-3 \n5: invokespecial #4 <Method Point(int)> 6: invokevirtual #5 <Method void Print (>> When line 5 is reached \nduring execution, there will be two different uninitialized Point objects. If the byte-code verifier \nis to check object initialization statically, it must be able to determine which references point to \nthe object that is initialized at line 5 and which point to the remaining uninitialized object. Otherwise, \nthe verifier would either prevent use of an initialized object or allow use of an uninitialized one. \n(The bytecode pro-gram above is valid and accepted by verifiers using the static analysis described below.) \nSun s Java Virtual Machine Specification [LY96] de- scribes the alias analysis used by the Sun JDK verifier. \nFor each line of the bytecode program, some status in-formation is recorded for every local variable \nand stack location. When a location points to an object that is known not to be initialized in all executions \nreaching this statement, the status will include not only the prop- erty uninitialized, but also the \nline number on which the uninitialized object would have been created. As refer- ences are duplicated \non the stack and stored and loaded in the local variables, the analysis also duplicates these line numbers, \nand all references having the same line number are assumed to refer to the same object. When an object \nis initialized, all pointers that refer to objects created at the same line number are set to initialized. \nIn other words, all references to uninitialized objects of a certain type are partitioned into equivalence \nclasses according to what is statically known about each reference, and all references that point to \nuninitialized objects created on the same line are assumed to be aliases. This is a very simple and highly \nconservative form of aliasing analysis; far more sophisticated meth-ods might be considered. However, \nthe approach can be implemented efficiently and it is sufficiently accurate to accept bytecode produced \nby standard compilers. Our specification of statically-correct Java bytecode in Section 4 uses the same \nform of aliasing analysis as the Sun JDK verifier. Since our approach is type based, the status information \nassociated with each reference is recorded as part of its type. One limitation of aliasing analysis based \non line numbers is that no verifiable program can ever be able to reference two objects allocated on \nthe same line, without first initializing at least one of them. If this sit-uation were to occur, references \nwould exist to two dif-ferent objects from the same static aliasing-equivalence class. Unfortunately, \nthere was an oversight in this re-gard in the development of the Sun verifier, which al-lowed such a \ncase to exist (as of version 1.1.4). As discussed in Section 7, aliasing based on line num-bers makes \nit problematic for a subroutine to return an uninitialized object. 3 JVMLi This section describes the \nJVML; language, a subset of JVML encompassing basic constructs and object initial-ization. Although this \nlanguage is much smaller than JVML, it is sufficient to study object initialization and formulate a sound \ntype system encompassing the static analysis described above. The run-time environment for JVML; consists \nonly of an operand stack and a fi- nite set of local variables. A JVMLi program will be a sequence of \ninstructions drawn from the following list: instruction ::= push 0 ) inc ( pop 1 if L ) store x ] load \nx ] new 0 ] init 0 ] use g ] halt where x is a local variable name, 0 is an object type, and L is an \naddress of another instruction in the program. InformaIly, these instructions have the following effects: \npush 0: pushes integer 0 onto the stack. inc: adds one to the value on the top of the stack, if that \nvalue is an integer. pop: removes the top element from the stack, provided that the stack is not empty. \nif L: if the top element on the stack is not 0, execu- tion jumps to instruction L. Otherwise, execution \nsteps to the next sequential instruction. This as-sumes that the top element is an integer. store Z: \nremoves a value from the top of the stack and stores it into local variable 2. load x: loads the value \nfrom local variable z and places it on the top of the stack. halt: terminates program execution. new \n0: allocates a new, uninitialized object of type CJ and places it on the stack. init B: initializes the \nobject on top of the operand stack, which must be a previously uninitialized ob-ject obtained by a call \nto new (T. This represents calling the constructor of an object. In this model, we assume that constructors \nalways properly ini-tialize their argument and return. However, as described in Section 6, there are \nseveral additional properties which must be checked to verify that constructors do in fact behave correctly. \n(T: performs an operation on an initialized object of type (T. This is an abstraction of several op-erations \nin JVML, including method invocation (invokevirtual) and accessing an instance field (putf ield/getf \nield). In each case, all explicit or implicit assumptions must be satisfied in order for the statement \nto be ex- ecuted. For example, a pop instruction cannot be ex- ecuted if the stack is empty. The exact \nconditions re-quired to execute each instruction are specified in the definition of the operational semantics, \nin Section 4.3. Although dup does not appear in JVMLi for simplicity, alias+ may arise by storing and \nloading object refer-ences from the local variables. 4 Operational and Static Semantics 4.1 Notation \nThis section briefly reviews the framework developed by Stata and Abadi in [SA98] for studying JVML. \nWe begin with a set of instruction addresses ADDR. Al-though we shall use integers to represent elements \nof this set, we will distinguish elements of ADDR from in-tegers. A program is formally represented as \na partial function from addresses to instructions. Dam(P) is the set of addresses used in program P, \nand P[i] is the ith instruction in program P. Dam(P) will always include address 1 and is usually a range \n{ 1, . . . , n} for some n. Equality on partial maps is defined as f = g iff Dam(f) = Dam(g) AVy E Dam(f). \nf[y] = g[y] Update and substitution operations are also defined. t/y E Dam(f): ifz=y otherwise where \nu, b, and v range over the codomain of f. This notation for partial maps will be used throughout this \npaper. Sequences will also be used. The empty sequence is t, and v. s represents placing w on the front \nof sequence s. A sequence of one element, v . 6, will sometimes be abbreviated to 11. When convenient, \nwe shall also treat sequences as partial maps from positions to elements of the sequence. For a sequence \ns, Dam(s) is the set of indices into s, and s[i] is the ith element in s from the right. Substitution \nis also defined on sequences, in the same manner as substitution on partial maps. 4.2 Values and Types \nThe types will be integers and object types. For objects, we assume there is some set T of possible object \ntypes. These types include all class names to whjch a program may refer. In addition, there is a set \nT of types for uninitialized objects. The contents of this set is defined in terms of T: SiEpiffcrETAiEADDR \n The type &#38;i is used for an object of type o allocated on line i of a program, until it has been \ninitialized. Given these definitions, JVMLi types are generated by the grammar: T ::= INT 1 c 1 ei ( \nTOP where c E T and Ci E 5?. The type INT will be used for integers. We discuss the addition of other \nbasic types in Section 6. The type TOP is the supertype of all types, with any value of any type also \nhaving type TOP. This type will represent unusable values in our static analy- sis. In general, a type \nmeta-variable 7 may refer to any type, including any object type g E T or uninitialized- object type \n&#38;i E 5?. In the case that a type meta- variable is known to refer to some uninitialized object type, \nwe will write it as i, for example. Each object type and uninitialized object type has a corresponding \ninfinite set of values which can be distin- guished from values of any other type. For any object, type \na, this set of values is A . Likewise, there is a set of values A&#38;i for all uninitialized object \ntypes c?;. In our model, we only need to know one piece of informa- tion for each object, namely, whether \nor not it has been initialized. Therefore, drawing uninitialized and initial- ized object references \nfrom different sets is sufficient for our purposes, and we do not need to model an ob- ject store. As \nwe will see below, this representation has some impact on how object initialization is modeled in our \noperational semantics. Values of the form 8 or 6 will refer to values known to be of some uninitialized \nobject type. The basic type rules for values are: w is a value n is an integer aEArT,7ciTUp v : TOP \nn : INT a:7 We also extend values and types to sequences: a:7 s:c3 .c:t a.s:r.cy  4.3 Operational Semantics \nThe bytecode interpreter for JVMLi is modeled using the standard framework of operational semantics. \nEach P[pc] = inc lJ t- (PC, f, n. 4 -+ (PC + 1, f, (n + 1) .4 f%4 = POP p t- (PC, f, 21 .s) --t (PC \n+ 1, f, 4 P[pc] = load z p k (PC, f, 4 --j (PC + 1, f, f bl .s) P[pc] = if L p I- (PC, f, 0 .s) + (PC \nf 1, f, 4 P[pc] = new a 6 E Ab,,., Unused(iL, f, s) p t- (PC, f, .s> --) (PC + 1, f, ii. 4 P[pc] a \nE A P t- (PC, f, a. Figure 2: JVMLi iustruction is characterized by a transformation of ma- chine states, \nwhere a machine state is a tuple (pc, f, s) with the following meaning: pc is a program counter, indicating \nthe address of the instruction that is about to be executed. f is a total map from VAR, the set of local \nvari-ables, to the values stored in the local variables in the current state. s is a stack of values \nrepresenting the operand stack for the current state in execution. The machine begins execution in state \n(1, fs, t). In this state, the first instruction in the program is about to be executed, the operand \nstack is empty, and the local variables may contain any values. This means that fs may map the local \nvariables to any values. Each bytecode instruction has one or more rules in the operational semantics. \nThese rules use the judg- ment p k (PC> f, s) + (PC , f , 4 to indicate that a program P in state (pc, \nf, s) can move to stat,e (PC , f , s ) in one step. The complete one-step operational semantics for JVMLi \nis shown in Figure 2. In that figure, n is any integer, v is any value, L and j are ariy addresses, and \nz is any local variable. P[pc]=push 0 p t- (PC, f, 4 + (PC + 1, f, 0.4 P[pc] = store z p I- (PC, f, \n0.4 -+ (PC + 1, f[x * 4, 4 P[pc] = if L n#O P t- (PC, f, n. 3) --j (L, f, 4  P[pc]=init cT 6 E A&#38;j \na E A , Unused(a, f, s) p k (PC, f, 6.4 + (PC + 1, [aldf, [a/+) = use CT 4 -+ (PC + 1, f, 4 operational \nsemantics. These operational semantic rules, with the exception of those added to study object initialization, \nare discussed in detail in [SA98]. The rules have been designed so that a step cannot be made from an \nillegal state. For example, it is not possible to execute a pop instruction when there is an empty stack. \nThe rules for allocating and initializing objects need to generate object values not in use by the program. \nThe only values in use are those which appear on the operand stack or in the local variables. Therefore, \nthe notion of being unused may be characterized by a#s VY E VAR. f [Y] # a (unused) Unused(a, f, s) When \na new object, is created, a currently unused value of an uninitialized object type is placed on the stack. \nThe type of that value is determined by the ob- ject type named in the instruction and the line number \nof the instruction. When the value for an uninitial-ized object is initialized by an init (T instruction, \nall occurrences of that value are replaced by a new value corresponding to an initialized object. In \nsome sense, initialization may be thought of as a substitution of a new, initialized object for an uninitialized \nobject. The new value is required to be unused. This allows the program to distinguish between different \nobjects of the P[i] = if L P[i] = inc Fj+l = FL = Fi Fi+l = Fi Sj = INT.S~+~ = INT.SL Si+I = Si = INT.(Y \ni + 1 E Dam(P) i + 1 E Dam(P) L E Dam(P) (inc) F,S,i t P F,S,itP P[i] = pop P[i] = push 0 FitI = F; F;+, \n= F; Sj = 7. Sj+l SiqI = INT-S~ i + 1 E Dam(P) i + i E Dom( P) (PW) (push 0) F,S,i t P F,S,itP P[i] \n= load x P[i] = store x x E Dom(Fi) x E Dom(Fi) Fi+l = F;[x I+ T] sj+;2j-gt si sj =r.sj+1 i + 1 E DcJm(P) \ni + 1 E Dam(P) (loud) (store) F,S,it P F,S,itP P[i] = new 0 Fi+l = Fi Sj+l = pi . Si 8 i $! sj Vy E Dom(Fi). \nFi[y] # 6i  P[i] = halt i + 1 E Dam(P) (halt) (new) F,S,i t P F,S,itP P[i] = init CT Fi+l = [o/&#38;]Fi \nSi = &#38;j . (Y P[i] = use u Sj+l = [U/&#38;.j]CX Fi+l = Fi j E Dam(P) sj = u. sj+1 i + 1 E Dam(P) i \n+ 1 E Dam(P) (init) (use) F,S,i t P F,S,i t P Figure 3: Static semantics. same type after they have been \ninitialized, but this fact is not necessarily needed to study the properties ad-dressed by this paper. \n 4.4 Static Semantics A program P is well typed if there exist F and S such that F, S t P, where F is \na map from ADDR to functions mapping local variables to types, and S is a map from ADDR to stack types \nsuch that Si is the type of the operand stack at location i of the program. As described in [SA98], elements \nin a map over ADDR are accessed as Fi instead of F[i]. Thus, Fi[y] is the type of local variable y at \nline i of a program. The Java Virtual Machine Specification [LY96] de-scribes the verifier as both computing \nthe type informa- tion stored in F and S and checking it. However, we assume that the information stored \nin F and S has al- ready been computed prior to the type checking stage. This simplifies rnatters since \nit separates the two tasks and prevents the t,ype synthesis from complicating the static semantics. In \nother words, we only need to trust the implementation of the type checker, and not the im- plernentation \nof the type inferencing part of the anal-ysis. If the two stages are combined, as they are in current \nimplementations, a bad program could be ac- cepted due to an error in the process of computing type information. \nHowever, separating the two tasks pre-vents the type checker from accepting a bad program due to such \nan error. The judgment which allows us to conclude that a program P is well typed by F and S is Vi E \nDam(P). F,S,i t P (Id prog) F,StP where FT ~ is a function mapping all variables in VAR to TOP. The \nfirst two lines of (wt prog) constrain the initial conditions for the program s execution to match the \ntype of the values given to the initial state in the operational semantics. The third line requires that \neach instruction in the program is well typed according to the local juclgments presented in Figure 3. \nThe (new) rule in Figure 3 requires that the type of the object allocated by the new instruction is left \non top of the stack. Note that this rule is only applicable if the uninitialized object type about to \nbe placed on top of the type stack does not appear anywhere in F; or S;. This restriction is crucial \nto ensure that we do not create a situation in which a running program may have two different values \nmapping to the same statically computed uninitialized object type. The rule for (use) requires an initialized \nobject type on top of the stack. The (init) rule implements the static analysis method described in Section \n2. The rule specifies that all occurrences of the type on the top of the stack are replaced by an initialized \ntype. This will change the types of all references to the object that is being initialized since all \nthose references will be in the same static equivalence class, and, therefore, have the same type. Figure \n4 shows a JVMLi program and the type infor- mation demonstrating that it is a well-typed program according \nto the rules in this section. 5 Soundness This section outlines the soundness proof for JVMLi. The main \nsoundness theorem states that no well-typed program will cause a run-time type error. Before stat-ing \nthe main soundness theorem, a one-step soundness theorem is presented. One-step soundness implies that \nany valid transition from a well-formed state leads to another well-formed state. Theorem 1 (One-step \nSoundness) Given P, F, and S such that F, S t P: VPC, f 1 s, PC , f 7 s . lJ t (PC, f, 4 + (PC , f , \n4 A s: s,, A VY E VAR. f[y] : Fpc[~/l A ConsistentInit(F,,,S,,, f,s) * s : Spc A Vy E VAR. f [y] : \nF+[y] A ConsistentInit(F,,, , Spcl, f , s ) A pc E Dam(P) This theorem lists the four factors which \ndictate whether or not a state is well formed. The values on the operand stack must have the types expected \nby the static type rules, and the local variable contents must match the types in F. In addition, the \nprogram counter must always be in the domain of the program. This can be assumed on the left-hand side \nof the implication since the operational semantics guarantee that transi-tions can only be made if P[pc] \nis defined. If the pro-gram counter were not in the domain of the program, no step could be made. The \nfinal requirement for a state to be well formed is that it has the ConsistentInit property. Informally, \nthis property means that the machine cannot access two dif- ferent uninitialized objects created on the \nsame line of code. As mentioned in Section 2, this invariant is criti- cal for the soundness of this \nstatic analysis. The Consis- i P[i] Fi [0] Si 1: new C TOP lz 2: new C TOP c, .c 3: store 0 TOP i2.61 \nC 4: load 0 62 Cl .e 5: load 0 &#38; c, .?I 6 A 6: init C c2 c2 . c, . t1 * E 7: use C C c.e, .c 8: \nhalt C i$ .c Figure 4: A JVMLi program and its static type information. (cons init) Q? E ?. 36 : T. Corresponds(Fi,Si, \nf, s, 6,;) ConsistentInit(Fi, Si, f, S) QX E Dom(Fi). F~[x] = ? - f[~] = h (corr) StackCorresponds(Si, \ns, ii, ?) Corresponds(Fi, Si, f, s, 6, ?) (SC 0) StackCorresponds(q 6, &#38;, +) Stack Corresponds \n(Si, s, 6, ?) (SC 4 Stack Corresponds(? . Si, b. S, b, +) Tf? Stack Corresponds(Si, s, &#38;, ?) (SC \n2) Stack Corresponds(r . Si, v . S, b, i) Figure 5: The ConsistentInit judgement. tentlnit property \nrequires a unique correspondence be-tween uninitialized object types and run-time values. Figure 5 presents \nthe formal definition of Consistent- Init. In that figure, Fi is a map from local variables to types, \nSi is a stack type. The judgment (cons init) is satisfied only if every uninitialized object type ? has \nsome value 8 that Corresponds to it. The first line of rule (COT) guarantees that every occurrence of \n? in the static types of the local variables is matched by 6 in the run-time state. The second line of \nthat rule uses an aux- iliary judgment to assert the same property about the stack type and operand stack \ninductively. Given this invariant, we are able to assume that when an init in-struction is executed, \nall stack slots and local variables affected by the type substitution in rule (init) applied to that \ninstruction contain the object that is being ini-tialized. The proof of Theorem 1 is by case analysis \non all possible instructions at P[pc]. The proof of this theorem and those that follow appear in the \nextended version of this paper. A complementary theorem is that a step can always be made from a well-formed \nstate, unless the program has reached a halt instruction. This progress theorem can be stated as: Theorem \n2 (Progress) Given P, F, and S such that F,Sk-P: QPC,f > s.  s : s,, A QY E VAR. f[~] : F,,[Y] A ConsistentInit(F,,, \nSpc, f, s) A pc E Dam(P) A P[pc] # halt * 3pc , f , s . P k (PC, f, s) + (PC , f , s ) Theorem 1 and \nTheorem 2 can be used to prove in- ductively that a program beginning in a valid initial state will always \nbe in a well-formed state, regardless of how many steps are made. In addition, a program will never get \nstuck unless it reaches a halt in instruction. When it does reach a halt instruction, the stack will \nhave the correct type, which is important since the re-turn value for a program, or method in the full \nJVML, is returned as the top value on the stack. The following theorem captures this soundness property: \nTheorem 3 (Soundness) Given P, F, and S such that F, S t P: QPC,fo, f > s. p t (1, fo, 4 -+* (PC, f, \ns) A Jpc , f , s . P t (PC, f, s) 4 (PC , f , s ) 3 P[pc] = halt A s: s,, If a program executing in \nour machine model attempts to perform an operation leading to a type error, such as using an uninitialized \nobject, it would get stuck since those operations are not, defined by our operational se-mantics. By \nproving that well-typed programs only get stuck when a halt instruction is reached, we know that, well-typed \nprograms will not attempt to perform any illegal operations. Thus, this theorem implies that our static \nanalysis is correct by showing that no erroneous programs are accepted. Therefore, no accepted program \nuses an uninitialized object. One technical point of interest is the asymmetry of the checks in rule \n(COT). That rule requires that all locations sharing type 7 contain the same value 8, but it does not \nrequire that all occurrences of 6 map to the type + in the static type information. We do not need to \ncheck the other direction because the rule is used only in the hypothesis of rule (cons init), where \nthe condition on the existential quantification of 6 requires that 6 : +. Therefore: b E Ai, and the \nonly types which we may assign to b are + and TOP. This allows us to assume that, as long as the stack \nand local variables are well typed when rule (cons init) is used, any occurrences of 6 are matched by \neither ? or TOP. Thus, with the exception of occurrences of TOP, the correspondence between b and ? holds \nin both di-rections. The situation for TOP introduces a special case in the proofs but does not affect \nsoundness, and the asymmetric checks are sufficient to prove the sound- ness of the system. If we were \nto change our model so that object values could potentially have more than one uninitialized object type, \ni.e. all uninitialized object ref- erences are drawn from a single set, then we would need to check both \ndirections for the correspondence and ex- plicitly deal with the special case for TOP in the (corr) judgment \n. 6 Extensions Several extensions to the JVMLi framework described in the previous sections have been \nstudied. First, there are additional static checks which must be performed on constructors in order to \nguarantee that they do prop- erly initialize objects. Section 6.1 presents JVML,, an extension of JVMLi \nmodeling constructors. Another extension, JVML,, combining object initialization and subroutines, is \ndescribed in Section 6.2. Section 6.3 shows how any of these languages may be easily ex-tended with other \nbasic operations and primitive types. The combination of these features yields a sound type system covering \nthe most complex pieces of the JVML language. 6.1 JVML, The typing rules in Section 4 are adequate to \ncheck code which creates, initializes, and uses objects, assum-ing that calls to init CJ do in fact properly \ninitialize objects. However, since initialization is performed by user-defined constructors, the verifier \nmust check that these constructors do correctly initialize objects when called. This section studies \nverification of JVML con-structors using JVML,, an extension of JVMLi. The rules for checking constructors \nare defined in [LY96] and can be summarized by three basic points: When a constructor is invoked, local \nvariable 0 contains a reference to the object that, is being initialized. A constructor must apply either \na different con-structor of the same class or a constructor from the parent class to the object that \nis being initial- ized before the constructor exits. For simplicity, we may refer to either of these \nactions as invoking the super class constructor. The only deviation from this requirement is for constructors \nof class Object. Since, by the Java language definition, Object is the only class with- out, a superclass, \nconstructors for Object need not call any other constructor. This one special case has not been modeled \nby our rules, but would be trivial to add. Note that these rules do not imply that constructors will \nalways return. For example, they do not prevent non-termination due to an infinite loop within a constructor. \nA more interesting case is when two constructors from the same class call each other recursively and, \ntherefore, never fully construct an object passed to them. While programs potentially exhibiting this \nbehavior could be detected by intra-procedural analysis, this type of anal- ysis falls outside of the \nbounds of the current verifier. JVML, programs are sequences of instructions con-t,aining any instructions \nfrom JVMLi plus one new in-struction, super o. This instruction represents calling a constructor of the \nparent class of class o (or a different const,ructor of the class a). For simplicity, the rest of this \nsection assumes that we are describing a constructor for object type cp, for some cp in T. To model the \ninitial state of a constructor invocation for class (p, a JVML, program is assumed to begin in a state \nin which local variable 0 contains an uninitialized reference. This corresponds to the ar-gument of the \nconstructor. Prior to halting, the pro-gram must, call super p on that object reference. As mentioned \nabove, this represents calling the super class constructor. We will use $0 as the type of the object \nstored in local variable 0 at the start of execution. The value in local variable 0 must be drawn from \nthe set AdO. We now assume ADDR includes 0, although 0 will not be in the domain of any program. Also, \nmachine state in the operational semantics is augmented with a fourth ele-ment, Z, which indicates whether \nor not a super class constructor has been called on the object that is be- ing initialized. The rules \nfor all instructions other than super do not affect z, and are derived directly from the rules in Figure \n2. For example, the rule for inc is: P[pc] = inc p t-c (PC, f 7 n. s, 4 + (PC+ 1, f 7 (n + 1) . s, 4 \n As demonstrated in Theorem 4 below, the initial state for execution of a constructor for cp is (1, f0[0 \ne i&#38;,1, e, false) where iLv E Ado. For super, the operational semantics rule is: P[pc] = super d \nii E A o a E A , Unused(a, f, s) P t-, (PC, f, 6. s, 4 + (PC + 1, [a/4f, [al% tmej  The typing rule \nfor super is very similar to the rule for init, and is shown below with the judgment for determining \nwhether a program is a valid constructor for objects of type cp. All the other typing rules are the same \nas those appearing in Figure 3. P[i] = super 0 Fi+l = [~/~olFi Si = 60 Cl si+1 = [a/GolQ i + 1 E Dam(P) \n( swd F, S, i t P FI = FToP[O +-+ $01 s, =t ZI = false VET Vi E Dam(P). F, S,i t P (wt cst) Vi E Dam(P). \nZ,i t P constructs cp F, S k P constructs cp The (wt cst) rule is analogous to (wt prog) from Sec-tion \n4. However, this rule places an additional restric-tion on the structure of well-typed programs. The \njudg- ment Z,i t P constructs cp is a local judgment which gives Zi the value true or false depending \non whether or not all possible execu-tion sequences reaching instruction i would have called super cp \nor not. The local judgments are defined in Fig- ure 6. As seen by those rules, one can only conclude \nthat, P[i] E {inc,pop, push 0, load z, store x,new (T, init g, use a} &#38;+I = zi Z, i I- P constructs \np P(i] = if L zi+1 = ZL = zi Z, i I- P constructs cp P[i] = super cp Zi+l = true Z, i t- P constructs \ncp P[i] = halt Z; = true Z, i I- P constructs cp Figure 6: Rules checking that a super class constructor \na program is a valid constructor for cp if every path to each halt instruction has called super p. These \njudg- ments also reject any programs which call super for a class other than cp. The existence of unreachable \ncode may cause more than one value of Z to conform to the rules in Figure 6. To make Z unique for any \ngiven pro- gram, we assume that, for program P, there is a unique canonical form Zp. Thus, Zp,i will \nbe a unique value for instruction i. The main soundness theorem for constructors in-cludes a guarantee \nthat constructors do call super on the uninitialized object: Theorem 4 (Constructor Soundness) Given \nP, F, S, p, and &#38;+, such that F, S I- P constructs cp and ci p:$&#38;J: VP5 fo, fl s, z- p kc (PC, \nf, s, 4 + (PC , f , -5 7 z ) + P[pc] = halt A z = true The main difference in the proof of Theorem 4, \nin com-parison with Theorem 3, is that the corresponding one-step soundness theorem requires an additional \ninvari-ant. The invariant states that when program P is in state (pc, f, s, z), z = Zp,,,,. The proof \nof this theo-rem appears in the extended version of this paper. This analysis for constructors is combined \nwith the analysis of normal methods in a more complete JVML model currently being developed. will always \nbe called prior to reaching a halt instruction. 6.2 JVML, The JVML bytecodes for subroutines have also \nbeen added to JVMLi and are presented in another extended language, JVML,. While this section will not \ngo into all the details of subroutines, detailed discussions of bytecode subroutines can be found in \nseveral other works [SA98, LY96]. Subroutines are used to compile the finally clauses of exception handlers \nin the Java language. Subroutines share the same activation record as the method which uses them, and \nthey can be called from different locations in the same method, enabling all locations where finally \ncode must be executed to jump to a single subroutine containing that code. The flexibility of this mechanism \nmakes bytecode verifica-tion difficult for two main reasons: Subroutines are polymorphic over local variables \nwhich they do not use. Subroutines may call other subroutines, as long as a call stack discipline is \npreserved. In other words, the most recently called subroutine must be the first one to return. This \nis a slight simplifica-tion of the rules for subroutines defined in [LY96], which do allow a subroutine \nto return more than one level up in the implicit subroutine call stack in certain cases, but does match \nthe definitions presented in [SA98]. JVML, programs contain the same set of instructions as JVMLi programs \nand, also, the following: jsr L: jumps to instruction L, and pushes the return address onto the stack. \nThe return address is the instruction immediately after the jsr instruction. P[pc] = jsr L p t- (PC, \nf, s) -+ (L, f, (PC + 1) .s) P[pc] = ret x p I- (PC, f, 4 + (fbl, f, 4 Figure 7: Operational semantics \nfor jsr and ret. P[i] = jsr L Dom(Fi+~) = Dom(Fi) Dolt C Dom(Fi) Vy E Dom(Fi). Fi[y] $! f vy E Dml(Si). \nSi[Y] $fz P Vy E Dom(Fi)\\Dom(F~). J ~+I[Y] = J i[y] Vy E Dorn(F~). FL[Y] = Fi[y] SL = (ret-from L) . \nSi (ret-from L) $ Si Vy E Dorn(F~). FL[Y] # (ret-from L) i + 1 E Dam(P) W L E Dam(P) F,S,i t- P P[i] \n= ret x RP,~ = {L) x E Dom(Fi) Fi[x] = (ret-from L) Vy E Dom(Fi). Fi[y] 6 1; vy E DOrn(Si). &#38;[y] \n$2 9 ( ret) Vj. Pb] = jsr L * VY E DMFi). A sj+1 = si F,S,i tP Fj+l[y] = Fi[yl Figure 8: Type rules for \njsr and ret. ret 2: jumps to the instruction address stored in local variable 2. The operational semantics \nand typing rules for these instructions are shown in Figure 7 and Figure 8. These rules are based on \nthe rules used by Stata and Abadi [SA98]. The type (ret-from L) is introduced to indicate the type of \nan address to which subroutine L may return. The meaning of Rp,i = {L} in (ret) is de- fined in their \npaper and basically means that instruction i is an instruction belonging to the subroutine starting at, \naddress L. All other rules are the same as those for JVMLi. The main issue concerning initialization \nwhich must be addressed in the typing rules for jsr and ret is the preservation of the ConsistentInit \ninvariant. A type loophole could be created by allowing a subroutine and the caller of that subroutine \nto exchange references to uninitialized objects in certain situations. An example of this behavior is \ndescribed in Section 7. When subroutines are used to compile finally blocks by a Java compiler, uninitialized \nobject refer-ences will never be passed into or out of a subroutine. The Java language prevents a program \nfrom splitting al-location and initialization of an object between code in- side and outside of a finally \nclause since both are part of the same Java operation, as described in Section 2. Either both steps occur \noutside of the subroutine, or both steps occur inside the subroutine. We restrict pro-grams not to have \nuninitialized objects accessible when calling or returning from a subroutine. For (ret), the following \ntwo lines are added. These prevent the sub- routine from allocating a new object without initializing \nit: Vy E Dom(Fi). Fi[y] $! 9 Vy E Dom(Si). Si[y] $Z f Similar lines are added to (jsr). The discussion \nof the interaction between subroutines and uninitialized ob-jects in the Java Virtual Machine specification \nis vague and inconsistent with current implementations, but the rules we have developed seem to fit the \ngeneral strategy described in the specification. This is certainly not the only way to prevent sub-routines \nand object initialization from causing prob-lems. For example, slightly less restrictive rules could \nbe added to (jsr): ^ %/ e Dom(F~j. FL[Y] t2 T Vy E Dom(Si). Si[y] $z ? These conditions still allow uninitialized \nobjects to be present when a subroutine is called, but those objects cannot be touched since they are \nstored in local vari-ables which are not accessed in the body of the subrou- tine. This would allow the \ntyping rules to accept more programs, but these programs could not have been cre- ated by a compiler \nfrom any valid Java program. The main soundness theorem, Theorem 3, has been proved for JVML,, and for \nJVML, with subroutines, by combining the proof of JVMLi soundness with the work of Stata and Abadi. These \nproofs appear in the extended version of this paper.  6.3 Other Basic Types and Instructions Many JVML \ninstructions are variants of operations for different basic types. For example, there are four add instructions \ncorresponding to addition on values of type INT, FLOAT, LONG, and DOUBLE. Likewise, many other simple \noperations have several different forms. These instructions and other basic types can be added to JVMLi, \nor any of the extended languages, easily. These instructions do not complicate any of the sound- ness \nproofs since they only operate on basic types and do not interfere with object initialization or subroutine \nanalysis. The only tricky case is that LONG and DOUBLE val- ues take up two local variables or two stack \nslots since they are stored as two-word values. Although this re-quires an additional check in the rules \nfor load and store to prevent the program from accessing a par-tially over-written two-word value, this \ndoes not pose any serious difficulty. Of the 200 bytecode instructions in JVML, all but approximately \n40 fall into this category and may be added to JVMLi without trouble, although a full pre-sentation of \nthe operational and type rules for these in- structions is beyond the scope of this paper. With these \nadditions, and the methods described in the previous subsections, the JVMLi framework can be extended \nto cover the whole bytecode language, except for a full ob-ject system, exceptions, arrays, and concurrency. \nCon-sidering objects and classes requires the addition of an object heap and a method call stack, as \nwell as a typing environment containing class declarations. We are cur- rently developing an extended \nsystem covering all these topics except concurrency. 7 The Sun Verifier This section describes the relationship \nbetween the rules we have developed for object initialization and subrou- tines and the rules implicitly \nused to verify programs in Sun s implementation. We first describe a mistake we have found in Sun s rules \nand then compare their corrected rules with our rules for JVML,. 1: jsr 10 // jump to subroutine 2: \nstore 1 // store uninitialized object 3: jsr 10 // jump to subroutine 4: store 2 // store another uninitialized \nobject 5: load 2 // load one of them 6: init P // initialize it 7: load 1 // load the other 8: use P \n// use uninitialized object!!! 9: halt 10: store 0 // store return address 11: new P // allocate new \nobject 12: ret 0 // return from subroutine Figure 9: A program that uses an uninitialized object but \nis accepted by Sun s verifier. 7.1 The Sun JDK 1.1.4 Verifier As a direct result of the insight gained \nby carrying out the soundness proof for JVML,, a previously unpub-lished bug was discovered in Sun s \nJDK 1.1.4 imple- mentation of the bytecode verifier. A simple program exhibiting the incorrect behavior \nis shown in Figure 9. Line 8 of the program uses an uninitialized object, but this code is accepted by \nthis specific implementation of the verifier. Basically, the program is able to allocate two different \nuninitialized objects on the same line of code without initializing either one, violating the Con-s&#38;e&#38;nit \ninvariant. The program accomplishes this by allocating space for the first new object inside the sub- \nroutine and then storing the reference to that object in a local variable over which the subroutine is \npolymor- phic before calling it again. After initializing only one of the objects, it can use either \none. The bug can be attributed to the verifier not placing any restrictions on the presence of uninitialized \nobjects at calls to jsr L or ret Z. The checks made by Sun s verifier are analogous to the (jsr) and \n(ret) rule in Fig- ure 8 as they originally appeared in [SA98], without the additions described in the \nprevious section. Removing these lines allows subroutines to return uninitialized ob-jects to the caller \nand to store uninitialized values across subroutine calls, which clearly leads to problems. Although \nthis bug does not immediately create any security loopholes in the Sun Java Virtual Machine, it does \ndemonstrate the need for a more formal specifi-cation of the verifier. It also shows that even a fairly \nabstract model of the bytecode language is extremely useful at examining the complex relationships between \ndifferent parts of the language, such as initialization and subroutines. 7.2 The Corrected Sun Verifier \nAfter describing this bug to the Sun development team, they have taken steps to repair their verifier \nimplemen-tation. While they did not use the exact rules we have presented in this paper, they have changed \ntheir im-plementation to close the potential type loophole. This section briefly describes the difference \nbetween their ap-proach and ours. The Sun implementation may be sum- marized as follows [Lia97]: Uninitialized \nobjects may appear anywhere in the local variables or on the operand stack at j sr L or ret x instructions, \nbut they can not be used after the instruction has executed. In other words, their static type is made \nTOP in the post-instruction state. This difference does not affect the ability of either Sun s rules \nor our rules to accept code created for valid Java language programs. The static types assigned to uninitialized \nobjects passed into constructors are treated differently from other uninitialized object types in the \nSun verifier. Values with these types may still be used after being present at a call to or an exit from \na subroutine. Also, the superclass constructor may be called anywhere, including inside a subroutine. \n Treating the uninitialized object types for constructor arguments differently than other uninitialized \ntypes al- lows the verifier to accept programs where a subroutine must be called prior to invoking the \nsuper class con-structor. This is demonstrated by Figure 10. That fig-ure shows a constructor for class \nC, as well as a rough translation of it into JVML, with subroutines (we ig- nore the code required for \nthe exception handler). The bytecode translation of the constructor will be rejected by our analysis \nbecause control jumps to a sub- routine when a local variable contains the uninitialized object passed \ninto the constructor. It is accepted by the class C extends Object { co { 1: push 0 // put 0 on stack \nint i; 2: store 1 // store it in i,, try { 3: jsr 7 // jump to subroutine i = 0; 4: load 0 // load constructor \narg. } finally { 5: super C // call superclass cnstr. 1 6: halt super (1; > 7: store 2 // store return \naddress . . . 8: ret 2 // return from subroutine > Figure 10: A constructor which will always call a \nsubroutine before invoking the super class constructor, and its translation into JVML, with subroutines \n(ignoring the exception handler). Note that this is not a valid Java program. Sun verifier due to their \nspecial treatment of the type of the uninitialized object passed into the constructor. However, the Java \nlanguage specification requires that the superclass constructor be called prior to the start of any code \nprotected by an exception handler. There-fore, the Java program in Figure 10 is not valid. The added \nflexibility of their method is not required to ver-ify valid Java programs, but it does make the analysis \nmuch more difficult. In fact, several published attacks, including the one described in Section 1, may \nbe at- tributed to errors in this part of the verifier. Other verifiers, such as the Microsoft verifier, \ncurrently reject the bytecode translation of this class. In summary, the differences in the two verification \ntechniques would only become apparent in handwritten bytecodes using uninitialized object types in unusual \nways, and both systems are sufficient to type check translations of valid Java programs. Since our method, \nwhile slightly more restrictive, makes both verification and our soundness proofs much simpler, we believe \nthat our method is reasonable. Related Work There are several other projects currently examining bytecode \nverification and the creation of correct byte-code verifiers. This section describes some of these projects, \nas well as related work in contexts other than Java. There have also been many studies of the Java language \ntype system [Sym97, DE97, Nv098], but we will mostly focus on bytecode level projects. Although the other \nstudies are certainly useful, and closely re-lated to this work in some respects, they do not address \nthe unique way in which the bytecode language is used and the special structures in JVML. In addition \nto the framework developed by Stata and Abadi (SA98] and used in this paper, there are other strategies \nbeing developed to describe the JVML type system and bytecode verification formally. The most closely \nrelated work is [Qia98], which presents a static type system for a larger fragment of JVML than is pre- \nsented here. While that system uses the same general approach as we do, we have attempted to present \na simpler type system by abstracting away some of the unnecessary details left in Qian s framework, such \nas different forms of name resolution in the constant pool and varying instruction lengths. Also, our \nmodel of sub- routines, based on the work of Stata and Abadi, is very different. The rules for object \ninitialization used in the original version of Qian s paper were similar to Sun s faulty rules, and they \nincorrectly accepted the program in Figure 9. After announcing our discovery of Sun s bug, a revised \nversion of Qian s paper containing rules more similar to our rules was released. Hagiya and Tozawa present \na type system for the fragment of JVML concerning subroutines [HT98]. We are currently examining ways \nin which ideas from that type system may used to eliminate some of the simpli- fications to the subroutine \nmechanism in the work of Stata and Abadi. Another approach using concurrent constraint pro-gramming is \nalso being developed [Sar97]. This ap-proach is based on transforming a JVML program into a concurrent \nconstraint program. While this approach must also deal with the difficulties in analyzing sub-routines \nand object initialization statically, it remains to be seen whether it will yield a better framework \nfor studying JVML, and whether the results can be easily translated into a verifier specification. Other \navenues toward a formal description of the verifier, including model checking [PV98] and data flow analysis \ntechniques [Go198], are also currently being pursued. A completely different approach has been taken \nby Cohen, who is developing a formal execution model for JVML which does not require bytecode verifica-tion \n[Coh97]. Instead, safety checks are built into the interpreter. Although these run-time checks make the \nperformance of his defensive JVM too slow to use in practice, this method is useful for studying JVML \nexe-Cllt.i~Jll and understanding the checks required to safely execute a program. The Kimera project \nhas developed a more experi-mental method to determine the correctness of exist- ing bytecode verifiers \n[SMB97]. After implementing a verifier from scratch, programs with randomly inserted errors were fed \ninto that verifier, as well as several com- mercially produced verifiers. Any differences among im- plementations \nmeant a potential flaw. While this ap-proach is fairly good at tracking down certain classes of implementation \nmistakes and is effective from a soft- ware engineering perspective, it does not lead to the samt concise, \nformal model like some of the other ap-proaches, including the approach presented in this pa-per. It, \nalso may not find JVML specification errors or more complex bugs, such as the one described in Sec-tion \n7. Other recent work has studied type systems for low- level languages other than JVML, These studies \ninclude the TIL intermediate languages for ML [TMC+96], and the more recent work on typed assembly lan-guage \n[MCGW98]. The studies touch on some of the same issues as this study, and the type system for typed assembly \nlanguage does contain a distinction between types for initialized and uninitialized values. However, \nthese languages do not contain some of the constructs found in JVML, and they do not require aspects \nof the static analysis required for JVML, such as the alias analysis required for object initialization. \n9 Conclusions and Future Work Given t,he need to guarantee type safety for mobile Java code, developing \ncorrect type checking and anal-ysis techniques for JVML is crucial. However, there is no existing specification \nwhich fully captures how Java bytecodes must be type checked. We have built on the previous work of Stata \nand Abadi to develop such a specification by formulating a sound type system for a fairly complex subset \nof JVML which covers both sub-routines and object initialization. This is one step to- wards developing \na sound type system for the whole bytecode language. Once this type system for JVML is complete, we can \ndescribe a formal specification of the verifier and better understand what safety and security guarantees \ncan be made by it. Although our model is still rather abstract, it has already proved effective as a \nfoundation for examining both .JVML and existing bytecode verifiers. Even with- out a complete object \nmodel or notion of an object heap, we have been able to study initialization and the inter- action between \nit and subroutines. In fact, a previously unpublished bug in Sun s verifier implementation was found \nas a result of the analysis performed while study-ing the soundness proofs for this paper. The work described \nin this paper opens several promising directions. One major task, which we are currently undertaking, \nis to extend the specification and correctness proof to the entire JVML, includ-ing the method call stack \nand a full object system. The methods described in Section 6 allow most vari-ants of simple instructions \nto be added in a stan-dard, straightforward way, and we are also examining methods to factor JVML into \na complete, yet mini-mal, set of instructions. In addition, the Java object, system has been studied \nand discussed in other con-texts [AG96, Sym97, DE97, Qia98], and these previous results can be used as \na basis for objects in our JVML model. We are in the process of finishing a soundness proof for a language \nencompassing the JVML elements presented in this paper plus objects, interfaces, classes, arrays, and \nexceptions. Other issues that have not been addressed to date are concurrency and dynamic load-ing, both \nof which are key concepts in the Java Virtual Machine. We also believe it will be feasible to generate \nan im- plementation of a bytecode verifier from a specification proven to be correct. This specification \ncould be ex-pressed in the kind of typing rules we use here, or some variant of this notation. Finally, \nwe expect that in the long run, it will be use- ful to incorporate additional properties into the static \nanalysis of Java programs. If Java is to become a popu- lar and satisfactory general-purpose programming \nlan-guage, then for efficiency reasons alone, it will be nec- essary to replace some of the current run-time \ntests by conservative static analysis, perhaps reverting to run-time tests when static analysis fails. \nFor example, we may be able to eliminate some run-time checks for ar-ray bounds and pointer casts. Other \nsafety properties, such as the use of certain locking conventions in a con- current JVML model, could \nalso be added to our static analysis. Acknowledgments: Thanks to Martin Abadi and Raymie Stata (DEC SRC) \nfor their assistance on this project. We thank Li Gong for his encouragement, and Frank Yellin and Sheng \nLiang of JavaSoft for several useful discussions. References [AG96j Ken Arnold and James Gosling. The \nJava Program- ming Language. Addison-Wesley, 1996. [Coh97] Rich Cohen. Defensive Java Virtual Machine \nVersion 0.5 alpha Release. Available from [DE971 [DFW96] [ Go1981 [I-IT981 [Lia97] [LY96] [MCGW98] [NV0981 \n[PV98] [Qia98] ISA981 [Sar97] [SMB97] ISym971 [TMC:+96] http://www.cli.com/software/djvm/index.html, \nNovember 1997. S. Drossopoulou and S. Eisenbach. Java is type safe -~ probably. In European Conference \nOn Object Ori-ented Programming, pages 389-418, 1997. Drew Dean, Edward W. Felten, and Dan S. Wallach. \nJava security: from HotJava to netscape and beyond. In Proceedings of the IEEE Computer Society Sym-posium \non Research in Security and Privacy, pages 190-200, 1996. Allen Goldberg. A specification of java load-ing \nand bytecode verification. In Proceedings of the Fifth ACM Conference on Computer and Communications \nSecurity, 1998. Available from http://www.kestrel.edu/-goldberg. Masami Hagiya and Akihiko Tozawa. On \na new method for dataflow anal-ysis of Java Virtual Machine subrou-tines. Available from http://nicosia.is.s.u-tokyo.ac.jp/members/hagiya.html. \nA prelimi-nary version appeared in SIG-Notes, PRO-17-3, Information Processing Society of Japan, 1998. \nSheng Liang. personal communication, November 1997. Tim Lindholm and Frank Yellin. The Java Virtual \nMachine Specification. Addison-Wesley, 1996. Greg Morrisett, Karl Crary, Neal Glew, and David Walker. \nFrom system F to typed assembly language. In Proc. 25th A CM Symposium on Principles of Pro- gramming \nLanguages, January 1998. Tobias Nipkow and David von Oheimb. JaVa[,ght is Type-Safe -Definitely. In Proc. \n25th ACM Sympo-sium on Principles of Programming Languages, Jan-uary 1998. Joachim Posegga and Harald \nVogt. Byte code veri-fication for java smart cards based on model check-ing. In 5th European Symposium \non Research in Computer Security (ESORICS), Louvain-la-Neuve, Belgium, 1998. Springer LNCS. Zhenyu Qian. \nA formal specification of Java Virtual Machine instructions for objects, methods and sub-routines. In \nJim Alves-Foss, editor, Formal Syntax and Semantics of Java. Springer-Verlag, 1998. Raymie Stata and \nMartin Abadi. A type system for Java bytecode subroutines. In Proc. 25th ACM Sym-posium on Principles \nof Programming Languages, January 1998. Vijay Saraswat. The Java bytecode verifica- tion problem. Available \nfrom http://www.re- search.att.com/*vj, November 1997. Emin Giin Sirer, Sean McDirmid, and Brian Ber-shad. \nKimera: A Java system architecture. Avail-able from http://kimera.cs.washington.edu, Novem-ber 1997. \nDon Syme. Proving Java type soundness. Techni- cal Report 427, University of Cambridge Computer Laboratory \nTechnical Report, 1997. D. Tarditi, G. Morrisett, P. Cheng, C. Stone, R. Haroer. and P. Lee. TIL: A type-directed \nop- . timizing compiler for ML. ACM SIGPLAN Notices, 31(5):181-192, May 1996. Sun, Sun Microsystems, \nand Java are trademarks or registered trade-marks of Sun Microsystems, Inc. in the United States and \nother countries. Xenon.Stanford.EDU:freunds  1 final.ps Thu Jul 16 13:02:58 1998 Printer: HP LaserJet \nIIISi Stanford University CSD Computer Facilities \n\t\t\t", "proc_id": "286936", "abstract": "In the standard Java implementation, a Java language program is compiled to Java bytecode. This bytecode may be sent across the network to another site, where it is then interpreted by the Java Virtual Machine. Since bytecode may be written by hand, or corrupted during network transmission, the Java Virtual Machine contains a <i>bytecode verifier</i> that performs a number of consistency checks before code is interpreted. As illustrated by previous attacks on the Java Virtual Machine, these tests, which include type correctness, are critical for system security. In order to analyze existing bytecode verifiers and to understand the properties that should be verified, we develop a precise specification of <i>statically-correct</i> Java bytecode, in the form of a type system. Our focus in this paper is a subset of the bytecode language dealing with object creation and initialization. For this subset, we prove that for every Java bytecode program that satisfies our typing constraints, every object is initialized before it is used. The type system is easily combined with a previous system developed by Stata and Abadi for bytecode subroutines. Our analysis of subroutines and object initialization reveals a previously unpublished bug in the Sun JDK bytecode verifier.", "authors": [{"name": "Stephen N. Freund", "author_profile_id": "81100165065", "affiliation": "Department of Computer Science, Stanford University, Stanford, CA", "person_id": "PP14068105", "email_address": "", "orcid_id": ""}, {"name": "John C. Mitchell", "author_profile_id": "81338490160", "affiliation": "Department of Computer Science, Stanford University, Stanford, CA", "person_id": "PP43125642", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/286936.286972", "year": "1998", "article_id": "286972", "conference": "OOPSLA", "title": "A type system for object initialization in the Java bytecode language", "url": "http://dl.acm.org/citation.cfm?id=286972"}