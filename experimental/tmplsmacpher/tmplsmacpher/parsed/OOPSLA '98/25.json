{"article_publication_date": "10-01-1998", "fulltext": "\n Reasoning about Java Classes (Preliminary Report) Bart Jacobs, Joachim van den Berg, Marieke Huisman, \nMartijn van Berkum Dep. Comp. Sci., Univ. Nijmegen, P.O. Box 9010, 6500 GL Nijmegen, The Netherlands. \n{bart,joachim,marieke,mvberkum}8cs.kun.n1 Ulrich Hcnsel, Hendrik Tews Inst. Theor. Informatik, TU Dresden, \nD-01062 Dresden, Germany. {hensel,tews}Qtcs.inf.tu-dresden.de Abstract WC present the first results of \na project called LOOP, on formal methods for the object-oriented language Java. It aims at verification \nof program properties, with support of modern tools. We use our own front-end tool (which is still partly \nunder construction) for translating Java classes into higher order logic, and a back-end theorem prover \n(namely PVS, developed at SRI) for reasoning. In several examples we demonstrate how non-trivial properties \nof Java programs and classes can be proven following this two-step approach. 1 Introduction Being able \nto reason about programs has always been one of the central objectives of research in computer science. \nProgress in this area is slow, because the subject matter is complicated. In order to reason about a \nprogram, one first has to assign meaning to this program (usually as some function acting on states), \nand then reason (using a suitable logic) about what this program does. Such reasoning is often subtly \ndifferent from ordinary mathematical reasoning be-cause of typical imperative phenomena, like side-effects, \nor because of different forms of partiality (ordinary or abrupt termination, e.g. via exceptions). This \npaper concentrates on reasoning about Java [5, lo]. Java is quickly becoming one of the most widely used \npro- gramming languages. Being able to reason about programs and classes in Java--and hence being able \nto establish cor- rectness or incorrectness of a Java implementation with re- spect to some specification, \nsee explicitly in Subsection 4.6 --- is of considerable interest. We use a proof tool (namely PVS [22]) \nfor reasoning, and avoid arguments by hand - which are generally considered less trustworthy. Using such \na proof assistant in this area has definite advantages. l A proof tool keeps track of which results have \nand which have not been proved. It can easily tell a user if all the assumptions on which a certain result \nrelies Permission to make d,g,tal 0, hard copes of all o, part of th,s work for personal o, c,ass,oom \nuse ,s granted w,thout fee provided that copes are not made o, dlstrlbuted to, protlt o, commewal advan-tage \nand that copes bear this no,,ce and the full c,tat,on on the tlrst page To copy otherwIse. 10 ,epubl,sh. \nIO post on servers o, 10 redtstribute to I,sts, ,equ,,es p,,o, specihc pe,m,ss,on and/or a fee. OOPSLA \n98 lo/98 Vancouver. B.C. 0 1998 ACM l-581 13.005.8/98/0010...$5.00 have been proved. These are typical \nbureaucratic ac-tivities, which can best be done by tools, because they often lead to mistakes, when \ndone by humans. Other such bookkeeping activities include keeping track of all case distinctions in a \nproof---which there are usu-ally many, when reasoning about programs. Program verification involves much \nroutine equational and Boolean reasoning. A tool can do this very well, once it has been loaded with \nappropriate rewrite rules (and decision procedures). Side-effects are important when dealing with imper-ative \nprograms. However, they are notoriously hard to reason about. Once they are properly incorporated in \nPVS theories, the proof tool helps the user to keep track of all these side-effects, and to make the \nright deduction steps. Side-conditions which are required to hold before an auxiliary lemma can be applied \nare enforced by the tool. This helps to prevent small mistakes. In brief, a proof assistant is like \na sceptic colleague who patiently checks all details and is willing to do routine tasks. An assertional \napproach (as used by such a proof tool, or possibly also by someone reasoning by hand) has a definite \nadvantage over testing: by testing one only checks a limited number of cases . In contrast, using assertional \nmethods one can prove statements of the form: for all parameters it is the case that .... This achieves \nan appropriate level of generality (and thus, confidence). So far we have discussed the use of a proof \nassistant in our project. Such a tool is used as a back-end, to our own tool, which we call LOOP (for \nLogic of Object-Oriented Program-ming). The LOOP tool translates Java classes into higher order logic, \nthus providing input for the back-end proof tool Selecting appropriate test cases is indeed a major issue \nin this area. PVS. In translating .Java classes to logic, the LOOP tool pro-vides a logical semantics \nfor Java. This will be an important topic in the paper. The LOOP tool is still under develop-ment, but \nwhat we discuss here is a version which automat-ically translates a non-trivial part of Java. For example, \nit handles inheritance and late binding in Java classes, but it does not handle threads. What we shall \ndescribe is a part of a more general LOOP tool described in [13] for translating object-oriented specifi-cations \ninto higher order logic. The tool performs the fol-lowing transformations. First it reads (lexes and \nparses) classes in CCSL (Coalge-braic Class Specification Language, see [13]) or Java, and transforms \nthese in some internal representation in the pro-gramming language Ocaml [24, 201 (the implementation \nlan-guage of LOOP). This representation is subjected to certain internal analyses, e.g. for establishing \nthe inheritance rela-tionships between classes. Finally, it is transformed into theories (and proofs) \nof the PVS theorem prover [22]. Much of the internal code of the tool is shared for both the trans-lations \nfrom CCSL and Java classes to PVS. The earlier paper [13] on CCSL showed the merits of a coalgebraic \nap-proach in the mathematically clean world of specification. Here, in contrast, we show that the coalgebraic \nframework can properly handle the messy details that come with an ex-isting real-world object-oriented \nprogramming language (for which we use Java as an example). In doing so, we use many of the semantical \nideas and results that have been developed over the past few decades. This LOOP tool (on Java classes) \nis typically used as follows. Assume a user wishes to prove a certain prop-erty about a particular Java \nclass (or about a collection of classes). For example, that a certain method always ter-minates normally, \nor that some property is an invariant of a class. The user can run the LOOP tool on the class2, say with \nname MyClass. The tool then produces a new file, called MyClass-basic .pvs3. It contains a translation \ninto the higher order logic of PVS of the Java class in the origi-nal file. This forms the basis for \nthe user s own work: (s)he can now create a separate file, say MyClass-user. pvs, with We always assume \nthat Java classes which are fed into the LOOP tool are accepted by a (standard) Java compiler. Also, \nat this stage, all Java classes that have to be translated are required to be in one input file for the \nLOOP tool. 3Actually, it also produces a file MyClass-basic.prf, containing proofs of standard results \nin the file NyClass_basic.pvs. This proof file is not relevant here. user-defined theories in which the \ngenerated theories from MyClass-basic .pvs are imported. Here the statements that the user wishes to \nprove about the (translated) Java class should appear. All these ( .pvs) files can be loaded into the \nPVS theorem prover, and the user can start trying to prove the desired results, using result of the translation \nof the LOOP tool. Summarising: I Java classes v I theories and proofs + QED, hbpefully 4 In this paper \nwe describe several examples of this two-step approach, usually by presenting: (1) the original Java \nclass(es) on which the LOOP tool is run, (2) some relevant details of the resulting translation, (3) \nsome propositions in PVS that we wish to prove, and possibly, (4) some details of the actual proof. See \nthe above diagram in which these four points can be recognised. This project makes heavy use of traditional \nresults and techniques from the semantics of programming languages, see e.g. [6, 21, 12, 261. In a nutshell, \ntraditional reason-ing about programs in a language C proceeds as follows. First, a suitably rich mathematical \nstructure 2, is identified, which can serve as semantic domain for fZ, and as domain of reasoning. Then, \nan interpretation function [I - 1: L: + V is written out, mapping the well-formed expressions of C to \nelements of the domain D. Usually, this interpretation func-tion is compositional , so that the interpretation \n[I si; s2 1 of a composite statement si; s:, is equal to [ si I# [ s2 I], where # is a composition operation \ndefined on V. Once this inter-pretation function is given, one can prove properties about statements \ns in G by reasoning about [SD in D. Basically the same approach forms the basis of the trans-lation of \nJava classes into the higher order logic of PVS, as performed by the LOOP tool. But also, there are some \nno-table differences: l The semantic domain V is not described in the ordi-nary language of mathematics, \nbut in the logic and type theory of PVS. These descriptions form part of certain prelude PVS files, which \nare common to all translations, see Section 2. l The interpretation function [-I] is not written out \nby hand, but calculated by the LOOP tool. How to do this translation is of course a major issue in this \nproject. Section 3 gives more information. Proofs about the resulting interpretation are not done by \nhand but by using a theorem prover (in this case PVS), as already discussed above. The translation works \nfor object-oriented programs, organised in classes. Therefore, the relations between classes (inheritance \nis a subclass of , and aggregation is a component of ) have to be translated appropri-ately, so that \noperations from one class are available (if needed) in another. This is based on a coalgebraic analysis \nof classes, see e.g. [23, 17, 181. Certain additional definitions are generated automat-ically. Especially, \nfor each class appropriate notions of invariance and bisimilarity are generated, see Subsec- tion 4.5. \nThese notions make it easier for the user to express certain results. For each field and method in a \ntranslated Java class ap- propriate rewrite lemmas are generated. These greatly improve automatic reasoning. \n What distinguishes the current project from other formal approaches to object-orientation (see e.g. \n[l, 21) is the com-bination of a coalgebraic semantics of classes, and extensive use of tools, both for \ntranslating and for reasoning. The use of coalgebras emphasises that a state space forms a black box \nwith only limited access to its elements. This naturally leads to notions of bisimilarity (observational \nindistinguishability) and invariance-for reasoning about objects-which are fun-damental in the theory \nof coalgebras, see e.g. [19, 18, 251. Also, modeling statements and expressions as coalgebraic state \ntransformer functions (see in the next section below) allows a natural treatment of non-termination (which \nis non- trivial in algebraic setting) and also of abrupt termination (e.g. caused by exceptions). The \nlogic that we use for reasoning about Java classes is (ultimately) the higher order, classical logic \nof the proof tool PVS. Current work involves incorporation of Hoare logic [15, 31, via appropriate definitions \nand rules in PVS. This will enable us to use standard reasoning techniques in program verification, including, \nfor example, variants and bad style (e.g. because of multiply occurring variable names, or control flow \nvia too many return s, break s, continue s or exceptions). It turns out that such programs are difficult \nto reason about-and therefore good test programs for our approach. Formal verification of software will \nalways remain a knowledge and labour intensive activity, but we hope that (eventually) our tool can contribute \nto this area. For ex-ample, it may become worthwhile to formally verify certain properties of classes \nwhich go into standard class libraries or into safety critical applications. This paper is organised \nas follows. It starts with a brief description of the logical semantics that is used for Java. Subsequently, \nin Section 3 the translation that is performed by the LOOP tool is sketched. Both these are substantial \ntopics, which we can only touch upon in the current paper. The remainder of the paper is devoted to (typical) \nexamples. It discusses reasoning about a non-trivial method body, in-heritance and late binding, local \nvariables and recursion, while loops with breaks and continues, invariance results, and also, briefly, \ncomponent classes. 2 Java semantics in the higher order logic of PVS In this section we give an impression \nof the LLprelude PVS files which provide the background for the translation of Java classes into higher \norder logic. They incorporate the semantic structure V, as discussed in the previous section. This prelude \nis divided into five files, describing the relevant datatypes, statements, expressions, operations, and \nthe un-derlying memory model. The total size of these PVS files is just under 200K (about 6000 lines). \nWe concentrate on some essential ingredients. Two important syntactic categories in Java are state-ments \nand expressions. These will both be translated as state transformer functions (in PVS), namely as: [Self \n-> StatResult? [SelfII and [Self -> ExprResult?[Self, Out]] invariants for while loops ([16]). In the \ncurrent paper we shall not use Hoare logic, and our reasoning is directly based on definitions. The work \non the LOOP project can be divided into the following categories (with initials of the authors who con-tribute \nmost to these parts): (1) Java semantics (BJ, MH), (2) automatic translation (JvdB, MvB, BJ), (3) proofs \nand proof methods (MH, BJ), (4) general LOOP infrastructure (UH, HT). We should emphasise that this is \nvery much work in progress, and that we are nowhere near a complete trans- lation of all possible Java \nclasses. The most important re- strictions are discussed in Section 3. But, as we hope that the examples \nbelow demonstrate, we can already handle a substantial part of the language. The manner in which it \nis done is of general interest, and the main topic of this paper. So far we have tested our tool only \non microscopic ex-amples: our tests are not as big as possible, but as sick as possible. A semantics \nfor a language like Java should of course also include programs which are generally considered The type \nSelf is a parameter for the underlying state space4, and Out is the parameter type of the output of the \nexpres-sion. We frequently use the question mark ? in PVS expres-sions on which our translation is based \nbecause ? s cannot occur in Java keywords nor in Java identifiers, and so we can prevent name clashes. \nIt clutters up the notation a bit, but it probably is best simply to ignore all these ? s. A more important \npoint is that these state transformer functions are examples of coalgebras (see [19]): they have a struc-tured \ntype (StatResult? or ExprResult?, and not Self) as codomain. Such functions cannot be written down in \nalge-braic approaches (where one typically has structured types as domains). The approach we use to give \nsemantics to Java (as implemented in the LOOP tool) is based on coalgebras, and is thus perfectly able \nto handle such (statement and expression) functions. 41n the actual translation, Self will be instantiated \nas OM?, describ- ing the global memory, see the end of this section. PreStatResult?[Self, Abnormal : \nTYPE1 : DATATYPE BEGIN hang? : hang?? norm?(ns? : Self) : norm?? abnorm?(dev? : Abnormal) : abnorm?? \nEND PreStatFlesult? PreExprResult?[Self, Abnormal, Out : TYPE] : DATATYPE BEGIN hang? : hang?? norm?(ns? \n: Self, res? : Out) : norm?? abnorm?(dev? : Abnormal) : abnorm?? END PreExprResult? ExprAbn? [Self : \nTYPE] : DATATYPE BEGIN IMPORTING ExceptionInterpretation excp?(es? : Self, ex? : ExcpIds) : excp?? END \nExprAbn? StatAbn?[Self : TYPE] : DATATYPE BEGIN IMPORTING ExceptionInterpretation, Lift?[stringl excp?(es? \n: Self , ex? : ExcpIds) : excp?? rtm?(rs? : Self) : rtrn?? break?(bs? : Self, blab? : Lift?[stringl) \n: break?? cont?(cs? : Self, clab? : Lift?[string]) : cant?? END StatAbn? Figure 1: The four main datatypes \nused for the translation The above codomain types of statements and expressions are abbreviations, obtained \nby substitution: StatResult? [Self] = PreStatResult? [Self, StatAbn? [Self]] ExprResult? [Self, Out] \n= PreExprResult? [Self, ExprAbn? [Self] , Out] Out of the expression. Hence there is a binary constructor \nnorm? in the data type PreExprResult?, with a state in Self and a result in Out as arguments. In these \ndefinitions it is convenient to keep a type Abnormal of abnormalities as parameter. The standard instantiation \nfor Abnormal in PreStatResult? is the type StatAbn? describing the possi- ble abnormalities for statements. \nThese include exceptions, returns, breaks and continues. The latter two statements may occur in Java \nwith or without a label. This possibility is captured in our translation by using a Lift? [string] ar-gument \nfor the break and continue constructors break? and cant? in StatAbn?-where the type Lift? [Xl adds a \n(new) bottom element to an arbitrary type X. In a similar fashion, the type ExprAbn? captures abnormalities \nin expressions (namely, exceptions only). On the basis of these datatypes we can already intro-duce some \nbasic program constructs. For example, a com- position (infix) operator # (intended as translation of \n; in Java) is defined in PVS. It takes two statements s, t of type [Self -> StatResult?[Selfl] and produces \na new state-ment s # t describing s followed by t, again of type [Self -> StatResult? [Self] 1. It is \ndefined as: (s # t) : [Self -> StatResult?CSelflJ = LAMBDACx : Self) : IF norm??(s(x)) THEN t(ns?(s(x))) \nELSE s(x) ENDIF Thus if s terminates normally in state x, resulting in a next state y = ns?(s(x)), then \n(s # t) (x) is t(y). And if s hangs or terminates abnormally in state x, then (s # t) (x) is s(x) and \nt is not executed. It is not hard to show that It is associative, and has a (left and right) unit skip?, \ngiven by skip? (x1 = norm?(x) Hence statements form a monoid. In a similar manner we define a conditional \nstatement, written as IF?THEN_ELSE(c) (s)(t), for a Boolean expres-sion c of type [Self -> ExprResult?[Self, \nboo111 and two statements s, t, as: involving four data types in PVS, see Figure 1. The two output types \nPreStatResult? and PreExprResult? de-scribe the possible outcomes of statements and expressions, as state \ntransformer functions. A (translated) statement in a particular state can either hang (yield outcome \nhang?), ter-minate normally (with outcome norm? lx), where x is a new state in Self), or terminate abnormally/abruptly \n(with out-come abnorm? (y) , with y describing the kind of abnormal- ity). The latter is used to model \nexceptions and statements affecting the control flow like break, return, and continue. In contrast an \noutcome hang? corresponds to non-termination. The PVS expressions hang?, norm? and abnorm? are the constructors \nof the datatype PreStatResult?. The associ-ated recognisers are hang??, norm?? and abnorm??, telling \nwhether an element in PreStatResult? is of the form hang?, norm? (x1 or abnorm? (y) , respectively. The \nassociated ac-cessors are ns? (extracting the x in norm?(x)) and dev? (extracting y in abnorm?(y)). The \noutcome of a (trans-lated) expression is very similar, except that normal ter-mination produces a (new) \nstate-because expressions can have side-effects-together with a result in the output type IF?THEN-ELSE(c)(s)(t) \n: [Self -> StatResult?CSelfll = LAMBDA(x : Self) : IF hang??(c(x)) THEN hang?? ELSIF norm??(c(x)) THEN \nIF res?(c(x)) THEN s(ns?(c(x))) ELSE t(ns?(c(x))) ENDIF ELSE abnorm?(excp?(es?(dev?(c(x))), ex?(dev?(c(x))))) \nENDIF  In this manner, Java constructs are translated in the pre-lude files, following the explanations \nin [lo]. Another such example is a RETURN? statement in PVS, defined as: RETURN? : [Self -> StatResult?[Selfll \n= LAMBDACx : Self) : abnorm?(rtrn?(x))  It creates a return abnormality, see Figure 1. There are anal- \nogous statements for throwing other abnormalities. Simi-larly, the two conjunction operators &#38; and \n&#38;I&#38; of Java are translated as AND and ANDTHEN in PVS, respectively. They are defined on Boolean \nexpressions e, d as: (e AND d) : [Self -> ExprResult?[Self, boo111 = LAMBDA(x : Self) : IF norm??(e(x)) \nTHEN LET y = ns?(e(x)), I = res?(e(x)) IN IF norm??(d(y)) THEN norm?(ns?(d(y)), r AND res?(d(y))) ELSE \nd(y) ENDIF ELSE e(x) ENDIF (e ANDTHEN d) : [Self -> ExprResult?[Self, boo111 = LAMBDA(x : Self) : IF \nnorm??(e(x)) THEN LET y = ns?(e(x)), r = res?(e(x)) IN IF NOT r THEN e(x) ELSE d(y) ENDIF ELSE e(x) \nENDIF Notice how side-effects are propagated through these com-posite expressions, via the intermediate \nstate y. Both AND and ANDTHEN equip the type of Boolean expressions with a monoid structure (both with \nthe constantly true expression as unit). Similar, but more complicated translations are formu-lated for \nswitch, while, etc. The latter works on a Boolean expression and a statement, and basically iterates \nthe state-ment a certain number of times, in case there is an n such that after n iterations the expression \nbecomes false, or an abrupt termination occurs. If there is no such n, the while statement hangs. We \ncan declaratively make this distinction in logic. More details are given in Subsection 4.4. We describe \na few more functions, that will be used be- low. Every element a:Out of an output type Out is turned \ninto a constant expression of type Out via the definition: const?(a) : [Self -> ExprResult?[Self, Out]] \n= LAMBDA(x : Self) : norm?(x, a) We have a special function E2S? for transforming an expres-sion e into \na statement, essentially by forgetting the output, if any. E2S?(e) : [Self -> StatResult?[Selfl] = LAMBDA(x \n: Self) : IF hang??(e(x)) THEN hang? ELSIF norm??(e(x)) THEN norm?(ns?(e(x))) ELSE abnorm?(excp?(es?(dev?(e(x))), \n ex?(dev(e(x))))) ENDIF Certain constructs in Java may be used both as expressions and as statement. \nThese constructs are then standardly translated as expressions, and E2S? is applied to them when they \nare used as statements. There is another useful (infix) operation ##, which produces an expression e \n## d from two expressions e and d by applying d to the (normal) state produced by e, while keeping the \nresult of e. IF norm??(e(x)) THEN LET y = ns?(e(x)), r = res?(e(x)) IN IF norm??(d(y)) THEN norm?(ns?(d(y)), \nr) ELSE d(y) ENDIF ELSE e(x) ENDIF This operation ## is used in the translation of <post oper-ations \n(such as post-increment i++), where first a value is produced and then some operation is performed. Examples \nwill appear below. A large part of our prelude files is devoted to suitable rewrite lemmas for all these \ndefinitions. They enable PVS to handle substantial parts of proofs automatically via rewrit-ing. These \nlemmas are usually very easy and follow almost directly from the definitions, but they are extremely \nuseful for automatic reasoning. In one of the prelude files a model OM? of an object mem-ory is defined, \ncontaining an infinite number of memory cells, each capable of storing an object. It comes equipped with \noperations for reading and writing values and refer-ences at particular positions. All classes are translated \nas coalgebras, see the next section, acting on (a position in) this global state space OM?. 3 Translating \nJava classes The LOOP tool calculates a function [ -1 which assigns meaning to Java classes. It follows \nthe Java grammar [lo, Chapter 191, and takes e.g. [el &#38; e21 = [elj AND [e21 as PVS translation of \nel &#38;I e2 in Java. Such clauses are handled, one-by-one, by Ocaml s yacc. Basically, this is how the \ntranslation works. But there is much more to say. Ignoring static initialisers, a class in Java consists \nof fields, methods and constructors. The latter are not trans-lated yet, but seem to present no fundamental \ndifficulties. so we concentrate on fields and methods. The fields (some-times called instance variables) \nand methods of a class arc collected by the LOOP tool in a PVS interface type (like in [13]). For each \nfield i an associated assignment operation i-becomes is generated. Thus, a class class MyClass I byte \ni, j; void stat-metho { . 1 float expr-methO 1 . 1 ) will give rise to the following interface (record) \ntype in PVS. MyClassIFace [Self 1 = C# i : byte, j : byte, i-becomes : [byte -> Self], j-becomes : \n[byte -> Self], stat-m&#38;h : StatResultCSelfl, expr-meth : ExprResultCSelf, float]  #I (e #X d) \n: [Self -> ExprResult?[Out]] = Hence we do not bother about garbage collection, and an LAMBDA(x : Self) \n: OutOfMemoryException is never thrown in our translated classes. A coalgebra for class MyClass is a \nfunction in PVS of the form c : [Self -> MyClassIFaceCSelfll where MyClassIFace [Self 1 is the interface \ntype generated for class MyClass. Such a coalgebra thus contains all the operations of a class in a single \nfunction. The individual operations can be extracted via (automatically generated) definitions like: \ni(c) : [Self -> byte] = LAMBDA(x : Self) : i(c(x)) stat-meth(c) : [Self -> StatResultCSelfll = LAMBDA(x \n: Self) : stat-meth(c(x))  In the sequel we shall always use individual operations with resnect to such \na coalgebra c. For more information about coalgebras (versus algibras), see [19]. Notice that the above \nfield i(c) in a coalgebra c has type [Self -> byte]. We would like to use it ai an express;&#38; with \ntype (Self -> ExprResult? [Self, byte] I. -This is achieved by translating every occurrence of i (in \nthe body of a Java method) as FSE? (i cc) ) , where F2E? is&#38; function< whose name is an abbreviation \nof field-to-expression--that is defined for an arbitrary result type Out as: F2E? : [[Self -> Out] -> \n[Self -> ExprResult?[Self, Out]]] = LAMBDA(f : [Self -> Out]) : LAMBDA(x : Self) : norm?(x, f(x))  Similarly, \nthe associated assignment operation i-becomes(c) has type [Self, byte -> Self]. We would like to use \nit as acting on an expression of type byte and producing an expression6 with result type byte. For this \nwe use a function A2E?, standing for assignment-to-expression. It is defined as: A2E? : [[Self, Out -> \nSelf] -> [[Self -> ExprResult?[Self, Out]] -> [Self -> ExprResult?[Self, Out]]]] = LAMBDA(a : [Self, \nOut -> Self]) : LAMBDA(e : [Self -> ExprResult?[Self. Out]]) : LAMBDA(x : Self) : IF norm??(e(x)) THEN \nLET y = ns?(e(x)), r = res?(e(x)) IN norm?(a(y, r), r) ELSE e(x) ENDIF The body of a method meth in \nclass MyClass gives rise to a predicate on a MyClass-coalgebra c which expresses that meth(c) is equal \nto the (translation of the) body of meth. That is, a method void move(int da, int db) ( fst = fst + da; \nsnd = snd + db;  in a class with integer fields fst and snd, is translated into a predicate called move-def? \non c, which expresses that for all states x, 'Assignments in Java can be expressions, like j = 5 in i \n= (j = 5). FORALL(da : int-java, db : int-java) : move(c)(x, da, db) = ( E2S?(A2E?(fst_becomes(c)) (F2E?(fst(c)) \n+ const?(da))) X E2S?(A2E?(snd_becomes(c)) (F2E?(snd(c)) + const?(db))) 1 (x)  The use of all these \nauxiliary functions E2S?, A2E?, F2E? looks a bit artificial in this simple example, because every-thing \nterminates normally and there are no side-effects. But that is not typical. (Actually, this is a simplified \nversion of the real translation which additionally involves a LET con-struct for handling the parameters \nda, db, see Figure 2 for a complete translation. The above serves to convey the main idea.) All method \ndefinitions are thus translated into predi-cates. The latter are combined via conjunction into a sin- \ngle predicate MyClassAssert? on the coalgebra c. A user can then develop the theory of coalgebras satisfying \nsuch predicates, incorporating how methods are implementated. These coalgebras can be seen as models \nof the class. This is basically as in [13]. This account simplifies matters slightly for explanatory \npurposes. We have already mentioned (at the end of the previous section) that all coalgebras operate \non the same state space OM?,describing a global memory. Each field dec-laration, say int i, is implemented \nvia a function, called get?int which can read a value at a particular location in OM?. The associated \nassignment operation (i-becomes) writes at this same location, via a function put?int. This memory location \nis a PVS variable p in the predicates defin-ing variables, assignments and methbd implementations, and \nultimatelv also MvClassAssert?. Hence as models of classes we really use functions in a dependent product \nof the form: d : [p : nat -> (MyClassAssert?(p))l so that d(p) is a coalgebra satisfying the method \nimple-mentations. (It should have been used instead of c above.) One can understand d(p) as an implementation \nof the class MyClass which acts on memory location p. In general, if a new variable of a class is created, \nit gets a (new) position p in the main memory OM? together with a coalgebra (of the class) acting on \nthis position p. An object is then basically a reference to a memory cell. Here we conclude our brief \nsketch of the translation that the LOOP tool performs. We emphasise that this transla-tion is far from \ncomplete. For example, it does not handle threads, and some of the language constructs are not, cov-ered \nyet (like constructors). However, the tool translates many statements and expressions already. Besides \nbeing incomplete, the translation also simplifies matters. For ex-ample, both floating point types float \nand double in Java are translated to the PVS type real. The latter is intro-duced axiomatically in PVS, \nand is for example dense and equipped with a complete order 5. The former are approx-imations of real \nnumbers (described precisely in the IEEE 754 floating point format). In order to translate accurately, \none would have to formalise this IEEE format in PVS. This is a non-trivial exercise, which is a project \non its own, see e.g. [7]. Similarly, we translate all Java integer types (byte, short, int, long and \nchar) to the PVS type int of integers, without taking bounds into account. Another (temporary) simplification \ninvolves exceptions. These are translated as sets of natural numbers (e.g. IndexOutOfBoundsException \nis {x : nat I50 <= x AND x < 60}, which is a completely ar-bitrary choice). Catching an exception then \ninvolves check-ing a subset relationship. This simplification works well in many situations because an \nexception object (like the e in the WeirdExpr class in the next section) is rarely really used (with \nas possible exception, in a print statement). The mo-tivation behind these simplifications is to be able \nto get a rudimentory translation off the ground, and not to be held up by initially irrelevant details. \n4 Examples In this section we elaborate some examples. In particular, we discuss: several Java classes, \ntheir translation into PVS by the LOOP tool, some results that a user may wish to prove (on the basis \nof the translation), and proofs of such results. Only the first example will be described in some detail. \nMany of the proofs of the results about Java classes that we present below are done by automatic rewriting. \nThis is very convenient and useful. But it is important to stress that this only works for simple (non-looping) \nstatements, such as assignments, conditionals, or operations. The more difficult statements with while \nor for loops or with recursion still require steering of the user at essential points (e.g. in order \nto find loop invariants). But also within such proofs the routine calculations can be done by automatic \nrewriting. 4.1 A weird method Consider the following (silly) Java class class WeirdExpr C int i; int \nlets-calculatecint j) I try { i *= (i > 5) ? (i++ % --j) : 8; } catch(Exception a) { j--i return i -j; \n.I return i + j; It contains an integer field i and a method lets-calculate yielding an integer after \nsome intricate computation involv-ing a conditional operator ? : and a remainder operation %. The latter \nthrows an exception, if its second argument is 0. The computation in itself is uninteresting, but the \nchallenge is to express the integer outcome (if any) of this method, in terms of the values of the parameter \nj, and the field i. In order to determine this outcome we have to take the following into account (among \nmany other things). The evaluation strategy: in the remainder expression i++ i! --j one computes the \nvalue of i as first argu- ment, then i is incremented, then j is decremcnted, and the resulting value \n(of j) is taken as second argu- ment, so that the remainder can finally be determined. l Exception handling: \nif the parameter j is 1, then the Java remainder operation % (translated as //) throws an ArithmeticException, \nwhich is caught by the sub- sequent catch clause--because ArithmeticException is a subclass of Exception; \nthis causes a particular flow of control. One of the subtleties in this example is that the increment \nexpression i++ only has a visible effect if the exception is thrown-because otherwise it is overruled \nby the *= assignment. l Return handling: the first return statement causes a jump of control to the end \nof the method. The latter two points are handled by the abnorm? option in statements and expressions \n(as discussed in the previous sec-tion). Special functions TRYPCATCH and CATCHEXPRRETURN? are defined \nwhich detect such abnormal outcomes. They remove certain abnormalities and take appropriate action. The \nfirst point is handled by suitable PVS representations of the (pre-and post-) increment/decrement and \nremainder operations, so that arguments are evaluated in the right or-der. See the analogous definitions \nof the AND and ANDTHEN functions in the previous section. Running the LOOP tool on this class yields \na series of PVS theories. They contain the translation of the method lets..calculate, given in Figure \n2. This translation is prob- ably unreadable, and not really meant for human consump-tion, but is included \nonly to show what really comes out. Hopefully, the reader will recognise the main structure of this Java \nmethod in its PVS translation, e.g. the Java con-ditional operator ? : translated as CHJESTION? in PVS. \nIt is not feasible to explain the whole translation in detail, so we will focus on some significant details. \nl The c and x variables in lets-calculate(c) (x, j) on the left hand side of the equation refer to the \ncoalgebra of the current class (i.e. of WeirdExpr) and the current state, respectively. Recall that methods \nand fields are always described with respect to some coalgebra. l A special local variable ret?lets-calculate \n(together with an associated assignment) is used for the output result of this method (which is returned \nat the end, by the CATCHEXPRRETURN? function). Another special Java variable par?j holds the value of \nthe PVS vari-able j (set at the beginning). It is used because PVS variables are different from Java \nvariables (for which there are assignments)r. For both these variables a new memory cell is allocated \nat the next free position, given by top?-after which the top? is incremented by topinc?. l A pre increment \nor decrement operation is translated simply by an assignment (which returns a value, see the previous \nsection). For a post increment or decre-ment operation we use the ## operation between two expressions, \nas described in the previous section. Using such an auxiliary variable also ensures that parameters \nare passed by value, see [S, 2.6.11. FORALL (j : int-java) : lets-calculate(c)(x, j) = LET ret?lets-calculate \n: [OM? -> int-javal = (LAMBDA(y: OM?) : get?int(y , top?(x) , I)), ret?lets-calculate-becomes : [[OM? \n, int-javal -> OM?l = (LAMBDA (y: OM? , v: int-java) : put?int(y , top?(x) , v , l)), par?j : [OM? -> \nint-java] = (LAMBDA (y: OM?) : get?int.(y , top?(x) , 0)). par?j-becomes : [[OM? , int-java] -> OM?] \n= (LAMBDA (y: OM? , v: int-java) : put?int(y , top?(x) , v , 0)) IN CATCH-EXPR-RETURN? (E2S?(A2E?(par?j_becomes)(const?(j))) \n# (TRY?CATCH ((E2S?(A2E?(i_becomes(c))((F2E?(i(c)) * QUESTION?((F2E?(i(c)) > const?(5))) (((F2E?(i(c)) \ntt A2E?(i_becomes(c))(inc(F2E?(i(c))))) // A2E?(par?j_becomes)(dec(F2E?(par?j))))) (const?(8))))))) \n((: (Exception , (E2S?((F2E?(par?j) #t A2E?(par?j_becomes)(dec(FZE?(par?j))))) # (E2S?(A2E?(ret?lets_calculate_becomes)((F2E?(i(c)) \n-F2E?(par?j)))) X RETURN?))) :))) # (E2S?(A2E?(ret?lets_calculate_becomes)((F2E?(i(c)) + F2E?(par?j)))) \nX RETURN?) ) (ret?lets-calculate)(topinc?(put?empty(x? , top?(x?)) , 1)) Figure 2: The LOOP translation \nof the weird method in PVS l The TRY?CATCH statement takes as argument a list of pairs-indicated in PVS \nby ( : :)-consisting of an exception class, together with the corresponding statement that should be \nexecuted if an exception of the kind in the first part of the pair occurs. In this example the list contains \nonly one pair. An example result that a user may wish to prove in PVS is the following. p : VAR nat \n d : VAR [m : nat -> (WeirdExprAssert?(m))] x : VAR OM?  lets-calculate-return : LEMMA FORALL(j : int-java) \n: norm??(lets-calculate(d(p))(x, j)) AND res?(lets-calculate(d(p))(x, j)) = IF i(d(p))(x) > 5 THEN IF \nj = 1 THEN i(d(p))(x) -j + 3 ELSE i(d(p))(x) * remainder(i(d(p))(x), j-1) + j -1 ENDIF ELSE i(d(p))(x) \n* 8 + j ENDIF  The lemma states that for all integers j, running the method lets-calculate with respect \nto the WeirdExpr coalgebra d(p) (acting in memory location p) in state x with parameter j terminates \nnormally (expressed by norm??(-)), and the resulting output value res?(-) satisfies the IF ... THEN .. \nELSE clause. It expresses the outcome of the method run in state x in terms of the values of the field \ni in state x and of the parameter j. Notice that the result involves a universal quantifier FORALL. It \nachieves a level of generality which can never be obtained by simply testing (i.e. by running the method \nfor specific values and checking the outcome). This shows the power of a theorem proving approach to \nformal verification. The above lemma can be proved in PVS by using basi-cally only two proof commands: \n(load-rewrite-theories .) and (do-rewrite). All the expressions in the lemma are then suitably rewritten \n(following the evaluation strategy of Java, as incorporated in the definitions of the prelude, see Section \n2) to the required result. This involves 222 sin- gle rewrite steps . Such rewriting must be done in \na clever manner, because the number of possibilities in each step is large: in principle, each expression \nand statement can hang, terminate normally, or terminate abruptly (involving vari-ous possible abnormalities). \nJust unfolding the definitions describing all possible outcomes quickly leads to screens full of unreadable \nPVS code. This complexity is managed by using many small rewrite steps for all cases in expressions and \nstatements from the prelude files (and by letting LOOP generate additional rewrite rules which are specific \nfor the translated class), so that in principle, complete definitions never have to be expanded. 0 the \nfastest machines at our disposal (a Pentium II 300 with 128M RAM, or an UltraSPARC 2 (model 2200) with \n1OOOM RAM admitting maximally 1 CPU per user) this takes in interactive mode (with prover output to the \nscreen, via emacs) about 2 min. run time, and a bit less than 3 min. realtime (including garbage collecting). \nIn batch mode, it takes less than half of the run time. 4.2 Inheritance: overriding, hiding and late \nbind-ing The previous example does not involve any typically object-oriented aspects. In this subsection \nwe consider some exam- ples with inheritance. At the level of interfaces (in PVS), inheritance is handled \nby nesting. For example, suppose we have classes: class A { float r, s; 1 class B extends A c float r, \nt; 1 Then interface types are generated of the following form. AIFace : TYPE = [# r : float,  s : float, \nr-becomes : [float -> Self], s-becomes : [float -> Self],  #I BIFace : TYPE = [# super-A : AIFace, \n r : float, t : float, r-becomes : [float -> Self], t-becomes : [float -> Self1  #I Definitions r(c), \ns(c), r-becomes(c) and s-becomes(c) are then automatically generated for a coalgebra c : [Self -> AIFace \n[Self 11 of class A, as discussed in the beginning of the previous section. For a coalgebra c : [Self \n-> BIFaceCSelfll of class B, there are similar definitions, of the following form-where we concentrate \non the fields. r(c) : [Self -> float1 = LAMBDA(x : Self) : r(c(x)) t(c) : [Self -> float] = LAMBDA(x \n: Self) : t(c(x)) s(c) : [Self -> float] = LAMBDA(x : Self) : s(super-A(c(x))) A-r(c) : [Self -> float] \n= LAMBDA(x : Self) : r(super-A(c(x))) In this manner the non-hidden field s from A is directly avail-able \nin B. And the hidden field r is also available, but under a different name A-r. This mechanism avoids \nsubtyping. It also underlies inheritance in CCSL [13]. At the level of method definitions we have to \nbe care-ful, because of overriding and late binding. In a class C we repeat all method definitions from \nsuper classes of C, but in-stantiated with a coalgebra from C. Late binding then works automaticallv. \nbut some care is needed to make sure that appropriate fields are selected. As an examole we consider \nthe translation of the fol-lowing series of >ava classes Parent -Child -Grandchild, defined via inheritance. \nclass Parent C int i; void base0 { i = 4; ) class Child extends Parent < int i, j; void derive { j = \n1; baseo; ) class Grandchild extends Child { void base0 { i = 8; ) The declaration int i in Child hides \nthe i from Parent, see [lo, Section 8.31, but running deriv in Child will affect i in Parent, and not \ni in Child. In contrast, running deriv in Grandchild will affect i in Child, but not i in Parent, due \nto the late binding mechanism which determines that within the Grandchild class deriv will call the (redefined) \nbase method from Grandchild. The aim is to prove the right values of the i s and j after running deriv \nin Child and in Grandchild, via automatic rewriting. The difficulty in this example is not located in \nthe complexities of the expressions involved, but in getting the bindings right. The LOOP tool solves \nthis difficulty by suitably repeating method definitions from superclasses in subclasses. Using the LOOP \ntranslation of these Java classes into PVS we first show that the method deriv terminates nor-mally (and \ndoes not hang or terminate abruptly). Then we can express the values of the fields in the resulting state \nafter deriv in terms of the original values as follows. For a Child coalgebra d(p) acting on an arbitrary \nmemory position p this is expressed in the following result. Child-deriv : LEMMA norm??(deriv(d(p))(x)) \nAND i(d(p))(ns?(deriv(d(p))(x))) = i(d(p))(x) AND j(d(p))(ns?(deriv(d(p))(x))) = 1 AND Parent-i(d(p))(ns?(deriv(d(p))(x))) \n= 4 The first assertion in the conjunction states that running the method deriv(d(p)) in an arbitrary \nstate x terminates normally. The next three statements describe the values of the variables i(d(p)), \nj(d(p)) and Parent-i(d(p)) (i.e. i from the super class Parent of child coalgebra d(p)) when evaluated \nin the normal state (accessed by ns?) resulting from running deriv (d(p) 1. For a Grandchild coalgebra \ngc (p> the required result is: Grandchild-deriv : LEMMA norm??(deriv(gc(p))(x)) AND i(gc(p))(ns?(deriv(gc(p))(x))) \n= 8 AND j(gc(p))(ns?(deriv(gc(p))(x))) = 1 AND Parent-i(gc(p))(ns?(deriv(gc(p))(x))) = Parent-i(gc(p))(x) \n Both lemmas are proved by automatic rewritingg. 'The Childderivlemma requires 36 rewrite steps, taking \nabout 10 sec. run time, and the GrandChildderiv lemma is proved in 40 steps, again in 10 sec. 4.3 Local \nvariables and recursion Sections 3 and 4.1 already briefly discussed how the LOOP tool handles parameters, \nlocal variables, and special vari-ables for returns. Here we describe this in more detail,, in the context \nof a recursive definition of the factorial function: class Fat 1 int fat (int n) C int i = 1; if (n != \n0) C i = n * fat (n -1); ) return i; The method fat has a parameter n, a local variable i and it returns \na value of type int. Local variables, just like parameters are handled in the LOOP translation via LETS \nin PVS, using a fresh memory location (see Figure 2). This will guarantee that whenever a new block is \nstarted (which may happen frequently, like in the above recursive method) new storage capacity is available. \nRecursion is handled by explicitly calculating the least fixed point of a suitable functional. This is \ndone by de-termining if there is a number n so that after n iterations the method does not hang. If this \nis the caSe the recursive definition is unfolded, the least such n times; otherwise the method hangs. \nThe least fixed point of this functional pro-vides the semantics for the recursive definition. The fixed \npoint approach actually works for mutually recursive func-tions as well, because we do not iterate individual \nmethods but the whole coalgebra (incorporating all methods). De-tails will be described elsewhere. Using \nthis formalisation we can prove, fat-lem : LEMMA FORALL(x : OM?, n : int-java) : IF n >= 0 THEN norm??(fac(c(p))(x, \nn)) AND res?(fac(c(p))(x, n)) = pvs-fat(n) ELSE hang??(fac(c(p))(x, n)) ENDIF where pvs-f ac is the \nusual factorial function, defined in PVS (for positive numbers). The proof proceeds by reasoning about \niterations (using induction over the natural numbers). 4.4 A while loop, with break and continue Towards \nthe end of Section 2 the semantics of a while state-ment is sketched: first it is decided if/when the \nloop ter-minates. If not, the while statement hangs, otherwise it comes down to executing the body the \nappropriate number of times. In Java, a while statement can terminate for two reasons: at some stage \n(1) its condition evaluates to false, or (2) execution of its expression or body statement terminates \nabnormally, because of an exception, break or return. Here we consider the following simple example. \nclass Loop ( int break-loop (int i) I lab : while (true) { if (i < 2O){i++; continue lab;) else break; \nreturn i: It involves a while loop in Java which terminates because of a break. Reasoning about while \nloops generally involves (see e.g. [3, 11, 9, 41) a loop invariant and also a variant. The latter is \na function from Self to some well-founded set,, which decreases with every execution of the loop body. \nVari-ants are used for proving termination. Using this approach we can prove the following. res?-break-loop \n: LEMMA norm??(break-loop(c(p))(x, i)) AND res?(break-loop(c(p))(x, i)) = max(i, 20)  More details of \nreasoning about such while loops with ab-normalities will appear in [16]. 4.5 An invariance result So \nfar we have only seen examples of user statements about individual methods in a Java class. The next \ntwo exam-ples will consider a class as a whole, first in showing that a certain predicate is an invariant \nof a class, and second in showing that a class can be a model (or implementation) of a specification. \nAs mentioned briefly in the introduction, the LOOP tool not only translates Java classes into PVS, but \nalso generates for each class appropriate notions of invariant and bisimula- tion. This involves some \nbasic constructions from the theory of coalgebras (see [18]), which are ultimately based on ideas in \ncategorical logic (see [14]). Here we concentrate on invari- ants. These are predicates on the state \nspace, which, once they are true for a state x, will remain true no matter which public methods (or assignments \nfor public variables) are applied to x. The definition of invariance is different for ev-ery class, because \nit depends, for example, on the method types. Consider for example the following Java class, describing \na simple counter modulo max. class Counter { private int max; private int val; int maximum0 C return \nmax; 1 int value0 C return val; ) void next0 I if ( val < max ) I val = val + 1; 1 else t val = 0; ) \n1 void clear0 ( val = 0; ) Counter(int n) t max = n; ) 1 An invariant for this class is a predicate \nwhich is closed under application of maximum, value, next and clear-but not under assignments for the \nprivate variables max and val. Intuitively it is clear that the following predicate on the global memory \nOM? is an invariant. In Java there are many visibility modifiers, see [lo, Section 6.61 many of which \nare related to Java s package system, but the LOOP tool only has public and private. The LOOP translation \nsends private in Java to private, and everything else to public. Within the LOOP tool, these visibility \nmodifiers are (currently) only rele-vant for the notions of invariant and bisimulation. BEGIN CCSLcounter \n: CLASSSPEC METHOD max : Self -> int; val : Self -> int; next : Self -> Self; clear : Self -> Self; \nASSERTION max-next : PVS max(next(x)) = max(x) ENDPVS max-clear : PVS max(clear(x)) = max(x) ENDPVS val-next \n: PVS val(next(x)) = IF val(x) < max(x) THEN val(x) + 1 ELSE 0 ENDIF ENDPVS val-clear : PVS val(clear(x)) \n= 0 ENDPVS CONSTRUCTOR new : int -> Self; CREATION max-new PVS FORALL(n : int) : max(nev(n)) = n ENDPVS \nval-neu PVS FORALi(n : int.) : val(new(n)) = 0 ENDPVS END CCSLcounter Figure 3: A counter class specification \nin CCSL val-below-max(d, p) : COM? -> boo11 = LAMBDA(x : OM?) : 0 <= max(d(p))(x) AND 0 <= val(d(p)) \n(x) AND val(d(p))(x) <= max(d(p))(x) Proving this formally amounts to proving the next lemma, val-below-max-inv \n: LEMMA invariant?(d(p))(val_below_max(d, p)) in which invariant? is a predicate which is generated \nby the LOOP tool. It is not hard to prove this result, since most of the work is done via automatic rewriting. \n4.6 A Java implementation satisfying a CCSL class specification The introduction of this paper describes \nhow the LOOP tool accepts and translates both class specifications (in a language called CCSL, see [13]) \nand class implementations (in Java) as input. These translations can be combined, so that one can check \nin PVS whether a Java class implements a CCSL specification. We briefly illustrate this combination by \n(re)considering the Java counter class from the previous subsection. A specification of such a counter \n(modulo max) is presented in Figure 3. It is written in CCSL [13], and this language is hopefully self-explanatory. \nWe concentrate on the (validity of the) assertions . The LOOP tool translates the CCSL counter specification \ninto In principle, the creation conditions for constructors are handled similarly. a series of PVS theories. \nIn one of these theories, the as-sertions in Figure 3 are combined into a single predicate CCSLcounterAssert? \non a CCSLcounter coalgebra c : [Self -> CCSLcount.erIFace[Selfll which combines the methods of the CCSL \ncounter class in a single function. In order to show that the Java imple-mentation forms a model of this \nCCSL specification we first have to transform a coalgebra describing the Java class into a coalgebra \nfor this CCSL class, and then show that the as-sertions of the CCSL class are satisfied. In PVS these \nsteps are as follows. p : VAR nat d : VAR Cp : nat -> (CounterAssert?(p  counter(d, p) : [OM? -> CCSLcounterIFaceEOM?]] \n= LAMBDA(x : OM?) : (X max := res?(max(d(p))(x)), val := res?(val(d(p))(x)), next := ns?(next(d(p))(x)), \nclear := ns?(clear(d(p))(x)) #I CCSLcounter-JavaImplementation : LEMMA CCSLcounterAssert?(count.er(d. \np)) The latter lemma establishes the desired implementation re-sult. It is proved automatically by rewriting \n.  4.7 Component classes and casting Classes can form components of other classes: if MyClass is already \ndefined, then one can declare a field MyClass mc in some other class (or even in MyClass itself). Once \nmc is properly initialised, methods from MyClass can be applied to mc. But also, mc can be cast to superclasses \nof MyClass, see [5, Subsection 5.13.21 or [lo, Section 5.51. This creates substantial difficulties for \nthe translation to PVS, which we can currently only handle by hand . That is, we know how to translate \nsuch casting, but LOOP does not13. Casting in Java introduces a difference between fields and methods \n(see [5, Section 3.41): suppose B is a subclass of A, and both A and B have a field f and a method m \n(of the same type). Thus f from A is hidden in B and m from A is overridden in B. Let b be of type B, \nand consider its cast a = (A)b to A. Then a.f is f in A, whereas a.m is m in B. This difference is highly \nrelevant for reasoning about casting14. The definition of the counter function also generates several \nobli-gations ( tee s ) to prove that the Java methods terminate normally, so that their result res? or \nresulting normal state ns? can be accessed. Also these obligations are handled by automatic rewriting. \n13The reason is that in order to perform the translation of a cast from class A to class B we need to \nknow both A and 8. This information can only be obtained by letting LOOP typecheck Java programs, be-cause \ncasting is often done implicitly. Java typechecking is currently being added to the LOOP tool. 140nr \ntranslation by hand handles this difference by letting a look at b with an adapted coalgebra. This can \nalso be expressed in terms of two references to a, see [5, page 691: one reference as its actual class \nand the other as its superclass . 5 Conclusions and further work We have sketched the essential ingredients \nof a (partial) translation of Java classes into the higher order logic of PVS, as performed by the LOOP \ntool. Also we have shown how this allows us to prove some elementary properties about Java classes in \nPVS. This may be seen as applied semantics of programming languages. Space restrictions prevent us from \ndescribing all details here, but more will be presented in future work. It may be clear that this project \nis far from finished. We will continue to extend the translation to aspects of Java which arc currently \nnot covered. Being able to reason about threads is a long-term goal, which will first require a funda- \nmental study of the semantics of threads in Java (see also [8]) within the coalgebraic approach underlying \nthe LOOP tool. Another future extension is to define an appropriate An-notated Java language consisting \nof standard Java with correctness assertions added as comments. These should be translated into appropriate \nverification conditions. To con-clude, we would like to emphasise that this is very much a research project \nand that major applications are not fore-seen in the near future. References 1. M. Abadi and I,. Cardelli. \nA Theory of Objects. Monographs in Comp. Sci. Springer, 1996. 2. IM. Abadi and K.R.M. Leino. A logic \nof object-oriented pro-grams. In M. 13idoit and M. Dauchet, editors, TAPSOFT 97: Theory und Practice \nof Software Development, number 1214 in Lect. Notes Comp. Sci., pages 682-696. Springer, Berlin, 1997. \n 3. K.R. Apt. Ten years of Hoare s logic: A survey-part I. ACM 7 rans. on Progr. Lang. and Systems, 3(4):431-483, \n1981. 4. K.R. Apt and E.-R. Olderog. Verificatzon of Sequential and Concurrent Programs. Springer, 1991. \n 5. K. Arnold and .J. Gosling. The Java Programming Language. Addison-Wesley, Znd edition, 1997. 6. \n.J.W. de Bakker. Mathematical Theory of Program Correct- ness. Prentice Hall, 1980.  7. V.A. Carreno \nand P.S. Miner. Specification of the IEEE-854 floating-point standard in HOL and PVS. In E.Th. Schubert, \nPh.J. Windley, and .J. Alves-Foss, edi-tors, IIigher Order Logic Theorem Proving and Its Appli-cations, \n1995. Cat.eg0r.v B Proceedings, available at URL http://lal.cs.byu.~du/lal/hol95/Bp~ocs/indexB.html. \n 8. P. Cenciarelli, A. Knapp, B. Reus, and M. Wirsing. From se-quential to multi-t,hre&#38;ded <Java: \nAn event-based operational semantics. In M. .Johnson, editor, Algebraic Methodology and Soflware Technology, \nnumber 1349 in Lect. Notes Comp. Sci., pages 75-90. Springer, Berlin, 1997. 9. M.J.C. Gordon. Mechanizing \nprogramming logics in higher order logic. In G. Birtwistle and P.A. Subrahmanyam, ed-itors, Current Trends \nrn Hardware Verification and Auto-mated Theorem Proving, Springer, 1989.  10. J. Gosling, B. Jay, and \nG. Steele. The Java Language Speci-fication. Addison-Wesley, 1996. 11. D. Grips. The Science of Programming. \nSpringer, 1981. 12. C.4. Gunter. Semantics of Programming Languages. Struc-tures an,d Techniques. The \nMIT Press, Cambridge, MA, 1992.  13. U. Hensel, M. Huisman, B. Jacobs, and H. Tews. Reasoning about \nclasses in object-oriented languages: Logical models and tools. In Ch. Hankin, editor, European Symposium \non Programming, number 1381 in Lect. Notes Comp. Sci., pages 105.-121. Springer, Berlin, 1998. 14. C. \nHermida and B. Jacobs. Structural induction and coin-duction in a fibrational setting. Inf. &#38; Comp., \nto appear, 1998. 15. C.A.R. Hoare. An axiomatic basis for computer program- ming. Common. ACM, 12:576-580, \n583, 1969.  16. M. Huisman and B. Jacobs. Hoare logic with abrupt termi- nation. In preparation, 1998. \n 17. B. .Jacobs. Objects and classes, co-algebraically. In B. Freitag, C.B. Jones, C. Lengauer, and \nH.-.J. Schek, editors, Object-Orientation with Parallelism and Persistence, pages 83-103. Kluwer Acad. \nPubl., 1996.  18. B. Jacobs. Invariants, bisimulations and the correctness of coalgebraic refinements. \nIn M. Johnson, editor, Algebraic Methodology and Software Technology, number 1349 in Lect. Notes Comp. \nSci., pages 276-291. Springer, Berlin, 1997. 19. B. Jacobs and J. Rutten. A tutorial on (co)algebras \nand (co)induction. EATCS Bulletin, 62:222%259, 1997. 20. X. Leroy. The Objective Cam1 system, Documentation \nand user s guide; Release 1.07, 1997. Available at URL http://pauillac.inria.fr/ocaml/htmlman. 21. J. \nLoeckx and K. Sieber. Th.e Foundations of Program Veri-fication. Wiley, 1987. 22. S. Owre, J.M. Rushby, \nN. Shankar, and F. van Henke. Formal verification for fault-tolerant architectures: Prolegomena to the \ndesign of PVS. IEEE Tkans. on Softw. Eng., 21(2):107-125, 1995. 23. H. Reichel. An approach to object \nsemantics based on ter-minal co-algebras. Math. Struct. in Comp. Sci., 5:129-152, 1995. 24. D. RCmy \nand J. Vouillon. Objective ML: An effective object-oriented extension of ML. Theory &#38; Practice of \nObJect Sys- tems, 1998, to appear. 25. 3. Rutten. Universal coalgebra: a theory of systems. Theor. Comp. \nSea., 1998, to appear. 26. R.D. Tennent. Semantics of Programming Languages. Pren-tice Hall, 1991. \n \n\t\t\t", "proc_id": "286936", "abstract": "We present the first results of a project called LOOP, on formal methods for the object-oriented language Java. It aims at verification of program properties, with support of modern tools. We use our own front-end tool (which is still partly under construction) for translating Java classes into higher order logic, and a back-end theorem prover (namely PVS, developed at SRI) for reasoning. In several examples we demonstrate how non-trivial properties of Java programs and classes can be proven following this two-step approach.", "authors": [{"name": "Bart Jacobs", "author_profile_id": "81100068878", "affiliation": "Dep. Comp. Sci., Univ. Nijmegen, P.O. Box 9010, 6500 GL Nijmegen, The Netherlands", "person_id": "PP14034379", "email_address": "", "orcid_id": ""}, {"name": "Joachim van den Berg", "author_profile_id": "81100129049", "affiliation": "Dep. Comp. Sci., Univ. Nijmegen, P.O. Box 9010, 6500 GL Nijmegen, The Netherlands", "person_id": "PP31099796", "email_address": "", "orcid_id": ""}, {"name": "Marieke Huisman", "author_profile_id": "81100035521", "affiliation": "Dep. Comp. Sci., Univ. Nijmegen, P.O. Box 9010, 6500 GL Nijmegen, The Netherlands", "person_id": "PP40035644", "email_address": "", "orcid_id": ""}, {"name": "Martijn van Berkum", "author_profile_id": "81100594609", "affiliation": "Dep. Comp. Sci., Univ. Nijmegen, P.O. Box 9010, 6500 GL Nijmegen, The Netherlands", "person_id": "P191936", "email_address": "", "orcid_id": ""}, {"name": "U. Hensel", "author_profile_id": "81100314545", "affiliation": "Inst. Theor. Informatik, TU Dresden, D-01062 Dresden, Germany", "person_id": "P286033", "email_address": "", "orcid_id": ""}, {"name": "H. Tews", "author_profile_id": "81332531730", "affiliation": "Inst. Theor. Informatik, TU Dresden, D-01062 Dresden, Germany", "person_id": "P105179", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/286936.286973", "year": "1998", "article_id": "286973", "conference": "OOPSLA", "title": "Reasoning about Java classes: preliminary report", "url": "http://dl.acm.org/citation.cfm?id=286973"}