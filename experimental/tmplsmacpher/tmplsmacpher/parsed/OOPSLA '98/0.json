{"article_publication_date": "10-01-1998", "fulltext": "\n An Evaluation of Automatic Object Inline Allocation Techniques Julian Dolby Andrew A. Chien Department \nof Computer Science Department of Computer Science and Engineering University of Illinois at IJrbana \nUniversity of California, San Diego dolby@cs.uiuc.edu achien@cs.ucsd.edu Abstract Object-oriented languages \nsuch as Java and Smalltalk provide a uniform object reference model, allowing ob-jects to be conveniently \nshared. If implemented directly, these uniform reference models can suffer in efficiency due to additional \nmemory dereferences and memory management operations. Automatic inline allocation of child objects within \nparent objects can reduce overheads of heap-allocated pointer-referenced objects. We present three compiler \nanalyses to identify inlin-able fields by tracking accesses to heap objects. These analyses span a range \nfrom local data flow to adaptive whole-program, flow-sensitive inter-procedural analy-sis. We measure \ntheir cost and effectiveness on a. suite of moderate-sized C++ programs (up to 30,000 lines including \nlibraries). We show that aggressive inter-procedural analysis is required to enable object inlin-ing, \nandour adaptive inter-procedural analysis [23] com- putes precise information efficiently. Object inlining \neliminates typically 40% of object accesses and alloca-tions (improving performance up to 50%). Furthermore, \n1 introduction Object-oriented languages provide abstraction, allowing programmers to isolate conceptual \nportions of a given program behind opaque interfaces, with attendant ben-efits in code modularity and \nreusability. Languages such as Java [32], Lisp [30], Pool [2] and Sather [31] provide this abstraction \nwith opaque objects for which clients have a reference and an interface specification. This isolates \nthe clients from any changes in a given object s implementation. Even fine-grained portions of a pro-gram, \nsuch as individual points for a graphics library, can be conveniently expressed in this manner. But these \nsame interfaces create overhead if imple- mented in the manner of a traditional Lisp or Java run-time \nsystem, using dynamic dispatch to call methods and heap-allocated objects accessed via pointers. Ad-ditionally, \nan object-oriented programming style gcner-ally encourages the use of small methods and objects Permwlon \nto make dtgltal or hard copes of all or pan of this work for personal or classroom use is granted without \ntee provfded that copes are not made or distributed for protut or commercial advan-tage and that copses \nbear this not!ce and the full citation on the tlrst page To copy otherwlse, to republish, to post on \nservers or to redlstrlbuw to IIsts. requres pnor specific perm#ss~on and/or a tee. OOPSLA 98 10198 Vancouver, \nB.C. 0 1998 ACM l-581 13.005.8/98/0010...$5.00 [5]. The combination of small methods and dynamic dispatch \nis a well-studied problem: dynamic dispatches are optimized statically by type inference [l, 6, 21, 241, \ndynamically by inline caching [16] or with hybrid ap-proaches like type feedback [17]. Static or hybrid \ntype analysis has been combined with method specialization [S, 251 to allow inlining, removing the small \nfunctions common in object-oriented code. Pervasive use of heap-allocated objects introduces overhead \nfor memory management and repeated pointer dereference. This can both increase memory traffic and hurt \nlocal code efficiency by reducing opportunities for register allocation which inhibits many scalar optimiza-tions. \nPointer dereference (called pointer chasing) over-head not only incurs additional memory traffic, but \ngiven performance sensitivity to data locality, typically reduces cache efficiency. This topic has been \nstudied by many researchers, using both runtime techniques (e.g. fine grained multi threading [22]) and \ncompile time ap-proaches (e.g. representations that explicate dependen-cies thru pointers [19]). But \nit remains a challenging open problem. Object inlining coalesces objects by in-line allocating child \nobjects within their container ob-jects. This attacks pointer chasing by eliding the point- ers and converts \nan unpredictable memory reference into one with spatial locality. But object inlining poses challenges \nof its own: it requires an analysis capable of distinguishing individual container and containee objects, \nboth to ensure that merging them does not change sharing relationships, and to generate appropriate code \nfor accessing state of merged objects where that is needed. A whole-program analysis that does this was \npresented in [9], and showed speedups of up to three-fold on a set of object-intensive benchmarks. However, \nthat study did not assess much analysis power is really required, and how many fields can be inlined \non a wider range of benchmarks. In this paper, we address those questions. So to assess the feasibility \nand benefit of object in-lining, we study its effectiveness using several analysis frameworks of varying \npower and cost, and a bench-mark suite including the NIHCL [14] and OATH class libraries, which together \nprovide multiple implementa-tions of a range of common data structures. These codes range from a few \nhundred lines to over 10,000 lines of C++ code (plus 20,000 lines of library). We imple-mented three \ndifferent program analyses. They all use data-flow properties to track how object fields are used and \ndefined; the analysis frameworks employed are lo-cal data flow, traditional control flow analysis [27] \nand adaptive flow analysis [24]. The control flow analysis and adaptive analysis variants are based upon \nthe tech- niques in our prior work [9]; however, our study revealed deficiencies in those techniques \nso we generalized them substantially for this study. Our results indicate object inlining optimizations \neliminate typically 40% and as much as 90% of the ob- ject accesses and allocations, and can deliver \nsignificant performance benefits (averaging 10% faster but rang-ing from no improvement to 50%). However, \nreaping these benefits requires powerful inter-procedural analy-sis that must focus effort to avoid excessive \ncost. Both the simple local technique nor the traditional flow anal- ysis proved insufficent. Fortunately, \nthe adaptive inter-procedural analysis we employed [24] computes precise information efficiently. We \nbegin by discussing our approach to inline alloca-tion in Section 2 and presenting an example program \nin Section 3. Next, Section 4 describes the Concert System [7] in which work was done, and Section 5 \ndetails our three program analyses. These analyses are evaluated on a suite of C++ programs in Section \n6. This suite is summarized in Section 6.2 and performance metrics and results are given in Sections \n6.3 and 6.4. Finally, we contrast related work in Section 7 and conclude with Section 8. 2 Automatic \nObject Mining The idea behind automatic object-inlining is provide a more efficient implementation without \naltering the model seen by the programmer. Thus, the source pro-gram might describe a logical structure \n(which we call the literal stmcture) of several objects, connected by references, and the resulting implementation \nafter ob-ject inlining might be these objects fused into a single object. The literal and optimized data \nstructure imple-mentations for an example pair of classes is illustrated by Figure 1. The literal implementation \nrequires multiple mem-ory operations to allocate and reclaim the storage for the objects, and pointer \ndereferences to reach the Point objects. In contrast, the optimized implementation can be allocated and \nreclaimed in a single operation and the fields directly accessed with a single load with offset instruction. \n2.1 Analysis and Transformation Requirements For inlining to be semantics preserving , program analy-sis \nmust provide two pieces of information for each inlin- able field. First, the analysis must precisely \nidentify all accesses to the child object, and, second, to ensure that sharing relationships are correctly \npreserved, the analy- sis must ensure that the child is not stored into multiple parents via the given \nfield. The need for precision is sig- nificant and difficult to achieve in many cases. Thus, the goal \nof the analysis is to identify the object fields (and The transformation must be semantics preserving \nin order for the program to continue to correctly implement the source pKlgG3Itl. contours ) for which \nthe object inlining transformation is semantics preserving. More successful analyses will find more field, \ncontour pairs which can be inlined. If the analysis produces the requisite information, then the object \ninlining transformation consists of the following steps3: 1. Create a new definition for the parent object \nwhich includes the inlined child object (fields and meth- ods), including constructor/destructor methods \n 2. Modify the allocation points to use the new object definitions 3. Rewrite all accesses to the child \nobject s state as accesses to the inlined child object.  2.2 Explicit Mine Allocation Some programming \nlanguages [lo, 331, notably C++, al-low programmers to manually specify inline object allo-cation to \nimprove performance. As with the automatic approaches, the objective is to reduce storage manage-ment \noverhead as well as the number of pointer deref-erences required to execute a program. An example of \nexplicit inline allocation is shown in Figure 2. class Rectangle C // Points are inlined Point upper-left; \nPoint lower-right; 1; class Point C int x-~0.5; int y-pos; 1; C++ Source ( >++ Implementation Figure \n2: Explicit Inline Allocation in C++ In our explicitly inlined example, there are still mul-tiple objects. \nReferences to child objects allocated in-side parents are allowed. There are two basic differences between \nautomatic and explicit object inlining: whether inline allocation is visible to the programmer--that \nis, whether it is part of the programming model-and whether the parent and child objects are fused. As \ncan be seen in Figure 2, ex- plicit inline allocation requires the programmer to ex-plicitly indicate \nwhich of the child objects are to be inlined. This requires explicit effort, and a change to the code \nstructure by the programmer. Further, it is not a semantics-preserving transformation in general -as \nthe the inlining operation changes the sharing se-mantics. The inlined child objects are by-value whereas \noutlined objects are by reference. Thus the advantages The separately customizable contexts of use of \nthe objects. 30nce a given field has been found inlinable, a policy decision must determine whether \nor not it actually is inlined. Since we are exploring the feasibility of object inlining, we currently \ninline whenever possible. class Rectangle C // (* declares references Point *upper-left; Point *lower-right; \n1; class Point < int x-pos; int y-pos; 1; C++ Source Figure 1: Literal and of automatic object inlining \nis that it can provide the performance benefits without requiring programmer ef-fort and that automation \nensures the correctness of the inlining transformation (and undoes it should the ad- dition of code invalidate \nthe transformation). Fusing parent and child objects into a single layout has two advantages. First, \nit allows optimizing per-object operations, such as concurrency control in a con- current object-oriented \nmodel (this was one of our orig-inal motivations). Second, it enables code generation for targets, such \nas the Java Virtual Machine and the Concert runtime system, that do not permit interior pointers.4 These \nchallenges will be illustrated by our running example, introduced in Section 3. 3 An Example To provide \ncontinuity, we employ a single example throughout for exposition of our analyses. The code example consists \nof the two class definitions from Fig-ure 1, and some methods (Figure 3). A Rectangle is defined by two \nPoints, each of which in turn consists of two integer coordinate values in 2-dimensional Carte-sian space. \nThe example methods and main0 program create several Points and a Rectangle, checking the validity of \nthe rectangle (lower right corner is really right of and below the other corner). Finally, the program \nprints the x coordinates of two points. The example illustrates the analysis requirements. To safely \ninline the Points (p, q) in the Rectangle (r), all uses of p and q must be identified. This includes \nall of the uses within the Rectangle class s methods and the main program. In addition, the analysis \nmust determine the sharing properties of the Points relative to its use in the Rectangle. This is required \nbecause inlined objects have by-value semantics, that is, they cannot be shared by multiple parents thru \ninlined fields. Note that the Point class cannot be inlined indis-criminately, and thus the analysis \nmust identify the sets of creations of Points which are to be optimized. Cre-ations of p and q must be \ndeleted, and their construc-tors redirected to the corresponding inlined fields of r. The two constructors \nfor the inlined versions of p and q must be specialized differently as one works upon the 4Additionally, \nsome issues such as garbage collection are more difficult -but not impossible -with interior pointers. \nLiteral Inlined (Optimized) Optimized Implementations Point::belowRight?fp) 1 if (p.x-pos > this->x-pas) \nreturn (p. y-pos < this->y-pm) ; else return false ; Point: :Pointfx. y) C this->x-pos = x; this->y-pos \n= y; 3 Rectangle: :Rectangleful, lr) c if (lr . belowRight? (ul) > 1 this->upper-left = ul; this->lower-right \n= lr; 3 else error ( invalid rectangle ) ; 3 main I p = new Point (3, 8) ; q = new Point (8. 6) ; r \n= new Rectanglecp, q); s = new Point(8, 7); tout << r.upper-left.x-pos << s.x-Pas; Figure 3: Example \nMethods lower-left and on the upperlight point. Finally, the creation of s must be left alone. Automatic \ninlining analysis must determine the sharing properties of the object to be inlined to deter-mine unambiguously \nwhich child object is assigned into which container. Since p, q and r are created in the same block of \ncode, the relationship is apparent: the in- stances p and q are assigned into r. However, in general \nthese creations could be separated by function calls and even assignments thru global state. Accesses \nto the objects must also be transformed. For example, the tout << statement in main gets two x-pos values, \none from a Point inlined into upper-left and one from a free-standing Point. These two x-pos operations \nmust have different implementations, as one must access the inlined field and the other a free-standing \none. 4 Background: The Concert Compiler For regions, we query their parent conditional, i.e. The implementation \nof our object inlining analyses was done in the Illinois Concert System [7], and so a brief discussion \nof the relevant aspects of the system is given here to provide context for subsequent description of \nthe optimization. Most relevant is the program repre-sentation and the analysis and cloning frameworks, \nall discussed below. 4.1 Program Representation The primary program representation used by the Con-cert \nCompiler is the Program Dependence Graph (PDG [12]) in Static Single Assignment (%A) form, of which a \nbrief sketch is provided here mostly to introduce ter-minology we use while describing our analyses. \nFig-ure 4 shows an example PDG fragment from the Point : : belowRight? method from Figure 3. The PDG \nrepresents methods as a tree of control dependence regions and conditional (including loop) nodes. Each \nregion is the child of the conditional node that governs whether or not it executes, so loop nodes have \none child region for the body and if nodes have one child each for true and false branches. The phi nodes \nof SSA form are attached to these conditional nodes. ev-ery other node -our graph has function calls, \nprimitive operations and field accesses -is contained in the re-gion of the conditional governing its \nexecution. Within a single region, ordering between nodes is represented explicitly by a set of data \nconstraints. ----ad,,ldr,mdem c_. Figure 4: Program Dependence Graph Note how dominance and post-dominance \nis implicit in this representation: if p. y-pos < y-pos executes then p.x-pos > x-pos must already have \ndone so because it is in a parent region and has a data dependence. We use this property for our inlining \nanalyses. In our sub-sequent discussion, we use aspects of this representation which we formalize below. \nFor single nodes, we use their region and kind properties and, for pairs of nodes within a single region, \nwe use the ordering constraint >: region(n) t the region containing n nl >- n2 t ni must execute after \nnz does if for conditional nodes while for loop nodes phi for all phi nodes kind(n) t call for function \ncalls access for all field accesses creation for new statements primitive for all other primitives the \nconditional that controls whether or not the nodes within the region execute: parent(r) t the conditional \nnode governing r For individual SSA values, we require knowing their creation, which is the node responsible \nfor generating that value, and their reaching definitions. We assume that unnecessary moves are eliminated, \nso the kind of creation(v) be one of call, phi, access, primitive or cre-ation. creation(n) t the node \nwhich creates n reaching(n) t the set of nodes using n  4.2 The Analysis Framework The Concert compiler \nhas a global analysis framework -adaptive analysis [24, 231 -that performs context sensitive flow analysis. \nThe flow analysis ultimately builds a program-wide data-flow graph connecting the values within and across \nthe individual method program graphs, with those values being specialized as needed by context sensitivity. \nContext sensitivity adapts to pro- gram structure, focusing analysis effort on interesting portions of \nthe program. The unit of context sensitivity is the contour [29], each of which represents an execution \nenvironment. For a given method, method contours can discriminate arbi- trary data-flow properties of \nits caller and creator: caller -the calling statement and contour. This cov-ers arguments, allowing discrimination \nbased upon data-flow properties of caller and its arguments. creator -the object contour representing \nself. This permits a limited form of alias analysis based upon properties of the target object. An object \ncontour represents a set of method con-tours of statements that create a given object. That is, each \nnew statement is analyzed with some number of method contours, and the object contours correspond-ing \nto that new statement each group some set of those method contours. Thus, an object contour represents \na new statement called in some context. In traditional control flow analysis (nCFA), contours are statically \ncreated to analyze a method separately for different callers from one or more level. But in adaptive \nanalysis, contours are created and split on demand: they are created when the analysis needs to distinguish \nsome property. An initial coarse data flow graph is built and then scanned for imprecisions; these imprecisions \nare used to direct selective adding of contours -splitting existing ones -to improve information quality. \nThis process iterates until no more contours improve infor-mation. The original use of this framework \nwas type infer-ence, which creates contours to distinguish type infor-mation. Method contours are created \nfor different sets of argument types; for polymorphic fields, different ob-ject contours are built for \nthe containing object to dif-ferentiate the types in the field. The analysis framework includes a mechanism \nfor distinguishing object contours with respect to uses of objects. We also use this frame- work to implement \nthe object-inlining analysis. Figure 5 illustrates analysis on the program fragment from Figures 1 and \n3. For simplicity, we ignore the last two statements in main. Figure 5(a) illustrates the initial coarse \ngraph. In the example, there is one contour per method and per class: the contours in the figures are \nlabeled with the function and (m,o), which records the method contour and object contour numbers. In \nFigure 5(a), the object contour 0 represents Points and 1 represents Rectangles. The main function has \n-as its object contour because it is not a method on any object. Object inlining analysis needs to distinguish \nob-jects assigned into different fields, and currently ob-jects from contour 0 are assigned into but \nupper-left and lowerlight. So the demand driven specialization mechanism tracks the values assigned to \nthese slots back to the creations of p and q; it then splits contour 0 into two contours -0 and 2 -to \ndistinguish these two cre-ations. This also causes all method contours to be split so that this always \nhas one contour. The resultant re-fined graph is shown in Figure 5(b). Subsequent discussion of our analysis \ndistinguishes specialized values by subscripting them with a given contour, so that v, is the value v \nspecialized to con-tour c. Furthermore, we use the following aspects of our representation: ulq * u2cz \n: data may flow from vicl to vzc2 Vlc, 4 v2cz : data may flow from vscZ to r/icl Creators(v,) t object \ncontours of vc. self(c) t object contour of this, Recall the object contours represent specializations \nof classes, so Creators(v,) is essentially the type of vc. 5 Analysis We explore three different analyses \nfor automatic object inlining, each of increasing analysis power. Recall that the goal of object inlining \nanalysis is to identify the ob- ject fields (and contours (See Section 4.2)) for which the object inlining \ntransformation is semantics preserving. More successful analyses will find more field, contour pairs \nwhich can be inlined. For a field to be safely inlin- able, the analysis must be able to precisely enumerate \nuses of the child object, and the sharing relationship be-tween the parent and child objects. These properties \nare are formalized in Section 5.1. The three different analy-ses for inlining, each of increasing power, \nare described in subsequent sections. 5.1 Criteria for lnlinable Fields To prove a field is safely inlinable, \nan object inlining analysis must compute the following information. All of the results must be precise. \nLet f denote a single field in a contour for a single class. Rf: the set of references to a container \nobject of field f Ef: the set of references to a containee object of field f Upf : Ef 6 Rf: a map from \ncontainees to their cor-responding containers Computing these properties requires precise resolu-tion \nof control flow and data flow in large programs. These definitions are independent of the program rep-resentation \nused, so the exact meaning of reference and class depend the analysis framework being used. For example, \na reference could be a value in an SSA graph or something more precise for a context-sensitive data-flow \ngraph. Further, a class could be a declared class, an object contour (see Section 4.2), or just the results \nof a specific set of new statements. Figure 6 shows this information for the lower-right field of the \nRectangle object in our example. The table labels values with the contours shown in Fig-ure 5(b). All \nvalues that contain objects assigned to or read from lower-left in Elower-right and all val-ues that \nhold Rectangles from the creation of r are in Rl am-right. In Figure 6, the results for these sets are \nprecise; the variables in Elower-,.ight are only used as the lower-left field of a Rectangle. If this \nwere not the case -i.e. if some member of Elower-r+t only might be from a Rectangle -there would be no \nway to generate a single sequence of code for the field reference. Elower-right + (this4, qo,lrz, this31 \nR lower-right t {ro, thisa} ( this4 -+ ro I -+ 7-o UPI ower-right + -+ this2 -+ this2 Figure 6: Example \nR, E and Up For a field to be inlinable, not only must Rf and Ef be precise, but Upf must be a realizable \nfunction. This is because object inlining requires Upf to direct a program transformation -substituting \ncontainer values for containee values -and realizability ensures that con-tainer values need not be used \nin places where they do not exist (e.g. before they are created). For example, in Figure 6, Ups maps \nthis4 to rs, but the two vari-ables are in different scopes, so it must be possible to pass re into the \nconstructor (or alternately inline the constructor) in order to replace this4 with it.  5.2 Analysis \nFrameworks Analyses to derive inlinable fields can use any data-flow analysis framework, but the choice \ncritically affects cost (space and time) and effectiveness (inlinable fields iden-tified). We explore \nthree different analysis frameworks, ranging from local data-flow analysis to adaptive flow-sensitive \nanalysis [24]. These frameworks allow us to explore the cost-effectiveness space of inlining analyses. \nLocal Data Flow Conventional intra-procedural analysis which is fast, but limits the identification of \ninlinable fields to those for which both Ef and Rf confined to a single procedure. This limitation could \nbe mitigated by good procedure inlining heuristics. CO , <c << s.xgos; (a) Pass One (b) Pass Two Figure \n5: Adapt ;ive Flow Analysis nCFA A conventional form of inter-procedural analysis with flow-sensitivity \nbased on n of levels of calling context [28]. Because of compute cost exponential in n, only small values \nof n are practical. The con-text sensitivity of nCFA allows inlining of objects for which Ef and Rf span \nprocedure boundaries. Adaptive Analysis (described in Section 4.2) An in-herently whole-program analysis \nwith demand-driven -and arbitrarily deep -context sensitivity. It is capable of distinguishing Ef and \nRf thru arbi-trarily many levels of procedure calls. A significant advantage of adaptive analysis over \nnCFA is that data flow is tracked even thru assignments to other object fields via object contours. \n5.3 Local Data Flow The local data flow analysis uses a single mechanism, tagging, to compute Ef, Rf \nand Ups simultaneously for each field in a given method. Local data flow works on individual methods, \nfor which the Concert Compiler uses SSA and the PDG (see Section 4.1) and values are tagged with information \nabout object fields to which they are assigned or from which they are read. We first define precisely \nwhat a tag is, then discuss how they are propagated by local data flow, and finally show how to compute \nEf, Rf and UpF from them. 5.3.1 Tags A tag is associated with a given program value; it is a sequence \n((object @ field), , . . . , (object @ field),) in-dicating the object fields to which that value is \nassigned or from which it is read. The objects are the SSA values representing the value from which the \nfield was accessed and fields are the fields accessed. For instance, a = b.f would yield a tag of ((b \n8 f)) for a. Manipulation of tags is defined as follows: NoTag a value not from any field Object((o@ \nf)) q o FieZd((0 @ f)) a f fy$;1 @J f), 7.. . 7 (0 @ f,,), * M~~eTagl((o~f),((o~f),,... ,(o@ff),))= ((0 \n@ f) 1 (0 8 f), > > (0 @ f,,)  5.3.2 Tag propagation The tags defined above are propagated by a standard \ndata-flow algorithm thru the program graph of an in-dividual method in order to compute Ef, Rj and Upf \nfor all fields f of all objects created in that method. In defining our data-flow equations, we will \nuse the =+ and += relations to indicate forward and backward data-flow relationships between values, \nand + to signify transitive closure. We use two sets of tags for each value in the program graph, ForwardTags \nand BackwardTags, to record fields from which the value is read and to which it is assigned respectively. \nTag propagation conceptually starts at the creation sites (i.e. new statements) of all uncontained objects, \nthat is, objects that are not assigned into any field of any object. The set of uncontained objects, \nwhich we call Top, is defined as follows: Top t kind(creation(v)) = creationA (v +;,, ( ::dL$j$~;;) } \n Propagation proceeds from the uncontained objects according to data-flow rules that tag all definitions \nand uses of object fields with tags corresponding to the ap- propriate object and field values. The rule \nfor object creations is straightforward: for each creation site in Top, its result is given the forward \ntag NoTag: v = new Obj A v E Top ==+ ForwardTags c {NoTag} Local data flow must treat field access nodes \nspecially, as fields represent global state rather than SSA values; there are two rules for these field \naccesses - one for reads and one for writes -that propagate the appropriate tag based upon the field \naccessed and the container s tag: Tags(v) t ForwardTags U BackwardTags v = o .f ----LI ForwardTags c \n{MakeTag((o@ f) ,tl)ltl E Tags(o)} o.f = v * BackwardTags t {MakeTag((o @ f) , tl)ltl E Tags(o)}) Finally, \nthere are the rules for propagating tags across data-flow constraints: ForwardTags t ForwardTags U U \n{t It E ForwardTags( {iIi*u} BackwardTags t BackwardTags(v)U U {t It E BackwardTags( {ilie=v} 5.3.3 \nComputing Ef, Rf and Upf Once the tag propagation is done, we compute Ef, Rf and Upf for each field of \neach object created in the method. We will give the definitions in terms of an ar- bitrary field fof \nan object n where II is the result of an object creation (i.e. a new statement). Rf is the transi- tive \nclosure, forward and backward, across the data flow from u throughout the method, and Ef is all the val-ues \ntagged with a pair representing the field f and an object in Rf. Note that the tags have recorded the \ncon-tainer value from which the field was extracted, which allows us to find the corresponding container \nfor a given member of Ef by looking the the Object of its tag. Rf t {vi Iv@= u =x)+vi } There are no \ncriteria for the precision of Rf for it is defined rather than calculated; however, both Ef and Upf must \nbe checked for ambiguity. If a value in Ef has more than one tag, then that value could be from mul-tiple \ncontainers, making inlining invalid. Similarly, Upf must be a many-to-one mapping, so a given member \nof Ef must not be mapped to more than one member of Rf: IForwardTags(v)l > 1VEf : IBa&#38;wardTags(v)l \n> 1 UPf : --&#38;,q,q (e, 7-1) E Upf A (e, 7-2) E Upf  5.3.4 Realizability We mentioned in Section 5.1 \nthat the mapping Upf must be checked for realizability: we must ensure that the specified transformation \nis legal. Recall that the transformation is simply substituting container values for uses of containee \nvalues according to Upf Values with a ForwardTag are no problem, for the correspond- ing container must \nexist; for values with a Backward-Tag, we are pushing the corresponding container back-ward along data-flow \npaths to control conditions where it may not exist. Since we are using the PDG (see Sec- tion 4.1), the \ncontrol conditions can be verified simply: for each mapping (e, r) where e has a BackwardTag, check that \nthe creation of e is below the creation of r in the PDG and the node in r s region that controls e (or \nis e) is not constrained to happen before the node creating r. These constraints are formalized in Figure \n7  5.4 nCFA Analysis The nCFA analysis, just like the local one, uses tag-ging to compute Ef, Rf; then \nwe will use the resultant Ef, Rf and inter-procedural data-flow graph to con-struct Upf . Tagging is \nused to identify uses of different containee objects, relying upon the statically created contours to \nprovide needed context sensitivity. We first define precisely what a tag is, then discuss how they are \npropagated using nCFA analysis. Finally we detail how to compute Ef, Rf and Upf. This analysis-and the \nsimilar adaptive analysis dis-cussed next-is based upon techniques we devised pre-viously [9]. The tag \npropagation for forward tags is exactly the same, but our prior technique worked by copying fields of \nthe child object into the fused object, which we called definition specialization. That proved inadequate \nwhen evaluated on larger programs, so we replaced that mechanism with backward tags. 5.4.1 Tags A tag \nis a sequence (f ieldl , . . . , field,) indicating from or to which fields a given value is read or \nassigned. The fields are field names from the program s classes. Ma-nipulation of tags is defined as \nfollows:   NoTag =+ not from field. MakeTw(f,(fl,... ,fn)) * (f,fl,... ,fn) Head((fl,. . , fn)) -fl \n 5.4.2 Tag propagation The tags defined above are propagated by a standard data-flow algorithm thru the \ninter-procedural data-flow graph in order to compute Ef, Rf. In defining our data-flow equations, we \nwill use the + and -+ relations to indicate forward and backward data-flow relationships between values. \nTag propagation conceptually starts at the creation sites (i.e. new statements) of classes, that is, \nclasses values of which type are not assigned into any field of any object. The set of uncontained classes, \nwhich we call Top, is defined as follows: Top t {C 1~3C~AI1Clas~=~3~~~ields(C) c E Creators(F) } Tags \nare propagated thru the inter-procedural data-flow graph along forward and back data-flow paths, with \nspecial rules for the results of object creations and field accesses. The rule for object creations is \nstraightfor- ward: for each creation site in Top, its result is given RegionAbove(rl, rz) t r-1 = r-2V \n(parent(r2) A RegionAbove(rr, region(parent(rz))) Above(nl, nz) t RegionAbove(region(nl), region(n2)) \nAfter(m, nz) t nl > nz V After(nl,parent(region(nz))) V After(parent(region(nr)),nz) LocalDominates(n1, \nnz) + Above(nl, n2) A -After(nl, 7~2) Realizable(Upj) t V(e,r)Eupf LocaZDominates(creation(r), creation(e)) \n Figure 7: Realizability the forward tag NoTag: v = new Class A Class E Top * ForwardTags t { NoTag} \n U There are two rules for field accesses -one for reads CECreators(f)cECreationPoints(C) and one for \nwrites -that propagate the appropriate tag based upon the field accessed and the container s tag (in \nthe subsequent equations, recall that n, is w specialized Computing Upf requires mapping from a given \ncon-to contour c): tainee value from Ef to the appropriate container value in Rj, which involves finding \nthe value to or from which v = o .f s ForwardTags t the containee goes or comes. We tackle finding the \nvalue differently for forward and backward tagged values. For-ward tagged values flowed from a container \n(hence the MakeTag(f, t) tag) and that is the one to use in place of it. At the c~creators(o,) points \nwhere the containee is extracted (i.e. at field reads), we have an association between the container \nand containee values, and so we can use the container o . f = v q BackwardTags t value instead. This \ngives us Upj for forward tagged values: e E Ej A ForwardTag ==+- 0 = r.f Ao*+ e -+ (e,r) E Upj Finally, \nthere are the rules for propagating tags across data-flow constraints (the restrictive clauses prevent \nUnhappily, backward tagged values are more com-extraneous propagation of tags across dynamic dis-plex. \nThere is the same association at points where thepatches): containee is inserted (i.e. at field writes), \nand that does tell us which container object to use. However, in order ForwardTags t to use this container \nvalue, we must pass it backwards t t E ForwardTags(x)A along the data-flow paths for the containee values, \nwhich Creators(Head(t)) fl Creators(w,) may not be possible. We deal with this by trying to find {I \n{zl~*vc 1 some value in Rj that dominates (denoted E) both the place where the containee is assigned \n(so that we are using the right container) and the creation of the con-tainee (so that we can replace \nthe right containee). We BackwardTags t need a very strict notion of dominance: i 3 j means the statement \ncreating of j executes at most once for each t t E BackwardTags(x)A execution of the statement creating \ni. Creators(Head(t)) n Creators(v,) {I {=I%*= j (e,r) E Upf -----r.  5.4.3 Computing Ef, Rj and Upf \no.f = eA Ef and Rf are each defined in terms of a class. Rj is rr+oA values flowing from the creations \nof the class containing VcEcteators(e)VcEcreationPoints(C)T c+ c f, and Ej is values flowing from the \ncreations of the classes of the child (i.e. the type of f): iizjt Container(f) t the class containing \nfield f (i + j A kind(j) = argument) VCreationPoints t results of news of C LocalDominates(creation(i), \ncreation(j)) 5.5 Adaptive Analysis The adaptive flow analysis (see Section 4.2) uses tugging and adaptive \nsplitting together to compute Ef, Rf; then we will use the resultant Ef, Rf and inter-procedural data-flow \ngraph to construct Upf. Tagging and adap-tive method splitting is used to disambiguate uses of different \ncontainee objects, and adaptive object split-ting creates individual object contours representing the \ncreations of containee objects. It is similar to the nCFA analysis, but is defined on object contours \nrather than classes, and creates object contours as needed. We first define precisely what a tag is, \nthen discuss how they are propagated using adaptive analysis. Finally we detail how to compute Ef , Rf \nand Upf . 5.5.1 Tags A tag is a sequence (f ieldcountor l, , f ieldcontour,) in-dicating from or to which \nfields of which contours (see Section 4.2) a given value comes or goes: contoun are the object contours \nrepresenting the creator of the ob-ject accessed and fields are field names from their respec-tive contours \nclasses. Manipulation of tags is defined as follows: NoTag a not from field. MakeTag(f,,(f,,,... ,fc,)) \n* (.fc~fc~l... yfcm) Head((fCl,... ,fc,)) ---r fc~  5.5.2 Tag propagation The tags defined above are \npropagated by a standard data-flow algorithm thru the inter-procedural data-flow graph in order to compute \nEf, Rf. Adaptive analysis is an iterative algorithm, and this tag propagation is repeated for each iteration \nof the analysis framework. In defining our data-flow equations, we will use the + and X= relations to \nindicate forward and backward data-flow relationships between values. Tag propagation conceptually starts \nat the creation sites (i.e. new statements) summarized by uncontained contours, that is, objects that \nare not assigned into any field of any object. The set of uncontained contours, which we call Top, is \ndefined as follows: Top t    4CEnllCIasses hGWds(C) 3c1~~PeatorS(~)~ E Creators(F,,) Tags are propagated \nthru the inter-procedural data-flow graph along forward and back data-flow paths, with special rules \nfor the results of object creations and field accesses. The rule for object creations is straightfor- \nward: for each creation site in Top, its result is given the forward tag NoTag: v = new Clbj A (Creators(v,) \n-Top) = 0 ==+ ForwardTags c {NoTag} There are two rules for field accesses -one for reads and one for \nwrites -that propagate the appropriate tag based upon the field accessed and the container s tag: v = \no.f ===s ForwardTags c MakeTag(f,,lf(,), cECreators(o,)t) o . f = v ===+ BackwardTags t ttT:(o,) (.,Ci!~~(.,) \nMakeTag(fse f(c)l )) Finally, the rules for propagating tags across data-flow constraints are exactly \nthe same as for nCFA. 5.5.3 Adaptive splitting The propagated tags are used to guide adaptive split-ting \nto disambiguate the uses and creations of different containee objects. The analysis framework allows \nindi-vidual analyses to register discriminator functions that determine whether a given contour needs \nto be split. Uses of different containees are disambiguated using the forward tags by splitting contours \nof methods in which differing tags from different callers merge. Each contour has a set of edges representing \nthe calls it summarizes. Contours are split so that all incoming edges have com-patible tags. The edges \nof a contour are partitioned into sets that become new contours as shown in Equation (1) of Figure 8; \nnote that Arg(e,i) is the ith argument of edge e. The object contours representing the creation of con- \ntainee objects are created by using the backward tags. These backward tags will be propagated from assign-ments \nto fields back toward the creations of the objects being assigned into that field, which must ultimately \nbe object creation statements, which are represented by object contours. Two steps are involved in splitting \nob-ject contours: first, the data-flow path from the field back to the creation must be separated by \nsplitting all intermediate methods according to the backward tags of their values as given in the formula. \nIn Equation (2) of Figure 8 Ret(e, i) is the ith return value of edge e. Then the object contours themselves \nmust be split. The object contours represent the result of a new oper- ation, so the backward tags will \nultimately flow all the way back to that value, and so these tags can be used to partition the object \ncontour into a set of contours. This is shown in Equation 3 of Figure 8; the result of the new statement \nis v in that equation.  5.5.4 Computing Ef, Rf and Upf In the adaptive analysis, an object contour is \ncreated to represent the containee objects, so Ef and RI are each defined in terms of an object contour. \nA field f is discriminated by the object contour of its container, which we designate fc. The computation \nis exactly the same as for nCFA, except that fields are specialized to Figure 8: Criteria {{el,... , \ne,} 113i,j,kForwardTags(Arg(e;, k)) # ForwardTags(Arg(e~, k)) } (1) {{el, . , e,} 113i,j,kBackwardTags(Ret(ei, \nk)) # BackwardZ ags(Ret(ej, k)) } (2) {{Cl,... , cn} pi,j,aa ckwardTags(u,i) # BackwardTags(v,j) } (3) \n object contours. So, Rf and Ef for a field f0 become CreationPoints t results of news of c V CJ+U EJ \n---+ U cECreationPoints(0) 1 1 Rf -t  c*+v u U U iI ( ~CECreators(f,)cECreationPoints(C) 1 Computing \nUpJ is exactly the same as for nCFA, except that it is done for the EJ and Rf specialized for a given \ncontour. 5.6 Object lnlining Transformation Once we have Ef , RJ and UPJ for a given field f, the object \ninlining transformation is simplicity itself, at least conceptually: replace uses e of the containee \nwith UpJ(e), move the containee s storage into the container, and delete all creations of a containee5. \n6 Evaluation We set out to determine how much analysis power is required for effective automatic inline \nobject allocation on a range of programs. Thus, we must measure how effective and costly each analysis \noption is at compile time, and their effects at runtime. Our primary met-rics measure the compile-time \nbenefits and costs -in-lined field counts and analysis costs -and dynamic run-time changes, field accesses \nand object allocations elim-inated. We also measure the impact of object inlining on the program overall. \nFirst, we describe what compil-ers (Section 6.1), benchmarks (Section 6.2) and metrics (Section 3) we \nused. We present our results in Sec-tion 6.4. 6.1 Methodology Our evaluation uses a range of C++ programs \nto com-pare our three inlining analyses -local, 1-cfa and adap- tive -with a base program compiled by \nthe Concert compiler with no ob$ect inlining. For calibration, we compare the runtime and code size these \nfour program 6Having El allows us to precisely find all creations because the results of such creations \nwill be in E,. eAll runs are done on a 266MHz Pentium Pro system with 128M of memory. for Adaptive Splitting \nversions with the same programs compiled with the lat- est gee (2.8.1). Both compilers are run with full \nopti-mization (03 for g++) and given the whole program. Thus, we use the five versions of each program \ncompiled as shown in Figure 1. In this table, analysis is the object inlining analysis used (l-CFA is \nthe traditional Control Flow Analysis), and policy whether inlining was done by hand, automatically or \nnot at all. For the l-CFA and adaptive analyses, analysis was performed before any transformation had \ntaken place; in order to make the local scheme as effective as possible, we performed the local analysis \nand transformation after method inlining. I object inlining 1 I name analysis 1 policy 1 compiler base \nI none I none I Concert 1 N.A. 1 manual 1 G++ 2.8.1 1 Table 1: Compared Analysis and Compiler Parameters \nSince the benchmark programs are in C++, they in-clude a lot of low-level information -e.g. specifying \nvirtual versus non-virtual functions, and denoting reg-ister, stack, heap and inlined storage allocation \n-that is not compatible with the high-level model expected by the Concert compiler. The Concert compiler \ndiscards all such information , ignores type information and uses a reference model for all objects. \n 6.2 Benchmarks We evaluate our object inlining techniques on the wide range of commonly-used standard \ndata structures con-tained in two class libraries: the National Institutes of Health Class Library (NIHCL) \nand the Object Abstract Type Hierarchy (OATH) libraries. We use them as they are freely available and \ncomprehensive. Both libraries come with a range of test programs that exercise the library, and we evaluate \nobject inlining both on these test codes and also third-party programs written us-ing the libraries. \nThe NIHCL codes include the 20,000 line NIHCL library, and the OATH codes include the 18,000 line OATH \nlibrary. In addition, we use some benchmark programs commonly used to evaluate ob-ject oriented systems; \nthese programs exhibit a variety of data and control structures. These codes -and the inlining opportunities \nthey exhibit -are summarized in Figure 2. The lines column has the lines of code in the Obviously, the \ngenerated code respects the semantics of dif- ferent storage allocations, such as the meaning of assignment \nprogram followed by the lines of library code in paren- theses. These codes represent a superset of the \nbench-marks used in our prior work 191; that work used only silo, richards, polyover and oopack. 6.3 \nMetrics To assess the respective benefits and costs of our ap-proaches to object inlining, we measure \ncompile-time cost and effectiveness and the runtime impact. Our whole-program compiler makes no distinction \nbetween a program and the libraries it uses, so all metrics cover the program and all libraries together. \nOur metrics are summarized in Table 3 and described below. Compile-Time Effectiveness We use a count \nof the to- tal number of fields found to be inlinable. To calibrate the effectiveness of our techniques, \nwe compare these counts with the number of fields manually declared in-1ine.s Compile-Time Cost We use \nthe amount of analysis precision required, which we measure as the amount of context-sensitivity required \nper method and per class. For the adaptive analysis, these counts are the total number of contours created \nacross all iterations. Direct Dynamic Effects By fusing objects, inline allo-cation should reduce the \nnumber of field accesses and object allocations during program execution, and we measure these as our \nprimary metric for runtime effec-tiveness. Overall Dynamic Effects To assess the impact of ob- ject inlining \non the program overall, we measure run-time, executable size and memory usage. The special-ization required \nby inlining could increase code size, and reducing the number of objects allocated should reduce total \nmemory usage. 6.4 Results We present our metrics in same four groups as for Ta-ble 3: compile-time effectiveness, \ncompile-time cost, di- rect dynamic effects and overall dynamic effects. 6.4.1 Compile-Time Effectiveness \nFigure 9(a) presents the counts of inlinable fields discov- ered for each analysis and program; polymorphic \nfields are counted as a fraction based on how many of the poly- morphic uses were found to be inlinable. \nThe counts range from 0 in some cases for 1-cfa and local analy-ses to 9 for stack and options for the \nadaptive analysis. These are raw counts, so the trend is for more fields to be inlinable in larger programs \nas they typically have more classes. It would be nice to calibrate by determining the numbers of fields \nreally inlinable, but this is problematic. One can-not determine this automatically -our automatic determination \nis what we are evaluating -and counting by hand is difficult and error-prone for codes the size and complexity \nof NIHCL and OATH. Adaptive analysis proved most effective, finding at least as many fields as any other \nanalysis, and a superset of those declared inline in C++. The 1-cfa analysis was as effective as adaptive \nanalysis on some programs, but dramatically less so for others. It sometimes did not find all the fields \ndeclared inline in C++. The local analysis was ineffective: it found no fields inlinable on several programs, \nand it never found more than two fields inlinable. Adaptive analysis -and sometimes 1-cfa as well -found \nfields not declared inline in C++ when there were objects conceptually in a dynamic relationship -such \nas cons cells -that were used statically in a given context. This demonstrates an advantage of automatic \nobject in-lining: the ability to discover fortuitously static uses of normally dynamic structures. The \nmost common case was fusing a cons cell with its associated data in situ- ation where analysis determined \nthere was no sharing amongst the list elements. This happened for options, pdl2a, silo and polyover. \nAdaptive analysis could fuse polymorphic lists in options. The 1-cfa analysis, lacking context sensitivity \nbased upon object values, generally could not handle polymor-phic structures; and, in each of sets, addcontentsto \nand OTdeTech, the sensitivity limits of l-CFA prevented it from specializing two fields actually declared \ninline in C++. Aside from those six fields, all other differences between adaptive and 1-cfa analysis \nare attributable to data sensitivity. The local data-flow analysis found very few fields, primarily because \nmost of the inlinable fields were in core program data structures used throughout the program and hence \nnot amenable to local analysis techniques. For oopack, the local analysis had trouble because all major \ndata structures are passed thru global variables. For several of the NIHCL benchmarks, one array in the \ncore data structures could not be inlined because it may be reallocated dynamically to resize it if it \nover-flows. This never actually happens in some of the bench- marks, but our compiler does not do sufficient \nrange propagation to figure this out. 6.4.2 Compile-Time Cost. The cost of our analyses is measured \nby the numbers of contours per method and class, as shown in Figures 9(b) and (c). The general trends \nfor method contours are different for the different analyses. Adaptive analysis has fairly flat costs \n-between 2 and 4 contours per method -across the programs, whereas 1-cfa cost rises as program size grows, \npeaking for our largest bench-mark, options. Local and base both use adaptive anal-ysis without the object \ninlining component, and they both show flat costs of between 1.5 and 3.5 contours per method. A notable \nfeatures of this graph is that adaptive object-inlining analysis does not raise the cost much over the \nbase adaptive analysis, except on add-contentsto for which cost doubles. The rise in cost of 1-cfa for \nlarger programs is ex- pected, and has been observed before; the small varia- tions in cost for adaptive \nanalysis track the structural complexity of the programs. More polymorphic codes such as richards and \noptions -which each use a polymor- phic core data structure -have higher costs than stack, 10.0 Adaptiva \nAnalysts 8.0 C++ Dedaralions (a) Unable Fields v) 14.0 3 G 12.0 5 10.0 !!2 2 8.0 5 6.0 z 4.0 gj 2.0 \n 0.0 (b) Contours Per Method 2 2.8 Adaptive Analysis $ 2.4 g 2.0 $ 1.6 5 1.2 3 0.8 8 0.4  0.0 \n(c) Contours Per Class Figure 9: Compile Measurements (absolute counts) I Prooram I M lanes I mam data \nstructures I znlznable oblects I NIHCL options 30K polymorphic lists list elements, empty, 1,2d-arrays \norderedcltn 20.11K dynamic arrays iterators, collection wrappers, arrays stack 20K stacks parent/child, \niterators, wrappers, arrays addcontentsto 20K sets, dynamic arrays iterators, wrappers, arrays OATH CSl \n18.1K arrays, smart pointers wrappers, parent/child, smart pointers pdl2a 18.1K queues, smart pointers \nwrappers, list elements other programs oopack 3.3K arrays, numbers array of objects silo 1.3K queues \nconses, list wrappers polyover 1.2K lists, objects array of objects, conses richards l.OK objects simple \nparent/child Table 2: Benchmark Summary Name Units Description Compile time effectiveness inlinable fields \ncount 1 number of inlined fields Comuile time cost method contours ) per method 1 method contours generated \nobject contours per class object contours generated I Direct dvnamic effects ., 1 reads count relative \nto base number of object field reads news count relative to base number of object allocations Overall \ndvnamic effects runtime time relative to base program runtime memory usage bytes relative to base total \nheap allocation code size bytes relative to base executable image size Table 3: Metrics silo and oopack \nwhich have no polymorphism whatso-This varies from one quarter to one half of the total ever. An anomaly \nis the relatively small difference be-compile time depending upon how much adaptive anal-tween adaptive \nand l-cfa on the OATH codes csl and ysis is required. Asymptotically, the runtime varies both pdZ2a. \nThese codes use an idiom for nil that creates in accordance with program size and with the amount of \ntype ambiguities throughout the program, which causes demand-driven sensitivity required; however, the \nactual substantial demand-driven splitting in an attempt to ruutimes for individual programs are not \nshown since resolve them. they are dominated by implementation details rather Figure 9(c) shows that \nfew object contours are than directly by properties of the programg. needed in general -none of the bars \ngo much above two. The costs are fairly constant between analyses, ex- 6.4.3 Direct Dynamic Effects cept \nfor some peaks for adaptive analysis. These peeks represent the extra precision needed for the most poly-The \ncharts in Figure 10(a) and (b) present details of morphic codes, particularly options and richards. This \nthe changes in object accesses and allocations induced extra precision is what allows adaptive analysis \nto in-by object inlining. They show the fraction of field reads line polymorphic fields. There are two \nanomalies. The removed and of object allocations removed respectively. first is that some bars are below \none, which happens The results are very varied for the adaptive and 1-cfa because some classes -such \nas abstract base classes -analyses; the peaks of both charts are high: for some are not instantiated \nat all and so do not generated ob-programs, almost all allocation and references can be ject contours. \nEven though 1-cfa does not create object eliminated. On the other hand, some programs -- such as contours, \nsome of its numbers are still greater thau one options and the OATH codes show little gain on either \ndue to splitting of the array class required due to im-metric. The average fraction of reads and allocations \nplementation artifacts. eliminated are 37% and 43% respectively over the base The actual runtime of our \nanalysis system varies Concert program. The local analysis proved ineffective: about two minutes on the \nsimplest program (oopaclc) For example, we use unsorted lists to record types, so com- without object \ninlining analysis to about 30 minutes for puting a type difference is an O(n*) operation. Programs with \nobject inlining analysis on the largest code (options). lots of classes suffer unnecessarily from this \nartifact. 2 80--2 70--$ GO--cr\" 50--5 40--al 30--3 20--8 10-I I I I !. I I I I I IB 'i o-! a -lO- (a) \nField Reads Reduction Adaptive Analysis 1 -CFA Analysis Local Analysis Base Analysis (b) Object Allocations \nReduction Figure 1 Direct Runtime Measurements (relative to base) only one program showed noticeable \ngains, due to how few inlinable fields the local analysis found. There is some correlation with the inlinable \nfield counts -as one might expect. The stacS code -which tied the larger options for the most inlinable \nfields at 9 - shows dramatic gains on both metrics: about 80 % of reads and 50% of objects both vanish. \nLarge reductions of reads for addcontentsto, oopack and polyover with adaptive analysis are due to removal \nof object deref-erences from critical paths in tight loops. The most dramatic reduction of object allocation \nis for oopack: almost 100% are eliminated. One array of complex numbers accounts for the vast bulk of \nthe ob-jects in this benchmark, so inline allocating the arrays elements removes almost all the objects. \nThe same is true to a lesser degree in polyover. On the other hand, a couple of programs show little \nimprovement in either metric even with adaptive analy-sis. The options code shows relatively modest gains \nde- spite having the most inlinable fields because it makes heavy use of strings, which implementation \ndetails pre-vent us from inline allocating. The csl code -and the oath library in general -have relatively \nfew inlinable fields due to type ambiguities caused by its idiom for nil objects.  6.4.4 Overall Dynamic \nEffects Runtime. The relative execution times of our bench-marks are shown in Figure 11(a); this chart \nshows the fractional performance improvement relative to the base Concert code. We are evaluating the \neffects of object inlining relative to the base Concert code, as that is a controlled experiment simply \nturning object inlining on and off. Given the completely different implementations of g++ and Concert, \nthe comparison with g++ is meant only as calibration of Concert s base performance. Com-pared with g++, \nthe Concert compiler produces slower code on 6 of the benchmarks and faster code on 5 of them. The chart \nshow mostly performance gains up to 50% (for polyover) for object inlining using adaptive analy-sis. \nThe average runtime gains are 3% for 1-cfa and 10% for adaptive analysis. The local analysis makes no \nap-preciable difference on any code. The most significant performance gains are for stack, oopack and \npolyouer. These gains come partially from the removed objects and reads, but are also due in large part \nto object in-lining enabling other optimizations, especially caching fields in registers and allocating \nobjects with provably limited lifetimes on the stack. The scarcity of performance gains from object inlin-ing \n-two programs are even slightly slower -on the other codes despite sometimes dramatic drops in read and \nobject counts can be explained in part by our com-piler. Our research focuses on high-level analysis \nand transformation, and we have a relatively simple code generator that is unambitious with local code \noptimiza- tions . Thus, when object inlining produces tighter bodies of code, that does not always translate \ninto bet- The register allocator is especially unhelpful on the Intel architecture with its scarcity \nof registers. ter performance. However, object inlining dramti-tally reduces references and allocations, \nand making our backend take advantage of the better code is continuing work. Memory Usage. Figure 11(b) \nshows the reduction in memory usage for the inlined program versions as a frac- tion of that used by \nthe base Concert program. Both the adaptive and 1-cfa programs show significant reduc-tions for many \nprograms; the reduction is due to the reduced overhead of fewer objects in our garbage col-lected model \nand the space saved by the elided pointer fields. The average reduction in memory allocation is 3% for \n1-cfa and 13% for adaptive analysis. In general, the correlation between reduced object allocations and \nreduced storage use is weak because of the variance in the size of single objects. The greatest reduction \noccurs for the stack code with adaptive analysis: in this case, in addition to remov-ing objects, object \ninlining enabled object state caching that allowed other objects to be pruned completely. Conversely, \nthe increase in object allocation caused by the local analysis on richards is caused by inlining in-hibiting \nother code optimizations, particularly object stack allocation. Code Size. Figure 11 shows the size of \nthe final pro-gram relative to the base executable produced by Con-cert. The various version produced \nby the Concert com-piler are of almost identical size for each program, show-ing the specialization required \nby inline allocation does not result in significant code expansion. This is because it by and large the \nspecialized methods would have to copied by inlining anyway. Compared with G++, the Concert compiler \nproduces smaller executables for the large programs because it does a better job of tree-shaking the \nclass libraries. 7 Related Work Related work falls into two broad categories: there are other mechanisms \nfor affecting inline allocation of ob- jects, and there are other analyses that function sim-ilarly to \na given aspect of object inlining but serve a different purpose. The idea of doing automatic object inlining \ndates back at least to the Emerald system, which has a refer- ence object model [3] that was designed \nso that the com-piler [18] could optimize object structures. However, while our adaptive analysis can \nproduce the information needed for inline allocation (see Section 5.1), the sim-ple, graph-algorithm-based \nanalysis system of the Emer- ald compiler was sufficient only to allow the inlining of (boxed) immediate \ntypes. Immediate types in Emerald posed fewer analysis challenges for they had by defini-tion the value \nsemantics required for inlining. Budimlic and Kennedy [4] sketch a combined object and method inlining \noptimization which they call object inlining. In their scheme, for an object created within a method, \nall its called methods are inlined and the state of the ob-ject replaced with local variables. Our inter-procedural \nThis is also why Concert is slower than g++ on several of the benchmarks. Percentage of Runtime Removed \nPercentage Byte Allocation Reduced Percentage of Code Removed 2 in0 G iG s 0 ul 0 0 I I I I I+ analyses \ntrack field usage throughout the program -re-gardless of procedure boundaries -which was vital for inlining \non our benchmarks; their scheme, like our local analysis, does not. But a detailed comparison is impos- \nsible as they give only a rough outline of their trans-formation which ignores the obvious aliasing concerns \nwhich we resolve by tagging. Runtime optimizations analogous to object inlining have also been tried; \nwitness cdr-coding as done in the Symbolics Lisp machines. The basic idea is that list el-ements are \nstored adjacently, eliminating the need for a tail pointer; this adjacency can be due to happenstance \nor can be arranged e.g. by a compacting garbage col-lector. Unlike our compile-time transformations, \ncdr-coding does not depend upon static analysis, and so can be applied to portions of lists and other \nentities to fine to be distinguishable by current static analysis tech-niques. On the other hand, our \nstatic techniques have no runtime overhead, whereas the fact that a cons cell is cdr-coded must be recorded \nand checked whenever the cell is accessed. There has been much work in the functional commu-nity on unboxing, \nin which specialized representations are used to reduce storage and access overhead. Our adaptive flow \nanalysis is able to compute precise inlin-ing information in the presence of assignments to object fields; \nthe unboxing work does not need to address this as there is no structure assignment in functional lan-guages. \nThe unboxing transformation of [20] handles polymorphism by generating specialized code only for monomorphic \nfunctions and coercing between general and unboxed representations as needed. On the other hand, our \noptimization is a global transformation that specializes polymorphic functions as needed. In [15], Cordelia \nHall and company present a trans- formation for Haskell that does generate specialized code to exploit \nunboxing for polymorphic functions. Their transformation resembles ours in that it propa-gates unboxedness \nthroughout the program generat-ing specialized code wherever needed. Our optimization is fully automatic \nand handles arbitrary user-defined object types. Due to the lazy semantics of Haskell, the transformation \nmust be told what variables can be safely unboxed; furthermore, this transformation only unboxes immediate \ntypes. In [26], Shao et al. unroll linked lists-essentially in-line allocating tail pointers-in a functional \nsubset of ML. Their analysis works using refinement types [13] that distinguish odd and even length lists. \nThese re-fined types are propagated using an abstract interpreta-tion, with rules for the refined types \ngenerated by cons statements. All functions that take list parameters are cloned and specialized with \nall possible combinations of refinement types for their list parameters. Our inter-procedural analyses \nhave two advantages. First, our field tags are more general, as they handle arbitrary object structures, \nrather than lists. Second, our inter-procedural analysis analyzes only specializations that are actually \nused. In [ll], the authors describe access paths, which are used in various kinds of pointer analyses. \nThe basic idea is that access paths keep track of object fields traversed during pointer dereferences. \nThe major difference be-tween access paths and our tags is that access paths start with stack variables, \nand are used for instance-based alias analysis, whereas our tags start from object creation sites and \nour analysis is class-based (actually object contour based). Object inlining analysis does not require \nthe precision of instance-based aliasing, and so we can use a potentially cheaper class-based mechanism. \n8 Summary We have studied three compiler analyses to identify safely inlinable fields. These analyses \nspan a range of cost and complexity, and all track field (member) ac-cesses in heap objects. These analyses \nspan a range of complexity from local data flow to adaptive whole-program, flow-sensitive inter-procedural \nanalysis. Mea-suring the cost and effectiveness of these analyses on a suite of moderate-sized C++ programs \n(up to 30,000 lines including libraries), we find that object inlining op-timizations eliminate 40% typically \nand as much as 90% of the object accesses and allocations, and can deliver significant performance benefits \n(averaging 10% faster but ranging from no improvement to 50%). But reaping these benefits requires powerful \ninter-procedural analy-sis that must focus effort to avoid excessive cost. For-tunately, the adaptive \ninter-procedural analysis we em- ployed [24] computes precise information efficiently. Acknowledgments \nThe Concert Compiler used for the experiments de-scribed in this paper has been the work of John Plevyak, \nVijay Karamcheti, Xingbin Zhang and Hao-Hua Chu in addition to the present authors. In particular, the \nadap- tive analysis techniques we use are the work of John Plevyak and Andrew Chien. The research described \nin this paper is supported in part by DARPA orders #E313 and #E524 through the US Air Force Rome Laboratory \nContracts F30602-96-1-0286 and F30602-97-2-0121, and NSF Young Investiga-tor award CCR-94-57809. Support \nfrom Microsoft, Intel Corporation, Hewlett-Packard, and Tandem Computers is also gratefully acknowledged. \nReferences 0. Agesen, J. Palsberg, and M. Schwartzbach. PI Type inference of SELF: Analysis of objects \nwith dynamic and multiple inheritance. In Proceedings of ECOOP 93, 1993. P. America. Inheritance and \nsubtyping in a PI parallel object-oriented language. In Proceedings of ECOOP, pages 234-42. Springer-Verlag, \nJune 1987. A. Black, N. Hutchinson, E. Jul, and H. Levy. Ob- 131 ject structure in the emerald system. \nIn Proceedings of OOPSLA 86, pages 78-86. ACM, September 1986. Zoran Budimlic and Ken Kennedy. Optimizing \njava: Theory and practice. Concurrency: Practice and Experience, 9(6), June 1997. ]41 [51 Brad Calder, \nDirk Grunwald, and Benjamin Zorn. Quantifying differences between C and C++ pro-grams. Technical Report \nCU-CS-698-94, Univer-sity of Colorado, Boulder, January 1994. PI C. Chambers and D. Ungar. Iterative \ntype analysis and extended message splitting. In Proceedings of the SIGPLAN Conference on Programming \nLan-guage Design and Implementation, pages 150-60, 1990. Andrew Chien, Julian Dolby, Bishwaroop Ganguly, \nVijay Karamcheti, and Xingbin Zhang. Support-ing high level programming with high performance: The Illinois \nConcert system. In Proceedings of the Second International Workshop on High-level Par-allel Programming \nModels and Supportive hhviron-merits, pages 15-24, April 1997. [71 PI Jeffrey Dean, Craig Chambers, and \nDavid Grove. Selective specialization for object-oriented lan-guages. In Proceedings of the ACM SIGPLAN \n95 Conference on Programmin g Language Design and Implementation, pages 93-102, La Jolla, CA, June 1995. \n[91 Julian Dolby. Automatic inline allocation of ob- jects. In Proceedings of the 1997 ACM SIGPLAN Conference \non Programming Language Design and Implementation, pages 7-17, Las Vegas, Nevada, June 1997. 1101 Margaret \nA. Ellis and Bjarne Stroustrup. The An- notated C++ Reference Manual. Addison-Wesley, 1990. [III Maryam \nEmami, Rakesh Ghiya, and Laurie J. Hen- dren. Context-sensitive interprocedural points-to analysis in \nthe presence of function pointers. In Proceedings of the 1994 ACM SIGPLAN Confer-ence on Programming \nLanguage Design and Imple- mentation, pages 242-256, 1994. WI Jeanne Ferrante, Karl J. Ottenstein, and \nJoe D. Warren. The program dependence graph and its use in optimization. ACM fiansactions on Pro-gramming \nLanguages and Systems, 9(3):319-49, July 1987. [I31 Tim Freeman and Frank Pfenning. Refinement tvnes \nfor ML. In Proceedinos of the 1991 ACM . Y I SIGPLAN Conference on Programming Language Design and Implementation, \nJune 1991. [I41 Keith E. Gorlen, Sanford M. Orlow, and Perry S. Plexico. Data Abstraction and Object-Oriented \nProgramming in C++. John Wiley and Sons, 1991. [I51 Cordelia Hall, Simon L. Peyton-Jones, and Patrick \nM. Sansom. finctional Programming, Glasgow 1994, chapter Unboxing Using Specializa- tion. Workshops in \nComputing Science. Springer-Verlag, 1995. WI Urs Hiilzle, Craig Chambers, and David Un-gar. Optimizing \ndynamically-typed object-oriented languages with polymorphic inline caches. In ECOOP 91 Conference Proceedings. \nSpringer-Verlag, 1991. Lecture Notes in Computer Science 512. [I71 Urs Hijlzle and David Ungar. Optimizing \ndynamically-dispatched calls with run-time type feedback. In Proceedings of the 1994 ACM SIG-PLAN Conference \non Programming Language De-sign and Implementation, pages 326-336, June 1994. Norman C. Hutchinson. Emerald: \nAn Object-Based Language for Distributed Programming. PhD the-sis, University of Washington, Department \nof Com- puter Science, Seattle, Washington, 1987. TR-87-01-01. [I81 Christopher Lapkowski and Laurie \nHendren. Ex- PI tended ssa numbering: Introducing ssa properties to languages with multi-level pointers. \nIn Proceed- ings of CASCON, 1996. Xavier Leroy. Unboxed objects and polymorphic typing. In Proceedings \nof the 19th Symposium on the Principles of Programming Languages, pages 177-188, 1992. 1201 J. Palsberg \nand M. Schwartzbach. Object-oriented type inference. In Proceedings of OOPSLA 91, pages 146-61, 1991. \n[2Il [221 James Philbin, Jan Edler, Otto J. Anshus, Craig C. Douglas, and Kai Li. Thread scheduling for \ncache locality. In Proceedings of the Seventh Sympo-sium on Architectural Support for Programming Languages \nand Operating Systems (ASPLOS-VII), pages 60-71, 1996. [231 John Plevyak. Optimization of Object-Oriented \nand Concurrent Programs. PhD thesis, University of Illinois at Urbana-Champaign, Urbana, Illinois, 1996. \nJohn Plevyak and Andrew A. Chien. Precise con-crete type inference of object-oriented programs. In Proceedings \nof OOPSLA 94, Object-Oriented PTO-gramming Systems, Languages and Architectures, pages 324-340, 1994. \n 1241 [251 John Plevyak and Andrew A. Chien. Type directed cloning for object-oriented programs. In Proceed-ings \nof the Workshop for Languages and Compilers for Parallel Computing, pages 566-580, 1995. Zhong Shao, \nJohn H. Reppy, and Andrew W. Ap-pel. Unrolling lists. In ACM Conference on Lisp and Functional Programming, \nJune 1994. PI [271 Olin Shivers. Control flow analysis in scheme. In SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 164-74. ACM, 1988. 1281 Olin Shivers. Control-Flow Analysis \nof Higher-Order Languages. PhD thesis, Carnegie Mellon University Department of Computer Science, Pitts- \nburgh, PA, May 1991. also CMU-CS-91-145. [29] Olin Shivers. Topics in Advanced Language Imple-mentation, \nchapter Data-Flow Analysis and Type Recovery in Scheme, pages 47-88. MIT Press, Cambridge, MA, 1991. \n[30] Guy L. Steele Jr. Common LISP: The Language. Digital Press, second edition, 1990. [31] David Stoutamire \nand Stephen Omohundro. Sather 1.1, draft. Available online from http:// www.icsi.berkeley.adu/Sather/Sather-l.l.ps, \nAugust 1995. [32] Sun Microsystems Computer Corporation. The Java Language Specification, March 1995. \nAvail- able at http://java.sun.com/l.Oalpha2/doc/java-whitepaper.ps. [33] N. Wirth and J. Gutknecht. \nProject Oberon: Design of an Operating System and Compiler. dison Wesley, 1992. The Ad- A Benchmark \nPrograms options is a command-line argument processing pack-age. It s central data structure is a polymor-phic \nlist of command line options, in which dif-ferent kinds of options-integer, real, string, etc-are represented \nby different subclasses of a generic Option class. orderedcltn is a test program for the ordered collec-tion \nclasses of NIHCL; it uses sets and ordered col-lections, both of which in turn use expandable ar-rays; \nit also uses a variety of other NIHCL classes for handling I/O, iteration are other support func-tions. \naddcontentsto is a test that creates a few ordered col-lections, and then loops adding 10,000 point ob-jects \nto them. It uses sets and ordered collections, both of which in turn use expandable arrays; it also uses \na variety of other NIHCL classes for handling I/O, iteration are other support functions. stack tests \nthe stack class of NIHCL. It creates stacks, ordered collections and other support objects, and pushes \nand pops objects of different classes (so the stacks are polymorphic) into them. sets is another a test \nprogram for the ordered collection and set classes of NIHCL; it uses sets and ordered collections, both \nof which in turn use expandable arrays; it also uses a variety of other NIHCL classes for handling I/O, \niteration are other support func-tions. csl tests character sets, and creates lists, character ob-jects \nand streams for doing I/O and inserting and deleting elements. pdl2a tests doubly-linked lists. It creates \nlists, charac-ter objects and streams for doing I/O and inserting and deleting elements. oopack is a \nset of tight numerical loops that use ob- ject extensively inside the loops. It uses iterator objects, \nmatrix wrapper objects and complex num-ber objects. silo is a discrete event simulator benchmark. Its \npri-mary data structure is a list of events, which it uses as a queue. It has event objects, resource \nobjects and various support objects. polyover performs an overlay of two polygon maps. It uses lists \nand arrays of polygon objects to represent polygon maps. richards is an operating system simulation bench-mark; \nit uses a central task queue to which tasks are added in an event driven fashion when they receive messages. \n6 Raw Evaluation Results Analysis Pw~m c++ options 6 orderkdcltn 6 addcontentsto 6 stack 8 sets 6 CSl \n5 pdl2a 3 oopack 1 silo 2 polyover 3 1 0 2 richards 3 3 0 Table 4: Counts of Inlinable Fields Anal: 5 \nprogram Tadaptive 1-cfa local base Tmethods options 1730 6154 1449 1449 441 orderedcltn 888 4067 666 \n666 327 addcontentsto 1066 2301 496 496 267 stack 600 3042 512 514 284 sets 971 3761 622 622 300 CSl \n1657 3099 1383 1383 423 pdl2a 1523 2651 1286 1286 417 oopack 166 567 140 140 89 silo 208 531 148 148 \n106 polyover 131 653 85 85 60 Richards 455 934 344 344 155 : -=: -Z Table 5: Method Contour Counts Analysis \n progmm adaptive 1-cfa local base options 12413096 14149096 14169245 14169245 orderedcltn 15566973 29626973 \n28227122 29627122 addcontentsto 967943 1583828 1583977 1583977 stack 246973 306973 1177122 1127122 sets \n23046973 58046973 58047122 58047122 csl 3204709 3204709 4005523 4005523 pdl2a 6222357 6222537 6377612 \n6377612 oopack 710523016 1220703514 1220703514 1220703514 silo 11291623 11693779 14338618 14338618 polyover \n454847146 1480582168 1480582168 1480582168 richards 11884990 11884990 13334790 13334790 Table 7: Field \nRead Counts =i= Analy 3 program adaptive 1-cfa local base classes options 205 150 159 159 90 orderedcltn \n125 120 121 121 72  t -- addcontentsto 133 118 118 118 72 Analy 9 stack 123 120 120 120 72 program radaptive \n1-cfa local base Tc++ sets 128 119 119 119 72 ootions 628 600 597 597 899 -L csl 222 216 221 221 94 \nordered&#38;n 485 467 466 466 697 pdl2a 218 215 223 223 94 addcontentsto 457 450 452 452 686 oopack 33 \n30 30 30 20 stack 438 437 437 437 692 silo 17 16 16 16 21 sets 483 477 480 480 694 polyover 13 12 12 \n12 17 csl 507 507 503 503 668 rlchards 24 16 16 16 24 --pdl2a 485 485 484 484 730 oopack 311 311 310, \n310 309 silo 333 333 333 333 342 Table 6: Object Contour Counts polyover 316 316 316 316 319 . .rlchards \n311 311 311 311 313E E=i= Ana lysis 1 program adaptive I-cfa local base options 204506 278507 284700 \n284700 Table 10: Code Sizes in kB ordered&#38;n 120433 220433 210627 210626 addcontentsto 10444 10468 \n10661 10661 stack 30432 50432 80625 70625 sets 140432 320432 320625 320625 csl 645 645 652 652 pdl2a \n340633 340643 500634 500634 oopack 13 2018 2018 2018 silo 465668 465670 787899 787899 polyover 41616 \n149164 149164 149164 richards 141 141 282 282  Analvsis I progmm adaptive 1-cfa local base Table 8: \nObject Allocation Counts optlons 4676 5236 5318 5318 ordered&#38;n 6538 7818 7700 7700 - addcontentsto \n164 164 167 167 I Analysis stack 818 978 1420 1220 program adaptive base -rc++ sets 15178 17738 17740 \n17740 options 1.97 1.99 1.07 csl 15 15 16 16 orderedcltn 1.79 1.93 1.57 pdl2a 12975 12975 14255 14255 \naddcontentsto 0.05 0.05 0.05 oopack 116 132 132 132 stack 0.07 0.08 0.09 silo 12606 12606 15184 15184 \nsets 1.97 1.84 1.09 polyover 2053 2914 2094 2094 csl 0.09 0.08 0.11 -richards 4 41 5 1 5992 pdl2a 0.68 \n0.70 1.69 oopack 14.9 18.16 19.83 silo 1.0 1.1 1.8  polyover 12.71 24.43 12.83 Table 11: Memory Usage \nin kB richards 38 40 30 Table 9: Runtimes in Seconds   \n\t\t\t", "proc_id": "286936", "abstract": "Object-oriented languages such as Java and Smalltalk provide a uniform object reference model, allowing objects to be conveniently shared. If implemented directly, these uniform reference models can suffer in efficiency due to additional memory dereferences and memory management operations. Automatic <i>inline allocation</i> of child objects within parent objects can reduce overheads of heap-allocated pointer-referenced objects.We present three compiler analyses to identify inlinable fields by tracking accesses to heap objects. These analyses span a range from local data flow to adaptive whole-program, flow-sensitive inter-procedural analysis. We measure their cost and effectiveness on a suite of moderate-sized C++ programs (up to 30,000 lines including libraries). We show that aggressive interprocedural analysis is required to enable object inlining, and our adaptive inter-procedural analysis [23] computes precise information efficiently. Object inlining eliminates typically 40% of object accesses and allocations (improving performance up to 50%). Furthermore,", "authors": [{"name": "Julian Dolby", "author_profile_id": "81100506419", "affiliation": "Department of Computer Science University of Illinois at Urbana", "person_id": "PP18001962", "email_address": "", "orcid_id": ""}, {"name": "Andrew A. Chien", "author_profile_id": "81406600821", "affiliation": "Department of Computer Science and Engineering, University of California, San Diego", "person_id": "PP79028287", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/286936.286943", "year": "1998", "article_id": "286943", "conference": "OOPSLA", "title": "An evaluation of automatic object inline allocation techniques", "url": "http://dl.acm.org/citation.cfm?id=286943"}