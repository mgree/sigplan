{"article_publication_date": "10-19-2008", "fulltext": "\n QVM: An Ef.cient Runtime for Detecting Defects in Deployed Systems Matthew Arnold Martin Vechev Eran \nYahav IBM Research IBM Research IBM Research Abstract Coping with software defects that occur in the \npost-deployment stage is a challenging problem: bugs may occur only when the system uses a speci.c con.guration \nand only under cer\u00adtain usage scenarios. Nevertheless, halting production sys\u00adtems until the bug is tracked \nand .xed is often impossible. Thus, developers have to try to reproduce the bug in labora\u00adtory conditions. \nOften the reproduction of the bug consists of the lion share of the debugging effort. In this paper we \nsuggest an approach to address the afore\u00admentioned problem by using a specialized runtime environ\u00adment \n(QVM, for Quality Virtual Machine). QVM ef.ciently detects defects by continuously monitoring the execution \nof the application in a production setting. QVM enables the ef\u00ad.cient checking of violations of user-speci.ed \ncorrectness properties, e.g., typestate safety properties, Java assertions, and heap properties pertaining \nto ownership. QVM is markedly different from existing techniques for continuous monitoring by using a \nnovel overhead manager which enforces a user-speci.ed overhead budget for quality checks. Existing tools \nfor error detection in the .eld usually disrupt the operation of the deployed system. QVM, on the other \nhand, provides a balanced trade off between the cost of the monitoring process and the maintenance of \nsuf.cient accuracy for detecting defects. Speci.cally, the overhead cost of using QVM instead of a standard \nJVM, is low enough to be acceptable in production environments. We implemented QVM on top of IBM s J9 \nJava Virtual Machine and used it to detect and .x various errors in real\u00adworld applications. Categories \nand Subject Descriptors D.2.5 [Testing and Debugging] General Terms Algorithms, Reliability Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA 08, October \n19 23, 2008, Nashville, Tennessee, USA. Copyright c . 2008 ACM 978-1-60558-215-3/08/10. . . $5.00  \n1. Introduction Despite increasing efforts and success in identifying and .xing software defects early \nin the development life cycle, some defects inevitably make their way into production. The wide variety \nof deployment con.gurations and the diversity of usage scenarios is almost a certain guarantee that any \nlarge system will exhibit defects after it has been deployed. Detecting and diagnosing defects in a production \nenviron\u00adment remains a signi.cant challenge. Failures in such envi\u00adronments might occur with low frequency \nand be virtually impossible to reproduce. For example, a defect might occur due to a speci.c concurrent \ninterleaving, a speci.c lengthy user interaction, or a slow resource leak that gradually de\u00adgrades system \nperformance leading to an eventual crash. Existing tools for diagnosing defects in the wild are limited \nand usually incur an unacceptable overhead that sig\u00adni.cantly disrupts the operation of the deployed \nsystem. On the other hand, reproducing the failure in a test environment (if at all possible) may require \nconsiderable time and effort. One way to detect rarely occurring defects is to contin\u00aduously monitor \na system for violations of speci.ed correct\u00adness properties. For example, this can be achieved by using \nglobal property monitors and local assertions. However, the typical cost of these techniques prevents \nprogrammers from widely using them in production environments. This work describes a runtime environment \nthat is able to detect and help diagnose defects in deployed systems. Towards this end, we present the \nQuality Virtual Machine (QVM), a runtime environment that uses the technology and infrastructure available \nin a virtual machine to improve soft\u00adware quality. QVM provides an interface that allows soft\u00adware monitoring \nclients to be executed with a controlled overhead. Based on this interface, we present three such clients \nthat continuously monitor application correctness by using a combination of simple global property moni\u00adtors \n(typestate properties) and assertions. In addition, QVM automatically collects debug information which \nenables ef\u00adfective defect diagnosis. We implemented QVM on top of IBM s J9 Java Virtual Machine. We used \na number of large-scale real-world appli\u00adcations with QVM and found defects in many of them. We explain \nthe design rationale behind QVM in Section 3.1. 1.1 Main Contributions The contributions of this paper \ninclude: QVM: a runtime environment targeted towards defect detection and diagnosis in production systems. \n A novel overhead manager that enforces an overhead budget on client analyses, while maintaining suf.cient \naccuracy for detecting defects.  We introduce property-guided sampling and in particular object-centric \nsampling, to collect sampled pro.les while preserving correctness of the analysis.  A lightweight interface \nthat helps separate analysis clients from the details of the underlying VM, and transparently manages \noverhead of these clients.  We use this infrastructure to implement three representa\u00adtive analysis clients: \n(i) tracking simple temporal safety properties and providing debug information; (ii) check\u00ading standard \nJava assertions; (iii) checking expressive heap queries pertaining to object ownership.  We implemented \nQVM on top of IBM s production Java Virtual Machine (J9). We used QVM as our standard day to day virtual \nmachine, running a wide range of applications without a noticeable slowdown. We show that QVM can be \nused to effectively detect defects in such applications, and help diagnose them. In addition, we evaluate \nthe overhead on the standard SPECjvm98 and Dacapo benchmarks.   1.2 Overview In this section we provide \na brief informal overview of QVM components and our experimental evaluation. Overhead Manager QVM allows \nthe user to specify an overhead that is considered acceptable for the current moni\u00adtoring environment. \nThe maximum acceptable overhead may be 5%-10% in a live deployed system, yet 100% overhead (factor of \n2 slowdown) may be considered acceptable in a testing environment. Given an overhead budget, the QVM \nstrives to collect as much useful information as possible from the executing program while staying within \nthe speci\u00ad.ed budget. QVM Interface (QVMI) A performance-aware pro.ling/\u00admonitoring interface that allows \nclient analyses to remain decoupled from the VM, while maintaining ef.ciency. The design goal of this \ncomponent is to enable development of powerful, yet ef.cient dynamic analyses. Technically, the overhead \nmanager and the QVMI work together to provide clients with a transparent adaptive overhead management. \nAnalysis Clients Using the QVM platform, we implement three analysis clients as follows. Typestate Properties: \nThis analysis client enables the dynamic checking of typestate properties. Dynamic check\u00ading of typestate \nproperties, as well as generalized multiple\u00adobject typestate, has been addressed before in Tracematches \n[3] and MOP [12]. We use the typestate client to demon\u00adstrate three contributions of our platform: (i) \nadaptive over\u00adhead management; (ii) collection of timing information for typestate transitions; (iii) \ncollection of additional detailed debug information with low overhead. Local Assertions: QVM allows ef.cient \nsampling of user assertions by intercepting standard Java assertions and man\u00adaging their execution through \nthe overhead manager. Heap Probes and Operations: QVM enables the dy\u00adnamic checking of various global \nheap properties such as object-sharing, ownership, thread-ownership and reachabil\u00adity. These properties \nare useful for both debugging and pro\u00adgram understanding purposes. Experimental Evaluation To evaluate \nthe usability of QVM in .nding defects and diagnosing them, we focused on typestate properties that correspond \nto resource leaks. For that purpose, we set QVM as the default JVM used in our en\u00advironment and used \nit to perform all of our daily tasks while recording its error reports. To further exercise QVM, we used \na wide range of applications on a regular basis. Some of the applications considered are an instant-messenger \n(goim), newsfeed readers (feednread, rssowl), .le management utili\u00adties (virgoftp, jcommander), large \nIBM internal applications, etc. For all of these applications, the overhead incurred by running them \non top of QVM was unnoticeable to the user. In some of our experiments (e.g., Azureus, virgoftp, goim), \nwe investigated each report manually, diagnosed the causes of the errors, and implemented .xes. For some \nap\u00adplications, our defect reports were con.rmed by the devel\u00adopment team, and our .xes were incorporated \ninto the code\u00adbase. To evaluate the usability of heap and local assertions, we have added such assertions \nto a small number of applications and evaluate their effectiveness. The overhead of QVM is not noticeable \nby the user while using interactive applica\u00adtions, so we use the SPECjvm98 and Dacapo benchmarks to perform \nevaluate the overhead manager s effectiveness.  2. Motivating Example Azureus [8] is an open-source \nimplementation of the Bit-Torrent protocol. It supports several modes of user inter\u00adaction, all implemented \nusing the Standard Widget Toolkit (SWT) [18]. Azureus is the #1 downloaded Java program from SourceForge, \nand has more than 160 million down\u00adloads to date. Azureus plays the role of both a client and a server \nfor P2P .le sharing, and is therefore a relatively long\u00adrunning application. Finding Bugs We run Azureus \nwith QVM, monitoring various correctness properties, including possible SWT re\u00adsource leaks and IOStream \nleaks. Azureus runs on QVM QVM ERROR:[Resource_not_disposed] object [0x98837030] of class [org/eclipse/swt/graphics/Image] \nallocated at site ID 2742 in method [com/aelitis/azureus/.../ListView.handleResize(Z)V] died in state \n[UNDISPOSED] with last QVM method [org/.../Image.isDisposed()Z] Figure 1. A sample QVM error report \nfor Azureus. with no apparent slowdown. Over the course of few hours, we check the QVM logs and observe \nthat some errors were reported. Fig. 1 shows an example of an error reported by QVM while running Azureus. \nThis is the actual error report as pro\u00adduced by QVM where some package names have been ab\u00adbreviated. \nBy itself, this error report provides useful infor\u00admation about the property being violated. In this \ncase, the reported Image object has not been properly disposed be\u00adfore it became unreachable. Failure \nto properly dispose such SWT resources leads to leakage of OS-level resources and may gradually hinder \nperformance and even lead to a system crash. The error report of Fig. 1 provides the basic informa\u00adtion \nnecessary to track down the error: the method in which the object was allocated, the object s last state, \nand the last method invoked on the object. Diagnosing the Cause The QVM error report above no\u00adti.es the \nuser that there is an error, but understanding the cause of the error and introducing a .x is still nontrivial. \nThe programmer needs to track the .ow of the object through the program to identify why dispose was not \ncalled. To as\u00adsist the programmer in this task, QVM provides additional, more detailed, debug information \nin the form of a typestate history. A typestate history for an object shows all the meth\u00adods that have \nbeen invoked with that object as a receiver, over the course of the object s lifetime from allocation \nto collection. For every method invocation, the invocation history collects the contexts in which it \nwas invoked. (We provide a more elaborate description of the typestate history in Section 5.1.) To maintain \na low runtime overhead, a typestate history is only collected for some of the tracked objects. Whenever \nan allocation site is identi.ed as allocating a number of ob\u00adjects that violate a property, QVM starts \nrecording typestate histories for a sample of objects allocated at that site. This object-centric sampling \nis one of the features that makes it possible to collect detailed debug information with low over\u00adhead. \nFig. 2 shows an example of a typestate history for an object allocated at the same site as the object \nreported in Fig. 1. The typestate history abstracts the history of methods invoked on the object. Technically, \nthe typestate history is a directed graph with labeled nodes and labeled edges. A node in the graph represents \nthe state of the object after a speci.c method has been invoked on it. There is a single node in the \ngraph for each method invoked on the object Figure 2. Sample typestate history for a single instance \nof Image that was reported as non-disposed in Fig. 1. The .g\u00adure only shows a single sample stack trace \nfor every method invoked on the object.  (summarizing all invocations of that method). A node in the \ngraph is labeled by the name of the invoked method, and by a set of (bounded) contexts representing \nthe contexts in which the method was invoked. An edge between nodes m1 and m2 in the graph represents \nthe fact that the method corresponding to m2 has been invoked immediately after the method corresponding \nto m1 has been invoked. Note that this directed edge only denotes the order in time between the two methods. \nIt does not say that m2 is called from m1 . Next, we show how we used the debug informa\u00adtion provided \nby QVM in order to .nd the cause of an error. In the example of Fig. 2, there are 5 meth\u00adods that have \nbeen invoked on the tracked object. First, the object is initialized by invoking the <init> and init \nmethods. Then, a graphical context (GC) is cre\u00adated around the image (internal new GC) and disposed (internal \ndispose GC). Finally, isDisposedis invoked over the image. The method Image.dispose() that is re\u00adquired \nfor properly disposing the image is never invoked.   class ListView extends ... { private Image imgView \n= null ; // ... protected void handleResize ( boolean bForce ) { // ... if ( imgView = = null || bForce \n) { imgView = new Image(listCanvas.getDisplay(), clientArea); lastBounds = new Rectangle(0, 0, 0, 0); \nbNeedsRefresh = true ; } else { // ... } // ... } } Figure 3. Azureus code fragment leaking SWT Image \nob\u00adjects. In this simple example, there is only one context in which each method has been invoked. The \ncontext is shown inside a rectangle next to its corresponding graph node. Considering the contexts in \nwhich the methods in this example were invoked, we can see that most of the operations on the tracked \nobject are performed through the handleResize method in which it was allocated. The only exception is \nthe call to isDisposed() which originates in a paint event of the list view. We therefore focus our attention \non the handleResize method in azureus.ui.swt.views.list.ListView. The typestate history serves as a guide \nto the execution in which the property was violated. Following the sequence of calls in the debug information \nwe further focus attention to the code excerpt shown in Fig. 3. The problem in this method represents \na common source of leaks: a new image is stored into the .eld imgViewwith\u00adout properly disposing the \nprevious image that was stored in the .eld. In this example, handleResizemixes the case of imgView == \nnull(no previous image is known for taking previous bounds) with the case of forced resize (bForce == \ntrue). As a result, there are cases in which a new Image is created without properly disposing the previous \nImage stored in imgView. The number of Image objects leaked as a result of this bug directly depends \non user interaction. Since this leak is associated with a resize event, it may not occur in high\u00adfrequency. \nHowever, the cumulative effect of a large number of small leaks may be fatal. In Section 7.1, we discuss \naddi\u00adtional problems found on Azureus by QVM, and show that some of these occur very frequently and result \nin signi.cant resource leaks. Developing a Fix Now that we have diagnosed the bug as being caused by \nnot disposing the old Image object stored in imgView, the question is how do we introduce a .x. What \nwe would like to do is to invoke dispose on the object stored in imgViewbefore we stored the newly allocated \nimage into the .eld. Unfortunately, we do not know what is the source of the Image stored in imgView, \nand in particular, whether this image is shared with other GUI components. In SWT, it is common for resources \nsuch as images, fonts, and colors protected void handleResize ( boolean bForce ) { // ... if ( imgView \n= = null || bForce ) { assert (! QVM.isShared ( imgView ) ) ; if ( imgView ! = null &#38;&#38; !imgView.isDisposed()) \n imgView.dispose (); imgView = new Image(listCanvas.getDisplay(), clientArea); lastBounds = new Rectangle(0, \n0, 0, 0); bNeedsRefresh = true ; } else { // ... } // ... } Figure 4. A .x to the Image leak in handleResize \nof Fig. 3 to be shared between multiple GUI components. The con\u00advention is that whoever allocates the \nresource is responsi\u00adble for its safe disposal. When we reach the point of allo\u00adcating a new Image and \nstoring it into imgView, we don t know whether the previous value of imgViewwas allocated in this method. \nFurthermore, we don t know whether other GUI components are still using the image. At this point, we \nleverage QVM s heap assertions and check that the object pointed-to by imgView is not shared (i.e., does \nnot have any references other than imgView pointing to it). We introduce disposal code preceded by an \nassertion that makes sure that we are not disposing a shared resource. (The disposal of a shared resource \nmight end up crashing the application at a later point when the user takes an action that uses the resource.) \nThe modi.ed handleResizemethod is show in Fig. 4. We now run the .xed version of this method with QVM \nfor a few weeks, and observe that the previously reported leak does not occur. Our assertion also makes \nsure that the disposal of the Image does not affect any other GUI component. We reported this leak and \nits .x, as well as other prob\u00adlems mentioned in Section 7, to the Azureus development team. The problems \nwere con.rmed as real bugs, and our suggested .xes were incorporated into the project s code\u00adbase. 3. \nQVM Platform In this section we describe the QVM platform. First, we pro\u00advide some background and design \nrationale, then we brie.y describe the overall QVM architecture and its main compo\u00adnents. Finally, in \nSection 3.3, we describe the QVM interface (QVMI). 3.1 Design Rationale: Modifying a VM Today s production-grade \nvirtual machines employ sophisti\u00adcated techniques and optimizations to achieve maximal ap\u00adplication performance. \nIn contrast, there is little support for application correctness in a production environment besides \nchecking low-level properties such as absence of null deref\u00aderences and array index bounds. While rich \nin functionality, current debug and monitoring interfaces (e.g., JVMTI) are also not applicable as they \nincur a slowdown that is unac\u00adceptable in production mode. The goal of this work is to extend a production-grade \nvirtual machine to provide software-quality services while maintaining competitive performance. We would \nlike a so\u00adlution to provide: (I) high performance and low overhead (II) maximal separation of analysis \nclients from the details of the underlying VM  There is an apparent tension between requirement (I) \nand (II). We resolve this tension by providing a generic interface (QVMI) that manages functionality \ncommon to all analysis clients, but in addition, we allow clients to cut through abstraction layers and \nuse other VM services when appropriate. However, our technique still requires VM modi.cations, and modifying \na production-grade virtual machine is a non\u00adtrivial task. A virtual machine is a large, complex system. \nMoreover, implementing the quality services inside a spe\u00adci.c VM makes them non-portable and ties users \nof the sys\u00adtem to the speci.c VM version. In contrast, using pure byte\u00adcode instrumentation at the language \nlevel or a standard pro\u00ad.ling interface such as JVMTI [29] is portable across virtual machines. Despite \nthese disadvantages, there are a number of ad\u00advantages in having at least part of an analysis reside \nwithin production VM, as we describe below. VM only information Having access to the runtime allows the \nclient analyses to utilize information that is not readily available at the language level. For example, \nanalyses can use free bits in object headers, directly examine the heap, quickly access structures like \nthread local storage, re-use existing VM code (such as garbage collection heap traversal logic) to perform \na slightly different functionality. Analyses can utilize low-level pro.le data and infrastructure, such \nas hardware performance monitors (HPM) and .ne-granularity timing (for example, see overhead monitor \nin Section 4). Performance Having access to the dynamic optimizer (JIT) ensures that the critical code \npaths are well optimized. The JIT can also use advanced optimization techniques for fast and slow paths \n(thin guards [5], code patching [37], full duplication [4], etc.). The system can also make use of pro\u00ad.le \ndata already collected by the VM to optimize and tune a dynamic analysis. Dynamic updating By using advanced \ntechniques such as code patching and on-stack replacement (OSR) [20], VMs can support ef.cient dynamic \nupdating of instrumentation during an application run. Deployment The deployment process becomes trivial \nbe\u00adcause the required features become as ubiquitous as the VM.  Figure 5. Overall architecture of QVM. \n There is no need to install an analysis (recompile the pro\u00adgram source to add instrumentation, etc) \nwhich is partic\u00adularly dif.cult for large production application that might make heavy use of custom \nclass loaders. Our analysis can be run by simply enabling a command line .ag on the VM. In the next section, \nwe provide an overview of the QVM architecture and show how we hide the complexity of the un\u00adderlying \nVM from most analysis clients by using the generic QVMI interface. 3.2 QVM Architecture Fig. 5 shows \nthe overall architecture of QVM. At a high level, the QVM extends the VM execution engine with three \nmain components: 1. QVM Interface (QVMI): A performance-aware pro.l\u00ading/monitoring interface that allows \nclient analyses to re\u00admain decoupled from the VM, while maintaining ef.\u00adciency. The design goal of this \ncomponent is to enable quick and easy development of powerful, yet ef.cient dy\u00adnamic analyses. QVMI is \ndescribed in Section 3.3. 2. Overhead Manager (OHM): The overhead control sys\u00adtem enables users to bound \nthe overhead incurred by QVM clients. The system does .ne-grained monitoring of the time spent in the \nclients and adapts the sampling to stay near or below overhead bounds. OHM is described in Section 4. \n 3. QVM Clients: A .exible set of clients that leverage QVMI. In this paper we describe three example \nclients that enable checking of a variety of correctness properties with controlled overhead. Clients \nare discussed in Sec\u00adtion 5.  In this architecture, the overhead manager and the QVMI work together \nto provide clients with a transparent adaptive overhead management. The clients use QVMI without the \nneed to be aware of overhead management mechanisms (but with the ability to partially control it when \ndesired). The OHM uses the information collected by QVMI to adjust the sample rate such that the overhead \nmatches the desired overhead speci.ed by the user.  3.3 QVMI: The QVM Interface Various pro.ling interfaces \nsuch as JVMTI make it easy to write monitoring clients. The client speci.es the events of in\u00adterest, \nand these events are provided by the interface. Clients are kept separate from the internal VM implementation \nthat collects the events. Similarly, although our pro.ling clients are packaged as part of the VM, keeping \na clear abstrac\u00adtion interface between the core VM details and the pro.l\u00ading clients is important for \nsoftware engineering reasons, for both maintenance and ease of adding additional clients in the future. \nThe primary limitation with existing and general pro.l\u00ading interfaces is performance. For example the \ngranularity at which events are requested is too coarse. With existing in\u00adterfaces such as JVMTI, if \na client wants to receive method callbacks for some subset of the method invocations, it must register \nto receive callbacks for all method invocations, and .lter out the unnecessary callbacks on the client \nside of the interface. This introduces signi.cant overhead that is com\u00adpletely unnecessary if the analysis \nneeds only a subset of the methods. Filtering on the VM side To address this problem, the QVM interface \nis designed such that an ef.cient implemen\u00adtation is possible. The key difference from existing pro.ling \ninterfaces is that it is structured with the goal of allowing as much .ltering as possible to occur on \nthe VM side of the interface. For example, if an analysis client needs method callbacks, it must specify \nwhat methods callbacks are neces\u00adsary. This allows the remainder of the program to run at full speed. \nSimilarly, the client may request method callbacks only for a subset of the objects in the program. The \nVM can use its suite of dynamic optimization techniques to achieve an ef.cient implementation of the \nsampled pro.le. Table 1 shows a partial list of the operations supported by QVMI. Clients that register \nwith QVMI have to support a similar set of operations (as described below). In addition to the operations \nlisted in Table 1, QVMI has similar callbacks for .eld read and writes, exceptions being thrown, and \nother events supported by standard interfaces such as JVMTI. In the table, we separate operations of \ndifferent stages of the execution by double horizontal lines. The manner in which these operations are \nused is illustrated below. On VM initialization Upon startup of the virtual machine, the clients have \nto register themselves with QVMI to receive callbacks by calling registerClient. On method compilation \nDuring the compilation of a method, the VM queries the QVM agents to determine whether the code being \ncompiled needs any form of in\u00adstrumentation. This insures that maximal .ltering occurs; instrumentation \nis not inserted on any program statements if it is not required by at least one client. This querying \nis done by invoking QVMI operations such as isTrackedAlloc and isTrackedCallSite, which query all of \nthe registered QVM clients to obtain a TrackLevel, which determines what level of instrumen\u00adtation is \nneeded. For example, for our typestate client, the compiler prompts QVMI to check whether allocation \nor method call sites in the code should be tracked. Further de\u00adtails on how the typestate client is implemented \nvia QVMI is discussed in Section 6.2. During execution Depending on the tracking-level, the VM .res events \nfor tracked sites by invoking operations such as allocEvent and invocationEvent. When an object is collected \nby the garbage collector, QVMI is noti.ed by calling objectDeath. 3.4 Property-guided sampling One of \nthe major features provided by QVMI is the ability to perform property-guided sampling. Sampling is a \nkey mechanism QVM uses to reduce analysis overhead, but for many analyses using naive random sampling \nwould render the analysis completely useless because the analysis relies on certain relationship between \nevents. For example, if a dynamic analysis detects .les that are opened but not closed, and tracking \nof method invocations were sampled randomly, QVM would report false positives any time .le openwas sampled, \nbut .le closewas not. To address this problem, QVM performs property-guided sam\u00adpling, ensuring that \nthe sampled pro.le maintains suf.cient properties to make the dynamic analysis meaningful. Object-centric \nsampling QVM supports a novel feature called object-centric sampling. This technique allows an analysis \nto sample at the object instance level; an object can be marked as tracked and the analysis can receive \nall pro.le events for this object, while receiving no events for untracked objects. This allows overhead \nreduction via sam\u00adpling, without destroying the pro.le properties needed for the dynamic analysis to \nproduce meaningful results. We refer to the points in the execution at which sampling decisions are made \n(ie, whether an object is tracked, whether an assertion is executed) as origins. Allocation sites are \norigins in our implementation of object-centric sampling. The decision of whether an object is tracked \nis made at allocation time; if sampled, a bit is set in the object header to mark the object as tracked. \nA short in\u00adlined code sequence checks this tracked bit on calls to QVM methods to determine whether a \ncallback is needed. Method Description void registerClient(Client c) Registers a client to receive callbacks \nTrackLevel isTrackedAlloc(AllocSite as) should the speci.ed allocation site be tracked CallTrackLevel \nisTrackedCallSite(CallSite cs) should the speci.ed call site be tracked boolean shouldExecute(Site s) \nshould this site .re an event (based on sampling info) void allocEvent(AllocSite as) tracked allocation \nevent void invocationEvent(CallSite as) tracked invocation event void objectDeath(Object o) object death \nevent Table 1. A Partial list of the operations supported by QVMI. 3.5 Extensions Our current interface \nis not intended to be complete, but is suf.cient to cover a broad range of clients, including those included \nin this paper. The clients we currently implemented are built as part of the VM, but the interface could \nalso be exposed to enable external clients. A full spec that could be published as a performance-aware \nalternate to the JVMTI is left for future work.  4. Overhead Manager Traditional dynamic analyses typically \noperate under the model that the user de.nes an analysis, then evaluates it to determine whether the \noverhead is acceptable. The instru\u00admentation that is used to implement the analysis is .xed, and the \noverhead incurred is a function of the program that is executed. The QVM Overhead Manager, or OHM, reverses \nthis mentality by allowing the user to specify an overhead that is considered acceptable for the current \nmonitoring environ\u00adment. The maximum acceptable overhead may be 5%-10% in a live deployed system, yet \n100% overhead (factor of 2 slowdown) may be considered acceptable in a testing envi\u00adronment. Thus, the \nacceptable overhead is one of the inputs to QVM. Given an overhead budget, the QVM strives to collect \nas much useful information as possible from the executing program while staying within the speci.ed budget. \nIf the maximum overhead speci.ed is too low, QVM may not report any useful information. This is obviously \nnot the desired outcome, but in many cases it is more desirable than losing control of the overhead and \nhaving a performance crisis as a result. There are three components to the overhead manager, each of \nwhich are discussed in the sections that follow. 1. Monitoring: measures the overhead imposed by the \nQVM clients 2. Sampling strategy: a strategy for sampling each origin (e.g. allocation site or an assertion \nsite) to ensure the system stays within the overhead budget 3. Controller: adjusts the sampling strategies \nfor each origin based on the measured overhead  4.1 Monitoring The overhead monitor uses .ne granularity \ntimers on entry and exit to all QVMI calls to record the time spent in QVM clients and in the QVMI itself. \nThe time is maintained sep\u00adarately for each origin (see Section 3.4) so that the sample rate of each \norigin can be adjusted independently. Timer accuracy The most important step in managing overhead is \nhaving the ability to measure overhead accu\u00adrately. The overhead controller cannot be expected to make \nreasonable decisions if it is being given incorrect timing data as input. Measuring overhead for coarse \ngrained events (such as garbage collection time) is relatively easy; a number of sys\u00adtem timing routines \ncan be used to obtain reasonable results. However, timing short, frequently executed regions is more \ndif.cult and requires having a timer that is both accurate and ef.cient. Using an inef.cient timer mechanism \nhas two serious problems: 1) it can cause signi.cant overhead if called fre\u00adquently (which can be the \ncase with some QVM clients), and 2) the error can be signi.cant when timing short regions and these timing \nerrors will accumulate. To address these problems, our OHM implementation uses inline assembly to read \nthe cycle counter using the In\u00adtel s RDTSC (Read Time Stamp Counter) instruction. This mechanism results \nin very fast and accurate time stamping on entry and exit of the QVMI. Our initial implementation used \nthe system call gettimeofday() and it created sig\u00adni.cant inaccuracies, as described in Section 7. Measuring \ntotal application time The timers measure time spent performing QVM tasks. To compute overhead relative \nto the non-QVM application, the OHM must also measure the total execution time. Using wall clock time, \nrather than process time, would be grossly incorrect for two reasons. First, interactive applications \nwould create signi.\u00adcant error because idle time would be counted as application time. Second, wall clock \nwould be wrong for multi-threaded applications running on multi-processor machines. QVM time is measured \nand accumulated from all running threads, thus the total time must be the sum of the time spent execut\u00ading \non all processors. For these reasons, we compute total time by using the getrusage() Linux system call \nto obtain the total time used by the JVM process. This solves the problems associ\u00adated with using wall \nclock time discussed above and works well in practice for most applications. However, it is still not \na fully robust solution when QVM activity is not evenly dis\u00adtributed across the application threads. \nFor example, consider an application with 2 threads run\u00adning for 1-second each in parallel on a 2-processor \nmachine; getrusage() will report 2 seconds of total execution time. Assume that QVM was given a 10% overhand \nbudget, which translates to 0.2 seconds allocated to QVM. If all of the QVM callback activity takes place \nin one of the two ap\u00adplication threads, one thread will run for 1.2 seconds while the other runs for \n1 second. Although the total CPU time is increased by 10% a user of the program would observe the program \nterminating after 1.2 seconds, a 20% increase. The most robust solution to this problem is to perform \noverhead tracking at the thread-level. If overhead budgets are tracked and enforced per-thread, total \noverhead as perceived by the user will always be within budget as well. A similar approach of using per-thread \nmetrics has been employed by real time systems to track time spent performing system services [6]. We \nleave an implementation of this approach within QVM as part of future work. Base overhead Even when accurately \nmeasuring the time spent in the QVM clients, there are still two potential sources of errors: 1) checking \noverhead, and 2) indirect effects. The main sources of checking overhead is the inlined .ltering. For \nexample: virtual method calls (or inlined method bodies) for meth\u00adods relevant to QVM clients .lter samples \nby checking a bit in the object header. origin sites (i.e. allocation sites) check their sampling strategy \n(described in Section 4.2) to decide whether the allocated object is tracked. These checks are short \ninlined code sequences and con\u00adtribute very little to overall overhead (see Section 7); how\u00adever, for \nvery aggressive instrumentation, such as instru\u00admenting all calls in the program, the base overhead can \npo\u00adtentially become signi.cant. Although not easy to measure online while the applica\u00adtion is executing, \nbase overhead can be estimated by observ\u00ading the frequencies of the checks, and using a model of per\u00adformance \nto estimate the overhead. Using a model is less desirable than direct measurement, but can still be used \nas a way of avoiding large performance surprises for aggressive clients. Our implementation does not \nyet perform this mod\u00adeling to avoid large base overhead, and it is left as part of future work. The second \nsource of base overhead is indirect effects on performance, such as cache pollution, or optimization \nin the JIT that are hindered by the presence of instrumenta\u00adtion. These sources of overhead are very \ndif.cult to measure without having two separate versions of the code and using techniques such as performance \nauditor [25] to identify the performance differences.  4.2 Sampling strategy The QVMI maintains separate \noverhead statistics for each origin (see Section 3.4), allowing the OHM to increase or decrease the sample \nrate independently for each origin. Hav\u00ading origin-speci.c sample rates enables signi.cant advan\u00adtages \nfor the client analysis. Maintaining a single sample rate would be suf.cient for managing total overhead, \nbut would be likely to miss origins in infrequently executed code. With origin-speci.c sampling, the \ncontroller can reduce overhead by scaling back hot origin sites, but continues to exhaustively track \nobjects from cold sites, thus allowing the client analy\u00adsis to see a broader view of the program execution. \nAs shown in Section 7, this sampling strategy results in increased error coverage for a given overhead \nbudget. Our implementation achieves sampling by maintaining a sampleCounter and a sampleCounterReset \nfor each origin. At runtime, the checking code at each origin site decrements and checks sampleCounter; \nif it is less than zero, the origin is selected to be tracked and the counter is reinitialized by the \nvalue in sampleCounterReset. The sampleCounterReset for each origin is adjusted by the Overhead Controller \nto change the sample frequency for that origin, thus reducing or increasing its overhead. Emergency shutdown \nObject-centric sampling is most ef\u00adfective for managing overhead when there are a large num\u00adber of objects \ncontributing to total overhead. If the majority of execution is dominated by method calls on a single, \nlong\u00adlived object, tracking this object will result in large overhead. To avoid severe performance degradation \nwhen a hot, long lived object is tracked, the QVM supports the notion of an emergency shutdown. On each \nQVMI callback for alloca\u00adtions and invocations, the system checks a .ag to determine whether an emergency \nshutdown is needed. If so, it disables the monitoring bit in the object header such that the object will \nno longer be sampled. The client analysis may now need to discard this object, as the method callbacks \nare not com\u00adplete. However, this mechanism allows the system to ensure that overhead can be controlled. \n 4.3 Overhead Controller The job of the Overhead Controller is to periodically check the QVM overhead, \nand adjust the sampling frequencies accordingly. If the overhead is above the budget, sample frequencies \nare reduced; if the overhead is below budget, the frequencies are increased. To avoid oscillation and \nlarge spikes in overhead, the con\u00adtroller monitors not only total overhead, but recent overhead. Recent \noverhead is computed via exponential decay; a sec\u00adond copy of application time and QVM time are maintained, \nand multiplied by a decay factor each time the controller wakes up. This gives more weight to recent \ntimings, effec\u00adtively measuring the overhead over a previous window of execution. The primary focus of \nthe controller is keeping the over\u00adhead below the overhead budget. Maximizing the client ex\u00adecuting time \nwithin that budget is also a goal, but it is sec\u00adondary. Thus the controller reduces sample frequencies \nif ei\u00adther the total overhead or recent overhead exceed their bud\u00adgets. If the overhead deviates too \nhigh above the budget, the controller enacts the emergency shutdown to stop pro.ling in the current set \nof objects, and starts tracking new objects once the overhead is within budget. Origin-speci.c adjustment \nThe QVMI maintains separate overhead statistics for each origin (see Section 4.2), allow\u00ading the OHM \nto increase or decrease the sample rate inde\u00adpendently for each origin. These origin-speci.c adjustments \nare made as follows. The controller decides on sample rates for each ori\u00adgin by maintaining a second \noverhead threshold, called originOverheadBudget. The sample rate of each origin is adapted to stay below \nthis overhead budget. If the over\u00adhead for an origin is below originOverheadBudget, the sample rate is \nincrease (or left alone if the origin is already exhaustively tracked). When the controller sees that \ntotal overhead is too high, it reduces the originOverheadBudget, thus effectively reducing the sample \nfrequency only for origins that exceed this overhead threshold. The originOverheadBudget is always less \nthan or equal to the total overhead budget, but may be signi.cantly lower if there are a large number \nof origins. This approach is similar to [22] which uses inverse sam\u00adpling to avoid missing memory leaks \nin cold code.  5. QVM Clients In this section, we describe three clients built on top of the QVM platform. \nWe have implemented a number of clients in order to cover a range of user properties: ranging from local \nassertions to continuous monitoring using temporal safety properties. 5.1 Typestate In this section, \nwe show how QVM is used to dynamically check typestate properties. Typestate [36] is a framework for \nspecifying a class of temporal safety properties. Typestates can encode correct us\u00adage rules for many \ncommon libraries and application pro\u00adgramming interfaces (APIs). For example, typestate can ex\u00adpress \nthe property that a Java program should dispose a na\u00adtive resource before its Java object becomes unreachable \nand is collected by the garbage collector. * dispose* | else release*  initial * object death  Figure \n6. A typestate property tracking proper disposal of SWT resources. Names of tracked types are not shown. \nDynamic checking of typestate properties, as well as gen\u00aderalized multiple-object typestate (also known \nas .rst-order properties [34, 38]), have been addressed before in Trace\u00admatches [3] and MOP [12]. We \nuse the typestate client to demonstrate three contributions of our platform: (i) adap\u00adtive overhead management; \n(ii) timed typestate transitions; (iii) collection of additional detailed debug information with low \noverhead. Using the QVM platform to implement dynamic types\u00adtate checking also provides us with an advantage \nin getting object-death callbacks directly from the garbage collector and not relying on a .nalizer method \nto be called. This guar\u00adantees that object-death events are .red in a timely manner (which is not guaranteed \nto happen when using .nalizers) and allows us to measure resource-drag (see below) more precisely. QVM \nuses a simple input language to let the user specify a .nite-state automaton that represents the typestate \nprop\u00aderty, and the types to which it applies. We refer to a type that appears in at least one typestate \nproperty as a tracked type. Once the tracked type is speci.ed, our implementation instruments every object \nof this tracked type with additional information that maps the object to its typestate. During ex\u00adecution, \nQVM updates the typestate of each tracked object, and when an object reaches its error state, QVM records \nan error report (as the one shown in Fig. 1) in a designated log .le. EXAMPLE 5.1. Fig. 6 shows a typestate \nproperty (repre\u00adsented as a .nite state automaton) that identi.es when an SWT resource has not been disposed \nprior to its garbage collection, thus possibly leaking native resources such as GDI handles. The tracked \ntypes are not shown in the .gure, as this property applies to a large number of types (e.g., org/eclipse/swt/widgets/Widget). \nSince all states other than the designated error state are accepting, we sim\u00adplify notation by not using \na special notation for accepting states. We label edges of the .nite-state automaton with reg\u00adular expressions \nthat de.ne when the transition is taken. For example, the transition from undisposed to disposed occurs \nwhen invoking a method whose name begins with dispose or release. We use else to denote a transition \nthat is .red when no other transition from the state can be matched (note that the automaton is deterministic). \n 1 / 1 1 : Image.<init>(Device;InputStream;)V Image.<init>(Device;InputStream;)V 2 : IR.loadImage(ClassLoader;...)Image \n3 : IR.loadImage(Display;...)Image 1 / 1 1 : Image.init(Device;ImageData;)V Image.init(Device;ImageData;)V \n2 : Image.<init>(Device;InputStream;)V 3 : IR.loadImage(ClassLoader;...)Image;  1 / 1 1 : Image.createMask(ImageData;Z)I \nImage.createMask(ImageData;Z)I 2 : Image.init(Device;ImageData;)V 3 : Image.<init>(Device;InputStream;)V \n 1 / 1  1 : Image.getImageData()ImageData; 1 : Image.getBounds()Rectangle; 1 : Image.createMask()V 2 \n: BGT1.doPaint(Z)V 2 : CLabel.getTotalSize(Image;...)Point; 2 : GC.drawImageMask(Image;...)V 3 : BGT1.setGraphic(Image;)Z \n3 : CLabel.computeSize(IIZ)Point; 3 : GC.drawImage(Image;...)V Figure 7. An example typestate history \nfor a leaking Image in Azureus. For brevity, we only show sample contexts and omit the context for isDisposed. \nIn Section 7.1 we report experimental results for such properties. For every typestate property, QVM \ntracks the number of times it has been violated. When the number of violations passes a speci.ed threshold, \nQVM starts recording addi\u00adtional debugging information in the form of a typestate his\u00adtory. As mentioned \nin Section 2, a typestate history of an object o is an abstraction of the sequence of method invocations \nperformed during execution with o as a receiver. We use the name typestate history because we summarize \nthe sequence of method invocations as an annotated DFA, similar to a typestate property. Intuitively, \na state in the typestate history represents the state of the object after a speci.c method has been invoked \non it. A state in the history is labeled with a set of (bounded) contexts representing the contexts \nin which the method has been invoked. A transition between states m1 and m2 in the history represents \nthe fact that the method correspond\u00ading to m2 has been invoked immediately after the method corresponding \nto m1 has been invoked. A typestate history therefore provides information about the way a single object \nthat violates the property was used in the program. This helps the programmer to diagnose the cause of \nthe reported violation. EXAMPLE 5.2. Fig. 7 shows an example typestate his\u00adtory produced by QVM. This \nprovides an account of the behavior of a single object that violates the prop\u00aderty. In the .gure, we \nhave abbreviated the type name BufferedGraphicTableItem1 to BGT1, and the type name ImageRepository to \nIR. In .gures of typestate his\u00adtories we do not show method signatures on the edges be\u00adcause the label \nof an edge is always identical to the label of its target state. Unlike the simple typestate history \nof Fig. 2, the typestate history of Fig. 7 contains cycles and multiple invocations of methods. The label \non a transition edge represents the number of times this transition occurred in the execution and the \nlast time when it occurred. For example, the transition from the state in which createMask is the last \nmethod invoked on the object to the state in which isDisposed is the last method invoked on the object \noccurs 64 times in the execution summarized by the history of Fig. 7. The last time in which the transition \noccurred is 52, where time is measured as the number of allocations performed by the program. In the \n.gures, we show the time counter divided by 1024. Resource Drag and Lag Since QVM tracks the last time \neach transition took place, it can be used to identify when a resource is not released in a timely manner \n(known as re\u00adsource drag). In such cases it is sometimes possible to im\u00adprove performance by releasing \nthe resource earlier. Simi\u00adlarly, since QVM also tracks calls to constructors and object\u00addeath events, \nit can be used to identify when an object is al\u00ad canvas . addDisposeListener( new DisposeListener () \n{ @Override public void widgetDisposed( DisposeEvent arg0 ) { if (img != null &#38;&#38; !img.isDisposed()) \n{ assert ( QVM.isObjectOwned (img )); img. dispose (); } } } ); Figure 8. Using QVM to check that an \nSWT resource is not shared before attempting to dispose it. located too early (memory lag) or kept reachable \nfor a longer time than necessary (memory drag). Extensions Our current implementation supports single\u00adobject \ntypestate properties. In the future, we plan to inves\u00adtigate how our VM extensions can be combined with \ntech\u00adniques for handling multiple object typestates such as Trace\u00admatches [3] and MOP [12]. In some cases, \nstatic analysis (e.g., [19, 10]) can be used to verify that a typestate property is never violated, or \nthat some transitions of a typestate property never occur in a program. These static approaches can be \nused to reduce the runtime overhead by eliminating some of the dynamic checks. However, in practice, \nthe static approaches usually do not scale to the systems targeted by QVM.  5.2 Local Assertions To \nallow adjustment of overhead, we allow Java assertions to be sampled. This means that during execution, \nwe may sometime choose not to evaluate an assertion.  5.3 Heap Probes QVM enables the dynamic checking \nof various global heap properties such as object-sharing, heap-ownership, thread\u00adownership and reachability. \nThese properties are useful for both debugging and program understanding purposes. QVM provides a library \nthat exports a set of methods, one for each heap property. We refer to these library methods as heap \nprobes. The programmer can invoke heap probes from her program in order to inspect the shape of the heap \nat a program point. The library uses various components of the underlying runtime in order to obtain \nan answer. Our list of currently supported probes is shown in Table 2. In the table, We use TC(o) to \ndenote the set of all objects that are transitively reachable from o. Technically, o can refer to either \nan object or a thread. Similarly to non-heap probes, our heap-probes can be sampled by the overhead manager \nto allow adjustment of overhead, and can therefore evaluate to one of three possible values: true, false, \nand unknown. The return value of a heap\u00adprobe can be used in a standard Java assertion. When a heap probe \nis used inside an assertion we refer to it as a heap assertion. EXAMPLE 5.3. Disposal of SWT resources \nis based on two principles: (i) the object which allocated the resource is re\u00adsponsible for its disposal; \n(ii) disposing a parent object dis\u00adposes its children. These principles work well for many cases as a \nlarge number of the allocated resources are set to form immutable containment tree that guarantees proper \n(albeit not timely) disposal. However, the treatment of shared re\u00adsources such as Color, Fonts, and Images, \nis more compli\u00adcated and error prone. For shared resources, .nding the proper disposal point in the program \nmay be rather challenging. In particular, the disposal may be based on programmer knowledge of the last \nuse of the shared resource in the application. Fig. 8 shows how a QVM assertion can be used to check \nthat a resource is not shared by others, before it is being disposed. The code fragment shown here corresponds \nto a common idiom for disposing a resource by a dispose lis\u00adtener. This particular code fragment is taken \nfrom a .x we introduced for the Azureus benchmark as described in Sec\u00adtion 7.1. 5.3.1 Discussion and \nExtensions When assertions are not sampled, our approach is also ap\u00adplicable for reducing veri.cation \nefforts by adding runtime checks of heap properties. For example, establishing that parts of the heap \nare disjoint may allow us to employ more ef.cient veri.cation techniques that abstract each part sepa\u00adrately. \nThe heap operations supported by QVM could be ex\u00adtended to provide a comprehensive runtime support for \nown\u00adership (e.g., the releaseand captureoperations of [32]).  6. Implementation In this section we \nprovide the implementation details of object-centric sampling, as well as QVM clients of Sec\u00adtion 5. \n6.1 Object-Centric Sampling There are two key components to the ef.cient implementa\u00adtion of object-centric \nsampling. First is the ability to obtain a single free bit in the object header, to enable ef.cient check\u00ading \nof whether an object is tracked. Once identi.ed as a tracked object, QVM clients need the ability to \nassociate analysis data with an object. We implemented this in QVM by creating an OBJECTINFO for every \ntracked object. This ObjectInfo is then passed to the client on all object-related callbacks so the client \ncan lookup or store data associated with the object (such as DFA state, etc). The mapping from object \nto ObjectInfo is performed via a hashtable lookup. On allocation of an object, the correspond\u00ading ObjectInfo \nis created and inserted into the hashtable; on object death, they are removed. QVMI callbacks that require \naccess to the ObjectInfo obtain it by doing a hash lookup. Probe Name Description isHeap(Object o) Returns \ntrue if object o is pointed to by a heap object, false otherwise isShared(Object o) Returns true if object \no is pointed to by two or more heap objects, false otherwise isObjectOwned(Object o1 , Object o2 ) isObjectOwned(Object \no) Returns true if o1 dominates o2 , false otherwise Returns true if the object pointed to by thisdominates \no, false otherwise isThreadOwned(Thread ta, Object o) isThreadOwned(Object o) Returns true if ta dominates \no, false otherwise Returns true if the current thread dominates o, false otherwise isUniqueOwner(Object \nroot) Returns true if root dominates all objects in T C(root), false otherwise isReachable(Object src, \nObject dst) Returns true if object dst is reachable from object src, false otherwise Table 2. QVM heap \nprobes. We use TC(o) to denote the set of all objects that are transitively reachable from o. An alternate \nimplementation would be to reserve a word in the object header to point to the object s ObjectInfo. While \nthis provides faster lookup, it is not necessarily the supe\u00adrior design because it reduces locality by \nincreasing object size, and this overhead is regardless of the sample rate. A hashtable lookup is signi.cantly \nslower, but the hashtable lookup is performed only for sampled objects; the inlined fast path only checks \nthe tracked bit in the object header. So although the hashtable implementation is slower for tracked \nobjects, it allows a lower base overhead that converged upon when the sample rate is reduced. Because \nthe goal of QVM is to target low-overhead scenarios, the hashtable design was chosen.  6.2 Typestate \nClient Upon VM startup, the typestate module loads all of the user supplied properties, parses and stores \nthat information in its own internal data structures. The typestate module then reg\u00adisters itself with \nthe runtime via the QVMI.registerClient call. On method compilation, the QVMI interface is called by \nthe JIT via the isTrackedAllocand isTrackedCallSite functions to determine whether instrumentation is \nneeded for allocations and calls. These functions return a value of type TrackLevel. This type can take \non one of three totally or\u00addered values: NEVER (the minimal value), SOMETIMES and ALWAYS (the maximal \nvalue). All of the registered QVM clients are queried and the return result is computed by tak\u00ading the \nmaximal value from all of the client responses to ensure that suf.cient instrumentation is inserted. \nQVM then adjusts the instrumentation based on the track\u00ading level. If the tracking-level is ALWAYS or \nSOMETIMES, QVM instruments the code with a callback to report the event that occurred. In the case of \nSOMETIMES, QVM inserts inlined logic to decide (during execution) whether the call\u00adback gets invoked, \nIf the tracking-level is NEVER, no code instrumentation is performed by QVM for the site. For allocations \nsites marked with track level SOME-TIMES, the inlined sampling logic consults the sampling strategy for \nthat origin (see Section 4.2). If selected for sam\u00adpling, the typestate allocation handler is called \nvia the QVMI allocEvent call. The handler creates its internal QVM tracking structure for the allocated \nobject, and marks the ob\u00adject as tracked by setting a bit in the object header. Note that there could \nbe multiple tracking structures per-object (e.g. the object is part of multiple typestate properties). \n For method invocations tagged with SOMETIMES, the in\u00adlined code sequence checks whether the receiver \nis a tracked object by checking the tracked bit in the header. This check is executed even for inlined \nmethods to ensure that callbacks are not optimized away by the JIT. If the object s tracked bit is set, \nQVMI s invocationEvent is invoked which then calls the typestate invocation handler. The handler is passed \nthe receiver object, that object s OBJECTINFO, and the method that was invoked. This handler updates \nthe track\u00ading structure for each DFA the object participates in. In our implementation for typestate, \nwe have used the object-centric tracking and sampling capabilities provided by QVMI (Section 3.4) and \nhave inlined check of whether the object is tracked. This keeps overhead low by ensuring that QVMI is \ninvoked only for tracked (sampled) objects. There are many other such property speci.c optimizations \nthat can be made. For example, if we know that the tracked object is in an error state that will not \nbe exited, QVM does not need to invoke any other callbacks on this object. On Object Death We have instrumented \nthe garbage col\u00adlector to provide precise death events. Whenever an object is detected to be unreachable \nduring the sweep phase of the collector, the collector calls the QVMI s objectDeath function. That function \nleads to calling the typestate mod\u00adule s handler for death events, where all object tracking in\u00adformation \nis freed (if the object is tracked), ensuring no memory leakage. If the object is found to be in a non\u00adaccepting \nstate, an error is reported. 6.2.1 Collecting Typestate Histories In typestate histories, we use a notion \nof time to record when events occurred. We measure the time as the num\u00adber of allocations performed by \nthe program. To provide a scalable and ef.cient implementation of global clock, each thread maintains \na local allocation counter, and these are aggregated to a single global (approximate) time every 10 millisec. \nThe precision of the aggregate global clock can be adjusted by the user by changing the frequency of \naggrega\u00adtion operations (at the cost of a performance hit when using higher frequency). 6.2.2 Discussion \nAlthough the typestate module is written as part of the VM, it is completely isolated from the VM via \nthe QVMI in\u00adterface; this interface can be used to easily write clients to check properties other than \ntypestate. By having access to an unused bit in the object header bits, QVM is able to ef.\u00adciently perform \nobject-centric sampling without needing to store additional words in the object. Moreover, the ability \nto precisely intercept object death events frees us from having to rely on technique such as .nalizers \nand weak references.  6.3 Heap Probes In our platform, the underlying memory subsystem already provides \na stop the world mark and sweep, parallel garbage collector, where the number of parallel marker threads \nis pa\u00adrameterized by the number of cores in the system. This mem\u00adory system is highly tuned for performance \nand provides rich synchronization functionality for controlling the application and collector threads. \nInterestingly, such a setup, although complex, contains many of the basic components necessary to perform \nour probe evaluation. Hence, we implement our heap probes by re-using and adjusting at key places much \nof this existing machinery. Next we describe in more detail our heap probe evaluation system. Operation \nOn system startup, a set of evaluation threads Tm is created by the virtual machine, where |Tm| is the \nnumber of cores. After creation, each thread tm E Tm im\u00admediately blocks. Upon probe invocation, the \nsystem un\u00adblocks all evaluation threads and each tm starts executing the probe in question. At the abstract \nlevel, the basic exist\u00ading graph traversal components are shown in Fig. 9. Each component is parameterized \nby the evaluator thread tm. The function trace() performs the transitive closure from the set tm.pending. \nThe only addition we made to the standard par\u00adallel tracing phase is the callback trace-step, which is \n.red whenever a new reference is encountered. Each probe is free to specialize this function. The set \nTa denotes the set of application threads ta in the system at the time a probe is invoked. The function \nmark-thread() processes the contents of each application thread stack but does not trace from it. The \nfunction mark-object() marks the object if it is not al\u00adready marked atomically. If it is not marked, \nit stores the children of the object in the pending set of each evaluator thread. Since this is a local \noperation, it is done without syn\u00adchronization. The function barrier() essentially waits for all evaluation \nthreads tm to reach it and then releases them. To avoid clutter, we assume that all sets are initialized \nto 0 be\u00adfore invoking the probe. Probe is-shared Fig. 10 shows how the components of a parallel garbage \ncollector are used to implement the probe is-shared()for a tracked object trackedo. For this probe, trace(tm) \nwhile (tm.pending \u00d8= 0) remove s from tm.pending for each o E{v | (s, v) E E} trace-step(s, o) mark-object(tm,o) \nmark-object(tm,o) atomic if (o \u00d8E Marked) Marked . Marked U{o} else return tm.pending . tm.pending U{o} \nmark-thread(tm,ta) for each o E roots(ta) mark-object(tm,o) mark-threads(tm,T ) for each ta E T mark-thread(tm,ta) \nFigure 9. Basic Components is-shared(tm, trackedo) tm.sources = 0 mark-threads(tm,Ta) trace(tm) lock(allsources) \nallsources . allsources U tm.sources result .|allsources| > 1 unlock(allsources) barrier() trace-step(s, \nt) if (trackedo = t) tm.sources = tm.sources U{s} Figure 10. Shared from heap a special case needs to \nbe addressed in order to compute a sound result of the probe when heap traversal is done in par\u00adallel \n(such a case does not exist in the sequential traversal). The special case is the following: it is possible \nthat with par\u00adallel evaluator threads, two or more parallel evaluators tm reach object o only once. In \nthat case, we need to make sure to combine the results of all of the evaluator threads. Note that in \nthe case where a single evaluator reaches two or more source objects pointing to o, the probe will return \ntrue with\u00adout needing to inspect what other threads have reached. One solution is to synchronize the \nevaluator threads on every trace-step() (e.g. by using a compare-and-swap instruction for example). However, \non many processor ar\u00adchitectures this would have a negative effect on performance. To avoid this, each \nparallel thread records the set of sources pointing to o that it encounters in trace-step(). Note that \nthis is a local operation and requires no synchronization. Upon termination of its tracing phase each \ntm updates a global set allsources under a lock. If there is more than one ob\u00adject in that shared set, \nwe return true, otherwise we return false. For clarity of presentation we have omitted some im\u00adplementation \ndetails from the .gures. For example, in the implementation, both local and global (i.e. allsources) \nsets of sources are of size two and we stop recording sources once that size is reached for the local \nset in trace-step(). Next, before agreeing on a global value of result and return\u00ading, the threads again \nsynchronize via a call to barrier(). We have also omitted key portions of the runtime system such as \nload-balancing, a key technique in parallel collectors. Such techniques are completely orthogonal to \nour implementation and can be added without affecting the code for the probe evaluation. 6.3.1 Optimizations \nWe are currently working on various optimizations to our system including evaluating multiple probes \nin parallel, con\u00adcurrent evaluation of probes and heuristic optimizations via write barriers with techniques \nsimilar to those described in [33]. Such an optimized implementation of heap probes and its evaluation \nremains a topic of future work.   7. Experimental Evaluation In this section we experimentally evaluate \nQVM. 7.1 Typestate Monitoring 7.1.1 Methodology In our experiments we focused on typestate properties \nthat correspond to resource leaks. We monitor leaks of SWT re\u00adsources and of IO streams. In these experiments \nthe goal was to see if we can detect typestate violations that occur over an extended period of time. \nIt is likely that massive leaks would have been detected and .xed in the testing phase, and there\u00adfore \nwhat we expect to .nd in these experiments is mostly a small number of leaks that accumulate over time. \nFor that purpose, we used a range of applications on a regular basis to perform our daily tasks. Some \nof the applications considered are an instant\u00admessenger (goim), newsfeed readers (feednread, rssowl), \n.le management utilities (virgoftp, jcommander), large IBM internal applications, etc. For all of these \napplications our strategy was to simply run them over QVM and record the reported errors. In some of \nour experiments we investigated each report manually, diagnosed the causes of the errors, and implement \n.xes. This was an important exercise for evaluat\u00ading and re.ning the debug information we collect (e.g., \nthe typestate history). Application azureus etrader feednread goim ibm app 1 ibm app 2 jcommander juploader \nnomadpim rssowl tvbrowser tvla virgoftp Total SWT Resources 11 17 1 3 0 3 9 0 2 8 0 0 6 60 IOStreams \nHigh Fixed Frequency 0 45 0 20 7 00 0 13 0 00 2 00 0 00 1 00 0 00 3 00 5 00 4 00 0 06 22 714 Table 3. \nSources of typestate violations in our application For every application, we indicate the number of sources \nthat are executed in a high-frequency (corresponding to critical leaks). 7.1.2 Applications and Results \nTable 3 summarizes the number of sources of typestate vio\u00adlations found in our applications. Rather than \ncounting the number of objects that violate the property, we count the allocation sites in which such \nobjects were allocated. This is a more objective measure of the number of bugs in the program than the \nnumber of objects exhibiting the violation which usually depends on the duration of program execu\u00adtion. \nIn order to measure the signi.cance of a violation, we record whether it occurs frequently in the program \nexecu\u00adtion. In some of our experiments we took the effort to inves\u00adtigate the errors and come up with \nappropriate .xes. Column .xed in the table reports the number of .xes we have intro\u00adduced and tested. \nAzureus Azureus [8] is a Java implementation of the Bit-Torrent protocol. It supports several modes of \nuser interac\u00adtion, all implemented using SWT. Azureus is the #1 down\u00adloaded Java program from SourceForge, \nand has more than 160 million downloads to date. Using QVM we were able to detect 11 sources of resource \nleaks in this application. We .xed 5 of these and reported them to the Azureus develop\u00adment team. The \nreports were con.rmed by the development team, and the .xes were incorporated into the codebase. At least \n4 of the reports correspond to leaks that were occurring rather frequently. One particularly high-frequency \ncase was a method Utils.getFontHeightFromPX(...) that was allocating a Font object in order to compute \nfont height and was not properly disposing the Fontobject upon its return. This method is frequently \ncalled and resulted with thousands of leaking fonts even for short executions. This method was very likely \ncreated by copying another method in the class that has similar functionality but returns the Fontobject. \nAmong our other .xes, we .xed the frequently leaking method getFontHeightFromPX(...)and our .x was incorporated \ninto the Azureus codebase. Another .x in Azureus required the addition of a dispose listener that properly \ndisposes of an Imageobject. This leak was not very frequent, but it would leak an image whenever a certain \npanel would be displayed (image is created in the VivaldiPanel.refreshContacts(...)method). Eclipse Trader \neclipseTrader is an SWT application that provides a framework for building an online stock trad\u00ading system. \neclipseTrader uses a frequently-updating UI to present streams of stock information, and as a result \nmay be particulary sensitive to resource leaks. Using QVM, we detected 17 sources of resource leaks. \nOur count of violation sources represents a lower bound on the number of places that have to be modi.ed \nfor in\u00adtroducing a .x. This is in part due to the fact that we are counting the number of allocation \nsites and not the alloca\u00adtion sites in context. When a common method (such as a factory method) is used \nto create objects that violate a prop\u00aderty in many contexts, we only count this as a single vio\u00adlation. \nSpeci.cally, for eclipseTrader, there are several allo\u00adcation sites that are used in different contexts. \nFor example, the method Settings.getColor(Color) returns a new Colorobject, and is used in a large number \nof contexts that fail to properly dispose the color. We count this method as a single violation source \nthat occurs with high frequency (there are tens of thousands leaking objects that are allo\u00adcated in this \nmethod in a typical execution of eclipsetrader). In general, counting the number of violation sources \nhas to be done carefully as the sources are not necessarily indepen\u00addent. For example. a whole sub-tree \nof components may leak due to a single missing dispose operation on the parent of the tree. Feed N Read \nfeednread is an open source newsfeed reader. In this news reader, the SWT resources are mostly properly \nmanaged. There are some resources that are not disposed before the program exits, but these are resources \nthat are supposed to be live throughout program execution by design. Although QVM reports these as violations, \nwe do not count them here as violation sources because this seems to be acceptable treatment of such \nresources (resources will be returned to the OS anyway when the application terminates). feednread seems \nto have some minor problems in properly closing IO streams when managing archived feeds. GOIM GOIM [1] \nis an Instant Messaging client based on the open source Jabber/XMPP protocol. We used GOIM run\u00adning on \nQVM to communicate between team members for a few days. Over the course of our evaluation, we detected \n3 sources of leaks and introduced .xes to all of them. We tested our .xed version of GOIM and con.rmed \nthat all pre\u00adviously reported leaks have been resolved. The .xes we introduced in GOIM were rather involved \nas we had to add new disposal code in places where no such code existed. Our .xes therefore involved \nintroducing new dispose methods as well as making sure that calls to these methods are propagated properly. \n IBM Applications We used QVM to run a development version of a large scale IBM product on a daily basis \nfor a period of a few weeks. For this application, no problems were reported by QVM. This is not surprising \nas the devel\u00adopment team is putting a lot of emphasis on preventing the kind of leaks we are tracking. \nWe used QVM to run a development version of another smaller IBM tool that makes heavy use of SWT. For \nthis application, we found 5 source of violations. The leaks are associated with user actions like opening \na new .le. JCommander JCommander is a multi-platform .le man\u00adager. For this application we found 9 sources \nof violations. JUploader JUploader is a small application that uploads images to Flickr. Its UI is very \nbasic and only involves a few SWT resources. For this application we found a single source of leaks causing \nthe rather frequent leak of EventOutputStreamobjects. Nomad PIM Nomad PIM is a personal information man\u00adager. \nIt has a rather involved SWT interface. For nomad we found 2 sources of violations. RSS Owl RSSOwl is \nan RSS newsreader. Running RSSOwl on QVM, we .nd 8 sources of SWT leaks and 3 sources of IO Streams leaks. \nTV Browser TV Browser is na electronic program guide. For this application we found 5 sources of leaking \nstreams. TVLA TVLA [26] is a parametric program analysis frame\u00adwork. Running TVLA with QVM we .nd two \ninput streams that are not closed by the parser processing input .les, and two streams that are not closed \nwhen producing the analysis output. These are very low frequency leaks that only create one leaking object \nper execution of the analysis engine. VirgoFtp VirgoFTP is a multi-platform, graphical FTP client written \nin Java using SWT. For this application QVM reported 6 sources of leaks. We introduced .xes to all of \nthese leaks, and tested that the .xed version resolves them. One source of a low-frequency leak in VirgoFTP \nis a typical pattern that repeats across many SWT applications. Changing the color/font preferences in \nan application often causes the leak of the previous colors/fonts used. These kind of leaks occur in \nsuch a low frequency that programmers are very likely choosing to ignore disposal of resources in this \ncase. Fixing this simple problem in VirgoFTP was rather complicated because the code was completely non-prepared \nfor handling these leaks. In order to .x these leaks we had to employ a rather signi.cant refactoring \nof the code. 7.1.3 Overhead Evaluation Methodology For overhead measurements we use the SPECjvm98 and \nDacapo benchmark suites.1 The bench\u00admarks were con.gured to run for roughly one minute to create a reasonable \nusage scenario, and total time was mea\u00adsured. 20 runs of each benchmark were used to reduce noise. We \ncreated a set of representative typestate properties that incur a signi.cant overhead. We instrumented \nclasses such as Java Collections, Enumerations, Vectors, and Streams. Results Figure 11 reports the overhead \nof the typestate monitoring client when applied to our benchmarks suite with a range of overhead budgets \n(5%, 10%, and 20%). The right\u00admost bar for each benchmark shows the overhead when the typestate client \nis applied exhaustively, ie, without sampling. The leftmost bar shows the base overhead (as described \nin which represents the base checking overhead that is incurred when no sampling takes place (see Section \n4.1). The overhead incurred when checking these typestate properties exhaustively is high (up to 10x \nslowdown, with 7 of the benchmarks over 2x slowdown). Heavyweight prop\u00aderties that introduce frequent \ncallbacks were selected inten\u00adtionally to allow us to evaluate the effectiveness of the sam\u00adpling infrastructure. \nThe base overhead (leftmost bar) is low, at most 2.5%. Having the base overhead be low is critical, as \nthis is the overhead that is the lowest overhead that can be achieved when sampling is disabled. The \nmiddle three bars show overhead incurred when QVM was run with a speci.c overhead budget. Although there \nis some .uctuation in the overhead achieved, it is gen\u00aderally quite close to the requested budget. Achieving \nac\u00adcuracy at this level is quite challenging because the whole process takes place online and within \na single execution of the benchmark. These results demonstrate not only the over\u00adhead monitor s ability \nto measure the overhead introduced, but the overhead controller s ability to keep the overhead close \nto the desired budget. Figure 12 shows an example of the overhead manager adapting the overhead of the \ntypestate client online for the javac benchmark and a 10% overhead budget. The x\u00adaxis shows time in seconds, \nand the y-axis shows percent overhead, as measured online by the QVM overhead mon\u00aditor. The spike around \n0.5 seconds occurs because there is some lag before the overhead monitor can react and reduce the sample \nrates. However, once the controller throttles the tagged objects at the hot allocation sites the overhead \ncon\u00adverges on the desired budget of 10%. The goal of QVM is not just to have low overhead, but to collect \nas much useful information as possible within the overhead budget. The sampling strategy employed by \nthe overhead manager (see Section 4.2) strives to distribute the 1 Jython and xalan were excluded from \nthe study because they do not run properly on the developmental version of the VM used for this work \n(independent of the QVM modi.cations).  samples across the allocation sites in the program, to help \n.nd bugs that may occur in cold code. Figure 13 compares the coverage of allocations sites achieved with \n5% budget when using origin-speci.c sampling, as well as global sam\u00adpling, where all sites are sampled \nequally. Origin-speci.c sampling enables nearly 100% coverage for all benchmarks, while global sampling \nmisses a signi.cant percentage of the allocation sites for at least half of the benchmarks. QVM is using \nsampling to reduce overhead so there is no expectation that all objects will be tracked, however in many \ncases the sampling mechanism allows the dynamic number of tracked objects to be signi.cantly higher than \none might anticipate. Table 4 reports the percent of objects allocated (of the tracked types) that are \nsampled to be tracked by the typestate monitor. Consider the program javac. Previously in Figure 11 we \nsaw that our example set of typestate properties introduces Overhead Budget Benchmark 1% 2% 5% 10% 20% \n50% 100% db 100 100 100 100 100 100 100 mpegaudio 98 100 100 100 100 100 100 jess 63 76 85 87 95 100 \n100 jack 22 37 45 52 71 100 100 javac 0.4 1 4 9 31 41 49 compress 100 100 100 100 100 100 100 mtrt 39 \n46 66 83 90 93 94 antlr 13 19 34 68 67 92 98 eclipse 4 7 12 28 44 66 67 luindex 5 51 79 97 99 99 100 \nhsqldb 7 13 16 30 43 31 75 chart 40 64 85 88 93 94 97 fop 47 70 42 66 100 100 100 bloat 100 100 100 100 \n100 100 100 pmd 81 99 99 99 99 100 100      Table 4. Object Coverage: Percent of allocated objects \n(of tracked types) that are selected by QVM for typestate moni\u00adtoring. overhead of around 970% when checked \nexhaustively. How\u00adever, Table 4 shows that with an overhead budget of 100% slowdown (more than a factor \nof 9 less than the exhaustive slowdown) 49% of the objects allocated (of tracked types) were still selected \nfor tracking. This can be explained when a relatively small number of objects contribute signi.cantly \nto the overhead; once sampling at these sites is throttled, the number of remaining allocations that \ncan be tracked within the overhead budget may be large. Some benchmarks (db, compress, bloat) report \n100% for all overhead budgets because their exhaustive overhead for the typestate properties we selected \nis below 1% (see Fig\u00adure 11).  7.1.4 Discussion Wrapper Streams For a large number of applications QVM \nreports violations of stream types that do not hold real resources but violate the contract of the InputStream \nand OutputStream API speci.cation. An example that is widely reported by QVM is the LEDataInputStream \nfrom the package swt.internal.image. This stream is a wrapper around an InputStream and is often not \nclosed because closing the wrapper closes the underlying Input-Stream. In many cases, the underlying \nstream outlives the wrapper stream and is therefore closed directly without ever invoking close()on the \nwrapper stream. In addition, streams such as ByteArrayInputStream and ByteArrayOutputStreamare simply \nwrappers around a byte array. Invoking close on such streams has no effect (although it is required by \nthe streams API in principle), and programmers therefore avoid this redundant method call. We do not \nconsider these to be real violations and do not include them in our QVM reports. Library Objects vs. \nApplication Objects Our initial speci\u00ad.cation for SWT resources was not the one shown in Fig. 6. Our \ninitial speci.cation required that dispose() be in\u00advoked on every SWT Widget, as this is the public method \nthat an application code can invoke to dispose a resource. However, in SWT, widgets are arranged into \nan ownership structure in which a widget may have a parent that is respon\u00adsible for its disposal. When \nthe parent is disposed, it dis\u00adposes all of its children, but instead of invoking the (public) method \ndispose to do so, it directly calls the (protected) internal method release. We therefore had to re.ne \nour speci.cation to be aware of the internal library implementa\u00adtion and the fact that an SWT widget \ncould be also released by an invocation of releasethat originates in library code. Additional re.nement \nof the speci.cation is required to avoid objects that are allocated in the library for internal library \nuse, and their lifetime is not managed (and should not be managed) by the application. For example, Font \nobjects allocated by the static method Font.gtk new()are managed by the library.  7.2 Assertions and \nHeap Probes Evaluating local assertions and heap probes on realistic benchmarks is a nontrivial task, \nas it requires that we de\u00advise meaningful assertions for each benchmark. Currently, we evaluated assertions \nand heap probes on a number of synthetic benchmarks and demonstrated that the overhead manager works \nas expected for these benchmarks. Since these are synthetic benchmarks, the measured numbers are rather \narbitrary and we therefore do not report them here. We have also evaluated heap probes in a single bench\u00admark \n SPECJbb2005. For this benchmark, heap probes were inserted on fairly frequently executed instructions, \nthus when run exhaustively caused signi.cant slowdowns (on the order of 100x). However, when running \nthe system with an overhead budget of 10%, the overhead manager success\u00adfully achieved an overhead of \n10.5% by sampling the heap probes. Furthermore, with 10% overhead, QVM provided 100% coverage of the \nprobe sites.  8. Related Work Aspects and Monitoring Dynamic tools such as Trace\u00admatches [3], and MOP \n[12] are able to detect violation of typestate properties, and in particular detect resource leaks. For \nexample, in [12], JavaMOP was used to successfully de\u00adtect a number of resource leaks in Eclipse. These \ntools ex\u00adtend aspect-oriented programming with the ability to specify declarative patterns against the \nhistory of the program, rather than against single events as in traditional aspects. Optimiz\u00ading the \nperformance of code generated from these declara\u00adtive speci.cations is a challenging task and is currently \nan active area of research. In [7], the authors concentrate on dy\u00adnamic optimizations that only consider \nthe speci.ed declara\u00adtive pattern and not the program on which it is applied. Such optimizations include \navoidance of memory leaks and bet\u00adter representation of the typestate automata. Alternatively, in [10], \nthe authors take the program into account and per\u00adform static optimizations, e.g., removing unnecessary \ninstru\u00admentation points from the program. Unfortunately, despite these optimizations, there are cases \nwhere the overhead is still unacceptable for some properties. In [9], the authors propose two techniques: \nspatial and temporal partitioning. In the .rst optimization, assuming multiple users of the ap\u00adplication, \nthe instrumentation points are partitioned into sets optimizing the per-user overhead. However, it is \nstill possi\u00adble to partition the points in a way that some set has a hot point. The second optimization \nspawns a monitoring thread which can switch the instrumentation on and off at various times. The intervals \nde.ning when the point should be on or off are predetermined off-line and given to the thread as pa\u00adrameter. \nIt seems that our approach of automatically adjust\u00ading the overhead online for a particular set of control \nsites will be bene.cial to the second optimization. Sampling for Scalable Monitoring Previous work has \nfo\u00adcused on low overhead techniques for sampling instrumenta\u00adtion [4] and collecting such pro.les in \nbursts [14]. However these techniques turn sampling on and off based on time or code execution frequency, \nand do not support a technique such as our object-centric sampling. In the cooperative bug isolation \n(CBI) project [27], the overhead of monitoring program execution is mitigated by using sparse random \nsampling and collecting information from a large number of users exercising the code. Collabora\u00adtive \ntechniques could be combined into QVM to collect ap\u00adplication errors from a wider group of users. We \nbelieve that the ubiquity of QVM provides a natural channel for wider adoption of CBI-based techniques. \nTypestate Veri.cation and Static Leak Detection A num\u00adber of sound static tools target detection or prevention \nof memory and resource leaks [23, 15, 16, 21, 19, 35]. Some tools speci.cally target detection of SWT \nresource leaks [28], and others target automatic generation of resource management code [17]. In principle, \nmost of these ap\u00adproaches are capable of detecting cases where an object is leaked or double disposed. \nIn practice, however, these approaches do not scale to industrial-sized applications, and produce a large \npercentage of false alarms. In addition, some of these approaches either require additional (potentially \ncumbersome) annotations or restrict the class of programs that may be written, e.g. by restricting aliasing \n[15, 21]. Heap Properties Mitchell [30] provides concise and in\u00adformative summaries of real world heap \ngraphs arising in production applications. The summaries are done of.ine and follow a set of useful heuristical \npatterns for summarizing graphs. In contrast, our goal is to check various user spec\u00adi.ed heap properties \nonline. Subsequent work by Mitchell and Sevitsky [31] study of.ine heap snapshots with the goal of .nding \ninef.ciencies in memory usage enforced by a par\u00adticular program design. Chilimbi et. al. [13] provide \na two-stage framework suit\u00adable for testing, where in the .rst stage a set of likely heap invariants \nbased on node degree are computed at a small number of program points. Then the instrumented program \nis executed and checked against these invariants and a bug is reported if a deviation is observed. Various \nworks have relied on the garbage collector to .nd memory leaks. Jump et al. [24] use the collector to \nhelp in suggesting potential leaks. Bond et al. [11] studies ef.cient leak detection for Java. Similarly \nto us, they make use of available bits in the object header and the adaptive pro.ling techniques from \n[22] applied on object use sites, in order to reduce the space and time overheads. We see these advances \nas potential QVM clients, which could manage the overall overhead for them. In a recent paper by Aftandilian \net al. [2], the authors suggest the idea of piggybacking on an existing garbage collector in order to \ncheck various heap properties. They propose two of the assertions we consider here, namely isShared and \nisObjectOwned, but have not implemented these assertions and hence have not had the chance to study the \nwide class of applications we have in order to see where and how the assertions are practically used. \n9. Future Work The overhead manager stands at the basis of QVM. Our current implementation uses simple \nstrategies that work well in practice, but do not guarantee any sort of optimality or enforce provable \nbounds. In the future, we plan to investigate how techniques from control theory can be used to provide \na robust theoretical foundation for the overhead manager. While our preliminary experience with heap \nassertions is promising, a thorough evaluation of these assertions is required on two aspects: (i) the \nappeal of heap assertions to programmers; (ii) the performance impact of heap assertions written in practice. \nWe plan to address these questions in future work. 10. Acknowledgments We would like to thank Joshua \nAuerbach for his helpful discussions on tracking overhead using per-thread metrics.  References [1] \nGOIM: Gamers own instant messenger. available at http://goim.us/wiki/show/GOIM. [2] AFTANDILIAN, E., \nAND GUYER, S. Z. GC assertions: Using the garbage collector to check heap properties. In MSPC (2008), \nACM. [3] ALLAN, C., AVGUSTINOV, P., CHRISTENSEN, A. S., HENDREN, L., KUZINS, S., LHOT \u00b4 AK, O., DE MOOR, \nO., SERENI, D., SITTAMPALAM, G., AND TIBBLE, J. Adding trace matching with free variables to aspectj. \nIn OOPSLA 05: Proceedings of the 20th annual ACM SIGPLAN conference on Object oriented programming, systems, \nlanguages, and applications (2005), ACM, pp. 345 364. [4] ARNOLD, M., AND RYDER, B. G. A framework for \nreducing the cost of instrumented code. In PLDI 01: Proceedings of the ACM SIGPLAN 2001 conference on \nProgramming language design and implementation (New York, NY, USA, 2001), ACM, pp. 168 179. [5] ARNOLD, \nM., AND RYDER, B. G. Thin guards: A simple and effective technique for reducing the penalty of dynamic \nclass loading. In Proceedings of the Sixteenth European Conference on Object-Oriented Programming (M\u00b4alaga, \nSpain, June 2002), B. Magnusson, Ed., vol. 2374 of Lecture Notes in Computer Science, pp. 498 524. [6] \nAUERBACH, J., BACON, D., CHENG, P., GROVE, D., BIRON, B., GRACIE, C., MCCLOSKEY, B., MICIC, A., AND SCIAMPACONE, \nR. Tax-and-Spend: Democratic Scheduling for Real-time Garbage Collection. In Proceedings of the International \nConference on Embedded Software (New York, NY, USA, 2008), ACM. [7] AVGUSTINOV, P., TIBBLE, J., AND \nDE MOOR, O. Making trace monitors feasible. In OOPSLA 07: Proceedings of the 22nd annual ACM SIGPLAN \nconference on Object oriented programming systems and applications (2007), ACM, pp. 589 608. [8] Azureus \n-Java BitTorrent client. http://azureus.sourceforge.net/. [9] BODDEN, E., HENDREN, L. J., LAM, P., LHOT \n\u00b4AK, O., AND NAEEM, N. A. Collaborative runtime veri.cation with tracematches. In 7th International Workshop \non Runtime Veri.cation (RV) (2007), vol. 4839 of Lecture Notes in Computer Science, pp. 9 21. [10] BODDEN, \nE., HENDREN, L. J., AND LHOT \u00b4AAK, O. staged static program analysis to improve the performance of runtime \nmonitoring. In ECOOP (2007), pp. 525 549. [11] BOND, M. D., AND MCKINLEY, K. S. Bell: bit-encoding online \nmemory leak detection. SIGOPS Oper. Syst. Rev. 40, 5 (2006), 61 72. [12] CHEN, F., AND ROS\u00b8U, G. MOP: \nAn Ef.cient and Generic Runtime Veri.cation Framework. In Object-Oriented Programming, Systems, Languages \nand Applica-tions(OOPSLA 07) (2007). [13] CHILIMBI, T. M., AND GANAPATHY, V. Heapmd: identify\u00ading heap-based \nbugs using anomaly detection. vol. 34, ACM, pp. 219 228. [14] CHILIMBI, T. M., AND HIRZEL, M. Dynamic \nhot data stream prefetching for general-purpose programs. In PLDI 02: Proceedings of the ACM SIGPLAN \n2002 Conference on Programming language design and implementation (New York, NY, USA, 2002), ACM, pp. \n199 209. [15] DELINE, R., AND FAHNDRICH, M. Enforcing high-level protocols in low-level software. In \nPLDI 01: Proceedings of the ACM SIGPLAN 2001 conference on Programming language design and implementation \n(New York, NY, USA, 2001), ACM Press, pp. 59 69. [16] DELINE, R., AND F\u00a8AHNDRICH, M. Adoption and focus: \nPractical linear types for imperative programming. pp. 13 24. [17] DILLIG, I., DILLIG, T., YAHAV, E., \nAND CHANDRA, S. The closer: Automating resource management in java. In ISMM (2008). [18] ECLIPSE. Standard \nwidget toolkit (swt). http://www.eclipse.org/swt/. [19] FINK, S., YAHAV, E., DOR, N., RAMALINGAM, G., \nAND GEAY, E. Effective typestate veri.cation in the presence of aliasing. In ISSTA 06: Proceedings of \nthe 2006 international symposium on Software testing and analysis (New York, NY, USA, 2006), ACM Press, \npp. 133 144. [20] FINK, S. J., AND QIAN, F. Design, implementation and evaluation of adaptive recompilation \nwith on-stack replace\u00adment. In International Symposium on Code Generation and Optimization (CGO 2003) \n(2003), pp. 241 252. [21] FOSTER, J. S., TERAUCHI, T., AND AIKEN, A. Flow\u00adsensitive type quali.ers. pp. \n1 12. [22] HAUSWIRTH, M., AND CHILIMBI, T. M. Low-overhead memory leak detection using adaptive statistical \npro.ling. SIGPLAN Not. 39, 11 (2004), 156 164. [23] HEINE, D. L., AND LAM, M. S. A practical .ow\u00adsensitive \nand context-sensitive c and c++ memory leak detector. In PLDI 03: Proceedings of the ACM SIGPLAN 2003 \nconference on Programming language design and implementation (New York, NY, USA, 2003), ACM, pp. 168 \n181. [24] JUMP, M., AND MCKINLEY, K. S. Cork: dynamic memory leak detection for garbage-collected languages. \nSIGPLAN Not. 42, 1 (2007), 31 38. [25] LAU, J., ARNOLD, M., HIND, M., AND CALDER, B. Online performance \nauditing: using hot optimizations without getting burned. SIGPLAN Not. 41, 6 (2006), 239 251. [26] LEV-AMI, \nT., AND SAGIV, M. TVLA: A framework for Kleene based static analysis. In Saskatchewan (2000), vol. 1824 \nof Lecture Notes in Computer Science, Springer-Verlag, pp. 280 301. [27] LIBLIT, B. Cooperative Bug Isolation \n(Winning Thesis of the 2005 ACM Doctoral Dissertation Competition), vol. 4440 of Lecture Notes in Computer \nScience. Springer, 2007. [28] LIVSHITS, V. B. Turning Eclipse against itself: Finding bugs in Eclipse \ncode using lightweight static analysis. Eclipsecon 05 Research Exchange, Mar. 2005. [29] MICROSYSTEMS, \nS. Jvmtm tool interface, version 1.0. In http://java.sun.com/j2se/1.5.0/docs/guide/jvmti/jvmti.html. \n[30] MITCHELL, N. The runtime structure of object ownership. In ECOOP (2006), D. Thomas, Ed., vol. 4067 \nof Lecture Notes in Computer Science, Springer, pp. 74 98. [31] MITCHELL, N., AND SEVITSKY, G. The causes \nof bloat, the limits of health. In OOPSLA 07: Proceedings of the 22nd annual ACM SIGPLAN conference on \nObject oriented programming systems and applications (2007), pp. 245 260. [32] M \u00a8Ownership transfer \nin ULLER, P., AND RUDICH, A. universe types. In OOPSLA 07: Proceedings of the 22nd annual ACM SIGPLAN \nconference on Object oriented programming systems and applications (New York, NY, USA, 2007), ACM, pp. \n461 478. [33] QIAN, F., AND HENDREN, L. An adaptive, region-based allocator for java. In Proceedings \nof the third international symposium on Memory management (Jun 2002), ACM Press, pp. 127 138. [34] RAMALINGAM, \nG., WARSHAVSKY, A., FIELD, J., GOYAL, D., AND SAGIV, M. Deriving specialized program analyses for certifying \ncomponent-client conformance. In PLDI 02: Proceedings of the ACM SIGPLAN 2002 Conference on Programming \nlanguage design and implementation (New York, NY, USA, 2002), ACM, pp. 83 94. [35] SHAHAM, R., YAHAV, \nE., KOLODNER, E., AND SAGIV, M. Establishing local temporal heap safety properties with applications \nto compile-time memory management. In Static Analysis Symposium (2003). [36] STROM, R. E., AND YEMINI, \nS. Typestate: A programming language concept for enhancing software reliability. IEEE Trans. Software \nEng. 12, 1 (1986), 157 171. [37] SUGANUMA, T., YASUE, T., KAWAHITO, M., KOMATSU, H., AND NAKATANI, T. \nA dynamic optimization framework for a Java just-in-time compiler. In OOPSLA 01: Pro\u00adceedings of the \n16th ACM SIGPLAN conference on Object oriented programming, systems, languages, and applications (New \nYork, NY, USA, 2001), ACM, pp. 180 195. [38] YAHAV, E., AND RAMALINGAM, G. Verifying safety properties \nusing separation and heterogeneous abstractions. In Proceedings of the ACM SIGPLAN 2004 conference on \nProgramming language design and implementation (2004), ACM Press, pp. 25 34. \n\t\t\t", "proc_id": "1449764", "abstract": "<p>Coping with software defects that occur in the post-deployment stage is a challenging problem: bugs may occur only when the system uses a specific configuration and only under certain usage scenarios. Nevertheless, halting production systems until the bug is tracked and fixed is often impossible. Thus, developers have to try to reproduce the bug in laboratory conditions. Often the reproduction of the bug consists of the lion share of the debugging effort.</p> <p>In this paper we suggest an approach to address the aforementioned problem by using a specialized runtime environment (QVM, for <i>Quality Virtual Machine</i>). QVM efficiently detects defects by continuously monitoring the execution of the application in a production setting. QVM enables the efficient checking of violations of user-specified correctness properties, e.g., typestate safety properties, Java assertions, and heap properties pertaining to ownership.</p> <p>QVM is markedly different from existing techniques for continuous monitoring by using a novel overhead manager which enforces a user-specified overhead budget for quality checks. Existing tools for error detection in the field usually disrupt the operation of the deployed system. QVM, on the other hand, provides a balanced trade off between the cost of the monitoring process and the maintenance of sufficient accuracy for detecting defects. Specifically, the overhead cost of using QVM instead of a standard JVM, is low enough to be acceptable in production environments.</p> <p>We implemented QVM on top of IBM's J9 Java Virtual Machine and used it to detect and fix various errors in real-world applications.</p>", "authors": [{"name": "Matthew Arnold", "author_profile_id": "81100021720", "affiliation": "IBM TJ Watson Research Center, Hawthorne, NY, USA", "person_id": "P1223164", "email_address": "", "orcid_id": ""}, {"name": "Martin Vechev", "author_profile_id": "81100269652", "affiliation": "IBM TJ Watson Research Center, Hawthorne, NY, USA", "person_id": "P1223165", "email_address": "", "orcid_id": ""}, {"name": "Eran Yahav", "author_profile_id": "81100285431", "affiliation": "IBM TJ Watson Research Center, Hawthorne, NY, USA", "person_id": "P1223166", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449776", "year": "2008", "article_id": "1449776", "conference": "OOPSLA", "title": "QVM: an efficient runtime for detecting defects in deployed systems", "url": "http://dl.acm.org/citation.cfm?id=1449776"}