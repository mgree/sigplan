{"article_publication_date": "10-19-2008", "fulltext": "\n Dynamic Optimizationfor Ef.cient Strong Atomicity Florian T. Schneider Vijay Menon Tatiana Shpeisman \nDepartment of Computer Science Google Ali-Reza Adl-Tabatabai ETH Zurich, Switzerland Seattle, WA98103 \nIntel Corporation .orian.schneider@inf.ethz.ch vsm@acm.org Santa Clara, CA 95054 {tatiana.shpeisman,ali-reza.adl\u00adtabatabai}@intel.com \nAbstract Transactional memory (TM) is a promising concurrency control alternative to locks. Recent work \n[30, 1, 25, 26] has highlighted important memory model issues regarding TM semantics and exposed problems \nin existing TM implemen\u00adtations.For safe, managed languages such asJava, thereisa growing consensus towards \nstrong atomicity semantics as a sound, scalable solution. Strong atomicity has presented a challenge \nto imple\u00adment ef.ciently because it requires instrumentation of non\u00adtransactional memory accesses, incurring \nsigni.cant over\u00adhead even when a program makes minimal or no use of transactions. To minimize overhead, \nexisting solutions re\u00adquire either a sophisticated type system, specialized hard\u00adware, or static whole-program \nanalysis. These techniques do not translate easily into a production setting on existing hardware. In \nthis paper, we present novel dynamic optimizations that signi.cantly reduce strong atomicity overheads \nand make strong atomicity practical for dynamic language en\u00advironments.We introduce analyses that optimistically \ntrack which non-transactional memory accesses can avoid strong atomicity instrumentation, and we describe \na lightweight speculation and recovery mechanism that applies these anal\u00adyses to generate speculatively-optimized \nbut safe code for strong atomicityina dynamically-loaded environment.We show how to implement these mechanisms \nef.ciently by leveraging existing dynamic optimization infrastructure in a Java system. Measurements \non a set of transactional and non-transactional Java workloads demonstrate that our tech\u00adniques substantially \nreduce the overhead of strong atomicity Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage.To copyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. OOPSLA 08, October 19 23, 2008, Nashville,Tennessee, USA. Copyright c &#38;#169; \n2008ACM 978-1-60558-215-3/08/10... $5.00 from a factor of 5x down to 10% or less over an ef.cient weak \natomicity baseline. Categories and Subject Descriptors D.1.3[Programming techniques]: Concurrent Programming \nParallel Program\u00adming; D.3.4[Programming Languages]:Processors Code generation, Compilers, Optimization, \nRun-time environ\u00adments General Terms Algorithms, Design, Experimentation, Lan\u00adguages, Measurement, Performance \n1. Introduction Transactional memory (TM) [18] has been suggested as an alternative to lock-based synchronization. \nLocks place many burdens on the programmer: Locks provide only indirect mechanisms for enforcing atomicity \nand isolation, and to make a program scale using locks, a programmer has to rea\u00adson about complexdetails \nsuch as .ne-grain synchronization and deadlockavoidance.TM promisesto remove thesebur\u00addens from the programmer \nand to automate them. Recent work [14, 2] has shown how TM can be tightly integrated into mainstreamlanguages \nand how TM can provide scala\u00adbility that competes with .ne-grain locks. But TM has arguably been a step \nback in the semantics it provides to the programmer. Most software transactional memory (STM) systems \nimplement weak atomicity [3]: they provide no ordering or isolation guarantees between trans\u00adactions \nand non-transactional memory accesses, and they cannot guarantee serializability of transactions in presence \nof potentially con.icting non-transactional accesses.Weak atomicity has surprising semantic pitfalls \nand in some cases, leads to incorrect execution for programs that are correctly synchronized under locks[30]. \nIn contrast, an STM system that implements strong atom\u00adicity [3, 30] guarantees serializability of transactions \nin the presence of non-transactional memory accesses. Strong atomicity avoids the pitfalls of weak atomicity \nand provides cleaner semantics. The primary obstacle to strong atomicity is the performance overhead \nrequired to enforce it.To im\u00adplement strong atomicity, an STM system must instrument Thread1 Thread2 \nfoo() { bar() { while (..) { atomic { ... = f.x; ... = f.x; f.x = ...; } } } } Figure 1. Strong atomicity \nexample non-transactional memory accesses with read or write bar\u00adriers, incurring signi.cant overhead \neven when a program makes minimal or no use of transactions. Past work has shown how to implement strong \natomicity ef.ciently using static whole-program analyses, but such analyses are im\u00adpractical in a dynamic \nlanguage environment, and without these optimizations, the high overheads of strong atomicity up to 5x \non some workloads make it nonviable for mainstream adoption. This paper presents a dynamic optimization \nframework that reduces strong atomicity overheads and makes strong atomicity practical for dynamic language \nenvironments such as Java. Our approach speculatively eliminates strong atom\u00adicity barriers based on \nincremental analyses performed by the JIT. The JIT can later detect mis-speculation and re\u00adcoverbydynamically \npatching mis-speculated accesses. The approach can take advantage of existing dynamic pro.le\u00adguided optimization \nand recompilation infrastructure to im\u00adprove its speculative optimization. In contrast to prior work \non optimizing strong atomicity, our approach does not de\u00adpend on static whole-program analysis; instead, \nit takes ad\u00advantage of existing dynamic optimization infrastructure in\u00adherent in Java VMs. We will use \nthe example program in Figure 1 to illus\u00adtrate our approach. Suppose that Thread1 initially invokes method \nfoo for the .rst time and triggers the JIT to com\u00adpile it. Because foo executes outside of a transaction, \nthe JITwould normally generate strong atomicity read and write barriers for the two accesses to f.x. \nUsing our approach, the JIT optimistically generates code with no strong atomicity barriers since it \nhas not yet seen anytransactional accesses to f.x that could causea con.ict.If Thread2 nowinvokes method \nbar for the .rst time, the JIT will compile it and dis\u00adcovera transactional readof f.x that may con.ict \nwith non\u00adtransactional writes to that .eld. Before bar is compiled and executed, the JIT must invalidate \ncode based upon now in\u00adcorrect assumptions. The JIT stops Thread1and patches the write to f.x in foo \nso that it performs a full write barrier. It does not patch the read to f.x in foo as there are still \nno transactional writes to f.x. Once patchingis done, Thread2 can safely execute bar without violating \nstrong atomicity. We make the following contributions: Wepresentadynamicnot-accessed-in-transaction \nanaly\u00adsis (D-NAIT) that optimistically and incrementally tracks the memory locations read or written \ninside transactions. We augment D-NAIT with an incremental alias analy\u00adsis that optimistically tracks \nwhether reference .elds are unique or can alias.  We present a low-overhead mechanism called phantom \nbarriers that allows the JIT compiler to eliminate strong atomicity barriers speculatively based on D-NAIT \nsanal\u00adysis. Phantom barriers convert to standard barriers via dynamic patching if D-NAIT s incremental \nanalysis later invalidates the speculation. We demonstrate how to re\u00adduce the cost of mis-speculation \nby leveraging existing pro.le-guided optimization and recompilation infrastruc\u00adture available in most \nhigh-performance Java VMs.  We measure the performance of our approach in the con\u00adtext of a Java STM \nsystem on a set of transactional and non-transactional benchmarks.We show that our ap\u00adproach can signi.cantly \nreduce the overhead of strong atomicity from a factor of 5 to less than 10% in most cases.  2. Background \nPrior work [13, 30, 1, 26] provides detailed arguments in favor of strong atomicity in STM. In this section, \nwe sum\u00admarize the motivations for strong atomicity,the current solu\u00adtions towards its implementation \nin STM, and the open per\u00adformance challenges that remain. 2.1 Motivationfor strong atomicity Froma programmer \ns perspective, strong atomicity provides stronger and more intuitive semantics than weak atomicity. In \nFigure 2, for example, Thread 1 tests a safety property (i.e., that the object x is non-null) andexecutes \nan instruction that may otherwise raise an exception. Under strong atom\u00adicity, this code is properly \nisolated and will neverfail. But under weak atomicity (or locks), malicious or buggy code can alter that \nsafety property in the middle of Thread 1 s transaction and trigger anexception. More generally,thisex\u00adample \nrepresents the commonly known Time-Of-Check-To\u00adTime-Of-Use (TOCTTOU) [4] vulnerability in system code \nand motivates strong atomicity semantics in high security or reliability situations. Although the above \nexample can break for both weak atomicity and locks, recent work [30] has shown that weak atomicity actually \nprovides weaker isolation and ordering guarantees than locks. Under weak atomicity, privatization and \nconsistency issues [1, 25, 26] can introduce incorrect behavior even in correctly synchronized programs \nthat are free of data races. Additionally, memory models for safe languages such as Java provide strong \nbehavioral guarantees even in the presence of data races. In Figure 3, a weakly Thread1 Thread2 atomic \n{if(x != null) .- x = null; x.f = ...; } Figure 2. TOCTTOU example: Under weak atomicity,ma\u00adlicious orbuggy \ncode can introduceafaultin Thread1. Initially x==0 and y==0 Thread1 Thread2 atomic {if (y==0) if (x==1) \nx = 1; y = 1; /*abort*/ } Can x==0? Figure 3. SDR example from [30]: Under weak atomicity, x can be 0. \nUnder strong atomicity or locks it cannot. atomic STM with in-place updates can produce a .nal result \nof x == 0, even though it is impossible in the equivalent lock-based program under the Java memory model. \nWeakly atomic STM implementations can be designed to provide as-strong-as-lock semantics [25] without \nstrong atomicity even in safe languages such as Java. Nevertheless, this requirement severely curtails \nthe STM design space. Current results show a signi.cant overhead and scalability cost to this approach \n[25]. Alternatively, one can avoid the pitfalls of weak atomic\u00adity by making sure that a program never \naccesses the same data both inside and outside a transaction. Recent work has proven that segregating \ndata in this manner in a weakly atomic STM gives the same semantics as strong atomicity [26]. This requires \neither programmer conventions or a spe\u00adcialtype systemthatsegregatesdataaswasdoneintheSTM for Concurrent \nHaskell [15]. Such conventions, however, in\u00adcrease the programmer sburden. Moreover, it s unclearhow \nto retro.t such a segregated type system into mainstream languages. Finally, in addition to its cleaner \nsemantics, a general requirement for strong atomicity semantics promises more consistent behavior between \nhardware TM (HTM) imple\u00admentations (which are already strong) and STM implemen\u00adtations (which can be \nmodi.ed to be strong).  2.2 Implementing strong atomicity Recent work has shown that an STM can implement \nstrong atomicity with no adverse effects on scalability [30]. The pri\u00admary challenge with strong atomicity \nis overhead it imposes in STM. Implementing strong atomicity requires tracking non\u00adtransactional memory \naccesses to detect con.icts with trans\u00adactional code.Byrelying onexisting cache coherencymech\u00adanisms, \nmany HTM systems implement strong atomicity naturally. In contrast, STM systems must instrument non\u00adtransactional \naccesses to implement strong atomicity, in\u00adcurring a signi.cant overhead even when a program makes minimal \nor no use of transactions. In native code, providing strong atomicity in an STM may be impractical as \nit requires recompiling the whole application, including pre-existing li\u00adbraries. In managed code, however, \nvirtual machines com\u00admonly add extra checks to memory accesses to support type safety (e.g., null, type, \nor bounds checks) orgarbage collec\u00adtion (e.g., read or write barriers). JIT compiler optimizations and \nruntime techniques [30] can reduce strong atomicity overheads, but their effective\u00adness has been mixed.For \ncertainworkloads, strong atomic\u00adity slowsdownexecutionbyafactorof5 even with these optimizations. Static \nwhole-program analysis has proven most effective in reducing strong atomicityoverheadsbut such analysisis \nnot practical in dynamic environments. In particular,the not\u00adaccessed-in-transaction analysis (NAIT) \n[30, 20] statically analyzes the whole program to determine which memory locations accessed outside of \na transaction are also never accessed inside transactions, allowing the compiler to skip strong atomicity \nbarriers for those locations. Static whole\u00adprogram analyses,however, are not practicalina production \nsetting where modular distribution of code and dynamic class loading are the norm. As described,NAIT \ncannot be performed in a production Java setting. 3. DynamicNAIT analysis In this section, we present \na dynamic not-accessed-in\u00adtransaction (D-NAIT) analysis and optimization for STM. The fundamental observation \nbehindNAIT [30, 20] is that a memory location that is not accessed inside a transaction requires no barriers \nto enforce strong atomicity. More pre\u00adcisely, a NAIT analysis categorizes memory locations as follows: \n The TxNone category contains memory locations that are not accessed inside a transaction. Non-transactional \naccesses to these locations do not require anybarriers.  The TxRead category contains locations that \nare only read inside a transaction. Only writes to these locations require barriers in non-transactional \ncode (to avoid non\u00adrepeatable reads [30] inside transactions).  The TxAll category contains locations \nthat are written and possibly read insideatransaction. These locations require both read and write barriers \nin non-transactional code.  The NAIT analysis described in [30, 20] is a static, whole-program analysis \nwhere the NAIT property is sum\u00admarized by the containing object type (and, for non-arrays, Type descriptor \nF.x State TxNone -. Type descriptor F.x State TxRead ... ... ... ... (a) After foo compiled (b) After \nbar compiled Figure 4. Simpli.ed D-NAIT state for Figure 1 the particular .eld). Once the entire program \nhas been prop\u00aderly analyzed, the compiler can eliminate strong barriers accordingly. In contrast to whole-program \nNAIT analysis, D-NAIT is dynamic and does not require whole-program analysis. D-NAIT builds its not-accessed-in-transaction \ninformation optimistically and incrementally as the JIT compiles the programat runtime.In particular,itexploitsthefactthatour \nJIT (described in [2]) lazily compiles two different versions of a method depending on whether it was \ninvoked inside or outside a transaction. Initially, the JIT assumes that all memory locations are never \naccessed transactionally. It maintains a global state ta\u00adble where memorylocations (summarizedby type \ndescrip\u00adtors) are initially set to TxNone . As the JIT compiles a new method, it takes the following \nsteps: 1. The JIT analyzes each method (via a linear scan), in\u00adspects each transactional load and store, \nand, if necessary, updates the global state table based on the corresponding type/.eld of the memory \naddress operand. Note, there is no need to analyze thread local data. Only accesses to shared data on \nthe heap (instance .elds or array elements) or to static data (class .elds) need to be analyzed. Figure \n4illustrates the global state for the example in Figure 1. 2. The JIT inspects each non-transactional \nload and store in the method. It generates non-transactional barriers based on the current global state \nof the analysis, as shown in Table 1. Where barriers appear unnecessary, it specula\u00adtively generates \na lightweight phantom barrier that has minimal runtime cost. 3. Finally, before emitting machine code \nand executing, the JIT determines if anypreviously compiled phantom bar\u00adriers are now invalidated by \nthe new global state and patches them in a thread-safe manner to execute a stan\u00addard strong barrier sequence \ninstead.  Once these steps are done, the JIT may safely emit and execute the new method. In the remainder \nof this section, we describe this process in more detail, and we discuss how to modify it to leverage \na pro.le-guided recompilation infrastructure. 3.1 D-NAIT analysis D-NAIT analysis incrementally computes \nnot-accessed-in\u00adtransaction state and barrier patching requirements. It uses Category Non-transactional \nRead Non-transactional Write TxNone Phantom barrier Phantom barrier TxRead Phantom barrier Strong barrier \nTxAll Strong barrier Strong barrier Table 1. D-NAIT categories patchList = EmptySet; for all txn accesses \nA { if A accesses thread-local object continue; [state, phantomReads, phantomWrites] = stateTable.getInfo(A.typeDescriptor); \nif (A is load) { if (state == TxNone) { state = TxRead; patchList += phantomWrites; phantomWrites = EmptySet; \n } } else { // A is store if (state == TxNone) { patchList += phantomWrites; phantomWrites = EmptySet; \n } if (state != TxAll) { patchList += phantomReads; phantomReads = EmptySet; } state = TxAll; phantomWrites \n= phantomReads = EmptySet;  } stateTable.setInfo(A.typeDescriptor, state, phantomReads, phantomWrites); \n} Figure 5. Pseudo-code for basic D-NAIT algorithm containing type and .eld information to summarize \ninfor\u00admation about individual memory accesses 1. Effectively, it relies on type-based aliasing to group \nmemory accesses into disjoint alias classes, such that accesses in different classes are guaranteed to \nrefer to different memory locations. The JIT maintains a global barrier state table with three entries \nfor each type descriptor (i.e., alias class) itsNAIT state (TxNone , TxRead or TxAll ), the list of \nread phantom barri\u00aders assuming that state, and the list of write phantom barriers assuming that state. \nEach time the JIT compiles a method, it performs a lin\u00adear scan over the method and updates the barrier \nstate table whenit encountersa transactional reador write operation.If anystatechangesoccur,theJITalsocomputesalistof \ncorre\u00adsponding phantom barriers to patch (as described in the next 1For instance .eld accesses, we always \nuse the most general containing type that de.nes the corresponding .eld. Similarly, for element accesses \nto an array of references, we always use Object[]. Figure 6. State transition diagram two subsections). \nFigure5shows the D-NAIT analysis algo\u00adrithm. Figure6shows the corresponding transition diagram for theNAIT \nstates. The analysis optimistically assumes that a memory loca\u00adtion is not accessed inside a transaction \nuntil it encounters a potentially con.icting transactional access, so each type de\u00adscriptorT initially \nstarts in TxNone state.A load operation transitionsTto the TxRead state unless it is in the TxAll state. \nAstore operation transitionsTto theTxAll state. This pass skips over transactional accesses where the \nJIT has already locally proven that an STM barrier is unnecessary (e.g., for transaction-local objects \n[2]); by de.nition, such accesses cannot con.ict with other threads. When theNAIT stateofa type descriptorTchanges \ndur\u00ading a method compilation, the JIT must patch any existing phantom barriers correspondingtoTin orderto \nensure cor\u00adrectness.Transitioningthe stateofTfrom TxNone to TxRead requires patching phantom write barriers \nassociated withT. Transitioning the state fromTxRead to TxAll requires patch\u00ading phantom read barriers \nassociated withT. Finally, transi\u00adtioning the state from TxNone to TxAll requires patching of both write \nand read barriers. ConsidertheexamplecodeinFigure7.Inthiscode, there are four different type descriptors: \nthree for each .eld of A and one for the elements of int[]. Table 2 illustrates the global state as each \nmethod is compiled. After only the con\u00adstructor A() and the method m1 have been compiled, the JIT has \nencountered no transactions, and the computed state en\u00adtry for each type descriptor is TxNone . The JIT \nhas, how\u00adever, encountered non-transactional accesses and optimisti\u00adcally suppressed strong atomicity \nbarriers. The global state table records the corresponding phantom read and phantom write barriers generated \nfor the given type descriptor. Once m2 is compiled, the JIT will process a transactional write to int[] \nand set the state of the type descripter to TxAll . All phantom reads(S3, S5)and writes(S4, S6)corresponding \nto int[] are patched and removed from the table. Similarly, the JIT will record a transactional read \nof the .eld A.x in m2. In this case, the state is set to TxRead , and only phan\u00ad class A { int[] x, y, \nz;  A() { S0: x = new int[N]; S1: y = new int[N]; S2: z = new int[N]; } void m1() { ... S3: ... = y[i]; \nS4: z[i] = ...; S5: ... = x[i]; S6: y[i] = ...; } void m2(int[] tmp) { atomic { S7: ... = tmp[i]; S8: \nx[i] = ...; } }  int[] m3() { S9: return y; } } Figure 7. D-NAIT example. Assume methods are initially \ninvoked and compiled in order: A(), m1, m2, m3. tom writes(S0)are patched and removed. After m3 (which \nhas no effect) is compiled, several patched barriers remain. 3.1.1 Context-sensitive D-NAIT analysis \nThe basic D-NAIT approach works .ne as long as common types and .elds are not accessed both inside and \noutside of transactions. In some cases, however, more precision can be acquired by considering additional \ncontext information. Consider again the example in Figure 7. In this case, only the array x is accessed \ntransactionally, but, as a result, all int[] accesses are presumed to require barriers. However, if the \nJIT can establish that reference .eld x points to a unique array, it can con.ne the effects of the transactional \nwrite to x[i] and still speculatively use phan\u00adtom barriers to access other int[] arrays. Uniqueness \nof reference .elds,likeNAIT, canbe trackedbytheJITinan optimisticfashion.In our implementation, we usea \nsimple dynamic approach.As withNAIT, we track uniquenessby type descriptor. When a class is .rst loaded, \nthe JIT opti\u00admistically assumes that its reference .elds are all initially marked unique.On each method \ncompilation,a uniqueness analysis pass updates the uniqueness information based on the following conservative \nrule:Areference .eldFis unique if it points to a freshly allocated object, and the object refer\u00adenceis \nstored only intoFand does not escape.If the .eldF (NAIT State, PhantomReads, PhantomWrites) After A() \n&#38;m1() After m2() &#38;m3() A.x A.y A.z int[] (TxNone , {S5}, {S0}) (TxNone , {S3,S6}, {S1}) (TxNone \n, {S4}, {S2}) (TxRead , {S5}, \u00d8) (TxNone , {S3,S6,S9}, {S1}) (TxNone , {S4}, {S2}) (TxAll , \u00d8, \u00d8) (TxNone \n, {S3,S5}, {S4,S6}) Table 2. D-NAIT analysis results for Figure7 is used in anymanner inconsistent with \nthis rule, it is marked as aliased. A reference escapes if it is returned from a method,passedasaparameterinamethodinvocation, \nstored intoa .eld other thanF, or thrown as anexception. These rules provide a conservative approximation \nof unique .elds. To exploit context information, we make two modi.ca\u00adtionstotheglobalstatetable, illustratedinTable3.First,we \nextend each type descriptor with an additional level of con\u00adtext.For example, A.x::int[] represents the \nint[] only reachable from A.x. When the context is unknown, ambigu\u00adous, or non-unique, we use the notation \n*::int[] to rep\u00adresent the generic aliased context. In our scheme, the mem\u00adory locations representedby \nA.x::int[] and *::int[] are disjoint. If we cannot establish that A.x pointstoauniquear\u00adray, the former \ndescriptor must be merged with and replaced by the latter descriptor. Second, we introduce a forwarding \npointer to facillitate merging. In Table 3, after m3 is com\u00adpiled, the entry for A.y::int[] is a forwarding \npointer to the aliased context.For type descriptors witha precise con\u00adtext, the presence of a forwarding \npointer indicates that the contextis aliased.The lackofa forwarding pointer indicates that the context \nis unique. Table 3 illustrates the effect of context for the example in Figure 7. Here, we use additional \ncontext to maintain distinct entries for A.x,A.y,andA.z. As the constructor and m1 are compiled, phantom \nbarriers are generated. Because all initialization of the .elds are to fresh memory and the memory never \nescapes, each extended descriptor is regarded as unique and has its own entry. When m2 is compiled, it \nobserves a transactional write to an int[] array. In this case, however, the write is in a unique context, \nand only A.x::int[] is updated to TxAll (triggering a patch on S5). There is also a read to an int[] \nof unknown context, and so *::int[] is set to TxRead . This, however, triggers no patching, as A.y and \nA.z still point to unique data that can not alias with the argument in m2. On the other hand, once m3 \nis compiled, A.y escapes and the entry for A.y::int[] must be merged into *::int[]. This, in turn, triggers \na patch on the write in S6. Overall, the use of context has allowed the system to maintain two extra \nphantom barriers: S3 and S4. Figure8illustrates the algorithm for managing additional context in D-NAIT. \nThe JIT employs a simple pass based on the rules described above to determine when an extended type descriptor \ntransitions from unique to aliased. When a mergeWithAliased(TypeDesc [C1::C2]) { patchList = EmptySet; \n[state,phantomReads,phantomWrites] = stateTable.getInfo([C1::C2].typeDescriptor); [state*,phantomReads*,phantomWrites*] \n= stateTable.getInfo([*::C2].typeDescriptor); // Using TxnNone < TxnRead < TxnAll state* = max(state, \nstate*); phantomReads* += phantomReads; phantomWrites* += phantomWrites; if (state* != TxnNone) { patchList \n+= phantomWrites*; phantomWrites* = EmptySet; } if (state* == TxnAll) { patchList += phantomReads*; \nphantomReads* = EmptySet; } stateTable.setInfo([*,C2], state*, phantomReads*,phantomWrites*); stateTable.setForwardingPointer([C1,C2],[*,C2]); \nreturn patchList; } Figure 8. Pseudo-code for merging barrier info transition occurs,itmust merge theextended \ntype descriptor C::T into the corresponding aliased descriptor *::T and in\u00adstall a forwarding pointer. \nThe new state is the more restric\u00adtiveof the twostates prior to merging. The phantom read and write lists \nare merged, and, depending on the new state, then patched and removed.  3.2 Phantom barrier generation \nAs the JIT compiles each method, it speculatively removes strong atomicity barriers based on the current \nglobal D-NAIT state. In their place, it generates lightweightphantom barriers that introduce minimal \nruntime overhead but can be later converted to standard barriers. These phantom bar\u00adriers are similar \nto speculatively devirtualized calls in [22]. During normal execution, the original load or store is \nexe\u00adcuted without a strong atomicity barrier. If the state of the .eld changes and the speculation is \ninvalidated, the phantom barrier is patched by the compiler to convert it to a standard strong atomicity \nbarrier. (NAIT State, PhantomReads, PhantomWrites) After A() &#38;m1() After m2() After m3() Final *::A.x \n(TxNone , {S5}, {S0}) (TxRead , {S5}, \u00d8) ... (TxRead , {S5}, \u00d8) *::A.y (TxNone , {S3,S6}, {S1}) ... (TxNone \n, {S3,S6,S9}, {S1}) (TxNone , {S3,S6,S9}, {S1}) *::A.z (TxNone , {S4}, {S2}) ... ... (TxNone , {S4}, \n{S2}) A.x::int[] (TxNone , {S5}, \u00d8) (TxAll , \u00d8, \u00d8) ... (TxAll , \u00d8, \u00d8) A.y::int[] (TxNone , {S3}, {S6}) \n... -. *::int[] -. *::int[] A.z::int[] (TxNone , \u00d8, {S4}) ... ... (TxNone , \u00d8, {S4}) *::int[] (TxNone \n, \u00d8, \u00d8) (TxRead , \u00d8, \u00d8) (TxRead , {S3}, \u00d8) (TxRead , {S3}, \u00d8) Table 3. Context-sensitive D-NAIT analysis \nresults for Figure7 Figure 9 shows the pseudo-code for a phantom write barrier used to protect an add \noperation that updates the heap.Aphantom barrier consistsoftwo parts: 1. The original load or store instruction. \nIf additional space is necessary to accomodate a patch, we can take one of two strategies. We can insert \nnops after the access instruction, or we can duplicate instructions following the original access if \npossible (i.e., theydo not also have phantom barriers). 2.A barrier code block, unique for each load \nor store, that performs the standard strong atomicity barrier fol\u00adlowedby anyduplicated instructions.In \nFigure9, <next statement1> is duplicated in the barrier block. Note, the barrier blockis onlyexecutedif \nthe methodis patched.It maybe generated lazilyby the JIT upon patching. In the intermediate representation, \nthe compiler maintains an additional phantom conditional jump in front of the orig\u00adinal instruction. \nThis phantom jump, not emitted in the .nal assembly code, is necessary to ensure that the normally un\u00adreachable \nbarrier code is connected to the control .owgraph. The barrier code itself is marked as infrequently \nexecuted (cold) code. In general, the compiler is able to leverage existing op\u00adtimizationstoef.ciently \ngenerate phantom barriers.Forex\u00adample, pro.le-guided code layout places all phantom barri\u00aders together \nat the end of a method s generated code along with other blocks that are deemed cold.To minimize the \nef\u00adfect of phantom barriers on register allocation, we also ex\u00adplicitly generate spill code in the cold \nbarrier block as shown in Figure 9. This prevents the cold barrier block from inter\u00adfering with live \nregister ranges on the hot path. Before the compiler emits a method with speculative phantom barriers, \nit records all information necessary to test and, if necessary, invalidate those barriers. The following \ninformation is maintain in the global state table: 1.For each type descriptor, the compiler retains a \nlist of instruction pointers to all corresponding loads and stores where phantom barriers have been generated. \n... // Original // Patch add [base+offset], 1 <= jmp barrier_block <next statement1> next_block: <next \nstatement2> ... ret barrier_block: <save live registers> <stm lock base> add [base+offset], 1 <stm unlock \nbase> <restore live registers> <next statement1> jmp next_block Figure 9. Phantom write barrier for an \nadd operation that stores to the heap in IA-32 pseudo-code. On patching, the add is overwritten with \na jump to the barrier block. If the instruction to patch is smaller than the jump, the instruction following \nthe memory access is duplicated in both the origi\u00adnal block and the barrier block. 2.For each load or \nstore instruction (identi.ed by its in\u00adstruction pointer), the compiler records the displacement to its \ncorresponding barrier code block. (This is elided in Tables2and3for conciseness.)  3.3 Phantom barrier \ninvalidation If JIT analysis on a method has triggered an access state transitiononatype descriptor,itmayinvalidatepreviously \ngenerated phantom barriers. Before emitting code that inval\u00adidates earlier assumptions, the compiler \nmust safely convert incorrect phantom barriers to regular strong barriers. It does this by taking following \nsteps: 1. The compiler accesses the above tables to determine the set of memory accesses to patch and, \nfor each access, a corresponding jump instruction to insert in its place. If this set is empty, no further \nwork is necessary, and the compiler jumps to step 6. 2. The compiler invokes a stop-the-world-mechanism \nand signalsall currentlyexecuting threadsto pauseatthenext safe point. 3. The compiler waits until all \nother threads have reached a safe point. 4. The compiler patches each instruction, installing a jump \nto the corresponding barrier block. Due to variable in\u00adstruction length on IA-32, the compiler must maintain \nthe size of each patched instruction to generate the cor\u00adrect NOP padding. As described earlier, the \ncompiler re\u00adserved enough space for a jump instruction that branches to the barrier block.For our platform, \nit reserves5bytes for a 32-bit branch to the barrier code2. 5. The compiler signals each paused thread \nto execute a serializing instruction(CPUID on our IA32 platform) and continue. 6. The compiler emits \ncode for the newly compiled method. At this point, all previously generated code has been updated and \nmade visible to other threads.  The safety of the above process relies on two other con\u00adstraints. First, \nonly one thread of compilation may access and update the global tables at a given time. In our system, \nthis in enforced in a coarse manner: only one thread may perform compilation at a time. Second, safe \npoints may not overlap with phantom barriers. Once all other threads are at safe points, the compiler \nis assured that no thread is concur\u00adrently executing a phantom barrier as it is being patched. The above \nalgorithm respects the general guidelines for thread-safe cross-modifying code for the IA-32 architecture \n[21]. In particular, the CPUID (or other serializing) instruc\u00adtion is necessary to .ush the instruction \ncache.To stop-the\u00adworld, we simply use existing VM and JIT mechanisms to support stop-the-world garbage \ncollection (including safe points). Note, our invalidation process does not need to abort on\u00adgoing transactions. \nInstead, it is suf.cient to pause transac\u00adtionsatsafepoints(asanyotherthread),andtoletthem con\u00adtinue \nfrom that point once patching is complete. The above mechanisms ensure that con.icts between transactional \nand non-transactional accesses occur only after patching is com\u00adpleted and visible to all threads. Table3showsthe \nsequenceof patches applied whenex\u00adecuting our running example (Figure 7) using context infor\u00admation.For \nsimplicity, we focus on int[] accesses. In m1, the JIT encounters no transactions and installs phantom \nbar\u00adriers for int[] accesses in S3,S4,S5,andS6. In m2, the JIT encounters a transactional write and patches \nS5. In m3, the 2A 2-byte short jump has a range of only +127/-128. Our code layout typically puts barrier \nblocks at the end of methods which is usually too far away. JIT encountersa uniqueness state change \nand patches S6. S3 and S4 remain unpatched. Phantom barriers to the .elds of A are maintained and patched \nsimilarly. 3.4 Exploiting pro.le-guided recompilation The cost of misspeculation in our system is potentially \nquite high. Patched jumps to out-of-line barriers are not as ef.\u00adcient as normally generated strong barriers, \nsuffering from additional instructions, poor code layout, and suboptimal register allocation. Stopping \nthe world temporarily halts all progress.Toexplore reducing misspeculation, weleverage infrastructure \nfor dynamic recompilation to employphantom barriers more selectively. Our runtime environment performs \ndynamic pro.le\u00adguided optimization and has two compilersbuilt-in (O1 and O2). The O1 compiler only performs \na minimal set of op\u00adtimizations and instruments the generated code to collect edge pro.le information. \nHot methods are selected using the pro.le information and recompiled with the aggressively optimizing \nO2 compiler. We use this framework to improve optimization of strong atomicitybarriers.Weexperimented \nwithtwo recompilation strategies. Bothexploit thefact that recompilation provides our analyses time to \nconverge and allows the compiler to make better decisions for hot methods. 1. Phantom barriers in O1+O2 \ncode:We generate phantom barriers during initial O1 compilation and speculate that there will be no patching. \nDuring O2 recompilation of hot methods, we replace misspeculated phantom barriers with the standard inlined \nbarriers. 2. Phantom barriers onlyinO2 code:We generate standard strong barriers during O1 compilation. \nDuring O2 recom\u00adpilation, we insert speculative phantom barriers more se\u00adlectively in hot methods. Overall, \nwe expect to see less patching activity with this approach.  We study the effects of both approaches \nin the next sec\u00adtion. 4. Performance We evaluate the effectiveness of our dynamic optimiza\u00adtions using \nboth transactional and non-transactional work\u00adloads. Our underlying STM, described in [2], uses an eager\u00adversioning, \nin-place update scheme (similar to that also de\u00adscribed in [16]). On top of this, our underlying system \nalso supports strong atomicity as described in [30]. For our workloads, we focus on those evaluated in \n[30]. For the standard, non-transactional SPEC JVM98, earlier dynamic techniques often left substantial \nstrong atomicity overhead. Only static whole-program optimization was gen\u00aderally effective at removing \nthis overhead. Similarly, for the transactional TSP (a traveling salesperson problem solver), earlier \ndynamic optimizations alone were ineffective, leav\u00adinga roughly3xoverhead.In contrast, the transactionalver\u00adsions \nof SpecJBB and OO7 in [30] already show little over\u00adheaddueto strong atomicity.Asexpected, our optimizations \ndo not have a noticeable effect on these workloads, and we do not discuss them further. Instead, we study \ntwo different versionsof SpecJBB thatexhibit signi.cant strong atomicity overhead: the unmodi.ed synchronized \nversion and a par\u00adtially transactionalizedversion that spends considerable time in non-transactional \ncode. In our experiments, we use object-level con.ict detec\u00adtion granularity in our STM, and we enable \nall JIT com\u00adpiler optimizations described in [2] and [30], as well as dynamic escape analysis [30]. We \ndo not use any static whole-program analyses [30] as our focus is on a pro\u00adduction Java setting. In our \nexperiments, we measure the performance of the baseline strong atomicity mode with\u00adout our new optimizations \n(labeled Strong (Base)), strong atomicity using D-NAIT (Strong (D-NAIT)), strong atomic\u00adity with context-sensitive \nD-NAIT (Strong (+Context)), and .nally strong atomicity with context-sensitive D-NAIT on hot methods \nonly and full strong atomicity barriers on cold methods (Strong (+Hot Method)). We conduct all our experiments \non an Intel Clovertown system with two 2.66 GHz quad-core processors for a total of eight hardware threads \nand 3.25 GB of RAM running MicrosoftWindowsXP Professional with ServicePack2. 4.1 SPEC JVM98 We .rst \nmeasure the effect of D-NAIT on the unmodi.ed SPEC JVM98 benchmark suite [31]. These benchmarks are non-transactional \nand, with the exception of mtrt, single\u00adthreaded. Ideally, we would like to see no STM overhead for \nnon\u00adtransactional workloads. As Figure 10 shows, the baseline strong atomicity mode incurs signi.cant \noverheads rang\u00ading froma minimumof14%ondbtoas muchas358% on mpegaudio because it inserts non-transactional \nbarriers for reads and writes. D-NAIT reduces these overheads con\u00adsiderably. When phantom barriers are \nonly used in hot meth\u00adods, the overheads range from unnoticeable on db to about 5% on mpegaudio. Because \nthe JIT never encounters any transactions,it always speculatively inserts phantom barri\u00aders in lieu of \nstandard barriers and never patches the phan\u00adtom barriers. This .gure does not show the effects of adding \ncontext information to D-NAIT since the JIT does not in\u00adsert anystrong atomicity barriers context information \nhas no effect on the results. Using phantom barriers on hot methods has only a negligible effect with \none exception. For com\u00adpress, overhead is lowered from 8% to 2%. Compress has unusually few very hot \nmethods, and, in this case, it appears bene.cial to only generate phantom barriers in those meth\u00adods. \n All remaining overhead from D-NAIT in Figure 10 is solely due to the cost of inactive phantom barriers; \nthese costsincludeexecutionofextranop instructions, cacheand TLB effects of code-size expansion from \nthe barrier blocks, and the effects of modeling phantom barriers in the JIT s IR on optimization phases. \nOur current implementation is also conservative in some respects: we do not duplicate in\u00adstructions as \ndescribed in Section 3.2 to reduce nops on the hot path, and we preallocate additional space in a method \ns stack frame to support saving and restoring registers in bar\u00adrier blocks. In general, we believe that \nwith further tuning including generating the barrier blocks on demand and removing the branches to the \nbarrier blocks in the IR we canbring these costsdowneven closerto zeroforworkloads such as SPEC JVM98 \nthat make no use of transactions. 4.2 Traveling Salesperson Problem TSP is a multithreaded Java implementation \nof the traveling salesperson problem used in earlier research on Java con\u00adcurrency [36, 19]. Each thread \nevaluates different portions of the search spaceina largely independent manner. Small critical sections, \nimplementedas transactionsin ourversion, are used to share intermediate work and track the currently \noptimal solution. From the perspective of strong atomicity, TSPis particularly interestingasa numberof \ndata structures are accessed both transactionally and non-transactionally as data computed by one thread \nis shared with others if it rep\u00adresents a potentially optimal solution. Moreover, it contains a benign \ndata race where the MinTourLen .eld (shown in Table 2), representing the current best, may be read non\u00adtransactionally \nas other threads transactionally update it. The correctness of the program relies on this .eld decreasing \nmonotonically a property that weakly atomic STMs may violate. Thus this program may theoretically execute \nincor\u00adrectly under weak atomicity. Figure 11 shows the results for TSP. On a single thread, D-NAIT reduces \nthe overhead of strong atomicity relative to weak atomicity from roughly 2.9x to 11% when using context \ninformation (and phantom barriers on all methods). Without context information, the overhead is 47%, \nand so the additional precision is very effective on this workload. All versions scale well up to 8 threads. \nAt 8 threads, D-NAIT is within 10% of the weak atomicity baseline. The Standard Strong Barriers Correctly \nSpeculated Phantom Barriers Mis-speculated Phantom Barriers Stop-The-World Invocations Baseline Strong \nD-NAIT +Context +Hot Method +Context &#38;Hot Method 851 62 36 760 746 0 741 762 91 105 0 48 53 0 0 0 \n4 4 0 0 Table 4. Generated Barrier Counts for TSP  overhead of D-NAIT is due to real contention (mostly \non the .eld MinTourLen)and due to a few non-transactional write barriers on array stores that context-sensitive \nD-NAIT cannot remove. When phantom barriers are only applied to hot meth\u00adods, D-NAIT is slightly less \neffective. Table 4 shows the static barrier counts for TSP: Context information increases the number \nof correctly speculated phantom barriers and re\u00adduces the number of standard strong barriers. Phantom \nbar\u00adriers for hot methods reduce the amount of mis-speculation and stop-the-worldinvocations. Thereisa \ntrade-offbetween less mis-speculation and an increased number of standard strong barriers in O1-compiled \ncode. For TSP, it appears bene.cialto insert these barriersearly.Evenat8threads,the cost of the stop-the-world \ninvocations does not negatively impact execution time.  4.3 SpecJBB2000 Finally, we investigate D-NAIT \non two different variations of the SpecJBB2000 workload [32]. In this multithreaded Java server benchmark, \neach thread operates on an indepen\u00addent warehouse data set for a .xed period of time. Perfor\u00admanceis \nmeasuredin termsofbusiness transactionsper sec\u00adond. Figure 12 shows the results for the standard, synchro\u00adnized \nversion of SpecJBB2000. This version has no trans\u00adactions and all its critical sections are protected \nby locks. The baseline strong atomicity decreases throughput consid- Figure 12. Standard, synchronized \nSpecJBB2000 erably compared to the plain synchronized version. This is unsurprising as all memory operations \nare non-transactional and the JIT thus instruments them with strong atomicity bar\u00adriers.With D-NAIT, \nhowever, we have perfect speculation, and we see throughput within a few percent of the plain syn\u00adchronized \nversion. The throughput of D-NAIT is within 7% of the synchronized version whereas standard strong atom\u00adicityisupto34%slower \nthan synchronizedversion. Adding context and focusing D-NAIT on hot methods only has little effect on \nthis workload. The results for the second version of SpecJBB, shown in Figure 13, evaluate a partially \ntransactional version of SpecJBB. This version retains all of the original synchro\u00adnization with the \nexception of the core B-Tree data structure Standard Strong Barriers Correctly Speculated Phantom Barriers \nMis-speculated Phantom Barriers Stop-The-World Invocations Baseline Strong D-NAIT +Context +Hot Method \n+Context &#38;Hot Method 15253 1860 1739 9765 9721 0 13165 13253 5481 5532 0 228 256 0 0 0 11 15 0 0 \n Table 5. Generated Barrier Counts for Synchronized JBB withTransactional B-Tree that is now fully transactional. \nOur intent here is to sim\u00adulate realistic settings where TM is introduced piecemeal into applications \nrather than ubiquitously at once. In con\u00adtrast to the standard version (where the B-Tree is not fully \nsynchronized), the transactional B-Tree in this version is thread-safe. Accordingly, we see a slight \noverhead in weak atomicity mode over the synchronized version in Figure 12. On average the base strong \natomicity con.guration is 30% slower than weak atomicity. With D-NAIT the throughput gets withinafew \npercentofthe weak atomicity baseline.On averageD-NAIT reducestheoverheadof strong atomicityto 5% of weak \natomicity for the partially transactional version of SpecJBB. Table5shows the barrier counts for SpecJBB. \nGenerat\u00ading phantom barriers only for hot methods (Strong +Con\u00adtext&#38;Hot Method) eliminates mis-speculated \nphantom bar\u00adriers, but does not help in terms of performance. All the patching in this benchmark already \noccurs during the warm\u00adup phase preceding the measurement phase. Therefore, mis\u00adspeculationof phantom \nbarriersis notafactor here and the increasednumberof standard barriers weighs more. Thisex\u00adplains whyinserting \nphantom barriers only in O2-compiled code (Strong +Context &#38; Hot Method) performs slightly worse \nwith an average overhead of 13%. 5. Related work 5.1 Incremental points-to and escape analysis There \nhave been a number of approaches for incremental analysisof programs.Withgrowing importanceof dynamic \ncompilation, incremental program analysis becomes more and more important. We distinguish two categories: \nopti\u00admistic and pessimistic analyses. An incremental, optimistic analysis makes optimistic assumptions \nabout unanalyzed part of the program. If optimizations are performed based on these assumptions, the \nsystem requires an invalidation and recovery mechanism should an assumption fail later. Pes\u00adsimistic \napproaches make conservative assumptions about unknown parts of the program. Therefore they do not re\u00adquire \nhandling for mis-speculation. Our work is incremental and optimistic, and we provide a code patching \nmechanism to recover from mis-speculation. 5.1.1 Optimistic analysis Optimistic inter-procedural analysis \nhas been shown useful for type analysis [28]. That approach targets the optimization of virtual method \ncalls. The system includes an event noti\u00ad.cation to recompile methods when an optimistic assump\u00adtion \nis invalidated. The JIT compiler tracks dependencies be\u00adtween alias sets and compiled methods to recompile \naffected methods in case an optimistic assumption is invalidated. Object inlining is another optimization \nthat can bene.t from an optimistic analysis.Wimmer et al. [37] perform dy\u00adnamic optimistic object inlining \n[12, 24] in a dynamic com\u00adpiler. The preconditions necessary to successfully inline ob\u00adjects are similar \nto our concept of unique references and are checked by runtime guards. If an inlined object refer\u00adenceisoverwritten,thesystem \nde-optimizesall methodsthat access invalidated inlined objects. The de-optimization pro\u00adcess, however, \nis unspeci.ed. Code patching has been used to enable speculative devir\u00adtualization of virtual method \ncalls [22] in a dynamic envi\u00adronment. An optimistic version of class hierarchy analysis (CHA) [11], based \nupon currently loaded classes, is used to .nd candidates for devirtualization. This style of speculative \noptimization and deoptimization differs from ours in two respects. First, speculative CHA as\u00adsumptions \nare re-veri.ed at dynamic class loading, where as D-NAIT assumptions can be veri.ed later at method recom\u00adpilation. \nSecond, and more subtly, deoptimization of devir\u00adtualized callsis simplerina multithreaded setting.The \ncom\u00adpiler may concurrently patch a call site (via an atomic in\u00adstruction) even as another thread is invoking \nthat call. Load\u00ading the new class does not invalidate with concurrently ex\u00adecuting devirtualized calls. \nIn contrast, in our system, com\u00adpiling a new method may invalidate existing phantom barri\u00aders. Converting \na phantom barrier to regular one requires a stronger mechanism for correctness (e.g., forcing all threads \nto a safe point). 5.1.2 Pessimistic analysis Incremental escape analyses have been proposed in the con\u00adtext \nof ahead-of-time compilation [7, 34] and also for JIT compilers [23]. In escape analysis, the compiler \nhas cor\u00adrect information at each step and can optimize each method safely without support for speculative \noptimization.Typical applications for escape analysis are stack allocation, scalar replacement and synronization \nremoval. Our optimization is essentially also a kind of synchro\u00adnization removal.We also operateina purely \ndynamic set\u00adting where whole-program analysis is not an option. In con\u00adtrasttoexisting incremental escape \nanalyses,D-NAITisop\u00adtimistic, and we eliminate barriers speculatively. The op\u00adtimistic nature of D-NAIT \npotentially provides more opti\u00admization opportunities over static analysis which is conser\u00advative about \nthe unknown parts of the program.  5.2 Ownership types The concept of unique references and restricting \naliasing among referenceshas been addressedinseveralways: Own\u00adership types [10] are static type systems \nthat restrict aliasing and limit the visibility of object references. Con.ned types [33] pursue a similar \ngoal. The con.nement property is use\u00adful to specify security constraints and is staticallychecked at \ncompile time. Applications of such ownership models range from correctness [5, 17] to security [9, 33] \nand optimizations [6]. All those approaches havein common that theyare static and usually require either \nprogrammer annotation or static (whole-program) analysis for inferring aliasing properties. Our approach \nborrows the idea of unique references to use context informationinD-NAIT,butdoesnotrelyonany form of \nannotations or whole-program or modular analysis. Instead, we dynamically inferownership properties.We \nop\u00adtimistically assume no aliasing for freshly allocated objects until proven otherwise. The dynamic \napproach has the ad\u00advantage that methods that are never actually executed do not contribute to the analysis \nresult.  5.3 Data race detection Strong atomicity barriers may be viewed as a mechanism to detect data \nraces. There are several static [36, 27] and dy\u00adnamic approaches[29,35,8]todetectdata races.Staticanal\u00adyses \nare usually sound, but more conservative (more false positives than dynamic analyses). On the other hand, \ndy\u00adnamic techniques add signi.cant runtime overhead because theyrequire expensive instrumentation. Thereareseveralwaysofreducingthis \nruntimeoverhead: The Eraser algorithm [29] uses a thread ownership model to use heavy-weight barriers \nonly on object that are actu\u00adally shared. Dynamic escape analysis [30] pursues a similar idea, but it \ntracks object visibility instead of actual shared accesses. This way the systems makes sure that it .nds \npo\u00adtentially shared objects early enough for the STM system to recover in case of an actual con.ict. \nPraun et al. [36] use static analysis eliminate instrumentationoverhead causedby dynamic race checking. \nUsing thread-local information ob\u00adtainedbythe static analysis the compiler can only instrument access \nto potentially shared objects. Ourwork on strong atomicity STM goes intoa similar di\u00adrection by optimistically \neliminating barriers for object that can never con.ict. However, since we work in a purely dy\u00adnamic setting \n(without whole-program information) we also need a backup procedure to recover from mis-speculation in \nour analysis. Another difference is that we do not have complete information about thread-locality,but \ninstead track which objects are accessed within transactions as an approx\u00adimation. 6. Conclusions Strong \natomicity provides a well-de.ned and intuitive se\u00admantics for transactional memorybut has been challenging \nto implementef.cientlyinadynamic languageenvironment. Past work has shown how to implement strong atomicity \nef\u00ad.ciently using static whole-program analyses,but such anal\u00adysesare impracticalinadynamiclanguageenvironment,and \nwithout these optimizations, the high overheads of strong atomicity make it nonviable for mainstream \nadoption. In this paper, we have presented new dynamic optimiza\u00adtions that signi.cantly reduce strong \natomicity overheads and are suitable for dynamic language environments such as Java. Our new dynamic \nD-NAIT analysis, augmented with context information from an incremental alias analysis, opti\u00admistically \ntracks which non-transactional memory accesses can avoid strong atomicity barriers. Our new phantom bar\u00adrier \nmechanism uses these results to generate optimized code that speculativelyavoids strong atomicity barriersbut \ncanbe patched to recover from mis-speculation if D-NAIT later re\u00ad.nes its optimistic results based on \nnew dynamically com\u00adpiled code.Weshowedhowto implement these mechanisms ef.cientlybyleveragingexisting \ndynamic infrastructureina Java system, and we demonstrated that our techniques sub\u00adstantially reducetheoverheadof \nstrong atomicityoveranef\u00ad.cient weakly-atomic baseline. The dynamic optimizations we have presented now \nmake strong atomicity practical in a dynamic language environment. References [1] ABADI, M., BIRRELL, \nA., HARRIS, T., AND ISARD, M. Semantics of transactional memory and automatic mutual exclusion. In POPL \n2008. [2] ADL-TABATABAI, A.-R., LEWIS, B. T., MENON, V. S., MURPHY,B.R.,SAHA,B., AND SHPEISMAN,T. Compiler \nand runtime support for ef.cient software transactional memory. In PLDI 2006. [3]BLUNDELL,C.,LEWIS,E.C., \nANDMARTIN,M. Subtleties of transactional memory atomicity semantics. Computer Architecture Letters 5,2(Nov. \n2006). [4] BORISOV, N., JOHNSON, R., SASTRY, N., AND WAGNER, D. Fixing races for fun and pro.t: how to \nabuse atime. In SSYM 2005 (Berkeley, CA, USA, 2005), USENIX Association, pp. 20 20. [5]BOYAPATI,C.,LEE,R., \nAND RINARD,M. Ownership types for safe programming: preventing data races and deadlocks. In OOPSLA 2002. \n[6] BOYAPATI,C.,SALCIANU,A.,WILLIAM BEEBEE,J., AND RINARD,M. Ownership types for safe region-based memory \nmanagement in real-time Java. In PLDI 2003 (2003). [7] CHOI, J.-D., GUPTA, M., SERRANO, M. J., SREEDHAR, \nV.C., AND MIDKIFF,S.P. Stack allocation and synchro\u00adnization optimizations for Java using escape analysis. \nACM Trans. Program. Lang. Syst. 25,6(2003). [8] CHOI, J.-D., LEE, K., LOGINOV, A., O CALLAHAN, R., SARKAR, \nV., AND SRIDHARAN, M. Ef.cient and precise datarace detection for multithreaded object-oriented programs. \nIn PLDI 2002. [9] CLARKE, D., RICHMOND, M., AND NOBLE, J. Saving the world from bad beans: deployment-time \ncon.nement checking. In OOPSLA 2003. [10]CLARKE,D.G.,POTTER,J.M., AND NOBLE,J. Owner\u00adship types for .exible \nalias protection. In OOPSLA 1998. [11]DEAN,J.,GROVE,D., AND CHAMBERS,C. Optimization of object-oriented \nprograms using static class hierarchy analysis. In ECOOP 1995. [12] DOLBY, J., AND CHIEN, A. An automatic \nobject inlining optimization and its evaluation. In PLDI 2000. [13] GROSSMAN, D., MANSON, J., AND PUGH, \nW. What do high-level memory models mean for transactions? In MSPC 2006. [14] HARRIS, T., AND FRASER, \nK. Language support for lightweight transactions. In OOPSLA 2003. [15] HARRIS, T., MARLOW, S., JONES, \nS. P., AND HERLIHY, M. Composable memory transactions. InPPoPP 2005. [16] HARRIS,T.,PLESKO,M.,SHINNAR,A., \nAND TARDITI,D. Optimizing memory transactions. In PLDI 2006. [17]HEINE,D.L., AND LAM,M.S.Apractical .ow-sensitive \nand context-sensitiveCand C++ memoryleak detector. In PLDI 2003. [18]HERLIHY,M., AND MOSS,J.E.B.Transactional \nmemory: architectural support for lock-free data structures. In ISCA 1993. [19]HINDMAN,B., AND GROSSMAN,D. \nAtomicity via source\u00adto-source translation. In MSPC 2006. [20]HINDMAN,B., AND GROSSMAN,D. Strong atomicity \nfor Java without virtual-machine support. Tech. Rep. UW-CSE\u00ad06-05-01, May 2006. [21] INTELCORPORATION. \nIntel 64 and IA-32 Architectures Soft\u00adware Developer s Manual Volume 3A: System Programming Guide. [22] \nISHIZAKI, K., KAWAHITO, M., YASUE, T., KOMATSU,H., AND NAKATANI,T. Astudyofdevirtualization techniques \nfor a Java just-in-time compiler. In OOPSLA 2000. [23] KOTZMANN, T., AND M\u00a8 \u00a8 OSSENBOCK,H. Escape analysis \nin the context of dynamic compilation and deoptimization. In VEE 2005. [24] LHOT\u00b4 AK, O., AND HENDREN, \nL. Run-time evaluation of opportunities for object inlining in Java. In JGI 02: Proc. of the conf. on \nJava Grande. [25] MENON, V., BALENSIEFER, S., SHPEISMAN, T., ADL-TABATABAI, A.-R., HUDSON, R. L., SAHA, \nB., AND WELC, A. Practical weak-atomicity semantics for Java STM. In SPAA 2008. [26]MOORE,K.F., AND GROSSMAN,D. \nHigh-level small-step operational semantics for transactions. In POPL 2008. [27] NAIK, M., AIKEN, A., \nAND WHALEY, J. Effective static race detection for Java. In PLDI 2006. [28]PECHTCHANSKI,I., AND SARKAR,V. \nDynamic optimistic interprocedural analysis: a framework and an application. In OOPSLA 2001. [29] SAVAGE, \nS., BURROWS, M., NELSON, G., SOBALVARRO, P.,AND ANDERSON,T. Eraser:a dynamic data race detector for multi-threaded \nprograms. In SOSP 1997. [30] SHPEISMAN, T., MENON, V., ADL-TABATABAI, A.-R., BALENSIEFER, S., GROSSMAN, \nD., HUDSON, R. L., MOORE, K. F., AND SAHA, B. Enforcing isolation and ordering in STM. In PLDI 2007. \n[31] STANDARD PERFORMANCE EVALUATION CORPORATION. SPEC JVM98, 1998. See http://www.spec.org/jvm98. [32] \nSTANDARD PERFORMANCE EVALUATION CORPORATION. SPEC JBB2000, 2000. See http://www.spec.org/jbb2000. [33]VITEK,J., \nANDBOKOWSKI,B. Con.ned types.InOOPSLA 1999. [34]VIVIEN,F., AND RINARD,M. Incrementalized pointer and \nescape analysis. In PLDI 2001 (2001). [35]VON PRAUN,C., AND GROSS,T.R. Object race detection. In OOPSLA \n2001. [36]VON PRAUN,C., AND GROSS,T.R. Static con.ict analysis for multi-threaded object-oriented programs. \nIn PLDI 2003. [37]WIMMER,C., ANDM\u00a8\u00a8OSSENBOCK,H. Automatic feedback\u00addirected object inlining in the Java \nHotspot virtual machine. In VEE 2007.   \n\t\t\t", "proc_id": "1449764", "abstract": "<p>Transactional memory (TM) is a promising concurrency control alternative to locks. Recent work has highlighted important memory model issues regarding TM semantics and exposed problems in existing TM implementations. For safe, managed languages such as Java, there is a growing consensus towards strong atomicity semantics as a sound, scalable solution. Strong atomicity has presented a challenge to implement efficiently because it requires instrumentation of non-transactional memory accesses, incurring significant overhead even when a program makes minimal or no use of transactions. To minimize overhead, existing solutions require either a sophisticated type system, specialized hardware, or static whole-program analysis. These techniques do not translate easily into a production setting on existing hardware. In this paper, we present novel dynamic optimizations that significantly reduce strong atomicity overheads and make strong atomicity practical for dynamic language environments. We introduce analyses that optimistically track which non-transactional memory accesses can avoid strong atomicity instrumentation, and we describe a lightweight speculation and recovery mechanism that applies these analyses to generate speculatively-optimized but safe code for strong atomicity in a dynamically-loaded environment. We show how to implement these mechanisms efficiently by leveraging existing dynamic optimization infrastructure in a Java system. Measurements on a set of transactional and non-transactional Java workloads demonstrate that our techniques substantially reduce the overhead of strong atomicity from a factor of 5x down to 10% or less over an efficient weak atomicity baseline.</p>", "authors": [{"name": "Florian T. Schneider", "author_profile_id": "81331503470", "affiliation": "ETH, Zurich, Switzerland", "person_id": "P1223170", "email_address": "", "orcid_id": ""}, {"name": "Vijay Menon", "author_profile_id": "81100196596", "affiliation": "Google, Seattle, WA, USA", "person_id": "P1223171", "email_address": "", "orcid_id": ""}, {"name": "Tatiana Shpeisman", "author_profile_id": "81100439172", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223172", "email_address": "", "orcid_id": ""}, {"name": "Ali-Reza Adl-Tabatabai", "author_profile_id": "81100032153", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223173", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449779", "year": "2008", "article_id": "1449779", "conference": "OOPSLA", "title": "Dynamic optimization for efficient strong atomicity", "url": "http://dl.acm.org/citation.cfm?id=1449779"}