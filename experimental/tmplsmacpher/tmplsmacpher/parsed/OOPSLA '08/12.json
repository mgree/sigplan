{"article_publication_date": "10-19-2008", "fulltext": "\n jStar: Towards Practical Veri.cation for Java  j j j Dino Distefano Matthew J. Parkinson Queen Mary, \nUniversity of London, UK University of Cambridge, UK ddino@dcs.qmul.ac.uk Matthew.Parkinson@cl.cam.ac.uk \nAbstract In this paper we introduce a novel methodology for verifying a large set of Java programs which \nbuilds on recent theoretical devel\u00adopments in program veri.cation: it combines the idea of abstract predicate \nfamilies [24 26] and the idea of symbolic execution and abstraction using separation logic [9]. The proposed \ntechnology has been implemented in a new automatic veri.cation system, called jStar, which combines theorem \nproving and abstract interpretation techniques. We demonstrate the effectiveness of our methodology by \nusing jStar to verify example programs implementing four popular de\u00adsign patterns (subject/observer, \nvisitor, factory, and pooling). Al\u00adthough these patterns are extensively used by object-oriented de\u00advelopers \nin real-world applications, so far they have been highly challenging for existing object-oriented veri.cation \ntechniques. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Program Veri.cation; D.3.3 \n[Programming Languages]: Language Constructs and Features Classes and inheritance General Terms Languages, \nTheory, Veri.cation Keywords Separation Logic, Modularity, Classes, Design Pat\u00adterns 1. Introduction \nIn the last few years speci.cation and veri.cation of object-oriented programs have seen considerable \nadvances thanks to the introduc\u00adtion of new technologies and tools which are becoming more ma\u00adture [2,6,7,10,17,30]. \nDespite this remarkable progress, real-world applications still present challenging problems for the \nveri.cation world. A noto\u00adrious example is given by design patterns [11], which are largely used in practice, \nand yet, many of their intricate idioms are still far beyond the reach of the current state of the art \n[16]. Some key challenges in verifying object-oriented programs are: Properties across multiple objects \nWe need to be able to express properties about several interacting objects from many different classes. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA \n08, October 19 23, 2008, Nashville, Tennessee, USA. Copyright c &#38;#169; 2008 ACM 978-1-60558-215-3/08/10. \n. . $5.00 Call-backs Methods often make calls that in turn will call the original object. This schema \ncan cause great dif.culty when one tries to verify it using class/object invariant based approaches. \nModular veri.cation Veri.cation must deal with a single class in isolation. Adding new classes cannot \ninvalidate the veri.cation of pre-existing classes, and changing implementations while preserving speci.cation \nshould only require the re-veri.cation of the changed code. In recent work, Parkinson and Bierman [25,26] \nproposed a mod\u00adular veri.cation technique that addresses these problems. Although theoretically useful, \nthis work has been criticised for not demon\u00adstrating its practical utility by providing an automated \ntool [18,28]. In this paper we address this criticism, by automating these novel theoretical foundations, \nand hence bringing them closer to being applicable to real programs. We have extended the abstraction \ntech\u00adniques developed for separation logic [9] and married them with these theoretical foundations. The \nresulting combination has given encouraging practical results in the veri.cation of four popular de\u00adsign \npatterns. Contributions. The contributions of this paper can be summa\u00adrized as follows. 1. An automatic \nveri.cation tool based on separation logic aiming at object-oriented programs written in Java. The tool, \ncalled jStar, integrates two essential parts: A (general) theorem prover for separation logic tailored \nto object-oriented veri.cation.  A (general) symbolic execution and abstraction technique for separation \nlogic tailored to object-oriented veri.cation. With the help of our theorem prover, the abstract interpre\u00adtation \nis able to perform .xed-point computation on strong properties resulting by the combination of heap information \nas well as data contents. The loop invariant is guessed auto\u00admatically, minimizing the burden of veri.cation. \n 2. We bring succinct separation logic speci.cation to the world of automatic object-oriented veri.cation. \nPre/post specs in our speci.cation language are simple. Even for intricate examples, such us the observer \nand visitor patterns, which involves proper\u00adties of complex heap-allocated objects, the pre/post are \nstraight\u00adforward. 3. We provide experimental evidence of the effectiveness of our approach by the automatic \nveri.cation of four popular design patterns (visitor, subject/observer, factory and pooling). These patterns \ntogether are a serious challenge for any other state of the art object-oriented veri.cation technique \nbecause of their intense use of aliased global state.  The paper is organized as follows. We start by \nintroducing jStar with a series of examples, \u00a72. We begin with an easy illustrative example and then \npresent how we have veri.ed the design patterns. We then give details on the architecture of jStar \u00a73, \nand then introduce the theory behind the tool: the theorem prover \u00a74, the symbolic execution \u00a75, and \nthe abstraction techniques \u00a76. We give an overview of related work, \u00a77, and future work \u00a78. Finally, \nwe conclude in \u00a79. j 2. jStar by Example In this section we demonstrate the veri.cation of a few simple \nprograms and several design patterns. 2.1 Cell/Recell Inheritance We begin by presenting a simple example \nof inheritance to illustrate the key concepts behind jStar. Consider two classes Cell and Recell: class \nCell {class Recell extends Cell { int val; int bak; void set(int x) {void set(int x) {val=x; bak=super.get(); \nsuper.set(x); }} int get() {int get() {return val; return super.get(); }} }} The Cell class has a val \n.eld, which is updated by the set method and its value is returned by the get method. The subclass Recell \nhas an additional .eld bak, which stores the previous value the object was set with. To specify the Cell \nclass, we use a property Val , which describes a Cell s contents. We de.ne the following in the Cell \ns speci.cation: de.ne Val (x, {content= y})=true |x.val.y ; NOTATION 1. This de.nition introduces our \nformulae, which are divided into two parts .|S. The .part concerns facts about stack variables and the \nSpart about heap allocated objects. A formal de.nition will be given in \u00a74. Notice that Val does not \nplace any constraint on stack variables. Henceforth, we simply omit the . part when it is simply true \nas in the de.nition above. The above de.nition de.nes Val (x, {content= y})to mean that the .eld val \nof object x has contents y, provided x is precisely of dynamic type Cell.If x is not of this type, then \nthis de.nition does not constrain the meaning of the property, called abstract predicate family [25]. \nOne can view this like a method de.nition: a method de.nition speci.es the behaviour of a method for \na single class, not for all classes. This de.nition also de.nes Val $Cell(x, {content= y}), which can \nbe used by any of Cell s subclasses. It is independent of the actual dynamic type of x , that is, it \nalways asserts x s val .eld contains y no mater the type of x . We refer to this second property as the \ninternal property as it corresponds precisely to the body of the de.nition for a particular class. Formally, \nwe have the following two axioms: type(x, Cell)=.(Val (x, {content= y}) ..Val $Cell(x, {content= y})) \nVal $Cell(x, {content= y}) .. true |x.val.y where type(x, Cell)means x is precisely of dynamic type Cell. \nThe .rst relates the internal property to the general property. Note that, this does not specify the \nmeaning of Val (x, {content= y})if x is not of dynamic type Cell. The second speci.es the internal prop\u00aderty. \nThis can be used to verify the class, but is not available when verifying other classes. That is, other \nclasses (including subclasses) must be independent of the speci.c internal de.nition of the predi\u00adcate, \nbut may mention the predicate abstractly. For each method, we provide two types of speci.cations: static \nand dynamic [7, 26]. The static speci.cation is used to give a precise speci.cation of the code s behaviour, \nwhile the dynamic is used to give a more abstract view of how the method behaves. More speci.cally, the \nstatic speci.cation is used for super and private calls and for verifying it is sound to inherit a method. \nThe dynamic speci.cation is used for dynamic dispatch and hence must be implemented by all subclasses \n(behavioural subtyping [20]). We can now use these notions to specify the behaviour of the get method: \nint get(): static pre: {|this.val .X} post: {X = return |this.val.X}; dynamic pre: {|Val (this, {content= \nX})} post:{X = return |Val (this, {content= X})}; The .rst speci.cation, the static speci.cation, describes \npre\u00adcisely how the method updates the val .eld.1 It has the precon\u00addition |this.val .X that speci.es \nthat the val .eld of this has the value X (a logical variable2), and the postcondition X =return |this.val.X \nspeci.es that the .eld still has the same value, and this value is returned, X =return. The second speci.cation, \nthe dynamic speci.cation, describes how the method alters the more abstract Val property, rather than \nthe concrete .elds. This enables subclasses to satisfy this speci.cation while changing the concrete \nbehaviour, that is, modifying different .elds. NOTATION 2. For the sake of brevity, in the following \nwe omit the keywords pre and post since it is clear that the .rst formula is the precondition and the \nsecond is the postcondition. Moreover, in the following, we only explicitly indicate the static quali.er, \nand it should be tacitly clear that the spec is dynamic when the static quali.ers is not indicated. We \ncan make the static speci.cation reveal less implementation details by using the Val $Cell property. \nint get() static: {|Val $Cell(this, {content= X }) } {X = return |Val $Cell(this, {content= X }) }; \nThis describes for all subclasses precisely what this method body does, but it does not reveal the .elds \nthat are actually modi.ed. As this pattern of speci.cation is common, we provide a short\u00adhand, which \nde.nes the dynamic speci.cation given above, and the second static speci.cation, with the single speci.cation. \nint get(): {|Val $(this, {content= X }) } {X = return |Val $(this, {content= X }) }; By post-.xing a \n$ onto a property it means interpret as the standard property in the dynamic speci.cation, that is without \nthe $, and as the internal property for the current class in the static speci.cation, in this case Val \n$Cell. 1 In this case, the update of the method get() is the identity function. 2 Sometimes called auxiliary \nor ghost variable. Hence, we can provide both speci.cations for set with: void set(int x): {|Val$(this, \n{content= X })} {|Val$(this, {content= x})}; We must also specify the behaviour of the constructor: void \n<init>(): {|}{|Val$(this, {content= X })} This speci.cation stipulates that constructing an object gives \nVal(this, {content= X }), and from a subclass s super constructor call results in the internal property \nVal$Cell(this, {content= X }). This enables subclasses to use this property without knowing its meaning. \nNow, we turn our attention to the Recell subclass. We must now de.ne what the Val property means for \nthe Recell class. de.ne Val(x, {content= y;old= z})= |Val$Cell(x, {content= y})*x.bak .z ; If x is of \ntype Recell, this de.nes Val(x, {content= y; old= z}) as the property associated to Val from the superclass \nCell and the additional bak .eld has value z . As we have de.ned the property with an additional labelled \nparameter, old, we must also provide a meaning to the property with only the content parameter. In effect, \nwe have width subtyping on the labelled parameters, where missing parameters are existentially quanti.ed. \nHence, this de.nes Val(x, {content= y}) for the Recell class as Val$Cell(x, {content= y}) *x.bak .z where \nz is an existentially quanti.ed variable. Importantly, by con\u00adtaining the Val$Cell property it allows \nthe Recell to make super calls to the Cell s methods, and also inherit methods, as the precondition of \nVal$Cell can be provided for the calls. We can give the speci.cations for Recell directly. void <init>(): \n{|}{|Val$(x, {content= y;old= z})}; int get(): {|Val$(this, {content= X ;old= Y })} {X =return |Val$(this, \n{content= X ; old= Y })}; void set(int x): {|Val$(this, {content= X ;old= Y })} {|Val$(this, {content= \nx;old= X })}; We must verify that these speci.cations are valid behavioural sub\u00adtypes, which follows \nfrom width subtyping of labelled parame\u00adters.  2.2 Visitor Pattern Next, we consider the visitor design \npattern [11]. We present the source code in Figure 1. Our example involves an abstract syntax tree (Ast) \nof integer expressions, which are made of constant in\u00adteger nodes (Const), and plus nodes (Plus) that \nrepresent the addi\u00adtion of two integer expressions. The Ast interface requires that each node can accept \na Visitor. The Visitor interface has two methods: visitC which is invoked when visiting a Const node; \nand visitP for visiting Plus nodes. The accept methods in the Const and Plus nodes simply call visitC \nand visitP respectively. We consider two concrete visitors in this section: Sum, an op\u00aderation that calculates \nthe value of the integer expression; and RZ an operation that simpli.es the integer expression by removing \nall the unnecessary additions of zero. The second is complicated by working in-place and swinging pointers \nwhere necessary. We begin by specifying the interfaces Visitor and Ast. We specify these classes with \nrespect to three abstract properties of the state: Visitor, Ast and Visited. We do not specify what the \nproperties concretely mean as these are only interfaces, and subclasses are free to choose de.nitions. \nIntuitively, Visitor(v, {context= z }) means that v is a visitor ready to visit an expression, and it \nhas some in\u00adternal data z ; Visited(v, {content= x ; context= z ; ast= a}) means that v is a visitor \nthat has visited a tree at a with content x , and the internal data of the visitor was z before it visited \nthis tree. Ast(a, {content= x }) means a is an integer expression with con\u00adtent x . We can see these \nproperties as specifying the protocol of the visitor pattern. We give the interfaces speci.cations as \ninterface Ast { void accept(Visitor v): {|Visitor(v, {context= z })*Ast(this, {content= x })} {|Visited(v, \n{content= x ;context= z ;ast= this})}; }interface Visitor { void visitC(Const c): {type(c, Const ) |Visitor(this, \n{context= z })*Ast(c, {content= x })}{|Visited(this, {content= x ;context= z ; ast= c})}; void visitP(Plus \np): {type(p, Plus ) |Visitor(this, {context= z })*Ast(p, {content= x })}{|Visited(this, {content= x ;context= \nz ; ast= p})}; } We see that accept will be called on an integer expression with a .rst parameter that \nis a visitor, which is ready to visit an integer expres\u00adsion, and when it returns it speci.es the visitor \nmust have visited this expression. The speci.cation for visitP and visitC are almost identical except \nthat this and the parameter are reversed, and they additionally have type information: for example, type(c, \nConst ), which speci.es that c is precisely of type Const. This type informa\u00adtion captures the double \ndispatch calling pattern used by the visitor. To enable us to specify the data associated to the abstract \nsyntax tree, we use two term constructors plus( , ) and const( ). Using this we can de.ne the Ast property \nfor the Const class as export Ast(x, {content= y})= y=const( v)|x.v .v ; This means that x is an integer \nexpression of a constant v , and the v .eld contains that value. Here rather than using de.ne to specify \nthe property, we use export this enables the veri.cation of other classes to use this de.nition, in particular, \nthe visitors, which depend on the internal representation for ef.ciency. Similarly, we de.ne Ast for \nthe Plus class: export Ast(x, {content= y})= y=plus( rv) lv, |x.left . l *Ast(l, {content= lv })  *x.right \n.r *Ast( rv}); r, {content= This means x is a plus of two integer expressions lv and rv, which are contained \nin the Astsinthe left and right .elds respectively. We specify the accept method for Const as (Plus omitted \nfor brevity) void accept(Visitor): {|Visitor(v, {context= z })*Ast(this, {content= x })} {|Visited(v, \n{content= x ;context= z ; ast= this})}; void accept(Visitor) static: {type(this, Const )|Visitor(v, {context= \nz }) *Ast(this, {content= x })} {|Visited(v, {content= x ; context= z ;ast= this})}; interface Ast{public \nvoid accept(Visitor v); } class Const implements Ast{int v; Const(int x) {this.v=x;} public void accept(Visitor \nv){v.visitC(this); }} class Plus implements Ast{Ast left,right; Plus(Ast l, Ast r){ left=l; right=r; \n } public void accept(Visitor v){v.visitP(this); }} interface Visitor{public void visitC(Const c); public \nvoid visitP(Plus p); } class Sum implements Visitor{int amount; public void visitP(Plus p){ p.left.accept(this); \np.right.accept(this); } public void visitC(Const c){amount+=c.v; }} class RZ implements Visitor{boolean \nisZero; boolean isChanged; Ast newl; public void visitC(Const c){if(c.v==0) this.isZero=true; } public \nvoid visitP(Plus p){p.left.accept(this); if(this.isZero) { this.isChanged=false; this.isZero=false; p.right.accept(this); \nif(!this.isChanged) { this.newl=p.right; this.isChanged=true; } }else{ if(this.isChanged){p.left=this.newl; \nthis.isChanged=false; } p.right.accept(this); if(this.isZero){this.isChanged=true; this.newl=p.left; \nthis.isZero=false; }else if(isChanged){p.right=this.newl; this.isChanged=false; }}}} Figure 1. An example \nof visitor pattern. The dynamic speci.cation is identical to the interfaces speci.ca\u00adtion, and the static \nspeci.cation is the same, but with the addition of the dynamic type information. This type information \nis neces\u00adsary to verify the double dispatch calling pattern in the visitor pat\u00adtern. There is a great \ndeal of redundancy in this speci.cation, as it is almost identical to the inherited speci.cation from \nthe interface. The rest of the details of the speci.cation are straightforward and omitted for compactness. \nNow we verify the concrete visitors, starting with the Sum vis\u00aditor. To specify the functional behaviour \nof this visitor we must de.ne a function that sums the integer expression: sum(const(v)) = v sum(plus(l, \nr)) = sum(l)+ sum(r) We can de.ne the Visitor and Visited properties for this class as: de.ne Visitor(x, \n{context= y})=|x.amount .y; de.ne Visited(x, {content= z; context= y; ast= a})= |x.amount .y +sum(z) \n*Ast(a, {content= z}); The Visitor de.nes that the amount .eld has some pre-existing value; and the Visited \nproperty de.nes that the amount .eld con\u00adtains the addition of the pre-existing value y and the summation \nof the integer expression z. The Visited property also contains the Ast that it has just read, this is \nnecessary to allow other visitors to update the structure (see the next example visitor). The method \nspeci.cations is straightforward and therefore omitted. Now, we turn our attention to the second concrete \nvisitor: RZ. This visitor removes all the additions of zero from an expression. Mathematically we .rst \nde.ne a function rz that removes the zeros rz (const(x)) = const(x) 8 > < rz(x) if rz(y)=const(0) rz(plus(x, \ny)) = rz(y) if rz(x)=const(0) > : plus(rz (x), rz(y)) otherwise For example, rz(plus(const(0),plus(const(1), \nconst(0)))) is const(1), and rz(const(0)) is const(0). The Visitor implementation is complicated by the \nin-place na\u00adture of the update, that is the visitor does not allocate any new storage nodes in the expression, \nit simply updates old ones. The Visitor property simply states that the isZero and isChanged .elds are \nboth initially set to false. The newl .eld can have any arbitrary value, and this is indicated by the \nexistentially quanti.ed value z import java.util.*; import java.sql.*; class DBPool{LinkedList<Connection> \nconns; String url,user,password; DBPool(String url,String user, String password){ conns = new LinkedList<Connection>(); \nthis.url = url; this.user = user; this.password = password; } public Connection getResource() throws \nSQLException{if(conns.size()==0) return DriverManager.getConnection(url,user,password); return conns.removeFirst(); \n} public void freeResource(Connection db) throws SQLException{if(conns.size() >= 20) db.close(); else \nconns.add(db); }} Figure 2. Database pool example de.ne Visitor(x, {context= y})= | x.isZero .false() \n*x.isChanged .false() *x.newl .z ; The Visited property is more complex: de.ne Visited(x, {content= z; \ncontext= y; ast= a})= |x.isZero .iz *x.isChanged .ic *x.newl .al *(ic al, {content= rz(z)}) = false() \n|Ast( ||ic = false() |Ast(a, {content= rz (z)})) *(iz = false() .rz(z)= const(zero()) |emp ||iz = false() \n.rz(z)= const(zero()) |emp); We use ||to mean disjunction, which combines two formula (both a pure and \nspatial part) to give a spatial formula. We use emp for the empty spatial formula. First, we relate the \n.elds to existential variables, so they can be used in the rest of an assertion. The next part speci.es \nif iz is true, then the content rz(z) is zero. If iz is false, then it is not zero. Finally, we specify \nthat if ic is true, then al contains the updated integer expression, otherwise the original node a is \nthe updated integer expression. The RZ class highlights the potential compactness of the spec\u00adi.cations. \nThe code for this class is almost incomprehensible, yet the two properties clearly express how the class \nworks, and that it satis.es the functional speci.cation of rz. j  2.3 Connection Pool Ownership Transfer \nNext we present a simple example of a connection pool for a database [12]. This example illustrates ownership \ntransfer [23, 25], that is when a connection is freed with freeResource it should no longer be used. \nWe present the source code in Figure 2. The class has two methods: getResource and freeResource. The \n.rst returns a pointer to an unused database connection. This might have come from its internal cache \nof connections stored in the linked list pointed to by the conns .eld, or it could be a freshly allocated \none from the database library. The second method, freeResource, either closes the connection it is passed, \nor adds the connection to its internal list of connections. Next, we present the speci.cation of these \nmethods: java.sql.Connection getResource(): {|DBPool$(this, {type = t })} {|DBPool$(this, {type = t }) \n*DBConnection(return, {connection= t }) }; void freeResource(java.sql.Connection db): {|DBPool$(this, \n{type = t }) *DBConnection(db, {connection= t }) }{|DBPool$(this, {type = t }) }; The getResource() method \ns pre-condition speci.es we must have a connection pool, DBPool, of some type t , and the postcondition \nspeci.es that we still have this pool, but additional we are returned a connection connected to t , DBConnection. \nHere t is used to represent the database connection strings (url, user and password). Due to the underlying \nseparation logic, we know this connection is separate from any other connection in use. The speci.cation \nof freeResource is the converse, its precondition speci.es that you must have a pool and a connection, \nand the postcondition speci.es you only have the pool. Hence, once freeing a connection you can no longer \nuse the connection. We can de.ne the DBPool property as de.ne DBPool(x, {type=t})= t=sql( password) \n|url, user, x.url . url * x.user . user * x.password .password *  x.conns .y * LinkedList( y, R ) *DBSet(setof \n(R ),t) ; This de.nes that the .elds that store the url, user and password contain the right data, and \nthat the conns .elds contains y , which is a list with contents R , represented by the property LinkedList. \nThe function setof converts a list into a multiset. We use a special predicate DBSet to represent that \neach value in the list points to a database connection. We discuss the precise details of this predicate \nlater in the paper. j 2.4 Factory Pattern The database connection pool in the previous section could \nbe re\u00adfactored to allow greater code reuse. In particular, we could break apart the database speci.c \ncomponent from the pool of resources. We can do this re-factoring with either the Factory pattern or \nthe Template method pattern [11]. We have performed and veri.ed both re-factorings. Here we just present \nthe Factory pattern as the code is simpler, and hence so is the speci.cation. We de.ne a ResourceFactory \ninterface that makes and destructs resources. We can then parametrize a pooling class, ResPool, with \na factory to create the objects that will be pooled. Finally, we make a ConnectionFactory class that \nimplements the ResourceFactory interface. We present the interface and the classes in Figure 3. We give \nspeci.cation to the factory that are very similar to the connection pool from earlier: interface ResourceFactory \n{ Object makeResource(): {|ResourceFactory(this, {type=t })} {|Resource(this, {handle= return; type= \nt }) *ResourceFactory(this, {type=t })}; import java.util.*; import java.sql.*; public interface ResourceFactory<R,E \nextends Exception>{public R makeResource() throws E; public void destructResource(R r) throws E; } public \nclass ResPool<R,E extends Exception>{LinkedList<R> resources; ResourceFactory<R,E> rf; ResPool(ResourceFactory<R,E> \nrf){ resources=new LinkedList<R>(); this.rf=rf; } public R getResource() throws E{ if(resources.size()==0) \nreturn rf.makeResource(); return resources.removeFirst(); } public void freeResource(R r) throws E{ \nif(resources.size()>=20) rf.destructResource(r); else resources.add(r); }} class ConnectionFactory implements \nResourceFactory<Connection,SQLException>{String url, user, password; ConnectionFactory(String url, String \nuser, String password){this.url=url; this.user=user; this.password=password; } public Connection makeResource() \nthrows SQLException{return DriverManager.getConnection(url,user,password); } public void destructResource(Connection \nc) throws SQLException{c.close(); }} Figure 3. Factory pattern void destructResource(Object r): {|Resource(this, \n{handle= r; type= t }) *ResourceFactory(this, {type=t })}{|ResourceFactory(this, {type=t })}; } However, \nthere is one key difference rather than specify precisely what resource will be returned, and consumed, \nwe use a property Resource(this, {handle= return; type= t }) that is dependent on the particular implementation \nof the ResourceFactory. This enables each implementation to specify what Resource means, for exam\u00adple, \none class speci.es it as a database connection and another as an XSLT processor. We can then specify \nthe ResPool class as class ResPool { de.ne ResPool(x, {factory= f;type= t})=|x.resources .y *x.rf .f \n*ResourceFactory(f, {type=t})* LinkedList( y, R )*IterRes(setof (R ),f,t); void <init>(ResourceFactory \nrf): {|ResourceFactory(rf, {type=t })}{|ResPool$(this, {factory= rf;type= t })}; void freeResource(java.lang.Object \nr): {|ResPool$(this, {factory= f ;type= t }) *Resource(f, {handle= r; type= t })}{|ResPool$(this, {factory= \nf ;type= t })}; java.lang.Object getResource(): {|ResPool$(this, {factory= f ;type= t })}{|ResPool$(this, \n{factory= f ;type= t }) *Resource(f, {handle= return;type= t })}; } Here, we must use a new predicate \nIterRes(X, f, t) to mean that there exists a Resource(f, {handle= i; type= t}) predicate for each element \ni of the set X . In separation logic, this would be given with the iterated separating conjunction: \u00aei.X \nResource(f, {handle= i; type= t}) The de.nition of ResPool means that for each element of the list from \ny ,wehavea Resource predicate, that was created by the ResourceFactory f . Finally, in the ConnectionFactory \nspeci.cation we de.ne the ResourceFactory and Resource properties: de.ne ResourceFactory(x, {type=t})= \nt =sql(url, password)|x.url . user, url * x.user . password; user *x.password . export Resource(x, \n{handle= y; type= t})= |DBConnection(y, {connection= t}); The most important part of this speci.cation \nis that the Resource de.nition is exported. This means that, since Resource is de.ned in the ConnectionFactory \nspeci.cation then any class can use the following fact in its veri.cation: type(f, ConnectionFactory \n)|Resource(f, {handle= x;type= t}) =.DBConnection(x, {type =t}) and the reverse type(f, ConnectionFactory \n)|DBConnection(x, {type=t}) =.Resource(f, {handle= x; type= t}) This means that any client of the resource \npool, who knows the type of the internal factory is a ConnectionFactory, will know it allocates and deallocates \ndatabase connections. We omit the method speci.cations as they follow directly from the interface. j \n 2.5 Subject/Observer We conclude our illustration of jStar by demonstrating an example of the subject/observer \npattern [11]. This has been a popular design pattern for challenging recent veri.cation techniques [1, \n3, 15, 18]. We present an example subject/observer pattern in Figure 4. We explain the code through its \nspeci.cation. We can specify the properties of the IntegerList as: de.ne Subject(s, {obs= O; vals= V \n})= |SubjectInternal$IntegerList(s, {obs= O})* SubjectData(s, {vals= V }); de.ne SubjectInternal(s, \n{obs= O})= |s.observers .o *LinkedList( o, O); export SubjectData(s, {vals= V })= |s.list . l *LinkedList(l, \nV );  public interface Subject{public void addObserver(Observer o); public void removeObserver(Observer \no); } public interface Observer{public void update(Subject o); } public class IntegerSize implements \nObserver{IntegerList bag; int size; public IntegerSize(IntegerList bag){ this.bag=bag; bag.addObserver(this); \n } public void update(Subject o){ if(o==bag) size=bag.list.size(); }} public class IntegerList implements \nSubject{ LinkedList list=new LinkedList(); LinkedList observers=new LinkedList(); public void beginModi.cation(){} \npublic void endModi.cation(){notifyObservers();} public void addObserver(Observer o){ observers.add(o); \no.update(this); } public void removeObserver(Observer o){ observers.remove(o); } private void notifyObservers() \n{ Iterator i=observers.iterator(); while(i.hasNext()) { Observer o=(Observer)i.next(); o.update(this); \n }}} Figure 4. Source code for Subject/Observer example exportSubjectObs(s, {obs= O; vals= V })= |Subject$IntegerList(s, \n{obs= O; vals= V }) *ObsSet(O, V, s); We de.ne the Subject property as being composed of two parts the \ndata, SubjectData, and the internal state, SubjectInternal. The latter represents the internal structures \nfor keeping the list of Observers, and the former is the data associate to the subject, in this case \na list of Integers. We additionally provide a predicate to represent the aggregate structure of the set \nof Observers and the subject: SubjectObs. This property is exported, so that clients can access the individual \nobservers as well as the whole aggregate. We also export the SubjectData so that clients can manipu\u00adlate \nthe state associated to the IntegerList using the beginModi.cation and endModi.cation methods. The client \nshould call beginModi.cation to gain access to the internal data, and upon completion of the mod\u00adi.cation \nshould call endModi.cation. void beginModi.cation(): {|SubjectObs$(this, {obs= O ; vals= V }) }{|SubjectInternal$(this, \n{obs= O }) *SubjectData(this, {vals= V }) *ObsSet( V, this) }; O, void endModi.cation(): {|SubjectInternal$(this, \n{obs= O }) *SubjectData(this, {vals= V 2}) *ObsSet( V, this) } O, {|SubjectObs$(this, {obs= O ; vals= \nV 2}) }; The speci.cation of beginModi.cation means that we can call the method if we have the property \nof the aggregate structure, and after the call we have the structure broken into parts, includ\u00ading the \nSubjectData property, which allows the client to mod\u00adify the associated data. The speci.cation of endModi.cation \ntakes a SubjectData predicate with a potentially different value, V 2 to the observers, and makes the \nobservers consistent with the new value. Note, if we had exported the Subject property as well, then \nfor this example the beginModi.cation method could be removed. We provide methods for adding and removing \nobservers from the aggregate structure: void addObserver(Observer o): {|SubjectObs$(this, {obs= O ; vals= \nV }) *Observer(o, {vals= v 2; subject= this}) }{|SubjectObs$(this, {obs= add(o,O); vals= V }) }; void \nremoveObserver(Observer o): {|SubjectObs$(this, {obs= add(o,O); vals= V }) } {|SubjectObs$(this, {obs= \nO ; vals= V }) *Observer(o, {vals= v 2; subject= s }) }; The .rst simply takes the aggregate and an Observer, \nand puts it into the aggregate, and the latter removes an observer from the aggregate. Finally, we have \na method notifyObservers, which when given a Subject and an out of date set of observers, ObsSet, will \nupdate the set of observers to the correct value: void notifyObservers(): {|Subject$(this, {obs= O ; \nvals= O, V }) *ObsSet( V2, this) }{|Subject$(this, {obs= O ; vals= O, V }) *ObsSet( V, this) }; The \nbehaviour of notifyObservers depends on the speci.cation of the Observer interface: interface Observer \n{void update(Subject s): {|Observer(this, {vals= v ; subject= s}) *SubjectData(s, {vals= v 2}) }{|Observer(this, \n{vals= v 2; subject= s}) *SubjectData(s, {vals= v 2) }; } This says the Observer will correctly update \nitself to the value current in SubjectData. Finally, we turn our attention to the constructors speci.cation: \nvoid <init>(): {|} {|Subject(s, {obs= empty(); vals= empty()}) }; void <init>() static: {|} {|SubjectData$IntegerList(s, \n{vals= empty()}) *SubjectInternal$IntegerList(s, {obs= empty()}) };  Pattern Time(s) LOC Result Visitor \n0.40 71 Yes Connection Pool 0.06 27 Yes Factory Pattern 0.10 46 Yes Subject/Observer 0.50 49 Yes Table \n1. Experimental results of the example patterns performed with jStar on a 1.66 GHz Intel Core Duo, 2 \nGB Ram. We might have expected the static post-condition of the construc\u00adtor to be Subject$IntegerList(s,{obs= \nempty(); vals= empty()}) but unfortunately, this is not true. The Subject predicate for this class contains \nthe SubjectData property, for the precise type of the object being constructed. However, as this constructor \nis po\u00adtentially inherited we do not know the object is precisely of type IntegerList: it could be a subtype. \nHence, we can only provide this weaker speci.cation. However, this allows subclasses to change the SubjectData \npredicate and still inherit the code from this classes methods: the veri.cation of all the instance methods \nof class is ab\u00adstract in the de.nition of SubjectData. j  2.6 Experimental Results on Patterns Veri.cation. \nWe have run jStar on all the pattern examples from Section 2. Table 1 reports the results. All static \nand dynamic specs for every example were automatically veri.ed. The Result column shows that all patterns \nmeet their speci.cations. j 3. The jStar Architecture Next, we give a global overview of jStar s internal \nstructure, de\u00adpicted in Figure 5. A detailed description of each component will be given in the next \nsection of this paper. jStar is composed by two main components: a theorem prover and the symbolic execu\u00adtion \nmodule. The prover is called by the symbolic execution during the veri.cation process to decide implications \nor to perform frame inference. The symbolic execution module is responsible for the .xed point computation \nof invariants. jStar accepts programs written in Jimple, which is one of the Soot toolkit intermediate \nrepresentations [29] designed to analyze Java programs. Hence, we use Soot for parsing Java into Jimple, \nthe latter is then parsed by jStar into its internal data structures. jStar is implemented in OCaml. \nOther input .les are used by jStar for the veri.cation of a Java program: (1) pre/post condition speci.cations \nof the program s methods as well as the speci.cation of the methods it calls; (2) the logic rules i.e., \nthe theory used by the theorem prover to decide entailment and other implications; and (3) the abstraction \nrules, which are special rules used to ensure convergence in the .xed-point computation of loop-invariants. \nAbstraction rules are an extension of the logical rules for deciding implications. j 4. Theorem Prover \nNext, we describe our abstract theorem prover for separation logic. The design is based on the entailment \nchecker in smallfoot [4]. 4.1 Formulae Let Var be a countable set of program variables (ranged over by \n x,y,...) and Var a countable set of existential variables (ranged over by y,...). A formula, H, is a \nrestricted form of separation x, Logic Rules Abstraction rules Spec: pre/post Java program Jimple code \n Figure 5. jStar architecture logic formula, de.ned by the following grammar. E ::= x|x |nil |... P ::= \nE = F |E =.F |p(E) S ::= s(E) . ::= true |P .. S ::= emp |S *S H ::= . .S Note that we use the letter \nH for formulae and in the following sections we use formulae to represent symbolic heaps. Given a formula \nH =. .S, we call . the pure part, whereas S is called the spatial part. We denote by Heaps the set of \nall symbolic heaps and we use hatted variables to (implicitly) denote existentially quanti.ed variables. \nThat is, . .S is a shorthand for .x 1,...,x n.. .S where x 1,...,x n are the existential variables occurring \nin . .S. The pure part . is a conjunction of pure predicates which states facts about the stack variables \nand existential variables (e.g., x = nil), but are not concerned with heap allocated objects. The spatial \npart is the *conjunction of spatial predicates, i.e., related to heap facts. In separation logic, the \nformula S1 *S2 holds in a heap that can be split into two disjoint parts where in one of them the only \nallocated memory is described by S1 and in the other only by S2. We usea .eld splitting model, i.e., \nin our model, objects are considered to be a compound entities composed by .elds which can be split by \n*.3 Notice that if S1 and S2 describe the same .eld of an object than S1 *S2 implies false. The predicate \nemp says that there is nothing allocated in the heap. The prover allows the de.nition of arbitrary pure \npredicates pand spatial predicates s. Here it is worth to mention a fundamental rule which gives the \nbases of local reasoning in separation logic: {H1}C {H2} Frame Rule {H1 *H}C {H2 *H} 3 An alternative \nmodel would consider the granularity of *at the level of objects. In that case, objects cannot be split \nby *since they are the smallest unit in the heap. (Expressions) (Pure predicates) (Spatial predicates) \n(Pure part) (Spatial part) (Formula) where C does not assign to H s free variables [22]. The frame rule \nallows us to circumscribe the region of the heap which is touched by C, (in this case H1), perform local \nsurgery, and combine the result with the frame, i.e. the part of the heap not affected by the command \nC (in this case H). In the rest of the paper we make intensive, although often tacit, use of the frame \nrule. j  4.2 Proof Rules Our prover works on sequents of the form Sf |.1 |S1 f.2 |S2 We call .1 |S1 \nthe assumed formula, .2 |S2 the goal formula, and Sf the subtracted (spatial) formula. The semantics \nof a judge\u00adment are: .1 .(Sf *S1)=..2 .(Sf *S2) The subtracted formula, Sf , is used to allow predicates \nto be re\u00admoved from both sides without losing information. This makes .nding complete proof rules easier, \nwhile guaranteeing termina\u00adtion. The prover has built in simpli.cation rules. We present just two here: \nSf *S |.1 |S1 f.2 |S2 Sf |.1 |S1 *S f.2 |S2 *S Sf [E/x] |.1[E/x] |S1[E/x] f.2[E/x] |S2[E/x] Sf |.1 .x= \nE |S1 f.2 |S2 These rules are used to prove the implications, but can also be supplemented by user supplied \nrules, for example: rule .eld remove1: ||.eld(?e1,?e2,?e3) f|.eld(?e1,?e2,?e4) if .eld(?e1,?e2,?e3) ||f?e3=?e4 \n| The empty parts of the sequent are simply preserved, and the ?e1, ?e3, ?e2 and ?e4 are variables that \ncan be uni.ed with any expres\u00adsion (as opposed to e, which can only be uni.ed with existential variables4). \nThe de.nition is equivalent to the following rule: Sf *.eld(E1,E2,E3) |.1 |S1 f.2 .E3 = E4 |S2 Sf |.1 \n|S1 *.eld(E1,E2,E3) f.2 |S2 *.eld(E1,E2,E4) This can be read as saying, if you have the same .eld on \neither side of the entailment, then they must have the same value. We can specify a property is true \nof either the subtracted or assumed formula by placing it on the far left hand side of a sequent. rule \n.eld .eld contradiction : .eld(?e1,?e2,?e3) *.eld(?e1,?e2,?e4) ||f| if This rule is actually equivalent \nto .eld(E1,E2,E3) *.eld(E1,E2,E4) .Sf *S1 Sf |.1 |S1 f.2 |S2 The rule means if the same .eld is contained \nin either of the sub\u00adtracted or assumed formula, then we have assumed a contradiction (because of the \nproperty of *in separation logic as discussed in Section 4.1) and the proof is complete. The user of \nthe theorem prover can instantiate our framework with any collection of these rules, by giving in input \nthe appropriate Logic Rules .le. 4 In all the jStar s input .les existentially quanti.ed variables are \npre.xed with an underscore. The prover simply uses these rules for proof search. For entail\u00adment checking \nthe following basic axiom is used. Sf |.1 |emp ftrue |emp As an example let us describe some of the rules \nused for the Connection Pool pattern in Section 2.3. There, we described a DBSet(S,t) predicate, which \nrepresented a set of connections S with parameter t. In separation logic, we would represent this as \n\u00aei.S DBConnection(i,t) We can encode this into the prover as follows. We represent sets with three functions \nadd(x,S), union(S1,S2) and empty(), which mean add x to the set S, combine the sets S1 and S2, and the \nempty set, respectively. We then encode DBSet as follows: rule dbsetleft add: ||DBSet(add(?x,?y),?t) \nf| if ||DBSet(?y,?t) *DBConnection(?x,{connection = ?t}) f| rule dbsetleft union: ||DBSet(union(?x,?y),?t) \nf| if ||DBSet(?y,?t) *DBSet(?x,?t) f| rule dbsetleft empty: ||DBSet(empty(),?t) f| if ||f| We show only \nthe left hand rules, and have a similar three right hand rules. Finally, we present a rule that allows \nus to try to unify these more complex terms rule DBSet : ||DBSet(?x,?y) f|DBSet(?z,?y) without ?x!=?z \nif DBSet(?x,?y) ||f?x=?z |or ||DBSet(?x,?y) f?x!=?z |DBSet(?z,?y) Here without ?x!=?z means do not apply \nthis rule if the inequality is present in the sequent. This ensures we only apply this rule once. The \nor means try to prove the .rst premise, and if that fails try the second, hence this rule demonstrates \nthe backtracking of the theorem prover. It says try to prove ?x=?z, and if you fail try something else. \nThis rule is incomplete, and hence other similar rules for add, union and empty are added. The prover \nalso can be extended with rewrite rules. The sum de.nition from earlier is converted to: rewrite sum \nplus : sum(plus(?x,?y)) = sum(?x) + sum(?y) rewrite sum const : sum(const(?n)) = ?n These rewrite rules \nare used to simplify terms. Frame Inference. A key part of symbolic execution requires frame inference, \nthat is given two formula (heaps) H1 and H2 .nd a third H3 such that H1 =.H2 *H3 . As with smallfoot, \nwe can .nd these by simply altering the basic axiom to addToFrame(.1 |S1) Sf |.1 |S1 ftrue |emp   nil \nFigure 6. The heap described in Example 1. This collects all the leftover formulae, .1 |S1, from the \nproof, and by taking the disjunction of these formulae forms the frame H3. Consider the following example \ninference .eld(X, \"val\",Z) |v = Z |.eld(X, \"bak\",W) ftrue |emp .eld(X, \"val\",Z) |true |.eld(X, \"bak\",W) \nfv = Z |emp emp |true |.eld(X, \"val\",Z) *.eld(X, \"bak\",W) ftrue |.eld(X, \"val\",v ) Here we .nd the frame \nto be v = Z |.eld(X, bak ,W). This says we have the bak .eld spare, and the existential variable v has \nbeen uni.ed with Z. j 5. Symbolic Execution Next, we de.ne our symbolic execution for object-oriented \npro\u00adgrams taking inspiration from [5, 9]. A symbolic execution de.nes the effect of a Jimple command \non a symbolic state. Symbolic states are speci.ed in terms of separation logic formulae. 5.1 Symbolic \nHeaps Let FNames, CNames, TNames and MNames be a countable set of .eld, class, type and method names \nrespectively. A signature of an object .eld/method is a triple (C: tf).CNames \u00d7TNames \u00d7(FNames .MNames) \nindicating that the .eld f in objects of class C has type t.In the following we indicate by Sig the set \nof all signatures and by ., .1,... its elements. The predicate x.(C: tf).E states that the object denoted \nby x points to the value E by the .eld f. In the examples section, we omitted the class and type parame\u00adters \nfor clarity, but they are essential in the symbolic execution for dealing with .eld shadowing. EXAMPLE \n1. The symbolic heap x.(NodeLL: NodeLL next).y *x.(NodeLL: int val).0* y.(NodeLL: NodeLL next).nil *y.(NodeLL: \nint val).0 describes a heap where there are precisely two allocated objects (of class NodeLL) x and y \nlinked by the next .eld and whose value is initialized to 0. Figure 6 shows a pictorial view of this \nheap. The de.nition of class NodeLL is class NodeLL { int val; NodeLL next; } j  5.2 Rules for Symbolic \nExecution. Symbolic execution implements the function: exec : Stmts \u00d7Heaps .P(Heaps) .{T} which takes \na Jimple statement and a heap and returns a set of element Tindicating that there is a possible error. \nTable 2 de.nes the transformations for basic commands which implement exec. The rule Assignment 1, when \nexecuted in a state H adds the information that in the resulting state x is equal to E. As in stan\u00addard \nHoare/Floyd style assignment, all the occurrences of x in H, and E are replaced by a fresh existential \nquanti.ed variable x . The Mutation rule updates (in-place) the value of the .eld f of object x with \nvalue E2. The Look-up rule adds an equality between x and the content of the .eld f of object E to the \nresulting state. As for Assignment 1, the occurrences of x in the input state is replaced by a fresh \nexistential variable x in the output state. The Return rule assigns the value to be returned to the special \nvariable ret which will be replaced when the control .ow exits the method. The rule Invoke deals with \nmethod invocation. The resulting state is determined by the function jsr which is applied to the specs \nof the method with signature (C: tm). In Jimple there are two main kinds of invocation: instance invoke \nand class invoke. Here, we focus on instance invokes as the class invokes are trivial.5 An instance of \nin\u00advoke can be either specialinvoke or virtualinvoke.6 We use invoke to range over these two possibilities. \nJimple translates super and private calls into specialinvoke, and dynamically dispatched calls into virtualinvoke. \nWe de.ne the following indexed func\u00adtion for speci.cations: specinvoke :Sig .P(Specs) where Specs is \nthe set of all pre/post speci.cation. When invoke is virtualinvoke the function gives all the dynamic \nspeci.cations associated to a method, and for specialinvoke it gives all the static speci.cations. Note \nthat Invoke rule is non-deterministic. The function jsr : Specs \u00d7Heaps \u00d7Var * .Heaps is de.ned as j H' \n*Q[wv/wv/wH' w] if H fP[ww]*jsr({P}m(w ){Q},H,wv)= Totherwise Given a pre/post spec {P}m(w ){Q}, the \ncurrent heap H where the m is called, and the actual parameters wv, jsr invokes the theorem prover for \nthe following frame inference question: ' H fP[wv/ww] *H that is, the prover attempts to .nd a heap H' \nwhich satis.es this entailment. In terms of the method call, H' is the part of the cur\u00adrent heap H which \nis not needed by the method execution, i.e., the frame of the call. The frame H' is then composed with \nthe spec s postcondition Q to form the result of the method call. This mech\u00adanism is sound because we \nappeal to the frame rule of separation logic [13]. When doing frame inference formal parameters are sub\u00adstituted \nby the actual ones. EXAMPLE 2. Consider the class Cell of Section 2 and let us as\u00adsume we are executing \nthe call x.set(7) in the following symbolic heap: Val(x, {content= 3}) *Val(y, {content= 9}) Here x and \ny are objects of class Cell. Recall the spec of the set method: void set(int x): {|Val (this, {content= \nX }) } {|Val (this, {content= x}) }; 5 Class invocations are sometimes called static invocations in Java. \nWe call them class invocations, so as not to confuse them with the statically determined calls to instance \nmethods, such as super calls. 6 Jimple also has interfaceinvoke; we treat this in the same way as resulting \nheaps after the execution of the statement or the special virtualinvoke. class LinkedList { private NodeLL \nhead; private NodeLL tail; void create() { head=null; while (true) { NodeLL n = new NodeLL(); n.next=head; \nhead=n; }} .... } Figure 7. Create method for LinkedList class. The frame inference question for the \ntheorem prover is to .nd a H ' such that: Val(x, {content= 3})*Val(y, {content= 9}) fVal(x, {content= \nX })*H ' The solution frame is H ' = X=3.Val(y, {content= 9}). Com\u00adbining the post-condition of the \nspec with the computed frame we obtain X =3.Val(x, {content= 7})*Val(y, {content= 9}) as X is unused \nit is removed leaving precisely what we expect from this method call. Rule Assignment 2 returns the resulting \nstate given by Invoke where the special variable ret is replaced by x. Similarly, rule New exploits Invoke \ncalling it with the constructor of class C. Rearrangement. The symbolic execution rules manipulate ob\u00adject \ns .elds. When these are hidden inside abstract predicates both Lookup and Mutation require the analyzer \nto expose the .elds they are operating on. This is done by the function rearr :Heaps \u00d7Var \u00d7Sig .P(Heaps) \nwhich exploits the frame inference of the theorem prover. It is de.ned as: rearr(H, x..)={H ' *x.. .v \n|H fH ' *x.. .v }. 6. Fixed Point Computation and Abstraction The jStar s symbolic execution module \nconstructs the control .ow graph of the input Jimple program. Then, for each node of the con\u00adtrol .ow \ngraph it computes the set of all possible symbolic heaps in which the node can be during any execution \nof the program. These sets can be in.nitely large. In order to ensure termination of symbolic execution \nwe apply abstraction in the spirit of abstract interpretation [8], and more speci.cally taking inspiration \nfrom Space Invader [9]. To explain the issue, consider the method create() in Figure 7. The second column \nof Table 3 depicts the heaps computed by symbolic execution at the while-loop point at different iterations \nand starting with the empty heap emp. The table shows that the number of NodeLL predicates grows unboundedly, \nand therefore the .xed-point computation would diverge. However, following Space Invader [9] we can replace \nchains of concrete NodeLL by the more abstract lseg predicate. We loose the information on the precise \nlength of the lists which in many cases is unessential and we will ensure the convergence of the .xed \npoint computation of the loop-invariant. This is done in the third column of Table 3. In the second iteration \nof the abstract execution we do not have any knowledge of the size of the list, and hence in the third \niteration we have reached the .xed point. Abstraction is done by rewriting rules, also called abstraction \nrules which implement the function abs :Heaps .Heaps We apply abstraction after the execution of any \ncommand, this helps to keep the state space small.7 Usually abstraction rules are that is H is replaced \nby H if the condition holds. H is more of the form: condition H *H ' . H *H '' (Abs Rule) ' '' '' abstract \nthan H ' since some unnecessary information is removed (abstracted away). In general, the simpli.cation \nof the formula is done by removing existentially quanti.ed variables that do not ap\u00adpear anywhere else \nin the heap. A concrete example is the following abstraction rule: .Var (H, x) x/ (NL) x, x, nil,H *NodeLL(x, \nv) *lseg( v ' ) . H *lseg(x, nil,v '' ) This rule abstracts away the information that we have at least \ntwo nodes and replaces it with the knowledge that there is at least one node.8 For soundness, the abstraction \nrules must be true implications in separation logic: the more concrete heap should imply the more abstract \none (e.g., in the rule above the left-hand side heap implies the right-hand side one). A framework for \nabstract interpretation of Java programs. We have designed jStar to be very general: that is, we do not \nhave hard-wired abstraction in our symbolic execution (as for example in Space Invader [9]). Instead, \nwe introduce a mechanism to de\u00ad.ne new abstraction rules which can be understood by the theorem prover \nas special kind of logical rules. In this way, new abstract do\u00admains, in the sense of abstract interpretation, \ncan be easily de.ned by providing new sets of abstraction rules. This approach provides jStar with a \ngreat level of .exibility. The abstraction rules accepted by the theorem prover rewrite a frame inference \nquestion into a simpler one. They have the form: condition (jStar Abs) H femp . H ' femp where the optional \ncondition enforces that some variables do not appear anywhere else in H as in the example rule (NL) above. \nHowever, here we have a different format since a formula is sim\u00adpli.ed not directly but as a consequence \nof the simpli.cation of an entailment. The mechanism of abstraction by means of the jStar s abstrac\u00adtion \nrules works as follows. Let s assume we want to abstract the heap H *H ''. For this purpose, the theorem \nprover is asked to .nd the frame of the entailment H *H '' femp Note that since the right-hand side is \nemp, the sought frame is trivially H *H ''. However, suppose we have (jStar Abs) among the set of abstraction \nrules. H matches with the left hand side of 7 Another possibility would be to apply abstraction at loop \npoints only. However, experimental experience has shown that this results in slower analyses. 8 Here \nwe use non empty list segment predicates composed by at least one node. Assignment 1 H, x = E -.x = \nE[ x/x] .H[ x/x] Mutation H *x.(C: tf).E1,x.(C: tf)= E2 -.H *x.(C: tf).E2 Look-up H *E.(C: tf ).E1,x \n= E.(C: tf)-.x = E1[ x/x] .(H *E.(C: tf ).E1)[ x/x] Return H, return E -.ret = E .H (C, t, m) jsr(S, \nH, v)= H ' S .specinvoke Invoke H, invoke x.(C: tm)(v) -.H ' H, invoke y.(C: tm)(v) -.H '  ' Assignment \n2 H, x = invoke y.(C: tm)(v) -.H [x/ret] H[ x/x], virtualinvoke x.(C: void init)(v) -.H ' Allocation \nH, x = new C(v) -.H ' Table 2. Symbolic execution rules for basic command. The primed variable x is \nfresh. Iteration Concrete execution Abstract execution 1 2 3 4 5 head = n .NodeLL(n, nil, v) head = n \n.NodeLL(n, n, v) *NodeLL( n, nil, v ' ) head = n .NodeLL(n, n, v) *NodeLL( n, n ' , v ') *NodeLL( n ' \n, nil, v '') ... ... head = n .NodeLL(n, nil, v) head = n .lseg(n, nil, w) head = n .lseg(n, nil, w) \n Table 3. Computed heaps at while-loop point of method create in concrete and abstract execution. (jStar \nAbs), therefore, the rule .res and the entailment question is replaced by H ' *H '' femp where, presumably, \nH ' is more abstract than H. As noted above, since the right-hand side is emp, the trivial frame for \nthis entail\u00adment is H ' *H ''. The latter is then returned by the prover as an abstraction of H *H '' \n. An example of few useful abstraction rules we use to deal with lists and their values is reported in \nTable 5. Here they are speci.ed with the syntax used in the abstraction .le given as input to jStar. \nThe initial frame inference question is indicated on the top (just below the name of the rule). The resulting \nentailment is at the bottom after the if keyword. The optional condition is speci.ed by the where clause. \nThe keyword notincontext following a variable informally means: that variable does not occur in any other \npredicate in the symbolic heap. The keyword notin prevents two variables to be uni.ed. Hence the rule \nLS LS should be read as: replace the entailment lseg(x, x, nil,s2) *H femp x, s1) *lseg( by lseg(x, nil,s1 \n\u00b7s2)*H femp provided .Var(H).{x}for x/any heap H. The other rules can be explained as follows. LS OBS \nIf an observer ?w is the .rst elements of a list of un\u00adknown type starting at ?x, i.e. ls(?x,?z,cons(?w,?r)), \nthen we can replace the occurrence of the single observer with a non\u00adempty list of observers (i.e. lsObs) \nstarting at ?w and having same subject and value, followed by a possibly empty list (lspe) of unknown \ntype. LS OBS APP1 This rule simply replaces two consecutive lists of observers with the same subject \nand value by one list which is the append of the two original ones. Built-in heap normalizations. Some \nnatural simpli.cations of symbolic heap have been built in the symbolic execution. First of Built-in \n1 P (wx) .P (wx) .. .S P (wx) .. .S Built-in 2 E = x .. .S (. .S)[E/x ] Table 4. Basic built-in abstraction \nfor the pure part. all, Jimple $-variables are existentially quanti.ed after their use. Moreover, the \nother abstractions are: 1. Erasing multiple occurrences of same predicate in the pure part. 2. Abstracting \nunneeded primed variables from the pure part.  The latter two built-in abstractions are formalized by \nthe rules in Table 4. j 7. Related Work The most closely related work is by Chin et al. [7]: they have \nalso built a tool for verifying object-oriented programs with separation logic. They also distinguish \nbetween static and dynamic speci.ca\u00adtions. However, underlying their tool is the standard class invariant \napproach, and we believe this makes it dif.cult for them to express the speci.cations for the design \npatterns veri.ed in this paper. We do not believe they can verify the examples we have presented. Both \nSpec. [2] and JML [6, 17] have been used to specify and verify object-oriented programs. There have been \nseveral exten\u00adsions (for example, [3, 18, 21]) to both systems proposed to han\u00addle the kind of examples \nwe have presented in this paper. We do not believe that either system can currently handle all the examples \npresented in this paper. Smans et al. [28] and Rosenberg et al. [1] have both proposed ways of automating \nthe ideas of dynamic frames [14]. Dynamic Rule LS LS: ||ls(?x, x,?s1) *ls( x,nil(),?s2) f| where x notincontext; \nx notin ?x if ||ls(?x,nil(),app(?s1,?s2)) f| Rule LS OBS: ||ls(?x,?z,cons(?w,?r)) *Observer(?w,{val=?v; \nsubject=?s}) f| if ||lspe( f,?z,?r) *lsObs(?x, f,cons(?w,empty()),?v,?s) f| Rule LS OBS APP1: ||lsObs(?x, \nf,?l,?v,?s) *lsObs( f,nil(),?l2,?v,?s) f| where f notincontext; f notin ?x, ?l, ?v, ?s, ?l2; if ||lsObs(?x,nil(),app(?l,?l2),?v,?s) \nf| Table 5. A sample of abstraction rules dealing with lists and val\u00adues. frames bring many of the advantages \nof separation logic to .rst\u00adorder theorem proving, and may enable them to specify and verify examples \nlike these. Similar to how jStar allows new abstract domains to be de.ned by new abstraction rules, TVLA \n[19] is a parametric tool for de.n\u00ading shape analyses which uses .rst-order logic with transitive clo\u00adsure. \nThe user, by de.ning so-called instrumentation predicates, changes the way the abstraction is done. TVLA \nis based on the concept of canonical abstraction [27], therefore, the fundamental abstraction principle \nis .xed. Depending on the problem to be an\u00adalyzed, instrumentation predicates are used to prevent the \nloss of crucial information. jStar takes the opposite point of view: without abstraction rules nothing \nis abstracted. Abstraction rules are used to explicitly state which unnecessary information can be abstracted \naway. Most importantly, however, TVLA is a system oriented to de\u00ad.ne static analyses whereas jStar is \noriented towards veri.cation. Bogor [10, 30] is an extensible explicit-state model checking framework \nfor Java. Bogor is completely automatic, but only con\u00adsiders heap structures of bounded size. On the \nother hand, jStar,by using appropriate abstractions, can deal soundly with unbounded heaps. We believe \nthat, in special cases, it would not be unreal\u00adistic thinking of using jStar in Bogor style , i.e., by \ndisallowing abstraction and executing only on concrete state spaces. j 8. Future Work At the time of \nwriting, jStar is just a research prototype and, therefore, there is plenty of room for improvement. \nOne of the strengths of jStar is its .exibility, which gives us a substantial power for experimentation \nwith new ideas and techniques. Using different sets of logic/abstraction rules we can obtain different \nways of reasoning about programs or doing abstraction. However, this high-.exibility of our system might \nraise problems. Currently, users are required to have some knowledge of theorem proving in order, for \nexample, not to design unsound logic rules (therefore, at the moment, jStar might be too complex to use \nby programmers). In the future, we are planning to study several kinds of possible automation which may \nhelp in alleviating this problem. We are planning to design several sets of logic and abstraction rules, \nable to cover a wide range of programs, and possessing good properties (e.g., proven to be sound, ensuring \ntermination and progress etc.). We are going to investigate the possibility of mechanizing some steps \nfor producing new rules in a sound way.  Further automation can be provided by studying techniques for \ninferring method speci.cations.  We believe that these features have the potential to reduce the danger \nof untrained users introducing errors. j 9. Conclusions In this paper we described jStar, a new automatic \nveri.cation tool for Java programs, and the theory behind it. jStar s foundations rely on the combination \nof new separation logic advances in theorem proving, symbolic execution, and abstraction. jStar is almost \ncompletely automatic. It requires generally small straightforward pre/post annotations, and loop-invariants \nare com\u00adputed automatically. The practical results on real-world programs are very promis\u00ading. Using \njStar, we have been able to verify an entire implemen\u00adtation of four design patterns. Although used commonly \nwhen im\u00adplementing Java applications, until now, these patterns have been beyond the reach of other state \nof the art automated Java veri.ca\u00adtion approaches. j Acknowledgments. We would like to thank Peter O \nHearn for strongly encouraging us in writing this paper. We also would like to thank the anonymous referees \nfor many interesting suggestions which helped us to improve the paper. The authors have both been supported \nby Royal Academy of Engineering Research Fellowships. j References [1] A. Banerjee, D. Naumann, and S. \nRosenberg. Regional logic for local reasoning about global invariants. In Proceeding of ECOOP, volume \n5142 of LNCS, pages 387 411. Springer, 2008. [2] M. Barnett, K. R. M. Leino, and W. Schulte. The Spec. \nprogramming system: An overview. In Proceedings of CASSIS, pages 49 69, 2005. [3] M. Barnett and D. A. \nNaumann. Friends need a bit more: Maintaining invariants over shared state. In MPC, volume 3125 of LNCS, \npages 54 84. Springer, 2004. [4] J. Berdine, C. Calcagno, and P. O Hearn. Smallfoot: Modular automatic \nassertion checking with separation logic. In FMCO 2005, volume 4111 of LNCS, pages 115 137. Springer, \n2006. [5] J. Berdine, C. Calcagno, and P. W. O Hearn. Symbolic execution with separation logic. In Proceedings \nof APLAS, volume 3780 of LNCS, pages 52 68. Springer, 2005. [6] L. Burdy, Y. Cheon, D. Cok, M. Ernst, \nJ. Kiniry, G. T. Leavens, K. R. M. Leino, and E. Poll. An overview of JML tools and applications. In \nProceedings of FMICS, pages 73 89, 2003. [7] W.-N. Chin, C. David, H. Nguyen, and S. Qin. Enhancing modular \nOO veri.cation with separation logic. In Proceedings of POPL, pages 87 99. ACM, 2008. [8] P. Cousot and \nR. Cousot. Abstract interpretation: A uni.ed lattice model for static analysis of programs by construction \nor approximation of .xpoints. In POPL 77: Principles of Programming Languages, pages 238 252. ACM Press, \n1977. [9] D.Distefano, P.O Hearn, and H.Yang. A local shape analysis based on separation logic. In Proceedings \nof TACAS, volume 3920 of LNCS, pages 287 302. Springer, 2006. [10] M. Dwyer, J.Hatcliff, M.Hoosier, and \nRobby. Building your own software model checker using the bogor extensible model checking framework. \nIn CAV, volume 3576 of LNCS, pages 148 152. Springer, 2005. [11] E. Gamma, R. Helm, R. Johnson, and J. \nVlissides. Design Patterns: Elements of Reusable Object-Oriented Software. Addison Wesley, 1994. [12] \nM. Grand. Patterns in Java. Wiley, second edition, 2002. [13] S. Ishtiaq and P. W. O Hearn. BI as an \nassertion language for mutable data structures. In POPL, pages 14 26, 2001. [14] I. T. Kassios. Dynamic \nframes: Support for framing, dependencies and sharing without restrictions. In FM, volume 4085 of LNCS, \npages 268 283. Springer, 2006. [15] N. R. Krishnaswami, J. Aldrich, and L. Birkedal. Modular veri.cation \nof the subject-observer pattern via higher-order separation logic. In Proceedings of FTfJP, 2007. [16] \nG. Leavens, K. Leino, and P.M\u00a8uller. Speci.cation and veri.cation challenges for sequential object-oriented \nprograms. Formal Aspects of Computing, 19(2):159 189, 2007. [17] G. T. Leavens, A. L. Baker, and C. Ruby. \nPreliminary design of JML: a behavioral interface speci.cation language for Java. SIGSOFT Software Engineering \nNotes, 31(3):1 38, 2006. [18] K. R. M. Leino and W. Schulte. Using history invariants to verify observers. \nIn Proceedings of ESOP, volume 4421 of LNCS, pages 80 94. Springer, 2007. [19] T. Lev-Ami and M. Sagiv. \nTvla: A system for implementing static analyses. In SAS, volume 1824 of LNCS, pages 280 301. Springer, \n2000. [20] B. H. Liskov and J. M. Wing. A behavioral notion of subtyping. ACM TOPLAS, 16(6):1811 1841, \n1994. [21] P. M\u00a8uller, A. Poetzsch-Heffter, and G. T. Leavens. Modular invariants for layered object \nstructures. Science of Computer Programming, 62:253 286, 2006. [22] P. W. O Hearn, J. C. Reynolds, and \nH. Yang. Local reasoning about programs that alter data structures. In Proceedings of CSL, volume 2142 \nof LNCS, pages 1 19. Springer, 2001. [23] P. W. O Hearn, H. Yang, and J. C. Reynolds. Separation and \ninformation hiding. In POPL, pages 268 280, 2004. [24] M. J. Parkinson. Local Reasoning for Java. PhD \nthesis, Computer Laboratory, University of Cambridge, 2005. UCAM-CL-TR-654. [25] M. J. Parkinson and \nG. M. Bierman. Separation logic and abstraction. In POPL, pages 247 258, 2005. [26] M. J. Parkinson and \nG. M. Bierman. Separation logic, abstraction and inheritance. In Proceedings of POPL, pages 75 86. ACM, \n2008. [27] M. Sagiv, T. Reps, and R. Wilhelm. Solving shape-analysis problems in languages with destructive \nupdating. ACM TOPLAS, 20(1):1 50, 1998. [28] J. Smans, B. Jacobs, F. Piessens, and W. Schulte. An automatic \nveri.er for java-like programs based on dynamic frames. In Proceedings of FASE, volume 4961 of LNCS, \npages 261 275. Springer, 2008. [29] R. Vall\u00b4ee-Rai, L. Hendren, V. Sundaresan, P. Lam, E. Gagnon, and \nP. Co. Soot -a java optimization framework. In Proceedings of CASCON 1999, pages 125 135, 1999. [30] \nX.Deng, J.Lee, and Robby. Bogor/kiasan: A k-bounded symbolic execution for checking strong heap properties \nof open systems. In ASE 2006, pages 157 166. IEEE, 2006.   \n\t\t\t", "proc_id": "1449764", "abstract": "<p>In this paper we introduce a novel methodology for verifying a large set of Java programs which builds on recent theoretical developments in program verification: it combines the idea of abstract predicate families and the idea of symbolic execution and abstraction using separation logic. The proposed technology has been implemented in a new automatic verification system, called jStar, which combines theorem proving and abstract interpretation techniques. We demonstrate the effectiveness of our methodology by using jStar to verify example programs implementing four popular design patterns (subject/observer, visitor, factory, and pooling). Although these patterns are extensively used by object-oriented developers in real-world applications, so far they have been highly challenging for existing object-oriented verification techniques.</p>", "authors": [{"name": "Dino Distefano", "author_profile_id": "81100325271", "affiliation": "Queen Mary, University of London, London, United Kingdom", "person_id": "P1223188", "email_address": "", "orcid_id": ""}, {"name": "Matthew J. Parkinson J", "author_profile_id": "81381605618", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1223189", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449782", "year": "2008", "article_id": "1449782", "conference": "OOPSLA", "title": "jStar: towards practical verification for java", "url": "http://dl.acm.org/citation.cfm?id=1449782"}