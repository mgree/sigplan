{"article_publication_date": "10-19-2008", "fulltext": "\n Typestate-like Analysis of Multiple Interacting Objects Nomair A. Naeem Ond.rej Lhot\u00b4 ak D. R. Cheriton \nSchool of Computer Science University of Waterloo Waterloo, Ontario, Canada {nanaeem,olhotak}@uwaterloo.ca \nAbstract This paper presents a static analysis of typestate-like tempo\u00adral speci.cations of groups of \ninteracting objects, which are expressed using tracematches. Whereas typesate expresses a temporal speci.cation \nof one object, a tracematch state may change due to operations on any of a set of related objects bound \nby the tracematch. The paper proposes a lattice-based operational semantics equivalent to the original \ntracematch semantics but better suited to static analysis. The paper de\u00ad.nes a static analysis that computes \nprecise local points-to sets and tracks the .ow of individual objects, thereby en\u00adabling strong updates \nof the tracematch state. The analy\u00adsis has been proved sound with respect to the semantics. A context-sensitive \nversion of the analysis has been im\u00adplemented as instances of the IFDS and IDE algorithms. The analysis \nwas evaluated on tracematches used in earlier work and found to be very precise. Remaining imprecisions \ncould be eliminated with more precise modeling of refer\u00adences from the heap and of exceptional control \n.ow. Categories and Subject Descriptors D.2.4 [Software En\u00adgineering]: Software/Program Veri.cation General \nTerms Veri.cation Keywords typestate, static analysis, tracematches 1. Introduction An object is not \nisolated; it interacts with other objects. For an object, a temporal speci.cation can be expressed using \ntypestate [35]. At any time, the object is in some state, and the state changes when an operation is \nperformed on the ob\u00adject. Many programming errors can be detected by check\u00ading whether undesirable states \nare reachable. A multitude Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. OOPSLA 08, October 19 23, 2008, Nashville, Tennessee, USA. Copyright c &#38;#169; \n2008 ACM 978-1-60558-215-3/08/10. . . $5.00 of typestate checking tools, both dynamic and static, have \nbeen developed [1, 5, 6, 10, 12, 13, 17 22, 24, 29]. Tempo\u00adral speci.cations can be applied to express \nconstraints on the interactions between software components. In this case, the speci.ed protocol may \ninvolve multiple interacting ob\u00adjects from different components. Some newer speci.cation mechanisms can \nexpress temporal properties of multiple ob\u00adjects [1, 10, 20, 29]. These formalisms are mainly intended \nfor dynamic checking. In this paper, we extend techniques from static typestate veri.cation to formulate \nand implement a static analysis of such multi-object temporal speci.cations. The static analysis has \ntwo classes of applications. First, it can be used for sound static program veri.cation. The anal\u00adysis \nis intended to be precise: in the ideal case, all possible violations are ruled out statically, and the \nprogram is there\u00adfore guaranteed to observe the speci.ed protocol. However, it is not always possible \nto rule out all violations statically. In this case, the program can be instrumented with dynamic checks \nthat report violations at run time. The second ap\u00adplication of the static analysis is to reduce the overhead \nof these dynamic checks. If the analysis proves that some in\u00adstrumentation points cannot possibly lead \nto a violation, no instrumentation is required at those points. Thus, the runtime overhead at those program \npoints is reduced. We have chosen tracematches [1] as the formalism for specifying the temporal properties \nto be checked. A trace\u00admatch speci.es which operations are relevant to the speci.\u00adcation, how the operations \nidentify the objects involved, the sequence of operations leading to an undesirable state, and what should \nbe done when a violation is detected at run time. For our analysis, tracematches have two advantages \nover similar formalisms. First, they are widely applicable because their semantics is intuitive and highly \nexpressive compared to other regular-expression-based formalisms. A key issue in de.ning such formalisms \nis how to tease apart the interac\u00adtions between operations on different objects; in some other systems, \noperations on different objects are not cleanly sep\u00adarated. Conceptually, a tracematch executes a separate \ncopy of a .nite automaton for every possible combination of run\u00adtime objects. While other systems require \neach automaton to bind all objects on the .rst state transition, tracematches do not have this restriction. \nSecond, the semantics of trace\u00admatches has been formally speci.ed, which allows us to for\u00admally prove \nthat the static analysis soundly abstracts the se\u00admantics. The original tracematch paper motivates the \ndesign of a declarative semantics from the programmer s point of view, then proves it equivalent to an \noperational semantics better suited for implementation [1]. The operations, and how they bind objects, \nare speci.ed using AspectJ pointcuts, which are in widespread use and have a formal speci.ca\u00adtion [3]. \nWhile the operational tracematch semantics is convenient for a dynamic implementation, it is dif.cult \nto abstract stati\u00adcally because it is de.ned in terms of manipulating and sim\u00adplifying boolean formulas, \na relatively complicated concrete domain. Thus, we have de.ned a new, equivalent semantics based on sets \nand lattices, which are more convenient to rea\u00adson about and to abstract. We have proven the two semantics \nbisimilar. The static analysis uses a provably sound abstrac\u00adtion of the lattice-based semantics. The \nformal de.nitions and correctness proofs are impor\u00adtant because reasoning about interacting objects is \nsubtle. Allan et al. wrote this about their dynamic implementation: In our experience it is very hard \nto get the implemen\u00adtation correct, and indeed, we got it wrong several times before we formally showed \nthe equivalence of the declarative and operational semantics. [1] Similar pitfalls apply when de.ning \na static analysis. A key difference between our analysis and previous work on typestate veri.cation is \nthat in a tracematch, typestate is associated not with a single object, but with a group of ob\u00adjects. \nExisting work on typestate veri.cation (e.g. [17, 18]) generally uses some abstraction of objects and \nadds the cur\u00adrent state to each abstract object. This approach cannot be applied when there is no single \nobject to which the state can be attached. Thus, our analysis uses two separate ab\u00adstractions: the .rst \nmodels individual objects and the second models tracematch state of related groups of objects. The .rst \nanalysis uses a storeless heap abstraction [14, 27] simi\u00adlar to earlier work [11,17,18,23,34]. The focus \nof the paper is on the second analysis, which is novel. Indeed, we present a speci.c object analysis \nonly for the sake of concreteness; the object analysis could be replaced with more precise or cheaper \nvariants if necessary for a particular application. The example in Figure 1 illustrates the kind of property \nthat the analysis veri.es. The method flatten takes a list of lists in, and adds all of their elements \nto the list out. The automaton below the code checks that a list is not updated during iteration, and \nthat every call to next on an iterator is preceded by a call to hasNext. A violation of the property \ncauses the automaton to enter one of the .nal states. The tracematch associated with this automaton (shown \nin Figure 2) has two parameters, the list (c) and the iterator (i). The next and hasNext operations bind \nthe iterator i, update binds the list c, and makeiter binds both. 1 void flatten(List in, List out) { \n2 Iterator it = in.iterator(); 3 while(it.hasNext()) { 4 List l = (List) it.next(); 5 Iterator it2 = \nl.iterator(); 6 while(it2.hasNext()) { 7 Object o = it2.next(); 8 out.add(o); 9 } 10 }  Figure 1. Tracematch \nexample: iterator safety According to the declarative tracematch semantics, a copy of the automaton is \nmade for every possible runtime pair of list and iterator. Each operation causes a transition in those \nautomata consistent with the bindings. For example, the update(c) operation on runtime list object oc \ncauses an update transition in all automaton copies having oc as their list c. Consider what information \na static analysis needs to prove the absence of a violation. First, it needs precise may\u00adalias information \nto determine that the list out updated in line 8 is not aliased with the list in or any of the lists \nit contains, over which the loops iterate. Interprocedural infor\u00admation is necessary because aliases \nmay be made elsewhere; for example, the caller of the method could pass in the same list as both in and \nout. In fact, since the method could be called several times on different lists, context sensitivity \nis useful. In addition, the analysis must ensure that each call to hasNext occurs on the same iterator \nas the subsequent call to next. Although some have suggested using must-alias analysis, proving this \nfact requires more than just knowing that a pair of variables must be aliased. A must-alias analysis \ncan prove that whenever execution reaches a given program point, two variables point to the same object. \nA must-alias analysis does not say anything about the values of variables 1 tracematch(Collection c, \nIterator i) { 2 sym makeiter after returning(i): call(* Collection+.iterator()) &#38;&#38; target(c); \n3 sym next before: call(* Iterator+.next()) &#38;&#38; target(i); 4 sym hasNext before: call(* Iterator+.hasNext()) \n&#38;&#38; target(i); 5 sym update after : (call(* Collection+.add*(..)) || 6 call(* Collection+.clear()) \n|| 7 call(* Collection+.remove*(..)) ) &#38;&#38; target(c); 8 9 makeiter (hasNext+ next)* ( next | hasNext* \nupdate+ (next | hasNext) ) 10 { 11 throw new RuntimeException( Violated safety property. ); 12 } 13 } \nFigure 2. Tracematch source code at different times during execution. It would be dif.cult to extend \nthe notion of must-aliasing to an unambiguous de.ni\u00adtion of the relationship between variables at different \ntimes. For example, it is not true that it2 in line 6 always points to the same object as it2 in line \n7. When control .ows from line 6 to line 7, it2 continues to point to the same iterator, but when control \n.ows from line 7 around the outer loop and back to line 6, the object to which it2 points changes. Thus, \na statement about the relationship between it2 at line 6 and it2 at line 7 would be ambiguous unless \nit somehow con\u00adsidered speci.c control .ow paths between the two points. Instead, in order to reason \nabout the objects pointed to by variables at different points in time, our analysis must track the .ow \nof individual objects along speci.c control .ow paths. To summarize, the analysis requires: 1. precise \nmay-alias information, 2. precise context-sensitive interprocedural information, and 3. .ow-sensitive \ntracking of individual objects along con\u00adtrol .ow paths.  The analysis presented in this paper satis.es \nall three re\u00adquirements. The main contributions of this paper are: 1. We de.ne a lattice-based operational \nsemantics of trace\u00admatches which is better suited to static analysis than the original semantics of Allan \net al. [1]. We have proven that the two semantics are bisimilar. (Section 2) 2. We de.ne a precise static \nabstraction of the lattice-based operational semantics. We have proven that the overall abstraction is \nsound with respect to the operational se\u00admantics. (Section 3) 3. We express the static analysis as instances \nof the IFDS [32] and IDE [33] frameworks which ef.ciently support context-sensitive interprocedural analysis. \n(Section 4)  4. We report experimental results from our implementation of the static analysis. We implemented \nthe analysis in Scala, using the tracematch implementation in the abc compiler [1,2] to provide the intermediate \nrepresentation to be analyzed. (Section 5) Due to space constraints, complete formal details and proofs \nare presented in a separate technical report [30]. 2. Tracematch Semantics Allan et al. [1] de.ne a tracematch \nas follows: DEFINITION 1. A tracematch is a triple (F, A, P ), where F is a .nite set of tracematch parameters, \nA is a .nite alphabet of symbols (operations), and P is a regular language over A. Figure 2 shows the \nsource code that a programmer would write to de.ne the example tracematch discussed in Sec\u00adtion 1. This \ntracematch has two parameters, a Collection c and an Iterator i. Lines 2-7 de.ne the four tracematch \nsymbols. Each symbol is accompanied by an AspectJ point\u00adcut that speci.es where in the base code the \nsymbol occurs. A pointcut may also bind objects from the base code to tracematch parameters. For example, \nthe makeIter point\u00adcut binds the target of the call (the collection) to c and the returned iterator to \ni. Line 9 de.nes the regular language of the tracematch and lines 10-12 provide the code to be exe\u00adcuted \nwhen the tracematch matches at run time. When writing a tracematch, the programmer speci.es P using a \nregular expression. Internally within the abc com\u00adpiler, P is represented as a non-deterministic .nite \nautoma\u00adton accepting the same language. To refer to this NFA, we use the customary notation (Q, A, q0,Qf \n,d), where Q is a .nite set of states, A is the .nite alphabet of tracematch sym\u00adbols, q0 . Q is the \nstart state, Qf . Q is a set of .nal states, and d . Q \u00d7 A \u00d7 Q is a transition relation. A tracematch \nis applied to a program in an existing lan\u00adguage such as Java or AspectJ. The program executes ac\u00adcording \nto the semantics of the base language, but the dy\u00adnamic tracematch implementation maintains additional \nstate to keep track of the con.guration of the tracematch. Allan et al. de.ned a declarative semantics \nof how tracematches ought to work, as well as an operational semantics that they proved equivalent [1]. \nNext, we review the declarative semantics. We then de.ne a new operational semantics based on sets and \nlattices which is more amenable to static analysis. In the technical report, we have proven the lattice-based \nsemantics equivalent to the semantics of Allan et al. Thus, all three semantics are equivalent. 2.1 Declarative \nSemantics of Tracematches The essential part of a tracematch is a regular expression over operations \nof interest (symbols). The dynamic trace\u00admatch implementation checks, for each suf.x of the program trace, \nwhether the suf.x is a word in the language speci.ed by the regular expression. Each such word is a match \nand causes the tracematch body to be executed. When a trace\u00admatch de.nes a safety property, each violation \nof the speci\u00ad.ed property is a match of the tracematch. Much of the expressive power of tracematches \ncomes from their parameters, to which symbols can bind speci.c objects. The tracematch body executes \nfor each suf.x of the trace that matches the speci.ed regular expression with a consistent set of object \nbindings. The declarative semantics makes this precise: a separate version of the tracematch au\u00adtomaton \nis instantiated for each possible set of objects that could be bound to the tracematch parameters. These \nautoma\u00adton versions run independently of each other. An automaton version makes a transition on each \nevent in the trace if the parameters bound by the event are bound to the objects asso\u00adciated with that \nautomaton version. The tracematch body is executed whenever an automaton version reaches an accept\u00ading \nstate; at that point, the automaton version is discarded. We illustrate with an example. Figure 3 shows \na possible trace of the events declared in the tracematch from Figure 2. Each hasNext and next event \nbinds an iterator object, up\u00addate binds a list object and makeiter binds both a list and an iterator. \nWe assume the program creates two list objects x and y and two iterator objects a and b. Thus, there \nare four possible ways in which these objects could be bound to the parameters, which correspond to the \nfour automaton ver\u00adsions shown as columns in Figure 3. Each column includes only those events from the \ntrace that are consistent with the object bindings of each version. The example trace results in matches \nof two automaton versions: the version with c=x and i=a, and the version with c=y and i=b. The .rst of \nthese signals that the collection was modi.ed while it was being iterated. The second signals two consective \nnext events with\u00adout an intervening hasNext event on the same iterator. Trace c=x i=a c=x i=b c=y i=a \nc=y i=b makeiter(x,a) hasNext(a) makeiter(y,b) next(a) hasNext(b) update(x) next(b) next(a) next(b) makeIter \nhasNext next update next hasNext update next next hasNext next next makeIter hasNext next next match \nno no match Figure 3. Declarative semantics of tracematches. Column 1 shows the program trace. Columns \n2 to 5 show automaton versions for different runtime objects bound to tracematch parameters.  2.2 A \nLattice-Based Operational Semantics The abc compiler includes a transformation that implements tracematch \nsemantics at run time. This is done by inserting additional code, which we call transition statements, \nat each point in the base program where a tracematch symbol could match. In the dynamic implementation, \nthe effect of each transition statement is to update the tracematch state to re\u00ad.ect the corresponding \nstate transition and parameter bind\u00adings. The operational semantics is de.ned on the code that results \nafter transition statements have been inserted. Before performing the static analysis, we simplify the \ncode to an intermediate representation (IR) containing only instructions relevant to tracematch semantics. \nThe intrapro\u00adcedural instructions in the IR are: s ::= tr (a, b)| body | v1 . v2 | v . h | h . v | v \n. null | v . new In addition, the IR contains method call and return instruc\u00adtions. In the IR, v can \nbe any variable from the set Var of local variables of the current method. The symbol h repre\u00adsents any \nheap location, such as a .eld of an object or an array element. The two instructions directly relevant \nto tracematches are tr (transition statement) and body (body statement). Each transition statement contains \na pair1 a, b where a . A is one of the symbols of the tracematch and b : F'. Var is a partial map specifying \nthe object to be bound to each tracematch parameter. The map b binds a subset of the pa\u00adrameters; any \nof the parameters may be left unbound. When 1 Allan et al. [1] allow each transition statement to contain \nmultiple tran\u00adsitions, each a pair (a, b). This is necessary because their implementation allows a single \ninstruction to be matched by multiple tracematch symbols. We fully handle this general case in the technical \nreport. The generality does not add expressivity, nor does it make the analysis any more inter\u00adesting, \nonly more complicated. We therefore restrict our discussion in this paper to the common case of a single \npair. tr (a, b) is executed, each automaton version whose object bindings are consistent with the objects \ncurrently pointed to by the variables speci.ed by b performs a transition on the symbol a. A body statement \nis generated immediately after every transition statement tr (a, b) in which a is a symbol on which the \ntracematch automaton contains a transition into an ac\u00adcepting state. The effect of body is to .nd each \nautomaton version in an accepting state, execute the tracematch body for it, and discard it. The remaining \nIR instructions are self-explanatory: they copy object references between variables and the heap, and \ncreate new objects. In the declarative semantics, the number of automaton versions that must be maintained \nis unbounded because the number of objects that could be created by the program is unbounded. This unboundedness \nhinders both a practical dynamic implementation and a static analysis. Therefore, Allan et al. de.ned \nan equivalent operational semantics. For the same reason, we de.ne a different operational semantics \nthat is well suited for static analysis. All three semantics have been proven equivalent. The core construction \nof our semantics is a binding lat\u00adtice. Figure 4 illustrates a sample binding lattice for a pro\u00adgram \nwith three objects o1,o2,o3; in general, the binding lattice is de.ned analogously for the unbounded \nnumber of objects that the program may allocate. Thus, the binding lat\u00adtice is in.nite. In Section 3.2, \nwe will de.ne a .nite abstrac\u00adtion of the binding lattice for use in the static analysis. The binding \nlattice comprises the element ., positive bindings (which are a single object), and negative bindings \n(which contain zero or more objects). The interpretation of each el\u00adement of the binding lattice is a \nset of objects: . represents the empty set, a positive binding represents a single object, and a negative \nbinding represents the set of all objects other than those in the binding. We write T as a synonym for \nthe empty set of negative bindings (which represents all objects). The lattice order corresponds to the \nsubset order on sets of objects: for any pair of bindings d1 [ d2, every object in the set represented \nby d1 is also in the set represented by d2. As a reminder that a set of objects indicates negative bindings, \nwe will always write such a set with a bar above it: O. The bar is only a reminder; it has no semantic \nmeaning. We extend the binding lattice pointwise to the space of functions that map each tracematch parameter \nto an element of the binding lattice. We say that a mapping m . F . Bind is consistent with a given automaton \nversion if the ob\u00adject it associates with each parameter f is in the set repre\u00adsented by m(f). Thus, \neach mapping m can be interpreted as a set of automaton versions. For example, consider the map\u00adping \nc . x, i .{b}. Of the automaton versions shown in Figure 3, only the one corresponding to c=x and i=a \nis consistent with this mapping. Again, the lattice order on T {o1} {o2} {o3} negative bindings {o1o2} \n {o 1o3}{o2o3} {o1o2o3} o3 o2 o1 positive bindings . bottom Figure 4. Concrete Binding Lattice Bind \nF . Bind corresponds to the subset order on automaton versions. The runtime state of a tracematch is \nthen de.ned as a set s of pairs (q, m), where q is a tracematch state, and m . F . Bind. Each pair (q, \nm) indicates that all automaton versions consistent with m are in the state q. When execution begins, \nthe initial tracematch state is the single pair (q0, .f.T). The binding map .f.T is consistent with every \nversion of the automaton, and q0 indicates that all these versions are in the initial state. Whenever \na transition statement executes, some automa\u00adton versions change state and others keep their old state. \nA mapping m in the runtime state must be re.ned to distin\u00adguish the versions whose state changes from \nthose whose state remains the same. In both cases, this re.nement is done using the meet operator of \nthe lattice. For example, consider a tracematch with a single pa\u00adrameter f and the automaton in Figure \n5, and suppose that the transition (a, f . o1) occurs. The automaton ver\u00adsion for o1 should move to state \nqa and all others should remain in state q. From the initial map .f.T, we per\u00adform meets with .f.o1 and \n.f.{o1} to obtain the desired pairs (qa, .f.o1) andq, .f.{o1} . Suppose the transi\u00adtion (b, f . o2) occurs \nnext. We again perform the meets of the existing states with both .f.o2 and .f.{o2} to ob\u00ad } tain (qab, \n.f..) , (qa, .f.o1) , (qb, .f.o2),q, .f.{o1o2} . Since the binding in the .rst pair is ., it is not consistent \nwith any automaton version and can be discarded. The next two pairs correspond to the two automaton versions \nfor o1 and o2 in states qa and qb, respectively, and the .nal pair corresponds to all other automaton \nversions still in the ini\u00adtial state. In the general case of a tracematch with multiple param\u00adeters, \nthere is an additional difference between negative and positive bindings. In the declarative semantics, \nonly the au\u00ad Figure 5. Example automaton tomaton versions consistent in all the parameters bound by \nthe transition statement change state; if an automaton ver\u00adsion is inconsistent in any parameter, its \nstate remains the same. Thus, for the automaton versions that change state, the new map is computed by \nreplacing each m(f) with the meet m(f)no, where o is the object bound to f by the transi\u00adtion statement. \nHowever, for the automaton versions that do not change state, multiple maps must be computed, one for \neach parameter bound by the transition statement. The map computed for each parameter f re.ects the condition \nthat the object bound to f in the automaton version differs from the object bound to f by the transition \nstatement. Thus, the new map for parameter f is constructed by replacing only m(f) with m(f) n{o}, where \no is the object bound to f by the transition statement. A formal de.nition of the transition function \ne that is ap\u00adplied to each pair (q, m) in the tracematch state is given in Figure 6. In the technical \nreport, the semantics is fully for\u00admalized and proven equivalent to the operational semantics of Allan \net al. .(b(f)) if f . dom(b) +0 (b, .) \u00a3 .f. e T otherwise 3.1 Object Abstraction The object abstraction \nrepresents each concrete object by the set of local variables pointing to it. This is the same abstraction \nas the nodes in Sagiv et al. s shape analysis [34]. However, our abstraction tracks only the nodes, not \nthe pointer edges between objects. The set of variables in the abstraction of each object is exact; it \nis neither a may-point-to nor a must-point-to ap\u00adproximation. Since it may not be known statically whether \na given pointer points to the object, the analysis maintains a set .. of abstract objects. This set is \nan overapproximation of all possible objects. That is, if it is possible for some concrete object to \nbe pointed to by the set of variables o., then the set o. must be an element of ... Converesely, the \npresence of o. in .. indicates that there may exist zero or more con\u00adcrete objects which are pointed \nto by the variables in o. and no others. For example, consider a concrete environment in which variables \nx and y point to distinct objects and z may be either null or point to the same object as x. The abstrac\u00adtion \nof this environment would be the set {{x}, {x, z}, {y}}. The abstraction subsumes both may-alias and \nmust-alias relationships. If variables x and y point to distinct objects, .. will not contain any set \ncontaining both x and y. If variables x and y point to the same object, every set in .. will contain \neither both x and y, or neither of them. At run time, a variable cannot point to more than one ob\u00adject \nat a time. Thus, every abstract object except the empty set \u00d8 represents at most one concrete object \nat any given point of execution. This enables precise .ow-sensitive anal\u00adysis including strong updates. \nSpeci.cally, if s is any statement in the IR except a heap load, and if o. is the set of variables pointing \nto a given con\u00ad crete object o, then it is possible to compute the exact set  {.(b(f))} if f = f, of \nvariables which will point to o after the execution of s. (b, ., f) \u00a3 .f,. T otherwise - e 0 The transfer \nfunction [s]ois shown in Figure 7. This property enables the analysis to that performs this computation \n +[a, b, .](q, m) \u00a3 ,,) ,m n e +0 (b, .): d(q, a, q e q .ow-sensitively track individual objects along \ncontrol .ow e -[b, .](q, m) \u00a3q, m n e - 0 (b, ., f): f . dom(b) paths; this was one of the three requirements \nmotivated in e[a, b, .](q, m) \u00a3 e +[a, b, .](q, m) . e -[b, .](q, m) Figure 6. Transition function, in \nthe Lattice-based opera\u00adtional semantics, for tr (a, b) in local variable environment ., which is applied \nto each pair (q, m) in the tracematch state. 3. Static Abstraction The abstraction is presented in two \nparts. The .rst abstrac\u00adtion computes object aliasing relationships. This information is needed to determine \nwhich objects are pointed to by the variables in each transition statement. The second abstrac\u00adtion models \nthe tracematch state. Using this abstraction, the analysis can prove that at certain body statements, \nthe trace\u00admatch cannot be in an accepting state. the introduction. We formalize the property in the accompa\u00adnying \ntechnical report [30, Proposition 2]. To precisely handle the uncertainty in heap loads we use the materialization \nor focus operation [11,17,18,23,34]. The abstract object o. is split into two, one representing the sin\u00adgle \nconcrete object that was loaded, and the other represent\u00ading all other objects previously represented \nby o.. Focus is important to regain the precision lost when an object is no longer referenced from any \nlocal variables, in which case the analysis lumps it together with all other such objects. In order for \na tracematch operation to be performed on such an object, the object must .rst be loaded into a variable. \nAt the load, the focus operation separates the loaded object from the other objects. If multiple tracematch \noperations are then performed on the object, the analysis knows that they are [s]o (o ) \u00a3 . . . . . \no . {v1}o \\ {v1}o \\ {v}o unde.ned if s = v1 . v2 . v2 . o if s = v1 . v2 . v2 . o if s . {v . null, v \n. new}if s . {e . v, tr(T ), body}if s = v . e focus[h ](v, o ) \u00a3 o \\ {v}o \\ {v}, o . {v} if oif o . \nh . h [s]O [h ](O ) \u00a3 [s]o (o ) : o . O o .O focus[h ](v, o ) if s = v . e if s = v . e [s]. (. , h ) \n[s]h (. , h ) \u00a3 \u00a3 [s]O [h ](. ) . {{v}} if s = v . new [s]O [h ](. ) otherwise [s]O [h ] h . {o . . : \nv . o } if s = e . v h otherwise Figure 7. Transfer function for the object abstraction performed on \nthe same concrete object as long as the local variable continues to point to it. In addition to the set \n. of possible abstract objects, the analysis tracks a subset h . . of abstract objects which may have \nescaped to the heap. The focus operation is per\u00adformed only on these escaped abstract objects. Since \nfocus splits one abstract object into two, it can theoretically lead to exponential growth in the abstraction. \nThe escape infor\u00admation was necessary and suf.cient to control this growth in the benchmarks that we \nevaluated. The technical report formally de.nes a correctness rela\u00adtion that ensures that for any concrete \nobject o occurring at run time, its abstract counterpart o is included in . , as well as in h if o is \nreferenced from the heap. We have proven that the transfer function for . and h preserves the correctness \nrelation [30, Theorem 2]. We illustrate the effect of the transfer functions using the example statement \nsequence shown in Figure 8. Statement 1 creates a new concrete object and assigns it to variable x. Correspondingly, \nthe transfer function [s]. creates the ab\u00adstract object {x}. Statement 2 assigns the value of x to some \npointer in the heap. The transfer function [s]h adds the ab\u00adstract object {x} to h since the concrete \nobject represented by this abstract object has been assigned to a heap location. The value of x is then \nassigned to a local variable w in state\u00adment 3. The transfer function [s]o adds the variable w to the \nabstract object {x} since after statement 3 executes, w and x point to the same concrete object. Statement \n4 creates a new concrete object and assigns it to y. Like in statement 1, a new abstract object, {y}, \nis added to . . Statement 5 is a load from the heap. The transfer function [s]O applies the focus operation \nto both {y} and {x, w}. Since the abstract object {y} is not in h , focus[h ](z, {y}) is simply {{y}}. \nHow\u00adever, since {x, w}. h , this abstract object is split into two: {x, w, z} and {x, w}. After statement \n5, . contains three abstract objects: {x, w}, {y}, and {x, w, z}. Statement 6 as\u00adsigns y to x. The transfer \nfunction [s]o is applied to each of the three abstract objects, yielding {w}, {x, y}, and {w, z}. Statement \n7 assigns null to z. This changes {w, z} to simply {w}, yielding the abstract environment {w}, {x, y}. \n. h 1: x . new {x} 2: h . x {x} {x} 3: w . x {x, w} {x, w} 4: y . new {x, w}, {y} {x, w} 5: z . h {x, \nw}, {y}, {x, w, z} {x, w}, {x, w, z} 6: x . y {w}, {x, y}, {w, z} {w}, {w, z} 7: z . null {w}, {x, y} \n{w} Figure 8. Example statement sequence to illustrate transfer functions  3.2 Tracematch Abstraction \nTypestate associates a state with each runtime object. Ex\u00adisting typestate analyses (e.g. [17, 18]) model \neach runtime object using an abstraction similar to the one de.ned in the previous section. The typestate \nanalysis models the state of a runtime object by maintaining a set of possible states for each abstract \nobject. A runtime object o can only be in state q if the abstract object o representing o has q in its \nset of possible states. When the analysis encounters an instruction that changes the state of an object, \nit updates the possible states of the appropriate abstract objects. In our setting, a state is not associated \nwith any single ob\u00adject, but with multiple objects. Thus, we cannot just add the state to any given object \nabstraction. Therefore, our analysis uses a second abstraction to represent the tracematch state. Each \nsuch abstract tracematch state contains within it the ab\u00adstractions of the objects bound by the tracematch. \nWe begin by presenting a simple but inef.cient abstrac\u00adtion of the tracematch state, then discuss the \nre.ned ver\u00adsion that we have implemented in our analysis. Thanks to the lattice-based design of our tracematch \nsemantics, a basic tracematch state abstraction would be straightforward to de\u00ad.ne. Recall that a concrete \ntracematch state is a set of pairs (q, m), where m maps each tracematch parameter to an ele\u00adment of the \nBind lattice. An abstraction of this state could be de.ned by replacing all concrete objects in the Bind \nlattice with their abstract counterparts as de.ned in the previous section. The resulting abstract lattice \nBind has the same structure as Bind, but each positive binding is an abstract object, and each negative \nbinding is a set of abstract ob\u00adjects. The overall abstraction is a set of pairs q, m , where m maps \neach tracematch parameter to an element of Bind . After working out some details, we de.ned a transfer \nfunc\u00adtion on this domain, proved that it correctly abstracts the semantics, and implemented it. However, \non tracematches with multiple parameters, the implementation did not scale to large benchmarks. The key \nreason for this is that the fo\u00adcus operation was applied to every abstract object bound by a tracematch \nstate. Since each focus splits the state into two, the growth was exponential in the number of abstract \nobjects appearing in the tracematch state. In fact, there is little bene.t to performing the focus oper\u00adation \nonce the object has been bound in a tracematch state. The bene.t of the focus operation is that it singles \nout one object, so that if a sequence of transition statements occurs, we know that they occur on the \nsame concrete object. Thus, focus is needed for precise aliasing information at the tran\u00adsition statement \nbefore an object is bound. However, after the object is bound, focusing it simply causes both resulting \nobjects to appear in two separate tracematch states, and does not improve precision of the tracematch \nabstraction. Therefore, in the tracematch state, we replaced the ob\u00adject abstraction (the precise set \nof variables pointing to the object) with an under-and over-approximation: a pair of a must set o! and \nmay set o? represents every concrete object ? pointed to by all variables in o! and only by variables \nin o. In the special case when the must and may sets are equal, we recover the precise set of variables \npointing to the object. The resulting abstract lattice Bind is illustrated for two vari\u00adables x, y in \nFigure 9. We use the notation x? to say that the variable x is in the may set but not the must set, and \nx to say that it is in both sets. Suppose that a tracematch state has bound an object pointed to by x \nand a heap load to y occurs. Instead of focusing the bound object to x and xy, we instead use the join \nof these two, namely xy?, to represent both pos\u00adsibilities. Thus, we avoid focusing objects already bound \nin the tracematch state. Ef.ciency can be further improved for negative bindings. It turns out that the \ntransfer function is independent of the may sets of negatively-bound objects; thus, we need only maintain \nthe must sets. This is because a negative binding T {y }{x} negative bindings {xy} x?y?  x? xy? y? \nx?y positive bindings   . bottom Figure 9. Abstract Binding Lattice Bind indicates that some object \no, is not the object o bound by a given automaton version; knowing that a given variable v may not point \nto o, gives no information about the identity of o, since v could still point to some other object o,, \nthat is also not o. In addition, although a concrete negative binding is a set of objects, all the must \nsets representing these objects can be replaced with their intersection without affecting pre\u00adcision \nof the analysis. Thus, the Bind lattice illustrated in Figure 9 represents a negative binding as simply \na set of variables that de.nitely point to every concrete object that may have been negatively bound. \nIn the technical report, we formally de.ne Bind , show that it is a .nite lattice, and that the abstraction \npreserves the partial order from Bind in Bind [30, Propositions 3 and 4]. The transfer function for the \ntracematch state abstraction for all statements except transition statements is shown in Figure 10. We \nagain draw a bar over each negative binding like we did for the concrete tracematch lattice. The helper \nfunction [s]d is similar to [s]o from the object abstraction, but it updates both the must and may set \nof each abstract binding. On a heap load instruction, it introduces uncertainty into the binding instead \nof focusing it. The transfer function is extended pointwise to maps of bindings by [s]m and to sets of \nabstract state pairs by [s]s . Like for [s]o , we have proven that the adapted function [s]d also tracks \neach concrete object .ow-sensitively along control .ow paths [30, Proposition 5]. The transfer function \nfor transition statements is more complicated. In the operational semantics, all variables men\u00adtioned \nin each transition statement are looked up in the con\u00adcrete environment. How should this lookup be performed \nin the abstract domain? A sound but imprecise and therefore [s]d (.) \u00a3. for all statements s . ! o! \n.{v1},o? .{v1} if s = v1 . v2 . v2 . o? o! \\{v1},o? .{v1} if s = v1 . v2 . v2 . o! . v2 . o . . ?  \no! \\{v1},o? \\{v1} if s = v1 . v2 . v2 . o! . v2 . o !? o ,o \u00a3 [s]do! \\{v},o? \\{v} if s .{v . null,v \n. new}o! \\{v},o? .{v} if s = v . e . . !? o,oif s .{e . v, body} . V .{v1} if s = v1 . v2 . v2 . V \n. . V \\{v1} if s = v1 . v2 . v2 . V V\u00a3 [s]dV \\{v} if s .{v . null,v . new,v . e} . . V if s .{e \n. v, body} [s]m (q, m ) \u00a3 q, .f.[s]d (m (f))  (s ) \u00a3 (q, m ) [s]s [s]m (q,m ).s .{(q0,.f.T)}  Figure \n10. Transfer functions for the tracematch state abstraction for s = tr (a, b). costly approach is to \nconsider that each variable v could point to any abstract object containing v, and to handle all possible \ncombinations of variable values independently. We use a more precise approach that considers compatibil\u00adity \n[34], the notion that some abstract objects cannot possibly correspond to concrete objects in the same \nexecution. For ex\u00adample, the abstract environment may contain both {x} and {x, y} if the object pointed \nto by x is also pointed to by y in some but not all executions. However, at any given instant at run \ntime, y cannot both point and not point to the object pointed to by x; thus, the two abstract objects \nare incompati\u00adble. The analysis therefore considers reduced environments, which are subsets of the abstract \nenvironment . satisfying the following constraints: The objects must all be compatible with each other, \nand with all objects in the tracematch state being updated.  The objects must be relevant: each object \nmust be pointed to by some variable in the transition statement.  The subset must contain some object \npointed to by each variable in the transition statement.  These constraints guarantee that each variable \npoints to a unique abstract object, so every variable can be looked up in the reduced abstract environment. \nIn addition, the con\u00adstraints reduce the otherwise possibly exponential number of subsets of the abstract \nenvironment to a small number, usu\u00adally only one. To be sound, the analysis considers all reduced environments \nsatisfying the constraints. Consider, for example, a transition statement binding x and y to two tracematch \nparameters. Suppose that the ab\u00adstract environment contains abstract objects {x}, {y}, {x, y}and {z}. \nThe subsets {{x}, {y}} and {{x, y}} satisfy the constraints of the reduced environment. The subsets {{x}, \n{x, y}} and {{y}, {x, y}} are not compatible. The subset {{x}, {y}, {z}}is compatible but not relevant \nsince the transition statement does not bind z. The subset {{x}} is not in the reduced en\u00advironment because \nit does not contain any object pointed to by y. It would be expensive to construct the reduced environ\u00adment \nby considering all subsets of the abstract environment and selecting those that satisfy the constraints. \nInstead, we use Algorithm 1, which, by construction, only generates en\u00advironments satisfying the constraints. \nThe algorithm works as follows: at each step, it chooses some abstract object o to remove from the abstract \nenvironment . , and calls itself re\u00adcursively to construct all reduced environments not contain\u00ading o \nand all reduced environments containing o . The set of all reduced environments not containing o is simply \nthe set of all reduced environments of the smaller abstract environ\u00adment . \\{o }. A reduced environment \ncan contain o only if o is relevant and compatible with other abstract objects in the environment. To \ncheck that o is relevant, the algorithm checks that o n relevantVars is non-empty. To ensure that o is \ncompatible with other abstract objects in the environment, the algorithm uses a parameter called forbiddenVars \nto keep track of variables which already appear in some abstract ob\u00adject. When it calls itself recursively \nto construct the reduced environments to which o will be added, it adds all the vari\u00adables in o to forbiddenVars. \nThus, the abstract objects in the environments returned by the recursive call cannot contain any of the \nvariables in o , so they are compatible with o . To each of the reduced environments returned by the \nrecursive call, the algorithm adds o , and the environments are then returned. In the base case, when \n. is empty, the algorithm returns either the empty environment if every relevant vari\u00ad Algorithm 1: reducedEnvs(., \nrelevantVars, forbiddenVars) Input: . : abstract environment Input: relevantVars: set of variables Input: \nforbiddenVars: set of variables Output: set of reduced environments (i.e. sets of abstract objects) \n1 if . = \u00d8 then 2 choose any o from . 3 r1 = reducedEnvs(. \\{o }, relevantVars, forbiddenVars) 4 if \n(o n relevantVars = \u00d8) . (o n forbiddenVars = \u00d8) then 5 r2 = reducedEnvs( . \\{o }, relevantVars \\ o, \nforbiddenVars . o ) 6 r3 = {., .{o } : ., . r2} 7 return r1 . r3 8 else 9 return r1 10 end 11 else 12 \nif relevantVars = \u00d8 then return { {} } 13 else return {}14 end able has already been included in some \nabstract object, or no environments if some relevant variable remains. Since Sagiv et al. s notion of \ncompatibility [34] is de.ned only for the precise object abstraction, we generalized it for the must-may \nabstraction. The generalized compatible pred\u00adicate is formally de.ned in Figure 11. In order for two \nab\u00adstract objects to be compatible, they must either be abstrac\u00adtions of distinct concrete objects, or \nof the same concrete object. In the former case, the two must sets need to be dis\u00adjoint. In the latter \ncase, the must set of each abstract object needs to be a subset of the may set of the other. Before com\u00adputing \nthe reduced environments using Algorithm 1, we use the generalized compatibility predicate to remove \nfrom the abstract environment any abstract objects that are incompat\u00adible with an abstract object already \nbound in the tracematch state. counterparts, but with abstract lookup lookup(O ,v) substi\u00adtuted for concrete \nlookup in .. The overall transfer function [tr (a, b)]m joins the results of e for all reduced abstract \nenvironments O . . . Finally, [s]s extends [s]m to sets of abstract tracematch state pairs; it is the \nsame as in Fig\u00adure 10. At control .ow merge points, the join operator used on sets of tracematch state \npairs is set union. We illustrate the effect of the tracematch state transfer function using the example \nstatements shown in Figure 13. In this example, the must and may sets in every positive binding are the \nsame, so we only show the set of vari\u00adables once in each positive binding. Consider the tracematch from \nFigure 2 whose automaton was shown in Figure 1. The right side of Figure 13 shows some of the tracematch \nstate computations performed when analyzing the statements in the left side of the .gure. Once statement \n3 has executed, . contains the abstract objects {l1}, {l2} and {it1}. The tracematch state s contains \nthe initial tracematch state pair !1?1 !2?2?2 ,o ,o !?!? !?!? !?!? !1?2!2?1 ) \u00a3o same( (1, {c .T,i . \nT}). The execution of statement 4 creates a state pair in state 2 with a positive binding for the two \ntrace\u00admatch parameters. Two state pairs with negative bindings for the parameters are also created. Hence, \nafter statement 4, the abstract tracematch state s contains the 4 state pairs shown in the .gure. Of \nthe computations required to model state\u00adment 5, the .gure shows only the computations needed to handle \nthe state pair (2, {c .{l1},i .{it1}}). The posi\u00adtive binding of l2 yields one state pair in state 3 \nwhich has a . o . o . o o ,o o, !1?1 !2!1!2 ) \u00a3o diff( n o = \u00d8 o ,o o, ) \u00a3same(ocompatible(o ) . diff(o \n) 1 ,o 2 1 ,o 2 1 ,o 2 Figure 11. Generalized compatibility predicate. The transfer function for transition \nstatements is de.ned binding of . for the tracematch parameter c. This represents in Figure 12. At a \nhigh level, it mirrors the semantics of tr (a, b) presented in Section 2. Having de.ned abstract variable \nlookup, the abstract tracematch transition func\u00ad an inconsistent binding and is discarded by the analysis. \nIf . had contained an abstract object {l1,l2}, indicating that l1 and l2 may have been aliased, the transfer \nfunction would tions e +0 ,e - ,e + ,e - ,e are exactly like their concrete lookup(O ,v) \u00a3o . O : v \n. o + o ,o where o = lookup(O ,b(f)) if f . dom(b) e (b, O ) \u00a3.f. 0 T otherwise ( } + ,+ ,) e [a, b, \nO ](q, m ) \u00a3 q,m n e (b, O ): d(q, a, q 0 - lookup(O ,b(f)) if f = f, e (b,O ,f) \u00a3.f,. 0 T otherwise \n( } - e - [b, O ](q, m ) \u00a3 q, m n e (b,O ,f): f . dom(b) 0 + e [a, b, O ](q, m ) \u00a3e [a, b, O ](q, m \n) . e - [b, O ](q, m )  [tr (a, b)][. ](q, m ) \u00a3 e [a, b, O ](q, m ) O .reduced environments of . Figure \n12. Transfer function for a transition statement tr (a, b), which is applied to each pair q, m in the \ntracematch state abstraction. 1 2 3 l1 . new l2 . new it1 . new s = {(1, {c . T, i . T})} 4 tr(makeIter, \n{c . l1, i . it1}) O = {{l1}, {it1}} e + 0 = { c . {l1}, i . {it1} }e+ = (2, {c . T, i . T} n {c . {l1}, \ni . {it1}})= 2, {c . {l1}, i . {it1}}) e- = ( 1, {c . {l1}, i . T}} , 1, {c . T, i . {it1}}} ( s = (1, \n{c . T, i . T}) , 1, {c . {l1}, i . T}} , 1, {c . T, i . {it1}}} , (2, {c . {l1}, i . {it1}}) 5 tr(update, \nc . l2) O = {{l2}}For tracematch state pair (2, {c . {l1}, i . {it1}}) only: e + 0 = {c . {l2}}e+ = (3, \n{c . {l1}, i . {it1}} n {c . {l2}})= (3, {c . ., i . {it1}}) e- = 2, {c . {l1}, i . {it1}} n {c . {l2}}}= \n2, {c . {l1}, i . {it1}})( s = (1, {c . T, i . T}) , 1, {c . {l1, l2}, i . T}} , 1, {c . {l1}, i . {it1}}} \n, 1, {c . {l1}, i . T}} , Figure 13. Example illustrating tracematch state transfer function  (2, {c \n.{l1},i .{it1}}) , (3, {c ..,i .{it1}})} have generated the state pair (3, {c .{l1,l2},i .{it1}}), indicating \na transition to state 3 with consistent bindings. The negative binding creates a state pair in state \n2. The ad\u00additional state pairs appearing in the .nal tracematch state s arise from the other state pairs \nthat were present before state\u00adment 5. The computation for these state pairs is not shown in the .gure. \nWe have proven [30, Theorem 3] that the transfer function preserves correctness. The correctness relation \nrelating [s]s concrete and abstract binding lattice elements is de.ned as follows. An abstract state \ns soundly approximates a concrete state s if for every pair (q, m) in s, there is a corresponding pair \nq, m in s that soundly approximates it. A pair q, m soundly approximates (q, m) if for every tracematch \nparameter f, m (f) is higher in the binding lattice than the abstraction of m(f) obtained by replacing \neach concrete object with the set of variables that point to it. Recall that a body statement completes \na match only if the concrete state contains a pair (q, m) such that q is a .nal state and m(f) is not \n. for any f. The correctness relation ensures that if this happens, the abstract state s must also contain \na pair q, m satisfying the same conditions. In the absence of such a pair in the abstract state, the \nanalysis concludes that the body statement cannot complete a match. 4. Context-Sensitive Interprocedural \nAnalysis We implemented the analysis as an instance of the IFDS algorithm of Reps et al. [32] with some \nsmall modi.cations. The IFDS algorithm implements a fully context-sensitive interprocedural data.ow analysis \nprovided that: the analysis domain is the powerset of a .nite set Dom,  the merge operator is union, \nand  the transfer function is distributive.  IFDS is an ef.cient dynamic programming algorithm that \nuses O(E|Dom|3) time in the worst case, where E is the number of control-.ow edges in the program. The \nkey rea\u00adson for its ef.ciency is that it evaluates transfer functions on each individual element of Dom \nat a time, rather than on a subset of Dom at a time (recall that each element of the anal\u00adysis domain \nis a subset of Dom). As a result, any distributive function f : P(Dom) .P(Dom) can be ef.ciently repre\u00adsented \nas a graph with at most (|Dom| + 1)2 edges [32, Sec\u00adtion 3]. The IFDS algorithm starts with a graph representa\u00adtion \nof the transfer function for each instruction in the pro\u00adgram, and works by composing them into transfer \nfunctions for ever longer sequences of instructions. Spec.cally, it uses a typical worklist algorithm \nto complete two tables of trans\u00adfer functions: the PathEdge table gives the transfer function from the \nstart node of each procedure to every other node in the same procedure, and the SummaryEdge table gives \nthe transfer function that summarizes the effect of each call site in the program. To formulate the tracematch \nanalysis as an IFDS prob\u00adlem, we must de.ne the set Dom and the transfer functions on individual elements \nof Dom. This cannot be done for the overall .ow function that computes both the object and tracematch \nabstractions because it is not distributive. This is because the tracematch state depends on abstractions \nof multiple objects, which could come from different control .ow paths. Individually, however, each of \nthe transfer func\u00adtions for the object abstraction and for the tracematch state abstraction is distributive. \nThus, we can .rst perform the ob\u00adject analysis as one instance of IFDS, then use the result to perform \nthe tracematch state analysis as a second instance of IFDS. Moreover, the decomposition into transfer \nfunctions on individual elements of a .nite set Dom comes naturally from the de.nition of the overall \ntransfer functions. For the object abstraction, Dom is two copies of the set of all possi\u00adble abstract \nobjects, one copy to represent each of . and h . Thus, the decomposed transfer function speci.es the \neffect of an instruction on a single abstract object at a time. For the tracematch state abstraction, \nDom is the set of all possible pairs q, m . Thus, the decomposed transfer function spec\u00adi.es the effect \nof an instruction on one pair at a time. The complete decomposed transfer functions and a proof of their \nequivalence to the overall transfer functions appears in the technical report [30]. In addition to the \ntransfer functions, an instantiation of the IFDS algorithm must specify how to map elements of Dom between \nthe caller and callee at a call site. Our mapping into the callee simply replaces actuals with formals, \nand removes all caller-side variables from both the object and tracematch state abstractions. In order \nto map objects from the callee back to the caller, we need to know which caller-side vari\u00adables pointed \nto the object prior to the call. This information is readily available in the IFDS algorithm. Although \n[32] did not anticipate making this information available to the trans\u00adfer function, it is straightforward \nto modify it to do so. The same modi.cation is also used in the typestate analysis of Fink et al. [17, \n18], and is likely to be useful in general in other IFDS analyses. 4.1 Collecting Useful Update Shadows \nThe analysis presented thus far can prove that the tracematch will never be in an accepting state at \na given body state\u00adment. If this can be proved for all body statements in the program, the property expressed \nby the tracematch has been fully veri.ed statically, and all dynamic instrumentation can be removed. \nHowever, the analysis may not be successful in ruling out all body statements. In this case, it is useful \nto compile a list of all transition statements that may contribute to a match at each body statement. \nIn static veri.cation, this list helps the user identify the source of the bug, or to decide that the \nerror report is a false positive. For example, if a col\u00adlection is updated during iteration, the body \nstatement is the failing next call on the iterator; more useful to the program\u00admer would be the location \nof the collection update. We are currently developing an Eclipse plugin to present this infor\u00admation \nto the programmer. In optimizing the dynamic trace\u00admatch implementation, all transition statements not \nleading to a potentially matching body statement can be removed, thereby reducing the runtime overhead \nof matching. The analysis can be extended to keep track of relevant transition statements by using the \nIDE [33] algorithm in\u00adstead of IFDS. The IDE algorithm is an extension of IFDS to analysis domains of \nthe form Dom . L, where Dom satis.es the same conditions as for IFDS and L is a lat\u00adtice of .nite height. \nIndeed, IFDS is a special case of IDE with L chosen as the two-point lattice .[T. The IFDS version of \nthe tracematch analysis presented thus far deter\u00admines only whether a given pair q, m is (T) or is not \n(.) present at each program point. To keep track of tran\u00adsition statements leading to a match, we keep \nthe same set Dom = Q \u00d7 (F . Bind ), and de.ne L to contain . along with all subsets of the set of all \ntransition statements. For each pair q, m present at a program point, the IDE ver\u00adsion of the analysis \nmaintains the set of transition statements that may have contributed to its presence. The IDE transfer \nfunctions are extensions of the IFDS transfer functions that we have already presented. The trans\u00adfer \nfunctions are fomally de.ned in the technical report; we brie.y summarize them here. The transfer function \nfor every statement other than a transition statement keeps the set of relevant transition statements \nfor each tracematch state pair unchanged. The transfer function for a transition statement adds the current \ntransition statement to the set of relevant transition statements for each tracematch state pair. There \nis one exception: when the transition statement transforms a tracematch state pair q, m to itself, the \ntransition state\u00adment is not added to the set of relevant transition statements for that pair. A transition \nstatement that does not change the concrete tracematch state at run time is not considered rele\u00advant \nbecause removing it would not change the program be\u00adhaviour. Such a statement occurs when the tracematch \nreg\u00ad * ular expression contains a subexpression of the form a , which causes a self-loop in the .nite \nautomaton. We have proved that a transition statement that does not change the abstract tracematch state \ncannot change the concrete trace\u00admatch state [30, Proposition 7]. It is therefore sound to omit a transition \nstatement that does not change the abstract trace\u00admatch state from the relevant transition statements. \nIt may happen that a transition statement in a loop changes the tracematch state in the .rst iteration \nbut not in any subsequent iteration. An optimized dynamic imple\u00admentation should execute the .rst, relevant \ntransition, but should avoid executing the redundant transitions in subse\u00adquent iterations of the loop. \nThis can be achieved by peeling one iteration of every loop containing a transition statement prior to \nperforming the IDE analysis. The analysis will mark the transition as relevant in the peeled iteration \nand unnec\u00adessary in the remaining loop. 5. Empirical Evaluation We empirically evaluated the precision \nof our analysis and compared it to Bodden et al. s existing tracematch anal\u00adysis [8], which uses may-point-to \ninformation to rule out possibly matching transition statements. The evaluation was performed on the \ntracematches from [8] plus one new one (FailSafeEnumHashtable), summarized below: ASyncIteration: A synchronized \ncollection should not be iterated over without owning its lock. FailSafeEnum: A vector should not be \nupdated while enu\u00admerating it. FailSafeEnumHashtable: A hashtable should not be up\u00addated while enumerating \nits keys or values. FailSafeIter: A collection should not be updated while iter\u00adating over it. HasNext: \nThe hasNext method should be called prior to every call to next on an iterator. HasNextElem: The hasNextElem \nmethod should be called prior to every call to nextElement on an enumeration. LeakingSync: A synchronized \ncollection should only be accessed through its synchronized wrapper. Reader: A Reader should not be used \nafter its InputStream has been closed. Writer: A Writer should not be used after its OutputStream has \nbeen closed. We applied the above tracematches to the benchmarks antlr, bloat, hsqldb, luindex, jython, \nand pmd from the Da-Capo benchmark suite, version 2006-10-MR2 [7]. Most of the benchmarks use re.ection \nto load key classes. We in\u00adstrumented the benchmarks using ProBe [28] and *J [15] to record actual uses \nof re.ection at run time, and provided the resulting re.ection summary to the static analysis. The jython \nbenchmark generates code at run time which it then executes; for this benchmark, we made the unsound \nassump\u00adtion that the generated code has no effect on aliasing or trace\u00admatch state. Each of the 6 benchmarks \nwas analyzed with each of the 9 tracematches, a total of 54 cases (tracematch/benchmark pairs). The 54 \ncases evaluated contained a total of 5409 .nal transition statements. We de.ne a transition statement \n(a, b)as .nal if the tracematch automaton contains a transition to an accepting state on a. Thus, a match \ncan be completed only at a .nal transition statement and implies a violation of the speci.ed property. \nWe count only .nal transition statements in the reachable part of the call graph. Of these, our analysis \nproved that 4815 (89 %) will never complete a match. Thus, a programmer wishing to check the tracematch \nproperties need only examine 11 % of the uses of the features checked by the tracematches. Bodden s analysis \ncomprises three stages. The .rst stage (QC) considers only the set of tracematch symbols present in the \nprogram; if every word satisfying the tracematch pat\u00adtern contains a given symbol and that symbol does \nnot ap\u00adpear anywhere in the program, the tracematch cannot match and hence the safety property enforced, \ncannot be violated. The second stage (FI) considers the may-point-to sets of the variables in each transition \nstatement. If a sequence of tran\u00adsitions is to lead to a violation, they must have consistent bindings, \nwhich is possible only if their points-to sets over\u00adlap. Bodden observed this stage to reduce the number \nof matching transition statements in seven of nine cases (trace\u00admatch/benchmark pairs); in one case, \nit completely elimi\u00adnated all possibility of a match. The third stage (FS) con\u00adsiders the order in which \nsymbols occur during execution, but does not coordinate this order with the .ow of individual objects; \nBodden observed no precision improvement over FI. Since our analysis subsumes QC and the precision of \nFI and FS is equivalent in practice, the evaluation in this section compares our analysis with FI. Of \nthe 54 cases, 36 actually used the features described by the tracematch, in the sense that QC did not \nrule out a match. These cases contained 1509 .nal transition statements, and our analysis proved that \n915 will never complete a match and hence do not violate the tracematch property. Each of the 36 cases \nis represented by a circle in Table 1. Beside each circle is a fraction giving the number of transition \nstatements at which a match could not be ruled out and the total number of .nal transition statements. \nIn 15 of the 36 cases, our analysis ruled out all matches; i.e. it successfully veri.ed that the benchmark \nis free of any violations of the property speci.ed by the tracematch. These cases are represented by \nthe 15 fully white circles. In comparison, the FI analysis ruled out all matches in only 1 of the 36 \ncases where QC was unsuccessful. However, the two analyses are complementary in that they are successful \non different transition statements. Our analysis fares better when the temporal order in which events \noccur is relevant in ruling out the match. When the feature monitored by the tracematch is used in many \ndistinct ways in different parts of the program, like iterators, FI is sometimes better at distinguishing \nthe different uses based on the alloca\u00adtion sites of the objects involved. More speci.c examples are \ndiscussed in the rest of this section. The two analyses can be run together, and the combination is more \nprecise than each analysis on its own. 5.1 Discussion of Results In this section we take a closer look \nat some of the results from Table 1. Of the 21 remaining cases in which all vi\u00adolations could not be \nremoved, 4 involve the HasNext and HasNextElem tracematches. In one case (HasNext/pmd), all possible \nmatches are actual violations of the tracematch pat\u00adtern. The code uses isEmpty to ensure that a collection \nis not empty, then calls next on an iterator without calling hasNext .rst. Similar violations occur in \nthe other three cases (in jython and in HasNext/bloat). In addition, these cases contain false positives \ndue to iterators stored only in .elds and not local variables. In the HasNext and Has-NextElem tracematches, \n.ow-sensitive tracking of individ\u00adual objects is crucial to ensure that the hasNext call occurs on the \nsame object as the calls to next. Thus, while our anal\u00adysis ruled out matches at 441 of the 476 .nal \ntransition state\u00adments, FI could not rule out a match at any of them.2 In 11 cases involving the FailSafe* \ntracematches, the analysis found both violations and likely false positives due to aliasing. Some collections, \nsuch as java.util.Hash\u00adtable, keep a singleton enumeration and iterator which are reused every time the \ncollection is empty. This violates the tracematch because an iterator is being used even though a collection \nwith which it was previously associated has since been updated. This accounts for many but not all of \nthe detected matches; the associated transition statements are shown in gray in Table 1. At many of the \nother transition statements, a match can\u00adnot be ruled out because a loop iterating over a collection \ncontains calls leading to very deep call chains comprising many methods, some of which update collections. \nThe anal\u00adysis is not able to prove that all these collections are distinct from the collection being \niterated. In some of these loops, may point-to information would help: FI ruled out matches at 19 transition \nstatements in 3 cases that our analysis did not. On the other hand, our analysis ruled out matches at \n54 transition statements in 2 cases that FI did not. Since so many methods are transitively called from \nthe loop, it is dif.cult to examine them all by hand to determine whether any of the updated collections \nmay in fact alias the iterated collection. We are working on a convenient user interface to visualize \nthe potential update locations and the call chains connecting them to the original loop. The cases involving \nthe Reader and Writer tracematches can be classi.ed into three categories. The .rst category in\u00adcludes \nreaders/writers of .les, which are closed after the last access. In these instances, our analysis proved \nall accesses occur before the close, thereby ruling out a violation. Since FI ignores the order of the \nevents, it could not rule out a violation. The second category includes readers/writers of the standard \ninput/output streams. These are never closed, and the FI analysis proves this fact, thus ruling out a \nmatch. These streams are often referenced only by their static .eld in the System class, and not by any \nlocal variables. There\u00adfore, our analysis cannot distinguish them from other read\u00aders/writers on which \nclose is called, and cannot rule out a match. The third category includes readers/writers for which neither \nanalysis can rule out a violation. We noticed the fol\u00adlowing pattern in several benchmarks. A loop repeatedly \n2 Some transition statements were ruled out in [8] because they were deter\u00admined to be in code that could \nnot be reached at run time. Our evaluation considers only reachable code. antlr bloat hsqldb jython \nluindex pmd  0 37 ASyncIteration 8   0 24 5  0 43 3 26 9 3 FailSafeEnum 8 3 24 4 43 3 26 9 FailSafeEnumHashtable \n297 0 14 6  44 316 1 15 11 49 FailSafeIter 18 0 4 0 2 315 1 15 11 49 HasNext 0 0 0 11 0 0 43 1 3 26 \n9 3 HasNextElem 0 200 LeakingSync 1  18 5 0  2 10 22 13 3 6 Reader 25 71 0 0 77 104 3 1 Writer \n Table 1. Fraction of .nal transition statements that may complete a match. The white part of each circle \nrepresents those that cannot complete a match. The black part represents those at which a match cannot \nbe ruled out, due either to analysis imprecision or an actual violation. The gray part represents those \nat which a violation is known to exist. calls a helper method that uses the reader/writer. Both the loop \nand the helper method contain a try block. An ex\u00adception during the input/output operation is caught \nin the helper, which closes the stream and re-throws the excep\u00adtion. The try block protecting the loop \ncatches the excep\u00adtion, thereby terminating the loop and preventing any fur\u00adther use of the reader/writer. \nBecause our analysis does not distinguish normal and exceptional returns, it conservatively assumes that \nthe loop could continue iterating and therefore use the reader/writer after the stream was closed. Overall, \nour analysis proves three Reader/Writer cases correct com\u00adpared to two for FI, but FI rules out slightly \nmore .nal tran\u00adsition statements than our analysis. In summary, although our analysis is often more precise \nthan FI, the two are complementary in that each is more effective than the other on certain code patterns. \nIn many practical cases, our analysis is precise enough to rule out a match. However, there remain cases \nwhere the abstraction looses all local variable references to an object. Thus, our analysis would bene.t \nfrom some information about pointers from within the heap. We will investigate augmenting the abstraction \nwith such information in future work. 6. Related Work When tracematches were introduced, space and time \nover\u00adhead of their dynamic implementation was a concern [1]. In general, the overhead varied widely depending \non the trace\u00admatch and the number of dynamic updates to the tracematch state that must be performed; \nin many cases, the overhead was prohibitive. One approach to reduce the overhead has been to im\u00adprove \nthe dynamic tracematch implementation [4]. In this approach, the tracematch automaton (but not the base \ncode to which it is applied) is analyzed statically to generate more ef.cient matching code. Speci.c \nattention has been paid to freeing bindings as soon as possible to reduce memory re\u00adquirements and to \ndetect statically when a tracematch may lead to unbounded space overhead. Freeing bindings early has \nthe additional bene.t of reducing the time required to .nd the binding requiring update when a transition \nstate\u00adment is encountered. This time can be reduced further by maintaining suitable indexes on the binding \nset. On some re\u00adalistic tracematches, these techniques yield speed improve\u00adments of multiple orders of \nmagnitude. Thus, these tech\u00adniques are necessary for a practical dynamic implementation of tracematches. \nA similar indexing technique is also applied in JavaMOP [10]. A second approach, of which our work is \nan example, is to use static analysis to reduce the number of transition statements that must be instrumented. \nAnother example is the work of Bodden et al. [8], which we discussed in Sec\u00adtion 5. In follow-on work \nto be presented at SIGSOFT/FSE 2008, Bodden et al. [9] have augmented the analysis with a suite of intraprocedural \n.ow-sensitive analyses. The analy\u00adses combine local alias information with inexpensive whole program \nsummary information. In their benchmark suite, tracematches described mostly local patterns, thus a care\u00adful \ncombination of these analyses could detect many viola\u00adtions and with few false positives. Guyer and Lin \ns [21, 22] client-driven pointer analysis is also related. Their analysis is based on a subset-based \nmay-point-to analysis followed by .ow-sensitive propagation of states on the abstract object represented \nby each allocation site. When a property can\u00adnot be proven, the analysis iteratively re.nes the context\u00adsensitivity \nof the points-to analysis in order to improve pre\u00adcision and hopefully verify the property. Dwyer and \nPuran\u00addare [16] also use static analysis to reduce the cost of dy\u00adnamic typestate veri.cation by proving \nthat certain transi\u00adtions need not be instrumented because they cannot lead to a violation. The static \nanalysis most closely related to our analysis is Fink et al. s typestate analysis [17, 18]. Their analysis \nalso uses an object abstraction in which an abstract object rep\u00adresents at most one concrete object, \nand it uses the focus operation to achieve this. Their object abstraction is more precise but more costly \nthan ours because it tracks access paths through .elds, rather than only references from local variables. \nIn addition, the object abstraction contains the al\u00adlocation site of each object, which provides the \nsame infor\u00admation as a subset-based may-point-to analysis. It would be possible to replace the object \nabstraction in our tracematch analysis with that of Fink et al. to improve precision. Un\u00adlike tracematches, \ntypestate applies only to a single object. Therefore, rather than requiring a separate tracematch ab\u00adstraction, \nFink et al. simply augment the abstraction of each object with its typestate. Another object abstraction \nsimilar to ours is used by Cherem and Rugina [11] to statically insert free instructions to deallocate \nsome objects earlier than the garbage collector can get to them. This application makes use of the property \nthat the abstract object corresponding to a given concrete ob\u00adject can be traced through the control \n.ow graph. The object abstraction is also more precise than ours, but less so than Fink s; it maintains \nreference counts from individual .elds rather than full access paths. This object abstraction could also \nbe substituted in the tracematch analysis. Multiobject temporal constraints have been studied by Jaspan \nand Aldrich [25, 26] in the context of plugins for object-oriented frameworks. The motivation for their \nwork is that since large frameworks introduce complex constraints that are dif.cult to understand and \ndocument, it is dif.\u00adcult for programmers to develop plugins which conform to the constraints laid down \nby the framework. They present a lightweight speci.cation system which allows the frame\u00adwork developers \nto specify runtime interactions between ob\u00adjects and the framework constraints that depend on these in\u00adteractions. \nA static analysis is presented that uses these spec\u00adi.cations and analyzes the plugin code for any violations \nof the constraints laid down by the framework developer. The analysis has been shown to work on real \nworld examples from the ASP.NET and Eclipse framework. Ramalingam et al. [31] present a veri.cation technique \nfor checking that a client program follows conventions re\u00adquired by an API. The effects and requirements \nof the API methods are speci.ed using a declarative language. The sys\u00adtem constructs a predicate abstraction \nof the API internals from the speci.cation. The predicate abstraction is used to prove that a client \nprogram satis.es the requirements. The system was used to check correct usage of iterators in client \nprograms of up to 2396 LOC. The Metal system [24] is an unsound state-based bug .nder for C. The core \nsystem does not consider aliasing; in\u00adstead an automaton is maintained for each variable, regard\u00adless \nof the object to which it may be pointing. It uses heuris\u00adtics such as synonyms (an unsound variation \nof must-alias analysis) to partially recover from this unsoundness. Metal was successful in .nding many \nlocking bugs in the Linux kernel. An alternative to analyzing arbitrary aliasing is to use a specialized \ntype system to restrict aliasing. An advantage of this approach is modularity: a violation of the type \nsys\u00adtem is local, as are violations of the typestate property when the aliasing restrictions are obeyed. \nA disadvantage is that it is dif.cult to apply to existing, unannotated code, although sometimes annotations \ncan be inferred automatically. The Vault system [12] uses keys, unique pointers to objects. The type \nsystem prevents duplication of keys, and each typestate change is correlated with a set of keys held \nat the point of the change. The same authors propose a system for specifying typestates of object-oriented \nprograms, focusing especially on object-oriented features such as subtyping [13]. To han\u00addle aliasing, \nthey allow objects to be either unaliased and up\u00addateable, or possibly aliased and non-updateable. CQual \n[19] is another system similar to but simpler than Vault. Bierhoff and Aldrich [5,6] present a type system \nin which both alias\u00ading and typestate information are speci.ed using types. A key innovation of their \nsystem are access permissions, which specify whether a pointer is unique or whether it is aliased but \nwith .ne-grained restrictions on which aliases may read or write to the object. Access permissions can \nbe split for multiple aliases and later recombined, making them more .exible than earlier aliasing control \nmechanisms. 7. Conclusions and Future Work We have presented a static analysis of temporal speci.ca\u00adtions \nof multiple interacting objects expressed using trace\u00admatches. The analysis has been proven sound with \nrespect to the tracematch semantics. A fully context-sensitive version of the analysis has been implemented \nas two instances of IFDS [32] and IDE [33] algorithms. The analysis was eval\u00aduated on the tracematches \nof Bodden et al. [8] and found to be very precise. The analysis ruled out the possibility of a violation \nat 89% of the .nal transition statements in the benchmarks that we evaluated. Thus, a programmer wishing \nto check the properties speci.ed by the tracematches would have to examine only the remaining 11% of \n.nal transition statements. Of the 36 tracematch/benchmark pairs in which the benchmark used features \nchecked by the tracematch, the analysis fully veri.ed 15 to contain no possible violations. Remaining \nimprecisions are mainly due to two factors. First, the analysis loses precision when all local variable \nref\u00aderences to an object are lost. This can be remedied either by making use of may-point-to information, \nor by adding more precise information about heap references to the object ab\u00adstraction. Even type information \nmay help in some cases. Second, the analysis fails to verify some tracematches due to imprecise handling \nof interprocedural exceptional control .ow. The precision of exceptional control .ow can be im\u00adproved \nwith suitable modi.cations to the IFDS and IDE al\u00adgorithms. We plan to investigate these improvements \nin the future. To make the analysis useful to programmers, and to ease our work of interpreting the results, \nwe are developing an Eclipse plugin for presenting the analysis results and for nav\u00adigating the call \ngraph and control .ow graph of the program. A screenshot from the current prototype of the plugin ana\u00adlyzing \nthe example from Figures 1 and 2 is shown in Fig\u00adure 14. The top view shows the code being analyzed in \nthe Eclipse source editor and the bottom view shows the results of the tracematch analysis. In this example, \nthe analysis has found one possible .nal transition statement, in line 23, that could violate the property. \nFor this .nal transition statement, the view also displays the update shadows that could have led to \nthe match, collected through the IDE analysis dis\u00adcussed in Section 4.1. A programmer investigating the \nvi\u00adolation in line 23 would examine the update transitions to .nd that the update in line 24 modi.ed \nthe list being iter\u00adated, leading to a violation the next time line 23 is executed. Acknowledgments We \nare grateful to Matt Negulescu and Robert Burke for de\u00adveloping the Eclipse plugin prototype. We have \nhad fruitful discussions about static veri.cation of multi-object tempo\u00adral properties with Jonathan \nAldrich, Eric Bodden, Laurie Hendren, Ciera Jaspan, and Patrick Lam. We thank the abc team for maintaining \nthe dynamic tracematch implementa\u00adtion in the abc compiler. Finally, we thank the anonymous reviewers \nfor their useful remarks and suggestions for the paper. This research was supported by the Natural Sciences \nand Engineering Research Council of Canada. References [1] C. Allan, P. Avgustinov, A. Christensen, L. \nHendren, S. Kuzins, O. Lhot\u00b4 ak, O. de Moor, D. Sereni, G. Sittampalam, and J. Tibble. Adding trace matching \nwith free variables to AspectJ. OOPSLA 05: Proceedings of the 20th ACM SIGPLAN Conference on Object Oriented \nProgramming Systems and Applications, pages 345 364, 2005. [2] P. Avgustinov, A. Christensen, L. Hendren, \nS. Kuzins, J. Lhot\u00b4ak, O. de Moor, D. Sereni, G. Sittampalam, ak, O. Lhot\u00b4and J. Tibble. abc : An extensible \nAspectJ compiler. Transactions on Aspect-Oriented Software Development I, pages 293 334. 2006. [3] P. \nAvgustinov, E. Hajiyev, N. Ongkingco, O. de Moor, D. Sereni, J. Tibble, and M. Verbaere. Semantics of \nstatic pointcuts in AspectJ. POPL 07: Proceedings of the 34th ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages, pages 11 23, 2007. [4] P. Avgustinov, J. Tibble, and O. de Moor. Making trace \nmonitors feasible. OOPSLA 07: Proceedings of the 22nd ACM SIGPLAN Conference on Object Oriented Programming \nSystems and Applications, pages 589 608, 2007. [5] K. Bierhoff and J. Aldrich. Lightweight object speci.cation \nwith typestates. ESEC/FSE 2005: Proceedings of the Joint 10th European Software Engineering Conference \n(ESEC) and the 13th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-13), pages \n217 226, 2005. [6] K. Bierhoff and J. Aldrich. Modular typestate checking of aliased objects. OOPSLA \n07: Proceedings of the 22nd ACM SIGPLAN Conference on Object Oriented Programming Systems and Applications, \npages 301 320, 2007. [7] S. Blackburn, R. Garner, C. Hoffman, A. Khan, K. McKin\u00adley, R. Bentzur, A. Diwan, \nD. Feinberg, D. Frampton, S. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, E. Moss, A. Phansalkar, D. \nStefanovi\u00b4c, T. VanDrunen, D. von Dinck\u00adlage, and B. Wiedermann. The DaCapo benchmarks: Java benchmarking \ndevelopment and analysis. OOPSLA 06: Pro\u00adceedings of the 21st ACM SIGPLAN Conference on Object Oriented \nProgramming Systems and Applications, 2006. [8] E. Bodden, L. Hendren, and O. Lhot\u00b4ak. A staged static \nprogram analysis to improve the performance of runtime monitoring. ECOOP 07: Proceedings of the 21st \nEuropean Conference on Object-Oriented Programming, pages 525 549, 2007. [9] E. Bodden, P. Lam, and L. \nHendren. Finding programming errors earlier by evaluating runtime monitors ahead-of-time. FSE 2008: ACM \nSIGSOFT International Symposium on the Foundations of Software Engineering, Nov. 2008. [10] F. Chen and \nG. Ros\u00b8u. Mop: an ef.cient and generic runtime veri.cation framework. OOPSLA 07: Proceedings of the 22nd \nACM SIGPLAN Conference on Object Oriented Programming Systems and Applications, pages 569 588, 2007. \n[11] S. Cherem and R. Rugina. Compile-time deallocation of individual objects. ISMM 06: Proceedings of \nthe 2006 International Symposium on Memory Management, pages 138 149, 2006. [12] R. DeLine and M. F\u00a8ahndrich. \nEnforcing high-level protocols in low-level software. PLDI 01: Proceedings of the 2001 ACM SIGPLAN Conference \non Programming Language Design and Implementation, pages 59 69, 2001. [13] R. DeLine and M. F\u00a8ahndrich. \nTypestates for objects. ECOOP 04: Proceedings of the 18th European Conference on Object-Oriented Programming, \npages 465 490, 2004. [14] A. Deutsch. A storeless model of aliasing and its abstractions using .nite \nrepresentations of right-regular equivalence rela\u00adtions. ICCL 92: Proceedings of the 4th IEEE International \nConference on Computer Languages, pages 2 13, 1992. [15] B. Dufour. Objective quanti.cation of program \nbehaviour using dynamic metrics. Master s thesis, McGill University, 2004. [16] M. B. Dwyer and R. Purandare. \nResidual dynamic typestate analysis: exploiting static analysis results to reformulate and reduce the \ncost of dynamic analysis. ASE 07: Proceedings of the twenty-second IEEE/ACM International Conference \non Automated Software Engineering, pages 124 133, New York, NY, USA, 2007. ACM. [17] S. Fink, E. Yahav, \nN. Dor, G. Ramalingam, and E. Geay. Effective typestate veri.cation in the presence of aliasing. ISSTA \n06: Proceedings of the International Symposium on Software Testing and Analysis, pages 133 144, 2006. \n[18] S. J. Fink, E. Yahav, N. Dor, G. Ramalingam, and E. Geay. Effective typestate veri.cation in the \npresence of aliasing. ACM Trans. Softw. Eng. Methodol., 17(2):1 34, 2008. [19] J. Foster, T. Terauchi, \nand A. Aiken. Flow-sensitive type quali.ers. PLDI 02: Proceedings of the 2002 ACM SIGPLAN Conference \non Programming Language Design and Implementation, pages 1 12, 2002. [20] S. Goldsmith, R. O Callahan, \nand A. Aiken. Relational queries over program traces. OOPSLA 05: Proceedings of the 20th ACM SIGPLAN \nConference on Object Oriented Programming Systems and Applications, pages 385 402, 2005. [21] S. Guyer \nand C. Lin. Client-driven pointer analysis. SAS 03: Proceedings of the 10th Annual International Static \nAnalysis Symposium, pages 214 236, 2003. [22] S. Guyer and C. Lin. Error checking with client-driven \npointer analysis. Sci. Comput. Program., 58(1-2):83 114, 2005. [23] B. Hackett and R. Rugina. Region-based \nshape analysis with tracked locations. POPL 05: Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Languages, pages 310 323, 2005. [24] S. Hallem, B. Chelf, Y. Xie, and D. \nEngler. A system and language for building system-speci.c, static analyses. PLDI 02: Proceedings of the \n2002 ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 69 82, 2002. [25] \nC. Jaspan and J. Aldrich. Checking semantic usage of frameworks. Library Centric Software Design Symposium, \n2007. [26] C. Jaspan and J. Aldrich. Checking temporal relations between multiple objects. Technical \nReport CMU-ISR-08\u00ad119, Carnegie Mellon University, Dec. 2008. [27] H. Jonkers. Abstract storage structures. \nde Bakker and van Vliet, editors, Algorithmic Languages, pages 321 343, 1981. [28] O. Lhot\u00b4ak. Comparing \ncall graphs. PASTE 07: Proceedings of the 7th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software \nTools and Engineering, pages 37 42, 2007. [29] M. Martin, B. Livshits, and M. S. Lam. Finding application \nerrors and security .aws using PQL: a program query language. OOPSLA 05: Proceedings of the 20th ACM \nSIGPLAN Conference on Object Oriented Programming Systems and Applications, pages 365 383, 2005. [30] \nN. Naeem and O. Lhot\u00b4ak. Extending typestate analysis to multiple interacting objects. Technical Report \nCS\u00ad2008-04, University of Waterloo, 2008. http://www.cs. uwaterloo.ca/research/tr/2008/CS-2008-04.pdf. \n[31] G. Ramalingam, A. Warshavsky, J. Field, D. Goyal, and M. Sagiv. Deriving specialized program analyses \nfor certifying component-client conformance. PLDI 02: Proceedings of the 2002 ACM SIGPLAN Conference \non Programming Language Design and Implementation, pages 83 94, 2002. [32] T. Reps, S. Horwitz, and M. \nSagiv. Precise interprocedural data.ow analysis via graph reachability. POPL 95: Proceedings of the 22nd \nACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 49 61, 1995. [33] M. Sagiv, \nT. Reps, and S. Horwitz. Precise interprocedural data.ow analysis with applications to constant propagation. \nTheoretical Computer Science, 167(1 2):131 170, 1996. [34] M. Sagiv, T. Reps, and R. Wilhelm. Solving \nshape-analysis problems in languages with destructive updating. ACM TOPLAS, 20(1):1 50, Jan. 1998. [35] \nR. E. Strom and S. Yemini. Typestate: A programming language concept for enhancing software reliability. \nIEEE Trans. Softw. Eng., 12(1):157 171, 1986.   \n\t\t\t", "proc_id": "1449764", "abstract": "<p>This paper presents a static analysis of typestate-like temporal specifications of groups of interacting objects, which are expressed using tracematches. Whereas typestate expresses a temporal specification of one object, a tracematch state may change due to operations on any of a set of related objects bound by the tracematch. The paper proposes a lattice-based operational semantics equivalent to the original tracematch semantics but better suited to static analysis. The paper defines a static analysis that computes precise local points-to sets and tracks the flow of individual objects, thereby enabling strong updates of the tracematch state. The analysis has been proved sound with respect to the semantics. A context-sensitive version of the analysis has been implemented as instances of the IFDS and IDE algorithms. The analysis was evaluated on tracematches used in earlier work and found to be very precise. Remaining imprecisions could be eliminated with more precise modeling of references from the heap and of exceptional control flow.</p>", "authors": [{"name": "Nomair A. Naeem", "author_profile_id": "81309497986", "affiliation": "University of Waterloo, Waterloo, ON, Canada", "person_id": "P1223207", "email_address": "", "orcid_id": ""}, {"name": "Ondrej Lhotak", "author_profile_id": "81100503314", "affiliation": "University of Waterloo, Waterloo, ON, Canada", "person_id": "P1223208", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449792", "year": "2008", "article_id": "1449792", "conference": "OOPSLA", "title": "Typestate-like analysis of multiple interacting objects", "url": "http://dl.acm.org/citation.cfm?id=1449792"}