{"article_publication_date": "10-19-2008", "fulltext": "\n * ToleratingMemoryLeaks MichaelD.Bond KathrynS.McKinley DepartmentofComputerSciences TheUniversityofTexas \natAustin {mikebond,mckinley}@cs.utexas.edu Abstract Type safety and garbage collection in managed languages \neliminate memory errors such as dangling pointers, double frees, andleaks ofunreachableobjects.Unfortunately,apro\u00adgram \nstillleaks memoryifit maintains referencesto objects it will never use again.Leaked objectsdecreaseprogramlo\u00adcality \nand increase garbage collection frequency and work\u00adload. A growing leak will eventually exhaust memory \nand crash theprogram. This paper introduces a leak tolerance approach called Melt that safely eliminates \nperformance degradations and crashes due to leaks of dead but reachable objects in man\u00adagedlanguages,given \nsuf.cientdisk spacetoholdleaking objects. Melt(1)identi.es stale objects that theprogramis not accessing;(2) \nsegregatesin-use and stale objectsby stor\u00ading stale objects todisk; and(3)preserves safetyby activat\u00adingstale \nobjectsif theprogram subsequently accesses them. Wedesign andbuildaprototypeimplementationofMeltin a \nJavaVMand showit adds overheadlow enoughforproduc\u00adtion systems.Whereas existingVMsgrindto ahalt andthen \ncrash onprogramswithleaks,Meltkeeps manyofthesepro\u00adgrams runningmuchlonger without signi.cantlydegrading \nperformance.Meltprovidesuserstheillusionofa .xedleak andgivesdevelopersmoretimeto .xleakyprograms. Categories \nand Subject Descriptors D.2.5[Software En\u00adgineering]:TestingandDebugging Errorhandling and re\u00adcovery \nGeneralTerms Reliability,Performance,Experimentation * This workwas supportedby anIntelPhDFellowship,NSFCNS-0719966, \nNSFCCF-0429859,NSFEIA-0303609,DARPAF33615-03-C-4106,Intel, CISCO, and Microsoft. Any opinions, .ndings \nand conclusions expressed herein aretheauthors anddonot necessarily re.ectthoseof thesponsors. Permission \nto make digital or hard copies of all or part of this work for personal or classroomuseisgranted withoutfeeprovided \nthat copiesarenot madeordistributed forpro.tor commercial advantage andthat copiesbearthis notice andthefull \ncitation onthe .rstpage.Tocopy otherwise,torepublish,topostonserversortoredistribute tolists, requiresprior \nspeci.cpermission and/or afee. OOPSLA 08, October19 23,2008,Nashville,Tennessee,USA. Copyright c &#38;#169; \n2008ACM978-1-60558-215-3/08/10. . .$5.00 1. Introduction Managed languages use type safety and garbage \ncollection to improve program reliability by eliminating errors inher\u00adentin explicit memorymanagement.For \nexample,thesefea\u00adtures eliminatedouble(repeat)frees andprematurefreesthat leave dangling pointers. They \nalso eliminate the effort re\u00adquired toinsertfrees correctly,improvingprogrammerpro\u00adductivity.Unfortunately,programmers \nmay neglect to elim\u00adinate pointers to objects the program will never use again. These objects are leaked \nbecause garbage collection uses reachability as an over-approximation of liveness.Leaksin\u00adcreasegarbage \ncollectionfrequency and workload and may hurt application performance by bloating the working set size. \nGrowing leaks slow and eventually crash the applica\u00adtion when memoryis exhausted. Leaks are especiallyhardto \nreproduce, .nd, and.x since they havenoimmediatesymptoms[24].Leaksin managed languagesareaprobleminpracticeand \na numberof recent toolshelp developersdiagnoseand .xleaks[44,9,34,38, 49,52].Unfortunately,leaks occurindeployedsoftwarebe\u00adcause, \neven with these tools,leaks sometimes escapedetec\u00adtionbydevelopers.Thegoal of leak tolerance is to provide \nusers the illusion there is no leak the program does not slowto ahalt orcrash.Leak toleranceis not a \nreplacement for .xingleaks;itgivesdevelopersmoretimeandinforma\u00adtionto .xleakswhileimprovingtheuserexperience. \nThispaperpresents a newleak tolerance approach called Melt that transferslikelyleaked objects todisk.By \nof.oad\u00ading leaks to disk and freeing up physical and virtual mem\u00adory,Meltsigni.cantlydelaysmemoryexhaustionsincedisks \nare typically orders of magnitudelarger than main memory. Meltis analogousto operatingsystempagingsincebothcon\u00adserve \nmemory by transferring stale memory to disk. How\u00adever,standardpagingisinsuf.cientfor managedlanguages \nsince(1)pages mixingin-use andleakedobjects waste space and cannot be paged to disk, and (2) garbage \ncollection thrashes sinceits working setis all objects.Melt effectively provides.ne-grained pagingbyusing \nobjectinstead ofpage granularity and by restricting the collector to access only objects in memory. Determining \nwhether an object is live (willbe usedagain)is undecidableingeneral,soMeltpre\u00addictsthatstale objects(objectstheprogramhas \nnot usedin a while) arelikelyleaks and moves them todisk.Meltis safe and maintainsprogram semantics.If \nthe application tries to access an object ondisk,Melt activates itbymovingitfrom diskbackto main memory. \nMelt keeps programs performing well by guaranteeing time and space remain proportional to in-use (non-leaked) \nmemory. It restricts the application and garbage collector to accessing in-use objects in memory and \nprohibits ac\u00adcesses to stale objects on disk, and it keeps metadata pro\u00adportionaltoin-use memory.Otherleaktolerance \napproaches forgarbage-collectedlanguagesdo notprovide thisguaran\u00adtee[11,21,57].Bookmarkingcollection \nis similartoMeltin that it restricts collection to in-use pages, but it operates at pagegranularity[26], \nwhereasMelt seekstotolerateleaks with.ne-grain object tracking and reorganization. WeimplementMeltin \naJavaVirtualMachine(JVM)us\u00ading a copying generational collector, but the design works with any tracing \ncopying or non-copying collector. Our re\u00adsults show thatMeltgenerally adds overhead only when the programis \ncloseto running out of memory.For simplicity, our implementation inserts instrumentation into the appli\u00adcation \nthat helps identify stale objects, adding on average 6% overhead,but afutureimplementationcouldinsertthis \ninstrumentation only in response to memory pressure. We apply Melt to 10 leaks, including 2 leaks in \nEclipse and a leakin aMySQLdatabase client application.Melt success\u00adfully tolerates .ve of these leaks: \nthroughput does not de\u00adgradeovertime, andtheprogramsrununtiltheyexhaustdisk space or exceed a24-hourlimit.Ithelps \ntwo otherleaksbut adds high overhead activating objects that are temporarily stalebut notdead.Of the \notherthree,twodo not exhibittrue leaks since most of theheapgrowthis memory thatisinad\u00advertentlyin-use:the \napplicationcontinuesto access objects itis notusing.Melt cannottolerate the thirdleakbecause of a shortcomingin \nthe currentimplementation. As a whole, our results indicate that Melt is a viable approachfor safely \nincreasingprogramreliability withlow overhead,anditis a compellingfeatureforproductionVMs. 2. LeakTolerancewithMelt \nMelt s primary objective is to give the illusion there is no leak: performance does not degrade as the \nleak grows, the programdoes notcrash, andit runs correctly.To achievethis objective,Melt meets thefollowingdesigngoals: \n1.Timeand space overheadsareproportional tothein-use memory, notleaked memory. 2. Melt provides safety \nby preserving and, if needed, acti\u00advating stale objects. Furthermore,Meltadheresto thefollowing invariants: \nStale objects are isolated from the in-use objects in a separate stale space, which resides ondisk. \nThe collector never accesses objects in the stale space, except when moving objects to the stale space. \n The application never accesses objectsin the stale space, except when activating objectsfrom the stale \nspace.  We satisfy these invariants as follows: (1) Melt identi.es stale objects (Section 2.1); (2) \nit segregates stale objects from in-use objects by moving stale objects to disk, and it uses double indirection \nfor references from stale to in-use objects(Section2.2); and(3)itinterceptsprogram attempts to access \nobjects in the stale space and immediately moves the objectintothein-use space.(Section2.3).Section2.4 \npresentshowMeltdecideswhenand which stale objectsto move todisk,based onhow close theprogramis to running \nout of memory. 2.1 IdentifyingStaleObjects We classifyreachable objectsthattheprogramhas not refer\u00adencedin \na while as stale.Iftheprogram never accessesthem again,theyaretrueleaks.As we showlater, someleaks man\u00adifest \nasin-use(live) objects.For example,theprogramfor\u00adgetstodeleteobjectsfromahashtable,keepsaddingobjects, \nand then rehashes all elements every time it grows beyond the currentlimit.Stalenessthus under-approximatesleaks \nof in-use objects. To identify stale objects, Melt requires modi.cations to both the garbage collector \nand the dynamic compiler. At a high level, the modi.ed collector marks objects as stale on each collection, \nand the modi.ed compiler adds instru\u00admentation to the application to unmark objects at each use. At each \ncollection, objects the program has not accessed since the last collection will still be stale, while \naccessed objects will be unmarked. For ef.ciency, the collector ac\u00adtually marks both references and objects \nas stale. It marks references by setting thelowest(least signi.cant)bit of the pointer.Thelowestbit is \navailablefor markingsince object referencesare word-alignedin mostVMs.InMelt,thecol\u00adlector marks objects \nas stale by setting a bit in the object header. The compiler adds instrumentation called a conditional \nread barrier [8] to every load of an object reference. The barrier checks whetherthe referenceis stale.Ifitis \nstale,the barrier unmarksthe referencedobjectandthe reference.The followingpseudocode shows thebarrier: \nb = a.f; // Application code if (b &#38; 0x1) { // Conditional barrier t = b; // Backup ref b &#38;= \n~0x1; // Unmark ref a.f = b; [iff a.f == t] // Atomic store b.staleHeaderBit = 0x0; // Unmark object \n}  This conditionalbarrier reduces overhead sinceitperforms storesonlythe .rsttimetheapplicationloadseach \nreference in each mutator epoch(the mutator is the application alone, not the collector). Checking for \na marked reference, rather than a marked object, reduces overhead since it avoids an extra memoryload. \nFor thread safety, we use an atomic store for the un\u00admarked reference (a.f = b). Otherwise another thread \ns write to a.f may be lost. The pseudocode [iff a.f == t] indicatesthe storeisdependentona.f beingunchanged. \nWe implement the atomic store using a compare-and-swap (CAS) instruction that succeeds only if a.f still \ncontains the original value of b. If the atomic store fails, the read barrier simply continues; it is \nsemantically correct to pro\u00adceed with(unmarked) b while a.f holds the update from the other thread. Similarly, \nclearing the stale header bit (b.staleHeaderBit = 0x0) must be atomic if another thread can update otherbitsin \ntheheader.In ourimplemen\u00adtation, these atomic stores add negligible overhead since the bodyof the conditionalbarrier \nexecutesinfrequently. At the next collection, each object will be marked stale if and only if the application \ndid not load a reference to it since the previous collection. Figure 1 shows an example heap with stale(shadedgray) \nobjects C and D. They have notbeen accessed since thelast collection,because all their incoming references \nare stale, marked with S. Although B hasincomingstale references, B isin-usebecause the refer\u00adence A.Bisin-use. \n 2.2 TheStaleSpace When the garbage collection traces the heap, it now also moves stale objectstothe \nstale space, which resides ondisk. For example,the collector moves stale objectsCand Dfrom Figure1to \nthe stale space, asillustratedbyFigure2. Stub-scion pairs. References from stale objects to in-use objects \nare problematic because moving collectors such as copying and compacting collectors movein-use objects.For \nexample, consider moving B, which has references from C and D. If B moves, we do not want to touch stale \nobjects to updatetheir outgoingreferences, which would violatethe invariants.We solve thisproblemby using \nstub-scionpairs, borrowed from distributed garbage collection [46]. Stub\u00adscion pairs provide two levels \nof indirection. Melt creates a stub object in the stale space and a scion objectin the in\u00aduse spacefor \neachin-use object thatis referencedby one or more stale object(s).The collector avoidstouchingstubs and \nstale objectsby referencingand updatingthe scion.The stub hasasingle .eldthatpointstothescion. Thescionhastwo \n.elds:onepointstothein-useobject andthe otherpointsbacktoits stub.We modifyreferencesin the stale spacethatreferto \nanin-use objectto referinsteadto thestub.Figure3showsBstub and Bscion providingtwolevels ofindirectionfor \nreferencesfrom Cand Dto B.Scions may not move. The collector treats scions as roots, retaining in\u00aduse \nobjectsreferencedbystale objects.Ifthe collectormoves an object referencedby a scion,it updates the scion \ntopoint to the moved object. Figure1. StaleObjects andReferences Figure2. Segregation ofIn-Use andStaleObjects \n Figure3. Stub-ScionPairs Figure4. Scion-ReferencedObjectBecomesStale To ensure eachin-use objecthas \nonlyone stub-scionpair, we use a scionlookup table that mapsfrom anin-use object toits scion,ifithasone.Thisdatastructureisproportional \ntothe number of scions, whichisproportionaltothe number of in-use objects in the worst case, but is usually \nmuch smaller in practice. The collector processes the scions at the beginning of collection. Returning \nto Figure 2, when the collector copies C to the stale space, B initially has no entry in the scion lookup \ntable, so Melt adds a mapping B . Bscion tothetablewhenit creates Bstub and Bscion. Next, when it copies \nD to the stale space, it .nds the mapping B . Bscion inthetable andre-usesthe existing stub-scionpair. \nThe resultingsystem snapshotis showninFigure3.  Itmayseemat.rstthatweneedscionsbutnotnecessarily stubs, \ni.e., stale objects could point directly to the scion. However, we needbothbecause anin-use object referenced \nbya scion maybecome stalelater.For example, considerthe case when Bbecomes staleinFigure3.In orderto \neliminate the scion without a stub(to avoid using in-use memory for stale-to-stalereferences),wewould \nneedto .nd all thestale pointerstothe scion, whichviolatesthe stale spaceinvariant to never visit stale \nobjects after instantiation. Instead, Melt copies B to the stale space,looks up the stublocationin the \nscion, andpointsthe stubto stale B.Note thatMelt accesses the disk both to modify the stub and to move \nthe new stale object.This accessesdo not violateinvariants since arepart of moving an object to the stale \nspace. Melt then deletes the scion and removes the entry in the scion lookup table. Figure4shows the \nresult.  2.3 ActivatingStaleObjects Melt prevents the application from directly accessing the stale \nspace since (1) these accesses would violate the in\u00advariant that the stale space is not part of the application \ns working set, and(2) object referencesinthe stale space may refertostubs and scions.Meltinterceptsapplicationaccess \nto stale objects by modifying the read barrier to check for referencesto the stale space: b = a.f; // \nApplication code if (b &#38; 0x1) { // Read barrier t = b; b &#38;= ~0x1; // Check if in stale space \n if (inStaleSpace(b)) { b = activateStaleObject(b); } a.f = b; [iff a.f == t] b.staleHeaderBit = \n0x0; } TheVMmethodactivateStaleObject() copiesthe stale object to the in-use space. Since other references \nmay still point to the stale version, activateStaleObject() cre\u00adates a stub-scionpairfor the activated \nobject asfollows:(1) it converts the stale space object version into a stub, and Figure5. StaleObjectActivation \n Figure6. ReferenceUpdatesFollowingActivation (2)it creates a scion and points the stub at the scion. \nThe scion points to the activated object. The store to a.f must be atomic with respect to the original \nvalue of b, i.e., [iff a.f == t]. Consider activating C from Figure 4. First, activate-StaleObject() \ncopies C to the in-use space. Then it re\u00adplaces stale C with a stub,allocates ascion, andlinksthem alltogether, \nas showninFigure5.Notethat Cretainsits ref\u00aderences to D and Bstub , and Eretainsits referenceto the old \nversion of C, whichis now Cstub. Ifthe applicationlaterfollows adifferentreferencetothe previouslystale \nobjectin the stale space, activateStale-Object() .ndsthe stubinthe object splace, whichitfol\u00adlowstothe \nscion, whichinturnpointstothe activatedobject. The .rstaccessof such areferencewill updatethereference \ntopointtothe activatedversion and any subsequentaccesses willgodirectly to thein-use object.For example,if \nthe ap\u00adplication accesses a reference from E to Cstub in Figure 5, activateStaleObject() follows Cstub \nto Cscion to C in thein-use space and updates the reference, as showninFig\u00adure6. 2.4 WhentoMoveObjectstotheStaleSpace \nMelt can mark objects as stale and/or move objects to the stale space on anyfull-heapgarbage collection.However,it \ndoes notmake sense toincurthis overheadifthe application is notleaking memory.Furthermore,Melt couldpotentially \n.llthediskfor a non-leakingapplication,producingan error Figure7. StatediagramforwhenMelt marksobjectsasstaleand \nmovesobjectstothestalespace. where none wouldhave existed.Thus,Meltdecides whether to mark and movebased \non howfull theheapis as shownin Figure7. InitiallyMeltis INACTIVE:itdoes not mark or move ob\u00adjects.It \nalsodoes notneed readbarriersif theVM supports adding themlater via recompilation or codepatching(we \ndid notimplement thisfeature).Theheap fullness is the ra\u00adtio of reachable memory to maximum heap size \nat the end of a full-heap collection. Since users typically run applica\u00adtionsinheaps atleasttwicethe \nminimum neededtokeepGC overheadlow,bydefault weuse50%fullnessasthe unex\u00adpected heap fullness. If the \nheap fullness exceeds this ex\u00adpected amount, Melt moves to the MARK state, where the GC marks all objects \nand references during the next full\u00adheapGC. AfterGCmarksallobjectsandreferences,Meltentersthe WAIT state. \nIt remains in the WAIT state until the program is close to memory exhaustion; then it enters the MOVE \n&#38; MARK state.Bydefault this thresholdis80%heapfullness. Users could specify 100%heapfullness, which \nwould wait until completeheap exhaustionbefore using the stale space. However, comingcloseto running \nout of memorybringsthe application to a virtual halt because garbage collection be\u00adcomes extremelyfrequent.In \nMOVE &#38; MARK, Melt moves all objects still markedtothe stale space.It marks all objects that remainin \nthein-use space, so they canbe movedto the stale space later if still marked. If the heap is still nearly \nfull (e.g., for fast-growing leaks), Melt remains in MOVE &#38; MARK for anotherfull-heapGC.Otherwise,it \nreturnsto WAIT until theheap.llsagain,and thenit returnsto MOVE &#38; MARK, and so on. Melt could potentially \nreturn to IN-ACTIVE if memory usagedecreased to expectedlevels(not shown). 3. ImplementationDetails This \nsection presents details speci.c to our implementa\u00adtion. Our approach is suitable for garbage-collected, \ntype\u00adsafe languages using tracing garbage collectors. We call ourimplementationMeltfor simplicity.WeimplementMelt \nin Jikes RVM 2.9.2, a high-performance Java-in-Java vir\u00adtual machine[1,2,32].TheDaCapobenchmark regression \ntestspageshowsthatJikesRVMperformsthe sameasSun Hotspot 1.5 and 15 20% worse than Sun 1.6, JRockit, and \nJ91.9, allcon.guredforhighperformance[16].Ourperfor\u00admance measurements are therefore relative to an excellent \nbaseline. Wehave madeMeltpubliclyavailable on theJikesRVM ResearchArchive[33]. 3.1 VMIssues Garbage \ncollection. Melt s design is compatible with moving and non-moving tracing collectors, such as copy\u00ading, \ncompaction, and mark-sweep, all of which are in use bymodernhigh-performanceVMs.Todemonstratethe .ex\u00adibility \nand generality of Melt, we use a high-performance generationalcopying collector.SinceMelt correctlyhandles \nmovingin-use objects,the most challengingcase,it can eas\u00adily handle non-moving collectors as well. The \ngenerational collector allocates objects into a nursery; when the nursery .lls, the collector traces \nthe live nursery objects and copies them into a copying mature space. The collector reserves half the \nmature space for copying. When the mature space .lls, the collectorperforms afull-heap collectionthat \ncopies alllive mature objectsinto the mature copy reserve. Jikes RVM s memory manager, the Memory Manage\u00adment \nToolkit (MMTk) [6], supports a variety of garbage collectors with most functionality residing in shared \ncode. Melt residesmostlyinthis shared code.Tosupport another collector, one must implement a method that \nspeci.es (1) the space(s) that containpotentially stale objects and(2) the spaceinto which to activate \nobjects. Identifying stale objects. To identify stale objects, Melt modi.es(1) the compilerto add readbarrierstothe \nappli\u00adcation and(2) the collector to markheap references and ob\u00adjects stale. Jikes RVM uses two compilers: \nan initial base\u00adline compiler and an optimizing compiler invoked for hot methodsatsuccessivelyhigheroptimizationlevels.Bothadd \nMeltreadbarriers.For ef.ciency and simplicity, we exclude VM objects and objectsdirectlypointed toby \nroots(regis\u00adters, stacks, and statics) as candidatesfor the stale space. Moving large objects. Like most \nVMs, MMTk allocates large objects (8 KB or larger) into a special non-moving large object space (LOS). \nSince we needto copy large ob\u00adjects todisk, we modifytheLOStohandle copying.During collection,whenMelt \n.rst encountersastalelargeobject,it movesittothe stale space, updatesthe reference,andinstalls aforwardingpointer \nused to correct any other references to this object.Atthe end ofthe collection,it reclaimsthe space for \nanylarge objectsit moves.Activation worksin the same way asfor other object sizes. Activating stale objects. \nMelt uses read barriers to inter\u00adcept applicationreadstothe stale space(Section2.3).Melt immediatelycopiesthe \nobjecttothe mature space(or alarge object spaceifthe objectislarge) and updatesthe reference. Since activation \nallocates into the in-use part of the heap, it may triggeragarbagecollection(GC).Applicationreads are \nnot necessarily GC-safe points. GC-safe points require the VM to be able to enumerate all the pointers \ninto the heap, i.e., to produce a stack map of the local, global, and temporary variablesin registers.InJikesRVM(asin \nmany other VMs), allocations, method entries, method exits, and loopbackedges areGC-safepoints.If an \nactivationtriggers aGC,Meltdefers collectionby requesting an asynchronous collection, which causes collection \nto occur at the nextGC\u00adsafepoint.  3.2 StaleSpaceonDisk 64-bit on-disk addressing. Melt uses an on-disk \nstale space with 64-bit addressing, even though memory is 32\u00adbit addressed.Whenit moves a stale object \ntodisk,it uses a 64-bitaddress and expandsthe object s reference slots to64 bits. Similarly, it uses \n64-bit stubs. Most stale objects refer tootherstale objects.Forstale objectsreferencedbyin-use objects, \nwe use alevelofindirectiontohandlethetranslation from32-to64-bit addresses.These mapping stubs residein \nmemory,but reference64-bit on-diskobjects.TheGCtraces mapping stubs, which resideinin-use memory, and \ncollects unreachable mapping stubs. The number of mapping stubs isboundedby the number of referencesfromin-use \nto stale memory,whichis smallinpractice,andis at worstpropor\u00adtional toin-use memory. Figures 8 and 9 \nshow the 64-bit on-disk stale space rep\u00adresentation for Figures 5 and 6. The main difference is the mapping \nstub space, which provides indirection for refer\u00adences from the in-use space to the stale space. Three \ntypes of referencesare64bits: mapping stubs,referencesinstale objects, andpointersfrom scionstotheir \nstubs.If a stale ob\u00adject references an in-memoryobject, e.g., Cstub . Cscion in Figure9, the reference \nuses onlythelower32bits. We use swizzling [39,58]to convertreferencesbetween 32-bit in-memory and 64-bit \non-disk addresses. When the collector moves an object to the stale space, it unswizzles outgoing reference \nslots.If a slot references a mapping stub, the collector storesthetarget ofthe mapping stubinthe slot, \nin orderto avoid usingin-use memory(the mapping stub) for anintra-disk reference.When a readbarrier activates \nan object in the stale space, it swizzles outgoing references by creating the mapping stubfor each slot \nthat references a64\u00adbitobject.Whenthe applicationactivates CinFigure8,Melt swizzles its references to \nBstub and D by creating mapping stubs BSms (mappingstubof Bstub)and Dms, and redirecting the referencesthroughthem, \nas showninFigure9. Figure8. Figure4withOn-DiskStaleSpace Figure9. Figure5withOn-DiskStaleSpace Buffering \nstale objects. Melt initially moves stale objects intoin-memorybuffers that each correspond to a64-bit \non\u00addisk address range. Buffering enables object scanning and object expansion(from32-to64-bit referenceslots) \nto oc\u00adcur in memory, and it avoids performing a native read() callfor every object moved to the stale \nspace.Furthermore, Melt .ushes these buffers to disk gradually throughout ap\u00adplicationexecutiontime,avoidingincreasedcollectionpause \ntimes. 3.3 Multithreading Melt supports multiple application and garbage collection threads by synchronizing \nshared accesses in read barriers, the scionlookuptable, andthe stale space.The scionlookup tableis a \nshared,globalhash table usedduringgarbage col\u00adlection to .nd existing scions for in-use objects referenced \nby the stale space. For simplicity, table accesses use global synchronization, but for better scalability, \na future imple\u00admentationcould use .ne-grained synchronizationoralock\u00adfreehashtable. Stale space accesses \noccur when the collector moves an object to the stale space or the application activates a stale object.Meltincreasesparallelismby \nusing one .lepercol\u00adlectorthread(thereis one collectorthreadperprocessor)and byusingthread-localbuffersfor \nstale objectsbefore .ushing themtodisk.Each thread allocates stale objectsto adiffer\u00adent part of the \n64-bit stale address range: the high 8 bits of the address specifythe threadID. An application thread \nmay activate an object allocated by the collector thread on another processor. In this case, the read \nbarrier acquires a per-collector thread lock when accessing thecollectorthread sbuffersand .le.WhenMelt \n.ushes stalebuffersinparallel with application execution,it acquiresthe appropriate collector thread \nslock.  3.4 SavingStaleSpace This section discusses approaches for reducing the size of the stale space.Wehave \nnotimplementedthese approaches. With Melt as described, garbage collection is incomplete because it does \nnot collect the stale space. Stale objects may become unreachable after they are moved to the stale space \nand furthermore, they may refer to in-use objects. These uncollectible in-use objects will eventually \nmove to thestale spacesincethey areinherently stale.Forexample, even if C in Figure 6 becomes unreachable, \nthe scion will keep it alive and it will eventually move to the stale space. One solution would be to \nreference-count the stale space, but reference counting cannot collect cycles. Alternatively, Meltcould \noccasionallytrace all memoryincludingthe stale space. An orthogonal approach would be to compress the \nstale space [12]. The stale space is especially suitable for compression compared with a regularheapbecausethe \nstale spaceis accessedinfrequently. 4. Results This section evaluates Melt s performance and its ability \nto tolerate leaks in several real programs and third-party microbenchmarks. 4.1 PerformanceMethodology \nVMcon.gurations. Bydefault,JikesRVMinitiallyuses a baseline non-optimizingcompilertogenerate machine \ncode. Over time, it dynamically identi.es frequently-executed methods and recompiles them athigher optimizationlevels. \nWe refer to experiments using this default execution model as using adaptive methodology. Because Jikes \nRVM uses timer-based sampling to detect hot methods, the adaptive methodologyis nondeterministic.For \nexample, compilation allocates memoryandperturbsgarbagecollection workload. To eliminate this source \nof nondeterminism, we use replay methodology[31,43,51].Replay uses advice .lestoforce theVM to compile \nthe same methods at the same level and point in execution and with the same pro.le information executions \nand thus avoidshigh variabilitydueto sampling\u00addriven compilation. Benchmarks. To measureMelt s overhead,we \nusetheDa-Capo benchmarks version 2006-10-MR1, a .xed-workload version ofSPECjbb2000 called pseudojbb, \nandSPECjvm98 [7,53,54]. Platform. Performance experiments execute on a dual\u00adcore3.2GHzPentium4 system \nwith2GB of main memory runningLinux2.6.20.3.Each corehas a64-byteL1 andL2 cacheline size, a16-KB8-wayset \nassociativeL1data cache, a 12K\u00b5ops L1 instruction trace cache, and a 1-MB uni.ed 8-way set associative \nL2 on-chip cache. The top four leaks inTable2 execute on aCore2Quad2.4GHz system with2 GB of main memory \nrunningLinux2.6.20.3,with126GB offreedisk space.Each corehas a64-byteL1 andL2 cache line size, an 8-way \n32-KB L1 data/instruction cache, and eachpair of cores shares a4-MB16-wayL2 on-chip cache. 4.2 Melt \nsOverhead Application overhead. Figure 10 presents the run-time overhead of Melt. We run each benchmark \nin a single mediumheap size,twotimesthe minimumin whichit can execute.Eachbaris normalizedto Base(anunmodi.edVM) \nand includes application and collection time, but not com\u00adpilation time. Each bar is the median of .ve \ntrials; the thin error bars show the range of the .ve trials. For all experi\u00adments, exceptfor some bloatexperiments, \nrun-to-run varia\u00adtionisquitelow since replaymethodologyeliminates almost all nondeterminism.The variationin \nbloatishighingeneral and not relatedto these con.gurations.Thebottom sub-bars are thefraction of time \nspentingarbage collection. Barriers includes only Melt s read barrier; the barrier s condition is never \ntrue since the collector does not mark references stale. Marking performs marking of references and objects \non everyfull-heapGC,i.e.,Meltis alwaysinthe MARK state(Section 2.4). Melt memory performs marking and \nmoving tothe stale space on everyfull-heapGC(i.e., Melt is always in the MOVE &#38; MARK state), but \nthe stale spaceisin memory ratherthan ondisk.This con.gurationis analogousto addingathirdgenerationbasedon \nobjectusage in a generational collector. Finally, Melt marks objects and moves objects to the on-disk \nstale space on every full-heap GC. Thegraph showsthatthe readbarrieralonecosts6% on average, and adding \nMarking adds no noticeable overhead. TheMeltmemory con.guration,whichdividestheheapinto in-use andin-memorystale \nspaces,has a negligible effecton overallperformance.Infact,it sometimesimprovescollec\u00adtorperformance(seebelow).Storing \nstale objects ondisk (Melt) adds 1% to average execution time because of the extra costs of swizzling \nbetween 32-and 64-bit references and transferring objects to and from disk. Melt improves theperformanceof \nafewprogramsrelativetobarrierover\u00adhead.Thisimprovementcomesfrombetterprogramlocality (jythonand lusearch)andlowerGC \noverhead(xalan). Melt s 6% read barrier overhead is comparable to read barrier overheadsfor concurrent,incremental, \nand real-time collectors[4,17,45], whoseincreasingprevalence maylead togeneral-purposehardware supportfor \nreadbarriers.Melt achieveslow overheadbecausethe common caseisjust two IA32 instructions in optimized \ncode: a register comparison Figure10. ApplicationexecutiontimeoverheadofMelt con.gurations. Sub-bars \nareGC time. Total Average per GC Moved to stale Activated  In-use Stale In.St St.In Scions GCs antlr \n 157,486 (10MB) 28 (0MB)  68,331 (7MB) 104,877 (6MB) 1,592 6,250 2,692 4 bloat 337,126 (19MB) 51,970 \n(2MB) 127,335 (9MB) 238,167(14MB) 13,196 29,701 10,358 6 chart 192,810 (10MB) 107 (0MB) 95,139(14MB) \n153,928 (8MB) 22,443 23,440 4,079 6 eclipse 1,789,252(102MB) 478,518(17MB) 258,823(18MB) 1,096,570(65MB) \n48,590 607,619 81,852 24 jython 215,807 (14MB) 16,842 (1MB) 47,253 (6MB) 193,691(12MB) 21,028 45,467 \n30,818 15 luindex 157,814 (9MB) 308 (0MB) 55,033 (7MB) 118,091 (7MB) 17,718 21,281 1,333 5 lusearch \n249,709 (16MB) 20,287 (2MB) 92,224(43MB) 205,606(13MB) 7,593 10,622 9,493 9 pmd 475,714 (26MB) 28,064 \n(1MB) 125,625 (8MB) 337,292(19MB) 39,811 18,787 10,419 16 xalan 701,733(151MB) 18,892 (1MB) 43,538(13MB) \n461,928(87MB) 26,741 77,565 5,173 101 Table1. Statisticsfor theDaCapobenchmarks runningMelt(everyGC) \nwith1.5times the minimumheap size. Normalized GC time Figure11. NormalizedGCtimesforMeltcon.gurations \nacrossheap sizes. and a branch. An alternative to all-the-time read barriers would be to start without \nread barriers and recompile all methods only when theprogram enteredthe MARK state. Collection overhead. \nFigure11showsthegeometric mean of the time spentingarbage collection as afunction ofheap size for all \nour benchmarks using Melt. We measure GC times at1.5x,2x,3x, and5xthe minimumheapsizefor each benchmark.Times \nare normalizedtoBasewith5x minheap. Note that they-axis starts at1and not0. The graph shows Marking \nslows collection by up to 7% forthe smallerheapsizes.The other con.gurations measure boththe overheadandbene.ts \nof usingthe stale space. Melt memory, which enjoys thebene.ts of reducedGC workload andfrequencydueto \nstale spacediscounting, speeds collec\u00adtion15% over Markingand8% over Base forthe1.5xheap. Melt adds up \nto10%GC overhead over anin-memory stale spaceduetopointerswizzlingandtransferringobjectstoand fromdisk.This \ncon.guration adds upto10% overthebase\u00adlineinlargeheaps,butbene.tsand costs areroughly equal atthe smallestheap \nsize, whereMelt netsjust1% overthe baseline. Compilation overhead. We also measurethe compile-time overheads \nof increased code size and slowing downstream optimizationsdueto readbarriers.Adding readbarriersin\u00adcreasesgeneratedcode \nsizeby10% and compilationtimeby 16% onaverage.Because compilationaccountsforjust4% on average of overall \nexecution time, the effect of compila\u00adtion on overallperformanceis modest. Melt statistics. Table 1 presents \nstale, in-use, and other statistics for Melt running the DaCapo benchmarks and marking and moving objects \nevery full-heap GC (i.e., the Leak (LOC) Melt s effect Reason EclipseDi. (2.4M) Runs until24-hr limit \n(1,000Xlonger) Virtuallyall stale EclipseCP (2.4M) Runs until24-hr limit (194Xlonger) All stale? JbbMod \n(34K) Runs untilcrash at 20hours (19Xlonger) All stale? ListLeak (9) Runs untildisk full(200Xlonger) \nAll stale SwapLeak (33) Runs untildisk full(1,000Xlonger) All stale MySQL (75K) Runs untilcrash(74Xlonger;high \nactivation overhead) Almostall stale Delaunay (1.9K) Some help;highactivation overhead Short-running \nSPECjbb2000 (34K) Runs 2.2Xlonger Most stale memoryin use DualLeak (55) Runs 2.0Xlonger Almostall stale \nmemoryin use Mckoi (95K) Runs 2.2Xlonger Threads stacks leak Table2. TenleaksandMelt sabilitytotoleratethem. \nMelt con.guration usedinFigures10 and11).We run with a small heap, 1.5 times the minimum heap size for \neach benchmark,in order to triggerfrequent collections and thus exerciseMelt moreheavily.Thetablepresentsthetotalnum\u00adber \nof objects moved to the stale space and activatedby the program.Italso shows objectsinthein-use and stale \nspaces, pointers from in-use to stale and from stale to in-use, and scions, averaged over each full-heap \nGC except the .rst, which we exclude since it does not move any objects to thestalespace.The .nal columnisthenumberoffull-heap \nGCs. We exclude fop and hsqldb since they execute fewer than twofull-heapGCs. Thetable showsthatMelt \nmoves9 151MB tothe stale space, and the program activates 0 17 MB of this mem\u00adory.Somebenchmarks activate \na signi.cantfraction of stale memory,for example, morethan10%for bloat, eclipse, and lusearch due to \nthis experiment s aggressivepolicy of mov\u00ading objects to the stale space on every GC. The next two columns \nof Table 1 show that often more than half of the heap is stale for a long time, which explains the reductions \nin collectiontime observedinFigure10.Leaktolerance can improve the performance of applications that do \nnot have leaksper se butonly use a smallportion of alarger working setfor signi.cantperiods of time.Used \nthis way,leak toler\u00adanceisanalogoustoa .ne-grained virtual memory manager for managedlanguages. The In.St \ncolumn shows the average number of refer\u00adencesfromin-useto stale objects.These referencesrequire a mapping \nstub to redirect from 32-bit memory to 64-bit disk,but there are usually sign.cantlyfewer mapping stubs \nthan in-use objects. The St.In and Scions columns show the number of referencesfrom staletoin-use objects \nandthe numberof scions,respectively.The next sectionshowsthat forgrowingleaks,the number ofscions stays \nsmall andpro\u00adportional to in-use memory, while references from stale to in-usegrow withtheleak, motivatingleaktolerance \ns use of stub-scionpairs.  4.3 ToleratingLeaks This section evaluateshow wellMelttoleratesgrowingleaks \nby running them longer and maintaining program perfor\u00admance. Table 2 shows all 10 leaks we found and \ncould re\u00adproduce: twoleaksinEclipse, EclipseDi. and EclipseCP;a leakin aMySQLclientapplication;aleakin \nDelaunay,a sci\u00adenti.c computing application; a real leak in SPECjbb2000 and aninjectedleakinSPECjbb2000 \ncalled JbbMod;aleak in Mckoi, a database application; and three third-party mi\u00adcrobenchmarkleaks: ListLeakand \nSwapLeakfromSunDe\u00adveloperNetwork, and DualLeakfromIBMdeveloperWorks. Melt tolerates 5 of these 10 leaks \nwell; it tolerates 2 leaks butaddshigh overheadby activating many stale objects; and itdoes notsigni.cantlyhelp3leaks. \nMelt cannot tolerate leaks in SPECjbb2000 and Dual-Leak because they are live leaks: theprogramsperiodically \naccess the objects they access. For example, DualLeak re\u00adpeatedly adds String objects to a HashSet. It \ndoes not re\u00admoveor usethese objects again.However,whenthe Hash-Set grows, it re-hashes all the elements \nand accesses the Stringobjects, sothe Stringcannot remaininthe stale space permanently. It seems challenging \nin general to determine that an object being accessed is nonetheless useless. How\u00adever,future work coulddesign \nleak-tolerantdata structures that avoid inadvertently accessing objects that the applica\u00adtion has not \naccessed in a while. At least two other leaky programs,EclipseDi. and MySQL,haveliveleaks, although theyleak \nsigni.cantly moredead thanlive memory, soMelt can still improve their longevity and performance signi.\u00adcantly. \nWe runthefollowingexperimentsin maximumheapsizes chosen to be about twice what each program would need \nif it were not leaking. All the programs except Delaunay havegrowingleaks, sotheirbehavior withand withoutMelt \nis not very sensitive to maximum heap size. All programs have a memory ceiling, which may be heap size, \nphysical memory, or virtual memory, although physical memory is always a ceiling sinceit causesGC tothrash[26,60].Melt \nextends a progam s memory ceiling to include all available disk space, substantially postponing a crash. \nWe run Jikes RVMin uniprocessormodebecauseinmultiprocessormode, Jikes RVM the VM often crashes before \ncompleting runs lasting many Sun JVM Melt hours, apparentlydue tobugsinMelt orJikesRVM. EclipseDi.. Eclipse \nis an integrated development envi\u00adronment (IDE) written in Java with over 2 millions lines of source \ncode [18]. We reproduce Eclipse bug #115789, which reports that repeatedly performing a structural (re\u00adcursive) \ndiff, or compare, slowly leaks memory that even\u00adtuallyleads to memory exhaustion.Theleak occursbecause \n 50 100 150 200 250 300   Iteration a data structure for navigation history maintains references \nitshould not.ItexistsinEclipse3.1.2butwas .xedby de-Figure 12. Performance comparison of Jikes RVM, Sun \nvelopers for Eclipse 3.2 after we reported a .x in previous JVM, and Meltforthe .rst300iterationsofEclipseDi.. \nleakdetection work[9]. We automaterepeatedstructuraldifferencesviaanEclipse plugin that reports the wall \nclock time for each iteration of thedifference.Figure12 shows thetime eachiterationtakes for vanilla \nJikes RVM 2.9.2, the Sun JVM 1.5.0, and Jikes RVM withMelt.Weuseiterationsasthex-axis.This .gure shows \nthe .rst 300 iterations in order to compare the three VMs, andFigure13shows theperformance ofjustMeltfor \nits entirerun(terminatedby usafter24hours).Unmodi.ed  JikesRVM slows and crashes after about50iterations \nwhen 0 20000 40000 60000 its heap .lls. Sun JVM, which uses a more space-ef.cient Iteration collector \nthan the generational copying collector used by Jikes in our experiments, runs almost 200 iterations \nbefore leakfor24hours. grindingto ahaltand crashing. Melt s performance stays steady in the long term \nwith variations in the short term. All VMs performance varies periterationbecauseiterationsinterruptedbyafull-heapGC \ntake longer. Melt s performance varies more because full\u00adheap GCs that move objects to the stale space \ntake longer: Meltmoves objectstothe stale space, unswizzlestheir refer\u00adences, and creates stub-scionpairs \nand mapping stubs.Melt buffersnew stale objectsin memoryduring theseGCs, and it .ushes these buffers \nto disk gradually during application  execution.Withoutthisgradual.ushing,performancevaries more. When \nwe terminate Melt at 24 hours, it has written Iteration over80GB to the on-disk stale space. Figure 14. \nComparison of reachable memory for the Figures14and15 show reachable memory, as reported at .rst300iterations \nof EclipseDi.. the end of thelastfull-heapGC,forthe sameVMs at each iteration.Unmodi.edJikesRVM andSunJVM \n.ll theheap as the leak grows, while Melt starts moving stale objects to the disk when the heap reaches \n80% full, and it keeps memory usage fairly constant in the long term. The .gures show that memory usage \noscillatesgraduallybetween about 100 and 130 MB: (1) Melt moves objects to buffers for the stale space \nwhen usage reaches 130 MB; (2) it then slowly.ushesthesebufferstodisk overtime; and(3)inthe meantime, \nthe leak continues to increase heap size until it  reaches130MB again and triggersMelt to repeat the \ncycle. Figures 16 and 17 report numbers of objects and refer\u00adences at eachiteration of the EclipseDi..Wedividethedata \n Figure15. Reachablememoryrunning EclipseDi. with between twographs since the magnitudes varygreatly.Fig- \n Meltfor24hours. ure16 showsthat referencesfrom stale toin-use and objects  Figure16. EclipseDi. leak \nwith Melt: stale objects and referencesfrom stale toin-use.   without Melt (logarithmic x-axis to show \nbehavior of both VMs). inthe stale spacebothgrowlinearlyoveriterations andhave large magnitudes. This \nresult motivates avoiding a solution that uses time or space proportional to stale objects or ref\u00aderences \nfrom stale to in-use objects. Figure 17 shows that Meltholdsin-use objects relativelyconstant overiterations. \nThe number of scionsgrowslinearly overtime, althoughit stays small in magnitude: roughly one scion per \niteration. This growth occurs because a very small part of the leak is live.Eachiterationleaks alargedata \nstructure, and the root objectof this structureremainslive,and this objectuses an extra scion. Thegraphshows \nthat the number of objects activatedin\u00adcreases linearly but its magnitude is still small compared with \nobjectsinthe stale space,i.e.,just afew stale objects are activated.Each activated object needs a scion, \nand many moreobjects areactivatedthantherearescions,whichshows that the application activates the same \nobjects over and over again.Future work could consider adifferentpolicyfor ob\u00adjects that have been activated. \nThe fact that scions stayrel\u00adatively small while stale-to-in-use references grow signi.\u00adcantly, motivatesMelt \ns use of stub-scionpairsto maintain referencesfrom stale toin-use objects. For the other leaks in this \nsection that Melt tolerates, we observe similar ratios for in-use and stale objects and referencesbetweenthem. \nEclipseCP. We reproduceEclipsebug#155889,whichre\u00adports a growing leak when the user repeatedly cuts text, \n1 10 100 1000 Iteration Figure19. EclipseCPreachable memory overtime, with and withoutMelt (logarithmic \nx-axis). saves,pastes the sametext, and saves again.AnEclipseplu\u00adgin we wrote exercises the GUI to perform \nthis cut-paste behavior.Figure18 showsthe runtime of eachiteration of a cut-save-paste-save of a large \nblock of text, using a loga\u00adrithmic x-axis since unmodi.ed Jikes runs for a short time before running \nout of memory. We do not present data for SunJVM since we could not reproducetheleak withit.The .gure \nshows that Melt adds some overhead to EclipseCP, butitis ableto execute withfairly constantlong-termper\u00adformancefor \nnearly200times as manyiterations as without Melt. We terminate Melt after 24 hours, at which point it \nhas used39GB ofdisk space.We note thattheperformance .uctuations are due to the application, not Melt, \nsince they occurwithunmodi.edJikesRVM.Figure19shows memory usage overtime, with and withoutMelt.Meltholds \nmemory fairlysteadyinthelongterm.The short-term .uctuationsare duetoMeltmoving objectsgraduallyto the \nstale space each time theheap reaches80%. JbbMod. SinceSPECjbb2000(seebelow)has signi.cant live heapgrowth,Tang \net al. modi.editbyinjecting aleak of dead(permanentlystale)objects[57].Thisversion,which we call JbbMod,is \na very slow-growingleak.Melt runs al\u00admost21hours(almost20times moreiterationsthan without Melt) before \ncrashing with an apparent heap corruption er\u00adror, likely due to a bug in Melt. During this time, it keeps \nperformance andmemory usagefairly constant.We thusbe\u00adlieve that all heap growth is dead and, in lieu \nof crashing, Melt would runtheprogram aslong asdisk space allowed. ListLeak. The .rst microbenchmark \nleak is from a post ontheSunDeveloperNetwork[56].Itis avery simpleand fast-growingleak: List list = new \nLinkedList();  while (true) list.add(new Object()); 200 400 600 800 1000 Iteration Clearly this leak \ngrows very quickly. Whereas unmodi.ed Jikes RVM and Sun JVM crash in seconds, Melt keeps withoutMelt. \nThey-axisislogarithmicbecause somepause ListLeak running until it .lls 126 GB of disk, which takes times \narequitehigh. about100 minutes. SwapLeak. This leak also comes from a message posted ontheSunDeveloperNetwork[55].The \nmessage asksfor help understanding why an attached program runs out of memory.Theprogram .rstinitializesanarray \nof1,000,000 SObjects, which each contain an inner class Rep. The pro\u00adgram then swaps out each SObject \ns Rep object with a new SObject s Rep object. Intuitively it seems that the second operation should have \nno net effect on reachable memory. However,as explainedbya responsetothe message,theVM keeps a referencefrom \naninner class objectbacktoits con\u00adtainingobject, whichcausesthe swapped-outRepobjectand the new SObjecttoremainreachable.The \n.xistomakethe innerclassstatic,butMeltprovidestheillusionofa .xwith\u00adout needingtounderstand orapplythe \n.x. The swapping operation leaks only about 64 MB, so we add a loop around this operation to create a \ngrowing leak. SwapLeak grows nearly as quickly as ListLeak, and unmodi.edJikesRVM andSunJVM survivefewerthan \n.ve iterations.Meltrunsitfor2,341iterations(7hours)andthen terminateswhenit .llstheavailable126GB ofdisk \nspace. MySQL. The MySQL leak is a simpli.ed version of a JDBC application from a colleague. The program \nexhausts memory unless it acquires a new connection periodically. Theleak, whichisin theJDBClibrary, \noccursbecauseSQL statements executed on a connection remain reachable un\u00adless the connectionis closed \nor the statements are explicitly closed.The MySQLleakrepeatedlycreates aSQL statement andexecutesit on \naJDBC connection.We count1,000state\u00adments as an iteration. The application stores the statement objects \nin a hash table. The program periodically accesses them when the hash table grows, re-hashing the statement \nobjects. However, in terms of bytes, objects referenced by the statement objects contribute much more \nto theleak,i.e., the vast majority of objects arepermanently stale. Melt tolerates this leak but periodically \nsuffers a huge pause whenthehashtablegrows and re-hashesits elements, which activates all statement objects. \nFigures 20 and 21 show theperformance(logarithmicy-axis) and memory us\u00ad  Iteration age of MySQL over \ntime, with and without Melt. Unmodi-.edJikesRVMandSunJVMquicklyrunoutofmemory,but Meltkeeps theprogram \nrunningfor74 times as manyitera\u00adtionsasJikesRVM.Whenthehashtableofstatementsgrows and re-hashes its elements, \ne.g., at iterations 300 and 600, pause times rise to30minutes.Ourimplementation ofMelt is notoptimizedfor \nactivationperformance sinceitdoes not considerlocality when moving objectstodisk or activating objects, \nso afutureimplementation couldpotentiallydobet\u00adter.Alternatively, animplementation couldattemptto recog\u00adnize \nthat statement objects arelive rather thandead. Meltterminateswithanunrelatedcorruptionerror,mostly likelycausedby \nabuginMelt orperhapsJikesRVM, after4 hours and20 minutes.Melt could tolerate theleaklongerif theVMdid \nnot crash, albeit withperiodicpauses to activate all statement objects. Delaunay. Next wepresent aleakin \nDelaunay, an appli\u00adcation thatperforms aDelaunay triangulation, whichgener\u00adates a triangle mesh, for \na set of points, that meets a set of constraints[22].We obtained theprogramfrom colleagues who added \na history directed acyclic graph (DAG) to re\u00adduce algorithmic complexity of the triangulation, but the \nInput Jikes Melt memory Melt   from useless memory accesses. We note that prior work on staleness-based \nleak detection diagnoses this leak because a smallpart of each order sdata structureis stale[9].Melt \nexecutes SPECjbb2000about twice aslong as withoutMelt (1166vs. 540 iterations) since it .nds some stale \nmemory to movetodisk.However,performance suffersbeginning at about 650 iterations because Melt starts \nmoving many ob\u00adjects thatare notpermanently stale todiskin order to avoid running out of memory, resulting \nin signi.cant activation overhead. DualLeak. This leak comes from an example in an IBM developerWorkscolumn[23].We \ncallit DualLeak since its 55 sources lines contain two different leaks. The program executes in iterations \nand exercises both leaks during each iteration.The .rstleakis slow-growingand occursbecause of an off-by-one \nerror that leads to an Integer object not being removed from a Vector on each iteration. The other leakgrows \nmorequicklyby adding multiple String objects to a HashSeton eachiteration. Melt cannot tolerate either \nleak since the program ac\u00adcesses all of the Vector and HashSet periodically.The Vec\u00adtor leakaccesses \nall slotsin the Vectoreveryiteration, since it removes elements from the middle of the vector, causing \nall leaked elements to the right to be moved one slot to the left.TheHashSetrepeatedly adds Stringobjectsthat \nare ac\u00adcessedduring re-hashing. Melt executes twice as many iterations of DualLeak as unmodi.ed Jikes \nRVM by swapping out the HashSet ele\u00adments when they are not in use. But this approach is not sustainable.When \nthe HashSet grows,Meltactivatesits el\u00adements,hurtingperformanceand eventually running out of memory. \nMckoi. We reproduce a memory leak reported on a mes\u00adsage board for Mckoi SQL Database, a database manage\u00adment \nsystem writteninJava[37].Theleak occursif apro\u00adgram repeatedlyopens adatabase connection, uses the con\u00adnection, \nand closes the connection. Mckoidoes notproperly dispose ofthe connectionthread,leadingto agrowing num\u00adber \nof unused threads.These threadsleak memory; most of theleakedbytes arefor each thread s stack. Melt cannot \ntolerate this leak because stacks are VM objects in Jikes RVM, so they may not become stale. Also, program \ncode accesses the stack directly, so read barriers cannotinterceptaccessesto stale objects.However,we \ncould modifyMelttodetect stale threads(threads not scheduled for a while) and make their stacks stale \nand also allow objects directly referenced by the stack to become stale. If the scheduler scheduled a \nstale thread, Melt would activate the stack and all objects referencedby the stack. Melt runs theleakfor \nabout twice aslong as unmodi.ed Jikes RVM because Melt still .nds some memory to swap out that is not \nin use, but soon the leaked stacks dominate memory usage and exhaust memory. size Time Time Time Stale \nActivated 15,000 7s 7s 7s 0MB 0MB 20,000 11 s 10 s 12 s 0MB 0MB 21,000 12 s 14 s 15 s 0MB 0MB 22,000 \nOOM 18 s 45 s 90MB 14MB 25,000 OOM 19 s 98 s 94MB 18MB 30,000 OOM 27 s 166 s 118MB 25MB Table 3. Delaunay \nrun times, stale memory, and acti\u00advated memory for various input sizes. OOM means out of memory. changeinadvertently \ncausedgraph components nolongerin thegraphto remain reachable. Delaunay is not a growing leak in a long-running \npro\u00adgram.Rather,thisleakdegradesprogramperformance and preventstheprogramfromrunninginputsizes andheapsizes \nthat would work without the leak. To highlight this prob\u00adlem, we execute the program with a variety of \ninput sizes, comparingJikesRVM toMelt s memory anddisk con.gu\u00adrations. Table 3 shows run times for all \ncon.gurations and how much memoryis transferred to andfromdisk using a maxi\u00admumheap sizeof256MB and avariety \nofinput sizes with afocus on21,000-22,000iterations, whentheprogram ex\u00adhausts memory.We setthethresholdfor \nmoving objectsto the stale space at 95% to avoid moving objects to the stale space too aggressively. \nFor input sizes =21,000 iterations, all VMs perform similarly since the program has enough memory. Starting \nwith 22,000 iterations, Melt tolerates the leakwhilethe unmodi.edVM runs out of memory.Theper\u00adformance \nofMeltwith anin-memory stale space scales well withinput size.The on-disk stale space sperformancedoes \nnot scale well because Melt activates many objects from disk, whichbecomes expensive when the workingset \nof ac\u00adcesses exceedsdiskbuffering.Atsomepoint,Meltisgoing beyond tolerating theleak,i.e., theheap would \nnotbelarge enough even if the leak were .xed, as indicated by the in\u00adcreasing amount of activated memory. \nThese results show that Melt can help somewhat with short-runningleaks,butit can add signi.cantoverheadifit \nincorrectlymoves manylive objectsto the stale space, since activation overhead willbehigh. SPECjbb2000. \nSPECjbb2000 simulates an order pro\u00adcessing system and is intended for evaluating server-side Javaperformance[54].It \ncontainsaknown,growing mem\u00adoryleak that manifests whenit runsfor along time without changing warehouses. \nIt leaks because it adds orders to an order list that should have no net growth and does not cor\u00adrectly \nremove some of them. Although SPECjbb2000 experiences unbounded heap growthovertime,it uses almost allthe \nobjects.Theprogram periodically accesses all orders in the order list. It seems unlikely that any system \nwill be able to differentiate useful 5. RelatedWork Although there is a lot of prior work on detecting \nleaks, only afew researchershave tried to tolerateleaks.Ourleak tolerance approach improves over previous \napproaches by offering a comprehensive and safe solution that identi.es stale objects andhandles smallleakingobjects \nwithtime and spaceproportionaltoin-use memory. 5.1 DetectingLeaks Static analysis for C and C++ detects \nleaks before the pro\u00adgram executesbutcanproducefalsepositives[14,25].This prior work focuses on identifying \nunfreed, unreachable ob\u00adjects whereas our work addresses reachable but dead ob\u00adjects. Dynamic tools for \nCand C++ track allocations, heap updates, andfreesto report unfreed objects[24,35,40] or track object \naccesses to report stale objects[15,47].Online leakdetectorsfor managedlanguagesidentifyheapgrowth orstaleobjectsto \n.ndpotentialleaks[9,34,38,44,49,52]. 5.2 DealingwithMemoryPressure Languagefeatures andautomatic approaches \ncanhelp appli\u00adcations experiencing memorypressure. To help programmers avoid leaks and manage large heaps, \nthe Java language de.nition provides weak and soft references.The collectoralways reclaims weakly-referenced \nobjects, and it reclaims softly-referenced objects if the ap\u00adplication experiences memory pressure [19, \n20]. Inserting soft and weak references adds to the development burden, andprogrammersmay stillforgetto \neliminatethelast strong (notweak or soft) reference. Staticlivenessdetection ofGC roots can reduce the \ndrag between when objects die and when they are collected[27] butcannotdeal with otherdead,but reachable, \nobjects. Many VMs dynamically size the heap based on appli\u00adcation behavior. For example, some approaches \nadaptively trigger GC or resize the heap in order to improve GC per\u00adformance andprogramlocality[13,59,60,61].These \nap\u00adproachesdo notdirectlyaddress memoryleaks. When the application s heap size exceeds its working set \nsize, bookmarking collection reduces collection over\u00adhead[26].It cooperateswith the operating systemto \nbook\u00admark swapped-out pages by marking in-memory objects they reference aslive.Thegarbage collector then \nnever vis\u00aditsbookmarkedpages.Bookmarking can compacttheheap butcannotmove objects referencedbybookmarkedpages.It \ntracks staleness onpagegranularity.Meltinsteaduses object granularity,groupingandisolatingleaking objects. \nGeneral error tolerance approaches, such as failure\u00adoblivious computing [50], DieHard [5], and Rx [48] \ndeal with memory corruption and nondeterministic errors to im\u00adprove reliability,but theydo nothandle \nmemoryleaks. 5.3 ToleratingLeaks Severalrecentpublicationsaddresstheproblemoftolerating leaks[11,21,41,42,57].ComparedtoMelt, \ntheyofferless coverage,do not scale, or are unsafe. Leaksin nativelanguages. Cyclic memory allocation \ntol\u00aderates leaks in C and C++ by limiting allocation sites to m live objects at a time[41].Pro.ling runsdetermine \nm for each allocation site, and subsequent executions allocateinto m-sized circular buffers. Cyclic memory \nallocation is un\u00adsafe since it may overwrite live memory, although failure\u00adobliviouscomputing[50]mitigatesthe \neffectsin somecases. Incontrast,ourapproachplaces norequirementsonalloca\u00adtion sites andis always safe. \nPlugsafelytoleratesleaksinC andC++ with an allocator that segregates objectsby age and allocation site,increasing \nthe likelihood that leaked and in-use objects will reside on distinctpages[42].Plugdeals withlaterfragmentation \nvia virtual compaction, which maps two or more virtual pages to the samephysicalpageif the allocated \nslots on thepages do notoverlap.Plug s approachhelps nativelanguages since objects cannot move, but collectors \nin managed languages can reorganize objects. In addition, segregating leaked and in-use objects is insuf.cient \nfor managed languages since tracing collectorsbydefault access the wholeheap. Leaks in managed languages. \nPanacea supports moving stale objects todisk[11,21].The approach requires annota\u00adtionsfor objectsthat \ncanbe movedtodisk, andthese objects must be serializable to get put on disk. Panacea does not scale for \nsmall, stale objects which we .nd are frequent leakculprits becauseitusesproxyobjectsfor swapped-out \nobjects.An advantage ofPanaceaisthatitisimplementedat thelibrarylevel and needs noVM modi.cations. LeakSurvivor \n[57] is the closest related work and was developed concurrently with Melt [10]. Both approaches free \nup virtual andphysical memory by transferringhighly stale objects to disk, and both preserve safety by \nreturning accessed disk objects to memory. Unlike Melt, LeakSur\u00advivor cannotguarantee space andtimeproportionaltoin-use \nmemorybecause referencesfrom staletoin-use objects con\u00adtinueto use space evenif thein-use objectsbecome \nstale.In particular, entriesinLeakSurvivor sSwap-Out Table (SOT) (similartoMelt s sciontable)cannotbe \neliminatedifthetar\u00adgetobject moves todisk, sinceincomingpointersfromdisk are unknown.Incontrast,Meltusestwolevelsofindirection, \nstub-scionpairs,to eliminate scions referencingobjectslater moved tothe stale space(Section2.2).Forthethreeleaks \nevaluatedinLeakSurvivor,theSOTgrows only slightly,but it is unclear if they grow proportionally to the \nleak since the experiments are terminated after two hours, before the leaks would have .lled the disk. \nMelt adds less overhead than LeakSurvivor to identify stale objects (6% vs. 21%) sinceLeakSurvivoraccesses \nanobject sheaderoneachread, while Melt uses referenced-based conditional read barriers to avoid accessing \nobjectheadersin the common case. 5.4 OrthogonalPersistenceandDistributedGC Leak tolerance uses mechanisms \nthat have been used in orthogonal persistence, distributed garbage collection, and other areas. Orthogonal \npersistence uses object faulting, pointer swizzling, and read barriers to support transparent storage \nof objects ondisk[3,28,29,36,62].Pointer swiz\u00adzling can alsobe used to supporthuge address spaces[39, \n58]. Our implementation uses swizzling to support a 64-bit disk space on a 32-bit platform. Read barriers \nare widely usedin concurrentgarbagecollectors[4,8,17,30,45,63]. Distributedcollectors use stub-scionpairsfor \nreferencesbe\u00adtween machines [46]. We use stub-scion pairs to support referencesfrom stale toin-use objects.Althoughleak \ntoler\u00adanceborrows existing mechanisms,previous workdoes not combine these mechanisms in the same way \nas leak toler\u00adance,i.e., toidentify,isolate, and activate stale memory. 6. Conclusion Garbagecollectionand \ntype safety saveprogrammersfrom many memory bugs, but dead, reachable objects hurt per\u00adformance and crash \nprograms. Given enough disk space, our leak tolerance approach keeps programs from slowing down and running \nout of memory. Melt requires only time and spaceproportionaltoin-use memory, ratherthanleaked memory,andpreservessafetyby \nactivating stale objects on diskthattheprogramlater references.OurMeltimplementa\u00adtion addslow enough \noverheadfordeployed use.Forgrow\u00adingleaksin realprograms,Meltsubstantiallydelays crashes dueto out-of-memoryerrors.Withplentyofdiskspace,Melt \nhas thepotential toimprove the user experience.Itbuysde\u00advelopers more time to .x leaks and keeps users \nhappy by providingtheillusionthereis noleak.These attributes make Melt a compellingfeatureforfutureproductionVMs. \nAcknowledgments We thankJason Davis for the MySQL leak,Patrick Carrib\u00adaultfortheDelaunayleak,MariaJumpfortheSPECjbb2000 \nleak, and Yan Tang for the modi.ed SPECjbb2000 leak. Thanks to Eddie Aftandilian, Emery Berger, Steve \nBlack\u00adburn, Curtis Dunham, Daniel Frampton, Robin Garner, David Grove, Samuel Guyer, Xianglong Huang, \nMaria Jump, Milind Kulkarni, Erez Petrank, Chris Pickett, Dim\u00aditriosPrountzos, andJenniferSartorforhelpfuldiscussions. \nWethankEmeryBerger,RudyDepena,TomHorn,Nicholas Nethercote, andthe anonymous reviewersfor valuablefeed\u00adbackonthepaper \ntext. References [1] B. Alpern, C. R. Attanasio, J. J. Barton, M. G. Burke, P. Cheng, J.-D. Choi, A. \nCocchi, S. J. Fink, D. Grove, M. Hind, S. F.Hummel, D.Lieber, V. Litvinov, M. Mergen, T. Ngo, J. R. Russell, \nV. Sarkar, M. J. Serrano, J. Shepherd, S.Smith,V.C.Sreedhar,H.Srinivasan,andJ.Whaley. The Jalape no VirtualMachine. \nIBMSystemsJournal, 39(1):211 238,2000. [2] M.Arnold,S.J.Fink,D.Grove,M.Hind, andP.F.Sweeney. Adaptive \nOptimization in the Jalape no JVM. In ACM Conference on Object-Oriented Programming, Systems, Languages, \nand Applications,pages47 65,2000. [3] M.P.Atkinson,L.Dayn`es,M.J.Jordan,T.Printezis, and S.Spence. AnOrthogonally \nPersistentJava. SIGMOD Rec., 25(4):68 75, 1996. [4] D. Bacon, P. Cheng, and V. Rajan. A Real-Time Garbage \nCollectorwithLowOverhead andConsistentUtilization. In ACM Symposium on Principles of Programming Languages, \npages285 298, 2003. [5] E.D.Berger andB.G.Zorn. DieHard:ProbabilisticMemory Safety for Unsafe Languages. \nIn ACM Conference on Programming Language Design and Implementation, pages 158 168, 2006. [6] S. M. Blackburn, \nP. Cheng, and K. S. McKinley. Oil and Water? High Performance Garbage Collection in Java with MMTk. In \nACM International Conference on Software Engineering,pages137 146, 2004. [7] S.M.Blackburn, R.Garner, \nC.Hoffman, A.M.Khan, K.S. McKinley,R.Bentzur,A.Diwan,D.Feinberg,D.Frampton, S.Z.Guyer,M.Hirzel,A.Hosking,M.Jump,H.Lee,J.E.B. \nMoss,A.Phansalkar,D.Stefanovi\u00b4c,T.VanDrunen,D. von Dincklage, and B. Wiedermann. The DaCapo Benchmarks: \nJava Benchmarking Development and Analysis. In ACM Conference on Object-Oriented Programming, Systems, \nLanguages, and Applications,pages169 190, 2006. [8] S.M.Blackburn andA.L.Hosking. Barriers:Friend orFoe? \nIn ACM International Symposium on Memory Management, pages143 151, 2004. [9] M.D.Bond and K.S.McKinley. \nBell:Bit-EncodingOnline Memory Leak Detection. In ACM International Conference on Architectural Support \nfor Programming Languages and Operating Systems,pages61 72,2006. [10] M.D.Bond andK.S.McKinley. ToleratingMemory \nLeaks. Technical Report TR-07-64, University of Texas at Austin, December2007. [11] D. Breitgand, M. \nGoldstein, E. Henis, O. Shehory, and Y.Weinsberg. PANACEA Towards aSelf-HealingDevelop\u00admentFramework. \nIn IntegratedNetworkManagement,pages 169 178, 2007. [12] G. Chen, M. Kandemir, N. Vijaykrishnan, M. \nJ. Irwin, B. Mathiske, and M. Wolczko. Heap Compression for Memory-Constrained Java Environments. In \nACM Confer\u00adence onObject-OrientedProgramming, Systems,Languages, and Applications,pages282 301, 2003. \n [13] W.Chen, S.Bhansali, T. Chilimbi,X. Gao, and W. Chuang. Pro.le-guidedProactiveGarbageCollectionforLocalityOp\u00adtimization. \nIn ACM Conference on Programming Language Design andImplementation,pages332 340, 2006. [14] S.Cherem,L.Princehouse, \nandR.Rugina. PracticalMemory Leak Detection using Guarded Value-Flow Analysis. In ACM Conference on Programming \nLanguage Design and Implementation,pages480 491, 2007. [15] T. M. Chilimbi and M. Hauswirth. Low-Overhead \nMemory Leak Detection Using Adaptive Statistical Pro.ling. In ACM International Conference on Architectural \nSupport for Programming Languages and Operating Systems, pages 156 164, 2004. [16] DaCapo Benchmark Regression \nTests. http://jikesrvm.anu.\u00adedu.au/ dacapo/. [17] E. W. Dijkstra, L. Lamport, A. J. Martin, C. S. Scholten, \nand E. F. M. Steffens. On-the-Fly Garbage Collection: An Exercise in Cooperation. Commun. ACM, 21(11):966 \n975, Nov.1978. [18] Eclipse.orgHome. http://www.eclipse.org/. [19] B. Goetz. Plugging memory leaks with \nweak references, 2005. http://www-128.ibm.com/developerworks/java/\u00adlibrary/j-jtp11225/. [20] B. Goetz. \nPlugging memory leaks with soft references, 2006. http://www-128.ibm.com/developerworks/java/\u00adlibrary/j-jtp01246.html. \n[21] M. Goldstein, O. Shehory, and Y. Weinsberg. Can Self-Healing Software Cope With Loitering? In International \nWorkshop onSoftwareQualityAssurance,pages1 8,2007. [22] L. J. Guibas, D. E. Knuth, and M. Sharir. Randomized \nIn\u00adcremental Construction of Delaunay and Voronoi Diagrams. In Colloquium on Automata, Languages and \nProgramming, pages414 431, 1990. [23] S. C. Gupta and R. Palanki. Java memory leaks Catch meifyou can,2005. \nhttp://www.ibm.com/developerworks/\u00adrational/library/05/0816 GuptaPalanki/index.html. [24] R.Hastings \nandB.Joyce. Purify:FastDetection ofMemory Leaks and Access Errors. In Winter USENIX Conference, pages125 \n136, 1992. [25] D.L.HeineandM.S.Lam. APracticalFlow-Sensitiveand Context-Sensitive C and C++ Memory Leak \nDetector. In ACM Conference on Programming Language Design and Implementation,pages168 181,2003. [26] \nM. Hertz, Y. Feng, and E. D. Berger. Garbage Collection without Paging. In ACM Conference on Programming \nLanguageDesign andImplementation,pages143 153,2005. [27] M. Hirzel, A. Diwan, and J. Henkel. On the Usefulness \nof Type and Liveness Accuracy for Garbage Collection and Leak Detection. ACM Transactions on Programming \nLanguages andSystems,24(6):593 624, 2002. [28] A.L.Hosking andJ.Chen. PM3:AnOrthogonalPersistent SystemsProgrammingLanguage \nDesign,Implementation, Performance. In International Conference on Very Large DataBases,pages587 598, \n1999. [29] A. L. Hosking and J. E. B. Moss. Object Fault Handling for Persistent Programming Languages: \nA Performance Evaluation. In ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications,pages \n288 303, 1993. [30] A. L. Hosking, N. Nystrom,Q. I. Cutts, and K. Brahnmath. Optimizing the Read and \nWrite Barriers for Orthogonal Persistence. In International Workshop on Persistent Object Systems,pages149 \n159, 1999. [31] X. Huang, S. M. Blackburn, K. S. McKinley, J. E. B. Moss, Z.Wang, andP.Cheng. TheGarbage \nCollectionAdvantage: Improving Program Locality. In ACM Conference on Object-Oriented Programming, Systems, \nLanguages, and Applications,pages69 80,2004. [32] JikesRVM. http://www.jikesrvm.org. [33] Jikes RVM \nResearch Archive. http://www.jikesrvm.org/\u00adResearch+Archive. [34] M. Jump and K. S. McKinley. Cork: Dynamic \nMemory Leak Detection for Garbage-Collected Languages. In ACM Symposium on Principles ofProgramming Languages,pages \n31 38,2007. [35] J.Maebe,M.Ronsse, andK.D.Bosschere. PreciseDetection of Memory Leaks. In International \nWorkshop on Dynamic Analysis,pages25 31,2004. [36] A. Marquez, S. M. Blackburn, G. Mercer, and J. Zigman. \nImplementing Orthogonally PersistentJava. In International Workshop on Persistent Object Systems, pages \n247 261, 2000. [37] Mckoi SQL Database message board: memory/thread leak with Mckoi 0.93 in embedded \nmode, 2002. http://www.\u00admckoi.com/database/mail/subject.jsp?id=2172. [38] N. Mitchell and G. Sevitsky. \nLeakBot: An Automated and Lightweight Tool for Diagnosing Memory Leaks in Large Java Applications. In \nEuropean Conference on Object\u00adOrientedProgramming,pages351 377, 2003. [39] J.E.B.Moss. Working withPersistentObjects:ToSwizzle \nor Not to Swizzle. IEEE Transactions on Computers, 18(8):657 673, 1992. [40] N. Nethercote and J. Seward. \nValgrind: A Framework for Heavyweight Dynamic Binary Instrumentation. In ACM Conference on Programming \nLanguage Design and Implementation,pages89 100, 2007. [41] H. H. Nguyen and M. Rinard. Detecting and \nEliminating Memory Leaks Using Cyclic Memory Allocation. In ACM International Symposium on Memory Management, \npages 15 29,2007. [42] G.Novark,E.D.Berger,andB.G.Zorn.Plug:Automatically ToleratingMemoryLeaksinC andC++Applications. \nTech\u00adnicalReportUM-CS-2008-009,University ofMassachusetts, 2008. [43] K. Ogata, T. Onodera, K. Kawachiya, \nH. Komatsu, and T. Nakatani. Replay Compilation: Improving Debuggability of a Just-in-Time Compiler. \nIn ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications,pages241 252, \n2006. [44] Oracle. JRockit Mission Control. http://www.oracle.com/\u00adtechnology/products/jrockit/missioncontrol/. \n[45] F.Pizlo,D.Frampton,E.Petrank, andB.Steensgaard. Sto\u00adpless: A Real-Time Garbage Collector for Multiprocessors. \nIn ACM International Symposium on Memory Management, pages159 172, 2007. [46] D.Plainfoss\u00b4e. DistributedGarbageCollection \nandReference Management in theSoul ObjectSupport System. PhD thesis, Universit\u00b4eParis-6,Pierre-et-Marie-Curie,1994. \n[47] F. Qin, S. Lu, and Y. Zhou. SafeMem: Exploiting ECC-Memory forDetecting Memory Leaks and Memory \nCorrup\u00adtionDuringProductionRuns. In InternationalSymposium on High-Performance Computer Architecture, \npages 291 302, 2005. [48] F.Qin,J.Tucek,J.Sundaresan, andY.Zhou. Rx:Treating Bugs as Allergies A Safe \nMethod to Survive Software Failures. In ACM Symposium on Operating Systems Principles,pages235 248, 2005. \n[49] Quest. JProbe Memory Debugger. http://www.quest.com/\u00adjprobe/debugger.asp. [50] M. Rinard, C. Cadar, \nD. Dumitran, D. Roy, T. Leu, and W. Beebee. Enhancing Server Availability and Security through Failure-Oblivious \nComputing. In USENIX Sym\u00adposium on Operating Systems Design and Implementation, pages303 316, 2004. [51] \nN.Sachindran, J.E.B.Moss, andE.D.Berger. MC2 :High-Performance Garbage Collection for Memory-Constrained \nEnvironments. In ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications,pages \n81 98, 2004. [52] SciTech Software. .NET Memory Pro.ler. http://www.\u00adscitech.se/mempro.ler/. [53] Standard \nPerformance Evaluation Corporation. SPECjvm98 Documentation, release1.03 edition,1999. [54] StandardPerformanceEvaluationCorporation.SPECjbb2000 \nDocumentation, release1.01 edition,2001. [55] SunDeveloperNetworkForum.JavaProgramming[Archive] -garbagecollectiondilema(sic),2003. \nhttp://forum.java.\u00adsun.com/thread.jspa?threadID=446934. [56] Sun Developer Network Forum. Re.ections \n&#38; Reference Objects -Java memory leak example, 2003. http://forum.\u00adjava.sun.com/thread.jspa?threadID=456545. \n [57] Y.Tang,Q.Gao,andF.Qin. LeakSurvivor:TowardsSafely ToleratingMemoryLeaksforGarbage-CollectedLanguages. \nIn USENIX Annual Technical Conference, pages 307 320, 2008. [58] P. R. Wilson. Pointer Swizzling at Page \nFault Time: Ef.ciently Supporting Huge Address Spaces on Standard Hardware. ACM SIGARCH Comput. Archit. \nNews,19(4):6 13,1991. [59] F.Xian,W.Srisa-an,andH.Jiang.MicroPhase:AnApproach to Proactively Invoking \nGarbage Collection for Improved Performance. In ACM Conference on Object-Oriented Programming, Systems, \nLanguages, and Applications,pages 77 96,2007. [60] T. Yang, E. D. Berger, S. F. Kaplan, and J. E. B. \nMoss. CRAMM: Virtual Memory Support for Garbage-Collected Applications. In USENIX Symposium on Operating \nSystems Design andImplementation,pages103 116, 2006. [61] T. Yang, M. Hertz, E. D. Berger, S. F. Kaplan, \nand J. E. B. Moss. Automatic Heap Sizing: Taking Real Memory into Account. In ACM International Symposium \non Memory Management,pages61 72,2004. [62] J. N. Zigman, S. Blackburn, and J. E. B. Moss. TMOS: A Transactional \nGarbage Collector. In International Workshop on PersistentObjectSystems,pages138 156, 2001. [63] B.Zorn. \nBarrierMethods forGarbage Collection. Technical Report CU-CS-494-90, University of Colorado at Boulder, \n1990. \n\t\t\t", "proc_id": "1449764", "abstract": "<p>Type safety and garbage collection in managed languages eliminate memory errors such as dangling pointers, double frees, and leaks of unreachable objects. Unfortunately, a program still leaks memory if it maintains references to objects it will never use again. Leaked objects decrease program locality and increase garbage collection frequency and workload. A growing leak will eventually exhaust memory and crash the program.</p> <p>This paper introduces a <i>leak tolerance</i> approach called <i>Melt</i> that safely eliminates performance degradations and crashes due to leaks of dead but reachable objects in managed languages, given sufficient disk space to hold leaking objects. Melt (1) identifies <i>stale</i> objects that the program is not accessing; (2) segregates in-use and stale objects by storing stale objects to disk; and (3) preserves safety by activating stale objects if the program subsequently accesses them. We design and build a prototype implementation of Melt in a Java VM and show it adds overhead low enough for production systems. Whereas existing VMs grind to a halt and then crash on programs with leaks, Melt keeps many of these programs running much longer without significantly degrading performance. Melt provides users the illusion of a fixed leak and gives developers more time to fix leaky programs.</p>", "authors": [{"name": "Michael D. Bond", "author_profile_id": "81100148693", "affiliation": "University of Texas at Austin, Austin, TX, USA", "person_id": "P1223159", "email_address": "", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "University of Texas at Austin, Austin, TX, USA", "person_id": "P1223160", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449774", "year": "2008", "article_id": "1449774", "conference": "OOPSLA", "title": "Tolerating memory leaks", "url": "http://dl.acm.org/citation.cfm?id=1449774"}