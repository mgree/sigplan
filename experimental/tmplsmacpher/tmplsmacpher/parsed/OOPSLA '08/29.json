{"article_publication_date": "10-19-2008", "fulltext": "\n Java Type Inference Is Broken: Can We Fix It? Daniel Smith Department of Computer Science Rice University \nHouston, Texas, USA dlsmith@rice.edu Abstract Java 5, the most recent major update to the Java Program\u00adming \nLanguage, introduced a number of sophisticated fea\u00adtures, including a major extension to the type system. \nWhile the technical details of these new features are complex, much of this complexity is hidden from \nthe typical Java devel\u00adoper by an ambitious type inference mechanism. Unfortu\u00adnately, the extensions \nto the Java 5 type system were so novel that their technical details had not yet been thoroughly in\u00advestigated \nin the research literature. As a result, the Java 5 compiler includes a pragmatic but .awed type inference \nal\u00adgorithm that is, by design, neither sound nor locally com\u00adplete. The language speci.cation points \nout that neither of these failures is catastrophic: the correctness of potentially\u00adunsound results must \nbe veri.ed during type checking; and incompleteness can usually be worked around by manually providing \nthe method type parameter bindings for a given call site. This paper dissects the type inference algorithm \nof Java 5 and proposes a sign.cant revision that is sound and able to calculate correct results where \nthe Java 5 algorithm fails. The new algorithm is locally complete with the exception of a dif.cult corner \ncase. Moreover, the new algorithm demon\u00adstrates that several arbitrary restrictions in the Java type \nsystem most notably the ban on lower-bounded type pa\u00adrameter declarations and the limited expressibility \nof inter\u00adsection types are unnecessary. We hope that this work will spur the evolution of a more coherent, \nmore comprehensive generic type system for Java. Categories and Subject Descriptors D.3.1 [Programming \nLanguages]: Formal De.nitions and Theory Semantics; D.3.2 [Programming Languages]: Language Classi.cations \nJava, Object-oriented languages; D.3.3 [Programming Lan- Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to \nlists, requires prior speci.c permission and/or a fee. OOPSLA 08, October 19 23, 2008, Nashville, Tennessee, \nUSA. Copyright c . 2008 ACM 978-1-60558-215-3/08/10. . . $5.00 Robert Cartwright Department of Computer \nScience Rice University Houston, Texas, USA cork@rice.edu guages]: Language Constructs and Features \nClasses and objects, Polymorphism General Terms Design, Languages 1. Introduction Java 51, the most recent \nmajor update to the Java Program\u00adming Language, introduced a number of sophisticated fea\u00adtures, including \na major extension to the type system. While the technical details of these new features are complex, \nmuch of this complexity is hidden from the typical Java developer by an ambitious type inference mechanism. \nPrior to the release of Java 5, there was no type infer\u00adence in Java. According to the Java language \nculture, the type of every variable, method, and dynamically allocated object must be explicitly declared \nby the programmer. When generics (classes and methods parameterized by type) were introduced in Java \n5, the language retained this requirement for variables, methods, and allocations. But the introduction \nof polymorphic methods (parameterized by type) dictated that either (i) the programmer provide the method \ntype ar\u00adguments at every polymorphic method call site or (ii) the language support the inference of method \ntype arguments. To avoid creating an additional clerical burden for program\u00admers, the designers of Java \n5 elected to perform type in\u00adference to determine the type arguments for polymorphic method calls. Since \ngenerics constituted a major technical addition to the language, the Java language designers, with input \nfrom the Java Community Process [15], spent several years care\u00adfully evaluating potential generic extensions \nand their tech\u00adnical implications. Nevertheless, the .nal design included a novel mechanism for declaring \nspecial union types called wildcards supporting covariant and contravariant subtyping. The use of wildcards \nalso necessitated adding some sup\u00adport for intersection types in the language. The inclusion of wildcards \nhelped support the accurate parameteric typing of 1 Throughout this paper, we use Java 5 to refer to \nthe language update coinciding with the release of Java SE 5.0 and speci.ed by the 3rd edition of the \nJava Language Speci.cation (JLS) [3]. The current Java platform version, Java SE 6.0, is consistent with \nthis speci.cation and makes no relevant language changes. many existing Java library methods, including \nthe re.ection library, which is an impressive achievement. On the other hand, this feature was so novel \nthat its technical foundations, particularly with regard to type inference, had not yet been thoroughly \ninvestigated in the research literature. Java wildcards are loosely based on virtual types, initially \npresented in the context of generic classes by Thorup and Torgersen [11] and subsequently re.ned by Igarashi \nand Vi\u00adroli [5]. But none of this supporting research focused on a core subset of the actual Java 5 design. \nMoreover, none of this prior work covered all of the technical problems that arise during type argument \ninference. As a result, the Java 5 compiler includes a pragmatic but .awed type infer\u00adence algorithm. \nWhile it essentially follows Odersky s al\u00adgorithm for GJ [1] (an academic forerunner of Java 5 that did \nnot include wildcards), the additional complexity intro\u00adduced by wildcards and intersections led to an \nalgorithm that is, by design, neither sound nor locally complete.2 The Java Language Speci.cation (JLS) \n[3] points out that neither of these failures is catastrophic: the correctness of potentially\u00adunsound \nresults must be veri.ed during type checking; and incompleteness can usually be worked around by manually \nproviding the method type parameter bindings for a given call site.3 This paper dissects the type inference \nalgorithm of Java 5 and proposes a sign.cant revision that is sound and able to calculate correct results \nwhere the Java 5 algorithm fails. The new algorithm is locally complete with the exception of a dif.cult \ncorner case. Moreover, the new algorithm demon\u00adstrates that several arbitrary restrictions in the Java \ntype system most notably the ban on lower-bounded type pa\u00adrameter declarations and the limited expressibility \nof inter\u00adsection types are unnecessary. We hope that this work will spur the evolution of a more coherent, \nmore comprehensive generic type system for Java. To motivate the need for changes in the algorithm, we \n.rst enumerate a number of bugs buried in the speci.cation. Next, we discuss ways in which, even after \nthese bugs have been addressed, the algorithm falls short either because it fails to correctly type a \ntypeable program (requiring the programmer to insert explicit annotations), or because it unduly limits \nexpressiveness of the language. Among these shortcomings is an incorrect join function and the language \nrestrictions noted above. Next, we formally specify an improved inference algo\u00adrithm that addresses many \nof the shortcomings in the Java 5 algorithm. This speci.cation includes de.nitions of the lan\u00adguage s \ncore type operations, such as subtyping and wildcard capture. 2 Soundness requires that inferred type \narguments not violate the typing rules; completeness requires that the algorithm produces a result where \nsome valid choice of type arguments exists. 3 Note, however, that some types, such as wildcard capture \nvariables, are inexpressible and thus can t be used as explicit type arguments. Finally, we discuss the \nimplications for backwards com\u00adpatibility arising out of changes to the inference algorithm. 2. Java \n5 Inference 2.1 Overview The Java 5 type argument inference algorithm produces type arguments for use \nat a speci.c call site of a polymorphic method. For example, consider the following method decla\u00adration: \nclass Util { static <T> Iterable<T> compose(Iterable<? extends T> list, T elt) { ... } } where compose \nadds a new element to an Iterable collec\u00adtion. As a running example, we ll refer to the following type \nhierarchy: interface Animal { ... } interface Herbivore extends Animal { ... } interface Carnivore extends \nAnimal { ... } Given an Iterable<Herbivore> named hs, an Herbivore h, and a Carnivore c, a client may \ninvoke compose with an explicit type argument: Iterable<Herbivore> hs2 = Util.<Herbivore>compose(hs, \nh); Iterable<Animal> hs3 = Util.<Animal>compose(hs, c); or, more typically, elide the type argument and \nrely on type inference to choose a value based on the types of the argu\u00adments: Iterable<Herbivore> hs2 \n= Util.compose(hs, h); Iterable<Animal> hs3 = Util.compose(hs, c); The Java 5 inference algorithm frames \nthe problem as a heuristic attempt to satisfy a set of subtyping constraints [3, 15.12.2.7-8].4 Let P1 \n...Pn be the method s type parame\u00adters. The notation .P1. represents the declared upper bound of P1 (this \nnotation extends to arbitrary type variables; later, we ll use .X. to refer to variable X s lower bound). \nGiven A1 ...Am as the types of the method invocation s arguments and F1 ...Fm as the corresponding method \nparameters de\u00adclared types, we must .nd a substitution s binding P1 ...Pn that satis.es the following \nconstraints (for all valid choices of i there are m + n such constraints to satisfy): Ai<: sFi sPi<: \ns.Pi. In certain circumstances, the algorithm also takes into ac\u00adcount the type expected by the method \ninvocation s context. 4 In the following discussion, we depart from the notation used by the JLS in order \nto maintain a consistent presentation throughout this paper. However, the ideas expressed by the notation \nare consistent with the speci.caiton. That is, where R is the method s declared return type and E is \nthe expected type, sR <: E is added to the set of subtyping constraints. The type E is only de.ned, and \nthus this additional constraint is only used in inference, where the method invocation appears as the \nvalue of a return statement, the initializer of a variable declaration, or the right-hand side of an \nassignment. That is, only in contexts in which the programmer has provided an explicit value for E. (And \neven where E is de.ned, the Java 5 algorithm often ignores it.) Note that these constraints describe \nexactly the conditions under which an invocation of a non-overloaded method with well-typed arguments \nis well-typed (and, if the constraint in\u00advolving E is used, the conditions under which the enclosing \nexpression is well-typed): if the constraints are satis.able, there exists a choice of type arguments \nthat makes the ex\u00adpression well-typed; if the constraints are unsatis.able, the expression is ill-typed \nfor all choices of type arguments. The Java 5 algorithm generates this set of constraints for each polymorphic \nmethod call site, and then the algorithm attempts to choose a value for s satisfying the constraints. \nIn the last compose invocation above Util.compose(hs, c) the relevant constraints are: Iterable<Herbivore> \n<: sIterable<? extends T> Carnivore <: sT sT <: Object The .rst two constraints are derived from the \ninvocation argument types, and the third from the (trivial) bound of T. The inferred substitution is \n[T := Animal]. Because the algorithm makes no guarantees about its results it is, by design, neither \nsound nor complete type checking handles the inferred arguments as if they were ex\u00adplicitly provided \nby the user: .rst checking their correctness, and then using them to determine the type of the method \nin\u00advocation expression. 2.2 Constraint Solving Internally, the Java 5 algorithm is a two-step process. \nFirst, argument value pairs (Ai and Fi for all i = m) are reduced to a conjunction of bounding constraints \non the instantia\u00adtions of P1 ...Pn. Each constraint is an assertion that sPi, for some i, is a subtype \nor supertype of a given bound. Sec\u00adond, a type satisfying these bounds is chosen for each type argument. \nThe reduction in the .rst phase is achieved with three mu\u00adtually recursive functions <:?, :>?, and = \n?. Each function . takes two arguments, A (derived from an argument type) and F (derived from a formal \nparameter type), and attempts to produce constraints describing the circumstances under which A . sF \nis true. In the base case, where F = Pi, the result is a bound on the corresponding argument, sPi. For \nexample, in the last compose invocation, the following two constraints must be reduced (sT <: Object, \nderived from the declared bound on T, is ignored until the second phase): Iterable<Herbivore> <: sIterable<? \nextends T> Carnivore <: sT Bounds for the second constraint are trivially produced: Carnivore <:? T = \n{sT :> Carnivore} Handling the .rst constraint is slightly more complex: Iterable<Herbivore> <:? Iterable<? \nextends T> = Herbivore <:? T = {sT :> Herbivore} Thus, the full set of bounds for the compose invocation \nis {sT :> Herbivore,sT :> Carnivore} In the second phase, the lower bounds of sPi are com\u00adbined with \na join operation to produce a single type.5 The join function is also implemented heuristically: ideally, \nthe invocation join(S, T ) produces a most speci.c type J such that S <: J and T <: J. By most speci.c \nwe mean that any other common supertype J. of S and T is also a supertype of J: .J.,J <: J.. The Java \n5 join function produces a com\u00ad mon supertype, but in some cases it is not the most speci.c. In the running \nexample, we have sT :> join(Herbivore, Carnivore)= Animal In most cases, the result of joining the lower \nbounds of sPi is then chosen as the binding of Pi. If, however, this is the type null (as is the case \nwhere there are no lower bounds), the declared bounds of P1 ...Pn are incorporated; if the expected type \nof the call E is de.ned, the bounds produced by E :>? R are also used. In this case, the upper bounds \nof sPi are merged (by constructing an intersection) to produce the binding. 2.3 Bugs in the Java 5 Algorithm \nThe Java 5 algorithm produces useful results in most situa\u00adtions. However, there are a number of cases \nin which it fails, either because there exist choices for s that it does not .nd, or because its choice \nof s does not satisfy the relevant sub\u00adtyping constraints. In both cases, this can lead to type errors \nor, where either the method to be invoked or an enclosing method call is overloaded, unexpected runtime \nbehavior. It will not, fortunately, lead to violations of type safety, be\u00adcause type checking makes no \nassumptions about the cor\u00adrectness of the algorithm s results. Some of the unsound\u00adness and incompleteness \nproperties of the algorithm arise from conscious engineering decisions. But in many cases the heuristic \nnature of the algorithm provides a cover for unin\u00adtentional bugs. Some of these bugs are outlined below. \n5 The join function is called lub (for least upper bound ) in the JLS [3, 15.12.2.7]. The join function \nis de.ned incorrectly for some wildcard\u00adparameterized types: join(List<? extends A>, List<? super A>)= \nList<A> This is clearly incorrect the result is a supertype of neither join argument. The join function, \nbecause it discards some type infor\u00admation, is unnecessarily imprecise in some cases: the re\u00adsult cannot \nbe a type variable (even if that variable is the common supertype of two other variables), nor can it \nbe an array of a parameterized type (like List<String>[]).  The inference algorithm does not correctly \nhandle type variables. For example, where A is a variable and F is an array type, A :>? F recurs on A \ns upper bound rather than its lower bound.  Default bounds on wildcards (Object and null) are in\u00adcorrectly \nignored by the algorithm. For example:  List<? super String> <:? List<? extends T> This ought to produce \n{sT :> Object}, rather than the 6 speci.ed {}. The algorithm s use of a parameter s upper bound allows \nreferences to a parameter to leak into the calling context. For example, given the following method signature: \n<T extends List<T>> T foo() Inference may determine (depending on the enclosing context) that sT = List<T>. \nIn addition to these bugs, the algorithm does not correctly handle the type null: null :>? T produces \nno bounds when it ought to produce {T <: null}. While clearly a mistake (the algorithm explicitly de.nes \nan incorrect result for null), this is not a problem as the language is currently de.ned, be\u00adcause no \ninvocation involving null as a supertype ever oc\u00adcurs: null is inexpressible, is never chosen by the \ninference algorithm, and is ignored when it appears as a default bound. However, subtle changes to the \nlanguage, including a .x for the wildcard-bound bug listed above, may violate this invari\u00adant.7  2.4 \nAdditional Limitations In addition to the mistakes described above, the Java 5 al\u00adgorithm is limited \nby design in a number of ways. In some 6 This bug is of particular signi.cance to the javac compiler, \nbecause it fails to verify the correctness of the inference results in this case, leading to a violation \nof type safety: code that compiles without error (or warning) will fail at runtime with an erasure-prompted \nClassCastException. See Appendix A.1 for an example. 7 Note that the inference algorithm in Section 3 \ndoes produce null. Also, an expressible null type would be quite useful; there is an independent sub\u00admission \nin Sun s Java bug database requesting it, with some accompanying discussion [17]. cases, these limitations \nlead to unsoundness or incomplete\u00adness; in others, they force restrictions on the rest of the lan\u00adguage. \nUnlike the above bugs, which are clearly faults in the speci.cation, language changes involving these \nitems are open to debate. However, we argue that the community would be well served by amending the speci.cation \nto ad\u00address these limitations. 2.4.1 Correct Join As mentioned previously, the Java 5 join function does \nnot always produce a most speci.c bound.8 As a simple example, consider the following invocation: join(List<Object>, \nList<String>) The correct result in this case is List<? super String>; the Java 5 function, however, \nnever produces wildcards with lower bounds, and will instead produce List<?>. The correct de.nition in \nother cases is more subtle. Con\u00adsider a similar invocation in which the two list element types are not \ndirectly related, but share a common supertype: join(List<Herbivore>, List<Carnivore>) The following \nis a tempting choice for the result (and is the result chosen by the Java 5 algorithm): J1 = List<? extends \nAnimal> However, it is equally reasonable to choose a lower bound for the wildcard: J2 = List<? super \nHerbivore &#38; Carnivore> Both J1 and J2 are supertypes of both List<Herbivore> and List<Carnivore>; \nyet neither is a subtype of the other. In practice, which type is more convenient depends on how the \ntype is used (J1 accommodates get operations, while J2 ac\u00adcommodates add operations). A joint University \nof Aarhus Sun Microsystems paper introducing wildcards makes note of this ambiguity [12, 3.1], but does \nnot mention how it can be resolved by either (i) producing a wildcard with both bounds: List<? extends \nAnimal super Herbivore &#38; Carnivore> or (ii) using a union type to represent the join: List<Herbivore> \n| List<Carnivore> Both of these types are subtypes of J1 and J2, and both are optimal (the .rst is optimal \nin the absence of union types). But neither is valid in Java 5, so to accommodate either approach, the \nlanguage would need to be extended. A second problem with join is that it is recursive but not normalizing: \nthe computation of join(S, T ) may depend on itself. For example, we may choose to de.ne classes C and \nD as follows: 8 Thus the result is thus not really a join or least upper bound at all, as the terms are \nused in lattice theory. class C implements Comparable<C> { ... } class D implements Comparable<D> { ... \n} Invoked with such types, the Java 5 join function has a circular dependency: join(C, D) = join(Comparable<C>, \nComparable<D>)= Comparable<? extends join(C, D)> = ... This circular dependency is handled in the JLS \nby intro\u00adducing recursive types. Informally, the result of the above join invocation is: Comparable<? \nextends Comparable<? extends ...>> Formally, this is the type \u00b5X.Comparable<? extends X> Unfortunately, \noutside the context of the join function s de.nition, the speci.cation makes no mention of such types. \nThey are not included in the de.nition of types, and their subtyping relationships with other types are \nleft unspeci.ed. Again, there are two alternatives. The .rst is to fully spec\u00adify the behavior of all \ntype operations (including subtyping, join, and inference) where recursive types are present. The second \nis to abandon recursive types and instead compute join using union types. This also requires adjusting \nthe do\u00admain of all type operations, but has the advantage that algo\u00adrithms involving unions are far simpler \nthan those involving recursive types. 2.4.2 Analysis Using Wildcard Capture In order to analyze subtyping \nrelationships involving a wildcard-parameterized type, the Java 5 subtyping algo\u00adrithm makes use of a \nwildcard capture operation (denoted .T .) that replaces the implicit there exists quanti.cation expressed \nby a wildcard with a fresh type variable. Where class C declares parameter P , .C<? extends B>. = C<Z> \nwhere .Z. = B &#38; [P := Z].P . For example, the class Enum has the following signature: class Enum<E \nextends Enum<E>> implements Comparable<E> The assertion Enum<? extends Runnable> <: Comparable<? extends \nEnum<?>> is true if and only if .Enum<? extends Runnable>. = Enum<Z> <: Comparable<? extends Enum<?>> \nwhere the fresh variable Z has both the wildcard s and the corresponding parameter s upper bounds: .Z. \n= Runnable &#38; Enum<Z> (In this particular example, the subtyping assertion is true, because Z <: Enum<?>.) \nThe Java 5 inference algorithm is inconsistent with the Java 5 subtyping algorithm in handling wildcards: \nrather than reasoning about wildcards by using capture, it simply recurs on the wildcard bound, ignoring \nthe bound of the corresponding type parameter. The invocation Enum<? extends Runnable> <:? Comparable<? \nextends T> produces {sT :> Runnable}. This constraint is too restric\u00adtive: the type Enum<?>, as we saw, \nis a valid choice for sT, but is not allowed by this inferred bound. The apparent solution to this omission \nis to invoke cap\u00adture in inference whenever it occurs in subtyping. However, this strategy forces us \nto generalize the inference algorithm to handle the broader domain of types generated by this rule. There \nis an implicit assumption in the Java 5 algo\u00adrithm that the constraints for all subtyping relationships \nwith which it is presented can be expressed as a conjunc\u00adtion of simple bounds. Note, however, that the \napplication A :>? F1 &#38; F2 does not conform to this scheme: it can be satis.ed by A :>? F1 or A :>? \nF2. In order to avoid the pos\u00adsibility that relevant information will be discarded, the Java 5 algorithm \nmust guarantee that such applications will never occur. In the absence of wildcard capture in type inference, \nwe can make the following assertions about the arguments to <:?, :>?, and = ?: The argument F , if it \nis a variable but not one of P1 ...Pn, cannot have bounds involving any of P1 ...Pn. This property holds \nbecause F is always derived from a type appearing in the method signature, and, due to scop\u00ading constraints, \nno variable appearing there can reference P1 ...Pn at its declaration point.  In <:?, where A is an \nintersection type and F is a class type, there is at most one class supertype of the intersec\u00adtion that \nhas the same class name as the upper type; where A is an intersection and F is an array type, if the \ninter\u00adsection has an array supertype, it also has a most speci.c array supertype.9  The argument F cannot \nbe an intersection type. Intersec\u00adtions can only be reached by the recursive application of the inference \nfunctions. However, variables, which might have intersections in their upper bounds, cannot involve any \nof P1 ...Pn, and so the recursion would never occur;  9 As a technicality, the JLS does not describe \nhow A <:? F should be handled where A is an intersection and F is an array, but the correct behavior \nfollows directly from this assumption. and for the reasons outlined in the previous point, there is no \nneed to represent the supertype of a class type as an intersection. Under these assumptions, all bounds \nproduced by infer\u00adence are cumulative. However, capture during inference vio\u00adlates the .rst assumption: \nit can produce new variables with bounds that refer to P1 ...Pn. In order to extend the inference algorithm \nto handle in\u00advocations where one of a number of different constraint sets must hold, the representation \nof constraint sets can be ex\u00adtended to constraint formulas: simple bounds on T1 ...Tn combined by boolean \nconjunction and disjunction. To reduce the complexity inherent in arbitrary boolean formulas, the domain \nof constraint formulas can be restricted to disjunc\u00adtive normal form a list of constraint sets (conjunctions), \nonly one of which need be satis.ed by the .nal choice of 10 T1 ...Tn. A simpler but less complete solution \nis to use capture in restricted scenarios that do not necessitate the use of disjunction. We can perform \ncapture on A, for example, without violating any of the above assumptions. 2.4.3 First-Class Intersection \nTypes As noted in the previous section, intersection types can intro\u00adduce additional complexity to the \ninference algorithm. For this reason, their use in Java 5 is extremely limited: a pro\u00adgrammer may only \nexpress an intersection in code when it appears as the upper bound of a type variable. (Program\u00admers \nmay be surprised to discover that the upper bound of a wildcard cannot be similarly expressed with an \nintersec\u00adtion.) If we are willing to extend the inference algorithm so that it handles disjunctive constraint \nformulas as described above it then becomes possible to support intersections as .rst-class citizens \nin the domain of types, admitting their us\u00adage anywhere an arbitrary type can appear.11 As a simple motivating \nexample, the Java API includes the interfaces Flushable and Closeable, implemented by streams that support \na flush and a close operation, respec\u00adtively. Taking advantage of these interfaces, it might be con\u00advenient \nto create a thread that occasionally .ushes a stream, and at some point closes it. Such a thread would \nneed to ref\u00aderence a variable of type Flushable &#38; Closeable. Another example appears in Appendix \nA.2. By using intersections in method signatures and implementation code, 10 Normalization to disjunctive \nnormal form, as with other methods for solv\u00ading arbitrary logical formulas, can potentially take an intractable \namount of time and space for large problem sizes. However, in this particular appli\u00adcation, problem sizes \nare always quite small: programmers almost never use more than four or .ve type parameters, for example, \nand we gener\u00adally expect the number of distinct, incompatible bounds inferred for those variables to \nbe relatively small. Also note that the complexity encoded by multiple disjuncts is discarded once inference \nat a particular call site deter\u00admines a solution multiple nested polymorphic method calls will not lead \nto exponential growth in the size of constraint formulas. 11 There is an independent submission in Sun \ns Java bug database requesting this feature, with some accompanying discussion [18]. it is possible to \nde.ne an ordered set that ensures that its elements are comparable to each other without requiring the \nelement type T to explicitly implement Comparable. In Java 5, it is often possible to approximate the \n.rst-class use of an intersection by introducing a type variable T with an intersection upper bound, \nand replacing all instances of the intersection with references to T. However, this approach is inconvenient \nfor the same reason that writing programs without wildcards is inconvenient it results in a prolifera\u00adtion \nof variable declarations that are irrelevant to the public interface of a class or method. Further, such \na conversion is not possible in general: a mutable .eld, for example, may hold values with different \ntypes, all compatible with the in\u00adtersection, over the course of its lifetime. There may be no non-intersection \nchoice for T that covers the domain of these values. Support for .rst-class intersections, combined with \nthe ability to make full use of wildcard capture during infer\u00adence, provides a compelling motivation \nfor extending the in\u00adference algorithm with disjunctive reasoning. 2.4.4 Recursively-Bounded Type Parameters \nJava 5 supports F-bounded polymorphism: a type parameter may appear recursively within its own bound; \nmutual recur\u00adsion among parameter bounds is also allowed. As noted in the list of speci.cation bugs (Section \n2.3), where the infer\u00adence algorithm attempts to incorporate the upper bounds of P1 ...Pn before choosing \ns, it does so incorrectly and al\u00adlows these recursive references to leak into the calling con\u00adtext. Notice \nthat the subtyping constraint involving parameter bounds make reference to s on both sides of the constraint: \nsPi<: s.Pi. Thus, the techniques used to solve other subtyping con\u00adstraints are dif.cult to apply here. \nIf we re interested in simply patching the speci.cation bug, the workaround is for inference to give \nup in cases that will produce out-of-scope results. A more useful solution is to simply ignore upper \nbounds and always choose the in\u00adferred lower bound (even if it is null). In practice, where there are \nmultiple correct choices for s, choosing the most speci.c instantiations the inferred lower bounds is \nusu\u00adally most useful to programmers. However, this solution is incomplete. Consider a simpli\u00ad.ed case \nin which there is only one parameter, P . Infer\u00adence may determine that sP :> T , for some T . Yet where \nT . <: [P := T ].P . it is possible that there exists some S such that T <: S <: [P := S].P .. The choice \nof s changes the bound that must be satis.ed the types [P := T ].P . and [P := S].P . need not be related. \nAs an example, consider a type MyString which ex\u00adtends the standard String class (which in turn extends \nComparable<String>).12 Now assume we pass two MyStrings to a method with the following signature: <T \nextends Comparable<T>> T min(T x, T y) The best choice for s is [T := String]. But the inferred lower \nbound is MyString, not String. Thus, inference fails to pro\u00adduce a correct result, and the user must \nprovide an explicit parameter.13 To improve on the lower bound strategy, what is needed is a way to describe \na type that falls within a number of bounds, some of which are in scope in the calling context, and some \nof which are parameterized by P1 ...Pn. Interest\u00adingly, wildcard capture has already been de.ned for \nexactly this purpose! It combines the bound of a wildcard with the potentially-recursive bound of a type \nparameter. Unfortunately, if we examine the results of wildcard cap\u00adture applied to lower-bounded wildcards, \nwe .nd that it, too, is incapable of managing some recursive bounds. For exam\u00adple, if class Foo has a \nparameter T extends Comparable<T>, we have the following: .Foo<? super MyString>. = Foo<Z> where .Z. \n= Comparable<Z> and .Z. = MyString In this case, the capture variable Z (and thus the wildcard itself) \nis malformed, because its bounds are inconsistent: 14 MyString .<: Comparable<Z>. It is not clear how \nbest to proceed. If wildcard cap\u00adture could be improved in some way so that this class of seemingly reasonable \ntype expressions were well-formed, it would be a useful fall-back for constraint solving in in\u00adference: \nwhere a set of inferred lower bounds do not sat\u00adisfy the declared bounds of a method s parameters, a \nset of properly-bounded capture variables could be chosen in\u00adstead. But describing such an improvement \nremains an open research question. Another alternative is to use trial and error, walking a depth-.rst \ntraversal of the type hierarchy from the lower bound to Object. But it is not clear that the satisfying \ntype S, if it exists, will always appear in this enumeration. Barring a universal solution to this problem, \nany Java type argument inference algorithm will be incomplete. 12 String cannot actually be extended, \nbecause it is declared final. But it is a familiar class that implements Comparable, so we use it here. \n13 Another workaround in this case is to use a wildcard in the bound: Comparable<? super T>. That works \nfor this simple method, but would not if a more complex class were being used. See Appendix A.3 for a \nsimilar, but more realistic and complex, example. 14 While the speci.cation is not clear about the conditions \nunder which a wildcard is malformed, it would violate transitivity of subtyping if capture were allowed \nto produce a variable with a lower bound that was not a subtype of its upper bound. Thus, such wildcards \nmust be malformed. 2.4.5 Lower-Bounded Type Parameters While wildcards may be bounded from either above \nor be\u00adlow, type parameters are not given this .exibility: only an upper bound is expressible. It s natural \nto wonder whether this inconsistency is necessary (especially given that vari\u00adables produced by wildcard \ncapture can have both upper and lower bounds).15 In fact, the limitation is closely tied to the type \nargument inference algorithm, and improvements to the algorithm would make this restriction unnecessary. \nAt .rst glance, it may seem that a lower bound on a type variable provides no useful information for \nthe programmer. For example, if T has a lower bound Integer and a method declares a parameter of type \nT, the method programmer must assume that, in the most general case, T represents the type Object, and \nthus has none of the methods speci.c to Integer. This intuition, however, is super.cial. When the type \nT is nested, both upper and lower bounds of the variable may be useful. The following method de.nition, \nnot legal in Java 5, demonstrates one reasonable use of a variable with a lower bound: <E super Integer> \nList<E> sequence(int n) { List<E> res = new LinkedList<E>(); for (int i = 1; i <= n; i++) { res.add(i); \n} return res; } Depending on the instantiation of E, the sequence method can be used to create lists \nof Integers, lists of Numbers, or lists of Objects (among other things). In each case, the method will \nadd some number of Integers to the list before returning it. This example could be roughly translated \ninto legal Java by replacing E with a wildcard (eliminating the type variable declaration and returning \na List<? super Integer>). But this is not a satisfactory alternative: a client may, for exam\u00adple, need \nto read from and write to a List<Number>, while a List<? super Integer> s get method returns Objects \nand its add method accepts only Integers. In addition to the practical argument, support for lower\u00adbounded \nvariable declarations is mandated by an appeal to uniformity: these bounds directly complement similar \nbounds on wildcards. The Aarhus Sun paper notes that, where a name representing a wildcard is needed, \nthe equiva\u00adlent of an existential-type open operation may be performed by invoking a polymorphic method \n[12, 3.3].16 For exam\u00adple, it is possible to shuf.e (both read from and write to) a List<?> by invoking \na method with signature <E> void shuffle(List<E> l) 15 This feature has been independently requested \nand discussed in Sun s Java bug database: [16]. 16 Existential types are traditionally used to de.ne \nan API in terms of a private, unnamed type. Clients of the API can use it by invoking an open operation, \ndeclaring a type variable as a stand-in for the private type. Similarly, we can sort a wildcard-parameterized \nlist, as long as the wildcard is bounded by something we know how to sort (a List<? extends Number>, \nsay): <E extends Number> void sort(List<E> l) Unfortunately, this strategy cannot work for lower-bounded \nwildcards, since Java 5 prohibits the declaration of a cor\u00adresponding lower-bounded type variable. This \nproblem is a fundamental de.ciency in the language s support for wild\u00adcards: a handle or witness for \ncertain wildcards is simply inexpressible without the loss of information about the wild\u00adcards bounds. \n(See Appendix A.4 for a pseudo real-world example in which such a handle is needed.) Given the signi.cance \nof lower-bounded parameters, why are they prohibited? The JLS indirectly provides some in\u00adsight into \nthe language designers motivation for making this restriction. While discussing lower bounds on wildcards, \nit implies that allowing lower bounds on method type param\u00adeters would make type inference for these \nmethods impos\u00adsible: Unlike ordinary type variables declared in a method signature, no type inference \nis required when using a wild\u00adcard. Consequently, it is permissible to declare lower bounds on a wildcard \n[3, 4.5.1]. It s easy to see that where inference consistently chooses the inferred lower bound as a \nparameter s instantiation, that bound will often violate the parameter s declared lower bound. Where \nthe declared lower bound is not de.ned in terms of P1 ...Pn, the solution is trivial: simply join the \ntwo bounds. But for interdependent lower bounds (probably rare in prac\u00adtice, if they serve any purpose \nat all), we can encounter the same problems as described in the previous section. For\u00adtunately, wildcard \ncapture can easily be extended to han\u00addle lower-bounded type parameters. And since many typical method \ninvocations do not lead to inferred upper bounds, the capture-based strategy described in Section 2.4.4 \nwill often produce useful, well-formed results. The only cases that can t be handled, as in the previous \nsection, are those in which a capture variable appearing in an interdependent bound makes the type incompatible \nwith the opposite in\u00adferred bound. In practice, such occurrences involving inter\u00addependent lower bounds \nare probably quite rare.  2.4.6 Broader Inference Locality Finally, perhaps the most visible shortcoming \nof Java 5 in\u00adference is its limited local scope. As has been discussed, the choice for s at a particular \ncall site is almost always deter\u00admined exclusively by the types of the invocation s arguments and the \ncorresponding method parameters. But there are of\u00adten a number of valid local choices for s; choosing \nthe best one from a broader perspective depends on how the return type of the method is used in a wider \ncontext. As a simple example, where a method with type pa\u00adrameter T returns values of type List<T>, an \nassignment to a variable of type List<Cloneable> will only be valid if s =[T := Cloneable]. Any more \nspeci.c choice for T will render the program incorrect. Similarly, if we nest the ex\u00adpression in another \nmethod invocation, the best choice for s depends on the corresponding formal parameter type. And if the \nouter method is overloaded or parametric, determining a choice for s that will render the entire expression \nwell-typed is quite complex. This potential for complexity highlights a tension be\u00adtween two important \nlanguage design goals. On the one hand, we do not want to force programmers to insert ex\u00adplicit type \nannotations where those annotations appear ob\u00advious and redundant. On the other hand, we do not want \nthe complexity of inference to lead to programmer confusion, where programmers cannot easily predict \nwhat the results of inference (and, where overloading is involved, the behavior of the program) will \nbe. We can balance these concerns and still improve the al\u00adgorithm by making more use of the bounds arising \nfrom an easily-determined expected type. As has been discussed, these bounds are derived from the following \nconstraint: sR <: E While, strictly speaking, any use of the expected type E allows context to in.uence \nthe type of an expression, this is not a concern in practice because E is only de.ned where its value \nis obvious to programmers (speci.cally, where the method invocation is the value of a return statement, \nthe initializer of a variable declaration, or the right-hand side of an assignment). The Java 5 algorithm \nmakes use of these bounds in limited cases, but it would be simple to extend the algorithm to always \nuse them where E is de.ned. It might also be practical to de.ne E in additional con\u00adtexts, such as where \nthe invocation is an argument to another method invocation, and the outer method is neither over\u00adloaded \nnor parametric. 3. Improved Algorithm Having considered a variety of solutions to shortcomings in the \nJava 5 type argument inference algorithm, we now com\u00adbine and formally present some of these solutions \nin a full algorithm de.nition.17 As was discussed, there are a num\u00adber of ways to handle many of the \nalgorithm s limitations (including simply accepting them). Here we present one ap\u00adproach, motivated by \na desire to address most of the above concerns while minimizing language changes. All the listed bugs \nhave been .xed; the possibility of other bugs is min\u00adimized by de.ning subtyping in a syntax-directed \nmanner, and by specifying subtype inference to correspond directly 17 This de.nition was originally published \nas one of two type system varia\u00adtions by Smith [10]. This version supersedes the .rst variation, and \nincludes both some technical corrections and some improvements to the presenta\u00adtion. The second variation \nis not included here, but may be independently useful: it formalizes the JLS s usage of recursive types. \nwith subtyping. The join operation is replaced with union types; recursive types are not present. Inference \nis able to handle disjunctive constraints by using constraint formulas, represented in disjunctive normal \nform. First-class intersec\u00adtion types and lower bounds on declared type variables are supported; wildcards \nand type variables are generalized to allow a single variable or wildcard to have both an upper and a \nlower bound. Inference still occurs on a per-invocation basis, but the expected return type is always \nused when it is available. Unlike core calculi like Featherweight Java [4], this def\u00adinition is intended \nto cover the full scope of the Java lan\u00adguage. On the other hand, it is not a full language de.nition, \nbut rather limited to a de.nition of types and the tools needed to analyze them. 3.1 Fundamentals 3.1.1 \nTypes A type is one of the following: The null type (denoted null here, but distinguishable by context \nfrom the value null).  A ground parameterized class type C<T1 ...Tn>, where C is a name and, for all \ni, Ti is a type.  A wildcard-parameterized class type C<W1 ...Wn>, where C is a name and, for all i, \nWi is a type argument, which is one of: A type. A wildcard ? extends Tu super Tl, where Tu and Tl are \ntypes. (A wildcard is not a type.)  A raw class type C, where C is a name.  A primitive array type \np[], where p is a primitive type name (int, char, etc.)  A reference array type T [], where T is a type. \n A type variable X, where X is a name.  An intersection type T1 &#38; ... &#38; Tn, where, for all \ni = n, Ti is a type.  A union type T1 | ... | Tn, where, for all i = n, Ti is a type.  For simplicity, \nwe have ignored primitive types. Gener\u00adally, primitives can be handled by implementations sepa\u00adrately \nbefore deferring to the type operations de.ned here. We also ignore any distinction between classes and \ninter\u00adfaces hereafter, the word class means either a class or an interface. The names referred to in \nthe de.nition are assumed to be globally-unique identi.ers. Every class and type variable declared by \na program must have exactly one such name.18 18 This is essentially what is meant by canonical names, \nas de.ned in the JLS. However, that de.nition does not apply to local classes and interfaces, nor to \ntype variables. All lists in this de.nition may be of any length, including 0. The type of a class C \nwith no declared parameters is the ground parameterized class type C<> (but may informally be written \nC). Types of nested classes do not appear explicitly in this de.nition. Instead, these are just treated \nlike top-level classes. We follow the convention that a class s list of parameters in\u00adcludes all type \nvariables available from outer declarations.19 For example, if class Foo declares inner class Bar, the \nex\u00adpression new Foo<String, Object>().new Bar<Cloneable>() has type Foo.Bar<String, Object, Cloneable> \nIn Java code, we would instead write Foo<String, Object>.Bar<Cloneable> Intersections represent the most \ngeneral type for which each of Ti is a supertype. If an intersection consists of some number of interface \nnames, for example, any class that im\u00adplements all the listed interfaces is a subtype of the intersec\u00adtion. \nComplementing this notion, unions represent the least general type for which each of Ti is a subtype. \nAny common supertype of these types is also a supertype of the union. Be\u00adcause unions are not currently \npart of Java, certain operations involving these types, such as method lookup and erasure, are de.ned \nneither in the JLS nor in this paper. Igarashi and Nagira [6] develop object-based union types in depth \nand present possible de.nitions for these missing pieces. In the notation that follows, we maintain the \nfollowing conventions: X, Y , Z, P , and Q represent type variables (P and Q usually represent declared \ntype parameters).  C represents a class name.  W represents a type argument either a type or a wild\u00adcard. \n All other capital letters represent arbitrary types.  To simplify the de.nition of structurally-recursive \nfunc\u00adtions, we will refer to the types of which a type is directly composed as its component types. The \nwildcard bounds of a wildcard-parameterized class type are among its component types. 3.1.2 Bounds Type \nvariables are always bounded a valid instantiation of a variable must be a subtype of its upper bound, \nand a 19 This list does not extend beyond a local scope if a class is de.ned inside a method, its parameters \ndo not include those of the method or of the enclosing class; the list also excludes variables that are \nnot available because a class is declared static. supertype of its lower bound. This information is provided \nby the source code, and where it is elided, Object is the default upper bound and null is the default \nlower bound. The functions upper and lower, which map variables to their bounds, are implicit parameters \n(for conciseness) to most of the operations that follow. Additionally, the capture function may produce \nnew variables, and thus new instances of upper and lower. These updated bound functions are implicitly \nthreaded through all subsequent operations on the types produced by capture. The expression .X. is shorthand \nfor the application of upper to X, producing X s upper bound; similarly, .X. produces X s lower bound. \n 3.1.3 Structural Well-formedness A type T is structurally well-formed (in the context of a set of class \nde.nitions) if and only if all of its component types are structurally well-formed and it violates none \nof the following assertions: Where T = C<T1 ...Tn>, the class named C exists and has n type parameters. \n Where T = C<W1 ...Wn>, the class named C exists and has n type parameters, and there exists some i \nsuch that Wi is a wildcard (thus n = 1).  Where T = C, the class named C exists and has at least one \ntype parameter.  Except where noted, all type operations de.ned below assume a domain of structurally \nwell-formed types (this includes types passed as implicit arguments, such as a class s parameters or \na variable s bounds). The safety of the type system relies on a stronger notion of semantic well\u00adformedness, \nde.ned later in this section. This distinction is necessary because semantic well-formedness relies on \nsubtyping and other type operations; we cannot in general guarantee the semantic well-formedness of the \noperations arguments, and instead must settle for the structural checks de.ned here. 3.1.4 Substitution \nSubstitution instantiates a set of type variables, and is de\u00adnoted sT or, more explicitly, [P1 := T1 \n... Pn := Tn]T . The types involved need not be well-formed. It is de.ned as the structurally-recursive \napplication of the following rule: [P1 := T1 ... Pn := Tn]X = Ti if, for some i, X = Pi; otherwise [P1 \n:= T1 ... Pn := Tn]X = X. By structurally-recursive we mean that, for arbitrary T , the substitution \nis applied to each T s component types, and a new type is constructed from these modi.ed types. The bounds \nof a wildcard within a wildcard-parameterized type are components of that type; the bounds of a variable \nare not. Thus, substitution cannot be used directly to instan\u00adtiate the bounds of a variable. 3.1.5 \nWildcard Capture Wildcard capture is an operation on type arguments (either types or wildcards, W1 ...Wn) \nand their corresponding type parameters (P1 ...Pn), producing a globally-unique vari\u00adable for each wildcard. \nEach new variable has the same bounds as the wildcard, combined with the (instantiated) bounds of the \ncorresponding type parameter. capture(W1 ...Wn,P1 ...Pn)= T1 ...Tn, where, for all i: If Wi is a type, \nTi = Wi.  If Wi is the wildcard ? extends Wiu super Wil, Ti = Zi for a fresh name Zi, where:  .Zi. \n= Wiu &#38; [P1 := T1 ... Pn := Tn].Pi.. .Zi. = Wil | [P1 := T1 ... Pn := Tn].Pi.. Capture is principally \nused to convert a wildcard-param\u00adeterized class type to a ground parameterized class type. We use the \nnotation .C<W1 ...Wn>. to represent such a conversion: where P1 ...Pn are the type parameters of class \nC and capture(W1 ...Wn,P1 ...Pn)= T1 ...Tn, we have .C<W1 ...Wn>. = C<T1 ...Tn>. 3.1.6 Direct Supertype \nOur subtyping de.nition relies on determining the direct supertype of a class type, denoted T.. This \nis de.ned as follows: Where T = C<T1 ...Tn>, If C = Object, T. is unde.ned. Else if C declares no supertypes, \nT. = Object. Else C declares supertypes S1 ...Sm and type pa\u00ad rameters P1 ...Pn; let s =[P1 := T1 ... \nPn := Tn]; T. = sS1 &#38; ... &#38; sSm. Where T = C<W1 ...Wn>, T. = .C<W1 ...Wn>... Where T = C, If \nC declares no supertypes, T. = Object. If C declares supertypes S1 ...Sm, T. = |S1| &#38; ... &#38; |Sm|. \n|Si|, used in the raw case, denotes the erasure of the given type, as de.ned in the JLS (4.6). The direct \nsupertype operation is implicitly parameter\u00adized by a class table which contains the supertype declara\u00adtions \nde.ned in the source code. All operations that depend on direct supertypes are similarly parameterized. \n 3.1.7 Subtype Relation The type S is a subtype of T , denoted S <: T , if and only if this relationship \ncan be demonstrated with the following set of inference rules: T <: T (REFLEX) S <: S. S. <: T (TRANS) \nS <: T null <: T (NULL) .i = n, Si ~ = Ti (CLASS-EQUIV) C<S1 ...Sn> <: C<T1 ...Tn> .i = n, Si . Wi (CLASS-CONTAIN) \nC<S1 ...Sn> <: C<W1 ...Wn> .C<W1 ...Wn>. <: T (CLASS-CAPT) C<W1 ...Wn> <: T C<T1 ...Tn> <: C (CLASS-ERASE) \nT <: T. (CLASS-SUP) p[] <: Cloneable &#38; Serializable (PRIM-ARR-CLASS) T [] <: Cloneable &#38; Serializable \n(ARR-CLASS) S <: T (ARR-COVAR) S[] <: T [] X <: .X. (VAR-SUP) Although it is sound, we do not include \nthe following distribution rule for intersections and unions:21 S &#38; (T1 | ... | Tn) <: (S &#38; T1) \n| ... | (S &#38; Tn) (DIST) Table 1 reexpresses subtyping algorithmically for any pair of types, subtyping \nis de.ned to hold if and only if a rule referenced in the corresponding cell of the table holds (S matches \none of the cases in the left column; T matches one of the cases in the top row. A - in the table represents \na result that is trivially false). The correspondence between the above declarative rules and the algorithmic \nrules in Table 1 is expressed formally in Section 3.1.9. Note that certain rules may be applicable to \nan S T pair but not appear in the corresponding table cell. For example, REFLEX is frequently elided; \nVAR-SUB* is not used where S is a union. In such cases, the elided rule is provably redun\u00addant. On the \nother hand, there are times (like the variable variable case) where every applicable rule must be tested. \nImplementing a subtyping algorithm in terms of these algorithmic rules is a straightforward process. \nIn order to guarantee termination, however, we require the following of the subtyping arguments in addition \nto the assumption that the types be structurally well-formed:22 No variable is bounded by itself that \nis, .X.+ . = X and .X.+ . = X. 1 ...T The class table is acyclic: C<T1 ...Tn>.+ . = C<T > n for any choice \nof T1 . ...T . . n .X. <: X (VAR-SUB) The class table does not exhibit expansive inheritance, as de.ned \nby Kennedy and Pierce [7]. T1 &#38; ... &#38; Tn <: Ti (INTER-SUP) Unlike the JLS, we do not prohibit \nmultiple-instantiation .i = n, S <: Ti inheritance: we might have C<T1 ...Tn>.+ = D<S1 ...Sm> 1 ...S \n(INTER-SUB) and C<T1 ...Tn>.+ where, for some i, = D<S > S <: T1 &#38; ... &#38; Tn m = S. Si .i. Even \nwith these limitations, certain subtyping invocations may depend on themselves (Kennedy and Pierce [7] \nprovide .i = n, Si<: T (UNION-SUP) S1 | ... | Sn <: T some examples). So the algorithm must keep track \nof in- Ti<: T1 | ... | Tn (UNION-SUB) If S <: T , then equivalently T is a supertype of S (de\u00adnoted T \n:> S). Where two types are mutual subtypes of each other that is, S <: T and T <: S we say that they \nare equivalent, denoted S ~20 = T . The expression S . W , used to express containment by a type argument \n(either a type or a wildcard) in CLASS-CONTAIN, is shorthand for the following: Where W is a type T , \nS ~ = T . Where W is a wildcard ? extends Tu super Tl, S <: Tu . Tl<: S. process invocations and terminate \n(negatively) whenever a subtyping invocation depends on itself.  3.1.8 Bounds Checking We use inBounds \nto assert that type arguments (T1 ...Tn) do not violate the bound assertions of their corresponding type \nparameters (P1 ...Pn). inBounds(T1 ...Tn,P1 ...Pn) is de.ned for struc\u00adturally well-formed types as follows: \n For all i, Ti<: [P1 := T1 ... Pn := Tn].Pi..  For all i, [P1 := T1 ... Pn := Tn].Pi. <: Ti.  21 A \ndistribution rule could (and ought to) be added as an extension to the current presentation, although \nde.ning a straightforward subtyping algo\u00ad rithm under such a rule requires tedious normalization steps. \n20 We usein subtyping where Java 5 uses =. This is independent of ~ = the main concerns addressed in \nthis paper, but is included as a convenience 22 The use of transitive closure here is intended to also \npermit the decompo\u00ad ~ = , and can thus be used interchangeably, but that are not =. sition of intersection \nand union types. to programmers, since there exist types that are T : null Ct<T1 . . . Tm> Ct<W1 . . \n. Wm> Ct null true true true true Cs<S1 . . . Sn> - CLASS-EQUIV, CLASS-SUP* CLASS-CONTAIN, CLASS-SUP* \nCLASS-ERASE*, CLASS-SUP* S: Cs<W1 . . . Wn> Cs ps[] S.[] Xs S1 &#38; . . . &#38; Sn S1 | . . . | Sn ----VAR-SUP* \nINTER-SUP* UNION-SUP CLASS-CAPT* CLASS-SUP* PRIM-ARR-CLASS* ARR-CLASS* VAR-SUP* INTER-SUP* UNION-SUP \nCLASS-CAPT* CLASS-SUP* PRIM-ARR-CLASS* ARR-CLASS* VAR-SUP* INTER-SUP* UNION-SUP CLASS-CAPT* REFLEX, CLASS-SUP* \nPRIM-ARR-CLASS* ARR-CLASS* VAR-SUP* INTER-SUP* UNION-SUP pt[] T .[] T : Xt T1 &#38; . . . &#38; Tm T1 \n| . . . | Tm S: null Cs<S1 . . . Sn> Cs<W1 . . . Wn> Cs ps[] S.[] Xs true ---REFLEX -VAR-SUP* true ----ARR-COVAR \nVAR-SUP* true VAR-SUB* VAR-SUB* VAR-SUB* VAR-SUB* VAR-SUB* REFLEX, VAR-SUP*, VAR-SUB* true INTER-SUB \nINTER-SUB INTER-SUB INTER-SUB INTER-SUB INTER-SUB true UNION-SUB* UNION-SUB* UNION-SUB* UNION-SUB* UNION-SUB* \nVAR-SUP*, UNION-SUB* S1 &#38; . . . &#38; Sn INTER-SUP* INTER-SUP* INTER-SUP*, VAR-SUB* INTER-SUB INTER-SUP* \nS1 | . . . | Sn UNION-SUP UNION-SUP UNION-SUP UNION-SUP UNION-SUP T <: T (REFLEX) ~ .i, Si = Ti .i, \nSi . Wi (CLASS-EQUIV) (CLASS-CONTAIN) C<S1 ...Sn> <: C<T1 ...Tn> C<S1 ...Sn> <: C<W1 ...Wn> .C<W1 ...Wn>. \n<: TC <: TS. <: T (CLASS-CAPT*) (CLASS-ERASE*) (CLASS-SUP*) C<W1 ...Wn> <: T C<S1 ...Sm> <: TS <: T Cloneable \n&#38; Serializable <: T Cloneable &#38; Serializable <: T (PRIM-ARR-CLASS*) (ARR-CLASS*) ps[] <: T S[] \n<: T S <: T .X. <: TS <: .Xt. (ARR-COVAR) (VAR-SUP*) (VAR-SUB*) S[] <: T [] Xs<: TS <: Xt .i, Si<: T \n.i, S <: Ti (INTER-SUP*) (INTER-SUB) S1 &#38; ... &#38; Sn <: TS <: T1 &#38; ... &#38; Tn .i, Si<: T \n.i, S <: Ti (UNION-SUP) (UNION-SUB*) S1 | ... | Sn <: TS <: T1 | ... | Tm Table 1. Algorithmic rules \nfor subtyping 3.1.9 Semantic Well-formedness In order to make useful assertions about the correctness \nof the above operations, a stronger notion of well-formedness is needed. Thus, a type is semantically \nwell-formed (in the context of a set of class de.nitions) if and only if it is struc\u00adturally well-formed, \nall of its component types are semanti\u00adcally well-formed, and it violates none of the following as\u00adsertions: \nWhere T = C<T1 ...Tn>, and class C has parameters P1 ...Pn, inBounds(T1 ...Tn,P1 ...Pn). Where T = C<W1 \n...Wn>, .C<W1 ...Wn>. is semanti\u00adcally well-formed.  Where T = X, .X. <: .X..  Well-formed, when used \nwithout quali.cation, refers to semantic well-formedness. In the context of a full lan\u00adguage de.nition, \nall types expressed in code should be well\u00adformed, and type analysis must only produce new types that \nare well-formed. Note the use of capture in validating the arguments of a wildcard-parameterized class \ntype. It is tempting to try to avoid capture conversion here, and in many situations its use can be eliminated. \nHowever, in general, we must use capture to insure two important conditions: .rst, that the variables \ngenerated by capture are not malformed each variable s lower bound is a subtype of its upper bound; and \nsecond, that non-wildcard arguments are within their bounds. Bounds in both cases may be de.ned in terms \nof capture variables and other type arguments, so the bounds must be instantiated before they are checked.23 \nGiven this stronger well-formedness notion, we can make a few important assertions about substitution, \nwildcard cap\u00adture, and subtyping. (We do not provide in this paper proofs for these assertions. They \ndo, however, provide a standard by which to informally verify correctness.) Substitution. The notion \nof well-formedness allows us to make the following de.nition and assertion regarding substitution: De.nition. \nAn invocation [P1 := T1 ... Pn := Tn]T is well\u00adformed if and only if T , P1 ...Pn, and T1 ...Tn are well\u00adformed \nand inBounds(T1 ...Tn,P1 ...Pn). Theorem. Where the substitution invocation sT is well\u00adformed, its result \nis also well-formed. The following lemmas help to demonstrate this result: Lemma. Where the substitution \ninvocations are well-formed, T1 <: T2 . sT1 <: sT2. Lemma. Where the substitution invocations are well-formed \nand the parameters Q1 ...Qm do not have bounds that in\u00ad 23We do not need to check the inBounds condition \nfor capture variables, since these variables are guaranteed to be in bounds, but we don t compli\u00adcate \nthe de.nition with this fact here. volve the parameters of s, inBounds(S1 ...Sm,Q1 ...Qm) . inBounds(sS1 \n. . . sSm,Q1 ...Qm). Wildcard capture. In general, capture may produce mal\u00adformed types from well-formed \narguments this is why the rules for semantic well-formedness check that the type is well-formed after \ncapture. We can, however, make the fol\u00adlowing claim: Theorem. Where W1 ...Wn are all wildcards and the \ntypes capture(W1 ...Wn,P1 ...Pn) are well-formed, inBounds(capture(W1 ...Wn,P1 ...Pn),P1 ...Pn) Subtyping. \nWell-formedness allows us to make the fol\u00adlowing soundness and completeness claim about the subtyp\u00ading \nalgorithm: Theorem. Where S, T , and all types in the implicit environ\u00adment (variable bounds and a class \ntable) are well-formed, the assertion S <: T is true according to algorithmic sub\u00adtyping (de.ned in Table \n1) if and only if it is derivable by the declarative subtyping inference rules.  3.2 Type Argument Inference \n3.2.1 Overview The type argument inference algorithm produces an instan\u00adtiation s =[P1 := T1 ... Pn := \nTn] of a set of method type parameters for a speci.c call site. The result is a function of the types \nof the formal parameters (F1 ...Fm), the types of the invocation s arguments (A1 ...Am), the method s \nreturn type (R), and the type expected in the call site s context (E). An inference result must satisfy \nthe following: .i, Ai<: sFi sR <: E inBounds(T1 ...Tn,P1 ...Pn) We proceed by .rst producing a set of \nbounding con\u00adstraints satisfying .rst two conditions, and then choosing types that both meet these constraints \nand fall within bounds speci.ed by P1 ...Pn. The algorithm is sound, but not com\u00adplete: the results will \nalways satisfy the three above con\u00adstraints, but where P1 ...Pn are referenced within their own bounds, \nit may fail to produce a result where one exists.24 In all other cases, it is complete. Bounding constraints \non the type arguments are deter\u00admined by two functions, <:? and :>?. A <:? F produces a minimal set of \nconstraints on T1 ...Tn required to satisfy A <: sF ; A :>? F similarly produces the constraints satis\u00adfying \nA :> sF . The constraints are expressed as logical for\u00admulas, combined and normalized with the operations \n.cf and .cf as outlined below. For convenience, a third infer\u00adence function, ~ =?, is a shortcut for \n.cf (A <:? F, A :>? F ). 24 See Section 2.4.4 for discussion regarding this special case. 3.2.2 Constraint \nFormulas A constraint formula is a formula in .rst-order logic ex\u00adpressing upper and lower bounds on \nour choices for types T1 ...Tn. Where a certain instantiation contains types that fall within the bounds \nexpressed by a formula f, that instan\u00adtation satis.es the formula: s |= f. We also use this notation \nfor implication: f |= . means .s, (s |= f) . (s |= .). In the inference algorithm, we restrict the form \nof all constraint formulas as follows, modeled after disjunctive normal form: m T1jl <: T1 <: T1ju . \n... . Tnjl <: Tn<: Tnju j=1 The value of m may be any natural number. We will use false as an abbreviation \nfor the formula in which m =0. If m =1, the formula is a simple constraint formula; we use true to represent \nthe simple formula null <: T1 <: Object . ... . null <: Tn<: Object Finally, an expression such as C \n<: T1 <: D is taken as an ab\u00adbreviation for a simple constraint formula in which the given parameter \nhas the speci.ed bounds, and all other parameters are bounded by the unconstraining null and Object. \nIt will be necessary to produce conjunctions and disjunc\u00adtions of constraint formulas. The operations \n.cf and .cf serve this purpose, while maintaining the invariant normal\u00adized form. These operations, de.ned \nbelow, are sound and complete with respect to simple conjunction and disjunction: Lemma. s |=(f . .) \nif and only if s |= .cf (f, .). Lemma. s |=(f . .) if and only if s |= .cf (f, .). Conjunction. Let .1 \n....m be simple constraint formu\u00adlas. Let Tijl refer to the lower bound of Ti in .j, and Tiju refer to \nthe upper bound. Then .cf (.1 ....m) has value n (Ti1l | ... | Timl) <: Ti<: (Ti1u &#38; ... &#38; Timu) \ni=1 The construction of unions and intersections here is required to eliminate redundant entries: String \n&#38; Object reduces to String, for example. If the result is unsatis.able that is, for some Ti, the \nlower bound is not a subtype of the upper bound it is simpli.ed to false. Note also that if any of .j \nis true (and m> 1), that formula is automatically discarded (because its bounds are always redundant). \nIn the general case where the arguments f1 ...fm are not simple we de.ne .cf by merging each possible \ncom\u00adbination of simple constraint formulas. In this case, each of of f1 ...fm can be treated as a set \nof simple formulas; the cross product of these sets, f1 \u00d7 ... \u00d7 fm, produces k m-tuples of the form (.1 \n....m). Applying .cf to each of these tuples (as de.ned above for simple formulas), we pro\u00adduce the set \nof simple formulas .. 1 ..... . Then we have k .cf (f1 ...fm)= .cf (.. 1 ..... ) k Again, we note that \nif any of fj is true, that set will be discarded; if any of fj is false, the result will also be false \n(because k =0). Disjunction. The .cf operation would be correct to sim\u00adply concatenate its arguments \ntogether. However, we wish to ensure that all formulas we produce are minimal. We can use the following \nto help eliminate redundant simple formulas: Theorem. For simple constraint formulas .1 and .2, .1 |= \n.2 if and only if, for all i, Ti1u<: Ti2u and Ti1l :> Ti2l. Now, we de.ne .cf (f1 ...fm) as follows. \nAgain treat\u00ading these formulas as sets of simple formulas, let .1 ....k be the union f1 . ... . fm. We \ncan compute a minimal equiva\u00adlent subset of .1 ....k, .. 1 ..... k. , where minimal means that .i, .j, \n.i |= .. (the intuition is that if one formula implies j another, the .rst is more constraining on s; \nthe only way a choice for s will satisfy neither formula is if it does not satisfy the less constraining \none). Now we have k. .cf (f1 ...fm)= .. i i=1 Again note that the trivial cases are handled correctly: \nif any of f1 ...fm is false, it will be ignored; if any of f1 ...fm is true, it will be the only member \nof the minimal subset, and the result will be true. 3.2.3 Subtype Inference The invocation A <:? F |\u00b5 \nproduces a constraint formula supporting the assumption that A <: sF . The parameter \u00b5 is a set of previous \ninvocations of <:? and :>?. For brevity, we do not express \u00b5 explicitly; it is always empty on exter\u00adnal \ninvocations, and wherever one of these operations is re\u00adcursively invoked (including mutual recursion \nbetween <:?, :>?, and ~ =?), the previous invocation is accumulated in \u00b5. If the invocation A <:? F \n. \u00b5, the result is false.  Else if, for some i, F = Pi, the result is A <: Ti<: Object.  Else if F \ninvolves none of P1 ...Pn, the result is A <: F (treating the boolean result of <: as a trivial constraint \nformula).  Otherwise, the result is given in Table 2. (A matches one of the cases in the left column; \nF matches one of the cases in the top row. A - in the table represents the formula false.)  Compare \nTable 2 to Table 1. Notice that the rules for inference follow directly from subtyping. The only changes \nreplace boolean operations with their analogs: <: becomes <:?; and and or become .cf and .cf .  3.2.4 \nSupertype Inference The invocation A :>? F |\u00b5 produces a constraint formula supporting the assumption \nthat A :> sF . The parameter \u00b5 is as described in the previous section. null Ca<A1 . . . An> Ca<W1 . \n. . Wn> Ca A: ps[] A.[] Xa A1 &#38; . . . &#38; An A1 | . . . | An null Ca<A1 . . . An> Ca<W1 . . . Wn> \nCa A: ps[] A.[] Xa A1 &#38; . . . &#38; An A1 | . . . | An [1]: There are two cases: F : F . Cf <F1 \n...Fm> Cf <W1 ...Wm> [] true true true [1] [2] - .A. <:? F .A. <:? F - A. <:? F A. <:? F - [4] [4] - \n[4] [4] A. <:? F . .A. <:? F .A. <:? F .A. <:? F .cf (Ai <:? F ) .cf (Ai <:? F ) .cf (Ai <:? F ) .cf \n(Ai <:? F ) .cf (Ai <:? F ) .cf (Ai <:? F ) F : Xf F1 &#38; . . . &#38; Fm F1 | . . . | Fm true true \ntrue A <:? .F . .cf (A <:? Fi) .cf (A <:? Fi) A <:? .F . .cf (A <:? Fi) .cf (A <:? Fi) A <:? .F . .cf \n(A <:? Fi) .cf (A <:? Fi) A <:? .F . .cf (A <:? Fi) .cf (A <:? Fi) A <:? .F . .cf (A <:? Fi) .cf (A <:? \nFi) [5] .cf (A <:? Fi) [6] [7] .cf (A <:? Fi) .cf (A <:? Fi) .cf (Ai <:? F ) .cf (Ai <:? F ) .cf (Ai \n<:? F ) ~~ If Ca = Cf , .cf (A1 =? F1,...,An =? Fn) Otherwise, A. <:? F [2]: There are two cases:  \nIf Ca = Cf , .cf (f1 ...fn) where, for all i: If Wi is a type, fi = Ai =? Wi  ~ If Wi is a wildcard \n? extends Fiu super Fil, fi = .cf (Ai <:? Fiu,Ai :>? Fil) Otherwise, A. <:? F [4]: Cloneable &#38; Serializable \n<:? F [5]: .cf (.A. <:? F, A <:? .F .) [6]: .cf (.A. <:? F, A <:? F1 ...A <:? Fm) [7]: .cf (A1 <:? F \n...An <:? F, A <:? .F .) Table 2. Rules for subtype inference If the invocation A :>? F . \u00b5, the result \nis false.  If, for some i, F = Pi, the result is null <: Ti<: A.  If F involves none of P1 ...Pn, the \nresult is F <: A (treating the boolean result of <: as a trivial constraint formula).  Otherwise, the \nresult is given in Table 3. (A matches one of the cases in the left column; F matches one of the cases \nin the top row. A - in the table represents the formula false.)  Similarly to Table 2, Table 3 follows \ndirectly from the subtyping rules (this is slightly less apparent, because the ta\u00adble has been transposed, \nallowing the upper type to appear on the left).  3.2.5 Inference Algorithm Building on these de.nitions, \nwe now describe the full algo\u00adrithm for type argument inference. The .rst two conditions to be satis.ed \nby the instantiation s that the invocation s arguments are subtypes of their corresponding formal parameters, \nand that the return type is a subtype of the expected type are described by the formula f = .cf (A1 <:? \nF1 ...Am <:? Fm,E :>? R) null Ca<A1 ...An> Ca<W1 ...Wn> Ca A: ps[] A. [] Xa A1 &#38; ... &#38; An A1 \n| ... | An null Ca<A1 ...An> Ca<W1 ...Wn> Ca A: ps[] A. [] Xa A1 &#38; ... &#38; An A1 | ... | An [1]: \nThere are two cases: ~~ If Ca = Cf , .cf (A1 =? F1,...,An =? Fn) Otherwise, A :>? F. [2]: There are \ntwo cases:  If Ca = Cf , .cf (f1 ...fn) where, for all i: If Wi is a type, fi = Wi =? Fi  ~ If Wi is \na wildcard ? extends Aiu super Otherwise, A :>? F. [3]: If Ca = Cf , true; otherwise, A :>? F. [4]: A \n:>? Cloneable &#38; Serializable [5]: .cf (A :>? .F ., .A. :>? F ) [6]: .cf (A :>? .F .,A1 :>? F ...An \n:>? F ) [7]: .cf (A :>? F1 ...A :>? Fm, .A. :>? F ) F : F . Cf <F1 ...Fm> Cf <W1 ...Wm> [] - [1] [2] \n[3] - -  .A. :>? F .cf (Ai :>? F ) .cf (Ai :>? F ) Xf A :>? .F . A :>? .F . A :>? .F . A :>? .F . \nA :>? .F . A :>? .F . [5] .cf (Ai :>? F ) [6] - A :>? .F . A :>? .F . A :>? .F . -- .A. :>? F .cf (Ai \n:>? F ) .cf (Ai :>? F ) F : F1 &#38; ... &#38; Fm .cf (A :>? Fi) .cf (A :>? Fi) .cf (A :>? Fi) .cf (A \n:>? Fi) .cf (A :>? Fi) .cf (A :>? Fi) [7] .cf (Ai :>? F ) .cf (A :>? Fi) Ail, fi = .cf (Aiu :>? Fi,Ail \n<:? Fi) -[4] [4] [4] - A. :>? F . .A. :>? F .cf (Ai :>? F ) .cf (Ai :>? F ) F1 | ... | Fm .cf (A :>? \nFi) .cf (A :>? Fi) .cf (A :>? Fi) .cf (A :>? Fi) .cf (A :>? Fi) .cf (A :>? Fi) .cf (A :>? Fi) .cf (A \n:>? Fi) .cf (A :>? Fi) Table 3. Rules for supertype inference Given the formula f, we must choose types \nfor T1 ...Tn satisfying the bounds of the corresponding parameters: inBounds(T1 ...Tn,P1 ...Pn). We .rst \nchoose values for T1 ...Tn based on the inferred lower bounds: for each conjunction in f of the form \nT1l<: T1 <: T1u . ... . Tnl <: Tn<: Tnu we choose Ti = Til. If this choice satis.es the inBounds condition, \nthat is the result. Otherwise, the next disjunct in f is used. If no solution is found using the inferred \nlower bounds, we instead use capture to produce the results. If we treat each assertion Til <: Ti<: Tiu \nin a constraint formula as a wildcard ? extends Tiu super Til we can represent f as follows: m f = W1j \n...Wnj j=1 To satisfy the bounds, we let T1 ...Tn = capture(W11 ...Wn1,P1 ...Pn) If the resulting capture \nvariables are well-formed, these are the choice for T1 ...Tn. Otherwise, the next disjunct in f is used. \nIf no results are found in this way, the algorithm reports failure. Note that there is a nondeterminacy \npresent in the above algorithm: where more than one simple constraint formula in the .nal constraints \nis satis.able, the choice of which for\u00admula to use depends on the order in which they are enumer\u00adated. \nThis nondeterminacy is inherent in the inference prob\u00adlem: if the constraints on T1 can be satis.ed with \neither T1 = String or T1 = Integer (but not with T1 = null), the algo\u00adrithm must arbitrarily choose one \nor the other. Clearly, such nondeterminacy must be avoided in a full speci.cation two different implementations \nmust not choose different types for T1. To do so, the speci.cation would need to extend the treatment \nof formula operations in terms of sets to preserve a well-de.ned order of elements.  3.2.6 Correctness \nand Complexity We do not make a formal analysis of the correctness or complexity of the inference algorithm \nhere. We do, however, state some useful properties that we expect to hold and informally discuss the \nalgorithm s ef.ciency. First, termination is closely tied to the termination of subtyping. Lemma. The \ntype argument inference algorithm terminates if the corresponding subtyping algorithm terminates. The \ncorrectness of the algorithm is also closely tied to that of subtyping. Lemma. The results of <:? and \n:>? are sound and complete with respect to the subtyping rules: s |= A <:? F if and only if sA <: sF \n(and the equivalent for :>?). Given this assertion, soundness is straightforward. Theorem. If type argument \ninference produces a result s = [P1 := T1 ... Pn := Tn], the corresponding method invoca\u00adtion is well-typed \n(as is the enclosing expression, where E is de.ned and the expression is otherwise correct): .i, Ai<: \nsFi  sR <: E  inBounds(T1 ...Tn,P1 ...Pn)  The completeness of <:? and :>? is similarly important \nin understanding the algorithm s limitations: the only source of incompleteness is in choosing an instantiation \nthat satis.es both the inferred and the declared bounds. In the typical, simple case in which parameter \nbounds are not recursive or interdependent, the algorithm can be expected to produce valid results when \nthey exist. To address ef.ciency, note that the dominating source of complexity (both in time and space) \nis in the manipulation of constraint formulas: .cf , in particular, calculates a cross product that may \nproduce up to m \u00d7 n disjuncts when given arguments with m and n disjuncts, respectively. Union and intersection \ntypes, as constructed by .cf , also have the po\u00adtential to grow to intractable sizes. However, these \nare con\u00adsistently minimized to eliminate redundancy; and, as noted in Section 2.4.2, we expect the sizes \nof the algorithm s inputs to be quite small in practice. 3.2.7 Special Cases When the above inference \nalgorithm is used in the context of the full Java language, a variety of subtleties must be addressed: \n E may be unde.ned, or R may be void. Then there are no constraints on the return type, and we do not \ninclude E :>? R in the result.  The types involved may be primitives. The inference op\u00aderations can \nbe easily extended to handle both primitive subtyping and reference subtyping, as appropriate.  Boxing \nor unboxing of the arguments or return value may be allowed. Determining whether these conversions should \noccur is always possible without knowing s. So we can assume here that A1 ...Am and E represent the types \nafter any necessary conversions.  Variable-length arguments may be used. In this case, the method signature \nprovides formal parameter types F1 ...Fj, and Fj is the array type Fj .[]. The constraint formula calculation \nmust then contain A1 <:? F1,..., Aj-1 <:? Fj-1, and, if m = j, Aj <:? Fj . ,..., Am <:? Fj. .  The type \nparameters of a class enclosing the method declaration may appear in F1 ...Fm, R, or the bounds of P1 \n...Pn. Substitution can be used to remove these from F1 ...Fm and R; but in order to handle any references \nin P1 ...Pn, we must de.ne new variables P1 . ...P .  n with bounds de.ned by the class parameter instantiations. \nAlternately, the class parameters can be included in the list of parameters to be inferred, but be constrained \nso that the only valid choice to instantiate a class parameter is the one that has already been provided. \n4. Backwards Compatibility Enhancements to the Java language are generally made in a backwards-compatible \nfashion: the revised language is a su\u00adperset of the previous version, and the behavior of previous programs \nis preserved. Unfortunately, changes to the current speci.cation that affect join and type argument inference \nare almost impossible to make without rendering some pro\u00adgrams incorrect, and changing the behavior of \nothers. Consider, for example, the signature of the method java.util.Arrays.asList: static <T> List<T> \nasList(T... ts) If this method is invoked in a context in which the expected type E is unknown as an \nargument to another method, for example invariant subtyping can easily cause a cor\u00adrect program to become \nincorrect with only slight modi.\u00adcations to the inference algorithm. That is, where the orig\u00adinal algorithm \nproduces T1 = U and the context of the invocation requires a List<U>, an algorithm that produces a better \nbut different type V will lead to an assertion that List<V > <: List<U>, which is false. More troubling \nis the possibility that a change to join or the inference algorithm, while not invalidating a certain \npre\u00adviously well-formed program, will change the meaning of that program. This is possible because overloading \nresolu\u00adtion is dependent on the types produced by type checking. The value of the test method below, \nfor example, depends on the sophistication of the inference algorithm used: interface NumBox<T extends \nNumber> { T get(); } static <T> T unwrap(NumBox<? extends T> arg) { return arg.get(); } static int f(Object \no) { return 0; } static int f(Number n) { return 1; } static int test(NumBox<?> arg) { return f(unwrap(arg)); \n} A system with an inference algorithm that uses cap\u00adture (or otherwise incorporates the declared bounds \nof a wildcard s corresponding parameter) can determine that the f(Number) function is applicable in the \nbody of test; one that does not will instead resolve f to the f(Object) func\u00adtion. Despite these incompatibilities, \nthe bugs in the Java 5 speci.cation (as described in Section 2.3), provide strong motivation for .xing \nthese operations even if the addi\u00adtional shortcomings of the inference algorithm are not ad\u00addressed. \nSo we are left with a problem: do we go to great lengths to enforce backwards compatibility with broken \nop\u00aderations (perhaps by de.ning two inference algorithms, and using the second only when the .rst is \nunsuccessful), or relax this requirement in order to correct and clean up the speci.\u00adcation? Complicating \nthis question is the fact that the javac compiler, and presumably others, is not entirely consistent \nwith the speci.cation, especially in areas where the speci.\u00adcation is incorrect. So it s not clear exactly \nwhich language any changes should seek to be backwards-compatible with. We believe backwards-compatibility \nconcerns can be mitigated in two ways. First, a new source-language com\u00adpiler .ag can be introduced, \nas was done in Java 1.4 when the assert keyword was added to the language. Second, a source-to-source \ntool can be developed that implements both the old and new inference algorithms, and inserts casts or \nexplicit type arguments as necessary wherever the two con.ict. In fact, because most programmers do not \nheav\u00adily exercise the language s generic features, it s quite likely problems would be rare enough that \nthis diagnostic tool need not make any .le modi.cations it could simply identify a handful of problem \nsites and leave programmers to manually .x them. Two properties of the algorithm speci.ed in this paper \nsoften the impact of the language change, minimizing the number of correct programs that would be rendered \nincorrect by the new system: Because type argument inference is de.ned in terms of the expected type \nE, changes to inference will rarely be problematic in contexts in which E is known (this includes assignments \nand return statements).  Where inference produces a different result than the Java 5 algorithm, the \nnew result is usually more speci.c; in practice, this often safe, since type variables in method return \ntypes are frequently not nested.  5. Historical Evolution and Related Work Algorithms for local type \nargument inference in languages with subtyping and bounded quanti.cation was .rst ex\u00adplored by Cardelli \n[2] and later Pierce and Turner [9; 8]. Pierce and Turner noted the dif.culty of performing infer\u00adence \nfor type parameters with interdependent bounds [8]. Type variables, parameterized types, and type argument \ninference in Java 5 were incorporated from the GJ language [1], an extension to Java designed to support \ngeneric pro\u00adgramming. The original speci.cation for GJ describes most of the features of Java 5, with \nthe exception of wildcards and intersection types. Wildcards arose out of research to extend GJ and sim\u00adilar \nlanguages with covariant and contravariant subtyping. Thorup and Torgersen [11] initially proposed what \nhas be\u00adcome known as use-site covariance allowing programmers to specify when a parameterized type is \ninstantiated that a particular type parameter should be covariant. Igarashi and Viroli [5] extended this \nnotion to include contravariance and established a connection to bounded existential types. Their work \nrequires support for lower bounds on type variables, though these bounds are not expressible in type \nvariable dec\u00adlarations. A joint project between the University of Aarhus and Sun Microsystems [12] extended \nthese ideas and merged them with the rest of the Java language, describing in partic\u00adular how wildcards \naffect type operations like type argument inference. Wildcard capture was .rst presented in a paper summarizing \nthis project. The 3rd edition of the Java Language Speci.cation [3] enhanced this prior work in a number \nof ways. Wildcard cap\u00adture was re.ned to produce variables whose bounds include both those of the wildcard \nand those of the corresponding type parameter. This enhancement produces a more useful capture variable, \nand may have been deemed necessary in order to guarantee that types produced by capture are well\u00adformed \n(that is, the capture variable is within the declared parameter s bound). It has a number of interesting \nside ef\u00adfects: .rst, intersection types are required to express the bound of some capture variables; \nsecond, a capture variable may have both an upper and a lower bound; and third, a cap\u00adture variable may \nappear in its own upper bound. Perhaps spurred by the requirement for intersections produced by capture, \nthe language was also extended to allow intersection types as the bounds of declared type variables. \nIn addition, the join operation (known as lub in the JLS) was de.ned to produce recursive types, an approach \nthat was avoided in the Aarhus Sun paper due to its complexity [12]. Torgersen, Ernst, and Hansen [13] \ncomplemented the speci.cation with a formal discussion of wildcards as im\u00adplemented in Java, and presented \na core calculus extending Featherweight GJ [4] with wildcards. Their calculus, for the sake of generality, \nallows arbitrary combinations of upper and lower bounds on both declared type variables and wild\u00adcards. \nThe paper, however, does not discuss how such gener\u00adality might affect the full Java language, and type \nargument inference in particular; nor does it prove important prop\u00aderties of the calculus, such as type \nsoundness or subtyping decidability. In fact, Kennedy and Pierce [7] have demonstrated the undecidability \nof subtyping algorithms (and, by extension, subtype inference algorithms) for some object-oriented type \nsystems that, like Java 5, contain contravariance. Their work is inconclusive on the question of whether \nJava 5 subtyp\u00ading is decidable, but raises the possibility that it is not. A problem arises when recursive \ninvocations of a subtyping al\u00adgorithm are parameterized by increasingly larger types. For\u00adtunately, Kennedy \nand Pierce s work suggests a straightfor\u00adward solution that can guarantee decidability in their simpli\u00ad.ed \ncalculus: the class hierarchy must not exhibit a property termed expansive inheritance. Class declarations \nof this kind can be readily detected, and seem to serve no practical use, so it is reasonable to prohibit \nthem. We follow this strategy here; while their decidability results are not proven to extend to the \nfull Java language, it seems likely that they will. Finally, this paper makes use of union types as a \ncomple\u00adment to intersections. These are explored in the context of object-oriented languages by Igarashi \nand Nagira [6]. While we do not argue here for .rst-class support for such types in the language doing \nso would con.ict with our goal of minimizing language changes we do allow type analysis to produce them, \nand Igarashi and Nagira s argument for full language support is worthy of consideration. Their work also \nsuggests how the members .elds, methods, and nested classes of union types might be determined, a topic \nwhich we do not explore here.25 6. Conclusion We have highlighted a number of bugs and limitations in \nthe Java 5 type inference algorithm, and presented an improved version of the algorithm. The improved \nalgorithm is sound, 25 Igarashi and Nagira interpret union types in a manner reminiscent of structural \nsubtyping: the union contains a certain method if a method with that name is declared in each union element. \nIf preferred, however, a more nominal approach could easily be developed. and is able to produce correct \nresults in a variety of cases in which the Java 5 algorithm falls short. It also minimizes the assumptions \nmade by the algorithm, thus making possible extensions to the language like .rst-class intersection types \nand lower-bounded type variables. The discussion of backwards compatibility in Section 4 addresses how \nchanges to the language might be put into practice. Given the number of .aws in the current speci.ca\u00adtion, \nan update to the inference algorithm seems inevitable, and that update will almost certainly violate \nbackwards com\u00adpatibility. Thus, addressing these bugs offers a good oppor\u00adtunity to make higher-level \ndecisions about the inference al\u00adgorithm, determining whether some non-essential improve\u00adments might \nalso be made. It would be useful to guide decisions about changes to the inference algorithm with an \nexperimental study of their practical impact. An analysis tool might demonstrate, for example, that nearly \nall legacy Java programs would not be adversely affected by backwards compatibility problems under the \nimproved algorithm proposed here. The problems encountered when handling recursively\u00adbounded type parameters \nprovide another opportunity for future work. If a universal solution can be developed, it will be possible \nto create a locally-complete type argument inference algorithm. The type system described in this paper \nhas been im\u00adplemented as a component of the DrJava IDE s interactive interpreter [14]. This updated interpreter \nprovides a useful demonstration of the improved inference algorithm. A. Code Samples   A.1 javac Inference \nFailure with Wildcards // This compiles in javac (1.5 &#38; 1.6) without war\u00ad// ning but throws a ClassCastException \nat runtime. <T> List<? super T> id(List<? super T> arg) { return arg; } void test() { List<Float> ln \n= new LinkedList<Float>(); List<?> l = ln; List<? super String> ls = id(l); ls.add(\"hi\"); Float f = ln.get(0); \n} A.2 First-class Intersections // For brevity, Comparable is abbreviated Cm public class SafeTreeSet<T> \n{ private TreeSet<T &#38; Cm<? super T>> set; public SafeTreeSet() { set = new TreeSet<T &#38; Cm<? super \nT>>(); } public void add(T &#38; Cm<? super T> elt) { set.add(elt); } public void addAll(Iterable<? extends \nT &#38; Cm<? super T>> elts) { for (T &#38; Cm<? super T> elt : elts) { set.add(elt); } } public Iterator<? \nextends T> iterator() { return colls.iterator(); } } A.3 Inference with Recursive Bounds interface \nRecurBox<T extends RecurBox<T>> { T get(); void set(T val); } interface Foo extends RecurBox<Foo> { } \n // inherited: Foo get(); } interface Bar extends Foo, Cloneable { // inherited: Foo get(); } <S extends \nRecurBox<S>, T extends S &#38; Cloneable> S unwrap(T arg) { return arg.get(); } int typeToVal(Object \no) { return 0; } int typeToVal(Foo f) { return 1; } int typeToVal(Bar b) { return 2; } void test(Bar \nb) { // For unwrap(b), S and T must satisfy: // T <: S <: RecurBox<S> // Bar <: T <: S &#38; Cloneable \nassert typeToVal(unwrap(b)) == 1; } A.4 Existential Open with a Lower Bound // Library code: interface \nProcessor<T> { /** Do some processing; true if successful. */ boolean process(T arg); } interface ProcQueue<T> \nextends Queue<Processor<T>> { } // Application code: /** Pass each of vals to a Processor in the queue; \n * if processing a value is successful, increment * it. After all processing is complete, enqueue * \nthe successful processors. */ static void runInts(ProcQueue<? super Integer> q, int[] vals) {  return \nrunIntsHelper(q, vals); } static <T super Integer> void runIntsHelper(ProcQueue<T> q, int[] vs) { List<Processor<T>> \nkeep = new LinkedList<Processor<T>>(); for (int i = 0; i < vs.length; i++) { Processor<T> p = queue.remove(); \nif (p.process(vs[i])) { keep.add(p); vs[i]++; } } queue.addAll(successful); } References [1] Gilad Bracha, \nMartin Odersky, David Stoutamire, &#38; Philip Wadler. Making the Future Safe for the Past: Adding Gener\u00adicity \nto the Java Programming Language. OOPSLA, 1998. [2] Luca Cardelli. An Implementation of F<:. Research \nreport 97, DEC Systems Research Center, 1993. [3] James Gosling, Bill Joy, Guy Steele, &#38; Gilad Bracha. \nThe Java Language Speci.cation, Third Edition. 2005. [4] Atshushi Igarashi, Benjamin Pierce, &#38; Philip \nWadler. Feath\u00aderweight Java: A Minimal Core Calculus for Java and GJ. OOPSLA, 1999. [5] Atsushi Igarashi \n&#38; Mirko Viroli. On Variance-Based Subtyp\u00ading for Parameteric Types. ECOOP, 2002. [6] Atsushi Igarashi \n&#38; Hideshi Nagira. Union Types for Object-Oriented Programming. Journal of Object Technology, vol. \n6, no. 2, February 2007. [7] Andrew J. Kennedy &#38; Benjamin C. Pierce. On Decidability of Nominal Subtyping \nwith Variance. FOOL/WOOD, 2007. [8] Benjamin C. Pierce &#38; David N. Turner. Local Type Argu\u00adment Synthesis \nwith Bounded Quanti.cation. Technical report TR495, Indiana University, 1997. [9] Benjamin C. Pierce \n&#38; David N. Turner. Local Type Inference. POPL, 1998. [10] Daniel Smith. Completing the Java Type \nSystem. Master s thesis, Rice University, 2007. [11] Kresten Krab Thorup &#38; Mads Torgersen. Unifying \nGeneric\u00adity: Combining the Bene.ts of Virtual Types and Parameter\u00adized Classes. Lecture Notes in Computer \nScience, 1999. [12] Mads Torgersen, Christian Plesner Hansen, Erik Ernst, Peter von der Ah\u00b4 e, Gilad \nBracha, &#38; Neal Gafter. Adding Wildcards to the Java Programming Language. SAC, 2004. [13] Mads Torgersen, \nErik Ernst, &#38; Christian Plesner Hansen. Wild FJ. FOOL, 2005. [14] DrJava IDE. http://drjava.org. \n[15] Java Community Process. http://jcp.org. [16] Type variables should have lower/super bounds. Java \nRequest for Enhancement. http://bugs.sun.com/view_ bug.do?bug_id=5052956. [17] Please introduce a name \nfor the null type. Java Request for Enhancement. http://bugs.sun.com/view_bug.do? bug_id=5060259. [18] \nMultiply-bounded reference type expressions. Java Request for Enhancement. http://bugs.sun.com/view_bug.do? \nbug_id=6350706.  \n\t\t\t", "proc_id": "1449764", "abstract": "<p>Java 5, the most recent major update to the Java Programming Language, introduced a number of sophisticated features, including a major extension to the type system. While the technical details of these new features are complex, much of this complexity is hidden from the typical Java developer by an ambitious type inference mechanism. Unfortunately, the extensions to the Java 5 type system were so novel that their technical details had not yet been thoroughly investigated in the research literature. As a result, the Java 5 compiler includes a pragmatic but flawed type inference algorithm that is, by design, neither sound nor locally complete. The language specification points out that neither of these failures is catastrophic: the correctness of potentially-unsound results must be verified during type checking; and incompleteness can usually be worked around by manually providing the method type parameter bindings for a given call site.</p> <p>This paper dissects the type inference algorithm of Java 5 and proposes a signficant revision that is sound and able to calculate correct results where the Java 5 algorithm fails. The new algorithm is locally complete with the exception of a difficult corner case. Moreover, the new algorithm demonstrates that several arbitrary restrictions in the Java type system---most notably the ban on lower-bounded type parameter declarations and the limited expressibility of intersection types---are unnecessary. We hope that this work will spur the evolution of a more coherent, more comprehensive generic type system for Java.</p>", "authors": [{"name": "Daniel Smith", "author_profile_id": "81381597074", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1223235", "email_address": "", "orcid_id": ""}, {"name": "Robert Cartwright", "author_profile_id": "81406592800", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1223236", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449804", "year": "2008", "article_id": "1449804", "conference": "OOPSLA", "title": "Java type inference is broken: can we fix it?", "url": "http://dl.acm.org/citation.cfm?id=1449804"}