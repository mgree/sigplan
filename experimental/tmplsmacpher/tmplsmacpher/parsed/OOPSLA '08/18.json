{"article_publication_date": "10-19-2008", "fulltext": "\n Enabling Static Analysis for Partial Java Programs emyDagenais \u00b4el\u00b4Barth Laurie Hendren  ebec,Canada \n\u00b4eal,Qu\u00b4McGillUniversity,Montr [bart,hendren]@cs.mcgill.ca Abstract Software engineering tools often \ndeal with the source code of programs retrieved from the web or source code repos\u00aditories. Typically, \nthese tools only have access to a subset of a program s source code (one .le or a subset of .les) which \nmakes it dif.cult to build a complete and typed inter\u00admediate representation (IR). Indeed, for incomplete \nobject\u00adoriented programs, it is not always possible to completely disambiguate the syntactic constructs \nand to recover the de\u00adclared type of certain expressions because the declaration of many types and class \nmembers are not accessible. We present a framework that performs partial type infer\u00adence and uses heuristics \nto recover the declared type of ex\u00adpressions and resolve ambiguities in partial Java programs. Our framework \nproduces a complete and typed IR suitable for further static analysis. We have implemented this frame\u00adwork \nand used it in an empirical study on four large open source systems which shows that our system recovers \nmost declared types with a low error rate, even when only one class is accessible. Categories and Subject \nDescriptors D.3.4 [Programming Languages]: Processors General Terms Languages, Experimentation Keywords \nPartial Programs, Type Inference, Java 1. Introduction and Motivation Static program analysis is an important \ntool for software engineering research: techniques such as bug detection [5] and feature location [21] \nheavily depend on static analyses to model a program s behavior and structure. Compiler frameworks, with \nwhich many static analyses were developed, usually assume that the complete program is available (either \nas source code or as a high-level binaries Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. OOPSLA 08, October 19 23, 2008, Nashville, Tennessee, USA. Copyright \nc &#38;#169; 2008 ACM 978-1-60558-215-3/08/10. . . $5.00 such as Java .class .les), even if only part \nof that program is to be analyzed. When the complete program is available, it is straightforward for \nthe compiler to build a correct, typed, and complete intermediate representation (IR) for the part of \nthe program to be analyzed. However, some methodologies used by software engi\u00adneering techniques preclude \nthe access to complete pro\u00adgrams. Indeed, source code retrieved from software version\u00ading systems [8], \nweb repositories [19], or bug reports [7], is typically dif.cult to compile: source folders and libraries \nrequired to build a snippet of code may not be known or ac\u00adcessible, and the correct versions of those \ncode artifacts may be impossible to automatically determine (e.g., which ver\u00adsion of Log4J is needed \nto compile Foo.java 1.4?). The goal of this paper is to provide techniques that pro\u00adduce complete and \ntyped intermediate representations for the source code of partial Java programs, even when only part \nof the program is accessible. The unavailability of many class declarations leads to two main challenges: \n(1) dealing with syntactic ambiguities and (2) determining the correct types for expressions such as \n.eld accesses and method calls. Syntactic ambiguities arise when classes and members for other parts \nof the program are not available. For exam\u00adple, consider the statement E.dothat(). Without the dec\u00adlaration \nfor E, it is not possible to determine if E is a class or a .eld. If E is a missing class, it could be \na call to a static method dothat() which is a member of the missing class E. Otherwise, if E is a missing \n.eld, then this is a virtual method call, with receiver E. Typing problems arise when a compiler or tool \ndoes not have access to the complete type hierarchy and the signatures of .elds or methods in classes \nthat are directly or indirectly referenced by the program under analysis. A Java compiler usually creates \nan intermediate representation (IR) such as an abstract syntax tree, annotating the IR with the appropri\u00adate \ntypes, based on type declarations. For example, given the following complete Java code snippet, the compiler \nwould use the declaration of class A at line 1 to .nd that the de\u00adclared type of the expression a.p1 \nat line 9 is String. The compiler would also use the declaration of class A to .nd that the method called \nat line 10 is the method A.add(Object) declared at line 3. 1 2 class A {String p1; 3 4 5 void add(Object \no) {}} 6 7 8 class B {void main() {A a = new A(); 9 a.p1 = hello ; 10 a.add(a.p1); 11 12 }} Software \nengineering tools that operate on partial pro\u00ad grams may not have access to the complete program and \nall of its declared types. For example, assume that a tool had access only to the source code for class \nB (and not A). In this case, the tool cannot .nd the declared type of some expres\u00adsions in the incomplete \nprogram (e.g., what is the declared type of a.p1?). To deal with this problem, these tools often fall \nback to syntactic analysis, which provides limited infor\u00admation. For example, if only class B is available, \na syntactic analysis will conclude that a method named add with one parameter is called at line 10. This \nlack of precise type in\u00adformation is a problem for tools, like PARSEWeb [19] and SemDiff [8], that analyze \npartial programs to recommend to programmers method calls from arbitrary frameworks. These tools require \nthe types of the receiver and the formal parameters in order for their recommendations to be use\u00adful \n(e.g., telling the user to call a method named add is not helpful if many classes declare such method). \nPARSEWeb and SemDiff have thus begun to perform partial type infer\u00adence to get more information from \nthe source code of in\u00adcomplete programs. For example, if only the declaration of class B was accessible, \nthey would conclude that at line 10, the method A.add(String) is called by looking at the as\u00adsignment \nof .eld p1. This information, although not strictly correct (there is no method A.add(String), but there \nis a method A.add(Object)), is more precise than the one pro\u00advided by syntactic analysis. Software engineering \ntechniques usually tolerate a certain level of imprecision and errors, as measured by precision and recall, \nso they can bene.t from information that is often more precise, but potentially incorrect. Thus, in designing \nour approach we traded some guarantees on correctness for increased precision. This also implies that \nour approach is not suitable for situations where a sound analysis is required, such as in program optimization. \nIn this paper, we propose a technique, Partial Program Analysis (PPA), which builds a typed IR of incomplete \nJava programs source code. Our technique recovers the declared types by performing partial type inference \nand resolves syn\u00adtactic ambiguities inherent to incomplete programs using heuristics. Although it is \nimpossible to guarantee that the generated IR is correct with respect to the result one would get given \nthe complete program, we aim to generate an IR which: (1) obeys the type constraints available in the \npar\u00adtial program under analysis, (2) does not introduce unknown program constructs, and (3) is suitable \nfor use with other static analysis tools. We implemented this approach in a prototype using Soot, a static \nanalysis framework [20], and Polyglot [15], an ex\u00adtensible compiler framework. Currently, our prototype \ntrans\u00adforms Java source code from an incomplete program into a typed abstract syntax tree (AST) and into \nJimple, a typed three-address intermediate representation, because those representations are suitable \nfor most static analyses. We used an early version of the PPA prototype in SemDiff to analyze the evolution \nof method calls in code retrieved from software repositories and to recommend precise method invocation \nto adapt client programs that broke during framework evolu\u00adtion [8]. Our positive experiences with that \nproject gave us some con.dence that PPA will be useful for developing other software engineering analyses \nand tools.1 To validate to what extent our proposed PPA technique produces useful results, we performed \na quantitative study on four open source programs, three of them from the Da-Capo benchmark suite [18], \nfor three common scenarios. We found that even for the hardest scenario, when the source code of only \none class is available, partial program analysis could generate an intermediate representation that was \non average 91% identical to the intermediate representation of the same class analyzed with the whole \nprogram. The contributions of this paper include: (1) the PPA tech\u00adniques that allow us to analyze incomplete \nJava programs, and that deal with both syntactic ambiguities and typing problems, (2) the implementation \nof a tool based on PPA that produces an IR and AST representation of an incomplete program, and (3) an \nempirical evaluation of our approach. In the rest of this paper, we .rst introduce our problem and terminology \nin more detail in Section 2. We then de\u00adscribe our approach to solving the typing problems in Sec\u00adtion \n3 and the ambiguous syntax problems in Section 4. We put it all together in Section 5, where we describe \nour over\u00adall algorithm. We then report on the results of the empirical evaluation of our technique (Section \n6). Finally, we discuss the related work in Section 7 and conclude in Section 8. 2. Partial Object-Oriented \nPrograms We consider a partial program to be a subset of a program s source .les. This de.nition is suitable \nfor current software engineering tools that can get as input complete source .les and that require more \nprecise information than what syn\u00adtactic analysis can provide.2 In a source .le, we associate a type \nfact with all references to declared types. For exam\u00adple, there are six type facts associated with line \n6 in Fig\u00ad 1 The PPA implementation is available at http://www.sable.mcgill.ca/ppa. 2 This de.nition of \npartial programs could even be relaxed to include any snippet of well-formed code. Although our approach \ndoes not rely on a complete source .le, the parser implementation that we currently use does. 1 2 class \nD {int .eld1 ; 3 4 void main() {A varA = new A(); 5 String s = hello ; 6 .eld1 = m1(s); 7 varA. .eld3 \n= s; 8 varA. .eld3 = B. .eld3 ; 9 Object o = new String( hello ); 10 11 12 }short m1(Object o) {return \n0;}} Figure 1. A partial program ure 1: the declared type of .eld1 s container (D), the declared type \nof .eld1 (int), the declared return type of method m1 (short), the declared type of method m1 s target \n(D), the declared type of m1 s formal parameter (Object) and the declared type of m1 s actual parameter \n(String). To sim\u00adplify our presentation, we will use the term type to refer to a declared type (as opposed \nto a runtime type) in the remain\u00adder of this paper. For example, at line 9, the declared type of the \nvariable o is Object, but the type of this variable during runtime is String. Given a partial program, \nthe challenge is to recover as many correct type facts as possible without having access to the rest \nof the program, i.e., referenced source .les, binaries, or dependencies such as libraries. For example, \nby analyz\u00ading only class D, we can infer two type facts at line 7: (1) the type of the container holding \nfield3 is A or one of its ancestors and (2) the type of field3 is a String or one of its ancestors. Furthermore, \nwe know at line 7 that the type of varA is A because we have access to its declaration in method main. \nIn the remainder of this paper, we will use static .elds in our examples (e.g., B.field3 at line 8) in\u00adstead \nof instance .elds to reduce the size of the examples: our analysis considers each syntactically different \n.eld ac\u00adcess as a distinct .eld, even if they share the same name. For example, at line 8, PPA considers \nthat there are two distinct .elds field3: the .rst is attached to the local variable varA and the second \nis attached to the type B. In the text, we will also always refer to the .eld name without the quali.er \nwhen it is unambiguous. Having access to only a subset of the source .les forces us to make an important \nassumption when performing partial program analysis: Compilable Program Assumption: The source .les of \na partial program compile without any error given the re\u00adquired dependencies. This is a reasonable assumption \nfor code extracted from software versioning systems or web repositories because a popular convention \nis to only commit source .les if they compile. The absence of class declarations makes it impos\u00adsible \nto detect type-related errors such as calling a non\u00ad 1 class E { 2 void main() { 3 A. .eld1 = new B( \nhello ); 4 Collection coll = A. .eld2 ; 5 A..eld1 .m2().m3(); 6 } 7 } Figure 2. Inferring type facts \nexisting method so we cannot assess whether the code is compilable or not. The compilable program assumption \nis thus necessary to infer type facts: in potentially uncompil\u00adable source code, every inference made \non type usage could be wrong. In this paper, we will focus on Java 1.4 which does not include features \nsuch as generics and autoboxing, and we will also assume that the user has access to standard Java types, \ne.g., java.lang.Object, either in a binary or source format. Again, this is a reasonable assumption because \nthose classes are required to execute any Java program. 3. Recovering Types in Partial Programs When \nanalyzing a partial Java program, it is possible to infer type facts by looking at how a type is used \nin the program. For example, in Figure 2, we see that the program assigns an instance of class B to field1 \nat line 3. Because of the Java type system, we know that field1 must be B or one of its ancestors. We \nde.ne the operator dt(x) which returns the declared type t of the Java expression x. For example, at \nline 4, dt(coll) = Collection. We also de.ne the subtype op\u00aderators, t1 <: t2, which means that t1 is \na subtype of t2, i.e., it is either t2 or a descendant of t2. The supertype operator, t1:>t2, means that \nt1 is either t2 or an ancestor of t2. For the last two operators, we consider class extension and inter\u00adface \nimplementation and extension (through the extends and implements keywords) to be the only generators \nof subtypes and supertypes. We use the related type operator, t1 ~ t2 when we know that two types are \nrelated, i.e, one is a subtype of the other or they share a common ancestor or de\u00adscendant.3 Finally, \nwe de.ne the operator target(x) which returns the target s type t of a method x or the container s type \nof a .eld x. For example, target(field1) :> A. Be\u00adcause partial programs are imprecise, a type t can \nbe either precise (e.g., dt(coll) = Collection) or imprecise (e.g., dt(field1) :> B). When we try to \ninfer a type fact, it sometimes happens that we cannot recover any information at all. We de.ne the following \ndata structures to handle these cases: 3 In Java, because all reference types are a subtype of java.lang.Object, \nall reference types are related to each other. The related type operator can still be used to distinguish \nreference types from primitives as they are not related. The unknown type is used as a placeholder for \nany type that is referenced, but not explicitly named. For example, in the following call chain, m2().m3(), \nthe return type of the method m3 is unknown, which denotes either a Java primitive, a Java class or void. \nTo fully qualify any type which has an ambiguous Fully Quali.ed Name (FQN), we de.ne the package p-unknown. \nThis package is necessary to distinguish a type located in the default (empty) package from a type that \nis located in an unknown package. The fully quali.ed name of the unknown type is thus p-unknown.unknown \neven if for the sake of brevity, we will always use the short name unknown. Finally, we de.ne a type \nfact as being a record containing the following attributes: (1) a Java expression x (e.g., a reference \nto a .eld), (2) the type t of the expression before the inference, and (3) the type t of the expression \nafter the inference. For example, if we just found that the unknown .eld field1 was a supertype of class \nB, we would have inferred the following type fact: {field1, unknown, :> B}. 3.1 Type Inference Strategies \nTo infer type facts, we rely on several strategies based on the Java programming language type system. \nThese inference strategies are sound in the sense that the real declared types will always respect the \nconstraints of the inferred type facts. For example, if a strategy infers that the type of an expres\u00adsion \nis a subtype of java.util.List, the real type is guar\u00adanteed to have this property. Although the inference \nstrate\u00adgies can generate imprecise type facts such as {field1, unknown, <: java.lang.Object}, we found \nduring our evaluation that they generally recover the real type. Table 1 shows the intuition behind the \ninference strategies that we devised. The formal inference rules for each of those strategies are presented \nin Appendix A. 3.2 Inferring Method Bindings When an expression s type has been inferred (e.g., using \none of our inference strategies), it is sometimes possible to determine a method binding that is ambiguous \nfrom a purely syntactic point of view. Consider the call to method m1 at line 4 in Figure 3. Because \nthere are two declarations of a method m1 with one parameter, it is not possible to decide which method \nis called when looking only at the syntax of the program. On the other hand, if we perform some type \ninference, we know that dt(field1) :> B at line 3, and thus, we are certain that we call the method m1(B) \ndeclared at line 10. Once we know the exact method binding, we can then use our method binding inference \nstrategy. Unfortunately, there are cases like line 5 where we cannot identify the correct method binding \nbecause the method is overloaded and the declared type of the parameter is unknown. A class can also \npotentially overload a method declared in a supertype. For example, in class H, we cannot soundly infer \nthat the method called at line 17 is the one declared at line 20. Indeed, we know from line 16 that dt(field3) \n:> 1 class G { 2 void main() { 3 A. .eld1 = new B(); 4 A. .eld4 = m1(A..eld1 ); 5 A. .eld5 = m1(A..eld2 \n); 6 B.m2(2); 7 B.m2(A..eld2 ); 8 } 9 10 Dm1(Bb) { ... } 11 Em1(int i) { ... } 12 } 13 14 class H extends \nI { 15 void main() { 16 A. .eld3 = new C(); 17 m1(A..eld3 ); 18 } 19 20 void m1(C c) { ... } 21 } Figure \n3. Method binding C. Suppose that dt(field3) = Object (which respects the type fact we inferred) and \nthat the supertype of I de.nes a method m1(Object). It follows that the method called at line 17, is \nI.m1(Object) and not H.m1(C). Determining a method binding is thus an undecidable problem because of \noverloaded methods.  3.3 Inferring Type Members Until now, we focused on inferring the type of an expres\u00adsion, \nbut, at the same time, we need to infer the existence and types of members (i.e., .elds and methods). \nFor example, in Figure 3, we inferred at line 3 that there is a .eld named field1 that is declared in \nthe type A or one of its super\u00adtypes. When analyzing a complete program, we could check whether these \nmembers exist and are accessible. Because we only have access to class G, we must rely on our assumption \nthat the underlying code compiles and that both members are accessible from the context of the calling \nmethod G.main. More speci.cally, when PPA encounters a reference to a type whose declaration is not available, \nit creates an internal representation of the type. If a member is accessed from this type, we add the \nmember to the generated type declaration. For example, at line 3 in Figure 3, PPA would generate the \nfact that class A has a .eld called field1 whose type is :> B. In adding missing members, .elds and methods \nare treated differently. Since .elds cannot be overloaded, we only generate a missing .eld once and reuse \nthis one if an\u00adother occurrence of the same .eld occurs. However, since methods can be overloaded, generated \nmethods cannot be reused like generated .elds. For example, at line 6, we can infer that there is a method \ncalled m2 that is in one of the Inference Strategy Example Explanation Assignment Return Method binding \nCondition Binary and unary operators Array Switch Conditional B. .eld1 = Hello World ; C c = B. .eld2 \n; int m1() {return B.method2(); } void main() { B. .eld3 = me(B..eld4 ); } D m3(E p1) {...} if (B.method4()) \n{... } int i = B. .eld7 - 10; B. .eld10 = B. .eld8 [B. .eld9 ]; switch(B. .eld11 ) {... } B..eld14 \n= B..eld12 ? c : B..eld13 ; int i = B..eld12 ? c : B..eld16 ; The type of an unknown expression on the \nright-hand side is the sub\u00adtype of a known left-hand side expression s type and vice-versa, e.g., {field1, \nunknown, :> java.lang.String} and {field2, unknown, <: C}. The type of an unknown return expression is \nthe subtype of the method s declared return type, e.g., {method2,unknown, <: int}. If we know the exact \nmethod binding, the types of the actual parameters are subtypes of the formal parameters types, and the \nexpression to which the method is assigned to is a supertype of the method s return type, e.g., {field3, \nunknown, :> D} and {field4, unknown, <: E}. An expression used as a condition must resolve to a boolean, \ne.g., {method4, unknown, boolean}. Depending on the operands types and the expected return type of a \nbinary or unary expression, it might be possible to infer the primitive type of an expression by taking \ninto account implicit type promotion, e.g., {field7, unknown, <: int}. When an unknown expression is \nused as an array index, we can infer that it is a subtype of int. For example, at line 14, we can infer \nthat {field9, unknown, <: int}. When an unknown expression is accessed using an array index, we can infer \nthat the type of the expression is an array, e.g., {field8, unknown, unknown[]}. Switch expressions enable \nus to infer that the operand is a subtype of the int primitive, e.g., {field11, unknown, <: int}. Conditional \nexpressions, represented by the ternary operator ? can be used in two fashions. First, if their return \ntype is not know, we can at least infer that the two last operands type must be related, e.g., {field13, \nunknown, ~ char}. Indeed, if dt(field14) = long, field13 s type can be either a subtype or a supertype \nof char: we can thus only say that the two types are related. When the return type is known, we know \nthat the last two operands must be a subtype of the return type, e.g., {field16, unknown, <: int}. Table \n1. Type Inference Strategies supertypes of B and that takes as a parameter a supertype of int. At line \n7, we cannot safely reuse this fact to infer the type of the actual parameter field2 because there might \nbe another method called m2 with a different parameter type. We thus infer that there is a method called \nm2 that takes a parameter of type unknown. Finally, inferred type members can be re.ned by type inference. \nFor example, if we later .nd that dt(field2) <: C, we will add a method m2(C) to B.  3.4 Combining Type \nInference Sometimes, we can infer two type facts related to the same expression. For example, in Figure \n4, at lines 3 and 4, we in\u00adfer that dt(field3) <: Object and dt(field3) <: String. By de.nition of a \nsubtype, it is clear that dt(field3) <: String because String <: Object. We say that the two inferred \ntype facts are converging and we only keep the most precise type fact (<: String). On the other hand, \nthe type facts that we infer at lines 5 and 6 are erroneous: dt(field4) :> Object and dt(field4) <: String \ncannot be true at the same time. Erroneous type facts contradict our compi\u00adlable program assumption, \nbut this is one of the few cases where we can detect and report a compilation error. Finally, the two \nlast type facts at lines 7 and 8, dt(field5) <: B and dt(field5) <: C, are con.icting: it is not possible \nto decide which of the two type facts is the most precise because three type hierarchies can explain \nthe code of lines 7 and 84: 1. B <: C, so dt(field5) <: B 2. C <: B, so dt(field5) <: C  3. There exists \na type P which is a common descendant of B and C (either B or C must be an interface). In that case, \nneither type fact is more precise. In the case of the third possibility, even if we knew the whole type \nhierarchy of B and C, it would still be impossible to determine the type of field5 because there might \nbe more than one common descendant P. 4 The converse is also true if we have the two following type facts: \ndt(field5) :> B and dt(field5) :> C. 1 class F { 2 void main() { 3 Object o1 = A. .eld3 ; 4 String s1 \n= A. .eld3 ; 5 A. .eld4 = new Object (); 6 String s2 = A. .eld4 ; 7 B b = A..eld5 ; 8 C c = A..eld5 ; \n9 }  10 } Figure 4. Combining type facts 1 class Y { 2 int m1() { 3 Aa1=Z..eld1; 4 Z. .eld1 = Z. .eld2 \n; 5 Aa2=Z..eld3; 6 Z. .eld4 = Z. .eld3 ; 7 } 8 } Figure 5. Con.icting type direction When we encounter \ntwo con.icting type facts, we .rst try to select the safest one, where we determine that a type fact \nis safer than another using the total ordering: unknown < missing < super missing < full. Each member \nof this ordering is de.ned as follows: If the type of a fact is unknown, it is less safe than a fact \nwhose type is known but whose declaration is missing (e.g., we know that dt(x) = B, but we do not have \naccess to the declaration of B). A known type with a missing declaration is less safe than a known type \nwhose declaration is accessible but not all of its supertypes (e.g., we have access to the declaration \nof B, but one of its supertype s declaration is missing). Finally, the safest type, full, means that \nwe have access to its declaration and the declaration of all of its supertypes. If the two type facts \nare equally safe, we keep the .rst type fact that we inferred. The rationale behind this scheme is that \nwe only keep types that allow us to work with safer (i.e., known) types, which is generally more precise \nthan just keeping the .rst inferred type fact and ignoring further type facts. Another alternative strategy \nwould be to treat all related type facts as constraints and try to solve the constraints to obtain the \nmost precise type fact. However, during our early experimentation with PPA, we observed that we generally \nproduced either one type fact or multiple con.icting type facts (e.g., field5 in Figure 4), which forced \nus to make an arbitrary choice. Therefore, we had no reason to think that a more complex type combination \nscheme involving constraint solving would produce more accurate results. Finally, when combining type \nfacts, the direction of the types, whether they are subtypes or supertypes, might con\u00ad 1 package ca.mcgill \n; 2 3 import ppa.*; 4 import java . util .*; 5 import soot .Unit; 6 7 class A { 8 void main() { 9 C c \n= B.getC (); 10 Collection coll = B. getCollection (); 11 coll.doThis(); 12 Unit u = B.getUnit (); 13 \nppa. internal .D d = B.getD(); 14 } 15 } Figure 6. Ambiguous fully quali.ed name .ict. In Figure 5, \nwe can produce this inference chain at lines 3 and 4: dt(field2) <: dt(field1) <: A. It is thus clear \nthat dt(field2) <: A by transitivity. On the other hand, the di\u00adrections of the types at lines 5 and \n6 con.ict: dt(field4) :> dt(field3) <: A. We can thus only say that dt(field4) ~ A or in other words, \nthat there is a path in the type hierarchy 5 that links field4 with A. 4. Ambiguous Syntax in Partial \nPrograms The programming language syntax is a source of impreci\u00adsion: Table 2 shows the main constructs \nthat are ambiguous in partial Java programs. When we encounter such ambiguous syntax constructs, we can \neither (1) create an unknown node in the AST rep\u00adresentation, or (2) use an heuristic that guesses the \nreal con\u00adstruct. The .rst strategy is sound, in the sense that it doesn t introduce a potentially wrong \nconstruct. However, it poten\u00adtially introduces many unknown parts of the code, losing useful parts of \nthe program. Furthermore, it breaks the com\u00adpatibility with client tools, which assume only valid Java \nconstructs. We thus relied on the use of heuristics that can produce wrong, but potentially more precise \nresults. Fully Quali.ed Name. When we encounter a reference to a simple type name (e.g., String), we \nuse the following heuristic to .nd the FQN of the ambiguous type: 1. If the ambiguous type is fully quali.ed, \nwe use that FQN (e.g., ppa.internal.D in Figure 6). 2. If there is an explicit import statement that \nends with the ambiguous type name, we use the FQN speci.ed in the import statement (e.g., soot.Unit in \nFigure 6).  5 Unfortunately, in Java, this is true for any two given reference types because every type \nis a subtype of Object so there is always a path from one type to another type that passes by Object. \nIn a language like C++ which does not have this concept of a universal supertype, related types would \nhave a more precise meaning. Syntax ambiguity Example Explanation Fully Quali.ed Name (FQN) Figure 6 \nThe FQN of a type cannot always be soundly inferred in a partial program because a programmer can use \nthe import * construct. For example, at line 9 in Figure 6, the FQN of C can either be: C (in the default \npackage), ca.mcgill.C (in the package of A), or ppa.C (because of import ppa.* ). Additionally, we cannot \nsoundly infer the FQN of a type contained in a known package (e.g., java.util). For example, at line \n10, the Collection type might be contained either in java.util or in ca.mcgill. Line 11 gives a hint \nthat the latter FQN is the good one since the java.util.Collection type does not declare the method doThis. \n Package or Class? Line 13 in Figure 6 It is not always possible to discriminate the part in the FQN \nthat relates to a type from the part that relates to the package. For example, at line 13, variable d \nmight be of type D or of type internal.D (an internal class). Field or Class? class B extends C {void \nmain() {E.doThat (); E = new F(); }} An expression such as E in the .rst line of the main method can \nbe ei\u00adther a .eld or a class. In the former case, we infer that target(doThat) = unknown and in the latter \ncase, we infer that target(doThat) :> E. It is sometimes possible to resolve this ambiguity by looking \nat other lines of code (such as the assignment) that provide hint that the expres\u00adsion is a .eld. This \nor Container? class G extends H {public void main() {I i = new I() {public void m1() {f1 = 2; It is not \nalways possible to soundly infer the container of a particular member in an internal class because a \nreference to this or to the container of an internal class is implicit in Java. For example, it is not \nclear whether target(f1) :> I or if target(f1) :> H. ... Overloaded operators class J extends K {void \nmain() {int i = 2 - f2; String s = Hello +(f3+2)+ World ; }} Some operators are overloaded by the Java \nlanguage. For example, it is not clear whether the + operator is the addition operator or the String \nconcatenation operator in the main method. In the latter case, because a String can be concatenated with \nan arbitrary type instance or a primitive, it is still not possible to soundly infer the type of the \n.eld f3. Table 2. Ambiguous syntax constructs in Java 3. If we have access to the packages imported \nusing a wild\u00adcard import statement (e.g., import java.util.*) and we .nd a type whose name is the same \nas the ambiguous type name, we use that FQN (e.g., java.util.Collection in Figure 6). If later on we \nrealize that this type is not ad\u00adequate (e.g., we are calling a method that is not declared in this type), \nwe rely on the last two heuristics to deter\u00admine its FQN. 4. If there is no wildcard import statement, \nwe append the name of the ambiguous type to the package of the ana\u00adlyzed type (e.g., ca.mgill.C). 5. \nIf there is at least one wildcard import statement, we append the name of the ambiguous type to the unknown \npackage (e.g., p-unknown.C in Figure 6).  Rules #3 and #4 can lead to wrong fully quali.ed names because \nthe type might be declared in the default package. We expect most programs to avoid de.ning types in \nthe default package because this practice is discouraged and often impractical. Package or Class? We \nalways consider the last part of a fully quali.ed name (after the last dot) to be the simple name of \nthe type and the rest of the FQN to be the package. This can be a false assumption if the FQN refers \nto an internal type. A false assumption has no impact on the FQN (it is the same no matter if the type \nis internal) but it changes the type of node in the AST representation. Thus, if at a later point we \n.nd that the initialization can only refer to an internal type, we modify its AST representation. Another \nstrategy would be to use the Java naming con\u00advention (a type name and a package name should respec\u00adtively \nstart with an uppercase and lowercase character) to determine which part of the FQN is the package and \nwhich part is the type. We would still need to tune this heuristic on a per project basis. Field or Class? \nWe consider any ambiguous reference (e.g., E.doThat()) to be a static method call from a class. If we \n.nd a hint contradicting that assumption (such as the instantiation of the ambiguous reference), we change \nthe AST node accordingly. Like the previous heuristic, we could also use the Java naming convention. \nThis or Container? Most of the time, an ambiguous ref\u00aderence to this or to the container of internal \ntypes is im\u00adpossible to resolve. We thus chose to always replace such ambiguous references by a reference \nto this. Overloaded operators. When we encounter an overloaded operator such as + or &#38;, we always \nconsider that the type of the operands is unknown. We use the binary operator inference strategy to decide \nthe type of the operands when it is possible. 5. PPA Algorithm Figure 7 shows an overview of the algorithm \nwhich consists of three passes. Although the general techniques introduced in this paper could be used \nin other systems, we implemented our approach using Polyglot [15] and Soot [20]. Polyglot is an extensible \ncompiler that creates an AST representation of a source .le by applying various passes such as disam\u00adbiguation, \ntype checking and exception checking. Soot uses Polyglot as a frontend to parse Java source .les and \nthen transforms the AST into a three-address intermediate repre\u00adsentation called Jimple that can be used \nto perform data .ow analysis. Our algorithm mainly extends Polyglot and works at the AST level. We .rst \nreview the three main passes of the algorithm and then discuss the different modes in which the algorithm \ncan be executed, its termination property, and its time complexity. Seed pass. The seed pass is performed \nwhile Polyglot builds the AST of a source .le. First, Polyglot tries to disambiguate each AST node (e.g., \nit determines if the expression is a .eld reference, a method call, a local variable reference, etc.). \nWe modi.ed Polyglot so it infers the missing type members as described in Section 3.3 and uses the heuristics \ndescribed in Section 4 to resolve ambiguous syntax constructs. Once the AST nodes are disambiguated, \nPPA visits each node and applies the inference strategy (presented in Ap\u00adpendix A) that corresponds to \nthe type of the visited AST node. For example, at line 4 in Figure 8, PPA can use the as\u00adsignment inference \nstrategy to infer the following type fact: {field1, unknown, <: A}. We visit each node of the AST in \npost.x order because the type of the parent node is often determined by the chil\u00addren s types. During \nthe visit, we generate type facts and append them to a worklist. When two type facts refer to the same \nexpression (e.g., we can infer two type facts at line 4 and 6 that are related to the .eld Z.field1), \nwe merge them according to the combination strategy we presented in Section 3.4. During the seed pass, \nwe only infer type facts and the unknown type is assigned to all unknown expressions. If a complete and \ncorrect program was available, there would be no unknown types at this point. However, partial programs \noften have some unknown types after the seed pass. For example, in Figure 8, dt(field1) = unknown. Type \ninference pass. Once the AST is built, we can use the type facts that we inferred to modify the nodes \nof the AST (called Make node safer in Figure 7). When modifying the type of a node, we keep the complete \ntype fact in memory, but we can only assign a simple type to a node to simplify the usage of the AST. \nFor example, if we have the following type fact, {field1, unknown, <: A}, we modify the declared type \nof the .eld nodes at lines 4, 5, 6, and 8 to be equal to A. Finally, when we modify a node, it is possible \nthat we can infer a new type fact. For example, at line 5, when we modify the assignment node, we can \ninfer that {field2, unknown, <: A} using the assignment inference strategy. The inferred type facts are \nappended and merged into the worklist. Method binding pass. When we build the AST and infer type facts, \nwe can encounter ambiguous method calls. For example, at line 9, we do not know which println method \nis called: it is an overloaded method. During the seed pass and type inference pass, we only select a \nmethod binding if there is no ambiguity to make sure that we do not introduce potentially erroneous or \ncon.icting type facts. The method binding pass basically forces the compiler to select the .rst possible \ndeclaration of method calls that remain ambiguous. Once the declaration is selected, this enables the \ninference of new type facts that are appended and merged into the worklist. The worklist is then processed \nlike in the type inference pass. For example, if we executed this pass on the program listed in Figure \n8, we would .nd that two method calls remain ambiguous: the call to println at line 9 and the call to \nm2 at line 10 (because Y extends X, the call might refer to a method declared in X). By forcing the selection \nof a method declaration, we would conclude that the method println(boolean) is called at line 9 and m2(C) \nat line 10, which would lead to the inference of the two following type facts: {field4, unknown, boolean}and \n{field5, unknown, <: C}. Results. Once the three passes are completed, PPA produces a typed abstract \nsyntax tree. Each node in the AST contains three kinds of information: (1) a type, (2) whether the decla\u00adration \nof the type is available (i.e., the source is accessible) or was generated by PPA, and (3) whether the \ntype is un\u00adsound. A type can be unsound if it was inferred using one of our syntax heuristics or in the \ncase of Java, if it was inferred through the related type operator (~). As seen in Section 3.4, types \ncan be also be obtained from an inference chain: if one of the type in the chain is unsound, the rest \nof the chain is also considered to be unsound. Finally, the Soot framework translates the abstract syntax \ntree into a typed three-address intermediate representation. Modes of execution. There are three main \nparameters that can be adjusted when using PPA. The .rst parameter concerns the input of the analysis. \nDe\u00adpending on the availability of source .les, PPA can be per\u00adformed on one Java source .le at a time \nor on a set of source .les. In the latter case, the worklist containing the inferred type facts is shared \namong all source .les and the type infer\u00adence and the method binding passes are only executed once the \nseed pass has been performed on each source .le. This enables the sharing of inferred type facts which \ncan lead to more precise inference, but it can also propagate imprecise type facts (see Appendix B for \nan example). The second parameter allows the user to disable type inference, effectively preventing the \nexecution of the type inference and the method binding pass. When type infer\u00ad // Seed pass for each node \nin AST do Disambiguate node Infer type facts Put and merge type facts into worklist end for // Type \ninference pass while worklist is not empty do for each node impacted by type fact do Make node safer \nInfer type facts Put and merge type facts into worklist end for end while // Method binding pass for \neach ambiguous method call do Select the .rst possible call binding Infer type facts Put and merge type \nfacts into worklist end for while worklist is not empty do for each node impacted by type fact do Make \nnode safer Infer type facts Put and merge type facts into worklist end for end while Figure 7. Partial \nprogram analysis algorithm 1 class Y extends X { 2 int m1() { 3 System.out. println (Z. .eld1 ); 4 Aa1=Z..eld1; \n5 Z. .eld1 = Z. .eld2 ; 6 Bb1=Z..eld1; 7 Z. .eld2 = Z. .eld3 ; 8 A.m1(Z..eld1 ); 9 System.out. println \n(Z. .eld4 );  10 m2(Z..eld5 ); 11 } 12 13 void m2(C param1) {...} 14 } Figure 8. Sample program ence \nis disabled, all unknown expressions are assigned to the unknown type. PPA still performs type member \ninfer\u00adence and uses our heuristics to resolve ambiguous syntax constructs because those are needed to \nbuild the AST. Finally, the third parameter enables the user to disable the method binding pass, preventing \nthe selection of arbitrary method bindings. In Section 6 we use these parameters to examine the effectiveness \nof our approach in different scenarios and to measure the added bene.ts of enabling the type inference \nand method binding passes. Termination. Our algorithm is ensured to always terminate. First, the number \nof AST nodes and type facts in a given program is .nite, so the .rst pass is always sure to complete. \nThe second pass also always completes because the number of times a type fact related to a particular \nexpression can be inferred is .nite. As explained in Section 3.4, we only infer a new type fact related \nto an expression if (1) it converges or (2) it con.icts with a previous type fact and is safer than a \nprevious type fact. The number of converging type facts that we can infer on an expression is bounded \nby the depth of the type hierarchy and the number of con.icting type facts that we can infer on a particular \nexpression is bounded by 4 (from unknown to full). Finally, in the third pass, we select the binding \nof ambiguous method calls, which has a .nite number. Complexity. To analyze the time complexity of our \nalgo\u00adrithm, we consider each pass individually. The complexity of the algorithm is bounded by n, the \nnumber of AST nodes in all source .les, fa, the number of type facts in all source .les, r, the maximum \nnumber of nodes referring to a type fact in all source .les, fn, the maximum number of type facts that \ncan be inferred on a node (typically the maxi\u00admum number of parameters in a method call), m, the max\u00adimum \nnumber of ambiguous method calls, k, the constant time required to perform operations on a node such \nas dis\u00adambiguation, modi.cation or method call binding selection, and h, the maximum depth of the program \ns type hierarchy. We consider that the selection of a method binding takes a constant time because we \nalways select the .rst binding. We can express the complexity of each pass with the following formulas: \nSeed pass = nfnk = O(nfn) Type inference pass = h \u00d7 farfnk = O(hfarfn) M. binding pass = mfnk+h\u00d7farfnk \n= O(mfn+hfarfn) Although the cost to process the worklist is potentially high (O(hfafnr)), several factors \nreduce the time complex\u00adity in practice. We found during our evaluation of partial program analysis that \nh< 4 because most type facts re\u00adlated to the same expression were con.icting, and when they were converging, \nthey always converged fast. The number of nodes impacted by a type fact, r, was also small: it was on \naverage equal to 1.57 and always below 213. Finally, the number of inferred type facts per node was low: \nfn < 4. 6. Evaluation To validate the performance of partial program analysis un\u00adder various circumstances, \nwe performed an empirical study on four open-source systems. We were mostly interested in evaluating \nthe following criteria: 1. The quality of the results obtained by PPA as measured by the number of correct \nand erroneous type facts. 2. The impact of the input (i.e., size of the partial program) on PPA precision. \n 3. The contribution of the various inference strategies in producing more precise results.  6.1 Experimental \nDesign We performed partial program analysis on every single class, including anonymous and internal \nclasses, of four open\u00adsource systems. Table 3 shows the target systems along with their version, the \nnumber of classes and the number of source lines of code (SLOC) they have. We selected these sys\u00adtems \nbecause they are relatively complex, their version his\u00adtory was available, they could be compiled with \nJava 1.4, and because the programming language and software en\u00adgineering communities frequently analyze \nthose programs. Indeed, the .rst three systems, Lucene [3], JFreeChart [1], and Jython [2] are part of \nthe DaCapo benchmark suite [18]. Because the three .rst systems are self-contained, i.e., they do not \nrequire any other library outside the Java standard library, we selected a fourth system, Spring [4], \nwhich de\u00adpends on 90 external jar .les to compile. This was to increase the external validity of our \nevaluation by analyzing various kinds of Java programs. In general, we wanted to assess the quality of \nthe results obtained by partial program analysis against the results ob\u00adtained when the complete program \nis available. To perform this comparison, we executed PPA on each class separately, without any other \nclasses in the target system, and obtained an intermediate representation of each class in the form of \na Jimple .le. We also transformed every class of the complete target system into Jimple. We thus obtained \ntwo Jimple rep\u00adresentations for each class, one from PPA and the other from the complete system, that \nwe could compare. The following example shows two Jimple statements, the .rst one from the partial program, \nthe second one from the complete program. 1: i = virtualinvoke $r1.<p-unknown.unknown: int length()>(); \n2: i = virtualinvoke $r1.<java.lang.String: int length()>(); When comparing the type facts referenced \nby two state\u00adments, there are four possible outcomes: correct The two types are the same. For example, \nthe return type of the method length is int in both statements. Target Version # Classes SLOC Lucene \n2.2.0 371 23937 JFreeChart 1.0.9 561 81538 Jython 2.2.1 995 83763 Spring 2.5.1 2011 98938 Table 3. Target \nsystems unknown The type of the partial program is unknown, which means that PPA could not infer anything \nabout this type. This is the case of the method s target in the .rst statement. hierarchy correct The \ntype in the partial program is a su\u00adpertype or a subtype, depending on the type direction in the type \nfact, of the type in the complete program. For example, if dt($r1) = CharSequence at line 1 and dt($r1) \n= String at line 2, we say that the two types are hierarchy correct. erroneous All other cases. Erroneous \ntypes can be inferred when we combine con.icting type facts or when we use certain syntax heuristics. \nWe only compared the short name of the types. The abil\u00adity to infer the fully quali.ed name of a type \nsolely depends on the project coding convention: if a project such as Lucene or Jython allows the usage \nof wildcard import statements, most inferred types will have a p-unknown package. Be\u00adcause a short name, \ngiven the context in which it is used, is often suf.cient to uniquely identify a type, we preferred to \nclassify as correct, types with an unknown package that matched the short name of a real type. Finally, \nwe chose to compare the Jimple intermediate rep\u00adresentation of the partial program and the complete program \nbecause (1) this is the typical representation used to perform data .ow analysis, (2) this provides a \nreasonable estimate of the results we would obtain if we performed the comparison at the AST or bytecode \nlevel (the transformation from Jimple to AST or bytecode is more straightforward than the trans\u00adformation \nfrom AST to bytecode), and (3) there are fewer statement types in Jimple than node types in a Polyglot \nAST which makes the comparison easier and more robust. 6.2 Quality We executed our implementation of \npartial program analy\u00adsis on one class at a time without its dependencies, for all classes in our four \ntarget systems. Table 4 shows the results of PPA. There are three main sections in the table corre\u00adsponding \nto the three con.gurations we used to execute PPA: (1) our baseline con.guration (type inference and \nmethod binding disabled) 6, (2) type inference enabled and method 6 Since our tool must build a properly \nconstructed Polyglot AST in order to continue processing an entire class .le, this is the minimal con.guration \nwe can enable. It uses the declared types that are available inside the class under analysis, plus syntax \nheuristics (Section 4) and it infers missing type Outcome Lucene JFreeChart Jython Spring baseline inf. \nno bind. % correct % unknown % h. correct % erroneous % correct % unknown % h. correct % erroneous 89.20 \n8.23 0.29 2.29 93.48 3.52 0.34 2.67 89.23 9.02 1.12 0.63 94.12 3.89 1.16 0.83 81.20 13.88 1.91 3.01 87.94 \n6.63 2.36 3.07 87.16 8.01 1.12 3.71 90.78 4.30 1.20 3.71 inf. bind. % correct % unknown % h. correct \n% erroneous 93.80 2.46 0.38 2.71 94.40 3.56 1.19 0.85 88.22 6.21 2.44 3.13 90.97 4.07 1.24 3.72 Total \nFacts 87706 250155 312907 325641 Table 4. Partial program analysis results binding disabled, and (3) \ntype inference and method bind\u00ading enabled. For each of the con.gurations, the percentage of type facts \nin the Jimple IR that correspond to one of the four possible comparison outcomes is indicated below the \ntarget system. For example, with the baseline con.guration, 89.20% of the type facts recovered by PPA \nwere correct and 2.29% of the type facts were erroneous. The last line reports the total number of type \nfacts in each complete system. For example, there were 250155 type facts in JFreeChart. Our baseline \ncon.guration recovered most of the type facts in the partial programs (up to 89.23% in JFreeChart). Thus, \ncombining the declared types available for the class under analysis with the syntax heuristics and type \nmem\u00adber inference works reasonably well. However, this baseline con.guration can be improved upon, and \nthe results indi\u00adcate that type inference provides most of the remaining im\u00adprovement. In the best case \n(Jython), type inference enabled the recovery of 6.7% of correct type facts. Forcing method bindings \nhad a much smaller impact on the precision of the results because in the best case (Lucene), it recovered \nonly 0.32% of correct type facts. Syntax heuristics were the largest contributor of erro\u00adneous type facts. \nIn the worst case (Spring), 3.71% of the inferred type facts were erroneous because of the syntax heuristics. \nThese errors are effectively unavoidable because most of the syntax construct ambiguities represent undecid\u00adable \nproblems. Still, as future work, we could validate the assumptions behind our syntax heuristics on more \nsystems to ensure that they are representative and minimize the po\u00adtential for erroneous type facts. \nThe number of unknown type facts decreased signi.\u00adcantly when we enabled type inference and method binding. \nTable 5 shows the distribution of the unknown types once we enabled these two parameters. On average, \nthe type in\u00adference and method binding passes correctly recovered 52% of the types that were previously \nunknown. On average, only members (Section 3.3). Outcome Lucene JFreeChart Jython Spring % correct 55.92 \n57.33 50.61 47.62 % h. correct 1.08 0.79 3.78 1.46 % erroneous 5.17 2.37 0.86 0.15 % unknown 37.83 39.50 \n44.75 50.77 Table 5. Unknown types distribution after the type infer\u00adence and method binding passes \nTarget From To # Revisions # Classes Lucene 149000 616506 1017 4800 JFreeChart 1 712 185 924 Jython 1 \n4011 1267 20609 Spring 2003-08-01 2008-02-24 7299 31101 Table 6. Target systems versions 1% of the unknown \ntypes were erroneously inferred by these two passes. This provides evidence that performing type in\u00adference \nand method binding is desirable. Hierarchy correct type facts only accounted for a small portion of the \ntotal type facts. This suggests that even if our heuristics and type inference strategies are theoretically \nim\u00adprecise (i.e., we often infer that an the type of an expression is subtype or a supertype of a type \nT), in practice, they of\u00adten recover the exact type. The small number of hierarchy correct and erroneous \ntype facts introduced by type infer\u00adence and method binding also indicates that con.icting type facts \ndo not represent a serious threat to the precision of the results. 6.3 Analysis Input Partial program \nanalysis can be performed on one class or on a set of classes. Having access to multiple type declara\u00adtions \ncan potentially improve the precision of the analysis. Because the accessibility to source .les may vary \nfrom one technique to the other, we devised three scenarios that are representative of current software \nengineering techniques. The .rst scenario assumes that the user of partial program analysis only has \naccess to one class: this is the same sce\u00adnario as the previous section. The second scenario assumes \nthat the user has access to one class and all classes that are directly referenced by this class. Approaches \nthat mine code from web repositories would typically have access to a sub\u00adset of the direct dependencies. \nThe third scenario assumes that the user mines version histories and has thus access to all .les that \nwere modi.ed in the same change set. To evaluate the second scenario, we took each class in a target \nsystem and computed their direct dependencies using the complete target system. For each class, we provided \nthe source .les containing the class and the direct dependencies to our tool, but we did not provide \nany dependencies that were contained in a jar .le. We then compared the inferred type facts from the \nclass in the partial program with the type Outcome Lucene JFreeChart Jython Spring single baseline % \ncorrect 89.20 89.23 81.20 87.16 % erroneous 2.29 0.63 3.01 3.71 inf. % correct 93.80 94.40 88.22 90.97 \n% erroneous 2.70 0.85 3.13 3.72 dep baseline % correct 99.30 95.97 98.13 93.31 % erroneous 0.33 0.23 \n0.27 2.64 inf. % correct 99.56 98.39 98.92 95.00 % erroneous 0.26 0.29 0.29 2.67 cs baseline % correct \n89.52 89.54 86.92 86.13 % erroneous 2.00 0.56 2.97 4.91 inf. % correct 93.88 94.82 90.68 90.34 % erroneous \n2.62 0.72 3.24 4.91 Table 7. Partial program analysis inputs facts from the class in the complete program, \nbut we did not compare the type facts inferred in the direct dependencies. For the third scenario, we \n.rst retrieved the change sets, i.e., .les that were committed together, from the Subversion repositories \nof Lucene, JFreeChart and Jython and we re\u00adcovered the change sets from the CVS repository of Spring \nusing a standard change set inference technique [22]. For each change set, we computed the list of classes \nthat (1) were changed or modi.ed, and (2) still existed in the current ver\u00adsion of the program. We obtained \na collection of class sets taken from the current version of the program that we pro\u00advided as input to \nour tool. For each change set, we compared the type facts inferred in all classes in the change set with \nthe type facts from the same classes in the complete program. Table 6 shows the range of versions we \nmined for each tar\u00adget system, the number of change sets (revisions) containing Java source .les related \nto the target system and the total number of classes that we analyzed. For each of the three scenarios, \nwe executed PPA with the three con.gurations used in Section 6.2: (1) baseline con.g\u00aduration, (2) type \ninference enabled and method binding dis\u00adabled, and (3) type inference and method binding enabled. Table \n7 shows the results of our analysis. The three main sections represent the three scenarios we evaluated: \nsingle class (single), one class with all direct dependencies (dep), and all classes in the same change \nset (cs). For each section, we report the percentage of correct and erroneous type facts for the .rst \n(baseline) and third con.gurations (inf.) of PPA. In all cases, we omitted the results of the second \ncon.gu\u00adration because there was no signi.cant difference between it and the third con.guration. The results \nfor the .rst con.gu\u00adration are the same as Table 4. Including the direct dependencies greatly increased \nthe percentage of correct type facts PPA could infer. This high precision actually left little room for \nimprovement from type inference. On average, 96% of the type facts were correct in the baseline con.guration \nwhen including all direct depen\u00addencies as opposed to 86% correct type facts in our baseline Strategy \nLucene JFreeChart Jython Spring single % Assign. 45.59 61.06 36.73 38.37 inf. % Return 13.41 6.10 52.93 \n31.12 no bind. % Method 0.66 0.72 0.39 0.35 % Condition 8.73 5.10 1.38 16.50 % Binary 22.01 17.64 6.06 \n7.12 % Unary 3.48 8.75 0.91 3.55 Total facts 4571 6700 41521 14462 single % Assign. 41.95 57.31 29.52 \n36.29 inf. % Return 12.25 5.73 42.53 29.42 bind. % Method 8.55 6.64 19.93 5.72 % Condition 7.97 4.79 \n1.11 15.60 % Binary 20.28 16.73 4.87 6.77 % Unary 3.18 8.21 0.73 3.36 Total facts 5006 7138 51675 15297 \nTable 8. Inference strategies results con.guration of single class analysis. We obtained fewer correct \ntype facts when analyzing Spring because a subset of the direct dependencies was contained in jar .les \nwhich were not supplied to the compiler. These results suggest that, when possible, retrieving a subset \nof the dependencies might be highly bene.cial since adding the dependencies had a greater impact than \ntype inference. Finally, because certain members were declared in an ancestor and were thus not ac\u00adcessible, \nwe still inferred erroneous and unknown type facts. Analyzing all classes in a change set did not signi.cantly \nimprove the precision of our results. On average, only 34% of the direct dependencies of a class were \nin the same change set. Usually, even if two related classes are in the same change set, the improvement \nmight be minimal if we the one class only access a few members in the other class. Still, further analysis \nof the change sets results are required. For example, some .les are changed more often than others: if \nthe .les that are frequently changed are also the ones that gives the best (or the worst) results when \nanalyzed by our tool, the results will be highly biased toward these .les. This could explain the decrease \nof precision for Spring (90.97% for single class analysis versus 90.34% for change set analysis). 6.4 \nInference Strategies Since we showed that type inference was bene.cial, we were interested in analyzing \nthe contribution of each inference strategy we devised and presented in Section 3.1. This infor\u00admation \ncan be used to determine which strategies are worth implementing if PPA needs to be implemented in an \nexisting technique. For each type fact that was processed in the work\u00adlist (see Figure 7), we recorded \nthe inference strategy that caused its insertion in the worklist which provided a good estimation of \nthe contribution of each strategy. Table 8 shows the percentage of type facts that each of the six most \npopular inference strategies generated: the other inference strategies had a negligible contribution. \nBecause the ordering and the proportion of the inference strategies were similar for each input scenario, \nwe only report the results when we analyzed one class at a time. The upper part of the table shows the \nproportion of each inference strategy when performing type inference without method binding and the lower \npart shows the results when performing type inference with method binding. The last line in each part \nindicates the number of type facts that were processed in the worklist. For example, when performing \ntype inference and method binding on Lucene, the assignment inference strategy generated 41.95% of the \ntype facts. The assignment inference strategy was the largest con\u00adtributor of type facts in all target \nsystems except Jython. The return and binary inference strategies came second in two target systems each. \nThose three strategies contributed to 90% of the type facts when disabling method binding and 76% when \nenabling method binding. Because a strategy can also trigger the use of another strategy (e.g., we .nd \nthe type of a .eld using the assignment strategy and then we use the method binding strategy because \na method uses this .eld as a parameter), we were interested in the inference chains produced by our approach. \nWe found the average inference chain length to be 1.02, meaning that generally, an inference strategy \ndoes not trigger the use of another strategy. We also found in a manual investigation of the inference \nchains for each inference strategy that there is no signi.cant correlation between any two inference \nstrategies.  6.5 Threats to Validity The external validity of this study is limited by the fact that \nwe only studied four programs. Because three of these programs are self-contained, i.e., they do not \nrequire external libraries, we studied the Spring Framework which requires 90 jar .les to increase the \nscope of our evaluation. Our four target systems have a large number of lines of code and their purposes \nare different enough to be representative of many Java programs. The fact that the results were also \nrelatively stable across all four programs suggests that results obtained with different systems would \nbe similar. Our unit of measurement to evaluate the precision of PPA was the number of correct type facts \nin the Jimple interme\u00addiate representation. This unit is a good indicator for tech\u00adniques that use PPA \nto retrieve static type information (e.g., SemDiff), but it is not suf.cient to evaluate the usefulness \nof our approach for client static analyses such as call graph generation and points-to analysis that \nuse the IR produced by PPA. These client static analyses typically require a higher precision than the \nsoftware engineering tools that currently use PPA. Researchers in both our groups and others will be \nable to do these sorts of experiments now that PPA is fully implemented and publicly available. The parser \nthat PPA uses takes as input well-formed Java source .les. Hence, it was not possible to evaluate our \nap\u00adproach against code snippets even if PPA does not require complete source .les. Although it is possible \nthat analyz\u00ading only code snippets could decrease the precision of our approach, we found during early \nexperimentation that type inference did not often cross the method boundaries, so the performance of \nPPA should not be dramatically impacted. Finally, when we analyzed the change sets, we only used the \nlatest version of the classes for each change set as op\u00adposed to using the version of these classes at \nthe time of the change set. We expect the results of our analysis to be rep\u00adresentative because the set \nof direct dependencies should be relatively stable during the lifetime of a class. 7. Related Work Static \nanalysis tools typically assume that a complete and correct representation of the program is available. \nOur work is quite different in that we assume that only part of the program is available. To the best \nof our knowledge, we know no other research project, except the prototype used in PARSEWeb [19], that \nperforms type inference and re\u00adsolves syntactic ambiguities with such constraints. Unfortu\u00adnately, it \nis not possible to provide a full evaluation of the PARSEWeb s prototype because it is not publicly available \nand the paper only describes two inference strategies the pro\u00adtotype used. Those strategies are equivalent \nto our return and method binding inference strategies. Still, there are several techniques that deal \nwith the pars\u00ading of incomplete programs. Two such examples include fuzzy parsers [13] which extract \nhigh level structures out of incomplete or syntactically incorrect programs, and island grammars [14] \nwhich parse snippets of code into islands (recognizable constructs of interest) and water (remaining \nparts). Knapen et. al. presented an approach for parsing C++ programs when missing some header .les [12]. \nTheir moti\u00advation was similar to ours, since they wanted to deal with sit\u00aduations where not all the code \nwas available. They developed various semantic tests and heuristics, similar to the syntax heuristics \nwe used and described in Section 4, to determine the nature of an ambiguous syntactic constructs. As \nopposed to PPA, this C++ parser does not try to infer the declared type of an AST node (like the inference \nstrategies presented in Section 3) and it creates an unknown node when it cannot soundly determine the \nnature of an expression. The programming system generator (PSG) enabled the creation of development environments \nthat could handle the parsing and analysis of incomplete programs [6]. For exam\u00adple, the environment \ncould list the possible types of an un\u00addeclared variable according to its context. The computation of \nthe possible types was encoded into a grammar written by the PSG users: the inference rules had thus \nto be manually de.ned and only simple inheritance schemes (e.g., Pascal) were supported. Another difference \nis that the environment generated by PSG was only suggesting possible types: it was not making any de.nitive \nchoice like PPA. Finally, modern Integrated Development Environments (IDE) often include tools to execute \nor analyze snippets of code. For example, the Java parser 7 in Eclipse is able to generate an Abstract \nSyntax Tree for incomplete programs, but it does not try to resolve syntax ambiguities and it does not \nprovide any typing information when the declaration of a type is missing. The Scrapbook editor8 tries \nto execute any snippet of code even if it is not included in a Java class. Again, this tool reports an \nerror if it encounters an undeclared type. In terms of inferring declared types for Java, Gagnon et. \nal. solved a related problem of .nding declared types of local variables when starting from Java bytecode \n[10]. Although their approach also used type constraints to assign declared types, their setting is quite \ndifferent since they have access to the complete program and type hierarchy, and there are no syntactic \nambiguities in bytecode. Other work, less directly related, includes static analy\u00adses techniques that \naim to analyze only part of a program. These are often designed for software engineering applica\u00adtions, \nwhere it is too expensive to analyze the whole pro\u00adgram. These techniques use an intermediate representation \ngenerated from the complete program where all type dec\u00adlarations are accessible. Examples of these techniques \nin\u00adclude partial data .ow analysis [9,11] which uses a demand\u00addriven approach to analyze only the relevant \npart of a whole program and fragment analysis [16, 17] which does a full analysis on a given fragment \nof the program, using summary information for the remainder. 8. Conclusions and Future Work We presented \nPartial Program Analysis, a technique that builds a typed abstract syntax tree and a typed three-address \nintermediate representation that software engineering tools can use to get more precise type information \nthan what syntactic analysis traditionally provides. We covered the two main challenges when analyzing \npartial programs in Java, the ambiguous language constructs and the determination of declared types, \nand we proposed type inference strategies and heuristics to solve these problems. We performed an empirical \nstudy on four open source programs and found that, on average, Partial Program Anal\u00adysis could uncover \n91.2% of correct type facts when analyz\u00ading one class at a time and only produced 2.7% of erroneous type \nfacts. This high precision suggests that partial program analysis is a viable approach to enable useful \nstatic analysis on incomplete Java programs. Finally, the current implementation of our prototype is \navailable online at http://www.sable.mcgill.ca/ppa. Acknowledgements The authors thank Eric Bodden and \nEkwa Duala-Ekoko for their valuable comments on the paper. This project was sup\u00ad 7 www.eclipse.org/jdt/core/index.php \n8 www.eclipsezone.com/eclipse/forums/t61137.html ported by the Natural Sciences and Engineering Research \nCouncil of Canada. References [1] JFreeChart. http://www.object-refinery.com/ jfreechart/. [2] Jython. \nhttp://www.jython.org. [3] Lucene. http://lucene.apache.org. [4] Spring Framework. http://www.springframework. \norg. [5] Nathaniel Ayewah, William Pugh, J. David Morgenthaler, John Penix, and YuQian Zhou. Using .ndbugs \non production software. In OOPSLA 07: Companion to the 22nd ACM SIGPLAN conference on Object oriented \nprogramming systems and applications companion, pages 805 806, 2007. [6] Rolf Bahlke and Gregor Snelting. \nThe PSG system: from formal language de.nitions to interactive programming environments. ACM Trans. Program. \nLang. Syst., 8(4):547 576, 1986. [7] Nicolas Bettenburg, Rahul Premraj, and Thomas Zimmer\u00admann. Extracting \nstructural information from bug reports. In MSR 08: Proceedings of the 2008 international workshop on \nMining software repositories, pages 27 30, 2008. [8] Barthel\u00b4\u00b4emy Dagenais and Martin P. Robillard. Recommend\u00ad \ning adaptive changes for framework evolution. In ICSE 08: Proceedings of the 30th International Conference \non Soft\u00ad ware Engineering, pages 481 490, 2008. [9] Evelyn Duesterwald, Rajiv Gupta, and Mary Lou Soffa. \nA practical framework for demand-driven interprocedural data .ow analysis. ACM Trans. Program. Lang. \nSyst., 19(6):992 1030, 1997. [10] Etienne Gagnon, Laurie J. Hendren, and Guillaume Marceau. Ef.cient \ninference of static types for java bytecode. In Static Analysis Symposium, pages 199 219, 2000. [11] \nRajiv Gupta and Mary Lou Soffa. A framework for partial data .ow analysis. In ICSM 94: Proceedings of \nthe International Conference on Software Maintenance, pages 4 13, 1994. [12] Gregory Knapen, Bruno Lagu\u00a8e, \nMichel Dagenais, and Ettore Merlo. Parsing C++ Despite Missing Declarations. In IWPC 99: Proceedings \nof the 7th International Workshop on Program Comprehension, page 114, 1999. [13] Rainer Koppler. A systematic \napproach to fuzzy parsing. Softw. Pract. Exper., 27(6):637 649, 1997. [14] Leon Moonen. Generating robust \nparsers using island grammars. In WCRE 01: Proceedings of the Eighth Working Conference on Reverse Engineering, \npage 13, 2001. [15] Nathaniel Nystrom, Michael R. Clarkson, and Andrew C. Myers. Polyglot: An extensible \ncompiler framework for java. In Proc. of the 12th International Conference on Compiler Construction, \npages 138 152, 2003. [16] Atanas Rountev, Ana Milanova, and Barbara G. Ryder. Fragment class analysis \nfor testing of polymorphism in java software. IEEE Transactions on Software Engineering, 30(6):372 387, \n2004. [17] Atanas Rountev, Barbara G. Ryder, and William Landi. Data\u00ad.ow analysis of program fragments. \nIn ESEC/FSE-7: Pro\u00adceedings of the 7th European Software Engineering Confer\u00adence held jointly with the \n7th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pages 235 252, 1999. \n[18] Stephen M. Blackburn et al. The dacapo benchmarks: java benchmarking development and analysis. In \nOOPSLA 06: Proceedings of the 21st annual ACM SIGPLAN conference on Object-oriented programming systems, \nlanguages, and applications, pages 169 190, 2006. [19] Suresh Thummalapenta and Tao Xie. Parseweb: a \nprogram\u00admer assistant for reusing open source code on the web. In ASE 07: Proceedings of the twenty-second \nIEEE/ACM in\u00adternational conference on Automated software engineering, pages 204 213, 2007. [20] Raja \nValle\u00b4e-Rai, Phong Co, Etienne Gagnon, Laurie Hendren, Patrick Lam, and Vijay Sundaresan. Soot -a Java \nbytecode optimization framework. In CASCON 99: Proceedings of the 1999 conference of the Centre for Advanced \nStudies on Collaborative research, page 13. IBM Press, 1999. [21] Wei Zhao, Lu Zhang, Yin Liu, Jiasu \nSun, and Fuqing Yang. Snia.: Towards a static noninteractive approach to feature location. ACM Trans. \nSoftw. Eng. Methodol., 15(2):195 226, 2006. [22] Thomas Zimmermann, Peter Weissgerber, Stephan Diehl, \nand Andreas Zeller. Mining version histories to guide software changes. IEEE Transactions on Software \nEngineering, 31(6):429 445, 2005. Appendix A Table 9 presents the inference rules that PPA applies in \na partial program. The .rst column indicates the inference rule name, the second column shows the AST \nnode templates to which the inference rule is applicable. The third column lists the type facts that \nare inferred. In an AST node template, arbitrary Java expressions are represented by w, x, y, and z, \nand types are represented by t, t1, and t2. The operator baseType returns the base type of an array (e.g., \nbaseType(int[])= int). The operator safest returns the safest type, or the .rst type if both are as safe, \nas de.ned in Section 3.4. Although type facts are generated for each AST node for which we do not have \naccess to the declared type, the type facts are only added to the worklist if they meet the safety criterion \npresented in Section 3.4. Finally, for the sake of brevity, we only present the relevant subset of the \nunary and binary operators. 1 // File A.java 2 class A { 3 void main() { 4 C.f1 = hello ; 5 C.f1 = C.f2; \n6 } 7 } 8 9 // File B.java 10 class B { 11 void main() { 12 C.m1(C.f2); 13 } 14 } Figure 9. A partial \nprogram Appendix B When analyzing multiple source .les, errors and impre\u00adcisions can be propagated. For \nexample, suppose that the classes A and B presented in Figure 9 are provided as input to PPA. The .eld \nf2 is shared by the two classes. In class A, PPA .nds that dt(f2) ~ String because dt(f2) <: dt(f1) :> \nString (inference chain produced at lines 4 and 5). PPA then concludes that at line 12, the method C.m1(String) \nis called. Unfortunately, this is not true since dt(f2) could be of any reference type (e.g., List) and \nthe parameter of method m1 could end up being far from the type String. If the two .les had been analyzed \nseparately, PPA would have concluded that at line 12, the method C.m1(Unknown) was called. This is still \nimprecise, but not as misleading as the previous inference. Inference Strategies Code Generated Type \nFact x =y; Assignment {x, dt(x), :> dt(y)}{y, dt(y), <: dt(x)} Return t m1() { {y, dt(y), <: t} ... \nreturn y; } Method Binding void m1() { ... x = m2(y); } t1 m2(t2 param1) {... } {x, dt(x), <: t1}{y, \ndt(y), <: t2} We assume that m2 declared after m1 is the binding selected by PPA. Condition for (y; \nx; z) {x, dt(x), boolean} while (x) if (x) x?y: z Unary Binary x++ !y x + y w &#38; z w | z {x, dt(x), \n~ int}{y, dt(y), boolean} {x, dt(x), ~ dt(y)}{y, dt(y), ~ dt(x)}{w, dt(w), ~ dt(z)}{z, dt(z), ~ dt(w)}or \n{w, dt(w), boolean}{z, dt(z), boolean}if the expected return type of &#38; or | is a boolean. Array Switch \nConditional x[y] switch(x) x ? y : z; {y, dt(y), <: int }{x, dt(x), dt(x[y])[] }{x[y], dt(x[y]), baseT \nype(x) } {x, dt(x), <: int} {y, dt(y), ~ z}{z, dt(z), ~ y}{x ? y : z, dt(x ? y : z), safest(dt(y), dt(z))}or \n{y, dt(y), <: t}{z, dt(z), <: t}if the expected type t of the conditional is known. Table 9. Type Inference \nRules  \n\t\t\t", "proc_id": "1449764", "abstract": "<p>Software engineering tools often deal with the source code of programs retrieved from the web or source code repositories. Typically, these tools only have access to a subset of a program's source code (one file or a subset of files) which makes it difficult to build a complete and typed intermediate representation (IR). Indeed, for incomplete object-oriented programs, it is not always possible to completely disambiguate the syntactic constructs and to recover the declared type of certain expressions because the declaration of many types and class members are not accessible.</p> <p>We present a framework that performs partial type inference and uses heuristics to recover the declared type of expressions and resolve ambiguities in partial Java programs. Our framework produces a complete and typed IR suitable for further static analysis. We have implemented this framework and used it in an empirical study on four large open source systems which shows that our system recovers most declared types with a low error rate, even when only one class is accessible.</p>", "authors": [{"name": "Barth&#233;l&#233;my Dagenais", "author_profile_id": "81321487788", "affiliation": "McGill University, Montreal, PQ, Canada", "person_id": "P1223202", "email_address": "", "orcid_id": ""}, {"name": "Laurie Hendren", "author_profile_id": "81100646110", "affiliation": "McGill University, Montreal, PQ, Canada", "person_id": "P1223203", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449790", "year": "2008", "article_id": "1449790", "conference": "OOPSLA", "title": "Enabling static analysis for partial java programs", "url": "http://dl.acm.org/citation.cfm?id=1449790"}