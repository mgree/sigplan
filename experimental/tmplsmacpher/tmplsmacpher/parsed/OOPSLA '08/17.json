{"article_publication_date": "10-19-2008", "fulltext": "\n Annotation Refactoring: Inferring UpgradeTransformationsfor LegacyApplications WesleyTansey EliTilevich \nDepartment of Computer Science VirginiaTech, Blacksburg,VA24061, USA {tansey,tilevich}@cs.vt.edu Abstract \nSince annotations were added to the Java language, many frameworks have moved to using annotated Plain \nOld Java Objects (POJOs) in their newest releases. Legacy applica\u00adtions are thus forced to undergo extensive \nrestructuring in order to migrate from old framework versions to new ver\u00adsions based on annotations(Version \nLock-in). Additionally, because annotations are embedded in the application code, changing between framework \nvendors may also entail large\u00adscale manual changes(Vendor Lock-in). This paper presents a novel refactoring \napproach that ef\u00adfectively solves these two problems. Our approach infers a concise set of semantics-preserving \ntransformation rules from two versions of a single class. Unlike prior approaches that detect only simple \nstructural refactorings, our algorithm can infer general composite refactorings and is more than 97% \naccurate onaverage.We demonstrate theeffectiveness of our approach by automatically upgrading more than \n80K lines of the unit testing code of four open-source Java appli\u00adcations to use the latest version of \nthe popular JUnit testing framework. Categories and Subject Descriptors D.2.3[CodingTools and Techniques]: \nObject-Oriented programming; D.2.6 [Program\u00adming Environments]: Integrated environments; D.2.7 [Distribu\u00adtion, \nMaintenance, and Enhancement]; D.3.3 [Language Con\u00adstructs andFeatures]: Frameworks,Patterns General \nTerms Languages, Experimentation Keywords Refactoring, Upgrading, Frameworks, Meta\u00addata, Java, Annotations, \nEclipse, JUnit Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page.To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. OOPSLA 08, October 19 23, 2008, Nashville,Tennessee, USA. Copyright c &#38;#169;2008ACM 978-1-60558-215-3/08/10... \n$5.00 1. Introduction By providing reusable designs and a prede.ned architec\u00adture, frameworks enable \ndevelopers to streamline the soft\u00adware construction process and have consequently become a mainstay of \nobject-oriented software development. One de\u00adsign decision that has to be made when creating a frame\u00adwork \nis how application and framework objects will in\u00adteract with each other. Traditionally, frameworks have \nem\u00adployed type and naming conventions to which the program\u00admer must adhere. However, since metadata support \nhas been added to modern object-oriented languages (e.g., Java Anno\u00adtations and .NET Attributes), frameworks \nhave increasingly moved to using language-supported metadata facilities. Be\u00ading embedded within the source \ncode next to the program elements they describe, annotations provide declarative in\u00adformation more robustly \nand concisely. As a result, many ex\u00adisting frameworks have switched from using type and nam\u00ading conventions \nto using annotated Plain Old Java Objects (POJOs) in their latest releases. Despite the bene.ts of annotation-based \nframeworks, several major drawbacks hinder their adoption and use. Legacy applications that were developed \nusing older frame\u00adwork versions based on type and namingrequirements must be upgraded to the annotation-based \nversions. This up\u00adgrade often requires hundreds or even thousands of tedious changes to source .les scattered \nthroughout the codebase. These changes are in fact refactorings, as they preserve the semantics of the \napplication in the presence of a new frame\u00adwork. While these refactorings are intuitively obvious to \nthe programmer, automating them is not trivial. A text-based .nd-and-replace approach is not suf.cient, \nas the required changes cannot be correctly detected with a regular expres\u00adsion search.Furthermore,existing \ninference algorithms can\u00adnot detect them automatically, and writing an automated refactoring tool by \nhand can be time-consuming and error\u00adprone. These complications often force a manual refactor\u00ading in \norder to upgrade an application. The bene.ts of up\u00adgrading to the latest annotation-based version of \na frame\u00adwork may therefore not be worth the programming effort re\u00adquired to apply these refactorings \nmanually, resulting in an anti-pattern that we call Version Lock-in. As noted in a recent article [31] \ndescribing metadata\u00adbased enterprise frameworks, annotations present an addi\u00adtional challenge. Due to \nthe tight coupling between annota\u00adtions and source code, switching between different frame\u00adwork vendors \ncan be prohibitively expensive for large soft\u00adware projects. Such a high re-engineering cost results \nin the phenomenon known as the Vendor Lock-In anti-pattern [6]. This paper presents a novel refactoring \napproach that solves both the Version and Vendor Lock-In problems out\u00adlined above. Our approach has three \nphases: .rst, the frame\u00adwork developer creates representative examples of a class before and after transitioning; \nsecond, our algorithm infers generalized transformation rules from the given examples; .nally, application \ndevelopers use the inferred rules to pa\u00adrameterize our program transformation engine, which auto\u00admatically \nrefactors theirlegacyapplications. We validate our approach by inferring refactorings for transitioning \nbetween three different unit testing frameworks (JUnit 3 [3], JUnit 4, and TestNG [4]), as well as three \ndif\u00adferent persistence frameworks (Java Serialization, Java Data Objects (JDO) [34], and Java Persistence \nAPI (JPA) [15]). With only .ve minor re.nements to the inferred unit testing transformation rules, we \nautomatically upgraded more than 80K lines of testing code in JHotDraw, JFreeChart, JBoss Drools, and \nApache Ant fromJUnit3 to JUnit 4. This paper makes the following novel contributions: Annotation Refactoring \na new class of refactorings that replaces the type and naming requirements of an old framework version \nor annotation requirements of a dif\u00adferent framework with the annotation requirements of a target framework. \n Anapproach to removing theVersionandVendor Lock\u00adin anti-patterns for annotation-based frameworks. \n A differencing algorithm that accurately infers general transformation rules from two versions of a \nsingle exam\u00adple.  The rest of this paper is structured as follows. Section 2 motivates our work by presenting \na real-world example. Section 3 gives an overview of our approach. Section 4 de\u00adscribes our inference \nalgorithm formally. Section5 presents the results of the case studies we have conducted. Section6 explainswhy \nexisting approaches areinsuf.cient. Section7 outlines future work directions, and Section 8 summarizes \nour contributions. 2. Motivating Example Whenever a widely-used framework undergoes a major ver\u00adsion \nupgrade (i.e., changing the structural requirements for application classes), framework developers or \nother domain experts commonly release an upgrade guide. A typical pre\u00adsentation strategy followed by \nsuch guides is to show an ex\u00adample legacy class and its corresponding upgraded version. With respect \nto annotation refactorings, recent framework upgrades that have led to the creation of such guides include \nEnterprise JavaBeans (EJB) version 2 to 3 [27], Hibernate annotations to the Java Persistence API (JPA) \n[40], and JU\u00adnitversion3 to4 [36]. JUnit 3 JUnit 4 import junit.framework.*; public class ATest extends \nTestCase { //called before every test protected void setUp() {} //called after every test protected void \ntearDown() {} //tests Foo public void testFoo() {} //tests Bar public void testBar() {} } import org.junit.*; \npublic class Atest { //called before every test @Before public void setUp() {} //called after every test \n@After public void tearDown() {} //tests Foo @Test public void testFoo() {} //tests Bar @Test public \nvoid testBar() {} } Figure 1. Comparisonsofa JUnit test caseinversion3and 4. To illustrate the challenges \nassociated with annotation refactorings, consider upgrading a JUnit application from version 3 to 4. \nFigures 1 and 2 show two example legacy classes and their corresponding upgraded versions, derived from \nthe upgrade guide [36]. Application classes that use JUnitfall into two categories: test cases and test \nsuites.Atest case class contains a set of methods for testing a piece of ap\u00adplication functionality. \nA test suite class groups related test cases, so that the framework can invoke them as a single unit. \nApplications using JUnit 3 must adhere to type and nam\u00ading requirements to designate test cases and suites. \nHow\u00adever, JUnit4switched to using an annotated POJO paradigm to express the same functionality. Table \n1 summarizes the differences between the application requirements of the two versions. While the refactorings \nrequired to upgrade a JUnit appli\u00adcation may be straightforward to the programmer, no exist\u00ading refactoring \ntool can make these changes automatically. JUnit 3 JUnit 4 //gets a collection of two //test cases to \nrun public class AllTests { public static Test suite() { TestSuite suite = new TestSuite(ATest.class); \nsuite.addTestSuite(BTest.class); return suite; } } } @RunWith(Suite.class) @SuiteClasses({ATest.class, \nBTest.class}) public class AllTests { //no suite method required Figure 2. Comparisonofa JUnit test \nsuiteinversion3 and 4. Application Element JUnit 3 JUnit 4 Test case class Extend TestCase None (POJO) \nInitialization method Override setUp @Before Destruction method Override tearDown @After Test method \nName starts with test @Test Test suite class Provides suite method @RunWith @SuiteClasses Table 1. \nA summary of the requirements for application elements using JUnitversions3 and4. Therefore, if the framework \ndeveloper wishes to provide au\u00adtomated upgrade support, she often has no choicebut to cre\u00adate a refactoring \ntool by hand. Such a task may require a sig\u00adni.cant investment by the frameworkdeveloper, as she must \n.rst gain pro.ciency in a refactoring library API (e.g., the Java DevelopmentToolkit (JDT) [20]) or a \ndomain-speci.c language (e.g., Spoon [28]). After becoming familiar with a library or a DSL, she must \nthen use it to write the refac\u00adtoring tool from scratch. As a result, framework develop\u00aders typically \nopt to provide backwards compatibility sup\u00adport rather than automated upgrade tools. Although provid\u00ading \nbackwards compatibility allows legacy applications to use a newer version of a framework, it does not \nallow them to take advantage of newly-introduced framework features. Thus, an approach to automatically \ngenerating refactor\u00ading tools capable of upgrading legacy applications has great potential bene.t. Next \nwe provide an overview of our ap\u00adproach and show how it can be used to automatically gener\u00adate a refactoring \ntool for upgrading JUnit applications. 3. Approach Overview Our approach is based on the wide availability \nof upgrade guides containing examples of legacy classes and their up\u00adgraded versions. If the human developer \nis expected to infer general rules for upgrading their legacy applications using these guides, then the \nexamples are likely to contain a level of detail that one could leverage to automate the process. Our \napproach automatically extracts this knowledge, cre\u00adating specialized refactoring tools that can upgrade \nlegacy applications. Our Eclipse Plug-in called Rosemari (Rule-Oriented Software Enhancement and Maintenance \nthrough Automated Refactoring and Inferencing) concretely imple\u00adments our approach. Creating an annotation \nrefactoring tool involves three steps. First, the framework developer selects two versions of a class, \none before and one after upgrading, that we call representative examples. The developer then picks a \npre\u00adde.ned specialization of our inference algorithm, called an upgrade pattern. Finally, the generated \nrules can be down\u00adloaded by application developers and subsequently used to parameterize our transformation \nengine, which will then au\u00adtomatically refactor their legacyapplications. Next we detail the main steps \nof our approach, using the previously pre\u00adsented JUnit example for demonstration. 3.1 Representative \nExamples Arepresentative example is a class or interface, such as those commonly included in framework \ntutorials, that uses frame\u00adwork features that differ between versions or vendors (e.g., Figures 1 and \n2 can serve as representative examples for upgrading JUnit). A representative example using an older \nframework is called a prior example. A representative ex\u00adample using a newer framework is called a posterior \nexam\u00adple. The framework developer provides a prior example and its corresponding posterior example, which \nmay differ in the following ways: 1. Super type changes 2. Method signature changes 3. Field type changes \n 4. Annotations added or removed 5. Annotation argument added or removed 6. Imports added or removed \n 7. Statement added or removed  The prior and posterior examples are compared at dif\u00adferent levels of \ngranularity in the encapsulation hierarchy, which we call levels for short. Speci.cally, examples are \ncompared at class, method, and statement levels. Differences between levels are used to detect the restructurings \nrequired to upgrade the prior example into the posterior example. However, detecting restructurings is \nonly onefacet of creat\u00ading a refactoring. The issue of when to apply a restructuring to a level is not \nclear without additional knowledge about how the application is beingupgraded. public class D extends \nC  public class D extends C { { @Ann public void foo() { public void foo() { System.out.println(); \n System.out.println(); } } } } Figure 5. An example showing the ambiguity inherent in inferring \nrefactorings between two arbitrary representative examples. For instance, consider the simple pair of \nprior and pos\u00adterior examples in Figure 5. While it is obvious that there is a method-level difference \nthat requires adding the @Ann annotation to foo, the refactoring rule to be inferred is un\u00adclear. One \npossible rule may be that a method named foo in any subclass of C should be annotated with @Ann. How\u00adever, \nanother rule could be that any method which calls Figure 3. The Rosemari context menu. The top set of \nmenu items are available refactorings; the bottom set of menu items are available inference patterns. \n System.out.println should be annotated with @Ann. To disambiguate when a restructuring should be applied \nin a refactoring, we follow a pattern-based approach described next.  3.2 UpgradePatterns When upgrading \nfrom a type and naming convention-based framework version to a newer annotation-based version, or when \nswitching between different annotation-based frame\u00adworks, refactoring rules typically follow common patterns, \nwhich we call upgrade patterns. One reason why these pat\u00adterns occur is that evolving a framework to \nuse annotations is normally driven by the desire to improve the software en\u00adgineering qualityof the framework \n(e.g., looser coupling be\u00adtween application and framework classes). Another reason is that switching \nbetween different annotation-based frame\u00adworks often requires using a different vocabulary to describe \nessentially the same functionality. Therefore, inferring the refactorings between two repre\u00adsentative \nexamples depends on the upgrade pattern followed. Next we describe three such common patterns we have \niden\u00adti.ed from our experiences. While we have found that these patterns successfully capture the refactorings \nfor many up\u00adgrade scenarios, other patterns can be plugged into our sys\u00adtem as needed. 3.2.1 Bottom-Up \nThis upgrade pattern applies restructurings on the basis of the level itself and its enclosing levels. \nFor example, refac\u00adtoring the methods in a JUnit 3 test case follows a bottom\u00adup pattern. Speci.cally, \nthe test, setUp and tearDown method restructurings are only relevant if their enclosing class is a TestCase. \n 3.2.2 Top-Down In contrast to the bottom-up pattern, a top-down pattern applies restructurings on the \nbasis of the level itself and its contained levels. For example, refactoring test suite classes inJUnit3followsa \ntop-down pattern. Speci.cally, the class is annotated with the @RunWith(Suite.class) annotation on the \nbasis of containing a suite method. 3.2.3 Identity This upgrade pattern applies restructurings only \non the ba\u00adsis of the level itself, assuming that all annotations in the .rst representative example have \na one-to-one mapping in the second representativeexample.For instance, theTestNG framework uses @BeforeMethod, \nwhich is identical in its functionality to the @Before annotation in JUnit 4. The developer can choose \nan appropriate upgrade pattern by observing the purpose of a given annotation. If adding an annotation \nremoves tight coupling between the enclosing elementsofalevel (e.g.,a class enclosinga method) and the \nframework, then it is likely a bottom-up pattern. If, however, the annotation describes the contained \nelements of a level (e.g., a method contained in a class), then it is likely a top\u00addown pattern. If the \nannotation simply changes how the level is expressed, then it is likely an identity pattern.  3.3 Transformation \nRules Inferred refactorings are represented as a collection of .rst\u00adorder when-then transformation rules,1 \nexpressed using a Domain Speci.c Language (DSL) we developed. A trans\u00adformation rule is composed of restructurings \nand constraints on their application. The when portion of a rule de.nes the constraints under which to \napply the restructurings de.ned in the then portion of the rule. While the generated rules possess a \nhigh degree of preci\u00adsion, some rules may require manual re.nement. Since the developer is not expected \nto write the transformation rules from scratch but rather .ne-tune the generated rules, we 1We use the \nJBoss Drools engine [30]. rule \"#1) Transform classes matching ATest\"rule \"#2) Transform all methods \nmatching setUp\" no-loop no-loop salience 10salience 20 when when $class : Application Class $class \n: Application Class -Visibility is public -Visibility is public -Superclass is \"junit.framework.TestCase\"-Superclass \nis \"junit.framework.TestCase\" then $method : Application Method Remove superclass from $class -Name \nmatches \"setUp\" Update $class -Declaring class is $class end -Not annotated with \"Before\" rule \"#3) Transform \nall methods matching tearDown\" -Visibility is protected no-loop  -Scope level is member salience 20 \n -Return type is \"void\" when  -Has 0 parameters $class : Application Class then -Visibility is public \n Add annotation \"Before\" to $method -Superclass is \"junit.framework.TestCase\" Set access level of $method \nto public $method : Application Method Update $class -Name matches \"tearDown\" Update $method -Declaring \nclass is $class end -Not annotated with \"After\"  rule \"#4) Transform all methods matching test.*\" \n -Visibility is protected  no-loop -Scope level is member  salience 20 -Return type is \"void\"  when \n -Has 0 parameters $class : Application Class then -Visibility is public Add annotation \"After\" to \n$method -Superclass is \"junit.framework.TestCase\" Set access level of $method to public $method : \nApplication Method Update $class -Name matches \"test.*\" Update $method -Declaring class is $class \n end -Not annotated with \"Test\" rule \"#5) Manage imports\" -Visibility is public no-loop -Scope level \nis member salience 0 -Return type is \"void\" when -Has 0 parameters $file : Application File  then \n -Does not import \"org.junit.After\" Add annotation \"Test\" to $method -Does not import \"org.junit.Before\" \n Update $class -Does not import \"org.junit.Test\" Update $method -Does not import \"org.junit.Assert.*\" \n end -Does import \"junit.framework.TestCase\" then  Add import \"org.junit.After\" to $file Add import \n\"org.junit.Before\" to $file Add import \"org.junit.Test\" to $file Add static import \"org.junit.Assert.*\" \nto $file Remove import \"junit.framework.TestCase\" from $file Update $file end  Figure 4. The generated \ntransformation rulestorefactora JUnit3 test case classto useJUnit4. chose to trade conciseness for readability \nand ease of un\u00adderstanding in designing our DSL. Having a collection of generic natural-language statements \nthat can be parameter\u00adized with concrete values, the developer can easily re.ne complex rules to better \nexpress the desired refactorings. Given the JUnit test case representative examples in Fig\u00adure 1 and \nthe Bottom-Up upgrade pattern, Rosemari gen\u00aderates .ve transformation rules, shown in Figure 4. Rules \n2-4 originally require that the target class directly extends TestCase. However, these transformations \nare valid for any class that extends TestCase, directly or indirectly. There\u00adfore, the developer can \nchange this constraint in each of the three rules by re.ning it to its more general version: Super\u00adclass \nis a junit.framework.TestCase . Additionally, the Vis\u00adibility is protected constraint in rules 2 and \n3 can easily be generalized by changing the constraint to Visibility is at least protected. The Rosemari \nplug-in provides a searchable collection of supported natural language statements that the developer \ncan reference when re.ning transformation rules. Once re.ned and named appropriately (e.g., JUnit v3 \nto v4), the refactor\u00ading can be applied by selecting a JUnit 3 test case source .le and choosing the \nrefactoring from the context menu, as shown in Figure 3. The source .le will then be automatically upgraded \nto JUnit 4. Next we present our algorithm for inferring annotation refactoring rules. 4. Inference Algorithm \nOur algorithm accepts two representative examples and infers a generalized set of transformation rules \nthat com\u00adFigure 6. A simple EnterpriseJava Beanexamplein EJB2 and 3. EJB 2 EJB 3 public class HelloWorldBean \n@Stateful public class HelloWorldBean { public void ejbActivate() {}implements SessionBean { public void \nejbActivate() {} @PostActivate @Remove public void ejbRemove() {} public void ejbRemove() {} } } posea \nrefactoring.We present our algorithm asa collection of seven smaller set manipulation algorithms con.gurable \nthrough a user-de.ned partial order on the levels of a rep\u00adresentativeexample.To further illustratehow \nour algorithm works, we show how each component algorithm contributes to learning the transformation \nrules for a simple Enterprise JavaBeans (EJB)upgrade scenario. Figure 6 shows the two EJB representative \nexamples, derived from the Oracle guide [27] on migrating applications from EJB2 to 3.2 4.1 Decomposing \nRepresentative Examples In order for our algorithm to calculate transformation rules, each representative \nexample must .rst be decomposed into a set of levels, P = {L1,L2,...,Ln}.A level is a set, L = {e1,e2,...,em}, \nof signature elements (i.e., tokens in a program element s signature) at a particular point in the encapsulation \nhierarchy. For example, the method level contains a set of annotations, a visibility identi.er, a scope \nidenti.er, a return type, a set of parameters, and a set of exceptions. Figure7 showsa full listof the \nsupportedlevels and their de.nitions. As discussed in Section 3.2, inferring the correct trans\u00adformation \nrules given a pair of representative examples is not possible without additional information about the \nrefac\u00adtoring. The Rosemari plug-in implementing our algorithm uses the concept of upgrade patterns to \nsimplify this process. However, upgrade patterns are merely wrappers for specify\u00ading a partial order \nover the set of levels in a representative example. Figure 8 shows the partial orders corresponding to \neach of the three previously discussed upgrade patterns. Figure 9 shows the level sets for the EJB example, \nwhich matches to a Bottom-Up pattern.  4.2 Component InferenceAlgorithms The foundation of our algorithm \nis to construct sets of in\u00addependent components and then merge them hierarchically. This section presents \nthe .ve algorithms that compose these independent components. 2Fully upgrading EJB applications requires \nstatic analysis of both Java source code and XML metadata .les and is thus outside the scope of this \npaper. The rules learned in this example are therefore only a subset of the total required to refactor \nan entire EJB application. 4.2.1 LevelRestructurings Our algorithm starts by .rst calculating the restructurings \nfor each level.A restructuring is a simple program transfor\u00admation function that adds, replaces, or removes \na signature elementinalevel.We calla restructuringa positive restruc\u00adturing if it adds or replaces an \nelement. A restructuring is a negative restructuring ifit removes an element. Figure 10 presents the \nLevelRestructurings algorithm for discovering a level s restructurings. The Prune method (line 6) removes \nunnecessary elements from N EGELS. This is an implementation addition to re\u00adduce the number of negative \nrestructurings generated, mak\u00ading the .nal transformation rules more concise and readable. For instance, \nchanging the visibility of a level is done by re\u00adplacing the current visibility with the new visibility \n(a posi\u00adtive restructuring) ratherthan .rst removing the current visi\u00adbility (a negative restructuring) \nand then adding the new vis\u00adibility (a positive restructuring). For the EJB example, LevelRestructurings \nis called three times (i.e., once for each level). For the HelloWorldBean level, P OSELSHelloW orldBean \n= {AStateful}, and thus a positive restructuring of Add annotation Stateful is gen\u00aderated. Similar positive \nrestructurings are generated for the ejbActivate and ejbRemove levels. However, only the Hel\u00adloWorldBean \nlevel produces a non-null value for removed {ISessionBean}, elements, as N EGELSHelloW orldBean = resulting \nin a negative restructuring of Remove interface SessionBean. Lemma 1. Let L = {e1,e2, ..., em} be a \nprior level, and let L ' = {e1,e2, ..., en} be a posterior level, such that L ' is the restructured version \nof L. LevelRestructurings(L, L ' ) returns a set of restructurings, R = {r1,r2, ..., rk} repre\u00adsenting \nexactly every required positive and negative restruc\u00adturing to transform L to L ' . Proof. If there is \nan element, eu . L ' such that eu ./L, + then a positive restructuring r = P ositiveRestructuring i (eu) \nis required to transform L to L ' . Thus, P OSELS = L ' - L (line 2) will contain eu, and adding a positive \nre\u00adstructuring to R for every element in P OSELS (lines 3-4) + guarantees that r will be in R. If a positive \nrestructuring, i + rj = P ositiveRestructuring(ev) is not required to trans\u00adform L to L ' , then either \nev . L or ev ./L ' . If ev . L, then L ' -L will remove ev and it will not be added to P OSELS; likewise, \nif ev ./L ' then L ' -L and consequently P OSELS + will not contain it. If P OSELS does not contain ev,then \nr j + will not be created in line4 and rj ./R. Therefore, R con\u00adtains every positive restructuring and \nno more. An analogous and opposite argument applies to negative restructurings.  4.2.2 LevelConstraints \nOur algorithm next computes a set of constraints de.ning when the discovered restructurings should be \napplied to a level. We call a constraint a positive constraint when it re\u00ad LClass = {Annotations, V \nisibility, SuperClass, SuperInterf aces} LIface = {Annotations, V isibility, SuperInterf aces} LF ield \n= {Annotations, V isibility, Scope, T ype} LMeth = {Annotations, V isibility, Scope, ReturnT ype, P arameters, \nExceptions} LCons = {Annotations, V isibility, Scope, P arameters, Exceptions} LMethInvoke = {N ame, \nArguments} LConsInvoke = {T ype, Arguments} LArg = {Expression} Figure 7. Levels of a representative \nexample. Bottom-Up LArg <L {LConsInvoke,LMethInvoke} <L {LCons,LMeth,LF ield} <L {LIface,LClass} Top-Down \n LArg <L {LConsInvoke,LMethInvoke} <L {LIface,LClass} <L {LCons,LMeth,LField} Identity {LIface,LClass,LCons,LMeth,LF \nield,LConsInvoke,LMethInvoke,LArg} Figure 8. Upgrade patterns as partial orders onP. {V public,ISessionBean}EJB2HelloW \norldBean = {AStateful,V public} EJB3HelloW orldBean = {V public,Smember,Rvoid} EJB2ejbActivate = {AP \nostActivate,V public,Smember,Rvoid} EJB3ejbActivate = {V public,Smember,Rvoid} EJB2ejbRemove = {ARemove,V \npublic,Smember,Rvoid}EJB3ejbRemove = Figure 9. Thelevel decompositionof theEJBexample. quires that anelementbe \npresent.A constraintisa negative constraint when it requires that an element not be present. Negative \nconstraints are necessary to ensure the generated transformation rules are not applied unnecessarily \n(e.g., to levels that have already been transformed by hand or a pre\u00advious upgrading session). Figure \n11 presents the LevelCon\u00adstraints algorithm for discovering a level s constraints. For the HelloWorldBean \nlevel, lines 2-3 create two posi\u00adtive constraints, Visibility is public and Directly implements SessionBean;lines \n5-6 then add one negative constraint,Not annotated with Stateful . For both method levels, positive constraints \nrequiring public visibility, member scope (i.e., non-static scope), and a return type of void are added \nalong with negative constraints requiring ejbActivate and ejbRe\u00admove to not be annotated with PostActivate \nand Re\u00admove , respectively. Our implementation also handles spe\u00adcial cases such as when a method does \nnot contain any pa\u00adrameters, as with both EJB method levels which receive a negative constraint requiring \nthat there are no parameters in the method signature. Lemma 2. Let L = {e1,e2, ..., em} be a prior level, \nand let L ' = {e1,e2, ..., en} be a posterior level, such that L ' is the restructured version of L. \nLevelConstraints(L, L ' ) returns a set ofconstraints, S = {s1,s2, ..., sk} representing exactly every \nrequired positive and negative constraint to match L. Proof. If there is an element, eu . L, it must \nhave an asso\u00ad + ciated positive constraint, s = P ositiveConstraint(eu) . i S. All elements in L are \niterated over and their corre\u00adsponding positive constraints are added to S in lines 2-3. + If a positive \nconstraint s = P ositiveConstraint(ev) is j + not required to match L, then ev ./L and s is never j added \nto S. Thus, S contains exactly every positive con\u00adstraint. If and only if there is an element ew . L \n' such that ew ./L, it must have an associated negative con\u00ad ALGORITHM: Level Restructurings INPUT: \nTwo levels L = {e1,e2,...,em},L ' = {e1,e2,...,en} where L ' is the restructured version of L. OUTPUT:A \nset R = {r1,r2,...,rp} of restructurings. 1. R .\u00d8 2. P OSELS . L ' - L 3. For i . 1 to |P OSELS| \n  4. R . R PositiveRestructuring(P OSELS[i]) 5. N EGELS . L - L '  6. Prune(N EGELS) // remove unnecessary \nelements 7. For j . 1 to |N EGELS|   8. R . R NegativeRestructuring(N EGELS[j]) 9. returnR  Figure \n10. The LevelRestructurings algorithm for calculating the required set of restructurings to transform \nbetween two levels. ALGORITHM: Level Constraints INPUT: Two sets L = {e1,e2,...,em},L ' = {e1,e2,...,en} \nof signature elements where is L ' the restructured version of L. OUTPUT: A set S = {s1,s2,...,sq} of \ncontext-free constraints. 1. S .\u00d8 2. For i . 1 to |L|  3. S . S PositiveConstraint(L[i]) 4. N EGELS \n. L ' - L 5. For j . 1 to |N EGELS|  6. S . S NegativeConstraint(N EGELS[j]) 7. returnS  Figure \n11. The LevelConstraints algorithm for calculat\u00ading the context-free set of constraints for a level. \n+ straint, s = P ositiveConstraint(ew) . S, since ac\u00ad k cording to lemma 1 it will generate a positive \nrestructuring in LevelRestructurings. N EGELS will therefore con\u00ad + tain ew (line 4) and add a negative \nconstraint, s , for exactly k all elements satisfying the aforementioned constraint (lines 5-6).  4.2.3 \nNamingConvention For method and .eld levels, our algorithm adds a name matching constraint intended to \ncapture naming conventions. Figure 12 shows the N amingConvention algorithm which takesa set, N = {n1,n2,...,nm}, \nof .elds or methods with identical signatures in both the prior and posterior examples and returns a \ngeneralized regular expression matching all the names in N . The algorithm .rst tokenizes a name based \non the Java naming convention of uppercase delimiters, then calculates the tokens which match identically. \nIf no naming convention is found, a literal expression matching only N is returned. As this is the case \nfor both EJB method levels, each has an exact naming constraint added. ALGORITHM: Naming Convention INPUT:A \nset N = {n1,n2,...,nm} of member names OUTPUT:A regularexpression naming convention 1. T OKEN S .Tokenize(n1) \n 2. For i . 2 to m 3. T OKEN S . T OKEN S Tokenize(ni) 4. If T OKEN S = \u00d8 5. return LiteralRegex(N \n) 6. return GeneralizedRegex(T OKEN S)  Figure 12. The N amingConvention algorithm for gener\u00adalizing \na set of names to a naming convention. 4.2.4 ContextConstraints Although a level is context-free, program \ntransformations are often not context-free operations but are rather based on some framework-dependent \nnotion of context.To accom\u00admodate these scenarios, we introduce the notion of context constraints. A \ncontext constraint, q for level L1 is a level constraint, s . L2, such that L1 <L L2 where <L is a user\u00adde.ned \npartial order on the set of levels, P . Figure 13 shows the ContextConstraints algorithmfor discovering \nall context constraints for a set of prior levels. It should be noted that the algorithm present is only \na semantically-equivalent version of the implementation, as in practice caching data structures can be \nused to eliminate the internal loop (lines 4-6). Since our EJB example follows a Bottom-Up pattern, all \nmethod levels are de.ned as dependent on their enclosing class level. Thus, ContextConstraints adds the \nadditional requirements that annotating a method named ejbActivate or ejbRemove with @PostActivate or \n@Remove, respectively, is only correct if the enclosing class haspublic visibility and implements SessionBean. \nALGORITHM: Context Constraints INPUT:A set P = {L1,L2,...,Ln} of levels. Aset Sall = {S1,S2,...,Sn} of \nsets of constraints such that .Si . Sall, .Li . P , Si is the set of level constraints for Li. A partial \norder<L on P . OUTPUT: A set Qall = {Q1,Q2,...,Qn} of context constraints such that .Qi . Qall,Qi is \nthe set of con\u00adstraints de.ning the context of Li. 1. Qall .\u00d8 2. For i . 1 to n 3. Qi .\u00d8 4. For j . \n1 to n 5. If P [i] <L P [j]  6. Qi . Qi Sall[j] 7. Qall . Qall {Qi} 8. return Qall Figure 13. The \nContextConstraints algorithm for calcu\u00adlating the additional constraints for every level. Lemma 3. Let \nP = {L1,L2, ..., Ln} be a set of prior levels, let <L be a partial order on P , and let Sall = {S1,S2, \n..., Sn} be a set of sets of constraints, such that .Si . Sall, .Li . P , Si is the set of context-free \nconstraints for Li. ContextConstraints(P, Sall,<L) returns an or\u00addered set of sets of context constraints, \nQall = {Q1,Q2, ..., Qn} such that .Qi . Qall, Qi is exactly the set of con\u00adtexts constraints for Li. \nProof. It is necessary to .rst show that .Qi . Qall, Qi is a set of context constraints for Li, then \nwe show that Qi is the exact set of context constraints as speci.ed by <L. ContextConstraints creates \na new set of context con\u00adstraints for every level in P (line 3) and adds the set to Qall (line 7); thus, \n|Qall| = |P |, and this completes the .rst half of the proof. For every Qi, ContextConstraints iterates \nover all elements in P and adds a set of level constraints to Qi if and only if their corresponding level \nsatis.es <L;thus, Qi is exactly the set of context constraints for Li, and this completes the second \nhalf of the proof. 4.2.5 SalienceValues Context-dependent transformations hinge on the assumption that \nthe context of the level they are transforming will not be invalidated before the level has been transformed. \nThis assumption could not be guaranteed if the rules were exe\u00adcuted arbitrarily.For instance, the method-level \ntransforma\u00adtions for the EJB example require that the target method is de.ned in a class implementing \nSessionBean. If the class-level transformations are arbitrarily executed before the method-level transformations, \nthe interface will be re\u00admoved and the method-level transformations will fail. To overcome this limitation, \nour algorithm calculates an exe\u00adcution order for each level, called a salience value. Rules with higher \nsalience values will be executed prior to rules with lower salience values (ties are broken arbitrarily). \nFig\u00adure 14 shows the SalienceV alues algorithm for calculat\u00ading saliencevaluesfora setof priorlevels. \nThe algorithmis analogous to a sorting algorithm parameterized by the partial order on L. ALGORITHM: \nSalienceValues INPUT:A set P = {L1,L2,...,Ln} of levels Apartial order <L on L. OUTPUT: A set Yall = \n{y1,y2,...,yn} of salience values, . yi . Yall, yi is the salience of Li. 1. Yall .\u00d8 2. For u . 1 to \nn 3. yu . 0 4. Forv . 1 to n 5. If P [v] <L P [u] 6. yu . yu + 10  7. Yall . Yall {yu} 8. return \nYall Figure 14. The SalienceV alues algorithm for calculating the order of execution for every level. \n  4.3 Merging Algorithms Once the necessary independent components have been inferred, two merging algorithms \nare invoked. The .rst merging algorithm, LevelT ransf ormations, combines the independent components \nfor a level into a set of trans\u00adformations for that level. The second merging algorithm, P rogramT ransf \normations, combines the level transfor\u00admations into a complete set of program transformations. 4.3.1 \nLevelTransformations The LevelT ransf ormations algorithm takes the results of the algorithms described \nin the previous section for a single level, and combines them into a set of generalized transfor\u00admation \nrules. Figure 15 shows the LevelT ransf ormations algorithm. Until now, we have focused on structural \nin\u00adference at or above the level of method headers. We have deliberately not detailed how we infer annotation \nattribute values, which can be any valid Java expression and as such require a deeper level of inference \nthan that of head\u00aders. Thus, inference of attribute values is delayed until the LevelT ransf ormations \nalgorithm (lines 4-10), when more complete program information is known. For every argument to the attribute, \nLevelT ransf ormations checks if a matching expression exists in the prior representative example (Lines \n6-7). If it does not, the algorithm gener\u00adates a literal transformation which adds the expression to \nthe attribute (line 8). If the expression does exist, however, it generates a generalized transformation \nbased on the con\u00adtext of the expression. In both cases, the salience of attribute transformations must \nbe slightly lower than that of the rest of the level transformations, since the annotation itself must \nbe added .rst before an attribute can be added.  4.3.2 ProgramTransformations The .nal algorithm, P \nrogramT ransf ormations, takes two decomposed representative examples, P and P ' , as well as a set of \nexpressions, X, in the prior representative exam\u00adple, and returns the set, Tall, of inferred program \ntransfor\u00admations. First, P rogramT ransf ormations builds the sets of fundamental components, Sall, Rall, \nQall, and Yall, for every level (lines 1-11). Then, it builds the set of context constraints (if any) \nfor every expression (lines 14-16). Fi\u00adnally, P rogramT ransf ormations iterates over all levels and \nadds each set of level transformations to Tall (lines 17\u00ad19). Figure 17 shows the rules output by the \nalgorithm to transform the EJB example used through this section. 5. Evaluation We evaluated our approach \non two criteria. First, we mea\u00adsured the accuracyof our inference algorithm by applying it to seven different \nrefactoring scenarios. Second, we demon\u00adstrated the effectiveness of the automatically inferred refac\u00adtorings \nby upgrading the testing portion of four well-known, open-source projects. The results of our evaluation \nshow that ALGORITHM: ProgramTransformations INPUT:A set P = {L1,L2,...,Ln} of prior levels. ' Aset P \n= {L ' ,L ' ,...,L ' }) of posterior levels. 1 2n A set X = {x1,x2,...,xm} of expression nodes in an \nAST. Apartial order <L on L. OUTPUT: A set Tall = {T1,T2,...,Tq} of transforma\u00adtions for this program. \n 1. Sall .\u00d8 2. Rall .\u00d8  3. For i . 1 to n 4. L1 . P [i] 5. L ' . P ' [i] 6. Si . LevelConstraints(Li,L \n' ) 7. Ri . LevelRestructurings(Li,L ' )  1 i i 8. Sall . Sall {Si} 9. Rall . Rall {Ri} 10. Qall \n. ContextConstraints(Sall,<L) 11. Yall . SalienceValues(P [0]) 12. Tall .\u00d8 13. QX .\u00d8 14. For i . \n1 to m 15. v . V [i]  16. QX . QX {Qall.v} 17. For i . 1 to n 18. Ti . LevelTransformations(Sall[i],Qall[i],Rall[i], \nX, QX )  19. Tall . Tall Ti 20. return Tall Figure 16. The P rogramT ransf ormations algorithm for \ninferring a set of transformation rules from two repre\u00adsentative examples. our approach produces highly-accurate \nrefactorings which, with few minor re.nements, can be automatically-applied to large-scale applications, \neffectively solving the Vendor and Version Lock-in anti-patterns for applications that use annotation-based \nframeworks. 5.1 Inferred Refactorings For our approach to be viable in a realistic setting, it has to \ninfer refactorings with a high degree of accuracy. To as\u00adsess the accuracy of our inferencing algorithm, \nwe manu\u00ad ALGORITHM: LevelTransformations INPUT:A set S = {s1,s2,...,sk} of context-free constraints. \nAset Q = {q1,q2,...,qm} of context constraints. Aset R = {r1,r2,...,rn} of restructurings. Aset X = {x1,x2,...,xu} \nof expression nodes. Aset QX = {Q1,Q2,...,Qu} of sets of context constraints for the expression nodes. \nAsalience scoreY for this level. OUTPUT:A set Tlevel = {t1,t2,...,tp} of transformations for thislevel. \n 1. Tlevel .\u00d8 2. For i . 1 to n 3. ri . R[i]  4. If T ypeOf (r1)= AttributeAddition and |ri.args| \n> 0 5. Forj . 1 to |ri.args| 6. Xa . Xri.args[j] 7. If Xa = \u00d8   8. Tlevel . Tlevel {LiteralTransformation(ri.args[j],Y \n- 1)} 9. Else   10. Tlevel . Tlevel {GeneralTransformation(ri.args[j],Qa,Y - 1)} 11. Tlevel . Tlevel \n{GeneralTransformation(ri,S Q,Y )} 12. return Tlevel  Figure 15. The LevelT ransf ormations algorithm \nfor generating a set of transformation rules for a level. ally evaluated each inferred refactoring in \nfour categories: constraints, restructurings, rule execution order, and manual re.nements required. The \nmetrics used to evaluate each cat\u00adegory are de.ned below.To helpexplain the metrics, wegive examples \nfrom the transformation rules listed in Figure 4. 5.1.1 Constraint Metrics For constraints, we measured \nthe number of correct, exces\u00adsive, erroneous, and missing constraints, de.ned as follows: Correct. Acorrect \nconstraint accurately captures a single requirementofa transformation rule.Forexample, Name matches test.* \ncorrectly requires the name of any test method to start with the test pre.x.  Excessive. An excessive \nconstraint unnecessarily limits the scopeofa transformation rule.Forexample, Visibility is protected \nlimits the applicability of rules 2 and 3 to only protected methods, even though public methods should \nbe captured as well.  Erroneous. An erroneous constraint captures require\u00adments that are incorrect for \na speci.c transformation rule. For example, Has 1 parameter would be erroneous for identifying a setUp \nmethod in rule 2.  Missing. Amissing constraint is a necessary requirement not present in a transformation \nrule. For example, if Re\u00adturn type is void were not present in rule 2, it would be a missing constraint. \n 5.1.2 Restructuring Metrics For restructurings, we measuredthe number of correct, erro\u00adneous, and missing \nrestructurings as follows: Correct. A correct restructuring performs a required atomic transformation \nin a transformation rule. For ex\u00adample, Set access level of $method to public in rule 2 correctly changes \nthe visibility of a protected setUp method.  Erroneous. An erroneous restructuring performs an atomic \ntransformation thatinvalidatesa transformation rule.For example, Set scope level of $method to static \nwould be erroneous for rule2 because the method should maintain its member scope.  Missing. A missing \nrestructuring is an atomic transfor\u00admation not presentina transformation rule.Forexample, if Add annotation \nBefore to $method were not present in rule 2, the composite refactoring would be incomplete.  rule \"#1) \nTransform classes matching HelloWorldBean\" no-loop salience 0 when $class : Application Class -Visibility \nis public -Implements \"javax.ejb.SessionBean\"  then Remove interface from $class Update $class end \nrule \"#2) Transform all methods matching ejbActivate\" no-loop salience 10 when $class : Application \nClass -Visibility is public -Implements \"javax.ejb.SessionBean\" $method : Application Method -Name matches \n\"ejbActivate\" -Declaring class is $class -Not annotated with \"javax.ejb.PostActivate\" -Visibility is \npublic -Scope level is member -Return type is \"void\" -Has 0 parameters  then Add annotation \"javax.ejb.PostActivate\" \nto $method Update $class Update $method end rule \"#3) Transform all methods matching ejbRemove\" no-loop \nsalience 10 when $class : Application Class -Visibility is public -Implements \"javax.ejb.SessionBean\" \n $method : Application Method -Name matches \"ejbRemove\" -Declaring class is $class -Not annotated with \n\"javax.ejb.Remove\" -Visibility is public -Scope level is member -Return type is \"void\" -Has 0 parameters \n then Add annotation \"javax.ejb.Remove\" to $method Update $class Update $method end Figure 17. The \nrules learned to transform the EJB example fromversion2 toversion3.  5.1.3 Rule Order Metrics For transformation \nrules, we measured the number of correct and erroneous rule execution orders (i.e., salience values) \nas follows: Correct. A correctly ordered transformation rule does not invalidate other rules when executed. \nFor example, executing rule 2 before rule 1 will not preclude rule 1 from executing.  Erroneous. An \nerroneously ordered transformation rule invalidates another rule whenexecuted.Forexample,ex\u00adecuting rule \n1 before rule 2 would invalidate rule 2 by prematurely removing the super class from the target test \ncase.   5.1.4 Manual Re.nement Metrics To measure the manual effort required by a developer, we counted \nthe number of minor and major re.nements needed for each refactoring as follows: Minor. A minor or small \nre.nement is a required change to a single constraint, restructuring, or rule execution or\u00adder.Forexample, \nchanging Visibility is protected to Visi\u00adbility is at least protected in rule2isa minor re.nement.  \nMajor. Amajor or large re.nement is a required addition or removal of an entire rule. For example, if \nrule 1 were not inferred, a major re.nement would be needed to add it by hand.  Scenario Upgrade Pattern \nJUnit 3 test cases to JUnit 4 Bottom-Up JUnit 3 test suites to JUnit 4 Top-Down JUnit 3 test cases to \nTestNG Bottom-Up JUnit 4 test cases to TestNG Identity Serializable classes to JDO Bottom-Up Serializable \nclasses to JPA Bottom-Up JDO classes to JPA Identity Table 2. The seven different upgrading scenarios \nand their corresponding upgrade patterns. The above criteria were used to measure the accuracy of the \ninferred refactorings for sevenscenarios, showninTable 2 with their corresponding upgrade patterns. The \n.rst two refactoring scenarios focus on upgrading from JUnit3to JU\u00adnit 4, as has been discussed throughout \nthe paper. The third and fourth scenarios focus on switching unit testing frame\u00adworkvendorsfrom JUnittoTestNG[4].TheTestNG \nframe\u00adwork was developed as a next generation testing framework extending beyond unit testing to support \nregression, integra\u00adtion, and functional testing. Recognizing that many exist\u00ading applications have implemented \ntheir testing functionality using JUnit, TestNG provides a hand-written automatic up\u00adgrade utility in \ntheir Eclipse plug-in. However, as of the lat\u00adest version of TestNG, this upgrade utility has several \nsoft\u00adware defects when upgrading JUnit4 test cases,such as not properly removing JUnit annotations, inserting \ndeprecated TestNG annotations, and incorrectly matching test method names. For this scenario, we used \na representative exam\u00adple of a TestNG test case that was identical to the JUnit 4 test case example in \nFigure 1, but with the corresponding TestNG annotations. The remaining three scenarios focus on upgrading \nap\u00adplications to use different enterprise orthogonal persis\u00adtence frameworks. In the .rst of these three \nscenarios, a Serializable class must be upgraded to use Apache s Java Data Objects (JDO) [34] annotations. \nIn the second scenario, the same Serializable class must be upgraded tousethe standardizedJ2EEJava PersistenceAPI(JPA)[15] \nTable 3. The accuracyof the inferred rules for the seven different upgrading scenarios. C=Correct; M=Missing; \nX=Excessive; E=Erroneous; S=Small(Minor); L=Large(Major). Scenario Constraints Restructurings Rules \nRe.nements Target Upgrade C M X E C M E C E S L Test Cases JUnit 3 to 4 JUnit 3 to TestNG JUnit 4 to \nTestNG 29 28 25 0 0 0 5 5 0 0 0 0 11 10 11 0 0 0 0 0 0 5 5 5 0 0 0 5 5 0 0 0 0 Test Suites JUnit 3 to \n4 52 0 0 0 11 0 0 6 0 0 0 Persistence Serializable to JDO Serializable to JPA JDO to JPA 78 78 67 0 0 \n0 0 0 0 0 0 0 14 14 24 0 0 0 0 0 0 8 8 8 1 1 1 1 1 1 0 0 0 Total 357 0 10 0 95 0 0 43 3 13 0 annotations. \nIn the third scenario, a class marked with JDO annotations must be transitioned to use JPA annotations.3 \nTable 3 shows the accuracy of the inferred refactorings. As proved in Lemmas 1-3, our algorithm does \nnot miss any required constraints or restructurings, nor does it infer any erroneous ones. Similarly, \nno major refactoring re.nements are requiredby thedeveloperin anyof the seven scenarios. The inference \nalgorithm generated the same .ve exces\u00adsive constraints in both of the JUnit 3 test case upgrading scenarios. \nTwo of these excessive constraints unnecessar\u00adily limit the applicability of the transformation rules \nfor the setUp and tearDown methods to only protected visibility, even though such methods can be public. \nThe remaining three excessive constraints unnecessarily require the declar\u00ading class of setUp, tearDown, \nand test methods to directly extend TestCase, even though an indirect extension is valid. These two situations \narise due to the small sample size used by our approach (i.e., only two representative examples). Thus, \nwhile the inferred JUnit 3 test case refactorings are correct for the given examples in both scenarios, \n.ve minor re.nements are necessary to make the refactorings general enough to fully capture all valid \ntest cases. For the persistence scenarios, each generated refactor\u00ading requires one transformation rule \nreordering. The inferred rules .nd a naming convention for both the primary database keyand persisted \nelements in a class, however the latter is a more general version of the former(i.e., both conventions \nwill match the primary database key). Thus, to ensure that the primary database key is annotated before \nregularly per\u00adsisted elements, it must be given a slightly higher precedence in the execution order, \nresulting in one required minor re.ne\u00adment for each of the persistence refactorings. The accuracymetrics \npresented above show that the rules automatically inferred by our algorithm have a high degree of accuracy. \nOn average, 97% of the total constraints, re\u00ad 3For the three orthogonal persistence scenarios, we have \nselected a commonly-used subset of functionality of JDO and JPAspeci.cations. The technical report version \nof this paper [38] contains representative examples for these persistence frameworks. structurings, and \nrule orderings require no re.nement by the developer, with .ve out of seven refactoring scenarios re\u00adquiring \nat most one minor change. The accuracy of the in\u00adferred refactorings has an important practical signi.cance. \nUnlike the hand-written upgrade utility providedbyTestNG, the JUnit4 toTestNG refactorings inferredby \nour approach accurately upgrade all JUnit 4 test cases without requiring anymanual re.nement.  5.2 \nCase Studies To demonstrate the effectiveness of a re.ned refactoring, we have upgraded the JUnit 3 test \ncases of four open-source, real-world applications to JUnit 4.Table4 presents the total number of lines \nof testing code, TestCase classes, test methods, setUp methods, and tearDown methods upgraded in each \napplication. Overall, we have successfully upgraded more than 80K lines of Java source code, eliminating \nthe need to perform this refactoring by hand. 6. RelatedWork Our approach relies on automated inference \nof program transformation and structural program differences. While these are broad and extensive research \nareas, to the best of our knowledge, none of the existing techniques in either of these areas are suf.cient \nto automatically upgrade applica\u00adtions that use annotation-based frameworks. 6.1 Technique Classi.cation \nIna comprehensive survey,Visser [41] presentsa taxonomy of program transformation systems. This taxonomy \ndivides program transformations into two broad categories: trans\u00adlation and rephrasing. Translation involves \ntransforming a program from one language to another, whereas rephras\u00ading is concerned with program-improving \ntransformations within the same language. Refactoring is a special subclass of rephrasing that improves \nthe design of a program while maintaining its functionality. Renovation brings a program up to date with \nchanged requirements, and migration ports a program from one language to another. Application Lines \nof Code Test Cases Tests setUp Methods tearDown Methods JHotDraw 7.0.9 378 2 42 2 2 JBoss Drools 4.0.3 \n16,942 101 453 38 11 Apache Ant 1.7.0 21,969 251 1,714 187 99 JFreeChart 1.0.8 41,056 318 1,739 39 1 \nTotal 80,345 672 3,948 266 113 Table 4. Upgrade statistics for the four real-world case studies. Our \napproach entails changing the application code to use a different framework. The program s semantics \nis preserved the program does the same thingbut usinga dif\u00adferent framework, thus classifying our approach \nas a refac\u00adtoring. However, traditional refactoring techniques do not capture large scale changes such \nas the use of a different framework. Upgrading an application that uses a frame\u00adwork based on subtyping \nand naming requirements to an annotation-based framework can also be considered a reno\u00advation. Additionally, \ntransforming legacy applications writ\u00adten in a language without annotations to a language with annotations \nis migration, as the different versions of a lan\u00adguage (e.g., Java 1.4 vs. Java 1.5) can be considered \nas two different languages. Since semantic equality is the main goal of our transformations, we consider \nour approach a refactor\u00ading.  6.2 ProgramTransformation Systems Our technique relies on rule-based program \ntransformations to implement the automatically-inferred refactorings. Mul\u00adtiple program transformation \nsystems have appeared in the research literature.Arepresentativeofa state-of-the-art gen\u00aderal program \ntransformation system is Stratego/XT [42], which enables a variety of transformations from both the translation \nand rephrasing categories. Another example of a multi-language transformation system is DMS R \u00ae[2], which \nfocuses on scalability and ef.ciency. Several other transformation systems target a single lan\u00adguage. \nJaTS [7] provides a Java-like syntax for specifying program transformations in a manner similar to macros. \nIn\u00adject/J [22] enables program transformations at a level higher than that of an abstract syntax tree \n(AST) by providing a meta-model that can be manipulated via a domain-speci.c scripting language. TXL \n[10] uses a .rst order functional programming model, allowing explicit programmer control over several \nphases of the parsing and rewriting process. iXJ [5] aims at providing a visual language to enable inter\u00adactive \nprogram transformations. The Smalltalk Refactoring Browser [32], a key example of a successful application \nof program transformation in a commercial setting, uses an ex\u00adtended Smalltalk syntax to specify AST \npattern trees. The Arcum framework [35] uses declarative pattern matching and substitution to specify \ncrosscutting design idioms. While these systems are extremely powerful tools for im\u00adplementing program \ntransformations, they do not provide support for automatically inferring transformation rules, as required \nby our approach. However, our algorithm is general enough that it could be used to infer transformation \nrules in any of the above systems that support metadata transforma\u00adtions. 6.3 Program Differencing To \ninfer the necessary set of transformations, our technique requires the ability to calculate differences \nbetween two pro\u00adgram versions. Program differencing is an active research area and several differencing \nalgorithms have been proposed recently. Dmitriev describes a make utility for Java [19] that lever\u00adages \nprogram change history to selectively recompile depen\u00addent source .les. UMLDiff[43, 45] detects structural \ndiffer\u00adences between two successive version of a program and ac\u00adcurately models the design evolution \nof the system. DSMD\u00adiff [26] identi.es differences betweendomain-speci.c mod\u00adels. Kim et al. [24] use \na string similarity measure to infer structural changes at or above the level of a method header, represented \nas .rst-order relational logic rules. Since none of these techniques extend beyond the method header \nlevel, they cannot be leveraged to detect upgrade patterns at the required level of granularity. The \nBreakaway tool [13] helps determine the detailed correspondences between two classes through the visualiza\u00adtion \nof similarities between two ASTs. The Change Distill\u00ading algorithm [21] uses an optimized version of \na tree dif\u00adferencing algorithm for hierarchically structured data [8] to extract .ne-grained source code \nchanges. The JDiff [1] al\u00adgorithm uses an augmented representation of a control-.ow graph to identify \nchanges in the behaviors between two ver\u00adsions of an object-oriented program. Since none of these al\u00adgorithms \ncan generalize the inferred differences, theycannot be leveraged to infer generalized refactoring rules. \n 6.4 API Evolution Transitioning a legacy application from a convention-based to an annotation-based \nframework is closely-tied to the prob\u00adlem of API evolution, which has been a highly-active area of recent \nresearch. Explicit documentation (e.g., change an\u00adnotations [9], refactoring tags [33], metapatterns \n[39], and deprecation inlining [29]) has been proposed as a means of facilitating evolution of framework \ndependent applications. More recent approaches aim at automating the inference and application of refactorings. \nCatchUp! [23] records refac\u00adtorings done by framework developers and provides facili\u00adties for replaying \nthem on the client to update application code. Extension rules [11, 12] enable generalization trans\u00adformations \nthat add variability and .exibility into the class structure of a framework, thereby ensuring consistencywith \nclient applications. RefactoringCrawler [16] combines syn\u00adtactic and semantic analyses to detect refactorings \nin evolv\u00ading components. RefacLib [37] follows a similar approach, but replaces semantic analysis with \nvarious analysis heuris\u00adtics. MolhadoRef [17] is a software con.guration manage\u00adment system that reduces \nmerge con.icts andfacilitates pro\u00adgram evolution comprehension by tracking refactorings and being aware \nof program entities. ReBA [18] generates com\u00adpatibility layers that ensure binary compatibility between \nnew library APIs and old clients, similarly to a binary adap\u00adtation layer in [14] that adapts legacybinaries \nfor new frame\u00adwork releases. Diff-CatchUp [44] leverages design differ\u00adences inferred by the UMLDiff \nalgorithm described above to apply a set of heuristics to suggest API replacements in response to compilation \nerrors. While these approaches have all been very effective for their target domains, theydiffer from \nour approach. Speci.\u00adcally, they only support simple refactorings such as Change Signature, and they \ndo not combine and generalize these refactorings, as required for upgrading applications that use annotation-based \nframeworks. 6.5 Programming by Demonstration Inferring a set of rules from a pair of examples bears \nsimi\u00adlarity to programming by demonstration [25]. For a system to be classi.ed as programming by demonstration, \nit must meet two criteria. First, the programmer must create the ap\u00adplication via the same commands or \nprocess that would be used to perform the task manually. Second, the programmer must write the program \nby giving an example of the desired behavior. Since Rosemari enables programmers to use the standard \nEclipse interface to input representative examples, it could be classi.ed as a refactoring by demonstration \nsys\u00adtem. 7. FutureWork Currently, our inferencing algorithm supports onlyJava5an\u00adnotations. In the future, \nwe plan to extend this work to sup\u00adport the upcoming Java7 annotations that enable annotating a broader \nset of program elements. However, our structural differencing algorithm will need to be extended to handle \nan\u00adnotated local variables in method bodies, possibly requiring static analysis. In addition, many frameworks \nthat used XML-based metadata rather than type and naming requirements in their previousversionshave since \ntransitionedto annotations.We plan to extend our approach to automatically infer refactor\u00adings for legacy \napplications that use XML-based metadata. Such an extension could potentially be enabled by extending \nthe notion of a prior representative example to include XML snippets, and subsequently incorporating \nXML analysis into our algorithm. Finally, .nding a more uni.ed approach to inferring refactoring rules \nhas great potential bene.ts. This may be realized either by replacing the current pattern-based ap\u00adproach \nwith a more sophisticated analysis, introducing a step for inputting domain-speci.c knowledge, or adding \nalgo\u00adrithmic support for multiple representative examples. These enhancements could eliminate the need \nfor a developer to decide on which upgrade pattern to use, .attening the learn\u00ading curve for using our \nsystem and increasing the possibility of widespread adoption. 8. Conclusions This paper presented Annotation \nRefactoring, an approach to solving the Vendor and Version lock-in problems asso\u00adciated with annotation-based \nframeworks. Our approach is based on the wide availability of upgrade guides contain\u00ading examples of \nlegacy classes and their upgraded versions. Leveraging these examples, our tool enables framework de\u00advelopers \nto generate refactoring utilities capable of automati\u00adcally upgrading legacyapplications. As demonstrated \nby our case studies, the inferred refactorings are highly-accurate and can effectively upgrade large-scale, \nreal-world applica\u00adtions. Acknowledgments The authors would like to thank Taweesup Term Apiwat\u00adtanapong, \nGodmar Back,PatrickYaner,Dave Zook, and the anonymous reviewers for their useful comments that helped \nimprove this paper. This research was supported by the De\u00adpartment of Computer Science atVirginiaTech. \nReferences [1] T. Apiwattanapong, A. Orso, and M. J. Harrold. A differencing algorithm for object-oriented \nprograms. In Automated Software Engineering, 2004. Proceedings. 19th International Conference on, pages \n2 13, 2004. [2] I. D. Baxter, C. Pidgeon, and M. Mehlich. DMS: Pro\u00adgram transformations for practical \nscalable software evolution. In ICSE 04: Proceeding of the 26th In\u00adternational Conference on Software \nEngineering, pages 625 634, Los Alamitos, CA, USA, 2004. IEEE Com\u00adputer Society. [3] K. Beck and E. Gamma. \nTest Infected: Programmers love writing tests. Java Report, 3(7):37 50, 1998. [4] C. Beust and H. Suleiman. \nNext GenerationJavaTest\u00ading:TestNG and Advanced Concepts. Addison-Wesley Professional, 2007. [5] M. Boshernitsan, \nS. L. Graham, and M. A. Hearst. Aligning development tools with the way programmers think about code \nchanges. In CHI 07: Proceedings of the SIGCHI Conference on Human Factors in Com\u00adputing Systems, pages \n567 576, New York, NY, USA, 2007.ACM. [6] W. Brown, R. Malveau, H. McCormick III, and T. Mowbray. AntiPatterns: \nrefactoring software, archi\u00adtectures, and projects in crisis. JohnWiley&#38;Sons, Inc. NewYork, NY, USA, \n1998.  [7] F. Castor and P. Borba. A language for specifying Java transformations. In V Brazilian Symposium \non Programming Languages, pages 236 251, 2001. [8] S. S. Chawathe, A. Rajaraman, H. Garcia-Molina, and \n J. Widom. Change detection in hierarchically struc\u00adtured information. In SIGMOD 96: Proceedings of the \n1996ACM SIGMOD international conference on Man\u00adagement of data, pages 493 504, NewYork, NY, USA, 1996.ACM. \n [9] K. Chow and D. Notkin. Semi-automatic update of applications in response to library changes. In \nICSM 96: Proceedings of the 1996 International Conference on Software Maintenance, page 359,Washington, \nDC, USA, 1996. IEEE ComputerSociety. [10] J. Cordy. The TXL source transformation language. Science of \nComputer Programming, 61(3):190 210, August 2006. [11] M. Cort\u00b4es,M.Fontoura, andC.Lucena. Using refactor\u00ading \nand uni.cation rules to assist framework evolution. SIGSOFT Softw. Eng. Notes, 28(6):1 5, 2003. [12] \nM. Cort\u00b4es,M.Fontoura, andC. Lucena. A Rule-based Approach to Framework Evolution. Journal of Object \nTechnology (JOT), 5(1), jan-feb 2006. [13] R. Cottrell, J. J. C. Chang, R. J. Walker, and J. Den\u00adzinger. \nDetermining detailed structural correspondence for generalization tasks. In ESEC-FSE 07: Proceed\u00adings \nof the the 6th ACM SIGSOFT Symposium on the Foundations of Software Engineering, pages 165 174, NewYork, \nNY, USA, 2007.ACM. [14] I.S\u00b8avga and M. Rudolf. Refactoring-based support for binary compatibility in \nevolving frameworks. In GPCE 07: Proceedings of the 6th International Con\u00adference on Generative Programming \nand Component Engineering, pages 175 184, New York, NY, USA, 2007.ACM. [15] L. DeMichiel and M. Keith. \nJSR 220: Enterprise JavaBeans 3.0, 2008. http://jcp.org/aboutJava/ communityprocess/final/jsr220/index.html. \n[16] D. Dig, C. Comertoglu, D. Marinov, and R. Johnson. Automated detection of refactorings in evolving \ncom\u00adponents. In ECOOP, pages 404 428, 2006. [17] D. Dig, K. Manzoor, R. Johnson, and T. N. Nguyen. Refactoring-aware \ncon.guration management for object-oriented programs. In ICSE 07: Proceed\u00adings of the 29th International \nConference on Software Engineering, pages 427 436, Washington, DC, USA, 2007. IEEE Computer Society. \n[18] D. Dig, S. Negara, V. Mohindra, and R. Johnson. ReBA: refactoring-aware binary adaptation of evolving \nlibraries. In ICSE 08:Proceedings of the 30th interna\u00adtional conference on Software engineering, pages \n441 450, NewYork, NY, USA, 2008.ACM. [19] M. Dmitriev. Language-speci.c make technology for the Java \nprogramming language. SIGPLAN Not., 37(11):373 385, 2002. [20] Eclipse Foundation. Eclipse Java development \ntools, March 2008. http://www.eclipse.org/jdt. [21] B. Fluri, M.Wuersch, M. Pinzger, and H. Gall. Change \ndistilling: Tree differencing for .ne-grained source code change extraction. IEEE Trans. Softw. Eng., \n33(11):725 743, 2007. [22] T. Genssler and V. Kuttruff. Source-to-source trans\u00adformation in the large. \nIn Modular Programming Lan\u00adguages, pages 254 265. Springer-Verlag, 2003. [23] J. Henkel and A. Diwan. \nCatchUp!: capturing and re\u00adplaying refactorings to support API evolution. In ICSE 05: Proceedings of \nthe 27th International Conference on Software Engineering, pages 274 283, New York, NY, USA, 2005.ACM. \n[24] M. Kim, D. Notkin, and D. Grossman. Automatic infer\u00adence of structural changes for matching across \nprogram versions. In The 29th International Conference on Soft\u00adware Engineering (ICSE 07), pages 333 \n343, 2007. [25] H. Lieberman. Your Wish is My Command: Program\u00adming By Example. Morgan Kaufmann, 2001. \n[26]Y.Lin,J.Gray,andF. Jouault. DSMDiff:Adifferentia\u00adtion tool for domain-speci.c models. EuropeanJournal \nof Information Systems, 16:349 361, 2007. [27] D. Panda, D. Clarke, and M. Schincariol. EJB 3.0 migration.Technical \nreport,Oracle, October 2005. [28] R. Pawlak, C. Noguera, and N. Petitprez. Spoon: Pro\u00adgram analysis and \ntransformation in Java. Technical report, INRIA Research Report, 2006. [29] J. H. Perkins. Automatically \ngenerating refactorings to support API evolution. In PASTE 05: Proceed\u00adings of the 6th ACM SIGPLAN-SIGSOFTWorkshop \non Program Analysis for SoftwareTools andEngineering, pages 111 114, NewYork, NY, USA, 2005.ACM. [30] \nM. Proctor, M. Neale,P. Lin, and M. Frandsen. Drools Documentation. Technical report, JBoss Inc., 2006. \n[31] C. Richardson. Untangling enterprise Java. Queue, 4(5):36 44, 2006. [32] D. Roberts and J. Brant. \nTools for making impossi\u00adble changes -experiences with a tool for transforming large Smalltalk programs. \nSoftware, IEE Proceedings -, 151(2):49 56, 2004. 1462-5970. [33] S. Roock and A. Havenstein. Refactoring \ntags for auto\u00admatic refactoring of framework dependent applications. In Proc. Int l Conf. eXtreme Programming \nand Flexible Processes in Software Engineering (XP), 2002. [34] C. Russell. Java Data Objects 2.1, June \n2007. http: //db.apache.org/jdo/specifications.html. [35] M. Shonle, W. G. Griswold, and S. Lerner. Beyond \nrefactoring: a framework for modular maintenance of crosscutting design idioms. In ESEC-FSE 07: Pro\u00adceedings \nof the the 6th ACM SIGSOFT Symposium on the Foundations of Software Engineering, pages 175 184, 2007. \n[36] R. Stuckert. JUnit reloaded, December 2006. http://today.java.net/pub/a/today/2006/ 12/07/junit-reloaded.html. \n[37] K. Taneja, D. Dig, and T. Xie. Automated detection of API refactorings in libraries. In ASE 07: \nProceed\u00adings of the 22nd IEEE/ACM International Conference on Automated Software Engineering. IEEE Computer \nSociety, 2007. [38]W.TanseyandE.Tilevich. Refactoringobject-oriented applications for metadata-based \nframeworks.Technical report,VirginiaTech, January 2008. [39]T. Tourw\u00b4e and T. Mens. Automated support \nfor framework-based software evolution. In ICSM 03: Proceedings of the International Conference on Soft\u00adware \nMaintenance, page 148, Washington, DC, USA, 2003. IEEE Computer Society. [40] D. Vines and K. Sutter. \nMigrating legacy Hiber\u00adnate applications to OpenJPA and EJB 3.0, August 2007. http://www.ibm.com/developerworks/ \nwebsphere/techjournal/0708_vines/0708_ vines.html. [41]E.Visser.A surveyof strategiesin programtransforma\u00adtion \nsystems. Electronic Notes in Theoretical Computer Science, 57, 2001. [42] E. Visser. Program transformation \nwith Stratego/XT: Rules, strategies, tools, and systems in StrategoXT-0.9. In Domain-Speci.c Program \nGeneration, volume 3016 of Lecture Notes in Computer Science, pages 216 238. Spinger-Verlag, June 2004. \n[43] Z. Xing and E. Stroulia. UMLDiff: an algorithm for object-oriented design differencing. In ASE 05: \nPro\u00adceedings of the 20th IEEE/ACM International Confer\u00adence on Automated Software Engineering, pages \n54 65, 2005. [44] Z. Xing and E. Stroulia. API-evolution support with Diff-CatchUp. IEEE Trans. Softw. \nEng., 33(12):818 836, 2007. [45] Z. Xing and E. Stroulia. Differencing logical UML models. Automated \nSoftware Engineering, 14(2):215 259, 2007.    \n\t\t\t", "proc_id": "1449764", "abstract": "<p>Since annotations were added to the Java language, many frameworks have moved to using annotated Plain Old Java Objects (POJOs) in their newest releases. Legacy applications are thus forced to undergo extensive restructuring in order to migrate from old framework versions to new versions based on annotations (<i>Version Lock-in</i>). Additionally, because annotations are embedded in the application code, changing between framework vendors may also entail largescale manual changes (<i>Vendor Lock-in</i>).</p> <p>This paper presents a novel refactoring approach that effectively solves these two problems. Our approach infers a concise set of semantics-preserving transformation rules from two versions of a single class. Unlike prior approaches that detect only simple structural refactorings, our algorithm can infer general composite refactorings and is more than 97% accurate on average. We demonstrate the effectiveness of our approach by automatically upgrading more than 80K lines of the unit testing code of four open-source Java applications to use the latest version of the popular JUnit testing framework.</p>", "authors": [{"name": "Wesley Tansey", "author_profile_id": "81388600058", "affiliation": "Virginia Tech, Blacksburg, VA, USA", "person_id": "P1223200", "email_address": "", "orcid_id": ""}, {"name": "Eli Tilevich", "author_profile_id": "81100650102", "affiliation": "Virginia Tech, Blacksburg, VA, USA", "person_id": "P1223201", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449788", "year": "2008", "article_id": "1449788", "conference": "OOPSLA", "title": "Annotation refactoring: inferring upgrade transformations for legacy applications", "url": "http://dl.acm.org/citation.cfm?id=1449788"}