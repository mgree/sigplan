{"article_publication_date": "10-19-2008", "fulltext": "\n Design and ImplementationofTransactional Constructsfor C/C++ Yang Ni James Cownie Adam Welc Ali-Reza \nAdl-Tabatabai Moshe Bach Sion Berkowits Robert Geva SergeyKozhukow Ravi Narayanaswamy JeffreyOlivier \nSerguei Preis Bratin Saha Ady Tal Xinmin Tian Intel Corporation {yang.ni,adam.welc,ali-reza.adl-tabatabai,moshe.bach, \n sion.bar-kovetz,james.h.cownie,robert.geva,sergey.s.kozhukow, ravi.narayanaswamy,je.rey.v.olivier,serguei.v.preis,bratin.saha,ady.tal,xinmin.tian}@intel.com \nAbstract This paper presents a software transactional memory sys\u00adtem that introduces .rst-class C++language \nconstructs for transactional programming.We describe new C++ language extensions, a production-quality \noptimizing C++ compiler that translates and optimizes these extensions, and a high\u00adperformance STM runtime \nlibrary. The transactional lan\u00adguage constructs support C++ language features including classes, inheritance, \nvirtual functions, exception handling, and templates. The compiler automatically instruments the programfor \ntransactionalexecutionand optimizesTMover\u00adheads. The runtime library implements multiple execution modes \nand implements a novel STM algorithm that sup\u00adports both optimistic and pessimistic concurrency control. \nThe runtime switches a transaction s execution mode dy\u00adnamically to improve performance and to handle \ncalls to precompiled functions andI/O libraries.We presentexper\u00adimental results on8 cores(two quad-core \nCPUs) runninga set of 20 non-trivial parallel programs. Our measurements show that our system scales \nwell as the numbers of cores increases and that our compiler and runtime optimizations improve scalability. \nCategories and Subject Descriptors D.3.3[PROGRAM-MING LANGUAGES]: Language Constructs and Features Concurrent \nprogramming structures General Terms Design, Languages, Performance Keywords Transactional memory, C/C++ \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page.To copyotherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA \n08, October 19 23, 2008, Nashville,Tennessee, USA. Copyright c &#38;#169; 2008ACM 978-1-60558-215-3/08/10... \n$5.00 1. Introduction Transactional Memory (TM) has received signi.cant atten\u00adtion recently as a simpler \nconcurrency control mechanism compared to locks. Locks have several pitfalls: Coarse\u00adgrained locking \ndoesn t scale to a large numbers of cores, while .ne-grained locking risks introducingbugs and com\u00adplicating \ncomposition of software modules. By providing automatic .ne-grained concurrencycontrol, TM avoids the \nproblems associated with locks and allows safe and scalable composition of software modules. Recent work \nhas extended various languages with new block constructs for expressing transactions. Much of this work \nhas focused on managed languages such as Java [20], C# [22], Haskell[21], and Caml [39], and onC[46,3, \n35, 15, 28]. Only quite recently have TM language proposals for C++ started to emerge [10]. Needless \nto say,Cand C++ are important languages because of their prevalence in systems code and performance-critical \napplications. Some prior work has supported transactional program\u00adming in C and C++ by providing an API \nrather than lan\u00adguage constructs [13, 31, 11, 16]. API approaches have al\u00adlowed rapid prototyping of \nSTM algorithms and analysis of their performance. But such APIs do not deliver completely on the main \ngoal of TM, which is to simplify concurrent programming. Manually adding calls to TM API functions imposesa \nsigni.cantburdenonthe programmerandis error prone. In this paper, we present a complete software transac\u00adtional \nmemory (STM) system that adds .rst-class language constructs for transactional programming to C++. The \nsys\u00adtem consists of new C++ language extensions, a compiler that translates and optimizes these extensions, \nand a high\u00adperformance STM runtime library. Compared to prior work on C, the new language constructs \nsupport C++ language features such as classes, inheritance, virtual functions, ex\u00adception handling, and \ntemplates.We also provide constructs that allow the programmer to create ef.cient transactional versions \nof existing libraries. This paper makes the follow\u00ading contributions: We introduce new language extensions \nto support trans\u00adactional memory in C++. Unlike prior work that focuses on C, our language extensions \nsupport C++ classes, vir\u00adtual functions, inheritance, templates, andexception han\u00addling. The language \nconstructs allow the programmer to call existing precompiled code inside transactions, in\u00adcluding code \nthat may perform unrestricted I/O. The sys\u00adtem also provides constructs for the expert library devel\u00adoper \nto develop versions of their libraries optimized for execution inside transactions. (Section 2)  We \nextend an existing, high-performance production C/C++ compiler to support our new transactional lan\u00adguage \nconstructs. We describe novel code generation techniques and compiler optimizations for these new lan\u00adguage \nconstructs. (Section 3)  We presenta novel STM runtime library that implements both optimistic and pessimistic \nconcurrency control. The runtime also implements a serial execution mode to support calls to legacy binaries \nand to support unre\u00adstricted I/O operations inside transactions. The runtime can switch between these \nexecution modes dynamically to optimize performance.We presenta novelTM library API that supports this \n.exible concurrencycontrol model while allowing compiler optimizations. (Section4)  We present a thorough \nexperimental evaluation of our STM system on a large set of parallel programs ported to use our language \nextensions. Our measurements demon\u00adstrate that our system scales well across these programs and that \nour optimizations are important for performance. Our measurements also show that optimistic concurrency \ncontrol performs better than pessimistic concurrency control though our pessimistic concurrency control \nal\u00adgorithm performs competitively in many cases. (Section 5)  We have released an earlier version of \nour system, in\u00adcluding the compiler and runtime described in this paper at the Intel WhatIf web site1. \nEarly adopters can download these tools and experiment with transactional programming in C++. 2. Transactional \nC/C++ This section describes our language extensions to support transactional memory in C++. Prior systems \nsupport basic mechanisms forC[46,3].We re.ne andextend these mech\u00adanisms to provide .rst-class language \nconstructs (rather than compiler pragmas) and to add full support for C++ classes, virtual functions, \ninheritance, templates, and exception han\u00addling. 1The URL for the release of our system is http://whatif.intel.com. \n2.1 Atomic blocks The tm atomic statement de.nes a basic atomic block, similarly to the atomic construct \npreviously de.ned in the literature[2,22]and introducedasaClanguage pragmain [46]: __tm_atomic { // block \nof arbitrary C/C++ statements } The TM system executes atomic blocks as transactions and isolates concurrently \nexecuting transactions from each other with the net effect that all the operations in one trans\u00adaction \nappear to complete either before or after all the oper\u00adations in anyother transaction. Within each atomic \nblock, the compiler instruments each shared-memory access so that its execution is delegated to the TM \nruntime. The TM runtime tracks all transactional ac\u00adcesses and detects con.icting accesses among concurrently \nexecuting transactions.Twotransactions con.ictiftheyboth access the same memory location at the same \ntime and at least one of them writes to that location. On a potential con\u00ad.ict, the TM runtime transparently \nrolls back the side effects of one of the con.icting transactions and re-executes it until it succeeds \nwithout con.icts. Atomic blocks can contain arbitrary code of all regu\u00adlar C/C++ statements, including \ndirect and indirect function calls, and virtual function calls. This includes calls to pre\u00adcompiled libraries \n(i.e., code that has not been compiled by the transactional compiler) and those that perform arbitrary \nI/O operations. Since the TM runtime cannot track the ac\u00adcesses inside precompiled code or roll back \nI/O operations, calling into such code inside a transaction causes the run\u00adtime to serialize execution \nof the transaction with respect to other transactions no other transactions are allowed to be in-.ight \nconcurrently withthe serial one. Section4describes the details of this serial execution mode. 2.2 Abort \nstatements The tm abort statement (a user abort)allows the pro\u00adgrammer to roll back an atomic block explicitly. \nThis state\u00adment must appear in the lexical scope of an atomic block. It rolls back all side effects of \nthe atomic block that stati\u00adcally encloses it and transfers control to the statement im\u00admediately following \nthe block. It ends the transaction if the enclosing atomic block is the outermost atomic block. Because \nthe runtime cannot log the side effects of pre\u00adcompiled functions, the tm abort statement can execute \nonly if the innermost atomic block containing it has not called a precompiled function (unless that function \nis a tm pure function as described in Section 2.4.2).Aruntime errorwill occurifan atomic blockexecutesauser \nabort after it has called a precompiled function: __tm_atomic { print( HelloWorld! ); __tm_abort; // \nerror (runtime failure) } This does not preclude calling a precompiled function in an atomic block that \nis at an outer dynamic nesting level relative to the block containing the abort statement: __tm_atomic \n{ print( HelloWorld! ); __tm_atomic { __tm_abort; // OK } } Nested atomic blocks have closed nesting \nsemantics [37], which means that the side effects of a nested transaction commit become visible only \nwhen the dynamically outer\u00admost transaction commits. Abort statements allow a pro\u00adgrammer to roll back \na transaction partially by aborting the innermost nested atomic block. The compiler and runtime, therefore, \nmay not .atten those nested atomic blocks that contain user abort statements. 2.3 Single lock semantics \nAtomic blocks provide single lock atomicity (SLA) seman\u00adtics[34]:Aprogrambehavesasifasinglegloballockguards \neach atomic block. This guarantees that programs that are race free under a single global lock will execute \ncorrectly under transactional execution. These semantics support the privatization and race free publication \npatterns [34].Atriv\u00adial implementation of atomic blocks can use a single global lock to implement isolation \n(though such an implementation must still perform undo logging to support abort statements). Infact the \nserialexecution mode (which supports calling pre\u00adcompiled binaries)falls backto usinga single global \nlockto implement atomic blocks. Consistent with the emerging C/C++ memory model speci.cation [8], SLA \nsemantics provides no guarantees for programs containing data races. In the presence of data races between \ntransactions and non-transactional code, code exe\u00adcuting outside a transaction may see speculative or \ninterme\u00addiate values produced by a transaction, and it may violate the isolationofa transactionby writingto \nmemory locations accessed inside a transaction. To support SLA semantics correctly, the STM implemen\u00adtation \nmust guarantee several important safety properties, namely privatization safety, granular safety, and \nobservable consistency[34]. These safety properties ensure that code that is race free under a single \nglobal lock remains race free under transactional execution; that is, they ensure that the STM implementation \ndoes not introduce a data race into a program thatis otherwise race free undera single lock. Most prior \nSTM systems did not properly maintain these proper\u00adties and thus cannot be used to implement single global \nlock semantics for C/C++ atomic blocks. 2.4 Function annotations To optimize code generation and allow \nthe user to opti\u00admize calls to functions that do not require instrumentation, our system introduces function \nannotations (similar to [46]). Anygiven function can be called from both inside and out\u00adside of an atomic \nblock.To support both transactional and non-transactionalexecutionof functionsef.ciently,the com\u00adpiler \ngenerates two versions of each function, one version with instrumentation for transactional execution \nand one version without. While just-in-time compilers can decide whether and when to duplicate code at \nrun time [2], static C/C++ compilers must make this decision at compile time. To avoid unnecessary code \nduplication, we introduce an an\u00adnotation to denote functions (including class member func\u00adtions) that \ncan be called from inside transactions. All an\u00adnotations are speci.ed using the declspec keyword on Windows \nand the attribute keyword on Linux. The examples that follow use theWindows notation. 2.4.1 tm callable \nAtm callable function is one that the programmer intends to call from inside a transaction and would \nlike compiled for ef.cient transactional execution. The compiler generates two versions of the code for \nsuch functions, one with instru\u00admentation and one without. The compiler uses a mangled name for the transactional \nclone of a tm callable func\u00adtion. The name mangling simply adds a transactional suf\u00ad.x to the function \nname and was designed to work correctly with the template name mangling for tm callable function templates. \nIf a tm callable function calls an unannotated function, the compiler generates code that triggers serial \nex\u00adecution unless it knows that the called function does not re\u00ad quire instrumentation or it has automatically \ngenerated an instrumented version of the called function. 2.4.2 tm pure Atm pure function is one that \nthe programmer asserts can execute safely inside a transaction without requiring trans\u00adactional instrumentation \nand without switching to serial ex\u00adecution. The programmer takes full responsibility for the be\u00adhavior \nof tm pure functions. The main intent of tm pure is to provide the programmer a way to optimize calls \nto pre\u00adcompiled library functions (such as math functions) that are known to be pure. The programmer \ncan safely annotate a function as tm pure if it does not access anystatic or non\u00adlocal memory or if it \nis pure from the perspective of higher\u00adlevel program logic (e.g., it accesses only immutable global variables). \nThe compiler can not validate the purity of all functions; however, to help .ag potential errors, it \nwill issue awarningifit compilesthe de.nitionofa tm pure function and detects thatitwouldhaveadded transactionalinstrumen\u00adtation \nto that function. 2.4.3 tm unknown The tm unknown attribute annotates a function whose TM properties \nare unknown (e.g., it is unclear to the programmer whether the function is going to be called from inside \na transaction, or the function is in a library and cannot be recompiledbytheTM compiler.)An unannotated \nfunctionis implicitlya tm unknown function. The compiler may decide to createan instrumentedversionofa \ntm unknown function. This annotation allows the programmer to override class\u00adlevel annotations described \nin Section 2.5. 2.5 Class annotations The tm callable annotation is allowed on class declara\u00adtions including \nC++ template classes. All member functions ofa tm callable class, both virtual and non-virtual, are im\u00adplicitly \ntm callable. This is equivalent to annotating each member function of the class as tm callable. This \neases C++ programming as it allows the programmer to annotate once at the classlevel rather than annotating \neach member function. In the following class declaration, for example, both foo() and bar() are implicitly \ntm callable: __declspec(tm_callable) class C { void foo(); void bar(); }; Derived classes inherit the \nclass-level tm callable an\u00adnotation. In case of multiple inheritance, a derived class in\u00adherits the tm \ncallable annotation if at least one of its base classes is annotated with tm callable. Function-level \nannotations override the class-level an\u00adnotation. In the following class declaration, for example, function \nfoo() gets the class-level tm callable annotation while function bar() s class-level annotation gets \noverrid\u00adden with tm unknown: __declspec(tm_callable) class C { void foo(); __declspec(tm_unknown) void \nbar(); }; 2.6 Virtual function overriding and inheritance Virtual function overriding and inheritance \nintroduce addi\u00adtional subtleties.Avirtual function canlegallyoverride an\u00adother virtual function if and \nonly if the two have compatible TM annotations. Table 1 shows the compatibility rules. In general, function \noverriding is legal if and only if the virtual function in the derived class has the same annotation \nas in the base class, or the function in the base class is tm unknown In the case of multiple inheritance, \na function in the de\u00adrived class may override virtual functions in the base classes onlyifthe rules speci.edinTable1hold \nseparatelyforev\u00adery pair of functions in the base and derived class. Consider a more complicated example \nthat combines these rules: derived class base class tm callable tm pure tm unknown tm callable yes no \nno tm pure no yes no tm unknown yes yes yes  Table 1. Compatibility rules for virtual function annotations \n__declspec(tm_callable) class A { __declspec(tm_unknown) virtual void foo(); }; class B { __declspec(tm_callable) \nvirtual void foo(); }; class C: A, B { void foo(); }; class D: A, B { __declspec(tm_pure) void foo(); \n// Error! }; In this example, class C inherits the tm callable at\u00adtribute from class A,soC::foo() is \nimplicitly tm callable. Accordingtothe rulesinTable1,a tm callable function (C::foo()) may override both \ntm unknown (A::foo()) and tm callable (B::foo()). At the same time, it is an error to annotate D:foo() \nwith tm pure, because it is in\u00adcompatible with tm callable (B::foo()). 2.7 Templates The function annotations \ncan be used on template functions, and the the tm callable annotation can be used on tem\u00adplate classes. \nThe following example shows how a function annotation can be used with function templates: template <class \nT> __declspec(tm_callable) T max(T a, T b) { T result; result = (a>b)? a : b; return (result); } 2.8 \nException handling Uncaught exceptions that propagate out of an atomic block cause the atomic block to \ncommit its side effects. The al\u00adternative strategy providesfailure atomicityby rolling back the atomic \nblock ssideeffectswhenanexception propagates out of the atomic block. Our justi.cations for committing \nthe transaction are the following: (1) Committing is consis\u00adtent withasingle lock semantics model as \nlock-based critical sections do not roll back side effects on an uncaught excep\u00adtion; (2) it is impossible \nto roll back the state of an atomic block if it has executed any tm unknown functions in serial mode \nwithout instrumentation; (3) rolling back the transac\u00ad void addCommitAction(void (*)(void*),void*) void \naddUndoAction(void (*)(void*),void*) Figure1. API for adding user actions for tm wrap functions tion \ncould result in an inconsistent state for the thrown ex\u00adception object (whose state may also be rolled \nback); and (4) we believe that it is better to provide a separate explicit mechanism for roll back than \nto overload exceptions with roll back the programmer canalways catchexceptions and explicitly roll back \nside effects using the tm abort state\u00adment. 2.9 Supportfor writing transactional libraries The system \nprovides an additional annotation along with an API that together allow the programmer to create optimized \ntransactionalversionsof libraries. Section4.5 describeshow we use these features to create a transactional \nversion of the memory management library. The system also provides an additional statement, tm waiver, \nsupporting escape ac\u00adtions that allow programmers to reduce transactional instru\u00admentation overhead whenever \nit is considered safe to do so. These featuresare intendedforexperts(e.g.,librarydevelop\u00aders) as programmers \nwho use these features must understand some of the details of how TM systems are implemented. 2.9.1 Function \nwrappers The tm wrap annotation declares a transactional wrapper function. Calls inside transactions \nto a wrapped function are redirected to the user-speci.ed wrapper function that escapes the transaction. \nTransactions that execute in serial mode may or may not execute wrapper functions as such transactions \nmight execute uninstrumented code. The fol\u00adlowing example shows how to declare a transactional wrap\u00adper \nfooTxn() for some function foo(): __declspec(tm_wrap(foo)) void fooTxn(); After seeing this declaration, \nthe compiler translates ev\u00adery in-transaction call to foo() into a call to fooTxn(), which executes without \nTM instrumentation. Like tm pure functions, the wrapper function is exe\u00adcuted without transactional instrumentation \nso the program\u00admer takes responsibility for their correct behavior. Inside a wrapper function, the programmer \nmust be careful not to ac\u00adcess memory that has been accessed transactionally as such an access may see \nan inconsistent or speculative value; that is, the programmer must segregate the data accessed inside \nthe wrapper function from data that is accessed transaction\u00adally by anythread including the thread making \nthe call. The programmer must also not execute anyatomic blocks inside the wrapper function.  2.9.2 \nUndo and commit actions Inside wrapper functions, the programmer must register the proper undo and commit \nactions to roll back or .nalize the effects of the wrapper function on an abort or commit, respectively.Acommit \nactionexecutes when the transaction commits.Anundo actionexecuteswhenthe transaction rolls back due to \na user abort or a con.ict. The TM library exports an API (Figure 1) that the pro\u00adgrammer can use to \nregister commit and undo actions inside of wrapper functions. addCommitAction adds an entry to the commit \naction log. addUndoAction adds an entry to the undo action log. In both functions, the .rst parameter \nis a pointer to the function that implements the action, and the second parameter is an argument that \nis passed to the action when it executes. Serial mode transactions containing no tm abort state\u00adments \ndo not roll back because they are guaranteed to com\u00admit. The undo actions for such transactions are ignored \nand their commit actions may execute immediately without ac\u00adtually being added to the commit action log. \n 2.9.3 Escape actions Certain data accesses inside of transactions, such as ac\u00adcesses to private or read-only \ndata, do not need to be in\u00adstrumented and yet the compiler may not always be able to detect such accesses \nautomatically. The tm waiver state\u00adment allows the programmers to convey such application\u00adlevel knowledge \nto the compiler and avoid unnecessary instrumentation-related overhead. The tm waiver state\u00adment de.nes \na block of code that will not be instrumented by the compiler and can be used by programmers to op\u00adtimize \na transactional application. Code regions de.ned by the tm waiver statement in effect bypass the transactional \nconcurrencycontrol mechanisms and as such should be used with caution. 3. TM compiler This section describes \nthe compiler support required for translating and optimizing the transactional language con\u00adstructs. \nThe compiler translates the transactional language constructs into code instrumented with calls to an \nSTM run\u00adtime. The instrumentation is amenable to many classical optimizations, such as redundancy elimination, \ndead code elimination, and memory optimizations. The interface be\u00adtween the compiler and runtime is designed \nto support com\u00adpiler optimizations and at the same time to support multiple STM algorithms. 3.1 Compiler-runtime \nABI Prior work [46] tightly coupled the compiler and generated code to the STM algorithms to maximize \ncompiler optimiza\u00adtion opportunities.The compilerin[46],forexample, inlined the STMfast paths into the \nprogram binary andexposed the operations that constitute the underlying STM algorithm to compiler optimizations. \nThis binds both the generated code and the compiler to one particular STM algorithm and pre\u00adcludes changing \nthe STM runtime or its algorithms without changing the compiler and the generated code. TxnDesc* getTransaction() \nint begin(TxnDesc*,int) void commit(TxnDesc*) int beginInner(TxnDesc*,int) void commitInner(TxnDesc*) \nvoid userAbort(TxnDesc*) void switchToSerialMode(TxnDesc*) void write<Type>(TxnDesc*,Type*,Type) Type \nread<Type>(TxnDesc*,Type*) void memcpy(TxnDesc*,void*,void*,size t) void logValue<Type>(TxnDesc*,Type*) \nvoid logBulk(TxnDesc*,void*,size t) void writeAW<Type>(TxnDesc*,Type*,Type) Type readAR<Type>(TxnDesc*,Type*) \nType readAW<Type>(TxnDesc*,Type*) Type readFW<Type>(TxnDesc*,Type*) Figure 2. Compiler-runtime ABI In \ncontrast,the compiler-runtimeABIinthiswork decou\u00adples the compiler and generated code from the runtime. \nThis approach sacri.ces some compiler optimization opportuni\u00adtiesbut signi.cantly increases the .exibility \nof the runtime: It allows the runtime to switch STM algorithms dynamically, and it allows the runtime \nlibrary developer to replace the li\u00adbrary in the .eld if necessary. We believe that this is the right \ntrade off to make. At high thread counts, the STM algorithms will likely in.uence end-to-end application \nperformance more than compiler op\u00adtimizations that are designed to reduce single-thread over\u00adheadsof \nthe STM.Forlow threads counts,a single global lock mode executing uninstrumented code may yield even \nbetter performance than an STM. Moreover, research on STM algorithms will likely continue into the future, \nand it is premature to commit to a single STM algorithm as the best; therefore, it is best tokeep the \ngenerated code .exible so that new STM algorithms can be linked dynamically. Although we limit our discussion \nto STM in this paper, support for hardware acceleration also requires a .exible runtime supporting dynamic \nswitching between TM algo\u00adrithms. Prior work [41, 43, 12] has developed various al\u00adgorithms for accelerating \nTM performance using different hardware acceleration techniques. Our system can dynami\u00adcally switch between \ndifferent algorithms to take advantage of hardware acceleration. Figure2 shows the ABI between the compiler \nand run\u00adtime. Each transaction hasa descriptor structure(TxnDesc) that holds the transaction meta-data. \nThe descriptor iskept in thread local storage (TLS). The ABI functions all take an explicit argument \nfor the descriptor structure toavoid redun\u00addant TLS accesses. The begin and commit functions start and \nend a trans\u00adaction, respectively. The begin function acts like a setjmp in that it may return multiple \ntimes. On the initial begin call, the return code directs the generated code to take the instru\u00admented \nor uninstrumentedcode path. The runtime can direct execution to the uninstrumented code if it decides \nto start a transaction in serial mode. On a con.ict or tm abort, the runtime executes a longjmp back \nto the begin function and returns a code that directs the generated code to re\u00adexecute or abort the transaction. \nThe second argument of the begin function passes .ags communicating information about the generated code \nto the runtime. This information in\u00adcludes whether the compiler has generated instrumented or uninstrumented \ncode, whether the atomic block has an abort statement, and whether it will (or might) call precompiled \ncode (i.e., a tm unknown function). The runtime uses this information to select the most appropriate \nexecution mode. When generating instrumented transactional code, the compiler knows if anyatomic block \nit encounters is nested. The compiler .attens nested atomic blocks unless they con\u00adtain an abort statement, \nin which case it generates calls to the beginInner and commitInner functions. Abort statements are translated \nto the userAbort function. The switchToSerialMode function switches the trans\u00adaction to the serial execution \nmode. As described later, the compiler inserts a call to this function before the .rst call to a tm unknown \nfunction. If the compiler detects that all paths through the atomic block call a tm unknown function \nthen it will communicate this fact to the runtime in the begin function; the runtime may then start the \ntransaction in serial mode. The compiler translates each transactional memory ac\u00adcess intoa calltothe \nread and write functions (also known as barriers).Thereisareadandwrite functionforeachprim\u00aditive data \ntype. These frequently-called functions use regis\u00adter parameter calling conventions to reduce their overhead. \nAs an optimization, the interface provides a function imple\u00admenting memory copying insideof transactions(memcpy). \nWrites to local variables and thread-local variables must be loggedin caseofan abortbut don tneedtobe \ntrackedfor con.ict detection as other transaction can taccess them. The compiler explicitly saves and \nrestores live scalar locals that are modi.ed by the atomic block on transaction begin and abort, respectively. \nNo logging is necessary for such vari\u00adables when they are written inside the atomic block. For a transactional \nwrite to a non-scalar local or a thread-local variable, the compiler generates a call to the logValue \nABI function followed by the write operation instead of gener\u00adating a call to the write function. The \nlogValue function logs the old value of an address without tracking con.icts to that address. The logBulk \nfunction similarly logsa memory range and can be used to log aggregates. 3.2 Barrier optimizations Our \ndesign strategy of decoupling the compiler and gener\u00adated code from the STM runtime precludes manyoptimiza\u00adtions \non the read and write barriers. The compiler cannot in\u00ad read(x) read(x) / \\ / \\ / \\ / \\ read(x) readFW(x) \nread(x) read(y) readAR(x) read(y) | | \\ / \\ / writeAR(x) writeAW(x) \\ / \\ / | | write(x) writeAR(x) read(y) \nread(y) | | read(y) readAR(y) (a) unoptimized (b) after barrier optimization (c) after redundancy (d) \nafter read-for-write elimination optimization Figure 3. Memory access optimizations line barrierfast \npath code sequences into the generated code, for example, as such code sequences depend on the STM al\u00adgorithm. \nSimilarly, redundancy elimination can t eliminate barriers that may appear redundant as such optimizations \nalso depend on the STM (e.g., a read barrier that is domi\u00adnated by a write barrier to the same location \nis redundant in an in-place-update STMbut notina write-buffering STM). To enable barrier optimization, \nthe ABI provides special\u00adized read and write barriers that encode the interesting re\u00addundancypatterns \nbetween read and write operations. These barriers allow the compiler to communicate the results of redundancyanalysis \nto the STM runtime. Section 4.2.3 de\u00adscribes how the runtime eliminates redundant STM opera\u00adtions in \nthese specialized read and write barriers for the dif\u00adferent STM algorithms. The readAW and writeAW barriers \nare used instead of regular read and write barriers where a read or write ac\u00adcess to a given location \nis dominated by another write to the same location executed within the same transaction. (readAR stands \nfor read-after-read , readAW stands for read-after-write , and readFW stands for read-for-write , etc.)The \nreadAR barrier is used instead of a regular read barrier where a read access to a given location is dominated \nby another read from the same location executed within the same transaction. The compiler uses the readFW \nbarrier in\u00adstead of a regular read barrier when it detects that a read operation from a given location \nwill always be followed by a write to the same location.To use this barrier, the compiler .rst transforms \nthe write operation into an internal writeAR operation and then transforms it into a writeAW operation \nafter it replaces the read that dominates the write with a readFW operation. Figure3showsanexampleof \nmemory access optimiza\u00adtions using the specialized read and write barriers. This .g\u00adure shows a control \n.ow graph at different optimization stages.  3.3 Function calls A function s annotation determines whether \nthe compiler generates a transactional clone of that function. The clone contains calls into the runtime \nABI and has a mangled version of the function s name. The compiler clones all tm callable functions and \nthose tm unknown functions thatit detects mightbe called from insidea transaction.A simple inter-procedural \nanalysis detects the set of functions reachable from inside a transaction. The function annotations \nalso determine the code gener\u00adation strategy for direct function calls.Within transactional code, the \ncompiler generates calls to the mangled names of cloned functions and to the tm wrap functions for wrapped \nfunctions; otherwise, it generates calls to the original unin\u00adstrumented function.For tm unknown functions \nthat it didn t clone, it inserts a call to the switchToSerialMode ABI function before the call. Calls \nto tm pure functions go to the uninstrumented version without switching to serial mode as the programmer \nhas asserted that these functions are safe to execute inside of transactions without instrumentation. \nIndirect function calls are slightly more complicated. Function pointer types do not have annotations, \nso it is un\u00adclear to the compiler whether the target of an indirect call has a clone or whether it requires \nserial execution because it is precompiled and nota tm pure function. All function point\u00aders point to \nthe original uninstrumented code so that indirect calls outside of transactions are not affected. Similar \nto [46], the compiler generates a marker at the beginning of every uninstrumented function that hasa \nclone; Figure4illustrates this marker. Inside transactions, an indirect function call .rst ORG_FUNC_ENTRY: \njmp RENAMED_ORG_FUNC_ENTRY mov eax, TM_INDIRECTION_MAGIC jmp CLONED_FUNC_ENTRY RENAMED_ORG_FUNC_ENTRY: \n// original (un-instrumented) // function code starts here CLONED_FUNC_ENTRY: // cloned (instrumented) \n// function code starts here Figure 4. Un-instrumented function s prologue checks whether the TM INDIRECTION \nMAGIC value exists at a .xed offset from the target address in the function pointer. Ifitdoes,thena clonedversionofthe \nfunctionexistsandthe call jumps to the clone s address (CLONED FUNC ENTRY). Otherwise, the call .rst \nswitches to serial execution mode before calling the original address in the function pointer. This scheme \nadds an extra level of indirection to indirect function calls inside of transactions. This technique \nfor implementing indirect calls unfortu\u00adnately treats precompiled tm pure functions as tm unknown functions: \nInside transactions indirect calls to precompiled tm pure functions triggerserialexecution.Toavoid this \nfor tm pure function that it recompiles, the compiler generates a prologue similartothe one presentedin \nFigure4but with both jump targets pointing to the same un-instrumented ver\u00adsion of the code. Generating \ncalls to virtual member functions requires special care. Because of the virtual function overriding and \ninheritance rules de.ned in Section 2.6, the compiler knows that all functions that override a tm callable \nor tm pure virtual function will have the same annotation. So calls to tm callable virtual functions \ncan indirectly call the clone of the target function via the address in the target func\u00adtion s prologue, \nand calls to tm pure virtualfunctions can simply call the target function without anychecks. Calls to \ntm unknown virtual functions, however, must dynamically check whether a clone of the target function \nexists using the same technique as for indirect calls. Inlining transactionally annotated functions also \nrequires special care when such functions are inlined into atomic blocks or into transactional clones. \nThe compiler s interme\u00addiate representation includes special code markers that al\u00adlows inlining of tm \npure functions. These markers ensure that the compiler omits transactional instrumentation for the inlined \nbody of a tm pure function. The compiler automati\u00adcally promotesthe inlinedbodyofa tm unknown or unanno\u00adtated \nfunction to tm callable if it inlines the function into another transactional clone or atomic block. \n4. TM runtime In this section we describe runtime support for multi-mode execution, discuss in detail \nour STM algorithms, introduce our contention management strategy,and presentatechnique enabling safe \nin-transaction explicit memory allocation and deallocation. 4.1 Execution modes The STM runtime supports \nfour execution modes: (1) opti\u00admistic, (2) pessimistic, (3) obstinate, and (4) serial. The .rst twoexecution \nmodes use an STM algorithm that implements in-place updates (eager versioning) with strict two-phase \nlocking[17] for writes. The algorithm implements both op\u00adtimistic and pessimistic concurrency control \nfor reads (the optimistic and pessimistic modes, respectively) and allows the runtime to choose dynamically \nbetween these two modes on a per-transaction basis. The STM system can switch be\u00adtween thesetwo modes \nmid-way througha transaction.Ital\u00adlows optimistic and pessimistic transactions to execute con\u00adcurrently \nand to read the same data. This is the .rst STM al\u00adgorithm that can support both forms of concurrencycontrol \nat the same time, while preserving important safety proper\u00adtiessuchasprivatizationsafety[45,34].Werefertothisnew \nSTM algorithm as the uni.ed STM algorithm. Atransaction running in serial mode never con.icts with another \ntransaction regular transactions are forbidden to run concurrently witha serial transaction.Atransaction \nrun\u00adning in obstinate mode always wins all con.icts with other transactions regular transactions are \nallowed to run con\u00adcurrently with the obstinate one, but the obstinate transac\u00adtion has the highest con.ict \nresolution priority of all transac\u00adtions in the system. The serial mode provides a mechanism for executing \nprecompiled code and unrestricted I/O oper\u00adations, while the obstinate mode provides an ef.cient exe\u00adcution \nmode for long running transactions that are likely to have con.icts and are expensive to roll back. To \nallow dynamic switching between modes, each trans\u00adaction descriptor contains a pointer to a function \ndispatch table containing functions that implement the mode-speci.c compiler-runtime ABI functions. Each \nof the four execu\u00adtion modes de.nes its own function dispatch table. The ABI functions are implemented \nas indirect calls through the mode pointertothe actual functions implementedforthe mode.To switch modesatransaction \nsimply points its descriptor s dis\u00adpatch table pointer to the desired mode s dispatch table. Al\u00adthough \nthe extra indirection adds overhead to each read and write barrier,it allows the runtime to select the \nmost ef.cient execution mode for each transaction. Section 4.4 discusses mode switching in more detail. \nA serial transaction containing no user abort statements does not require instrumentation because it \nis guaranteed to commit and there are no other concurrent transactions with which it can con.ict. When \nstarting such a transac\u00adtion, the runtime selects execution of un-instrumented code if the compiler has \nindicated that it has generated an un\u00adinstrumented version of an atomic block. But in case the compiler \ndid not generate an uninstrumented version of an atomic block, (e.g., to minimize code bloat) the runtime \nhas a serial mode dispatch table with trivial read and write barri\u00aders that simply access memory. In \naddition, the runtime has a .fth serial atomic dispatch tableto support serial modeex\u00adecution of atomic \nblocks that contain user abort statements. To support roll back, write barriers in this dispatch table \nlog old values on writes. 4.2 Uni.ed STM algorithm The pessimistic mode algorithm uses a bit-vector \nto repre\u00adsent the set of visible readers who have locked a memory location for shared reading. Pessimistic \nreader-writer locks automatically provide observable consistencyand, in the ab\u00ad State Optimistic TxnRec \nEncoding Upper bit values Pessimistic TxnRec Encoding Upper bit values Meaning Shared x..x1 version number \n0..001 x..x01 all zero bit-vector of readers no pessimistic readers read locked x..x11 bit-vector of \nreaders read locked with pending upgrade Exclusive x..x0 owner TxnDesc 0..000 x..x00 all zero owner bit \nmask write locked by optimistic write locked by pessimistic Figure 5. Transaction record encoding sence \nof optimistic readers, also automatically provide priva\u00adtization safety [34, 33]. The optimistic mode \nalgorithm uses a timestamp-based algorithm that incrementally updates a transaction s timestamp by validating \nthe transaction each time it reads a value that has a more recent time stamp. Like other timestamp-based \nalgorithms [46, 13],itkeepsa con\u00adsistent read set thus maintaining observable consistency.To implement \nprivatization safety in the presence of optimistic readers, all transactions must quiesce [46, 13, 33] \non com\u00admit. The quiescence algorithm maintains a global quiescence list of timestamps for all in-.ight \ntransactions. Every pes\u00adsimistic transaction has an in.nite timestamp. Every opti\u00admistic transaction \nsets its timestamp at the beginning of its execution to the value of the global timestamp, and updates \nit every time it successfully validates its read set. Before committing, every transaction must wait \nfor all transactions whose timestamp in the list is smaller than its own times\u00adtamp. After a transaction \ncommits or aborts it sets its corre\u00adsponding timestamp to in.nity. Apointer-sized transaction record \n(or TxnRec) tracks the transactional state of aligned memory blocks accessed inside transactions. The \nmemory block size is a parameter of our system that we set to be the same as the cache line size but \ncanbeanypower-of-two size.A.xed-sized transaction record table contains all of the transaction records. \nEach table entry has twoTxnRecs, one for optimistic and the other for pessimistic concurrency control.A \nhash function maps memory addresses to entries in this table. A TxnRec table entry can be in either the \nshared state, indicating that multiple transactions can read the data that maps to that entry, or the \nexclusive state, indicating that a single owning transaction can read or write the data that maps to \nit. Figure 5 summarize the pessimistic and opti\u00admistic TxnRec bit encodings. In the exclusive state, \nthe op\u00adtimistic TxnRec contains a pointer to the descriptor of the owning transaction while the pessimistic \nTxnRec contains a bit mask uniquely identifying the exclusive owner. In the shared state, the optimistic \nTxnRec contains a timestamp value while the pessimistic TxnRec containsabit-vector rep\u00adresenting the \nvisible readers who have read-locked the data that maps to the TxnRec. The least-signi.cant bit of the \nopti\u00admistic TxnRec distinguishes between the shared and exclu\u00adscriptor pointers point to word-aligned \nstructures. Similarly for the least-signi.cant bit of the pessimistic TxnRec. 4.2.1 Write barrier algorithm \nOn a write, a transaction .rst acquires exclusive ownership of the pessimistic TxnRec regardless of whether \nit is running in optimistic or pessimistic mode. Once it has acquired ex\u00adclusiveownershipofthe pessimisticTxnRec,itthenchanges \nthe optimistic TxnRec to theexclusive state.A transaction can change the value of the optimistic TxnRec \nonly when holdingexclusiveownershipof the pessimistic TxnRec.To release exclusive write ownership, a \ntransaction releases the optimistic TxnRec (by storing a new timestamp into it) be\u00adfore releasing the \npessimistic TxnRec. The pessimistic Txn-Rec thus acts as a write-lock for the entire table entry. This \nimplies that a transaction always has exclusive ownership of the pessimistic TxnRec if it has exclusive \nownership of the optimistic TxnRec. Figure6 shows the write barrier algorithm for both op\u00adtimistic and \npessimistic modes.(We show only the barrier algorithms for accessing an integer. The algorithms for other \ndata types are similar.) The write barrier .rst acquires ex\u00ad writeInt(txn, addr, val) { acquireLock(txn,addr); \nlogUndoInt(txn, addr); *addr = val; } acquireLock(txn,addr) { txnRecPtr = getTxnRecPtr(addr); txnRec \n= txnRecPtr->pessimistic; if (tnxRecPtr->optimistic == txn) return; /* already have ownership */ if (isReadOrWriteLocked(txnRec) \n|| !CAS(&#38;txnRecPtr->pessimistic,txnRec, txn->ownerBitMask) { acquireLockSlow(txn,addr); } logWrite(txn,txnRecPtr); \nif (txnRecPtr->optimistic > txn->localTimeStamp) { validate(txn); } /* lock the optimistic TxnRec */ \ntxnRecPtr->optimistic = txnDesc;  } sive states:Timestamps are oddvalues and transaction de- Figure \n6. Write barrier algorithm validate(txnDesc) { ts = globalTimeStamp; for (txnRecPtr in txnDesc->readSet) \n{ txnRec = txnRecPtr->optimistic; if (isWriteLocked(txnRec)) { if (txnRec != txnDesc) txnAbort(txnDesc): \n} else { if (txnRec > txnDesc->localTimeStamp) txnAbort(txnDesc); } } txnDesc->localTimeStamp = ts; updateQuiescenceList(ts); \n } Figure 7. Validation algorithm clusive ownership on the blocks containing the accessed data (acquireLock) \nand then logs the old value in the undo log(logUndoInt)before performing the write. The acquireLock function \nchecks for redundant lock acquisi\u00adtion requests and then attempts to acquire exclusive owner\u00adship of \nthe pessimistic TxnRec if it detects no data access contention. If exclusive ownership of the pessimistic \nTxn-Rec cannot be immediately acquired, execution falls into the slow path. The acquireLockSlow function \n(not shown) handles the slow case of handling con.icts with other trans\u00adactions and upgrading read locks \nto write locks. Section 4.3 describes contention management in more detail. After acquiring ownership \nof the pessimistic TxnRec, a transaction executing the write barrier logs a pointer to the TxnRec into \nthe write set (for later unlocking) and puts the optimistic TxnRec into the exclusive state. Then, if \nthis transaction is optimistic, it validates its read set if the opti\u00admistic TxnRec has a later timestamp \nthan the transaction s currenttime stamp. (Sincethe transactionhas acquiredown\u00adership of the pessimistic \nTxnRec, the optimistic TxnRec must be holding a time stamp). The validation procedure (Figure 7) checks \nthat for each optimistic TxnRec in the read set either the transaction has exclusive ownership of that \nTxnRec or the timestamp of the TxnRec is not greater than that of the current transaction s. This ensures \nthat the transaction sees a consistent view of memory. The valida\u00adtion procedure also updates the local \ntime stamp of the cur\u00adrent transaction to re.ect that it is consistent with respect to the current global \ntime stamp and updates the transaction s timestamp in the global quiescence list.  4.2.2 Read barrier \nalgorithm The optimistic and pessimistic execution modes use differ\u00adent read barriers, and each mode \nuses its respective Txn-Rec. Figure8 shows the optimistic mode read barrier. The read barrier executes \na straight line fast path for the case in which the transaction already owns the optimistic Txn-Rec, \nor the case in which the TxnRec is not owned exclu\u00ad int readOptimisticInt(txnDesc,addr) { val = *addr; \ntxnRecPtr = getTxnRecPtr(addr); txnRec = txnRecPtr->optimistic; if (txnRec == txnDesc) return val; if \n(isWriteLocked(txnRec) || txnDesc->localTimeStamp < txnRec ) return readSlowOptimisticInt(txnDesc,addr); \nlogRead(txnDesc, txnRecPtr); return val;  } int readSlowOptimisticInt(txnDesc,addr) { txnRecPtr = getTxnRecPtr(addr); \ndo { txnRec = txnRecPtr->optimistic; val = *addr; }while(!validateAndLog(txnDesc,txnRecPtr,txnRec)); \nreturn val; } int validateAndLog(txnDesc,txnRecPtr,txnRec) { if (isWriteLocked(txnRec) || !checkReadConsistency(txnDesc,txnRecPtr,txnRec)) \n{ contentionOnRead(txnDesc, txnRecPtr); return 0; } logRead(txnDesc,txnRecPtr); return 1;  } int checkReadConsistency(txnDesc,txnRecPtr,txnRec){ \nif (txnRec > txnDesc->localTimeStamp) validate(txnDesc); return *txnRecPtr == txnRec; } Figure 8. Optimistic \nread barrier algorithm sively by anyone and has an earlier timestamp than the cur\u00adrent transaction. \nIt delegates all other cases to a slow path (readSlowOptimisticInt). Thefast path logsa pointer to the \nTxnRec into the read set (for later validation) in the case where the TxnRec is not exclusively owned \nby anyone. The optimistic mode read barrier slow path loops read\u00ading both the TxnRec and the data until \nit sees that a TxnRec is not locked by another transaction. The validateAndLog function veri.es that \na TxnRec is not owned by another transaction and also post-validates the TxnRec using the function checkReadConsistency. \nPost-validation ensures that the transaction s read set is consistent with the times\u00adtamp stored in the \noptimistic TxnRec and that the value of the timestamp has not changed in the meantime. On con\u00adtention, \ncontrol passes to the contentionOnRead function in the contention manager. int readPessimisticInt(txnDesc,addr) \n{ txnRecPtr = getTxnRecPtr(addr); txnRec = txnRecPtr->pessimistic; if (!isLockedByMe(txnDesc,txnRec)) \n{ return readSlowPessimisticInt(txnDesc,txnRecPtr); } return *addr; } int readSlowPessimisticInt(txnDesc,txnRecPtr) \n{ txnRec = txnRecPtr->pessimistic; while (isWriteLockedOrUpgradeRequested(txnRec) || !CAS(&#38;txnRecPtr->pessimistic,txnRec, \ntxnRec ^ txnDesc->ownerBitMask)) { contentionOnRead(txnDesc,txnRecPtr); txnRec = txnRecPtr->pessimistic; \n} logRead(txnDesc,txnRecPtr); return *addr; } Figure 9. Pessimistic read barrier algorithm Figure 9 \nshows the pessimistic mode read barrier. The read barrierfast path completes successfully if the transac\u00adtion \nalready owns a read or write lock on the TxnRec; oth\u00aderwise theexecutionfalls into the slow path. The \nslow path loops until it can acquire a read lock on the TxnRec and then logs a pointer to the TxnRec \ninto the read set (for later unlocking). Similarly to the optimistic read barrier, control passes to \nthe contentionOnRead function on contention. The read barrier gives priority to any transaction who has \nrequested an upgrade from a read lock to a write lock.  4.2.3 Optimized barriers Section 3.2 described \nhow the compiler communicates re\u00adsults of data .ow analysis to the runtime via specialized bar\u00adriers. \nThis section describes how the runtime system opti\u00admizes these specialized barriers. The readAW (read-after-write) \nand writeAW (write-after\u00adwrite) functions contain only a simple load or store since the transaction already \nholds an exclusive lock for that lo\u00adcation in both the pessimistic and optimistic modes. The readAR (read-after-read) \nfunctions containa simple load for pessimistic transactions since the transaction already holdsa read \nlock for the read location.For optimistic transactions, these functions do not update the read set since \nthe loca\u00adtion has already been added to the read set, and, if the cur\u00adrent transaction s timestamp is \nsmaller than the one stored in the optimistic TxnRec, the current transaction immediately aborts because \nthe location may have been updated by other transactions. The readFW (read-for-write) function allows \nthe runtime to take a write lock immediately, thus avoiding unnecessaryreadloggingandavoidingtheneedto \npromotea read lock later (pessimistic read concurrency) or to perform additional validations (optimistic \nread concurrency).  4.2.4 Transaction commit and abort A committing outermost pessimistic transaction \n.rst re\u00adleases all its read locks.Acommitting outermost optimistic transaction .rst validates its read \nset, aborting if validation fails. As an optimization, this validation is performed only if the write \nset is not empty and the timestamp of the trans\u00adaction is less than the current global time stamp (indicating \nthat other transactions have committed since the last time the transaction validated). The commit algorithm \nthen re\u00adleases write locks and quiesces on all other in-.ight opti\u00admistic transactions (to ensure privatization \nsafety). Finally, the commit algorithm executes all the commit actions reg\u00adistered for a given transaction. \nThe compiler .attens nested transactions that contain no abort statements. Nested trans\u00adactions that \ncannot be .attened perform no actions on com\u00admit. An aborting transaction, pessimistic or optimistic, \nreverts all the updates performed within the scope of the transaction and executes all the undo actions \nregistered for a given transaction. An outermost transaction releases all its locks and consults the \ncontention manager with respect to actions that may have to be taken before it is re-executed (e.g., \nexponential back-off). 4.2.5 Quiescence optimizations The runtime performs two optimizations to reduce \nor avoid the cost of quiescence. The lazy start optimization delays declaring a transaction as optimistic \nfor as long as possible, reducing the time interval during which other transactions need to wait for \nit during quiescence. Instead of setting the transaction stimestamp at transaction start, this optimization \nsets the timestamp to in.nity until the .rst optimistic read barrier, at which point it sets the timestamp \nto the value of the global timestamp. Read after write and read for write barrier functions as well as \nall the write barrier functions do not set the timestamp as these barriers hold a lock for the memory \naccess.Asweshowin Section5,this techniquesig\u00adni.cantly improves the performance of workloads in which \nall reads are read for writes or read after writes. In the .ltering optimization, quiescence uses a mask \nto skip over transactions that have not performed optimistic reads. Each transaction is assigned a stability \n.ag byte in a global mask that indicates whether the transaction has performed any optimistic reads (not \nincluding read after writes or read for writes). Eight stability .ags make a 64\u00adbit integer, which can \nbe checked in one instruction. Instead of going through all transactions one by one, quiescence can now \nquickly check eight transactions a time. If a 64\u00adbit chunk of the mask in nonzero, it can check individual \nbytes using binary search and quiesce only on transactions with nonzero stability .ag bytes. This optimization \nreduces quiescence cost for programs in which most transactions don tperform optimistic reads.  4.3 \nContention management The STM runtime s contention management framework al\u00adlows multiple contention handling \npolicies to be plugged in via a contention management interface. The current system provides a default \npolicythat uses exponential back-offand a policy that uses a variant of the polka policy [49]. The contentionOnRead() \nand contentionOnWrite() func\u00adtions handle the case in which a transaction encounters con\u00adtention when \nattemptingadata access operation, whereas the contentionOnAbort() function handles the case in which \na transaction has aborted and is about to re-execute. Each policy implements a dispatch table containing \npointers to these functions,andeach transaction holdsa pointertoadis\u00adpatch table for the contention management \npolicy. 4.4 Mode switching Atransaction starts in optimistic mode. The obstinate mode guarantees forward \nprogress of long transactions, so a con\u00adtention manager may transition an optimistic transaction to obstinate \nmode if the transaction re-executes too manytimes due to con.ict. If the transition to obstinate modefails \nbe\u00adcause of another obstinate transaction, then a contention manager may simply transition the transaction \nto pessimistic mode. The transition can occur in-.ight or on re-execution of the transaction. To become \npessimistic in-.ight, an optimistic transaction validates its read set and acquires pessimistic read \nlocks for all the transaction records in its read set. If this fails, the transaction aborts and restarts \nin pessimistic mode. We do not support in-.ight transitions in the opposite direction a pessimistic \ntransaction can become optimistic,but only on re-execution. An obstinate transaction is simply a unique \npessimistic transaction that has the highest con.ict resolution priority in the system. An optimistic \ntransaction can reach obstinacy only after becoming pessimistic. The system allows at most one obstinate \ntransaction at at time, implemented using an obstinacy token. A transaction must acquire this token in \norder to become obstinate. A serial transaction runs exclusively with respect to all other transactions \n no other transaction is allowed to run while a serial transaction is running. This is different from \nan obstinate transaction, which can coexist with other trans\u00adactions.Atransactioncan transitiontothe \nserialmode either in-.ight or on re-execution.To transition in-.ight,a trans\u00adaction .rst becomes obstinate, \nwhich ensures that no other obstinate or serial transaction is present in the system. It then transitions \nto serial mode and waits until all transac\u00adtions complete. No new transactions can start while a serial \ntransaction exists.  4.5 Transactional memory management In orderforanSTM systemtobe practical,it mustprovidea \nsafe and ef.cient mechanism supporting memory allocation and de-allocation insideoftransactions.Failingtoprovide \nadequate memory management support may leadto serious performance and safety problems, such as memory \nexhaus\u00adtion or dangling references. Unlike previous work on transactional memory manage\u00adment [27], our \nsystembuilds on top of the default platform memory allocator. This avoids requiring the developer to \nrebuild the entire application with a custom transactional memory allocator.We use the tm wrap annotation \ndescribed in Section 2.9 to implement wrappers for all memory alloca\u00adtion functions. The wrappers also \nregister commit and undo actionsthatneedtobeexecutedbythe memory allocatoron transaction termination. \nSimilar to the solution presented in [27], we associate a ticket number with each allocation and de-allocation \nsite. Non-transactional code has an implicit ticket number equal to 1. A non-nested transaction starts \nwith a ticket number equal to 2, increments it on the start of every nested trans\u00adaction, and decrements \nit on every commit. Unlike in [27] our ticket numbers are thread-local and do not have to be unique across \nthreads.Ticket numbers are used to determine ifa free operation canbeexecuted immediatelyor shouldbe \ndeferred until a future transaction commit. In addition to allocating the requested memory, the al\u00adlocation \nfunction wrapper creates an allocation record and stores it in a thread-local table. The allocation record \ncon\u00adtains the address of an allocated memory fragment and the current ticket number. The function wrapper \nalso registers commit and undo actions to be executed on commit or abort of the outermost transaction. \nThe commit action removes the allocation record from the table. The undo action re\u00admoves the allocation \nrecord and de-allocates thegiven mem\u00adory fragment. The de-allocation function wrapper determines when \nto de-allocate a memory chunk based on the chunk s ticket number, which it looks up in the allocation \nrecord table using the chunk s memory address.2 The wrapper function de-allocates memory immediately \nif the ticket number is greater than or equal to the current ticket number. Otherwise, it registers a \ncommit action to be executed on commit of the innermost transaction where the ticket number of the resuming \ntransaction meets the conditions for de-allocation. The commit action simply deallocates the given memory \nfragment, and deletes its associated allocation record if one exists. 5. Experimental results To evaluate \nour system, we experimented with a wide range of workloads, including STAMP[9], SPLASH2[51], and PARSEC[4]. \nOur results show that the optimistic mode out\u00adperforms the pessimistic mode,but the pessimistic algorithm \nperforms competitively in manycases, especially at lowcon\u00ad 2If no record exists, the allocation site \nis non-transactional and assigned a ticket numberof1 tention levels. In addition, we found compiler \noptimizations and runtime quiescence optimizations very effective for re\u00adducing the overhead of STM and \nimproving its scalability. 5.1 Workloads and experimental environment We ported and ran 20 programs \nfrom the benchmark suites ofSTAMP[9], SPLASH2[51], andPARSEC[4] for ourex\u00adperiments. STAMP is a TM benchmark \nsuite developed by Stanford. We used version 0.9.4, which contains three programs, all of which feature \nrelatively long transactions compared to traditional parallel workloads. SPLASH2 is a benchmark suite \nof classical parallel programs, includ\u00ading numerical analysis kernels and scienti.c and graphics applications. \nAccording to our measurements, most of the SPLASH2 programs spend less than 1% execution time in critical \nsections (and some of them 5% with large input). Some of the SPLASH2 programs, however, use parallel \npro\u00adgramming patterns that are interesting from a TM perspec\u00adtive; for example, barnes uses double-checked \nlocking to avoid lockingoverhead when loadingthe contentsofan oct\u00adtree data structure, and radiosity \ndoes privatization to take tasks off a shared task queue. We also used one program .uidanimate from \nthePARSEC suitein ourevaluation. This program simulates .uids and features extremely short atomic regions \n(one increment operation each) in extremely large numbers (more than 10 million). The STAMP programs \nwere originally written using transactions.We ported STAMP to our language constructs and created a coarse-grained \nlock version of them by us\u00ading a single global lock to guard every atomic block. The SPLASH2 programs \nwere originally written using .ne\u00adgrained locks.Wecreatedatransactionalversionof SPLASH2 by replacing \nthe lock-based critical sections with atomic blocks and created a coarse-grained version by replacing \nall the locks witha single global lock.We did the same thing for .uidanimate to create transactional \nand coarse-grained lock versions. For some SPLASH2 programs, we also in\u00adcreased the input size. For barnes, \nraytrace, and radiosity, the programs .nished in seconds when running in a single thread using the original \ninput.With our input, they.nished in minutes when running in a single thread. The barnes program contains \na data race in its double\u00adchecked locking pattern. This program breaks when trans\u00adlated to use transactions \nbecause of this data race. We rewrote barnes to remove this data race and to make it com\u00adply with the \nemerging C++ memory model [8]. Eliminating the data race not only .xed the problembut also improved its \nperformance relative to locks. We ran our experiments on an 8-core system with 8GB of main memory running \nRedHat Enterprise LinuxVersion 4. The system had two sockets, each with a quad-core Intel Xeon X5355 \n(Clovertown) CPU at 2.66GHz. Each CPU had an 8MB L2 cache. Our STM was con.gured to use a table of 220 \ntransaction record entries and cache-line-granularity for con.ict detection. 5.2 Scalability of STM \n Figure 10 shows the scalability of our system, running the 20 programs from STAMP, SPLASH2, and PARSEC. \nThe numbers are reported as speedup over single-thread execu\u00adtion of the same programs using coarse-grained \nlocks, and they include all compiler and runtime optimizations. For each program, we show the speedups \nwith 1, 2, 4, and 8 threads. Numbers greater than1 re.ect better performance (a) Single Thread (b) 8Threads \nFigure11. Comparison of optimistic STM (oSTM), pessimistic STM (pSTM), coarse-grained locks (CGL) and \n.ne-grained locks(FGL). Numbersarereportedasspeedupover single-threadexecutionofCGL.Wedon thaveaversionofSTAMPusing \n.ne-grained locks. than single-thread coarse-grained locks, while numbers less than1re.ectworse performance. \nMost of the programs scaled well using our STM. At2 or more cores, the SPLASH2 programs and .uidanimate \nall perform better than the single-core coarse-grain lock con.g\u00aduration. Some of the SPLASH2 programs \n cholesky, fft, and ocean did not scale well due to lack of large in\u00adput. These programs also don t \nscale using coarse-grained or .ne-grained locks. At 4 or more cores, the STM con\u00ad.guration performed \nbetter than the single-thread coarse\u00adgrained lock con.guration for all STAMP programs except vacation/high. \nWe observed that vacation/high had many false con.icts due to cache-line granularity con.ict detec\u00adtion, \nso .ner-grain con.ict detection should improvethe per\u00adformance of vacation/high. To achieve good scalability \non kmeans and genome, we used tm waiver blocks for reads to shared read-only data. Pastworkhas considered \noptimisticSTM superiortopes\u00adsimistic mainly because the latter performs lock operations on transactional \nreads [40].We measured the scalability of both, and compared them to the coarse-grained lock con\u00ad.guration \nrunning the same workloads. Figure 11 measures the performance of the optimistic and pessimistic modes \nof the runtime and compares it with the performance of .ne\u00adgrained and coarse-grained locks. (Note that \nwe don t have .ne-grain versions of the STAMP programs. Also, in this .gure and in the rest of this section, \nwe limit our discussion of results for SPLASH2 to three programs barnes, raytrace, and radiosity which \nhad non-trivial critical sections com\u00adpared to the rest of the SPLASH2 programs.) Figure11(a) shows the \nsingle-thread speedup of the optimistic mode, pessimistic mode, and .ne-grain lock con.gurations rela\u00adtive \nto coarse-grain locks. The results in Figure11(a) show that both STM modes imposed additional single-threadover\u00adhead \ncompared to coarse-grained locks. This overhead was mostly caused by the compiler instrumentation for \nread and write barriers. STAMP programs are affected by this more than SPLASH2 or .uidanimate. The pessimistic \nmode in\u00adcurred slightly more overhead than the optimistic mode due to the lock operations it does on \nreads. As the number of threads increases, STM starts overcoming this instrumenta\u00adtion overhead and starts \nbeating coarse-grained locks. The results in Figure 11(b)) show that at 8 threads STM per\u00adforms better \nthan coarse-grained locks, and for SPLASH2 performs close to .ne-grained locks. In most programs, pes\u00adsimistic \nperforms closeorequalto optimistic,butin genome and vacation/low, pessimistic performs signi.cantly worse \nbecause of the lock operations it does on reads. 5.3 Runtime quiescence optimizations Figure 12 shows \nthe overhead of quiescence (privatization safety) and the performance improvements from the qui\u00adescence \noptimizations. The numbers in this .gure show speedups over a baseline STM that uses the quiescence al\u00adgorithm \ndescribedin Section4.2but without quiescenceop\u00adtimizations.To measure theoverheadof quiescence (priva\u00adtization \nsafety), we measured the performance of our work\u00adloads with quiescence disabled. Because the majority \nof our benchmarks (all but radiosity) do not use the privati\u00adzation pattern, it is legal to turn quiescence \noff for them. Disabling quiescence improved the performance of the op\u00adtimistic algorithm for all the \nbenchmarks except for vaca\u00adtion/high(as noted before,vacation/high suffers fromfalse con.icts). Quiescence \nincurs a signi.cant overhead on the STM,over 150%inthe caseof barnesand40%or morein5 other workloads. \nThe .ltering and lazy start quiescence op\u00adtimizations both reduced the overhead of quiescence. Some workloads \nbene.t mostly from the lazy start optimizations while others bene.t mostly from the .ltering optimization, \nso a combination of both optimizations appears to be the best strategy. The combined optimizationsgain \nback most of the overhead of quiescence and improve the performance of barnes and .uidanimateby almost \n200%.For .uidanimi\u00adate, the optimized optimistic STM even outperformed the STM with quiescence disabled \nbecause the lazy start tech\u00adnique also reduced the number of read set validations in the read barriers. \n(Note that the numbers in Figures 11 and 10 include these two optimizations.) 5.4 Compiler optimizations \nFigure 13 shows the performance improvements from using the compiler optimizations described in Section \n3.2. This .gure shows results for 1, 2, 4, and 8 threads as speedup over using no compiler optimizations \nfor the same number of threads. Fluidanimate bene.ts the most from compiler op\u00adtimizations, witha 150% \nimprovement at8threads and 48% at4threads. Kmeans/low and kmeans/high also bene.t sig\u00adni.cantly,with \nimprovements of 26% and 43%, respectively, at 8 threads. These improvements were due mostly to the read-for-write \nbarriers introduced by the compiler optimiza\u00adtions and described in Section 3.2. For .uidanimiate and \nkmeans, this optimization turns all read barriers into read\u00adfor-write barriers, which combined with the \nquiescence op\u00adtimization avoids quiescence and validation costs. 6. Related work Several STM systems \nhave introduced the basic atomic block language construct into C [46, 10, 3, 35, 15, 28]. Some of these \napproaches introduce pragmas [46, 28] and OpenMPextensions[3,35].In contrast,ourworkaimstoin\u00adtroduce \n.rst class C++ language constructs for TM that are orthogonal to the programming model and interact correctly \nwith other C++ language features. Crowl et al. [10] explore some of the high-level alternatives to introducing \nTM lan\u00adguage constructs into C++. Other systems have introduced Figure 13. Compiler optimizations the \nbasic atomic block language construct into managed lan\u00adguages [20, 21, 39, 2, 22, 26] Severalofthesepast \nsystemsalsoprovideanexplicit con\u00adstruct to rollback a transaction in the form of either an abort [46, \n10] or a retry statement [21, 2, 3, 35]. The commit and abort actions available in our system are reminiscent \nof the handlers used in the recent proposals for open-nested trans\u00adactions [38] and for transactional \nboosting [23], in which handlers can be used to implement .nalizing and compensat\u00ading actions. In addition \nto certain subtle differences in their behavior, handlers used with open nesting differ from ac\u00adtions \nused in our system by being automatically executed as separate transactions. Instead of .rst-class language \nconstructs, some systems provide an STM library interface [25, 13, 24, 31, 14]. Some of these systems \nleverage C++ language features (such as multiple inheritance, templates, and operator overloading) to \neliminate the syntactic clutter associated with STM APIs [11, 16]. In contrast, .rst-class language extensions \nprovide syntactic convenience to the programmer, enable compiler optimizations for TM,and enable static \nanalyses that provide static guarantees. Different STM systems implement different types of con\u00adcurrency \ncontrol. Existing eager versioning (i.e., in-place update) STM systems support pessimistic concurrency \ncon\u00adtrol for writes and either optimistic [2, 22] or pessimistic [40] concurrency for reads. Lazy versioning \n(i.e., write\u00adbuffering) STM systems [13, 47, 20] can support optimistic concurrencycontrol for write \noperations as well. Unlike the system described in this paper, none of the existing STM systems has allowed \nconcurrent transactions that use differ\u00adent concurrencycontrol mechanisms. The idea of mode switching \nhas appeared previouslybut only in the context of systems that utilize a mix of hardware and software \ntransactional memory techniques [41, 12, 29, 43]. In the phased TM approach [29], all transactions in \nthe system execute in the same mode one failing hardware transaction causesall transactionsinthe systemtoexecutein \nsoftware. In the Hybrid TM [12] and hardware-accelerated STM [41] approaches, a transaction may execute \neither in a pure software mode or in a mode that uses hardware support for TM, and transactions using \ndifferent modes can execute concurrently. Memory models for STM systems and issues concerning transactional \nsemantics in general have recently attracted signi.cant attention. Blundell et al. [5] introduced the \nno\u00adtions of weak and strong atomicity. Shpeisman et al. [42], Abadi et al. [1], and Moore and Grossman \n[36] have all fur\u00adther investigated these issues. Menon et al. [34, 33] and Grossman et al. [18] discuss \nseveral other TM memory model issues, along with implications that language memory models, such as the \nJava Memory Model [30] or the emerg\u00ading memory model for C/C++ [8], may havefor TM. Finally, issues concerning \nthe desirable safety properties that STM systems should preserve whenexecuting concurrent transac\u00adtions, \nsuch as privatization or publication safety, have been explored by Spear et al. [45], Menon et al. [34, \n33] and Abadi et al. [1], among others. In order to guarantee safety of STM systems in a more general \nsense, certainkeymechanisms mustbe designedand implemented carefully to work correctly in a transactional \ncontext. Correct handling of I/O and calls to legacy code from inside transactionswas .rst proposedbyBlundell \net al. [6] for hardware transactions and then by Spear et al. [44] and Welc et al. [48] in the context \nof an STM. Solutions for safe and ef.cient memory management in STM systems havebeen addressedby Hudsonetal.[27](explicit \nmemory allocation for unmanaged languages) andMcGachey et al. [32] (automatic memory management throughgarbage \ncol\u00adlection). STM systems must ef.ciently manage contention be\u00adtween concurrently executing transactions. \nHerlihy et al. [24] introduced the concept of contention managers sepa\u00adrated from the rest of the STM \nsystem. In [49] and [50], Scherer and Scott further investigated and evaluated sev\u00aderal different contention \nmanagement policies. Examples of other topics investigated in this area include contention man\u00adagement \npolicies with provable worst case properties (Guer\u00adraoui et al. [19]) or identi.cation of performance \npathologies that may result from using certain contention management policies (Bobba et al. [7]). 7. \nConclusions In this paper we presented a software transactional memory system that introduces .rst-class \nC++ language constructs for transactions.Wedescribed newC++ languageextensions to support transactional \nmemory. These constructs support C++ language features such as classes, inheritance, virtual functions,exception \nhandling, and templates.Weextended an existing, high-performance production C/C++ compiler to translate \nand optimize these new languageextensions.We presented a novel STM runtime library implementing both \noptimistic and pessimistic concurrency control, as well as other important features such as support for \ncalls to legacy binaries and unrestricted I/O.We also presenteda thorough experimentalevaluationofourSTM \nsystemonalargesetof TM workloads and demonstrated that our system performs well across these workloads. \n References [1] M. Abadi, A. Birrell,T. Harris, and M. Isard. Semantics of transactional memory and automatic \nmutual exclusion. In POPL 2008. [2] A.-R. Adl-Tabatabai,B.T.Lewis,V.S. Menon,B.R.Murphy, B. Saha, andT. \nShpeisman. Compiler and runtime support for ef.cient software transactional memory. In PLDI 2006. [3] \nW. Baek, C. C. Minh, M. Trautmann, C. Kozyrakis, and K. Olukotun. The OpenTM transactional application \nprogramming interface. In PACT 2007. [4] C. Bienia,S.Kumar,J. Singh, andK. Li. The parsec bench\u00admark \nsuite: Characterization and architectural implications. Technical Report 811-08, Princeton University, \n2008. [5] C. Blundell, E. C. Lewis, and M. Martin. Subtleties of transactional memory atomicity semantics. \nComputer Architecture Letters, 5(2), Nov. 2006. [6] C. Blundell, E. C. Lewis, and M. Martin. Unrestricted \ntransactional memory: Supporting I/O and system calls within transactions. Technical Report CIS-06-09, \nUniversity of Pennsylvania, Department of Comp. and Info. Science, 2006. [7]J. Bobba,K.E. Moore,L.Yen,H.Volos,M.D. \nHill,M.M. Swift,andD.A.Wood. Performance pathologiesin hardware transactional memory. In ISCA 2007. [8] \nH. J. Boehm and S. Adve. Foundations of the C++ concurrencymemory model. In PLDI 2008. [9] C. Cao Minh, \nM. Trautmann, J. Chung, A. McDonald, N. Bronson, J. Casper, C.Kozyrakis, and K. Olukotun. An effectivehybrid \ntransactional memory system with strong isolation guarantees. In ISCA 2007. [10] L. Crowl,Y.Lev,V. Luchangco,M. \nMoir, andD. Nussbaum. Integrating transactional memory into C++. In TRANSACT 2007. [11] L. Dalessandro, \nV. J. Marathe, M. F. Spear, and M. L. Scott. Capabilities and limitations of library-based software transactional \nmemory in C++. In TRANSACT 2007. [12]P. Damron,A. Fedorova,Y.Lev,V. Luchangco,M. Moir,and D. Nussbaum. \nHybrid transactional memory. In ASPLOS 2006. [13] D. Dice, O. Shalev, and N. Shavit. Transactional locking \nII. In DISC 2006. [14] R. Ennals. Software transactional memory should not be obstruction-free. http://www.cambridge.intel-research.net/ \nrennals/notlockfree.pdf, 2005. [15]P. Felber,C. Fetzer,U.M\u00a8uller,T.Riegel,M.S\u00a8u\u00dfkraut,and H. Sturzrehm. \nTransactifying applications using an open compiler framework. In TRANSACT 2007. [16] J. Gottschlich and \nD. A. Connors. DracoSTM:Apractical C++ approach to software transactional memory. In LCSD 2007. [17] \nJ. Gray and A. Reuter. Transaction Processing: Concepts and Techniques. Morgan Kaufmann, 1993. [18] D. \nGrossman, J. Manson, andW. Pugh. What do high-level memory models mean for transactions? In MSPC 2006. \n[19] R. Guerraoui, M. Herlihy, M. Kapalka, and B. Pochon. Robust contention management in software transactional \nmemory. In SCOOL 2005. [20] T. Harris and K. Fraser. Language support for lightweight transactions. In \nOOPSLA 2003. [21]T. Harris,S. Marlow,S.P. Jones,andM. Herlihy. Composable memory transactions. In PPoPP \n2005. [22]T. Harris,M. Plesko,A. Shinnar, andD.Tarditi. Optimizing memory transactions. In PLDI 2006. \n[23] M. Herlihy and E. Koskinen. Transactional boosting: a methodology for highly-concurrent transactional \nobjects. In PPoPP 2008. [24] M. Herlihy, V. Luchangco, M. Moir, and I. William N. Scherer. Software transactional \nmemory for dynamic\u00adsized data structures. In PODC 2003. [25] M. Herlihy, V. Luchangco, and M. Moir. A \n.exible framework for implementing software transactional memory. In OOPSLA 2006. [26] B. Hindman and \nD. Grossman. Atomicity via source-to\u00adsource translation. In MSPC 2006. [27] R. L. Hudson, B. Saha, A.-R. \nAdl-Tabatabai, and B. C. Hertzberg. McRT-Malloc:Ascalable transactional memory allocator. In ISMM 2006. \n[28] IBM. IBM C/C++ for Transactional Memory, for AIX, V0.9, Language Extensions and User s Guide. http://dl.alphaworks.ibm.com/technologies/xlcstm/xlcstm\u00adwhitepaper.pdf. \n[29] Y. Lev, M. Moir, and D. Nussbaum. PhTM: Phased transactional memory. In TRANSACT 2007. [30] J. Manson, \nW. Pugh, and S. V. Adve. The Java memory model. In POPL 2005. [31]V.J. Marathe,M.F. Spear,C. Heriot,A. \nAcharya,D. Eisen\u00adstat, I.William N. Scherer, and M. L. Scott. Lowering the overhead of software transactional \nmemory. In TRANSACT 2006. [32]P. McGachey, A.-R. Adl-Tabatabai,R.L. Hudson,V. Menon, B. Saha, and T. \nShpeisman. Concurrent GC leveraging transactional memory. In PPoPP 2008. [33]V. Menon,S. Balensiefer,T. \nShpeisman, A.-R. Adl-Tabatabai, R.L. Hudson,B.Saha,andA.Welc. Practical weak-atomicity semantics for \nJava STM. In SPAA 2008. [34]V. Menon,S. Balensiefer,T. Shpeisman, A.-R. Adl-Tabatabai, R. L. Hudson, \nB. Saha, and A. Welc. Single global lock semantics in a weakly atomic STM. In TRANSACT 2008. [35] M. \nMilovanovi\u00b4c,R. Ferrer,V. Gajinov,O.S. Unsal,A. Cristal, E. Ayguad\u00b4e, and M. Valero. Multithreaded software \ntransactional memory and OpenMP. In MEDEA 2007. [36] K. F. Moore and D. Grossman. High-level small-step \noperational semantics for transactions. In POPL 2008. [37] J. E. B. Moss and A. L. Hosking. Nested transactional \nmemory: model and preliminary architecture sketches. In SCOOL 2005. [38]Y.Ni,V. Menon, A.-R. Adl-Tabatabai,A.L. \nHosking,R.L. Hudson, J. E. B. Moss, B. Saha, andT. Shpeisman. Open nesting in software transactional \nmemory. In PPoPP 2007. [39] M.F. Ringenburgand D. Grossman. AtomCaml: .rst-class atomicity via rollback. \nIn ICFP 2005. [40] B. Saha, A.-R. Adl-Tabatabai, R. Hudson, C. C. Minh, and B. Hertzberg. McRT-STM:A \nhigh performance software transactional memory system for a multi-core runtime. In PPoPP 2006. [41] \nB. Saha, A.-R. Adl-Tabatabai, andQ. Jacobson. Architectural support for software transactional memory. \nIn MICRO2006. [42]T. Shpeisman,V. Menon, A.-R. Adl-Tabatabai,S. Balensiefer, D. Grossman, R. L. Hudson, \nK. F. Moore, and S. Bratin. Enforcing isolation and ordering in STM. In PLDI 2007. [43] A. Shriraman, \nV. J. Marathe, S. Dwarkadas, M. L. Scott, D. Eisenstata, C. Heriot, I.William N. Scherer, and M.F. Spear. \nHardware acceleration of software transactional memory. In TRANSACT 2006. [44] M. Spear, M. Michael, \nand M. Scott. Inevitability mech\u00adanisms for software transactional memory. In TRANSACT 2008. [45]M.F.Spear,V.J. \nMarathe,L. Dalessandro,andM.L. Scott. Privatization techniques for software transactional memory. Technical \nReport 915, University of Rochester, Computer Science Dept., 2007. [46] C. Wang, W.-Y. Chen, Y. Wu, B. \nSaha, and A.-R. Adl-Tabatabai. Code generation and optimization for transactional memory constructs in \nan unmanaged language. In CGO 2007. [47]A.Welc,A.L. Hosking,andS.Jagannathan. Transparently reconciling \ntransactions with locking for Java synchroniza\u00adtion. In ECOOP 2006. [48] A. Welc, B. Saha, and A.-R. \nAdl-Tabatabai. Irrevocable transactions and their applications. In SPAA 2008. [49] I.WilliamN. Scherer \nandM.L. Scott. Advanced contention management for dynamic software transactional memory. In PODC 2003. \n[50] I.William N. Scherer and M. L. Scott. Contention manage\u00adment in dynamic software transactional memory. \nIn CSJP 2004. [51]S.C.Woo,M. Ohara,E.Torrie,J.P. Singh,andA. Gupta.The SPLASH-2 programs: Characterization \nand methodological considerations. In ISCA 1995.   \n\t\t\t", "proc_id": "1449764", "abstract": "<p>This paper presents a software transactional memory system that introduces first-class C++ language constructs for transactional programming. We describe new C++ language extensions, a production-quality optimizing C++ compiler that translates and optimizes these extensions, and a high-performance STM runtime library. The transactional language constructs support C++ language features including classes, inheritance, virtual functions, exception handling, and templates. The compiler automatically instruments the program for transactional execution and optimizes TM overheads. The runtime library implements multiple execution modes and implements a novel STM algorithm that supports both optimistic and pessimistic concurrency control. The runtime switches a transaction's execution mode dynamically to improve performance and to handle calls to precompiled functions and I/O libraries. We present experimental results on 8 cores (two quad-core CPUs) running a set of 20 non-trivial parallel programs. Our measurements show that our system scales well as the numbers of cores increases and that our compiler and runtime optimizations improve scalability.</p>", "authors": [{"name": "Yang Ni", "author_profile_id": "81325489808", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223174", "email_address": "", "orcid_id": ""}, {"name": "Adam Welc", "author_profile_id": "81100163106", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223180", "email_address": "", "orcid_id": ""}, {"name": "Ali-Reza Adl-Tabatabai", "author_profile_id": "81100032153", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223181", "email_address": "", "orcid_id": ""}, {"name": "Moshe Bach", "author_profile_id": "81381603661", "affiliation": "Intel Corporation, Haifa, Israel", "person_id": "P1223182", "email_address": "", "orcid_id": ""}, {"name": "Sion Berkowits", "author_profile_id": "81381607603", "affiliation": "Intel Corporation, Haifa, Israel", "person_id": "P1223183", "email_address": "", "orcid_id": ""}, {"name": "James Cownie", "author_profile_id": "81100473354", "affiliation": "Intel Corporation, Glasgow, United Kingdom", "person_id": "P1223184", "email_address": "", "orcid_id": ""}, {"name": "Robert Geva", "author_profile_id": "81381604117", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223185", "email_address": "", "orcid_id": ""}, {"name": "Sergey Kozhukow", "author_profile_id": "81381607839", "affiliation": "Intel Corporation, Novosibirsk, Russian Fed.", "person_id": "P1223186", "email_address": "", "orcid_id": ""}, {"name": "Ravi Narayanaswamy", "author_profile_id": "81100055955", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223187", "email_address": "", "orcid_id": ""}, {"name": "Jeffrey Olivier", "author_profile_id": "81381600884", "affiliation": "Intel Corporation, Champaign, IL, USA", "person_id": "P1223175", "email_address": "", "orcid_id": ""}, {"name": "Serguei Preis", "author_profile_id": "81381605717", "affiliation": "Intel Coporation, Novosibirsk, Russian Fed.", "person_id": "P1223176", "email_address": "", "orcid_id": ""}, {"name": "Bratin Saha", "author_profile_id": "81100311903", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223177", "email_address": "", "orcid_id": ""}, {"name": "Ady Tal", "author_profile_id": "81100507021", "affiliation": "Intel Corporation, Haifa, Israel", "person_id": "P1223178", "email_address": "", "orcid_id": ""}, {"name": "Xinmin Tian", "author_profile_id": "81100106742", "affiliation": "Intel Corporation, Santa Clara, CA, USA", "person_id": "P1223179", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1449764.1449780", "year": "2008", "article_id": "1449780", "conference": "OOPSLA", "title": "Design and implementation of transactional constructs for C/C++", "url": "http://dl.acm.org/citation.cfm?id=1449780"}