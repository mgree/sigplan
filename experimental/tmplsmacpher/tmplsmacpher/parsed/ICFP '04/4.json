{"article_publication_date": "09-19-2004", "fulltext": "\n Relating Models of Backtracking Mitchell Wand Dale Vaillancourt College of Computer and Information \nScience College of Computer and Information Science Northeastern University Northeastern University 360 \nHuntington Ave, Room 202 WVH 360 Huntington Ave, Room 202 WVH Boston, MA 02115 Boston, MA 02115  wand@ccs.neu.edu \ndalev@ccs.neu.edu ABSTRACT Past attempts to relate two well-known models of backtrack\u00ading computation \nhave met with only limited success. We relate these two models using logical relations. We accom\u00admodate \nhigher-order values and in.nite computations. We also provide an operational semantics, and we prove \nit ade\u00adquate for both models.  Categories and Subject Descriptors D.3.1 [Programming Languages]: Formal \nDe.nitions and Theory; F.3.2 [Logics and Meanings of Programs]: Se\u00admantics of Programming Languages Denotational \nseman\u00adtics, Operational semantics; D.1.1 [Programming Tech\u00adniques]: Applicative (Functional) Programming; \nD.1.6 [Pro\u00adgramming Techniques]: Logic Programming; D.3.3 [Pro\u00adgramming Languages]: Language Constructs \nand Fea\u00adtures; F.3.3 [Logics and Meanings of Programs]: Stud\u00adies of Program Constructs General Terms \nLanguages, Theory  Keywords two-continuation semantics, streams, adequacy, logical rela\u00adtions, monads \n1. INTRODUCTION There are two well-known models of backtracking compu\u00adtation: the stream model and the \ntwo-continuation model. The stream model represents backtracking computations by a stream of answers, \nand the two-continuation model uses a success continuation and a failure continuation. Hughes [8] de.nes \na backtracking monad to be a monad with ad\u00additional operations disj and fail satisfying .ve additional \naxioms. Both the stream model and the two-continuation Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. ICFP 04, September 19 21, 2004, Snowbird, Utah, USA. Copyright \n2004 ACM 1-58113-905-5/04/0009 ...$5.00. model are backtracking monads, but this fact does not give us \nany deeper relation between the two. Past attempts to relate these models have met with lim\u00adited success: \neither the types do not work out, or the relation works in one direction but not the other, or the relation \ndoes not work for higher-order values. We show how to relate the monads in a simple way. We relate streams \nof scalars using a representation inspired by Danvy et al. [4]. We then extend this to higher-order values \nusing logical relations. At observable types this yields the identity relation, and so we get a denotational \nequivalence between the values in each model. We then provide an op\u00aderational semantics and prove it \nadequate for both models. 2. BACKTRACKING COMPUTATION We are interested in modeling a simply-typed call-by\u00advalue \nPCF that permits backtracking computation, such as a higher-order variant of Icon or Snobol. Such a language \nhas types . ::= nat | .1 . .2 and terms t ::= x | .x.t | t1 t2 | succ | cn | rec f.(.x.t) | t1 . t2 | \nfail where c0,c1,c2, \u00b7\u00b7\u00b7 are constants of type nat and succ is a constant of type nat . nat. We allow \nrecursive functions with rec f.(.x.t), and fail represents a computation which fails to produce a value. \nThe computation t1 .t2 evaluates to t1, and, if computation backtracks, t1 is discarded in favor of t2. \nIt is a simple exercise to extend our results by considering an object-language with pairs, booleans, \nconditionals, and other features. We omit them to save space. The canonical toy example in our calculus \nis nats, a pro\u00adgram that evaluates to some natural number. The value of nats starts at 0, and each time \ncomputation backtracks to nats its value increases by 1. nats-from = rec f.(.n.n . f(succ n)) nats = \nnats-from(c0) Note that this language is considerably more general than Prolog. We consider this relationship \nin section 7. 3. MONADIC METALANGUAGES Following the lead of Moggi, we give a semantics to an object-language \nwith computational e.ects by .rst trans\u00adlating it into a monadic metalanguage (for convenience, we abbreviate \nthis to MML). An MML is just a typed .-calculus that is equipped with the constants unit and bind. These \ntwo constants are computation constructors: they permit us to treat e.ectful computations as values of \nsome abstract datatype. Intuitively, unit constructs a computation that immediately returns a value, \nand bind sequences two com\u00adputations (where the second computation is parameterized on the results and \ne.ects of the .rst). We enrich MML with natural numbers, a successor function, and a family of .xed\u00adpoint \noperators in order to explore the meaning of in.nite computations such as nats. We then augment MML with \ntwo more computation constructors to handle backtracking. 3.1 Core MML The core MML has types a, \u00df ::= \ns | a . \u00df | Ta where s ranges over some scalar or base types (including nat and 1, the type whose only \nvalue is ()). a . \u00df is a function type, and Ta is an abstract type of computations that produce values \nof type a. The terms are given by: e ::= x | .x.e | e1 e2 | succ | cn | unita | bind\u00dfa This language \nis minimal, but it is a straightforward task to extend it with conditionals, pairs, booleans, a predecessor \nfunction, etc. The terms have types succ : nat . nat cn : nat (.n . N) unita : a . Ta bind\u00dfa : T\u00df . (\u00df \n. Ta) . Ta for each pair of types a and \u00df. unita takes a value v of type a to a computation which simply \nproduces v when run. bind\u00dfa cf denotes a computation that runs c and then runs the computation obtained \nby feeding c s result to f. The equations that must hold in this metalanguage are the usual \u00df and . laws \nof typed .-calculus, the standard monad laws, and the successor law: bind (unit e) f =(fe) bind e unit \n= e bind (bind cf) g = bind c (.v. bind (fv) g) succ cn = cn+1 The operations given so far capture .nite \nsequences of com\u00adputation, but in order to capture backtracking we must be able to construct computations \nthat represent more than a single answer. We turn to Hughes [8] for two such construc\u00adtors, and we add \na family of .xed-point operators to express in.nite computations. 3.2 Backtracking MML Hughes de.nes \na backtracking monad to be a monad with two additional constants disj and fail subject to additional \naxioms. The operation fail represents a computation that cannot produce further answers, and disj constructs \na com\u00adputation that produces answers generated by either of its constituent computations. The constants \ntypes and axioms are: faila : Ta disj a : Ta . Ta . Ta disj fail c = c disj c fail = c disj (disj c1 \nc2) c3 = disj c1 (disj c2 c3) bind (disj c1 c2) f = disj (bind c1 f)(bind c2 f) The laws state that fail \nis a left and right unit of disj , disj is associative, and bind distributes through disj . We also want \nto explore in.nite computations such as nats, and therefore we add a family of .xed-point operators subject \nto the following type and axiom: .xa\u00df : ((a . T\u00df) . (a . T\u00df)) . (a . T\u00df) .x e = e(.x e) We will consider \na MML with these additional constants and axioms. The interpretations of scalar types, function types, \nvari\u00adables, abstractions, application, numbers, successor, and .xed\u00adpoints of MML are .xed, but the interpretations \nof the com\u00adputation types and monad operations depend on the repre\u00adsentation of computations. We give \nthe .xed interpretations here and address the representation of computations in the following section. \nWe interpret MML types as complete partial orders (not necessarily with bottom), and we write aM for \nthe interpre\u00adtation of type a in a monad M. Scalar types are interpreted as discrete orders (i.e., sets \nwhose order is given by an equiv\u00adalence relation). For example, natM = N, and the ordering is the identity \nrelation. Function types are interpreted as cpo s of continuous functions: sM = Ds (a . \u00df)M =[aM . \u00dfM \n] Computation types Ta will always be interpreted as cpos with bottom. Our cpos need not have a bottom \nelement, but the function space [aM . \u00dfM ] has a bottom element whenever \u00dfM has one. We write .aM for \nthe ordering rela\u00adtion on the domain aM . If G : Var . Types, then EnvG, the set of G-consistent environments, \nis the set of all . . [Var . a aM ] such that forall x . dom(.), (.(x) . G(x)). We write e M for the \ninterpretation of an expression e in the monad M. IfG f e : a, then e M . [EnvG . aM ]. When e is closed, \nwe take the liberty of writing e M in place of e M . (where . . Env\u00d8). e M is de.ned as follows: x M \n. = .(x) .x.eM . = .v.(e M .[v/x]) (e0 e1)M . =(e M 0 .)(e M 1 .) succ M = .n.(n + 1) M c = n n . f(n) \n.xM = .f. n.. (.) As usual, .x is only de.ned on functions whose domain has a bottom element, and our \ninterpretations for computation types will always have bottom. This is why we assign the type given above \nfor .x. 3.3 From the Object Language to the MML Equipped with a metalanguage for backtracking, we now \nturn to the translation from the object language. Since our object-language is call-by-value, we use \nthe standard call-by-value translation [12]. This translation maps object\u00adlanguage functions to metalanguage \nfunctions that consume values and produce computations. Dually, the translation of an application intuitively \nreads: evaluate t1, bind the value to f, evaluate t2, bind the value to x, and .nally evaluate fx . The \ntranslation on types is: '.' = T. * s * = s (.1 . .2) * = .1 * . T. 2 * and the translation on terms \nis as follows: 'x' = unit x '.x.t' = unit (.x.'t') 't1 t2' = bind 't1' (.f. bind 't2' (.x.f x)) 'succ' \n= unit succ 'cn' = unit cn 't1 .t2' = disj 't1''t2' 'fail' = fail 'rec f.(.x.t)' = unit (.x .f..x.'t') \n We demonstrate this translation on nats and simplify the result with \u00df, ., the monad laws, and the .xed \nportion of MML s interpretation: 'nats' = 'nats-from(c0)' = '(rec f.(.n.n .f(succ n))) c0' = bind 'rec \nf.(.n.n .f (succ n))' .f. bind 'c0' (.x.f x) = bind (unit (.x .f..n.'n .f(succ n)')) .f. bind (unit \nc0)(.x.f x) = bind (unit c0) (.x .f..n.'n .f(succ n)') =(.x .f..n.'n . f(succ n)') c0 =(.x .f..n. disj \n(unit n) 'f(succ n)') c0 = disj (unit c0) bind (unit (.x .f..n.'n .f(succ n)')) .g. bind 'succ c0' (.x.gx) \n= disj (unit c0) bind 'rec f.(.n.n .f(succ n))' .g. bind 'c1' (.x.gx) = disj (unit c0) 'nats-from(c1)' \nWe see that the result is a computation that produces either c0 or the result of evaluating 'nats-from(c1)', \nas expected.  4. TWO BACKTRACKING MONADS There are two well-known models of backtracking com\u00adputation, \nand they are, in fact, both backtracking monads. The .rst one models backtracking computations as a stream \nof answers, and the monad operations correspond to stan\u00addard operations on streams. The second model \nrepresents backtracking computations as procedures that consume two continuations. The .rst continuation \nis a success contin\u00aduation; it consumes an answer and a second continuation that can be invoked to get \nanother answer. A computation will invoke the second continuation when it has no further answers of its \nown to produce. 4.1 Stream Monad The stream monad S is given by the following domain and interpretations \nfor types and the monad operations. The domain S(A) of streams over elements of A is de.ned as follows: \nS(A)= . . {(a1,...,an)| n = 0,ai . A}. {(a1,...,an) .| n = 1,ai . A}. {(a1,... )| ai . A} where is stream \nappend (with w1 w2 = w1 when w1 is in\u00ad.nite or .). The element . represents a computation that runs \nin.nitely without deciding if there are any answers. The element (a1,...,an) represents a .nite stream \nwith ex\u00adactly n elements. The element (a1,...,an) . represents a computation that has determined the \n.rst n elements in the stream but runs in.nitely when trying to decide if there are any more answers. \nLast, (a1,... ) represents an in.nite stream. The ordering on streams is a pre.x ordering, S(A), de\u00ad.ned \nas follows. For all s . S(A): . S(A) s (a1,a2,...,an) S(A) (b1,b2,...,bn) .. aiA bi (1 = i = n) (a1,a2,...,an) \n. S(A) (b1,b2,...,bn) s .. aiA bi (1 = i = n) (a1,a2,...) S(A) (b1,b2,...) .. aiA bi (.i . .) The .rst \nclause says that . is related to all streams. The second clause says that two .nite streams are related \nif and only if they are the same length, and the elements are point\u00adwise related. The third clause relates \nstreams whose tail is unde.ned to streams which are at least as de.ned, point\u00adwise. In.nite streams are \nrelated if and only if their elements are pointwise related.1 We write aS or e S for the interpretation \nof type a or meta\u00adlanguage term e in the monad S. Scalar and function types are interpreted as stated \nin section 3.2, and computation types are interpreted as stream domains: (Ta)S = S(aS ) The constant \nunit constructs a singleton stream, bind is map-append, fail is the empty stream, and disj is stream\u00adappend: \nunitS = .a.(a) bindS . f = . bindS (a1,...,an) f = f(a1) ... f(an) bindS (a1,...,an) . f = f(a1) ... \n f(an) . bindS (a1,... ) f = f(a1) ... failS = () disj S = .c1c2.(c1 c2) The stream monad yields an \ninterpretation of nats that is equivalent to the in.nite stream of natural numbers in 1Note that (1, \n2) S(N) (1, 2, 3) does not hold under this ordering. The following does hold: (1, 2) . S(N) (1, 2, 3). \nascending order: 'nats'S = 'nats-from(c0)'S =(disj (unit c0) 'nats-from(c1)')S = disj S (unit c0)S 'nats-from(c1)'S \n= (c0) 'nats-from(c1)'S 4.2 Two-Continuation Monad The two-continuation monad K is slightly more involved \nthan the stream monad; it is constructed as follows. Let O be a domain of observations; that is, O will \ncontain the values that we can observe when a computation terminates. A computation must terminate in \norder to observe a result. We therefore assume that O does not contain a bottom ele\u00adment signifying non-termination. \nSensible choices for O in\u00adclude any domain of scalars and the domain of streams over scalars (consider \nthe stream of answers printed in the Pro\u00adlog REPL). For the latter, we set O = S(natS) - {.}. We write \nO. to denote O with a bottom element (re-)adjoined. The process of choosing an O is coupled with the \nprocess of choosing initial continuations in which to run computations. We explore this dimension towards \nthe end of section 6. Now we de.ne K(A) = [[A . [1 . O.] . O.] . [1 . O.] . O.] The domain [1 . O.] is \nthe domain of failure continua\u00adtions, and [A . [1 . O.] . O.] is the domain of success continuations. \nA success continuation takes an answer in A and a failure continuation. If the computation has an an\u00adswer \nto produce, it will send it to the success continuation. It will also pass along a failure continuation \nthat, if invoked, will continue computation with the next answer. If a com\u00adputation cannot produce any \nmore answers, it will invoke its failure continuation to produce an answer. We interpret scalar and function \ntypes as in the stream monad, but the computation types are interpreted using K instead of S: sK = Ds \n(a . \u00df)K =[aK . \u00dfK ] (Ta)K = K(aK ) The monad operations are interpreted by: unitK = .a.(..f..af) bindK \n= .cf.(..f.c (.bf.fb.f) f) failK = ..f.f() disj K = .c1c2.(..f.c1.(.().c2.f)) The constant unitK constructs \na computation that succeeds just once with the given value a, and bindK extends the success continuation \nof c by applying f to c s result in the original continuations. Note that when c fails, the entire bindK \nexpression fails; this is useful for modeling conjunc\u00adtion. failK is a computation which simply invokes \nits failure continuation, and disj K evaluates to its .rst computation c1 in an extended failure continuation. \nShould c1 fail, c2 s answers will be sent to the success continuation. The argu\u00adment to the failure continuation \nin the last case must be (), the single element of type 1, hence we write (.()....) in the de.nition \nof disj K . The two-continuation monad yields an interpretation of nats that, when handed a success and \na failure continuation, will pass c0 and a new failure continuation to the success continuation. If invoked, \nthe new failure continuation will produce the rest of the answers. 'nats'K .f = 'nats-from(c0)'K .f =(disj \n(unit c0) 'nats-from(c1)')K .f = disj K (unit c0)K 'nats-from(c1)'K .f =(..f.. c0 f) . (.().'nats-from(c1)'K \n.f) = .c0 (.().'nats-from(c1)'K .f)  5. RELATING THE TWO MODELS We relate the two semantics with a logical \nrelation. A logical relation R consists of a type-indexed family of rela\u00adtions Ra for each type a in \nthe language. At scalar type Ds we choose Rs to be the identity relation on because the models share \na representation of scalars. We then de\u00ad.ne the relation at higher-order types inductively. The .rst \nwell-known use of this technique is in Plotkin [13], though he credits Troelstra [18]. Mitchell [11] \nprovides a thorough account of logical relations. Figure 1: A logical relation relates the models of \ntwo semantics. Our logical relation R is de.ned as follows. For each type a in the metalanguage, we de.ne \na relation Ra . (aS \u00d7aK ) by induction on a, as follows: 1. Rs is the identity relation on the shared \ninterpretation of scalar types s. 2. Ra.\u00df = {(f, g) |.(a, a') . Ra.(fa, ga') . R\u00df} 3. RTa is the smallest \nrelation on S(aS ) \u00d7 K(aK ) such that:  (., .) . RTa.  ((), ..f.f()) . RTa.   '' if (a1,a1),..., \n(an,an) . Ra, then ((a1,...,an), (.k.(ka'1) * (ka'\u00b7\u00b7\u00b7 * (ka'))) . RTa 2) * n(n = 1) ((a1,...,an) ., \n(.k.(ka'1) * (ka'\u00b7\u00b7\u00b7 * (ka' 2) * n) * .)) . RTa RTa is closed under limits of .-chains in (Ta)S \u00d7 (Ta)K \n. * is a right-associative composition-like operator; it is de\u00ad.ned by f *g = .x.f(.().gx) We use * to \ncompose two functions that each consume a failure continuation: ...(.a) * (.b)= ..f..a(.()..bf) Lemma \n1 states that * amounts to a representation of stream\u00adappend. Lemma 1. If (c1,c 1' ), (c2,c 2' ) . RTa, \nthen (c1 c2, (.k.(c1 ' k) * (c2 ' k))) . RTa Proof: By induction on the structure of c1 and closure \nof RTa under limits of .-chains. We illustrate the case where c1 is in.nite. c1 and c ' 1 are both limits \nof .-chains: . c1 = sn, where sn sn+1 n.. . ' ' ' ' c1 = sn, where sn sn+1 n.. where sn s ' n = = (a1, \n. . . , an) . .k.(k a ' 1) * \u00b7 \u00b7 \u00b7 * (k a ' n) * . ' Since (c1,c 1) . RTa and RTa is closed under limits \nof .\u00adchains of related values, we know .n . ..(sn,s n' ) . RTa It is easy to show, by induction that \nfor all n, (sn c2, ...(s ' .) *c 2' ) . RTa n It is easy to verify that sn c2 and ...(sn' .) *c ' 2 \nare both .-chains. We note that * is continuous since it is de.nable using just abstraction and application. \nSince RTa is closed under limits of .-chains of related values, we deduce (c1 c2, .k.(c1 ' .) * (c2 ' \n.)) = n..(sn c2, ...(s ' n .) * (c ' 2 .)) . RTa Lemma 2. R is a logical relation. Proof: We must show \nthat the denotations of each constant are related. We illustrate the case for disj . We must show (disj \nS , disj K ) . RTa.Ta.Ta. Assume (s, s ' ), (t, t ' ) . RTa. Then disj S st = s t K ' ' '' disj st = \n...(s.) * (t.) and so, by Lemma 1, (disj S s t, disj K s ' t ' ) . RTa. But since we chose (s, s ' ) \nand (t, t ' ) arbitrarily, we use the de.\u00adnition of logical relation at function type twice to conclude \nthat (disj S , disj K ) . RTa.Ta.Ta. Two environments . and . ' are logically related with respect to \nsome type environment G when their domains agree and they map variables to related values: (., . ' ) \n. RG .. dom(.)= dom(. ' )= dom(G) ..x . dom(G).(.(x),. ' (x)) . RG(x) Theorem 1. If G f e : a and (., \n. ' ) . RG, then (e S., eK . ' ) . Ra. Proof: Immediate from Lemma 2 and the Basic Lemma of Logical Relations \n[11]. Theorem 2. Let e be a closed backtracking MML term of type Ts. Then e S =(e K cons nil), where \ncons = .af.(a) f() nil = .().() Proof: Let O = S(Ds) - {.}. If e is a closed backtracking MML term of \ntype Ts, and e S = (a1,...,an), then e K = (.k.(ka1) * (ka2) * \u00b7\u00b7\u00b7 * (kan)). So e K cons = .s. cons a1 \n(cons a2 (cons a3 ... (cons an s) ... )) and therefore K e cons nil = cons a1 (cons a2 (cons a3 ... (cons \nan nil) ... )) = (a1,...,an) S = e The other cases follow by continuity. Since this is a denotational \nequivalence, an operational semantics for metalanguage terms that is adequate for one denotational semantics \nwill be adequate for the other. We explore this result in section 6. From Failure Continuations to Failure \nComputations. Another model K ' can be obtained by replacing the fail\u00adure continuations [1 . O.] by failure \ncomputations O., so K ' (A)=(A . O. . O.) . O. . O., and unitK' = .a.(..f..af) bindK' = .cf.(..f.c (.bf.fb.f) \nf) failK' = ..f.f disj K' = .c1c2.(..f.c1 . (c2.f))) The logical relation is obtained by replacing the \ncomposition\u00adlike operator * with standard functional composition . in the de.nition of RTa, to get '' \n' ((a1,...,an), (.k.(ka 1) . (ka 2) .\u00b7 \u00b7\u00b7. (ka n))) . RTa etc. This leads to a version of the story in \nwhich one passes along expressions to be evaluated in case of failure rather than procedures that must \nbe invoked to retrieve more an\u00adswers.  6. AN ADEQUATE OPERATIONAL SEMANTICS We supply an operational \nsemantics for the backtracking MML in three stages. First, we de.ne a monadic metalan\u00adguage mPCF that \nis simpler than the backtracking MML. We then translate the latter into mPCF in such a way that the K \nsemantics is equal to this translation followed by mPCF s semantics, L. Finally, we provide an adequate \nop\u00aderational semantics for mPCF. This tactic greatly simpli.es both the operational semantics and the \nproof of adequacy that follows. The adequacy proof demonstrates that the given operational semantics \nis adequate with respect to the L semantics, and therefore it is adequate for the K seman\u00adtics. Since \nthe two-continuation semantics and the stream semantics are logically related, the adequacy result extends \nfrom K to S. 6.1 mPCF mPCF is a MML that captures nontermination as a com\u00adputational e.ect. We include \na type Snat for streams of natural numbers and stream constructors cons and nil with these types2: nil \n: Snat cons : nat . L(Snat) . Snat The types and terms are generated by the following gram\u00admar: t ::= \ns | t1 . t2 | Lt | Snat M ::= x | .x.M | M1M2 | succ | cn | unit | bind | .x | cons | nil We have renamed \nthe type constructor T to L to avoid con\u00adfusion between backtracking MML and mPCF computation types. \nWe write Mt for the set of closed terms of type t. We interpret mPCF in the lift monad. The interpretations \nfor scalar and function types are as before, and L interprets computation types as lifted domains. Finally, \nL interprets Snat as streams of natural numbers. sL = Ds (t1 . t2)L =[t1 L . t2 L] (Lt)L =(t L). (Snat)L \n= S(natS ) - {.} The interpretations for variables, abstraction, application, succ, cn, and .x remain \nas they are in the monads S and K. In L, unit takes a value to a computation that terminates with that \nvalue, and bind encodes strict application: unitL = .d. lift(d) bindL = .cf. case c of ... | lift(d) \n. f(d) Observe that (L(Snat))L =(S(N) - {.}). = S(N). There\u00adfore we can de.ne nilL and cons L in the \nusual way. nilL = () . (L(Snat))L cons L = .xy.(x) y . (L(Snat))L 6.2 Translating from MML to mPCF \nOur translation from MML to mPCF is straightforward; we simply implement the two-continuation semantics \nin mPCF. The translation on types is crafted such that IalL = aK . Let O be any mPCF type such that OL \n= O (e.g., O = Snat or nat). Isl = s Ia . \u00dfl = Ial.I\u00dfl ITal =(Ial. (1 . LO) . LO) . (1 . LO) . LO 2Our \nresults can be extended to streams Sa of arbitrary type, but we do not need the additional generality \nhere. Iunitl = .a...f..af Ibindl = .cf...f.c (.bf.fb.f) f Idisj l = .c1c2...f.c1 . (.().c2 .f) Ifaill \n= ..f.f() I.xl = .x Isuccl = succ Icnl = cn Ixl = x I.x.el = .x.Iel Ie1 e2l = Ie1lIe2l As in section \n4.2, we restrict the argument of failure con\u00adtinuations to be (). Also, note that this translation never \nproduces any unit or bind terms in mPCF. The K interpretation of types is preserved by I\u00b7l: Lemma 3. \nFor any backtracking MML types a, we have: aK = IalL Proof: By a trivial induction on a. The K interpretation \nof terms is also preserved by I\u00b7l: Theorem 3. For MML terms e, if G f e : a and . is G-consistent, then \ne K . = IelL. Proof: By induction on the structure of e. No translation on . is necessary, due to Lemma \n3. In the next section we give an operational semantics for mPCF and prove that it is adequate with respect \nto L. The\u00adorem 3 is signi.cant in this context because it says that we can evaluate an MML program by \ncompiling it into mPCF and applying mPCF s evaluator.  6.3 Operational Semantics We provide a deterministic \ncall-by-name operational se\u00admantics for mPCF. The grammar for values V and evalua\u00adtion contexts E is: \nV ::= cn | .x.M | unit M | cons VM | nil | cons V | bind V | succ | unit | bind | .x E ::= [] | EM | \nbind E | succ E | cons E We write V t to refer to the set of closed values of type t. Reduction halts \nif the term reaches any constant, an ab\u00adstraction, or unit of some term.3 Evaluation is permitted in \nan empty context, in the operator position of an application, in the .rst argument of bind, and in the \noperand position of successor. (We permit the latter because the type of succ precludes the possibility \nthat its argument diverges.) The reduction for application is standard \u00df reduction, and we augment this \nrule with reductions for successor and the standard reduction for a call-by-name .xed-point operator. \nThe reduction and context for bind encodes strict applica\u00adtion. (.x.M1) M2 . M1[M2/x] succ cn . cn+1 \n.x M . M(.x M) bind (unit M1) M2 . M2 M1 bind (bind M1 M2) M3 . bind M1 .v. bind (M2v) M3 It is straightforward \nto verify that this semantics satis.es safety and progress. 3Remember that unit, in the context of mPCF, \nmeans the computation has terminated with some result. 6.4 Adequacy Proof: By structural induction on \nt and coinduction at Snat. Now we prove the adequacy of our operational semantics with respect to the \nlift semantics, L. The main result is theorem 4. It states that a closed term M reduces to a Lemma 6 \nis the main lemma for the adequacy proof; it is value in the operational semantics if and only if M does \nnot used to show the reverse implication in the adequacy the\u00addenote .. This property is of particular \ninterest when M is orem. Let . range over substitutions of closed terms for of an observable type; we \ncan use it to show that these two variables, and de.ne . =G . .. .x . dom(G)..(x) =G(x) semantics agree \non the meaning of terms whose values are .(x). Let M \u00b7 . denote the simultaneous, capture-free sub\u00adobservable. \nOur presentation follows that of Winskel [22]. stitution of the free variables in M for their values \nin .. Assume M is a closed mPCF term. De.ne operational Lemma 6. If G f M : t and . =G ., then ML. =t \nM \u00b7 .. convergence (1) for M and denotational convergence (2) for M as follows: Proof: By induction on \nthe structure of M. M . .. .v.(M . * v) (1) L M = x: x. = .(x) =t .(x)= x \u00b7 . holds since . =G .. M \n. .. f M : s (2) . .f M : t1 . t2 M = .x.M0: .f M : Snat We must show .f M : Lt ..d . t L.ML = lift(d) \n (.x.M0)L. =o (.x.M0) \u00b7 . t1.t2 Theorem 4 (Adequacy). If M is a closed mPCF term, ' Fix an arbitrary \n(d ' ,e ) . (=t1 ). By de.nition of then M . .. M . =o , we must demonstrate t1.t2 Proof: ((.x.M0)L.)(d \n' ) =t2 (((.x.M0) \u00b7 .)e ' ) ML ' ) =.: The forward implication follows directly from .. 0 .[d ' /x] \n=t2 (((.x.M0) \u00b7 .)e Lemma 4 below. . .. .w.(((.x.M0 \u00b7 .) e ' ) . * w . M0 L.[d ' /x] =ot2 w) Following \nthe de.nition of ., the application on the below and considering only closed terms. . left-hand side \ntakes a step and the goal becomes: .=: The reverse implication follows from Lemma 6 ' L ' .w.(M0 \u00b7 .[e \n/x] . * w . M0 .[d /x] =o w) t2 We have that G,x : t1 f M0 : t2 and .[d ' /x] =G,x:t1 Note that if M \nis not of computation type, then M ., and .[e ' /x], and so, inductively, we can assume hence M reduces \nto a value v. L '' M0 .[d /x] =t2 M0 \u00b7 .[e /x] Lemma 4. For closed mPCF terms M, we have Unfolding the \nde.nition of =t2 completes the proof: M . * v =. ML = v L .w.(M0 \u00b7 .[e ' /x] . * w . M0 L.[d ' /x] =ot2 \nw) Proof: By induction on the length of the reduction se\u00adquence. . M = M1 M2: In order to prove the converse, \nwe de.ne an approximation Let G f M1 : t1 . t2,G f M2 : t1, and . =G .. relation =ot between denotations \nand closed values for each Inductively, assume: type t. In order to express that a denotation approximates \n \u00d7 V t L a closed term, we use =t . De.ne (=ot ) . (tL ) and M1 . =t1.t2 M1 \u00b7 . (3) (=t ) . (tL \u00d7 Mt \n) by induction on t: L M2 . =t1 M2 \u00b7 . (4) d =o d . DsL s v .. . d = v '' (3) implies there is a closed \nvalue v such that d =o v .. .(d ' ,M ) . (=t1 ).d(d ' ) =t2 (vM ) t1.t2 d =o unit(M) .. d = .. d = \nlift(d ' ) . d ' =t MM1 \u00b7 . . * v . (M1 L.) =to 1.t2 v d =o .. d = () and v = nil Lt S(nat) v and unwinding \nthe de.nition of =o gives ' t1.t2 . d = (a) b and v = cons vM s.t. a =o ' and b =L(S nat) M .(d '' \n' nat v ,M ) . (=t1 ).(M1 L.)(d ' ) =t2 (vM ) d =t M .. .v.(M . * v . d =ot v) Applying (4) we infer \nThe recursion in the de.nition of =o is to Snat and =Snat LL be interpreted coinductively. That is, =o \n(M1 .)(M2 .) =t2 (vM2 \u00b7 .) Snat and =Snat are de.ned to be the largest relations satisfying the given \nL = (M1M2). =t2 (vM2 \u00b7 .) (5) conditions. This allows d =o v to hold even in cases Snat By (5): We note \nin Lemma 5 that the approximation relation is L when d is an in.nite stream. .w.(vM2 \u00b7 .) . * w . (M1M2). \n=ot2 w closed under limits of .-chains on the left. But M1 . * v and (vM2 \u00b7 .) . * w implies Lemma 5. \nLet f M : t. If d0 d1 ... dn ... is an .-chain in tL and .n . ..dn =t M, then . n.. dn =t M. M1M2 \u00b7 . \n. * w and therefore (M1M2)L. =t2 M1M2 \u00b7 . D M = cn: Follows trivially from the de.nitions of (=nat ) \nand (=o nat ). D M = succ: Assume M0 L = n =nat M0. Then .v.M0 . * v . n =o nat v By de.nition of =o \nnat , v = cn. We must show (succ M0)L =(n + 1) =nat succ M0 .. .w.(succ M0 . * w . (n + 1) =o nat w) \nSince M0 cn, we know succ M0 cn+1. More\u00ad . * . * over, (n + 1) =o cn+1, and so choosing w = cn+1 nat \ncompletes the proof. D M = unit: Assume M0 L =t M0. We must show (unit M0)L = lift(M0 L) =o unit M0 Lt \n.. .w. unit M0 . * w . lift(M0 L) =Lto w But since lift(M0 L)= ., it su.ces to choose w = unit M0. D \n M = bind: We show bindL =Lt2.(t2.Lt1).Lt1 bind by proving (bind M1 M2)L =Lt1 bind M1 M2 whenever ML \n1 =Lt2 M1 and ML 2 =t2.Lt1 M2 We proceed by cases on M1 L . ML bindL . M2 L = ., and so this case holds \nby the de.nitions of =Lt1 and =o 1 =.: Lt1 . ML Unwinding the de.nition of bindL, we must show M2 L(d) \n=Lt1 bind (unit M) M2 By de.nition of =Lt1 and the operational seman\u00adtics, the goal becomes M2 L(d) =o \n(M2 M) 1 = lift(d): Lt1 The inductive hypotheses are lift(d) =Lt2 unit M (6) L M =t2.Lt1 M2 (7) 2 (6) \ngives us d =t2 M, and applying (7) yields the goal. D M = .x: We must show L .x=((t1.Lt2).(t1.Lt2)).(t1.Lt2) \n.x It su.ces to assume (.f.M)L =(t1.Lt2).(t1.Lt2) .f.M and show (.x .f.M)L . =t1.Lt2 (.x .f.M) .. g(n) \n=t1.Lt2 (.x .f.M) (8) n.. where g =(.f.M)L = ...ML[./f]. (8) follows from .n . ..g(n) =t1.Lt2 (.x .f.M) \n(9) and Lemma 5. We prove (9) by induction on n. When n = 0, .=t1.Lt2 (.x .f.M) follows from the de.nitions \nof =t1.Lt2 , =ot1.Lt2 , =Lt2 , and =o Lt2 . Now, inductively, we assume g(n) =t1.Lt2 (.x .f.M) and must \nshow (n+1) g=t1.Lt2 (.x .f.M) (10) Expanding the de.nition of =t1.Lt2 , the goal becomes: (n+1) .v.(.x \n.f.M) . * v . g=o v t1.Lt2 By the operational semantics (.x .f.M) . (.f.M)(.x .f.M) . M \u00b7 [(.x .f.M)/f] \nWe choose v to be M \u00b7 [(.x .f.M)/f], and we know (n+1) L(n) g= M[g/f] Therefore our goal becomes ML[g(n)/f] \n=ot1.Lt2 M \u00b7 [(.x .f.M)/f] We note that [g(n)/f ] =G [(.x .f.M)/f], and therefore by structural induction \nwe have ML[g(n)/f] =t1.Lt2 M \u00b7 [(.x .f.M)/f] Unwinding the de.nition of =t1.Lt2 satis.es our goal. D \nM = nil: We must show nilL = () =S(nat) nil, but this is imme\u00addiate since nil is a value and () =o nil. \nD S(nat) M = cons: Assume n =nat N and d =S(nat) M0. We must show cons L nd =S(nat) cons NM0 . * We know \n(1) cons NM0 cons cn M0, and (2) ncn by the .rst inductive hypothesis. Com\u00ad =o nat bining (2) with the \nsecond inductive hypothesis gives us cons L nd =o M0 S(nat) cons cn Thus, in conjunction with (1), we \ndeduce .v. cons NM0 . * v . cons L nd =o S(nat) v and the goal immediately follows. D There are a number \nof notable corollaries of the adequacy theorem. The .rst says that the operational semantics and the \nL semantics agree on programs of scalar, function, and stream-of-scalar type: Theorem 5. Let M be a closed \nmPCF term of scalar, function, or stream-of-scalar type. Then M . * v .. ML = v L The second says that \nthe operational semantics and the L semantics agree on programs of computation type: Theorem 6. Let f \nM : Lt for some mPCF term M. Then: LL L M . * (unit M0) .. .d . t.(M= lift(d) . M0 = d) Proof: Both theorems \n5 and 6 are immediate via adequacy. The stream semantics is also related to the operational se\u00admantics. \nBy varying the type of observables, we can deduce di.erent relations between them. First, let e be a \nback\u00adtracking term of type T nat. We show that the .rst answer produced is related to the .rst element \nof the stream e S . Let our observable domain O be N. Encode a stream whose head is n as the natural \nnumber n+1, and encode the empty stream as 0. Theorem 7. Let e be a closed backtracking MML term of type \nT nat, and de.ne .0 =(.n..f.(unit(succ n))) f0 = .(). unit c0 Then Iel .0 f0 . * (unit M) i. either (1) \ne S = () and ML =0 (2) e S = (n) w and ML = n +1 Proof: From Theorem 1 we know that (e S ,e K ) . RTa \n(11) and by Theorem 3 we know K = IelL e We consider each case of the shape of the stream e S : case \ne S = .: K .L fLK .L fL By (11), e = .. Hence IelL 00 = e 00 = .. So, by Theorem 6, Iel .0 f0 does not \nreduce to a value. case e S = (): By (11), e K = ....f.f(). Hence, IelL 0 fL 00 () = .L = fL lift(0). \nSo, by Theorem 6, Iel .0 f0 unit(M), . * where ML = 0. case e S = (n) w: By (11), e K = ...(.n) *w ' \n, where (w, w ' ) . RTa. Hence LL KLL IelL .0 f0 = e.0 f0 L ' L =(.0 n)(.().(wf0 )) = lift(n + 1) By \nTheorem 6, Iel .0 f0 . * unit(cn+1).  We can derive a stronger relationship between the stream semantics \nand the operational semantics by choosing a dif\u00adferent observable domain. Theorem 8. Let e be a closed \nbacktracking MML term of type T nat, let O= Snat, and de.ne .0 = .af. unit(cons af()) f0 = .(). unit(nil) \nThen Iel .0 f0 . * unit(M) i. either (1) e S = () and M = nil (2) e S = (n) w and M = cons cn M0 and \nM0 L = w  Proof: If O = Snat, then O. = S(N). Note that .L 0 and fL 0 are just cons and nil as de.ned \nin Theorem 2. From Theorem 1 we know that (e S ,e K ) . RTa (12) and by Theorem 3 we know e K = IelL \nWe consider each case of the shape of the stream e S : case e S =.: By (12), e K = .. Hence e K .L fL \n= IelL .L fL = 00 00 .. So, by Theorem 6, Iel .0 f0 does not reduce to a value. case e S = (): By (12), \ne K = ..f.f(). Hence LL KLL IelL .f= e .f 00 00 L = f0 () = lift(()) So, by Theorem 6, Iel .0 f0 . * \nunit(nil). case e S =(n) w: By (12), e K = ...(.n) *w ' , where (w, w ' ) . RT (nat). Hence LL KLL \nIelL .0 f0 = e.0 f0 L ' L =(.0 n)(.().(wf0 ))) ' L = lift((n) (wf0 )) . * So, by Theorem 6, Iel .0 f0 \nunit(cons cn M), ' fL where ML =(w 0 ).   7. RELATED WORK Both the stream and two-continuation models \nhave a long history in Prolog implementations. The stream model was invented independently by Abelson \nand Sussman [1], Kahn [9], and Wadler [19]. The two-continuation model appears in Federhen [5] though \nit is undoubtedly older. Kahn [9] discusses upward failure continuations versus downward success continuations \nas strategies for embedding the two\u00adcontinuation model in a stack architecture. It is worth noting that \nthe computational model of Pro\u00adlog is a stripped-down version of the backtracking monad. Prolog programs \ndo not pass any values; all communica\u00adtion happens by modifying the current substitution. In this sense, \nProlog programs are actually imperative programs in the backtracking monad. This means that the param\u00adeter \nof the computation type is .xed. Rather than dealing with Ta for arbitrary a, Prolog models need only \nconsider T (Subst), where Subst is the type of substitutions. This sim\u00adpli.ed form of computation makes \nthe relationship between T (Subst)S and T (Subst)K far less complicated than in the general case that \nwe explore. The de.nition of a backtracking monad comes, inter alia, from Hughes [8]. Hughes also presented \na derivation of the two-continuation model from the axioms via fold-unfold transformations [2]. This \nderivation is .awed in two ways: .rst, it depends on an induction hypothesis that is at best problematical. \nWe will discuss this issue below. Further\u00admore, the derivation shows only that if e = v is deducible \nin the derived system, then it is also deducible in the original system. It does not show that if e = \nv is deducible in the original system, it is also deducible in the derived system. That is, the derived \nsystem is sound but not adequate with respect to the original. This is a standard problem with fold-unfold \ntransformations [14] that must be addressed if we are to deal correctly with possibly non-terminating \ncom\u00adputations. Hinze [7] extended Hughes result from monads to monad transformers. His derivation followed \nthat of Hughes, with the same di.culties. The problem in establishing even the soundness of these derivations \nlies in writing down an induction hypothesis that is strong enough to support the proof. Both of the \nproofs represent computations by higher-order abstract syntax, so that they are envisioned as trees, \nwhich might be expressed in Haskell as: data Comp a = Unit a | forall b.Bind (Comp b) (b -> Comp a) To \nillustrate the di.culty, consider the calculation near the end of Section 5.2 of [8]: (m bind f)(ValueBind(value \n.k)) =(m bind f) bind k) (13) = m bind .x . (fx bind k)) (14) = m(ValueBind(.x . value(fx bind \n k))) (15) = m(ValueBind(.x . fx(ValueBind(value .k)))) (16) Here, (13), (15) and (16) are instances \nof the induction hypothesis m(ValueBind(value .k)) = value(m bind k) and the conclusion is an instance \nof the same equation, with m replaced by m bind f. But what is the induction mea\u00adsure here? (1) and \n(3) use the induction hypothesis at m, which is certainly smaller than m bind f . But (16) uses it \nat (fx), which might be larger than m bind f. Hinze [personal communication] has suggested the follow\u00ading \ninduction principle: to prove a property P for all ele\u00adments of Comp a, prove the following (where here \na, b range over values, not types): 1. P (Unit a) 2. If P (m) and for all b, P (f(b)), then P (Bind \nmf)  This would work .ne if the elements of Comp a were B\u00adway trees of .nite depth for any .xed B (e.g., \nB = Subst as suggested above for Prolog); the induction principle would be justi.ed by induction on the \nheight of the tree. Trees of in.nite depth, as generated by .x, would be handled by appropriate continuity \narguments. Unfortunately, the elements of Comp a are not B-way trees of .nite depth. Choose a to be int \nand b to be (Comp int). Then Bind at Comp int is an injection from (Comp (Comp int)) * (Comp int -> Comp \nint) to (Comp int). Therefore (Comp int) is required to contain its own function space as a subset. Thus, \n(Comp int) does not meet our expectation that it look like a set of trees, and the induction principle \nsuggested above is problematical at best. It is possible that this induction principle is .xable, but \nit would clearly involve order-theoretical niceties. We avoid this dilemma by treating the metalanguage \nas an ordinary .-calculus, without the complications of higher\u00adorder abstract syntax. Haskell implementations \nessentially do the same thing: the second component to Bind is repre\u00adsented not as a function, but as \na closure. Since Haskell does not allow testing for equality between higher-order values, there is no \nway to detect the di.erence inside the language. Another approach to this problem is to try to describe \nthe two-continuation model as a representation of the oper\u00adational semantics of the stream model. We \nhave explored .nal algebras for this purpose [21, 10, 6]. In this approach, the stream is represented \nby its actions on success (unit) and failure (fail). This also gives soundness but not ade\u00adquacy. Other \nalternatives are to represent the stream by its case function (sometimes called the Scott representation \n[20]) or by its fold function (corresponding to the Church representation); neither of these representations \nyields the two-continuation model. Our representation is similar to a Church representation, except that \nthe .rst argument to the fold function (the action on cons ) is required to be distributive. The approach \nclosest to ours is that of Danvy et al. [4], who formulate the problem in terms of monad morphisms. They \ndeal only with a .rst-order object-language, and the behavior of their proposal under .xed-points is \nnot clear. Although they do not set out their representation explicitly as we do in case 3 of the de.nition \nof our logical relation, their representation coincides with ours for .rst-order quan\u00adtities. Seres, \nSpivey, and Hoare [16, 15] also explore the relation\u00adship between backtracking monads. They are interested \nin monads that capture search strategies for logic programs. They formulate three monads: the .rst captures \ndepth-.rst search, the second breadth-.rst, and the third allows both. They de.ne monad morphisms from \nthe third one to both the .rst and second. Both monads in this paper implement depth-.rst search. Claessen \nand Ljungl\u00a8of extend Seres and Spivey s embed\u00adding of Prolog into Haskell [16] by using more sophisticated \ntypes. Certain Prolog programs which would normally just fail at run-time are considered ill-typed in \ntheir system. To accomplish this, they generalize their type of substitutions by taking advantage of \nextensions provided by the GHC im\u00adplementation of Haskell. Thielecke [17] investigates the relationship \nbetween the answer type for CPS terms and the control e.ects exhibited by those terms. He employs a type-and-e.ect \nsystem to reason about control e.ects. This work could be useful in re.ning our formulation of observable \ntypes in backtracking programs. Gordon and Crole [3] have developed a technique for fac\u00adtoring adequacy \nproofs for languages whose semantics is or\u00adganized monadically. Essentially, they prove adequacy of an \nobject-language operational semantics by relating it to an adequate metalanguage operational semantics. \n 8. FUTURE WORK We intend to provide operational semantics for the the backtracking metalanguage, MML, \nand also one for the ob\u00adject language. We would like to extend our adequacy re\u00adsult to these semantics. \nThis goal exists in the context of a larger goal: we would like to explore how program anal\u00adyses of metalanguage \nprograms relate to analyses of cor\u00adresponding object-language programs. For example, if we perform a \n.ow analysis on a mPCF program, does this in\u00adduce a useful .ow analysis for the corresponding MML and \nobject-language programs? Finally, we believe that it is de\u00adsirable to automate these techniques by formalizing \nthem in a theorem-prover or a metalogic. 9. SUMMING UP We attack the long-standing question of the relationship \nbetween two well-known models of backtracking computa\u00adtion. We are able to relate the two models, and \nwe accommo\u00addate higher-order quantities and in.nite computations using a logical relation. Since the \nmodels share a representation of observable values, we obtain a denotational equivalence at observable \ntypes. This means that an operational semantics that is adequate for one model is adequate for the other. \nWe provide an operational semantics which is adequate for mPCF, a variant of PCF that can express non-terminating \ncomputations. By giving a translation from MML to mPCF, we obtain an evaluator for MML programs. Since \nthe trans\u00adlation preserves semantics, the evaluator for MML programs is adequate for both the two-continuation \nand stream seman\u00adtics. 10. ACKNOWLEDGEMENTS We thank David Herman for his comments and for iden\u00adtifying \na bug in the adequacy proof. We also express our gratitude to the anonymous referees for their insightful \ncom\u00adments. 11. REFERENCES [1] Hal Abelson and Gerald Jay Sussman. The Structure and Interpretation of \nComputer Programs. MIT Press, Cambridge, MA, 1985. [2] Rod M. Burstall and John Darlington. A transformation \nsystem for developing recursive programs. Journal of the ACM, 24:44 67, 1977. [3] R. L. Crole and A. \nD. Gordon. Factoring an Adequacy Proof. In C. J. van Rijsbergen, editor, FP 93 Glasgow Workshop on Functional \nProgramming, Workshops in Computing, pages 9 25. Springer-Verlag, 1994. [4] Olivier Danvy, Bernd Grobauer, \nand Morten Rhiger. A unifying approach to goal-directed evaluation. New Generation Computing, 20:53 73, \n2002. [5] Scott Federhen. A mathematical semantics for PLANNER. Master s thesis, University of Maryland, \n1980. [6] Matthias Felleisen, Mitchell Wand, Daniel P. Friedman, and Bruce Duba. Abstract continuations: \nA mathematical semantics for handling functional jumps. In Proceedings of the 1988 ACM Symposium on LISP \nand Functional Programming, Salt Lake City, Utah, July 1988. [7] Ralf Hinze. Deriving backtracking monad \ntransformers. In Proc. ACM SIGPLAN International Conference on Functional Programming, pages 186 197, \n2000. [8] John Hughes. The design of a pretty-printing library. In J. Jeuring and E. Meijer, editors, \nAdvanced Functional Programming, volume 925. Springer Verlag, 1995. [9] K. M. Kahn and M. Carlsson. How \nto implement prolog on a LISP machine. In J. A. Campbell, editor, Implementations of Prolog, pages 119 \n134. Chichester, 1984. [10] Samuel Kamin. Final data type speci.cations: A new data type speci.cation \nmethod. In Conf. Rec. 7th ACM Symposium on Principles of Programming Languages, pages 131 138, 1980. \n[11] John C. Mitchell. Foundations for Programming Languages. MIT Press, Cambridge, MA, 1996. [12] Eugenio \nMoggi. Notions of computation and monads. Information and Computation, 93(1):55 92, 1991. [13] Gordon \nD. Plotkin. LCF considered as a programming language. Theoretical Computer Science, 5:223 255, 1977. \n[14] David Sands. Total correctness by local improvement in the transformation of functional programs. \nACM Transactions on Programming Languages and Systems, 18(2):175 234, March 1996. [15] Silvija Seres, \nJ. Michael Spivey, and C. A. R. Hoare. Algebra of logic programming. In International Conference on Logic \nProgramming, pages 184 199, 1999. [16] Silvija Seres and Michael J. Spivey. Embedding prolog into haskell. \nIn Haskell Workshop 99, 1999. [17] Hayo Thielecke. From control e.ects to typed continuation passing. \nIn Conf. Rec. 30th ACM Symposium on Principles of Programming Languages, pages 139 149. ACM Press, 2003. \n[18] A. S. Troelstra, editor. Metamathematical Investigation of Intuitionistic Arithmetic and Analysis, \nvolume 344 of Lecture Notes in Mathematics. Springer-Verlag, Berlin, Heidelberg, and New York, 1973. \n[19] P. L. Wadler. How to replace failure by a list of successes. In Jean-Pierre Jouannaud, editor, Functional \nProgramming Languages and Computer Architecture, volume 201 of Lecture Notes in Computer Science, pages \n113 128. Springer Verlag, September 1985. [20] Christopher P. Wadsworth. Some unusual .-calculus numeral \nsystems. In J. R. Seldin and J. P. Hindley, editors, To H.B. Curry: Essays on Combinatory Logic, Lambda-Calculus \nand Formalism, pages 215 230. Academic Press, New York and London, 1980. [21] Mitchell Wand. Final algebra \nsemantics and data type extensions. Journal of Computer and Systems Science, 19:27 44, 1979. [22] Glynn \nWinskel. The Formal Semantics of Programming Languages. MIT Press, Cambridge, MA, 1993.   \n\t\t\t", "proc_id": "1016850", "abstract": "Past attempts to relate two well-known models of backtracking computation have met with only limited success. We relate these two models using logical relations. We accommodate higher-order values and infinite computations. We also provide an operational semantics, and we prove it adequate for both models.", "authors": [{"name": "Mitchell Wand", "author_profile_id": "81100072594", "affiliation": "Northeastern University, Boston, MA", "person_id": "PP39025873", "email_address": "", "orcid_id": ""}, {"name": "Dale Vaillancourt", "author_profile_id": "81100445068", "affiliation": "Northeastern University, Boston, MA", "person_id": "P693058", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1016850.1016861", "year": "2004", "article_id": "1016861", "conference": "ICFP", "title": "Relating models of backtracking", "url": "http://dl.acm.org/citation.cfm?id=1016861"}