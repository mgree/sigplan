{"article_publication_date": "09-19-2004", "fulltext": "\n From Process Logic to Program Logic Kohei Honda Department of Computer Science Queen Mary, London kohei@dcs.qmul.ac.uk \nAbstract We present a process logic for the p-calculus with the linear/af.ne type discipline [6, 7, 31, \n32, 33, 59, 60]. Built on the preceding studies on logics for programs and processes, simple systems \nof assertions are developed, capturing the classes of behaviours rang\u00ading from purely functional interactions \nto those with destructive update, local state and genericity. A central feature of the logic is representation \nof the behaviour of an environment as the dual of that of a process in an assertion, which is crucial \nfor obtain\u00ading compositional proof systems. From the process logic we can derive compositional program \nlogics for various higher-order pro\u00adgramming languages, whose soundness is proved via their embed\u00addings \ninto the process logic. In this paper, the key technical frame\u00adwork of the process logic and its applications \nis presented focussing on pure functional behaviour and a prototypical call-by-value func\u00adtional language, \nleaving the full technical development to [27, 26].  Categories and Subject Descriptors D.3.1 [Formal \nDe.nitions and Theory]: Semantics; F.3.1 [Specifying and Verifying and Reasoning about Programs]: Assertions, \nLog\u00adics of programs, Speci.cation techniques; F.3.2 [Semantics of Pro\u00adgramming Lanugages]: Process models \n General Terms Language, Theory, Veri.cation  Keywords Types, Mobile Processes, Higher-Order Functions, \nHoare Logic, Duality, p-Calculus 1. Introduction Program Logics offer abstraction of programs behaviours \ncentring on logical predicates on them, combined with proof systems for deriving valid judgements. They \nare useful both for the design of programs on a rigorous basis (i.e. speci.cation) and analysis of existing \nprograms (i.e. veri.cation). In fact, these two aspects are Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 04, September 19 21, 2004, Snowbird, Utah, \nUSA. Copyright 2004 ACM 1-58113-905-5/04/0009 ...$5.00. most effectively integrated in real engineering \npractice, where code or design in production, annotated with predicates which express crucial safety \nproperties, is subjected to logical reasoning and the result is re.ected onto the process of design and \ncoding. This rea\u00adsoning part may even be half-mechanised, so that programmers can get feedback quickly \nand reliably. For all these purposes the proof system may as well be compositional (i.e. rules are built \nfollow\u00ading the syntactic structure of the language) since, in this way, we can reason about a larger \nprogram based on properties derived for its constituting parts. Some logics are mathematically general \nfor a given class of programs in that all meaningful observable properties are precisely speci.able (and, \nup to derivability of valid judgement in the associated domain, relatively provable) in the system. Since \nthe program logics of this kind can express properties of programs in a general and rigorous fashion, \nand because the associated proof system offers a fundamental articulation of semantics of language constructs \nand their interplay, many engineering activities ranging from static analyses to program testing increasingly \nuse program logics as their foundation. One of the well-known instances of such logics, which in effect \ninitiated the whole .eld of compositional program logics, is the speci.cation logic by Tony Hoare [21], \nHoare Logic, developed on the basis of earlier work by Floyd [16] and Naur [49]. Hoare Logic, originally \npresented for a simple imperative programming language, is powerful from an engineering viewpoint: formulae \nand rules are simple and intuitive, capturing the essence of dynam\u00adics of imperative programs concisely \nand elegantly. And it is sat\u00adisfying from a theoretical viewpoint; not only the proof system is both \nsound and (relatively) complete with respect to a naturally de\u00ad.ned model, but each of the rules has \na decisive form which follows the principle of .nding a weakest precondition for a desired con\u00adclusion. \nThere have been a vast body of theoretical and practical studies starting from Hoare s work (see various \nsurveys including [4, 11]). The maturity of the theoretical understanding and prac\u00adtical techniques is \nnow reaching the stage where one can develop consistent proof rules for reasoning about non-trivial fragments \nof real-world programming languages, cf. [51, 35, 55, 40]. Compositional program logics make it possible \nto reason about observable properties of software starting from their constituent parts. A piece of software, \nin principle and increasingly in prac\u00adtice, can consist of programs written in different languages. Even \nif a program is written in a single language, when it runs under an operating system, its properties \nshould be considered in combina\u00adtion with those of the operating system, which may be written in a different \nlanguage. Another instantiation of the same problem is when a high-level language calls native code (many \nlibraries of a high-level language are implemented in this way). In fact, almost all kinds of software \nnowadays explicitly or implicitly rely on the functionalities of other software. A Java program relies \non its APIs which are implemented using native code and OS libraries, an OS library uses kernel calls, \nand even a kernel relies on, for exam\u00adple, the proper working of the network for carrying out its essential \nfunctionalities. Thus reasoning about behaviour of software across language boundaries, but still on \na rigorous logical basis, is funda\u00admental for guaranteeing the safe behaviour of software. In spite of \nmany studies on Hoare Logic and its derivatives, it seems this topic has not been investigated as extensively \nas the subject may deserve. We present in this paper one possible approach to this problem domain. The \nidea is to develop compositional logics for a tiny for\u00admalism of interaction, and use it to derive, analyse \nand mediate, via encoding of language constructs in it, logics for more complex pro\u00adgramming languages. \nThis tiny formalism which is a minimal core of a process calculus, the p-calculus, introduced by Milner, \nParrow and Walker [46] has a simple operation, communication of names, and a small set of algebraic \noperators, including parallel composition. The p-calculus is a calculus of concurrency, devel\u00adoped along \nthe line of such process calculi as CCS [43], CSP [23] and ACP [5]. But, as the originators noted [46], \nit has great ex\u00adpressive power to represent diverse forms of computation, and as such may as well be \nregarded as a calculus for describing software behaviour in general, including higher-order sequential \ncomputa\u00adtion [45]. In fact, if we constrain the composition of processes using a class of type annotations \n(which come from Linear Logic [18, 39], Game Semantics [3, 30, 34] and study of types for the p-calculus \n[48, 53, 37, 25]), we can embed a wide class of pro\u00adgramming languages into name passing processes without \nlosing essential semantic properties [6, 59, 60, 31, 7, 32, 33]. If, therefore, we can .nd a suitable \nnotion of logic for typed name passing pro\u00adcesses together with its sound compositional proof rules, \nwe may as well be able to derive logics for different programming languages via encoding; and, in turn, \nthe typed p-calculus would serve as a common stratum of these program logics, allowing the combined reasoning \nfor multiple languages. Thus our process logic starts from typed processes. Following Hennessy-Milner \nLogic [20], a basic modal logic for nondetermin\u00adistic processes, assertions in the logic centre on communication, \nde\u00adscribing reciprocal interaction a process may have with its environ\u00adment. Types offer fundamental \norganising principles for structuring assertions: among others, they lead to a form of logical description \nof behaviours where behaviour of an environment is represented as the dual of that of a process, which \nis crucial for obtaining compo\u00adsitional proof rules. The resulting logical description precisely cap\u00adtures \nsemantics of typed processes, which is then re.ected onto dif\u00adferent programming languages via their \nembedding in the typed p\u00adcalculus. The present paper illustrates these key technical elements in the \nsimplest setting, focussing on purely functional sequential processes and a basic call-by-value higher-order \nlanguage. The ex\u00adperiment with a large class of sequential behaviour and different kinds of higher-order \nprogramming languages (including call-by\u00adname, two forms of polymorphisms, data structure with destructive \nupdate, objects and global and local state) is reported in [27]. It also reports how the original Hoare \nLogic is recoverable from a stateful version of the process logic, suggesting fruitful connections to \nthe foregoing studies on program logics. A basic reservation to our approach would be that its extensive \nuse of types may result in dif.culties in its practical adaptation. Examining the effects of close interplays \nbetween types and logics is one of the signi.cant future issues, together with extensions of the framework \nto the realm of behaviours beyond those treated so far, which include, among others, concurrency and \ndistribution. 1.1 Possible Technical Contributions Apart from the general direction to use the typed \nlogics for the p\u00adcalculus as a unifying basis of program logics, the following points may be counted \namong technical novelties of the present work. 1. The .nding that duality-based types (originating in \nthe fore\u00adgoing studies on types and semantics of interaction) leads to a highly structured form of Hennessy-Milner \nlogic for the p\u00adcalculus. The representation of the behaviour of an environ\u00adment in assertions yields \nsimple compositional proof rules. 2. The use of fully abstract embeddings of programming lan\u00adguages \ninto typed p-calculi to derive, analyse and verify pro\u00adgram logics for these languages. This extends \nvarious se\u00admantic embeddings of programming languages in processes [44, 58, 6, 59] to a logical setting. \n 3. As an outcome of 1 and 2, a systematic technique to use names and operations on them for reasoning \nabout programs and data structure on a uniform basis, including, among oth\u00aders, higher-order functions \nand procedures, polymorphisms, and complex data structures.  Regarding the third point, a uniform treatment \nof higher-order fea\u00adtures of programming languages in compositional program logics may not have been \nknown so far, in spite of many studies on pro\u00adgram logics in the past. The present work offers a general \ntechnical solution to this problem, using decomposability of language con\u00adstructs into .ne-grained dynamics \nof name passing processes and the precise logical analysis of the resulting representation through the \ntyped process logics. 1.2 Related Work As may be clear from the preceding discussions, the present work \nowes much to the three research strands of semantics of compu\u00adtation: compositional program logics, theories \nof processes, and types for functions and interaction. In the following we discuss those works directly \nrelated with the material presented in this short paper: more comprehensive discussions are found in \n[27]. Among extensions of Hoare s axiomatic method, the proof rules for procedures studied by Hoare and \nClint [22, 10] predict the log\u00adical treatment of replicated processes in the present work. Kowal\u00adtowsky \n[38] proposes a way to use names to express return values of procedures. Abadi and Leino [2] propose \na framework in which names of objects and operations on them are used as essential ele\u00adments of a program \nlogic for an object-oriented language. In this context, the present work extends the usage of names in \nthese works to a general basis of speci.cations. Jones [36] demonstrated that not only pre/post conditions \nbut also an explicit assertion on the two-way constraints on a program and its environment is effective \nfor reasoning about shared variable concurrency (a related idea is found in [17]). We owe to Jones work \nthe idea of representation of the environments behaviour in logical speci.cations of programs, as recorded \nin the shape of the sequent in the present process logic. In a tradition different from Hoare Logic, \nequational logics for the .-calculi have been studied since the classical work by Church, Curry and others. \nLCF [14] augments the standard equational the\u00adory of the .-calculus with Scott s .xed point induction. \nOther prominent logics along this line include those for polymorphic .\u00adcalculi [54, 1]. The program logics \nfor higher-order functions de\u00adrived from process logics differ in that their assertion describes be\u00adhavioural \nproperties of programs rather than equates programs, al\u00adlowing speci.cations with arbitrary degrees of \nprecision as well as smoothly extending to non-functional behaviour (for further tech\u00adnical comparisons \nsee [27, \u00a71.2]). Hennessy-Milner Logic [20], one of the starting points of the present work, enjoys a \nsound and complete equational characteri\u00adsation for bisimilarity. Similarly the present logic enjoys \nthe same property for the typed contextual congruence. The embeddabil\u00adity of a program logic in a process \nlogic is .rst demonstrated by Milner for a basic speci.cation logic for shared variable concur\u00adrency \n[43]. Existing studies on logics for the p-calculus include Hennessy-Milner Logic [47] (for characterising \ndifferent bisimi\u00adlarities) and Spatial Logic [9] (for capturing spatial structures of processes). Dam \ns survey [13] details the dif.culties in develop\u00ading the proof system of Hennessy-Milner Logic for the \nuntyped p-calculus. All these preceding studies are done in the untyped set\u00adting: the present work demonstrates \nthat the use of types can lead to compositional process logics in which compositional program logics \nare precisely embeddable. 1.3 Structure of the paper In the remainder, Section 2 introduces the basic \nideas of the typed process logic, including assertions, their semantics, and proof rules. Section 3 derives \na compositional program logic for call-by-value PCF [15] from the process logic, outlines how a fully \nabstract logi\u00adcal embedding leads to a simple proof of soundness of the proof rules, and concludes with \nsimple inference examples. Detailed proofs as well as experiments of the framework for a wide range of \nsequential processes and programs are found in [27, 26, 28]. 1.4 Notation Logical connectives are used \nwith their standard precedence and association: e.g. A /B =Yx.C VD =E is parsed as (A /B)= (((Yx.C)VD)=E). \n=on formulae denotes logical equivalence. As far as no confusion arises, we use these connectives both \nsyntac\u00adtically (i.e. as connectives in formulae in process/program logics) and semantically (i.e. for \ndiscussing validity of various kinds). Acknowledgement. The author thanks Martin Berger, Adriana Compagnoni, \nMasahito Hasegawa, Alex Simpson, Nobuko Yoshida and anonymous referees for enriching discussions, communications \nand comments. The author is partially supported by EPSRC grant GR/S55545.  2. Typed Process Logic 2.1 \nProcesses The p-calculus used in this paper is a typed variant of the standard asynchronous p-calculus \n[29, 8]. The following gives the reduction rule of the asynchronous p-calculus. x(jy).P Ix(jv)-+P[jv/jy] \n(1) Here jy denotes a potentially empty vector y1...yn of names, Ide\u00adnotes parallel composition, x(jy).P \nis an input, and x(jv)is an asyn\u00adchronous output. Operationally, this reduction represents the con\u00adsumption \nof an asynchronous message by a receptor. The idea ex\u00adtends to a receptor with replication, !x(jy).P: \n!x(jy).P Ix(jv)-+!x(jy).P IP[jv/jy]. (2) where the replicated process remains in the con.guration after \nre\u00adduction. Types for processes prescribe usage of names. To be able to do this with precision, it is \nimportant to control dynamic sharing of names. For this purpose, it is useful to restrict name passing \nto bound (private) name passing, where only bound names are passed in communication [57]. Using bound \nname passing leads to simple proof rules without sacri.cing expressiveness. Syntactically we re\u00adstrict \noutputs to the form (.jy)(x(jy)IP)(where (.jy)indicate name hiding: names in jy should be pairwise distinct), \nwhich we hence\u00adforth write x(jy)P (observe the lack of . in this pre.x, indicating the lack of synchronisation). \nThe restriction of syntax to the bound output gives the following simpler form of dynamics.  x(jy).P \nIx(jy)Q -+(.jy)(P IQ) !x(jy).P Ix(jy)Q -+!x(jy).P I(.jy)(P IQ) x(jy)Q indicates that x(jy)is an asynchronous \noutput exporting jy which are originally local to Q. After communication, jy are shared between P and \nQ. We also use branching x[&#38;iEI (jyi).Pi], where I is a .nite or count\u00adable indexing set, and selection \nx..i(j w), the latter written x..i(j w)P in the bound output notation. These constructs are used for \nrepre\u00adsenting base values, conditionals and the case construct [6, 59, 18]. They play a basic role in \nthe typed setting, just as the case/injection constructs in the typed .-calculus with sums. The dynamics \nof branching/selection is given by the following reduction rule. x[&#38;iEI (jyi).Pi]Ix..j(jyj)P -+(.jyj)(Pj \nIP) The reduction involves selection of one branch, discarding remain\u00ading ones, combined with name passing. \nWe can now summarise the formal grammar of the calculus. Be\u00adlow and henceforth xyy ...range over a countable \nset of names. P ::=x[&#38;iEI (jyi).Pi]Ix..i(jy)P I!x(jy).P Ix(jy)P I PIQ I(.x)P I0. We often omit the \nindex set I in x[&#38;iEI(jyi).Pi]. In the present pa\u00adper we only consider {*}(a distinguished singleton), \nl={tyf}, and N={0y1y...}as the indexing sets for branching.1 When the indexing set is {*}, the branching \nis written x(jy).P, regaining the non-replicated unary pre.x. PIQ is parallel composition of P and Q, \n(.x)P is the result of hiding x in P, and 0 is the inaction. We usually omit the empty vector and 0 s, \nwriting, for example, x for x(), x.P for x().P, x[&#38;i .Pi]for x[&#38;i ().Pi], and x..i for x..i(). \nThe structural congruence =(which includes the a-equality) is standard [59]. The reduction relation -+is \ngenerated starting from the rules already given, closing the relation under contexts except under input \npre.xes, taking processes modulo =. As untyped processes, the above syntax can represent a large class \nof sequential and concurrent behaviours. We use the af.ne type discipline [6] for constraining their \nbehaviour to purely func\u00adtional ones. We use the following action modes [6, 59], which represent different \nmodes of communication actions at channels. +Af.ne input tAf.ne output ! Replicated server ? Client request \nto ! We also use twhich stands for uncomposability. +indicates a non\u00adreplicated input which receives \nan output at most once. tindicates an output which is done at most once. Thus +and tare dual to each \nother. When we compose +and tat a shared channel, we obtain t, indicating no further composition is possible \nat that chan\u00adnel. ! indicates a replicated input, while ? indicates an output to ! (these symbols are \nfrom [18]). Thus ? and ! are dual to each other. When they are composed, we obtain !, so that a replicated \nchannel is available to an arbitrary number of dual outputs. 1For in.nitary branching, we assume a suitable \nrestriction on the use of indices of selections (detailed in [27, Appendix A]) so that processes represent \nonly computable functions.        Using the action modes, the grammar of channel types, ranged \nover by tyt'y.y..., is given as follows (jt denotes a vector). ty.y..::=(jt)! I(jt)? I[&#38;iEIjti]lI[EiEIjti]tIt \n(jt)! indicates a replicated input which receives channels of typejt. (jt)? is its dual. [&#38;iEIjti]lindicates \na branching input which has I\u00adbranches and which, at each i-th branch, receives channels of type jti. \n[EiEIjti]tis its dual. The symbol tis also used as a type, again denoting uncomposability. The mode of \nt is its outermost mode (if t (if t =t). =t)or tWe often write .p if the mode of . is p.Given t t, the \ndual of = t, written t , is the result of exchanging, in t, ! and ?, +and t,as well as &#38; and E.An \naction type (Gy.y...) is a .nite map from names to channel types. fn(G)is its domain. An action type \nis sequential if it contains at most one channel whose type is of the mode t(operationally this condition \nguarantees the existence of at most once thread in a typable process). In this paper we only use sequential \naction types. A classi.cation of channel types called polarities [32, 39] plays a basic r ole in the \nprocess logic. A channel type, or a name given that type, is positive (resp. negative) if its mode is \none of !yt(resp. ?y+). tis neutral. Intuitively, a type or a typed channel which emits, or generates, \ninformation is positive, while one which receives, or consumes, information is negative (a behavioural \ncharacterisation of this idea is given in [32]; note polarities are not directly related to the distinction \nbetween input and output). A typed term is written IP IG (read: P has type G,or P is typed under G). \nThe typing rules are presented and illustrated in Appendix A: however the following technical development \nshould be understood without details of the typing rules. A few examples of typed processes follow. 1. \nThe process w..3 simply selects the third branch at w, for which we have Iw..3 Iw:[EiEN]t. def 2. Let \n[[3]]x =!x(w).w..3. Then I[[3]]x Ix : N\u00c6where N\u00c6= ([EiEN]t)!. The process, when invoked at x with a single \nname, immediately outputs 3 via that name. def 3. Let doublexy =!x(w).y (u)u[&#38;nEN.w..nX2]. Then we \nhave Idoublexy Iy : N\u00c6yx : N\u00c6 . When invoked at x, the process asks back at y, receives n, and gives \nits double as the answer to the original question. [[3]]y and doublexy interact as: [[3]]y Idoublexy \nIx (w)w[&#38;if ..i]-++[[3]]y Idoublexy If ..6. 4. Let [x +y]t def =!x(w).y(u)u.w with t def (()t)!. \nThen we have = I[x +y]t Ix : tyy : t . This is a copycat of type t [34, 6], which acts as a transparent \nlink between two locations, as the following reduction indicates (below .is the standard weak bisimilarity \n[46]). [x +y]t Ix (w)P -++.[x +y]t Iy (w)P Similarly we can de.ne a copycat for general !/+-types, as \nformally given in Appendix B. 5. Using a generalised copycat, we can represent recursion. Let IP IGyj \njx:jt!, write .iPi for the n-fold parallel compo\u00adsition, and de.ne: it def \u00b5jy=jx.P =(.jy)(PI.i[yi +xi]ti \n). it Then we have I\u00b5jy=jx.P Ijx :jt!. In this agent, each output from P at yi is mediated to its own \nxi, realising recursive behaviour via a circular link.  2.2 Assertions for Typed Processes 2.2.1 Basic \nIdeas Processes are inherently interactional, and, for that reason, their behaviour is dependent on the \nenvironment s behaviour. Recall doublexy above. If we invoke this process at x, and if !y(c). c..3 is \npresent, then doublexy will return 6: but if at y there is !y(c). c..1 then it answers with 2. Thus a \nprocess in general can guarantee a certain behaviour only by relying on the behaviour of an environ\u00adment \n[36], arriving at the following form of judgement: PG Irely A guar B (3) where A and B are formulae whose \ngrammar is given later. Negative names in G may occur in A (but not in B), while positive names in G \nmay occur in B (but not in A). The judgement can be read as: If P typed under G can rely on A as the \nbehaviour of an environment, then the process combined with the environment can guarantee B. We often \nwrite P Irely AguarB, leaving the action type implicit. As a concrete example, we can specify the behaviour \nof doublexy as follows. Below we assume the action type y : N\u00c6yx : N\u00c6 . Below the symbol e stands for \nthe empty vector of names. doublexy Irely y _e =..3()guar x _e =..6().(4) The term y _e, which consists \nof a name y, operator _, and the ar\u00adgument e, is best understood as abstraction of an output of form \ny (c), with e indicating y carries no arguments except for a return channel. ..3()can be understood as \nabstraction of an output c..3. Thus y _e =..3()says that the invocation y(c)is answered by an output \nc..3. The bound c is not mentioned since its concrete nam\u00ading is insigni.cant. Thus _indicates typed \ninteraction: in the next section we encode function application into this operation. Reading the second \nformula in the same way, (4) as a whole says that, if the environment returns 3 when invoked at y with \nthe null argument, then the process itself would return 6 when invoked similarly at x. How such formulae \narise from those in Hennessy-Milner logic is discussed in [27, Section 2]. The next assertion is more \ndetailed than (4). doublexy Irely y _e =..i()guar x _e =..2Xi()(5) Since i does not occur in G, i is \nauxiliary [22]. As in Hoare Logic, auxiliary names are universally quanti.ed in the whole sequent. Thus \n(5) says that, for each i EN, if the environment is such that it returns i for its invocation at y, then \nP returns 2 Xi. Now consider the following process which slightly alters doublexy. def double'=!x(yw).y \n(u)u[&#38;nEN.w..2Xn]. x Note y is now bound. For this agent, the assertion corresponding to (5) becomes, \nunder the typing x :(N\u00c6[EiEN]t)!: double'x Irely Tguar y _e =..i()=x _y =..2Xi(). x _y indicates x is \nnow invoked with a single argument (together with an implicit return channel). Since y is auxiliary, \nwe may rewrite the above rely formula as Yyyi.(y_e =..i()=x=..2Xi()). _y 2.2.2 Terms Terms in the logic \nare given by the following grammar. Below let t be of mode ! or t, and . be of mode t. nat '' e ::=*It \nIf In IxIxIe +eIe XeI... . a ::=xt Ia _jb I..e(ja). ' The .rst set of terms (eye y...) are data expressions, \nwhile the sec\u00ad '' ond set (aya ybyb ' y...) behaviour expressions. TyT y..denotes atomic data sets ({*}, \nland N). Data expressions denote their elements, while behaviour expressions abstract process interactions. \nThe well\u00adtypedness of data/behaviour expressions is naturally given, setting the type of a_ jb to be \nttassuming a has type (j.t)! andjb has typej. (for the full typing rules, see Appendix C). We usually \nomit . from .. . e (ja), and write (ja)tfor ..*(ja)for brevity. 2.2.3 Formulae Formulae are those of \nthe .rst-order logic with equality [42]. Be\u00adlow *ranges over {/yVy=}and Q over {Yy3}. A ::=e1 =e2 Ia1 \n=a2 IA IA1 *A2 IQ i.A IQ x.A We also use the truth T(which is, say, 1 =1) and the falsity F (which is \nT). The quanti.cations induce binding, for which we assume the standard bound name convention. fn(A)denotes \nfree names in A. A is well-typed if whenever a variable/name occurs twice they own the same type and \neach pair of equated terms have the same type. We only consider well-typed formulae from now on. 2.2.4 \nJudgement A judgement for a typed process IP IG has the following shape. PG I=rely A guar B . (6) A (resp. \nB)isthe rely formula (resp. the guarantee formula) of the judgement. Those names in A and B which are \nfrom G are called primary names, others auxiliary names. Assuming G =.1y.2 such that types in .1 (resp. \n.2) are negative (resp. positive/neutral), the free names in A (resp. in B) should be typed under .1 \n(resp. under .2), combined with a typing on auxiliary names, common to A and B. Note free names in formulae \nin each judgement are strictly typed by the underlying action type. Also note neutral names, i.e. those \ntyped by t, never occur in formulae (since a name in a formula is always either positive or negative). \nThis indicates logical insignif\u00adicance of neutral names (which re.ects their behavioural insigni.\u00adcance: \nno visible action is possible at neutral names). An assertion is sometimes written P I=relyAguar B, leaving \nthe action type im\u00adplicit. An assertion means either a judgement or formulae occur\u00adring in a judgement. \n 2.2.5 Total and Partial Correctness In the following we present simple semantics of assertions. Be\u00adfore \nstarting, however, a note is due on the treatment of divergence in speci.cation. As in Hoare logic, an \nassertion in the present typed process logic can be either about total correctness (where non-trivial \nassertions always guarantee termination) or about par\u00adtial correctness (where divergence allows arbitrary \nspeci.cations). These two, together with a third one which subsumes both, are dis\u00adcussed in detail in \n[27]. In the present paper we focus on the logics for total correctness because of its simplicity in \npresentation. Semantics of assertions uses an abstract notion of behaviour, de\u00ad.ned from the standard \ntyped congruence for af.ne processes [6]. The congruence, written . =p, is the maximum typed congruence \n. satisfying: IP .=p Q Ix:()tiff P .x =Q .x, where IP1 =p P2 IG means IP1 2 IG are related by .+*xIR \n=p and P .x means P \u00ad 2.2.6 Model Let t be positive. An abstract process p of type t, often written \npt , is a map from the names to the . =p-congruence classes such that: (1) P Ep(x)implies IP Ix : t, \nand (2) p is closed under injective ()() xy xy renaming, i.e. p(x)=p(y)yxfor each xyy, where yxis a name \npermutation acting on processes as an injective substitution. A model . is a .nite map from names to \nabstract processes. . has t1 tn type G iff . =x1: p y..yxn : pn and G =y..yxn :tn. .G indicates 1 x1:t1. \nhas type G. A model . is total if x: p E. implies p 1, where p 1 if a process (hence every process) in \np has in.nite reductions. 2.2.7 Satisfaction Relation Fix auxiliary names in A and an interpretation \nI , the latter mapping the former to constants and abstract processes. The interpretation [[e]]I is standard, \nstarting from [[x]]I =I(x). For behaviour expres\u00adsions, the interpretation [[a]]I .. is given by: _[[x]]I \n.. =(I U.)(x), _[[x _jy]]I .. =[[x]]I .. _[[y1]]I ....[[yn]]I .. and _[[..e(x1..xn)]]I .. =..[[e]]I ([[x1]]I \n....[[xn]]I ..). where p _q1..qn and ..i(p1..pn)are given as follows. _p _jq is the abstract process \nwhose image at (say) z is ' (.xjy)(p(x)Ix(jyz ' )(.qi(yi)I[z +z].)). _..j(p1..pn)is the abstract process \nwhose image at (say) x is x..j(jy).i pi(yi). In these clauses we confuse an abstract process with a concrete \nprocess in its . =p-congruence class. This does not lead to ambiguity because of congruency and renaming \nclosure. The notion of satisfaction of A by a model . under an interpreta\u00adtion I , written . I=I A, is \ngiven by induction on the structure of A. We start from: . I=I e1 =e2 =[[e1]]I =[[e2]]I. . I=I a1 =a2 \n=[[a1]]I .. =[[a2]]I .. Logical connectives are interpreted classically: . I=I A1 /A2 =(. I=I A1)/(. \nI=I A2) . I=I A = (. I=I A) T . I=I Yx.A =Yc ET.. I=I.x:cAy . I=I Yxt .A =Yp E[[t]].. I=I.x:pAy where, \nin the last line, [[t]]denotes the set of all abstract processes of type t. The rest is de Morgan duality. \n 2.2.8 Semantics of Judgement Let IP IG. We write P I=.G with . =x1: p1y..yxn : pn to de\u00adnote IP . =p.iPiG \nsuch that Pi Epi(xi)for each i. Fixing auxiliary names in A and its interpretation I, let us write P \nI=I A when P I=. and . I=I A for some total . (the restriction to total models is for ensuring total \ncorrectness: I is left unconstrained). We can now formally de.ne the semantics of assertion. De.nition \n1 Assume IP IGy. where G is negative and . is pos\u00aditive/neutral. Then we write PG . I=relyAguar B when, \nfor each I and IR IG,R I=I A implies (. fn(G))(PIR)I=I B. A basic property of the typed process logic \nfollows, which says that assertions valid for each process precisely characterise its be\u00adhaviour up to \nthe contextual congruence. Below PG =L QG stands for YAyB.(PG I=relyAguar B =QG I=relyAguarB ). IP . \nProposition 1 PG =L QG iff =p Q IG. See [27, \u00a73.8, \u00a74.4] for the proof. Though this property does not \ndirectly pertain to expressiveness of assertions, it does con.rm that speci.cations in the present logic \nspeak no more and no less than observable properties of processes. (Par) (Zero) P IrelyA1 guar B1/C -Q \nIrelyA2/C guar B2 0 IrelyA guar APIQ Irely A1/A2 guar B1/B2 (Rec) P Irely A-iy guarB(0)ix P Irely A /B(i)[jy/jx]guar \nB(i+1) \u00b5jyt =jx.P Irely A guar B (Res) (Weak) P Irely AguarB-xPG Irely AguarB  (.x)P IrelyAguar BPG \nx:t IrelyAguar B (Bral) (Selt) Yi.Pi Irely A[..i(jyi)/x]guar BP Irely A guar B[..i(jy)/x] x[&#38;i(jyi).Pi]Irely \nAguar Bx..i(jy)P Irely A guar B (In! ) (Out? ) Yjy.(C1 =C2[x_jy/z])=BA =C1 =C2[x_jy/z]/x _jy . yy P Irely \nA-iy/Ci1 guar C2 P Irely A-z /C2 z guar Ci1 /B-iy !x(jyz).P Irely A guar Bx(jyz)P IrelyA guar B Figure \n1: Proof Rules for Processes  2.3 Proof Rules for Process Logic One of the signi.cant consequences \nof the representation of envi\u00adronments in assertions in the present logic is the existence of simple \ncompositional proof rules for valid assertions. We use the judge\u00adment of the form PG IrelyAguarB for \nprovability, which should follow the same typing constraint on primary/auxiliary names in formulae as \nbefore (action types are often omitted). The proof rules are given in Figures 1 and 2. In each rule, \nwe assume all occur\u00adring processes and assertions, including those in the conclusion, are well-typed. \nFurther conventions: _A-iy indicates no name injy occurs in A, while Aiy indicates all primary names \nin A are in {jy}. _iyjy...exclusively range over auxiliary names (in a given judgement). _In each rule, \nno primary names in a judgement in its premise should overlap with auxiliary names in a judgement in \neither its premise or its conclusion. Among the proof rules, (Zero) should need no illustration. (Res) \nis reminiscent of Hoare s rule for local name [24]. In (Weak), x can occur as an auxiliary name in A \nin the antecedent. (Par) rule assumes non-circular parallel composition, where pos\u00aditive names in P are \ncompensated by negative names in Q, but not vice versa (the precise condition is given in Appendix A). \nAs a result, we obtain the simple proof rule, close to the cut rule in the sequent calculus. Since a \nparallel composition in af.ne processes can always be decomposed into a non-circular one and a recursion, \n(Consequence) A=A ' yB ' =B (Aux-Y) (Aux-3) P Irely A ' guarB ' P IrelyA-i guarBP Irely AguarB-i P Irely \nAguarBP IrelyAguar Yi.BP Irely 3i.AguarB Figure 2: Structural Rules this does not lose generality. In \nthe premise, if a free name in E is primary in the .rst sequent, then it should also be so in the second \nsequent, because of our convention on name usage noted above. (Rec) uses the expression for recursion \ngiven in \u00a72.1, and com\u00adbines mathematical induction and recursive behaviour, ensuring to\u00adtal correctness. \nIn the rule, A(e)denotes the result of substituting e for a hole in a formula, avoiding name capture. \nThe rule is close to Harel s rule for the while command [19], which is known to be complete for strong \nmodels [4]. For tractable reasoning, one may extend the rule to well-founded induction [16]. (Bral) says \nthat, if x[&#38;i(jyi).Pi]is to guarantee B relying on A, each branch Pi should guarantee B relying on \nA in which x is spe\u00adcialised into its i-th branch by substitution. (Selt) is its dual, saying, for an \noutput x..i(jy)P to guarantee B relying on A, P itself should guarantee B relying on A, with x in B replaced \nby its carried value. (In!) and (Out?) are another pair of mutually dual proof rules. For (In!), suppose \nP guarantees C2 at z, relying on A and C1, with only the latter being about jy. Then !x(jyz).P can guarantee, \nfor all jy satisfying C1, that the result of invoking x withjy satis.es C2 which is now about x and jy \nby substitution. B is a weaker property, so we safely place the formula in the conclusion. In (Out?), \nwe .rst assume A as the global property of the envi\u00adronment, which in particular talks about x. Under \nA, suppose P can guarantee C1 at jy. Further, suppose P can guarantee Bif the envi\u00adronment satis.es C2 \nat z. Finally suppose A and C1 together ensure that invoking x with argumentsjy will result in z satisfying \nC2. Then invoking x with arguments jy and a return channel z will in effect guarantee B. The condition \nx _jy .demands the result of invocation does not diverge, an essential requirement for the total correctness. \nFormally a .for a of type .tstands for: 3ijx.a =..i(jx). Moving to Figure 2, (Consequence) is similar \nto the correspond\u00ading rule in Hoare Logic, except that the entailment =in the present logic is not only \nabout number-theoretic facts but also about the universe of sequential behaviour. For the latter, we \nmay use: (extensionality) Yjx.u _jx =v _jx =u =v. ' (data) ..e(jx)=..e.(jy)=e =e /jx =jy. The remaining \ntwo structural rules are immediate consequences of the semantics of auxiliary names, which are universally \nbound in the whole sequent (and, for (Aux-3), observing that the rely condi\u00adtion is interpreted contravariantly). \nThese two rules are essentially simple instances of Hoare s well-known adaptation rule [22], but are \nfound to be useful in the present proof system (for other struc\u00adtural rules, see [27, \u00a73.6]). Many inference \nexamples using these proof rules are given in [27]: some are also found in Section 3 in relationship \nwith proof rules for higher-order functions. The following result is proved in [26, Sections 3 and 4] \nby rule induction of the proof rules. Theorem 1 (soundness) For each IP IG,ifPG Irely A guar B then PG \nI=rely A guar B.   3. Program Logics via Process Logics 3.1 PCFv and its Process Encoding In this section \nwe show how we can derive a program logic for the call-by-value PCF (henceforth PCFv) from the af.ne \nprocess logic, leading to natural proof rules as well as their soundness. First we summarise the syntax \nof PCFv. M ::=c Ix I.xa .M IMN Iop(jI M) a=\u00dfa \u00b5x..y.M Iif M then N1 else N2 Binding etc. are standard. \nay\u00dfy...are types, whose grammar is to be given soon. c is a constant for which we consider booleans .y.and \nnatural numbers n. op(M0y...yMn-1)denotes an n-ary arithmetic or boolean operation (e.g. succ(M), M /N). \nValues ' (VyV y...) are variables, constants, .-abstractions and recursions. We use the standard weak \ncall-by-value one-step reduction [15], written M -+M ' . Types, ranged over by ay\u00dfy..., are generated \nfrom: a ::=lINIa \u00df. land Nare atomic types. A typed term has the form G IM : a, where G is a base, which \nis a .nite map from variables to types. The typing rules are standard [15] and are omitted. Assuming \nG I M12 : a, we write G IM1 =. M2: a when, for each closing context C[Mi]of type N, we have C[M1].n iff \nC[M2].n, where .denotes convergence to a value. PCFv can be fully abstractly embedded into af.ne processes \n[6] using the encoding by Milner [44, 30]. The encoding of types is given by:2 def def def \u00c6\u00c6 N=([EiEN]t)! \nl=([EiE ]t)! (a \u00df)\u00c6=(a\u00c6(\u00df\u00c6)t)! The encoding of programs closely follows that of types. There are two \nkinds: [[V ]]m (for values) and ((M))u (for all terms). Some of the main ones are: def [[n]]m =!m(c).c..n \ndef [[xa]]m =[m +x]a\u00c6 def [[.xa .M]]m =!m(xc).((M))c a=\u00df def =\u00dft [[\u00b5x.V ]]m =(.x)([[V ]]mI[x +m](a\u00c6 ) \ndef ((MN))u =(.m)(((M))mIm(c).(.n)(((N))nIn(e).c(eu))) def ((V ))u =u(m)[[V]]m. The encoding is type-preserving \nin the following way: G IM : a yu +I((M))u IG\u00c6yu:(a\u00c6)t(7) where G\u00c6is the result of pointwise mapping \nand dualising each channel type. Proposition 2 (Berger, Honda, Yoshida [6]) 1. (de.nability) For each \nIP Iu : (a\u00c6)t, there exists a PCFv\u00adterm IM : a such that ((M))u =. P. 2. (full abstraction) For each \nG IM12 : a, we have G IM1 =. M2: a iff ((M1))u =p ((M2))u.  2To be precise, we use a truly linear mode \n[59] for tin the encoding of each atomic type (we can also use a terser, but less uniform, encoding in \n[6]). See [27, \u00a76.2] for detail. 3.2 Assertions for PCFv The signi.cance of type preservation in the \nschema (7) is that the translation guides us to develop a simple program logic for PCFv. Let us start \nfrom an assertion for the encoding of G IM : a in the typed process logic. By type preservation in (7), \nwe know it has the following form: ((M))u Irely Aguar E (8) where A is about G\u00c6and E is about u : (a\u00c6)t \n. A key observation which leads to the assertion language for PCFv is that, since the process logic under \nconsideration is total, as far as A is satis.able (and if not, i.e. if A =F, the assertion is vacuously \nvalid for any E), we can set u of E as total, so that we can write: E =3m.(u =(m)t/B) (9) We further \nobserve each primary name, say xi,in A is given a (.)\u00c6\u00admapped type, which is in accordance with the type \na\u00c6of m. This allows us to uniformly decode this assertion back to M: A ' IM :uB ' f. ((M))u IrelyAguar \nE (10) where A ' and B ' are suitably de.ned counterparts of A and B. Inher\u00aditing from the process encoding, \nthe assertion uses a (fresh) name, u, which we call anchor. An anchor is used for representing the point \nof operation (hence speci.cation) of M. Using u, the formula B 'can now talk about what this program \ndoes, assuming the prop\u00aderty A 'of the environment. The rely formula is now placed in the position of \nthe type environment, while the original guarantee formula is placed in the position of the type of M. \nWe can now formally introduce syntax of assertions. Firstly, the grammar of terms and formulae of the \nlogic follows. Below *E {/yVy=}and Q E{Yy3}. a a e ::=xIb In It If I.Ie1 _e2 Ie1 +e2 Ie1 Xe2 I... A ::=TIFIe1 \n=e2 IA IA1 *A2 IQ x.A .a denotes divergence (which is seldom used in speci.cations but is needed for \nsemantic completeness), often written .. The opera\u00adtor _can be understood as the call-by-value version \nof application in combinatory logic [12]. We write e .for e =., which corre\u00adsponds to a .in the process \nlogic, cf. \u00a72.3. We distinguish a term of a boolean type (say t) from a formula (say T). This is necessary \nsince a boolean term can take the value .. In practice, however, we can often infer a given boolean term \nis total, in which case it can be soundly identi.ed with a formula, as is often done in Hoare Logic. \nTerms are typed starting from constants and variables, requiring, in e1 _e2, that e1 (resp. e2) has type \na \u00df (resp. a) for some a and \u00df, in which case the whole term has type \u00df. The well-typedness of formulae \nis de.ned as before. We can now present the syntax of judgements. _ A IMG;a :uB (for provability); and \n_ A I=MG;a :uB (for validity) In both, we assume G IM : a, u Efn(A)Ufn(G)and fn(G)nfn(B)= 0/, as well \nas well-typedness of formulae. Following Section 2, we call A (resp. B) rely formula (resp. guarantee \nformula) of the judge\u00adment. In the judgement, the primary names in A are those occurring in G, while \nthe primary name of B is the anchor u. We often omit type annotation, writing e.g. A IM :uB.By an assertion \nwe mean either a judgement or the rely/guarantee formula used in it. Let us look at a couple of examples. \nThe .rst one is a simple assertion for the identity function. TI.xa .x :u Yya .u _y =y (11) which says \nthat the program, when applied to any well-typed argu\u00adment y of type a, will return that argument as \na result. This sequent has a precise analogue in the process logic via encoding. Since the program under \nconsideration is a value, we can take [[.xa .x]]u, for which we can state: !u(xm).m(c)[c +x]a\u00c6 IrelyTguar \nYy.u _y =(y)t(12) which is easily derivable in the proof rules in \u00a72.3. Note (y)tin (12) becomes simply \ny in (11). Another simple example uses a non-trivial assumption on a higher\u00adorder variable. YxN .Even(f \n_x)I(f 3)+1:u Odd(u) (13) where Even(n)(resp. Odd(n)) says that n is even (resp. odd). In the process \nlogic, this assertion becomes, writing a gives e for 3c.(a = (c)t/c _e =..e())for brevity: f (xc)([[3]]x \nIc(y).y(e)e[&#38;n .u(c)[[n +1]]c])I rely Yx.3i.(f _x gives i /Even(i)) guar 3j.(u gives j /Odd(j)) The \nindirection via af.ne output complicates the formulae: yet we can precisely read out the high-level assertion \nin (13) from the low\u00adlevel one. More examples of assertions will be given in \u00a73.5. 3.3 Semantics of \nJudgement Intuitively, a judgement A I=M :uB under the typing jx :jt IM : \u00df means that, restricting our \nattention to total correctness as before: If a vector of closed values of type jt satisfy A, then the \nresult of substituting them for variables in M con\u00adverges to a value whose behaviour satis.es B, under \nan arbitrary interpretation of auxiliary names. Below we substantiate this informal reading in a simplest \npossible 3 way. Let .y.' y...range over the =.-congruence classes of typed closed terms, which we call \nbehaviours. We write .a if . is of type a. For each type a, there is a unique congruent class of the \ndiverging terms, which we write . a or simply ..If . =., we say . is a total behaviour. =\u00df Let .aand \n.a 2 . Then .1 _.2 is given as the congruence class 1 including MN for M E.1 and N E.2. Arithmetic operations \netc. are similarly de.ned. A model . maps names to total behaviours. An interpretation I maps names to \nboth total and non-total be\u00adhaviours. Given a model . and an interpretation I , the map [[e]]I .. is \nde.ned by induction on e, starting from [[x]]I .. =(I U.)(x). The satisfaction relation . I=I A is standard. \nWe then write . I=I A u (read: . with anchor u satis.es A under I ) when u : . I=I A (where u : . is \nthe model that maps u to .). Finally with M closed, M I=I A u I stands for 3..(M E. /. I=A). We also \nwrite jx : jV I=I A for jx :j. I=I A with Vi E.i. We can now de.ne: u De.nition 2 (semantics of judgement) \nAssume jx :j\u00df IM : a. Then A I=M :u B iff, for each well-typed I and each jV of types j\u00df such I that \njx :jV I=I A,we have M[jV /jx]I=B. u The validity in the PCFv-logic is precisely embeddable into that \nv of the process logic. The translation of formulae is written ((A))i, where jv indicate the primary \nnames in A (which are to be treated 3An alternative model construction is discussed in [27, Appendix \nB]. as total behaviours). The embedding starts from (always choosing fresh names for newly introduced \nnames): def y yy ((e1 =e2))i=3x1x2.(x1 =x2 /((e1))i/((e2))i) x1 x1 The rest is compositional with respect \nto logical connectives and quanti.ers. The map ((e))ixy encodes a term e to a formula4, naming the term \nas x and indicating jy are primary. The map is de.ned inductively as follows. v def . u =x (x E{jv}) \n((x))i= u u =(x)t(x E{jv}) def vv ((op(je)))i=3jx.(/i ((ei))i/(u.=/i xi .)/ u xi Yjy.(/i xi =..yi ()=u=..op(iyt())) \nv def v ((e1 _e2))iu =3x1x2.(/i ((ei))ixi /(u.=/i xi .)/ Yy1y2.(/i xi gives yi =u gives y1_y2 )) v def \n((.))i=u . u In the second line, an operation op is assumed to be total and strict in each argument (when \nop is nullary the map becomes that for a constant). The translation decomposes coalesced PCFv-types into \ntheir af.ne (partial) and replicated (total) parts. This decomposition makes the mapping complex. The \nresulting complexity in turn sug\u00adgests abstraction and convenience in speci.cation we obtain when we \nmove from the .ne-grained process logic to a logic tailored for a speci.c programming language. A key \nresult on the logical embedding follows. The property is called logical full abstraction by Longley and \nPlotkin [41], though in a different setting. The proof uses Proposition 2 (in particular de.nability), \nsee [27, \u00a76.4] for detail. Below we use the entailment 3m.(u =(m)t/((B))u[m/u])=((B))e, which allows \nus to simplify the guarantee formula. Theorem 2 (logical full abstraction) Assume jx :ja IM : \u00df. Then \nA I=M :m Biff ((M))u I=rely ((A))ix guar ((B))e .  3.4 Proof Rules for PCFv-Logic The correspondence \nbetween assertions in the PCFv-logic and those in the process logic leads to simple proof rules for PCFv, \nwhich are given in Figure 3. As in \u00a72.3, Aiy means primary names in A are inside {jy}, A-iy means no \nname from jy occurs in A, and iyi ' y...ex\u00adclusively range over auxiliary names. Again as in \u00a72.3, we \nassume that, in each rule, no primary names in a judgement in the premise should overlap with auxiliary \nnames in any judgement in the rule, either in the premise or in the conclusion. All rules in Figure 3 \nshould naturally read from the viewpoint of PCFv-computation. [Var]says that, if something can be said \nabout what x denotes in the environment, then the same thing can be said about x as a term, named as \nu. This axiom corresponds to, via encoding, the following copycat laws, derivable in the rules of the \nprocess logic (see [27, \u00a73] for the derivation). Below we assume t has mode ! and . has mode +. (Copycat-!) \n[x +x ' ]t Irely A[x ' /x]guar A ' (Copycat-+) [x +x]. Irely A[x ' /x]guar A [Const]is about identity \nof u and a constant c, which is reminiscent of the assignment rule in Hoare Logic. [Op]is a generic rule \nfor 4Terms in the PCFv-logic include composite values, which in gen\u00aderal cannot be expressed as terms \nin the process logic. - - [Var] A[x/u]Ix :u A [Const] A[c/u]Ic :u A A IMi :mi Ci (1 \"i \"ntA /(/iCi)=B[op(m1y..ymn)/u][Op] \nA Iop(M1y..yMn):uB A IM :bCA /C[t/b]IN1:uBA /C[f/b]IN2:uB [If] A I..M ....N1 ....N2:uB A -xii /C1 x IM \n:mC2 Yxji.(C1 =C2[u _x/m])=B [Abs] A I.x.M :uB A IM :mC1 A IN :xC2 C1 =C2 =B[m _x/u]/m _x . [App] A IMN \n:uB A I.y.M :uB(0)A /B(i)[x/u]I.y.M :uB(i +1)[Rec] A I\u00b5x..y.M :u Yi.B(i) A =A0 A0 IM :uB0 B0 =B [Consequence] \nA IM :uB A -i IM :uB A IM :uB -i [Aux-Y][Aux-3] A IM :u Yi.B 3i.A IM :uB Figure 3: Proof Rules for PCFv \noperators (which in fact subsumes the rule for constant). Syntacti\u00adcally [Op]assumes the corresponding \noperator is in the language of the logic; semantically it assumes the operator is total. [If]is close \nto the conditional rule in Hoare Logic, keeping clean symmetry like its predecessor. Note, in the rule, \nA IM :bC indicates (as far as A is satis.able) M terminates. This allows us to conclude the whole term \nterminates. [Abs]says that, if, under the assumption C1 about x, the program M named as m satis.es C2, \nthen .x.M named as u satis.es the fol\u00adlowing property: for any x satisfying C1, the result of applying \nx to u, named as m, satis.es C2. The global assumption A should not mention x. The quanti.cation of the \nauxiliary namesji is in fact redundant in the presence of [Aux-Y]discussed below, but having it together \nis almost always convenient in reasoning. Dually [App] says that if M named as m satis.es C1, and N named \nas x satis\u00ad.es C2, and C1 and C2 together imply B whose u is substituted for m _x, as well as convergence \nof the invocation, then MN named as u satis.es B. [Rec]combines recursion with mathematical induction, \nin direct correspondence with (Rec). Again we may extend this rule to well\u00adfounded induction. The .nal \nthree rules are structural rules. [Consequence]is just as in Hoare logic. [Aux-Y]and [Aux-3]come from \nthe semantics of auxiliary names, just as in \u00a72.3. For applying the consequence rule, we need to calculate \nthe validity of formulae in the domain of call-by-value sequential behaviour, in addition that of the \nstandard number theory. Figure 4 lists three basic rules (rules similar to (.\u00adright) are valid for the \n.rst-order operators). Each of these proof rules can be cleanly decomposed into a few steps of inference \nin the process logic. As an example, we show the case of [App]. For brevity let M and N be values, in \nwhich case the (ext) Yy.e1 _y =e2 _y =e1 =e2 (.-left) ._e =. (.-right) e _.=. Figure 4: Axioms for Strict \n_ encoding becomes: def ' ((MN))u =(.m)([[M]]mIm(xu ' )([[N]]xI[u +u])) The following derivation starts \nfrom the antecedents of [App]and .nally reaches its conclusion, all in the encoded form. Ant 1,2,3 are \nthree conditions in the antecedent, while IH stands for the induction hypothesis. 1.[[M]]m Irely((A))ix \nguar ((C1))m (Ant 1, IH) 2.[[N]]x Irely((A))ix guar((C2))x (Ant 2, IH) ' 3.[u +u]Irely ((B))e[u ' /u]guar \n((B))e (copycat law) ' 4.m(xu ' )([[N]]xI[u +u]))I rely ((C1))m /((A))ix guar ((B))e (2, 3, Ant 3, (Out)) \n' 5.[[M]]mIm(xu ' )([[N]]xI[u +u])I rely ((A))ix guar ((B))e (1, 4, (Par)) 6.((MN))u Irely ((A))ix guar \n((B))e (Res) Decomposing each rule in the same way, we arrive at: Proposition 3 Let G IM : a with G \n=jx :ja. Then A IM :uB implies ((M))u Irely ((A))ix guar ((B))e . We can now establish a key property \nof the proof rules. Theorem 3 (soundness of PCFv-logic) A IM :u B implies A I= M :u B. PROOF : Assume \nA IMix:it;a :uB. jx:jV I= I A x =[[jV]]ix I=[[I ]]((A))i(Theorem 2) =(.jx)(((M))uI[[jV]]ix)I=[[I ]]((B))u \n(Prop. 3, Thm. 1) =((M[jV /jx]))u I=[[I ]]((B))u (Proposition 1) =M[jV /jx]I=I B (Theorem 2) Note the \nproof needs both directions of Theorem 2. Examples of inferences using these proof rules are listed in \n\u00a73.5.  3.5 Examples of Inferences in PCFv-Logic We show two simple examples of inferences in the PCFv-logic. \nFurther examples are found in [27, \u00a76]. First we derive a natural speci.cation for the identity function. \n1.T/x =i Ix :mm=i (Var) 2.TI.x.x :u YxNiN .(x =i =u _x =i)(Abs) 3.TI.x.x :u YxN .(u _x =x)(Conseq) Next \nwe consider the standard recursive factorial: def Fact =\u00b5f ..x.if x =0 then 1 else x Xf (x -1). The assertion \nwhich we wish to prove is: TIFact :u YnN .u _n=n!. (14) Being simple as a statement, the inferences to \nreach this assertion will use all proof rules of PCFv-logic given in Figure 3. By the shape of [Rec], \nthe proof is divided into two parts, the base case def and the induction step. For brevity we let B(f \n)(n)=f _n=n! and def M =if x =0 then 1 else x Xf (x -1). We .rst show the base case. Below (falsity) \nstands for the lemma FIN :uA for each N and A, which is easily derived by rule induction. 1.x =0 Ix =0:bb \n=t (Var, Num, Eq) 2.x =0 /t =t I1:vv =1 (Num, Conseq) 3.x =0 /f =t Ix Xf (x -1):vv =1 (falsity) 4.x =0 \nIif x =0 then 1 else x Xf (x -1):vv=1 (1, 2, 3, If) 5.TI.x.M :u YxN .(x =0 =u _x =1) (4, Abs) 6.TI.x.M \n:uB(u)(0) (Conseq) where (Eq) is an instance of [Op]. For the induction step: 1.B(f )(n)/x =n +1 Ix =0:bb \n=f (Var, Num, Eq) 2.B(f )(n)/x =n +1 /FI1:vv =(n +1)! (Num, Conseq) 3.B(f )(n)/x =n +1 /TIx :mm=n +1 \n(Var, Conseq) 4.B(f )(n)/x =n +1 /TIf :lB(l)(n)(Var, Conseq) 5.B(f )(n)/x =n +1 /TIx -1:kk =n (3. Subt) \n6.B(f )(n)/x =n +1 If (x -1):vv=(n -1)! (4, 5, App) 7.B(f )(n)/x =n +1 Ix Xf (x -1):vv=n! (3, 6, Mult) \n8.B(f )(n)/x =n +1 IM :vv=n! (1, 2, 6, If) 9.T/B(f )(n)I.x.M :uB(u)(n +1)(7, Abs, Conseq) where (Mult) \nand (Subt) are instances of [Op]. We can now combine the two conclusions, writing them as (*)and (**): \n1.TI.x.M :uB(u)(0) (*) 2.T/B(f )(n)I.x.M :uB(u)(n +1)(**) 3.TIFact :u YnN .B(u)(n)(1, 2, (Rec)) y thus \nreaching the required statement (14).  3.6 Extensions The speci.cation for the identity function in \nthe previous subsec\u00adtion, Yx.(u _x =x), may at .rst look no different from the \u00dfv \u00adequality (.x.x)x =x. \nA basic difference is that the statement Yx.(u_ x =x)in the present logic does not mention concrete programs. \nThis allows us to discuss the universe of behaviour insulated from speci.c programs and programming languages, \noffering a clean perspective on semantics of speci.cations. But it does not end there. More importantly, \nthis method of spec\u00adi.cations which is based on the idea that behaviour is interac\u00adtional, so that it \nis best speci.ed by unfolding it one by one via interaction has signi.cance when the complexity of behaviour \nincreases, either in type/data structures or in the nature of compu\u00adtation such as statefulness. The \nproposed approach scales in both dimensions, backed up by the underlying process logics [27]. For example, \nto treat sums and products, one only has to add the fol\u00adlowing terms to the PCFv-logic. e ::=...I()I(e1ye2)Ipi(e)I..i(e)(i \n=1y2) A pair (e1ye2)is redundant but is convenient in proofs. We can then write, for example, Yz.(p1(u)_z \n=2 Xz), which says u is a pair whose left value is a doubling function. There are (almost obvious) proof \nrules associated with them, all embeddable into the af.ne process logic. To have potentially circular \ndata structure, which is omnipresent in real-world programming, we can add recursive types, which can \nbe simply treated in the process/PCFv-logic if we use the iso-recursive approach [52]: we extend types \nwith recursion \u00b5X.a (taken up to the standard isomorphism), with no need to add new proof rules. Using \nrecursive types, we can represent, for example, the type of def lists as ....(a)=\u00b5Y.(Unit+(aXY)). We \ncan then reason about a list by unfolding it one by one (which is the best way if a list is large: and \nwould be the only way if it is in.nite). For clarity, one may add new terms to the logic, even though \nall are de.nable from the given constructs. e ::=...I[e]I[e :: e ' ] We can then write down, for example, \na speci.cation for a pro\u00adgram which eliminates all zero valued-cells from a given list (say l), using \nthe following two predicates: def _A(uyl)=l =[e]=u _l =[e]. def _B(uyl)=l =[x :: y]=(x =0 =u _l =[x :: \nu _y])/(x =0 = u _l =u _y). As a .rst step, the required speci.cation may be written as Yl....(Nt .(A(u.l)/B(uyl))(see \n[27, \u00a710] for further detail). The proof rules for lists are also easily derived. In the same way, the \napproach smoothly extends to two forms of second-order polymorphism (for both universal and existential \nabstraction), call-by-name evaluation, higher-order imperative pro\u00adcedures, computation with local state, \nand data structure with de\u00adstructive update (cf. [50, 56]). All these extensions are based on the idea \nof naming data and procedural objects, and de.ning suit\u00adable operations on typed names. For example, \nwe may describe the behaviour of the universal identity in the second-order .-calculus, .X..xX .x : YX.XX, \nwith anchor u, as follows. X lY Y=Y YX.Yx.(u_[X]_x =x). The assertion says that a type-abstracted behaviour \nnamed as u, when it is applied to any type a and well-typed argument y of type a, will return that argument \nitself as a result. Similarly we name an existentially pack and open it; or name a stateful procedure \nand assert how it changes a state and produces a value upon invocation. See [27, 28] for the account \nof these and other experiments.  References [1] Abadi, M., Cardelli, L., Curien, P.-L., Formal Parametric \nPolymorphism, TCS 121, 1-2, (Dec), 9-58. Elsevier, 1993. [2] Abadi, M, Leino, R. A logic for object-oriented \nprograms, pages 682 696, TAPSOFT 97, LNCS, 1997. [3] Abramsky, S., Jagadeesan, R. and Malacaria, P., \nFull Abstraction for PCF. Info. &#38; Comp. 163 (2000), 409-470. [4] Apt, K.R. Ten Years of Hoare Logic: \na survey. TOPLAS. 3:431-483, 1981. [5] Baeten, J.C.M. and Weijland, W.P. Process Algebra. Cambridge \nUniversity Press, 1990. [6] Berger, M., Honda, K. and Yoshida, N., Sequentiality and the p-Calculus, \nTLCA01, LNCS 2044, 29 45, 2001. [7] Berger, M., Honda, K. and Yoshida, N., Genericity and the p-Calculus, \nFoSSaCs 03, LNCS 2620, 103 119, 2003. [8] Boudol, G., Asynchrony and the pi-calculus, INRIA Research \nReport 1702, 1992. [9] Caires, L. and Cardelli, L., A Spatial Logic for Concurrency (Part I). Info. \n&#38; Comp., 2003. [10] Clint, M. and Hoare C.A.R. Program proving: jumps and functions. Acta Inf. 1:214 \n224, 1971. [11] Cousot, P. Methods and logics for proving programs. Handbook of Theoretical Computer \nScience, volume B, 843-993. Elsevier, 1999. [12] Curry, B. and Feys, R. Combinatory Logic. North-Holland, \n1958. [13] Dam, M. Proof Systems for p-Calculus Logics. Logic for Concurrency and Synchronization. Studies \nin Logic and Computing, Oxford University Press, 2003. [14] Gordon, M., Milner, A. and Wadsworth, C., \nEdinburgh LCF, LNCS 78, 1979. [15] Gunter, C., Semantics of Programming Languages: Structures and Techniques, \nMIT Press, 1992. [16] Floyd, W. Assigning meaning to programs. Prc. Symp. in Applied Mathematics. 19:19-32, \n1967. [17] Francez N. and Pnueli, A. A proof method for cyclic programs. Acta Inf. 9, pp.133-157, 1978. \n[18] Girard, J.-Y., Linear Logic, TCS, 50:1 102, 1987. [19] Harel, D. Proving the correctness of regular \ndeterministic programs. TCS, 12:61 81, 1980. [20] Hennessy, M. and Milner, R. Algebraic Laws for Nondeterminism \nand Concurrency. Journal of ACM, 32:1, pp.137-161, 1985. [21] Hoare, C.A.R. An axiomatic basis of computer \nprogramming. CACM, 12:576-580, 1969. [22] Hoare, C.A.R. Procedures and Parameters: an axiomatic approach. \nLecture Notes in Mathematics 188, 102 116, Semantics of Algorithmic Languages, Springer, 1971. [23] Hoare, \nC.A.R. Communicating Sequential Processes, Prentice Hall, 1985. [24] Hoare, C.A.R. and Wirth, N., An \naxiomatic de.nition of the programming language PASCAL. Acta Inf. 2:335 355, 1973. [25] Honda, K., Composing \nProcesses, POPL 96, 344-357, ACM, 1996. [26] Honda, K. Sequential Process Logics: Soundness Proofs. Typescript, \n50pp. November 2003/January 2004. Available at: www.dcs.qmul.ac.uk/ kohei/logics. [27] Honda, K. Process \nLogic and Duality: Part (1) Sequential Processes. Typescript, 210pp. March 2004. Available at: www.dcs.qmul.ac.uk/ \nkohei/logics. [28] Honda, K. and Yoshida, N., A Compositional Logic for Polymorphic Higher-Order Functions. \nPPDP 04, ACM, 2004. [29] Honda, K. and Tokoro, M. An object calculus for asynchronous communication. \nECOOP 91, LNCS 512, 133 147, 1991. [30] Honda, K. and Yoshida, N. Game-theoretic analysis of call-by-value \ncomputation. TCS, 221:393 456, 1999. [31] Honda, K. and Yoshida, N., A Uniform Type Structure for Secure \nInformation Flow, POPL 02, 81 92, ACM, 2002. [32] Honda, K. and Yoshida, N., Noninterference proofs from \nFlow Analysis. To appear in: Journal of Functional Programming, CUP, 2004. [33] Honda, K., Yoshida, N. \nand Berger, M., Control in the p-Calculus, Proc. CW 04, ACM, 2004. [34] Hyland, M. and Ong, L., On Full \nAbstraction for PCF : I, II and III. Info. &#38; Comp. 163 (2000), 285-408. [35] Jacobs, B. et al. Reasoning \nabout Java Classes (Preliminary Report). OOPSLA 98, ACM, 1998. [36] Jones, C.B. Speci.cation and Design \nof (Parallel) Programs. Proc. IFIP 9th World Computer Congress. North Holland, 321-332, 1983. [37] Kobayashi, \nN., Pierce, B., and Turner, D., Linear types and the p-calculus, TOPLAS, 21(5):914 947, 1999. [38] Kowaltowsky, \nT. Axiomatic approach to side effects and general jumps. Acta Informatica 7, 357-360. [39] Laurent, O., \nPolarized games, LICS 2002, 265-274, IEEE, 2002. [40] Leavens, G. and Baker, A. Enhancing the Pre-and \nPostcondition Technique for More Expressive Speci.cations. FM 99: World Congress on Formal Methods, Springer, \n1999. [41] Longley, J. and Plotkin, G. Logical Full Abstraction and PCF. Tbilisi Symposium on Logic, \nLanguage and Information. 333-352, Stanford, CSLI, 1998. [42] Mendelson, E. Introduction to Mathematical \nLogic (third edition). Wadsworth Inc., 1987. [43] Milner, R., Communication and Concurrency, Prentice \nHall, 1989. [44] Milner, R., Functions as Processes, MSCS. 2(2):119 141, 1992, [45] Milner, R., Speech \nby Robin Milner on receiving an Honorary Degree from the University of Bologna, ICALP 97, http://www.cs.unibo.it/icalp/Lauree \nmilner.html. [46] Milner, R., Parrow, J. and Walker, D., A Calculus of Mobile Processes, Info. &#38; \nComp. 100(1):1 77, 1992. [47] Milner, R., Parrow, J.G. and Walker, D.J., Modal logics for mobile processes, \nTCS, 114:149 171, 1993. [48] Milner, R., Polyadic p-Calculus: a tutorial. Proceedings of the International \nSummer School on Logic Algebra of Speci.cation, Marktoberdorf, 1992. [49] Naur, P. Proof of algorithms \nby general snapshots. BIT 6, 310 316, 1966. [50] O Hearn, P., Yang, H. and Reynolds, J., Separation and \nInformation Hiding, POPL 04, 268 280, 2004. [51] Oheimb, D.V., Hoare Logic for Java in Isabelle/HOL. \nConcurrency: Practice and Experience. John Wiley, 2002. [52] Pierce, B.C., Types and Programming Languages, \nMIT Press, 2002. [53] Pierce, B.C. and Sangiorgi. D, Typing and subtyping for mobile processes. MSCS, \n6(5):409 454, 1996. [54] Plotkin, G. and Abadi, M., A Logic for Parametric Polymorphism, LICS 98, 42 \n53, IEEE Press, 1998. [55] Poetzsh-Heffter, A. and Muller, P. A programming logic for sequential Java. \nESOP 99, LNCS 1576, 162-176, 1999, [56] Reynolds, J. Intuitionistic Reasoning about Shared Mutable Data \nStructure, Millennial Perspectives in Computer Science, Oxford, 1999. [57] Sangiorgi, D., p-calculus, \ninternal mobility, and agent-passing calculi. TCS, 167(2):235 271, 1996. [58] Walker, D., Objects in \nthe p-calculus. Info. Comp., 116(2):253-271, 1995. [59] Yoshida, N., Berger, M. and Honda, K., Strong \nNormalisation in the p-Calculus, LICS 01, 311 322, IEEE, 2001. Full version in: Info. &#38; Comp., 191:145 \n202, 2004. [60] Yoshida, N., Honda, K. and Berger, M. Linearity and Bisimulation, FoSSaCs 2002, LNCS \n2303, 417 433, 2002. (Zero) (Par) (G1 :G2)(Res) (Weak) -IPi IGi (i=12tIP IGyx :t! tIP IG-x I0 I IP1IP2 \nIG1 8G2 I(.x)P IG IP IGyx :t? t (Bral) Yi.IPi I?G-xyIx[&#38;i(jyi).Pi]I j yi :jtiyv:.t Gyx :[&#38;ijti]l \nyv:. (Selt) IP I?GyIx..i(jy) jy :jti P IGyx :[EiEIjti]t (In! ) (Out? ) (G(x) = ( jt.' )? ) IP I?G-xyjy \n:jtyz:. IP I?Gyjy:jtyz:.' yv:.t I!x(jyz).P IGyx :(jt.)! Ix(jyz)(P)IGyv:. Figure 5: Sequential Af.ne Typing \nAppendix A. Sequential Af.ne Typing In the following, we present a concise, but self-contained, illus\u00adtration \nof the af.ne type discipline used in the present paper. For further detail, see [27, \u00a72.2]. Firstly, \nit suf.ces to consider the channel types of the shape given below [34, 3, 6] (jtp indicates that each \ntype injt has mode p). _(jt? .t)! and, dually, (jt! .l)?. _[&#38;iEIjti ? ]land, dually, [EiEIjti ! ]t \n. Note an input type only carries output types, dually for an output type. A replicated input type carries \nzero or more ?-types (which may be considered as arguments it may receive); and a unique af.ne output \n(which may be considered as a return channel). Du\u00adally for a ?-type. The typing rules are presented in \nFigure 5, which are a variant of the sequential af.ne typing introduced in [6]. They differ from those \nin [6] in that it does not use IO-modes for ensuring sequen\u00adtiality. This is made possible by the use \nof sequential action types. Some notations: Gy. denotes the union of G and ., indicating at the same \ntime disjointness of their domains. ?G indicates G only use types of mode ?, similarly for G-x says x \ndoes not occur in G. For parallel composition, we use the partial operation 8, given by: (1) G 8. =Gy. \n(fn(G)nfn(.)=0/). (2) G .x :t 8. .x :t' =T .x :. (t 8t' =. and G 8. =T). In other cases G 8. is unde.ned. \nIn (2), t 8. is a commutative partial operation which satis.es: (a-1) t? 8t? =t? y(a-2) t! 8t? =t! y(b) \ntl8tt =t. (a-1) and (a-2) together say a replicated input is ready to absorb as many dual outputs. (b) \nsays a linear input and its dual linear output compensate each other to become the uncomposable type. \nWe brie.y illustrate the typing rules. In each rule, we assume all occurring types are well-formed and \nall occurring action types are sequential (including those in conclusion). (Zero) assigns the empty type \nto 0. (Par) composes two processes using 8: in the antecedent, we write G :. when G 8. is de.ned. We \ncan show, as far as G8. is sequential, 8ensures both determinacy and single\u00adthreadedness of a process. \n(Par-nc) IP1 I? +G1y! t.1y! tT (Rec) IP2 ITy? +G2y! t.2 G1 :G2yfn(.i)nfn(G jy. j)=0/ (i=j)IP I? +Gyjy \n:jtyjx:jt IP1IP2 IG1 8G2y.1y.2yT 8T I\u00b5jy =jx.P I.yjx :jt! Figure 6: Rules for Non-Circular Composition \nand Recursion (Res) hides a channel of mode ! and t(thus channels of mode ?, +and tneed their duals before \nhiding). (Weak) weakens ?-as well as t-channels. (Bra) says that if, for each i, a process has only output \ntypes as speci.ed, then we can pre.x it with a branching in\u00adput (note each type in jti has mode ? by \nwell-formedness of types). (Sel) says that, if there is a process with !-channels and ?-channels, then \nwe can construct a linear selection output which carries those !-channels. (In) says that if a process \nhas a speci.ed action type, then we can abstract jy (of typejt, which are ?-types) and z (of type ., \nwhich is a t-type) to construct a replicated input, which sup\u00adpresses free outputs G. Note G has mode \n?, saying only ?-channels are suppressed under replication. (Out) is similar to (Sel), except the ?-type \nat x should already appear in the antecedent. Processes typable with these rules cover essentially all \nsequen\u00adtial af.ne processes in [6] modulo =. which allows fully abstract embeddings of, among others, \nboth call-by-value and call-by-name PCF with products and sums. The typability is closed under reduc- \nP '' tion in the way: IP IG and P -+P 'implies P ' =such that IP '' IA for some P '' . Finally we list \nthe non-circular version of (Par) rule and the re\u00adcursion rule in Figure 6. ? +G etc. indicate the modes \nof types in G, just like ?G. These rules are used as the basis of the proof rules in \u00a72.3. The non-circular \n(Par) rule is equipotent to the original (Par) rule when combined with the recursion rule up to simple \nsyntactic conversion. B. Copycat We de.ne a copycat [x +y]t for an arbitrary t of mode +or! by the following \ninduction. { !x(ja).y(jb).i[bi +ai].i (t =(j.)! ) def [x +y]t =x[&#38;i(jai).y..i(jbi).ij[bij +aij].ij \n](t =[&#38;ij.i]l) def where, in [&#38;ij.i]l, we set, for each i, j.i =.i1...ij...imi for some mi. \nC. Well-typed Behaviour Expressions We say a has type t by the following induction. (1) xt has type t; \n (2) a _ jb has type ttiff a has type (j.t)! andjb has typej.; (3) .. . e (ja)has type . =[EiETjti]tiff \ne has type T and that, for each valuation, if e =i ET then ja has type jti.  Above a valuation is a \nwell-typed map from names to constants. Note each well-typed behaviour expression has a unique type. \nIt usually (as in this paper) suf.ces, for various embeddings of pro\u00adgramming languages, to consider \nonly those terms whose well\u00adtypedness is feasibly checkable.  \n\t\t\t", "proc_id": "1016850", "abstract": "We present a process logic for the p -calculus with the linear/affine type discipline [6, 7, 31, 32, 33, 59, 60]. Built on the preceding studies on logics for programs and processes, simple systems of assertions are developed, capturing the classes of behaviours ranging from purely functional interactions to those with destructive update, local state and genericity. A central feature of the logic is representation of the behaviour of an environment as the dual of that of a process in an assertion, which is crucial for obtaining compositional proof systems. From the process logic we can derive compositional program logics for various higher-order programming languages, whose soundness is proved via their embeddings into the process logic. In this paper, the key technical framework of the process logic and its applications is presented focussing on pure functional behaviour and a prototypical call-by-value functional language, leaving the full technical development to [27, 26].", "authors": [{"name": "Kohei Honda", "author_profile_id": "81100624236", "affiliation": "University of London - Queen Mary, London", "person_id": "PP31050384", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1016850.1016874", "year": "2004", "article_id": "1016874", "conference": "ICFP", "title": "From process logic to program logic", "url": "http://dl.acm.org/citation.cfm?id=1016874"}