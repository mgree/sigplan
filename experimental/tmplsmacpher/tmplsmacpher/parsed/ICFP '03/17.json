{"article_publication_date": "08-25-2003", "fulltext": "\n Call-by-Value is Dual to Call-by-Name Philip Wadler Avaya Labs wadler@avaya.com ABSTRACT The rules \nof classical logic may be formulated in pairs cor\u00adresponding to De Morgan duals: rules about &#38; are \ndual to rules about .. A line of work, including that of Filinski (1989), Gri.n (1990), Parigot (1992), \nDanos, Joinet, and Schellinx (1995), Selinger (1998,2001), and Curien and Her\u00adbelin (2000), has led to \nthe startling conclusion that call-by\u00advalue is the de Morgan dual of call-by-name. This paper presents \na dual calculus that corresponds to the classical sequent calculus of Gentzen (1935) in the same way \nthat the lambda calculus of Church (1932,1940) cor\u00adresponds to the intuitionistic natural deduction of \nGentzen (1935). The paper includes crisp formulations of call-by\u00advalue and call-by-name that are obviously \ndual; no similar formulations appear in the literature. The paper gives a CPS translation and its inverse, \nand shows that the trans\u00adlation is both sound and complete, strengthening a result in Curien and Herbelin \n(2000). Note. This paper uses color to clarify the relation of types and terms, and of source and target \ncalculi. If the URL below is not in blue, please download the color version, which can be found in the \nACM Digital Library archive for ICFP 2003, at http://portal.acm.org/proceedings/icfp/archive, or by googling \nwadler dual . Categories and Subject Descriptors F.4.1 [Theory of Computation]: Mathematical Logic  \nGeneral Terms Languages, Theory  Keywords Curry-Howard correspondence, sequent calculus, natural de\u00adduction, \nDe Morgan dual, logic, lambda calculus, lambda mu calculus Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 03, August 25 29, 2003, Uppsala, Sweden. \nCopyright 2003 ACM 1-58113-756-7/03/0008 ...$5.00. 1. INTRODUCTION 1.1 Classical logic and duality Yin \nand yang, winner and loser, positive and negative, particle and anti-particle, true and false: notions \nof duality pervade philosophy, science, and mathematics. Theoreti\u00adcians appreciate duality because it \nreveals deep symmetries. Practitioners appreciate duality because it o.ers two-for\u00adthe-price-of-one economy. \nA salient instance of duality is that between conjunction and disjunction in classical logic, sometimes \ncalled de Mor\u00adgan duality. To .nd the dual of a proposition, one swaps occurrences of conjunction (&#38;) \nwith occurrences of disjunc\u00adtion (.) and occurrences of true (.) with occurrences of false (.), leaving \noccurrences of negation (\u00ac) unchanged. Two propositions are equivalent if and only if their duals are \nequivalent. For example, the Law of Contradiction states that a proposition and its negation are never \nboth true, A &#38; \u00acA = .. Dually, in classical logic, the Law of the Excluded Middle states that either \na proposition or its negation is always true, A .\u00acA = .. For a second example, &#38; distributes through \n., A &#38;(B . C)=(A &#38; B) . (A &#38; C). Dually, in classical logic, . distributes through &#38;, \nA . (B &#38; C)=(A . B)&#38;(A . C). The formulations of logic introduced by Boole (1847) and Frege (1879) \ndo not mention duality. It was .rst introduced by Schr\u00a8oder (1890), who presented de.nitions and theorems \nin pairs, the duals side-by-side in two columns. Schr\u00a8oder was inspired by the duality between points \nand lines in projective geometry, as introduced by Poncelet (1818) and Gergonne (1826). (See Nidditch \n(1962) and Grattan-Guinness (2000).)  1.2 Curry-Howard for classical logic Some of the most important \ncontributions to computing occurred just before the computer was invented. In a series of in.uential \npapers, Church (1932,1940) introduced the un\u00adtyped and typed .-calculus. And in a single landmark pa\u00adper, \nGentzen (1935) introduced the two formulations of logic most widely used today, natural deduction and \nsequent cal\u00adculus, in both intuitionistic and classical variants. (The pa\u00adper also introduced the use \nof the symbol . for universal quanti.cation.) Gentzen believed that natural deduction corresponded better \nto the style of reasoning used in practice (hence the name), but recognized that sequent calculus better \nre\u00adveals the duality of classical logic. Further, Gentzen could demonstrate the consistency of sequent \ncalculus by a method of normalizing proofs called Cut elimination, but he could demonstrate the consistency \nof natural deduction only by showing its equivalence to sequent calculus. Only much later did Prawitz \n(1965) show how to nor\u00admalize proofs in natural deduction directly. And only later still did Howard (1980) \npublish a direct correspondence be\u00adtween proofs in intuitionistic natural deduction and terms in typed \n.-calculus, with Prawitz s normalization of proofs corresponding to Church s .-reduction. Similar correspon\u00addences \nbetween logic and computation were observed by Curry and Feys (1958) and de Bruijn (1968). What came \nto be called the Curry-Howard correspon\u00addence has proven to be a robust technique for relating a wide \nrange of systems of logic and computation. In par\u00adticular, Curry-Howard can be applied to classical as \nwell as intuitionistic logic, and to sequent calculus as well as natural deduction. Sussman and Steele \n(1975) introduced a call/cc opera\u00adtor in Scheme to capture computing with continuations, and Felleisen \net al. (1987) introduced the C operator to model call/cc. (For a fascinating history of continuations \nsee Reynolds (1993).) Gri.n (1990) extended the Curry-Howard correspondence to classical logic, by observing \nthat the type of call/cc corresponds to Pierce s Law, and that the type of C corresponds to the Law of \nDouble Negation. A re.nement of the correspondence between classical logic and computation was given \nby the .\u00b5-calculus of Parigot (1992,1994). The .\u00b5-calculus corresponds to classical natu\u00adral deduction \nin just the same way that .-calculus corre\u00adsponds to intuitionistic natural deduction. Call-by-name semantics \nfor the .\u00b5-calculus have been investigated by Ong (1996) and call-by-value semantics by Ong and Stewart \n(1997).  1.3 Call-by-value and call-by-name Filinski (1989) was the .rst to suggest that call-by-value \nmight in some sense be dual to call-by-name in the presence of continuations. Danos, Joinet, and Schellinx \n(1995) proposed two dual embeddings of classical logic into linear logic, LKQ and LKT, noting that the \n.rst corresponded to call-by-value and the second to call-by-name. Selinger (1998,2001) modeled the call-by-name \nsemantics of .\u00b5-calculus in a control category, and the call-by-value semantics of .\u00b5-calculus in a dual \nco-control category. Curien and Herbelin (2000) further explored this duality using a computational calculus \nbased on sequent calculus, derived from a similar calculus explored earlier by Herbelin (1994). Because \nsequent calculus displays the dualities of classical logic more clearly than natural deduction, Curien \nand Parigot s formulation o.ers some improvements over that of Selinger. However, in none of these cases \nis the duality quite as compelling as one might like. Filinski s formulation lacks any connection with \nlogic. Danos, Joinet, and Schellinx s formulation is in terms of proof nets and linear logic, with a \nless direct connection to computation. Selinger s formula\u00adtion of duality is not an involution the dual \nof the dual of a term is not the original term, but only a term that is equivalent up to isomorphism \nof types. Curien and Herbe\u00adlin s formulation is an involution, but to achieve this they must introduce \na di.erence operator as the dual to implica\u00adtion. The computational interpretation of implication A.B \nis a function, but the computational interpretation of the di.erence B - A = B &#38; \u00acA is not particularly \nintuitive. Barbanera and Berardi (1996) introduce a symmetric .\u00adcalculus, with a clear notion of duality. \nHowever, they do not consider either call-by-value or call-by-name reduction, instead their calculus \nis non-con.uent. 1.4 The dual calculus This paper presents a dual calculus, which corresponds to the \nclassical sequent calculus of Gentzen (1935) in the same way that the .-calculus of Church (1932,1940) \ncorresponds to the intuitionistic natural deduction of Gentzen (1935). The approach taken here is to \nreturn to the traditional formulation of duality in logic, where conjunction, disjunc\u00adtion, and negation \nare primitive, and implication is de.ned in terms of the other connectives. Conjunction (A &#38; B) corresponds \nto a product type (A \u00d7 B), disjunction (A . B) corresponds to a sum type (A+B), and negation (\u00acA) corre\u00adsponds \nto a continuation type (A . R). Implication may be de.ned in terms of these connectives, though di.erent \ndef\u00adinitions are required for the call-by-value and call-by-name calculi; one takes A . B =\u00ac(A &#38; \n\u00acB) for call-by-value and A . B =\u00acA . B for call-by-name. The paper includes crisp formulations of call-by-value \nand call-by-name that are obviously dual; no similar formula\u00adtions appear in the literature. The paper \ngives a CPS trans\u00adlation and its inverse, and shows that the translation is both sound and complete. \nThe paper is organized as follows. Section 2 reviews Gentzen s classical sequent calculus. Section 3 \nintroduces the dual calculus. Section 5 presents call-by-value and call-by-name reduction rules, and \nobserves that they are dual. Section 6 describes call-by-value and call-by-name CPS translations, and \nshows that they are sound and com\u00adplete with regard to reductions. Section 7 concludes with a speculation \non the dual of call-by-need.  2. GENTZEN S SEQUENT CALCULUS Figure 1 presents the syntax and inference \nrules of the sequent calculus. The rules given here are identical to those in Gentzen (1935), down to \nthe choice of symbols. Let A, B, C range over formulas, where a formula is either an atomic formula X; \na conjunction A &#38; B; a disjunction A . B; a negation \u00acA; or an implication A . B. Let G, . range \nover antecedents and T, . range over succedents, both of which are sequences of formulas separated by \ncommas. A sequent has the form G . T. The interpretation of a sequent is that the conjunction of the \nformulas in the antecedent implies the disjunction of the formulas in the succedent. So the sequent A1,..., \nAm . B1,..., Bn corresponds to the formula (A1 &#38; \u00b7\u00b7\u00b7 &#38; Am) . (B1 .\u00b7 \u00b7\u00b7. Bn). Formula Antecedent \nA, B, C G, . ::= ::= X | A &#38; B | A . B | \u00acA | A . B A1, . . . , Am Succedent T, . ::= B1, . . . , \nBn Sequent G . T Id A . A G . T,A G . T,B A, G . T B, G . T &#38;R &#38;L G . T,A &#38; BA &#38; B, \nG . T A &#38; B, G . T G . T, A G . T, B A, G . T B, G . T .R .L G . T, A . B G . T, A . B A . B, G . \nT A, G . T G . T, \u00acA \u00acR G . T, A \u00acA, G . T \u00acL A, G . T, B G . T, A . B .R G . T, A B, . . . A . B, G, \n. . T, . .L G . T, A A, . . . Cut G, . . T, . G . TG . T Thinning A, G . TG . T,A A, A, G . TG . T, \nA, A Contraction A, G . TG . T,A ., A, B, G . TG . T, B, A, . Interchange ., B, A, G . TG . T, A, B, \n. Figure 1: Gentzen s sequent calculus There are logical rules for each connective, labeled right or \nleft according as to whether the connective is introduced in the succedent or antecedent. Right rules \nserve the same purpose as introduction rules in natural deduction, while left rules serve the same purpose \nas elimination rules. The remaining rules are structural. Id is the obvious ax\u00adiom, from A one may infer \nA. Cut combines a proof with A in the succedent and a proof with A in the antecedent to yield a proof \nwith only the other formulas in the antecedents and succedents. Informally, this is justi.ed as follows: \nfrom G one may infer that either A holds or one of T holds; if A holds then from it and . one may infer \nthat one of . holds; else one of T holds. Thinning introduces an additional for\u00admula, Contraction replaces \ntwo identical formulas by one, and Interchange permutes the order of formulas. Gentzen proved sequent \ncalculus satis.es a Cut elimina\u00adtion property: any proof of a sequent can be transformed to a proof of \nthe same sequent that does not contain Cut. A corrollary of Cut elimination is consistency of the logic: \nthe sequent . (which corresponds to true implies false) cannot be the consequence of any rule other than \nCut, and is therefore not derivable. The dual of a formula not containing implication is de.ned in Figure \n2. The dual of conjunction is disjunction and vice versa, and negation is its own dual. The dual of a \nsequence of formulas is the reverse of the sequence of duals. Proposition 2.1. Duality is an involution, \nA.. = A. Rule &#38;R is dual to .L, &#38;L is dual to .R, \u00acR is dual to \u00acL, Id and Cut are dual to themselves, \nand Thinning, Contraction, Interchange come in dual pairs. Hence, we have the following. Proposition \n2.2. A sequent not containing implication is derivable if and only if its dual is derivable. G . T i. \nT. . G. . Implication can be de.ned in terms of other connectives. Proposition 2.3. Implication can be \nde.ned by A . B =\u00acA . B or A . B =\u00ac(A &#38; \u00acB). (X). = X (A &#38; B). = A. . B. . A. &#38; B. (A . \nB)= (\u00acA). =\u00acA. (A1,..., Am). = Am . ,..., A1 . Figure 2: Duality for the sequent calculus  3. THE DUAL \nCALCULUS The dual calculus is a reformulation of Gentzen s se\u00adquent calculus. Under Curry-Howard for \nnatural deduc\u00adtion, terms represent proofs and variables label assumptions. Here terms, coterms, and \nstatements represent proofs, and variables and covariables label antecedents and succedents. Coterms \nand covariables correspond to what are sometimes called continuation terms and continuation variables. \nFigure 3 presents the syntax and inference rules of the dual calculus. The types of the calculus are \nthe same as the formulas of Gentzen s sequent calculus. Let x, y, z range over variables, and a, \u00df, . \nrange over covariables. Let M, N range over terms, which yield values. A term is either a variable x; \na pair (M, N); an injection on the left or right of a sum (M)inl or (N)inr; a complement of a coterm \n[K]not; a function abstraction .x. N, with x bound in N ; or a covariable abstraction (S).a, with a bound \nin S. Let K, L range over coterms, which consume values. A coterm is either a covariable a; a projection \nfrom the left or right of a product fst[K] or snd[L]; a case [K, L]; a comple\u00adment of a term not(M); \na function application M @ L; or a variable abstraction x.(S), with x bound in S. Finally, let S, T range \nover statements. A statement is a cut of a term against a coterm, M K. Note that angle brackets always \nsurround terms, square brackets always surround coterms, and round brackets al\u00adways surround statements. \nCurly brackets are used for sub\u00adstitution and holes in contexts. There are three kinds of sequents, called \nright, left, and center, according to whether the proof of the sequent is rep\u00adresented by a term, coterm, \nor statement. A right sequent has a distinguished formula in the succedent, that is labeled by a term \nrather than a covariable. A left sequent has a distinguished formula in the antecedent, that is labeled \nby a coterm rather than a variable. A center sequent has no distinguished formula, and contains a statement. \nAs with sequent calculus, there are logical rules for each connective. Right rules always end with a \nright sequent and left rules always end with a left sequent. The &#38; and . rules begin and end with \nthe same kind of sequent, while the \u00ac rules reverse the kind of sequent. For example, &#38;R begins and \nends with right sequents, while \u00acL begins with a right sequent and ends with a left sequent. The remaining \nrules are structural rules. Id is split into two forms, one with a right sequent and one with a left \nse\u00adquent. Cut has a right sequent and a left sequent above the line, and ends in a center sequent. There \nare two new struc\u00adtural rules, RI and LI, that convert a center sequent to an equivalent right or left \nsequent, by designating a covariable to yield the value of the term, or a variable to consume the value \npassed to the coterm. Figure 4 also shows three derived rules. Id is a symmetric form of IdR and IdL \nthat concludes with a center sequent, which cuts a variable against a covariable. RE is an inverse of \nRI that converts a right sequent into an equivalent center sequent by cutting a term against a covariable. \nLE is an inverse of LI that converts a left sequent into an equivalent center sequent by cutting a variable \nagainst a coterm. RI and LI behave like introduction rules in natural deduc\u00adtion, and RE and LE behave \nlike elimination rules, hence their names. They also resemble the Activate and Passivate rules in some \nformulations of the .\u00b5-calculus, such as that presented by Ariola and Herbelin (2003). Finally, there \nare eighteen rules for Thinning, Contrac\u00adtion, and Interchange in the antecedent and succedent for right, \nleft, and center sequents. Only the six rules for right sequents are shown, the remaining twelve rules \nfor left and center sequents are similar. The rules shown are not duals; instead, the antecedent rules \nfor right sequents are dual to succedent rules for left sequents, and vice versa, while an\u00adtecedent and \nsuccedent rules for center sequents are dual to each other. In Contraction, substitution of one variable \nfor another is written M{x/y}, and substitution of one covari\u00adable for another is written K{a/\u00df}. The \ncomputational interpretation of a sequent is as fol\u00adlows: one must supply a value for every variable \n(and term) in the antecedent, and the computation will pass a value to some continuation variable (or \ncoterm) in the succedent; this corresponds to the fact that the sequent represents the conjunction of \nthe formulas in the antecedent and the dis\u00adjunction of the formulas in the succedent. Hence, the com\u00adputational \ninterpretation of a right sequent x1 : A1,..., xm : Am . \u00df1 : B1,..., \u00dfn : Bn . M : Bn+1 is that if each \nvariable xi is supplied a value of type Ai then evaluation of the expression M will either return a value \nof type Bn+1 or pass to some continuation variable \u00dfj a value of type Bj . The computational interpretation \nof a left sequent K : A0 . x1 : A1,..., xm : Am . \u00df1 : B1,..., \u00dfn : Bn is that if each variable xi is \nsupplied a value of type Ai and a value of type A0 is supplied to the coterm K, then evaluation will \nreturn to some continuation variable \u00dfj a value of type Bj . The computational interpretation of a center \nsequent x1 : A1,..., xm : Am . S .. \u00df1 : B1,..., \u00dfn : Bn is that if each variable xi is supplied a value \nof type Ai then execution of the statement S with pass to some continuation variable \u00dfj a value of type \nBj . The two variable rules correspond to trivial computations. Term x yields the value passed in to \nvariable x. Coterm a consumes a value and passes it out to covariable a. Computationally, the formula \nA &#38; B corresponds to the product type, where the proof of a conjunction is represented by a pair \nof the proofs of its subformulas. The term (M, N) yields a pair of type A &#38; B consisting of the values \nyielded by terms M of type A and N of type B. The coterm fst[K] consumes a pair of type A &#38;B, projects \nout the .rst compo\u00adnent, and passes it on to be consumed by coterm K of type A. Similarly for snd[L]. \nDually, the formula A . B corresponds to the sum type, where the proof of a disjunction is represented \nby a proof of K : A . G . TG . T . M : A Type Term Coterm Statement A, B, C M, N K, L S, T ::= ::= ::= \n::= X | A &#38; B | A . B | \u00acA | A . B x | (M, N) | (M)inl | (N)inr | [K]not | .x. N | (S).a a | [K, \nL] | fst[K] | snd[L] | not(M) | M @ L | x.(S) M K Antecedent Succedent G, . T, . ::= ::= x1 : A1, . \n. . , xm : Am \u00df1 : B1, . . . , \u00dfn : Bn Right sequent Left sequent Center sequent G . T . M : A K : A \n. G . T G . S .. T IdR x : A . . x : A IdL a : A . . a : A G . T . M : A G . T . N : B K : A . G . T \nL : B . G . T &#38;R &#38;L G . T . (M, N) : A &#38; B fst[K] : A &#38; B . G . T snd[L] : A &#38; B \n. G . T G . T . M : A G . T . N : B K : A . G . T L : B . G . T  .R .L G . T . (M)inl : A . B G . T \n. (N)inr : A . B [K, L] : A . B . G . T \u00acR \u00acL G . T . [K]not : \u00acA not(M) : \u00acA . G . T x : A, G . T . \nN : B G . T . M : AL : B . . . . .R .L G . T . .x. N : A . BM @ L : A . B . G, . . T, . G . S .. T,a \n: Ax : A, G . S .. T RI LI G . T . (S).a : A x.(S): A . G . T G . T . M : AK : A . . . . Cut G, . . M \n K .. T, . G . T . M : C G . T . M : C Thinning x : A, G . T . M : C T . T,a : A . M : C x : A, y : \nA, G . T . M : C G . T, \u00df : A, a : A . M : C Contraction x : A, G . T . M{x/y} : C G . T, a : A . M{a/\u00df} \n: C ., x : A, y : B, G . T . M : C G . T, \u00df : B, a : A, . . M : C ., y : B, x : B, G . T . M : C Interchange \nG . T, a : A, \u00df : B, . . M : C (also Thinning, Contraction, Interchange for center and left sequents) \nFigure 3: The dual calculus Id x : A . x a .. a : A G . T . M : AK : A . G . T RE LE G . M a .. T,a \n: Ax : A, G . x K .. T Figure 4: Derived structural rules 193 (X). = X (A &#38; B). = A. . B. (A . B). \n= A. &#38; B. (\u00acA). =\u00acA. .. . a. ((M, N)). = [M.,N.] ([K, L]). =(K.,L.)((M)inl). = fst[M.] (fst[K]). \n=(K.)inl ((N)inr). = snd[M.] (snd[L]). =(K.)inr ([K]not). = not(K.) (not(M)). = [M.]not (x)= x (a)= a.. \n((S).a). = .(S.)(x.(S)). = (S.).x . K. M. (M K)= .. .. (x1 : A1,..., xm : Am). = xm : Am ,..., x1 : \nA1 .. .. (\u00df1 : B1,..., \u00dfn : Bn). = \u00dfn : Bn ,..., \u00df1 : B1 Figure 5: Duality for the dual calculus either \nits left or right subformula. The term (M)inl yields a value of type A . B consisting of the injection \non the left of the value yielded by term M of type A. Similarly for (N)inr. The coterm [K, L] is like \na case expression: it consumes a value of type A . B, and depending on whether it is a left or right \ninjection, passes on the injected value to be consumed by coterm K of type A or coterm L of type B. Logically, \nthe formula \u00acA is equivalent to the implication A ... This suggests that computationally the formula \n\u00acA should correspond to a continuation, where a continuation is a function that accepts a value and returns \nnothing. (One may recall the song about Charlie on the MTA: And did he ever return, no he never returned, \nand his fate is still unlearned. ) Though it never returns, a continuation may still yield a value through \none of its free covariables, just as it may consume values other than its argument through its free variables. \nThe term [K]not yields a continuation of type \u00acA that accepts an argument of type A and passes it to \nbe consumed by the coterm K. The term not(M) consumes a continuation of type \u00acA by passing it as argument \nthe value IdR x : A .. x : A .R x : A .. (x)inl : A .\u00acA RE x : A . (x)inl . .. . : A .\u00acA LI x.((x)inl \n .): A .. . : A .\u00acA \u00acR . . : A .\u00acA . [x.((x)inl .)]not : \u00acA .R . . : A .\u00acA . ([x.((x)inl .)]not)inr \n: A .\u00acA RE . ([x.((x)inl .)]not)inr d .. . : A .\u00acA, d : A .\u00acA Cont . ([x.((x)inl .)]not)inr . .. \n. : A .\u00acA RI .. (([x.((x)inl .)]not)inr .).. : A .\u00acA Figure 6: Law of the excluded middle has a unique \nproof tree (up to structural rules), and the correspondence with sequent calculus is more closely pre\u00adserved. \nA proof in the sequent calculus is mapped into the dual calculus by adding occurrences of RI, LI, RE, \nand LE as needed; and a proof in the dual calculus is mapped into the sequent calculus by eliding the \noccurrences of RI, LI, RE, and LE. (Avoiding overlap in this way resolves the problem mentioned by Curien \nand Herbelin (2000) in the paragraph spanning pages 234 5 that ends no perfect world .) Types, terms, \ncoterms, statements not involving impli\u00adcation have a dual, as de.ned in Figure 5. The de.nition assumes \na bijection mapping each variable x into a covari\u00adable x ., with its inverse mapping each covariable \na into a variable a., such that x .. = x and a.. = a. Proposition 3.1. Duality is an involution, A.. \n= A M.. = M K.. = K S.. = S. Proposition 3.2. A sequent not containing implication is derivable if and \nonly if its dual is derivable, .. .. M. : A. . T. . G. G . T . M : A of the term M of type A. The formula \nA . B corresponds to a function type. The K : A . G . T i. T. . G. . K. : A. term .x. N yields a function \nof type A . B that takes an argument x of type A and yields the value of term N of type B. The coterm \nM @L consumes a function of type A.B by passing it as argument the value of the term M of type A, and \nthen passing the result to be consumed by the coterm L of type B. Cut plugs together a term and a coterm. \nThe statement M K takes the value yielded by term M and passes it to be consumed by coterm K. G . S \n.. T .. T. . S. .. G. . As with sequent calculus, implication can be de.ned in terms of the other connectives. \nWe will return to this point after considering an extended example, the law of the ex\u00ad cluded middle, \nand considering the reduction rules for call\u00ad by-value and call-by-name.  4. EXAMPLE: EXCLUDED MIDDLE \n In RI, the term (S).a executes statement S and yields the value of type A passed to the covariable a. \nIn LI, the coterm x.(S) consumes a value of type A which is bound to the variable x and then executes \nstatement S. Rules Cut, Id, RE, and LE overlap; we can avoid the over\u00adlap by using Cut only when the \nterm is not a variable and the coterm is not a covariable; using RE only when the term is not a variable, \nand using LE only when the coterm is not a covariable. Then every term, coterm, and statement still Figure \n6 shows a proof of the law of the excluded mid\u00addle, A .\u00acA. The computational interpretation of this proof \nexploits the ability of classisal control operators to return multiple times from a single term. The \nterm of type A .\u00acA .rst returns an injection into the right of the sum, a contin\u00aduation that expects \na value of type A. If the continuation is ever passed such a value, then the original term of type A \n.\u00acA now returns an injection into the left of the sum, containing the value passed to the continuation. \n The following story illustrates this behavior. (With apolo\u00adgies to Peter Selinger, who tells a similar \nstory about a king, a wizard, and the Philosopher s stone.) Once upon a time, the devil approached a \nman and made an o.er: Either (a) I will give you one billion dollars, or (b) I will grant you any wish \nif you pay me one billion dollars. Of course, I get to choose whether I o.er (a) or (b). The man was \nwary. Did he need to sign over his soul? No, said the devil, all the man need do is accept the o.er. \nThe man pondered. If he was o.ered (b) it was unlikely that he would ever be able to buy the wish, but \nwhat was the harm in having the opportunity available? I accept, said the man at last. Do I get (a) or \n(b)? The devil paused. I choose (b). The man was disappointed but not surprised. That was that, he thought. \nBut the o.er gnawed at him. Imagine what he could do with his wish! Many years passed, and the man began \nto accumulate money. To get the money he sometimes did bad things, and dimly he realized that this must \nbe what the devil had in mind. Eventually he had his billion dollars, and the devil appeared again. Here \nis a billion dollars, said the man, handing over a valise containing the money. Grant me my wish! The \ndevil took possession of the valise. Then he said, Oh, did I say (b) before? I m so sorry. I meant (a). \nIt is my great pleasure to give you one billion dollars. And the devil handed back to the man the same \nvalise that the man had just handed to him.  5. REDUCTIONS A cut of a term against a variable abstraction, \nor a cut of a covariable abstraction against a coterm, corresponds to substitution. This suggests the \nfollowing reduction rules. (\u00dfL) M x.(S) -. S{M/x} (\u00dfR) (S).a K -. S{K/a} Here substitution in a statement \nof a term for a variable is written S{M/x}, and substitution in a statement of a coterm for a covariable \nis written S{K/a}. A critical pair occurs when a covariable abstraction is cut against a variable abstraction. \n(S).a x.(T ) Sometimes such reductions are con.uent. (x a).a y.(y \u00df) x y.(y \u00df)(x a).a \u00df x \u00df \n But sometimes they are not. (x a).\u00df y.(z .) x az . To restore con.uence we must limit reductions, \nand this is achieved by adopting call-by-value or call-by-name. Call-by-value only reduces a cut of a \nvalue against a vari\u00adable abstraction, but reduces a cut of a covariable abstrac-Value V replaces term \nM in rule (\u00dfL). A value cannot be a covariable abstraction, so this avoids the critical pair. Call-by-name \nonly reduces a cut of a covariable abstrac\u00adtion against a covalue, but reduces a cut of any coterm against \na variable abstraction. (\u00dfL) M x.(S) -.n S{M/x} (\u00dfR) (S).a P -.n S{P/a} Covalue P replaces coterm K \nin rule (\u00dfR). A covalue cannot be a variable abstraction, so this avoids the critical pair. In .-calculus, \nthe move from call-by-value to call-by-name generalizes values to terms. In dual calculus, the move from \ncall-by-value to call-by-name generalizes values to terms but restricts coterms to covalues, clarifying \nthe duality. Call-by-value reductions are shown in Figure 7. Let V, W range over values. A value is a \nvariable, a pair of values, a left or right injection of a value, or any complement. The fact that any \ncomplement is a value is analogous to the fact that any function is a value in the .v calculus. A context \nis a term or coterm that contains a hole which may be .lled with a term. Let E range over term contexts. \nThe hole is written {}, and the result of .lling the hole in a term context E with a term M is written \nE{M}. Reductions (\u00df&#38;), (\u00df.), (\u00df\u00ac), and (\u00df.) are logical reduc\u00adtions, and correspond to cutting a \nright rule against a left rule. For instance, the (\u00df&#38;) reductions correspond to the following familiar \nreductions from lambda calculus. (\u00df&#38;) fst (V, W ) -.v V (\u00df&#38;) snd (V, W ) -.v W The remaining \nreductions are structural. Reductions (\u00dfL) and (\u00dfR) correspond to following an introduction rule by an \nelimination rule. Reductions (.L) and (.R) correspond to following an elimination rule by an introduction \nrule. Re\u00adduction (.) is a commuting rule. Reductions (.L), (.R), and (.) are in fact expansions. To avoid \nin.nite regress, expansions (.L) and (.R) should be applied only to a term M or coterm K that is not \nthe immediate subject of a cut, and expansion (.) should be applied only when the term M is not a value. \nUnlike (\u00dfL), there is no need to restrict to values in (.L). Reduction (.) introduces new bindings for \nevery subterm that is not a variable. It is similar to the reductions (let.1) and (let.2) in the .c-calculus \nof Moggi (1988). (let.1) MN -.c let x = M in xN (let.2) VN -.c let y = N in Vy These reductions correspond \nto the operation of introduc\u00ading names for subterms in continuation passing style, as ex\u00adplained by Sabry \nand Wadler (1997). It is claimed without proof that the reductions are con\u00ad.uent. It is also claimed \nthat if reductions (.L), (.R), and (.) are omitted, then the remaining reductions are strongly normalizing \nfor typed terms. Call-by-name reductions are shown in Figure 8. With the exception of implication, they \nare dual to call-by-value. Proposition 5.1. For terms, coterms, and statements not involving implication, \ncall-by-value is dual to call-by\u00adname, .. .. tion against any coterm. M -.v N M. -.n N. K. -.n L. i. \n(\u00dfL) V x.(S) -.v S{V/x}S{K/a} .. S. -.n T . . (\u00dfR) (S).a K -.v Value V, W ::= x |(V, W )|(V )inl \n|(W )inr | [K]not | .x. N Term context E ::= ({ },M)|(V, {}) | ({})inl | ({ })inr (\u00df&#38;) (\u00df&#38;) (\u00df.) \n(\u00df.) (\u00df\u00ac) (\u00df.) (V, W ) fst[K] (V, W ) snd[L] (V )inl [K, L] (W )inr [K, L] [K]not not(M).x. N V \n@ L -.v -.v -.v -.v -.v -.v V K W L V K W L M K V x.(N L) (\u00dfL) (\u00dfR) (.L) V x.(S) (S).a K K -.v \n-.v -.v S{V /x}S{K/a}x.(x K) if x .. free(K) (.R) M -.v (M a).a if a .. free(M) (.) E{M} -.v (M x.(E{x} \n \u00df)).\u00df Figure 7: Call-by-value reductions Covalue P, Q ::= a | [P, Q] | fst[P ] | snd[Q] | not(M)| M \n@ Q Coterm context F ::= [{},K] | [P, {}] | fst[{}] | snd[{}] (\u00df&#38;) (\u00df&#38;) (\u00df.) (\u00df.) (\u00df\u00ac) (\u00df.) (M, \nN) fst[P ] (M, N) snd[Q] (M)inl [P, Q] (N)inr [P, Q] [K]not not(M).x. N M @ Q -.n -.n -.n -.n -.n \n-.n M P N Q M P N Q M K M x.(N Q) (\u00dfL) (\u00dfR) (.L) M x.(S) (S).a P K -.n -.n -.n S{M/x}S{P/a}x.(x \n K) if x .. free(K) (.R) M -.n (M a).a if a .. free(M) (.) F {K} -.n y.((y F {a}).a K) Figure 8: \nCall-by-name reductions Implication can be de.ned in terms of the other operators. Under call-by-value \nfunction abstractions must translate to values, while under call-by-name function applications must translate \nto covalues, and this forces di.erent de.nitions for the two reduction disciplines. Proposition 5.2. \nUnder call-by-value, implication can be de.ned by A . B =\u00ac(A &#38; \u00acB) .x. N = [z.(z fst[x.(z snd[not(N)])])]not \nM @ L = not((M, [L]not)). The translation of a function abstraction is a value, and the inference and \nreduction rules for implication can be derived from the inference rules for the other connectives. Proposition \n5.3. Under call-by-name, implication can be de.ned by A . B =\u00acA . B .x. N = (([x.((N)inr .)]not)inl \n .).. M @ L = [not(M),L]. The translation of a function application is a covalue, and the inference and \nreduction rules for implication can be de\u00adrived from the inference rules for the other connectives. \n 6. CONTINUATION-PASSING STYLE Plotkin (1975) formalized the call-by-value .v-calculus and its corresponding \ncontinuation-passing style (CPS) translation. He showed that the CPS translation is sound in that it \npreserves reductions, but not complete in that it does not re.ect equalities. Sabry and Felleisen (1993) \nsharpened Plotkin s result by taking as their source the .c \u00adcalculus of Moggi (1988). They showed that \nthe CPS trans\u00adlation from .c is both sound and complete, in that it is an equational correspondence that \nboth preserves and re.ects equalities. Sabry and Wadler (1997) sharpened this result further. They showed \nthat the CPS translation is a Galois connection that both preserves and re.ects reductions. Here we give \nan analogous result for the CPS translation from the dual calculus, strengthening a result of Curien \nand Herbelin (2000). The call-by-value CPS translation is shown in Figure 9, and the call-by-name CPS \ntranslation is shown in Figure 10. We write (A)V , (V )V , (M)v , (K)v , (S)v for the call-by-value translation \nof types, values, terms, coterms, and statements, and similarly for call-by-name. The call-by-value CPS \ntranslation resembles that for the .v-calculus in Plotkin (1975), and the call-by-name CPS translation \nresembles that for the .\u00b5-calculus in Hofmann (X)V = X (A &#38; B)V = (A)V \u00d7 (B)V (A . B)V = (A)V +(B)V \n(\u00acA)V = (A)V . R (x)v = .... x ((M, N))v = ... (M)v (.x. (N)v (.y. . (x, y))) ((M)inl)v = ... (M)v (.x. \n. (inl x)) ((N)inr)v = ... (N)v (.y. . (inr y)) ([K]not)v = .... (.z. (K)v z) ((S).a)v = .a. (S)v (M \n K)v (x)V ((V,W ))V ((V )inl)V ((W )inr)V ([K]not)V (a)v = ([K, L])v = (fst[K])v = (snd[L])v = (not(M))v \n= (x.(S))v = = (M)v (K)v = x =((V )V , (W )V ) = inl (V )V = inr (W )V = (K)v .z. a z .z. case z of \ninl x . (K)v x, inr y . (L)v y .z. case z of (x, -) . (K)v x .z. case z of (-,y). (L)v y .z. (... (M)v \n.) z .x. (S)v Figure 9: Call-by-value CPS translation (a)N = a (X)N = X ([P, Q])N =((P )N , (Q)N )(A \n&#38; B)N = (A)N +(B)N (fst[P ])N = inl (P )N (A . B)N = (A)N \u00d7 (B)N (snd[Q])N = inr (Q)N (\u00acA)N = (A)N \n. R (not(M))N = (M)n (x)n = ... x . (a)n = .z.z a ((M, N))n = ... case . of inl a . (M)n a, inr \u00df . \n(N )n \u00df ([K, L])n = .z. (K)n (.a. (L)n (.\u00df. z (a, \u00df))) ((M)inl)n = ... case . of (a, -) . (M)n a (fst[K])n \n= .z. (K)n (.a. z (inl a)) ((N)inr)n = ... case . of (-,\u00df). (N)n \u00df (snd[L])n = .z. (L)n (.\u00df. z (inr \u00df)) \n([K]not)n = ... (.z. (K)n z) . (not(M))n = .z. z (... (M)n .) ((S).a)n = .a. (S)n (x.(S))n = .x. (S)n \n (M K)n = (K)n (M)n Figure 10: Call-by-name CPS translation and Streicher (1997). Similar translations \nare presented by Curien and Herbelin (2000) and Selinger (2001). The source of the translations is the \ndual calculus without implications, and the target is a restriction of the simply typed .-calculus. The \nsyntax and reductions of the target are shown in Figure 11. The typing rules for the target are not shown, \nas they are standard. The target calculus is indi.erent, in the sense of Plotkin (1975), in that the \narguments of all reductions are values, so the reductions are equally valid under both call-by-value \nand call-by-name. Proposition 6.1. The call-by-value CPS translation pre\u00adserves types. Proposition 6.3. \nThe call-by-value and call-by-name CPS translations are dual. (A)V = (A.)N (V )V = (V .)N (M)v = (M.)n \n(K)v = (K.)n (S)v = (S.)n There is an intuitive explanation of the duality between the CPS translations, \nderived directly from de Morgan s laws relating conjunction and disjunction. Consider the continuation \nof a term of pair type A &#38; B. Depending on . . . . . . whether the term is deconstructed using fst[] \nor snd[], either (G)V , (\u00acT)V . (V )V :(A)VG . T . V : A the continuation will select the .rst component \nof type A or(G)V , (\u00acT)V . (M)v :(\u00ac\u00acA)V G . T . M : A i. the second component of type B, and then continue \nevalu\u00ad(G)V , (\u00acT)V . (K)v :(\u00acA)VK : A . G . T G . S .. T . . . . ation. Thus, the continuation for \na pair \u00ac(A &#38; B) is a sum (G)V , (\u00acT)V . (S)v : R of continuations \u00acA .\u00acB. Now consider the continuation \nof a term of sum type A . B. Since the term may be con- Proposition 6.2. The call-by-name CPS translation \nstructed using either ()inl or ()inr, the continuation must be prepared to accept both a left injection \nof type A and a preserves types. . . . . . . (\u00acG)N , (T)N . (P )N :(A)NP : A . G . T right injection \nof type B. Thus, the continuation for a sum (\u00acG)N , (T)N . (M)n :(\u00acA)N G . T . M : A \u00ac(A . B) is a pair \nof continuations \u00acA &#38; \u00acB. The CPS translations preserve and re.ect reductions. We i. (\u00acG)N , (T)N \n. (K)n :(\u00ac\u00acA)NK : A . G . T  G . S .. T . . . . (\u00acG)N , (T)N . (S)n : R Type A, B ::= X | A \u00d7 B | \nA + B | A . R Value Term V, W M, N ::= ::= x | (V, W ) | inl V | inr W | K .a. S Coterm K, L ::= .x. \nS Statement S, T ::= a V |case V case V case V M V of (x, -) . S |of (-, y) . T |of inl x . S, inr y \n. T | (\u00df\u00d7) case (V,W ) of (x, -) . S -. S{V/x}(\u00df\u00d7) case (V,W ) of (-,y). T -. T {W/y}(\u00df+) case inl V \nof inl x . S, inr y . T -. S{V/x}(\u00df+) case inr W of inl x . S, inr y . T -. T {W/y}(\u00df.)(.a. S)(.x. T \n) -. S{T {-/x}/a -} Figure 11: CPS target calculus Value Term V, W M, N ::= ::= x | (V, W ) | (V )inl \n| (W )inr | [K]not (S).a Coterm K, L ::= x.(S) Statement S, T ::= V a |V fst[K] |V snd[L] |V [K, \nL] |V not(M) Figure 12: Kernel of the call-by-value dual calculus  (x)V = x (X)V = X ((V, W ))V =((V \n)V , (W )V ) (A \u00d7 B)V = (A)V &#38;(B)V (inl V )V =((V )V )inl (A + B)V = (A)V . (B)V (inr W )V =((W )V \n)inr (A . R)V =\u00ac(A)V (K)V = [(K)v]not (.a. S)v = ((S)v).a (.x. S)v = x.((S)v) (aV )v = (V )V a (case \nV of (x, -) . S)v = (V )V fst[x.((S)v)] (case V of (-,y). T )v = (V )V snd[y.((T )v)] (case V of inl \nx . S, inr y . T )v = (V )V [x.((S)v), y.((T )v)] (MV )v = (V )V not((M)v) Figure 13: Inverse call-by-value \nCPS translation is entirely dual. The proof given here is based on that of Sabry and Wadler (1997). In \nthe CPS translations, .-abstractions in boldface are administrative, that is, they are reduced at the \ntime the translation is performed. Figure 14 presents .ve examples, showing the translation before and \nafter performing the ad\u00administrative reductions. The target syntax in Figure 11 is closed with respect \nto substitutions. The notation S{V/x} stands for statement S with all occurrences of variable x replaced \nby value V , and is again a valid statement in the target. Note it may not be valid to substitute a term \nthat is not a value for a variable. The notation S{T {-/x}/a -} stands for statement S with all occurrences \nof the form aV replaced by T {V/x}. Note that all occurrences of a in a valid statement in the target \nhave the form aV for some value V , and the result is again a legal statement in the target. The target \nis also closed with respect to reductions, in that reduction of a term in the target syntax always yields \na term in the target syntax. The key intuition behind the proofs is to note that there is a kernel of \nthe dual calculus that is in one-to-one correspon\u00addence with the CPS target calculus. This kernel is \nshown in ((x, y))v ' '' = ... (.... x)(.x. (.... y)(.y.. (x,y' ))) = ... . (x, y) ((z fst[a]).a)v '' \n'' = .a. (.... z)(.z. case zof (x, -) . (.z.az'' ) x) = .a. case z of (x, -) . ax (((z fst[a]).a, (z \n snd[\u00df]).\u00df))v = ... (.a. ' case z of (x, -) . ax) (.x. (.\u00df. case z of (-,y). \u00dfy) (.y' .. (x' ,y' ))) \n= ... case z of (x, -) . case z of (-,y). . (x, y) (x a)v = (.... x)(.z. a z) = ax ([a]not not(x))v \n= (... . (.z. (.z. a z)z)) (.z. (... (... x .) .) z) = (... x .)(.z. a z) Figure 14: Examples of CPS \ntranslation (((x, y))v)v =(x, y) (((z fst[a]).a)v)v = (z fst[x.(a x)]).a ((((z fst[a]).a, (z snd[\u00df]).\u00df))v)v \n= (z fst[x.(z snd[y.((x, y) .)])]).. ((x a)v)v = x a The CPS translation preserves substitution of \na value for a variable, and of a coterm for a covariable. Proposition 6.5. Let S, V , x, K, a be in the \ndual cal\u00adculus. Then (S{V/x})v = (S)v{(V )V /x}(S{K/a})v = (S)v{(K)v/a}. Applying the CPS translation \nfollowed by its inverse amounts to putting a term, coterm, or statement of the dual calculus into a normal \nform with regard to the reductions (\u00dfL), (\u00dfR), (.L), (.R), and (.) of the source calculus. Proposition \n6.6. Let M, K, S be terms of the dual cal\u00adculus. Then M -.v ((M)v)v K -.v ((K)v)v S -.v ((S)v)v. In the \nabove reductions, only the rules (\u00dfL), (\u00dfR), (.L), (.R), and (.) are applied, and they are applied until \nthey can be applied no further. (As usual, one must be careful not to apply (.L) and (.R) within a cut, \nand not to apply (.) when the term is a variable.) The inverse CPS translation followed by the CPS trans\u00adlation \nis the identity. Proposition 6.7. Let N, L, and T be in the CPS target calculus. Then ((N)v)v = N ((L)v)v \n= L ((T )v)v = T. The CPS translation preserves reductions. Proposition 6.8. Let M, N, K, L, S, T be \nin the dual calculus. Then .. .. (M)v -. (N)v M -.v N (([a]not not(x))v)v [z.(z a)]not not((x .)..) \n(K)v -. (L)v (S)v -. (T )v . K -.v L implies = .. S -.v T Figure 15: Examples of kernel terms Figure \n12. Like the CPS target calculus, the kernel is closed with respect to substitutions and reductions. \nThe CPS translation has a right inverse, as de.ned in Figure 13, which maps each term in the CPS target \nto the corresponding term in the kernel. Translating a term of Each reduction in the dual calculus translates \nto zero or more reduction steps in the CPS target. In particular, re\u00adductions (.L), (.R), and (.) translate \nto zero steps, as their left and right sides have identical CPS translations after ad\u00administrative reductions \nhave been applied. The inverse CPS translation preserves reductions. Proposition 6.9. Let M, N, K, L, \nS, T be in the CPS target calculus. Then .. .. the dual calculus into CPS and then applying the inverse \nM -. N (M)v -.v (N)v CPS translation yields a corresponding term in the kernel. K -. L (K)v -.v (L)v \nimplies .. Figure 15 presents the .ve kernel terms corresponding to S -. T (S)v -.v (T )v. the .ve translations \nin Figure 14. A term in the kernel has no (\u00dfL) or (\u00dfR) redexes. Note, however, that such redexes may \nbe created after reduction (\u00df\u00ac) is applied. In the CPS target, there is no reduction corresponding to \n(\u00df\u00ac), but the reductions corresponding to (\u00dfL) and (\u00dfR) play a similar role. The CPS translation on values \nrelates in the usual way to the CPS translation on terms. We can summarize our results as follows. The \nCPS trans\u00adlation is a Galois connection; furthermore, the CPS trans\u00adlation followed by its inverse is \nthe identity, so we have the stronger form of Galois connection called a re.ection. The following is \nequivalent to Propositions 6.6 6.9. Proposition 6.10. Let M , K, S be in the dual calculus, and N , L, \nT be in the CPS target calculus. Then .. .. Proposition 6.4. Let V be a value of the dual calculus. \n(M)v -. N ((N)v)v = N M -.v (N)v (K)v -. L and ((L)v)v K -.v (L)v = L .. (V )v = ... . (V )V (S)v -. \nT, ((T )v)v S -.v (T )v .  7. CONCLUSIONS Here is a speculation about one possible application of these \nideas. Call-by-name can be ine.cient because a single term may be evaluated many times. Call-by-need \navoids this ine.ciency by overwriting a term with its value the .rst time it is evaluated. Similarly, \nin the dual calculus it becomes clear that call\u00adby-value can be ine.cient because a single coterm may \nbe evaluated many times. A strategy dual to call-by-need could avoid this ine.ciency by overwriting a \ncoterm with its cov\u00adalue the .rst time it is evaluated. Terms in the dual calculus are not always easy \nto read. Compare, for instance, the .-calculus term (fst V, snd M ) with a corresponding dual calculus \nterm, (V fst[x.(V snd[y.(. (x, y))])]).. The latter is reminiscent of continuation-passing style like \nthe Pompidou Center in Paris, the plumbing is exposed on the outside. While this can make the expression \nharder on the eyes, it also like CPS, and like the Pompidou Center has the advantage of revealing structure \nthat previously was hidden. Call-by-name was introduced in the seminal work of Church (1932), and call-by-value \nwas introduced in a review a few years later by Bernays (1936). Almost a half century passed between \nthe initial publications of Church (1932) and Gentzen (1935) and their linkage in a publication by Howard \n(1980). After a further quarter of a century, an underlying duality between the two fundamental forms \nof evaluation has been revealed. What more will we discover before the centenary of the birth of .-calculus, \nnatural deduction, and sequent calculus? Acknowledgements Thanks to Pierre-Louis Curien, Olivier Danvy, \nTim Gri.n, Hugo Herbelin, Robert McGrail, Rex Page, Amr Sabry, Pe\u00adter Selinger, Ken Shan, and Steve Zdancewic \nfor discussions on this work.  8. REFERENCES Zena Ariola and Hugo Herbelin (2003) Minimal classical \nlogic and control operators. In 30 th International Colloquium on Automata, Languages and Programming, \nEindhoven, The Netherlands. F. Barbanera and S. Berardi (1996) A symmetric lambda calculus for classical \nprogram extraction. Information and Computation, 125(2):103 117. P. Bernays (1936) Review of Some Properties \nof Conversion by Alonzo Church and J. B. Rosser. Journal of Symbolic Logic, 1:74 75. George Boole (1847) \nThe mathematical analysis of logic. Macmillan, Barclay, and Macmillan, Cambridge. Alonzo Church (1932) \nA set of postulates for the foundation of logic. Annals of Mathematics, II.33:346 366. Alonzo Church \n(1940) A formulation of the simple theory of types. Journal of Symbolic Logic, 5:56 68. P.-L. Curien \nand H. Herbelin (2000) The duality of computation. In 5 th International Conference on Functional Programming, \npages 233 243, ACM, September 2000. H. B. Curry and R. Feys (1958) Combinatory Logic. North-Holland (see \nChapter 9, Section E). V. Danos, J-B. Joinet and H. Schellinx (1995) LKQ and LKT: Sequent calculi for \nsecond order logic based upon linear decomposition of classical implication. In Advances in Linear Logic, \nJ-Y. Girard, Y Lafont and L. Regnier editors, London Mathematical Society Lecture Note Series 222, Cambridge \nUniversity Press, pp. 211-224. N. G. de Bruijn (1968) The mathematical language Automath, its usage, \nand some of its extensions. In Symposium on Automatic Demonstration, Versailles, 1968, pages 29 61. Springer-Verlag, \nLecture Notes in Mathematics 125, 1970. M. Felleisen, D. Friedman, E. Kohlbecker, and B. Duba (1986) \nReasoning with continuations. In Proceedings of the First Symposium on Logic in Computer Science, pages \n131 141, IEEE. Andrzej Filinski (1989) Declarative continuations and categorical duality. Master s thesis, \nUniversity of Copenhagen, Copenhagen, Denmark, August 1989. (DIKU Report 89/11.) Gottlob Frege (1879) \nBegri.sschrift,a formula language, modeled upon that of arithmetic, for pure thought. Halle. Reprinted \nin Jan van Heijenoort, editor, From Frege to G\u00a8odel, A Sourcebook in Mathematical Logic, 1879 1931, \nHarvard University Press, 1967. Gerhard Gentzen (1935) Investigations into Logical Deduction. Mathematische \nZeitschrift 39:176 210,405 431. Reprinted in M. E. Szabo, editor, The Collected Papers of Gerhard Gentzen, \nNorth-Holland, 1969. Joseph Diaz Gergonne (1826) Annales de math\u00b4ematique pures et appliqu\u00b4ees, 16:209. \nTimothy Griffin (1990) A formulae-as-types notion of control. In 17 th Symposium on Principles of Programming \nLanguages, San Francisco, CA, ACM, January 1990. Ivor Grattan Guinness (2000) The Search for Mathematical \nRoots 1870 1940. Princeton University Press. Hugo Herbelin (1994) A lambda-calculus structure isomorphic \nto sequent calculus structure. In Computer Science Logic, pages 61 75, Springer-Verlag, LNCS 933. M. \nHofmann and T. Streicher (1997) Continuation models are universal for .\u00b5-calculus. In Proceedings of \nthe Twelfth Annual IEEE Symposium on Logic in Computer Science, pages 387 397. Eugenio Moggi (1988) Computational \nlambda-calculus and monads. Technical Report ECS-LFCS-88-66, Edinburgh University, Department of Computer \nScience. P. H. Nidditch (1969) The Development of Mathematical Logic. Thoemmes Press, Bristol (reprinted \n1998). C.-H. L. Ong (1996) A semantic view of classical proofs: Type-theoretic, categorical, and denotational \ncharacterizations. In Proceedings of the Eleventh Annual IEEE Symposium on Logic in Computer Science, \npages 230 241. C.-H. L. Ong and C. A. Stewart (1997) A Curry-Howard foundation for functional computation \nwith control. In Proceedings of the Symposium on Principles of Programming Languages, pages 215 227. \nM. Parigot (1992) .\u00b5-calculus: an algorithmic interpretation of classical natural deduction. In LPAR \n1992, pages 190 201, Springer-Verlag, LNCS 624. G. D. Plotkin (1975) Call-by-name, call-by-value and \nthe .-calculus. In Theoretical Computer Science, 1:125 159. Jean-Victor Poncelet (1818) Annales de math\u00b4ematique \npures et appliqu\u00b4ees, 8:201. Dag Prawitz (1965) Natural Deduction: A Proof-Theoretical Study. Almqvist \nand Wiksell, Stockholm. John Reynolds (1993) The discoveries of continuations. Lisp and Symbolic Computation, \n6(3/4):233 248. Amr Sabry and Matthias Felleisen (1993) Reasoning about programs in continuation-passing \nstyle. Lisp and Symbolic Computation, 6(3/4):289 360. Amr Sabry and Philip Wadler (1997) A re.ection \non call-by-value. In ACM Transactions on Programming Languages and Systems, 19(6):916-941. F. W. K. \nE. Schr\u00a8uber die oder (1890) Vorlesungen \u00a8Algebra der Logik (Teachings on the Algebra of Logic), Volume \n1. Teubner Press, Leibzig. Peter Selinger (1998) Control categories and duality: an axiomatic approach \nto the semantics of functional control. Talk presented at Mathematical Foundations of Programming Semantics, \nLondon, May 1998. Peter Selinger (2001) Control categories and duality: on the categorical semantics \nof the lambda-mu calculus. In Mathematical Structures in Computer Science, 11:207 260. Gerald Jay Sussman \nand Guy Lewis Steele Jr. (1975) Scheme: an interpreter for extended lambda calculus. MIT AI Memo 319, \nDecember 1975.   \n\t\t\t", "proc_id": "944705", "abstract": "The rules of classical logic may be formulated in pairs corresponding to De Morgan duals: rules about & are dual to rules about <i>V</i>. A line of work, including that of Filinski (1989), Griffin (1990), Parigot (1992), Danos, Joinet, and Schellinx (1995), Selinger (1998,2001), and Curien and Herbelin (2000), has led to the startling conclusion that call-by-value is the de Morgan dual of call-by-name.This paper presents a dual calculus that corresponds to the classical sequent calculus of Gentzen (1935) in the same way that the lambda calculus of Church (1932,1940) corresponds to the intuitionistic natural deduction of Gentzen (1935). The paper includes crisp formulations of call-by-value and call-by-name that are obviously dual; no similar formulations appear in the literature. The paper gives a CPS translation and its inverse, and shows that the translation is both sound and complete, strengthening a result in Curien and Herbelin (2000).", "authors": [{"name": "Philip Wadler", "author_profile_id": "81100173596", "affiliation": "Avaya Labs", "person_id": "PP39030941", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/944705.944723", "year": "2003", "article_id": "944723", "conference": "ICFP", "title": "Call-by-value is dual to call-by-name", "url": "http://dl.acm.org/citation.cfm?id=944723"}