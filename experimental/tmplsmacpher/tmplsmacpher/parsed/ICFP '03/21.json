{"article_publication_date": "08-25-2003", "fulltext": "\n Polish Parsers, Step by Step R. John M. Hughes S. Doaitse Swierstra Computing Science Institute of \nInformation and Computing Sciences Chalmers University of Technology Utrecht University P.O. Box 80.089 \nSE-412 96 G\u00f8teborg, Sweden 3508 TB Utrecht, the Netherlands rjmh@cs.chalmers.se doaitse@cs.uu.nl ABSTRACT \nWe present the derivation of a space e.cient parser combi\u00adnator library: the constructed parsers do not \nkeep unneces\u00adsary references to the input, produce online results and e.\u00adciently handle ambiguous grammars. \nThe underlying tech\u00adniques can be applied in many contexts where traditionally backtracking is used. \nWe present two data types, one for keeping track of the progress of the search process, and one for representing \nthe .nal result in a linear way. Once these data types are com\u00adbined into a single type, we can perform \na breadth-.rst search, while returning parts of the result as early as possi\u00adble.  Categories and Subject \nDescriptors D.1.1 [Programming Techniques ]: Applicative (Func\u00adtional) Programming General Terms Algorithms \n Keywords parser combinators, breadth-.rst search, Polish representa\u00adtion, ambiguous grammars, online \nresults, GLR parsing 1. INTRODUCTION A basic parser combinator library can be formulated in a few lines \n(see .gure 1, [1]). We use the interface described in [4]: p <*> q parses p followed by q,where p returns \na func\u00adtion that is applied to the result of q in order to con\u00adstruct the result of the sequential composition \n p <|> q parses either p or q  pSucceed v is a parser that immediately succeeds with\u00adout accepting \nany input and returns v  Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. ICFP 03, August 25 29, 2003, Uppsala, Sweden. Copyright 2003 ACM 1-58113-756-7/03/0008 \n...$5.00. pFail is the unit of <|>  pSym s is the parser that recognizes the symbol s and returns this \ns  f <$> p applies f to the result of parsing p,  p <* q parses a p and recognizes a q and returns \njust the result of p,and  c <$ p parses a p but just returns c.  Note that this is not a monadic interface. \nSuch simple libraries thus far always have had some short\u00adcomings: 1. Backtracking implementations based \non the list of suc\u00adcesses method keep a reference to the full sequence of input tokens, until it has \nbecome clear that no further alternatives will be found. 2. Parsers only start producing a result once \nthe complete input has been examined, and thus do not exhibit on\u00adline behaviour. 3. Simple backtracking \nimplementations are grossly in\u00ade.cient when dealing with ambiguous grammars; for each possible parse \nfor a part of the text, the rest of the text is parsed once. This becomes immediately clear if we look \nat the code for the sequential composition of two parsers: p <*> q. If the parser p can succeed in several \ndi.erent ways by consuming the same pre.x of the input, the parser q is called once for each of those \nsuccessful parses of p, with the same remaining input as argument.  As a consequence of the .rst two \npoints the constructed result and the initial input are both present in memory once a complete parse \nhas been found. This is highly undesirable if we process input that represents a long list of similar \nitems such as a bibtex .le, or when we describe a lexical scanner that returns a list of input tokens. \nIn such situations we do not want .rst read and recognize a complete input .le before producing any output: \noutput should be produced as soon as an individual element has been recognized. If the grammar is LL(1), \nas required by the parsers de\u00adscribed by Swierstra and Duponcheel [6], this problem does not occur, since \nit is a property of the grammar that once a successful alternative is taken, backtracking will not .nd \nother possible parses and can thus be avoided; as conse\u00adquence references to the input have not to be \npreserved and in.xl 3 <|> in.xl 4 <*>, <*, <$, <$> type Parser a = String . [(a, String)] (<|>) :: Parser \na . Parser a . Parser a (<*>) :: Parser (b . a) . Parser b . Parser a pSucceed :: a . Parser a pFail \n:: Parser a pSym :: Char . Parser a pSucceed v inp =[(v, inp)] pFail =[] (p <|> q) inp = pinp + qinp \n(p <*> q) inp =[(fa, rr) | (f , r) . pinp , (a, rr) . qr ] pSym a inp = case inp of (s : ss) . if a = \ns then [(s, ss)] else [] [] . [] f <$> q = pSucceed f <*> q p <* q = const <$> p <*> q f <$ q = const \nf <$> q Figure 1: Backtracking implementation the constructed result can be returned as it is being pro\u00adduced. \nFor non LL(1) grammars the problem can be par\u00adtially cured by assuming that by default no backtracking \nhas to take place, and to require explicit annotation in the code where a longer look-ahead is needed \n(the try construct in the Parsec library [3])1 . This works well for grammars that are (almost) in the \nLL(1) class, provided the programmer of the parser indicates explicitly at which points the LL(1) assumption \ndoes not hold. As with placing cut clauses in a Prolog program, this requires a grammar analysis from \nthe side of the user of the library. Sometimes this is easily done, but it can also be a complicated \nand error prone process, and is in any case something the writer of the parser has to be continuously \naware of. In an earlier paper ([4]) we have explained how we can implement a parsing algorithm that performs \na breadth\u00ad.rst instead of a depth-.rst search for a complete parse, and sequentially accesses the input \nstream; it furthermore removes the LL(1) restrictions and works with unbounded look-ahead. This completely \ncures the .rst problem men\u00adtioned above, without any annotations provided by the pro\u00adgrammer nor a need \nto understand how the parsing process proceeds internally, but it introduces the second problem mentioned. \nIn this paper we show how to cure the second and third problem mentioned: the build-up of a complete \nresult in memory and the ine.cient handling of ambiguous gram\u00admars. The only di.erence that remains from \nvery general parsing processes for context-free languages such as GLR ([7]) is that, basically using \na top-down parsing method, we 1Unfortunately parsers constructed by the Parsec library do not exhibit \nonline behaviour due to their monadic formula\u00adtion. cannot handle left recursive grammars and left-factorization \nmay be needed in certain situations to improve performance. We do not see this as a problem at all, since \nin practice uses of left recursion usually can be nicely captured using special combinators for recognizing \nlist like structures. The key idea in this paper is a new data type that en\u00adables us to represent any \nvalue in a linear way (i.e. as a sequence of fragments), thus enabling us to intersperse the result value \nwith information about progress of the parsing process. This type is introduced in section 2. In section \n3 we start by repeating the way we construct breadth-.rst recog\u00adnizers, and subsequently extend them \nwith an incremental construction of the parsing result. In section 4 we show that the advantages that \nare provided by monadic parser inter\u00adfaces are not lost, and that it is still possible to parameterize \nparsers with values stemming from earlier recognized parts of the input. In section 5 we extend the data \ntype that we have introduced so it becomes possible to parse ambiguous grammars e.ciently, and in section \n6 we discuss some opti\u00admizations to the code given, that were left out for the sake of presentation. \nIn section 7 we discuss some practical as\u00adpects of a library built on the ideas presented in this paper, \nwhereas in 8 we re.ect on what we have done and mention some further applications of the ideas presented. \n 2. THE POLISH REPRESENTATION While parsing we will recognize the fragments of the value that witnesses \na complete and successful parse in a sequen\u00adtial way, so for a moment we forget about parsing and focus \non the question whether we can .nd a data type that is suitable for representing such a linearly fragmented \nvalue. In order to answer this question we let ourselves be inspired by the way values are represented \nin Polish expressions. 2.1 The Problem Polish notation, in which we write operators before their operands, \nis a way of writing expressions unambiguously in a linear way, i.e. without brackets. For example, 1 \n+ 2 \u00d7 3is written as + 1 \u00d7 23, and sin x \u00d7 p/4 is written \u00d7 sin x/p 4. One can interpret Polish by inspecting \nthe operator at the beginning of the expression, evaluating the correct number of arguments, and then \napplying the operator to the argu\u00adment values. To do so correctly, one must know the arity of each op\u00aderator, \nwhich could be problematic if we allow operators to be arbitrary functions. But we can apply the usual \ntrick of currying all functions, and taking function application to be the only operator, with functions \nthus becoming ordinary values. Writing function application as @ , 1 + 2 is now written as @ @+1 2. The \nproblem we consider in this paper is the design of a fully typed representation and interpreter for Polish \nexpres\u00adsions in Haskell. The essence of a Polish representation is its linear nature, but unfortunately \nwe cannot use ordinary lists since we require the elements to be of di.erent types. More speci.cally, \nwe are looking for a data type with con\u00adstructors App and Val such that we can represent the ex\u00adpression \nabove by: App (App (Val (+) (Val 1(Val 2 .)))) Since we know from the syntax of Polish expressions when \nan expression is complete the . at the end of the list is unim\u00adportant. We will from now on write such \nlists as functions, so that we can use function composition for concatenation, and write instead for \nthe list above: App \u00b7App \u00b7Val (+) \u00b7Val 1 \u00b7Val 2 We will aim to write an interpreter such that interpret \n(App \u00b7App \u00b7Val (+) \u00b7Val 1 \u00b7Val 2) =3 This problem is interesting because Polish expressions must be able \nto contain values of many di.erent Haskell types. In fact, we do not believe the Haskell 98 type system \nis powerful enough to allow this, but with the extensions in the current versions of Hugs and GHC, it \nis. The reader may like to try to solve the problem unaided, before reading further: it is quite a challenge! \n 2.2 A Simpler Problem If we cannot immediately see how to represent Polish ex\u00adpressions in Haskell, \nwe can consider the simpler problem of representing ordinary expressions. We may try to de.ne atype Expr \nwith a binary constructor App and a unary con\u00adstructor Val, so that 1+2 is represented by App (App (Val \n(+)) (Val 1)) (Val 2), for example. Of course, the type of our representation should guarantee that no \ntype errors arise during expression evaluation. To ensure that we only represent well-typed expressions, \nwe had better make the type that an expression evaluates to into a part of its own type. That is, we \nde.ne a type Expr a representing expressions that evaluate to a value of type a. Now it is clear what \nthe types of the constructors should be: Val :: a .Expr a App :: Expr (b .a) .Expr b .Expr a This suggests \nthe type de.nition data Expr a = Val a |App (Expr (b .a)) (Expr b) but here the variable b is unbound. \nFortunately, current Haskell extensions permit us to quantify type variables ex\u00adistentially in type de.nitions: \nwe can say that an App ex\u00adpression contains an Expr (b .a)and an Expr b for some type b, but this type \nmay vary from App node to App node. Thus we write the type de.nition as2 data Expr a = Val a |.b. App \n(Expr (b .a)) (Expr b) which introduces the constructors with exactly the types we want. An evaluator \nfor such expressions is easy to write: eval :: Expr a .a eval (Val a)= a eval (App e1 e2 )= let f = eval \ne1 a = eval e2 in fa We remark only that this de.nition uses polymorphic re\u00adcursion, which is allowed \nin Haskell provided that a type signature is given explicitly. 2The keyword for this construct used to \nbe forall, but GHC nowadays also accepts exists. 2.3 The Polish Type Returning to Polish expressions, \nit is tempting by analogy to de.ne a type Polish a, representing Polish expressions of type a, but a \nmoment s re.ection shows this will not be enough. In the expression App \u00b7Val (const 1) \u00b7Val 2, for example3 \n, the Polish subexpression Val (const 1) \u00b7Val 2 after the initial App represents two values, namely const \n1 and 2, of di.erent types. In general, a Polish expression may represent arbitrarily many values, and \ntherefore we cannot expect it to be possible to give the type Polish just a single type parameter. Our \nsolution is to give the Polish type an additional pa\u00adrameter, representing the type of the part at the \nright hand side of a \u00b7 . Thus the expression above will have the type s .Polish Int s, while the subexpression \nVal (const 1) \u00b7 Val 2 will have the type s .Polish (b .Int)(Polish Int s). We need to assign the constructors \nthe following types: Val :: a .Polish b s .Polish a (Polish b s) App :: Polish (b .a)(Polish b s) .Polish \na s Notice that these types account for the number of values the expression represents, which is increased \nby Val and decreased by App. Once again, we can handle the type variable b in the type of App, which \ndoes not appear in the type of its result, by an existential quanti.cation. But the type of Val presents \na dif\u00adferent problem: its result type is not of the form Polish a s, which means that we cannot directly \ngive Val this type via a data type de.nition. Fortunately, the natural type above is an instance of Val \n:: a .s .Polishas which does have a result type of the right form, so we will simply take this to be \nthe type of Val instead, and de.ne the following nested data type: data Polish a s = Val a s |.b. App \n(Polish (b .a)(Polish b s)) Now indeed, terms of the sort we considered in the intro\u00adduction are well-typed. \nFor example, App \u00b7App \u00b7Val (+) \u00b7Val 1 \u00b7Val 2 :: s .Polish Int s 2.4 A Polish Interpreter Our second \ngoal is an interpreter for Polish expressions, that is, a function interpret :: (s .Polish a s) .a But \nthis type does not take into account that some Polish expressions represent many values for example, \nthe Polish expression following an App. We therefore generalize to a function eval, which returns both \nthe value of the .rst com\u00adplete sub-expression, and the unconsumed part of the Polish input: eval :: \nPolish a s .(a, s) We can then de.ne interpret v =(fst \u00b7eval)(v ()) 3Where const x is a constant function \nreturning x The eval function is now straightforward to de.ne: eval :: Polish a s . (a, s) eval (Val \na s)=(a, s) eval (App s)= let (f , s .)= eval s (a, s ..)= eval s. in (fa, s ..) Once again, polymorphic \nrecursion is needed to type this de.nition, so the type signature cannot be omitted. Since Haskell s \nlet-expression binds lazily, s . will not be evaluated if f is a lazy function for example: interpret \n(App \u00b7 Val (const 1) \u00b7 Val .) = 1 This is exactly what we are looking for in an online parser, since \nit means that we can start evaluating a Polish expres\u00adsion, and even construct a part of its result, \nbefore the en\u00adtire expression has become available. It will be this property that facilitates the online \nbehaviour of the parser combina\u00adtor library that we will introduce now.  3. PARSING POLISH 3.1 Motivation \nAs we mentioned in the introduction, the design of the Polish type arose as the result of an attempt \nto de.ne a parser combinator library that constructs parsers that re\u00adturn their result in an online way; \nthat is, as soon as it can be unambiguously decided that some value will be used to construct the .nal \nresult it becomes available to the callee of the parser, just as a foldr may already return part of its \nresult when processing a list of elements. We also want to avoid a problem in many parsing libraries \nrelated to choice. Every parser must be able to choose be\u00adtween alternative possible parses for the same \ninput for example, between parsing an addition and parsing a multi\u00adplication. Normally one parse fails \nquickly, since they ac\u00adcept quite di.erent constructs. But in backtracking parsers this choice operation \nresults in a space leak. The prob\u00adlem occurs when the .rst alternative to be tried actually succeeds, \nand therefore consumes a large amount of input, but the second alternative is retained as a backup. To \nre\u00adtain the possibility of constructing the second parse, the entire input must be kept available even \nthough the sec\u00adond parse in all probability would fail quickly were it to be tried. Ever since Wadler \n[8], backtracking parsing libraries have included more or less ad hoc solutions to this problem, permitting \nthe second parse to be discarded when the .rst one commits to its result. These solutions unfortunately \nlead to unmodular code: when we write the .rst alternative, we must decide when to commit based on our \nknowledge of all its alternatives. When the grammar is later modi.ed, such parsers have a tendency to \nstop working. One of the consequences of taking the backtracking (or depth-.rst) approach is that it \nis only after the parsing pro\u00adcess has been completed that the result becomes available; the information \nabout how the result was reached precedes the actual result. One moment of re.ection however tells us \nthat from a parsing point of view there is nothing which prevents us from already returning that part \nof the result for which no parser threads are competing anymore. So as soon as we are no longer interested \nin look-ahead infor\u00admation we can produce the result recognized thus far. This will usually be after \ninspecting only a few input tokens. rSucceed = R (.kinput . kinput) rFail = R (.kinput . Fail) Rp <*> \nRq = R (.kinput . p (qk) input) Rp <|> Rq = R (.kinput . pk input best qkinput ) pSym a = R (.kinput \n. case input of (s : ss) . if a = s then Shift (kss) else Fail [] . Fail ) Fail best p = p q best \n Fail = q Done best Done = error \"ambiguous grammar\" Done best q = Done p best Done = Done (Shift \nv) best (Shift w)= Shift (v best w) recognize (Rr) input = rDone input Figure 2: The recognizing combinators \nThe question that arises now is how to combine the two useful properties: not unnecessarily retaining \nreferences to the input, and returning parts of the result as soon as pos\u00adsible. The basic idea is that \nthe parser returns a interleaving of two kinds of sequences: a sequence of fragments constituting the \nresult we are interested in, and a trace of the parsing process itself that is used for the breadth-.rst \nsearch. 3.2 Recognisers Let us for a moment postpone the question of how a parser constructs a result, \nand focus on recognizers instead, where a recognizer is a degenerate parser that does not build up value. \nOur recognizers will just indicate their progress, and .nally their success or failure by returning a \nvalue of type: data Progress = Shift Progress | Done | Fail in which Shift represents the successful \nrecognition of a sin\u00adgle input token, Fail indicates a dead end, and Done signals the completion of a \nsuccessful parse. A recognizer take two arguments: a continuation for rec\u00adognizing the rest of the input \nonce once this recognizer has succeeded, and the input of which a pre.x has to be recog\u00adnized. For the \nsake of presentation we will assume that the input is a sequence of characters: newtype Rec = R (String \n. Progress) . (String . Progress) We can now de.ne the combinators for sequential com\u00adposition <*>, alternative \ncomposition <|>, the basic always successful recognizer rSucceed , the always failing recognizer rFail, \nand a function for constructing a single-symbol rec\u00adognizer rSym. They are all given in .gure 2. The \nchoice between two alternatives is implemented by the function best (.gure 2), that traverses the two \nalterna\u00adtives in a synchronized way: when both of its alternatives present a Shift, the function produces \none while removing the Shift s at the same time from both alternatives. If ei\u00adther of its alternatives \npresents a Done this indicates we have found a successful parse. In case both alternatives present Done \nat thesame timewehavefound more than one successful parse, and thus have been parsing with an ambiguous \ngrammar. Notice that a failing alternative can be discarded altogether as soon as it presents its Fail \nstep, so that a recognizer built using <|> will ultimately return either one of its branches, provided \nthe grammar is not am\u00adbiguous. Note however that the function best is looking only as far as needed into \nthe progress information in or\u00adder to decide which alternative to choose; thus the strategy we follow \ndeals with unbounded look-ahead, and only looks ahead when needed. 3.3 Parsers The next step is to extend \nthe recognizers to real parsers, that return a parsing result. The essence of this paper is that for \nthe result type of a parser we de.ne a data type Steps, that combines both the Polish and Progress data \ntypes (.g\u00adure 3); our parsers deliver information both regarding their progress, just like our recognizers, \nand their result, expressed in Polish. If we think of the Progress type as representing a sequence of \nrecognition steps, and the Polish type as a sequence of applications and values, then the Steps type \nrepresents an interleaving of these two sequences. Because of the freedom we will use in changing an \ninterleaving it is no longer guaranteed that the Done constructor marks the end of a sequence. So we \nhave slightly changed its introduc\u00adtion: it can now contain further steps. In the function parse (.gure \n3) we use this facility to pass back the unused part of the input in the result. The reason for linearising \nthe output of a parser in Polish, is that it can be interleaved with the recognition trace. So our .rst \nattempt for the type representing the new parsers is: newtype Par a = P (.w. (String . w) . (String .Steps \na w) ) unP (Pp)= p In .gure 3 we also de.ne an evaluation function evalSteps for Steps which just discards \nthe recognition trace and oth\u00aderwise behaves like eval. The de.nition of a small library of basic parsing \ncombina\u00adtors appears in .gure 4 (apart from the new function best , to which we return below). Using \nthese de.nitions we may construct a parser for an addition expression, using a very simple parser for \nintegers: pPlus =(+) <$> pInt <* pSym + <*> pInt pInt =0 <$ pSym 0 <|> ... <|> 9 <$ pSym 9 data Steps \na s = Val as |.b. App (Steps (b .a)(Steps b s)) | Shift (Steps a s) | Done (Steps a s) | Fail evalSteps \n:: Steps a s .(a,s) evalSteps (Vala s)=(a,s) evalSteps (App s)= let (f ,s .)= evalSteps s (a,s ..)= \nevalSteps s. in (fa,s evalSteps (Shift v)= evalSteps v evalSteps (Done v)= evalSteps v evalSteps Fail \n= error \"wrong input\" Figure 3: The data type Steps pSucceed :: a .Par a pFail :: Par a pSym :: Char \n.Par Char pSucceed a = P (Val a\u00b7) pFail = P (. .Fail) Pp <*> Pq = P ((App\u00b7) \u00b7p \u00b7q) Pp <|> Pq = P (.kinput \n.(pk input) best (qk input) ) pSym a = P (.kinput . case input of (s : ss) .if a =s then (Shift \u00b7Val \ns \u00b7k) ss else Fail [] .Fail ) parse p input = let (result,rest )= evalSteps (p (.rest .Done (Val rest \n())) input ) in (result,fst \u00b7evalSteps $ rest) Figure 4: The parsing combinators The result of parsing \n1 + 2 with this parser is: App \u00b7 App \u00b7 App \u00b7 Val const \u00b7 App \u00b7 Val (+) \u00b7 Shift \u00b7 App \u00b7 Val (const 1) \n\u00b7 Val 1 \u00b7 Shift \u00b7 Val + \u00b7 Shift \u00b7 App \u00b7 Val (const 2) \u00b7 Val 2 Done which, when we evaluate it, yields \nconst ((+) (const 1 1 )) + (const 2 2 ), or (after simpli.cation) 1 + 2, that is, 3. Now suppose that \nwe try to parse the same input, using an analogous parser for multiplications instead. This results in \na sequence of steps terminated by Fail: App \u00b7 App \u00b7 App \u00b7 Val const \u00b7 App \u00b7 Val (*) \u00b7 Shift \u00b7 App \u00b7 Val \n(const 1) \u00b7 Val 1 \u00b7 Fail Now, a parser which parses either an addition or a mul\u00adtiplication must choose \nbetween these parses, and we can see immediately that this is more complicated than in the case of recognizers. \nThe choice must be made based on the progress information embedded in the sequence, and indeed cannot \nbemadeuntil thesecond Shift has been produced, but this information is preceded in each parse by Polish \nop\u00aderations for creating the parse result. Moreover, since the parse result di.ers between the two parses, \nwe clearly cannot start returning it until we know which parse will eventually be chosen. Fortunately, \nwe can freely change the interleaving of the Polish operations and the recognition trace as long as we \ndo not reorder either subsequence, since they are essentially independent of each other. In particular, \nwe can move the .rst progress step to the front of a sequence, thus making it possible to make a progress \ndecision. We therefore de\u00ad.ne a function getProgress that moves the .rst element of the embedded progress \ntrace to the head of the interleaved sequence (or formulated di.erently, pushes the value con\u00adstructing \nelements behind the .rst progress step), returning a parse with a top constructor that is either Shift, \nFail or Done.We de.ne the best function on parsers to convert its arguments into this form, if necessary, \nand de.ne some new alternatives for the function best . Fail best p = p q best Fail = q Done best \nDone = error \"ambiguous grammar\" Done a best q = Done a p best Done a = Done a Shift v best Shift \nw = Shift (v best w) p best q = getProgress id p best getProgress id q This de.nition is closely analogous \nto the de.nition for rec\u00adognizers. The getProgress function traverses its input searching for a step, \naccumulating the step-free part of its input in its .rst parameter as a function, and then reinserts \nthe accumulated information after the .rst progress step (we will make sure that every parse ends with \na Done step): getProgress f (Vala s)= getProgress (f \u00b7 Val a ) s getProgress f (App s)= getProgress (f \n\u00b7 App ) s getProgress f (Done p)= Done (fp) getProgress f (Shift s)= Shift (fs) getProgress f (Fail )= \nFail Unfortunately, this straightforward de.nition of getProgress does not type-check! The reason is \nthat, in the .rst equa\u00adtion, we apply getProgress to s of type s a type variable. The problem is that \nthe second component of a Val need not be of Steps type, so we cannot apply getProgress to it. Our solution \nis to overload getProgress instead; so we de\u00adclare class HasProgress st where getProgress :: (st . Steps \nx y) . st . Steps x y and make the above de.nition the instance at type Steps: instance HasProgress s \n. HasProgress (Steps a s) where ...as before... This instance declaration de.nes HasProgress (Steps a \ns)in terms of HasProgress s; we also need a base case , which we can take to be: instance HasProgress \n() where getProgress f () = Fail Provided we see to it that top-level parsers produce a Steps a () for \nsome a, we will now be able to apply getProgress to all intermediate parses. The introduction of this \nclass now enforces a slight adap\u00adtation of our parser type: newtype Par a = P (.w. (HasProgress w . (String \n. w) . String . Steps a w) ) With this de.nition, the .rst version of our simple Polish parsing library \nis complete, and can be used to write online parsers which do not leak space.  4. MONADIC INTERFACE \nOne of the advantages of a monadic interface ([2]) over the interface chosen here is that one can parameterize \nparsers on the results of earlier successful parsers. Fortunately it is straightforward to make Parser \nalso an instance of the Monad class. We proceed as follows. Let us assume that parser p is of type Par \na,and that q is of type a . Par b. Suppose we know the result a of the parser p that serves as the left \noperand in a monadic composition, then the result of a parser P (.kinput . p (qak) input) will be of \ntype Steps a (Steps b s). So all we now have to do is to de.ne a function getVal , that makes it possible \nto extract the value of type a from this sequence. getVal :: Steps a (Steps b s) . (a,Steps b s) getVal \n(Vala s)=(a,s) getVal (App s)= let (a,s .)= getVal s (f ,s ..)= getVal s. in (fa,s ..) getVal (Shift \nv)= let (a,r)= getVal v in (a,Shift r) getVal (Done v)= let (a,r)= getVal v in (a,Done r) getVal (Fail) \n=(.,Fail) One can see getVal as the counterpart of getProgress . Whereas the latter manipulates the sequence \nin such a way that it starts with progress information, it is getVal that makes the .rst value represented \nin the sequence available, while keeping the progress information. In order to avoid further typing problems \nwe have given getVal atype that is somewhat less general than one might expect, in the sense that we \nrequire the second parameter of the Steps argument to be a Steps again. This is not unreasonable; apparently \nwe are not only interested in the embedded value, but we also want to keep the steps, and thus we need \na place to return them too. The instance de.nition for the monad now becomes: instance Monad (Parser \ns) where return a = pSucceed a Pp > = q = P (.kinput . let (a,ps qres)= getVal (p (unP (qa) k) input) \nin ps qres ) At .rst sight this may look confusing, since part of the parsing result is used for the \nconstruction of the parser p (unP (qa) k) itself. Note however that all the informa\u00adtion in the sequence \nthat is needed for this value is produced by the .rst parser, and thus can be freely used before the \nsecond parser is called, and thus before the second parser has to be constructed! Note also that progress \ninformation stemming from the use of p is also immediately available in ps qres, even before the value \nresulting from the call to p has become fully available. Lazy evaluation saves our day again! The value \nps qres contains the progress information from p, together with the progress information and result from \nqa (and of course also elements stemming from k). Notice that if the parse p fails then the value a is \nprobably unde.ned. This does not do any harm because the result of q will never be inspected, being shielded \nby a Fail. One may wonder what should be the interpretation of a parser such as: pSym 1 > = const (return \n1). Should it immediately return the value 1, or should it only do so provided it has .rst recognized \na 1; it is clear from the def\u00adinitions above that we chosen for the latter interpretation. Note that \nwe do not recommend using the monadic in\u00adterface without good reason, since the parsers it constructs \ndo not have online behaviour, for an essential reason no part of the result of a bind can be produced \nuntil at least the .rst operand has completed parsing. One should only use this interface when there \nis a good reason to param\u00adeterize a parser on a previously parsed value. One good example is a parser \nthat recognizes expressions based on op\u00aderator priorities: .rst we recognize the priority de.nitions, \nand bind them to a function that subsequently parses ex\u00adpressions ([5]). Another nice example is the \nrecognition of XML-like structures: pXML = do t . pOpenTag Tag t <$> pMany pXML <* pCloseTag t data XML \n= Tag t [XML] pMany p =(:) <$> p <*> pMany p <|> pSucceed [] Finally some might wonder whether the monadic \nlaw p> = return = p holds. In a strict sense it does not since the online behaviour of the left hand \nside is di.erent from that in the right hand side. They are however equivalent with respect to inspection \nusing getVal and getProgress. 5. PARSING AMBIGUOUS GRAMMARS Standard backtracking implementations implicitly \nproduce a search tree of which the leaves represent possible solutions and failures. Such a tree may \nhowever contain many identi\u00adcal subtrees, and as such may be more expensive to evaluate than strictly \nneeded. So the question arises whether we can share the computations represented by such subtrees, thus \ngetting a DAG-like structure. In the context of parsing this situation arises if we deal with ambiguous \ngrammars: a spe\u00adci.c segment of input may be recognized in many di.erent ways, but the state we are in \nafter all such successful recogni\u00adtions is the same. Can we can extend our library to recognize such \nsituations, and prevent costly recomputations? The answer to this question will be partly a yes, but \nbe\u00adfore presenting our solution we look into the type of an am\u00adbiguous parser. The list of successes \napproach naturally lends itself to dealing with ambiguous grammars, because of the chosen encoding: an \nempty list denotes failure, a sin\u00adgleton list a single success and a longer list more than one successful \nparse. So the fact that we return a list value automatically handles the situation in which we deal with \nambiguous grammars. Our parsers however always return a single result, and as long as we do not know \nyet what this single result will be, postpone the point at which they return (part of) any value. So \nwe make essential use of the fact that eventually there will always exactly be one successful path from \nthe root to a leaf in the search tree. So we propose the introduction of a new parser combinator amb \nthat indicates that a parser may return more than one result: amb :: Par a . Par [a ] The essence of \nan ambiguous parse is that several paral\u00adlel parsing threads terminate at the same time.Since we perform \na breadth-.rst execution of these threads this point is easily recognized, provided we mark the points \nin the sequence where a parse for the ambiguous nontermi\u00adnal is completed. In order to be able to do \nso we intro\u00adduce one more alternative for the data type Steps, called RS. This alternative corresponds \nclosely to a shift-reduce state in a bottom-up parser, and contains information about sequences that \nrepresent complete parses (reduce), and se\u00adquences corresponding to parses that extend beyond this point \n(shift): data Steps a r = ...as before ... | RS [Steps a r ](Steps a r) We .rst discuss how to extend \nthe function best .Since the RS essentially is a progress indicator, we decide to deal with it by adding \npatterns to the de.nition of best directly and not to leave this to getProgress somehow. The extended \nbest best :: HasProgress r . Steps a r . Steps a r . Steps a r ... Shift v best Shift w = Shift (v best \n w) RSas ac best RSbs bc = RS (as + bs) (ac best bc) RSas ac best r@(Shift )= RS as (ac best r) l@(Shift \n) best RSbs bc = RS bs (l best bc) p best q = getProgress id p best getProgress id q instance HasProgress \ns . HasProgress (Steps a s) ... getProgress f (RS r s)= RS (mapf r)(fs) Figure 5: The extended function \nbest is given in .gure 5. The .rst line represents the already ex\u00adisting case in which both alternatives \nhave not completed yet, and can make progress by shifting a symbol. The next case, with an RS pattern \nat both sides, corresponds to a reduce-reduce con.ict , i.e. a join-point where several am\u00adbiguous parses \nmeet again. We do not see the con.ict as a con.ict however since we want to deal with ambiguous gram\u00admars \nexplicitly, and thus just store both results in the .rst component of the resulting RS. Notethatitis \nanessential invariant of our approach that if two RS meet each other in acallto best they correspond \nto the same point in the input, since they are both preceded by an equal number of Shift steps! The second \ncomponents of both arguments may con\u00adtain sequences corresponding to shift actions at this point of the \ninput, so we choose between these shifting sequences with another call to best. The next two alternatives \ncorre\u00adspond to a shift-reduce state, for which we compare the shift side with the other shift sequence \nincorporated in the RS side. Furthermore we extend the de.nition of getProgress for the RS case, by storing \nthe f -represented value steps in the components. It seems that we are done now, but unfortunately we \nhave still some more work to do, since we now have RS con\u00adstructors left in our sequences. Since we allow \nambiguous nonterminals to occur inside other ambiguous nonterminals we have to make sure that the RS \nmarks corresponding to di.erent non-terminals do not get mixed up. We solve this problem by introducing \nfor each introduction of an RS mark a process unRS (.gure 6), that removes these marks again. This makes \neverything dealing with ambiguity invis\u00adible outside the non-terminal, besides the fact that its type \nhas changed. Now we can give the de.nition of amb: amb (Pp) = P (.kinput . unRS id (p (.inp . RS [kinp \n] Fail) input) ) The last alternative of the function unRS is the most inter\u00adesting one. The ls argument \nnow contains a list of sequences, all starting with Val and App steps making up the value we are interested \nin, and a common tail that corresponds to the steps taken afterwards. The snd (head res) recovers one \nof these common tails and uses this to build a new sequence that contains at the head a Val occurrence \nwith the values Although we could have made a separate class for overload\u00ading the function unRS we have \ndecided to extend the class HasProgress with an extra function. Notice that when the function best is \ncalled in the last alternative of unRS we know what te type of the tail is, but Haskell doesn t; so we \nhad to place a constraint on the function unRS for keep\u00ading track of this. class HasProgress st where \ngetProgress :: (st . Steps x y) . st . Steps x y unRS :: HasProgress y . (st . Steps x y) . st . Steps \n[x ] y instance HasProgress r . HasProgress (Steps a r) where ... unRS f (Val a r)= unRS ( f \u00b7 Val a) \nr unRS f (App r)= unRS ( f \u00b7 App ) r unRS f (Shift r)= Shift ( unRSf r) unRS f (Done r)= error \"incorrect \nprogram\" unRS f Fail = Fail unRS f (RS lsr) = let res = map (evalSteps \u00b7 f ) ls in Val (map fst res)(snd \n(head res)) best unRS f r instance HasRS () where ... unRS = . Figure 6: Removing RS marks found for \nthe ambiguous parser and the steps produced by the continuation. Of course this new sequence now will \nhave to compete with possible other, still active threads, for this nonterminal. Of course the RS mark \nalso has to be removed from this alternative. One might wonder whether this solution is really online. \nThe answer is that it is not, but also that it cannot be online. The online property essentially depends \non the fact that we may produce a result once we know that no other result will be produced, i.e. we \nhave one active thread left. But in the case of an ambiguous grammar we only know that this is the caseoncewehave \nreached the RS mark: in a parser amb (p <*> q) it may be the case that the ambiguity actually stems from \nthe q, so the fact that we have only one thread while working on the p does not bring us very much. We \n.nally notice that when constructing the RS step in the continuation we expect the continuation k to \nreturn some Steps b r, so we will have to specialize the type of Par abit: newtype Par a = P (.br. HasProgress \nr . (String . Steps b r) . String . Steps a (Steps b r) ) 6. SOME OPTIMIZATIONS Thus far we have not \npaid attention yet to the e.ciency of our algorithms; we have placed emphasis on the presentation instead. \nin this section we show some improvements that may be necessary for a really useful library. 6.1 Combining \nsteps There is an easy optimisation which can be quite signi.\u00adcant if the function best has to compare \nseveral steps before being able to decide; i.e. in those cases where we need a signi.cant look-ahead. \nWhen getProgress traverses the progress-free part of a parser, is accumulates the information found there, \nand rein\u00adserts this after the .rst encountered step. If getProgress is subsequently applied again to \nthe constructed result, it will traverse this progress-free pre.x again, which is clearly wasteful. The \nwaste can be avoided by introducing a new alternative of Steps, representing a suspended getProgress \ncomputation: data Steps a s = ...as before ... |.bx. Mix (Steps b x .Steps a s)(Steps b x) Mixf s represents \nthe sequence fs, withaninvariant that f only adds progress-free steps. Now we can modify getProgress \nto construct a suspension Mixf s asoon as it encounters its .rst progress step, and to continue directly \nfrom that point on if applied to the same sequence again. The new cases are: getProgress f (Done p)= \nDone (Mixf p) getProgress f (Shift s)= Shift (Mixf s) getProgress f (Mixg s)= getProgress (f \u00b7g) s Other \nfunctions on Steps just treat Mixf s as fs. 6.2 Special cases The sequences constructed contain many \nfrequently oc\u00adcurring subsequences that, if they are represented by special alternatives, can reduce \nthe length of the sequence consid\u00aderably. We mention a few that may be introduced, but we will not discuss \nthe extensions to the functions involved since they are all straightforward. To start with we observe \nthat quite often a Shift is imme\u00addiately followed by a Val, so it makes good sense to have a special \nkind of step ShiftVal, that acts both as a shift and as a Val. As we can see from the examples given \nthere are many occurrences of <$> and <$ in our parsers. For these we may introduce a special step kind: \ndata Steps a r = ... | ShiftVal a r |.b. AppVal (b .a)(Steps b r) f <$> q =(AppVal f \u00b7) \u00b7q f <$ q =(AppVal \n(const f )\u00b7) \u00b7q Similarly, we notice that in many cases we are not inter\u00adested in the result of the parser, \nand just want to recognize something. In such cases it is wasteful to insert the values into the sequence, \ntogether with a function which removes them from the result. An e.cient solution is to tuple ev\u00adery parser \n(constructor P) with a recognizer (constructor R) that recognizes the same sequence of input tokens but \ndoes not return a result; so instead of constructing parsers out of parsers and recognizers out of recognizers \nwe now construct pairs of a parser and a recognizer out of such pairs. type PR a =(Par a, Rec) f <$> \n(Pp, Rr)=(P ((AppVal f \u00b7) \u00b7p) ,Rr ) f <$ (Pp, Rr)=(P ((Val f \u00b7) \u00b7r) ,Rr ) (Ppp,Rpr) <*> (Pqp, Rqr)=(P \n((App\u00b7) \u00b7pp \u00b7qp) ,R ( pr \u00b7qr) ) (Ppp,Rpr) <* (Pqp, Rqr)=(P ( pp \u00b7qr) ,R ( pr \u00b7qr) ) Lazy evaluation \nwill make that only parsers that are actually used are constructed.  7. PRACTICAL POLISH The techniques \ndescribed in this paper have been included, although in a heavily optimized way, in a parsing library, \ntogether with many other libraries and tools4 . This combi\u00adnator library ([4]) produces parsers that \nparse at about half the speed of o.-line generated parsers, while also preparing for and performing full \nerror repair and error reporting. This repair process was addressed by Swierstra and Azero ([5, 4]), \nwho describe a parsing strategy in which an error repairing parser returns a sequence of steps that represent \na trace of progress of the parsing process and the taken repair actions. The corresponding parsing result \nwas built up in an accumulating parameter, and is appended to the parsing trace when a successful parse \nhas been found. Hence that solution did not have online behaviour. The basic idea of the error repair \nis that a parser doesn t just fail when a sym\u00adbol cannot be recognized, it proceeds in parallel along \ntwo alternative routes: insert the symbol expected, and delete the current input symbol and try again. \nOnce we associate a speci.c cost with each insertion and deletion we can use a more general version of \nour function best to select between all the di.erent possible corrections, according to whatever strategy \none might wish to express. One of the nice aspects of the introduction of the data type Steps is that \nnothing prevents us from incorporating even more information in the sequence by adding extra alternatives, \nprovided they once again form an orthogonal subsequence whose elements may be freely shifted back and \nforth in the main sequence, pro\u00advided their mutual order does not change. We use this for getting tracing \ninformation out of the parsing process and for constructing error messages. 8. OTHER APPLICATIONS We \nhave derived a small parsing library using a number of orthogonal concepts. Looking back at the code \nconstructed we can see three di.erent elements: 1. a data type Progress with a function best 2. a data \ntype Steps,withaclass HasProgress containing a function getProgress (and possibly unRS) 3. a set of \nparser combinators generating sequences con\u00adsisting of the .rst two elements  4http://cvs.cs.uu.nl/cgi-bin/cvsweb.cgi/uust/INSTALL.html \nWe notice that the .rst two elements are of independent interest, and that there is nothing in them that \nis particu\u00adlarly connected to parsing. Essentially elements of the data type Progress represent search \ntrees, with Shift applications forming the edges, Done and Fail as leaves, and calls to best for forming \nbranching nodes and representing the breadth\u00ad.rst searching process. A path in such a tree may further\u00admore \ncontain a value, represented as a sequence of fragments interleaved with Shift s. The single role of \nthe parser combinators is to generate this branching tree, but we may easily envision other appli\u00adcations \nthat generate similar structures. A second observation is that the trick we applied to the data type \nExpr a in converting it toadatatype Polishar can be applied to all data types. Suppose we need a se\u00adquential \nrepresentation of a data type T . Now provide all data types reachable from T with an extra parameter \nand rewrite each right hand side of an alternative in a continu\u00adation passing style. As an example consider \nthe following two de.nitions for RoseTree: the standard one and its con\u00adtinuation style counterpart (the \n.-ed identi.ers): data RoseTree a = Node a [RoseTree a ] | Leaf type IntRoseTree = RoseTree Int data \nRoseTree. a . r = Node. (a . (List (Rosetree. a) r)) | Leaf . r data List. f . r = Cons. (f . (List. \nf . r)) | Nil. r data Int. r = Int. Int r type IntRoseTree. = RoseTree. Int. In our example we have used \nthe type Polish because parsers are polymorphic in the result they return, and we should thus be able \nto represent any kind of value. The technique may be useful in many other contexts. 9. WNIOSKI (CONCLUSIONS) \nWe have shown that we can represent Polish expressions in Haskell in such a way that progress information \nsuch as recognizer steps can be merged with the Polish, and a lazy interpreter can be de.ned, permitting \napplications that pro\u00adduce Polish to work in an online manner. Applications that output Polish can be \nrun in parallel , by synchroniz\u00ading their progress, and this in turn permits a breadth-.rst exploration \nof a search space. The Polish idea underlies a high performance parsing library, which demonstrates its \npracticality, and we hope it may .nd other applications too. 10. ACKNOWLEDGEMENTS We want to thank Arthur \nBaars, Atze Dijkstra and Daan Leijen for helpful comments on earlier versions of the paper, and we thank \nAndres L\u00a8oh for his help with the lhs2TEX system. 11. REFERENCES [1] J. Fokker. Functional parsers. In \nJ. Jeuring and E. Meijer, editors, Advanced Functional Programming, number 925 in Lecture Notes in Computer \nScience, pages 1 52. Springer-Verlag, Berlin, 1995. [2] G. Hutton and E. Meijer. Monadic parser combinators. \nJournal of Functional Programming, 8(4):437 444, July 1998. [3] D. J. P. Leijen and H. J. M. Meijer. \nParsec: Direct style monadic parser combinators for the real world. UU-CS 2001-35, Department of Computer \nScience, P.O.Box 80.089, 3508 TB Utrecht, the Netherlands, 2001. [4] S. D. Swierstra. Combinator parsers: \nFrom toys to tools. In G. Hutton, editor, Electronic Notes in Theoretical Computer Science, volume 41. \nElsevier Science Publishers, 2001. [5] S. D. Swierstra and P. R. Azero Alcocer. Fast, error correcting \nparser combinators: a short tutorial. In J. Pavelka, G. Tel, and M. Bartosek, editors, SOFSEM 99 Theory \nand Practice of Informatics, 26th Seminar on Current Trends in Theory and Practice of Informatics, volume \n1725 of LNCS, pages 111 129, November 1999. [6] S. D. Swierstra and L. Duponcheel. Deterministic, error-correcting \ncombinator parsers. In J. Launchbury, E. Meijer, and T. Sheard, editors, Advanced Functional Programming, \nvolume 1129 of LNCS-Tutorial, pages 184 207. Springer-Verlag, 1996. [7] E. Visser. Scannerless generalized-lr \nparsing. P 9707, Programming Research Group, University of Amsterdam, July 1997. [8] P. L. Wadler. How \nto replace failure by a list of successes. In J. Jouannaud, editor, Functional Programming Languages \nand Computer Architecture, volume 201 of LNCS, pages 113 128. Springer-Verlag, 1985.   \n\t\t\t", "proc_id": "944705", "abstract": "We present the derivation of a space efficient parser combinator library: the constructed parsers do not keep unnecessary references to the input, produce online results and efficiently handle ambiguous grammars. The underlying techniques can be applied in many contexts where traditionally backtracking is used.We present two data types, one for keeping track of the progress of the search process, and one for representing the final result in a linear way. Once these data types are combined into a single type, we can perform a breadth-first search, while returning parts of the result as early as possible.", "authors": [{"name": "R. John M. Hughes", "author_profile_id": "81546443956", "affiliation": "Chalmers University of Technology, G&#248;teborg, Sweden", "person_id": "P639768", "email_address": "", "orcid_id": ""}, {"name": "S. Doaitse Swierstra", "author_profile_id": "81100040645", "affiliation": "Utrecht University, Utrecht, The Netherlands", "person_id": "PP14026122", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/944705.944727", "year": "2003", "article_id": "944727", "conference": "ICFP", "title": "Polish parsers, step by step", "url": "http://dl.acm.org/citation.cfm?id=944727"}