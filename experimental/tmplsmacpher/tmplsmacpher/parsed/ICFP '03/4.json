{"article_publication_date": "08-25-2003", "fulltext": "\n An Extension of HM(X) with Bounded Existential and Universal Data-Types Vincent Simonet INRIA Rocquencourt \n Vincent.Simonet@inria.fr Abstract We propose a conservative extension of HM(X), a generic cons\u00adtraint-based \ntype inference framework, with bounded existential (a.k.a. abstract) and universal (a.k.a. polymorphic) \ndata-types. In the .rst part of the article, which remains abstract of the type and constraint language \n(i.e. the logic X), we introduce the type system, prove its safety and de.ne a type inference algorithm \nwhich com\u00adputes principal typing judgments. In the second part, we propose a realistic constraint solving \nalgorithm for the case of structural sub\u00adtyping, which handles the non-standard construct of the constraint \nlanguage generated by type inference: a form of bounded universal quanti.cation. Categories and Subject \nDescriptors: D.3.3 [Programming Lan\u00adguages]: Language Constructs and Features General Terms: Languages, \nTheory. Keywords: Constraint-based type inference, existential and univer\u00adsal data-types, structural \nsubtyping. 1 Introduction HM(X) is a generic constraint-based type inference system, origi\u00adnally de.ned \nfor the .-calculus with let by Odersky, Sulzmann and Wehr [18]. It goes on with the tradition of the \nHindley Milner type system by providing the combination of let-polymorphism and a complete type reconstruction \nalgorithm. However, the interest of HM(X) lies in its greater generality: indeed, it is fully parametrized \nby a logic, X, which is used for expressing types and relating them with constraints. Then, instantiating \nthe framework with differ\u00adent possible logics yields a large variety of type systems. For in\u00adstance, \nletting X be the standard Herbrand logic retrieves the usual uni.cation-based Hindley Milner system. \nSimilarly, choosing a logic equipped with a partial order between types yields a type system featuring \nboth subtyping and let-polymorphism. Another contribution of HM(X) resides in its treatment of the typing \nprob\u00adlem as a constraint. This approach allows modular and systematic Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 03, August 25 29, 2003, Uppsala, Sweden. \nCopyright 2003 ACM 1-58113-756-7/03/0008 ...$5.00 de.nitions of type inference systems, by reducing the \nquestion of determining whether a program is well-typed to constraint resolu\u00adtion. The HM(X) framework \ncan naturally be extended to deal with the whole ML programming language, including references [23], \nex\u00adceptions and variant or record data-types. It also has been used as the basis of type systems for \nsome advanced programming con\u00adstructs [22], or to describe static analyses [24]. However, all these extensions \nare orthogonal to the treatment of polymorphism which remains in the ML tradition. Besides, Odersky and \nL\u00a8aufer [16] proposed an extension of the ML language with existential quanti.cation in algebraic data\u00adtypes, \nwhich yields a Hindley/Milner style version of Mitchell and Plotkin s abstract types [14]. In this extension, \nthe types provided in de.nitions of algebraic data-types may comprise locally quanti.ed variables, e.g.: \ntype t = K of Exists a. a * ( a -> int) (Following Odersky and L\u00a8aufer [16], we adopt a Caml-like [12] \nsyntax for the examples, but we explicitly mention quanti.ers in declarations.) The intuition is that \nthe type tis isomorphic to the existential type .a.a\u00d7(a . int). Any value of type a\u00d7(a . int), for some \na, can be packed in the type tby a simple application of the constructor K; then, it can be accessed \nvia a regular pattern\u00admatching: match (v : t) with |K x-> e In short, the expression emust be type-checked \nin an environ\u00adment where the program variable xreceives the type . \u00d7 (. . int) where . is a new type \nsymbol that cannot occur in the type of e, in order to preserve abstraction. It is equivalent to say \nthat the function funx->emust receive the polymorphic type scheme .a.a \u00d7 (a . int) . t for some type \nt which does not involve a. This style of existential quanti.cation has been implemented in compilers \nfor Hope [20], Caml [13] and Haskell [2], and has shown its practicality and its value for programming: \nit provides in particular .rst class data abstraction and allows heterogeneous data structures aggregating \ndifferent implementations of the same abstract type. What is more, the principle of combining the intro\u00adduction \nand the elimination of existential quanti.cation with the data-type mechanism seems most appealing: this \nprovides the nec\u00adessary source code annotations for preserving type inference, while remaining reasonably \nlightweight and natural for the programmer. In the same spirit, R\u00b4emy [25] proposed the introduction \nof univer\u00adsally quanti.ed variables in data-types, as in the following declara\u00adtion: typeu= LofForAll \na. ( a-> a) Similarly, u is isomorphic to the polymorphic type .a.(a . a). This extension permits to \ncounterbalance in some situations the limitations of let polymorphism and allows an encoding of Sys\u00adtem \nF. For instance, this is useful for de.ning structures which con\u00adtain simultaneously data and functions, \nas in object-oriented pro\u00adgramming, and also allows the introduction of higher-order func\u00adtions whose \narguments have polymorphic types. Such a need is particularly liable to appear in the presence of abstract \ndata-types, because in short any function which manipulates a value com\u00ading from some existential data-type \nmust be polymorphic. 2 Overview In this paper, we propose an extension, called HM..(X), of the HM(X) \nframework with bounded existential and universal data\u00adtypes. The language we consider is a call-by-value \n.-calculus with let and references. As for the original HM(X), our system is parametrized by the logic \nof types and constraints, which allows different instances. Let us now detail the contributions of this \npaper. First and foremost, it provides a general template for equipping HM(X)-based type sys\u00adtems with \n.rst class existential and universal types: this naturally includes all HM(X) instances, but also other \nsystems which follow the same guidelines, e.g. [4, 24]. Obviously, the reasons which lead to introduce \nsuch mechanisms are not particular to these program\u00adming languages and systems; they correspond to those \nwhich are largely discussed in the literature, some of which we have men\u00adtioned in the introduction. \nHowever, the need for a .rst class data abstraction mechanism is likely to increase in languages featuring \nadvanced and expressive type systems: roughly speaking, the more precisely types describe expressions, \nthe more one needs to aggre\u00adgate values of different types. We observed this phenomenon while experimenting \nwith our HM(X)-like type system tracing informa\u00adtion .ow in ML [24] and its prototype implementation \nfor the Caml language, Flow Caml [26]. In this system, usual ML types are an\u00adnotated with security levels \nbelonging to some arbitrary lattice and representing a hierarchy of principals: for instance, modeling \nthe security policy of a bank, one may have one security level for every client. The information concerning \neach client can be stored in a record, which may be de.ned as follows: type a client_info = { cash: a \nint; send_msg: a int -> unit; ... } This de.nition is identical to that we would have in Caml, with the \ndifference that the record type client_info must carry one parameter which is the security level of the \nclient. This security level also appears in the record components types: the .eld cash stores the current \nbalance of the client s account, hence it has the type of an integer labeled by the client s security \nlevel. Similarly, send_msg is a function which allows sending a message to the given client. The bank \ns security policy naturally requires that each client can only receive information about its personal \nsituation, so the argument of send_msg must have (at most) the security level a. In Caml, all records \nstoring information about clients would have the same unannotated type, client_info, so it would be possible \nto store the clients .le in some data structure, such as a list of type client_info list. On the contrary, \nin Flow Caml, records corresponding to distinct clients have incompatible types because their annotations \ndiffer and, as a consequence, the clients .le forms a heterogeneous set of records which is not representable. \nA natural solution consists in making the client s security level exis\u00adtentially quanti.ed in the declaration: \nin section 6.2, we will follow up on this example and show how extending Flow Caml s type sys\u00adtem with \nthe framework of the current paper allows manipulating such data structures. Secondly, instantiating \nHM..(X) with the standard Herbrand logic, we retrieve a system close to those of Odersky and L\u00a8aufer \n[16] and R\u00b4emy [25]. However, we believe our constraint-based presentation to be more modular and lightweight, \nbecause it clearly separates issues related with the logical de.nition of the type system from those \nconcerning type inference. Indeed, in previous approaches, the typing rule for opening abstract values \nintroduce Skolem types for existentially quanti.ed variables, i.e. new incompatible (for uni\u00ad.cation) \ntype symbols. Although this is an ef.cient implementa\u00adtion technique for dealing with existentially quanti.ed \nvariables in a uni.cation-based type inference engine, this is not really handy to manipulate when studying \nthe type system itself, e.g. proving type safety results. Our approach stands in sharp contrast: the \nlogical presentation of the type system relies only on the usual type gen\u00aderalization mechanism. For \nthe purpose of type inference, the con\u00adstraint language is enriched with a construct which provides a \nform of bounded universal quanti.cation, whose resolution is delegated to an external constraint solver. \nAs a third contribution, this paper describes a realistic algorithm for solving this extended constraint \nlanguage for the case of structural subtyping. To the best of our knowledge, this is the .rst practi\u00adcal \nalgorithm to be proposed which deals with a form of bounded universal quanti.cation in subtyping constraints. \nWe will now proceed as follows. In section 3, we introduce the lan\u00adguages of types, constraints and programs. \nThen, in section 4 we de.ne the type system HM..(X), prove it ensures safety of program execution and \ndescribe an algorithm which computes principal typ\u00ading judgments. The presentation and the proofs of \nthese topics are carried out in a general context, with limited assumptions about the model in which \ntypes and constraints are interpreted. In section 5, we propose a realistic algorithm for solving constraints \ngenerated by type inference in the case of structural subtyping. Section 6 concludes with some discussion \nabout the possible continuations of this work, and about integrating it into our information .ow ana\u00adlyzer \n[24, 26]. By lack of space, only the most signi.cant fragments of proofs are given. However, they can \nbe found integrally in the full version of this paper [27]. 3 The core language We let a variance . \nbe a pair of booleans (.+ ,.-). We write . (read: covariant), e (contravariant) and 8 (invariant) for \nthe vari\u00adances (1,0), (0,1) and (1,1), respectively. A signature of arity n is a list of n variances \n[.1,...,.n]. 3.1 Types and constraints Our framework is parametrized by a .rst-order logic, X, whose \nvariables, terms and formulas are respectively type variables, types and constraints. Type variables \nare supposed to be in in.nite num\u00adber and are denoted by the meta-variables a and \u00df. We let a\u00afstand for \na .nite list of types variables, and given two sets of variables V1 and V2, we let V1#V2 be a shorthand \nfor V1 nV2 = 0/. . ft =t'. .(t)=.(t') . fC1 .C2 . . fC1 and . fC2 . f.\u00afC ..\u00af.[\u00af \u00afC a.t a.t]f. f.\u00af=..t \na.t]fD ..[\u00af \u00afC a.D tC \u00af.[\u00af \u00afa.t]fand .\u00af.[\u00af \u00af t a.t]fD Figure 1. Interpretation of constraints We follow \nthe model-based approach of Pottier [23] by interpreting the logic in a model (T,=), which is a partially \nordered set whose elements t are ground types. This differs from the original presen\u00adtation of HM(X) \n[29] where constraints are viewed as elements of an abstract cylindric constraint system. Although it \nis slightly less general, we believe our presentation to be more concise. Further\u00admore, it allows manipulating \nsolutions of constraints, which is of greater help when one describes constraint resolution algorithms. \nAs it is usual, we do not fully specify the .rst-order logic X nor the model T , but only state a few \nrequirements they must ful.ll. Thus, our framework remains abstract from several choices, as the .avor \nof subtyping at hand (e.g. structural or non-structural subtyping). In section 5, we will describe one \nof the possible instances. The logic X must at least comprise the following language of types: t ::=a \n|unit |t .t |t ref |e(t\u00af)|p(t\u00af)|... Types include type variables, a base type unit, functions and refer\u00adences \ntypes. Existential and universal types are named: we let e and p range over disjoint sets of existential \nand universal constructors, respectively. For the time being, we do not specify how data-types are declared, \nwe will address this question in section 3.2. We just require each constructor to have a signature which \nspeci.es in par\u00adticular its arity. If . is a variance, we de.ne =. by: t =. t'.((if .+then t =t')and \n(if .-then t'=t)) Let a symbol be either an existential or universal constructor, or one of unit, .and \nref. We equip the last three symbols with the usual signatures: sig(unit)=[], sig(.)=[e,.]and sig(ref)=[8]. \nA symbol . of signature [.1,...,.n]is interpreted in the model by a total mapping [.] from Tn to T , \nsuch that [.](t1,...,tn)= [.](t1',...,t')if and only if, for all i, ti =.i ti'. Moreover, we as\u00ad n sume \nthe interpretations of two distinct symbols to produce in\u00adcomparable ground types. Types are interpreted \nin the model by assignments: an assignment . is a total mapping from types to ground types which is a \nmorphism for symbols (i.e. for all . and t1,...,tn, .(.(t1,...,tn))=[.](.(t1),...,.(tn))). Constraints \nare interpreted in the model by a two-place predicate \u00b7f\u00b7, whose arguments are an assignment and a constraint; \nif . fC holds, we say that . satis.es or isa solution of C. The constraint language of the logic X must \nprovide the following constructs, whose interpretation is speci.ed by the laws of .gure 1: C,D ::=t =t \n|C .C |.a\u00af.C |.a\u00af.D =tC |... Constraints include subtyping between types (we let t =t'be a shorthand \nfor t =t'.t'=t), conjunction of constraints and exis\u00adtential quanti.cation. In addition to these standard \nconstructs, we require a custom form of constraint, .a\u00af.D =tC, which is generated by the type inference \nalgorithm when it requires an expression to have some bounded polymorphic type. We give a weak semantics \nto universal quanti.cation by requiring the bound D to be satis.\u00adable: an assignment . is a solution \nof .a\u00af.D =tC if it satis.es .a\u00af.D and, for every assignment t\u00afof the variables a\u00afsuch that .[a\u00af .t\u00af] \nsatis.es D then .[a\u00af .t\u00af]is a solution of C. Doing so preserves the property that any sub-constraint \nof a satis.able constraint is also satis.able, which shall help constraint resolution, see section 5. \nWe introduce the constant true for some arbitrary universally true constraint, e.g. .a.a =a. We assume \nthe standard notions of free\u00advariables and capture-avoiding substitutions to be de.ned on con\u00adstraints \n(fv(C)stands for the set of variables free in C and C[t/a]is the constraint C where every free occurrence \nof a is substituted by t). We write C1 F C2 if C1 implies C2, i.e. every solution of C1 is also a solution \nof C2. Two constraints are equivalent if they imply each other. 3.2 Data-type declarations We now have \nto provide a way to relate data-type constructors to plain types, i.e. to specify the type of the values \neach data-type ac\u00adcepts. Our approach super.cially differs from that of Odersky and L\u00a8aufer [16]. First, \nwe choose not to make data-types declarations part of the expression language; instead we consider they \nare de\u00ad.ned globally. Second, we simplify the presentation by separating them from variants and records; \nin other words we only consider one summand variants (or isomorphically one .eld records). Al\u00adthough \ncombining the introduction of existential or universal quan\u00adti.cation with building or matching of data \nstructures is convenient in a real programming language, we believe this to be orthogonal to the formal \npresentation of the system. For every existential constructor e, we assume a declaration of the form: \n\u00af\u00af e(a\u00af) .\u00df[D].t with fv(t,D).a\u00af.\u00df (Such a declaration is considered modulo a-conversion of the vari\u00ad \n\u00af ables a\u00afand \u00df, which are supposed to be distinct.) The intuition behind is that the type e(a\u00af)is an \nabbreviation for the existential \u00af type .\u00df[D].t. The main difference with the case of ML is that exis\u00adtential \ntypes supply a constraint D which bounds the quanti.cation, \u00af i.e. which may relate the quanti.ed variables \n\u00df with one another and with the type parameters a\u00af. In words, the above declaration means that an expression \nof type e(a\u00af)can be built from any ex\u00adpression which has the type t for some instance of \u00df\u00afsatisfying \nD. In the case of a uni.cation-based system where the only expressible relation between types is equality, \nthere was no need for such a con\u00adstraint, because roughly speaking it can always be set to true by uni.cation \nand substitution of type variables. However, this is no longer the case with a more elaborate constraint \nlanguage, e.g. in the presence of subtyping. Similarly, a universal constructor p must have a declaration \nof the form: \u00af\u00af p(a\u00af) .\u00df[D].t with fv(t,D).a\u00af.\u00df which means that a value may be injected in the type \np(a\u00af)if and only if it has the type t for every solution \u00df\u00afof D. Subtyping between data-types has been \nde.ned by equipping con\u00adstructors with signatures. One must ensure that each of them .ts the logical \ninterpretation of the corresponding constructor. Thus, for existential constructors, we require that \n\u00af\u00af if e(a\u00af1) .\u00df1[D1].t1 and e(a\u00af2) .\u00df2[D2].t2 with \u00df\u00af2 #fv(t1)then \u00af D1 .e(a\u00af1)=e(a\u00af2)F .\u00df2.(D2 .t1 =t2) \nThe intuition is that e(a\u00af1)=e(a\u00af2)requires every expression of type e(a\u00af1)to have the type e(a\u00af2): then, \nfor every instance of t1 with \u00df\u00af1 satisfying D1, there must exist a greater instance of t2 for some \n\u00af \u00df2 which satis.es D2. In other words, the variances assigned to the constructor e must be valid for \nthe underlying existential type, which is necessary for the type system to be safe, see proof of lemma \n3. The following is the counterpart for universal construc\u00adtors: if p(a\u00af1) .\u00df\u00af1[D1].t1 and p(a\u00af2) .\u00df\u00af2[D2].t2 \nwith \u00df\u00af1 #fv(t2) then D2 . p(a\u00af1) = p(a\u00af2) F .\u00df\u00af1.(D1 . t1 = t2) The inequality p(a\u00af1) = p(a\u00af2) requires \nthat for every instance of .\u00df\u00af2[D2].t2, there exists a lesser one of .\u00df\u00af1[D1].t1. 3.3 Expressions Let \nx, m range over disjoint denumerable sets of program variables and memory locations, respectively. Then \noperators, values and expressions are de.ned as follows: op ::= ref | := | ! v ::= x | m | () | .x.e \n| op | :=m |(v)e |(v)p e ::= x | m | () | .x.e | op | ee | let x = v in e |(e)e | opene ewith v |(v)p \n| openp e The core of the language is a .-calculus with references. Expres\u00adsions include program variables, \nmemory locations, a unit constant, .-abstractions, three operators for allocating, updating and reading \nmemory cells, and function applications. The let construct has the same meaning as the basic expression \n(.x.e)v; however, as usual in ML, it directs the type-checker to generalize x s type. The language is \nextended with existential and universal introduction and elim\u00adination constructs. (\u00b7)e and (\u00b7)p are data-type \nconstructors, they tell when to pack values as abstract or polymorphic ones, respec\u00adtively. Polymorphic \nvalues can be read directly with openp which is nothing but the inverse of the constructor (\u00b7)p. Accessing \nexis\u00adtential ones is slightly more subtle: for the sake of type soundness, we need the content of an \nexistential value to be used only within a statically known bounded scope: for this purpose, the construct \nopene ewith v includes a handling function v which will receive as argument the content of the matched \nexpression e. The grammar of expressions constrains sub-expressions of some constructs to be values rather \nthan arbitrary expressions: the bind\u00ading in let, the handler in opene and the content of a polymor\u00adphic \ndata-type. These sub-expressions correspond to the point where the type system performs some type generalization: \nfollow\u00ading Wright [31], we restrict it to values, to preserve soundness in the presence of references. \nA store is a partial mapping from memory locations to values. The small-step semantics is de.ned on con.gurations \ne / \u00b5 which con\u00adsist in a pair of an expression and a store. The reduction rules are given in .gure 2. \nAs usual in presence of side-effects, we choose a call-by-value evaluation strategy; hence evaluation \ncontexts E are de.ned by the following grammar: E ::=[] e | v[] |([])e | opene []with v |([])p | openp \n[]  4 The type system We now present the type system HM..(X). In section 4.1, it is de\u00ad.ned as a logic \nof deduction rules. Then, in section 4.2, we prove it is safe i.e. reduction of well-typed expression \ncannot go wrong and section 4.3 describes a type inference algorithm, that is, a pro\u00adcedure to derive \nmost general typing judgments. In this section, we identify constraints modulo logical equivalence. Although \nthe representation of constraints is of main importance for the design of a constraint solver, it does \nnot matter when de.ning a type system and proving it correct. 4.1 Typing rules A type scheme s is a \ntriple of a set of quanti.ers a\u00af, a constraint C and a type t; we write s = .a\u00af[C].t. Type schemes are \nconsidered modulo renaming of quanti.ed variables. A program environment is a partial mapping from program \nvariables to type schemes. A memory environment is a partial mapping from memory locations to types. \nThe type system HM..(X) is de.ned by the set of deduction rules of .gure 3. Judgments about expressions \nhave the form C,G,M f e : t where t is the type assigned to the expression, the environments G and M \ngive type schemes to e s free program variables and types to memory locations, respectively, and the \nconstraint C carries as\u00adsumptions about the type variables that are free in G, M and t.By generalization, \na type scheme may be assigned to a value, hence a judgment of the form C,G,M f v : s. Two extra forms \nare employed to reason about stores C,M f \u00b5 and con.gurations C,G f e / \u00b5 : t. We omit G and M in judgments \nwhen they are empty. We now comment on the typing rules of .gure 3, starting with the three non-syntax \ndirected ones. Firstly, GENERALIZE generalizes the type of a value to produce a type scheme. All type \nvariables that are not free in the environments and the constraint C can be universally quanti.ed. Moreover, \nwe require the generated scheme to have instances, hence the premise C F .a\u00af.C ' .SUB is a standard subsumption \nrule, allowing an expression which has some type t' to be used with any greater type t. Rule HIDE makes \na type variable local to a sub-derivation, which is of interest before generalization. Rules VAR and \nLOC assign types to program variables and mem\u00adory locations by looking up the appropriate environment. \nNote that G(x) is a type scheme, of which VAR makes a fresh instance. UNIT dealswiththeunitconstantand \nOPassignsthestandardtypestoop\u00aderators: typeref (t)= t . t ref, type:=(t)= t ref . t . unit and type!(t)= \nt ref . t. Rules for .-abstraction ABS, function appli\u00adcation APP and let-binding LET are standard. In \nABS, we slightly abuse notations by mapping x to the simple type t in the program environment, while \nit should be .\u00d8[true].t. When typing (e)e, rule EXIST looks up the declaration of the data-type e and \nrequires e to have some instance of the type t which satis.es D (in fact, by SUB, e may have any type \nt' such that C F t'= t). In OPENEXIST, the expression e must have an e type (for the sake of simplicity, \nwe require the parameters of the data-type to be variables, but this is not restrictive because subsumption \nallows introducing names for arbitrary sub-terms in types). Then, the handler v must have the type scheme \n.\u00df\u00af[D].t'. t so that it is a function able to accept any possible instance of the existential type. Furthermore, \nin order to preserve type abstraction, the result returned by the handler cannot leak information about \nthe existentially quanti.ed type variables \u00df\u00af, hence they must not appear in the type t. Rule POLY looks \nup the declaration of the universal data-type p and requires the value v to have the corresponding type \nscheme. Conversely, in OPENPOLY, the expression e must have a p type, and an instance of the scheme found \nin the declaration is taken. The last three rules of the system deal with stores and con.gu\u00adrations. \nSTORE requires each entry of the store to have the type given by the memory environment. CONF allows \nderiving a judg\u00ad .x.ev / \u00b5 . e[v/x] / \u00b5 (\u00df) let x = v in e / \u00b5 . e[v/x] / \u00b5 (let) opene (v1)e with v2 \n/ \u00b5 . v2 v1 / \u00b5 (e) openp (v)p / \u00b5 . v / \u00b5 (p) ref v / \u00b5 . m / \u00b5[m . v] if m . dom \u00b5 (ref) :=mv / \u00b5 \n. () / \u00b5[m . v] if m . dom \u00b5 (assign) !m / \u00b5 . \u00b5(m) / \u00b5 (deref) '' E[e] / \u00b5 . E[e '] / \u00b5 if e / \u00b5 . \ne ' / \u00b5 (context) Figure 2. Semantics ment about a con.guration from those on the expression and the \nstore. CONFHIDEisrequiredforthetypesystemtoenforcesubject\u00adreduction: indeed, because of allocation, the \nmemory environment is liable to grow throughout reduction and therefore to involve new typevariables. \nThosecannolongerbemadelocalby HIDE,butstill by CONFHIDE, because typing judgments on con.gurations do \nnot mention the memory environment. For the sake of conciseness, we did not make the two following rules \npart of our de.nition of HM..(X), however it can be checked that they are valid, i.e. adding them in \nthe system does not extend the set of derivable judgments: WEAKEN C,G,M f e : . C ' F C C ' ,G,M f e \n: . INST C,G,M f v : . \u00afa[C '].t C,G,M f v : t C F C ' The former states that the constraint in a type \njudgment about some expression can be weakened (. stands for either a type t or a type scheme s), while \nthe latter allows instantiating type schemes at any place in derivations.  4.2 Type safety We now state \nthe correctness of the type system, i.e. that evaluation of well-typed expressions cannot go wrong. This \ncould be achieved following a semi-syntactic approach [23], which consists in de.n\u00ading an intermediate \nground system, B..(T ), whose types are those of T . However, we prefer to proceed in a direct way, by \nproving HM..(X) satis.es subject-reduction, since it shows that each re\u00adduction step preserves typings. \nProving type safety is simpli.ed by restricting our attention to canonical derivations. We chose a logic, \nrather than syntax\u00addirected, presentation of the type system, since the former is much more concise than \nthe latter. The restriction to canonical deriva\u00adtions allows to recover the bene.t of the latter. Canonical \nderiva\u00adtions (about expressions or con.gurations) are those where every instance of HIDE is above an \ninstance of GENERALIZE. We write C,G,M fce : t if the judgment C,G,M f e : t has a canonical deriva\u00adtion. \nLemma 1 (Canonical derivations) If C,G f e / \u00b5 : t holds then there exists a canonical derivation of \nthis judgment. Lemma 2 (Subsumption) Assume C, G, M fce : t. There exists t' such that C F t'= t and \nthe derivation of C, G, M fce : t' ends by an instance of a syntax-directed rule. A memory environment \nM ' extends M if and only if the domain of the latter is a subset of that of the former, and M agrees \nwith M ' where both are de.ned. We can now state our main lemma. Lemma 3 (Subject-reduction) Let e/\u00b5 \n. e ' /\u00b5 ' . Assume C,M fc e : t and C,M f \u00b5. Then, there exists a memory environment M ' , ' which extends \nM, such that C, M 'f e ' : t and C, M 'f \u00b5. ' Proof. By induction on the derivation of e / \u00b5 . e / \u00b5 \n'.By lemma 2, we may assume, w.l.o.g., that the derivation of C,M fce : t ends by an instance of a syntax-directed \nrule. By lack of space, we only give the case related to existential data-types; all others can be found \nin the full version of the paper [27]. '' . Case (e).e is opene (v1)e with v2 and e is v2 v1 and \u00b5 is \n\u00b5. The derivation of C,M fce : t must end with an instance of OPENEXIST whose premises are C, M fc (v1)e \n: e(a\u00af) (1) and e(a\u00af) .\u00df\u00af[D].t1 (2) and C, M fcv2: .\u00df\u00af[D].t1 . t (3) and \u00df\u00af#fv(t) (4). By lemma 2 and \nEXIST, (1) implies C,M f v1: t' 1 (5) and e(a\u00af') .\u00df\u00af'[D '].t' 1 (6) and C F D ' (7) and C F e(a\u00af') = \ne(a\u00af) (8). Invok\u00ad\u00af ing (4) and by a renaming of \u00df in (2) and (3), we may assume \u00af \u00df #fv(t' 1,C,M) (9). \nBy the requirement on e s signature (sec\u00adtion 3.2), (2), (6), (8) and (9) yield (C . D ') F .\u00df\u00af.(D . \nt' 1 = t1) and, by (7), C F .\u00df\u00af.(D . t' 1 = t1) (10) follows. By (5), WEAKEN and SUB, we have (C . D \n. t' 1 = t1),M f v1: t1, and, by (3) and INST, (C . D . t' 1 = t1),M f v2: t1 . t.By APP, this yields \n' (C . D . t' 1 = t1),M f e : t. Using (4) and (9), by an instance ' of HIDE, we obtain C ..\u00df\u00af.(D . t1 \n'= t1),M f e : t.By WEAKEN and (10), C,M f e ' : t follows. D The previous lemma entails the following, \nmore abstract statement: ' Theorem 1 (Subject-reduction) If C f e / \u00b5 : t and e / \u00b5 . e ' / \u00b5 then C \nf e ' / \u00b5 ' : t. A closed con.guration e / \u00b5 is well-typed if C f e / \u00b5 : t holds for some type t and \nsatis.able constraint C. Lemma 4 (Progress) Consider a closed con.guration e / \u00b5. Ifitis well-typed and \nirreducible, then e is a value. We omit the proof of this result, which is standard and can be found \nin [27]. Let e be a closed expression. e / \u00b5 is said to go wrong if there '' exists an irreducible con.guration \ne ' / \u00b5 such that e / \u00b5 .* e ' / \u00b5 ' and e is not a value. The combination of subject-reduction and progress \nensures that well-typed con.gurations cannot go wrong, which proves the type safety of HM..(X). Theorem \n2 (Safety) If e / \u00b5 is closed and well-typed, then it does not go wrong.  4.3 Type inference From here \non, we restrict our attention to source language expres\u00adsions, i.e. expressions which do not contain \nmemory locations. In\u00addeed, introducing memory locations was only useful to de.ne a small-step semantics \nand state the type safety theorem. Figure 4 de.nes the type inference algorithm as a function, .\u00b7f\u00b7 : \n\u00b7., which takes three arguments: the program environment G, the Syntax-directed rules VAR G(x)= . \u00afa[C \n'].t C F C ' C,G,M f x : t LOC C,G,M f m : M(m) ref UNIT C,G,M f () : unit OP C,G,M f op : typeop(t) \nABS C,G[x . t'],M f e : t C,G,M f .x.e : t' . t APP LET EXIST C,G,M f e1: t'. t C,G,M f e2: t' C,G,M \nf v : s C,G[x . s],M f e : t C,G,M f e : te(a\u00af) .\u00df\u00af[D].t C F D C,G,M f e1 e2: t C,G,M f let x = v in \ne : t C,G,M f(e)e : e(a\u00af) OPENEXIST C,G,M f e : e(a\u00af) e(a\u00af) .\u00df\u00af[D].t' POLY \u00af C,G,M f v : .\u00df\u00af[D].t'. \nt\u00df #fv(t) C,G,M f v : .\u00df\u00af[D].tp(a\u00af) .\u00df\u00af[D].t C,G,M f opene ewith v : t C,G,M f(v)p : p(a\u00af) OPENPOLY \nC,G,M f e : p(a\u00af) p(a\u00af) .\u00df\u00af[D].t C F D Non-syntax-directed rules GENERALIZE C .C ' ,G,M f v : t C F .a\u00af.C \n' a\u00af#fv(C,G,M) C,G,M f v : .a\u00af[C '].t  Stores and con.gurations STORE dom \u00b5 = dom M .m . dom MC,M f \n\u00b5(m) : M(m) C,M f \u00b5 C,G,M f openp e : t SUB C,G,M f e : t' C F t'= t C,G,M f e : t CONF C,G,M f e \n: t C,M f \u00b5 C,G f e / \u00b5 : t HIDE C,G,M f e : ta #fv(G, M,t) .a.C,G,M f e : t CONFHIDE C,G,e f \u00b5 : ta \n#fv(G,t) .a.C,G,e f \u00b5 : t Figure 3. The type system HM..(X) expression to be typed, e, and a type t. \nIt returns the minimal (w.r.t. implication) constraint C under which hypothesis t is a valid type for \ne in the environment G, i.e. C,G f e : t holds. (In every line of .gure 4, we naturally assume the local \ntype variables introduced by the algorithm to be distinct and fresh w.r.t. fv(G,t).) The recursive de.nition \nof the constraint returned by the type in\u00adference algorithm follows the syntax-directed rules of the \nlogical presentation of the type system (.gure 3). However, in order to be complete, the algorithm must \ntake in account any possible use in HM..(X) derivations of one of the non-syntax-directed rules. First, \nSUB is dealt with by generating coercions in constraints at any place where subsumption can occur in \nHM..(X). In what con\u00adcerns HIDE, the constraints produced by the type inference algo\u00adrithm systematically \nexpose a minimal number of type variables: the free variables of G f e : t are (a subset of) those of \nG and t. Lastly, generalization (rule GENERALIZE) is handled in the infer\u00adence process in two different \nways. On the one hand, the treatment of polymorphism introduced by let is standard: the type scheme to \nbe assigned to the variable x is not given explicitly in the program, so, to ensure principality, the \nmost general one must be computed and inserted in the environment. For this purpose, a fresh type vari\u00adable \na is introduced for the typing of v, so that a is the only variable which can be generalized in the constraint \nG f v : a (other free variables are bound in the environment G). Hence, .a[ G f v : a ].a is a most general \ntype scheme for v in the environment G. On the other hand, in the expressions opene ewith v and (v)p \nthe value v is expected to have a type scheme which is given by the data-type declaration. So, the type \ninference algorithm computes v s princi\u00adpal typing and must then ensure this to be more general than \nthe expected one. This comparison is simply encoded by a universally quanti.ed constraint: in opene ewith \nv, the handler v must have the scheme .\u00df\u00af[D].t'. t, hence the constraint .\u00df\u00af.D=t G f v : t'. t . Similarly, \nin (v)p, the scheme .\u00df\u00af[D].t is expected; this yields the constraint .\u00df\u00af.D =t G f v : t . The following \ntheorem states that the type inference algorithm is correct, i.e. that the constraint it generates is \nthat of a valid typing judgment about the given expression. Theorem 3 (Correctness) For all G, e and \nt, the judgment G f e : t ,G f e : t is derivable. Proof. The proof is by induction on the expression \ne. Again, by lack of space, we only give the cases concerning existential data\u00adtypes. Those about universal \ndata-types are similar, and others are standard. All can be found in [27]. . Case e = (e ')e. Let a\u00afand \n\u00df\u00afbe distinct variables not in fv(t,G) (1) and e(a\u00af) .\u00df\u00af[D].t' (2). By induction hypothesis, we have \nG f e ' : ' '' t' ,G f e : t'.By WEAKEN, this yields G f e : t'. D,G f e : t' (3). By an instance of \nEXIST with the premises (3), (2) and G f e ' : t'. D F D, we obtain G f e ' : t'. D,G f e ' : e(a\u00af).By \nWEAKEN and SUB, G f e ' : t'. D . e(a\u00af) = t,G f e ' : t (4) follows. By (1), a\u00af\u00df\u00afappear only in the constraint \nof the judgment (4), then by HIDE, we obtain .a\u00af\u00df\u00af.( G fe ' : t'.D .e(a\u00af) =t),G fe ' : t (5). By (1) \nand (2), G fe : t is .a\u00af\u00df\u00af.( G fe ' : t'.D .e(a\u00af) =t), hence (5) is the goal. G fx : t G f() : t G f.x.e \n: t G fe1 e2 : t G flet x = v in e : t G fop : t G f(e)e : t G fopene ewith v : t G f(v)p : t G fopenp \ne : t = .\u00afa.(C .t' =t) = unit =t = .a1a2.( G[x .a1] fe : a2 .a1 .a2 =t) = .a.( G fe1 : a .t . G fe2 : \na ) = G[x ..a[C].a] fe : t ..a.C = .a.(typeop(a) =t) = .\u00afa\u00af\u00df.( G fe : t' .D .e( \u00afa) =t) = .\u00afa.( G fe \n: e( \u00afa) ..\u00af\u00df.D =t G fv : t' .t ) = .\u00afa.(.\u00af\u00df.D =t G fv : t' .p( \u00afa) =t) = .\u00afa\u00af\u00df.( G fe : p( \u00afa) .D .t' \n=t) G(x)= .\u00afa[C].t' C = G fv : a e( \u00afa) .\u00af\u00df[D].t' e( \u00afa) .\u00af\u00df[D].t' p( \u00afa) .\u00af\u00df[D].t' p( \u00afa) .\u00af\u00df[D].t' \nFigure 4. Type inference for HM..(X) \u00af . Case e = opene e ' with v. Let a\u00afand \u00df be distinct variables \nnot in fv(t,G) (1) and e(a\u00af) .\u00df\u00af[D].t' (2). By induction hypothesis, we have G fe ' : e(a\u00af) ,G fe ' : \ne(a\u00af) (3) and G fv : t'.t ,G fv : t'.t (4). By WEAKEN, D..\u00df\u00af.D=t G fv : t'.t ,G fv : t'.t (5) follows \nfrom (4). Because .\u00df\u00af.D =t G f v : t'. t F .\u00df\u00af.D, \u00af \u00df #fv(.\u00df\u00af.D =t G fv : t'.t ),by GENERALIZE,(1)and(5)yield \n.\u00df\u00af.D =t G f v : t'. t ,G f v : .\u00df\u00af[D].t'. t (6). By WEAKEN and OPENEXIST, the judgment G f e ' : e(a\u00af) \n..\u00df\u00af.D =t G f v : t'.t ,G fe : t can be derived from (3), (6), (2) and (1). By (1) and HIDE, .a\u00af.( G \nfe ' : e(a\u00af) ..\u00df\u00af.D =t G fv : t'.t ),G fe : t (7) follows. By (1) and (2), G f e : t is .a\u00af.( G f e \n' : e(a\u00af) . .\u00df\u00af.D =t G fv : t'.t ), hence (7) is the goal.  We continue by showing the type inference \nalgorithm to be com\u00adplete, i.e. to produce the minimal constraint (w.r.t. implication) un\u00adder whose hypothesis \nan expression is typable. Lemma 5 (Subsumption) G fe : t .t =t' F G fe : t' . Theorem 4 (Completeness) \nIf C,G fe : t then C F G fe : t .If C,G fv : .a\u00af[C '].t and a\u00af#fv(G) then C F .a\u00af.C ' =t G fv : t . Proof. \nBy induction on the input derivation. By lack of space, we only give the cases concerning existential \ndata-types. Those about universal data-types are similar, and others are standard. .Case EXIST. The hypothesis \nis C,G f(e)e : e(a\u00af). This derivation ends by an instance of EXIST whose premises are C,G fe : t (1), \ne(a\u00af) .\u00df\u00af[D].t (2) and C F D (3). Using the induction hypothesis with (1), we have C F G fe : t . By \n(3), we obtain C F G fe : t . D (4). Let e(a\u00af'\u00df\u00af') .\u00df\u00af[D '].t' (5) with a\u00af'\u00df\u00af'#fv(G,a\u00af) (6). By (2), \n(5) and lemma 5, (4) implies C F .a\u00af'\u00df\u00af' .( G fe : t'.D '.e(a\u00af') = e(a\u00af)) (7). By (5) and (6), G f(e)e \n: e(a\u00af) is the right-hand-side of (7), which is hence the goal. . Case OPENEXIST. The hypothesis is C,G \nf opene ewith v : t. Thisderivationendsbyaninstanceof OPENEXISTwhosepremises are C,G fe : e(a\u00af) (1), \ne(a\u00af) .\u00df\u00af[D].t' (2), C, G fv : .\u00df\u00af[D].t'.t (3) and \u00df\u00af#fv(t) (4). Thanks to (4), we may assume \u00df\u00af#fv(C,G) \n(5). ' Invoking the induction hypothesis, (1) and (3) yield C F G fe : t (6) and C F .\u00df\u00af.D =t G fv : \nt'.t (7), respectively. Let e(a\u00af') .\u00df\u00af[D '].t'' (8) with a\u00af'#fv(C,G,t) (9). By lemma 5, (6) and (7) yield \na' F G fe : t'' G fv : t'' .t . C .a\u00af= \u00af..\u00df\u00af.D =t By (9), C F a' .( G fe : t'' .\u00af..\u00df\u00af.D =t G fv : t'' \n.t ) (10) follows. By (5), (8) and (9), G f opene ewith v : t is the right-hand-side of (10), which is \nhence the goal.   5 Solving constraints: the case of structural subtyping We are done describing the \nHM..(X) type system and its type in\u00adference algorithm, which provides a procedure to compute (the con\u00adstraint \nof) the principal typing judgment for a given program. We shall now deal with the resolution of constraints: \nindeed, according to the type safety theorem, a program is well-typed in HM..(X) if and only if the constraint \nproduced by inference is satis.able in the logic X. However, addressing this question in a general con\u00adtext, \nwithout specifying more precisely the properties of the logic and the model is not conceivable: constraints \nresolution techniques heavily depend on them. We choose to turn our attention to the case of structural \nsubtyp\u00ading [15], because our initial motivation resides in the introduction of existential and universal \ndata-types in our information .ow in\u00adference system for the Caml language [24, 26]. In short, with struc\u00adtural \nsubtyping, two comparable ground types must be (.nite) trees which have the same shape and only differ \nby their leaves or atoms. This .avor of subtyping naturally arises when one intends to ex\u00adtend a uni.cation-based \ntype system with annotations belonging to a poset, in order to perform some static analysis [1, 5, 24]. \nResolution of sets of inequalities in the case of structural subtyping has been intensively studied, \nand ef.cient algorithms are known for solving and simplifying constraints [6, 30, 9, 28]. However, the \ntype inference algorithm of section 4 produces a non-standard form of constraints, .\u00df\u00af.D =tC, which combines \nuniversal quanti.cation with implication. On the one hand, Kuncak and Rinard [10] re\u00adcently showed that \nthe .rst-order theory of structural subtyping of non-recursive types is decidable; however, this study \ndoes not yield a practical algorithm for solving constraints. On the other hand, previous works [8, 28] \ndescribed ef.cient algorithms for deciding top-level entailment of constraints, where all free variables \nare im\u00adplicitly universally quanti.ed. However the problem we tackle here is more general. Because of \nthe presence of unquanti.ed free vari\u00adables, the result of the comparison is no longer a simple boolean: \none must determine the minimal hypothesis if any about these variables which guarantees the implication \nto be true. Our approach consists in trying to express this hypothesis itself as a constraint, i.e. to \ntranslate every construct .\u00df\u00af.D =t C into a regular constraint without universal quanti.cation and implication. \nThe interest of this strategy, known as quanti.ers elimination, is that, because the target constraint \nlanguage is standard, it bene.ts from the existing techniques, such as simpli.cation methods. Designing \nalgorithms for solving constraints of a logic which in\u00adcludes an implication operator is recognized to \nbe a dif.cult ques\u00adtion, because they involve a form of disjunction: the constraint can be solved either \nby negating the left-hand-side of the implication or by satisfying the right-hand-side, which breaks \nthe usual closure mechanisms. Here, we bypass this problem thanks to two partic\u00adular properties. Firstly, \nleft-hand-sides of implications are not ar\u00adbitrary in constraints generated by type inference: they are \nexactly the constraints which are given in data-type declarations (by con\u00advention, all these have been \ndenoted by the meta-variable D in the paper). As a consequence, we impose some restrictions about their \nform in order to strike a compromise between the expressivity of the system and the ef.ciency of constraint \nresolution, as will be ex\u00adplained in subsection 5.3. Secondly, we gave a weak semantics to universal \nquanti.cation: indeed .\u00df\u00af.D =tC implies .\u00df\u00af.D (and, as a consequence, .\u00df\u00af.(D .C)). This was not necessary \nfor the type inference algorithm (because it could generate .\u00df\u00af.D ..\u00df\u00af.D .C in place of .\u00df\u00af.D=tC). However, \nmaking this explicit in the semantics of constraints serves the constraint solver: in particular, it \npreserves the property that any sub-constraint of a satis.able constraint is also satis.able. 5.1 The \nground model Let us brie.y introduce a generic model Ts for structural subtyping, parametrized by a set \nof symbols (which must at least include those of section 3). Every symbol . must come with a .xed arity \na(.) and a signature sig(.). Then ground types are .nite trees labeled by symbols, de.ned by: t ::=.(t1,...,ta(.)) \nSymbols of arity 0 are ground atoms; we suppose they are partially ordered by the lattice order =0. Other \nnon-constant symbols are type constructors and denoted by the meta-variable f. (We do not introduce some \nkinding system to separate them because this is not required by the forthcoming algorithm.) Subtyping \nis the smallest partial order between types = which includes =0 and such that, if sig(f)=[.1,...,.n], \nthen for all t1,...,tn,t1' ,...,tn' : .iti =.i ti '.f(t1,...,tn)=f(t1' ,...,t ') n We let be the symmetric \ntransitive closure of =. Every equiva\u00adlence class of this relation is a set of ground types which have \nthe same shape; on which the subtyping order =de.nes a lattice struc\u00adture [28]. It is straightforward \nto check that (Ts,=) satis.es the assumptions made in section 3 about the ground model of types. 5.2 \nThe constraint language In the forthcoming subsection 5.4, we will describe the solving al\u00adgorithm as \na small step reduction which rewrites constraints. As a consequence, constraints are not only used to \ndenote the problems produced by type inference, but also to describe their internal repre\u00adsentation in \nthe solver as well as intermediate steps of computation. Then, in the remainder of this section, we extend \nthe constraint lan\u00adguage as follows. Let a cset R be a multiset, interpreted as a conjunction, whose \nel\u00adements are elementary constraints of the form t1 = t2 or t1 t2. . fR ..(t 0t').R .(t)0.(t') . f..(f(a\u00af)=. \na).C ..t\u00af.(a)=f(t\u00af)and .[a\u00af.t\u00af]fC Figure 5. Interpretation of constraints (This second non-standard form \ndoes not improve the expressive\u00adness of the language: indeed, because each of s equivalence classes \nis a lattice, t1 t2 could be encoded by .a.(a =t1 .a = t2). However, the possibility to explicitly remove \nexistentially quanti.ed variables is mandatory in several steps of the algorithm.) Then, constraints \nare built on top of csets by the following gram\u00admar: C ::=R |C .t =t |.a.C |.\u00df\u00af.D =tC |..(f(a\u00af)=. a).C \nBy scope extrusion, we can restrict the right-hand-side of every conjunction to be a simple inequality \nrather than an arbitrary constraint without loss of expressiveness (see the full version of the paper \n[27] for the details). We made this presentation choice because it simpli.es the description of the algorithm \nand avoids some technical issues; however there is no theoretical dif.culty in generalizing the framework \nto an unrestricted conjunction. The last construct of the constraint language is part of the solver s \ninternal representation of constraints. Indeed, the algorithm is based on the possibility offered by \nstructural subtyping to ex\u00adpand types and decompose inequalities, as illustrated by the fol\u00adlowing example. \nConsider the constraint a = f(\u00df1,...,\u00dfn):ev\u00adery solution of this inequality maps a to a type whose root \nis f; hence we can expand this variable by introducing fresh vari\u00adables a1,...,an and rewriting the constraint \nas .a1 ...an.(a = f(a1,...,an).f(a1,...,an)=f(\u00df1,...,\u00dfn)). Besides, taking ad\u00advantage of this expansion, \nit is possible to decompose the inequality as a conjunction relating variables instead of type terms: \nthe above constraint is indeed equivalent to .a1 ...an.(a =f(a1,...,an). a1 =.1 \u00df1 .\u00b7\u00b7\u00b7.an =.n \u00dfn) (where \nsig(f)=[.1,...,.n]). Al\u00adthough it is logically correct, the result does not explicitly record the fact \nthat the variables a1,...,an have been introduced by the expansion, as names for a s sub-terms. This \nis why we provide a dedicated construct for binding variables generated by expansion: ..(f(a\u00af)=. a).C \nrequires a to be a f type and the fresh variables a\u00afare bound to its sub-terms in C. We moreover require \na not to ap\u00adpear free in C. This can naturally be encoded as .a\u00af.(f(a\u00af)=a.C). However, the former explicitly \nrelates the introduced variables a\u00afto the original one a, which guides the constraint solver. We extend \nthe interpretation of constraints to the new language in the natural way, see .gure 5 (0range over the \nsymbols =, =and ). We let an atom . be either a symbol of arity 0 or a type variable. A cset is atomic \nif and only if it involves only atoms, i.e. all its elements have the form .1 0.2. 5.3 Restricting universal \nquanti.cation We now explain the restriction our algorithm imposes on the form of constraints allowed \nin data-type declarations, and, thereby those which appear in the left-hand-side of .\u00df\u00af.D =tC constructs. \nIn fact, the restriction concerns not just the constraint D, but the pair of the list of quanti.ed variables \n\u00df\u00afand the constraint D, which we refer to as a quanti.cation bound. It is worth noting that supposing \nthe constraint D to have no ex\u00adistential quanti.er inside does not affect expressiveness: indeed, every \nvariable which is existentially quanti.ed in D can be made universally quanti.ed up front (e.g., with \nthe appropriate capture\u00adavoiding renamings, the constraint .\u00df\u00af.(.a.D)=tC is equivalent to .\u00dfa\u00af.D =tC). \nBesides, type constructors can be removed from quanti.cation bounds by the standard expansion and decomposi\u00adtion \nprocess. For instance .\u00df.(\u00df = a1 . a2)=tC is equivalent to .\u00df1\u00df2.(a1 =\u00df1 .\u00df2 =a2)=tC[\u00df1 . \u00df2/\u00df]. Similarly, \nthanks to the weak interpretation of universal quanti.cation, .\u00df1\u00df2.(\u00df1 . . \u00df2 =a)=tC can be rewritten \ninto ..(a =a1 .a2).(.\u00df1\u00df2.(a1 = \u00df1 .\u00df2 =a2)=tC[a1 .a2/a]). Combining these observations, it is natural \nto require the constraint of a quanti.cation bound .\u00df\u00af.D.\u00b7\u00b7\u00b7 to be a conjunction of in\u00adequalities involving \natoms (which, abusing notations, we consider to be a cset). These inequalities allow to relate together \nthe vari\u00ad \u00af ables of \u00df and to limit their range by some external bounds (i.e. ground atoms or variables \nnot in \u00df\u00af). So, considering a variable \u00df of \u00af \u00df, three situations may arise: 1. \u00df has no bound in D, \ni.e. is only related to variables of \u00df\u00af.In this case, no assumption can be made about its structure in \nthe right-hand-side of the implication: for instance, the constraint .\u00df.true=t(\u00df =a1 .a2)is not satis.able, \nbecause \u00df cannot be restricted to range only over arrow types. 2. \u00df has one lower and/or one upper bound(s) \nin D. Consider for instance the constraint C1 = .\u00df.(\u00df = a)=t(\u00df = a1 '. a' 2). Because of the weak semantics \nof ., this constraint implies .\u00df.(\u00df = a .\u00df = a' 1 . a' 2). Hence, any solution of C1 maps \u00df s bound, \na, to an arrow type. This allows expand\u00ading a as a1 . a2 and it remains to solve C2 = .\u00df.(\u00df = a1 . a2)=t \n(\u00df = a1 '. a' 2): C1 is indeed equivalent to  . ..(a =a1 .a2).C2. As explained above, C2 is equivalent \nto .\u00df1\u00df2.(a1 =\u00df1 .\u00df2 =a2)=t(a' 1 =\u00df1 .\u00df2 =a2' ). Because a1 (resp. a2) is the unique lower (resp. upper) \nbound of \u00df1 (resp. \u00df2), the latter can de.nitely be assigned to the former in the right-hand-side of \nthe implication. Then C2 naturally implies (a' 1 = a1 .a2 = a' 2). Next, it is easy to check that these \ntwo constraints are in fact equivalent, which completes the resolution. 3. \u00df has several lower or upper \nbounds in D. In this case, the same decomposition principle applies as in the previous case. However, \nit may produce constraints whose resolution is dif\u00ad.cult to deal with in an ef.cient manner. To illustrate \nthis point, let us consider the constraint C3 = .\u00df.(\u00df = a1 .\u00df = a2)=t (\u00df = a), which can be rewritten \nusing the least\u00adupper-bound operator of the lattice as syntactic sugar into .\u00df.(\u00df =a1 na2)=t(\u00df =a). By \nthe same reasoning as above, C3 is equivalent to (a1 na2 = a). However, the n operator now appears in \nthe left-hand-side of an inequality. Designing ef.cient algorithms for solving such inequalities seems \nto be a dif.cult problem, because they encode a form of disjunction. That is the reason why we will restrict \nour attention to the .rst two cases; as our examples will show, we believe they are expressive enough \nfor most usages (see section 6.2). We now precisely formalize the assumption we make about quan\u00adti.cation \nbounds. For this purpose, we introduce constraint graphs: a constraint graph G of size n is de.ned as \na subset of {1,...,n}\u00d7{1,...,n}. Then, given a list of n types t1,...,tn, we let the graph instance G \n[t1,...,tn]be the conjunction .{ti =t j |(i, j).G}.A node i is said to be the lower (resp. upper) bound \nof G if and only if for all j, the pair (i, j)(resp. (j,i)) belongs to G. Abusing terminol\u00adogy, we also \nsay in this case that ti is the lower (resp. upper) bound of G [t1,...,tn]. Then, we require the constraint \nD of any quanti.\u00adcation bound .\u00df\u00af.D. \u00b7\u00b7\u00b7 to be writable as a conjunction of graph instances G1[t\u00af1].\u00b7\u00b7\u00b7.Gn[t\u00afn] \nsuch that every variable of \u00df\u00afhas at most one occurrence in t\u00af1,...,t\u00afn, and, for all i, the graph instance \nGi[t\u00afi]is either unbounded: every term in t\u00afi is a variable of \u00df\u00af, or bounded: all variables in t\u00afi are \nin \u00df\u00af, except those of two terms of t\u00afi which are respectively lower and upper bounds of the graph. These \ncorrespond to the cases 1 and 2 of the above discussion, re\u00adspectively. Here are some examples of quanti.cation \nbounds: (1) .\u00df1\u00df2\u00df3.(\u00df1 =\u00df2 =\u00df3).\u00b7\u00b7\u00b7 (2) .\u00df1\u00df2.(a1 =\u00df1 =a2 .a1 =\u00df2 =a2).\u00b7\u00b7\u00b7 (3) .\u00df1\u00df2.(.1 =\u00df1 =\u00df2 =.2).\u00b7\u00b7\u00b7 \n Each of these three examples involve a single graph instance. In (1), the constraint \u00df1 =\u00df2 =\u00df3 is \nthe unbounded instance G1[\u00df1,\u00df2,\u00df3] of the graph G1 = {(1,2);(2,3)}. On the contrary, the graph in\u00adstances \nin (2) and (3) are bounded: in the former, the bounds are the free variables a1 and a2 and the latter \nis bounded by the ground atoms .1 and .2. An atom . is unbounded under the quanti.cation .\u00df\u00af.D.\u00b7\u00b7\u00b7 if \nand only if it is a variable of \u00df\u00afwhich appears in a unbounded graph of D. Otherwise, it is bounded. \nGiven a graph G, we let G. be G, Ge be the graph obtained by reversing every edge in G (i.e. {(i, j) \n| (j,i). G}) and G8 be G..Ge . We let bnd\u00df\u00af(D) be the set of inequalities a1 = a2 such that a1 and a2 \nare respectively lower and upper bounds of a graph instance of D. We write D* for the closure of D, that \nis the smallest cset which contains D, every trivial constraint a 0 a, and such that if .1 01 .2 . D* \nand .2 02 .3 .D* then .1 0102 .3 .D* .  5.4 The algorithm The constraint resolution algorithm consists \nin the reduction . de\u00ad.ned in .gure 6. Its broad outline is to rewrite the input constraint into a solved \nform S (in the case where the input constraint is not sat\u00adis.able, the algorithm can also return the \nspecial constant failure). Solved forms compose a subset of constraints de.ned as follows: S ::=R |..(f(a\u00af)=. \na).S In short, a solved form is a cset R preceded by a list of binders which record the type structure \nexhibited by expansion. The .rst group of rules in .gure 6 governs expansion and decom\u00adposition in a \ncset, with the purpose of making it atomic: rule (A) expands a variable which has some known structure \nand (B) decom\u00adposes an elementary constraint between two types with the same head constructor. If a cset \nrelates two incompatible types, then it is not satis.able, as re.ected by (C). The three next groups \nof rules deal with the constructs [].t1 =t2, .a.[] and .\u00df\u00af.D =t[], respectively: because they are not \nallowed in solved forms, they must be eliminated. Roughly speaking, these rules act by pushing down the \nconstruct at hand until it reaches the cset of the constraint; and then it can be eliminated by operating \non the cset. Sketching a parallel with an implementation, one could say that solved forms correspond \nto the memory representation of constraints; the three constructs of the constraint language stand for \nthe functions provided to the client of the implementation to incrementally build constraints; and the \nthree corresponding sets of Expansion and decomposition . (A) R . ..(f(a\u00af)= a).(R[f(a\u00af)/a]) a 0 f(t\u00af) \n. R,a\u00af#fv(R) (B) {f(t\u00af) 0 f(t\u00af')}. R . {t1 0.1 t1' ,...,tn 0.n t' }. R sig(f)=[.1,...,.n] n (C) {f(t\u00af) \n0 .(t\u00af')}. R . failure f = . Insertion of an inequality . . (D) (..(f(a\u00af)= a).S) .t1 = t2 . ..(f(a\u00af)= \na).(S .t1[f(a\u00af)/a] = t2[f(a\u00af)/a]) (E) R .t1 = t2 . R .{t1 = t2}  Existential quanti.cation . (F) .a.(..(f(a\u00af)= \na).S) . .a\u00af.S .. (G) .\u00df.(..(f(a\u00af)= a).S) . ..(f(a\u00af)= a).(.\u00df.S) \u00df . a\u00af (H) .a.R . {.1 0102 .2 | .1 01 \na,a 02 .2 . R;.1,.2 = a}. (R\\a) R atomic  Universal quanti.cation Scope-extrusion .. (I) .\u00df\u00af.D =t(..(f(a\u00af)= \na).S) . ..(f(a\u00af)= a).(.\u00df\u00af.D[f(a\u00af)/a]=tS) a . \u00df\u00af,a\u00af# (\u00df\u00af. fv(D)) . (J) .a\u00df\u00af.D =t(..(f(a\u00af)= a).S) . .a\u00af\u00df\u00af.D[f(a\u00af)/a]=tS \na bounded in D and a\u00af# (\u00df\u00af. fv(D)) . (K) . \u00af=.(f( \u00af= a).S) . failure \u00dfa.D t(.a) a unbounded in D Expansion \nand decomposition \u00af \u00dfa.D tR . . \u00afa.(D[f( \u00af=a)/a]) t) . D, \u00af (L) . \u00af=\u00df \u00afa)/a]) t(R[f( \u00af a 0 f(\u00afa #fv(D,R,\u00df) \n. \u00af (M) .\u00df\u00af.D =tR . ..(f(a\u00af)= a).(.\u00df\u00af.(D[f(a\u00af)/a]) =t(R[f(a\u00af)/a])) a 0 f(t\u00af) . D,a\u00af#fv(D,R,\u00df),a . \u00df\u00af \n(N) .\u00df\u00af.(D . G [f(t\u00af1),...,f(t\u00afk)]) =tR . .\u00df\u00af.(D .i G.i [t1,i,...,tk,i]) =tR sig(f)=[.1,...,.n] (O) .\u00df\u00af.(D \n.{f(t\u00af) = f'(t\u00af')})=tR . failure f = f' Elimination (P) .\u00df\u00af.D =tR . bnd\u00df\u00af(D) .{ub\u00df\u00af.D(.1) = lb\u00df\u00af.D(.2) \n| .1 = .2 . R\\D*} D and R atomic .{sk\u00df\u00af.D(.1) sk\u00df\u00af.D(.2) | .1 .2 . R\\D*} D and R atomic and \u00df 0 . . \n(R\\D*) (Q) .\u00df\u00af.D =tR . failure for some \u00df . \u00df\u00afunbounded in D  Contexts (R) C[C] . C[C'] if C .C' (S) \nC[failure] . failure  . C ::=[] . t = t |.a.[] |.\u00df\u00af.D =t[] |..(f(a\u00af)= a).[] Figure 6. Solving constraints \nin structural subtyping rules can be read as the (recursive) de.nition of these functions. Rules (D) \nand (E) deal with [] .t1 = t2: the former permutes a con\u00adjunction . with a binder . (because the variable \na is not allowed to . appear in the context ..(f(a\u00af)= a).[], it must be substituted in the types t1 and \nt2) while the latter removes an inner-most occurrence of . by inserting the inequality in the cset of \nthe constraint. Rules of the next group deal with existential quanti.cation: (F) and (G) intend to commute \nan existential quanti.cation .\u00df.[] with . a binder ..(f(a\u00af)= a).[].If \u00df is a then (F) applies and the \nquan\u00adti.cation on a disappears. Otherwise, the two quanti.ers can be safely commuted by (G). When an \nexistential quanti.cation reaches an atomic cset then it is eliminated by (H) which performs a local \ntransitive closure of the graph described by R. 0102 stands for the concatenation of 01 and 02, which \nis = (resp. =)if 01 and 02 are both = (resp. =) and otherwise; (R\\a) stands for the subset of R s constraints \nwhich do not involve a, i.e. {.1 0 .2 | .1 0 .2 . R and .1,.2 = a}. The fourth group of rules handles \nuniversal quanti.ers. Rules (I), (J) and (K) deal with binders . which appear in the right-hand-side \nof the implication. If the bound variable, a, is not captured by the universal quanti.cation, then the \ntwo quanti.ers may be commuted as re.ected by (I). It is worth noting that, in general, existential and \nuniversal quanti.ers cannot be swapped; however this is possi\u00adble with the restricted form of existential \nquanti.cation provided by binders . , because the introduced variables a\u00afare indeed fully de\u00adtermined \nby a. The cases where the variable a is universally bound are handled by (J) and (K): if a appears in \nan unbounded graph of D then the latter applies: the constraint is not satis.able because a cannot be \nconstrained to range only over f types. On the contrary, if a has bounds in D, it is possible to require \nthem to be f types, hence (J). Rules (L)to (O) perform expansion and decomposition of the constraint \nD which delimits the range of universal quanti.\u00adcation. In conjunction with (A) and (B) they aim at making \nR and D both atomic. Lastly, rule (P) allows the elimination of universal quanti.ers by rewriting a constraint \nof the form .\u00df\u00af.D =tR where D and R are atomic into a simple cset. The built cset .rst contains bnd\u00df\u00af(D), \nwhich is equivalent to .\u00df\u00af.D. Second, the algorithm con\u00ad siders every constraint .1 0 .2 of the cset \nR. Two cases may arise: if it appears in D*, then it is satis.ed by any solution of D so that it can \nbe forgotten. Otherwise, another elementary constraint, which is necessary and suf.cient for every solution \nof D to satisfy .1 0 .2 (i.e. equivalent to .\u00df\u00af.D =t.1 0 .2), is generated: In the case where .1 0 .2 \nis .1 = .2, we consider the greatest assignment ub\u00af(.1) the atom .1 may receive in the quan\u00ad \u00df.Dti.cation \nbound .\u00df\u00af.D . \u00b7\u00b7\u00b7:if .1 is not one of the quanti\u00ad.ed variables (i.e. .1 . \u00df\u00af), ub\u00df\u00af.D(.1) is naturally \n.1 itself; if .1 . \u00df\u00afand .1 is bounded in D then ub\u00af(.1) is the unique \u00df.Dlower bound of .1 in D. We \nsymmetrically de.ne lb\u00af(.2) \u00df.Dand generate the constraint ub\u00af(.1) = lb\u00af(.2). \u00df.D\u00df.D The case where .1 \n0 .2 is .1 .2 is dealt with similarly. We let sk\u00af(.) be a representative of . s equivalence class \u00df.D \nunder the bound .\u00df\u00af.D .\u00b7\u00b7\u00b7, e.g. lb\u00af(.) or ub\u00af(.). Then \u00df.D\u00df.Dthe constraint sk\u00af(.1) sk\u00af(.2) is generated. \n\u00df.D\u00df.D If one of .1 and .2, say .1, is unbounded in .\u00df\u00af.D .\u00b7\u00b7\u00b7,lb\u00af(.1), \u00df.Dub\u00af(.1) and sk\u00af(.1) are not \nde.ned. Then, (P) cannot be ap\u00ad \u00df.D\u00df.D plied, but (Q) yields a failure. Because recursive types are not \nvalid solutions for constraints in the ground model, one must ensure that the elementary constraints \nof a solved form do not require cyclic type structures. This veri.ca\u00adtion is commonly referred to as \nthe occur-check; because it is stan\u00addard, we omit its formal description which can be found in previ\u00adous \nworks [28]. What is more, this check is necessary to guarantee the termination of expansion and decomposition: \nas a consequence, it must be performed when expanding a cset or the quanti.cation bound of the inner-most \nuniversal quanti.cation, if any. In the full version of this paper [27], we give a formal proof that \nthe reduction de.nes an algorithm rewriting constraints that satisfy the occur-check into an atomic solved \nform or fails. This addresses the question of constraint resolution. Indeed, solving atomic solved forms \nis a well-known issue [6]: it only requires to check that every path between ground atoms in the graph \nde.ned by the inequalities of the cset is valid w.r.t. the partial order =0.   6 Discussion and examples \n6.1 On possible extensions The programming language studied in this paper is reduced to its core. However, \nit can naturally be extended by adding constants in the language, appropriate d-rules in the semantics, \nnew type con\u00adstructors and the corresponding typing rules, which should not raise any particular issue. \nFurthermore, the solving algorithm of sec\u00adtion 5 is already equipped for such extensions, because it \nmakes no particular assumption about the set of type constructors. We did not introduce in the description \nof the solving procedure any procedure for simplifying constraints; nevertheless, such tech\u00adniques are \nmandatory to obtain ef.cient and scalable algorithms. In [28], we formalized a complete resolution framework \n(for stan\u00addard structural subtyping constraints) that includes a series of sim\u00adpli.cation techniques, \nmany of which rely on polarities assigned to type variables. These techniques can be generalized in the \npresence of universal quanti.ers, considering universally quanti.ed variables as bipolar. What is more, \nbecause the mechanism described in sec\u00adtion 5 permits to incrementally eliminate universal quanti.cations \nfrom constraints, extending an existing constraint solver for struc\u00adtural subtyping can be done with \na limited effort. Indeed, a rea\u00adsonable strategy consists in, every time a constraint .\u00df\u00af.D =t S is built, \nsimplifying the constraint S, and then eliminating the univer\u00adsal quanti.cation. Such an extension would \npreserve most of the existing implementation, in particular the internal representation of constraints. \nIt would be an interesting question to design algorithms for solv\u00ading constraints generated by HM..(X) \nwhich handle other forms of subtyping. We considered the case of non-structural subtyping where the set \nof types forms a lattice, as in [22]. Limiting quan\u00adti.cation bounds to be conjunctions of inequalities \nbetween univer\u00adsally quanti.ed variables, we believe it is possible to solve the con\u00adstraints generated \nby HM..(X) s inference algorithm by consider\u00ading these variables as new symbols in the types lattice \nas Skolem types and to translate the constraint bounding quanti.cation as axioms about the order between \nsymbols. However, further studies are necessary to precisely formalize and prove this possibility. Lastly, \nseveral researchers have recently proposed conservative ex\u00adtensions of ML which offer higher-order polymorphism \nin a more .exible way. Odersky and L\u00a8aufer [17] studied a type system that al\u00adlows explicit type scheme \nannotations for function arguments. Gar\u00adrigue and R\u00b4emy designed PolyML [7], where the elimination of \npolymorphic types is said semi-explicit: the source code must men\u00adtion only the points where polymorphic \nvalues are used, their types can be inferred. Subsuming PolyML, MLF [11] made the opening of polymorphic \nvalues fully implicit. Actually, these works rely on uni.cation mechanisms and do not consider subtyping; \nextending them in this direction remains to be explored. Other proposals try to combine subtyping in \ncombination with higher-order polymor\u00adphism and type inference [3, 21, 19]; however, they fail to type \nall ML programs. 6.2 On information .ow analysis We plan to integrate the mechanism of abstract and \npolymorphic data-types described in the current paper in the Flow Caml system, our prototype information \n.ow analyzer for the Caml language. We here give a taste of that by considering some examples, which \nillus\u00adtrate the expressiveness of HM..(X) in a concrete setting. For the sake of simplicity, we omit \nsome of the security annotations in Flow Caml types (in particular those on top of .), because they are \nout of the topic of the current paper. We follow up on the example of a bank s clients .le introduced \nin section 2. As we have explained, the type of every value giving some information about a client is \nlabeled by its security level: for instance !alice int is the type of an integer carrying information \nabout the client !alice. The set of security levels is supposed to be equipped with a lattice structure, \nso we have in particular a security level !clients which is the least upper bound of all clients security \nlevels. The framework presented in the current paper allows to get round the problem we pointed out in \nsection 2 by de.ning the type client_info as follows: type client_info = Exists a with a < !clients . \n{ cash : a int; send_msg : a int -> unit; ... } This declaration mentions one existentially quanti.ed \nvariable, a, which is the security level of the client, hence it must be less than !clients, as re.ected \nby the constraint a < !clients which bounds the quanti.cation (the lower bound of a is implicitly the \nbottom element, ., of the security level lattice). Because a is local to the declaration, it does not \nappear as a parameter of the type. As a result, all client records have the same type, client_info, and \ncan be stored in a list of type client_info list. Then, one may de.ne a function which iterates on a \nlist of clients and sends to each of them a message containing its current balance: let rec send_balances \n= function [] -> [] | { cash = x; send_msg = send } :: tl -> send x; send_balances tl We combine the \nelimination of the existential quanti.cation with the matching of the record structure, which allows \nan intuitive and lightweight syntax. De-sugaring this example in the syntax of the current paper, we \nrealize that the function which corresponds to the second case of the pattern matching .x.send.tl.(send \nx;send balances tl) must, to preserve type abstraction, have a type scheme where the security level of \nthe integer x and f s argument can range over all levels less than !clients, i.e. .a[a =!clients]. a \nint .(a int .unit).client info list .unit which is naturally the case in our example. On the contrary, \ncon\u00adsider the following ill-typed piece of code: let illegal_flow = function {cash=x1} ::{send_msg = \nf2 }::_-> f2x1 |_ -> () In the case where the clients list comprises at least two entries, this function \nsends the balance of the .rst client to the second one. This is not allowed by the bank s security policy \nand rejected by the type system: in the .rst clause of the pattern-matching, the pattern in\u00adtroduces \ntwo variables, \u00df1 and \u00df2, which are the respective existen\u00adtially quanti.ed variables of the two opened \nrecords, ranging inde\u00adpendently on security levels less than !clients. The clause s body requires \u00df1 \nto be less than or equal to \u00df2, this yields the constraint .\u00df1\u00df2.(\u00df1 \u00df2 =!clients)=t (\u00df1 =\u00df2) which is \nnot satis.able, hence the typing failure. Our next example is a function which computes the total balance \nof the bank from a clients .le: let rec total = function [] -> 0 |{ cash=x }::tl-> x+total tl The result \nof total is an integer which is likely to carry informa\u00adtion about any opened record, hence it must be \nlabeled by the least upper bounds of their security levels, which is !clients. Hence, this function receives \nthe type client info list .!clients int. As pointed out in the introduction, high order functions operat\u00ading \non existential types generally require second order polymorphic types. For instance, let us try to write \na function check which takes as argument a record and a function which performs some compu\u00adtation on \nthe client s balance: letcheckf{cash=x; send_msg = send}= send (f x) To preserve abstraction, this de.nition \nrequires the function f to have the type !clients int ..int, i.e. to accept any argument whose level \nis less than or equal to !clients and to produce a result of level .. Such a type constrains f s result \nnot to depend on its argument, which is naturally not acceptable. A solution consists in packing the \nfunction f in a polymorphic data-type: type t =ForAll a . {op: a int -> a int } This allows to write: \nletcheck{op= f} { cash = x; send_msg = send } = send (f x) which has the type t -> client_info -> unit. \nIn fact, the data-type t provides an encoding of second order polymorphic types; some syntactic sugar \navoiding the prior declaration of the type t would be convenient in such a situation. Our main direction \nfor future work is to study the possibility to make security levels also values of the Flow Caml language. \nThis would permit some dynamic tests whose correctness must be ver\u00adi.ed statically on existentially quanti.ed \nvariables when opening data structures. Continuing with our example, this would allow for instance computing \nthe total balance of a subset of clients.  7 REFERENCES [1] A. S. Aiken and M. F\u00a8ahndrich. Program analysis \nusing mixed term and set constraints. In Static Analysis Symposium, 1997. [2] L. Augustsson. Haskell \nB. user s manual, 1994. [3] L. Cardelli. An implementation of FSub. Technical Report 97, Digital Equipment \nCorporation Systems Research Center, 1993. [4] S. Conchon and F. Pottier. JOIN(X): Constraint-based type \ninference for the join-calculus. In European Symposium on Programming, 2001. [5] J. S. Foster, T. Terauchi, \nand A. Aiken. Flow-sensitive type quali.ers. In Pro\u00adgramming Language Design and Implementation, 2002. \n[6] Y.-C. Fuh and P. Mishra. Polymorphic subtype inference: Closing the theory\u00adpractice gap. In European \nJoint Conference on Theory and Practice of Software Development, 1989. [7] J. Garrigue and D. R\u00b4emy. \nExtending ML with semi-explicit higher-order poly\u00admorphism. Journal of Functional Programming, 155(1/2), \n1999. [8] F. Henglein and J. Rehof. The complexity of subtype entailment for simple types. In Symposium \non Logic in Computer Science, 1997. [9] M. Hoang and J. C. Mitchell. Lower bounds on type inference with \nsubtypes. In Principles of Programming Languages, 1995. [10] V. Kuncak and M. Rinard. Structural subtyping \nof non-recursive types is decid\u00adable. In Symposium on Logic in Computer Science, 2003. [11] D. Le Botlan \nand D. R\u00b4emy. MLF: Raising ML to the power of system F. In International Conference on Functional Programming, \n2003. [12] X. Leroy, D. Doligez, J. Garrigue, D. R\u00b4emy, and J. Vouillon. The Objective Caml system. http://caml.inria.fr/. \n[13] M. Mauny and F. Pottier. An implementation of Caml Light with existential types. Research Report \n2183, INRIA, 1993. [14] J. Mitchell and G. Plotkin. Abstract types have existential types. ACM Transac\u00adtions \non Programming Languages and Systems, 10(3), 1988. [15] J. C. Mitchell. Type inference with simple subtypes. \nJournal of Functional Programming, 1(3), 1991. [16] M. Odersky and K. L\u00a8aufer. An extension of ML with \n.rst-class abstract types. In Workshop on ML and its Applications, 1992. [17] M. Odersky and K. L\u00a8aufer. \nPutting type annotations to work. In Principles of Programming Languages, 1996. [18] M. Odersky, M. Sulzmann, \nand M. Wehr. Type inference with constrained types. Theory and Practice of Object Systems, 5(1), 1999. \n[19] M. Odersky, C. Zenger, and M. Zenger. Colored local type inference. ACM SIGPLAN Notices, 36(3), \n2001. [20] N. Perry. The Implementation of Practical Functional Programming Languages. PhD thesis, 1990. \n[21] B. C. Pierce and D. N. Turner. Local type inference. ACM Transactions on Programming Languages and \nSystems, 22(1), 2000. [22] F. Pottier. A versatile constraint-based type inference system. Nordic Journal \nof Computing, 7(4), 2000. [23] F. Pottier. A semi-syntactic soundness proof for HM(X). Research Report \n4150, INRIA, 2001. [24] F. Pottier and V. Simonet. Information .ow inference for ML. ACM Transactions \non Programming Languages and Systems, 25(1), 2003. [25] D. R\u00b4emy. Programming objects with ML-ART: An \nextension to ML with abstract and record types. In Theoretical Aspects of Computer Science, 1994. [26] \nV. Simonet. Flow Caml, information .ow inference in Objective Caml. http: //cristal.inria.fr/~simonet/soft/flowcaml/, \n2003. [27] V. Simonet. An extension of HM(X) with bounded existential and universal data-types. Full \nversion. http://cristal.inria.fr/~simonet/publis/ simonet-ifcp03-full.ps.gz, 2003. [28] V. Simonet. Type \ninference with structural subtyping: The faithful formalization of an ef.cient constraint solver. Submitted \nfor publication. http://cristal. inria.fr/~simonet/publis/simonet-structural-subtyping.ps.gz, 2003. [29] \nM. Sulzmann, M. Odersky, and M. Wehr. Type inference with constrained types. In Workshop on Foundations \nof Object-Oriented Languages, 1997. [30] J. Tiuryn. Subtype inequalities. In Symposium on Logic in Computer \nScience, 1992. [31] A. K. Wright. Polymorphism for imperative languages without imperative types. TR \n93-200, Rice University, 1993.  \n\t\t\t", "proc_id": "944705", "abstract": "We propose a conservative extension of HM(<i>X</i>), a generic constraint-based type inference framework, with bounded existential (a.k.a. abstract) and universal (a.k.a. polymorphic) data-types. In the first part of the article, which remains abstract of the type and constraint language (i.e. the logic <i>X</i>), we introduce the type system, prove its safety and define a type inference algorithm which computes principal typing judgments. In the second part, we propose a realistic constraint solving algorithm for the case of structural sub-typing, which handles the non-standard construct of the constraint language generated by type inference: a form of bounded universal quantification.", "authors": [{"name": "Vincent Simonet", "author_profile_id": "81100608449", "affiliation": "INRIA Rocquencourt", "person_id": "P343137", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/944705.944710", "year": "2003", "article_id": "944710", "conference": "ICFP", "title": "An extension of HM(X) with bounded existential and universal data-types", "url": "http://dl.acm.org/citation.cfm?id=944710"}