{"article_publication_date": "08-25-2003", "fulltext": "\n Dependency-style Generic Haskell Andres L\u00a8oh Dave Clarke Johan Jeuring andres@cs.uu.nl dave@cs.uu.nl \njohanj@cs.uu.nl Institute of Information and Computing Sciences Utrecht University P.O. Box 80.089 3508 \nTB Utrecht, the Netherlands  ABSTRACT Generic Haskell is an extension of Haskell that supports the construction \nof generic programs. During the development of several applications, such as an XML editor and compres\u00adsor, \nwe encountered a number of limitations with the exist\u00ading (Classic) Generic Haskell language, as implemented \nby the current Generic Haskell compiler. Speci.cally, generic de.nitions become disproportionately more \ndi.cult to write as their complexity increases, such as when one generic func\u00adtion uses another, because \nrecursion is implicit in generic de.nitions. In the current implementation, writing such functions su.ers \nthe burden of a large administrative over\u00adhead and is at times counter-intuitive. Furthermore, the absence \nof type checking in the current implementation can make Generic Haskell hard to use. In this paper we \ndevelop the foundations of Dependency\u00adstyle Generic Haskell which addresses the above problems, shifting \nthe burden from the programmer to the compiler. These foundations consist of a full type system for Depen\u00addency-style \nGeneric Haskell s core language and appropriate reduction rules. The type system enables the programmer \nto write generic functions in a more natural style, taking care of dependency details which were previously \nthe programmer s responsibility. Categories and Subject Descriptors D3.3 [Programming Languages]: Language \nconstructs and features  General Terms Languages, Design, Theory  Keywords Generic Haskell, Generic \nprogramming, functional program\u00adming, type systems Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. ICFP 03, August 25 29, 2003, Uppsala, Sweden. Copyright 2003 ACM \n1-58113-756-7/03/0008 ...$5.00. 1. INTRODUCTION Generic programming simpli.es a programmer s job. No \nmore need a programmer write functions such as map or fold or pretty print for her data structures. These \ncan be written once and for all as a generic de.nition and applied automatically to all of the programmer \ns datatypes, even as those datatypes evolve. In Classic Generic Haskell, a Haskell extension based on \nideas due to Hinze [13, 16, 18], generic functions can be writ\u00adten which are applicable to Haskell datatypes \nof all kinds. Generic functions are easy to write. Cases are supplied for sums and products, for the \nunit datatype, for primitives, and for constructors. The type of each case follows a partic\u00adular pattern. \nTo produce a generic instance for some type, Hinze s theory dictates how a compiler assembles cases to\u00adgether \nfollowing the structure of the type to produce well\u00adtyped code. We have experimented quite a lot with \nthe Classic Generic Haskell compiler and implemented a number of advanced generic programs such as digital \nsearching, the zipper, and XML tools such as a compressor, an editor, and a database. For all Classic \nGeneric Haskell s simplicity, however, some complexity remains to hamper us as soon as we write generic \nfunctions for these more involved applications. Rather than write generic de.nitions in the natural recursive \nstyle mod\u00adern programmers are accustomed to, as in map(Prod a b) (a, b)=(map(a) a, map(b) b), the theory \nunderlying Classic Generic Haskell dictates that we supply additional parameters for the recursive invoca\u00adtions \nof generic functions, as in map(Prod) mapa mapb (a, b)=(mapa a, mapb b). The additional arguments mapa \nand mapb are used to de\u00adnote the recursive instances of map at the types for the arguments of the product. \nThese function arguments are supplied with the appropriate value when the compiler gen\u00aderates code. When \nusing a generic function that depends upon another generic function, the number of parameters increases \nand functions must be tupled together, and unpacked when re\u00adquired. We must write something like foobar(Prod) \n(fooa, bara)(foob, barb)(x, y)= (de.nition of foo, de.nition of bar ) rather than the more natural foo \n(Prod a b) (x, y) = de.nition of foo bar (Prod a b) (x, y) = de.nition of bar . The reason for the complications \nis that we do not have access to the type arguments, only to the recursive calls of the function being \nde.ned. That means, for instance, that we cannot access bar (a) while de.ning foo(Prod) as a stand-alone \nfunction. The language forces the function into the structure of a catamorphism, but sometimes this .xed \nrecursion pattern is not a good match for the algorithm one wants to implement, resulting in unnecessarily \ncomplex and nearly unmaintainable code. Our present goal is to move this complexity from the user to \nthe compiler. This shift enables the programmer to write her code in a natural style, leaving the dependency \ncon\u00adstraints to the type system. The result is not only a ratio\u00adnal reconstruction of Classic Generic \nHaskell, which we dub Dependency-style Generic Haskell, in doing so we gain in expressivity, enabling \nexamples which were previously only possible using unnatural coding practices. From a larger perspective, \nwe provide a .rm founda\u00adtion which not only goes beyond the foundation for Clas\u00adsic Generic Haskell, \nbut opens the door to tackle problems which had previously seemed too far o.. Future possibilities include \nbetter support for type-indexed types, higher-order and locally de.ned generic functions, dependency \ninference, type inference of kind-. type arguments, generic functions based on kinds other than *, and \npattern matching on type arguments. The paper is organized as follows. Section 2 presents some motivating \nexamples. Section 3 describes the core calcu\u00adlus. Section 4 presents type rules for checking well-formed \nexpressions along with their dependency information. Sec\u00adtion 5 gives the reduction semantics of the \ncalculus. Sec\u00adtion 6 describes related work. Section 7 discusses what we have achieved here, and points \nto future work. In this paper we use Classic Generic Haskell to refer to earlier versions of Generic \nHaskell, as implemented in the Amber and Beryl [5] versions of the compiler. This paper de\u00adscribes the \nfoundations of Dependency-style Generic Haskell. When no confusion will arise, we use Generic Haskell \nto refer to Dependency-style Generic Haskell. 2. EXAMPLES This section introduces Dependency-style Generic \nHaskell through a number of examples. 2.1 Generic equality The equality function takes two values of \na datatype and compares them. In Haskell the equality function can be derived for a user-de.ned datatype, \nas in data Bush = Leaf Int | Bin Bush Bush deriving Eq. In Generic Haskell we can de.ne the generic equality \nfunc\u00adtion. A datatype consists essentially of sums, products, base types like Int, and a unit type. Sums, \nproducts and unit can be viewed as Haskell datatypes as follows: data Unit = Unit data Sum ab = Inl a \n| Inr b data Prod a b =(a, b). We need to de.ne equality only on these types to obtain an equality function \nfor an arbitrary datatype. In Classic Generic Haskell, this is coded as follows. type Eq( *) t = t . \nt . Bool type Eq( .1 . .2) t = .u.Eq( .1) u . Eq( .2) (tu) eq(t :: .) :: Eq( .) t eq(Int) ij = eqInt \ni j eq(Unit) Unit Unit = True eq(Sum) eqa eqb (Inl a)(Inl a')= eqa a a . eq(Sum) eqa eqb (Inr b)(Inr \nb')= eqb b b. eq(Sum) eqa eqb = False eq(Prod) eqa eqb (a, b)(a . , b')= eqa a a . . eqb b b. This de.nition \nconsists of a kind-indexed type, a type signa\u00adture assigning the kind-indexed type to eq,and several \ncases de.ning eq for the basic datatypes. Using this de.nition, the Classic Generic Haskell compiler \ngenerates a de.nition of eq(Bush), which is used to compare two Bush values [18]. The function eq is \na generic function which recurses over the type structure of its argument type. The recursion is implicit \nin the arguments eqa and eqb in the Sum and Prod cases. We would rather write the following de.nition, \nwhich is how we de.ne equality in Dependency-style Generic Haskell. eq(Int) ij = eqInt i j eq(Unit) Unit \nUnit = True eq(Sum da db) (Inl a)(Inl a')= eq(da) aa . eq(Sum da db) (Inr b)(Inr b')= eq(db) bb. eq(Sum \nda db) = False eq(Prod da db) (a, b)(a . , b')= eq(da) aa . . eq(db) bb. The recursion over the type \nstructure is explicit: the case eq(Prod da db) is expressed in terms of eq(da) and eq(db).We think this \nstyle is more readable, especially when a generic function depends on another generic function. Functions \nwritten in the this style can be translated to the former style, so no expressiveness is lost; the only \ndi.erence is readability. We write da for a type variable that appears in a type index and call it a \ndependency variable.Thus we syntac\u00adtically distinguish quanti.ed type variables from type vari\u00adables \nthat may appear in a type index. It is not necessary to make this distinction, but it simpli.es the terminology \nin later discussions. A dependency variable introduces a de\u00adpendency. For example, if we write eq(List \nda), then this function depends on the function eq(da). Depending on means that in order to call function \neq(List da) on two lists, we need a function eq(da) that determines equality of the values in the list, \nas in the following example, (let eq(da) = .x . .y . eqInt x y in eq(List da) [1, 2, 3] [1, 2, 3], let \neq(da) = .c . .d . toUpper c = toUpper d in eq(List da) \"Hello\" \"HELLO\") which has value (True, True). \nThe type of the Classic (i.e., the .rst) version of eq is the kind-indexed type Eq. Consider the case \neq(Prod).The product type has kind . . . . *, and hence eq(Prod) takes an equality function for the left \ncomponent of the prod\u00aduct, and an equality function for the right component of the product, and only \nthen takes two product values. The second line of a kind-indexed type has the same structure for any \nimplicitly recursive generic function. The type of equality on a type of kind .1 . .2 is a function from \nthe type of equality for kind .1 to the type of equality for kind .2. This structure is enforced by the \ntranslation method used in Generic Haskell. In the case of the dependency-style de.nition, a type index \nalways has kind *, but in turn may contain dependency variables, so a kind-indexed type in the classic \nsense is not an option. If we ignore dependency vari\u00adables, we have the following type for function eq \non types t of kind *. eq(t) :: t . t . Bool If a type argument of a generic function contains a depen\u00addency \nvariable, and the generic function uses a (possibly di.erent) generic function in its de.nition, then \nthe type records a dependency constraint for the dependency vari\u00adable. For example, the generic function \neq only uses itself, so for the type List da we get the following type. eq(List da) :: .a.(eq(da) :: \na . a . Bool) . List a . List a . Bool It turns out that all information about the type of a generic \nfunction can be calculated from the base case for a single dependency variable of kind *.For eq this \nis eq(da) :: .a.(eq(da) :: a . a . Bool) . a . a . Bool. The type of eq on a type with a kind other than \n*, possibly containing many dependency variables, is a generalization of this type. We make this explicit \nby abstracting over the types a and da using the generalize construct, and applying the expression obtained \nto the type on which we want an instance of the equality function. eq(t) :: (generalize (da) a . (eq(da) \n:: a . a . Bool) . a . a . Bool) t In Section 4 we explain how to calculate instances of a gen\u00aderalized \ntype. 2.2 Huffman coding in XComprez XComprez is a generic compressor for XML documents [12]. XComprez \nseparates an XML document into its struc\u00adture (the markup) and its contents (the strings). The DTD that \ndescribes the structure of the document is translated to a Haskell datatype, and the structure of the \ndocument is translated to a value of this datatype. Using knowledge about the DTD (and the datatype to \nwhich it is translated), the structure of an XML document can be compressed con\u00adsiderably; the contents \nare compressed by means of a stan\u00addard compressor. To improve the compression of the contents, we apply \nthe following variant of Hu.man coding. Given an input value, we calculate the number of occurrences \nof each constructor. Given the number of occurrences of each constructor, we calculate the optimal Hu.man \nencoding for the particular value, and we encode the value using this encoding. The function conCount \ncalculates the number of occur\u00adrences of each constructor in a value of a datatype: conCount(t) :: (generalize \n(da) b . (conCount(da) :: b . [(ConDescr , Int)]) . b . [(ConDescr , Int)]) t. The function conCount \nis used in encode encode(t) :: (generalize (da) b . (conCount(da) :: b . [(ConDescr , Int)], encode'(da) \n:: b . [(ConDescr , Int)] . [Bit ]) . b . [Bit ]) t encode(da) x = let table = conCount(da) x in encode'(da) \ntable x, where encode' is the generic function that encodes each con\u00adstructor as a list of bits [12]. \nThis is an example of a generic abstraction [6]: a generic function de.ned in terms of one or more other \ngeneric functions instead of recursively over the type structure. Function encode is an example where \nthe dependency constraints contain dependencies on other generic functions, unlike function eq which \nonly contains the constraint that is identical to the type itself. 2.3 Pretty-printing important information \nSuppose we want to pretty-print a value of a datatype, but only parts which satisfy some condition. For \nexample, we only want to print trees that have at least a certain height, or we only want to print balanced \ntrees. Suppose we have a generic function important that determines whether or not to print a subtree. \nimportant(t) :: (generalize (da) b . (important(da) :: b . Bool) . b . Bool) t The function print depends \non function important. print(Int) = printInt print(Unit) = printUnit print(Sum da db) (Inl a)= if important(da) \na then print(da) a else \"...\" print(Sum da db) (Inr b)= if important(db) b then print(db) b else \"...\" \nprint(Prod da db) (a, b)= if important(da) a then if important(db) b then print(da) + print(db) b else \nprint(da) a + \"...\" else if important(db) b then \"...\" + print(db) b else \"...\" The dependency shows \nin the type of function print: print(t) :: (generalize (da) b . (important(da) :: b . Bool, print(da) \n:: b . String) . b . String) t. This is an example of a generic function de.ned recursively over the \ntype structure, which depends on another generic function. In Classic Generic Haskell, we would have \nto pair the de.nitions of print and important, de.ning two essen\u00adtially separate aspects at the same \ntime. 2.4 Traversal functions To illustrate the extensibility Generic Haskell provides, we present a \nseries of modi.cations to a running example. Adapting from L\u00a8ammel and Peyton Jones [25], we use the \nfollowing datatypes to represent the organizational structure of a company. data Company = C [Dept ] \ndata Dept = D Name Manager [SubUnit ] data SubUnit = PU Employee | DU Dept data Employee = E Person Salary \ndata Person = P Name Address data Salary = SFloat type Manager = Employee type Name = String type Address \n= String Update Salaries. We wish to update a Company value, which involves giving every Person a 15% \npay rise. To do so requires visiting the entire tree and modifying every occur\u00adrence of Salary. The implementation \nrequires pretty stan\u00addard boilerplate code which traverses the datatype, until it .nds Salary, where \nit performs the appropriate update itself one line of code before reconstructing the result. In Generic \nHaskell writing this function requires but a few lines. The code is based on the standard generic map: \nmap(t) :: (generalize (da) a1 a2 . (map(da) :: a1 . a2) . a1 . a2) tt map(Unit) v = v map(Int) v = v \nmap(Sum da db) (Inl a)= Inl (map(da) a) map(Sum da db) (Inr b)= Inr (map(db) b) map(Prod da db) (a, b) \n=(map(da) a, map(db) b). The generalized type of map takes two arguments so that it canbe usedinthe type \nmodifyingway we are usedto. With only one argument it would degenerate to the generic iden\u00adtity function \n[14]. This is our .rst example of a generalized type that takes more than one type argument. The code \nto perform the updating is given by the following three lines, the .rst of which is the necessary type \nsignature, the second states that the function is based on map, though it introduces an additional parameter \nwhich is automatically threaded through the computation, and the third performs the update of the salary, \nusing the threaded value. The extends construct denotes that the cases of map are copied into update. \nThese are the default cases describedinClarke and L\u00a8oh [6]. (This is, in e.ect, a preprocessing step \nand thus extends does not appear in the calculus.) update(t) :: (generalize (da) a . (update(da) :: Float \n. a . a) . Float . a . a) t update(da) p extends map(da)update(Salary) p (Ss)= S (s \u00b7 (1+ p)) The introduction \nof the new threaded variable p is impos\u00adsible in Classic Generic Haskell. Being able to do this is a \nsmall but signi.cant advance over our previous work. Update Update Salaries . Political forces require \nthat the code be changed so that only marketing gets a raise, of 25%, as well as giving a certain manager \na 10% raise. Being versed in generic programming enables the programmer to update the previous code as \nfollows: updateNew (t) :: (generalize (da) a . (updateNew (da) :: Float . a . a) . Float . a . a) t updateNew \n(da) extends update(da)updateNew (Dept) p (D name manager subunits)= let newp = if name = \"marketing\" \nthen 0. 25 else p in D name manager (updateNew(SubUnit) newp subunits) updateNew (Employee) p (E person \nsalary)= let newp = if person = daevclarke then 0. 1 else p in Eperson (updateNew(Salary) newp salary). \nSeparating Matching from Updating. Understanding the social nature of management structures, the programmer \nwrites her code more generally by separating the updating of salaries from the code which determines \nwho gets what pay rise. A match function performs a test on a part of the or\u00adganizational structure. \nThe result of the function is one of: NoMatch indicating that no work need be done to that part; Value \nn indicating that the value, presumably the amount of the pay rise, needs to be applied to this part \nof the tree; and .nally Inconsistent indicating that di.erent subparts of the same part require di.erent \ninconsistent updates which requires recursion to further distinguish the parts. This is captured using \nthe following datatype and operation: data Data a = NoMatch | Value a | Inconsistent (.. ):: (Eq a) . \nData a . Data a . Data a NoMatch .. NoMatch = NoMatch (Value a) .. (Value b)= if a = b thenValue a else \nInconsistent .. = Inconsistent. Using the generic function known as crush,which is agen\u00aderalization of \nfold, crush(t) :: (generalize (da) a . (crush(da) :: b . (b . b . b) . a . b) . b . (b . b . b) . a \n. b) t crush(Unit) eop = e crush(Int) eop = e crush(Sum da db) eop (Inl a)= crush(da) eopa crush(Sum \nda db) eop (Inr b)= crush(db) eopb crush(Prod da db) eop (a, b)= op (crush(da) eopa) (crush(db) eopb), \nthe basis for all match functions is matchBase(t) :: (generalize (da) a . (matchBase(da) :: a . Data \nb) . a . Data b) t matchBase(da) extends crush(da) NoMatch (.. ). This match function can be specialized \nto perform the match that we are interested in, as follows. match(t) :: (generalize (da) a . (match(da) \n:: a . Data Float) . a . Data Float) t match(da) extends matchBase(da)match(Dept) (Dname )= if name = \n\"marketing\" then (Value 0. 25) else NoMatch match(Employee) p (Eperson )= if person = daevclarke then \n(Value 0. 1) else NoMatch The update function can now refer to this match function, though their code \ncan evolve separately. This is where the dependency information of Generic Haskell comes in. updatePre(t) \n:: (generalize (da) a . (updatePre(da) :: Float . a . a, update(da) :: Float . a . a, match(da) :: a \n. Data Float) . Float . a . a) t updatePre(da) extends update(da) updatePre(Con da) pc@(Con a)= case \nmatch(Con da) c of Value newp . Con $ update(da) newp a NoMatch . c Inconsistent . Con $ updatePre(da) \npa The Con-case is applied at the constructor positions in a value. This code can be converted to an \nordinary Haskell value by specializing it to our Company datatype as follows: updateGrand :: Float . \nCompany . Company updateGrand = updatePre(Company). 2.5 Further Applications Other applications which \nbene.t from Dependency-style Generic Haskell include type-indexed datatypes [19, 17], such as generic \ndictionaries and the zipper: a data structure used to represent a tree together with a subtree that is \nthe focus of attention, where that focus may move left, right, up, or down the tree. These navigation \nfunctions depend heavily upon each other, and create a heavy notational burden when expressed in Classic \nGeneric Haskell.  3. CORE LANGUAGE Figure 1 presents the grammar for the core language un\u00adderlying \nDependency-style Generic Haskell. Grammar pro\u00adductions which speci.cally treat generic constructs are \nem\u00adphasized. The core language simpli.es the language in which we present examples: all lambda abstractions \nare explicit, whereas pattern matching, constructors, in.x operators, tu\u00adples and lists are not treated \nspecially. Furthermore, let has been divided into letrec and deplet. We use horizontal bars over subexpressions \nto denote po\u00adtential repetition of constructs. For instance, t denotes a vector of (possibly di.erent) \ntypes. Both primed (t ' )and indexed (t0) elements denote independent elements, rather than the components \nof a vector, as we never need to refer to vector elements individually. A Generic Haskell program consists \nof four components: programs, expressions, types and kinds. 3.1 Programs A program consists of de.nitions \nof generic functions, fol\u00adlowed by a single expression to be evaluated. A generic func\u00adtion is a type-indexed \nvalue, an expression taking a type ar\u00adgument, consisting of an obligatory type signature followed by \na number of cases de.ned over type patterns. With\u00adout loss of generality, we also assume that there is \na set of global prede.ned datatypes and functions, rather than include these in the calculus. 3.2 Expressions \nAn expression may be a variable, a function application or abstraction, a recursive let binding (which \nis now marked ex\u00adplicitly as letrec instead of let), or one of two new features for generic programming. \nThe .rst of these applies a generic function to a type to obtain the instance of that generic func\u00adtion \non that type. Such an application of a type-indexed value might introduce a dependency constraint in \nthe type of the expression, which will be propagated outwards until satis.ed. This means that the generic \nfunction depends on an additional value which should be provided by the envi\u00adronment surrounding the \nexpression. This is achieved us\u00ading a deplet, the second generic programming feature. The deplet construct \nintroduces dependency bindings which are used to satisfy dependency constraints arising from its body. \nThe variable name associated with a deplet must refer to a known type-indexed value de.ned in the top-level \nprogram. 3.3 Types Types are divided into two levels: types and type schemes, i.e. types with dependency \nconstraints or universal quanti.\u00adcation. The .rst level, ordinary program types, consists of type variables \n(which also refer to globally known datatypes), type application and function types. In addition to these \nfa\u00admiliar concepts we have the novel notion of dependency type variable. Dependency type variables only \nappear within the special type parentheses (\u00b7). Ordinary type variables are bound by a universal quanti.er \nor a lambda abstrac\u00adtion at the type level, whereas dependency type variables are bound inside the type \nparentheses within a case of a generic function (t). e or in a deplet construct, such as deplet v(da \ndb) = e1 in e2. In the generic function case, the dependency variables scope over e;in the deplet,the \nvariable da scopes over e1 and e2, whereas the arguments db are local to e1. The type of a generic function \nis a generic type, built using generalize (da). .a. s.Lambda ab\u00adstractions on the type level can occur \nonly here. The generic type is instantiated at a particular type to obtain the type of an instance of \nthe generic function for that type. The second level consists of type schemes, which are types extended \nwith universal quanti.cation (to denote polymor\u00adphic types) and with dependency constraints (to denote \nde\u00adpendencies on generic functions). A dependency constraint is a set of dependencies, each consisting \nof the name of a generic function, a dependency variable and a type. Depen\u00addencies are introduced by \ncalls to generic functions and can be satis.ed by deplet-bindings. We write .a. t if the set of dependency \nconstraints is empty, and (D) . t if there are no quanti.ed variables.  3.4 Kinds Although they do not \nappear in the program text, kinds are used heavily in the internal machinery to control the well-formedness \nof types. The kind of manifest types (i.e., types which correspond directly to values) is *. Type constructors \nhave functional kinds. Furthermore, we have two special kinds which play a role in the types of generic \nfunctions. The new moon is used as the kind of the type argument in a generic function, and the full \nmoon 0 is the kind of the fully applied type of a generic function. If a type contains one or more dependency \nvariables, then this fact is re.ected in its kind, (K) . ., in the form of kind dependencies. A kind \ndependency, K, is a set consisting of kind assignments for each dependency type variable. We use kind \ndependencies to check if the dependency structure of a Kinds Dependency constraints . ::= * (kind of \nmanifest types) D ::= x(da db) :: s | (kind of type argument) | 0 (generic kind) Expressions | .1 . \n.2 (functional kind) e ::= x,y,z,... (variable) | (e1 e2) (application) Dependency kinds | .x . e (lambda \nabstraction) . ::= (K) . . | x(t) (type application) | letrec x = e in e0 (let(rec) binding) Kind dependencies \n| deplet x(da db) = e1 in e2 K ::= da :: . (dependency binding) Types Declarations t ::= a,b,c,... (variable) \nD ::= x(a) :: s = (b dc). e| da,db,dc,... (dependency variable) generic function | (t1 t2) (application) \n| t1 . t2 (functional type) Main program | generalize (da). .a. s M ::= D; e (generic type) Type schemes/dependency \ntypes s ::= .a.(D) . t Figure 1: Syntax of Generic Haskell core language type is well-formed, as well \nas to steer the computation of the generalized type of generic functions.  4. TYPE AND KIND CHECKING \nThedevelopment of thetype systemwepresent in this sec\u00adtion, and indeed the recent development of Generic \nHaskell, has been driven by how generic functions are used in actual programs. The original work of Hinze \nenabled independent generic functions to be written in a natural recursive style [15], though such functions \ncould only be written for .xed kinds such as * or * . *. Hinze [16] then lifted this re\u00adstriction. As \na result, generic functions in Generic Haskell are applicable to types of any kind. Unfortunately, the \nstyle in which functions are written is cumbersome to use. In this paper, we do things a little di.erently \nfrom Hinze, but gain signi.cantly more ground. We enable generic func\u00adtions to be written in a natural \nstyle, while retaining the ability to apply them at all kinds. The Classic Generic Haskell value map(List) \nbecomes map(List da) in the de\u00adpendency style. That is, instead of applying map to the type constructor \nList, the arguments to the constructor are supplied with dependency variables, such as da in List da. \nIn addition, the Classic Generic Haskell value map(List) re\u00adceives the function which it applied to the \nlist elements as a ordinary function argument, whereas in Dependency-style Generic Haskell, this argument \nis supplied via a deplet ex\u00adpression which provides a binding for map(da). Thus in the dependency style, \nwhenever a type argu\u00adment appears within the type parentheses (\u00b7),it has kind *, modulo dependencies. \nOur type system assigns the kind (da :: *) . * to the type List da, which mirrors the * . * kind of the \nList type constructor. In the dependency style, generic functions still possess kind-indexed types, but \nthey can no longer be automatically applied to types of all kinds, rather types must be supplied with \nenough dependency vari\u00adables to make them e.ectively kind *. So ultimately nothing is lost. The code \nof map (see Section 2) introduces a recursive dependency of map on itself at type da. In addition to \nthis common behavior, our system enables further dependencies on other generic functions. These are recorded \nin a generic type, as we also have seen in the examples. The goal of the type system, beyond usual type \ncorrectness, is to ensure that the correct dependency information is speci.ed with generic functions, \nand that dependencies are correctly satis.ed or propagated when using generic functions. The kind checking \nrules are explained in Section 4.1. Be\u00adfore delving into the type system, we must .rst discuss in Section \n4.2 the rather technical topic of kind-indexed types, which denote the signatures of generic functions \nand from which the types of instances are determined. Forming the basis for Hinze s elegant proposal \n[16], these now bear the brunt of the complexity with the addition of dependencies. The type checking \nrules will then be explained in Section 4.3. 4.1 Kind checking Kind judgments are of the form A . f :: \n(K) . ..The environment A assigns kinds to global datatypes and local type variables. The kind-level \ndependencies K bind depen\u00addency variables to kinds. Dependencies are part of the syn\u00adtax of the kinds. \nThe intention is that the dependencies are inferred rather than previously known, which is why K does \nnot appear on the left-hand side of the turnstile. The codomains of both A and K are restricted to plain \nkinds i.e., dependencies on the kind level are not nested. The full kind checking rules are presented \nin Figure 2. The rules T-Var, T-App, T-Fun and T-Lambda are rela\u00adtively standard, except that a collection \nof kind-level depen\u00addencies is threaded through the rules along with the kind. The connection between \nkind-level dependencies and the use of dependency variables on the type level is established in the rules \nT-DVar and T-Dep. A dependency variable introduces a dependency on itself by rule T-DVar. Depen\u00addency \nvariables must be used consistently at the same kind in any given scope. Type-level dependencies are \nalso re\u00ad.ected at the kind level using rule T-Dep.If a type has a dependency of the form (v(da db):: \ns), then da is the only de\u00adpendency variable that is visible outside; arguments db are local to the type \nscheme s.Thus s may depend on these argument variables (and only on these) and is thus of kind (da :: \n.) .*,where . are the argument variables kinds. The kind of da is ..*, and this dependency is recorded \nin the .nal kind of the type. Type signatures of generic functions are special in that they contain the \ngeneralize construct. This construct trans\u00adforms a speci.c instance of the type of the generic function \ninto a generalized kind. This process is mirrored on the kind level. From rule T-Generic, the type to \nbe general\u00adized must have kind *n ,where 0 n+1 n *= **= * .*. The arguments of this type are, after generalization, \ninstan\u00adtiated to the type argument of the generic function. To enforce this instantiation, the type argument \nof the generic function gets a special kind, the new moon . Accord\u00adingly, rule T-Generic assigns kind \n0n+1 00 0n (= 0(= .( to the type resulting from generalization. The fully applied generalized type then \nhas full moon kind 0. Only gener\u00adalization introduces and 0 kinds, and P-Generic (dis\u00adcussed in Section \n4.3) enforces that all type signatures of generic functions are of kind 0. Type signatures of generic \nfunctions must thus always consist of a fully applied generalized type, possibly involv\u00ading universal \nquanti.cation for type variables of kind 0,as allowed by rule T-Forall. The algorithm that computes the \ngeneralized kind-indexed type for the generic function makes heavy use of this fact. The .nal component \nof kinding is the instance relation .1 . .2 between kinds. This is de.ned in rules K-Inst-Refl and K-Inst-Dep \n(Figure 3), and is used as a kind-level sub\u00adsumption in T-Sub to extend the set of dependencies which \nappear in a kind. 4.2 Kind-indexed types One of the key ideas of Hinze s theory, as implemented in Classic \nGeneric Haskell, is that certain type-level constructs, such as recursion, abstraction and application, \nare always interpreted as their value-level counterparts. This leads to the reasoning that generic functions \npossess kind-indexed types [16]. The type of a generic function is tied to the kind of its type argument, \nestablishing identities such as: eq(Tree Int)=eq(Tree)(eq(Int)). Here the application at the type level \n(of Tree to Int)can be replaced by the value level application of two instances of the generic function \nat those types. In Dependency-style Generic Haskell, we no longer allow type arguments of higher kinds, \nbut we keep the general idea: instead of a higher-kinded type, we use type argu\u00adments which contain dependency \nvariables. This shift en\u00adables generic functions to depend on generic functions other than just itself. \nIn the dependency style, the identity corre\u00adsponding to the one above is: eq(Tree Int)=deplet eq(da)= \neq(Int)in eq(Tree da). In Classic Generic Haskell, kind-indexed types have to be de.ned explicitly by \nthe programmer. For instance, the type of generic equality reads Eq( *) a = a .a .Bool Eq( .1 ..2) a \n= .b.Eq( .1) b .Eq( .2) (ab). The function eq(t)then has type Eq( .) t,where . is the kind of t. The \nsecond case captures the fact that equality on kind .1 ..2 takes an equality function on the argument \ntype to an equality function on the resulting type. Note that the second line of this type could be automati\u00adcally \nderived by the compiler, because the interpretation of type application as value-level application is \nintrinsic to the theory. Because of the increased complexity due to depen\u00addencies, we opt for this solution \nin dependency-style Generic Haskell, requiring a signature only for kind *, plus depen\u00addency information. \nThus a generic type signature takes the following form (the general form of types of kind 0): x(c):: \n.a. (generalize (da)..b. (y(da):: s) .t) c ...c. Three sorts of type variables occur within a type signature: \nthetypeargument c; outer quanti.ed, non-generic variables a; and abstracted variables b. The latter kind \nare called generic variables and will be instantiated with the type ar\u00adgument when generating instances \nof the generic type. Note that there are as many applications to c at the end as there are variables \nin b. A generic function may depend on itself and on other func\u00adtions. The dependencies y are the generic \nfunctions that x depends on. The generalize construct generalizes the type for a spe\u00adcial case (the type \nof x(da),where da is ofkind (da :: *) .*) toafunction tapp which produces a correct type for all type \narguments of kind (K) .*. This function is used during type checking and is de.ned in terms of the kind-indexed \ntype kapp as follows: tapp(x; t)= .a.kapp(x; .; a |t ...t). where . is the dependency kind of t. The \nfunction kapp, which is similar to the kind-indexed type in Classic Generic Haskell, depends on both \nthe non-generic and the generic variables that occur in the type signature. We only sketch its de.nition \nhere, deferring the details to a technical re\u00adport [28]: kapp(x; *; a |t)=base type of x kapp(x;(da :: \n. .*,K) .*; a |t)= .d.(y(da db):: kapp(y;(db :: .) .*;variables)) .kapp(x;(K) .*; a |[da .d ]t). For \nkind *types (without dependency variables), the result\u00ading type is the type speci.ed in the type signature, \nwithout the dependencies. The second case expresses the intuition that a generic function on a type that \ndepends on a variable of kind . .*introduces dependencies for the functions that x depends on, using \nkapp on that kind and a set of variables which is a selection of a,possibly someglobaltypes,and d. The \ninformation which variables are used here is extracted from the dependency constraint in the type signature \nspec\u00adi.ed by the programmer. If da is not of kind *,then local dependency variables, db, are introduced \nin the dependency constraints and used in the recursive calls of kapp to return . .* to the form (K) \n.*. As a concrete example, recall the type of generic equality from Section 2: eq(a) :: (generalize (da). \n.b.(eq(da) :: b . b . Bool) . b . b . Bool) a. Figure 4 contains some example values of the tapp function \nfor this signature. The last case, involving a dependency variable of kind * . *, is an example of a \nnested depen\u00addency constraint, making use of a local dependency variable argument. 4.3 Type checking \nType judgments have the form AKV . e :: s,where the environment V assigns types to variables and generic \nfunc\u00adtion names, whereas the other two environments support kind checking. The type judgments di.er from \na standard Hindley-Milner system mainly due to the handling of depen\u00addency constraints. As dependency \nconstraints represent hid\u00adden arguments, and dependency constraints can be nested and contain universal \nquanti.ers, we also have to deal with rank-n polymorphic types to some extent. We have drawn from Odersky \nand L\u00a8aufer [29] to deal with this aspect. The type rules E-Var, E-Gen, E-Appl,and E-Lambda are pretty \nstandard. Type schemes and thus dependency constraints are only introduced by the following constructs: \na variable that has been bound in a letrec, or a type appli\u00adcation of a generic function. The letrec \nconstruct is the usual recursive let binding corresponding to let in Haskell. All variables bound in \na letrec binding are assumed to be mutually dependent. De\u00adpendency constraints are treated analagously \nto class con\u00adstraints or implicit parameters in that a value having de\u00adpendencies may be bound to a variable \nin a letrec.This gives the feel of dynamically scoped dependency variables. For example, the program \nletrec x = map(List da) in (deplet map(da) = .x . x +1 in x [1, 2, 3], deplet map(da) = null x in x [\"one\", \n\"two\", \"three\" ]) has type (List Int, List Bool). We made this choice for the typing rule of letrec because \nit matches the idea that the dependencies are part of the type of a value. An alternative is discussed \nin Section 7. By rule E-TApp, a generic function is declared with a type signature of kind 0. From the \ngeneric type signature and the type at which the generic function is applied, the result type of the \nexpression is computed using the auxiliary function tapp, described above. A deplet expression is used \nto satisfy dependency con\u00adstraints arising from the use of a generic function in its body. The type s \n(without dependencies) of the expression e1 which is used to satisfy the dependency must match the type \noccurring in the appropriate dependency constraint of the body expression e2.As deplet is somewhat like \nlocally de.ning an additional case for a generic function, we use local dependency variables as type \narguments when the de\u00adpendency which arises is not of kind *.Thus, the argument variables db in the rule \nE-Deplet are local to the expression e1. Finally, the remaining dependencies D1 and D2 of the bound expression \nand the body must be compatible as well. As with kinds, we have a subtyping relation on types (Fig\u00adure6). \nTherelation s1 s2 expresses the intention that expressions of type s1 are also of type s2. The relation \nis ex\u00adploited in the subsumption rule E-Sub. The rules in Figure 6 modify those of Odersky and L\u00a8aufer \nto handle dependency constraints. Rule T-Inst-Dep establishes a connection be\u00adtween the instance relation \non type schemes and the instance relation on constraints. Dependency constraints represent hidden parameters. \nUnused, but well-kinded dependencies canbe addedto a type (D-Inst-1). Furthermore, because they are arguments, \ndependencies become more general as the types in them become more speci.c (D-Inst-2). This is analogous \nto the contravariance of the argument position of the function arrow. The .nal rules are for type checking \nthe well-formedness of generic de.nitions and programs. These are given in Fig\u00adure 7. By P-Generic, a \ncase of a generic function is type correct if the type of its right-hand side matches the type declared \nfor the generic function. This is achieved using the function tapp to compute the type of the generic \nfunc\u00adtion at the speci.c type of the case in question, using the type signature of the generic function. \nFinally, by P-Prog, a program in the core language is type correct if all cases of all generic functions \nare correct, and if the .nal expres\u00adsion is typeable. The environments A and V contain global datatypes \nand global functions, respectively.  5. REDUCTION SEMANTICS Figure 8 presents a fragment of the reduction \nrules for the core language. For brevity we have omitted the unin\u00adteresting reduction rules. It remains \nimplicit in the rules that bound variables should generally be renamed in such a way that no variables \nare captured during substitution. The style in which these rules are presented keeps letrec and deplet \nde.nitions around to act like environments for the expressions being evaluated. Reduction proceeds against \na .xed environment S containing the bindings for each case of each generic function. To be able to perform \nthe reduction, we need to keep information about dependencies from the type checking process. The reason \nis that we have to know when it is safe to reduce a deplet or a lambda expression. Therefore, we assume \nthat the domain of an expression s de\u00adpendency constraint is accessible via the deps function. We also \nassume that the kinds of all type arguments in generic applications and the dependencies of all generic \nfunctions are available via functions arity, which gives the arity of a type, and dependencies, which \ngives the names of generic functions which it depends on. The function length denotes the length of a \nvector of variables. The reduction rules R-App and R-Letrec are standard, except for the fact that in \nR-App, all dependencies of the argument have to be resolved before the application can be reduced. This \nis because lambda-bound variables are always of simple types, not type schemes, and thus are dependency\u00adfree. \nA letrec is reduced by substitution in the underlying expression. A letrec can only be eliminated if \nthe bound variables do not occur anymore in its body. Unlike letrec, a deplet construct is not reduced \nby performing substitu\u00adtion on its complete body. Rather, it is pushed down the expression, as shown \nfor example in R-Deplet-Letrec.A deplet is directly propagated to the body of a letrec here, not a.ecting \nthe expressions in the bound variables. This implements the dynamically scoped behavior of dependency \nconstraints. There are similar rules that push a deplet through applications or lambda abstractions. \nThe three rules R-Case, R-Deplet and R-TApp handle various forms a :: . .AA.t :: .1 .1 .2 T-Var T-DVar \nT-Sub A.a :: () .. A.da :: (da :: .) .. A.t :: .2 A.t1 :: (K) .(.2 ..1) A.t2 :: (K) ..2 A.s1 :: (K) .* \nA.s2 :: (K) .* T-App T-Fun A.(t1 t2):: (K) ..1 A.(s1 .s2):: (K) .* A, a :: .1 .s :: () ..2 .2 .{*, 0} \nA, a :: .1 .s :: (K) ..2 T-Forall T-Lambda A..a.s :: () ..2 A..a.s :: (K) ..1 ..2 A.s1 :: db :: . .* \n.0 = . .* A.(D) .s2 :: (da0 :: .0, K) .* A..a. s :: (da :: *) .*n T-Dep T-Generic 0n A.(x(da0 db):: \ns1, D) .s2 :: (da0 :: .0, K) .* A.generalize (da)..a. s :: () .( Figure 2: Kind checking rules (K1) ..1 \n(K2) ..1 K-Inst-Refl K-Inst-Dep .. (K1) ..1 (da :: .2, K2) ..1 Figure 3: Instance relation on (dependency) \nkinds t :: * tapp(eq; t)= t .t .Bool t :: * .* tapp(eq; t da)= .a.(eq(da):: a .a .Bool) .ta .ta .Bool \nt :: * .(* .*) tapp(eq; t da db)= .a..b.(eq(da):: a .a .Bool, eq(db):: b .b .Bool) .tab .tab .Bool t \n:: (* .*) .* tapp(eq; t da)= .a.(eq(da db):: .b.(eq(db):: b .b .Bool) .ab .ab .Bool) .ta .ta .Bool Figure \n4: Example instances of tappfor generic equality AKV.e :: s1 AK.s1 AKV.e :: sa ./ftv(V) x :: s .V s2 \nE-Var E-Sub E-Gen AKV.x :: s AKV.e :: s2 AKV.e :: .a.s AKV.e1 :: (D) .(t2 .t1) AKV.e2 :: (D) .t2 AK V, \nx :: t1 .e :: (D) .t2 E-App E-Lambda AKV.(e1 e2):: (D) .t1 AKV..x .e :: (D) .t1 .t2 A.s1 :: 0 x :: s1 \n.V AKV.tapp(x; t)= s2 V ' = V, x :: s AKV' .e :: s AKV ' .e0 :: s0 E-TApp E-Letrec AKV.x(t):: s2 AKV.letrec \nx = e in e0 :: s0 A.da db :: (db :: ., K) .* AKV.e1 :: (y(db):: s, D1) .t ' AKV.e2 :: (x(da db):: (y(db):: \ns) .t ' , D2) .t AK.(D2)(D1) E-Deplet AKV.deplet x(da db) = e1 in e2 :: (D1) .t Figure 5: Type checking \nrules AK.(D1)(D2) T-Inst-Refl T-Inst-Dep AK.ss AK.(D1) .t (D2) .t AK.[a .t ]s1 s2 AK.s1 s2 a ./ftv(s1) \nT-Inst-Univ-1 T-Inst-Univ-2 AK..a.s1 s2 AK.s1 .a.s2 A.da db :: (db :: ., K) .* A.s :: (K) .* AK.s2 s1 \nAK.(D1)(D2) D-Inst-1 D-Inst-2 AK.() (x(da db):: s) AK.(x(da db):: s1, D1)(x(da db):: s2, D2) Figure 6: \nInstance relation on types and dependency constraints A, a :: . s :: () . 0 AV . x(a) :: s = (b dc). \ne well-formed A . b dc :: (K) . * AKV . e :: tapp(x; b dc) ' AKV . e :: s P-Generic P-Prog AV . x(a) \n:: s = (b dc). e well-formed AV . x(a) :: s = (b dc). e; e well-formed Figure 7: Program checking rules \n(R-App)(.x . e1) e2 . [x . e2 ]e1 where deps(e2)= \u00d8 (R-Letrec) letrec x0 = e0; x = e in e ' . letrec \nx0 = e0; x = e in [x0 . e0 ]e ' (R-Deplet) deplet x(da db) = e in x(da db) . e where deps(e)= \u00d8 (R-Deplet-Letrec) \ndeplet x(da db) = e0 in (letrec x = e in e ' ) . letrec x = e in (deplet x(da db) = e0 in e ' ) (R-Case) \nx(a db) . e where x(a db). e . S (R-TApp) x(t0 t1 da) . deplet y(da1 db) = y(t1 db) in x(t0 da1 da) \nwhere da,db are fresh, arity(t1)= length(db), dependencies(x)= y Figure 8: A fragment of the reduction \nrules of generic function application. These depend on whether the form of the function s type argument \nis, respectively, a type constructor applied to some number of dependency variables, a dependency variable \napplied to some number of variables, or a type of some other form. By rule R-Case a generic function \napplied to a type constructor with depen\u00addency arguments is reduced to the corresponding value in the \nenvironment. Rule R-Deplet handles a local depen\u00addency declaration for the case where a dependency variable \nis in the constructor position, reducing to the value de.ned in the appropriate deplet clause. Finally, \nrule R-TApp re\u00adduces the other cases, where the type appearing in an ar\u00adgument position is not a dependency \nvariable. The idea is to transform away the rightmost of these, t1, into depen\u00addencies on a new dependency \nvariable da1 which replaces t1 in the argument type. The dependencies introduced by at\u00adtempting to reduce \nthe generic function x are those which x depends upon. A consequence of applying this rule is that the \ntype arguments in the resulting expression are simpler than the original; multiple applications of this \nrule eventu\u00adally simplify all type arguments so that the rules R-Case and R-Deplet become applicable. \nBeyond these reductions, the Generic Haskell compiler computes embedding and projections of all datatypes \ninto types constructed from Unit, Sum,and Prod, and special\u00adizations for such types. This mechanism is \northogonal to the system described in this paper, and has been described else\u00adwhere [14]. We tacitly \nassume that the required functions are supplied within the environment S. The usual progress and subject \nreduction theorems hold for our reduction semantics with respect to the type system presented earlier. \nThe proofs are included in a technical report [28].  6. RELATED WORK The .eld of generic programming \nhas grown consider\u00adably in recent years. Much of this work stems from so\u00adcalled theories of datatypes, \nfor example [3], which are often based on category theoretic notions such as initial algebras. These \napproaches focus on generic control constructs, such as folds [32], which are derived from datatypes. \nBased on initial algebra semantics, Charity [7] automati\u00adcally generates folds and so forth for datatypes \non demand, but otherwise does not allow the programmer to write her own generic functions. PolyP [21] \nextends Haskell with a special construct for de.ning generic functions, also based on initial algebras. \nAlthough PolyP permits type inference and functions which make use of the pattern functor of a datatype, \nwhich we cannot do, it supports only regular datatypes, not mutually recursive, multiparameter, nested \ntypes, or types containing function spaces. In Functorial ML [23] the algorithm for map, for exam\u00adple, \nis de.ned using combinators to .nd the data upon which argument function will apply. While supporting \ntype infer\u00adence, Functorial ML programming is a rather low level lan\u00adguage and lacks the simplicity of \nHinze s approach. Functo\u00adrial ML and other work on shape theory has resulted in the programming language \nFISh [22]. Weirich and others [33] (and the earlier work on in\u00adtensional polymorphism [8]) employ a typecase \nconstruct which performs run-time tests on types to implement poly\u00adtypic functions of an expressiveness \nsimilar to Hinze s. Ruehr s structural polymorphism [31] adopts similar type tests. By avoiding type \ninterpretation at run-time, Generic Haskell distinguishes itself from these approaches. The work of Hinze \n[18, 16, 13], upon which Generic Haskell is based, is a major improvement over the other approaches, \nbecause it allows the instantiation of generic functions on mutually recursive, multiparameter, nested \ntypes, or types containing function spaces. Clarke and L\u00a8oh [6] present a few extensions to Hinze s framework \nwhich are compatible with the framework presented here, and will be incorporated into the compiler for \nDependency-style Generic Haskell. Closest to the work described in the present paper are both Weirich \ns original higher-order intensional type anal\u00adysis [33] and her recent type-erasure approach [34]. This \napproach o.ers the advantage of support for separate com\u00adpilation, dynamic loading, and polymorphic recursion. \nIn addition, by carrying around a representation of type in\u00adformation, she can successfully treat universal \nand existen\u00adtial quanti.cation. The implementation of our approach requires no type information at run-time, \nenables separate compilation, and can certainly handle polymorphic recur\u00adsion, as our cases must have \na certain degree of polymor\u00adphism. Our calculus does however carry run-time informa\u00adtion around, using \nit for dispatch purposes. The big di.er\u00adence between our system and Weirich s is that we handle the dependency \nof one generic on another, and treat generic functions by name, rather than as anonymous case state\u00adments. \nAltenkirch and McBride [2] present a rather complicated encoding of much of our style of generic programming \n(ex\u00adcluding the dependency extension) into a system of depen\u00addent types. While this approach is highly \nexpressive, we argue that there is a long way to go before it is usable by mere mortals as a programming \nlanguage. We expect that using type theory one can do anything we do in this paper and probably much \nmore, but we suspect that programming the examples given in Section 2 will be very di.cult. The programming \nlanguage Haskell supports deriving clauses for a certain number of built-in classes (Eq, Show, etc) [30]. \nThis facilitates the automatic overloading of cer\u00adtain functions for datatypes which have the deriving \nclause speci.ed. Hinze and Peyton Jones explore an extension, fol\u00adlowing Hinze s earlier ideas [15], \nwhich integrated generics with Haskell s type class system [20]. This system su.ers from some limitations \ndue to the interaction with the type class system. G Caml [9, 10] presents a generic program\u00adming extension \nfor O Caml [26]. The proposal does not aim to cover all datatypes, and as such can be seen as a way of \nachieving Haskell-style overloading in O Caml. The generic extension for Clean is also based on Hinze \ns work [1]. This proposal is more closely integrated with the type class sys\u00adtem, but does not include \nany of the extensions described here. Generic Haskell, on the other hand, takes the ap\u00adproach of exploring \ngeneric programming in isolation, as an extension to the Haskell language. L\u00a8ammel and Peyton Jones present \na very neat idea which enables generic programs to be written in almost pure Haskell (Haskell with rank-2 \ntypes and a form of type coer\u00adcion operator). We believe that our approach is more gen\u00aderal. One reason \nsupporting this is that our de.nitions are open, in that they can be extended or updated, whereas once \na generic function has been constructed in L\u00a8ammel and Pey\u00adton Jones s proposal, its behavior is .xed. \nThey also lack the ability for one generic function to depend on another generic function, as our dependencies \npermit. Furthermore, they generate generics only at kind *. Their approach is based on combinators, whereas \nours is based on functions which are de.ned indexed on the structure of types. In their favor, their \napproach is better integrated into Haskell. A dependency resembles a quali.ed type: a type with restrictions \nthat require certain type variables to be an in\u00adstance of a particular class [24]. Inferring the context \nre\u00adquirements for quali.ed types is, however, easier, because the dependencies for a generic function \nappear at multiple kinds, and thus have types with di.ering forms. Depen\u00addencies are similar in spirit \nto implicit parameters [27], and deplet is similar to the with construct (now an ordinary let) in that \nthe functions referred to are not explicitly given as arguments. Implicit parameters are supplied at \na .xed monomorphic type, whereas a dependency refers (often) to an entire generic function, which includes \ncases of polymor\u00adphic type. The development of Generic Haskell is example driven. We encountered the \nneed for dependencies when we imple\u00admented the digital searching and zipper examples in our work on type-indexed \ndatatypes [19]. Most other approaches we have seen only use simple examples such as map and zip as their \nmotivating examples. 7. DISCUSSION We have made design choices at several points when de\u00adveloping the \nlanguage. We discuss two here. Firstly, distin\u00adguishing dependency variables from ordinary variables \nhas been useful in making the dependency concept explicit, al\u00adthough this distinction is not necessary. \nSecondly, we could have adopted an alternative formulation of letrec which im\u00adplements a statically scoped \nview, as opposed to the more dynamic view taken in our system, using the following rule. V ' = V, x :: \nt ' ' AKV ' . e :: (D) . t AKV ' . e0 :: (D) . t AKV. letrec x = e in e0 :: (D) . t Here the types for \nthe let-bound variables are added to the environment without their dependencies. Thus the bound variables \nhave a dependency-free type when used in the body. The dependencies of the bound variables as well as \nof the body must be compatible and become the common dependencies of the whole expression. As presented \nhere, generic functions are explicitly anno\u00adtated for types of kind *.Rank-n types appear, in con\u00adjunction \nwith dependency constraints, in the types of in\u00adstances of generic functions on particular types. It \nis easy to extend the language presented here to allow rank-n types everywhere. If we are given explicit \ntype annotations for all rank-n types, we can infer the types of the expressions in the language, following \nalong the lines of Odersky and L\u00a8aufer [29], also adapting ideas from Lewis et al [27] and Chitil [4]. \nA prototype implementation of the system described in this paper including type inference exists, although \nwe have not yet incorporated it into the Generic Haskell compiler. The prototype can be obtained by contacting \nthe authors. In conclusion, we have introduced a core language, a type system, and a reduction semantics \nfor a new style of generic programming language which we have called Dependency\u00adstyle Generic Haskell. \nThe development of this language has been strongly motivated by practical concerns, derived from our \nexperience programming in Generic Haskell. The di.erence with Classic Generic Haskell is signi.cant, \nand the number of new concepts may seem overwhelming. How\u00adever, we feel the added complexity is justi.ed, \nas the sys\u00adtem presented in this paper provides foundations which not only go beyond Classic Generic \nHaskell, but also opens the door to tackle problems which previously seemed too far o.. Possibilities \ninclude better support for type-indexed types, higher-order and locally-de.ned generic functions, depen\u00addency \ninference, type inference of kind-* type arguments, generic functions based on kinds other than *, and \npat\u00adtern matching on type arguments. Initial experiments have shown promising results in these areas. \nWe feel that de\u00adpendency inference, i.e. allowing the programmer to omit dependencies in generic type \nsignatures, is our most press\u00ading concern. 8. REFERENCES [1] Artem Alimarine and Rinus Plasmeijer. A \ngeneric programming extension for Clean. In Proceedings of the 13th International workshop on the Implementation \nof Functional Languages, IFL 01, pages 257 278, 2001. [2] Thorsten Altenkirch and Conor McBride. Generic \nprogramming within dependently typed programming. In Gibbons and Jeuring [11], pages 1 20. [3] Richard \nBird, Oege de Moor, and Paul Hoogendijk. Generic functional programming with types and relations. Journal \nof Functional Programming, 6(1):1 28, 1996. [4] Olaf Chitil. Compositional explanation of types and \nalgorithmic debugging of type errors. In ICFP 01, pages 193 204, September 2001. [5] Dave Clarke, Johan \nJeuring, and Andres L\u00a8oh. The Generic Haskell User s Guide Beryl release. Technical Report UU-CS-2002-047, \nUtrecht University, 2002. [6] Dave Clarke and Andres L\u00a8oh. Generic Haskell, speci.cally. In Gibbons \nand Jeuring [11], pages 21 48. [7] Robin Cockett and Tom Fukushima. About Charity. Yellow Series Report \nNo. 92/480/18, Dep. of Computer Science, Univ. of Calgary, 1992. [8] Karl Crary, Stephanie Weirich, and \nJ. Gregory Morrisett. Intensional polymorphism in type-erasure semantics. In ICFP 98, pages 301 312. \nACM Press, 1998. [9] Jun Furuse. G Caml O Caml with extensional polymorphism extension. Project home \npage at http://pauillac.inria.fr/~furuse/generics/, 2001. [10] Jun Furuse. Generic polymorphism in ML. \nIn Journ\u00b4ees Francophones des Langages Applicatifs, January 2001. [11] Jeremy Gibbons and Johan Jeuring, \neditors. Generic Programming, volume 243 of IFIP.Kluwer Academic Publishers, January 2003. [12] Paul \nHagg. A framework for developing generic XML Tools. Master s thesis, Department of Information and Computing \nSciences, Utrecht University, 2002. [13] Ralf Hinze. A generic programming extension for Haskell. In \nErik Meijer, editor, Proceedings of the Third Haskell Workshop, Technical report of Utrecht University, \nUU-CS-1999-28, 1999. [14] Ralf Hinze. Generic Programs and Proofs. 2000. Habilitationsschrift, Bonn University. \n[15] Ralf Hinze. A new approach to generic functional programming. In POPL 00, pages 119 132. ACM Press, \n2000. [16] Ralf Hinze. Polytypic values possess polykinded types. Science of Computer Programming, 43(2-3):129 \n159, 2002. [17] Ralf Hinze and Johan Jeuring. Generic Haskell: applications, 2003. To appear. [18] Ralf \nHinze and Johan Jeuring. Generic Haskell: practice and theory, 2003. To appear. [19] Ralf Hinze, Johan \nJeuring, and Andres L\u00a8oh. Type-indexed data types. In Proceedings of the 6th Mathematics of Program Construction \nConference, MPC 02, volume 2386 of LNCS, pages 148 174, 2002. [20] Ralf Hinze and Simon Peyton Jones. \nDerivable type classes. In Graham Hutton, editor, Proceedings of the 2000 ACM SIGPLAN Haskell Workshop, \nvolume 41.1 of Electronic Notes in Theoretical Computer Science. Elsevier Science, August 2001. [21] \nP. Jansson and J. Jeuring. PolyP a polytypic programming language extension. In POPL 97, pages 470 482. \nACM Press, 1997. [22] C. B. Jay. Programming in FISh. International Journal on Software Tools for Technology \nTransfer, 2:307 315, 1999. [23] C.B. Jay, G. Bell`e, and E. Moggi. Functorial ML. Journal of Functional \nProgramming, 8(6):573 619, 1998. [24] Mark P. Jones. Quali.ed Types: Theory and Practice. Cambridge University \nPress, 1994. [25] Ralf L\u00a8ammel and Simon Peyton Jones. Scrap your boilerplate: a practical approach to \ngeneric programming. In Proc ACM SIGPLAN Workshop on Types in Language Design and Implementation (TLDI \n2003), 2003. [26] Xavier Leroy et al. The Objective Caml system release 3.02, Documentation and user \ns manual, December 2001. Available from http://caml.inria.fr/ocaml/htmlman/. [27] Je.rey Lewis, Mark \nShields, Erik Meijer, and John Launchbury. Implicit parameters: Dynamic scoping with static types. In \nPOPL 00, pages 108 118, Jan 2000. [28] Andres L\u00a8oh, Dave Clarke, and Johan Jeuring. Dependency-style \nGeneric Haskell. Technical Report UU-CS-2003-022, Institute of Information and Computing Sciences, Utrecht \nUniversity, 2003. [29] Martin Odersky and Konstantin L\u00a8aufer. Putting type annotations to work. In POPL \n96, pages 54 67, New York, N.Y., 1996. [30] Simon Peyton Jones, John Hughes, et al. Haskell 98 A non-strict, \npurely functional language. Available from http://haskell.org, February 1999. [31] Fritz Ruehr. Analytical \nand Structural Polymorphism Expressed Using Patterns Over Types.PhD thesis, University of Michigan, 1992. \n[32] T. Sheard and L. Fegaras. A fold for all seasons. In Proceedings of the 6th ACM Conference on Functional \nProgramming Languages and Computer Architecture FPCA 93, pages 233 242. ACM Press, June 93. [33] Stephanie \nWeirich. Higher-order intensional type analysis. In Daniel Le M\u00b4etayer, editor, Programming Languages \nand Systems: 11th European Symposium on Programming, ESOP 2002, 2002. [34] Stephanie Weirich. Higher-order \nintensional type analysis in type erasure semantics. Available from http://www.cis.upenn.edu/~sweirich/, \nDecember 2002.  \n\t\t\t", "proc_id": "944705", "abstract": "Generic Haskell is an extension of Haskell that supports the construction of generic programs. During the development of several applications, such as an XML editor and compressor, we encountered a number of limitations with the existing (Classic) Generic Haskell language, as implemented by the current Generic Haskell compiler. Specifically, generic definitions become disproportionately more difficult to write as their complexity increases, such as when one generic function uses another, because recursion is implicit in generic definitions. In the current implementation, writing such functions suffers the burden of a large administrative overhead and is at times counter-intuitive. Furthermore, the absence of type checking in the current implementation can make Generic Haskell hard to use.In this paper we develop the foundations of <i>Dependency-style Generic Haskell</i> which addresses the above problems, shifting the burden from the programmer to the compiler. These foundations consist of a full type system for Dependency-style Generic Haskell's core language and appropriate reduction rules. The type system enables the programmer to write generic functions in a more natural style, taking care of dependency details which were previously the programmer's responsibility.", "authors": [{"name": "Andres L&#246;h", "author_profile_id": "81100364350", "affiliation": "Utrecht University, Utrecht, The Netherlands", "person_id": "P639757", "email_address": "", "orcid_id": ""}, {"name": "Dave Clarke", "author_profile_id": "81100391212", "affiliation": "Utrecht University, Utrecht, The Netherlands", "person_id": "PP14138652", "email_address": "", "orcid_id": ""}, {"name": "Johan Jeuring", "author_profile_id": "81100339289", "affiliation": "Utrecht University, Utrecht, The Netherlands", "person_id": "PP39038408", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/944705.944719", "year": "2003", "article_id": "944719", "conference": "ICFP", "title": "Dependency-style generic haskell", "url": "http://dl.acm.org/citation.cfm?id=944719"}