{"article_publication_date": "08-25-2003", "fulltext": "\n Boxes Go Bananas: Encoding Higher-Order Abstract Syntax with Parametric Polymorphism Geoffrey Washburn \nStephanie Weirich Department of Computer and Information Science University of Pennsylvania {geoffw,sweirich}@cis.upenn.edu \nAbstract Higher-order abstract syntax is a simple technique for implement\u00ading languages with functional \nprogramming. Object variables and binders are implemented by variables and binders in the host lan\u00adguage. \nBy using this technique, one can avoid implementing com\u00admon and tricky routines dealing with variables, \nsuch as capture\u00adavoiding substitution. However, despite the advantages this tech\u00adnique provides, it is \nnot commonly used because it is dif.cult to write sound elimination forms (such as folds or catamorphisms) \nfor higher-order abstract syntax. To fold over such a datatype, one must either simultaneously de.ne \nan inverse operation (which may not exist) or show that all functions embedded in the datatype are para\u00admetric. \nIn this paper, we show how .rst-class polymorphism can be used to guarantee the parametricity of functions \nembedded in higher-order abstract syntax. With this restriction, we implement a library of it\u00aderation \noperators over data-structures containing functionals. From this implementation, we derive fusion laws \nthat functional pro\u00adgrammers may use to reason about the iteration operator. Finally, we show how this \nuse of parametric polymorphism corresponds to the Sch\u00a8urmann, Despeyroux and Pfenning method of enforcing \nparametricity through modal types. We do so by using this library to give a sound and complete encoding \nof their calculus into System F.. This encoding can serve as a starting point for reasoning about higher-order \nstructures in polymorphic languages. Categories and Subject Descriptors D.3.3 [PROGRAMMING LANGUAGES]: \nLanguage Constructs and Features abstract data types, polymorphism, control struc\u00adtures; F.3.3 [LOGICS \nAND MEANINGS OF PROGRAMS]: Software type structure, program and recursion schemes, func\u00adtional constructs; \nF.4.1 [MATHEMATICAL LOGIC AND FOR-MAL LANGUAGES]: Mathematical Logic Lambda calculus and related systems, \nmodal logic Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP \n03, August 25 29, 2003, Uppsala, Sweden. Copyright 2003 ACM 1-58113-756-7/03/0008 ...$5.00 General Terms \nLanguages  Keywords Higher-order abstract syntax, modal type system, catamorphism, parametricity, parametric \npolymorphism 1 Introduction Higher-order abstract syntax (HOAS) is an old and seductively sim\u00adple technique \nfor implementing a language with functional pro\u00adgramming.1 The main idea is elegant: instead of representing \nob\u00adject variables explicitly, we use metalanguage variables. For ex\u00adample, we might represent the object \ncalculus term (.x.x) with the Haskell expression lam (\\x -> x). Doing so eliminates the need to implement \na number of tricky routines dealing with object language variables. For example, capture-avoiding substitution \nis merely function application in the metalanguage. However, out\u00adside of a few specialized domains, such \nas theorem proving, partial evaluation [26], logical frameworks [22] and intensional type anal\u00adysis [27, \n30], higher-order abstract syntax has found limited use as an implementation technique. One obstacle \npreventing the widespread use of this technique is the dif.culty in using elimination forms, such as \ncatamorphisms2, for datatypes containing functions. The general form of catamorphism for these datatypes \nrequires that an inverse be simultaneously de\u00ad.ned for every iteration [16]. Unfortunately, many operations \nthat we would like to de.ne with catamorphisms require inverses that do not exist or are expensive to \ncompute. However, if we know that the embedded functions in a datatype are parametric, we can use a version \nof the catamorphism that does not require an inverse [9, 24]. A parametric function may not examine its \nargument; it may only use it abstractly or push it around . Only allowing parametric embedded functions \nworks well with HOAS because the terms with non-parametric embedded functions are ex\u00adactly those that \nhave no correspondence to any .-calculus term [24]. In this paper, we use iterator to refer to a catamorphism \nrestricted to arguments with parametric functions. A type system can separate parametric functions from \nthose that 1While the name comes from Pfenning and Elliott [21], the idea itself goes back to Church. \n[4]. 2Catamorphisms (also called folds) are sometimes represented with the bananas (|\u00b7|) notation [15]. \nare not. For example, Fegaras and Sheard [9] add tags to mark the types of datatypes whose embedded functions \nare not para\u00admetric, prohibiting iteration over those datatypes. Alternatively, Sch\u00a8urmann, Despeyroux \nand Pfenning [24, 8] use the necessity modality ( box ) to mark those terms that allow iteration. However, \nmany modern typed languages already have a mechanism to enforce that an argument be used abstractly parametric \npoly\u00admorphism. It seems desirable to .nd a way to use this mechanism instead of adding a separate facility \nto the type system. In this pa\u00adper, we show how to encode datatypes with parametric function spaces in \nthe polymorphic .-calculus, including iteration operators over them. Our speci.c contributions are the \nfollowing. For functional pro\u00adgrammers, we provide an informal description of how restricting datatypes \nto parametric function spaces can be enforced in the Haskell language using .rst-class polymorphism. \nWe provide a safe and easy implementation of a library for iteration over higher-order abstract syntax. \nThis Haskell library allows the natural expression of many algorithms over the object language; to illustrate \nits use, we use it to implement a number of operations including Danvy and Filinski s optimizing one-pass \nCPS conversion algorithm [6]. Furthermore, because we encode the iteration operator within the polymorphic \n.-calculus, we also derive fusion laws about the iteration operator that functional programmers may use \nto reason about their programs. To show the generality of this technique, we use this implementa\u00adtion \nto show a formal translation from the Sch\u00a8urmann, Despeyroux and Pfenning modal calculus [24] (called \nhere the SDP calculus) to System F.. This encoding has an added bene.t to language de\u00adsigners who wish \nto incorporate reasoning about parametric func\u00adtion spaces. It demonstrates how systems based on the \npolymor\u00adphic .-calculus may be extended with reasoning about higher-order structure. We do not claim \nthat this encoding will solve all of the problems with programming using higher-order abstract syntax. \nIn particular, algorithms that require the explicit manipulation of the names of bound variables remain \noutside the scope of this implementation technique. The remainder of this paper is as follows. Section \n2 starts with background material on catamorphisms for HOAS, including those developed by Meijer and \nHutton [16] and Fegaras and Sheard [9]. In Section 2.1 we show how to use .rst-class polymorphism and \nab\u00adstract types to provide an interface for Fegaras and Sheard s imple\u00admentation that enforces the parametricity \nof embedded functions. Using this interface, we show some examples of iteration includ\u00ading CPS conversion \n(Section 2.2). In Section 3, we describe an implementation of that interface within the part of Haskell \nthat cor\u00adresponds to System F., and describe properties of that implemen\u00adtation in Section 3.1. Section \n4 describes the SDP calculus and Section 5 presents an encoding of that calculus into F., using the implementation \nthat we developed in Section 3. Section 6 presents future work, Section 7 presents related work, and \nSection 8 con\u00adcludes. We include Generic Haskell code for the polytypic part of our implementation in \nAppendix A and the full encoding of the SDP calculus into System F. in Appendix B. 2 Catamorphisms for \ndatatypes with embed\u00added functions The following recursive datatype represents the untyped .-calculus \nusing Higher-Order Abstract Syntax (HOAS).3 data Exp = Lam (Exp -> Exp) | App Exp Exp The data constructor \nLam represents .-expressions. How\u00adever, instead of explicitly representing bound .-calculus variables, \nHaskell functions are used to implement binding and Haskell variables are used to represent variables. \nFor example, we might represent the identity function (.x.x)as Lam (\\x -> x) or the in.nite loop (.x.(xx))(.x.(xx)) \nas App (Lam (\\x -> App x x)) (Lam (\\x -> App x x)). Using this datatype, we can implement an interpreter \nfor the .\u00adcalculus. To do so, we must also represent the result values (also using HOAS). data Value \n= Fn (Value -> Value) unFn (Fn x) =x It is tricky to de.ne recursive operations, such as evaluation, \nover this implementation of expressions. The argument, x,to Lam below is a function of type Exp -> Exp. \nTo evaluate it, we must convert x to a function of type Value -> Value. Therefore, we must also simultaneously \nde.ne an inverse to evaluation, called uneval, such that eval . uneval = \\x -> x. This inverse is used \nto convert the argument of x from a Value to an Exp. eval :: Exp -> Value eval (Lam x) = Fn (eval . x \n. uneval) eval (App y z) = unFn (eval y) (eval z) uneval :: Value -> Exp uneval (Fn x) = Lam (uneval \n. x . eval) Consider the evaluation of ((.x.x)(.y.y)). First eval replaces App with unFn and pushes \nevaluation down to the two subcomponents of the application. Next, each Lam is replaced by Fn, and the \nargu\u00adment is composed with eval and uneval. The unFn cancels the .rst Fn, and the identity functions \ncan be removed from the com\u00adpositions. As uneval is right inverse to eval, we can replace each (eval \n. uneval) with the identity function. eval (App (Lam (\\x -> x)) (Lam (\\y -> y))) = unFn (eval (Lam (\\x \n-> x))) (eval (Lam (\\y -> y))) = unFn (Fn (eval . \\x -> x . uneval)) (Fn (eval . \\y -> y . uneval)) = \n(eval . uneval) (Fn (eval . uneval)) = (\\x -> x) (Fn (\\y -> y)) = Fn (\\y -> y) Many functions de.ned \nover Exp will follow this same pattern of recursion, requiring an inverse for Lam and calling themselves \nre\u00adcursively for the subcomponents of App. Catamorphisms capture the general pattern of recursion for \nfunctions de.ned over recur\u00adsive datatypes. For example, foldl is a catamorphism for the list datatype \nand can implement many list operations. For lists of type 3All of the following examples are in the syntax \nof the Haskell language [19]. While some of the later examples require an exten\u00adsion of the Haskell type \nsystem .rst-class polymorphism this extension is supported by the Haskell implementations GHC and Hugs. \nnewtype Rec a = Roll (a (Rec a)) data ExpF a =Lam (a ->a) | App aa type Exp = Rec ExpF lam :: (Exp -> \nExp) -> Exp lam x = Roll (Lam x) app :: Exp -> Exp -> Exp appxy =Roll(Appxy) xmapExpF :: (a -> b, b -> \na) -> (ExpF a -> ExpF b, ExpF b -> ExpF a) xmapExpF (f,g) = (\\x -> case x of Lamx -> Lam(f.x.g) App yz \n->App (f y) (fz), \\x-> case x of Lamx -> Lam(g.x.f) App yz ->App (g y) (gz)) cata :: (ExpF a-> a) -> \n(a -> ExpF a) ->Rec ExpF -> a cata f g(Roll x) = f ((fst (xmapExpF (cata f g, ana f g))) x) ana :: (ExpF \na-> a) -> (a -> ExpF a) ->a -> Rec ExpF ana fg x= Roll (snd (xmapExpF (cata f g, ana f g)) (g x)) Figure \n1. Meijer/Hutton catamorphism [a], foldr replaces [] with a base case of type b and (:) with a function \nof type (a ->b -> b). Meijer and Hutton [16] showed how to de.ne catamorphisms for datatypes with embedded \nfunctions, such as Exp. The cata\u00admorphism for Exp systematically replaces Lam with a function of type \n((a ->a) -> a) and App with a function of type (a ->a -> a). However, just as we de.ned eval simul\u00adtaneously \nwith uneval, the catamorphism for Exp must be simultaneously de.ned with an anamorphism. The catamor\u00adphism \nprovides a way to consume members of type Exp and the anamorphism provides a way to generate them. In \norder to easily specify this anamorphism, we use a slightly more complicated version of the Exp datatype, \nshown at the top of Fig\u00adure 1. This version makes the recursion in the datatype explicit. The newtype \nRec computes the .xed point of type constructors (func\u00adtions from types to types). The type Exp is the \n.xed point of the type constructor ExpF, where the recursive occurrences of Exp have been replaced with \nthe type parameter a. The .rst argument to cata is of type ExpFa->a (combining the two functions mentioned \nabove, of type ((a ->a) -> a) and (a-> a -> a)). The .rst argument to ana has the inverse type a -> ExpF \na. The functions cata and ana are de.ned in terms of xmapExpF,a generalized version of a mapping function \nfor the type construc\u00adtor ExpF. Because of the function argument to Lam, xmapExpF maps two functions, \none of type a-> b and the other of type b-> a. The de.nition of xmapExpF is completely determined by \nthe de.nition of ExpF. With Generic Haskell [5], we can de.ne xmap and automatically generate xmapExpF \nfrom ExpF (see Ap\u00ad data Rec a b=Roll (a(Rec a b)) |Place b dataExpFa =Lam(a->a)|Appaa type Exp a = Rec \nExpF a lam ::(Expa-> Expa)->Expa lam x = Roll (Lam x) app ::Expa-> Expa-> Expa appxy =Roll(Appxy) xmapExpF \n:: (a -> b, b -> a) -> (ExpF a -> ExpF b, ExpF b -> ExpF a) xmapExpF (f,g) = (\\x -> case x of Lamx -> \nLam(f.x.g) App yz ->App (f y) (fz), \\x -> case xof Lamx -> Lam(g.x.f) App yz ->App (g y) (gz)) cata :: \n(ExpF a -> a) -> Exp a-> a cata f (Roll x) = f ((fst (xmapExpF (cata f, Place))) x) cata f (Place x) \n= x Figure 2. Fegaras/Sheard catamorphism pendix A).4 That way, we can easily generalize this catamorphism \nto other datatypes. Unlike map, which is de.ned only for covari\u00adant type constructors, xmap is de.ned \nfor type constructors that have both positive and negative occurrences of the bound variable. The only \ntype constructors of F. for which xmap is not de.ned are those whose bodies contain .rst-class polymorphism. \nFor example, .a : ...\u00df : ..a . \u00df. We can use cata to implement eval. To do so we must de\u00adscribe one step \nof turning an expression into a value (the function evalAux) and one step of turning a value into an \nexpression (the function unevalAux). evalAux :: ExpF Value -> Value evalAux (Lam f) = Fn f evalAux (App \nx y) = (unFn x) y unevalAux :: Value -> ExpF Value unevalAux (Fn f) = Lam f eval :: Exp -> Value eval \nx = cata evalAux unevalAux x Using cata to implement operations such as eval is convenient because the \npattern of recursion is already speci.ed. None of eval, evalAux or unevalAux are recursively de.ned. \nHowever, for some operations, there is no obvious (or ef.cient) inverse. For exam\u00adple, to using cata \nto print out expressions also requires writing a parser. Fegaras and Sheard [9] noted that sometimes \nthe operation of the catamorphism often undoes with f what it has just done with 4Meijer and Hutton s \nversion of xmapExpF only created the .rst component of the pair. In ana where the second component is \nneeded, they swap the arguments. This is valid because fst (xmap (f,g)) = snd(xmap (g,f)). However, while \nthe version that we use here is a little more complicated, it can be de.ned with Generic Haskell. g. \nThis situation occurs when the argument to cata contains only parametric functions. A parametric function \nis one that does not analyze its argument with case or cata. When the argument to cata is parametric, \nFegaras and Sheard showed how to implement cata without ana. The basic idea is that for parametric functions, \nany use of ana during the computation of a catamorphism will always be annihilated by cata in the .nal \nre\u00adsult. Therefore, instead of computing the anamorphism, they use a place holder to store the original \nargument. When cata reaches that place holder, it returns the stored argument. To implement Fegaras and \nSheard s catamorphism, we must rede\u00ad.ne Rec. In Figure 2, we extend it with an extra branch (called Place) \nthat is the place holder. Because Place can contain any type of value, Rec (and consequently Exp) must \nbe parameterized with the type of the argument to Place. This type is the result of the catamorphism \nover the expression. In the implementation of cata, Place is the second argument to xmapExpF instead \nof ana f.It is a right inverse to cata f by de.nition. For example, to count the number of occurrences \nof bound variables in an expression, we might use the following code. countvarAux :: ExpF Int -> Int \ncountvarAux (App x y) = x + y countvarAux (Lam f) = f 1 countvar :: Exp Int -> Int countvar = cata countvarAux \nThe function countvarAux describes what to do in one step. The number of variables in an application \nexpression is the sum of the number of variables in x and the number of variables in y. In the case of \na .-expression, f is a function from the number of variables in a variable expression (i.e. one) to the \nnumber of variables in the body of the lam. For example, to count the variables in (.x. xx): countvar \n(lam (\\x -> app x x)) = (countvar . (\\x -> x + x) . Place) 1 = (\\x -> (countvar (Place x)) + (countvar \n(Place x))) 1 = (countvar (Place 1)) + (countvar (Place 1)) =2 This de.nition of cata only works for \narguments whose function spaces are parametric and who do not use Place. Informally, we call such expressions \nsound and other expressions unsound. Apply\u00ading cata to an unsound expression can return a meaningless \nresult. For example, say we de.ne the following term: badplace :: Exp Int badplace = lam (\\x -> Place \n3) Then countvar badplace = 3, even though it contains no bound variables. Even more importantly for \nhigher-order abstract syntax, unsound datatypes do not correspond to untyped .-calculus expres\u00adsions, \nso it is important to be able to distinguish between sound and unsound representations.5 5It is also \nimportant to distinguish between sound and unsound members of datatypes that have meaningful non-parametric \nrepre\u00adsentations. For these datatypes, the behavior of the Fegaras and Sheard catamorphism on unsound \narguments does not correspond to the Meijer and Hutton version. There are two ways for parametricity \nto fail, corresponding to the two destructors for the type Exp a. A function is not parametric if it \nuses cata or case to examine its argument, as below: badcata :: Exp Int badcata = lam (\\x -> if (countvar \nx == 1) then app x x else x) badcase :: Exp a badcase = lam (\\x -> case x of Roll (App v w) -> app xx \nRoll (Lam f) -> x Place v -> x) Fegaras and Sheard designed a type system to distinguish between sound \nand unsound expressions. Datatypes such as Exp were an\u00adnotated with .ags to indicate whether they had \nbeen examined with either case or cata, and if so, they were prevented from appearing inside of non-.agged \ndatatypes. Furthermore, their language pre\u00advented the user from accessing Place by automatically generating \ncata from the de.nition of the user s datatype. 2.1 Enforcing parametricity with type ab\u00adstraction The \ntype of badcata is Exp Int. This type tells us that something is wrong: the type parameter of Exp is \nconstrained to be Int,so we can only use cata on this expression to produce an Int. The same is true \nfor badplace. Whenever we use cata or Place in an expression, this parameter will be constrained. If \nwe can ensure that only sound expressions have type (forall a. Exp a), then we can use .rst-class polymorphism \nto enforce that the argument to a function is sound. That way, we can be assured that it will behave \nas expected. For example, de.ne a version of cata, called iter0 that may only be applied to sound expressions, \nbelow. The imple\u00admentation of cata uses the argument at the speci.c type (Exp a), so it is safe for iter0 \nto require that its argument has the more general type (forall a. Exp a). iter0 :: (ExpF b -> b) -> (forall \na. Exp a) -> b iter0 = cata However, this new type does not prevent expressions like badcase from being \nthe argument to iter0. We can prevent such case anal\u00adysis inside lam expressions by ruling out case analysis \nfor all terms of type Exp t. If the user cannot use case, then they cannot write badcase. While this \nrestriction means that some operations cannot be naturally de.ned in this calculus, cata alone can de.ne \na large number of operations, as we demonstrate below and in Section 2.2. There are two ways to prohibit \ncase analysis. The .rst way is to reimplement Exp in such a way that cata is the only possible oper\u00adation \n(in other words without using a Haskell datatype). We discuss this alternative in Section 3. The second \nway to prohibit case analysis is to make Rec an abstract type constructor. If the de.nition of Rec is \nhidden by some module boundary, such as with the interface in Figure 3, then the only way to destruct \nan expression of type Exp a is with cata. Because Roll and Place are datatype constructors of Rec, and \ncata pattern matches these constructors, they must all be de.ned in the same module as Rec. However, \nbecause we only need to prohibit case analysis, we can export Roll and Place as the functions roll and \nplace. With roll we can de.ne the terms app and lam anywhere. type Rec a b --abstract dataExpFa =Lam(a->a)|Appaa \ntype Exp a = Rec ExpF a roll :: ExpF (Exp a) -> Exp a place :: a -> Exp a cata ::(ExpFa-> a) -> Expa-> \na Figure 3. Iteration library interface We can also make good use of place. The type forall a. Exp a \nenforces that all embedded functions are parametric, but it can only represent closed expressions. What \nif we would like to examine expressions with free variables? In HOAS, an expression with one free variable \nhas type Exp t -> Exp t. To compute the catamor\u00adphism for the expression, we use place to provide the \nvalue for the free variable. openiter1 :: (ExpF b -> b) -> (Exp b -> Exp b) -> (b-> b) openiter1 f x \n= \\y -> cata f (x (place y)) If we would like to make sure that the expression is sound, we must quantify \nover the parameter type and require that the expression have type forall a. Exp a -> Exp a. iter1 :: \n(ExpF b -> b) -> (forall a. Exp a -> Exp a) -> (b -> b) iter1 = openiter1 With iter1 we can determine \nif that one free variable occurs in an expression. freevarused :: (forall a. Exp a -> Exp a) -> Bool \nfreevarused e = iter1 (\\x -> case x of (App xy) -> x || y (Lam f) -> f False) e True An app expression \nuses the free variable if either the function or the argument uses it. The occurrence of the bound variable \nof a lam is not an occurrence of the free variable, so False is the argument to f, but the expression \ndoes use the free variable if it appears some\u00adwhere in the body of the abstraction. Finally, the program \nworks by feeding in True for the value of the free variable. If the result is True then it must have \nappeared somewhere in the expression. There is no reason to stop with one free variable. There are an \nin.\u00adnite number of related iteration operators, each indexed by the type inside the forall. The types \nof several such iterators are shown below. For example, the third one, iterList, may analyze expres\u00adsions \nwith arbitrary numbers of free variables. iter2 :: (ExpF b -> b) -> (forall a. Exp a -> Exp a -> Exp \na) ->(b -> b-> b) iterFun :: (ExpF b -> b) -> (forall a. (Exp a -> Exp a) -> Exp a) ->((b -> b)-> b) \niterList :: (ExpF b -> b) -> (forall a. ([Exp a] -> Exp a)) -> ([b] -> b) Each of these iterators is \nde.ned by using xmap to map (cata f) and place. Thus we can easily implement them by de.ning the appropriate \nversion of xmap. However, because xmap is a polytypic function, we should be able to automatically generate \nall of these iterators using Generic Haskell. The following code implements these operations. Below, \nthe notation xmap{|g|} generates the in\u00adstance of xmap for the type constructor g. openiter{|g :: * -> \n* |} :: (ExpF a-> a) -> g (Exp a) ->g a openiter{|g|} f = fst (xmap{|g|} (cata f, place)) iter{|g :: \n* -> * |} :: (ExpF a -> a) -> (forall b. g (Exp b)) -> g a iter{|g|} = openiter{|g|} Unfortunately, the \nabove Generic Haskell code cannot automat\u00adically generate all the iterators that we want, such as iter1, \niterFun and iterList. Because of type inference, g can only be a type constructor that is a constant \nor a constant applied to type constructors [13]. In particular, we cannot represent the type con\u00adstructor \n(.a : ..a . a) in Haskell, so we cannot automatically gen\u00aderate the instance iter1 :: (f b-> b) -> (forall \na. (Exp a) -> (Exp a)) -> b -> b Fortunately, using a different extension of Haskell, called functional \ndependencies [14], we can generate these versions of openiter. For each version of iter that we want, \nwe still need to rede.ne the generated openiter with the more restrictive type. iter1 :: (ExpF a -> a) \n-> (forall b.Exp b -> Expb) -> a-> a iter1 = openiter The Iterable class de.nes openiter simultaneously \nwith its in\u00adverse. The parameters m and n should be g(Exp a) and ga, where each instance speci.es g. \n(The type a is a parameter of the type class so that m and n may refer to it.) Also necessary are the \nfunc\u00adtional dependencies that state that m determines both a and n. These dependencies rule out ambiguities \nduring type inference. class Iterable a mn |m -> a, m -> n where openiter :: (ExpF a -> a) -> m -> n \nuniter ::(ExpFa-> a) -> n->m If g is the identity type constructor, then m and n are Exp a and a respectively. \ninstance Iterable a (Exp a) a where openiter = cata uniter f = place Using the instances for the subcomponents, \nwe can de.ne instances for types that contain ->. instance (Iterable a m1 n1, Iterable a m2 n2) => Iterable \na (m1 -> m2) (n1 -> n2) where openiter f x = openiter f . x . uniter f uniter f x = uniter f . x . openiter \nf With these instances, we have a de.nition for openiter{|.a.a . a|}. It is not dif.cult to add instances \nfor other type constructors, such as lists and tuples. 2.2 Examples of iteration We next present several \nadditional examples of the expressiveness of iter0 for arguments of type (forall a. Exp a). The pur\u00adpose \nof these examples is to demonstrate how to implement some of the common operations for .-calculus terms \nwithout case analy\u00adsis. For example, we can use iter0 to convert expressions to strings. So that we have \ndifferent names for each nested binding occurrence, we must parameterize this iteration with a list of \nvariable names. Haskell s list comprehension provides us with an in.nite supply of strings. vars :: [String] \nvars = [ [i] | i <-[ a .. z ] ] ++ [ i : show j | j <-[1..], i <-[ a .. z ] ] showAux :: ExpF ([String] \n-> String) -> ([String] -> String) showAux (App x y) vars = \"(\" ++ (x vars) ++ \" \" ++ (y vars) ++ \")\" \nshowAux (Lam z) (v:vars) = \"(fn \" ++ v ++ \". \" ++ (z (const v) vars) ++ \")\" show :: (forall a. Exp a) \n-> String show e = iter0 showAux e vars Applying show to an expression produces a readable form of the \nexpression. show (lam (\\x -> lam (\\y -> app x y))) = (fn a. (fn b. (a b))) Another operation we might \nwish to perform for a .-calculus ex\u00adpression is to reduce it to a simpler form. As an example, we next \nimplement parallel reduction for a .-calculus expression.6 Parallel reduction differs from full reduction \nin that it does not reduce any newly created redexes. Therefore, it terminates even for expres\u00adsions \nwith no \u00df-normal form. Parallel reduction may be speci.ed by the following inductive de.nition. M . M' \nM . M' N . N' x . x .x.M . .x.M' MN . M'N' M . M' N . N' (.x.M)N . M'{x/N'} We use iter0 to implement \nparallel reduction below. The tricky part is the case for applications. We must determine whether the \n.rst component of an application is a lam expression, and if so, perform the reduction. However, we cannot \ndo a case analysis on expressions, as the type Exp a is abstract. Therefore, we imple\u00adment parallel reduction \nwith a pairing trick7. As we iterate over the term we produce two results, stored in the following record: \ndataPARa=PAR{par ::Expa, apply ::Exp a -> Exp a } The .rst component, par, is the actual result we want \nthe parallel reduction of the term. The second component, apply, is a func\u00ad 6This example is from Sch\u00a8urmann \net. al [24]. 7Pairing was .rst used to implement the predecessor operation for Church numbers. The iteration \nsimultaneously computes the desired result with auxiliary operations. tion that we build up for the application \ncase. In the case of a lam expression, apply performs the substitution in the reduced term. Otherwise, \napply creates an app expression with its argument and the reduced term.8 parAux :: ExpF (PAR a) -> PAR \na parAux (Lam f) = PAR{par =lam(par.f.var), apply = par .f. var } where var :: Expa -> PARa var x= PAR \n{par =x, apply =app x} parAux (App x y) = PAR { par = apply x (par y), apply = app (apply x (par y)) \n} parallel :: (forall v. Exp v) -> (forall v. Exp v) parallel x = par (iter0 parAux x) For example: show \n(parallel (app (lam (\\x -> app x x)) (lam (\\y -> y)))) = \"((fn a. a) (fn a. a))\" While we could not write \nthe most natural form of parallel reduc\u00adtion with iter0, other operations may be expressed in a very \nnat\u00adural manner. For example, we can implement the one-pass call-by\u00advalue CPS-conversion of Danvy and \nFilinski [6]. This sophisticated algorithm performs administrative redexes at the meta-level so that \nthe result term has no more redexes than the original expres\u00adsion. The algorithm is based on two mutually \nrecursive operations: cpsmeta performs closure conversion given a meta-level continua\u00adtion (a term of \ntype Exp a-> Exp a), and cpsobj does the same with an object-level continuation (a term of type Exp a). \ndata CPS a =CPS { cpsmeta :: (Exp a -> Exp a) -> Exp a, cpsobj ::Expa-> Expa} If we are given a value \n(i.e. a .-expression or a variable) the func\u00adtion value below describes its CPS conversion. Given a meta\u00adcontinuation \nk, we apply k to the value. Otherwise, given an object continuation c, we create an object application \nof c to the value. value :: Exp a -> CPS a value x =CPS { cpsmeta = \\k -> k x, cpsobj =\\c -> appcx} The \noperation cpsAux takes an expression whose subcomponents have already been CPS converted and CPS converts \nit. For applica\u00adtion, translation is the same in both cases except that the meta-case converts the meta-continuation \ninto an object continuation with lam. cpsAux :: ExpF (CPS a) -> CPS a cpsAux (App e1 e2) = CPS { cpsmeta \n= \\k -> appexp (lam k), cpsobj = appexp } where appexp c = (cpsmeta e1) (\\y1 -> (cpsmeta e2) (\\y2 -> \napp (app y1 y2) c)) 8In Haskell, the notation apply x projects the apply compo\u00adnent from the record x. \ntype Rec f a=(f a -> a) -> a data ExpF a =Lam (a ->a) | App aa type Exp a = Rec ExpF a roll :: ExpF (Exp \na) -> Exp a roll x = \\f -> f (fst (xmapExpF (cata f, place)) x) place :: a -> Exp a place x =\\f -> x \nlam :: (Exp a-> Exp a)-> Exp a lam x = roll (Lam x) app :: Exp a-> Exp a-> Exp a app yz =roll (App yz) \nxmapExpF :: (a -> b, b -> a) -> (ExpF a -> ExpF b, ExpF b -> ExpF a) xmapExpF (f,g) = (\\x -> case x of \nLamx -> Lam(f.x.g) App yz ->App (f y) (fz), \\x-> case x of Lamx -> Lam(g.x.f) App yz ->App (g y) (gz)) \ncata :: (ExpF a -> a) -> Exp a-> a catafx =xf iter0 :: (ExpF a -> a) -> (forall b. Exp b) -> a iter0 \n= cata Figure 4. Catamorphism in the F. fragment of Haskell For functions, we use value, but we must \ntransform the function to bind both the original and continuation arguments and transform the body of \nthe function to use this object continuation. The outer lam binds the original argument. We use value \nfor this argument in f and cpsobj yields a body expecting an object continuation that the inner lam converts \nto an expression. cpsAux (Lam f) = value (lam (lam . cpsobj . f . value)) Finally, we start cps with \niter0 by abstracting an arbitrary dy\u00adnamic context a and transforming the argument with respect to that \ncontext. cps :: (forall a. Exp a) -> (forall a. Exp a) cps x= lam (\\a -> cpsmeta (iter0 cpsAux x) (\\m \n-> app a m)) show (cps (lam (\\x -> app x x))) = \"(fn a. (a (fn b. (fn c. ((b b) c)))))\" Above, a is the \ninitial continuation, b is the argument x, and c is the continuation for the function.  3 Encoding iteration \nin F. In the previous section, we implemented iter as a recursive func\u00adtion and used a recursive type, \nRec, to de.ne Exp. To prevent case analysis, we hid this de.nition of Rec behind a module boundary. However, \nthis module abstraction and is not the only way to prevent case analysis. Furthermore, term and type \nrecursion is not neces\u00adsary to implement this datatype. We may de.ne iter and Rec in the fragment of \nHaskell that corresponds to F. [10] so that iteration is the only elimination form for Rec. This implementation \nappears in Figure 4. The encoding is similar to the encoding of covariant datatypes in the polymorphic \n.-calculus [3] (or to the encoding of Church nu\u00admerals). We encode an expression of type Exp a as its \nelimination form. For example, something of type Exp a should take an elimi\u00adnation function of type (ExpF \na -> a) and return an a. To imple\u00adment cata we apply the expression to the elimination function. To create \nan expression, roll must encode this elimination. There\u00adfore, roll returns a function that applies its \nargument f (the elimi\u00adnation function) to the result of iterating over x. Again, to use xmap we need \na right inverse for cata f. The term place in Figure 4 is an expression that when analyzed returns its \nargument. We can show that place is a right inverse by expanding the above de.ni\u00adtions: cata f . place \n= (\\x -> cata f (place x)) = (\\x -> (place x) f) = (\\x -> ((\\y -> x) f)) = (\\x -> x) 3.1 Reasoning about \niteration There are powerful tools for reasoning about programs written in the polymorphic .-calculus. \nFor example, we know that all pro\u00adgrams that are written in F. will terminate. Therefore, we can ar\u00adgue \nthat the examples of the previous section are total on all in\u00adputs that may be expressed in the polymorphic \n.-calculus, such as app (lam (\\x -> app x x))(lam (\\x -> app x x)). Un\u00adfortunately, we cannot argue that \nthese examples are total for ar\u00adbitrary Haskell terms. For example, calling any of these routines on \n(lam (let f x= fx in f)) will certainly diverge. Further\u00admore, even if the arguments to iteration are \nwritten in F., if the op\u00aderation itself uses type or term recursion, then it could still diverge. For \nexample, using the recursive datatype Value from Section 2, we can implement the untyped .-calculus evaluator \nwith iter0. Parametricity is another way to reason about programs written in F.. As awkward as they may \nbe, one of the advantages to pro\u00adgramming with catamorphisms instead of general recursion is that we \nmay reason about our programs using algebraic laws that follow from parametricity. While the following \nlaws only hold for F.,we may be able to prove some form of them for Haskell using tech\u00adniques developed \nby Johann [12]. Using parametricity, we can derive a free theorem [28] about ex\u00adpressions of type (forall \na. (b a -> a) -> a).If x has this type, then f . f = id and f . g = h . fst (xmap|b|(f,f )) => f(xg)= \nxh The equivalence in this theorem is equivalence in some parametric model of F., such as the term model \nwith \u00df.-equivalence. Using the free theorem, we can prove a number of properties about itera\u00adtion. First, \nwe can show that iterating roll is an identity function, that iter0 roll = id. Using this result we can \nshow the unique\u00adness property for iter, which describes when a function is equal to an application of \niter. It resembles an induction principle for iter0. f . f = id and f . roll = h . fst (xmap|b|(f,f )) \n<=> f=iter0h The <= direction follows directly from the implementation of iter0 and roll. The => direction \nfollows from the free theorem. Finally, the fusion law can be used to combine the composition of a function \nf and an iteration into one iteration. This law follows directly from the free theorem. f . f = id and \nf . g = h . fst(xmap|b|(f,f )) => f . iter0 g = iter0 h  However, there is an important property about \nthis encoding of the .-calculus that we have not proven. Adequacy states that if a F. term is of type \nforall a. Exp a and is in canonical form, then it should be the encoding of the canonical form of some \n.-calculus expression. In other words, there is no extra junk in the type forall a. Exp a, such as badcase. \nAs a .rst step towards prov\u00ading this result, we next show how this F. library can encode a lan\u00adguage \nwith iteration over HOAS that itself adequately embeds the .-calculus.  4 Enforcing parametricity with \nmodal types In the next section, we formally describe the connection between the interface we have provided \nfor iteration over higher-order ab\u00adstract syntax and the modal calculus of Sch\u00a8urmann, Despeyroux and \nPfenning (SDP) [24]. We do so by using this library to give a sound and complete embedding of the SDP \ncalculus into F.. First, we provide a brief overview of the static and dynamic semantics of this calculus. \nThe syntax of the SDP calculus is shown in Figure 5. The SDP calculus enforces the parametricity of function \nspaces with modal types. Modal necessity in logic is used to indicate those propositions that are true \nin all worlds. Consequently, these propo\u00adsitions can make use of only those assumptions that are also \ntrue in all worlds. In Pfenning and Davies [20] interpretation of modal necessity, necessarily true propositions \ncorrespond to those formu\u00adlae that can be shown to be valid. Validity is de.ned as derivable with respect \nto only assumptions that themselves are valid assump\u00adtions. As such, the typing judgments have two environments \n(also called contexts), one for valid assumptions, ., and one for local assumptions, .. The terms corresponding \nto the introduction and elimination forms for modal necessity are box and let box.We give them the following \ntyping rules: .;\u00d8 fM : A .;. fboxM : DA .;. fM1: DA1 . {x : A1};. fM2: A2 .;. flet box x : A1 = M1 inM2: \nA2 A boxed term, M, has type DA only if it has type A with respect to the valid assumptions in ., and \nno assumptions in local environ\u00adment. The let box elimination construct allows for the introduction of \nvalid assumptions into ., binding the contents of the boxed term M1 in the body M2. This binding is allowed \nbecause the contents of boxed terms are well-typed themselves with only valid assump\u00adtions. Another way \nto think about modal necessity is that terms with boxed type are closed and do not contain any free variables, \nexcept those that are bound to closed terms themselves. Operationally, boxed terms behave like suspensions, \nwhile let box substitutes the contents of a boxed term for the bound variable. Be\u00adcause the operational \nsemantics is de.ned simultaneously with con\u00ad (Pure Types) B ::= b |1 |B1 .B2 |B1 \u00d7B2 (Types) A ::= B \n|A1 .A2 |A1 \u00d7A2 |DA (Terms) M ::= x |c |()|.x : A.M |M1M2 | box M |let box x : A = M1 inM2 |(M1,M2)|fstM \n|sndM |iter [A1,A2][T] M (Term Replacement) T ::= \u00d8 |T {x.M}|T {c.M}(Pure Environment) . ::= \u00d8 |. {x \n: B}(Valid Environment) . ::= \u00d8 |. {x : A}(Local Environment) . ::= \u00d8 |. {x : A}(Signatures) S ::= \u00d8 \n|S {c : B .b} Figure 5. Syntax of SDP calculus version to canonical forms, it is parameterized by the \nenvironment . that describes the types of free local variables appearing in the expression. . fM1 '.box \nM1 ' : DA1 . fM2{M1' /x}'.V : A2 . flet box x : A1 = M1 inM2 '.V : A2 To enforce the separation between \nthe iterative and parametric func\u00adtion spaces, the SDP calculus de.nes those types, B, that do not contain \na D type to be pure . Objects in the calculus with type DB, boxed pure types, can be examined intensionally \nusing an iteration operator, while objects of arbitrary impure type, A, cannot. This forces functions \nof pure type, .x : B1..M : B1 .B2,tobe paramet\u00adric. This is because the input, x, to such a function \ndoes not have a boxed pure type, and there is no way to convert it to one x will not be free inside \nof a boxed expression in M. Consequently, the functions of pure type may only treat their inputs extensionally, \nmaking them parametric. The language is parameterized by a constant type b and a signature, S,of data \nconstructor constants, c, for that base type. Each of the constructors in this signature must be of type \nB .b. Because B is a pure type, these constructors may only take parametric functions as arguments. For \nexample, consider a signature describing the untyped .\u00adcalculus, S = {app : b \u00d7b .b,lam : (b .b) .b}, \nwhere the constant type b corresponds to Exp. Using this signature, we can write a function to count \nthe number of bound variables in an expression, as we did in Section 2.9 countvar \" .x : Db. iter[Db,int][{app \n..y : int..z : int.y + z, lam .. f : int .int. f 1}] x The term iter intensionally examines the structure \nof the argu\u00adment x and replaces each occurrence of app and lam with .y : int..z : int.y + z and . f : \nint .int. f 1 respectively. The typing rule for iter is the following: .;. fM : DB .;. fT : A(S) .;. \nfiter [DB,A][T] M : A(B) The argument to iteration, M, must have a pure closed type to be analyzable. \nAnalysis proceeds via walking over M and using the 9For simplicity, our formal presentation of SDP (in \nFigure 5) does not include integers. However, it is straightforward to extend this calculus to additional \nbase types. replacement T, a .nite map from constants to terms, to substitute for the constants in the \nterm M. The type A is the type that will replace the base type b in the result of iteration. The notation \nA(B)substitutes A for the constant b in the pure type B. Each term in the range of the replacements must \nalso agree with replacing b with A. We verify this fact with the judgment .;. fT : A(S), which requires \nthat if T(c)=Mc and S(c)=Bc, then Mc must have type A(Bc). Operationally, iteration in the SDP calculus \nworks in the following fashion. . fM '.boxM ' : DB ' \u00d8 fM '.V : B ' . f(A,.,T)(V )'.V : A(B) . fiter[DB,A][T]M \n'.V : A(B) First, the argument to iteration M is evaluated, . fM '.box M ' : DB, producing a boxed object \nM ' . M ' is then evaluated to .-long ' canonical form via \u00d8 fM '.V : B. Next we perform elimination \n'' of that canonical form, (A,.,T)(V ), walking over V and using T to replace the occurrences of constants. \nFinally, we evaluate that ' result, . f(A,.,T)(V )'.V : A(B). In order to simplify the presentation of \nthe encoding, we have made a few changes to the SDP calculus. First, while the language pre\u00adsented in \nthis paper has only one pure base type b, the SDP calculus allows the signature S to contain arbitrarily \nmany base types. How\u00adever, the extension of the encoding to several base types is straight\u00adforward. Also, \nin order to make the constants of the pure language more closely resemble datatype constructors, we have \nforced them all to be of the form B .b instead of any arbitrary pure type B.To facilitate this restriction, \nwe add unit and pairing to the pure frag\u00adment of the calculus so that constructors may take any number \nof arguments.  5 Encoding SDP in F. The terms that we de.ned in Section 3, roll and iter, correspond \nvery closely to the constructors and iteration primitive of the SDP calculus. In this section, we strengthen \nthis observation by showing how to encode all programs written in the SDP calculus into F. using a variation \nof these terms. There are two key ideas behind our encoding: We use type abstraction to ensure that \nthe encoding of boxed objects obeys the closure property of the source language, and prevents variables \nfrom the local environment from appearing inside these terms. To do so, we parameterize our encoding \nby a type that represents the current world and maintain the in\u00advariant that all variables in the local \nenvironment mention the current world in their types. Because a term enclosed within a box must be well-typed \nin any world, when we encode a boxed term we use a fresh type variable to create an arbitrary world. \nWe then encode the enclosed term with that new world and wrap the result with a type abstraction. As \na consequence, the encoding of a data-structure within a box cannot contain free local variables because \ntheir types would mention that fresh type variable outside of the scope of the type abstrac\u00adtion.  We \nencode constants in the source language as their elimina\u00adtion form with roll. Furthermore, we restrict \nthe result of elimination to be of the type that is the world in which the term was encoded. However, \nthe encoding of boxed expres\u00ad  sions quanti.es over that world, allowing the resulting com\u00adputations \nto be of arbitrary type. The encoding of the SDP calculus can be broken into four primary pieces: the \nencodings for signatures, types, terms, and replace\u00adments. To simplify our presentation, we extend the \ntarget language with unit, void, products, and variants. The syntax of these terms appears in Figure \n6. This extension does not weaken our results as there are well known encodings of these types into F.. \nIn the re\u00admainder of this section, we present the details of the encoding and describe the most interesting \ncases. The full speci.cation of this encoding appears in Appendix B. Signatures. The encoding of signatures \nin the SDP calculus, no\u00adtated t(S), corresponds to generating the type constructor whose .xed point de.nes \nthe recursive datatype. (For example, ExpF in Section 2.) The argument of the encoding, a speci.ed world \nt, cor\u00adresponds to the argument of the type constructor. For this encoding, we assume the aid of an injective \nfunction L that maps data constructors in the source language to distinct labels in the target language. \nWe also need an operation called parameteri\u00adzation, notated t(B)and de.ned in Appendix B.1. This operation \nparameterizes pure types in the source calculus with respect to a given world in the target language, \nand produces a type in the tar\u00adget language. Essentially, t(B) substitutes the type t for the base type, \nb,in B. We encode a signature as a variant. Each .eld corresponds to a constant ci in the signature, \nwith a label according to L, and a type that is the result of parameterizing the argument type of ci \nwith the provided type. .ci .dom(S) S(ci)=Bi .b t(S)\" (L(c1): t(B1),...,L(cn): t(Bn)) We often use parameterization \nand the signature translation to build type constructors in the target language, so we de.ne the following \ntwo abbreviations: B* \" .a : ..a(B) S* \" .a : ..a(S) Types. As with the encoding of signatures, the encoding \nof types is parameterized by the worlds in which they occur. We write the judgment for encoding a type \nA in the source calculus in world t as . fA tt' . The environment . tracks type variables allocated during \nthe translation and allows us to chose variables that are not in scope. The two interesting cases for \nencoding types from the source calculus are those for the base type and for boxed types. The case for \nb corresponds to Rec ExpF a from Section 3. Therefore, we de.ne the abbreviation Rec S* a \" (S*a .a).a, \nintuitively a .xed point of S*, to the same idea of encoding a datatype as its elimination form. . fb \nt Rec S* t The rule for boxed types uses type abstraction to ensure the result is parametric with respect \nto its world. Na\u00a8ively, we might expect to use a fresh type variable as the new world and then encode \nthe contents of the boxed type with that type variable. This encoding ensures that the type is parametric \nwith respect to its world and then quanti.es over the result. a ... {a : .}fA at' WRONG! . fDA t .a:..t' \n (Kinds) . ::= . | .1 . .2 (Types) t ::= 1 | 0 | a | t1 . t2 |. a:..t | t1 \u00d7 t2 |( l1: t1,...,ln : tn)| \n.a : ..t | a | t1t2 (Terms) e ::= x |() | .x : t.e | e1e2 | .a:..e | e[t] |( e1,e2)| fste | snde | injleof \nt | case eofinjl1 x1 ine1 ... injln xn inen (Type Variable Environment) . ::= \u00d8 | . { a : .}(Term Environment) \nG ::= \u00d8 | G { x : t} Figure 6. Syntax of F. with unit, void, products, and variants However, with this \nencoding we violate the invariant that the types of all free local variables mention the current world, \nbecause the encoding does not involve t. Instead, we use the fresh type vari\u00adable to create a new world \nfrom the current world and consider a as a world transformer . During the translation, a term will be \nen\u00adcoded with a stack of world transformers, somewhat akin to stack of environments in the implicit formulation \nof modal types [7]. a . .. { a : . . .}f A at t' . f DA t . a:. . ..t' The na\u00a8ive translation of the \nunit type also forgets the current world. For this reason, we add a non-standard unit to F. that is parameter\u00adized \nby the current world. In other words, the unit type 1 is of kind . . . and the unit term () has type \n. a:..1(a). Our type translation instantiates this type with the current world. . f 1 t 1[t] The remaining \ntypes in the SDP language are encoded recursively in a straightforward manner. The complete rules can \nbe found in Appendix B.3. Terms and replacements. We encode the source term, M, with the judgment .;. \nf M t e. In addition to the current world, t, and the set of allocated type variables, ., the encoding \nof terms is also parameterized by a set of term variables, .. This set of variables allows the encoding \nto distinguish between variables that were bound with . and those bound with let box. We will elaborate \non why this set is necessary shortly. Our encoding of boxed terms follows immediately from the encod\u00ading \nof boxed types. Here we encode the argument term with respect to a fresh world transformer applied to \nthe present world and then wrap the result with a type abstraction. a . .. { a : . . .} ;. f M at e .;. \nf box M t .a:. . ..e We encode let box by converting it to an abstraction and application in the target \nlanguage. However, one might note the discrepancy between the type of the variable we bind in the abstraction \nand the type we might na\u00a8ively expect. . f DA1 tt1 .;. f M1 t e1 .;. { x}f M2 t e2 .;. f let box x : \nA1 = M1 inM2 t (.x : t1.e2)e1 The type of x is A1 and so one might assume that the type of x in the target \nshould be the encoding of A1 in the world t. However, let box allows us to bind variables that are accessible \nin any world and using A1 encoded against t would allow the result to be used cata : . a:..(S* a . a) \n. (Rec S* a) . a cata \" .a:.... f : (S* a . a)..y : (Rec S* a).yf place : . a:..a . Rec S* a place \" \n.a:...x : a.. f : (S* a . a).x xmap{| t|} : . a:... \u00df:..(a . \u00df \u00d7 \u00df . a) . (ta . t\u00df \u00d7 t\u00df . ta) openiter{| \nt|} : . a:..(S* a . a) . t(Rec S* a) . ta openiter{| t|} \" .a:... f : S* a . a. fst(xmap{| t|} [Rec S* \na][a]( cata[a] f , place[a]) ) iter{| t|} : . . :... a:..(S* a . a) . (. \u00df:. . ..t(Rec S* (\u00df.)) . ta \niter{| t|} \" .. :...a:... f : S* a . a. .x : (. \u00df : . . ..t(Rec S* (\u00df.))).openiter{| t|} [a] f (x[a]) \nroll : . a:..S* (Rec S* a) . Rec S* a roll \" .a:...x : S* (Rec S* a). . f : S* a . a. f (openiter{| S*|} \n[a] fx) Figure 7. Library routines only in the present world. Because the encoding of M1 will evalu\u00adate \nto a type abstraction, a term parametric in its world, we do not immediately unpack it by instantiating \nit with the current world. Instead we pass it as x and then, when x appears we instantiate it with the \ncurrent world. Consequently, we use . to keep track of variables bound by let box. When encoding variables, \nwe check whether x occurs in . and perform instantiations as necessary. x . . x . . .;. f x t x .;. f \nx t x[.a : ..t] If the variable is in ., then it is applied to a world transformer that ignores its argument, \nand returns the present world. This essentially replaces the bottom of the world transformer stack captured \nby the type abstraction substituted for x with the world t. Doing so ensures that if we substitute the \nencoding of a boxed term into the encoding of another boxed term, the type correctness of the embedding \nis maintained by correctly propagating the enclosing world. Figure 7 shows the types and de.nitions of \nthe library routines used by the encoding. The only difference between it and Figure 4 is that iter abstracts \nthe current world and requires that its argument be valid in any transformation of the current world. \nAgain, we make use of the polytypic function xmap to lift cata to arbitrary type constructors . Because \nxmap is de.ned by the structure of a type constructor t, we cannot directly de.ne it as a term in F.. \nInstead, we will think of xmap{| t|} as macro that expands to the mapping function for the type constructor \nt. (We use the notation {|\u00b7|} to distinguish between polytypic instantiation and parametric type instantiation.) \nThis expansion is done according to the de.ni\u00adtion in Appendix A. We do not cover the implementation \nhere, see Hinze [11] for details. Encoding constants in the source calculus makes straightforward use \nof the library routine roll. We simply translate the constant into an abstraction that accepts a term \nthat is the encoding of the argu\u00adment of the constant, and then uses roll to transform the injection \ninto the encoding of the base type, Rec S* t. S(c)= B . b . f B ttB .;. f c t.x : tB.roll[t](injL(c) \nx of S*(Rec S* t)) The encoding of iteration is similarly straightforward. We instanti\u00adate our polytypic \nfunction iter with a type constructor created from parameterizing B, and then apply it to the current \nworld and the en\u00adcodings of the intended result type A, the replacement term T and argument term M. tA \n. f A ttA .;. f Tt eT.;. f M t eM .;. f iter[DB,A][T] M t iter{|B*|}[t][tA]eT eM The encoding of replacements \nT is uncomplicated and analogous to the encoding of signatures. We construct an abstraction that con\u00adsumes \nan instance of an encoded signature, dispatching the variant using a case expression. In each branch, \nthe encoding of the corre\u00adsponding replacement is applied to the argument of the injection. .ci . dom(T) \n.;. f T(Ci) t ei .;. f T ttA.x : S*tA.case x ofinjL(c1) y1 in(e1y1) ... injL(cn) yn in(enyn) The encodings \nfor the other terms in the source language are straightforward and appear in Appendix B.4. Now that we \nhave de.ned all of our encoding for any closed term M in the SDP cal\u00adculus, we put everything together \nto construct a term e in our target calculus using the initial judgment \u00d8;\u00d8 f M 0 e. We use the void \ntype as the initial world to enforce the parametricity of unboxed constants. 5.1 Properties of the encoding \nWe have proven a number of desirable properties concerning this encoding. However, before we can state \nthese properties, we must .rst de.ne the relationship between the environments in the source and target \ncalculi. These relations hold when all types from the local environment are encoded with the current \nworld, and all types from the valid environment are .rst boxed then encoded with any world. DEFINITION \n5.1 (ENCODING TYPING ENVIRONMENTS). We write . f . tG1 and . f .G2 to mean that .x : A . .,x : tA . G1 \nwhen . f A ttA .x : A . .,x : tA . G2 when there exists . f t' such that . f DA t' tA The relation for \nvalid environments above is not parameterized by the current world. A single valid environment may be \nencoded as many different target environments, depending on what worlds are chosen for each type in the \nenvironment. However, in some sense the encodings are equivalent. If the translation of M type checks \nwith one encoding of ., it will type check with any other encoding of .. The encoding is type preserving. \nIf we encode a well-typed term M, the resulting term will be well-typed under the appropriately translated \nenvironment. Furthermore, the converse is also true. If the encoding of a term M is well-typed in the \ntarget language, then M must have been well-typed in the source. This means that the target language \npreserves the abstractions of the source language. THEOREM 5.2 (STATIC CORRECTNESS). Assume . f t and \n. f . tG1 and . f .G2. 1. If .;dom(.) f M t e then .;. f M : A and . f A ttA . .;G1 G2 f e : tA tA 2. \nIf .;dom(.) f Tt e. then .;. f T : A(S) and . f A ttA . .;G1 G2 f e. : tA(S). tA PROOF. By mutual induction \nover the translation of terms (.;dom(.) f M t e) and of replacements tA (.;dom(.) f Tt e.). Furthermore, \nsource evaluation and canonicalization is the same as \u00df.-equivalence in the target calculus. THEOREM \n5.3 (DYNAMIC CORRECTNESS). If \u00d8;. f M : A ' and \u00d8;. f M t e and \u00d8;. f V t e and \u00d8 f A ttA and \u00d8;. f \u00d8;. \ntG then 1. . f M '. V : A . \u00d8;G f e =\u00df. e ' : tA. 2. . f M . V : A . \u00d8;G f e =\u00df. e ' : tA.  PROOF. \nThe forward direction follows by simultaneous induction on the evaluation of M (. f M '. V : A) and the \nconversion of M to canonical form (. f M . V : A). The reverse direction follows from the forward direction \nand from the fact that evaluation in the SDP calculus is deterministic and total.  6 Future work Although \nwe have shown a very close connection between SDP and its encoding in F., we have not shown that this \nencoding is adequate. We would like to show that if t is the image of an SDP type, then all terms of \ntype t are equivalent to the encoding of some SDP term. In other words, there is no extra junk of type \nt. Show\u00ading this result would also show that encoding the .-calculus with app and lam is adequate, because \nthe SDP calculus can already adequately encode the .-calculus. Alternatively, we could try to show adequacy \nwith respect to the .\u00adcalculus directly using a different method. It may also be possible to do so for \nthe simpler encoding of modal types, informally presented in the .rst part of the paper, that uses .rst-order \nquanti.cation and discards the current world. Whereas this simpler encoding allows the translation of \nsome terms that are rejected by the SDP calculus to type check (for example, .x : Db. box x), it may \nstill be adequate for encoding the untyped .-calculus. One important extension of this work is the case \noperator. Because there are limitations to what may be de.ned with iter, the SDP calculus also includes \na construct for case analysis of closed terms. However, we have not yet found an obvious correspondence \nfor case in our encoding. Another further area of investigation is into the dual operation to iter, the \nanamorphism over datatypes with embedded functions. An implementation of this operation, called coiter, \nis below. The coiter term is an anamorphism it generates a recursive data structure from an initial seed. \ndata Dia f a=In (f (Dia fa), a) coroll ::Diafa->f(Diafa) coroll (In x) = fst x coplace :: Dia f a -> \na coplace (In x) = snd x coiter0 :: (a -> f a) -> a -> (exists a. Dia f a) coiter0 g b = In (snd (xmap \n(coplace, coiter0 g) (g b)), b) Instead of embedding the recursive type in a sum, we embed it in a product. \nThe two selectors from this product have the dual types to roll and place. In the de.nition of coiter0 \nwe use coplace as the inverse where we would have used cata in the de.nition of ana. A term of type (exists \na. Dia b a) corresponds to the possibility type (0 b) in a modal calculus. However, while a general anamorphism \nis an inverse of a catamorphism, coiter is not an inverse to iter. In fact, iter cannot consume what \ncoiter pro\u00adduces, giving doubts to its practical use. (On the other hand, ana itself has seen little \npractical use for datatypes with embedded func\u00adtions.) From a logical point of view, this restriction \nmakes sense. Combining anamorphisms and catamorphisms (even for datatypes without embedded functions) \nleads to general recursion. 7 Related work The technique we present, using polymorphism to enforce para\u00admetricity, \nhas appeared under various guises in the literature. For example, Shao et al. [27] use this technique \n(one level up) to imple\u00adment type-level intensional analysis of recursive types. They use higher-order \nabstract syntax to the represent recursive types and re\u00admark that the kind of this type constructor requires \na parametric function as its argument. However, they do not make a connec\u00adtion with modal type systems, \nnor do they extend their type-level iteration operator to higher kinds. Xi et al. [31] remark on the \ncor\u00adrespondence between HOAS terms with the place operator (which they call HOASvar) and closed terms \nof Mini-ML.but do not in\u00ad e vestigate the relationship or any form of iteration. While higher-order abstract \nsyntax has an attractive simplicity, the dif.culties programming and reasoning about structures encoded \nwith this technique have motivated research into language exten\u00adsions for working with higher-order abstract \nsyntax or alternative approaches altogether. Dale Miller developed a small language called ML. [17] that \nintroduces a type constructor for terms formed by abstracting out a parameter. These types can be thought \nof as function types that can be intensionally analyzed through pattern matching. Pitts and Gabbay built \non the theory of FM-sets to de\u00adsign a language called FreshML [23] that allows for the manipu\u00adlation \nand abstraction of fresh names . Nanevski [18] combines fresh names with modal necessity to allow for \nthe construction of more ef.cient residual terms, while still retaining the ability to eval\u00aduate them \nat runtime. The Delphin Project [25] by Sch\u00a8urmann et al. develops a functional language for manipulating \ndatatypes that are terms in the LF logical framework. Because higher-order abstract syntax is the primary \nrepresentation technique in LF, Delphin pro\u00advides operations for matching over higher-order LF terms \nin regular worlds. The SDP calculus uses modal necessity to restrict match\u00ading to closed worlds, so regular \nworlds provide additional .exi\u00adbility without the dif.culties of matching in an open world. The Hybrid \n[2] logical framework provides induction over higher-order abstract syntax by evaluation to de Bruijn \nterms, which provide straightforward induction. There is a long history of encoding modality in logic, \nbut only re\u00adcently has the encoding of modal type systems been explored. Acar et al. [1] use modal types \nin a functional language that provides con\u00adtrol over the use of memoization, and implement it as a library \nin SML. Because SML does not have modal types or .rst-class poly\u00admorphism, they use run-time checks to \nenforce the correct use of modality. Davies and Pfenning [7] presented, in passing, a simple encoding \nof the modal .-calculus into the simply-typed .-calculus that preserves only the dynamic semantics. Washburn \nexpanded upon this encoding, showing that it bisimulates the source calcu\u00adlus [29]. 8 Conclusion While \nother approaches to de.ning an induction operator over higher-order abstract syntax require type system \nextensions to en\u00adsure the parametricity of embedded function spaces, the approach that we present in \nthis paper requires only type polymorphism. Be\u00adcause of this encoding, we are able to implement iteration \noperators for datatypes with embedded parametric functions directly in the Haskell language. However, \ndespite its simplicity, our approach is equivalent to pre\u00advious work on induction operators for HOAS. \nWe demonstrate this generality by showing how the modal calculus of Sch\u00a8uermann, De\u00adspeyroux and Pfenning \nmay be embedded into F. using this tech\u00adnique. In fact, the analogy of representing boxed terms with \npoly\u00admorphic terms makes semantic sense: a proposition with a boxed type is valid in all worlds and polymorphism \nmakes that quanti.ca\u00adtion explicit. Acknowledgements We thank Margaret DeLap, Eijiro Sumi, Stephen Tse, \nStephan Zdancewic and the anonymous ICFP reviewers for providing us with feedback concerning this paper. \n 9 References [1] U. Acar, G. Blelloch, and R. Harper. Selective memoiza\u00adtion. In Thirtieth ACMSIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, New Orleans, LA, Jan. 2002. [2] S. Ambler, R. L. Crole, \nand A. Momigliano. Combining higer order abstract syntax with tactical theorem proving and (co)induction. \nIn Theorem Proving in Higher Order Logics, 15th International Conference, TPHOLs 2002, Hampton, VA, USA, \nAugust 20-23, 2002, Proceedings, volume 2410 of Lec\u00adture Notes in Computer Science. Springer, 2002. [3] \nC. B\u00a8ohm and A. Berarducci. Automatic synthesis of typed .-programs on term algebras. Theoretical Computer \nScience, 39:135 154, 1985. [4] A. Church. A formulation of the simple theory of types. Jour\u00adnal of Symbolic \nLogic, 5:56 68, 1940. [5] D. Clarke, R. Hinze, J. Jeuring, A. L\u00a8oh, and J. de Wit. The Generic Haskell \nuser s guide. Technical Report UU-CS-2001\u00ad26, Utrecht University, 2001. [6] O. Danvy and A. Filinski. \nRepresenting control: a study of the CPS transformation. Mathematical Structures in Computer Science, \n2(4):361 391, Dec. 1992. [7] R. Davies and F. Pfenning. A modal analysis of staged com\u00adputation. Journal \nof the ACM, 48(3):555 604, May 2001. [8] J. Despeyroux and P. Leleu. Recursion over objects of func\u00adtional \ntype. Mathematical Structures in Computer Science, 11:555 572, 2001. [9] L. Fegaras and T. Sheard. Revisiting \ncatamorphisms over datatypes with embedded functions (or, programs from outer space). In Twenty-Third \nACMSIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 284 294, St. Petersburg Beach, \nFL,USA, 1996. [10] J.-Y. Girard. Une extension de l interpr\u00b4etation de G\u00a8odel a`l analyse, et son application \n`al \u00b4elimination de coupures dans l analyse et la th\u00b4eorie des types. In J. E. Fenstad, editor, Pro\u00adceedings \nof the Second Scandinavian Logic Symposium, pages 63 92. North-Holland Publishing Co., 1971. [11] R. \nHinze. Polytypic values possess polykinded types. Science of Computer Programming, 43(2 3):129 159, 2002. \nMPC Special Issue. [12] P. Johann. A generalization of short-cut fution and its cor\u00adrectness proof. Higher-Order \nand Symbolic Computation, 15:273 300, 2002. [13] M. P. Jones. A system of constructor classes: overloading \nand implicit higher-order polymorphism. Journal of Functional Programming, 5(1), Jan. 1995. [14] M. P. \nJones. Type classes with functional dependencies. In Proceedings of the 9th European Symposium on Program\u00adming, \nESOP 2000, Berlin, Germany, number 1782 in LNCS. Springer-Verlag, 2000. [15] E. Meijer, M. M. Fokkinga, \nand R. Paterson. Functional pro\u00adgramming with bananas, lenses, envelopes and barbed wire. In FPCA91: \nConference on Functional Programming Lan\u00adguages and Computer Architecture, pages 124 144, 1991. [16] \nE. Meijer and G. Hutton. Bananas in space: Extending fold and unfold to exponential types. In FPCA95: \nConference on Functional Programming Languages and Computer Architec\u00adture, pages 324 333, La Jolla, CA, \nJune 1995. [17] D. Miller. An extension to ML to handle bound variables in data structures: Preliminary \nreport. In Proceedings of the Logical Frameworks BRA Workshop, May 1990. [18] A. Nanevski. Meta-programming \nwith names and neces\u00adsity. In Proceedings of the seventh ACM SIGPLAN inter\u00adnational conference on Functional \nprogramming, pages 206 217. ACM Press, 2002. [19] S. Peyton Jones, editor. Haskell 98 Language and Libraries: \nThe Revised Report. Cambridge University Press, 2003. [20] F. Pfenning and R. Davies. A judgmental reconstruction \nof modal logic. Mathematical Structures in Computer Science, 11(4):511 540, Aug. 2001. [21] F. Pfenning \nand C. Elliott. Higher-order abstract syntax. In 1988 ACM SIGPLAN Conference on Programming Language \nDesign and Implementation, pages 199 208, Atlanta, GA, USA, June 1988. [22] F. Pfenning and C. Sch\u00a8urmann. \nSystem description: Twelf a meta-logical framework for deductive systems. In H. Ganzinger, editor, Proceedings \nof the 16th International Conference on Automated Deduction (CADE-16), pages 202 206, Trento, Italy, \nJuly 1999. [23] A. M. Pitts and M. Gabbay. A metalanguage for program\u00adming with bound names modulo renaming. \nIn Mathematics of Program Construction, pages 230 255, 2000. [24] C. Sch\u00a8urmann, J. Despeyroux, and F. \nPfenning. Primitive re\u00adcursion for higher-order abstract syntax. Theoretical Com\u00adputer Science, 266(1 \n2):1 58, Sept. 2001. [25] C. Sch\u00a8urmann, R. Fontana, and Y. Liao. Delphin: Functional programming with \ndeductive systems. Available at http:// cs-www.cs.yale.edu/homes/carsten/, 2002. [26] E. Sumii and N. \nKobayashi. A hybrid approach to online and of.ine partial evaluation. Higher-Order and Symbolic Com\u00adputation, \n14(2/3):101 142, 2001. [27] V. Trifonov, B. Saha, and Z. Shao. Fully re.exive intensional type analysis. \nIn Fifth ACM SIGPLAN International Con\u00adference on Functional Programming, pages 82 93, Montreal, Sept. \n2000. [28] P. Wadler. Theorems for free! In FPCA89: Conference on Functional Programming Languages and \nComputer Architec\u00adture, London, Sept. 1989. [29] G. Washburn. Modal typing for specifying run-time code \ngeneration. Available from http://www.cis.upenn.edu/ ~geoffw/research/, 2001. [30] S. Weirich. Higher-order \nintensional type analysis in type-erasure semantics. Available from http://www.cis. upenn.edu/~sweirich/, \n2003. [31] H. Xi, C. Chen, and G. Chen. Guarded recursive datatype con\u00adstructors. In Thirtieth ACMSIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, pages 224 235, New Orleans, LA, USA, Jan. 2003. A \nGeneric Haskell implementation of xmap type XMap {[*]} t1 t2 = (t1 -> t2, t2 -> t1) type XMap {[k -> \nl]} t1 t2 = forall u1 u2. XMap {[k]} u1 u2 -> XMap {[l]}(t1 u1)(t2 u2) xmap {| t:: k|} :: XMap {[k]} \nt t xmap {| Unit |} = (id,id) xmap {| :+: |} (xmapA1,xmapA2) (xmapB1,xmapB2) = (\\x -> case x of (Inl \na) -> Inl (xmapA1 a) (Inr b) -> Inr (xmapB1 b), \\x -> case xof (Inl a) -> Inl (xmapA2 a) (Inr b) -> Inr \n(xmapB2 b)) xmap {| :*: |} (xmapA1,xmapA2) (xmapB1,xmapB2) = (\\(a :*: b) -> (xmapA1 a) :*: (xmapB1 b), \n\\(a :*: b) -> (xmapA2 a) :*: (xmapB2 b)) xmap {| (->) |} (xmapA1,xmapA2) (xmapB1,xmapB2) = (\\f -> xmapB1 \n. f . xmapA2, \\f -> xmapB2 . f . xmapA1) xmap {| Int |} = (id, id) xmap {| Bool |} = (id, id) xmap {| \nIO |} (xmapA1,xmapA2) = (fmap xmapA1, fmap xmapA2) xmap {| [] |} (xmapA1,xmapA2) = (map xmapA1, map xmapA2) \n B Full encoding of SDP B.1 Parameterization t(B1) \" t1 t(B2) \" t2 t(b) \" tt(1) \" 1 t(B1 . B2) \" t1 . \nt2 t(B1) \" t1 t(B2) \" t2 t(B1 \u00d7 B2) \" t1 \u00d7 t2 B.2 Signatures .ci . dom(S) S(ci)= Bi . b t(S) \" (L(c1) \n: t(B1),...,L(cn) : t(Bn))  B.3 Types . f ta . .. {a : . . .}f A at t' . f b t Rec S* t. f DA t .a:. \n. ..t' . f A1 tt1 . f A2 tt2 . f 1 t 1(t) . f A1 . A2 tt1 . t2 . f A1 tt1 . f A2 tt2 . f A1 \u00d7 A2 tt1 \n\u00d7 t2 B.4 Terms x . . x . . .;. f x t x .;. f x t x[.a : ..t] a . .. {a : . . .};. f M at e .;. f boxM \nt .a:. . ..e .;. f() t ()[t] S(c)= B . b . f B ttB .;. f c t.x : tB.roll[t](injL(c) x of(Rec S* t)(S)) \n .;. f M t e . f A1 tt1 .;. f .x : A1.M t.x : t1.e .;. f M1 t e1 .;. f M2 t e2 .;. f M1M2 t e1e2 . \nf DA1 tt1 .;. f M1 t e1 .;. {x}f M2 t e2 .;. f let box x : A1 = M1 inM2 t (.x : .a.t1.e2)e1 .;. f M1 \nt e1 .;. f M2 t e2 .;. f M t e .;. f(M1,M2) t (e1,e2) .;. f fstM t fste .;. f M t e .;. f sndM t snde \ntA . f A ttA .;. f Tt eT.;. f M t eM .;. f iter [DB,A][T] M t iter{|B*|}[t][tA] eT eM B.5 Replacements \n.ci . dom(T) .;. f T(ci) t ei .;. f TtA.x : S*tA.case x ofinjL(c1) y1 in(e1y1) t ... injL(cn) yn in(enyn) \n  \n\t\t\t", "proc_id": "944705", "abstract": "Higher-order abstract syntax is a simple technique for implementing languages with functional programming. Object variables and binders are implemented by variables and binders in the host language. By using this technique, one can avoid implementing common and tricky routines dealing with variables, such as capture-avoiding substitution. However, despite the advantages this technique provides, it is not commonly used because it is difficult to write sound elimination forms (such as folds or catamorphisms) for higher-order abstract syntax. To fold over such a datatype, one must either simultaneously define an inverse operation (which may not exist) or show that all functions embedded in the datatype are parametri.In this paper, we show how first-class polymorphism can be used to guarantee the parametricity of functions embedded in higher-order abstract syntax. With this restriction, we implement a library of iteration operators over data-structures containing functionals. From this implementation, we derive \"fusion laws\" that functional programmers may use to reason about the iteration operator. Finally, we show how this use of parametric polymorphism corresponds to the Sch&#252;rmann, Despeyroux and Pfenning method of enforcing parametricity through modal types. We do so by using this library to give a sound and complete encoding of their calculus into System F<inf>?</inf>. This encoding can serve as a starting point for reasoning about higher-order structures in polymorphic languages.", "authors": [{"name": "Geoffrey Washburn", "author_profile_id": "81100451282", "affiliation": "University of Pennsylvania", "person_id": "P639763", "email_address": "", "orcid_id": ""}, {"name": "Stephanie Weirich", "author_profile_id": "81100093135", "affiliation": "University of Pennsylvania", "person_id": "P267927", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/944705.944728", "year": "2003", "article_id": "944728", "conference": "ICFP", "title": "Boxes go bananas: encoding higher-order abstract syntax with parametric polymorphism", "url": "http://dl.acm.org/citation.cfm?id=944728"}