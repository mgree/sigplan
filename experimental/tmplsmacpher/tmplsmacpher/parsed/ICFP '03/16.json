{"article_publication_date": "08-25-2003", "fulltext": "\n A Sound and Complete Axiomatization of Delimited Continuations Yukiyoshi Kameyama Masahito Hasegawa \nInstitute of Information Sciences and Electronics Research Institute for Mathematical Sciences University \nof Tsukuba Kyoto University Tsukuba, Japan Kyoto, Japan and Japan Science and Technology Corporation \nand Japan Science and Technology Corporation  kam@is.tsukuba.ac.jp hassei@kurims.kyoto-u.ac.jp ABSTRACT \nThe shift and reset operators, proposed by Danvy and Fil\u00adinski, are powerful control primitives for capturing \ndelimited continuations. Delimited continuation is a similar concept as the standard (unlimited) continuation, \nbut it represents part of the rest of the computation, rather than the whole rest of computation. In \nthe literature, the semantics of shift and reset has been given by a CPS-translation only. This paper \ngives a direct axiomatization of calculus with shift and reset, namely, we introduce a set of equations, \nand prove that it is sound and complete with respect to the CPS-translation. We also introduce a calculus \nwith control operators which is as expressive as the calculus with shift and reset, has a sound and complete \naxiomatization, and is conservative over Sabry and Felleisen s theory for .rst-class continuations. Categories \nand Subject Descriptors D.3.1 [Programming Languages]: Formal De.nitions and Theory; F.3.2 [Logics and \nMeanings of Programs]: Se\u00admantics of Programming Languages General Terms Languages,Theory,Veri.cation \n Keywords Continuation, CPS-translation, Axiomatization 1. INTRODUCTION First-class continuations are \npowerful control facility in functional programming languages such as Scheme (call/cc) and SML/NJ (callcc \nand throw). It captures the whole rest of computation so that we can represent loops, backtrack\u00ading, \ncoroutines, and other control structures [29]. However, one sometimes wants to capture some part of the \nrest of Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP \n03, August 25 29, 2003, Uppsala, Sweden. Copyright 2003 ACM 1-58113-756-7/03/0008 ...$5.00. computation, \nand compose the captured continuation with ordinary functions. In the literature, such a kind of con\u00adtinuations \nis called partial continuations, delimited contin\u00aduations, functional continuations, or composable continua\u00adtions, \nand we use the term delimited continuations in this paper. Recent years have found that delimited continua\u00adtions \nare useful in writing programs with explicit control in such areas as partial evaluation, CPS-translation, \nand even mobile computation [32, 30, 27, 2]. There are many proposals for representing .rst-class de\u00adlimited \ncontinuations [9, 6, 23, 17, 14]. Among them, Danvy and Filinski s shift and reset operators [6, 7] are \nmost widely used and e.cient implementations for them have been pro\u00adposed [11, 13]. An important merit \nof their operators is that a clean and rigorous semantics is given through a CPS\u00adtranslation. Moreover, \nFilinski [11] proved that any express\u00adible1 monadic e.ects are representable by the shift and reset operators, \nwhich demonstrates the expressive power of these operators. We address the problem of reasoning about \nprograms with .rst-class delimited continuations, in particular the shift and reset operators. Although \nthere is a rigorous CPS-based se\u00admantics for shift and reset, the CPS-translation generates larger and \nrestructured codes, with which it is often very hard to recognize the high-level aspects of the original \npro\u00adgram (though the size of the generated codes is not really a matter, if we use compacting CPS-translations \n[25, 8]). Thus we look for a direct axiomatization which is closer to the programmer s intuition and \nyet as powerful as the CPS\u00adbased reasoning. In this paper, we give such an axiomatization for shift and \nreset, and prove the soundness and completeness of our axiomatization with respect to the semantics given \nby CPS\u00adtranslation. Based on our axiomatization, one can directly reason about properties of programs \nwhich involve shift and reset, without converting the program to CPS-terms. Our method is an extension \nof the technique developed by Sabry and Felleisen [25], who gave a sound and complete ax\u00adiomatization \nof call-by-value type-free lambda calculus with .rst-class continuations. There are mainly two obstacles \nwhen we apply their technique to shift and reset. The .rst one is that, the target calculus of the CPS\u00adtranslation \nin the case of shift and reset is not the usual 1He de.nes that a monad is expressible if its de.ning \nfunc\u00adtions . and * are de.ned in purely functional object lan\u00adguage. CPS-forms, by which we mean there \nare non-value terms in an argument position in functional application. This means that we cannot use \nthe full \u00df.-equality in the target cal\u00adculus, which is extensively used in their proof. To avoid this \nproblem we use Danvy and Filinski s CPS-hierarchy, which can be considered as doubling CPS-translation, \nthat is, to CPS-translate source terms twice (though this is only conceptual. In this paper we use a \ncurried version of CPS\u00adhierarchy, which does not exactly agree with the composition of two CPS-translations.) \nThe second problem is the complexity of this doubling CPS-translation. In the target calculus of CPS-translation, \nwe must treat not only an ordinary continuation variable, but also a metacontinuation variable which \nis introduced by the second CPS-translation, and the term structure of the target calculus is more complex \nthan Sabry-Felleisen s. Also, we have two operators shift and reset, rather than a single primitive callcc, \nwhich also complicates the proof. Nevertheless, by making clear distinction between pure eval\u00aduation \ncontexts and ordinary evaluation contexts, and care\u00adfully treating the reset primitive, we are able to \nextend Sabry and Felleisen s technique to the shift and reset case, and .nd a sound and complete axiomatization. \nIndependently to Sabry and Felleisen, Hofmann [18] also proposed a sound and complete axiomatization \nfor a call\u00adby-value lambda calculus with .rst-class continuations. He constructed a term model using \na category-theoretic machin\u00adery to prove the result, which is more structured than Sabry and Felleisen \ns. However, he treated a typed version, and it is not certain that his proof technique can be applied \nto the type-free case. Recently F\u00a8uhrmann and Thielecke presented a re.ned proof and axiomatization in \na typed setting [12]. Sabry [24] proposed an elegant technique to obtain a sound and complete axiomatization \nwith respect to a CPS-semantics. He applied it to a calculus with shift and lazy reset, which di.ers \nfrom (ordinary) reset in that a reset term is always a value. As a by-product of his proof, he showed \nsome ax\u00adioms by Sabry and Felleisen [25] are redundant. In order to apply Sabry s technique to the calculus \nfor shift and reset, we must carefully reformulate the target calculus since the target calculus in our \ncase does not have the full \u00df.-equality while we need the \u00df.-equality for continuations (and meta\u00adcontinuations). \nYet, we must note that the resulting axioms in this work are very close to Sabry s, and in fact, his \naxioms can be obtained by adding one axiom to ours. We shall use this fact to obtain conservativity of \nour axioms over Sabry\u00adFelleisen s axiomatization. The rest of this paper is organized as follows. We \nintro\u00adduce the shift and reset operators and their CPS-translation in Section 2. Our axiomatization with \nthe soundness theo\u00adrem is given in Section 3. Section 4 analyzes the target cal\u00adculus and gives an inverse \ntranslation from the target to the source. Section 5 and Section 6 give a proof of the complete\u00adness \nof our axioms. Section 7 examines the axioms given in this paper, speci.cally, gives conservativity and \nsome inde\u00adpendence results. Section 8 gives concluding remarks. 2. SHIFT AND RESET 2.1 Source Language \nIn this section we introduce the shift and reset operators due to Danvy and Filinski [6, 7] in a type-free, \ncall-by-value setting. The grammar of the calculus .Sis given by: (terms) M, N ::= V |MN |(M. (values) \nV ::= x |.x.M |S where x is a variable, MN and .x.M are application and .-abstraction. The shift operator \nresembles the standard .rst-class con\u00adtinuation operator callcc, but it captures part of the rest of \nthe computation, and the part is speci.ed by the (dynami\u00adcally determined) closest reset operator. In \nthe calculus .S, the angle brackets in the term (M)represent the reset op\u00aderator, namely, they delimit \nthe e.ect of the shift operators in M. We give the shift operator as a constant, rather than the original \nform .c.M, which can be de.ned by S(.c.M) in our formulation. Free and bound occurrences of variables \nare de.ned as usual. FV (M) denotes the set of free variables in M. The usual capture-avoiding substitution \nis denoted by M{x := N}. We introduce three kinds of contexts. (contexts) C ::= [] |.x.C |CM |MC |(C. \n(e-contexts) E ::= [] |EM |VE |(E. (p-contexts) F ::= [] |FM |VF where C stands for contexts, E for evaluation \ncontexts (e\u00adcontexts, for short), and F for pure evaluation contexts (p\u00adcontexts, for short). Contexts \nand evaluation contexts are standard [10]. We distinguish from other contexts a pure evaluation context, \nwhich is an evaluation context that does not have any enclosing reset operators around the hole. We use \nthe metavariables E and F (with su.xes) for e-contexts and p-contexts, resp. For a context C and a term \nM,we write C[M] for the usual (variable-capturing) hole-.lling op\u00aderation. For instance, if C = .x.[ \n] and M = xy, then C[M] =.x.xy,thus x is captured by C. If a variable x becomes a bound variable in C[x], \nwe say itis captured by C. An intuitive operational semantics of the shift and reset operators can be \ngiven as follows. Let E, F and V be an e\u00adcontext, a p-context and a value, resp. We have the following \nequalities (or reductions if we read from left to right): E[(F [SV ])]= E[(V (.x.(F [x])))] E[(V )]= \nE[V ] In the .rst line, the shift operator S encapsulates part of the rest of the computation as a function \n.x.(F [x]). The context being captured is speci.ed by the closest reset op\u00aderator, since F is a p-context, \nand there are no other reset s enclosing the hole. The captured computation is almost .x.F [x], but it \ncontains an additional reset operator, which correctly delimits the (possible) e.ects in F; this also \nal\u00adlows a simple CPS-translation, as explained by Danvy and Filinski [6]. Note that, the current delimited \ncontinuation F is discarded, so the shift operator also behaves like an abort. In the second line, the \nreset operator is discarded if its content is already a value. In this paper we also consider other control \noperators D and A, whose intuitive semantics is given as follows: E[(F [DV ])]= E[(F [V (.x.A(F [x]))])] \nE[(F [AV ])]= E[V ] Since the shift operator does two things (capturing a de\u00adlimited continuation and \naborting), we want to split its roles into two operators to help our technical development. The abortive \nbehavior of shift is inherited by the A-operator, and the role of capturing a delimited continuation \nis inher\u00adited by the D-operator. By replacing the shift operator by the D-and A-operators we obtain the \ncalculus .DA. Note that S and D, A are inter-de.nable by each other. That is, .S can de.ne .DA, and vice \nversa. D = .z.S(.k.k(z(.x.A(kx)))) A = .z.S(.d.z) S = .z.D(.k.A(z(.x.(kx)))) Formally, these equations \nare justi.ed by the CPS-translation given later. The decomposition of the shift operator to the D-and \nA\u00adoperators are not new to this work, and we refer to Murthy [21] and Filinski [11] for interested readers. \nIn this paper, we shall .rst axiomatize the calculus .DA, then the calculus .S. 2.2 CPS-translation \nA CPS-translation is a syntactic translation from source terms to target terms. In our case, the source \ncalculus is .S and .DA, and the target language is the pure type-free lambda calculus without control \noperators. As explained in the introduction, we shall use Danvy and Filinski s CPS-hierarchy (metacontinuation \nsemantics). The reason is as follows: the image of the ordinary CPS-translation of a shift-term contains \na term like k'(kx), whose evaluation is sensitive to the evaluation order. Since we want to eval\u00aduate \nit in call-by-value, the full \u00df-reduction cannot be used in the target language. On the other hand, if \nwe adopt the CPS-hierarchy (twice or more CPS-translations), target terms do not contain such forms, \nand we can safely use the full \u00df.-equality in the target calculus. Before giving the CPS-translation \nwe introduce a combi\u00adnator J in the target calculus de.ned by J = .x...x.It is the image of the empty \ncontext (the identity continuation). The CPS-translations of .S and .DA in Plotkin style are given as \nfollows, where the introduced bound variables k, k', x, v, w, m, n, and . are assumed to be fresh. [[] \n: Term . Target Term [[V ]] = .k.kV * [[MN]] = .k.[[M]](.m.[[N]](.n.mnk)) [[(M)]] = .k..[[M]]J(.v.kv.) \n( ) * : Value . Target Term * x = x (.x.M) * = .x.[[M]] S * = .xk.x(.vk'..kv(.w.k'w.))J D * ' = .xk.x(.vk.kv)k \nA * = .xk...x Note that the result of translating the term (M) needs two arguments k and .. The .rst \none is the ordinary con\u00adtinuation parameter, while the second one is the metacon\u00adtinuation parameter. \nAn important observation on the CPS-translation above is that, while the continuation variable k can \nbe used many times (by the D-operator), the metacontinuation variable . is always used once, thus linear. \nIntuitively, it can be explained like this: the CPS-translation is essentially the composition of two \nsuccessive (ordinary) CPS-translations, and the source language of the second CPS-translation is the \nordinary call-by-value lambda calculus without control operators. Therefore, as shown in the literature \n[5, 4, 15], continuations are used linearly and the target calculus of the second CPS-translation can \nbe considered as linear lambda calculus. Continuations in the second CPS-translation are metacontinuations \nin our setting, thus . is linear in the tar\u00adget calculus. The second author exploits this linearity in \nhis semantic analysis of delimited continuations [16]. Although we present the CPS-translation in a type-free \nsetting, we may consider its target calculus as typed calculus with recursive types, and the mentioned \nlinearity is made explicit in the type system. We will brie.y mention in the conclusion how it is done. \nThe CPS-translation above de.nes a rigorous semantics of shift and reset. The reset operator installs \nthe identity continuation J as the current continuation. The D-operator captures the current continuation \nk (up to the most recently called reset operator), and applies .vk'.kv to the argument. The A-operator \ndiscards the current continuation k, and directly applies the argument x to the metacontinuation .. \n 3. AXIOMS For the purpose of presentation, we give the axioms in this section, and postpone the proof \nof the completeness to later sections. The actual development was in the opposite order; these axioms \nhave been obtained during the proof of completeness. 3.1 Axioms and their Soundness The set of axioms \nfor .DA is given in Figure 1, and that for .S is given Figure 2. For the sake of comparison, we list \nSabry and Felleisen s axiomatization for .rst-class continuations [25] in Figure 3. (we slightly changed \nthe names of the axioms from the orig\u00adinal.) Some explanations of our axioms will follow. The axioms \n\u00dfv, .v and \u00df. are axioms for pure lambda terms, and are essentially the same as those for Moggi s computational \nlambda calculus [20], which is considered as the canonical calculus in call-by-value. Sabry and Felleisen \ns axiomatizations contains the axiom \u00df-lift, but it is known to be derivable2 . The axioms D-elim, D-current, \nD-abort, and D-lift are ax\u00adioms for the D-operator. It is easy to see that these axioms in our axiomatization \n(Figure 1) are essentially equivalent to Sabry and Felleisen s axiomatization (Figure 3) for un\u00adlimited \ncontinuations if we identify D with callcc. The only di.erence is that the latter contains an extra axiom \n(callcc\u00adtail), but it is derivable as is shown below. The remaining axioms are the key to the axiomatization \n2Sabry [24] attributes this observation to Filinski. (.x.M)V = M{x := V } .x. Vx = V (.x.F [x])M = F \n[M] (V ) = V ((.x.M)(N)) =(.x.(M))(N) D(.k.M)= M D(.k.kM)= D(.k.M) D(.k.C[F [kM]]) = D(.k.C[kM]) F \n[DM]= D(.k.F [M(.f.kF [f])]) F [AM]= AM (AM) = (M)A(M) = AM \u00dfv .v,if x .. FV (V ) \u00df.,if x .. FV (F ) \nreset-value reset-lift D-elim, if k .. FV (M) D-current D-abort, if k is not captured by C D-lift, if \nk ..FV (F [DM]) and f ..FV (kF ) A-lift A-top A-reset Figure 1: Axioms for .DA Axioms \u00dfv, .v, \u00df., reset-value, \nand reset-lift with the following axioms. S(.k.kM)= M S-elim, if k ..FV (M) (F [SM]) = (M(.x.(F [x]))) \nreset-S,if x ..FV (F ) S(.k.(M))= S(.k.M) S-reset Figure 2: Axioms for .S of delimited continuations. \nThe axioms A-lift, A-top, A\u00adreset, and reset-value are already present in Sabry s work [24], but the \nnotion of values in his calculus is di.erent from that in our calculus in that he treated lazy prompt \n(reset) and (M) is always a value. The axiom reset-lift seems new to this work. It states a non-trivial \nequality on the nested and sequential uses of the reset operator, and is also the key case of the equation \n\u00df.-reset-2 in Lemma 1 below. For .S, we replace the seven axioms for D and A by three axioms for S, which \nclosely resemble those for Felleisen s C\u00adoperator [10] except that we need some extra care for the interaction \nwith the reset operator, and that the continua\u00adtion captured by S is composable (not abortive). Let T \nbe one of the theories .DA, .S, and .\u00df., where .\u00df. is the pure lambda calculus with the full \u00df.-equality. \nWe write T. M = N if M = N is derived from the axioms in T . We also write M = N for the syntactic equality \n(including a-equivalence). Theorem 1 (Soundness). Let T be .DA or .S, and M and N be terms in T . Then \nT. M = N implies .\u00df. . [[M]] = [ N]]. This theorem is proved by directly computing both sides of each \naxiom, and the proof is omitted.  3.2 Derivable Equations The next two lemmas give several useful equations \nin .DA and .S. The proofs of these lemmas can be found in the appendix. Lemma 1. The followingequations \nare derivablein .DA, in which we assume x ..FV (F ) . FV (E) .{k} and k ..FV (M2). F [(.x.N)M]=(.x.F \n[N])M\u00df-lift ((M)) = (M) reset-reset (DM) = (MA) D-top (.x.D(.k.M1))M2 = D(.k.(.x.M1)M2) D-tail ((.x.(F \n[x]))M) = (F [M]) \u00df.-reset-1 (.x.E[x])(M) = E[(M)] \u00df.-reset-2 The axiom \u00df.-reset-2 is similar to \u00df., \nbut the former allows an arbitrary e-context E in the body of the \u00df-redex, rather than a p-context F \n(which must not have reset-operators enclosing the hole). Note that a more general equation (.x.E[x])M \n= E[M] is not sound with respect to the CPS\u00adtranslation. Lemma 2. The following equations are derivable \nin .S, in which we assume x ..FV (kF ) and k ..FV (F ).FV (M). F [SM]= S(.k.M(.x.(kF [x])))S-nat S(.k.Mk)= \nSM S. (.x.S(.k.N))M = S(.k.(.x.N)M) S-tail Note that the equation S-nat has a similar form to D-lift, \nhowever, it can be derived in .S.  4. TARGET CALCULUS AND INVERSE TRANSLATION The goal of the rest of \nthis paper is to prove the complete\u00adness of the axioms for .DA and .S. There are three ways to prove \nthe completeness of this kind. The .rst approach is due to Sabry and Felleisen [25], who carefully analyze \nthe Axioms \u00dfv, .v , \u00df., and A-lift with the following axioms. F [(.x.N)M]=(.x.F [N])M\u00df-lift callcc(.k.M)= \nM callcc-elim, if k ..FV (M) callcc(.k.kM)= callcc(.k.M) callcc-current callcc(.k.C[F [kM]]) = callcc(.k.C[kM]) \ncallcc-abort, if k is not captured by C F [callccM]= callcc(.k.F [M(.f.kF [f])]) callcc-lift, if k .. \nFV (F [M]) and f .. FV (kF ) (.x.callcc(.k.M1))M2 = callcc(.k.(.x.M1)M2) callcc-tail Figure 3: Sabry \nand Felleisen s Axioms for callcc target of the CPS-translation, then de.ne an inverse of the CPS-translation, \nand prove the equality in the target (the \u00df.-equality) is preserved by the inverse translation. The other \ntwo approaches are Hofmann s work [18] and Sabry s work [24], both of which are cleaner than Sabry-Felleisen \ns proof. However, it is not certain whether we can apply these techniques to the calculus with shift \nand reset. Hofmann s work is for the typed-setting. It seems possible to apply Sabry s work to our case, \nbut it needs reformulation of the target calculus. In order to axiomatize the very calculus Danvy and \nFilinski proposed, we will adopt Sabry-Felleisen s approach in this paper. In this and the next sections, \nwe take .DA as the source calculus; the completeness for .S is derived in Section 6 as a corollary to \nthe case of .DA. 4.1 The Target Calculus We .rst analyze the structure of the target terms of the CPS-translation \nwhich is necessary to de.ne an inverse of the CPS-translation. Assume that the ordinary variables are \nx1, \u00b7\u00b7\u00b7 xn, the con\u00adtinuation variables are k1, \u00b7\u00b7\u00b7 ,km, and the metacontinua\u00adtion variable is .. By \nthe linearity condition of the meta\u00adcontinuation variable, we need only one metacontinuation variable. \nThe following grammar de.nes the target calculus. (terms) T (pre-values) Q (answers) R (values) W (continuations) \nK (metacontinuations) G ::= .k.Q | WW ::= ...R | TK | KW ::= QG | GW ::= x1 | \u00b7\u00b7\u00b7 | xn | .x.T ::= k1 \n|\u00b7\u00b7\u00b7 | km | .x.Q ::= . | .x.R A term in the target calculus is called a T -term if it be\u00adlongs to the \nclass T de.ned above. Similarly, a Q-, R-, W -, K-, and G-term are de.ned. Since there is only one metacontinuation \nvariable ., the term ...R does not have free metacontinuation variables. By further extending this reasoning, \nwe have that T -, Q-, W \u00adand K-terms do not contain free metacontinuation variables, and R-and G-terms \ncontain a single free occurrence of the metacontinuation variable .. Theorem 2. (i) Let M and V be a \nterm and a value in .DA, resp. Then [[M]] is a T -term and V * is a W -term in the target calculus. (ii) \nThe target calculus is closed under the full\u00df.-reductions. Proof. (i) We have that D * and A * are W \n-terms, and J is a K-term. Other cases are proved by straightforward induction. (ii) This is easily proved \nby case-analysis. We must be careful to check that the linearity condition on the meta\u00adcontinuation variable \n. is preserved through the reduction, but it is proved by straightforward induction. Even though the \nabove grammar is closed under the re\u00adductions in the target calculus, there are T -terms which are not \nan image of any source term. However, in the next subsection, we see that an inverse function from all \nthe T -terms to the source terms can be de.ned. 4.2 Inverse Translation The inverse of the CPS-translation \nis a total function from the set of target terms (not necessarily in the image of CPS-translation, but \narbitrary terms de.ned by the above grammar) to the set of terms in .DA. Depending on the six classes \nin the target calculus, the inverse translation con\u00adsists of the six functions, T -1( ), Q-1( ), R-1( \n), W-1( ), K-1 ( ), and G-1( ) de.ned below.    T -1 (.k.Q)= T -1 (W1W2)= Q-1(...R)= Q-1(TK)= Q-1(KW \n)= R-1 (QG)= R-1 (GW )= W-1 (x)= W-1 (.x.T )= K-1 (k)= K-1 (.x.Q)= G-1 (.)= D(.k.A(Q-1(Q))) W-1(W1)W-1(W2) \nD(...R-1(R)) K-1 (K)[T -1(T )] K-1 (K)[W-1(W )] G-1 (G)[(Q-1(Q))] G-1 (G)[W-1(W )] x .x.T -1(T ) k[] \n(.x.(Q-1(Q)))[ ] .[] G-1 (.x.R)=(.x.R-1(R))[ ] The inverse translation is similar in spirit to Sabry \nand Felleisen s inverse translation [25]. For instance, we explic\u00aditly capture continuations in the cases \nof T -1(.k.Q) and Q-1(...R). Yet, there are di.erences in treating values and continuations, and these \nare subtle points. For instance, a reset (delimiter) is inserted to the result of K-1(.x.Q), which is \nessential for our completeness proof. As an example of the inverse translation, let us consider the term \n.k.fx(.v.k(.ak.ka)) in the target calculus. This term is obtained by \u00df-reducing [ (.ya.a)(fx)]]. We can \ncom\u00adpute its inverse as follows: T -1 (.k.fx(.v.k(.ak ' .k ' a))) =D(.k.A(Q-1(fx(.v.k(.ak ' .k ' a))))) \n=D(.k.A(K-1(.v.k(.ak ' .k ' a))[T -1(fx)])) By a similar calculation, we have K-1'' '' (.v.k(.ak .k a)) \n= (.v.(k(.a.D(.k .A(ka)))))[ ], T -1 (fx) = fx thus, the result of the inversion is D(.k.A((.v.(k(.a.D(.k \n' .A(k ' a)))))(fx))). We can show the resulting term is equal to (.va.a)(fx) un\u00adder the theory .DA. \nGoing back to the de.nition of the inverse translation, let us observe that its images have the following \nspecial form: T -1 1. (T ) is a term, W-1(W ) is a value, and K-1(K) and G-1(G) are p-contexts in .DA. \n 2. Whenever Q-1(Q) appears as subterms of other terms, it is either of the form (Q-1(Q)) or the form \nA(Q-1(Q)). Namely, Q-1(Q) always appears in a delimited context, or an abortive context. The same thing \nholds for K-1(K). 3. Whenever G-1(G)[M] appears as a subterm of other terms, M is either of the form \nW-1(W ) or the form (N).  These observations will be used in the completeness proof. In the following, \nwe simply write ( )-1 for the six inverse translations to avoid clutter. We can prove that the inverse \ntranslation is in fact the (left) inverse of the CPS-translation up to the axioms in Figure 1. Theorem \n3. Let M be a term and V be a value in .DA. Then we have: .DA . ([[M]])-1 = M * )-1 = V.DA . (V Proof. \nWe prove the theorem by simultaneous induction on M and V . (Case M is a value V1) -1 *-1 ([[V1]])=D(.k.A(k(V1 \n))) = D(.k.A(kV1)) (by I.H.) = D(.k.kV1) (by D-abort) = V1 (by D-current, D-elim) (Case M = N1N2) ([[N1N2]])-1 \n=D(.k.A((.m.((.n.(k(mn)))([[N2]])-1))([[N1]])-1)) = D(.k.A((.m.((.n.(k(mn)))N2))N1)) (by I.H.) = D(.k.A((k(N1N2)))) \n(by \u00df.-reset-1 twice) = D(.k.A(k(N1N2))) (by A-reset) = D(.k.k(N1N2)) (by D-abort) = N1N2 (by D-current,D-elim) \n(Case M =(N)) ([[(N)]])-1 =D(.k.A(D...(.v..(kv))(([[N]]J)-1))) = D(.k.A(D....(k(([[N]]J)-1)))) (by \u00df.-reset-2) \n= D(.k.A(k(([[N]]J)-1))) (by D-current, D-elim) = D(.k.k(([[N]]J)-1)) (by A-reset,D-abort) = (([[N]]J)-1) \n(by D-current,D-elim) =((.x.(D(....x)))[[N]]-1) = ((.x.x)[[N]]-1) (by D-current,D-elim,reset-value) = \n([[N]]-1) (by \u00df.) = (N) (by I.H.) (Case V = x or V = .x.M1) Easily shown. (Case V =D) (D * )-1 = .x.D(.k.A(k(x(.v.D(.k \n' .A(kv)))))) = .x.D(.k.A(k(x(.v.kv)))) (by D-abort,D-elim) = .x.D(.k.k(xk)) (by .v ,D-abort) = .x.D(.k.xk) \n(by D-current) = D (by .v twice) (Case V =A) (A * )-1 = .x.D(.k.A(D(....x))) = .x.Ax (by D-current,D-elim \ntwice) = A (by .v )  5. REDUCTIONS IN THE TARGET CAL-CULUS The CPS-and the inverse-translations give \na syntactic correspondence between the source and the target calculi. In this section, we establish the \ncorrespondence in the equality\u00adlevel. Namely, we show the equality in the target calculus (the full \u00df.-equality) \nis preserved through the inverse trans\u00adlation. 5.1 Substitution and Inverse Translation In this subsection, \nwe prove three lemmas which essen\u00adtially say that a substitution and the inverse-translation commute. \nWe have three such lemmas corresponding to three classes of variables (an ordinary variable, a continua\u00adtion \nvariable, and a metacontinuation variable). The .rst substitution lemma is for an ordinary variable x. \nTheorem 4. Let X be one of T -, Q-, R-, W -, K-, G\u00adterms, and W be a W -term. Then we have: -1 = X-1 \n.DA . (X{x := W }){x := W -1} The proof is straightforward. The second substitution lemma is for a continuation \nvari\u00adable k. Theorem 5. Let X be one of T -, R-, W -, G-terms, and Y be one of Q-, K-terms. Then we have: \n-1 -1-1 .DA . (X{k := K})= X{k := .f.A(K[f])} -1-1-1 .DA . ((Y {k := K})) = (Y {k := .f.A(K[f])}) -1 \n-1-1 .DA . A(Y {k := K})= A(Y {k := .f.A(K[f])}) Proof. The theorem is proved by simultaneous induction \non X and Y . We prove only the interesting cases here. The second equation for Y = k can be proved as \nfollows: LHS =(K-1) RHS =((.f.A(K-1[f]))[ ]) = (A(K-1)) (by \u00df.) = (K-1) (by reset-A) Note that, A(K-1) \nis a p-context, hence we can apply \u00df. in the above derivation. The third equation for Y = k can be proved \nsimilarly, using A-lift instead of reset-A. The third substitution lemma is for a metacontinuation variable \n.. Since . does not appear free in T -, Q-, W -, and K-terms, we need to consider R-and G-terms only. \nTheorem 6. Let R be an R-term, and G,G 2 be G-terms. Also let M be a term in the source calculus .DA. \nThen we have: -1 -1 -1 .DA . (R{. := G2})= G2 [(D(...R))] -1-1 -1 .DA . (G{. := G2})[(M)]= G2 [(D(...G[(M)]))] \nProof. The theorem is proved by simultaneous induction on R and G. (Case: R = QG) Note that Q does not \ncontain . free. LHS = (Q(G{. := G2}))-1 = (G{. := G2})-1[(Q-1)] -1 -1-1 = G[(D(...G[(Q)]))] (by I.H.) \n2 -1 -12 RHS = G[(D(...(QG)))] G-1 = [(D(...G-1[(Q-1)]))] 2 (Case: R = GW ) Note that W does not contain \n. free. LHS = ((G{. := G2})W )-1 = (G{. := G2})-1[W -1] =(G{. := G2})-1[(W -1)] (by reset-value) -1 -1-12 \n= G[(D(...G[(W )]))] (by I.H.) -1 -1-1 = G[(D(...G[W ]))] (by reset-value) 2 -1 -12 RHS = G[(D(...(GW \n)))] -1 -1-12 = G[(D(...G[W ]))] (Case: G = .) LHS = G-1[(M)] 2 RHS = G-1[(D(....(M)))] 2 = G-1[((M))] \n(by D-current,D-elim) 2 = G-1[(M)] (by reset-reset) 2 (Case: G = .x.R) We may assume x .. FV (G2). LHS \n= (.x.(R{. := G2})-1)(M) -1 -1 =(.x.G[(D(...R))])(M) (by I.H.) 2 -1 -1 =(.x.G[((.x.D(...R))x)])(M ) (by \n\u00dfv) 2 -1 -1 2 = G[((.x.D(...R))(M))] (by \u00df.-reset-2) G-1 =[(D(...(.x.R-1)(M)))] (by D-tail) 2 -1 -1 \n RHS = G2 [(D(...(.x.R)(M)))] Hence, we are done. 5.2 The \u00df.-Reductions and the Inverse Trans\u00adlation \nWe are ready to prove that the \u00df.-equality is preserved by the inverse translation. Theorem 7. Let Xi \nbe T -, R-or W -terms, Yi be Q-or K-terms, Gi be G-terms in the target calculus, for i =1, 2. Let M bea \ntermin .DA. Then we have the following: -1 -1 .\u00df. . X1 = X2implies.DA . X= X 12 -1 -1 .\u00df. . Y1 = Y2 implies.DA \n.(Y ) = (Y ), and 12 -1 -1 .DA .A Y1 = A Y2 -1 -1 .\u00df. . G1 = G2 implies.DA . G1 [(M)]= G2 [(M)] Proof. \nNote that the second equation for Yi can be de\u00adrived from the .rst one for Yi. Assuming .DA .(Y -1) = \n1 (Y -1),we have .DA .A Y -1 = A(Y -1) = A(Y -1) = 2 112 A Y2 -1, by using A-reset twice. Note also that \nit su.ces to prove the theorem when the equality in the target calculus (the \u00df.-equality) is obtained \nby one-step \u00df-or .-reduction. Then the theorem is proved by structural induction on X1, Y1, and G1. Again \nit su.ces to prove the term in consideration is the redex, since the inverse translation commutes with \nhole-.lling of contexts, C-1[M-1 namely, (C[M])-1 = ] if we appropriately de.ne C-1 for a context C. \nWe .rst consider the cases for \u00df-reduction. If the sub\u00adstituted variable is an ordinary variable (x), \nor a metacon\u00adtinuation variable (.), then we can immediately prove these cases from the .rst and the \nthird substitution lemmas. For instance, let us consider the case where Y1 = (.x.Q3)W and Y2 = Q3{x := \nW }. Then we can prove the second equation as: -1 -1 -1 (Y )=((.x.(Q))W ) 13 = ((Q3 -1{x := W -1})) (by \n\u00dfv) = (((Q3{x := W })-1)) (substitution lemma) = ((Q3{x := W })-1) (by reset-reset) The most di.cult \ncase is that we substitute a K-term for a continuation variable k, namely, the case where Y1 = (.k.Q3)K \nand Y2 = Q3{k := K}. We can calculate as: (Y -1) 1 =(K-1[D(.k.AQ-1)]) 3 = (A(K-1[D(.k.AQ-1)])) (by reset-A) \n3 '-1-1 '-1 = (D(.k .A(K[(.k.AQ3 )(.f.k (A(K[f])))]))) (by D-lift) '-1-1 '-13 = (D(.k .A(K[A(Q{k := .f.k \n(A(K[f]))})]))) (by \u00dfv) We can use D-lift in the derivation above, since A(K-1)is a p-context. We also \ncalculate a subterm in the last equation as: -1 '-1 A(Q{k := .f.k (A(K[f]))}) 3 -1 -1 3 = A(Q{k := .f.A(K[f])}) \n(by A-lift) = A((Q3{k := K})-1) (by substitution lemma) Using this equality, we can proceed the calculation \nas: '-1-1 (D(.k .A(K[A((Q3{k := K}))]))) = (A(K-1[A((Q3{k := K})-1)])) (by D-elim) = (A((Q3{k := K})-1)) \n(by A-lift) = ((Q3{k := K})-1) (by reset-A) =(Y -1) 2 In the derivation, A-lift is applicable, since \nA(K-1)is a p-context. For the cases of .-reduction, the proofs are almost straight\u00adforward. We pick up \ntwo cases here. (Case: Y1 = ...Q2. and Y2 = Q2) Let us note that . .. FV (Q2). -1 -1 (Y )= (D(....(Q))) \n12 = ((Q-1)) (by D-current,D-elim) 2 = (Q-1) (by reset-reset) 2 (Case: G1 = .x.G2x and G2) Let M be a \nterm in .DA, then we have: -1 -1 G1 [(M)] = (.x.G[x])(M) 2 = G-1[(M)] (by \u00df.-reset-2) 2  6. MAIN THEOREMS \nIn this section, we give the main theorems of this paper. 6.1 Soundness and Completeness of .DA Theorem \n8 (Soundness &#38; Completeness of .DA). Let M1 and M2 be terms in .DA. Then we have: = M2 if and only \nif .\u00df. . [[M1]]= [ M2]] .DA . M1 Proof. The soundness (the only-if direction) has already been proved. \nWe prove the completeness (the if-direction). Suppose .\u00df. . [[M1]]= [ M2] . Since [ Mi] is a T -term \n(for -1 -1 i =1, 2), we have .DA . [[M1]]=[[M2]]by Theorem 7. Since .DA . [[Mi]]-1 = Mi (for i =1, 2) \nby Theorem 3, we have .DA . M1 = M2. 6.2 Soundness and Completeness of .S So far we have been concentrating \non the analysis of the calculus with reset, D-and A-operators. Now we come back to our original motivation, \nand turn our attention to the calculus with shift and reset. Instead of directly deriving a theory for \nthem as we did for .DA, our strategy here is to relate these two calculi and prove the theory for shift \nand reset can prove the same set of equations as that for .DA. To relate .DA and .S, we de.ne a syntactic \ntranslation ( ). from .DA terms to .S terms, which replaces the con\u00adstants D and A by their de.nitions \nwith S. It merely re\u00adplaces these constants, and preserves other constructs. For the opposite direction, \nthe translation ( ) replaces S by its de.nition with D and A. We list the interesting cases below: ( \n). : .DA . .S D. = .z.S(.k.k(z(.x.A.(kx)))) A. = .z.S(.d.z) ( ) : .S. .DA S = .z.D(.k.A(z(.x.(kx)))) \nThe following lemma states that these translations are sound with respect to the CPS-translation, and \nthat they are inverses to each other modulo the equality theories. Recall that the CPS-translation for \n.S was de.ned at the same time as that for .DA in Section 2. Lemma 3. Let M bea termin .DA, and N bea \ntermin .S. Then we have: .\u00df. . [[M]] = [ M.]] .\u00df. . [[N ]] = [ N]] . M= M .DA . .S. N . = N Proof. We \nonly prove the key case of the last equation where N = S. S . = .z.D.(.k.A.(z(.x.(kx)))) = .z.S(.k.k(A.(z(.x.(A.(kx)))))) \n(by \u00dfv) = .z.S(.k.A.(z(.x.(kx)))) (by A.-lift,reset-A.) = .z.S(.k.(z(.x.(kx)))) (by S-reset,reset-A.) \n= .z.S(.k.z(.x.(kx))) (by S-reset) = .z.Sz (by S-nat) = S (by .v) In the derivation above, we used A.-lift \n(F [A.M]= A.M) and reset-A. ((A.M) = (M)), which follow from reset-S, S-tail, S-nat, and \u00dfv. The next \nlemma states the soundness of these transla\u00adtions. Lemma 4. (i) Let M1 and M2 be terms in .DA. Then .DA \n. M1 .. = M2 implies .S. M1 = M2 . (ii) Let N1 and N2 be terms in .S. Then .S. N1 = N2 implies .DA . \nN1 = N2 . The proof of this lemma can be found in the appendix. By combining these two lemmas with \nTheorem 8, we ob\u00adtain the completeness of .S. Theorem 9 (Soundness &#38; Completeness of .S). Let N1 \nand N2 be terms in .S. Then we have: .S. N1 = N2 if and only if .\u00df. . [[N1]]= [ N2]] Proof. The soundness \nhas already been proved. For the completeness, let us suppose .\u00df. . [[N1]] = [ N2]]. By Lemma 3, .\u00df. \n. [[N1 ]]= [ N2 ] . By the completeness of .DA, we have .DA . N1 = N2 . Then by Lemma 4, . . .S. N1 \n= N2 . From this, we can deduce .S. N1 = N2 using Lemma 3. 6.3 Languages with Basic Constants We remark \nthat our results can be modi.ed to the source calculi which have non-functional (basic) constants, such \nas natural numbers. One may wonder if our results can be applied to more realistic programming languages, \nsuch as Scheme [1], since the axiom .v does not hold in general in this case. We can, however, give a \nsound and complete ax\u00adiomatization for this calculus in the same manner as Sabry and Felleisen s work \n[25], that is, by simultaneously restrict\u00ading .v in the source calculus and . in the target calculus. \nWe omit the details here due to space limitation.  7. IMPLICATIONS OF AXIOMATIZATION AND INDEPENDENCE \nIn this section, we examine the axioms in .DA to get some insight on the calculus. 7.1 Conservativity \nAs we already mentioned in Section 3, the .rst three axioms \u00dfv, .v, and \u00df. in Figure 1 correspond to \nMoggi s computational lambda calculus, and the axioms D-elim, D\u00adcurrent, D-abort, and D-lift correspond \nto Sabry-Felleisen s axiomatization for callcc if we identify the D-operator with callcc. In other words, \nthe D-operator in .DA behaves in the same way as callcc3 . The remaining axioms are needed to axiomatize \nthe delimiter (the reset operator) and the A\u00adoperator. All but the axiom reset-lift appear in Sabry s \naxiomatization for shift and lazy reset [24], but the actual meaning of axioms are not quite the same, \nsince a term in the form (M) is a value in his calculus, but not a value in our calculus. Sabry s theory \nmay be obtained by adding axioms to .DA in an obvious way4 . An immediate but non-trivial consequence \nof our axiom\u00adatization is that the theory of delimited continuations is a conservative extension of that \nof .rst-class (unlimited) con\u00adtinuations, which can be shown below. Since Sabry and Felleisen s axioms \n[25] for .rst-class continuations (that is, without delimited continuations) are derivable from our .DA \n(where we replace callcc by D), it follows that any valid equa\u00adtion in Sabry and Felleisen s theory is \nalso derivable in .DA. As a reverse direction, let M = N be a provable equation in .DA, where M and N \ndo not contain the reset-operator. Then M = N is provable in Sabry s theory for lazy reset 3Filinski \n[11] already mentioned this correspondence. 4For each axiom in our theory which refers to a value V ,we \nadd a new axiom which is obtained by replacing V by (M)in the original axiom. [24], since it is stronger \nthan .DA. By carefully examin\u00ading Sabry s work, we can see Sabry s theory for shift and lazy reset is \nconservative over Sabry and Felleisen s theory for .rst-class continuations (see the discussion in the \ncon\u00adclusion below), hence M = N is also provable in Sabry and Felleisen s theory. It thus follows that \nTheorem 10 (Conservative Extension). The theory .DA is a conservative extension of Sabry and Felleisen \ns theory of .rst-class continuations [25] (when we identify D with callcc). Note that this is not a trivial \nobservation, as the CPS\u00adtranslations of the A-operator are not quite the same in these theories (while \ncallcc and D do have the same trans\u00adlation). However, as one intuitively expects, this di.erence can \nbe ignored as long as we do not use the reset operator. 7.2 Independence of Axioms We already mentioned \nthat many theories in the literature (such as Moggi s computational lambda calculus and Sabry and Felleisen \ns theory for callcc) contain redundant axioms, namely, some axioms are derivable from others. A natural \nquestion is whether .DA consists of independent axioms. We cannot fully answer this question, but as \na partial an\u00adswer, we can show all but one new axioms are independent from other axioms, thus they are \nnot redundant. In our equational setting, we say an axiom A is indepen\u00addent from a theory T if A is not \nderivable from T , and T.{A} is consistent, where an equational theory T is con\u00adsistent if M = N is not \nprovable from T for some M and N. Theorem 11 (Independence of Axioms). Let ax be one of A-lift, A-top, \nA-reset, and reset-value. Then ax is independent from .DA -{ax}. Proof. From the soundness theorem (Theorem \n1) and the consistency of .\u00df., we have .DA is consistent. To show the underivability of the axioms, we \nde.ne a mod\u00adi.ed CPS-translation from .DA to .\u00df., under which only one axiom becomes unsound while the \nothers remain sound. For a term M and a value V , we write ([M]) and V for the modi.ed versions of CPS-translations \n[ M] and V * , respec\u00adtively. We will de.ne four modi.ed CPS-translations, but use the same symbols for \nall the cases. For the axiom A-lift, we modify the following two de.ni\u00adtions of the CPS-translation: \n([(M)]) = ([M]) A = .xk.kx The de.nitions for other terms are unchanged, for instance, ([V ]) = .k. kV \n and x = x. It is easy to see only A-lift is unsound and all the other axioms are sound with respect \nto this modi.ed CPS-translation, which implies that A-lift is not derivable from other axioms. For the \naxiom A-top, we change the following one: ([(M)]) = ([M]) For the axiom A-reset, we change the following \none: ([(M)]) = .k. k(.xk ' .. ([M])J(.v.vxk ' .)) The term in the right hand side may look rather complex, \nbut it is the result of .rst expanding the term [ .x.(M)x]], then replacing [ M]] by ([M]) (after some \n\u00df-reductions). For the axiom reset-value, we change the following one: ([(M)]) = ([AM]) In all cases, \nthe unsoundness of the speci.ed axiom and the soundness of all the other axioms can be shown eas\u00adily. \nWe do not know if the remaining axiom reset-lift is inde\u00adpendent or not, although we believe so.  8. \nCONCLUSION The shift and reset operators attract many researchers interest because of its expressiveness \nand rigorous semantics via CPS-translation. However, there are theoretically not pleasant features in \nthese operators. For instance, if we try to have a type system as an extension of the standard simply \ntyped lambda calculus, and we allow the type of the reset terms to be higher-order, then the CPS-translation \ndoes not preserve typing, and the calculus is not strongly normalizing. There are several attempts to \nremedy this defect including Murthy s work [21] and ours [19]. However, due to its simple semantics, \nmost researchers use the original shift and reset operators. In this paper, we return to the original \nshift and reset, and have given a sound and complete axiomatization for the calculus with shift and reset, \nand an equivalent cal\u00adculus with D, A, and reset. The latter calculus .DA is not only useful for expressing \nthe inverse translation used in the completeness proof, but also interesting on its own right, as it \nis a conservative extension over Sabry and Felleisen s theory for .rst-class continuations. Having a \nvery similar motivation in mind, Sabry [24] ax\u00adiomatized a calculus with shift and lazy reset, which \nis a close, but di.erent calculus than Danvy and Filinski s. He invented an elegant technique to prove \nthe completeness of such an axiomatization and obtained a complete axiomati\u00adzation which is very similar \nto ours. In fact, the only di.er\u00adences of his axioms and ours are that (i) (M) is a value in his calculus, \nand (ii) our calculus has an extra axiom reset\u00adlift. If we regard (M) as values, then the axiom reset-lift \nis derivable, so the essential di.erence is (i). In practice, we are interested in evaluating the inside \nof reset-terms, namely, M in the term (M) while Sabry s lazy reset suspends evaluation of reset-terms, \nso the practical importance of his calculus remains uncertain. We have axiomatized the very calculus \nDanvy and Filinski proposed and many followers have been using, in which sense we can say our axiomatization \nshould be more useful. However, our proof technique is based on Sabry and Felleisen s work [25], and \nit consists of a lot of syntactic calculations. On the other hand, Sabry s new tech\u00adnique is much more \nelegant. In order to apply Sabry s proof technique to our case, we have to carefully formalize the target \ncalculus in such a way that the evaluation is in call\u00adby-value in the interpretation of the shift operator, \nand in call-by-name in manipulating continuation parameters. We did not take this approach in this paper, \nsince it is not clear that the target calculus Danvy and Filinski s originally de\u00ad.ned coincides with \nsuch a hybrid system. We brie.y state some future work. Firstly, we should extend our work to include \nthe full CPS-hierarchy, which involve not only continuation and metacontinuation param\u00adeters, but also \nmetameta-continuation parameters and so on (in general, metan-continuation parameters for n> 1). In this \nwork, we have treated the simplest case of n = 1, which means we allow only one kind of shift and reset \noperators. In some applications [30], one wants to use many di.erent kinds of shift/reset operators which \ndo not interact, thus extending our result to such a general case seems necessary. Since we have used \nthe linearity of the metacontinuation variable ., a straightforward extension of our proof is not possible \nfor the case of n> 1. Secondly, we have considered equational theories in this paper, and not considered \nreduction theories, namely, we did not orient equations. As Sabry and Wadler [26] and Barthe et al [3] \npointed out, we should also study reduction theories, in particular, we want to know if there is a set \nof reduction rules for shift and reset which is sound and complete with respect to CPS-translation. It \nis already a di.cult problem for the case of .rst-class continuations. We should at least consider optimized \n(administrative redex\u00adfree) CPS-translation in the sense of Plotkin [22], Steele [28], Danvy-Filinski[6], \nSabry-Felleisen [25], and Danvy-Nielsen [8]. Finally, we wish to obtain a deeper, more semantics-oriented \nunderstanding of the delimited continuations and our com\u00adpleteness proof. The second author has started \nto study this direction [16] by replacing the target calculus by (models of) a linear lambda calculus \nwith a recursive type. Let us .x the answer type R, and let D be the recursive type de.ned by D = D . \n(D . RD) . RD where RX =(X . R) .R (the linearly-used continuations monad [15]), then the tar\u00adgets of \nthe CPS-translation in Section 4 can by typed as: (terms) (D . RD) . (D . R) .R (pre-values) RD (answers) \nR (values) D (= D . (D . RD) . RD) (continuations) D . RD (metacontinuations) D . R Note that the linearity \ncondition of the metacontinuation variable is expressed by the linear implication .. This ap\u00adproach also \nseems to be closely related to a recent work by Thielecke [31]. Acknowledgments: The authors would like \nto thank Olivier Danvy and Amr Sabry for careful reading and valu\u00adable comments. Thanks are also due \nto anonymous referees for their insightful suggestions. 9. REFERENCES [1] H. Abelson et al. Revised5 \nReport on the Algorithmic Language Scheme. Higher-Order and Symbolic Computation, 11(1):7 105, 1998. \n[2] K. Asai. Online Partial Evaluation for Shift and Reset. In Proc. ACM Workshop on Partial Evaluation \nand Semantics-Based Program Manipulation, pages 19 30, 2002. [3] G. Barthe, J. Hatcli., and M. H. S\u00f8rensen. \nRe.ections on Re.ections. In Proc. Ninth International Symposium on Programming Language Implementation \nand Logic Programming, pages 241 258, 1997. [4] J. Berdine, P. O Hearn, U. Reddy, and H. Thielecke. Linear \nContinuation Passing. Higher-Order and Symbolic Computation, pages 181 208, 2002. [5] O. Danvy. Formalizing \nImplementation Strategies for First-Class Continuations. In Proc. 9th European Symposium on Computing, \nLecture Notes in Computer Science 1782, pages 151 160, 1990. [6] O. Danvy and A. Filinski. Abstracting \nControl. In Proc. 1990 ACM Conference on Lisp and Functional Programming, pages 151 160, 1990. [7] O. \nDanvy and A. Filinski. Representing Control: a Study of the CPS Transformation. Mathematical Structures \nin Computer Science, 2(4):361 391, 1992. [8] O. Danvy and L. R. Nielsen. A First-Order One-Pass CPS Transformation. \nIn Proc. FOSSACS 2002, Lecture Notes in Computer Science 2303, pages 98 113, 2002. [9] M. Felleisen. \nThe Theory and Practice of First-Class Prompts. In Proc. 15th Symposium on Principles of Programming \nLanguages, pages 180 190, 1988. [10] M. Felleisen and R. Hieb. The Revised Report on the Syntactic Theories \nof Sequential Control and State. Theoretical Computer Science, 103:235 271, 1992. [11] A. Filinski. Representing \nMonads. In Proc. 21st Symposium on Principles of Programming Languages, pages 446 457, 1994. [12] C. \nF\u00a8uhrmann and H. Thielecke. On the Call-by-Value CPS Transform and its Semantics. Information and Computation, \nto appear. [13] M. Gasbichler and M. Sperber. Final shift for call/cc: Direct Implementation of Shift \nand Reset. In Proc. 7th International Conference on Functional Programming, pages 271 282, 2002. [14] \nC. A. Gunter, D. Remy, and J. G. Riecke. A Generalization of Exceptions and Control in ML-Like Languages. \nIn Proc. Functional Programming and Computer Architecture, pages 12 23, 1995. [15] M. Hasegawa. Linearly \nUsed E.ects: Monadic and CPS Transformations into the Linear Lambda Calculus. In Proc. International \nSymposium on Functional and Logic Programming, Lecture Notes in Computer Science 2441, pages 167 182, \n2002. [16] M. Hasegawa. On the Semantics of Delimited Continuations. manuscript, 2003. [17] R. Hieb, \nR. Dybvig, and C. W. Anderson. Subcontinuations. Lisp and Symbolic Computation, 6:453 484, 1993. [18] \nM. Hofmann. Sound and Complete Axiomatisations of Call-by-Value Control Operators. Mathematical Structures \nin Computer Science, 5:461 482, 1995. [19] Y. Kameyama. A Type-Theoretic Study on Partial Continuations. \nIn Proc. IFIP International Conference on Theoretical Computer Science, Lecture Notes in Computer Science \n1872, pages 489 504, 2000. [20] E. Moggi. Computational Lambda-Calculus and Monads. In Proc. 4th Symposium \non Logic in Computer Science, pages 14 28, 1989. [21] C. Murthy. Control Operators, Hierarchies, and \nPseudo-Classical Type Systems: A-Translation at Work. In Proc. ACM Workshop on Continuation, pages 49 \n71, 1992. [22] G. D. Plotkin. Call-by-Name, Call-by-Value, and the .-Calculus. Theoretical Computer Science, \n1:125 159, 1975. [23] C. Queinnec and B. Serpette. A Dynamic Extent Control Operator for Partial Continuations. \nIn Proc. 18th Symposium on Principles of Programming Languages, pages 174 184, 1991. [24] A. Sabry. Note \non Axiomatizing the Semantics of Control Operators. Technical Report CIS-TR-96-03, Dept. of Information \nScience, Univ. of Oregon, 1996. [25] A. Sabry and M. Felleisen. Reasoning about Programs in Continuation-Passing \nStyle. Lisp and Symbolic Computation, 6(3-4):289 360, 1993. [26] A. Sabry and P. Wadler. A Re.ection \non Call-by-Value. ACM Transactions on Programming Languages and Systems, 19(6):916 941, 1997. [27] T. \nSekiguchi, T. Sakamoto, and A. Yonezawa. Portable Implementation of Continuation Operators in Imperative \nLanguages by Exception Handling. In Advances in Exception HandlingTechniques, Lecture Notes in Computer \nScience 2022, pages 217 233, 2001. [28] G. L. Steele Jr. RABBIT: A Compiler for SCHEME. Technical Report \nAITR-474, Arti.cial Intelligence Laboratory, Massachusetts Institute of Technology, 1978. [29] C. Strachey \nand C. P. Wadsworth. Continuations: A Mathematical Semantics for Handling Full Jumps. Higher-Order and \nSymbolic Computation, 13(1/2):135 152, 2000. [30] E. Sumii. An Implementation of Transparent Migration \non Standard Scheme. In Proc. Workshop on Scheme and Functional Programming, pages 61 63, 2000. [31] H. \nThielecke. From Control E.ects to Typed Continuation Passing. In Proc. 30th Symposium on Principles of \nProgramming Languages, pages 139 149, 2003. [32] P. Thiemann. Cogen in Six Lines. In Proc. International \nConference on Functional Programming, pages 180 189, 1996.   APPENDIX (Proof of Lemma 1) (\u00df-lift, assuming \nx .. FV (F ) . FV (M)) (.x.F [N])M =(.x.(.y.F [y])N)M (by \u00df.) =(.x.(.y.F [y])((.x.N)x))M (by \u00dfv) =(.y.F \n[y])((.x.N)M) (by \u00df.) = F [(.x.N)M] (by \u00df.) (reset-reset) ((M)) = (A(M)) (by A-top) = (AM) (by A-reset) \n= (M) (by A-top) (D-top) (DM) = (A(DM)) (by reset-A) = (D(.k.A(M(.f.k(Af))))) (by D-lift) = (D(.k.A(M(.f.Af)))) \n(by D-abort) = (A(M(.f.Af))) (by D-elim) = (M(.f.Af)) (by reset-A) = (MA) (by .v) (D-tail) Putting F \n= [] in D-lift, we have DM = D(.k.Mk). Then we can derive: (.x.D(.k.M1))M2 = D((.x..k.M1)M2) (by \u00df-lift) \n= D(.z.(.x..k.M1)M2z) (by the above equation) = D(.z.(.k.(.x.M1)M2)z) (by \u00df-lift) = D(.k.(.x.M1)M2) (by \n\u00dfv) (\u00df.-reset-1) ((.x.(F [x]))M) = ((.x.D(.k.k(F [x])))M) (by D-elim,D-current) = (D(.k.(.x.k(F [x]))M)) \n(by D-tail) = (A(D(.k.(.x.k(F [x]))M))) (by reset-A) = (D(.k.(.x.(.f.k(Af))(F [x]))M)) (by D-lift) = \n(D(.k.(.x.(.f.Af)(F [x]))M)) (by D-abort) = ((.x.A((F [x])))M) (by D-elim,.v ) = ((.x.A(F [x]))M) (by \nA-reset) = (A(F [M])) (by \u00df.) = (F [M]) (by reset-A) (\u00df.-reset-2) We prove (.x.E[x])(M) = E[(M)] by induction \non E. The only interesting case is E = (E1). (.x.E[x])(M) = (.x.(E1[x]))(M) = ((.x.E1[x])(M)) (by reset-lift) \n= (E1[(M)]) (by I.H.) = E[(M)] (Proof of Lemma 2) We can prove S-nat as follows: F [SM]= S(.k.k(F [SM])) \n(by S-elim) = S(.k.(k(F [SM]))) (by S-reset) = S(.k.(M(.x.(k(F [x]))))) (by reset-S) = S(.k.M(.x.(k(F \n[x])))) (by S-reset) Other equations follow from S-nat. (Proof of Lemma 4) We can prove that each axiom \nin .DA is translated to a provable equation in .S , and vice versa. Here we give a proof of the most \ninteresting case, namely, we will verify the axiom D-lift is translated to a provable equation in .S \n. (F [DM]). = F .[D.M.] = F .[S(.k.k(M.(.x.A.(kx))))] (by S-tail,\u00df.) = S(.h.(.k.k(M.(.x.A.(kx))))(.x.(hF \n.[x]))) (by S-nat) = S(.h.(.x.(hF .[x]))(M.(.x.A.(hF .[x])))) (by \u00dfv ) = S(.h.(.x.hF .[x])(M.(.x.A.(hF \n.[x])))) (by S-lift-reset) = S(.h.hF .[M.(.x.A.(hF .[x]))]) (by \u00df.) =(D(.h.F [M(.x.hF [x])])). (by \u00dfv,\u00df.) \nIn the derivation we used the following equation as S-lift\u00adreset: S(.k.(.x.(N))M)= S(.k.(.x.N)M) which \ncan be proved by S-tail and S-reset. \n\t\t\t", "proc_id": "944705", "abstract": "The shift and reset operators, proposed by Danvy and Filinski, are powerful control primitives for capturing <i>delimited continuations</i>. Delimited continuation is a similar concept as the standard (unlimited) continuation, but it represents part of the rest of the computation, rather than the whole rest of computation. In the literature, the semantics of shift and reset has been given by a CPS-translation only. This paper gives a direct axiomatization of calculus with shift and reset, namely, we introduce a set of equations, and prove that it is sound and complete with respect to the CPS-translation. We also introduce a calculus with control operators which is as expressive as the calculus with shift and reset, has a sound and complete axiomatization, and is conservative over Sabry and Felleisen's theory for first-class continuations.", "authors": [{"name": "Yukiyoshi Kameyama", "author_profile_id": "81100569451", "affiliation": "University of Tsukuba, Tsukuba, Japan", "person_id": "P504412", "email_address": "", "orcid_id": ""}, {"name": "Masahito Hasegawa", "author_profile_id": "81100270904", "affiliation": "Kyoto University, Kyoto, Japan", "person_id": "PP14102175", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/944705.944722", "year": "2003", "article_id": "944722", "conference": "ICFP", "title": "A sound and complete axiomatization of delimited continuations", "url": "http://dl.acm.org/citation.cfm?id=944722"}