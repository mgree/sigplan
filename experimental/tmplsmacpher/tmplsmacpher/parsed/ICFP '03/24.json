{"article_publication_date": "08-25-2003", "fulltext": "\n Meta-Programming through Typeful Code Representation* Chiyan Chen and Hongwei Xi Computer Science \nDepartment Boston University {chiyan, hwxi}@cs.bu.edu Abstract By allowing the programmer to write code \nthat can generate code at run-time, meta-programming offers a powerful approach to pro\u00adgram construction. \nFor instance, meta-programming can often be employed to enhance program ef.ciency and facilitate the \nconstruc\u00adtion of generic programs. However, meta-programming, especially in an untyped setting, is notoriously \nerror-prone. In this paper, we aim at making meta-programming less error-prone by providing a type system \nto facilitate the construction of correct meta-programs. We .rst introduce some code constructors for \nconstructing typeful code representation in which program variables are replaced with deBruijn indices, \nand then formally demonstrate how such type\u00adful code representation can be used to support meta-programming. \nThe main contribution of the paper lies in recognition and then for\u00admalization of a novel approach to \ntyped meta-programming that is practical, general and .exible.  Categories and Subject Descriptors D.3.2 \n[Programming Languages]: Language Classi.cations Applicative Languages  General Terms Languages, Theory \n Keywords Meta-Programming, Multi-Level Staged Programming, Typeful Code Representation * Partially \nsupported by NSF grants no. CCR-0224244 and no. CCR-0229480 Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 03, August 25 29, 2003, Uppsala, Sweden. \nCopyright 2003 ACM 1-58113-756-7/03/0008 ...$5.00 1 Introduction Situations often arise in practice where \nthere is a need for writ\u00ading programs that can generate programs at run-time. For in\u00adstance, there are \nnumerous cases (kernel implementation [18], graphics [26], interactive media [10], method dispatch in \nobject\u00adoriented languages [9, 2], etc.) where run-time code generation can be employed to reap signi.cant \ngain in run-time performance [17]. To illustrate this point, we de.ne a function evalPoly as follows \nin Scheme for evaluating a polynomial p at a given point x. (define (evalPoly p x) (if (null? p) 0 \n (+ (car p) (* x (evalPoly (cdr p) x))))) Note that we use a nonempty list (a0 a1 ... an) in Scheme \nto repre\u00adsent the polynomial anxn +...+a1x+a0. We now de.ne a function sumPoly such that (sumPoly p xs) \nreturns the sum of the values of a polynomial p at the points listed in xs. (define (sumPoly p xs) (if \n(null? xs) 0 (+ (evalPoly p (car xs)) (sumPoly p (cdr xs))))) When calling sumPoly, we generally \nneed to evaluate a .xed poly\u00adnomial repeatedly at different points. This suggests that we imple\u00adment \nsumPoly with the following strategy so as to make sumPoly more ef.cient. We .rst de.ne a function genEvalPoly \nas follows, where we make use of the backquote/comma notation in Scheme. (define (genEvalPoly p) (define \n(aux p x) (if (null? p) 0 (+ ,(car p) (* ,x ,(aux (cdr p) x))))) (lambda (x) ,(aux p x))) When \napplied to a polynomial p, genEvalPoly returns an s\u00adexpression that represents a procedure (in Scheme) \nfor evaluating p. For instance, (genEvalPoly .(321)) returns the following s\u00adexpression, (lambda (x)(+ \n3 (* x (+ 2 (* x (+ 1 (* x 0))))))) which represents a procedure for evaluating the polynomial x2 + 2x \n+ 3. Therefore, given a polynomial p, we can call (eval (genEvalPoly p) .()) to generate a procedure \nproc for evaluating p1; presumably, (proc x) should execute faster than (evalPoly p x) does. This leads \nto the following (potentially) more ef.cient implementation of sumPoly. (define (sumPoly p xs) (define \nproc (eval (genEvalPoly p) ())) (define (aux xs) (if (null? xs) 0 (+ (proc (car xs)) (aux xs)))) \n (aux xs)) Meta-programming, though useful, is notoriously error-prone in general and approaches such \nas hygenic macros [11] have been pro\u00adposed to address the issue. Programs generated at run-time often \ncontain type errors or fail to be closed, and errors in meta-programs are generally more dif.cult to \nlocate and .x than those in (ordi\u00adnary) programs. This naturally leads to a need for typed meta\u00adprogramming \nso that types can be employed to capture errors in meta-programs at compile-time. The .rst and foremost \nissue in typed meta-programming is the need for properly representing typed code. Intuitively, we need \na type constructor (\u00b7)code such that for a given type t, (t)code is the type for expressions representing \ncode of type t. Also, we need a func\u00adtion run such that for a given expression e of type (t)code, run(e) \nexecutes the code represented by e and then returns a value of type t when the execution terminates. \nNote that we cannot in general execute open code, that is, code containing free program variables. Therefore, \nfor each type t, the type (t)code should only be for ex\u00adpressions representing closed code of type t. \nA common approach to capturing the notion of closed code is through higher-order abstract syntax (h.o.a.s.) \n[3, 24, 23]. For instance, the following declaration in Standard ML (SML) [19] declares a datatype for \nrepresenting pure untyped closed .\u00adexpressions: datatype exp = Lam of (exp -> exp) | App of exp * exp \n As an example, the representation of the untyped .-expression .x..y.y(x) is given below: Lam(fn (x:exp) \n=> Lam (fn (y:exp) => App(y, x)) Although it seems dif.cult, if not impossible, to declare a datatype \nin ML for precisely representing typed .-expressions, this can be readily done if we extend ML with guarded \nrecursive (g.r.) datatype constructors [35]. For instance, we can declare a g.r. datatype constructor \n(\u00b7)HOAS and associate with it two value constructors HOASlam and HOASapp that are assigned the following \ntypes, re\u00ad spectively.2 .a.\u00df.((a)HOAS . (\u00df)HOAS) . (a . \u00df)HOAS .a.\u00df.(a . \u00df)HOAS *(a)HOAS . (\u00df)HOAS) Intuitively, \nfor a given type t, (t)HOAS is the type for h.o.a.s. trees that represent closed code of type t. As an \nexample, the h.o.a.s. representation of the simply typed .-expression .x : int..y : int . int.y(x) is \ngiven below, HOASlam(fn x:int HOAS => HOASlam(fn y:(int -> int) HOAS => HOASapp(y, x))) which has the \ntype (int . (int . int) . int)HOAS. 1Note that eval is a built-in function in Scheme that takes an s-expression \nand an environment as its arguments and returns the value of the expression represented by the s-expression. \n2Note that, unlike a similar inductively de.ned type construc\u00adtor [25], HOAS cannot be inductively de.ned. \nBy associating with HOAS some extra value constructors, we can represent closed code of type t as expressions \nof type (t)HOAS. In other words, we can de.ne (\u00b7)code as (\u00b7)HOAS. The function run can then be implemented \nby .rst translating h.o.a.s. trees into (untyped) .rst-order abstract syntax (f.o.a.s.) trees3 and then \ncom\u00adpiling the f.o.a.s. trees in a standard manner. Please see a recent paper [35] for more details on \nsuch an implementation. Though clean and elegant, there are some serious problems with representing code \nas h.o.a.s trees. In general, it seems rather dif\u00ad.cult, if not impossible, to manipulate open code in \na satisfactory manner when higher-order code representation is chosen. On the other hand, there is often \na need to directly handle open code when meta-programs are constructed. For instance, in the de.nition \nof the function genEvalPoly, the auxiliary function aux returns some open code containing one free program \nvariable (which is closed later). We feel it may make meta-programming too restrictive if open code manipulation \nis completely disallowed. Furthermore, higher-order code representation may lead to a subtle problem. \nSuppose we need to convert the following h.o.a.s. tree t, which has the type ((int)HOAS . int)HOAS, into \nsome f.o.a.s. tree in order to run the code represented by t: HOASlam (fn (x: (int HOAS) HOAS) => run \nx) We then need to apply the function run to a variable ranging over expressions of type ((int)HOAS)HOAS \nwhen making this conver\u00adsion, which unfortunately causes a run-time error. This is precisely the problem \nof free variable evaluation, a.k.a. open code extrusion, which we encounter when trying to evaluate the \ncode: <fn x:<int> => (run <x>)> in MetaML [33]. In this paper, we choose a form of .rst-order abstract \nsyntax trees to represent code that not only support direct open code manipulation but also avoid the \nproblem of free variable evaluation. As for the free program variables in open code, we use deBruijn \nindices [8] to represent them. For instance, we can declare the following datatype in Standard ML to \nrepresent pure untyped .-expressions. datatype exp = One | Shi of exp | Lam of exp | App of exp * exp \n We use One for the .rst free variable in a .-expression and Shi for shifting each free variable in a \n.-expression by one index. As an example, the expression .x..y.y(x) can be represented as follows: Lam(Lam(App(One,Shi(One)))) \nFor representing typed expressions, we re.ne exp into types of the form (G,t), where (\u00b7,\u00b7) is a binary \ntype constructor and G stands for type environments, which are represented as sequences of types; an \nexpression of type (G,t) represents some code of type t in which the free variables are assigned types \nby G, and therefore the type for closed code of type t is simply (e,t), where e is the empty type environment. \nIt is certainly cumbersome, if not completely impractical, to pro\u00adgram with f.o.a.s. trees, and the direct \nuse of deBruijn indices fur\u00adther worsens the situation. To address this issue, we adopt some meta-programming \nsyntax from Scheme and MetaML to facilitate the construction of meta-programs and then provide a translation \nto eliminate the meta-programming syntax. We also provide interest\u00ading examples in support of this design. \n3For this purpose, we may need to introduce a constructor HOASvar of the type .a.string . (a)HOAS for \nrepresenting free variables. kinds . ::= type |env types t ::= a |t 1 .t 2 |(G,t )|.a. : . .t type env. \nG ::= . |e |t :: G constants c ::= cc |cf const. fun. cf ::= run const. con. cc ::= Lift |One |Shi |App \n|Lam |Fix expressions e ::= x | f |c(e1,...,en) | lam x.e |e1(e2) |.x f .e | . i(v) |. e(e) values v \n::= x |cc(v1,...,vn) |lam x.e |. i(v) exp. var. ctx. G ::= 0/ |G ,x : t typ. var. ctx. . ::= 0/ |. ,a \n: type |. ,. : env Figure 1. The syntax for . code The main contribution of the paper lies in recognition \nand then for\u00admalization of a novel approach to typed meta-programming that is practical, general and \n.exible. This approach makes use of a .rst-order typeful code representation that not only supports direct \nopen code manipulation but also prevents free variable evaluation. Furthermore, we facilitate meta-programming \nby providing certain meta-programming syntax as well as a type system to directly sup\u00adport it. The formalization \nof the type system, which is considerably involved, constitutes the major technical contribution of the \npaper. We organize the rest of the paper as follows. In Section 2, we in\u00adtroduce an internal language \n.code and use it as the basis for typed meta-programming. We then extend .code to . + code in Section \n3, including some syntax to facilitate meta-programming. In Sec\u00ad tion 4, we brie.y mention an external \nlanguage which is designed for the programmer to construct programs that can eventually be transformed \ninto those in .+ code. We also present some examples in support of the practicality of meta-programming \nwith .+ code. In Sec\u00adtion 5, we introduce additional code constructors to support more programming features \nsuch as references. Lastly, we mention some related work and then conclude. 2 The Language .code In \nthis section, we introduce a language .code, which essentially ex\u00adtends the second-order polymorphic \n. -calculus with general recur\u00adsion (through a .xed point operator .x), certain code constructors for \nconstructing typeful code representation and a special function run for executing closed code. The syntax \nof .code is given in Fig\u00adure 1. We provide some explanation on the syntax as follows. We use the kinds \ntype and env for types and type environ\u00adments, respectively. In addition, we use a and . for the vari\u00adables \nranging over types and type environments, respectively, and a. for either an a or a . .  We use t for \ntypes and G for type environments. A type en\u00advironment assigns types to free expression variables in \ncode. For instance, bool :: int :: e is a type environment which as\u00adsigns the types bool and int to the \n.rst and the second expres\u00ad sion variables, respectively. We use t G for either a t or a G.  We use \n(G,t )as the type for expressions representing code of type t in which each free variable is assigned \na type by the type environment G. For instance, the expression App(One,Shi(One)) can be assigned the \ntype ((int .int) :: int :: e ,int) to indicate that the expression represents some code of type int in \nwhich there are at most two free variables such that the .rst and the second free variables have the \ntypes int and int .int, respectively.  The (code) constructors Lift,One,Shi,Lam,App and Fix are  Lift \n: .. ..a .(a ) .(. ,a )Lam : .. ..a 1..a 2.((a 1 :: . ,a 2)) .(. ,a 1 .a 2)App : .. ..a 1..a 2.((. ,a \n1 .a 2),(. ,a 1)) .(. ,a 2) Fix : .. ..a .((a :: . ,a )) .(. ,a ) One : .. ..a .() .(a :: . ,a ) Shi \n: .. ..a 1..a 2.((. ,a 1)) .(a 2 :: . ,a 1) run : .a .((e ,a )) .a Figure 2. The types of some constructors \nin . code used for constructing expressions representing typed code in which variables are replaced with \ndeBruijn indices [8], and the function run is for executing typed closed code represented by expressions. \n We differentiate lam-bound variables x from .x-bound vari\u00adables f ;a lam-bound variable is a value but \na .x-bound vari\u00adable is not. This differentiation mainly prepares for introduc\u00ading effects into the system. \n We use .i(\u00b7) and .e(\u00b7) to indicate type abstraction and application, respectively. For instance, the \nexpression (.a .. x : a .x)[int] in the Church style is represented as  . e(. i(lam x.x)). Later, the \npresence of .i and .e allows us to uniquely determine the rule that is applied last in the typing derivation \nof a given expression. Preparing for accommodat\u00ading effects in .code, we impose the usual value restriction \n[34] by requiring that .i be only applied to values. It is straightforward to extend .code with some \nbase types (e.g., bool and int for booleans and integers, respectively) and constants and functions related \nto these base types. Also, conditional expressions can be readily added into .code. Later, we may form \nexamples in\u00advolving these extra features so as to give a more interesting presen\u00adtation. We assume a \nvariable can be declared at most once in an expression (type) variable context G (. ). For an expression \nvariable context G , we write dom(G ) for the set of variables declared in G and G (xf )= t if xf : t \nis declared in G . Note that similar notation also applies to type variable contexts . . We use a signature \nS to assign each constant c a c-type of the fol\u00adlowing form, .a. 1: . 1 ....a. : . m.(t 1,...,t n) .t \nm where n indicates the arity of c. We write c(e1,...,en) for applying a constant c of arity n to n arguments \ne1,...,en. For constants c of arity 0, we may write c for c(). For convenience, we may write .. for a \nlist of quanti.ers .a.1: . 1 ....a. : . m, where m . = 0/ ,a. 1: . 1,...,a. m : . m Also, we may write \n.a and .. for .a : type and .. : env, respec\u00adtively. In Figure 2, we list the c-types assigned to the \ncode con\u00adstructors and the function run. Note that a c-type is not regarded as a type. 2.1 Static and \nDynamic Semantics We present the kinding rules for .code in Figure 3. We use a judg\u00adment of the form \n. ft : type (. fG : env) to mean that t (G)isa well-formed type (type environment) under . . We use T \nfor .nite mappings de.ned below and dom(T ) for the domain of T . T ::=[] |T [a.. t G] Kinding rules \n. ft G : . . (a. )= . . fa. : . . ft 1: type . ft 2: type . ft 1 .t 2: type . fG : env . ft : type . \nf(G,t ): type . ,a. : . ft G : type . f.a. : . .t G : type . fe : env . ft : type . fG : env . ft :: \nG : env Figure 3. The kinding rules for . code Note that [] stands for the empty mapping and T [a. .t \nG] stands for the mapping that extends T with a link form a. to t G, where we assume a. ..dom(T ). We \nwrite t G[T ] for the result of substituting each a. .dom(T ) with T (a. ) in t G. The standard de.nition \nof substitution is omitted here. We write . fT : . 0 to mean that for each a. .dom(T )= dom(.0), . fT \n(a. ) : . 0(a. ). Given a type variable context . and an expression variable context G , we write . fG \n[ok] to mean that . fG (x) : type is derivable for every x .dom(G ). We use . ;G fe : t for a typing \njudgment meaning that the expression e can be assigned the type t under . ;G , where we require . fG \n[ok]. The typing rules for .code are listed in Figure 4. In the rule (ty-iLam), which introduces .i, \nthe premise . fG [ok] ensures that there are no free occurrences of a. in G . PROPOSITION 2.1. (Canonical \nForms) Assume that 0/ ;0/ fv : t is derivable. Then we have the following. If t = t 1 .t 2, then v is \nof the form lam x.e.  If t = (G,t 1), then v is of one of the following forms: Lift(v1), One, Shi(v1), \nLam(v1), App(v1,v2) and Fix(v1).  If t = .a. .. , then v is of the form . i(v1).  PROOF. The proposition \nfollows from a straightforward inspection of the typing rules in Figure 4. We use . for .nite mappings \nde.ned below: . ::=[] |. [xf .e] and write e[. ] for the result of substituting each xf .dom(. ) for \n. (xf ) in e. We write . ;G f(T ;. ) : (. 0;G 0) to mean . fT : . 0 and for each xf .dom(. )= dom(G0), \n. ;G f . (xf ) : G 0(xf )[T ]. We assign dynamic semantics to .code through the use of evaluation Typing \nrules . ;G fe : t  . fG [ok] G (xf )= t (ty-var) . ; G fxf : t S (c)= .. 0.(t 1,...,t n) .t. fG [ok] \n. fT : . 0 . ; G fei : t i[T ] for i = 1,...,n  (ty-cst) . ; G fc(e1,...,en) : t [T ] . ;G ,x : t 1 \nfe : t 2 (ty-lam) . ; G flam x.e : t 1 .t 2 . ;G fe1: t 1 .t 2 . ; G fe2: t 1 (ty-app) . ; G fe1(e2) \n: t 2 . ;G , f : t fe : t (ty-.x) . ; G f.x f .e : t . ,a. : . ;G fv : t. fG [ok] (ty-iLam) . ; G f. \ni(v) : .a. : . .t . ;G fe : .a. : . .t. ft G : . (ty-eLam) . ; G f. e(e) : t [a. .t G] Figure 4. The \ntyping rules for . code contexts, which are de.ned as follows. eval. ctx. E ::=[] |c(v1,...,vi-1,E,ei+1,...,en) \n|E(e) |v(E) |. e(E) Given an evaluation context E and an expression e, we use E[e] for the expression \nobtained from replacing the hole [] in E with e. We de.ne a function comp as follows, where we use xfs \nfor a se\u00adquence of distinct expression variables xf . Note that comp is a func\u00adtion at meta-level. comp(xfs;Lift(v)) \n= v comp(xfs,xf ;One)= xf comp(xfs,xf ;Shi(v)) = comp(xfs;v) comp(xfs;Lam(v)) = lam x.comp(xfs,x;v) comp(xfs;App(v1,v2))=(comp(xfs;v1))(comp(xfs;v2)) \ncomp(xfs;Fix(v)) = .x f .comp(xfs, f ;v) Intuitively, when applied to a sequence of distinct expression \nvari\u00adables xfs and a value v representing some code, comp returns the code. For instance, we have comp(\u00b7,x, \nf ;App(One,Shi(One))) = f (x). DEFINITION 2.2. We de.ne redexes and their reductions as fol\u00adlows. (lam \nx.e)(v) is a redex, and its reduction is e[x .v].  .x f .e is a redex, and its reduction is e[ f ..x \nf .e].  .e(. i(v)) is a redex, and its reduction is v.  run(v) is a redex if comp(\u00b7;v) is de.ned, and \nits reduction is comp(\u00b7;v).  Given expressions e = E[e1] and e. = E[e1], we write e .e. and say e reduces \nto e. in one step if e1 is a redex and e1 is its reduction.  2.2 Key Properties We .rst establish the \nfollowing substitution lemma. LEMMA 2.3. (Substitution) Assume that .,.0;G,G0 f e : t is derivable and \n.;G f (T;.): (.0;G0)holds. Then .;G f e[.]: t[T] is derivable. PROOF. The proof follows from structural \ninduction on the typing derivation of .,.0;G,G0 f e : t. We now de.ne a function G(\u00b7)as follows that \nmaps a given expres\u00adsion variable context to a type environment. G(0/)=e G(G,x : t)=t :: G(G) LEMMA 2.4. \nLet G be xf1: t1,...,xfn : tn.If 0/ f G [ok]holds and 0/;0/ f v : (G(G),t) is derivable, then 0/;G f \ncomp(xf1,...,xfn;v): t is derivable. PROOF. This follows from structural induction on v. THEOREM 2.5. \n(Subject Reduction) Assume 0/;0/ f e : t is deriv\u00adable. If e . e. holds, then 0/;0/ f e. : t is derivable. \nPROOF. With Lemma 2.3 and Lemma 2.4, the proof follows from structural induction on the typing derivation \nof 0/;0/ f e : t. THEOREM 2.6. (Progress) Assume 0/;0/ f e : type is derivable. Then e is either a value \nor e . e. holds for some expression e. . PROOF. With Proposition 2.1, the theorem follows from structural \ninduction on the typing derivation of 0/;0/ f e : t. Combining Theorem 2.5 and Theorem 2.6, we clearly \nhave that the evaluation of a well-typed closed expression e in .code either reaches a value or continues \nforever. In particular, this indicates that the problem of free variable evaluation can never occur in \n.code. 2.3 Meta-Programming with .code It is already possible to do meta-programming with .code. For \nin\u00adstance, we can .rst form an external language MLcode by extending ML with code constructors (Lift, \nOne, Shi, App, Lam, Fix) and the special function run, and then employ a type inference algorithm (e.g., \none based on the one described in [4]) to elaborate programs in MLcode into programs, or more precisely \ntyping derivations of programs, in .code. As an example, we show that the function genEvalPoly in Section \n1 can be implemented as follows, where we use [] for empty type environment e and <;> for the type constructor \n(\u00b7,\u00b7). val plus = fn x: int => fn y: int =>x+y val mult = fn x: int => fn y: int =>x*y fun genEvalPoly \n(p) = let fun aux (p) = if null (p) then Lift (0) else App (App (Lift plus, Lift (hd p)), App (App \n(Lift mult, One), aux (tl p))) withtype int list -> <int :: []; int> in Lam (aux p) end withtype int \nlist -> <[]; int -> int> The withtype clause following the de.nition of the function aux is a type annotation \nindicating that aux expects to be assigned the type typecon (type, type) FOAS = { g, a}. ( g, a) FOASlift \nof a | { g, a}. ( a * g, a) FOASone | { g, a1, a2}. ( a1 * g, a2) FOASshi of ( g, a2) FOAS | { g, a1, \na2}. ( g, a1 -> a2) FOASlam of ( a1 * g, a2) FOAS | { g, a1, a2}. ( g, a2) FOASapp of ( g, a1 -> a2) \nFOAS * ( g, a1) FOAS | { g, a}. ( g, a) FOASfix of ( a * g, a) FOAS typecon (type) ENV = (unit) ENVnil \n| { g, a}. ( a * g) ENVcons of a * ( g) ENV (* fix x => e is the fixed point of fn x => e *) fun comp \n(FOASlift v) = (fn env => v) | comp (FOASone) = (fn (ENVcons (v, _)) => v) | comp (FOASshi e) = let \n val c = comp e in fn (ENVcons (_, env)) => c env end | comp (FOASlam e) = let val c = comp e in \nfn env => fn v => c (ENVcons (v, env)) end | comp (FOASapp (e1, e2)) = let val c1 = comp e1 val c2 \n= comp e2 in fn env => (c1 env) (c2 env) end | comp (FOASfix e) = let val c = comp e in fn env => fix \nv => c (ENVcons (v, env) end withtype { g, a}. ( g, a) FOAS -> ( g ENV -> a) fun run e = (comp e) (ENVnil) \nwithtype { a}. (unit, a) FOAS -> a Figure 5. Implementing code constructors and run (int)list .(int \n:: e,int), that is, aux takes an integer list and returns some code of type int in which the .rst and \nonly free variable has type int. Similarly, the withtype clause for genEvalPoly means that genEvalPoly \ntakes an integer list and returns some closed code of type int . int. Given the obvious meaning of null, \nhd and tl, it should be straight\u00adforward to relate the ML-like concrete syntax used in the above program \nto the syntax of (properly extended) .code. Evidently, this kind of programming style is at least unwieldy \nif not impractical. To some extent, this is just like writing meta-programs in Scheme without using the \nbackquote/comma notation. Therefore, we are naturally led to provide some syntactic support to facilitate \nmeta\u00adprogramming. 2.4 Embedding .code into .2,G\u00b5 Before presenting syntactic support for meta-programming, \nwe show a direct embedding of .code in .2,G\u00b5, where .2,G\u00b5 is an inter\u00adnal language that essentially extends \nthe second order polymorphic .-calculus with guarded recursive (g.r.) datatype constructors [35]. This \nsimple and interesting embedding, which the reader can skip without affecting the understanding of the \nrest of the paper, indi\u00adcates that the code constructors in .code can be readily interpreted through \ng.r. datatypes. In Figure 5, we use some concrete syntax of ML2,G\u00b5 to de\u00adclare a binary g.r. datatype \nconstructor (\u00b7,\u00b7)FOAS, where ML2,G\u00b5 [35] is an external language of .2,G\u00b5. The code construc\u00adtors Lift,One,Shi,App,Lam,Fix \nhave their counterparts FOASlift, FOAone, FOAshi, FOAapp, FOASlam, FOAS.x in . 2,G\u00b5. We use a type in \n.2,G\u00b5 for representing a type environment in .code; the unit type 1 represents the empty type environment \ne , and the type constructor *, which is for constructing product types, rep\u00adresents the type environment \nconstructor ::; the type constructor (\u00b7,\u00b7)FOAS represents (\u00b7,\u00b7). Formally, we de.ne a translation |\u00b7| \nas follows, which translates type environments and types in .code into types in .2,G\u00b5. |e | = 1 |t :: \nG| = |t |*|G||a. | = a. |t 1 . t 2| = |t 1|.|t 2||(G,t )| =(|G|,|t|)FOAS |.a. : . .t | = .a..|t | The \nfunction run is implemented in Figure 5. We use a withtype clause for introducing a type annotation. \nThe type annotation for run indicates that run is expected to be assigned the type .a .(1,a )FOAS . a \n, which corresponds to the type .a .(e ,a ). a in . code. However, it needs to be pointed out that this \nimplementa\u00adtion of run cannot support run-time code generation, for which we need a (primitive) function \nthat can perform compilation at run-time and then upload the code generated from the compilation. With \nthis embedding of .code in . 2,G\u00b5, we are able to construct pro\u00adgrams for performing analysis on typeful \ncode representation. For instance, the function comp de.ned in Figure 5 is such an example.  3 The \nLanguage .+ code We extend .code to . + with some meta-programming syntax code adopted from Scheme and \nMetaML. expressions e ::= ...| (e)| (e) Loosely speaking, the notation (\u00b7) corresponds to the backquote \nnotation in Scheme (or the notation (\u00b7) in MetaML), and we use (e) as the code representation for e. \nOn the other hand, (\u00b7)corresponds to the comma notation in Scheme (or the notation (\u00b7)in MetaML), and \nwe use (e)for splicing the code e into some context. We refer (\u00b7)and (\u00b7)as meta-programming syntax. The \nexpression variable context G is now de.ned as follows, exp. var. ctx. G ::= 0/ | G ,xf @k : t where \nxf @k stands for variables at level k = 0 and we use the name staged variable for xf @k. Intuitively, \nan expression e in the empty evaluation context is said to be at level 0; if an occurrence of e in e0 \nis at level k, then the occurrence of e in (e0)is at level k +1; if an occurrence of e in e0 is at level \nk +1, then the occurrence of e in (e0)is at level k; if an occurrence of lam x.e1 or .x f .e1 is at level \nk, then x or f is bound at level k. A declared staged variable xf @k in G simply indicates that xf is \nto be bound at level k. 3.1 Static Semantics For each natural number k, let posk be the set {1,...,k}, \nor formally {n | 0 <n = k}. We use G for .nite mappings from positive integers to type environments such \nthat the domains of G are always equal to posk for some k. In particular, we use 0/ for the mapping G \nsuch G that dom(G)=pos0. We write . fk G [ok]to mean that G Typing rules . ;G fke : t . fG G [ok] G \n(xf @0)=t k (ty-var-0) G . ; G fk xf : t G . fk+1 G [ok] G (xf @(k +1))=t (ty-var-1) G . ; G fk+1 xf \n: t G S (c)=.. 0.(t 1,...,t n). t. fk G [ok] G . f T : . 0 . ; G fk ei : t i[T ] for i =1,...,n (ty-cst) \nG . ; G fkc(e1,...,en): t [T ] . ;G ,x@k : t 1 fG ke : t 2 (ty-lam) G . ; G fk lam x.e : t 1 . t 2 G \nG . ;G fke1: t 1 . t 2 . ; G fke2: t 1 (ty-app) G . ; G fke1(e2): t 2 G . ;G , f @k : t fke : t (ty-.x) \n. ; G fG .x f .e : t k G+G . ;G fk+1 e : t (ty-encode) G . ; G f (e): (G(k +1;G ),t ) k G . ;G fe : \n(G(k +1;G ),t ) k (ty-decode) . ; G fG+G (e): t k+1 . ,a. : . ;G f00/v : t. f00/G [ok] (ty-iLam) . \n; G f00/. i(v): .a. : . .t . ;G f00/e : .a. : . .t. f t G : . (ty-eLam) . ; G f00/. e(e): t [a. . t \nG] Figure 6. The typing rules for . + code 1. . f G (xf ): type for each xf . dom(G ), and 2. dom(G)=posk, \nand 3. . f G(n): env for each n . dom(G).  In addition, we introduce the following de.nitions. Given \nG, k >0 and G , we de.ne G(k;G )as follows. G(k;0/ )= G ; G(k;G ,x@n : t )= t :: G(k;G ) if n =k; G(k;G \n,x@n : t )= G(k;G ) . if n =k. Given G, G and t , we de.ne G(0;G ;t )=t and G(k;G ;t )=G(k - 1;G ;(G(k;G \n),t )) for k . dom(G), where G =G(k). We write G(G ;t ) for G(k;G ;t )if dom(G)=posk. Given G and G such \nthat dom(G)=posk, we use G +G for the mapping G1 such that dom(G1)=posk+1, G1(n)=G(n) for each n . posk \nand G1(k +1)=G. We use .;G fe : t for a typing judgment in .+ G code, where we re\u00ad k G quire . fk G [ok]. \nIntuitively, G(k) stands for the initial type envi\u00adronment for code at level k. We present the typing \nrules for .+ code in Figure 6. Note that polymorphic code is only allowed to occur at level 0.  3.2 \nTranslation from .+ code into .code We introduce some notations needed in the following presentation. \nFor n = 0, we use .i (e) for .i(...(.i(e))...), where there are nn occurrences of .i, and we use .e (e) \nsimilarly. Also, we now nuse xfs for a sequence of staged variables, that is, xfs is of the form xf1@k1,...,xfn@kn. \nFor each k > 0, we de.ne vark(xfs;xf ) as follows under the assumption that xf @k occurs in xfs: for \nxfs =(xfs1,xf1@k1), vark(xfs;xf ) is .ek+1(Onek) if k1 = k and xf1 = xf ; .ek+2(Shik)(vark(xfs1;xf )) \nif k1 = k and xf1 =.xf ; vark(xfs1;xf ) if k1 =.k In Figure 7, we de.ne a translation transk(\u00b7;\u00b7) for \neach k = 0 that translates expressions in .+ We .rst de\u00ad code into those in .code. .ne some functions \nthat are needed in the de.nition of transk(\u00b7;\u00b7). These functions basically generalize the code constructors \nwe have. Given e, e1,...,en, we write Liftn(e) for Lift(...(Lift(e))...), where there are n occurrences \nof Lift; and Appn(e)(e1)...(en) for e if n = 0, or for App(Appn-1(e)...(en-1),en) if n > 0; and Appnk \n(e)(e1)...(en) for e if n = 0, or for .ek+2(Appk)(Appn-1(e)...(en-1))(en) k if n > 0. Given type environments \nG1,...,Gn and type t, we write (G1,...,Gn;t) for (G1,(...,(Gn,t)...)). With this notation, we have G(G;t)= \n(G1(1;G),...,Gk(k,G);t), where G = 0/ + G1 + ...+ Gk. A crucial property of transk(\u00b7;\u00b7) is captured by \nthe following lemma, which consists of the main technical contribution of the paper. LEMMA 3.1. Assume \nthat .;G fG e : t is derivable in .+ k code and G is of the form xf1@k1: t1,...,xfn@kn : tn. Then .;(G)0 \nf transk(xf1@k1,...,xfn@kn;e) : G(G;t) is derivable in .code, where (G)0 is de.ned as follows: (0/)0 \n= 0/ (G,x@0 : t)=(G)0,x : t (G,x@(k + 1) : t)0 =(G)0 PROOF. The proof follows from structural induction \non the typing G derivation of .;G fke : t. Given an expression e in .+ code, we write trans(e) for trans0(0/;e) \n(if it is well-de.ned) and call it the translation of e. THEOREM 3.2. Assume that 0/;0/ f00/e : t is \nderivable. Then 0/;0/ f trans(e) : t is derivable. PROOF. This immediately follows from Lemma 3.1. The \nprogrammer can now construct a meta-program in .+ code that may (and probably should) make use of meta-programming \nsyntax and then assign it the dynamic semantics of its translation in .code. In other words, we may just \ntreat meta-programming syntax as mere syntactic sugar. This is precisely the signi.cance of Theorem 3.2. \nWe conclude this section with an example to show how the type sys\u00adtem of .+ code can prevent free variable \nevaluation. Let us recall the example: <fn x => (run <x>)> in MetaML, whose evaluation leads to free \nvariable evaluation. In .+ code, the example corresponds to e = (lam x. (run( (x)))). Clearly, trans(e)= \ntrans0(0/;e)= Lam(run(One)). Note that the type of the expression One must equal (t :: G,t) for some \nG and t but run is only allowed to be ap\u00adplied to an expression whose type is (e,t) for some t. Therefore, \ntrans(e) is ill-typed. By Theorem 3.2, e is also ill-typed in .+ code and thus should be rejected.  \n3.3 Some Remarks We mention a few subtle issues so as to facilitate the understanding of .+ code. Bound \nVariables at Stage k >0At level k for some k >0, a bound variable merely represents a deBruijn index \nand a binding may van\u00adish or occur unexpectedly . For instance, let e be the expression (lam x. ( f x)) \nand e. = trans(e)= Lam( f (One)). Let f be the identity function. Then e. evaluates to Lam(One), which \nrepresents the code lam x.x.  Let f be the shift function lam x.Shi(x). Then e. evaluates to Lam(Shi(One)), \nwhich represents the code lam x.y for some free variable y that is distinct from x; there is no binding \nbe\u00ad tween Lam and One in e.  Let f be the lift function lam x.Lift(x). Then e. evaluates to Lam(Lift(One)) \nand run(e.) evaluates to lam x.One (not to lam x.Lift(x)); there is no expected binding between Lam and \nOne in e.. Let e0 be the expression run(run(e.)(1)). Then e0 is rejected as the expression run(e.)(1), \nwhich evaluates to  4 One, cannot be assigned a type of the form (e,t). Cross-Stage Persistence In meta-programming, \na situation often arises where a value de.ned at an early stage needs to be used at a later stage. For \ninstance, in the expression (lam x.x + x), the function +, which is de.ned at stage 0, is used at stage \n1. This is called cross-stage persistence (CSP) [32]. As is indicated in the typing rules (ty-var-0) \nand (ty-cst), CSP for variables at stage 0 and constants is implicit in .+ However, for variables in\u00ad \ncode. troduced at stage k > 0, CSP needs to be explicit. For instance, (lam x. (lam y.y(x))) is ill-typed \nin .+ code as the variable x is intro\u00adduced at stage 1 but used at stage 2. To make it typable, the pro\u00adgrammer \nneeds to insert % in front of x: (lam x. (lam y.y(%x))), where % is a shorthand for Lift, that is, %(e) \nrepresents (Lift(e)) for any expression e. Note that Lift can also be de.ned as %, that is, Lift(e) can \nbe treated as (%e) for any expression e. 4In . [21], e0 cannot be typed, either. However, e0 can be typed \nin the current implementation of MetaML [29] and MetaO-Caml [30]; in the former e0 evaluates to 1 (which \nwe suspect may be caused by an implementation error) but in the latter the evaluation of e0 raises a \nrun-time exception caused by free variable evaluation. Liftn Liftn Lamn Lam1 Lamn+1 Appn App1 Appn+1 \nFixn Fix1 Fixn+1 Onen One1 Onen+1 Shin Shi1 Shin+1 trans0(\u00b7;\u00b7) : = : = = : = = : = = : = = : = = trans0(xfs;xf \n)= trans0(xfs;c(e1,...,en)) = trans0(xfs;lam x.e)= trans0(xfs;e1(e2)) = trans0(xfs;.x f .e)= trans0(xfs;.i(e)) \n= trans0(xfs;.e(e)) = trans0(xfs; (e)) = trans1(\u00b7;\u00b7) transk(xfs;xf )= transk(xfs;xf )= trans1(xfs;c(e1,...,en)) \n= trans1(xfs;lam x.e)= trans1(xfs;e1(e2)) = trans1(xfs;.x f .e)= trans1(xfs; (e)) = trans1(xfs; (e)) \n= transk(\u00b7;\u00b7) for k > 1 transk(xfs;xf )= transk(xfs;xf )= transk(xfs;c(e1,...,en)) = transk(xfs;lam \nx.e)= transk(xfs;e1(e2)) = transk(xfs;.x f .e)= transk(xfs; (e)) = transk(xfs; (e)) = ..1 .....n..a.a \n.(.1,...,.n;a) .in+1(lam x.Liftn(x)) ..1 .....n..a1..a2.(.1,...,.n-1,a1 :: .n;a2).(.1,...,.n;a1 .a2) \n.i 3(lam x.Lam(x)) .in+3(lam x.App(Lift(.en+2(Lamn)),x)) ..1 .....n..a1..a2.(.1,...,.n;a1 .a2).(.1,...,.n;a1).(.1,...,.n;a2) \n.i 3(lam x1.lam x2.App(x1,x2)) .in+3(lam x1.lam x2.App(App(Lift(.en+2(Appn)),x1),x2)) ..1 .....n..a.(.1,...,.n-1,a \n:: .n;a).(.1,...,.n;a .a) .i 2(lam x.Fix(x)) .in+2(lam x.App(Lift(.en+1(Fixn)),x)) ..1 .....n..a.(.1,...,.n-1,a \n:: .n;a) .i 2(One) .in+2(Lift(.en+1(Onen))) ..1 .....n..a1..a2.(.1,...,.n;a2).(.1,...,.n-1,a1 :: .n;a2) \n.i 3(lam x.Shi(x)) .in+3(App(Lift(.en+2(Shin)),x)) xf if xf @0 occurs in xfs c(trans0(xfs;e1),...,trans0(xfs;en)) \nlam x.trans0(xfs,x@0;e) trans0(xfs;e1)(trans0(xfs;e1)) .x f .trans0(xfs, f @0;e) .i(trans0(xfs;e)) .e(trans0(xfs;e)) \ntrans1(xfs;e) Lift(xf ) if xf @0 occurs in xfs var1(xfs;xf ) if xf @1 occurs in xfs Appn(Lift(lam x1 \n...lam xn.c(x1,...,xn)))(trans1(xfs;e1))...(trans1(xfs;en)) Lam(trans1(xfs,x@1;e) App(trans1(xfs;e1),trans1(xfs;e2)) \nFix(trans1(xfs, f @1;e)) trans2(xfs;e) trans0(xfs;e) Liftk(xf ) if xf @0 occurs in xfs vark(xfs;xf ) \nif xf @k occurs in xfs Appnk (Liftk(lam x1 ...lam xn.c(x1,...,xn)))(transk(xfs;e1))...(transk(xfs;en)) \n.ek+2(Lamk)(transk(xfs,x@k;e) .ek+2(Appk)(transk(xfs;e1))(transk(xfs;e2)) .ek+1(Fixk)(transk(xfs, f @k;e) \ntransk+1(xfs;e) transk-1(xfs;e) Figure 7. The de.nition of transk(\u00b7;\u00b7) for k =0  4 Meta-Programming \nwith .+ code We now need an external language ML+ code for the programmer to construct meta-programs \nand then a process to translate such pro\u00adgrams into typing derivations in (properly extended) .+ code.We \npresent one possible design of ML+ code as follows, where b is for base types such as bool, int, etc. \ntypes t ::= b |a |t .t |(G,t) type env. G ::= . |e |t :: G type schemes s ::= t |.a.s expressions e ::= \nx | f |c(e1,...,en) |if(e1,e2,e3) | lam x.e |lam x : t.e |e1(e2) |.x f .e |.x f [a1,...,an] : t.e |let \nx = e1 in e2 end |(e : t) (e) | (e) The only unfamiliar syntax is .x f [a1,...,an] : t.e, which we use \nto support polymorphic recursion; this expression is expected to be assigned the type scheme s = .a1 \n....an.t. We have implemented a type inference algorithm based on the one in [4] that supports the usual \nlet-polymorphism. Like in Haskell [22], if the type of a recursive function is given, then poly\u00admorphic \nrecursion is allowed in the de.nition of the function. We are now ready to present some examples of meta-programs \nin ML+ code. Example 1 The previously de.ned function genEvalPoly can now be implemented as follows, \nwhich makes no explicit use of code constructors. fun genEvalPoly (p) = let fun aux p x = if null \n(p) then Lift (0) else (hd p + x * (aux (tl p) x)) withtype { g}. int list -> < g; int> -> < g; int> \nin (fn x => (aux p x)) end withtype { g}. int list -> < g; int -> int> Note that the type annotations, \nwhich can be automatically inferred, are presented solely for making the program easier to understand. \nExample 2 The following program implements the Ackermann function. fun ack m n = if m = 0 then n + 1 \n else ifn=0 then ack (m-1) 1 else ack (m-1) (ack m (n-1)) withtype int -> int -> int We can now de.ne \na function genAck as follows such that the func\u00adtion returns the code for computing ack(m) when applied \nto a given integer m. fun genAck m = if m = 0 then (fn n => n+1) else (fun f (n) => let val f = \n(genAck (m-1)) in if n = 0 then f 1 else f (f (n-1)) end) withtype { g}. int -> < g; int -> int> \nWe use the syntax (fun f (n) => ...) for (fix f => (fn n => ...)) , which translates into something of \nthe form Fix(Lam(...)). This shows an interesting use of recursion at level 1. Also, we point out that \npolymorphic recursion is required in this example.5 Example 3 We contrast an unstaged implementation \nof inner product (innerProd) with a staged implementation of inner prod\u00aduct (genInnerProd) in Figure \n8. Given a natural number n, genInnerProd(n) returns the code for some function f1; given an integer \nvector v1 of length n, f1 returns the code for some func\u00adtion f2; given an integer vector v2 of length \nn, f2 returns the inner product of v1 and v2. For instance, if n = 2, then f1 is basically equivalent \nto the function de.ned below; fn v1 => (fn v2 => 0 + (Lift (sub (v1, 0))) * sub (v2, 0) + (Lift (sub \n(v1, 1))) * sub (v2, 1)) if v1[0]= 6 and v1[1]= 23, then f2 is basically equivalent to the function \nde.ned below. fn v2 =>0+6 *sub (v2, 0) + 23 * sub (v2, 1) Notice that this example involves expressions \nat level 2 and the use of a CSP operator %.  5 Extensions It is straightforward to extend .code (and \nsubsequently .+ code) to sup\u00ad port additional language features such as conditionals, pairs, refer\u00adences, \netc. For instance, in order to support conditional expressions of the form if(e1,e2,e3), we introduce \na code constructor If and assign it the following type; ...a.(.,bool ).(.,a).(.,a).(.,a) we then de.ne \nIfn as we have done for the previous code construc\u00adtors in Figure 7, and extend the de.nition of transk(\u00b7;\u00b7) \nproperly for k =0. It is even easier to extend .code with pairs and references. For in\u00adstance, in order \nto support references, all we need to assume is a type constructor (\u00b7)ref and the following functions \nof the given types, where 1 stands for the unit type. ref : .a.a .(a)ref deref : .a.(a)ref .a update \n: .a.(a)ref .a .1 It is standard to assign dynamic semantics to ref, deref and update, and we omit the \ndetails. As an example, the following expression (lam x.lam y.update(y)(deref(x))) is translated into \nLam(Lam(App(App(Lift(update),One), App(Lift(deref),Shi(One))))) In [1], it is argued that a program corresponding \nto the following one would cause the problem of free variable evaluation to occur in MetaML [33] as r \nstores some open code when it is dereferenced. let val r = ref 1 val f = (fn x => (r := (x+1); 2) in \nrun (!r) end 5To avoid polymorphic recursion, we need to change genAck(m-1) into Shi(Shi(genAck(m-1))) \nin the implementa\u00adtion. fun innerProd n = (* unstaged implementation of inner product *) let fun aux \ni v1 v2 sum = if i < n then aux (i+1) v1 v2 (sum + sub (v1, i) * sub (v2, i)) else sum withtype int -> \nint -> int array -> int array -> int in fn v1 => fn v2 => aux 0 v1 v2 0 end withtype int -> int array \n-> int array -> int fun genInnerProd n = (* staged implementation of inner product *) let fun aux i \nv1 v2 sum = if i < n then aux (i+1) v1 v2 ( sum + %(sub ( v1, i)) * sub ( v2, i)) else sum withtype \n{ g1, g2}. int -> < g1; int array> -> < g1, g2; int array> -> < g1, g2; int> -> < g1, g2; int> in (fn \nv1 => (fn v2 => (aux i v1 v2 0))) end withtype { g1, g2}. int -> < g1; int array -> < g2; int array \n-> int> > Figure 8. A meta-programming example: inner product This, however, cannot occur in .+ code \nas the above program is ill\u00adtyped: if r is assigned the type ((e,int))ref, then it cannot be used to \nstore open code; if r is assigned a type ((G,int))ref for some nonempty G, then the code stored in it \ncannot be run. With value restriction, it is also straightforward to support let\u00adpolymorphism in code: \nwe can simply treat let x = v in e end as syntactic sugar for e[x .v]. What seems dif.cult is to treat \npattern matching in code. One ap\u00adproach is to translate general pattern matching into the following form \nof .xed pattern matching for sum types, case e0 of inl(x1) .e1 |inr(x2) .e2 and then introduce three \ncode constructors Inl, Inr and CaseOf of the following types, ...a1.a2.(.,a1).(.,a1 + a2) ...a1.a2.(.,a2).(.,a1 \n+ a2) ...a1.a2.a3. (.,a1 + a2).(a1 :: .,a3).(a2 :: .,a3).(.,a3) respectively. The rest becomes straightforward \nand we omit the details. An alternative is to introduce a CaseOf code constructor for every declared \ndatatype, and a code constructor for each value constructor associated with the datatype. This approach \nis more .exible than the previous one in practice but still has dif.culty supporting nested patterns. \nWe plan to introduce .rst-class patterns to better address the issue in the future.  6 Related Work \nand Conclusion Meta-programming, which can offer a uniform and high-level view of the techniques for \nprogram generation, partial evaluation and run-time code generation, has been studied extensively in \nthe lit\u00aderature. An early reference to partial evaluation can be found in [13], where the three Futamura \nprojections are presented for generating compil\u00aders from interpreters. The notion of generating extensions, \nwhich is now often called staged computation, is introduced in [12] and later expanded into multi-level \nstaged computation [15, 14]. Most of the work along this line attempts to stage programs automati\u00adcally \n(e.g., by performing binding-time analysis) and is done in an untyped setting. In [7], a lambda-calculus \n. based on the intuitionistic modal logic S4 is presented for studying staged computation in a typed \nset\u00adting. Given a type A, a type constructor , which corresponds to a modality operator in the logic \nS4, can be applied to A to form a type A for (closed) code of type A. With this feature, it becomes \npos\u00adsible to verify whether a program with explicit staging annotations is indeed staged correctly. However, \nonly closed code is allowed to be constructed in . , and this can be a rigid restriction in practice. \nFor instance, the usual power function, which is de.ned below, fun power n x = (* it returns the nth \npower of x *) if n = 0 then 1 else x * power (n-1) x can be staged in .+ code as follows in two different \nmanners. fun power1 n = if n = 0 then (fn x => 1) else (fn x => x * (power1 (n-1)) x) fun power2 n \n= let fun auxix= if i = 0 then 1 else ( x * (aux (i-1) x)) in (fn x => (aux n x)) end However, the second \nversion (power2) does not have a counterpart in . as it involves the use of open code: there is a free \nvariable in the code produced by (aux n x). An approach to addressing the limitation is given in [6], \nwhere a type constructor Ois introduced, which corresponds to the modal\u00adity in discrete temporal logic \nfor propositions that are true at the subsequent time moment. Given a type A, the type OA is for code, \nwhich may contain free variables, of type A.6 This approach is es\u00ad 6Note that the function run is not \npresent in .O for otherwise the problem of free variable evaluation would occur. sentially used in the \ndevelopment of MetaML [33], an extension of ML that supports typed meta-programming by allowing the pro\u00adgrammer \nto manually stage programs with explicit staging annota\u00adtions. On one hand, when compared to untyped \nmeta-programming in Scheme, the type system of MetaML offers an effective approach to capturing (pervasive) \nstaging errors that occur during the con\u00adstruction of meta-programs. On the other hand, when compared \nto partial evaluation that performs automatic staging (e.g., in Similix), the explicit staging annotations \nin MetaML offer the programmer more .exibility and expressiveness. However, as was .rst pointed out by \nRowan Davies, the original type system of MetaML contained a defect caused by free variable evaluation \n(as the function run is available in MetaML) and there have since been a number of attempts to .x the \ndefect. For instance, in [20], types for (potentially) open code are re.ned and it then becomes possible \nto form types for closed code only. In general, a value can be assigned a type for closed code only if \nthe value does not depend on any free program variables. This approach is further extended [1] to handle \nreferences. Though sound, this approach also rules out code that is safe to run but does contain free \nprogram variables. We now use an example to illustrate this point. Let e1 be the following expressions \nin .+ code, lam f . (lam x. (run( f ( x)))) and e2 = trans(e1)= lam f .Lam(run( f (One))). Clearly, e2 \ncan be assigned a type of the following form:7 ((t1 :: G1,t1).(e,(t2 :: G2,t3))) .(G2,t2 . t3) However, \ne2 cannot be assigned a type in [20] or [1] as the type systems there cannot assign f ( x) a closed code \ntype. Though this is a highly contrived example, it nonetheless indicates some inadequacy in the notion \nof closed types captured by these type systems. In [31], there is another type system that aims at assigning \nmore accurate types to meta-programs in MetaML. In the type system, a notion of environment classi.ers \nis introduced. Generally speak\u00ading, environment classi.ers are used to explicitly name the stages of \ncomputation, and code is considered to be closed with respect to an environment classi.er a if a can \nbe abstracted. This approach is similar (at least in spirit) to the typing of runST in Haskell [16]. \nTo some extent, an environment classi.er resembles a type envi\u00ad ronment variable . in .+ code and the \ntype (a)(t)a for code of type t that is closed with respect to an environment a relates to the type ...(.,t) \nin .+ code. Another approach to addressing the limitation of . is presented in [21]. Instead of re.ning \nthe notion of (potentially open) code in .O, the calculus . in [21] relaxes the notion of closed code \nin . by extending . with a notion of names that is inspired by some developments in Nominal Logic [27] \nand FreshML [28]. Given an expression representing some code, the free variables in the code are represented \nas certain distinct names; the set of these names, which is called the support of the expression, is \nre.ected in the type of the expression. The code represented by an expression can be executed only if \nthe support of the expression is empty. Clearly, the notion of a support in . corresponds to the notion \nof a type en\u00advironment in .code. The primary difference between . and .code as we see is that the development \nof the former is guided, implicitly or explicitly, by the notion of higher-order abstract syntax while \nthe latter is based on a form of .rst-order abstract syntax. 7For example, this means e2 can be applied \nto the function lam x.Lift(x) (and the application evaluates to Lam(One)) but not to the function lam \nx.x. There were certainly earlier attempts in forming typeful code rep\u00adresentation. For instance, in \na dependent type system such as LF, it is fairly straightforward to form a type exp(t) in the meta-language \nfor representing closed expressions of type t in the object language. Unfortunately, such typeful code \nrepresentation seems unsuitable for meta-programming as the strict distinction between the meta\u00adlanguage \nand the object language makes it impossible for expres\u00adsions in the meta-language to be handled in the \nobject language. In particular, note that the code constructor Lift is no longer de.nable with this approach. \nAn early approach to typeful code representa\u00adtion can be found in [25], where an inductively de.ned datatype \nis formed to support typeful representation for terms in the second\u00adorder polymorphic .-calculus. This \nrepresentation is higher-order and supports both re.ection (i.e., to map the representation of an expression \nto the expression itself) and rei.cation (i.e., to map an expression to the representation of the expression). \nHowever, it handles rei.cation for complex values such as functions in a man\u00adner that seems too limited \nto support (practical) meta-programming. In [5], an approach is presented that implements (a form of) \ntype\u00adful h.o.a.s. in Haskell-like languages to represent simply typed .\u00adterms. With this approach, it \nis shown that an implementation of the normalizing function for simply typed .-terms preserves types. \nHowever, the limitation of the approach is also severe: It does not support functions that take typeful \nh.o.a.s. as input (e.g., a function like run in .code). In this paper, we present a novel approach to \ntyped meta\u00adprogramming that makes use of a form of .rst-order typeful code representation in which program \nvariables are replaced with de-Bruijn indices. We form a language .code in which expressions representing \ncode can be constructed through code constructors and then executed through a special function run. Although \n.code suf\u00ad.ces to establish a theoretical foundation for meta-programming, it lacks proper syntax to \nsupport practical meta-programming. We address the issue by extending .code into .+ code with some meta\u00adprogramming \nsyntax adopted from Scheme and MetaML; we .rst form rules to directly type programs in .+ code and then \nde.ne a trans\u00adlation from .+ code into .code for assigning dynamic semantics to .+ We also present examples \nin support of meta-programming code. with .+ code. Furthermore, we feel that the concrete code representation \nin .code can be of great use in facilitating the understanding of meta-programming. For instance, the \nconsiderably subtle differ\u00adence between (%(e)) and ((%e)) [31] can be readily explained in .code; the \nformer and the latter are translated into Lift(e.) and App(Lift(lift),e.), respectively, where e. is \nthe translation trans(e) of e and lift is lam x.Lift(x); run(Lift(e.)) reduces to eand run(App(Lift(lift),e.)) \nreduces to Lift(v.), where v. is the value of run(e.) (assuming e. represents closed code); so the difference \nbe\u00ad tween (%(e)) and ((%e)) is clear: the former means e is not exe\u00adcuted until the second stage while \nthe latter, which requires e to be closed, indicates that e is executed at the .rst stage and its value \nis lifted into the second stage. We also show that .code can be embedded into .2,G\u00b5 in a straightfor\u00adward \nmanner, establishing an intimate link between code construc\u00adtors and guarded recursive datatypes. This \nembedding immediately gives rise to the possibility of constructing programs that perform analysis on \ncode. In future, we are interested in a more .exible approach to handling pattern matching in code. For \nthis purpose, we seem to be in need of .rst-class patterns. Also, we plan to study how names, instead \nof deBruijn indices, can be used to form .rst-order typeful code representation, and we believe this \nis an important step towards im\u00adplementing transformations for typed programs in a type-correct manner. \n 7 Acknowledgment We thank Walid Taha for his valuable comments on a previous ver\u00adsion of the paper and \nJoseph Hallett for his efforts on proofreading the paper. Also, we thank some anonymous referees, whose \ncom\u00adments helped us raise the quality of the paper signi.cantly. 8 References [1] C. Calcagno, E. Moggi, \nand T. Sheard. Closed Types for a Safe Imper\u00adative MetaML. Journal of Functional Programmng, 2003. (to \nappear). [2] C. Chambers and D. Ungar. Customization: Optimizing Compiler Technology for SELF. In Proceedings \nof 16th ACM SIGPLAN Confer\u00adence on Programming Language Design and Implementation (PLDI 89), pages 146 \n160, 1989. [3] A. Church. A formulation of the simple type theory of types. Journal of Symbolic Logic, \n5:56 68, 1940. [4] L. Damas and R. Milner. Principal type-schemes for functional pro\u00adgrams. In Conference \nRecord of the Ninth Annual ACM Symposium on Principles of Programming Languages, pages 207 212, Albuquerque, \nNew Mexico, 1982. [5] O. Danvy and M. Rhiger. A Simple Take on Typed Abstract Syntax in Haskell-like \nLanguages. In Proceedings of the 5th International Sym\u00adposium on Functional and Logic Programming (FLOPS \n01), pages 343 358, Tokyo, Japan, March 2001. [6] R. Davies. A temporal logic approach to binding-time \nanalysis. In Symposium on Logic in Computer Science (LICS 96), pages 184 195, 1996. [7] R. Davies and \nF. Pfenning. A Modal Analysis of Staged Computation. Journal of ACM, 48(3):555 604, 2001. [8] N. G. de \nBruijn. Lambda calculus notation with nameless dummies. Indagationes mathematicae, 34:381 392, 1972. \n[9] L. P. Deutsch and A. M. Schiffman. Ef.cient Implementation of Smalltalk-80 System. In Proceedings \nof 11th ACM SIGPLAN Sympo\u00adsium on Principles of Programming Languages, pages 297 302, Salt Lake City, \nUtah, 1984. [10] S. Draves. Partial evaluation for media processing. ACM Computing Surveys (CSUR), 30(3es):21, \n1998. [11] R. Kent Dybvig. Writing hygienic macros in Scheme with syntax\u00adcase. Technical Report #356, \nComputer Science Department, Indiana University, 1992. [12] A. Ershov. On the partial computation principle. \nInformation Process\u00ading Letters, 6(2):38 41, 1977. [13] Y. Futamara. Partial evaluation of computation \nprocess. Systems, com\u00adputers, controls, 2(5):45 50, 1971. [14] R. Gl\u00a8uck and J. J\u00f8rgensen. An automatic \nprogram generator for multi\u00adlevel specialization. Lisp and Symbolic Computation, 10(2):113 158, 1997. \n[15] N. D. Jones, P. Sestoft, and H. S\u00f8ndergaard. An expriment in partial evaluation: the generation \nof a compiler generator. In Rewriting Tech\u00adniques and Applications, pages 124 140. Springer-Verlag LNCS \n202, 1985. [16] J. Launchbury and S. Peyton-Jones. State in Haskell. Lisp and Sym\u00adbolic Computation, \npages 293 342, 1995. [17] M. Leone and P. Lee. Optimizing ml with run-time code generation. In ACM SIGPLAN \n96 Conference on Programming Language Design and Implementation, pages 137 148, Philadelphia, PA, June \n1996. ACM Press. [18] H. Massalin. An Ef.cient Implementation of Fundamental Operating System Services. \nPh. D. dissertation, Columbia University, 1992. [19] R. Milner, M. Tofte, R. W. Harper, and D. MacQueen. \nThe De.nition of Standard ML (Revised). MIT Press, Cambridge, Massachusetts, 1997. [20] E. Moggi, W. \nTaha, Z.-E.-A. Benaissa, and T. Sheard. An Idealized MetaML: Simpler, and More Expressiove. In European \nSymposium on Programming (ESOP 99), pages 193 207. Springer-Verlag LNCS 1576, 1999. [21] A. Nanevski \nand F. Pfenning. Meta-Programming with Names and Necessity. A previous version appeared in the Proceedings \nof the International Conference on Functional Programming (ICFP 2002), pp. 206 217. [22] S. Peyton Jones \net al. Haskell 98 A non-strict, purely functional language. Available at http://www.haskell.org/onlinereport/, \nFeb. 1999. [23] F. Pfenning. Computation and Deduction. Cambridge University Press. (to appear). [24] \nF. Pfenning and C. Elliott. Higher-order abstract syntax. In Proceed\u00adings of the ACM SIGPLAN 88 Symposium \non Language Design and Implementation, pages 199 208, Atlanta, Georgia, June 1988. [25] F. Pfenning and \nP. Lee. A Language with Eval and Polymorphism. In International Joint Conference on Theory and Practice \nin Soft\u00adware Development, pages 345 359, Barcelona, Spain, March 1989. Springer-Verlag LNCS 352. [26] \nR. Pike, B. Locanthi, and J. Reiser. Hardware/Software Trade-offs for Bitmap Graphics on the Blit. Software \n Practice and Experience, 15(2):131 151, February 1985. [27] A. M. Pitts. Nominal logic, a .rst order \ntheory of names and bind\u00ading. Information and Computation. To appear. (A preliminary version appeared \nin the Proceedings of the 4th International Symposium on Theoretical Aspects of Computer Software (TACS \n2001), LNCS 2215, Springer-Verlag, 2001, pp 219 242.). [28] A. M. Pitts and M. J. Gabbay. A metalanguage \nfor programming with bound names modulo renaming. In R. Backhouse and J. N. Oliveira, editors, Mathematics \nof Program Construction. 5th International Con\u00adference, MPC2000, Ponte de Lima, Portugal, July 2000. \nProceedings, volume 1837 of Lecture Notes in Computer Science, pages 230 255. Springer-Verlag, Heidelberg, \n2000. [29] T. Sheard, W. Taha, Z. Benaissa, and E. Pasalic. MetaML. Available at http://www.cse.ogi.edu/PacSoft/projects/metaml/. \n[30] W. Taha, C. Calcagno, L. Huang, and X. Leroy. MetaOCaml. Avail\u00adable at http://www.cs.rice.edu/ taha/MetaOCaml/. \n[31] W. Taha and M. F. Nielsen. Environment classi.ers. In Proceedings of the 30th ACM SIGPLAN Symposium \non Principles of Programming Languages, pages 26 37, New Orleans, January 2003. [32] W. Taha and T. Sheard. \nMulti-Stage Programming with Explicit An\u00adnotations. In Proceedings of the Symposium on Partial Evaluation \nand Semantic-Based Program Manipulation (PEPM), pages 203 217, Amsterdam, 1997. [33] W. Taha and T. Sheard. \nMetaML and multi-stage programming with explicit annotations. Theoretical Computer Science, 248(1-2):211 \n242, 2000. [34] A. Wright. Simple imperative polymorphism. Journal of Lisp and Symbolic Computation, \n8(4):343 355, 1995. [35] H. Xi, C. Chen, and G. Chen. Guarded recursive datatype constructors. In Proceedings \nof the 30th ACM SIGPLAN Symposium on Principles of Programming Languages, pages 224 235, New Orleans, \nJanuary 2003.  \n\t\t\t", "proc_id": "944705", "abstract": "By allowing the programmer to write code that can generate code at run-time, meta-programming offers a powerful approach to program construction. For instance, meta-programming can often be employed to enhance program efficiency and facilitate the construction of generic programs. However, meta-programming, especially in an untyped setting, is notoriously error-prone. In this paper, we aim at making meta-programming less error-prone by providing a type system to facilitate the construction of correct meta-programs. We first introduce some code constructors for constructing typeful code representation in which program variables are replaced with deBruijn indices, and then formally demonstrate how such typeful code representation can be used to support meta-programming. The main contribution of the paper lies in recognition and then formalization of a novel approach to typed meta-programming that is practical, general and flexible.", "authors": [{"name": "Chiyan Chen", "author_profile_id": "81100119914", "affiliation": "Boston University", "person_id": "P414181", "email_address": "", "orcid_id": ""}, {"name": "Hongwei Xi", "author_profile_id": "81100625632", "affiliation": "Boston University", "person_id": "PP39051360", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/944705.944730", "year": "2003", "article_id": "944730", "conference": "ICFP", "title": "Meta-programming through typeful code representation", "url": "http://dl.acm.org/citation.cfm?id=944730"}