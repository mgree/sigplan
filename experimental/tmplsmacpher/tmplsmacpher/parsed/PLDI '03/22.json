{"article_publication_date": "05-09-2003", "fulltext": "\n Optimizing Indirect Branch Prediction Accuracy in Virtual Machine Interpreters * M. Anton Ertl David \nGregg TU Wien Trinity College, Dublin ABSTRACT Interpreters designed for e.ciency execute a huge number \nof indirect branches and can spend more than half of the execution time in indirect branch mispredictions. \nBranch target bu.ers are the best widely available form of indirect branch prediction; however, their \nprediction accuracy for ex\u00adisting interpreters is only 2% 50%. In this paper we investi\u00adgate two methods \nfor improving the prediction accuracy of BTBs for interpreters: replicating virtual machine (VM) in\u00adstructions \nand combining sequences of VM instructions into superinstructions. We investigate static (interpreter \nbuild\u00adtime) and dynamic (interpreter run-time) variants of these techniques and compare them and several \ncombinations of these techniques. These techniques can eliminate nearly all of the dispatch branch mispredictions, \nand have other ben\u00ade.ts, resulting in speedups by a factor of up to 3.17 over e.cient threaded-code interpreters, \nand speedups by a fac\u00adtor of up to 1.3 over techniques relying on superinstructions alone. Categories \nand Subject Descriptors D.3 [Software]: Programming Languages; D.3.4 [Programming Languages]: Processors \nInterpreters General Terms Languages, Performance, Experimentation  Keywords Interpreter, branch target \nbu.er, branch prediction, code replication, superinstruction * Correspondence Address: Institut f\u00a8ur \nComputersprachen, Technische Universit\u00a8at Wien, Argentinierstra\u00dfe 8, A-1040 Wien, Austria; anton@mips.complang.tuwien.ac.at \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n03, June 9 11, 2003, San Diego, California, USA. Copyright 2003 ACM 1-58113-662-5/03/0006 ...$5.00. \n1. INTRODUCTION Di.erent programming language implementation ap\u00adproaches provide di.erent tradeo.s with \nrespect to the fol\u00adlowing criteria: Ease of implementation  Portability (Retargetability)  Compilation \nSpeed  Execution Speed  Interpreters are a popular language implementation ap\u00adproach that can be very \ngood at the .rst three criteria, but has an execution speed disadvantage: an interpreter de\u00adsigned for \ne.ciency typically su.ers a factor of ten slowdown for general-purpose programs over native code produced \nby an optimizing compiler [10].1 In this paper we investigate how to improve the execution speed of interpreters. \nExisting e.cient interpreters perform a large number of indirect branches (up to 13%of the executed instructions). \nMispredicted branches are expensive on modern processors (e.g., they cost about 10 cycles on the Pentium \nIII and Athlon and 20 cycles on the Pentium 4). As a result, in\u00adterpreters can spend more than half of \ntheir execution time recovering from indirect branch mispredictions [7]. Conse\u00adquently, improving the \nindirect branch prediction accuracy has a large e.ect on interpreter performance. The best indirect branch \npredictor in widely available processors is the branch target bu.er (BTB). Most current desktop and server \nprocessors have a BTB or similar struc\u00adture: all Pentiums, Athlon, Alpha 21264, Itanium 2. BTBs mispredict \n50% 63% of the executed indirect branches in threaded-code interpreters and 81% 98% in switch-based in\u00adterpreters \n[7]. In this paper, we look at software ways to improve the prediction accuracy. The main contributions \nof this paper are: We propose the new technique of replication (Sec\u00adtion 4.1) for eliminating mispredictions. \n 1For library-intensive special-purpose programs the speed di.erence is usually much smaller. Not all \ninterpreters are designed for e.ciency on general-purpose programs and some may produce slowdowns by \na factor > 1000 [15]. Un\u00adfortunately, many people draw incorrect general conclusions about the performance \nof interpreters from such examples. typedef enum { add /* ... */ } Inst; void engine() { static Inst \nprogram[] = { add /* ... */ }; Inst *ip = program; int *sp; for (;;) switch (*ip++) { case add: sp[1]=sp[0]+sp[1]; \nsp++; break; /* ... */ } } Figure 1: VM instruction dispatch using switch We evaluate this technique, \nas well as existing superin\u00adstruction techniques, and the combination of these techniques with respect \nto prediction accuracy and performance (Section 7).  We introduce several enhancements of dynamic su\u00adperinstructions \n(in addition to replication), in particu\u00adlar: extending them across basic blocks; and a portable way \nto detect non-relocatable code fragments (Sec\u00adtion 5.2).  We empirically compare the static [8] and \ndynamic [13] superinstruction techniques against each other (Sec\u00adtion 7).   2. BACKGROUND 2.1 Ef.cient \nInterpreters This section discusses how e.cient interpreters are im\u00adplemented. We do not have a precise \nde.nition for e.\u00adcient interpreter, but the fuzzy concept designed for good general-purpose performance \nshows a direct path to spe\u00adci.c implementation techniques. If we want good general-purpose performance, \nwe can\u00adnot assume that the interpreted program will spend large amounts of time in native-code libraries. \nInstead, we have to prepare for the worst case: interpreting a program perform\u00ading large numbers of simple \noperations; on such programs interpreters are slowest relative to native code, because these programs \nrequire the most interpreter overhead per amount of useful work. To avoid the overhead of parsing the \nsource program re\u00adpeatedly, e.cient interpretive systems are divided into a front-end that compiles the \nprogram into an intermediate representation, and an interpreter for that intermediate rep\u00adresentation; \nthis design also helps modularity. This paper deals with the e.ciency of the interpreter; the e.ciency \nof the front-end can be improved with the established methods for speeding up compiler front-ends. To \nminimize the overhead of interpreting the intermedi\u00adate representation, e.cient interpretive systems \nuse a .at, sequential layout of the operations (in contrast to, e.g., tree-based intermediate representations), \nsimilar to machine code; such intermediate representations are therefore called virtual machine (VM) \ncodes.2 E.cient interpreters usually use a VM interpreter (but not all VM interpreters are e.\u00adcient). \n The interpretation of a VM instruction consists of access\u00ading arguments of the instruction, performing \nthe function of the instruction, and dispatching (fetching, decoding and starting) the next instruction. \nDispatch is common to all VM interpreters and can consume most of the run-time of an interpreter, so \nthis paper focuses on dispatch. Dispatching the next VM instruction requires executing one indirect branch \nto get to the native code that imple\u00adments the next VM instruction. In e.cient interpreters the machine \ncode for simple VM instructions can take as few as 3 native instructions (including the indirect jump), \nresulting in a high proportion of indirect branches in the executed in\u00adstruction mix (we have measured \nup to 13%for the Gforth interpreter and 11%for the Ocaml interpreter [7]). There are two popular VM instruction \ndispatch tech\u00adniques: Switch dispatch uses a large switch statement, with one case for each instruction \nin the virtual machine in\u00adstructionset. Switchdispatchcan be implementedin ANSI C (see Fig. 1), but is \nnot very e.cient [7] (see also Section 3). Threaded code represents a VM instruction as address of the \nroutine that implements the instruction [1]. In threaded code the code for dispatching the next instruction \nconsists of fetching the VM instruction, jumping to the fetched address, and incrementing the instruction \npointer. This technique cannot be imple\u00admented in ANSI C, but it can be implemented in GNU C using the \nlabels-as-values extension. Figure 2 shows threaded code and the instruction dispatch sequence. Threaded \ncode dispatch executes fewer instructions, and provides better branch prediction (see Section 3). Several \ninterpreters use threaded code when compiling with GCC, and fall back to switch dispatch, if GCC is not \navailable (e.g., the Ocaml interpreter, YAP, Sicstus Prolog). 2.2 Branch Target Buffers CPU pipelines \nhave become longer over time, in order to support faster clock rates and out-of-order superscalar execution. \nSuch CPUs execute straight-line code very fast; however, they have a problem with branches, because they \nare typically resolved very late in the pipeline (stage n), but they a.ect the start of the pipeline. \nTherefore, the following instructions have to proceed through the pipeline for n cycles before they are \nat the same stage they would be if there was no branch. We can say that the branch takes n cycles to \nexecute (in a simpli.ed execution model). To reduce the frequency of this problem, modern CPUs use branch \nprediction and speculative execution; if they pre\u00addict the branch correctly, the branch takes little \nor no time to execute. The n cycles delay for incorrectly predicted 2The term virtual machine is used \nin a number of slightly di.erent ways by various people; we use the meaning in the .rst item of http://foldoc.doc.ic.ac.uk/foldoc/foldoc.cgi?virtual+machine. \nVM Code VM instruction routines Machine code for imul Dispatch next instruction Machine code for iadd \nDispatch next instruction GNU C Alpha assembly next_inst = *ip; ldq s2,0(s1) ;load next VM instruction \nip++; addq s1,0x8,s1 ;increment VM instruction pointer goto *next_inst; jmp (s2) ;jump to next VM instruction \n Figure 2: Threaded code: VM code representation and instruction dispatch address of branch instruction \n Figure 3: Branch Target Bu.er (BTB) branches is called the misprediction penalty. The mispredic\u00adtion \npenalty is about 10 cycles on the Pentium III, Athlon, and 21264, and about 20 cycles on the Pentium \n4. The best predictor for indirect branches in widely avail\u00adable CPUs is the branch target bu.er (BTB). \nAn idealised BTB contains one entry for each branch and predicts that the branch jumps to the same target \nas the last time it was executed (see Fig. 3). The size of real BTBs is limited, re\u00adsulting in capacity \nand con.ict misses. Most current CPUs have a BTB-style predictor, e.g. all Pentiums, Athlon, Al\u00adpha 21264, \nItanium 2. Better indirect branch predictors have been proposed [4, 5, 11], and they would improve the \nprediction accuracy in interpreters substantially [7]. However, they have not been implemented yet in \nwidely available hardware, and it is not clear, if and when they will be available. The software tech\u00adniques \nexplored in this paper improve the prediction accu\u00adracy now, by a similar amount.  3. INTERPRETERS \nAND BTBS Ertl and Gregg investigated the performance of several virtual machine interpreters on several \nbranch predictors [7] and found that BTBs mispredict 81% 98% of the indirect branches in switch-dispatch \ninterpreters, and 57% 63% of the indirect branches in threaded-code interpreters (a vari\u00adation, the so-called \nBTB with two-bit counters, produces slightly better results for threaded code: 50% 61% mispre\u00addictions). \nWhat is the reason for the di.erences in prediction ac\u00adcuracy between the two dispatch methods? The decisive \ndi.erence between the dispatch methods is this: A copy of the threaded code dispatch sequence is usually \nappended to thenativecodefor each VM instruction; as a result, each VM instruction has its own indirect \nbranch. In contrast, with switch dispatch all compilers we have tested produce a single indirect branch \n(among other code) for the switch, and they compile the breaks into unconditional branches to this common \ndispatch code. In e.ect, the single indirect branch is shared by all VM instructions. Why do these mispredictions \noccur? Consider the VM code fragment in Fig. 4, and imagine that the loop has been executed at least \nonce. With switch dispatch, there is only one indirect branch, the switch branch, and consequently there \nis only one BTB entry involved. When jumping to the native code for VM instruction A, the BTB entry is \nupdated to point to that native code routine. When the next VM instruction is dis\u00adpatched, the BTB will \ntherefore predict target A; in our example the next instruction is B, so the BTB mispredicts. The BTB \nnow updates the entry for the switch instructions to point to B, etc. So, with switch dispatch the BTB \nalways predicts that the current instruction will also be the next one to be executed, which is rarely \ncorrect. For threaded code, each VM instruction has its own in\u00addirect branch and BTB entry (assuming \nthere are no con\u00ad.ict or capacity misses in the BTB); e.g., instruction A has Branch br-A and BTB entry \nbr-A, etc. So, when VM in\u00adstruction B dispatches the next instruction, the same target will be selected \nas on the last execution of B; since B oc\u00adcurs only once in the loop, the BTB will always predict the \nsame target: A. Similarly, the branch of the GOTO instruc\u00adtion will also be predicted correctly (branch \nto A). However, A occurs twice in our code fragment, and the BTB always uses the last target for the \nprediction (alternatingly B and GOTO), so the BTB will never predict A s dispatch branch correctly. We \nwill concentrate on interpreters using separate dis\u00adpatch branches in the rest of the paper. 4. IMPROVING \nTHE PREDICTION ACCU-RACY Generally, as long as a VM instruction occurs only once in the working set of \nthe interpreted program, the BTB will predict its dispatch branch correctly, because the instruction \nfollowing the VM instruction is the same on all executions. But if a VM instruction occurs several times, \nmispredictions are likely. 4.1 Replicating VM Instructions In order to avoid having the same VM instruction \nseveral times in the working set, we can create several replicas of the same instruction. We copy the \ncode for the VM instruction, and use di.erent copies in di.erent places. If a replica occurs only once \nin the working set, its branch will predict the next instruction correctly. Figure 5 shows how replication \nworks in our example. switch dispatch threaded code VM BTB next instruction BTB next instruction program \nentry prediction actual entry prediction actual label: A switch A B br-A GOTO B B switch B A br-B A A \nA switch A GOTO br-A B GOTO GOTO label switch GOTO A br-GOTO A A Figure 4: BTB predictions on a small \nVM program threaded code VM BTB next instruction program entry prediction actual label: A1 br-A1 BB B \nbr-B A2 A2 A2 br-A2 GOTO GOTO GOTO label br-GOTO A1 A1 Figure 5: Improving BTB prediction accuracy by \nreplicating VM instructions threaded code VM BTB next instruction program entry prediction actual label: \nA br-A BA BA BA br-B A GOTO GOTO GOTO label br-GOTO A A Figure 6: Improving BTB prediction accuracy with \nsuperinstructions There are two copies of the VM instruction A now, A1,and A2. Each of these copies has \nits own dispatch branch and its own entry in the BTB. Because A1 is always followed by B, and A2 is followed \nby GOTO, the dispatch branches of A1 and A2 always predict correctly, and there are no mispredic\u00adtions \nafter the .rst iteration while the interpreter executes the loop (except possibly mispredictions from \ncapacity or con.ict misses in the BTB).  4.2 Superinstructions Combining several VM instructions into \nsuperinstructions is a technique that has been used for reducing VM code size and for reducing the dispatch \nand argument access overhead in the past [14, 13, 10, 8]. However, its e.ect on branch prediction has \nnot been investigated in depth yet. In this paper we investigate the e.ect of superinstructions on dispatch \nmispredictions; in particular, we .nd that us\u00ading superinstructions reduces mispredictions far more than \nit reduces dispatches or executed native instructions (see Section 7.3). To get an idea why this is the \ncase, consider Figure 6: we combine the sequence B A into the superinstruction B A. This superinstruction \noccurs only once in the loop, and A now also occurs only once, so there are no mispredictions after the \n.rst iteration while the interpreter executes the loop.  5. IMPLEMENTATION 5.1 Static Approach There \nare two ways of implementing replication and su\u00adperinstructions (see Fig. 7). In the static approach \nthe interpreter writer produces replicas and/or superinstructions at interpreter build-time, typically \nby generating C code for them with a macro pro\u00adcessor or interpreter generator (e.g., vmgen supports \nstatic superinstructions [8]). During VM code generation (at inter\u00adpreter run-time) the interpreter front-end \njust selects among the built-in replicas and/or superinstructions. For static replication two plausible \nways to select the copy come to mind: round-robin (i.e., always select the statically least-recently-used \ncopy) and random. We tried both ap\u00adproaches in our simulator, and achieved better results for round-robin, \nso we use that in the rest of the paper. Our explanation for the better results with round-robin selec\u00adtion \nis spatial locality in the code; execution does not jump around in the code at random, but tends to stay \nin a speci.c region (e.g., in a loop), and there it is less likely to encounter the same replica twice \nwith round-robin selection. E.g., in our example loop we will get the perfect result (Fig. 5) if we have \nat least two replicas of A and use round-robin selection, whereas random selection might use the same \nreplica of A twice and thus produce 50%mispredictions. For static superinstructions one can use dynamic \npro\u00adgramming (shortest-path algorithm) to select the optimal (minimum) number of superinstructions for \na given basic block [2]. A simpler alternative is the greedy (maximum munch) algorithm. In the rest of \nthe paper we use the greedy algorithm (because we have not yet implemented dynamic programming); preliminary \nsimulation results indicate there is almost no di.erence between the results for optimal and greedy selection. \n 5.2 Dynamic Approach In the dynamic approach the replicas or superinstructions are created when the \nVM code is produced at interpreter run-time. To implement replication, every time the interpreter front\u00adend \ngenerates a VM instruction, it creates a new copy of the code for the VM instruction, and lets the threaded \ncode pointer point to the new copy (see Fig. 7). In this way each instance of a VM instruction gets its \nown replica, ensuring that there are no mispredictions (apart from those resulting from the limited BTB \nsize). The original copies of the code are only used for copying, and are never executed. The front-end \nknows the end of the code to be copied through a label there [13]. Static Replication Dynamic Replication \ndata segment code segment data segment data segment code segment VM Code VM instruction routines VM Code \nVM routine copies VM routine originals Machine code for iloadMachine code for iadd Machine code for \niadd Dispatch nextDispatch next Dispatch next Machine code for iload Machine code for iadd Machine code \nfor iload Dispatch next Dispatch next Dispatch next Machine code for iload Machine code for iload Dispatch \nnext Dispatch next Machine code for iload Dispatch next Figure 7: The static and the dynamic approach \nto implementing replication Implementing dynamic replication with dynamic superin\u00adstructions requires \nonly a small change over dynamic repli\u00adcation alone, if the replicas are already laid down in memory \nin the same sequence as the VM code: just do not copy the dispatch code except on VM basic block ends. \nThis results in one superinstruction for each basic block. If you want dynamic superinstructions without \nreplica\u00adtion, you have to perform another change: at the end of each VM basic block, check if the superinstruction \nhas al\u00adready occured; if so, eliminate the new replica, and redirect the threaded code pointers to the \n.rst version of the superin\u00adstruction (see [13]). One can get dynamic superinstructions larger than a \nbasic block with two more changes: Keep the increments of the VM instruction pointer even if you do \nnot copy the rest of the dispatch code; as a result, the VM code will be quite similar to the dynamic \nreplication case (whereas you have only one threaded-code pointer per superinstruction if you elim\u00adinate \nthe increments); this allows to continue the su\u00adperinstruction across VM code entry points; on a VM jump \nto the entry point, the threaded code pointer at this place will be used and result in entering the code \nfor the superinstruction in the middle.  Let the dispatch for the fall-through path of a con\u00additional \nVM branch be at the end of the conditional branch code, and use an additional dispatch for the branch-taken \npath; then you can also eliminate the (fall-through) dispatch at the end of a conditional VM branch. \n As a result of these two optimizations, all dispatches are eliminated, except dispatches for taken \nVM branches, VM calls and VM returns (see Fig. 8). One problem with the dynamic approach is that it can \nonly copy code that is relocatable; i.e., it cannot copy code, if the code fragment contains a PC-relative \nreference to some\u00adthing outside the code fragment (e.g., an Intel 386 call instruction), or if it contains \nan absolute reference to some\u00adthing inside the code fragment (e.g., a MIPS j(ump) instruc\u00adtion). Whether \nthe code for a VM instruction is relocatable or not depends on the architecture and on the compiler; \nso, a general no-copying list [13] is not su.cient.  data segment data segment VM Code VM routine copies \nMachine Code for A  if (top-of-stack != 0) { ip = target Dispatch next } Basic block boundaries Machine \ncode for B but no dispatch Machine code for C Machine code for return Dispatch next Figure 8: Superinstructions \nacross basic blocks Our approach to this problem is to have two versions of the VM interpreter function, \none with some gratuitious padding between the VM instructions. We compare the code frag\u00adments for each \nVM instruction of these two functions; if they are the same, the code fragment is relocatable, if they \nare di.erent, it is not. The dynamic approach requires a small amount of platform-speci.c code; on most \narchitectures it needs only code for .ushing the I-cache, but, e.g., on MIPS it might have to ensure \nthat the copies are in the same 256MB region as the original code to ensure that the J and JAL instruc\u00adtions \ncontinue to work.  5.3 Comparison The main advantage of the static approach is that it is completely \nportable, whereas the dynamic approach requires a small amount of platform-speci.c code. Another advantage \nof static superinstructions is that their code can be optimized across their component instructions, \nwhereas dynamic superinstructions simply concatenate the components without optimization. In particular, \nstatic su\u00adperinstructions can keep stack items in registers across com\u00adponents, and combine the stack \npointer updates of the com\u00adponents. In addition, static superinstructions make it pos\u00adsible to use instruction \nscheduling across component VM instructions. These advantages can also be exploited in a dynamic setting \nby combining static superinstructions with dynamic superinstructions and dynamic replication. Moreover, \nstatic replication and superinstructions also work for non-relocatable code. However, at least for Gforth \nthe code for the frequently-executed VM instructions is relocatable on the 386 and Alpha architecture. \nFor the JVM, instructions that can throw exceptions are often non\u00adrelocatable (relative branch to the \nthrow code outside the code for the VM instruction), but that can be worked around, e.g., by using an \nindirect branch instead of the rel\u00adative branch. Finally, the static approach does not need to pay the \ncost of copying the code at run-time (including potentially ex\u00adpensive I-cache .ushes), that the dynamic \napproach has to pay. However, in our experiments this copying takes 5ms for a 10000-line program (190KB \ngenerated code) on a Celeron\u00ad800, so that should usually not be a problem3 . The main advantage of the \ndynamic approach is that it perfectly .ts replications and/or superinstructions to the in\u00adterpreted program, \nwhereas the static approach has to select one set of replications/superinstructions for all programs. \nAnother advantage of the dynamic approach is that the number of replications and superinstructions is \nonly limited by the resulting code size, whereas in the static approach the time and space required for \ncompiling the interpreter limit the number of replications and superinstructions to around 1000 (e.g., \ncompiling Gforth with 1600 superinstructions re\u00adquires 5 hours and 400 MB on a Celeron-800).  5.4 Relation \nto just-in-time compilers The machine code resulting from dynamic superinstruc\u00adtions with replication \nis similar to what a simple just-in-time (JIT) native-code compiler produces. So why not write a JIT \ncompiler in the .rst place? The reason is portability. Native-code compilers take a sig\u00adni.cant e.ort \nto retarget to another architecture (typically months to years, for each architecture). In contrast retarget\u00ading \nthe dynamic replication/superinstruction part from the 386 to the Alpha architecture took about an hour. \nAnd if we do not invest the hour, we can still fall back to the base in\u00adterpreter on the new architecture; \nin contrast, if you do not want to invest the months of e.ort for retargeting a JIT, you need a separate \nfallback system (e.g., an interpreter), and that needs even more e.ort. And all these targets and the \nfallback system have to be maintained, requiring yet more e.ort. Technically, the main di.erence between \ncode from a sim\u00adple, macro-expanding native-code compiler and our code from dynamic replication with \ndynamic superinstructions is: our code accesses immediate arguments of VM instruction through the VM \ncode representation; and it uses indirect branches instead of direct branches for control-.ow changes. \nSee Section 7.6 for a timing comparison.  6. EXPERIMENTAL SETUP We have conducted experiments using \na simulator as well as experiments using an implementation of these techniques. We used a simulator to \nget results for various hardware con\u00ad.gurations (especially varying BTB and cache sizes), and to get \nresults without noise e.ects like cache or BTB con.icts, 3Actually, in comparison to plain threaded code, \nthe copying overhead is already amortized by the speedup of the Forth\u00adlevel startup code, leading to \nthe same total startup times (17ms on the Celeron-800). Program Version Lines Description gray 4 754 \nparser generator bench-gc 1.1 1150 garbage collector tscp 0.4 1625 chess vmgen 0.5.9 2068 interpreter \ngenerator cross 0.5.9 2735 Forth cross-compiler brainless 0.0.2 3519 chess brew 38 29804 evolutionary \nprogramming Figure 9: Benchmark programs used or (for static methods) instruction scheduling or register \nal\u00adlocation di.erences. The results from the simulation and the real implementa\u00adtion agree reasonably \nwell, so in this paper we mainly report results from the implementation running on real processors, and \nwe refer to the simulation results only to clarify points that are not apparent from the real-world implementation \nresults. 6.1 Implementation We implemented the techniques described in Section 4 in Gforth, a product-quality \nForth interpreter. In particular, we implemented static superinstructions us\u00ading vmgen [8]; we implemented \nstatic replication by repli\u00adcating the code for the (super)instructions on interpreter startup instead \nof at interpreter build-time; in all other re\u00adspects this implementation behaves like normal static repli\u00adcation \n(i.e., the replication is not speci.c to the interpreted program, unlike dynamic replication). This was \neasier to implement, allowed to use more replication con.gurations (in particular, more replicas) and \nshould produce the same results as normal static replication (except for the copying overhead, and the \nimpact of that was small compared to the benchmark run-times). We implemented dynamic methods pretty \nmuch as de\u00adscribed in Section 5.2, with free choice (through command\u00adline .ags) of replication, superinstructions, \nor both, and su\u00adperinstructions within basic-blocks or across them. By us\u00ading this machinery with a VM \ninterpreter including static superinstructions we can also explore the combination of static superinstructions \n(with optimizations across compo\u00adnent instructions) and the dynamic methods. One thing that we have not \nimplemented is eliminating the increments of the VM instruction pointers along with the rest of the instruction \ndispatch in dynamic superinstruc\u00adtions. However, by using static superinstructions in addition dynamic \nsuperinstructions and replication we also reduce these increments (in addition to other optimizations); \nlook\u00ading at the results from that, eliminating only the increments probably does not have much e.ect. \nIt would also con.ict with superinstructions across basic blocks. 6.2 Machines We used an 800MHz Celeron \n(VIA Apollo Pro chipset, 512MB PC100 SDRAM, Linux-2.4.7, glibc-2.2.2, gcc-2.95.3) for most of the results \nwe present here. The reason for this choice is that the Celeron has a relatively small I-cache (16KB), \nL2 cache (128KB), and BTB (512 entries), so any negative performance impacts of the code growth from \nour techniques should become visible on this processor. plain static repl static super static both dynamic \nrepl dynamic super dynamic both across bb with static super speedup 3.0 2.0 1.0  Figure 10: Speedups \nof various interpreter optimizations on a Celeron-800 For comparison, we also present some results from \na 1200MHz Athlon (Thunderbird; VIA KT133 chipset, 192MB PC100 SDRAM, Linux-2.4.0, glibc-2.1.3, gcc\u00ad2.95.1). \nThis processor has a larger I-cache (64KB), L2 cache (256KB), and BTB (2048 entries). Both processors \nallow measuring a variety of events with performance-monitoring counters, providing additional in\u00adsights. \n 6.3 Benchmarks Figure 9 shows the benchmarks we used for our exper\u00adiments. The line counts include \nlibraries that are not preloaded in Gforth, but not what would be considered as input .les in languages \nwith a hard compile-time/run-time boundary (e.g., the grammar for gray, and the program to be compiled \nfor cross), as far as we could tell the di.erence.  7. RESULTS 7.1 Interpreter variants We compared \nthe following variants of Gforth: plain Threaded code; this is used as the baseline of our comparison \n(factor 1). static repl Static replication with 400 replicas and round\u00adrobin selection. static super \n400 static superinstructions with greedy se\u00adlection. static both 35 unique superinstructions, 365 replicas \nof in\u00adstructions and superinstructions (for a total of 400). dynamic repl Dynamic replication dynamic \nsuper Dynamic superinstructions without repli\u00ad cation, limited to basic blocks (very similar to what \nPiumarta and Riccardi proposed [13]). dynamic both Dynamic superinstructions, limited to ba\u00adsic blocks, \nwith replication. across bb Dynamic superinstructions across basic blocks, with replication. with static \nsuper First, combine instructions within a ba\u00adsic block into static superinstructions (with 400 su\u00adperinstructions) \nwith greedy selection, then form dy\u00adnamic superinstructions across basic blocks with repli\u00adcation from \nthat. This combines the speed bene.ts of static superinstructions (optimization across VM in\u00adstructions) \nwith the bene.ts of dynamic superinstruc\u00adtions with replication. We used the most frequently executed \nVM instructions and sequences from a training run with the brainless bench\u00admark for static replication \nand static superinstructions. We used 400 additional instructions for the static vari\u00adants because it \nis a realistic number for interpreters dis\u00adtributed in source code: it does not cost that much in in\u00adterpreter \ncompile-time and compile-space, and using more gives rapidly diminishing improvements. The presented \nresults are for complete benchmark runs, including interpreter startup times, benchmark compilation, \nand, for the dynamic variants, the time spent in code copy\u00ading. 7.2 Speedups Figure 10 shows the speedups \nthese versions achieve over plain on various benchmarks. The dynamic methods fare better than the static \nmeth\u00adods (exception: on brainless static superinstructions do bet\u00adter than dynamic replication; that \nis probably because the training program was brainless). For the static methods, we see that static replication \ndoes better than static superinstructions, probably because repli\u00adcation depends less on how well the \ntraining run .ts the ac\u00adtual run. A combination of replication and superinstructions is usually better, \nhowever (see Section 7.5). For the dynamic methods, superinstructions alone per\u00adform better than replication \nalone. However, the combina\u00adtion performs even better; exceptions: cross and brainless on the Celeron, \ndue to I-cache misses (on the Athlon the combination is better for all benchmarks). Performing both optimizations \nacross basic blocks is always bene.cial, and using static superinstructions in addition helps some more \n(exception: brew, because static superinstructions do not improve the prediction accuracy there and because \nit exe\u00adcutes more native instructions; this is an artifact of the im\u00ad plain static repl static super \n static both dynamic repl dynamic super dynamic both across bb with static super events 1.0 0.8 0.6 \n0.4 0.2 0.0  cycles (*500M) taken_branches (*50M) icache_misses (*100k) code_bytes (*250k) instructions \n(*250M) taken_mispredicted (*50M) miss_cycles (*500M) Figure 11: Performance counter results for bench-gc \non a Celeron-800 plain static repl static super static both dynamic repl dynamic super dynamic both \nacross bb with static super events 1.0 0.8 0.6 0.4 0.2 0.0  cycles (*60G) taken_branches (*6G) icache_misses \n(*200M) code_bytes (*1M) instructions (*30G) taken_mispredicted (*6G) miss_cycles (*60G) Figure 12: \nPerformance counter results for brew on a Celeron-800 plementation of superinstructions in this version \nof Gforth and does not transfer to other interpreters or future versions of Gforth). Overall, the new \ntechniques provide very nice speedups over the techniques usually used in e.cient interpreters (up to \nfactor 2.08 for static both over plain, and factor 3.17 for with static super across plain), but also \nacross existing tech\u00adniques that are not yet widely used (factor 1.30 for static both over static super \n[8] on bench-gc, and factor 1.29 for with static super over dynamic super [13]).  7.3 Other metrics \nWe take a closer look at the reasons for the speedups by looking at various other metrics, using mostly \nperformance monitoring counters: cycles (tsc) The number of cycles taken for executing the program; this \nis proportional to the reciprocal of the speedup. instructions (event C0) Executed (retired) instructions. \ntaken branches (event C9) Executed (retired) taken branch instructions.  taken mispredicted (event CA) \nExecuted (retired) taken branch instructions that are mispredicted. For plain most of these mispredictions \nare mispredictions of the dispatch indirect branches of the interpreter. We use the same scale factor \nfor this event as for taken branches, so you can directly see how many of the taken branches are mispredicted. \nWe also scale this event such that 1 misprediction corresponds to 10 cycles (the approximate cost of \na misprediction on a Celeron or Athlon); this allows you to directly see how much of the time is spent \nin mispredictions and compare this to, e.g., the time spent in I-cache misses. icache misses (event 81) \nInstruction fetch misses. Note the scale factor for these events; they are much rarer than the others. \nmiss cycles (event 86) Cycles during which the instruc\u00adtion fetch is stalled (usually due to I-cache \nmisses); we use the same scale factor for this event as for cy\u00adcles, so you can directly see how much \nof the time is spent in I-cache misses, and compare this to, e.g., taken mispredicted.   code bytes \nThe size of the code generated at run-time, in bytes. Due to the way we implemented static replica\u00adtion, \nyou see a few KB of code generated even for some static schemes. Figure 11 shows these metrics for bench-gc. \nIn this benchmark nearly all of the executed branches are dispatch branches [7], so the e.ects of our \ndispatch optimizations should be most evident there. Figure 12 shows these metrics for brew. Thisisour \nlargest benchmark, so it may unveil e.ects from code growth that are not apparent with smaller benchmarks \n(however, brain\u00adless and cross have a slightly higher proportion of I-cache miss cycles, so the locality \ncharacteristics of a program do not necessarily correlate with size). The .rst thing to notice is that \nboth the instructions and the taken branches count are the same for plain, static repl, and dynamic repl. \nSimilarly, they are the same for dynamic super and dynamic both. The reason is that (after startup, with \nits negligible copying overhead) these interpreters exe\u00adcute exactly the same sequence of native instructions, \nonly coming from di.erent copies of the code. So the di.erence in cycles between these interpreters comes \nfrom the di.erence in branch mispredictions, I-cache misses and other, similar e.ects (however, looking \nat the data, we believe that other e.ects only play a negligible role). Looking at the cycles and taken \nmispredicted metrics, we see that mispredictions consume a large part of the time in the plain interpreter, \nand that just eliminating most of these mispredictions by dynamic replication gives a dra\u00admatic speedup \n(factor 2.39 for bench-gc). Our simulations show that the remaining mispredicted dispatch branches are \ndue to indirect VM branches (mostly, VM returns), apart from capacity and con.ict misses in the BTB. \nThe static methods do not work that well: they do not reduce the mispredictions as much, because they \nhave to reuse VM instructions. Dynamic superinstructions without replication have a slightly worse misprediction \naccuracy than dynamic repli\u00adcation, because superinstructions are reused, but they make up for this by \nexecuting fewer instructions, and (for brew) taking fewer miss cycles. Looking at the instructions, we \nsee that VM superinstruc\u00adtions do not reduce the number of executed native instruc\u00adtions much. Both static \nand dynamic superinstructions re\u00adduce this by similar amounts (apart from brew); dynamic superinstructions \neliminate more dispatch code (see also the e.ect on taken branches), whereas static superinstructions \nallow optimizations between component VM instructions. Across bb reduces the instructions a little more, \nand with static super also a little more (exception: brew). Looking at taken branches, we get a similar \npicture as with instructions, except that dynamic superinstructions re\u00adduce this metric much more than \nstatic superinstructions. Also, across bb and with static super have the same num\u00adber of taken branches \n(exception: brew), because with static super only changes what goes on in a dynamic superinstruc\u00adtion, \nnot how it is formed. Taken branches also indicates (and our simulation results con.rm) that the length \nof the average executed superin\u00adstruction is quite short for static superinstructions (typically around \n1.5 component instructions), but also for dynamic superinstructions (around 3 component instructions). \nAlso, across bb does not increase the superinstruction length by much, because in Forth the most frequent \nreason for basic block boundaries is calls and returns, and across bb does not help there; therefore \nwe expect across bb to have a greater ef\u00adfect on superinstruction length and on performance in other \nlanguages.      7.4 Code growth A frequent reaction to the proposal for replication is that the \nresulting code growth will cause so many performance problems that the end result will be slower than \nthe original interpreter; a quick look at the speedups (Fig. 10) should convince everyone that this is \nnot true, even on a CPU with small caches like the Celeron. Still, in this section we take a closer look \nat the code growth and its e.ect on various metrics. In the code bytes bars of Fig. 12 we see that the \ndynamic\u00adreplication based methods produce about 1MB of native code for brew, with longer superinstructions \nand static su\u00adperinstructions reducing the code size a little. In many en\u00advironments this is quite acceptable \nfor a 30000-line program (e.g., brew also consumes 0.5MB of the Gforth data space containing threaded \ncode and data). Dynamic superinstructions without replication reuse su\u00adperinstructions a lot, resulting \nin a generated code size of only 200KB. These size di.erences are also re.ected in icache misses: the \nstatic methods have very few misses, dynamic super some more, and the replication-based methods even \nmore; this is also re.ected in the miss cycles. However, the miss cycles only consume a small part of \nthe total cycles in most cases, and only in a few cases do they overcome the bene.t obtained from better \nprediction accu\u00adracy; in particular, on the Celeron dynamic both spends 23% of the cycles on misses when \nrunning brainless (compared to 7.5%for dynamic super), resulting in a slowdown by factor 1.11; however, \ndynamic both is faster for most other bench\u00admarks on the Celeron, and for all benchmarks on the Athlon \n(factor 1.07 for brainless). So, unless you have reason to expect to run programs with particularly bad \ncode locality, we recommend using dy\u00adnamic replication together with dynamic superinstructions for general-purpose \nmachines. Another way of looking at the issue is to compare the code generated by our replication methods \nto code generated by a native-code compiler4; it will typically be larger than the native code by a small \nconstant factor (the factor may be even < 1 if the native-code compiler uses loop unrolling, inlining, \nand other code replicating optimizations); for most code I-cache misses are not a big issue, so the code \nsize resulting from replication is usually not a big issue, either. 7.5 Balancing static methods Figure \n13 shows timing results for various combinations of static replication and superinstructions. Each line \nrepre\u00adsents a given number of total additional instructions, vary\u00ading distributions between replication \nand superinstructions along the X axis. . We can see that the performance improves with the total number \nof additional instructions, but approaches a limit of around 200M cycles. 4Unfortunately the native-code \nForth compilers we use do not report the size of the generated code, so we cannot present empirical data \nhere.   cycles 0 25400M 50 100 200 400 800 200M 0 %superinstructions %replicas 50 50 across bb bigForth \niForth tscp 2.98 5.13 3.51 brainless 2.49 2.73 brew 2.17 0.92 Figure 14: Speedups of across bb and two \nnative code compilers over plain. We can also see that a combination of replication and superinstructions \ngives good results; as long as we are not too close to the extreme points, performance is not very sensitive \nto the actual distribution between replication and superinstructions.  7.6 Speed comparison with native-code \ncom\u00adpilers In this section we look at how far the resulting interpreters are still from relatively simple \nnative-code compilers. The native-code Forth compilers we used are bigForth-2.03 and iForth-1.12. For \nthe data in this section we used Gforth\u00ad0.6.1, which gives slightly di.erent speedups from the ver\u00adsion \nused earlier. We also use tscp-0.5. We only ran those benchmarks that we could get to run on the di.erent \ncom\u00adpilers easily. The benchmarks were run on an Athlon-1200 (Linux-2.4.19, glibc-2.1.3). You see the \nresults in Fig. 14. Drawing conclusions from such a small sample size (both compilers and benchmarks) \nis dangerous, but the speed di.erence between interpreters and native-code compilers appears to be less \nthan many people imagine.  8. RELATED WORK The accuracy of static conditional branch predictors has \nbeen improved with software methods: branch alignment [3] and code replication [12, 18, 17]. The present \npaper looks at using software methods to improve the accuracy of the BTB, a simple dynamic indirect branch \npredictor. Our code replication di.ers from replication for conditional branch prediction in all aspects: \nour work addresses a dy\u00adnamic indirect branch predictor (the BTB) instead of a static conditional branch \npredictor. Replication for condi\u00adtional branches works at compile-time and is based on pro.l\u00ading to .nd \ncorrelations between branches to be exploited by replication, and no data is a.ected; in contrast, our \nreplica\u00adtion changes the representation of the interpreted program at program startup time to decide \nthe replicas to use. Better indirect branch predictors than BTBs have been proposed in a number of papers \n[4, 5, 11] and they work well on interpreters [7], but they are not available in hardware yet, and it \nwill probably take a long time before they are universally available, if at all. There are a number of \nrecent papers on improving in\u00adterpreter performance [14, 6, 13, 16]. Software pipelining the interpreter \n[9, 10] is a way to reduce the branch dis\u00adpatch costs on architectures with delayed indirect branches \n(or split indirect branches). Ertl and Gregg [7] investigated the performance of vari\u00adous branch predictors \non interpreters, but did not investigate means to improve the prediction accuracy beyond threaded code. \nIn a similar vein, Romer et al. [15] investigated the performance characteristics of several interpreters. \nThey used ine.cient interpreters, and thus did not notice that e.cient interpreters spend much of their \ntime on dispatch branches. Papers dealing with superoperators and superinstructions [14, 13, 10, 8] concentrated \non reducing the number of exe\u00adcuted dispatches and sometimes the VM code size, but have not evaluated \nthe e.ect of superinstructions on BTB pre\u00addiction accuracy (apart from two paragraphs in [8]). In par\u00adticular, \nPiumarta and Riccardi invested extra work to avoid replication (in order to reduce code size), but this \nincreases mispredictions on processors with BTBs. 9. CONCLUSION If a VM instruction occurs several times \nin the working set of an interpreted program, a BTB will frequently mispre\u00addict the dispatch branch of \nthe VM instruction. We present three techniques for reducing mispredictions in interpreters: replicating \nVM instructions, such that hopefully each replica occurs only once in the working set (speedup up to \na fac\u00adtor of 2.39 over an e.cient threaded-code interpreter); and combining sequences of VM instructions \ninto superinstruc\u00adtions (speedup up to a factor of 2.45). In combination these techniques achieve an \neven greater speedup (up to a factor of 3.17). There are two variants of these optimizations: The static \nvariant creates the replicas and/or superinstructions at in\u00adterpreter build-time; it produces less speedup \n(up to a factor of 1.99), but is completely portable. The dynamic variant creates replicas and/or superinstructions \nat interpreter run\u00adtime; it produces very good speedups (up to a factor of 3.09), but requires a little \nbit of porting work for each new platform. The dynamic techniques can be combined with static superinstructions \nfor even greater speed (up to a fac\u00adtor 3.17). The speedup of an optimization has to be balanced against \nthe cost of implementing it. In the present case, in addition to giving good speedups, the dynamic methods \nare relatively easy to implement (a few days of work). Static replication with a few static superinstructions \nis also pretty easy to implement for a particular interpreter. The software and data we used for this \npaper is available at http://www.complang.tuwien.ac.at/anton/interpreter-btb/. Acknowledgements We thank \nthe referees for their helpful comments. The per\u00adformance counter measurements were made using Mikael \nPettersson s perfctr package. 10. REFERENCES [1] J. R. Bell. Threaded code. Commun. ACM, 16(6):370 372, \n1973. [2] T. C. Bell, J. G. Cleary, and I. H. Witten. Text Compression. Prentice-Hall, 1990. [3] B. \nCalder and D. Grunwald. Reducing branch costs via branch alignment. In Architectural Support for Programming \nLanguages and Operating Systems (ASPLOS-VI), pages 242 251, 1994. [4] K. Driesen and U. H\u00a8olzle. Accurate \nindirect branch prediction. In Proceedings of the 25th Annual International Symposium on Computer Architecture \n(ISCA-98), pages 167 178, 1998. [5] K. Driesen and U. H\u00a8olzle. Multi-stage cascaded prediction. In EuroPar \n99 Conference Proceedings, volume 1685 of LNCS, pages 1312 1321. Springer, 1999. [6] M. A. Ertl. Stack \ncaching for interpreters. In SIGPLAN 95 Conference on Programming Language Design and Implementation, \npages 315 327, 1995. [7] M. A. Ertl and D. Gregg. The behaviour of e.cient virtual machine interpreters \non modern architectures. In Euro-Par 2001, pages 403 412. Springer LNCS 2150, 2001. [8] M. A. Ertl, D. \nGregg, A. Krall, and B. Paysan. vmgen a generator of e.cient virtual machine interpreters. Software Practice \nand Experience, 32(3):265 294, 2002. [9] J. Hoogerbrugge and L. Augusteijn. Pipelined Java virtual machine \ninterpreters. In Proceedings of the 9th International Conference on Compiler Construction (CC 00). Springer \nLNCS, 2000. [10] J. Hoogerbrugge, L. Augusteijn, J. Trum, and R. van de Wiel. A code compression system \nbased on pipelined interpreters. Software Practice and Experience, 29(11):1005 1023, Sept. 1999. [11] \nJ. Kalamatianos and D. Kaeli. Indirect branch prediction using data compression techniques. Journal of \nInstruction Level Parallelism, Dec. 1999. [12] A. Krall. Improving semi-static branch prediction by code \nreplication. In Conference on Programming Language Design and Implementation, volume 29(7) of SIGPLAN, \npages 97 106, Orlando, 1994. ACM. [13] I. Piumarta and F. Riccardi. Optimizing direct threaded code by \nselective inlining. In SIGPLAN 98 Conference on Programming Language Design and Implementation, pages \n291 300, 1998. [14] T. A. Proebsting. Optimizing an ANSI C interpreter with superoperators. In Principles \nof Programming Languages (POPL 95), pages 322 332, 1995. [15] T. H. Romer, D. Lee, G. M. Voelker, A. \nWolman, W. A. Wong, J.-L. Baer,B.N. Bershad,and H. M. Levy. The structure and performance of interpreters. \nIn Architectural Support for Programming Languages and Operating Systems (ASPLOS-VII), pages 150 159, \n1996. [16] V. Santos Costa. Optimising bytecode emulation for Prolog. In LNCS 1702, Proceedings of PPDP \n99, pages 261 267. Springer-Verlag, September 1999. [17] C. Young, N. Gloy, and M. D. Smith. A comparative \nanalysis of schemes for correlated branch prediction. In 22nd Annual International Symposium on Computer \nArchitecture, pages 276 286, 1995. [18] C. Young and M. D. Smith. Improving the accuracy of static branch \nprediction using branch correlation. In Architectural Support for Programming Languages and Operating \nSystems (ASPLOS-VI), pages 232 241, 1994.   \n\t\t\t", "proc_id": "781131", "abstract": "Interpreters designed for efficiency execute a huge number of indirect branches and can spend more than half of the execution time in indirect branch mispredictions. Branch target buffers are the best widely available form of indirect branch prediction; however, their prediction accuracy for existing interpreters is only 2%--50%. In this paper we investigate two methods for improving the prediction accuracy of BTBs for interpreters: replicating virtual machine (VM) instructions and combining sequences of VM instructions into superinstructions. We investigate static (interpreter build-time) and dynamic (interpreter run-time) variants of these techniques and compare them and several combinations of these techniques. These techniques can eliminate nearly all of the dispatch branch mispredictions, and have other benefits, resulting in speedups by a factor of up to 3.17 over efficient threaded-code interpreters, and speedups by a factor of up to 1.3 over techniques relying on superinstructions alone.", "authors": [{"name": "M. Anton Ertl", "author_profile_id": "81100016086", "affiliation": "TU Wien", "person_id": "PP39023339", "email_address": "", "orcid_id": ""}, {"name": "David Gregg", "author_profile_id": "81100422211", "affiliation": "Trinity College, Dublin", "person_id": "P397707", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/781131.781162", "year": "2003", "article_id": "781162", "conference": "PLDI", "title": "Optimizing indirect branch prediction accuracy in virtual machine interpreters", "url": "http://dl.acm.org/citation.cfm?id=781162"}