{"article_publication_date": "05-09-2003", "fulltext": "\n Static Con.ict Analysis for Multi-Threaded Object-Oriented Programs Christoph von Praun and Thomas \nR. Gross Laboratory for Software Technology ETH Z\u00a8urich 8092 Z\u00a8urich, Switzerland ABSTRACT A compiler \nfor multi-threaded object-oriented programs needs information about the sharing of objects for a variety \nof reasons: to implement optimizations, to issue warnings, to add instrumentation to detect access violations \nthat occur at runtime. An Object Use Graph (OUG) statically captures accesses from di.erent threads to \nobjects. An OUG extends the Heap Shape Graph (HSG), which is a compile-time ab\u00adstraction for runtime \nobjects (nodes) and their reference re\u00adlations (edges). An OUG speci.es for a speci.c node in the HSG \na partial order of events relevant to the corresponding runtime object(s). Relevant events include read \nand write access, object escape, thread start and join. OUGs have been implemented in a Java compiler. \nInitial experience shows that OUGs are e.ective to identify ob\u00adject accesses that potentially con.ict \nat runtime and isolate accesses that never cause a problem at runtime. The capa\u00adbilities of OUGs are \ncompared with an advanced program analysis that has been used for lock elimination. For the set of benchmarks \ninvestigated here, OUGs report only a frac\u00adtion of shared objects as con.icting and reduce the number \nof compile-time reports in terms of allocation sites of con\u00ad.icting objects by 28 92% (average 64%). \nFor benchmarks of up to 30 KLOC, the time taken to construct OUGs is, with one exception, in the order \nof seconds. The information collected in the OUG has been used to instrument Java programs with checks \nfor object races. OUGs provide precise information about object sharing and static protection, so runtime \ninstrumentation that checks those cases that cannot be disambiguated at compile-time is sparse, and the \ntotal runtime overhead of checking for object races is only 3 86% (average 47%). Categories and Subject \nDescriptors D.3.4 [Software]: Compilers; D.2.3 [Software Engineer\u00ading]: Object-oriented programming Java \nThis research was supported, in part, by a gift from the Microprocessor Research Lab (MRL) of Intel Corp. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n03, June 9 11, 2003, San Diego, California, USA. Copyright 2003 ACM 1-58113-662-5/03/0006 ...$5.00. \nGeneral Terms Program analysis, representations for concurrent programs  Keywords Race detection, heap \nshape graph, object use graph 1. INTRODUCTION A compiler for an object-oriented programming language \nwith multi-threading needs precise information about the sharing of objects. The absence of precise information \nhas undesirable consequences: the compiler must make many conservative assumptions, and they either inhibit \na wide range of optimizations or lead to additional synchronizing operations. A key issue is to determine \nthe sharing of objects by threads. Previous work on escape analysis [2, 3, 6, 30, 21] has classi.ed object \naccesses at compile-time according to properties of the accessed object. This information is stored in \nthe global Heap Shape Graph (HSG) and provides the ba\u00adsis for improving the placement and kind of synchronization \noperations. The HSG keeps information that is valid for all points in the program. If an object is accessed \nby two threads, then the object is considered to be shared. However, there are situations where more \ndetailed analysis may reveal that the second thread starts only after the termination of the .rst, and \nin that case, no sharing of the object takes place. This paper presents a practical approach to analyse \nobject\u00adoriented programs to discover such cases. We construct an Object Use Graph (OUG) that approximates \nthe happened\u00adbefore relation [16] of access events that are issued by dif\u00adferent threads to a speci.c \nobject. The OUG augments the HSG and re.nes escape information: Instead of attribut\u00ading a global classi.cation \nto an object (or rather its compile\u00adtime abstraction) and the sites it is accessed from, the OUG recognizes \nstructural, temporal, and lock-based protection of accesses in di.erent lifephases of the object or contexts \nfrom which the object is accessed. This information is de\u00adrived from the control .ow inside individual \nthreads and in\u00adformation about lock protection, object escape, thread-start and join. This information \nallows a variety of optimizations and, in addition, is precise enough to be useful for the static detection \nof synchronization defects. The information in the OUG is the foundation for vari\u00adous applications in \nconcurrence-aware compiler systems: (1) reporting of potentially con.icting accesses to the pro\u00adgrammer; \n(2) sparse program instrumentations for dynamic class Shared { int i; Shared(){i=0; } //(20) } class \nExample extends Thread { static Shared s_field; static Object lock_ = new Object(); static void main(String[] \nargs) { Shared s_local = new Shared(); // (2),(3) s_local.i++; // (4),(5) s_field = s_local; // (6) s_field.i++; \n// (7),(8),(9) Thread t = new Example(); t.start(); // (10) synchronized(lock_) { s_field.i++; // (11),(12),(13) \n} t.join(); // (14) s_field.i++; // (15),(16),(17) } void run() { // (22) synchronized(lock_) { s_field.i++; \n// (23),(24),(25) } // (26) } } Figure 1: Example Java program. detection of access con.icts, e.g., [29, \n7]; (3) compiling and optimizing programs in view of speci.c programming-level memory models, e.g., [18]; \n(4) optimization of synchroniza\u00adtion and memory allocation in concurrent programs [2, 3, 6, 30, 21]. \nWe implemented OUGs for standard Java programs and report here the evaluation for a set of multi-thread \nJava programs. The computation of OUGs requires a whole pro\u00adgram analysis, and hence OUGs are designed \nfor a way\u00adahead compilation and link model. 2. EXAMPLE Figure 1 shows a simple program with two threads \nthat both access an object of class Shared.We use this exam\u00adple to illustrate how OUGs di.er from previous \nabstractions. The numbers in comments relate program statements to ab\u00adstract events that are used during \nthe analysis described in the following sections. The terms abstract object and abstract thread refer \nto the compiler s entities that conservatively approximate runtime entities and do not necessarily correspond \nto unique runtime instances. The terms runtime object and runtime thread re\u00adfer to actual objects and \nthreads that exist when the pro\u00adgram is executed. When there is no risk of confusion, we just talk about \nobjects and threads. 2.1 Modeling of threads A key aspect of OUGs is to explicitly distinguish the e.ect \nof di.erent threads to abstract objects. The Java language allows the compiler to determine the threads \nthat may ever be created and started during a pro\u00adgram run as well as the call-closure of methods executed \nby these threads. In addition to the initial thread starting at the main method, threads correspond to \nobjects of class Thread. The type, entry method, and the multiplicity of threads are determined from \nthe thread allocation sites (Sec\u00adtion 3.1). The implicit invocation of class initializers does not generally \nallow to attribute their code to a particular runtime thread, and hence static initializers are modeled \nas separate initialization threads. In the example of Figure 1, there is one main thread T1 with entry \nmethod Example::main, one user thread T2 with entry method Example::run and several init threads corre\u00adsponding \nto class initializers. 2.2 Modeling of data Java employs a simple memory model: Objects are allo\u00adcated \non a global heap and object access is possible only through references issued at object creation time. \nThis model facilitates the computation of an approximation of the runtime object structure in the HSG \nat compile time. Nodes in the HSG represent individual runtime objects or sets of objects that are aliased. \nEdges represent points-to relations introduced through reference .elds. The overall result of the shape \nanalysis is a set of graphs rooted at class or thread nodes. Figure 2 shows the HSG for the example program \nof Fig\u00adure 1. Nodes in the HSG are given unique names and gi refers to the node with unique id i.In this \nexample, g4 corresponds to class Example with its variables s field and lock . The node is marked as \nthread root, because it is the context of an init and the main thread. Similarly, nodes g1,g2,g3 correspond \nto other classes. Nodes g5 to g11 repre\u00adsent objects that are allocated during the execution of ab\u00adstract \nthreads in di.erent contexts.  Figure 2: HSG for the example program. 2.3 Modeling of object uses \nObject uses are modeled by OUGs. The nodes in the OUG represent events, edges represent a safe approximation \nof the happened-before relation. Events represent either program actions (accesses to .elds, thread activity, \n...), or record the compiler s analysis. Possible nodes in an OUG are: GET/PUT: Read or write access \nto a .eld of the object. LOAD/STORE/ESCAPE: Fetch or deposit a reference to the object from/to another \nvariable. An ESCAPE node is a variant of a STORE node and occurs if the object holding the target variable \nis potentially shared among threads. TSTART/TJOIN: Start or join of a thread. ENTRY/EXIT: Thread entry \nand exit. These nodes do not correspond to a program action. CALL: Method invocation site. These nodes \nare only used during the construction of the graph (Section 3); the e.ect of events that are issued downstream \nof calls are inlined into the graph at the position of the CALL node. Recursive calls sites are not unfolded, \nbut con\u00adnected to the surrounding invocation context (Section 3.3.3). Nodes have a number of attributes: \nthe abstract thread and the program site that issues the event, the thread that is managed (TSTART/TJOIN), \nthe host object (LOAD/STORE/ESCAPE), the accessed .eld or method as well as the set of locks held during \nthe access (GET/PUT/CALL). There are three kinds of edges that express a general or\u00addering of events \nfor all program executions: Control-.ow ordering: Control-.ow edges represent the or\u00adder of events inside \na thread. If a program accesses an abstract object inside a loop or recursion, the OUG of that abstract \nobject is cyclic. Reference-.ow ordering: A thread cannot access an object before the creator thread \nof an object has made the ref\u00aderence available through a shared variable. This restric\u00adtion is modeled \nby reference-.ow edges that connect STORE/ESCAPE nodes with corresponding LOAD nodes. Reference-.ow edges \nimpose an ordering on events of the same thread or di.erent threads. Thread-relation ordering: Athread \nT cannot issue any event before T has been started. This fact is modeled by a TSTART node that precedes \nthe ENTRY node representing the entry method of the started thread. Similarly, a TJOIN node follows the \nEXIT. These edges from/to TSTART and TJOIN are called thread-relation edges. Two events in the OUG are \ncon.icting if (1) there is no ordering between the events, and (2) the events stem from di.erent threads, \nand (3) at least one event is a PUT, and (4) the accesses are not done under common lock protec\u00adtion. \nEvents that are not con.icting with any other event are safe. This de.nition of a con.ict is a compile-time \nab\u00adstraction for a data race. This approximation is safe because all runtime events that can constitute \na data race are deter\u00admined as con.icting in the OUG. As our compile-time view considers all control-.ows \npossible, there might however be events that are determined as con.icting in the OUG that do not constitute \na data race in any program execution. Figure 3 shows the .nal OUG example of the abstract object g10 \nfrom Figure 3, and the construction steps are described in subsequent sections. Note that the analysis \nclassi.es the PUT and GET events (20), (4), and (5) as safe, because references to (objects represented \nby) g10 are not available to thread T2 (they have not escaped at that stage of the execution). Events \n(8) and (9) are safe, because T2 has not been started. Events (12), (13), (24), (25) are not ordered \nin the graph, there is however a common unique lock that is held during all accesses. Events (16) and \n(17) are again safe, because T2 has been joined. Event (3) has been re.ned by the activities of the constructor \n(events (19), (20), (21)) and is therefore unlinked from the graph. Figure 3: OUG for the abstract object \ng10 of Figure 2. All update and read-/accesses to the Shared instance are hence ordered. The example \ndemonstrates that the ana\u00adlysis of OUGs is able to detect di.erent patterns that are commonly used to \nsynchronize threads and protect shared objects from unordered access. Without detecting the tem\u00adporal \nordering, conservative assumptions would have to be made. 2.4 Thread-directed heap traversal OUGs are \nbuilt during a symbolic execution of the ab\u00adstract threads. In an object-oriented program, the control \n.ow of the execution follows a path through the nodes that represent the objects in the program. An action \non a speci.c node (e.g., get.eld, put.eld) is noted as an event in the corre\u00adsponding OUG. In that way, \nOUGs are built incrementally during the traversal of the HSG. Figure 4 shows the HSG extended with temporary \nrefer\u00adence edges that correspond to reference relations through local variables along the execution of \nthe main thread T1. The heap traversal of T1 is illustrated as a path along the reference edges with \nspeci.c annotations at object accesses. Accesses correspond to method invocation or .eld access. The \ninitial sequence of the symbolic execution of the main thread is illustrated in Figure 4: A. Start of \nthread T1 at its entry method Example::main. B. The object g10 of class Shared is created and initial\u00adized. \nAllocation and constructor invocation are noted as events (2) and (3) in the OUG of g10 (Figure 3). Events \nthat are issued by the constructor of Shape are shown in a separate subgraph (events (19), (20), (21)). \nThe subgraph is inlined into the the graph of the main method at the corresponding CALL event (3). For \nsimplicity, this scenario omits the access to the super\u00adclass constructor in Shape::<init>. C. Read and \nwrite of .eld Shared::i. The accesses ap\u00adpear as GET (4) and PUT event (5) in Figure 3. D. Write access \nto .eld Example::s field in g4.Two events are generated in di.erent OUGs: A PUT event is added to the \nOUG of g4, and an ESCAPE event is recorded in the OUG of g10 (event (6) in Figure 3). E. Read of .eld \nExample::s field in g4. Two events are generated in di.erent OUGs: A GET node is added to the OUG of \ng4 , and the LOAD event (7) is added to the graph that stands for the object pointed to by the reference \nthat is being handled (OUG of g10). F. Read and write of .eld Shared::i in g10. The accesses correspond \nto the events (8) and (9) in Figure 3. G. Creation and initialization of g5.  Figure 4: Fragment of \nthe HSG with annotations of the start sequence of the heap traversal for the Example::main thread. The \nJava language de.nes a synchronization mechanism that resembles Monitors [14], and locks are generally \nas\u00adsociated with objects. This mechanism enforces that the protection region of locks coincides with \ndynamic program scopes (methods or blocks), hence lock protection can be tracked along a symbolic execution \nand added as annota\u00adtions to event nodes in the OUGs. Section 3.4 explains in detail how lock protection \ncan be inferred from sets of locked abstract objects.  3. CONSTRUCTION OF OUGS The overall process of \nconstructing OUGs for a multi\u00adthreaded program follows several phases: 1. Determine the abstract threads \nin the program and their call graphs (Section 3.1). 2. Build the global heap shape graph (Section 3.2). \n 3. Build OUGs during a symbolic execution of the ab\u00adstract threads (Section 3.3). 4. Analyze OUGs and \ndetermine con.icting events (Sec\u00adtion 3.4).  The .rst and second phase are based on the procedures de\u00adscribed \nin [21] and hence our description is brief. 3.1 Determining abstract threads An abstract thread is a \ncompile-time concept that repre\u00adsents a sequential control .ow in a program. An abstract thread T is \nde.ned as T := .tid, .m0, ..., mn., kind, multi. where tid is a unique id of the thread, and m0, ..., \nmn specify the entry methods. Three kinds of abstract threads exist: an init thread for every class initializer \nmethod, one main thread corresponding to the unique entry point of the overall program, and user threads \n(instances of java.lang.Thread or its subclasses). multi speci.es if multiple concurrent run\u00adtime instances \nof an abstract thread can exist. If a user thread has multiple or multiply executed allocation sites, \nthen multiple instances are assumed to execute concurrently, otherwise abstract threads are unique. An \nallocation site is multiply executed, if it (or one of its callers) is inside a loop or recursion, or \nthe allocating thread is not unique. Each abstract thread is characterized by the methods it executes \nobtained from the call graph rooted at the thread entry methods. Our implementation bounds the entry \nmeth\u00adods for user threads as well the implementation alternatives at polymorphic call sites through a \nvariable type analysis (VTA) [26]. 3.2 Computing the HSG The HSG represents a .ow-insensitive model \nof global data and their reference relations, approximating object con\u00adnectivity at any program point. \nFlow-insensitivity makes the HSG suitable for the analysis of multi-threaded pro\u00adgrams, because the .ow \nand progress of individual threads is generally not known at compile-time. The HSG is computed according \nto Ruf s uni.cation\u00adbased analysis [21]. It is compositional because every method is analyzed independently \nand method summaries are used to transfer the e.ect of method execution to indi\u00advidual call sites. A \nmethod summary is parameterized with caller context (parameters, return value(s), and thrown ex\u00adception(s)), \nand hence the analysis is context-sensitive.The intra-procedural analysis is .ow-insensitive. The runtime \nvalues of reference variables are represented as alias sets. Alias sets stand for a runtime object or \nsets of such, and constitute the nodes in the HSG. In addition to abstractions for object instances, \nthe HSG contains a node for each class modeling the class variables. An alias set AS is de.ned as AS \n:= ..eldmap,props, tidmask. where .eldmap maps fully quali.ed .eld names to alias sets representing the \nobjects reachable through those .elds. The .ag props is used to note various properties, e.g., if the \nalias set is equivalent or connected to an alias set for a class or thread root (global) or if the object \nis accessed by multi\u00adple thread instances (shared). tidmask speci.es the abstract threads that access \nthe object(s) corresponding to the alias set. The data structure supports the union of two alias sets, \ncombining the .eld maps (the alias sets of the same .elds are uni.ed recursively) and the global .ags \n(the result is global if at least one argument is marked global). Edges in the shape graph are featured \nby references to alias sets containedinthe .eldmap. The analysis associates variables with alias sets \nand uni\u00ad.es those alias sets in a stepwise process along the control .ow of the program. Intra-procedural \nand inter-procedural analyses approximate the e.ect of method invocations. 3.2.1 Inter-procedural analysis \nFirst, alias sets for class and abstract threads are created. These alias sets are the roots of the heap \nshape graph. Fur\u00adther alias sets are connected to these roots as a result of a sequence of intra-procedural \nsteps (Section 3.2.2). Nodes that are transitively reachable through these root nodes are global and \nrepresent objects that are potentially accessed from multiple threads. The inter-procedural analysis \ncon\u00adsiders all abstract threads and their methods in the reverse order of their invocation (bottom up \ntraversal of strongly connected components in the call graph). Recursion is han\u00addled specially, for details, \nsee [21]. 3.2.2 Intra-procedural analysis Given a method, the goal of the intra-procedural analysis \nis to establish a method summary that models the execution e.ect of a method to a calling context. A \nmethod summary captures aliases created through method invocation for data shared between caller and \ncallee, i.e., parameters, return values, and thrown exceptions. In addition, the e.ect of the method \nexecution in terms of allocated, read, and written objects is recorded. A method summary MS[m]of a method \nm is de.ned as a tuple of alias sets MS[m]:= ..f0, ..., fn., ret, except, allocs, reads, writes. The \ncomputation of the method summaries starts with the creation of alias sets for all formal reference parameters \nf0, ..., fn and local variables. ret and except are alias sets for the return values and thrown exceptions. \nFormal parameters are not aliased at this point, and caller-side aliasing is taken into account when \na method summary is instantiated at call sites. A control-.ow insensitive traversal of the statements \nof the method gradually builds the method summary. As\u00adsignment combines alias sets; .eld and array accesses \ncreate .eld-reference relations (all slots of an array are represented by a single symbolic .eld). Object \nallocation and access are recorded in the sets allocs, reads,and writes. At a call site, the method summary \nof the callee is already available (see previous section). The summary is cloned and embedded into the \nmethod summary of the caller by unify\u00ading the alias sets of formal and actual parameters, return values \nand thrown exceptions. This instanced version of the callee s method summary is called a method context. \nAt object access sites (allocation, .eld/array access, method call), the id of the abstract thread is \nnoted in the alias set representing the access target. After the creation of the HSG, this information \nis used to determine if objects are accessed by multiple or multiply executed abstract threads (hence \nglobal alias sets become shared).  3.3 Symbolic execution The symbolic execution phase narrows the classi.cation \nof abstract objects further and partitions shared abstract objects into con.icting and non-con.icting. \nFor that pur\u00adpose, OUGs are gradually constructed for all shared objects in the HSG. In an object-oriented \nenvironment, a symbolic execution maps nicely into a traversal of the heap shape structure determined \nin the previous analysis phase (Sec\u00adtion 3.2). The current position of the traversal re.ects the currently \naccessed abstract object. 3.3.1 Intra-procedural analysis An OUG is assembled gradually during the symbolic \nexe\u00adcution, from individual Method Object Use Graphs (MOUG). Similar to an OUG at the whole program level, \na MOUG models the relevant events at the level of a method m.A MOUG can be understood as a control-.ow \ngraph on which actions that do not result in events for the abstract object of interest are pruned. MOUG[m, \nrelevant]:= .events, edges. The abstract object of interest is speci.ed as a set of alias sets relevant. \nThis set speci.es either local alias sets l0, ..., ln that, in a given method context, correspond to \nthe object of interest, or as a global alias set if the object of interest corresponds to a class. Hence, \nfor a speci.c method m, a number of MOUGs can exist, depending on the object of interest and aliasing \nthat is given by the caller. MOUGs are created in a single .ow-sensitive method traversal, such that \nedges correspond to control-.ow rela\u00adtions and nodes correspond to program actions. At any object allocation, \naccess, and call site, the analysis deter\u00admines if the statement is relevant for the abstract object \nof interest and consequently acts as follows: At allocation sites, a NEW node is created in the MOUG. \nAt access sites to arrays or non-volatile, non-.nal .elds, a PUT or GET is created. If a reference variable \nis handled that refers to the abstract object of interest, a STORE or LOAD event is cre\u00adated. At a call \nsite, if the call target or one of the arguments to the call corresponds to the abstract object of interest, \na CALL node is created. CALL nodes are not unfolded dur\u00ading the creation of MOUGs (see Section 3.3.2). \nCall sites of other methods can be considered as start and join as well if the callee starts a thread \non any path, or joins a thread on all paths. We use a data .ow analysis to determine these properties \nfor all methods after the HSG is built. Figure 5(a) shows an OUG for the Example::main method, where \nthe object of interest is referenced by the .rst local variable (alias set l1), holding the return value \nof the allocation statement of the Shared object. The local variable that refers to the lock of the synchronized \nblock is l5, the global alias set representing class Example is g4.At the start of the symbolic execution \nof thread T1 (or more precisely, at step B in Figure 4), the MOUG in Figure 5(a) is copied and mapped \ninto the thread entry context, unify\u00ading alias sets l1 with g10 and l5 with g11. Consequently, the STORE \nevent (6) becomes an ESCAPE, because the target object g4, which stores the reference to g10, is shared. \nThe CALL event (3) is unlinked, and a copy of the MOUG in Figure 5(b) is inlined. The inlined nodes model \nevents that the constructor Shared::<init> issues to the object that is being initialized (the this reference \ncorresponds to alias set l0). MOUGs are created on demand during the symbolic ex\u00adecution and cached. \nFigure 5(a) and (d) are both MOUGs for the Example::main method; they represent however a view on di.erent \nsets of relevant objects, l1 and l2. Figure 5: Example MOUGs. 3.3.2 Inter-procedural analysis The analysis \nprocesses each abstract thread and its entry methods individually. The initial method context is deter\u00admined \nfrom the thread-entry method and the thread root object. The analysis ignores the control-.ow inside \nmeth\u00adods. During the traversal, the analysis keeps track of the abstract objects that are locked by the \nthread. The traver\u00adsal of methods with block monitors is handled as a special case and follows the basic \nblock structure such that the lock protection of individual statements is determined correctly. When \nthe symbolic execution of m encounters the .rst relevant event for an abstract object g, an initially \nempty OUG is created and associated with g. Before processing a statement, the analysis determines if \nan MOUG of method m in the current method context has already been mapped into the OUG of g. (The symbolic \nexecution maintains a mapping between method contexts and the corresponding subgraphs. This mapping and \nthe current statement allow the symbolic execution to determine the node in the OUG that corresponds \nto the current statement.) If not, the set L of local alias sets that correspond to g in the current \nmethod context is determined, then MOUG[m, L] is computed (Sec\u00adtion 3.3.1), cloned, and copied into the \nOUG of g. The symbolic execution treats call sites as follows: First, the method context of the callee \nis determined (see Section 3.2.2). At this point, the method context is complete re\u00adgarding the information \nabout which alias sets are global or shared. The method context of the callee allows to de\u00adtermine a \nset S of shared objects that are read, written or allocated by the call. For each abstract object in \ns . S,the appropriate MOUG of the callee is determined, considering aliasing at the call site (method \ncontext of the caller). This MOUG is inlined at the CALL node that corresponds to the current statement \nin the OUG of s. For polymorphic call sites, each target method is processed separately. At this point \nof the analysis, context sensitive type information associated with alias sets can be exploited to bound \npoly\u00admorphism. At a recursive call site, the symbolic execution reuses the method context of the corresponding \nactive call and does not descend further. The reuse of method contexts during the symbolic execution \nis discussed in more detail in Section 3.3.3. At a .eld or array access site, the current set of locks \nis attached to the access event in the a.ected OUG. At allocation sites, a counter is incremented in \nthe alias set that corresponds to the allocated objects. The incre\u00adment accounts for the uniqueness of \nthe allocating thread and whether the allocation or one of the call sites on the stack of the symbolic \nexecution is in a loop or recursion. In contrast to the way uniqueness has been determined for threads \n(Section 3.1), this method of tracking the multiplic\u00adity of objects is context-sensitive and hence more \nprecise. Information about the uniqueness of ordinary object is nec\u00adessary to determine lock protection \nin the con.ict analysis (Section 3.4). After the symbolic execution, an OUG is a disjoint set of subgraphs \nresulting from di.erent abstract threads. The events in the graphs are connected through control-.ow \nedges. Then, reference-.ow and thread-relation edges are added after the symbolic execution to create \na coherent graph from the subgraphs. A reference-.ow edge is added between STORE/ESCAPE and LOAD nodes \nthat specify the same abstract object as host (and do not stem from the same method context). In addition, \nthread-relation edges are added between corresponding TSTART/ENTRY and EXIT/TJOIN nodes. In the example \nprogram, the OUG of g10 in Figure 3 is combined from the MOUGs (a), (b) and (c) in Figure 5. 3.3.3 Optimizations \nThe symbolic execution can be the most expensive phase of the analysis because it considers all possible \n.ows through the call graph of the program. If all call sites are followed in a straight forward manner, \nthe worst case complexity of the symbolic execution is exponential in the number of call sites. The .rst \noptimization is to avoid repeated descents into calls with equivalent method, thread and locking contexts. \nThese three aspects of context in the symbolic execution are encoded in a site context SC: SC := .m, \n.a0, ..., an., tid, lockset. For the target method m of the call site, a0, ..., an are the actual parameters, \ntid is the id of the abstract thread that is processed, and lockset denotes the set of lock alias sets \nheld at the call site. The symbolic execution memorizes all processed call sites in terms of site contexts. \nAt a call site, actual parame\u00adters from the current method context, tid and lockset are matched with \nsite contexts of earlier invocations of m.In the matching, global alias sets are identi.ed with their \nunique id, other alias sets can be determined as fully local if only local alias sets are reachable through \ntheir .elds. A match means that the method tid, lockset,and allalias sets that are not fully local are \nequal; in that case, the symbolic ex\u00adecution does not descend into the call. This optimization resembles \ncall caching in functional languages [13], although our mechanism for matching is simpler. This .rst \noptimization has consequences that can deterio\u00adrate the precision of OUGs: The CALL node corresponding \nto a cached call site is not unfolded, but handled such that the subgraph of the earlier invocation is \ninlined. This pro\u00adcedure is safe with respect to the con.ict analysis in Section 3.4, because the happened \nbefore relation is weakened: The current site, the earlier site and all events in between will be deemed \nto happen concurrently. A second optimization is to avoid descents into methods that do not a.ect the \nstate of shared data. At a call site the analysis determines from the method context if shared data is \nallocated, read or written. A generic form of this at\u00adtribute is computed along the creation of method \nsummaries (Section 3.2.2).  3.4 Con.ict analysis The con.ict analysis determines con.icting events (as \nde\u00ad.ned in Section 2.3) in an OUG. Runtime actions of con\u00ad.icting events may participate in a data race. \nWe assume that events issued by static initializers are generally not con.icting. This assumption allows \nto bypass conservatism about the concurrency of init threads (Section 2.1) due to the lack of information \nabout implicit calls of static initial\u00adizers. The assumption makes the analysis unsound, i.e., po\u00adtentially \ncon.icting accesses that involve static initializers are not reported. In practice however, we found \nthat this assumption reduces the number of spurious reports and does not lead to underreporting for the \nprograms we investigated (Section 5). The con.ict analysis identi.es potentially con.icting PUT and GET \nevents in an OUG of object g in four steps: First, control .ow and reference .ow are considered: Events \nbetween a NEW and an ESCAPE event are safe be\u00adcause they happen before the object is accessible to threads \nother than the allocating thread, unless we detect that these events have a predecessor that is a successor \nto an ESCAPE. The second step considers thread-relation ordering: Events that are not successors of TSTART \nare safe if all of them are issued by the same unique thread. Similarly, events dominated by a TJOIN \nare safe if they are all issued by the same unique thread. Two restrictions apply however: A thread might \nbe started at several sites, and hence not all TSTART events of a thread may appear in the OUG of g (those \nthat happen before g is allocated could have been omitted). In this case, TSTART is not a safe indicator \nfor thread ordering. Moreover, a JOIN event is a safe thread relation information only if the joined \nthread is unique. In these cases, the TSTART or TJOIN nodes do not allow to infer protection properties \nfrom the ordering. In the third step, the remaining access events are checked for lock protection. If \nonly GET events remain, the object is classi.ed as readonly. Else, an object g is lock-protected if the \nintersection I of locksets of all events is not empty and one of the following cases applies: (1) All \naccesses to g are performed through the this-reference and g . I is held. (2) g is object-local, i.e., \nonly reachable through some hosting object h,and h . I. (3) There is a unique lock object u . I. The \nfourth step is only done if lock protection cannot be determined at the object level. Then accesses are \ndi.erenti\u00adated according to the .elds they target, and lock or readonly protection is determined for \nindividual .elds as in the third step. If all .elds are protected, the object is mix-protected, otherwise \nthe object is classi.ed as con.icting.  4. USE OF THE OUG This section explains how the .ndings of \nthe con.ict anal\u00adysis can be e.ciently exploited in the executing program. The goal is to distinguish \ncode that targets a con.icting ob\u00adject at runtime from code that targets safe objects. Hence the executedcode \nshoulddependonthe heap contextof the execution, and di.erent versions of the same method account for \ndi.erent classes of heap contexts (Section 4.1). The result of this code classi.cation is exploited by \na pro\u00adgram instrumentation that checks for object races during a program execution (Section 4.2). 4.1 \nMethod specialization In the view of OUGs, events originate at object access sites in the program code. \nTurning the view from objects to methods, the entirety of OUGs record the kinds of objects and the kinds \nof access that may happen at a speci.c ob\u00adject access site. The actual classi.cation thereby depends \non the heap context within which the method that performs the access is called. Specializations are created \nin 3 steps: (1) First, all heap contexts are identi.ed within which a method operates. Every heap context \nprovides a special\u00adization candidate. This information is recorded during the symbolic execution. Then, \nthe con.ict analysis determines the con.ict properties of abstract objects and individual ac\u00adcess sites. \n(2) Then specialization candidates are classi.ed and grouped according to the properties determined by \nthe con.ict analysis. (3) Finally, actual method specializations are determined and method invocation \nsites are adjusted to invoke specializations if necessary. In specialized methods, the resolution of \npolymorphic calls must consider not only the type/compile-time properties of the target object (as done \nwith di.erent variants of vtables), but also the calling context. Our implementation unfolds polymorphic \ncall sites as cascades of instanceof checks, introducing additional runtime overhead.  4.2 Object race \nchecker We have developed a program instrumentation that de\u00adtects object races [29] that occur at runtime. \nThe system is based on the checking of locksets for accesses to objects that are actually shared. For \nthe evaluation in Section 5.2, we use a simpli.ed version of the system in [29] (no second ownership) \nthat uses information from OUGs and optimizes the instrumentation through program transformation and \ndata-.ow analysis.     philo elevator mtrt sor tsp hedc mold ray monte program characteristics appl \nloc 81 528 11298 300 706 28299 1402 1972 3674 appl classes 2 5 34 7 4 48 11 19 19 lib classes 129 \n142 158 132 141 208 129 131 146 methods in call graph 192 311 722 205 302 1025 224 270 441 bytecodes \nin call graph 3605 6820 20137 4483 6481 24375 6531 5982 8161 user threads 2 2 2 3 2 5 2 2 2 method \nspec 68 118 578 16 108 3653 111 150 267          compilation resources shape analysis [s] 0.7 \n1.3 2.6 0.7 1.6 6.5 0.9 0.9 1.1 symb exec [s] 0.5 0.8 2.5 0.5 0.8 123.6 0.9 0.8 1.3 meth sites proc \n103 191 1090 50 168 29254 156 209 431 meth sites reused 85 163 1640 43 123 60233 244 285 452 meth sites \nnoe.ect 100 179 855 81 163 29423 136 174 358 con.ict analysis [s] 0.1 0.2 2.8 0.1 0.2 433.8 0.9 0.9 \n0.5 memory [MB] 0.5 3.0 14.7 0.5 1.5 263.5 1.5 3.4 3.8 Table 1: Benchmark characterization and compilation \nproperties. philo elevator mtrt sor tsp hedc mol ray monte     classi.cation of HSG nodes class \n131 147 192 139 145 256 140 150 165 inst 43 65 199 44 62 467 51 71 79 inst unique 29 43 122 31 39 \n356 33 35 51 shared 10 13 97 3 13 184 16 29 36 3 6 55 1 6 116 6 12 28 shared readonly shared lock-protected \n6 3 36 1 4 30 6 6 2 shared mix-protected 0 0 1 0 0 2 0 3 1 1 4 5 1 3 36 4 8 5 shared con.icting OUGs \nnodes max 217 327 1618 286 311 83052 537 302 726 nodes median 50 95 74 116 99 417 99 64 59 edges \nmax 435 689 6083 410 640 206456 616 616 2450 edges median 67 172 111 221 163 748 145 92 84 Table \n2: Characteristics of HSG and OUGs (no arrays).       5. EXPERIENCE We have implemented OUGs in \na Java-X86 way-ahead compilation environment. Our runtime system is based on GNU libgcj version 2.96 \n[12]. The numbers we present in the static and dynamic assessment refer to the overall program including \nlibrary classes, and excluding native code. The e.ect of native code for aliasing and object access has \nbeen modeled explicitly in the compiler. We use several multi-threaded benchmark programs [29] to evaluate \nthe cost and precision of our program analysis (Section 5.1) and to quantify the runtime consequences \non the example instrumentation for object race checking (Sec\u00adtion 5.2.3). philo is a simple Dining Philosopher \napplication. eleva\u00adtor is a real-time discrete event simulator that is used as an example in a course \non concurrent programming. Elevators are modeled as individual threads that poll directives from a central \ncontrol board. Communication through the control board is synchronized through locks. The con.guration \nwe used simulates 4 elevators. mtrt is a multi-thread raytracer from the JVM98 benchmark suite [28], \ncon.gured with 2 threads. sor (Successive Over-Relaxation over a 2D grid), and tsp (Traveling Salesman \nProblem) are data-and task\u00adparallel applications with data access patterns of scienti.c codes; synchronization \namong threads is based on fork-join rather than locks. hedc is a warehouse for scienti.c astro\u00adphysics \ndata developed at ETH [25]. This benchmark repre\u00adsents an application kernel that implements a meta crawler \nfor searching multiple Internet archives in parallel. In the benchmark con.guration, 4 principal threads \nissue random queries to 2 archives each. The individual queries are han\u00addled by reusable worker threads. \nThe workload of this ap\u00adplication kernel is typical for Internet server applications and similar to applications \nbased on alternative mechanisms, such as Java Servlets. The programs mol(dyn), ray(tracer), monte(carlo) \nare multi-threaded numeric applications from the Java Grande benchmarks [15]. 5.1 Compile-time characteristics \nTable 1 describes the benchmarks and the results of the program analysis. The lines of code appl loc \nand classes appl classes account only for the application, not for the Java library. lib classes speci.es \nthe number of library classes that an application is linked with. The number of methods is given in methods \nin call graph including native and abstract ones, bytecodes in call graph speci.es the size of the analyzed \ncode. The number of user threads speci.es the number of ab\u00adstract threads determined by the analysis, \nincluding the main-thread, not including init threads. Execution time and memory consumption of the compilation \nhave been mea\u00adsured on a Pentium IV 1.4 GHz; the implementation of the analysis has not been tuned. method \nspec speci.es the number of specializations that are generated for object race checking. method spec \nrelated to methods in call graph is an estimation for the code-bloat. The shape analysis creates method \nsummaries and pro\u00adcesses each (non-native, non-abstract) method in the call graph once. The symbolic \nexecution phase is optimized to reuse results from earlier passes through methods if possible. The number \nmeth sites proc speci.es how many method invocation have actually been followed during this phase of \nthe analysis. For all programs but hedc, the execution cost is on the order of a few seconds (and actually \nlower than, e.g., the cost to construct the call graph). As discussed in Section 3.3, two optimizations \nare possi\u00adble: meth sites reused,and meth sites noe.ect list how often these optimizations have been \ne.ective. We see that these optimizations make the symbolic execution phase practical and result in more \nthan linear gains of analysis time for larger programs (hedc, mtrt). The total saving is not just the \nnumbers reported under meth sites reused and meth sites noe.ect, but also includes nested calls that \nwould have been followed if the analysis had descended and processed these calls. The long duration of \nthe symbolic execution for hedc is due to the imprecision of available type and alias infor\u00admation. For \nthis benchmark, 31 methods (some of which are frequently used in di.erent contexts) are found in one \nstrongly connected component of the call graph. Due to the loss of context sensitivity, spurious aliasing \nis created in the HSG among unrelated objects, leading to further im\u00adprecision and conservative assumptions \nin the downstream analyses. If objects that are actually local to methods or threads become global or \nshared due to aliasing, this means fewer optimization opportunities and hence more work dur\u00ading the symbolic \nexecution. Rows class and inst in Table 2 specify the number of nodes in the shape graph that correspond \nto classes or (sets of) object instances (not including arrays). inst unique is the number of unique \nobjects of inst.Row shared quanti.es the subset of nodes that are accessed from several (non-init) threads \nor a non-unique user thread during the symbolic ex\u00adecution. Shared nodes are further distinguished according \nto the results of the con.ict analysis: Objects that are not writ\u00adten after they have escaped (determined \nby the OUG) are shared readonly (true for most alias sets that correspond to classes). Abstract objects \nwith lock protection are reported as shared lock-protected. shared con.ict speci.es those ab\u00adstract objects \nthat experience con.icting accesses without lock protection on di.erent .elds. Object that use di.er\u00adent \nprotection mechanisms for individual .elds, but have no con.icting .elds, are given in row shared mix-protected. \nTable 2 also reports the size of OUGs. For each program, we observe that there are a large number of \nsmall OUGs (median \u00ab max). Some OUGs are a lot larger than the median. As shown in Table 3, row max alloc \nsites per obj, there are some objects with a high degree of aliasing, and the OUGs of these objects are \nthe larger ones. This property is crucial for hedc, which has 21 exceptionally large OUGs (#nodes +#edges \n> 15000). Our implementation of the con.ict analysis only veri.es lock protection in these cases, and \nclassi.es 9 objects as safe and 12 as con.icting. Table 3 illustrates the precision of information in \nOUGs compared to other, more conservative variants for determin\u00ading object sharing. Rows global specify \nglobal objects that are read and written by the main or user threads, and the total number of allocation \nand access sites. Such informa\u00adtion could be reported by an escape analysis, e.g., [3, 6, 30]. Row r/w \nshared re.nes this set and only reports ob\u00adjects that are r/w accessed from multiple-threads as, e.g., \ndetermined by the analysis of Ruf [21]. In row OUG (lock protection), the the OUG-based con.ict analysis \nhas been simpli.ed (the .rst two steps in the con.ict analysis in Sec\u00adtion 3.4 are omitted and lock-protection \nis determined for all events in the graph). Finally the numbers for OUG (all) report the .ndings of the \ncomplete con.ict analysis. The reduction compared to r/w shared quanti.es the combined e.ect of considering \n(1) control-.ow inside a thread, (2) the inter-thread relations, and (3) lock protection. The percent\u00adages \ngiven in row improvement specify the saving compared to r/w shared. We also specify the average and maximum \nnumber of allocation sites corresponding to NEW events in the OUGs per abstract object. This numbers \nindicates the degree of aliasing encountered, which is particularly high for hedc. In addition, the total \nnumber of con.icting .elds and the average and maximum number of access sites cor\u00adresponding to GET and \nPUT events per .eld are given. The con.icts encountered by some abstract objects can be classi.ed into \nfour categories: 1. Row all writes locked speci.es cases where all writes are lock-protected (and reads \nare not). Most of such con\u00ad.icts could be identi.ed as benign access pattern for lazy initialization \n(double-checked locking [23]). One of the reports in tsp corresponds to a global variable for the minimal \ntour length found so far. The up\u00addates are monotone and double checked, and concur\u00adrent reads of outdated \ninformation are tolerated by the algorithm. Hences this actual race is benign. Another report corresponds \nto objects that represent route in\u00adformation. In the actual execution, writes are ordered with respect \nto reads due to higher level synchroniza\u00adtion, hence there is no actual race. 2. Row object local to \nthread speci.es critical objects that are thread roots or object local to a thread root object. All con.icts \nreported in this category turned out to be benign, because the a.ected variables and objects are accessed \nby a single runtime thread These reports result from the inability of the analysis to distinguish di.erent \nruntime instances of abstract threads that are not unique. 3. Row one lock but not unique speci.es cases \nwhere the lockset is non-empty, but the analysis fails to deter\u00admine the uniqueness of the locked object. \nIn elevator, e.g., the locks protecting the data structures of indi\u00advidual .oors are initialized in a \nloop and stored in an array. Despite the non-uniqueness of the lock in the compile-time view, the same \nlock instance consistently protects data for a certain .oor at runtime. All reports in this category \nhave been benign for the benchmarks. 4. The last category no common lock summarizes con.icts without \ncommon lock protection. In mtrt, a data race is found on the variable RayTracer::threadCount, which is \nhowever not rel\u00adevant to the execution of the program. In mol,two reports refer to objects that are actually \nthread-local to their non-unique allocating thread. Another con\u00ad.ict report for this benchmark is benign, \nbecause the con.icting access is done only by one of multiple run\u00adtime threads with a speci.c id (control \n.ow depends  on thread id). In ray, six reports correspond to ob\u00adjects that are initialized by the \nmain thread and conse\u00adquently associated with a speci.c instance of a worker thread that issues reads \nand writes. The con.ict ana\u00adlysis recognizes that events of the main thread do not participate in a con.ict; \nhowever, the worker thread is not unique and hence the analysis conservatively as\u00adsumes that the read \nand write events by the worker threads con.ict. For one reported object, a check\u00adsum is updated by the \nworker threads under common lock protection and read by the main thread after the worker threads are \njoined. The join is however not safely recognized, because the joined thread is not unique. In monte, \na data race is found on a variable that .ags if debug information should be printed. The race is benign, \nbecause the variable is always set to the same value. In hedc most reports are spurious for two reasons: \nSome critical objects are accessed from a non unique user thread; at runtime however, each instance is \na.liated with only one actual thread. Moreover, some critical objects are accessed by di.erent abstract \nthreads without lock protection. At runtime, an or\u00addering of these accesses is guaranteed by thread start \nand join, however the corresponding thread manage\u00adment events are not safely recognized by the con.ict \nanalysis. A true report points to an unsynchronized as\u00adsignment of null to a shared variable Task::thread \n, which could be read by another thread and lead to a NullPointerException. When investigating the cause \nof con.icts, the reports list allocation and access sites for con.icting objects. For most programs, \nthese lists are short, and the classi.cation of the con.ict allows easy analysis. For hedc, the scope \nof the inspection is enlarged due to aliasing.  5.2 Runtime aspects 5.2.1 Classi.cation of objects At \nruntime, we use a mechanism that precisely tracks ac\u00adcesses to objects from di.erent threads including \nlockset in\u00adformation [29]. This runtime information together with the compile-time information tagged \nto the object headers al\u00adlows to verify consistency between the results of the compile\u00adtime analysis \nand the actual runtime behavior. Objects that theruntime checker observed to beaccessed by morethan one \nthread are reported in Table 4 in row actually shared. The di.erence between shared and actually shared \ncan be re\u00adgarded as an indicator for the precision of our compile-time object classi.cation. There are \ntwo reasons for objects to be classi.ed as shared that never become actually shared at runtime: First, \nthere might be control-.ow paths that enable actual sharing but they have not been taken in the speci.c \nprogram run we report. Hence in this case, the di.erence between shared and non shared is caused by an \napplication property. Sec\u00adond, alias sets are conservatively classi.ed as global/shared during the creation \nof the HSG. This phenomenon is espe\u00adcially critical for methods that are part of a recursion, where context \nsensitivity is lost (details in [21]). The.rstaspectparticularly a.ects tsp: Worker threads that determine \nand rate tours in the graph topology main\u00adtain route information in objects. Depending on the overall \nlength of a tour, route information may be made available to other threads or may be dropped early by \nthe thread that created it. The second aspect particularly a.ects hedc, where our current implementation \nmakes conservative as\u00adsumptions in the treatment of a large recursion (Section 5.1). Row actually con.ict \nlists the number of object races that have been determined by the runtime checker. This number is always \nlower or equal to con.ict, and the di.erence is again an indicator for the precision of the static analysis. \nSome of the reported object races are not actual races since ordering is given through program properties, \ne.g., higher\u00adlevel synchronization. Some of the actual con.icts correspond however to real program defects \n(see static con.ict detection in Section 5.1, and [29, 7]). For mtrt, tsp,and monte, the actual con.icts \ncorrespond to real data races and have been already deter\u00admined by the static analysis (see Section 5.1). \nThe reports for ray do not re.ect real data races, due to an initialization before thread start ordering \n(see Section 5.1 why a static con.ict has been assumed nevertheless). Similarly, the re\u00adport on mol and \nmost reports of hedc do not correspond to real races. In the latter, result data produced by worker threads \nis collected from containers after these threads have been joined, and hence accesses to the containers \nare natu\u00adrally ordered. 5.2.2 Classi.cation of object accesses This section reports and quanti.es the \nruntime bene.t that is obtained from the precise classi.cation of objects and access sites. Table 5 lists \nthe dynamic number of .eld ac\u00adcesses according to a compile-time classi.cation of objects. In row stack-escape, \nall accesses to stack-escaping objects are counted, similarly for categories global and shared r/w. The \nlast two columns report accesses to objects that are identi.ed as con.icting based on their OUG. For \nrow con\u00ad.icting OUG .ow-insensitive, all .eld accesses to con.icting objects are counted. In row con.icting \nOUG .ow-sensitive, only accesses through con.icting access sites are counted. For most benchmarks, i.e., \nphilo, elevator, mtrt, tsp, hedc, and monte, information from OUGs helps to reduce the num\u00adber of accesses \nover shared r/w. Lock-protection, reference\u00ad.ow, and inter-thread ordering contribute to the improve\u00adment. \nFor some benchmarks, however, the analysis is not e.ective, mainly due to conservatism in the classi.cation \nof objects and their access sites. In mol, e.g., most of the ac\u00adcesses target small objects that are \nsolely accessed by the al\u00adlocating thread. The OUG that corresponds to these objects is nevertheless \nfound to be con.icting, because the objects are reachable through a .eld of the thread object (hence \nglobal), the accessing thread is not unique (hence shared), and the accesses do not happen under lock \nprotection (hence con.ict).  5.2.3 Object race checking Table 6 reports the dynamic frequency of access \nchecks in programs instrumented for object race detection (Section 4.2). The instrumentation associates \na check with certain critical .eld and method accesses; not all critical .eld accesses need to be instrumented \n(details in [29]). An access check is done in two stages: First, an inline check tests if the accessed \nobject is owned by the accessing thread; if so, execution can proceed. Otherwise, a lockset check veri.es \ncompliance with a certain locking policy. Rows inline and lockset in Table 6 report the corresponding \nnumbers. philo elevator mtrt sor tsp hedc mol ray monte global abstract objects 13 allocation sites \n18 access sites 135 38 55 526 91 117 1002 14 18 288 30 42 478 201 256 1954 25 27 963 39 56 466 54 59 \n399 r/w shared abstract objects 7 allocation sites 12 access sites 111 10 17 246 59 89 956 5 4 197 9 \n13 337 107 180 1818 14 19 899 24 43 408 20 29 252 OUG (lock protection) abstract objects 2 allocation \nsites 2 access sites 21 7 9 168 8 19 165 5 4 155 6 5 190 76 163 1387 8 7 751 18 31 254 20 29 216 OUG \n(all) abstract objects ... improvement (%) allocation sites ... improvement (%) access sites ... improvement \n(%) avg/maxalloc sites per obj. con.icting .elds avg/maxacc sites per .eld con.ict types all writes locked \nobject local to thread one lock but not unique no common lock 1 86 1 92 11 90 1.0/1 2 5.5/8 0 1 0 0 4 \n60 6 65 113 54 1.5/2 12 9.3/29 2 1 1 0 5 91 16 82 121 87 4.0/9 20 5.7/23 1 1 2 1 1 80 2 50 75 62 2.0/2 \n11 6.8/11 0 1 0 0 3 67 3 77 58 83 1.0/1 6 9.7/14 2 1 0 0 36 63 129 28 1110 38 4.1/63 198 4.8/33 11 2 \n8 15 Table 3: Static con.ict detection (no arrays). philo elevator mtrt sor tsp hedc mol 485 71 67 75 \n5 16 15 74 63 48 529 144 118 41 65 53 1.3/2 2.0/4 3.8/9 50 19 19 10.6/127 5.5/13 5.9/23 0 0 1 1 0 0 3 \n7 2 0 2 1 ray monte  shared allocated 11 43 440 4 10011 861 2064 2103951 20020 actually shared 8 37 \n15 4 375 207 5 345 20013 con.ict allocated 2 33 6 2 5002 491 2051 2103667 20007 actually con.ict 0 \n0 1 0 163 15 1 69 1 Table 4: Allocation of objects with their compile-time classi.cation and the actual \nsituation at runtime. The instrumentation has been applied with di.erent cri\u00adteria for determining critical \nobjects. The number of dy\u00adnamic inline checks decreases as the classi.cation of criti\u00adcal objects becomes \nmore precise (from row stack-escape to OUG). The magnitude of lockset checks follows this trend, the \nprecise number may however vary for di.erent program runs, depending on the thread schedule and the moment \nwhen objects become actually shared. A simple optimiza\u00adtion of the instrumentation is to cover more than \na single access with one check if accesses are not separated through thread synchronization. Rows OUG \noptimized report the resulting number of checks. For mtrt, hedc, mol and ray, the numbers are reduced \nsigni.cantly. In the case of mol, the static classi.cation of object accesses has not been suc\u00adcessful \nto reduce the number of critical .eld accesses (Table 5). Hence, depending on the kind of instrumentation, \ncon\u00adventional optimizations can be an e.ective complement to the static analysis for reducing the runtime \npenalty of an instrumentation. Table 7 quanti.es the execution overhead for object race checking on a \nPentium III, 933 MHz system. philo, elevator and hedc are not included since they are not CPU-bound; \nfor the other benchmarks, we report the average time of three runs. The base version orig and the instrumented \nver\u00adsions stack-escape, global, shared r/w,and OUG are compiled without optimization. The variants optimized \nand OUG op\u00adtimized are compiled with loop transformation, and PRE for expression and redundant load elimination. \nThe categories correspond to the those in Table 6. The execution overhead of the instrumentation stems \nfrom lockset checking operations at certain critical object ac\u00adcesses. In addition, the resolution of \npolymorphic calls in the instrumented versions creates overhead (Section 4.1): Despite only about 1000 \nruntime checks (Table 6), mtrt is slowed down due to frequent calls of specialized methods (Section 4.1). \n  5.3 Limitations The con.ict analysis considers only accesses from user threads (Section 2.1). Initializer \nthreads do not execute in separate runtime threads, but are invoked implicitly in the stream of some \nuser thread. Hence object ac\u00adcesses from initializer threads can also participate in con\u00ad.icts, and those \ncon.icts are not detected by our proce\u00addure. Our model does not consider the execution of .nalize methods \ninvoked from a separate .nalizer thread.Conse\u00adquently, our analysis of access con.icts does not take \nac\u00adcesses in the scope of .nalizer threads into account. philo elevator mtrt sor\u00d7106 tsp\u00d7106 hedc mol\u00d7106 \nray\u00d7106 monte      stack-escape global shared r/w 8479 4783 4728 20957 17347 17029 231.3\u00d7106 6.0\u00d7106 \n5.9\u00d7106 150.6 150.6 150.6 696.4 696.4 696.4 149413 39808 33480 1311.4 1311.4 1311.4 3443.5 3391.1 3391.1 \n313.1\u00d7106 651305 490049 con.icting OUG .ow-insensitive 136 10937 4578 150.1 521.5 27133 1310.0 2743.3 \n210017 con.icting OUG .ow-sensitive 116 8662 3509 150.1 274.7 18144 1303.5 2740.7 210017 Table 5: E.ect \nof the static analysis, number of .eld accesses to objects (no arrays). philo elevator mtrt sor tsp hedc \nmol\u00d7106 ray\u00d7106 monte stack-escape inline 3610 5919 225.2\u00d7106 598 244.2\u00d7106 26177 637.9 2413.5 774040 \nlockset 1163 2559 5839 344 174.9\u00d7106 4764 316.5 326.4 195062     global inline 2218 5421 935123 \n 572 244.2\u00d7106 12456 637.9 2377.3 340205 lockset 780 2548 2925 339 174.9\u00d7106 3294 316.5 326.4 160057 \nshared r/w inline 2257 5316 925564 509 244.2\u00d7106 11539 637.9 2377.3 340060 lockset 747 2527 816 303 \n174.9\u00d7106 3128 316.5 326.4 160019 OUG inline 3 2237 2331 5 69.2\u00d7106 7786 629.7 1941.5 40007 lockset \n0 2201 2196 0 5519 1595 314.4 0.2 1 OUG optimized inline 2 2193 1038 4 56.2\u00d7106 6513 420.1 856.8 40007 \nlockset 0 2181 906 0 4971 902 104.8 104.6 2 Table 6: E.ect of the optimization, number of dynamic checks \ndone for object race checking (no arrays). The approach of OUGs requires whole-program knowl\u00adedge and \nhence Java features like re.ection and dynamic class loading are not accommodated. Information obtained \nfrom TSTART and TJOIN events is used conservatively (Section 3.4). Additional information about thread \nordering, as could be obtained from annota\u00adtions or user input, would improve the precision of this anal\u00adysis \n(e.g., for hedc).  6. RELATED WORK An exhaustive survey on problems and current research in the analysis \nof multi-threaded programs is given by Rinard [20]. Concurrency analysis aims at approximating the order \nof statements executed by di.erent threads and computes the may happen in parallel (MHP) relation among \nstatements. Statements are however not distinguished according to their execution context and the accessed \ndata. The combination of MHP information with a model of program data (heap shape and reference information) \ncould be used to deter\u00admine con.icting data accesses. This approach is discussed by Midki. et al. [18], \nbut no compiler implementation re\u00adsults are yet available. OUGs naturally provide such an integration \nof control-and data-.ow information in context\u00adsensitive manner. Bristow et al. [5] used an inter-process \nprecedence graph for determining anomalies in programs with post-wait syn\u00adchronization. Taylor [27], \nand Duesterwald and So.a [9] ex\u00adtend this work and de.ne a model for parallel tasks in Ada programs with \nrendez-vous synchronization. The program representation in [9] is modular and allows to e.ciently an\u00adalyze \nprograms with procedures and recursion based on a data .ow framework. Masticola and Ryder [17] generalize \nand improve the approach of [9] and provide experimental evidence of the e.ectiveness of their technique. \nRecent work from Naumovich et al. [19] computes the potential con\u00adcurrency in Java programs at the level \nof statements. The authors have shown that the precision of their data-.ow al\u00adgorithm is optimal for \nmost of the small applications that have been evaluated; medium to large sized benchmark pro\u00adgrams have \nnot been studied. The approach requires that the number of real threads in the system is speci.ed as \ninput to the analysis; the handling of recursion is not described in the paper. OUGs borrow ideas from \nthe program representations pro\u00adposed in [5, 9]. However, OUGs partition the view on all program statements \ninto sets of accesses statements to in\u00addividual objects. This means a reduction in the size of the graphs \nwhich is crucial for con.ict analyses with superlinear complexity. Moreover, OUGs account for an object-oriented \nmodel of memory, threads, and locks, tailoring the analysis of methods with regard to the heap-execution \ncontext (Sec\u00adtion 3.3.2). Recent work of Choi et. al. [7] models concurrent threads in an interthread \ncall graph, which is an extension of a call graph including edges for thread start but not for thread \njoin. In addition, synchronized blocks are modeled explicitly by approximating locks held at call sites. \nThe interthread callgraph contains one node per method and hence, unlike OUGs, does not distinguish method \nexecu\u00adtions in di.erent thread-and heap-contexts. Sasha and Snir [24] have studied shared memory programs \nwith structured multi-threading where the scope of paral\u00adlelism is limited and known at compile time. \nThe focus is determining inter-thread dependencies introduced through shared data access. They developed \nan analysis that inserts a minimum number of memory fence instructions into pro\u00adgrams with data races, \nhence allowing sequentially consis\u00adtent executions of such programs on weak memory hardware. OUGs can \nhandle unstructured multi-threading as well. In object-oriented programs, access to shared data is typ\u00adically \ndone indirectly through references. In such an envi\u00adronment, program analysis faces more di.culties to \ndeter\u00admine the relation between threads and the data they access mtrt sor tsp mol ray monte no instrumentation \n base 20.8 3.8 8.9 20.6 49.4 23.4 optimized1 19.9 3.2 8.9 46.1 22.6 object race checking stack-escape \nglobal shared r/w OUG OUG optimized 41.7 29.6 29.0 28.5 (37%)  27.7 (39%) 3.9 3.9 3.9  3.9 (3%) 3.3 \n(3%) 23.8 23.8 23.9 10.3 (16%) 10.1 (14%) 64.0 65.5 65.4 66.0 (220%)  38.4 (86%) 116.1 111.5 110.9 \n82.7 (67%) 73.0 (58%) 41.5 41.3 42.0 40.9 (75%) 40.4 (79%) Table 7: Runtime in seconds and overhead \nof the program instrumentation (array access not instrumented). than in languages with limited pointer \nusage. Flow-sensitive pointer analysis has been extended to multi-threaded pro\u00adgrams by Rugina and Rinard \n[22]. Their algorithm for Cilk programs explicitly models the interference between parallel sections \nin the program and the additional aliasing created through this interference. Unlike Cilk, other object-oriented \nlanguages model concurrent activities themselves as objects, and hence the scope of concurrency is not \nlimited to a static program scope (unstructured concurrency). A starting point for the optimization of \nsuch programs is to determine the lo\u00adcality of objects with respect to allocating threads. Based on di.erent \nvariants of pointer analyses, escape analyses have been developed for Java, e.g., [2, 3, 6, 30]. OUGs \nextend this work and model locking, threads-and their interaction with objects explicitly. Other representations \nof parallel programs have been de\u00adsigned with speci.c optimizations in mind. Diniz and Ri\u00adnard [8], e.g., \nfocuses on the movement and elimination of lock-operations in automatically parallelized object-based \nprograms. Their analysis is based on an inter-procedural control .ow graph of all threads. This graph \nexplicitly mod\u00adels the structure of locking and protected program scopes. Data are modeled as read and \nwrite sets that are attributed to the individual nodes of the graph. The transformations require that \nthe program is free of data races, a condition met by automatically parallelized programs. Unlike OUGs, \nprotection of data against concurrent access is only deter\u00admined according to lock-protection and a known \nrelation between locks and protected code regions. Polymorphism and di.erent execution contexts of methods \nmake it di.cult to infer such a relation in typical object-oriented programs. OUGs, in contrast, compute \na relation between data and their protecting locks. All aforementioned approaches to relate threads and \nac\u00adcessed data, including OUGs, are based on data-and control-.ow information. Recent work on type systems \nhas shown that data protection and locking policies can also be codi.ed in data and method declarations \nthat are checked statically. The main advantage of this approach is its modu\u00adlarity, which makes it, \nin contrast to a whole program anal\u00adysis, well amenable to treat incomplete and large programs. Unlike \nOUGs, the application of these approaches to existing programs is not without di.culties: The type systems \nhave either been proposed as extensions to existing programming languages [1, 4], or require annotations. \nFlanagan and Fre\u00adund [10] present a type system that is able to specify and 1mol is very sensitive to \nthe cache layout of local variables and optimizations resulted in a performance degradation; for OUG \noptimized, loop transformations and PRE are disabled for this program. check lock-protection of individual \nvariables. In combina\u00adtion with an annotation [11] generator, they applied the type checker to Java programs \nof up to 450 KLOC. The annota\u00adtion generator is able to recognize common locking patterns and further \nuses heuristics to classify as benign certain ac\u00adcesses without lock protection. The heuristics are e.ective \nin reducing the number of spurious warnings; some are however unsound (but this property has not been \na problem for the benchmarks investigated in [11]). OUGs model the reach\u00adability of objects explicitly \nand recognize cases of isolation beyond lock-protection that are covered by the heuristics automatically. \nThe number of clustered warnings generated per KLOC is of the same magnitude as the reports we obtain \nfor our benchmarks.  7. CONCLUSION The Object Use Graph is a concise extension of the Heap Shape Graph \nand provides a model of the runtime structure and the interaction of shared objects in the context of \ndi.er\u00adent threads. The OUG builds on previous work on pointer analysis and extends points-to information \nwith information about the temporal relation of accesses. This information is thread-sensitive and approximates \nthe complete set of pos\u00adsible accesses at runtime. We have implemented OUGs for a way-ahead compilation \nsystem for Java. A .rst evalu\u00adation for a set of non-trivial Java programs demonstrates that OUGs can \nbe constructed with acceptable e.ort and that they produce tangible bene.ts for compilers and users. \nOUGs provide information that is more precise than what can be obtained by analyses that do not model \nthe temporal relationships. As a result, fewer accesses are approximately classi.ed as con.icting, so \na compiler that wants to draw the user s attention to those (possibly erroneous) accesses has fewer accesses \nto report. A runtime bene.t can be realized as well if the compiler wants to insert dynamic checks to \nreport actual sharing; there are fewer access sites to instrument. As multi-threading is embraced by \nmore users (and .nds its way into future processor architectures), there will be increased demands on \nthe compiler to provide reporting of access con.icts or to optimize placement and kinds of syn\u00adchronization \noperations. OUGs are a solid foundation for concurrence-aware compilation systems. 8. ACKNOWLEDGMENTS \nWe thank Matteo Corti and Florian Schneider for their contributions to the compiler infrastructure and \nthe referees for their detailed and insightful comments. 9. REFERENCES [1] D. Bacon, R. Strom, and A. \nTarafdar. Guava: A dialect of Java without data races. In Proc. Conf. Object-Oriented Programming, Systems, \nLanguages, and Applications (OOPSLA 00), pages 382 400, Oct. 2000. [2] B. Blanchet. Escape analysis for \nobject-oriented languages -Application to Java. In Proc. Object-Oriented Programming, Systems, Languages, \nand Applications (OOPSLA 99), pages 20 34, Nov. 1999. [3] J. Bogda and U. H\u00a8olzle. Removing unnecessary \nsynchronization in Java. In Proc. Conf. Object-Oriented Programming, Systems, Languages, and Applications \n(OOPSLA 99), pages 35 46, Nov. 1999. [4] C. Boyapati, R. Lee, and M. Rinard. Ownership types for safe \nprogramming: preventing data races and deadlocks. In Proc. Conf. Object-Oriented Programming, Systems, \nLanguages, and Applications (OOPSLA 02), pages 211 230, Nov. 2002. [5] G. Bristow, C. Dreay, B. Edwards, \nand W. Riddle. Anomaly detection in concurrent programs. In Proc. Intl. Conf. on Software Engineering \n(ICSE 79), pages 265 273, 1979. [6] J. Choi, M. Gupta, M. Serrano, V. Sreedhar, and S. Midki.. Escape \nanalysis for Java. In Proc. Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA \n99), pages 1 19. ACM Press, Nov. 1999. [7] J.-D. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, \nand M. Sridharan. E.cient and precise datarace detection for multithreaded object-oriented programs. \nIn Conf. Programming Language Design and Implementation (PLDI 02), pages 258 269, June 2002. [8] P. Diniz \nand M. Rinard. Synchronization transformation for parallel computing. In Proc. Symp. Principles of Programming \nLanguages (POPL 97), pages 187 200, Jan. 1997. [9] E. Duesterwald and M. So.a. Concurrency analysis in \nthe presence of procedures using a data-.ow framework. In Proc. Symp. Testing, Analysis and Veri.cation \n(TAV4), pages 36 48, 1993. [10] C. Flanagan and S. Freund. Type-based race detection for Java. In Proc. \nConf. Programming Language Design and Implementation (PLDI 00), pages 219 229, June 2000. [11] C. Flanagan \nand S. Freund. Detecting race conditions in large programs. In Proc. Workshop Program Analysis for Software \nTools and Engineering (PASTE 01), pages 90 96, June 18 19 2001. [12] GNU Software. gcj -The GNU compiler \nfor the Java programming language. http://gcc.gnu.org/java, 2000. [13] A. Heydon, R. Levin, and Y. Yu. \nCaching function calls using precise dependencies. In Proc. Conf. Programming Language Design and Implementation \n(PLDI 00), pages 311 320, June 18 21 2000. [14] C. Hoare. Monitors: An operating system structuring concept. \nCommunications of the ACM, 17(10):549 557, Oct. 1974. [15] Java Grande Forum. Multi-threaded benchmark \nsuite. http://www.epcc.ed.ac.uk/javagrande/, 1999. [16] L. Lamport. How to make a correct multiprocess \nprogram execute correctly on a multiprocessor. IEEE Trans. on Computers, 46(7):779 782, July 1997. [17] \nS. Masticola and B. Ryder. Non-concurrency analysis. In Proc. Symp. Principles and Practice of Parallel \nProgramming (PPoPP 93), pages 129 138, 1993. [18] S. Midki., J. Lee, and D. Padua. A compiler for multiple \nmemory models. In Rec. 9th Workshop Compilers for Parallel Computers (CPC 01), June 2001. [19] G. Naumovich, \nG. Avrunin, and L. Clarke. An e.cient algorithm for computing MHP information for concurrent Java programs. \nIn Proc. 7th European Software Engineering Conf. and 7th Symp. Foundations of Software Engineering, pages \n338 354, Sept. 1999. [20] M. Rinard. Analysis of multithreaded programs. In Proc. Static Analysis Symp. \n(SAS 01), July 2001. [21] E. Ruf. E.ective synchronization removal for Java. In Proc. Conf. Programming \nLanguage Design and Implementation (PLDI 00), pages 208 218, June 2000. [22] R. Rugina and M. Rinard. \nPointer analysis for multithreaded programs. In Proc. Conf. Programming Language Design and Implementation \n(PLDI 99), pages 77 90, May 1 4, 1999. [23] D. Schmidt and T. Harrison. Double-checked locking: An optimization \npattern for e.ciently initializing and accessing thread-safe objects. In F. Buschmann, R. Martin, and \nD. Riehle, editors, Pattern Languages of Program Design (PLoP) 3, pages 363 375, 1998. [24] D. Shasha \nand M. Snir. E.cient and correct execution of parallel programs that share memory. ACM Trans. on Programming \nLanguages and Systems, 10(2):282 312, Apr. 1988. [25] E. Stolte, C. von Praun, G. Alonso, and T. Gross. \nScienti.c data repositories designing for a moving target. In Proc. Conf. ACM SIGMOD/PODS, June 2003. \n[26] V. Sundaresan, L. J. Hendren, C. Raza.mahefa, R. Vall\u00b4ee-Rai, P. Lam, E. Gagnon, and C. Godin. Practical \nvirtual method call resolution for java. In Proc. Object-Oriented Programming, Systems, Languages, and \nApplications (OOPSLA 00), pages 264 280, Oct. 15 19 2000. [27] R. Taylor. A general purpose algorithm \nfor analyzing concurrent programs. Communications of the ACM, 26(5):362 376, May 1983. [28] The Standard \nPerformance Evaluation Corporation. SPEC JVM98 Benchmarks. http://www.spec.org/osg/jvm98, 1996. [29] \nC. von Praun and T. Gross. Object race detection. In Proc. Object-Oriented Programming, Systems, Languages, \nand Applications (OOPSLA 01), pages 70 82, Oct. 2001. [30] J. Whaley and M. Rinard. Compositional pointer \nand escape analysis for Java programs. In Proc. Object-Oriented Programming, Systems, Languages, and \nApplications (OOPSLA 99), pages 187 206, Nov. 1999.   \n\t\t\t", "proc_id": "781131", "abstract": "A compiler for multi-threaded object-oriented programs needs information about the sharing of objects for a variety of reasons: to implement optimizations, to issue warnings, to add instrumentation to detect access violations that occur at runtime. An Object Use Graph (OUG) statically captures accesses from different threads to objects. An OUG extends the Heap Shape Graph (HSG), which is a compile-time abstraction for runtime objects (nodes) and their reference relations (edges). An OUG specifies for a specific node in the HSG a partial order of events relevant to the corresponding runtime object(s). Relevant events include read and write access, object escape, thread start and join.OUGs have been implemented in a Java compiler. Initial experience shows that OUGs are effective to identify object accesses that potentially conflict at runtime and isolate accesses that never cause a problem at runtime. The capabilities of OUGs are compared with an advanced program analysis that has been used for lock elimination. For the set of benchmarks investigated here, OUGs report only a fraction of shared objects as conflicting and reduce the number of compile-time reports in terms of allocation sites of conflicting objects by 28--92% (average 64%). For benchmarks of up to 30 KLOC, the time taken to construct OUGs is, with one exception, in the order of seconds.The information collected in the OUG has been used to instrument Java programs with checks for object races. OUGs provide precise information about object sharing and static protection, so runtime instrumentation that checks those cases that cannot be disambiguated at compile-time is sparse, and the total runtime overhead of checking for object races is only 3--86% (average 47%).", "authors": [{"name": "Christoph von Praun", "author_profile_id": "81325490306", "affiliation": "ETH Z&#252;rich, Z&#252;rich, Switzerland", "person_id": "PP40026858", "email_address": "", "orcid_id": ""}, {"name": "Thomas R. Gross", "author_profile_id": "81332502168", "affiliation": "ETH Z&#252;rich, Z&#252;rich, Switzerland", "person_id": "PP43125826", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/781131.781145", "year": "2003", "article_id": "781145", "conference": "PLDI", "title": "Static conflict analysis for multi-threaded object-oriented programs", "url": "http://dl.acm.org/citation.cfm?id=781145"}