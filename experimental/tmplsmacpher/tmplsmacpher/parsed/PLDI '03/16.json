{"article_publication_date": "05-09-2003", "fulltext": "\n A Provably Sound TAL for Back-end Optimization . Juan Chen Dinghao Wu Andrew W. Appel Hai Fang Princeton \nUniversity Yale University {juanchen, dinghao, appel}@cs.princeton.edu hai.fang@yale.edu ABSTRACT Typed \nassembly languages provide a way to generate machine\u00adcheckable safety proofs for machine-language programs. \nBut the soundness proofs of most existing typed assembly lan\u00adguages are hand-written and cannot be machine-checked, \nwhich is worrisome for such large calculi. We have de\u00adsigned and implemented a low-level typed assembly \nlanguage (LTAL) with a semantic model and established its soundness from the model. Compared to existing \ntyped assembly lan\u00adguages, LTAL is more scalable and more secure; it has no macro instructions that hinder \nlow-level optimizations such as instruction scheduling; its type constructors are expres\u00adsive enough \nto capture data.ow information, support the compiler s choice of data representations and permit typed \nposition-independent code; and its type-checking algorithm is completely syntax-directed. We have built \na prototype system, based on Standard ML of New Jersey, that compiles most of core ML to Sparc code. \nWe explain how we were able to make the untyped back end in SML/NJ preserve types during instruction \nselection and register allocation, without restricting low-level optimiza\u00adtions and without knowledge \nof any type system pervading the instruction selector and register allocator. Categories and Subject \nDescriptors F.3.1 [Theory of Computation]: Logics and Meanings of Programs specifying and verifying and \nreasoning about programs; D.3.4 [Software]: Programming Languages pro\u00adcessors, compilers General Terms \nLanguages, Veri.cation  Keywords Typed Assembly Language, Proof-Carrying Code .This research was supported \nin part by DARPA award F30602-99-1-0519. Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 03, June 9 11, 2003, San Diego, California, USA. Copyright 2003 \nACM 1-58113-662-5/03/0006 ...$5.00. 1. INTRODUCTION The idea of Proof-Carrying Code (PCC) [18] is that \nthe compiler should produce machine code accompanied by a proof of safety. A weakness of previous PCC \nsystems is that the proof-checking infrastructure is too complex to prove sound. We have built the .rst \ncompiler that produces ma\u00adchine code accompanied by safety proofs that are machine\u00adcheckable in a simple \nlogic from minimal axioms. Most PCC compilers, including ours, are based on typed intermediate languages \nor Typed Assembly Language (TAL) [17], which provide a way to generate safety proofs auto\u00admatically. \nTAL has a soundness guarantee: If a TAL pro\u00adgram type-checks and there is no bug in the assembler, the \nmachine code is safe to execute. Soundness is proved as a metatheorem outside of the proving system; \nthe proof is hand-written and not machine-checkable. The typing rules and the type checker are in the \ntrusted computing base (TCB), that is, bugs in these components can let unsafe code slip past the checker. \nThere have been many variants of TAL [15, 23, 16], which rely on similar soundness metatheorems. A recent \nvariant [10] has a machine-checkable metatheorem. It is hard to manage the soundness proofs and avoid \nerrors when scaling up to realistic type systems for real compilers. The goal of the Foundational Proof-Carrying \nCode (FPCC) [2] project at Princeton is to build machine-checkable safety proofs for machine-code programs \nfrom the minimal set of axioms. We have designed a low-level typed assembly lan\u00adguage (LTAL) to be the \ninterface between the compiler and the checker: the compiler compiles a source program to ma\u00adchine code \nannotated by an LTAL program. This paper focuses on the LTAL interface and the com\u00adpiler. Our design \nand implementation has the following de\u00adsirable properties, some of which are shared by some other TAL \nand PCC systems (see Figure 1 and Appendix A): Compiles a real source language. We have built a compiler \nfor almost all of core ML a full-scale source language with polymorphic higher-order functions, disjoint\u00adsum \nrecursive datatypes, and so on. Compiles to a real target machine. We generate high-quality Sparc code. \nFoundational speci.cation. We have a concise logical speci.cation, independent of any type system, of \nthe safety property guaranteed by our system: in our prototype we guarantee memory safety and that only \na certain subset of Sparc instructions will be executed [2]. Furthermore, our speci.cation relates to \nthe actual machine language to be executed not assembly language we model (and check) instruction encodings \nexplicitly. Key: . partially .\u00b7 nearly completely 1 2 3 456 7 8 91011 SpecialJ [9] . TALx86 [17] .\u00b7 \n. . .. DTAL [23] FTAL [12] .\u00b7 TALT [10] .\u00b7 .\u00b7 . Our LTAL .\u00b7 .\u00b7 .\u00b7 Figure 1: Comparison of typed assembly \nlanguages (see Appendix A) Machine-checked proof. We have a machine-checked proof (mostly .nished) of \nthe soundness of our system that is, if the LTAL type-checks, the machine code is safe. Unlike any other \nTAL or PCC system, our proof is with respect to a minimal set of axioms, the largest part of which is \na speci.cation (in logic) of the instruction set architecture of the Sparc processor. Minimal checker. \nJust in case you are worried about bugs (or Trojan horses) in proof checkers, our soundness proof is \ncheckable in a very minimal logic: the trusted base of our system (including axioms, machine speci.cation, \nand a C program implementing LF checking) is less than 2700 lines of code [5, 22], an order of magnitude \nsmaller than other systems. Atomicity. Some other TALs have macro instruction sequences (or even worse, \ncalls to the runtime system) for compare-and-branch, or datatype tag-checking, or memory allocation. \nThis inhibits optimizations such as hoisting and scheduling.1 Each of our LTAL instructions corresponds \nto at most one machine instruction. Compiler can choose data representations. For data structures such \nas tagged disjoint sums, a compiler may want to exercise discretion in choosing data layouts, unhampered \nby assumptions built into a typed assembly language. LTAL permits this .exibility; some other TALs do \nnot. Data.ow &#38; induction analysis. LTAL includes ex\u00adistential and singleton types that are powerful \nenough to permit data.ow-based safety proofs of optimized machine code (though our prototype compiler \ndoes not exploit all of this power yet). Position-independent code. To avoid the need to trust a linker, \nwe show how to check typed position-independent code even in the presence of long jumps and of operations \nthat move code addresses into pointer variables and closures. Basic blocks. LTAL groups instructions \ninto basic blocks, 1These optimizations can be done in the assembler, but need to be trusted bug-free, \nwhereas our system does not need to trust them. Compiles real source languageCompiles to real target \nmachineFoundational speci.cationMachine-checked soundness proofMinimal checker AtomicityCompiler can \nchoose data reprs.Data.ow analysisPosition-independent codeBasic blocksSyntax-directed checking making \nit easy for an optimizing compiler to reorder blocks to optimize cache placement or shorten span-dependent \nin\u00adstructions. Syntax-directed. Typechecking LTAL is syntax-directed; that way, if a compiler generates \na well-typed LTAL pro\u00adgram it doesn t have to worry about whether the checking algorithm will be smart \nenough to .nd a proof. 2. OVERVIEW OF FPCC Necula s PCC system [18] constructs for untrusted code a \nveri.cation condition (VC), which has the property that if VC holds with regard to the logic axioms and \nthe typ\u00ading rules, the program is safe. A VC generator (VCGen) is used by both the code producer and \nthe code consumer to construct VCs. VCGen examines a machine-code pro\u00adgram instruction by instruction \nand calculates the weakest preconditions for each instruction in Hoare-logic style. This VC-based veri.cation \nbuilds the type system and machine instruction semantics into the algorithm for formulating the safety \npredicate. VCGen must be trusted to generate the right formula, but it is a large program (23,000 lines \nof C code [6]), thus di.cult to guarantee bug-free. 2.1 FPCC The motivation of Foundational PCC is to \nmake the TCB as small as possible, without committing to any speci.c type system. We believe that the \nsmaller the TCB, the more con\u00ad.dence PCC users can have. Our TCB consists of the spec\u00adi.cation of the \nsafety policy, machine instruction semantics, and the proof checker. In the current implementation, it \nis less than 2,700 lines of code [5, 22], of which more than half is the speci.cation of the Sparc instruction \nset architecture. To make the TCB minimal, we choose Church s higher-order logic with a few axioms of \narithmetic, give types a semantic model to move the type system out of the TCB, and model machine instructions \nby a step relation between machine states; we avoid VCGen entirely [3]. In order to support contravariant \nrecursive datatypes and mutable .elds, we model types as predicates on states, ap\u00adproximation indices \n[4], and type levels [1]. We have an abstraction layer, Typed Machine Language (TML) [20], to hide the \ncomplex semantic models for types. TML pro\u00advides a rich set of constructors for types, type maps, and \ninstructions, and an orthogonal set of primitive type con\u00adstructors such as union, intersection, existential \nand univer\u00adsal quanti.cation, and so on. TML is so expressive that type-checking for it is undecidable; \nit is more a logic than a type system. However, it is very useful for building seman\u00adtic models of higher-level, \napplication-speci.c type systems such as LTAL: we give LTAL constructors a semantic model in terms of \nTML. The soundness of LTAL typing rules is proved not by a metatheorem as in TAL, but by their semantic \nmodel [21], bottom up: .rst we use higher-order logic with axioms for arithmetic to prove lemmas about \nmachine instructions and types, then we prove the TML typing rules based on these lemmas, then we prove \nthe soundness of LTAL typing rules in the TML model. Each typing rule is represented as a derived lemma \nin our logic. LTAL bene.ts from its semantic model in many aspects: .rst, it is more scalable. Adding \nnew rules that can be described in our semantic model generally does not a.ect the soundness of existing \nrules, which we found very useful ML program LTAL Machine Program Code OK! STATIC PROOFSCOMPILATION \n|Components described in this paper| TCB Figure 2: Foundational PCC Framework in evolving the design. \nSecond, it is more secure because the typing rules are moved out of the TCB. Third, TML connects LTAL \nto real machine instruction semantics, thus bridges the gap between typed assembly language and ma\u00adchine \nlanguage. The FPCC framework is shown in Figure 2. A source program is compiled into a machine-code program \nand an LTAL program. The code consumer receives the LTAL rules, along with their soundness proof; checks \nthe soundness proof [5, 22]; and then runs the LTAL checker, which is a simple computation (like Prolog \nbut without backtracking and with only a very limited form of uni.cation). LTAL is not intended as a \nuniversal TAL. Instead, it is extensible. Our semantic modeling technique is very mod\u00adular. New operators \ncan be added to LTAL (and proved sound) without disturbing the soundess proofs for existing operators, \nas long as the new operators conform to the as\u00adsumptions in the semantic model. We started with a very \nsimple model [3], and when we added contravariant recursive types [4] and mutable record .elds [1] these \nchanges did vio\u00adlate previous assumptions and require nonmodular rewrites. But now our model is very \npowerful and general: none of the existing LTAL soundness proofs will need to be touched when we add \noperators to handle extensible sums, various kinds of exception handling mechanisms, various kinds of \nmultidimensional arrays (with or without pointer indirec\u00adtions), or arbitrary predicates on scalar values. \n 2.2 FPCC-ML Compiler Our compiler transforms core ML (ML without the mod\u00adule system) into Sparc code \nwith LTAL annotations. At present our prototype omits exceptions, arrays, and strings. We have built \nour compiler based on the Standard ML of New Jersey system. There are several stages: the front end of \nSML/NJ trans\u00adlates source ML programs to FLINT (a typed intermediate language based on Fw) [19]; we have \nreused the FLINT front end. Our newly built typed CPS-conversion and closure con\u00adversion phases generate \nNFLINT (a typed intermediate lan\u00adguage like Morrisett s sC [17]). The next few phases break down complex \ninstructions, build basic blocks, and insert coercions to get machine-independent LTAL programs. The \nback end takes machine-independent LTAL, and produces machine code with machine-speci.c LTAL annotations \nand some auxiliary information, such as mapping from labels to their addresses. SML/NJ s back end uses \nthe untyped MLRISC retar\u00adgetable instruction selection, register allocation, and low\u00adlevel optimization \nsoftware [11]. The di.culty is to make MLRISC preserve and manipulate type information, with\u00adout rewriting \nthe MLRISC or making it dependent on our particular type system. Fortunately, MLRISC already had some \nsupport for an annotation mechanism [13] that per\u00admits comments on the instructions; we have generalized \nthis mechanism and used it to propagate types. 2.3 Checker Our checker has two main components. First, \nit uses a simple LF type-checker to check a proof, in higher-order logic, of the soundness of the LTAL \ntyping rules [5, 22]. We can view these LTAL rules as a set of lemmas. On the other hand, the LTAL rules \ncan be regarded as a set of Prolog-like clauses. Then, because these rules are syntax-directed, the checker \ncan run a very simple subset Prolog interpreter (without backtracking and with only a limited form of \nuni.cation) on these rules to type-check the machine-language program [5, 22]. The LTAL program is only \nan untrusted hint so that the checker can take advantage of type and data.ow in\u00adformation from the compiler \nin proving the safety of the machine code. The process of running the checker on a machine code and the \ncorresponding LTAL program is like type-checking the machine code according to structural in\u00adformation \nfrom the LTAL program. The overall goal of the checker is judge_prog H P where P is the binary code (a \nsequence of instruction words) and H is the correspond\u00ading LTAL program. The predicate judge prog characterizes \nwell-typedness. The checker solves this goal according to the structure of H. In the underlying semantic \nmodel, we can prove that well-typedness implies safety: judge_prog H P -> safe_program P. The predicate \nsafe program is the machine-level safety pol\u00adicy. When the checker succeeds on the goal judge prog H \nP, we apply this lemma to get a proof of safe program P.  3. LTAL We have designed our own typed assembly \nlanguage be\u00adcause we want to generate safety proofs of machine code, with as much .exibility as possible \nfor an optimizing com\u00adpiler. Thus, even part-way through a sequence of instruc\u00adtions that allocates on \nthe heap or that does datatype-tag discrimination, the LTAL type system must be able to de\u00adscribe the \nmachine state. That is, LTAL has no macro in\u00adstructions: each LTAL instruction corresponds to one Sparc \ninstruction (or is a coercion with no runtime e.ect). Be\u00adcause no sequence of instructions is unbreakable, \nlow-level optimizations such as instruction scheduling are permissible (however, at present our LTAL \ndoes not accommodate the .lling of branch-delay slots on the Sparc). Macro instruc\u00adtions in other TALs \n(such as malloc and test-and-branch)   T ::= t |T|. | int |.t.T | \u00b5t.T | boxed Types | n\u00af| intt T | \n.eld iT | T1 = T2 | T1 . T2 | codeptr[t1,... ,tj ](m,cc, v1 : T1,... ,vn : Tn) | addr(l) | di.(l1,l2) \n| defcc ::= cc cmp(T1,T2) Cond.Codes | cc testm(m) | cc none v ::= x | i | l | c(v) | vdi.(l1,l2) Values \nc ::= cid | c1 . c2 | cpack(T1,T2) Coercions | cfold[T] | cunfold | crange[n1,n2] | cinj1 T | cinj2 T \n| cproj1 | cproj2  | cunion(c1,c2) | cinters(c1,c2) | cname | cdefop ::= + |-|.| / Arith. Ops . ::= \n= | =*| > |: | < |: Arith. Compares Instructions i ::= (t, v.) = open(v) no instruction | v . = v move, \nor nop | v = v1 op v2 ALU instructions | v = sethi(n) sethi | store(vi,v) store | v = record move | inc \nalloc(v) add | v = load(v1,v2) load | v = addradd(v1,v2) add | call(v, [T1,... ,Tn]) jump | calln(l, \n[T1,... ,Tn]) fall through \u00df | cmpcc(v1,v2) subcc \u00df | (t, v1. ) = cmpcci(v1,v2) subcc \u00df | testm(n) subcc \n\u00df | if(.) then l1 else l2 branch \u00df | ifr(.){v} then (v1,l1) else (v2,l2) \u00df | i.ull then l1 else l2 \u00df \n| iftag(.){v} then (v1,l1) else (v2,l2) Basic block B ::= l[t1,... ,tj](m, cc, v1 : T1,... ,vn : Tn)= \ni1; ... ; ik LRT ::= (L, R, T ) Environments L ::= {l1 .n a1,... ,ln .n an} label map R ::= {x1 .n r1,... \n,xn .n rn} register map T ::= {1 .n T1,... ,n .n Tn} type abbrev. map P ::= (LRT, B.) Program Figure \n3: LTAL Syntax. Marked \u00df operators are speci.c to machines with condition codes. that expand to a .xed \nsequence of machine instructions, in\u00adterfere with low-level optimization. 3.1 Syntax LTAL is a calculus \nwith conventional features such as vari\u00adable names and scoping rules. The LTAL syntax is shown in Figure \n3. LTAL supports .rst-order kinds; it has only limited support for higher-order kinds, since TML does \nnot model higher-order kinds in full generality. For core ML, this is enough. LTAL has a set of standard \ntypes: type variables2, top and bottom types, integer types, existential types, and recursive types. \nWe give type boxed to pointers pointing to heap values. There are low-level constructors to model high-level \nab\u00ad 2In our implementation we use de Bruijn indices, but in this presentation we will show named variables. \n stractions, such as singleton integer type \u00afn and re.ned in\u00adteger type intt n\u00affor integers (i has type \nintt n\u00afmeans i.n is true, where . is a predicate on integers such as = or :), .eld types, intersection \ntypes and union types for records and user-de.ned datatypes. To model basic blocks (with their live variables) \nand func\u00adtions (with their formal parameters) we have polymorphic code pointer types codeptr[t.](m, cc, \nv1 : T1,... ,vn : Tn). where t.is a list of type variables, m is the available memory size known at this \npoint, cc is the condition code require\u00adment, and vi : Ti are the input arguments. For label arithmetic \nwe have type constructors addr and di., which will be explained further in Section 3.7.  Type def refers \nto a type expression by a name; in our implementation, names are just integers. Each program can have \na sequence of type abbreviations that give names to type expressions. This mechanism makes LTAL programs \nconcise, and saves the checker some work. The checker ex\u00adpands a name to the type expression it stands \nfor only when such expansion is needed. Otherwise, the checker simply passes the name around, which is \nmore e.cient than pass\u00ading the type expression. We have a special category cc to capture the condition \ncodes status (on machines with condition codes), which in\u00adcludes cc cmp for comparison, cc testm for \nmemory avail\u00adability testing, and cc none for arbitrary status. A value can be a variable x, an integer \ni, a label l,a coerce value c(v), or a vdi. value. We use variables to track aliases of registers. Di.erent \nvariables with di.erent types can be assigned the same register, indicating di.erent views of the same \nregister to the type-checker. Value constructor vdi. and type constructors addr and di. are used for \ntyped position-independent code. Their meaning is explained in Section 3.7. Coercions are used to change \nthe type of values; all coer\u00adcions are free of runtime e.ect, as they follow subtyping relations in the \nunderlying model. Many of these coer\u00adcions are conventional, such as identity, composition, pack, fold/unfold, \ninject, and project. Coercion rules are further discussed in Section 3.5. LTAL has a machine-independent \ncore, which includes: move and ALU instructions, sethi for loading large integers, store, record, and \ninc alloc for heap allocation, calln for call by fall-through, (which generates no code), and addradd \nfor address arithmetic. Each target machine re\u00adquires the addition of machine-speci.c operators and rules. \nThe instructions in LTALSparc that are speci.c to machines with condition codes are: cmpcc compares two \nintegers and sets condition codes; cmpcci compares a value with a compile-time-known integer, sets condition \ncodes and re\u00ad.nes the type of the value; testm tests for out-of-heap; if is normal conditional branch \nwithout type re.nement; ifr is conditional branch with type re.nement in both branches, and i.ull and \niftag specialize type re.nement for memory allocation and datatype tag discrimination, respectively. \nFunction declaration l[t.](m, cc, v1 : T1,... ,vn : Tn)= i1; ... ; ik de.nes a function (basic block) \nwith label l, type parameters t., formal parameters v1 : T1,... ,vn : Tn, and function body i1 ...ik \nwhich is a sequence of LTAL instruc\u00adtions. The number m speci.es how much memory is guaran\u00adteed to be \navailable when the function is called. If a function speci.es m words and allocates no more than m words, \nthere is no need to test the memory availability. Otherwise, it has to check explicitly if there is enough \nmemory. The condition\u00adcode requirement cc speci.es the status of condition codes when the function is \ncalled. The function label l is assigned a code pointer type codeptr[t.](m, cc, v1 : T1,... ,vn : Tn). \nEach function is closed in the sense that there are no free type variables or value variables. Triple \nLRT represents three environments that keep aux\u00adiliary information for type checking: label environment \nL maps labels to addresses (o.set from the beginning of the program); register environment R maps variables \nto tempo\u00adraries (registers or spill locations); type abbreviation envi\u00adronment T maps type abbreviations \nto their expansions. An LTAL program consists of the above environments and a set of function declarations. \n 3.2 Static Semantics The low-level type and term constructors in LTAL make the typing system expressive. \nYet we need a decidable and simple type-checking algorithm so that proof generation can be done without \na complicated decision procedure or con\u00adstraint solver. To this end, we have made LTAL completely syntax-directed. \nThere are no subtyping rules; instead, we use coercions to avoid nondeterministic choices during type \nchecking. We explain various typing judgments, and then show some typing rules in this section. The typing \njudgment for values LRT ; a;< . v : T means value v has type T under environment LRT ; a; <. Triple LRT \nis part of the program. Kind environment a is alist of type variables bound so far (in our implementation \nwe use de Bruijn numbers, so a is just a number). Value environment < maps variables to their types. \nThe judgment LRT . (a; h;<; cc) {i} (a.; h.;<.; cc .) means after instruction i is executed, environment \n(a; h;<; cc) be\u00adcomes (a.; h.;<.; cc .). The construction <,v : T augments < with a new binding v : T \nand keeps the bindings other than v unchanged. The heap-allocation environment his explained in Section \n3.4. Environment cc speci.es the current status of condition codes. As an example we will show a simpli.ed \nrule for an LTAL add instruction. In Section 3.7 we will show a di.erent typed version of add. These \ntwo di.erent typed versions of add expand to the same Sparc machine instruction. The .rst rule we show \nhere is useful for compiling a source-language add for which no data.ow tracking is needed to prove safety; \nthe second is useful for compiling address arithmetic. Having multiple LTAL instructions for the same \nmachine instruction simpli.es type-checking. LRT ; a;< . x : int LRT ; a;< . y : int LRT . (a; h;<; cc) \n{z = x + y} (a; h;<,z : int; cc) In fact, this rule is dramatically simpli.ed for clarity. The full \nversion looks like this: (1) LRT ; a;< . x : int32 (2) LRT ; a;< . y : int32 (3) p. = p +4 (4) rmap(LRT \n)(z)= tz (5) rmap(LRT )(x)= tx (6) realreg(tz)= rz (7) realreg(tx)= rx (8) ym = match reg or imm(y) \n (9) <. = {z : int32}= (<\\z) (10) decode list pp.PP . i ADD(rx,ym,rz) LRT ;r . (p; a; h;<; cc; P ){z \n= x + y}(p.; a; h;<.; cc; P .)  The .rst and second premises state that both x and y have type int32, \nthe 32-bit integer type. Address p is the location of current instruction z = x + y; p. is the location \nof the next instruction. Premise (3) speci.es that the length of the add instruction is 4 bytes. Premises \n(4) and (5) relate variables z and x to their tem\u00adporary numbers, and premises (6) and (7) map temporaries \nto registers; this rule would not be applicable to operands represented in spill locations (but of course \nthat s true of the actual Sparc add instruction too). There are about 1000 temporaries (after register \nallocation); the .rst 20 are reg\u00adisters, and the remainder are in the spill area. The per\u00adprogram rmap \nthe R component of LRT maps variables to temporaries; the program-independent relations realreg and memtemp \nrelate temporaries to their machine represen\u00adtation. Since value y can be either a register or an immediate, \nwe use match reg or imm in premise (8) to match either a register or an immediate. So ym can be either \n(rmode ry) for some register ry or (imode i) for some immediate i. Premise (9) states the relation between \nthe value typing context before and after execution of the current instruction. Before we add the type \nof variable z into the context, all aliases of z should be killed since they are not live anymore, which \nis what <\\z does. Premise (10) will be explained in the next subsection. The conclusion is like a Hoare-logic \njudgment. In envi\u00adronment LRT , the instruction z = x + y is at location p; the length of the instruction \nis p. - p; this instruction does not a.ect type contexts a or heap allocation environment h; value context \n< becomes <. after execution; the machine code at location p. is P . . 3.3 Instruction decoding The \ndecode list relation in premise (10) maps an instruc\u00adtion word to a higher-level instruction with semantic \nmean\u00ading. Speci.cally, it says that the instruction word at the be\u00adginning of P with length p. - p is \nan add instruction i ADD(rx,ym,rz). We check for proper instruction encod\u00ading with rules such as the \nfollowing:  3230 25 19 1413 5 32 \u00b7 2+ Z = X9 64 \u00b7 X9 +0= X7 32 \u00b7 X7 + X = X6 2 \u00b7 X6 +0= X4 256 \u00b7 X4 \n+0= X1 32 \u00b7 X1 + Y = W decode(i ADD(X, rmode(Y ),Z),W )  This rule is not an axiom of our system, it \nis a lemma derived from a more concise and readable de.nition of instruction encodings [14]. The predicate \nA \u00b7 B + C = D shown here is a simpli.cation of an actual predicate that also checks that C<A and that \nA, B, C, D are natural numbers. 3.4 Heap Allocation Like SML/NJ, our compiler allocates closures and \nrecords in registers or on the heap; we don t push and pop the stack. At present, our type system (like \nmost TALs) also does not accommodate reasoning about garbage collection either. We intend to handle stacks \nand GC in the future, after we de\u00advelop a uni.ed theory of stack and heap deallocation (prob\u00adably based \non a region calculus). As in SML/NJ, with so much heap allocation we need ex\u00adtremely e.cient, in-line \nallocation of records. We model the allocable heap memory as a large contiguous region bounded by two \npointers, allocptr and limitptr. Heap allocation is broken into two steps: .rst, test whether there is \nenough memory for allocation; second, initialize memory.   Before the runtime system starts executing \na program, it reserves a chunk of memory, and sets the allocptr to the lowest address of the memory chunk, \nand the limitptr the highest address (minus a constant C = 4096). When the program needs n memory words, \nwhere 4n : C, it tests whether allocptr : limitptr; if so, then at least n words must be available. Then \nit .lls in n words consecutively to addresses from allocptr to allocptr +4n - 4, then increases allocptr \nby 4n. The following LTAL instruction sequence creates a 3-.eld record [v0,v1,v2] and assigns it to v. \nThe corresponding Sparc instructions are on the right side of the table (d, d0, d1, d2 are registers \nassigned to LTAL variables v, v0, v1, v2). LTAL Sparc l0 : l0 : testm(3) subcc allocptr, limitptr, %g0 \ni.ull then l1 else l2 bg l1 l2 : l2 : store(0, v0) st d0, [allocptr + 0] store(1, v1) st d1, [allocptr \n+ 4] store(2, v2) st d2, [allocptr + 8] v = record mov allocptr, d inc alloc 3 add allocptr, 12, allocptr \n. . . . . . l1 : . . . l1 : . . . Block l0 tests if there are at least 3 words in the memory for allocation; \nafter the testm comparison the condition\u00adcode environment is cc testm(3). Then the branch instruc\u00adtion \ni.ull consumes this condition code, and statically guarantees 3 words in the fall-through case (memory \nis not full). Block l2 initializes the three newly allocated words. In\u00adstruction store(i, vi) initializes \nthe word whose address is allocptr +4i with vi. Instruction v = record copies allocptr to v. Instruction \ninc alloc n increases allocptr by 4n. The instruction sequence for allocation is not .xed. The instruction \nscheduler can shu.e these instructions with oth\u00aders, as long as certain constraints hold. An allocation \nenvironment his used to check heap allo\u00adcation. It consists of three parts: the number of words that \nare guaranteed to be available in the memory, the largest index of initialized .elds, and the type of \nthe partial record initialized so far. We don t need the initialization .ags used in TALx86 [17]. The \ntyping rules for the allocation instructions are shown in Figure 4. The judgement LRT ; a; h; <; cc .. \nl states that the signature of block l matches the current environment. If this judgement holds, it is \nsafe to jump to block l. Instruc\u00adtions testm and i.ull establish the allocation environment in which \nthe store instructions type-check. The compiler can (and does) optimize by making one i.ull cover the \nse\u00adquential allocation of several di.erent records in a control\u00ad.ow path that covers several basic blocks. \nThe parameter m of codeptr conveys the necessary information about how much memory is guaranteed to remain. \n 0 : n : 1024 LRT . (a; h; <; cc) {testm(n)} (a; h; <; cc testm(n)) cc = cc testm(n) LRT ; a; h; <; \ncc .. l1 LRT ; a;(n, -1, boxed); <; cc .. l2 LRT . (a; h; <; cc) {i.ull then l1 else l2} (a; h; <; cc) \nLRT ; a;< . vi : int= i 0 : i<n m . = max(m, i) LRT ; a;< . v : ti t. = t = (.eld iti)  LRT . (a;(n, \nm, t); <; cc) {store(vi,v)} (a;(n, m .,t.); <; cc) LRT . (a;(n, m, t); <; cc) {v = record} (a; h;<,v \n: t; cc) LRT ; a;< . v : int= n . m<n. : n LRT . (a;(n, m, t); <; cc testm(k)) {inc alloc v}(a;(n - \nn . , -1, boxed); <; cc none) LRT ; a;< . v : int= n . m<n. : n cc = cc *testm(k) LRT . (a;(n, m, t); \n<; cc) {inc alloc v} (a;(n - n . , -1, boxed); <; cc) Figure 4: Rules for Allocation Instructions A \ntuple type [T0,T1,... ,Tn-1] is represented in LTAL as (.eld 0 T0) = (.eld 1 T1) = ... = (.eld (n - 1) \nTn-1). If v has this type, then the word located at memory address v has type T0, at address v + 4 type \nT1, etc. (where 4 is the word size). When a .eld is initialized by a store instruction, one more conjunct \n(a .eld type) is added into the type of the partial record in the allocation environment. After initialization, \nthe allocptr is copied to a variable (with record type) by instruction v = record, and then the allocptr \nis adjusted to point to the next available memory word by instruction inc alloc. After instruction inc \nalloc, the condition codes set by testm are invalid because allocptr has been changed. So we reset the \ncondition-code environ\u00adment if it is cc testm. 3.5 Coercions A coercion only changes the static type \nof a value; it has no runtime e.ect. A coercion c de.nes a type transformation function fc. If c is applied \nto value v of type T , we get another value c(v) of type fc(T ). Type T and fc(T ) should be compatible, \nmore accurately, it should be provable in the underlying model that T is a subtype of fc(T ). Coercions \nsimplify type-checking by telling the checker, in e.ect, where to apply subtyping. However, this can \nsigni.cantly increase the size of the LTAL code. We list some coercion rules in Figure 5. The coercion \nc typing judgement a; LRT .c T n T . means that under kind environment a and maps LRT , coercion c changes \nT to T . . Sometimes after applying a coercion we need to use the value both at its old type and its \nnew type. This has been a di.culty in some previous TALs, which assign types to registers: they have \nto emit a mov instruction to handle this case. We solve this problem by assigning types to variables, \nnot to registers: A variable has only one type, but di.erent variables can be assigned the same register. \nA move-with\u00ad     cinj1 [ 1 2]a; LRT .c T1 n T1 . T2 cinj2 [ 1 2]a; LRT .c T2 n T1 . T2 T . = T [\u00b5t.T/t] \ncfold[\u00b5u. ]a; LRT .c T . n \u00b5t.T c2 c1 n T .. a; LRT .c T a; LRT .c T .n T . c1 = c2 T .. a; LRT .c T \nn c1 c2 n T . n T . a; LRT .c T1 1 a; LRT .c T2 2 cunion(c1,c2)a; LRT .c T1 . T2 n T1 . . T2 . Figure \n5: Selected coercion rules coercion creates a new variable (in the same register) with\u00adout executing \nan instruction. In e.ect, the variable name in an LTAL instruction tells the checker which type to use. \nThis means that when we kill a variable (by assigning a new value to its underlying register), we must \nalso kill all the other variables bound to that register. When adding a new type binding v : T , we examine \neach binding v . : T . in < and remove it from < if v . is assigned the same register as v, which means \nv . should be no longer live. We use (<\\v),v : T to represent this operation; it can be seen in premise \n(9) of the big rule in Section 3.2. When there is no ambiguity, it is abbreviated to <,v : T . On the \nother hand, a move-with-coercions such as v = c(v .) does not require the application of the \\v operator; \nother aliases of v continue to be active.  3.6 User-de.ned Datatypes LTAL s low-level type constructors \nprovide support for various data representations, and extracting and checking tags. The type-checker \ncan check the connection between a sum value and its tag, and re.ne the type of sum values after tag-checking. \nWe provide .exibility for the compiler writer to choose her preferred style of datatype representa\u00adtion; \nthe representations we describe in this section are not new, but the point is that we can type each aspect \nof their construction and deconstruction. For simplicity, we use the notation [T0,T1,... ,Tn-1] for tuple \ntypes and use the following two type macros: Type range(n1,n2) for type (int; n1) = (int< n2). A sum \ntype is often represented as range(0,n) . t. The number n indicates the number of constant construc\u00adtors, \nwhich are represented as integer 0, 1,... ,n - 1. Type t is the union of types for the boxed constructors. \n Type hastag(Ttag,T ) for (.eld 0 Ttag) = T . It means that the tag of a sum value has type Ttag, and \nthe sum value is of type T .  The compiler can choose from di.erent data representa\u00adtions for user-de.ned \ndatatypes such as intlist: datatype intlist = nil | cons of int . intlist (1) The most straightforward \nrepresentation is to tag each constructor with a small integer: nil is tagged 0, and cons tagged 1. \nintlist1 = \u00b5t.([int= 0] . [int= 1, [int,t]])  (2) We assume that small integers can be distinguished \nfrom pointers, thus constant data constructors can be represented as small integers: nil is represented \nas integer 0; cons is a boxed record with tag 0. intlist2 = \u00b5t.(range(0, 1) . [int= 0, [int,t]])  (3) \nA datatype with only one value-carrying constructor can be optimized further. If the value-carrying constructor \ncar\u00adries an always-boxed value, it need not be tagged. Since cons carries a tuple that is always boxed, \nits tag can be removed.  intlist3 = \u00b5t.(range(0, 1) . [int,t]) Creating Sum Values. We create an empty \nlist of intlist1 by building a 1-element record v0 = [0], then coercing it to type intlist1:  The only \ndi.erence between v0, v1 and v2 is coercions. They are assigned the same register, so no Sparc instruction \nis emitted for the above LTAL instructions. By inserting coercions, the type-checker can easily tell \nthat value v0 can be coerced to be of type intlist1. It sim\u00adply checks if the type of v0 is the .rst \npart of union type [int= 0].[int= 1, [int, intlist1]] (by the rule of coercion cinj1), and if the type \nof v1 is exactly the same as intlist1 with type variable t replaced with intlist1 (coercion cfold). The \nfollowing two LTAL instructions create an empty list of intlist3 by coercing integer 0 to be of type \nintlist3.  Coercion crange[n1,n2] changes a value of type int= n to type range(n1,n2) if n1 : n<n2. \nIn the .rst instruction the type-checker only needs to check if 0 : 0 < 1 holds. Eliminating Sum Values. \nConsider what happens when doing case discrimination on a boxed-tag style of sum type representation, \nsuch as is used when there are multiple value\u00adcarrying constructors. Given a value x, one fetches the \ntag into a variable y, then does a conditional branch on y; at this point, the di.culty is in relating \nthe outcome of the condi\u00adtional branch to the re.ned type of x. One solution is to use a macro TAL instruction \nto code for the load+compare+ branch; we wanted to avoid all such macro instructions. We use type quanti.cation \nand singleton types to keep track of the implicit data.ow. User-de.ned datatype datatype t = A | B | \nC of int | D of int . t can be represented in LTAL as: T = \u00b5t.(range(0, 2) . [int= 0, int] . [int= 1, \nint,t]). Switching on sum values in source program case(v : t) of A = eA | B = eB | C(x) = eC | D(x, \ny) = eD is translated to the following LTAL and Sparc instruction . ... sequence (Variables v0, v, v \n0,v1,v2,v3,v 3,v 3 are all assigned register d, and variable t is assigned dt): LTAL Sparc v0 = cunfold(v) \n(., v0. ) = cmpcci(v0, 256) subcc d, 256 ifr(:){v0. } then (v1,lCD) else (v2,lAB) bge lCD lAB : ... lAB \n: ... lCD : lCD : (t1,v3)= open(v1) t = load(v3, 0) ld [d],dt cmpcc(t, 0) subcc dt, 0, %g0 iftag(=){v3} \nthen (v3. ,lC ) else (v3 .. ,lD) be lC lD : ... lD : ... lC : ... lC : ... We need to generate code \nthat tests v to decide which branch to take. Each test and each branch should be an explicit LTAL instruction. \nFrom our assumption that no pointers point to the .rst 256 words in the memory, if v is a small integer \n(less than 256), then it is either A or B, other\u00adwise it is C or D. Instruction cmpcci performs this \ntest and sets condition codes. Instruction ifr examines the condition codes and rebinds two fresh variables \nv1 and v2 with re.ned types for boxed and unboxed cases respectively. Variable v1 has type .t.hastag(t, \n[int= 0, int] . [int= 1, int,T ]), which means it is tagged (we do not know the tag yet). Variable v2 \nhas type range(0, 2), which means it is either 0 or 1. Both v1 and v2 are forced to be assigned the same \nregister as v0, so no machine instruction is needed to move v0 to v1 or v2. In the unboxed case, we further \ntest if v2 is 0 or 1, which is easy. In the boxed case, we need to test the tag of v1. Variable v1 hides \nthe type of its tag by existential types. We .rst open v1 to v3 and bind a brand new type vari\u00adable t1. \nAgain, no Sparc instruction is needed because v1 and v3 are assigned the same register. Variable v3 has \ntype hastag(t1, [int= 0, int] . [int= 1, int,T ]). Instruction load extracts the tag t and gives it type \nt1. Then cmpcc checks if tag t is 0 and set condition-code environment to be cc cmp(t1, \u00af 0). Instruction \niftag checks condition codes set by cmpcc, rebinds two new variables v3 . and v3 .. as aliases of v3 \nand does conditional branch. The type-checker checks in iftag instruction that: cc is cc cmp(T0, 0), \nv3 is of type \u00afhastag(T0.,T ), and T0 = T0.; and it re.nes the types of v3 . and v3 .. to [int= 0, int] \nand [int= 1, int,T ], respectively. This re.nement rules out disjuncts by the result of comparing tags \nwith integers. All these rules will be explained in detail in an upcomping thesis [8]. A constraint solver \nas in DTAL [23] is overkill for our purpose. The connection between a tagged value and its tag is established \nby existential types, since every time we open a variable of type .t.hastag(t, T ) and assign it to some \nvariable v, we get a fresh type variable t. , and only v s type contains the new type variable t. in \nthe .rst conjunct (.eld 0 t.), and only by instruction load(v, 0) can we get a variable of type t. . \n For simplicity we use linear search here. LTAL also per\u00admits binary search; to do an indexed jump we \nwould need to extend LTAL, but our underlying semantic model will permit this in a modular way. 3.7 \nDon t trust the linker! To avoid the need to reason about possible bugs in the link-loader, we arrange \nthat each compilation unit needs no link-editing, and links to others using closures, in the style of \nSML/NJ [7, \u00a73]. We must avoid the need for a linker to do relocation. Our safety policy says, a program \nis safe if, no matter where we load it in memory, it will never access an illegal address or execute \nan illegal instruction [2]. Position-independent code must use relative addresses in\u00adstead of absolute \nones. The problem arises when we move a label into a register or store it in memory, to make a function-pointer \nor a closure. The value of the label depends on where the code is loaded. We adopt the solution that \nSML/NJ uses, but we show how to type-check it. Each function takes a base parameter, which is the start \naddress of its own machine code in the memory. We keep the base address of the current function in a \nregister, and calculate the addresses of labels as o.sets from base. When a function f is called, the \naddress f is passed as its own base argument. In the body of a function f, moving a label g to variable \nv is implemented as v = addradd(base,g-f), where g-f is a constant computed by the compiler. Instruction \naddradd is translated to Sparc add instruction, and used only for address arithmetic. <. =<,v : addr(g) \nLRT ; a;< . v1 : addr(f) LRT ; a;< . v2 : di.(g, f) LRT . (a; h; <; cc) {v = addradd(v1,v2)} (a; h;<.; \ncc) To type-check position-independent code, we introduce type constructors addr and di.. The former \ngives a type to base and the latter types the di.erence between two labels. For example, in the above \nexample v = addradd(base,g - f), variable base has type addr(f); the constant g - f, which is represented \nas a value vdi.(g, f), has type di.(g, f); and the typing rule for addradd will give type addr(g) to \nv. When a function f is called in a compilation unit other than where it is de.ned, its label is (statically) \nunknown at the call site. Then the type of its base cannot be addr. We use existential types to hide \nthe base type; the type of f becomes ...codeptr[t.](m, [base : ., . . . ]). To make sure that f itself \nis passed to its base when f is called, we make f have type ...(. = codeptr[t.](m, [base : ., . . . ])). \nAs an important optimization, when a function is called only by direct jumps from known locations, it \ndoes not need its own base argument it can use the base of one of its known callers. This avoids addradd \ninstructions in local loops and branches.  4. MAKING AN UNTYPED BACK END PRESERVE TYPES Our compiler \nis based on SML/NJ, whose back end uses MLRISC [11], a generic framework for compiler back ends. It can \nbe customized to di.erent source languages and retar\u00adgeted to di.erent architectures. MLRISC provides \ninstruc\u00adtion selection, register allocation, and instruction scheduling modules parameterized by machine \nspeci.cations. To gener\u00adate a compiler back end, users customize these modules for their target machine. \nMLRISC has been used in many com\u00adpiler projects including SML/NJ for years, and generates high-performance \ncode. We did not originally intend to take advantage of ML-RISC, because MLRISC is totally untyped while \nwe need type-preserving transformations. When we learned of the annotation mechanism [13], we tried using \nannotations to connect the typed representation we need and the untyped one MLRISC uses. The experiment \nturned out to be re\u00adwarding: reusing MLRISC this way is much less work than writing a back end from scratch, \nand has the advantages that MLRISC provides, such as generating code with good performance and being \nretargetable. 4.1 Annotations Annotations in MLRISC are like comments; in fact, they are emitted as comments \nin assembly code. They have no runtime e.ect. One can annotate cells (pseudo-registers that will be mapped \nto physical registers or memory words), in\u00adstructions, code blocks, and compilation units. Each anno\u00adtation \ndescribes a property of the construct it annotates, and a construct can have many annotations addressing \ndif\u00adferent properties. MLRISC provides ways to create, append, extract and remove annotations. By annotating \ncells with variables, instructions with LTAL instructions, code blocks with function signatures, compila\u00adtion \nunits with type de.nitions, we get a close correspon\u00addence between MLRISC code and LTAL programs. Originally \nMLRISC developers added this mechanism to propagate type information to code optimization phases. Annotations \nhave been used extensively in MLRISC to pass information without changing existing data structures. Data \nabstraction hides the representation of client annotations from MLRISC s register allocator and instruction \nselector. However, we found that MLRISC did not take care to maintain annotations through every program \ntransforma\u00adtion. For example, sometimes MLRISC removes annotations of instructions, or creates new constructs \nwithout annota\u00adtions because it does not know what annotations to give them. So the main di.culty in \nusing MLRISC is how to restore the missing annotations.  4.2 Basic Blocks Part of the solution to missing \nannotations is to design LTAL to provide annotations when MLRISC rewrites in\u00adstructions. At .rst we used \nextended basic blocks in LTAL: instruc\u00adtions such as if(v) then(l, .) else(l.,..) could appear in the \nmiddle of a function body. To avoid long jumps, ML-RISC would create a new block for the fall-through \ncase and change the jump block to be fall-through case. In the fol\u00adlowing example, the neq case has more \nthan 221 instructions, but the eq case does not. MLRISC simply switches the two cases, changing the code \nin the left column to the one in the right. Label l3 is for illustration purpose. It does not exist before \nMLRISC switches branches. l1 : ... l1 : ... be l2 (else l3) bne l3 (else l2) (l3 :)neq case (l2 :)eq \ncase l2 : eq case l3 : neq case Newly created block l3 needed to be annotationed with an LTAL function \nsignature, which MLRISC could not provide since there was no LTAL function that corresponds to this new \nblock. So we changed LTAL to make each basic block a function. Thus in the above example, when MLRISC \nmoves blocks, the LTAL function signature for l3 is already there. The important lesson here is that \na good TAL should serve not only as an interface between a compiler and a checker, but also as a useful \nintermediate language in the back-end phases of the compiler itself. By using basic blocks instead of \nextended basic blocks, LTAL becomes useful as such an intermediate language. 4.3 Hooks Our approach \nneeds tight connection between machine code and LTAL annotations. But MLRISC sometimes breaks annotations. \nThis causes problems. For example, MLRISC transformed instruction d1 = 3+ d2 to d1 = d2 + 3 (thus one \nSparc instruction su.ces), and annotated the new in\u00adstruction with the annotation of the old one. The \nLTAL annotation of d1 =3+ d2 would be like v1 =3+ v2 where v1 and v2 are assigned register d1 and d2 \nrespectively. This annotation is not valid for d1 = d2 + 3. The checker will try to map 3 to d2 and v2 \nto 3, and fail. This problem results from the fact that MLRISC does not know the meaning of annotations \nor the connection between annotations and code, thus could not preserve them. Yet MLRISC should not understand \nannotations because di.er\u00adent users give di.erent annotations. Our solution is that MLRISC users provide \nhooks (functions) that manipulate annotations, and MLRISC calls those hooks when it trans\u00adforms the code. \nThe commuting transformation (shown above) will call a function of type annotation n annotation to restore \nannotations before it exchanges the two operands. This function takes the old instruction s annotation \nand rewrites it to .t the new instruction. Another case in which MLRISC breaks LTAL annotations is when \nit splits an instruction into several ones. For exam\u00adple, pseudo-instruction d = 4097 is split into two \ninstruc\u00adtions, d = sethi 4 and d = d or 1, where the .rst instruc\u00adtion loads the high 22 bits of constant \n4097 to the high 22 bits of register d, and the second instruction loads the low 10 bits. In our modi.ed \nback end, MLRISC calls a function to get the annotations for the two new instructions.  5. MEASUREMENTS \nThe LTAL calculus is a large engineering artifact, just like the compiler that produces it and the Sparc \nmachine that consumes it. It comprises (at the current state of im\u00adplementation) approximately 1200 operators \nand rules, in\u00adcluding 196 machine-language Sparc instruction construc\u00adtors (many of which are not used \nby the compiler and could be deleted from our checker), 263 Sparc instruction decod\u00ading rules, 30 coercion \noperators and 49 coercion rules, 48 explicit-substitution operators and reduction rules, 41 types and \nconstructors for such things as label-maps and register\u00admaps, 27 type operators (union, intersection, \n.eld, etc.), 69 rules for type re.nement, 98 rules for wellformedness of types, 73 operators and rules \nfor local environment man\u00adagement, 44 operators and rules for static arithmetic cal\u00adculations, 38 rules \nfor parsing the label, register, and type maps, 50 structural matching heuristics for type expressions, \n51 LTAL instruction constructors, and 53 typing rules for instructions. A typical large rule, such as \nthe one shown in Section 3.2, is quanti.ed over a dozen variables and has a dozen premises. In all, the \ncurrent LTAL type checker is 3900 lines of (non\u00adblank, non-comment) Prolog-like source code. The machine\u00adchecked \nproof of the soundness of all the LTAL rules (which is nearing completion) is over 98,000 lines of higher-order \nlogic as represented in the Twelf system. The axioms com\u00adprise 1850 lines, almost all of which is the \nspeci.cation of the Sparc instruction set. The compiler from core ML to LTAL+machine code is written \nin ML; its size (including blank lines and comments) is 50k lines of the Standard ML of New Jersey (110.35) \nfront end (unmodi.ed); 1.8k lines of code copied and modi.ed from the implementation of the SML/NJ interactive \ntop\u00adlevel loop; 2.7k lines to translate FLINT to NFLINT; 7.8k lines to translate NFLINT to LTAL; 1.2k \nlines to interface of MLRISC; and approximately 50k lines of the MLRISC system3 itself, of which 400 \nlines are new or modi.ed to support our more-general annotation interface. 5.1 Performance We compared \nour performance4 to that of SML/NJ 110.35 on two small benchmarks: Life (adapted from the Standard ML \nbenchmark suite) and RedBlack, which uses balanced trees to do queries on integer sets. Benchmark redblack \nlife SML/NJ Compile time 0.300 0.490 sec. SML/NJ Run time 0.013 0.262 FPCC Compile time 0.955 2.998 Safety \ncheck time 0.183 0.432 FPCC Run time 0.014 0.407 FPCC/SMLNJ slowdown 1.036 1.555 Sparc instrs. 870 1816 \nLTAL tokens 34278 57670 Coercion tokens 17% 23% Our compile time is not competitive (2.998 seconds to \ncompile Life compared to 0.49 seconds for the production release of SML/NJ); we have not engineered our \ncompiler algorithms as necessary for a production compiler. Run time is almost as good as SML/NJ. We \ndo not garbage col\u00adlect; SML/NJ spends 0.02% of its time garbage-collecting on these benchmarks. SML/NJ \ns better performance is proba\u00adbly because it has more sophisticated liveness-based closure conversion \nand .lls branch-delay slots. To measure Safety check time, we translate our lemmas into Prolog rules \nand time the execution in SICStus Prolog. As an alternative, we are building a minimal-size interpreter \nfor syntax-directed lemmas; it is much simpler than Prolog because it doesn t require backtracking or \nfull uni.cation; we have yet to measure the checking speed in that interpreter. 3The MLRISC software \nhas several other analyses, opti\u00admizations, and target machine speci.cations that we did not use and \nthat we don t count here. 4Measured on Sun UltraSparc E250, 400 MHz.  Simple encodings should be able \nto represent LTAL in a few bits per token, so the LTAL expression should not be signi.cantly bigger than \nthe machine-language program. Eliminating the coercions thus requiring some backtrack\u00ading in the checker \ncould save about 20% in LTAL size. The builders of SpecialJ [9] and TALx86 [15] have devoted substantial \ne.ort to reducing proof size not just removing coercions but getting the checker to reconstruct other \ndata as well. Clearly, there is some engineering to be done in this respect, although we would not want \nto complicate any part of the checker that is in the trusted base.  6. RELATED WORK AND CONCLUSION Morrisett \net al. s TAL [17] demonstrated the idea of typed assembly language, but was too limited for practical \npro\u00adgramming languages. Extensions of this work supported stack allocation [16] and implemented a more \nrealistic cal\u00adculus (TALx86) [15] for compiling a safe C-like language to Intel IA32 assembly language. \nXi and Harper s DTAL [23] added a restricted form of dependent types to TAL to sup\u00adport array bound check \nelimination and datatype tag dis\u00adcrimination. These implementations have soundess proved by hand about \nabstractions of subsets of the system that is actually implemented; the proofs cannot be machine-checked. \nThese TALs each have a macroinstruction malloc for heap allocation (and TALx86 has another macro btagi \nwhich tests tags and branches). Hamid et al. proposed a syntactic approach to build machine-checkable \nfoundational proofs. They designed Feath\u00aderweight Typed Assembly Language (FTAL) [12], mapped each valid \nmachine state to a well-typed FTAL program, and related transition of machine states to evaluation of \nFTAL programs by a machine-checked syntactic metatheorem. It is not clear whether syntactic metatheorems \nscale very well, or can be made as modular as our semantic-modelling ap\u00adproach; FTAL is too featherweight \nto tell. Crary [10] has built a more substantial TALT, with a machine-checked syn\u00adtactic metatheorem \nproving progress and preservation; he is now working on the machine-checked metatheorem relating his \ntyped calculus to the bare machine untyped step rela\u00adtion. We have designed a syntactic low-level typed \nassembly language with a semantic model that backs up its soundness with a machine-checkable proof. The \nsemantic modelling technique makes LTAL easily and safely extensible. It has a rich set of expressive \nconstructors, yet its type-checking is decidable and simple. We have implemented a prototype compiler \nthat transforms core ML programs to Sparc code annotated with LTAL programs. In our compiler an untyped \nback end preserves types by annotations and hooks. 7. ACKNOWLEDGEMENTS We would like to thank Noam Zeilberger \nfor his improve\u00adments on the implementation of calling conventions and run\u00adtime exception controls. Also, \nwe are grateful to many re\u00adviewers who gave us very constructive comments on earlier versions of this \npaper. 8. REFERENCES [1] Amal J. Ahmed, Andrew W. Appel, and Roberto Virga. A strati.ed semantics of \ngeneral references embeddable in higher-order logic. In 17th Annual IEEE Symposium on Logic in Computer \nScience (LICS 2002), pages 75 86. IEEE, June 2001. [2] Andrew W. Appel. Foundational proof-carrying code. \nIn Symposium on Logic in Computer Science (LICS 01), pages 247 258. IEEE, 2001. [3] Andrew W. Appel and \nAmy P. Felty. A semantic model of types and machine instructions for proof-carrying code. In POPL 00: \nThe 27th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 243 253. ACM Press, \nJanuary 2000. [4] Andrew W. Appel and David McAllester. An indexed model of recursive types for foundational \nproof-carrying code. ACM Transactions on Programming Languages and Systems, 23(5):657 683, September \n2001. [5] Andrew W. Appel, Neophytos Michael, Aaron Stump, and Roberto Virga. A trustworthy proof checker. \nIn Iliano Cervesato, editor, Foundations of Computer Security workshop, pages 37 48. DIKU, July 2002. \ndiku.dk/publikationer/tekniske.rapporter/2002/02\u00ad12.pdf. [6] Andrew W. Appel and Daniel C. Wang. JVM \nTCB: Measurements of the trusted computing base of Java virtual machines. Technical Report CS-TR-647-02, \nPrinceton University, April 2002. [7] Matthias Blume and Andrew W. Appel. Lambda-splitting: A higher-order \napproach to cross-module optimizations. In Proc. ACM SIGPLAN International Conference on Functional Programming \n(ICFP 97), pages 112 124, New York, June 1997. ACM Press. [8] Juan Chen. A Sound Typed Assembly Language \nfor Real Languages on Real Machines. PhD thesis, Princeton University, 2003. In preparation. [9] Christopher \nColby, Peter Lee, George C. Necula, Fred Blau, Ken Cline, and Mark Plesko. A certifying compiler for \nJava. In Proceedings of the 2000 ACM SIGPLAN Conference on Programming Language Design and Implementation \n(PLDI 00). ACM Press, June 2000. [10] Karl Crary. Toward a foundational typed assembly language. In POPL \n03: The 30th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, page (to appear). ACM \nPress, January 2003. [11] Lal George. MLRISC: Customizable and reusable code generators. Technical report, \nBell Laboratories, May 1997. [12] Nadeem Hamid, Zhong Shao, Valery Trifonov, Stefan Monnier, and Zhaozhong \nNi. A syntactic approach to foundational proof-carrying code. In Proc. 17th Annual IEEE Symposium on \nLogic in Computer Science (LICS 02), pages 89 100, July 2002. [13] Allen Leung and Lal George. MLRISC \nAnnotations. http://cm.bell-labs.com/cm/cs/what/smlnj/compiler\u00adnotes/annotations.ps. [14] Neophytos G. \nMichael and Andrew W. Appel. Machine instruction syntax and semantics in higher-order logic. In CADE-17: \n17th International Conference on Automated Deduction, pages 7 24. Springer-Verlag, June 2000. LNAI 1831. \n [15] Greg Morrisett, Karl Crary, Neal Glew, Dan Grossman, Richard Samuels, Frederick Smith, David Walker, \nStephanie Weirich, and Steve Zdancewic. TALx86: A realistic typed assembly language. In Second ACM SIGPLAN \nWorkshop on Compiler Support for System Software, pages 25 35, Atlanta, GA, 1999. INRIA Technical Report \n0288, March 1999. [16] Greg Morrisett, Karl Crary, Neal Glew, and David Walker. Stack-based typed assembly \nlanguage. J. Functional Programming, 12(1):43 88, January 2002. [17] Greg Morrisett, David Walker, Karl \nCrary, and Neal Glew. From System F to typed assembly language. ACM Transactions on Programming Languages \nand Systems, 21(3):527 568, May 1999. [18] George Necula. Proof-carrying code. In 24th ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, pages 106 119, New York, January 1997. ACM Press. [19] \nZhong Shao. An overview of the FLINT/ML compiler. In Proc. 1997 ACM SIGPLAN Workshop on Types in Compilation, \nJune 1997. [20] Kedar N. Swadi and Andrew W. Appel. Typed machine language and its semantics. www.cs.princeton.edu/~appel/papers, \nJuly 2001. [21] Gang Tan, Kedar Swadi, Dinghao Wu, and Andrew W. Appel. Construction of a semantic model \nfor a typed assembly language. January 2003. [22] Dinghao Wu, Andrew W. Appel, and Aaron Stump. Foundational \nproof checkers with small witnesses. March 2003. [23] Hongwei Xi and Robert Harper. A dependently typed \nassembly language. In 2001 ACM SIGPLAN International Conference on Functional Programming, pages 169 \n180. ACM Press, September 2001. APPENDIX A. COMPARISON OF TAL SYSTEMS Figure 1 makes sweeping claims \nabout many competing proof-carrying-code (PCC) and typed-assembly-language (TAL) systems. Here we explain \nthe basis for these claims, based on our understanding of the various cited works. Boxed nu\u00admerals i \nreference the columns of the table. SpecialJ [9] is a PCC compiler from Java byte code 1 to x86 machine \nlanguage 2 . It includes a veri.cation condition (VC) generator that scans the Java .class .les (that \ncontain compiled information about the data layout and formal pa\u00adrameters of methods) and the machine \ncode, extracting a formula that is supposed to imply the correctness of the machine code. The closest \nthat SpecialJ comes to a founda\u00adtional speci.cation 3 is a reference [9, \u00a74.2] to a proof about a di.erent \nVC generator in an earlier system. Assumptions about instruction encodings and about the safety policy \nare implicit in the VC generator (a C program tens of thousands of lines long), and there is no machine-checked \nsoundness SpecialJ mostly treats instructions atomically 6 : for ex\u00adample, comparisons that set condition \ncodes can be sepa\u00adrated from branches that depend on them. However, mem\u00adory allocation is done by a call \nto the runtime system. Data representations are .xed by the surrounding Java runtime 7 . The VC generator \nand prover can accommodate data.ow\u00adbased optimizations 8 . Position-independent code does not seem to \nhave been a design goal 9 . Since the VC is entirely a post-compilation pass, support for basic blocks \nas a tool for back-end optimization is beside the point 10 . There is no syntax-directed calculus at \nthe interface between the SpecialJ compiler and the prover/checker 11 . TALx86 [17, 16, 15] is the typed \nassemply language of the Popcorn compiler, which compiles a superset of a subset of C 1 to Pentium code \n2 . Several papers about di.er\u00adent subsets of TALx86 each specify overlapping subsets of the safety property, \nbut there is no formal speci.cation of the safety achieved by the actual implementation 3 . There is \nno machine-checked soundness proof  TALx86 has nonatomic instruction sequences for compare-and-branch \nand for memory allocation 6 ; later versions of TALx86 can sep\u00adarate the compare from the branch. Disjoint-sum \ndatatype tag-checking is done in separable atomic instructions in the implementation 6 , and with some \n.exibility in choosing rep\u00adresentations 7 . There is limited support for data.ow-based reasoning on integer \nvariables 8 or for position-independent code 9 . Blocks in TALx86 are extended basic blocks, not basic \nblocks this would hamper optimizations that reorder blocks but in the implementation there is a pseudoinstruc\u00adtion \nto handle fall-through that could mitigate this prob\u00adlem 10 . TALx86 (as implemented) is approximately \nsyntax\u00addirected, but omits many coercions to save space; there is no formal speci.cation of what a compiler-writer \nmust do to guarantee that proofs will be checkable 11 . DTAL [23] is a Dependently Typed Assembly Language. \nDTAL has been demonstrated with a toy source language 1 and no translation to any particular target machine \n2 . Ex\u00adcept for the lack of correspondence to a real machine, there is a formal speci.cation 3 of the \nsafety property; there is no machine-checked proof 4 5 . Atomicity of instructions is impossible to judge \nin the absence of a translation to a real machine 6 . There is only one tagged 2-way sum datatype  \nThe dependent types permit reasoning about data.ow analysis on user program variables and other quantities \n8 . There is no position-independent code 9 . Extended basic blocks are used instead of basic blocks \n10 . Type-checking is not syntax-directed, but requires a more sophisticated de\u00adcision procedure 11 . \nFeatherweight Typed Assembly Language, FTAL [12], demonstrates an approach to foundational proof-carrying \ncode using machine-checked soundness proofs based on syn\u00adtactic operational semantics. There s no compiler \nfor a source language nor translation to any target machine but there is a type-independent speci.cation \nof the safety prop\u00aderty, encoded in the Strati.ed Calculus of Inductive Con\u00adstructions (CiC), with a \nmachine-checked proof in the Coq system However, the safety speci.cation does not in\u00adclude instruction \nencodings or other real-machine issues  Existing checkers for CiC are at least an order of mag\u00adnitude \nlarger than our minimal LF checker 5 . Atomicity of instructions is impossible to judge in the absence \nof a trans\u00adlation to a real machine 6 . There is not enough support for data structures to judge whether \nthe compiler has .exibility to choose data representations 7 . Although the possibility is mentioned \nof adding existentials and singletons to sup\u00adport data.ow-based reasoning, this has not been done 8 . \nThere is no position-independent code 9 . Extended basic blocks are used instead of basic blocks 10 . \nTypechecking is syntax-directed 11 .   TALT [10] is a Foundational typed assembly language, meaning \nthat, like ours, it is intended to support machine\u00adchecked proofs from .rst principles. It has not yet \nbeen demonstrated (as far as we can tell) in a compiler for any source language 1 , but its application \nto Pentium assembly language is quite explicit 2 . There is a near-foundational speci.cation of safety, \nbut it does not model instruction de\u00adcoding 3 . Soundness of TALT type-checking will be proved by machine-checked \nmetatheorems of progress, type preser\u00advation, and a simulation relation between the typed cal\u00adculus and \nthe untyped machine calculus; machine-checked progress and preservation proofs have been built, but work \non the simulation proof is still ongoing However, the implementation of Twelf s metatheorem checker \n(in which these theorems are written) is two orders of magnitude larger than our minimal LF checker \n TALT has nonatomic compare-branch and memory-allocation instructions 6 . Its use of explicit unions \nand tags for representing disjoint sums appears to allow a compiler .exibility in choosing represen\u00adtations \n7 . Its use of singleton types (like ours) gives the power to reason about data.ow 8 . TALT does not \nsupport position-independent code 9 , but it does support reason\u00ading about relative addressing that is \nalmost enough for that purpose. TALT has no notion of blocks (neither extended nor basic) 10 . TALT has \nno syntax-directed type-checking algorithm (type-checking is not even decidable), so typing derivations \nmust be sent from compiler to checker 11 .  The LTAL system described in this paper achieves almost \nall of our goals. However, we don t yet compile all of core ML 1 ; we expect to do all of core ML in \na few months. Our soundness proofs based on the semantic model are con\u00adstructed by hand and checked by \nmachine, but the machine\u00adchecked proofs are not .nished 4 ; we expect to .nish in a few months. All of \nour instructions are atomic except for the delayed branch on the Sparc processor, which we bundle with \na nop instruction in the delay slot 6 .  \n\t\t\t", "proc_id": "781131", "abstract": "Typed assembly languages provide a way to generate machine-checkable safety proofs for machine-language programs. But the soundness proofs of most existing typed assembly languages are hand-written and cannot be machine-checked, which is worrisome for such large calculi. We have designed and implemented a low-level typed assembly language (LTAL) with a semantic model and established its soundness from the model. Compared to existing typed assembly languages, LTAL is more scalable and more secure; it has no macro instructions that hinder low-level optimizations such as instruction scheduling; its type constructors are expressive enough to capture dataflow information, support the compiler's choice of data representations and permit typed position-independent code; and its type-checking algorithm is completely syntax-directed.We have built a prototype system, based on Standard ML of New Jersey, that compiles most of core ML to Sparc code. We explain how we were able to make the untyped back end in SML/NJ preserve types during instruction selection and register allocation, without restricting low-level optimizations and without knowledge of any type system pervading the instruction selector and register allocator.", "authors": [{"name": "Juan Chen", "author_profile_id": "81100119052", "affiliation": "Princeton University", "person_id": "PP39028301", "email_address": "", "orcid_id": ""}, {"name": "Dinghao Wu", "author_profile_id": "81100657993", "affiliation": "Princeton University", "person_id": "P517405", "email_address": "", "orcid_id": ""}, {"name": "Andrew W. Appel", "author_profile_id": "81100498630", "affiliation": "Yale University", "person_id": "PP14174176", "email_address": "", "orcid_id": ""}, {"name": "Hai Fang", "author_profile_id": "81539337456", "affiliation": "Yale University", "person_id": "P517410", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/781131.781155", "year": "2003", "article_id": "781155", "conference": "PLDI", "title": "A provably sound TAL for back-end optimization", "url": "http://dl.acm.org/citation.cfm?id=781155"}