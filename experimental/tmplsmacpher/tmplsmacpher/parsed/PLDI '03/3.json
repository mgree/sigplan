{"article_publication_date": "05-09-2003", "fulltext": "\n The Design, Implementation, and Evaluation of a Compiler Algorithm for CPU Energy Reduction Chung-Hsing \nHsu and Ulrich Kremer Department of Computer Science Rutgers, The State University of New Jersey {chunghsu,uli}@cs.rutgers.edu \nABSTRACT This paper presents the design and implementation of a com\u00adpiler algorithm that e.ectively optimizes \nprograms for en\u00adergy usage using dynamic voltage scaling (DVS). The al\u00adgorithm identi.es program regions \nwhere the CPU can be slowed down with negligible performance loss. It is im\u00adplemented as a source-to-source \nlevel transformation using the SUIF2 compiler infrastructure. Physical measurements on a high-performance \nlaptop show that total system (i.e., laptop) energy savings of up to 28% can be achieved with performance \ndegradation of less than 5% for the SPECfp95 benchmarks. On average, the system energy and energy\u00addelay \nproduct are reduced by 11% and 9%, respectively, with a performance slowdown of 2%. It was also discovered \nthat the energy usage of the programs using our DVS algorithm is within 6% from the theoretical lower \nbound. To the best of our knowledge, this is one of the .rst work that evaluates DVS algorithms by physical \nmeasurements. Categories and Subject Descriptors D.3.4 [Programming Languages]: Processors compil\u00aders, \noptimization General Terms Algorithms, Experimentation, Measurement, Performance  Keywords Dynamic \nvoltage scaling, energy savings 1. INTRODUCTION Power dissipation has always been a crucial issue in \nthe design of battery-powered computing systems. Projected improvements in the capacity of the batteries \n(5-10%) can\u00adnot keep pace with what is needed to support the increasing demands of new features and performance \non mobile plat\u00adforms [23]. This widening battery gap drives the research Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 03, June 9 11, 2003, San Diego, California, \nUSA. Copyright 2003 ACM 1-58113-662-5/03/0006 ...$5.00. and development of low power electronics since \nbattery life\u00adtime correlates positively with power dissipation, i.e., re\u00adduced power dissipation leads \nto prolonged battery life. Yet, current state-of-the-art high-performance mobile micropro\u00adcessors have \nbattery lives of less than 4 hours for typical Windows applications [30]. More recently, power is becoming \na .rst-class design con\u00adstraint for high-performance computing systems [34]. It is projected that power \ndissipation of future microprocessor chips will increase from 100 W today to about 2,000 W in 2010 [6]. \nHigh power consumption raises temperature, dete\u00adriorates performance and reliability, and increases the \ncosts of thermal packaging and power delivery. Power is also a big issue for server clusters. A server \nfarm with 8,000 servers consumes 2 megawatts [34], and a future peta.op system will consume around 100 \nmegawatts [4]. Heavy-duty air condi\u00adtioning and backup cooling and power-generation equipment already \nconstitute a signi.cant portion of the total opera\u00adtion cost, presently around 25% [34, 38]. The environmental \nimpact of increased power demands has also become a ma\u00adjor concern. The recent trend towards ultra-dense \nclusters [46] will only worse the problem. Dynamic voltage scaling (DVS) is recognized as one of the \nmost e.ective power reduction techniques. It exploits the fact that a major portion of power of CMOS \ncircuitry scales quadratically with the supply voltage [8]. As a result, lowering the supply voltage \ncan signi.cantly reduce power dissipation. For non-interactive applications such as movie playing, decompression, \nand encryption, fast processors re\u00adduce device idle times, which in turn reduce the opportu\u00adnities for \npower savings through hibernation strategies. In contrast, DVS techniques are still bene.cial in such \ncases, i.e., DVS reduces power even when these devices are active. However, DVS comes at the cost of \nperformance degrada\u00adtion. An e.ective DVS algorithm is one that intelligently determines when to adjust \nthe current frequency-voltage set\u00adting (scaling points)and to which frequency-voltage setting (scaling \nfactors), so that considerable savings in energy can be achieved while the required performance is still \ndelivered. Designing a good DVS algorithm is not an easy task. First of all, the overheads of transitions \nto and from di.er\u00adent frequency-voltage settings may wipe out the bene.ts of DVS. Currently, it takes \nhundreds of microseconds to switch from one setting to another, which may be translated into tens of \nthousands of instructions for a high-performance pro\u00adcessor. As a result, proposals such as using cache \nmisses to trigger DVS [28] may not be e.ective if the performance requirement is critical. Furthermore, \nthe battery lifetime does not have a simple linear relationship with the power consumption of the circuit. \nIt has been shown that the max\u00adimum battery lifetime is achieved when the variance of the discharge current \ndistribution is minimized [35]. Most prior DVS algorithms do not consider these transition overheads. \nRecent work (e.g., [1, 18, 48]) starts to pay attention to these costs. Even if the transition overheads \nare taken into account, the design of a good DVS algorithm is still not easy. A simple approach is to \nidentify regions that show energy re\u00adduction potential within the performance bounds, and to ex\u00adecute \nthese regions at lower frequencies. This is exactly the philosophy behind many so-called interval-based \nDVS algo\u00adrithms (e.g. [36, 10, 26, 13, 42, 41, 27]). Interval-based DVS algorithms adapt to the variations \nof a workload closely by calculating a scaling factor at the beginning of each .xed\u00adlength time interval. \nUnfortunately, in practice, a recent study by Grunwald et al. [15] shows noticeable performance loss \nin some of interval-based algorithms. Theoretically, it has been formally proved [49, 21] that the optimal \nDVS algo\u00adrithm is to run each non-interactive task at a constant speed and complete it right at the deadline. \nIshihara and Yasuura goes further by showing that, in a system where only a lim\u00adited set of voltage-frequency \nsettings are available, at most two of the settings are required to implement the optimal DVS algorithm. \nWhile this strategy seems simple and at\u00adtractive, it is practically not implementable for tasks whose \nexecution times are unknown in advance, The impact of shutting down other computer components, such as \nthe disk and the display, is another factor a good DVS algorithm needs to take into account. In this \nsetting, running at a higher frequency and turning o. components may result in lower energy usage than \nrunning at a slow speed and leaving them on (until the deadline) [26, 32]. In other words, running as \nslowly as possible will minimize the CPU energy consumption but increase the total system en\u00adergy consumption, \nbecause the power-consuming non-CPU devices stay on longer. Similarly, the performance impact of computer \ncomponents may need to be considered as well. For example, nonideal memory behavior are identi.ed in \n[5, 29], which may a.ect the choice of the scaling factor at each scaling point. This paper presents \nthe design and implementation of a compiler algorithm that e.ectively addresses the aforemen\u00adtioned design \nissues. The idea is to identify the program regions in which the CPU is mostly idle due to memory stalls, \nand slow them down for energy reduction. On an ar\u00adchitecture that allows the overlap of the CPU and memory \nactivities, such slow-down will not result in serious perfor\u00admance degradation. As a result, it alleviates \nthe situation where non-CPU system components become dominant in the total system energy usage. The algorithm \ntakes transi\u00adtion overheads into account, and is evaluated on a real sys\u00adtem with the total system energy \nas the comparison metric. More importantly, the algorithm is parametric. A set of parameter values is \nprovided and shown to be appropriate for the e.ectiveness of the algorithm. Finally, we choose to use \nSPECfp95 benchmark suite for experiments because of its variety of CPU-boundness, which will be explained \nlater, and because we target both mobile computers and high-performance systems. The main contributions \nof this paper include the design and implementation of a compiler-directed DVS algorithm, and the evaluation \nof its e.ectiveness on a real high-performance laptop machine through physical measurements. To the best \nof our knowledge, this is one of the .rst implementation of a DVS algo\u00adrithm on a real system. physical \nmeasurements showing that total system en\u00adergy savings in the range of 0% to 28% can be achieved with \nperformance degradation from 0% to 4.7% for the SPECfp95 benchmarks. On average, the energy us\u00adage and \nenergy-delay product are reduced by 11% and 9%, respectively, at a performance penalty of 2.15%. To the \nbest of our knowledge, this is one of the .rst evaluation using physical measurements and address\u00ading \ntotal system energy usage.  further .ndings that our pro.le-driven algorithm is able to reduce energy \nusage within 6% from the the\u00adoretical lower bound, and that its e.ectiveness is not critically dependent \non the training inputs.  a study of two commercial laptops from the system de\u00adsign point of view. The \nexperimental results show that in some cases the high-performance high-power system together with our \nDVS algorithm is more energy e.\u00adcient than the low-performance low-power system. We are not aware of \nany similar study published in the lit\u00aderature.  The rest of the paper is organized as follows: Section \n2 lists some of the previous work. Section 3 discusses in detail the design and implementation of our \ncompiler-directed DVS algorithm. The experiment setup and results are discussed in Section 4, followed \nby conclusions and future work in Sections 5. 2. RELATED WORK There are many proposed DVS algorithms \nin the litera\u00adture. Due to the space limitation, we only discuss work re\u00adlated to intra-task DVS algorithms, \nas which our algorithm can be categorized. An intra-task algorithm allows the scal\u00ading points to be put \nin the middle of a task execution. The determination of scaling points and the calculation of scaling \nfactors may be done o.-line or on-line. Interval-based DVS algorithms are one type of intra-task algorithms. \nThey operate at .xed-length time intervals and rely solely on the state of the system and the trace history \nto determine the scaling factors. Examples in this category include [36, 10, 26, 13, 42, 41, 27]. Checkpoint-based \nal\u00adgorithms are another type of intra-task algorithms. In this type of algorithm, the scaling points \nare identi.ed o.-line and the scaling factors are calculated on-line [25, 33, 40, 3]. In contrast to \ninterval-based algorithms which place scal\u00ading points at the beginning of each .xed-length interval, \ncheckpoint-based algorithms place scaling points at selected branches to exploit the slacks due to run-time \nvariations. As a result, they require o.-line program analysis to identify the candidate branches. The \nalgorithm we present in this paper identi.es scaling points and determines scaling factors o.-line, with \nthe help of pro.le data. Our algorithm has many signi.cant di.er\u00adences from the algorithms mentioned \nabove. Our algorithm has a tighter performance constraint in mind. Many existing algorithms use the worst-case \nexecution time or the execu\u00adtion time of the unoptimized program as the performance constraint. In our \nexperiments, 5% of the total execution time of the optimized program is all the slack time DVS can exploit. \nAs we will show in Section 4.4, tighter performance constraint may lead to better system energy e.ciency. \nOur algorithm also takes the transition overheads into ac\u00adcount and is evaluated on real systems with \nthe measure\u00adments of the total system energy usage. Many of the previ\u00adous results were based on simulation, \nusing simulators such as Wattch [7] and SimplePower [50], and evaluated the pro\u00adposed algorithms using \nthe power model associated with the particular simulator. As a consequence, the quality of the comparison \nresults relies on the accuracy of the power model in a simulator. To the best of our knowledge, our work \nis one of the .rst attempts in using the physical measurement for the evaluation of the DVS algorithms. \nPillai and Shin [37] evaluated their inter-task algorithm on a laptop with a 550 MHz AMD K6-2+ chip. \nFlautner and Mudge [12] implemented their inter-task algorithm on a laptop with a 300-600 MHz Transmeta \nTM5600 processor. Our work adopts a table-driven approach similar to the one presented by Saputra et \nal. [39]. However, the table entries in our algorithm only store the performance infor\u00admation, through \npro.ling, and the energy information is de\u00adrived from an analytical model. In contrast, their algorithm \nstores both performance and energy information in the ta\u00adble. The work in this paper is also di.erent \nfrom our pre\u00advious work in [20, 18]. In the previous work, an analytical performance prediction model \nwas used. As a result, the e.ectiveness of the DVS algorithm depends on how well the performance model \npredicts the target architecture. In this work we treat the target architecture as a black box. In ad\u00addition, \nthis work presents a more general framework for our DVS algorithm and introduces an additional constraint \nfor a better quality of the algorithm. Finally, the work of [20, 18, 39] was done using a simulator, \nwhile the work presented in this paper uses physical measurements for evaluation, and targets total system \nenergy usage, not only energy usage of single system components.  3. THE ALGORITHM We propose a DVS \nalgorithm which can be summarized as solving the following minimization problem. minR,f Pf \u00b7 T (R, f)+ \nPfmax \u00b7 T (P - R, fmax) +Ptrans \u00b7 2 \u00b7 N(R) (1) subject to T (R, f)+ T (P - R, fmax)+ Ttrans \u00b7 2 \u00b7 N(R) \n= (1 + r) \u00b7 T (P, fmax) (2) The problem simply states: given a program P ,.nd aregion R and a frequency \nf such that, if region R is executed at frequency f and the rest of the program P - R is executed at \nthe peak frequency fmax, the total execution time plus the switching overhead Ttrans \u00b7 2 \u00b7 N(R) is increased \nno more than r percent of the original execution time T (P, fmax), while the total energy usage is minimized. \nHere T (R, f) represents the total execution time of region R running at frequency f, N(R) represents \nthe number of times region R is executed, Pf represents the power dissipation of the system at frequency \nf,and Ttrans and Ptrans represent a single switching overhead in term of performance and power, respectively. \n In our DVS algorithm, a program region R is assumed to be a single entry and single exit program structure. \nEx\u00adamples of a region include a loop nest, a call site, a called procedure, a sequence of statements, \nor even the entire pro\u00adgram. While this de.nition may sound too restrictive, it is able to guarantee \nthat all the top-level statements inside a region are executed the same number of times. As a result, \nthe algorithm is able to count the number of occurrences of DVS switchings as 2\u00b7N(R), since the algorithm \nassumes that DVS interface will only be called at the entry and the exit of the region. Experiments have \nshown that this de.nition works reasonably well in practice. Besides the performance constraint in Equation \n(2), our DVS algorithm introduces an additional constraint on the size of the selected region, namely \nT (R, fmax)/T (P, fmax) = . (3) Equation (3) enforces the size of the selected region R to be su.ciently \nlarge for two reasons. First, it makes sure that the region takes longer time to execute than a single \nexecu\u00adtion of the DVS call. Furthermore, our past experience has suggested that executing a larger region \n(in time) at a higher frequency often has less performance impact than executing a smaller region at \na lower frequency. The importance of introducing Equation (3) will be illustrated in Section 4.7. In \nshort, the DVS algorithm we propose in this paper is parameterized by four sets of factors. Tables T \n(R, f)and N(R) capture the behavior of the input program. Parame\u00adters Pf , Ttrans,and Ptrans model the \nunderlying machine. Parameter r represents the user s speci.cation, while pa\u00adrameter . is a design parameter \nfor the compiler. 3.1 Implementation Details The prototype for our DVS algorithm is implemented as a \npro.le-driven source-to-source transformation in SUIF2 [45], as shown in Figure 1. It starts by instrumenting \nthe input program at selected program locations (the instrumentation phase). The instrumented code is \nthen executed, .lling a subset of entries in tables T (R, f)and N(R) (the pro.l\u00ading phase). Once the \npro.ling is done, the rest of table entries are derived based on these .lled entries. Then the minimization \nproblem is solved by enumerating all possi\u00adble regions and frequencies. Finally, the corresponding DVS \nsystem calls are inserted at the boundaries of the selected region (the selection phase). Two kinds of \nprogram constructs are instrumented in our implementation, namely, all sites and explicit loop struc\u00adtures. \nExplicit loop structures include for and while loops. Currently, loops based on goto s are not instrumented \nand will not be considered as candidate regions. The pro.ling of the instrumented program only constructs \npart of tables T (R, f)and N(R). The rest of the table en\u00adtries are derived using the rules shown in \nFigure 2. In order to do this, an interprocedural analysis pass is implemented. The pass traverses all \nprocedures reachable from the main routine in reverse topological order, treating strongly con\u00adnected \ncomponents in the call graph as single nodes. For each visited procedure, the annotated abstract syntax \ntree (AST), embedded in the SUIF2 intermediate format, is tra\u00adversed in a bottom-up fashion. To improve \nthe e.ciency, only AST nodes representing if statements, explicit loop structures, and call sites are \nannotated with the appropri\u00adate T (R, f)and N(R) values. The corresponding values for original DVS ed \nC program C program  \u00ad 6 SUIF2 passes 6 pro.le machine Figure 1: The .ow diagram of the compiler imple\u00admentation. \nsequences of regions as a larger region are computed on the .y in the selection phase. Note that only \nregions in a forward sequencing manner are taken into account. That is, for program construct loop() \nsequence(R1,... ,Rn) the regions composed of Ri . Ri+1 . ... . Rj for j = i are considered, but not the \nwrap-around regions, Ri . .... Rn . R1 . ... . Rj for j<i.  3.2 An Illustrating Example In this section, \nwe illustrate our compiler algorithm using an example program shown on the left in Figure 3. The example \ncode is presented in terms of control .ow between what we call basic regions, where L and C stand for \nloop nests and call sites, respectively. The algorithm .rst identi\u00ad.es which regions to instrument. In \nour example, it is these basic regions our algorithm instruments. After the pro.ling phase, the entries \nof T(Ri,f)and N(Ri) for these regions are .lled, as shown on the right in Figure 3 assuming only two \nCPU frequencies fmax and fmin are available. Then, the al\u00adgorithm starts to consider other candidate \nregions which we call combined regions. For example, if(L4,L5) is a candi\u00addate region since it is an \nif-then-else construct that encloses regions L4 and L5. Similarly, seq(C2,C3) is a candidate re\u00adgion \nthat consists of two consecutive procedure calls. The region seq(C2,C3,if(L4,L5)) is also considered \nas a can\u00addidate region. Even the entire program foo is treated as a candidate region in our implementation. \nNot all combinations of regions are quali.ed as candi\u00addate regions. For example, seq(C1,C2) is not considered \nas a combined region since it has two entry points, one at the entry of C1 and the other at the entry \nof C2. Simi\u00adlarly, seq(C3,L4) is not a candidate region because of the two exit points. Our current implementation \ndoes not con\u00adsider region seq(if(L4,L5),L2) either. While it satis.es the single-entry-single-exit property, \nit does not satisfy our forward sequencing restriction. The particular reason for us to impose this restriction \nis to reduce the number of candi\u00addate regions that need to be examined in the region selection phase. \nFor our example, there are nine regions total. During the selection phase, the values of T(R,f)and N(R) \nfor the combined regions are required. To derive the values, our implementation follows the rules in \nFigure 2. For example, the execution time of region if(L4,L5) running at if statement: R: if () then \nR1 else R2 T(R,f)= T(R1,f)+ T(R2,f) N(R)= N(R1)+ N(R2) explicit loop structure: R: loop () R1 T(R,f)= \nT(R1,f) N(R)is pro.led  call site: R: call F() T(R,f)= T(F,f) \u00b7 N(R)/N(F) N(R)is pro.led  sequence \nof regions: R: sequence(R1, ... ,Rn) T(R,f)= {T(Ri,f): 1 = i = n}N(R)= N(R1)= ... = N(Rn) procedure: \nF: procedure F() R T(F,f)= T(R,f) N(F)= {N(Ri): Ri is a call site to F()} Figure 2: The rules of deriving \nthe table entries T(R,f) in our DVS algorithm. frequency f can be derived as the sum of execution times \nof regions L4 and L5 running at frequency f, i.e., T(if(L4,L5),f)= T(L4,f)+ T(L5,f) As a result, our \nimplementation derives T(if(L4,L5),fmax) =8+ 2 =10and T(if(L4,L5),fmin)=12+4 =16. The number of visits \nin region if(L4,L5), N(if(L4,L5)) can be derived as ten. For the call sites, let us assume C1 and C3 \ncall to the same procedure foo, which is only called by these two sites and contains basic regions. Our \nimplementation attributes the time period from the entry of C1 to the entry of the .rst encountered basic \nregion in foo to T(C1,f). This pro.led time is usually very small; in our case it is zero. As a result, \nwe need to recover the execution time for each call site. The rule in Figure 2 assumes the execution \ntime of a call does not depend on the actual parameters. We can then estimate the execution time for \ncall site C1 as T(C1,f)= T(foo,f) \u00b7 1/(1 + 10) where T(foo,f) is the estimated total execution time \nfor procedure foo running at frequency f. Finally, our implementation enumerates all candidate re\u00adgions \nwith respect to the minimization problem shown in Equations (1) (3). In general, our implementation exam\u00adines \nmany more candidate regions. For example, it found 30 program locations to instrument in the SPEC95 swim \nbench\u00admark and considered 2387 candidate regions. 3.3 Discussion The proposed DVS algorithm is parameterized \nin terms of T(R,f) without describing how to compute these val\u00adues. Our current implementation uses pro.ling \nto get these ENTRY T (R, f) R N(R) fmax fmin C1 1 0 0 C2 10 10 12 C3 10 0 0 L4 8 8 12 L5 2 2 4  Figure \n3: The example program is shown on the left in terms of control .ow between regions. The table on the \nright represents the pro.led data for the instrumented regions. values. Pro.le-driven compiler optimization \nhas its advan\u00adtages and disadvantages. A program optimized with respect to one data input or machine \ncon.guration may not work well on another input or con.guration. Pro.le-driven opti\u00admization also increases \nthe compilation time. On the other hand, pro.ling captures more system e.ects which a com\u00adpiler model \nmay have di.culty to model, is more generally applicable, and allows more aggressive optimization. Our \nearly work [19] proposed a compiler model that enables us to pro.le T (R, fmax) and estimate the rest \nof T (R, f)an\u00adalytically. While it may shorten the compilation time, this early work involves the computation \nof the memory stall time for each region and requires the help from performance counters in the system. \nUnfortunately, for the target system we experimented on (described later), we had a hard time re\u00adlating \nthe counted events to the actual performance. This is partially due to the lack of documentation and \ndesired event types. Using a compile-time prediction model to compute all T (R, f) entries sounds attractive \nsince it is portable across di.erent data inputs and machine con.gurations. However, the quality of the \noptimized code highly depends on the ac\u00adcuracy of the model which is hard to guarantee due to the complex \ninteraction between all components in the system.  4. EXPERIMENTS 4.1 Hardware Platform The hardware \nplatform is a Compaq Presario 715US note\u00adbook computer. We chose this laptop as our hardware plat\u00adform \nfor at least three reasons. First of all, notebook com\u00adputers are battery-powered and are therefore very \nsensitive to energy consumption. Secondly, the technology used in notebook computers today addresses \nmore power issues and will soon be adapted to the high-performance systems for temperature control. Thirdly, \nthis laptop is equipped with Compaq spec Presario 715US AMD CPU mobile Athlon 4 f 600-1200 MHz V 1.15-1.45 \nV front side bus DDR 100 MHz memory 256 MB PC-133 graphics VIA 16 MB LCD display 14.1-inch 1024x768 disk \n20 GB f Vf 600 1.15 700 1.20 800 1.25 900 1.30 1000 1.35 1100 1.40 1200 1.45  Table 1: The system con.guration \nof the Compaq Presario 715US notebook computer. a high-performance microprocessor (mobile AMD Athlon \n4) that allows DVS. Intel s Xscale-based processors, although they support DVS, do not have .oating-point \nunits. Trans\u00admeta s Crusoe processors do not provide enough memory level parallelism (i.e., allow multiple \noutstanding cache misses at the same time) which is a salient feature in many high\u00adperformance computers. \nThe Presario computer is equipped with a high-performance mobile AMD Athlon 4 microprocessor. The processor \nis a 3-way superscalar out-of-order decode and execution decou\u00adpled computing engine with dynamic branch \nprediction and speculative execution. It contains a 64KB instruction cache, a 64KB data cache, a full-speed \non-die 256 KB level two ex\u00adclusive cache, and a hardware data prefetching unit. The processor supports \nDVS under software control. For our ex\u00adperiments, it is able to operate from 600 MHz at 1.15 V to 1200 \nMHz at 1.45 V, wih 7 di.erent frequency-voltage pairs. Table 1 summaries the con.guration of the system. \n 4.2 Software Platform The Linux 2.4.18 kernel was installed on the laptop. All the benchmarks were compiled \nby the GNU compilers using optimization level -O2. The DVS support is done through user-level system \ncalls. The input of a DVS call is the desired frequency. The call will .nd the corresponding voltage \nand write both frequency and voltage encodings into machine\u00adspeci.c registers. The registers values are \nthen used by the regulator to adjust the CPU clock frequency and voltage level. To pro.le the values \nof T (R, f)and N(R), we also imple\u00admented another user-level system call. The input of such a call is \nthe region number. For T (R, f), a high-resolution timer is needed to measure the elapsed time between \ntwo such system calls. We did this by reading out the current cycle counter value on a per-process basis. \nFor N(R), the system call implementation maintains a table indexed by the region number and increments \nthe appropriate table entry. 4.3 Benchmark Choices The SPECfp95 benchmark suite was used for experiments \nbecause of its variety of CPU-boundness and because we tar\u00adget both mobile computers and high-performance \nsystems. We found that the overall energy savings for a benchmark correlates negatively with the CPU \nboundness of the bench\u00admark. In other words, less CPU-bound applications have potentially more energy \nreduction. Here we de.ne the CPU SPECfp95 benchmark \u00dfcpu swim 0.04 tomcatv 0.06 hydro2d 0.13 su2cor 0.17 \napplu 0.30 apsi 0.37 mgrid 0.45 wave5 0.57 turb3d 0.75 fpppp 1.00 SPECint95 benchmark \u00dfcpu compress \n0.47 vortex 0.70 gcc 0.83 ijpeg 0.95 li 1.00 perl 0.98 go 1.00 m88ksim 1.00 Table 2: The potential DVS \nenergy savings and per\u00adformance slopes of the SPEC95 benchmarks. boundness \u00dfcpu as a ratio between 0 \nand 1, with 1 being extremely CPU-bound, using the least square .tting of { Tf } to the following linear \nmodel. Tf /Tfmax = \u00dfcpu \u00b7 (fmax/f)+ c0 Table 2 shows the corresponding CPU-boundness for each benchmark \nin the entire SPEC95 benchmark suite. It can be seen that SPECfp95 benchmarks have a wider range of pro\u00adgram \nbehavior than SPECint95 benchmarks. Recent studies [43, 44] have shown that typical multimedia benchmarks \nare less CPU-bound than SPECint95 benchmarks. The is par\u00adtially due to the fact that many of the popular \nmultimedia benchmarks are really compression and decompression pro\u00adgrams [24]. In addition, a recent \nstudy [22] observes that multimedia applications do not just contain .xed-point op\u00aderations. We believe \nthat more and more multimedia appli\u00adcations will be implemented as .oating-point intensive com\u00adputations, \npartly because of the current trend of physically\u00adbased modeling for virtual reality environments such \nas PC games, for example, [47].  4.4 Comparison Metrics For comparison, we used total execution time \nT , total sys\u00adtem energy usage E, and energy-delay product E \u00b7 T [14]. As described in Section 1, power-performance \ntrade-o.s mo\u00adtivates the technique of dynamic voltage scaling. While an application can be executed with \nlow power dissipation, its execution time may be unacceptably long. To seemlessly include the latency \nconstraint into the picture, energy and energy-delay product are used by many as metrics for the comparison \nof di.erent power-aware systems. The energy is equal to the product of the average power dissipation \nand the total execution time, i.e., E = P \u00b7T . Energy-delay prod\u00aduct is equal to the product of the energy \nusage and the total execution time, i.e., E \u00b7 T = P \u00b7 T 2 . Energy translates di\u00adrectly to battery life, \nwhile the energy-delay product ensures a greater emphasis on performance.  4.5 Measurements We performed \nseveral experiments with our DVS algo\u00adrithm and measured the actual energy consumption of the system \nthrough a digital power meter. The power meter, a Yokogawa WT110 [31], sent power measurement data ev\u00adery \n250 ms to another computer, which stores them in a log for later use. Each power measurement data point \nis the Figure 4: The experimental setup. parameter value T (R, f) pro.led N(R) pro.led Pf V 2 f \u00b7 f \nTtrans 20 \u00b5s Ptrans 0W r 5% . 20% Table 3: The input parameters for our algorithm. average power over \n9500 samples in the period of 250 ms. That is, the power meter samples current and voltage at arateof26 \n\u00b5s. The comparisons were done by executing the benchmark with the reference data set. When pro.ling, \nthe training data set (train.in) provided with the SPEC95 benchmark distribution was used. All the benchmarks \nwere run to completion. During the measurements, the battery was removed. In addition, the power dissipation \nof the AC adapter was excluded. The monitor may be on or o. during the measurements, depending on whether \nthe benchmark needs it or not. Figure 4 shows the measurement setup. The cost of each instrumentation \ncall is about 50 ns. The cost of each DVS call is approximately 10 \u00b5splusthe tran\u00adsition time from one \nDVS level to another. We do not know the actual time required for voltage transition to occur. The white \npaper [2] suggests that it takes less than 100 \u00b5s but provides no speci.c information. A typical DC-DC \ncon\u00adverter is about 200\u00b5s/1V [40]. In the experiments we set the transition time to be 20 \u00b5s and the \nassociated power dissipation to be 0 W. We found that Ttrans =20 \u00b5sworks well in our experiments. As \nlong as it is su.ciently large to prevent the transition overheads from being a dominant factor in the \nsystem performance, the accuracy of Ttrans is not critical. In addition, the large value of Ttrans allows \nus to ignore the cost of Ptrans and simplify the algorithm. Ta\u00adble 3 lists the parameter settings of \nour DVS algorithm used in the experiments. 4.6 The Compilation Time The compilation time of our algorithm \nis in the order of minutes. Table 4 lists the timing spent in each phase. The instrumentation phase takes \n7 157 seconds which includes the times of converting to and from the SUIF2 intermediate representation \nplus the time of selecting program locations to instrument. The sub-phase of selecting program locations \nto instrument contributes 6% 13% of the total compilation time for the instrumentation phase, with 9% \non average. In total instru\u00ad compilation mentation pro.ling selection time phase phase phase swim 34 \n7 819 tomcatv 173 4 158 11 hydro2d 340 44 173 123 su2cor 403 37 257 109 applu 284 83 13 188 apsi 1264 \n157 40 1067 mgrid 190 10 152 28 wave5 544 151 48 345 turb3d 1839 39 268 1532 fpppp 1628 82 11 1535 Table \n4: The compilation time (in seconds) of our algorithm in various phases. other words, the conversion \nbetween the input C program and the SUIF2 representation is very expensive. On the other hand, in the \nselection phase, the dominating sub-phase is the process of evaluating all candidate regions for the \nbest region. It accounts for 74% 98% of the total compilation time for the phase, with the average 83%. \nBenchmarks apsi, turb3d and fpppp took the longest compilation times among all benchmarks. The long com\u00adpilation \ntimes can be attributed to the large number of can\u00addidate regions and the cost of .nding these candidate \nre\u00adgions. The current implementation enumerates all possible sequences of a statement list for .nding \ncandidate regions. As a result, the cost can be characterized by the number of statement sequences tried. \nFor benchmarks apsi and fpppp, the selection phase evaluated 77,335 and 51,025 candidate regions respectively. \nIn contrast, only 2,044 27,535 candi\u00addate regions were evaluated for other benchmarks. The se\u00adlection \nphase looked 290,299 340,448 statement sequences for the three benchmarks. It only looked 3,955 118,775 \ncom\u00adbinations for other benchmarks. Clearly, there is room for improvement in our compiler algorithm. \n 4.7 Experimental Results The experimental results are shown in Table 5. The exe\u00adcution time Tr and \nenergy consumption Er are all relative to the case in which the same program was run on the non-DVS system, \ni.e., the program is executed at the peak frequency and voltage. Note that the energy consumption is \nthe overall system energy usage, not just the microprocessor s energy usage. It can be seen that program \nenergy savings of 0% to 28% can be achieved with performance degradation of 0% to 4.7%. On average, the \nenergy and energy-delay prod\u00aduct are saved 11% and 9%, respectively, with a performance slowdown of 2.15%. \nFurthermore, the energy savings of a benchmark using our compiler algorithm correlates negatively with \nits CPU boundness. Our algorithm is able to identify that bench\u00admark fpppp is extremely CPU-bound (its \n\u00dfcpu =1)and therefore cannot be slowed down without signi.cant perfor\u00admance penalties. There is a big \ngap in terms of energy usage at \u00dfcpu = 0.3. It indicates that if an application is CPU\u00adbound, our algorithm \nmay not be able to reduce a consid\u00aderable amount of energy without increase the performance tolerance. \nAs we will see in Section 4.9, none of the DVS algorithm is able to do so if \u00dfcpu is greater than 0.5 \nwhen only 5% of performance slow-down is allowed. benchmark selection Tr (%) Er (%) swim R/600 102.93 \n76.88 tomcatv R/800 101.18 72.05 hydro2d R/900 102.21 78.70 su2cor R/700 100.43 86.37 applu R/900 104.72 \n87.52 apsi R/1100 100.94 97.67 mgrid R/1100 101.13 98.67 wave5 R/1100 104.32 94.83 turb3d R/1100 103.65 \n97.19 fpppp P/1200 100.0 100.0 average 102.15 88.99  Table 5: The relative execution time and system \nen\u00adergy usage for the SPECfp95 benchmarks using train\u00ading input train.in. Our DVS algorithm has introduced \na region size con\u00adstraint, Equation (3), which prefers large region to be se\u00adlected. In the experiments, \nthis size constraint was set to be 20% or more of the total execution time. If this con\u00adstraint is dropped, \nour algorithm will select a di.erent but smaller region for benchmark turb3d. Speci.cally, with the constraint, \n64% of time the benchmark is executed at 1100 MHz. In contrast, without the constraint, 31% of time the \nbenchmark is executed at 700 MHz. Both selections are able to reduce the energy usage by 3%. However, \nthe per\u00adformance penalty becomes 10% if such a size constraint is not included. This particular case \nillustrates the importance of introducing Equation (3). 4.8 Different Training Inputs A common question \nfor pro.le-based algorithms is how much the quality of the results is a.ected by the di.erent training \ninputs. In this section, we evaluate such an impact using another training data set std.in developed \nby Burger [9]. For SPECfp95 benchmarks, since they all have a common structure of an initialization phase \nfollowed by repetitions of a computation phase, in most cases data set std.in uses the same reference \ndata set but reduces the number of repeti\u00adtions. Table 6 column std.in gives the de.nition of data set \nstd.in for SPECfp95 benchmarks. For example, data set std.in for benchmark swim uses the same reference \ndata set but reduces the repetitions from 900 down to 45. Note that benchmarks mgrid and fpppp do not \nuse the reference data set as input. The column selection in Table 6 lists the slow-down strategy our \ncompiler .nds if data set std.in is used as the training input. Except those benchmark rows marked same \n, our compiler algorithm found di.erent regions to slow down at di.erent speed if using std.in. However, \nas shown in Figure 5, the quality of slow-down strategies using di.erent training inputs is quite similar \nin terms of energy usage. Similar conclusion can be drawn for the energy-delay product as well. For benchmarks \nswim and su2cor, using data set std.in as training input seems to produce better results. This is due \nto the di.erent CPU boundness values provided by the two di.erent data sets. For the reference data set \nof swim,the CPU boundness \u00dfcpu is 0.04. In contrast, data set std.in provides \u00dfcpu = 0.07 and data set \ntrain.in provides \u00dfcpu benchmark std.in selection Tr swim ref,900.45 P/700 101.10 tomcatv ref,750.62 \nsame 101.18 hydro2d ref,200.6 same 102.21 su2cor ref,40.5 R/800 107.31 applu ref,300.5 R/900 103.61 apsi \nref,960.6 R/900 105.00 mgrid test,40.4 R/1000 102.91 wave5 ref,40.10 R/800 102.33 turb3d ref,111.2 R/1100 \n106.16 fpppp train same 100.00 Table 6: The relative execution time and system en\u00adergy usage for the \nSPECfp95 benchmarks using train\u00ading input std.in. relative energy usage 1.2 1 0.8 0.6 0.4 0.2 0 Figure \n5: The relative energy usage of our compiler approach using training inputs train.in and std.in and the \npotential energy savings. = 0.19. Since data set std.in more closely models the CPU boundness of the \nreference data set, our algorithm was able to .nd a better slow-down strategy. Similarly, the reference \ndata set of su2cor provides \u00dfcpu = 0.17, while the data sets std.in and train.in provides \u00dfcpu = 0.25 \nand 0.47, respectively. As a result, our algorithm was able to exploit more memory boundness of the benchmark \nand produced a better energy-delay product value.  4.9 Comparison with Other Algorithms A natural follow-up \nquestion is how e.ective our com\u00adpiler algorithm is as compared to the other proposed DVS algorithms. \nWe would like to point out that many of the ex\u00adisting DVS algorithms have a set of parameters that can \nbe tuned. While it is possible to manipulate these parameters to get better e.ectiveness of the algorithms, \nit is still an open question how to do this in a systematic fashion. For exam\u00adple, Grunwald et al. [15] \nstudied several interval-based OS\u00addirected algorithms and found that the e.ectiveness of the best algorithm \nthey studied depends on the selected thresh\u00adold values which are data sensitive. To avoid the complications \ndue to di.erent settings of algorithm parameters, we have developed a methodology to compute the potential \nenergy savings any DVS algorithm can generate [17]. Speci.cally, given the set of measured execution \ntime and system power { (Tf ,Pf ) } at various frequencies f, the minimum energy usage Er * can be derived \nby solving the following linear programming problem. * . E =min (Pf ) tf r \u00b7 tf )/(Pfmax \u00b7 Tfmax f \nsubject to tf = (1 + r) \u00b7 Tfmax , f tf /Tf =1, 0 = tf f The optimal DVS algorithm { tf } determines \nthe duration (inseconds)ateachfrequency f such that the relative en\u00adergy usage Er is minimized while \nthe deadline is met and the required workload is performed. Figure 5 compares the energy usage derived \nby our DVS algorithm and the theoretical lower bound. It can be seen that in many cases our algorithm \nhas energy reduction very close to the lower bound, within 6%. In a few benchmarks, the lower bounds \nare larger than those using our algorithm. For example, the largest error occurs for benchmark su2cor \nusingdataset std.in, which is 5% more. It is because our algorithm does not guarantee that the performance \ncon\u00adstraint will always be satis.ed. The main reason is that the training input and the reference input \nmay have di.erent behaviors in terms of CPU-boundness. In this case our al\u00adgorithm generated the performance \nslow-down. For bench\u00admark su2cor, since our algorithm generates performance slow-down of 7.3%, we can \nreplace r =5%by r =7.3% when computing Er * . As a result, the di.erence drops down to 1.2%. We believe \nthe inaccuracy of 1.2% comes from the measurement errors when acquiring Tf and Pf experimen\u00adtally. Nevertheless, \nthe di.erence in energy usage between our algorithm and the theoretical optimum is never greater than \n2% for all tests we have done. 4.10 Multiple Region Extension Our compiler algorithm assumes that only \none region is allowed to be slowed down. This can certainly be relaxed to allow multiple regions to be \nslowed down. One way to do so is to formulate the algorithm as solving a zero-one inte\u00adger linear programming \nproblem (ZILP), as follows. Given  a program P = i Ri, we are trying to .nd out the val\u00adues for zero-one \nvariables .(Ri,f) that solves the following minimization problem: min .(Ri,f) \u00b7 Pf \u00b7 T(Ri,f)+ Ptrans \n\u00b7 Ntrans . i,f subject to i,f .(Ri,f)\u00b7 T(Ri,f)+Ttrans \u00b7 Ntrans = (1+r)\u00b7 T(P,fmax) .(Ri,f)=1 f where \nNtrans = N(Ri,Rj) \u00b7 1 \u00b7|.(Ri,f) - .(Rj ,f)| i,j 2 f Solution .(Ri,f) = 1 means that region Ri is executed \nat frequency f, 0 if not. Note that the total number of tran\u00adsitions Ntrans is 2 \u00b7 N(R) in the single-region \nalgorithm. In the multi-region algorithm, it is replaced by a more com\u00adplex equation. The equation enumerates \nall pairs of re\u00adgions Ri and Rj and accumulates the number of transitions from Ri to Rj , as indicated \nby N(Ri,Rj ), if the two re\u00adgions are assigned with di.erent frequencies, as indicated by 1 \u00b7|.(Ri,f) \n- .(Rj ,f)|. 2 f To estimate N(Ri,Rj ) from the pro.le N(R), a transi\u00adtion graph is constructed through \ninter-procedural analy\u00adsis. A transition graph is a directed graph whose nodes are regions Ri and edges \nare weighted by N(Ri,Rj). The current prototype implements reaching de.nition analysis and approximates \nthe number of transitions between regions N(Ri,Rj ). More details can be found in [18]. Note that, the \nproblem formulation is new, which unfortunately introduces more variables to solve due to the discreteness \nof the DVS levels. ZILP problems are in general considered hard problems due to the combinatorial aspect \nof integer programming. Experiences tell us that when the number of transitions ex\u00adceeds over 50, the \nsolver has a hard time to solve it e.\u00adciently, i.e., within a reasonable time. In our experiments, we \nset the reasonable time as an hour. Unfortunately, ex\u00adcept benchmarks swim and tomcatv,the rest of SPECfp95 \nbenchmarks have the number of transitions more than 50 and cannot be solved e.ciently. On one hand, techniques \nneed to be invented to reduce the problem size or approx\u00adimate the optimal solutions. On the other hand, \nas shown in Section 4.9, single-region algorithm is not far from the optimal DVS algorithm in terms of \nproducing energy e.\u00adcient programs. There is not much room for improvement because of multiple region \n.exibility. In general, this is good news since the multi-region algorithm is more complicated to implement \nand less e.cient in terms of compilation time.  4.11 System Design Concerns In this section we present \nan interesting comparison of two commercial laptop systems. One system has a high\u00adperformance processor \nwith a more e.cient memory subsys\u00adtem, and the other system has a low-power processor with a less e.cient \nmemory subsystem. Both systems support DVS using di.erent DVS algorithms. We compare the two systems \nfor their energy e.ciency. The high-performance system is the Compaq Presario lap\u00adtop, which is equipped \nwith our DVS algorithm. The low\u00adpower system is the Fujitsu LifeBook P2040 laptop, which is operated \nby another DVS algorithm, the LongRun tech\u00adnology [11]. Table 7 compares the two systems, including their \nDVS support and memory system performance. It can be seen that the Presario computer is high-power and \nhas a worse power-performance e.ciency (MIPS/W). The ratios were computed by running the Dhrystone 2.1 \nbenchmark on the two systems. On the other hand, its memory system performance is better. Both computers \nhave similar memory latency, but the memory bandwidth (MB/s) of the Presario computer is larger. In addition, \nit provides more memory\u00adlevel parallelism (MLP), i.e., it allows multiple outstanding cache misses. The \nmemory bandwidth was computed us\u00ading the STREAM benchmark [?]. The memory latency and the memory-level \nparallelism ratio were derived using the LMbench benchmark [?]. The comparison of the two systems is \nshown in Figure 6. The baseline is the energy-delay product on the Presario computer with our DVS algorithm \ndisabled. The LongRun technology is set to the economy mode with all .ve perfor\u00admance levels available. \nIt can be seen that in some bench\u00admarks such as swim and hydro2d, applying our DVS algo- Compaq Fujitsu \nspec Presario 715US LifeBook P2040 AMD Transmeta CPU mobile Athlon 4 Crusoe TM5800 RISC VLIW out-of-order \nin-order cache 384KB 512KB f 600-1200 MHz 300-800 MHz V 1.15-1.45 V 1.0-1.3 V levels 7 5 Pdhry 52.79 \nW 13.65 W MIPS/W 29.24 45.47 lmem (ns) 210.6 195.7 MLP 2.5 1.0 MB/s 436.4 347.1  Table 7: The DVS support \nand power breakdown of the two laptops we tested. rithm on a less power-e.cient system results in better \nen\u00adergy e.ciency. Furthermore, for CPU-bound applications such as wave5 and fpppp, even the high-performance \nnon-DVS system has much smaller energy-delay products. On average, the high-performance Presario computer \ntogether with our DVS algorithm reduces the energy-delay product by 9%. In contrast, the low-power LifeBook \ncomputer with the LongRun technology is 4% more than the Presario com\u00adputer without any DVS algorithm \nenabled. There are at least two reasons why the high-performance high-power system performs better in \nsome cases. First of all, the high-performance features of the system pays o. by reducing the total execution \ntime signi.cantly, though the power dissipation (i.e., energy usage per second) is higher due to the \nimplementation of these features. Secondly, the energy usage of the processor in the Presario computer \nis signi.cant. At the peak performance level, 64% of the total system power can be attributed to the \nprocessor for the Pre\u00adsario computer. In contrast, the processor of the LifeBook computer only contributes \n27%. Although AMD has an on-line DVS algorithm as part of the PowerNow! technique we are not able to \ncompare it against our DVS algorithm since the software is only exe\u00adcuted on the Microsoft Windows system. \n 5. CONCLUSIONS AND FUTURE WORK In this paper we have discussed a novel compiler algorithm that e.ectively \nutilizes dynamic voltage scaling to save en\u00adergy. The algorithm picks a single region to be executed \nat a lower performance level without introducing serious perfor\u00admance degradation. A prototype implementation \nbased on the SUIF2 compiler infrastructure was used to evaluate the algorithm on the SPECfp95 benchmarks. \nPhysical measure\u00adments showed that signi.cant energy savings in the range of 0% to 28% can be achieved \nwith performance penalties between 0% and 4.7% for the SPECfp95 benchmarks. On av\u00aderage, the energy and \nenergy-delay product are reduced by 11% and 9%, respectively, with a performance slowdown of 2.15%. To \nthe best of our knowledge, this work presents one of the .rst working implementation of DVS algorithms \nand one of the .rst to evaluate DVS algorithms through physical measurements. relative energy-delay \nproduct 2.5 2 1.5 1 0.5 0 swim tomcatv hydro2d su2cor applu apsi mgrid wave5 turb3d fpppp benchmark \nFigure 6: The relative energy-delay product of our compiler approach and the LongRun technology with \nrespect to the Presario notebook without DVS. The energy is the entire system energy. We plan to study \nthe impact of locality optimizations on the e.ectiveness of our DVS algorithm. Most advanced lo\u00adcality \noptimizations try to reduce the memory stalls to im\u00adprove performance while our DVS algorithm exploits \nmem\u00adory stalls for energy reduction. An early work [16] has shown that there are still plenty of opportunities \nto apply our DVS algorithm to the highly optimized codes. It is also observed that in some cases the \nless successful optimization lead to higher energy savings. We plan to perform a similar study on real \nsystems to see whether these observations still hold.  6. REFERENCES [1] N. AbouGhazaleh, D. Moss\u00b4e, \nB. Childers, and R. Melhem. Toward the placement of power management points in real time applications. \nIn Proceedings of the Workshop on Compilers and Operating Systems for Low Power, September 2001. [2] \nAdvanced Micro Devices, Inc. Mobile AMD athlon 4 processor model 6 CPGA data sheet. Publication 24319, \nNovember 2001. [3] A. Azevedo, I. Issenin, R. Cornea, R. Gupta, N. Dutt, A. Veidenbaum, and A. Nicolau. \nPro.le-based dynamic voltage scheduling using program checkpoints in the COPPER framework. In Proceedings \nof Design, Automation and Test in Europe Conference,March 2002. [4] D. Bailey. 21st century high-end \ncomputing. In Invited Talk, Applications, Algorithms, and Architectures Workshop for BlueGene/L, August \n2002. [5] F. Bellosa. The bene.ts of event-driven energy accounting in power-sensitive systems. In Proceedings \nof 9th ACM SIGOPS European Workshop, September 2000. [6] S. Borkar. Design challenges of technology scaling. \nIEEE Micro, 19(4):23 29, July/August 1999. [7] D. Brooks, V. Tiwari, and M. Martonosi. Wattch: A framework \nfor architectural-level power analysis and optimizations. In 27th International Symposium on Computer \nArchitecture , June 2000. [8] T. Burd and R. Brodersen. Energy e.cient CMOS microprocessor design. In \nthe 28th Hawaii International Conference on System Sciences , January 1995. [9] D. Burger. Hardware \nTechniques to Improve the Performance of the Processor/Memory Interface.PhD thesis, Computer Sciences \nDepartment, University of Wisconsin-Madison, 1998. [10] L. Chandrasena and M. Liebelt. A rate selection \nalgorithm for quantized undithered dynamic supply voltage scaling. In Proceedings of the International \nSymposium on Low-Power Electronics and Design , August 2000. [11] Transmeta Corporation. http://www.transmeta.com. \n[12] K. Flautner and T. Mudge. Vertigo: Automatic performance-setting for linux. In Proceedings of the \n5th Symposium on Operating Systems Design and Implementation, December 2002. [13] K. Flautner, S. Reinhardt, \nand T. Mudge. Automatic performance-setting for dynamic voltage scaling. In Proceedings of the 7th Annual \nInternational Conference on Mobile Computing and Networking, July 2001. [14] R. Gonzalez and M. Horowitz. \nEnergy dissipation in general purpose microprocessors. IEEE Journal of Solid-State Circuits, 31(9):1277 \n1284, September 1996. [15] D. Grunwald, P.Levis, K.Farkas, C. Morrey III,and M. Neufeld. Policies for \ndynamic clock scheduling. In Proceedings of the 4th Symposium on Operating System Design and Implementation \n, October 2000. [16] C.-H. Hsu and U. Kremer. Dynamic voltage and frequency scaling for scienti.c applications. \nIn Proceedings of the 14th annual workshop on Languages and Compilers for Parallel Computing , August \n2001. [17] C.-H. Hsu and U. Kremer. Compiler-directed dynamic voltage scaling for memory-bound applications. \nTechnical Report DCS-TR-498, Department of Computer Science, Rutgers University, August 2002. [18] C.-H. \nHsu and U. Kremer. Single region vs. multiple regions: A comparison of di.erent compiler-directed dynamic \nvoltage scheduling approaches. In Workshop on Power-Aware Computer Systems , 2002. [19] C.-H. Hsu, U. \nKremer, and M. Hsiao. Compiler-directed dynamic frequency and voltage scheduling. In Workshop on Power-Aware \nComputer Systems , November 2000. [20] C.-H. Hsu, U. Kremer, and M. Hsiao. Compiler-directed dynamic \nvoltage/frequency scheduling for energy reduction in microprocessors. In Proceedings of the International \nSymposium on Low-Power Electronics and Design , August 2001. [21] T. Ishihara and H. Yasuura. Voltage \nscheduling problem for dynamically variable voltage processors. In International Symposium on Low Power \nElectronics and Design , pages 197 202, August 1998. [22] S. Kim and A. Somani. Characterization of an \nextended multimedia benchmark on a general purpose microprocessor architecture. Technical Report DCNL-CA-2000-002, \nElectrical and Computer Engineering Department, Iowa State University, 2000. [23] K. Lahiri, A. Raghunathan, \nS. Dey, and D. Panigrahi. Battery-driven system design: A new frontier in low power design. In Asia South \nPaci.c Design Automation Conference / International Conference on VLSI Design, January 2002. [24] B. \nLee and L. John. Implications of programmable general purpose processors for compression/encryption applications. \nIn IEEE 13th International Conference on Application-speci.c Systems, Architectures and Processors, July \n2002. [25] S. Lee and T. Sakurai. Run-time voltage hopping for low-power real-time systems. In Proceedings \nof the 37th Conference on Design Automation , pages 806 809, June 2000. [26] J. Lorch and A. Smith. Improving \ndynamic voltage algorithms with PACE. In Proceedings of the International Conference on Measurement and \nModeling of Computer Systems , June 2001. [27] Z. Lu, J. Hein, M. Humphrey, M. Stan, J. Lach, and K. \nSkadron. Control-theoretic dynamic frequency and voltage scaling for multimedia workloads. In Proceedings \nof the 2002 International Conference on Compilers, Architectures, and Synthesis for Embedded Systems, \nOctober 2002. [28] D. Marculescu. On the use of microarchitecture-driven dynamic voltage scaling. In \nWorkshop on Complexity-E.ective Design, June 2000. [29] T. Martin and D. Siewiorek. Nonideal battery \nand main memory e.ects on cpu speed setting for low power. IEEE Transactions on Very Large Scale Integration \nSystem, 9(1):29 34, February 2001. [30] T. L. Martin. Balancing Batteries, Power, and Performance: System \nIssues in CPU Speed-Setting for Mobile Computing. PhD thesis, Department of Electrical and Computer Engineering, \nCarnegie Mellon University, Pittsburgh, Pennsylvania, 1999. [31] K. Masahiro, K. Kazuo, H. Kazuo, and \nO. Eiichi. WT110/WT130 digital power meters. Yokogawa Technical Report 22, 1996. [32] A. Miyoshi, C. \nLefurgy, E. Hensbergen, and R. Rajkumar. Critical power slope: Understanding the runtime e.ects of frequency \nscaling. In Proceedings of the 16th Annual ACM International Conference on Supercomputing, June 2002. \n[33] D. Moss\u00b4e, H. Aydin, B. Childers, and R. Melhem. Compiler-assisted dynamic power-aware scheduling \nfor real-time applications. In Workshop on Compiler and Operating Systems for Low Power , October 2000. \n[34] T. Mudge. Power: A .rst class design constraint for future architectures. IEEE Computer, 34(4):52 \n58, April 2001. [35] M. Pedram and Q. Wu. Design considerations for battery-powered electronics. In Proceedings \nof the 36th Conference on Design Automation, June 1999. [36] T. Pering, T. Burd, and R. Brodersen. The \nsimulation and evaluation of dynamic voltage scaling algorithms. In Proceedings of 1998 International \nSymposium on Low Power Electronics and Design , pages 76 81, August 1998. [37] P. Pillai and K. Shin. \nReal-time dynamic voltage scaling for low-power embedded operating systems. In Proceedings of the 18th \nSymposium on Operating Systems Principles, October 2001. [38] R. Rajamony and R. Bianchini. Energy management \nforserverclusters. In Tutorial, 16th Annual ACM International Conference on Supercomputing, June 2002. \n[39] H. Saputra, M. Kandemir, N. Vijaykrishnan, M.J. Irwin, J. Hu, C.-H. Hsu, and U. Kremer. Energy-conscious \ncompilation based on voltage scaling. In ACM SIGPLAN Joint Conference on Languages, Compilers, and Tools \nfor Embedded Systems and Software and Compilers for Embedded Systems , June 2002. [40] D. Shin and J. \nKim. A pro.le-based energy-e.cient intra-task voltage scheduling algorithm for hard real-time applications. \nIn Proceedings of the International Symposium on Low-Power Electronics and Design , August 2001. [41] \nT. Simunic, L. Benini, A. Acquaviva, P. Glynn, and G. De Micheli. Dynamic voltage scaling for portable \nsystems. In Proceedings of the 38th Design Automation Conference , June 2001. [42] A. Sinha and A. Chandrakasan. \nDynamic voltage scheduling using adaptive .ltering of workload traces. In Proceedings of the 14th International \nConference on VLSI Design, January 2001. [43] N. Slingerland and A. Smith. Cache performance for multimedia \napplications. In Proceedings of the 15th IEEE International Conference on Supercomputing, June 2001. \n[44] S. Sohoni, Z. Xu, R. Min, and Y. Hu. A study of memory system performance of multimedia applications. \nIn ACM Joint International Conference on Measurement &#38; Modeling of Computer Systems , June 2001. \n[45] SUIF. Stanford University Intermediate Format. [46] RLX Technologies. Serverblade. http://www.rlxtechnologies.com. \n[47] K. van den Doel, P. Kry, and D. Pai. FoleyAutomatic: Physically-based sound e.ects for interactive \nsimulation and animation. In Proceedings of the 28th annual conference on Computer graphics and interactive \ntechniques, August 2001. [48] F. Xie and M. Martonosi and S. Malik. Compile time dynamic voltage scaling \nsettings: Opportunities and limits. In Proceedings of the ACM SIGPLAN Conference on Programming Languages \nDesign and Implementation , June 2003. [49] F. Yao, A. Demers, and S. Shenker. A scheduling model for \nreduced cpu energy. In IEEE Annual Symposium on Foundations of Computer Science, pages 374 382, October \n1995. [50] W. Ye, N. Vijaykrishna, M. Kandemir, and M.J. Irwin. The design and use of SimplePower: A \ncycle-accurate energy estimation tool. In Design Automation Conference , June 2000.  \n\t\t\t", "proc_id": "781131", "abstract": "This paper presents the design and implementation of a compiler algorithm that effectively optimizes programs for energy usage using dynamic voltage scaling (DVS). The algorithm identifies program regions where the CPU can be slowed down with negligible performance loss. It is implemented as a source-to-source level transformation using the SUIF2 compiler infrastructure. Physical measurements on a high-performance laptop show that total <i>system</i> (i.e., laptop) energy savings of up to 28% can be achieved with performance degradation of less than 5% for the <b>SPECfp95</b> benchmarks. On average, the system energy and energy-delay product are reduced by 11% and 9%, respectively, with a performance slowdown of 2%. It was also discovered that the energy usage of the programs using our DVS algorithm is within 6% from the theoretical lower bound. To the best of our knowledge, this is one of the first work that evaluates DVS algorithms by physical measurements.", "authors": [{"name": "Chung-Hsing Hsu", "author_profile_id": "81100321639", "affiliation": "", "person_id": "PP39037584", "email_address": "", "orcid_id": ""}, {"name": "Ulrich Kremer", "author_profile_id": "81339510457", "affiliation": "Rutgers, The State University of New Jersey", "person_id": "PP43125724", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/781131.781137", "year": "2003", "article_id": "781137", "conference": "PLDI", "title": "The design, implementation, and evaluation of a compiler algorithm for CPU energy reduction", "url": "http://dl.acm.org/citation.cfm?id=781137"}