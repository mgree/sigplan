{"article_publication_date": "05-09-2003", "fulltext": "\n Compile-Time Dynamic Voltage Scaling Settings: Opportunities and Limits Fen Xie Margaret Martonosi \nSharad Malik Department of Electrical Department of Electrical Department of Electrical Engineering Engineering \nEngineering Princeton University Princeton University Princeton University Princeton, NJ Princeton, NJ \nPrinceton, NJ fxie@ee.princeton.edu mrm@ee.princeton.edu sharad@ee.princeton.edu ABSTRACT With power-related \nconcerns becoming dominant aspects of hard\u00adware and software design, signi.cant research effort has been \nde\u00advoted towards system power minimization. Among run-time power\u00admanagement techniques, dynamic voltage \nscaling (DVS) has emerged as an important approach, with the ability to provide signi.cant power savings. \nDVS exploits the ability to control the power con\u00adsumption by varying a processor s supply voltage (V) \nand clock frequency (f). DVS controls energy by scheduling different parts of the computation to different \n(V, f) pairs; the goal is to minimize energy while meeting performance needs. Although processors like \nthe Intel XScale and Transmeta Crusoe allow software DVS con\u00adtrol, such control has thus far largely \nbeen used at the process/task level under operating system control. This is mainly because the energy \nand time overhead for switching DVS modes is considered too large and dif.cult to manage within a single \nprogram. In this paper we explore the opportunities and limits of compile\u00adtime DVS scheduling. We derive \nan analytical model for the max\u00adimum energy savings that can be obtained using DVS given a few known \nprogram and processor parameters. We use this model to de\u00adtermine scenarios where energy consumption \nbene.ts from compile\u00adtime DVS and those where there is no bene.t. The model helps us extrapolate the \nbene.ts of compile-time DVS into the future as processor parameters change. We then examine how much \nof these predicted bene.ts can actually be achieved through optimal settings of DVS modes. This is done \nby extending the existing Mixed-integer Linear Program (MILP) formulation for this prob\u00adlem by accurately \naccounting for DVS energy switching overhead, by providing .ner-grained control on settings and by considering \nmultiple data categories in the optimization. Overall, this research provides a comprehensive view of \ncompile-time DVS management, providing both practical techniques for its immediate deployment as well \ntheoretical bounds for use into the future. Categories and Subject Descriptors D.3.4 [Programming Languages]: \nProcessors Compilers; D.4.7 [Operating System]: Organization and Design Real-time Sys\u00adtems and Embedded \nSystems; I.6.4 [Computing Methodologies]: Simulation and Modelling Model Validation and Analysis Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 03, June 9 \n11, 2003, San Diego, California, USA. Copyright 2003 ACM 1-58113-662-5/03/0006 ...$5.00. General Terms \nDesign, Experimentation Keywords Low Power, Compiler, Dynamic Voltage Scaling, Mixed-integer Linear Programming, \nAnalytical Model 1. INTRODUCTION The International Technology Roadmap for Semiconductors high\u00adlights \nsystem power consumption as a limiting factor in our ability to develop designs below the 50nm technology \npoint [26]. Indeed power/energy consumption has already started to dominate execu\u00adtion time as the critical \nmetric in system design. This holds not just for mobile systems due to battery life considerations, but \nalso for server and desktop systems due to exorbitant cooling, packaging and power costs. Dynamic voltage \nand frequency scaling (DVS) is a technique that allows the system to explicitly trade off performance \nfor en\u00adergy savings, by providing a range of voltage and frequency oper\u00adating points. DVS allows one \nto reduce the supply voltage at run time to reduce power/energy consumption. However, reducing the voltage \n(V) increases the device delay and so must be accompa\u00adnied by a reduction in clock frequency (f). Thus, \nthe voltage and frequency must be varied together. Proposals have been made for purely-hardware DVS [21] \nas well as for schemes that allow DVS with software control [7, 14, 12]. DVS accomplishes energy re\u00adduction \nthrough scheduling different parts of the computation to different (V,f) pairs so as to minimize energy \nwhile still meeting execution time deadlines. Over the past few years DVS has been shown to be a powerful \ntechnique that can potentially reduce over\u00adall energy consumption by several factors. More recently DVS \ncontrol has been exposed at the software level through instructions that can set particular values of \n(V,f). These mode-set instructions are provided in several contemporary microprocessors, such as Intel \nXScale [14], StrongArm SA-2 and AMD mobile K6 Plus [1]. However, the use of these instructions has been \nlargely at the process/task level under operating system control. The coarser grain control at this level \nallows for easy amor\u00adtization of the energy and run-time overhead incurred in switching between modes \nfor both the power supply (V) as well as the clock circuitry (f). It also makes the control algorithm \neasier since it is relatively easy to assign priorities to tasks, and schedule higher pri\u00adority tasks \nat higher voltages and lower priority tasks at lower volt\u00adages. Providing this control at a .ner grain \nlevel within a program would require careful analysis to determine when the mode-switch advantages outweigh \nthe overhead. Hsu and Kremer provide a heuristic technique that lowers the voltage for memory bound sec\u00adtions \n[10]. The intuition is that the execution time here is bound by memory access time, and thus the compute \ntime can be slowed down with little impact on the total execution time, but with poten\u00adtially signi.cant \nsavings in energy consumption. Using this tech\u00adnique, they have been able to demonstrate modest energy \nsavings. Subsequent work on using mathematical optimization by Saputra et al. [25] provides an exact \nmixed-integer linear programming (MILP) technique that can determine the appropriate (V,f) setting for \neach each loop nest. This optimization seems to result in better energy savings. However, this formulation \ndoes not account for any energy penalties incurred by mode switching. Thus, it is unclear how much of \nthese savings will hold up once those are accounted for. In this paper we are interested in studying \nthe opportunities and limits of DVS using compile-time mode settings. We seek to an\u00adswer the following \nquestions: Under what scenarios can we get signi.cant energy savings? What are the limits to these savings? \nThe answers to these questions determine when and where (if ever) is compile-time DVS worth pursuing. \nWe answer these questions by building a detailed analytical model for energy savings for a pro\u00adgram and \nexamining its upper limits. In the process we determine the factors that determine energy savings and \ntheir relative con\u00adtributions. These factors include some simple program dependent parameters, memory \nspeed, and the number of available voltage levels. We also examine how these opportunities can be exploited \nin practice. Towards this end we develop an MILP optimization for\u00admulation that extends the formulation \nby Saputra et al. by including energy penalties for mode switches, providing a much .ner grain of program \ncontrol, and enabling the use of multiple input data categories to determine optimal settings. We show \nhow the solu\u00adtion times for this optimization can be made acceptable in practice through a judicious \nrestriction of the mode setting variables. Fi\u00adnally, we show how the results of this optimization relate \nto the limits predicted by our analytical model. The rest of this paper is organized as follows. Section \n2 re\u00adviews related work in this area. This is followed by a description of our analytical model and analysis \nin Section 3. Section 4 derives the MILP formulation used to determine the values of the optimal mode \nsetting instructions. Section 5 discusses some implementa\u00adtion details for our MILP-based approach, and \nSection 6 provides the results of various experiments. Critical and unresolved issues are the focus of \nSection 7. Finally, we present some concluding remarks in Section 8.  2. RELATED WORK DVS scheduling \npolicies have been studied exhaustively at the operating system, micro-architecture and compiler levels. \nAlgo\u00adrithms at the OS level using heuristic scheduling include an interval\u00adbased algorithm like Lorch \nand Smith s proposal [19] and a task\u00adbased algorithm like Luo and Jha s work [20]. Integer Linear Pro\u00adgramming \n(ILP) based scheduling has also been used in algorithms at the OS level. For example, Ishihara and Yasuura \n[15] give an ILP formulation that does not take into account the transition costs. Swaminathan and Chakrabarty \n[28] incorporate the transition costs into the ILP formulation but make some simpli.cations and ap\u00adproximations \nin order to make the formulation linear. At the micro\u00adarchitecture level, Ghiasi [9] suggests the use \nof IPC (instructions per cycle) to direct DVS, and Marculescu [21] proposes the use of cache misses to \ndirect DVS. Both are done through hardware sup\u00adport at run time. Some research efforts have targeted \nthe use of mode-set instruc\u00adtions at compile time. Mode-set instructions are inserted either evenly at \nregular intervals in the program like Lee and Sakurai s work [18], or on a limited number of control \n.ow edges as proposed by Shin [27]. In the latter, the mode value is set using worst-case execution time \nanalysis for each basic block. Hsu and Kremer [10] suggest lowering voltage/frequency in memory-bound \nregions us\u00ading power-down instructions and provide a non-linear optimization formulation for optimal \nscheduling. Saputra et al. [25] derive an ILP formulation for determining optimal modes for each loop \nnest, but do not consider the energy overhead of switching modes. The ef.ciency of scheduling policies \nhas also been discussed in the literature. Hsu and Kremer [11] have introduced a simple model to estimate \ntheoretical bounds of energy reduction any DVS algo\u00adrithm can produce. In [15], a simple ideal model \nwhich is solely based on the dynamic power dissipation of CMOS circuits has been studied and an OS level \nscheduling policy is discussed based on that model and ILP. Some other work focuses only on the limits \nof energy savings for DVS systems without taking into consideration actual policies. Qu provides models \nfor feasible DVS systems in his work [23]. However, evaluating the potential energy savings of compile-time \nDVS policies for real programs has not received much attention thus far. We feel it is important as it \ngives us deep insight into opportunities and limits of compile time DVS. In this paper, we present a \nrealistic analytical model incorporat\u00ading features of both real program behavior and compile time DVS \nscheduling. We also extend existing ILP formulations to apply DVS to any granularity of program code \nwith practical transition costs and multiple data categories. 3. ANALYTICAL MODELING FOR ENERGY SAVINGS \nFROM COMPILE-TIME DVS 3.1 Overview We are interested in answering the following questions: What are the \nfactors that in.uence the amount of power savings obtained by using compile-time DVS? Can we determine \nthe power savings and upper bounds for them in terms of these factors? The answers to these questions \nwill help provide insight into what kinds of pro\u00adgrams are likely to bene.t from compile-time DVS, under \nwhat sce\u00adnarios and by how much. Among other outcomes, accurate analysis can help lay to rest the debate \non the value of intra-program DVS scheduling. There has been some research on potential energy savings \nfor DVS scheduling. Analytical models have been studied in [15] and [23]. However, that research only \nmodels computation operations and not memory operations, thus not capturing the critical aspect of program \nexecution. Further, their models are not suitable for bound analysis for compile time DVS because they \nignore critical aspects of the compile time restriction. In this section, we describe a more realistic \nand accurate analytical model to determine achievable en\u00adergy savings that overcome the restrictions \nof prior modeling ef\u00adforts. In deriving this model we make the following assumptions about the program, \nmicro-architecture and circuit implementation: 1. The program s logical behavior does not change with \nfre\u00adquency. 2. Memory is asynchronous with the CPU. 3. The clock is gated when the processor is idle. \n 4. The relationship between frequency and voltage is: f = k(v - vt)a/v where vt is the threshold voltage, \nand a is a technology-dependent factor (currently around 1.5) [24]. 5. Computation can be assigned to \ndifferent frequencies at an arbitrarily .ne grain, i.e. a continuous partitioning of the computation \nand its assignment to different voltages is pos\u00adsible. 6. There is no energy or delay penalty associated \nwith switching between different (V,f) pairs.  While the .rst 4 assumptions are very realistic, the \nlast two are optimistic in the sense that they allow for higher energy savings than may be achievable \nin practice. As we are interested in deter\u00admining upper bounds on the achievable savings, this is acceptable. \nOf course, the optimism should not result in the bounds being too loose and thus useless in practice. \nWe will review the tightness of the bounds in Section 6. 3.2 Basic Model The existence of memory operations \ncomplicates the analysis. Cache misses provide an opportunity for intra-program DVS, since execution \ntime will not change with voltage/frequency if the mem\u00adory is asynchronous with the processor. Slowing \ndown the fre\u00adquency in that region will save energy without impacting perfor\u00admance. However, savings \nare limited by the compile-time aspect of intra-program DVS. As mode-set instructions are inserted stat\u00adically, \nit applies to all executions of a speci.c memory reference, both cache misses as well as hits. It is \nrare to have a reference always suffer a miss. Slowing down all executions for that refer\u00adence may save \nenergy for cache misses, but will result in loss of performance for cache hits. Our model captures this \neffect. For any piece of static code, we can divide it into two major op\u00aderations: computation and memory \noperations. For computation operations, some operations depend on the result of pending mem\u00adory operations, \nreferred to as the dependent part, and some can run concurrently with memory operations, referred to \nas the overlap part. For memory operations, some end up being cache hits and others need to go to memory \nto fetch the operands. We de.ne the following program parameters of the model based on the observa\u00adtion. \nNoverlap The number of execution cycles of computation opera\u00adtions that can run in parallel with memory \noperations. Ndependent The number of execution cycles of computation oper\u00adations that are dependent on \nmemory operations. Ncache The number of execution cycles of memory operations due to cache hits. tinvariant \nThe execution time of cache miss memory operations. As memory operates asynchronously relative to the \nproces\u00adsor, this time is independent of processor frequency, and thus is measured absolutely rather than \nin terms of processor cy\u00adcles. Consequently, the total execution time for any piece of code or program \nas it just meets its deadline can be represented as illus\u00adtrated in Figure 1, with the different cases \ncorresponding to differ\u00adent relative values of these parameters. In these .gures, the fre\u00adquency f is \nnot .xed through the program execution and may vary. In the .gures, tdeadline is the time deadline that \nthe computation needs to meet. Note that in actual program execution the memory operations and the overlapping \nand dependent computations will be interleaved in some way. However, we can lump all the occurrences \nof each category together as shown in the above .gures since, as we will show, for purposes of the analysis \nit is suf.cient to consider the total time taken by each of these categories. Also, we can consider the \nvertical dimension to be time, and order the three categories as shown, even though in actual execution \nthey will be interleaved. In Figure 1(a), parallel computation operations determine the ex\u00adecution time \nof the overlap part and total execution time is Noverlap/f+ Ndependent /f. In Figures 1(b) and 1(c), \nmemory operations domi\u00adnate the overlap part and total execution time is tinvariant+Ncache/f+ Ndependent \n/f. The .ner distinction between Figures 1(b) and 1(c) will be made later in the analysis. The total \nexecution time expres\u00adsion for any of these cases is: max(tinvariant + Ncache/f, Noverlap/f)+ Ndependent \n/f The goal of the analytical model is to .nd minimum energy points (i.e., maximum energy savings) using \ndifferent voltages for differ\u00adent parts of the execution, subject to the following two time con\u00adstraints: \n1. The total execution time is less than tdeadline. 2. The time for the dependent computation operations \ncannot overlap with the time for the memory operations tinvariant+ Ncache  f . This respects the fact \nthat dependent calculations must wait for the memory operations to complete. We now state our overall \noptimization problem. In Figure 1, as\u00adsume a time ordering from top to bottom. Let t1 be the time the \noverlapping computation .nishes, t2 be the time the dependent op\u00aderations start execution and t3 be the \ntime all computation .nishes. The goal, then, is to minimize: t1 t3 E = v12(t)f1(t)dt + v22(t)f2(t)dt \n0 t2 Ncache f1 and (iii) t1 = t2. The .rst integral represents energy con\u00adsumption during the overlapping \ncomputation. The second integral represents energy during the dependent computation period. As mentioned \nearlier, we assume perfect clock gating when the proces\u00adsor is waiting for memory, and thus there is \nno energy consumption in the processor during idle memory waits. Also, we account here for only the processor \nenergy; the memory energy is a constant independent of processor frequency. Unlike models proposed in \n[15] or [23], the presence of memory operations adds signi.cant complexity to the optimization problem. \nWe now consider speci.c cases of this optimization, corresponding to different options for the set of \nvoltages available.  3.3 Continuously Scalable Supply Voltage We .rst consider the case where the supply \nvoltage can be scaled continuously, i.e. v1,v2 can vary continuously over some range [VL,VH ]. While \ncontinuous scaling may not be available in prac\u00adtice, this analysis serves two purposes. First, it helps \nus build up to the discrete case presented in the next section. Second, it approx\u00adimates the case where \nthe number of discrete voltages available is suf.ciently large. Previous work considering only computation \nop\u00aderations and not memory operations showed that for a .xed dead\u00adline, the optimal solution is to use \na single supply voltage which adjusts the total execution time to just meet the deadline [15]. So, in \nthis case v1 is a constant over [0,t1] and 0 at other times. v2 is a constant over [t2,t3] and 0 otherwise. \nWe now need to .nd appro\u00adpriate v1, v2, [0,t1] and [t2,t3] such that energy is minimized. 3.3.1 Computation \nDominated and Memory Domi\u00adnated Cases The .rst two cases illustrated in Figure 1 arise depending on the \nbalance of computation and memory operations. In the computa\u00adtion dominated case, the memory time is \nlargely irrelevant, because meeting the deadline mainly revolves around getting the computa\u00adtion done \nin time. Because this case has no slack due to asyn\u00adchrony with memory, this case is similar to the pure \ncomputation case in [15] and thus a single frequency leads to optimal energy performance. In the memory \ndominated case, the computation is broken into two parts, the overlapped and the dependent part, each \nwith its own time constraint. Thus, the optimal operating point arises when two frequencies are chosen: \none for the overlapped computation, and a different one for the dependent computation. For both the com\u00adputation \nand memory dominated cases, the .rst case we consider is when the overlapping computation operations \ntake longer than cache hit memory operations, which means Ncache <Noverlap. This means that any frequency \nadjustments done in the upper part of the timeline will dilate the computation side more than the mem\u00adory \nside. Section 3.3.2 handles the (relatively uncommon) other possibility later. A key dividing line between \nthe computation dominated and memory dominated cases concerns the in.ection point when mem\u00adory time begins \nto matter. We use the term finvariant to refer to a clock frequency at which the execution time of Noverlap \n- Ncache cycles of computation operations just balances the cache miss ser\u00advice time tinvariant. (Therefore, \nwe use vinvariant to refer to the voltage setting paired with that frequency). If the optimal energy \npoint can be reached with a frequency slower than finvariant we say that the program is computation dominated. \nIf the speed is slower than finvariant, then the Noverlap - Ncache cycles of com\u00adputation operations \ntake up all cache miss period tinvariant and go beyond as shown in 1(a). The problem becomes one of minimizing: \n22 E(v1,v2)= Noverlap * v1 + Ndependent * v2 subject to different constraints depending on If f1 >finvariant \nNcache Ndependent ++ tinvariant = tdeadline subject to the constraints (i) t3 = tdeadline, (ii) t2 = \ntinvariant + f1 f2    (a) Computation-Dominated Case. (b) Memory-Dominated Case. (c) Sub-Case: Memory-Dominated, \nwith slack. Figure 1: Possible Overlaps of Memory and Computation 5 x 10 If f1 = finvariant 7 Noverlap \nNdependent += tdeadline 6 f1 f2 Representing f as a function of v to get all equations in terms of v: \nIf k(v1-vT )a >finvariant v1 Ncachev1 Ndependent v2 ++ tinvariant = tdeadline k(v1 - vT )a k(v2 - vT \n)a If k(v1-vT )a = finvariant v1 Noverlapv1 Ndependent v2 += tdeadline k(v1 - vT )a k(v2 - vT )a Due \nto the time constraints, v1 and v2 are not independent. We use this in deriving the value of v1 (and \nthus v2) that results in the least energy as follows. dE dv2=2Noverlapv1 +2Ndependent v2 dv1 dv1 dv2 \nis obtained from the constraint equations. dv1 If k(v1-vT )a >finvariant v1 dv2 (1 - a - vT )(v2 - vT \n)a+1 Ncachev1 v1 = - ) (v1 - vT )a+1 dv1 Ndependent v2 (1 - a - vT ) v2 If k(v1-vT )a v1 = finvariant \ndv2 (1 - a - vT )(v2 - vT )a+1 Noverlapv1 v1 = - ) (v1 - vT )a+1 dv1 Ndependent v2 (1 - a - vT ) v2 k(v1-vT \n)a So, if f1 = >finvariant, we get: v1 dE (1 - a - vT )(v2 - vT )a+1 Ncache v1 =2Noverlapv1(1 - ) (v1 \n- vT )a+1 dv1 Noverlap (1 - a - vT ) v2 On the other hand if k(v1-vT )a = finvariant then: v1 dE (1 - \na - vT )(v2 - vT )a+1 v1 =2Noverlapv1(1 - ) (v1 - vT )a+1 dv1 (1 - a - vT ) v2 Energy Consumption 1 \n0 Supply Voltage v1 (volt) Figure 2: Computation Dominated: Energy consumption ver\u00adsus supply voltage \n(v1) of overlapped compute/memory region. Noverlap+Ndependent We de.ne fideal = . The conditions for \ntdeadline which minimum energy is achieved depend on the relationship be\u00adtween finvariant and fideal. \nIf finvariant = fideal, then using the single frequency fideal, tinvariant is completely .lled up with \ncomputation operations as shown in Figure 1(a). It is obvious that dE =0.So v1 = dvideal v2 = videal \nis the required condition to minimize energy. This is consistent with the equation for the case f1 = \nfinvariant. Figure 2 shows the relationship between energy consumption and supply voltage v1 for a set \nof parameters that satisfy these con\u00additions (i.e. Ncache <Noverlap,finvariant = fideal). The energy \nconsumption using vinvariant and videal are shown. When v1 < videal or v1 >videal, energy consumption \nincreases as you move away from videal. When v1 = v2 = videal, energy is minimized. The minimum energy \nis E =(Noverlap + Ndependent )videal. Since a single (V,f) setting is optimal for this case, intra-program \nDVS will not provide energy savings here. If finvariant <fideal, Figure 3 shows the energy consump\u00adtion \nwith respect to different v1. While the computation-dominated case had a single frequency setting as \nits optimal point, this case requires two different settings for optimality. It is hard to give a closed-form \nexpression for the optimal settings, but we can use tools to get numerical solutions. To plot the energy \nrelationship, we selected various values of v1, and for each v1 we compute the optimal value of v2 from \nthe relationships above. Therefore, the minimum energy point in Figure 3 shows the best v1 choice, this \n x 105 x 105 2.5 7 6 2 5 1.5 Energy Comsumption Energy Comsumption 4 3 1 V ideal 2 Vinvariant V opt 1 \nVideal 0 0 0.5 1 1.5 2 2.5 3 3.5 Supply Voltage v1 (volt) Figure 3: Memory Dominated: Energy consumption \nversus supply voltage (v1) of mixed compute/memory region. allows us to select the overall optimal v1,v2 \npair. What we see is that the optimum point in this case is for a v1 that is less than videal from the \ncomputation-dominated case, and a v2 that is greater. This corresponds to low-frequency operation while \nthe overlapped com\u00adputation is hidden by the memory latency operation, followed by high-frequency hurry-up \nexecution of the dependent computation when memory .nally returns.  3.3.2 Special Case: Memory-Dominated, \nwith slack. 0.5 0 0 0.5 1 1.5 2 2.5 3 3.5 Supply Voltage v (volt) 1 Figure 4: Memory Dominated, with \nslack: Energy consump\u00adtion versus supply voltage (v1) of mixed compute/memory re\u00adgion. 0.1 0.08 Energy \nSaving 0.06 0.04 0.02 Thus far, we have dealt with cases where Ncache is relatively small compared to \nNoverlap.If Ncache = Noverlap, the cache hit memory operations take longer than the overlapping computa\u00adtion \noperations, and indeed any attempt to slow down the overlap execution will actually dilate the memory \ntime by an even greater amount due to Ncache. This case is illustrated in Figure 1(c). This effect can \nbe thought of as related to the fact that when we assign clock frequencies to code regions statically, \nwe are .xing the clock frequency both for executions of the static code that result in many cache misses \nas well as for other executions that may result in many cache hits. Ndependent The total execution time \nhere is Ncache ++tinvariant. f1 f2 The problem then reduces to minimizing: 22 E(v1,v2)= Ncachev1 + Ndependent \nv2 subject to the following deadline constraint: Ncachev1 Ndependent v2 ++ tinvariant = tdeadline k(v1 \n- vT )a k(v2 - vT )a (Here, we have assumed the (V,f) relationship given in Section 3.1.) From this we \nget: (1 - a - vT )(v2 - vT )a+1 =2Ncachev1 * (1 - v1 * ) dE (v1 - vT )a+1 dv1 (1 - a - vT ) v2 Ncache+Ndependent \nLet fideal = and videal the corresponding tdeadline-tinvariant supply voltage for this case. Energy consumption \nsatisfying the above time constraints is a convex function of v1 as shown in Figure dE 4. It is easy \nto deduce that when v1 = v2 = videal, dv1 =0.A single frequency fideal minimizes energy consumption. \n2 Emin =(Ncache + Ndependent )videal  3.3.3 Continuous Voltage Settings: Summary and Results The primary \nresult here is that a special relationship between var\u00adious parameters is required to achieve energy \nsavings using compile\u00adtime mode settings. Speci.cally, we need Noverlap >Ncache and fideal >finvariant. \nThe latter of these conditions translates to: 0 1500 1000 Ndependent (103 cycles) 500 200 400 600 800 \n1000 1200 1400 1600 1800 Noverlap (103 cycles) Figure 5: Continuous Case: Energy Saving Ratio with re\u00adspect \nto different Noverlap and Ndependent (Ncache =3 \u00d7 105cycles, tdeadline = 3000\u00b5s, tinvariant = 1000\u00b5s). \n(Noverlap+Ndependent )/tdeadline > (Noverlap-Ncache)/tinvariant. When all the parameters are consistent \nwith the above conditions, it is possible to use multiple voltages for different parts of the com\u00adputation \nto achieve power savings over the single voltage case. Fur\u00adther, the analysis tells us that two voltages \nsuf.ce for this case. Energy savings is a function of Noverlap, Ndependent , Ncache, tinvariant and tdeadline. \nTo visualize the dependence, we now con\u00adsider various surfaces in this space, keeping three of these \nparame\u00adters at .xed values and varying two of them. Energy savings for different Noverlap and Ndependent \nare il\u00adlustrated in Figure 5. For .xed Ncache,tdeadline and tinvariant, for most cases, there is no energy \nsavings. When Noverlap is less than Ncache, computation operations will not extend over the full tinvariant \nperiod, so one single frequency can achieve the min\u00adimum energy. This corresponds to Figure 4. Recall \nthat single frequency outcomes offer no energy savings over a .xed a priori frequency choice. As Noverlap \nincreases, some computations can be executed within tinvariant without increasing execution time. Two \nfrequencies instead of one can then used to achieve minimum energy, as shown in Figure 3. As Noverlap \nkeeps increasing, even\u00adtually computation operations dominate. At this point, the virtual deadline set \nby memory operations is of no consequence and a sin\u00adgle frequency (this time due to computation dominance) \nwill once again be optimal. This corresponds to Figure 2. Thus there are again no energy savings when \ncompared to the best static single frequency setting. In Figure 6, Noverlap,Ndependent and tdeadline \nare .xed. As tinvariant increases, energy saving increases. This is intuitive be\u00adcause as the memory \nbottleneck increases, the opportunities for Subject to constraint: 0.5 h i (x1i + x2i) = 0.4 tdeadline \nFi 0.3 Energy Saving 0.2 0.1 0 3500 3000 2500 2000 1500 500 1000 tinvariant (\u00b5s) 80010001200140016001800 \n600 400 200 Ncache (103 cycles) Figure 6: Continuous Case: Energy Saving Ratio with re- Here x1i and \nx2i are the number of cycles at voltage level i for the two parts of the computation respectively. The \nconstraint above is just the minimum constraint. Other constraints will depend on the values of certain \nparameters and will be added on a case by case basis. Leveraging off prior work by [15] allows us to \nprogress on the problem. We have already used the result that for computation with a .xed deadline and \nno memory operations, with continuous volt\u00adage scaling, a single voltage level results in the least energy. \nWe now use a second result provided there. For the discrete case they show that the minimum energy can \nbe obtained by selecting the spect to different Ncache and tinvariant (Noverlap =4 \u00d7 two immediate neighbors \nof the optimum voltage in the continuous 106cycles, Ndependent =5.8 \u00d7 106cycles, tdeadline = 5000\u00b5s). \n0.35 0.3 case that are available in the discrete set. Thus, for the computation bound and memory bound \nwith slack cases, both of which needed a single optimum frequency, fopt, in the continuous case, we know \nthat the discrete case will require the two immediate neighbors of fopt from the available voltages. \nWhat remains to be determined is the number of cycles each of these frequencies is used for. We determine \nthis for the computation dominated case from Sec\u00adtion 3.3. The memory bounded with slack case is similar \nand will Energy Saving Figure 7: 0.25 0.2 0.15 0.1 0.05 0 500 1000 1500 1500 2000 2000 2500 2500 3000 \n3000 3500 N (103cycles) 4500 4000 3500 cache 4000 5000 t(\u00b5s) deadline Continuous Case: Energy Saving \nRatio with re\u00ad spect to different tdeadline and Ncache (Noverlap =4 \u00d7 106cycles, Ndependent =5.7 \u00d7 106cycles, \ntinvariant = 1000\u00b5s). voltage scaling due to overlap slack increase. Usually when not be discussed here. \nConsider the two neighboring values for voltage and frequency: va <videal <vb and fa <fideal <fb. Say \nthat xa cycles are executed with voltage va and xb cycles are executed with voltage vb. The values for \nxa and xb are determined by solving for the following constraints: xa/fa + xb/fb = tdeadline xa + xb \n= Noverlap + Ndependent Consider next the memory-dominated case that resulted in two frequencies in the \ncontinuous-scaling approach. We cannot use the two frequencies from the continuous case to .nd discrete \nfrequen\u00adcies that minimize the energy as we did for the single frequency case. Instead, this needs a \nfresh analysis approach. Let variable y represent the execution time for Ncache. Then Ncache y must be \nless than finvariant to stay in the memory-dominated Ncache case. Since y is a deadline for Ncache, we \nknow that f1 = y is the optimal frequency for this code in the continuous case. Sim- Ndependent Ncache \n =0, energy saving is maximized. This is because when ilarly, f2 is the optimal frequency for = tdeadline-tinvariant-y \nall memory operations are cache miss memory operations, slowing down the overlap computations does not \ndilate the memory time-Ndependent . This gives us: fa,fb the immediate discrete neigh\u00ad bors of f1 and \nfc,fd the immediate discrete neighbors of f2,asthe line, and thus does not impede the start of the dependent \noperations. Figure 7 shows energy savings with respect to different tdeadline and Ncache. Other parameters \nare .xed. When Ncache is small, as tdeadline increases, energy savings increase. Once again, this makes \nintuitive sense because the greater slack gives more oppor\u00adtunities for energy savings. As Ncache gets \nbigger, however, en\u00ad four frequencies required in this case. What remains to be deter\u00ad mined is the number \nof cycles executed at each frequency. These are obtained by solving for the following constraints: xa/fa \n+ xb/fb = y ergy savings go up, achieve a maximum point and then go down again. This is because as Ncache \nincreases, the slowdown over the tinvariant has more impact on the execution time. So it is less likely \ntwo frequencies will reduce energy.  3.4 Scaling Voltage with Discrete Settings In the case where voltage \nis continuously scalable, optimal set\u00adtings can always be obtained with either one or two voltage choices. \nIn real processors, however, supply voltages are much more likely to be scalable only in discrete steps. \nThus, rather than having free choice of v1 and v2, they must be selected from a set of values (VL,VL2...Vh). \nThe problem becomes one of minimizing: xc/fc + xd/fd = tdeadline - tinvariant - y xa + xb = Ncache xc \n+ xd = Ndependent Note that thus far, all the frequencies and cycle counts deter\u00admined are a function \nof y, i.e. they depend on the value of y se\u00adlected. We can also express the minimum energy as a function \nof y. We run as many execution cycles as possible from Noverlap - Ncache at the lower frequency fa and \nthe remaining (if any) at fre\u00adquency fb. Emin(y)= va(y)2 xa + vb(y)2 xb + vc(y)2 xc + vd(y)2 xd+ xava(y)2 \n+ hhh tinvariant ij=0 i 2 2 2 y E = V V V (x1i + x2i) i x1i + j x2j = i max((Noverlap - Ncache - tinvariantxa \ny )vb(y)2 , 0) 5 x 10 2.55 2.5 0.35 2.45 Energy Saving 0.3 0.25 0.2 0.15 0.1 Energy 2.4 2.35 2.3 1.1 \n2.25 1.2 1.3 1.4 1.5 1.6 1.7 y x 105 Figure 8: Discrete case: energy consumption versus the execu\u00adtion \ntime of Ncache, i.e. y. 0.5 0.4 0.05 0 15000 2 10000 1.5 1 x 105 Ncache (103 cycles) 5000 0.5 tinvariant \n(ms) Figure 10: Discrete Voltage Levels: Energy savings for dif\u00adferent Ncache and tinvariant relative \nto best single-frequency setting that meets the deadline. (7 discrete voltage lev\u00ad els, Noverlap =1.3 \n\u00d7 107cycles, Ndependent =7 \u00d7 107cycles, tdeadline =3.5 \u00d7 105 \u00b5s). Energy Saving 0.3 0.2 0.35 0.1 0.3 \n0 Energy Saving 0.25 0.2 500 1000 180016001400 1500 1200 1000800600 400 N (103 cycles) 200 overlap N \n(103 cycles) dependent Figure 9: Discrete Case: Energy savings with respect to differ\u00adent Noverlap and \nNdependent relative to best single-frequency setting that meets the deadline. (7 voltage levels, Ncache \n= 2 \u00d7 105cycles, tdeadline = 5200\u00b5s, tinvariant = 1000\u00b5s). fa(y)fb(y) Ncache Emin(y)= [( - y)vb(y)2+ \nfb(y) - fa(y) fa(y) (1 + tinvariant )(y - Ncache )va(y)2]+ yfb(y) fc(y)fd(y) Ndependent [( - (tdeadline \n- tinvariant - y))vd(y)2 fd(y)-fc(y) fc(y) Ndependent+y +(tdeadline - tinvariant - y - )vc(y)2]+ fd(y) \nmax((Noverlap - Ncache - fa(y)fb(y) tinvariant (y - Ncache ))vb(y)2 , 0) yfb(y)-fa(y) fb(y) fa(y),fb(y),fc(y),fd(y) \nare staircase functions of y. It is hard to determine analytically for what value of y is Emin(y) mini\u00admized. \nHowever, we can do this numerically for a speci.c instance. Figure 8 shows how Emin(y) changes with y \nfor a particular case, which enables us to select the y for which energy is minimized. 3.4.1 Discrete \nVoltage Settings: Summary and Re\u00adsults The main results in this case are that for the compute bound and \nmemory bound with slack cases, we can use the two voltages from the available set that are nearest neighbors \nof the single optimal voltage in the continuous case. For the memory bound case, four voltages are needed, \nand can be determined using the techniques described. We now examine the surfaces for the energy savings \nobtained in terms of the dependent parameters in Figures 11, 9 and 10. The .gures do a good job of conveying \nthe complexity of the energy op\u00adtimization space when discrete voltage settings are involved. Bene\u00ad.ts \nof intra-program DVS peak and drop as one moves into regions that are either poorly-served or well-served \nby a single static fre\u00adquency setting. In fact, one of the main motivations of the MILP\u00adbased DVS formulation \npresented in the next section is that it offers a concrete way of navigating this complex optimization \nspace. 0.15 0.1 0.05 0 1500 1000 250 Ncache 500 150 200 (103 cycles) 100 tdeadline (\u00b5s) Figure 11: Discrete \nCase: Energy savings for different tdeadline and Ncache relative to best single-frequency setting that \nmeets the deadline. This graph is plotted for a case with seven possible discrete voltage levels. (tdeadline \n= 1340\u00b5s, Noverlap =1.3 \u00d7 107cycles, Ndependent =7 \u00d7 107cycles).  When more voltage settings are available, \nthe number of peaks in the graphs increases. When the stepsize between voltage settings is smaller, the \namplitude of each peak becomes smaller as well. This follows fairly intuitively from the fact that .ne-grained \nvoltage set\u00adtings allow one to do fairly well just by setting a single voltage for the whole program \nrun; intra-program readjustments are of lesser value if the initial setting can be done with suf.cient \nprecision. To better understand energy trends in the discrete voltage case, we study here a set of benchmarks \nconsidering situations with 3, 7 or 13 available voltage levels. In all experiments, a =1.5,vt = 0.45V \n, and we considered 5 different deadlines as elaborated on in Section 6. By using cycle-level CPU simulation \nto get program parameters Ncache, Noverlap,Ndependent and tinvariant, we can plug the values into the \nanalytic models generated in this section. The maximum energy savings predicted by the models is illustrated \nin Table 1. Interestingly, energy savings is not monotonic with deadline be\u00adcause we compare not to the \nhighest-frequency operation, but to Benchmark Voltages levels Deadline1 Deadline2 Deadline3 Deadline4 \nDeadline5 adpcm 3 0.62 0.37 0.02 0.15 0.06 7 0.23 0.02 0.05 0.19 0.08 13 0.11 0.03 0.06 0.09 0.09 epic \n3 0.62 0.33 0.04 0.31 0.09 7 0.22 0.23 0.14 0.14 0.12 13 0.10 0.12 0.03 0.04 0.13 gsm 3 0.60 0.37 0.10 \n0.33 0.12 7 0.21 0.02 0.03 0.16 0.15 13 0.10 0.03 0.05 0.06 0.05 mpeg/decode 3 0.66 0.38 0.03 0.26 0.07 \n7 0.26 0.03 0.10 0.10 0.09 13 0.14 0.03 0.12 0.11 0.10 Table 1: Analytical Results of Energy Saving \nRatio for different voltage levels the best single frequency that meets the deadline. Nonetheless, lax \ndeadlines (e.g., Deadline 1) and few voltage levels offer the best scenario for compile-time DVS. Overall, \nthe key message of the analytic model, particularly for the case of discrete voltage settings, is that \nwhile DVS offers signi.cant energy savings in some cases, the optimization space is complex. Achieving \nenergy savings via compile-time, intra-program DVS seems to require a fairly intelli\u00adgent optimization \nprocess. Our MILP-based proposal for managing this optimization is presented in the next section. 4. \nPRACTICAL ENERGY SAVINGS USING MATHEMATICAL OPTIMIZATION Section 3 provides a detailed analysis for the \nmaximum energy savings possible using pro.le-based intra-program DVS. As it uses some simplifying assumptions, \nit leaves open the question as to how much of the predicted savings can actually be extracted in practice. \nIn this and the following section, we answer this question using a practical implementation of a mathematical \noptimization formulation of the problem. 4.1 Overview Here we assume that instructions or system calls \nare available to allow software to invoke changes in clock frequency and sup\u00adply voltage. For example, \nin the Intel XScale processor, the clock con.guration is speci.ed by writing to a particular register \n[14]. Throughout the paper we refer to these invocations generically as mode-set instructions , although \ntheir implementations may range from single instructions to privileged system calls. For this study we \nuse a Mixed-Integer Linear Programming (MILP) based tech\u00adnique to determine optimal placements of the \nmode-set instructions in the code such that total program energy is minimized, subject to meeting a constraint, \nor deadline, regarding the program run-time. Overall, the goal is to operate different parts of the program \nat the lowest possible frequency that will allow the program to meet its deadline with the least power \nconsumption. This MILP formulation extends the one presented by Saputra et al. [25] by including the \nenergy cost of a mode switch, consid\u00adering .ner grain control over code regions controlled by a single \nsetting, and considering multiple input data categories to drive the optimization. Since executing a \nmode-set instruction has both time and energy cost, we wish to place them at execution points that will \nallow the bene.t of invoking them (improvements in energy or in ability to meet the deadline) to outweigh \nthe time/energy cost of invoking them. Thus, some knowledge is needed of the execution time and frequencies \nfor different parts of the program. As shown in Fig\u00adure 12, an initial approach might involve considering \nthe beginning of each basic block as a potential point for inserting a mode-set instruction. Some blocks, \nhowever, such as blocks 2 or 5 in the di\u00adagram, may bene.t from different mode settings depending on \nthe path by which the program arrives at them. For example, if block 5 is entered through block 4, and \nthis .ow is along the critical path of the program, then it may be desirable to run this at a different \n1  mode setting than if it is entered through block 3, in which case it is not on the critical path. \nFor reasons like this, our optimization is actually based on pro\u00adgram edges rather than basic blocks. \nEdge-based analysis is more general than block-based analysis; it allows us to incorporate con\u00adtext regarding \nwhich block preceded the one we are about to enter. Figure 13 gives the general .ow of our technique. \nThe MILP formulation, brie.y described in the next section, presumes that we have pro.led the program \nand have a set of transition counts that correspond to how often we execute a basic block by entering \nit through a speci.c edge and leaving it through a speci.c edge. This is referred to as the local path \nthrough a basic block. We also pro.le to determine the execution time and energy of each basic block. \nSection 4.2 discusses our methodology further, and Section 4.3 discusses how this methodology can be \ngeneralized to allow for pro.ling multiple input sets or categories of input types. We assume, as is \ncommon in current processors, that there are a .nite number of discrete voltage/frequency settings at \nwhich the chip can operate. (This improves upon some prior work that relied upon a continuous tradeoff \nfunction for voltage/frequency levels [19]; such continuous (V,f) scaling is less commercially-feasible.) \nFigure 13 also shows a step where the possible set of mode instructions is passed through a .ltering \nset, where some of them are restricted to be dependent on other instructions based on the program .ow. \nThis independent set of mode instructions is used to formulate the MILP program which will determine \nthe value for each mode instruction. Subsequent sections discuss the criteria used in restriction as \nwell as its implementation. 4.2 The MILP Formulation We start by accounting for the transition energy \nand time costs. Let SE (vi,vj) be the energy transition cost in switching from volt\u00adage vi to vj and \nST (vi,vj ) be the execution time switching cost Program Dependence constraints DVS ed program from \nvi to vj . SE =(1-u)*c *|vi 2 -vj 2|2*c ST = |vi -vj |IMAX Equations for SE, ST have been taken from \n[4], and are considered to be an accurate modeling of these transition costs. The variable c is the voltage \nregulator capacitance and u is the energy-ef.ciency of the voltage regulator. IMAX is the maximum allowed \ncurrent. Let there be N possible modes that can be set by the mode\u00adset instruction. For an edge (i, j)in \nthe control .ow graph there are N binary-valued (0/1) mode variables kijm,m =1, 2, ...N. kijm =1if and \nonly if the mode-set instruction along edge (i, j) sets the mode to m as a result of the DVS scheduling, \nand is 0oth\u00aderwise. Since each edge can be set to at most one mode, we have the following constraint \namong the mode variables for a given edge .N (i, j): m=1 kijm =1 With this, the optimization problem \nto be solved is to minimize: RRN RRR -. -. kijmGij Ejm + Dhij SE (khi,kij ) i=1 j=1 m=1 h=1 i=1 j=1 subject \nto the following constraint: RR N i=1 j=1 m=1 RR h=1 i=1 kijmGij Tjm+ R -. -. Dhij ST (khi,kij )=deadline \nj=1 In the relationships above, R is the number of regions, i.e., nodes such as basic blocks in a control-.ow \ngraph. N is the number of mode settings, kijm is the mode variable for mode m on edge (i, j) -. and kij \nis the set of mode variables (N in all) for edge (i, j). Ejm is the energy consumption for a single invocation \nof region j under mode m. Gij is the number of times region j is entered through edge (i, j) and Dhij \nis the number of times region i is entered through edge (h, i)and exited through edge (i, j). Tjm is \nthe ex\u00adecution time for a single invocation of region j under mode m. These last four values are all \nconstants determined by pro.ling. If we let Vm be the supply voltage of mode m, then SE is the -. -. \ntransition energy cost for one mode transition, such that SE(khi,kij )= .N .N c *(1-u)|khimV 2 -m. m \nkijmV 2 |Likewise, ST , m=1 m=1 the transition time cost for one mode transition, is represented as: \n-. -. 2*c .N .N ST (khi,kij )= |khimVm -kijmVm|. m=1 m=1 IMAX The introduction of the mode variables \ninstead of the voltage variables linearizes the energy and execution time costs Ei and Ti for region \ni. While SE and ST are still non-linear due to the absolute value term, there is no quadratic dependence \non the vari\u00adables; the Vm term in SE is now a constant. The absolute value dependence can be linearized \nusing a straightforward technique. To remove the absolute value, |x|, we introduce a new variable y to \nreplace |x|and add the following additional constraints: -y = x =y. Applying this technique to SE and \nST , the formulation is completely linearized as follows. Minimize Gij kijmEjm +Dhij ehij CE ijm hij \nsubject to the constraints: Gij kijmTjm +Dhij thij CT =deadline ijm hij kijm =1 m .22 -ehij =(khimVm \n-kijmVm)=ehij m -thij =(khimVm -kijmVm)=thij m The absolute value operations in the switching time and \nenergy relationships have been removed; the new variables ehij and thij are part of constraints introduced \nfor their removal, and CE =c * (1-u), CT = 2*c are constants related to switching energy IMAX and time \nin the linearized form. Note that while each edge has a mode set instruction, if at run time the mode \nvalue for an edge is the same as the previous one, no transition cost is incurred. This is due to the \nnature of the transition cost functions SE and ST , which, as expected, have non-zero value only if the \ntwo modes are distinct. Thus, a mode set instruction in the backward edge of a heavily executed loop \nwill be silent for all but possibly the .rst iteration. A post-pass optimization within a compiler can \neasily hoist some such instructions out of the loop. As mentioned in Section 4.1, the run time for the \nMILP solver can be signi.cantly reduced by a careful restriction of the solution space. The mode instruction \non some edge (i, j)can be forced to have the same value as the mode instruction on some other edge -. \n-. (u, v), so that kij =kuv. This reduces the number of independent variables for the MILP solver, and \nconsequently its runtime. While this restriction can potentially result in some loss of optimality in \nthe objective function, the deadline constraints are still met. The practical issues in deciding which \nedges to select for this restriction are discussed in the experimental section. 4.3 Handling Multiple \nData Sets The formulation described thus far optimizes based on a single pro.le run from a single input \ndata set. Here we extend the method\u00adology to cover multiple categories of inputs. While different data \ninputs typically cause some variation in both execution time and energy, one can often sort types of \ninputs into particular categories. For example, with mpeg, it is common to consider categories of inputs \nbased on their motion and complexity. The MILP-based scheduling algorithm can be adapted to handle multiple \ncategories of inputs. For each category of inputs, a typi\u00adcal input data set is chosen. The goal is to \nminimize the weighted average of energy consumption of different input data sets while making sure that \nthe execution time using different typical input data sets meets a common or individual deadlines. The \nformulation is remodeled as working to minimize: pg(kijmGijg Ejmg +Dhijg ehij CE) g ijm hij subject to \nthe following constraints: .gkijmGijg Tjmg + i jm Dhijg thij CT = deadline hij kijm =1 m .22 -ehij = \n(khimV - kijmV )= ehij mm m -thij = (khimVm - kijmVm)= thij m In these relations, pg is the possibility \nof input category g as input. Ejmg is the energy consumption of region j in mode m for input data in \ncategory g and likewise Tjmg is the execution time of region j in mode m for input data in category g. \nGijg is the number of times region j is entered through edge (i, j)for input data in category g and the \npath counter Dhijg refers to the number of times region i is entered through edge (h, i)and exited through \nedge (i, j)for input data in category g. The other terms are the same as before. These modi.cations retain \nthe linearity of the objective func\u00adtion and constraints. The objective function now minimizes the weighted \naverage energy over the different categories, and the dead\u00adline constraints ensure that this is done \nwhile obeying the deadline over all categories. If applicable, this formulation also allows for having \na separate deadline for different categories if needed. The following section describes our actual MILP-based \nimplementation in further detail before we present our energy results. 5. DVS IMPLEMENTATION USING PROFILE-DRIVEN \nMILP As shown in Figure 13, our optimal frequency setting algorithm works by pro.ling execution, .ltering \ndown to the most important frequency-setting opportunities, and then sending the results to an MILP solver. \nThis section describes this .ow in greater detail, with the following subsections discussing the pro.ler, \n.lter, and solver steps respectively.  5.1 Simulation-based Program Pro.ling As already described, \nour MILP approach requires pro.ling data on the per-block execution time, per-block execution energy, \nand local path (the entry and exit for a basic block) frequencies through the program being optimized. \nWhile the local path frequencies need only be gathered once, the per-block execution times and en\u00adergies \nmust be gathered once per possible mode setting. This is because the overlap between CPU and memory instructions \nwill mean that the execution time is not a simple linear scaling by the clock frequency. (That is, we \nassume that memory is asynchronous relative to the CPU and that its absolute response time is unaffected \nby changes in the local CPU clock.) To gather the pro.le data for the experiments shown here, we use \nsimulation. We note however, that other means of pro.ling would also work well. One could for example, \nuse hardware performance counters to pro.le both performance and energy data for real, not simulated, \napplication runs [16]. The data shown here have been gathered using the Wattch power/\u00adperformance simulator \n[3], which is based on SimpleScalar [5]. Our simulations are run to completion for the provided inputs, \nso we get a full view of program execution. (Sampling methods might be accurate enough to give good pro.les \nwhile reducing pro.le time.) For both our time/energy pro.les and for our experimen\u00adtal results in subsequent \nsections, we used the simulation con.gu\u00adration listed in Table 2. We assume that the CPU has three scaling \nlevels for (V,f). They are a frequency of 200MHz paired with a sup\u00adply voltage of 0.7V, 600MHz at 1.3V, \nand a maximum performance setting of 800MHz at 1.65V. This is similar to some of the voltage\u00adfrequency \npairings available in Intel s XScale processors [6]. Parameter Value RUU size 64 instructions LSQ size \n32 instructions Fetch Queue size 8 instructions Fetch width 4 instructions/cycle Decode width 4 instructions/cycle \nIssue width 4 instructions/cycle Commit width 4 instructions/cycle Functional Units 4 Integer ALUs 1 \ninteger multiply/divide 1 FP add, 1 FP multiply 1 FP divide/sqrt Branch Predictor Combined, bimodal 2K \ntable 2-level 1K table, 8bit history 1K chooser BTB 512-entry, 4 way L1 data-cache 64K, 4-way(LRU) 32B \nblocks, 1 cycle latency L1 instruction-cache same as L1 data-cache L2 Uni.ed, 521K, 4-way(LRU) 32B blocks, \n16-cycle latency TLBs 32-entry, 4096-byte page Table 2: Con.guration parameters for CPU simulation. \n5.2 Filtering Edges to Reduce MILP Solution Time While our MILP approach generally works in practice \nfor even large programs, its runtime can be reduced by .ltering the edges that are considered as candidates \nfor mode-set instructions. As dis\u00adcussed in Section 4.2, the frequencies in certain regions may be linked \nto (i.e., the same as) the frequencies in other regions. This reduces the number of independent variables \nfor the ILP solver. A simple and intuitive rule for doing this is as follows. Our goal is to identify \nedges (i, j)such that the total power con\u00adsumption of block j when entered from (i, j)is relatively negli\u00adgible. \nIn this case, not much is lost by giving up the .exibility of independently setting the mode instruction \nalong (i, j). If this edge is selected, then its mode value can be made to be the same as that for edge \n(k, i)which has the largest count (obtained during pro\u00ad.ling) for all incoming edges to block i. The \nmotivation for this is that it will result in edge (i, j)not changing its mode whenever block i is entered \nfrom edge (k, i). The selection rule is as follows. We .lter out all edges whose total destination energy \nis in the tail of the energy distribution that cumulatively comprises less than 2% of the total energy \n(for an arbitrarily selected mode). Filtered edges are still considered as far as timing constraints \nare concerned, so all deadlines are met. Filtering only affects the energy achieved.  5.3 Mathematical \nProgramming: Details Once pro.les have been collected and .ltering strategies have been applied, the \ntransition counts and the program graph structure are used to construct the equations that express DVS \nconstraints. We use AMPL [8] to express the mathematical constraints and to enable pruning and optimizations \nbefore feeding the MILP problem into the CPLEX solver [13]. As shown in Figure 14, our edge .ltering \nmethod greatly prunes the search space for the MILP solver, and brings optimization times down from hours \nto seconds. (We gather these data for six of the MediaBench applications [17], with a transition time \nof 12 \u00b5s, and transition energy of 1.2\u00b5J.) Table 3 shows that for the benchmarks considered the minimum \nenergy determined by the solver remain essentially unchanged from the case when the full set of edges \nis considered. As discussed in Section 4.2, the deadlines will still be met exactly, even with the .ltering \nin place.  Figure 14: Speedup in MILP solution time when edge .ltering Figure 15: Impact of transition \ncost. Energy is normalized to is applied. minimum energy without transition. benchmark All:Energy Subset:Energy \nmpeg 122392.8 \u00b5J 122392.8 \u00b5J gsm 72287.6 \u00b5J 72287.6 \u00b5J mpg123 37291.4 \u00b5J 37291.4 \u00b5J adpcm 10194.3 \u00b5J \n10195.4 \u00b5J epic 33021.9 \u00b5J 33021.9 \u00b5J ghostscript 357.3\u00b5J 357.3\u00b5J Table 3: Energy consumption when the \nMILP solver is run on Exec_time1 Exec_time2 Exec_time3 All at 800Mhz All at 600Mhz All at 200Mhz Figure \n16: Positions of deadlines much lower than those typically found in real processors. A typical capacitance \nc of 10\u00b5f yields 12\u00b5s transition time and 1.2\u00b5J transi\u00ad tion energy cost for a transition from 600MHz/1.3V \nto 200MHz/0.7V. the full set of program edges (left) or the .ltered subset of tran\u00ad sition edges (right). \n6. EXPERIMENTAL RESULTS This 12\u00b5s transition time corresponds well to published data for XScale [14]. \nWe used a wide range of c from 100\u00b5 to 0.01\u00b5fin our experiments. In order to focus on transition cost \nin this experi\u00adment, we hold the deadline constant. In particular, all benchmarks This section provides \nexperimental results showing the improve\u00adments offered by real-world optimal DVS settings chosen by MILP. \n6.1 Benchmarks and Methodology Our method is based on compile-time pro.ling and user-provided (or compiler-constructed) \ntiming deadlines. To evaluate it here, we focus on multimedia applications in which one can make a solid \ncase for the idea that performance should meet a certain threshold, but beyond that threshold, further \nincreases in performance are of lesser value. For example, once you can view a movie or listen to an \naudio stream in real-time, there is lesser value in pushing speed beyond real-time playback; as long \nas a speci.ed speed level has been reached, we argue that energy savings should be paramount. The benchmarks \nwe have chosen are applications from the Me\u00addiabench suite [17] except for mpg123. Unless otherwise speci.ed, \nwe use the inputs provided with the suite, and we run the programs to completion. 6.2 Impact of Transition \nCost Changing a processor s voltage and frequency has a cost both in terms of delay and in terms of energy \nconsumption. Thus, the time or energy required to perform a DVS mode setting instruction can have an \nimportant impact on the DVS settings chosen by the MILP approach, and thus the total execution time and \nenergy. Frequent or heavyweight switches can have signi.cant time/energy cost, and thus the MILP solver \nis less likely to choose DVS settings that re\u00adquire them. The .rst experiment we discuss here shows the \nimpact of tran\u00adsition cost on minimum energy. As given by the equations in Sec\u00adtion 4.2, transition time \nand transition energy are both functions of the power regulator capacitance as well as the values of \nthe two voltages that the change is between. Thus, for a given voltage dif\u00adference, one can explore the \nimpact of different switching costs by varying the power regulator capacitance, c.As c drops, so do both \ntransition costs. In the data shown here, we examine .ve power regulator capaci\u00adtances. They show a range \nof transition costs from much higher to are asked to operate at a deadline that corresponds to point \n5 in Figure 16. This is given, for each benchmark, by the time in the Deadline 5 column of Table 4. This \nrange of deadlines will be discussed shortly in more detail when the examine the impact of different \ndeadlines on energy savings. Results for six Mediabench benchmarks are shown in Figure 15. For each benchmark, \nthe energy is normalized to that program run\u00adning at a .xed 600MHz clock rate. This clock rate is suf.cient \nto meet the deadline, so for very high transition costs (c = 100\u00b5f), there are few or no transitions \nand so the energy is the same as in the base case. At the highest transition cost shown, there are fewer \nthan 10 transitions executed for most of the benchmarks across their whole run. As c decreases, transition \ncosts drop, and so does the minimum energy. This is because when transition cost drops, there are more \nchances to eliminate the slack by having more and more of the program execute at 200MHz. For example, \nin the mpeg bench\u00admark, zero transitions are attempted at the highest transition cost, while at the lowest \none, a run of the benchmark results in a total of over 112,000 mode-setting instructions being executed \n(dynamic). If there were no transition energy costs at all, the maximum en\u00ad ergy saving would be bounded \nby the ratio of the V 2f values, or 0.72/1.32 which equals 0.29. For the smallest possible c values, \none can see that we approach this value, since transition costs are quite small. 6.3 Impact of Deadline \non Program Energy The second experiment shows the impact of deadline choice on minimum energy. Although \nthe absolute values of the deadlines vary for each benchmark, the deadline positions we choose are il\u00adlustrated \nabstractly and generally in Figure 16. For the most aggres\u00adsive deadlines (these smaller times are towards \nthe left hand side) the program must run at the fastest frequency to meet the dead\u00adline. Towards the \nright hand side of the .gure, denoting the very lax deadlines, programs can run almost entirely at the \nlow-energy 200MHz frequency and yet still meet the deadline. Between these two extremes, programs will \nrun at a mix of frequencies, with some Benchmark Exec time at 200 MHz Exec time at 600 MHz Exec time \nat 800 MHz Deadline 5 Deadline 4 Deadline 3 Deadline 2 Deadline 1 adpcm/encode 29.5 9.9 7.4 29.0 20.0 \n10.0 8.1 7.6 mpeg/decode 557.6 187.3 141.0 557.6 300.0 190.0 181.0 151.0 gsm/encode 334.0 111.4 83.6 \n333.0 220.0 120.0 100.0 90.0 epic 152.6 53.6 41.0 150.0 100.0 60.0 50.0 45.0 ghostscript 2.0 0.89 0.74 \n2.0 1.5 1.0 0.81 0.76 mpg123 177.7 59.2 44.4 177.6 100.0 60.0 58.0 45.0 Table 4: Deadline boundaries \nand chosen deadlines for benchmarks (ms) 500 450 1.2 1 400 350 0.8 opt. 300  Normalized Energy Time \nopt. for flwr 250 0.6 0.4 opt. for bbc 200 opt. for average 150 100 50 0 0.2 Figure 17: Impact of deadline \non energy. Energy is normalized Figure 19: Dependence of program runtime on input data used to the energy \nof the best of the three possible single frequency for MILP pro.ling. settings. deadlines, re.ecting \nthe changing complexity of the solution space. 300 Table 5 shows the variations in the dynamic mode \ntransition counts for the benchmarks for different deadlines (for c=10\u00b5f tran\u00ad 250 sition cost). At the \nextremes (Deadlines 1 and 5) there are few choices and thus not too many mode transitions. However, closer \nto the middle, we see signi.cant mode transitions for most bench\u00ad marks as they have all three (V,f) \nchoices to draw from. This MLP Solving Time 200 demonstrates the ability of the formulation to navigate \nthe range of choices, and switching many times to .nd the best (V,f) choice for each part of the program. \n150 100 6.4 Results for Multiple Pro.led Data Inputs 50 The results here demonstrate the resilience of \nenergy choices across different input data sets as well as the result of optimiza\u00ad 0 tion for average \nenergy as formulated previously. We focus here on the mpeg benchmark, and we examine four different data \ninputs. The inputs can be considered to fall into two different categories, based on different encoding \noptions. The .rst category uses no B Figure 18: MILP solution time (in seconds) for different dead\u00ad frames; \nit includes 100b.m2v and bbc.m2v. The second category uses 2 B frames between I and P frames; it includes \n.wr.m2v and cact.m2v. All mpeg .les are Test Bitstreams from [22]. Figure 19 shows program execution \ntimes for different input data and pro.ling runs for the mpeg benchmark. In particular, the x\u00adaxis shows \nfour different input .les for the benchmark. For each benchmark, we show the runtime results from four \ndifferent pro.l\u00ading approaches. The leftmost bar shows the runtime for an mpeg run on that input .le \nwhen the pro.ling run is also on that input .le. The second bar shows the runtime in which the pro.ling \ndata was collected using the .wr input set for all runs. The third bar shows the runtime when the bbc \ninput was used for the pro.ling runs. The rightmost bar shows the runtime when optimization is done for \nthe average of .wr and bbc input sets (with equal weight). The data show that the multi-input case is \noften nearly as good as optimizing based on the identical input. An exception, however, is that optimizing \nbased on the bbc input leads to poor execution time estimation, however. We believe this is because the \nbbc in\u00adput is from the input category with no B frames, so the MILP solver does poorly in estimating \nthe time and energy impact of the code related to their processing. Finally, optimizing for the average \nlines. number of transitions between them. To make this more concrete for the benchmarks we consider, \nTable 4 includes the runtimes of each benchmark when operat\u00ading purely at 800MHz, 600MHz, or 200MHz without \nany transi\u00adtions. To test MILP-based DVS on each benchmark, we choose 5 application-speci.c deadlines \nper benchmark that are intended to exercise different points along the possible range. These chosen deadlines \nare also given in Table 4. The results here are shown for a typical transition cost of c =10\u00b5f. Figure \n17 shows the optimized energies for these experiments. Moving from deadline 1 (stringent) towards deadline \n5 (lax) the program energy is reduced by nearly a factor of 2 or more. Across the range, the MILP solver \nis able to .nd the operating point that offers minimal energy while still meeting the deadline. As shown \nin Figure 18, the chosen deadline can sometimes have an effect on the required solution time. In some \ncases (e.g. gsm/en\u00adcode), the solution time can dramatically change with changing mpeg/decode gsm/encode \nmpg123 epic adpcm/encode ghostscript Deadline 1 5 1 190 4 0 2 Deadline 2 2645 2777 1559 519 0 7 Deadline \n3 5 85 936 552 0 3 Deadline 4 2645 8206 1550 492 0 23 Deadline 5 0 1845 6 4 0 2 Table 5: Dynamic Mode \nTransition Counts Benchmark Ncache (Kcycles) Noverlap (Kcycles) Ndependent (Kcycles) tinvariant (\u00b5s) \nadpcm 732.7 735.6 4302.0 915.9 epic 8835.6 12190.4 9290.1 4955.9 gsm 13979.6 13383.0 29438.3 389.0 mpeg/decode \n42621.1 44068.7 27592.1 2713.4 Table 7: Simulation results of program parameters case makes sure that \nthe deadlines are met for both the cases being considered. Further, Figure 19 also illustrates the representative \nnature of these two input sets. Using the average case (rightmost bar) works as well as using the single \npro.le data set (leftmost bar) across the board -even when the speci.c data sets are not included in \nthe average as with cact and 100b. We have similarly measured the sensitivity of energy results to speci.c \npro.le inputs and have found results as good or better than the runtime results presented here; the sensitivity \nis fairly modest overall. 6.5 A Comparison of Analytical and Pro.le-Driven Results By using cycle-level \nCPU simulation to get the key program pa\u00adrameters as shown in Table 7, we plugged values into the analytic \nmodels generated in Section 3 and discussed the resulting maxi\u00admum energy savings predicted by the models \nin Table 1. Now, Table 6 gives the energy savings results for the same programs when run through the \nMILP-based optimization process. Because the analytical model makes optimistic assumptions about switching \ntime and energy, it is expected to be an optimistic bound, and in\u00addeed, the savings predicted by the \nanalytical model exceed those of MILP-based approaches at all but one point. (For the gsm bench\u00admark \nwith three voltage levels at Deadline 5, the simulation energy savings exceeds that of the analytical \nmodel by 0.01, apparently a rounding issue.) Nonetheless, the general trends in both tables are similar. \nFurther, the comparison shows that the analytical bounds are close enough to be of practical value. Because \nenergy savings is not monotonic with deadline and be\u00adcause the optimization space is relatively complex, \nan MILP-based approach seems to be an important enabling technique for compile\u00adtime, intra-program DVS. \nA second message here is that as we increase the number of available voltage levels, the bene.ts of DVS \nscheduling decrease signi.cantly. In fact it could well be argued that if circuit imple\u00admentations permit \na very large number of DVS settings, it may not be worth resorting to intra-program DVS a single voltage \nselec\u00adtion can come close enough. This is not surprising given the results for our model with continuous \nvoltage scaling, which is the limiting case of increasing the number of discrete levels. We would like \nto highlight this important by-product of our modeling for the case of only inter-program and no intra-program \nDVS, our model can help determine a single optimal voltage based on a few simple pa\u00adrameters. 7. DISCUSSION \nAND FUTURE WORK This paper examines the opportunities and limits of DVS scal\u00ading through detailed modeling \nfor analysis, and exact mathemat\u00adical optimization formulations for compiler optimization. While this \nstudy offers useful insight into, and techniques for compiler\u00adoptimized DVS, there are subtleties and \navenues for future work that we will touch on brie.y here. In the analytical model we ignore delay and \nenergy penalties for DVS. This was required because it was not possible to a priori pre\u00addict how many \ntimes, and between what voltages, the switches will happen. This potentially made the model optimistic \nin terms of achievable energy savings. It remains open to see if we can extend the model to account for \nthese costs. The second optimistic assumption of .ne-grain control on the level of granularity of control \nfor DVS mode setting, while opti\u00admistic, is not particularly so. We can potentially insert mode set\u00adting \ninstructions for every instruction, and that represents reason\u00adably .ne grain control. On the optimization \nside, a key issue in the formulation of the problem concerns which code locations are available for inserting \nmode-set instructions. While our early work focused on methods that considered possible mode-sets at \nthe beginning of each basic block, we feel that edges are more general because MILP solutions may assign \na different frequency to a basic block depending on the entry path into it. On the other hand, this generalization \nwill warrant certain code optimizations when actually implemented in a compiler. First, annotating execution \non an edge would, if im\u00adplemented naively, add an extra branch instruction to each edge since one would \nneed to branch to the mode set instruction and then branch onward to the original branch destination. \nClearly, op\u00adtimizations to hoist or coalesce mode-set instructions to avoid extra branches can potentially \nimprove performance. More generally, we hope to broaden our MILP formulation to target larger code regions \nor paths [2]. Moving from edges to paths would allow us to build more program context into our anal\u00adysis \nof mode-set positioning. Furthermore, it would also allow us to more accurately pro.le the time/energy \ncosts of code regions; by not breaking execution on basic block boundaries, our pro.le would more faithfully \nre.ect execution on deeply-pipelined ma\u00adchines with extensive branch speculation. 8. SUMMARY This paper \nseeks to address the basic questions regarding the opportunities and limits for compile-time mode settings \nfor DVS. When and where (if ever) is this useful? What are the limits to the achievable power savings? \nWe start by providing a detail analytical model that helps de\u00adtermine the achievable power savings in \nterms of simple program parameters, the memory speed, and the number of available voltage levels. This \nmodel helps point to scenarios, in terms of these pa\u00adrameters, for which we can expect to see signi.cant \nenergy savings, and scenarios for which we cannot. One important result of this modeling is that as the \nnumber of available voltage levels increase, the energy savings obtained decrease signi.cantly. If we \nexpect fu\u00adture processors to offer .ne grain DVS settings, then compile-time intra-program DVS settings \nwill not yield signi.cant bene.t and thus will not be worth it. For the scenarios where compile-time \nDVS is likely to yield en\u00adergy savings few voltage settings, lax program deadlines, memory\u00adbound computation; \nselecting the locations and values of mode set\u00adtings is non-obvious. Here we show how an extension of \nthe exist\u00ading MILP formulation for this can handle .ne grain mode-settings, use accurate energy penalties \nfor mode switches and deal with mul\u00adtiple input data categories. Through careful .ltering of independent \nlocations for mode setting instructions, we show how this optimiza\u00adtion can be done with acceptable solution \ntimes. Finally we apply this to show how the available savings can be achieved in practice. Benchmark \nVoltage levels Deadline 1 Deadline 2 Deadline 3 Deadline 4 Deadline 5 adpcm 3 0.49 0.23 0.00 0.03 0.01 \n7 0.16 0.01 0.01 0.04 0.01 13 0.09 0.01 0.02 0.02 0.02 epic 3 0.57 0.30 0.03 0.27 0.05 7 0.18 0.19 0.10 \n0.10 0.07 13 0.10 0.09 0.01 0.01 0.08 gsm 3 0.57 0.37 0.09 0.32 0.13 7 0.18 0.02 0.03 0.16 0.14 13 0.10 \n0.02 0.05 0.06 0.05 mpeg/decode 3 0.60 0.34 0.03 0.24 0.05 7 0.21 0.02 0.09 0.08 0.07 13 0.13 0.02 0.11 \n0.10 0.08 Table 6: Simulation results of energy savings for different numbers of voltage levels. 9. \nREFERENCES [1] Advanced Micro Devices Corporation. AMD-K6 processor mobile tech docs, 2002. http://www.amd.com. \n[2] T. Ball and J. R. Larus. Ef.cient path pro.ling. In International Symposium on Microarchitecture, \npages 46 57, 1996. [3] D. Brooks, V. Tiwari, and M. Martonosi. Wattch: A framework for architectural-level \npower analysis and optimizations. In Proceedings of the 27th International Symposium on Computer Architecture, \nJune 2000. [4] T. Burd and R. Brodersen. Design issues for dynamic voltage scaling. In Proceedings of \nInternational Symposium on Low Power Electronics and Design (ISLPED-00), June 2000. [5] D. Burger, T. \nM. Austin, and S. Bennett. Evaluating future microprocessors: the SimpleScalar tool set. Tech. Report \nTR-1308, Univ. of Wisconsin-Madison Computer Sciences Dept., July 1996. [6] L. T. Clark. Circuit Design \nof XScale (tm) Microprocessors, 2001. In 2001 Symposium on VLSI Circuits, Short Course on Physical Design \nfor Low-Power and High-Performance Microprocessor Circuits. [7] K. Flautner, S. K. Reinhardt, and T. \nN. Mudge. Automatic performance setting for dynamic voltage scaling. In Mobile Computing and Networking, \npages 260 271, 2001. [8] R. Fourer, D. Gay, and B. Kernighan. AMPL: A modeling language for mathematical \nprogramming. Boyd and Fraser Publishing Company, Danvers, Massachusetts, 1993. [9] S. Ghiasi, J. Casmira, \nand D. Grunwald. Using IPC variation in workloads with externally speci.ed rates to reduce power consumption. \nIn Workshop on Complexity-Effective Design, June 2000. [10] C. Hsu and U. Kremer. Single region vs. multiple \nregions: A comparison of different compiler-directed dynamic voltage scheduling approaches. In Proceedings \nof Workshop on Power-Aware Computer Systems (PACS 02), February 2002. [11] C. Hsu and U. Kremer. The \ndesign, implementation, and evaluation of a compiler algorithm for CPU energy reduction. In To appear \nin Proceedings of ACM SIGPLAN Conference on Programming Languages, Design, and Implementation (PLDI 03), \nJune 2003. [12] C. Hughes, J. Srinivasan, and S. Adve. Saving energy with architectural and frequency \nadaptations for multimedia applications. In Proceedings of the 34th Annual International Symposium on \nMicroarchitecture (MICRO-34), 2001. [13] ILOG CPLEX. Web page for ILOG CPLEX mathematical programming \nsoftware, 2002. http://ilog.com/products/cplex/. [14] Intel Corp. Intel XScale (tm) Core Developer s \nManual, 2002. http://developer.intel.com/design/intelxscale/. [15] T. Ishihara and H. Yasuura. Voltage \nscheduling problem for dynamically variable voltage processors. In International Symposium on Low Power \nElectronics and Design (ISLPED-98), pages 197 202, August 1998. [16] R. Joseph and M. Martonosi. Run-time \npower estimation in high-performance microprocessors. In International Symposium on Low Power Electronics \nand Design (ISLPED), 2001. [17] C. Lee, M. Potkonjak, and W. H. Mangione-Smith. MediaBench: A Tool for \nEvaluating and Synthesizing Multimedia and Communication Systems. In Proceedings of the 30th International \nSymp. on Microarchitecture, Dec. 1997. [18] S. Lee and T. Sakurai. Run-time voltage hopping for low-power \nreal-time systems. In Proceedings of the 37th Conference on Design Automation (DAC 00), June 2000. [19] \nJ. Lorch and A. Smith. Improving dynamic voltage algorithms with PACE. In Proceedings of the International \nConference on Measurement and Modeling of Computer Systems (SIGMETRICS 2001), June 2001. [20] J. Luo \nand N. K. Jha. Power-pro.le driven variable voltage scaling for heterogeneous distributed real-time embedded \nsystems. In Int. Conf. VLSI design, Jan. 2003. [21] D. Marculescu. On the use of microarchitecture-driven \ndynamic voltage scaling. In Workshop on Complexity-Effective Design, June 2000. [22] MpegTv. Mpeg video \ntest bitstreams. http://www.mpeg.org/MPEG/video.html, 1998. [23] G. Qu. What is the limit of energy saving \nby dynamic voltage scaling? In Proceedings of the International Conference on Computer Aided Design, \n2001. [24] T. Sakurai and A. Newton. Alpha-power model, and its application to CMOS inverter delay and \nother formulas. IEEE Journal of Solid-State Circuits, 25:584 594, Apr 1990. [25] H. Saputra, M. Kandemir, \nN. Vijaykrishnan, M. Irwin, J. Hu, C.-H. Hsu, and U. Kremer. Energy-conscious compilation based on voltage \nscaling. In Joint Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES 02) and Software \nand Compilers for Embedded Systems (SCOPES 02), June 2002. [26] Semiconductor Industry Association. International \nTechnology Roadmap for Semiconductors, 2001. http://public.itrs.net/Files/2001ITRS/Home.htm. [27] D. \nShin, J. Kim, and S. Lee. Intra-task voltage scheduling for low-energy hard real-time applications. IEEE \nDesign and Test of Computers, 18(2):20 30, March/April 2001. [28] V. Swaminathan and K. Chakrabarty. \nInvestigating the effect of voltage switching on low-energy task scheduling in hard real-time systems. \nIn Asia South Paci.c Design Automation Conference (ASP-DAC 01), January/February 2001.  \n\t\t\t", "proc_id": "781131", "abstract": "With power-related concerns becoming dominant aspects of hardware and software design, significant research effort has been devoted towards system power minimization. Among run-time power-management techniques, dynamic voltage scaling (DVS) has emerged as an important approach, with the ability to provide significant power savings. DVS exploits the ability to control the power consumption by varying a processor's supply voltage (V) and clock frequency (f). DVS controls energy by scheduling different parts of the computation to different (V, f) pairs; the goal is to minimize energy while meeting performance needs. Although processors like the Intel XScale and Transmeta Crusoe allow software DVS control, such control has thus far largely been used at the process/task level under operating system control. This is mainly because the energy and time overhead for switching DVS modes is considered too large and difficult to manage within a single program.In this paper we explore the opportunities and limits of compile-time DVS scheduling. We derive an analytical model for the maximum energy savings that can be obtained using DVS given a few known program and processor parameters. We use this model to determine scenarios where energy consumption benefits from compile-time DVS and those where there is no benefit. The model helps us extrapolate the benefits of compile-time DVS into the future as processor parameters change. We then examine how much of these predicted benefits can actually be achieved through optimal settings of DVS modes. This is done by extending the existing Mixed-integer Linear Program (MILP) formulation for this problem by accurately accounting for DVS energy switching overhead, by providing finer-grained control on settings and by considering multiple data categories in the optimization. Overall, this research provides a comprehensive view of compile-time DVS management, providing both practical techniques for its immediate deployment as well theoretical bounds for use into the future.", "authors": [{"name": "Fen Xie", "author_profile_id": "81100418330", "affiliation": "Princeton University, Princeton, NJ", "person_id": "P517408", "email_address": "", "orcid_id": ""}, {"name": "Margaret Martonosi", "author_profile_id": "81100542224", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP14188253", "email_address": "", "orcid_id": ""}, {"name": "Sharad Malik", "author_profile_id": "81100342626", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP15029667", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/781131.781138", "year": "2003", "article_id": "781138", "conference": "PLDI", "title": "Compile-time dynamic voltage scaling settings: opportunities and limits", "url": "http://dl.acm.org/citation.cfm?id=781138"}