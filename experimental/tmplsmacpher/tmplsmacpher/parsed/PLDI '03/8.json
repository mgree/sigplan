{"article_publication_date": "05-09-2003", "fulltext": "\n Points-to Analysis using BDDs. Marc Berndl, Ond.rej Lhot\u00b4ak, Feng Qian, Laurie Hendren and Navindra \nUmanee Sable Research Group, School of Computer Science McGill University Montreal, Quebec, CANADA H3A \n2A7 [berndl,olhotak,fqian,hendren,navindra]@sable.mcgill.ca  ABSTRACT This paper reports on a new approach \nto solving a subset-based points-to analysis for Java using Binary Decision Diagrams (BDDs). In the model \nchecking community, BDDs have been shown very ef\u00adfective for representing large sets and solving very \nlarge veri.cation problems. Our work shows that BDDs can also be very effective for developing a points-to \nanalysis that is simple to implement and that scales well, in both space and time, to large programs. \nThe paper .rst introduces BDDs and operations on BDDs using some simple points-to examples. Then, a complete \nsubset-based points-to algorithm is presented, expressed completely using BDDs and BDD operations. This \nalgorithm is then re.ned by .nding ap\u00adpropriate variable orderings and by making the algorithm propagate \nsets incrementally, in order to arrive at a very ef.cient algorithm. Experimental results are given to \njustify the choice of variable or\u00addering, to demonstrate the improvement due to incrementalization, and \nto compare the performance of the BDD-based solver to an ef.cient hand-coded graph-based solver. Finally, \nbased on the re\u00adsults of the BDD-based solver, a variety of BDD-based queries are presented, including \nthe points-to query. Categories and Subject Descriptors D.3 [Software]: Programming Languages; D.3.4 \n[Programming Languages]: Processors compilers, optimization General Terms Languages, Experimentation \n Keywords Points-to analysis, binary decision diagrams 1. INTRODUCTION In this paper, we take a well-known \nproblem from the compiler optimization community, points-to analysis, and we show how to .This work was \nsupported, in part, by NSERC and a Tomlinson Graduate Fellowship. Special thanks to J\u00f8rn Lind-Nielsen \nfor his publicly-available BuDDy package. We would also like to thank the PLDI reviewers who provided \nseveral insightful comments. Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to solve this problem ef.ciently using reduced ordered binary deci\u00adsion diagrams (ROBDDs)1 \nwhich have been shown to be very ef\u00adfective in the model checking community. Whole program analyses, \nsuch as points-to analysis, require ap\u00adproaches that can scale well to large programs. Two popular ap\u00adproaches \nto .ow-insensitive points-to analysis have been pursued in the past, equality-based approaches like those \npioneered by Steens\u00adgaard [32], and subset-based approaches like the analysis .rst sug\u00adgested by Andersen \n[1]. The subset-based approaches give more accurate results, but they also lead to greater challenges \nfor ef.\u00adcient implementations [6, 10, 12, 19, 25, 28, 34].2 For this paper, we have chosen to implement \na subset-based points\u00adto analysis for Java. At a very high level, one can see this problem as .nding \nthe allocation sites that reach a variable in the program. Consider an allocation statement S : a = new \nA();. If a variable x is used in some other part of the program, then one would like to know whether \nx can refer to (point-to) an object allocated at S. A key problem in developing ef.cient solvers for \nthe subset-based points-to analysis is that for large programs there are many points\u00adto sets, and each \npoints-to set can become very large. Often, many of these points-to sets are equal or almost equal. Several \nmethods of representing them compactly have been studied in the past, in\u00adcluding collapsing equivalent \nvariables [10, 24] and designing new representations for sets [11, 17, 18]; the BDD-based approach that \nwe introduce in this paper is another example of such a compact representation. Since BDDs have been \nshown to be effective for compactly rep\u00adresenting large sets and for solving large state space problems \nlike those generated in model checking, it seemed like an interesting question to see if BDDs could also \nbe used to ef.ciently solve the points-to problem for Java. In particular, we wanted to examine three \naspects of the BDD solution: (a) execution time for the solver, (b) memory usage, and (c) ease of specifying \nthe points-to algo\u00adrithm using a standard BDD package. In summary, our experience was that BDDs were \nvery effective in all three aspects. The contributions of this paper include: We propose and develop \nan ef.cient BDD-based algorithm for subset-based points-to analysis for Java. To our knowl\u00adedge, we are \nthe .rst group to successfully use BDDs to solve such an analysis ef.ciently.  We provide new insights \ninto how to make the BDD-based implementation ef.cient in terms of space and time. First, we used a systematic \napproach to .nd a good variable or\u00addering for the points-to set. Second, we noted that the al\u00ad  republish, \nto post on servers or to redistribute to lists, requires prior speci.c 1In the remainder of this paper \nwe simply refer to BDDs, meaning permission and/or a fee. ROBDDs. PLDI 03, June 9 11, 2003, San Diego, \nCalifornia, USA. Copyright 2003 ACM 1-58113-662-5/03/0006 ...$5.00. 2A more detailed description of related \nwork is found in Section 7. gorithm should propagate the sets incrementally, and pre\u00adsented an incremental \nversion. This general idea of incre\u00admentalizing the algorithm may be useful in solving other program \nanalysis problems using BDDs. Third, we found that specifying an analysis using high-level BDD opera\u00adtions \nallowed us to specify our analysis very compactly and it was very simple to experiment with a wide va\u00adriety \nof algorithms. Our source code (available on our web page: http://www.sable.mcgill.ca/bdd/) contains \nmany different variations that can be enabled by switches. We experimentally validated the BDD-based \napproach by comparing its performance to a previously existing ef.cient solver. For small problem sizes, \nwe found that the time and space requirements are similar, but for larger problems, the BDD-based approach \nrequires less memory, and scales bet\u00adter.  Although we initially intended to compute only points-to \nsets, we found that the BDD approach leads to a solution that can be used to answer a variety of queries, \nof which the points-to query is only one. We suggest several possible other queries. In future work we \nplan to develop this aspect of our work further.  The rest of this paper is organized as follows. In \nSection 2 we provide an introduction to BDDs and operations on BDDs using small examples based on the \npoints-to problem. Given this intro\u00adductory material, we then introduce our points-to algorithm and its \nimplementation using BDDs in Section 3. Then, in Section 4, we show how to improve the performance of \nthe algorithm by choosing the correct variable ordering and making the algorithm incremental. In Section \n5 we give experimental results for our best BDD algo\u00adrithm and compare its performance to a hand-coded \nand optimized solver based on SPARK. In Section 6 we discuss possible appli\u00adcations for the results of \nour algorithm, which includes answering points-to queries. Finally, Section 7 gives a discussion of related \nwork and Section 8 gives conclusions and future work. 2. BDD BACKGROUND A Binary Decision Diagram (BDD) \nis a representation of a set of binary strings of length n that is often, equivalently, thought of as \na binary-valued function that maps binary strings of length n to 1 if they are in the set or to 0 if \nthey are not. Structurally, a BDD is a rooted directed acyclic graph, with ter\u00adminal nodes 0 and 1 , \nand where every non-leaf node has two successors: a 0-successor and a 1-successor. As in a binary trie, \nto determine whether a string is in the set represented by a BDD, one starts at the root node, and proceeds \ndown the BDD by fol\u00adlowing either the 0-or 1-successor of the current node depending on the value of \nthe bit of the string being tested. Eventually, one ends up either at 1 , indicating that the string \nis in the set, or at 0 indicating that it is not. To use a concrete example, consider the program fragment \nin Figure 1. The points-to relation we would compute for this code is {(a, A), (a, B), (b, A), (b, B), \n(c, A), (c, B), (c, C)}, where (a, A) indi\u00adcates that variable a may point to objects allocated at allocation \nsite A. Using 00 to represent a and A, 01 to represent b and B, and 10 to represent c and C, we can encode \nthis points-to relation using the set {0000, 0001, 0100, 0101, 1000, 1001, 1010}. Figure 2(a) shows an \nunreduced BDD representing this set where the variables a, b and c are encoded at BDD node levels V0 \nand V1 A: a =new O(); B: b =new O(); C: c =new O(); a =b; b =a; c =b; Figure 1: Example code fragment. \nand the heap objects A, B and C are encoded at the H0 and H1 levels. As a convention, 0-successors are \nindicated by dotted edges and 1-successors are indicated by solid edges. Notice that nodes marked x, \ny, and z in Figure 2(a) are at the same level and have the same 0-and 1-successors. This is because they \nrepresent the subset {A, B}, which is shared by all three pro\u00adgram variables. Because they are at the \nsame level and share the same successors, they could be merged into a single node, reduc\u00ading the size \nof the BDD. Furthermore, since their two successors are the same (the 1 node), their successor does not \ndepend on the bit being tested, so the nodes could be removed entirely. Simplify\u00ading other nodes in this \nmanner, we get the BDD in Figure 2(b). The BDD with the fewest nodes is unique if we maintain a consistent \nordering of the nodes; it is called a reduced BDD. When BDDs are used for computation, they are always \nkept in a reduced form. In the examples so far, the bits of strings were tested in the order in which \nthey were written. However, any ordering can be used, as long as it is consistent over all strings represented \nby the BDD. For example, Figure 2(c) shows the BDD that represents the same relation, but tests the bits \nin a different order. This BDD requires 8 nodes, rather than 5 nodes as in Figure 2(b). In general, choosing \na bit ordering which keeps the BDDs small is very important for ef\u00ad.cient computation; however, determining \nthe optimal ordering is NP-hard [23]. BDDs support the usual set operations (union, inter\u00adsection, complement, \ndifference) and can be maintained in reduced form during each operation. A binary operation on BDDs A \nand B, such as A . B, takes time proportional to the number of nodes in the BDDs representing the operands \nand result. In the worst case, the number of nodes in the BDD representing the result can be the product \nof the number of nodes in the two operands, but in most cases, the reduced BDD is much smaller [23]. \nBuDDy[20] is one of several publicly-available BDD packages. Instead of requiring the programmer to manipulate \nindividual bit positions in BDDs, BuDDy provides an interface for grouping bit positions together. The \nterm domain is used to refer to such a group. In the example in Figure 2, we used the domain V to represent \nvariables, and H to represent pointed-to heap locations. Another BDD operation is existential quanti.cation. \nFor exam\u00adple, given a points-to relation P C V \u00d7H, we can existentially quan\u00adtify over H to .nd the set \nS of variables with non-empty points-to sets: S = {v |.h.(v, h) E P}. The relational product operation \nimplemented in BuDDy com\u00adposes set intersection with existential quanti.cation, but is imple\u00admented more \nef.ciently than these two operations composed. Specif\u00adically, rel prod(X, Y, V 1)= {(v2, h) |.v1.((v1, \nv2) E X . (v1, h) E Y )}. To illustrate this with an example, for the code fragment in Figure 1, consider \nthe initial points-to set {(a, A), (b, B), (c, C)} (corresponding to the .rst three lines of code) and \nthe assignment edge set {(b, a), (a, b), (b, c)} (corresponding to the last three lines of code). The \npair (a, b) corresponds to the statement b := a; that is, we write the variables in reverse order, indicating \nthat all allo\u00adcation sites reaching a also reach b. The initial points-to set is rep\u00adresented in the \nBDD in Figure 3(a) using the domains V 1 and H. bit 3 (V1) bit 2 (V0) bit 1 (H1) bit 0 (H0) (b) Figure \n2: BDDs for points-to relation {(a, A), (a, B), (b, A), (b, B), (c, A), (c, B), (c, C)} (a) unreduced \nusing ordering V1V0H1H0, (b) reduced using ordering V1V0H1H0, (c) reduced using alternative ordering \nH0V0H1V1   Figure 3: (a) BDD for initial points-to set {(a, A), (b, B), (c, C)} (b) BDD for edge set \n{(a n b), (b n a), (b n c)} (c) result of rel\u00adprod((a),(b),V1) (the points-to set {(a, B), (b, A), (c, \nB)}) (d) result of replace((c),V2ToV1) (e) result of (a).(d) (the points-to set {(a, A), (a, B), (b, \nA), (b, B), (c, B), (c, C)} The edge set contains pairs of variables, so two variable domains (V 1 and \nV 2) are required to represent it; its representation is shown in Figure 3(b). Given these two BDDs, \nwe can apply the relational product with respect to V 1 to obtain the BDD of the points-to sets after \npropagation along the edges (Figure 3(c)), using the domains V 2 and H. The replace operation creates \na BDD in which information that was stored in one domain is moved into a different domain. For example, \nwe would like to .nd the union of the points-to relations in parts (a) and (c) of Figure 3, but the former \nuses the domains V 1 and H, while the latter uses V 2 and H. Before .nding the union, we applying the \nreplace operation to (c) to obtain (d), which, like (a), uses domains V 1 and H. We can now .nd (e)=(a).(d), \nthe points-to set after one step of propagation. If we repeated these steps a second time, we would obtain \nthe .nal points-to set BDD from Figure 2(b). Note that it is possible for a BDD for a large set to have \nfewer nodes than the BDD for a smaller set. In this case, although the points-to set grows from three, \nto six, to seven pairs, the BDD rep\u00adresenting it goes from eight to six to .ve nodes (see Figures 3(a), \n3(e), and 2(b), respectively).  3. POINTS-TO ALGORITHM WITH BDDS A points-to analysis computes a points-to \nrelation between vari\u00adables of pointer type and allocation sites. Our analysis is a Java extension of \nthe analysis suggested for C by Andersen [1]. As such, it is both .ow-and context-insensitive. The analysis \ntakes as input constraints modelling four types of statements: allocation, simple assignment, .eld store, \nand .eld load (Figure 4). pt(l) in\u00addicates the points-to set of variable l. l1 n l2 indicates that l2 \nmay point to anything that l1 may point to. Based on a call graph built using class hierarchy analysis \n[7], we add appropriate assignment edges to model inter-procedural pointer .ow through method pa\u00adrameters \nand return values. We took this approach of generating all the constraints ahead of time because in this \n.rst study, we wanted to clearly separate the constraint generator from the solver. In fu\u00adture work, \nwe plan to integrate them more closely, making it pos\u00adsible to experiment with building the call graph \non-the-.y as the points-to analysis proceeds. The inference rules shown in Figure 5 are used to compute \npoints\u00adto sets. The basic idea is to apply these rules until a .xed point is reached. The .rst rule models \nsimple assignments: if l1 points to o, and is assigned to l2, then l2 also points to o. The second rule \na : l := newC oa E pt(l) l2:= l1 l1 n l2 q. f := ll n q. f l := p. fp. f n l Figure 4: The four types \nof pointer statements (constraints). models .eld stores: if l points to o2, and is stored into q. f \n, then o1. f also points to o2 for each o1 pointed to by q. Similarly, the third rule models .eld loads: \nif l is loaded from p. f , and p points to o1, then l points to any o2 that o1. f points to. l1 n l2 \no E pt(l1) (1) o E pt(l2) o2 E pt(l) l n q. fo1 E pt(q) (2) o2 E pt(o1. f ) p. f n lo1 E pt( p) o2 E \npt(o1. f ) (3) o2 E pt(l) Figure 5: Inference rules 3.1 BDD Implementation The rules presented in Figure \n5 apply to elements of points-to (pt) and assignment-edge (n) relations. In BDDs, we encode them as operations \non entire relations, rather than their individual ele\u00adments. In our algorithm, we map the components \nof relations onto .ve BuDDydomains (groups of bit positions). FD is a domain representing the set of \n.eld signatures.  V 1 and V 2 are domains of variables of pointer type. We need two such domains in \norder to represent the n relation of two variables.  H1 and H2 are domains of allocation sites. Two \nare needed, along with the FD domain, in order to represent the pt re\u00adlation for .elds of objects, which \ncontains elements of the form o2 E pt(o1. f ).  We now describe the most important relations used in \nthe algo\u00adrithm, along with the domains onto which they are mapped. pointsTo C V 1 \u00d7 H1 is the points-to \nrelation for variables, and consists of elements of the form o E pt(l).  f ieldPt C (H1\u00d7FD) \u00d7H2 is the \npoints-to relation for .elds of heap objects, and consists of elements of the form o2 E pt(o1. f ). \n edgeSet C V 1\u00d7V 2 is the relation of simple assignments, and consists of elements of the form l1 n l2. \n stores C V 1 \u00d7 (V 2 \u00d7 FD) is the relation of .eld stores, and consists of elements of the form l1 n \nl2. f .  loads C (V 1 \u00d7 FD) \u00d7 V 2 is the relation of .eld loads, and consists of elements of the form \nl1. f n l2.  typeFilter C V 1\u00d7H1 is a relation which speci.es which ob\u00adjects each variable can point-to, \nbased on its declared type. This is used to restrict the points-to sets for variables to the appropriate \nobjects. The BDD algorithm is given in Figure 6. First, the algorithm loads input constraints and initializes \nthe relations introduced above. The main algorithm consists of an inner loop nested within an outer loop. \nTo make the algorithm easier to understand, we annotated the type of the relations involved in each step \nof computation. Lines 1.1 to 1.2 implement rule (1). In line 1.1, the edgeSet and pointsTo relations \nare combined. This relprod operation computes the rela\u00adtion {(l2, o) |.l1.l1 n l2 . o E pt(l1)}, the \npre-conditions of rule (1). In line 1.2, the relation is converted to use domains V 1 and H1 rather than \nV 2 and H1, and in line 1.4, it is added into the pointsTo relation. Line 1.3 will be explained later. \nLines 2.1 to 2.3 implement rule (2). Line 2.1 computes the intermediate result of the .rst two pre-conditions: \ntmpRel1 = {(o2, q. f ) |.l.o2 E pt(l) . l n q. f }. In line 2.2, tmpRel1 is changed to domains suitable \nfor the next computation. In line 2.3, the resulting relation of all three pre-conditions is computed \nas {(o2, o1. f ) |.q.(o2, q. f ) . o1 E pt(q)}. In a similar way, lines 3.1 to 3.3 implement rule (3). \nAgain, the .rst two pre-conditions are .rst combined to form a temporary relation (line 3.1), then combined \nwith the results from rule (2) (line 3.2). After changing the result to the appropriate domains (line \n3.3), we obtain new points-to pairs to add to the points-to relation. These are merged into the pointsTo \nset in line 4.2. The algorithm in Figure 6 is very close to the real code of our implementation using \nthe BuDDy package. So far, we have not explained the purpose of lines 1.3 and 4.2. An earlier points-to \nstudy [17, 18] showed that static type information is very useful to limit the size of points-to sets \nby including only allocation sites of a subtype of the declared type of the variable. Lines 1.3 and 4.2 \nimplement this by screening all newly-introduced points-to pairs with a typeFilter relation. This relation \nis constructed in line 0.3 from three relations read from the input .le: the subtype relation between \ntypes, the declared type relation between variables and types, and the allocated type relation between \nallocation sites and types.  4. PERFORMANCE TUNING As we have seen in section 2, different variable \norderings result in different sizes of the BDD for the same set. By default, BuDDy interleaves the variables \nof all domains; this tends to be a good or\u00addering for transition systems in model checking. For our points-to \nproblem set, however, the default ordering turns out to only work on toy problems, and was very slow \non real benchmarks. This lead us to explore a variety of different variable orderings by rearrang\u00ading \nand interleaving domains. In practice, different orderings yield dramatically different performance. \nThe best ordering we encoun\u00adtered gives impressive results even without further optimizations. When, \nin addition, we applied incrementalization, the performance of the BDD solver became very competitive \ncompared to a care\u00adfully hand-coded solver. Before introducing variable orderings and optimizations, \nwe .rst describe the experimental setup on which our performance pro.ling and tuning were done. 4.1 \nExperimental Setup We selected benchmarks from the SPECjvm98 [31] suite, SPECjbb2000 [30] and three other \nlarge benchmarks: sablecc-j, soot-cand jedit. Table 1 shows the description of each benchmark. Sablecc-j \nis a parser generator written in /* ---initialization ---*/ /* 0.1 */ load constraints from the input \nfile /* 0.2 */ initialize pointsTo, edgeSet, loads, and stores /* 0.3 */ build typeFilter relation repeat \nrepeat  /* ---rule 1 ---*/ /* 1.1 */ newPt1:[V2xH1] = relprod(edgeSet:[V1xV2], pointsTo:[V1xH1], V1); \n/* 1.2 */ newPt2:[V1xH1] = replace(newPt1:[V2ToV1], V2ToV1); /* ---apply type filtering and merge into \npointsTo relation ---*/ /* 1.3 */ newPt3:[V1xH1] = newPt2:[V1xH1] n typeFilter:[V1xH1]; /* 1.4 */ pointsTo:[V1xH1] \n= pointsTo:[V1xH1] . newPt3:[V1xH1]; until pointsTo does not change  /* ---rule 2 ---*/ /* 2.1 */ tmpRel1:[(V2xFD)xH1] \n= relprod(stores:[V1x(V2xFD)], pointsTo:[V1xH1], V1); /* 2.2 */ tmpRel2:[(V1xFD)xH2] = replace(tmpRel1:[(V2xFD)xH1], \nV2ToV1 &#38; H1ToH2); /* 2.3 */ fieldPt:[(H1xFD)xH2] = relprod(tmpRel2:[(V1xFD)xH2], pointsTo:[V1xH1], \nV1); /* ---rule 3 ---*/ /* 3.1 */ tmpRel3:[(H1xFD)xV2] = relprod(loads:[(V1xFD)xV2], pointsTo:[V1xH1], \nV1); /* 3.2 */ newPt4:[V2xH2] = relprod(tmpRel3:[(H1xFD)xV2], fieldPt:[(H1xFD)xH2], H1xFD); /* 3.3 */ \nnewPt5:[V1xH1] = replace(newPt4:[V2xH2], V2ToV1 &#38; H2ToH1]); /* ---apply type filtering and merge \ninto pointsTo relation ---*/ /* 4.1 */ newPt6:[V1xH1] = newPt5:[V1xH1] n typeFilter:[V1xH1]; /* 4.2 */ \npointsTo:[V1xH1] = pointsTo:[V1xH1] . newPt6:[V1xH1]; until pointsTo does not change  Figure 6: The \nbasic BDD algorithm for points-to analysis benchmark description compress Modi.ed Lempel-Ziv method \n(LZW). db Performs multiple database functions on mem\u00adory resident database. raytrace A raytracer that \nworks on a scene depicting a di\u00adnosaur. mpegaudio Decompresses audio .les that conform to the ISO MPEG \nLayer-3 audio speci.cation. jack A Java parser generator that is based on the Pur\u00addue Compiler Construction \nTool Set (PCCTS). jess Java Expert Shell System. sablecc-j An object-oriented parser generator written \nin Java. jbb2000 A Java program emulating a 3-tier system with emphasis on the middle tier. javac The \nJava compiler from the JDK 1.0.2. soot-c A bytecode to bytecode optimization and anno\u00adtation framework. \njedit A full-featured editor written in Java. Table 1: Benchmark description Java, and soot-cis a bytecode \ntransformation framework. Both are non-trivial Java applications, and are publicly-available in the Ashes \n[2] suite. Jedit [15] is a full-featured editor written in Java. We generated the constraints for our \nBDD-based solver using the SPARK points-to analysis framework [17,18]. Constraints were generated for \na .eld-sensitive analysis (using a separate points-to set for each .eld of the objects allocated at each \nallocation site). The call graph used for interprocedural .ow of pointers was con\u00adstructed using class \nhierarchy analysis. Effects of native methods were considered, as supported by SPARK. The raw points-to \nconstraints generated from an input program can either be fed directly to a solver as input, or they \ncan .rst be simpli.ed off-line by substituting a single variable for groups of variables known to have \nthe same points-to set [24]. This results in a smaller set of constraints for an equivalent problem. \nWe used the SPARK framework to generate both unsimpli.ed and simpli.ed versions of the constraints as \ninput to our BDD solver. We denote a simpli.ed set of constraints with the letter s, and an unsimpli.ed \nset of constraints with ns. A points-to analysis solver for a typed language such as Java has two reasonable \noptions for dealing with the declared types of variables: it can solve the points-to constraints .rst, \nand restrict the points-to sets to subtypes of the declared type afterwards [25, 33]; alternatively, \nit can remove objects of incompatible type as the points-to analysis proceeds [17, 18, 34]. Both our \nBDD solver and the SPARK solver support both variations. We denote a solver that respects declared types \nthroughout the analysis with the letter t, and one that ignores them until the end with nt. The two options \nfor simpli.cation and two options for handling of types result in four combinations, all four of which \nhave been used in related work. In this study, we focus on three of them: (s/t), (ns/t), and (ns/nt). \nWe stress that the same sets of constraints were used as input to both our BDD solver and the SPARK solver. \nThe BDD Solver is written in C++ and uses the BuDDy2.1 C++ interface compiled with GCC 2.95.4 at -O3. \nThe BuDDy package has a built-in reference counting mark-and-compact garbage col\u00adlector for recycling \nBDD nodes. Whenever the proportion of free nodes is less than a threshold (20% by default), the kernel \nincreases the node table size. In our experiments for performance measure\u00adment, we used a heap size of \n160M. All our experimental data were collected on a 1.80 GHz Pentium 4 with 1 GB of memory running Linux \n2.4.18.  4.2 Variable Ordering In this section, we describe the path leading us to .nd ef.cient or\u00adderings \nand empirically compare several representative orderings. We consider two factors in choosing a variable \nordering: the ordering of domains and interleaving of the variables of differ\u00adent domains. We use the \nfollowing naming scheme for orderings: when we list several domain names together, their variables are \nin\u00adterleaved; when we list domain names separated by underscores, the variables of one domain all come \nbefore those of the next. For example, if f0, f1,..., fn are the variables of the domain fd and v0, v1,..., \nvn are the variables of the domain v1, the order\u00ading fdv1 corresponds to f0v0 f1v1 ... fnvn, and fd v1 \ncorresponds to f0 f1 ... fnv0v1 ... vn. Within each domain, the variables are ar\u00adranged from the most \nsigni.cant bit to the least signi.cant bit, be\u00adcause the more signi.cant bits may not all be used (always \n0), and placing them closer to the beginning reduces the BDD size. Using the default ordering fdv1v2h1h2, \nour BDD solver cannot solve real benchmarks. We investigated the performance bottleneck and found that \nmost of time was spent on the relprod operation for rule (1) (line 1.1 of Figure 6). This operation propagates \npoints-to sets along assignment edges. Since this operation only involves the edgeSet and pointsTo relations, \nwhich use the domains v1, v2 and h1, only the arrangement of these three domains affects this opera\u00adtion. \nWe experimented with several arrangements and interleavings of these three key domains. The graph in \nFigure 7 shows the effect of two different order\u00adings of the domains h1 and v1 on the execution time \nof the rel\u00adprod operation in line 1.1 (on the javacbenchmark, with off-line simpli.cation and respecting \ndeclared types). The x-axis gives the loop iteration number and the y-axis gives the time spent on each \niteration of the relprod operation in line 1.1. The solid line corre\u00adsponds to the case where h1 comes \nafter v1 whereas the dotted line corresponds to the case where h1 comes before v1. Note that the execution \ntime of relprod changes dramatically: with v1 before h1, each operation takes less than 0.5s, while with \nh1 before v1, each operation takes about 4.2s on average. Our experiments with other orderings con.rm \nthis behavior, and we conclude that arranging v1 before h1 is a good heuristic.  iteration number the \nexecution time of relprod operation Figure 7: Effect of domain arrangement We also measured the size \nof the pointsTo relation for these two orderings expecting the slower ordering to correspond to a larger \nrelation. Surprisingly, we did not .nd this to be the case, both or\u00adderings gave similar sizes. This \nindicates that the relprod operation in BuDDyis sensitive to not only the size of operands but also the \nvariable ordering. In other experiments, we found that arranging v1 before v2 for the edgeSet relation \nyields better performance, but this has a much smaller effect than rearranging v1 and h1. One possible \nexplana\u00adtion is that the edgeSet relation (using the domains v1 and v2) re\u00admains constant during the \ncomputation, while the pointsTo relation (using domains v1 and h1) is repeatedly recomputed; therefore, \nthe order of v1 and h1 affects the computation more. After determining the order in which to arrange \ndomains, we looked at the effect of interleaving them. Again, we only consid\u00adered v1, v2, and h1, since \nthese are the domains involved in the most expensive operation. Figure 8 shows the effect on the BDD \nsize of the pointsTo relation and on the execution time of line 1.1 in each iteration. When v1 and h1 \nare interleaved, the BDD for the initial points-to relation is much smaller than when they are placed \none after the other. However, as the analysis proceeds, the BDD with the interleaved ordering grows to \nabout .ve times the size of the BDD with v1 before h1. This is because the points-to sets be\u00adgin to grow \nas the analysis proceeds, but it appears that the latter BDD is able to exploit their regularity and \nremain small. The size increase in the BDD with the interleaved ordering degrades the per\u00adformance signi.cantly. \nThus, a good heuristic is to place v1 before h1, and not interleave them. Table 2 summarizes the performance \nof the BDD solver with four representative orderings. Column (a) corresponds to the de\u00adfault ordering \nused by BuDDy; this ordering cannot solve real bench\u00admarks in a reasonable time. Column (b) is another \nexample of a bad ordering, with h1 before v1. This ordering already allows the solver to .nish on small \ninputs. The last two columns show the performance when using a good domain arrangement, without in\u00adterleaving \nv1 and h1. The performance improvement is dramatic. The difference between last two columns shows the \neffect of inter\u00adleaving v1 and v2. This effect is much less signi.cant. The BDD for the edgeSet relation \nis smaller when v1 and v2 are interleaved, and we observed fewer garbage collections. The pointsTo relation \nhas the same size with either ordering. On small inputs (s/t), the two orderings yield comparable performance. \nOn large problem sets (ns/nt), interleaving v1 and v2 gives much better performance. (a) -fdv1v2h1h2 \n(b) -h1 v1v2 fd h2 (c) -fd v1v2 h1 h2 (d) -fdv1 v2 h1h2       benchmark (a) (b) (c) (d) compress \n(s/t) compress (ns/t) compress (ns/nt) javac (s/t) javac (ns/t) javac (ns/nt) sablecc-j (s/t) sablecc-j \n(ns/t) sablecc-j (ns/nt) jedit (s/t) jedit (ns/t) jedit (ns/nt) 6420s N/C N/C 9360s N/C N/C 9960s N/C \nN/C N/C N/C N/C 996s 4200s 8280s 1203s 4920s 10140s 1388s 5700s 9480s 2460s N/C N/C 21s 53s 145s 23s \n62s 167s 22s 63s 158s 36s 112s 336s 19s 84s 228s 24s 104s 286s 23s 111s 269s 35s 358s 784s Table 2: \nEffect of variable ordering on performance (N/C means the solver does not complete the run in 4 hours.) \nnumber of nodes 400000 350000 300000 250000 200000 150000 100000 50000 0  iteration number (a) the BDD \nsize of pointsTo relation 0 2 4 6 8 10 12 14 16 18 iteration number (b) the execution time of relprod \noperation Figure 8: Effect of interleaving domains  4.3 Incrementalization So far, we have seen that \nordering has a huge effect on the perfor\u00admance of the basic BDD solver. The empirical study and analysis \nlead us to .nd good orderings that yield reasonable performance in our basic algorithm. However, this \nis not the end of the story. We apply one further optimization on our basic algorithm, which improves \nthe performance to compete with a highly ef.cient, hand\u00adcoded solver. Whenever the pointsTo relation \nchanges, the solver propagates points-to pairs by repeating the relprod operation in line 1.1 until it \nreaches a .xed point. The execution time of the relprod opera\u00adtion is proportional to the sizes of the \nBDDs being combined, in this case pointsTo and edgeSet. In each iteration, we propagate all points-to \nsets along all edges, even though most points-to sets have already been propagated in previous iterations. \nThis leads us to an additional optimization, incrementalization. The idea is to propagate, in each iteration, \nonly the part of each points-to set that has been newly introduced since the last itera\u00adtion (the old \npart has already been propagated). Figure 9 shows the replacement for rule (1) of the algorithm. Notice \nthat the pointsTo operand of relprod in line 1.1 has been replaced with a newPointsTo relation, which \nholds only newly introduced points-to pairs. A new benchmark fdv1v2h1h2 fdv1v2h1h2 non-inc inc non-inc \ninc compress (s/t) 20.63 11.72 19.07 9.80 compress (ns/t) 54.46 26.83 83.63 19.66 compress (ns/nt) 145.33 \n71.55 228.21 58.58 javac (s/t) 22.62 14.83 23.89 10.83 javac (ns/t) 62.35 30.55 103.52 23.14 javac (ns/nt) \n166.66 80.04 285.65 65.46 sablecc-j (s/t) 21.90 14.00 23.10 10.60 sablecc-j (ns/t) 63.43 30.05 110.87 \n22.86 sablecc-j (ns/nt) 158.33 76.53 269.30 63.82 jedit (s/t) 35.92 20.11 35.43 15.60 jedit (ns/t) 112.47 \n47.53 357.97 35.29 jedit (ns/nt) 336.18 150.72 783.92 120.53 Table 3: Analysis time improvement due to \nincrementalization line 1.3 has been added, in which any old points-to pairs that have already been propagated \n(and are therefore present in the pointsTo relation) are removed from the newPointsTo relation. This \nopti\u00admization keeps the newPointsTo relation small (both in terms of set size, and number of BDD nodes), \ngreatly speeding up the relprod operation. In a similar way, we also applied incrementalization to the \nother rules. The details are omitted here; the full incrementalized algo\u00adrithm is given in Appendix A \nand the full source code can be found on our web site http://www.sable.mcgill.ca/bdd/. Table 3 shows \nthe improvements in analysis times due to incre\u00admentalization on the two good variable orderings that \nwe identi\u00ad.ed earlier. For the ordering fd v1v2 h1 h2, incrementalization improves the performance almost \n100% for all input sizes. With the ordering fdv1 v2 h1h2, the improvement is even more dra\u00admatic, and \nbecomes more signi.cant when the problem becomes larger. On jedit (ns/t), incrementalization makes the \nsolver al\u00admost 10 times faster. Combined with incrementalization, the or\u00addering fdv1 v2h1h2 outperforms \nfd v1v2 h1 h2 on all of the benchmarks. By .nding a good variable ordering, and by incrementalizing the \nalgorithm, we have signi.cantly improved its performance, to the point that it competes with hand-coded \npoints-to solvers. In fact, as we show in the next section, for large problems, the BDD algorithm scales \nwell and produces extremely compact encodings of the points-to sets.  5. FULL EXPERIMENTAL RESULTS \nWe introduced our benchmarks and experimental setup in sec\u00adtion 4.1. We also presented the performance \nof the BDD solver on four benchmarks during the tuning process. In this section, we present and discuss \nthe performance of our best variable ordering for BDDs compared to an ef.cient, hand-coded solver, SPARK \n[17, 18], in three aspects: time, memory requirements, and scalability. SPARK includes several different \nsolving algorithms; we used the incremental worklist propagation algorithm, the fastest one. We are interested \nnot only in scalability in terms of the size of the program being analyzed, but also in the dependence \nof the solver on techniques that reduce the size of the problem being solved, such as respecting declared \ntypes and off-line variable substitution. This is because these techniques may not always be applicable. \nFor example, if we were analyzing a program written in C rather than Java, we could not rely on declared \ntypes. Even when analyzing Java, declared types are not always used [25] because they may be     \n   newPointsTo = pointsTo; repeat  /* ---rule 1 ---*/ /* 1.1 */ newPt1:[V2xH1] = relprod(edgeSet:[V1xV2], \nnewPointsTo:[V1xH1], V1); /* 1.2 */ newPt2:[V1xH1] = replace(newPt1:[V2ToV1], V2ToV1); /* ---remove \nold (already propagated) points-to pairs ---*/ /* 1.3 */ newPt3:[V1xH1] = newPt2:[V1xH1] \\ pointsTo:[V1xH1]; \n /* ---apply type filtering and merge into pointsTo relation ---*/ /* 1.4 */ newPointsTo:[V1xH1] = newPt3:[V1xH1] \n. typeFilter:[V1xH1]; /* 1.5 */ pointsTo:[V1xH1] = pointsTo:[V1xH1] . newPointsTo:[V1xH1]; until pointsTo \ndoes not change  Figure 9: Incremental modi.cation to rule (1) of algorithm inconvenient to represent \nin the speci.c solver being implemented. 180 Off-line variable substitution is applicable only when all \nthe con\u00ad straints are available before the analysis begins; we could not use 160 it if we were computing \nthe call graph on-the-.y as the points-to 140 100 Spark  analysis proceeds. Table 4 presents our benchmarks \nordered by the size of the prob\u00adlem sets and grouped under the headings (s/t), (ns/t) and (ns/nt), where \ns denotes simpli.cation of the set of constraints, while ns denotes no simpli.cation, and t denotes use \nof type information during propagation, whereas nt denotes no use of type information during propagation. \nThe column labelled constraints gives the size memory usage (MB) 120 BDD 80 60 of the input in terms \nof the number of constraints, including allo\u00adcation sites, direct assignments, and .eld loads and stores. \nWithout simpli.cation, we see that numbers of constraints for the bench\u00admarks range from 316K to 433K. \nThe set size column indicates the sum of the sizes of the computed points-to sets across all variables, \nand is an indication of the size of the solution (the output). 5.1 Performance of BDDs For small problem \nsets, we .nd that our BDD solver is very com\u00adpetitive in terms of solving time, and even begins to beat \nSPARK when solving jedit, our largest benchmark. Further, in terms of memory usage, the BDD solver is \na clear winner. Figure 10 plots the memory usage versus the number of input constraints for the (s/t) \ncase, where the constraint set has been simpli.ed and the type information is used. Note that not only \nis the absolute space used much lower for the BDD solver, but also the space used for the BDD solver \nscales very well as the number of constraints increases. The difference in space usage widens when we \nconsider the other cases, (ns/t) and (ns/nt), where the number of input constraints are larger. As indicated \nby the middle section of Table 4, without sim\u00adpli.cation but using type information (ns/t), the BDD solver \nscales gracefully to a mere 38 MB of memory usage in the worst case, whereas the traditional solver requires \nup to 244 MB of RAM. The .nal section of Table 4 shows the results when type infor\u00admation is not used. \nNote that the size of output sets increases dra\u00admatically, they are about an order of magnitude larger \nthan when types are used. This makes it clear that solvers using an explicit representation of points-to \nsets will have dif.culty scaling if type information is not used, because the total size of the points-to \nsets becomes up to 356 million elements. This number includes only points-to sets corresponding to variables; \nthe points-to sets corre\u00adsponding to .elds of heap objects (the .eldsPt relation in our al\u00adgorithm) are \nmore than an order of magnitude larger. Even a very 40 20 0 170 180 190 200 210 220 230 240 number of \nconstraints (x1000) Figure 10: Memory usage vs. number of constraints (s/t) ef.cient set representation \nusing a single bit per set element would require a huge amount of memory to store these sets. In fact, \nthe SPARK solver uses such an encoding, and it ran out of memory on all of the problems which ignored \ndeclared types, even on a larger machine with 2 GB of memory. However, when we look at the results for \nthe BDD solver we see that even though the set size has increased by about a factor of 10 over the (ns/t) \ncase, the BDD memory usage increases by less than a factor of 2, and solves all problems in less than \n66 MB. This demonstrates the ability of BDDs to take advantage of the sharing of large sets. Overall, \nwe see that both solvers are ef.cient on small problem sets, and that the hand-coded solver is good at \nhandling inputs with type information. As the problem sets get larger, however, the BDD solution shows \na remarkable ability to scale well and handle large points-to sets by exploiting regularity in the sets \nto keep the repre\u00adsentation small. Techniques in which declared types are not used to limit the size \nof points-to sets, which have been used in related work [25, 33], would not be able to scale to this \nsize of problem; however, the BDDs do.  5.2 Notes on Measuring Memory Usage As previously noted, for \nthe timing run of the BDD solver, we allotted a heap of 160 MB to reduce the frequency of garbage col\u00adlections. \nHowever, the solver never requires this full amount during mation. One option is to extract the entire \nrelation into an explicit representation of the points-to sets. The time to enumerate the set of satisfying \nbit-vectors for a BDD X is nearly linear to the num\u00adber of solutions3. Alternatively, it can selectively \nextract only the points-to set of a variable, or those of a speci.c set of variables, on demand. A third, \ninteresting option is to minimize or even elimi\u00adnate the need to extract an explicit representation, \nbut rather use the BDD representation and operations for further computation. The size of the explicit \nrepresentation of the relation stored in a BDD may be quite large; by encoding part or all of the subsequent \nset processing with BDD operations, we can avoid constructing an ex\u00adplicit representation of this possibly \nlarge relation. benchmark const\u00ad set BDD SPARK raints size time mem time mem 103 106 (s) (MB) (s) (MB) \n(s/t) The most common use of points-to information is to determine whether two heap references p. f \nand q. f could refer to same loca\u00adtion, which reduces to checking whether p and q could be aliased. A \ndemand-driven way to solve this is to extract the points-to set of pt( p) and pt(q) by using the standard \nBDD operation, restrict, and check if the intersection of two sets is not empty (an empty set in BDD \nequals to the bdd falseconstant): pt(p) = restrict(pointsTo, BDD(p), V1); pt(q) = restrict(pointsTo, \nBDD(q), V1); alias(p,q) = (pt(p) n pt(q) = bdd_false); Another common use of points-to information is \nvirtual method call resolution. To resolve a method call site, a compiler needs a set of possible types \nof the receiver. This can be determined by checking the types of the objects found in the points-to set \nof the receiver. As the object types are encoded in a BDD relation, we can .nd the sets of possible receiver \ntypes for all receivers using just one relational product operation. Thus we can .nd all the types for \nall the receivers in just one step. varTypes = relprod(pointsTo, objectType, H1) The implicit BDD encoding \nhas advantages beyond that of com\u00adpactness. Direct operations on BDDs are very powerful; they allow a \ncompiler to use a high-level speci.cation to describe complex queries and set transformations. Not only \ndoes this enable rapid development, but with a good ordering, one can expect good per\u00adformance.  7. \nRELATED WORK Points-to analysis [1, 9, 32] has been an active research .eld in the past several years. \nHind [14] gives a very good overview of the current state of algorithms and metrics for points-to analysis. \nAn important issue is how well the algorithms scale to large programs. Various points-to analyses make \ntrade-offs between ef.ciency and precision. Equality-based analysis [32] runs in almost linear time, \nbut with less precise results. On the other hand, subset-based anal\u00adysis [1] produces more precise results, \nbut with cubic worst-case complexity. In this work, we developed a speci.c version of a subset-based \nanalysis that is suitable for implementing with BDDs, and which exhibits good space and time behaviour \nwhen used to an\u00adalyze a range of Java programs, including a variety of large bench\u00admark programs. Various \noptimizations have been proposed to improve the ef.\u00adciency of points-to analyses. Two of these optimizations, \ncycle elimination [10] and variable substitution [24], are based on the idea that variables whose points-to \nsets are provably equal can be merged, so that a single representation of the set can be shared 3If |X| \nis size of the set, and M is the number bits used to encode the BDD, then the set can be enumerated in \nT(|X|\u00d7 M) time. compress db raytrace jack mpegaudio jess jbb2000 javac sablecc-j soot-c jedit (ns/t) \n174 174 175 177 178 180 185 198 212 218 232 6.7 6.8 6.7 7.1 7.0 7.2 7.8 8.0 7.3 9.9 12.2 10 10 10 10 \n10 10 10 11 11 12 16 21 21 21 21 21 21 19 23 23 23 28 8 8 8 8 8 8 9 10 8 10 19 84 84 84 87 88 88 100 \n99 101 104 169 compress db raytrace jack mpegaudio jess jbb2000 javac sablecc-j soot-c jedit (ns/nt) \ncompress db raytrace jack mpegaudio jess jbb2000 javac sablecc-j soot-c jedit 316 317 318 325 325 330 \n342 366 393 397 433 316 317 318 325 325 330 342 366 393 397 433 18.3 18.4 18.3 19.2 19.1 19.8 20.9 21.0 \n19.9 24.9 35.1 163.3 163.9 163.4 171.5 171.2 183.3 206.7 199.7 196.3 228.4 344.9 20 20 22 22 23 24 22 \n23 23 26 35 59 59 59 59 61 61 70 65 64 66 121 29 28 29 29 30 29 23 31 31 33 38 38 38 38 38 39 39 42 40 \n41 43 66 11 11 11 12 13 12 13 14 14 15 35 oom oom oom oom oom oom oom oom oom oom oom 127 128 129 132 \n134 136 159 148 158 162 244 oom oom oom oom oom oom oom oom oom oom oom Table 4: Performance and live \ndata of BDD solver. The value oom indicates that the solver ran out of memory, even on a machine with \n2 GB. the computation. To measure the actual memory usage, we started BuDDy with 23 MB as the initial \nsize of the node table and a 2.4 MB cache size. Whenever less than 20% of memory was left, BuDDy increased \nthe size of the node table by 2.4 MB. This allowed us to measure the maximum live set size to within \n2.4 MB. Note that the actual memory allocated is up to 20% higher than this number, because BuDDyalways \nmaintains 20% of unused nodes for future use. In SPARK, the memory requirements increase monotonically \nas the analysis proceeds, so we simply report the .nal live set size af\u00adter a garbage collection at the \nend of the analysis. This comparison can only be used as a rough reference, since Java and C++ have dif\u00adferent \nobject models and memory management. However, we are measuring only the size of the data structures used \nby the points\u00adto analysis, excluding any structures introduced by the language\u00adspeci.c run-time system. \nThe memory requirements should there\u00adfore be at least roughly comparable, in spite of the differences \nbe\u00adtween Java and C++. 6. APPLICATIONS Section 5 shows that the BDD encoding scheme allows the points\u00adto \nproblem to be solved quickly and represents the points-to relation compactly. A compiler has several \noptions for accessing this infor\u00adby multiple variables. Heintze and Tardieu [12] reported very fast analysis \ntimes using a demand-driven algorithm and a carefully de\u00adsigned implementation of points-to sets [11]. \nSeveral groups adapted the points-to analyses used for C to Java [19, 25]. These approaches, however, \nwere applied only to benchmarks using the JDK 1.1.8 class library. One of the dif.cult points for whole \nprogram analysis for Java is that even very simple programs touch, or appear to touch, a large part of \nthe class library. The JDK 1.3.1 class library is several times larger than the 1.1.8 li\u00adbrary, and techniques \nwhich applied to the 1.1.8 case may no longer scale. Recently, two approaches have been presented that \nhave been shown to scale well to the JDK 1.3.1 library. Whaley and Lam [34] adapted the approach of Heintze \nand Tardieu to Java programs, and managed to get it to scale to benchmarks using the JDK 1.3.1 class \nlibrary (although they made optimistic, potentially unsafe, assump\u00adtions about what part of the library \nneeds to be analyzed). Lhot\u00b4ak and Hendren [17,18] presented the SPARK framework, which al\u00adlows experimentation \nwith many variations of points-to analyses for Java. They used this framework to implement points-to \nsolvers that were more ef.cient in time and space than the other reported work, including that of Whaley \nand Lam, making it the most ef.\u00adcient Java points-to analysis solver of which we are aware. There\u00adfore, \nin our study of BDD-based points-to analysis, we used the SPARK framework both to generate the input \nto our BDD-based solver, and as a baseline solver against which to compare our new BDD-based solver. \nOrdered Binary Decision Diagrams [5] represent boolean func\u00adtions as DAGs. The canonical representation \nallows ef.cient boolean operations and testing of equivalence and satis.ability. Symbolic Model Checking \n[16] is used to verify circuits with an ex\u00adtremely large number of states by using BDDs. The use of BDDs \nin this context has allowed researchers to solve larger problems than can be solved using table-based \nrepresentations of graphs. BDDs have also been used in software veri.cation and program analyses. PAS \n[29] converts predicate and condition relations in a control .ow graph to a compact BDD representation \nand performs analy\u00adsis on these BDDs. Another use of BDDs is to represent large sets and maps; TVLA [21] \nand Bebop [3] are examples. In our work, as in model checking, we use BDDs to represent all data structures, \nand we show non-trivial techniques to make the original algorithm scalable to large programs using this \nnew representation. Although model checking and program analyses are not tightly connected yet, several \npublications have pointed out theoretical connections between them [26, 27]. The theoretical foundation \nof .ow analyses is the .xed-point theory on monotonic functions, whose counterpart in model checking \nis the modal \u00b5-calculus. Schmidt and Steffen [27] presented a methodology of treating it\u00aderative .ow \nanalysis as model checking of abstract interpretations. Bandera [8] is a tool-set applying such ideas \nto analyzing realistic programs. Like some other work [4], it abstracts program prop\u00aderties to linear \ntemporal logic (LTL) or computational tree logic (CTL) formulas, which can be veri.ed ef.ciently by existing \nmodel checking tools. Martena and Pietro [22] studied the application of a model checker, Spin, to solve \nintraprocedural alias analysis for C. In a different program analysis setting, BDD-based groundness analysis \nfor constraint (logic) programs has become one of the stan\u00addard approaches [13]. 8. CONCLUSIONS AND \nFUTURE WORK In this paper, we have presented a BDD-based points-to analysis that scales very well in \nterms of time and space, and is very easy to implement using standard BDD packages. The motivation to \nuse BDDs came from the fact that for large programs, the number and size of points-to sets can grow so \nthat even well-tuned traditional representations fail to scale appropriately. BDDs have been shown to \nwork well for large problems in the model checking commu\u00adnity, and we wanted to see if they could be \napplied effectively to the points-to problem. We showed that with the appropriate tuning, a fairly simple \nalgorithm could deliver a solver that was competi\u00adtive with previously existing solvers and provided \na very compact representation of points-to relationships. It was not immediately obvious that a BDD-based \napproach would work for a program analysis like points-to. Although BDDs have been shown to be very effective \nin areas like hardware ver\u00adi.cation, program analyses face program properties that are quite different \nfrom those areas, including: 1) the problem may not be represented by LTL and CTL formulas; and 2) the \nanalyzed object may not have many common patterns. For example, the transition system of a circuit written \nin CTL often exhibits regularities in the structure, which can be compactly represented in BDDs by apply\u00ading \ngood heuristics. However, before we started our work, it was not clear if the subset-inclusion relationship \ngraph, and other data structures required for points-to analysis, had common structures that could give \ncompactness. By systematically exploring a va\u00adriety of orderings and empirically analyzing the performance, \nwe did .nd an incrementalized algorithm and associated variable or\u00addering that led to compact BDD representations. \nIt is interesting to note that in the case of points-to analysis, it was not so important to .nd a compact \nrepresentation for the input problem (unlike the case of hardware veri.cation, where the input description \nmay be very large and have many common patterns), but it was important to .nd a compact representation \nfor the solution (i.e. the points-to relationships). Thus, it was the fact that the points-to sets showed \na lot of regularity that leads to a fast and space-ef.cient solution. It would be very interesting to \nsee if other whole-program analyses exhibit the same sort of regularity in their solutions. In our opinion, \nthis is very likely. In our work so far, we concentrated on choosing a good variable ordering and developing \nthe incremental propagation algorithm. It is possible that this could be further improved by introducing \nsome aspects of graph-based solvers into the BDD solver. For exam\u00adple, it would be very interesting to \nsee if ef.cient BDD algorithms for collapsing strongly connected components [35] would further improve \nthe ef.ciency of our BDD-based points-to algorithm. An\u00adother idea which has been suggested for improving \nthe ef.ciency of BDDs is dynamic variable reordering. Our preliminary experi\u00adments with using this technique \non our points-to problem showed no signi.cant improvement. In fact, the cost of reordering the large \nBDDs involved appeared to be even higher than the cost of solv\u00ading the points-to problem with the original \nordering. We there\u00adfore leave further investigation of dynamic variable reordering for BDD-based points-to \nanalysis as future work. In addition to achieving our goals in terms of time and space, we were pleasantly \nsurprised with how easy it was for us to specify a wide variety of algorithms with the BDD approach. \nWe tried many variations of the points-to analysis while developing our algorithm and it was very easy \nto go from one variation to the next. Based on this experience, we believe that a BDD package should \nbe part of the standard toolkit for compiler analysis developers. Further, our BDD-based points-to analysis \nshould be very easy to incorporate into program analysis tools where BDDs are used more and more frequently. \nWe plan to continue our work with BDDs and to further experi\u00adment with the kinds of queries outlined \nin Section 6. In addition, we would like to make a tighter connection between the Soot frame\u00adwork and \na BDD toolkit so that subsequent BDD-based analyses could be speci.ed at a very high level.  9. REFERENCES \n[1] Lars Ole Andersen. Program Analysis and Specialization for the C Programming Language, May 1994. \nPh.D thesis, DIKU, University of Copenhagen. [2] Ashes suite collection http://www.sable.mcgill.ca/software/. \n [3] Thomas Ball and Sriram K. Rajamani. Bebop: A Path-sensitive Interprocedural Data.ow Engine. In Proceedings \nof PASTE 01, pages 97 103, Jun 2001. [4] David Basin, Stefan Friedrich, Marek Gawkowski, and Joachim \nPosegga. Bytecode Model Checking: An Experimental Analysis. In Dragan Bosnacki and Stefan Leue, editors, \nModel Checking Software, 9th International SPIN Workshop, volume 2318 of LNCS, pages 42 59. Springer-Verlag, \nApr 2002. [5] Randal E. Bryant. Symbolic Boolean Manipulation with Ordered Binary Decision Diagrams. \nACM Computing Surveys, 24(3):293 318, 1992. [6] Manuvir Das. Uni.cation-based pointer analysis with \ndirectional assignments. In Proceedings of PLDI 00, pages 35 46, Jun 2000. [7] Jeffrey Dean, David Grove, \nand Craig Chambers. Optimization of object-oriented programs using static class hierarchy analysis. In \nWalter G. Olthoff, editor, ECOOP 95 Object-Oriented Programming, 9th European Conference, volume 952 \nof Lecture Notes in Computer Science, pages 77 101, \u00b0 Aarhus, Denmark, Aug 1995. Springer. [8] Matthew \nB. Dwyer, John Hatcliff, Roby Joehanes, Shawn Laubach, Corina S. Pasareanu, Robby, Hongjun Zheng, and \nW Visser. Tool-Supported Program Abstraction for Finite-State Veri.cation. In Proceedings of ICSE, pages \n177 187, 2001. [9] Maryam Emami, Rakesh Ghiya, and Laurie J. Hendren. Context-sensitive interprocedural \npoints-to analysis in the presence of function pointers. In Proceedings of PLDI 94, pages 242 256, 1994. \n [10] Manuel F\u00a8ahndrich, Jeffery S. Foster, Zhendong Su, and Alexander Aiken. Partial online cycle elimination \nin inclusion constraint graphs. In Proceedings of PLDI 98, pages 85 96, Montreal, Canada, Jun 1998. [11] \nNevin Heintze. Analysis of large code bases: The compile-link-analyze model, 1999. http://cm.bell-labs.com/cm/cs/who/nch/cla.ps. \n[12] Nevin Heintze and Olivier Tardieu. Ultra-fast aliasing analysis using CLA: A million lines of C \ncode in a second. In Proceedings of PLDI 01, pages 254 263, June 2001. [13] Pascal Van Hentenryck, Agostino \nCortesi, and Baudouin Le Charlier. Evaluation of the domain Prop. Journal of Logic Programming, 23(3):237 \n278, 1995. [14] Michael Hind. Pointer Analysis: Haven t We Solved This Problem Yet? In Proceedings of \nPASTE 01, pages 54 61, Jun 2001. [15] jEdit: Open source programmer s text editor. http://www.jedit.org/. \n[16] J.R. Burch, E.M. Clarke, D.E. Long, K.L. MacMillan, and D.L. Dill. Symbolic Model Checking for Sequential \nCircuit Veri.cation. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 13(4):401 \n 424, 1994. [17] Ond.rej Lhot\u00b4ak. Spark: A .exible points-to analysis framework for Java. Master s thesis, \nMcGill University, December 2002. [18] Ond.rej Lhot\u00b4ak and Laurie Hendren. Scaling Java points-to analysis \nusing Spark. In G. Hedin, editor, Compiler Construction, 12th International Conference, volume 2622 of \nLNCS, pages 153 169, Warsaw, Poland, April 2003. Springer. [19] Donglin Liang, Maikel Pennings, and Mary \nJean Harrold. Extending and evaluating .ow-insensitive and context-insensitive points-to analyses for \nJava. In Proceedings of PASTE 01, pages 73 79, 2001. [20] J\u00f8rn Lind-Nielsen. BuDDy, A Binary Decision \nDiagram Package. Department of Information Technology, Technical University of Denmark, http://www.itu.dk/research/buddy/. \n[21] R. Manevich, G. Ramalingam, J. Field, D. Goyal, and M. Sagiv. Compactly Representing First-Order \nStructures for Static Analysis. In Manuel V. Hermenegildo and German Puebla, editors, Proceedings of \nSAS 02, volume 2477 of LNCS, Madrid, Spain, September 2002. Springer. [22] Vincenzo Martena and Pierluigi \nSan Pietro. Alias Analysis by Means of a Model Checker. In R. Wilhelm, editor, Compiler Construction, \n10th International Conference, volume 2027 of LNCS, pages 3 19, Genova, Italy, April 2001. Springer. \n[23] Cristoph Meinel and Thorsten Theobald. Algorithms and Data Structures in VLSI Design. Springer, \n1998. [24] Atanas Rountev and Satish Chandra. Off-line Variable Substitution for Scaling Points-to Analysis. \nIn Proceedings of PLDI 00, pages 47 56, Jun 2000. [25] Atanas Rountev, Ana Milanova, and Barbara Ryder. \nPoints-to analysis for Java using annotated constraints. In Proceedings of OOPSLA 01, pages 43 55, 2001. \n[26] David A. Schmidt. Data Flow Analysis is Model Checking of Abstract Interpretations. In Proceedings \nof POPL 98, pages 38 48, Jan 1998. [27] David A. Schmidt and Bernhard Steffen. Program analysis as model \nchecking of abstract interpretations. In Proceedings of SAS 98, pages 351 380, 1998. [28] Marc Shapiro \nand Susan Horwitz. Fast and accurate .ow-insensitive points-to analysis. In Proceedings of POPL 97, pages \n1 14, Paris, France, Jan 1997. [29] John W. Sias, Wen mei W. Hwu, and David I. August. Accurate and Ef.cient \nPredicate Analysis with Binary Decision Diagrams. In Proceedings of the 33rd annual IEEE/ACM International \nSymposium on Microarchitecture, pages 112 123, Dec 2000. [30] SPEC jbb200 benchmark http://www.spec.org/osg/jbb2000/. \n[31] SPEC jvm98 benchmarks http://www.spec.org/osg/jvm98/. [32] Bjarne Steensgaard. Points-to analysis \nin almost linear time. In Proceedings of POPL 96, pages 32 41, Jan 1996. [33] Vijay Sundaresan, Laurie \nHendren, Chrislain Raza.mahefa, Raja Vall\u00b4ee-Rai, Patrick Lam, Etienne Gagnon, and Charles Godin. Practical \nvirtual method call resolution for Java. In Proceedings of the 2000 OOPSLA, pages 264 280, 2000. [34] \nJohn Whaley and Monica Lam. An ef.cient inclusion-based points-to analysis for strictly-typed languages. \nIn Proceedings of SAS 02, volume 2477 of LNCS, 2002. [35] Aiguo Xie and Peter A. Beerel. Implicit enumeration \nof strongly connected components. In International Conference on Computer-Aided Design, pages 37 40, \nNov 1999. APPENDIX A. FULL INCREMENTAL ALGORITHM /* global variables, initialized by input constraints \n*/ bdd pointsTo; // points-to relation V1 x H1 bdd edgeSet; // assignment relation V1 x V2 bdd stores; \n// field store relation V1 x (V2 x FD) bdd loads; // field load relation (V1 x FD) x V2 bdd typeFilter; \n// encoding type filter V1 x H1 /* caches for intermediate results */ bdd fieldPt; // (H1 x FD) x H2 \npoints-to relation for fields of heap objects bdd storePt; // H2 x (V1 x FD) temporary relation for field \nstores bdd loadAss; // (H1 x FD) x V2 temporary relation for field loads /* incrementally computes points-to \nrelation */ void solve_incremental(){ bdd oldPointsTo = bdd_false(); // initialize variable to FALSE \n(0) bdd newPointsTo = pointsTo; // main iteratons do{ // repeat rule (1) in the inner loop, see Figure \n9 for details do{ bdd newPt1 = bdd_relprod(edgeSet, newPointsTo, fdd_ithset(V1)); bdd newPt2 = bdd_replace(newPt1, \nV2ToV1); bdd newPt3 = newPt2 -pointsTo; newPointsTo = newPt3 &#38; typeFilter; pointsTo = pointsTo | \nnewPointsTo; } while (newPointsTo != bdd_false()); newPointsTo = pointsTo -oldPointsTo;  // apply rule \n(2) bdd tmpRel1 = bdd_relprod(stores, newPointsTo, fdd_ithset(V1)); // (V2xFD)xH1 bdd tmpRel2 = bdd_replace(bdd_replace(tmpRel1, \nV2ToV1), H1ToH2); // (V1xFD)xH2 bdd newStorePt = tmpRel2 -storePt; storePt |= newStorePt; // (V1xFD)xH2 \n bdd newFieldPt = bdd_relprod(storePt, newPointsTo, fdd_ithset(V1)); // (H1xFD)xH2 newFieldPt |= bdd_relprod(newStorePt, \noldPointsTo, fdd_ithset(V1)); // (H1xFD)xH2 newFieldPt -= fieldPt; fieldPt |= newFieldPt; // (H1xFD)xH2 \n // apply rule (3) bdd tmpRel3 = bdd_relprod(loads, newPointsTo, fdd_ithset(V1)); // (H1xFD)xV2 bdd newLoadAss \n= tmpRel3 -loadAss; bdd newLoadPt = bdd_relprod(loadAss, newFieldPt, fdd_ithset(H1)&#38;fdd_ithset(FD)); \nnewLoadPt |= bdd_relprod(newLoadAss, fieldPt, fdd_ithset(H1)&#38;fdd_ithset(FD)); loadAss |= newLoadAss; \n oldPointsTo = pointsTo;  // convert new points-to relation to normal type newPointsTo = bdd_replace(bdd_replace(newLoadPt, \nV2ToV1), H2ToH1); newPointsTo -= pointsTo; // apply typeFilter newPointsTo = typeFilter &#38; newPointsTo; \npointsTo |= newPointsTo; // loop until points-to set has no changes } while (newPointsTo != bdd_false()); \n}  \n\t\t\t", "proc_id": "781131", "abstract": "This paper reports on a new approach to solving a subset-based points-to analysis for Java using Binary Decision Diagrams (BDDs). In the model checking community, BDDs have been shown very effective for representing large sets and solving very large verification problems. Our work shows that BDDs can also be very effective for developing a points-to analysis that is simple to implement and that scales well, in both space and time, to large programs.The paper first introduces BDDs and operations on BDDs using some simple points-to examples. Then, a complete subset-based points-to algorithm is presented, expressed completely using BDDs and BDD operations. This algorithm is then refined by finding appropriate variable orderings and by making the algorithm propagate sets incrementally, in order to arrive at a very efficient algorithm. Experimental results are given to justify the choice of variable ordering, to demonstrate the improvement due to incrementalization, and to compare the performance of the BDD-based solver to an efficient hand-coded graph-based solver. Finally, based on the results of the BDD-based solver, a variety of BDD-based queries are presented, including the points-to query.", "authors": [{"name": "Marc Berndl", "author_profile_id": "81100077521", "affiliation": "McGill University, Montreal, CANADA", "person_id": "P514146", "email_address": "", "orcid_id": ""}, {"name": "Ondrej Lhot&#225;k", "author_profile_id": "81100503314", "affiliation": "McGill University, Montreal, CANADA", "person_id": "P397734", "email_address": "", "orcid_id": ""}, {"name": "Feng Qian", "author_profile_id": "81100414440", "affiliation": "McGill University, Montreal, CANADA", "person_id": "PP43120331", "email_address": "", "orcid_id": ""}, {"name": "Laurie Hendren", "author_profile_id": "81100646110", "affiliation": "McGill University, Montreal, CANADA", "person_id": "PP14221385", "email_address": "", "orcid_id": ""}, {"name": "Navindra Umanee", "author_profile_id": "81100639693", "affiliation": "McGill University, Montreal, CANADA", "person_id": "P517420", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/781131.781144", "year": "2003", "article_id": "781144", "conference": "PLDI", "title": "Points-to analysis using BDDs", "url": "http://dl.acm.org/citation.cfm?id=781144"}