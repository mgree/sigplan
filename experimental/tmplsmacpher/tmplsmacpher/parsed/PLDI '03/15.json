{"article_publication_date": "05-09-2003", "fulltext": "\n A Static Analyzer for Large Safety-Critical Software (Extended Abstract) Bruno Blanchet*\u00a7 Patrick Cousot\u00a7 \nRadhia Cousot*\u00b6 J\u00b4er ome Feret\u00a7 Laurent Mauborgne \u00a7 Antoine Min\u00b4e \u00a7 David Monniaux *\u00a7 Xavier Rival \u00a7 \nABSTRACT We show that abstract interpretation-based static program analysis canbe made e.cient andprecise \nenough toformally verify a class of properties for a family of large programs with few or no false alarms. \nThis is achieved by re.nement of a general purpose static analyzer and later adaptation to particular \nprograms of the family by the end-user through parametrization. This is applied to the proof of soundness \nof data manipulation operations at the machine level for periodic synchronous safety critical embedded \nsoftware. The main novelties are the design principle of static an\u00adalyzers by re.nement and adaptation \nthrough parametriza\u00adtion(Sect.3 and7),the symbolic manipulation of expres\u00adsions to improve the precision \nof abstract transfer functions (Sect.6.3),the octagon(Sect.6.2.2), ellipsoid(Sect.6.2.3), and decision \ntree (Sect. 6.2.4) abstract domains, all with sound handling of rounding errors in .oating point compu\u00adtations, \nwidening strategies (with thresholds: Sect. 7.1.2, delayed: Sect. 7.1.3) and the automatic determination \nof theparameters(parametrizedpacking: Sect.7.2). Categories and Subject Descriptors D.2.4[SoftwareEngineering]: \nProgramVeri.cation for\u00admal methods, validation, assertion checkers;D.3.1[Program\u00adming Languages]: Formal \nDe.nitions and Theory se\u00admantics; F.3.1 [Logics and Meanings of Programs]: Specifying and Verifying and \nReasoning about Programs Mechanicalveri.cation, assertions,invariants;F.3.2[Logics and Meanings of Programs]: \nSemantics ofProgramming Languages Denotational semantics, Program analysis. General Terms Algorithms, \nDesign, Experimentation, Reliability, Theory, Veri.cation. Keywords Abstract Interpretation; Abstract \nDomains; Static Analy\u00adsis; Veri.cation; Floating Point; Embedded, Reactive, Real-Time, Safety-Critical \nSoftware. * CNRS(Centre National de la Recherche Scienti.que) \u00a7 \u00b4 Ecole normale sup\u00b4erieure. First-name.Last-name@ens.fr \n\u00b6 \u00b4 Ecole polytechnique. First-name.Last-name@polytechnique.fr Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 03, June 9 11, 2003, San Diego, California, \nUSA. Copyright 2003 ACM 1-58113-662-5/03/0006 ...$5.00. 1. INTRODUCTION Critical software systems (as \nfound in industrial plants, automotive, and aerospace applications) should never fail. Ensuring that \nsuch software does not fail is usually done by testing, whichis expensivefor complex systems withhigh \nre\u00adliability requirements, and anyway fails to prove the impos\u00adsibility of failure. Formal methods, such \nas model checking, theorem proving, and static analysis, can help. The de.nition of failure itself is \ndi.cult, in particular in the absence of a formal speci.cation. In this paper, we choosetofocus on aparticular \naspectfoundin all speci.ca\u00adtions for critical software, that is, ensuring that the critical software \nnever executes an instruction with unde.ned or fatal error behavior, such as out-of-bounds accesses to \nar\u00adrays orimproper arithmetic operations(such as over.ows or division by zero). Such conditions ensure \nthat the program is written according to its intended semantics, for example thecritical systemwill neverabortitsexecution. \nThesecor\u00adrectness conditions are automatically extractable from the source code,thusavoiding the needfor \na costlyformal spec\u00adi.cation. Our goal is to prove automatically that the soft\u00adware never executes such \nerroneous instructions or, at least, togiveavery smalllist ofprogrampointsthat maypossibly behave in \nundesirable ways. Inthispaper, wedescribe ourimplementation and exper\u00adimental studies of static analysis \nby abstract interpretation over afamily of critical software systems, and wediscuss the main technical \nchoices and possible improvements. 2. REQUIREMENTS Whendealing with undecidablequestions onprogram ex\u00adecution, \nthe veri.cation problem must reconcile correctness (which excludes non exhaustive methods such as simula\u00adtion \nor test), automation (which excludes model checking with manual production of a program model and deductive \nmethods where provers must be manually assisted), preci\u00adsion (whichexcludesgeneral analyzers which wouldproduce \ntoo many false alarms, i.e., spurious warnings about poten\u00adtial errors), scalability (for software ofa \nfew hundred thou\u00adsand lines), and e.ciency (with minimal space and time requirements allowing for rapid \nveri.cation during the soft\u00adware production process which excludes a costly iterative re.nement process). \nIndustrialized general-purpose static analyzers satisfy all criteria but precision and e.ciency. Traditionally, \nstatic analysis is made e.cient by allowing correct but somewhat imprecise answers to undecidable questions. \nIn many usage contexts, imprecision is acceptable provided all answers are sound andtheimprecisionrate \nremainslow(e.g.5to15% of the runtime tests cannot typically be eliminated). This is the caseforprogram \noptimization(such as static elimination of run-time array bound checks), program transformation (suchas \npartial evaluation), etc. In the context of program veri.cation, where human in\u00adteractionmustbe reduced \nto a strict minimum,falsealarms areundesirable. A5% rateoffalsealarmsonaprogramof a few hundred thousand \nlines would require a several person\u00adyear e.ort to manually prove that no error is possible. For\u00adtunately, \nabstract interpretation theory shows that for any .nite class of programs, it is possible to achieve \nfull pre\u00adcision andgreat e.ciency[7] by discovering an appropriate abstractdomain. Thechallengeistoshowthatthistheoret\u00adical \nresult can be made practical by considering in.nite but speci.c classes of programs and properties to \nget e.cient analyzers producing few or no false alarms. A .rst experi\u00adment on smallerprograms of afewthousandlines \nwasquite encouraging[5] and thepurposeof thispaperistoreport on a real-life application showing that \nthe approach does scale up. 3. DESIGN PRINCIPLE The problem is to .nd an abstract domain that yields \nan e.cient and precise static analyzer for the given family of programs. Our approach is in two phases, \nan initial design phase by specialists in charge of designing a parametrizable analyzer followed by an \nadaptation phase by end-users in charge of adapting the analyzer for (existing and future) programs in \nthe considered family by an appropriate choice of the parameters of the abstract domain and the iteration \nstrategy(maybe using someparameter adaptation strategies provided by the analyser). 3.1 Initial Design \nby Re.nement Starting from an existing analyzer [5], the initial design phase is an iterative manual \nre.nement of the analyzer. We have chosen to start from a program in the considered fam\u00adily thathasbeen \nrunning for10years without any run-time error, so that all alarms are, in principle, due to the impre\u00adcision \nof the analysis. The analyzer can thus be iteratively re.ned for this example until all alarms are eliminated. \nEach re.nement step starts with a static analysis of the program, which yields false alarms. Then a manual \nback\u00adward inspection of the program starting from sample false alarms leads to the understanding of the \norigin of the im\u00adprecision of the analysis. There can be two di.erent reasons for the lack of precision: \nSomelocalinvariants are expressibleinthe current ver\u00adsion of the abstract domain but were missed either: \nbecause some abstract transfer function (Sect. 5.4) was too coarse, in which case it must be rewritten \ncloser to the best abstraction of the concrete transfer function [9], (Sect. 6.3); orbecause a widening \n(Sect.5.5)was too coarse, in which casetheiteration strategy mustbe re.ned(Sect.7.1); Some local invariants \nare necessary in the correctness proof but are not expressible in the current version of the abstract \ndomain. To express these local invariants, a new abstractdomainhastobedesignedby specialistsandincor\u00adporated \nin the analyzer as an approximation of the reduced product[9] of this new component with the already \nexisting domain(Sect. 7.2). When this new re.nement of the analyzerhasbeenimple\u00admented,itistested ontypical \nexamplesand then onthefull program to verify that some false alarms have been elim\u00adinated. In general \nthe same cause of imprecision appears several times in the program; furthermore, one single cause of \nimprecision at some program point often leads later to many false alarms in the code reachable from that \nprogram point, so a single re.nement typicallyeliminates afewdozen if not hundreds of false alarms. Thisprocessistoberepeated \nuntil thereisno orveryfew false alarms left. 3.2 Adaptation by Parametrization The analyzer can then \nbe used by end-users in charge of proving programs in the family. The necessary adapta\u00adtion of the analyzer \nto a particular program in the family is by appropriate choice of some parameters. An example providedinthepreliminary \nexperience[5] wasthe widening with thresholds (Sect. 7.1.2). Another example is relational domains (such \nas octagons [30], Sect. 6.2.2) which cannot be applied toallglobal variables simultaneouslybecausethe \ncorresponding analysis would be too expensive; it is possi\u00adble to have the user supply for each program \npoint groups of variables on which the relational analysis should be inde\u00adpendently applied. In practice \nwe have discovered that the parametrization canbelargely automated(andindeeditisfully automated for octagons \nas explained in Sect. 7). This way the e.ort to manually adapt the analyzer to a particular program in \nthe family is reduced to a minimum. 3.3 Analysis of the Alarms We implemented and used a slicer [34] \nto help in the alarm inspection process. If the slicing criterion is an alarm point, the extracted slice \ncontains the computations that led to the alarm. However, the classical data and control dependence-based \nbackward slicing turned out to yield pro\u00adhibitively large slices. In practice we are not interested in \nthe computation of the variablesfor which the analyzer alreadyprovides a value close to end-user speci.cations, \nand we can consider only the variableswelackinformationabout(integeror .oatingpoint variables that may \ncontain large values or boolean variables that may take any value according to the invariant). In the \nfuture we plan to design more adapted forms of slicing: an abstract slice would only contain the computations \nthatlead to an alarm point wherever the invariant is too weak.  4. THE CONSIDERED FAMILY OF PRO-GRAMS \nThe considered programs in the family are automatically generated using a proprietary tool from a high-level \nspeci.\u00adcation familiar to control engineers, such as systems of dif\u00adferential equations or synchronous \noperator networks(block diagrams as illustrated in Fig. 1), which is equivalent to theuse of synchronouslanguages(like \nLustre [20]). Such synchronous data-.ow speci.cations are quite common in real-world safety-critical \ncontrol systems ranging from let\u00adter sorting machine control to safety control and monitoring systems \nfor nuclear plants and .y-by-wire systems. Peri\u00adodic synchronous programming perfectly matches the need \nfor the real-time integration of di.erential equations by for\u00adward, .xed step numerical methods. Periodic \nsynchronous programs have the form: declare volatile input, state and output variables; initialize state \nvariables; loop forever read volatile input variables,  compute output and state variables,  write \nto volatile output variables;  wait for next clock tick; end loop Our analysis proves that no exception \ncan be raised (but the clock tick) and that all data manipulation operations are sound. The bounded execution \ntime of the loop body should alsobe checkedby static analysis[16] toprove that the real-time clock interrupt \ndoes occur at idle time. We operate on the C language source code of those sys\u00adtems, ranging from a few \nthousand lines to 132,000 lines of C source code (75 kLOC after preprocessing and simpli.\u00adcation as in \nSect. 5.1). We take into account all machine\u00addependent aspects of the semantics of C (as described in \n[5]) as well as the periodic synchronous programming as\u00adpects (for the wait). We use additional speci.cations \nto describe the material environment with which the software interacts (essentially ranges of values \nfor a few hardware registers containing volatile input variables and a maximal execution time to limit \nthe possible number of iterations in the external loop1). The source codes we consider use only a reduced \nsubset ofC,bothinthe automaticallygeneratedglue code and the handwritten pieces. As it is often the case \nwith critical sys\u00adtems, there is no dynamic memory allocation and the use of pointers is restricted to \ncall-by-reference. On the other hand, animportant characteristicsof thoseprogramsisthat the number of \nglobal and static2 variables is roughly lin\u00adear in the length of the code. Moreover the analysis must \nconsider the values of all variables and the abstraction can\u00adnotignore anypart of theprogram withoutgenerating \nfalse alarms. It was therefore agrand challenge todesign an anal\u00adysis that is precise and does scale \nup. 5. STRUCTURE OF THE ANALYZER The analyzerisimplementedinObjectiveCaml[25]. It operatesintwophases: \nthepreprocessing andparsingphase followed by the analysis phase. 5.1 Preprocessing Phase The source code \nis .rst preprocessed using a standard Cpreprocessor, then parsed using a C99-compatible parser. Optionally, \na simplelinker allowsprograms consistingof sev\u00aderal source .les to be processed. The program is then \ntype-checked and compiled to an intermediate representation, a simpli.ed version of the ab\u00adstract syntaxtree \nwith all types explicit and variablesgiven unique identi.ers. Unsupported constructs are rejected at \nthis point with an error message. Syntactically constant expressions are evaluated and re\u00ad 1Most physical \nsystems cannot run forever and some event counters in their control programs are bounded because of this \nphysical limitation. 2InC, a static variable has limited lexical scopeyet isper\u00adsistent with program \nlifetime. Semantically, it is the same as a global variable with a fresh name. placed by their value. \nUnused global variables are then deleted. This phase is important since the analyzed pro\u00adgrams use large \narrays representing hardware features with constant subscripts; those arrays are thus optimized away. \nFinallythepreprocessingphaseincludespreparatorywork for tracepartitioning(Sect.7.1.5)andparametrizedpacking \n(Sect. 7.2). 5.2 Analysis Phase The analysis phase computes the reachable states in the considered abstract \ndomain. This abstraction is formalized by a concretization function . [8, 9, 11]. The computation of \nthe abstraction of the reachable states by the abstract interpreter is called abstract execution. The \nabstract interpreter .rst creates the global and static variables of the program (the stack-allocated \nvari\u00adables are created and destroyed on-the-.y). Then the ab\u00adstract execution is performed compositionally, \nby induction on the abstract syntax, and driven by the iterator. 5.3 General Structure of the Iterator \nThe abstract execution starts at a user-supplied entry pointfortheprogram, such asthe main function. \nEachpro\u00adgram construct is then interpreted by the iterator according to the semantics of C as well as \nsome information about the target environment(some orders of evaluationleft unspeci\u00ad.ed by the C norm, \nthe sizes of the arithmetic types, etc., see[5]). TheiteratortransformstheCinstructionsintodi\u00adrectivesfortheabstractdomainthat \nrepresentsthe memory state of the program (Sect. 6.1), that is, the global, static and stack-allocated \nvariables. The iterator operates in two modes: the iteration mode and the checking mode. The iteration \nmode is used to gen\u00aderateinvariants; no warningisdisplayed when somepossible errorsaredetected. Wheninchecking \nmode,theiteratoris\u00adsues a warning for each operator application that may give an error onthe concretelevel(thatisto \nsay,theprogram may be interrupted, such as when dividing by zero, or the computed result may not obey \nthe end-user speci.cationfor this operator, such as when integers wrap-around due to an over.ow). In \nall cases, the analysis goes on with the non\u00aderroneous concrete results (over.owing integers are wiped \nout and not considered modulo, thus following the end-user intended semantics). Tracing facilities with \nvarious degrees of detail are also available. For example the loop invariants which are gener\u00adated by \nthe analyzer can be saved for examination. 5.4 Primitives of the Iterator Whetheriniterationorchecking \nmode,theiteratorstarts with an abstract environment Eat thebeginning of a state\u00adment S in the program \nand outputs an abstract environ\u00ad ment [S].(E) which is a valid abstraction after execution of statement \nS. This means that if a concrete environment maps variables to their values, [S]s is a standard semantics \nof S (mappingan environment . before executing S to the corresponding environment [S]s(.) after execution \nof S), [S]c is the collecting semantics of S (mapping a set E of environments before executing S to the \ncorresponding set [S]c(E)= {[S]s(.) |. . E}of environments after execu\u00adtion of S), .(E.) is the set of \nconcrete environments be\u00ad fore S then [S].(E)over-approximates the set [S]c(.(E)) of environments after \nexecuting S in that [S]c(.(E)) . .([S] (E )). The abstract semantics [S] is de.ned as fol\u00adlows: Tests: \nlet us consider a conditional S = if (c){S1 }else {S2 } (an absentelse branch is considered as an empty \nexecution sequence). The condition c can be assumed to have no side e.ect and to contain no function \ncall, both of which can be handledby .rstperforming aprogramtransformation. The iterator computes: [S] \n(E )= [S1] (guard (E ,c))U [S2] (guard (E,\u00acc)) where the abstract domain implements: U as the abstract \nunion that is an abstraction of the union . of sets of environments;  guard (E ,c) as an approximation \nof [c]c(.(E )) where the collecting semantics [c]c(E)= {. . E |[c]s(.)= true}of the condition c is the \nset of concrete environments . in E satisfying condition c. In practice, the abstract domain onlyimplements \nguard for atomic conditions andcompound ones are handled by structural induction.  Loops arebyfarthe \nmostdelicateconstructto analyze. Let us denote by E0 the environment before the loop: while (c){body \n} The abstract loop invariant to be computed for the head of the loop is an upper approximation of the \nleast invariant of F where F(E)= .(E0).[body]c([c]c(E)). The .xpoint computation F (E )= E0 U [body] \n(guard (E ,c)) is al\u00adwaysdoneiniteration mode, requires a widening(Sect.5.5) and stops with an abstract \ninvariant E satisfying F (E ) . E (where the abstract partial ordering x . y implies .(x) . .(y)) [11]. \nWhen in checking mode, the abstract loop invariant has .rst to be computed in iteration mode andthen, \nan extraiteration(in checking modethistime), starting from this abstract invariant is necessary to collect \npotential errors. Sequences i1;i2: .rst i1 is analyzed, then i2, so that: [i1;i2] (E )= [i2] .[i1] (E \n) . Function calls are analyzedby abstract execution of the function body in the context of the point \nof call, creating temporary variablesfor theparameters andthe return value. Since the considered programs \ndo not use recursion, this gives a context-sensitive polyvariant analysis semantically equivalent to \ninlining.  Assignments are passed to the abstract domain.  Return statement: We implemented the return \nstate\u00adment by carrying over an abstract environment represent\u00ading the accumulated return values(and environments,if \nthe function has side e.ects).  5.5 Least Fixpoint Approximation with Widening and Narrowing The analysis \nofloopsinvolves theiterative computation of an invariant E that is such that F (E ). E where F is an \nabstraction of the concrete monotonic transfer function F of the test and loop body. In abstract domains \nwith in\u00ad.nite height, this is done by widening iterations computing a .nite sequence E0 = ., ..., E n+1 \n= En F (En), ..., EN of successive abstract elements, until .nding an invari\u00ad ant EN. The widening operator \nshould be sound (that is the concretization of xy should overapproximate the concretizations of x and \ny) and ensure the termination in .nitetime[8,11](see an exampleinSect.7.1.2). In general, this invariant \nis not the strongest one in the abstract domain. This invariant is then made more and more precise by \nnarrowing iterations: EN, ..., E n+1 = En F (En)where the narrowing operator is sound(the concretization \nof xy is an upper approximation of the intersection of x and y)and ensurestermination[8,11].  6. ABSTRACT \nDOMAINS The elements of an abstract domain abstract concrete predicates, thatis,properties or sets ofprogram \nstates. The operations of an abstract domain are transfer functions ab\u00adstracting predicate transformers \ncorresponding to all basic operationsin theprogram[8]. The analyzerisfullyparamet\u00adricin the abstractdomain(thisisimplemented \nusing anOb\u00adjectiveCamlfunctor). Presently theanalyzerusesthe mem\u00adory abstract domain ofSect.6.1, which \nabstracts sets ofpro\u00adgram data states containing data structures such as simple variables, arrays and \nrecords. This abstract domain is itself parametric in the arithmetic abstract domains (Sect. 6.2) abstractingproperties \nof sets of(tuples of) boolean,integer or .oating-point values. Finally,theprecisionoftheabstract transfer \nfunctions can be signi.cantly improved thanks to symbolic manipulations of theprogram expressionspreserv\u00ading \nthe soundness oftheir abstract semantics(Sect.6.3). 6.1 The Memory Abstract Domain When aCprogramis executed, \nalldata structures(simple variables, arrays, records, etc) are mapped to a collection of memory cells \ncontaining concrete values. The memory ab\u00adstractdomain is an abstraction ofsets of such concrete mem\u00adory \nstates. Its elements, called abstract environments, map variables to abstract cells. The arithmetic abstract \ndomains operate on the abstract value of one cell for non-relational ones(Sect.6.2.1) and on several \nabstract cellsfor relational ones(Sect.6.2.2,6.2.3, and6.2.4). An abstract valuein a abstract cellis \ntherefore the reduction of the abstract values providedby eachdi.erentbasic abstractdomain(thatis an \napproximation oftheir reducedproduct[9]). 6.1.1 Abstract Environments An abstract environment is a collection \nof abstract cells, which can be of the following four types: An atomic cell represents a variable of \na simple type (enumeration, integer, or .oat) by an element of the arith\u00admetic abstract domain. Enumeration \ntypes, including the booleans, are considered to be integers.  An expanded array cell represents a program \narray us\u00ading one cell for each element of the array. Formally, let  i i A = `(v1,...,v )\u00b4 be the family \n(indexed by a set .) ni.. of values of the array(of size n)to be abstracted. The ab\u00adstraction is . (representing \nnon-accessibility of dead code) when A is empty. Otherwise the abstraction is an abstract array Ae of \nsize n such the expanded array cell Ae[k]is the i abstraction of Si.. vk for k =1, ..., n. Therefore \nthe ab\u00adstractionis component-wise, each element of the arraybeing abstracted separately. A shrunk array \ncell represents a program array using a single cell. Formally the abstraction is a shrunk array cell \ni As abstracting Sn Svk. All elements of the array are k=1 i.. thus shrunk together. Weusethisrepresentationforlarge \narrays where all that mattersis the range of the storeddata. A record cell represents aprogram record(struct)us\u00adingonecellforeach \n.eld of therecord. Thusourabstraction is .eld-sensitive. 6.1.2 Fast Implementation of Abstract Environments \nAnaiveimplementation of abstract environments may use an array. We experimented with in-place and functional \nar\u00adrays and found this approach very slow. The main reason is that abstract union U operations are expensive, \nbecause they operate in time linear in the number of abstract cells; since both the number of global \nvariables (whence of ab\u00adstract cells) and the number of tests(involving the abstract union U )are linear \nin the length of the code, this yields a quadratic time behavior. A simple yet interesting remark is \nthat in most cases, abstract union operations are applied between abstract en\u00advironments that are identical \non almost all abstract cells: branches oftests modify afew abstract cells only. Itis there\u00adfore desirable \nthat those operations should have a complex\u00adity proportional to the number of di.ering cells between \nboth abstract environments. We chose to implement ab\u00adstract environments using functional maps implemented \nas sharable balanced binary trees, with short-cut evaluation when computing the abstract union, abstract \nintersection, widening or narrowing of physically identical subtrees [5, \u00a76.2]. An additional bene.t \nof sharing is that it contributes to the rather light memory consumption of our analyzer. On a10,000-line \nexample wetried[5],the executiontime was divided by seven, and we are con.dent that the exe\u00adcution times \nwould have been prohibitive for the longer ex\u00adamples. The e.ciency of functional maps in the context \nof sophisticated static analyseshas alsobeen observedby[26] for representing .rst-order structures. \n6.1.3 Operations on Abstract Environments Operations on a C data structure are translated into op\u00aderations \non cells of the current abstract environments. Most translations are straightforward. Assignments: In \ngeneral, an assignment lvalue := e is translated into the assignment of the abstract value of e into \nthe abstract cell corresponding to lvalue. However, for array assignments, such as x[i]:= e, onehas to \nnote that the array index i may not be fully known, so all cells possibly corresponding to x[i] may either \nbe assigned the value of e, or keep their old value. In the analysis, these cells are assigned the upper \nbound of their old abstract value and the abstract value of e. Similarly, for a shrunk array x, after \nan assignment x[i]:= e, the cell representing x may contain eitherits old value(for array elements not \nmodi.edby the assignment), or the value of e.  Guard: The translation of concrete to abstract guards \nis notdetailedsince similar to the above case of assignments.  Abstract union, widening, narrowing: \nPerformed cell\u00adwise between abstract environments.   6.2 Arithmetic Abstract Domains The non-relational \narithmetic abstract domains abstract setsof numbers whiletherelationaldomainsabstract setsof tuples of \nnumbers. The basic abstract domains we started with[5] aretheintervals andthe clocked abstractdomain \nabstracting time. They had to be signi.cantly re.ned using octagons (Sect. 6.2.2), ellipsoids (Sect. \n6.2.3) and decision trees(Sect. 6.2.4). 6.2.1 Basic Abstract Domains The Interval Abstract Domain. The \n.rst, and simplest, implemented domain is the domain of intervals, for both integerand .oating-pointvalues[8]. \nSpecial carehastobe taken in the case of .oating-point values and operations to alwaysperform roundingin \nthe rightdirection and tohandle specialIEEE[23] values such asin.nities and NaNs(Not a Number).  The \nClocked Abstract Domain. A simple analysis using theintervalsgives alargenumber offalsewarnings. Agreat \nnumber of those warnings originate from possible over.ows in counters triggered by external events. Such \nerrors can\u00adnothappeninpractice,becausethose events are counted at most once per clock cycle, and the \nnumber of clock cycles in a single execution is bounded by the maximal continuous operating time of the \nsystem. We therefore designed a parametric abstract domain. (In our case, the parameter is the interval \ndomain [5].) Let X be an abstract domain for a single scalar variable. The elements ofthe clockeddomain \nconsistintriplesin(X )3 .  A triple(v ,v-,v)represents the set of values x such that +x . .(v ), x -clock \n. .(v-) and x + clock . .(v), where clock isaspecial,hidden variableincremented each timethe analyzed \nprogram waits for the next clock signal. + 6.2.2 The Octagon Abstract Domain Consider the following \nprogram fragment: R := X-Z; L := X; if (R>V) L := Z+V; At the end of this fragment, we have L = X. In \norder to prove this, the analyzer must discover that, when the test is true, we have R = X-Z and R > \nV, and deduce from this that Z+V < X (uptorounding). Thisispossibleonly with a relational domain able \nto capture simple linear inequalities between variables. Several such domains have been proposed, such \nas the widespread polyhedron domain [13]. In our prototype, we have chosen the recently developed octagon \nabstract domain [28, 30], which is less precise but faster than the polyhe\u00addrondomain:it can represent \nsetsof constraintsof theform \u00b1x\u00b1y = c, andits complexityis cubicin time andquadratic in space(w.r.t. \nthe number of variables),instead of expo\u00adnentialforpolyhedra. Evenwith thisreduced cost,thehuge number \nof live variables prevents us from representing sets of concrete environmentsasonebig abstract state(asit \nwas doneforpolyhedrain[13]). Therefore wepartition the set of variables into small subsets and use one \noctagon for some of these subsets(such agroup of variablesbeing then called a pack). The set ofpacksis \naparameter of the analysis which canbedetermined automatically(Sect.7.2.1). Another reason for choosing \noctagons is the lack of sup\u00adport for .oating-point arithmetics in the polyhedron do\u00admain. Designing relational \ndomains for .oating-point vari\u00adables is indeed a di.cult task, not much studied until re\u00adcently [27]. \nOn one hand, the abstract domain must be sound with respect to the concrete .oating-point semantics (handlingrounding, \nNaNs, etc.); on the otherhandit should use.oating-point numbersinternallyto manipulateabstract data for \nthe sake of e.ciency. Because invariant manipula\u00adtions in relational domains rely on some properties \nof the real .eld nottruefor .oating-points(such as x +y = c and z - y = d implies x + z = c + d), it \nis natural to consider that abstract values represent subsets of RN (in the rela\u00adtional invariant x + \ny = c, the addition + is considered in R, without rounding, over.ow, etc.). Our solution separates the \nproblem in two. First, we design a sound abstract do\u00admainforvariablesinthereal .eld(ourprototypeusesthe \noctagon library [28] which implementation is described in [29]). This is much easier for octagons than \nfor polyhedra, as most computations are simple (addition, multiplication and division by 2). Then, each \n.oating-point expression is transformed into a sound approximate real expression tak\u00ading rounding, over.ow, \netc. into account(we use thelinear forms described in Sect. 6.3) and evaluated by the abstract domain. \nComing back to our example, it may seem that octagons are not expressive enough to .nd the correct invariant \nas Z + V < X is not representable in an octagon. However, our assignment transfer function is smart enough \nto extract from the environment theinterval[c,d]where V ranges(with d = RM where RM is an upper bound \nof R already computed by the analysis) and synthesize the invariant c = L-Z = d, which is su.cient to \nprove that subsequent operations on L will not over.ow. Thus, there was no need for this family of programs \nto use a more expressive and costly relational domain. Remark that this approach provides a generic way \nof implementing relational abstract domains on .oating-point numbers. It is parametrized by: a strategy \nforthedetermination ofpacks(Sect.7.2.1);  anunderlying abstractdomainworkinginthereal .eld. Aspects \nspeci.c to .oating-point computation (such as rounding and illegal operations) are automatically taken \ncare of by our approach.  6.2.3 The Ellipsoid Abstract Domain To achieve the necessary precision, several \nnew abstract domains had to be designed. We illustrate the general ap\u00adproach on the case of the ellipsoid \nabstract domain. By inspection of the parts of the program on which the previously described analyses \nprovide no information at all on the values of some program variables, we identi.ed code of the form: \nif (B){ Y := i; X := j; }else { X' := aX - bY + t; Y := X; X := X'; } where a and b are .oating-point \nconstants, i, j and t are .oating-point expressions, B is a boolean expression, and X, X' , and Y are \nprogram variables. The previously described analysesyieldtheimprecise result that X and Y may take any \nvalue. This apparently specialized style of code is indeed quite frequent in control systems since it \nimplements the simpli.ed second order digital .ltering discrete-time system illustrated in Fig. 1. The \n.rst branch is a reinitialization step, the second branch consists in an a.ne transformation F. Since \nthis code is repeated inside loops, the analysis has to .nd an invariant preserved by this code. We looked \nmanually for such an invariant on typical examples, identi.ed the above Figure 1: A simpli.ed second-order \ndigital .ltering system. generic form (essentially depending on a and b), then de\u00adsigned a generic abstract \ndomain ea,b able to discover such invariants, implemented the abstract domain lattice and transferoperationsand.nallylettheanalyzerautomatically \ninstantiatethe speci.c analysistothe code(inparticularto parts that may not have been inspected). To \n.nd an interval that contains the values of X and Y in the speci.c case where we can compute bounds to \nthe expression t by the previously described analyses, say |t|= tM, we have designed a new abstract domain \nea,b based on ellipsoids, that can capture the required invariant. More precisely, we can show that: \nProposition 1 If 0 <b< 1, a 2 - 4b< 0, and k = 2 tM aXY + bY2 = k is pre\u00ad v , then the constraint X2 \n- 1- b served by the a.ne transformation F. The proof of this proposition follows by algebraic manip\u00adulations \nusing standard linear algebra techniques. In our examples, the conditions on a and b required in Prop. \n1 are satis.ed. We still have to design the abstract operations to propagate the invariant in the program, \nand to take into account rounding errors that occur in .oating-point compu\u00adtations(and are not modeledinthe \naboveproposition). Having.xed two .oating-point numbers a and b such that 0 <b< 1 and a 2 - 4b< 0, we \npresent a domain ea,b, for describing sets of ellipsoidal constraints. An element in ea,b is a function \nr which maps a pair of variables (X,Y)to a .oating-point number r(X, Y) such that X2 - aXY + bY2 = r(X, \nY). Webrie.ydescribe someprimitives and transferfunctions of our domain: Assignments. Let r . ea,b be \nthe abstract element de\u00adscribing some constraints before a statement X := e, our goal is to compute the \nabstract element r ' describing a set of constraints satis.ed after this statement: 1. in case e is a \nvariable Y, each constraint containing Y gives a constraint for X. Formally, we take r ' such that r \n'(U,V)= r(sU,sV) where s is the substitution of the variable Y for the variable X; 2. in case e is an \nexpression of the form aY+bZ+t, we .rst remove any constraint containing X, then we add a new constraint \nfor X and Y. We therefore take:  r ' = r[(X, ) . +8][(,X) . +8][(X,Y) . d(r(Y,Z))]. We have used the \nfunction d de.ned as follows: v !2 v|a| b+ b!!v d(k)= b+4fv k +(1+f)tM 2 4b-a where f is the greatest \nrelative error of a .oat with re\u00adspect to a real and t . [-tM,tM]. Indeed, we can show that, if Y2 -aYZ \n+ bZ2 = k and X = aY -bZ + t, then in v exact real arithmetic X2 -aXY+bY2 = ( bk+tM)2, and taking into \naccount rounding errors, we get the above formula for d(k); 3. otherwise, we remove all constraints containing \nX by tak\u00ad ' ing r= r[(X, ) . +8][(,X) . +8]3 . ' Guards are ignored, i.e., r= r.  Abstract union, intersection, \nwidening and narrowing are computed component-wise. The widening uses thresh\u00adolds as described in Sect. \n7.1.2.  The abstract domain ea,b cannot compute accurate re\u00adsultsby itself, mainly because ofinaccurate \nassignments(in case 3.) and guards. Hence we use an approximate reduced product with the interval domain. \nA reduction step con\u00adsists in substituting in the function r the image of a couple (X,Y)bythe smallestelement \namong r(X,Y)andthe .oating\u00adpoint number k such that k is the least upper bound to the evaluation of the \nexpression X2 -aXY + bY2 in the .oating\u00adpoint numbers when considering the computed interval con\u00adstraints. \nIn case the values ofthe variable X and Y areproved tobe equal, we canbe much moreprecise and take the \nsmall\u00adest element among r(X, Y)and the least upper bound to the evaluation ofthe expression(1 -a + b)X2 \n. These reduction steps are performed: before computing the union between two abstract ele\u00adments r1 \nand r2, we reduce each constraint ri(X,Y)such that ri(X,Y)= +8 (wherei .{1;2}); +8 and r3-i(X, Y)= \n before computing the widening between two abstract elements r1 and r2, we reduce each constraint r2(X, \nY)such that r2(X, Y)=+8 and r1(X,Y) +8; =  before an assignment of the form X' := aX -bY + t, we re.ne \nthe constraints r(X, Y). These reduction steps are especially useful in handling a reinitialization iteration. \n Ellipsoidal constraints are then used to reduce the in\u00adtervals of variables: after each assignment \nA of the form v X' := aX -bY + t, we use the fact that |X'|= 2 bqr/(X/,X2 ) , 4b-a' where ris the abstractelementdescribing \na set of ellipsoidal constraintsjust afterthe assignment A. This approach is generic and has been applied \nto handle the digital .lters in the program. 6.2.4 The Decision Tree Abstract Domain Apart from numerical \nvariables, the code uses also a great deal of boolean values, and no classical numerical do\u00admain deals \nprecisely enough with booleans. In particular, booleans can be used in the control .ow and we need to \nre\u00adlate the value of the booleans to some numerical variables. Here is an example: B := (X=0); if (\u00ac \nB) Y := 1/X; We found also more complex examples where a numeri\u00adcal variable could depend on whether \na boolean value had 3 This is also the case for initialization. changed or not. In order to deal precisely \nwith those exam\u00adples, we implemented a simple relational domain consisting in a decision tree with leaf \nan arithmetic abstract domain4 . Thedecision trees are reducedby orderingboolean variables (asin[6])andbyperforming \nsome opportunistic sharing of subtrees. The only problem with this approach is that the size of decision \ntrees can be exponential in the number of boolean variables, and the code contains thousands of global \nones. So we extracted a set of variable packs, and related the variables in the packs only, as explained \nin Sect. 7.2.3.  6.3 Symbolic Manipulation of Expressions We observed, in particular for non-relational \nabstract do\u00admains, that transfer functions proceeding by structural in\u00adduction on expressions are not \nprecise when the variables in the expression are not independent. Consider, for in\u00adstance, the simple \nassignment X := X-0.2* X performed in the interval domain in the environment X . [0,1]. Bottom\u00adup evaluation \nwill give X - 0.2 * X . [0,1] - 0.2 * [0, 1] . [0, 1] - [0,0.2] . [-0.2,1]. However, because the same \nX is used on both sides of the - operator, the precise result should have been[0, 0.8]. In order to solve \nthis problem, we perform some simple algebraic simpli.cations on expressions before feeding them to the \nabstract domain. Our approach is to linearize each expression e, that is to say, transform it into a \nlinear form e[e] on the set of variables v1,...,vN with interval coe.\u00adcients: e[e]= PNi=1 [ai,\u00dfi]vi+[a,\u00df]. \nThelinearform e[e]is computed by recurrence on the structure of e. Linear oper\u00adatorsonlinearforms(addition, \nsubtraction, multiplication anddivisionby a constantinterval) are straightforward. For instance, e[X-0.2* \nX]=0.8* X, which will be evaluated to [0, 0.8] intheintervaldomain. Non-linear operators(multi\u00adplication \nof two linear forms, division by a linear form, non\u00adarithmetic operators) are dealt by evaluating one \nor both linear form argument into an interval. Although the above symbolic manipulation is correct in \nthe real .eld, it does not match the semantics of C expres\u00adsions for two reasons: .oating-point computations \nincur rounding;  errors(divisionby zero,over.ow,etc.) may occur.  Thankfully,the systems weconsider \nconformtotheIEEE 754 norm [23] that describes rounding very well (so that, e.g., the compiler shouldbepreventfrom \nusing the multiply\u00adadd-fused instruction on machines for which the result of a multiply-add computation \nmaybeslightlydi.erentfromthe .oating point operation operation A+(B\u00d7C)for some in\u00adput values A, B, C). \nThus,itiseasy to modify therecursive construction of linear forms from expressions to add the er\u00adror \ncontribution for each operator. It can be an absolute error interval, or a relative error expressed as \na linear form. We have chosen the absolute error which is more easily im\u00adplemented and turned out to \nbe precise enough. To address the second problem, we .rst evaluate the ex\u00adpression in the abstract interval \ndomain and proceed with thelinearization to re.ne the result onlyif nopossible arith\u00admetic error was \nreported. We are then guaranteed that the simpli.ed linear form has the same semantics as the initial \nexpression. 4The arithmeticabstractdomainisgeneric. Inpractice,the interval domain was su.cient.  7. \nADAPTATION VIA PARAMETRIZA-TION In order to adapt the analyzer to a particular program of the considered \nfamily, it may be necessary to provide in\u00adformation to help the analysis. A classical idea is to have \nusersprovide assertions(which canbeproved tobeinvari\u00adants and therefore ultimately suppressed). Another \nidea is to useparametrized abstractdomainsinthe staticprogram analyzer. Then the static analysis can \nbe adapted to a par\u00adticularprogramby an appropriate choice of theparameters. We provide several examples \nin this section. Moreover we show how the analyzer itself can be used in order to help or even automatizethe \nappropriatechoiceof theseparameters. 7.1 Parametrized Iteration Strategies 7.1.1 Loop Unrolling In many \ncases, the analysis of loops is made more precise by treating the .rst iteration of the loop separately \nfrom the following ones; this is simply a semantic loop unrolling transformation: a while loop may be \nexpanded as follows: if (condition){body; while (condition){body }} The above transformation canbeiteratedn \ntimes, where the concerned loops and the unrolling factor n are user-de.ned parameters. In general, the \nlarger the n, the more precise the analysis, and the longer the analysis time. 7.1.2 Widening with Thresholds \nCompared to normal interval analysis [10, \u00a72.1.2], ours does not jump straight away to \u00b18, but goes through \na number of thresholds. The widening with thresholds T for the interval analysis of Sect. 6.2.1 is parametrized \nby a threshold set T that is a .nite set of numbers containing -8 and +8 and de.ned such that: ' [a,b]T \n[a ' ,b ' ]=[if a <a then max{e . T |e = a ' }else a, b ' if b ' >b then min{h . T |h =}else b] In order \nto illustrate the bene.ts of this parametrization (see othersin[5]),letx0 be the initial value of a variable \nX subject to assignments of the form X := ai * X + \u00dfi, i . . in the main loop, where the ai, \u00dfi, i . \n. are .oating point constants such that 0 = ai < 1. Let be any M such that M = max{|x0|, |\u00dfi| ,i . .}. \nWe have M =|x0|and 1-ai M = aiM + |\u00dfi|and so all possible sequences x 0 = x0, n+1 n x = aix +\u00dfi, i . \n. of values of variable X are bounded since .n = 0: |x n|= M. Discovering M may be di.cult in particular \nif the constants ai, \u00dfi, i . . depend on complex boolean conditions. As long as the set T of thresholds \ncon\u00adtains some numbergreater or equal tothe minimum M, the interval analysis of X with thresholds T will \nprove that the value of X is bounded at run-time since some element of T will be an admissible M. In \npractice we have chosen T to be (\u00b1a.k)0=k=N. The choice of a and . mostly did not matter much in the \n.rst experiments. After the analysis had been well re.ned and many causes of imprecision removed, we \nhad to choose a smaller value for . to remove some false alarms. In any case, a.N should be large enough; \notherwise, many false alarms for over.ow are produced. 7.1.3 Delayed Widening When widening the previous \niterate by the result of the transfer function on that iterate at each step as in Sect. 5.5, some values \nwhich can become stable after two steps of widening may not stabilize. Consider the example: X := Y + \n.; Y := a * X + d This should be equivalent to Y := a * Y + \u00df (with \u00df = d + a.), and so a widening with \nthresholds should .nd a stable interval. But if we perform a widening with thresh\u00adolds at each step, \neach time we widen Y, X is increased to a value surpassing the threshold for Y, and so X is widened to \nthe next stage, which in turn increases Y further and the next widening stageincreases the value of Y.This \neventually results in top abstract values for X and Y. In practice, we .rst do N0 iterations with unions \non all abstract domains, then we do widenings unless a variable which was not stable becomes stable (this \nis the case of Y here when the threshold is big enough as described in Sect.7.1.2). We addafairness condition \nto avoidlivelocksin cases for each iteration there exists a variable that becomes stable. 7.1.4 Floating \nIteration Perturbation The stabilization check for loops considered in Sect. 5.4 has to be adjusted because \nof the .oating point computa\u00adtionsinthe abstract. Let us considerthat[a,b]is the math\u00adematical interval \nof values of a variable X on entry of a loop. We let FC,A([a,b])be the mathematical interval of values \nof X after a loop iteration. C = R means that the concrete operationsintheloop areconsidered tobeon mathematical \nreal numbers while C = F means that the concrete opera\u00adtions in the loop are considered to be on machine \n.oating point numbers. If FR,A([a,b]) =[a ' ,b ' ] then FF,A([a,b]) = [a ' - .1,b ' + .1] because of \nthe cumulated concrete round\u00ading errors .1 = 0 when evaluating the loop body5 . The same way A = R means \nthat the interval abstract domain is de.ned ideally using mathematical real numbers while A = F means \nthat the interval abstract domain is imple\u00admented with .oating point operations performing rounding in \nthe right direction. Again, if FC,R([a,b]) =[a ' ,b ' ] then FC,F([a,b])=[a ' -.2,b ' + .2]because of \nthe cumulated ab\u00adstract rounding errors during the static analysis of the loop body. The analyzer might \nuse FF,F which is sound since if FR,R([a,b])=[a ' ,b ' ]thenFF,F([a,b])=[a ' -.1-.2,b ' +.1+.2] which \ntakes both the concrete and abstract rounding errors into account(respectively .1 and .2). Mathematically, \na loop invariant for variable X is an in\u00adterval[a,b]such that FF,R([a,b]). [a,b]. However, the loop stabilization \ncheck is made as FF,F([a,b]) . [a,b], which is sound but incomplete: if FF,R([a,b]) is very close to \n[a,b], e.g. FF,R([a,b]) =[a,b] then, unfortunately, FF,F([a,b]) = [a - .2,b + .2] * [a,b]. This will \nlaunch useless additional iterations whence a loss of time and precision. The solution we have chosen \nis to overapproximate FF,F by FbF,F such that FbF,F([a,b])=[a ' -.*|a ' |,b ' +.*|b ' |]where [a ' ,b \n' ]= FF,F([a,b])and . is aparameter of the analyzer cho\u00adsen to be an upper bound of the possible abstract \nrounding errors in the program loops. Then the loop invariant inter\u00ad 5 We take the rounding error on \nthe lower and upper bound to be the same for simplicity. val is computed iteratively with FbF,F, which \nis simply less precise than with FF,F, but sound. The loop stabilization test is performed with FF,F \nwhich is sound. It is also more precisein case.*(min{|a ' |;|b ' |})isgreater than the absolute error \non the computation of FF,F([a ' -. *|a ' |,b ' + .*|b ' |]). We have not investigated about the existence \n(nor about theautomaticcomputation) of such aparameterinthegen\u00aderal case yet, nevertheless attractiveness \nof the encountered .xpoints made the chosen parameter convenient. 7.1.5 Trace Partitioning In the abstract \nexecution of the program, when a test is met, both branches are executed and then the abstract environments \ncomputed by each branch are merged. As de\u00adscribedin[5] we canget a moreprecise analysisby delaying this \nmerging. This means that: if (c){S1 }else {S2 }rest is analyzed as if it were if (c){S1; rest }else {S2; \nrest }. Asimilar techniqueholdsfor the unrollediterations ofloops. As this process is quite costly, the \nanalyzer performs this trace partitioning in a few end-user selected functions, and the traces are merged \nat the return point of the function. Informally, in our case, the functions that need partitioning are \nthose iterating simultaneously over arrays a[] and b[] such that a[i] and b[i] are linked by an important \nnumer\u00adical constraint which does not hold in general for a[i] and b[j] where i = j. This solution was \nsimpler than adding complex invariants to the abstract domain.  7.2 Parametrized Abstract Domains Recallthatour \nrelationaldomains(octagons ofSect.6.2.2, and decision trees of Sect. 6.2.4) operate on small packs of \nvariables for e.ciency reasons. This packing is determined syntactically before the analysis. The packing \nstrategy is a parameter of the analysis; it gives a trade-o. between accu\u00adracy(more,biggerpacks) and \nspeed(fewer, smallerpacks). The strategymust alsobe adapted to thefamily ofprograms to be analyzed. 7.2.1 \nPacking for Octagons We determine a set of packs of variables and use one oc\u00adtagon for each pack. Packs \nare determined once and for all, before the analysis starts, by examining variables that interact in \nlinear assignments within small syntactic blocks (curly-brace delimited blocks). One variable may appear \nin severalpacks and we coulddo someinformationpropagation (i.e.reduction [9])between octagons at analysis \ntime, using common variables aspivots;however, thisprecisiongain was not needed in our experiments. There \nis a great number of packs,buteachpackis small;itis ourguess that ourpacking strategy constructs, for \nour program family, a linear num\u00adber of constant-sized octagons, e.ectively resulting in a cost linear \nin the size of the program. Moreover, the octagon packs are e.ciently manipulated using functional maps, \nas explained in Sect. 6.1.2, to achieve sub-linear time costs via sharing of unmodi.ed octagons. Our \ncurrent strategy is to create one pack for each syn\u00adtactic block in the source code and put in the pack \nall vari\u00adables that appear in a linear assignment or test within the associated block, ignoring what \nhappens in sub-blocks of the block. For example, on a program of 75 kLOC, 2,600 octagons were detected, \neach containing four variables on average. Largerpacks(resultinginincreased costandpre\u00adcision) could \nbe created by considering variables appearing in one or more levels of nested blocks; however, we found \nthat, in our program family, it does not improve precision. 7.2.2 Packing Optimization for Octagons \nOur analyzer outputs, as part of the result, whether each octagon actually improved the precision of \nthe analysis. It is then possible to re-run the analysis using only packs that were proven useful, thus \ngreatly reducing the cost of the analysis. (In our 75 kLOC example, only 400 out of the 2,600 original \noctagons were in fact useful.) Even when the program or the analysis parameters are modi.ed, it is per\u00adfectly \nsafe to use a list of useful packs output by a previous analysis. We experimented successfully with the \nfollowing method: generate at night an up-to-date list of good oc\u00adtagons by a full, lengthy analysis \nand work the following day using this list to cut analysis costs. 7.2.3 Packing for Decision Trees In \norder to determine useful packs for the decision trees of Sect. 6.2.4, we used the following strategy: \neach time a numerical variable assignment depends on a boolean, or a boolean assignmentdepends on a numerical \nvariable, weput both variables in a tentative pack. If, later, we .nd a pro\u00adgram point where the numerical \nvariable is inside a branch depending on the boolean, we mark the pack as con.rmed. In order to deal \nwith complex boolean dependences, if we .nd an assignment b := expr where expr is a boolean ex\u00adpression, \nwe add b to allpacks containing avariablein expr. Inthe end, wejustkeep the con.rmedpacks. At .rst, we \nrestrained the boolean expressions used to ex\u00adtend thepacksto simpleboolean variables(wejust consid\u00adered \nb := b )and thepackscontained at mostfourboolean variables and dozens of false alarms were removed. But \nwe discovered that morefalse alarms couldbe removedif we ex\u00adtended those assignments to more general \nexpressions. The problem was thatpacks could then contain up to36boolean variables, which gave very bad \nperformance. So we added a parameter to restrict arbitrarily the number of boolean variables in a pack. \nSetting this parameter to three yields an e.cient and precise analysis of boolean behavior.  8. EXPERIMENTAL \nRESULTS The main program we are interested in is 132,000 lines of C with macros(75kLOC afterpreprocessing \nand simpli.\u00adcation as in Sect. 5.1) and has about 10,000 global/static variables(over21,000 after array \nexpansion asinSect.6.1). Wehad1,200false alarms with the analyzer[5] we started with. The re.nements \nof the analyzer described in this pa\u00adper reduce the number of alarms down to 11 (and even 3, depending \non the versions of the analyzed program). Fig. 2 gives the total analysis timefor afamily of relatedprograms \non commodity hardware(2.4GHz,1GbRAMPC), using a slow but precise iteration strategy. The memory consumption \nof the analyzer is reasonable (550Mbfor thefull-sizedprogram). Severalparameters, for instance the size \nof the octagonpacks(Sect. 7.2.1), allowfor a space-precision trade-o.. The packing optimization strategy \nof reusing results from preceding analysis to reduce the number of octagons time (s) 8000 7000 6000 5000 \n4000 3000 2000 1000 0 0 1020304050607080 kLOC Figure 2: Total analysis time for the family of pro\u00adgrams \nwithout packing optimization(Sect.7.2.2). (Sect. 7.2.2) reduces, on the largest example code, mem\u00adory \nconsumption from 550 Mb to 150 Mb and time from 1h40minto40min. Furthermore,thecurrentautomatic tuning \nof the iteration strategy may be made more e.cient, using fewer iterations and thus reducing analysis \ntime. 9. RELATED WORK Let us discuss some other veri.cation methods that could have been considered. \nDynamic checking methods were ex\u00adcludedfor a safety critical system(atbestdata canbe col\u00adlected at runtime \nand checked o.ine). Static methods re\u00adquiring compiler or codeinstrumentation(such as[15]) were also \nexcluded in our experiment since the certi.ed compiler as well as the compiled code, once certi.ed by \ntraditional methods, cannot be modi.ed without costly re-certi.cation processes. Therefore we only consider \nthe automated static proof of software run-time properties, which has been a re\u00adcurrent research subject \nsince a few decades. 9.1 Software Model Checking Software model checking [22] has proved very useful \nto trace logical design errors, which in our case has already been performed at earlier stages of the \nsoftware develop\u00adment, whereas we concentrate on abstruse machine imple\u00admentation aspects of the software. \nBuilding afaithful model of theprogram(e.g.in PromelaforSpin [22])wouldbejust toohard(it can take signi.cantly \nmore timeto write a model thanitdid to write the code) and error-prone(by checking a manual abstraction \nof the code rather than the codeitself,it is easy to miss errors). Moreover the abstract model would \nhave to be designed with a .nite state space small enough tobefully explored(in the context of veri.cation, \nnotjust debugging), which is very di.cult in our case since sharp dataproperties mustbetakeninto account. \nSoit seemsim\u00adportanttohavethe abstract model automaticallygenerated by the veri.cation process, which \nis the case of the abstract semantics in static analyzers. 9.2 Data.ow Analysis and Software Abstract \nModel Checking Data.ow analyzers(such asESP[14]) as well as abstrac\u00adtionbased softwaremodel checkers(such \nasa.o. Blast [21], CMC[31] and Slam [4])have madelargeinroadsin tackling programs of comparable size \nand complexity. Their impres\u00adsive performance is obtained thanks to coarse abstractions (e.g. resulting \nfrom a program shrinking preprocessing phase[14,1]or obtainedby aglobally coarsebutlocallypre\u00adcise abstraction[31]). \nIn certain cases, the abstract model is just a .nite automaton, whose transitions are triggered by certain \nconstructionsinthe source code[15];this allow checking at the source code level high-level properties, \nsuch as allocated blocks of memory are freed only once or in\u00adterrupts are always unmasked afterbeingblocked \n, ignoring dependencies on data. The bene.t of this coarse abstraction is that only a small part of the \nprogram control and/or data have to be consid\u00adered in the actual veri.cation process. This idea did not \nwork out in our experiment since merging paths or data in\u00adevitablyleads to manyfalse alarms. On the contrary \nwehad to resort to context-sensitivepolyvariant analyses(Sect.5.4) withloop unrolling(Sect.7.1.1) sothat \nthe size of the(se\u00admantically) expanded codetoanalyzeismuchlargerthan that of the original code. Furthermore, \nthe properties we proveinclude .nenumericalconstraints,which excludessim\u00adple abstract models. 9.3 Deductive \nMethods Proof assistants(such as Coq [33],ESC[17]orPVS[32]) facesemanticproblems whendealing with real-lifeprogram\u00adming \nlanguages. First, the prover has to take the machine\u00adlevel semanticsintoaccount(e.g., .oating-pointarithmetic \nwith rounding errors as opposed to real numbers, which is far from being routinely available 6). Obviously, \nany tech\u00adnique for analyzing machine arithmetic will face the same semantic problems. However, if the \ntask of taking concrete and rounding errors into account turned out to be feasible for our automated \nanalyzer, this task is likely to be daunt\u00ading in the case of complex decision procedures operating on \nideal arithmetic[32]. Furthermore, exposing tothe userthe complexitybroughtby thoseerrorsislikely to \nmakeassisted manual proof harrowing. A second semantic di.culty is that the prover needs to operate on \nthe C source code, not on some model written in a prototyping language so that the concrete program se\u00admantics \nmustbeincorporatedintheprover(atleastinthe veri.cation condition generator). Theoretically, it is possi\u00adble \nto do a deep embedding of the analyzed program into thelogicof theproof assistant thatis,providing a \nmathe\u00admatical object describing the syntactic structure of the pro\u00adgram as well as a formal semantics \nof the programming lan\u00adguage. Proving any interesting property is then likely to be extremely di.cult. \nShallow embeddings mapping the originalprogramtoacorresponding program intheinput syntax of the prover \n are easier to deal with, but may be di.cult to produce in the presence of nondeterministic inputs, .oating-point \nrounding errors etc. . . The last and main di.culty with proof assistants is that they mustbe assisted,inparticulartohelpproviding \ninduc\u00adtive arguments (e.g. invariants). Of course these provers could integrate abstract domains in the \nform of abstrac\u00adtionprocedures(toperform online abstractions of arbitrary predicates into their abstract \nform) as well as decision pro\u00adcedures(e.g.tocheckforabstractinclusion ). The main problem is to have \nthe user provide program independent 6For example ESC is simply unsound with respect to mod\u00adular arithmetics[17]. \nhints, specifying when and where these abstraction and de\u00adcisionprocedures mustbe applied, as well ashowtheinduc\u00adtive \narguments can be discovered, e.g. by iterative .xpoint approximation, without ultimately amounting to \nthe imple\u00admentation of a static program analysis. Additionally, our analyzer is designed to run on a \nwhole family of software, requiring minimal adaptation to each individual program. In most proof assistants, \nit is di.cult to change the program without having to do a considerable amount of work to adapt proofs. \n 9.4 Predicate Abstraction Predicate abstraction, which consists in specifying an ab\u00adstraction by providing \nthe atomic elements of the abstract domaininlogicalform[19] e.g. by representing sets of states asbooleanformulasover \na set ofbasepredicates, would cer\u00adtainly have been the best candidate. Moreover most imple\u00admentations \nincorporate an automatic re.nement process by success and failure [2, 21] whereas we successively re.ned \nour abstract domains manually, by experimentation. In ad\u00addition to the semantic problems shared by proof \nassistants, a number of di.culties seem to be insurmountable to auto\u00admate this design process in the \npresent state of the art of deductive methods: 9.4.1 State Explosion Problem: To get an idea of the size \nof the necessary state space, wehavedumped themainloop invariant(atextual .leover 4.5 Mb). The main loop \ninvariant includes 6,900 boolean interval assertions(x . [0,1]),9,600interval assertions(x . [a,b]), \n25,400 clock assertions(Sect.6.2.1),19,100 additive octago\u00adnal assertions(a = x +y = b), 19,200subtractive \noctagonal assertions(a = x-y = b, see Sect. 6.2.2), 100 decision trees (Sect.6.2.4)and1,900 ellipsoidal \nassertions(Sect.6.2.3)7 . In order to allow for the reuse of boolean model check\u00aders, the conjunction \nof true atomic predicates is usually en\u00adcoded as a boolean vector over boolean variables associated to \neachpredicate[19](thedisjunctive completion[9] of this abstractdomaincanalsobe usedtoget moreprecision[2, \n21], but this would introduce an extra exponential factor). Model checking stategraphs corresponding \nto several tenths of thousands ofboolean variables(not counting hundreds of thousands ofprogrampoints) \nis still a real challenge. More\u00adover very simple static program analyzes, such as Kildall s constant \npropagation [24], involve an in.nite abstract do\u00admain which cannot be encoded using .nite boolean vectors \nthus requiring the user to provide beforehand all predicates that willbeindispensabletothe staticanalysis(forexam\u00adple \nthe above mentioned loop invariant involves, e.g., over 16,000 .oatingpointconstantsatmost550 of themappear\u00ading \nin the program text). Obviously some of the atomic predicates automatically generated by our analysis \nmight be super.uous. On one handitishard tosay which ones and ontheotherhand this does not count all \nother predicates that may be indispens\u00adable at some program point to be locally precise. Another approach \nwould consist in trying to verify each potential 7Figures are rounded to the closest hundred. We get \nmore assertions than variables because in the 10,000 global vari\u00adables arrays are counted once whereas \nthe element-wise ab\u00adstraction yields assertions on each array element. Boolean assertions are needed \nsince booleans are integers in C. faulty operation separately (e.g., focus on one instruction that may \nover.ow at a time) and generate the abstractions lazily[21]. Eventhough repeating thisanalysisover100,000 \ntimes might be tractable, the real di.culty is to automat\u00adically re.ne the abstract predicates (e.g. \nto discover that considered in Prop. 1). 9.4.2 Predicate Re.nement: Predicate abstraction per se uses \na .nite domain and is therefore provably less powerful than our use of in.nite ab\u00adstractdomains(see[12], \ntheintuitionis that allinductive as\u00adsertionshavetobeprovided manually). Thereforepredicate abstraction \nis often accompanied by a re.nement process to cope withfalse alarms[2,21]. Under speci.c conditions, \nthis re.nement can be proved equivalent to the use of an in.nite abstract domain with widening[3]. Formally \nthisre.nementisa .xpointcomputation[7,18] at the concrete semantics level, whence introduces new el\u00adements \nin the abstract domain state by state without ter\u00admination guarantee whereas, e.g., when introducing \nclocks from intervals or ellipsoids from octagons we exactly look for an opposite more synthetic point \nof view. Therefore the main di.culty of counterexample-based re.nement is still to automate the presently \npurely intellectual process of de\u00adsigning precise and e.cient abstract domains.    10. CONCLUSION \nInthisexperiment, wehad tocope with stringent require\u00adments. Industrial constraints prevented us from \nrequiring any change in the production chain of the code. For in\u00adstance, it was impossible to suggest \nchanges to the library functions that would o.er the same functionality but would make the code easier \nto analyze. Furthermore, the code was mostly automatically generated from a high-level spec\u00adi.cation \nthat we could not have access to, following rules of separation of design and veri.cation meant to prevent \nthe intrusion of unproved high-level assumptions into the veri.\u00adcation assumptions. It was therefore \nimpossible to analyze the high-level speci.cation instead of analyzing the C code. That the code was \nautomatically generated had contrary e.ects. On the one hand, the code .t into some narrow subclass of \nthe whole C language. On the other hand, it used some idioms not commonly found in human-generated codethat \nmay maketheanalysis moredi.cult; forinstance, where a human would have written a single test with a booleanconnective,thegeneratedcodewould \nmakeonetest, store the result into a boolean variable, do something else do the second test and then \nretrieve the result of the .rst test. Also, the code maintains a considerable number of state variables, \na large number of these with local scope but unlimited lifetime. The interactions between several com\u00adponents \nare rather complex since the considered program implement complex feedback loops across many interacting \ncomponents. Despite those di.culties, we developed an analyzer with a very high precision rate, yet operating \nwith reasonable computational power and time. Our main e.ort was to discover an appropriate abstraction \nwhich we did by man\u00adual re.nement through experimentation of an existing ana\u00adlyzer[5] and canbelater \nadaptedby end-userstoparticular programs through parametrization (Sect. 6.3 and 7). To achieve this, \nwe had to develop two specialized abstract do\u00admains(Sect.6.2.3 and6.2.4) andimprove an existingdomain \n(Sect. 6.2.2). The centralideain this approachis that once the analyzer has been developed by specialists, \nend-users can adapt it to otherprogramsinthefamily without much e.orts. However coming up with a tool \nthat is e.ective in the hands of end users with minimal expertise in program analysis is hard. Thisis \nwhy wehaveleft to the user the simplerparametriza\u00adtions only(such as widening thresholdsinSect.7.1.2 \neasily found in the program documentation) and automated the more complex ones(such asparametrizedpackingSect.7.2). \nTherefore, the approach should be economically viable. 11. REFERENCES [1] S. Adams, T. Ball, M. Das, \nS. Lerner, K. Rajamani, M. Seigle, , and W. Weimer. Speeding up data.ow analysis using .ow-insensitive \npointer analysis. SAS (2002), LNCS 2477, Springer, 117 132. [2] T. Ball, R. Majumdar, T. Millstein, and \nS. Rajamani. Automatic predicate abstraction of C programs. PLDI. ACM SIGPLAN Not. 36(5)(2001), 203 213. \n[3] T. Ball, A. Podelski, and S. Rajamani. Relative completeness of abstraction re.nement for software \nmodel checking. TACAS(2002), LNCS 2280, Springer, 158 172. [4] T. Ball and S. Rajamani. The SLAM project: \ndebugging system software via static analysis. 29th ACM POPL(2002), 1 3. [5] B. Blanchet, P. Cousot, \nR. Cousot, J. Feret, L. Mauborgne, A. Min\u00b4e, D. Monniaux, and X. Rival. Design and implementation of \na special-purpose static program analyzer for safety-critical real-time embedded software. The Essence \nof Computation: Complexity, Analysis, Transformation.(2002), LNCS 2566, Springer, 85 108. [6] R. Bryant. \nGraph based algorithms for boolean function manipulation. IEEE Trans. Comput. C-35 (1986), 677 691. \n[7] P. Cousot. Partial completeness of abstract .xpoint checking. SARA(2000), LNAI 1864, Springer, 1 \n25. [8] P. Cousot and R. Cousot. Abstract interpretation: a uni.ed lattice model for static analysis \nof programs by construction or approximation of .xpoints. 4th ACM POPL(1977), 238 252. [9] P. Cousot \nand R. Cousot. Systematic design of program analysis frameworks. 6th ACM POPL(1979), 269 282. [10] P. \nCousot and R. Cousot. Abstract interpretation and application to logic programs. J. of Logic Prog. 2 \n3, 13(1992), 103 179. [11] P. Cousot and R. Cousot. Abstract interpretation frameworks. J. Logic and \nComp. 2, 4(1992), 511 547. [12] P. Cousot and R. Cousot. Comparing the Galois connection and widening/narrowing \napproaches to abstract interpretation. PLILP(1992), LNCS 631, Springer, 269 295. [13] P. Cousot and N. \nHalbwachs. Automatic discovery of linear restraints among variables of a program. 5th ACM POPL(1978), \n84 97. [14] M. Das, S. Lerner, and M. Seigle. ESP: Path-sensitive program veri.cation in polynomial time. \n29th ACM PLDI(2002), 58 70. [15] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking system rules using \nsystem-speci.c, programmer-written compiler extensions. Usenix Association, OSDI 2000, 1 16. [16] C. \nFerdinand, R. Heckmann, M. Langenbach, F. Martin, M. Schmidt, H. Theiling, S. Thesing, and R. Wilhelm. \nReliable and precise WCET determination for a real-life processor. ESOP(2001), LNCS 2211, Springer, 469 \n485. [17] C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson, J. Saxe, and R. Stata. Extended static \nchecking for Java. PLDI. ACM SIGPLAN Not. 37(5) (2002), 234 245. [18] R.Giacobazzi andE.Quintarelli.Incompleteness, \ncounterexamples and re.nements in abstract model-checking. SAS(2001), LNCS 126, Springer, 356 373. [19] \nS. Graf and H. Sa\u00a8idi. Construction of abstract state graphs with PVS. CAV(1997), LNCS 1254, Springer, \n72 83. [20] N. Halbwachs, P. Caspi, P. Raymond, and D. Pilaud. The synchronous data.ow programming language \nLustre. Proc. of the IEEE 79, 9(1991), 1305 1320. [21] T. Henzinger, R. Jhala, R. Majumdar, and G. Sutre. \nLazy abstraction. 29th ACM POPL(2002), 58 70. [22] G. Holzmann. The model checker Spin. IEEE Trans. Softw. \nEng. 23, 5(1997), 279 295. [23] IEEE Computer Society. IEEE standard for binary .oating-point arithmetic. \nTech. rep., ANSI/IEEE Std 745-1985, 1985. [24] G. Kildall. A uni.ed approach to global program optimization. \n1st ACM POPL(1973.), 194 206. [25] X. Leroy, D. Doligez, J. Garrigue, D. R\u00b4emy, and J. Vouillon. The \nObjective Caml system, documentationand user s manual(release3.06).Tech. rep., INRIA, Rocquencourt, France, \n2002. [26] R. Manevich, G. Ramalingam, J. Field, D. Goyal, and M. Sagiv. Compactly representing .rst-order \nstructures for static analysis. SAS(2002), LNCS 2477, Springer, 196 212. [27] M. Martel. Static analysis \nof the numerical stability of loops. SAS(2002), LNCS 2477, Springer, 133 150. [28] A. Min\u00b4e. The octagon \nabstract domain library. http://www.di.ens.fr/~mine/oct/. [29] A. Min\u00b4e. A new numerical abstract domain \nbased on di.erence-bound matrices. PADO(2001), LNCS 2053, Springer, 155 172. [30] A. Min\u00b4e. The octagon \nabstract domain. IEEE AST in WCRE(2001), 310 319. [31] M. Musuvathi, D. Park, A. Chou, D. Engler, and \nD. Dill. Cmc: A pragmatic approach to model checking real code. Usenix Association, OSDI 2002. [32] S. \nOwre, N. Shankar, and D. Stringer-Calvert. PVS: An experience report. FM-Trends 98(1999), LNCS 1641, \nSpringer, 117 132. [33] The Coq Development Team. The Coq proof assistant reference manual(version7.4).Tech. \nrep.,INRIA, Rocquencourt, France, 2003. [34] M. Weiser. Program slicing. IEEE Transactions on Software \nEngineering SE-10, 4(1984), 352 357.  \n\t\t\t", "proc_id": "781131", "abstract": "We show that abstract interpretation-based static program analysis can be made efficient and precise enough to formally verify a class of properties for a family of large programs with few or no false alarms. This is achieved by refinement of a general purpose static analyzer and later adaptation to particular programs of the family by the end-user through parametrization. This is applied to the proof of soundness of data manipulation operations at the machine level for periodic synchronous safety critical embedded software.The main novelties are the design principle of static analyzers by refinement and adaptation through parametrization (Sect. 3 and 7), the symbolic manipulation of expressions to improve the precision of abstract transfer functions (Sect. 6.3), the octagon (Sect. 6.2.2), ellipsoid (Sect. 6.2.3), and decision tree (Sect. 6.2.4) abstract domains, all with sound handling of rounding errors in oating point computations, widening strategies (with thresholds: Sect. 7.1.2, delayed: Sect. 7.1.3) and the automatic determination of the parameters (parametrized packing: Sect. 7.2).", "authors": [{"name": "Bruno Blanchet", "author_profile_id": "81100497004", "affiliation": "CNRS (Centre National de la Recherche Scientifique) and &#201;cole normale sup&#233;rieure", "person_id": "PP14173660", "email_address": "", "orcid_id": ""}, {"name": "Patrick Cousot", "author_profile_id": "81100592699", "affiliation": "&#201;cole normale sup&#233;rieure", "person_id": "PP39049972", "email_address": "", "orcid_id": ""}, {"name": "Radhia Cousot", "author_profile_id": "81100592574", "affiliation": "CNRS (Centre National de la Recherche Scientifique) and &#201;cole polytechnique", "person_id": "PP14204543", "email_address": "", "orcid_id": ""}, {"name": "J&#233;rome Feret", "author_profile_id": "81100522160", "affiliation": "&#201;cole normale sup&#233;rieure", "person_id": "P517411", "email_address": "", "orcid_id": ""}, {"name": "Laurent Mauborgne", "author_profile_id": "81100216710", "affiliation": "&#201;cole normale sup&#233;rieure", "person_id": "P169392", "email_address": "", "orcid_id": ""}, {"name": "Antoine Min&#233;", "author_profile_id": "81100432807", "affiliation": "&#201;cole normale sup&#233;rieure", "person_id": "P517399", "email_address": "", "orcid_id": ""}, {"name": "David Monniaux", "author_profile_id": "81100428259", "affiliation": "CNRS (Centre National de la Recherche Scientifique) and &#201;cole normale sup&#233;rieure", "person_id": "P62994", "email_address": "", "orcid_id": ""}, {"name": "Xavier Rival", "author_profile_id": "81100659525", "affiliation": "&#201;cole normale sup&#233;rieure", "person_id": "P502800", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/781131.781153", "year": "2003", "article_id": "781153", "conference": "PLDI", "title": "A static analyzer for large safety-critical software", "url": "http://dl.acm.org/citation.cfm?id=781153"}