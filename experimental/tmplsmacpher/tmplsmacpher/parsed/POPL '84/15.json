{"article_publication_date": "01-15-1984", "fulltext": "\n The global storage needs of a subcomputation Jean-Claude Raoult LRI, B~timent 490 Universit6 de Paris-Sud, \nOrsay 91405 Orsay Cedex Ravi Sethi Bell Laboratories Murray Hill, New Jersey 07974 Abstract. A defining \ncharacteristic of \"functional\" specifications is the absence of assignments: updates of tables and data \nstructures are expressed by giving the relationship between the new and old values. An obvious implementation \nallocates separate space for new and old values and may consume a lot of storage. However, even when \nupdates of attributes like symbol tables are expressed function- ally, we would like to avoid making \ncopies of the symbol table during attribute evaluation. In other words, if possible, the implementation \nshould have a single global copy of the table that is updated using assignments. Since the value of the \nglobal copy changes during computation, the order of evaluation has to be chosen carefully. In this paper, \nwe partition attributes into classes, the problem being to determine if there exists an evaluation order \nthat allows each class to share a global storage area. The solution extends to handle symbol tables for \nblock structured languages. More precisely, consider a directed acyclic graph D in which vertices represent \nattribute values to be computed. Associated with each vertex is a labelindicating the storage area to \nbe shared by the ver- tex. Storage used during the evaluation of D is studied by playing a pebble game \non D with the fol- lowing steps: (1) pebble (i.e. place a pebble) on a source; (2) pebble a vertex if \nall its successors have pebbles (a pebble may be moved to the vertex from one of its successors); (3) \npick up a pebble. Each vertex must be pebbled exactly once. The use of global storage is formalized by \ndefining single peb- blings, in which at most one of the vertices with a given label has a pebble at \nany time. The results. also apply to a form of pebbling, called chain pebbling, that allows symbol tables \nfor block structured languages to be studied. 1. Introduction Consider a directed acyclic graph (dag) \nD, with labels or types associated with the vertices. Vertices represent values and edges represent dependencies \nbetween values. For example, a + b is represented by a vertex for + with edges to the leaves for a and \nb. The label of a vertex is called an attribute and each vertex is tailed an attribute instance. Dags \nlike D arise during the evaluation of attribute grammars [17]. D then represents the actual computations \nneeded to evaluate the attribute instances for a parse tree (i.e. chain or redun-dant dependencies are \ncollapsed into a single vertex). As a second example, D can be a dag representing distinct intermediate \nvalues of items in a database [32]. Labels on vertices distin-guish between items. Permission to copy \nwithout fee all or part of this material is granted publication and date appear, and notice is given \nthat copying is by provided that the copies are not made or distributed for direct permission of the \nAssociation for Computing Machinery. To copy commercial advantage, the ACM copyright notice and the title \nof the otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1983ACM0-89791-125-3/84/001/0148 \n$00.75 148 We are interested in the use of global storage during the evaluation of D. An evaluation \nof D starts at the leaves and proceeds towards the root(s), computing each vertex exactly once. For at \nleast two reasons, we may want to compute all instances of an attribute into the same global storage \nspace. (1) Database applications often require a (global) current version of each item to be maintained. \n(2) To avoid copying of large attributes when an incremental change occurs, glo- bal attributes (updated \ndestructively) have been considered. I Evaluation is formalized in Section 3 in terms of a \"pebble game\" \non a dug D: placing a pebble on a vertex corresponds to evaluation of the vertex. A pebble represents \na storage area. Constraints in Section 4 on the placement of pebbles (b~ised on vertex labels) formalize \nthe shar- ing of storage by attribute instances. The problem is to determine if there exists a constrained \nevaluation of a dug. Most of the technical difficulties in this paper arise because we also consider \nstack-like attributes which are a generalization of global attributes to allow symbol-tables of block \nstructured languages to be studied. Similar attributes have been considered by Baker [2] in the context \nof left to right bottom-up evaluation. In this paper we examine the structure of the dug D. (Previous \nwork on the above prob- lem in [33] deals with the dug D as given.) Suppose dug D is formed by pasting \nB into template T, written T[B]. In the attribute grammar application, the template T is for a production \nand B is the subdag for a nonterminal in the production. Since the size of B increases with the size \nof the parse tree, we are interested in considering \"approximations\" to B; A approximates B, if the space \nusage of T[B] can be inferred from the space usage of T[A] and B itself. Since the tem- plate T is generally \nsmall, and A is expected to be much simpler than B, it will be easier to examine T[A ]. The complexity \nresults in Section 5 suggest the restrictions in Section 6 on the structure of dags. A structural characterization \nof approximation is given in Section 6 so we can test if one dug is an approximation of another. However, \ntesting is not intended to be the main application. In Section 7 canonical approximations are constructed. \nApproximations are expected to be used in testing storage usage properties of attribute grammars. Related \nwork. Evaluators for attribute grammars start with an order of evaluation and then try to optimize storage. \nA fixed order of evaluation allows a storage area to be released as soon as all references to it have \noccurred. Data flow analysis techniques [8, 14] can then be used to recycle storage. Pass oriented evaluators \n[4, 9, 13, 18, 20, 27] by their very nature restrict evaluation order, although explicit control over \ntraversals is allowed by [11]. The benefits of optmization can be significant. For example, Rgiha [27] \ncites experiments in which a recycling algorithm led to a multi-pass evaluator using only 20% to 28% \nof the storage areas required by the previous \"unoptimized\" algorithm. Tree-walk evaluators [15, 28] \ndetermine a traversal by analyzing attribute dependencies in the grammar rules, but storage properties \nare not considered in the analysis. Dynamic evaluators [7, 16, 21] determine an evaluation order based \non the attribute depen- dencies for a given parse tree, but, again, storage requirements are not part \nof the analysis. (The approach of [22] allows sharing between instances of an attribute and is quite \ndifferent; however, random access is sacrificed in the process.) Schmidt [29] considers the specialized \nproblem of \"statically checking that a store argument in a denotational definition [can] be modelled \nas a global variable in any implementation of the definition.\" His checking criteria look at reads and \nwrites of the store. Very similar criteria have been applied to checking the correctness (serializability) \nof data- base transactions. It is observed in [32] that checking serializability reduces to the problem \nof ! In Knuth's original paper [17], attributes attached to the start symbol could be accessed and updated \nwithin the parse tree. Well formedness constraints kept updates of the attributes from interfering. Relaxation \nof the con- straints leads naturally to the global attributes considered in [5, 6, 12, 18, 19, 26]. Of \ncourse, the problem of implementing functional specifications using destructive updates is not particular \nto attribute evaluation. Schwartz [30] annotates first order recursive equations with declarations that \ncan be used for last-use informa- tion; he then considers the problem of verifying the declarations. \n149 determining if variables corresponding to items in the database can be made global in dag specifi- \ncation of assignments to the database The \"read before edges\" of [34] and the \"bi-paths\" of [24] are \nrelated to the criteria for determining pebblings in [33]. The approach in this paper differs from previous \nwork on attribute evaluators in one signi- ficant respect: global storage requirements as well as dependency \ninformation is taken into account to determine an evaluation order. The approach is therefore a refinement \nof dynamic and tree-walk evaluation because it restricts the feasible evaluation orders to those using \nstorage in a prescribed fashion. Results from [33] can be applied to dynamic evaluators; here we consider \nthe extension of [33] to tree-walk evaluators. The definition of approximations in this paper for- malizes \nthe intuition \"that from a database system's viewpoint, a transaction is completely deter- mined by the \nsubset of [items] it reads and writes [3].\" 2. Example: nested environments Consider the expression construct \nexp-. let id=expt in exp2. The meaning of the let expression is suggested by: let formal = actual in \nfunction_body For example, let z = a+b+c in z 3 --(a+b+c) 3 More precisely, the meaning of exp is given \nusing two attributes v and e, representing values and \"environments\", respectively: an environment maps \nan identifier to a value. The following attri- bute rules reflect the fact that function_body is evaluated \nin an environment with formal bound to the value of actual (update is defined below). v(exp) = v(exp2); \ne(expt) = e(exp); e(exp2) = update(e(exp), id, v(expl)) In the rules, f = update(f,z,a) is a function \nthat differs from f only at z, i.e. f (z)=a and f(x)=f(x) for all x~z. The relationship between the attributes \nfor a let expression is suggested by Figure 1. Here the subdags $1 and S2 are pasted into a template \nT consisting of a single nonleaf vertex labeled update. In the formalization, we consider the pasting \nof one dag at a time, the generalization to several nonoverlapping subdags is immediate. v (exp), v (exp2) \n e (exp2) .... ~\" update ~ \"\".. ................. .\":\"'$2 ................ e(exp), e(expl) id v (expl) \n\". . .~ ..'\" $1 \".. Figure 1. The above diagram suggests the relationship between the attributes for \nexpres- sion exp \", let id = expt in exp2. The dags St and $2 sketch the attribute values that arise \nfrom subexpressions expt and exp2. These subdags are shown dotted, because all we know about them is \nthat they will take environments as inputs and yield values as out- puts, as suggested by the dotted \narrows. let expressions introduce a limited form of block structure, which can be illustrated using: \n150 let a = (let b=10 in b) in a Given an initial environment e0, the attributes for this expression \nare shown in Figure 2.  7pl v v( xp) \"x e a  ~e a / a apply f'x e0 b 10 Figure 2. Attribute instances \nfor a nested let expression. Note that the value of identif- iers a and b in an environment is obtained \nby applying the environment function to the identifier. It is easy to see that a simple global storage \narea does not suffice for environments e0, eb, and e~ in Figure 2. When q for the inner let is defined, \ne0 cannot be overwritten, since it will be needed to create ea for the outer let. The reason for considering \napproximations can also be illustrated from Figure 1. Very little information about St and $2 is needed \nto decide that a global storage area does not suffice for environments. All we need is for $1 to have \nan instance of an environment in it. Starting with e(exp), the environment within St will be constructed; \nat some point we have to revert back to e(exp) so that it can be updated to e(exp2). Proofs that the \nenvironment can be implemented with a stack can also be done with a very simple approximation of $1 and \n$2. In Figure 2 it is important that both pairs e0, q and e0, e, are along \"chains\", where a chain is \na path without gaps. The formal counterpart of the stack discipline for environments is the requirement \nthat all environment vertices that are simultaneously accessible be along a chain. 3. Background: pebble \ngames study space requirements The register allocation problem illustrates some of the issues that arise \nduring the evaluation of a functional specification. One approach to expression evaluation is as follows. \n(1) Construct a directed acyclic graph (dag) for a straight line program [1]. The dag is a functional \nrepresenta- tion of thc values computed by the program. (2) Select an order of evaluation for the nodes \nin the dag. Once the order is fixed, it is easy to determine the minimal number of registers needed \n[23]. Notation. If there is an edge (x,y) we write x--y, or y--x, and say that X is a successorof x, \nwhile x is a predecessorof y. A leaf is a vertex with no successors, while a rootis a vertex with no \npredecessors. [] The register allocation problem can be formalized as a pebble game on a graph with the \nfol- lowing rules. There is an unlimited supply of pebbles. 1. A leaf may be pebbled at any step. 2. \nA vertex may be pebbled if all its successors have pebbles; in particular, a pebble may be moved to the \nvertex from any of the successors. 3. Any pebble may be removed at any step. 4. Each vertex is pebbled \nonce.  The object of the game is to determine the minimal number of pebbles needed during a playing \nof the game. This pebble game has been studied extensively [25]; there is an obvious correlation between \nthe number of pebbles and space usage. 151 Rule (2) implies that the graph being pebbled must be acyclic, \nso we restrict attention to dags henceforth. More precisely, a pebbling defines a total order on vertices: \nx<y denotes that x is pebbled before y. 4. Pebble games for studying use of global storage The pebble \ngames in this paper work with pebbles of several types. In the usual pebble game as defined in Section \n3, pebbles are interchangeable (in other words vertices in the dag are assumed to take up approximately \nequal amounts of space). Minimization of the number of peb- bles is known to be a hard problem [31]. \nAs in [10, 33] we attach labels to vertices reflecting the type or the storage properties of the object \nrepresented by the vertex. A pebble game is defined in [33] in which pebbles have types and the type \nof the pebble placed on a vertex matches the type of the vertex, z Ganzinger [10] consider allocation \nfunctions that map labels to storage areas; the problem of minimizing the number of.storage areas used \nis shown to be NP-complete. We are interested in two variants of the pebble game. In the first variant, \nthere is a single pebble of a given type. This case corresponds to the situation in which a single global \ncopy of the attribute has to be maintained, either because the space needed is so large, or because access \nto the attribute has to be controlled. In the second variant, there are an unlimited number of peb- bles \nof a given type, but the placement of pebbles is restricted; in particular pebbles must be removed in \na last-in-first-out order that models the use of symbol tables in a block structured language. In order \nto specify the variants precisely, we need notation to talk about the labels of ver- tices and also to \nindicate connectedness or lack thereof between vertices with the same label. Definitions. We write x:l \nto indicate that x has label I, and say that x is an/-vertex. We write x-gy if x-.y and x and y are both \nl-vertices. 3 There is an l-chain from x to y if x-/,*y. When I is clear from the context, we simply \ntalk of chains rather than/-chains. In fact, we will talk of/-chains and write \"7\" only when I is in \nthe set Ic defined below. We write x :! I Y :1 or simply x ]y when I is clear from the context if either \n(1) 1 is in It and x and y are distinct, or (2) I is in Ic and there is neither a chain from x to y nor \na chain from y tox. [~ Definition. Let there be a set Ic of environment like objects, and a set Is of \nstate like objects. A pebbling of a dag is a single-Is pebbling, if for each label s in Is there is at \nmost one pebble on vertices labeled s, at each step. A pebbling of a dag is a chain-It pebbling, if for \neach label e in Ic, the e-vertices with pebbles constitute a chain, at each step. A pebbling that is \nsimultaneously a chain-ic pebbling and a single-Is pebbling will be referred to as a chain-lc single-It \npebbling, n It was shown in [31] that determining if a single-it pebbling exists is an NP-complete prob- \nlem if the set It can be arbitrary. Heuristics for determining pebblings are given in [33]. 5. Setting \nthe stage In this section we show that it is difficult to say much about the pebbling of a pasted dag. \nPasting is formalized by taking the union of subdags. Definition. The graph G UH is formed from G and \nH by taking the union of their vertex and edge sets. The connection of a dag with the outside world is \nthrough a shared part consisting of \"input\" and \"output\" subdags. 2 For technical reasons, the definition \ndeals with untyped pebbles; the effect of typed pebbles is obtained by placing restrictions on the placement \nof pebbles. 3 As usual, we write --P and ~ for the reflexive transitive closures of \"\" and \"/', respectively. \nIn other words xt-.~x . if there is a sequence of vertices Xl, - - ,x n, where xi.-bxi+ I for all i, \nl~i<n. Similar remarks apply to 152 Definition. We consider triples A = (Ga,l,O) where Ga is a graph \nand I and O are non- empty subgraphs of Ga called the input and the output of A. The union IUO is called \nthe inter-face of A. When I and O are clear from the context, we write A for both A and GA. [] We will \nneed to place some technical restrictions on the union of dags and also on peb-hlings. These restrictions \nare motivated by the next theorem which states that even if pebblings exist for S and T, it is NP-complete \nto determine if there exists a pebbling of S U T. PROPOSITION 1. The following problem is NP-complete. \nLet single-Is pebblings exist for dags S and T, where Is is an arbitrary set of labels on the vertices \nof S and T. Determining if there is a single-is pebbling of SUT is NP-complete. o A number of plausible \nrestrictions do not change the complcxity of the problem in Proposi- tion 1. COROLLARY. The problem of \nProposition I remains NP-complete with each of the following restric- tions. 1. There is at most one \ninterface vertex with a given label. 2. An interface vertex is a source or a sink. A further restriction \nis: an interface vertex is a leaf in S and a root in T 3. All non interface vertices in S are pebbled \none after the other. 4. At some step in the pebbling, all interface vertices have pebbles. []  The \nabove NP-completeness result motivates the following restrictions on the pasting of subdags. We will \nconsider T[A] formed by pasting A within template T. The definition of T[A] has to be given carefully \nbecause we want to make sure that the connection between T and A is through the interface vertices and \nthat connections between vertices to be chain-pebbled are maintained. Definition. Let the vertices and \nedges of a graph G be denoted by V~: and EG, respectively. For A = (GA,I,O), we write T[A] for the graph \nwith vertices VTUVc. A and edges ErU(Eca-EI), satisfying: (i) For the vertices, TNGaCIUO. (ii) Sources \nin A of edges that are not in A must belong to I. Equivalent restatements are:  (x~A &#38; (x--y)~A) \n--> x~I xE(A-I) => (x-.y)(A [] The following restriction on pebblings allows the pebbling of a subdag \nto be considered independently of the pebbling of the rest of the dag. We begin by looking at a dag A, \nand will then consider pebblings of A within T[A ], for any T. Definition. A pebbling of A is consecutive \nif (1) all input vertices have pebbles at the step when the first (non-input) vertex in A- I is pebbled, \nand if (2) all output vertices have pebbles at the end. [] Restriction. Henceforth, pebblings of triples \nsuch as A will be consecutive. [] The following proposition explores some consequences of this fairly \nstrong restriction. Informally, if A can be pebbled consecutively, then: Vertex x pebbled before input \nvertex y must be an input vertex. Distinct input vertices with the same label must be along a chain. \nDistinct output vertices with the same label must be along a chain. Recall that input vertices have pebbles \non them at the beginning and output vertices have pebbles on them at the end. If for some label I to \nbe chain pebbled, there are both input and output vertices, then all other vertices with label I must \nhave a chain to the input ver- tex. 153 PROPOSITION 2. IrA accepts a consecutive pebbling, then 4 Vx,y. \nx<y => (yEI => x~l) Vx:l,y:lEl. ~(xly ) Vx:I,y:IEO. ~(xly ) Vx:IEI. ~y:lEO. y'r*x) => (Vz:IE(A-I) z-~*x) \nn Having looked at A by itself, we consider the pebbling of A as a subdag. Definition. A is pebbled consecutively \nin a pebbling \u00a2 of T[A] if (1) the restriction of 7r to the vertices of A is a consecutive pebbling of \nA, and (2) A-I is pebbled during a contiguous sequence of steps in ~r. o Non-interface vertices from \nT can be pebbled between the input vertices and vertices in A-I. However, a pebble must remain on an \ninput vertex until the first vertex of A- I is peb- bled, so vertex w:! of T that does not have a chain \nto input vertex v:l cannot be pebbled between v and A- I. This statement is restated as the next proposition. \nPROPOSITION 3. If T[A ] has a pebbling in which A is pebbled consecutively, then Vu:IEI. Vw:IET-A. (ulw \n&#38; u<w) => VvEA. v<w n 6. Approximations of subdags In practice, we expect templates like T to be \nsmall, while the pasted dag A can be large. Using Figure 1 again, only the update vertex and the leaf \nfor the identifier belong solely to the template. Rather than treating T and A symmetrically as in the \nlast section, we use the intuition that T is small and formulate a test that may examine the structure \nof T, but not of A. In particular only a small \"approximation\" of A will be examined. A first cut at \ndefining approximations is to say that A approximates B if T[A] has a pebbling whenever T[B] does. A \nweaker definition has wider applications. Definition. A r- B if and only if they have same input and \noutput vertices and for all T, T[A] has a pebbling if T[B] and A do. o The next proposition characterizes \napproximations in terms of graphical structure so approximations can easily be tested. Its proof requires \na number of cases to be examined. Infor-mally, if A r-B then: There is a function c from A to B that \nmaps each vertex to a vertex with the same label and maps interface vertices to themselves. Furthermore, \na chain between a vertex y and input vertex x in A results in a similar chain between c(y) and c(x) in \nB. PROPOSITION 4. lf A ~ B then 1. A has a pebbling if B does. 2. There exists a function c:A-,B preserving \nlabels (i.e. x:! => c(x):l), extending the identity on ILIO (i.e. x(lUO => c(x)=x), such that y l-~x \nif c(y)l-~c(x ) when x and y have the same label and x and y are interface vertices or when x is an input \nvertex;furthermore, c(y) cannot be in I unless y is, if there are at least two labels in A:  (C1) V! \nEIc.fVx:l,y :1EIUO). c(y)i,*c(x ) --> y-p~x (C2) (Vx:iEI)(Vy:! EA). xly => c(x)lc(y) (C3) ~u:m,v:lEA. \nm~l) => ~qlEIc. ~y:l((A-l)) => (3c(y'):lE(B-I))) 4 We give the precise statement becat, se it takes care \nof both single and chain pebblings. As mentioned in Sec- tion 4, we write 7' only when I E Ic. Proof \nSketch. We first show that the function c exists by deriving a contradiction from the assumption that \nit does not. In order to derive a contradiction, we have to show the existence of some T such that both \nA and T[B] have pebblings, but T[A] does not. Existence is shown by construction. Once the existence \nof c is established, there are three cases corresponding to the following conjunctions of conditions: \n(1) ~C1; (2) C1 &#38; -C2; (3) C1 &#38; C2 &#38; ~C3. In each case we con-struct T such that for A and \nB satisfying the case assumptions, A and T[B] have pebblings but T[A] does not. n PROPOSITION 5. Suppose \nthat A and B satisfy conditions (C1-C3) of Proposition 4. Then A E_B istrue. Proof Sketch. Suppose, A \nr-B is false..Then there exists T such that A and T[B] have pebblings but T[A ] does not. A consecutive \npebbling of T[A] is constructed from a consecutive pebbling of T[B] by removing the vertices of B-I and \ninserting the vertices of A-I. The ordering on vertices of A-I is from a consecutive pebbling of A. The \ndefault is to replace B-I by A-I, with the exception being to insert A -I just after the step when all \nvertices in I have pebbles. The excep- tion occurs if (1) B-I is empty, or, (2) there is no output vertex \nin B-I and there is at most one label ! (/c on vertices in A-I. (Without loss of generality, A- I is \nnonempty; otherwise simply removing the vertices of B-I yields a consecutive pebbling of T[A ].) The \nbulk of the proof consists of showing that the above ordering gives a pebbling of T[A]. [] The main application \nof Proposition 5 occurs in the next section. 7. Canonical approximations of subdags In the last section, \nwe talked about approximations between two arbitrary dags A and B. Some of the difficulties in the proofs \narise precisely from the arbitrary nature of A and B. In this section we consider a particular approximation \nthat is simpler than B. We replace B in T[B] by a simpler dag B which is a quotient of B under a suitable \nequivalence relation. This relation will be reminiscent of the conditions in Proposition 4. The results \nin this section first construct the equivalence relation and quotient and then show that it is suitable. \nMore precisely, we show both B r- B and B E B. Furthermore, B has a pebbling if B does. Putting these \nobservations together we get: PROPOSITION 6. Suppose B has a pebbling. Then, for all T, T[B] has a pebbling \nif and only if T[/~] does. o We begin by defining three equivalence relations reminiscent of conditions \nC1-C3 in Propo- sition 4. Since non-labeled vertices do not constrain pebblings, we restrict attention \nto B L the full subgraph of labeled vertices of B. Definition. Relations RI, R2, and R 3 are defined \nby: = {(u,,,) I u:l &#38; v:! &#38; l S\u00a2 &#38; (Vx:l 1oo) v x} e2 = {(u,,,) I,,:l &#38; ,,:! &#38; i \nl.&#38; (W:I O ulx ,.Ix} R3 = {(u,v) I u:! &#38; v:! &#38; uEI -<=> v6. l} = R I &#38; R2\"&#38; R 3 [] \nThe graph/~ has the vertices of BL/--. There is a mapping q:BL -\"/3. The edges of g are defined as follows. \nIf x and y have the same label, if there is an edge x-,y and q(x)~q(y), then there is an edge q(x)-,q(y). \nA sequence of propositions now establishes Proposition 6 above. 155 8. Discussion Study of the approximation \nof subdags is a stepping stone to a test of the storage properties of all dags generated by an attribute \ngrammar, in dealing with a grammar instead of a single dag, \"safe\" choices have to be made. A similar \nproblem is faced in [15]: \"Unfortunately, dif- ferent subtrees with the same root symbol may nevertheless \nexhibit different input-output depen- dencies, so we cannot hope to characterize a nonterminal precisely \nby means of a single graph. Instead our IO~,'s will present a sort of worst-case picture of potential \ninput-output dependen- cies.\" The objective is to define \"safe\" approximations of all the dags that can \nbe generated from a nonterminal. (For let expressions, or for statements in a programming language such \nsafe approximations are easy to find.) An inductive proof can then be given that all dags generated by \nan attribute grammar have the desired pebblings. References 1. A.V. Aho and J. D. Ullman, \"Optimization \nof straight line programs,\" SIAMJ. Comput-ing 1(1), pp. 1-19 (March 1972). 2. T.P. Baker, Personal communication, \nNovember 1983. 3. P.A. Bernstein, D. W. Shipman, and W. S. Wong, \"Formal aspects of serializability \nin database concurrency control,\" IEEE Trans. Software Engineering SE-5(3), pp. 203-216 (May 1979). \n4. G.V. Bochman, \"Semantic evaluation from left to right,\" Comm. ACM 19(2), pp. 55-62 (February 1976). \n 5. J. Borowiec, \"Pragmatics in a compiler production system,\" pp. 314-340 in Methods of Algorithmic \nLanguage Implementation, ed. A. Ershov and C. H. A. Koster, Lecture Notes in Computer Science 47, Springer-Verlag, \nBerlin (1977). 6. C.A. Brown and P. W. Purdom, Jr, Specifying one-pass bottom-up compilers, Computer \nSci- ence Dept., Indiana Univ., Bloomington IN (July 1981). 7. R. Cohen and E. Harry, \"Automatic generation \nof near-optimal linear-time translators for non-circular attribute grammars,\" Sixth Annual ACM Symposium \non Principles of Program- ming Languages, San Antonio TX, pp. 121-134 (January 1979). 8. P. Cousot and \nR. Cousot, \"Systematic design of program analysis frameworks,\" Sixth Annual ACM Symposium on Principles \nof Programming Languages, San Antonio TX, pp. 269- 282 (January 1979). 9. R. Farrow, \"Linguist-86: yet \nanother translator writing system based on attribute gram- mars,\" SIGPLAN Notices 17(6), pp. 160-171 \n(June 1982). 10. H. Ganzinger, \"On storage optimization for automatically generated compilers,\" pp. \n132-141 in Theoretical Computer Science, 4th GI Conference, Lecture Notes in Computer Science 67, Springer-Verlag, \nBerlin (1979). 11. H. Ganzinger, R. Giegerich, U. M6ncke, and R. Wilhelm, \"A truly generative semantics- \ndirected compiler generator,\" SIGPLAN Notices 17(6), pp. 172-184 (June 1982). 12. H. Ganzinger, K. Ripken, \nand R. Wilhelm, \"MUG1 -An incremental compiler-compiler,\" ACM Annual Conference, pp. 415-418 (1976). \n 13. M. Jazayeri and D. Pozefsky, \"Space-efficient storage management in an attribute grammar evaluator,\" \nACM Transactions on Programming Languages and Systems 3(4) (October 1981). 14. N.D. Jones and S. S. \nMuchnick, \"A flexible approach to interprocedural data flow analysis and programs with recursive data \nstructures,\" Ninth ACM Symposium on Principles of Pro- gramming Languages, pp. 66-74 (1982). 15. K. \nKennedy and S. K. Warren, \"Automatic generation of efficient evaluators for attribute grammars,\" Third \nACM Symposium on Principles of Programming Languages, Atlanta GA,  156 pp. 32-49 (January 1976). 16. \nK. Kennedy and J. Ramanathan, \"A deterministic attribute grammar evaluator based on dynamic sequencing,\" \nACM Transactions on Programming Languages and Systems 1(1), pp. 142-160 (July 1979). 17. D. E. Knuth, \n\"Semantics of context-free languages,\" Mathematical Systems Theory 2(2), pp. 12%145 (1968). Errata 5(1), \npp. 95-96 (1971). 18. K. Koskimies and K.-J. Rgihfi', \"Modelling of space-efficient one-pass translation \nusing attribute grammars,\" SoJiware - Practice and Experience 13, pp. 119-129 (1983). 19. J. Lewi, K. \nDe Vlaminck, J. Huens, and M. Huybrechts, A Programming Methodology in Compiler Construction, Part 1: \nConcepts, North-Holland, Amsterdam (1979). 20. P.M. Lewis II, D. J. Rosenkrantz, and R. E. Stearns, \n\"Attributed translations,\" J. Com-puter and System Sciences 9, pp. 279-307 (1974). 21. B. Lorho, \"Semantic \nattribute processing in the system Delta,\" pp. 21-40 in Methods of Algorithmic Language Implementation, \ned. A. Ershov and C. H. A. Koster, Lecture Notes in Computer Science 47, Springer-Verlag, Berlin (1977). \n 22. O. L. Madsen, \"On defining semantics by means of extended attribute grammars,\" pp. 259-299 in Semantics \nDirected Compiler Generation, ed. N. D. Jones, Lecture Notes in Com- puter Science 94, Springer-Verlag, \nBerlin (1980). 23. T. Marill, \"Computational chains and the simplification of computer programs,\" IRE \nTrans. Electronic Computers EC-11(2), pp. 173-180 (April 1962). 24. C.H. Papadimitriou, \"The serializability \nof concurrent database updates,\" J. ACM 26(4), pp. 631--653 (October 1979).  25. N. Pippenger, \"Pebbling,\" \nProc. Fifth IBM Syrup. on Math. Foundations of Computer SSci- ence, pp. 1-19 (May 1980). 26. K.-J. R~'ihg, \n\"On attribute grammars and their use in a compiler writing system,\" Report A-1977-4, Dept. of Computer \nScience, University of Helsinki (August 1977). 27. K.-J. Rgihg, \"A space management technique for multi-pass \nattribute evaluators,\" Report A-1981-4, Dept. of Computer Science, University of Helsinki (November 1981). \n 28. M. Saarinen, \"On constructing efficient evaluators for attribute grammars,\" pp. 382-397 in Automata, \nLanguages and Programming, Fifth Colloquium, Lecture Notes in Computer Science 62, Springer-Verlag, Berlin \n(1978). 29. D. Schmidt, \"Detecting global variables in denotational specifications,\" manuscript, Com-puter \nScience Dept., Edinburgh Univ. (May 1983). 30. J. Schwarz, \"Verifying the safe use of destructive updates \nin applicative programs,\" pp. 395-411 in Program Transformations, 3rd Intl. Symposium on Programming, \ned. B. Robinet, Dunod, Paris (1978). 31. R. Sethi, \"Complete register allocation problems,\" S'IAM J. \nComputing 4(3), pp. 226-248 (September 1975). 32. R. Sethi, \"A model of concurrent database transactions,\" \n22nd Annual Symposium on Founda- tions of Computer Science, Nashville TN, pp. 175-184 (October 1981). \n 33. R. Sethi, \"Pebble games for studying storage sharing,\" Theoretical Computer Science 19(1), pp. 69-84 \n(july 1982). 34. R.E. Stearns, P. M. Lewis II, and D. J. Rosenkrantz, \"Concurrency control for database \nsystems,\" pp. 19-32 in 17th Annual Symposium on Foundations of Computer Science, Houston Texas (October \n1976).  157  \n\t\t\t", "proc_id": "800017", "abstract": "<p>A defining characteristic of &#8220;functional&#8221; specifications is the absence of assignments: updates of tables and data structures are expressed by giving the relationship between the new and old values. An obvious implementation allocates separate space for new and old values and may consume a lot of storage. However, even when updates of attributes like symbol tables are expressed functionally, we would like to avoid making copies of the symbol table during attribute evaluation. In other words, if possible, the implementation should have a single global copy of the table that is updated using assignments. Since the value of the global copy changes during computation, the order of evaluation has to be chosen carefully. In this paper, we partition attributes into classes, the problem being to determine if there exists an evaluation order that allows each class to share a global storage area. The solution extends to handle symbol tables for block structured languages.</p> <p>More precisely, consider a directed acyclic graph <italic>D</italic> in which vertices represent attribute values to be computed. Associated with each vertex is a <italic>label</italic> indicating the storage area to be shared by the vertex. Storage used during the evaluation of <italic>D</italic> is studied by playing a <italic>pebble game</italic> on <italic>D</italic> with the following steps: (1) pebble (i.e. place a pebble) on a source; (2) pebble a vertex if all its successors have pebbles (a pebble may be moved to the vertex from one of its successors); (3) pick up a pebble. Each vertex must be pebbled exactly once. The use of global storage is formalized by defining <italic>single pebblings</italic>, in which at most one of the vertices with a given label has a pebble at any time. The results also apply to a form of pebbling, called <italic>chain pebbling</italic>, that allows symbol tables for block structured languages to be studied.</p>", "authors": [{"name": "Jean-Claude Raoult", "author_profile_id": "81100617549", "affiliation": "LRI, B&#226;timent 490, Universit&#233; de Paris-Sud, Orsay, 91405 Orsay Cedex", "person_id": "P136446", "email_address": "", "orcid_id": ""}, {"name": "Ravi Sethi", "author_profile_id": "81100354362", "affiliation": "Bell Laboratories, Murray Hill, New Jersey", "person_id": "PP39039094", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/800017.800526", "year": "1984", "article_id": "800526", "conference": "POPL", "title": "The global storage needs of a subcomputation", "url": "http://dl.acm.org/citation.cfm?id=800526"}