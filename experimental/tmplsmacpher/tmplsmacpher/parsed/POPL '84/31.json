{"article_publication_date": "01-15-1984", "fulltext": "\n Efficient lmpl?met:tation of the Smalltalk-80 S sty_.~_qLn \" I.. Peter I)cutsch Xerox PARC, Software \nConcepts Group Allan M. Schiffman Fairchild I.ahoratory hw Artificial Intelligence Research ABS'I'I{ACr \nThe Smalltalk-80* programming language includes dynamic storage allocation, fuU upward limargs, and universally \npolymorphic procedures; file Smalllalk-80 programming system features interactive exect, tion wiflt incremental \ncompilation, and implementation portability. These features of modern programming systems are among the \nmost difficult tu implement efficiently, even individually. A new implemelltation of the Small/alk-80 \nsystem, hnsted on a sinall microprocessor-based computer, achieves high performance while retaining' \ncomplete (object code) compatibility with existing implementations. This paper discusses the most significant \noptimization techniques developod over the course of the project, many of which are applicable to other \nlanguages. The key idea is to represent certain nmtime state (both code and data) in more than one form. \nand to convert between fo~xns when needed. *Smalhalk-80 is atrademark of the Xerox Corporalion. BACKGROUNI) \nThe Smalltalk-80 system is an object-oriented programming language and interactive programming environment. \nThe Smalltalk-80 language inclodes many of the most difficult-to-implement features of modern progralnming \nlanguages: dynamic storage allocation, full upward funargs, and call-time binding of procedure names \nto actual procedures based on dynamic type information, sometimes called message-pa~#tg. The interactive \nenvironment includes a full complement of programming tools: compiler, debugger, editor, window system, \nand so on, all written in the Smalltalk-80 language itself. A detailed overview of the system appears \nin [SCG 8l]. [Goldberg 83] is a technical refcrcncc for both file nnn-interactive programmer and the \nsystem implcmentor; [Goldberg 841 is a reference manual for the interactive system. SPE('IAL l)l I,'FICULTil,;S \nThe standard Smalltalk-80 system implementation is based on an ideal virtual machine or v-machine. The \ncompiler generates code for this machine, and the implementor's documentation describes the system as \nan interpreter for the v- Permission to copy without fee all or part of this material is granted provided \nthat the copies are not made or distributed for direct commercial advantage, the ACM copyright notice \nand the. title of the publication and its date appear, and notice is given that copying is by permission \nof the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or \nspecific permission. &#38;#169; 1983 ACM 0-89791-125-3/84/001/0297 $00.75 machine instruction set, similar \nto the Pascal P-system [Ammann 75] [Ammann 77]. One unusual feature of the Smalltalk-80 v- machine is \nthat it makes runtime state such as procedure activations visible to tile programmer as data objects. \nThis is similar to tile \"spaghetti stack\" model of Interlisp [XSIS 83l, but more straightforward: Intcrlisp \nuses a programmer-visible iudircction mechanism to reference pr~x:edure activations, whe~'cas Ihe Sinalltalk-80 \nprogrammer treats procedure actiwttioas just like any other data objects. The Sinalltalk-80 language \napproaches programming with generic data types through message-passing and dynamic typing. To invoke \na pl'Occdure (method in Smalltalk-80 terminology), a message is sent to a data object (the receiver), \nwhich selects the method to be c\u00d7ecuted. 'Ibis means that a method address must bc found at runtime. \nAt a given lexical point in the code, only die message name (selector) is known. To perform a message-send, \nthe data type (class) of file receiver is extracted, and the selector is used as a hash index into a \ntable of the message dicliottary of the class, which maps selectors to methods. The task of melhod-lookup \nis complicated by the inherilance property of classes --a cla~ may be defined as a subclass to another, \ninheriting all of the methods of the supcrclass. If the initial method-lookup fails, the lookup algorithm \ntries again usirlg the message dictionary of the superclass of the receiver's class, continuing in this \nway up the class hierarchy until a method cnrresponding to the selector is found or the top of the inheritance \nhierarchy is reached. The Smalltalk-80 language uses the organization of objects into classes to provide \nstrong information hiding. Only the methods associated with a given class (and its subclasses) can access \ndirectly the state nf an instance of that class. All access from \"outside\" must be through messages. \nIk'cause of this, a Smalltalk-80 program must often make procedure calls to access state where I,mguages \nsuch as Pascal could compile a direct access to a tield of a record. This makes the performance of the \nmethod-lookup algorithm even more critical. IMPLEMENTATION OUTLINE The purpose of the research de~ribed \nhere was to build a Smalltalk-80 system with acceptable performance on a relatively inexpensive, microproecssor-based \ncomputer; specifically, to discover how to implement the basic data and code objects of the Smalltalk-80 \nsystem in a way that still conformed to the v-machine specification, but were more suitable for conventional \nhardware. (As of early 1982, the only implementations that ran at acceptable speed were on non-commercial, \nuser-microprogra,nmable roachines, as de~ribed in [Krasner 83] [I.ampson 81].) The system specification \nin [Goldberg 83] includes tile definition of internal data structttres and object code representation \nfor the virtual machine. Indeed, much of the system code depends on these definitions. We chose to take \nthese definitions as given, rather than alter the system code. 297 \"lhis was motivated partly by a desire \nto retain object-code portability, and pardy by a desire not to complicate the description of the SmaUtalk-80 \nmachine model. The single principle that underlies all the results reported here is dynamic change of \nrepresentation. By this we mean that the same infi)rmation is represented in more than one (structurally \ndifferent) w,~y during its lifetime, being converted transparently between representations a:; needed \nfor efficient use at any moment. An important special case of this idea is caching: one can think of \ninformation in a cache as a different representation of the same information (considering contents and \naccessing information together) in the backup memory. In the implementation described in this paper, \nwe applied this principle to several different kinds of runtime information in the Smalltalk-80 system. \n* We dynamically translate v-code (i.e., code in the instruction set of the v-machine) into code that \nexecutes directly on the hardware without interpretation, the native code or n-code. Translated code \nis cached: it is regenerated rather than paged. * We represent procedure activation records (contexts \nin Smalltalk-80 parlance) in either a machine-oriented form, when they are being used to hold execution \nstate, or in the form of Smalltalk-80 data objects, when they are being treated as such. * We use several \ndifferent caches to speed up the polymorphic search required at each procedure invocation. In the best \ncase, which applies over 90% of the time, a Smalltalk-80 procedure invocation requires only one comparison \noperation in addition to a conventional procedure linkage. * Using the techniques in [Deutsch&#38;Bobrow \n76], we represent reference count information for automatic storage management in a way that eliminates \napproximately 85% of the reference counting operations required by a standard implementation.  CODE \nTRANSLATION Targeting code to a portable v-machine has been used in other language implementations. Usually \nv-code targeting is used only to avoid having multiple (one per target machine) code-generation phases \nof the compiler; a secondary benefit is that v-code is usually much more compact than code for any real \nmachine. Since the Smalltalk-80 compiler is just one tool available in the same interactive environment \nused for execution, and other tools besides the compiler must be able to examine the machine state, the \nv-machine approach is even more attractive in reducing the cost of rehosting. PERFORMANCEISSU I~ To rehost \nthe system, an implementor must emulate the v-machine on the target hardware, either in microcode or \nin software. This normally incurs a severe performance penalty arising from several factors. * Processors \nhave specialized hardware for fetching, decoding, and dispatching their own native instruction set. This \nhardware is typically not available to the prngrammcr (although it may be available at the microprogram \nlevel), and therefore not useful to the v-machine interpreter in its time-consuming operation of instruction \nfetching, decoding, and dispatching. * The v-machine architecture may be substantially different from \nthat of the underlying hardware. [:or example, many v-machines, including both the P-system  and Smalltalk-80 \nv-machines, use a stack-oriented architecture for convenience in code generation, but most available \nhardware machines execttte register-oriented code much more efficiently than stack-oriented code. * The \nbasic operations of the v-machine may be relatively expensive to implement, even though the overall algorithm \nrepreseqted by a v-code program may not be much more expensive than if it were implemented in the hardware \ninstruction set. For example, even though a naive interpreter for the Smalltalk-80 v-code must perform \nrcl~:renee counting operations every time it pushes a variable value onto the stack, a sequence of several \ninstructions often has no net effect on reference counts. If the v-code were translated to n-code after \nnormal compilation of a source program to v-code, the interpreter's overhead could be eliminated and \nsome optimizations become possible. One technique for eliminating part of the overhead of interpretation \nis threaded code [Bell 73] [Moore 741. In this approach, v-code consists of an actual sequence of subroutine \ncalls on runtime routines. This technique does reduce the o~;erhead for fetching and dispatching v-code \ninstructions, although it does not help with operaod decoding, or enable optimizations that span more \nthan one v-instruction. We prefer to translate v-code to in-line n-code in a more sophisticated way. \nNaive translation from v-code to n-code is a process something like macro-expansion. In fact, [Mitchell \n71] observed that a translator can be derived very simply from an interpreter by having the interpreter \nsave its action-routine code in a buffer rather than executing it. If the computation performed by individual \naction routines is small relative to the computation needed for the interpreter loop, the benefit of \neven this simple kind of translation will be great. Translation-time can also be considered an opportunity \nfor peephole optimization or even mapping stack references to registers [Pittman 80]. Translation back-ends \nfor portable compilers have been implemented [Zellweger 79]. DYNAMIC TRANSI,ATION Because the Smalltalk-80 \nv-code is a compact representation that captures the basic semantics of the language, n-code will typically \ntake up much more space than v-code. (In the implementation discussed in this paper, n-code takes about \n5 times as much space as v-code.) This would place severe stress on a virtual memory system if the n-code \nwere being paged. However, since n-code is derived algorithmicafiy from v-code, there is no need to keep \nit permanently: it can be recomputed when needed, if this is more efficient than swapping it in from \nsecondary storage. This leads us to the idea of translating at runtime. (The idea of dynamic translation \nappears in [Rau 78], where it is applied to translation from v-code to microcode.) When a procedure is \nabout to be executed, it must exist in n-code form. If it does not, the call faults and the translator \ntakes co,ltrol. The translator finds the corresponding v-code routine, translates it, and completes the \ncall. Since, as mentioned earlier, the translation process is more akin to macro-expansion than compilation, \ntranslation time for a v-code byte is comparable to the time taken to interpret it. We consider the translation \napproach, and dynamic translation in partietdar, to be the most interesting part of our research, since \nit motivated the work on multiple state rcprcsentations described below. A later section of this paper \npresents the experimental results that support our contention that dynamic translation is an effective \ntechnique in a substantial region of current technological parameters. 298 MAPPING STNI'E AT RUNTIME \nSince the definition of the Smalltalk-80 v-machine makes runtime state sucl~ as procedure activations \nvisible to the progrannner as data objects, an implementation based on n-code must find a way to make \nthe state appear to the programmer as though it were the state of a v-machine, regardless of the actual \nrepresentation. The system must maintain a mapping of n-machine st.'tte to v-machine state; in particular, \nit nmst keep the v-code a~ailable for inspection. How can we guarantee that all attempts to access a \nquantity requiring representation mapping are detected? The structure of the Smalltalk-80 language guarantees \nthat the only code that can access an object of a given class directly is the code that implements messages \nsent to that class. 'lllus, the only code that can directly access the parts of an object requiring mapping \nis code associated with that object's class. Recall that all the code in the Smalltalk-80 system is written \nin the Snlalitalk-80 language, hence compiled into v-code. When we translate a p~x~cedure from v-code \nto n-code that is asst~.'iatcd with a class whose representation may require mapping, we generate special \nn-code that calls a subroutine to ensure that the object is represented in a form where accesses to its \nnamed parts are meaningful. The most obvious quantity requiring mapping is the return address (PC) in \nan activation record, whicll refers to a location in the n-code procedure rather than in the v-code. \nAlthough there is no simple algorithtnic correspondence between the v-PC and the n-PC values, the v-PC \nneed only be available when a program attempts to inspect an activation as a data objcct. At that moment, \nthe system can consult (or compute) a table associated with the procedure that gives the correspondence \nbetween n-and v-PC rallieS. We can greatly reduce the size of the mapping tables for PC values by observing \nthat the PC can only be accessed when an activation is suspended, i.e., at a procedure call or interrupt/process-switch. \nIf we are willing to accept somewhat greater latency in a Smalltalk-80 program's response to interrupts, \nwe can choose a restricted but sufficient set of allowable interrupt points, and only store the mapping \ntables for those points. This is what our implementation does: interrupts are only allowed at, and PC \nmap entries are only stored for, all prtx:cdure calls and backward branches (the latter since interrupts \nmust be allowed inside loops). MUI,TIPLE REI)RI'2\"iENTA'I'IONS OF CONTEXTS As mentioned earlier, the \nformat of procedure activation records are part of the Smalltalk-80 v-machine specification. Contexts \nare full-fledged data objects; they have identifiable fields which can be accessed and they respond'to \nmessages. A context is created for every message-send. There is also syntax in the language for creating \ncontexts whose activation is deferred, cldled block contexts in Smalltalk-80 terminology, which correspond \nto the functional&#38; closures, or funargs of other languages. Most control structures in the Smalltalk-80 \nsystem are implemented with block contexts. The fact that contexts are standard data objects implies \nthat they must be created like data objects, i.e., allocated on a heap and reclaimed by garbage collection \nor reference counting. Unforttmately. conventional machines are adapted for calling sequences that create \na new activation record as a stack flame, storing suspended state in predefined slots in the frame. Actually \nimplementing contexts as heap objects results in a serious performance penalty. Mcasttrements show that \neven in Smalltalk-80 programs, more than 85% of all contexts behave like procedure activations in conventional \nlanguages: they are created by a call, never referenced as a data object, and can be freed as soon as \ncontrol returns from them. (Note that any context in which a block context is created does not satisfy \nthis criterio,1.) Such contexts are candidates for stack-frame representation. (An unpublished experimental \nimplementation of an earlier Smalltalk system used linear stacks, but did not deal properly with contexts \nthat outlived their callers.) Stack allt~cation of contexts solves one of the two major efficiency problems \nassociated with treating contexts like other objects, namely the ovcrbead of allocating the contexts \nthemselves. [l)ctltmh&#38;llobrow 76] shows how to solve the other problem, of reference counting operations \napparently being required on every store into a local variable. With these two problems solved, we can \nrise the hardware subroutine call, return, and store instructions directly. Ottr system has several types \nof context representations. A message-send creates a new context in a representation optimized for execution: \na frame is allocated on the machine's stack (with some spare slots) by the usual machine instructions. \nIn the simple case, where no reference is ever made to the context as a data object, the machine's return \niristruction simply pops the fi'ame off file stack when control returns fi'om the context. This kind \nof context, which lives its life as a stack frame, we call volatile. At the other extreme, we store contexts \nin a format compliant with the virtual machine specification, which can be manipttlated as data items. \nWe call this representation stable. The third representation of a context, called hybrid, is a stack \nframe that incorporates header information to make it look partly like an ordinary data object. A volatile \ncontext is converted to hybrid when a pointer is generated to it. Since this makes it possible fi~r programs \nto refer to the context as an object, we fill in slots in the frame corresponding to the header fields \nin an ordinary object. This pseudo-object is tagged as being of a class we name \"l)ummyContext.\" A block \nof memory is allocated, and its address is stored in the context in case the context must be stabilized \nin the future. Since there may be pointers to this context, it cannot be returned fiom in a normal way, \nso the return address is copied to another slot in the frame and replaced with the address of a clean-up \nroutine that stabilizes the context on return. When a message is sent to a hybrid context, the send fails \n(there are no procedures defined for the DummyContext class), and a routine is called to convert the \nhybrid context to the stabilized form. At this point PC mappitlg comes into play; the n-PC in the activation \nis converted to a v-PC for the stabilized representation. Poi,lters to the hybrid context are switched \nto refer to the stable context (this is simple in our system, which uses an indirection table for all \nobjects). After the context has been stabilized, tile failed mess,age is re-sent to the stable form. \nA stable context is not suitable for execution. Before a stabilized context can be resumed, it is reconstituted \non the stack as hybrid. Again, this means that the n-PC must be reconstructed fi'om tile v-PC. Usually \nthe v-PC does not change during the stable period, so our system includes a one-element cache ill each \nn-code procedure for tile most recent v-PC/n-PC pair, to avoid having to run the mapping algorithm. Block \ncontexts are \"~boro\" in stable form, since the whole purpose of closures is to provide a representation \nfor an execution context which can be invoked later. IN-I,INE CACI lING OF METHOI) Ai)I)R I~JSES Mess~tge-passing \nis applied down to the simplest operations in Smalltalk. The system provides a variety of predefined \nclasses: the most basic operations on.elementary data types (such as addition of integers) are performed \nby primitives implemented 299 by the kernel of die system, rather Ih;in by Smalltalk routines, but there \nis no distinction drawn at the language level. Since mes.~ge-sends are so ubiquitous, they must bc fast: \nthe operation 6f method-lookup is both expensive and critical. All existing Smalltalk-80 implementations \naccelerate method- lookup by using a method cache, a hash table of pooular method addresses indexed by \nthe pair (receiver class, message selector). This simple technique typically improves system perfi~rmance \nby 20-30%. More extensive measurements of this improvement appear in [Krasner 83]. Further performance \nimprovements are suggested by the observation of dynamic locality of lype usage. That is, at a given \npoint in code, the receiver is often the same class as the receiver at the same point when the code was \nlast exect,ted. If wc cache the looked-up method address at the point of send, subsequent execution of \nthe send code has the method address at hand, and method-lookup can be avoided if the class of the receiver \nis the same as it was at the previous execution of this particular send. Of course, the class of the \nreceiver may have changed, and must be checked against the class corresponding to the cached method address. \nIn the implementation described here, the translator generates n-code for sends unlit~ked --as a call \nto the method- lookup routine, with the selector as an in-line argument. The method-lookup routine links \nthe call by finding the receiver class, storing it in-line at the call point, and doing the method- lookup \n(like other implementations, it uses a selector/class-method cache). When the n-code method address is \nfound, it is placed in-line with a call instruction, overwriting the former call to the lookup routine. \n\"['he call is then re-executed. (Of course, there may be no corresponding n-code method, in which case \nthe translator is called firsL) Note that this is a kind of dynamic code modification, which is generally \ncondemned in modern practice. The n-method address can just as well be placed out- of-line and accessed \nindirectly; c~de modificatioll is more cl~cicnt, and we are using it in a weIFconfined way. The entry \ncode of an n-code method checks the stored recei~crclass from the point of call against the actoal receiver \nclass. If they do not match, relinking must \u00a2~:cur, just as if the call had not yet been linked. Since \nlinked sends have n'code method addresses bound in- line, this address must be invalidated if the called \nn-code method is being discarded from memory. The idea of\" scanning all n-code routines to invalidated \nlinked addresses was initially so daunting that we almost rejected the scheme. However, since n- code \nonly exists in main memory, invalidation cannot produce time-consuming page faults. Furthermore. since \nthe PC mapping tables described earlier contain precisely the addresses of calls in the n-code, no searching \nof the n-code is required: it is only necessary to go through the mapping tables and overwrite the call \ninstructions to which the entries point. (A scheme similar to this may be found in [Moon 73].) For a \nfew special selectors like +, the translator generates in-line code fi~r the common case along with the \nstandard send code. For example. -I- generates a class check to verity that both argnments are small \nintegers, native code for integer addition, and an overflow check on the result. If any of the checks \nfail, the send code is execrated. This is a space-time tradeoff justified by measurements that indicate \nthat the ovcrwhehning majority of arithmetic operations invoh'c only small integers, even though they \nare (in principle) polymorphic like all other operations in the language. EXPERIMENTAL R F, SULTS Three \naspects of our results deserve experimental validation: the use of stable and volatile context representations, \nthe use of the one-clement in-line cache and linked sends for accelerating method-lookup, and the technique \nof v-codc to n-code translation (specifically, dynamic translation). CON'I'I\u00a3XT R I':PRF~SENTATIONS The \ndramatic drop in reference counting overhead obtained by treating contexts specially has been documented \nelsewhere (e.g., [Krasqcr 83], section 19). We also obtain a striking efficiency improvement by allocating \ncontexts oil a stack, and by keeping their contents in execution-oriented form. Off`setting these advantages, \nin our implementation there is an added overhead of converting coqtcxts between volatile/hybrid and stable \nfi}rms, and of ensuring that a context accessed as a data object (either by sending it a message or directly \nwhile running a method ilnplcmentcd in a context class) is in stable form. 3'o evaluate the perfi~rmance \nadvantage of linear context. allocation and volatile rcpresentatinn, we compared our code for allocating \nand deallocating contexts against code based on a hypothetical design that used the standard object representation \nfor contexts, but did not reference-count their contcnts. This code appears to take about 8 times as \nhmg to exccutc, which would nlakc it consume 12\u00b0o of total execution time compared to 1.5% for our present \ncode. I,ess than 10CO of all co,~texts cvcr exist in othcr than volatile fibrin, l~lock contexts, which \narc created in stable fi~rm, and their cnclosing context, which must be madc hybrid so the block context \ncan refer to it, account for two-thirds of these: nearly all of the remainder arise fi'om an implcmcntation \ndetail rcgarding linkiqg togcther fixed-size stack segments. [n all of our measured examples, the time \nrcquired for thc conversion between the stable and volatile form was under 3CO of total execution time. \nIf the receiver of a message is not a hybrid context, there is no overhead for making the check bccausc \nit happens as part of the normal mcthnd-k)okup (recall that hybrid contexts appear to be objects of a \nspecial class DummyContcxt with no associated methods). Only when method-loukup fails is a check made \nwhether the receiver was actually a DummyCoqtext. In the normal operation of the system, mcssagcs are \nonly sent to contexts by thc debugger and for cleanup during dcstruction of a process, so the overall \nimpact is negligible. As di~usscd above, methods associated with context classes must be translated specially, \nso that each rcfcrence to an instance variablc chccks to makc snrc the rcccivcr is in stable form. The \ntime required for this check is negligible. IN-LINE CACIIE AND ],INKED SENDS Independent measurements \nby us and by a group at U.C. Bcrkcley confirm that the one-element in-line cache is cffective about 95% \nof the time. Measuremcnts reported in [Krasner 83] indicate that a more conventional global cache of \na reasonable size is effective about 85-90% of the time. It may be that an in-linc cache tends to lower \nthe effectiveness of the global cache, since most of thc Iookups that would socceed in the global cache \nare now handled by the in-line cache, but we have no direct evidence on this point. Adding an in-line \ncache to the simple translator described below improved overall performance by only 9%. On a benchmark \nconsisting ahnost entirely of message sends where the in-'line cache is guaranteed valid, the in-line \ncache only improved pcrforlnanc\u00a2 by 11%. 'l'llc improvement obtained by adding an in-line cache to the \noptimizing translator was also about L0%. Our original hand-analysis indicated that the overall improvement \nshould be closer to 20%, and we cannot yet account for the discrepancy. The code produced by the optimizing \n300 translator for the activate-and-return benchmark is a remarkable 47% faster than the code from the \nsimple translator with the in- line cache, s'lggesting that operations other than the overhead eliminated \nby the in-line cacl~e still dominates overall execution time. I)YNAMIC COIIE \"I'IIANSLATION Our implementation \nof the Smalltalk-80 v-machine is designed to be easily switchable between different execution strategies. \nWe have implemented a straightforward interpreter, a simple translator with almost no optimization, and \na more sophisticated translator. Both translators exist in two variants, with and without the in-line \ncache described above. Switching between strategies simply requires relinking the implementation with \na different set of modules; the price in execution speed paid for this flexibility is negligible. Our \nfirst experiment in code translation was a simple translator that does little peephole optimization and \nalways generates exactly 4 n-bytes per v-byte. Clhe latter restriction eliminated the need for the PC \nmapping tables described earlier.) Our second experiment was a translator that does significant peephole \nnptilnization. The code it generates keeps the top element of the v-machine stack in a machine register \nwhenever possible, and implements all v-instructions in-line except sends and a few rare instructions \nlike load current context. Even arithmetic and relational operations are implemented in-line, with a \ncall on an nttt-of-line routine if the operands arc not small integers. The resulting code is bulky but \nfast. To estimate the space required by translated methods, we have observed that the average v-method \nconsists of 55% pointers (literal constants, message selectot.'s, and references to global variables) \nand 45% v-instructions. Since our simple translator expands each v-code byte to 4 n-code bytes, the expansion \nfactor for the method as a whole is .55+(.45*4)=2.35. The version of the simple translator that uses \nan in-line cache simply triples the size of the pointer area, leaving room for a cached class and n- \nmethod pointer regardless of whether the pointer is a selector or something else. This expands the total \nsize of methods by a factor of (3*.55)+(4*.45)=3.45. The observed expansion factors for the optimizing \ntranslators appear in the table below. We ran the standard set of Smalltalk-80 benchmarks described in \n[Krasner 83], section 9, using each of our five execution strategies. The normalized results are summarized \nin the following table: Strategy Space Ti.me Interpreter 1.00 1.000 Simple translator, 2.35 0.686 no \nin-line cache Simple translator 3.45 0.625 with in-line cache Optimizing translator, 5.0 0.564 no in-line \ncache Optimizing translator 5,03 0.515 with in-line cache The space figure fi)r the optimizing translator \nwithout the in- line cache could be reduced at the expense of further sh)wing the code down. With respcct \nto paging behavior in a virtual memory environment, we would like to compare the following three execution \nstrategies: * Pure interpretation: only v-code exists; it is brought into main memory as needed. * Static \ntranslation: n-code is generated simultaneously with v-code. Only n-code is needed at execution time. \nN-code is brought into memory as needed, * Dynamic translation: n-code is kept in a cache in main memory: \nv-code is brought into memory for translation as needed.  Note that space taken by n-code in main memory \ntrades off against space for data. When main memory space is needed (either fi)r n-code or for da~0, \nwe have the option of replacing data pages or discarding n-code. Unfortunately, since the work described \nhere has been carried out in a non-virtual memory environment, we have no experimental results on this \ntopic. CONCLUSIONS AND RELATED WORK Perhaps the most intportant observation from our research is that \nwe have demonstrated that it is possible to implement an interactive system based on a demanding high-level \nlanguage. with only a modest increase in memory requirements and without the use of any of the special \nhardware (special-purpose mierocude, tagged memory architecture, garbage collection co- processor) often \nadvocated for such systems, and with resulting perfonnanee that users judge excellent. We have achieved \nthis by careful optimization of the observed common cases and by the plentiful use of caches and other \nchanges of representation. A related research project [Patterson 83] is investigating a Smalllalk-80 \nimplementation that uses only n-code, on a specially designed VI,SI processor called SOAR. As discussed \nabove, this implementation requires rewriting the compiler, debugger, and other tools that manipulate \ncompiled code and contexts, We expect some interesting comparisons between the two approaches sometime \nin 1984, when the SOAR implementation becomes operational. We believe the techniques described in this \npaper are applicable in varying degrees to other late-bound languages such as I,isp, and to portable \nV-code-based language implementations such as the Pascal P-system, but we have no current plans to investigate \nthese other languages. ACKNOWLEDGMENTS Thanks are doe to Mike Braca. who programmed the I/O kernel of \nour implementation: Bob Hagmann, who programmed the optimizing code translator and made many contributions \nto the design of the system: and Mark Roberts, who implemented the disk file system and virtual memory \ncapabilities. Bob Hagmann, Dan Ingalls, and Paul McCullough contributed helpfitl comments on this paper. \nThe Smalludk-80 system itself is owed to PARC SCG. Butler I,ampson gave helpful suggestions during the \nearly project design phase. R E FER ENCES [Ammann 75] Ammann, U., Nod. Jcnsen, K.. Nageli, H.. \"The Pascal \n(P) Colnpilcr Implementation Notes.\" Institut Fur Inlbrmatik, Eidgenossische Tcchni~he IIochschule, Zurich, \n1975. [Ammann 77] Ammann, U., \"On code generation in a Pascal compiler.\" Software Practice and Experience \nv7 #3. June/July 1977, pp. 391-423. [Bell 73] Bell. J. R., \"Threaded Code.\" Communications ofthe ACM, \nel6 (1973) pp. 370-372. [l)eutsch &#38; Bobrow 76] Dcutsch, L. P., Bobrow, D. G., \"An efficient, incremental, \nreal-time garbage collector.\" Communications of the ACM, October 1976. 301 [Goldberg 83] Goldberg, A., \nRobson. I)., \"Smalltalk-80: The i.anguage and its Implementation.\" Addison-Wesley, Reading, MA, 1983. \n[Goldberg 84] Goldberg. A., \"Smalltalk-80: The Interactive Programming Environment.\" Addison-Wesley, \nReading, MA,  L984. [Krasner83] Krasner, Glenn. F'd., \"Smalltalk-80: Bits of History, Words of Advice.\" \nAddison-Wesley, Reading, MA, 1983. [[.ampson 81] i.ampson, B. W., Ed., \"The I)orado: A ! ligh- Perfi,'mance \nPersonal Computer.\" Xerox PARC Report CSL-SL-I, Palo Alto, CA, January 1981. [Mitchell 71] Mitchell, \nJ. G., \"The Design and Construction of Flexible and t:fficient Interactive Programming Systems,\" Ph.I). \ndissertation. 1971, NTIS AI) 712-721, in Outstanding I)i:~sertations in the Computer Sciences, Garland \nPublishing, New York (1978). [Moon 73] Moon D., Ed., Maclisp Manual pp. 3-75 to 3-77, MIT AI Laboratnry \nTechnical Report (1973). [Moore 74] Ml~ore, C. H., \"FORTH: a New Way to Program a Computer.\" Astronomy \nand Astrophysics Supplement, # L5 (1974) pp 497-511. [Patters~m 83] Patterson, D., F.d., \"Smalltalk \non a RISC: Architectural Investigations (ProceedingsofCS 292R).\" University of California. Berkeley, \nApril 1983. [Perkins 79] Perkins, I). R., Sites, R. I.., \"Machine independent Pascal code optimization.\" \nACM SIGPI.AN Notices v14 #8 (August 1979) pp. 201-207. [Pittman 80] Pittman, T.J., \"A Practical Optimizer: \nZero-Address to Multi-AddressCode.\" M.S. thesis, University of California, Santa Cruz, June 1980. [Rau \n78] Rau. B. R.. \"Levels of Representation of Programs and the Architecture of Universal Host Machines.\" \nPrececdings of Micro- 11, Asilomar, CA. November 1978. [Richards 75] Richards, M., \"The portability of \nthe BCPI. compiler.'\" Software, Practice and Experience vl (1971) pp. 135- 146. [SCG 81] Software Concepts \nGroup, special issue on SmaUtalk. BY'I3-; Magazine, volume 6, number 8, August 1981. [XSIS 83] Masinter, \n1.. M., Ed., \"Intedisp Reference Manual,\" Xerox Special Inforrnation Systems, Pasadena, CA, 1983. [Zellweger \n79] Zellweger, P. T., \"Machine-lndependent Optimization in SOPAIPII.LA.'\" The S-! Project 1979 Annual \nReport (Chapter 8), i.awrcnce Livermore I.aboratory (1979), \n\t\t\t", "proc_id": "800017", "abstract": "<p>The Smalltalk-80* programming language includes dynamic storage allocation, full upward funargs, and universally polymorphic procedures; the Smalltalk-80 programming system features interactive execution with incremental compilation, and implementation portability. These features of modern programming systems are among the most difficult to implement efficiently, even individually. A new implementation of the Smalltalk-80 system, hosted on a small microprocessor-based computer, achieves high performance while retaining complete (object code) compatibility with existing implementations. This paper discusses the most significant optimization techniques developed over the course of the project, many of which are applicable to other languages. The key idea is to represent certain runtime state (both code and data) in more than one form, and to convert between forms when needed.</p>", "authors": [{"name": "L. Peter Deutsch", "author_profile_id": "81100238951", "affiliation": "Xerox PARC, Software Concepts Group", "person_id": "PP39071052", "email_address": "", "orcid_id": ""}, {"name": "Allan M. Schiffman", "author_profile_id": "81100270771", "affiliation": "Fairchild Laboratory for Artificial Intelligence Research", "person_id": "P328959", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/800017.800542", "year": "1984", "article_id": "800542", "conference": "POPL", "title": "Efficient implementation of the smalltalk-80 system", "url": "http://dl.acm.org/citation.cfm?id=800542"}