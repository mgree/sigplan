{"article_publication_date": "01-15-1984", "fulltext": "\n Expressional Loops Richard C. Waters MrI' Artificial Intelligence Laboratory 545 l'cchnology Square \nCanlbn'idge MA 02139 This paper proposes an expressional loop notation (XLoop) based out the ideas described \nin [16,17] which make.\u00a2 it practical to e.,;press loops as compositions of functioas. The primary benefit \nof\" Xla\u00d7)p is that it brings the powerfinl metaphor of expressions and decomposability to bear on the \ndomain of loops. Wherever this metaphor em be applied, il makes algorithms much ea'ier to, construct, \nunderstand, and modify. Xl.oop applies the expressional metaphor to loops by iutrod~:cing a new data \ntype series. A series is an ordered one dimcnsi:~nal sequence of data objects. Series are used to reprcscm \nh~termcdiate results during a computation. AlD,rithms x:h~ch would typically be rendered as iter::tive \nloops are instead represented ~:s ~mpositions of functions operating on series. For example, the program \nSOM_WCT c.):~pules the sum of the elements in a vector of integers by using ENUM_VEi:TOR tO create a \nseries of the integers in the vector and then using SUM to compute their sum. type VECT is array (INFEGER \nrange <>) of INTEGER;  function SUM_VECT(V: VECT) return INTEGER Is begin return SUM(ENUM_VECTOR(V) \n) ; end; SUH_VECT((2,3,4)) IS g The idea of using intermediate aggregate data structures in order \nto represent algorithms such as the one above in an expressional form is not a new one. For example, \nin Apl[9], arrays arc often used for this purpose. In fact, using intermediate data structures in this \nway is most properly looked at as a question of coding style, and is readily applicable to any language \nwhich provides sufficiently flexible support for aggregate data structures. Unfortunately, when mediated \nby physicul data structurcs, the expressional s:yle is extremely inefficient in comparison with conventional \niterative loops due to the time and space required to manipulate these intermediate Permission to copy \nwithout fee all or part of this material is granted provided that the copies are not made or distributed \nfor direct commercial advantage, the ACM copyright notice and the title of the publication and its date \nappear, and notice is given that copying is by permission of the Association for Computing Machinery. \nTo copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1983 ACM 0-89791-125-3/84/001/OO01 \n$00.75 data structures. In order to provide for efficient execution, XI.oop has been designed so that \na preprocessor can con vert loop expre~ions h~to efficient iterative loop code which does not manipulate \nany series dala vbjects. 'lhc principal advance made by XLoop over prior I(x~ping notalions is that, \nt\u00a2~ a considcrable extent, it makes it possible For users to have their cake and eat it too. On the one \nhand. it retain:, most of the logical advantages which accrue from representing loops as expressions. \nOn the other hand, XLoop is governed by a set of restrictiuns ~.hich guarantee that every loop expl'cssi~,n \ncan he converted into efficient ile;afix c loop code. As a rcsull, using the notation entails no rcd,cti,,n \nin run time efficiency. It is important to note that XI.oop is not intended to be applicable to every \nkind of loop. Rather. it is designed to make it particularly easy to rcprescnt ;;nd manipulate the kind \nof straightforward loops which ~:ppcar m',~t commonly in programs. By fbcu~il;g on the main concept, \nthe XLt\u00d7~p notatin:: .~ rendered semantically clean, easy to understand, and easy to execute efficiently. \nThis paper describes how Xloop could ~c intreduced as a prcprocessor-bascd cxtensk,n to lhe language \nAda I1] an,'l all of file examples are couched in tel ms of AJ;L Fto,~,ever, none ofthe b~tsic concepts \nbehind the notation have any!hing to do with the Ado language pcr se. For examl;le. Xl.oop is already \nin routine usc as a macro-based cxlcnsion to the language l..isp [19]. q!'ds inlplemenvJtion ix dc~'ribcd \nin detail in [18] which also describes a number of fcatttrcs of the notation whic'~, in the interest \nof brevity, are not discussed in this paper. The concept of exprcssionnl loops proposed here was motivated \nby observing rqmlarilics in the kinds of straightlbrward loops whidl appear in progranls most often [16]. \nOver the years, hrmy langtnage designe~:~ have also noticed various aspects el' thcse regularities and \ntherefore many of the key features of XLoop appear in one form or another in other looping conslructs. \nThe .',dvanlagc of the nolatior, proposed here This report descr, bes research done at the Ar!ificial \nIntelligence Laboratory oJ the Ma~sachusett~ Institute of Technology. Support for the laboratory's artificia? \nintelligence research has been provided in part by the Advar~ced Research Projccts Agency of the Department \nqf Defense under Office of Naval Research contract N00014-80-C-0505, in part by National Science Foundation \ngrant MCS-7912179, and in part by 1BM. is that it distills these concepts into a senlanlically complete \nwhole which is easy to understand, easy to execute efficiently, and easy to add as an extension to current \nlanguages. The Expressional Metaphor A language such e=~ Ada provides a number of facilities which together \nembody the expressional metaphor. To start with, there is the concept of functions (and operators and \nprocedures) which compute data ~alues from data values and the idea that they can be composed together \ninto expressions. Of paramount importance are the facilities which make it possible Ibr the user to define \nnew functions. In support of this, is the concept of a variable which makes it possible to use the value \ncomputed by a function in more than one place. Also important are facilities for defining generic functions. \nConditional constructs such as if and case can be included as part of the expressional metaphor, however, \nthe inclusion of more general control constructs such as looping ,and recursion lead to complications \n~hich are beyond the scope of what is referred to here as the expressional metaphor. The key property \nof expressions which makes them particularly easy to construct, manipulate, and understand is decomposability. \nThe property of decomposability has two aspects: separability and composability. Separability means that \nan expression can be broken up into separate subexpressions which can be completely understood in isolation \nfrom each other. Composability means that the behavior of the expression as a whole is simply the composition \nof the behaviors of the subcxpressions. For example, in the expression \"S0R r (ASS (X))\" the behavior \nof the SORT can be understood without having to think about where its input comes from, where its output \nwill be used. or about anything else that is going on in the expression. In the absence of side-effects, \nthe only interaction between the fimctions in an expression is the data flow between them. Typically, \nlogical separability of subexpressions is enst=red by temporal separation during execution. For example, \nin the expression above, the computation of ASS is completed before the computation of SORT begins. As \na result, it is impossible for the computation of SORT tO have any effect whatever on the computation \nof ABS and the effects of the computation of ASS on the computation of SORT can be completely specified \nby the state of the environment after the computation of ASS has been completed. Composability is ensured \nby the fact that there is no looping and each functional application is computed at most once. Recursion \nis prohibited in order to enst~re that it is always possilple to straightforwardly determine the behavior \nof the parts before determining the behavior of their composition. The goal of XLoop is to apply all \nof the features of the expressional metaphor to the domain of loops. The key difficulty in doing this \nis that it is not practical to use temporal separation as the basis for the decomposability of loop expressions. \nAs will be discussed below, at the cost of restricting its expressive power, XLoop is almost completely \nsuccessful in supporting decomposability by other means. Series The foundation for XLoop is the generic \ndata type serieswhich is described by the following generic package specification. The package does not \nhave to specify an actual implementation for series since the preprocessor converts every loop expression \ninto an iterative loop which does not reference any series. generic type BASE Is limited private: package \nSERIES_OF ta type STYPE is private: type LS ta array (INTEGER runge <)) of BASE: function LITERAL_SERIES(X: \nLS) return STYPE;  functlon LENGTH(S: STYPE) return INTEGER; The generic package takes a base data type \nand creates a series type. A series is very much like a one dimensional array. It is linear sequence \nof zero or more elements each of which must be of the b~tse data type. However, unlike arrays, accessing \narbitrary individual elemenLs of a seres is not supported. There is no difficulty in principle with having \na series of a series, however, in the interest of simplicity, this issue is ignored below. A new series \ntype can be defined by instantiating the generic package. package INTEGER_SERIES tn new SERIES_OF(INTEGER): \nuse INTEGER_SERIES: subtype INTEGERS ts INTEGER_SERIES.STYPE:  LENGTH(LITERAL_SERIES((2,3,4))) is 3 \nThe package defines a function LITERAL_SERIES which supports the concept of a literal series. It also \ndefines a number of other serics functions which are applicable to a series of any kind of object. For \nexample, the function LENGTH takes a series and returns the number of elements in it. As a convenience \nfor the user. XLoop supports two syntactic sugarings which make it easier to work with series. First, \na new data type constructor nerte= of base is provided as an abbreviation for the generic instantiation \nabove. This type constructor is similar to the array type constructor array of except that there is no \nindex specification. Second, a literal form for a series value [component, component, ...] is introduced \nin analogy with the literal form for an array value. The use ofthese forms is illustrated below. type \nINTEGERS in nerten of INTEGER; LENGTH([2,3,4]) is 3 Predefinecl Series Operations A number of standard \nseries functions (i.e., functions which either have a series argument or a series result) are provided \nby XLoop as part of the standard programming environment. For example, the following generic package \ndefines a number of functions applicable to a series of an integer type. Note that in analogy with array \nof XLoop supports the use of series of in the specification ofa fomlal generic parameter. genertc type \nINT tn range O: type INTS ta series of ZNT; wtth functton \"+\" (X,Y: INT) return INT ts <); wtth functlon \n\">\" (X,Y: INT) return BOOLEAN ta O; package INT_SERIES_OPS tm function ENUM_INTERVAL(X,Y: INT) return \nINTS; function SUM(S: INTS) return INT; function MAX(S: INrS) return INT;  As illustrated below, the \nfunction ENUM_INTERVAL takes two integers ~u+d retu ms a series of integers counting from the first up \nto the second. The fimctions SUM and MAX ulke in a series of integers and compute their sum and maximum \nrespectively. package INTEGER_OrS is new INT_SERIES_OPS(INTEGER, INTEGERS): use ]NTEGER_OPS: ENUM_INTERVAL(2,4) \niS [2,3,4] SUM([2,3,43) is 9 The following gcneric package defines series functions which are applicable \nto one dimensional arrays. The function ENUM_VECTOR creates a series of the elements in a vector. The \nfunction FILL_VECTOR fills in the initial portion of a vector with the items from a series. genertc type \nBASE is 11mlted private; type BASEV is array (INTEGER range <>) of BASE; type BASES ts series of BASE; \npackage VECTOR_SERIES_OPS ts function ENUM_VECTOR(V: BASEV) return BASES; function FILL_VECTOR(V: 8ASEV, \nS: BASES) return BASEV;  end; package VECT_OPS ts new VECTOR_SERIES_OPS(INTEGER. VECT, INTEGERS); use \nVECT_OPS ; ENUM_VECTOR((2,3,4)) is [2,3,4] FILL_VECTOR((2,3,4), [1,2]) is (1,2,4) The series functions \npresented above illustrate two major classes of series functions: enumerators and reducers. An enumerator \n(e.g., ENUM_INTERVAL) takes one or more inputs and creates a series result. A reducer (e.g., SUM) takes \none or more series inputs and reduces them to a result combining their elements. User Defined Series \nFunctions XLoop allows a user to define series functions (and series procedures) in the same way that \noperations on other data types are defined. This is illustrated by the definition of the series function \nAVERAGE which computes the average of the integers in a series. function AVERAGE(S: INTEGERS) return \nINTEGER Is begtn return SUM(S)/LENGTH(S) ; end; In addition to series functions and procedures, the \nuser can define generic series operations in the normal way. Series Variables XLoop uses standard Ada \nsyntax in order to support the declaration and manipulation of variables which hold series values. This \nis illustrated by the function parameter s above, and by the local variable t below. In the following \ndiscussion, any block which is the body of a series function or which declares a series variable is referred \nto as a series block. function AVERAGE_VECT(V: VECT) return INTEGER iS I: INTEGERS :: ENUM_VECTOR(V); \nbegin return SUM(I)/LENGTH(I); end; An imporulnt property of variables in general is that if one is \ngiven a value then this value can be used many times without having to be rccomputed. When the XLoop \npreprocessor converts loop exprcssions into itcrative loops it takes care to s,pport this I)roperty for \nseries variables. For example, while the variable t is used in two places in the program above, the computation \ncorresponding to ENUM_VECrOR(V) is only performed once in the code which results. In order to avoid duplicate \ncomputation in a series block, the preprocessor combines ~tll of tile computation in any series block \ninto a single loop. In contrast, if there are two or more loop expressions in an ordinary block then \neach one is converted into a separate loop. Mapping A nt,mber of gencric serics functions which construct \nnew serics functions are provided as part of Xkoop. The most fundamental of thcse gcneric serics functions \nis naP. The generic spccification below is one of a family of generics which operate on functions (and \nproccdurcs) of different numbers of arguments. generic type T1; type r2; type T1S ls series of TI; typu \nr2s Is sertes of T2; with function FiX: TI) return T2; function MAP(XS: TIS) return T2S; Given a function \nfrom type T1 to type T2, mapping would convert it into a function from series or Tl tO series of T2. \nThe nth element of the output of the series function crcated is computed by applying the original function \nto the nth element of the input. The Icngth of the output series is the same as the length of the input \nseries. The use of the generic function MAP is illustrated in the program SUM_ABS_VECT which sums up \nthe absolutc values of the integers in a vector. function SUN_ABS_YECT(V: VECT) return INTEGER ts function \nNAP_ABS ts new MAP(INTEGER. INTEGER, INTEGERS, INTEGERS, ABS); begin return SUM(MAP_ABS ( E NUM_VECTOR \n(V)) ) ; end; An important issue to consider is how easy it is to determine thc behavior of the series \nfimction which is creatcd by SAP. In a straightforward case like the one above, the behavior of the result \nis just the conjunction of the behaviors of the individual applications of the mapped function. This \nsimple relationship is valid because the individual applications ofthc mapped function do not interact. \nThings would be more complicated if the mapped fi,nction maintained any kind ofstatc value. XLoop is \nrestrictcd by outlawing thc mapping of functions which maintain state. In particular, mapped functions \nare prohibited from assigning to any free variables. This restriction guarantees that. in the absence \nof side-effects, the simple relationship above always holds. The section after next presents several \ngeneric series fimctions which create series functions which maintain ~m internal state. Implicit Mapping \n MAP is by far the most commonly used series operation. In order to facilitate its use. Xkoop provides \na syntactic sugaring which makes its use implicit. Whenever a function which returns a result of type \nr is tzsed in a situation where a result of type series of x is required then the function is mapped \nto create a series function whose output is of the appropriate type. The same transfomlation is applied \nwhenever a function (or procedure) which expects an input of type r is ~pplied to a value of type series \nof T. This process is illustrated in the following version of the program SUM_ABS_VECT. functlon SUM_ABS_VECT(V: \nVECl) return INTEGER is  begin return SUM(ABS(ENUM_VECTOR(V) )) ;  end; In the example, the implicit \nmapping process maps 'the application of ASS. Implicit mapping is also applied to variables and constants \nif they appear in a context where a series is required. This is done by mapping a zero argument function \nwhose body is the variable or constant in question. An example of this is shown in the program below \nwhich adds a parameter N to each element of a vector. In the body, both \"+\" and N are implicitly mapped. \nfunctlon INC_VECT(V: VECT, N: INTEGER) return VECT is begin return FILL_VECTOR(V, N+ENUM_VECTOR(V)); \n end; Implicit mapping is also applied to quasi-function:d operations such as array referencing and \nrecord component selection. However, in order not to violate the prohibition above, implicit mapping \nis not applied to assignment. Neither is it applied to control constructs or any other kind ofstatement. \nInitialization and Epilog Computation Consider the series block in the program FUN below. This program \nis contrived to illustrate the fact that a series block can be divided into three zones of computation: \nat-sta~l code which is pertbrmed before the rest of the computation gets underway, at-end code which \nis pcrfomwd after the main computation is completed, and map code which is performed in between. function \nFUN(V: VECT, N: INTEGER) return INTEGER IS begin return SUM(ABS(ENUM_VECTOR(V(I..N))))/N;  end; The \nprogram computes the average of the absolute values of the elements in a slice of a vector. The selection \nof the slice is performed at the start of the loop. The fimction ABS is mapped over the elements of the \nslice. The division by U is pcrformed after the resulting series has been summed. The series function \nENUM_VECtOR interfaces between the at-start code and the map code. The series function SUM interfaces \nbetween the map code and the at-end code. Usually, the nesting of expressions makes it clear which zone \nof computation a given function is in. However, this may not always be the case. In addition to MAP, \ntwo generic series procedures are provided which make it possible for the user to explicitly specify \nwhich zone is appropriate. The generic procedure AT_START specifies that a procedure is to be executed \nbefore a loop starts. AT_END specifies thal a procedure is to be executed after a loop terminates. generlc \nwlth procedure INITIALIZATION()| procedure AT_START() ; generlc wtth procedure EPILOG(); procedure AT_END(); \n The use of AT_START and AT_END is illustrated by the following definition of the series procedure WRITE_FILE. \nThis procedure writes a series of integers into a file. AT_START is used to open the file, WRITE is mapped \nover the series of integez~, and AT_END is used to close the file. WRITE_FILE would be conceptually much \nless useful if it did not include the actions of creating and closing the file. procedure WRITE_FILE(NAME: \nSTRING; S: INTEGERS) le package INTEGER_IO ts new INPUT_OUTPUT(INTEGER): use INTEGER_IO; FILE: OUT_FILE; \nprocedure OPEN_FILE() te begin CREATE(FILE. NAME); end; AT_START_OPEN_FILE Is new AT_START(OPEN_FILE); \nprocedure CLOSE_FILE() Is begin CLOSE(FILE); end; AT_END_CLOSE_FILE is new AT_END(CLOSE_FILE); begln \nAT_START_OPEN_FILE; WRITE(FILE, St; AT_END_CLOSE_FILE; end; Reduction, Enumeration, and Generation This \nsection describes three generic series functions which create series functions which have internal state \nvariables. The generic series function REDUCE iS used to construct reducer series functions such as SUM. \ngeneric type VAL is prlvete; type BASE is prtvete; type BASES Is serles of BASE: INIT: VAL; wlth function \nSTEP(STATE: VAL B: BASE) return VAL; function REDUCE(S: BASES) return VAL; REDUCEcreates a series function \nwith an internal state variable. The state is initialized to the value INIT. The nth value of the state \nis computed by calling the function STEP with the prior value of the state as its first argument and \nthe nth element of the series input as its second argument. When the input series is exhausted, the final \nvalue of the state variable is returned as the result lfthere are no elements in the series input then \nthe value INIT will be returned. The use of REDUCE is illustrated by the following definition of SUM. \nfunction SUM is new REDUCE(INTEGER, INTEGER, INTEGERS, O, \"+\");  Enumerator seres functions such as \nENUM_INTERVAL carl be constructed by using the generic series function ENUMERATE. genertc type BASE \nts prtvete; type BASES ts sertes of BASE; wtth functton TEST(B: BASE) return BOOLEAN; with function STEP(B: \nBASE) return BASE; function ENUMERATE(INIT: BASE) return BASES; Like REDUCE, ENUMERATE creates a series \nfimction with an internal ~ate. The state is initialized to the v~ue INIT. Each successive value of the \nstate is computed by applying the function STEP to the prior state value. The function TEST is applied \nto each state value and computation stops the first time this function returns the result TRUE. 'l'he \noutput series consists of the values of the state in order, starting with INtr, up tO but not inch,ding \nthe first value for which TEST returns the value TRUE. The use of the generic series function ENUMERATE \niS illustrated by the following definition for the series function ENUM_VECTOR. The auxiliary function \nDONE (which is used ,as the temlination test for the enumeration) is defined inside of the series function \nso that it can refer to the upper limit of the vector passed to the series fimction. An em,memtor is \ncreated which counts up to this value. This enumerator is applied to the lower limit of the vector passed \nto ENUM_VECTOR tO create a series ofindecies. Array referencing is mapped over this series to create \na series of the elements in the vector. functton INC(I: INTEGER) return INTEGER |I begin return I+1; \nend; function ENUM_VFCTOR(V: VECT) return INTEGERS tl; FINAL: INTEGER := V'LAST; function DONE(I: INTEGER) \nreturn BOOLEAN tl begin return I>FINAL; end; functton ENUM_INDECIES ts new ENUMERATE(INTEGER. INTEGERS, \nDONE, INC); begin  return V(ENUM_INDECIES(V'FIRST)); end; XLoop provides a generic series function GENERATE \nwhich is identical to ENUMERATE except that it has no TEST argument. As a result, the series fimction \ncreated can never tenninate :rod creates an infinite series of values. This is ofl.en convenient in situations \nwhere other series fimctions in the loop expression will temfinate the loop. GENERATE makes it possible \nto create series functions which enumerate as many elements as are needed by the rest of the computation \nwithout the overhead of doing temlination testing. Due to the fact that they use a state variable, it \nis not trivial to deduce the behavior of the series functions produced by REDUCE, ENUMERATE,and GENERATE. \nIn order to do so, one must solve a rcci,rrence equation involving the state variable. In order to keep \nthis process as simple ~ts possible, :ill three of these generic series fimctions are prohibited form \noperating on functions which maintain their own state variables. The generic operations MAP, AT_START, \nAT_END, REDUCE, ENUMERATEarid GENERATE are a fundamental part of XLoop. Together, they can he used to \ndefine all of the other series operations, while they themselves cannot be defined in terms of other \nconstructs. Rather, they are operationally defined by the XLoop preprocessor. EFficient Execution When \ndesigning X Loop it was felt that the issue of efficiency could not be ignored. As a result.; it W:LS \ndesigned fronl the beginning with the idea of using a preprocessor to convert all loop expressions into \niterative loops, iFhe notation was restricted wherever necessary in order Facilitate conversion to efficient \ncode. The iterative loops which are produced by the preprocessor have several advantageous properties \nwith regard to efficicncy. Eoch series is cx)mputed one element at a time. and only a single element \nof each series exists in memory at any one time. There is no duplication of code. For example, if there \nis only one call on a given series function in a loop expression, then there is only one instance of \neach of the pieces of code which come from that series function in the iterative code produced. The code \nproduced does not contain any flag variables or intemaediate buffers which are not explicitly specified \nby the series functions in the loop expression being converted. The next two sections give a brief outline \nof the conversion process used by the XLoop preprocessor. The process is described in more detail in \n[16.18]. \"llac Conversion Process When a loop expression is encountered, it is first parsed in order \nto locate all of the serics functions in it. As part of the parsing process, implicit mapping of fimctions \nis performed. The loop expression is then converted into an iterative loop by combining all of the series \nfimctions in it together and then rendering this function as a kx)p. The following two functions show \nthe result of the conversion process. functton SUM_VECT(V: VECT) return INTEGER t$ begtn return SUM(ENUM_VECTOR(V) \n) ;  end: functton SUM_VECT_ITER(V: VECT) return INTEGER ts I ,FINAL,SUM: INTEGER; begin I := V'FIRST; \n--from ENUM=VECTOR FINAL := V'LAST; --from ENUM_VECTOR SUM := o1 --from sum loop Ir I>FINAL then exit; \nend 11'; --from ENUM_VECIOR X := V(1); --from ENUM_VECfOR I := I+I; --from ENUM_VECTOR SUM := SUM+X; \n--from SUM end loop: return SUM; --from SUM  end; The body of the program SUM VECT_I rER shows the kind \nof code which is produced when the preprocessor converts the loop expression in the program SUM_VECT. \nihe loop which results is composed of a number of scpamte pieces of code which are specified by the series \nIhnctions sum and ENUM_VECTOR. The comments indicate where each line comes from. Compositional Combination \nThe central theme behind the conversion process is a change of point of view. ll~e most straightfonvard \nway to think of the evaluation of a loop expression is ,as the computation of one series from ,another \nuntil the final result is computed. In cont,','tst, the conversion process evaluates a loop expression \nby combining series functions together. Essentially. it computes one series function from another until \nit has derived a single function which directly computes the result of the entire expression. The key \nstep in conversion is thc way a composition of series functions such ,as \"A(B(... ))\" is handled. The \ntwo functions are combined togethcr into a single scries function by the process of compositional combination, \nlhe new series function which results has the ~lille net computational effect ~LS the original composition \nbut does not use any series ~alues in its internal computatior,. In addition, the rcsulting fimction \ntemlinates as soon as either of the initial functions would have terminated. Internally, each series \nfunction is represented as a three part structure containing the code associated with the three zones \nof computation. The at-start, map, and at-end code Ibr the new series fimction is derived by concatenating \nthe corresponding parts of 8 and A. The series data flow from 6 to A is implemented by ordinary data \nflow carrying single series elements from the parts of B to the parts of A in the new fimction. The result \nof this process can be seen in tile program SUM_VECT_ITER in the previous section. The process of compositional \ncombination produces a vast improvement in efficiency. However. it entails a radical change in execution \norder from simple nested execution to interleaved execution. Instead of executing B completely before \nbeginning the execution of A, the combined function intern~ixes the execution of the original functions \nso that each cycle of computation executes some of 13 followed by some of A. As will be discussed in \nthe next section. Xl.oop has to be significantly restricted in order to ensure that this is a correctness \npreserving change. Restrictions on the Notation l'he most important restriction placed on Xl.oop is that \nevery series function is required to have the property of registration. This property has two parts. \nI-'irst, it requires that any function which creates a series must create the series elements in order, \none at a time, with every execution of its map code producing exactly one element. Second, it requires \nthat any fimction which uses a series must use the series elements in order, one at a time, with every \nexecution of its map code using exactly one element. A function does not have to actually use all of \nthe elements ofan input series, however, it cannot continue to operate if an input series has run out \nof elements. The registration property is enforced by the fact that the generic series fimctions NAP, \ntNUMEaATC, etc. are incapable of creating a series function which violates registration. The fact that \nevery series function in a loop expression has the registration property implies that each series clement \ncreated can only be used on the same cycle in which it was created. This property ensures that each series \nelement created need only be retained for a single cycle of the computation. As a result, ordinary variables \ncan be used to implement the data flow of series including that which ~is mediated by series variables. \nThis is an important underpinning Ibr the correctness of compositional combination. Note that if series \nelements were allowed to be used on cycles of the computation other than the ones they were created on. \nthe resulting loop would have to contain buffers in order to communicate these elements from one cycle \nto ~mother. The prohibition, discussed above, against mapping or reducing any function which ,assigns \nto a free variable is nece~'~ry in order to ensure that. in thc absence of side-effects, series functions \ncannot interact in any way other than through the data flow between them and therefore will not be adversely \ncffected by the change in execution order introduced by compositional combination. Unfortunately, compositional \ncombination is not correctness preserving if side-effects are present There are two kinds of problems, \ncaused by side-effects. First, they may cause series functions in a loop expression to interact with \neach other preventing them from being understood separately. This problcm should not re=dly bc countcd \nas a failing of XL.oop in particular since intcraction via sidc-effects bctwecn the functions in an ordinary \nexpression also causes the break down of the expressional metaphor. The second problem with side-effects \nis that the change in exccution order potentially changes the net effect of side-cffects. XLoop tries \nto lessen the impact of this problem two ways. First, the fact that every loop is always transformcd \nby the introduction of interleaved execution is made a prominent visible aspect of XLoop. The user can \nthen use this fact as the basis for analyzing the result of sidc-effecL~. Sccond. thc convcrsion process \nis carried out in a very regular way in order to facilitate the understanding ofside-effccts. In particular, \nthe user can depend on the fact that all of the code he writes will be cxecutcd exactly once on each \ncycle of the resulting loop, and exactly in the order he wrote them in. A number of less important restrictions \nare required in order to guarantee that the conversion process can always be applied to a loop expression. \nFor example, all instances of series variables and series functions must be identifiable by the preprocessor. \nIn addition, all series functions are expanded inline and therefore tl,eir definitions must be available \nat the time of conversion. This means among other things that Xl.oop cannot support the idea ofcomputing \na series function at run time. Cotermination Tile process which causes the result of the compositional \ncombination ofA(B(... ) ) tO be terminated as soon as either A or s would have terminated is referred \nto as cotermination, if 0 terminates first, then cotcrmination is clearly the correct thing to do since \nregistration requires that the execution of A must terminate as.soon as its input runs ouk If A stops \nfirst then things are more complicated. However, cotermination has many practical advantages in this \nsituati.,3n. First, if cotcrmination were not applied then the iterative loop code produced would be \nless efficient because a flag variable would I~we to be introduced in order to allow the execution of \n0 to c~)ntinue without t.~mtinuing the execution ofa. In addition, it can be argued that terminating \ns prematurely is a useful efficiency measure. Continuing to execute e would only waist time since A will \nnot use any additional series elements computed by 13. If B is an enumerator which would othenvise produce \nan infinite series, then cotermination is particularly important. In fact. in the absence of cotermination, \ninfinite series would be of little practical value. Unfortunately. cotem~ination violates the expressional \nmetaphor because it means that some properties of series fimctions (e.g.. their tcrmination) cannot bc \ndetermined solely in isolation. Fortunately. there is a usefid middle ground with regard to the property \nof decomposability. As discussed in [16.18]. as long as no statcnrcnts are made which depend on a specific \nminimum length for ,'my series, then any statement which is true about a series function in isolation \nwill be true when the function is composcd with other functions in a loop expression. For example, it \nis all right to say that ENUM_VECTOR enumera~tes successive ele,nents of a vector starting with the first \none. it is even all right to say that it will produce a sequence no longer than the vector. However. \nit is not all right to make any claim about may minimum number of vector elements which defi~fitely will \nbe enumerated. Given the kind of statements which can be dependably made, a great deal can be detcrnfined \nabout a loop expression by using strait;ht composition, in order to go beyond this and make statements \nabout termination, global reasoning is required. Since enumerators are the only series fimctions which \ncan cause termination this reasoning can focus exclusively on them. For example, if there is only one \nenumerator in a loop expression, then the expression as a whole terminates if ,and when the enumerator \ndoes. Series Functional Combinators The process of compositional combination is an example of a series \nfunctional combinator. It takes in a pair of series functions and computes a new series function. XLoop \nsupports a number of other series functional combinato~. For example, the combinator R[STRICl takes an \nenumerator and a predicate and creates a new enumerator whose output consists only ot\" the elements of \ntile output of the original cnulnerator which satisfy the predicate. The combinator APPEU0 takes in two \nor more enumerators and creates an enunterator whose output is a concatenation of the outputs of the \noriginal enumerators. These combinators are syntactically treated ,as generic series functions which \ntake series functions ,as formal parameters. Like the basic generic series functions (MAP, ENUNERATE, \netc.) series functional combinators ~,re fundamental in that they must be supported directly by the preprocessor \nand cannot be deftned by the user. Many kinds of series function:d combinators can be introduced into \nXLoop. However, care must be taken to make st, re that they do not violate the registration property. \nFor example, aESralCr works by creating a new enumerator which uses the map code of the old enumerau)r \n~ts a subloop. Each time the map code of the new enumerator is executed it executes the map code of the \nold ent,merator repetitively until a value satisfying the predicate is produced. Notice that if the old \nenumerator had a series input the resulting ent,merator would violate registration because it would try \nto use several elements fro,n this input on each cycle. Therefore, in order to satisfy rcgistration, \nthe series fi,nction argument to RESTRICT must be prohibited from referring to any series. Series functional \ncombinators add a new dimension to XLoop because they make it possible to perform operations which the \nregistration property prohibits series functions from performing. For example, it is not possible to \nwrite a series function which will take in the serics [z.-1,a] and select only the positive elements \nreturning the series [1. z] because the second element of the output is computed from the third element \nof the input. However. one can use the combinator RESTRICT I(3 take all enumerator which produces the \nseries [t,-l,2] and create an enumerator which produces the series [ 1,2 ]. Langt, age Independence \nThe presentation of XLoop above was couched in terms of Ada. However. none of the ideas behind the notation \nare inherently dependent on ,'my specific language. In fact, it is somewhat misleading to call XLoop \na notation because it is not tied up in any particular set of keywords or syntactic structures. Rather, \nit is a set of concepts and there is no fundamental re`a~n why these concepts could not be implemented \nas a preprocessor b,'tsed extension to ahnost any language. For example, under the name LEtS (pronounced \n\"/et es\"). XLoop has been implemented as a macro-based extension to Lisp (see [18]). Consider what the \nbasic concepts behind XLoop are. To start with, there are two themes which underlie the notation: the \nexpressional metaphor and the desire for efficiency. The expressional metaphor is supported be several \nspecific facilities: the series data type. series variables, series blocks, and series functions (including \nuser definable ones). In addition, generic series fiinctions provide the basis for constructing new series \noperations. Experience has shown that implicit mapping is a crucial conve~,ience. Efficiency is supported \nby the preprocessor. An important part of. this is the set of restrictions which have to be en forced. \nExtending a typical language to support XLoop is a relatively straightforward matter. Each feature of \nXLoop is syntactically introduced in analogy with preexisting language features. Series are analogous \nto arrays. Series variables and blocks are analogous to ordinary variables and blocks. Series functions \nare defined and used in analogy with ordinary functions. Implicit mapping requires no syntactic st,pport, \nit only effects the way that the preprocessor interprets loop expressions. One difficulty is that many \nlanguages do not support the idea of a generic function or macro. If this is the case. then the language \nwould have to be extend to allow the representation of the generic series functions. Note that in order \nto extend a language to support XLoop one does not have to modify the compiler (or interpreter) for the \nlanguage at all. This is because XLoop is completely supported by the preprocessor. The preprocessor \ntakes in programs which may. or may not, have an extendcd syntax and produces programs which are represented \nentirely in the base language. Comparison With Other Loop Notations The next few sections compare XLoop \nwith a number of other notations. Each section focuses on three issues: expressiveness, efficiency, and \nfaithfulness to the expressional metaphor (in particular, the support for the logical separability of \nseries functions). Physical Series To a large extent the expressional metaphor is a question of style. \nLoops can be written in expressional style in many languages. This can be done by using some ordinary \naggregate data structure as an explicit representation for a series. Loops are then represented as compositions \nof functions which operate on these physical series. The most straightlbrward way to represent a series \nexplicitly is as a linear data structure (such as an array or list) containing a physical representation \nfor each individual dement of the series. The term physical series will be used to refer to this approach. \nOther approaches to representing series explicitly will be discussed below. The physical series approach \ncan be applied to a wide variety of languages. The only problem is that many languages make it difficult \nto dynanfically create aggregate data structures whose length is not known at compile time and return \nthem from functions. When it is applicable, the physical series approach is completely ~fithful to the \nexpressional mmaphor because loop expressions arc directly executed its garden variety expressions. Using \nphysical series is also more expressive than XI,oop. Most kmguages support fimctions, variables, and \nuser definition of new Ihnclions. These facilities are therefore available for constructing functions \noperating on physical series. If a language supports thc definition ofgeneric fimctions or macros then \nthese Facilities will also be available. Going beyond this, the physical series approach is not limiled \nby the kinds of restrictions which are placed on XLoop (e.g., registration). The one area where XLoop \nis inherently more expressive is in its support for computation with infinite series. This is not supportable \nas part of the physical series approach because a physical data object cannot hold an infinite series \nof values. The language which is most heavily identified with the physical series approach to wdting \nloops is Apl [9]. It is common practice in Apl to represent looping algorithms as compositions of operations \non arrays. Apl provides a variety of powerful array operations and allows the user to define arbitrarily \ncomplex functions on arrays. The only areas where the expressiveness of Apl is limited is that it does \nnot support either infinite arrays or generic functions. The user cannot define functions with functional \narguments. In addition, though, Apl has a number of operators which are described as taking functions \nas arguments, these operators are not true generics because they only accept literal instances of the \npredcfined operators as functional arguments. As a result, these operators should more properly he looked \nat as part of a particularly orderly nmning convention for a class of built in functions. As discussed \nabove, the fatal flaw in the physical series approach is that it is extremely inefficient. Large mnounts \nof time and space are wasted manipulating intermediate data stn~ctures which would not have to be created \nat all if an iterative looping style were used. Lazy Evaluation and Coroutines An interesting way to \ntry and maintain the simplicity of the physical series approach while rendering it more efficient would \nbe to use lazy evaluation [4,6] or explicit coroutines [7] in order to facilitate more efficient computation \nwith series. The basic idea here is to represent a series by a coroutine which is capable of producing \nsuccessive elements of the series when requested. This approach can be more efficient in two situations. \nFirst, if the series being computed are large, the coroutine approach saves space. Second. if it turns \nout that only the first few elements of a series are actually used in further computation then the coroutine \napproach can save time by not having to compute the rest. An additional advantage of the coroutine approach \nis that infinite series can be easily represented. Unfortunately, in the kind of simple loops XLoop is \ndesigned to represent almost all of the elements of intennediate series are used in Ihrther computation. \nIn this situation the coroutine calling overhead causes the coroutine appro~mh to be slower than computation \nwith physical series. In any case, the coroutine approach is much less efficient than an iterative loop \nwould be. In face any approach which manipulates series explicitly is less efficient than iterative loop \ncode which does not have to manipulate series at all. An interesting aspect of\" the coroutine approach \nis that it implicitly entails a switch from simple nested execution to interleaved execution. In addition, \nthe computation of seres elements only on demand is similar to cotermination. As a result, the coroutine \napproach has many of the same difficulties supporting the expressional metaphor that XLoop has. In order \nto be faithful to the metaphor many of the same restrictions would have to be applied. For example, one \nwould have to make sure that the execution of one coroutine could not alter the state maintained by another \ncoroutine. An additional problem with the coroutine approach is that since seres elements are computed \nonly on demand, the order in which computations are performed can be a function of the input data. This \ncan make it exceedingly difficult to figure out the interaction of side-effect operations. Note that \ncoroutines are inherently a much more powerful concept than expressions. For example, the coroutine language \nof Kahn and MacQueen [7] makes it possible to express arbitrarily complex parallel algorithms. Using \ncoroutines merely to represent expressions severely under utilizes them and backs them into a corner \nwhere they arc not particularly efficient. Partial Conversion A more fruitful way to try and maintahl \nthe simplicity of the physical seres approach while rendering it more efficient is to use partial convel~ion \nto iterativc lbrn~. The basic idea here is that if the user writes a convoluted loop expression which \ndoes not correspond to an itcrative loop then little is lost by failing to transform it. On the other \nhand if a loop expression does correspond to an iterative loop than it can, in principlc, be converted \nto this form with the concomitant gain in efficiency. The premier example of this approach has beea the \nwork on compilers for Apl [2.5]. Optimizing Apl compilcrs attcmpt to locate array expressions where the \narrays are being used merely as intermediate series, and then eliminate the actual computation of these \narrays. Once an expression corresponding to the kind of simple loop representable by XLoop is located, \nit is easy :o eliminate the intermediate arrays. (Wadler's Listless Transformer [15] pursues a similar \napproach for compiling a Lisp-like language.) The biggest barrier to applying the partial conversion \napproach is that it is not that easy to do. The only reason to pursue partial conversion is that the \nnotation supports some features which cannot be converted. This raises a whole new problem --identifying \nwhat parts of what loops can be converted. This is a very hard task in its own right and attempts to \nsolve it have only been partially successful to date. Assuming for the moment that a converter could \nbe constructed which would succeed in identifying and transfornling every convertible subexnression, \nthere are still several inherent problems with the partial conversion approach. First, considerable overhead \nmust be introduced ;nto a loop in order to interface with each subexprcssion which cannot be converted. \nTo start with, code (and memoq, buffers) have to be added in order to construct physical series objects \nfor each series used by the unconverted subexpression. Similar steps have to be taken to decode the physical \nseries which come back from the subexpression. Unfortunately, the series going to or from the subexpressions \nin question are not the only ones which have to be temporarily converted to physical tbrm. Any series \nwhich is created before the subexpression and used after it must also be buffered across the execution \nof the subcxprcssion. As a result of all this, the presence of a single unconvertable function call can \ndrastically degrade the efficiency of a loop expression. Second. as discussed above, in the presence \nof side-effects, conversion is not a correctness preserving prtx:ess. This does not present a severe \nproblem for XLoop because it can simply specify that everything will be transformed and therefore the \nuser must analyT.e his side-effects from that point of view. Partial conversion cannot take this approach \nbecause it cannot guarantee that everything can be transformed. As a result., one has to refrain from \nconvening any subexpression producing side-effects (including input/output) even if it is otherwise convertible. \nIn summary, there arc two basic difficulties with the partial conversion approach. First, additional \nresearch has to be done before it can reach its full potential. Second, if a user is concerned with efficiency \nthen he must be very careful about the loop expressions he writes. As a practical matter this means that \nhe must be aware of, and follow, the same kinds of restrictions which are placed on XLOOp. Worse than \nthis, it is not sufficient for the user to be aware of what kinds of loop expressions are logically convertible, \nhe must be aware of what kinds of loop expressions the converter is capable of recognizing as convertible. \nLoop Constructs The discussion so far has not talked about traditional looping constructs at all. There \nhave been a number of developments in that area which are relevant to Xkoop. A key motivation behind \nXLoop is that most looping algorithms are built up out of stereotyped fragments of looping behavior and \ntherefore loops are easier to underst,.ald, construct., and modify if these fragments are expressed as \neasily identifiable syntactic units (e.g., series functions). This basic idea has been at least partially \nrecognized by many language designers and many looping constructs allow at least some loop fragments \nto be specified as separate units. For example, most DO constructs support the concept of enumerating \na series of integers. Note that these constructs do n~ enforce logical separability of this loop fragment \nunless (like Ada FOR) they prohibit the user from altering the enumeration variable in the loop body. \nIf Iogicfil separability is not enforced, then it can be arbitrarily difficult to verify that simple \nenumeration is actually occurring. If simple enumeration is not occurring, then the stereotyped syntactic \nrealization of the enumerator can be more misleading than helpful. Such constructs are only a small step \nin the direction of XLoop because they do not in general, support any other looping fi'agment, lterators \nin CLU [8] and generators in Alphard [13] support generalized enumerators and allow a programmer to define \nnew named enun~crators. However. they do not support any other kind of looping fragment. The Lisp to \nconstruct [19] allows the user to rcprcscnt a wide variety of Ioopin 8 fragments, but does not allow \nthc user to define nanlcd fragments nor enforce the logical separability of fragments, The MacLisp macro \nLOOP [3] (which is based on the iterative statemcnts provided as part of the Intcrl,isp Clisp facility \n[14]) supports all kinds of looping fragments and the user can define new named fragmcnts (though this \nis rather cumbersome in practice). In addition, unlike the constructs above, t_0oP supports the comhination \nof fragments in a variety of ways. Unfortunately. LOOP is not based on the idea of the expressional mcutphor \nand loop fragmcms arc not combined by functional composition but rather by using an ad hoc pseudo-English \nsyntax. Morc fimdanlcntally, LOOP does not do anything to cn force the logical separability of fragments. \nIn general, standard looping constructs produce efficient code. However. while they provide varying amounts \nof support for the concept of loop fragments, they provide little support for the expressional style, \nand even less support for the true logical separability of fragments. Hibol and Model The language Hibol \n[11,12] is the oldest language which both supports the idea of a series and which is sufficiently constrained \nso that it is completely convertible into efficient loop code. It is a very high level business data \nprocessing, language based on the concept of a flow (which is basically equivalent to a series). It is \nstrongly oriented toward loop expressions (there is no other way to specify a loop) and relies heavily \non the concept of implicit mapping. The body of each Hibol program is a nonprocedural set of loop expressions \nspecifying computations on data files. (The language Model [10] though somewhat more powerful is very \nsimilar to Hibol.) From the point of view of this discussion the primary weakness of Hibol is that it \ndoes not provide much support for the exprcssional metaphor. First, it supports only a small number of \nbuilt in series functions and does not allow the user to defne new ones. Second, it supports only two \nof the generic series operations: implicit mapping and restriction. Another difficulty with Hibol is \nthat the concept of expressional loops is embedded in a language which is oriented solely towards business \ndata processing. Generator Expressions Wilc [21] has developed an interesting approach (generator expressions) \nto expressional loops based on his earlier thesis work [20]. In this approach a series is represented \nby a function (caUed a generator) which is capable of enumerating the elements in the series. There are \ntwo ways to operate on generators. First, generators can be operated on by built in and user defined \nfunctions. Second, a set of special combinators (similar to XLoop combinators) are provided which can \nbe used to compute one generator function from another. Whenever a function is applied to a generator, \nthe generator is transformed into a physical series before being passed to the function. In this situation \ngenerator expressions are an example of the physical series approach with all its attendant power and \ninefficiency. The combinators support an entirely different mode of operation. The combinators provided \ninclude the XLoop combinators, most of the XLoop generic series functions, and a few other operations, \nif the user writes an expression in terms of these combinators, the expression is processed at compile \ntime and converted into an iterative loop in basically the same way that XLoop expressions are converted. \nNote, that since some expressions involving generators are converted into iterative loops and some are \nnot. generator expressions are an example of a partial conversion approach with all its attendant problems \nand inefficiencies. An unfortunate limitation of generator expressions is that users are not allowed \nto define new combinators. As a result, in order for an expression to be converted into an iterative \nloop, it must be built up solely by using the built in combinators, A logical problem with generator \nexpressions is that they are not sufficiently restricted in order to ensure the separability of generator \nsubexpressions. In particular, the combinators operate in much the same way as XLoop combinators and \nentail a shiR from temporal separation of execution to interleaving of computation. However. the kinds \nof operations which can be performed by generators are unrestricted. As a result, generator subexpressions \ncannot be reliably understood in isolation. In addition, no attempt has been made to restrict the combinators \nin order to ensure that efficient code will be produced as a generator is progressively modified by a \nsequence of combinators. For example, if a generator is stored in a variable aJtd then used in two different \nplaces in a generator expression all of the code associated with it will appear twice in the generator \nwhich results from the expression, Acknowledgments Both this paper and the design of XLoop have benefited \nfrom helpful comments made by many people. In particular, I would like to thank C. Rich, D. Chapman, \nE. Ciccarelli, and G. Faust for making a number of useful suggestions on form and content, and for being \nthe first users of the Lisp implementation of the notation. I would like to thank A. Duncan for his suggestions \non the best way to fit the notation into Ada. References [1]J.G.P. Barnes, \"Programming in Ada', Addison-Wesley, \nLondon, 1982. [2]T.A. Budd. \"An APL Compiler\", Univ. of Arizona, Dept. of Comp. Sci. \"i'R 81-17, October \n1981. [3]G. Burke and D. Moon, \"Loop Iteration Macro\", MrI'/I.CS/rM-169, July 1980. [4] D.P. Friedman \nand D.S. Wise, \"CONS Should Not Evaluate Its Arguments\", Indiana Tech. Rep. 44, Nov. 1975. [5]L.J. Guibas \nand D.K. Wyatt, \"Compilation and Delayed Evaluation in APL', in Proc. 5th ACM POPL Conf., Sept. 1978. \n[6]P. Henderson and J.H. Morris. \"A Lazy Evaluator\", presented at the SIGPI.AN-SIGAC1 Syrup. on Principles \nof Programming I_anguages. Atlanta, Jan. 1976. [7]G. Kahn and D.B. MacQueen, \"Coroutines and Networks \nof Parallel Processes\", in 1977 Proc. IFIP congress, North-Holland, Amsterdam The Netherlands, 1977. \n[8] B.H.l.iskev, el. al., \"CLU Reference Mamlal\", Lecture Notes in Computor Science. G. Goos and J. Hartmanis \neditors, V114 Springer..Verlag, New York, 1981. [9] R.P. Potivka and S. Pakin, \"API.: \"llle Language \nand Its Usage\", Prentice-Hall, Englewood Cliffs N J, 1975. [10]N.S. Prywes, A. Pnueti, and S. Shastry, \n\"Use of a Non-Procedural Specification I.anguage and Associated Program Generator in Software Development\", \nACM TOPI,AS, VI #2, October 1979, pp 196-217. [11]G.R. Ruth, \"Data Driven I.oops'. M1T/I.CS/I'R-244. \n1981. [12]G.R. Ruth. S. Alter, and W. Martin, \"A Very High 1.evel Language for Business Data Processing\". \nMrr/LcsfrR-254, 1981. [13] M. Shaw and W.A. Wulf, \"Abstraction and Verification in AI.PIIAP, I): Defining \nand Specifying Iteration and Generators\", CACM V20 pp 553-564, Aug, 1977. [14]W. Teitelman, \"Interi.isp \nReference Manual\", Xerox PA RC, 1978, Ll 5] P. WadJer, \"Applicative I.anguages, program Transformation, \nan~i I.ist Operators\", PhD Thesis. Carnegie-Mellon Univ.. 1982. [16] R,C. Waters, \"Automatic Analysis \nof the I.ogical Structure of Programs\". Ml'l'/AI/'I'R-492, December 1978. [17] R.C. Waters, \"A Method \nfor Analyzing 1.oop Programs\", IEEE Trans, on Soft. Eng,, V5 #3, May 1979. [18]R.C, Waters, \"LETS: an \nExpressional Loop Notation\", MIT/AIM-680, October 1982. [19] D, Wcinreb and D. Moon, \"Lisp Machine Manual\", \nM1T Cambridge MA, July 1981. [20] I).S. Wile. \"A Generative. Nested-Sequential Basis for General Purpose \nProgramming Languages\", PhD Thesis, Carnegie-Mellon Univ., November 1973. [21] I').S. Wile, \"Generator \nF'.xpressions\", USC Information Sciences Instittae Technical b~,eport ISI/RR-83-116, 1983.  10 \n\t\t\t", "proc_id": "800017", "abstract": "<p>This paper proposes an expressional loop notation (XLoop) based on the ideas described in [16,17] which makes it practical to express loops as compositions of functions. The primary benefit of XLoop is that it brings the powerful metaphor of expressions and decomposability to bear on the domain of loops. Wherever this metaphor can be applied, it makes algorithms much easier to construct, understand, and modify.</p> <p>XLoop applies the expressional metaphor to loops by introducing a new data type <italic>series.</italic> A series is an ordered one dimensional sequence of data objects. Series are used to represent intermediate results during a computation. Algorithms which would typically be rendered as iterative loops are instead represented as compositions of functions operating on series. For example, the program SUM_VECT computes the sum of the elements in a vector of integers by using ENUM_VECTOR to create a series of the integers in the vector and then using SUM to compute their sum.</p>", "authors": [{"name": "Richard C. Waters", "author_profile_id": "81100026965", "affiliation": "MIT Artificial Intelligence Laboratory, 545 Technology Square, Cambridge, MA", "person_id": "PP14022171", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/800017.800511", "year": "1984", "article_id": "800511", "conference": "POPL", "title": "Expressional loops", "url": "http://dl.acm.org/citation.cfm?id=800511"}