{"article_publication_date": "01-15-1984", "fulltext": "\n Interactive Proof Cheekln8 TAomas Reps sad Bomen Alpcvn Cornell University Abstract Knowledge of logical \ninference rules shows s special- ised proof editor to provide a user with feedback about errors in s \nproof under development. Providing such feed- hlck involves checking a collection of constraints on the \nstrings of the proof IsnKua~e. Because attribute ~unmsrs allow uch constraints to be expressed in s modular, \ndeclarative fashion, they are s suitable underlying formal. ism for s proof-checking editor. This paper \ndiscusses how sun attribute graanm~r can be used in an editor for pactial- correctness program proofs \nin Hosts-style lo~c, where verification condition ace proved using the sequent cal- culus. 1. Introduction \nThis paper concerns the design of an editor for partial-correctness program proofs in Hosre-style logic \n[ltoare 1969], where verification conditions are proved using the sequent calculus [Gentsen 10~5]. The \nchief inno- vation in the editor' design is that proofs sro treated as object with constraints on them. \nThe editor keep the user informed of errors and inconsistencies in s proof by reexamining the proofs \nconstraint alter each modification to it. This treatment of proof checking is analogous to the treatment \nof arithmetic-dependency checking in a spread- beet system [Bricklin &#38; Franlmton 1970]; al'ter each \nmodification, the constraints of the system are reexam-in d, and changes are updated in the display. \nThe implementation approach used in the proof-checking editor differs from that of other system . Rule \nof inference \"are embedded in the editor as an attribute grammar. This allows proof checking to be done \nin sn incremental fuhion, resulting in good response time. The editor has been implemented using the \nSynthesiser Gen- erator, a system that creates editors from an attribute grammar description [Repe &#38; \nTeitelbanm 19fi3]. \"f3d~ lark w~ m~ppoeted In l=~ by the Nstlo~d Selenm Fo-~4-- tlon und~ 8nmtJ MC~80-0421S, \nMCS81 _.0~___, ud' ~(~77, Bomm Alpem b suppost~l by u 11~4 Gnu/u~ Fdomhlix Author,' ~ Dep~mmt ~r Cumputa. \nscisnm, Up.on H~ ~y, Ithaca. N.Y. 148~. Permission to copy without fee all or part of this material is \ngranted provided that the copies are not made or distributed for direct commercial advantage, the ACM \ncopyright notice and the title of the publication and its date appear, and notice is given that copying \nis by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires \na fee and/or specific permission. &#38;#169; 1983ACM0-89791-125-3/84/001/0036 $00.75 In its current \nform, the editor is just a prototype, suitable for demonstrntins the principles on sasH exam. pies, hut \nnot for proving dsable theorems or msnipuinting large program . (To some extent this is due to the state \nof the Synthesizer Generator, which is still under develop- ment). Nonetheless, the editor represents \n8, promising approach to interactive verification. This paper discusses the use of attribute grammars \nfor providing feedback about errors in a proof under development. While the attribute grammar described \nforms the basis for our proof-checking editor, this paper is not a discussion of that psrticuhr editor. \nRather, .the paper concerns the appropriateness of s particular-data 8tructurs -attributed derivation \ntrees -for representing proofs in proof-checking editors, regacdies8 of what user interface is desired. \nThe paper is nrganised into $ sections, as follows: Section 2 presents an example of s proof being modified, \nwhich motivates the formalisstlon of inter calve proof checking described in Section 8. Section 8.1, \nfollowing [Oerhsrt 1975J, shows how sen rating s program's verification conditions can be expressed with \nan attribute grammar; Section 8.2 shows how checking of predicate- logic proofs can be expressed with \nan attribute grammar. Section 4 discusses some enhancements to the basle approach aimed at making the \nuser' task Jam tedious when proofs are created and modified. Section 5 discusses how the attribute-grammar \napproach differs from the approaches used in other interactive proof-development systems. Section 6 draws \nsome conclusion about our experience with the attribute-grammar approach. 2. Interactive proof checking \nThe editor provides information about mistakes in s program proof by checking the program's statements \nSgslnst a formal specification of the program' behavior and indicating places where the code does not \nimplement the specification. A program proof can be presented as a proo/o,,fflme --a program mmotated \nwith assertions. In the example given below, which is meant to suuest what one sees on the terminal screen \nduring editing, program text in a proof outline that is inconsistent with the proof outline's 8asertions \nis hlghiishted in the program display. Of course, this mechanism could be replaced by, or used in conjunction \nwith, dingnostic messages. E#smp/e. Suppose we are trying to correct the fol-lowing proof outline no \nthat it will compute s to be the product of s and b, using repeated addition: 36 >0} If :-, 6 Z :toO \nwhile[]~invariant If ~ -1 ^ e~+z --sob do If :,.. If - 1 Z:mZ +18 od (z -.4} In this piece of code, \nthe initial sat on of variables y and s establishes the Ioop-invariant on entering the loop, and the \nloop-body reestablishes the invariant on each succeed- Log iteration. However, the conjunction of the \ninvariant and the negation of the loop-condition fail. to establish the post-condition of the loop. This \nsituation i8 signaled (above) by highlighting the loop-condition. To fix the problem, the first clause \nof the variant is changed to If ~ O, but now the loop-body fails to rees- tablish the variant, which \nis signaled (below) by highlighting the loop-body: (6 >0} If :--b Z :toO while If ) 0 invariant If > \n0 A eqr+z --sob do le :-- e -lJ Iz:--z+al od {, sob} - The problem is that the conjunction of the loop-condition \nand the variant does not imply the weakest pre-condition of the invarlant with respect to the loop-body; \noperationally, the loop-condition allows the loop to exe-cute one too many times. By changins the loop-condition \nto If ) 0, the loop-body will reestablish the invarlant, and the invariant and the negation of the loop-condition \nwU] still establish the post.condition, so the entire program is displayed in the normal font: {6 >0} \nIf :--b Z :mmO while If >Oinvarlantif >0 A eq'+z msob do Ir :-- J'-1 ~:mZ+a od (, -.ob) This example \nillustrates that modifying one part of s proof outline may introduce an inconsistency in some other part \nof the proof outline and simultaneously correct an inconsistency in yet third part of the proof' outline. \nThus, the editor must not only incorporate the notion of an inconsistent proof, but the notion of dependencies \namong parts of a proof, as well. The next section shows bow these notions may be expressed using an ttrlbute \ngrammar. 3. Attribute grammars and formal logical sys-tems An attribute grammar is context-free grammar \nextended by attaching attributes to the symbols of' the grammar. Associated with each production of the \ngram- mar is a set of semea|ic cqa~ioar, each equation defines one attribute as the value of semantic \n.taactlea applied to other attributes in the production. Attributes are divided into two disjoint clumes: \n8ifstkeslzed attributes and imAcr/ted attributes. Each semantic equation defines a value for a synthesised \nattribute of the left-hand side no terminal or an inherited attribute of right-hand side symbol The \naxioms and inference rules of formal logical system can be expressed ns productions and semantic equations \nof an attribute grammar. Dependencies among attributes, as defined in the semantic equations of such \na grammar, express dependencies among parts of proof. An attribute instance in an attributed derivation \ntree is said to be co eistc~ if its value is equal to the value obtained by evaluating the rlght-hand \nside of its defining semantic equation. An attributed derivation tree is eonsistenfl U ~r/6ufed if all \nof its attribute instances are consistent. A proof is represented as a consistently attributed derivstinn \ntree of the grammar. Proofs are modified by operations that restructure the derivation tree, such as \npruning, grafting, and deriving. Restructuring deriva\" tion tree directly affects the values of the \nattributes st the modificJtion point; some of the attributes may no longer have consistent values. Thus, \nincremental proof checking can be performed by (incrementally) updating attribute values throughout the \ntree in response to modifications. Fundamental to this approach is the ides of an incrzmeafd at|rlbufe \neeedeetor, an algorithm to produce a consistently attributed tree after each restructuring opera. tion. \nAn incremental attribute evaiuator works by follow- ins attribute-dependency relationships in the tree \nto rees- t bUsh consistent values. Several algorithms for this are given in [Rape 1982] and [Rape et \nan. 19~], including ones that are asymptotically optimal in time. When proofs re developed in top-down \nfashion, the editor must not only incorporate the normal rules of logic, but the notion of an incomplete \nproof, as well. Creating a proof top-down entails growing derivation tree. During development, it is \n partial derivation tree; that is, it contains unexpanded nonterminals. This is potentially a problem, \nbecause at an unexpanded nonter- minal X we have no means for giving values to the syn- the ned attributes \nof X nor to any of the attributes that depend on them; this conflicts with our desire to maintain values \nfor every attribute of the tree. To void this problem, we provide csmpictisg pro. ductioa, X ::-= .L, \nfor each nontermLoal symbol X. The symbol / denotes \"unexpanded,\" and the semantic equa- tions of the \ncompleting production define values for the synthceised attributes of X. By convention, an occurrence \nof an unexpanded no terminal is considered to have derived l. By this device, all partial derivation \ntrees (from the user's viewpoint) are considered complete 37 derivation trees (from the editor's viewpoint), \nand to a proof is de,eloped, it8 tree may be fully attributed st all .rages To formalise the notion of \ninconsistent portions of proof, we introduce cieek czprcs~'oas. A check exprmmion is Boolean semantic \nfunction that indicates whether con- straints of the formal system are satisfied, if an editing operation \nmodifies the proof in such way that cow attaints are violated, check expremlons indicating sstisfae- \ntion of constraints become Cabs. These are then nsed to annotate the program display to provide the user \nwith feedback bout errors that exist in the proof. In the example given in the previous section, the \nfont of the proofs print representation depends on the values of check expressions in the pmore derivation \ntree. As an aside, note that our use of terms like \"seman- tic equation\" conforms with accepted attribute-grammar \nterminology, although strictly speaking such terms are mlsnomertc These terms are carryovers from the \ncontext in which attribute grammars were originally used, namely, defining the meaning of context-free \nlanguage, and they have remained standard eve thongh attribute grammars are often used to describe the \nannotation of tree with information that hu nothing to do with its meaning. For example, correct era \nof formal proofs is purely syntactic matter (to a logician), but because it cannot be expressed in \ncontext.free formalism, we make use of the available non-context.free mechanism -the \"semantic\" mechanism \nof an attribute grammar. 3.1. Generating verification conditions Generation of a program's verification \nconditions can be expressed with an attribute grammar using two attributes: pre and post. Pre is synthesised \nattribute of Strut and StmtList whose value is formula in the language of assertions; poet is an inherited \nattribute of Strut and StmtLiet whose value is also formula in the language of assertions. The relationships \namong these attributes that express partial correctnem of programs are given by the rules of the grammar \npresented in Figure I, which is adapted from one given in [Gerhart 1075J. (For brevity, we have not shown \nthe productions that can be derived from Id, Exp, Co d, and Assertion, nor have we shown the completing \nproductions of the grammar). In the semantic equations in Figure 1, ~ well u throughout the rest of the \npaper, we use conventionally accepted notation to express set operstions~ we use \".\" ns the operator \nfor selecting an attribute of no terminal, and we nse subscripts to distinguish among multiple instances \nof the same no terminal. We alsu make use of the nonstandard notion of ~atsetlc rc/ereacc. Insofar am \n component of the syntax tree is often Osc/~ s sufficient representation of the value to be arsucisted \nwith the comps erie's root, we allow a nonterminal's name (when not qualified by an attrihute selection) \nto denote the syntactic component as a value. For example, in pro- duction (I) of Figure I, (I) Progrmn \n::-- {Amertion} StmtL~ {Aamrtion} b~mtLi~.~ ,,, A~serb'eat cheek: leT/teercm(A~serh'eas D b~nd/,~.lWe) \nAHerh'eat and A~s~'ese refer to the compensate derived from the rule's two Amertion nontermintb. Far \nfurther dis~mi__on of syntuetic references in attribut~grsmmar specifications, the reader is referred \nto [Reps &#38; Teitelbanm 1tel. (I) Program ::- (.din.teen) 8tmtLh* (Amrtio ) ~mtLisf.posf --Asssrffeae \ncheck: Is ~orsm (Aeecrffest ~) b~WLiet.prc ) (S) StmtLin ::-- Strut ~ml.posf --b~mfLi~.po~ ~mtList.prc \n--~mt.prs (8) Stmtl, ist ::-- 8trot StmtLiet b~mtList~posf m b~mtl, ists.potf b'*mt.p,st == -~m*Lisfl~prs \n~mtListz.prc --~m/.prc (4) Strut ::-- Id :-- I~p ..qmz.pr, --~mz.f,,~V.p (5) Strut ::-- if Goad then \n8tmtList elee StmtLiet fl ~mtLisfs.ped an ~q~m&#38;pe~ b'fndLisf~pod m ~m~.p,~ ~Nlt&#38;prc m (gee4 ~) \n8tmf.f, lSfl.pre ) ^ (-~Oeed :2 ~mz\u00a3i~s, lws ) (8) Strut ::-- while Oond invsriant Amertion do 8finaList \nod b'tml.prc ,m Aseeetin SfmtLisf.pott --As#orb'on check: le Tic erem ((Asscrtloe A'~ (7sad) D b~mLpest) \ncheck: ls Tlcersm ((Asecrffon A Cond)Db~mfList.prs ) Fifm'c 1: Oeneruting verJflcstion conditions. The \nsemantic equstions of the grammar treat ststo- ments M backward pmdicste tnmdormem [i)ijkstr 19'/8]. \nin an ueigume t statement, for example, the mlstionship between the p,'s and peg# attribute is that the \npro stark but, is defined M the peer attribute with the ezpremon on the right.hand side of the smigmnent \nsubstituted for all occurrences of the left-hand side identifier. (In Figure I this is denoted by the \nexpression ~mf.pett~p). For while-looper the post-condition of the Imp-body and the pre-condition of \nthe parent statement are defined i terms of the Joop-Jnvariant. This allows inconsistent code and smertlons \nto he detected M violations of the check-expremions: check: IsrAcercm((Acecr6o A -~Cnd) D b~mt.posf) \ncheck: lsTicercm((Asscrffoe A 0gad) D ~mtLi~.pre ) where the function leTheorem is decision procedure \n- procedure that returns true if its argument is theorem in the sseertion-langusl~e logic. It is at \nthls point that we reach one of the common 8tumbfing blocks of verification systems - the decidability \nof an smertion language stroq enough to express the 38 verification conditions constructed by the rules \ngiven above. For instance, no decision procedure exists for first-order predicate logic [Turin S 19a7]. \nIn the next section, we sidestep this problem by having the user creute and manipulate the required proofs, \ninstead of having the system try to estlblish theorems automatically. Further on, in Section 4.1, we \ndiscus how to incorporate decision procedures for subtheoriee of predi- cate logic, 8o that the user \nneed not prove theorems that automatic techniques are capable of establishing. By having the user create \nand manipulate proofs of verification conditions, we make the user responsible for proving theorems that \nan automatic theorem prover might be incapable of proving. Oramm~r rules in Figure I that have check \nexpremion involving bThcorem are chansed to include \"Proof\" no terminal for each (predicate-calculus) \nproof obligation of the production. Thus, the new rule for while loops hse two Proof no terminals, one \nst which the user must create proof of (Asecvlios A -~Cos,t) :3 $tn~.po~ and second at which the user \nmust create proof of (AuertiOa A Coad) :3 ~m/L*'~.prc. 8.2. Checking proofs of verification conditions \nBecause the editor is tree-manipulstin$ system, we need formal satin of the smertion-lansus4|e logic \nthat sllom proofs of verification conditions to be conveniently represented as tree-structured objects. \nIt the smertion language is a predicate logic, suitable tormalisstion is Gentsen's sc4mzntcdctdw IGentsen \n1086, Klsene 1952]. A seqmc,~ consist, of two set of formulas, separated by an arrow, such is: (At, An,..., \nA,) -.* (Bu Be, ..., Be) (1) The set {dbAg,..., d.}, on the left, is called the nteccdest; the set (Be, \nBe,..., B.), on the right, is called the nccedest. A sequent is theorem Jn the sequent calculus if it \ncan be derived from the system's ulnas and rules of inference. It can be shown that sequent is theorem \nin the sequent calculus if and only if, in one of the more familiar forms of the predicate calculus, \n formula in the succedent can be demonstrated tokin$ the formulas in the antecedent ss assumptions [Oentsen \n1086]. Informal~ then, one can think of the formulas of the antecedent ae known facts sad the formulae \nof the suecedent ae pals, one of which is to be demonstrated; thus, the informs/ meaning of the sequent \n(I) is no different from smerth~ the formulae AsAAsA \"'\" AA. :3 BIVBsV \"'\" VB. The inference rules of \nsequent calculus allow us to infer new sequent from old sequente. For each logics/ operator there are \ntwo inference ruissc an esalpis rule and s #fm#/Je#ie rule. The analysis rule for (logical) operator \n\u00ae expresses how formula of the form A \u00aeB may be introduced into an antecedent; the synthesis rule for \n\u00ae expresses how A \u00aeB may be introduced into s succedent. For example, nsln S the mete-variables A and \nB to represent single formulae and the met~vsriabks r and A to represent finite sets of formulae, the \nrules for the impli- cation operator D Ire expressed E Implication F -~\u00a3 U (A) r U {B) -*\u00a3 an\"Y~' r U \n{A :~ e) -A Implication r U {A) -, \u00a3 U (B) (2b)  synth, , r -. A u {A n) The implication analysis rule \ngiven is (2a) m~,e (roughly) that if we want to amuse A D B, we must demonstrate A, and we must demonstrate \nour goal mmumlng B. The implication synthesb rule given as (2b) uys (again roughly) that ff we want to \ndemonstrate A :3 B, we must show that by assuming A we can demonstrate B. An attribute grammar can be \nused to express the rules of sequent calculus ae So lows. A sequent is represented by Proof nontermlnal \nthor has two inherited ttributes: an eats cries# ttribute and an ~ccedeat attri- bute. Each production \nof the grammar represents rule of inference or an axiom scheme (see below). The right- hand sidce of \nproductions correspond n| to inference rule, contain additional Proof no terminals whom m~ece&#38;nt \nand ssccc&#38;n# ttributes ire defined in terms of the eel co&#38;s# and eKe deal ttributes of the parent \nProof no terminal. The check expressions of the sequent-calculus srsmm~r express the constraint that \n production derived from a Proof no terminal repro ate an appropri- ate deductive step. For exsmpJe, \nthe productions corresponding to the Implication inference rules are shown in Figure 2. s In each production \nin Figure |, there are two \"Wff\" no term nab on the right-hand side that determine how an inference rule \nis nets tiered. The subtrece derived from these Wff's determine the components of the formula being analysed \n(or synthceised, ae the caee may be), as well is the antecedent and succedente of the right-hand -'de \nProof no term nab. Tim check expmmlons ensure that the Wff belns analysed (synthesis d) reallyis in the \nleft-hand side Proof no term eel's select&#38;a# (m~cc&#38; t) attribute. a ~ tw ~ m d tJm ndm d ~ lumtm \nIqle uuF b ~wad In u upi~dlu st tin qul d tJm imi~r. /. Impllcstion snslysis */ Proof ::-, show Wff Proof \nmmume Wff Proof check: (W~'ID W~'2) c Proof s.s,teccde~ Proof o.ntecede=t --Proof s.ntcccdent -( W~,D \nW~a) Proof ;.suecedest --Proof s.sueccdcst U { WBs} Proof ~sntcccde~ --Proq ,.antecedent -( WB'zD W~',} \nU ( wf,} Proof s.slJccedest .= Proof 1.sueczdcat /0 Implication synthesis ./ Proof ::== assume Wff show \nWff Proof check: (WflD WM~) e Proof ,.ewcccdcat Proof g.ontcccdest == Proof s.utcccdent U { Wb's} Proof \ng.ne ce &#38; st --Proof ,.s.ccedent -(Wl,:) Wl,} LJ ( wb',} Figure ~: Grammar rules corresponding to \nthe implication inference rules. The axioms of the sequent calculus ire expressed in three schemes: (as) \nr U {A} .-, ,, U (A} (Sb} r U {fates} -. A r -a U {true} ($c) The scheme given as ($s) 8sys that if \nformula A is given, then A is demonstrated; (3b) says that if you start with false, then anything can \nhe demonstrated; (3c) 8kye that everything demonstrates true. These three axiom schemes can be combined \ninto n single production whose check expression gives the condition under which applica- tion of sun \naxiom completes a branch of the proof: Proof ::== immediate check: fs.ke e Proof.u/testiest V true e \nProof.s~ce&#38;nt  V (Proof.antecedent n Proo].s~eedcst p~ 4~) Finally, we need to define the atomic \npredicates of our logic; for instance, we need predicates for equality stud kss than: Exp =- Exp Exp \n< EXp Wff's are built out of predicates using Ingicsl connectives. The expressions (Exp) in the predicates \ncan be troy expres- sion of the progrmnming langu,~ge; whatever is legul on the right-hand side of an \namiKnment is kfpd Exp. To fully incorporate these predicates into our logical tyetem we include their \naxlomstk definition. For exsan- pie, the axioms for equality can he expressed as: r -A U (:-:1 (.a) (4b) \nr -a U {fJ-K) ~ (K-O} r -. a U ((7-g) A (K--L) ~ (7.v)) (4c) where the mean-variables J, K, and L represent \nsingle expres8iona Each axiom adds in additional production to the srsrnmsr. For instance, the production \ncorresponding to axiom (4a) is: Proof ::== by reflexivity check: tiers e#isfs #e Proot.euccedznt et~A \nfad # ie Of gAS ~om 7,7 4. Enhancements to the basic approach to proof checking Using the proof editor \ndescribed in the previous sec- tion cam be maddeningly tedious; the editor is proof checker, not theorem \nprover, and proofs must be eom- pkts formal proofs. This section discusses two wkys of making the user's \ntask km tedious when proofs sure created and modified. First, we discuss how the editor can be extended \nto include some automatic deductive capabili- ties so that the user does not have to supply so much detail. \nSecond, we show how pnttern matching can be used within proof trees to facilitate editing. 4.1. Automitk \ndeductive capabilities In Section 8.~, we sidceteped the uncles dab Hay of predicate logic by havins \nthe user write proofs, instead of having the editor try to utoblish theorems automatically. In prsctlce, \nthis approach is untensbk because it forces the user to provide nheulutely every detoil of a proof. Give \nsn unexpsnded Proof ode that is ks/of the tree, we can often check ths~ its sequent can he proven usin \nS decision procedure for n subtheory of predicate logic. Another pomibillty is to apply Iwoof t~tle \n[Gordon et al. 107q,that does its beet to construct proof tree, hut ms), ksve lone Proof nodes unexpanded \nfor the user to fill in later. 4.1.1. Decision procedures The editor can be extended with decision procedures \nby making use of known alsorithms for deciding simple theories. For ezsmpk, an alSurlthm for deciding \nthe theory of equality with uninterpreted function symbols [Johnson 1981, Nelson 1981] can be used as \nthe buds of procedure for prepositional inference. Our proof editor uses the propoeltional-inference \nprocedure from the PL/CV2 proof-checking compiler [Constsbk et sL 1982]; it is incorporated into the \neditor through the grammar rule: Proof ::-- automatic check: lsA~tomstic (Proo/. n~eccdcat ,Pro6/..uccede~ \n) where hAutomatic returns true if the PL/CrV2 propositional-inference procedure can establish the second \nargument from the first argument. The PL/C'W2 automatic-lnference procedure has cer- tain limitations \nbecause it is a decision procedure for only a subtheory of propositional logic {a subtheory selected \nso that problems of inherent computational complexity do not have to be solved). Thus, the grammar production \ngiven above will not be applicable when the theorem to be established requires the use of a primitive \ninference rule that the automatic procedure never attempts to apply. E#ample. Proving the sequent {~ \n6, ~} -* {.~(6A(c3~))} (6) requires the use of the implication ~,nthesis rule to estab- lish the formula \nc Dd, ns in the starred branch of the fol- lowing proof tree: (o,b,~,d)-.{~ f.) (o,b,d)-..(6) (,,b,d)-.(e:~ \n ( ., 6, d} --. ( .} (o, b, ~ --(b^t'c=d)) {., 6, '9 -\" (.^CS^~c=d)))  Thus, s decision procedure that \nnever applies implication synthesis cannot establish (fi). However, there is still a way to help cut \ndown on tedious manipulations when automatic inference pro-cedures are not applicable. Our editor incorporates \na mechanism whereby the user can isolate the offending term sad apply the appropriate inference rule \nexplicitly. This mechanism is based on an additional rule of inference termed the cut ra/e, expressed \nme. r -{A) r U {,4} -. a Cut rule: (6) F-.A The cut rule (6) says that if we want to prove some goal, \nwe can demonstrate some formula A sad then use A it an assumption in the proof of the goal. The cut rule \nallows a user to isolate a formula easily, because automatic infer. ences can be used to skip over the \neasy intermediate steps. E#6mp/c. Returning to the example shove, if we choose c ~ d as the cut formula \nA, the proof branches into two subproofs whose sequents are: {., 6, ~} -(e:)~) (7) and {a, b, d, cDd] \n-. {,^(6A(eDd))) (8) We ire then able to apply implication synthesis directly to (7), and the automatic \ninference rule can be used to estab- fish (8) because n proof can be found that makes no use of implication \nsynthesiec {.,6,~,c~d}-.{6} ].,b,d,e~d)~.{,3d) {.,~,d,c~.~-.{.} (., b, d, c~.~ -(6^#~d/) {J, 6, d, odd) \n-.. (,A(bA(cDd))} 4.1.1. Proof tactics A proof tactic is s method for applying inference rules repeatedly \nand recureively until none is applicable [Gordon etal. I070]. In proof editors, n proof t~tic may be \nemployed to automatically construct a proof fragment, doing its best to construct s proof tree, but pomibly \nleav- ins some unexpanded Proof nodes for the user to fill in later [Bates &#38; Constable 1083]. E#smple. \nGiven an unexpanded Proof nonterminal with the sequent given above as equation (5), a proof tac- tic \ncould apply the and synthesis rule twice to produce the attributed derivation tree that corresponds to \nthe infer- ence: (.,s,d}-.{6} (.,6,d)-.(e=d} (.,6,d}-.(.} (., 6, d} -. (6^(c~d/) (., ~, ~) -{e^(6A(c~d))} \nleaving an unexpanded Proof nonterminal with sequent: (., 6, d} -. (c~d} In the attribute-grammar framework, \ns proof tactic would require using inherited attributes to drive the tree construction process. As currently \nimplemented, proof tactics cannot be incorporated into our editor, because attribute-driven tree construction \nis forbidden in the Syn- thesiser Generator, the Synthesiser Generator only sJlows attribution of a previously \nconstructed abstract-syntax tree. Attribute-driven tree construction has been explored for resolving \nambiguities in attribute-grammar-hosed parsers [Watt 19T7, Rowland 1977, IUfilton etal. 1079], A somewhat \ndifferent notion of \"computing with attriboted trees\" is currently being studied for inclusion in the \nSyn- thesiser Generator [Reps &#38; Teitelhaum 1083]; this mechanism appears to be powerful enough to \nexpress proor tactics. 4.2. A proof representation that uses pattern matching The attribute grsmmur described \nin Section 3.2 for representing sequent-calcu]ns proofs as attributed trees hu a significant drawback: \nthe representation often makes it tedious to modify previously developed proofs. This sec- tion describes \ns modification of the grammar that avoids this problem. The grammar of Section 3.2 specifies that one \nor two Wfl's be derived st each Proof node in order to (1) indicate which formula of the Proofs sequent \nis being analysed or synthesised, and (2) determine the antecedents and succedente asmcinted with the \nnode's subordinate Proof nonterminals. Consider what happens when we modify a proof, say by changing \nu variable name in an assumption from x to y. The proof now hu errors at each Proof node where s Wff \ncontains a use of x, because the Wff refers to a formula not in the Proof node's sequent. To reestablish \ns correct proof, it is necessary to (manually) change each of the Wfl's that refer to x. The problem \nwith the grammar of Section &#38;2 is that the Wff nonterminals bind los mncl iqformatios into the proof \nrepresentation by specifying too precisely how the infer- ence rules are instantiated. An alternative \napproach makes use of \"WflPattern's\" and pattern matching. A WffPattern is partial Wff-- a Wff possibly \ncontaining unexpanded now terminals -and WffPattern matches Wff if the latter can be derived from the \nformer. Instead of having Wff's at each Proof nonterminal, the grammar is changed to have WtlPattern's, \nwhich are then used to determine the antecedents and succedents associated with the node's subordinate \nProof nonterminais. For example, Figure 3 gives the modified rule for implication analysts. In contrast \nto the rule with two Wff nonterminals given previously in Figure 2, the new rule has two WffPattern's. \nThese WffPattern's give the com- ponents of a patters for the formula being analysed, which is selected \nout of the left-hand aide Proof nonterminal's antecedent by a pattern-matching lookup. When there is \nmore that one formula in the antecedent that matches the pattern, the user may have to specify more \ndetailed pat- tern. (Note that premise and conclusion, the components of the matched formula, appear \nin the context-free part of the rule; this is to suggest that the user would be given an indication in \nthe display as to which formula in the antecedent the pattern matched). /. Implication analysis ./ Proof \n::-- Inalys.e by (WflPatternDWflPattern) show premise Proof assume conclusion Proof let wf =- Fi=dMetcA \n(( WffPatgernsD W~PaItcr~, Pros/s.ntcccdca| ) Acre premise and conclusion ere SAc components Of Wff \nProo~ g.aatcccde~ I,, Pros] t.antecedent -{w~} Proo~ 8.succcdent m Proof 1.sncccdea| [J (prcmltc} Proof \n~nteccdcnt --Pros/,.antecedent -{w,~ U {\u00a2omclusloa} Proof s.snccc dent --Proo~ t.succcdcn/ F;gure 8.\" \nImplication analysis rule that uses pattern matching. The proof grammar that uses pattern matching in \nthe semantic equations is a significant improvement over the old grammar. At most nodes of a proof tree, \nit is not necessary for the WffPattern's to contain variable names; in most cases, a structural pattern \nalone is sufficient to indicate which formul of the ProoFs sequent is be'ms analysed or synthesisetL \nNow if we change a variable name from x to y, the proof will still check as before, because all (structural) \nWflPsttern'8 will still match for- mula in the appropriate sequent, and the proper antecedent and sueesdent \nwill be associated with each Proof nonterminal of the tree. 5. Comparison with alternative approaches \nThe attribute grsanmar discussed above formalism an approach to intersctlve proof development that is \ndifferent from what is done in other interactive verification systems. This section dbcusees some of \nthe differ'ences between our approach and the approaches used in other systems. The Desisner/Verifier's \nAmisS at [Moriconl 1070] uses one alternative approach. There, the user interacts with the Assistant, \nwhich in turn decides what needs to be reverifled based on an analysis of the dependencies among the \nprocedures of program. An important difference in the way proofs are treated by the Assistant and the \nway they are treated by our editor is the granularity and incrementallty of proof checking in the two \nsystems, in many respectaq the Amistsnt is simUar to compilation-control systems, such as Make ~Feldman \n19T9]; the Assis- tant decides what to reverify on s per-proesdure basis, and when procedure is reverlfied \nit is reverified in its entirety. By contreet, our editor decides what to reverify on per-inference-rule \nbeeis, and by virtue of the optimal behavior of the alprithm used for incremental attribute updating, \nreanalysis is conhed to the attributes that actually need new values. in the Edinburgh LCF system [Gordon \net al. 1979], there is a notion of objects of type tam, but the objects of type tlm are not proofs as \nsuch. Tim is an abstract data type whose constructor functions obey the invariant \"all tam objects are \nprovable,\" that is, derivable from the axioms by applications of inference rules. An attempt to use a \nconstructor to make an inappropriate deductive step ends in failure. By contreet, our editor supports \nthe development of actual proofs, which can be manipulated and restructured directly, and the editor \nincorporates the notion of a proof with errors and inconsistencies in it. The approach taken in AVID \nis much closer to the approach taken in our editor. AVID is an editor for the top-down development of \nPL/CV2 proofs that incor-porates a proof checker to provide information about a pmof's errors and inconsistencies \n[Krafft 1981, Constable etal. 1082]. An important difference between our editor and AVID is that AVID \nis without a notion of logical dependencies analogous to the attribute dependencies in our editor's attribute \ngrammar. Lacking the information needed to re-uee previous verification information us n proof is checked, \nAVID carries out verification only when there is an explicit request by the user, and it always reverifiee \n proof in its entirety. The closest relative of our editor is the proof-checking editor that is part \nof the PRL system [Bates &#38; Constable 1983]. PRL provides machine aid in the creb- 42 tion of definitions, \nfunctions, and proofs based on s sequent calculus for constructive first-order predicate logic over integers \nand lists. One difference between our proof editor and the one used in PRL is the way the two editors \nhandle inconsistencies in s proof. The PRL editor forbids inconsistencies by requiring each interior \nnode of the proof tree to be an appropriate deductive step. One is able to go back and modify an interior \nnode of the proof, but if this would introduce an inconsistency into s subproof, the subproof is deleted. \nBy contrast, proofs constructed with our editor are allowed to have inconsistencies in them ns they arc \ndeveloped; our editor uses knowledge shout dependencies among parts of s proof (encoded in attribute \ndependencies) to keep track of such inconsistencies. Our proof editor and the PRL editor sbo differ in \nthe way they implement proof checking. The PRL approach may be characterised u the ecmsatlc-arh',n approach; \nduring editing, each operation that affects a node of type X invokes an action associated with the category \nX. An action is an imperative routine that can walk the program tree making updates to nodes of the tree \nas well ss to global data structures. Our approach to proof checking relies on two attractive properties \nof attribute grummartc (I) Attribute grammars are declarative statements of relations that must hold \namong the parts of proof; propagation of context-dependent information through the syntax tree need \nnot be described expli- citly, as it is implicit in the formalism. (2) Attribute grammars allow automatic \nreestablish-ment of consistent attribute values when a proof is modified, without the need for explicit \nundoing or rollback actions; furthermore, such updating ean he performed in an asymptotically optimal \nmanner.  For further discussion of the relative merits of the semantic-action and the attribute-grammar \napproaches, the reader is referred to [Reps et ai. 1083]. 6. Summary and conclusions Our concern is the \ndesign of editors that allow one to create and modify program proofs in Hoare-style logic. We have constructed \nan editor that treats proof as an object with constraints on it; the editor keeps track of inconsistencies \nin a proof by reexamining the proors con- strainte after each modification to it. The logical system \nis encoded in the editor ns an attribute grammar. We feel that the attrlbute-grammar approach to interactive \nproof checking is a promising one on a number of counts. Attribute grammars permit the specification \nof the constraints of a formal logical system, as described in Section $. Attribute grammars are a good \nframework for incorporating previously developed solutions to verification problems, such as fast decision \nprocedure for subtheories of predicate logic, as described in Section 4.1. Further-more, there exist \noptimal algorithms for incremental attri- bute updating, which means proof checking can be done in an \nincremental and optimal fashion. Finally, there exist compiler-compilers and editor generators that produce \nmajor software components from an attribute grammar description of language; this makes it particularly \neasy to implement m/stems hosed on the ideas discussed in this paper. Acknowledgements We were stimulated \nto write this discussion of our work on interactive proof checking aider receiving encouragement from \na number of people who had seen the prototype proof-checking editor; discussions with Rod Bur- still, \nBob (~onetabie, Alan Demers, Edeger Dijkstrz, Gerard Huet, Oillee Kakn, Dave McQueen, and Tim Teitelbaum \nwere particularly interesting. We would also like to thank our coHeMues who read the paper and com- mented \non it; the suggestions of Bob Constable, Bob Harper, Susan Horwits, Mark Krentel, Fred Schneider, and \nTim Teitelbanm have been extremely helpful ReFerences [Bates &#38; Constable 1083J Bates, J. and Constable, \nP~ Proob as programs. Tecb. Pep. 82-630, Dept. of Computer Science, Cor- nell Univ., lth~ct~ N.Y., Feb. \n1083. [Brick[in &#38; Frankston 1979 I Brieklin, D. and Frankston, B. V/e/Ode Oempater Sol|mare ProgrJm \nfir tic Apple II and II Pi,~,. Per- sonal Software, Inc., Sunnyvale, Calif., 1970. [Constable et sl. \n1982] Constable, R., Johnson~ S., and F-,ichenlsub, C. Lecture Notes is Computer Sos'sacs, voL 135: Istro-d~tloa \n#e tAe PL/G~# Progrsmm/,~ Logic. Springer-Vedng, New York, 1982.  [nij t l.?,] Dijkstr~ F~W. A /~'eclpllae \nel Pro~,mm/uf. Prentice-Hall, Englewood Clifb, N.J., 1076. IFeldman 19?0| Feldman, S.L lVlake - A program \nfor maintaining computer programs. So/Zmlre --Pre~tlce ,sad Espericnce 0, 4 (April 1979), 266-26,5. [Gentsen \n1935] Oentsen, O. InvestiSltions into logical deductions. In TAe Collected Paper, oI (TerAerd (Tcstzes, \nM.E. Ssaho (ed.), North-Holland, Amsterdam, 1959, pp. 68-181. [Oerhart 1975] Gerhart, S.L. (~orreetness-preser~ing \nprogram trandormations. In Conference Record of the 2nd ACM Symposium on Principles of Programming Languages, \nPalo Alto, Calif., Jan. 20-22, 1975, pp. 54-88. [Gordon et ai. 1079] Gordon, IUL, Milner, IL, and Wadsworth, \nC. Lee- lure N, tc, in Computer ,~cieacc, vol. 78: Ed/sburgA LCF. Springer-VerhtK, New York, 1979. iHoaro \n,.s01 Hoare, C.A.R. An axiomatic basis for computer prolp-smming. Comma. ACM IJ~, 10 (Oct. 1080), ST&#38;5~O,583. \n[Johnson 11081] Johnson, S. A computer system for checkins proof,~ Tech. Rep. 80-444 and Ph.D. dissertation, \nDept. of Computer Science, ~ornell Univ., lthncs, N.Y., Jan. 108L [Kleene 1052] Kleene, S.C. lutroduct~ou \nle Metems~Aem~ic~. North-Holland, Amsterdam, 1052. [Knuth 10~1 Knuth, D.E. Semantics or context-free \nlungua&#38;,eL M~tk. ,~t. Tkeorll ~, 2 (June 1088), 127-146. JKrffifft 10811 Krafft, D. AVI~. A system \nfor the interactive development of veriflably correct programs. Tech. Rep. 81-467 and Ph.D. dissertation, \nDept. of Com- puter Science, Cornell Univ., Ithscs, N.Y., Aug. 1081. ~{ilton et al. 1070] Milton, D.R., \nKirchhoff, L.W., and Rowland, B.IL An ALL(l) compiler generztor, in Proceedings of the SIGPLAN Symposium \non Compiler Construc- tion, Denver, Colo., AUK. &#38;10, 1970, $1QPLAN Noticc~ 1~, 8 (Aug. 1070), 152-157. \n[Moriconi 1070] Moriconi, M. A desisner/verifler'8 assistant. I\u00a3\u00a3~ Trans. $oflm. Eng. ~E-5, 4 (July 1070), \n387-401. [Nelson 1081 ! Nelson, G. Techniques for prosrsm verificstiou. Tech. Rep. CSL-81-10, Xerox Pale \nAlto Research Center, Pale Alto, Calif., June 1081. [Reps 1082] Reps, 1\". Oeneratlng lansusl~-bssed environments. \nTech. Rep. 82.514 and Ph.D. dissertation, Dept. of Computer Science, Cornell Univ., lthnes, N.Y., Aug. \n1082. To be published by M.LT. Press, Csmbridse, Ma~., Feb. 1084. [Peps &#38; Tei~elbaum 1083] Reps, \nT., and Teitelbanm, T. The Synthesiser Oen- erstor. Dept. of Computer Science, Comell Univ., Ithacs, \nN.Y., Oct. 1083. ~eps et ~. 1083] Reps, T., Teitelbaum, T., and Demem, A. incre-mental context-dependent \nan~dyeis for lanSua4|e-based editors. ACM Trns. PreFr~m. Lau~. Slier. 3 (July 1083), 440-477. [Rowland \n1077I Rowland, B.R. Combining pa~rslng and evaluation for -ttributed grammars. Tech. Rep. 308 and Ph.D. \ndissertation, Dept. of Computer Science, Univ. of Wisconsin, Madison, Wise., Nov. 1077.  [Tu~.~ 1o371 \nTur~n$, A.NL On computable numbers with an application to the Entscheidungsproblem. Prec. Loudou Metk. \nSot., eer. J~, 4~ (1038-7), 230-286. [Wstt 1077J W~t, D~ The psmins problem for ~ Ifnm~ msr~ Acre l~orm~c8 \n$ (10TT), I-~0. Appendix: (]rsmm~ rules tor first.order predicate iosic [* Axiom schemes: r U {tim} - \n  r-~ U (*~'} .I Proof ::--Immtdlate check: rain c Proof . e~c \u00a2 c &#38;st V true c P,~sf.o~ce&#38;sg \nV (Prsef.u~ccc&#38;~ ('1Presl \"'vge\u00a2~nt ~ 4) I* ~-pUc**~n ~ r-a LJ {a) r U {e}- A \"I ru{a ~ e} -a Proof \n::-. show Wff Proof mmume WE Proof check: ( WI,:3 Wlt] c Proof l.~lecc~.nt Prssf miteec &#38;st --Prosl \ni.s,acce~nt -{ WI~3 Wl,} l~',,h.mc\u00a2cdesl --Prs,f l.m=,,kst l,.J { wIJ Proof mitecekM -Pro,l,.a,de.,klt \n-{ Wit::) WId U ( wId Preef ~msecedesd -- Proof i.eueeedeaf I. ,-pU=,~. q~the~ r U {A} \"A U {el .i Proof \n::-- assume Wff show Wff Proof check: (WflD WBt) c Pr**f,.ncc\u00a2&#38;~ Pr**fs.nlccc&#38;nl --Proof I.unlcce&#38;mt \nU { Wli} Presf I~ mscec ~ rill -Prs,/,.necc~nt -{ Wll::)Wit} U { wJM I, ~d --,~,: r U Ix, n} -* A \"I \nru{x An}--A Proof ::-, ~eume Wm sad Wl Proof check: ( WJ~ W~) c Pr**l i.utecc&#38;ss Presf p s~eecdenl \n -P,'*,I ,.,,~cc, ,~,,e -{ wI, Awl,} U { Wl~, wl,} Pre,f ~necc&#38;st --Pr,~ z.neecden# r..,4U{A} r-au{e} \n.i  i.~d ,yoth,~: r -A U {A ^ e} Proof ::-- show Wff Proof show Wff Proof cheek: (W~'zA W~'=) ( Prool \n~.o~ccde g proo[ t.ntecedemt ,\" Proof t.smteeedest Proo~ ~.n\u00a2ce de ! . p, oo! ~.,.~cde ~ -{w#~ wJ'.} \nU {w#d Proof ~Htceedenl ,\" Proo.tI.e leeedestg Pros[ st see de at --Proof t.s~cedent -{W~l'd~ W.~'.} \nU {W/a} r U {A}-. 4 ru{s}-* 4  I.o, -~.~-: r U {A V B) -- a '\"\"I Proof ::== assume WIf Proof aumume \nWlf Proof check: (W#~g W#a) ( Pr, ol ~.. reccdesl Pr0o~ ~nlecc~ ., Pros/,.satccc~,t -{ W~zV W#,} U \n{ WJ,} Proo~s~t~ccdest m. Proo.tt.s~cedest Proo~~s lcccde~t ,. Proo~ l.sstccede~ -{ W~'IVW~a} U { Wffa} \nProol ~ee,dest --Prool t ~eecdest r-, 4 U{A, B}  [. Or synthesis: r ~ A U {A V B } e/ Proof ::-- show \nW8 or Wff Proof check: ( W~tV WU~ ( Prool t s~eede~ prooj~astecedent .., Proo~l.ntccedeat Pros[ wince \ndear r -. 4 U {A} .i   i. No~ .,,~s',: r U {..A} .-. 4 Proof ::-- show We Proof check: ('~ W~) c Proo~ \nz. s~ceedest Proo[ ~ssteeedent m Proo~ l /eeedeal -{',W~) Pr,ol g,s~cedeat --Proof z.tseee~at U { W~J~ \nr U (A} 4 I. ,st ,,th,;-: r -. ~ U {-Ai ./ Proof ::-- ~sume W~ Proof cheek: ('~ W~ ( Pros/t.~wecde~ \nProols..ntecedent .Proo,,.,teec,cs,~.c{W~ Proo~ ws~cedemt m Proo~ I.t OCO~IZ| - r U lAP)} U {v,,~ (,)} \n-4 I\" AU ,~-~r~ r U {V,.A{,)} --A el~r~ ~ is term .tree/st # is A(s) .1 Proof ::-- usume Wff substituting \ngxp for ld Proof cheek: ~[d. W~J~ ~ Pro,[ t sntcecde~ Pres] wnteeckat \"- Preo.t l. Stccedeal U { W~m) \nPres~ wncee~at \" Preo~ t.~eedent r -4 U {~)) /, ~ qn~he~ r --A U {V,.A(,)} ,,/,ere b is es,~ 0t ~csm'~t \nlrce is A(#) el Proof ::-- show WE sub6titutins ld for ld Proof check: (Vld~ Wl) c Pr..! t.e*gccde.~ \ncheck: Nc~rre\u00a2 ( Idb WlJ Proe~ l~mntcccdemt m Preo~ z.mmteeedesl Pvool ~nec~&#38;sl . p,.q,.c.~.~ -{wd, \nw~ U { wn~,\") r U {A~J} -a I* g'~ -'~'~ r U {~,.4(s}} - 4  tt~n b is esei~te s~4 ,ccsrrlmt lrcc is \nA(s) e/ Proof ::-- assume WE ubstitutlng Id for id Proof check: (glda.Wl) ( Pr,*! l.utecc~ check: NotFrec \n(Id.. W~)  Prools.s~cec&#38;sl . p,..!,.~c.,~,, {:,u, w~ U { w(,~,'} Proot ~noeekst --Pros! 1.s,gcc~st \n r -A U {sp)} i. r~u, .~,thes. r -. 4 U (x,.s(,}} ,~ t i, tern l-c lot i= ~#) */ Proof ::-- show WH \nsubetitutlnlg ~tp for Id Proof check: (~IL W~ c Pr**[ t.,~cckst proe~ l~s~eeeJes! ,- Proe~ s.utccede~ \nPreoh.noeckst  --prool,.nccckst -{3;LW~ ~ {WW,,} 45   \n\t\t\t", "proc_id": "800017", "abstract": "<p>Knowledge of logical inference rules allows a specialized proof editor to provide a user with feedback about errors in a proof under development. Providing such feedback involves checking a collection of constraints on the strings of the proof language. Because attribute grammars allow such constraints to be expressed in a modular, declarative fashion, they are a suitable underlying formalism for a proof-checking editor. This paper discusses how an attribute grammar can be used in an editor for partial-correctness program proofs in Hoare-style logic, where verification conditions are proved using the sequent calculus.</p>", "authors": [{"name": "Thomas Reps", "author_profile_id": "81100117392", "affiliation": "Cornell University", "person_id": "PP40023877", "email_address": "", "orcid_id": ""}, {"name": "Bowen Alpern", "author_profile_id": "81100226760", "affiliation": "Cornell University", "person_id": "P31824", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/800017.800514", "year": "1984", "article_id": "800514", "conference": "POPL", "title": "Interactive proof checking", "url": "http://dl.acm.org/citation.cfm?id=800514"}