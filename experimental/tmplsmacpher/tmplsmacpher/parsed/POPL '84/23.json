{"article_publication_date": "01-15-1984", "fulltext": "\n Pattern Driven Lazy Reduction: A Unifying Evaluation Mechanism for Functional and Logic Programs (Extended \nSummary) P.A.Subrahmanyam and J-H. You Department of Computer Science University of Utah Salt Lake \nCity, Utah 84112 Abstract A novel lazy evaluation mechanism, pattern-driven lazy reduction, is developed \nthat serves as a unifying evaluation mechanism for both functional and logic programs. The reduction \nof a function call can be viewed as \"semantically\" unifying the function call with the leR hand side \nof a defining equation, and applying the unifier to the right hand side. Lazy reduction is achieved by \nthe pattern which the function call matches against. Function reductions are actually \"driven\" by patterns \nin this sense. It is shown that this evaluation mechanism works well for both functional programs and \nlogic programs that involve \"executable\" functions. As a result, logic programs can be enhanced with \n(1) the availability of a functional computing environment where there is no notion of backtracking, \nthus alleviating the degree of control difficulties typically encountered in logic programs, and (2) \nthe ability to terminate \"infinite computations\" without the introduction of complex control issues at. \nthe user-level. On the other hand, functional programs can be equipped with the power of logic programming \nlanguages, e.g., Prolog. 1. Introduction Since Kowalski's proposal for using predicate logic as a programming \nlanguage [12], the theory and pragmatics of logic programming have gained increasing attention so much \nso that the number of users in the United States is approximately doubled each year. The prototypical \nrepresentative of logic programming is Prolog (see, for example, [1, 4, 5, 12, 19]), which This Research \nwas sponsored in part by the Defense Advanced Research Projects Agency, US Department of Defense, Contract \nNo. MDA903-S1-C-0414. Permission to copy without fee all or part of this material is granted provided \nthat the copies are not made or distributed for direct commercial advantage, the ACM copyright notice \nand the title of the publication and its date appear,and notice is given that copying is by permission \nof the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or \nspecific permission. &#38;#169; 1983 ACM 0-89791-125-3/84/001/0228 $00.75 has been evidenced to be a \nsimple and powerful language. However, current Prolog systems suffer from a number of problems, including \n(1) a general difficulty in controlling program execution, (2) the lack of the concept of \"evaluation\", \nleading to the logic base sometimes not being transparent, and (3) the unavailability of means to describe \nterminating computations on infinite data structures. On the other hand, functional languages with equational \nflavors have also attracted many researchers (see, for example, [2, 18]). The major drawback of these \nlanguages, as compared to Prolog, is the lack of knowledge-based inferencing abilities to cope with \nsearch-based computations. This paper introduces a novel evaluation mechanism, pattern- driven reduction, \nwhich can ~1) be employed as an evaluation mechanism for functional programs, and (2) serve as a basis \nfor a combined computing environment of logic and functions, which supports computing on infinite data \nstructures, and provides both backtracking free (functional) and non-deterministic (logic) computing \ncomponents for the user to choose from. Some of the \"induced\" (and therefore unnatural) control problems \ntypically encountered in Prolog programs can be eliminated or eased by (1) writing program segments as \nfunction equations; and (2) explicitly embodying the concept of \"evaluation\" in the programs written. \nIn the next section we introduce the notion of pattern--driven reduction in a functional environment. \nThe remainder of the paper continues with discussions of applications of the mechanism in a combined \nenvironment of logic and functions. In what follows, we will use Edinburgh DEC-10 Prolog notation 1, \nexcept for using ^ (up arrow) for the list constructor cons, for example, writing [A]X] as A ^ X (equivalent \nto the Lisp notation cons(A, X)) for convenience. The reader should think of this and other constructors \nas merely symbols without pre--defined meanings. We assume that the reader is familiar with logic programming \nin general. 1In Edinburgh DEC-IO Prolog, identifiers with the first letter capitalized denote variables, \nand with the first letter being lower case denote constants. A Lisp lis t, for example, (1 2 3), can \nbe written as [1,2,3} in Edinburgh Prolog snd can be also written as I ^2 ~ Sh[ ]inthispape1\". 228 2. \nPattern-Driven Reduction in a Functional Environment 2.1. Syntax of Function Declarations The functional \nenvironment considered here consists of (i) a set of function definitions and (2) a set of \"strict\" primitive \nfunctions, i.e. some primitive boolean functions and arithmetic operations ). A functmn definlhon conmsts \nof a set of equations. To simplify our exposition, we assume a fiat computing environment, denoted by \nEQN. Base constructors (e.g., 0, [ l, O, etc) and constructors (e.g., successor, cons, push, etc) can \nbe freely invented by the user. Terms composed of base constructors, constructors and variables can stand \nfor formal parameters and can be used in equations. The left hand side of an equation can have more than \none set of parameters (see Example 2 below). The following two simple examples serve to illustrate the \nsyntax of the functional environment. Example 1. lnorder listing of a binary tree inorder(tr(~, N, 0)) \n= N ^ [ | inorder(tr(L, N, R)) = append(inorder(L), N ^ inorder(R)) append([ ], L) = L append(A ^ L1, \nL2) = A ^ append(L1, L2) Example 2. A Curried version of the function map map(F)([ ]) = [ ] map(F)(A \n^ L) = F(A) A map(F)(L) Note that the syntax of Example 2 resembles the Curried version of function definitions. \nDoing this introduces the concept of \"resulting functions\" into equations. The function variable F can \nnow be instantiated to a resulting function, not necessarily a defined function. 2.2. Reduction of Function \nTerms The reduction of a function term f(sl,...,s n) can be viewed as finding a substitution Q for the \nleft hand side f(tl,...,t n) of an equation such that f(tl,...,tn) Q = f(sl,...,sn). The \"result\" of \nthe reduction is obtained by applying Q to the right hand side of the equation 3. This one way unification \nis called biased unification in this paper. The corresponding reduction procedure is called One_Step_Reduction. \nIn trying to unify two terms, say, f(tl,...,t n) and f(sl,...,Sn) , suppose there are subterms t i and \ns i that are not unifiable in the conventional sense. If s i (or t i) is reducible and the reduced version \nof it is unifiable with t i (respectively si), then we say that f(tl,...,t n) and f(sl,...,s n) are semantically \nunifiable. The corresponding process is called semantic unification. By combining semantic unification \nwith biased unification we obtain the notion of biased semantic unification. The lazy evaluation effect \nis achieved by requiring that a biased unification algorithm perform \"reduction-by-need\", that is, perform \nonly those reductions that are necessary in order to make two terms semantically unifiable. Consider \nthe following ~Strictly speaking, all primitives can be defined by equations. Thus, the choice of primitives \nis not a crucial step in modeling. aHowever, we will write, for example, 7 instead of 5 \u00f7 1 \u00f7 1 for convenience. \nexample which defines a generator g of an infinite stream of squares (of integers), and a function f. \nExample 3. g(N) =N*N ^ g(N t !) flX,M ^ Y) = ifX ~. 0 then M f(X-1,Y) else fix + 1,Y) One_StepReduction \nof the term f(1, g(5)) gives us 25 ~ frO, g(6)) with Qf= {X=I, M=25, Y=g(6)} and Qg = {N=5}. Notice that \ng(5) needs to be reduced first in order to reduce fl, g(5)). The above example serves to provide some \nintuition about the notions of pattern-driven reduction and reduction-by-need. When the terms M ^ Y and \ng(5) were to match, g(5) was reduced once to yield 25 ^ gl6) which was then matched with M ~' Y with \nM bound to 25 and Y to g(6). If we try to match, say, M' N\" Y with g(5), then g(5) will be reduced twice \nto become 25 ~ 36 ~' g(7). Thus, such reductions of function terms are in fact driven by patterns, and \nthis is what we mean by pattern-driven reduction. The actual number of reductions carried out is based \non the need to match a pattern and this is what we mean by reduction-by- need. Notice that by adopting \nan equational model the notion of lazy evaluation extends to any algebraic data type in a very natural \nway without increasing language complexity. The careful reader has probably noticed that the definition \nof the function if_thenelse and its involvement in the reduction has been ignored. The function if then \nelse can be defined (in prefix notation) by equations if. then_else(true, X, Y) = X ifthenelse(false, \nX, Y) = Y The reduction of a function term, for example, if__then else(f(a), g(b), h(c)) will cause \nf(a) to match against the boolean constant true or false, which in turn demands reduction of f(a). The \nfunction ifthenelse defined in this fashion is non-strict, that is, neither g(b) nor h(c) is demanded \nin the current reduction.  2.3. A Biased Semantic Unification Algorithm We now give the definition of \nreducibility of function terms below. A biased semantic unification algorithm is described in Figure \n1 and the procedure One Step_Reduction in Figure 2. Functions can have more than one set of parameters; \nfor clarity of our exposition, however, we will write function terms with only one set of parameters. \nDefinition 1: Reducibility of Function Terms Let f(sl,...,s n) be a function term to be reduced. Let \ngl,'\",gp ,where p -0, be function calls contained in f(sl,...,Sn). The function term fs1,...,s n) is \nreducible if there exists (1) a function term f(sl',...,Sn') obtained from f(sl,...,s n) by performing \nzero or more reductions of each of gl,'\",g~, (2) an equation whose left hand side is f(tl,...,t n) and \n~3) a substitution Q such that f(tp...,tn)Q = flsl',...,sn'). [] Note that in the algorithm, we assume \nthat common variables cannot appear on the left hand side of an equation. As a result, the equations \nin the set I will not be interrelated, thus eliminating the necessity of processing equations that are \ninterrelated by common variables. 229 A Biased Semantic Unification Algorithm Input: The left hand side \nof an equation f(t 1,...,t n), a function t, erm f (sl..... Snl and EQN. Output: A failure report or \na substitution Q=-{xl=m], xz=m 2 ..... xp=mp}, where xi's are variables and mi's are terms. Begin I \n<--{t I = s~ ..... t ~ s.}; Q <--~; Repeat Until I ~ remove an equation t i ~ s t from 1; if t i is identical \nto s i then do nothing elseif t, is a variable then add t i = s i to Q elseif s, is a constant or a variable \nthen stop with failure else let t, = g(t;'. .... tp') and s i = g' (Sl',...,Sq') if g = g' and p = q \n then add ti'=s i ' for all i to I elseif s, is reducible then add tifOne_Step_Reduction (s i) to I else \nstop with failure; End Repeat; Output Q; End. Figure 1: A biased semantic unification algorithm Procedure \nOne_StepReduction {f {s 1 .... , s n) ) ; find an equation f (tl,.... t n} = R-IS in EQN; call the biased \nsemantic unification algorithm with input terms f(s 1,..,,s n) and f{tl,....t n) Return the result of \napplying Q to the RHS where Q is the substitution returncd by the biased semantic unification algorithm; \nEnd. Figure 2: The procedure OneStepReduction 2.4. An Interpreter for Function Reductions An interpreter \nfor function reductions is presented in Figure 3. The top level driving process is called Reduce. An \nillustration of the reduction process followed by this interpreter is given in Example 4. Reduce ( term \n) Se~. if term is an atomic term or not reducible then Return term; let term be f(t~ ..... tn) if f is \ne constructor then Return f ( Reduce ( t I ) ..... Reduce { t n ) ) else Return Reduce {One_Step_Reduction \n(term)) End Figure 3: An Interpreter for Function Reductions Example 4. Computing any finite portion \nof an infinite sequence whose elements are pairs of integers and their squares, both increased by 1. \npairs(N) = IN,N*NI ^ pairs(N + 1) first N pairs(N) = truncate(N, map(map(plusl))(pairs(D)) plusl(N) \n= N+I truncate(0, L) = I1 truncate(N, A ^ !,) = ifN > 0 then A ^ truncateIN-l, L) The function map \nis defined in Example 2. The sequence of reductions in interpreting the function term first--N--pairs(2) \nis shown in Figure 4. f irst-l~-pai rs (2) I v truncate{2, mapimap(plusl)) {pair{I))) V map(plusl) ([l,l]) \n/~ truncate{(1, map(map(plusl)){pair(2))) I v [2,2] /'map(plusl) {[2,4]) /, truncate(o, map(map(plusl) \n) (pair (1))) I v [2,2] ~'[3,5] /'l ] Figure 4: A sample run of Example 4 3. Computing with Infinite \nData Structures Before discussing applications of pattern-driven reduction in logic programming, it is \nrelevant to motivate the need for allowing computations on infinite data structures and the difficulty \nof achieving this in logic programming languages. The advantages of being able to compute with infinite \ndata structures have been cogently argued for by several researchers e.g., [9, 10]. By computing with \ninfinite data structures, we mean that the program can manipulate as a whole data objects that are conceptually \ninfinite, even though the user may, in any given computation, only wish to obtain a finite truncation \nof the potentially infinite objects. This ability not only provides a new programming style in which \none can separate the data processing aspect from possibly complex boundary conditions, but also provides \na way to elegantly solve certain classes of problems. In Prolog, data objects are dynamically built up \nas variable bindings that result from unification. Since infinite data structures can only be generated \nas a result of an infinite number of procedure calls, in order to generate an infinite data structure, \nthere must be at least one procedure that can potentially run forever (and consequently, the corresponding \nformula can neither be proved true nor false ). On the other hand, since only a finite portion of the \ninfinite structure need be manifest during any particular execution, it should be possible to stop the \nprogram (i.e. for the formula to be proved true) at any time. Consider, for example, the generator of \nan infinite list of integers starting from N: 230 gen(M, L). 4. Pattern-Driven Reduction in a Combined \ngen(N, N ~ L) :- N1 is N+ 1, gen(Nl, L). Environment of Logic and Functions is a built-in procedure in \nDEC-10 Prolog [14J. The second clause can be used to generate an infinite list of integers, while the \nfirst clause can stop the computation at any time, if invoked. The goal ?- gen(1, L) will have !, bound \nto the infinite list of integers starting from 1 on the assumption that the first clause is never invoked. \nThe drawback of this definition is that while defining an infinite data structure generator, the programmer \nmust be concerned with the problem of generating the proper termination of the program. This is an inherent \nphenomenon for a logic programming language based on the resolution procedure and cannot be avoided, \nsince every formula should be proved true in order for a computation to terminate meaningfully. where \nthe relation is 4 \" In order to obtain only finite portions of this infinite list of integers, we may \nwant to define a procedure for finite truncation. One such procedure may be defined as follows: truncate(0, \nInfinite, [ I). truncate(N, A ^ Infinite, A ^ Finite) :- N1 is N-l, truncate(Nl, Infinite, Finite). \nTo define a procedure that generates the first N integers starting from 1, we can then write the following \nclause: first N_ints(N, L):-truncate(N, L1, L), gen(1, LI ). Although this program is \"logically\" correct, \nspecifying an appropriate control strategy for the program may not be an easy task. To properly terminate \nthe program and to gain efficiency, control facilities of the underlying logic programming language should \nsupport the following control strategy: 1. The execution of the goal should be coroutine-triggered (demand--driven) \nwhere the process gen is the designated producer and the process truncate the consumer. 2. The second \nclause for gen (amongst two clauses defining the process gen) should always be chosen when the consumer \nprocess truncate has not been terminated (resolved to an empty clause). The first clause must be chosen \nafter the consumer truncate has been terminated.  The key to this control strategy is to choose the \nright clause for gen at the right time, depending on whether or not there exist consumer processes. For \ncyclic infinite streams (e.g., the solution to Hamming's problem in [34 ), however, this strategy no \nlonger works, because it is not clear when to terminate those consumer processes that are involved in \nthe cycle(s), especially in the case that cycles are interconnected to form a complex network. It is \ntrue that, because of the completeness of the resolution procedure, there always exists a proof for a \n\"logically\" correct program, which means there always exists a way to terminate the program. However, \ndue to the control complexity, as far as we know, no existing Prolog systems based on Robinson's resolution \nprocedure [16] provide control features which can be used to terminate the computation of a goal like, \nsay, ?- first N ints(100, L). 4z is x means that the integer expression X is evaluated and the result \nis unified with Z. Z is X fails ifX is not an integer exproasion. We now show how pattern-driven reduction \ncan be employed in a computing environment that affords both logic and functions. Doing this introduces \nthe notion of \"executable functions\" in relations, that is, the concept of function evaluation is introduced \nin Horn clauses. To properly embed functions into relations, we need to modify the conventional unification \nalgorithm to deal with executable functions. The modified procedure is called (general) semantic unification \nin this paper. 4.1. A Semantic Unification Algorithm The process of unifying two terms can be viewed \nas one of solving simultaneous equations 113J. For example, the problem of unifying fls I, ..., s n) \nwith fit,, ..., t n) is equivalent to solving the set of equations {s I = tl, s,, = t2,...,s n = tn}. \nThe solution of these equations, if one exists, is of the form {x] = Pl, x2 = P2'\"\"Xm =Pm ) where the \nxi's are variables and the pi's are terms. In conventional unification, an equation g(tl,...,t p) = g'(sl,...s \nq) is not solvable ifg and g' are not identical or ifp ~q, since g and g' are both treated as constructors. \nIn contrast, semantic unification allows either g or g' or both (or any function symbol in the equation) \nto be defined functions. Two terms are semantically unifiable (i.e., the corresponding equation is solvable \nin this context) if there exist semantically equivalent forms (obtained by reduction(s) on any reducible \nterm in the equation) which are unifiable. The lazy evaluation effect can be achieved by requiring that \na semantic unification perform reduction-by-need, that is, perform only those reductions that are necessary \nin order to make an equation solvable. Presented in Appendix l is a formalization of this extension to \nthe conventional unification algorithm, e.g., the one described in {13]. The algorithm is non-deterministic \n(in the sense that the transformation rules can be applied in an arbitrary order) and abstract (in the \nsense no concrete implementation strategy is supplied). Note that the algorithm ignores \"occur checks \n''5. As an exercise, the reader may work through the sequence of changes to the equation {30*factorial(X) \n= facterial(6)}, where factorial is a defined function and the multiplication operation * is assumed \nto be associative. As expected, the solution to this equation is {X=4}. \"Conventional\" unification will \nfail in this example. The following example illustrates how lazy reduction is achieved in this combined \nenvironment. Example 5. Indeterminately choosing a \"good\" character. filter(P, [ ]) = [ ] filter(P, A \n^ L) = ifP(A) then A ^ filter(P, L) elsefilter(P, L) good(N) = if (N = a) or (N = b) then true else \nfalse choose(First ^ Rest, First). choose(First ^ Rest, Second) :- choose(Rest, Second)  Applying \nthe semantic unification algorithm described above to ~'Occur chocks\" refer to chocks to see ira variable \nthat is being substituted for by a term occurs in the term itself, e.g. as in * = fix). It has been argued \nthat cycles can arise only if assertions and queries are formulated in certain abnormal ways [ 17L Most \nProlog systems do not perform \"occur checks\" in order to improve efficiency of the unification procedure. \n231 the equation choose(filter(good, [c,b,f,a]), Good) = choose[First ^ Rest, First) we can get the unifier \nQ = {Good = First, First = b, Rest = filter(good, If, a[)}. The function term filter(goed, [f,a]) is \na part of the result of reducing filter(good, [c,b,f, aD twice. The reductions were driven by the pattern \nFirst ^ Rest. 4.2. A Sample Execution in the Combined Environment The underlying execution model for \nthe combined environment can be envisioned as consisting of two processes: a driving process and an answer-collector. \nThe driving process invokes the resolution procedure which is based on semantic unification while the \nprocess answer-collecter does \"back substitutions\" and demands complete reductions of function terms \n\"thrown out\" by the driving process. Notice that without the process answer-collector, the corresponding \nexecution can be incomplete, that is, there can be some function terms left unevaluated. We would like \nto re-emphasize the fact that there is no notion of backtracking in function reductions. This means that \ntwo goals like ?- p(X, gen(1)) ?-p(X, I ^ gen(2)), where gen(N)= N ^ gen(N + 1), are semantically equivalent, \nsince the sign \"=\", meaning \"can be replaced by\", is actually an equivalence-preserving transformation. \nTherefore, there is no need to go back from the second goal to the first. Example 6. Evaluating a polynomial \nof order n at a series of x values in a given range. (Such evaluations are used in plotting curves.) \nA polynomial of order n is represented by a list of n coefficients. For example, 2\"x2+ 4\"x--5 is represented \nby the list [-5,4,21. poly(X, An ^ L) = X*poly(X, L) + An poly(X, l 1) = 0 curve(X, Inc, L) = poly(X, \nL) ^ curve(X + Inc, Inc, L) curve in range(Start, End, Inc, Coeffs, Y_values) :- range(Start, End, Inc, \ncurve(Start, lnc,Coeffs), Y values). range[Current, End, Inc, L, [ ]) :- Current > End. range(Current, \nEnd, Inc, A ^ LI, A ^ L2) :- range(Current + Inc, End, Inc, L1, L2). In defining the function curve, \none does not have to worry about boundary conditions, that is, the engineering of how the function terminates. \nThis makes it easier to program and the resulting program is somewhat more flexible. Several ~;teps by \nthe driving process in executing the goal ?-curve in range(-1, 1, 0.1, [2,5], L) is sketched in Figure \n5. The actions of the process answer-collector are included as comments. The subi's are used to show \nthe bindings of interests. Driving Process ?--curve in range(-1, 1, o.1, [2,5], L) I I sub1 = {L ~ Y \nvalues} I I /* the process answer-collector is created */ I /* and waits for the binding of Y_values \n*/ v ?~ range(-], 1, 0.1, curve(-1, 0.1, [2,5]), Y_values) sub2 = |A = poly(--1, [2,5]) L] = curve(--0.9, \n0.1, [2,51) Y values = A ~L2 /* answer--collector demands reduction of */ /* poly(-1, [2,51) and waits \nfor the binding */ /* of L2 */ V ?-range(--0.9, 1, 0.1, curve(--O.9, 0. I, [2,5]). L2) Figure 5: A sample \nexecution of Example 5 5. A Solution to the Problem of Finding the First N Lucky Numbers Example 7 Finding \nthe First N Lucky Numbers. A well-known number-theoretic computation involves the computation of lucky \nnumbers which proceeds as follows: from the list of numbers 1,2,3,4 .... we remove every second number, \nleaving the list 1,3,5,7,9 ..... Since 3 is the first number (except for 1) that has not been used in \nsifting, we remove every third number from the remaining numbers, obtaining 1,3,7,9,13,15,19,21, .... \nNow every seventh number is removed, leaving 1,3,7,9,13,15,21 ..... and so on. The numbers that are never \nremoved from the list are the lucky numbers. The original description of the problem can be found in \n[15]. The difficulty with computational frameworks that do not support computing with infinite data structures \nis that it may require complex number-theoretic calculations to estimate a priori how many integers should \nbe produced in order to get th e first N lucky numbers. One can, of course, use a conservative range \nof integers to search for the first N lucky numbers --in which case some of the computations will be \nredundant. A program to compute the first N lucky numbers without any redundant computations is given \nbelow: gen(N) = N ^ gen(N + 2) sift(M ^ L, N) = M ^ sift(sieve(L, M, N), N + 1) sieve(A ^ L, M, N) = \nifM=N then sieve(L, M, 1) else A ^ sieve(L, M, N + 1) truncate(0, Infinite, [ ]). truncate(N, A ^ Infinite, \nA ^ Finite) :- truncate(N-I, Infinite, Finite). first N lucky_numbers(N,L) :- truncate(N, 1 ^ sift(gen(3), \n3), L). The function gen i8 used to generate all odd numbers (since no even number can be a lucky number). \nThe function sift incrementally outputs the first number M in the current list as a lucky number, calls \non the function sieve to remove every Mth 232 number in the list, and then starts the same process again \non the remaining list. The variable N is used to count the position of each number in the list in order \nto determine whether the number should be removed or not. 6. Related Work and Discussion We have described \na novel lazy evaluation mechanism, pattern-driven lazy reduction, that provides a unifying evaluation \nmechanism for functional and logic programs. This enhances the logic computing environment by adding \nthe ability to gracefully terminate computations on infinite data structures and extends the functional \ncomputing environment by providing a knowledge-based inferencing capability. We have shown how pattern-driven \nreduction can serve as a basis for cleanly integrating these two computing environments into a more powerful \none. The conventional lazy evaluation mechanism is described elsewhere, e.g., in [6] and [9], and has \nbeen incorporated into several languages with equational flavors, e.g., those described in {18] and [2]. \nThe pattern-driven lazy reduction mechanism advocated in this paper uses pattern matching as the \"demand\" \nfor achieving laziness. The advantages of pattern-driven lazy evaluation are: (1) simplicity (only an \nextended unification algorithm is needed); (2) generality (higher order functions and lazy evaluation \non arbitrary algebraic data types are both supported without increasing language complexity); (3) eliminating \nthe need of specifications from the user (e.g., de/ay and force in {9]); and (4) prevision of a clean \nand natural mechanism for integrating functions and logic. A demand-driven lazy evaluation rule is provided \nin a logic programming language described in [8] to achieve the ability to terminate computations on \ninfinite data structures. This language is based on natural deduction and provides a functional notation. \nHowever, the rule they give only deals with acyclic computations, that is, for infinite data structures \nbuilt up cyclically the rule is inadequate. In addition, it is the user's responsibility to explicitly \nspecify that the laziness is required. Further, it is not feasible to incorporate facilities that deal \nwith higher order functions in this language due to the first order nature of the deduction system used. \n An interpreter for function term reductions has been implemented in PSL [7}. We are currently developing \nan implementation-oriented general semantic unification algorithm. The development of a precise computational \nmodel based on the pattern--driven reduction mechanism and a corresponding interpreter is also under \nway. The report on this work will appear in a future paper. 7. References 1. Kenneth A.Bowen. Prolog. \nACM national conference, 1979, pp. 14--23. 2. R. M.Burstall and D.T. Sannella. HOPE User's Manual. Dept. \nof Computer Science, University of Edinburgh, Edinburgh,  Scotland, 1980. 3. K.L. Clark and Steve Gregory. \nA relational language for parallel programming. Functional programming and computer architecture, October, \n1981, pp. 171-179. 4, W.F. Clocksin and C.S. Mellish. Programming in Prolog. Springer-Verlag, 1981. \n 5, M. H.van Emden. Programming with resolution logic. Machine Intelligence 8, London, 1978, pp. 266-299. \n 6, D. P.Friedman and D.S. Wise. CONS should not Evaluate Its Arguments. Automata, Languages and Programming, \nEdinburgh, 1976. 7, The Utah Symbolic Computation Group. The Portable Standard Lisp Users Manual. 3.1 \nedition, Dept. of Computer Science, University of Utah, 1983. 8, A. Hanssen, S.Haridi and S.-A. Tarnlund. \nProperties of a logic programming language. Logic programming, New York, 1982, pp. 267-280. 9. P. Henderson. \nFunctionalprogramming. Prentice-Hall, 1980. 10. Robert M.Keller. Semantics and applications of function \ngraphs. Tecb. Rept. UUCS-8-112, University of Utah, Dept. of Computer Science, October, 1980. 11. Bill \nKornfeld. Equality for Prolog. 8th International Joint Conference on Artificial Intelligence, Karlsruhe, \nWest Germany, August, 1983. 12. R.A.Kowalski. Predicate logic as a programming language. Proceeding \nof IFIP 74, 74, pp. 556-574. 13. Alberto Martelli and Ugo Montanari. \"An efficient unification algorithm.\" \nACM Transaction on Programming Languages and Systems 4, 2 (April 1982), 258--282. 14. Luis Moniz Pereira, \nFernando C N Pereira and David I-I.D. Warren. User's Guide to DECsystem-lO Prolog. 1978. 15. Edward \nM.Reingold, Jurg Nievergeit and Narsingh Deo. Combinatorial Algorithms: Theory and Practice. Prentice-Hall, \n1977. 16. J.A.Robinson. \"A Machine Oriented Logic Based on the Resolution.\" J. ACM 12, 1 (January 1965), \n23-41.  17. J. A.Robinson and E.E. Sibert. Logic programming in Lisp. School of Computer and Information \nScience, Syracuse University, December, 1980.  18. D.A.Turner. SASL Language Manual. University of St. \nAndrews, 1979.  19. D. H.D. Warren, F.Pereira and L.M. Pereira. \"PROLOG: the language and its implementation \ncompared with LISP.\" SIGPLAN Notices 12, 8 (1977), 109-115.  8. Appendix I: A Semantic Unification \nAlgorithm Global variables and auxiliary procedures used in the algorithm: -QUEUE: a first-in-first-out \nqueue whose elements are sets of equations. Initially it is empty. -C: the current set of equations. \n-Add(SET, QUEUE): inserts the set (of equations) SET into QUEUE. - Add all(E, C, QUEUE): for each reducible \nterm t in the equation E, let 233 New_~t = C-E U E[UOne __step _Reduction(t)l do Add(Newset, QUEUE), \nwhere * e[~t'] denotes e with t replaced by t', and C-E denotes set difference, -Front(QUEUE): returns \nthe ~ont set in QUEUE. The set returned is deleted from QUEUE.  A Semant~ Unification Algo~thm Input: \nTwo relation terms p(s1,...,s,~, p(t~,...,tn} and EQN.  Output: A failure report or a set of equations \n{x I = ml, x 2 = m 2 .... , Xp ~ mp| where xi's are variables and mi's are terms Add{{t I = s I ..... \nt n = Sn} , QUEUE); RepeatUn~l QUEUE = O or success is reported C <- FrontiQUEUE}; Repeat Until a failure \nis reported or no transformation applies, in which case success is reported. I* Repeatedly attempt \nto apply any of the */ /* following transformations to each */ /* equation in C */ 1. Eliminate any equations \nof the form x=x. 2. If x and y are distinct variables, x=y is in C and x has other occurrences in C, \nthen replace these occurrences of x by occurrences of y.  3. Replace t=x by x=t if x is a variable and \nt is not.  4. If x is a variable and t~ and t 2 are not, replace x=t~ and x=t 2 by x=t~ and t~=t 2. \n 5. In case an equation E is of the form g(t I' ..... tp') = g'(sl',...,Sq'} where p > 0 and q > 0 \n em~ {a) p = q and g = g' and both g and g' are constructors C <- C--E U {tl'=sl', .... tp'=sq'}; ease \n(b) p = q and g = g' and both g and g' are defined functions C <- C--E U {t~'=s~', .... tp'=Sq'}; if \nthere exist reducible terms then Add_all{E, C, QUEUE); ease (c) one of g and g' is a defined function, \nsay g, and the corresponding term g(t;', .... tp') is reducible, and the other, i.e., g', is a constructor \n let LHS = g(tl',...,tp') C <- C-E U {One Step_Reduetion(UHS) = g'(s~', .... Sq')}; case {d) {p =/ q \nor g =/ g') and there exist reducible terms Add_all{E, C, QUEUE~; C <-- Front~QUEUE}; ease {e) none of \nthe above applies report a failure End Repeat End Repeat; success has been reported then the semantic \nunification succeeds with output C else the semantic unification fails End.   \n\t\t\t", "proc_id": "800017", "abstract": "<p>A novel lazy evaluation mechanism, <italic>pattern-driven lazy reduction</italic>, is developed that serves as a unifying evaluation mechanism for both functional and logic programs. The reduction of a function call can be viewed as &#8220;semantically&#8221; unifying the function call with the left hand side of a defining equation, and applying the unifier to the right hand side. Lazy reduction is achieved by the pattern which the function call matches against. Function reductions are actually &#8220;driven&#8221; by patterns in this sense. It is shown that this evaluation mechanism works well for both functional programs and logic programs that involve &#8220;executable&#8221; functions. As a result, logic programs can be enhanced with (1) the availability of a functional computing environment where there is no notion of backtracking, thus alleviating the degree of control difficulties typically encountered in logic programs, and (2) the ability to terminate &#8220;infinite computations&#8221; without the introduction of complex control issues at the user-level. On the other hand, functional programs can be equipped with the power of logic programming languages, e.g., Prolog.</p>", "authors": [{"name": "P. A. Subrahmanyam", "author_profile_id": "81100179037", "affiliation": "Department of Computer Science, University of Utah, Salt Lake City, Utah", "person_id": "PP14072565", "email_address": "", "orcid_id": ""}, {"name": "J-H. You", "author_profile_id": "81100561096", "affiliation": "Department of Computer Science, University of Utah, Salt Lake City, Utah", "person_id": "P330901", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/800017.800534", "year": "1984", "article_id": "800534", "conference": "POPL", "title": "Pattern driven lazy reduction: A unifying evaluation mechanism for functional and logic programs", "url": "http://dl.acm.org/citation.cfm?id=800534"}