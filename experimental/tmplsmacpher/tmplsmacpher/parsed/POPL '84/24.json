{"article_publication_date": "01-15-1984", "fulltext": "\n Static inference of properties of applicative programs Prateek Mishra and Robert M.Keller Department \nof Computer Science University of Utah Salt Lake City, UT 84112 Abstract An applicative program denotes \na function mapping values from some domain to some range. Abstract interpretation of applicative programs \ninvolves using the standard denotation to describe an abstract function from a \"simplified\" domain to \na \"simplified\" range, such that computation of the abstract function is effective and yields some information, \nsuch as type information, about the standard denotation. We develop a general framework for a restricted \nclass of abstract interpretations that deal with non-strict functions defined on non-fiat domains. As \na consequence, we can develop inference schemes for a large and useful class of functional programs, \nincluding functions defined on streams. We describe several practical problems and solve them using abstract \ninterpretation. These include inferring minor signatures and relevant clauses of functions, which have \narisen out of our work on a strongly-typed applicative language. This work was supported in part by a \nUniversity of Utah Research Fellowship, and grants from IBM, NSF (no. MCS-8106177), and the Defense Advanced \nResearch Projects Agency, US Department of Defense (contract No. MDA903-81-C-0414). 1. Introduction \n1.1. Abstract Interpretation of applicative programs Static inference techniques for applicative programs \nare of use in developing optimized implementations of applicative languages and enhancing the reliability \nof applicative programs by deducing aspects of the \"type\" of a function. The technique of abstract interpretation \n15, 6] forms the theoretical basis for our techniques. An applicative program denotes a function mapping \nvalues from some domain to some range. Permission to copy without fee all or part of this material is \ngranted provided that the copies are not made or distributed for direct commercial advantage, the ACM \ncopyright notice and the title of the publication and its date appear, and notice is given that copying \nis by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires \na fee and/or specific permission.  &#38;#169; 1983 ACM 0-89791-125-3/84/001/0235 $00.75 Abstract interpretation \nof applicative programs consists of using the standard denotation to describe an abstract function from \na simplified domain (\"simplified\" in that only particular properties of interest are captured) to a simplified \nrange. The computation of the abstract function yields some information about the standard denotation. \nThe techniques developed here can cope with a very general class of first-order applicative programs: \nnon~-strict functions acting On non-flat domains. There is great utility in being able to deal with this \nclass, as many useful applicative programs consist of non-strict functions acting on streams (a non-fiat \ndomain) 18, 12]. We formulate a set of simple conditions characterizing a well-formed abstract interpretation, \nand describe a computational scheme for arriving at the *'abstract\" denotation of an expression. Static \ninference for applicative languages often involves computing a description of values that might be bound \nto parameters of functions, as well as a description of values returned by functions. Constructing the \ndescription as a set of values, as is the case for imperative languages[5] is unsatisfactory. Non-strict \nfunctions may yield useful results on being applied to expressions whose evaluation does not terminate. \nHence the description may need to take termination into account [19J. To do so consistently forces us \nto consider sets with an order-structure of the kind familiar in work on indeterminacy 121}. Further, \nin dealing with non- fiat domains, as we do, the sets have a more complex order structure than is the \ncase with fiat domains, somewhat independent of whether or not termination is of interest. The standard \ndenotation of a function definition f is written [[fi]:D -> R. The use of abstraction functions, which \n\"simplify\" the domain and range of a function, are central to our approach. Abstraction maps Absl\".D \n-> A1 and Abs2:R -> A2, capture aspects of the domain D and range R in \"simpler\" domains A1 and A2 (for \na description of \"acceptable\" abstraction maps see section 3). Clearly, A1 and A2 should capture some \ncharacteristic of the domain (D) and range (R) which are of interest. We then interpret [[f]] as a function, \neither from A1 to A2, or from more complex domains constructed out of A1 and A2. Depending on the structure \nof the underlying domains (A1 and A2), several such interpretations may be available. We describe one \nsuch interpretation below; a complete discussion may be found in Section 3. 235  The union-bused interpretation \ninterprets Hill as a function from the powerdomain of A1 (written PDIA11) to PDIA21. While [191 has earlier \ngiven a similar construction for flat I domains, a number of difficulties arise in developing such a \nconstruction for non-fiat domains 122, 21. In this paper, we confine our work to using a standard powerdomain \nconstruction which is well behaved for finite Al and A2. Many, but not all, computationally effective \nabstract interpretations involve such domains. As our examples involve only finite AI and A2 the construction \nyields the necessary theoretical framework. The following diagram summarizes the union-based interpretation. \nA function [[fll: D -> R induces a relation Riifl I from AI to A2 which in turn induces a function from \nPD[A1] -> PD[A21; the function i is an embedding function (i:j = {j}). The union-based interpretation \nfor Ilfll is written f[f]] \"b. Z:) EL\" ~Y] >A?  A1 Rrf~J.J ) A2 PDNlY-Cr [.TJ \"~ ) PD[A2] V a~.A1, \na Rlifl I z, V z\u00a2 { Abs2:[{fll:x I Absl:x =a } V AF.PDiA1], [[fI]UD:A = { b i aR11fllb, V acA } Figure \nI: Union-based interpretation The action of [[f]] ub on any A~PD[A1], consists of taking the union of \nall possible values given by applying [[f]] to the pre- image of A in D; these values are mapped to a \npoint in PD[A2] by Abs2. In practice, [[f]]ub cannot be directly computed. Instead an approximation, \nwritten [[tub]], derived from analyzing the representation (function definition) for f is used. As is \nwell known [5] computation of [[fub]] is only possible if the domain PD[A1] -> PD[A2] possesses the finite \nchain property -all chains converge in a finite number of steps. IA flat domain isone in which x ~ yimplies \nx = /orx = y I[fubll overestimates I[f]l ub, in that: V aE PDIAI I, [IfUbll:a D IlfllUb:a As [IfUbll \noverestimates the set of values an expression might produce, it is useful in situations where we wish \nto show that certain values (e.g. error values) cannot result from the evaluation of an expression. We \nillustrate the utility of these ideas, with a number of practical applications. We motivate and solve \nthe problems of inferring what we call minor signatures and relevant clauses. These have arisen out of \nour work in developing a strongly typed applicative language TFEL 114, 16) and are described in Subsections \n1.2 and 1.3. In addition, we remark that the inference technique described in [181 can be described in \nour framework. In 118 I, abstract interpretation is used to optimize the implementation of integer valued \napplicative programs in a call-by-need programming language. A simple computation allows the inference \nof \"strict\" parameters of functions -i.e. those parameters that may be safely computed by call-by- value. \nThis scheme has a simple description (a combination of join and meet interpretations) in our framework. \n 1.2. Minor signatures Example 1.2.1 displays the type integer list together with functions first and \nrest defined on integer lists. The language we use is an extended applicative language, of the form called \n\"equational\" or \"clausal\", similiar to HOPE {3] or TFEL [14, 161. Functions in such languages can be \nspecified via their action on prototypical terms. All functions are strongly typed; types are specified \nby data equations. The symbol \"+ +\" should be read as \"or\"; the symbol \":\" stands for function application. \ndata list = nil + + fby[integer # list[ dec first: list -> integer --first:tby[x,y[ = x dec rest: list-> \nlist --rest:fby[x,y] = y Example 1.2.1 The data equation defines the type list of integers. AI| data \nare represented by data constructors applied to a number of subterms, each of which represents another \ndata item. The type list has two constructors: nil and/by. Fby accepts terms of type integer and list \nand constructs a list out of them. Constructors form \"records\" of the appropriate type and arity, components \nof which are recoverable by (implied) selector functions. Functions first and rest are specified by equations \nor clauses describing their action on prototypical terms belonging to list. 236 The need for inferring \nminor signatures is motivated by noting that fir.st and rest are partial*d5 functions. Typically, an \napplication of the form first:nil would generate an error at run-time. Fixing our terminology, let the \nmajor signature of a function be what is traditionally known as the signature (or type) of a function. \nIn the case of rest the major signature is list->list. Given the major signature of a function, the minor \nsignature characterizes the action of the function on terms belonging to the domain type of its major \nsignature, indicating such things as: 1. Is the function total ? In the case of rest, given any term \nbelonging to list (the domain type), does it yield a proper term belonging to list (the range type), \nor does it yield an error value ? Clearly rest is not total, as it yields an error value when applied \nto nil. 2. If the function is partial, what are the terms belonging to its domain type for which it yields \nan error value ? For rest, the only such term is nil. More formally, we define: Definition 1: Given \nfunction fwith major signature D -> D, let P be a partition of D, then the minor signature of f with \nrespect to P is a function from P to the powerset of P augmented with an error-value such that: minor \nsignature(D:a = { b i } iffV x~a, [[f:x]J~b i for some i In sections that follow we will provide a precise \ndescription of possible partitions (via abstraction mappings), describe an appropriate power construction \nand carry out inference with respect to a particular partition. In practice, we can only compute an approximation \nto the minor signature; this implies that we will certify only a subset of all total functions to be \ntotal. Instead of picking out the precise set of terms for which a function yields an error, we will \npick out a superset of these terms. The utility of performing such a minor signature analysis should \nbe clear: information on the behaviour of functions is made available to the user at compile time; some \nerroneous expressions are detected before a program is run, and the run-time overhead of including error-handlers \nis reduced accordingly. Thus, inferring minor signatures is a form of compile-time detection of exceptions. \nIn contrast, the language ML [7] explicitly incorporates such exceptions in the form of failures. Minor \nsignatures are useful for static detection of errors, whereas failures in ML serve beth as a means of \nindicating errors, and as an explicit programming technique. =In this context, by partial function we \nmean a function that yields an error on being applied to a term in its defined domain. We are not referring \nto the polsibility of non--termination. 1.3. Relevant clauses The utility of inferring relevant clauses \nis illustrated by the following example. Consider the following definition of the type (univariatc) Ixdynomial \nand the function value which evaluates a polynomial at the integer n. data poly = X + + constlintegerl \n+ + mullpoly # polyl + + addlpoly # pely] + + sub[poly # polyl + + exp{poly # integer] dec value: poly \n-> integer Ill- value:lX,nl = n 121- value:lconstlpl,n] = p 13l- value:lmullx,y],n] = valuelx,nI*valuely,n] \n14]-value:{addlx,yl,nl = valuelx,n] + valuely,n] [5J- valne:{sublx,y],nl = value{x,n] - valuely,n] [6]- \nvalue:lexp[x,mJ,n] = valuelx,n]'m Example 1.3.2 The function value is specified by its action on every \npossible term belonging to type poly. In Example 1.3.2 we have attached a clause number to each clause. \nFrequently, only a few clauses will be needed to determine the result of a particular application of \nvalue --consider the expressions ualue:/mul[X,const/3]],9] and value:[exp[X,7],9]. In the first expression \nonly the first three clauses, and in the second expression the first and last clauses, are of interest. \nWe will call such clauses relevant clauses. To be precise, we should speak of relevant clauses of a function \nwith respect to an application of the function to a term. Determining the relevant clauses of a function \nstatically allows an interpreter to reduce the number of clauses it must inspect at run-time; this is \nof particular importance in combinator based (i.e. copying) interpreters [11] and systems based on tree \nrewriting [9], in which an application is effectively replaced with its definition. Such a definition \nwill typically involve a run-time case analysis for minor signatures. By inferring minor signatures at \ncompile time, the size of definitions which must be copied is substantially reduced. More formally, we \ndefine: Definition 2: Given function fwith major signature D -> D, the relevant clauses of fwith respect \nto a partition P of D, is a function from P to the powerset of clause numbers such that: relevant clause(/):a \n= {ki} iffV x~a, clause k i (for some i) is relevant in the expression f:x. Again, we will only be able \nto compute an approximation to the relevant clauses of a function, inferring a superset of the relevant \nclauses. Inferring relevant clauses of a function is related to the notion of overloading [1], in the \nsense that each clause defining a function can be considered to be an independent function definition \n(e.g. value above). In overloading, however, an a priori signature of an overloaded function is always \navailable, thereby restricting the problem 237 to one of choosing a single function from a set of functions. \nInferring relevant clauses, on the other hand, involves both computing a \"signature\" for each clause \nof the function based on some description of terms (as described below) and, when given an application \nof the function to a term, choosing the subset of clauses which could be applicable. 1.4. Related Work \nAbstract interpretation of imperative programs has been formalized by [5, 6]. In their framework abstract \ninterpretation takes the form of modelling values of program variables at different points in a program. \nAs we have earlier suggested, their construction involves power sets rather than power domains. Consequently, \nunlike the domains we consider, which are complete partial orders, the Cousots' work with complete lattices. \nMycroft [19] pioneered the extension of abstract interpretation to applicative programs. While he has \nnot addressed the problems that arise in dealing with non-fiat domains, we owe several crucial observations \nto him ( see Section 3) and urge the interested reader to consult Chapter 2 of[19] for a comprehensive \ndiscussion of the abstract interpretation problem for applicative languages. In the remainder of this \nwork we describe a correctness result for the construction sketched in Figure I and apply this result \nto the problems discussed above. In section 2 we describe interpretations for data equations and function \ndefinitions, which form the basis for arriving at the minor signature and relevant clause of functions. \nSection 3 is an outline of the correctness result and provides the necessary machinery for abstracting \nthe interpretations given in Section 2. In section 4 we describe solutions for the minor signature and \nrelevant clause problems; section 5 describes an important example of the use of relevant clause inference. \n  2. Standard Interpretations In this section we specify a denotational interpretation for data equations \nand provide two denotationai interpretations for function definitions. The first relates function definitions \nto their standard denotations (i.e. namely abstract functions). The second interprets function definitions \nas functions from terms to sets of clause numbers. Building an approximation to the first definition \nyields the minor signature of a function; approximating the second definition yields the relevant clauses \nof a function, We also specify a \"simplified\" domain based on which we construct approximations. We will \nuse functions defined on the following types as examples: data integer = zero + + succlinteger] data \nbool = true + + false Example 2.0.3 There are two popular styles of interpreting data equations as domains. \nThe first, which we will call a \"strict\" domain, reduces to the insistence that a value is defined (non-bottom) \nonly if all its sub-values are defined. This gives rise to a fiat domain. \"Lazy\" domains result if we \nadmit terms with components that may be undefined and lead to the possibility of \"infinite objects\" derived \nfrom cyclic constant definitions. Details of these constructions may be found in [12, 4]. As we are interested \nin non-fiat domains, we use the second interpretation. We capture error values by introducing constant \nbad (after [15]) into the domain of data values. As we are modelling non-strict functions, we cannot \ninsist that functions be bad- preserving -yield bad on being applied to bad. Similarly \"lazy\" interpretations \nof data equations will generate terms with bad embedded in them. Figure II displays the structure of \nthe domain of integer values, extended with bad, for both the \"lazy\" and \"strict\" interpretations. Note \nthat we use type integer only to capture the essential structure of streams with minimal development \nof formal machinery. We are not suggesting that \"lazy\" implementations of type integer are useful in \npractice. succ[badl i succ(zero] \\ I / \\ I / \\ I /succ[.J-]I I I bad zero \\ / \\/ I t I bad zero \\ I \\ \nI \\ I \\ I I succ[zerol / / / / .. _E J_ Figure II: Lazy and strict interpretations for integers The \ntwo interpretations for expressions and functions definitions that we use are conventional and we do \nnot 238 describe them in any detail. The first, Efun, maps expressions and function definitions to \nvalues and functions over the TOI (Type of Interest). Applying a function to an unexpected argument results \nin the value bad. Example 2.0.4 demonstrates the action of Efu n, using function subl defined on integers. \nsubl:succ[zero] = zero subl:succ[succ[x]] = succ[subl:succ[x]] Efun[[ subl:succ[zero] ]] = zero Efunf[ \nsubl:zero ]] = bad Example 2.0.4  Our second interpretation is more interesting. We number each clause \nin a function definition with a positive integer (1..n). The action of Ecl is to yield the clause numbers \nthat are entered during execution. Operationally, this is equivalent to each clause in a function definition \nreturning a pair, consisting of the computed value and the clause number. In the following discussion \nwe ignore the computed value, but clearly it is essential in defining the interpretation. Ecl maps expressions \ninto sets of clause numbers and interprets functions as mapping values (drawn from the TOI) to sets of \nclause numbers. Intuitively, Ecl simulates the evaluation of a function on being applied to an argument, \ncollecting clause numbers as it does so. The result of applying a function to a value is a set of clause \nnumbers describing the clauses entered during evaluation. The action Ecl on expressions can be thought \nof as yielding a collection of sets of clause numbers each labelled by the function name and function \napplication from which the set is derived. In Example 2.0.5 the function euen, (defined on integers), \nis mapped to a function from integers to sets of clause numbers. [1[-even:zero = true [2]-even:succ[zero] \n= false [3]- even:succ[succ[x]] = even:x Ecl[[ even ]] : integer-> PowerSet{Clause numbers] = < <zero, \n{ 1 } >, < socc[zero], {2) >, <succ[succ[zero]], {1,3}>.,.> EcI[I even:succ[succ[succlseroH] ]] = [even, \n{3,2}] Eel[[ even:subl:succ[succ[zero]] ]] = [subl, {1,2}[[even, {2}] Example 2.0.5 The particular \ndomain (partition) which we use as an example is derived from the set of the constructors (written Con). \nFor the type integer, augmented with bad, Con is derived from the set of constructors {zero, succ, J_, \nbad}. It is straightforward to verify that the abstraction map 4) is acceptable in the terminology of \nsection 3. 4): INTEGER--> Con 4):J-=-L 4):zero = zero 4):succlxl =succ &#38; 4):x 4):bad = bad succ \n&#38;.L = succ Definition of 4) succ &#38; bad succ&#38; zero \\ / SUCC I bad I zero \\/ I ..L. Structure \nof Con The operator \"&#38;\" can be thought of as a form of infix union, with singleton subset succ&#38; \nI identified with succ. This ensures the continuity of 4). 4) applied to an integer value reveals the \nconstructors used to construct the value. 4) induces a map from terms and constant equations to Con in \nthe obvious manner. 3. Correctness In this section we provide an outline of the correctness proof for \nthe techniques described in Section 1. Definitions of continuity, finite element, complete partial order \n(c.p.o), countably algebraic c.p.o (domain] and other domain theoretic notions used below can be found \nin [22]. Theorems 4 and 5 are standard in domain theory [21], and define a powerdomain construction for \nfinite c.p.o.'s. Definition 3: Let E be a c.p.o. A subset X of E i~ convex iff (V x,y,z~E, x -< y -< \nz and x,zEX implies y~X). Let Conu(X) = { z ] z~E, x<-z<-y, x,ycX }. Theorem 4: [Plotkin] Given a finite \nc.p.o D, PD[D] = { Conu(X) ] X ~ D, X::~} , PD[D[ is a e.p.o with ~ defined to be: [Egli-Milner ordering]: \na <- b iff V y~b there exists x~a such that x -< y and V x~a there exists y~b such that x -< y. Theorem \n5: For any c.p.o D, Closed Union (Conu U) is a continuous function on PD[D], and the subset relation \n(~) is continuous over PD[D]. We will also use the subset relation on functions over 239 PD{D]; this \nis a natural \"lifting\" to functions~ Theorem 4 states that the union-based interpretation can be expressed \nin terms of the above powerdomain construction. In stating theorem 4, we need to place a technical restriction \non the order structure of acceptable \"simplified\" domains a~on the abstraction mapping. If abstraction \nmapping Abe maps domain D to A, we require the ~ order on A to to be related to the < order on D, in \nthat al,a2eA should be related only if elements of D from the pre-images under Abs, are related. The \nrestriction on abstraction mapping states that the sets { x I Absl:x = al }, { x I Absl:x = a 2 } must \nbe related in a particular way. Definition 6: Given domains D and A, continuous, total and onto abstraction \nmapping Abs:D -> A,is an an acceptable abstraction mapping ifffor all al, a2eA, ifa I ~ a 2 then for \nall finite elements xe{ r I Absl:r = all there exists ye ( s I Absl:s = a2} with x-< y, and for all finite \nelements yet s [ Absl:s = a2} there exists xe{ r I Absl:r = al} with x-<y. In what follows we assume \nall abstraction mappings to be acceptable. This restriction on abstraction mappings is fairly complex, \nbut we do not have a simpler characterization at this time. Theorem 7: Given {[f]]:D -> R, D and R domains, \nacceptable abstraction maps Abel: D -> A1, Abe2: R -> A2, A1 and A2 finite, domains, let: [[f]]Ub:a = \nConv[{Abs2:{[f]]:x IAbsl:x = a}] then: 1. {[f]]ub is a continuous function from A1 -> PDIA2]. 2. { \nAbs2:[[f]l:x I Absl:x = a } ~ [[f]]ub:a 3. If {[f~], [[f2]~b:D -> R, 1|fill ~-{[f2]] then [{fill----- \n[[f~l] .  4.{{fllUbn extends to [II~UB:pD[AI] -> PDIA21, [[fJlV-:X = Cony { [[f]]'V:a I aeX }. Proof: \nWe outline (1) above, parts (2), (3) and ~) are straightforward. For a I <- a 2 we need to show [[t3]--:a! \n-< [[f]]U~:a 2. From the definition of acceptable abstraction mapping we have, for all finite elements \ns~{ x I Absl:x = aj } there e~ists r~{ y ] Abel:y = a2} with s <- r and vice-versa. Further Abe2\u00b0[[f]] \nis a continuous function from D to A2. Then { Abs2:[[f]]:x I Absl:x = a I } --- { Abs2:{{fl]:x I Abel:x \n= a2}, as A2 is finite. Each f:D -> R induces a map from A1 to PDIA2] and can further be embedded into \nPD{A1] -> PD[A2]. Note that securing composition of functions is the only reason to consider PD[A1] -> \nPD[A2]; indeed it can be verified that the embedding yields a closed sub-space of PD[A1] -> PDIA2] consisting \nof the \"natural extension\" of the function space A1 -> PD[A2]. We freely identify these interpretations \nin future development. In 7.2, for fiatdomains we have the relationship {[fllUb:a = { Abs2:f:x I Absl:x \n= a }. For non-fiat domains, the relationship is weakened to an inclusion. The well known \"convex hull\" \nproblem 12], caused by identifying sets with their convex closures, forces us to make the weaker statement \non non-fiat domains. In pragmatic terms this implies some extra loss of information during inference. \nThe union-based interpretation is useful when the set of all possible results is of interest; two subsidiary \ninterpretations, the meet and join interpretations, yield upper and lower bounds of the set of results, \nand are often simpler to use in applications. The meet (or join) interpretations are only available when \nthe range (A2, in A1 -> A2) is a meet-- (or join)--complete (closed under greatest lower bounds (least \nupper bounds) of subsets of A2). Theorem 8: Given [[f]]:D -> R, D and R domains, acceptable abstraction \nmaps Abel: D -> A1, Abe2: R -> A2, A1 and A2 finite domains, let: {[f]~:a = U{{Abs2:[{fl]:x I Absl:x \n= a}] [[f]Im:a =~[{Abe2:[[f]]:x I Abel:x = a}] then: 1. {[f]~,[[f]]m are continuous functions from A1 \n-> A2. 2. Vze{ x I Abel:x = a }, Abe2:[[f]]:z - [[f]]m:a 3. VzE{ x I Absl:x = a }, Abs2:[{f]]:z -[[f]~:a \n 4. If [[f~]], [[f~]] :D -> R, .{{fill <-- [[f2 ]] then [{fl]]' ([[f2]] ') ~ [[f2]] m ([[f2]]J).  Proof: \nStraightforward from Theorem 7 and continuity of meet and join over the powerdomain (p.477 {21]). Below \nwe present an application of the union-based and join abstract interpretations for the minor signature \nand relevant clause problems: Union-bused, D = integer, R = integer, Absl= Abs2 = \u00a2, A1 = A2 = Con \nEfunl[ sub1 H ub = zero -> {bad}, eucc &#38; zero -> {zero, succ &#38; zero}, J_ -> W, succ -> {succ} \nbad -> {bad}, succ &#38; bad -> {succ &#38; bad,bad} Example 3.0.6: Minor signature of subl For the \nrelevant clause problem, the availability of a complete lattice (A2 = Powereet[Clause Numbers]) with \n-equal to ~ suggests that the join interpretation should suffice: argument similar to that used above: \nJoin, D = integer, R = PowerSetlClause Numbersl, Absl= ~, Abs2 = identity, A1 = Con, A2 = PowerSetlCiause \nNumbersl Ecl[[ even JJJ = zero -> {1}, succ &#38; zero-> {1,2,3} i ->{}, succ ->{S} bad -> {}, succ \n&#38; bad -> {3} Example 3.0.7: Relevant clauses of even Theorems 7 and 8 are not helpful in actually \ncomputing [|fl]ub/j/m, as [[f~b/j/m are defined via the standard denotation. We need to derive [[fuWj/m \ni] as approximations to [[f]]uVjsm from the function representation for f.Theorems 7 8 are applied \"piecewise\" \nto primitive interpreted functions (if-then-else etc.) inducing an interpretation for function defintions \nvia composition and by taking fix-points. Before doing so we need some results on function application \n composition:  Theorem 9: 1. (l[fllUb\u00b0llgJ] \"b) D_([lfll \u00b0 llg]l) \"b,  2. ([[f]l\" ttg]l/<- tt@t]gli, \n3. ([(f]] \u00b0 [tg]]) m -> [[f]]m o [[g]l = Proof: For (I) above, notice that [[f]]ub:[[a]]Ub :~ [[f:a]] \nub. For and (3) similarly. We write recursive function definitions as f = Elf] interpreted as usual \nby the taking of fix-points with respect a set of primitive functions symbols { c i }. For the union- \nbased interpretation we have: Theorem 10: Given a function representation f = Elf] for function [[f][:D \n-> R, Abstraction maps Absl:D -> A1, Abs2: R-> A2: [if]tub ~ f[fub]] where [[tab]] = lira i (EUb)i[ \n.L ] where EUb[fJ = E [fJ <c'i/c ~> V i, and [[c'i]J = [Ici11 ub. Proof: From 11ci]] ~ []c'i]] and Theorem \n9 we have the relationship for finite compositions of primitive functions, and only need to show that \nthe relationship holds for limits. From En[.L] ~ (EUD)n[.L], and the continuity of the subset predicate \nwe have the required relationship. The role of two partial orders (~, -<) over the underlying powerdomain \nfor the union-based interpretation has beer, remarked upon by [191. The < ordering captures improvement \nduring the process of iterating to the fixed point; the ~ ordering captures lose of information due to \ncoarseness of the abstract interpretation. The correctness result for [If]~ and ]]film follows by an \nTheorem II: Ilta'll \" IIl'll m \" Ilt'll \" IlflJ j --IlfiJl Proof: As above, using continuity of meet \nand join as relations. The intersection-based interpretation (the dual of the union-based interpretation) \ndefined by [/f]/b:a = N { {Abs2://f//:x} I Absl:x = a } is not available in general, unless the underlying \npowerdomain has a natural intersection operation. The intersection-based interpretation is useful when \nwe need to show that a certain value must result from the evaluation of an expression. It is not clear \nwhether it is possible to consistently extend the underlying domain to permit such an operation. Finally, \nwe compare our constructions with those of 15] and 119]. We have earlier in Section 1 pointed out some \nspecific differences. We further note that our construction is developed in a non-standard fashion and \nlimited to a restricted set of abstraction maps. Traditionally abstract interpretations of a standard \ninterpretation are formulated as abstractions of the \"collecting interpretation\" -the natural lifting \nof the standard semantics to the powerdomain (or powerset) ofthe underlying domain (or set). Our development \nof abstract interpretation is therefore fairly restrictive. The traditional setting has the advantage \nthat interpretations can easily be compared (see Cousots' lattice of abstract interpretations) and more \ncomplex abstraction maps can be expressed.  4. Solving for Minor Signatures and Relevant clauses We \ndiscuss some pragmatic details of the minor signature and relevant clause inference system. The system \ncarries out both inferences in sequence; minor signatures are inferred first and used to drive the relevant \nclause inference system. Function definitions are first mapped into an appropriate form for solution \nby computation of least fixed points. For minor signature inference, this implies non-recursive function \ndefinitions take on functionality PD[Con] -> PD/Con], with recursive definitions appearing as functionals \nover the same space. For relevant clause inference the functionality is Con -> PowerSet/ Clause Numbers]. \n The transformation is straightforward, save for leR hand sides of clauses (called pattern predicates) \nwhich require some pre-processing. As pointed out in Section 3 primitive functions are simply re-interpreted \nover the abstract domains. This works well for functions such as if-then--else, but before re-interpreting \nclauses it is necessary to carry out some extra pre-processing. Define the intersection set of a pattern \npredicate to be those elements of Con having a pre- image in the TO[ containing elements which might \nmatch the pattern predicate. For x in f:x = e I the intersection set is all of Con; for Suce[x] in f:succ[x] \n= e I the intersection set is {succ &#38; zero, succ, succ &#38; bad}. Using intersection sets we 241 \n produce clause definitions over Con, as shown below in Example 4.8 for sub1: subl:succ &#38; zero = \nzero U succ &#38; subl:(succ &#38; zero) subl:succ &#38; bad = succ &#38; subl:(succ &#38; bad) U bad \nsubl:J_ = J_ sub 1:bad = bad subl:zero = bad sub l:succ = succ &#38; subl:succ U succ &#38; sub1:j_ \n Example 4.8: Transformed version of Sub1 Memebers of Con, that do not belong belong to any intersection \nset show up mapping to bad (except for -L) in the re-interpreted clauses. Currently, the re-interpreted \nclauses are solved for using a simple iterative algorithm. Example 4.9 displays the inferred minor signature \nfor subl, computed from the representation in Example 4.8: Efun[[SublUb]]= bad -> {bad}, succ-> {succ}, \n zero -> {bad}, J_ -> {_[_}, succ&#38; zero -> {succ &#38; sero,zero,succ}, succ &#38; bad -> {succ \n&#38; bad, bad, succ}, ub Example 4.0.9: Efunl[subl ]1 ub . The over-estimate of results inferred by \nEfun[isubl ]] m visible when compared with Efun[[ sub1 ]] ub. m Section 3. For ub . the value succ&#38; \nzero, Efun[[Subl ]] ymlds { succ&#38; zero, zero, succ}, as opposed to {succ &#38; zero, zero} suggested \nby Efun[[ sub1 ]]ub. Basically the inference algorithm fails to infer termination and consequently throws \nin the extra value succ. Restating the goals of minor signature inference discussed in section 1 in terms \nof SubI: Subl is a partial function, yielding an error when applied to zero. Error-handlers need only \nbe included when the minor signature suggests that bad ub occurs amongst the set of possible results. \nFrom Efu.[[ f ]] Efunl[f~b]] we have: * b]]:a - If Efun[[ f = { bad } for some a~Con, then for all values \nx in the pre-image of a, Efu n [[ f:x ]] = bad. - If.for some x, Efun[[ fix ]] = bad, then badeEfu n \n[[ fuo ]]:Abel:x The presence of bad in the set of results can be used as a necessary condition for the \ninclusion of an error handler. -Finally, if bad does not occur in aset of results, i.e. bad is absent \nfrom Efun[[fUD]]:a for some asCon, then no error can occur for values drawn from the pre-image of a, \ni.e Efun[[f:x]] <> bad where x such that Absl:x = a. Computing relevant clauses follows the general \noutline suggested above. As we are using the join interpretation, we have Ecl[[ f [~ -< Ecl[I t J }[, \nand will in general infer a superset of the relevant clauses. The meet interpretation could also be used \nto infer a subset (all clauses that must be utilized for a particular application), but is not of practical \ninterest. Example 4.10 displays the inferred relevant clauses for even. Note that we cannot solve the \nrelevant-clause problem without inferring the minor signature of functions concerned, as at all times \nwe require estimates of the values being passed to functions and the values returned by them: ub Eel[[even \n]] = zero -> {1}, succ&#38;sero-> {1,2,3}, J_ ->\u00ae, succ -> {3} bad ->0, succ&#38; bad -> {3} Example \n4.10: Ecl[[#]]  Comparing with Eel[[ even ]~ in section 3, we find Ed[[ even j ]] to be identical; this \nwill not be the case in general. Finally, we note some points where the actual inference system differs \nfrom the theoretical basis. As noted in Section 3, using the union-based interpretation forces the identification \nof subsets of Con with their convex closures. This forces the identification of {_L, succ &#38; zero} \nand {-I-, succ, succ&#38; zero}. We are currently investigating whether we can avoid this identification \nboth for non-recursive functions (straightforward) and (use a looping test)for recureive definitiom.It \nremains to be seen if this is well-founded. 5. Relevant clause Inference in a language Intended for \nconcurrent execution We describe the important role played by relevant clause inference in optimizing \nthe execution of the functional language FEL [14] on a reduction--based multiproceseor [11]. In [13] \na method was given whereby sequences could be stored either as Lisp dotted-pairs, as contiguous blocks \n(called tuples), or as contiguous blocks representing virtual concatenations of sequences (called concs). \nIn other words, the underlying representation of a given sequence might use these constructs in any combination \nand to any number of levels. An obvious reason to prefer one representation over another is the accessibility/modifiability \ntrade-off: Access of the ith component of a dottsd-pair representation requires time linear in i, whereas \naccess of a tuple requires constant time; Access of a virtual concatenation is somewhere in between, \ndepending on ba/ance. On the other hand, since the possibility of shared or concurrent access to sub--structures \npreculdes in-place modification (a new structure must be created), pure tuples are the most expensive \nto (virtually) modify. Subsequently, a set of sequence operators was provided in FEL for performing commonly-used \noperations on these generic sequences. The intention here was to relieve the programmer from having to \nthink about several different versions of operators which do similar operations, and to provide optimized \nimplementations of these operators which could exploit the potential for concurrent execution in an applicative \nmultiprecesser. For example, the generalization of Lisp's mapcar written as II (called parallel application) \nis such that f II x applies a function f component-wlse to any sequence x.Similarly, if fs is a sequence \nof functions, then fs :: x applies each f in the sequence to x, and so on. In implementing such generic \noperators, the general case demands the inclusion of a run-time test for the representation type of the \nsequence at each level of recursion. However, in many applications, only one of the representations is \nactually used. Consider the function rest as it might be defined on integer sequences with the generic \nrepresentation described above. Example 5.11 illustrates the clauses in a format similar to that used \nin TFEL: data intlist -~ nil + + list[integer tuplel + + iby[integer, intlistJ + + conc[intlist tuple]] \n dee rest : intlist -> intlist rest:list[x| = list[t---rest:x|| rest:fby[x,y] = y rest:cone[x| = if t----first:x \n= nil then rest:conc[t---rost:x ]] else conc[rest:t--first:x,t---rest:x| Example 5.11: integer lists \n The function t--first yields the first element of a tuple; function t--rest yields the tuple derived \nby removing the first element. The constructors nil and/by are conventional; the constructor list builds \na list from an arbitrary number of integers and is stored as a tuple, the constructor cone (standing \nfor concatenation) also builds a tuple of its arguments. The extractor functions, (e.g. rest above) interpret \nconc and list appropriately, effectively causing them to possess the same functional semantics as append \nor list would in Lisp. Use of cone and list therefore yields lists that are (often) structured as blocks \nrather than pairs, achieving the objectives described above. However, this generous use of constructors \nforces supporting functions (e.g. rest above) to be be written with many clauses. In a copying reduction-based \nsystem this implies excessive memory utilization (through function body copying). The relevant clause \nand minor signature inference scheme described herein permits us to optimize the implementation by excluding \ntests for representations which have been inferred not to be relevant. This scheme is thus a powerful \ndevice for freeing the programmer from detailed concerns about representations, permitting easy change \nfrom one to another, and allowing greater experimentation to find which representation yields the best \npossibilities for concurrent execution. An implementation in full FEL, incorporating both minor signature \ninference and relevant clause inference, is underway. 6. Conclusion We have argued that abstract interpretation \nprovides an useful framework in which to develop inference schemes for applicative languages. We have \npresented several practical examples of its utility and outlined a simple correctness proof for the abstract \ninterpretations we use. We are currently extending the work in several directions. The correctness proof \ncontained in this paper is fairly ad-hoc (restriction to finite domains etc.) and we are in the process \nof extending it[20[. We are also examining several other inference problems that include extending[18} \nto list structures in general; re-phrasing, and thereby extending to functions, the cycle-sum test in \n[23] as well as describing the aggregate update problem J l0] as an inference problem. A prototype implementation \nthat infers relevant clauses and minor signatures is operational. An implementation in full FEL is underway. \nDetails of algorithms used and gains due to optimization will appear in [17]. Acknowledgements We thank \nPrakash Panangaden, Uday Reddy and Esther Shilcrat for helpful discussions and in aiding the preparation \nof this report. References 1. United States Department of Defense. Reference manual for the ADA programming \nlanguage. United states Department of Defense, 1982.  2. M. Broy. Fixed point theory for communication \nand concurrency. Lectures at the International Summer school on Theoretical Foundations of Programming \nMethodology, July, 1981, pp..  3. Burstall R.M., MacQueen D.B. and Sanella D.T. HOPE: An Experimental \nApplicative Language. 1980 LISP Conference, 1980, pp. 136-143.  4. Cartwright R., Donahue J. The semantics \nof Lazy (And Industrious) Evaluation. Symposium on Functional Languages and LISP, August, 1982, pp. 253-264. \n 5. P. Cousot and R.Cousot. \"Abstract Interpretation: A Unified Lattice Model for Static Analysis of \nPrograms by Construction or Approximation ofFixpeints.\" POPL IV (Jan 1977), 238-252.  6. P. Cousot. \nSemantic Foundations ofpregram analysis. In N.Jones and N.Muchnick, Ed., Program Flow Analysis: Theory \nand Applications, Prentice-Hall, 1981, pp. 303-342.  7. M. Gordon, R.Milner, L.Morris, M.Newey, C.Wadsworth. \nA Metalanguage for Interactive Proof in LCF. Fifth POPL, 1978, pp. 119-130.  8. P. Henderson. Functional \nprogramming. Prentice-Hall, 1980.  9. Hoffman C.M., O'Donnell J. \"Programming with Equations.\" TOPLAS \n4, 1 (Jan. 1982), 83-111.  10. P. Hudak. The aggregate update problem in functional programming systems. \nIn preparation, Yale University, 1983  11. R.M. Keller, G.Lindstrom, and S.Patil. A loosely- coupled \napplicative multi-processing system. AFIPS, AFIPS, June, 1979, pp. 613-622.  12. R.M.Keller. Semantics \nand Applications of Function Graphs. Tech. Rept. UUCS-80-112, University of Utah, Computer Science Department, \n1980.  13. R.M. Keller. Divide and CONCer: Data structuring for applicative multiprecessing. Prec. \n1980 Lisp Conference, August, 1980, pp. 196-202. 14. R.M.Keller. FEL Manual. University of Utah, 1983. \n 15. R. Kieburtz. Precise typing of data type specifications. POPL X, Jan., 1983, pp. 109-116.  16. \nP. Mishra. Data Types in Applicative Languages: Abstraction and Inference. Ph. D.propesal, May 1983 \n 17. P. Mishra, R.M. Keller. Optimized execution of a strongly typed applicative language. To appear, \nUniversity of Utah,1983 18. A. Mycroft. The theory and practice of transforming call- by-need into call-by-value. \nIn LNCS 83, LNCS 83, Springer-Verlag, 1980, pp. 269-281.  19. A. Mycroft. Abstract Interpretation and \nOptimising Transformations for Applicative Programs. Ph.D. Th., University of Edinburgh, December 1981. \n 20. P. Panangaden, P.Mishra. General pewerdomain constructions for abstract interpretation and indeterminacy. \nIn preparation, University of Utah, 1983 2!. G.D.Plotkin. \"A Powerdomain Construction.\" SIAM J.Comput.5, \n3 (Sept. 1976), 452-480. 22. M.B.Smyth. \"Power Domains.\" JCSS 16 (1978), 23-36.  23. W. Wadge. An Extensional \ntreatment of Dataflow Deadlock. In G.Kahn, Ed., Semantics of Concurrent Computation,Springer-Verlag, \n1979, pp. 285-299.    \n\t\t\t", "proc_id": "800017", "abstract": "<p>An applicative program denotes a function mapping values from some domain to some range. <italic>Abstract interpretation</italic> of applicative programs involves using the standard denotation to describe an abstract function from a &#8220;simplified&#8221; domain to a &#8220;simplified&#8221; range, such that computation of the abstract function is effective and yields some information, such as type information, about the standard denotation. We develop a general framework for a restricted class of abstract interpretations that deal with non-strict functions defined on non-flat domains. As a consequence, we can develop inference schemes for a large and useful class of functional programs, including functions defined on <italic>streams</italic>. We describe several practical problems and solve them using abstract interpretation. These include inferring <italic>minor signatures</italic> and <italic>relevant clauses</italic> of functions, which have arisen out of our work on a strongly-typed applicative language.</p>", "authors": [{"name": "Prateek Mishra", "author_profile_id": "81339517422", "affiliation": "Department of Computer Science, University of Utah, Salt Lake City, Utah", "person_id": "PP39076073", "email_address": "", "orcid_id": ""}, {"name": "Robert M. Keller", "author_profile_id": "81406598224", "affiliation": "", "person_id": "PP39078734", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/800017.800535", "year": "1984", "article_id": "800535", "conference": "POPL", "title": "Static inference of properties of applicative programs", "url": "http://dl.acm.org/citation.cfm?id=800535"}