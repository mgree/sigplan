{"article_publication_date": "01-15-1984", "fulltext": "\n TEMPORAL VERIFICATOON OF CARRIER-SENSE LOCAL AREA NETWORK PROTOCOLS* D. E. Shasha Harvard University \nand IBM A. Pnueli Harvard University and Weizmann Institute W. Ewald Oxford University Abstract: We \nexamine local area network protocols and verify the cor- rectness of two representative algorithms using \ntemporal logic. We introduce an interval temporal logic that allows us to make assertions of the form \n\"in the next k units, X holds.\" This logic encodes intuitive arguments about contention pro- tocols quite \ndirectly. We present two proofs of an Ethernet-like contention protocol, one using the interval temporal \nlogic and one using classical temporal logic. We also verify a contention-free protocol using an invariant \nthat seems to have ' wide applicability for such protocols. Section 1: Network Assumptions In this paper \nwe examine typical local area network protocols and verify the correctness of two representative algorithms \nusing temporal logic. The examination is actually bidirection- al. On one hand we prove the correctness \nof two algorithms that are typical of local area network protocols. On the other, we examine the adequacy \nof the temporal logic formalism as a tool for verifying algorithms that depend strongly on the lengths \nof transmission delays. The conclusions we would like to draw from this double ex- amination can be \nsummarized as follows: This work was supported in part by Rome Air Development Center, contract number \nF30602-81-C-0028, by the Office of Naval Research, contract number N00014-80-C-674, by the National Science \nFoundation grant number MCS79-07762, and by the Applied Reasoning and International Business Machines \nCorporations. The work was performed while the authors were at Harvard University. Permission to copy \nwithout fee all or part of this material is granted provided that the copies are not made or distributed \nfor direct commercial advantage, the ACM copyright notice and the title of the publication and its date \nappear, and notice is given that copying is by permission of the Association for Computing Machinery. \nTo copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1983 ACM0-89791-125-3/84/001/0054 \n$00.75 First, it is possible and hence highly recommendable to con-struct formal proofs of carrier-sense \nnetwork protocols. Fur-thermore, the proofs are readable and highlight the intuitive principles underlying \nthe protocols. Second, the classical temporal approach, as presented say in [MP] and [OL], can be applied \neven to systems which depend on delays of specific lengths. In order to do this, various auxiliary variables \nand counters have to be added to the state. This requirement of augmentation by auxiliary variables in \norder to perform concurrent verification is well-known and has been observed in several previous works, \ne.g., [OG] and [HO]. (See also [Cli] and [Cla].) As an alternative to the addition of auxiliary variables \nwhich sometimes amounts to the explicit introduction of a global clock, we consider an extension of temporal \nlogic. This ex- tension enables us to formalize statements such as \"in m time units from now X\". As a \nbasis to the extended logic, we have adopted a subset of Kr6ger's LAR system [Kr], which we further extend \nto be able to speak about bounded intervals (see [Mos] , [HMM] , [SMV] , and [KVdR] , for a related approach \nto different problems). The advantage in using our quantified interval logic is that it can directly \nformalize intuitive arguments one would make in reasoning about delay-dependent algorithms. Another obvi- \nous advantage is eliminating the need for auxiliary variables. On the other hand, the advantage of using \nthe classical tem- poral logic approach is its neat division of properties into invariance (safety) and \nliveness properties. In addition, there is the principle of using the simplest formalism that will ac-complish \nthe task. In this paper, we present two proofs based on classical tempo- ral logic and one based on the \nqualified interval logic we have developed. In this way, we hope to illustrate to the reader the distinctive \nstyle of each formalism and the available tradeoffs between the approaches. 1.2 Networks A computer network \nis a collection of autonomous processors interconnected by a communication subnet [Tan]. The dis- tinctive \nfeatures of carrier-sense local area networks are that the subnet is a common broadcast channel with \nonly a short delay. It is principally the length of this delay that distin- guishes a local area network \nfrom general broadcast communi- cation networks (which include satellite hook-ups). In our discussion \nwe make the following assumptions about networks: I. (Broadcast Assumption) Each message unit will be \nre-ceived by every process attached to the channel, though it may be garbled, a fixed time after it is \nsent. 2. (Uniform Speed Assumption) All processes operate at the same speed. (This is an assumption of \nconvenience. Changing it requires complicating the proofs somewhat.) 3. (Collisions Only Assumption) \nThere are no errors, except those caused by collisions. (In practice, additional action can handle other \nerrors.) 4. (Collisions are detectable) A process can always distin- guish a message unit originating \nfrom another process from one that it sends. (This is an idealization in that detection is usually only \nguaranteed within some constant time.) 5. (Finite Message Assumption) No process sends continu- ously \nforever.  Section 2 presents a temporal logic for bounded intervals. Section 3 describes an Ethernet-like \nprotocol, which differs slightly from that of [MB] and proves its safety and livencss, using this logic. \nSection 4 does the same using classical tem- poral logic. Section 5 verifies a contention-free protocol \ncalled the Shortest Delay Access Method I LH]. Section 6 summarizes the results and discusses avenues \nfor future work. Section 2: The Quantified Interval Logical System We make use of a subset of Kr6ger's \nIKrl language LAR. The subset includes the connectives of propositional logic, plus the symbol O. The \nintended semantics of O(k)(X) is that proposition X will hold in k time units from now (k may be negative). \nWe drop the parentheses when the mean-ing is clear. We take the following axioms from Kr6ger: A I) All \ntautologies of classical propositional logic. A2) O(k)~A .,-..., ~O(k)A. A3) O(k)(AvB) ..--., O(k)(A)vO(k)(B). \nA4) O(O)A ~ A. A5) O(k)O(k')A ~ O(k + k')A. Inference rules: RI I-A, I-A-- a ~ I-a R2) I-A ~, I-O(k)A, \nWe add the capability to talk about intervals as follows: A7) [k.k'lA q V.m((k_<m_<k') --, O(m)A). A8) \n<k,kt>A ~ = a m((k_<m_<kl)^O(m)A). The logic allows us to state conditions which hold over inter-vals. \nFor example [2,5] (jsends) means that from two units from now to five units from now, process j sends. \nMore complicated expressions are possible. For example <1,6>[0,31(i receives) means that some time between \none unit from now and six units from now, i will start to receive and i will receive for four units. \nWe now state some elementary propositions about our interval expressions. These can be easily derived \nfrom the first order theory of addition over the integers (a decidable theory). Later we will only use \nthese propositions, though of course we could do everything in first order predicate calculus. EO) a_<b \n--~ (<a,b>A 4.---, ~la,bl~A). El) O(r)la,blX -,------ [r+a. r+blX. E2) (x_<x~)^(yt_<y)AIx,ylX -~ Ix',y'lX. \nE3) (x<xl)^(y'_<y)^<x',y'>X --~ <x,y>X. The next four propositions give information about how to reduce \ncomplex diamond and box expressions. The first one says that if over some interval, it will come to pass \nthat X will hold continuously over some other interval, then there must be some interval over which X \nholds continuously and X must hold sometime in another interval. E4) (u_<v)^ (w_< x)^ <u,v>lw,xlX --~ \n[v + w,x + uJXA<u + w,v + x>X. ES) (a<b^c<_d)-.~ ([a,bl[c,dlX ~-.~ [a+c,b+d]X). E6) (a<bAc<d) (<a,b><c,d>X \n~ <a+c,b+d>X). Finally, we list propositions that link boxes and diamonds with logical connectives. \nE7) [a,blX^[b+ l,clX --~ [a,c]X. ES) <a,c>X --~ <a,b>Xv<b+ l,c>X. E9) <a,b>XA[a,b]Y --~ <a,b>(X^Y). El0) \nla,blX^la,blY , , la,bl(X^Y) Eli) <a,b>X~ :lzs.t.a<z_<b^O(z)(XA[l,b_z]~X). El2) Vjla,bl,~j , [a,bl(VJ~i). \nNow, we state the inference rules we need for intervals R3) I---A ~ B ~ I---<k,k'>A --~ <k,k'>B. R4) \nI--A ~ B., I--Ik,k'lA -* ILk'lB. RS) I--~, i ~ I-Vie i. Section 3. An Ethernet-like Protocol and its \nProof The state transition diagram of the protocol for each process is in figure I. Processes which do \nnot wish to send and are not receiving remain in IDLE. If process i has a message ready, it enters state \nATTEMPT with a delay d between i and 2N + 1 and an index (I) equal to the length of the message. N here \nis a parameter of the system and bounds the transmission delay between two processes. After this, the \nprocess will decrement its delay time counter as long as it doesn't receive a message unit from another \nprocess. If R reaches zero, the process begins to send its message, decrementing / by one after send- \ning each unit. When / reaches zero, the process returns to IDLE. If the process receives while decrementing \nR, while sending, or while at IDLE, it enters the RECEIVING state. A process i may pass the contents \nof a message to the next higher communication layer, if i receives the end-of-message token of a message \naddressed to i. In the diagram, each transition represents what can happen in one process step. We have \nthe following network axioms, for all processes j and k. Variable trip(j,k) represents the time in process \nsteps for a message unit originating at j to be received at k. (One proc-ess step before the message \nunit is \"received\", it is \"sensed.\") In the following discussion we will make use of the following m \n~.mmql * m uldmm m ~al ~ Iwmt4e-mm :. F~:I --tJ ~{Jt :. II. t;I --tNmt aut mlt: I :m I-- I;I Delay Proposition: \n(~i at ATTEMPT v(w<R(i)))^[O,w](w<_d) --~ [0,wl~i sends. Proof: Wc will prove by induction that the following \npredi- cate always holds assuming the antecedent above holds: prod(t) = (0<t<w..4. O(t)(~i at ATTEMPTv(w_t)<R(i)). \n This predicate bounds the delay from below during the inter- val from 0 to w. Pred(0) holds since it \nis implied by the ante- cedent of the proposition. Claim: pred(t) .-4, pred(t + I). Case I: t + I>w, \nthen pred(t + I) is trivially true. Case 2: O(t+ I)(~i at ATTEMPT), then p(t+ I) is obviously true. Case \n3: Otherwise. 3.1 O(t)(i at ATTEMPT)^O(t + I)(i at ATTEMPT), then p(t + I) holds by local reasoning about \ndelay, i.e., both R(i) and w-t are decremented by I on going from t to t + I. 3.20(t)(~i at ATTEMPT)^O(t \n+ I)(i at ATTEMPT), then p(t + I) holds by assumption since d is bounded from below, from 0 until w. \nFigure I -E~emet-styk Protocol equivalence: j receives ~ = :lk. j receives from k NO) trip(i,j) + trip(j,k)_>trip(i,k) \nNI) I <trip(j.k)<N, N2) (j#k)Aj sends .--.. O(trip(j.k))(k receives from j). N3) j receives from k ~O( \n-trip(k,jD'(k sends). N4) j senses from k ~ O(I)(j receives fr\"--om k). This protocol differs from the \nEthernet protocol in not using the exponential back-off policy for calculating delays, in hay* ing an \ninitial delay, and in having a very short minimum delay. We use a different method for calculating delays \nto make the dependence of liveness on the randomly assigned delays as clear as possible. The maximum \ndelay of 2N + I is what is needed to ensure liveness. Our two program axioms concern the delay value \nd and the message length I m I. Pl) l_<d_<2N+ I. P2) { m { >2N. Before proving the safety theorem, we \nprove a proposition that describes the role the delay plays. Suppose that in the next interval of length \nw, i draws initial delays greater than w. ff i's remaining delay now is greater than w or i is not in \nATTEMPT, then i will not send during the next w units. Consequently the claim holds, which implies that \nfor all t, pred(t) holds. Therefore, by definition of the intervals, [0,w](R(i)>0v~i at ATTEMPT). [] \n For simplicity we may assume that whenever j is not at AT- TEMPT d(j) = ~. 3.1 Safety Safety is the \nproposition that a process that has sent its entire message without detecting interference can be assured \nthat this message was received without errors. Formally, we ex-press this as follows. Theorem Safety: \nFor any process i, if p + I is the length of i's message to k, then [0,p](i sends) O(trip(i,k))[0,p](k \nreceives from iA(jlti-* ~k receives from j)). The proof is based on the fact that the minimum length \nof the message is 2N + 1. Here is a sketch of the main ideas. If some other process j sends anytime from \n-trip(j,i) to N (i.e., <-trip(j,i),N>j sends), then the network axioms ensure that <0,2N>i receives. \nThis would prevent i from completing its messag'~, which contradicts the assumption. Hence [ -trip(j,i),N](~j \nsends). Moreover, since i sends until p, process j will start to receive from i sometime in the interval \nfrom 0 to N and will continue to receive at least until p + trip(i,j). Hence j will not send until p \n+ trip(i,j) at least ([N,p + trip(i,j)]~j sends). Combining these two facts, we have [ -trip(j,i), p \n+ trip(i,j)l~j sends. The network axiom NO ensures that this implies that the con- sequent of the theorem \nholds. We now make this proof for- mal. 56 Theorem Safety: For any process i, if p + I is the length \nof i's message to k, then [0,p](i sends) -1~ O(trip(i,k))[O,p](k receives from i^(j#i--~ ~k receives \nfrom j)). Proof: We know from N2 that O(trip(i,k))[0,p](k receives from i) so it only remains to show \nthat j.~i--,. O(trip(i,k)) [0,p](~k receives from j). We proceed by stages A) ~< -trip(j,i),N>(j sends). \nProof of A: Assume not. That is, assume < -trip(j,i),N>(j sends). !. j sends~ O(trip(j,i))(i receives) \nbyN2 2. < -trip(j,i),N>j sends, by assumption. 3. <0,N + trip(j,i)>(i receives) by I, 2, and R3; 4. \n<0,2N>(i receives) byNI,3, andE3. 5. <0,p>(~i sends) by local reasoning and E3 again. 6. Contradicts \nthe assumption of the theorem, by E0.  B) [N,p + trip(i,j)](~j sends). Proof of B: I. [0,p](i sends), \nby assumption. 2. [0,p]O(trip(i,j))(j receives from i) by N2. 3. [trip(i,j),p + trip(i,j)](~j sends) \nby local reasoning and E5. 4. [N,p + trip(i,j)](~j sends) byNI and E2.  C) [trip(i,k),p + trip(i,k)](~k \nreceives from j). Proof of C: I. [ -trip(j,i),p + trip(i,j)](~j sends) by A, B, and E7. 2. trip(j,i) \n+ trip(i,k)>trip(j,k) by NO. 3. -trip(j,i)<trip(i,k)-trip(j,k) by 2. 4. trip(i,j) + trip(j,k)_>trip(i,k) \nby NO. 5. trip(i,D_>trip(i,k)-trip(j,k) by 4. 6. [trip(i,k)-trip(j,k),p + trip(i,k)-trip(j,k)]~j sends, \nby 1, 3, 5, and E2. 7. O(trip(j,k)) [trip(i,k)-trip(j,k),p + trip(i,k)-trip(j.,k)]~k receives from j \nby 6 and N2. 8. [trip(i,k),p + trip(i,k)](~k receives from j) by 7 and El. 9. O(trip(i,k)) [0,p]~k \nreceives by 8 and El again.  3.2 Liveness Liveness says that each process that enters state Attempt, \nwill eventually (with probability 1) be able to send. Our basic argument will be that the random delays \nwill eventually favor process i This will permit i to send long enough to silence other processes until \ni completes. Theorem Liveness: i wants-to-send --~ {a s.t. O(a)[O,p]iDsends. We assume that at the \nbeginning of some period a process k sends a message unit and then falls silent as of time unit I. We \nignore the case when i wants to send and the channel is silent. In this case either i completes the message \nor it is interrupted in which case we can take k = i. We also assume that, starting at this time, for \na period of 3N units, whenever i draws a delay time, it will draw I and whenever any other process draws \na delay time, it will draw 2N + I. We can make such assumptions about delay times because each proc- \ness draws from an independcnt random number generator, so any random assignment over a bounded interval \nwill eventual- ly occur. Later we will make this argument more formal. By the end of the first N units \nall processes besides k receive from k and therefore all processes including k have been out of the ATTEMPT \nstate. Because of their long delay time, all processes except i will remain silent from N to 2N, at least. \nSuppose LastTime -1 is the last time from 0 to N that a process h sends. Then i will start sending at \nthe latest at LastTime + N, whereas all other processes will not send from LastTime + N to LastTime + \n2N. Hence, process i will start to send and will continue for at least N units, during which time no \nother process will send. By the end of these N units all other processes will have received from i. Therefore, \nprocess i will be able to send to completion without detecting any collisions. Note that 3N units is \nthe minimum time required for i to be favored. If i were favored only for 2N units, then the follow- \ning situation could arise. Process i begins to send between N and 2N, but is then interrupted. Process \nj might receive i's interrupted message between 2N and 3N, wait the minimum delay time and then send, \nthus preventing i from completing. We need two propositions for this theorem. These tell us when i can \nbe assured of continuing to send. The first propo- sition will be applied when process i has not yet \nsent for N units. First Send Proposition: (l(i)-c)^(c>r)^i sends^ 10,r](~i receives) [0,r](i sends)AO(r)(l(i) \n=c- r). Proof: We will prove this by induction. Our predicate will be pred(O = (O_<t<r)-.~O(O(l(i) =c-t^i \nsends) pred(O) holds by assumption. The induction is by local rea- soning. Therefore [O,r]((l(i)_>(c--r))hi \nsends)AO(r)(I(i) =c-r). ra  The second send proposition applies when process i has al- ready sent for \nat least N units, implying that all other process- es have received from i. Intuitively, it says that \nonce i has sent for this long, no other process can compete.  Second Send Proposition: (c>0)^(r>_N)^[0,r]( \ni sends^~j sends) AO(r)(l(i)ffic) --,.O(r+ l)(i sendsA~j sends^l(i)=c-1). Proof: Assume the antecedent \nholds. Then, 1. Vj#i O(r + l-trip(j,i))(~j sends) ^O(r+ l-trip(i,j))(i sends) by NO andN1. 2. O(r+ l)(~i \nreceivesA~j sends) by l, N2, andN3. 3. O(r + l)(i sends^l(i) = c - 1) by 2 and local reasoning.  57 \n[]  Theorem Liveness: i wants-to-send --~ :la s.t. O(a)[0,p]i sends. That is, if i wants to send a message \nof length p, then eventually it will send it to comple- tion. Proof: We assume the following conditions \nhold eventually.  Assumptions: 1) 3k. k sendsAO(I)(~k at A\"TTEMPT) ll) Vj(j#i)A[0,3N](j enters ATTEMPT \n--* d(j) = 2N + I) lIi) [0,3N](i enters ATTEMPT --~ d(i) = 1) Let ~ be the process ensured by assumption \nI. In I! and III \"j enters ATTEMPT\" is an abbreviation for j. at ATTEMPT^O(-l)~j at ATTEMPT. We proceed \nby stages. A) Vk(<0,N>(~k at ATTEMPT)) A Proof of A: ^By NI and N2 for k unequal to k and by as-sumption \nfor k. B) \u00a5j(j#i ~ [N,2N]~j sends). Proof of B: I. <0,N>(~j at ATTEMPT) by A. 2. <0,N>(~j at ATTEMPT^[0,2N](2N<_d(j))) \nby as-sumption II and l. 3. <0,N>([0,2N]~j sends) by Delay proposition. 4. [N,2N](~j sends) byE4. \n Proof of C: I. Let LastTime between I and N have the following prop- erties ]h. O(LastTimc-l) h sends)^\u00a5r#i \n[LastTime, N]~r sends. LastTime is well-defined by El I and B. 2. <LastTime,N + LastTime>\u00a5j#:i(d(j) = \n2N + 1 v~j at ATTEMPT) by N2, assumption II, and since 0 < LastTime < N. 3. [N + LastTime,2N + LastTime \n+ 1](~j sends) by the Delay proposition. 4. [LastTime,2N + LastTime + I](~j sends) by 1, 3, B, and E7. \n 5. O(N + LastTime)[0,N + l](~i receives ^Vj#i(~j sends)) byNI, N2andEl.  Let L, O<L_<(N + LastTime)<2N, \nbe the smallest in- tegersuch that (*) O(L)[0,N + I](~i receives ^\u00a5j#i~(j sends)) L must exist by 5. \nL must be positive, since due to as-sumption 1 <0,N>(i receives). Hence the minimality of L implies that \n(**) O(L-I)(i receivcsv3j#i j sends). But O(L-I)(j sends) ..~ 0-('L)<0,N>(i receives) by N-I\" and N2, \ncontradicting (*). Hence (**) implies that O(L-I)(i receives). From this discussion and the definition \nof L, we have 6. O(L-l)(i receives)^O(L)[0,N + 1] (~i receivesAVj#i(~j sends)) 7. <0,2N>(iuat ATTEMPT \n^ (l(i)=p)^i sends^10,N] (~i receives ^ Vj~i(~j sends))) by 6, assumption Ill, and local reasoning for \ni. 8. <0,2N>([0,N](i sendsA~j sendsA~i receives) AO(N)(l(i) = p --N)) by 7 and the first Send Proposi- \ntion.  D) <0,2N>([0,p](i sends) Proof of D: We proceed by.induction i. (p -r>0)A(r>N) A[0,r](i sends^~j \nsends)AO(r)(I(i) =p-r) --~([0,r + l](i sends^ ~j sends) AO(r + l)(l(i) = p --(r + i))) by the second \nSend Proposition and E7. 2. <0,3N>([0,p](i sendsA~j sends) ^O(p)(l(i) =0)) by C and I by induction and \nR3. D Let us denote the assumptions that we made in proving live- ness by A I, A 2 and A 3 respectively. \nThen what we have really proved formally is the implication: A I ^A2AA3^i wants to send --~ <0,2N>[0,p](i \nsends). The fact that if i wants to send then either the conjunction AI^A2AA3 will eventually be realized \nor i will complete sending his message earlier requires arguments outside the logic for it justification. \nIntuitively, these arguments say that if we wait long enough then any probabilistic assumption about \na bounded interval will eventually be realized with prob- ability 1. Section 4: Ethernot Proof Using \nClassical Temporal Logic The quantified interval logic allowed us to talk about events k units after \na give instant and about intervals of any length. The classical temporal logic only allows us to talk \nabout semi- infinite intervals and about the instant immediately following another instant. Specifically, \nwe limit our temporal language to O(X),~(X),[](X), which have the semantics \"in the next instant X,\" \n\"sometime after this instant X,\" and \"for all time from this instant on X,\" respectively. For this reason, \nour classical formalization must encode in its state description much of the bounded interval information. \nFor example, we can no longer assert that after i sends a message unit, j will receive it tHp(i,j) units \nlater. Instead, we posit the existence of an edge of length trip(i,j) and assert that the message starts \nat i and covers one distance unit to- wards j in each time unit. To encode interval information, we make \nuse of history variables which say, for example, that i has not received in the last k time units. Let \nP be the set of processes. We model the network as a complete graph G = (P,E) with the following properties. \nEach edge (i,j) in E has trip(i,j) positions numbered 1 to tripod) in ascending order from i towards \nj. The portion nearest i is called the tail and the portion nearest j is called the head. 58 Definitions \nI. Delay(i) = R(i) if i at ATTEMPT(R is the delay counter). Otherwise Delay(i)>_N. 2. Send(i) -The number \nof time units during which i has sent consecutively up to but not including the present instant. (If \ni doesn't send in this instant then Send(i) will be zero in the next instant.) 3. NotSend(i) -The number \nof time units during which i has not sent consecutively up to but not including the present instant. \n(If i sends in this instant then NotSend(i) will be zero in the next instant.) 4. Receive(i,j) -The \nnumber of time units during which i has received from j consecutively up to but not including the present \ninstant. 5. NotReceive(i,j) -The number of time units during which i has not received from j consecutively \nup to but not in-cluding the present instant.  Predicates !. pos(i,j,q) -Position q along the path from \ni to j is occu-pied. 2. something(i,j) ~ (~n s.t. 0<p<trip(i,j)^pos(i,j,n)) 3. approach(i) ~ (:~j s.t. \nsomething(j,i)). 4. tailfull(i,j,p) : = (Vn s.t. n<trip(i,j)^n<p)(pos(i,j,n))) 5. tailempty(i.j,p) \n~ (Vn s.t. n < trip(i,j) ^ n < p)(~pos(i,j,n)))  6. headfull(i,j,p) ~ (Vn s.t. n < trip(i,j) ^ n < p)(pos(i,j,trip(i,j) \n-n))) 7. hcadcmpty(i,j,p) ,,..-=. (Vn s.t. n < trip(i,j) ^ n < p)(~pos(i,j,trip(i,j) -n))) 8. j receives \nfrom i 4----,. pos(i,j,trip(i,j)).  Axioms I. V q s.t. 0<q<trip(i,j), pos(i,j,q) : -~ O(pos(i,j,q + \n1)). That is, units move one position at a time. 2. V j#i,i sends~ O(pos(i,j,1)). 3. V p>0  (Receive(i,j) \n=p^i receives from j) ~ O(Receive(i,j) = p + 1).  4. V p>0 NotReceive(i,j) = p^ ~i receives from j ~ \nO(NotReceive(i,j) = p + l).  5. V p>0 (Send(i) = pal sends) ~ :-O(Send(i) = p + I). 6. V p>0 (NotSend(i) \nffi p^~i sends) O(NotSend(i) == p + I).  7. Send(i)>0 ~ NotSend(i) = 0, 8. NotSend(i)>0 .-b Send(i) \n==0, 9. Receive(i)>0 ~ NotReceive(i) = 0. 10. NotReceive(i)>0 --. Receive(i) ==0. ! I. V p>_trip(i,j) \n (tailfull(i,j,p) --= (headfull(i,j,p)))and (tailempty(i,j,p) ~ (headempty(i,j,p)))  Invariants I. \nSend(i) = p --,. Vj tailfull(i,j,p). 2. (p>trip(i,j)^Send(i) = p) .-. Receive(j0i) = p -trip(i,j). 3. \nNotSend(i) = p .4. Vj tailempty(i,j,p).  4. p>trip(i,j)ANotScnd(i) = p --~ NotReceive(j,i) = p -trip(i,j). \n 5. Receive(i,j) = p --,. (Send(j) --- trip(j.i) + pvSend(j)<trip(j,i)) 6. NotReceive(i,j) = p --,. \n(NotSend(j) = trip(j,i) + pvNotSend(j)<trip(j,i)) 7. Send(i) = p --, NotReceive(i,j)>p + I. 8. Reecive(i,j) \n= pap>0--~ NotSend(i)>p.  The proofs of the first four invariants arc based on axioms I-3 and the definitions \nof Send, Receive, NotReceive, tailfull and tailempty. Invariants 5 and 6 follow easily from invari-ants \n2 and 4 respectively. Invariaots 8 and 9 follows from the causal relationship between receiving and not \nsending. We omit the details. Safety As in the quantified interval version of this proof, safety means \nthat if i sends for some time r>2N then the destination of i's message, k, will eventually receive for \nr units from i without receiving from any other process. We divide this proof into two stages. The first \nstage explores the consequences of i's sending for r units for some r greater that 2N. The second stage \nshows that this implies that k receives without interference. Stage I Send(i) = rAr>2N --~ Vk(k#i)Vj(j~k^j#i) \nReceivc(k,i) = r-trip(i,k)^headfull(i,k,trip(i,k)) ^ headempty(j,k,trip(j,k)) ^ hcad full(i,j,trip(i,j)) \n^ (NotReceive(k,j) > r-trip(i,k)). Proof: Assume Send(i) = rAr>2N hold. Let i,j, and k be as in the \nconsequent. i) NotReceive(i,j)>r by invariant 7. ii) Reccivc(j,i) = r -trip(i.j) by invariant 2. iii) \nIlcadfull(i,j,trip(i,j)) by invariant I and axiom il. iv) NotSend(j)>r -trip(i,j), by invariant 8 and \nii. v) r-trip(i,j)>r -N>N>trip(j,i), by NI and since r>2N. vi) NotSend(j) = r + trip(j,i), by i, iv, \nv, and invariant 6. vii) NotReceive(k,j) = trip(j,i) + r -trip(j,k), by invariant 4. viii) NotReceive(k,j)>r \n-trip(i,k), by vii and NO. ix) Headempty(j,k,trip(j,k)), by vi. invariant 3, and axiom II. x) Conclusion \nfollows from ii, iii, vii, and ix where ii and iii apply to both j and k. Our classical proof makes use \nof the following rule of infer-ence based on integcr induction IMP]. Suppose pred(p) is some predicate \nand limit is some positive integer constant. [--(0<p)^(pred(p) --~ ~(tp' s.t. (0_<p'<p)^pred(p'))) ]-0<wApred(w) \n--~ ~(pred(0)). The second stage of the safety proof is really a safe liveness proof in the sense that \nit shows an eventually condition which ensures safety. 59 Stage I1: (Send(i) = r)^(r>2N) --, Let ~)(Receive(k,i) \n= r^NotReceive(k,j)>r). B = {j [ j~iAMinDist(j)>Delay(j)}. Proof: Assume Send(i) = r^r>2N holds. We \nprove the consequent by induction. Our induction predicate is achieved by the stage I assertion and network \naxiom NO when the predicate parameter p is trip(i,k). pred(p): (r>2N)^Receive(k,i) ffi r -p^headfull(i,k,p) \n^headempty(j,k,p)^headfull(i,j,p -trip(j.k)) ^ (NotReceive(k,j) > r -p) ^ (p < trip(i,k)). By local \nreasoning it is clear that for 0<p, pred(p) --~ O(pred(p -I)) which implies pred(p)--~ 0(pred(p- 1)). \nSo, 0(pred(0)). This in turn implies (> (Receive(k,i) ffi r ^ NotReceive(k,j) > r). Liveness Since liveness \ndepends on probabilistic arguments, we use the approach suggested in [Pn] for proving probabilistic liveness. \nHowever. in order to simplify the presentation we will present first a deterministic liveness proof under \nthe assumption of modified program. Then we will indicate how to change the proof to a probabilistic \nproof for the original program. Thus, let us assume that the processes are asymmetric in that i always \ndraws a short delay and the other processes draw a long delay. Let us redefine the value of the delay \nvariable as follows: 6) Delay(i)= R(i) if i at ATTEMPT (R is the delay counter). Otherwise Delay(i) = \nd(i) ffi i. 6') Vj#i Delay(j) ffi R(j) if j. at ATTEMPT. Otherwise Delay(j) = d(j) = 2N + I. We will \nsee that liveness is not too difficult to prove in this logic. Our strategy will be to list four predicates. \nEach of these predicates represents a milestone in our proof. We will start our proof with an initial \npredicate which implies that eventually the first of the four listed predicates Pl(p) will hold when \np is a value less than N. Exactly what value p has depends on the specific state of the network when \nthe initial predicate hold. This will imply that eventually the second listed predicate P2(p) will hold \nwhen p = N and so on. The fourth predicate at 0, P4(0), implies liveness. We let our initial assumption \nbe called init. init: k .sends^O(~k at ATTEMPT) hi wants to send. Before we list the predicates, we will \ndefine two useful terms. Note that i is the process that is favored by short delays and j is any other \nprocess. Processes k and s may represent any process at all. For any process k, define: MinDist(k) ffi \nmin |r13 s pos(s,k,trip(s,k) -r)} Thus, MinDist(k) is the minimal distance of any bit approach- ing \nprocess k. If no bit is approaching process k then MinDist(k) is undefined. Predicates using the term \nMinDist(k) imply that is defined. The set B is the set of all processes, excluding i, that have a bit \napproaching them but whose delay is so low that they will send at least once before they receive the \nfirst approaching bit. We are now ready to state the predicates. P I (p): (Delay(i) < I v approach(i)) \n^ [((p>0)^B~tO^ Vjwti((approach(j) vDelay(j)>N + p) ^ (joB -* MinVist(j) < p))) v((p. 0)AB .= O^\u00a5jwti(approach(j)vDelay(j) \nw 2N + I))] The predicate says that as long as the set of short-delay proc- esses is still not empty, \nevery process other than i either has a bit approaching it or has a long delay time. When the set of \nshort-delay processes becomes empty, then every process other than i will either have a delay time of \n2N + I (if it has just sent) or will have a bit approaching it. As for i, it will either have a short \ndelay time or have a bit approaching it. P2(p): ((MinDist(j)<p^Mindist(j)_<Delay(j))v(Delay(j)_>N + p)) \n^ NotSend(j) ~ N -p ^ (Delay(i) -0 v Mindist(i) < p -I). P2 says that processes other than i either have \na long delay or will soon receive from the last process to send. In the mean- time, i's delay will go \nto zero because amessage will reach it before N -1 units are over. P3(p): NotReceive(i,j)~N + 1 - pASend(i)~N \n-p ^ Delay(i)., 0 ^ Delay(j) >p ^ NotSend(j) ~ 2N -p. Predicate P3 says that i will now be able to send \nand j will not send for N units. P4(p): NotReceive(i,j)>2N -p^Send(i)22N -p ^ NotSend(j) > 3N -p ^ headfull(i,j) \n> N ^ Receive(j,i) ~ N -p. Predicate P4 says i will keep going for 2N units. Theorem Livenena init -4, \n0Send(i) -2N.  Proof: Claim init: init--~ O(Pl(N)vPl(0)) Proof of Claim init: A A Delay(k) ,- 2N + 1 \nin the next instant. For all j~tk there is a bit approaching j. Thus, all conditions are satisfied and \nwe are free to choose pffiNifB~tO and p.,0ifB.,O. In the first case each job has MinDist(j)_<N as required. \nIn the second case, Pl (0) is satisfied immediately. Claim Pl: p>0^Pl(p) ~ O(:lp' s.t. 0<p'<pAPl(p')). \nProof of claim PI: At this instant B is not empty. The clause concerning i is clear from the assumption \nabout i's delay and axiom 1. There are two cases for the next instant: either B is empty or B isn't. \nWe treat each of these in turn. Suppose B is not empty in the next instant. For each j dis-tinct from \ni such that approach(j) and O(approach(j)), MinDist(j) will decrease by at least 1. If ~approach(j) now \nand O(approach(j)), then j is not in B by the delay assump- tion for j now. Therefore each MinDist(j) \nfor j in B will decrease by one at least. For j distinct from i such that approach(j) now and O(~approach(j)), \nO(Delay(j) = 2N + I). If ~approach(j) now and O(~approach(j)), Delay(j) cannot decrease by more than \none. achieving the predicate for p -I. Suppose B is empty in the next instant. Then there is some process \nj such that j is in B now, but not in the next instant. In this instant MinDist(j)>Delay(j). One possibility \nis that MinDist(j) = 1, in which case Delay(j) = 0 now and j must be sending. In this case, Delay(j) \nffi 2N + I in the next in- stant. The other possibility is that MinDist(j) decreases by more than one. \nThis implies that some process s has sent. Therefore, in the next instant, Delay(s) ,= 2N + I and Yts.t. \nt#sapproach(t). This meets the requirements of P1(0). Claim PI -P2: Pl(0) .-~ P2(N). Claim P2: p>0^P2(p) \n~ O(P2(p -1)). Claim P2 -P3: P2(0) --, P3(N). Proof of claim P2 -P3: Since MinDist(j)<0 is impossible, \nP2(0) implies that Delay(j) , N. NI implies that N>trip(j,i). The other clauses are straightforward. \nClaim P3: 0<p<_NAP3(p) ~ O(P3(p -1)). Claim P3 -P4: P3(0) .-~ P4(N). Claim P4: 0<p<NAP4(p) --* O(P4(p \n-I)). So, we conclude that init --~ O(P4(0)). Since P4(0) ~ 0Send(i) -2N, we have established the precondi-tion \nof Stage II of safety (the safe-liveness portion). This establishes liveness. Let us reconsider now the \noriginal program for which iiveness can be proved only probabilistically. We adopt the approach developed \nin [Pn] by which it suffices to prove liveness for all extremely fair computations. For the present case \nin which the processes operate synchronously the relevant proof rule is a simplified version of the rule \nin [Phi : }-P may lead from Sto~   boO~ --o0~  That is, if by an appropriate choice of the probabilistic \nactions we can get from any state satisfying ~, to a state satisfying in one step, then if ~ holds infinitely \nmany times then so does ~k. The assertions ~ and ~k are any first order expressible state assertions. \nLet us consider the structure of the deterministic program above. It typically consisted 'of two types \nof steps: a) A logical implication such as: PI -P2: Pl(0) ~ P2(N), and b) One step implications such \nas: Pl: p>0^Pl(p) --~ :mp'(0<p<p) s.t. O(Pl(p')) from which we inferred by induction Pl(p) --~ OPI(O) \n We now Iransform the proof above as follows: a) Each logical implication ~ -.. ~k is transformed into: \n o0~ ~ 00~  That is, if ep holds infinitely often then so does Lk b) Each one step implication such \nas $ ~ O~k is transformed first into I\"-Program may lead from ep to \u00a2,. The justification of ~ ~ O~k \ninvariably used local reasoning which often includes the assumption that i draws a delay of I and every \nj#,i draws 2N + I. This means that there exists some probabilistic choice that will always lead from \na ,# state into a ,/,-state. This is exactly the statement that the program may lead from ,~ to ~k. Consequently, \nwhenever we could previously justify ~ ~ O~k for the modified program we can now justify \"P may lead \nfrom ,/, to ~k\" in the original program. From this by the extremely-fairness rule we conclude: ~o0~-~ \n00~.  We now apply the following induction rule: ~p>0^00$(p) --~ 1-10yp'(0<p'<p) s.t. ep(p') ImOO~'(p) \n\"\" 005(0)  This rule can be justified by the proof system for linear tem- poral logic. As a result we \ncan transform any step in the proof such as: Pl(p)-... OPI(O) into: OOPl(p) -.~ O<}Pl(O).  Consequently \nthe complete proof of the liveness property is transformed into: I) Fl~init .., 00Send(i) --2N. To complete \nthe proof in the probabilistic case we assume that i wants to send. It is not too difficult to infer \nfrom this that: e~init. Together with I above this shows that i completes sending its message. Section \n5. Shortest Delay Access Method Protocol The Ethernet-like protocol we have just analyzed is a conten- \ntion protocol. We now analyze a typical, but non-trivial, contention-free protocol. We present a style \nof invariaot that seems to be widely applicable to such protocols. The communication subnet topology \nwe consider for this algorithm is a line segment as shown for example in figure 3. The designers [LH] \nhave generalized the protocol to a tree structured topology, but we restrict ourselves to a linear to- \npology for expository reasons. The algorithm for this protocol is shown in figure 2. A mes-sage originating \nat process i contains a \"token direction\" field whose value is either right or left. When a process i \nsends a message, it sends message portions in both directions along the subnet. Processes with no messages \nto send are in the IDLE state. When a process j has a message to send, it en- ters the WAIT state. The \nprocess stays in the WAIT state 61 until it receives an end-of-message for a copy of a message whose \ndirection is the same as its token direction, The proc- ess then enters/the READY state with a delay \ntime dependent on the difference between its process identifier and the proc- ess identifier of the originator \nof the previous end-of-message. (This dependence on the process identifiers of previous sen- ders is \nthe principal algorithmic feature of contention-free protocols that is absent in contention protocols.) \nIf j's delay time goes to zero, it sends its message to completion associat- ing the same token direction \nwith its message as the token direction of the message it most recently received. The proto- col guarantees \nthat a sending process won't detect other proc- esses while transmitting, obviating the need for collision-detection. \nFor simplicity, we don't explicitly show the proc- essing of received messages, as we did for the Ethernet. \nSuff-ice it to say that messages addressed to a given process are passed on to the client level of that \nprocess. j wants.to-send m length - 0 j receives j receives flt'st blank following mli) ^direct (i,j) \n= token(re(i)) ~ldclay :- (IJ-tl)d; token(re') :. token(mti));I w~u4e mnt bY l pmvl~m m~ge I I i j \nFlswl S -kbesaatlc ~btr~&#38;#169;terl'r.mtloo ;bowlns that J mekl be at READY. even U~h e ams Or tro,~, \nt q~mgtm J. in order to show that the situation of figure 3 never comes to pass, we must specify the \nstate of the channel. The state must tell whether there is a message unit at each location, the direction \nit is travelling, and the identifier of the sender. This will be sufficient to show that process j of \nfigure 3 will receive before its delay shrinks to zero. As we have observed, this protocol allows many \nmessages to be on the subnet simultaneously. We imagine that these messages and the blank spaces among \nthem form a \"train\", containing message units (corresponding to boxcars) and blanks (corresponding to \nflatcars) as in figure 4. delay - I~ \\ -llength :- Ire'l; ~ delay OI length> I dglay > I ^ ~j receives \n~lsend next unit; ~{delay :. delay - I;Ilength:. length-I;} Figure 2 - Sh,,rtest Dcl;iy Access bleth\u00a2~ \nProtocol Processes at the right and left ends of the line segment are called end-processes. They have \na slightly different protocol in that they are never in the IDLE state (they are always ready to send \nat least a token) and they reverse the direction of the token. The leftmost process has an identifier \nof zero and the processes are numbered in ascending sequential order up to the rightmost process. The \nintuitive reason the algorithm works is that after a proc- ess i stops sending, processes to the right \nor processes to the left, but not both, may enter READY, depending on the token direction. Of those at \nREADY~ the one closest to i will have the shortest delay time and will be the next to send. Its delay \ntime will be so much shorter that it will be able to prevent other processes from sending once it initiates \nits own message. The main difficulty is to show that the difference in the delays is such that if i \nstarts to send and j is at READY, then j will not start to send at least until it has received the end-of- \nmessage of i. Figure 3 gives a schematic characterization of this situation. Messages attach to the end \nof the train from \"spurs\". The spur of j contains a preamble consisting of d blanks (the delay time of \nj after receiving the first blank following a message of j -1) and a message length of len(j), which \nmay be zero. At any one time, at most one spur is feeding the train. Since the train is meant to characterize \nthe progress of messages along a channel, a message unit from a spur becomes two message units: one going \nto the right and one going to the left. Each message unit (boxcar) is labelled with the process which \nsent it, the token direction of the message it is part of, and a direction. Suppose the message from \ni, re(i) is sent with a token direction of right. Then all units.from the message re(i) (both left-going \nand right-going) are labelled with an identifi- er of i and a token direction of right. Figure 4 shows \nthe three kinds of situations the train can be in. (The figure only shows the right-going portion of \na train all of whose bits are labelled with a token direction of right.) In the first situation, the \ncaboose is at process j with the blanks from the preamble feeding in (figure 4.1). In the second, the \ncaboose is at j with the message feeding in (figure 4.2). Each new message unit or blank becomes the \nnew ca- boose. Once the last message unit feeds in from the spur of j, the caboose moves to the right. \nIn the third, the caboose c of a the train is between two processes j and j + 1 (figure 4.3). Provided \nthere is only one source of message units (boxcars) and the channel (track) contains no units which approach \nthe caboose, this characterization guarantees that there will be at most one message unit (boxcar) per \nposition on the channel (track). This establishes safety directly. Since the caboose will arrive at every \nspur, each process will be permitted to send. This establishes liveness. Hence, our main task will be \nto show that the train is always in one of these three situations, assuming the following initial conditions: \n 62 m(j) -number of message units from process j already on the channel. the leftmost process (process \nO) sends a single message unit with a token direction of right; all other processes are in the IDLE or \nWAIT states; and if there are nonblank positions, they consist of right-going bits with token directions \nof left (remaining from a previous run of the train from right to left). Since we have quite a few functions \nand predicates, we list them in alphabetical order: blank(x) -position x on the channel has no message \nunit on it. d -the minimum delay of one process after receiving the first blank following a message of \nanother process. This is a par- ameter of the algorithm (figure 2). delay(j) -the current delay of process \nj. dir(x) -direction of movement of the bit at location x. it assumes the values left or right if x is \noccupied by a message bit and is undefined otherwise. id(x) -if x is not blank, then the process from \nwhich the unit at position x originated This is undefined if there is more than one originating process. \nlen(j) -length of the message process j wishes to send. loc(j) -location of j NumBlanks(x,x') -number \nof blanks between x and x' inclu-sive. prc(j) -number of blanks from the preamble of process j that are \nalready on the channel. rprocess -identifier of rightmost process. rightend -Ioe(rproccss). token(re(i)) \n-direction of the token associated with re(i). tokendir(x) -dircction of the token associated with the \nbit at X. twodir(x) -bit at location x has both a left direction a right direction. This predicate is \ntrue only for bits that have just been generated by a sending process, in the next step each such bit \nsplits into a right-going bit and a left-going bit. The movement of bits along the channel can now be \ndefined in terms of these predicates. Axioms: I. ((dir(x) = right)vtwodir(x))^(x<rightend) ^(id(x) = \ni)^( tokendir(x) ~ y)) O((dir(x + I) = right) ^(id(x + I) = i)^ (tokendir(x + I) ~ y)) 2. ((dir(x) = \nleftvtwodir(x))A(0<x) ^(id(x) = i)^(tokendir(x) = y)) ~ :~ O((dir(x -I) = left) ^(id(x -I) = i)^(tokendir(x \n-I) = y)) 3. i sends^token(re(i)) = y ,----* O(twodir(Ioe(i)) ^ id(Ioe(i)) = i ^  tokendir(Ioc(i)) \n= y) 4. O(~blank(loe(i))) --~ O(i receives). We are now ready to express our train predicate. For simplic- \nity we deal with the predicate that characterizes a right-moving train all of whose bits have a token \ndirection of right. For this reason, we call the predicate rtrain. We will number the clauses of the \npredicate and explain them below. e . rtram(c,c ,j,w,m): I. w = pre(j)^m = m(j) 2. Vx((x>c) --~ (blank(x)v(dir(x) \n= right))) ^Vx((x<c) --=. (blank(x)v(dir(x) = left))). 3. i c ! = min(rightend, c + jd + ~\" re(k) + \nw). k=l  4. Vx((x>c') --~ (blank(x)vtokcn~lr(x) = left)) ^Vx((0<x<c') ~ (blank(x) v(tokendir(x) = right^id(x) \nis defined)). 5. Vr((c' < Ioc(r) v Ioc(r) <c) --~ (r at IDLEvr at WAIT)). 6. Vk(0_< k <_rprocess)Vx((e \n< x <_e' ^ ~ blank(x)^id(x) = k) --,. (k<_j^ NumB|anks(c,x) = (j -k)d + w)). 7. Yh(c<loc(h) <c' h at \nIDLEvh at WAITv~blank(Ioc(h))v (h at READY^(Delay(h) = NumBlanks(e,loc(h)) + (h -j)d -w)).  Clause I \nsimply identifies the w and m parameters with the number of blanks of the preamble and the number of \nmessage 63 units respectively of j that are already on the channel. Clause 2 says that all the non-blank \nlocations Io the left of c are left-going and all those to the right of c are right-going. Clause 3 specifies \nthe location of the right end of the rtrain. Clause 4 says that all locations between c and the right \nend of the rtrain have token directions of right and unique id s. Locations beyond the right end of the \nrtrain have token direc- tions of left and unique id's; these were produced by the previom; Itrain -the \nsymmetric situation when all units have token directions of left. Clause 5 says the processes to the \nleft of c and to the right of c ~ are in WAIT or in IDLE. Clause 6 gives the number of blanks between \nc and some message re(k), where c<loc(k). Clause 7 makes use of clause 6 by bounding the delay from below \nby a delay factor plus'the number of blanks between c and Ioc(k). Having parameterized rtrain, we can \ndescribe the three situa- tions of figure 4 quite succinctly. The union of the three situations will \nbe our invariant. R I : c = Ioc(j) ^ rtrain(c,c',j,pre(j).0) A (j at WAITvj at IDLE vfj at READyAdclay(j)=d-pre(j))). \nR2: c={oc(j)^rtrain(c.c',j,d,m(j))^ j. at TRANSMIT^~blank(Ioc(j))^delay(j)=0^ twodir(Ioc(j)) ^ re(j) \n< len(j). R3: Ioc(j)<c<loc(j + I)artrain(c,c',j,tl,len(j)). R I is the situation of figure 4.1 where \nthe flatcars of (i.e. blanks in the preamble) are coupled to the train. Note that they do so even when \nj is at WAIT or IDLE. This reflects the fact that algorithm gives each process a turn to send whether \nit wants to or not. R2 is the situation of 4.2 where boxcars from j (i.e. message units) couple to the \ntrain. R3 is the situation of 4.3 where the train is between j and j + I (i.e. j is no longer sending). \nOur invariant for the case when the token direction of each bit in thc train is right is RIvR2vR3. To \nguarantee that this invariant is maintained we list six prop- ositions which characterize the changes \nof the rtrain predicate from one instant to the next. After listing them, we will explain their correspondence \nto the invariant. Proposition 1A: (Counting Down Delay) (c = lee(j) ^ rtrain(c,c~,j,w,t)) ^ w<d) --~ \nO(rtrain(c,e' + I,j,w + 1,0)) Proposition 1B: (Preparing to Send) (c = Ioc(j) ^ rtrain(c,cl,j,d,0) ^0<len(j) \n^j<rprocess) --~ O(rtrain(c,c ~ + I,j,d,l)) Proposition 2A: (Counting Down Message) (c = lee(j) ^ rtrain(c,ct,j,d,w) \n^ w<len(j)) --~ O(rtrain(c,c ~ + I.j,d.w + I)) Proposition 2B: (Preparing to Stop) (c = lee(j) ^ rtrain(c,c',j,d.len(j)) \n--* O(rtrain(c + I.c p + I,j,d.len(j))). Proposition'3A= (Between Spurs) ((loc(j)<c<loc(j + I)-l)^rtrain(c,cl,j,d,len(j))) \n--. O(rtrain(c + I,c t + I.j,d,len(j))) Proposition 3B: (Approaching Spur) ((c = Ioc(j + 1 )- I )^ rtrain(c,c',j,d,len(j)) \n--. O(rtrain(c + I,c' + l,j + 1,0.0)) Proposition IA specifies the changes of the rtrain which occur \nwhile RI holds. Proposition IB shows the transition from a case where R1 holds to one where R2 holds. \nSimilarly, prop- osition 2A governs transitions from instants where R2 holds to other instances where \nR2 holds and proposition 2B de-scribes the transition from R2 to R3. Propositions 3A and 3B handle the \nstates of rtrain in between stations. We omit the proof of the propositions themselves. Safety and Liveness \nSafety consists of the proposition that any non-blank location will consist only of message units from \none process. This is weaker notion of safety than the classical one which says that if i sends a message \nthen eventually j will receive that mes-sage. The stronger notion only requires that more information \nbe attached to each bit and that we prove easy but long theo- rems describing the movement of the bits. \n Theorem Safety: If R 1 v R2 v R3 ^ rtrain(0,0,0,0,0) ^ (\u00a5j(l_<j<rprocess) (j atmlDLEv j at WAIT)), then \nI-I(~blank(x) --~ (id(x) is well-defined)). The fact that id(x) is well defined implies that position \nx on the communication line is occupied by a bit that originated at a single process. Consequently, this \ninvariant implies that no collision or overlap between two distinct messages can occur. Proof: R1 vR2vR3 \nis maintained as an invariant by propo- sitions 1A-3B. Each clause of the invariant implies that 3a,b,c,e,f \ns.t. rtrain(a,b,c,e,f). The rtrain predicate implies that for all locations, ~blank(x) ..., id(x) is \nwell-defined. [] As for the Ethernet, liveness is the proposition that process i eventually sends its \nentire message if it wants to send now. Since we have only defined rtrains, we cannot prove full live- \nness, but rather a limited version, namely: Theorem Livonoss: (rtrain(c,e~,k,x,y)^c<loc(i)^i wants to \nsend) --~ 0 (rtrain(Ioc(i),x,i,d,len(i))). Proof: The main idea in the proof is that eventually the \nend of the train reaches every process. When it reaches a process that wants to send, the process couples \nits message with pre- ceding blanks to the end of the train. The progress of the train is clear in between \nstations (processes), but it is delayed for awhile at each station. This delay however, is bounded by \nd plus the size of the current message, if any, that the process wants to send. Let us measure the distance \nbetween an arbi- trary instance rtrain(a,c,j,e,f) and our goal rtrain(Ioc(i),x,i,d,len(i)) assuming a<loc(i). \nOur measure will be the following two-tuple: (Ioc(i)-a,(d + len(i)) + (d + len(j))-(e + f)). Suppose \nwe consider the two-tuples to be lexicographically ordered. We observe that every transition allowed \nby propositions IA-3B decreases the difference so measured. Therefore the differ- ence eventually reaches \n(0,0), [] Full liveness requires that we define a predicate Itrain to be symmetric to rtrain and invariant \nclauses LI, L2, and L2 to be symmetric to RI, R2, and R3. We also need an axiom which shows how an rtrain \nis transformed into an Itrain (as well as the symmetric transformation the other way): r train(rightend,rightend,rprocess,d,O) \n--~ O( I train(rightend,rightend,rprocess,d, 1 )). Liveness then consists of the proposition: &#38;i \n-wants -to -send--. ~(rtrain(Ioc(i),x,i,d,len(i))v  Itrain(Ioc(i),x,i,d,len(i))). We omit the details \nof the proof. Section 6: Conclusion We have studied proof methods for local area network proto- cols. \nTo facilitate one possible approach, we have introduced a decidable temporal logic proof system which \npermits state- ments about time intervals. We have used both classical temporal logic and our extended \nlogic to verify typical conten- tion and contention-free protocols. We have observed that the extended \nlogic captures the intui- tive argument underlying contention protocols better than the classical temporal \nlogic. By contrast, contention-free proto- cols enjoy the inherent invariant of being collision-free, \nhence invariants (and therefore the classical logic) appear to be more natural for these algorithms. \nPut another way, contention-free protocols enable us to reconstruct the essen-tial features of a system's \nhistory from the present state and therefore do not require the strong measurability of timc offered \nby the Quantified Interval logic. We observe again that this is not an impossibility argument, as the \nsimpler for- malism can be applied to contention protocols as well. Still. we think a formal study of \nthe appropriateness of various logics to different kinds or real-time problems is an important direction \nfor future work. Acknowledgement This work began as a term project by one of us (Shasha) for Ed Clarke's \ncourse on formal languages at Harvard in the fall of 1981. We would like to thank Ed Clarke, Steve German, \nand Jude Miller for their helpful comments on earlier drafts of this work. We would also like to thank \nJo Genzano for her expert typing of the manuscript. References [Cla] E.M. Clarke, \"Proving the correctness \nof Coroutines without History Variables,\" Acta lnformatica 13, 169- 188 (1980). [Cli] M. Clint, \"On the \nUse of History Variables,\" Aeta informatica 16, 15-31 (1981). [HMMIJ. Halpern, Z. Manna, and B. Moszkowski, \n\"A Hard- ware Semantics Based on Temporal Intervals,\" STAN- CS-83-963, March, 1983. Stanford University. \n[HOI B. T. Hailpern and S. S. Owicki, \"Modular Verifica- tion of Computer Communication Protocols,\" IEEE \nTransactions on Communications, Vol. COM-31, No. I, January 1983. [KVdRIP. Koymans, J. Vytopil, and W. \nP. de Roever \"Real- Time Programming and Asynchronous Message Pass- ing\" ACM Proceedings of the Second \nAnnual ACM Symposium on Principles of Distributed Computing, pp. 187-197, August. 1983. [Kr] F. KrOger, \n\"LAR: A Logic of Algorithm Reasoning,\" Acta Informatiea 8, 243-266 (1977). [LH] L. Li and H. D. Hughes, \n\"Definition and Analysis of a New Protocol,\" Proc. 6th Conference on Local Com- puter Networks, Minneapolis, \n198 I. [MBI R. M. Metcalfe and D. R. Boggs, \"Ethernet: Distrib-uted Packet Switching for Local Computer \nNet-works.\" Comm. ACM Vol. 19, pp. 395-404, July 1976. [Mosl  [MPI lPnl IOGI lOLl I SMV  1 SPE [Tanl \nB. Moszkowski, \"A Temporal Logic for Multi-level Reasoning about Hardware,\" STAN-CS-82-952, De-cember, \n1982. Stanford University. Z. Manna and A. Pnueli, \"Verification of Concurrent Programs: Temporal Proof \nPrinciples,\" Proc. of the Workshop on Logic of Programs (D, Kozen, ed.), Yorktown Heights, NY (1981). \nSpringer-Verlag Lec- ture Notes in Computer Science 13 I, pp. 200-232. A. Pnueli, \"On the Extremely Fair \nTreatment of Pro- babilistic Algorithms\", 15th ACM Symposium on The- ory of Computing, Boston, April \n1983. S. S. Owicki and D. Gries, \"Verifying Properties o[ Parallel Programs: an axiomatic approach,\" \nCACM 19 (5): 279-285. May 1976. S. S. Owicki and L. Lamport, \"Proving Liveness Prop- erties of Concurrent \nPrograms,\" ACM Transactions on Programming Languages and Systems. Vol. 4, No. 3, pp. 455-495, July 1982, \n] R. L. Schwartz, P. M. Melliar-Smith. and F. H. Vogt, \"An Interval Logic for Higher-Level Temporal Rea-soning.\" \nACM Proceedings of the Second Annual ACM Symposium on Principles of Distributed Com- puting, pp. 173-186, \nAugust, 1983. [ D. E. Shasha. A. Pnueli, and W. Ewald. \"Temporal Verification of Carrier-Sense Local \nArea Network Protocols.\" IBM Research Report, RCI0132. August 1983. A. S. Tanenbaum, Computer Networks, \nPrentice-Hall, 1981. 65 \n\t\t\t", "proc_id": "800017", "abstract": "<p>We examine local area network protocols and verify the correctness of two representative algorithms using temporal logic. We introduce an interval temporal logic that allows us to make assertions of the form &#8220;in the next k units, X holds.&#8221; This logic encodes intuitive arguments about contention protocols quite directly. We present two proofs of an Ethernet-like contention protocol, one using the interval temporal logic and one using classical temporal logic. We also verify a contention-free protocol using an invariant that seems to have wide applicability for such protocols.</p>", "authors": [{"name": "D. E. Shasha", "author_profile_id": "81332526781", "affiliation": "Harvard University and IBM", "person_id": "PP14107702", "email_address": "", "orcid_id": ""}, {"name": "A. Pnueli", "author_profile_id": "81100648459", "affiliation": "Harvard University and Weizmann Institute", "person_id": "PP40036715", "email_address": "", "orcid_id": ""}, {"name": "W. Ewald", "author_profile_id": "81100608065", "affiliation": "Oxford University", "person_id": "P334243", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/800017.800516", "year": "1984", "article_id": "800516", "conference": "POPL", "title": "Temporal verification of carrier-sense local area network protocols", "url": "http://dl.acm.org/citation.cfm?id=800516"}