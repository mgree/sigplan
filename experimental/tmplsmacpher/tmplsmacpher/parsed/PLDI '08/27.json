{"article_publication_date": "06-07-2008", "fulltext": "\n Inferring Locks for Atomic Sections Sigmund Cherem * Department of Computer Science Cornell University \nIthaca, NY 14853 siggi@cs.cornell.edu Abstract Atomic sections are a recent and popular idiom to support \nthe development of concurrent programs. Updates performed within an atomic section should not be visible \nto other threads until the atomic section has been executed entirely. Traditionally, atomic sections \nare supported through the use of optimistic concurrency, either using a transactional memory hardware, \nor an equivalent software emulation (STM). This paper explores automatically supporting atomic sections \nusing pessimistic concurrency. We present a system that combines compiler and runtime techniques to automatically \ntransform pro\u00adgrams written with atomic sections into programs that only use locking primitives. To minimize \ncontention in the transformed pro\u00adgrams, our compiler chooses from several lock granularities, using \n.ne-grain locks whenever it is possible. This paper formally presents our framework, shows that our compiler \nis sound (i.e., it protects all shared locations accessed within atomic sections), and reports experimental \nresults. Categories and Subject Descriptors F.3.2 [Semantics of Pro\u00adgramming Languages]: Program Analysis; \nD.3.3 [Language Con\u00adstructs and Features]: Concurrent programming structures; D.3.4 [Processors]: Compilers \nGeneral Terms Algorithms, Languages, Theory, Experimenta\u00adtion, Performance Keywords Static lock inference, \natomic sections, concurrency. 1. Introduction One of the main problems when developing concurrent software \nis to maintain a consistent view of the shared state among all the con\u00adcurrent threads. For many years \nprogrammers have used pessimistic concurrency to develop these applications. Pessimistic concurrency \nconsists of blocking the execution of some threads in order to avoid generating an inconsistent shared \nstate. For example, using locks to prevent data races. However, developing reliable and ef.cient applications \nwith pessimistic concurrency is an arduous task. Pro\u00adgrammers need to use .ne-grain locks to minimize \ncontention and * This work was developed while the author was an intern at Microsoft Research, Redmond. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n08, June 7 13, 2008, Tucson, Arizona, USA. Copyright c . 2008 ACM 978-1-59593-860-2/08/06. . . $5.00 \nTrishul Chilimbi Sumit Gulwani Microsoft Research One Microsoft Way Redmond, WA 98052 {trishulc, sumitg}@microsoft.com \nneed to carefully acquire and release locks to eliminate the possibil\u00adity of a harmful data race and \ndeadlocks. This is especially dif.cult to do in a modular way. Consider, for example, combining library \ncode and client code, the absence of deadlocks in the library code and in the client code does not guarantee \nabsence of deadlock in the composition of the library and client code. Even after mastering all these \nchallenges, programmers do not always have a guarantee that the written locks yield the intended program \nsemantics. Recently, programming languages researchers have adopted the concept of atomic sections from \nthe database community as a possible alternative. Atomic sections allow programmers to give a high level \nspeci.cation of the concurrency semantics. Without any intervention from the programmer, the underlying \nsystem enforces that atomic sections, i.e. sections of code protected by an atomic keyword, appear to \nbe executed atomically. Under strong atomicity semantics these sections appear to be atomic with respect \nto any other statement in the program. Whereas under weak atomicity semantics atomic sections appear \nto be atomic with respect to other atomic sections in the code [2]. That is, for any program execution \ntrace, there must exist an equivalent trace where all atomic sections are executed in some serial order. \nFor programmers this is a very attractive alternative, since all the dif.culties of manual pessimistic \nconcurrency are abstracted away. A natural implementation of atomic sections is to use optimistic concurrency \nvia the use of specialized transactional memory hard\u00adware (TM) [12, 11] or a software transactional memory \n(STM) that emulates such hardware [21, 9, 17]. These systems treat atomic sec\u00adtions like transactions \nand allow them to run concurrently. When\u00adever a con.ict occurs, one of the con.icting transactions is \nrolled back and re-executed. Some systems [20, 7] would prevent con.icts using locks, but roll back transactions \nwhen a deadlock occurs. An optimistic system is typically desired when con.icts are rare and hence rollbacks \nseldom occur. However, optimistic concurrency has some disadvantages. Cer\u00adtain applications do not perform \nwell under an optimistic concur\u00adrency model as they incur a large number of transaction aborts and rollbacks. \nAdditionally, not all atomic sections can be rolled back, for example after observable actions are performed. \nA well designed pessimistic approach could provide an alternative that avoids these disadvantages, by \noutperforming optimistic concur\u00adrency in applications that are not suited to transactions, and not performing \ntoo much worse than transactions in programs where transactions scale. In addition, a pessimistic approach \nallows ob\u00adservable actions inside atomic sections. This paper presents an automated system to support \natomic sec\u00adtions using pessimistic locking. Our system consists of a compiler framework and a runtime \nlibrary. The compiler reads programs with atomic sections and produces equivalent programs that use lock \nfor concurrency-control. The inferred locks enforce the weak atomicity semantics of the atomic sections. \nThe transformed pro\u00ad 1: void move (list* from, list* to) { 2: atomic { 3: elem* x = to->head; 4: 5: elem* \ny = from->head; 6: from->head = null; 7: if(x==null){ 8: to->head = y; 9: }else{ 10: 11: while(x->next \n!= null) 12: x = x->next; 13: x->next = y; 14: } 15: } 16: } (a) acquire(to.head); elem* x = to->head; \nacquire(from.head); elem* y = from->head; from->head = null; if (x == null) { to->head = y; } else { \nacquire(x.next); while(x->next != null) x = x->next; x->next = y; } releaseAll(); (b) acquireAll({to.head, \nfrom.head, E}); elem* x = to->head; elem* y = from->head; from->head = null; if (x == null) { to->head \n= y; } else { while(x->next != null) x = x->next; x->next = y; } releaseAll(); (c) Figure 1. Example \nprogram: moves list elements between from and to. (a) Original program with atomic section. (b) Fine-grain \nlocking scheme susceptible to deadlock. (c) Multi-grain locking scheme avoiding deadlock. E is a coarse \nlock protecting all elements in the to list. grams can be run using a special lock runtime library. This \nap\u00adproach allows users to write programs with atomic sections and run them without the need of specialized \nhardware or an STM. Our compiler provides several guarantees about the transformed programs. The generated \nprograms must: (a) satisfy the weak atom\u00adicity semantics originally speci.ed by the atomic sections, \n(b) be deadlock free, and (c) avoid unnecessary thread contention intro\u00adduced by locks. The last property \nis necessary to avoid using trivial locking schemes that waste parallelism, for example, using a single \nglobal lock to protect all atomic sections. This paper discusses in detail how we generate programs satis\u00adfying \nthese properties. First, to satisfy the atomic semantics we for\u00admally show that locks introduced by the \ncompiler protect all shared locations accessed within an atomic section. Second, to avoid dead\u00adlocks \nwe borrow a locking protocol from the database community. Third, to reduce contention we insert locks \nof multiple granulari\u00adties, using .ne-grained locks as much as possible. The following summarizes our \ncontributions: We present formal de.nitions to model locks. We de.ne the notion of abstract lock schemes \nthat allows us to represent locks and the relation between locks of different granularities.  We present \na formal analysis framework to infer locks for an atomic section, given an input lock scheme speci.cation. \n We show that our analysis is sound. That is, if at the entry of an atomic section each thread acquires \nthe locks inferred by our analysis, then the execution of the program is guaranteed to respect the weak \natomicity semantics.  We describe a library to support locks of multiple granularities.  We show experimental \nresults for an instance of our framework indicating that the analysis scales well to medium size appli\u00adcations, \nyields better performance for benchmarks not suited to transactions, and performs not too much worse \nthan an STM in some benchmarks where transactions scale.  The rest of this document is organized as \nfollows. Section 2 illustrates the ideas behind our system using several examples. Section 3 introduces \nour formal de.nitions for locks and abstract lock schemes. Section 4 formalizes the analysis framework \nthat in\u00adfers locks, and discusses how we implemented an instance of this framework. Section 5 discusses \na multi-grain locking runtime li\u00adbrary used to support the transformations enabled by our analysis. We \npresent our experimental results in Section 6. Finally, we dis\u00adcuss related work in Section 7 and conclude \nin Section 8. 2. Example This section presents two examples to illustrate the features of our system. \nThe examples use a list data-structure de.ned in terms of two datatypes: typedef struct struct elemtypedef \nstruct elem_t _t* nexlist_t { t; int* { elem* data; head; } } elem; list; Atomic sections with locks \nFigure 1(a) presents a program that moves elements from one list to another. By the end of the function \nmove the list from is empty and the list to contains the concate\u00adnation of the input lists. The entire \nfunction should be executed atomically, since it is wrapped in a block labeled with an atomic keyword. \nThe goal of our system is to introduce locks to enforce the semantics of the atomic section. A .rst attempt \nto write the code using locks would be to acquire a global lock at the entry of the atomic section, and \nrelease it by the end of the section. This approach could introduce a lot of contention: the function \nmove cannot be executed in one thread if any other thread is inside an atomic section. A second attempt \nwould be to use .ne-grain locks, one lock for each location accessed within the function move. Figure \n1(b) shows the result of this approach. Before accessing a location v we request a .ne-grain lock to \nprotect it using a call to acquire(e), where e is an expression whose value is the location v. Then, \nwe release all locks by the end of the atomic section. Unfortunately, this code is susceptible to deadlocks. \nFor example, if we call move(l1,l2) and move(l2,l1) concurrently, the .rst thread could lock l1.head \non line 2, the second thread could lock l2.head on the same line, then both threads will be blocked in \nline 4. Our system uses a third approach, which consists in avoid\u00ading deadlocks by using a locking protocol. \nThe protocol is imple\u00admented by acquiring all locks at the entry of the atomic section. To use the protocol, \nour compiler needs to estimate what locations are accessed within the atomic section, and then introduce \nlocks at the entry of the section to protect each accessed location. Fine-grain locks can still be used \nto protect shared locations, as long as the compiler can determine an expression that protects the desired \nlocation. However, when atomic sections access an un\u00ad 1: elem* y,x; 2: int* w; 3: ... 4: if (...) { 5: \nx=y; 6: } 7: atomic { {y->data, w} 8: x->data = w; {y->data, w} 9: int* z = y->data; {y->data} 10: *z= \nnull; {z} 11: } Figure 2. Analysis example: .nding .ne-grain protecting locks. bounded number of locations, \nor when there is no expression in scope to protect a shared location, our system introduces coarse\u00adgrain \nlocks. Figure 1(c) shows the transformation our system gen\u00aderates for the function move.The acquireAll \ninstruction applies the locking protocol on the input set of locks. The locks on to.head and from.head \nare .ne-grain locks. The lock E is a coarse-grain lock used to protect every element of the to list. \nFinding .ne-grain locks Our compiler tries to use .ne-grain locks as much as possible. To achieve this \ngoal, the compiler needs to describe the locations accessed within an atomic section in terms of expressions \nthat are in scope by the entry of the atomic block. We use the example in Figure 2 to illustrate this. \nIn Figure 2, consider the shared location pointed by z at line 10. Note that the expression z is not \nin scope at the entry of the section, because z is de.ned later at line 9. The compiler performs a backward \ntracing to deduce what expressions are equivalent to z at the entry of the section. At line 9 the compiler \ndetermines that z is equivalent to y->data. The expression y->data can be affected by the update of x->data \nat line 8 if x and y are aliased. In fact, x will alias y if the true branch at line 4 is taken. Since \nthe compiler can t decide whether this branch is taken or not, it must consider both cases. When x and \ny are aliased, x->data will replace the value of y->data, and hence the location pointed by z at line \n10 would be equivalent to w at the entry of the atomic section. Otherwise, when x and y are not aliased, \ny->data is not changed by the assignment in line 8, and thus y->data at line 7 would point to the location \nthat z points to at line 10. The compiler performs a similar backward tracing for every lo\u00adcation accessed \nwithin the atomic section. Then, it introduces calls to acquire .ne-grain locks for each expression derived \nat the entry of the section. For instance, in our example the compiler will lock both y->data and w ensuring \nthat the access on line 10 is always protected by one of these locks. Additionally, to ensure termina\u00adtion \nthe compiler bounds the size of the expressions it collects. The compiler introduces calls to acquire \ncoarse-grain locks to protect expressions whose size exceeds the established bound. 3. Formalizing Locks \nThis section introduces formal de.nitions about locks. These def\u00adinitions will be useful to answer questions \ninvolving locks and atomic sections. For example: What shared locations are protected by a lock? Are \ntwo locks protecting a common location? Are all shared accesses of an atomic section protected by a set \nof locks L? After introducing our input language, we will proceed by giving a de.nition of concrete locks \nsemantics. We will show how this formal semantics can be used to answer some of the questions above. \nThen we will instantiate our general semantics de.nition to give examples of commonly used locks. In \nthe last part of this section we will introduce the notion of an abstract lock scheme. Abstract locks \nare essentially an approx\u00ad st .Stmt ::= x = e |*x = e | if( b) st else st |while( b) st | st; st |atomic{st} \ne .E ::= x |*x |&#38; x |x + i |new( n) |null | f( a0,...,an) b .B ::= x = y |b .b |b .b |\u00acb Figure 3. \nInput Language imation of concrete locks that we use to formalize our inference system. The formal de.nitions \nwill allow us to show that our tool produces programs that respect the atomic semantics. 3.1 Language \nFigure 3 presents our input language. The language contains stan\u00addard constructs such as heap allocation, \nassignments, and control\u00ad.ow constructs, but also includes atomic sections. Expressions in\u00adclude variables, \ndereferences, address-of variables, offsets, alloca\u00adtions, and null values. All values in this language \nare locations or null, no pointer arithmetic is allowed. Array dereferences and struc\u00adture dereferences \nare not distinguished, they are all modeled using .eld offsets. We denote the domain of offsets by F \n. Return state\u00adments return x are modeled by an assignment retf = x,where retf is a special variable \nmodeling the return value of f. Our output language is the same as the input language, except that atomic \nsections are replaced by two instructions: acquireAll( L) , that receives a set of locks L,and releaseAll, \nthat releases all locks held by a thread.  3.2 Concrete Lock Semantics A lock is simply a name l in \nsome domain LNames that implicitly protects a set of locations. We introduce a lock semantics to make \nthis relation between locks and locations explicit. We write the semantics of a lock l using the denotational \nfunction in the domain: [[ \u00b7]] : LNames .2 Loc \u00d7E. where Loc is the domain of memory locations and E. \n= {ro, rw}is the domain of access effects (reads and writes). When [[ l]] =( P, e) we say that l is a \nlock that, when acquired, protects all locations in the set P , but only to allow the accesses described \nby e. For example [[ l]] = ( {v}, ro) then l ensures that v is protected for reads, but it is not protected \nto update its value. With this de.nition, we can distinguish .ne-grain and coarse\u00adgrain locks. A .ne-grain \nlock protects a single memory location at all times, formally, .v. [[ l]] =( {v}, ) while a coarse-grain \nlock may protect more than one location. The domain 2 Loc and the subset relation .form a lattice. We \nalso de.ne a simple two point lattice ( E., .) for the set of effects, where the read-write effect is \nthe top element (ro . rw). The domain used in the lock semantics (2 Loc \u00d7E.) forms a lattice as well, \nwhich is de.ned as the product of the two lattices (2 Loc , .) and ( E., .) . We can use the lock lattice \nto reason about the relation between locks, for example: Con.ict: two locks con.ict if they protect a \ncommon location, and at least one of them allows write effects: con.ict( la,lb) . [[ la]] n[[ lb]] ) \n=( \u00d8, . [[ la]] U[[ lb]]=( , ro) Coarser-than:a lock lb is coarser-than a lock la if it protects all \nlocations protected by la, allowing at least the same effects: coarser ( lb,la) .[[ la]] .[[ lb]] 3.2.1 \nExamples where p is a program point in the domain PP and e is an effect \u00b7 ep in E.. The operator takes \na variable symbol and returns a lock We now give several example of locks, characterized using our semantics \nde.nition. epep and * ep are used to relate different; the operations +name l = x locks in L. Together \nthey can be used to express what locations are Expression locks Program expressions can be used to de.ne \n.ne\u00adgrain locks. Let s denote a program state in our concrete seman\u00adtics, and consider a program expression \ne. Whenever the program reaches the state s, the runtime value of e is always a single lo\u00adcation v. This \ncan be written formally using the following relation \\s,e).v. To protect vfor any read or write access, \nwe can de.ne protected by each abstract lock. We further discuss the semantic meaning of these operators \nbelow. Abstract lock schemes will be used by our lock inference algo\u00adrithm to compute locks that protect \natomic sections. To guarantee that our inference terminates, we require Lto be bounded. Alterna\u00adtively, \nwe could use widening operators in our inference algorithm. se a .ne-grain lock l with the following \nsemantics: We decided to make Lbounded to simplify our presentation. se ]] = ( {v |\\s,e).v},rw) [[ l \nRelation with concrete locks We say that an abstract lock scheme is a sound approximation of the concrete \nsemantics if for any Global lock A global lock lg protects all memory locations: [[ lg ]] = ( Loc,rw) \nprogram point pand effect e, the following conditions are satis.ed: Type-based locks In a type-safe language, \nwe could use types to The top element Trepresents a global lock, protect all values of such type: [[ \nlt ]] = ( {v |typeOf ( v)= t' .t' <: t},rw) [[ T]] =( Loc,rw) where typeOf returns the runtime type of \na value, and <: is a If l1 =l2, then the lock l2 must be coarser than l1: subtyping relation. In the \npresence of subtyping, for example with class inheritance in object oriented languages, the super-type \nis a .l1,l2,.l1 =l2 .[[ l1]] [[ l2]] coarser lock than a sub-type, i.e. t<: t' .[[ lt ]] [[ lt' ]] . \n Pointer analysis locks Consider a .ow-insensitive and context- Alock x ep protects the address of xto \nbe used with the effect e insensitive pointer analysis. The analysis abstraction is a set of at the program \npoint p, formally: allocation sites, called points-to set. We can de.ne a lock for each points-to set \npas follows: ep ]] .s,x.s@ p.\\s,&#38; x).v .( {v},e) [[ x [[ lp]] =( {v |allocOf ( v) .p},rw) where \ns@ p denotes that s is a state that reaches the program where allocOf is a function that returns the \nsite where v was point p,and \\s,&#38; x). v says that the address of x is the allocated. The lock lp \nprotects all memory locations allocated in location v in the state s. any of the allocation sites in \np. If a location v is protected by l and v' is a location pointed to Read and write locks A global read \nlock l r and a global write by the .eld iof v,then l+ ep imust protect v', formally lock l w have the \nfollowing semantics: .l .L,s,v,v' = v+ s i. [[ lr]] =( Loc,ro)[ lw ]] = ( Loc,rw) ( {v},ro) [[ l]] . \n( {v'},e) [[ l+ ep i]] Lock pairs We can also combine the power of two lock sets by where + s performs \nan offset operation in the concrete seman\u00adcomputing their Cartesian product. Let l1 and l2 be two lock \nnames. We de.ne the concrete pair lock ( l1,l2) as: tics of the state s. The operation * ep satis.es \na similar condition: [[( l1,l2)]] = [ l1]] n[[ l2]] This means, the pair lock protects the intersection \nof the locations .l .L,s,v,v' = *sv. protected by the individual locks. For example, we can combine \n( {v},ro) [[ l]] . ( {v'},e) [[ *expression locks and global read and write locks to obtain a new ep \nl]] set of .ne-grain locks that protect locations either for read-only or where *s performs a value \ndereference in the concrete state s. read-write accesses. The combination of \u00b7 ep , + ep and * ep allows \nus to inductively construct a lock that protects the value of any expression e at a  3.3 Abstract Lock \nSchemes ep program point pto perform an access e.Let be be such lock, then:The lock semantics allows \nus to understand the relation between locks and locations. In this section we explore reasoning about \n ee c x ep = x ep e+ i + ep i = * ep be ro p locks in abstract manner, but ensuring that our reasoning \nis a safe ro d *e = be ppp approximation of the concrete locks semantics. We de.ne an abstract lock \nscheme S as a tuple Notice that all subexpressions of eonly need to be protected for read effects (ro). \nS=( L,=,T , \u00b7 ep ,+ ep ,* ep ) ep where elements in L. LNames are lock names, ( L,=,T) is a join-semilattice \nwith top element T.Since ( L,=) is a join semi\u00adlattice, the relation =is re.exive, transitive and anti-symmetric. \nFor any pair of elements of L, the join U, which returns their least upper-bound, is de.ned. For convenience \nwe write a<b to say that a=b.a= b. The operators domains are the following: * epep : V .L : L\u00d7F .L : \nL.L + \u00b7 3.3.1 Examples The following are examples of abstract lock schemes, similar to the examples \nof concrete locks that we gave in the previous section. Expression locks with k-limiting Expression locks \nas presented so far can t be used in an abstract lock scheme because the set of locks is not bounded. \nWe introduce k-limiting to bound the set of expression locks, and de.ne a scheme Sk as follows: L = {lp \n|length(e)=k.p.PP}.{T} e = = {(lp,lp),(lep ,T)|lp .L} ee e j lp p e &#38;x if k =1 x = T if k =0 j ' \ne lep +i length(e+i)=k.p=p ' lep +p i = T otherwise j e lp ' l*pe length(*e)=k.p=p ' *= pe T otherwise \nThe scheme consists of locks le for any expression of length equal or smaller than k. All longer expressions \nare represented by the Telement. Note that the effect eis not used in the de.nitions, hence all locks \nprotect locations for read-write effects (rw). Uni.cation-based pointer analysis Consider a .ow-insensitive \nuni.cation-based pointer analysis like Steensgard s [22]. Let Abe the sets of points-to sets returned \nby the analysis, such that each set s . A is disjoint from the others; each program expression is associated \nwith a points-to set (which we write as e : s); and points-to relations are denoted by edges s .s '. \nA sound abstract lock scheme S= based on the result of this analysis would be: L = {ls |s.A}.{T} = = \n{(ls,ls),(ls,T)|ls .L} x ep = s,where &#38;x:s ls +pe i = s *ep ls = s ',where s.s ' Read and write locks \nWe can de.ne a lock scheme Se that protects locations by the kind of accesses performed in them: L = \nE. x ep = e = = l+ep i = e T = rw *ep l = e Field based locks We can de.ne a lock scheme Si that protects \nlocations by the offset in which they are accessed, as follows: L = {s|s.F} x e = T p = = . l+e i = {i} \nT = F *ep p l = T Cartesian product The Cartesian product S1 \u00d7S2 of two abstract schemes S1 and S2 can \nbe constructed by taking the Cartesian product of the domains and functions: L = L1 \u00d7L2 = = {((a,b),(c,d))|a=b.c \n=d} e ee xp =(xp1,xp2) e ee (a,b)+p i =(a+p1 i,b+p2 i) e ee *p (a,b) =(*p1a,*p2b) If two abstract lock \nschemes are sound approximations of the con\u00adcrete semantics, so is their Cartesian product. In the earlier \nexample from Figure 1(c) we used a locking scheme based on the Cartesian product of 3-limited expression \nlocks and points-to set locks (S3 \u00d7S=). In the .gure, we used a syntactic simpli.cation to represent \neach lock. We used to.head and from.head to represent the .ne-grain locks (lto.head ,lL)and (lfrom.head \n,lL),where L is the points-to set for the list contain\u00aders. We also used the symbol E to represent the \ncoarse-grain lock (T,lE),where E is the points-to set for all list elements. Notice that (T,lE)is not \na global lock, it can be held concurrently with any lock ( ,ls)that protects any other points-to set \ns=E. 4. Lock Inference Analysis This section presents the analysis that deduces a set of locks to protect \nan atomic section. We .rst present our formal framework that will allow us to formally show that the \nanalysis is sound. Then we discuss how we implemented an instance of this framework. 4.1 Analysis Framework \nThe analysis receives two external inputs: an abstract lock scheme (S) and the results of an alias analysis. \nThe alias analysis is useful to understand the effects of store assignments, as we saw in the example \nfrom Figure 2 when updating x->data. The result of the alias analysis is given by a relation mayAlias(e1,e2,p)that \nanswers whether two expressions e1 and e2 may point to the same location at a program point p. For each \nprogram point p inside an atomic section, we will compute a set of lock names Np .L. The set of locks \nNp protects all the locations used from the point pand forward until the thread reaches the end of the \natomic section. Additionally, no lock in Np is redundant in the following ways: (a) For any lock l .Np,there \nis some location protected by the lock l that is referenced inside the corresponding atomic section (during \nsome run of the program) under the assumption that all program paths are feasible (since our analysis \nis path-insensitive). (b) For any pair of locks l1,l2 . Np neither l1 <l2 nor l2 <l1. We formalize the \nanalysis using a data.ow formulation. The algorithm is a backward data.ow analysis that starting at the \nend of an atomic section computes the locks for each point until it reaches the entry of the atomic section. \nInitialization The analysis starts at the end of the atomic section with an empty set of locks: N0 =\u00d8. \nTransfer functions Figure 4 presents the intra-procedural analy\u00adsis rules. Given a set N of lock names \nat the program point after a statement st, the analysis computes a new set N ' for the program point \nbefore st. The new set N ' must protect all locations protected by N and all locations accessed directly \nby the statement. Note the rules are formulated using closure operators which are not meant to be used \nin an implementation. Section 4.3 discusses how this analysis is implemented in practice. The .gure omits \nprogram point and effect annotations to sim\u00adplify the presentation. The reader should note that every \noperation \u00b7, * and + on the .rst component of a pair corresponds to the program point aafter the assignment, \ni.e., \u00b7 a, * a and +a;and ev\u00adery operation on the second component corresponds to the program point bbefore \nthe assignment. However, both use the same effects e. For example, the relation Sx=y must be read as: \ne1 e2 e1 e2 Sx=y ={(*a xa ,*y )} bb For any assignment e1 = e2 we describe the transfer function as a \ncombination of two basic relations Se1=e2 and Qe1 .The relation Se1=e2 includes a minimal set of locks \nthat are changed by the statement. For example, in Sx=y any location protected by *xafter the statement \nis protected by *y before the statement. We express how other locks are transformed using the closure \noperator closure(S). For instance, the transfer function maps *(*x+i)after the statement to *(*y+i)before \nthe statement. The closure of Idallows us to express that any expression not affected by the assignment \nwill remain unchanged by the transfer function. The closure of Qe1 are those expressions in closure(Id) \nthat are affected by the statement, and thus must be excluded from the transfer function. For example, \nthe transfer function of Tx=y maps *(*z)to *(*z),but *(*x)is not mapped to *(*x)because (*(*x),*(*x)) \n. closure(Qx). Finally, all transfer functions in\u00adclude a new set of locks G that protect the locations \naccessed di\u00adrectly by the assignment. For any assignment e1 = e2, the transfer function is: We de.ne \nthe transfer of x = f(a0, ..., an) as follows: N ' = transfer (e1 = e2,N) transfer(x = f(a0, ..., an),N)= \n.l .N}. Grw . Gro * = {l ' |(l, l ' ) .Te1=e2 e1 e2 trans (p0 = a0; ...; pn = an; stf-body ; x = retf \n,N) T is the underlying transfer function relation: where stf-body is the body of f,and trans * is de.ned \nas the least solution to the following recursive formulation: Te1=e2 = closure(Se1=e2 .Id) -closure(Qe1 \n) closure(S)= S trans 8 >< >: * (st, N)= trans * (st1,N) Utrans * (st2,N) st =if(b) st1 else st2 trans \n* (st1, trans * (st2,N)) st =st1; st2 N Utrans * (st; while(b) st, N) st =while(b) st, N . ({(l + i, \nl ' + i) |(l, l ' ) .closure(S)}({(*l, *l ' ) |(l, l ' ) .closure(S)} . Id = {(z, z) |z .V } transfer \n(st, N) otherwise S is a set of core changes induced by the statement: Sx=y = {(*x, *y)} Sx=y+i = {(*x, \n*y + i)}Sx=&#38;y = {(*x, y)} Sx=*y = {(*x, *(*y))}Sx=new = Sx=null = {} S*x=y = {(*(l), *y) |l ~*x} \nQ are trivial mappings violated by the statement: Qx = {(*x, *x)} Q*x = {(*(*x), *(*x))} G are new locks \nto protect the accesses in the current statement: Ge = {*e x ro ,x ro} Gro = {x ro} Gro = {} *x x+i &#38;x \nGro Gro Gex = {x e} new = {} null = {} Figure 4. Transfer functions. Annotations on operators are omitted \nto simplify the presentation. The transfer function of *x = y uses a may alias relation ~.We construct \n~from the results of the alias analysis that was given as input to this algorithm. If two expressions \ne1 and e2 may alias at a program point p, written mayAlias(e1,e2,p), the relation ~holds p ~ bp on their \nabstract locks, i.e. eb1 e2 . To illustrate how the framework works, consider our earlier ex\u00adample from \nFigure 2. The program s atomic section can be rewrit\u00adten in our simpli.ed language as follows: atomic \n{ t1 =x +data; *t1 = w; t2 =y +data; z =*t2; *z = null; } Initially, our analysis starts with an empty \nset of locks at the end of the section. The transfer function of *z = null uses G to introduce two new \nlocks *z and z. Lets focus on what happens to *z only. The statement z = *t2 de.nes z in terms of t2, \nhence our transfer function uses the relation Sz=*t2 to transform *z into **t2. Notice that the pair \n(*z, *z) is mentioned in the set Q, and thus *z is no longer included in the set of locks. Similarly, \nthe transfer function for t2 =y +data transforms **t2 into *(*y + data), which we wrote as y->data in \nFigure 2. The assignment *t1 = w requires us to look at the may alias information. Assume that the alias \nanalysis indicates that mayAlias(t1,y + data, \u00b7) holds at that point, then the relation *t1 ~*y + data \nalso holds. This enables the transformer S*t1=w to introduce *w in the set of locks. Additionally, *(*y \n+ data) remains in the set of locks because it is in closure(Id) and it is not listed in closure(Q). \nFinally, the .rst assignment t1= x+ data doesn t remove any of our locks and we conclude that to protect \nthe access in the last line, we need both *(*y + data) and *w. Merge operation At merge points we compute \nthe join of two set of locks N1 and N2 as follows: N1 UN2 = {l .N1 .N2 |.l ' .N1 .N2 .l<l ' } all locks \nare combined together, but we exclude locks protecting locations that are already protected by other \nlocks in the set. Figure 5. Inter-procedural equations Function calls Figure 5 formulates how to reason \nabout function calls. Essentially we model function calls as a composition of three groups of statements: \nthe .rst group assigns actual arguments to the formal arguments used in the callee, the second group \nis the body of the callee, and the .nal group consist of assigning the return value of the callee to \nthe left hand side of the call. The formulation uses trans * to de.ne the transfer function for compound \nstatements. These are essentially summaries of the transfer functions of several statements. As mentioned \nearlier, these rules are meant as a formal declaration of our system, not as an implementation. Transformation \nFrom the analysis solution we retrieve the set of locks N inferred for the entry point of each atomic \nsection. We replace each atomic section with two statements: a statement acquireAll(N) at the entry point \nof the atomic section, and a state\u00adment releaseAll at the end of the atomic section.  4.2 Soundness \nTo ensure that our algorithm is correct, we need to connect our ab\u00adstract domain with the program semantics. \nOur operational seman\u00adtics consist of states s. States contain a shared heap and a set of locks Li held \nby each thread i. Additionally, our semantics keeps track of the state of each thread, whether it is \ninside or outside an atomic section. Using our concrete locks semantics [[\u00b7]], our opera\u00adtional semantics \ncheck that any shared location accessed inside an atomic section is protected by a lock in Li. In particular, \na step in the semantics \\s, st).s ' will get stuck if the check doesn t hold. THEOREM 1. Let s be a reachable \nstate, where thread i is about to execute a statement st within an atomic section. Let N be the result \nof our analysis for such atomic section. If at the entry of the atomic section, the thread i acquired \nall locks in N, then there exists some s ' such that \\s, st).s ', i.e. the program doesn t get stuck. \nProof. Our proof is based on the assumption that both the ab\u00adstract lock scheme and the mayAlias query \nare sound. The theorem proof is based on induction on the program structure, and it uses the lemmas below \nto show each step of the proof. LEMMA 1. The locks before any assignment protect the locations accessed \ndirectly by the statement. Formally, .st =(*e1 = e2),s@( st),v, N ' = transfer(st, N) . (\\s, e1).v ..l \n.N ' . ({v}, rw) [[l]]) . (.(*e) .subs(ei) . \\s, e).v ..l .N ' . ({v}, ro) [[l]]) where s@( st) is any \nstate that reaches the program point before st, subs(ei) returns all dereference subexpressions of e1 \nand e2, e1 ranges over {&#38;x, *&#38;x}. LEMMA 2. Assume N is a set of locks protecting all locations \naccessed after a statement st. Except for unreachable locations, the locks inferred by transfer ( st, \nN) protect all the locations that were protected by N after the statement: .st, l .N, s, v .Loc . s@( \nst) .reach( s, v) .( {v},e) [[ l]] . ..transfer( st, N) . ( {v},e) [[ l ' ]] l ' where reach( s, v) holds \nif the location v is reachable from some program variable in state s. Due to lack of space our semantic \nrules and proofs are omitted here; they can be found in a companion technical report [6].  4.3 Implementation \nWe have developed an instance of this analysis framework for a .xed locking scheme and alias analysis. \nThe formal presentation of our inference algorithm uses constructs, such as the closure opera\u00adtor and \nthe trans * function, that can t be implemented in practice. This section describes how we implemented \nour framework and discusses optimizations that we performed for our chosen instance of the framework. \nWe also discuss possible extensions to deal with pre-compiled libraries. Implementing the framework Our \nimplementation keeps a set of locks for each program point, and uses a standard worklist algorithm to \ncompute solutions to the data.ow equations. The algorithm operates at the level of individual locks, \nnot at the level of set of locks that is used in the equations. The worklist contains pairs of locks \nand program points ( l, p) . The worklist is initialized using the information in the sets G presented \nin Figure 4. That is, for each assignment e1 = e2 within .Gro the atomic section, we add ( l, p) if l \n.Grw e1 e2 and p is the program point before e1 = e2. We only omit a lock l = x if we can tell that x \nis a thread local variable whose address is never stored. The algorithm takes a pair ( l, p) from the \nworklist, and for each predecessor statement st of the point p, we apply its transfer function and add \nthe resulting locks l1' , ..., l ' to the abstraction n at the point p ' before the statement. If the \nabstraction changed at p ',we add ( li' ,p ' ) to the worklist, and repeat the process until the worklist \nis empty. We do not explicitly compute the closure operations used in the transfer functions and procedure \ncalls. For transfer functions, our implementation is based on recursive substitutions of expressions. \nFor function calls, we use a standard technique based on function summaries [19]. A function summary \nfs essentially caches the analysis results for the body of a function f.Given a lock l at the end of \nthe function f, fs( l) is the set of locks that protect the same locations as l at the beginning of the \nfunction f. More precisely, when analyzing a lock l after a function call x = f( a1, .., an) , we perform \nthe following steps: We map the lock to the callee s context by analyzing the as\u00adsignment x = retf . \nThe assignment simulates returning from the call to f and setting the return value to x.Let l1 bealock \nresulting of analyzing such assignment.  If no summary exists for l1 in fs,we add ( l1, exitf ) to the \nworklist, where exitf is the program point by the end of f.  If a summary for l1 is found, then let \nl2 be a lock in the result of the summary (l2 .fs( l1) ).  We unmap the lock l2 back to the caller by \nmodeling how actual arguments are passed as formals to the callee, i.e. pi = ai.The resulting locks are \nmerged at the point p before the call, and added to the worklist if the abstraction changed.  Additionally, \nwhen the algorithm reaches the entry point of the function ( l, entryf ) the analysis updates the function \nsummary by adding l to fs( src( l)) ,where src( l) records the origin of a lock by the end of the function. \nWe initialize src( l)= l at the exit point of a function and we preserve it in the transfer functions, \ni.e, when l ' .transfer ( st, l) then src( l)= src( l ' ) . After updating the summary, the analysis \nalso unmaps the lock l to all callers of the current function. Instantiating the framework We chose an \nabstract lock scheme based on k-limited expressions, points-to sets and read/write effects (S k \u00d7S =\u00d7S \ne). We use Steensgard s analysis [22] to compute both the points-to sets in S = and the mayAlias relation. \nOur compiler implementation is specialized to take advantage of this scheme. In particular, from all \npossible pairs of expressions and points-to set locks, only few combinations need to be manipulated by \nthe analysis. If an expression e belongs to a points-to set P , then the analysis will never consider \na pair of e with P ' = P . This is because e and P ' protect disjoint sets of locations, and thus their \ncombination protects no memory location. In fact, the relevant pairs of expressions and points-to sets \nimplicitly de.ne a tree hierarchy instead of a general lattice. This tree has a root node ( T, T) that \nprotects all locations. The root s immediate children are points-to set locks ( T,P ) that protect a \npartition of the memory. Finally, each points-to set has k-limited expression locks ( e, P ) as children. \nThese children protect a location within the memory partition protected by ( T,P ) . In practice, for \na lock ( e, P ) the transfer functions will al\u00adways conclude that P remains unchanged, because P is a \n.ow\u00adinsensitive lock, and thus it protects the same set of locations be\u00adfore and after each statement. \nOnce an expression reaches the k\u00adlimit and becomes Tthe analysis will never update this component either. \nTherefore, we exploit these observations in our implementa\u00adtion: our tool only tracks k-limited expressions \nuntil they become T, at which point the tracing is stopped, and the corresponding points-to set lock \nis added to the analysis solution. Supporting pre-compiled libraries Our compiler implementation assumes \nthat the whole source code is available for analysis. How\u00adever, pre-compiled libraries could be supported \nusing speci.ca\u00adtions that summarize function effects. For instance, for our locking scheme based on S \nk \u00d7S = \u00d7S e, we can use a list of coarse-grain locks as function speci.cations. Since our coarse-grain \nlocks are .ow-insensitive locks, they can essentially be used to protect all ac\u00adcesses done inside a \npre-compiled function. When reasoning about calls to pre-compiled functions, the analysis needs to inspect \nthe .ne-grain locks inferred at the point after the call, evaluate if the expressions and subexpressions \nused in .ne-grain locks could be changed by the call, and if so, replace the affected .ne-grain locks \nby coarser locks. By specifying coarse-grain locks and effects in function speci.cations, our compiler \nwould be able to do this. 5. Runtime System The lock inference algorithm introduces locks of multiple \ngranular\u00adities. This section presents a runtime library necessary to support this kind of locks. 5.1 \nMulti-Granularity Locking Library Unlike traditional locks, with multi-grain locks there are pairs of \nlocks that cannot be held concurrently. Hence, acquiring multi\u00adgrain locks in any linear order does not \nguarantee that locking is deadlock free. To support multi-grain locks, we implemented a library based \non ideas introduced by Gray et al. [16, 15] from the database com\u00admunity. To illustrate the key ideas \nof a multi-grain locking protocol, consider the following example. Suppose we have a simple lock structure \nof three locks la,lb, and T,where la =Tand lb =T. X S X S. X Is SIx S X Is . . . SIx . S . . Ix . (a) \nIx . (b) . Figure 6. Compatibility of access modes: (a) traditional modes, (b) with intention modes. \nWe would like to allow la and lb to be held concurrently. But if a thread acquires T, no other thread \ncan get la or lb. Suppose a .rst thread wants to acquire la. The protocol must ensure that before re\u00adquesting \nla, T is not taken by any other thread. One way to do this is to acquire T and then la, but this will \nnot allow another thread to request lb. Instead, a multi-grain protocol marks T with an in\u00adtention.This \nintention says that somewhere lower in the structure, the current thread holds a lock. When some other \nthread wishes to acquire T, it must wait until the intention mark is removed. How\u00adever, intention marks \nare compatible, hence a second thread can also mark T with his intention, and acquire lb concurrently \nwith la. More generally, a protocol for multi-grain locks operates based on three basic ideas: (a) lock \nrelationships are structured, (b) locks are requested in a top-down fashion, and (c) dependencies between \nlocks are made explicit during the protocol using intention modes. Traditionally, locks can be acquired \nin two modes: read-only or shared (S), and read-write or exclusive (X). Adding intentions introduces \nthree new modes: intention to read (Is), intention to write (Ix), and read-only with the intention to \nwrite some child nodes (SIx). Figure 6 shows the compatibility between these ac\u00adcess modes. A pair of \naccess modes marked with . can be held concurrently. If the lock structure is a tree the following deadlock \nfree proto\u00adcol guarantees that no con.icting locks are held concurrently: Before acquiring l for reads \n(S) or intention to read (Is), each ancestor l ' (l = l ') must be held by this thread in Ix or Is. \n Before acquiring l for X, SIx or Ix each ancestor l ' (l = l ') must be held by this thread in SIx or \nIx mode.  Siblings are acquired in the same order by all threads.  Locks are released bottom up or \nat the end of the transaction.  This protocol can be extended to deal with general lattice struc\u00adtures \n(not only trees), but we omit this for simplicity. Since our im\u00adplementation uses a locking scheme that \nhas a tree-like structure, the protocol presented here is suf.cient. 5.2 Lock Runtime API We implemented \nthe multi-grain protocol for our locking scheme (Sk \u00d7 S= \u00d7 Se) in a runtime library. The library s API \nconsists of three functions: to-acquire, acquire-all, release-all. The function to-acquire takes a lock \ndescriptor (see below) and adds it to a list of pending locks. The function acquire-all proceeds to request \nall pending locks using the protocol presented above. The function release-all unlocks every lock in \nthe list and clears the list. In order to acquire locks using the protocol, our library requires partial \nknowledge of the lock structure: for every lock l the protocol accesses all locks in the path from the \nroot T to the lock l.We do not store the entire lock structure in the library, we provide the library \nwith the relevant portion of the locking structure using lock descriptors instead. For our locking scheme, \nthe lock descriptor is just a triple consisting of a memory address (describing the Sk component), a \nnumber (describing the S= component), and a boolean (indicating the effect ro or rw). Internally, the \nlibrary maintains a map associating lock descriptors with actual locks. The transformation we presented \nin Section 4 inserts state\u00adments acquireAll(N) fora setoflocks N = {l1, ..., ln},and releaseAll to release \nall locks. Our implementation translates releaseAll into release-all,and acquireAll(N) to the sequence \nto-acquire(p1); ...; to-acquire(pn); acquire-all(); where pi is the lock descriptor of a lock li.  5.3 \nSupporting nested atomic sections Our inference algorithm and transformation do not need to reason about \nnesting of atomic sections. When atomic sections are nested, the outer section protects the locations \nincluded in the inner section, hence it is unnecessary to acquire locks when entering the inner section. \nHowever, sections could be nested in one thread, but not nested in another thread, more precisely, an \ninner section in one thread can be the outer-most section of some other thread. Such other thread must \nacquire locks when entering that section. Nested sections can be supported via an additional form of \ncon\u00adtext sensitivity in the program: whether the current thread is inside an atomic section. This can \nbe implemented with a small extension to our runtime library by adding an integer variable nlevel for \neach thread. We can track the nesting level of each thread by incre\u00admenting (decrementing) nlevel whenever \nacquireAll (releaseAll) is called. However, we would only append, acquire, and release locks when the \nvalue of nlevel is 0. 6. Results This section describes our experimental setup and presents both compile-time \nand run-time statistics. 6.1 Experiment Setup We used the Phoenix infrastructure [1] as a front end to \nimplement our analysis. A .rst phase reads C/C++ programs and outputs each function in a simpli.ed intermediate \nrepresentation (IR). A second phase reads the IR and performs the whole program analysis as de\u00adscribed \nin Section 4.3. Finally, a third phase performs the program transformations based on the analysis results. \nAll phases are imple\u00admented in C#. We manually replicate the transformation phase in order to generate \nthe transformed programs using a different com\u00adpiler (see further below). We used several values for \nk, between 0 and 9, to build the k\u00adlimited expressions. Programs were compiled on a 1.66Ghz Dual Core, \n2 GB RAM machine, running Windows XP SP2. Runtime experiments were performed on a 1.86Ghz Intel Xeon \ndual-quad core, 16 GB RAM, server system running Windows Server 2003 SP2 x64 edition. Benchmarks We analyzed \nseveral of the SPECint2000 bench\u00admarks [23], the STAMP benchmarks (v0.9.6) [4] and a set of micro\u00adbenchmarks \nusing traditional data-structures. These sets of pro\u00adgrams correspond to the top, middle and bottom portion \nof Ta\u00adble 1, respectively. The STAMP and micro-benchmarks are con\u00adcurrent applications that contain atomic \nsections protecting shared memory accesses. The .rst three micro-benchmarks are implemen\u00adtations distributed \nwith the STAMP benchmarks. The hashtable-2 is a different implementation of hashtable. The difference \nbetween hashtable and hashtable-2 is how put operations are implemented. Given a list in a bucket, hashtable-2 \ninserts a new entry at the begin\u00adning of the list, hashtable traverses the list to perform the insertion. \nAdditionally, hashtable-2 never changes the size of the table or re\u00adhashes values. On the other hand \na put in hashtable might rehash and access all elements in the table during this process. These four \nmicro-benchmarks are run with the same harness that performs sev\u00aderal operations (put or insert, get \nor lookup,and remove). Each op\u00ad Program Size (Kloc) Atomic sections Analysis Time (s) k =0 k =9 gzip \nparser vpr crafty twolf gap vortex 10.3 14.2 20.4 21.2 23.1 71.4 71.5 1 1 1 1 1 1 1 1.6 3.4 4.2 11.0 \n5.0 32.6 5.3 111.3 6.2 15.4 3.0 76.6 10.6 193.7 vacation genome kmeans bayes labyrinth 10.1 9.8 4.2 11.6 \n8.0 3 5 3 7 3 2.4 3.3 1.7 2.0 1.4 1.4 1.8 2.4 1.2 1.3 hashtable rbtree list hashtable-2 TH 3.4 1.9 1.5 \n0.4 5.1 4 4 4 4 7 0.7 0.8 0.8 0.8 0.7 0.8 0.7 0.7 1.0 1.0 Table 1. Program size and analysis time in \nseconds. eration is enclosed in an atomic section. Each atomic section con\u00adtains a loop with additional \nnop instructions to make the program spend more time inside the atomic sections. The program TH ac\u00adcesses \ntwo data-structures instead of one. It essentially combines rbtree and hashtable. Like all other micro-benchmarks, \nthis pro\u00adgram is run with a harness that performs several put, get and re\u00admove operations. However, each \noperation randomly selects to use one or the other data-structure, hence half of the accesses are on \neach structure. The SPECint2000 programs are not concurrent, but they were used to measure the scalability \nof the analysis. We wrapped the main function of these programs inside an atomic section, and analyzed \nthem in the same fashion as the concurrent programs. We used the TL2 (v0.9.3) STM [7], distributed with \nthe STAMP benchmarks, to compare the runtime performance of our approach against an optimistic alternative. \nThe TL2 STM can be compiled under Windows using Cygwin and gcc-3.4.4. Manual transformations To make \ncomparisons fair, we use the same compiler (gcc) to build both the programs with TL2 and the transformed \nprograms with our multi-grain locking library. Be\u00adcause the Phoenix infrastructure doesn t support source-to-source \ntransformations, we manually performed our transformations at the source level in order to compile the \nprograms with gcc. Notice, our manual intervention is minimal and mimics the same changes done by our \ncompiler in Phoenix. With the appropriate infrastructure, these changes could be done completely automatically. \n 6.2 Compiler Statistics Table 1 shows the size of each program and the analysis time. The analysis \ntime corresponds to the second phase of our compilation process. This includes the time for the uni.cation-based \npoints-to analysis and the backward data.ow analysis, but doesn t include time spent parsing or generating \ncode. As mentioned earlier in Section 4.3, the data.ow analysis is only performed for expression locks \nuntil they become T. Thus, the analysis with k =0doesn t perform any data.ow computation, so this column \ncan be used as a rough estimate of the time spent in the pointer analysis. The time spent by the data.ow \nanalysis depends on the size of the atomic sections, and the number of shared memory accesses within \nthe atomic sections. Only in the SPEC benchmarks the size of the atomic sections, and therefore the analysis \ntime, is correlated with the program size. For this reason, the SPEC benchmarks use total number of locks \n700 600  Fine grain ro 500 Fine grain rw Coarse grain ro 400 Coarse grain rw 300 200 100 0 k=0 k=1 \nk=2 k=3 k=4 k=5 k=6 Figure 7. Combined total number of .ne-grain and coarse-grain locks from all programs. \nIncreasing the analysis precision reduces the number of coarse locks and possibly reduces contention. \nmore analysis time than the other programs. The STAMP bench\u00admarks and the micro-benchmarks contain small \natomic sections; thus the analysis cost is fairly low. The numbers observed are quite promising; they \nshow that our technique can scale to analyze large atomic sections of up to 80 KLOC. On average, the \nanalysis is an order of magnitude faster than parsing the programs using Phoenix. Lock Distribution For \neach value of k we counted the number of locks chosen by our analysis to protect each atomic section. \nWe divide the locks into four categories: (a) .ne-grain read-only locks (read-only expressions), (b) \n.ne-grain read-write locks, (c) coarse\u00adgrain read-only locks (read-only points-to sets), (d) and coarse\u00adgrain \nread-write locks. Figure 7 shows the overall results. Each column shows the combined total number of \nlocks in each category from all atomic sections of every program. As expected, all locks chosen by the \nanalysis with k =0are coarse-grain locks. As we increase the value of k we observe that coarse-grain \nlocks can be replaced by one or more .ne-grain locks, and sometimes coarse-grain locks can be removed \naltogether. The former is illustrated in the column of k =1, where individual coarse-grain locks are \nreplaced by several .ne-grain locks (thus the increase in the number of locks). The latter is illustrated \nwhen k =3, where the total number of locks is reduced. We expect this decrease is due to objects allocated \nwithin atomic sections: these objects are not reachable by the entry of their atomic section, and thus, \nthey are not shared unless they become explicitly stored in another location. Locks protecting the other \nlocation implicitly protect the allocated cells. The data.ow analysis deduces this when tracing .ne-grain \nlocks up to their allocation site. Beyond k =6there is no apparent bene.t of increasing the value of \nk. This is because our k-limited locks are used to pro\u00adtect locations in non-recursive structures, for \nexample in global variables, structure .elds, or array entries. Non-recursive structures have a bounded \ndepth, and typically programmers use a depth of 2 or 3 heap dereferences. Both offset operations and \nheap derefer\u00adences contribute to the length of an expression, thus many expres\u00adsions with 3 heap dereferences \nmay have length k =6.  6.3 Runtime Statistics We evaluate the runtime performance only on the concurrent \nap\u00adplications (STAMP and micro-benchmarks). We ran the STAMP benchmarks using the low contention parameters \nsuggested in the documentation distributed with the programs. For the micro\u00adbenchmarks we used two parameter \ncon.gurations: low and high. The low setting reduces contention by performing more read-only operations, \nin particular, gets are four times more common. Con\u00adversely, the high setting uses puts four times more \noften. Except for hashtable-2,the high setting introduces more contention than the low setting. In hashtable-2,a \nput operation updates a single shared memory location, hence the high setting does not increase the contention \nas much as in the other applications. Global Execution time (s) Coarse Fine + Coarse STM Program (k =0) \n(k =9) genome 8.6 9.0 14.5 15.2 vacation 0.8 0.8 0.8 263.3 kmeans 49.3 52.7 76.9 111.2 bayes 49.8 49.9 \n49.6 82.9 labyrinth 7.8 7.9 7.8 4.1 hashtable-high 51.7 51.3 51.4 75.8 hashtable-low 44.8 23.1 23.1 11.1 \nrbtree-high 41.1 40.3 40.3 5.3 rbtree-low 40.2 20.9 20.9 5.0 list-high 49.5 48.6 48.6 19.2 list-low 43.4 \n22.3 22.3 8.8 hashtable-2-high 41.2 40.3 20.6 5.1 hashtable-2-low 40.1 21.1 20.6 5.0 TH-high 45.4 24.5 \n24.5 53.0 TH-low 41.3 11.4 11.3 7.3 Table 2. Execution times using 8 threads. Table 2 shows the running \ntime of the evaluated benchmarks using 8 threads. The .rst column shows the running time using a single \nglobal lock to protect each atomic section. The next two columns show the time consumed by the transformed \napplications when using the locks chosen by the analysis with k =0(Only Coarse) and with k =9(Coarse \n+ Fine). The last column shows the running time when using TL2. Figure 8 shows some scalability tests \nfor selected applications. Runtime impact of multi-granularity locks. The bene.ts of our transformation \nconsiderably vary between applications. In particu\u00adlar, our transformation has a negative effect on the \nSTAMP bench\u00admarks. These programs have no opportunity of increasing paral\u00adlelism by distinguishing read \nand write effects or by introducing our multi-grain locks. Compared to global locks, our transforma\u00adtion \nwill increase the execution times due to the overhead in the multi-grain locking protocol. This negative \neffect is illustrated in genome, shown in Figure 8. In this program, the Coarse+Fine con\u00ad.guration protects \n4 atomic sections using a single coarse-grain lock with write effects, which enables the same parallelism \nthan a global-lock. Only one section is protected by .ne-grain locks. We do not see these locks improving \nparallelism either, but instead we see an increase in overhead: the program acquires more locks and the \nmulti-grain locking protocol performs more operations. The opposite effect was observed in the micro-benchmarks. \nIn rbtree, for example, we can see the bene.ts of tracking read and write effects. The analysis determined \nthat get operations per\u00adform only memory reads. This allows our system to run multi\u00adple get operations \nconcurrently by protecting them using read-only locks. Since the low con.guration performs more get operations, \nthe transformation with coarse-grain locks runs almost twice as fast than using global locks. For the \nsame reason, coarse-grain locks are twice as fast in the low setting than in the high setting. The analysis \nwith k =9didn t introduce any .ne-grain locks, hence the results are the same as with k =0. The bene.t \nof .ne-grain locks over coarse-grain locks is re\u00advealed in hashtable-2 (Figure 8). As mentioned earlier, \nthe put op\u00aderation in this program only updates a single shared memory loca\u00adtion (one bucket entry). \nThe analysis with k =9assigns a single .ne-grain lock to protect that location. When put operations are \nfour times more common than other operations (high setting), .ne\u00adgrain locks halve the execution time \nof coarse-grain locks. Our technique enabled parallelism between pairs of puts(using .ne-grain locks) \nand between pairs of gets (using read-only locks), but put and get still have contention with each other \nwhen using locks. We believe this is the reason why the performance of multi\u00adgrain locks did not improve \nin hashtable-2 when moving from 4 to 8 threads. Since four out of .ve operations are puts, it is highly \nlikely (with more than an 80% chance) that one of the 8 threads is performing a put while another thread \nis performing a get or a remove, and hence some threads are likely to become blocked and waste parallelism. \nOur system s performance improves when transactions access disjoint portions in memory that are protected \nby independent locks. Two accesses to disjoint data-structures can always run con\u00adcurrently. This effect \nis illustrated in TH, also shown in Figure 8. Since this program uses two data-structures, coarse-grain \nlocks can always exploit more parallelism than a global lock. When using 8 threads, our inferred locks \nare 1.9 times better than a global lock in the high setting, and 3.6 times better in the low setting. \nComparison with TL2 Except for labyrinth, the TL2 system per\u00adforms worse in the STAMP benchmarks than \nusing either a global lock or our inferred multi-grain locks. This is because a lot of time is spent \nin rolling back and re-executing atomic sections with con\u00ad.icts. This is clearly illustrated in vacation, \nwhich runs only 1,000 successful transactions, while it aborts a total of 1.7 million transac\u00adtions. \nIn genome, the overhead of acquiring .ne-grain locks makes our system only 5% faster TL2, in contrast, \ncoarse-grain locks are 41% faster. In kmeans, our programs also run about 29% faster than TL2, even with \nthe overhead introduced by .ne-grain locks. The TL2 system performs better on the micro-benchmarks when \nusing the low setting. It also performs well on for rbtree, hashtable-2 and list with the high setting. \nOn average, when con\u00adsidering all micro-benchmarks together, TL2 ran 14% faster than the multi-grain \nlocks generated with k =9in the high setting, and 60% faster in the low setting. This is expected, as \nlocks can\u00adnot model as much parallelism as an optimistic system. TL2 scales better than our inferred \nlocks in hashtable-2, even when our com\u00adpiler uses .ne-grain locks. We believe that the additional speed \nin TL2 comes from parallelism between pairs of operations that are disallowed by our locks, such as pairs \nof put and get operations. In hashtable,a put operation might resize the table and re-hash values, in \nwhich case the operation will access the entire table. For this reason TL2 spends lots of time rolling \nback transactions in hashtable-high. We see a similar effect in TH-high, since one of the data-structures \nin TH is hashtable. Interestingly, when reaching 8 threads in TH-high, our multi-grain locks scales well, \nbut TL2 becomes slower than using a global lock. Final comments We have seen that our compiler can scale \nto an\u00adalyze large atomic sections. While the results vary across bench\u00admarks, we have also seen that \nour transformation can effectively exploit more parallelism than a global lock. We believe our re\u00adsults \ncan be improved by proposing new locking schemes to select locks. For example, in kmeans an array-range \nanalysis could detect when atomic sections only access a portion of a matrix. The anal\u00adysis framework \nintroduced in this paper provides a good starting point to explore more sophisticated schemes and to \ndeduce good optimizations that minimize the set of locks used to protect atomic sections (like in [8]). \nOverall, our system is preferable to global locks when applica\u00adtions have low contention (e.g. in rbtree-low) \nor have several sec\u00adtions accessing disjoint data-structures (e.g. in TH). Optimistic ap\u00adproaches are \nlikely to be more ef.cient when contention is low. Our system would be preferable to STMs in three scenarios: \nwhen applications have non-reversible operations within atomic sections, have high contention, or have \nlong atomic sections. In the last two scenarios, an optimistic approach might introduce large overhead \nin detecting con.icts and rolling back transactions (e.g. vacation, rbtree (low -80% gets) hashtable-2 \n(high -80% puts) genome 30 50 25 2040   Execution time (sec) Execution time (sec) Execution time (sec) \nExecution time (sec) Execution time (sec) Execution time (sec) 30 20 15 10 5 10 0 # of threads # of \nthreads # of threads TH (low -80% gets) TH (high -80% puts) kmeans (high) 200 70180 160 140   120 100 \n80 60 60 50 40 30 20 40 20 10 # of threads # of threads # of threads Figure 8. Execution times for rbtree, \nhashtable-2, TH, genome,and kmeans using1, 2, 4 and8threads. hashtable-high). Our system is preferable \nto both global-locks and STM in applications with low contention and non-reversible opera\u00adtions, but \nalso in applications where several atomic sections access disjoint data-structures with very high contention \n(e.g. TH-high). 7. Related Work Multi-granularity locking The problem of multi-granularity locking and \nits related trade-off between concurrency and overhead was .rst considered in the context of database \nsystems [16]. The choice of locking granularity considered in the context of databases was based on the \nhierarchical structure of the data storage, e.g., .elds, records, .les, indices, areas, and the entire \ndatabase. The choice of locking granularity in our case is more challenging be\u00adcause of lack of any natural \nhierarchical scheme over the (possibly unbounded number of) memory locations accessed by a program. This \nrequires creation of more complex locking abstractions. Multi\u00adgrain locking requires sophisticated locking \nprotocols, as opposed to simply locking entities according to some total order. Such pro\u00adtocols have \nbeen discussed in the context of database systems [15]. In our work, we adapt these protocols for deadlock \navoidance. Lock inference for atomic sections There has been some recent work on compiler based lock \ninference from atomic speci.cations. Some of these approaches either require user annotations or operate \nover a .xed (and .nite) granularity of locks. On the contrary, our approach is automatic and supports \nmulti-granularity locks. The granularity of locks considered in Autolocker [18] is one that is speci.ed \nby programmer annotations. Our approach is com\u00adpletely automatic requiring no annotations from the programmer \nother than atomic sections. The granularity considered by Hicks et al. [13] is based on the (.nite number \nof) abstract locations in a points-to graph. The lock associated with each abstraction loca\u00adtion locks \nall memory locations that are represented by that abstract location. Our more general locking scheme \nframework can be in\u00adstantiated using this lock abstraction. However, we also allow more .ne-grained locking \nabstractions like expression locks. The granularity of locks considered by Emmi et al. [8] is based on \npath expressions (a variable followed by a .nite sequence of .elds). The lock associated with each path \nexpression locks all lo\u00adcations that the expression can ever evaluate to in any run and at any program \npoint. Such a scheme is too coarse-grained compared to our seemingly similar, but quite different, expression \nlocks. Our expression locks at a given program point p andina givenprogram run r, lock only the memory \nlocation to which the corresponding expression evaluates to at the program point p in the run r.More\u00adover, \nour expression locks are just an instance of our general multi\u00adgranularity locking scheme. However, the \nissue addressed by Emmi et al. [8] is more about optimizing the set of locks that need to be acquired \n(since the cost of acquiring a lock is non-trivial) by phras\u00ading it as an optimization problem. For example, \nif whenever x is accessed, y is also accessed, then we only need to acquire lock on y. This is an orthogonal \nissue and our work can also leverage such an optimization. The granularity of locks considered by Harpert \net al. [10] is based on components of interfering atomic sections. They reduce contention by detecting \nwhen sections do not interfere. They can use a .ne-grain lock to protect a component. However, all sections \nin a component must use the same lock, thus their support for .ne\u00adgrain locking is restricted. For example, \nin hashtable-2 this would require using the same lock to protect both get and put, hence not allowing \nthe .ne-grain locking of put. Hindman and Grossman [14] present a source to source transla\u00adtion to implement \natomic sections in Java using locks. They delay acquiring locks until the .rst time an access is encountered. \nThis al\u00adlows them to use .ne-grain locking more freely, but unlike our ap\u00adproach, it doesn t prevent \ndeadlocks ahead of time. Instead they log write operations and support rolling back transactions when \ndead\u00adlocks are detected. Our system prevents aborting transactions, and hence supports transactions with \nnon-reversible operations. Other approaches for concurrency speci.cations Besides using atomic sections, \nseveral researchers have looked at other models to specify constraints on concurrent applications. Vaziri \net al. [24] present a data centric synchronization ap\u00adproach. Programmers only label data that must be \naccessed together in order to maintain data consistency, then a static analysis infers critical sections \nto enforce these consistency requirements. Col\u00adorama [5] introduces a hardware alternative to infer these \nsections. Both Vaziri et al. and Colorama use transactions to implement crit\u00adical sections. This paper \naddresses a complementary issue: how to implement ef.ciently these critical sections using locks. Speci.ca\u00adtions \nlike those required by Varizi et al. could help our compiler minimize the set of locks used to protect \nan atomic section, be\u00adcause only a few memory accesses must be protected to maintain consistency. This \nis an interesting direction for future work. Flux [3] presents a different mechanism for writing concurrent \napplications based on high-level data .ow between computation nodes (commonly C/C++ functions). Programmers \ndeclare mutual exclusion between these nodes by specifying lock names and their effects (read or write). \nThe Flux programming model is more man\u00adageable for programmers than traditional lock APIs, in particular, \nthe language provides a type system that can detect and prevent deadlocks. However, the programmer is \nstill responsible for associ\u00adating locks with data, choosing an appropriate granularity level for their \nlocks, and ensuring that all shared accesses are protected. In contrast, all these tasks are done automatically \nby our compiler. 8. Conclusions We have presented a general framework that infers locks to pro\u00adtect atomic \nsections. This framework is attractive for three main reasons. First, it provides an automatic implementation \nof atomic sections based on locking primitives, avoiding the disadvantages of optimistic concurrency. \nSecond, it guarantees that the transformed programs respect the atomic semantics. And third, it is parameter\u00adized. \nIt can be instantiated with different abstract lock schemes to .t user needs. We presented an implementation \nof our framework for a .xed lock scheme and reported our experimental experience. Acknowledgments We \nwould like to thank the anonymous reviewers for their useful comments. References [1] Phoenix compiler \ninfrastructure. http://research.microsoft.com/phoenix/. [2] Colin Blundell, E. Lewis, and Milo Martin. \nSubtleties of transactional memory atomicity semantics. IEEE Computer Architecture Letters, 5(2), 2006. \n[3] Brendan Burns, Kevin Grimaldi, Alexander Kostadinov, Emery D. Berger, and Mark D. Corner. Flux: a \nlanguage for programming high-performance servers. In Proceedings of the annual conference on USENIX \n06 Annual Technical Conference, pages 13 13, 2006. [4] Chi Cao Minh, Martin Trautmann, JaeWoong Chung, \nAusten McDonald, Nathan Bronson, Jared Casper, Christos Kozyrakis, and Kunle Olukotun. An effective hybrid \ntransactional memory system with strong isolation guarantees. In Proceedings of the International Symposium \non Computer Architecture, Jun 2007. [5] Luis Ceze, Pablo Montesinos, Christoph von Praun, and Josep Torrel\u00adlas. \nColorama: Architectural support for data-centric synchronization. In Proceedings of the International \nSymposium on High Performance Computer Architecture, pages 133 144, 2007. [6] Sigmund Cherem, Trishul \nChilimbi, and Sumit Gulwani. Inferring locks for atomic sections. Technical Report MSR-TR-2007-111, MSR, \nAugust 2007. [7] Dave Dice, Ori Shalev, and Nir Shavit. Transactional locking ii. In Proceedings of \nthe 20th International Symposium on Distributed Computing (DISC), Stockholm, Sweeden, September 2006. \n [8] Michael Emmi, Jeffrey S. Fischer, Ranjit Jhala, and Rupak Majumdar. Lock allocation. In Proceedings \nof the ACM Symposium on the Principles of Programming Languages, 2007. [9] Keir Fraser and Tim Harris. \nConcurrent programming without locks. ACM Transactions on Computer Systems, 25(2), 2007. [10] Richard \nL. Halpert, Christopher J. F. Pickett, and Clark Verbrugge. Component-based lock allocation. In Proceedings \nof the International Conference on Parallel Architectures and Compilation Techniques, September 2007. \n[11] Lance Hammond, Vicky Wong, Mike Chen, Brian D. Carlstrom, John D. Davis, Ben Hertzberg, Manohar \nK. Prabhu, Honggo Wijaya, Christos Kozyrakis, and Kunle Olukotun. Transactional memory coherence and \nconsistency. In Proceedings of the International Symposium on Computer Architecture, 2004. [12] Maurice \nHerlihy and J. Eliot B. Moss. Transactional memory: architectural support for lock-free data structures. \nIn Proceedings of the International Symposium on Computer Architecture, San Diego, CA, 1993. [13] Michael \nHicks, Jeffrey S. Foster, and Polyvios Prattikakis. Lock inference for atomic sections. In ACM SIGPLAN \nWorkshop on Languages, Compilers, and Hardware Support for Transactional Computing, June 2006. [14] Benjamin \nHindman and Dan Grossman. Atomicity via source-to\u00adsource translation. In ACM SIGPLAN Workshop on Memory \nSystems Performance and Correctness, October 2006. [15] R. Lorie J. Gray and G.F. Putzolu. Granularity \nof locks in a shared database. In Proceedings of International Conference on Very Large Databases, 1975. \n[16] R. Lorie J. Gray, G.F. Putzolu, and I.L. Traiger. Granularity of locks and degrees of consistency. \nIn Modeling in Data Base Management Systems, G.M. Nijssen ed., North Holland Pub., 1976. [17] V. J. Marathe, \nM. F. Spear, C. Heriot, A. Acharya, D. Eisenstat, W. N. Scherer III, and M. L. Scott. Lowering the overhead \nof software transactional memory. In ACM SIGPLAN Workshop on Languages, Compilers, and Hardware Support \nfor Transactional Computing,Jun 2006. [18] Bill McCloskey, Feng Zhou, David Gay, and Eric Brewer. Autolocker: \nsynchronization inference for atomic sections. In Proceedings of the ACM Symposium on the Principles \nof Programming Languages, pages 346 358, 2006. [19] T. Reps, S. Horowitz, and M. Sagiv. Precise interprocedural \ndata.ow analysis via graph reachability. In Proceedings of the ACM Symposium on the Principles of Programming \nLanguages.ACM, January 1995. [20] B. Saha, A. Adl-Tabatabai, R. L. Hudson, C. Cao Minh, and B. Hertzberg. \nMcrt-stm: a high performance software transactional memory system for a multi-core runtime. In Proceedings \nof the ACM SIGPLAN symposium on Principles and practice of parallel programming, pages 187 197, 2006. \n[21] Nir Shavit and Dan Touitou. Software transactional memory. In Proceedings of the ACM symposium on \nPrinciples of Distributed Computing, 1995. [22] Bjarne Steensgaard. Points-to analysis in almost linear \ntime. In Proceedings of the ACM Symposium on the Principles of Programming Languages, St. Petersburg \nBeach, FL, Jan 1996. [23] Joseph Uniejewski. SPEC Benchmark Suite: Designed for today s advanced systems. \nSPEC Newsletter Vol 1, Issue 1, SPEC, Fall 1989. [24] Mandana Vaziri, Frank Tip, and Julian Dolby. Associating \nsynchro\u00adnization constraints with data in an object-oriented language. In Proceedings of the ACM Symposium \non the Principles of Program\u00adming Languages, January 2006.    \n\t\t\t", "proc_id": "1375581", "abstract": "<p><i>Atomic sections</i> are a recent and popular idiom to support the development of concurrent programs. Updates performed within an atomic section should not be visible to other threads until the atomic section has been executed entirely. Traditionally, atomic sections are supported through the use of optimistic concurrency, either using a transactional memory hardware, or an equivalent software emulation (STM).</p> <p>This paper explores automatically supporting atomic sections using pessimistic concurrency. We present a system that combines compiler and runtime techniques to automatically transform programs written with atomic sections into programs that only use locking primitives. To minimize contention in the transformed programs, our compiler chooses from several lock granularities, using fine-grain locks whenever it is possible.</p> <p>This paper formally presents our framework, shows that our compiler is sound (i.e., it protects all shared locations accessed within atomic sections), and reports experimental results.</p>", "authors": [{"name": "Sigmund Cherem", "author_profile_id": "81100413343", "affiliation": "Cornell University, Ithaca, NY, USA", "person_id": "P1022807", "email_address": "", "orcid_id": ""}, {"name": "Trishul Chilimbi", "author_profile_id": "81100578606", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1022808", "email_address": "", "orcid_id": ""}, {"name": "Sumit Gulwani", "author_profile_id": "81100315615", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1022809", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1375581.1375619", "year": "2008", "article_id": "1375619", "conference": "PLDI", "title": "Inferring locks for atomic sections", "url": "http://dl.acm.org/citation.cfm?id=1375619"}