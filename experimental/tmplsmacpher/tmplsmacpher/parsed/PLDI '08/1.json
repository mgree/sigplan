{"article_publication_date": "06-07-2008", "fulltext": "\n Race Directed Random Testing of Concurrent Programs Koushik Sen EECS Department, UC Berkeley, CA, USA. \n ksen@cs.berkeley.edu Abstract Bugs in multi-threaded programs often arise due to data races. Numerous \nstatic and dynamic program analysis tech\u00adniques have been proposed to detect data races. We propose a \nnovel randomized dynamic analysis technique that utilizes potential data race information obtained from \nan existing analysis tool to separate real races from false races without any need for manual inspection. \nSpeci.cally, we use poten\u00adtial data race information obtained from an existing dynamic analysis technique \nto control a random scheduler of threads so that real race conditions get created with very high prob\u00adability \nand those races get resolved randomly at runtime. Our approach has several advantages over existing dynamic \nanalysis tools. First, we can create a real race condition and resolve the race randomly to see if an \nerror can occur due to the race. Second, we can replay a race revealing execu\u00adtion ef.ciently by simply \nusing the same seed for random number generation we do not need to record the execu\u00adtion. Third, our \napproach has very low overhead compared to other precise dynamic race detection techniques because we \nonly track all synchronization operations and a single pair of memory access statements that are reported \nto be in a poten\u00adtial race by an existing analysis. We have implemented the technique in a prototype \ntool for Java and have experimented on a number of large multi-threaded Java programs. We re\u00adport a number \nof previously known and unknown bugs and real races in these Java programs. Categories and Subject Descriptors \nD.2.4 [Software Engi\u00adneering]: Software/Program Veri.cation; D.2.5 [Software Engineering]: Testing and \nDebugging General Terms Languages, Algorithms, Veri.cation Keywords race detection, dynamic analysis, \nrandom test\u00ading, concurrency Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. PLDI 08, June 7 13, 2008, Tucson, Arizona, USA. Copyright c . 2008 ACM 978-1-59593-860-2/08/06. \n. . $5.00 1. Introduction Multi-threaded programs often exhibit wrong behaviors due to data races. Such \nconcurrent errors such as data races and deadlocks are often dif.cult to .nd because they typically happen \nunder very speci.c interleavings of the executing threads. A traditional method of testing concurrent \nprograms is to repeatedly execute the program with the hope that dif\u00adferent test executions will result \nin different interleavings. There are a few problems with this approach. First, the out\u00adcome of such \ntesting can be highly dependent on the test en\u00advironment. For example, some interleavings may only occur \non heavily-loaded test systems. Second, this kind of testing depends on the underlying operating system \nor the virtual machine for thread scheduling it does not try to explicitly control the thread schedules; \ntherefore, such testing often ends up executing the same interleaving many times. De\u00adspite these limitations, \nsuch testing is an attractive technique for .nding bugs in concurrent systems for several reasons: 1) \ntesting is inexpensive compared to sophisticated techniques such as model checking and veri.cation, 2) \ntesting often scales to very large programs. Numerous program analysis techniques have been devel\u00adoped \nto detect and predict data races in multi-threaded pro\u00adgrams. Despite recent advances, these techniques \noften re\u00adport many data races that are false warnings. For example, a hybrid dynamic race detection tool \n[37] reports 51 data races for tomcat, out of which 39 are false warnings. Sim\u00adilarly, a static race \ndetection tool [33] reports 19 data races in hedc, out of which 13 are false warnings. Moreover, be\u00ading \nimprecise in nature, most of these tools require manual inspection to see if a race is real or not. Nevertheless, \nthese tools are very effective in .nding data races because they can predict data races that could potentially \nhappen during a real execution for such a prediction, they do not need to see an actual execution (in \ncase of static race detection) or they need to see one real concurrent execution (in case of dynamic \nrace detection.) Imprecision in race detection can be eliminated by a precise dynamic race detection \ntechnique, called happens\u00adbefore race detection [44]. However, it has three problems: .rst, it can only \ndetect a race if it really happens in an execu\u00adtion and therefore, cannot predict a potential race. Second, \nthis technique has a very large runtime overhead as it needs to track every shared memory access at runtime. \nThird, since it tracks shared memory accesses at runtime, it can perturb an execution and can prevent \nthe observation of a race that can happen when memories are not tracked. Although, the second problem \ncan be alleviated by using off-line analy\u00adsis [34], there is no easy solution for the other two problems. \nWe propose a new technique for .nding bugs in con\u00adcurrent programs, called race-directed random testing \n(or RACEFUZZER.) RACEFUZZER combines race detection with a randomized thread scheduler in order to .nd \nreal race conditions in a concurrent program with high probability and to discover if the detected real \nraces could cause an excep\u00adtion or an error in the program. The technique works as fol\u00adlows. RACEFUZZER \n.rst uses an existing imprecise race de\u00adtection technique, such as hybrid dynamic race detection, to \ncompute a set of pairs of program statements that could po\u00adtentially race in a concurrent execution. \nFor each pair in the set, also called a racing pair of statements,RACEFUZZER then executes the program \nwith a random schedule. In the random schedule, at each program state, a thread is picked randomly and \nits next statement is executed with the follow\u00ading exception. If the next statement of the randomly picked \nthread is contained in the racing pair of statements, then the execution of the statement is postponed \nuntil another thread is about to execute a statement in the racing pair and the ex\u00adecution of the statement \nresults in a race with the execution of the postponed statement. We say that the execution of two statements \nare in race if they could be executed by different threads temporally next to each other and both access \nthe same memory location and at least one of the accesses is a write. If RACEFUZZER discovers such a \nsituation where the execution of the next statement by a thread could race with the execution of a postponed \nstatement, then RACEFUZZER reports a real race. In this situation, RACEFUZZER also ran\u00addomly picks one \nof the two statements to execute next and continues to postpone the execution of the other statement. \nSuch a random resolution of real races helps RACEFUZZER to .nd if an exception or an error (such as an \nassertion viola\u00adtion) can happen due to the race. In summary, RACEFUZZER actively controls a randomized \nthread scheduler of concur\u00adrent program based on potential data races discovered by an imprecise race \ndetection technique. RACEFUZZER has several useful features. Classifying real races from false alarms. \nRACE-FUZZER actively controls a randomized thread scheduler so that real race conditions get created \nwith very high probability. (In Section 3.2, we explain our claim about high probability through an example \nand empirically val\u00adidate the claim in Section 5.) This enables the user of RACEFUZZER to automatically \nseparate real races from false warnings, which is otherwise done through manual inspection.  Inexpensive \nreplay of a concurrent execution exhibit\u00ading a real race. RACEFUZZER provides a concrete con\u00ad  current \nexecution that exhibits a real race two racing events in the concurrent execution are brought tempo\u00adrally \nnext to each other. Moreover, it allows the user to replay the concrete execution by setting the same \nseed for random number generation. An appealing feature of this replay mechanism is thatitrequires no \nrecording of events making the replay mechanism lightweight. The re\u00adplay feature is a useful tool for \ndebugging real races. Separating some harmful races from benign races. RACEFUZZER randomly re-orders \ntwo racing events. This enables RACEFUZZER to .nd if a race could cause a real exception in the program. \nAs a result harmful races that could lead to errors get detected. No false warnings. RACEFUZZER gives \nno false warn\u00adings about races because it actually creates a race con\u00addition by bringing two racing events \ntemporally next to each other.  Embarrassingly parallel. Since different invocations of RACEFUZZER are \nindependent of each other, perfor\u00admance of RACEFUZZER can be increased linearly with the number of processors \nor cores.  Although in RACEFUZZER, a randomized thread sched\u00aduler is directed by potential race conditions, \nwe can bias the random scheduler by other potential concurrency prob\u00adlems such as potential atomicity \nviolations, atomic-set seri\u00adalizability violations [51], or potential deadlocks. The only thing that \nthe random scheduler needs to know is a set of statements whose simultaneous execution could lead to \na concurrency problem. Such sets of problematic statements could be provided by a static or dynamic analysis \ntech\u00adnique [23, 22, 2]. We have implemented RACEFUZZER in a prototype tool for Java. The tool has been \napplied to a number of large benchmarks having a total of 600K lines of code. The results of these experiments \ndemonstrate two hypotheses. RACEFUZZER can create real race conditions with very high probability. (We \ngive also give intuitive reasons be\u00adhind this claim using an example in Section 3.2.) RACE-FUZZER can \nalso effectively .nd subtle bugs in large pro\u00adgrams.  RACEFUZZER detects all known real races in known \nbenchmarks. This shows that RACEFUZZER misses no real races that were predicted and manually con.rmed \nby other dynamic analysis techniques.  To our best knowledge, RACEFUZZER is the .rst tech\u00adnique of its \nkind that exploits existing race detection tech\u00adniques to make dynamic analysis of concurrent programs \nmore effective and informative for debugging. Despite the various advantages of RACEFUZZER, it has some \nlimita\u00adtions. First, being dynamic in nature, RACEFUZZER can\u00adnot detect all real races in a concurrent \nprogram it detects a real race if the race can be produced with the given test harness for some thread \nschedule. This can be alleviated by combining RACEFUZZER with a symbolic execution tech\u00adnique. Second, \nbeing random in nature, RACEFUZZER may not be able to separate all real races from potential races. However, \nthis did not happen in our experiments with ex\u00adisting benchmarks. Third, RACEFUZZER may not be able to \nseparate all harmful races from the set of real races because we say that a race is harmful only if it \ncauses an exception or an error in the program. A harmful race may not raise an exception, but produce \nwrong results, in which case, RACE-FUZZER cannot say if a race is harmful. 2. Algorithm In this section, \nwe give a detailed description of the RACE-FUZZER algorithm. We describe RACEFUZZER using a sim\u00adple abstract \nmodel of concurrent systems. 2.1 Background De.nitions We consider a concurrent system composed of a \n.nite set of threads. Each thread executes a sequence of statements and communicates with other threads \nthrough shared objects. In a concurrent system, we assume that each thread terminates after the execution \nof a .nite number of statements. At any point in the execution, a concurrent system is in a state.Let \nS be the set of states that can be exhibited by a concurrent system starting from the initial state s0. \nA concurrent sys\u00adtem evolves from one state to another state when a thread executes a statement of the \nprogram. We assume that a state\u00adment in the program can access at most one shared object this can be \nachieved by translating a standard program into 3-address code. Next we introduce some de.nitions that \nwe will use to describe our algorithms. Enabled(s) denotes the set of threads that are enabled in the \nstate s. A thread is disabled if it is waiting to acquire a lock already held by some other thread (or \nwaiting on a join or a wait in Java.)  Alive(s) denotes the set of threads whose executions have not \nterminated in the state s.A state s is in deadlock if the set of enabled threads at s (i.e. Enabled(s))is \nempty and the set of threads that are alive (i.e. Alive(s)) is non-empty.  Execute(s, t) returns the \nstate after executing the next statement of the thread t in the state s.  NextStmt(s, t) denotes the \nnext statement that the thread t would execute in the state s.  The following de.nitions are only required \nto brie.y de\u00adscribe the hybrid race detection algorithm [37]. The execu\u00adtion of a concurrent program \ncan be seen as a sequence of events (ei)where an event denotes the execution of a state\u00adment by a thread. \nAn event e can be of the following three forms. MEM(s, m, a, t, L) denotes that thread t performed an \naccess a .{WRITE, READ }to memory location m while holding the set of locks L and executing the statement \ns.  SND(g, t) denotes the sending of a message with unique id g by thread t.  RCV(g, t) denotes the \nreception of a message with unique id g by thread t.  An important relation that is used by the hybrid \nrace de\u00adtection algorithm is the happens-before relation on events exhibited by a concurrent execution. \nGiven an event se\u00adquence (ei), the happens-before relation .is the smallest relation satisfying the following \nconditions. If ei and ej are events from the same thread and ei comes before ej in the sequence (ei),then \nei .ej.  If ei is the sending of the message g and ej is the recep\u00adtion of the message g,then ei .ej. \n .is transitively closed.  2.2 The RACEFUZZER Algorithm In this section, we describe an algorithm \nthat actively con\u00adtrols a random thread scheduler to create real races and to de\u00adtect errors that could \nhappen due to real races. The algorithm works in two phases. The .rst phase computes a set of pairs of \nstatements that could potentially race during a concurrent execution. The second phase uses each element \nfrom the set to control the random scheduling of the threads in a way so that the real racing events \ncould be brought temporally next to each other in the schedule. The .rst phase of the algorithm uses \nhybrid race detection [37], an imprecise, but effective, technique for detecting pairs of statements \nthat could poten\u00adtially race in a concurrent execution. Although we use hybrid race detection in the \n.rst phase, any other static or dynamic race detection technique could be used instead. Phase 1: Hybrid-Race \nDetection. We next brie.y summarize the hybrid-race detection algo\u00adrithm [37] that we have implemented \nin our tool. At runtime, the algorithm checks the following condition for each pair of events (ei,ej). \nei = MEM(si,mi,ai,ti,Li) .ej = MEM(sj,mj ,aj,tj,Lj ) .ti = mj .(ai = WRITE .aj = WRITE) = tj .mi .Li \nnLj = \u00d8.\u00ac(ei .ej) .\u00ac(ej .ei) The above condition states that two events are in race if in those events \ntwo threads access the same memory loca\u00adtion without holding a common lock, at least one of the ac\u00adcesses \nis a write, and the two accesses are concurrent to each other (i.e. one access does not happens-before \nthe other.) If the condition holds for a pair of events (ei,ej),thenwesay (si,sj ) is a racing pair of \nstatements. The computation of the relation . is done by maintaining a vector clock with ev\u00adery thread. \nThe events that are classi.ed as SND(g, t) and RCV(g, t) events are of the following types. If thread \nt1 starts a thread t2, then events SND(g, t1) and RCV(g, t2) are generated, where g is a unique message \nid. If thread t1 calls t2.join() and t2 terminates, then events SND(g, t2) and RCV(g, t1) are generated, \nwhere g is a unique message id. If a o.notify() on thread t1 signals a o.wait() on thread t2, then events \nSND(g, t1) and RCV(g, t2) are generated, where g is a unique message id. Note that the above algorithm \nre\u00adquires us to track every shared memory access and every lock acquire and release operations. Therefore, \nhybrid race detection can have signi.cant runtime overhead. Several op\u00adtimizations have been proposed \n[37] to reduce the runtime overhead. Phase 2. RACEFUZZER. Our key contribution is the second phase of \nthe algorithm, which we next describe informally. Let (s1,s2) beapairof statements that have been inferred \nto be potentially racing in the .rst phase. Due to the imprecision of the .rst phase, these two statements \nmay not actually race in an actual exe\u00adcution. Therefore, in the second phase we try to control our scheduler \nrandomly based on this pair. Speci.cally, we exe\u00adcute the various threads following a random schedule \n(i.e. at each state we pick an enabled thread randomly), but when\u00adever a thread is about to execute a \nstatement in {s1,s2},we postpone the execution of the thread. The postponed thread keeps on waiting until \nanother thread is about to execute a statement in {s1,s2} and the execution of the statement ac\u00adtually \nraces with the .rst thread, i.e. both threads access the same memory location if they execute their next \nstatements and one of the accesses is a write. In that scenario, we ran\u00addomly resolve the race by allowing \none thread between the two threads to execute the next statement and keep postpon\u00ading the other thread. \nNote that in the above scenario, we have detected a real race and we have also resolved the race ran\u00addomly \nso that we can observe if something bad can happen due to the race. While postponing threads, it may \nhappen that several threads are about to execute a statement in {s1,s2}, but they are not racing because \nthey would access different dynamic shared memory locations when they execute their next statements. \nIn such a case, we keep postponing all the threads that are about to execute a statement in {s1,s2}.At \nany point, if we manage to postpone all the threads, then we pick a random thread from the set to break \nthe deadlock. The formal description of the RACEFUZZER algorithm is given in Algorithm 1 and Algorithm \n2. The algorithm takes as an input s0, the initial state of the program, and RaceSet, a set of two statements \nthat could potentially race in a concurrent execution. The algorithm maintains a set postponed that contains \nall the threads whose execution has been delayed in order to bring two racing events next to each other. \nThe next statements to be executed by these threads belong to the set RaceSet. Algorithm 1 Algorithm \nRACEFUZZER 1: Inputs: the initial state s0, a set of two racing statements RaceSet 2: s := s0 3: postponed \n:= \u00d8 4: while Enabled(s)= \u00d8 do 5: t := a random thread in Enabled(s)\\ postponed 6: if NextStmt(s, t) \n. RaceSet then 7: R := Racing (s, t, postponed) 8: if R = \u00d8 then /* Actual race detected */ 9: print \nERROR: actual race found 10: /* Randomly resolve race */ 11: if random boolean then 12: s := Execute(s, \nt) 13: else 14: postponed := postponed .{t} 15: for all t' . R do ' 16: s := Execute(s, t) 17: postponed \n:= postponed \\{t'} 18: end for 19: end if 20: else /* Wait for a race to happen */ 21: postponed := postponed \n.{t} 22: end if 23: else 24: s := Execute(s, t) 25: end if 26: if postponed = Enabled(s) then 27: remove \na random element from postponed 28: end if 29: end while 30: if Active(s)= \u00d8 then 31: print ERROR: actual \ndeadlock found 32: end if Algorithm 2 Function Racing(s, t, postponed) 1: Inputs: program state s, thread \nt,and set postponed 2: return {t' | t' . postponed s.t. NextStmt(s, t) and NextStmt(s, t') access the \nsame memory location and at least one of the accesses is a write} The algorithm runs in a loop until \nthere is no enabled thread in the execution. At the termination of the loop, RACEFUZZER reports an actual \ndeadlock if there is at least one active thread in the execution. In each iteration of the loop, RACEFUZZER \nexecutes some statements of the pro\u00adgram as follows. RACEFUZZER picks a random thread t that is enabled \nand that has not been postponed. If the next state\u00adment of the thread is not in the set RaceSet,then \nRACE-FUZZER executes the next statement. This is the trivial case. Otherwise, if the next statement of \nt is in the set RaceSet, then RACEFUZZER computes a subset R of the set post\u00adponed.The set R contains \nall threads of postponed, such that the execution of the next statement of a thread in R access the same \ndynamic shared memory location as the next state\u00adment of the thread t and at least one of the accesses \nis a write. The computation of the set R is done by the function Racing described in Algorithm 2. If \nthe set R is non-empty, then RACEFUZZER has brought at least two threads, i.e. the thread t and any thread \nin R,such that the execution of the next statements by the two threads are in race. At this point, RACEFUZZER \nreports a real race. RACEFUZZER then randomly resolves these races either by executing the next statement \nof the thread t or by executing the next statements of all the threads in R.If RACEFUZZER chooses to \nexecute the next statements of the threads in R, then the thread t is placed in the postponed set and \nthe threads in R are removed from the postponed set. We next point out some key observations about the \npostponed and R sets. The execution of the next statements of the threads in postponed cannot mutually \nrace because whenever a race happens, RACEFUZZER resolves the race by executing one element of a racing \npair. This also implies that the execution of the next statements of the threads in R cannot mutually \nrace. Another observation is that R can contain more than one element because the next statements of \nthe threads in R can read access the same memory location. If the set R is empty, then there is no real \nrace. There\u00adfore, RACEFUZZER adds t to the set postponed so that it can wait for a real race to happen. \nAt the end of each it\u00aderation of the main loop in the RACEFUZZER algorithm, it may happen that the set \npostponed is equal to the set of all enabled threads. This results in a deadlock situation in the RACEFUZZER \nalgorithm because in the next iteration RACEFUZZER has no thread for scheduling. RACEFUZZER breaks this \ndeadlock situation by randomly removing one thread from the set postponed. After the termination of the \nmain loop in RACEFUZZER, the set of enabled threads is empty. This implies that either all the threads \nhave died or some threads have reached a deadlock situation. In the latter case, RACEFUZZER reports a \nreal deadlock. In RACEFUZZER, we can trivially replay a concurrent execution by picking the same seed \nfor random number generation. This is because RACEFUZZER ensures that at any time during execution only \none thread is executing and it resolves all non-determinism in picking the next thread to execute by \nusing random numbers. Deterministic replay is a powerful feature of RACEFUZZER because it allows the \nuser to replay and debug a race condition.  3. Advantages of RACEFUZZER 3.1 Example 1 illustrating RACEFUZZER \nFigure 1 shows a two-threaded program with a real race. For the simplicity of description, instead of \nusing Java, we use pseudo code to describe the example program. The vari\u00adables x, y, z and the lock L \nare shared between the two threads. The values of x, y, and z are initialized to 0. If all statements \nof thread1 execute .rst, then ERROR1 is not reached. Otherwise, if all statements of thread2 Initially:x \n=y = z = 0; thread1 { thread2 { 1: x=1; 7: z=1; 2: lock(L); 8: lock(L); 3: y=1; 9: if(y==1) { 4: unlock(L); \n10: if (x != 1){ 11: ERROR2; 5: if (z==1) 12: } 6: ERROR1; 13: } } 14: unlock(L); } Figure 1. A program \nwith a real race execute .rst, then ERROR1 is reached. This happens due to a race over the variable z \nstatement 7 and statement 5 of the program can be executed by the two threads, respectively, without \nany synchronization between them. There is no race over the variable y because any access to y is protected \nby the lock L. The accesses to the variable x may appear to be in race because such accesses are not \nconsistently protected by a single lock. However, the accesses are implicitly synchro\u00adnized by the variable \ny. As such, the execution of the state\u00adments 1 and 10 (i.e. the statements accessing x) cannot be brought \ntemporally next to each other in the two threads. Therefore, there is no race over the accesses to x. \nHybrid race detection technique will, however, report that there is a race over the variable x. We now \nillustrate the RACEFUZZER algorithm using the example. In the .rst phase of the algorithm, hybrid race \nde\u00adtection will report that statement pairs (5, 7) and (1, 10) are in race. In the second phase, we will \ninvoke Algorithm 1 with RaceSet initialized to {5, 7} and {1, 10}. For each value of RaceSet, the algorithm \nwill be invoked several times with different random seeds. Let us consider the two cases corre\u00adsponding \nto two different initializations of RaceSet. Case 1: RaceSet = {1, 10}. In this case, it is not possi\u00adble \nfor thread2 to .rst reach statement 10. If thread1 .rst reaches statement 1, then it will delay the execution \nof the thread until it sees the execution of statement 10 by thread2. However, since y=0, thread2 will \nnot exe\u00adcute statement 10 and will terminate. Following the pseudo\u00adcode at line 26 of Algorithm 1, thread1 \nwill be removed from postponed and it will execute the remaining statements. Therefore, no real race \nwill be reported. Case 2: RaceSet = {5, 7}.If thread1 .rst reaches state\u00adment 5, then it starts waiting. \nthread2 then reaches state\u00adment 7 and RACEFUZZER reports a real race. Depending on whether statement \n7 or statement 5 is executed next, ERROR1 is reached or not executed, respectively. The same happens \nif thread2 .rst reaches statement 7. The above example shows that RACEFUZZER can de\u00adtect and create a \nreal race situation without giving any false Initially: x = 0; thread1 { thread2 { 1. lock(L); 10. x \n= 1;  2. f1(); 11. lock(L);  3. f2(); 12. f6();  4. f3(); 13. unlock(L);  5. f4(); } 6. f5();  \n7. unlock(L);  8. if (x==0)  9. ERROR;  } Figure 2. A program with a hard to reproduce real race \nwarning. Hybrid race detection, or similar imprecise tech\u00adniques, can, on the other hand, give false \nwarnings. RACE-FUZZER detects the only real race in the program. It also creates a couple of scenarios, \nor concurrent executions, to il\u00adlustrate the race. One such scenario shows the reachability of ERROR1. \nMoreover, RACEFUZZER provides full functional\u00adity to replay these scenarios. 3.2 Example 2 illustrating \nthat RACEFUZZER can detect races with high probability We use the two-threaded program in Figure 2 to \nargue that RACEFUZZER can create a real race condition with high probability compared to an algorithm \nusing the default scheduler or a simple random scheduler. The program uses a shared variable x which \nis initialized to 0. The important statements in this program are statements 8, 9, and 10. We add the \nother statements in the program to ensure that statement 8 gets executed after the execution of a large \nnumber of statements by thread1 and statement 10 gets executed by thread2 at the beginning. This snippet \nrepresents a pattern in real-world programs. If we run the program with the default scheduler or use \na simple randomized scheduler, then the probability of ex\u00adecuting statements 8 and 10 temporally next \nto each other is very low. In fact, with high probability, the execution of statements 8 and 10 will \nbe separated by the acquire and the release of the lock L. As such a happens-before race detec\u00adtor will \nnot be able to detect the race with high probabil\u00adity. Moreover, in this example, it is very unlikely \nthat state\u00adment 10 will be executed after statement 8. This implies that ERROR will not be executed with \nvery high probability. The probability of detecting the race and reaching the ERROR statement depends \non the number of statements before state\u00adment 8. The probability becomes lower as the number of statements \nbefore statement 8 is increased. We now show that RACEFUZZER creates the real race with probability 1 \nand reaches the ERROR statement with probability 0.5. Moreover, we show that this probability is independent \nof the number of statements before statement 8. In the .rst phase, hybrid race detection will predict \nthat state\u00adment 8 and statement 10 could be in race. The RACEFUZZER algorithm will then be invoked with \nRaceSet initialized to (8, 10). For any thread schedule, either thread1 will get postponed at statement \n8 or thread2 will get postponed at statement 10. Therefore, RACEFUZZER will create the race condition \nwith probability 1. In either case, RACEFUZZER will resolve the race and execute thread1 with probabil\u00adity \n0.5. Therefore, the probability that thread1 reaches the ERROR statement is 0.5. The above example shows \nthat in some situations even if two racing statements are separated by many statements in a real execution, \nthey can be brought temporally next to each other with high probability by RACEFUZZER.As such RACEFUZZER \ncan create real race conditions with very high probability. Our experimental results in Section 5.2 support \nthis fact.  4. Implementation RACEFUZZER can be implemented for any language that supports threads and \nshared memory programming, such as Java or C/C++ with pthreads. We have implemented the RACEFUZZER algorithm \nonly for Java. The implementa\u00adtion is part of the CALFUZZER tool set [45] developed to experiment with \nvarious smart random testing algorithms. RACEFUZZER instruments Java bytecode to observe various events \nand to control the thread scheduler. Bytecode instru\u00admentation allows us to analyze any Java program \nfor which the source code is not available. The instrumentation inserts various methods provided by RACEFUZZER \ninside Java pro\u00adgrams. These methods implement both hybrid-race detection and the RACEFUZZER algorithm. \nThe implementation of the hybrid-race detection algo\u00adrithm is not an optimized one. This is because the \ngoal of this work is to implement and experiment with the RACE-FUZZER algorithm. As such the implementation \nof the hybrid-race detection algorithm runs slower than the opti\u00admized implementation reported in [37]. \nThe instrumentor of RACEFUZZER modi.es all bytecode associated with a Java program including the libraries \nit uses, except for the classes that are used to implement RACE-FUZZER. This is because RACEFUZZER runs \nin the same memory space as the program under analysis. RACEFUZZER cannot track lock acquires and releases \nby native code. As such, there is a possibility that RACEFUZZER can go into a deadlock if there are synchronization \noperations inside unin\u00adstrumented classes or native code. To avoid such scenarios, RACEFUZZER runs a \nmonitor thread that periodically polls to check if there is any deadlock. If the monitor discovers a \ndeadlock, then it removes one thread from the set postponed. RACEFUZZER can also go into livelocks. Livelocks \nhap\u00adpen when all threads of the program end up in the postponed set, except for one thread that does \nsomething in a loop with\u00adout synchronizing with other threads. We observed such live\u00adlocks in a couple \nof our benchmarks including moldyn.In the presence of livelocks, these benchmarks work correctly because \nthe correctness of these benchmarks assumes that the underlying Java thread scheduler is fair. In order \nto avoid livelocks, RACEFUZZER creates a monitor thread that peri\u00adodically removes those threads from \nthe postponed set that are waiting for a long time. In [31], it has been shown that it is suf.cient to \nperform thread switches before synchronization operations, provided that the algorithm tracks all data \nraces. RACEFUZZER,there\u00adfore, only performs thread switches before synchronization operations. This particular \nrestriction on thread switch keeps our implementation fast. Since RACEFUZZER only tracks synchronization \noperations and a racing statement pair, the runtime overhead of RACEFUZZER is signi.cantly lower than \nthat of hybrid-race detection and happens-before race detection techniques.  5. Empirical Evaluation \n5.1 Benchmark Programs We evaluated RACEFUZZER on a variety of Java multi\u00adthreaded programs. The benchmark \nincludes both closed programs and open libraries that require test drivers to close them. We ran our \nexperiments on a Macbook Pro with a 2.2 GHz Intel Core 2 Duo processor and 2GB RAM. We considered the \nfollowing closed benchmark programs in our experiments: moldyn, montecarlo, raytracer, three benchmarks \nfrom the Java Grande Forum, cache4j, a fast thread-safe implementation of a cache for Java ob\u00adjects, \nsor, successive order-relaxation benchmark from ETH [53], hedc, a web-crawler application kernel devel\u00adoped \nat ETH [53], weblech, a multi-threaded web site download and mirror tool, jspider, a highly con.gurable \nand customizable Web Spider engine, jigsaw 2.2.6, W3C s leading-edge Web server platform. The total lines \nof code in these benchmark programs is approximately 600,000. The bugs and real races discovered in the \nbench\u00admark programs whose column 8 has an empty entry, were previously unknown. The open programs consist \nof several synchronized Collection classes provided with Sun s JDK, such as Vector in JDK 1.1, ArrayList, \nLinkedList, HashSet,and TreeSet in JDK 1.4.2. Most of these classes (except the Vector class) are not \nsynchro\u00adnized by default. The java.util package provides spe\u00adcial functions Collections.synchronizedList \nand Collections.synchronizedSet to make the above classes synchronized. In order to close the Collection \nclasses, we wrote a multi-threaded test driver for each such class. A test driver starts by creating \ntwo empty objects of the class. The test driver also creates and starts a set of threads, where each \nthread executes different methods of either of the two objects concurrently. We created two objects because \nsome of the methods, such as containsAll, takes as an argument an object of the same type. For such methods, \nwe call the method on one object and pass the other object as an argument. We use our experiments two \ndemonstrate the following two hypotheses: 1. RACEFUZZER can create real race conditions with very high \nprobability. It can also show if a real race can lead to an exception. 2. The real races detected automatically \nby RACEFUZZER are same as the real races that are predicted and manually con.rmed for a number of existing \nbenchmark programs.   5.2 Results Table 1 summarizes the results of our experiments. Column 2 reports \nthe number of lines of code. The reported num\u00adber of lines of code is always fewer than the actual number \nof lines of code. This is because we do not count lines in several libraries. Columns 3, 4, and 5 report \nthe average run\u00adtime for the benchmark programs using normal execution, the hybrid-race detection algorithm, \nand RACEFUZZER,re\u00adspectively. For the I/O intensive benchmarks, the runtime of RACEFUZZER is 1.1x-3x \ngreater than normal execution time. However, the runtime is signi.cantly greater for the high-performance \ncomputing applications. The runtime of the hybrid-race detection algorithm has many orders of mag\u00adnitude \nhigher runtime for the high-performance benchmarks. Theruntimefor RACEFUZZER is not that high because \nwe only instrument the racing statements and synchronization operations in RACEFUZZER.Since RACEFUZZER \nis a tool for testing and debugging, we do not worry about runtime as long as the average runtime is \nless than a few seconds. Due to the interactive nature of the jigsaw webserver, we do not report the \nruntime for jigsaw. Columns 6, 7, and 8 report the number of potential races detected by the hybrid algorithm, \nthe number of real races reported by RACEFUZZER, and the number of real races known from case studies \ndone by other researchers, respec\u00adtively. In each case, we count the number of distinct pairs of statements \nfor which there is a race. The fact that the numbers in column 7 are equal to the numbers in column 8 \ndemonstrates our hypothesis 2, i.e., RACEFUZZER reports all real races that were reported by existing \ndynamic anal\u00adysis tools. In case of moldyn, we discovered 2 real races (but benign) that were missed \nby previous dynamic analysis tools. Column 9 reports the total number of distinct pairs of racing statements \nfor which an exception has been thrown by a benchmark program. Column 10 reports the number of exceptions \nthrown by a benchmark when run with the JVM s default scheduler. We describe details of some of the exceptions \ndetected by RACEFUZZER in the next section. The results in these two columns show that RACEFUZZER is \nfar more effective in discovering insidious errors in concur\u00adrent programs compared to the default scheduler. \nColumn 11 Program Name SLOC Average Runtime in sec. Normal Hybrid RF Hybrid # of Races RF (real) known \n# of Exceptions RF Simple Probability of hitting a race moldyn 1,352 2.07 > 3600 42.37 59 2 0 0 0 1.00 \nraytracer 1,924 3.25 > 3600 3.81 2 2 2 0 0 1.00 montecarlo 3,619 3.48 > 3600 6.44 5 1 1 0 0 1.00 cache4j \n3,897 2.19 4.26 2.61 18 2 - 1 0 1.00 sor 17,689 0.16 0.35 0.23 8 0 0 0 0 - hedc 29,948 1.10 1.35 1.11 \n9 1 1 1 0 0.86 weblech 35,175 0.91 1.92 1.36 27 2 1 1 1 0.83 jspider 64,933 4.79 4.88 4.81 29 0 - 0 0 \n- jigsaw 381,348 - - 0.81 547 36 - 0 0 0.90 vector 1.1 709 0.11 0.25 0.2 9 9 9 0 0 0.94 LinkedList 5979 \n0.16 0.26 0.22 12 12 - 5 0 0.85 ArrayList 5866 0.16 0.26 0.24 14 7 - 7 0 0.55 HashSet 7086 0.16 0.26 \n0.25 11 11 - 8 1 0.54 TreeSet 7532 0.17 0.26 0.24 13 8 - 8 1 0.41 Table 1. Experimental results. shows \nthat in most cases RACEFUZZER can create a real race with very high probability. In order to roughly \nestimate the probability, we ran RACEFUZZER 100 times for each rac\u00ading pair of statements. The above \nresults demonstrate our hypothesis 1.  5.3 Bugs Found RACEFUZZER discovered a number of previously unknown \nuncaught exceptions in the benchmark programs. We next describe a couple of them. RACEFUZZER discovered \nan uncaught exception in cache4j that happens due to a race over the sleep .eld in CacheCleaner.java.The \ncode snippet causing the exception is shown below. Thread2: Thread1: _sleep = true; try { synchronized(this){ \nsleep(_cleanInterval); if(_sleep){} catch (Throwable t){ interrupt(); } finally { } _sleep = false; \n } } If sleep is set to true by Thread2 before entering the try block and Thread1 is executed next, then \nan uncaught InterruptedException is thrown causing Thread2 to crash. Note that here this corresponds \nto Thread2. We discovered some concurrency related problems in the JDK 1.4.2 classes LinkedList, ArrayList, \nHashSet, and TreeSet. Speci.cally, we discovered real races in the containsAll and equals methods of \nLinkedList and ArrayList, and in the containsAll and addAll methods of HashSet and TreeSet.For example, \nif we call l1.containsAll(l2) and l2.removeAll() in two threads, where l1 and l2 are synchronized LinkedLists \n(created using Collections.synchronizedList), then we can get both ConcurrentModificationException and \nNoSuchElementException. This is because the containsAll method is implemented by the superclass AbstractCollection \nand the imple\u00admentation uses iterator in a thread-unsafe way: a call to l1.containsAll(l2) calls the \nsynchronized iterator method on l2 and then goes over the iterator without holding the lock on l2. As \na result, the iterator accesses the modCount .eld of l2 without holding the lock on l2. Therefore, any \nother method call on l2 that modi.es modCount,such as removeAll, would interfere with the iterator code \nleading to exceptions. The code works without exception in a single-threaded setting and probably the \ndevelopers had a single-threaded setting in mind while implementing the unsynchronized containsAll method \nin AbstractCollection. However, while extending the LinkedList class to synchronized LinkedList using \na decorator pattern in the Collections class, the developers did not override the containsAll method \nto make it thread-safe.  6. Related Work A large body of research focuses on dynamic or static race \ndetection [41, 35, 21, 43, 10, 14]. Type based tech\u00adniques [20, 5, 6], which require programmer annotations, \nhave been used to reduce the race detection problem to a type checking problem. Since annotation writing \ncreates signi.\u00adcant overhead, techniques [3] have been proposed to infer type annotations by looking \nat concurrent executions. Other language based techniques for static race detection include nesC [24] \nand Guava [5]. Several static race detection tech\u00adniques [49, 19, 39] based on lockset [43] have been \npro\u00adposed. An important advantage of the static techniques is that they could .nd all potential race \nconditions in a pro\u00adgram. A primary limitation of these techniques is that they report a lot of false \nraces. More recent efforts on static race detection [33, 32] have signi.cantly reduced the number of \nfalse warnings with minimal annotations, but the problem of false positives still remains. Moreover, \nthese techniques could not infer if a race could lead to an exception in the program. Therefore, manual \ninspection is needed to separate real races and harmful races. Manual inspection often over\u00adwhelms the \ndevelopers. RACEFUZZER tries to reduce the ef\u00adfort of manual inspection by exploiting the potential race \nre\u00adports generated by any imprecise race detection technique to guide a random thread scheduler. Dynamic \nrace detection techniques are often based on lockset [43, 53, 10, 36, 2] or on happens-before [44, 14, \n1, 11, 30, 42, 13, 34]. Lockset based dynamic techniques could predict data races that did not happen \nin a concur\u00adrent execution; however, such techniques can report many false warnings. Happens-before based \ndynamic techniques are capable of detecting races that actually happen in an exe\u00adcution. Therefore, these \ntechniques are precise, but they can\u00adnot give good coverage as lockset based algorithms. Speci.\u00adcally, \nhappens-before race detectors cannot predict races that could happen on a different schedule or they \ncannot create a schedule that could reveal a real race. Recently happens\u00adbefore race detection has been \nsuccessfully extended to clas\u00adsify harmful races from benign races [34], but they suf\u00adfer from the same \nlimitations as happens-before techniques. Hybrid techniques [14, 37, 38, 54] combine lockset with happens-before \nto make dynamic race detection both precise and predictive. Despite the combination, hybrid techniques \ncould report many false warnings. One characteristics that distinguishes RACEFUZZER from other dynamic \ntechniques is that RACEFUZZER actively controls the thread scheduler, whereas the other techniques passively \nobserve an execution. Recently, a couple of random testing techniques [18, 50] for concurrent programs \nhave been proposed. These tech\u00adniques randomly seed a Java program under test with the sleep(),the yield(),and \nthe priority() primitives at shared memory accesses and synchronization events. Al\u00adthough these techniques \nhave successfully detected bugs in many programs, they have two limitations. These techniques are not \nsystematic as the primitives sleep(), yield(), priority() can only advise the scheduler to make a thread \nswitch, but cannot force a thread switch. Second, reproducibility cannot be guaranteed in such systems \n[50] unless there is builtin support for capture-and-replay [18]. RACEFUZZER removes these limitations \nby explicitly con\u00adtrolling the scheduler. We recently proposed an effective ran\u00addom testing algorithm, \ncalled RAPOS [45], to sample par\u00adtial orders almost uniformly at random. However, we ob\u00adserved that RAPOS \ncannot often discover error-prone sched\u00adules with high probability because the number of partial or\u00adders \nthat can be exhibited by a large concurrent program can be astronomically large. Therefore, we focused \non test\u00ading error-prone schedules, i.e. schedules that exhibit a race condition. Static veri.cation [4, \n16, 28, 40, 8] and model check\u00ading [17, 29, 25, 27, 52, 31] or path-sensitive search of the state space \nis an alternative approach to .nding bugs in con\u00adcurrent programs. Model checkers being exhaustive in \nna\u00adture can often .nd all concurrency related bugs in concur\u00adrent programs. Unfortunately, model checking \ndoes not scale with program size. Several other systematic and exhaustive techniques [7, 9, 48, 46] for \ntesting concurrent and parallel programs have been developed recently. These techniques exhaustively \nexplore all interleavings of a concurrent pro\u00adgram by systematically switching threads at synchronization \npoints. More recently, efforts [47] have been made to com\u00adbine model checking with lockset based algorithms \nto prove the existence of real races; however, this technique suffers from scalability problem as in \nmodel checking. Randomized algorithms for model checking have also been proposed. For example Monte Carlo \nModel Check\u00ading [26] uses random walk on the state space to give proba\u00adbilistic guarantee of the validity \nof properties expressed in linear temporal logic. Randomized depth-.rst search [15] and its parallel \nextensions have been developed to dramat\u00adically improve the cost-effectiveness of state-space search \ntechniques using parallelism. Capture and replay techniques have been combined with delta-debugging [12] \nto pinpoint a program location where a thread switch could result in a program failure. The key difference \nbetween this technique and RACEFUZZER is that the former technique narrows down the difference between \na successful schedule and a failure inducing schedule to pin\u00adpoint a bug. RACEFUZZER randomly controls \nthread sched\u00adules based on potential race conditions to determine if a race is real.  Acknowledgment \nWe would like to thank Ras Bodik, Jacob Burnim, and Shau\u00adnak Chatterjee for providing valuable comments \non a draft of this paper. This work is supported in part by the NSF Grant CNS-0720906. References [1] \nS. V. Adve, M. D. Hill, B. P. Miller, and R. H. B. Netzer. Detecting data races on weak memory systems. \nIn 18th annual International Symposium on Computer architecture (ISCA), pages 234 243. ACM, 1991. [2] \nR.Agarwal,A.Sasturkar,L. Wang, andS.D.Stoller. Opti\u00admized run-time race detection and atomicity checking \nusing partial discovered types. In 20th IEEE/ACM international Conference on Automated software engineering \n(ASE), pages 233 242. ACM, 2005. [3] R. Agarwal and S. D. Stoller. Type inference for parame\u00adterized \nrace-free java. In Veri.cation, Model Checking, and Abstract Interpretation, 5th International Conference \n(VM-CAI), pages 149 160, 2004. [4] A. Aiken and D. Gay. Barrier inference. In 25th ACM SIGPLAN-SIGACT \nsymposium on Principles of programming languages, pages 342 354. ACM, 1998. [5] D. F. Bacon, R. E. Strom, \nand A. Tarafdar. Guava: a dialect of java without data races. In ACM SIGPLAN Conference on Object-Oriented \nProgramming Systems, Languages and Applications (OOPSLA 00), pages 382 400, 2000. [6] C. Boyapati and \nM. C. Rinard. A parameterized type system for race-free java programs. In ACM SIGPLAN Conference on Object-Oriented \nProgramming Systems, Languages and Applications (OOPSLA 01), pages 56 69, 2001. [7] D. Bruening. Systematic \ntesting of multithreaded Java programs. Master s thesis, MIT, 1999. [8] S. Burckhardt, R. Alur, and \nM. M. K. Martin. Checkfence: checking consistency of concurrent data types on relaxed memory models. \nIn CM SIGPLAN 2007 Conference on Programming Language Design and Implementation (PLDI), pages 12 21, \n2007. [9] R. H. Carver and Y. Lei. A general model for reachability testing of concurrent programs. In \n6th International Conference on Formal Engineering Methods (ICFEM 04), volume 3308 of LNCS, pages 76 \n98, 2004. [10] J. D. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, and M. Sridharan. Ef.cient and \nprecise datarace detection for multithreaded object-oriented programs. In Proc. of the ACM SIGPLAN Conference \non Programming language design and implementation, pages 258 269, 2002. [11] J.-D. Choi, B. P. Miller, \nand R. H. B. Netzer. Techniques for debugging parallel programs with .owback analysis. ACM Trans. Program. \nLang. Syst., 13(4):491 530, 1991. [12] J.-D. Choi and A. Zeller. Isolating failure-inducing thread schedules. \nIn ISSTA 02: Proceedings of the 2002 ACM SIGSOFT international symposium on Software testing and analysis, \npages 210 220. ACM, 2002. [13] M. Christiaens and K. D. Bosschere. Trade, a topological approach to on-the-.y \nrace detection in java programs. In JavaTM Virtual Machine Research and Technology Symposium (JVM), pages \n15 15. USENIX Association, 2001. [14] A. Dinning and E. Schonberg. Detecting access anomalies in programs \nwith critical sections. In Proc. of the ACM/ONR Workshop on Parallel and Distributed Debugging, 1991. \n[15] M. B. Dwyer, S. Elbaum, S. Person, and R. Purandare. Parallel randomized state-space search. In \n29th International Conference on Software Engineering (ICSE), pages 3 12. IEEE, 2007. [16] M. B. Dwyer, \nJ. Hatcliff, Robby, and V. P. Ranganath. Exploiting object escape and locking information in partial\u00adorder \nreductions for concurrent object-oriented programs. Form. Methods Syst. Des., 25(2 3):199 240, 2004. \n[17] J. E. M. Clarke, O. Grumberg, and D. A. Peled. Model checking. MIT Press, 1999. [18] O. Edelstein, \nE. Farchi, Y. Nir, G. Ratsaby, , and S. Ur. Multithreaded Java program test generation. IBM Systems Journal, \n41(1):111 125, 2002. [19] D. R. Engler and K. Ashcraft. Racerx: effective, static detection of race conditions \nand deadlocks. In 19th ACM Symposium on Operating Systems Principles (SOSP), pages 237 252, 2003. [20] \nC. Flanagan and S. N. Freund. Type-based race detection for java. In ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation (PLDI 00), pages 219 232, 2000. [21] C. Flanagan and S. N. Freund. \nDetecting race conditions in large programs. In Proc. of the Program Analysis for Software Tools and \nEngineering Conference, 2001. [22] C. Flanagan and S. N. Freund. Atomizer: a dynamic atom\u00adicity checker \nfor multithreaded programs. In 31st ACM SIGPLAN-SIGACT Symposium on Principles of Program\u00adming Languages \n(POPL), pages 256 267, 2004. [23] C. Flanagan and S. Qadeer. A type and effect system for atomicity. \nIn ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation, pages 338 349, 2003. \n[24] D. Gay, P. Levis, R. von Behren, M. Welsh, E. Brewer, and D. Culler. The nesC language: A holistic \napproach to networked embedded systems. In ACM SIGPLAN Conference on Programming language design and \nimplementation, pages 1 11, 2003. [25] P. Godefroid. Model checking for programming languages using verisoft. \nIn 24th Symposium on Principles of Program\u00adming Languages, pages 174 186, 1997. [26] R. Grosu and S. \nA. Smolka. Monte carlo model checking. In 11th International Conference Tools and Algorithms for the \nConstruction and Analysis of Systems (TACAS 2005), volume 3440 of LNCS, pages 271 286, 2005. [27] K. \nHavelund and T. Pressburger. Model Checking Java Programs using Java PathFinder. Int. Journal on Software \nTools for Technology Transfer, 2(4):366 381, 2000. [28] T. A. Henzinger, R. Jhala, and R. Majumdar. Race \nchecking by context inference. SIGPLAN Not., 39(6):1 13, 2004. [29] G. Holzmann. The Spin model checker. \nIEEE Transactions on Software Engineering, 23(5):279 295, 1997. [30] J. Mellor-Crummey. On-the-.y detection \nof data races for programs with nested fork-join parallelism. In ACM/IEEE conference on Supercomputing, \npages 24 33. ACM, 1991. [31] M. Musuvathi and S. Qadeer. Iterative context bounding for systematic testing \nof multithreaded programs. In ACM Symposium on Programming Language Design and Implementation (PLDI 07), \n2007. [32] M. Naik and A. Aiken. Conditional must not aliasing for static race detection. In 34th ACM \nSIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 327 338, 2007. [33] M. Naik, A. \nAiken, and J. Whaley. Effective static race detection for java. In ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 308 319, 2006. [34] S. Narayanasamy, Z. Wang, J. Tigani, A. \nEdwards, and B. Calder. Automatically classifying benign and harmful data races using replay analysis. \nIn ACM SIGPLAN 2007 Conference on Programming Language Design and Implementation (PLDI), pages 22 31, \n2007. [35] R. Netzer and B. Miller. Detecting data races in parallel program executions. In Advances \nin Languages and Compilers for Parallel Computing. MIT Press, 1990. [36] H. Nishiyama. Detecting data \nraces using dynamic escape analysis based on read barrier. In Virtual Machine Research and Technology \nSymposium, pages 127 138, 2004. [37] R. O Callahan and J.-D. Choi. Hybrid dynamic data race detection. \nIn ACM SIGPLAN symposium on Principles and practice of parallel programming, pages 167 178. ACM, 2003. \n[38] E. Pozniansky and A. Schuster. Ef.cient on-the-.y data race detection in multithreaded c++ programs. \nIn Ninth ACM SIGPLAN symposium on Principles and practice of parallel programming (PPoPP), pages 179 \n190. ACM, 2003. [39] P. Pratikakis, J. S. Foster, and M. Hicks. LOCKSMITH: context-sensitive correlation \nanalysis for race detection. In ACM SIGPLAN conference on Programming language design and implementation \n(PLDI), pages 320 331. ACM, 2006. [40] S. Qadeer and D. Wu. Kiss: keep it simple and sequential. In ACM \nSIGPLAN 2004 conference on Programming language design and implementation (PLDI), pages 14 24. ACM, 2004. \n[41] B. Richards and J. R. Larus. Protocol-based data-race detection. In Proc. of the SIGMETRICS symposium \non Parallel and distributed tools, pages 40 47, 1998. [42] M. Ronsse and K. D. Bosschere. Recplay: a \nfully integrated practical record/replay system. ACM Trans. Comput. Syst., 17(2):133 152, 1999. [43] \nS. Savage, M. Burrows, G. Nelson, P. Sobalvarro, and T. E. Anderson. Eraser: A dynamic data race detector \nfor multithreaded programs. ACM Trans. Comput. Syst., 15(4):391 411, 1997. [44] E. Schonberg. On-the-.y \ndetection of access anomalies. In ACM SIGPLAN 89 Conference on Programming Language Design and Implementation \n(PLDI), volume 24, pages 285 297, 1989. [45] K. Sen. Effective random testing of concurrent programs. \nIn 22nd IEEE/ACM nternational Conference on Automated Software Engineering (ASE 07), 2007. [46] K. Sen \nand G. Agha. A race-detection and .ipping algorithm for automated testing of multi-threaded programs. \nIn Haifa veri.cation conference 2006 (HVC 06), Lecture Notes in Computer Science. Springer, 2006. [47] \nO. Shacham, M. Sagiv, and A. Schuster. Scaling model checking of dataraces using dynamic information. \nJ. Parallel Distrib. Comput., 67(5):536 550, 2007. [48] S. F. Siegel, A. Mironova, G. S. Avrunin, and \nL. A. Clarke. Using model checking with symbolic execution to verify parallel numerical programs. In \nInternational symposium on Software testing and analysis (ISSTA), pages 157 168. ACM Press, 2006. [49] \nN. Sterling. Warlock: A static data race analysis tool. In USENIX Winter Technical Conference, pages \n97 106, 1993. [50] S. D. Stoller. Testing concurrent Java programs using randomized scheduling. In Workshop \non Runtime Veri.cation (RV 02), volume 70 of ENTCS, 2002. [51] M. Vaziri, F. Tip, and J. Dolby. Associating \nsynchronization constraints with data in an object-oriented language. In 33rd ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Languages (POPL), pages 334 345, 2006. [52] W. Visser, K. Havelund, G. Brat, \nand S. Park. Model checking programs. In 15th International Conference on Automated Software Engineering \n(ASE). IEEE, 2000. [53] C. von Praun and T. R. Gross. Object race detection. In 16th ACM SIGPLAN conference \non Object oriented programming, systems, languages, and applications (OOPSLA), pages 70 82. ACM, 2001. \n[54] Y. Yu, T. Rodeheffer, and W. Chen. Racetrack: ef.cient detection of data race conditions via adaptive \ntracking. SIGOPS Oper. Syst. Rev., 39(5):221 234, 2005.  \n\t\t\t", "proc_id": "1375581", "abstract": "<p>Bugs in multi-threaded programs often arise due to data races. Numerous static and dynamic program analysis techniques have been proposed to detect data races. We propose a novel randomized dynamic analysis technique that utilizes potential data race information obtained from an existing analysis tool to separate real races from false races without any need for manual inspection. Specifically, we use potential data race information obtained from an existing dynamic analysis technique to control a random scheduler of threads so that real race conditions get created with very high probability and those races get resolved randomly at runtime. Our approach has several advantages over existing dynamic analysis tools. First, we can create a real race condition and resolve the race randomly to see if an error can occur due to the race. Second, we can replay a race revealing execution efficiently by simply using the same seed for random number generation--we do not need to record the execution. Third, our approach has very low overhead compared to other precise dynamic race detection techniques because we only track all synchronization operations and a single pair of memory access statements that are reported to be in a potential race by an existing analysis. We have implemented the technique in a prototype tool for Java and have experimented on a number of large multi-threaded Java programs. We report a number of previously known and unknown bugs and real races in these Java programs.</p>", "authors": [{"name": "Koushik Sen", "author_profile_id": "81100399070", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P1022830", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1375581.1375584", "year": "2008", "article_id": "1375584", "conference": "PLDI", "title": "Race directed random testing of concurrent programs", "url": "http://dl.acm.org/citation.cfm?id=1375584"}