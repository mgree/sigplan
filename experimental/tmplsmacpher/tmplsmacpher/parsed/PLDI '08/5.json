{"article_publication_date": "06-07-2008", "fulltext": "\n Automatic Volume Management for Programmable Microfluidics Ahmed M. Amin, Mithuna Thottethodi, T. N. \nVijaykumar Steven Wereley*, and Stephen C. Jacobson. School of Electrical &#38; Computer Engineering, \nPurdue University*School of Mechanical Engineering, Purdue University.Department of Chemistry, Indiana \nUniversity {amamin, mithuna, vijay, wereley}@purdue.edu, jacobson@indiana.edu Abstract Microfluidics \nhas enabled lab-on-a-chip technology to minia\u00adturize and integrate biological and chemical analyses to \na single chip comprising channels, valves, mixers, heaters, separators, and sensors. Recent papers have \nproposed programmable labs-on-a\u00adchip as an alternative to traditional application-specific chips to reduce \ndesign effort, time, and cost. While these previous papers provide the basic support for programmability, \nthis paper identifies and addresses a practical issue, namely, fluid volume management. Volume management \naddresses the problem that the use of a fluid depletes it and unless the given volume of a fluid is distributed \ncarefully among all its uses, execution may run out of the fluid before all its uses are complete. Additionally, \nfluid volumes should not overflow (i.e., exceed hardware capacity) or underflow (i.e., fall below hardware \nresolution). We show that the problem can be formulated as a linear programming problem (LP). Because \nLP s complexity and slow execution times in practice may be a concern, we propose another approach, called \nDAGSolve, which over-con\u00adstrains the problem to achieve linear complexity while maintaining good solution \nquality. We also propose two optimizations, called cascading and static replication, to handle cases \ninvolving extreme mix ratios and numerous fluid uses which may defeat both LP and DAGSolve. Using some \nreal-world assays, we show that our tech\u00adniques produce good solutions while being faster than LP. Categories \nand Subject Descriptors D.3 [Programming Languages]: Compilers General Terms: Algorithms, Design Keywords: \nMicrofluidics, Programmable lab-on-a-chip, Fluid volume management  1 Introduction Microfluidics is \nthe field of handling fluids in small quantities, typically at the scale of nano or pico liters. Microfluidics \nhas min\u00adiaturized and integrated channels, valves, mixers, heaters, and sep\u00adarators to enable chemical \nand biological analyses in a single chip called a lab-on-a-chip (LoC). LoCs enable faster, cheaper and \nhigher-precision analyses over the traditional bench-scale methods. To date, LoCs have been applied in \ndiverse industrial and academic Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor profit or commercial advantage and that copies bear this notice and the full citation on the first \npage. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior \nspecific permission and/or a fee. domains, such as drug discovery, virology, clinical applications, \ngenomics, biochemistry and chemical synthesis. Thus far LoCs have been designed as application-specific \nchips which closely map an assay (fluidic algorithm) to the LoC hard\u00adware. Assays are analogous to conventional \ncomputer programs, where fluids correspond to variables, and operations such as mix, incubate, separate \nand sense manipulate input fluids to generate new fluids. The application-specific approach leads to \nconsiderable design effort, turn-around time, and cost. To address these limita\u00adtions, Urbanski et al. \n[13] pioneer the idea of programmable labs\u00adon-a-chip (PLoC)1, and introduce a new programming language \nfor microfluidics called Biostream [10]. In prior work, we pro\u00adposed a comprehensive instruction set \ncalled AquaCore Instruction Set (AIS), and a microarchitecture called AquaCore [2]. While the previous \npapers provide the basic support for pro\u00adgrammability, this paper identifies and addresses a practical \nissue, namely, fluid volume management. The issue of fluid volume man\u00adagement arises because fluids have \na fixed total volume, and the use of a fluid (variable) depletes it. If there are many uses of a fluid, \nthe given volume of the fluid must be distributed carefully among the uses to prevent execution from \nrunning out of the fluid before all of the uses occur. This distribution poses a challenge when the uses \nrequire different proportions of volumes as is the case when a fluid is mixed with different other fluids \nin different ratios (e.g., one use for a fluid is in a mix ratio of 1:2 while another use for the same \nfluid is in a mix ratio of 1:10). The destructive nature of fluid uses is fundamentally different than \nthat of use of variable values in conventional computers where uses (i.e., reads) are non-destructive. \nThis difference indicates the novelty of the problem, motivating the need for volume management. Dealing \nwith destructive uses is further complicated by low-level, imple\u00admentation-dependent details of the fluidic \nhardware, such as maxi\u00admum capacity (of reservoirs and functional units) and minimum fluid transport \nresolution (imposed by the fluid transport/ handling hardware). Forcing the programmer to handle these \nconstraints would diminish the practicality of PLoCs. Consequently, we han\u00addle this issue automatically \nusing a combination of the compiler and run-time system. Biostream has proposed a reactive approach for \nvolume man\u00adagement, called regeneration [10]. Regeneration allows the fluid to run out and re-generates \nthe fluid just before the next use by re\u00adexecuting the code fragments that produce the fluid (i.e., the \nback\u00adward slice [11]). While elegant in theory, regeneration may place a high or unbounded demand on \nLoC resources. Mimicing PLDI 08 June 7 13, 2008, Tucson, Arizona, USA. 1. We clarify that PLoC s programmability \nis software programmability Copyright &#38;#169; 2008 ACM 978-1-59593-860-2/08/06...$5.00. (like microprocessors), \nand not burn-in programmability (like FPGAs). unbounded resources through virtualization is feasible \nin conven\u00adtional computers, but microfluidic technology is not yet at that level of maturity. Even when \nregeneration is feasible, regeneration re-executes fluidic instructions (in the fluidic datapath) which \nare slow and are likely to incur overhead (PLoCs use a heterogeneous organization where the datapath \nis fluidic and control is electronic and orders-of-magnitude faster [10][2]). In contrast, we take the \npro-active approach of reducing the chances of running out of a fluid (but not eliminating it, as we \nexplain later). Thus, our approach mostly avoids regeneration s overhead while regenera\u00adtion can be used \nas our back-up when our approach cannot avoid fluid running out. The key challenge is ensuring that not \nonly all the direct uses of a given fluid but also all the uses of fluids indirectly derived from the \ngiven fluid satisfy their respective usage proportions. For instance, an assay mixes fluids a and b in \nsome ratio to produce fluid c and then mixes fluids a and c in some other ratio to produce fluid d, which \nis later used to produce fluid e. Thus, we need to ensure that our distribution of a s volume among its \nuses results in enough volume of d for its later use. Additionally, fluid volumes should not overflow \n(i.e., exceed hardware capacity) or underflow (i.e., fall below hardware transport resolution), and must \nbe an integer multiple of the minimum hardware transport resolution. We call this volume-assignment problem \nInteger Volume Manage\u00adment (IVol). At present, the complexity of IVol is unknown and is left as an open \nquestion for future work. However, we show that IVol can be cast as an integer linear programming (ILP) \nproblem. This formulation is our first contribution. Because ILP is NP-Hard, and because the underlying \nchemistry in inherently tolerant of minor inaccuracies in mix ratios, we provide a rational formulation \nof the problem, called Rational Volume Management (RVol), and round the resulting volume assignment to \nintegers. To solve RVol, we employ linear programming (LP) instead of ILP. However, for L-bit inputs \nand n variables, LP has a worst-case asymptotic com\u00adplexity of O(n3L) [4]. While such complexity may \nbe tolerable for modest-size assays at compile-time, there are cases where we have to solve this problem \nat run-time because volumes of some inter\u00admediate fluids may not be available at compile time (e.g., \nthe vol\u00adume yielded by a separate-by-size step may not be known a priori). In such cases, LP s complexity \nmay be a concern despite the fact that run-time computations can be done in the PLoC s fast electronic \ncontrol. While one may think that LP solvers are fast in practice despite LP s worst-case complexity, \nwe show that LP is significantly slow for real-world assays. Consequently, we wish to rely on LP at run-time \nonly if there are no other alternatives. We propose one such alternative approach for RVol, called DAGSolve, \nwhich artificially over-constrains the problem to achieve a linear-complexity solution. Because of its \nartificial con\u00adstraints, DAGSolve may, in some uncommon cases, not find a solution even though LP may. \nIn our experiments with real-world assays, DAGSolve was always successful, as we show in Section 4. Therefore, \nDAGSolve is a more suitable run-time option than LP. DAGSolve is our second contribution. For the uncommon \ncase where DAGSolve fails to find a feasible solution, we fall back on LP, which itself may not find \na solution and is backed up by BioStream s regeneration because it is better to provide a slow solution \nthan no solution. There are corner cases, such as extreme mix ratios (e.g., mix ratio of 1:1000) or numerous \nuses of a fluid (e.g., 7 uses of a fluid that has a volume of 6 multiples of minimum hardware transport \nresolution), that can defeat both LP and DAGSolve. For instance, a mix ratio of 1:399 using hardware \nwith maximum and minimum capacities of 100 and 1 units, respectively, would cause either an underflow \nor an overflow. To handle extreme ratios, we employ cascading, a well-known idea in life sciences, to \nbreak an extreme ratio into two or more cascaded ratios (e.g., break 1:399 into 1:19 followed by 1:19). \nFinally, because of hardware limit of maximum capacity, numerous uses of a fluid can cause underflow \neven if we produce as much volume of the fluid as possible without causing overflow. In such cases, we \nproduce extra volume by replicating the backward slice of the fluid s production. The two optimizations \nof applying cascading and static replication to assays are our third contribution. To implement our \nideas, we build a simple compiler and a soft\u00adware run-time system which we describe in the paper. We \nevaluate our ideas on real-world assays and show that our techniques are effective in avoiding fluid \noverflow and underflow. The rest of the paper is organized as follows. Section 2 presents some background \non PLoCs and related work. Section 3 discusses the ILP formulation, DAGSolve, and its extensions. We \nshow our compiled code and present our results in Section 4, and conclude in Section 5. 2 Background \nThere are two primary technologies for microfluidic devices: flow-based and droplet-based. Flow-based \ntechnologies rely on continuous or discrete fluid manipulation, while droplet-based technologies manipulate \nfree-standing droplets of fluids. We focus on flow-based devices, though our techniques may be adapted \nfor droplet-based LoCs. Today s real-world application-specific LoCs typically com\u00adprise of channels \n(for fluid transport), valves (for flow control), reservoirs (for storage), input and output ports, and \nfluidic func\u00adtional units, such as mixers, heaters, separators and sensors. Imple\u00admentation details of \nthese components can be found in [8]. The PLoC uses these pre-existing building blocks. 2.1 Baseline \nPLoC Architecture We use AquaCore [2] as our baseline PLoC architecture, and implement our volume management \ntechniques based on the AquaCore Instruction Set (AIS). Assays written in AIS are very similar to conventional \ncomputer assembly programs, where fluids correspond to variables, and operations such as mix, incubate, \nsep\u00adarate and sense manipulate existing fluids to generate new fluids. Though AIS may seem similar to \ntheir computer instruction sets, there are four key differences based on observations of real-world assays \n[2]. First, because intermediate fluids produced in assays are often used only once and usually immediately \nafter their production, binding the fluids to storage results in unnecessarily moving the fluids from \nfunctional units to storage and back. To that end, AIS employs storage-less operands which are decoupled \nfrom storage so that fluids are transferred from one functional unit to another without any intervening \nstorage (similar to [6]). Second, assays are typically specified using variable volumes, unlike computational \noperands which use fixed-size data types and rely on padding to handle other sizes. However, fluidic \noperands cannot be padded easily to a fixed larger volume (by topping off) Table 1: A subset of AIS \n move id1, id2, <rel vol> incubate id, temp, time  move-abs id1, id2, vol input id2, id1  mix id1, \ntime output id2, id1  separate.CE id1, Esep, len, sense.OD id1, senseval time sense.FL id1, senseval[] \n separate.SIZE id1, time concentrate id1, temp, time  separate.AF id1, time  in cases where reagent \nconcentrations have to be maintained. Accordingly, AIS instructions operate on variable volumes. All \nour pro-active volume management techniques handles variable vol\u00adumes. Third, because most assays specify \nvolumes only in a few steps and leave operand volumes implicit, forcing every instruction to specify \nits operand volume would be cumbersome. Accordingly, AIS allows operand volumes to be implicit. In the \nfew steps when assays specify volumes, they usually use relative volumes. There\u00adfore, AIS allows operands \nto optionally specify relative volumes (but also allows absolute volumes in the uncommon case). Because \nthe use of relative volumes combined with the destructive nature of fluid usage can result in assays \nrunning out of a fluid, relative-vol\u00adume operands give rise to the need for volume management. Fourth, \nbecause microfluidics lacks the theoretical guarantees of universality (i.e., the fluidic equivalent \nof Turing-Complete\u00adness), PLoCs must turn to experimental evaluation for coverage. While this aspect \nis orthogonal to this paper, we list this aspect for completeness. A subset of the AquaCore Instruction \nSet (AIS) is shown in Table 1 (see [2] for the complete set). The operand id space includes not only \nreservoirs (analogous to registers), but also func\u00adtional units, allowing one instruction to send its \noutput directly to another without having to go to storage (i.e., storage-less oper\u00adands). Most instructions \ndo not specify any volumes for their oper\u00adands. For such instructions, the functional unit operates on \nthe implicit volume available, and allows variable volume handling. The optional operand <rel vol>in \nmove specifies relative vol\u00adumes for transfer. The relative volumes are translated to implemen\u00adtation \nspecific volumes at runtime, enabling variable volume support and increased code portability. The list \nincludes different flavors of separate and sense (e.g., separate.CE denotes elec\u00adtrophoresis-based separation, \nseparate.AF separates using affinity to a reagent pre-loaded in the separator, sense.OD and sense.FL \ndenote sensing of optical density and fluorescence, respectively). Figure 1 shows a block diagram of \nthe AquaCore microarchi\u00adtecture consisting of heterogeneous components: a dry electronic control part \nand a wet fluidic datapath part. Because electronics is mature, reliable, inexpensive and can provide \ncontrol functionality, AquaCore uses electronic control. The electronic dry part inter\u00adprets AIS instructions \nand provides control signals to the wet part, and is implemented using a conventional microcontroller. \nAs such, the dry electronic control is orders of magnitude faster than the flu\u00adidic wet part, a difference \nwe leverage to perform some run-time computation in our volume management scheme without incurring performance \noverhead. The wet part consists of fluidic functional units (FFUs) (e.g., mixers, heaters, separators, \nand sensors), a set of reservoirs, and input and output ports. These components are connected by a set \nof channels. Furthermore, these components have a capacity limit, exceeding which would cause an overflow. \nNote that the number of reservoirs is fixed and limited, and current LoC technology does not provide \na dense equivalent (such as DRAM or disk), hence careful compile-time allocation is required. Additionally, \nAqua-Core uses microfluidic valves to control fluid flow which, much like electronic tri-state buffers, \nare central to enabling PLoC opera\u00adtion under program control. At each end of each channel is a microfluidic \npump that effects fluid transfer from one component to another by peristalsis as described in [2]. These \npumps may be used for accurate volume metering [12], which is required to han\u00addle variable volumes. Further, \nthey impose a discrete, minimum volume transport unit, or least count. Finally, we note that, while several \nhardware techniques exist to achieve fluid transfer and metering [8], they all exhibit some form of least \ncount.  3 Automatic Volume Management Recall from Section 1 that volume management is needed because \nthe use of a fluid results in the fluid s depletion, and if there are many uses of a fluid, the initial \nvolume of the fluid must be distributed carefully among the uses to prevent execution from running out \nof fluid. Such distribution must obey the relative-vol\u00adume proportions specified by the assay. Dealing \nwith destructive uses is further complicated by low-level, implementation-depen\u00addent details of the fluidic \nhardware, such as maximum capacity and minimum transport resolution. Fundamentally, this running out \noccurs because real implemen\u00adtations have a least count. Consider an example, where fluid A is partitioned \ninto four portions and one of the portions is to be mixed with fluid B in the ratio 10:1 (A:B). Then \nif A s portion in this mix is small to start with then B may underflow (i.e., the volume needed may be \nsmaller than the least count). Burdening the pro\u00adgrammer with the details of avoiding such underflow \nwould defeat the purpose of PLoCs, and as such, an automatic scheme for vol\u00adume management is required. \nHowever, because a fluid may have multiple uses like the above example, avoiding underflow requires automatic \nschemes to assign volumes such that all the uses of a fluid can be satisfied. One may think that the \nexample assumes four uses of A which is uncommon as fluids are usually used only once (Section 2.1). \nHowever, we note that multiple uses may lead to the correctness problem of fluid running out. As observed \nin computer systems research, the common case is not everything; the uncommon case must be correct. While \nour concern is allocation of portions among uses to avoid running out of fluids, evaporation and residue \nin the fluid- Electronic Control  path may also cause fluids to run out. Evaporation is alleviated by \nimmersing the fluidpath in immiscible liquids (oils in most cases) [9]. Residue in the fluidpath is reasonably \npredictable and can be corrected by over-provisioning [12]. As such, our techniques ignore fluid loss. \nOur problem is defined as follows. Given as assay which uses fluids in one or more instructions, in different \nratios, find an abso\u00adlute volume assignment for each use of each fluid, such that the assignment: 1) \nsatisfies the usage ratio constraints as defined by the assay; 2) is an integer multiple of the least \ncount hardware res\u00adolution; 3) does not underflow (i.e., the minimum fluid use in any operation is greater \nthan or equal to the least count); and 4) does not cause an overflow (i.e., the total amount of fluid \nassigned in any operation is less than the hardware maximum capacity). We call this problem Integer Volume \nManagement (IVol). Before describing our volume management schemes, we note that in the absence of unlimited \nfluidic hardware resources our techniques can only minimize, but not eliminate, the possibility of underflow, \njust like a computer program can cause underflow in floating-point arithmetic. Such underflow cannot \nbe prevented by the system and the assay must be rewritten to avoid underflow. In general, there are \ntwo fundamental ways to address this problem: either by pro-actively and conservatively using fluids \nsuch that they last for the entire assay (if possible); or by reactively regenerating fluids that are \nexhausted. Reactive approaches may incur overhead due to regeneration s re-execution which runs on the \nslow fluidpath, as described in Section 1. We adopt the pro\u00adactive approach which reduces the chances \nof underflow and thus the number of times regeneration is needed. We fall back on regen\u00aderation when \nunderflow is not avoided by our approach. Volume management amounts to computing absolute volumes as \nlong as two factors are known statically: (a) the number of uses of all fluids in an assay and (b) the \noutput volumes (relative to the input) of all assay steps. However, if either of these factors is unknown \nstatically and can be determined only at run-time, then computing the absolute volumes becomes more involved. \nThe number of uses is statically known for straight line code and not known for assays with control flow. \nWhile volumes of fluids in most steps are known or are computable at compile time (e.g., the volume in \na mixture is in general the sum of volumes of the com\u00adponents and thermal expansion of fluids due to \nheating is usually too insignificant to alter volumes), there are exceptions that need online volume \nmeasurement. For instance, when mixing or heating alters the fluids chemical nature, or, more commonly, \nin the case of separations where the volume of the output is unknown at com\u00adpile time. Such exceptions \nare known to the compiler or assay writer, and we assume that the corresponding operation can be flagged \n(e.g., using an opcode variant) so that the volumes can be measured at run-time [3]. We discuss our proposed \nsolutions in three parts. First, we describe our DAG internal representation (Section 3.1) and our algorithms \nfor the statically-known case (Section 3.2-Section 3.3). Second, we present extensions to DAGSolve that \nhandle corner cases of in Section 3.4. Finally, we extend the base algorithms to support statically-unknown \ncases in Section 3.5. 3.1 Assay DAG Representation We represent an assays as a simple directed acyclic \ngraph (DAG) defined as follows. Nodes represent operations (typically input A, B, C K = mix A:B in ratio \n1:4  2/3 1/34/5 L = mix B:C in ratio 2:1 1/5 M = mix K:L in ratio 2:1 N = mix L:C in ratio 2:3 3/5 \n (a) 2/3 Figure 2: Assay DAG (b)  Representation volume-aggregating operations such as mixes) and \nedges represent true dependence among the operations. The edges are annotated with values to denote the \nratio in which the source fluids is used in the operation. Input nodes have no in-bound edges and final \noutput nodes have no outbound edges. Figure 2 shows a simple assay and its corresponding DAG. Because \nall fluid uses are known and because there are no unknown output volumes (relative to input) in the assay, \nthe DAG corresponds to the statically-known case. Assays with loops are also represented as DAGs whenever \nthe loops can be unrolled completely, as we see later. 3.2 Integer Volume Management (IVol) and ILP \nFormulation The problem of Integer Volume Management (IVol) is one of assigning volumes in integer multiples \nof least-count to the various uses of fluids to satisfy the assay constraints (mix ratios, number of \nuses) and the hardware constraints (maximum capacity and least\u00adcount). We have attempted to determine \nthe complexity of IVol and tried casting it as some well-known problems. For example, one may think that \nvolume management can be cast as a network flow problem. However, network flow problems have the key \nrequire\u00adment of flow conservation at intermediate nodes (i.e., the sum of all outputs of a node is equal \nto the sum of it s inputs), while in our case, each intermediate node potentially violates such requirement \nbecause all the produced fluid need not be used. We show later in Section 3.3 that imposing flow conservation \nstill does not make the problem amenable to casting as a network flow problem. As such, determining the \ncomplexity of IVol is left as an open question for future work. We show that IVol can be cast as an integer \nlinear programming problem (ILP). We describe the ILP formulation (constraints and objective function) \nin the context of our DAG representation (say G(V,E)). The variables representing the volumes in nodes \nand edges are subject to the following classes of constraints with the number of constraints for each \ntype shown parenthetically. (1) Minimum volume constraints ensure that no volume is smaller than the \nleast count (one constraint per edge, |E| constraints in all). In addition to the least count constraint, \nthere may be additional min\u00adimum volume constraints for fluid functional units (e.g. separa\u00adtors). (2) \nMaximum capacity constraints limit the sum of volumes assigned to edges entering a node to the node s \nhardware capacity (one constraint per node, |V| constraints in all). (3) Non-deficit con\u00adstraints ensure \nthat the use of a fluid (the sum of volumes of out\u00adbound edges) at a node does not exceed the volume \nof the fluid, which is the sum of volumes of inbound edges (one constraint for every non-output node, \n|V| constraints at most). (4) Ratio con\u00adstraints ensure that volumes of the inbound edges are in the \nspeci\u00adfied mix ratio (one constraint for each node corresponding to a mix, |V| constraints at most). \n(5) Relative node output to input, for nodes representing instructions such as separates, where the output \nvolume of a node is not necessarily equal to the sum of its inputs, Minimum/Maximum volRatio (assuming \nleast count < r,s,v,y all 1:1 ratios) least count < t,u,w,x r - s = 0 A,B,C < max vol t - u = 0 K (=r+s) \n< max vol v - w = 0 L(=t+u) < max vol x - y = 0 M (=v+w) < max vol N (=x+y) < max vol Non-Deficit v <= \nr + s Node output to input w + x <= t + u NULLr < = A Objective function s + t <= B Output to output \n10% f = sum(M,N) u + y <= C 0.9 N <= M M <= 1.1 N Figure 3: ILP formulation rather a relative fraction \nof the total input (one constraint for each node of the fractional output type, |V| constraints at most). \nThough any feasible volume assignment that satisfies the above constraints is adequate to remove underflow, \nwe set the objective function to maximize the sum of all output volumes to maximize the output production. \nIn some cases, the solution may be skewed to produce very little of one output fluid and much more of \nanother output fluid if such outputs maximize the sum of all output volumes. To avoid such skew, we add \none optional set of constraints called Rel\u00adative output-to-output constraints, where output volumes are \nset to be within a fixed percentage of each other (twice the number of constraints as output nodes, |V| \nconstraints at most). Note that for simplicity we bound the relative ratio of all outputs with respect \nto one output instead of bounding every possible pair which would result in O(V2) constraints). Figure \n3 shows the optimization func\u00adtion and set of constraints derived from the assay shown in Figure 2. One \ndrawback to using ILP to solve IVol is that ILP is NP-Hard. An alternate approach to solving IVol is \nto use LP (polyno\u00admial complexity) to provide a non-integer solution and then round the result to an \ninteger, which we call Rational Volume Manage\u00adment (RVol). One may think that practical ILP solvers are \nfast in practice and that the asymptotic worst-case complexity difference between ILP and LP may not \nnecessarily translate to execution time reduction for our specific problems at typical problem sizes. \nHowever, we show later in Section 4.3 that the ILP solver we used is significantly slower than the LP \nsolver for some of our bench\u00admarks. Simple rounding of the RVol results to the nearest integers may cause \ninaccuracies in mix ratios. Rounding up causes more input fluids to be consumed and rounding down causes \nless output fluids to be produced, both of which may lead to underflow. Fortunately, the underlying chemistry \nis inherently tolerant of small impreci\u00adsions in mix ratios, given that usual operating volumes are in \nthe order of nanoliters and the least count is in the order of picoliters. We did not observe such underflow \nproblems in practice and the errors for our benchmarks were below 2%. As such, we defer investigation \nof more sophisticated rounding techniques to the future. While the LP-based solution to the RVol problem \nis feasible, we make two observations to motivate a more efficient algorithm for RVol. First, while the \npolynomial execution time of LP-based RVol may seem tractable for compile-time volume assignment, volume \nassignment must occur at run-time for statically-unknown cases, as mentioned in Section 1. LP has worst-case \ncomplexity of O(n3L), where n is the number of variables and L is the number of bits in the binary representation \nof the variables [4]. Because worst-case asymptotic complexity may not be an accurate indica\u00adtor of practical \nexecution times, we show in Section 4.3 that LP can still be significantly slow for large assays. Second, \nas PLoCs become more widespread and their programmability matures, composition of assays will lead to \nlarger assays, resulting in a cor\u00adresponding increase in the input to the LP problem. Next we describe \nour linear-complexity RVol algorithm that overcomes the above problems.  3.3 DAGSolve To overcome the \nhigh complexity of our LP formulation to solve RVol, we make the key observation that, by adding some \narti\u00adficial constraints, the problem of fluid volume management can be solved in linear complexity, occasionally \nsacrificing a feasible solution that would be found by LP. To that end, we propose DAG-Solve, a linear \ntime algorithm for fluid volume management, and fall back on LP when DAGSolve fails to find a feasible \nvolume assignment. DAGSolve over-constrains RVol by adding the two following constraints. First, we constrain \nthe output volumes (say A, B and C) to be in some relative proportion to each other (say Va:Vb:Vc) while \nLP allows the outputs to be any volume. Note that this con\u00adstraint does not fix the absolute volume of \nany output. Second, whereas LP imposes only the non-deficit constraint that can cap\u00adture feasible solutions \nthat may have excess fluids, we add a no\u00adexcess, flow-conservation constraint as well. Effectively, the \nflow\u00adconservation constraint forces the generated volume for each inter\u00admediate fluid to be equal to \nthe total volume of its uses. Recall that the key distinction between the volume assignment problems \nand network flow problems was that flow conservation was not necessary in volume assignment. We reconsidered \nusing the network flow approach after artificially introducing flow con\u00adservation. Some aspects of the \nproblem, such as achieving a mix\u00adratio, can be expressed as multi-commodity network flow (MCNF) given \nabsolute volumes. However, our problem requires the com\u00adputation of absolute volumes from relative volumes. \nFurther, each node in an assay creates a new fluid (commodity) due to mixing, heating or similar alteration. \nTherefore, each commodity traverses a single level in our DAG, unlike MCNFs. As such, we did no pur\u00adsue \nthe network-flow approach. Our DAGSolve algorithm uses the above two additional set of constraints to \nreduce RVol to a simple propagation algorithm on the DAG. DAGSolve starts with the final relative output \nvolumes (the first additional constraint), then performs a backward pass on the DAG to assign relative \nvolumes to all nodes and edges, such that all the assay constraints (ratio constraints and relative output\u00adto-input \nconstraints) and the flow-conservation constraint (the sec\u00adond additional constraint) are satisfied. \nThen a forward pass assigns real absolute volumes which impose the hardware con\u00adstraints (least count \nand maximum capacity) on the solution. The pseudocode for the algorithm is shown in Figure 4. We define \na node s Vnorm as a measure of the fluid volume at the node relative to other nodes. Because Vnorm is \na relative mea\u00adsure, all nodes Vnorm value should be normalized to a common node or set of nodes. To \nthat end, we choose this set of nodes to be the output nodes (leaf nodes), and apply the first artificial \ncon\u00adstraint of setting all output nodes Vnorm = 1 (i.e., each output is normalized to itself and all \nthe output volumes are equal). Though the Vnorms could be set to arbitrary values to produce outputs \nin DAGSolve{ 1. Build DAG from assay  2. Set leaf nodes Vnorm to 1 and others to 0 //Vnorm calculation \n 3. foreach node N in reverse topol. order of DAG  4. foreach outbound edge E for N  5. N.V:= N.V \n+ E.V  norm normnorm 6. foreach inbound edge E for N  7. E.V := E.ratio * N.V  normnorm //Dispensing \n 8. Max_V:= maximum node V norm norm 9. foreach node N and edge E in DAG  10. N.volume := (N.V*max_default)/Max_V \n  normnorm 11. E.volume := (E.V*max_default)/Max_V normnorm }  Figure 4: DAGSolve Algorithm arbitrary \nratios without any other changes to the algorithm, unless we have information to prefer production of \none output fluid over another, we initialize all output volumes to be equal. Similarly, we define an \nedge s Vnorm as the volume of the fluid associated with the edge normalized to the volumes of the final \noutput fluids. Vnorm calculation proceeds in reverse topological order of the DAG and updates the values \nfor edges and nodes (Figure 4, lines 3-7). Each node is assigned a Vnorm equal to the sum of its outbound \nedges values (Figure 4, line 5) and then each inbound edge is updated as the product of the original \nedge value (the original ratio) and the node value (Figure 4, line 7). Note that setting each node s \nVnorm to the sum of the outbound edges values is our sec\u00adond artificial constraint requiring flow-conservation \nof fluids at intermediate nodes. Figure 5 shows the application of DAGSolve to the example given in Figure \n2. Node L is assigned 1/3 + 2/5 = 11/15 and edges B-L and C-L are updated as 2/3*11/15 = 22/45 and 1/3*11/15 \n= 11/ 45. Figure 5(a) shows the updated values for all the nodes and edges. A node s Vnorm may be less \nthan one (e.g., node K) or more (e.g., node B) depending on their relative volumes with respect to output \nvolume. The next step is to assign absolute volumes based on nodes Vnorm (Figure 4, lines 8-11) and the \nhardware constraints. To avoid overflow (i.e., to satisfy the maximum capacity constraint), we assign \nthe node with the largest Vnorm (node B in our example) a volume equal to the default machine-dependent \nmaximum (e.g., 100 nl). To ensure that the original ratios specified by the assay are honored, each other \nnode and edge is assigned a fraction of the default maximum equal to the ratio of its Vnorm to the largest \nVnorm (Figure 4, lines 10-11). Figure 5(b) shows the dispensed volumes for all the nodes and edges. If \nthe ratio of the largest Vnorm to a smallest Vnorm is less than the ratio of the default maximum to the \nleast count, the smallest BC A  A BC 52 48 24 2/15 13 K K 3/5 59 2/3 65 (a) M N (b) M N  Figure 5: \nDAGSolve Example Figure 6: Volume Management Flowchart Vnorm will underflow because its absolute volume \nwill be less than the least count. However, this failure in DAGSolve could be the result of the additional \nconstraints imposed by DAGSolve and does not imply that there is no feasible solution. An LP solver solving \nthe original LP formulation (Section 3.2) without the addi\u00adtional constraints could still discover a \nfeasible solution. Thus, we fall back on LP whenever our above approach leads to underflow. In comparison \nwith the worst-case O(n3L) complexity of LP, DAGSolve is of linear complexity as it visits each node \nand edge twice. Our results (Section 4) show that there is a significant dif\u00adference in execution time \n(~80x). Thus, the use of DAGSolve as a preferred technique that may sometimes fail combined with the \nbacking of a more robust, but slow LP solution can be viewed as a volume management hierarchy. One may \nthink that adding the same artificial constraints to the LP formulation may, in practice, increase the \nefficiency of LP. However, we show in Section 4.3 that while LP does benefit in some cases from the additional \ncon\u00adstraints, the gap between DAGSolve and LP (with additional con\u00adstraints) performance remains large \n(~60x). 3.4 Extensions to DAGSolve Recall from Section 1, some corner cases of extreme mix ratios or \nnumerous uses of a fluid may arise for which neither DAGSolve nor LP may produce feasible volume assignments. \nIn this section, we discuss two techniques that modify the DAG to address the above two problems. The \nmodified DAGs are re-processed through the same volume management hierarchy consisting of DAGSolve and \nLP. Figure 6 illustrates how the volume manage\u00adment hierarchy (on the left) interacts with our techniques \nto handle extreme mix ratios and numerous uses (on the right). We discuss extreme mix ratios first and \nnumerous uses next. 3.4.1 Handling Extreme Mix Ratios Cascading Mix ratios that exceed the ratio of \nthe least count to the maxi\u00admum hardware capacity are infeasible to execute, and defeat DAG-Solve, LP, \nand even regeneration. For instance, a mix ratio of A and B in a ratio of 1:1000, where the ratio of \nthe least count to maximum capacity is 1:100 would cause either (1) an underflow of A if we set the volume \nof B to the hardware maximum, or (2) an overflow of B if we set A as the least count. Such extreme ratios \nhave traditionally been handled by cascaded mixing where a desired mix ratio is achieved as a combination \nof two or more cas\u00adcaded mix operations, each of which has a less skewed mix ratio. For example, a single \nA-B mixture of 1:99 can be achieved by first mixing C= A-B in the ratio 1:9, followed by C-B in the ratio \nof 1:9. (It may be more intuitive to think of the above example as creating a 1-part-in-100-parts mix \nby first creating a 1-part-A-in-10-parts 1 9 1 99 9 1 9 excess Figure 7: Cascaded Mixing mixture (say \nC) and then creating another 1-part-C-in-10-parts final mixture). Observe that the above example creates \n10 parts of C and uses only 1 part which implies excess production, which is allowed in the LP formulation \n(non-deficit constraint in Section 3.2), but is expressly prohibited in the DAGSolve algo\u00adrithm due to \nthe flow conservation constraint. Without such excess production, cascading in DAGSolve would fail to \navoid underflow in case of extreme mix ratios. However, introducing a priori unknown excess production \nleads to unknown amount of discarded output which would prevent the direct backward computation of Vnorms \nfrom known output volumes. In contrast, LP can handle excess production because such unknown discarded \noutputs corre\u00adspond to independent slack variables in the LP formulation. Fortu\u00adnately, we make the key \nobservation that the fraction of the output volume to be discarded can always be computed a priori. In \nthe example above, we know that exactly 9/10 parts of C are dis\u00adcarded. Consequently, DAGSolve can incorporate \nthis special case of excess production. The DAG transformation for excess handling in the case of the \nexample is shown in Figure 7. We replace the original extreme-ratio mix node (C) with two cascaded mixes. \nAt the intermediate node of the cascade (C ), we add an excess node and an edge from the intermediate \nnode to the excess node that both have a Vnorm equal to 0.9*Vnorm(C ). DAGSolve is modified slightly \nto handle excess nodes as a special case. Unlike ordinary nodes/edges whose Vnorms are computed in a \nbackward pass, the Vnorms of the excess edge and excess node are computed after their source node s Vnorm \nis known. In general, we use cascading only if the assay has no feasible volume assignment with the direct \nmix, as shown in Figure 6, When an extreme mix ratio (say 1:R) prevents feasible volume assignment, we \napply cascading as follows. We initially attempt a cascade of two mixes, where each mix is equivalent \nto 1: R + 1 1 , and the amount discarded at the intermediate node is R +1 1/ R + 1. If one level of \ncascading is insufficient to   eliminate extreme mix ratios, we iteratively deepen the cascading by \nusing three mixes each equal to 1:3 R +1 1 and so on, until a suitable non-extreme mix-ratio is achieved. \nFinally, note that cas\u00adcading has the negative side-effects of increasing the demand on the PLoC s fluid-path \nresources (e.g., functional units and reser\u00advoirs), and of increasing the number of uses of the fluid \nwith the larger contribution in the original mix. (In the example in Figure 7, C requires an additional \nmix and uses of B increase to two from one.) In extreme cases, the increase of fluid uses due to cascading \nmay cause underflow, which may require static replication (Section 3.4.2) as a solution as shown in Figure \n6. While Biostream [10] also relies on allowing excess production for their mix instructions, their approach \nis fundamentally different from ours in that they allow mixing only in a 1:1 ratio, and discard half \nof the output of the mix while we allow variable volume (and ratio) mixes. Because of their fixed-ratio \nmixing, achieving arbi\u00adtrary mix ratios always requires cascading (except for 1:1 mixing), which executes \non the slow fluid path, while our approach requires cascading only for uncommon cases of extreme mix \nratios.  Finally, we note that though we allow cascading and excess production by default, there maybe \ncases where cascading mixes and producing/discarding excess fluid is disallowed because of safety, cost, \nregulation, or even correctness. For such fluids (identi\u00adfied by the programmer) we do not allow excess \nproduction. 3.4.2 Handling Numerous Uses Static Replication Because of the hardware limit of maximum \ncapacity, numerous uses of a fluid (naturally or induced by cascading) can cause underflow even if we \nproduce as much volume of the fluid without causing overflow. For such cases, where certain highly-used \nfluids must be produced in excess of hardware capacity, we employ static code replication to replicate \npart of the backward slice of the fluid s production. Various traditional compiler techniques for determining \nthe backward slice of a variable exist [11]. In our context, static replication of the backward slice \nachieves pro-active generation of fluid in excess of what a single reservoir can hold by creating multiple \ninstances of the same fluid. We repli\u00adcate the numerous-usage node and distribute the original outbound \nuses as evenly as possible between the replicas. Once replication is complete, we re-run DAGSolve to \nproduce new Vnorm values for the new graph. If an underflow still occurs, we replicate another level \nin the DAG, effectively replicating the predecessor-nodes predecessors. Replication continues in an iterative \nfashion until the underflow is eliminated. Because replication increases the demand on the PLoC s fluid-path \nresources (like cascading), the replicated code may exceed the PLoC s resources. In such cases, compilation \nfails. We follow this iterative procedure instead of one-shot repli\u00adcation of the entire backward slice \nbecause such one-shot replica\u00adtion may cause compilation failure even in cases where the iterative procedure \nsucceeds. Finally, note that static replication is merely a graph transformation, and the LP formulation \nmay be applied on the new DAG as well. Because our replication is static, the additional demand for fluid-path \nresources is known a priori and accounted for at com\u00adpile time. Thus, we can determine statically if \nthe modified DAG fits within the PLoC s resources, as shown in Figure 6. In contrast, Biostream s reactive \nregeneration places a run-time demand for the resources that cannot be planned for and thus, may be hard \nto sat\u00adisfy. Because cascading and static replication place extra demand on the resources, we fall back \non these two schemes as a final option to avoiding underflow, as shown in Figure 6.  3.5 Statically-Unknown \nCase Our volume management schemes so far assume that both the volumes output at every assay step and \nthe number of uses are known statically. However, either of these quantities may be known only at run \ntime, as discussed before. We extend DAG-Solve to handle each such uncertainty unknown volume first \nand unknown use next, and show how these alterations easily apply to LP. To handle statically-unknown \nvolumes, we delay the volume assignment step from compile time to run time while keeping Vnorm calculation \nat compile time to reduce run-time overhead. To compute Vnorm, we cut the outbound edges of the unknown-vol\u00adume \nnodes. Consequently, these nodes become similar to final out\u00adput nodes, while the sink of each cut edge \nbecomes similar to an input node. While the natural input nodes are unconstrained in that the input volumes \ncan be anything up to the default maximum, these artificial input nodes volumes are constrained to be \nequal to the output of the unknown-volume instruction, which is measured at run time. The edge cutting \nmay partition the DAG into several partitions to each of which we apply DAGSolve. While we calcu\u00adlate \nthe Vnorm of the nodes and edges of all the partitions as before, there is one difference in the final \nstep of absolute volume assign\u00adment (i.e., application of the hardware constraints) due to con\u00adstrained \ninputs. Assigning the default maximum to the node with the largest Vnorm may require more than the available \nvolume at a constrained input. To handle that case, we compute the minimum ratio of each input s Vnorm \nand the available input volume for each constrained input once the volume is measured. Consequently, \nnodes and edges are assigned volumes by scaling their Vnorm with this ratio. While the above method handles \nunknown-volume nodes, such nodes may prevent applying DAGSolve to normal, known-volume instructions. \nConsider the output of a normal, known-volume instruction, node X in Figure 8(a). Node X has two uses, \none of which transitively feeds an unknown-volume instruction (node U, shown as a hashed node). At the \ntime of X s execution U s execu\u00adtion has not even begun, and as such, U s outbound edge volumes cannot \nyet be determined. However, an earlier use of X (the X-Y edge in Figure 8(a)) needs to be assigned some \nvolume without waiting for the later unknown use. Thus, unknown-volume instruc\u00adtions prevent us from \nassigning volumes on the basis of transitive use. To handle this problem, we partition the DAG at compile \ntime by cutting the outbound edges of nodes that transitively lead to an unknown-volume node and marking \nthe edges as constrained inputs. As before, the known-volume instruction node is treated as if it were \na final output node, and we compute the Vnorm for the partitioned DAG. At run time, we divide conservatively \nthe known-volume instruction output into N equal portions, if there are N uses of the output fluid (here \nwe assume all the uses are known and handle unknown-uses next). We then apply the above method for constrained \ninputs to assign volumes. Figure 8(b) shows the DAG in Figure 8(a) after cutting Y-U and the outbound \nedges of X, with X , X , and U representing constrained inputs. X and X each get half the volume of \nX and U gets the run-time output of U. One slight refinement to the above conservative strategy is that \nif a partition gets more than one of the N uses, say m uses, then we can replace the m constrained inputs \n(of 1/N each) with a single con\u00adstrained input of m/N. Note that the above conservative strategy (including \nthe refine\u00adment) with its potential for underflow is needed only for the instructions whose transitive \nuse DAG includes unknown-volume instructions. All other instructions can be handled better via DAG-Solve. \nIf the programmer can provide hints on approximate output volume relative to input volume at the unknown-volume \ninstruc-  U  1/2 X 1/2 X U (a) (b)  Figure 8: Statically-unknown Case tion, the portion per use \ncan be adjusted accordingly instead of the default of equal portions across uses. In DAGSolve we model \nsuch a hint as a node whose output shrinks the input volume in the spec\u00adified ratio. We also note that \nsuch a node is trivially compatible with the LP formulation mentioned before. Next, we handle unknown \nuses, which occur due to control\u00adflow in the assay (if-then-else and loop constructs). To handle if\u00adthen-else, \nwe conservatively include both if and else paths in our DAG and apply DAGSolve (similar to standard dataflow \nanalyses in modern compilers). Loops with statically-known number of iter\u00adations can be unrolled that \nmany times and handled by DAGSolve. One may think that instead of unrolling, one could apply DAG-Solve \nto the body of the loop and then scale the input volumes by the number of iterations. However, if the \nloop has loop-carried dependencies where fluids from different iterations are mixed in ratios, such simple \nscaling will not work. For loops whose iterations are not known even at loop entry (e.g., while loops), \nthere are two options: (1) The programmer pro\u00advides a hint of the upper bound on the number of iterations \nfor a loop. We simply unroll the loop that many times and apply DAG-Solve. (2) While the programmer may \nnot know the number of iterations, she may know the minimum volumes that the loop should output for successful \ncompletion of the assay. These mini\u00admum volumes can be used in the case of loops with independent iterations. \nFor such loops, we make two changes to DAGSolve before applying it to the loop body. First, instead of \nassigning the largest Vnorm to the default maximum, we pick the output node with the smallest Vnorm and \nassign it the programmer-specified volume. All other nodes and edges are scaled as per the ratio of their \nVnorm and that of the chosen output node. This process gives us the volumes of the input fluids needed \nfor one iteration to pro\u00adduce the specified output volumes in that iteration. The assumption here is \nthat as much of the input fluids is produced as possible (over-provisioning may be achieved by static \nreplication), and each iteration takes as much as needed from this initial volume. This strategy, however, \nis a departure from DAGSolve where inter\u00admediate nodes produced only as much fluid as needed. Accord\u00adingly, \nthe second change is that we break up the assay at loops and treat nodes outputting fluids to loops as \nif they were final output nodes. Finally, the per-iteration input volumes are valid only if the loop \niterations are independent. In the presence of loop-carried dependencies, the specified output volumes \nwould be reached after multiple iterations and as such, input volumes cannot be calculated from one iteration \nas done above. For such loops, we fall back on the first option of the programmer specifying an upper \nbound on the number of iterations. Note that programmer-provided hints or bounds, could be from any source \nincluding, but not limited to, human expertise, profiling runs and prediction. While we have described \nour approach for handling the stati\u00adcally-unknown cases in DAGSolve, the same approach works if we need \nto use LP, by applying the same DAG transformations and adding the same constraints. Like DAGSolve, LP \ncan also reduce its run-time overhead by solving all but the constrained inputs at compile time and then \nincrementally solving the constrained inputs at run time. ASSAY glucose START fluid Glucose, Reagent, \nSample; fluid a, b, c, d, e; VAR Result[5]; a = MIX Glucose AND Reagent IN RATIOS 1 : 1 FOR 10; SENSE \nOPTICAL it INTO Result[1]; b = MIX Glucose AND Reagent IN RATIOS 1 : 2 FOR 10; SENSE OPTICAL it INTO \nResult[2]; c = MIX Glucose AND Reagent IN RATIOS 1 : 4 FOR 10; SENSE OPTICAL it INTO Result[3]; d = MIX \nGlucose AND Reagent IN RATIOS 1 : 8 FOR 10; SENSE OPTICAL it INTO Result[4]; e = MIX Sample AND Reagent \nIN RATIOS 1 : 1 FOR 10; SENSE OPTICAL it INTO Result[5]; END (a) glucose{ move mixer1, s2, 4 input s1, \nip1;Glucose mix mixer1, 10 input s2, ip2;Reagent move sensor2, mixer1 input s3, ip3;Sample sense.OD \nsensor2, Result3 move mixer1, s1, 1 move mixer1, s1, 1 move mixer1, s2, 8 move mixer1, s2, 1 mix mixer1, \n10 mix mixer1, 10 move sensor2, mixer1 move sensor2, mixer1 sense.OD sensor2, Result4 sense.OD sensor2, \nResult1 move mixer1, s3, 1 move mixer1, s1, 1 move mixer1, s2, 1 move mixer1, s2, 2 mix mixer1, 10 \nmix mixer1, 10 move sensor2, mixer1 move sensor2, mixer1 sense.OD sensor2, Result5 sense.OD sensor2, \nResult2  } (b) move mixer1, s1, 1 Figure 9: Glucose Assay  4 Results We evaluate our volume management \nscheme in two parts: (1) avoiding underflow in RVol using DAGSolve on some real-world assays and (2) \nthe error of our simple rounding. We also compare the execution times of DAGSolve and LP, and show the \nnumber of times regeneration is triggered assuming no volume management. We first describe the assays \nand our experimental infrastructure, and then present our results. 4.1 Infrastructure and Benchmarks \nWe define a simple high-level language to specify the assays. Our syntax is similar to the specification \nformat used in conven\u00adtional assays. We use the names of common operations (e.g., mix, separate, incubate) \nas key words which are accompanied by the relevant parameters such as operand fluids, temperature, and \ntime duration of operation. Figure 9(a) through Figure 11(a) show three assays written in our language. \nThe variable it corresponds to the output of the previous statement. We do not describe our language \nin any more detail due to space limitation. We construct a compiler to translate the high-level assays \ninto the AquaCore Instruction Set (AIS) (Section 2.1). The usual steps of parsing, intermediate repre\u00adsentation, \nregister allocation, and code generation are similar to those of a conventional compiler. We show the \ncompiler-generated AIS code in Figure 9(b) through Figure 11(b). Our compiler imple\u00adments DAGSolve (the \nstatically-known case) without cascading and replication which we perform manually. For LP, we use Mat\u00adlab \ns linprog command, which is based on LIPSOL (Linear Inte\u00adrior Point Solver) [14]. Figure 9 shows the \nsource and the AIS code for detecting the concentration level of glucose in a given sample using an optical \nsensor [9]. The assay uses a calibration step to obtain a best-fit curve of known amounts of dilutions \nof a standard glucose concen- ASSAY glycomics START fluid buffer1a, buffer1b, buffer2; --buffer2 has \nPNGanF fluid buffer3a, buffer3b, buffer4, buffer5; fluid sample, lectin, C_18, NaOH; fluid effluent,effluent2,effluent3, \nwaste,waste2,waste3; MIX buffer1a AND sample FOR 30; SEPARATE it MATRIX lectin USING buffer1b FOR 30 \nINTO effluent AND waste; MIX effluent AND buffer2 FOR 30; INCUBATE it AT 37 FOR 30; MIX it AND buffer3a \nIN RATIOS 1:10 FOR 30; LCSEPARATE it MATRIX C_18 USING buffer3b FOR 30 INTO effluent2 AND waste2; MIX \neffluent2 AND buffer4 AND NaOH IN RATIOS 1:100:1 FOR 30; MIX it AND buffer3a FOR 30; LCSEPARATE it MATRIX \nC_18 USING buffer3b FOR 2400 INTO effluent3 AND waste3; MIX effluent3 AND buffer5 FOR 30 (a) END glycomics{ \nmove heater1, mixer1 input s1, ip1 ;buffer1a incubate heater1, 37, 30 input s2, ip2 ;sample move mixer1, \nheater1, 1 input s3, ip3 ;lectin move mixer1, s6, 10 input s4, ip4 ;buffer1b mix mixer1, 30 input s5, \nip5 ;buffer2 move separator2.matrix, s7 input s6, ip6 ;buffer3a move separator2.pusher, s8 input s7, \nip7 ;C_18 move separator2, mixer1 input s8, ip8 ;buffer3b separate.LC separator2, 30 input s9, ip9 ;buffer4 \nmove mixer1,separator2.out1,1 input s10, ip10 ;NaOH move mixer1, s9, 100 input s11, ip11 ;buffer5 move \nmixer1, s10, 1 mix mixer1, 30 move mixer1, s1 move mixer1, s6 move mixer1, s2 mix mixer1, 30 mix mixer1, \n30 move separator2.matrix, s7 move separator1.matrix, s3 move separator2.pusher, s8 move separator1.pusher, \ns4 move separator2, mixer1 move separator1, mixer1 separate.LC separator2, 2400 separate.AF separator1, \n30 move mixer1,separator2.out1 move mixer1,separator2.out1 move mixer1, s11 move mixer1, s5 mix mixer1, \n30 (b) mix mixer1, 30 } Figure 10: Glycomics Assay tration. The sample s reading is placed on this \ncurve to obtain the concentration. The numbers in the move and mix instructions are the relative volumes \nand number of seconds of mixing, respec\u00adtively (as discussed in Section 2.1). Figure 10 shows the source \nand AIS code for a glycomics assay (study of sugar molecules in proteins) [7]. The assay first concen\u00adtrates \nthe proteins containing glycans (sugar molecules) by an affinity separation using lectin as the affinity \nmatrix. Then, the gly\u00adcans are cleaved from the proteins by mixing with a solution of PNGan F enzyme, \nand the extracted glycans are once more sepa\u00adrated from the proteins using liquid chromatography (we \nadd separate.LC to AIS for this purpose). To enhance future analy\u00adsis and measurements, the effluent \nis permethylated using sodium hydroxide. Finally, the effluent undergoes chromatography, mak\u00ading it ready \nfor external measurements such as mass spectrometry. Figure 11 shows an assay to study the impact of \ninhibitors on enzyme kinetics [5]. Four different dilutions of enzyme, substrate and inhibitor are created. \nThen, all combinations of the dilutions are mixed and incubated and the optical density is sensed. The \noptical sensor gives an indication of enzyme activity at that spe\u00adcific dilution, for that specific substrate, \nin the presence of that spe\u00adcific inhibitor dilution. Because the number of loop iterations are known \nat compile time, we fully unroll the loops. ASSAY enzyme_test START VAR inhibitor_diluent, enzyme_diluent, \nsubstrate_diluent; VAR i, j, k, temp, RESULT[4][4][4]; fluid Diluted_Inhibitor[4], Diluted_Enzyme[4]; \nfluid Diluted_Substrate[4]; fluid inhibitor, enzyme, diluent, substrate; inhibitor_diluent = 1; enzyme_diluent \n= 1; substrate_diluent = 1; temp = 1; FOR i FROM 1 TO 4 START --inhibitor Diluted_Inhibitor[i] = MIX \ninhibitor AND diluent IN RATIOS 1:inhibitor_diluent FOR 30; temp = temp * 10; inhibitor_diluent = temp \n- 1; ENDFOR temp = 1; FOR j FROM 1 TO 4 START --enzyme Diluted_Enzyme[j] = MIX enzyme AND diluent \n IN RATIOS 1:enzyme_diluent FOR 30; temp = temp * 10; enzyme_diluent = temp - 1;  ENDFOR temp = 1; \nFOR k FROM 1 TO 4 START --substrate Diluted_Substrate[k] = MIX substrate AND diluent IN RATIOS 1:substrate_diluent \nFOR 30; temp = temp * 10; substrate_diluent = temp - 1; ENDFOR FOR i FROM 1 TO 4 START --inhibitor FOR \nj FROM 1 TO 4 START --enzyme FOR k FROM 1 TO 4 START --substrate MIX Diluted_Inhibitor[i] AND Diluted_Enzyme[j] \nAND Diluted_Substrate[k] FOR 60; INCUBATE it AT 37 FOR 300; SENSE OPTICAL it INTO RESULT[i][j][k]; \n ENDFOR ENDFOR (a) ENDFOR END enzyme_test{ input s1, ip1;inhibitor input s2, ip2;diluent input s4, \nip3;enzyme input s6, ip4;substrate dry-mov inh_dil, 1 dry-mov enzyme_dil, 1 dry-mov subs_dil, 1 dry-mov \ntemp, 1 loop0: index i: 1->4 move mixer1, s1, 1 move mixer1, s2, inh_dil mix mixer1, 30 dry-mov r0, \ntemp dry-mul r0, 10 dry-mov temp, r0 dry-sub r0, 1 dry-mov inh_dil,r0 move s3(i), mixer1 dry-mov temp, \n1 loop1: index j:1->4 move mixer1, s4, 1 move mixer1, s2, enzyme_dil mix mixer1, 30 dry-mov r0, temp \ndry-mul r0, 10 dry-mov temp, r0 dry-sub r0, 1 dry-mov enzyme_dil, r0 move s5(j), mixer1 dry-mov temp, \n1 loop2: index k: 1->4 move mixer1, s6, 1 move mixer1, s2, subs_dil mix mixer1, 30 dry-mov r0, temp \ndry-mul r0, 10 dry-mov temp, r0 dry-sub r0, 1 dry-mov sub_dil,r0 move s7(k), mixer1 loop3: index i:1->4 \nloop4: index j:1->4 loop5: index k:1->4 move mixer1, s3(i) move mixer1, s5(j) move mixer1, s7(k) mix \nmixer1, 60 move heater1, mixer1 incubate heater1, 37, 300 move sensor2, heater1 dry-mov t4, i dry-mul \nt4, 16 dry-mov t5, j dry-mul t5, 4 (b) dry-add t5, t4 dry-mov t6, k dry-add t6, t5 sense.OD sensor2,RESULT(t6) \n} Figure 11: Enzyme Assay  4.2 DAGSolve s Solution Quality We evaluate DAGSolve on our benchmarks \nin terms of DAG\u00adSolve s goal of avoiding overflow and underflow. For all of our benchmarks, we assume \na default maximum of 100 nl. Recent results on polydimethylsiloxane (PDMS) valves (a common type of valve \nused in microfluidic devices) show that a least count of 100 pl is feasible [12].  The glucose assay \n(Figure 9) has five uses of the reagent, four of glucose and one of the sample. We show the DAG for this \nassay and the Vnorm generated by DAGSolve in Figure 12(a) and the actual volumes in Figure 12(b). The \nsmallest volume dispensed is 3.3 nl which is well above the least count. Because all the volumes and \nfluid uses are statically known, not only the Vnorm calculations but also the volume assignments occurs \nat compile time and thus, there is no run-time overhead for this assay. The glycomics assay (Figure 10) \nconsists of a sequence of mix and separate operations. Because the assay has three separations which \nproduce statically-unknown volumes (Section 3.5), DAG\u00adSolve s final volume assignment step is done at \nrun time. The DAG is partitioned at the unknown-volume nodes resulting in four partitions, as shown in \nFigure 13. Buffer 3a (in the second and third partitions) is used in two partitions and hence the correspond\u00ading \ninput node is split into two constrained-input nodes each of which gets half the default maximum (i.e., \n50 nl). The three nodes X1, X2, and X3 represent the constrained inputs corresponding to the unknown \nvolumes generated by the separates. Because the sep\u00adarate s output volumes are unknown, we show only \nthe Vnorm and not the final volumes. While most of the Vnorm are reasonably large numbers, the X2 input \nto the third partition has a Vnorm of 1/204 which may be a concern. If X2 s separation output volume \nin the second partition is high then there would be no underflow; other\u00adwise, we would need more of X2 \ns separation output, for which BioStream s regeneration would have to be triggered. Due to the unknown-volume \ninstructions, only the first parti\u00adtion s volumes may be computed at compile time, while the remaining \npartitions volumes must be calculated at run-time. We show later that the run-time overhead of this computation \nis a few milliseconds on a 750-MHz processor, and is acceptable given that fluidic instructions take \nseconds to execute. The enzyme assay (Figure 11), creates four different dilutions for each of the enzyme, \nsubstrate and inhibitor using the same dilu\u00adent. Thus, the diluent is used twelve times. All combinations \nof the resultant dilutions are mixed so that each dilution is used sixteen times. Because the DAG for \nthis assay is large and symmetric, we show only the enzyme-diluent part of the DAG in Figure 14(a). With \nthe output Vnorm set to 1, all the dilutions Vnorm equal 16/3 ~ 5.3 (the dilutions are the middle nodes \nin Figure 14(a) and each   x2 NaOH buf1a sample x1 x 3 buf2   buf5 buf4 buf3a / 50 buf3a / 50 \n Figure 13: Glycomics assay DAG dilution is used in 16 mixes in the ratio of 1:1:1). The maximum Vnorm \nis for the diluent fluid (Vnorm = 54). DAGSolve results in 9.8 nl for all the dilutions (Vnorm of 5.3 \nnormalized to the maximum Vnorm of 54 and scaled to 100 nl). Each dilution is split 16 times into 0.6 \nnl volumes to give the final volumes of 1.8 nl. One of the dilutions corresponds to the 1:999 mix of \nthe enzyme and diluent. As stated above, the dilution s volume is 9.8 nl and the enzyme input to the \nmix is 9.8 pl which is the minimum dispensing volume in this assay. While this dispense step under\u00adflows, \nall other steps dispense about 100 pl or more staying at or above the least count. The underflow is not \nsurprising considering (1) the extreme mix ratio of 1:999 used in this assay, and (2) the many uses of \nthe diluent fluid. In fact, we found that LP also fails to avoid this underflow. To address this underflow, \nwe apply the optimizations of cascading and static replication (Section 3.4). As we discuss below, both \noptimizations are needed to avoid the underflow because both problems of extreme ratios and many uses \nare there. We cascade each of the 1:999 mixes to three 1:9 mixes (shown in bold in Figure 14(b)). Each \nof the newly-created intermediate nodes is assigned a Vnorm of 16/3, equal to that of the original Diluent \n  Enzyme  Outputs  Dilutions (a)  extreme ratio node. For each cascaded mix, the diluent is used \ntwo more times (increasing the total number of uses from 12 to 18), and its Vnorm increases to 81. The \nunderflowing volume of 9.8 pl initially assigned to the 1:999 mix changes to 123 pl, correspond\u00ading to \nthe volume assigned to the 1:9 mix for the first node in the cascade. Though the initial underflow is \neliminated, there is a new underflow corresponding to the 1:99 mix ratio where the minimum dispensed \nvolume is 65.6 pl now. This underflow occurs due to the extreme mix ratio and due to the increased use \nof the diluent, and may be removed by increasing the diluent volume via static repli\u00adcation, or by cascading \nthe 1:99 mix. We first examine static repli\u00adcation and replicate the diluent input node three times so \nthat the problematic mix receives higher volume (similar to using three input instructions to three different \nreservoirs). Each replica is used in one set of dilutions one for enzyme, one for substrate, and one \nfor inhibitor. In this dilution, the diluent s Vnorm reduces by a factor of 3 from 81 with no replication \n(Figure 14(a)) to 81/3 = 27 with replication (Figure 14(b)). Accordingly, the minimum dis\u00adpensed volume \nincreases by a factor of 3 from 65.5 pl to 196 pl, eliminating all underflow in the assay. Note that \nbecause the dilu\u00adent s Vnorm is the maximum, reduction in the Vnorm results in increase in actual volumes \ndue to the inverse relationship of vol\u00adumes with the maximum Vnorm. We also tried the option of using \nreplication without cascading which resulted in underflow with the minimum dispensed volume of 29.5 pl \ncorresponding to the 1:999 mix ratio. Recall from Section 3.3 that DAGSolve (and LP) provide a solution \nto RVol. To achieve our initial goal of solving the IVol problem, we round the results of the rational \nvolume assignment to the closest integer multiple of the least-count. Such rounding did not cause any \noverflow/underflow for our assays. However, because such rounding can introduce errors in mix ratios, \nwe eval\u00aduate its effect on our benchmarks using a maximum volume of 100 nl and least count of 0.1 nl. \nAveraged across the glucose and enzyme assays, the error was no more than 2%. (We do not include rounding \nerror for the glycomics assay as the assay depends on statically unknown volume.)  4.3 Run Times Table \n2 shows the execution times of DAGSolve and LP, the number of constraints generated by LP, and the number \nof times regeneration is triggered assuming no volume management. Each execution time includes the processing \ntime of generating the con\u00adstraints from the internal DAG representation and for executing the algorithm \n(DAGSolve or LP). The execution times are from runs on a 750 MHz Intel PIII processor with 256 MB memory \n(each number is averaged over 10 runs to account for OS-related varia\u00adtions). For the glycomics assay, \nwe show the total run time of all the four partitions of the DAG (resulting from the statically unknown \nseparation steps in this assay). For our assays, while DAGSolve is about 80 times faster than LP, even \nLP takes less than one second. This run-time is acceptable not only for compile-time solvable assays \nbut also for run-time solutions like the glycomics assay which has separation steps with unknown volumes. \nThus, both schemes incur little overhead com\u00adpared to fluidic instruction execution times of several \nseconds. To explore DAGSolve s complexity advantage over LP, we increase the enzyme assay s problem size. \nInstead of four dilu\u00adtions, we perform ten dilutions for each of the enzyme, substrate Table 2: DAGSolve, \nLP, and Regeneration Assay DAG-Solve (s) LP (s) LP constraints Regen. count Glucose ~ 0 0.08 49 2 Glycomics \n0.003 0.28 84 -- Enzyme 0.016 0.73 872 85 Enzyme10 1.57 1211 11258 1313 and inhibitor. The results are \nshown under the assay name Enzyme10 in Table 2. LP s run time increases to more than 20 min\u00adutes, while \nDAGSolve remains under 2 seconds, confirming that DAGSolve scales better than LP for large problem sizes. \nThough the LP solution for this example can be computed at compile time, such overhead when incurred \nat run time would be significant, even if fluidic instructions take several seconds to execute. To eliminate \nthe possibility that the DAGSolve s speedups were solely due to the additional constraints, we evaluate \nthe effects of adding DAGSolve s additional constraints (flow conser\u00advation and output equalization) \nto the LP formulation. Though the additional constraints result in some improvement in LP s run time, \neven in the best case (glucose assay), LP remained signifi\u00adcantly slower than DAGSolve with a minimum \nslowdown of 60x (as compared to 80x without the additional constraints). Without volume management, regeneration \nis required twice for the simple glucose assay, and 85 times for the enzyme assay. With DAGSolve, there \nare no regenerations. The number of regen\u00aderations for the glycomics assay is not shown because the number \ndepends on the volume output at each separation. However, if the separation steps in glycomics produce \nlow volumes, then regenera\u00adtion may be required even with DAGSolve. Overall, our pro-active approach \nreduces the need for regeneration which executes on the slow fluidic path, and may require extra fluidic \nresources. Thus, our approach achieves low run-time overhead and low resource requirement for volume \nmanagement. Finally, we compare LP and ILP. For ILP, we used the integer mode for the Matlab extension \nof LP Solve 5.5 [1]. Though the ILP solver achieved similar execution times as the LP solver for the \nglucose assay, the ILP solver ran for hours without generating a solution for the enzyme assay, whereas \nthe LP solver completed in 0.73 seconds.   5 Conclusions We identified and addressed a practical issue, \nnamely, fluid vol\u00adume management, in programmable labs-on-a-chip (PLoC). Vol\u00adume management addresses \nthe problem that the use of a fluid depletes it and unless the given volume of a fluid is distributed \ncarefully among all its uses, execution may run out of the fluid before all its uses are complete. Additionally, \nfluid volumes should not overflow (i.e., exceed hardware capacity) or underflow (i.e., fall below hardware \nresolution). We showed that the problem can be formulated as a linear programming problem (LP). Because \nLP s complexity and slow execution times in practice may be a concern, we proposed another approach, \ncalled DAGSolve, which over-constrains the problem to achieve linear complexity while maintaining good \nsolution quality. We also proposed two optimiza\u00adtions, called cascading and static replication, to handle \ncases involving extreme mix ratios and numerous fluid uses which may defeat both LP and DAGSolve. We \nshowed that our techniques produce good solutions for some real-world assays while being faster than \nLP. Our techniques relieve the PLoC programmer from not only assay-specific details of mix ratios and \nnumber of uses but also low-level hardware details of maximum capacity and resolution. Our goal is to \nraise the level of abstraction in lab-on-a-chip tech\u00adnology as modern programming languages and compilers \nhave done for computer technology. Acknowledgments The authors would like to thank the anonymous reviewers \nfor their invaluable comments. This work is based in part upon work supported by the National Science \nFoundation (NSF) under Grant Numbers CCF-0726821 and CCF-0726694. This work was also supported in part \nby the Purdue Research Foundation (PRF). References [1] MILP LP_Solve 5.5, http://sourceforge.net/project/show\u00adfiles.php?group_id=145213. \n[2] A. M. Amin, M. Thottethodi, T. N. Vijaykumar, S. Wereley, and S. C. Jacobson. AquaCore: A Programmable \nArchitecture for Microfluidics. In Proceedings of the 34th ISCA, pages 254 265, 2007. [3] R. Go mez, \nR. Bashir, A. Sarikaya, M. Ladisch, J. Sturgis, J. Robinson, T. Geng, A. Bhunia, H. Apple, and S. Wereley. \nMicrofluidic Biochip for Impedance Spectroscopy of Biologi\u00adcal Species. Biomedical Microdevices, 3(3):201 \n209, 2001. [4] C. C. Gonzaga. An algorithm for solving linear programming programs in O(n3L) operations. \nIn Progress in Mathematical Programming Interior-point and related methods. Springer-Verlag New York, \nInc., 1988. [5] A. Hadd, D. Raymond, J. Halliwell, S. Jacobson, and J. Ramsey. Microchip Device for Performing \nEnzyme Assays. Analytical Chemistry, 69(17):3407 3412, 1997. [6] J. Janssen and H. Corporaal. Partitioned \nregister file for TTAs. In Proceedings of the 28th MICRO, pages 303 312, 1995. [7] Y. Mechref and M. \nNovotny. Structural Investigations of Gly\u00adcoconjugates at High Sensitivity. Chemical Reviews, 102(2):321 \n370, 2002. [8] N. Nguyen and S. Wereley. Fundamentals and Applications of Microfluidics. Artech House, \n2002. [9] V. Srinivasan, V. Pamula, M. Pollack, and R. Fair. A digital microfluidic biosensor for multianalyte \ndetection. In Proceed\u00adings of the 16th Annual IEEE International Conference on Mi\u00adcro Electro Mechanical \nSystems, pages 327 330, 2003. [10] W. Thies, J. P. Urbanski, T. Thorsen, and S. Amarasinghe. Abstraction \nlayers for scalable microfluidic biocomputing. Natural Computing, 2007. [11] F. Tip. A survey of program \nslicing techniques. Journal of pro\u00adgramming languages, 3:121 189, 1995. [12] M. A. Unger, H.-P. Chou, \nT. Thorsen, A. Scherer, and S. R. Quake. Monolithic Microfabricated Valves and Pumps by Multilayer Soft \nLithography. Science, 288(5463):113 116, 2000. [13] J. P. Urbanski, W. Thies, C. Rhodes, S. Amarasinghe, \nand T. Thorsen. Digital microfluidics using soft lithography. Lab on a Chip, 6(1):96 104, Jan 2006. \n[14] Y. Zhang. Solving large scale linear programs by interior point methods under the MATLAB environment. \nTechnical Report 96 01, Baltimore, MD 21228 5398, USA, 1996. \n\t\t\t", "proc_id": "1375581", "abstract": "<p>Microfluidics has enabled lab-on-a-chip technology to miniaturize and integrate biological and chemical analyses to a single chip comprising channels, valves, mixers, heaters, separators, and sensors. Recent papers have proposed programmable labs-on-a-chip as an alternative to traditional application-specific chips to reduce design effort, time, and cost. While these previous papers provide the basic support for programmability, this paper identifies and addresses a practical issue, namely, fluid volume management. Volume management addresses the problem that the use of a fluid depletes it and unless the given volume of a fluid is distributed carefully among all its uses, execution may run out of the fluid before all its uses are complete. Additionally, fluid volumes should not overflow (i.e., exceed hardware capacity) or underflow (i.e., fall below hardware resolution). We show that the problem can be formulated as a linear programming problem (LP). Because LP's complexity and slow execution times in practice may be a concern, we propose another approach, called DAGSolve, which over-constrains the problem to achieve linear complexity while maintaining good solution quality. We also propose two optimizations, called cascading and static replication, to handle cases involving extreme mix ratios and numerous fluid uses which may defeat both LP and DAGSolve. Using some real-world assays, we show that our techniques produce good solutions while being faster than LP.</p>", "authors": [{"name": "Ahmed M. Amin", "author_profile_id": "81331487785", "affiliation": "Purdue University, W. Lafayette, IN, USA", "person_id": "P1022741", "email_address": "", "orcid_id": ""}, {"name": "Mithuna Thottethodi", "author_profile_id": "81100433175", "affiliation": "Purdue University, W. Lafayette, IN, USA", "person_id": "P1022742", "email_address": "", "orcid_id": ""}, {"name": "T. N. Vijaykumar", "author_profile_id": "81100528323", "affiliation": "Purdue University, W. Lafayette, IN, USA", "person_id": "P1022743", "email_address": "", "orcid_id": ""}, {"name": "Steven Wereley", "author_profile_id": "81331507232", "affiliation": "Purdue University, W. Lafayette, IN, USA", "person_id": "P1022744", "email_address": "", "orcid_id": ""}, {"name": "Stephen C. Jacobson", "author_profile_id": "81410593324", "affiliation": "Indiana University, Bloomington, IN, USA", "person_id": "P1022745", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1375581.1375590", "year": "2008", "article_id": "1375590", "conference": "PLDI", "title": "Automatic volume management for programmable microfluidics", "url": "http://dl.acm.org/citation.cfm?id=1375590"}