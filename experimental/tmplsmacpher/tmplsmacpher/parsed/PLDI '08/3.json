{"article_publication_date": "06-07-2008", "fulltext": "\n A Study of Concurrent Real-Time Garbage Collectors Filip Pizlo * Erez Petrank Bjarne Steensgaard Purdue \nUniversity West Lafayette, IN 47907 pizlo@purdue.edu Microsoft Research One Microsoft Way Redmond, WA \n98052 Microsoft Research One Microsoft Way Redmond, WA 98052 erez@cs.technion.ac.il Bjarne.Steensgaard@microsoft.com \nAbstract Concurrent garbage collection is highly attractive for real-time sys\u00adtems, because of.oading \nthe collection effort from the executing threads allows faster response, allowing for extremely short \ndead\u00adlines at the microseconds level. Concurrent collectors also offer much better scalability over incremental \ncollectors. The main prob\u00adlem with concurrent real-time collectors is their complexity. The .rst concurrent \nreal-time garbage collector that can support .ne synchronization, STOPLESS, has recently been presented \nby Pizlo et al. In this paper, we propose two additional (and different) al\u00adgorithms for concurrent real-time \ngarbage collection: CLOVER and CHICKEN. Both collectors obtain reduced complexity over the .rst collector \nSTOPLESS, but need to trade a bene.t for it. We study the algorithmic strengths and weaknesses of CLOVER \nand CHICKEN and compare them to STOPLESS. Finally, we have implemented all three collectors on the Bartok \ncompiler and runtime for C# and we present measurements to compare their ef.ciency and responsive\u00adness. \nCategories and Subject Descriptors D.1.5 [Object-oriented Pro\u00adgramming]: Memory Management; D.3.3 [Language \nConstructs and Features]: Dynamic storage management; D.3.4 [Proces\u00adsors]: Memory management (garbage \ncollection); D.4.2 [Storage Management]: Garbage Collection General Terms Algorithms, Design, Performance, \nReliability 1. Introduction Garbage collectors automatically reclaim dynamically allocated objects when \nnot required by the program any more. Garbage col\u00adlection is widely acknowledged for supporting fast \ndevelopment of reliable and secure software. It has been incorporated into modern languages, such as \nJava and C#. An interesting question that arises is how to adapt garbage collection for real-time computation, \nwhere (high) responsiveness should be guaranteed, and (short) deadlines must be met. Traditional stop-the-world \ncollectors are not ade\u00adquate since a collection may take too long, preventing the program * Work done \nwhile the author was an intern at Microsoft Research. Work done while the author was on sabbatical leave \nfrom the Computer Science Dept., Technion, Haifa, Israel. Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to \nlists, requires prior speci.c permission and/or a fee. PLDI 08, June 7 13, 2008, Tucson, Arizona, USA. \nCopyright c . 2008 ACM 978-1-59593-860-2/08/06. . . $5.00 from responding on time. Concurrent mark-sweep \nand reference\u00adcounting collectors (e.g., [11, 13, 22, 1]) can be adapted to become real-time by taking \nspecial care of several issues, such as schedul\u00ading, triggering, stack-over.ow, etc. However, as these \ncollectors do not move objects, some programs may face bad fragmentation and run out of memory, thus \nfailing to meet deadlines. There seems to be an emerging consensus that some form of partial compaction \nmust be supported to obtain real-time memory management sup\u00adport. Historically, real-time compacting \ngarbage collectors start with Baker s proposed real-time collector [3]. Baker s collector was incremental \nand built for uniprocessors, meaning that the collector and the program threads ran on the same processor, \nalternating CPU usage over time. Two problems make this collector inadequate for modern systems. First, \nmultiprocessor support is becoming mandatory for modern applications even in the real-time space. Second, \nthe collector s share of the CPU is proportional to the program allocation rate therefore, if a program \nperformed a burst of allocations at a speci.c garbage collection phase, the program would have to yield \nalmost all of its CPU share to the garbage collector, causing an inevitable deadline miss. To solve this \nproblem, time-based collectors were proposed by Robertz and Henriksson [27]. In this setting, the collector \ndoes not get a share of the CPU when the program allocates. Instead, the collector is always entitled \nto a .xed constant fraction of the CPU time, and this fraction is computed according to the program allocation \nrate. A limit of around 50% for collector share of the CPU is typically used in modern real-time collectors \nsuch as IBM s Metronome [2]. However, the length of the collector scheduled quantum is required to be \nof substantial length (hundreds of mi\u00adcroseconds currently) and may need to grow when using very large \nscale parallel systems. This substantial collector quantum limits the ability to improve responsiveness. \nConcurrent collectors seem highly appealing for obtaining high responsiveness. As a concurrent collector \nruns on a different core (or processor) off-loading work from the program, the program may be able to \nmeet strict deadlines. However, concurrent collec\u00adtors that move objects (even non real-time) are quite \nrare [17, 18, 8]. Herlihy and Moss s lock-free collector [17] has an unbounded re\u00adsponse time and space \noverhead, and is thus inadequate for real\u00adtime support. Hudson and Moss [18] and Cheng and Blelloch [8] \npropose a elegant and ef.cient concurrent copying collector. How\u00adever, they require that either the program \nthreads use locks to syn\u00adchronize; otherwise, the collector introduces locks. Thus, they can\u00adnot support \na lock-free system. A .rst concurrent real-time garbage collection algorithm, STOPLESS, that supports \nlock-free parallel computation with .ne-grained synchronization was presented by Pizlo et al. [25]. STOPLESS \nobtains fast response times at the lev\u00adels of ten microseconds, improving drastically over response time \nprovided by previous technology. In this paper we propose two additional and different such col\u00adlectors: \nCHICKEN and CLOVER. CHICKEN and CLOVER are con\u00adcurrentandreal-timejustlike STOPLESS.Theyprovidecompaction \nsupport for dealing with fragmentation, they support lock-freedom and .ne-grained synchronization, and \nthey can deal with various memory models. The two new collectors are built on simple design ideas, and \nare less complicated than STOPLESS. However, the sim\u00adpli.cation comes with a cost and we discuss and \nstudy the trade\u00adoffs in this paper. Algorithms for real-time concurrent collection are only starting \nto appear and we believe that proposing more al\u00adgorithmic approaches and studying their relative performances \nand real-time guarantees is important for our understanding of real-time garbage collection. CHICKEN \nisbasedontheoptimisticassumptionthatthechances that the program will actually modify an object at the \nsame time that the collector is moving it are small. CHICKEN will work per\u00adfectly .ne when such a race \ndoes not happen and CHICKEN will be able to abort a move of an object gracefully when a race does hap\u00adpen. \nThe details of how the CHICKEN collector gracefully aborts a move are somewhat more complicated, and \nare explained in Sec. 4. While preserving lock-freedom, we maintain the invariant that all threads agree \non whether an object is copied or not, and all threads always use the correct copy of the object to load \nand store values. CLOVER uses a different approach. It does not block data races between the collector \nand the program threads. Instead it builds on an observation from probability theory. If one chooses \na value v uniformly at random from a space of 2\u00a3 values V , and if no infor\u00admation on this value is provided \nto a program P, then the probability that the program will store this value at any given store execution \nis 2-\u00a3. CLOVER starts by tossing coins to produce a random value. It then assumes that the program will \nnot store this value during its execution, and thus, this value can be used as a marker to mark a .eld \nas obsolete after it has been copied. CLOVER veri.es that the program indeed adheres to this assumption \nby putting a guard in a write barrier. In case the program does write the forbidden value, a lock needs \nto be used, and lock-freedom cannot be guaranteed any more. Note that correctness is always guaranteed, \nit is only lock-freedom that is lost with an extremely small probability. We discuss this strategy and \nmotivate the use of (well-founded) proba\u00adbilistic assumptions for memory management and systems at large \nin Sec. 2. We discuss, motivate, and compare the two new concurrent real-time garbage collector algorithms \nto each other and to the STOPLESS collector. In addition, we have implemented all three algorithms on \nBartok and we provide measurements to demonstrate and compare their performance. The contributions in \nthis paper include: 1. Presentation of the CHICKEN concurrent real-time collector. 2. Presentation of \nthe CLOVER concurrent real-time collector. 3. Introduction of rigorous probabilistic assumptions into \nsystems. 4. Comparison of the two algorithms to each other and to the STOPLESS collector of Pizlo et \nal. 5. Implementation and performance study of all three collectors (CHICKEN, CLOVER, and STOPLESS). \n We remark that although our algorithms can be used with hard real\u00adtime systems, our implementation \ndoes not currently support hard real-time. A discussion on the limitations of the implementation appears \nin Section 8. Organization. In Section 2 we motivate and discuss the ap\u00adproaches set forth by CLOVER \nand CHICKEN. In Section 4, we present the CHICKEN collector and in Section 5 we present the CLOVER collector. \nWe compare these two collector with the STO-PLESS collector in Section 7. The implementation details \nand mea\u00adsurements report appear in Sections 8 and 9. We discuss related work in Section 10 and conclude \nin Section 11. 2. Real-Time, Failure Probabilities, and Aborting a Copy Lest men suspect your tale untrue, \nKeep probability in view. John Gay Real-time guarantees seem to be at odds with aborting or fail\u00adure \nprobabilities. When handling real-time tasks, one expects the system to always be robust and predictable \nin the presence of worst case scenarios. However, this view of real-time systems is miscon\u00adceiving. A \ncomputer system cannot provide absolute guarantees. The major goal of a real-time system can be viewed \nas attempting to bring down the failure probability to an extremely low level. To realize that problems \ncan always happen, one can envision the list of problems that cannot be avoided. For example, the possibility \nof a bug in the software, of a hardware failure, of memory corrup\u00adtion, maybe one should also consider \nunexpected interrupts, page\u00adfaults, or just an odd behavior of the cache misses that may prevent a garbage \ncollector from .nishing on time. The list of inherently bad events goes on, but all these possible causes \nof failures happen with an extremely small probability. Typically, these bad cases are dismissed without \na rigorous computation of the small error proba\u00adbilities by which they occur. The reason for this lack \nof rigor is that it is not clear what the distribution space is. CLOVER has a small probability of failing \nto support lock\u00adfreedom. However, this failure probability can be well de.ned and computed (or bounded). \nThe actual distribution space and error probability computation will be speci.ed in Section 5, and they \ncan be made quite small with a proper design parameters. A philosophical question that rises is what \nprobability is small enough to be acceptable in real-time systems. Such a question cannot be scienti.cally \nanswered, but consider, for example, car accident statistics. Up-to-date statistics show that out of \nthe 301 million people living in the U.S. in July 2007, about 115 die every day in vehicle crashes. Assuming \nthat the accidents are uniformly distributed, any speci.c person dies every day with probability higher \nthan 1/300000 from a car crash. A hardware failure is much more likely. So is it enough that the program \nmeets its deadlines with such probability? CLOVER fails to remain lock-free with a much smaller probability \nof around 10-20. Arguably, this failure probability is negligible for all practical purposes. It is important \nto note that the failure probability is bounded independently of the input or of any other program run \ncharacteristics. Thus, for any possible run, and even a worst case one, only the coin tosses determine \nwhether lock-freedom cannot be guaranteed, and as long as these coin tosses are independent of the rest \nof the run, the low error probability is guaranteed. Aborting an object copy with CHICKEN is not as clean \nand rigorously analyzable as giving up lock-freedom in CLOVER. For CHICKEN lock-freedom is always guaranteed, \nbut it is not guaran\u00adteed that all objects marked for compaction will indeed be moved. With very small \nprobability CHICKEN will abort copying one or more of the objects. The problem is that such aborts may \nfoil at\u00adtempts to reduce fragmentation. The probability of aborting an ob\u00adject relocation cannot be rigorously \ncomputed, much like the proba\u00adbility of other system hazards that may occur. The probability of ac\u00adtually \naborting an object replacement with CHICKEN is extremely small as will be clear from the description \nof the algorithm in Sec\u00adtion 4. 3. Common Design Principles Several design features are common to all \ncollectors discussed in this paper, i.e., STOPLESS, CHICKEN, and CLOVER. We have at\u00adtempted to use a \nshared implementation of all common features so that the comparison becomes as accurate as possible. \nThe different parts in the implementation are exactly those in which the algo\u00adrithms differ between the \nthree collectors. All collectors run concurrently with the program threads on a separate processor (or \ncore). The description focuses on the use of two collector threads, one for compaction and one for the \nmark\u00adsweep reclamation. The framework can be easily extended into run\u00adning additional concurrent collector \nthreads by adopting a work dis\u00adtribution mechanism that is known in the art, such as the one in [4]. \nThe three compacting collectors discussed in this paper are em\u00adbarrassingly parallel because each object \nis copied independently of any other object. Such an extension was not required with the machines we \nused for our measurements (8 cores), but will be re\u00adquired for scalability with a larger number of cores. \nWe assume in this work that the collectors operate on spare processors. Thus, complicated scheduling \nissues that often appear with uniprocessors do not arise. The only question that needs to be addressed \nis how many collectors must be run concurrently, so that they can always cope with the program threads \nallocation pace. This number can be computed using formulas developed in prior art see [24, 2]. All three \ncollectors employ the same ef.cient lock-free on-the\u00ad.y mark-sweep collector to reclaim objects concurrently. \nIt is the same as was used for STOPLESS [25]. All three collectors use par\u00adtial compaction infrequently \nto reduce fragmentation. The main al\u00adgorithmic challenge is in designing the real-time concurrent com\u00adpacting \ncollectors. It is also the compaction that introduces the highest overheads. Our study concentrates on \nthree different com\u00adpaction mechanisms. The objects to be moved can be selected using any criteria on \nfragmentation that one may envision. In previous work, objects have been evacuated out of scarcely populated \npages, and we follow that idea in our implementation. The objects to be moved are marked for moving before \nthe concurrent compaction begins. We denote the original copy of the object the from-space copy and we \ndenote by to-space the copied object in the new loca\u00adtion. A soft handshake (similar to [25]) is used \nto communicate the phases of the collector to the program threads and make them use the appropriate memory \nbarriers for the phase. The path specializa\u00adtion method that was used with STOPLESS is also employed \nwith the two new collectors to reduce the overhead of the read barri\u00aders substantially and allow proper \ncomparison. A new method for incremental lock-free stack scanning, that reduces the pauses in\u00adcurred \nby stack scanning, has been developed for the new collectors but its description is beyond the scope \nof this paper. Other compo\u00adnents such as arraylets [8] are known in the art and outside the focus of \nthis paper. All three collectors support lock-freedom. They allow the pro\u00adgram threads to cooperate via \nshared memory; they never use locks; and they never make a program thread wait for the collector more \nthan a small and bounded number of steps. Loosely speaking, lock-freedom ensures that if some of the \nthreads are held up and delayed for any reason, the rest of the threads can still make progress. The \nrequirement is that there ex\u00adists a bound \u00a3 such that after the program threads make \u00a3 steps collectively, \none of them must make progress. Lock-freedom elim\u00adinates the danger of deadlocks and livelocks, it provides \nimmunity to other threads failures, it ensures robust performance even when faced with arbitrary thread \ndelays, and it prevents priority inver\u00adsion (in which a higher priority thread waits for a lock held \nby a lower priority thread). And last but not least, it allows scalable per\u00adformance due to .ne-grained \nsynchronization. Wait-freedom is an even stronger guarantee ensuring that any thread that makes \u00a3 steps, \nmakes progress. We next move to describing the two new methods for real\u00adtime concurrent compaction of \nthe heap. We will also overview the existing STOPLESS collector that we compare to.  4. The CHICKEN \nCollector Both optimists and pessimists contribute to our society. The optimist invents the airplane \nand the pessimist the para\u00ad chute. Gil Stern 4.1 An Overview CHICKEN allows both the collector and the \nprogram threads to exploit an optimistic assumption about program behavior to gain raw speed as well \nas real-time guarantees that are unprecedented for a concurrent copying collector. The optimistic assumption \nis that the program threads are unlikely to modify objects marked for copying during the brief window \nduring which those objects are copied; if the assumption does not hold, copying is aborted for the affected \nobjects. With this assumption in hand, we design an algorithm in which reading and writing are cheap \nwait free operations, while the algorithm responsible for performing the copy is allowed to be mostly \nimpervious to concurrent program activity. 4.2 Main Design Points The main design points of the algorithm \nfollow. Objects are copied as a whole. In contrast to STOPLESS mov\u00ading of objects .eld-by-.eld from the \noriginal to the new location, CHICKEN completely copies an object to its new location and then lets all \nprogram threads switch to working on the new location. (The only exception is arrays, for which each \narraylet is copied in\u00addependently.) Thus, either the from-space object contains the most up-to-date state, \nor the to-space does. This property is useful for read performance, as it allows .eld reads to be implemented \nusing a simple wait-free Brooks-style barrier, rather than the heavier bar\u00adriersof STOPLESS or CLOVER.Theseothercollectorsrequirereads \nto do per-.eld checks to see where the latest version of a .eld is such a check in practice requires \nmore indirection than the Brooks barrier. Writing is a wait-free operation. When a program thread is \nabout to write to an object, it asserts that either the object is fully copied (in which case it can \nwrite to to-space) or it is not tagged for copy\u00ading at all (in which case it can write to from-space). \nIf the object is in neither state, then our optimistic assumption did not hold. In this special case, \ncopying is aborted for that object. Aborting is im\u00adplemented using a compare-and-swap, which can only \nfail if some other thread already aborted the copying process for this object, or if the copier completed \ncopying. Thus, the write barrier always completes in a constant number of steps, making it wait-free. \nA soft-handshake occurs before copying starts. Each object that the collector means to copy is tagged \nbefore the soft-handshake is initiated. The collector does not proceed with copying until all threads \nacknowledge the initiation of a compaction phase. This has an important implication. After successfully \naborting object copy\u00ading, a program thread may assume that the object will not be copied until the next \ncompaction runs; furthermore, a new compaction will not start until the program thread acknowledges a \nhandshake. Thus, writes to the from-space location of an object, whose copying process was aborted, are \nsafe. The copying process is wait-free. Objects are .ipped from from\u00adspace to to-space individually. \nWhen the copier has copied all .elds T read<T>(object o, int offset) {return *(o->header.forward + offset); \n} Figure 1. CHICKEN read barrier. void write<T>(object o, int offset, T value) {if (o->header.tagged) \n// slow path CAS(o->header, Header(forward=o, tagged=true) . Header(forward=o, tagged=false)); // fast \npath *(o->header.forward + offset) = value; } Figure 2. CHICKEN write barrier. void copy(object o) {o->header.tagged \n= true; InitiateHandshake(); WaitForAllThreads(); object copy = AllocToSpace(sizeof(o)); memcpy(copy, \no, sizeof(o)); if (CAS(o->header, Header(forward=o, tagged=true) . Header(forward=copy, tagged=false))) \nFixup(); } Figure 3. CHICKEN copying algorithm. For clarity of presentation, we show a simpli.ed copying \nalgorithm, which only copies one object. In practical implementations, this algorithm would be extended \nto copy as many objects as required. of an object to to-space, it asserts that the object is still tagged; \nif so, the object is .ipped by installing a forwarding pointer in from\u00adspace that refers to to-space. \nThis assert-and-.ip is implemented using a compare-and-swap instruction on the same word that holds the \ntag. The assertion fails (that is, the object is no longer tagged) only if the copying is aborted by \nsome program thread. In this case, the to-space copy is discarded. Thus if a program thread writes to \nan object before the copier .ips it, it clears the tag and the object is not copied; otherwise the object \nis copied and the program threads write to and read from to-space thereafter. To summarize, CHICKEN requires \nonly a Brooks-style read barrier and a wait-free aborting write barrier that in the fast path only requires \na read operation and a branch followed by the original write operation. The sections that follow provide \nadditional details about the algorithm: Section 4.3 describes the object model and Section 4.4 speci.es \nthe details of the algorithms used for reading, writing, and copying. 4.3 The Object Model CHICKEN requires \nthat one pointer-sized word be added to each object s header, as shown in Fig. 4(a). This word is used \nfor a forwarding pointer (to facilitate a Brooks-style read barrier) and a tagged bit. Objects are always \nallocated with the forwarding pointer referring to the object itself, and the tagged bit being set to \nzero indicating that the object is not tagged for copying. The .rst step to copying is to toggle the \ntagged bit, as shown in Fig. 4(b). Copying completes with the tagged bit being toggled back and the forwarding \npointer being made to refer to the to-space object copy, as seen in see Fig. 4(c).  4.4 CHICKEN Pseudocode \nFor the mutator, CHICKEN is designed to allow high-speed heap accesses even during concurrent copying \nactivity. Meanwhile, CHICKEN copyies the contents of the object into to-space. Fig. 1 shows the read \nbarrier. Note that this is a standard Brooks-style read barrier; the only possible source of additional \noverhead is masking off the tagged bit. Fig. 2 shows the write barrier. The write barrier ensures that \nthe mutator only writes to the object if the object is either not tagged for copying, or it is already \nfully copied. As discussed before, this brings up a possible race between the collector thread that attempts \nto copy the object, and the program thread that wants to mark the original version of the object unmoveable \nbefore modifying it. This race is settled by a CAS operation on the word that contains the forwarding \npointer and the tag bit. The copier prepares a copy of the object concurrently, in the hope that no thread \nwill modify it during the creation of the replica. When the new copy is ready, the copier performs a \nCAS to atomically change the self-pointer into a forwarding pointer and clear the tag bit simultaneously. \nAtomicity is crucial, because at the same time, the program thread may attempt to perform a CAS on the \nsame word if it is about to modify a .eld in the object. The write barrier in Fig. 2 speci.es the action \nto be taken with each write during the moving phase. If the tag bit is clear, then the object is either \nalready copied or is not meant to be copied at all. In that case, no race is expected and the forwarding \npointer can be used to access the relevant object and .eld. Otherwise, the object is about to be moved \nand the program thread needs to mark it unmoveable by clearing the tag bit and keeping the self-pointer. \nNote that this modi.cation of the header word must be executed with a CAS. Indeed, a simple store will \nmark the correct tag and pointer, but it may occur after the copier has executed its CAS, and other threads \nmay be already using the new copy. The CAS makes sure that the header word still contains a self-pointer \nand a set tagged bit while changing it into the unmoveable value. After executing the CAS, the program \nthread does not care if the CAS execution was successful, or the copier has modi.ed the header word earlier \nto point to the new object, or another program thread has marked the object unmoveable. In all these \ncases, the pointer in the header properly references the object copy that should be accessed and that \nwill not be moved during the current collection cycle. In the explanation above, we assumed a strong \nCAS, i.e., one that only fails if a concurrent execution of a CAS on the same word succeeds. Such a CAS \nis provided by the cmpxchg instruction on x86 as well as a method in both the C# and Java 1.5 standard \nlibraries. It can be easily emulated using either LL/SC or a weak CAS on platforms that do not support \nstrong CAS natively. On the fast path, this barrier requires a load (to load the header word), a branch \n(to check that the tagged bit is not set), and the ac\u00adtual write operation. On the slow path, an interlocked \ncompare-and\u00adswap operation is required. It is interesting to note that the branch that guards the CAS \nis strictly a throughput optimization the CAS already performs the same check as the branch; as such \nit may be worthwhile for implementors interested more in predictability than throughput to omit the branch. \nEven on the slow path, both reading and writing are wait-free operations. Application compare-and-swap \noperations are supported by a designated CAS barrier that extends the standard write barrier. For CAS \noperations that involve primitive types, the store at the end of the write barrier simply needs to be \nreplaced with the CAS  Figure 4. CHICKEN object states. On the left, (a) illustrates the neutral state \nof an object. In (b) we show the object being copied. Finally, (c) shows the object after copying completes. \nitself. CAS operations that deal with object pointers are slightly complicated by the need to rede.ne \nequality. Indeed, STOPLESS, CLOVER, and CHICKEN all have equality barriers that rede.ne a==b such that \nit returns true even if a is a from-space pointer and b is a to-space pointer to the same object (or \nvise-versa). CAS on objects must be rede.ned in a similar manner, resulting in a lock\u00adfree, rather than \nwait-free CAS implementation. Copying under CHICKEN is shown in Figure 3. For simplicity of presentation \nwe present the code for copying a single object and we discuss the extension to multiple objects later. \nThe .rst step of copying is to tag the object we wish to copy. Next we initiate a soft handshake and \nwait for all threads to acknowledge this ensures that no write barriers that observed the object as being \nuntagged be\u00adfore copy() began end up performing the write while the object s contents are being copied. \nOnce all threads acknowledge the hand\u00adshake, the to-space copy is allocated and the contents are copied \nusing a regular memcpy operation. Once this completes the object is .ipped by asserting that it is still \ntagged, and if so, forwarding it to the to-space copy. If the .ip is successful, we ask the collector \nto .xup the heap by replacing any references to the from-space object with references to the to-space \ncopy. Extending to multiple objects presents a trade-off. The simplest extension is to perform the operation \ndescribed in Figure 3 for each copied object. However, this implies a handshake per object, which delays \nthe collector and creates an additional overhead for the pro\u00adgram threads. (Regardless, the .xup should \nbe invoked only once between compaction cycles.) The other extreme is to run a loop to tag all objects, \nthen execute a single handshake, and then execute all object copying. This extreme only requires one \nhandshake and is a simple and reasonable choice, which we have used in our im\u00adplementation. However, \nthis choice extends the window of time in which aborts can happen. In between the two extremes, one can \nrun a handshake per copying of a predetermined space quota. For ex\u00adample, one can tag objects for an \naccumulated size of s kilobytes, perform a handshake and relocate these objects. Then repeat for the \nnext s kilobytes and so forth.  4.5 Heap Fixup After compaction .nishes, the mutator will only access \nto-space but from-space pointers may still exist both in the heap and in the roots. For the collector \nto be able to safely discard from-space objects, all from-space pointers must be replaced by to-space \npoint\u00aders. Our strategy is to leverage the existing mark algorithm. After compaction, we trigger the \ncollector to run a mark-sweep cycle; during the mark cycle all pointers in the roots and in the heap \nare replaced by their to-space variants. The sweep phase then reclaims all from-space memory. Just as \nduring other collector activities, there is the risk of un\u00adwanted behavior due to concurrent mutator \nactivity. In this case, while heap .xup is running, the mutator may read as-yet un\u00adforwarded from-space \nreferences from the heap. We have two solutions either rerun root .xup after heap .xup, or have the object \nread<object>(object o, int offset) {object result = *(o->header.forward + offset); if (result!=null) \nresult=result->header.forward; return result; } Figure 5. CHICKEN eager read barrier. object tracePtr(object \no, int offset) { while (true) {object oldPtr = *(o + offset); object newPtr = oldPtr->header.forward; \nif (oldPtr == newPtr) return oldPtr; if (CAS(o + offset, oldPtr . newPtr)) return newPtr; }} Figure 6. \nFunction used by collector to access a pointer in an object during tracing. Pointers are updated if they \nrefer to from-space using a CAS loop that avoids losing concurrent mutator writes. mutator use an eager \nread barrier for reads of object references. In an eager read barrier, references are forwarded before \nbeing placed in a local variable. Note that .xing up a pointer is executed with a CAS to make sure that \nthe .x-up does not race with the mutator on changing a pointer .eld. Such a race may result in a inappropri\u00adate \n.x of a different pointer than the one attempted by the .x-up procedure. Fig. 5 shows an example CHICKEN \nread barrier specialized for object references, in which both the object being loaded from as well as \nthe value loaded are forwarded. Mutator writes can likewise interfere with heap .xup: if the mu\u00adtator \nwrites a new value into a .eld as the collector is installing an updated pointer in that .eld, there \nis the risk that the mutator s write will be lost. Our implementation avoids this problem by having the \ncollector update pointers using a simple CAS-based transaction that ensures that an updated pointer can \nonly be installed if doing so does not change the logical value of the pointer .eld. The algo\u00adrithm used \nby our collector to trace pointers during the .xup phase is shown in Fig. 6. 4.6 CHICKEN Summary CHICKEN \nis designed for speed. Readingand writing donot require synchronization operations like compare-and-swap, \nexcept in the write slow path. Both reads and writes are wait-free in the worst case. Application compare-and-swap \noperations are lock-free. The copier itself is light-weight, fast, and highly parallelizable: the copying \ntask(s) can safely ignore concurrent mutator activity right up until the point where the copy operation \nis committed by .ipping the object. The .ip is a wait-free operation. However, this high performance \ncomes at a cost: there is no guarantee that a particular object selected for relocation will actually \nbe relocated. Indeed, it is possible for some hot objects to not be relocated in any copying cycle. \n5. The CLOVER Collector What does chance ever do for us? William Paley In this section we introduce the \nCLOVER collector. This collec\u00adtor builds on the fact that random arbitrary events seldom happen and furthermore, \nwe can analyze the probability of things going wrong. In CLOVER, if things go wrong, at worst a program \nthread will block but the program will still behave correctly. CLOVER fails to support lock-freedom with \nnegligible probability. We stress that this negligible probability depends on random coin tosses made \nby the collector during the execution and not on the input or any other property of the execution. Namely, \nthere is no bad input or bad execution that cannot be handled. The advantage of CLOVER over CHICKEN is \nthat it always relocates objects marked for relo\u00adcation; relocation is never aborted. The advantage of \nCLOVER over STOPLESS is that it is simpler and has a lower time and space over\u00adhead. The drawback of \nCLOVER is that it may fail to support lock\u00adfreedom, although such failure occurs with negligible probability. \n5.1 An Overview The main challenge for real-time concurrent collectors is that they need to relocate \nobjects while the program threads are accessing them. At some point, the program threads should .ip from \naccess\u00ading the old copy of the .eld into accessing the new copy. It is not acceptable to stop the threads \nsimultaneously to make sure they all switch their target memory accesses simultaneously. So some means \nmust be used to ensure that all threads switch to working with the new version simultaneously. If not \nproperly handled, one thread will write to the old version while another reads from the new version and \nthe memory model will not be properly kept. This problem was solved in the CHICKEN design by not allowing \nany access to an object while two copies of it exist in the system. Any suchaccessrenderedthenewcopyunusable. \nSTOPLESS usedaspe\u00adcial intermediate copy for each relocated object. The intermediate object was larger \nthan the original object and additional .elds were used to synchronize all accesses to all three object \ncopies (original, intermediate, and new version) during the relocation. The basic idea undelying the \nCLOVER collector is to toss a random value a and assume the program is never going to write this value \nto the heap.1 The chances that a random value of 64 bits will be ever written to the heap by an application \nis negligible, as will be discussed later. Now that CLOVER holds this magical value, it can use it to \nblock accesses to a .eld of the original object. When CLOVER wants to switch the accesses of all threads \nfrom the old version of a .eld to a new version of it, it installs an a into the old .eld. This is done \natomically using a CAS instruction. When a program thread sees an a in a .eld, it knows that this .eld \nis obsolete and its value should be accessed in the object s to-space version. What remains is to handle \nthe unfortunate case that the appli\u00adcation does write an a unexpectedly. As this event happens with 1 \nThe a value may in practice be selected on a per-.eld, per-object, per\u00adphase, or per-execution basis. \nIn our implementation we choose it on a per-execution basis, which is the straightforward choice. The \ndifference between the alternatives is only relevant for an actively adversarial program that attempts \nto break the system and determine a. We do not insist on real-time support for such attackers. such low \nprobability, a simple solution is to just ignore it. The pro\u00adgram may fail to run correctly, but the \nprobability of this failure is smaller than hardware corruption, which we normally ignore. We choose \na more aesthetic solution in which the write-barrier guards against this event. Whenever the program \nthread tries to write the randomly selected a value, the barrier blocks the application until the copying \nphase terminates. Thus, correctness is always guaran\u00adteed, but the lock-freedom guarantee may be lost \nwith negligible probability. The details are provided below. 5.2 Supporting Lock-Freedom with High Probability \nConsider the following hypothetical system in which each heap .eld has a special value which we will \ncall a reserved for a concurrent copying collector. The program is guaranteed to never use a. Instead, \nif a is stored into a .eld it means that the .eld has been relocated to the new to-space copy of the \nobject. Given this simplifying assumption, it is easy to design a non-blocking copying concurrent collector. \nvoid copyField<T>( object from, int offset) { while (true) {T value = *(from + offset); *(from->forward \n+ offset) = value; if (CAS(from + offset, value . a)) break; }} T read<T>(object o, int offset) {T value \n= *(o + offset); if (value == a) return *(o->forward + offset); else return value; } void write<T>(object \no, int offset, T value) {if (value == a) WaitUntilCopyingEnds(); while (true) { T old = *(o + offset); \nif (old == a) { *(o->forward + offset) = value; break; } else if (CAS(o + offset, old . value)) break; \n}} Figure 7. Pseudo-code for CLOVER. The problem is that systems do not normally provide such guarantees, \nunless special hardware is designed (e.g., to contain an extra bit per .eld for this purpose). For heap \npointers .eld, one can easily pick an a that is never used2, and probably also for IEE 754 .oating point \nvalues3. But this will not work for integers in most modern languages in C# and Java, an int must be \n32-bit, and a long must be 64-bit; there is no way to make the program avoid any speci.c value. CLOVER \noffers an innovative solution for obtaining such an a by employing randomness it picks a random number \nto serve as a. CLOVER will atomically install a into an original .eld to 2 Because of alignment rules, \na valid heap pointer is guaranteed to be a multiple of 4 on most platforms so a could just be any pointer-width \ninteger that is not a multiple of 4. 3 NaN can be represented using any bit sequence in which the fraction \nis non-zero. Thus, if we have the power to pick a single representation of NaN in the heap, we can use \nany of the other representations as a). signify the relocation of this .eld into to-space. Thus, the \nmaximum possible length of a, N, can be set to the maximum number of contiguous bits that an be set atomically \nby a CAS on the target architecture. Because a is picked at random, it is unlikely that the mutator will \nuse a for its own purposes; for example, on the modern x64 architecture, N = 128; thus, the probability \nof a program thread writing the same a that CLOVER picksinamemory write is 2-128. The probability of \nthis event occurring is equal to tossing a biased coin 128 times independently and seeing it land on \nits face each and every time. Just to appreciate the scarity of this event, consider running this experiment \nagain and again every nanosecond since the beginning of the universe (the big bang) until now. We would \nstill have a tiny probability of about 2-40 to actually observe all coins facing the same predetermined \nside 128 times in one of these experiments. For systems supporting a CAS of 64 bits only, we would get \na probability of 2-64, which is still amazingly small, and signi.cantly smaller than any known estimate \non the probability of encountering a hardware failure. One important fact from probability theory should \nbe high\u00adlighted. If the coins are tossed uniformly and independently at ran\u00addom, then an execution will \nwrite an a with probability exactly 2-128 at each memory write, no matter how the program behaves. This \nis correct even for malicious programs, as long as they are given no information about a, i.e., a is \ntossed independently of the program execution. Informally, if the execution is independent of the choice \nof a, then there is no way any memory write can hit a with probability that exceeds 2-128. The pseudo \ncode of CLOVER is shown in Figure 7. The copying is described for a given object to relocate and a given \naddress for relocation. All to-space locations are always pre-initialized with as. The copier copies \nthe value of the .eld into the to-space area and then installs an a into the original location. Upon \nfailure (due to program use of this .eld) the relocation is retried. Note that although the program never \nhas to wait for the collector (except for a small bounded number of steps), the collector may be delayed \nby program activity. Conditions can be paused on program execution and scheduler fairness to guarantee \ncollector progress. A more algorithmic (and involved) way to deal with progress guarantee exists, but \nis omitted from this short version of the paper. The write barrier detects when the user is about to \nstore an a and blocks him from doing so until copying completes. All writes are executed using CASes \nduring the copying phase. The barriers presented thus far are heavy and slow. Reading requires a read \nand a branch in the best case. Writing requires two branches (one to check that we re not writing an \na and another to check if the from-space contains a), a read, and a write in the best case. Such barriers \nwill pose a large throughput overhead in practice. To solve this drawback, we employ barriers that can \nbe disabled when they are not needed for example during phases of execution when there is no concurrent \ncopying activity. Similarly to STOPLESS and CHICKEN, soft handshakes are used to avoid stopping all the \nprogram threads simultaneously when switching between the three different phases. However, when using \nsoft handshakes, the operation of parallel program threads is not always fully synchronized. Namely, \nduring a transition from one phase to another, some threads may start operating in the new phase while \nthe remaining threads are still operating in the previous phase. Special care is taken to make sure that \nthe barriers are properly coordinating program and collector activity in spite of this partial synchronization. \nThe full CLOVER algorithm proceeds through three phases: idle, prep, copy. Each phase has slightly different \nbarriers: Barriers are disabled in the idle phase. The prep phase acts as a buffer between idle and \ncopy. In prep we use a write barrier that is designed for compatibity with both the idle and the copy \nphases.  The copy phase uses the barriers presented in Figure 7.  See Figure 8 for the prep phase write \nbarrier. If from-space contains an a, the prep write barrier cannot write to to-space since if other \nthreads are still in the idle phase, the write would be invisible to them. Thus, if from-space contains \na, the modi.ed write barrier checks if the system has already progressed into the copy phase; if so, \nit proceeds using the usual logic; otherwise, it blocks until the transition into the copy phase is complete. \nNote that the code will only wait for the copy phase if from-space contained a user a value since if \nthe a was installed by the collector, the current phase would already be copy. void write<T>(object o, \nint offset, T value) { if (value == a) WaitUntilCopyingEnds(); while (true) { T old = *(o + offset); \nif (old == a) { HandShakeCooperate(); if (phase != copy ) WaitUntilCopyPhase(); restart write barrier \nin copy phase; } else if (CAS(o + offset, old . value)) break; }} Figure 8. CLOVER write barrier used \nin the prep phase.  6. An Overview over STOPLESS STOPLESS [25] was the .rst practical concurrent compactor \nto sup\u00adport .ne-grained synchronization. STOPLESS is not designed to rely on chance instead it works \nhard to ensure that all objects that were tagged for copying are in fact copied, and that no mu\u00adtator \nthread will ever block on a heap access. The main insight of STOPLESS is the use of a temporary, expanded \nobject model to store copy status information see Fig. 9. Copying is performed by .rst copying between \nthe from-space object and the expanded object, and then by copying out of the expanded object and into \nthe to-space object. During each phase of copying, either the source or destination has an adjacent status \n.eld; this allows the use of a double-word compare-and-swap to both access the data in the ex\u00adpanded \nobject .eld and assert its status. As in CLOVER, phasing is used to carefully enable and disable barriers. \nSTOPLESS delivers high throughput when there is no copying activity, and allows the mutator threads to \nkeep running without pauses while copying activity is on-going. Accessing the heap is deterministically \nlock-free, but requires the use of heavy and complicated barriers. Although the program never needs to \nwait for the collector, the STOPLESS copier does not have a progress guarantee. In a small probability \nworst-case race scenario, repeated writes to a .eld in the expanded object may cause the copier to be \npostponed inde.nitely. STOPLESS works hard to ensure that all objects get copied, but under pathological \ncases (such as multiple simultaneous mutator writes to the same .eld during entry into the compaction \nphase) an object may not get copied. 7. Properties of the Three Collectors We have presented CHICKEN \nand CLOVER; as well, we have re\u00adviewedthebasicdesignof STOPLESS.Thesethreeconcurrentcom\u00ad Figure 9. STOPLESS \nexpanded object. pacting algorithms provide different timeliness and progress guar\u00adantees. Differences \nexist in the way that the mutator accesses the heap, the handling of object copy aborting, and the termination \nof the compaction process. Let us discuss these differences explicitly before presenting measurements. \nHeap access. All three algorithms aim to provide lock-free heap access, but subtle differences exist \nin how strong this guarantee is, and how much work the mutator has to do to safely access the heap. CHICKEN \nis by far the most mutator-friendly algorithm all heap accesses are wait-free with the exception of compare-and-swap \non object .elds, which is lock-free. On the other hand, CLOVER and STOPLESS can at best only provide \nlock-free writes, and reads re\u00adquire branching. In the worst case, CLOVER will perform the worst of these \ncollectors: a heap write may be stalled until compaction completes however this will only happen with \na very low proba\u00adbility. CLOVER s heap access algorithms are simpler to implement than the ones in STOPLESS, \nand can achieve better performance in practice. Aborting. CLOVER never aborts object copying except if \nit is speci.cally requested by the user through a pin operation, for ex\u00adample using the C# fixed statement. \nSTOPLESS may abort ob\u00adject copying in the rare case that multiple mutator threads write to the same .eld \nsimultaneously during entry into the compaction phase. CHICKEN aborts object copying very eagerly no \nwrites to the heap are allowed unless the object is not copied at all or fully copied, with aborting \nused to guarantee the former condition if the latter does not hold. Termination. CHICKEN s compaction \nphase is guaranteed to complete, but it may not copy all objects. CLOVER does not have a termination \nguarantee for the simple version presented above. CLOVERhas a more complex version that can provide a \nprogress guarantee, however, it is outside the scope of this conference sub\u00admission. This version will \nguarantee termination, while also guar\u00adanteeing that all objects are copied. STOPLESS does not have a \ntermination guarantee. It is noteworthy how the algorithms do not differ. They all provide lock-free \nobject allocation, they all support .ne-grained synchronization, and all require only minimal changes \nto a mark\u00adsweep collector to be fully integrated with it. As well, all three collectors give the mutator \na logically higher priority than the collector in the case of concurrent accesses to the same data: the \ncollector cannot cause the mutator to spend unbounded time in a barrier.  8. Implementation To compare \nSTOPLESS, CHICKEN, and CLOVER, we have imple\u00admented them all in the Bartok system. The Bartok system \nconsists of a compiler and a runtime system. The compiler can be con.g\u00adured to insert different kinds \nof read-and write-barriers in the gen\u00aderated code. Similarly, the runtime system can be con.gured to \nuti\u00adlize different kinds of garbage collector algorithms. The compiler performs ahead-of-time compilation \nfrom the CIL byte-code format [15] to stand-alone executable .les. For the pur\u00adposes of evaluation, the \nsystem is being used in a con.guration that generates Intel x86 machine code programs. All three concurrent \nreal-time collectors have been con.gured to use the same concurrent mark-sweep collector as in [25]. \nThe mark-sweep collector follows ideas from [12, 11, 13], where the reference write-barrier ensures that \nan unmarked (white) object is marked gray when a reference to the object is overwritten. Alloca\u00adtion \nis also lock free except when the user did not correctly con.g\u00adure the collector for a given application \ns allocation rate. All three concurrent copying collectors share a common mech\u00adanism for choosing the \nset of objects to relocate. For the purposes of evaluating the relative performance of the different \ncollectors, a very simple scheme that is often used with partially compacting collectors has been adopted. \nEntire memory pages that .t evacua\u00adtion criteria less than 50% occupancy are tagged. At most 10% of all \nin-use memory pages are chosen for relocation. Compaction is not necessarily invoked in every garbage \ncollection cycle; for evaluation purposes, we invoke compaction every 5 garbage col\u00adlection cycles. Instead \nof operating within a pre-determined arti.cial heap size limit, the garbage collectors are permitted \nto use as much mem\u00adory as they deem necessary. Garbage collection cycles are started according to an \nadaptive triggering mechanism that is based upon current heap size and allocation rate. For evaluation \npurposes, the concurrent copying collectors all use the same triggering mecha\u00adnism. The read-and write-barriers \nemployed by the concurrent collec\u00adtors have different behavior according to which phase the garbage collector \nis in. To reduce the overhead of the barriers in the presence of this phase behavior, an optimization \ncalled path-specialization is used for all the garbage collectors. Path-specialization creates ver\u00adsions \nof the code that are specialized for being executed in speci.c subsets of phases. Code is inserted to \nensure that control .ow is transferred to the appropriate version of the code. Each collector has a set \nof barrier methods that are used when the object reloca\u00adtion mechanism is idle and another set of barrier \nmethods for when the object relocation mechanism is active. While our current implementation features \ngood real-time re\u00adsponsiveness on the benchmarks that are available to us, it should be noted that our \ncurrent system does not provably meet hard real\u00adtime guarantees. This is in part because our implementation \nis lack\u00ading certain features known to be required for a fully robust real-time garbage collector, and \nin part because we have not analyzed our collectors performance to the extent that would be necessary \nto classify them as hard real-time. In particular, we have not imple\u00admented features such as arraylets, \nstacklets, or priority boosting. Arraylets and stacklets allow for better bounds on large object al\u00adlocation \nand scanning of large stacks, respectively. Priority boost\u00ading is needed to guarantee that threads reach \nsafepoints in a timely manner. If we knew how fast our collector performs all of its key functions marking, \nsweeping, and copying then we could pro\u00advide users with a formula for picking tuning parameters such \nthat the collector always keeps up. We leave these issues to future work. In addition to all the above, \nstrict hard real-time systems may re\u00adquire a veri.cation of the garbage collection code, which is notori\u00adously \ndif.cult to achieve, and poses some open problems. 9. Measurements The test programs used for this evaluation \nare summarized in Ta\u00adble 1. We translated the JBB program from Java into C#. In our previous work [25], \nwe used a different translation of JBB into C#, which, according to the available porting notes, had \nseveral scalable data structures replaced with non-scalable ones. Our new JBB port Benchmark Types Methods \nInstructions Objects Allocated KB Allocated Description sat 24 260 19,332 8,161,270 171,764 SAT satis.ability \nprogram. lcsc 1,268 6,080 403,976 8,202,479 426,729 A C# front end written in C#. zing 155 1,088 23,356 \n12,889,118 928,609 A model-checking tool. Bartok 1,272 8,987 297,498 434,401,361 11,339,320 The Bartok \ncompiler. go 362 447 145,803 17,904,648 714,042 The commonly seen Go playing program. othello 7 20 843 \n640,647 15,809 The commonly seen Othello program. xlisp 194 556 18,561 125,487,736 2,012,723 The commonly \nseen lisp implementation. crafty 154 340 40,233 1,794,677 217,794 Crafty chess program translated to \nC#. JBB 65 506 20,445 501,847,561 54,637,095 JBB ported to C#. Table 1. Benchmark programs used for \nperformance comparisons. does not, to our knowledge, have this problem, as we were careful to pick the \nbest C# equivalents for the Java classes used by JBB. All measurements have been performed on an Intel \nSupermicro X7D88 dual x86 quad-core workstation running Microsoft Win\u00addows Server 2003 R2 Enterprise \nx64 Edition at 2.66GHz with 16GB RAM. We performed measurements for collector con.gurations where the \nobject relocation mechanism was activated every 5 garbage col\u00adlection cycles. For each non-JBB program, \neach con.guration was run once in sequence, and the sequence was repeated a total of 5 times. The JBB \nprogram was only run once for each con.guration. When error bars are present in graphs, they represent \na 95% con.\u00addence interval. The memory barriers used by our collectors impose an overhead on the test \nprograms. To characterize this overhead, we measured the throughput of the programs with the three different \ncollectors and compared it to the throughput of a system that reclaims garbage using the base-line mark-sweep \nnon-compacting concurrent collec\u00adtor. For the non-JBB programs, the relative execution time numbers are \nshown in Figure 10. For the JBB program, the JBB transactions per second for various numbers of warehouses \nunder various col\u00adlectors are shown in Figure 11. Typically, the CLOVER collector generally imposes less \noverhead than does the STOPLESS collec\u00adtor, and the CHICKEN collector imposes less overhead than do both \nthe STOPLESS and CLOVER collectors. Figure 11. Scalability of JBB for different collectors. Higher num\u00adbers \nmean more transactions per second, which indicates better per\u00adformance. The STOPLESS, CHICKEN, and CLOVER \ncollectors were all de\u00adsigned to be able to support real-time applications that have re\u00adquirements of \nextremely short response times. In other words, the collectors must exhibit extremely short pause times \nand allow ap\u00adplications to remain responsive during any and all garbage collec\u00adtion phases. To demonstrate \nthis, we repeated the responsiveness measurements of Pizlo et al. [25]. A test program .res events at \na rate of 108KHz (simulating the frequency of high quality audio samples) and a computation must end \nbefore the next event .res. The test was run with three different computation tasks and with varying \nspeci.ed sizes. The IntCopy task copies a speci.ed num\u00adber of integer values in an array. The test attempts \nto copy 256, 128, or 64 integer values. The RefCopy task copies a speci.ed number of reference values \nin an array, invoking the reference write barrier of a collector. The RefStress task is similar to the \nRefCopy task, but the program has another thread that repeatedly allocates (and releases) a 400MB data \nstructure involving over a million objects. The measurement results for all three collectors as well \nas for the non-copying base-line collector are shown in Table 2. As ex\u00adpected,thetwonewcollectors CHICKEN \nand CLOVER performbet\u00adter than the previous STOPLESS collector. The non-copying collec\u00adtor is performing \nbest as expected, but CHICKEN is able to consis\u00adtently handle the copying of 256 reference values at \na frequency of 108KHz, even in the presence of high rate concurrent allocations. The STOPLESS and CLOVER \ncollectors are unable to consistently complete this task at such high rate when concurrent stressing \nallo\u00adcations are run, because of their heavier barriers. However, they are able to consistently complete \nthe smaller task of copying 64 values. The Windows Server operating system, on which we implemented our \ncollectors, is not a real-time operating system, and we ran our System Size Task Done Missed High non-copy \n256 IntCopy 99.997% 0.001% 115\u00b5s RefCopy 99.996% 0.001% 47\u00b5s IntStress 99.995% 0.002% 128\u00b5s RefStress \n99.991% 0.006% 67\u00b5s STOPLESS 256 IntCopy 99.997% 0.001% 51\u00b5s RefCopy 99.995% 0.002% 49\u00b5s IntStress 5.357% \n49.758% 134\u00b5s RefStress 11.304% 53.861% 145\u00b5s CLOVER 256 IntCopy 99.997% 0.001% 53\u00b5s RefCopy 99.996% \n0.002% 49\u00b5s IntStress 25.766% 38.579% 95\u00b5s RefStress 11.227% 62.448% 132\u00b5s CHICKEN 256 IntCopy 99.997% \n0.001% 67\u00b5s RefCopy 99.994% 0.003% 56\u00b5s IntStress 99.991% 0.003% 118\u00b5s RefStress 99.978% 0.012% 117\u00b5s \nSTOPLESS 128 IntStress 4.777% 92.308% 68\u00b5s RefStress 92.371% 7.072% 110\u00b5s CLOVER 128 IntStress 46.280% \n49.759% 92\u00b5s RefStress 98.246% 1.589% 97\u00b5s STOPLESS 64 IntStress 99.973% 0.015% 135\u00b5s RefStress 99.980% \n0.010% 108\u00b5s CLOVER 64 IntStress 99.980% 0.011% 112\u00b5s RefStress 99.969% 0.012% 99\u00b5s Table 2. Indicators \nof overall responsiveness for various garbage collectors for an event frequency of 108KHz. The IntCopy \nand RefCopy tasks involve copying a number of integer and reference values, respectively. The Stress \nversions of the tasks adds another thread that repeatedly allocates and releases a 400MB data structure \ninvolving over a million objects. test on a Windows Server s standard running environment. There\u00adfore \na 100% on-time response should not be expected. The program we used to measure responsiveness is roughly \nsim\u00adilar to the HighFrequencyTask used to illustrate the responsiveness of Eventrons [28]. Our test program \ntries to perform a larger (and quanti.able) amount of work for each event than does the HighFre\u00adquencyTask. \nThe task used by our test program can be considered somewhat equivalent to a non-null Eventron. Figure \n12 shows his\u00adtograms for the concurrent garbage collectors of the times between when a timer indicated \nthat the task should be commenced and when the task was actually completed. The histogram shows that \nconcurrent collectors support programs that require extremely short response times. The histogram has \ntwo peaks. One is at around 1 microseconds, which represents the time it takes to perform the task when \nthe garbage collector is in the idle phase. The other peak is at 3 microseconds for CLOVER and 4 microseconds \nfor STOP-LESS and represents the time it takes to perform the task when the garbage collector is in a \nnon-idle phase. For CHICKEN the task is completed at around 1 microsecond even in the non-idle phase. \nIt is not possible to make a direct comparison between the results presented here and those from [28] \nbecause the tests are run on different machines and different underlying operating systems. However, \nthe results of the garbage collected environment with our compacting collectors seem at the very least \ncomparable to the non\u00adgarbage-collected environment in that paper. A support for events that occur in \nsuch high frequency has not been reported in the literature before. The STOPLESS and CHICKEN collectors \nmay both fail to relo\u00adcate objects that have been chosen for relocation. The failure to re\u00adlocate an \nobject may defeat the purpose of relocating any number of Figure 12. Histogram of how long after an event \noccurred the scheduled task was completed. The task was to copy 64 reference values in the presence of \na competing allocating thread (RefStress). The events were scheduled to occur every 9.26\u00b5s, which is \nroughly equivalent to a frequency of 108KHz. Tasks may be started late due to a previous task running \nlate. Tasks not started prior to the start of the next event were skipped. Figure 13. The rate of failure \nof the STOPLESS and CHICKEN collectors to relocate an object that has been chosen for relocation. Smaller \nnumbers are desirable. other objects, and is therefore clearly undesirable. We measured the failure rate \nof attempted object relocations for both the STOPLESS and CHICKEN collectors, where the CHICKEN collector \nis run in a worst-case (most aborting) mode in which all objects are copied with a single handshake. \nIf a failure to relocate defeats the purpose of relocating additional objects (for example if the collector \ndesired to have an entire page evacuated), then we count those additional objects as also having failed. \nThe results are shown in Figure 13. As expected, the CHICKEN collector in its worst-case mode suffers \nfrom a higher copying aborting rate than does the STOPLESS col\u00adlector. Another cause of failure is the \none for CLOVER in which the program uses the a value that is randomly chosen by CLOVER. We have not witnessed \nthat happening in the runs we made, and we do not expect such an event to happen during one s lifetime. \nNo relevant measurements can be made. We also ran responsiveness experiments based on the JBB benchmark. \nJBB transactions normally run for about a millisecond. For our highly responsive collector, this does \nnot pose a respon\u00adsiveness challenge. It is noteworthy that this represents a different class of real-time \napplication than what we are targetting we are more interested in systems that deal with much shorter \ntimescales. On timescales that are substantially below a millisecond, collector pauses such as those \nseen in previous real time garbage collection work would be disastrous; it is exactly in those cases \nthat we see the greatest bene.t to our approaches. When dealing with millisec\u00adond timescales, collectors \nwith sub-millisecond pauses are likely to perform as well as or even better than the techniques we are \nproposing, in much the same way that a well tuned stop-the-world non-real-time collector will outperform \nany real time garbage col\u00adlector in a long timescale throughput test. Nevertheless, the results in Figure \n14 are interesting. Since different transactions run in different phases of the collector run, they demonstrate \nvarious la\u00adtencies, showing the overhead of the slow paths of the barriers. As expected, there are no \ntransactions that take extremely long to execute. CHICKEN the fastest of our copying collectors has a \nvery narrow distribution of transaction times with a maximum of 1ms.4 CLOVER has a worst case of 3ms \nwhile STOPLESS is a bit worse, with a worst case of 5ms. In Figure 14(a) we show the performance of the \nstop-the-world mark-sweep collector for comparison. Since JBB triggers many collections, there is a good \nchance that some transactions will take signi.cantly longer than normal in the worst case we see 70ms. \nIn our tests of other stop\u00adthe-world collectors for example, our generational collector we saw results \nthat were generally worse in the worst case than the mark-sweep collector. Compaction Measuring the effects \nof compaction is currently dif.cult. The standard benchmarks run well without any com\u00adpaction and therefore \nthe non-copying method always does better. Our experience with commercial long-running large applications \nshows that fragmentation does develop over time and requires some sort of compaction. However, no such \nbenchmark is openly avail\u00adable for measurement publication. With real-time garbage collec\u00adtion, there \nis an apparent consensus that a worst-case fragmentation problem must be handled. We believe this consensus \nis just and we adhere to it by providing support for partial compaction upon need. However, like previous \npublications, we cannot provide supporting measurements to demonstrate the necessity of compaction for \nthe run. Compaction should be considered a mean that is seldom used, and not one that must be used continuously \nwith program run. 10. Related Work An incremental copying collector with short pauses was .rst pro\u00adposed \nby Baker [3]. This collector was designed for a single threaded program running on a uniprocessor. Baker \nused a work\u00adbased scheduling of garbage-collection work which was later found to consume a large fraction \nof the CPU time at some phases, lead\u00ading the program to a practical halt. Henriksson and Roberts [16, \n27] and Bacon et al. [2] cut the overheads by using a Brook style [7] read barrier. Bacon et al. proposed \nto use a time-based scheduling of the collector, letting the collector and program thread alternate usage \nof CPU time (on a uniprocessor). Cheng and Blelloch [5, 8] designed and implemented a concur\u00adrent copying \ngarbage collection with a bounded response time for modern platforms. They have also introduced the minimum \nmu\u00adtator utilization measure (MMU) to verify that the collector does 4 This performance is identical \nto our non-copying concurrent mark-sweep collector. Hence, with CHICKEN there is no measurable overhead \nto copy\u00ading in this test. not use up the CPU time when the program is supposed to use it. The Sapphire \ncollector [18] is a concurrent copying collector for Java. Sapphire achieves low overhead and short pauses. \nHowever, both collectors are targeted at high level programs that make little (or no) use of .ne-grained \nsynchronization. They both employ a blocking mechanism in the write-barrier while relocating volatile \nvariables. Thus, Sapphire and the Cheng-Blelloch collectors can\u00adnot not support lock-free programs. In \nparticular, if the collector is preempted, program threads may need to block and wait until it resumes. \nThe Metronome is a real-time garbage collector [2] for Java, which serves IBM s WebSphere Real-time Java \nVirtual Machine. The Metronome employs a Brook-style barrier and a time-based collection scheduling to \nobtain consistently high mutator utiliza\u00adtion. To avoid fragmentation at a reasonable cost, mark-sweep \nis used with an occasional partial compaction. The Metronome does not currently support multiprocessing \nor atomic operations. It ob\u00adtains pauses around the millisecond, which is two degrees of mag\u00adnitude higher \nthan the pauses obtained by the concurrent collectors presented in this paper. Herlihy and Moss described \nthe .rst mechanism for lock-free copying garbage collection [17]. However, their time and space overhead \nwould be prohibitive for use in modern high performance systems. Recently, the STOPLESS collector was \nproposed by Pizlo et al. [25]. As far as we know, this is the .rst collector that provides real-time \nguarantees, concurrency, and support for lock-free pro\u00adgram that employ .ne-grained synchronization. \nSTOPLESS reports pauses at the levels of microseconds. In this paper, we provide two alternative real-time \nconcurrent collectors that reduce the overhead of STOPLESS, and provide unprecedented short and predictable \nre\u00adsponse times. Nevertheless, each of these new collectors has a dis\u00adadvantage, clearly stated in this \npaper. We study and compare the three collectors. Several papers have proposed using special hardware \nto support real-time garbage collection. One recent such work is Click et al. s real-time collector for \nAzul Systems [9] which runs a mark-sweep collector and performs partial compaction, using special hardware \nto atomically and ef.ciently switch application accesses from an old copy of an object to its new clone. \nAnother recent approach is Meyer s real-time garbage-collected hardware system [23]. Several compacting \ncollectors are known in the literature [19]. The recent Compressor [20] is an ef.cient concurrent compactor. \nHowever, the concurrent Compressor suffers from a trap storm in one of its phases that yields very low \nprocessor utilization for an interval that may last tens of milliseconds. Concurrent collectors (e.g., \n[29, 10, 6, 26, 4]) and on-the-.y collectors (e.g., [11, 14, 13, 21, 1]) have been designed since the \n70 s, but except for the ones discussed above, none of them moves objects concurrently with program execution. \n 11. Conclusion We have proposed two new concurrent real-time garbage collector for managed languages: \nCLOVER and CHICKEN. These new col\u00adlectors support programs that employ .ne-grained synchronization in \na lock-free manner. CHICKEN uses an optimistic approach lead\u00ading to the lowest overhead. It also achieves \nunprecedented high re\u00adsponsiveness, not previously achievable. The cost is that it may fail to copy objects \nwhen low-probability races occur. CLOVER intro\u00adduces an interesting and novel probabilistic approach \nto concurrent collectors in order to make sure that all objects are copied and still obtain a low overhead \n(although not as low as CHICKEN). How\u00adever, it may fail to guarantee lock-freedom with a small probability \n(that can be rigorously computed). These new collectors provide two more ef.cient alternatives to the \nrecent STOPLESS collector.  We studied these three collectors for the absolute and relative prop\u00aderties. \nWe have also implemented all three collectors and presented measurements of their performance and overheads. \n  References [1] Hezi Azatchi, Yossi Levanoni, Harel Paz, and Erez Petrank. An on-the-.y mark and sweep \ngarbage collector based on sliding view. OOPSLA 2003. [2] David F. Bacon, Perry Cheng, and V.T. Rajan. \nA real-time garbage collecor with low overhead and consistent utilization. In POPL 2003. [3] Henry G. \nBaker. List processing in real-time on a serial computer. CACM, 21(4):280 94, 1978. [4] Katherine Barabash, \nOri Ben-Yitzhak, Irit Goft, Elliot K. Kolodner, Victor Leikehman, Yoav Ossia, Avi Owshanko, and Erez \nPetrank. A parallel, incremental, mostly concurrent garbage collector for servers. TOPLAS 27(6):1097 \n1146, November 2005. [5] Guy E. Blelloch and Perry Cheng. On bounding time and space for multiprocessor \ngarbage collection. PLDI , 1999. [6] Hans-Juergen Boehm, Alan J. Demers, and Scott Shenker. Mostly parallel \ngarbage collection. SIGPLAN Notices, 26(6):157 164, 1991. [7] Rodney A. Brooks. Trading data space for \nreduced time and code space in real-time garbage collection on stock hardware. the 1984 Symposium on \nLisp and Functional Programming, 1984. [8] Perry Cheng and Guy Blelloch. A parallel, real-time garbage \ncollector. In PLDI , 2001. [9] Cliff Click, Gil Tene, and Michael Wolf. The pauseless GC algorithm. \nVEE, 2005. [10] Edsgar W. Dijkstra, Leslie Lamport, A. J. Martin, C. S. Scholten, and E. F. M. Steffens. \nOn-the-.y garbage collection: An exercise in cooperation. CACM, 21(11):965 975, 1978. [11] Damien Doligez \nand Georges Gonthier. Portable, unobtrusive garbage collection for multiprocessor systems. In POPL 1994. \n[12] Damien Doligez and Xavier Leroy. A concurrent generational garbage collector for a multi-threaded \nimplementation of ML. POPL 1993. [13] Tamar Domani, Elliot Kolodner, and Erez Petrank. A generational \non-the-.y garbage collector for Java. PLDI 2000. [14] Tamar Domani, Elliot K. Kolodner, Ethan Lewis, \nElliot E. Salant, Katherine Barabash, Itai Lahan, Erez Petrank, Igor Yanover, and Yossi Levanoni. Implementing \nan on-the-.y garbage collector for Java. ISMM 2000. [15] ECMA. Standard ECMA-335, Common Language Infrastructure \n(CLI), 4th edition edition, June 2006. [16] Roger Henriksson. Scheduling Garbage Collection in Embedded \nSystems. PhD thesis, Lund Institute of Technology, 1998. [17] Maurice Herlihy and J. Eliot B Moss. Lock-free \ngarbage collection for multiprocessors. IEEE Tran. Paral. &#38; Dist. Sys., 3(3), May 1992. [18] Richard \nL. Hudson and J. Eliot B. Moss. Sapphire: Copying GC without stopping the world. In Joint ACM Java Grande \n ISCOPE 2001 Conference, 2001. [19] Richard E. Jones and Rafael Lins. Garbage Collection: Algorithms \nfor Automatic Dynamic Memory Management. Wiley, Chichester, 1996. [20] Haim Kermany and Erez Petrank. \nThe Compressor: Concurrent, incremental and parallel compaction. PLDI 2006. [21] Yossi Levanoni and Erez \nPetrank. An on-the-.y reference counting garbage collector for Java. OOPSLA 2001. [22] Yossi Levanoni \nand Erez Petrank. An on-the-.y reference counting garbage collector for Java. TOPLAS, 28(1), 2006. [23] \nMatthias Meyer. A true hardware read barrier. ISMM 2006. [24] Yoav Ossia, Ori Ben-Yitzhak, Irit Goft, \nElliot K. Kolodner, Victor Leikehman, and Avi Owshanko. A parallel, incremental and concurrent GC for \nservers. PLDI 2002. [25] Filip Pizlo, Daniel Frampton, Erez Petrank, and Bjarne Steensgaard. Stopless: \nA real-time garbage collector for modern platforms. ISMM 2007. [26] Tony Printezis and David Detlefs. \nA generational mostly-concurrent garbage collector. ISMM 2000. [27] Sven Gestegard Robertz and Roger \nHenriksson.\u00b0 Time-triggered garbage collection robust and adaptive real-time GC scheduling for embedded \nsystems. LCTES 2003. [28] Daniel Spoonhower, Joshua Auerbach, David F. Bacon, Perry Cheng, and David \nGrove. Eventrons: A safe programming construct for high-frequency hard real-time applications. PLDI 2006. \n[29] Guy L. Steele. Multiprocessing compactifying garbage collection. CACM, 18(9):495 508, September \n1975. \n\t\t\t", "proc_id": "1375581", "abstract": "<p>Concurrent garbage collection is highly attractive for real-time systems, because offloading the collection effort from the executing threads allows faster response, allowing for extremely short deadlines at the microseconds level. Concurrent collectors also offer much better scalability over incremental collectors. The main problem with concurrent real-time collectors is their complexity. The first concurrent real-time garbage collector that can support fine synchronization, STOPLESS, has recently been presented by Pizlo et al. In this paper, we propose two additional (and different) algorithms for concurrent real-time garbage collection: CLOVER and CHICKEN. Both collectors obtain reduced complexity over the first collector STOPLESS, but need to trade a benefit for it. We study the algorithmic strengths and weaknesses of CLOVER and CHICKEN and compare them to STOPLESS. Finally, we have implemented all three collectors on the Bartok compiler and runtime for C# and we present measurements to compare their efficiency and responsiveness.</p>", "authors": [{"name": "Filip Pizlo", "author_profile_id": "81312485539", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P1022732", "email_address": "", "orcid_id": ""}, {"name": "Erez Petrank", "author_profile_id": "81100377919", "affiliation": "Microsoft Corporation, Redmond, WA, USA", "person_id": "P1022733", "email_address": "", "orcid_id": ""}, {"name": "Bjarne Steensgaard", "author_profile_id": "81100440791", "affiliation": "Microsoft Corporation, Redmond, WA, USA", "person_id": "P1022734", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1375581.1375587", "year": "2008", "article_id": "1375587", "conference": "PLDI", "title": "A study of concurrent real-time garbage collectors", "url": "http://dl.acm.org/citation.cfm?id=1375587"}