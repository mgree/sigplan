{"article_publication_date": "06-07-2008", "fulltext": "\n Sketching Concurrent Data Structures Armando Solar-Lezama, Christopher Grant Jones, Rastislav Bod\u00edk \nUniversity of California, Berkeley {asolar,cgjones,bodik}@eecs.berkeley.edu Abstract We describe PSKETCH, \na program synthesizer that helps program\u00admers implement concurrent data structures. The system is based \non the concept of sketching, a form of synthesis that allows pro\u00adgrammers to express their insight about \nan implementation as a partial program: a sketch. The synthesizer automatically completes the sketch \nto produce an implementation that matches a given cor\u00adrectness criteria. PSKETCH is based on a new counterexample-guided \ninductive synthesis algorithm (CEGIS) that generalizes the original sketch synthesis algorithm from [20] \nto cope ef.ciently with concurrent programs. The new algorithm produces a correct implementation by iteratively \ngenerating candidate implementations, running them through a veri.er, and if they fail, learning from \nthe counterexam\u00adple traces to produce a better candidate; converging to a solution in a handful of iterations. \nPSKETCH also extends SKETCH with higher-level sketching constructs that allow the programmer to express \nher insight as a soup of ingredients from which complicated code fragments must be assembled. Such sketches \ncan be viewed as syntactic de\u00adscriptions of huge spaces of candidate programs (over 108 candi\u00addates for \nsome sketches we resolved). We have used the PSKETCH system to implement several classes of concurrent \ndata structures, including lock-free queues and concurrent sets with .ne-grained locking. We have also \nsketched some other concurrent objects including a sense-reversing bar\u00adrier and a protocol for the dining \nphilosophers problem; all these sketches resolved in under an hour. Categories and Subject Descriptors \nD.3.3 [Programming Lan\u00adguages]: Language Constructs and Features; D.2.2 [Software En\u00adgineering]: Design \nTools and Techniques General Terms Languages, Design Keywords Sketching, Synthesis, Concurrency, SAT, \nSPIN 1. Introduction Data structures designed to be shared among many concurrent threads are among the \nmost complex programs one can write in less than a thousand lines of code. The source of this complexity \ncan be traced back to the requirement that the data structure maintain con\u00adsistency in the presence of \nmany simultaneous updates. Morover, Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 08, June 7 13, 2008, Tucson, Arizona, USA. Copyright c . 2008 ACM \n978-1-59593-860-2/08/06. . . $5.00 programmers must maintain this consistency while keeping mutual exclusion \nto a minimum, in order to prevent the data structure from becoming a sequential bottleneck in a highly \nconcurrent applica\u00adtion. In order to achieve this, data-structure designers must resort to complex schemes \nto maintain the consistency with only .ne\u00adgrained locking, or even without using locks at all, relying \nonly on atomic primitives provided by the hardware. Finally, the com\u00adposition of concurrent objects is \nfar from trivial, so library-based approaches will not shield programmers from the complexities of concurrent \ndata structures. In this paper, we argue that program synthesis in the form of sketching can be an important \nelement in helping programmers cope with these daunting challenges. Sketching is a form of soft\u00adware \nsynthesis designed to make programming easier by helping programmers focus on the high-level implementation \nstrategy and leave the low-level details to the synthesizer. With sketching, the programmer creates an \nimplementation by writing a sketch a partial program containing only the easier-to-write parts of the \ncode, together with additional insight to help synthesize the re\u00admaining holes . In this way, the programmer \nis relieved from the most demanding aspects of programming, while still maintaining full control over \nthe implementation. Previous work applied Sketching to the development of ciphers and error correction \ncodes, and to important classes of scienti.c programs [18,20]. But the PSKETCH synthesizer described \nin this paper is the .rst sketch synthesizer capable of reasoning about concurrency. PSKETCH extends \nthe original SKETCH system with a new synthesis algorithm based on the concept of counterexample\u00adguided \ninductive synthesis (CEGIS). The new system also adds high-level sketching constructs to the original \nlanguage, making it easier to express insights about the implementation without having to think about \nthe details. Like its predecessor, the PSKETCH synthesizer performs com\u00adbinatorial synthesis, framing \nthe synthesis problem as a search for a sketch completion that satis.es a given correctness criteria. \nThe synthesis algorithm uses counterexample-guided inductive synthe\u00adsis (CEGIS) to search this space \nef.ciently. CEGIS works by se\u00adlecting candidate implementations from the space, then using the counterexample \nproduced by a veri.cation procedure to prune a large fraction of the search space when the selected candidate \nis shown to be wrong. The key innovation in PSKETCH is to reformu\u00adlate CEGIS for the case when the counterexample \nproduced by the veri.er is no longer an input, but an execution trace on the selected candidate. By reformulating \nCEGIS in this way, we are able to take any veri.er capable of producing counterexample traces and use \nit to build a sketch synthesizer. The new high-level sketching constructs make it easy for the programmer \nto use the synthesizer. For example, the programmer can now ask the synthesizer to discover the correct \nordering of operations in a block. This is especially useful in the concurrent setting, where programmers \nmust often expend considerable effort determining the right point to release a lock, or the right way \nto order a sequence of updates to shared data. The new constructs also make it simple to constrain the \nset of pointer expressions that the synthesizer can use to complete a pointer-valued hole. This makes \nit very easy for programmers to provide partial insights about complex pointer-manipulations. We have \nused the PSKETCH system to implement several classes of concurrent data structures, including lock-free \nqueues and concurrent sets with .ne-grained and optimistic locking . We have also sketched some interesting \nconcurrent objects including a sense-reversing barrier and a protocol for the dining philosophers problem. \nThe synthesizer is able to quickly search through enor\u00admous spaces of candidate programs; in one of our \nbenchmarks, for example, the synthesizer was able to .nd a correct implementation for a lock-free queue \nfrom a space of more than 108 candidate implementations in about 50 minutes. In summary, the key contributions \nof the paper are. 1. A generalization of the CEGIS approach to synthesize concur\u00adrent programs. 2. A \nset of language extensions and high-level constructs to sup\u00adport sketching of concurrent data structures. \n 3. An experimental evaluation of sketching for concurrent data structures.  Section 2 is a tutorial \non sketching for concurrent data struc\u00adtures. Section 3 provides a brief introduction to the sequential \nSKETCH language, and Section 4 introduces the extended PS-KETCH language. Section 5 describes the CEGIS \nalgorithm for se\u00adquential programs, and Section 6 shows how we generalized it to handle concurrent programs. \nSection 7 demonstrates how the new sketching constructs are implemented on top of the base language, \nand Section 8 contains our empirical evaluation of PSKETCH.  2. Sketching with Concurrency In this section \nwe introduce sketching of concurrent data structures from the programmer s point of view. We show how \nwith only a few constructs for sketching concurrent operations the PSKETCH language allows the programmer \nto express enough of the structure to synthesize a correct and ef.cient implementation, all the while \nhaving only a partial knowledge about how the .nal program will work. We will walk through the development \nusing a problem assigned two years ago in a undergraduate exam on operating systems. We start by quoting \nthe exam problem. Deceitfully simple, the problem was successfully answered by less than 30% of the students, \neven with additional hints (which we omitted). Lock-Free Queue. An object such as a queue is considered \nlock-free if multiple processes can operate on this object simulta\u00adneously without requiring the use \nof locks, busy-waiting, or sleep\u00ading. We will construct a lock-free FIFO queue using an atomic swap operation. \nThis queue needs both an Enqueueand a Dequeue method. Instead of the traditional Head and Tail pointers, \nwe will have PrevHead and Tail pointers. PrevHead will point at the last object returned from the queue, \nso PrevHead.next will point to the head of the queue. Here are the basic class de.nitions, under the \nassump\u00adtion that only one thread accesses the queue at a time. // Holding cell for an entry class QueueEntry \n{ QueueEntry next = null; Object stored; int taken = 0; QueueEntry(Object newobject) { stored = newobject; \n} } // The actual Queue (not yet lock-free!) class Queue { QueueEntry prevHead = new QueueEntry(null); \nQueueEntry tail = prevHead; void Enqueue(Object newobject) { newEntry = new QueueEntry(newobject); tail.next \n= newEntry; tail = newEntry; } Object Dequeue() { QueueEntry nextEntry = prevHead.next; while (nextEntry \n!= null &#38;&#38; nextEntry.taken == 1) nextEntry = nextEntry.next; if (nextEntry == null) return null; \nelse { nextEntry.taken = 1; prevHead = nextEntry; return nextEntry.stored; }}} Suppose that we have \nan atomic swap instruction that takes a local variable (register) and a memory location and swaps their \ncontents. In a relaxed dialect of Java that allows pointers, it can be described as follows. Object AtomicSwap(variable \naddr, Object newValue) { Object result = *addr; // Get old value (object) *addr = newValue; // Store \nnew object return result; // Return old contents } Problem (a). Using the AtomicSwap() operation, rewrite \ncode for Enqueue() such that it will work for any number of simultaneous Enqueue and Dequeue operations. \nYou should never need to busy wait. Do not use locking (e.g., test-and-set lock). Although tricky, it \ncan be done in a few lines. Problem (b). Rewrite code for Dequeue() such that it will work for any number \nof simultaneous threads working at once. Again, do not use locking. You should never need to busy-wait. \n. This problem gives away more about the .nal solution than sketching typically requires, yet it is interesting \nenough to illustrate how sketching is helpful. The following development re.ects the actual sketching \nprocess by a co-author who had not previously seen the solution to this problem. Let us .rst consider \nhow the programmer might sketch the concurrent Enqueue operation. First, the programmer speculates that, \nin addition to the initialization of a new entry, the method will consist of one or more of following \nstatements: assignment ::= location = value swap ::= tmp = AtomicSwap(location, value) The next step \nis to come up with locations and values that the con\u00adcurrent Enqueue may need to reference. The programmer \nguesses that these sets are suf.cient overestimates: location ::= {tail, tail.next, newEntry.next, tmp.next}value \n::= location .{tmp, newEntry, null} Next, the programmer realizes an important implication of the AtomicSwap \nsemantics. Unlike CAS, whose typical use is to update the data structure only when a race condition has \nnot occurred, AtomicSwapmodi.es the location unconditionally. Therefore, if the swap fails, some corrective \naction may be necessary. The programmer of course does not know what it means for the swap to fail, or \nwhether it can fail at all, because he does not know the solution. He can, however, state his observation \nby adding #define aLocation {| tail(.next)? | (tmp|newEntry).next |} #define aValue {| (tail|tmp|newEntry)(.next)? \n| null |} #define anExpr(x,y) {| x==y | x!=y | false |} void Enqueue(Object newobject) { Node tmp = null; \nnewEntry = new QueueEntry(newobject); reorder { aLocation = aValue; tmp = AtomicSwap(aLocation, aValue); \nif (anExpr(tmp, aValue)) aLocation = aValue; } } Figure 1. A sketch for the concurrent Enqueue. a .xup \nstatement to the set of statements that may comprise the concurrent Enqueue. .xup ::= if (expr (tmp, \nvalue)) assignment expr(x,y) ::= x == y | x != y At this point, the programmer believes to have listed \na superset of the statements that the concurrent Enqueuemight need. He does not know how to assemble \nthese statements into a working method, but he can already express an informal sketch of the desired \nEnqueue method: The concurrent Enqueue method will execute in some se\u00ad quential order (i) an assignment, \n(ii) a swap, and (iii) an optional .xup statement. This is the extent of the reasoning that needs to \nbe carried out about the concurrent Enqueue, and the resulting informal sketch is all that the synthesizer \nneeds to know to perform the synthesis. We are now ready to write the sketch in the PSKETCH language. \nThe sketched Enqueue is shown in Figure 1. Since it closely cor\u00adresponds to the informal sketch, little \nexplanation is in order. First, note that macro de.nitions behave as in C. Second, the PSKETCH expression \n{|e1|e2|...|} asks the synthesizer to select one of the ei expressions, which can be given as regular \nexpressions. Third, the reorder construct speci.es that the statements in its body can appear in any \norder in the .nal implementation. Finally, note that the programmer included among the choices for anExpr \nthe false expression; this makes the .xup statement optional. The value of the sketch for the programmer \nis highlighted by the fact that the sketched Enqueue represents 1,975,680 unique candidate programs. \nSince the synthesizer will select a correct one from among them, the programmer can now think in terms \nof coming up with a set of ingredients rather than how to orchestrate them. It remains to specify the \ncorrectness condition, so that the synthesizer can select a correct candidate. We discuss how this is \ndone in Section 4, but here it suf.ces to say that the programmer\u00adspeci.ed conditions require that the \nconcurrent Enqueue obeys the same structural properties as the sequential counterpart that was given \nin the problem statement, and is sequentially consistent. The resolution of the sketch in Figure 1 by \nthe synthesizer produces the concurrent Enqueue method in Figure 2. The .xup statement was optimized \naway because it was unnecessary (the synthesizer replaced anExp with false). The sketch for the concurrent \nDequeue is shown in Figure 3. In this operation, the programmer easily realized that the main trick is \nto test the taken .eld with atomicSwap, so this aspect was not sketched. The tricky part was to come \nup with correct code that can advance the prevHead pointer as far as possible, for improved void Enqueue(Object \nnewobject) { Node tmp = null; newEntry = new QueueEntry(newobject); tmp = AtomicSwap(tail, newEntry); \ntmp.next = newEntry; } Figure 2. The sketch from Figure 1, resolved. Object Dequeue() { QueueEntry nextEntry \n= prevHead.next; while (nextEntry!=null &#38;&#38; atomicSwap(nextEntry.taken,1)==1) nextEntry = nextEntry.next; \nif (nextEntry == null) return null; else { QueueEntry p = {| prevHead | nextEntry |}; while (p != NULL \n&#38;&#38; {| p(.next)?.taken |} ) prevHead = p; p = p.next; return nextEntry.stored; }}} Figure 3. A \nsketch for the concurrent Dequeue. Object Dequeue() { QueueEntry nextEntry = prevHead.next; while (nextEntry!=null \n&#38;&#38; atomicSwap(nextEntry.taken, 1)==1) nextEntry = nextEntry.next; if (nextEntry == null) return \nnull; else { QueueEntry p = prevHead; while (p != NULL &#38;&#38; p.next.taken) prevHead = p; p = p.next \nreturn nextEntry.stored; }}} Figure 4. The sketch from Figure 3, resolved. performance. This loop was \nsketched. In it, there is a choice of where to start the iteration (there were only two plausible choices) \nand a choice where to end the loop (again, only two choices). The sketch for Dequeue in Figure 3 represents \nonly 4 programs, but together with the Enqueue sketch, the programmer has encoded over .ve million candidate \nimplementations. Section 8 describes a sketch for Dequeue that corresponds to more candidates; that sketch \nseeks to synthesize a program that updates the prevHead pointer during the .rst loop. Such a Dequeue \nhas incomparable performance with that in Figure 4 (depending on the workload, one or the other may be \npreferred). These two sketches give hope that sketches may be used to quickly develop alternative algorithms. \n 3. The SKETCH Language To give necessary background for the sections that follow, we summarize here \nthe SKETCH language introduced in [21]. This language supports sketching-based synthesis by extending \na simple imperative language with a single synthesis operator on top of which higher-level and domain-speci.c \nsynthesis constructs can be added as mere syntactic sugar. Withthe SKETCH language,theprogrammer.rstwritesaclean, \nbehavioral speci.cation for an algorithm, and then he sketches an outline of an ef.cient implementation. \nWe have observed that this outline, called a sketch, captures the programmer s insight about the implementation \nwhile allowing the programmer to leave tedious details unspeci.ed. Let us illustrate programming with \nSKETCH using a small pro\u00adgram submitted to a SKETCH programming contest that we orga\u00adnized in the past \nyear. The contestant used SKETCH to implement a problem that he had previously solved by hand; this manual \nprocess took half a day. As we will see shortly, sketching the same imple\u00admentation is much easier. The \nproblem at hand is to compute a 4 \u00d7 4 matrix transpose. The speci.cation is given in the function trans. \n(Note that trans is an executable speci.cation, not a declarative one, and so one can debug it easily \nwith standard debugging techniques.) int[16] trans(int[16] M) { int[16] T= 0; for (int i = 0; i < 4; \ni++) for (int j = 0; j < 4; j++) T[4 *i + j]= M[4 *j + i]; return T; } While optimizing the transpose, \nthe student realized that it might be possible to parallelize the transpose with a SIMD instruc\u00adtion \ncalled shufps. This instruction accepts two 4-word arrays and semi-permutes each into a 2-word array; \nthe semi-permutations are given by a third argument. The following SKETCH function emulates the semantics \nof shufps in the SKETCH language.The in\u00addexing notation a[b::c] translates to a sub-array of c cells \nof array a starting at index b. int[4] shufps(int[4] x1, int[4] x2, bit[8] b) { int[4] s; s[0] = x1[(int) \nb[0::2]]; s[1] = x1[(int) b[2::2]]; s[2] = x2[(int) b[4::2]]; s[3] = x2[(int) b[6::2]]; return s; } The \nstudent s insight was that a shufps-based transpose had to proceed in two stages: The input matrix had \nto be permuted into an intermediate matrix, which would then be permuted into the resulting (transposed) \nmatrix. It was not immediately obvious, however, how exactly the two stages were to proceed. The sketch \ntrans_sse shown below expresses the student s in\u00adsight. First, we need to introduce the sketch constructs \nin the lan\u00adguage. The implements directive in the function header tells the synthesizer to resolve the \nsketch trans_sse such that it is behav\u00adiorally equivalent to trans, i.e., the two must compute the same \nfunction. The ?? operators, called the primitive hole, will be re\u00adplaced by the synthesizer with suitable \nconstants to satisfy the behavioral equivalence. Finally, the repeat(n) s construct is a synthesis-time \nmacro that n times replicates s. The replication cre\u00adates fresh holes, each of may be replaced with a \ndifferent constant. int[16] trans_sse(int[16] M) implements trans { int[16] S= 0, T= 0; repeat (??) \nS[??::4] = shufps(M[??::4], M[??::4], ??); repeat (??) T[??::4] = shufps(S[??::4], S[??::4], ??); return \nT; } The sketch concisely expresses the insight. Notice that the pro\u00adgrammer .xed the two permutation \nstages but he left unspeci.ed (1) the number of shufpsinstructions necessary for the task, (2) the ranges \nof matrix cells to be permuted, and (3) the bit vectors direct\u00ading the permutations. The above sketch \nresolves in 33 minutes on a 1.G GHz Core 2 laptop. The synthesized trans_sse is shown be\u00adlow. (The binary \nstrings are initializers for the bit-arrays, and are read left-to-right): S[4::4] = shufps(M[6::4], \nM[2::4], \"11001000\"); S[0::4] = shufps(M[11::4], M[6::4], \"10010110\"); S[12::4] = shufps(M[0::4], M[2::4], \n\"10001101\"); S[8::4] = shufps(M[8::4], M[12::4], \"11010111\"); T[4::4] = shufps(S[11::4], S[1::4], \"10111100\"); \nT[12::4] = shufps(S[3::4], S[8::4], \"11000011\"); T[8::4] = shufps(S[4::4], S[9::4], \"11100010\"); T[0::4] \n= shufps(S[12::4], S[0::4], \"10110100\");  4. The Concurrent PSketch Language The PSKETCH language extends \nthe SKETCH language introduced in [20] in two important directions. First, it provides higher level sketching \nconstructs with which programmers can more easily ex\u00adpress their insights. Second, it introduces threads \nand synchroniza\u00adtion primitives. Concurrency introduces nondeterminism, which precludes the SKETCH approach \nof specifying a sketch s behavior by a reference implementation to which a resolved sketch must be functionally \nequivalent. At the end of this section, we describe how correct behavior is speci.ed in PSKETCH. 4.1 \nHigh-level sketching constructs The sequential SKETCH language extends its imperative base with a single \nsynthesis construct: the primitive hole expression, ??, which the synthesizer replaces with a constant \nthat makes the sketch satisfy its speci.cation. Prior work found the primitive hole suf.cient for synthesizing \nexpressions (r-values), such as loop bounds and index expressions in matrix manipulations. [20] When \nsketching concurrent data structures, we found a need to synthesize (1) left-hand-side expressions (l-values) \nand (2) control .ow, such as the order in which statements execute. To facilitate sketching of these \nconstructs, PSKETCH introduces two features (i) regular-expression expression generators, (ii) a reorder \nblock. As we will show in section Section 7, these constructs can be implemented as syntactic sugar on \ntop of the basic ?? expression. Regular-expression expression generators. Regular-expression generators \n(hereafter RE-generators) allow the programmer to sketch both r-value and l-value expressions from a \nrestricted regular grammar. The RE-generator construct has the form {|e|}, where e is a regular expression \nliteral. The semantics of the construct is that the synthesizer substitutes the syntactic occurrence \nof the construct with a string from L(e) such that the substitution makes the sketch satisfy its speci.cation. \nRE-generator are not simply expanded as a macro, however; for programmability, we require that each component \nregular expression e be well typed. RE-generators are typically used to enumerate symbolic mem\u00adory locations \nor values that the synthesized code can reference. For example, the following PSKETCH fragment shows \nhow we sketched the use of a compare-and-swap (CAS) instruction in a doubly-linked data structure. CAS({| \nhead(.next|.prev)? |}, {| newNode(.next|.prev)? |}, {| newNode(.next|.prev)? |}) The .rst CAS argument \nselects the location to be modi.ed, and the second and third arguments give the old and new values, respec\u00ad \n#define NODE {| (tprev|cur|prev)(.next)? |} #define COMP {| (!)? ((null|cur|prev)(.next)? == (null|cur|prev)(.next)?) \n|} while(cur.key < key){ Node tprev = prev; reorder { if (COMP) { lock (NODE); } if (COMP) { unlock (NODE); \n} prev = cur; cur = cur.next; } } Figure 5. A sketch of hand-over-hand locking. while(cur.key < key){ \nif (prev != null) unlock (prev); lock (cur.next); prev = cur; cur = cur.next; } Figure 6. The sketch \nfrom Figure 5, resolved. tively. When writing the sketch, the programmer suspected (or in\u00adsisted) that \na CAS had to be used in the synthesized code, but he did not know which location had to be updated, and \nwith what values. With the sketch below, he effectively speci.ed all 27 CAS frag\u00adments that made sense \nin the context of the list addition operation (accessing other locations does not make sense in this \noperation). RE-generators support only two regular expression operators: e1|e2 and optional expressions \ne?. At .rst sight, the exclusion of Kleene closure might seem ar\u00adbitrary, but keep in mind that RE-generators \nare used to generate bounded program text. In real code, it is unusual to .nd chains of pointer dereferences \nof the form {|p(.next)*|} with more than two or three levels of dereferencing, so adding Kleene closure \nwould increase the search space without any signi.cant program\u00admability bene.t. Reorder block. Concurrent \ndata structures often depend on careful statement ordering to satisfy desired invariants. For this rea\u00adson, \nwe extended PSKETCH with a reorder construct that leaves the synthesizer in charge of determining the \ncorrect order for the statements in a block of code. The synthesizer considers all pos\u00adsible orders of \nthese statements and selects one that, together with other choices made by the synthesizer, turns the \nsketch into a pro\u00adgram that meets the speci.cation. In Section 2, we showed a sketch that used reorder \nto let the synthesizer decide where in a block of code to use an atomic swap. In many other sketches, \nwe have similarly used the reorder block to describe a soup of operations which, when ordered in the \nright sequence, can produce a correct program. Another use of reorder is to control mutual exclusion. \nFor ex\u00adample, one of our benchmarks implements a hand-over-hand lock\u00ading scheme for adding and removing \nelements from a concurrent set represented as a sorted linked list (see Section 8). As the algorithm \nscans the list, it must acquire and release some locks to maintain a sliding window of locks around the \npointers it is holding. This scheme is tricky to get right, but we can use the reorder block to give \nthe synthesizer the freedom to discover the correct strategy for acquiring and releasing the locks. The \nsketch is shown in Fig\u00adure 5, and the synthesized code is shown in Figure 6. Note how the struct Lock \n{ int owner = -1; } unlock(Lock lk) { lock(Lock lk) { assert lk.owner == pid; atomic(lk.owner == -1){ \nlk.owner = -1; lk.owner = pid; } } } Figure 7. Locks implemented with conditional atomics. synthesizer \nused the freedom to reorder statements to discover the correct strategy for acquiring and releasing the \nlocks. 1 4.2 Concurrency Primitives The key novelty in PSKETCH is the support for synthesizing con\u00adcurrent \nprograms. To write these concurrent sketches, we included three concurrency constructs in the PSKETCH \nlanguage. While these three constructs are standard, supporting them required re\u00adthinking our synthesis \nalgorithm, which we discuss in Section 6. Threads. Threads are created with the construct fork (int i, \nN) b which spawns N threads and blocks until all N threads terminate. Each thread executes the statement \nb. The index variable i contains a unique id for each thread, from 0 to N - 1. All variables declared \ninside b are thread-local. All other variables, together with the heap, are shared. Our current system \nonly supports programs with a single fork statement, optionally preceded by a sequential prologue and \nfol\u00adlowed by a sequential epilogue. However, this limitation is not in\u00adherent to the method; it is only \na matter of engineering to extend the system to support multiple, nested fork statements. Atomic Sections. \nAn atomic section is a block of code that is guaranteed to execute without interference from other threads. \nAtomic sections can be used to model the atomic primitives, such as compare-and-swap or read-and-increment, \navailable on a particular architecture. Synchronization. PSKETCH translates all synchronization primitives \ninto conditional atomic sections [13]. A conditional atomic is an atomic section that blocks until its \ncondition holds. For example, lock and unlock primitives can be implemented in terms of conditional atomics \nas shown in Figure 7. It is worth noting that PSKETCH does not support spin-locks, so they must be modeled \nwith conditional atomics. We discuss this limitation in more general terms in Section 6. 4.3 Speci.cations \nin PSKETCH In SKETCH, a sketch is synthesized into a program that complies with a separately provided \nbehavioral speci.cation, which is bound to the sketch with the implements keyword. The synthesizer either \noutputs a program is functionally equivalent to the speci.cation (in terms of observable outputs) or \nreports that the sketch cannot be resolved (i.e., cannot be completed to behave like the speci.cation). \nThis mode of speci.cation is still supported in PSKETCH, but it is useful only for those parallel sketches \nfor which one expects de\u00adterministic behavior. The .nal state of concurrent data structures typically \ndepends on the nondeterministic interleaving of opera\u00adtions in concurrent threads, so a speci.cation \nde.ned by input/out\u00adput equivalence is less useful. 1 PSKETCH does not necessarily resolve reorder so \nthat it minimizes mu\u00adtual exclussion. If optimality is desired, we believe the best way to achieve it \nis to synthesize many correct candidates and select the best one by mea\u00adsuring the performance of each, \nas is done in autotuning [6]. Still, the pro\u00adgrammer can use assert statements to constrain solutions \nto only those with mutexes that are, e.g., separated by at most two statements. PSKETCH allows the programmer \nto specify desired correctness conditions using assert statements. The semantics of PSKETCH is that the \nsynthesized program must (1) behave like the speci.cation bound with the implements clause; and (2) be \nfree of assertion fail\u00adures on all inputs and all thread interleavings. These assertions also include \nimplicit ones added by the synthesizer to guarantee mem\u00adory safety and freedom from deadlock. The programmer-speci.ed \ncorrectness criteria are typically checked in the epilogue; Section 8 describes how we used assertions \nto de.ne correctness for some of the benchmarks we evaluated.  5. Synthesis for Sequential Sketches \nThe SKETCH synthesizer solved sequential sketches using a counterexample-guided synthesis algorithm. \nThe algorithm was in\u00adtroduced in [20], where it was presented as a solver for the prob\u00adlem of 2-quanti.er \nQuanti.ed Boolean Satis.ability specialized for synthesis of sketches. We have recently found a deep \nconnec\u00adtion between the original algorithm and inductive program synthe\u00adsis [4]. This section describes \nthe original algorithm from this more general perspective as counterexample-guided inductive synthesis \n(CEGIS), and highlights the connection to program veri.cation. The algorithm is described on a reduced \nsubset of the language that is limited to basic control .ow and integer holes. Section 6 extends this \nalgorithm to handle concurrent sketches that use conditional atomic sections as the only synchronization \nprimitive. Section 7 describes how the remaining language features are implemented in terms of these \nbasic constructs. 5.1 The Counterexample-Driven Inductive Synthesis A sketch with only integer holes \ncan be understood as a parame\u00adtrized program Sk[c], where c is a control vector containing the values \nfor all the integer holes in the program. For a given input x, we can represent the correctness requirements \nfor candidate Sk[c] as a predicate P (x, c) on x and c. Thus, the sequential sketch syn\u00adthesis problem \nreduces to .nding a control vector satisfying the following equation. .c..x.P (x, c) (5.1) The two-quanti.er \nalternation makes this problem very dif.cult, but the CEGIS algorithm solves it by using the principle \nof induc\u00adtive synthesis. The problem of inductive synthesis is to generate a candidate implementation \nthat is consistent with a set of observations about the behavior of the program on a given set of inputs. \nFor sequential sketch synthesis, our observations consist of a set of inputs E, together with the observation \nthat the candidate Sk[c] must satisfy the correctness criteria on these inputs. Therefore, we can frame \nthe inductive synthesis problem as follows. .c..x . E.P (x, c) (5.2) Given a boolean representation of \nthe predicate P , Equation (5.2) can be expanded and supplied to a SAT solver directly since the universal \nquanti.cation over the small set E can be expressed as a simple conjunction. On its own, however, an \ninductive synthesizer is unable to guar\u00adantee the correctness of the candidate solution. The synthesizer \ncan only guarantee that the resulting implementation will match the given observations. As more observations \nare added, the resulting implementations are expected to converge to a correct implementa\u00adtion, but the \ninductive synthesizer is unable to detect convergence on its own. To address this problem, CEGIS couples \nthe inductive synthe\u00adsizer with a veri.cation procedure. The veri.er serves two func\u00adtions: it rejects \nincorrect candidates until convergence is reached, and it produces observations to drive the inductive \nsynthesizer. The Figure 8. Counterexample driven synthesis algo. veri.er is very good at producing observations \nbecause every time a candidate fails, the counterexample that proves the failure is guar\u00adanteed to cover \na corner case not covered by any previous observa\u00adtions. The complete algorithm is illustrated in Figure \n8. It is worth noting that the CEGIS algorithm places very few requirements on the veri.cation procedure; \nany veri.cation procedure capable of producing concrete counterexamples can be incorporated into the \nalgorithm. The power of the CEGIS algorithm was demonstrated empiri\u00adcally in [20]; for example, in one \nreported experiment, the sketch solver synthesized a sketch of AES by analyzing only 655 inputs from \nspace of 2256 possible inputs. This demonstrated both the power of the inductive synthesis approach, \nand the high quality of the observations produced by the veri.er. The challenge of concurrent synthesis \nis to extend this algorithm for the case when the observations are no longer just inputs, but traces \nshowing how speci.c thread interleavings in a candidate solution lead to property violations.  6. Synthesis \nfor Concurrent Sketches This section develops a concurrency-aware synthesizer to support the concurrency \nextensions to the SKETCH language. The con\u00adcurrent synthesizer exploits the bene.ts of inductive synthesis \nob\u00adserved in the sequential setting. In that setting, synthesis from ob\u00adservations allowed us to ignore \nall but a few counterexample in\u00adputs, which turned the 2QBF synthesis problem into a sequence of SAT \nproblems. Here, we show that a correct candidate can be computed by considering only a few counterexample \nthread inter\u00adleavings, sidestepping the need to reason about all possible thread interleavings during \nsynthesis. We implemented the algorithm on top of the existing SKETCH infrastructure, using SPIN as our \nveri\u00ad.cation engine with very positive results. The algorithm follows counterexample-guided inductive \nsyn\u00adthesis: The inductive synthesizer evaluates each candidate on a set of observations. Each observation \nis a .xed thread schedule. As a result, the inductive synthesizer evaluates each candidate only on traces \ninduced by the observations, ignoring all other interleavings. Traces have sequential semantics, so observations \nreduce the concurrent synthesis problem into a sequential one.  The veri.er is standard in that it considers \nall thread interleav\u00adings in the provided candidate. If the candidate is bad, the ver\u00adi.er generates \na counterexample trace that witnesses the asser\u00adtion violation. Counterexample traces are then used as \nobserva\u00adtions.  The algorithm can accommodate any veri.er as long as it pro\u00adduces a bounded counterexample. \nThe correctness guarantees of the system will be those which the veri.er can decide. However, the inductive \nsynthesizer can only eliminate candidates based on violation of safety properties on a trace. Therefore, \nwe require that any liveness properties be approximated as safety properties which must hold after a \nbounded number of steps. For example, the syn\u00adthesizer enforces termination by requiring that candidates \nterminate after a bounded number of steps for the bounded inputs it considers. The algorithm outlined \nabove is relatively straightforward. The challenge is how to turn a trace into a valid observation; that \nis, how to make it applicable to all candidates. Compared to inputs, which act as observations in the \nsequential setting, traces do not lend themselves directly to that role: while a counterexample input \nproduced on one candidate is applicable to other candidates, a trace is speci.c to a candidate and thus \nincompatible with others. We could, of course, arbitrarily project a trace onto another candidate, but \nwe want good observations. An observation is good if it prunes away many bad candidates, by exposing \ntheir violations. Since a trace exposes an (unidenti.ed) problem detected in a candidate by a veri.er, \nit is desirable that projected trace retains the ability to expose this problem in candidates that share \nthe problem. Two issues complicate projection of traces onto other candi\u00addates. 1. Projection onto candidate \nspace. We cannot afford to project traces individually for each candidate, as there are too many candidates. \nInstead, we need to transform the sketch so that a given counterexample trace is projected simultaneously \nonto all candidates in the candidate space. 2. Preservation of errors. We know that a counterexample \ntrace exposes an error in a candidate, but we do not know what aspects of the trace caused the error. \nHence, projection cannot aim to preserve a speci.c fragment of a trace. Instead, it needs to preserve \nas much as possible under some notion of error in the candidate.  Let us now address the .rst problem, \nstarting from .rst princi\u00adples. To turn a trace into an observation, we need to project a trace tc1 produced \non a candidate program c1 onto a trace tc2 valid on a candidate c2. We denote the projection of tc1 onto \nc2 with tc1 Cc2, or tC c when the origin of t is clear from the context. We de.ne tc1 Cc2 to be a single \ntrace, rather than a set of traces. (The latter would enable preservation of more errors present in tc1 \n, but this would come at the cost of growing the size of the observation set.) The goal is to be able \nto use a set Te of counterexample traces to .nd a plausible candidate c. A candidate is plausible iff \ntrace tC c does not fail, for all traces t . T . A trace is considered to fail when it encounters an \nassertion violation or a deadlock. This is denoted with a predicate fail(t). Thus, we want to search \nfor a candidate c to satisfy the following equation. .t . Te . \u00acfail(tC c) In order to make the search \nef.cient, we need to produce a boolean encoding of the problem above, similar to what is used in sequential \nsynthesis [20]. The .rst step, is to encode the space of candidate programs as a function Sk[c] parametrized \nby a bit\u00advector c, so different values of c make Sk a different candidate. The second step is to create \na new function Skt[c] such that Skt[c]= tC Sk[c] Skt[c] is therefore a projection of trace t on the candidate \nSk[c]. With this encoding, the SAT solver is now left to solve the problem .t . Te . \u00acfail(Skt[c]) Where \nfail(Skt[c]) is a boolean function of c computed symboli\u00adcally for each individual trace in Te. Note \nthat Skt[c] is a sequential trace, so this is the same inductive synthesis problem as in the se\u00adquential \nsetting. To explain how Skt[c] is computed symbolically from Sk and t, we need to return to the second \nquestion how to preserve errors exposed by a trace. To simplify the presentation, let us assume that \nthe sketch is acyclic, which implies that all candidates are acyclic. This is not a serious simpli.cation \nbecause our inductive synthesizer explores executions of bounded length. The acyclic restriction is will \nsimplify the explanation because each statement is executed at most once. When projecting traces, our \ngoal is to ensure that, whenever possible, the projected trace preserves the error exposed in the original \ntrace. An error is that aspect of a candidate program that was responsible for an assertion violation: \nit could be not enough synchronization causing a race condition, or too much of it causing a deadlock, \nor any other bug allowed by the sketch. An error is an inherently vague concept, so rather than de.ning \nit directly, we de.ne preservation of errors in terms of maximally preserving the ordering of steps in \nthe original trace. A step is a pair (s, i), of a statement s and the thread i which executed it. ' \nWe say that a trace tpreserves a trace t if all steps common to t' and t are executed in the same order \nin both traces; i.e. if s1 precedes s2 in t, and both s1 and s2 are present in t', then s1 ' precedes \ns2 in t. This notion of preservation is practically relevant if preserving step ordering indeed preserves \nthe conditions that lead to an error. This is to be expected if preserving the order also helps preserve \nthe data.ow relationship that led to the error in the .rst trace. For example, if data .owing from s1 \ncaused an assertion failure in s2 in a candidate c1, then if a trace for candidate c2 preserves this \nerror\u00adcausing data.ow, the trace should serve to eliminate candidate c2. Preserving the order does not \nnecessarily mean the data.ow will be preserved. For example, it is possible that executing s1 before \ns2 exposed an error in c1 but it does not in c2, because something in the program c2 executed between \nthese two steps and masked the error. However, step-ordering preservation is simple to enforce and we \nhypothesize that it preserves many errors. Preserving or\u00addering of statements worked well for the errors \nthat we manually examined. Therefore, in general, we want Skt[c] to be a preserving pro\u00adjection of t. \nHowever, it is not always possible to .nd a preserving projection of a trace into another candidate program, \nas the follow\u00ading example illustrates. bool c = ??; thrd1: { sa; if (c) wait; s1; if (!c) signal } thrd2: \n{ sb; if (!c) wait; s2; if (c) signal }  This sketch corresponds to two candidate programs, selected \nbased on the value of c: ct: thrd1: { sa; wait; s1; } thrd2: { sb; s2; signal; } cf : thrd1: { sa; s1; \nsignal; } thrd2: { sb; wait; s2; } All traces for ct execute s2 before s1. However, none of these traces \ncan be projected onto cf in a preserving manner because all traces for cf execute s1 before s2. In these \nsituations where a preserving projection is not possible, we require that Skt[c] be a preserving projection \nof the longest pre\u00ad.x of t for which such a projection is possible. For example, if the trace tt for \nct is (2, sb),(1, sa),(2,s2),(2, signal),(1, wait),(1,s1), then the encoder can not produce a complete \npreserving projection into cf . Thus, Sktt [0] = (2, sb), (1, sa), a projection of the longest pre.x \nof tt for which a preserving projection is possible. The algorithm that produces Skt[c] from Sk and t \nis relatively simple. As a .rst step, it performs if-conversion [1] on the sketch Sk to turn it into \na sequence of predicated atomic statements (either atomic blocks, or simple assignments). An interesting \nproperty of this representation is that any candidate implementation Sk[c] derived from the sketch will \ncontain a subset of the statements present in Sk. In the second step, the algorithm produces a version \nof the sketch Ski for each thread i in the trace. The n th statement of Ski , sni is derived from the \nn th statement of Sk by renaming all local variables to have thread-unique names. This guarantees that \nlocal variables will behave as expected when we interleave statements from different threads. The next \nstep is to interleave the sequences of statements cor\u00adresponding to the different threads into a single \nsequence of state\u00adments. To do this, the algorithm sorts all the statements sni accord\u00ading to the partial \norder imposed by both the thread and the sequen\u00adtial threading; namely: (i) If step (si,n) precedes (sj \n,m) in the ij ij trace, then sn <sm. (ii) If i = j.n<m then sn <sm. (iii) If the trace t exposes a deadlock \ninvolving a set of steps D =(sj ,m) ..., then if sjm corresponds to a step in the deadlock set, and s \nin does not, then sni <smj . The last constraint is there for technical reasons, to make it eas\u00adier for \nus to both do deadlock detection and rule out suf.xes of traces which can not be made into a preserving \nprojection. The .\u00adnal step in producing Skt is to take the sequence of guarded state\u00adments form the previous \nstep, and replace all conditional atomics atomic(c) s with a conditional like the one shown below. if(c) \ns; else if(some other thread can make progress) return OK; else assert 0 : deadlock ; The resulting \nencoding Skt represents the preserving projec\u00adtion of the trace t onto all the candidates in the space. \nMoreover, fail(Skt[c]) can be represented as a boolean function of c, which allows us to solve the inductive \nsynthesis problem ef.ciently with a SAT solver. Section 8 will describe our empirical evaluation of the \nmethod, but before that, we must describe how the synthesizer handles the high-level sketching constructs. \n 7. Translating Sketching Constructs In the last two sections, we described how the synthesizer com\u00adpletes \nsketches containing only integer holes. In this section, we describe how the new high-level sketching \nconstructs are imple\u00admented by showing their translation to simple code fragments with integer holes. \n7.1 Regular Expression Generators The translation of RE-generators depends on whether the RE\u00adgenerator \nis an l-value or r-value. In both cases, we will use the following terminology. Assume that the RE-generator \nr describes a set S(r) of k syntactically valid strings, denoted s1,...,sk. Translating an r-value RE-generator \nis straightforward. This translation requires lg k bits of primitive holes. translateRvalueGen (r)= switch \n(??){ case 1: return s1; ... case k: return sk; } The translation of an l-value RE-generator r that \nappears in the statement r=e is much like the r-value RE-generator translation, except that each statement \nin the switch block is a choice of assignments from e to si.  7.2 Reorder Statement A reorder block \nwith a set S of k statements s0,...,sk-1 rep\u00adresents k! possible candidate programs; so the synthesizer \nneeds to encode this exponential space of possibilities in a reasonable amount of PSKETCH code. The PSKETCH \nsynthesizer actually contains two different encodings for the reorder block, each with different tradeoffs \nof space and complexity. Our .rst, quadratic, encoding is shown below. It uses k lg k control bits and, \nafter unrolling the for loop, will have k copies of each statement in the block, for a total of k2 . \ntranslateReorder (S)= int[k] order = ??k assert noDuplicates in order for (i=0 to k - 1) switch (order[i]) \n{ case 1: S1 ... case k: Sk } Notice that the assert forces the synthesizer to consider only se\u00admantically \nlegal values of the array order(permutations of 1 ...k), which is initialized with k primitive holes. \nThe second encoding actually requires exponential space, but for many sketches, it has proven to be signi.cantly \nmore ef.cient than the quadratic one. The basic idea is as follows. Suppose that we start with a list \nof m statements s0; ... ; sm-1, and we want to insert a statement sm somewhere in the list. We can encode \nthis easily in 2*m+1 statements. i=??; if(i=0){ sm;} s0; if(i=1) {sm;} s1; ... if(i=m-1){ sm;} sm-1; \nif(i=m) sm;  We can apply this construction recursively to build a representa\u00adtion of the reorder. To \ndo this, we start with s0, and we use the construction above to add s1 before or after it. Then, we repeat \nthe process to insert s2 into the resulting sequence; the same process is repeated to insert each subsequent \nstatement. The resulting repre\u00adsentation will have 2i copies of si, and will require on the order of \nn 2 control bits. Surprisingly, for many benchmarks this encoding is much better than the quadratic one, \nboth in terms of speed and size. There are several reasons for this. First, in most of our benchmarks, \nthe num\u00adber of statements in the reorder blocks are relatively small. More\u00adover, our reorder blocks often \ncontain statements of drastically dif\u00adferent sizes; blocks with only a couple of very expensive statements \ncan be encoded more ef.ciently with the exponential encoding. For example, if a reorder block has two \nexpensive statements and three inexpensive ones, the quadratic encoding will require 10 expensive statements \nand 15 cheap ones. With the exponential encoding, we can encode this block with 3 expensive statements \nand 28 cheap ones, as long as we add them in the right order. Thus, if the expen\u00adsive statements are \nmore than twice as expensive as the cheap ones, the exponential encoding will be more ef.cient.  8. \nEvaluation This section presents our evaluation of the desugaring of the PS-KETCH language shown above, \nthe new PSKETCH language in\u00adtroduced in Section 4, and our CEGIS algorithm from Section 6. Speci.cally, \nwe evaluate the performance of our PSKETCH com\u00adpiler and the expressiveness of the PSKETCH language on \na suite of Table 1. Summary of benchmark sketches. C is the set of candi\u00addate programs encoded by each \nsketch. Sketch Description |C| queueE1 Lock-free queue: restricted Enqueue() 4 queueE2 Lock-free queue, \nfull Enqueue() 106 queueDE1 queueE1, plus sketched Dequeue() 103 queueDE2 queueE2, plus sketched Dequeue() \n108 barrier1 Sense-reversing barrier, restricted 104 barrier2 Sense-reversing barrier, full 107 fineset1 \nFine-locked list, restricted find() method 104 fineset2 Fine-locked list, full find() 107 lazyset Lazy \nlist, singly-locked remove() 103 dinphilo Approximation of dining philosophers problem 106 benchmarks. \nThe benchmarks were chosen because they are com\u00adplex to implement, due to subtle issues caused by concurrency. \nOur performance results are encouraging: PSKETCH successfully searched spaces of about 108 syntacti\u00adcally \nunique candidates in under an hour, consuming less than 500 MiB of memory.  Our CEGIS algorithm required \nonly a few observations (mean\u00ading only a few calls to the veri.er) to resolve a sketch, or de\u00adtermine \nthat it could not be resolved. In our benchmarks, PS-KETCH required 10 iterations to .nd a correct implementation \nfrom a space of about 108 possibilities. PSKETCH was also able to show after only 7 observations that \none of our benchmark sketches could not be resolved.  The expressiveness of the PSKETCH language is \nharder to eval\u00aduate, but we show example sketches of our benchmarks below and argue that they capture \nthe insight behind a solution, with a min\u00adimum of unnecessary detail. For example, we were able to sketch \nand synthesize a previously-unknown-to-us Dequeue() method of a lock-free queue. These results indicate \nthat parallel programmers might .nd PSKETCH useful. We begin this section by introducing our hypotheses \nabout the PSKETCH system. Next, we present the benchmarks we used to teste these hypotheses, showing \nsome of our example sketches. We then report PSKETCH s performance across our test suite, and dis\u00adcuss \nthe results. Finally, we summarize the limitations we encoun\u00adtered in the PSKETCH synthesizer. 8.1 Hypotheses \nWe wish to evaluate the following hypotheses. Synthesis scales well with the size of the candidate program \nspace. This scalability is the key to the sketching approach: it en\u00adables programmers to write sketches \nwith less mundane or subtle detail, leaving its completion to the synthesizer. We test this hy\u00adpothesis \nby measuring the time for PSKETCH to resolve sketches that encode increasingly large candidate spaces. \nOur encoding of the observations made from failed candidates captures useful information about the cause \nof failure. This ap\u00adpraises the projection strategy we use to encode information from the traces in the \ninductive synthesizer. The number of observations required to resolve a sketch (or show that it cannot \nbe resolved) can measure the strategy s effectiveness. Fewer observations suggest that the encoding is \ncapturing more useful information from each trace. The PSKETCH language is expressive for this domain. \nWe do not attempt to measure this quantitatively; instead, we show how we expressed the insights behind \nour benchmarks using PSKETCH.  8.2 Benchmarks Our benchmarks are intended to represent various sketching \nsce\u00adnarios across different problems. These sketches were chosen as exemplars; we have sketched other \ndata structures that we omit here, including a doubly-linked list and full version of the lazy list\u00adbased \nset described below. Table 8.2 summarizes the more detailed descriptions of the benchmarks that follow. \n8.2.1 Lock-free queue The .rst version of this queue, queueE1, contains a sketch of a re\u00adstricted version \nof the Enqueue() method discussed in Section 1. It is restricted in that its candidate space is smaller \nthan the Enqueue() sketch from Section 1. The second version, queueE2, has the full Enqueue() sketch \nshown in Section 1. For this benchmark, we also analyzed the complexity of resolv\u00ading a problem where \nmultiple methods had been sketched. The Dequeue() sketch from Section 1 had too few holes to serve this \npurpose. Instead, one of us decided to try implementing Dequeue() with a single while loop. In a few \nminutes, he wrote the very simple sketch shown below. The sketch simply places in a reorder block all \nthe statements that one could reasonably expect to be necessary for the solution. The solution times \nfor this experiments correspond to the queueDE1 and queueDE2 benchmarks. Object Dequeue() { QueueEntry \ntmp = null; boolean taken = 1; while (taken) { reorder { tmp = {| prevHead(.next)?(.next)? |}; if (tmp \n== null) return null; prevHead = {| (tmp|prevHead)(.next)? |}; if (!tmp.taken) taken = AtomicSwap(tmp.taken, \n1); } } return tmp.stored; } The queue benchmarks were resolved with respect to the con\u00adjunction of \nthe following correctness conditions: Sequential consistency [15]. If a thread A enqueues a1 and a2, \nthen a1 must be dequeued before a2. Note that is a weaker condition than linearizability [12].  Structural \nintegrity. The queue is not corrupted by concurrent operations. Speci.cally: (1) the head and tail are \nnot null;  (2) prevHead.taken == 1; (3) the tail is reachable from the head; (3) tail.next == null; \n(4) there are no cycles in the queue; (5) no untaken nodes precede taken ones. PSKETCH also enforces \nmemory safety by default: no null point\u00aders may be deferenced, and array accesses must be within bounds. \nIt is worth noting that for queueE2 and queueDE2, we found that we had to use more than one operation \nper thread or more than two threads for veri.cation in order to get solutions that generalized to more \nthreads and more operations per thread. 8.2.2 Sense-reversing barrier Barriers allow multiple threads \nto synchronize at the same program point before continuing. They are dif.cult to implement for a cou\u00adple \nof reasons. First, the last thread to reach the barrier must realize that it is last, then awaken the \nother, waiting threads. Second, barri\u00aders must prevent newly awoken threads from passing through later \nbarrier points. An insight to solving these problem is to separate consecutive barrier points into two \nphases, even and odd; the phase is called the barrier s sense, and reverses after each barrier point \n[10]. The barrier object keeps the global boolean sense, and each thread has a local sense. When a thread \nreaches a barrier point, it either waits until its local sense matches the barrier sense, or if the last \nthread, reverses the barrier sense, awakening the waiting threads. However, this insight is far from \nan implementation. The barrier code requires subtle reasoning about interleaved threads and inter\u00admediatebarrierstates. \nWeclaimthatthe PSKETCH languageiswell suited to capturing the insight behind a sense-reversing barrier. \nBe\u00adlow, we sketch the barrier s next() method. The sketch encodes next() as a soup of operations, to \nbe executed (or not) under some conditions on the barrier state. The synthesizer is left to .nd an implementation \nthat avoids harmful races, deadlocks, and other intricate details. We .rst write the .elds of the Barrier: \n(1) sense, the current phase; (2) senses, the local senses of each thread; and (3) count, the number \nof threads yet to reach the barrier. We de.ne the soup of operations comprising the insight behind next() \nas follows: 1. Update the thread s own sense of the barrier. 2. Atomically decrement the count of threads \nyet to arrive. 3. Under some condition, wait until the barrier sense changes to some predicate of the \nthread s own sense. 4. Under some condition, set the barrier s sense and yet-to-arrive count so as to \nwake up the other threads, and prepare the barrier for the next shot.  Before .nishing the sketch, we \nde.ne under some condition as a PSKETCH generator function that returns a boolean expression of its arguments: \nboolean predicate (a, b, c, d) { return {| (!)? (a==b | (a|b)==?? | c | d) |}; } Now, translating the \noperations above into a sketch is straightfor\u00adward. We make them into a soup by placing them in a reorder \nblock: void next (Barrier b, Thread th) { boolean s = b.senses[th]; s = predicate (0, 0, s, s); int cv \n= 0; boolean tmp = 0; reorder { // (1) Update t s local sense b.senses[th] = s; // (2) Decr. count of \nyet-to-arrive threads cv = AtomicReadAndDecr (b.count); // (3) Wake up other threads, reset barrier tmp \n= predicate (b.count, cv, s, tmp); if (tmp) { reorder { b.count = N; b.sense = predicate (b.count, cv, \ns, s); } } // (4) Wait at barrier tmp = predicate (b.count, cv, s, tmp); if (tmp) { boolean t = predicate \n(0, 0, s, s); atomic (b.sense == t); } } } The benchmark barrier2 is the sketch shown above. The com\u00adpanion \nbarrier1 is a reduced version with a smaller candidate pro\u00adgram space. The barrier s correctness was \nestablished by a client program that ensured that threads always joined properly at each barrier point, \ntogether with the implicit deadlock check performed by PSKETCH. This client program launched N threads \nthat reached a barrier B times. Before waiting at the bth invocation of next(), each thread t set a bit \nreached[t][b]. After passing through the bth call to next(), each thread ensured that its left neighbor \ntl had also reached the bth barrier by asserting reached[t-l][b]. 8.2.3 Finely locked, list-based set \nThis data structure implements the Set data type with a sorted, singly linked list. In a highly concurrent \nsetting, locking the entire list for each add(), remove(), and contains() operation is unac\u00adceptable. \nThe insight behind the .nely locked list is to maintain a sliding window of locks around the nodes being \ntraversed during set operations, to allow concurrent modi.cations to disjoint areas of the list. Implementing \nthis locking scheme, known as hand-over\u00adhand-locking [11], is dif.cult; the programmer must order the \nac\u00adquisition and release of locks while traversing the data structure, keeping in mind deadlocks and \ndata structure corruptions due to concurrent modi.cations. For this list, we sketched a method find (key)that \nreturns cur, the node with a least key greater than or equal to key, and prev, the node greatest key \nless than key. The main loop of the find method was described in Section 4; the sketch left the synthesizer \nto decide which nodes to lock and unlock and under what conditions, and how to order these locking, unlocking, \nand traversal statements. It is straightforward to implement the other data structure methods us\u00ading \nthis find() helper. The benchmark fineset2 is our full sketch, and fineset1 is a reduced version of fineset2. \nThe correctness criteria for these benchmarks were similar to those for the queue* suite, with structural \nchecks speci.c to this structure. 8.2.4 Singly-locked remove() method of lazy list This is a problem \nproposed by [11]. Its basis is a lazily-updated, list-based set data structure due to [9]. The add() \nand remove() methods of this set are optimistic, in that they traverse the data structure without locking. \nOnly when the list is to be modi.ed do they check that the their view of the list is still valid. Both \nadd() and remove() acquire two locks before modifying the list. This problem asks whether the list s \nremove() method can be modi.ed to take only one lock, instead of two (the answer is no ). We translated \nthis problem into a sketch for PSKETCH to solve by .rst removing the lock statements from the original \nremove() method. Next, we gave PSKETCH the freedom to lock any one of a set of nodes at any point in \nthe body of the stripped-down remove(), and likewise for unlock. The correctness criteria for this sketch \nwere the same as for the fineset* benchmarks. When we ran this benchmark with two threads performing \nboth add and remove, the synthesizer returned NO , as expected. Sur\u00adprisingly, PSKETCH was actually able \nto .nd a solution that worked for the case where one thread performs only adds and another thread performs \nonly removes. 8.2.5 Dining philosophers This problem has P philosophers at a circular table, with a \nplate of spaghetti in the center. A philosopher needs two chopsticks to eat. Each philosopher has chopsticks \nat his left and right, but because the table is circular, there are only P total chopsticks. The problem \nis to .nd a chopstick-acquisition policy which avoids deadlock, in which no philosopher can eat; and \nstarvation, in which particular philosophers cannot eat. Thus, we want a resource policy that satis.es \nthe properties (1) some philosopher can always eat; and (2) every philosopher will always eventually \neat. We modeled the problem in PSKETCH as follows: there are P philosophers encoded as a fork(int p; \nP) block, each contend\u00ading for its left and right of P locks. The philosophers attempt to eat T times, \nblocking if they cannot acquire their left and right chop\u00adsticks. The resource acquisition policy was \nsketched as an expres\u00adsion of t, p, P , which indicated whether the right or left chopstick should be \nacquired .rst. The order in which the chopsticks were released was also left unspeci.ed. As to correctness, \nPSKETCH implicitly enforces property (1) above by ensuring that the execu\u00adtion is deadlock free. As we \ndescribed earlier, we can only enforce livenes properties by approximating them as a safety property \nin a bounded execution. Our sketch approximates property (2) by en\u00adsuring that all philosophers are able \nto eat T times in the P * T steps of the execution. With this sketch and this correctness condi\u00adtions, \nthe synthesizer was able to produce a correct implementation of the protocol; a minor variant over the \nstandard solution presented in textbooks [16].  8.3 Performance We tried to synthesize each benchmark \nfor workloads with various numbers of threads and operations, and patterns of operations when possible. \nThe particular tests of the queue*, fineset*, and lazyset benchmarks are labeled with the following scheme: \na test named ed(ed|ed) means that .rst a sequential enqueue e was performed , next a sequential dequeue \nd, and .nally two threads were forked to each perform an enqueue then dequeue (ed|ed). The set tests \nuse the same scheme, with a and r standing for add and remove , respectively. For each test, we gathered \nthe following data: Resolvable whether the sketch could be completed into a correct implementation. \n Itns the number of observations required for CEGIS to termi\u00adnate.  Ssolve, V solve for the synthesizer, \nthe time for its SAT solver to return SAT or UNSAT; for the veri.er, the time for SPIN to complete its \nsearch for a counterexample schedule.  Smodel, Smodel for the synthesizer, the time to build a boolean \nsatis.ability problem; for the veri.er, the time to compile an input model into a veri.cation program. \n Time:Total total elapsed time between invoking PSKETCH and it returning an answer. This time does \nnot equal Ssolve+ Smodel+ V solve+ Smodel because part of the time is spent in our compiler frontend. \n Memory the maximum memory used by the synthesizer, ver\u00adi.er, and PSKETCH. The maximum total memory \nincludes memory used by our Java frontend.  We tested PSKETCH on a laptop with a 2 GHz Core 2 Duo processor \nand 2 GB of RAM, running version 2.6.20-16 of the Linux kernel. The results are tabulated in Figure 9. \nThe data in Figure 9 reveal a few interesting trends. First, there is an approximately linear correlation \nbetween the log of the size of the candidate space C and number of iterations before .nding a solution, \nas observed in a sequential sketch synthesizer [20]. We have plotted log C against number of iterations \nin Figure 10, for se\u00adlected tests. Second, neither synthesis nor veri.cation clearly dom\u00adinated the total \nsolution time across the test suite, though veri.\u00adcation tended to be more expensive. Third, we see that \nfor each benchmark, changing the number of threads or the methods called on each thread had a big effect \non veri.cation times, but synthesis stayed fairly constant. A fourth trend is the large amount of time \nneeded to generate and compile the SPIN veri.ers, which domi\u00adnated the total time for several tests. \n 8.3.1 Limitations PSKETCH s most severe limitation is that it only guarantees cor\u00adrectness of synthesized \nprograms with respect to safety properties, up to a bounded number of executed instructions. However, \nwe be\u00adlieve that with future work, PSKETCH can handle liveness prop\u00aderties. A second limitation is that \nPSKETCH only returns a single correct implementation of a sketch. In many contexts, one wishes to .nd \nall correct solutions, then search these for an optimal one (e.g., with autotuning [6]). The CEGIS algorithm \ncan trivially produce multiple correct candidates, but future research might additionally guide its search \nby optimality criteria. PSKETCH is also hampered by engineering limitations, mostly due to the delicate \nconnection between the SPIN veri.er and the SAT synthesizer. As mentioned above, for some programs we \nsaw a large discrepancy between the time needed to verify the unsim\u00adpli.ed models emitted by PSKETCH \nand hand-simpli.ed versions of the same models. Applying traditional compiler optimizations to these \nmodels was dif.cult, because they threatened to upset the correlation of counterexamples between SPIN \nand our synthesizer. Another practical problem was the large overhead of compiling SPIN veri.ers, which \nwere C programs with up to tens of thou\u00adsands of lines of code. Both problems are amenable to better \nengi\u00adneering. Synthesizing data structures that are correct with respect to linearizability is a future \ngoal. Our current CEGIS algorithm can synthesize and verify data structures with respect to linearizability \ncriteria, but it is dif.cult to embed these criteria in sketches. We believe that this problem can be \nsolved with richer speci.cations in the PSKETCH language.  9. Related Work In previous work we have \nproposed sketching as a methodology for developing ef.cient algorithms from a low-level outline thereof. \nThis line of work proved useful for writing bit-streaming pro\u00adgrams [19] and was later extended to work \nfor arbitrary .nite computations [20] and unbounded stencil computations [18]. The sketching approach \nis related to earlier research in control infer\u00adence, including foundational work on Prolog [14], as \nwell as efforts in the .eld of AI for determinizing an agent s behavior via learn\u00ading techniques [3]. \nAlternatively, transformational synthesis frame\u00adworks (e.g., [8, 17]) are largely domain-speci.c and \napply sepa\u00adrately provided programmer insights through an interactive synthe\u00adsis process. Synthesis of \nConcurrent Algorithms. While computer-aided veri.cation of concurrent programs has gained signi.cant \nmomen\u00ad queueE1 Test ed(ee|dd) ed(ed|ed) (e|e|e)ddd Resolvable yes yes yes Itns 1 1 1 Total 8.79 9.24 \n13 Ssolve 0.01 0.02 0.05 Time (s) Smodel 0.04 0.04 0.12 Vsolve 0.07 0.86 5.67 Vmodel 5.55 6.1 5.05 Maximum \nMemory (MiB) Total Smem Vmem 54.41 13.72 5.13 67.04 13.73 8.25 72.81 17.54 31.69 queueDE1 ed(ee|dd) ed(ed|ed) \nyes yes 4 4 46.97 64.18 2.63 5.27 4.76 7.98 0.32 7.09 31.95 33.76 135.51 172.92 54.7 66.73 6.69 22.31 \nqueueE2 ed(ed|ed) (e|e|e)ddd yes yes 5 8 114.7 249.2 16.22 44.74 9.93 23.3 5.32 104.59 71.98 60.98 171.69 \n213.69 69.31 92.64 17.63 114.69 queueDE2 ed(ed|ed) yes 10 3091.37 2676.07 147.07 16.28 184.72 489.26 \n313.2 30.13 barrier1 N = 3, B = 2 N = 3, B = 3 yes yes 4 8 49.74 120.21 0.11 0.39 0.57 2.37 37.3 97.03 \n8.07 14.69 177.31 398.19 17.54 19.85 130.31 331.06 barrier2 N = 2, B = 3 yes 9 66.46 4.375 13.613 1.272 \n35.243 153.67 54.73 10.70 fineset1 ar(ar|ar) ar(ar|ar|ar) ar(a|r|a|r) ar(arar|arar) ar(aaaa|rrrr) yes \nyes yes yes yes 2 1 1 1 2 130.44 363.89 196.52 165.43 225.54 2.5 0.56 0.73 0.66 8.63 4.21 1.03 1.25 1.26 \n12.94 2.55 279.02 112.02 80.02 74.12 110.97 74.29 73.86 73.85 111.07 161.14 249 153.56 259.25 345.62 \n55.46 29.03 29.17 29.14 156.81 23.88 169.38 73.88 136.38 145.75 fineset2 ar(ar|ar) ar(ar|ar|ar) ar(a|r|a|r) \nar(arar|arar) ar(aaaa|rrrr) yes yes yes yes yes 3 3 2 2 3 281.46 795.19 384.83 299.97 468.7 13.41 12.95 \n11.57 4.85 40.86 15.17 20.58 13.7 6.33 46.3 4.03 509.59 170.42 99.82 107.69 229.24 232.38 171.1 174.01 \n228.61 260.14 376.63 325.26 346.56 563.1 123.77 149.32 169.07 75.68 287.41 34.81 233.44 95.75 212.94 \n227 lazyset ar(aa|rr) ar(ar|ar) yes NO 12 7 179.17 100.24 5.32 1.88 16.6 5.41 11.43 2.51 107.4 66.49 \n294.03 246.81 54.28 41.87 11.38 9.81 dinphilo N = 3, T = 5 N = 4, T = 3 N = 5, T = 3 yes yes yes 4 3 \n3 34.03 54.46 745.94 4.34 1.96 3.06 4.39 2.23 2.99 6.22 36.11 724.5 12.61 9.93 10.2 194.08 158.69 1419.5 \n114.33 53.15 83.98 19.19 78.75 1340.31 Figure 9. Performance results. tum in recent years, the automated \nsynthesis of concurrent algo\u00adrithms is a relatively new research direction, and most of the pre\u00advious \nwork in the .eld is designed for synthesis within in a spe\u00adci.c domain of algorithms (e.g., [5]). Notable \nin this context is the recent work on synthesis of concurrent garbage collectors by Vechev et al.. In \nan earlier work [23] the authors apply an auto\u00admated transformational-style space exploration to derive \nprovably correct variants from a basic (correct) concurrent GC implemen\u00adtation. In a more recent work \n[24] an exhaustive exploration pro\u00adcedure is applied to a space of implementationstion variants with \nvarying degrees of atomicity and instruction reordering, and com\u00adbined with effective pruning of vacuously \nincorrect implementa\u00adtion sub-spaces. In this approach the authors deploy a separate veri.cation procedure \nbased on the SPIN model checker [13] to check the absence of concurrency bugs in each of the generated \ncandidate implmenetations. Their framework, unlike ours, is capa\u00adble of verifying concurrent implementations \nthat manipulate arbi\u00adtrary unbounded data structures, thanks to the use of abstraction in the veri.cation \nprocedure. This, however, is not an inherent lim\u00aditation of our approach and the use of abstraction-capable \nveri\u00ad.ers is a work in progress. Also, the generation method used in their approach heavily depends on \ntailored semantic rules to prune the search space effectively, and is restricted to a prede.ned set of \nconcurrency-related transformations and synchronization prim\u00aditives. In contrast, our synthesizer applies \ngeneric transformations to reduce the problem into its 2QBF representation and delegates the effort of \nconducting an effective search to an ef.cient, general purpose SAT-based solver. Veri.cation of Concurrent \nData Structures. Particular con\u00adcurrent data structures are often checked for correctness using au\u00adtomated \nprovers. Examples include the veri.cation of a prominent wait-free concurrent set implementation [9, \n22]. Such efforts often rely on massive proof scripts and associated domain-speci.c logic (e.g., in PVS \nor some other proof system) that need to be writ\u00adten per veri.cation task. In contrast, our framework \ncan be used to synthesis and automatically verify arbitrary concurrent implemen\u00adtations with only few \nassumptions about the underlying execution model. CheckFence [7] is a tool that can .nd subtle concurrency \nbugs occurring under various memory consistency models and gen\u00aderates a counter example that can be used \nto infer the apporpriate .x (i.e., adding memory fences to enforce consistency). Similar to our approach, \nchecking an imperative concurrent program is reduced to a SAT problem, and as such bears similar limitations. \nIt is dif\u00adferent from ours in the way that imperative programs are encoded into Boolean circuits. In \nrecent work [2], verifying linearizability of concurrent heap-manipulating algorithms was done using \n3-valued logic abstraction. Here, an abstract interpreter (TVLA) was applied to capture the (.nite) differences \nbetween states exhibited by two implementations of the same data structure, and to verify their uni\u00ad.cation \nat linearization points. Although sound and highly expres\u00adsive, this framework requires apriori knowledge \nof the linearization points in a concurrent implementation, and is known to have inher\u00adent scalability \nproblems due to the size of the abstract domain that is being used.  10. Conclusion The paper describes \na new sketch synthesizer for the development of concurrent programs, with an emphasis on concurrent data \nstruc\u00adtures. Sketching affords the programmer the same .ne control over the structure of the resulting \nprogram as manual coding, while at the same time allowing him to leave unspeci.ed those parts of the \nprogram which are hard to derive by hand. Our system relies on a CEGIS algorithm to generate candidate \nimplementations by analyzing traces of failed implementations to try to prevent the new candidates from \nexhibiting the same bugs. To our knowledge, ours is the .rst synthesizer capable of using counterexample \ntraces from failed concurrent programs to guide the search for a correct implementation. We implemented \nPSKETCH relying on the SPIN veri.er and the SKETCH synthesis infrastructure. With the system, we have \nsketched and synthesized concurrent data structures including a Lock-free queue, and a list with hand-over-hand \nlocking. In each of these programs, the tricky fragments were exclusively sketched and successfully synthesized. \nAcknowledgment We want to thank Gilad Arnold for his help with preparation of the submission manuscript. \nThis paper was in.uenced by the many discussions we had with Martin Vechev, Eran Yahav, and Mooly Sagiv. \nWe are grateful to the anonymous referees for their helpful comments. This work is supported in part \nby the National Science Foundation with grants CCF-0085949, CNS-0326577, and CNS\u00ad0524815, a generous \ngift from IBM Corporation, an IBM Fellow\u00adship, and the University of California MICRO program.  References \n[1] J. R. Allen, K. Kennedy, C. Porter.eld, and J. Warren. Conversion of control dependence to data dependence. \nIn POPL 83: Proceedings of the 10th ACM SIGACT-SIGPLAN symposium on Principles of programming languages, \npages 177 189, New York, NY, USA, 1983. ACM. [2] D. Amit, N. Rinetzky, T. Reps, M. Sagiv, and E. Yahav. \nComparison under abstraction for verifying linearizability. In CAV 07: 19th International Conference \non Computer Aided Veri.cation, volume 4590, pages 477 490. Springer, 2007. [3] D. Andre and S. Russell. \nProgrammable reinforcement learning agents. Advances in Neural Information Processing Systems, 13, 2001. \nMIT Press. [4] D. Angluin and C. H. Smith. Inductive inference: Theory and methods. ACM Comput. Surv., \n15(3):237 269, 1983. [5] Y. Bar-David and G. Taubenfeld. Automatic discovery of mutual exclusion algorithms. \nIn PODC 03: Proceedings of the twenty\u00adsecond annual symposium on Principles of distributed computing, \npages 305 305, New York, NY, USA, 2003. ACM. [6] J. Bilmes, K. Asanovic, C.-W. Chin, and J. Demmel. Optimizing \nmatrix multiply using phipac: A portable, high-performance, ansi c coding methodology. In International \nConference on Supercomputing, pages 340 347, 1997. [7] S. Burckhardt, R. Alur, and M. M. K. Martin. Checkfence: \nchecking consistency of concurrent data types on relaxed memory models. In PLDI 07: Proceedings of the \n2007 ACM SIGPLAN conference on Programming language design and implementation, volume 42, pages 12 21, \nNew York, NY, USA, 2007. ACM. [8] B. Fischer and J. Schumann. Autobayes: a system for generating data \nanalysis programs from statistical models. Journal of Functional Programming, 13(3):483 508, May 2003. \n[9] S. Heller, M. Herlihy, V. Luchangco, M. Moir, W. N. S. III, and N. Shavit. A lazy concurrent list-based \nset algorithm. In OPODIS 05: 9th International Conference on Principles of Distributed Systems, volume \n3974, pages 3 16. Springer, 2005. [10] D. Hensgen, R. Finkel, and U. Manber. Two algorithms for barrier \nsynchronization. International Journal of Parallel Programming, 17(1):1 17, 1988. [11] M. Herlihy and \nN. Shavit. The art of multiprocessor programming. Morgan Kaufmann, 2008. [12] M. P. Herlihy and J. M. \nWing. Linearizability: a correctness condition for concurrent objects. ACM Trans. Program. Lang. Syst., \n12(3):463 492, 1990. [13] G. J. Holzmann. The model checker SPIN. Software Engineering, 23(5):279 295, \n1997. [14] R. Kowalski. Algorithm = logic + control. Commun. ACM, 22(7):424 436, 1979. [15] L. Lamport. \nHow to make a multiprocessor computer that correctly executes multiprocess programs. IEEE Transactions \non Computers, 28(9):690 691, 1979. [16] A. Silberschatz and P. B. Galvin. Operating System Concepts. \nJohn Wiley &#38; Sons, Inc., New York, NY, USA, 2000. [17] D. R. Smith. KIDS: A semiautomatic program \ndevelopment system. IEEE Transactions on Software Engineering, 16(9):1024 1043, 1990. [18] A. Solar-Lezama, \nG. Arnold, L. Tancau, R. Bodik, V. Saraswat, and S. Seshia. Sketching stencils. In PLDI 07: Proceedings \nof the 2007 ACM SIGPLAN conference on Programming language design and implementation, volume 42, pages \n167 178, New York, NY, USA, 2007. ACM. [19] A. Solar-Lezama, R. Rabbah, R. Bodik, and K. Ebcioglu. Pro\u00adgramming \nby sketching for bit-streaming programs. In PLDI 05: Proceedings of the 2005 ACM SIGPLAN conference on \nProgramming language design and implementation, pages 281 294, New York, NY, USA, 2005. ACM Press. [20] \nA. Solar-Lezama, L. Tancau, R. Bodik, V. Saraswat, and S. Seshia. Combinatorial sketching for .nite programs. \nIn ASPLOS 06, San Jose, CA, USA, 2006. ACM Press. [21] A. Solar-Lezama, L. Tancau, R. Bodik, V. Saraswat, \nand S. Seshia. Combinatorial sketching for .nite programs. In 12th International Conference on Architectural \nSupport for Programming Languages and Operating Systems (ASPLOS 2006), pages 404 415, New York, NY, USA, \n2006. ACM Press. [22] V. Vafeiadis, M. Herlihy, T. Hoare, and M. Shapiro. Proving correctness of highly-concurrent \nlinearisable objects. In PPoPP 06: Proceedings of the eleventh ACM SIGPLAN symposium on Principles and \npractice of parallel programming, pages 129 136, New York, NY, USA, 2006. ACM. [23] M. T. Vechev, E. \nYahav, and D. F. Bacon. Correctness-preserving derivation of concurrent garbage collection algorithms. \nIn PLDI 06: Proceedings of the 2006 ACM SIGPLAN conference on Programming language design and implementation, \npages 341 353, New York, NY, USA, 2006. ACM. [24] M. T. Vechev, E. Yahav, D. F. Bacon, and N. Rinetzky. \nCgcexplorer: a semi-automated search procedure for provably correct concurrent collectors. In PLDI 07: \nProceedings of the 2007 ACM SIGPLAN conference on Programming language design and implementation, pages \n456 467, New York, NY, USA, 2007. ACM. \n\t\t\t", "proc_id": "1375581", "abstract": "<p>We describe PSketch, a program synthesizer that helps programmers implement concurrent data structures. The system is based on the concept of sketching, a form of synthesis that allows programmers to express their insight about an implementation as a partial program: a sketch. The synthesizer automatically completes the sketch to produce an implementation that matches a given correctness criteria.</p> <p>PSketch is based on a new counterexample-guided inductive synthesis algorithm (CEGIS) that generalizes the original sketch synthesis algorithm from Solar-Lezama et.al. to cope efficiently with concurrent programs. The new algorithm produces a correct implementation by iteratively generating candidate implementations, running them through a verifier, and if they fail, learning from the counterexample traces to produce a better candidate; converging to a solution in a handful of iterations.</p> <p>PSketch also extends Sketch with higher-level sketching constructs that allow the programmer to express her insight as a \"soup\" of ingredients from which complicated code fragments must be assembled. Such sketches can be viewed as syntactic descriptions of huge spaces of candidate programs (over 10<sup>8</sup> candidates for some sketches we resolved).</p> <p>We have used the PSketch system to implement several classes of concurrent data structures, including lock-free queues and concurrent sets with fine-grained locking. We have also sketched some other concurrent objects including a sense-reversing barrier and a protocol for the dining philosophers problem; all these sketches resolved in under an hour.</p>", "authors": [{"name": "Armando Solar-Lezama", "author_profile_id": "81100173160", "affiliation": "UC Berkeley, Berkeley, CA, USA", "person_id": "P1022762", "email_address": "", "orcid_id": ""}, {"name": "Christopher Grant Jones", "author_profile_id": "81350597582", "affiliation": "UC Berkeley, Berkeley, CA, USA", "person_id": "P1022763", "email_address": "", "orcid_id": ""}, {"name": "Rastislav Bodik", "author_profile_id": "81100033082", "affiliation": "UC Berkeley, Berkeley, CA, USA", "person_id": "P1022764", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1375581.1375599", "year": "2008", "article_id": "1375599", "conference": "PLDI", "title": "Sketching concurrent data structures", "url": "http://dl.acm.org/citation.cfm?id=1375599"}