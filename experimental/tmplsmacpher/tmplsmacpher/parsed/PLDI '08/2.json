{"article_publication_date": "06-07-2008", "fulltext": "\n Immix:AMark-Region Garbage Collector with Space Ef.ciency,Fast Collection, and MutatorPerformance * \n Stephen M. Blackburn Australian National University Steve.Blackburn@anu.edu.au Abstract Programmers \nare increasingly choosing managed languages for modern applications, which tend to allocate manyshort-to-medium \nlived small objects. Thegarbage collector therefore directly deter\u00admines program performance by making \na classic space-time trade\u00adoffthatseekstoprovidespaceef.ciency,fast reclamation,andmu\u00adtator performance. \nThe three canonical tracinggarbage collectors: semi-space, mark-sweep, and mark-compact each sacri.ce \none ob\u00adjective. This paper describesa collectorfamily, called mark-region, and introduces opportunistic \ndefragmentation, which mixes copy\u00ading and marking in a single pass. Combining both, we implement immix,anovel \nhigh performancegarbage collector that achieves all three performance objectives.Thekeyinsightisto allocateand \nre\u00adclaim memory in contiguous regions, at a coarse block grain when possible and otherwise in groups \nof .ner grain lines. We show that immix outperforms existing canonical algorithms, improving total application \nperformance by 7 to 25% on average across 20 benchmarks.As the mature spaceina generational collector, \nim\u00admix matches or beats a highly tuned generational collector, e.g. it improves jbb2000 by 5%. These \ninnovations and the identi.cation ofa newfamilyof collectors open new opportunities forgarbage collector \ndesign. Categories and Subject Descriptors D.3.4 [Programming Lan\u00adguages]: Processors Memory management \n(garbage collection)GeneralTerms Algorithms, Experimentation, Languages, Performance, Measurement Keywords \nFragmentation, Free-List, Compact, Mark-Sweep, Semi-Space, Mark-Region, Immix, Sweep-To-Region, Sweep-To-Free-List \n1. Introduction Modern applications are increasingly written in managed lan\u00adguages and make con.icting \ndemands on their underlying mem\u00adory managers.Forexample, real-time applications demand pause\u00adtime guarantees, \nembedded systems demand space ef.ciency, and servers demand high throughput. In seeking to satisfy these \nde\u00admands, the literature includes reference counting collectors and three canonical tracing collectors: \nsemi-space, mark-sweep, and mark-compact. These collectors are typically used as building blocks for \nmore sophisticated algorithms. Since reference count\u00ading is incomplete, we omit it from further consideration \nhere. Un\u00adfortunately,the tracing collectors each achieve only two of: space * This work is supported \nby ARC DP0666059, NSF CNS-0719966, NSF CCF\u00ad0429859, NSF EIA-0303609,DARPAF33615-03-C-4106, Microsoft, \nIntel, and IBM. Anyopinions, .ndings and conclusions expressed herein are the authors and do not necessarily \nre.ect those of the sponsors. Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page.To \ncopyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 08, June 7 13, 2008,Tucson, Arizona, USA. Copyright . 2008ACM 978-1-59593-860-2/08/06... \n$5.00 c Kathryn S. McKinley TheUniversityofTexasat Austin mckinley@cs.utexas.edu ef.ciency, fast collection, \nand mutator performance through con\u00adtiguous allocation of contemporaneous objects. Figure1starkly illustrates \nthis dichotomy for full heapversions of mark-sweep (MS), semi-space (SS), and mark-compact (MC) implemented \nin MMTk [12], running on a Core 2 Duo. It plots the geometric mean of total time, collection time, mutator \ntime, and mutator cache misses as a function of heap size, normalized to the best, for 20 DaCapo, SPECjvm98, \nand SPECjbb2000 bench\u00admarks, and shows 99% con.dence intervals. The crossing lines in Figure 1(a) illustrate \nthe classic space-time trade-offat the heart of garbage collection. Mark-compact is uncompetitive in \nthis setting due to its overwhelming collection costs. In smaller heap sizes, the space and collector \nef.ciency of mark-sweep perform best since the overheads of garbage collection dominate total performance. \nFigures 1(c) and 1(d) show that the primary advantage for semi\u00adspaceis 10% better mutatortime compared \nwith mark-sweep, due to bettercache locality.Oncetheheapsizeislargeenough,garbage collection time reduces, \nand the locality of the mutator dominates total performance so semi-space performs best. To explain this \ntradeoff, we need to introduce and slightly ex\u00adpand memory management terminology.Atracinggarbage collec\u00adtor \nperforms allocation of new objects, identi.cation of live ob\u00adjects, and reclamation of free memory. The \ncanonical collectors all identify live objects the same way, by marking objects during a transitive closure \nover the object graph. Reclamation strategy dictates allocation strategy, and the litera\u00adture identi.es \njust three strategies: (1) sweep-to-free-list, (2)evacu\u00adation, and (3) compaction.For example, mark-sweep \ncollectors al\u00adlocatefromafreelist,markliveobjects,andthen sweep-to-free-list  (a)TotalTime (b) Garbage \nCollectionTime  (c) MutatorTime (d)MutatorL2 Misses Figure 1. PerformanceTradeoffsFor Canonical Collectors: \nGeo\u00admetric Mean for 20 DaCapo and SPEC Benchmarks. puts reclaimed memory back on the free list [30, 29, \n24]. Because mark-sweepcollectionis non-moving,itistimeandspaceef.cient, but cannot provide locality \nfor contemporaneously allocated ob\u00adjects. Semi-space, older-.rst,garbage-.rst, and others evacuate by \nmoving all live objects to a new space, reclaiming the old space en masse[19,9,4,26,36,17,22]. Mark-compact,the \ncompressor,and others compact by moving all live objects to one end of the same space, reclaiming the \nunused portion en masse [37, 20, 28, 33]. Evacuation and compaction strategies provide contiguous alloca\u00adtion, \nwhich puts contemporaneously allocated objects next to each otherin space,andthusoffergood mutator locality.However,evac\u00aduation \nincursa2 \u00d7 spaceoverheadand in-place compactionistime inef.cient because it requires multiple passes \nover the heap. This paper identi.es the mark-region family of non-moving tracing collectors. Mark-region \nuses the sweep-to-region strategy, which reclaims contiguous free regions and thus provides contigu\u00adous \nallocation.To reduce fragmentationinmark-region and other non-moving collectors, this paper introduces \nopportunistic defrag\u00admentation which mixes copying and marking in a single pass. Us\u00ading these building \nblocks, we introduce immix, a novel high per\u00adformancegarbage collector that combines mark-region with \noppor\u00adtunistic defragmentationto achievespaceef.ciency,fast collection, and contiguous allocation for \nmutator performance. In a mark-region collector, region size embodies the collector s space-time tradeoff. \nLarge contiguous regions maximize mutator performance and minimize collection cost,but are space inef.cient \nsince a single object can withhold an entire region. Small regions increase spaceef.ciencybut increase \ncollection time, reduce muta\u00adtor performance, and make placement of large objects harder. Im\u00admix balances \nthese concerns by preferentially managing memory at a coarse block grain andfalling back toa .ne line \ngrain when necessary. Immix reclaims completely free 32KB .xed size blocks, and groups of free 128B lines \nin partially populated blocks. Immix contiguously allocates objects in empty and partially .lled blocks. \nImmix addresses fragmentation, a problem for all non-moving collectors, with demand-driven, opportunistic \nevacuation. When defragmentation is necessary, immix chooses source blocks (to evacuate) and target blocks \n(to allocate into) prior to collection. It evacuates objects from source blocks, leaving forwarding pointers. \nEvacuation is opportunistic because if immix runs out of space, it stopsevacuating.Ifan objectis pinnedbythe \napplicationorisona target page, immix simply marks the object, leaving it in place. Weevaluateimmixasafullheap \ncollectorandintwocomposite collectors. Comprehensive performance measurements show that immix consistently \noutperforms the best of the canonical collectors by 5 to 25% in total performance on average across many \nheap sizes, rarely degrades performance, and improves one benchmark by 75%.To measure space ef.ciency, \nwe compute the minimum heap size in which each algorithm executes. Immix requires on average only 3% \nmore memory than mark-compact, and it requires 15% less than mark-sweep. Furthermore, it matches the \nmutator locality of semi-space and the collection time of mark-sweep. Webuildagenerational collector \nwith anevacuating semi-space nursery and an immix mature space. Although we did not tune im\u00admix for the \nmature space, this collector performs slightly better on 20 benchmarks than an evacuating semi-space \nnursery and mark\u00adsweep mature space, JikesRVM s best performing production gen\u00aderational collector. However,it \nsigni.cantly improves several inter\u00adesting benchmarks, e.g., total time for SPECjbb2000 improves by 5% \nor more on all heap sizes we tested.We also design and im\u00adplement an in-place generational variant based \non the stickymark bits algorithmof Demmersetal.to supportpinning[21].Wemade these collectors publiclyavailablein \nJikesRVM. These results showthat mark-region collectorscoupled with de\u00adfragmentation offer an interesting \ndirection for further exploration. 2. RelatedWork Researchers have previously addressed the tension between \nmuta\u00adtor performance, collection speed, and space ef.ciency. However, we are unawareofanypublishedwork \nwhich describesorevaluates a mark-region collector.We de.ne mark-region and the sweep-to\u00adregion strategyon \nwhichitis based.We implementandprovidede\u00adtailed analysis of immix, a high performance collector which \ncom\u00adbines mark-region collection and opportunistic defragmentation. Mark-Region Collectors. We believe \nthat there are two previous implementations of mark-region collectors, a JRockit [11] collec\u00adtor and \nan IBM [18] collector. Our descriptions here are based on web sites where neither are described in detail \nor evaluated, and the original JRockit web site is no longer available. The JRockit collector uses a \nrange of coarse grain block sizes, and only recy\u00adcles completely free blocks for allocation.To limit \nfragmentation, it compacts a fraction of the blocks at every garbage collection, incurring multi-pass \noverheads for that fraction of the heap. The IBM collector uses thread local heaps (TLH), which are unsynchronized,variable-sized,bump-allocated \nregions witha minimum size of 512 bytes [18]. The allocator uses a TLH for ob\u00adjects smaller than 512 \nbytes, and for larger objects only when they .t in the current TLH. The collector uses a global synchronized \nfree list to allocate both TLHs and large objects. The allocation andmarkphaseeach usebitvectorsatan8byte \nresolution.When the allocator .lls a TLH, it scans the TLH and records the start positions of each of \nthe objects in the allocbits bit vector. Immix does not use allocation bits, which impose avoidable overhead. \nThe mark phase records live objects in a markbits vector, which requires synchronization that immixavoids. \nThe sweep phase com\u00adpares the markbits and allocbits vectors to identify free memory. The collector places \ncontiguous free memory greater than 512 bytes on the free list for subsequent use as either a TLH or \nlarge object. It does not recycle dark matter , regions less than 512B. Immixdiffersina numberofregards.Our \nmetadataoverheadis lower (0.8% compared to 3.1%). The IBM collector requires 8-byte alignment and an \nextra header word in each object that stores the object size (typically around 10% space overhead). Immix \nis struc\u00adtured around aligned 128B lines and 32KB blocks, and can reclaim space at 128B granularity. \nThe IBM collector does not reclaim re\u00adgions smallerthan512B,butcan apparently reclaimspaceat8byte alignment. \nThe IBM collector addresses fragmentation using com\u00adpaction, describedby Borman [18] as complex , while \nimmix uses evacuation to achieve lightweight and opportunistic defragmenta\u00adtion. The IBM mark-region \ncollector and its derivatives have been referred to in publications [10, 28],but to date have not been \nde\u00adscribed or evaluated in a publication. Mark-Sweep Variants. Spoonhower et al. [34] take a differ\u00adent \napproach, developing a collector which dynamically applies mark-sweep and semi-space policies to regions \nof the heap, us\u00ading page residency counts. Immix applies mark-region uniformly to all of memory.Vam [24] \nis designed to provide contiguous al\u00adlocation when possible for non-moving explicit memory manage\u00adment. \nIf a block becomes fragmented, Vam must revert to size\u00adsegregated free-lists which make no guarantees \nabout locality. The Metronome real-timegarbage collector attains pause time guaran\u00adtees, space guarantees, \nand collector ef.ciencyusing mark-sweep, but not mutator locality [8, 7]. Metronome s mostly non-copying \non-demand defragmentation is most similar to immix s defrag\u00admentation. However, it requires exact fragmentation \nstatistics for each size-segregated block from a previous collection to evacuate objects from one block \nto another. Whereas, opportunistic defrag\u00admentation adds the ability to evacuate as dynamically possible \nand without .rst computing precise fragmentation statistics.  Figure 2. Immix Heap Organization Space \nEf.ciency and Contiguous Allocation. Approaches to im-3.1 Ef.cient Mark-Region Design prove the space \nef.ciencyof contiguous heap organization, such as mark-compact, MC2, and copy size reduction [1, 20, \n33, 31], all may substantially increasegarbage collection costs. Thegarbage\u00ad.rst collector [22] bump \nallocates into empty 1MB .xed sized regions. Each collection selectively evacuates the most fragmented \nregions. It relies on a concurrent tracing collector to identify garbage and bi-directional remembered \nsets to evacuate regions in arbitrary order. Although Kermany and Petrank introduced an ef.cient two \npass compaction algorithm [28] which uses a single compact pass after a mark pass, immix opportunistic \nevacuation performs defragmentation in one pass, the mark pass. Immix then performs a separate sweep \npass to .nd free blocks. Immix always performs .ne-grained line sweeps lazily.Kermanyand Petrank im\u00adplemented \nin Jikes RVM, but their source is not available. They show improvementsover mark-sweepbut are not competitive \nwith JikesRVM s high performance generational production collector, except on one benchmark, jbb2000.We \nmatch and sometimes out\u00adperform the Jikes RVM production collector even with our full heap algorithm. \nThree immix variants, including the most simple full heap algorithm, substantially outperform JikesRVM \ns produc\u00adtion collector on jbb2000 (see Figure 4(c)). Generational Collectors. High performance generational \ncol\u00adlectors resolve the tensions between reclamation strategies with composite algorithms. State-of-the-art \ncollectors use an evacuating nursery that provides mutator locality to the young objects, and typically \na mark-compact or mark-sweep mature space for col\u00adlection and space ef.ciency, together with occasional \nmature space compaction [11]. However,some application domains, such as real\u00adtime, have yet to bene.t \nmuch from generational collection [25]. 3. Immix: Mixing Locality, Speed, and Ef.ciency A naive mark-region \nimplementation is straightforward. Memory is divided into .xed sized regions, each of which is either \nfree or unavailable. The allocatorbump allocates into free regions until all free regions are exhausted, \ntriggering a collection. The collector marks any region containing a live object as unavailable and all \nothers as free. Objects may not span regions. This simple algorithm motivates the design of immix and \nraises two questions: (1) How big should the regions be? Large regions are space-inef.cient since a single \nsmall object can withhold an entire region, while small regions increase space ef.ciency but increase \ncollection time. (2) How to defragment? An entire region is unavailable as long as any object within \nit remains alive, so defragmentation is essential. Immix addresses the dilemma of region sizing by operating \nat twolevels, coarse grained blocks and .ne grained lines.Byreclaim\u00ading at line granularity, it recycles \npartially used blocks. When the allocator recycles a block, it skips over unavailable lines, allocat\u00ading \ninto contiguous free lines. Objects may span lines,but cannot span blocks. Immix addresses fragmentation \nby using lightweight opportunistic evacuation, which is folded into marking when de\u00adfragmentation is \nnecessary, as described in Section 3.2. The base mark-region algorithm used by immix is quite simple. \nInitial Allocation. All blocks are initially empty.Athread-local allocator obtains an empty block from \nthe global allocator, and bump allocates objects into the block. When the allocator exhausts the block, \nit requests another block and repeats until the entire heap is exhausted, which triggers a collection. \nIdenti.cation. The collector tracestheliveobjectsbyperforming a transitive closure starting with the \napplication roots. As immix traces the object graph, it marks objects and lines in a line map. Reclamation. \nWhen immix completes the trace, it performs a coarse-grained sweep, linearly scanning the line map and \nidenti\u00adfying entirely free blocks and free lines in partially free blocks. It returns entirelyfreeblockstoaglobalpool,andit \nrecyclespartially free blocks for the next phase of allocation. Steady State Allocation. Threads resume \nallocation into recycled blocks, provided on demand, in address order, and skip over com\u00adpletely full \nand completely empty blocks. The thread-local alloca\u00adtorlinearly scansthelinemapofeachrecycledblockuntilit.ndsa \nhole (one or more contiguous free lines). The allocator thenbump allocatesintothathole.Onceitexhauststhehole,theit \ncontinuesits linearscanfor anotherholeuntilitexhauststherecyclableblock.It then requests another block. \nOnce the allocators have exhausted all recyclable blocks, theyallocate into empty blocks until the entire \nheap is exhausted. Figure 2 illustrates the basic immix heap organization during steady state allocation. \nJust likeasemi-space allocator,the allocator maintains a cursor and a limit, as shown in the .gure, pointing \ninto block .ve. The limit for immix is either the next occupied line, or the end of the block. When the \ncursor would exceed the limit, immix .nds the next hole in the block, and resets the cursor and the limit. \nIf there is no hole, it requests another block. 3.1.1 Mark-Region Details andPolicies The above algorithm \nis relatively easy to implement. However, we found that for high performance over a wide range of workloads, \nwe needed to consider and tune the following policies and mecha\u00adnisms. RecyclingPolicy. At the end of \na collection, each block is either free, recyclable, or unavailable. The collector marks a partly used \nblock with at least F freelinesas recyclable.Weexploredvarious thresholds for immix but found that the \nmost simple policy of F= 1workedbest. Section5.4showsthattheoverheadofrecycling blocks with few available \nlines is only incurred regularly when space is very scarce, which is precisely when such diligence is \nrewarded. AllocationPolicy. Immix allocates into recyclable blocks in ad\u00address order. It saves allocating \ninto completely free blocks until last because multiple consumers may compete for free blocks and they \noffer more .exibility.For instance, the thread-local allocators and the LOS (large object space) compete \nfor pages. The LOS requires completely free pages. Inspired by prior work [36, 17, 22], we ex\u00adplored \nother allocation orderings in an effort to maximize the like\u00adlihood of reclaiming completely free blocks \nat collection time. In the full heap setting, we found the simple address order process\u00adingworked best.We \ndid not revisit these policies fora generational setting and believe theyare an interesting avenue for \nfuture work. Parallelism. Our immix implementations are parallel. Theysup\u00adport multiple collector threads \nand multiple mutator threads. Our implementations however do not perform concurrent collection in whichthe \nmutatorand collectorexecutein parallel.Toachievescal\u00adable parallel allocation and collection throughout \nimmix, we follow adesign pattern common to manysystems. The design pattern max\u00adimizesfast, unsynchronized \nthread-local activities and minimizes synchronized global activities. Thus, the synchronized global allo\u00adcator \ngives blocks to the thread-local allocators (TLA), which are unsynchronized. Similarly, our base mark-region \ncollector requires hardly anysynchronization. The transitive closure is performed in parallel. It allows \nraces to mark objects since at worst an object will be marked and scanned more than once. Since updating \nnearby bits in a bitmap can generate a race, we use bytes to represent line marks, incurringa 1/128 metadataoverhead,butavoiding \nsynchro\u00adnization. Immix performs coarse-grained sweeping in parallel by dividing the heap among the available \ncollector threads. Our eval\u00aduation demonstrates that immix performs very well on uniproces\u00adsorsandatwo-way \nmachine,butweleaveto futureworka detailed study of parallelism. Demand Driven Over.ow Allocation. We \nfound in an early de\u00adsign that the allocator occasionally skipped over and wasted large numbers of holes \nwhen trying to allocate medium objects into frag\u00admented blocks.We de.nea medium object as greater thana \nline. Toaddress this problem, we implementdemand drivenover.ow al\u00adlocation.We pair each immix allocator \nwith an over.ow allocator that is also a contiguous allocator, however it always uses empty blocks. If \nimmix cannot accommodate a medium object in the cur\u00adrent block,but there are one or more free lines between \nthebump pointer cursor and limit, immix allocates it with the over.ow allo\u00adcator.Thus,immix allocatesmediumobjectsintheover.owblocks \nonly on demand.Forexamplein Figure2, there are three free lines between the cursor and the limit. If \nthe mutator requests an object whose size exceeds three lines, immix triggers over.ow allocation toavoidwasting \nthree lines.Since thevast majorityof objectsin Java programs tend to be small [14] and lines accommodate \nseveral objects on average, this optimization improves space ef.ciency. It is extremely effective at \ncombating, dynamically on demand, the pathological effect of occasional medium object allocations into \na recycled block dominated by small holes. Section 5.4 shows that over.ow allocation improves performance \nin memory constrained heaps that tend to fragment more. 3.2 Defragmentation: Lightweight Opportunistic \nEvacuation A pure mark-region collector is non-moving and thus subject to fragmentation. Both evacuation \n[8, 7] and compaction [18] can be effective defragmentation mechanisms. Immix uses opportunis\u00adtic evacuation. \nAt the start of each collection, immix determines whether to defragment, e.g., based on fragmentation \nlevels. If so, immix uses statistics from the previous collection to select defrag\u00admentation candidates \nand evacuation targets. Whenthe collector encountersaliveobjectinacandidateblock, it opportunistically \nevacuates the object. It only evacuates an ob\u00adjectifthe applicationhasnot pinneditandpriorevacuationhasnot \nexhausted all target space. If an object is unmovable when the col\u00adlector encounters it, the collector \nmarks the object and line as live and leaves it in place. Otherwise, the collector evacuates the object \nto a new location on a target block and leaves a forwarding pointer which records the address of the \nnew location. If the collector en\u00adcounters subsequent references to a forwarded object, it replaces them \nwith the value of the object s forwarding pointer. To evacuate an object, the collector uses the same \nallocator as the mutator, continuing allocation right where the mutator left off. Once it exhausts any \nunused recyclable blocks, it uses any com\u00adpletely free blocks. The collector of course does not allocate \ninto defragmentation candidate blocks. By default, immix sets aside a small number of free blocks that \nit never returns to the global allo\u00adcator and only ever uses for evacuating. This headroom eases de\u00adfragmentation \nandis countedagainst immix soverall heapbudget. By default immix reserves 2.5% of the heap as compaction \nhead\u00adroom,but Section5.4shows immixisfairly insensitivetovalues ranging between1and 3%. 3.2.1 DefragmentationPolicies \nand Details This section describes additional details of opportunistic defrag\u00admentation, including parallelism, \nand pinning. Candidate Selection. A variety of heuristics may select defrag\u00admentation candidates. A simple \npolicy would target fractions of the heap in a round-robin manner like JRockit. Similar to Metronome \n[8, 7], our implementation instead performs defrag\u00admentation on demand. If there are one or more recyclable \nblocks that the allocator did not use or if the previous collection did not yield suf.cient free space, \nimmix triggers defragmentation at the beginning of the current collection. If immix chooses to defragment, \nit selects candidate blocks with the greatest number of holes since holes indicate fragmentation. It \nuses conservative statistics from the previous collection and al\u00adlocation statistics from the last mutator \nperiod to select as many blocks as theavailable space allows.Tocompute these estimates ef\u00ad.ciently,immix \nusestwohistograms indexedbyhole count;a mark histogram estimating required space and an available histogram \nre\u00ad.ectingavailable space.Themark histogramis constructedeagerly during the coarse-grain sweep at the \nend of each collection. Immix marks each block with its number of holes and updates the mark histogram \nto indicate the distribution of marked lines in the heap as afunctionofthe numberof holesinthe associated \nblock.Forexam\u00adple, if a block has thirty marked lines and four holes, we increment the fourth bin in \nthe histogram by thirty. Since these operations are cheap, we can afford to perform them at the end of \nevery collec\u00adtion,evenif thereisno subsequent defragmentation.Immix creates the available histogram lazily, \nonce it decides to defragment. Each bin in the available histogram re.ects the number of available lines \nwithin the blocks with the given number of holes. To identify candidates, immix walks the histograms, \nstarting with the most fragmented bin, increments the required space by the volume in the mark histogram \nbin, and it decrements the avail\u00adable space by the volume in the available histogram bin. Immix decrements \nthe bin number,moving from most fragmented to least. When including the blocks in the bin would exceed \nthe estimated available space, immix selects as defragmentation candidates all blocks in the previous \nbin and higher. Section 5.4 shows this policy worksverywellforourfull-heap collector,butwehavenottuned \nit for a generational setting, which we leave to future work. Mixing Marking and Evacuation. The collector \nmixes evacua\u00adtion and marking, combining a mark bit, orthodox forwarding bits, and forwarding pointer \nin the object header. Even without defrag\u00admentation,aper-objectmarkis necessaryin additiontoalinemark, \nto ensure the transitive closure terminates. Objects on candidate blocks are movable, except if they \nare pinned. Pinned objects are not movable. Remember that immix: a) only triggers defragmenta\u00adtionif \nthereisavailable memory,andb)when selecting candidates, tries to ensure that it can accommodate their \nevacuation. However, since candidate selection is based entirely on space estimates, the collector may \nconsume all the unused memory before evacuating all the candidate objects. At this point, all subsequently \nprocessed objects become unmovable. Initially all objects are neither marked or forwarded. When the collector \nprocesses a reference to an object, if the object is un\u00admarked and not movable, it marks the object and \nenqueues the ob\u00adject for processing of its children. If the object is unmarked and movable, it evacuates \nthe object, installs a forwarding pointer, sets the forwarded bits, and then enqueues the forwarded object \nfor pro\u00adcessing of its children. If an object is marked and not forwarded, the collector performs no \nadditional actions. If the object is forwarded, the collector updates the reference with the address \nstored in the forwarding pointer. This design combines mark-region and evacuation on a per\u00adobject basis. \nIt also uses the same allocator for the mutator and collector. These innovations achieve opportunistic, \nsingle-pass evacuation-based defragmentation. Parallel Defragmentation. During defragmenting collection, \nas withanyevacuatinggarbage collection, someformof synchroniza\u00adtion is essential to avoid evacuating \nan object into two locations duetoa race.We usea standard compare andexchange approach to manage the \nrace to forward an object.Weexploit MMTk sfa\u00adcility for trace specialization to separately specialize \nthe collector code for defragmentation and normal scenarios. This specialization gives us all the bene.ts \nof defragmentation and only pays for the synchronization overhead when it is actually required. Pinning. \nIn some situations, an application may request that an objectnotbemoved.This language featureis requiredforC#,and \nalthough not directly supported by Java, some JVM-speci.c class library code in JikesRVM optimizes for \nthe case when an object isimmovable,forexample,toimprovebuffer managementfor.le I/O.We thereforeleverage \nimmix s opportunism andofferexplicit support for pinning. When the application requests pinning for an \nobject, immix sets a pinned bit in the object header. Defragmenta\u00adtion never moves pinned objects.  \n 3.3 Further Implementation Details This section describes a few more implementation details. Block and \nLine Size. Key parameters for immix are the block and line size.Weexperimentallyselecteda line sizeof \n128B and a block size 32KB, as shown in Section 5.4.We roughly size the blocks to match the operating \nsystem page size. For simplicity, we choose a uniform block size and do not permit objects to span blocks. \nWe use the default large object size of 8K currently im\u00adplemented in MMTk. Thus, immix only considers \nobjects smaller than 8K. A 32KB block can accommodate at least four immix objects, bounding worst-case \nblock-level fragmentation to about 25%. Blocks are also the unit of coarse-grain space sharing among \nthreads, which has two consequences: (1) each block acquisition and release must be synchronized, and \n(2) threads cannot share space at a .ner granularity than a block. Smaller block sizes would have higher \nsynchronization overheads and a higher worst case fragmentation bound,but more space sharing. Larger \nblockswould have less synchronization andlowerworst case fragmentation,but worse space sharing. Section \n5.4 shows that immix performance is not very sensitive to block size, but large block sizes can reduce \nmemory ef.ciencyin small heap sizes. We roughly size lines to match the architecture s cache line and \nto accommodate more than one object. The 128B line size re.ects a tension between metadata overhead for \nsmall lines (since we re\u00adquire one mark byte per line), and higher fragmentation for large lines (since \nwe only reclaim at line granularity). Section 5.4 shows that immix is more sensitive to line size than \nblock size. The small\u00adest object sizein JikesRVMis 8B the sizeof the standard header with no payload \nfor an object with no .elds. In theory, if all ob\u00adjects are 8B and only one object per two lines survives \na collection and each survivor straddles two lines, worst-case line fragmenta\u00adtion is 97%. Given the \nallocation and live object size demographics for these benchmarks, a line size of 128B accommodates one \nto four objects on average [14] with an average worst-case internal fragmentationof 25% andalowerexpected \nfragmentation.Tuning line size seems most closely tied to the programming language s in.uence on object \nsize demographics, rather than the architecture. Size and Accounting of Metadata. We embed all immix \nmeta\u00addata in the heap, leveraging a mechanism provided by MMTk to interleave metadata at 4MB intervals. \nThus, immix, like all other MMTk collectors, is correctlycharged for its metadata space over\u00adhead. Immix \nrequires one byte per line and four bytes per block, totaling 260 bytes per 32KB block, which amounts \nto 0.8%. Conservative Marking. Immix may allocate objects across line boundaries. This choice impacts \nmarking, allocation, and space ef\u00ad.ciency. Since immix cannot reclaim space at a .ner granularity than \na line, the collector must mark all lines on which a live object resides.A simpleexact marking scheme \ninterrogates the object s type information to establish its size, and then iterates through the address \nrange, marking the relevant lines.Wefoundexperimentally that these operations were quite expensive, especially \nwhen com\u00adpared to mark-sweep which simply sets a bit in the object header. We instead use conservative \nline marking. We leverage the observation that the overwhelming majority of objects are less than 128 \nbytes [14], so can span at most two lines. Conservative marking explicitly marks just the line associated \nwith the start of each small object, independent of the object s exact size and placement, making marking \nsimple and cheap. Sincea small object may span two lines, conservative marking implicitly marks the secondlinebyskippingthe.rstlineineachholeat \nallocationtime. In the worst case, conservative marking could waste nearly a line for every hole. Since \nmedium objects are uncommon, we perform exact marks for them at collection time. However, our optimization \nrequires that we differentiate small and medium objects, which requires interrogating each object s size, \ndefeating much of the effectofthe optimizations.Wesolvethisproblembyusingasingle header bit to mark each \nobject as small (0) or medium (1) when the object is allocated. Since in Java, the size of non-array \nobjects is statically known, JikesRVM s optimizing compiler can statically evaluate the conditional and \nelide the setting of the size bit for small objects, which form the overwhelming majority of allocated \nobjects. Figure 2 shows example line marks due to conservative marking. Conservative marking signi.cantly \nspeeds up marking of small objects compared with exact marking. Optimization of Hot Paths. We took great \ncare to ensure the allocation and tracing hot paths were carefully optimized. As we experimented with \nvarious algorithmic alternatives, we evaluated the performance of the resulting mechanism, ensuring the \nallocator matched semi-space performance, and the tracing loopwas as close aspossibleto mark-sweep tracing.Forexample,weexaminedthe \ncompiled IR for the allocation sequence, con.rming the compiler eliminated setting a bit in the header \nof small objects. We found that tracing performance was noticeably better if the collector performsthe \nline mark operation whenit scans an object, rather than when it marks an object. Because the scanning \ncode is longer and loops over and examines any child references, we believe that it provides better latencytolerance \nfor hiding the cost of the line mark operation.  (a)TotalTime Intel Core2Duo (b)TotalTime AMD Athlon \n(c)TotalTime PPC 970 (d) MutatorTime Core2Duo (e) MutatorL2 Misses Core2Duo (f) CollectorTime Core2Duo \nFigure 3. Geometric Mean Full Heap Algorithm Performance Comparisons forTotal, Mutator, and CollectorTime \n (a) javac Core2Duo (b) luindex Core2Duo (c) pjbb2000 Core2Duo Figure 4. Selected Benchmarks Showing \nImmix, Mark-Sweep and Composite Performance 4. Methodology We use the following experimental methodology. \nBenchmarks. We use all the benchmarks from SPECjvm98 and DaCapo (v. 2006-10-MR2) suites, and pseudojbb2000. \nThe Da-Capo suite [14] is a recently developed suite of real-world open source Javaapplications which \nare substantially more complexthan the SPECjvm98. The characteristics of both are described else\u00adwhere \n[15]. Pseduojbb2000 is a .xed workload version of SPEC jbb2000 [35].We con.gureit with8 warehouses and \n12500 trans\u00adactions per warehouse. Of these benchmarks, jbb2000, hsqldb, lusearch, and xalan are multi-threaded. \nHardware and Operating System We use three hardware plat\u00adforms: (1) Intel Core2Duo witha2.4GHz clock,a800MHz \nDDR2 memory, a 32KB, 64B line 8-way L1, and a 4MB, 64B line 16\u00adway L2; (2) AMD Athlon 3500+ with a 2.2GHz \nclock, a 400MHz DDR2 memory, a 64KB, 64B line 2-way L1, and a 512B, 64B line 16-way L2; and (3) IBMPowerPC \n970 G5 with a 1.6GHz clock, a 333MHz DDR memory, a 32KB, 128B line 2-way L1, and a 512KB, 128B line 8-way \nL2. All the systems run Linux 2.6.20ker\u00adnels from Ubuntu 7.04.We use the perfctr [32] library togather \nhardware performance counters on the Core2Duo. All CPUs oper\u00adatein 32-bitmode,anduse 32-bitkernels.Weuseallavailablepro\u00adcessors \nin our performance evaluations, so our main results, from the Core2Duo use two processors.We use separate \nuniprocessor runs togather performance counter data due to perfctr limitations. Our AMD and PPC results \nare uniprocessor. Jikes RVM and MMTk. We implement our algorithm in the memory management toolkit (MMTk) \n[13, 12] in revision 13767 ofJikesRVM[3,2] (October2007).JikesRVMisanopen source high performance [27] \nJava virtual machine (VM) written almost entirely in a slightly extended Java. Jikes RVM does not have \na bytecode interpreter. Instead,afast template-driven baseline com\u00adpiler produces machine code when the \nVM .rst encounters each Java method. The adaptive compilation system then optimizes the frequently executed \nmethods [5]. Using a timer-based approach, it schedules periodic interrupts. At each interrupt, the adaptivesystem \nrecords the currently executing method. Using a threshold, the op\u00adtimizing compiler selects and optimizes \nfrequentlyexecuting meth\u00adods at increasing levels of optimization. Since the interrupts are not deterministic, \nthe level of compiler activity and .nal code quality are non-deterministic. We use four standard MMTk \ncollectors in our experiments. MS is a mark-sweep implementation that uses a Lea-style segregated .ts \nfree list [29]. SS is a classic semi-space garbage collector, althoughit usesa mark stack rather thana \nCheneyscan [19].MCis a Lisp-2 [37] style mark-compact collector which unconditionally Table 1. Full Heap \nAlgorithm Performance at2\u00d7 Minimum Heap benchmark time (ms) MS SS MC IX compress 3305 1.00 1.01 1.02 \n1.00 jess 1405 1.00 1.06 1.20 0.90 raytrace 1034 1.00 1.33 1.32 0.92 db 6256 1.00 1.06 1.04 0.96 javac \n2616 1.00 1.03 1.03 0.93 mpegaudio 2554 1.00 0.98 0.94 0.97 mtrt 771 1.00 1.44 1.28 0.97 jack 2319 1.00 \n1.17 1.22 0.92 antlr 2117 1.00 1.21 1.16 0.93 bloat 8038 1.00 1.27 1.27 0.87 chart 7009 1.00 1.04 1.14 \n0.93 eclipse 33412 1.00 1.07 0.93 fop 1795 1.00 1.02 1.03 0.95 hsqldb 1562 1.00 1.14 0.87 0.88 jython \n7459 1.00 1.40 0.82 luindex 9830 1.00 1.11 1.11 0.96 lusearch 10463 1.00 1.25 1.39 0.95 pmd 4775 1.00 \n1.19 1.39 1.01 xalan 4773 1.00 1.11 1.14 0.90 pjbb2000 16510 1.00 0.99 0.95 0.88 min max geomean 1.00 \n1.00 1.00 0.98 1.44 1.14 0.87 1.39 1.13 0.82 1.01 0.93 benchmark time (ms) Copying (G|SS-.) In-Place \n(G|.-.) MS SS IX MS IX IXnm compress 3297 1.00 1.00 0.99 1.00 0.99 1.00 jess 1116 1.00 1.04 1.02 1.19 \n1.01 1.10 raytrace 884 1.00 1.93 0.96 1.18 1.02 1.01 db 6362 1.00 1.01 1.02 0.99 0.97 javac 2650 1.00 \n1.02 0.99 1.06 1.02 1.02 mpegaudio 2487 1.00 0.97 1.00 1.00 1.00 1.00 mtrt 670 1.00 1.81 1.01 1.21 1.07 \n1.05 jack 2156 1.00 1.12 0.96 1.19 1.06 1.06 antlr 1950 1.00 1.20 0.96 1.06 0.99 bloat 6371 1.00 1.09 \n1.00 1.24 1.03 1.08 chart 6657 1.00 1.03 0.99 1.06 0.98 0.98 eclipse 31588 1.00 1.02 0.99 1.10 0.99 1.01 \nfop 1722 1.00 0.99 0.99 1.02 1.00 0.99 hsqldb 1756 1.00 2.04 1.11 1.00 1.16 jython 5322 1.00 1.17 0.98 \n1.19 0.99 1.01 luindex 9763 1.00 1.47 1.00 1.02 0.99 0.98 lusearch 8088 1.00 0.99 0.97 1.15 0.98 1.01 \npmd 4799 1.00 1.18 1.02 1.23 1.18 1.27 xalan 4999 1.00 0.93 1.11 1.01 pjbb2000 15288 1.00 0.95 1.05 0.97 \n1.04 min max geomean 1.00 1.00 1.00 0.97 2.04 1.20 0.93 1.11 0.99 1.00 1.24 1.10 0.97 1.18 1.02 0.97 \n1.27 1.03 compacts the entire heap.G|SS-MSisa generational collector with a variable sized evacuating \nnursery and mark-sweep mature space. All collectors, including immix, use MMTk s large object space (LOS) \nfor objects greater than 8KB. Experimental Design and Data Analysis. We conduct all of our comparisons \nacross a range of heap sizes from one to six times the minimum heap in which mark-sweep will run (see \nFigure 5). To limit experimental noise, machines are stand-alone with all unnecessary daemons stopped \nand the network interfacedown.We ran each experiment six times, with each execution interleaved among \nthe systems being measured. We discard the fastest and slowestexperimentsandreportherethe meanoftheremainingfour \nexperiments. Each graph shows 99% con.dence intervals. We use Jikes RVM s replay feature to factor out \nnon-determ\u00adinistic allocation into the heap by the compiler due to timer-based adaptiveoptimization decisions \n[14].For collectorexperiments, the allocation load must remain constant. Replay uses a pro.le of all \nthe dynamic informationgathered for compilation decisions: edge frequencies, the dynamic call graph, \nand method optimization lev\u00adels. Whenexecuting, the system lazily compiles, as usual,but under replay \nuses the pro.le to immediately compile the method to its .\u00adnallevelof optimization.Wegathered.ve setsof \npro.les for each benchmark usingabuildof JikesRVM with the mark-sweep col\u00adlector, running each benchmark \nfor ten iterations to ensure the pro\u00ad.le captured steady state behavior.We selected pro.le information \nfromthefastestofthe.vetrialsandthenusedthatpro.leforallex\u00adperiments reportedinthispaper.We choosethefastestsinceslower \nmutator performance obscures differences due to thegarbage col\u00adlector.We also use JikesRVM s new pro.ling \nmechanism tobuild optimized, pro.led images for each collector. Because the .rst it\u00aderation is dominated \nby compilation and startup costs, we time the second iteration of the benchmark.We measured the performance \nof second iteration replay and found that it outperformed a tenth it\u00aderation run using the default adaptive \noptimization system.We also compared our replay con.guration with Sun s 1.5 and 1.6 produc\u00adtion JVMs \nin server mode, timing the second iteration on the Da-Capo benchmarks, and found JikesRVM with replay \noutperformed JDK1.5by5%whileJDK1.6 outperformedreplayby12%.Weare therefore con.dent that our experiments \nare conducted in a highly optimized environment. Table 2. Generational Performance at 1.5\u00d7 Minimum Heap \n5. Results We .rst evaluate immix (IX) against three canonical collectors representing the three previously \npublished reclamation strategies, mark-sweep ( MS , sweep-to-free-list), semi-space ( SS , evacu\u00adate), \nand mark-compact ( MC , compact)on three architectures. We break down performance by mutator and collector. \nWe use hardware performance counters to reveal the role of locality and minimum heap sizes to show space \nef.ciency. Section 5.2 mea\u00adsures immix as a component of a composite generational collec\u00adtor and comparesagainst \nJikesRVM s production collector,a high performance generational mark-sweep composite. Section 5.3eval\u00aduates \nan in-place generational algorithm that handles pinning with respect to both mark-sweep and immix full \nheap algorithms. Sec\u00adtion 5.4 teases apart the contributions of various aspects of immix. Together the \nresults show that a full heap implementation of im\u00admix outperforms existing canonical full heap collectors \nand occa\u00adsionally outperformsaproduction generationalcollector.Agenera\u00adtional composite based on immix \nmodestlybut consistently outper\u00adforms the production collector onaverage and on some benchmarks signi.cantly \noutperforms the production collector. 5.1 Full Heap ImmixPerformance Figure 3 shows performance as the \ngeometric mean for all 20 benchmarks for the three canonical collectors and immix. Each graph normalizes \nperformance to the best result on the graph and covers heap sizes from 1\u00d7 to 6\u00d7 the minimum heap in which \nmark-sweep will run each benchmark. Figures 3(a)-(c) show total performance for the three architectures, \nand Figures 3(d)-(f) show theCore2Duo mutatortime, mutatorL2cachemisses,andgarbage collection time.Table1presentsadetailed \nperformance sliceat2\u00d7 the minimum heap size. Figures 3(a)-(c) show thatimmix (IX) outperforms each of \nthe collectors on all heap sizes on all three architectures, typically by around 5-10%. Immix achieves \nthis result by breaking the perfor\u00admance dichotomy illustrated in Figure 1. Figures 3(d) and (e) show \nthat immix matches the superior mutator times of contiguous allo\u00adcation by providing comparable numbers \nof L2 misses on the Core 2Duo. Figures 3(f) shows that immix matches the superiorgarbage collection times \nof mark-sweep. Figures 3(b)-(c) show that immix performseven betterontheAMDandPPCthanitdoesontheCore \n2. The rest of our analysis focuses on the Core 2. Figure 5. MinimumHeap Sizesfor Canonical Algorithms, \nNormalizedto Mark-Sweep. Mark-Sweep MinimumShownin Label(inMB). Figure5shows the minimum heap sizes for \neachof the canon\u00adical algorithms and immix, normalized to mark-sweep (MS). The legend contains the heap \nsizes for mark-sweep for each benchmark in MB. The minimums reported here are total heap sizes, inclu\u00adsive \nof LOS, metadata, etc. Immix (86%) is 14% more space ef\u00ad.cient than mark-sweep on average, and is close \nto the ef.ciency of mark-compact (83%). Immix is occasionally more space ef.\u00adcient than mark-compact, \ne.g., see pmd and db.We speculate that one cause may be pathological interactions between mark-compact \n(which may move every object at every collection), and address\u00adbased hashing, which pays a one word header \npenalty for anyob\u00adjectthatismovedafterbeing hashed. Immix minimizesmoving,so is much less exposed to \nthis problem. Table 1 shows that immix achieves its improvements reliably and uniformly, improving over \nor matching the best of the other collectors on nearly every benchmark. The worst degradation suf\u00adfered \nby immix is 1%, and its greatest improvement is 18% at this heap size. Across the 11 heap sizes and 20 \nbenchmarks we mea\u00adsured, the worst result for immix was a 4.9% slowdown on hsqldb ata 1.1\u00d7 heap. The \nbest result for immix was a 74% (a factor of four) improvement for jython compared to MS, ata1\u00d7 heap. \nThese results indicate that immix not only performsverywell,but is remarkably consistent and robust. \nSince performance deteriorates rapidlyforall collectorsatvery smallheap sizes,we highlight2\u00d7 heap size \nin Table 1, which in Figure 3(a) is approximately the knee in all four performance curves. In some cases, \nimmix signi.cantly outperformed JikesRVM s high performance production generational collector ( GenMS \n, G|SS-MS), with a semi-space nursery ( G|SS ) and mark-sweep old space ( MS ). Figure 4(a) shows that \nfor javac, immix is by far the best choice of collector, outperforming mark-sweep (MS) and three generational \ncollectors. Figure 4(b) shows that for luin\u00addex, immix is again the best performing collector, except \nin a very tight heap where the immix in-place generational collector (G|IX-IX, Section 5.3) performs \nslightly better. In Figure 4(c), the immix full heap algorithm eclipses mark-sweep (MS) and the JikesRVM \nproduction collector (G|SS-MS) in allbut the tightest heaps. Fig\u00adure 6(c) shows that in larger heaps \nimmix outperformsG|SS-MS on average across all benchmarks.  5.2 AGenerational Composite We now examine \nthe performance of immix in a composite gen\u00aderational collector.We implemented our composite following \nthe templateofJikesRVM s production collector(G|SS-MS), which is a highly tuned collector representative \nof manyhigh performance production collectors. This collector allocates into a variable-sized evacuating \nnursery and promotes survivors of nursery collections into a mark-sweep mature space [13]. Thus it is \na generational semi-space, mark-sweep composite. Because it uses a semi-space for young objects, this \ncollector does not support pinning. It uses an ef.cient boundary write barrier [16], identifying nursery \nob\u00adjects as thoselying aboveacertain (constant) address boundary.We created a semi-space, immix composite \n(G|SS-IX), which mirrors G|SS-MSinallregardsexceptforthechangein maturespacealgo\u00adrithm.We also compare \nwith JikesRVM s GenCopy collector,a semi-space, semi-space generational composite (G|SS-SS), which also \ndiffers only in its mature space algorithm.We did not com\u00adpare against a semi-space, mark-compact composite \n(G|SS-MC) because JikesRVM does not currentlyhave sucha collector. Figure 6(a) shows the total performance \nof each of the three generational semi-space composites usinga geometric meanof our 20 benchmarks, and \nincludes mark-sweep (MS) as a reference. First, we note that the generational collectors signi.cantly \nand consistently outperformMSin this geometric mean,explaining the wide-spread useof such collectors.We \nsee thatG|SS-IX performs similar to and slightly better than G|SS-MS. It is interesting to note thatG|SS-IX \nperforms well even at larger heap sizes, where the mutator performance will tend to dominate. Since each \nof the three collectors shares exactly the same write barrier, allocator, and nursery implementation, \nthe observed performance difference is most likely due to better mature space locality offered by immix \nas compared to mark-sweep. Table 2 shows a performance slice of the generational semi\u00adspace composites \nat a 1.5\u00d7 heap, which Figure 6(a) indicates is the knee in the performance curves for these collectors. \nG|SS-IX performs slightly better than JikesRVM s production collector (G|SS-MS) on average, with .ve \ngood results, only one poor result (hsqldb), and the remainder neutral. The few empty cells indicate \na collectorfailing to successfully complete either due to memory exhaustion or some otherfailure. Figures \n4(a) and (b) show that for some benchmarks, includ\u00ading javac and luindex, there is little difference \nbetweenG|SS-IX andG|SS-MS. However, Figure 4(c) shows that for some impor\u00adtant benchmarks, including \njbb2000,G|SS-IX consistently outper\u00adformsG|SS-MS. Our implementation ofG|SS-IX is untuned we use exactly \nthe same parameters and con.guration in the immix mature space as for the full heap algorithm. We believe \nthere is roomforimprovement,butleavethatto futurework.  5.3 StickyMark Bit In-Place Collector We now \nevaluate mark-sweep (MS) and immix (IX) based im\u00adplementations of a sticky mark bit in-place generational \nalgo\u00adrithm [21] (G|MS-MS andG|IX-IX). The stickymark-bit is a sim\u00adple and elegant extension of a full \nheap collector to perform partial collections, collecting only the newly allocated objects. The pri\u00admary \ndifference between our implementation and Demmers et al. s  (a) Copying Generational (b) In-Place Generational \n(c) ImmixVariants Figure 6. Generational Collector Performance on Core2Duo. Geometric Meanof20 DaCapo \nand SPEC Benchmarks. original by is that we use an ef.cient object-remembering bar\u00adrier [16] to identify \nmodi.ed mature objects rather than page pro\u00adtection and card marks. Our collectors are trivial extensions \nover their canonical full heapcounter-parts. An early implementation of JikesRVM had an in-place generational \ncollector which did not use stickymark bits,but storedextra stateontheside.In Attanasioet al. sgarbage \ncollectorreview[6],theymentionthis collector,butdo notevaluateit. Domanietal.[23]buildandevaluatean on-the-.y \ngenerational collector using the stickymark bits algorithm. Aside from these collectors, we are unaware \nof in-place generational col\u00adlection .nding use outside of the conservative setting of Demmers et al. \ns work, where a stickymark bit collector is the only way to achieve generational scavenging since copying \nis not possible. Figure 6(b) shows that each of these in-place collectors im\u00adproves over the canonical \nalgorithms in tighter heaps with mini\u00admal degradation in large heaps. In particular,G|IX-IX almost uni\u00adformly \nimprovesover IX.However,G|MS-MS does not improve suf.cientlyoverMStojustifyits use,giventhe optionofaregu\u00adlar \ncopying generational collector. In Figure 6(c), we seeG|IX-IX compared to the other immix collectors \nand JikesRVM s produc\u00adtion collector (G|SS-MS). These results show that G|IX-IX per\u00adforms very competitively. \nSince in-place generational collection is trivial to implement, and unlike composites with evacuating \nnurs\u00aderies, does not detract from the mostly non-moving properties of immix, the in-place immix collector \nmay have interesting applica\u00adtion opportunities. Columns6,7and8ofTable2showa performance sliceata 1.5\u00d7 \nheap for the mark-sweep and immix in-place collectors, with results normalized to JikesRVM s production \ncollector,G|SS-MS. Here we include two variants on G|IX-IX: G|IX-IX will oppor\u00adtunistic evacuate during \nnursery collections as well as during de\u00adfragmentation, whileG|IX-IXnm will only opportunistically evacu\u00adate \nduring defragmentation time.We found that thesetwovariants performed about the same.Wespent more timetuning \nthis collector than we didG|SS-IX,butit remainsafairly naive implementation, and similar toG|SS-IX, can \nlikely be improved. The result of the experiment within-place generational collec\u00adtion highlights the \nimportance of signi.cantly improving the per\u00adformance of the full heap algorithm. While the mark-sweep \nin\u00adplace collector is interesting and perhaps useful in a conservative collection context, changing the \nbase from mark-sweep to immix transforms the idea into a serious proposition for a performance\u00adoriented \nsetting.  5.4 Understanding ImmixPerformance Each of the preceding sections and Figure 6(c) showhowthe \nimmix achievesall three goals: spaceef.ciency(Figure5),fast collection (Figure 3(f)) and mutator performance \n(Figure 3(d)). This section examines the individual features and policysensitivities presented inTables3and4. \nBlock Utilization To understand immix s allocation behavior, columns2 6ofTable3showhowallocationwas distributed \namong blocks, in terms of the fullness of the blocks. At the nominal2\u00d7 heap size, immix allocates 79% \nof data into completely free or mostly free blocks(< 25% marked), on average across our bench\u00admark suite. \nOnly occasionally, always less than 5%, does immix allocate into mostly full blocks with > 75% marked.We \nalso mea\u00adsured how these statistics vary with heap size. Immix allocates morefromrecyclable blocksinsmallheapsthanlarge.Forexam\u00adple, \ncompared to 43% of allocation to completely free blocks at 2\u00d7 heap size, immix allocates 76% ata6\u00d7 heap \nsize. This trend is because more frequent collection tends to fragment the heap more; given longer to \ndie more objects die together, whereas more frequent collection exposes more differences in object lifetimes. \nOver.ow Allocation We found over.ow allocation helps provide spaceef.ciencyintight heaps. Column7ofTable3showstheper\u00adcentofobjectsthatimmixsendstotheover.ow \nallocator.Onaver\u00adage, it handles 4% of allocation, however jython and xalan are con\u00adspicuous outliers. \nColumn5ofTable4shows the performance ef\u00adfect of turning offthe over.ow allocator mechanism. Three bench\u00admarks, \nantlr, jython and lusearch, bene.t from this mechanism, and xalan is slowed down by over.ow allocation. \nNote however, that the memory savings associated with a given use of the over\u00ad.ow allocator may vary \nwidely, depending on the size of pending allocation and the level of fragmentation of the recycled blocks. \nImportance of Blocks, Lines, and Defragmentation Columns2 and3ofTable4show performance for mark-region \ncollectors that provide just block marking (block); block and line marking with over.ow allocation,but \nwithout defragmentation (No DF); block, line, over.ow, and defragmentation with no head room (No HR); \neverything but over.ow allocation (No Ov). Some benchmarks perform remarkably well, while others are \nunable to run at all in a2\u00d7 heap.In columns8,9and10ofTable3, we show the amount of dark matter due to \nimprecise marking. Column 8 shows the imprecision overhead of marking only ata block grain, column9 shows \nthe overhead for line marking, and column 10 shows the overhead due to conservative line marks.Weexpressoverhead \nas a percentage of the actual bytes live at each collection, so a 100% overhead means markingwas imprecisebyafactoroftwo.Ifthe \ncollector only recycled blocks(block), block fragmentation would lead to it on average in.ating the amount \nmarked by 93% (nearly double). However, for some benchmarks such as db, compress and jython, a naive \nblock-grain marking scheme is remarkably effective. If the system used line marking(line),but still did \nnot perform defragmentation, waste would in.ate the amount marked by23%onaverage.We alsomeasuredthe memorywasteddueto \nconservative marking.A few benchmarks, such as javac and fop waste25to20%,butmost benchmarkswastelessthan6%. \n Allocation Marking Waste Pinning Compaction (1.5\u00d7 Min Heap) clean blocks < 25% < 50% < 75% >= 75% over\u00ad.ow \nblock line consv calls pinned objects Compactions Candidate Blocks % reuse net yield # GCs KB live compress \n0% 58% 38% 0% 2% 1% 18% 8% 2% 68 2 7 100% 5600 83% 89% 5% jess 27% 61% 10% 1% 0% 0% 208% 22% 12% 127 \n3 1 5% 5280 13% 100% 100% raytrace 60% 11% 2% 25% 1% 0% 100% 37% 20% 368 3 0 db 87% 9% 3% 1% 0% 0% 15% \n9% 3% 314 2 0 javac 23% 38% 20% 12% 4% 3% 216% 75% 25% 5K 450 2 20% 5664 27% 100% 100% mtrt 65% 12% 2% \n18% 2% 0% 76% 44% 20% 488 4 0 jack 26% 61% 7% 2% 2% 4% 188% 23% 10% 34 2 2 8% 12832 8% 100% 100% antlr \n51% 30% 7% 6% 1% 5% 48% 13% 5% 5K 4529 0 bloat 30% 64% 3% 1% 1% 1% 101% 13% 6% 33 8 6 10% 33888 17% 100% \n100% chart 42% 48% 6% 1% 3% 1% 134% 15% 5% 29K 58 0 eclipse 34% 54% 4% 1% 2% 6% 87% 13% 5% 112K 35K 13 \n24% 229696 21% 97% 95% fop 36% 17% 26% 14% 4% 4% 134% 44% 20% 0 0 0 hsqldb 99% 0% 0% 0% 0% 0% 26% 23% \n1% 43 0 0 jython 64% 11% 1% 1% 0% 23% 24% 7% 2% 14 0 2 5% 10816 50% 91% 96% luindex 45% 39% 7% 3% 1% \n4% 76% 12% 5% 43K 7K 0 lusearch 25% 53% 9% 7% 3% 4% 52% 9% 3% 171K 9K 1 1% 8544 52% 3% 5% pmd 43% 33% \n11% 10% 1% 2% 110% 35% 15% 137 2 4 17% 43488 43% 90% 96% xalan 11% 41% 18% 9% 3% 18% 59% 10% 4% 39K 27K \n1 6% 7360 39% 100% 100% min max mean 0% 99% 43% 0% 64% 36% 0% 38% 10% 1% 25% 7% 0% 4% 2% 0% 23% 4% 15% \n216% 93% 7% 75% 23% 1% 25% 9% 1% 100% 20% 8% 83% 35% 3% 100% 87% 5% 100% 80% Table 3. Allocating, Marking, \nPinning, and Compaction Statistics. Compaction at 1.5\u00d7 Minimum Heap, All Others at2\u00d7 Minimum Heap Pinning \nOpportunisticevacuationallows immixtoelegantlysup\u00adport object pinning. Although Javadoes not support \nobject pinning, it is an important feature of C# and Jikes RVM s class libraries optimize for pinning \nin the classes gnu.java.nio.VMChannel and org.jikesrvm.jni.VM_JNIFunctions. In each case, the li\u00adbraryavoids \nindirection andbuffering when theVM assures an ob\u00adjectwillnotmove. Columns11and12ofTable3showthe number \noftimesacallwasmadetopinanobjectduringthesecond iteration of each benchmark, and the number of objects \nwhich were pinned as a result. Objects are pinned only once. The pinning interface always returns true \nfor mark-sweep since it never moves objects, andalways returnsfalsefor semi-spaceand mark-compact because \nneither support pinning. Immix pins the requested object and re\u00adturns true. Immix performs pinning in \nall of the results reported in this paper.We performed detailed performance analysis and found that pinning \nhas no effect on performance for most benchmarks; hasavery small advantage for three benchmarks which \nusepinning heavily;and slightlydegrades performanceforafourth benchmark. Opportunistic Defragmentation \nColumns 13 18ofTable3show thebehaviorof opportunistic defragmentationina1.5\u00d7 heap. Even at this modest \nheap size, only8benchmarks require defragmenta\u00adtion and only compress triggers defragmentation on every \ncollec\u00adtion.We measured thevolumeof blocks marked as defragmenta\u00adtion candidates and the amount of live \ndata on those blocks, ex\u00adpressed as a percentage. This percentage is an indirect measure of fragmentation \nsince it does not quantify the number of holes.We see wide variations from 8% to 83% of live objects \non candidate blocks.We see that thevast majority (87%)ofevacuatedlive ob\u00adjects are tucked into recyclable \nblocks rather than being evacuated to completely free blocks.Wemeasured defragmentation yield.Op\u00adportunistic \ndefragmentation has limited success on compress and lusearch,but neither of these programs stress the \ncollector much. On the remaining programs, defragmentation successfully converts 95% or more of the candidate \nspace to completely free blocks. These statistics showthat opportunistic defragmentation effectively \ncompresses the heap on demand and is only occasionally triggered. Defragmentation Headroom We alsoexplored,butdonotshow \nin detail, how immix s minimum heap size is in.uenced by elimi\u00adnating (1) the default 2.5% defragmentation \nheadroom, (2) defrag\u00admentation, and (3) both defragmentation and line-grain reclama\u00adtion. Eliminating \ndefragmentation and line-grain reclamation, thus only performing block-grain recycling, would require \nmore than doubling the average minimum heap size. Performing line-grain marking,but no defragmentation \nstill increases the minimum heap size signi.cantly, on average 45% and up to 361%. Headroom also signi.cantly \nbene.ts immix.With zero headroom, immixwould re\u00adquire an increase of between 16% on average, although \nfor xalan and antlr, immix performed better with no headroom.Weexper\u00adimented with headroom of 1, 2, and \n3%; all were suf.cient to achieve small heap sizes in immix. Immix was not very perfor\u00admance sensitive \nto these choices;2% performs slightly better than our current 2.5% threshold acrossa numberof heap sizes,but \nall were suf.cient for robust immix performance in small heaps. Blockand Line Sizes Columns 6 9ofTable4show \nthe sensitiv\u00adity of immix to line and block size, measuring half and twice the default sizes of 32KB \nand 128B for blocks and lines respectively. Per-benchmarkvariationbasedonblocksize rangesfrom7%better \nto 7% worse for large blocks. Large blocks show a slight improve\u00adment ata2\u00d7 heap size,but theyperformworsein \nsmaller heaps. Smaller blockshave slightly lessvariation,but neither changeim\u00admix much. The eclipse and \nxalan benchmarks are most sensitiveto line size, and sensitivity grows in smaller heap sizes. Most bench\u00admarksarenotthat \nsensitivetolinesize,butwefoundthat128Bis more consistent and better across manyheap sizes. 6. Conclusion \nThis paper describes mark-region, anewfamilyof non-moving col\u00adlectors that allocate and reclaim memoryin \ncontiguous regions.To combat fragmentation, we introduce lightweight opportunistic de\u00adfragmentation, \nwhich mixes copying and marking in a single pass. Wecombine both ideas inimmix,anovel high performancegarbage \ncollector which attains space ef.ciency,fast collection and muta\u00adtor performance. Immix outperforms existing \ncanonical collectors, each of which sacri.ce one of these three performance objectives. As a mature space \nin a generational collector, immix matches or beats a highly tuned generational collector. By describing \nmark\u00adregion for the .rst time and presenting a detailed analysis of a high performance mark-region implementation, \nthis paper opens up new directions for future collector design. Acknowledgments We thank our anonymous \nreviewers for helping us greatly improve the paper.We thankDavid Bacon, Daniel Frampton, Robin Garner, \nbenchmark compress jess raytrace db javac mpegaudio mtrt jack antlr bloat chart eclipse fop hsqldb jython \nluindex lusearch pmd xalan min max geomean Algorithmic Features Block Line No HR No Ov 1.00 1.00 1.00 \n1.01 0.98 1.00 1.07 1.00 1.00 1.01 1.04 1.04 1.03 1.00 0.99 1.00 1.01 0.99 1.00 1.00 1.00 1.26 1.02 1.00 \n0.98 1.01 1.02 0.97 1.06 1.05 1.04 0.99 1.03 1.00 1.01 1.02 1.02 1.01 1.01 1.09 1.08 1.28 1.00 3.15 1.81 \n1.08 1.24 1.05 1.04 1.00 1.57 1.13 1.05 1.05 1.04 1.05 1.00 1.60 1.20 1.98 0.91 0.99 0.99 0.98 0.91 1.60 \n3.15 1.98 1.08 1.19 1.12 1.11 1.01 Block Size 16KB 64KB 1.00 1.00 1.04 0.99 0.98 0.96 1.00 1.00 1.03 \n0.98 1.00 1.00 0.99 0.98 0.99 0.98 1.00 1.07 1.01 0.99 1.02 1.00 1.03 1.02 1.01 1.00 1.00 0.92 1.03 0.99 \n1.01 1.01 1.04 1.00 1.00 1.00 0.96 0.97 0.96 0.92 1.04 1.07 1.01 0.99 Line Size 64B 256B 1.00 1.01 1.02 \n0.99 0.97 0.96 1.01 1.00 0.99 1.02 1.01 1.00 1.00 1.00 0.98 0.97 0.98 1.01 1.00 1.01 1.01 1.00 1.05 1.02 \n1.02 1.00 0.99 0.91 1.06 1.01 0.99 1.00 1.05 1.03 1.00 1.00 0.93 1.03 0.93 0.91 1.06 1.03 1.00 1.00 \nTable 4. Performance Sensitivity. Relative to Immix2\u00d7 Heap. and David Grove for their insight, feedback \nand technical assis\u00adtance.WethankallofthedevelopersofJikesRVM, withoutwhom this research would not happen. \nReferences [1] D. Abuaiadh, Y. Ossia, E. Petrank, and U. Silbershtein. An ef.cient parallel heap compaction \nalgorithm. In ACM Conference on Object Oriented Programming,Systems, Languages, and Applications,pages \n224 236, Vancouver, BC, Canada, 2004.ACM. [2] B. Alpern, D. Attanasio, J. J. Barton, M. G. Burke, P.Cheng, \nJ.-D. Choi, A.Cocchi,S.J.Fink,D.Grove,M.Hind,S.F.Hummel,D.Lieber,V. Litvinov, M. Mergen, T. Ngo, J. \nR. Russell, V. Sarkar, M. J. Serrano, J. Shepherd, S. Smith,V. C. Sreedhar, H. Srinivasan, and J. Whaley. \nThe Jalape no virtual machine. IBM SystemJournal, 39(1), Feb. 2000.  [3] B. Alpern, D. Attanasio, J. \nJ. Barton, A. Cocchi, S.F. Hummel, D. Lieber, M.Mergen,T.Ngo,J. Shepherd,andS. Smith. ImplementingJalape \nnoinJava. In ACM Conference on Object Oriented Programming, Systems, Languages, and Applications, Denver, \nCO, Nov. 1999. [4] A.W. Appel. Simple generationalgarbage collection andfast allocation. Software Practice \nand Experience, 19(2):171 183, 1989. [5] M. Arnold, S. J. Fink, D. Grove, M. Hind, and P. Sweeney. Adaptive \noptimization in the Jalape In ACM Conference on Object no JVM. Oriented Programming, Systems, Languages, \nand Applications, pages 47 65, Minneapolis, MN, October 2000. [6] C. Attanasio, D. Bacon, A. Cocchi, \nand S. Smith. Acomparative evaluation of parallelgarbage collectors. In Proceedingsof theWorkshop on \nLanguages and Compilers forParallel Computing, CumberlandFalls,KY,Aug. 2001. [7] D.F. Bacon,P. Cheng, \nandV.T. Rajan. Controlling fragmentation and space consumptionin the Metronomea real-timegarbage collector \nforJava. In ACM Conference on Languages, Compilers, andTools for Embedded Systems, pages 81 92, San Diego, \nCA, June 2003. [8] D.F. Bacon,P. Cheng, andV.T. Rajan.Areal-timegarbage collector withlow overhead and \nconsistent utilization. In ACM Symposium on the Principles of Programming Languages, pages 285 294, New \nOrleans, LA, Jan. 2003. [9] H.G.Baker. List processingin real-timeonaserial computer. Communications \nof theACM, 21(4):280 94, 1978. [10] K. Barabash,O. Ben-Yitzhak,I. Goft,E.K.Kolodner,V. Leikehman,Y. Ossia, \nA. Owshanko, and E. Petrank. A parallel, incremental, mostly concurrent garbage collector for servers. \nACMTransactions on Programming Languages and Systems, 27(6):1097 1146, 2005. [11] BEA Systems Inc. Using \nthe JRockit runtime analyzer. http://edocs. bea.com/wljrockit/docs142/usingJRA/looking.html, 2007. [12] \nS. M. Blackburn,P. Cheng, and K. S. McKinley. Myths and realities: The performance impact of garbage \ncollection. In Proceedings of the ACM Conference on Measurement&#38; Modeling Computer Systems, pages \n25 36, NY, NY, June 2004. [13] S. M. Blackburn, P. Cheng, and K. S. McKinley. Oil and water? High performancegarbage \ncollectioninJavawith MMTk.In Proceedings of the 26th International Conference on Software Engineering, \npages 137 146, Scotland, UK, May 2004. [14] S. M. Blackburn, R. Garner, C. Hoffman, A. M. Khan, K. S. \nMcKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Frampton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, \nH. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4c, T. VanDrunen, D. von Dincklage, and B. Wiedermann. \nThe DaCapo benchmarks: Java benchmarking development and analysis. In ACM Conference on Object Oriented \nProgramming, Systems, Languages, and Applications, pages 169 190, Portland, OR, USA, Oct. 2006. [15] \nS. M. Blackburn, R. Garner, C. Hoffman, A. M. Khan, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, \nD. Frampton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4c, \nT. VanDrunen, D. von Dincklage, and B. Wiedermann. The DaCapo Benchmarks:Java benchmarkingdevelopment \nand analysis(extendedversion). Technical Report TR-CS-06-01, Dept. of Computer Science, Australian National \nUniversity, 2006. http://www.dacapobench.org. [16] S. M. Blackburn and A. Hosking. Barriers: Friend or \nfoe? In The ACM International Symposium on Memory Management,pages 143 151,Vancouver, BC, Canada, Oct. \n2004. [17] S. M. Blackburn, R. E. Jones, K. S. McKinley, and J. E. B. Moss. Beltway: Getting around garbage \ncollection gridlock. In ACM Conference on Programming Language Design and Implementation, pages 153 164, \nBerlin, Germany, June 2002. [18] S. Borman. Sensible sanitation understanding the IBM Java garbage collector. \nhttp://www.ibm.com/developerworks/ibm/library/ i-garbage1/, Aug. 2002. [19] C. J. Cheney. Anonrecursive \nlist compacting algorithm. Communications of theACM, 13(11):677 678, Nov. 1970. [20] J. Cohen and A. \nNicolau. Comparison of compacting algorithms forgarbage collection. ACM Transactions on Programming Languages \nand Systems, 5(4):532 553, Oct. 1983. [21] A. Demmers, M.Weiser, B. Hayes, H. Boehm, D. Bobrow, and S. \nShenker. Combining generational and conservativegarbage collection: framework and implementations. In \nACM Symposium on the Principles of Programming Languages, pages 261 269, San Francisco, California, United \nStates, 1990. ACM. [22] D. Detlefs, C. Flood, S. Heller, andT. Printezis. Garbage-.rstgarbage collection. \nIn TheACM International Symposium on Memory Management, Vancouver, BC, Canada, Oct. 2004.ACM. [23]T. \nDomani,E.K.Kolodner,andE. Petrank.Agenerational on-the-.ygarbage collector for java. In PLDI 00: Proceedings \nof the ACM SIGPLAN 2000 conference on Programming language design and implementation, pages 274 284,Vancouver, \nBritish Columbia, Canada, 2000.ACM. [24] Q. Feng and E. Berger. Alocality improving dynmaic memory allocator. \nIn TheACMWorkshop Memory SystemsPerformance, pages 68 77, Chicago, IL, June 2005. [25] D. Frampton, D. \nF. Bacon, P. Cheng, and D. Grove. Generational real\u00adtime garbage collection: A a three-part invention \nfor young obects. In European Conference on Object-Oriented Programming, pages 101 125, Berlin, Germany, \nJuly 2007. [26] R. L. Hudson and J. E. B. Moss. Incremental collection of mature objects. In Proceedings \nof the InternationalWorkshop on Memory Management, number 637 in Lecture Notes on Computer Science, pages \n388 403. Springer-Verlag, 1992. [27] JikesRVM CoreTeam.VM performance comparisons. http://jikesrvm. anu.edu.au/~dacapo/index.php?category=release, \n2007. [28] H.Kermanyand E. Petrank. The compressor: concurrent, incremental, and parallel compaction. \nIn ACM Conference on Programming Language Design and Implementation, pages 354 363, Ottawa, Ontario, \nCanada, 2006.ACM. [29] D. Lea. Amemory allocator. Technical report, SUNY at Oswego, 1996. [30] J. McCarthy. \nRecursive functions of symbolic expressions and their computationby machine,PartI. Commun.ACM, 3(4):184 \n195, 1960. [31] P. McGacheyand A. L. Hosking. Reducing generational copyreserve overhead withfallback \ncompaction. In TheACM International Symposium on Memory Management, pages 17 28, Ottawa, CA, June 2006. \n[32] M. Pettersson. Linux Intel/x86 performance counters, 2003. http: //user.it.uu.se/~mikpe/linux/perfctr/. \n[33] N. Sachindran, J. E. B. Moss, and E. D. Berger. MC2: High-performance garbage collectionn for memory-constrained \nenvironments. InACM Conference on Object Oriented Programming, Systems, Languages, and Applications, \npages 81 98,Vancouver, Canada, Oct. 2004. [34] D. Spoonhower, G. Blelloch, and R. Harper. Using page \nresidencyto balance tradeoffs in tracinggarbage collection. In ACM International Conference on Virtual \nExecution Environments, Chicago, IL, June 2005.ACM. [35] Standard Performance Evaluation Corporation. \nSPECjbb2000 Documentation, release 1.01 edition, 2001. [36] D. Stefanovi\u00b4c, K. S. McKinley, and J. E. \nB. Moss. Age-based garbage collection. In ACM Conference on Object Oriented Programming, Systems, Languages, \nand Applications, Denver, CO, Nov. 1999. [37]P. Styger. LISP2garbage collector speci.cations. Technical \nReport TM\u00ad3417/500/00 1, System Development Cooperation, Santa Monica, CA, Apr. 1967.   \n\t\t\t", "proc_id": "1375581", "abstract": "<p>Programmers are increasingly choosing managed languages for modern applications, which tend to allocate many short-to-medium lived small objects. The garbage collector therefore directly determines program performance by making a classic space-time tradeoff that seeks to provide space efficiency, fast reclamation, and mutator performance. The three canonical tracing garbage collectors: semi-space, mark-sweep, and mark-compact each sacrifice one objective. This paper describes a collector family, called <i>mark-region</i>, and introduces <i>opportunistic</i> defragmentation, which mixes copying and marking in a single pass. Combining both, we implement <i>immix</i>, a novel high performance garbage collector that achieves all three performance objectives. The key insight is to allocate and reclaim memory in contiguous regions, at a coarse <i>block</i> grain when possible and otherwise in groups of finer grain <i>lines</i>. We show that immix outperforms existing canonical algorithms, improving total application performance by 7 to 25% on average across 20 benchmarks. As the mature space in a generational collector, immix matches or beats a highly tuned generational collector, e.g. it improves jbb2000 by 5%. These innovations and the identification of a new family of collectors open new opportunities for garbage collector design.</p>", "authors": [{"name": "Stephen M. Blackburn", "author_profile_id": "81100547435", "affiliation": "Australian National University, Canberra, Australia", "person_id": "P1022730", "email_address": "", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "University of Texas at Austin, Austin, TX, USA", "person_id": "P1022731", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1375581.1375586", "year": "2008", "article_id": "1375586", "conference": "PLDI", "title": "Immix: a mark-region garbage collector with space efficiency, fast collection, and mutator performance", "url": "http://dl.acm.org/citation.cfm?id=1375586"}