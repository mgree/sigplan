{"article_publication_date": "06-07-2008", "fulltext": "\n Fair Stateless Model Checking Madanlal Musuvathi Shaz Qadeer Microsoft Research {madanm,qadeer}@microsoft.com \nAbstract Stateless model checking is a useful state-space exploration tech\u00adnique for systematically testing \ncomplex real-world software. Ex\u00adisting stateless model checkers are limited to the veri.cation of safety \nproperties on terminating programs. However, realistic con\u00adcurrent programs are nonterminating, a property \nthat signi.cantly reduces the ef.cacy of stateless model checking in testing them. Moreover, existing \nstateless model checkers are unable to verify that a nonterminating program satis.es the important liveness \nprop\u00aderty of livelock-freedom, a property that requires the program to make continuous progress for any \ninput. To address these shortcomings, this paper argues for incorporat\u00ading a fair scheduler in stateless \nexploration. The key contribution of this paper is an explicit scheduler that is (strongly) fair and \nat the same time suf.ciently nondeterministic to guarantee full cover\u00adage of safety properties. We have \nimplemented the fair scheduler in the CHESS model checker. We show through theoretical arguments and \nempirical evaluation that our algorithm satis.es two important properties: 1) it visits all states of \na .nite-state program achieving state coverage at a faster rate than existing techniques, and 2) it .nds \nall livelocks in a .nite-state program. Before this work, non\u00adterminating programs had to be manually \nmodi.ed in order to apply CHESS to them. The addition of fairness has allowed CHESS to be effectively \napplied to real-world nonterminating programs without any modi.cation. For example, we have successfully \nbooted the Singularity operating system under the control of CHESS. Categories and Subject Descriptors \nD.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation formal methods, validation; D.2.5 [Software \nEngineering]: Testing and Debugging debug\u00adging aids, diagnostics, monitors, tracing General Terms Algorithms, \nReliability, Veri.cation Keywords Concurrency, fairness, liveness, model checking, multi\u00adthreading, shared-memory \nprograms, software testing 1. Introduction Concurrent programs are dif.cult to get right. Subtle interactions \namong communicating threads in the program can result in unex\u00adpected behaviors. These behaviors typically \nresult in bugs that oc\u00adcur late in the software development cycle or even after the software Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 08, June 7 \n13, 2008, Tucson, Arizona, USA. Copyright c &#38;#169; 2008 ACM 978-1-59593-860-2/08/06. . . $5.00. \n Model checking [5, 24] is a promising method for detecting and debugging deep concurrency-related errors. \nA model checker sys\u00adtematically explores the state space of given system and veri.es that each reachable \nstate satis.es a given property. This paper is con\u00adcerned with stateless model checking, a style of state-space \nsearch .rst proposed in Verisoft [8]. A stateless model checker explores the state space of the program \nwithout capturing the individual pro\u00adgram states. The program is executed under the control of a special \nscheduler that controls all the nondeterminism in the program. This scheduler systematically enumerates \nall execution paths of the pro\u00adgram obtained by the nondeterministic choices. Stateless model checking \nis particularly suited for exploring the state space of large programs, because precisely capturing all \nthe essential state of a large program can be a daunting task. Apart from the global variables, heap, \nthread stacks, and register contexts, the state of a running program can be stored in the operating system, \nthe hardware, and in the worst case, in a different machine across a network. Even if all the program \nstate can be captured, processing such large states can be very expensive [12, 21]. On the downside, \nstateless model checking is directly applicable only to terminating programs. Such programs terminate \nunder all executions and equivalently, have acyclic state spaces. In our expe\u00adrience, most realistic \nconcurrent programs have cyclic state spaces. This paper introduces the novel technique of fair stateless \nmodel checking for effectively searching the state spaces of nonterminat\u00ading programs. Nontermination \nand cyclic state spaces present a signi.cant ob\u00adstacle to existing stateless model checkers. To illustrate \nthe prob\u00adlem, consider the nonterminating program in Figure 1. The pro\u00adgram is a variation of the dining \nphilosophers example with two threads Phil1 and Phil2 trying to acquire two resources fork1 and fork2. \nPhil1 acquires fork1 and then attempts to acquire fork2 without blocking. If this attempt fails, then \nit releases fork1 and retries. Phil2 tries to acquire the two resources in the reverse divergence resulting \nfrom nonterminating executions, the model checker must be run with a depth bound. To get good coverage \nfor safety veri.cation, this bound must be large enough to allow ex\u00adploring the deepest state in the \nstate space. However, as the bound increases, the model checker spends exponentially more resources unrolling \ncycles in the state space than visiting new states. A use\u00adful measure of the wasteful work performed \nduring the search is the number of non-terminating executions explored for a particu\u00adlar depth bound. \nFigure 2 shows that, for our example (Figure 1), as the depth bound increases the number of nonterminating \nex\u00adecutions explored increases exponentially. Second, nontermina\u00adtion introduces the possibility of livelocks, \nan entirely new class of errors characterized by the inability of the program to make progress. For example, \nthe repeated execution of the transition se\u00adquence Phil1: Acquire(fork1), Phil2: Acquire(fork2), Phil1: \nTryAcquire(fork2), Phil2: TryAcquire(fork1), Phil1: Release(fork1), Phil2: Release(fork2) is a live\u00adlock. \nDepth-bounded stateless model checking does not have the ability to detect such errors. Fair stateless \nmodel checking solves both the aforementioned problems by performing state-space search with respect \nto a fair and demonic scheduler. Our .rst key insight is that correct pro\u00adgrams make continuous progress \non fair schedules. A schedule is fair if every thread that is enabled in.nitely often is sched\u00aduled in.nitely \noften. Conversely, a schedule is unfair if a thread is starved of its chance to execute despite being \nenabled in\u00ad.nitely often. 1 For example, the schedule in which Phil1 per\u00adforms Acquire(fork1) and then \nPhil2 repeatedly executes Acquire(fork2), TryAcquire(fork1), Release(fork2) is unfair. A cycle in the \nstate space of a correct program corresponds to an unfair schedule in which an enabled thread is starved \ncontinu\u00adously so that the other threads participating in the cycle are unable to make progress. By performing \nstate-space search with respect to a fair scheduler, the model checker is able to prune such cycles away. \nNote that a cycle in an incorrect program, such as the one in Figure 1, might correspond to a livelock. \nHowever, such an erro\u00adneous cycle must be fair, otherwise it would not be considered an error by the \nprogrammer. Our scheduler does not prune such cycles and will in fact generate an in.nite execution in \nthe limit. It is this ability to distinguish between fair and unfair executions that gives fair stateless \nmodel checking the ability to detect livelocks. 1 In the literature, this notion of fairness is quali.ed \nas strong fairness. For brevity, we simply refer to this notion without the quali.er in this paper. \n Obviously, a fair scheduler is restricted from making some scheduling decisions that are otherwise available \nto a scheduler with no fairness requirement. It is important to ensure that these restrictions do not \nreduce the coverage achieved during state-space exploration. Our second key insight enables us to do \nso. We ob\u00adserve that threads in correct programs indicate when they are un\u00adable to make progress by yielding \nthe processor. A yield is usually indicated by the presence of a sleep operation or a timeout while waiting \non a resource. To achieve fairness, the scheduler only pe\u00adnalizes yielding threads and prioritizes threads \nthat are able to make progress. In particular, the scheduler is fully nondeterminstic in the absence \nof yield operations. Section 3 describes the fair scheduling algorithm and provides theoretical results \nto characterize its sound\u00adness. To support these theoretical results, Section 4 provides exper\u00adimental \nresults which indicate that our algorithm achieves complete state coverage on a variety of programs. \nWe have implemented our scheduler in the CHESS model checker. This algorithm extends the ability of CHESS \nto handle nonterminating programs. Prior to this implementation, any pro\u00adgram given to the checker had \nto be manually modi.ed to terminate under all schedules. This manual effort was a signi.cant hurdle to \nthe deployment of CHESS because in our experience, real programs are almost always nonterminating. By \nnot requiring this manual ef\u00adfort, the fair scheduling algorithm has signi.cantly improved the applicability \nof CHESS to real-world programs; we can now boot the Singularity operating system [13] under the control \nof CHESS. We present our evaluation, including several bugs found, in Sec\u00adtion 4. In summary, the main \nnovel contributions of this paper are the following: We have introduced fair stateless model checking, \na novel technique for systematic testing of nonterminating programs. Our method signi.cantly enhances \nthe applicability of stateless model checking to large programs with cyclic state spaces. In addition, \nit allows stateless model checkers to detect a new class of livelock errors.  We have implemented our \nalgorithm in the stateless model checker CHESS. The algorithm makes it much easier to apply CHESS to \nlarge programs and found three previously unknown errors in real-world programs of which two are livelocks. \n 2. Overview In this section, we present an overview of our method for system\u00adatically testing nonterminating \nprograms. We use the example pro\u00adgram in Figure 3 to motivate the discussion. This program has two threads \nand a global variable x initially set to zero. The .rst thread t sets x to 1, while the second thread \nu spins in a loop waiting for the update of x by t. The state space of this program is shown at the right \nof Figure 3. For this simple program, the state can be captured by the program counter of the two threads. \nFor instance, the state (a,c) is the initial state where the two threads are about to execute the instructions \nat locations a and c respectively. The state space contains a cycle between (a,c) and (a,d), resulting \nfrom the the spin loop of u. Obviously, this program does not terminate under the schedule that continuously \nruns u without giving a chance for t to execute. Our method is applicable to programs that are expected \nto ter\u00adminate under all fair schedules. That is, nontermination under a fair schedule is unexpected and \nis potentially an error. However, there is no requirement on these programs to terminate under unfair \nschedules. We call such programs fair-terminating. The program in Figure 3 is fair-terminating since \nits only in.nite execution is not fair. This execution continuously starves thread t despite t being \nenabled in.nitely often. Our intuition for fair-terminating programs is based upon our observation of \nthe test harnesses for real-world concurrent pro\u00adgrams. In practice, concurrent programs are tested by \ncombining them with a suitable test harness that makes them fair-terminating. A fair scheduler eventually \ngives a chance to every thread in the program to make progress ensuring that the program as a whole makes \nprogress towards the end of the test. Such a test harness can be created even for systems such as cache-coherence \nprotocols that are designed to run forever ; the harness limits the number of cache requests from the \nexternal environment. In addition, the notion of fair termination coincides with the intuitive behavior \npro\u00adgrammers expect of their concurrent programs. For instance, one expects the program in Figure 3 to \nterminate when run on a real machine. This expectation is due to our implicit assumption that the underlying \nthread scheduler in the operating system is fair. In this paper, we provide a solution to the following \nimportant problem: Input: A concurrent program Q and a safety property . Problem: Determine if Q is fair-terminating \nand satis.es .. If Q is not fair-terminating, produce a fair nonterminating execution of Q. If Q violates \n., produce a .nite execution of Q violating .. All previous solutions proposed for this problem are stateful; \nthey require capturing the state of the program Q. As discussed in the introduction, capturing the state \nof large program is error-prone and expensive. The main contribution of this paper is a practical stateless \nsolution to this problem. Our solution, called fair stateless model checking, uses a fair and demonic \nscheduler for systematically exploring the set of fair executions of the program Q. The scheduler maintains \na partial order on the set of threads in each state. Intuitively, this partial order de.nes a scheduling \npriority over threads in each state an enabled thread cannot be scheduled in a state if a higher priority \nthread, as determined by the partial order, is enabled in that state. The priority is updated appropriately \nduring the execution of a program with the guarantee that any in.nite execution generated by our scheduler \nis fair (Section 3). An execution obtained by unrolling an unfair cycle in the state space of a nonterminating \nprogram is pruned by our scheduler, thereby leading to a more ef.cient search. While being fair, the \nscheduler must also be demonic and at\u00adtempt to generate enough schedules to achieve full state cover\u00adage. \nFor example, a scheduler that generates a single fair sched\u00adule is useless for .nding bugs because it \nmisses most behaviors of the program! Similarly, a round-robin scheduler does not consider many interleavings \nof the threads in the program. Ideally, it would be desirable for a fair scheduler to generate all possible \nfair exe\u00adcutions of the program. But the set of all fair executions of a fair\u00adterminating program, even \nfor a .xed input, may be (enumerably) in.nite. Therefore, it is impossible for any stateless model checker, \nincluding ours, to generate all fair executions in a bounded amount of time. However, for checking safety \nproperties, it is only neces\u00adsary to generate enough executions to cover all reachable states of the \nprogram. To achieve full state-coverage, our scheduler depends on an important characteristic of correct \nprograms. We observed that threads in correct programs indicate when they are unable to make progress \nby yielding the processor. Whenever a thread waits for a resource that is not available, it either blocks \non the resource or yields the processor. A block or a yield tells the operating system scheduler to perform \na context switch, hopefully to the thread holding the resource required by the waiting thread. If the \nwaiting thread does not yield the processor and continues to spin idly, it will needlessly waste its \ntime slice and slow down the program; such a behavior is consequently considered an error. Therefore, \nin addition to being fair-terminating, correct programs also satisfy the following good samaritan property: \nif a thread is scheduled in.nitely often, then it yields in.nitely often. The program in Figure 3 satis.es \nthis property because there is a yield statement in the spin loop of thread u. Also, a thread that terminates \nafter executing a .nite number of steps obviously satis.es the good samaritan property. Our scheduler \nintroduces an edge in the priority order only when a thread yields and thereby indicates lack of progress. \nThus, our scheduler ensures that in the absence of yield operations, the priority order remains empty \nand all threads have equal priority. At each scheduling point, the scheduler nondeterministically attempts \nall scheduling choices that respect the priority order. Our intuition is that programs are parsimonious \nin the use of the yield operations as their excessive use may unnecessarily decrease performance. Therefore, \nthese operations are used sparingly, typically at the back edges of spin loops. Consequently, every reachable \nstate is likely to be reachable via a yield-free execution along which our algorithm behaves like the \nstandard nondeterministic scheduler used in model checkers. We provide theoretical results (in Section \n3) characteriz\u00ading the coverage of our algorithm. We also provide experimental evaluation (in Section \n4) to show that our algorithm provides com\u00adplete state coverage on a variety of realistic programs. In \nsummary, fair stateless model checking is a semi-algorithm which takes as input a program that is expected \nto satisfy the good samaritan property and be fair-terminating. There are four out\u00adcomes possible when \nthis algorithm is applied to such a program. 1. The algorithm terminates with a safety violation. 2. \nThe algorithm diverges and generates, in the limit, an in.nite execution that violates the good samaritan \nproperty. 3. The algorithm diverges and generates, in the limit, an in.nite fair execution. 4. The \nalgorithm terminates without .nding any errors.  In theory, the second and third outcomes manifest in \nan in.nite execution being generated. In practice, it is not possible for a stateless model checker to \nidentify or generate an in.nite execution. Therefore, we ask the user to set a large bound on the execution \ndepth. This bound can be orders of magnitude greater than the maximum number of steps the user expects \nthe program to execute. The model checker stops if an execution exceeding the bound is reached and reports \na warning to the user. This execution is then examined by the user to see if it actually indicates an \nerror. In the rare case it is not, the user simply increases the bound and runs the model checker again. \nUsing this mechanism, our algorithm is able to detect the livelock in the program of Figure 1. 3. Fair \nstateless model checking In this section, we describe fair stateless model checking in detail. We .x \na multithreaded program Q with a .nite set Tid of threads. The program Q starts execution in its initial \nstate s0. At each step, one thread in Tid performs a transition and updates the state. In this presentation, \nwe assume that the transition relation of each thread is deterministic and consequently thread scheduling \nis the only source of nondeterminism. However, our method is easily generalized to accommodate a nondeterministic \nbut .nitely-branching thread transition relation. The program Q is equipped with state predicates enabled(t) \nand yield(t) for each thread t . Tid. The predicate enabled(t) is true in a state s iff thread t is enabled \nin s. The predicate yield(t) is true in a state s iff thread t is enabled in s and executing thread t \nin s results in a yield. 1 init.P := {}; 2 .u . Tid : init.E(u) := {}; 3 .u . Tid : init.D(u) := Tid; \n4 .u . Tid : init.S(u) := Tid; 5 curr := init; 6 while true do 7 T := curr.ES \\ pre(curr.P, curr.ES); \n8 if T = {} then 9 return; 10 end 11 t := Choose(T ); 12 next := NextState(curr,t); 13 next.P := curr.P \n\\ (Tid \u00d7{t}); 14 foreach u . Tid do 15 next.E(u) := curr.E(u) n next.ES; 16 if u = t then t . s1 . s2 \n... is a .nite or in.nite sequence of states and transitions. Each such execution is equipped with a \n1 0 t An execution s0 17 next.D(u) := state predicate sched(t) for each thread t . Tid such that for \n all n = 0, sched(t) is true in sn if and only if tn = t. A .nite curr.D(u) . (curr.ES \\ next.ES); 18 \nelse t t . false at sn for each t . Tid. Such a state sn is called a deadlock. 0 s1 . s2 ...sn 1 execution \ns0 is terminating if enabled(t) is 19 next.D(u) := curr.D(u); 20 end A state s is reachable if it is \nthe .nal state of an execution. 21 next.S(u) := curr.S(u) .{t}; tt . all threads t . Tid, if t is enabled \nin.nitely often in s then t is 1 = s0 . s1 0 An in.nite execution s s2 ... is fair iff for 22 end 23 \nif curr.yield(t) then scheduled in.nitely often in s. This property is formalized as the following linear \ntemporal logic [23] formula: SF = .t . Tid : GFenabled(t) . GFsched(t) Every in.nite execution s of Q \nis expected to satisfy the following good samaritan property: GS = .t . Tid : GFsched(t) . GF(sched(t) \n. yield(t)) Intuitively, this property states that for all threads t, if t is scheduled in.nitely often, \nthen in in.nitely many of those t transitions thread t also yields. The fair stateless model checking \nalgorithm, apart from detecting safety violations, also attempts to detect an in.nite execution that \neither violates the good samaritan property or is fair. We refer to the value of the predicates enabled(t), \nsched(t), and yield(t) in state s as s.enabled(t), s.sched(t), and s.yield(t) respectively. We also use \ns.ES to refer to the set {x . Tid |s.enabled(t)} of threads enabled in state s. Given a relation R . \nTid \u00d7 Tid and a set X . Tid, we de.ne pre(R, X)= {x . Tid |.y . Tid :(x, y) . R . y . X}. We present \nthe fair model checking algorithm (Algorithm 1) as a nondeterministic fair scheduler. Our algorithm makes \nexplicit the available nondeterministic choices at each scheduling point. It is easy to augment this \ndescription with either a stack to perform depth-.rst search or a queue to perform breadth-.rst search. \nTo focus on the essence of our algorithm, we have elided the (standard) search mechanism from the algorithm \ndescription. The algorithm takes as input a multithreaded program Q to\u00adgether with its initial state \ninit. It assumes that the program Q comes with a function NextState that takes a state s and a thread \nt and returns the state that results from executing t in state s. The al\u00adgorithm starts with the initial \nstate and an empty execution. In each iteration of the loop (lines 7 30), the algorithm extends the current \nexecution by one step. The algorithm terminates with a complete terminating execution, when the return \nstatement on line 9 is exe\u00adcuted. Each thread t . Tid partitions an execution s into windows; a window \nof thread t lasts from a state immediately after a yielding transition by thread t to the state immediately \nafter the next yielding transition by t. Our algorithm maintains for each state s several 24 H := (next.E(t) \n. next.D(t)) \\ next.S(t); 25 next.P := next.P . ({t}\u00d7 H); 26 next.E(t) := next.ES; 27 next.D(t) := {}; \n28 next.S(t) := {}; 29 end 30 curr := next; 31 end Algorithm 1: Fair stateless model checking auxiliary \npredicates that record information about a window of thread t. 1. S(t) is the set of threads that have \nbeen scheduled since the last yield by thread t. 2. E(t) is the set of threads that have been continuously \nenabled since the last yield by thread t. 3. D(t) is the set of threads that have been disabled by some \ntransition of thread t since the last yield by thread t.  In addition to these predicates, each state \ns also contains a relation s.P which represents a priority ordering on threads. Speci.cally, if (t, u) \n. s.P then t will be scheduled in s only when s.enabled(t) and \u00acs.enabled(u). In each iteration, the \nalgorithm .rst computes T (line 7), the set of schedulable threads that satisfy the priorities in curr.P. \nIf T is empty, then the execution terminates. Otherwise, the algorithm se\u00adlects a thread t nondeterministically \nfrom T (line 11) and schedules t to obtain the next state. It is this nondeterminism inherent in the \nexecution of the Choose(T ) on line 11 that a model checker must explore. As explained earlier, it is \neasy to add systematic depth-.rst or breadth-.rst search capability to our algorithm. Line 13 removes \nall edges with sink t from P to decrease the relative priority of t. The loop at lines 14 22 updates \nthe auxiliary predicates for each thread u . Tid. The set E of continuously enabled threads is updated \nby taking the intersection of its current value with the set of enabled threads in next (line 15). The \nset D of threads disabled by thread t is updated by taking the union of its current value with Figure \n4. Emulation of Algorithm 1 on the spin loop in Figure 3. When thread u yields in the second transition \nfrom state (a,d), the P in the subsequent state ensures that u does not enter the spin loop the second \ntime. the set of threads disabled by the latest transition (line 17). The set of scheduled threads is \nupdated on line 21. Finally, if the transition just executed is a yielding transition, then the data \nstructures are updated appropriately to mark the beginning of a new window of u (line 23 29). The set \nH computed on line 24 contains only those threads that were never scheduled in the current window of \nthread t and were either continuously enabled, or disabled by thread t at some point in the window. Line \n25 reduces the priority of t with respect to the threads in H. Figure 4 shows an emulation of Algorithm \n1 for the program in Figure 3. For conciseness, Figure 4 only shows the emulation when the scheduler \nattempts to schedule the thread u continuously. We focus the emulation on the values of the relation \nP and the predicates S(u), D(u), and E(u). The relation P is initialized to be empty. The predicates \nS(u), D(u) and E(u) are initialized in such a way that their values remain unchanged until the .rst yield \nof thread u. These values also provide the additional guarantee that the update of P at the .rst yield \nof any thread is guaranteed to leave the value of P unchanged. This behavior ensures that the .rst window \nof any thread begins after its .rst yield at which point the predicates S(u), D(u) and E(u) get initialized \nappropriately. In the emulation, the scheduler executes thread u continuously. Starting from the initial \nstate (a,c), the .rst window of u begins once the scheduler has scheduled u twice. At this point, u has \ngone through the spin loop once and the state is (a,c) again. In this state, P = {}, S(u)= {}, D(u)= \n{}, and E(u)= ES = {t, u}. When u is executed for one more step, u is added to S(u) and the state becomes \n(a,d). In this state, yield(u) is true as u will yield if executed from this state. However, the P relation \nis still empty allowing the scheduler to choose either of the two threads. If the scheduler chooses to \nschedule u again, the thread com\u00adpletes the second iteration of the loop and the program enters the state \n(a,c). Algorithm 1 adds the edge (u, t) to P because the set H on line 24 evaluates to {t}. Thus, the \nalgorithm giving the yielding thread u a lower priority than the pending thread t. This update to P makes \nthe set of scheduler choices T = {t}. Thus, the scheduler is forced to schedule t, which enables u to \nexit its loop. Generalizing this example, if the thread t was not enabled in the state (a,c), say if \nt was waiting on a lock currently held by u, the scheduler will continue to schedule u till it releases \nthe lock. Further, if t was waiting on a lock held by some other thread v in the program, the fairness \nalgorithm will guarantee that eventually v makes progress releasing the lock. THEOREM 1. Every in.nite \nexecution s generated by Algorithm 1 satis.es the property GS . SF . PROOF. We do the proof by contradiction. \nSuppose Algorithm 1 t0t1 generates an in.nite execution s = s0 . s1 . s2 ... that satis.es GS but does \nnot satisfy SF . Therefore, there is a thread u such that s satis.es GFenabled(u) . FG\u00acsched(u). That \nis, the execution s eventually reaches a state si after which u is never scheduled but is enabled in.nitely \noften. Let T be the set of threads that are scheduled in.nitely often in s. Since Tid is .nite and s \nis an in.nite execution, the set T is nonempty. Since s satis.es GS, every thread in T must yield in.nitely \noften. There are two cases: thread u is enabled forever after si or thread u is both enabled in.nitely \noften and disabled in.nitely often after si. Case 1: Suppose thread u is enabled forever after si. Consider \nan arbitrary t . T . Since s satis.es GS and t is scheduled in.nitely often in s, there exist j and k \nsuch that i<j<k, sj .sched(t), sj .yield(t), sk.sched(t) and sk.yield(t). Consider the iteration of the \nloop in lines 6 31 of Algorithm 1 in which the curr = sk. Since u is forever enabled but never scheduled \nafter si, we have that u . next.E(t) and u . next.S(t) at line 24. Therefore, at line 25 u . H and the \nedge (t, u) is added to next.P. Since thread u is continuously enabled after si and therefore after sk, \nthe edge (t, u) precludes the scheduling of t after sk (line 7). This is a contradiction since t is scheduled \nin.nitely often. Case 2: Suppose thread u is both enabled in.nitely often and disabled in.nitely often \nafter si. Since T is .nite, there must be some thread t . T that disables u in.nitely often. Since s \nsatis.es GS and t is scheduled in.nitely often in s, t dis\u00adables u at some point after i and between \ntwo states where yield(t) holds. Formally, there exist j such that i<j< k = l, sj .sched(t), sj .yield(t), \nsk.sched(t), sk.enabled(u), \u00acsk+1.enabled(u), sl.sched(t), and sl.yield(t). Consider the iteration of \nthe loop in lines 6 31 of Algorithm 1 in which the curr = sl. Since u is never scheduled after si, we \nhave that u . next.D(t) and u . next.S(t) at line 24. Therefore, at line 25 u . H and the edge (t, u) \nis added to next.P. Since thread u is never scheduled after si and therefore after sk, the edge (t, u) \nis present in sn.P for all n = k. This edge precludes the scheduling of t after sk (line 7) whenever \nthread u is also enabled. This is a contradiction since thread t disables thread u in.nitely often. 0 \nTheorem 1 yields the following termination guarantee about Algorithm 1. THEOREM 2. If no in.nite execution \nof Q satis.es the property GS . SF , then Algorithm 1 terminates on Q. PROOF. We do the proof by contradiction. \nSuppose Algorithm 1 does not terminate on Q. Then the tree of executions explored by the algorithm is \nin.nite. Since Tid is .nite, this execution tree is .nitely branching. By K\u00a8 onig s lemma, there must \nbe an in.nite execution in this tree. Since every execution generated by Algorithm 1 is an execution \nof Q, this execution must satisfy GS . SF (by Theorem 1). Hence, we arrive at a contradiction. 0 Now, \nwe prove certain desirable properties of the fair model checking algorithm. THEOREM 3. At line 7 of Algorithm \n1, the set T is empty if and only if the set curr.ES is empty. PROOF. The proof relies on the fact that \nthe P relation when viewed as edges in a graph with nodes from Tid contains no cycles. The loop invariant \nat line 6 requiring that curr.P is an acyclic relation is suf.cient to prove our theorem. We .rst prove \nthis loop invariant. Upon loop entry, we have curr = init. The relation curr.P is empty and the invariant \nis trivially true. Consider an arbitrary iteration of the loop. We assume the loop invariant at the beginning \nof this iteration and prove it at the end. In each iteration of the loop, whenever outgoing edges from \nt are added to P at line 25, all incoming edges into t have already been removed earlier at line 13. \nLine 21 adds t to next.S(u) for all u . Tid and therefore it is guaranteed that graph after the execution \nof ti the second time the unfair cycle is executed. Since u is never scheduled, this edge is not removed, \nand consequently ti cannot be scheduled at the next occurrence of xi. Case 2: Suppose there exists i \n. [0,n] such that xi.enabled(u) and \u00acxN(i).enabled(u). Since every in.nite execution of Q satis\u00ad.es GS, \nthere exists j . [0,n] such that ti = tj and xj .yield(tj ) is true. Therefore the edge (tj ,u) is added \nto the priority graph af\u00adter the execution of tj the second time the unfair cycle is executed. Since \nu is never scheduled, this edge is not removed, and conse\u00adquently ti = tj cannot be scheduled at the \nnext occurrence of xi. 0 Now, we present two theorems that characterize the soundness of our algorithm \non .nite-state systems. Consider a .nite transition t = x0 . x1 \u00b7\u00b7\u00b7 xn 0 . The yield count of thread \nt insequence a a, denoted by d(a, t), is the cardinality of the set {0 = i< nt = ti The yield count \nof a, denoted by t . next.S(t) at line 24 and t . H at line 25. Thus, even line 25 |. xi.yield(t)}. d(a) \nis the maximum of d(a, t) over all threads t . Tid. The does not add any incoming edges into t and each \niteration of the loop leaves P acyclic. We now show that the loop invariant implies our theorem. Clearly, \nif curr.ES is empty at line 7 then T is also empty. We prove the other direction by contradiction. Suppose \nT is empty but curr.EnabledSet is nonempty. Therefore curr.ES . pre(curr.P, curr.ES). Consider the projection \nof the relation curr.P relation on to the set curr.ES. Since curr.P is acyclic and yield count of a reachable \nstate s is the minimum of d(s) over all executions s whose .nal state is s. The following theorem captures \nthe soundness guarantee of our algorithm for safety properties. THEOREM 5. Algorithm 1 either generates \nan in.nite execution or visits every reachable state of Q whose yield count is zero. curr.ES is nonempty, \nthis projection is a nonempty acyclic rela\u00adtion and therefore contains a maximal element. That is, there \nexists t . curr.ES such that .u . curr.ES :(t, u) . curr.P. This contradicts our assumption curr.ES . \npre(curr.P, curr.ES). 0 Theorem 3 guarantees that Algorithm 1 never reports a false deadlock. In practice, \nthis means that the algorithm can always drive the program to a terminating state, without requiring \nthe execution to be pruned at a partial execution. Such pruning, as can typically happen with depth-bounding \ntechniques, avoids wasting scarce model checking resources. While the theorems above hold even for in.nite-state \nsystems, the theorems stated below provide intuition for the ef.cacy of the fair model checking algorithm \non .nite-state systems. For the re\u00admainder of this section, we assume that Q is a .nite-state program. \nFor .nite-state systems, all in.nite behaviors traverse cycles 0 t in the state space. A cycle t is a \ntransition sequence x0 . PROOF. Suppose Algorithm 1 does not generate an in.nite execu\u00adtion. Therefore, \nthe tree of executions explored by the algorithm is .nite (by K\u00a8onig s lemma). This tree is guaranteed \nto contain all executions whose yield count is zero because along such an execu\u00adtion the priority graph \nremains empty throughout. Every reachable state of Q with yield count zero is the .nal state of an execution \nin which there are no yields. Therefore, the algorithm eventually visits all such reachable states. 0 \nEvery in.nite execution generated by our algorithm reveals a liveness error (Theorem 1). Theorem 5 indicates \nthat our algorithm is sound with respect to safety properties if the program Q does not have any liveness \nerrors and all reachable states are reachable by yield-free executions. Theorem 6 below captures the \nsoundness of our algorithm with respect to liveness properties as well. THEOREM 6. Suppose x0 is a reachable \nstate of Q whose yield tt 0 = x0 . x1 \u00b7\u00b7\u00b7 xn count is zero and t n . x0 is a fair cycle whose yield \ncount is at most one. Then Algorithm 1 generates an in.nite t . x0 such that the states x0,x1,...,xn \nThe cycle t is reachable if the state x0 is reachable. The cycle t n are all distinct. x1 \u00b7\u00b7\u00b7 xn execution. \nis fair if for every thread t . Tid, either \u00acxi.enabled(t) for all i . [0,n] or t = ti for some i . [0,n]. \nThe cycle t is unfair if it is not fair. Note that an in.nite execution that traverses an unfair cycle \nforever is not fair. The following theorem shows that our algorithm unrolls an unfair cycle fully at \nmost twice and thus signi.cantly reduces wasteful search. THEOREM 4. Suppose every in.nite execution \nof Q satis.es the t property GS, s0 . s1 \u00b7\u00b7\u00b7 x0 is a .nite execution of Q, and PROOF. We do the proof \nby contradiction. Suppose Algorithm 1 does not generate an in.nite execution. By Theorem 5, the state \nx0 is eventually visited with an empty priority graph. If the yield count of t is zero, then there are \nno yields in t and t can be executed repeatedly to generate an in.nite execution. Suppose the yield count \nof t is one. Since t is fair, every thread that is enabled anywhere in the cycle is also scheduled in \nthe cycle. Moreover, a thread t may yield at most once in t . Therefore, the set S(t) contains both E(t) \nand D(t) at the unique yield point of t, if any. Consequently, the yield of t does not add any edges \nto P. 0 As discussed in Section 2, we expect that all reachable states tt 0 x0 . x1 \u00b7\u00b7\u00b7 xn n n . x0 \nis an unfair cycle in Q. Then, Algorithm 1 t does not generate the execution s0 . s1 \u00b7. tt 0 \u00b7\u00b7 x0 . \nx1 \u00b7\u00b7\u00b7 xn are reachable by a yield-free execution due to the parsimonious use t t t 0 n 0 x0 . x1 \u00b7\u00b7\u00b7 \nxn . x0 . x1 \u00b7\u00b7\u00b7 xn. of the yield operation by real programs. If this is not the case, then our algorithm \ncan be parameterized by a small constant k> 0 so as to only process every k-th yield of a thread. The \nsoundness theo\u00ad tt n 0 . x1 \u00b7. x0 is an unfair cycle, there is a thread u such that u = ti for all i \n. [0,n] and xi.enabled(u) PROOF. Since x0 \u00b7\u00b7 xn rems (both for safety and liveness) for the parameterized \nalgorithm for some i . [0,n]. Let N(i) denote (i + 1)mod(n + 1). Since are straightforward generalizations \nof the corresponding theorems xi.enabled(u) for some i . [0,n], there are only two cases: either stated \nabove. xi.enabled(u) for all i . [0,n] or there exists i . [0,n] such that xi.enabled(u) and \u00acxN(i).enabled(u). \nCase 1: Suppose xi.enabled(u) for all i . [0,n]. Since every in.nite execution of Q satis.es GS, there \nexists i . [0,n] such 4. Evaluation This section presents the empirical evaluation of the fair demonic \nthat xi.yield(ti) is true. Therefore the edge (ti,u) is in the priority scheduler described in Section \n3. We have implemented our algo\u00adTable 1. Characteristics of input programs to CHESS Programs LOC Threads \nSynch Ops Dining Philosophers 54 3 48 Work-Stealing Queue 1266 3 99 Promise 14044 3 26 APE 18947 4 247 \nDryad Channels 16036 5 273 Dryad Fifo 18093 25 4892 Singularity kernel 174601 14 167924 rithm in the \nCHESS software model checker. CHESS is designed for systematic testing of shared-memory multithreaded \nprograms. To use CHESS, the user provides a test case that exercises a concurrent scenario. CHESS executes \nthis test repeatedly, while controlling the thread schedule such that every execution of the test takes \na differ\u00adent interleaving. CHESS is stateless and avoids capturing any state, including the initial state \nof the program, during state-space search. The implementation of the fair scheduler in CHESS maintains \ndata structures to implement the auxiliary state used in Algorithm 1. An important issue is the inference \nof yielding transitions; our im\u00adplementation treats every synchronization operation with a .nite timeout \nand every explicit processor yield as yielding operations. Another important issue is the integration \nof fair-scheduling with the context-bounded search [22] strategy implemented in CHESS. In a concurrent \nexecution, a preemption occurs when the scheduler forces a context switch despite the current running \nthread being en\u00adabled. Context-bounded search explores only those executions in which the number of preemptions \nis bounded by a small number provided by the user of CHESS. Fair scheduling is easily combined with context-bounding. \nThe only subtle aspect of the combination is that fair scheduling can introduce a preemption when the \ncur\u00adrently running thread gets a lower priority than another enabled thread. For soundness of the context-bounded \nsearch, it is impor\u00adtant to not count such preemptions. 4.1 Ability to handle large nonterminating programs \nPrior to the implementation of the fair scheduler, CHESS, like other stateless model checkers, could \nonly handle terminating programs. As depth bounding was unsatisfactory for our purposes, any in\u00adput program \nwith nonterminating behavior required manual mod\u00adi.cation. As an example of the effort required, consider \nthe sim\u00adple program in Figure 3. One can .x the nonterminating behavior by introducing a synchronization \nvariable that u blocks on when waiting for an update to x. In addition, the behavior of t (and all other \nthreads that access x) should be modi.ed to appropriately signal the synchronization variable after an \nupdate to x, a non-local change to the program. Finally, one has to ensure that the intro\u00adduced synchronization \ndoes not result in deadlocks due to adverse interactions with existing synchronizations in the program. \nIn prac\u00adtice, such modi.cations typically require intimate knowledge of the program, and in our experience, \nare dif.cult and error-prone. Pre\u00adviously, it took us several weeks to prepare a realistic program as \nan input to CHESS. With the fair scheduler in place, CHESS could readily handle nonterminatingprograms. \nTable 1describestheprograms CHESS is currently able to handle. Table 1 also provides the maximum num\u00adber \nof threads created and synchronization operations performed per execution of these programs in CHESS. \nIn particular, we are able to systematically test the entire boot and shutdown process of the Singularity \noperating system [13]. Also, we have run CHESS on unmodi.ed versions of Dryad, a distributed execution \nengine for coarse-grained data-parallel applications [15], and APE (Asyn\u00adchronous Processing Environment), \na library in the Windows oper\u00adating system that provides a set of data structures and functions for asynchronous \nmultithreaded code. Apart from these large programs, CHESS is also able to handle low-level synchronization \nlibraries that typically employ nonblock\u00ading algorithms. Manually modifying them to be terminating is \nei\u00adther impossible or requires algorithmic changes. We have applied CHESS to an implementation [20] of \nthe work-stealing queue algo\u00adrithm originally designed for the Cilk multithreaded programming system \n[7], and Promise, a library for data-parallel programs. 4.2 Coverage of safety properties This section \ndemonstrates that the fairness algorithm is effective for checking safety properties. First, we show \nthat the algorithm achieves 100% state coverage for the .rst two programs in Table 1. Also, we show that \nfairness signi.cantly improves the speed of the state space search, for various search strategies. Finally, \nwe demon\u00adstrate the ability of the the fairness algorithm to .nd both existing and previously unknown \nsafety violations in large programs. All the experiments described in the paper were performed on an \noff-the-shelf computer with Intel Xeon 2.80GHz CPU with 2 processors and 3 GB of memory running Windows \nVista Enterprise operating system. 4.2.1 State coverage CHESS is a stateless model checker and thus does \nnot have the capability to capture program states. To measure state coverage, we manually added facilities \nto extract states for two examples; the dining philosophers and the work-stealing queue. The state of \nthese programs consists of the state of all global variables, the heap, and the stack of all threads \nin the program. While the bits com\u00adprising the state can be automatically extracted, we had to manu\u00adally \nabstract the (in.nite) state of the program into a reasonable, .nite representation. Also, in order to \navoid multiple representa\u00adtions of behaviorally equivalent heaps, we used a simple heap\u00adcanonicalization \nalgorithm [14]. Table 2 shows the results from our coverage experiments for these two examples, each \nwith two con.gurations. For each of the con.gurations, we used four search strategies a context-bounded \nsearch with bounds (cb) from 1 to 3 and a depth-.rst search (dfs). For each strategy, we ran CHESS with \nand without the fairness algorithm. As termination is not guaranteed without fairness, the search proceeds \nonly upto a depth bound (db) varying from 20 to 60. Once the depth-bound is reached, a random search \n[17] is performed until the end of the execution is reached. New states visited during the random search \nare included while measuring state coverage. To measure the total number of states reachable with a strategy, \nwe also performed a stateful search of the state space and stored the state signatures in a hash table. \nWe used this table to check if the subsequent runs cover all of the states. In our experiments, we found \nthat the fairness algorithm achieves 100% coverage on all but one of the cases. The fairness algorithm \ntimes out for a depth-.rst search strategy on the work-stealing queue with two stealers. The fourth column \nin Table 2 shows the number of states explored with fairness, and except for the one case above, this \nnumber is greater than or equal to the total number of states in the third column. The number of states \nexplored with fairness is larger than the total number of states, as the fairness algorithm introduces \nadditional preemption points. This essentially forces the fairness algorithm to visit states that are \nbeyond the cur\u00adrent context-bound. For comparison, Table 2 also shows the number of states visited for \nruns without fairness with different depth bounds. For some runs, the search with small depth bounds \nterminate without visiting all the states. In other cases with larger depth-bounds, the search Con.guration \nSearch Strategy Total States With Fairness Without fairness db=20 db=30 db=40 db=50 db=60 Dining cb=1 \n27 27 27 27 27 27 27 Philosophers cb=2 28 28 28 28 28 28 28 2 philosophers cb=3 29 29 29 29 29 29 29 \ndfs 29 29 29 29 29 29 29 Dining cb=1 102 102 102 102 102 102 102 Philosophers cb=2 144 144 143 144 144 \n144 144 3 philosophers cb=3 167 171 167 169 169 169 169 dfs 177 177 174 177 177 168* 139* Work-Stealing \ncb=1 278 278 236 278 278 278 278 Queue cb=2 814 814 554 765 814 814 814 1 stealer cb=3 1287 1297 694 \n1133 1287 1287 1287 dfs 1726 1726 871 1505 1726 1307* 683* Work-Stealing cb=1 350 378 238 334 350 350 \n350 Queue cb=2 1838 2000 971 1630 1822 1838 1838 2 stealers cb=3 3271 3311 dfs 4826 1321* Table 2. within \n5000 seconds is marked with a *. times out. For the work-stealing queue with two stealers, all runs using \nthe depth-bounded strategy time out.  4.2.2 Rate of state coverage Fair stateless search can be more \nef.cient as it does not unroll un\u00adfair cycles in the state space (Theorem 4). To quantify this, Fig\u00adures \n5 and 6 show the time taken to complete the search for two of the four con.gurations in Table 2. The \nresults were similar for the other two (smaller) con.gurations. The .gures show the time taken to complete \nthe search for each of the search strategies with and without fairness. For the runs without fairness, \nwe report the time for various depth bounds. Note, the y-axis on these .gures is in log scale. The runs \nwith fairness explores the state space exponentially faster than the runs without fairness, without sacri.cing \nstate cov\u00aderage. In Figure 6, for cb=3 strategy, the run with a depth bound of 20 completes faster than \nthe run with fairness but does not cover all states. Also, the depth-.rst strategy times out in all runs. \n 4.2.3 Ability to .nd errors The experiments above show that fairness improves the ef.cacy of safety \nchecking without sacri.cing soundness for two programs. On larger programs, for which state extraction \nis not manually feasible, we demonstrate the ef.cacy of the fairness algorithm indirectly by demonstrating \nits ability to .nd safety errors in the programs. A prior version of CHESS had found six bugs on versions \nof the work-stealing queue and the Dryad channels, modi.ed to be termi\u00adnating. We ran CHESS on the unmodi.ed \nprograms with a context\u00adbound of 2 preemptions, both with and without fairness. Since these programs \nare nonterminating, we set the depth-bound to 250 for the search without fairness. This depth-bound is \nthe minimum re\u00adquired to .nd these errors. Table 3 compares the performance of the search with fairness \nto the search without fairness. As the table shows the fairness algorithm .nds the .rst .ve errors much \nfaster both in terms of the number of executions explored prior to the buggy execution and the time taken \nfor the search. The sixth error is not found by the search without fairness. The seventh row in Table \n3 shows a previously unknown bug that the fairness algorithm found in Dryad. The bug is caused by an \nincorrect .x of bug 3 by the developer of Dryad. This error is also not found by the search without fairness. \nFigure 6. Work-stealing queue (2).  4.3 Liveness violations The fairness algorithm diverges in two \ncases, when the program violates the good samaritan property (Section 2) or contains a live\u00adlock. Both \nthese outcomes indicate correctness or performance er\u00adrors in the program. We demonstrate one instance \nof each violation that CHESS found in existing programs. Bugs No. of executions Time (secs) With Fairness \nWithout Fairness With Fairness Without Fairness WSQ bug 1 WSQ bug 2 WSQ bug 3 Dryad bug 1 Dryad bug 2 \nDryad bug 3 Dryad bug 4 82 112 212 310 4002 25113 21014 182 432 843 11024 47030 -- 2 8 12 8 114 754 677 \n8 24 74 273 1247 >7200 >7200 Table 3. Number of executions of the test and the time required to .nd \nerrors with and without fairness in work-stealing queue (WSQ) and Dryad channels. The fourth Dryad error \nis a previously unknown error that CHESS found in the .x of the .rst three errors. void Worker::Run(Object \nobj) { while (!stop) { while (!stop &#38;&#38; task != null) { // perform task ... task = PopNextTask(); \n} if (!stop) { task = group.Idle(this); } } } Task WorkerGroup::Idle(Worker currentWorker) { while (!stop) \n{ ... // No work to be found // Yield to other threads. currentWorker.YieldExponential(); ... } return \nnull; } Figure 7. Violation of the good samaritan property. Under certain cases, the outer loop in Worker::Run \nresults in the thread spinning idly till time-slice expiration. 4.3.1 Good samaritan property violation \nWeused CHESS totesttheimplementationofalibrarythatprovides ef.cient parallel execution of tasks. This \nlibrary maintains a col\u00adlection of worker threads, partitioned into a set of worker groups. CHESS detected \na violation of the good samaritan property during the shutdown of the library. There is a .eld called \nstop in both the Worker and WorkerGroup classes. During the shutdown pro\u00adcess, the stop .eld in a worker \ngroup and the stop .eld in each worker of that worker group is set to true, causing all the workers to \neventually .nish. However, there is a small window of time dur\u00ading which the stop .eld in the worker \ngroup is true but the stop .eld in one of the workers is false. In this situation, if the queue of tasks \nis empty, then the worker spins in a loop without yielding the processor until its time-slice expires. \nThis behavior starves other threads, potentially including the one that is responsible for setting the \nstop .eld of the worker to true. volatile int x; //... int x_temp = InterlockedRead(x); if(common case \n1) break; if(common case 2) break; ... // spin in the uncommon case while(x_temp != 1){ Sleep(1); //yield \n// BUG: should read x once again } Figure 8. The spinloop incorrectly waits on a temporary cache of the \nglobal variable, resulting in a livelock. 4.3.2 Livelock in Promise We used CHESS to test the implementation \nof promises, a con\u00adcurrency primitive for specifying data parallelism. The implemen\u00adtation is optimized \nfor ef.ciency and selectively uses low-level hardware primitives for performance. CHESS detected a livelock \nin promises caused by simple programming error. While we are unable to provide the actual code snippet, \nFigure 8 shows pseudo\u00adcode exhibiting the same error. For the sake of performance, programmers tend to \nmake local copies of shared global variables. The livelock in Figure 8 occurs when the program erroneously \nwaits for the local copy to change, without updating the copy with the value in the global variable. \nThis bug was hard to detect as it only occurred in those rare thread interleavings in which the common \ncases shown in the pseudo-code were inapplicable. 5. Related work The need for fairness when reasoning \nabout concurrent programs is well known [19, 2, 6, 3, 10]. Of the different useful notions of fairness \n[6, 18], this paper deals with strong fairness (also known as strong process fairness [3] or fairness \n[19]). Fairness has also been studied extensively in the context of model checking [5, 24, 25, 1, 12] \nof temporal logic speci.cations, all of which deal with stateful model checking. To our knowledge, this \npaper is the .rst to propose fairness as a means of improving the ef.cacy of stateless model checking \nfor safety veri.cation. Also, this paper is the .rst to extend the ability of stateless model checking \nto comprehensively detect livelocks. Our fair scheduling algorithm is related to the explicit scheduler \nconstruction in Apt and Olderog [2, 6]. This scheduler is primarily used as a proof methodology for proving \nthe termination of con\u00adcurrent programs. In particular, the scheduler requires generating a random integer \nfor the priority of a thread after every step. Such unbounded nondeterminism [10], while useful in generating \nall fair schedules of a program, cannot be effectively implemented in a model checker. In contrast, our \nalgorithm requires a .nite choice among a subset of enabled threads at each step of the execution. Most \noperating system schedulers employ mechanisms to fairly share resources among competing threads and users. \nThese algo\u00adrithms typically manipulate priorities [16, 11] based on resource usage or use randomized \nschemes [27] to guarantee fairness. These algorithms are not designed to expose the nondeterministic \nchoices of the scheduler and cannot be used in a model checker. The model checker described in this paper \nbelongs to the class that directly execute programs [8, 26, 21, 28] (as opposed to ana\u00adlyzing abstract \nprogram models). The technique of stateless model checking was proposed in Verisoft [8] and has been \nsuccessful for systematically testing industrial concurrent systems [4]. Stateless model checking typically \nrelies on partial-order reduction tech\u00adniques [9] to reduce the state space explored. Partial-order reduc\u00adtion \ncan only determine the equivalence of two executions of the same length and thus is inherently incapable \nof detecting equiva\u00adlence of executions that revisit the same state in a cycle. Partial\u00adorder reduction, \nhowever, can be used to signi.cantly reduce the set of all fair schedules of fair-terminating programs, \nan interesting avenue of future research that we are currently pursuing. Killian et al. [17] use a hybrid \nstateful and stateless technique to .nd liveness errors in network protocols. Their algorithm can only \n.nd those liveness violations that are characterized by the presence of dead states and will not .nd \nthe livelock in the dining philosopher example (Section 1) or the violation of the good samaritan property, \ndescribed in Section 4.3.1. Also, their algorithm provides no soundness guarantees of .nding livelocks. \n6. Conclusions and future work This paper proposes the use of a fair scheduler in stateless model checking. \nFairness both enables the detection of liveness errors and substantially improves the ef.ciency of safety \nveri.cation in a stateless model checker. The incorporation of the fair scheduling algorithm in the CHESS \nmodel checker has signi.cantly improved the applicability of CHESS to large nonterminating programs. \nThe fairness-enhanced CHESS has found many liveness errors in several industry-scale programs. Currently, \nCHESS checks two liveness properties: fair termina\u00adtion and the good-samaritan rule. We would like to \nextend CHESS to check an arbitrary liveness property. To motivate this work, we are currently identifying \nliveness properties that are useful for mul\u00adtithreaded software. We are also investigating extensions \nto the fair scheduler to handle unbounded thread creation. Acknowledgements We thank Tom Ball for help \nwith the evaluation of the fair sched\u00aduler. We also thank Patrice Godefroid, Andreas Podelski, Mihalis \nYannakakis, and the reviewers for valuable comments on a prior version of the paper. References [1] S. \nAggarwal, C. Courcoubetis, and P. Wolper. Adding liveness properties to coupled .nite-state machines. \nACM Transactions on Programming Languages and Systems, 12(2):303 339, 1990. [2] K.R. Apt and E.-R. Olderog. \nProof rules and transformations dealing with fairness. Science of Computer Programming, 3:65 100, 1983. \n[3] Krzysztof R. Apt, Nissim Francez, and Shmuel Katz. Appraising fairness in languages for distributed \nprogramming. In POPL 87: Principles of Programming Languages, pages 189 198, 1987. [4] Satish Chandra, \nPatrice Godefroid, and Christopher Palm. Software model checking in practice: an industrial case study. \nIn ICSE 02: International Conference on Software Engineering, pages 431 441, 2002. [5] E.M. Clarke and \nE.A. Emerson. Synthesis of synchronization skeletons for branching time temporal logic. In Logic of Programs, \nLNCS 131, pages 52 71. Springer-Verlag, 1981. [6] Nissim Francez. Fairness. In Texts and Monographs in \nComputer Science. Springer-Verlag, 1986. [7] Matteo Frigo, Charles E. Leiserson, and Keith H. Randall. \nThe implementation of the Cilk-5 multithreaded language. In PLDI 98: Programming Language Design and \nImplementation, pages 212 223. ACM Press, 1998. [8] P. Godefroid. Model checking for programming languages \nusing Verisoft. In POPL 97: Principles of Programming Languages, pages 174 186. ACM Press, 1997. [9] \nPatrice Godefroid. Partial-Order Methods for the Veri.cation of Concurrent Systems: An Approach to the \nState-Explosion Problem. LNCS 1032. Springer-Verlag, 1996. [10] Orna Grumberg, Nissim Francez, and Shmuel \nKatz. Fair termination of communicating processes. In PODC 84: Principles of Distributed Computing, pages \n254 265. ACM Press, 1984. [11] Joseph L. Hellerstein. Achieving service rate objectives with decay usage \nscheduling. IEEE Transactions on Software Engineering, 19(8):813 825, 1993. [12] G. Holzmann. The model \nchecker SPIN. IEEE Transactions on Software Engineering, 23(5):279 295, May 1997. [13] Galen C. Hunt, \nMark Aiken, Manuel Fhndrich, Chris Hawblitze\u00adland Orion Hodson, James R. Larus, Steven Levi, Bjarne Steensgaard, \nDavid Tarditi, and Ted Wobber. Sealing OS processes to improve de\u00adpendability and safety. In Proceedings \nof the EuroSys Conference, pages 341 354, 2007. [14] Radu Iosif. Exploiting heap symmetries in explicit-state \nmodel checking of software. In ASE 01: Automated Software Engineering, pages 254 261, 2001. [15] Michael \nIsard, Mihai Budiu, Yuan Yu, Andrew Birrell, and Dennis Fetterly. Dryad: distributed data-parallel programs \nfrom sequential building blocks. In Proceedings of the EuroSys Conference, pages 59 72, 2007. [16] J. \nKay and P. Lauder. A fair share scheduler. Communications of the ACM, 31(1):44 55, 1988. [17] Charles \nEdwin Killian, James W. Anderson, Ranjit Jhala, and Amin Vahdat. Life, death, and the critical transition: \nFinding liveness bugs in systems code. In NSDI 07: Symposium on Networked Systems Design and Implementation, \npages 243 256, 2007. [18] M. Z. Kwiatkowska. Survey of fairness notions. Information and Software Technology, \n31(7):371 386, 1989. [19] Daniel J. Lehmann, Amir Pnueli, and Jonathan Stavi. Impartiality, justice and \nfairness: The ethics of concurrent termination. In ICALP 81: International Conference on Automata Languages \nand Programming, pages 264 277, 1981. [20] Daan Leijen. Futures: a concurrency library for C#. Technical \nReport MSR-TR-2006-162, Microsoft Research, 2006. [21] M. Musuvathi, D. Park, A. Chou, D. Engler, and \nD. L. Dill. CMC: A pragmatic approach to model checking real code. In OSDI 02: Operating Systems Design \nand Implementation, pages 75 88, 2002. [22] Madanlal Musuvathi and Shaz Qadeer. Iterative context bounding \nfor systematic testing of multithreaded programs. In PLDI 07: Programming Language Design and Implementation, \npages 446 455, 2007. [23] Amir Pnueli. The temporal logic of programs. In FOCS 77: Foundations of Computer \nScience, pages 46 57, 1977. [24] J. Queille and J. Sifakis. Speci.cation and veri.cation of concurrent \nsystems in CESAR. In Fifth International Symposium on Program\u00adming, LNCS 137, pages 337 351. Springer-Verlag, \n1981. [25] M. Y. Vardi and P. Wolper. An automata-theoretic approach to automatic program veri.cation. \nIn LICS 86: Logic in Computer Science, pages 322 331. IEEE Computer Society Press, 1986. [26] W. Visser, \nK. Havelund, G. Brat, and S. Park. Model checking programs. In ASE 00: Automated Software Engineering, \npages 3 12, 2000. [27] Carl A. Waldspurger and William E. Weihl. Lottery scheduling: Flexible proportional-share \nresource management. In OSDI 94: Operating Systems Design and Implementation, pages 1 11, 1994. [28] \nJunfeng Yang, Paul Twohey, Dawson R. Engler, and Madanlal Musuvathi. Using model checking to .nd serious \n.le system errors. ACM Transactions on Computer Systems, 24(4):393 423, 2006.  \n\t\t\t", "proc_id": "1375581", "abstract": "<p>Stateless model checking is a useful state-space exploration technique for systematically testing complex real-world software. Existing stateless model checkers are limited to the verification of safety properties on terminating programs. However, realistic concurrent programs are nonterminating, a property that significantly reduces the efficacy of stateless model checking in testing them. Moreover, existing stateless model checkers are unable to verify that a nonterminating program satisfies the important liveness property of livelock-freedom, a property that requires the program to make continuous progress for any input.</p> <p>To address these shortcomings, this paper argues for incorporating a fair scheduler in stateless exploration. The key contribution of this paper is an explicit scheduler that is (strongly) fair and at the same time sufficiently nondeterministic to guarantee full coverage of safety properties.We have implemented the fair scheduler in the CHESS model checker. We show through theoretical arguments and empirical evaluation that our algorithm satisfies two important properties: 1) it visits all states of a finite-state program achieving state coverage at a faster rate than existing techniques, and 2) it finds all livelocks in a finite-state program. Before this work, nonterminating programs had to be manually modified in order to apply CHESS to them. The addition of fairness has allowed CHESS to be effectively applied to real-world nonterminating programs without any modification. For example, we have successfully booted the Singularity operating system under the control of CHESS.</p>", "authors": [{"name": "Madanlal Musuvathi", "author_profile_id": "81100333862", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1022821", "email_address": "", "orcid_id": ""}, {"name": "Shaz Qadeer", "author_profile_id": "81100286660", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1022822", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1375581.1375625", "year": "2008", "article_id": "1375625", "conference": "PLDI", "title": "Fair stateless model checking", "url": "http://dl.acm.org/citation.cfm?id=1375625"}