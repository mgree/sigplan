{"article_publication_date": "09-09-2012", "fulltext": "\n Experience Report: a Do-It-Yourself High-Assurance Compiler Lee Pike Nis Wegmann Galois, Inc. University \nof Copenhagen leepike@galois.com niswegmann@gmail.com Abstract Embedded domain-speci.c languages (EDSLs) \nare an approach for quickly building new languages while maintaining the advantages of a rich metalanguage. \nWe argue in this experience report that the EDSL approach can surprisingly ease the task of building \na high-assurance compiler. We do not strive to build a fully formally\u00adveri.ed tool-chain, but take a \ndo-it-yourself approach to increase our con.dence in compiler-correctness without too much effort. Copilot \nis an EDSL developed by Galois, Inc. and the National Institute of Aerospace under contract to NASA for \nthe purpose of runtime monitoring of .ight-critical avionics. We report our expe\u00adrience in using type-checking, \nQuickCheck, and model-checking off-the-shelf to quickly increase con.dence in our EDSL tool\u00adchain. Categories \nand Subject Descriptors D.2.4 [Software/Program Veri.cation]: Reliability General Terms Languages, Veri.cation \nKeywords embedded domain-speci.c language, compiler, veri.\u00adcation 1. Introduction The do-it-yourself \n(DIY) culture encourages individuals to de\u00adsign and craft objects on their own, without relying on outside \nex\u00adperts. DIY construction should be inexpensive with easy-to-access materials. Ranging from hobbyist \nelectronics1 to urban farming to fashion, DIY is making somewhat of a resurgence across the United States. \nWe see no reason why DIY culture should not also extend to compilers, and in particular, to high-assurance \ncompilers. By high\u00adassurance, we mean a compiler that comes with compelling evi\u00addence that the source \ncode and object code have the same opera\u00adtional semantics. High-assurance compilers development has traditionally \nre\u00adquired years of effort by experts. A notable early effort was the CLI Stack, of which a simple veri.ed \ncompiler was one part [17]. The CLI Stack was veri.ed by the precursor to the ACL2 theorem prover. The \nmost recent instance is CompCert, which compiles a 1 This even includes full-featured unpiloted air vehicles! \nSee http:// diydrones.com/. Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. ICFP 12, September 9 15, 2012, Copenhagen, Denmark. Copyright c &#38;#169; 2012 \nACM 978-1-4503-1054-3/12/09. . . $10.00 Sebastian Niller Alwyn Goodloe Unaf.liated NASA sebastian.niller@gmail.com \na.goodloe@nasa.gov  subset of C suitable for embedded development to machine code for a number of targets \n[16]. CompCert is formally veri.ed in the Coq theorem-prover indeed, CompCert is written in Coq s spec\u00adi.cation \nlanguage. While CompCert achieves the highest levels of assurance, generating the evidence comes at a \nsteep price, since it relies on manually interacting with a theorem-prover. Neither the CLI Stack nor \nCompCert are DIY projects: building them requires relatively esoteric skills that combine interactive \ntheorem-proving and multiple engineer-years of veri.cation effort. In this experience report, we argue \nthat by leveraging functional languages and off-the-shelf veri.cation tools, we can accumulate signi.cant \nevidence of correctness at a fraction of the cost and with\u00adout the specialized know-how required by interactive \nveri.cation approaches. The case-study of our approach is the Copilot language and toolset, developed \nby Galois, Inc. and the National Institute of Aerospace under contract to NASA. Copilot is a stream language \nfor generating embedded C-code software monitors for system properties. Copilot itself is not comparable \nto a veri.ed compiler like CompCert: Copilot back-ends stop at the C level, where Com\u00adpCert starts. Verifying \nC semantics against the semantics of a ma\u00adchine model is extraordinarily dif.cult. Still, for high-level \nlan\u00adguages, we can do much better than the status quo. Speci.cally, we employ three not-so-secret weapons \nfrom the functional languages and formal methods communities in our work. 1. Embedded DSLs: We implement \nCopilot as an embedded domain-speci.c (EDSL) language [15] within Haskell. 2. Sub-Turing complete languages: \nCopilot is targeted at embed\u00added programming, therefore we focus on the class of programs that are computable \nin constant time and constant space. 3. A verifying compiler: CompCert typi.es a veri.ed compiler ap\u00adproach \nin which the compiler itself is proved correct. A verify\u00ading compiler is one that provides evidence that \na speci.c com\u00adpilation is correct [19]. We borrow from this second approach. (We emphasize that this \nreport is about assurance of the EDSL compiler itself, not about the functional correctness of programs \nwritten in the EDSL.)  While the approaches we describe are known within the func\u00adtional programming \nand formal methods communities, the pur\u00adpose of this experience report is to demonstrate the engineering \nease in putting them to use. In particular, the EDSL approach is well-known for quickly prototyping new \nlanguages, but the reader should have some level of skepticism that they are appropriate for high-assurance \ndevelopment; we hope to dispel that skepticism. Furthermore, there is nothing special about the Copilot \nlanguage with respect to assurance. We hope to convince the reader that the approach we have taken can \nbe applied broadly to new language design. Outline. In Section 2, we brie.y introduce Copilot (we assume \nsome familiarity with Haskell syntax). The heart of the report is Section 3 in which we describe our \nlessons learned for easily generating evidence of correctness. We brie.y mention related work in Section \n4, and make concluding remarks in Section 5. 2. The Copilot Language &#38; Toolset From 2009-2011, NASA \ncontracted Galois, Inc. to research the possibility of augmenting complex aerospace software systems \nwith runtime veri.cation (RV). RV is a family of approaches that employ monitors to observe the behavior \nof an executing system and to detect if it is consistent with a formal speci.cation. A mon\u00aditor implementation \nshould be simple and direct and serve as the last line of defense for the correctness for the system. \nThe need for aerospace RV is motivated by recent failures in commercial avionics and the space shuttle \n[11]. Our answer to the contract goals was Copilot, an EDSL to gen\u00aderate embedded monitors.2 The Copilot \nlanguage itself, focusing on its RV uses for NASA, has been previously described [20]. We will very brie.y \nintroduce Copilot in this paper; our focus is more speci.cally about compiler correctness. One research \nchallenge of the project was phrased as, Who watches the watchmen? meaning that if the RV monitor is \nthe last line of defense, then it must not fail or worse, introduce unintended faults itself! Nonetheless, \nbecause the primary goal of the project was to implement an RV system and to .eld-test it, few resources \nwere available for assuring the correctness of the Copilot compiler. Our approach was born out of necessity. \nCopilot s expression language. In the following, we brie.y and informally introduce Copilot s expression \nlanguage. One design goal for Copilot is to use a familiar syntax and model of compu\u00adtation; doing so \nis a .rst step in reducing speci.cation errors. The Copilot language mimics both the syntax and semantics \nof lazy lists (which we call streams) in Haskell. One notable exception though is that operators are \nautomatically promoted point-wise to the list level, much like in Lustre, a declarative language for \nembedded programming [12]. For example, the Fibonacci sequence modulo 232 can be written as follows in \nHaskell: fib :: [Word32] fib = [0,1] ++ zipWith (+) fib (drop 1 fib) In Copilot, the equivalent de.nition \nis the following: fib :: Stream Word32 fib = [0,1] ++ (fib + drop 1 fib) Copilot overloads or rede.nes \nmany standard operators from Haskell s Prelude Library. Here is a Haskell and equivalent Copilot function \nthat implements a latch (.ip-.op) over streams the out\u00adput is the XOR of the input stream and the latch \ns previous output. For example, for the input stream T,F, F, T, F,F,T,F,F, ... latch generates the stream \nF,T, T, T, F,F,F,T,T, T, ... In Haskell, latch can be de.ned latch :: [Bool] -> [Bool] latch x=outx where \nout ls = [False] ++ zipWith xor ls (out ls) xornm =(n||m)&#38;&#38;not(n&#38;&#38;m) and then in Copilot \n(xor is a built-in operator for Copilot): latch :: Stream Bool -> Stream Bool latch x = out where out \n= [False] ++ x xor out 2 Copilot source code is available at http://leepike.github.com/ Copilot/ and \nis licensed under the BSD3 license. The base types of Copilot over which streams are built include Booleans, \nsigned and unsigned words of 8, 16, 32, and 64 bits, .oats, and doubles. Type-safe casts in which over.ow \ncannot occur are permitted. Sampling. Copilot programs are meant to monitor arbitrary C programs. They \ndo so by periodically sampling symbol val\u00adues. (Copilot samples variables, arrays, and the return values \nof side-effect free functions sampling arbitrary structures is future work.) For a Copilot program compiled \nto C, symbols become in\u00adscope when arbitrary C code is linked with the code generated by the Copilot \ncompiler. Copilot provides the operator extern to in\u00adtroduce an external symbol to sample. The operator \ntypes a string denoting the C symbol. Copilot can be interpreted as well as compiled. When inter\u00adpreted, \nrepresentative values are expected to be supplied by the pro\u00adgrammer. For example, the following stream \nsamples the C variable e0 of type uint8 t to create each new stream index. If e0 takes the values 2,4, \n6,8,... the stream ext has the values 1, 3, 7, 13, .... ext :: Stream Word8 ext = [1] ++ (ext + extern \n\"e0\" interp) where interp = Just [2,4..] We make the design decision to build interpreter values for \nexternal values into the language. (If the user wishes not to provide inter\u00adpreter values, the constructor \nNothing can be used.) Sampling arrays and functions is similar (for space constraints, we omit an example \nof function sampling). For example, the fol\u00adlowing stream samples an array with the prototype uint32 \nt arr[3]: arr :: Stream Word32 arr = externArray \"arr\" idx 3 interp where idx :: Stream Word8 idx = [0] \n++ (idx + 1) mod 2 interp = Just (repeat [0,1,2]) The interpreter takes a list of lists to represent \npossible array values. Effects. Copilot has exactly one mechanism for output called triggers. For example, \nconsider the following example trigger: trigger \"trig\" (fib mod 2 == 0) [ arg fib, arg (latch fib) ] \nA trigger has a guard that is a Boolean-valued Copilot stream, and a list of arguments, which are Copilot \nexpressions. A trigger is .red exactly when its guard (stating that the current value from the fib stream \nis even in this case) is true. A trigger s implementation is a C function with a void return type that \ntakes the current values of the trigger arguments as arguments. For example, given the de.nition of fib \nand latch above, the prototype of the C-function implementing the trigger trig de.ned above is void trig(uint32_t, \nbool); The de.nition of a trigger is implementation-dependent and up to the programmer to implement. \nCopilot s toolchain. Copilot s toolchain is depicted in Figure 1, which we highlight here; assurance-relevant \naspects of the toolchain are covered in more detail later. Copilot is deeply embedded in Haskell. A Copilot \nprogram is rei.ed (i.e., transformed from a re\u00adcursive structure into explicit graphs via observable \nsharing [10]) and then some domain-speci.c type-checking is done. At this point, we have transformed \nthe program into the core language, an in\u00adtermediate representation. The core package contains an interpreter \n(~300 LOCs) as well as a custom QuickCheck engine and test har\u00adness for testing interpreter output against \none of the back-ends  Rei.cation and DSL-speci.c type\u00adchecking Evaluation QuickCheck Translation  \n Compilation Compilation Model checking Figure 1. The Copilot toolchain. The back-ends translate a \nCopilot core program into the lan\u00adguage of another Haskell-hosted EDSL for code generation. We use the \nAtom3 [13] and SBV4 packages for code generation, both of which generate a subset of C99 embedded code \nthat is constant\u00admemory and nearly constant-time. Atom is an EDSL originally designed by Tom Hawkins \nat Eaton Corp. for synthesizing real\u00adtime embedded control systems from high-level speci.cations. The \nlanguage provides scheduling constructs, obviating the need for a real-time operating system when cooperative \nscheduling is suf.\u00adcient. Symbolic Bit Vectors (SBV) is an EDSL developed by Lev\u00adent Erk\u00a8 ok. The primary \nfocus of SBV is to express and reason about bit-level Haskell programs. In particular, the language pro\u00advides \ntight integration with satis.ability modulo theories (SMT) solvers (e.g., Yices [8]) for automatic proofs \nand to check for satis\u00ad.ability. The EDSL also contains a C-code generator which we use. Other features \nof the language include test-case generation and au\u00adtomated synthesis. We use the recent Safe Haskell \ncompiler extensions to imple\u00adment Copilot [23]. Copilot s language package is explicitly Trust\u00adworthy \nHaskell, as there is a single instance of unsafeCoerce to implement observable sharing. Copilot s core \nlanguage is written in Safe Haskell. A separate package generates a driver for the CBMC model\u00adchecker \n[6], which we use to check the equivalence between the C code generated by each back-end. 3. Lessons \nLearned: Quick and Easy Correctness Evidence In the following, we describe some lessons-learned in quickly \nand easily building assurance into an EDSL compiler. Lesson: Turing-complete macros, small, Turing-incomplete \nlan\u00adguages. C-like languages treat macros as a second-class feature they are just textual substitution. \nLisp-like languages take the con\u00adverse approach, treating macros as a .rst-class datatype, so macros \nare on par with (Turing-complete) programming. These are two extremes, but they largely represent the \nstatus of macro program\u00adming. EDSLs, however, treat meta-programming as .rst-class, and programming as \nsecond-class! The difference in emphasis of ED\u00ad 3 http://hackage.haskell.org/package/atom, BSD3 license. \n4 http://hackage.haskell.org/package/sbv, BSD3 license. SLs is because the embedded language is a datatype \nwithin its host language (we assume a deep-embedding of the DSL [10]). The dif\u00adference affects how one \nprograms using an EDSL. Practically, one spends very little time directly using the operators of the \nEDSL it\u00adself but rather, one generates EDSL programs using combinators from the host language. Embedded \nsystem programming, with time and memory con\u00adstraints, does not require the full power of a general-purpose \nTuring-complete language [4]. But a Turing-complete macro lan\u00adguage affords bene.ts in code-reuse and \nlibrary development. With an EDSL, one can have his cake and eat it too: Arbitrarily complex combinators \nover the EDSL can be written, but then a simple core language can be reasoned about. Reasoning about \nthe correctness of sub-Turing-complete lan\u00adguages is easier than general-purpose languages. For example, \na verifying compiler for a cryptographic DSL leveraged the ability to automatically generate measures \nto formally prove termination of programs written in the language [19]. Conversely, Sassaman et al. argue \nthat a principal origin of insecurity in computer systems is due to Turing-complete (or more generally, \ntoo powerful) data\u00addescription languages [21]. data Expr a where --Constants Const :: Type a -> a -> \nExpr a --Stream constructors Drop :: Type a -> Int -> Id -> Expr a --Let expressions Local :: Type a \n-> Type b -> Name -> Expr a ->Exprb-> Exprb Var :: Type a -> Name -> Expr a --Operators Op1 ::Op1ab->Expr \na->Exprb Op2 ::Op2abc->Expra->Exprb->Exprc Op3 ::Op3abcd->Expra->Exprb ->Exprc-> Exprd --Externals ExternVar \n:: Type a -> Name -> Maybe [a] -> Expr a ExternFun :: Type a -> Name -> [UExpr] -> Maybe (Expr a) -> \nMaybe Int -> Expr a ExternArray :: Integral a => Type a -> Type b -> Name -> Int -> Expr a -> Maybe [[b]] \n-> Maybe Int -> Expr b --Untyped streams data UExpr = forall a. UExpr { uExprType :: Type a , uExprExpr \n:: Expr a } Figure 2. The core Copilot expression language abstract syntax. The core language of Copilot \nis both small and unpowerful: as noted, only programs requiring a constant amount of space can be written \nin Copilot. In Figure 2 is the generalized abstract datatype (GADT) [22] that is the abstract syntax \nfor Copilot expressions in the core language. There are constants, the drops stream con\u00adstructor (dropping \na .nite number of pre.x list elements), let\u00adexpressions within Copilot for user-de.ned expression sharing, \nex\u00adternal program inputs, and unary, binary, and ternary operators. One .nal data type, UExpr contains \nexistentially-typed streams that are used in argument lists. Everything else is syntactic sugar or spe\u00adci.c \noperators. (The operational semantics of Copilot, given by an interpreter function over the Expr datatype, \nis about 200 LOCs.) Despite the small size of the core language and the lack of computational power, \nwith Haskell s parametric polymorphism and standard library combinators, we can enjoy the bene.ts of \ncode reuse and abstraction in building libraries while maintaining a terse core language. For example, \nin our fault-tolerant voting library, the Boyer-Moore linear-time Majority Vote algorithm [3] is written \nas a Haskell function that gets expanded at compile-time into a Copi\u00adlot program. Libraries for bounded \nlinear-temporal logic, regular expressions, bounded folds, bounded scans, etc. are similarly just Copilot \nmacros. The idea that the macro language can be arbitrarily complex is obvious to the functional languages \ncommunity, but it is a disrup\u00adtive one to the embedded languages community, particularly for safety-critical \nsystems. Typical declarative languages for embed\u00added systems design, like Lustre [4], are not polymorphic \n(poly\u00admorphism is limited to a small set of pre-de.ned operators, like if-then-else). Lesson: multi-level \ntype-checking. Type-checking is the .rst de\u00adfense against incorrect programs. We used a two-layer approach: \nlet the host language enforce types where possible, and write a custom checker for type-checking that \nfalls outside of the host language s type system. In this way, we rely on Haskell to do most of the heavy \nlifting. We use GADTs to represent both the front-end abstract syntax and the core language. The use \nof parameterized datatypes makes the probability of unanticipated type-casts low. There are only two \ncases during which we escape Haskell s type system, which may lead to incorrect type-casts. The .rst \ncase is when a back-end pretty-prints C code. The correctness of such code can be determined by inspecting \na small number of functions and class instances. The second case arises during the translation from the \ncore abstract syntax into the back-ends, which are themselves EDSLs embedded in Haskell. Both the core \nlanguage and the back-ends make use of polymorphic functions and class constraints. As a matter of software \nengineering, we do not want Copilot s core functions to be dependent on the classes introduced in the \nback\u00adends doing so would require modifying functions and datatypes de.ned in the core with new class \nconstraints for each time a new back-end is added! Therefore, we use the ideas of type-safe dynamic typing \nto translate from the core language to the back-end languages without relying on compiler extensions \nor unsafe functions [2]. The basic idea is to create witness functions that we pattern-match against. \nFor example, for the class SymWord ( Symbolic Word ) in the SBV back-end, we create the following instance \ndatatype and an instance function mapping Copilot types to SymWords: data SymWordInst a = SymWord a => \nSymWordInst symWordInst :: Type a -> SymWordInst a symWordInst t = case t of Bool -> SymWordInst Int8 \n-> SymWordInst ... where Type is a phantom type containing concrete representations of Copilot s core \ntypes. data Type :: * -> * where Bool :: Type Bool Int8 :: Type Int8 ... Then during the translation, \nwe pattern-match. For example, in translating the addition operator, we translate from Copilot s Add \nconstructor in the core language to SBV s addition operator +: transBinaryOps op = case op of Add t -> \ncase W.symWordInst t of W.SymWordInst -> (+) ...  The upshot is that we have created potentially partial \ntranslation functions, but type-incorrect translation is not possible. In addition to type-checking provided \nby Haskell, we perform a small amount of custom type-checking (~250 LOCs). The two classes of custom \ntype-checking are (1) causality analysis and (2) type-checking external variables (arrays and functions). \nCausality analysis ensures that stream dependencies are evaluated strictly. Strict dependencies are necessary \nwhen we are sampling variable values in real-time from the external world. For example, the fol\u00adlowing \nCopilot stream equations fail type-checking since y initially depends on values from the variable x before \nany values have been generated: x :: Stream Word8 x = extern \"ext\" Nothing y = drop 2 x We also check \nat compile-time that streams are productive; for example, the stream de.nition x=x fails type-checking. \nIn addition, external variables are just strings with associated types. Therefore, we must check that \nthe same string is not given two different types or declared to be of two different kinds of sym\u00adbols \n(e.g,. a global variable vs. a function symbol). For example, the following two expressions, if they \nappear in the same Copilot program, fail type-checking: x :: Stream Word8 x = extern \"ext\" Nothing y \n:: Stream Word16 y = extern \"ext\" Nothing Lesson: cheap front-end/back-end testing. QuickCheck [5] test\u00ading \nis so easy to implement and so effective that no EDSL com\u00adpiler should be without it. QuickCheck can \nof course be used for unit testing during compiler development, but we use it to gener\u00adate regression \ntests for the semantics of the EDSL by comparing the output of the interpreter against the Atom back-end \n(we plan to implement QuickCheck testing against the SBV back-end in the future). We generate a stand-alone \nexecutable that for a user-speci.ed number of iterations, 1. generates a random Copilot program, 2. \ncompiles the Copilot program to C, 3. generates a driver.c .le containing a main function as well as \nvalues for external variables, 4. compiles and links an executable (using gcc), 5. executes the program, \n 6. and compares its output to the output from the Copilot inter\u00adpreter.  Weights can be set to determine \nthe frequency of generating the various Copilot language constructs and streams of different types. There \nare at least two approaches to generating type-correct programs. First, we can generate random programs, \nthen .lter ill\u00adtyped programs using the type-checker. Second, we can generate type-correct programs directly. \nWe take the second approach. Gen\u00aderating type-correct programs is not dif.cult in our case: as de\u00adscribed \nalready, because Copilot s abstract syntax is parameter\u00adized by Haskell type variables, type-correct \nexpression generation is straight-forward. We need only to ensure the small number of domain-speci.c \ntype rules are also satis.ed. The bene.t of generating type-correct programs directly is that if the \ngenerator is implemented correctly, every generated program is type-correct and will be tested. The danger, \nhowever, is that the generator may be too strict, omitting some type-correct programs from being generated \nand tested. With the standard options, we generate, compile, test and pretty\u00adprint to standard output \nabout 1,000 programs per minute. It is easy to let the QuickCheck test generator run continuously on \na server, generating some million and a half programs per day (in practice, bugs, if present, tend to \nappear after just 10s or 100s of generated programs). The kinds of bugs we have caught include forgotten \nwit\u00adness for the Atom back-end and the out-of-order bugs in which the interpreter output stream values \nbefore sampling variables. A non-bug we discovered was disagreement on .oating-point val\u00adues between \nGHC s runtime system (executing the interpreter) and libc. We solved this problem by just checking that \n.oating point values are within some small constant range, noting that pathologi\u00adcal cases may cause \ndifferences outside of a constant range without violating the IEEE .oating-point standard. Lesson: cheap \nback-end proofs. The veri.ed compiler approach assumes that the compiler itself is within the trusted \ncomputing base (TCB) the software that must be trusted to be correct. Con\u00adsequently, it requires a monolithic \napproach to veri.cation in which the compiler is veri.ed. But what if the compiler can be removed from \nthe TCB? Doing so can reduce the dif.culty of providing as\u00adsurance evidence. This is our motivation for \na proof approach of the back-ends. Recalling Figure 1, Copilot has two back-ends that generate C. We \nleverage the open-source model-checker CBMC to prove the equivalence of the code generated by each back-end \n[6]. CBMC uses C as its speci.cation language. In our work, we use CBMC. CBMC can prove memory-safety \nproperties, such as no division by zero, no not-a-number .oating-point errors, and no array out-of\u00adbound \nindexes. It can also prove arbitrary propositional formulas given in the body of assert() functions. \nTo prove equivalence between the two back-end outputs, we au\u00adtomatically generate a driver program that \nexecutes both back-ends for one step, compares their outputs, takes another step, compares their outputs, \nand so on for a user-speci.ed number of iterations. The generated driver is of the form for(i= 0; i<RNDS;i++) \n{ sampleExterns(); atom_step(); sbv_step(); assert( atomStr_0 == sbvStr_0 &#38;&#38; atomStr_1 == sbvStr_1 \n&#38;&#38; ... ); } For sampled variables (arrays, functions), we use CBMC s built\u00adin model of nondeterminism \nto model arbitrary inputs to Copilot programs. CBMC proves the two programs are memory-safe and have \nequivalent semantics for a .nite number of user-speci.ed iterations (RNDS). Model-checking works out \nof the box in our case because both back-ends generate simple code (e.g., no non-linear pointer arithmetic, \nno function pointers, no loops) in the state-update func\u00adtions. This use of formal methods emphasizes \nthe lesson about sim\u00adple, Turing-incomplete languages from Section 3. A proof of correspondence on the \nC code reduces the trust required in the Atom and SBV back-ends. Assuming the model\u00adchecker is sound, \nincorrectly-generated code will be claimed to be equivalent only if bugs with the same effects appear \nin both back-ends. In addition, memory-safety errors, even if they appear simultaneously in both programs, \nwill be caught. That said, one must still trust the C compiler CompCert [16] would be a good point in \nthis case. Furthermore, Copilot programs are expected to be executed forever (i.e., they are programs \nover in.nite streams), which mimics the behavior of embedded soft\u00adware. CBMC symbolically unrolls programs \neither completely if possible or to a user-speci.ed depth; it does not perform an induc\u00adtive proof, so \ncurrently, we only show equivalence up to a user-set bound (RNDS in the code-snippet above). Using a \nmodel-checker with induction (e.g., k-induction via SAT [14]) would strengthen the assurance case. Finally, \nnote that this use of model-checking takes the verifying rather than veri.ed-compiler approach: model\u00adchecking \nis done for each program compiled. The kinds of bugs we have caught mostly include incorrect or\u00addering \nof functions in the generated C (e.g., sampling external val\u00adues after computing next-state values for \nstreams). Because we do not yet have a QuickCheck testing infrastructure between the inter\u00adpreter and \nthe SBV back-end, we get a transitive argument that the SBV back-end is equivalent to the Atom back-end, \nwhich has evi\u00addence of matching the interpreter through the use of QuickCheck. From an evidence perspective, \nmodel-checking the back-ends re\u00adduces the required trust in the Haskell compiler/interpreter, since we \ncheck the generated artifacts. Ideally, we would have the power of an EDSL without having to trust the \nruntime system of the host language. Lesson: a uni.ed host language. Our last lesson is one ob\u00advious \nto the functional programming community, but novel in safety-critical languages. EDSLs are intrinsically \nimmune to whole classes of potential compiler bugs. For example, because a separate parser, lexer, tokenizer, \netc. are not necessary, EDSLs do not suffer from these front-end bugs. This assumes that the host language \ns front-end does not contain bugs, which for a stable well-used host language, is more likely than for \na new DSL front-end. We enjoyed two other advantages. First, translating between EDSLs in the same host \nlanguage was type-safe and relatively easy since the two back-ends we use were existing EDSLs. Translating \nfrom Copilot into a back-end is a matter of converting from one ab\u00adstract syntax datatype into another, \nnever leaving the host language. Second, the host language serves as more than a macro lan\u00adguage: it \nserves as a partial build system. For example, consider the case of generating distributed Copilot programs \nto be run on networked processors, where we want to parameterize inputs based on the processor identi.er. \nWith an EDSL, this is no more dif.cult than parameterizing the compile function. In our experiments with \nNASA, we did just this to build fault-tolerant monitors [20]. 4. Related Work Our experience report builds \non research in disparate .elds includ\u00ading functional programming and EDSL design, compiler veri.ca\u00adtion, \nand embedded safety-critical languages. In this section, we provide just a few pointers into the literature \nthat inspired us. Some might believe that compilers are generally bug-free (even if speci.c programs \nare buggy). Work at the University of Utah has dispelled this myth [24], having uncovered hundreds of \nbugs in C compilers like gcc, clang, and even the (unveri.ed) front\u00adend of the CompCert compiler [16]. \nCompiler veri.cation is still important. Our work does not address C compilation directly, but it does \nreduce the risk of encountering bugs in C compilers by constraining the language to a small subset of \nwell-de.ned C. FeldSpar is an EDSL in Haskell designed for digital signal processing designed by Ericsson \nand Chalmers University [1]. FeldSpar s architecture and implementation is similar to Copilot s and could \nintegrate the assurance approaches we have described. Researchers at the University of Minnesota have \nalso built a family of DSLs tailored for safety-critical embedded system modeling [9]. The host language \nwas designed so that new DSLs can be speci.ed using attribute grammars. It appears the purpose of the \nlanguage is primarily for modeling, so the work does not address compilation, and consequently does not \naddress compiler correctness issues. Finally, Filet-o-Fish is a related DSLs framework for operating \nsystem development [7]. The authors emphasize compiler assur\u00adance as we do, also using an interpreter \nto provide an operational semantics and using QuickCheck for testing. An alternative to the EDSL approach \nis to take a functional lan\u00adguage and augment it with suf.cient evidence to be used directly in safety-critical \ncontexts, such as avionics development. A consor\u00adtium did just that with OCaml, rewriting the SCADE code \ngener\u00adator [18]. Qualifying the software required substantially reducing OCaml s runtime system and garbage \ncollector, extensive testing, and providing traceability of requirements. From a formal veri\u00ad.cation \nperspective, the requirements are lightweight (the main di\u00adrect evidence for correctness is testing). \n5. Conclusions Despite our experience, EDSLs are not a panacea. Copilot suffers the same problems that \nmany EDSL implementations do. Error messages from the Haskell compiler are not domain-speci.c. There \nis no graphical development environment (common in embedded systems development). Large Haskell expressions \nare easy to gen\u00aderate, which can be expensive to interpret or compile. Copilot does not currently have \na highly-optimizing back-end. Regarding our approach to compiler assurance, there are some weaknesses. \nFirst, since the interpreter and back-ends are built on the core language, bugs in translation from the \nfront-end will af\u00adfect all the targets. While QuickCheck tests the executables against the interpreter, \nthe model-checker only proves properties about (its interpretation of) the C source semantics. CompCert \nwould obvi\u00adously be a good choice to compile C, then. Finally, as noted in the introduction, we have \nfocused here on evidence of correct compi\u00adlation, but our implementation does not necessarily help ensure \na speci.c program meets its speci.cation. These shortcomings point to future research efforts. In summary \nwe hoped to make two points in this report: .rst, that EDSLs are a viable approach for building high-assurance \ncom\u00adpilers, and second, that strong evidence can be generated with little work or expertise. With the \nEDSL, you do not have to write your own front-end, most type-checking is done for you, and today s off\u00adthe-shelf \nmodel-checkers are capable of checking real programs. But don t take our word for it; do-it-yourself. \nAcknowledgments This work was supported by NASA Contract NNL08AD13T. We wish to especially thank the \nfollowing individuals for advice on our work: Ben Di Vito, Paul Miner, Eric Cooper, Joe Hurd, and Aaron \nTomb. Robin Morisset worked on an earlier version of Copilot. Nis Wegmann and Sebastian Niller completed \nthis work while they were visiting researchers at the National Institute of Aerospace. References [1] \nE. Axelsson, K. Claessen, M. Sheeran, J. Svenningsson, D. Engdal, and A. Persson. The design and implementation \nof Feldspar -an embedded language for digital signal processing. In Implementation and Application of \nFunctional Languages, volume 6647 of LNCS, pages 121 136. Springer, 2011. [2] A. I. Baars and S. D. Swierstra. \nTyping dynamic typing. In Intl. Con\u00adference on Functional Programming (ICFP), pages 157 166. ACM, September \n2002. [3] R. S. Boyer and J. S. Moore. MJRTY: A fast majority vote algorithm. In Automated Reasoning: \nEssays in Honor of Woody Bledsoe, pages 105 118, 1991. [4] P. Caspi, D. Pialiud, N. Halbwachs, and J. \nPlaice. LUSTRE: a declara\u00adtive language for programming synchronous systems. In 14th Sympo\u00adsium on Principles \nof Programming Languages, pages 178 188, 1987. [5] K. Claessen and J. Hughes. QuickCheck: A lightweight \ntool for random testing of Haskell programs. In ACM SIGPLAN Notices, pages 268 279. ACM, 2000. [6] E. \nClarke, D. Kroening, and F. Lerda. A tool for checking ANSI-C programs. In Tools and Algorithms for the \nConstruction and Analysis of Systems (TACAS), LNCS, pages 168 176. Springer, 2004. [7] P. E. Dagand, \nA. Baumann, and T. Roscoe. Filet-o-Fish: practical and dependable domain-speci.c languages for OS development. \nIn Proceedings of the Fifth Workshop on Programming Languages and Operating Systems (PLOS 09), pages \n1 5. ACM, 2009. [8] B. Dutertre and L. D. Moura. The Yices SMT solver. Technical report, SRI, 2006. [9] \nJ. Gao, M. Heimdahl, and E. Van Wyk. Flexible and extensible notations for modeling languages. In Fundamental \nApproaches to Software Engineering (FASE), volume 4422 of LNCS, pages 102 116. Springer Verlag, March \n2007. [10] A. Gill. Type-safe observable sharing in Haskell. In Proceedings of the 2009 ACM SIGPLAN \nHaskell Symposium, September 2009. [11] A. Goodloe and L. Pike. Monitoring distributed real-time systems: \nA survey and future directions. Technical Report NASA/CR-2010\u00ad216724, NASA Langley Research Center, July \n2010. [12] N. Halbwachs and P. Raymond. Validation of synchronous reactive systems: from formal veri.cation \nto automatic testing. In ASIAN 99, Asian Computing Science Conference. LNCS 1742, Springer, Decem\u00adber \n1999. [13] T. Hawkins. Controlling hybrid vehicles with Haskell. Presentation. Commercial Users of Functional \nProgramming (CUFP), 2008. Avail\u00adable at http://cufp.galois.com/2008/schedule.html. [14] T. Kahsai, Y. \nGe, and C. Tinelli. Instantiation-based invariant discov\u00adery. In 3rd NASA Formal Methods Symposium, volume \n6617 of LNCS, pages 192 207. Springer, 2011. [15] D. Leijen and E. Meijer. Domain speci.c embedded compilers. \nIn Domain-Speci.c Languages Conference. USENIX, 1999. [16] X. Leroy. Formal veri.cation of a realistic \ncompiler. Communications of the ACM, 52:107 115, July 2009. [17] J. S. Moore, editor. Special Issue on \nSystem Veri.cation: Journal of Automated Reasoning, volume 5, 1989. [18] B. Pagano, O. Andrieu, T. Moniot, \nB. Canou, E. Chailloux, P. Wang, P. Manoury, and J.-L. Colao. Experience report: using Objective Caml \nto develop safety-critical embedded tools in a certi.cation framework. In G. Hutton and A. P. Tolmach, \neditors, International Conference on Functional Programming (ICFP), pages 215 220. ACM, 2009. [19] L. \nPike, M. Shields, and J. Matthews. A verifying core for a crypto\u00adgraphic language compiler. In Proceedings \nof the 6th Intl. Workshop on the ACL2 Theorem Prover and its Applications, pages 1 10. ACM, 2006. [20] \nL. Pike, S. Niller, and N. Wegmann. Runtime veri.cation for ultra\u00adcritical systems. In Proceedings of \nthe 2nd Intl. Conference on Run\u00adtime Veri.cation, LNCS. Springer, September 2011. [21] L. Sassaman, M. \nL. Patterson, S. Bratus, and A. Shubina. The Halting problems of network stack insecurity. ;login: The \nUSENIX Magazine, 36(6), December 2011. [22] T. Schrijvers, S. Peyton Jones, M. Sulzmann, and D. Vytiniotis. \nCom\u00adplete and decidable type inference for GADTs. In International Con\u00adference on Functional Programming \n(ICFP), ICFP 09, pages 341 352. ACM, 2009. [23] D. Terei, S. Marlow, S. P. Jones, and D. Mazi`eres. \nSafe haskell. In Proceedings of the Haskell Symposium, 2012. [24] X. Yang, Y. Chen, E. Eide, and J. Regehr. \nFinding and understanding bugs in C compilers. In Programming Language Design and Imple\u00admentation (PLDI), \npages 283 294. ACM, 2011. \n\t\t\t", "proc_id": "2364527", "abstract": "<p>Embedded domain-specific languages (EDSLs) are an approach for quickly building new languages while maintaining the advantages of a rich metalanguage. We argue in this experience report that the \"EDSL approach\" can surprisingly ease the task of building a high-assurance compiler. We do not strive to build a fully formally-verified tool-chain, but take a \"do-it-yourself\" approach to increase our confidence in compiler-correctness without too much effort. <i>Copilot</i> is an EDSL developed by Galois, Inc. and the National Institute of Aerospace under contract to NASA for the purpose of runtime monitoring of flight-critical avionics. We report our experience in using type-checking, QuickCheck, and model-checking \"off-the-shelf\" to quickly increase confidence in our EDSL tool-chain.</p>", "authors": [{"name": "Lee Pike", "author_profile_id": "81100548223", "affiliation": "Galois, Inc., Portland, OR, USA", "person_id": "P3804328", "email_address": "leepike@gmail.com", "orcid_id": ""}, {"name": "Nis Wegmann", "author_profile_id": "81548021668", "affiliation": "University of Copenhagen, Copenhagen, Denmark", "person_id": "P3804329", "email_address": "niswegmann@gmail.com", "orcid_id": ""}, {"name": "Sebastian Niller", "author_profile_id": "81543221056", "affiliation": "Unaffiliated, Germany", "person_id": "P3804330", "email_address": "sebastian.niller@gmail.com", "orcid_id": ""}, {"name": "Alwyn Goodloe", "author_profile_id": "81100225770", "affiliation": "NASA, Hampton, VA, USA", "person_id": "P3804331", "email_address": "a.goodloe@nasa.gov", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364553", "year": "2012", "article_id": "2364553", "conference": "ICFP", "title": "Experience report: a do-it-yourself high-assurance compiler", "url": "http://dl.acm.org/citation.cfm?id=2364553"}