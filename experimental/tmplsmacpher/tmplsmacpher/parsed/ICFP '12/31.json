{"article_publication_date": "09-09-2012", "fulltext": "\n Automatic Amortised Analysis of Dynamic Memory Allocation for Lazy Functional Programs HugoSim oes SteffenJost \nPedroVasconcelos LudwigMaximilliansUniversit\u00a8at, M\u00b4arioFlorido Munich,Germany jost@tcs.i..lmu.de LIACC,UniversidadedoPorto, \nKevinHammond University ofStAndrews, StAndrews,UK kh@cs.st-andrews.ac.uk Porto,Portugal {hrsimoes,pbv,amf}@dcc.fc.up.pt \nAbstract This paper describes the .rst successful attempt, of which we are aware, to de.ne an automatic, \ntype-based static analysis of re\u00adsource bounds for lazy functional programs. Our analysis uses the automatic \namortisation approachdevelopedby HofmannandJost, which was previously restricted to eager evaluation. \nIn this paper, we extend this work to a lazy setting by capturing the costs of un\u00adevaluated expressions \nin type annotations and by amortising the payment of these costs using a notion of lazypotential.Wepresent \nour analysis as a proof system for predicting heap allocations of a minimal functional language (including \nhigher-order functions and recursive data types) and de.ne a formal cost model based on Launchbury s \nnatural semantics for lazy evaluation. We prove the soundness of our analysis with respect to the cost \nmodel. Our ap\u00adproach is illustrated by a number of representative and non-trivial examples that have \nbeen analysed using a prototype implementa\u00adtion of our analysis. Categories and Subject Descriptors D.3.2 \n[Programming Lan\u00adguages]: FunctionalLanguages Keywords lazy evaluation, resource analysis, amortisation, \ntype systems 1. Introduction Non-strictfunctionalprogramminglanguages, suchasHaskell[36], offerimportantbene.tsintermsof \nmodularity and abstraction[23]. A key practical obstacle to their wider use, however, is that extra\u00adfunctionalproperties,such \nastime-and space-behaviour, areoften dif.culttodetermineprior to actuallyrunning theprogram.Recent advances \nin static cost analyses, such as sized-timed types [43,44] and type-based amortisation [18, 19]have enabled \nthe automatic prediction of resource bounds for eager functional programs, in\u00adcluding uses of higher-order \nfunctions [29]. This paper extends type-based amortisationtolazy evaluation,describing a static anal\u00adysisfordetermining \na-priori worst-casebounds on execution costs (speci.cally,dynamic memoryallocations). Permission to make \ndigital or hard copies of all or part of this work for personal or classroomuseisgranted withoutfeeprovided \nthat copiesarenot madeordistributed forpro.tor commercial advantage andthat copiesbearthis notice andthefull \ncitation onthe .rstpage.Tocopy otherwise,torepublish,topostonservers ortoredistribute tolists, requiresprior \nspeci.cpermission and/or afee. ICFP 12, September9 15,2012,Copenhagen,Denmark. Copyright c &#38;#169; \n2012ACM978-1-4503-1054-3/12/09. . .$15.00 Thispaper makes thefollowing novel contributions: a) wepresentthe \n.rst successful attempt,of which weareaware, toproduce an automatic, type-based, static analysis of resource \nboundsforlazy evaluation; b) we introduce a cost model for heap allocations for a minimal lazyfunctionallanguagebasedonLaunchbury \ns natural seman\u00adticsforlazy evaluation[30], and use this as thebasisfordevel\u00adoping a resource analysis; \nc) we have proved the soundness of our analysis with respect to the cost-instrumented semantics(dueto \nspacelimitations, we presentonly aproof sketch); and d) weprovideresultsfromaprototypeimplementationtoshowthe \napplicability of our analysis to some non-trivial examples. * Our amortised analysis derives costs with \nrespect to a cost seman\u00adticsforlazy evaluation thatderives fromLaunchbury s natural op\u00aderational semanticsofgraph \nreduction.Itdealswithboth.rst-order and higher-order functions, but does not consider polymorphism. For \nsimplicity, we restrict our attention to heap allocations , but previous results have shown that the \namortised analysis approach also extends to other countable resources, such as worst-case exe\u00adcutiontime[28].Inordertoensureagood \nseparationof concerns, our analysis assumes the availability ofHindley-Milner typeinfor\u00admation.We extendHofmannandJost \ns type annotationsfor cap\u00adturing potential costs[19]withinformation aboutthelazy evalu\u00adation context. \nThe analysis produces a set of constraints over cost variables that we solve in our prototype implementation \nusing an external LP-solver. We have thus demonstrated all the steps that are necessary to produce a \nfully-automatic analysis for determin\u00adingbounds on resource usageforlazily-evaluatedprograms. 2. ACostModelforLazyEvaluation \nOur cost modelisbuiltonSestoft srevision[40] ofLaunchbury s natural semantics for lazy evaluation [30]. \nLaunchbury s seman\u00adtics forms one of the earliest and most widely-used operational accounts of lazy evaluation \nfor the .-calculus. De la Encina and Pe na-Mar\u00b4i[13,14]subsequently proved that the Spineless Tagless \nG-Machine [24]is sound and complete w.r.t. one of Sestoft s ab\u00adstract machines.Wethereforehave ahighdegree \nof con.dence that thecost modelforlazy evaluationdevelopedhereis notjusttheo\u00ad * The detailed soundness \nproof and a web version of our analysis are available at http://www.dcc.fc.up.pt/~ pbv/cgi/aalazy.cgi \n. Note that, because we do not consider deallocation, we model total allo\u00adcation but not residency. \n retically sound, but also that it could, in principle, be extended to model realimplementations oflazyevaluation. \n2.1 Syntax The syntax ofinitialexpressions (the subjectofour cost analysis)is the .-calculusextended \nwithlocalbindings,data constructors and pattern matching: e ::= x | .x.e | ex | let x = e1 in e2 | letcons \nx = c(yx)in e | matche0 with c(x )-> e1 otherwise e2 As in Launchbury s semantics, we restrict the arguments \nof ap\u00adplications to be variables and we require that nested applications be translated into nested let-bindings. \nlet-expressions bind vari\u00adablestopossibly recursiveterms.Inline with commonpracticein non-strict functional \nlanguages, we do not have a separate letrec form, as in ML. For simplicity, we consider only single-variable \nlet-bindings:multiplelet-bindings canbe encoded,ifneeded, using pairs and projections. Note that constructor \napplications c(xx)will never occurin theinitialexpression.Theyare onlyeverintroduced through evaluation \nof letcons-expressions. This is the main differ\u00adencebetween our notation andthose ofLaunchburyorSestoft.The \ndifference is motivated by the need to syntactically distinguish al\u00adlocatinga new constructorfrom simplyreferencingan \nexistingone. DelaEncina andPe na-Mar\u00b4iuse a similar notation.Our operational semantics is de.ned over \naugmented expressions, ee, that include these constructor applications: e ::= e | c(xl) eAn evaluation \nresultisthen an(augmented) expression w, which is in weak head normal form (whnf),i.e.itis a .-abstraction \nor constructor application. w ::= .x.e | c(xl) In the remainder ofthispaper we willuselowercaseletters \nx,yfor bound variablesininitialexpressions and l,k for fresh variables (designatedlocations)thatareintroducedthroughevaluation \noflet\u00adand letcons-expressions.  2.2 Cost-instrumentedoperational semantics Figure1de.nes aninstrumentedbig-stepoperationalsemanticsfor \nlazy evaluation that we will use as the basis for our analysis. Our m semantics is given as a relation \nH,S,L ' e . w,H ' , where ee m e is an augmented expression;H is aheap mappingvariables to aug\u00admented \nexpressions(thunks, that may require evaluation to weak head normal form); S is a set of bound variables \nthat are used to ensure the freshness condition in the LET./LETCONS. rules; and L is a set of variables \nused to record thunks that are under eval\u00aduation and toprevent cyclic evaluation(similartothe well-known \nblack-hole technique used in [30]). The result of evaluation is an expression w in whnf and a .nal heap \nH ' . The parameters m,m ' are non-negative integers representing the number of avail\u00adable heap locations \nbefore and after evaluation, respectively. The purpose ofthe analysis that willbedevelopedinSection3is \nto ob\u00adtain a static approximation for m that will safely allow execution to proceed. For readability, \nwe may omit the resource information fromjudgements whenthey are not otherwise mentioned, writing m simplyH,S,L \n. ee. w,H ' instead of H,S,L ' e . w,H ' . m e The only rules that bind variables to expressions in the \nheap are LET. and LETCONS.. These are therefore the only places Thistransformationdoes notincrease worst-case \ncostsbecause,inacall\u00adby-need setting, function arguments must, in general, be heap-allocated in order \nto allow in-place update and sharing of normalforms. w isin whnf m (WHNF.) H,S,L m w . w,H l . LH,S,L \n.{l} m ' H(l). w,H ' mm (VAR.) H,S,L m ' l . w,H ' [l . w] lisfresh e1 ' = e1[l/x] e2 ' = e2 [l/x] \n' m ' H[l . e1],S,L ' e . w,H ' m 2 (LET.) m +1 H,S,L m ' let x = e1 in e2 . w,H ' lisfresh yi ' = yi[l/x] \ne ' = e[l/x] m ' H[l . c(yx')],S,L m ' e . w,H ' (LETCONS.) m +1 H,S,L m ' letcons x = c(yx)in e . w,H \n' mm ' H,S,L m ' e . .x.e ' ,H ' H ' ,S,L m ' ' e [l/x]. w,H '' m H,S,L m ' el . w,H '' (APP.) m H,S \n.{x }.BV(e1).BV(e2),L m ' e0 . c(xl),H ' ' m H ' ,S,L m ' e1[xl/xx]. w,H '' H,S,L m m ' matche0 with \nc(x )->e1 otherwise e2 . w,H '' (MATCH.) ' m H,S .{x }.BV(e1).BV(e2),L m ' e0 . w,H ' ' w '= c(xl) H \n' ,S,L mm ' e2 . w,H '' m H,S,L m ' matche0 with c(x )->e1 otherwise e2 . w,H '' (FAIL.) Figure1. Cost-instrumentedOperationalSemantics \nwhere new fresh locations are needed. These heap allocations may either allocate new constructors (letcons), \nor thunks or .\u00adabstractions(let).For simplicity,butwithoutloss ofgenerality, we choose to use a uniform \ncost model: evaluation willcost one(heap) unit for each fresh heap location that is needed during evaluation. \nOther cost models are alsopossible[28], modelling the usage of other countable resources such as execution \ntime, or stack usage, for example. The WHNF. rule for weak-head normal forms (.\u00adexpressions and constructors)incurs \nno cost. Any costs must have beenalready accountedforby aninitial let-or letcons-expression. The VAR. \nand APP. rules are identical to the equivalent ones in Launchbury s semantics. The VAR. rule is restricted \nto loca\u00adtionsthat are not marked asbeing under evaluation(so enforcing black-holing ). The MATCH. and \nFAIL. cases deal respectively with successful/unsuccessful pattern matches against a construc\u00adtor. These \nrules record the bound variables in e1 plus the new bound variables in xx solely in order to ensure freshness \nin the LET./LETCONS. rules. We nowgive the auxiliaryde.nition\u00a7 thatformalises the notion offreshness \nofvariables andalemma regardingthepreservation of locations that are marked as black-holes . De.nition \n2.1 (Freshness). A variable x is fresh in judgement H,S,L . ee . w,H ' if x does not occur in either \ndom(H), L or S nordoesit occurboundin either ee or ran(H). Lemma 2.2 (Invariant Black Holes). If H,S,L \n. ee. w,H ' then for all l . L we have H ' (l)= H(l). In other words, \u00a7Due todeLaEncina andPe na-Mar\u00b4i[13]. \n heap locations that are under evaluation are preserved during intermediate evaluations. Proof. By inspection \nof the operational semantics (Figure 1) we observethat VAR. isthe onlyrulethatmodi.es an existinglocation \nland that this ruledoes not apply when l . L.  2.3 Example: call-by-need versus call-by-value/call-by-name \nConsider the expression below, whichincludes adivergent term: let z = z in (.x..y.y)z (2.1) Under a call-by-value \nsemantics, this would fail to terminate, be\u00adcause z does not admit a normal form. In our call-by-need \nseman\u00adtics,however, evaluation succeeds: H,S,L 10 let z = z in (.x..y.y)z . .y.y,H[l3 . l3 ] overallpotential \nof alist of n elements(ignoring anypotentialfor thelist elements themselves)is qnil + n \u00d7 qcons , as \nexpected. The principaladvantage of this choiceis that we can use ef.cientlinear constraint solvers to \nautomatically determine suitable type annota\u00adtions. The main limitation is that we can only express potentials \nand costs that arelinearfunctions of the number of constructors in adata structure.Recent workbyHoffmann \net al.[18] showsthat multivariate polynomial cost functions can also be ef.ciently in\u00adferred,however, \nand still only requirelinear constraint solving. Acrucialdifferencebetween classic amortised analysis[35,42] \nand type-based amortised analysisis that the type system cankeep track ofdata sharing through an explicit \nstructural rule.This allows potential to be de.ned per-reference re.ecting how often a data structure \nis accessed. The advantage is that we do not require ephemeral usage of data structures to ensure the \nsoundness of amortisation.Thedisadvantageisthat(fully evaluated) cyclicdata The .nalheapisaugmented with \nafreshlocation l3 whose content is a cyclic self-reference; because the argument z is discarded by the \napplication, its evaluation is never attempted. We can see that the semanticsis call-by-need ratherthan \ncall-by-namebyobserving the sharing of normalforms.Consider, let f = let z = z in (.x..y.y)z (2.2) inlet \ni = .x.xinlet v = fiin fv where f isboundtothethunk(2.1)and appliedtwicetotheidentity function. Evaluation \nof fv forces the thunk. After the thunk is evaluated, the location l0 that is associated with f is updated \nwith the corresponding whnf, .y.y. The second evaluation of f does not not re-evaluatethethunk(2.1).Startingfromthe \nempty con.guration, wederive: can only be assigned either zero or in.nite potential, and that the type \nsystem requires an extra structural rule. It is important to note that, although we are de.ning a static \nanalysis, the overallpotentialfor any actualdata structure can only be known dynamically, when the concrete \ndata size is known. We never actually need to compute this potential, however, but rather concern ourselves \nwith the change in potential along all possible computationpaths. 3.1 Annotated types and contexts The \nsyntax of annotated types includes type variables, functions, thunks and (possibly recursive) data types \nover labelled sums of products, representing the types of each constructor. (2.2). .x.x, q A, B, C ::= \nX | (A) A-.B |Tq [l0 . .y.y,l1 . .x.x,l2 . .x.x,l3 . l3] q q xx Evaluating expression(2.2)thus costsfourheap \ncells,thatis, one | \u00b5X.{c1 :(q1 ,B1)| \u00b7\u00b7\u00b7 |cn :(qn,Bn)} \u00d8,\u00d8,\u00d8 40 cell for each let-expression. Under \na call-by-name semantics, the cost wouldinsteadbe5, since thelet-expression thatisbound to f would thenbe \nevaluated twice, rather than once ashere. 3. AnAmortisedAnalysisforLazyEvaluation Our type-based cost \nanalysis is based on the principle of amor\u00adtisation, that is, averaging the costs of individual operations \nover a sequence of such operations. It is often possible to obtain bet\u00adter worst-casebounds by amortisation \nthanby reasoning about the costs of single operations. For example, we may obtain a worst\u00adcase bound \nof O(n)for a sequence of n operations even if some oftheindividual operations cost more than O(1).Amortisationhas \nbeen successfullyusedin manual complexity analysis ofdata struc\u00adturesinbothimperative[42] andfunctional \nsettings[35] andfor automatic resource analysis of strictfunctionallanguages[18,19, 27, 29]. It has never \nbeen previously used for automatic resource analysis of lazy evaluation. One method for deriving amortised \nbounds starts by de.ning a potential function from data structures to real numbers. The amortised cost \nof an operation is de.ned as t + f ' -f, where t is the actual cost of the operation(e.g. time or memory) \nand f, f ' are the potentials of the data before and after the operation. The key objective is to choose \nthe potential func\u00adtion so thatit simpli.es the amortised costs, e.g. so that the change inpotential \noffsets any variation in actual costs, and the amortised costs are therefore constant. We assign potential \nto data structures in a type-directed way: recursive data types are annotated with positive coef.cients \nthat specify the contribution of each constructor to the potential of the data structure.For example,ifwe \nannotate the emptylist construc\u00adtor with qnil and the non-empty list constructor with qcons , then the \nWe use meta-variables A, B, C for types, X,Y for type variables and p, q for annotations(i.e. non-negative \nrational numbers, rep\u00adresenting potential). Typing contexts are multisets of pairs x:A of variables and \nannotated types; we use multisets to allow separate potential to be accounted for in multiple references. \nWe use G,. etcfor contexts and G. x for the multisetof types associated with x in G,i.e. G. x = {A|x:A \n. G}. q ' . The annotations q, q in the function type A-' B express the q resourcesbefore and after evaluation(henceits \ncost); similarly,the annotations q, q ' in a type Tqq (A)capture the cost of evaluating a thunk (this \ncan be zero if the thunk is known to be in whnf). For simplicity, we exclude resource parametricity [29], \nsince this is onlyimportantforfunctions thatare re-usedindifferent circum\u00adstances, and notforthunksthat \nare evaluated at most once.Itisthus orthogonal to thispaper. x In a(possiblyrecursive)data type \u00b5X.{c1 \n:(q1 ,B1)| ... |cn : x (qn,Bn)} each coef.cient qi represents the potential associated with one application \nof constructor ci. We consider only recur\u00adsive data types that are non-interleaving [32], i.e. we exclude \n\u00b5-types whose bound variables overlap in scope (e.g. \u00b5X.{c1 : (...,\u00b5Y .{c2 :(...,X)})}).Thishelps usprove \na cruciallemma oncyclicstructuresinthekey soundnessproof(Theorem1).Note that this restriction does not \nprohibit nested data types; e.g. the type of lists of lists of naturals is \u00b5Y.{nil :(qn' ,()), cons : \n(qc' ,(LN,Y ))}, where N = \u00b5X.{zero :(qz ,()), succ :(qs,X)} is the type of naturals and LN = \u00b5Y.{nil \n:(qn,()), cons : (qc,(N,Y ))}is the type of list of naturals. Note also that distinct listscanbe assigneddifferentconstructor \nannotationsintheirtypes, thusimproving theprecision of the cost analysis.  (SHAREEMPTY) Y(A|\u00d8) (SHAREVAR) \n Y(X|X,. . .,X) xx Bi = \u00b5X.{c1 :(qi1 ,Bi1 )| \u00b7\u00b7\u00b7 |cm :(qim,Bim)}Y(Axj Bx1j , ..., Bxnj ) pj = Ln qij \n(1= i = n, 1 = j= m) i=1 (SHAREDAT) xx Y(\u00b5X.{c1 :(p1,A1)| \u00b7\u00b7\u00b7 |cm :(pm,Am)}| B1 , ...,Bn ) Y(Ai |A) \nY(B|Bi ) qi = qqi -q = qi ' -q ' (1= i = n) (SHAREFUN) qq1 Y(A-.-.q- n. ) ' B A1 ' B1, ...,An ' Bn \nqq q 1 n Y(A|A1,...,An ) qi = qqi -q = qi ' -q ' (1= i = n) (SHARETHUNK) Y((A) Tq1(A1),...,Tqn(An)) \nTq ' ' qq q 1 n xx Y(Aj |B1j , ...,Bnj ) m = |A|= |Bi| (1= i = n, 1 = j= m) (SHAREVEC) Y(Ax Bx1 , ..., \nBxn ) (SHAREEMPTYCTX) Y(G|\u00d8) Y(A|B1 ,...,Bn ) Y(G|.) (SHARECTX) Y(x : A, G|x : B1 ,...,x : Bn,.) Figure2. \nSharingRelation 3.2 SharingandSubtyping Figure 2 shows the syntactical rules for an auxiliary judgement \nY(A|B1 ,...,Bn )that is used to share a type A among a .nite multiset of types {B1 ,...,Bn}. It is used \nto limit contraction in ourtype system.Datatype annotationsforpotentialassociatedwith A are linearly \ndistributed by the Y relation among B1 ,...,Bn, whereas cost annotations for functions and thunks are \npreserved. Sharingalso allows the relaxingofannotations to subsume subtyp\u00ading(i.e.potential annotations \ncandecrease, cost annotations may increase).Itisimportant to note thata decrease ofcost annotations forthunks(possiblydownto \nzero) can onlybe achieved through the PREPAY structural rule(Figure4)and notthroughthese shar\u00ading rules. \nPre-paying allows us to correctly model the reduced costs of lazy evaluation by allowing costs to be \naccounted only oncefor athunk.The SHAREEMPTY, SHAREVARandSHAREVEC rules are trivial. The SHAREDAT rule \nallows potential from the data constructors that comprise A tobe shared among the Bi.The SHAREFUNand \nSHARETHUNKrules allow anycostsforfunctions and thunks, respectively, to be replicated. The SHARECTXEMPTY \nand SHARECTX rules extend the sharing relation for typing con\u00adtexts in a pointwise manner: G shares to \n. iff for each type as\u00adsignment x:Ain Gthere exists x:B1 ,...,x:Bn in .and Ashares to B1 ,...,Bn. The \nspecial case of sharing one type to a single other corresponds to a subtyping relation; we de.ne the \nshorthand notation A<:B to mean Y(A|B).This relation expresses the re\u00adlaxation of potentials and costs: \ninformally, A<:B implies that A, B haveidenticalunderlyingtypesbut B haslower or equalpo\u00adtential and \ngreater or equal cost than that of A.As usual in struc\u00adtural subtyping, this relation is contravariant \nin the left argument of functions (SHAREFUN). Aspecial case occurs when sharing a type or contexttoitself:because \nofnon-negativityY(A|A,A)(re\u00adspectivelyY(G|G,G)), requires that thepotentialannotationsin A (respectively \nG) be zero. We use this property to impose a con\u00adstraint that types or contexts carry nopotential.A variant \nof thisis Y(A|A,A ' ), whichimpliesthat A ' is a subtype ofAthatholds no potential.  3.3 Typingjudgements \nOur analysisispresented inFigures3 and 4 as aproof system that derivesjudgments oftheform G p ' e : A, \nwhere G is a typing p e context, e is an augmented expression, A is an annotated type and ' e p,p are \nnon-negative numbers approximating the resources avail\u00adablebefore and after the evaluation of e, respectively. \nFor simplic\u00ad e ity, we will omit these annotations whenever they are not explic\u00aditlymentioned.Because \nvariables referenceheapexpressions, rules dealingwiththeintroduction and elimination ofvariables alsodeal \nwith the introduction and elimination of thunk types: VAR elimi\u00adnates an assumption of a thunk type, \ni.e. of the form x : Tqq (A). Dually, LET and LETCONS introduce an assumption of a thunk type. Note that \nLETCONS is not simplyidentical to a LET rule that allows augmented expressions to be bound, since it \naccounts for the constructor potential q differently. In order to avoid duplicat\u00adingpotentialwhere a \n.-abstractionis appliedmore than once, ABS ensures that G does not carry potential, by forcing it to \nshare with itself. APP ensures that the argument andfunction types matchand includesthecostof thefunctioninthe \n.nal result.TheCONS rule simply ensures consistency between the arguments and the result type. Since \nconstructors cannot appear in source forms, the rule is used only when we need to assign types either \nto heap expres\u00adsionsortoevaluation results.TheMATCH ruledealswithpattern\u00admatching over an expression \nof a (possibly recursive) data type. The rule requires that both branches admit an identical result type \nand that estimated resources after execution of either branch are equal; ful.lling such a condition may \nrequire relaxing type and/or cost information using the structural rules below. The matching branch uses \nextra resources corresponding to the potential anno\u00adtation on the matched constructor. The structural \nrules of Figure 4 allow the analysis tobe relaxedin various ways: WEAK allows the introduction of an \nextra hypothesis in the typing context; RELAX  x:Tp p (A) p p ' x : A (VAR) x . dom(G,.) Y(A|A,A ' ) \nq = q ' G,x:T0 0(A ' ) q q ' G,. 1 + p p ' letx = e1 in e2 : C e1 : A .,x:Tq q (A) p p ' e2 : C (LET) \nA = \u00b5X.{\u00b7 \u00b7 \u00b7|c : (q, xB)| \u00b7 \u00b7 \u00b7 } x . dom(G,.) Y(A|A,A ' ) G,x:T0 0(A ' ) 0 0 c(xy): A .,x:T0 0(A) p \np ' e : C G,. 1 + q + p p ' letcons x = c(xy)in e : C (LETCONS) G,x:A q q ' e : C G 0 0 x . dom(G) .x.e \n: A-.q q ' C Y(G|G,G) (ABS) G p ' e : A-.q ' C p G,y:A q p + q p ' + q ' ey : C (APP) x B = \u00b5X.{\u00b7 \u00b7 \n\u00b7|c :(q,A)| \u00b7 \u00b7 \u00b7} (CONS) y1 :A1[B/X], ...,yk:Ak[B/X] 00 c(xy): B xx B = \u00b5X.{\u00b7 \u00b7 \u00b7|c :(q,A)| \u00b7\u00b7\u00b7} |A|= \n|x |= kxi . dom(.), for alli pp + q G: B . ' : C .,x1:A1 [B/X],...,xk:Ak[B/X] p ' : C ' e0 ' e2 ' e1 \npp p (MATCH) p G,. p ' matche0 with c(x )->e1 otherwise e2 : C Figure3. SyntaxDirectedTypeRules G p \n' e : C pp (WEAK) G,x:A p ' e : C p0 '' G p ' e : Ap = p0 p-p0 = p -p0 0 (RELAX) G p ' e : A p G,x:Tq0 \n' (A) p ' e : Cq0 = q ' q p (PREPAY) p + q1 G,x:Tqq0 ' +q1(A) p ' e : C G,x:A1,x:A2 p ' e : C Y(A|A1 \n,A2 ) p (SHARE) G,x:A p ' e : C p p G,x : B p ' e : C A<:B (SUPERTYPE) p G,x : A p ' e : C G p ' \ne : B B<:C p (SUBTYPE) G p ' e : C p Figure4. StructuralTypeRules allows argument coststobe relaxed; \nPREPAY allows(part of)the cost of a thunk to be paid for, so reducing the cost of further uses; SUPERTYPE \nand SUBTYPE allow supertyping in a hypothesis and subtypingintheconclusion, respectively;.nally, SHAREallowsthe \nuse of sharing to splitpotentialin ahypothesis. Because our semantics does not deallocate resources, \nit can be expected that all the lower annotationsinthetypesystemcanbe setto zero,i.e.the p ' in atypejudgement, \nandtheq ' infunction and thunk types(but not the m ' in an evaluationjudgement).However, .xingthemto \nzero wouldincreasethe complexityofour soundness proof[26,Section2.1]and wehave therefore retained them. \n 3.4 Worked examples We nowpresent typederivationsforthe examplesfromSection2.3 in order to illustrate \nhow the type rules of Figures 3 and 4 model the costs of our operational semantics.Recall example(2.1)which \ndemonstratesthat unneeded redexes are not reduced(i.e.,thatthe semanticsis non-strict): let z = z in(.x..y.y)z \nEvaluation of this term in our operational semantics succeeds and requires oneheapcell(for allocatingthe \nthunk namedbyz): H,S,L 01 letz = z in (.x..y.y)z . .y.y,H ' AnanalysisforthistermisgiveninFigure5 as \nanannotated type derivationwiththefollowing .naljudgement: 1 -. \u00d8 0 let z = z in (.x..y.y)z : Tqq (B)qq \n' B The annotationsintheturnstile of thisjudgementgive a cost esti\u00admate ofoneheapcell, matchingthe exact \ncost ofthe operationalse\u00admantics.The result of the evaluation is theidentityfunction, .y.y.  c) Finally, \nwe feed the linear constraints to a standard linear pro\u00ad . VAR gramming solver. with the objective of \nminimizing the overall z:T 0 0(A) 00 z : A expression cost. Any solution gives rise to a valid annotated \ntyping derivation, and hence to a concrete formula bounding VAR y:Tq (B) q ' y : B evaluation costsin \nterms oftheprogram sinputdata sizes. q q . . ABS q -. B Theimplementation allows some trivial syntactic \nextensions to the 00 : Tq q \u00d8 .y.y (B) ' q WEAK term language, namely, multiple constructor branches \nin match\u00ad q. - B 00 x:Tp p : Tq q (A) .y.y (B) expressions and omission of thedefault alternative.Also, \nasinML ' q q ABS or Haskell, we require that data constructors are associated with -. (.x..y.y)z : Tqq \n0 -. (B)' B q 00 : Tp Tq \u00d8 .x..y.y (A) a single data type. This ensures that the use of the CONS rule \nis 0 p q APP . . q syntax-directed. -. (B)' B q (A) 00 z:Tp p q LET It remains to explain how to decide \nwhen to use the structural -. B \u00d8 10 z in (.x..y.y)z : Tqq (B) let z = rulesfrom Figure 4. We use SHARE \nto split the context G into two ' q where p = p ' ,q = q ' ,Y(A|A,A) (3.1) Figure5. Typederivationfor \nnon-strict evaluation example(2.1). Thetype annotationsq,q ' represent the cost ofthe thunkforthe ar\u00adgument.Theseparameters \ncanbe arbitrary, subjectonlyto the side conditions q = q ' .The type B is similarlyarbitrary. The second \nexample (2.2) illustrates the sharing of normal forms,i.e.lazyevaluation: let f = let z = z in (.x..y.y)z \ninlet i = .x.xinlet v = fiin fv Evaluating fv forces the thunk f; following evaluation, the loca\u00adtion \nassociated with f is updated with the whnf. Subsequent eval\u00aduation of f re-uses this result.Evaluation \nof the overall expression therefore costs4 cells: G1,G2 whentyping sub-expressions(e.g. whentyping e1 \nand e2 in let x = e1 in e2 ); note that this does not lose precision un\u00adnecessarily, sincetheunused types \ncanbe assigned zeropotential. We consequently delegate the task of .nding the best assignment (i.e. one \nyielding the least cost) to the LP solver. We use WEAK depending on the remaining free variables in the \nsub-expressions. We allow PREPAY tobe usedfor thebody e2 of anylet-expression let x = e1 in e2. Once \nagain, this does not lose precision because therulecanbeusedtopay anypart ofthecost(possibly zero); hence, \nwe allow the LP solver to decide how to use it for each individualthunkin orderto achieve an overalloptimalsolution.Fi\u00adnally, \nwe allow the use of RELAX at every node of the derivation andSUBTYPE attheapplication rule(toenforce \ncompatibility be\u00adtweenthefunction andits argument)andatthe MATCH rule(to ob\u00adtainacompatible resulttype).Thismaygeneratemore \nconstraints and variables for intermediate types than necessary; the resulting increasein sizehas negligible \ncostfor currentLP-solvers(infact, allour examples were solvedbya typicaldesktop computerinless thanone \nsecond).HoffmanandJosthaveshownthattheLPprob\u00ad \u00d8,\u00d8,\u00d8 40 (2.2). .x.x, lemsthataregeneratedforthe eager \namortisedanalysis exhibit reg\u00adularities that allowlower complexity thangeneralLP solving[19]. [l0 . .y.y,l1 \n. .x.x,l2 . .x.x,l3 . l3] We conjecture that this should alsobe truefor our analysis. ThetypederivationinFigure6showsthe \nanalysisforthis example, withthe .nal typejudgement replicatingtheexact operational cost of 4 heap cells. \nNote that we use the structural rule PREPAY to pay the cost of the thunk that is bound to f precisely \nonce. We also employ SHARE to allow the function f tobe used twice.The duplicationisjusti.edbecause the \ntype of f carries no potential (i.e.itshares toitself). 4. Experimentalresults We have constructed a \nprototype implementation of an inference algorithm for the type system of Figures 3 and 4.\u00b6 The inference \nalgorithmisfully automatic(itdoes not requiretype annotations fromtheprogrammer)andmayeitherproduce an \nadmissible anno\u00adtated typing orfail(meaning that costbounds could notbefound). Our analysis is therefore \na whole program analysis. Inference is conducted in three stages: a) We .rst perform Damas-Milner type \ninference to obtain an unannotated Hindley-Milner version of the type derivation us\u00adingthe syntax-directedrulesinFigure3.The \nunannotatedtypes formafreealgebraand canbedetermined using standard .rst\u00adorder uni.cation. b) We then \ndecorate the Hindley-Milner types with fresh annota\u00adtion variablesforthetypes ofthunks, arrows anddata \nconstruc\u00adtors andperform atraversalofthetypederivationgatheringlin\u00adear constraints among annotations \naccording to the sharing and subtyping conditions. \u00b6Available at http://www.dcc.fc.up.pt/~ pbv/cgi/aalazy.cgi \n. 4.1 List reversal Our .rst recursive example is the classical list reversal using an accumulatingparameter: \nlet rev_acc = \\xs ys -> match xs with Nil () -> ys | Cons(x,xs ) -> letcons ys = Cons(x,ys) in rev_acc \nxs ys The analysis fails to .nd an annotated typing for the above frag\u00adment. This is because the recursion \nis over the .rst argument of a Curriedfunction and the ABS rule only allowspotential in the last argument(sinceit \nrequires the context to share toitselfin order to avoid duplicating potential). Two solutions are possible: \neither rewritethefunctiontouse apairoflistsinstead of usingCurrying orsimply.iptheargument order.Wechoosethelatter: \nlet rev_acc = \\ys xs -> match xs with Nil () -> ys | Cons(x,xs ) -> letcons ys = Cons(x,ys) in rev_acc \nys xs The analysis can now yield an informative type. If we abbreviate the type oflists of Aas: def \nL(qc,qn,A)= \u00b5X.{Cons :(qc, (T00 (A),T00 (X)))| Nil :(qn, ())} .We use theGLPKlibrary: http://www.gnu.org/software/glpk \n.  . (Figure5) WEAK -. (B) . VAR 00 z : T(B) 00 -. 00 B 10 10 f:T (T B)z in (.x..y.y) let z = 00 00 \nx : B (B) x:T ABS 00 \u00d8 .x.x : B WEAK 00 00 (B) .x.x : B : T . . .. VAR VAR -. 00 -. (B) fi : Bf:T 0 \n-. 00 B) 00 -. fv : B 0 LET 00 (T(B) (B) 00 f : T 00 00 (T(B) (B) 00 f : T(B) 00 B) 00 f:TBf:TB 00 \nAPP APP -. f:T 0 -. let v = fiin fv : B 0 00 (T 000000 (T 0000 0000 f:TB),i:T -. (B) 0 (B) B),v:T (B) \n00 -. (B) -. (B) -. (B) 0 B),iT: 00 00 00 (T 000000 10 B),f:T (T B),i:T (B) 00 . . SHARE -. 00 00 (B) \nf:T 0000 10 f:T (T(B) let v = fiin fv : B LET 00 (T 0000 20 (T B) let i = .x.xin ... : B PREPAY 0 . \n . 10 30 f:TB)let i = .x.xin ... : B 0 LET 0 00 -. (C) Figure6. Typederivationforlazy-evaluation example(2.2). \nthen we obtain: let mkqueue = \\f r -> match f with 40 \u00d8 let f =(let z = z in(.x..y.y)z)inlet i = .x.xinletv \n= fiin fv : B, where B C T = 0 Nil() -> let f = reverse r in letcons r = Nil() in letcons q = Pair(f \n,r ) (L(0,0,A))-.(L(1,0,A))-. This annotated type assigns apotential of1heap cell to each Cons 00 00 \n00 00 L(0,0,A) acc : T T rev  in q letcons q = Pair(f,r) in q in the recursion argument xs.The .rst \nargument ysand the result otherwise bothhavenopotential.Thus,theanalysisgivesabound of n heap cellsfor \nreversingalistoflengthn, whichis,infact,the exact cost.  4.2 Functionalqueues We now considerOkasaki \nspurelyfunctionalqueues,implemented aspairs oflists[35].Thisdata structure allows O(1)amortised ac\u00adcesstimetobothends \nofthequeue, andis commonlyusedas an ex\u00adampleforderiving amortisedbounds.Thetranslationintoourlan\u00adguageis \nshowninFigure7.Itconsists ofthreefunctions: mkqueue normalizes a pair of front and back lists by reversing \nthe back list when the front list is empty, so ensuring that the front is empty iff thequeue asawholeisempty; \nthe enqueue function adds an ele\u00adment to theback of thequeue; and the dequeue function returns a newqueue \nwithout thefront element.We omit the auxiliaryde.ni\u00adtion ofreverse whichuses rev acc fromSection4.1.Assuming \nnormalized queues, the enqueue function has constant worst-case cost. The dequeue function may involve \nreversing a variable-size list, soits worst-caseisO(n);however, the amortisedcostforboth operationsis \nO(1).Thetypesinferredbyour analysis are shownin Figure 8. They express amortised bounds that correspond \nexactly to Okasaki s analysis, which assigns 1 unit of potential for each elementin thebacklist of thequeue.Moreprecisely: \nmkqueue consumes a .xed cost of 3 heap cells plus 1 cell for each node in the back list; furthermore, \nthe result queue preserves1unit ofpotentialfor each nodein the newbacklist; let enqueue = \\x q -> match \nq with Pair(f,r) -> letcons r = Cons(x,r) in mkqueue f r let dequeue = \\q -> match q with Pair(f,b) \n-> match f with Cons(x,f ) -> mkqueue f b  1 0 Figure7. Okasaki spurelyfunctionalqueues. let repeat \n= \\x -> let xs = repeat x in letcons ys = Cons(x,xs) in ys The two de.nitions yield exactly the same \nin.nite list of values. However, the .rst one is more ef.cient: repeat will generate a cyclicstructureoccupying \nasingleheap node,while repeat will allocate many (identical) nodes as the result stream is traversed. \nWe can observe these non-functional properties in the types that our analysisinfersfor the twode.nitions: \n(A)-. 000000 \u00b5X.{Cons :(0, (T...} (A),T(X)))| repeat : T enqueue anddequeue have .xedamortisedcosts(5&#38;3units, \n respectively),preserving1unit ofpotentialin thebacklist. repeat : T 4.3 In.nite structures Our next \nexample concerns the use of lazy evaluation to de.ne in.nite lists(i.e. streams). Consider two de.nitions \nof a function thatgenerates a stream ofidentical values: let repeat = \\x -> letcons ys = Cons(x,ys) in \nys  2 0 (A)-. First note that, because the results of both functions are in.nite structures, they must \nhave zero potential, hence the zero annota\u00adtion on Cons. The type for repeat shows that it costs 1 heap \ncell to generate the .rst node and that subsequent nodes have no fur\u00adther cost (because the thunk annotations \nare zero). The type for repeat ,however, shows that evaluating each tailthunk of the re\u00adsultlist costs2 \ncells(plus2 cellsforthe .rst node). 000020 \u00b5X.{Cons :(0, (T...} (A),T(X)))| (L(0,0,A))-.  00-.(A)(T \n00 (L(1,0,A))-.(L(0,0,A))\u00d7 T(L(1,0,A)))-. 50 30 00 000000 (L(1,0,A)) (L(0,0,A))\u00d7T mkqueue : T TT 0000 \n0000 T 00 (L(0,0,A))\u00d7T 00 (L(1,0,A)) enqueue : T (A)-.B)-.T(A)-.B)-.T(A)-.B)-.T(A)-.B)-.T 000000 0 00 \n00 00 0 0 01 00 01 0 T (L(1,0,A)))-. Figure8. Analysis of thefunctionalqueues example. 30 dequeue : \nT 00 (T 00 000000 (L(0,0,A))\u00d7 T (L(0,0,A))\u00d7 T(L(1,0,A)) T (X)))|Nil :(1,())})-.\u00b5X.{Cons :(0,(T 00 0000 \n0000000000 (\u00b5X.{Cons :(3,(T(X)))| ...} (T (A),T(B),T (4.1) map : T (X)))|Nil :(1,())})-.\u00b5X.{Cons :(0,(T \n00 0000 00001000 (\u00b5X.{Cons :(3,(T(X)))| ...} (T (A),T(B),T (4.2) map : T (X)))|Nil :(0,())})-.\u00b5X.{Cons \n:(0,(T 30 0000 00000030 (\u00b5X.{Cons :(0,(T(X)))| ...} (T (A),T(B),T (4.3) map : T (X)))|Nil :(0,())})-.\u00b5X.{Cons \n:(0,(T 30 0000 00001030 (\u00b5X.{Cons :(0,(T(X)))| ...} (T (A),T(B),T (4.4) map : T Figure9. Analyses of \nmap for .nite(4.1)(4.2)andin.nitelists(4.3)(4.4).  4.4 Higherorderfunctionsoverlists Proof. By induction \non the height of derivation of G,x:A p e e : The nexttwolemmas establishinversionpropertiesfor constructors \nand .-abstractions. ' p C, simply replacing any occurrences of x for y. Consider now thehigher-orderfunction \nmap that applies afunction to every elementin alist: let map = \\f xs -> match xs with Nil () -> letcons \nnil=Nil() in nil Lemma 5.2 (CONS inversion). If G . c(xy): B then B = | Cons(x,xs ) -> let y = f x \nx \u00b5X.{... |c :(q, A)| ... }and Y(G|xy:Ax[B/X]). in let ys = map fxs  in letcons ys = Cons(y,ys ) in \nys Figure 9 shows four distinct typings inferred depending on use: (4.1)and(4.2)wereinferredfor mapping \nover a .nite list(which can carrypotential) while(4.3)and(4.4)wereinferredfor mapping over an in.nite \none (which must have zero potential). Thus, the .rst two typings (4.1) and (4.2) offset costs with potential \nfrom the argumentlist(threeheap cellsforeach Cons and one for each Nil)while(4.3)and(4.4)defer costs \nto the tail thunk of the result lists. Note also that (4.1) and (4.3) allow a zero-cost argument function \nwhile(4.2) and(4.4)allow a unit-cost argumentfunction; the effect of this changeis re.ected on the thunk \ncostsfor thehead ofthe resultlists.Finally, we remarkthatthe analysis chooses these ** q. Lemma 5.3 (ABS \ninversion). If G . .x.e : A-' C then there q exists G ' such that Y(G|G ' ), Y(G ' |G ' ,G ' ), x ./dom(G \n' ) and q G ' ,x:A q ' e : C. ProofSketch forboth lemmas. A typing with conclusion G . c(xy): B must \nresultfrom axiom CONS followedby(possiblyzero) q.uses of structural rules. Similarly, a typing G . .x.e \n: A-' C q must result from an application of the rule ABS followed by uses of structural rules.Theprooffollowsbyinduction \non the structural rules, considering each rule separately. The .nal auxiliarylemmaallowssplitting contextsusedfortyping \nexpressionsin whnf according to a split of the result type. typings automatically according to use. Lemma \n5.4 (Context Splitting). If G 00 w : A, where w is an expression in whnf and Y(A|A1,A2 ); then there \nexists G1 ,G2 5. Soundness such that Y(G|G1 ,G2 ), G1 00 w : A1 and G2 00 w : A2. ProofSketch. Theprooffollowsfrom \nan application ofLemma5.2 This section establishes the soundness of our analysis with respect to the \noperational semantics of Section 2. We begin by stating some auxiliary proof lemmas and preliminary de.nitions, \nnotably (ifw isa constructor)orLemma5.3(if w is an abstraction)together formalizing the notion of potential \nfromSection3.We then de.ne with thede.nition of sharing. 5.2 GlobalTypes,ContextsandBalance We now de.ne \nsome auxiliary mappings that will be necessary for formulating the soundness of our type system. The \nmapping M from locations to types, written {l1 . A1 ,...,ln . An}, records the global type of alocation, \nwhich accounts for allpoten\u00adtialin all references tothatlocation.The mapping C fromlocations to typing \ncontexts, written {l1 . G1,...,ln . Gn}, associates each location with its global context thatjusti.es \nits global type. Weextend theprojection operationfrom(local) contextstoglobal e theprincipalinvariants \nof our system, namely, type consistency and type compatibility relations between a heap con.guration \nof the operational semantics and global types, contexts and balance. We conclude with the soundness resultproper(Theorem1). \n 5.1 AuxiliaryLemmas We nowpresent some auxiliaryprooflemmasfor our type system. The .rst lemma allows \nus to replace variables in type derivations. Notethatbecause of thelazy evaluation semantics(and unlikethe \nusual substitution lemma for the .-calculus), we substitute only variablesbut not arbitrary expressions. \np e : Cand y/ . dom(G). contextsin the natural way: IfG,x:A Lemma5.1(Substitution). ' p p e e e)then \nalso G,y:Ae[y/x] ** Note, however, that using the same de.nition with both .nite and in.-We also extend \nsubtyping to global types in the natural way, nite structures would generate infeasible constraints due \nto the absence of namely M <:M ' if and only if dom(M) . dom(M ' ) and for resourceparametricity (introducedin[29]). \nall l . dom(M) we have M(l)<:M(l ' ). This relation will be FV(: C. def ' {l1 . G1 ,...,ln . Gn}l (G1,..., \nGn)l Cl = p =  used to assert that the potential assigned to global types is always non-increasing during \nexecution. Furthermore, we introduce an auxiliary balance (or lazy potential) mapping B from locations \nto non-negative rational numbers. This keeps track of the partial costs of thunks that have been paid \nin advance by applications of the PREPAY rule. Note that these auxiliary mappings are needed only in \nthe soundness proof of the analysis for bookkeeping pur\u00adposes,butare not partof theoperational semantics \ninparticular, theydo notincur runtime costs.  5.3 Potential We de.ne the potential of an augmented \nexpression with respect to a heap and an annotated type. The potential of expressions that are not whnfs(i.e. \nthunks) and .-abstractions is always zero. For data constructors, the potential is obtained by summing \nthe type annotation with the(recursive)potential contributedby each of the arguments.Notethatfor cyclicdata \nstructures,thepotentialis only de.nedif all the type annotations of all nodes encountered along a cycle \nare zero(the overallpotential must therefore alsobe zero). De.nition5.5(Potential). Thepotentialassigned \nto an augmented (LOC3) H(l)notin whnf and l . L and G= \u00d8 The three cases in the above de.nition are mutually \nexclusive: LOC1 applies when the expression in the heap is already in whnf; otherwise LOC2 and LOC3 apply,depending \non whether the thunk is or is not under evaluation. For LOC2, the balance B(l) asso\u00adciated with location \nl is added to the available resources for typ\u00ading the thunk H(l), effectively reducing its cost by the \nprepaid amount. Once evaluation has begun (LOC3), or once it has com\u00adpleted(LOC1),thebalanceis consideredspent.However, \nwe never lower or reset thebalance, sinceitis simplyignoredin such cases. De.nition 5.9 (Type consistency \nof heaps). We say that a heap state (H,L) is consistent with global contexts, global types and balance, \nand write C,B .MEM (H,L): M, if and only if for all l . dom(H): C(l),B;H,L .LOC l : M(l)holds. De.nition \n5.10 (Globalcompatibility). We say that a global type M is compatible with context G and a global context \nC, written Y(M |G,C ),ifand onlyif Y(M(l)|Gl ,Cl )for alll . dom(M). De.nition 5.9 requires the type \nconsistency of each speci.c loca\u00ad expression e of type Aunder heap H, written fHe:A),isde.ned in(5.1)withinFigure10. \nEquation(5.2)extendsthede.nitiontotyping contextsinthenat\u00adural way.Equation(5.3)de.nespotentialforglobal \ncontexts,but considers only thunksthat are not under evaluation.Finally,(5.4) de.nes a convenient shorthand \nnotation for a similar summation over thebalance.The next twolemmasformalize theintuition that e sharing \nsplitsthepotential of atypeand thatasupertype of atype Ahaspotential thatis nogreater than A. e Lemma \n5.6 (Potential Splitting). If Y(A|A1,...,An ) then for alle such that the potentials are de.ned, we have \nfHe:A) = fHe:Ai). e e eL (( ( i This lemma has an important special case when A occurs as one of the \ntypes on the right hand side: if Y(A|A,B1 ,...,Bn )then tion. De.nition 5.10 requires that the global \ntype of each location accountsforthejointpotential of all referencestoitin eitherthe local orglobal contexts. \n 5.5 Soundnessof theproof system We can now state the soundness of our analysis as an augmented typepreservation \nresult. Theorem1 (Soundness). Let t . Q+ be .xed,but arbitrary.If the following statementshold p G p \n' e : A (1.A) C,B .MEM (H,L): M (1.B) Y(M |(G,T),C ) (1.C) ' H,S,L . e . w, H (1.D) e =0for alli. thenfor \nall m . N such that e is not in whnf oris a .-abstraction (because potentials are zero in e:Bi) ProofSketch. \nFirst note that the results follow immediately if e fH( LL m = t + p+fH(G)+fH(T)+FH(C)+FH(B) (1.E) those \ncases). The potential is also zero if e e e is a constructor that is part of a cycle (since otherwise \nit would be unde.ned). The remaining case is for a constructor with no cycles, i.e. a directed M <:M \n' (1.F) acyclicgraph(DAG).Theproof is thenbyinduction on the length ' 0 G 0 w : A (1.G) of thelongestpath. \n'' '' C ,B .MEM (H ,L): M (1.H) e such that there exist m ' , G ' , C ' , B ' and M ' such that Lemma5.7 \n(PotentialSubtype). If A<:B thenfor all Y(M ' |(G ' ,T),C ' ) (1.I ) thepotentials are de.ned, wehave \nfH( e e e:A)= fHe:B). Proof. By the de.nition of subtyping, this is a direct corollary of Lemma5.6for \nthe case when n =1. 5.4 Consistency andCompatibility We now de.ne the principal invariants for proving \nthe soundness of our analysis, namely, consistency and compatibility relations between a heap con.guration \nand the global types, contexts and balance. We proceed by .rst de.ning type consistency of a single location \nand then extendit to a wholeheap. De.nition 5.8 (Type consistencyof locations). We say that loca\u00ad tion \nladmitstype Tqq (A)under context G,balance B,heap con.g\u00aduration (H,L), and write G,B;H,L .LOC l : Tqq \n(A), if q = q ' and one of thefollowing casesholds: (LOC1) H(l)isin whnf and G 00 H(l): A q + B(l) (LOC2) \nH(l)notin whnf and l . L and G q ' H(l): A ( m ' H,S,L m ' e . w, H (1.J) '' LL m = t + p + fH' (w:A)+fH' \n(T)+FH' (C ' )+FH' (B ') (1.K) Informally, the soundness theorem reads as follows: if an ex\u00adpression \ne admits a type A (1.A), the heap can be consistently typed (1.B) (1.C) and the evaluation is successful \n(1.D), then the result whnf also admits type A (1.G). Furthermore, the re\u00adsulting heap can can also be \ntyped (1.H) (1.I ) and the static bounds that are obtained from the typing of e give safe resource estimatesfor \nevaluation(1.E)(1.J)(1.K). The arbitrary value t is used to carry over excess potential which is not \nused for the immediate evaluation but will be needed in subsequent ones (i.e. for the argument of an \napplication). Similarly, the context T is used to preserve types for variables that are not in the cur\u00adrent \nscope but that are necessary for subsequent evaluations (i.e. the alternatives of the match). Because \nof space limitations, we present here only a proof sketch; a detailed proof is available at http://www.dcc.fc.up.pt/~ \npbv/AALazyExtended.pdf .  .p+ L i fH(H(li):Bi[A/X]) ifA = \u00b5X.{\u00b7 \u00b7 \u00b7|c:(p,Bx)| \u00b7 \u00b7 \u00b7}and e = c(xl) def \n.e . Tq fH(e:A)= fH(e:B) ifA = q (B) (5.1) ee . .0 otherwise def fH(G) = L{fH(H(x):A) x:A . G} (5.2) \nL def FH(C)= L{fH(C(l)) l . dom(H)and l/. L and H(l)is not a whnf} (5.3) def FL L{ H(B)= B(l) l . dom(H)and \nl/. L and H(l)is not a whnf} (5.4) Figure10. Potential ProofSketch. The proof is by induction on the \nlengths of the derivations of (1.D) and (1.A) ordered lexicographically, with the derivation of the evaluation \ntaking priority over the typing derivation. We proceed by case analysis of the typing rule used inpremise(1.A), \nconsideringjustsome representative cases. Case VAR: The typingpremise l:Tp (A) p ' l : Ais an axiom. \np p Byinversion of the evaluationpremise, we obtain H,S,L .{l}. H(l). w,H ' .In order to apply induction \nto the evaluation of the thunkH(l), wetake thetypingcontextfromthehypothesis oftype consistency for thelocation \nl.We applyinduction to a typing with theglobal type M(l)rather than thelocal type Tpp (A)in thelocal \ncontext.Thisgives us a stronger conclusion with a context that we canthen split usingLemma5.6 tojustify \ntype consistencyforthe heapupdate andthelocalcontext answerforthe answer.Finally, we require an auxiliary \nresult to ensure that if the update introduces a cycle, the locations on the cycle can be assigned a \ntype with zero potential(alemma containedin thefullproof). 1+ p Case LET: The typingpremise is G,. p \n' let x = e1 in e2 : C andevaluationpremisegives H0 ,S,L . e2[l/x]. w,H ' where H0 = H[l . e1[l/x]]is \nthe heap extended with a new location l and thunk. To apply induction to the evaluation of e2[l/x]we \nre\u00adestablishthe consistency to the newlocation l;thisisdone usingG from the typing hypothesis together \nwith an idempotent type for self-references to l. Applying induction then yields all required conclusions. \nCase MATCH: The typingpremise is: G,. p ' matche0 with c(x )->e1 otherwise e2 : C p By inversion of \nthe type rule, we get a typing G p ' : B for p e0 e0, where B = \u00b5X.{\u00b7 \u00b7 \u00b7|c :(q,Ax)| \u00b7 \u00b7 \u00b7}is some data \ntype with a constructor c. We apply induction to the evaluation of e0 and then do a case analysis on \nthe evaluation rule used (i.e. MATCH. or FAIL.). We then apply induction to either e1 [xl/x ] or e2 and \nobtaintheproofobligation.To establishthepremise(1.E)on m for the MATCH. case, we use de.nition of potential: \nfH(c(xl):B)= q+L i fH(li:Ai[B/X]) i.e.thepotential of the constructoris the sum of the type annotation \nq plus thepotentialofits context. 6. RelatedWork As described above, we build heavily on Launchbury s \nnatural semantics for lazy evaluation [30], as subsequently adapted by Sestoft,and exploitideasthat weredevelopedbydelaEncinaand \nPe na-Mar\u00b4i[14,15].Thereis a signi.cantbody of other work on thesemanticsof call-by-need evaluation.Pre-datingLaunchbury \ns work,Josephs[25]gave a denotational semantics of lazy evalua\u00adtion, using a continuation-based semantics \nto model sharing, and including anexplicit store.However,thisapproachdoesn t .t well with standard proof \ntechniques. Maraist et al. [31] subsequently de.ned both natural and reduction semantics for the call-by-need \nlambda calculus, so enabling equational reasoning, and a similar approach wasindependently describedbyAriola \nandFelleisen[4]. Bakewell andRunciman[6] havepreviouslyde.ned an oper\u00adational semantics for Core Haskell \nthat gives time and space exe\u00adcution costsin terms ofSestoft s semanticsforhisMark1 abstract machine.The \nworkhas subsequentlybeen extendedtogive a model that can be used to determine space leaks by comparing \nthe space usagefortwo evaluators using abisimulation approach[5].Gus\u00adtavsson andSands[17]havesimilarlyde.nedaspace-improvement \nrelation that guarantees that some optimisation can never lead to asymptotically worse space behaviour \nfor call-by-need programs andMoran andSands[33]havede.ned animprovement relation for call-by-need programs \nthat can be used to determine whether one terminatingprogramimproves anotherin allpossible contexts. \nFinally, like delaEncinaandPe na-Mar\u00b4i, Mountjoy[34] de\u00adrivedan operationalsemanticsfortheSpinelessTaglessG-Machine \nfrom the natural semantics of Launchbury and Sestoft, includ\u00ading poly-applicative .-expressions. The \nmain differences between these approaches are thatdelaEncina andPe na-Mar\u00b4icorrect some mistakes in Mountjoy \nspresentation, that theyprovide correctness proofs,thattheir semantics correctlydeals withpartialapplications \nin the Spineless Tagless G-Machine, that they deal with partial applications as normal forms, and that \nthey consider two distinct implementation variants, based on push/enter versus apply/eval. Our own workdiffersfrom \nthisbody of earlier workin that we not onlyprovide an operationalsemanticsto modellazyevaluation,but \nalsoprovideacorresponding cost semanticsfromwhich wederive a static analysis to automatically determine \nupper bounds on the memoryrequirements oflazilyevaluatedprograms. Resource analysis based on pro.ling \nand manual code inspec\u00adtionhaslongformedthe state-of-the-art andstillis currentpractice in many cases. \nIndeed, for non-strict functional languages, such as Haskell, ad-hoc techniques, manual analysis or symbolic \npro\u00ad.ling are the only currently viable approaches: as we have seen, the dynamic demand-driven nature \nof lazy functional program\u00adming creates particular problems for resource analysis, whether manual or \nautomatic. There has therefore been very little work on static resource analysis for lazy functional \nprograms, and, to ourknowledge, no previous automatic analysis has ever been pro\u00adduced. The most signi.cant \nprevious work in the area is that by Sands[37,38], whosePhD thesisproposed a cost calculusfor rea\u00adsoningabout \nsuf.cientandnecessaryexecutiontimeforlazilyeval\u00aduated higher-order programs, using an approach based \non evalua\u00adtion contexts [39, 45]to capture information about evaluation de\u00adgree and appropriate projections \n[47] to project this information tothe required approach.Wadler[45]had earlierproposed a sim\u00adilar approach \nto that taken by Sands, but using strictness analy\u00adsis combined with appropriate projections, rather \nthan the need\u00adedness analysis that Sands uses. A primary disadvantage of such approaches lies in the \ncomplexity of the domain structure and as\u00adsociatedprojections that mustbe used when analysing even simple \ndata structures such as lists. In contrast, our approach easily ex\u00adtends to arbitrarily complexdata structures.A \nsecondarydisadvan\u00adtage is that, unlike the self-contained analysis we have described, projection-basedapproaches \nrely onthe existence of a complex and powerfulexternal neededness analysis todetermine evaluation con\u00adtexts \nfor expressions. These are seriouspractical disadvantages: in fact,todate, we are notaware of anyfully \nautomatic static analysis thathasbeenproduced using these techniques.  Anumber of authorshaveproposed \nanalysis approachesbased on transforming lazy programs to eager ones (e.g. Bjerner and Holmstr\u00a8om[7], \nFradet and M\u00b4etayer[16]). The resultingprograms may thenbe analysed using(simpler)techniquesfor eagerly \nevalu\u00adated programs, such as the automatic amortised analysis we have previously developed [19, 28, 29]. \nUnlike our work, these ap\u00adproaches are generally restricted to .rst-order programs, and suf\u00adferfrom theproblems \nthat theyare,ingeneral, not cost-preserving, that they lead to potentially exponential code explosion, \nand that, because they alter the program, they are not suitable for use with standard compilersforlazyfunctionallanguages. \nSeveral authors haveproposed symbolic pro.ling approaches, where programs are annotated with additional \ncost parameters. For example,Wadler[46] uses monads to capture execution costs through atick-countingfunction;Albert \net al.[1] adds additional cost parameters to each function, using logic variables to capture sharinginformation \nand so avoid costduplication; andHope[22] describes how to derive an instrumented function for determining \ntime and space usage,including a simpledeallocation model,for a strictfunctionallanguage and outlineshowthiscouldbeextended \nto lazy evaluation. Danielsson[12] takes this work a stage further, describing alibrary that canbe used \nto annotate(lazy) functions with the time that is needed to compute their result. An anno\u00adtated monad \nis then used to combine these time complexity an\u00adnotations.This canbe used to verify(but not infer)the \ntime com\u00adplexity of(lazy) functionaldata structures and algorithms against Launchbury s semantics, using \na dependent type approach. Pro\u00advided the cost modelis suf.ciently accurate, symbolicpro.ling ap\u00adproaches \ncan give exact costs for speci.c program inputs. They are also easy to implement. However, unlike the \nwork described here,the costinformationisinput-dependent, cannotgive aguaran\u00adteed worst-case exceptin \ntrivial cases, and transforms theprogram in a waythat may notbe cost-preservingfor all metrics.Unlike \nour analysis, such approaches therefore cannot produce upper bounds on resource usagefor allpossibleprograminputs. \nThe amortised analysis approach has been previously studied by a number of authors, but has never previously \nbeen used to au\u00adtomaticallydeterminethecostsoflazy evaluation.Tarjan[42].rst described amortised analysis, \nbut as a manual technique. Okasaki [35] subsequently described how Tarjan s approach could be ap\u00adplied \nto (lazy) data structures, but again as a manual technique. While therehas subsequently been signi.cantinterestin \nthe use of amortised analysisforautomaticresourceusage analysis,using an advanced per-reference potential, \nnone of this newer work, how\u00adever,considerslazy evaluation. Hofmann andJost[19] werethe .rsttodevelop \nan automatic amortised analysisforheap consump\u00adtion,exploiting adifference metric similartothat usedbyCrary \nand Weirich[11](thelatter,however, only check bounds, and therefore do notperform an automatic static \nanalysis ofthekindwe require); Hofmann et al.haveextended theirmethod tocoveracomprehen\u00adsive subset of \nJava, including imperative updates, inheritance and type casts[20,21];Shkaravska et al.[41]subsequently \nconsidered heap consumption inference for .rst-order polymorphic lists; and Campbell[9]hasdeveloped theideas \nofdepth-based andtempo\u00adrary credit uses to give better results for stack usage. Hoffmann etal.[18] achieved \nanotherbreakthroughby extendingthetech\u00adniquetoinfermultivariatepolynomial costfunctions, still only re\u00adquiring \nef.cient LP solving. Finally, several authors have recently studied analysesforheap usagein eagerlanguages, \nwithout consid\u00aderinglazy evaluation. For example,Albert et al.[2]present afully automatic,liveheap-space \nanalysisfor an object-orientedbytecode language with a scoped-memory manager, and have subsequently extendedthisto \nconsidergarbage collection[3],but,unlike our sys\u00adtem,data-dependencies cannotbe expressed.Braberman et \nal.[8] inferpolynomialbounds on theliveheap usagefor aJava-likelan\u00adguage withautomatic memory management, \nbutdo not covergen\u00aderal recursive methods.Finally,Chinet al.[10]present alinearly\u00adboundedheap and stack \nanalysisfor alow-level(assembler) lan\u00adguage withexplicit(de)-allocation,butdo not coverlazy evaluation \norhigh-levelfunctionalprogramming constructs. 7. ConclusionsandFurtherWork This paper has introduced \na new automatic type-based analysis for accurately determining bounds on the execution costs of lazy \n(higher-order)functionalprograms.The analysis uses the newidea of lazy potential as part of an amortised \nanalysis technique that is capable of directly analysing lazy programs without requiring defunctionalisation \nor other non-cost-preserving program transfor\u00admations.Our analysisdeals with(potentiallyin.nite)recursivedata \nstructures, nesteddata structures, and cyclicdata structures.Itisde\u00ad.nedfor arbitrarydata types(including \ne.g. trees).Wehaveproved the soundness of this analysis against an operational semanticsde\u00adrivedfromLaunchbury \ns natural semantics ofgraph reduction, and analysed some non-trivial examples oflazy evaluation using \napro\u00adtotypeimplementation of the analysis. A number of extensions to this work would repay further in\u00advestigation. \nFirstly, to reduce complexity, our system is restricted to monomorphicde.nitions.It shouldbe straightforward, \nalbeitla\u00adborious,toadapt ourprevious work onpolymorphism[29]toalso cover the lazy setting, including \nresource parametricity , which allows function applications to have different costs depending on context. \nSecondly, we have only considered linear cost functions. Althoughit wouldincrease complexity,Hoffmann \net al.[18] sap\u00adproach to polynomial cost functions, which infers asymptotically tightboundsfor manypracticalexamples, \nshould alsobe applicable here.Thirdly,while wehavepreviously constructed[28,29]anal\u00adyses that are capable \nof dealing with arbitrary countable resources for strictlanguages, for simplicity,in thispaper we have \nrestricted our attention to heap allocations. Analysing time and stack usage shouldfollow a similar structuretothatpresentedhere,but \nrequires a richer operational semantics than that given by Launchbury. Fi\u00adnally,it wouldbeinterestingto \nextendthis workto afullproduction abstract machine such as the Spineless Tagless G-Machine [24]. This \nwould allow us to con.rm our results against real functional programs writtenin non-strictlanguages such \nasHaskell. Acknowledgements Thisworkis supportedby EUgrantsSCIEnce(RII3-CT-026133), ADVANCE(IST-248828) \nandParaPhrase(IST-288570), andEP-SRCgrant HPC-GAP(EP/G055181). Hugo Sim oes would like to thank Fundac\u00b8 \naoparaaCi enciaeTecnologia,Portugal forPh.D. grantSFRH/BD/17096/2004. References [1] E.Albert,J.Silva,andG.Vidal. \nTimeEquationsforLazyFunctional (Logic)Languages. InProc.AGP-2003:2003JointConf. onDeclara\u00adtiveProg.,ReggioCalabria,Italy,Sept.3-5,2003,pages13 \n24,2003. [2] E. Albert, S. Genaim, and M. G\u00b4omez-Zamalloa. Live Heap Space Analysis for Languages with \nGarbage Collection. In Proc. ISMM 2009: Intl. Symp. on Memory Management, pages 129 138, Dublin, Ireland, \nJune2009.ACM. ISBN978-1-60558-347-1.  [3] E.Albert,S.Genaim,andM.G\u00b4omez-Zamalloa. ParametricInference \nofMemoryRequirements forGarbageCollected Languages. In Proc. 2010 International Symposium on Memory Management, \nISMM 10, pages121 130,NewYork,NY,USA,2010.ACM. [4] Z. M. Ariola and M. Felleisen. The Call-by-Need Lambda \nCalculus. J.Funct.Program.,7:265 301,May1997. [5] A. Bakewell and C. Runciman. A Model for Comparing \nthe Space Usage of Lazy Evaluators. In Proc. PPDP 2000: Intl. Conf. on Principles andPracticeofDeclarativeProg.,Quebec,Canada,pages \n151 162,2000. [6] A.Bakewell andC.Runciman. ASpaceSemanticsforCoreHaskell. Electr.Notes Theor.Comput. \nSci.,41(1),2000. [7] B. Bjerner and S. Holmstr\u00a8om. A Compositional Approach to Time Analysis of First \nOrder Lazy Functional Programs. In Proc. FPCA 89: Conf. on Functional Prog. Langs. and Comp. Arch.,pages \n157 165,1989. [8] V.Braberman,F.Fern\u00b4andez,D.Garbervetsky,andS.Yovine.Paramet\u00adric Prediction of Heap \nMemory Requirements. In Proc. ISMM 2008: Intl. Symp. on Memory Management, pages 141 150, NewYork,NY, \nUSA,June2008. [9] B. Campbell. Amortised Memory Analysis Using the Depth of Data Structures. InG.Castagna, \neditor, Proc. ESOP 2009: 18th European Symposium on Programming, York, UK, pages 190 204. Springer LNCS5502,2009. \n[10] W.-N.Chin,H.Nguyen,C.Popeea, andS.Qin. AnalysingMemory Resource Bounds for Low-Level Programs. In \nProc. ISMM 08: Intl. Symp. on Memory Management, pages 151 160, Tucson, USA, June 2008.ACM. ISBN978-1-60558-134-7. \n[11] K. Crary and S. Weirich. Resource Bound Certi.cation. In Proc. POPL 2000: ACM Symp. on Principles \nof Prog. Langs., pages 184 198,Jan.2000. [12] N. A. Danielsson. Lightweight Semiformal Time Complexity \nAnal\u00adysis for Purely Functional Data Structures. In Proc. POPL 2008: Symp. on Principles of Prog. Langs., \nSan Francisco, USA, January 7-12,2008,pages133 144.ACM,2008. [13] A.delaEncinaandR.Pe na-Mar\u00b4i.ProvingtheCorrectnessoftheSTG \nMachine. In Proc. IFL 01: Impl. of Functional Langs., Stockholm, Sweden,Sept.24-26,2001,pages88 104.SpringerLNCS2312,2002. \n[14] A. de la Encina and R. Pe na-Mar\u00b4i. Formally Deriving an STG Ma\u00adchine. In Proc.5thInternationalACMSIGPLANConference \nonPrin\u00adciples andPractice ofDeclarativeProgramming,27-29August2003, Uppsala,Sweden,pages102 112.ACM,2003. \n[15] A. de la Encina and R. Pe na-Mar\u00b4i. From Natural Semantics to C: a FormalDerivation of twoSTGMachines. \nJ. Funct. Program.,19(1): 47 94,2009. [16] P.Fradet andD.L.M\u00b4etayer. Compilation offunctionallanguagesby \nprogram transformation. ACM Transactions on Programming Lan\u00adguages andSystems,13(1):21 51,January 1991. \n[17] J. Gustavsson and D. Sands. A Foundation for Space-Safe Transfor\u00admations of Call-by-Need Programs. \nElectronic Notes on Theoretical Computer Science, 26,1999. [18] J. Hoffmann, K. Aehlig, and M. Hofmann. \nMultivariate Amortized Resource Analysis. In 38th Symp. on Principles of Prog. Langs. (POPL 11),pages357 \n370,2011. [19] M. Hofmann and S. Jost. Static Prediction of Heap Space Usage for First-Order Functional \nPrograms. In Proc. POPL 2003: ACM Symp. onPrinciples ofProg.Langs.,pages185 197,Jan.2003. [20] M.HofmannandS.Jost.Type-BasedAmortisedHeap-SpaceAnalysis \n(for an Object-Oriented Language). In Proc. ESOP 06: European Symposium onProg.,pages22 37,Mar.2006. \n[21] M.HofmannandD.Rodriguez.Ef.cienttype-checking foramortised heap-space analysis. In Proc.CSL 09:18thEACSLAnnualConf.on \nComputer Science Logic,pages317 331,2009. [22] C. Hope. A Functional Semantics for Space and Time. PhD \nthesis, 2008.University ofNottingham. [23] R. Hughes. Why Functional Programming Matters. The Computer \nJournal, 32(2):98 107,1989. [24] S. L. P. Jones. Implementing Lazy Functional Languages on Stock Hardware: \nThe Spineless Tagless G-Machine. J. Funct. Program.,2 (2):127 202, 1992. [25] M. B. Josephs. The semantics \nof lazy functional languages. Theor. Comput. Sci.,68(1):105 111, 1989. [26] S. Jost. Static Prediction \nof Dynamic Space Usage of Linear Func\u00adtionalPrograms,Dipl.Thesis,DarmstadtUniv.ofTech.,2002, . [27] S.Jost. \nAutomated AmortisedAnalysis.PhD thesis,LMUMunich, . [28] S.Jost,H.-W.Loidl,K.Hammond,N.Scaife,andM.Hofmann. \nCar\u00adbon Credits for Resource-Bounded Computations Using Amortised Analysis. In Proc. FM 2009: Intl. Conf. \non Formal Methods, pages 354 369.Springer LNCS5850,2009. [29] S. Jost, H.-W. Loidl, K. Hammond, and M. \nHofmann. Static deter\u00admination ofquantitative resourceusageforhigher-orderprograms.In Proc.POPL2010:ACMSymp. \nonPrinciples ofProg.Langs.,Madrid, Spain,pages223 236,Jan.2010. [30] J. Launchbury. A Natural Semantics \nfor Lazy Evaluation. In Proc. POPL 93:Symp.onPrinc.ofProg.Langs.,pages144 154,1993. [31] J. Maraist, \nM. Odersky, and P. Wadler. The Call-by-Need Lambda Calculus. J. Funct.Program.,8:275 317,May1998. [32] \nR.Matthes. Extensions ofSystemFbyIteration andPrimitiveRecur\u00adsion onMonotoneInductionTypes. PhD thesis,LMUMunich,1998. \n[33] A.Moran andD.Sands. Improvementin aLazy Context:AnOpera\u00adtionalTheoryforCall-by-Need. In POPL,pages43 \n56,1999. [34] J. Mountjoy. The Spineless Tagless G-machine, naturally. In Proc. ICFP 98:Intl.Conf.onFunctionalProg.,pages163 \n173,1998. [35] C.Okasaki. PurelyFunctionalDataStructures.CambridgeUniversity Press,1998. [36] S.PeytonJones(ed.),L.Augustsson,B.Boutel,F.Burton,J.Fasel, \nA. Gordon, K. Hammond, R. Hughes, P. Hudak, T. Johnsson, M. Jones, J. Peterson, A. Reid, and P. Wadler. \nReport on the Non-Strict Functional Language, Haskell (Haskell98). Technical report, Yale University,1999. \n[37] D. Sands. Complexity Analysis for a Lazy Higher-Order Language. In Proc. ESOP 90: European Symposium \non Programming, Copen\u00adhagen, Denmark,SpringerLNCS432,pages361 376,1990. [38] D. Sands. Calculi for Time \nAnalysis of Functional Programs. PhD thesis,ImperialCollege,University ofLondon,September1990. [39] D. \nSands. Computing with Contexts: A Simple Approach. In Proc.HOOTSII:Higher-OrderOperationalTechniquesinSemantics, \nElectr. NotesinTheoretical Comp.Sci.1998. [40] P.Sestoft.Deriving aLazyAbstractMachine. J.FunctionalProgram\u00adming,7(3):231 \n264,1997. [41] O. Shkaravska, R. van Kesteren, and M. van Eekelen. Polynomial Size Analysis of First-Order \nFunctions. In Proc. TLCA 2007: Typed LambdaCalculiandApplications(TLCA2007),pages351 365,Paris, France,June26 \n28,June2007.Springer LNCS4583. [42] R.E.Tarjan. Amortized computational complexity. SIAMJournal on Algebraic \nandDiscreteMethods,6(2):306 318, April1985. [43] P.B.Vasconcelos. SpaceCostAnalysisUsingSizedTypes.PhDthesis, \nUniversity ofStAndrews,2008. [44] P. B. Vasconcelos and K. Hammond. Inferring Cost Equations for Recursive, \nPolymorphic and Higher-Order Functional Programs. In Proc. IFL 03: Impl. of Functional Languages, pages \n86 101, Edin\u00adburgh,UK,2004.Springer LNCS3145. [45] P.Wadler.StrictnessAnalysisaidsTimeAnalysis.InProc.POPL \n88: ACMSymp. onPrinc. ofProg.Langs.,pages119 132,1988. [46] P.Wadler. TheEssence ofFunctionalProgramming. \nIn Proc. POPL 92:ACMSymp. onPrinciples ofProg.Langs.,pages1 14,Jan.1992. [47] P.WadlerandJ.Hughes.ProjectionsforStrictnessAnalysis.In \nProc. FPCA 87: Intl. Conf. on Functional Prog. Langs. and Comp. Arch., Springer LNCS274,pages385 407,Sept.1987. \n   \n\t\t\t", "proc_id": "2364527", "abstract": "<p>This paper describes the first successful attempt, of which we are aware, to define an automatic, type-based static analysis of resource bounds for lazy functional programs. Our analysis uses the automatic amortisation approach developed by Hofmann and Jost, which was previously restricted to eager evaluation. In this paper, we extend this work to a lazy setting by capturing the costs of unevaluated expressions in type annotations and by amortising the payment of these costs using a notion of <i>lazy potential</i>. We present our analysis as a proof system for predicting heap allocations of a minimal functional language (including higher-order functions and recursive data types) and define a formal cost model based on Launchbury's natural semantics for lazy evaluation. We prove the soundness of our analysis with respect to the cost model. Our approach is illustrated by a number of representative and non-trivial examples that have been analysed using a prototype implementation of our analysis.</p>", "authors": [{"name": "Hugo Sim&#245;es", "author_profile_id": "81548019076", "affiliation": "Universidade do Porto, Porto, Portugal", "person_id": "P3804380", "email_address": "hrsimoes@dcc.fc.up.pt", "orcid_id": ""}, {"name": "Pedro Vasconcelos", "author_profile_id": "81548019077", "affiliation": "Universidade do Porto, Porto, Portugal", "person_id": "P3804381", "email_address": "pbv@dcc.fc.up.pt", "orcid_id": ""}, {"name": "M&#225;rio Florido", "author_profile_id": "81100497160", "affiliation": "Universidade do Porto, Porto, Portugal", "person_id": "P3804382", "email_address": "amf@dcc.fc.up.pt", "orcid_id": ""}, {"name": "Steffen Jost", "author_profile_id": "81100111171", "affiliation": "Ludwig Maximillians Universit&#228;t, Munich, Germany", "person_id": "P3804383", "email_address": "jost@tcs.ifi.lmu.de", "orcid_id": ""}, {"name": "Kevin Hammond", "author_profile_id": "81456615219", "affiliation": "University of St Andrews, St Andrews, United Kingdom", "person_id": "P3804384", "email_address": "kh@cs.st-andrews.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364575", "year": "2012", "article_id": "2364575", "conference": "ICFP", "title": "Automatic amortised analysis of dynamic memory allocation for lazy functional programs", "url": "http://dl.acm.org/citation.cfm?id=2364575"}