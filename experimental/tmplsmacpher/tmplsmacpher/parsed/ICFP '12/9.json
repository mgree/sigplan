{"article_publication_date": "09-09-2012", "fulltext": "\n Painless Programming Combining Reduction and Search Design Principles for Embedding Decision Procedures \nin High-Level Languages Tim Sheard Portland State University sheard@cs.pdx.edu Abstract We describe \nthe Funlogic system which extends a functional lan\u00adguage with existentially quanti.ed declarations. An \nexistential dec\u00adlaration introduces a variable and a set of constraints that its value should meet. Existential \nvariables are bound to conforming values by a decision procedure. Funlogic embeds multiple external deci\u00adsion \nprocedures using a common framework. Design principles for embedding decision procedures are developed \nand illustrated for three different decision procedures from widely varying domains. Categories and Subject \nDescriptors D.1.0 [Software.]: Program\u00adming Techniques.General. General Terms Applicative Programming, \nLogic Programming, Functional Programming Keywords Search, .rst order logic, decision procedures 1. Introduction \nThere are many styles of declarative programming functional pro\u00adgramming (FP), logic programming (LP), \nand constraint based pro\u00adgramming (CLP), to name a few. Most systems that implement a particular style \nfall exclusively into one of two broad compu\u00adtational modalities that I call reduction and search. A \ndeclarative program, in the reduction modality, consists of a set of instructions for transforming the \ninput into the output. A declarative program, in the search modality, consists of a description of the \nproperties of a solution using some sort of logic, and then searching a solu\u00adtion space for an answer \nthat has those properties. It is important to emphasize that both kinds of systems can emulate the other \n(since most are Turing complete). In fact, there are some systems that combine both modalities, such \nas Curry[4], Ciao![10], Flora[20], AMPL[8], and Oz[24]; The most common approach is to build a general \npurpose language around a single search modality mecha\u00adnism. These languages often call specialized external \ntool, such as a SAT solver (Alloy[12]), Linear-Programming libraries (AMPL), an SMT solver (DMinor[3]), \nor a CLP solver library (Ciao!). Another approach is to embed a search modality into a func\u00adtional language \nthrough the use of libraries or specialized data structure design. Such systems often do a competent \njob. But in general both kinds of systems suffer from one or more of the fol\u00adlowing problems. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 12, September \n9 15, 2012, Copenhagen, Denmark. Copyright c &#38;#169; 2012 ACM 978-1-4503-1054-3/12/09. . . $15.00 \n Loss of generality. Systems built around a single search based mechanisms can solve a one class of \nproblems well, but break down on other classes.  Impedance mismatch. The use of embedded libraries to \nbroaden the class of problems amenable to solution often re\u00adsults in a certain unnaturalness in their \nuse. For example they may require the user to script a bunch of library calls using a given API.  Sub-optimal \nnotation. Some problems are naturally and suc\u00adcinctly encoded using specialized notation. Systems built \naround libraries often require the user to encode their problem descrip\u00adtion in an embedded speci.cation \nlanguage using the host lan\u00adguage s notation.  Poor abstraction. Specialized systems are often very \nexpres\u00adsive, but not succinct. It matters not, that a problem can be ex\u00adpressed, if it requires thousands \nof lines to do so.  Loss of incremental improvement. Through contests such as SMT-COMP [2], and the \nCADE ATP System Competition [25] the competition amongst implementers of specialized solvers is immense. \nThe winning systems often make tremendous im\u00adprovements over previous year s winners. Capturing these \ngains is important.  The author, interested in alternate ways to specify programs declaratively, tried \nmany systems, and ran into all of the problems above. He noticed that every problem is avoided in some \nsystem. Could all the problems be avoided in a single system? He decided to try by following the design \nprinciples below. A good system combines both computational modalities. Search naturally describes some \nproblems, and reduction others. The two systems complement each other in several important ways. Logic \nbased programs are often both concise and easy to un\u00adderstand; while functional programs make great scripting \nlan\u00adguages, for combining things together.  A good system should have multiple external solvers. This \nal\u00adlows the system to be general over several classes of problems, yet bene.t from specialized implementations \nand incremental improvements.  A good system naturally supports alternate notations where necessary, \nbut reuses notation where possible.  A good abstraction that bridges between the functional and logic \nworlds is necessary. The abstraction should be general it should apply to all logics. It should be both \neasy to use and understand.  Funlogic is a new language (not an embedded domain speci.c language). It \nhas its own compiler. It reuses key ideas from many systems (set notation from Datalog, escape from one \nsyntax to an\u00adother from MetaML, relational algebra as .rst order logic from Al\u00adloy and KodKod, narrowing \nfrom Curry, and overloaded types from Haskell). In building Funlogic, the author learned many engineer\u00ading \nlessons and much about combining multiple solvers. He made a number of research discoveries worth reporting. \n Search problems are best described by multiple dimensions. These include description of the search \nspace, special cases that either shrink the search space (such as symmetries) or make its description \nsmaller, the properties that should hold of the solution, the strategy used to search the space, and \na description of the target of the search are we looking for any solution, no solution, multiple solutions, \na solution that maximizes an objective function, an approximate solution, or a solution as a probability \ndistribution? We have found these dimensions to describe every kind of search we have studied. Additional \ndimensions, to add to our understanding of existing systems, are sought.  Overloading of terms allows \nthe same language to be used in both the reduction and search modality. A term that describes the property \nof a solution speci.es input to an external solver. The meaning of a term in a constraint, is not the \nsame as an identical term in another part of the program. This difference in meaning can be explained \nby two techniques: overloading and staging. Precise semantics can be given for the language in terms \nof these two techniques.  The rest of this paper is as follows: In Section 2 we describe our system. \nIn Section 3 we solve several small problems (each with a different solver). In Section 4 we discuss \nthe eight steps necessary to add a new solver. Then, in three large Figures (4, 5, 6), we step through \nthe eight steps for each solver, discussing similarities and differences using real data extracted from \nthe examples introduced in Section 3. In Section 5 we discuss a few of the many possible extensions that \nmight make our system even more useful. In Section 6 we discuss how it is related to other systems. 2. \nLanguage description Funlogic combines functional programming with .rst-order logic. A program in Funlogic \nconsists of a sequence of declarations. A declaration introduces into scope one or more names, and each \nname is bound to a value. Values bound to newly introduced names are either primitive (like data constructors) \nor they are computed by either reduction or search. There are six kinds of declarations. 1. Value. (twoPi,x) \n= (3.14159 * 2.0, not True) A value declaration introduces one or more names by use of a pattern on the \nleft-hand-side of an equation. The term on the right-hand-side is reduced to a value, and that value \nis matched against the pattern, binding the names in the pattern. In the example above twoPi is bound \nto 6.28318 and x is bound to False. 2. Dimension. dim width#Int = [1 .. 3] A dimension declaration introduces \na .nite subset of a base type. Base types include Int, Real, Bool, String, Char. Di\u00admensions are .nite \nsets and play a key role in describing search spaces. 3. Data. data Tree a = Tip |Fork(Tree a) a (Tree \na) A data declaration introduces one or more constructors which are either functions or constants of \na newly introduced type. In this example Tree is a new type, and Tip is a constant of type Tree, and \nFork is a ternary function that returns a Tree. An enumeration (a data type consisting of only constants), \nalso introduces a Dimension with the same name.  4. Function. len []= 0 len (x:xs) = 1 + len xs A function \ndeclaration introduces a function de.ned by pattern matching over one or more clauses. Functions may \nbe recursive. 5. Formula. anc(x,y) -> person(x),person(y). anc(x,y) <\u00ad parent(x,y); parent(x,z),anc(z,y). \n A formula declaration is an alternate syntax for introducing a name that binds to a .nite set. A .nite \nset describes a relation, and the formula syntax is reminiscent of a Prolog or Datalog program. The formula \nis a concise way of describing compli\u00adcated sets. A formula declaration has two parts: a constraint anc(x,y) \n-> person(x),person(y) and a computation: anc(x,y) <-parent(x,y);parent(x,z),anc(z,y). The constraints \ncan place arbitrary limits on what the computation can add to the set. In the example above person is \na previously introduced dimension (playing the role of a unary predicate), and parent a previously introduced \nrelation. Formula are an example of an alternate notation and are discussed in detail in Section 3.3. \n 6. Search. exists ys : List 4 Int where sum ys == 9 find First by SMT A search declaration introduces \none or more names whose val\u00adues are computed by search. It contains a number of compo\u00adnents: the name(s) \nbeing introduced (ys), a description of the search space (List 4 Int), a set of constraints (sum ys==9), \na strategy (First) and a technique (or solver) used to perform the search (SMT). In the paragraphs that \nfollow we will introduce additional fea\u00adtures of Funlogic by introducing a number declarations, then \nwe will explore the consequences of the declarations by showing an interaction with the read-eval-print \nloop of Funlogic. An interac\u00adtion starts with the prompt exp> , which is followed on the same line with \nthe user s input, followed on the next line with the sys\u00adtem s response. For example exp> 4+4 8:: Int \nHere we see that the system responds with 8:: Int when the user types 4+4 after the prompt. Feature List. \nHaskell-like list syntax is supported. Lists can be constructed by enumeration, the use of constructors \n([] for nil, and the in.x (:) for cons), and list comprehensions. Lists also support pattern matching. \nexp> [True,False] [True,False]:: List Bool exp 1:2:[] [1,2]:: List Int exp> [2..6] [2,3,4,5,6]:: List \nInt exp> [(i,i-j) | i <-[8,9], j <-[3,4]] [(8,5),(8,4),(9,6),(9,5)]:: List (Int,Int) exp> case [3,4] \nof { [] -> 99; (x:xs) -> x} 3:: Int Feature Dimension. Finiteness plays an important role in Fun\u00adlogic. \nSearch spaces are .nite n-dimensional spaces, or can be de\u00adscribed by a .nite number of logical variables. \nFunlogic uses the notion of dimension to describe this phenomena. A single dimen\u00adsion is introduced by \nthe dim declaration, or by an enumeration. dim int11#Int = [0..10] dim int2#Int = [4,5] data Name = \nTom | Hal | Jon These declarations introduce names for three dimensions. exp> int11 Int#11:: Dim Int \nexp> int2 Int#2:: Dim Int exp> Name Name#3:: Dim Name In general, Funlogic uses the symbol # in the syntax \nthat manip\u00adulates dimensions. Multi-dimensions are constructed from other di\u00admensions by use of the dimension \naggregate operator that consists of the # operator followed by a tuple of dimensions. For example. pair \n= #(Name,int11) triple = #(pair,int11) Dimensions are .attened when they are aggregated. Note how triple \nhas been .attened into sequence of 3 simpler dimensions even though it was constructed by aggregating \ntwo dimensions. exp> pair #(Name#3,Int#11):: Dim (Name,Int) exp> triple #(Name#3,Int#11,Int#11):: Dim \n(Name,Int,Int) Operations on dimensions include iteration using a list compre\u00adhension, and the function \nelem:: Dim a -> a -> Bool. exp> [ i | i <-#(Name,int2) ] [(Tom,4),(Tom,5),(Hal,4),(Hal,5),(Jon,4),(Jon,5)] \n:: List (Name,Int) exp> elem pair (Tom,5) exp> elem pair (Hal,55) True:: Bool False:: Bool Feature Array. \nArray are .nite aggregates with constant time access functions. An array with type: Array d i is indexed \nby values in the dimension d and contain elements of type i. Arrays are constructed by array:: Dim d \n-> List i -> Array d i. twoD = array #(Name,int2) [ a , b , c , d , e , f ] oneD = array width [\"red\",\"blue\",\"green\"] \nFor 2-D arrays the elements in the initialization list appear in row\u00admajor order. It is assumed that \nthere is an element in the list for every point in the domain d. exp> oneD 12 3 +-----+-------+--------+ \n|\"red\"| \"blue\"| \"green\"| +-----+-------+--------+ :: Array Int String exp> twoD 45 +---+---+ Tom| a | \nb | +---+---+ Hal| c | d | +---+---+ Jon| e | f | +---+---+ :: Array (Name,Int) Char Arrays are accessed \nusing index:: Array d i -> d -> i. The in.x operator (.) is also bound to the same function. Dimen\u00adsions \nof an array are accessed by arrayDim:: Array d i -> Dim d. exp> index oneD 3 \"green\":: String exp> twoD.(Jon,4) \ne :: Char exp> arrayDim twoD #(Name#3,Int#2):: Dim (Name,Int) Feature Set. A value of type Set(A,B,C) \nstores a set of tuples of type (A,B,C). A set is constructed with the function set:: Dim d -> List d \n-> Set d. Elements of a set are constrained by the domain of the set. dim int3#Int = [1,2,3] s1 = set \n#(int3,int3) [(1,2),(1,2),(2,3),(0,4)] Set construction removes elements from the list that are out\u00adside \nthe domain. Set construction also ignores duplicates. Note the missing tuples in s1 below. exp> s1 {(1,2) \n(2,3)}:: Set(Int,Int) 3. Several small problems In Figure 1 are several small problem solutions written \nin Funlogic. Each illustrates a different search based paradigm. All are remark\u00adably similar. A problem \nis de.ned. A solution is phrased in terms of an existentially declared data structure with .rst order \nconstraints, and a solver is chosen. The majority of the code comprising a so\u00adlution consists of a few \nsmall functions that manipulate data and express relevant boolean valued functions used to constrain \nwhich solutions are acceptable. 3.1 A production problem In the lower-left quadrant of Figure 1 is a \nFunlogic program that solves a production problem using an linear-programming solver. The problem involves \nchoosing the production level at several fac\u00adtories to meet estimated sales demand while minimizing transporta\u00adtion \ncosts, subject to some global constraints. The existentially de\u00adclared array prod holds production information. \nThe value stored in prod.(f,s) holds the number of units produced at factory f destined for store s. \nConstraints include: Factory A is smaller than the others, and its total production cannot exceed 150 \nunits.  every prod.(f,s) value is positive or zero.  The sum of production for each store is equal \nto estimated sales at that store.  Shipping costs vary between each factory and store, and are stored \nin the array ship. The store owners wish to minimize to\u00adtal shipping costs. Note that the speci.cation \nof the problem is ex\u00adpressed in terms of ordinary user level functions: sum, and and. These and several \nother library functions are found in the lower\u00adright quadrant of Figure 1. 3.2 An N-queens solver In \nthe upper-right quadrant of Figure 1 is a Funlogic program that solves the N-queens problem using an \nSMT solver. The problem involves placing n-queens on a n \u00d7 n chessboard in a manner such that no queen \ncan take another queen using the moves of chess. rank = 2 --Rank 2 (4x4) Soduko solver dim size#Int \n= [0 .. rank*rank -1 ] dim digit#Int = [1.. rank*rank ] input = set #(size,size,digit) [(0,3,4),(1,1,2),(1,2,1) \n,(2,1,1),(2,2,4),(3,3,1)] --(i,j,n) is in the set if \"ij\"= n (ij in base-rank) square = set #(size,size,size) \n[ (i,j,(div i rank) * rank + (div j rank)) | i <-size, j <-size ] exists grid : set #(size,size,digit) \ninput .. universe where --every row(n) has 1-4 and[$(full {k<-grid($n,j,k)}) | n <-size] &#38;&#38; --every \ncolumn(n) has 1-4 and[$(full {k<-grid(i,$n,k)}) | n <-size] &#38;&#38; --every box(n) has 1-4 and[$(full \n{k<-grid(i,j,k),square(i,j,$n)}) | n <-size ] &#38;&#38; --each coordinate has only one digit $(grid(i,j,n),grid(i,j,m) \n-> eq#digit(n,m) ) find First by SAT ans = setToArray grid --Production minimization problem dataFactory=A \n|B |C data Store = NYC | ATL | LA pairs = #(Factory,Store) ship = array pairs [2,3,5,3,2,1,3,4,2] sales \n= array Store [230,140,300] exists prod: Array #(Factory,Store) Int where sum[ prod.(A,s) | s <-Store \n] <= 150 &#38;&#38; and [ prod.(f,s) >= 0 | (f,s) <-pairs ] &#38;&#38; and [ sales.s == sum [prod.(f,s) \n| f <-Factory] | s <-Store ] find Min sum[ prod.(f,s) * ship.(f,s) | (f,s) <-pairs ] by LP  size = 4 \n--An N-Queens Solver dim width#Int = [1 .. size] dim i2#Int = [0,1] rowPts i = [(i,j) | j <-width] colPts \nj = [(i,j) | i <-width] nwEdges = append (rowPts 1) (colPts 1) swEdges = append (rowPts size) (colPts \n1) add mpts=sum[m.p|p<-pts] downDiag(x,y) = (x,y):[(x+i,y+i)| i <-width, x+i <= size, y+i <= size] \nupDiag (x,y) = (x,y):[(x-i,y+i)| i <-width, x-i >= 1, y+i <= size] exists bd : Array #(width,width) i2 \nwhere --every row(i) adds to 1 and [add bd (rowPts i) == 1 | i <-width] &#38;&#38; --every column(i) \nadds to 1 and [add bd (colPts i) == 1 | i <-width] &#38;&#38; --every diagonal adds to 0 or 1 and [add \nbd (downDiag p) <= 1 | p <-nwEdges ] &#38;&#38; and [add bd (upDiag p) <= 1 | p <-swEdges ] find First \nby SMT --Library functions append :: List a -> List a -> List a append [] ys = ys append (x:xs) ys = \nx :(append xs ys) and :: BoolLike b => [b] -> b and [] = true and [x] =x and (x:xs) = x &#38;&#38; (and \nxs) sum :: NumLike t => [t] -> t sum [] = liftI 0 sum [x] =x sum (x: xs)=x+ (sumxs) Figure 1. Solutions \nfor several small problems We assume the reader is familiar with this problem1. The program works as \nfollows. It represents a solution by an array of integers in the range [0..1] A 4-queens solution looks \nlike: solution representation Q Q Q Q 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0  The invariant (on the representation) \nis that every row and col\u00adumn sums to exactly 1, and that the sum of every diagonal is at most 1. To \ncompute these sums, we proceed in two steps. First we de.ne simple functions that return a list of points, \nrepresenting co\u00ad 1 See wikipedia.org/wiki/Eight queens puzzle for a good discussion. ordinates in the \narray, for rows, columns, and diagonals. It is best to visualize the points that a function returns by \nusing a graphical rep\u00adresentation. An X in a square means that coordinate is an element of the list returned. \nRows (rowPts) and columns (colPts) are par\u00adticularly easy and are implemented by simple comprehensions \nover the size of the problem. rowPts i colPts j j x x x x  x x x x  Diagonals are more complex. \nGiven a point, (i,j), we compute the list of points on the up and down diagonals starting at that point \nas visualized below. downDiag(i,j) upDiag (i,j) jj x x x x x x  i To compute all the diagonals, we \nsee that every complete diag\u00adonal is rooted at a point on the edge of the array. Down-diagonals are rooted \non points on the north and west edges, and up diagonals are rooted on points on the south and west edges. \nnwEdges swEdges x x x x x x x x x x x x x x  To sum the elements in an array we de.ne the function \nadd. It is given an array and a list of coordinates, and sums the elements of the array at those coordinates. \nHere we make use of the library function sum which adds all the elements in a list. The answer we are \nsearching for will be stored in the ex\u00adistentially declared array bd. It is a 2-D array with dimensions \n#(width,width) . It stores elements in the range of the dimen\u00adsion i2 ([0..1]). The constraint on bd \nis a large conjunction consisting of 4 parts: rows, columns, up-diagonals, and down-diagonals. each part \nhas the form: and [ add bd (f i) o 1 |i<-alphas ] where alphas is a set of elements (here, either a positive \ninteger less than the puzzle size or a coordiate of an edge), f is a function from an element to a list \nof points, and o is a boolean relation. For each coordinate in (fi) we sum the element at that coordinate, \nand compare that sum to 1. 3.3 An exercise in alternate notation In the upper-left quadrant of Figure \n1 is a Funlogic program for solving soduko problems. It uses a SAT solver, and much of its elegance and \nsimplicity relies on using an alternate notation for describing and manipulating sets. A set of n-tuples \nis an n-ary relation. FunLog has two alternate notations for manipulating relations formula and constraints. \nThe simplest formula is called an atom. It is comprised of a name followed by a parenthesized list of \npatterns. For example R(p1, .., pn). To be well formed R must be a set of n\u00adtuples of type (t1, .., tn) \nand each pattern pi must have type ti. The atom R(p1, .., pn) denotes the largest subset of R in which \nevery tuple matches the patterns (p1, .., pn). Atoms are the basic building blocks of formula and constraints. \nIn Figure 2 are rules for constructing formula and constraints. These notations are modelled after both \nProlog terms and Datalog formula (that express the relational algebra). Because I assume that Formula \nsyntax. let x::Set(A,B), y::Set(A,B), g::Set(B,B), h::Set(C,D), and f::Set(C,B). Also let a, b, c, and \nd be variables, and p and q be patterns. Then we can denote operations on these sets by the following \nformula: formula meaning type x(p,q) atomic formula, .lter Set (A,B) x(a,b); y(c,d) union of x and y \nSet (A,B) x(a,b), y(a,b) intersection of x and y Set (A,B) x(a,b), h(c,d) product of x and h Set (A,B,C,D) \nh(c,d),f(c,b) join ofh and f Set (C,D,B) { a <-y(a,b) } the 1st projection of y Set A eq#n(a,b) equality \non n Set (n,n) Constraint syntax. A constraint denotes a boolean valued function over a set of tuples. \nLet r::Set d, s::Set d, and f::Set(d,e) where d and e are .nite domains as explained in Section 2, then: \nformula meaning none r(x) r is the emptyset full r(x) r contains every tuple in domain d some r(x) r \nhas at least one element one r(x) r has exactly one element r(x) <= s(y) r is a subset of s f(x,y) -> \nr(x) r is a subset of { x <-f(x,y)} f(x,y)| x->y in f, y functionally depends on x Example translation. \nA formula denotes a set, and a constraint denotes a boolean value. Each translates to ordinary function \ncalls over sets. Formula translate into calls to functions that implement the relational algebra over \nsets of tuples. An example translation follows. { c <-x(a,\"Tom\"),y(a,c) } First we select only those \ntuples of x whose second component is \"Tom\", then join the resulting relation with y on the common component \na. This results in a ternary relation, z(a,\"tom\",c), which is then projected on its third component. \nproject3of3 (join (select (\\(a,b)->b==\"Tom\") x) y) Figure 2. The meaning of formula and constraints by \nexample. most readers are familiar with at least one of these notations2, I only give suggestive examples \nfor each supported construction in both notations. Embedding alternate syntax. The default syntax of \nFunlogic is the expression. Any place an expression is expected a formula or a constraint can be used \nby escaping into one of the alternate syn\u00adtaxes by use of the $( ... ) operator. Consider the declarations \ndim people#String = [\"Anita\",\"Barbara\",\"Caleb\",\"Frank\",\"Tim\"] parent = set #(people,people) [(\"Frank\",\"Tim\"),(\"Tim\" \n, \"Caleb\") ,(\"Anita\",\"Tim\"),(\"Barbara\",\"Caleb\")] To create a set consisting of those tuples that include \nvalid ( child, parent, grandparent) triples, one may declare: threeGen = $(parent(x,y),parent(y,z)) which \nescapes to the alternate formula notation to express a self\u00adjoin on the parent relation. One can test \nif that set has exactly one element by escaping into the alternate constraint notation. 2 if you are \nnot, see wikipedia.org/wiki/Datalog for an introduction exp> threeGen {(\"Caleb\",\"Tim\",\"Anita\") (\"Caleb\",\"Tim\",\"Frank\")} \n: Set(String,String,String) exp> exp> $(one threeGen(x,y,z)) False: Bool It is also possible to escape \nfrom the formula notation into the expression notation. Let the variable n have value \"Tim\", then in \na formula parent(x,$n) the $n indicates an escape into the expres\u00adsion notation, and is equivalent to \nthe formula parent(x,\"Tim\"). This makes it possible to parameterize sets speci.ed using the for\u00admula \nnotation. 3.4 A Soduko solver Soduko puzzle of rank n consists of a square matrix with edge size equal \nto n \u00d7 n where some of the squares have been .lled in with digits in the range [1.. n \u00d7 n]. A sample \npuzzle of rank = 2 is given below. 0123 0 4 2 1 1 4 1 (0,3,4) 1 (1,1,2) (1,2,1) 2 (2,1,1) (2,2,4) 3 \n(3,3,1) To solve this problem, a number between 1 and 4 must be inserted into each empty coordinate. \nThe invariant of a successful solution is that all the digits 1-4 must appear (in any order) in every \nrow, in every column, and in every 2\u00d72 box. We make the term box precise in our code, but note, in a \nrank n problem, the boxes are n \u00d7 n. Each coordinate in a row, column, or box is given an index (between \n0 and n - 1) as illustrated below. For example the coordinates (1,3,i) (in bold font) are in row 1, column \n3, and box 1. row column box 0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 0 1 2 3 0 1 2 3 0 1 2 3 0 1 2 3 0 0 1 \n1 0 0 1 1 2 2 3 3 2 2 3 3  We represent a problem as a .nite set of triples. One for each .lled in square \nin the problem description. The triples for the sample puzzle are listed to the right of the puzzle above \n(they are called input in the solution). The interpretation of a triple (row,col,k) is that the value \nk is stored at coordinate (row,col). Because both (row,col,3) and (row,col,5) could be in the set, it \nis possible for many numbers to be stored at each coordinate. Thus an additional invariant is that exactly \none number is stored at each coordinate. We solve the problem by computing sets of triples, which are \nsubsets of the 3-dimensional search space. Each subset, s, contains the tuples comprising a single row, \ncolumn, or box. If we project ({k <-s(i,j,k) }) a set of tuples, like s, on the digit column, we obtain \na set of digits, where each element is in the range 1-4 (see the digit dimension declaration). An invariant \nis met if this set is the full set {1,2,3,4}. Computing the projection over row n ({k<-grid($n,j,k)}) \nand column n ({k<-grid(i,$n,k)}) is trivial. The n th box takes some care. The set square assigns every \ncoordinate to a single box index. Thus the tuple (i,j,n) is in the set, square, if coordinate (i,j) is \nassigned to box n. This is easy to compute by noting that n = ij if we read ij as a 2 digit number in \nbase rank. When rank is 2, square is the set: {(0,0,0),(0,1,0),(0,2,1),(0,3,1),(1,0,0),(1,1,0) ,(1,2,1),(1,3,1),(2,0,2),(2,1,2),(2,2,3),(2,3,3) \n,(3,0,2),(3,1,2),(3,2,3),(3,3,3)} See the graphic labeled box above for a visual representation of square \nat rank 2. 4. Seven steps to adding a new solver The steps we discuss in this section constitute a prescription \nof how to incorporate an external solver into a high-level language. We consider these steps to be the \nresearch results of this paper. We discuss these steps in two passes. First we introduce the steps in \nthe abstract. Then in Figures 4, 5, and 6 we illustrate each of the steps, on each of the solvers, using \nactual data from the problems introduced in Figure 1. Every solver accepts problems in a given form, \nthe compiler must capture this form, but hide its details from the programmer. The programmer thinks \nin terms of data and functions supported by Funlogic. The key to painless programming is maintaining \nthe programmer s view. This is done by the use of overloading. In Figure 3 are four abstract classes \nof operations. Three of these classes are familiar to most programmers arithmetic, booleans, comparisons. \nThe fourth class captures operations in the relational algebra, and will be familiar to any one who has \nstudied data bases. In the same .gure we supply concrete instances. These are the functions programmers \nnormally associate with these operations. Each solver will associate a different set of functions with \nthese operators, and supply a mechanism to lift a concrete value to its representation type(s). This \nprocess is described in the next few paragraphs. As we look closely at each solver, keep in mind how \nwidely their structure varies, yet they will all yield to this same process. 1. Representation types. \nThe .rst step to incorporating a solver is to choose a data structure to represent problems solvable \nby that solver. Actual representation types appear as the .rst step in each of the Figures 4, 5, and \n6. These come in several .avors. Term representations. The type SAT (.gure 5) is an abstract representation \nof the booleans. The type SMT (.gure 4) is an abstract representation of operations and comparisons over \nnu\u00admeric types. These types are essentially term representations of expressions over of the concrete \ntype they represent.  Structural representations. The type MExp (.gure 6) captures the domain of constraints \nover linear arithmetic expressions as used in linear-programming problems. Here the representation captures \nstructural properties of the problem domain that a term is a polynomial.  Propositional representations. \nThe type (BitVector SAT t) (.gure 5) is an abstract representation of .nite sets of elements of type \nt. A propositional representation stores bits and repre\u00adsents different values depending on the truth \nor falsity of the bits stored. Some users may be familiar with a bit-blasting proposi\u00adtional representation \nof arithmetic, where integers in the range [0 .. n] are represented as log2 bits. A propositional repre\u00adsentation \ncompiles to a SAT problem.  Search tree. A fourth kind of representation type is that of an explicit \nsearch tree. Overloaded operations prune paths in the tree that do not lead to a solution that meets \nthe constraints. For space reasons, an example of this type of representation is not given in the paper. \n 2. Overloading. The second step in the process of maintaining an abstract view of solver representations \nis the use of overload\u00ading. Programmers write constraints using the computational mech\u00adanisms of FunLog \n functions and data structures. User de.ned Overloaded operators class BoolLike b where true :: b false \n:: b (&#38;&#38;) :: b -> b -> b (||) :: b -> b -> b liftB :: Bool -> b class NumLike t where liftI :: \nInt -> t liftR:: Rational -> t (+) :: t -> t -> t (*) :: t -> t -> t class(NumLike t,BoolLike b) => Compare \nt b where (<=):: t -> t -> b (==):: t -> t -> b class SetLike s where create:: Dim a -> [a] -> s a select:: \n(a -> Bool) -> s a -> s a proj3of3:: s (a,b,c) -> s c Concrete instances instance BoolLike Bool where \ntrue = P.True false = P.False x &#38;&#38; y = x P.&#38;&#38; y x || y = x P.|| y liftB x = x instance \nNumLike Int where liftI x = x liftR x = error \"UnSupported\" (+) x y = x P.+ y (*) x y = x P.* y instance \nCompare Int Bool where (<=) x y = x P.<= y (==) x y = x P.== y instance SetLike Set.Set where create \ndom xs = Set.fromList [ x | x <\u00adtuples dom , elem x xs] select p xs = Set.filter p xs proj3of3 xs = Set.map \nthird xs where third(x,y,z) = z We use a Haskell-like notation to describe classes and instances. The \nuse of the notation P.x indicates the concrete un-overloaded function or value. Both classes and concrete \ninstances are abbreviated, we show only a few member functions, enough to explain the examples in Figure \n1, in the implementation there are many more member functions. Note that all solvers, no matter what \ntheir representation types, will support the same abstract interfaces. For space reasons, concrete instances \nfor Float, Double, and Rational are not shown. Figure 3. Overloading with abstract and concrete instances. \nfunctions manipulate both real data and abstract data representa\u00adtions through the magic of overloading. \nOverloading in Funlogic is similar to overloading in Haskell. Every primitive (numeric opera\u00adtors, boolean \noperators, set operations, etc.) has a standard concrete implementation and one or more overloaded abstract \nimplementa\u00adtions. One for each solver that might use that operator. Abstract implementations of operators \nmanipulate abstract representations. User written functions, through overloading, inherit multiple im\u00adplementations \nthrough a library passing mechanism. Which library is passed depends upon the context. Whether the user \nis manipulat\u00ading real data or solver representations, he uses the same functions in the same way. 3. \nInitialization. The third step in the process of maintaining an abstract view of solver problems is initialization. \nAn existentially declared variable must be translated (or initialized) into the internal representation \nof the appropriate solver. The programmer views this internal representation as if it was an ordinary \nconcrete value when he writes constraints. Ordinary functions and data, de.ned by the programmer, are \nused to manipulate it. Initialization chooses an abstract representation and constructs a view consistent \nwith the programmers view of the data. An initializer looks like a type. Depending upon the solver, this \ntype will be expanded into some abstract representation, different for each solver. 4. Staging and Resolving \nOverloading. The .fth step in the pro\u00adcess of maintaining an abstract view of solver problems is handling \nmixed concrete and abstract data in the constraints associated with existential declarations. Data is \nconcrete if it is a literal constant, or declared outside the existential declaration. Consider a constraint \nfor an SMT existential declaration.  exists x::Int, z::Int where ((x + (2 + y)) == z) Where (+) and \n(==) are overloaded, 2 is concrete, y is concrete because it is declared outside the existential, and \nx and z are abstract (existentially bound). We type check the program in the following environment. (+):: \nforall n . NumLike n => n -> n -> n (==)::foralln b. Compare nb=>n->n-> b x:: t1 -\u00ad existentially bound \nx s type is unconstrained y:: Int -\u00ad y s type is concrete z:: t2 -\u00ad existentially bound z s type is unconstrained \n Type checking infers a type for a term, and reconstructs the term where overloading is made explicit, \nand unconstrained types my become constrained by context, and concrete sub terms are made as large as \npossible. The term is reconstructed with the following type, and the types of x and z are further constrained. \n((x (+)#A (liftI#B ((liftI#C 2) (+)#D y))) (==)#E z):: t4 x:: t3; y:: Int; z:: t3 The reconstructed overloaded \noperators ((+), (==), liftI) are tagged with constraints (A, B, etc). We separate the constraints from \nthe reconstructed term to make the term easier to read. #A = (NumLike t3); #B = (NumLike t3); #C = (NumLike \nI) #D = (NumLike I); #E = (Compare t3 t4) Note that the term ((liftI#C 2) (+)#D y) is completely static, \nsince the constraints #C and #D are completely static. Note further, that some of the others are unconstrained. \nThis is because we make few assumptions about the variables x and z. In the next step, we use the solver \ncontext to remove this uncertainty. First, a where clause represents a boolean value, so the whole term \nmust have the type representing SMT s version of Bool, which is SMT. Second, the existential variables \nhave type Int and SMT s version of Int is also SMT. See Figure 4 for the details. So under the variable \nassignment {x:: SMT, y:: Int, z:: SMT } we check the reconstructed term. ((x (+)#A (liftI#B ((liftI#C \n2) (+)#D y))) (==)#E z):: SMT This completely .xes the types in each of the constraints A# = (NumLike \nSMT); B# = (NumLike SMT); C# = (NumLike I) D# = (NumLike I); E# = (Compare SMT SMT) This speci.es an \nexact function for each overloaded call. ((x :+: LitI (id 2 P.+ y)) :=: z) What we have described is \na type based binding time analysis where concrete terms are static, and abstract terms are dynamic. We \nhave used two binding time analyses, and have found them both to work well. The .rst is embedded in an \non-line partial evaluator that uses a lazy (just in time) lifting. We have also used a static (off-line) \nanalysis, based upon some previous work [17, 22], appropriate for a compiled semantics. See Appendix \nB for details of this step. 5. Constraint generation. The fourth step in the process of main\u00adtaining \nan abstract view of solver problems is constraint speci.\u00adcation. The user writes a boolean valued expression \ninvolving the existentially declared variables. His constraints may also mention any other concrete data \nin scope. This constraint is executed using the overloading associated with the particular solver, as \ndescribed above. Evaluation under the overloaded functions associated with the solver produces abstract-input \nappropriate for that solver. 6. Input formatting. While the representation type is meant to capture \nthe structure of the input to a solver, there will always be some reformatting necessary to accommodate \nthe input format of individual solvers. 7. Instantiation. Once a problem has been solved by an external \nsolver, the solution must be used to instantiate the abstract structure of existential variables into \nconcrete data.  4.1 The N-Queens problem The N-Queens problem is solved by a SMT solver. The 7-step \nprocess is illustrated in Figure 4. It uses a term representation we call SMT. This is an untyped term \nalgebra that builds data structures representing expressions over arithmetic, booleans, and comparisons. \nIts abstract instances just build larger terms from smaller terms, by using the constructor functions \nfrom SMT. The n-queens problem initializes a small vector of values, each in the range [0..1]. In the \nSMT solver, an array is initialized to a real array of abstract variables (elements of type SMT). The \ntypes of these abstract variables is taken from the initializer (the range [0..1]) and passed as input \nto the solver (see step 7). Functions that manipulate these variables will be overloaded and build SMT \ndata. To illustrate constraint generation in the queens example study one of the constraints from Figure \n1. and [add bd (rowPts i) == 1 | i <-width] Binding time analysis, lifts the constant 1, and the expression \nis evaluated in a context where the functions add, and, and (==), are bound to their abstract instances. \nAbstract variables from each row i are added and their sum is equated with 1. The effect is to build \nSMT data. Inspect the abstract initialization to see that the correct variables are indeed added. The \nSMT data is then formatted to meet the input speci.cations of the solver. 4.2 The Soduko problem The \nSoduko problem is solved by a SAT solver. The 7-step process is illustrated in Figure 5. It uses a term \nrepresentation (we call SAT) to represent the booleans, and a propositional representation we call BitVector \nto represent sets. The type (BitVector SAT t) is an abstract representation of .nite sets of elements \nof type t.A BitVector value (BV dxs) stores a list of pairs, xs. There is one pair, (t,b), in the list \nfor each possible tuple element, t, of the dimension d. The second element, b, of a pair, is an abstract \nboolean. If that abstract boolean represents True then the tuple element, t, is in the set, otherwise \nit is not. When concrete booleans are used (i.e. BitVector Bool t), a set is a concrete bit-vector (one \nbit for each possible tuple). When abstract booleans are used (i.e. BitVector SAT t), elements can be \nconditionally present in a set, depending upon the assignment of truth values to logical variables (i.e. \nvalues of the form (VarP n)) in the abstract boolean expression. In addition to operations over booleans, \nthe abstract functions create, select, proj3of3, and join, that manipulate abstract sets, are de.ned \nas instances. The missing de.nitions appear in Appendix A, along with the functions combine and mergeL, \nthat play important roles in explaining how abstract sets are manipu\u00adlated. The function call (combine \nf (x,p) pairs) .nds the pair Step 1. Problem Representation. data SMT = VarE String | LitB Bool --True \nor False | LitI Int --23 | SMT :&#38;&#38;: SMT --x &#38;&#38; y |SMT:+:SMT --x+y | SMT :==: SMT --x \n== y | SMT :<=: SMT --x <= y Step 2. Overloading. instance NumLike SMT where liftI = LitI (+)xy=x:+: \ny instance BoolLike SMT where true = LitB P.True false = LitB P.False (&#38;&#38;) = (:&#38;&#38;:) liftB \n= LitB instance Compare SMT SMT where (<=)x y= x:<=:y (==)x y= x:==:y Step 3. Initialization. Produces \nan array where each element is an SMT variable. bd : Array #(width,width) i2 1234 +-----+-----+-----+-----+ \n1| bd1 | bd2 | bd3 | bd4 | +-----+-----+-----+-----+ 2| bd5 | bd6 | bd7 | bd8 | +-----+-----+-----+-----+ \n3| bd9 | bd10| bd11| bd12| +-----+-----+-----+-----+ 4| bd13| bd14| bd15| bd16| +-----+-----+-----+-----+ \nSteps 4. Binding time analysis. --user function add m pts = sum [m.p | p <-pts] --one part (for brevity) \nof queens constraint and [add bd (rowPts i) == 1 | i <-width] ---> and [add bd (rowPts i) == liftI 1 \n| i <-width] Step 5. Constraint generation. Constraint evaluates using over\u00adloaded functions and, add, \nand (==). (and (= (+ bd1 (+ bd2 (+ bd3 bd4))) 1) (= (+ bd5 (+ bd6 (+ bd7 bd8))) 1) (= (+ bd9 (+ bd10 \n(+ bd11 bd12))) 1) (= (+ bd13 (+ bd14 (+ bd15 bd16))) 1))  Step 6. Input formatting leads to SMT input \n.le (define bd1::(subtype (x::int) (or (= x 0) (= x 1)))) (define bd2::(subtype (x::int) (or (= x 0) \n(= x 1)))) ... (assert (and (= (+ bd1 (+ bd2 (+ bd3 bd4))) 1) (= (+ bd5 (+ bd6 (+ bd7 bd8))) 1) ... Figure \n4. N-Queens problem pipeline.  Step 1. Problem Representation. data SAT = VarP Int | FalseP | TruthP \n| AndP SAT SAT data BitVector b a = BV (Domain a) [(a,b)] Step 2. Overloading. See Appendix A for full \nde.nitions. instance BoolLike SAT where true = TruthP false = FalseP (&#38;&#38;) = AndP liftB True = \nTruthP liftB False = FalseP instance BoolLike b => SetLike (BitVector b) where create d xs = ... select \np (BV d xs) = BV d [(x, liftB (p x)) | (x,b) <-xs] proj3of3 (BV (D3 _ _ d) xs) = ... join (BV (D2 a b) \nxs) (BV (D2 _ c) ys) = ... Step 3. Initialization. Produces BitVector SAT (Int,Int,Int) grid: set #(size,size,digit) \ninput .. full [(0,0,1)=p1 (0,0,2)=p2 (0,0,3)=p3 (0,0,4)=p4 (0,1,1)=p5 (0,1,2)=p6 (0,1,3)=p7 (0,1,4)=p8 \n(0,2,1)=p9 (0,2,2)=p10 (0,2,3)=p11 (0,2,4)=p12 (0,3,1)=p13 (0,3,2)=p14 (0,3,3)=p15 (0,3,4)=T (1,0,1)=p16 \n(1,0,2)=p17 (1,0,3)=p18 (1,0,4)=p19 (1,1,1)=p20 (1,1,2)=T (1,1,3)=p21 (1,1,4)=p22 (1,2,1)=T (1,2,2)=p23 \n(1,2,3)=p24 (1,2,4)=p25 (1,3,1)=p26 (1,3,2)=p27 (1,3,3)=p28 (1,3,4)=p29 (2,0,1)=p30 (2,0,2)=p31 (2,0,3)=p32 \n(2,0,4)=p33 (2,1,1)=T (2,1,2)=p34 (2,1,3)=p35 (2,1,4)=p36 (2,2,1)=p37 (2,2,2)=p38 (2,2,3)=p39 (2,2,4)=T \n(2,3,1)=p40 (2,3,2)=p41 (2,3,3)=p42 (2,3,4)=p43 (3,0,1)=p44 (3,0,2)=p45 (3,0,3)=p46 (3,0,4)=p47 (3,1,1)=p48 \n(3,1,2)=p49 (3,1,3)=p50 (3,1,4)=p51 (3,2,1)=p52 (3,2,2)=p53 (3,2,3)=p54 (3,2,4)=p55 (3,3,1)=T (3,3,2)=p56 \n(3,3,3)=p57 (3,3,4)=p58] Steps 4. Binding time analysis and alternate syntax expansion produces constraint. \nfull {k <-grid(3,j,k)} --> full (proj3of3 (select (\\ (i,j,k)->i==3) grid)) Step 5. Constraint generation. \nConstraint evaluates using over\u00adloaded functions, full, proj3of3, and select. (p45 \\/ p49 \\/ p53 \\/ p56) \n/\\ (p46 \\/ p50 \\/ p54 \\/ p57) /\\ (p47 \\/ p51 \\/ p55 \\/ p58) Step 6. Input formatting leads to .cnf .le \np cnf 58 3 45495356 0 46505457 0 47515558 0 Figure 5. Soduko problem pipeline. (x,q) in pairs (if any) \nand replaces its abstract boolean q with (f pq). This can be used to effectively insert or delete elements \nde\u00adpending upon the values of p and f, for example (combine (||) (x,True) xs) adds x and (combine (&#38;&#38;) \n(x,False) xs) re\u00admoves x. The function mergeL iterates combine. The Soduko problem initializes a .nite \nset. An initializer for a .nite set has the form: Set #(d1,d2) s1 .. s2. It includes a pair of concrete \nsets, s1 and s2. The set s1 must be a subset of the set s2 and both must have the same dimensions as \nthe set being initialized. Like all abstract sets, the initialized set consists of a list of pairs. The \nintuition for initialization can be seen in the picture below  Tuples in s1 have their BoolLike values \nset to True, they are de.nitely in the set. Tuples not in s2 have their BoolLike values set to False, \nthey are de.nitely not in the set. The others are assigned a boolean valued propositional variable. Different \nassignments of True or False to the propositional variables will change what is in the set. Note that \nthe tuples given as input to the Soduko puzzle ((0,3,4), (1,1,2), (1,2,1), (2,1,1), (2,2,4), and (3,3,1)) \nall have their BoolLike value set to True, and all the others are as\u00adsigned a propositional variable. \nThis is because the set s2 is the full set of tuples (the universe). It is not unusual for an initializer \nto be: Set #(d1,d2) none .. universe, which is completely uncon\u00adstrained (i.e. every tuple is assigned \na propositional variable). But, choosing appropriate bounds can dramatically decrease the size of the \nproblem sent to the solver, and thus effect its ef.ciency. Other initializers (not shown) allow users \nto describe symmetries[5, 23], which also can make the search process more ef.cient. In the Soduko example, \none part of the constraint is: full {k <-grid(3,j,k)}. The alternate notation expands to a term involving \nthe overloaded functions full, proj3of3 and select. No binding time annotations are needed. This compares \na one column projection to the full set {1,2,3,4}. The term is evaluated in an overloaded context to \nget a SAT term. To see how the answer arises, consider its .rst conjunct (p45 \\/ p49 \\/ p53 \\/ p56).A \n2 is in the set if and only if this conditions holds. The only tuples in row 3 with a 2 in the k position \nare: (3,0,2)=p45 (3,1,2)=p49 (3,2,2)=p53 (3,3,2)=p56. So, one of the variables p45, p49, p53, or p56 \nmust be true. In a similar fashion, the second and third conjuncts assure 3 and 4 are also in the set \n(work it out for yourself). What about 1? Why no conjunct for 1? Because the tuple (3,3,1)=T is already \n.xed by the input, so 1 will always in the set {k <-grid(3,j,k)}. This representation is then formatted \ninto a standard .cnf .le and passed to the sat solver. 4.3 The Production problem The Production problem \nis solved by a Linear Programming solver. The 7-step process is illustrated in Figure 6. It uses a struc\u00adtural \nrepresentation (we call Mexp, for Mathematical program\u00adming) to represent polynomials over several variables. \nFor ex\u00adample: 3x+ 2y+1. Operations, like (+), combine polynomi\u00adals. For example: (3x +2y +1)+(2x+ 2z+3) \nresults in (5x +2y+2z+4). Step 1. Problem Representation. type PolyNom n = [(String,n)] data MExp n \n= Term (PolyNom n) n data Rel n --true false = RANGE (PolyNom n) (Range n) | TAUT | UNSAT Step 2. Overloading. \nSee Appendix A for full de.nitions. instance NumLike (MExp Int) where liftI n= Term []n (+) (Term [] \na) (Term [] b) = ... instance BoolLike [Rel Int] where liftB True = [TAUT] (&#38;&#38;) xs ys = ... instance \nCompare (MExp Int) [Rel Int] where (<=) (Term [] a) (Term [] b) = ... Step 3. Initialization. Array .lled \nwith unit polynomials. prod: Array #(Factory,Store) Int NYC ATL LA +---------+---------+---------+ A| \n(1a + 0)| (1b + 0)| (1c + 0)| +---------+---------+---------+ B| (1d + 0)| (1e + 0)| (1f + 0)| +---------+---------+---------+ \nC| (1g + 0)| (1h + 0)| (1i + 0)| +---------+---------+---------+ : Array (Factory,Store) (MExp Int) Steps \n4. Binding time analysis. Constraint is annotated. and [ sales.s == sum [prod.(f,s) | f <-Factory] | \ns <-Store ] --> and [liftI(sales.s)==sum[prod.(f,s) | f<-Factory] | s <-Store ] Step 5. Constraint generation. \nConstraint evaluates using over\u00adloaded functions. Transformed to coef.cient matrix. 230 <=(1a+1d+1g)<=230 \n140 <=(1b+1e+1h)<=140 300 <=(1c+1f+1i)<=300 abcdefghi +----+--+-+-+-+-+-+-+-+-+-+---+---+ |230 |<=|1|0|0|1|0|0|1|0|0|<= \n|230| +----+--+-+-+-+-+-+-+-+-+-+---+---+ |140 |<=|0|1|0|0|1|0|0|1|0|<= |140| +----+--+-+-+-+-+-+-+-+-+-+---+---+ \n|300 |<=|0|0|1|0|0|1|0|0|1|<= |300| +----+--+-+-+-+-+-+-+-+-+-+---+---+ Step 6. Input formatting leads \nto .mps .le NAME prod ROWS N COST E R1 E R2 E R3 COLUMNS a COST 2 a R1 1 ... ENDATA Figure 6. Production \nProblem pipeline. The type [Rel n] represents a boolean term. An element of such a list is a ternary \nrelation, bounding a polynomial from above and below. For example: -8 <=(3x+ 2y) <=-3. Comparisons build \nthese relations. E.g. a constant comparison (3x +2y+1)<= 7, produces: -8 <=(3x+ 2y) <=6. More complex, \ncomparing two polynomials (3x+2y+5)<= (y+5z+2) becomes -8 <= (3x +y -5z)<= -3 Using this representation \nof terms, an abstract boolean is a list of ternary relations. To overload the operator (&#38;&#38;), \nthe two sets are unioned, by combining elements with a common polynomial, by squeezing the lower and \nupper bounds. {-8 <= (3x) <= 6} &#38;&#38; { 4 <= (3x) <= 9} becomes { 4 <= (3x) <= 6 } The full de.nitions \nfor the overloaded operations in the abstract instance step are found in Appendix A. The production problem, \nlike the Soduko problem, initializes to a real array storing abstract data. Here each array cell holds \na unit polynomial over a different variable. A unit polynomial has only one variable (with a coef.cient \nof 1) and an additive constant of 0. In the production problem, we illustrate constraint generation using \nthe last of the three constraints. Binding time analysis recog\u00adnizes that the sub term sales.s is completely \nstatic (it will reduce to a constant, like 230) so it is annotated with liftI. Each of the sums leads \nto a bounded polynomial. From these bounded polynomials an array of coef.cients is constructed. Note \nthat for each polynomial, only some of the coef.cients are set to 1, these correspond to the entries \nin prod for the same store (i.e. the same column in the abstract array). The array of coef.cients is \nformatted as a standard .mps .le. 5. Possible extensions Additional solvers. The .rst and most natural \nextension is to .nd and incorporate additional solvers. The linear-programming solver framework can be \ngeneralized to solve problems over real or rational numbers, or to allow non-linear constraints. We are \nlooking for suggestions for new kinds of solvers. Allowing programmers to add solvers. A more useful \nexten\u00adsion would be to add language features that allow programmers to add their own solvers. Currently \nthe Funlogic compiler must be hacked to add a new solver. The design principles specify the steps necessary. \nTo allow programmers to add solvers, each step would have to be internalized. Currently the language \nis a simple call by value language. Users write no type information at all, and every term is given, \nwhat appears to be a simple Hindley-Milner type. In reality, 2-stage overloaded types are actually used. \nTo inter\u00adnalize the 7 steps the language would have to be much more sophis\u00adticated. It would need overloading \nand classes, staging annotations, and more. All this would have to accessible to the programmer. While \nI believe this is possible. I have not built it, yet. What should we search for? New solvers expand the \ndesign principles to accommodate new ideas. The linear programming solver is a case in point. The other \nsolvers can return any solution that meets the constraints. The LP solver must .nd a solution that maximizes \nthe objective function. When we .rst embedded the LP solver we had to generalize the notion of what we \nwere solving for. This led us to add the find clause to an existential declaration. Now one can find \nthe First (SAT,SMT,Narrowing), or the Max or Min (LP) solution. This led us to think about other possible \nways of describing what we should search for. We have currently added two other find modes: Many and \nAbstract. We envision these being used as design exploration tools by the programmer. They help the programmer \ndesign his program by exploring the design space of possible constraints. The Abstract mode allows the \nuser to visualize the results of initialization. Rather than generate and .nd a solution that meets the \nconstraint. It prints out the constraint and binds the existentially quanti.ed variables to their initializations. \nThis lets the program\u00admer use the read-eval-print loop to visualize the results of potential constraints \n(much the way we did in Figures 4, 5, and 6, which were in fact created using the Abstract mode). The \n(Many x) mode solves the constraint, and then instantiates and prints out x under the solution. It then \npauses and goes into an interactive loop that allows the programmer to type in addi\u00adtional constraints. \nThese constraints are then added to the original ones and the process is repeated. This allows the programmer \nto incrementally develop what constraints are necessary. Over or un\u00adder constraining problem speci.cations \nis common, and using this mechanism allows exploration of the possibilities. Other possibili\u00adties of \ndesign exploration include Populating large constrained data structures. Given a data structure and \na bunch of constraints one can explore questions like: Is there a value which meets all the constraints? \nWhat does a value look like? What if I add an additional constraint?  Model Checking. Given a data structure \nand a bunch of con\u00adstraints is it true that every solution (or model) has additional properties.  Test \ngeneration. Find some input data that forces a computa\u00adtion to go down a certain path for testing purposes. \n  The existential declaration allows programmers to explore these design parameters from within the \nlanguage. No need for an exter\u00adnal tool or analysis. 6. Related work Funlogic embeds multiple solvers \nin a general purpose language. This combination is rare. Several systems, self described as mod\u00adelling \nlanguages, such as AMPL [8] and GAMS, support multiple solvers. But, they are not programming languages, \njust a conve\u00adnient notation to write down the math that describes a problem. The solvers they support \nall concern minimizing or maximizing an objective under various kinds of constraints. I know of two systems \nthat embed solvers in database languages, based upon Datalog, by using the notion of plugin [14, 19]. \nBut neither provides strong scripting capability. Recently, Kuncak et al.[16] introduced the idea of \na software synthesis procedure, where code is synthesized at compile time by the use of a decision procedure. \nThe synthesized code, when exe\u00adcuted at runtime, will provide values for existentially de.ned vari\u00adables. \nThey introduce the notion of a formula, a syntactic subset of boolean valued terms, for which the decision \nprocedure knows how to synthesize code. In this paper we demonstrate how over\u00adloading can both replace \nthe syntactic restriction with constrained types, and broaden the class of decision procedures applicable. \nIn more recent work[15] they have strengthened their decision proce\u00addures by extending them with a notion \nof symbolic evaluation of user de.ned functions. While Funlogic is a unique collection of ideas, I would \nbe remiss if I did not acknowledge many .ne papers which strongly in.uenced my thinking in its design. \nThe work of Daniel Jackson[11, 29] and his student Emina Torlak[28] .rst opened my eyes to the fact that \nnon-trivial speci\u00ad.cations (all of relational algebra) could be expressed in .rst order logic. The thesis \nby Toni Mancini[18], strongly reinforced this fact. The Curry language[9], developed by Michael Hanus \nand Ser\u00adgio Antoy was also in.uential. The recent paper[4] A New Com\u00adpiler from Curry to Haskell, explained \nto me exactly how Curry .ts within the design principles developed in this work (though I didn t realize \nit at the time I .rst implemented a narrowing solver). I .rst encountered the use of overloading to generate \nconstraints in the paper Logical Abstractions in Haskell[7] by Nancy A. Day, John Launchbury, and Jeff \nLewis. It took a while for me to real\u00adize that this could be generalized from boolean constraints to \ncon\u00adstraints over other domains, such as numeric domains, or even alge\u00adbraic data structures. My knowledge \nof how to type and implement overloading comes mainly from the .ne paper Typing Haskell in Haskell[13] \nby Mark Jones. One key element necessary to use overloading as a constraint generation mechanism is effective \ninitialization of existentially in\u00adtroduced variables. Good initialization abstracts over aggregates \n(allowing the user to declare one array, rather than many individ\u00adual variables), and chooses good representations \nthat minimize the problems to be solved. My approach to initialization was strongly in.uenced by the \nsmall check system[21] (which uses a type-based system to generate all small values of a given type) \n, and by con\u00adversations with Emina Torlak. Emina taught me the bounding trick for .nite set initialization, \nand the importance of using symmetry in initialization. Binding time analysis was the last piece of the \npuzzle. Experi\u00adence with MetaML[26, 27] made it possible to recognize a binding time problem when I saw \none. The two binding analyses I have ex\u00adperimented with include an interpreted approach based upon nor\u00admalization \nby evaluation[1, 6], and an approach based on some work by a former student, Nathan Linger[22], which \nis outlined in Appendix B. Interesting enough, a third approach[17], outlined by Linger, performs the \nanalysis, not by abstract interpretation, but by reducing the problem to a boolean SMT problem. So we \nhave come full circle. 7. Performance I built the system as a proof of concept, not to optimize perfor\u00admance. \nThere are lots of possibilities. Here are a few baseline tim\u00adings for the programs in the paper: 4 queens \na few hundredths of a second; 8 queens in a second; 10 queens time out (the limit is 60 seconds). Rank \n2 Soduko in a few hundredths of a second; Rank 3 Soduko (the normal 9x9) in about 3 seconds; Rank 4 Soduko \ntimes out. But, by changing the initializer for SAT, and swapping in a specialized formula to CNF pass, \na student solved rank 7 (49x49) puzzles. Using specialized representations makes a difference, and giving \nusers programmers access to these is important. We leave this to future work 8. Conclusion The existential \ndeclaration is an expressive abstraction, bridging the functional and logic worlds, for many different \nkinds of problems, solvable by a wide variety of decision procedures. Implementing existential declarations \nover a wide variety of domains requires embedding multiple decision procedures. Fortunately, the steps \nin\u00advolved can be can be precisely described. Overloading and staging are the key ingrediants to giving \nprecise semantics to the embed\u00adding process. Acknowledgments There are many people who helped me in my \nresearch. First I would like to thank Molham Aref and Emir Pasalic who got me started thinking about \nother ways to think about declarative pro\u00adgramming, and LogicBlox (a great place to work in Atlanta Ga.) \n which partially supported this research. I would also like to thank Jim Hook (my co-teacher) and all \nthe class members of the Win\u00adter 2011 class Mathematical Logic via Foundational Algorithms at PSU that \nhelped re.ne my thinking about how to combine logic and functional programming. This work was also supported \nin part by NSF grant 0910500. References [1] V. Balat and O. Danvy. Strong normalization by type-directed \npartial evaluation and run-time code generation. Lecture Notes in Computer Science, 1473:240 252, 1998. \nISSN 0302-9743. [2] C. Barrett, M. Deters, A. Oliveras, and A. Stump. Design and results of the 3rd annual \nsatis.ability modulo theories competition (SMT-comp 2007). International Journal on Arti.cial Intelligence \nTools, 17(4): 569 606, 2008. [3] G. M. Bierman, A. D. Gordon, C. Hritc, and D. Langwor\u00adthy. Semantic \nSubtyping with an SMT Solver. TechRe\u00adport MSR-TR-2010-99, Microsoft Research, Dec. 2010. URL http://research.microsoft.com/en-us/projects/dminor/. \n[4] B. Bra\u00dfel, M. Hanus, B. Peem\u00a8oller, and F. Reck. KiCS2: A new compiler from curry to haskell. In \nH. Kuchen, edi\u00adtor, WFLP, volume 6816 of Lecture Notes in Computer Science, pages 1 18. Springer, 2011. \nISBN 978-3-642-22530-7. URL http://dx.doi.org/10.1007/978-3-642-22531-4. [5] J. M. Crawford, M. L. Ginsberg, \nE. M. Luks, and A. Roy. Symmetry\u00adbreaking predicates for search problems. In KR, pages 148 159, 1996. \n[6] O. Danvy, M. Rhiger, and K. H. Rose. Normalization by evaluation with typed abstract syntax. J. Funct. \nProgram, 11(6):673 680, 2001. [7] N. A. Day, J. Launchbury, and J. Lewis. Logical abstractions in haskell. \nIn Proceedings of the 1999 Haskell Workshop. Utrecht Uni\u00adversity Department of Computer Science, Technical \nReport UU-CS\u00ad1999-28, October 1999. [8] R. Fourer, D. M. Gay, and B. W. Kernighan. AMPL A Modeling Language \nfor Mathematical Programming. The Scienti.c Press, South San Francisco, 1993. [9] M. Hanus. Report on \nCurry (ver.0.8.2). Inst. fur Informatik, Christian-Albrechts Universitat, .de, 2006. [10] M. Hermenegildo \nand T. CLIP Group. An Automatic Documentation Generator for (C)LP Reference Manual. The Ciao System \nDocumen\u00adtation Series TR CLIP5/97.3, Facultad de Inform\u00b4atica, UPM, Aug. 1997. URL http://clip.dia.fi.upm.es/Software/Ciao/. \nOnline at http://clip.dia.fi.upm.es/Software/Ciao/. [11] D. Jackson. An intermediate design language \nand its analysis. In Proceedings of the ACM SIGSOFT 6th International Symposium on the Foundations of \nSoftware Engineering (FSE-98), volume 23, 6 of Software Engineering Notes, pages 121 130, New York, Nov. \n3 5 1998. ACM Press. [12] D. Jackson. Software Abstractions: Logic, Language, and Analysis. The MIT \nPress, Cambridge, Mass., 2006. [13] M. P. Jones. Typing Haskell in Haskell. In ACM Haskell Workshop , \ninformal proceedings, Oct. 1999. [14] D. Klabjan, R. Fourer, and J. Ma. Algebraic modeling in a deductive \ndatabase language. In 11th INFORMS Computing Society Conference, 2009. [15] A. S. Koksal, V. Kuncak, \nand P. Suter. Constraints as control. In POPL 12, Proceedings of the 39th annual ACM SIGPLAN-SIGACT symposium \non Principles of programming languages, pages 151 164. ACM, 2012. [16] V. Kuncak, M. Mayer, R. Piskac, \nand P. Suter. Software syn\u00adthesis procedures. Communications of the ACM, 55(2):103 111, Feb. 2012. ISSN \n0001-0782 (print), 1557-7317 (electronic). doi: http://dx.doi.org/10.1145/2076450.2076472. [17] N. Linger \nand T. Sheard. Binding-time analysis for metaML via type inference and constraint solving. In K. Jensen \nand A. Podelski, editors, TACAS, volume 2988 of Lecture Notes in Computer Science, pages 266 279. Springer, \n2004. ISBN 3-540-21299-X. [18] T. Mancini. Declarative constraint modelling and speci.cation-level reasoning. \nDiploma thesis, Universita degli Studi di Roma La Sapienza , 2004. [19] D. Z. Molham Aref and E. Pasalic. \nUsing optimization services in datalog. In 11th INFORMS Computing Society Conference, 2009. [20] M. Novak, \nG. Gardarin, and P. Valduriez. Flora: A functional-style language for object and relational algebra. \nLecture Notes in Computer Science, 856:37 46, 1994. ISSN 0302-9743. [21] C. Runciman, M. Naylor, and \nF. Lindblad. SmallCheck and Lazy SmallCheck: automatic exhaustive testing for small values. ACM SIGPLAN \nNotices, 44(2):37 48, Feb. 2009. ISSN 0362\u00ad1340 (print), 1523-2867 (print), 1558-1160 (electronic). doi: \nhttp://doi.acm.org/10.1145/1543134.1411292. [22] T. Sheard and N. Linger. Search-based binding time analysis \nusing type-directed pruning. In ASIA-PEPM, pages 20 31, 2002. URL http://doi.acm.org/10.1145/568173.568176. \n[23] I. Shlyakhter. Generating effective symmetry-breaking predicates for search problems. Discrete Applied \nMathematics, 155(12):1539 1548, 2007. URL http://dx.doi.org/10.1016/j.dam.2005.10.018. [24] G. Smolka. \nThe de.nition of kernel oz. Technical report, Saarl\u00a8ats-und Landesbibliothek; Sonstige Einrich\u00ad andische \nUniversit\u00a8tungen. DFKI Deutsches Forschungszentrum f\u00a8ur K\u00a8unstliche Intelli\u00adgenz, 1994. URL urn:nbn:de:bsz:291-scidok-37290. \n [25] G. Sutcliffe and C. B. Suttner. The CADE ATP system competition. In D. A. Basin and M. Rusinowitch, \neditors, IJCAR, volume 3097 of Lecture Notes in Computer Science, pages 490 491. Springer, 2004. ISBN \n3-540-22345-2. [26] Taha and Sheard. MetaML and multi-stage programming with explicit annotations. TCS: \nTheoretical Computer Science, 248, 2000. [27] W. Taha and T. Sheard. MetaML and multi\u00adstage programming \nwith, Feb. 09 1999. URL http://citeseer.ist.psu.edu/516106.html; http://cse.ogi.edu/ walidt/paper-2.ps. \n [28] E. Torlak and D. Jackson. Kodkod: A relational model .nder. In O. Grumberg and M. Huth, editors, \nTACAS, volume 4424 of Lecture Notes in Computer Science, pages 632 647. Springer, 2007. ISBN 978-3-540-71208-4. \n [29] E. Torlak, A. Prof, and D. Jackson. Thesis: A constraint solver for software engineering: Finding \nmodels and cores of large relational speci.cations., Dec. 04 2008. URL http://stuff.mit.edu/people/emina/papers/etorlak-cv.pdf. \nA. MP abstract instance functions In this appendix are the missing functions for the abstract instance \ndeclarations in Figures 5 and 6. mergePf[]ys= ys mergePfxs[]= xs mergeP f ((x,n):xs)((y,m):ys)= case \ncompare x y of EQ->case(fnm) of 0 -> mergeP f xs ys i -> (x,i):mergeP f xs ys LT -> (x,n): mergeP f \nxs ((y,m):ys) GT -> (y,m): mergeP f ((x,n):xs) ys  combine oper(t,b)[] = [] combine oper(t,m)((s,n):xs)| \nt==s = (t,oper m n): xs combine oper(t,m)((s,n):xs)=(s,n):combine oper(t,m)xs mergeL oper [] ys = ys \nmergeL oper ((z,m):xs) ys = mergeL oper xs (combine oper (z,m) ys) instance NumLike (MExp Int) where \nliftIn =Term []n (+) (Term [] a) (Term [] b) = Term [] (a+b) (+) (Term [] a) (Term ys b) = Term ys (a+b) \n(+) (Term xs a) (Term [] b) = Term xs (a+b) (+) (Term xs a) (Term ys b) = Term (mergeP (+) xs ys) (a+b) \n instance Compare (MExp Int) [Rel Int] where (<=) (Term [] a) (Term [] b) = if (a <= b) then [TAUT] else \n[UNSAT] (<=) (Term [] a) (Term xs b) = [RANGE xs (Range (LtEQ(a-b)) PlusInf)] (<=) (Term xs a) (Term \n[] b) = [RANGE xs (Range MinusInf (LtEQ (b-a)))] (<=) (Term xs a) (Term ys b) = [RANGE (mergeP (+) xs \n(negPoly ys)) (Range MinusInf (LtEQ (b-a)))] instance BoolLike [Rel Int] where liftB True = [TAUT] liftB \nFalse =[UNSAT] true = [TAUT] false = [UNSAT] (&#38;&#38;) xs ys = help (sort xs) (sort ys) where help \n(UNSAT:_) ys = [UNSAT] help xs (UNSAT:_) = [UNSAT] help (TAUT: xs) ys = help xs ys help xs (TAUT: ys) \n= help xs ys help [] ys = ys help xs [] = xs help (RANGE x a:xs) (RANGE y b:ys) | x P.== y = RANGE x \n(intersectRange a b): help xs ys help (RANGE x a:xs)(ys@(RANGE y b:_)) |x<y = RANGE x a:(help xs ys) \nhelp (xs@(RANGE x a:_))(RANGE y b:ys) |x>y = RANGE y b:(help xs ys) instance BoolLike b => SetLike (BitVector \nb) where create d xs = BV d [(t,liftB(elem t xs)) | t <-tuples d] select p (BV d xs) = BV d [(x, liftB \n(p x)) | (x,b) <-xs] proj3of3 (BV (D3 _ _ d) xs) = BV (D1 d) (mergeL (||) [(z,b) | ((x,y,z),b) <-xs] \n[(x,false) | x <-d]) join (BV (D2 a b) xs)(BV (D2 _ c) ys)= BV d3 ans whered3 =D3a bc ans = mergeL (||) \n[ ((a,b,c),p&#38;&#38;q) | ((a,b),p) <-xs , ((x,c),q) <-ys ,x P.==a ] [(t,false)| t <-tuples d3] B. \nStaging type inference In this section we provide further details of the staging type\u00adinference process \ndiscussed in Paragraph 4 of Section 4. Lets start with a description of syntax. I keep everything very \nsimple here. The real language has more, but this simple version extends natu\u00adrally. constants: i ::= \n{..., -1,0 +1, ...} b ::= {True,False} class library: A ::= NumLike t | BoolLike t | Compare t t | SetLike \nt types: T,t::=Int|Bool|t->t|x schemes: S ::= forall xs . A => T terms: E,f,e::= v|fe|i|v#A|b Each class \nlibrary has a number of overloaded methods. See Figure 3 for details. In the staging type-inference process, \nwe will need to compute a type from an overloaded operator and a class library. libType:: v -> A -> T \nlibType (+) (NumLike t) = t -> (t -> t) libType liftI (NumLike t) = Int -> t libType (==) (Compare t \nb) = t -> (t -> t) instan (forall xs . A => T) = (A[ts/xs],T[ts/xs]) Where the ts in instan are fresh \ntype variables. The staging type-inference process is a syntax directed walk over a term in the presence \nof an environment, s:: v -> S, that maps variable names to schemes. The judgment s |-E --> (E ,T) means, \nunder s the term E has type T, and reconstructs to E . The process is strongly reminiscent of type inference \nin the presence of class constraints[13] and search based binding time analysis[22]. -----------------------------------------LIB \ns |-x#A --> (X,libType x A) fresh t -----------------------------------------INT s |-i --> (liftI#(NumLike \nt) i, t) fresh t -----------------------------------------BOOL s |-b --> (liftB#(BoolLike t) b, t) \ninstan(s v) --> (C,t) -----------------------------------------VAR s |-v --> (v#C v,t) fresh w unify \ndom xt s |-x --> (x ,xt) s |-f --> (f ,d -> r) t = (f x ) -----------------------------------------APP \ns|-f x-->(castxtd r) where cast I d r = (liftI#(NumLike w) t,w) cast B d r = (liftB#(BoolLike w) t,w) \ncastn dr=(f x ,r) Three points are worth making. First, in the rules INT and BOOL every constant is \nlifted to an overloaded type. Second, in the rule VAR every overloaded variable is instantiated and lifted \nto a fresh type. Third, in the rule APP if an argument of an application has a concrete type (I for Int \nand B for Bool), then the reconstructed call is lifted to a fresh type.  \n\t\t\t", "proc_id": "2364527", "abstract": "<p>We describe the Funlogic system which extends a functional language with existentially quantified declarations. An existential declaration introduces a variable and a set of constraints that its value should meet. Existential variables are bound to conforming values by a decision procedure. Funlogic embeds multiple external decision procedures using a common framework. Design principles for embedding decision procedures are developed and illustrated for three different decision procedures from widely varying domains.</p>", "authors": [{"name": "Timothy E. Sheard", "author_profile_id": "81548019091", "affiliation": "Portland State University, Portland, OR, USA", "person_id": "P3804313", "email_address": "sheard@cs.pdx.edu", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364542", "year": "2012", "article_id": "2364542", "conference": "ICFP", "title": "Painless programming combining reduction and search: design principles for embedding decision procedures in high-level languages", "url": "http://dl.acm.org/citation.cfm?id=2364542"}