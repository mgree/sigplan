{"article_publication_date": "09-09-2012", "fulltext": "\n Equality Proofs and Deferred Type Errors A Compiler Pearl Dimitrios Vytiniotis Simon Peyton Jones Microsoft \nResearch, Cambridge {dimitris,simonpj}@microsoft.com Abstract The Glasgow Haskell Compiler is an optimizing \ncompiler that ex\u00adpresses and manipulates .rst-class equality proofs in its intermedi\u00adate language. We \ndescribe a simple, elegant technique that exploits these equality proofs to support deferred type errors. \nThe technique requires us to treat equality proofs as possibly-divergent terms; we show how to do so \nwithout losing either soundness or the zero\u00adoverhead cost model that the programmer expects. Jos\u00b4e Pedro \nMagalh aes Utrecht University jpm@cs.uu.nl completely (and statically) erased, so that they induce no \nruntime execution or allocation overhead. Proof assistants and dependently typed languages (Bove et al. \n2009; Norell 2007; The Coq Team) adopt a similar design with statically erasable proofs, including ones \nthat go beyond equality to more complex program properties. However, there is one important dif\u00adference: \nin proof assistants the proof language is the computation language, always a side-effect free and terminating \nlanguage that guarantees logical consistency of the proofs. On the other hand, . . C the computation \nlanguage includes partial functions and Features]: Abstract data types; F.3.3 [Studies of Program and \ndivergent terms. To ensure logical consistency, FC keeps the Categories and Subject Descriptors D.3.3 \n[Language Constructs in System F Constructs]: Type structure equality proof language as a syntactically \nseparate, consistent-by\u00adconstruction set of equality proof combinators. General Terms Design, Languages \nKeywords Type equalities, Deferred type errors, System FC 1. Introduction In a compiler, a typed intermediate \nlanguage provides a .rm place to stand, free from the design trade-offs of a complex source lan\u00adguage. \nMoreover, type-checking the intermediate language pro\u00advides a simple and powerful consistency check on \nthe earlier stages of type inference and other optimizing program transformations. The Glasgow Haskell \nCompiler (GHC) has just such an interme\u00addiate language. This intermediate language has evolved in the \nlast few years from System F to System FC (Sulzmann et al. 2007; Weirich et al. 2011) to accommodate \nthe source-language features of GADTs (Cheney and Hinze 2003; Peyton Jones et al. 2006; Sheard and Pasalic \n2004) and type families (Chakravarty et al. In this paper we investigate the opportunities and challenges \nof blurring the rigid proof/computation boundary, without threatening soundness, by allowing proof-like \n.rst-class values to be returned from ordinary (even divergent or partial) computation terms. We make \nthe following contributions: The proofs-as-values approach opens up an entirely new pos\u00adsibility, that \nof deferring type errors to runtime. A common objection to static type systems is that the programmer \nwants to be able to run a program even though it may contain some type errors; after all, the execution \nmight not encounter the er\u00adror. Recent related work (Bayne et al. 2011) makes a convinc\u00ad ing case that \nduring prototyping or software evolution program\u00admers wish to focus on getting part of their code right, \nwithout .rst having to get all of it type-correct. Deferring type errors seems to be just the right mechanism \nto achieve this. Our new approach gives a principled way in which such erroneous pro\u00ad . 2005; Kiselyov \net al. 2010); and from System FC to System Fgrams can be run with complete type safety (Sections 3 and \n5). C, a . calculus now fully equipped with kind polymorphism and datatype promotion (Yorgey et al. \n2012). The key to the almost effortless shift to proofs-as-values is C, with the recent addi\u00ad based \non a simple observation: System F . The principal difference between System F and System FC is that, \ntion of kind polymorphism (Yorgey et al. 2012), already allows us to de.ne within the system an ordinary \n.rst-class type for type equality (Section 4). As such, we can have ordinary val\u00ad  . C carries equality \nproofs: evidence that type equality constraints are satis.ed. Such proofs together with type information, \nSystem F are generated during the type inference process and are useful for . type checking System FC \nprograms. However, once type checking . of the FC program is done, proofs very much like types can \nbe ues of that type, that are passed to or returned from arbitrary (even partial or divergent) terms. \nMoreover, deferring type er\u00adrors aside, there are other compelling advantages of proofs-as\u00ad values in \nan evidence-passing compiler, as we outline in Sec\u00ad tion 6. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 12, September 9 15, 2012, Copenhagen, \nDenmark. Copyright &#38;#169; 2012 ACM 978-1-4503-1054-3/12/09. . . $15.00 Most functional programmers \nthink of types as static objects, with zero run-time overhead, and they expect the same of proofs about \ntypes. Treating type equality proofs as values seriously undermines this expectation. In Section 7 we \naddress this chal\u00ad lenge and show how the optimizer of GHC, with no changes whatsoever, can already eliminate \nthe cost of equality proofs except in corner cases where it would be wrong to do so.  Everything we \ndescribe is fully implemented. As far as we know, GHC is the .rst, and only, widely-used optimizing compiler \nthat manipulates .rst-class proofs. We describe this paper as a pearl because it shows a simple and elegant \nway in which the apparently\u00adesoteric notion of a proof object can be deployed to solve a very practical \nproblem. 2. The opportunity: deferring type errors Suppose you type this Haskell term into the interactive \nread-eval\u00adprint prompt in GHCi: ghci> fst (True, a &#38;&#38; False) This term does not go wrong when \nevaluated: you might expect to just get back the result True from projecting the .rst component of the \npair. But in a statically typed language like Haskell you get the type error: Couldn t match Bool with \nChar In the first argument of (&#38;&#38;) , namely a This behaviour is .ne for programs that are (allegedly) \n.nished, but some programmers would much prefer the term to evaluate to True when doing exploratory programming. \nAfter all, if the error is in a bit of the program that is not executed, it is doing no harm! In particular, \nwhen refactoring a large program it is often useful to be able to run parts of the completed program, \nbut type errors prevent that. What we want is to defer type errors until they matter. We have more to \nsay about motivation and related work in Section 8. As we shall see, System F. C allows us to offer precisely \nthis be\u00adhaviour, without giving up type safety. Here is an interactive session with ghci -fdefer-type-errors: \nghci> let foo = (True, a &#38;&#38; False) Warning: Couldn t match Bool with Char ghci> :type foo (Bool, \nBool) ghci> fst foo True ghci> snd foo Runtime error: Couldn t match Bool with Char Notice that: The \nde.nition of foo produced a warning (rather than an error), but succeeds in producing an executable binding \nfor foo.  Since type checking of foo succeeded it has a type, which can be queried with :type to display \nits type, (Bool,Bool).  The term fst foo typechecks .ne, and also runs .ne, returning True.  The term \nsnd foo also typechecks .ne, and runs; however the evaluation aborts with a runtime error giving exactly \nthe same error as the original warning.  That is, the error message is produced lazily, at runtime, \nwhen and only when the requirement for Char and Bool to be the same type is encountered. 2.1 How deferring \ntype errors works, informally GHC s type inference algorithm works in two stages: .rst we gen\u00aderate type \nconstraints, and then we solve them (Vytiniotis et al. 2011). In addition, inference elaborates the Haskell \nsource term to an explicitly typed F. C term, that includes the types and proofs ( ev\u00adidence in GHC jargon) \ncomputed by the constraint solver. In the previous example, during type inference for the sub-term a \n&#38;&#38; False we generate a type equality constraint, written Char ~ Bool. Usually the constraint \nsolver would immediately re\u00adject such a constraint as insoluble, but with -fdefer-type-errors we take \na different course: we generate evidence for Char ~ Bool, but ensure that if the (bogus) evidence is \never evaluated it brings the program to a graceful halt. More concretely, here is the F. C term that \nwe generate for foo: foo = let (c : Char ~ Bool)= error \"Couldn t...\" in (True,(cast a c) &#38;&#38; \nFalse) The elaborated foo contains a lazy binding of an evidence variable c of type Char ~ Bool to a \ncall to error. The latter is a built-in Haskell constant, of type .a . String . a, that prints its argument \nstring and brings execution to a halt. When we evaluate fst foo the result is True; but if we evaluate \nsnd foo, we must evaluate the result of (&#38;&#38;), which in turn evalu\u00adates its .rst argument, cast \na c. The cast forces evaluation of c, and hence triggers the runtime error. Note that the exact placement \nof coercions, and thus which errors get deferred, depends on the in\u00adternals of the type inference process; \nwe discuss this in more detail in Section 5.4. There is something puzzling about binding variable c with \nthe type Char ~ Bool. The evidence variable c is supposed to be bound to a proof witnessing that Char \nand Bool are equal types, but is nevertheless bound to just a term, and in fact a crashing term, namely \nerror! How can we then ensure soundness, and how can we get statically erasable proofs? It turns out \nthat the type Char ~ Bool is almost but not quite the type of a proof object. To explain how this works, \nwe move on to present some more details on GHC s typed intermediate language, System F. C. 3. TheF. C \nlanguage System F. C is a polymorphic and explicitly typed language, whose syntax is given in Figure \n1. Our presentation closely follows the most recent work on F. C Yorgey et al. (2012), and we will not \nrepeat operational semantics and type soundness results; instead, we refer the reader to Yorgey et al. \n(2012) for the details. A quick glance at Figure 1 will con.rm that the term language e is mostly conventional, \nexplicitly-typed, lambda calculus, with let\u00adbindings, literals (l), data constructors (K), and case expressions. \nIn addition, the language includes type and kind polymorphism: type (.a:..e) and kind (...e) abstractions, \nand type (e .) and kind (e .) applications, respectively. Some motivation for kind abstractions and applications \ncomes from previous work but, as we shall see in Section 6.2, kind polymorphism will play a key role \nhere as well. The distinctive feature of F. C is the use of coercions, .. A coercion . of type t ~# . \nis nothing more than a proof of type equality between the types . and t. Contrary to the notation used \nin Section 2.1 and in previous presentations of System F. C notice that we use symbol ~# instead of ~ \nfor coercion types, and Constraint# rather than Constraint for their kind this is for a good reason \nthat will become evident in Section 4.2. The term (e > .) is a cast that converts a term e of type t \nto one of type ., when . : t ~# .. Once again, this is deliberately different than the cast term that \nappeared in Section 2.1, as we discuss in Section 4.2. The only other place where a coercion . may appear \nin the term language is in an application (e .), so coercions are not .rst-class values. Dually, one \ncan abstract over such coercions with a coercion abstraction . (c:t ~# .) . e.  Terms e, u ::= x | \nl | .x:s.e | eu | .a:..e | e . | ...e | e . Type/kind polymorphism | .c:t.e | e . Coercion abs/app | \nK | case e of p . u | let x:t = e in u | e > . Cast p ::= Kc:t x:t Patterns  Types .,s,t, . ::= a Variables \n| H Constants | F Type functions | .1 .2 Application | .. Kind application |.a:... Polymorphic types \n|...t Kind-polymorphic types Type constants H ::= T Datatypes | (.) Arrow | (~#) Primitive equality type \nKinds ., . ::= . | * | . . . |.... Polymorphic kinds | Constraint# Kind of static proofs Coercion values \n., d ::= c Variables | .1 .2 Application |(.) Re.exivity | .1; .2 Transitivity | sym . Symmetry | ... \nOther coercion forms Environments G, . ::= \u00b7| G,bnd bnd ::= . Kind variable | a : . Type variable | c \n: s ~# . Coercion variable | x : s Term variable | T : .... . * Data type  | K : .. (a:.a).t . T . a \nData constructor   | ... Type families etc. Notation T .t = T .1 ... .m t1 ...tn a . a = a1 . ... \n. an . a  for a either . or t G0 = initial (closed) environment 3 (~#) : .... . . . Constraint# Figure \n1: Syntax of System FC (excerpt) The syntax of coercions themselves (. in Figure 1) includes coer\u00ad cion \nvariables, constructors for re.exivity, transitivity, and symme\u00adtry, as well as other constructors (such \nas lifting type equalities over data constructors) that we do not need to discuss in this paper. The \nwell-formedness judgement for terms appears in Figure 2 and is mostly conventional. In particular, the \nrules for coercion abstraction and application (ECABS and ECAPP) mirror those for terms (EABS and EAPP). \nThe rule for case expressions (ECASE) is also standard but notice that it allows us to bind coercion \nvariables, as well as term variables, in a pattern. 3.1 Types, kinds, and kind polymorphism The type \nlanguage of System F. C includes variables and constants, type and kind application, as well as the type \nof type-polymorphic G ftm e : t (x:t) . G (K:s) . G0 EVAR ECON G ftm x : t G ftm K : s G,(x:s) ftm e \n: t G ftm e : s . t G fty s : * EABS G ftm u : s EAPP G ftm .x:s.e : s . t G ftm e u : t G, (c:s) ftm \ne : t G fty s : Constraint# ECABS tm .c:s.e : s . t G f G ftm e : (s1 ~# s2) . t co . : s1 ~# s2 G f \nECAPP G ftm e . : t G fk . G ftm e : .a:..t tm ty . : . G,(a:.) f e : t G f ETABS ETAPP tm .a:..e : .a:..t \ntm G f G fe . : t[./a] G ftm e : ...t tm G, . fe : t G fk . EKABS EKAPP tm ...e : ...t tm G f G fe . \n: t[./.] tm G,(x:s) fu : s G ftm e : t tm co . : t ~# . G, (x:s) fe : t G f ELET ECAST G ftm let x:s \n= u in e : t G ftm e > . : . G ftm e : T .s For each branch Kx:t . u (K:.. (a:.a).s1 ~# s2 . t . T . \na) . G0 .i = ti[./.][s/a] .1i = s1i[./.][s/a] .2i = s2i[./.][s/a] G,c:.1 ~ .2 x:. ftm u : s ECASE tm \nG fcase e of K (c:s1 ~# s2)(x:t) . u : s Figure 2: Well-formed terms values (.a:...) and the type of \nkind-polymorphic values (...t). The type constants H include data constructors (T ), and the func\u00adtion \nconstructor (.) as well as the equality constructor (~#). The well-formedness judgement for types appears \nin Figure 3. What should the kind of ~# be? We mentioned previously that we would like to classify any \ntype t ~# s as having kind Constraint#, but the kind of t and s can be any kind whatsoever. This indicates \nthat ~# should be given the polymorphic kind: .... . . . Constraint# This kind, made valid because the \nsyntax of kinds . includes kind polymorphism, is recorded in the initial environment G0 (bottom of Figure \n1). Well-formedness of kinds (G fk .), for this presentation, amounts to well-scoping, so we omit the \ndetails from Figure 3. As a convention, we write t ~# . to mean (~#) .t. in the rest of this paper, where \nthe kind . of t and . is clear from the context. Finally, notice that well-formed arrow types1 are allowed \nto accept an argument which is either Constraint# or *, to account for coer\u00adcion or term abstraction, \nbut may only return *, hence disallowing any functions to return a value of type t ~# .. However, as \nwe will 1 For simplicity of presentation we do not include a binding for (.) in the initial environment \nG0, hence only allowing fully applied arrow types, unlike Haskell.  ty t : . G f (a : .) . G (T : .) \n. G TVAR TDATA ty T : . G fty a : . G fty t1: .1 ty t2: * G fG f.1 .{*,Constraint#} TARR ty t1 . t2: \n* G f G fty t1 : .1 . .2 G fty t : .... G fty t2 : .1 TAPP G fk . TKAPP G fty t1 t2 : .2 G fty t . : \n.[./.] G,(a:.) fty t : * G, . fty t : * G fk . G fty .a:..t : * TALL G fty ...t : * TKALL co . : s1 \n~# s2 G f ... k . G f ... Figure 3: Well-formed types and coercions see in Section 4, a function can \nwell return terms that contain such coercions. F.  3.2 C datatypes with coercions In F. C, coercions \ncan appear as arguments to data constructors, a feature that is particularly useful for representing \ngeneralized algebraic datatypes (GADTs) (Peyton Jones et al. 2006). Consider this source Haskell program \nwhich de.nes and uses a GADT: data Ta where T1 :: Int . T Int T2 :: a . Ta f :: Ta . [a] f (T1 x)=[x \n+ 1] f (T2 v)=[] main = f (T1 4) In F. C, we regard the GADT data constructor T1 as having the type: \nT1 : .a . (a ~# Int) . Int . Ta So T1 takes three arguments: a type argument to instantiate a,a coercion \nwitnessing the equality between a and Int, and a value of type Int. Here is the F. C version of main: \nmain = f Int (T1 Int (Int) 4) The coercion argument has kind Int ~# Int, for which the evidence is just \n(Int) (re.exivity). Similarly, pattern-matching on T1 binds two variables: a coercion variable, and a \nterm variable. Here is the F. C elaboration of function f : f = .(a : *). . (x : Ta) . case x of T1 (c \n: a ~# Int)(n : Int) . (Cons (n + 1) Nil) > sym [c] T2 v . Nil The cast converts the type of the result \nfrom [Int] to [a]2. The coercion sym [c] is evidence for (or a proof of) the equality of these types, \nlifting c (of type a ~# Int) over lists ([c], of type [a] ~# [Int]), before applying symmetry. We urge \nthe reader to consult Sulzmann et al. (2007) and Weirich et al. (2011) for more examples and intuition. \nA .nal remark: we will be presenting and discussing a number of F. C programs in the rest of the paper. \nFor readability purposes we will sometimes omit type or kind applications in F. C terms when these types \nor kinds are obvious from the context, making the syntax appear less verbose. 4. Two forms of equality \nIn Section 2 we sketched how to use type-equality evidence to sup\u00ad port deferred type errors, using s \n~ t as the type of equality evi\u00addence. Then in Section 3 we introduced our intermediate language, System \nF. C, in which explicit coercions of type s ~# t represent ev\u00adidence for the equality of two types. The \ndistinction between (~) and (~#) is crucial: it allows us to to marry a sound, erasable lan\u00adguage of \nproofs with the potentially-unsound ability to have terms that compute proofs, as we discuss in this \nsection. 4.1 The tension Types have a very valuable property that programmers take for granted: they \ngive strong static guarantees, but they carry no run\u00adtime overhead. This zero-overhead guarantee is formally \njusti.ed by an erasure property: we can erase all the types before running the program, without changing \nthe result. Can we offer a similar guarantee for coercions? Yes, we can. Sys\u00adtem F. C is carefully designed \nso that coercion abstractions, coercion applications, and casts, are all statically erasable, just like \ntype ab\u00adstractions and applications. But this statement is manifestly in tension with our approach to \ndeferred type errors. Consider once more the F. C term let (c : Char ~ Bool)= error \"Couldn t match...\" \nin snd (True,(cast a c) &#38;&#38; False) Obviously we cannot erase the binding of c and the cast, leaving \nsnd (True, a &#38;&#38; False), because the latter will crash. So it seems that insisting on complete \nerasure of equalities kills the idea of deferring type errors stone dead!  4.2 The two equalities We \nnow present our resolution of this tension. We have carefully maintained a distinction between (~#), \nthe type of primitive coercions . in F. C, which are fully erasable, and  (~), type of evidence generated \nby the type inference engine, which cannot be erased.  However (~) is not some magical built-in device. \nRather, we can de.ne it as a perfectly ordinary GADT (like the one we have already seen in Section 3.2), \nthus: data a ~ b where Eq# :: (a ~# b) . a ~ b 2 We informally use Haskell s notation [t ] for the type \nlist of t, and Cons and Nil as its constructors.  This de.nition introduces a new algebraic data type \nconstructor (~), belonging in the T syntactic category of Figure 1. It has exactly one data constructor \nEq#, whose (important) argument is a static equality proof. Readers familiar with proof assistants or \ntype theory will immediately recognize in the de.nition of (~) the type used traditionally in such systems \nto internalize de.nitional equality as a type (e.g. refl_equal in Coq). Like (~#), the data type (~) \nis polymorphically kinded: ~ : .. . . . . . * Eq#: .. . .(a : .)(b : .) . (a ~# b) . (a ~ b) As with \nt ~# s we usually omit the kind application in t ~ s as a syntactic convenience. The key point is that \nif . : s ~# t, then a value Eq# . is an ordinary term, built with the data constructor Eq#, and having \ntype s ~ t. Given the GADT (~) we can de.ne the function cast that takes such a term-level equality witness \nand casts a value between equivalent types: cast : .(ab : *) . a . (a ~ b) . b cast = .(ab : *). . (x \n: a) . . (eq : a ~ b). case eq of Eq# (c : a ~# b) . x > c Each use of cast forces evaluation of the \ncoercion, via the case expression and, in the case of a deferred type error, that is what triggers the \nruntime failure. Just as cast is a lifted version of >, we can lift all the coercion combinators from \nthe (~#) type to (~). For example: mkRe. :: .. . .(a : .) . a ~ a mkRe. = .. . .(a : .). Eq# . aa (a) \nmkSym :: .. . .(ab : .) . (a ~ b) . (b ~ a) mkSym = .. . .(ab : .) . . (c : a ~ b) . case c of Eq# c \n. Eq# . ba (sym c) The relationship between (~) and (~#) is closely analogous to that between Int and \nInt#, described twenty years ago in our implemen\u00adtation of arithmetic in GHC (Peyton Jones and Launchbury \n1991). Concretely, here is GHC s implementation of addition on Int: data Int = I# Int# plusInt :: Int \n. Int . Int plusInt x y = case x of I# x'. ' case y of I# y'. I# (x+# y') An Int is an ordinary algebraic \ndata type with a single constructor I# (the # is not special; it is just part of the constructor name). \nThis constructor has a single argument, of type Int#, which is the type of unboxed integers, a honest-to-goodness \n32-bit integer value just like C s int. Finally (+#) is the machine 32-bit addition instruction. We may \nsummarise the relationships thus: A value of type Int, or s ~ t, is always heap-allocated; it is always \nrepresented by a pointer to the heap-allocated object; and the object can be a thunk.  A value of type \nInt#, or s ~# t is never heap-allocated; and it cannot be a thunk. There is no bottom value of type Int#, \nor s ~# t; we say that they are unlifted types.  The plusInt function lifts the primitive addition +# \nfrom Int# to Int, by explicitly evaluating and unboxing its arguments; and the function mkSym works in \njust the same way.  The main difference between Int# and a ~# b is that the fomer is represented by \na 32-bit unboxed value, whereas the latter has a structure that is irrelevant for the execution of a \nprogram, and can be represented by a zero-bit value, or entirely erased it comes to the same thing in \nthe end. 5. Type inference and deferral of type errors With F. C in hand we can now explain in more detail \nthe mechanism of deferring type errors. We begin by sketching a little more about the type inference \nprocess. 5.1 Type inference by constraint generation GHC s type inference algorithm works in two stages \n(Vytiniotis et al. 2011): Step 1: traverse the syntax tree of the input Haskell term, gen\u00aderating type \nconstraints together with an elaborated term3 in System F. C.  Step 2: solve the constraints, creating \nF. C bindings that give evidence for the solution.  For example, consider the term show xs, where xs \n: [Int], and show : .a . Show a . a . String. In Step 1 we generate: Elaborated term: show [Int] d6 xs \nConstraint: d6 : Show [Int] The elaborated term looks much like the original except that show is now \napplied to a type argument [Int] (corresponding to the .a in show s type) and an evidence argument d6 \n(corresponding to the Show a . in its type). The constraint is given a fresh name, d6 in this example, \nwhich is mentioned in the elaborated term. Af.cionados of Haskell s type-class system will recognise \nd6 as show s dictionary argument: it is simply a tuple of functions, the methods of the Show class. When \nStep 1 is complete, the constraint solver solves the generated constraints, producing evidence bindings: \nd6 : Show [Int]= $dShowList Int $dShowInt Here the solver has constructed a dictionary for Show [Int], \nusing the dictionary-construction functions that arise from the instance declarations of the class Show: \n$dShowInt : Show Int $dShowList : .a . Show a . Show [a] Finally, the evidence bindings are wrapped around \nthe term in a let to make an executable term: let d6 = $dShowList Int $dShowInt in show [Int] d6 xs \n 5.2 Equality constraints This is all quite conventional. Somewhat less conventionally (but following \nthe French school of type inference (Pottier and R\u00b4 emy 2005)) GHC generates equality constraints as \nwell as type-class constraints. We simpli.ed the show example; in reality GHC gen\u00aderates the following: \nElaborated term: show a d6 (cast xs c5) Constraints: d6 : Show a c5 : [Int] ~ a When instantiating show \ns type in Step 1, the constraint generator does not yet know that it will be applied to the type [Int], \nso instead it creates a fresh uni.cation variable a, and uses that to instantiate show s type. Later, \nwhen checking show s argument x, it must ensure that show s argument type a is equal to the actual type \nof xs, namely [Int]. It ensures this (eventual) equality by generating 3 In reality we .rst generate \nan elaborated term by decorating the Haskell source term, and then desugar it, but we will ignore that \nextra step here.  an equality constraint c5 : [Int] ~ a, again with an arbitrary fresh name c5 which \nnames the evidence for the equality. Lastly, in the elaborated term, we use the cast term cast xs c5 \nto convert xs into a term of type a. Notice that c5 s type [Int] ~ a uses the boxed equality (~) rather \nthan the primitive F. C equality (~#) (Section 4.2). In Step 2, the constraint solver has a little extra \nwork to do: as well as solving the constraints and giving bindings for the evidence vari\u00adables, it must \nalso produce bindings for the uni.cation variables. In our running example, the solution to the constraints \nlooks like this: a =[Int] c5 : [Int] ~ a = mkRe. [Int] d6 : Show [Int]= $dShowList Int $dShowInt The \nsolver decided to eliminate a by substituting [Int] for a, the .rst of the above bindings. The equality \nc5 now witnesses the vacuous equality [Int] ~ [Int], but it must still be given a binding, here mkRe. \n[Int]. (Recall that mkRe. was introduced in Section 4.2.) Actually, as a matter of ef.ciency, in our \nreal implementation the constraint generator solves many simple and immediately-soluble equalities (such \nas a ~ [Int]) on the .y using a standard uni.ca\u00adtion algorithm, rather than generating an equality constraint \nto be solved later. But that is a mere implementation matter; the imple\u00admentation remains faithful to \nthe semantics of generate-and-solve. Moreover, it certainly cannot solve all equalities in this way, \nbe\u00adcause of GADTs and type families (Vytiniotis et al. 2011).  5.3 Deferring type errors made easy In \na system generating equality proofs using the (~) datatype, which has values that can be inhabited by \nordinary terms, it is de\u00adlightfully easy to support deferred type errors. During constraint generation, \nwe generate a type-equality constraint even for uni.ca\u00adtions that are manifestly insoluble. During constraint \nsolving, in\u00adstead of emitting an error message when we encounter an insolu\u00adble constraint, we emit a \nwarning, and create a value binding for the constraint variable, which binds it to a call to error, applied \nto the error message string that would otherwise have been emitted at compile time. And that s all there \nis to it. It is worth noting several features of this implementation technique: Each F. C term given \nabove is a well-typed F. C term, even though some are generated from a type-incorrect Haskell term. Of \ncourse it can fail at run-time, but it does so in a civilized way, by raising an exception, not by causing \na segmentation fault, or performing (&#38;&#38;) of a character and a boolean. You might consider that \na program that fails at runtime in this way is not well-typed, in Milner s sense of well typed programs \ndo not go wrong . But Haskell programs can already go wrong in this way consider (head [ ]) for example \n so matters are certainly no worse than in the base language. In short, we have merely deferred the type \nerrors to runtime; we have not ignored them! Deferring type errors is not restricted to interpreted \nexpressions typed at the interactive GHCi prompt. You can compile any module with -fdefer-type-errors \nand GHC will produce a compiled binary, which can be linked and run.  There is no re.ection involved, \nnor run-time type checking. Indeed there is no runtime overhead whatsoever: the program runs at full \nspeed unless it reaches the point where a runtime error is signalled, in which case it halts. (This claim \nassumes the optimisations described in Section 7.)  The technique makes elegant use of laziness. In \na call-by-value language, a strict binding of c in Section 2.1 would be evaluated by the call fst foo, \nor even when foo is bound, and it would ob\u00adviate the entire exercise if that evaluation triggered the \nruntime error! Nevertheless, the idea can readily be adapted for call-by\u00advalue, by simply making (~) \ninto a sum type: data a ~ b where Eq# :: (a ~# b) . a ~ b Error :: String . a ~ b Now, the evidence \nfor an erroneous type constraint would be an Error value, and evaluating that is .ne. We simply need \nto adjust cast to deal with the Error case: cast = .(ab : *). . (x : a). . (eq : a ~ b) . case eq of \nEq# (c : a ~# b) . x > c Error s . error s The technique works uniformly for all type constraints, not \nonly for equality ones. For example, in Section 5.1, suppose there was no instance for Show [Int]. Then \nthe constraint d6 : Show [Int] would be insoluble, so again we can simply emit a warning and bind d6 \nto an error thunk. Any program that needs the evidence for d6 will now fail; those that don t, won t. \n We can defer all type errors in terms, but not kind errors in types. For example, consider  data T \n= MkT (Int Int) f (MkT x)= x The type Int Int simply does not make sense applying Int to Int is a kind \nerror, and we do not have a convenient way to defer kind errors, only type errors.  5.4 The placement \nof errors Since many different parts of a program may contribute to a type error, there may be some non-determinism \nabout how delayed a deferred type error will be. Suppose that upper : [Char] . [Char], and consider the \nterm: upper [True, a ] There are two type incompatibilities here. First, the boolean True and character \na cannot be in the same list. Second, the function upper expects a list of characters but is given a \nlist with a boolean in it. Here is one possible elaboration: Elaborated term: upper [cast True c7, a \n] Constraints: c7 : Bool ~ Char But the program could also be elaborated in another way: Elaborated term: \nupper (cast [True,cast a c8 ] c9) Constraints: c8 : Char ~ Bool c9 : [Bool] ~ [Char] In this case, type \ninference has cast a to Bool using c8, so that it can join True to form a list of Bool; and then cast \nthe list [Bool] to [Char] using c9 to make it compatible with upper. The two elaborated programs have \nslightly different runtime behaviour. If the term is bound to tm, then head (tail tm) will run successfully \n(returning A ) in the .rst elaboration, but fail with a runtime error in the second. We might hope that \nthe type inference engine inserts as few casts as possible, and that it does so as near to the usage \nsite as possible. In fact this turns out to be the case, because the type inference engine uses the (known) \ntype of upper to type-check its argument, expect\u00ading the result to be of type [Char]. This idea of pushing \ndown the expected type into an expression, sometimes called bidirectional or local type inference (Pierce \nand Turner 2000), is already im\u00ad plemented in GHC to improve the quality of error messages; see Peyton \nJones et al. (2007, Section 5.4) for details. Although it is a heuristic, and not a formal guarantee, \nthe mechanism localises the casts very nicely in practice.  Nevertheless, the bottom line is that the \ndynamic semantics of a type-incorrect program depends on hard-to-specify implementation details of the \ntype inference algorithm. That sounds bad! But we feel quite relaxed about it: The issue arises only \nfor programs that contain errors. Type correct programs have their usually fully-speci.ed semantics. \n Regardless of the precise placement of coercions, the elaborated program is type correct. This is not \na soundness issue.  The imprecision of dynamic semantics is no greater a short\u00adcoming than the lack \nof a formal speci.cation of the precise type error message(s) produced by a conventional type infer\u00adence \nengine for a type-incorrect program. And yet no compiler or paper known to us gives a formal speci.cation \nof what type errors are produced for a type-incorrect program.  That said, it is interesting to re.ect \non approaches that might tighten up the speci.cation, and we do so in Section 9.  5.5 Summary There \nare many reasons why evidence-based type elaboration, us\u00ading constraint generation and subsequent constraint \nsolving, is de\u00adsirable (Vytiniotis et al. 2011): It is expressive, readily accommodating Haskell s type \nclasses, implicit parameters, and type families.  It is modular. The constraint generator accepts a \nvery large in\u00adput language (all of Haskell), so it has many cases, but each case is very simple. In contrast, \nthe constraint solver accepts a very small input language (the syntax of constraints) but em\u00adbodies a \ncomplex solving algorithm. Keeping the two separate is incredibly wonderful.  It is robust: for example \nit does not matter whether the con\u00adstraint generator traverses the term left-to-right or right-to-left: \nthe resulting constraint is the same either way.  Neither the constraint generator nor the solver need \nbe trusted; a very simple, independent checker can type-check the elaborated F.  C term. To this list \nwe can now add a completely new merit: it is dead easy to implement deferred type errors, a feature that \nis desired by many Haskell programmers. 6. Discussion Now that we have discussed type inference in more \ndetail, we pause to re.ect on our design choices. 6.1 Evidence uniformity We ve seen that deferring type \nerrors provides a good motivation for treating coercions as term-level constructs. But there is another \nway in which treating coercions as values turns out to be very convenient. In the Haskell source language, \nequality constraints are treated uniformly with type-class constraints and implicit\u00adparameter constraints; \nanywhere a class constraint can appear, an equality constraint can appear, and vice versa. Class constraints \nand implicit-parameter constraints de.nitely cannot be erased: by design their evidence carries a runtime \nvalue. Treating some con\u00adstraints as non-erasable values and others (the equalities) as type\u00adlike, erasable \nconstructs, led to many annoying special cases in the type inference and source-to-F. C elaboration of \nHaskell programs. The most troublesome example of this non-uniformity arises when treating Haskell s \nsuperclasses. Consider the declaration class (a ~ Fb, Eq a) . Cab where... Here Eq a is a superclass \nof Cab, meaning that from evidence for Cab one can extract evidence for Eq a. Concretely this extraction \nis witnessed by a .eld selector: sc2 : Cab . Eq a which takes a dictionary (i.e. record of values) for \nCab and picks out the Eq a .eld. In just the same way one should be able to extract evidence for a ~ \nFb, which suggests a selector function with type sc1 : Cab . (a ~ Fb) Before we distinguished (~) and \n(~#) we could not write this function because there simply is no such function in F. C; indeed the type \nCab . (a ~# Fb) is not even well kinded in Figure 3. There is a good reason for this: dictionaries can \nbe recursively de.ned and can diverge (L\u00a8 ammel and Peyton Jones 2005), so the selector function may \ndiverge when evaluating its arguments but the type a ~# Fb cannot represent divergence, because that \nwould be unsound. The tension is readily resolved by (~); the type of sc1 is well formed and its de.nition \nlooks something like this: sc1 = .ab . . (d : Cab). case d of MkC (c : a ~# Fb)(eq : Eq a)... . Eq# c \n This accumulation of infelicities led us to the two-equality plan, and in fact we had fully implemented \nthis design even before we ever thought of deferring type errors. Now, we get the ability to defer errors \nregarding type uni.cation, missing class constraints, and implicit parameters, all in one go.  6.2 Why \nkind polymorphism is important We have mentioned that both equalities (~#) and (~) are kind\u00adpolymorphic, \nbut we have not yet said why. Right from the begin\u00adning Haskell has featured kinds other than *, such \nas * . *. During type inference, when unifying, say, a\u00df ~ Maybe Int, the inference engine or, more precisely, \nthe constraint solver must decom\u00adpose the equality to give a ~ Maybe and \u00df ~ Int. The former equal\u00adity \nis at kind * . *, so it follows that the (~) type constructor itself must be either (a) magically built \nin or (b) poly-kinded. And simi\u00adlarly (~#). Solution (a) is entirely possible: we could add s ~ t and \ns ~# t to the syntax of types, and give them their own kinding rules. But there are unpleasant knock-on \neffects. The optimizer would need to be taught how to optimize terms involving (~). Worse, it turns out \nthat we need equalities between equalities, thus (s1 ~ t1) ~ (s2 ~ t2), which in turn leads to the need \nfor new coercion combinators to decompose such types. There are many other reasons for kind polymorphism \nin F. C (Yorgey et al. 2012), and once we have kind polymorphism we can readily make the equality type \nconstructors kind-polymorphic.  6.3 What the Haskell programmer sees A salient feature of Haskell s \nquali.ed types (type classes, implicit parameters, equality constraints) is that the type inference engine \n.lls in the missing evidence parameters. So if f has type f :: (Num b,a ~ Fb) . a . b . b then given \na source-language call (f e1 e2), the type inference will generate the elaborated call (f st dce1 e2), \nwhere s and t are the types that instantiate a and b, and d and c are evidence terms that witness that \nNum t holds and that s ~ F t, respectively. One might wonder whether one can (in Haskell) also write \ng :: (a ~# Fb) . a . b . b and have the above evidence-generation behaviour. No, you cannot. The whole \npoint of the (~) type is that it can be treated uniformly with other evidence (bound in letrec, returned \nas a result of a call), whereas (~#) cannot. So in the source language s ~# t is not a type constraint \nyou can write before the . in a Haskell type, and have it participate in constraint solving. The entire \nconstraint generation and solving process works exclusively with well-behaved, uniform, boxed constraints. \nOnly when constraint solving is complete does (~#) enter the picture, as we discuss next. 7. Optimizing \nequalities We now have a correct implementation, but it looks worryingly expensive. After all, the constraint \ngeneration/solving process may generate a program littered with coercion bindings and casts, all of which \nare invisible to the programmer, have no operational signi.cance, and merely ensure that well typed programs \ndon t go wrong . Yet each will generate a heap-allocated Eq# box, ready to be evaluated by cast. Happily, \nalmost all of these boxes are eliminated by existing optimizations within GHC, as this section describes. \n7.1 Eliminating redundant boxing and unboxing The fact that we have de.ned (~) as an ordinary GADT means \nthat is fully exposed to GHC s optimizer. Consider a Haskell 98 program that turns out to be well typed. \nThe constraint generator will produce many constraints that are ultimately solved by re.ex\u00adivity, because \nthe two types really are equal. Here is a typical case of an elaborated term: let (c : Char ~ Char)= \nmkRe. Char in ... (cast e c)... (Recall that mkRe. and cast were de.ned in Section 4.2.) As it stands, \nthe let will heap-allocate a thunk which, when evaluated by the cast, will turn out to be an Eq# constructor \nwrapping a re.exive coercion (Char). All this is wasted work. But GHC s optimizer can inline the de.nitions \nof mkRe. and cast from Section 4.2 to get let (c : Char ~ Char)= Eq# * Char Char (Char) in ... (case \nc of Eq# c '. e > c ' )... Now it can inline c at its use site, and eliminate the case expression, giving \n...(e > (Char)) ... Remembering that primitive casts (>) can be erased, we have elim\u00adinated the overhead. \nMoreover, the optimizations involved have all been in GHC for years; there is no new special purpose \nmagic. What happens when a deferred type error means that a cast cannot, and should not, be erased? Consider \nonce more the F. C term let (c : Char ~ Bool)= error \"Couldn t match...\" in snd (True,(cast a c) &#38;&#38; \nFalse) Now, simply by inlining cast and c, the optimizer can transform to snd (True,(case error \"...\" \nof {Eq# c . a > c}) &#38;&#38; False) After inlining (&#38;&#38;), and simplifying case-of-error to \njust a call of error, both standard transformations in GHC s optimizer) we get snd (True,error \"...\") \nEven erroneous programs are optimized by removing their dead code! The point is this: by exposing the \nevaluation of coercions, we allow the existing optimizer transformations to work their magic.  7.2 Equalities \nand GADTs Let us reconsider the GADT example given in Section 3.2: data Ta where T1 :: Int . T Int T2 \n:: a . Ta There we said that the constructor T1 is typed thus: T1 : .a . (a ~# Int) . Int . Ta That \nis true in System F. C. But the Haskell programmer, who knows only of the type s ~ t, considers T1 to \nhave this type: T1 :: .a . (a ~ Int) . Int . Ta It would be perfectly sound to adopt the latter type \nfor T1 in the elaborated program; for example, function f from Section 3.2 would be elaborated thus: \nf = .a . . (x : Ta). case x of T1 (c : a ~ Int)(n : Int) . cast (Cons (n + 1) Nil)(mkSym [c]) T2 v . \nNil Since an argument of type a ~ Int has a lifted type with a boxed representation, it would take up \na whole word in every T1 object. Moreover, since c is bound by the pattern match, the case expres\u00adsion \nin mkSym will not cancel with an Eq# box in the binding for c. This is not good! What has become of our \nzero-overhead solution? The solution is simple: we desugar GADTs to contain unlifted, rather than lifted, \nequalities. We can do this in such a way that the Haskell programmer still sees only the nice well-behaved \n(~) types, as follows. First, in the elaborated program the type of T1 is: T1 : .a . (a ~# Int) . Int \n. Ta However, the elaborator replaces every source-language call of T1 with a call of a constructor wrapper \nfunction, T1wrap, de.ned like this: T1wrap : .a . (a ~ Int) . Int . Ta T1wrap = .(a : *) . . (c : a ~ \nInt) . . (n : Int). case c of Eq# c1 . T1 c1 n The wrapper deconstructs the evidence and puts the payload \ninto T1 where, since it is erasable, it takes no space. Dually, a source-program pattern match is elaborated \ninto a F. pattern match together with code to re-box the coercion. So our function f is elaborated thus: \nf = .a . . (x : Ta). case x of T1 (c1 : a ~# Int)(n : Int)  . let c = Eq# c1 --Re-boxing in cast (Cons \n(n + 1) Nil)(mkSym [c]) T2 v . Nil Now the earlier optimizations will get rid of all the boxing and un\u00adboxing \nand we are back to nice, ef.cient code. The technique of un\u00adboxing strict arguments on construction, \nand re-boxing on pattern matching (in the expectation that the re-boxing will be optimized away) is precisely \nwhat GHC s UNPACK pragma on constructor ar\u00adguments does. So, once more, coercions can hitch a free ride \non some existing machinery.  7.3 How much is optimized away? We have argued that the boxing and unboxing, \nintroduced in the elaborated program by the type checker, will largely be eliminated by standard optimizations. \nBut not always! Indeed that is the point: the main reason for going to all of this trouble is to handle \nsmoothly the cases (deferred type errors, recursive dictionaries) when equal\u00adities cannot, and should \nnot, be erased. But still, one might reason\u00adably ask, can we offer any guarantees at all? Consider a \ntype-correct Haskell program that contains (a) no equal\u00adity superclasses, and (b) no functions that take \nor return a value of type s ~ t, apart from GADT constructors. This includes all Haskell 98 programs, \nand all GADT programs. After typechecking and elaboration to F. C, suppose that we inline every use of \nmkRe., mkSym, etc, and the GADT constructor wrappers. Then Every use of a variable of type s ~ t will \nbe a case expression that scrutinises that variable, namely the unboxing case expres\u00adsions in mkRe., \nmkSym, etc, and GADT constructor wrappers.  Every binding of an evidence variable of type s ~ t will \nbe a let whose right hand side returns a statically-visible Eq# box.  By inlining these let-bound evidence \nvariables at their use sites, we can cancel the case with the Eq# constructors, thereby eliminating all \nboxing and unboxing. To illustrate, consider once more the elaboration of function f at the end of the \nprevious subsection. If we inline mkSym and cast we obtain: f = .a . . (x : Ta). case x of T1 (c1 : a \n~# Int)(n : Int) . let c = Eq# c1 in --Re-boxing ' let c2 = case c of Eq# c '. Eq# (sym [c ]) in case \nc2 of '' Eq# c2 . Cons (n + 1) Nil > c 2 T2 v . Nil The right hand side of c2 comes from inlining mkSym, \nwhile the case c2 ... comes from inlining cast. Now we can inline c in case c... , and c2 in case c2 \n... , after which the cancellation of boxing and unboxing is immediate. When does this not work? Consider \nexception (b) above, where a programmer writes a function that is explicitly abstracted over an equality: \nf : .a . Fa ~ Int . [Fa] . Int fx = head x + 1 The elaborated form will look like this: f : .a . Fa \n~ Int . [Fa] . Int f = .a . . (c : Fa ~ Int) . . (x : [Fa]) . head (cast x c)+ 1 Since c is lambda-bound, \nthere is no Eq# box for the cast to cancel with. However we can perform the same worker/wrapper split \nto this user-de.ned function that we did for constructors, thus f : .a . Fa ~ Int . [Fa] . Int f = .a \n. . (c : Fa ~ Int). . (x : [Fa]). case c of Eq# c '. fwrk c' x fwrk : .a . Fa ~# Int . [Fa] . Int fwrk \n= .a. . (c ' : Fa ~# Int). . (x : [Fa]). let c = Eq# c ' in head (cast x c)+ 1 Now in fwrk the boxing \nand unboxing cancels; and dually we are free to inline the wrapper function f at its call sites, where \nthe unboxing will cancel with the construction. This worker/wrapper mechanism is precisely what GHC already \nimplements to eliminate boxing overheads on strict function arguments (Peyton Jones and Santos 1998), \nso it too comes for free. There is a small price to pay, however: the transformation makes the function \nstrict in its equality evidence, and that in turn might trigger a deferred error message slightly earlier \nthan strictly necessary. In our view this is a trade-off worth making. In our current implementation \nthe worker/wrapper transform on equalities is only applied when the function really is strict in the \nequality; we have not yet added the re.nement of making it strict in all equalities.  7.4 Summary In \nshort, although we do not give a formal theorem (which would involve formalizing GHC s optimizer) we \nhave solid grounds, backed by observation of optimized code, for stating that the uni\u00adform representation \nof equality evidence can be successfully opti\u00admized away in all but the cases in which it cannot and \nshould not be eliminated, namely for deferred type errors and functions that must accept or return term-level \nequalities (such as selectors for equality superclasses). Of course, introducing and then eliminating \nall these boxes does mean a lot more work for the compiler, but this has not proved to be a problem in \npractice. 8. Related work 8.1 Relation to hybrid and gradual typing Hybrid type checking (Flanagan 2006) \nrefers to the idea of defer\u00ad ring statically unproved goals as runtime checks. Achieving simi\u00adlar effects, \nbut arriving from the opposite end of the spectrum soft typing tries to elimiminate statically as many \nruntime checks as possible (Wright and Cartwright 1997). There are two differences compared to our approach: \nFirst, in hybrid type checking typically only unsolved goals will be deferred whereas insoluble ones \nwill be reported statically. In our case, insoluble and unsolved goals will be deferred. Second, unsolved \ngoals will be deferred as checks in hy\u00adbrid type systems, whereas they will remain errors in our system: \nOur treatment of coercions does not replace static type errors by runtime checks, but rather delays triggering \na static error until the offending part of the program is evaluated, at runtime. For instance, consider \nthe following program, which contains a static error but is compiled with -fdefer-type-errors: f :: .a \n. a . a . a f xy = x &#38;&#38; y There is a static error in this program because f is supposed to be \npolymorphic in the type of its arguments x and y, which are nevertheless treated as having type Bool. \nAt runtime, even if we evaluate the application of f on arguments of type Bool, such as f True False \nwe will get a type error Couldn t match type a with Bool , despite the fact that the arguments of f are \nof type Bool at runtime. In contrast, a truly dynamic type-check would not trigger a runtime error. \n In the context of GHC, there is no straightforward way to incor\u00adporate runtime checks instead of error \ntriggers at runtime, unless dynamic type information is passed along with polymorphic types. Though systems \nwith dynamic types and coercions have been stud\u00adied in the literature (Henglein 1994), we have not examined \nthis possibility. There is a large body of work on interoperating statically and dy\u00adnamically typed parts \nof a program, often referred to as gradual typing (Ahmed et al. 2011; Siek and Taha 2006; Siek and Vachhara\u00ad \njani 2008; Tobin-Hochstadt and Felleisen 2006). Typically, stat\u00ad ically insoluble goals will be reported \nstatically (Siek and Taha 2006), whereas insoluble goals which perhaps arise from the po\u00ad tential interoperation \nof dynamic and static parts of the program will be wrapped with runtime checks. The main problem in grad\u00adual \ntyping is to identify how to assign blame in case of a contract violation (or a dynamic type error). \nWe have seen in Section 5.3 that non-determinism in the dynamic placement of the type error may well \nexist. Consequently it might be an interesting avenue to explore if ideas from gradual typing could help \nus specify a more predictable blame assignment for these deferred type errors. Note .nally that previous \nwork on type error slicing (Haack and Wells 2004) has focused on identifying parts of a program that \ncontribute to a type error and would be potentially useful for reducing this non-determinism both for \nstatic error messages and for better spec\u00ad ifying the dynamic behaviour of an erroneous program. Deferring \ntype errors is also a valuable tool in the context of IDE development. In an IDE it is essential to provide \nfeedback to the programmer even if the program has errors. The Visual Basic IDE uses a hierarchy of analysis \nto provide gradually more functionality depending on the type of errors present (Gertz 2005). For instance, \nif there are type errors, but no parse errors, smart indentation and automatic code pretty-printing can \nalready be applied. However, more complicated refactorings require type information to be avail\u00adable. \nSome IDEs use error-correcting parsers to be able to provide some functionality in the presence of parsing \nerrors, but a type error will require a correction by the user before the IDE can offer func\u00adtionality \nthat depends on the availability of types. Deferring type errors allows the compiler to complete type \nchecking without .x\u00ading the type errors, allowing for a Haskell IDE to remain functional even for programs \nthat do not type-check.  8.3 Proof erasure Coq (The Coq Team) uses a sort-based erasure process by introduc\u00ading \na special universe for propositions, Prop, which is analogous to our Constraint# kind. Terms whose type \nlives in Prop are erased even when they are applications of functions (lemmas) to computa\u00adtional terms. \nThis is sound in Coq, since the computation language is also strongly normalizing. Extending the computation \nlanguage of F . . C proofs or .nding a way to restrict the ordinary computation language of FC using \nkinds in order to allow it to construct prim\u00ad 8.2 Deferring type errors DuctileJ is a plugin to the \nJava compiler that converts a normal Java program to one in which type checking is deferred until runtime \n(Bayne et al. 2011). The authors provide an extensive discussion of the software engineering advantages \nof deferring type errors, under two main headings. During prototyping, programmers often comment out \npartly written or temporarily out-of-date code, while prototyping some new part. Commenting out is tiresome \nbecause one must do it consistently: if you comment out f you must comment out everything that calls \nf , and so on. Deferring type errors is a kind of lazy commenting-out process.  During software evolution \nof a working system it can be burden\u00adsome to maintain global static type correctness. It may be more \nproductive to explore a refactoring, or change of data represen\u00adtation, in part of a software system, \nand test that part, without  itive equalities is an interesting direction towards true dependent types \nfor Haskell. Irrelevance-based erasure is another methodology proposed in the context of pure type systems \nand type theory. In the context of Epi\u00adgram, Brady et al. (2003) presented an erasure technique where \nterm-level indices of inductive types can be erased even when they are deconstructed inside the body \nof a function, since values of the indexed inductive datatype will be simultaneously deconstructed and \nhence the indices are irrelevant for the computation. In the Agda language (Norell 2007) there exist \nplans to adopt a similar irrelevance-based erasure strategy. Other related work (Abel 2011; Mishra-Linger \nand Sheard 2008) proposes erasure in the context of PTSs guided with lightweight programmer annotations. \nThere also exist approaches that lie in between sort-based erasure and irrelevance-based erasure: for \ninstance, in implicit calculus of con\u00adstructions (Miquel 2001) explicitly marked static information (not \nnecessarily Prop-bound) does not affect computation and can be committing to propagating the change globally. \nWe urge the reader to consult this excellent paper for a full exposi\u00adtion, and a good evaluation of the \npractical utility of deferring type errors both during prototyping and for software evolution. Note however \nthat although our motivations are similar, our imple\u00admentation differs radically from that in DuctileJ. \nThe latter works by a de-typing transformation that uses Java s runtime type infor\u00admation and re.ection \nmechanisms to support runtime type checks. This imposes a signi.cant runtime cost the paper reports \na slow\u00addown between 1.1 and 7.8 times. In contrast, our implementation performs no runtime re.ection \nand runs at full speed until the type error itself is encountered. The DuctileJ de-typing transformation \nis also not entirely faithful to the original semantics unsurprisingly, the differences involve re.ection \n whereas ours is fully faithful, even for programs that involve Haskell s equivalent of re.ection, the \nTypeable and Data classes. To be fair, many of the DuctileJ complexities go away because Haskell is a \nsimpler language than Java. Further, GHC already implemented (the quite advance fea\u00adtures of) kind polymorphism, \ncoercions, and unboxing, which al\u00adlowed us to piggyback -fdefer-type-errors onto the existing compiler \nimplementation with very little effort. erased (Barras and Bernardo 2008). In F . C the result of a computa\u00adtion \ncannot depend on the structure of an equality proof, by con\u00adstruction: there is no mechanism to decompose \nthe structure of a coercion at all at the term-level. Hence a coercion value needs no structure (since \nit cannot be decomposed), which allows us to per\u00adform full erasure without any form of irrelevance analysis. \nThis idea of separating the computational part of a proof-like object, which always has to run before \nwe get to a zero-cost log\u00adical part is reminiscent of a similar separation that A-normal forms introduce \nin re.nement type systems, for instance (Bengt\u00ad son et al. 2008) or the more recent work on value-dependent \ntypes (Borgstrom et al. 2011; Swamy et al. 2011). This line of work seems the closest in spirit to ours, \nwith similar erasure concerns, and there is rapidly growing evidence of the real-world potential of these \nideas see for instance the discussion and applications reported by Swamy et al. (2011). 9. Future work \nand conclusions Error coercion placement This paper has been about an imple\u00admentation technique that \nuses .rst-class proof-like objects to al\u00adlow for deferred type errors with very low overhead. A natural \nnext step would be towards a declarative speci.cation of the elabora\u00adtion process from source to a target \nlanguage which speci.es the placement of the deferred error messages on potentially erroneous sub-terms. \nRecent related work on coercion placement in the con\u00adtext of coercive subtyping is the work of Luo (2008) \nand Swamy et al. (2009); these would certainly be good starting points for in\u00ad vestigations on a declarative \nspeci.cation of deferring type errors. The canonical reference for coercion placement in a calculus with \ntype-dynamic is the work of Henglein (1994), but it seems some\u00ad what disconnected from our problem as \nwe do not have currently any way of dynamically passing type information or executing pro\u00adgrams that \ncontain static errors but are safe dynamically.  In general, this problem seems very hard to tackle \nwithout ex\u00adposing some of the operation of the underlying constraint solver. In the other direction, \na principled approach to deferring type er\u00adrors might actually provide guidance on the order in which \ncon\u00adstraints should be solved. For instance, when solving the constraints C1 .C2 .C3 arising from the \nexpressions e1, e2, and e3 in the term if e1 then e2 else e3, we might want to prioritise solving the \ncon\u00adstraint C1. In this way, if an error is caused by the interaction of the expressions e2 or e3 with \ne1, we would still be able to execute the condition of the branch e1 before we emit a deferred type error \nfor e2 or e3. Otherwise we run the danger of the term e2 or e3 forcing some uni.cation that makes constraint \nC1 insoluble, giving rise to an earlier error message (during evaluation of the condition term e1). However, \nit is not clear what should happen when C2 and C3 have a common uni.cation variable, and there is freedom \nin de\u00adferring either one, for instance. Therefore this problem is certainly worth further investigation. \nThe equality type Internalizing de.nitional equality (~#) as a type (~) is pretty standard in languages \nwith dependent types (Li\u00ad cata and Harper 2005). For example, programming with .rst-class equality witnesses \nis sometimes convenient to avoid shortcomings of implementations of dependent pattern matching. Recent \nwork on higher-dimensional type theory (Licata and Harper 2012) goes one step further to show that the \n(~) datatype can be extended with yet another constructor for term-level isomorphisms between types. \nInterestingly the usual de.nitional equality infer\u00adence rules apply for this extended equality type. \nMoreover they show that the term language can be equipped with an equational theory that is rich enough, \nso that types enjoy canonical forms. Of course the language they address is simpler in some respects \n(no partiality or divergence, no polymorphism), nor is there a reduction semantics. In a real compiler, \nbeing able to extend the (~) datatype with true computational isomorphisms and maintain soundness and \nproviding a transparent treatment of these isomorphisms with min\u00adimal programmer intervention is an interesting \ndirection for future research. Conclusions In this paper we have proposed a simple and light\u00adweight mechanism \nfor deferring type errors, in a type-safe way that requires no program rewriting, and preserves the semantics \nof the program until execution reaches the part that contains a type error. We have shown that this can \nbe done in an entirely safe way in the context of a typed intermediate language, and in fact without \nre\u00ad quiring any modi.cations to System F. C or the compiler optimizer. This work is fully implemented \nin GHC, where it has in addition greatly simpli.ed the implementation of type inference and elabo\u00ad ration \nof Haskell to F. C. Acknowledgments Particular thanks are due to Etienne Laurin, who suggested to us \nthe idea of deferring type errors (GHC Trac ticket 5624), although his implementation was very different \nto the one described here. We thank Stephanie Weirich and Brent Yorgey for their detailed comments and \nsuggestions, and the ICFP reviewers for the helpful feedback. This work has been partially funded by \nthe Portuguese Foundation for Science and Technology (FCT) via the SFRH/BD/35999/2007 grant, and by EPSRC \ngrant number EP/J010995/1. References Andreas Abel. Irrelevance in type theory with a heterogeneous equality \njudgement. In Foundations of Software Science and Computational Structures, 14th International Conference, \nFOSSACS 2011, pages 57 71. Springer, 2011. Amal Ahmed, Robert Bruce Findler, Jeremy G. Siek, and Philip \nWadler. Blame for all. In Proceedings of the 38th annual ACM SIGPLAN-SIGACT Symposium on Principles of \nProgramming Languages, POPL 11, pages 201 214, New York, NY, USA, 2011. ACM. ISBN 978-1\u00ad4503-0490-0. \ndoi: 10.1145/1926385.1926409. Bruno Barras and Bruno Bernardo. The implicit calculus of constructions \nas a programming language with dependent types. In Foundations of Software Science and Computation Structure, \npages 365 379, 2008. doi: 10.1007/978-3-540-78499-9 26. Michael Bayne, Richard Cook, and Michael Ernst. \nAlways-available static and dynamic feedback. In Proceedings of 33rd International Conference on Software \nEngineering (ICSE 11), pages 521 530, Hawaii, 2011. Jesper Bengtson, Karthikeyan Bhargavan, C\u00b4edric Fournet, \nAndrew D. Gor\u00addon, and Sergio Maffeis. Re.nement types for secure implementations. In Proceedings of \nthe 2008 21st IEEE Computer Security Foundations Symposium, pages 17 32, Washington, DC, USA, 2008. IEEE \nComputer Society. ISBN 978-0-7695-3182-3. Johannes Borgstrom, Juan Chen, and Nikhil Swamy. Verifying \nstateful programs with substructural state and Hoare types. In Proceedings of the 5th ACM Workshop on \nProgramming Languages meets Program Veri.cation, PLPV 11, pages 15 26, New York, NY, USA, 2011. ACM. \nISBN 978-1-4503-0487-0. Ana Bove, Peter Dybjer, and Ulf Norell. A brief overview of Agda a functional \nlanguage with dependent types. In TPHOLs 09: Proceedings of the 22nd International Conference on Theorem \nProving in Higher Order Logics, pages 73 78, Berlin, Heidelberg, 2009. Springer-Verlag. Edwin Brady, \nConor McBride, and James McKinna. Inductive families need not store their indices. In Stefano Berardi, \nMario Coppo, and Ferruccio Damiani, editors, TYPES, volume 3085 of Lecture Notes in Computer Science, \npages 115 129. Springer, 2003. Manuel M. T. Chakravarty, Gabriele Keller, and Simon Peyton Jones. As\u00adsociated \ntype synonyms. In ICFP 05: Proceedings of the Tenth ACM SIGPLAN International Conference on Functional \nProgramming, pages 241 253, New York, NY, USA, 2005. ACM. James Cheney and Ralf Hinze. First-class phantom \ntypes. CUCIS TR2003\u00ad1901, Cornell University, 2003. Cormac Flanagan. Hybrid type checking. In Proceedings \nof the 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 06, pages 245 256, \nNew York, NY, USA, 2006. ACM. doi: 10.1145/1111037.1111059. Matthew Gertz. Scaling up: The very busy \nbackground compiler. MSDN Magazine, 6 2005. URL http://msdn.microsoft.com/en-us/ magazine/cc163781.aspx. \nChristian Haack and J. B. Wells. Type error slicing in implicitly typed higher-order languages. Science \nof Computer Programming, 50:189 224, March 2004. ISSN 0167-6423. Fritz Henglein. Dynamic typing: syntax \nand proof theory. Science of Computer Programming, 22:197 230, June 1994. ISSN 0167-6423.  Oleg Kiselyov, \nSimon Peyton Jones, and Chung-chieh Shan. Fun with type functions. In A.W. Roscoe, Cliff B. Jones, and \nKenneth R. Wood, editors, Re.ections on the Work of C.A.R. Hoare, History of Computing, pages 301 331. \nSpringer London, 2010. doi: 10.1007/ 978-1-84882-912-1 14. Ralf L\u00a8ammel and Simon Peyton Jones. Scrap \nyour boilerplate with class: extensible generic functions. In Proceedings of the 10th ACM SIGPLAN International \nConference on Functional Programming, ICFP 05, pages 204 215, New York, NY, USA, 2005. ACM. doi: 10.1145/1086365. \n1086391. Daniel R. Licata and Robert Harper. A formulation of dependent ML with explicit equality proofs. \nTechnical Report CMU-CS-05-178, Carnegie Mellon University Department of Computer Science, 2005. Daniel \nR. Licata and Robert Harper. Canonicity for 2-dimensional type theory. In Proceedings of the 39th annual \nACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 12, pages 337 348, New York, \nNY, USA, 2012. ACM. doi: 10.1145/2103656. 2103697. Zhaohui Luo. Coercions in a polymorphic type system. \nMathematical Structures in Computer Science, 18(4):729 751, August 2008. ISSN 0960-1295. doi: 10.1017/S0960129508006804. \nAlexandre Miquel. The implicit calculus of constructions: extending pure type systems with an intersection \ntype binder and subtyping. In Pro\u00adceedings of the 5th International Conference on Typed Lambda Calculi \nand Applications, TLCA 01, pages 344 359, Berlin, Heidelberg, 2001. Springer-Verlag. ISBN 3-540-41960-8. \nNathan Mishra-Linger and Tim Sheard. Erasure and polymorphism in pure type systems. In Roberto Amadio, \neditor, Foundations of Software Science and Computational Structures, volume 4962 of Lecture Notes in \nComputer Science, pages 350 364. Springer Berlin / Heidelberg, 2008. Ulf Norell. Towards a practical \nprogramming language based on dependent type theory. PhD thesis, Department of Computer Science and Engineer\u00ading, \nChalmers University of Technology, September 2007. Simon Peyton Jones and John Launchbury. Unboxed values \nas .rst class citizens in a non-strict functional programming language. In FPCA91: Conference on Functional \nProgramming Languages and Computer Ar\u00adchitecture, pages 636 666, New York, NY, August 1991. ACM Press. \nSimon Peyton Jones and Andr\u00b4e Santos. A transformation-based optimiser for Haskell. Science of Computer \nProgramming, 32(1-3):3 47, Septem\u00adber 1998. Simon Peyton Jones, Dimitrios Vytiniotis, Stephanie Weirich, \nand Geoffrey Washburn. Simple uni.cation-based type inference for GADTs. In Proceedings of the 11th ACM \nSIGPLAN International Conference on Functional Programming, pages 50 61, New York, NY, USA, 2006. ACM \nPress. ISBN 1-59593-309-3. Simon Peyton Jones, Dimitrios Vytiniotis, Stephanie Weirich, and Mark Shields. \nPractical type inference for arbitrary-rank types. Jour\u00adnal of Functional Programming, 17(01):1 82, 2007. \ndoi: 10.1017/ S0956796806006034. Benjamin C. Pierce and David N. Turner. Local type inference. ACM Trans\u00adactions \non Programming Languages and Systems, 22(1):1 44, January 2000. ISSN 0164-0925. doi: 10.1145/345099.345100. \nFranc\u00b8ois Pottier and Didier R\u00b4emy. The essence of ML type inference. In Benjamin C. Pierce, editor, \nAdvanced Topics in Types and Programming Languages, chapter 10, pages 389 489. MIT Press, 2005. Tim Sheard \nand Emir Pasalic. Meta-programming with built-in type equal\u00adity. In Proc 4th International Workshop on \nLogical Frameworks and Meta-languages (LFM 04), pages 106 124, July 2004. Jeremy G. Siek and Walid Taha. \nGradual typing for functional languages. In Scheme and Functional Programming Workshop, pages 81 92, \nSeptem\u00adber 2006. Jeremy G. Siek and Manish Vachharajani. Gradual typing with uni.cation\u00adbased inference. \nIn Proceedings of the 2008 symposium on Dynamic languages, DLS 08, pages 7:1 7:12, New York, NY, USA, \n2008. ACM. doi: 10.1145/1408681.1408688. Martin Sulzmann, Manuel M. T. Chakravarty, Simon Peyton Jones, \nand Kevin Donnelly. System F with type equality coercions. In Proceedings of the 2007 ACM SIGPLAN Workshop \non Types in Language Design and Implementation, pages 53 66, New York, NY, USA, 2007. ACM. Nikhil Swamy, \nMichael Hicks, and Gavin M. Bierman. A theory of typed coercions and its applications. In Proceedings \nof the 14th ACM SIG-PLAN International Conference on Functional Programming, ICFP 09, pages 329 340, \nNew York, NY, USA, 2009. ACM. ISBN 978-1-60558\u00ad332-7. Nikhil Swamy, Juan Chen, Cedric Fournet, Pierre-Yves \nStrub, Karthikeyan Bharagavan, and Jean Yang. Secure distributed programming with value-dependent types. \nIn Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming, ICFP 11, pages \n266 278. ACM, September 2011. doi: 10.1145/2034773.2034811. The Coq Team. Coq. URL http://coq.inria.fr. \nSam Tobin-Hochstadt and Matthias Felleisen. Interlanguage migration: from scripts to programs. In Companion \nto the 21st ACM SIGPLAN Symposium on Object-Oriented Programming Systems, Languages, and Applications, \nOOPSLA 06, pages 964 974, New York, NY, USA, 2006. ACM. doi: 10.1145/1176617.1176755. Dimitrios Vytiniotis, \nSimon Peyton Jones, Tom Schrijvers, and Martin Sulzmann. OutsideIn(X): Modular Type inference with local \nassump\u00adtions. Journal of Functional Programming, 21, 2011. Stephanie Weirich, Dimitrios Vytiniotis, Simon \nPeyton Jones, and Steve Zdancewic. Generative type abstraction and type-level computation. In Proceedings \nof the 38th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 11, pages \n227 240, New York, NY, USA, 2011. ACM. ISBN 978-1-4503-0490-0. Andrew K. Wright and Robert Cartwright. \nA practical soft type system for scheme. ACM Transactions on Programming Languages and Systems, 19(1):87 \n152, January 1997. ISSN 0164-0925. doi: 10.1145/239912. 239917. Brent A. Yorgey, Stephanie Weirich, Julien \nCretin, Simon Peyton Jones, Dimitrios Vytiniotis, and Jos\u00b4e Pedro Magalh aes. Giving Haskell a promotion. \nIn Proceedings of the 8th ACM SIGPLAN Workshop on Types in Language Design and Implementation, TLDI 12, \npages 53 66, New York, NY, USA, 2012. ACM. doi: 10.1145/2103786.2103795.      \n\t\t\t", "proc_id": "2364527", "abstract": "<p>The Glasgow Haskell Compiler is an optimizing compiler that expresses and manipulates first-class equality proofs in its intermediate language. We describe a simple, elegant technique that exploits these equality proofs to support deferred type errors. The technique requires us to treat equality proofs as possibly-divergent terms; we show how to do so without losing either soundness or the zero-overhead cost model that the programmer expects.</p>", "authors": [{"name": "Dimitrios Vytiniotis", "author_profile_id": "81548018885", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P3804332", "email_address": "dimitris@microsoft.com", "orcid_id": ""}, {"name": "Simon Peyton Jones", "author_profile_id": "81100271851", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P3804333", "email_address": "simonpj@microsoft.com", "orcid_id": ""}, {"name": "Jos&#233; Pedro Magalh&#227;es", "author_profile_id": "81453643564", "affiliation": "Utrecht University, Utrecht, Netherlands", "person_id": "P3804334", "email_address": "jpm@cs.uu.nl", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364554", "year": "2012", "article_id": "2364554", "conference": "ICFP", "title": "Equality proofs and deferred type errors: a compiler pearl", "url": "http://dl.acm.org/citation.cfm?id=2364554"}