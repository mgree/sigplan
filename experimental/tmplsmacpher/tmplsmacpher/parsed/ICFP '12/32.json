{"article_publication_date": "09-09-2012", "fulltext": "\n Introspective Pushdown Analysis of Higher-Order Programs Christopher Earl Ilya Sergey Matthew Might \nUniversity of Utah KU Leuven University of Utah cwearl@cs.utah.edu ilya.sergey@cs.kuleuven.be might@cs.utah.edu \n David Van Horn Northeastern University dvanhorn@ccs.neu.edu Abstract In the static analysis of functional \nprograms, pushdown .ow anal\u00adysis and abstract garbage collection skirt just inside the boundaries of \nsoundness and decidability. Alone, each method reduces analy\u00adsis times and boosts precision by orders \nof magnitude. This work illuminates and conquers the theoretical challenges that stand in the way of \ncombining the power of these techniques. The challenge in marrying these techniques is not subtle: computing \nthe reachable control states of a pushdown system relies on limiting access dur\u00ading transition to the \ntop of the stack; abstract garbage collection, on the other hand, needs full access to the entire stack \nto compute a root set, just as concrete collection does. Introspective pushdown systems resolve this \ncon.ict. Introspective pushdown systems pro\u00advide enough access to the stack to allow abstract garbage \ncollection, but they remain restricted enough to compute control-state reacha\u00adbility, thereby enabling \nthe sound and precise product of pushdown analysis and abstract garbage collection. Experiments reveal \nsyn\u00adergistic interplay between the techniques, and the fusion demon\u00adstrates better-than-both-worlds precision. \nCategories and Subject Descriptors D.3.4 [Programming lan\u00adguages]: Processors Optimization; F.3.2 [Logics \nand Meanings of Programs]: Semantics of Programming Languages Program analysis, Operational semantics \nGeneral Terms Languages, Theory Keywords CFA2, pushdown systems, abstract interpretation, pushdown analysis, \nprogram analysis, abstract machines, abstract garbage collection, higher-order languages 1. Introduction \nThe recent development of a context-free1 approach to control\u00ad.ow analysis (CFA2) by Vardoulakis and \nShivers has provoked a 1 As in context-free language, not context-sensitivity. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 12 September 10 12, Copenhagen, Denmark. \nCopyright c &#38;#169; 2012 ACM 978-1-4503-1054-3/12/09. . . $15.00 seismic shift in the static analysis \nof higher-order programs [22]. Prior to CFA2, a precise analysis of recursive behavior had been a stumbling \nblock even though .ow analyses have an important role to play in optimization for functional languages, \nsuch as .ow\u00addriven inlining [13], interprocedural constant propagation [19] and type-check elimination \n[23]. While it had been possible to statically analyze recursion soundly, CFA2 made it possible to analyze \nrecursion precisely by matching calls and returns without approximation. In its pursuit of recursion, \nclever engineering steered CFA2 just shy of undecidability. The payoff is an order-of-magnitude reduction \nin analysis time and an order-of-magnitude increase in precision. For a visual measure of the impact, \nFigure 1 renders the abstract transition graph (a model of all possible traces through the pro\u00adgram) \nfor the toy program in Figure 2. For this example, pushdown analysis eliminates spurious return-.ow from \nthe use of recursion. But, recursion is just one problem of many for .ow analysis. For instance, pushdown \nanalysis still gets tripped up by the spurious cross-.ow problem; at calls to (id f) and (id g) in the \nprevious example, it thinks (id g) could be f or g. Powerful techniques such as abstract garbage collection \n[14] were developed to solve the cross-.ow problem.2 In fact, abstract garbage collection, by itself, \nalso delivers orders-of-magnitude im\u00adprovements to analytic speed and precision. (See Figure 1 again \nfor a visualization of that impact.) It is natural to ask: can abstract garbage collection and pushdown \nanlysis work together? Can their strengths be multiplied? At .rst glance, the answer appears to be a \ndisheartening No. 1.1 The problem: The whole stack versus just the top Abstract garbage collections seems \nto require more than push\u00addown analysis can decidably provide: access to the full stack. Ab\u00adstract garbage \ncollection, like its name implies, discards unreach\u00adable values from an abstract store during the analysis. \nLike con\u00adcrete garbage collection, abstract garbage collection also begins its sweep with a root set, \nand like concrete garbage collection, it must traverse the abstract stack to compute that root set. But, \npushdown 2 The cross-.ow problem arises because monotonicity prevents revoking a judgment like procedure \nf .ows to x, or procedure g .ows to x, once it s been made.   (3) with GC only: 105 states (4) with \npushdown analysis and abstract GC: 77 states Figure 1. We generated an abstract transition graph for \nthe same program from Figure 2 four times: (1) without pushdown analysis or abstract garbage collection; \n(2) with only abstract garbage col\u00adlection; (3) with only pushdown analysis; (4) with both pushdown analysis \nand abstract garbage collection. With only pushdown or abstract GC, the abstract transition graph shrinks \nby an order of magnitude, but in different ways. The pushdown-only analysis is confused by variables \nthat are bound to several different higher\u00adorder functions, but for short durations. The abstract-GC-only \nis confused by non-tail-recursive loop structure. With both techniques enabled, the graph shrinks by \nnearly half yet again and fully recov\u00aders the control structure of the original program. (define (id \nx) x) (define (f n) (cond [(<= n 1) 1] [else (* n (f (-n 1)))])) (define (g n) (cond [(<= n 1) 1] [else \n(+ (* n n) (g (-n 1)))])) (print (+ ((id f) 3) ((id g) 4))) Figure 2. A small example to illuminate \nthe strengths and weak\u00adnesses of both pushdown analysis and abstract garbage collection. systems are \nrestricted to viewing the top of the stack (or a bounded depth) a condition violated by this traversal. \nFortunately, abstract garbage collection does not need to arbitrarily modify the stack. In fact, it does \nnot even need to know the order of the frames; it only needs the set of frames on the stack. We .nd a \nricher class of machine introspective pushdown systems which retains just enough restrictions to compute \nreachable control states, yet few enough to enable abstract garbage collection. It is therefore possible \nto fuse the full bene.ts of abstract garbage collection with pushdown analysis. The dramatic reduction \nin ab\u00adstract transition graph size from the top to the bottom in Figure 1 (and echoed by later benchmarks) \nconveys the impact of this fusion. Secondary motivations There are three strong secondary motiva\u00adtions \nfor this work: (1) bringing context-sensitivity to pushdown analysis; (2) exposing the context-freedom \nof the analysis; and (3) enabling pushdown analysis without continuation passing style. In CFA2, monovariant \n(0CFA-like) context-sensitivity is etched directly into the abstract semantics, which are in turn, phrased \nin terms of an explicit (imperative) summarization algorithm for a partitioned continuation-passing style. \nIn addition, the context-freedom of the analysis is buried implicitly inside this algorithm. No pushdown \nsystem or context-free gram\u00admar is explicitly identi.ed. A necessary precursor to our work was to make \nthe pushdown system in CFA2 explicit. A third motivation was to show that a transformation to continuation\u00adpassing \nstyle is unnecessary for pushdown analysis. In fact, push\u00addown analysis is arguably more natural over \ndirect-style programs. 1.2 Overview We .rst review preliminaries to set a consistent feel for terminology \nand notation, particularly with respect to pushdown systems. The derivation of the analysis begins with \na concrete CESK-machine\u00adstyle semantics for A-Normal Form .-calculus. The next step is an in.nite-state \nabstract interpretation, constructed by bounding the C(ontrol), E(nvironment) and S(tore) portions of \nthe machine while leaving the stack the K(ontinuation) unbounded. A simple shift in perspective reveals \nthat this abstract interpretation is a rooted pushdown system. We then introduce abstract garbage collection \nand quickly .nd that it violates the pushdown model with its traversals of the stack. To prove the decidability \nof control-state reachability, we formulate in\u00adtrospective pushdown systems, and recast abstract garbage \ncollec\u00adtion within this framework. We then show that control-state reach\u00adability is decidable for introspective \npushdown systems as well. We conclude with an implementation and empirical evaluation that shows strong \nsynergies between pushdown analysis and abstract garbage collection, including signi.cant reductions \nin the size of the abstract state transition graph.  1.3 Contributions We make the following contributions: \n1. Our primary contribution is demonstrating the decidability of fusing abstract garbage collection with \npushdown .ow analysis of higher-order programs. Proof comes in the form of a .xed\u00adpoint solution for \ncomputing the reachable control-states of an introspective pushdown system and an embedding of abstract \ngarbage collection as an introspective pushdown system. 2. We show that classical notions of context-sensitivity, \nsuch as k-CFA and poly/CFA, have direct generalizations in a push\u00addown setting: monovariance3 is not \nan essential restriction, as in CFA2. 3. We make the context-free aspect of CFA2 explicit: we clearly \nde.ne and identify the pushdown system. We do so by starting with a classical CESK machine and systematically \nabstracting until a pushdown system emerges. We also remove the orthogo\u00adnal frame-local-bindings aspect \nof CFA2, so as to directly solely on the pushdown nature of the analysis. 4. We remove the requirement \nfor CPS-conversion by synthesiz\u00ading the analysis directly for direct-style (in the form of A\u00adnormal form \nlambda-calculus). 5. We empirically validate claims of improved precision on a suite of benchmarks. \nWe .nd synergies between pushdown analysis and abstract garbage collection that makes the whole greater \nthat the sum of its parts.  2. Pushdown preliminaries The literature contains many equivalent de.nitions \nof pushdown machines, so we adapt our own de.nitions from Sipser [20]. Read\u00aders familiar with pushdown \ntheory may wish to skip ahead. 2.1 Syntactic sugar When a triple (x, e, x1) is an edge in a labeled graph: \n\u00a31 x I x = (x, e, x1). 1 Similarly, when a pair (x, x) is a graph edge: 11 x I x= (x, x). We use both \nstring and vector notation for sequences: a1a2 ...an =\\a1,a2,...,an)= ga.  2.2 Stack actions, stack \nchange and stack manipulation Stacks are sequences over a stack alphabet G. To reason about stack manipulation \nconcisely, we .rst turn stack alphabets into stack\u00ad 3 Monovariance refers to an abstraction that groups \nall bindings to the same variable together: there is one abstract variant for all bindings to each variable. \n action sets; each character represents a change to the stack: push, pop or no change. For each character \n. in a stack alphabet G, the stack-action set G\u00b1 contains a push character .+; a pop character .-; and \na no-stack\u00ad change indicator, E: g . G\u00b1 ::= E [stack unchanged] || .+ .- for each . . G for each . . \nG [pushed .] [popped .]. In this paper, the symbol g represents some stack action. When we develop introspective \npushdown systems, we are going to need formalisms for easily manipulating stack-action strings and stacks. \nGiven a string of stack actions, we can compact it into a minimal string describing net stack change. \nWe do so through the operator L\u00b7J :G\u00b1* . G\u00b1* , which cancels out opposing adjacent push-pop stack actions: \nLg .+.- g 1J = Lg g 1JLg Eg 1J = Lg g 1J, so that LggJ = gg, if there are no cancellations to be made \nin the string gg. We can convert a net string back into a stack by stripping off the push symbols with \nthe stackify operator, h\u00b7l :G * \u00b1 -G * : 1(n)(n)1 h.+.+ ....+ l = \\.,...,.,.), and for convenience, \n[g ]= hLggJl. Notice the stackify operator is de.ned for strings containing only push actions. 2.3 Pushdown \nsystems A pushdown system is a triple M =(Q, G,d) where: 1. Q is a .nite set of control states; 2. G \nis a stack alphabet; and 3. d . Q \u00d7 G\u00b1 \u00d7 Q is a transition relation.  The set Q \u00d7G * is called the \ncon.guration-space of this pushdown system. We use PDSto denote the class of all pushdown systems. For \nthe following de.nitions, let M =(Q, G,d). The labeled transition relation (9-.M ) . (Q \u00d7 G * ) \u00d7 G\u00b1 \n\u00d7 (Q \u00d7 G * ) determines whether one con.guration may transition to another while performing the given \nstack action: HH1 (q, g.) 9-. (q1, g.) iff q I q. d [no change] M .- .-1 (q, . : g.) 9-. (q1, g.) iff \nq I q. d [pop] M .+ .+ 11 (q, g.) 9-. (q,. : g.) iff q I q. d [push]. M If unlabelled, the transition \nrelation (9-.) checks whether any stack action can enable the transition: g c 9-. c1 iff c 9-. c1 for \nsome stack action g. MM For a string of stack actions g1 ...gn: g1...gng1g2gn-1gn c0 9-. cn iff c0 9-. \nc1 9-. \u00b7\u00b7\u00b7 9-. cn-1 9-. cn, M MMM M for some con.gurations c0,...,cn. For the transitive closure:  \ng * . c 9-. c 1 iff c 9-. c 1 for some action string g . MM  2.4 Rooted pushdown systems A rooted pushdown \nsystem is a quadruple (Q, G, d, q0) in which (Q, G,d) is a pushdown system and q0 . Q is an initial (root) \nstate. RPDSis the class of all rooted pushdown systems. For a rooted pushdown system M =(Q, G, d, q0), \nwe de.ne the reachable-from-root transition relation: g * g1 c 9--. c 1 iff (q0, \\)) 9-. c and c 9-. \nc . M MM In other words, the root-reachable transition relation also makes sure that the root control \nstate can actually reach the transition. We overload the root-reachable transition relation to operate \non control states: gg q 9--. q 1 iff (q,g.) 9--. (q 1 , g. 1) for some stacks g., g. 1 . MM For both \nroot-reachable relations, if we elide the stack-action label, then, as in the un-rooted case, the transition \nholds if there exists some stack action that enables the transition: g q 9--. q 1 iff q 9--. q 1 for \nsome action g. MM 2.5 Computing reachability in pushdown systems A pushdown .ow analysis can be construed \nas computing the root\u00adreachable subset of control states in a rooted pushdown system, M =(Q, G, d, q0): \n q : q0 9--. q M Reps et. al and many others provide a straightforward summariza\u00adtion algorithm to compute \nthis set [1, 8, 17, 18]. Our preliminary report also offers a reachability algorithm tailored to higher-order \nprograms [4].  2.6 Nondeterministic .nite automata In this work, we will need a .nite description of \nall possible stacks at a given control state within a rooted pushdown system. We will exploit the fact \nthat the set of stacks at a given control point is a regular language. Speci.cally, we will extract a \nnondeterministic .nite automaton accepting that language from the structure of a rooted pushdown system. \nA nondeterministic .nite automaton (NFA) is a quintuple M =(Q, S, d, q0,F ): Q is a .nite set of control \nstates;  S is an input alphabet;  d . Q \u00d7 (S .{E}) \u00d7 Q is a transition relation.  q0 is a distinguished \nstart state.  F . Q is a set of accepting states.  We denote the class of all NFAs as NFA. 3. Setting: \nA-Normal Form .-calculus Since our goal is analysis of higher-order languages, we operate on the .-calculus. \nTo simplify presentation of the concrete and abstract c . Conf = Exp \u00d7 Env \u00d7 Store \u00d7 Kont [con.gurations] \n. . Env = Var -Addr [environments] s . Store = Addr . Clo [stores] clo . Clo = Lam \u00d7 Env [closures] . \n. Kont = Frame * [continuations] f . Frame = Var \u00d7 Exp \u00d7 Env [stack frames] a . Addr is an in.nite set \nof addresses [addresses]. Figure 3. The concrete con.guration-space. semantics, we choose A-Normal Form \n.-calculus. (This is a strictly cosmetic choice: all of our results can be replayed mutatis mutandis \nin the standard direct-style setting as well.) ANF enforces an order of evaluation and it requires that \nall arguments to a function be atomic: e . Exp ::= (let ((v call)) e) [non-tail call] | call [tail call] \n| \u00e6 [return] f, \u00e6 . Atom ::= v | lam [atomic expressions] lam . Lam ::= (. (v) e) [lambda terms] call \n. Call ::= (f \u00e6) [applications] v . Var is a set of identi.ers [variables].  We use the CESK machine \nof Felleisen and Friedman [5] to specify a small-step semantics for ANF. The CESK machine has an explicit \nstack, and under a structural abstraction, the stack component of this machine directly becomes the stack \ncomponent of a pushdown system. The set of con.gurations (Conf ) for this machine has the four expected \ncomponents (Figure 3). 3.1 Semantics To de.ne the semantics, we need .ve items: 1. I : Exp . Conf injects \nan expression into a con.guration: c0 = I(e)=(e, [], [], \\)). 2. A : Atom\u00d7Env \u00d7Store -Clo evaluates \natomic expressions: A(lam, ., s)=(lam,.) [closure creation] A(v, ., s)= s(.(v)) [variable look-up]. \n 3. (.) . Conf \u00d7 Conf transitions between con.gurations. (De.ned below.) 4. E : Exp .P (Conf ) computes \nthe set of reachable machine con.gurations for a given program:  E(e)= {c : I(e) . * c} . 5. alloc \n: Var \u00d7 Conf . Addr chooses fresh store addresses for newly bound variables. The address-allocation function \nis an opaque parameter in this semantics, so that the forthcom\u00ading abstract semantics may also parameterize \nallocation. This parameterization provides the knob to tune the polyvariance and context-sensitivity \nof the resulting analysis. For the sake of de.ning the concrete semantics, letting addresses be natural \nnumbers suf.ces, and then the allocator can choose the lowest unused address: Addr = N alloc(v, (e, \n., s, .)) = 1+max(dom(s)). Transition relation To de.ne the transition c . c 1, we need three rules. \nThe .rst rule handle tail calls by evaluating the function into a closure, evaluating the argument into \na value and then moving to the body of the closure s .-term: _ c __ _ c___ _ 11 1 ([[(f \u00e6)] , ., s, \n.) . (e,.,s,.) , where ([[(. (v) e)] ,.1)= A(f, ., s) a = alloc(v, c) .11 = .1[v 9. a] s1 = s[a 9. A(\u00e6, \n., s)]. Non-tail call pushes a frame onto the stack and evaluates the call: cc ([[(let ((v call)) e)] \n, ., s, .) . (call, ., s, (v, e, .): .) . Function return pops a stack frame: cc (\u00e6, ., s, (v, e, .1): \n.) . (e, .11,s1,.) , where a = alloc(v, c) .11 = .1[v 9. a] s1 = s[a 9. A(\u00e6, ., s)]. 4. Pushdown abstract \ninterpretation Our .rst step toward a static analysis is an abstract interpretation into an in.nite state-space. \nTo achieve a pushdown analysis, we simply abstract away less than we normally would. Speci.cally, we \nleave the stack height unbounded. Figure 4 details the abstract con.guration-space. To synthesize it, \nwe force addresses to be a .nite set, but crucially, we leave the stack untouched. When we compact the \nset of addresses into a .nite set, the machine may run out of addresses to allocate, and when it does, \nthe pigeon-hole principle will force multiple closures to reside at the same address. As a result, we \nhave no choice but to force the range of the store to become a power set in the abstract con.guration-space. \nThe abstract transition relation has components analogous to those from the concrete semantics: Program \ninjection The abstract injection function I : Exp . Conf pairs an expression with an empty environment, \nan empty store and an empty stack to create the initial abstract con.guration: c 0 = I(e)=(e, [], [], \n\\)). Atomic expression evaluation The abstract atomic expression evaluator, A : Atom \u00d7 EStore .P(E Env \n\u00d7 CClo), returns the value of an atomic expression in the context of an environment and a store; it returns \na set of abstract closures: ., .)} [closure creation]A(lam, s)= {(lam, A (v, ., s ) = s ( .(v)) [variable \nlook-up]. Conf Env \u00d7 CKont [con.gurations] c . C= Exp \u00d7 EStore \u00d7 A. . E= Var -Addr [environments] Env \nA s . CAE Store = Addr .PClo[stores] dClo Env clo . E= Lam \u00d7 E[closures] . . AC* Kont = Frame [continuations] \n f . C= Var \u00d7 Exp \u00d7 E[stack frames] Frame Env a . A[addresses]. Addr is a .nite set of addresses Figure \n4. The abstract con.guration-space. Reachable con.gurations The abstract program evaluator E : Exp .P(C \nConf ) returns all of the con.gurations reachable from the initial con.guration: E (e)= c : I (e) r * \nc . Because there are an in.nite number of abstract con.gurations, a na\u00a8ive implementation of this function \nmay not terminate. Transition relation The abstract transition relation (r) . C\u00d7 C Conf Conf has three \nrules, one of which has become non\u00addeterministic. A tail call may fork because there could be multiple \nabstract closures that it is invoking:  _ c __ _ c___ _ 11 1 ([[(f \u00e6)] , ., .) r .s.) , where s, \n(e, , , ([[(. (v) e)] ,. 1) .A(f, s) ., A a = alloc(v, c ) .11 .1 = [v 9. a ] s 1 = a 9. ., s u [ A(\u00e6, \ns)]. We de.ne all of the partial orders shortly, but for stores: ( s u s 1)( a)= s ( a) . s 1( a). \nA non-tail call pushes a frame onto the stack and evaluates the call: c c ([[(let ((v call)) e)] , s, \n(call, s, (v, e, .) . ., .) r ., .): A function return pops a stack frame: c c .11 (\u00e6, s, (v, e, . \n1.) r ,s 1 .) , where ., ): (e, , A a = alloc(v, c ) . 11 = . 1[v 9. a ] s 1 = a 9. ., s u [ A(\u00e6, s)]. \n Allocation: Polyvariance and context-sensitivity In the abstract semantics, the abstract allocation \nfunction AConf . alloc : Var \u00d7 CA Addr determines the polyvariance of the analysis. In a control\u00ad.ow \nanalysis, polyvariance literally refers to the number of abstract addresses (variants) there are for \neach variable. An advantage of this framework over CFA2 is that varying this abstract allocation function \ninstantiates pushdown versions of classical .ow analyses. All of the following allocation approaches \ncan be used with the abstract semantics. The abstract allocation function is a parameter to the analysis. \n Monovariance: Pushdown 0CFA Pushdown 0CFA uses vari\u00adables themselves for abstract addresses: A Addr \n= Var alloc(v, c ) = v. Context-sensitive: Pushdown 1CFA Pushdown 1CFA pairs the variable with the current \nexpression to get an abstract address: A Addr = Var \u00d7 Exp alloc(v, (e, s, ., .)) = (v, e). Polymorphic \nsplitting: Pushdown poly/CFA Assuming we com\u00adpiled the program from a programming language with let-bound \npolymorphism and marked which functions were let-bound, we can enable polymorphic splitting: A Addr = \nVar + Var \u00d7 Exp (v, [ (f \u00e6)]]) f is let-bound alloc(v, ([[(f \u00e6)] , s, ., .)) = v otherwise. Pushdown \nk-CFA For pushdown k-CFA, we need to look beyond the current state and at the last k states. By concatenating \nthe expressions in the last k states together, and pairing this sequence with a variable we get pushdown \nk-CFA: A Addr = Var \u00d7 Expk A alloc(v, \\(e1,. 1,s 1,. 1),...))=(v, \\e1,...,ek)). 4.1 Partial orders For \neach set X inside the abstract con.guration-space, we use the natural partial order, ( X ) . X \u00d7 X . \nAbstract addresses and syntactic sets have .at partial orders. For the other sets, the partial order \nlifts: point-wise over environments: . . 1 iff . (v)= . 1(v) for all v . dom( .); component-wise over \nclosures: (lam,. ) (lam,. 1) iff . . 1; point-wise over stores: s s 1 iff s ( a) s 1( a) for all a . \ndom( s); component-wise over frames: (v, e, . ) (v, e, . 1) iff . . 1; element-wise over continuations: \n11 1 \\ f1,..., fn) \\f 1,..., fn) iff f i f i; and component-wise across con.gurations: 1111 (e, s, .s.. \n1 and s. . . ., .) (e, , , ) iff .s 1 and  4.2 Soundness To prove soundness, an abstraction map a connects \nthe concrete and abstract con.guration-spaces: a(e, ., s, .)=(e, a(.),a(s),a(.)) a(.)= .v.a(.(v)) a(s)= \n. {a(s(a))} a. a(a)= a a\\f1,...,fn) = \\a(f1),...,a(fn)) a(v, e, .)=(v, e, a(.)) a(a) is determined by \nthe allocation functions. It is then easy to prove that the abstract transition relation simulates the \nconcrete transition relation: Theorem 4.1. If: a(c) c and c . c 1 , 1 . C then there must exist c Conf \nsuch that: a(c 1) c 1 and c r c 1 . Proof. The proof follows by case-wise analysis on the type of the \nexpression in the con.guration. It is a straightforward adaptation of similar proofs, such as that of \n[11] for k-CFA. 5. The shift: From abstract CESK to rooted PDS In the previous section, we constructed \nan in.nite-state abstract interpretation of the CESK machine. The in.nite-state nature of the abstraction \nmakes it dif.cult to see how to answer static analysis questions. Consider, for instance, a control .ow-question: \nAt the call site (f \u00e6), may a closure over lam be called? If the abstracted CESK machine were a .nite-state \nmachine, an algorithm could answer this question by enumerating all reach\u00adable con.gurations and looking \nfor an abstract con.guration ([[(f \u00e6)] , ., .) in which (lam, ) .A (f, s). However, be\u00ad s, ., cause the \nabstracted CESK machine may contain an in.nite number of reachable con.gurations, enumeration is not \nan option. Fortunately, a shift in perspective reveals the abstracted CESK machine to be a rooted pushdown \nsystem. This shift permits the use of a control-state reachability algorithm in place of exhaustive search \nof the con.guration-space. In this shift, a control-state is an expression-environment-store triple, \nand a stack character is a frame. Figure 5 de.nes the program-to-RPDS conversion function A PDS : Exp \n. RPDS. At this point, we can compute the root-reachable control states using a straightforward summarization \nalgorithm [1, 17, 18]. This is the essence of CFA2. 6. Introspection for abstract garbage collection \nAbstract garbage collection [14] yields large improvements in pre\u00adcision by using the abstract interpretation \nof garbage collection to make more ef.cient use of the .nite address space available during analysis. \nBecause of the way abstract garbage collection operates, it A PDS(e)=(Q, G, d, q0), where Q = Exp \u00d7 \nEStore Env \u00d7 CG= Frame C (q, E, q1) . d iff (q, . ) r (q 1 ,. ) for all . (q, f -,q 1) . d iff (q, f \n: .) r (q 1 ,. ) for all . 11 11 (q, f +,q ) . d iff (q, . ) r (q ,f : .) for all . (q0, \\))= I (e). \nA Figure 5. PDS : Exp . RPDS. grants exact precision to the .ow analysis of variables whose bind\u00adings \ndie between invocations of the same abstract context. Because pushdown analysis grants exact precision \nin tracking return-.ow, it is clearly advantageous to combine these techniques. Unfortu\u00adnately, as we \nshall demonstrate, abstract garbage collection breaks the pushdown model by requiring full stack inspection \nto discover the root set. Abstract garbage collection modi.es the transition relation to con\u00adduct a stop-and-copy \ngarbage collection before each transition. To do this, we de.ne a garbage collection function G : C. \nConf C Conf on con.gurations: c G(e, s, ., c), ., .)=(e, s|Reachable( .), where the pipe operation f|S \nyields the function f, but with inputs not in the set S mapped to bottom the empty set. The reachability \nfunction Reachable : Conf . Addr) .rst computes the CP( A root set, and then the transitive closure of \nan address-to-address adjacency relation: c _ __ _ * Reachable(e, s, a0 . Root( a0 a ., .)= a : c) \nand , s - CP( A where the function Root : Conf . Addr) .nds the root addresses: Root(e, ., s, . ) = \nrange( .) . StackRoot( .), and the StackRoot : Kont .P( A AAddr) function .nds roots down the stack: \n StackRoot\\(v1,e1,. 1),..., (vn,en,. n)) = range( .i), i and the relation (-) . AStore \u00d7 A Addr \u00d7 CAddr \nconnects adjacent addresses: a 1 iff there exists (lam,. ) . s ( a) such that a 1 . range( .). a \u00ad s \nThe new abstract transition relation is thus the composition of abstract garbage collection with the \nold transition relation: (rGC)=(r) . G Problem: Stack traversal violates pushdown constraint In the formulation \nof pushdown systems, the transition relation is re\u00adstricted to looking at the top frame, and even in \nless restricted for\u00admulations, at most a bounded number of frames can be inspected. Thus, the relation \n(rGC) cannot be computed as a straightforward pushdown analysis using summarization. Solution: Introspective \npushdown systems To accomodate the richer structure of the relation (rGC), we now de.ne introspec\u00adtive \npushdown systems. Once de.ned, we can embed the garbage\u00adcollecting abstract interpretation within this \nframework, and then focus on developing a control-state reachability algorithm for these systems. An \nintrospective pushdown system is a quadruple M =(Q, G, d, q0): 1. Q is a .nite set of control states; \n 2. G is a stack alphabet; 3. d . Q \u00d7 G * \u00d7 G\u00b1 \u00d7 Q is a transition relation; and 4. q0 is a distinguished \nroot control state.  The second component in the transition relation is a realizable stack at the given \ncontrol-state. This realizable stack distinguishes an introspective pushdown system from a general pushdown \nsystem. IPDSdenotes the class of all introspective pushdown systems. Determining how (or if) a control \nstate q transitions to a control state q 1, requires knowing a path taken to the state q. Thus, we need \nto de.ne reachability inductively. When M =(Q, G, d, q0), transition from the initial control state considers \nonly empty stacks: g q0 9--. q iff (q0, \\), g, q) . d. M For non-root states, the paths to that state \nmatter, since they deter\u00admine the stacks realizable with that state: g g q 9--. q 1 iff there exists \ng such that q0 9--. q and (q, [g ], g, q 1) . d, M M (g1,...,gn) g1 g2 gn 1 where q 9--. q 1 iff q 9--. \nq1 9--. \u00b7\u00b7\u00b7 9--. q . M MMM 6.1 Garbage collection in introspective pushdown systems To convert the garbage-collecting, \nabstracted CESK machine into an introspective pushdown system, we use the function IPDS : CExp . IPDS: \nC IPDS(e)=(Q, G, d, q0) Q = Exp \u00d7 EStoreEnv \u00d7 C C G= Frame (q, ) . d iff .) r (q 1 ,. ) ., E, q1G(q, \n(q, f : ., f -,q 1) . d iff G (q, f : .) r (q 1 ,. ) (q, f+,q 1G(q, 1 ,.) ., ) . d iff .) r (qf : (q0, \n\\))= I (e). 7. Introspective reachability via Dyck state graphs Having de.ned introspective pushdown \nsystems and embedded our abstract, garbage-collecting semantics within them, we are ready to de.ne control-state \nreachability for IDPSs. We cast our reachability algorithm for introspective pushdown sys\u00adtems as .nding \na .xed-point, in which we incrementally accrete the reachable control states into a Dyck state graph. \nA Dyck state graph is a quadruple G =(S, G, E, s0), in which: 1. S is a .nite set of nodes; 2. G is \na set of frames; 3. E . S \u00d7 G\u00b1 \u00d7 S is a set of stack-action edges; and 4. s0 is an initial state; \n such that for any node s . S, it must be the case that: * (s0, \\)) 9-. (s, g.) for some stack g.. G \nIn other words, a Dyck state graph is equivalent to a rooted push\u00addown system in which there is a legal \npath to every control state from the initial control state.4 We use DSG to denote the class of Dyck state \ngraphs. (Clearly, DSG . RPDS.) Our goal is to compile an implicitly-de.ned introspective push\u00addown system \ninto an explicited-constructed Dyck state graph. Dur\u00ading this transformation, the per-state path considerations \nof an in\u00adtrospective pushdown are baked into the Dyck state graph. We can formalize this compilation \nprocess as a map, DSG : IPDS . DSG. Given an introspective pushdown system M =(Q, G, d, q0), its equivalent \nDyck state graph is DSG(M)=(S, G,E,q0), where s0 = q0, the set S contains reachable nodes: g S = q : \nq0 9--. q for some stack-action sequence g , M and the set E contains reachable edges: gg E = q I q 1 \n: q 9--. q 1 . M Our goal is to .nd a method for computing a Dyck state graph from an introspective pushdown \nsystem. 7.1 Compiling to Dyck state graphs We now turn our attention to compiling an introspective pushdown \nsystem (de.ned implicitly) into a Dyck state graph (de.ned explic\u00aditly). That is, we want an implementation \nof the function DSG. To do so, we .rst phrase the Dyck state graph construction as the least .xed point \nof a monotonic function. This formulation provides a straightforward iterative method for computing the \nfunction DSG. The function F : IPDS . (DSG . DSG) generates the mono\u00adtonic iteration function we need: \nF(M)= f, where M =(Q, G, d, q0) f(S, G, E, s0)=(S1 , G,E1 ,s0), where S1 = S . s 1 : s . S and s 9--. \ns 1 .{s0} M g g 11 1 E= E . s I s : s . S and s 9--. s . M Given an introspective pushdown system M, \neach application of the function F(M) accretes new edges at the frontier of the Dyck state graph. 4 We \nchose the term Dyck state graph because the sequences of stack actions along valid paths through the \ngraph correspond to substrings in Dyck languages. A Dyck language is a language of balanced, colored \nparentheses. In this case, each character in the stack alphabet is a color.  7.2 Computing a round of \nF The formalism obscures an important detail in the computation of an iteration: the transition relation \n(9--. ) for the introspective pushdown system must compute all possible stacks in determining whether \nor not there exists a transition. Fortunately, this is not as onerous as it seems: the set of all possible \nstacks for any given control-point is a regular language, and the .nite automaton that encodes this language \ncan be lifted (or read off) the structure of the Dyck state graph. The function Stacks : DSG . S . NFA \nperforms exactly this extraction: M Stacks(S, G, E, s0)(s)=(S, G, d, s0, {s}), where (s 1, ., s11) . \nd if (s 1,.+,s 11) . E g (s 1, E, s11) . d if s 1 9--. s 11 and [g ]= E. M  7.3 Correctness Once the \nalgorithm reaches a .xed point, the Dyck state graph is complete: Theorem 7.1. DSG(M) = lfp(F(M)). Proof. \nLet M =(Q, G, d, q0). Let f = F(M). Observe that lfp(f )= fn(\u00d8, G, \u00d8,q0) for some n. When N . M, then \nit easy to show that f(N) . M. Hence, DSG(M) . lfp(F(M )). To show DSG(M ) . lfp(F(M)), suppose this \nis not the case. Then, there must be at least one edge in DSG(M) that is not in lfp(F(M)). By the de.ntion \nof DSG(M), each edge must be part of a sequence of edges from the initial state. Let (s, g, s 1) be the \n.rst edge in its sequence from the initial state that is not in lfp(F(M). Because the proceeding edge \nis in lfp(F(M)), the state s is in lfp(F(M)). Let m be the lowest natural number such that s appears \nin f m(M). By the de.nition of f, this edge must appear in fm+1 (M), which means it must also appear \nin lfp(F(M )), which is a contradiction. Hence, DSG(M) . lfp(F(M)). 7.4 Complexity While decidability \nis the goal, it is straightforward to determine the complexity of this na\u00a8ive .xed-point method. To determine \nthe complexity of this algorithm, we ask two questions: how many times would the algorithm invoke the \niteration function in the worst case, and how much does each invocation cost in the worst case? The size \nof the .nal Dyck state graph bounds the run-time of the algorithm. Suppose the .nal Dyck state graph \nhas m states. In the worst case, the iteration function adds only a single edge each time. Between any \ntwo states, there is one E-edge, one push edge, or some number of pop edges (at most |G|). Since there \nare at most |G|m 2 edges in the .nal graph, the maximum number of iterations is |G|m 2 . The cost of \ncomputing each iteration is harder to bound. The cost of determining whether to add a push edge is constant, \nas is the cost of adding an E-edge. So the cost of determining all new push edges and new E-edges to \nadd is constant. Determining whether or not to add a pop edge is expensive. To add the pop edge s I.- \ns 1, we must prove that there exists a con.guration-path to the control state s, in which the character \n. is on the top of the stack. This reduces to a CFL-reachability query [9] at each node, the cost of \nwhich is O(|G\u00b1|3 m 3) [8]. To summarize, in terms of the number of reachable control states, the complexity \nof this naive algorithm is: O((|G|m 2) \u00d7 (|G\u00b1|3 m 3)) = O(|G|4 m 5). (As with summarization, it is possible \nto maintain a work-list and introduce an E-closure graph to avoid spurious recomputation. This ultimately \nreduces complexity to O(|G|2 m 4).) 8. Implementation and evaluation We have developed an implementation \nto produce the Dyck state graph of an introspective pushdown system. While the .xed-point computation \n7.2 could be rendered directly as functional code, ex\u00adtending the classical summarization-based algorithm \nfor pushdown reachability to introspective pushdown systems yields better per\u00adformance. In this section \nwe present a variant of such an algorithm and discuss results from an implementation that can analyze \na large subset of the Scheme programming language. 8.1 Iterating over a DSG: An implementor s view To \nsynthesize a Dyck state graph from an introspective pushdown system, it is built incrementally node by \nnode, edge by edge. The na\u00a8ive .xed point algorithm presented earlier, if implemented liter\u00adally, would \n(in the worst case) have to re-examine the entire DSG to add each edge. To avoid such re-examination, \nour implementation adds E-summary edges to the DSG. In short, an E-summary edge connects two control \nstates if there exists a path between them with no net stack change that is, all pushes are cancelled \nby corresponding pops. With E-summary edges available, any change to the graph can be propagated directly \nto where it has an effect, and then any new E-summary edges that propagation implies are added. Whereas \nthe correspondence between CESK and an IPDS is rela\u00adtively straightforward, the relationship between \na DSG and its orig\u00adinal IPDS is complicated by the fact that the IPDS keeps track of the whole stack, \nwhereas the DSG distributes (the same) stack in\u00adformation throughout its internal structure. A classic \nreachability-based analysis for a pushdown system re\u00adquires two mutually-dependent pieces of information \nin order to add another edge: 1. The topmost frame on a stack for a given control state q. This is essential \nfor return transitions, as this frame should be popped from the stack and the store and the environment \nof a caller should be updated respectively. 2. Whether a given control state q is reachable or not from \nthe ini\u00adtial state q0 along realizable sequences of stack actions. For ex\u00adample, a path from q0 to q \nalong edges labeled push, pop, pop, push is not realizable: the stack is empty after the .rst pop, so \nthe second pop cannot happen let alone the subsequent push.  These two data are enough for a classic \npushdown reachability summarization to proceed one step further. However, the presence of an abstract \ngarbage collector, and the graduation to an introspec\u00adtive pushdown system, imposes the requirement for \na third item of data: 3. For a given control state q, what are all possible frames that could happen \nto be on the stack at the moment the IPDS is in the state q? It is possible to recompute these frames \nfrom scratch in each it\u00aderation using the NFA-extraction technique we described. But, it is easier to \nmaintain per-node summaries, in the same spirit as E\u00adsummary edges. A version of the classic pushdown \nsummarization algorithm that maintains the .rst two items is presented in [4], so we will just outline \nthe key differences here. The crux of the algorithm is to maintain for each node q 1 in the DSG, a set \nof E-predecessors, i.e., nodes q, such that q 9--. g 1 M q and [g ]= E. In fact, only two out of three \nkinds of transitions can cause a change to the set of E-predecessors for a particular node q: an addition \nof an E-edge or a pop edge to the DSG. It is easy to see why the second action might introduce new E-paths \nand, therefore, new E-predecessors. Consider, for example, adding the .--edge q I.- q 1 into the following \ngraph: 1 q0 .+ . qq H . q1 As soon this edge drops in, there becomes an implicit E-edge between q0 and \nq1 because the net stack change between them is empty; the resulting graph looks like: H .+ .- . 1 H \nq0 q . q . q1  where we have illustrated the implicit E-edge as a dashed line. A little re.ection on \nE-predecessors and top frames reveals a mutual dependency between these items during the construction \nof a DSG. Informally: A top frame for a state q can be pushed as a direct predecessor, or as a direct \npredecessor to an E-predecessor.  When a new E-edge q -H1 is added, all E-predecessors of q  . q become \nalso E-predecessors of q 1. That is, E-summary edges are transitive. .- When a .--pop-edge q - . q 1 \nis added, new E-predecessors of a state q1 can be obtained by checking if q 1 is an E-predecessor of \nq1 and examining all existing E-predecessors of q, such that .+ is their possible top frame: this situation \nis similar to the one depicted in the example above. The third component all possible frames on the stack \nfor a state q is straightforward to compute with E-predecessors: starting from q, trace out only the \nedges which are labeled E (summary or otherwise) or .+. The frame for any action .+ in this trace is \na possible stack action. Since these sets grow monotonically, it is easy to cache the results of the \ntrace, and in fact, propagate incre\u00admental changes to these caches when new E-summary or .+ nodes are \nintroduced. Our implementation directly re.ects the optimiza\u00adtions discussed above. 8.2 Experimental \nresults A fair comparison between different families of analyses should compare both precision and speed. \nWe have extended an existing Figure 6. Benchmark results. The .rst three columns provide the name of \na benchmark, the number of expressions and variables in the program in the ANF, respectively. For each \nof eight combinations of pushdown analysis, k .{0, 1} and garbage collection on or off, the .rst two \ncolumns in a group show the number of control states and transitions/DSG edges computed during the analysis \n(for both less is better). The third column presents the amount of singleton variables, i.e, how many \nvariables have a single lambda .ow to them (more is better). Inequalities for some results denote the \ncase when the analysis did not .nish within 30 minutes. For such cases we can only report an upper Program \nExp Var k k-CFA k-PDCFA k-CFA + GC k-PDCFA + GC mj09 19 8 0 83 107 4 38 38 4 36 39 4 33 32 4 1 454 812 \n1 44 48 1 34 35 1 32 31 1 eta 21 13 0 63 74 4 34 34 6 28 27 8 28 27 8 1 33 33 8 32 31 8 28 27 8 28 27 \n8 kcfa2 20 10 0 194 236 3 36 35 4 35 43 4 35 34 4 1 970 1935 1 87 144 2 35 34 2 35 34 2 kcfa3 25 13 0 \n272 327 4 58 63 5 53 52 5 53 52 5 1 > 7119 > 14201 = 1 1761 4046 2 53 52 2 53 52 2 blur 40 20 0 > 1419 \n> 2435 = 3 280 414 3 274 298 9 164 182 9 1 261 340 9 177 189 9 169 189 9 167 182 9 loop2 41 14 0 228 \n252 4 113 122 4 86 93 4 70 74 4 1 > 10867 > 16040 = 3 411 525 3 151 163 3 145 156 3 sat 63 31 0 > 5362 \n> 7610 = 6 775 979 6 1190 1567 6 321 384 6 1 > 8395 > 12391 = 6 7979 10299 6 982 1330 7 107 106 13 bound \nof singleton variables as this number can only decrease. implementation of k-CFA to optionally enable \npushdown analysis, abstract garbage collection or both. Our implementation source and benchmarks are \navailable: http://github.com/ilyasergey/reachability As expected, the fused analysis does at least as \nwell as the best of either analysis alone in terms of singleton .ow sets (a good metric for program optimizability) \nand better than both in some cases. Also worthy of note is the dramatic reduction in the size of the \nabstract transition graph for the fused analysis even on top of the already large reductions achieved \nby abstract gabarge collection and pushdown .ow analysis individually. The size of the abstract transition \ngraph is a good heuristic measure of the temporal reasoning ability of the analysis, e.g., its ability \nto support model\u00adchecking of safety and liveness properties [12]. In order to exercise both well-known \nand newly-presented in\u00adstances of CESK-based CFAs, we took a series of small bench\u00admarks exhibiting archetypal \ncontrol-.ow patterns (see Figure 6). Most benchmarks are taken from the CFA literature: mj09 is a run\u00adning \nexample from the work of Midtgaard and Jensen designed to exhibit a non-trivial return-.ow behavior, \neta and blur test com\u00admon functional idioms, mixing closures and eta-expansion, kcfa2 and kcfa3 are two \nworst-case examples extracted from Van Horn and Mairson s proof of k-CFA complexity [21], loop2 is an \nex\u00adample from the Might s dissertation that was used to demonstrate the impact of abstract GC [11, Section \n13.3], sat is a brute-force SAT-solver with backtracking. 8.2.1 Comparing precision In terms of precision, \nthe fusion of pushdown analysis and abstract garbage collection substantially cuts abstract transition \ngraph sizes over one technique alone. We also measure singleton .ow sets as a heuristic metric for preci\u00adsion. \nSingleton .ow sets are a necessary precursor to optimizations such as .ow-driven inlining, type-check \nelimination and constant propagation. Here again, the fused analysis prevails as the best-of\u00ador better-than-both-worlds. \n Program mj09 eta kcfa2 kcfa3 blur loop2 sat 0-CFA 111 E E E 111 E 211 E 8 711 3611 111 8 4511 0-PDCFA \nE 111 E E E 111 E 111 21 5011 2911 1611 61 191 1-CFA 411 E 111 E 2411 E 8 111 41 3011 8 511 8 31 1-PDCFA \nE E E E 111 E 5811 211 1111 5511 131 21 121 3711 Figure 7. We ran our benchmark suite on a 2 Core 2.66 \nGHz OS X machine with 4 Gb RAM. For each of the four analyses the left column denotes the values obtained \nwith no abstract collection, and the right one with GC on. The results of the analyses are presented \nin minutes (1) or seconds (11), where E means a value less than 1 second and 8 stands for an analysis, \nwhich has been interrupted due to the an execution time greater than 30 minutes. Running on the benchmarks, \nwe have revalidated hypotheses about the improvements to precision granted by both pushdown analy\u00adsis \n[22] and abstract garbage collection [11]. The table in Figure 6 contains our detailed results on the \nprecision of the analysis. 8.2.2 Comparing speed In the original work on CFA2, Vardoulakis and Shivers \npresent experimental results with a remark that the running time of the analysis is proportional to the \nsize of the reachable states [22, Section 6]. There is a similar correlation in the fused analysis, but \nit is not as strong or as absolute. From examination of the results, this appears to be because small \ngraphs can have large stores inside each state, which increases the cost of garbage collection (and thus \ntransition) on a per-state basis, and there is some additional per\u00adtransition overhead involved in maintaining \nthe caches inside the Dyck state graph. Table 7 collects absolute execution times for comparison. It \nfollows from the results that pure machine-style k-CFA is always signi.cantly worse in terms of execution \ntime than either with GC or push-down system. The histogram on Figure 8 presents Figure 8. Analysis times \nrelative to worst (= 1) in class; smaller is better. On the left is the monovariant 0CFA class of analyses, \non the right is the polyvariant 1CFA class of analyses. (Non-GC k-CFA omitted.)  normalized relative \ntimes of analyses executions. About half the time, the fused analysis is faster than one of pushdown \nanalysis or abstract garbage collection. And about a tenth of the time, it is faster than both.5 When \nthe fused analysis is slower than both, it is generally not much worse than twice as slow as the next \nslowest analysis. Given the already substantial reductions in analysis times provided by collection and \npushdown anlysis, the amortized penalty is a small and acceptable price to pay for improvements to precision. \n9. Related work Garbage-collecting pushdown control-.ow analysis draws on work in higher-order control-.ow \nanalysis [19], abstract machines [5] and abstract interpretation [3]. Context-free analysis of higher-order \nprograms The motivating work for our own is Vardoulakis and Shivers very recent discovery of CFA2 [22]. \nCFA2 is a table-driven summarization algorithm that exploits the balanced nature of calls and returns \nto improve return\u00ad.ow precision in a control-.ow analysis. Though CFA2 exploits context-free languages, \ncontext-free languages are not explicit in its formulation in the same way that pushdown systems are \nexplicit in our presentation of pushdown .ow analysis. With respect to CFA2, our pushdown .ow analysis \nis also polyvariant/context-sensitive (whereas CFA2 is monovariant/context-insensitive), and it covers \ndirect-style. On the other hand, CFA2 distinguishes stack-allocated and store\u00adallocated variable bindings, \nwhereas our formulation of pushdown control-.ow analysis does not: it allocates all bindings in the store. \nIf CFA2 determines a binding can be allocated on the stack, that binding will enjoy added precision during \nthe analysis and is not subject to merging like store-allocated bindings. While we could incorporate \nsuch a feature in our formulation, it is not necessary for achieving pushdownness, and in fact, it could \nbe added to classical .nite-state CFAs as well. 5 The SAT-solving bechmark showed a dramatic improvement \nwith the ad\u00addition of context-sensitivity. Evaluation of the results showed that context\u00adsensitivity \nprovided enough fuel to eliminate most of the non-determinism from the analysis. Calculation approach \nto abstract interpretation Midtgaard and Jensen [10] systematically calculate 0CFA using the Cousot\u00adCousot-style \ncalculational approach to abstract interpretation [2] applied to an ANF .-calculus. Like the present \nwork, Midtgaard and Jensen start with the CESK machine of Flanagan et al. [6] and employ a reachable-states \nmodel. The analysis is then constructed by composing well-known Galois connections to reveal a 0CFA incorporating \nreachability. The ab\u00adstract semantics approximate the control stack component of the machine by its top \nelement. The authors remark monomorphism materializes in two mappings: one mapping all bindings to the \nsame variable, the other merging all calling contexts of the same function. Essentially, the pushdown \n0CFA of Section 4 corre\u00adsponds to Midtgaard and Jensen s analysis when the latter map\u00adping is omitted \nand the stack component of the machine is not ab\u00adstracted. CFL-and pushdown-reachability techniques This \nwork also draws on CFL-and pushdown-reachability analysis [1, 8, 17, 18]. For instance, E-closure graphs, \nor equivalent variants thereof, ap\u00adpear in many context-free-language and pushdown reachability algorithms. \nFor our analysis, we implicitly invoked these methods as subroutines. When we found these algorithms \nlacking (as with their enumeration of control states), we developed Dyck state graph construction. CFL-reachability \ntechniques have also been used to compute clas\u00adsical .nite-state abstraction CFAs [9] and type-based \npolymorphic control-.ow analysis [16]. These analyses should not be confused with pushdown control-.ow \nanalysis, which is computing a fun\u00addamentally more precise kind of CFA. Moreover, Rehof and Fah\u00adndrich \ns method is cubic in the size of the typed program, but the types may be exponential in the size of the \nprogram. Finally, our technique is not restricted to typed programs. Model-checking higher-order recursion \nschemes There is ter\u00adminology overlap with work by Kobayashi [7] on model-checking higher-order programs \nwith higher-order recursion schemes, which are a generalization of context-free grammars in which produc\u00adtions \ncan take higher-order arguments, so that an order-0 scheme is a context-free grammar. Kobyashi exploits \na result by Ong [15] which shows that model-checking these recursion schemes is de\u00adcidable (but ELEMENTARY-complete) \nby transforming higher\u00adorder programs into higher-order recursion schemes. Given the generality of model-checking, \nKobayashi s technique may be considered an alternate paradigm for the analysis of higher\u00adorder programs. \nFor the case of order-0, both Kobayashi s tech\u00adnique and our own involve context-free languages, though \nours is for control-.ow analysis and his is for model-checking with respect to a temporal logic. After \nthese surface similarities, the techniques diverge. In particular, higher-order recursions schemes are \nlimited to model-checking programs in the simply-typed lambda-calculus with recursion. 10. Conclusion \nOur motivation was to further probe the limits of decidability for pushdown .ow analysis of higher-order \nprograms by enriching it with abstract garbage collection. We found that abstract garbage collection \nbroke the pushdown model, but not irreparably so. By casting abstract garbage collection in terms of \nan introspective pushdown system and synthesizing a new control-state reachability algorithm, we have \ndemonstrated the decidability of fusing two powerful analytic techniques. As a byproduct of our formulation, \nit was also easy to demon\u00adstrate how polyvariant/context-sensitive .ow analyses generalize to a pushdown \nformulation, and we lifted the need to transform to continuation-passing style in order to perform pushdown \nanalysis. Our empirical evaluation is highly encouraging: it shows that the fused analysis provides further \nlarge reductions in the size of the abstract transition graph a key metric for interprocedural control\u00ad.ow \nprecision. And, in terms of singleton .ow sets a heuristic metric for optimizability the fused analysis \nproves to be a better\u00adthan-both-worlds combination. Thus, we provide a sound, precise and polyvariant \nintrospective pushdown analysis for higher-order programs. Acknowledgments We thank our anonymous reviewers \nfor their detailed comments on the submitted paper. This material is based on research spon\u00adsored by \nDARPA under the programs Automated Program Anal\u00adysis for Cybersecurity (FA8750-12-2-0106) and Clean-Slate \nRe\u00adsilient Adaptive Hosts (CRASH). The U.S. Government is autho\u00adrized to reproduce and distribute reprints \nfor Governmental pur\u00adposes notwithstanding any copyright notation thereon. References [1] BOUAJJANI, \nA., ESPARZA, J., AND MALER, O. Reachability analysis of pushdown automata: Application to Model-Checking. \nIn CONCUR 97: Proceedings of the 8th International Conference on Concurrency Theory (1997), Springer-Verlag, \npp. 135 150. [2] COUSOT, P. The calculational design of a generic abstract interpreter. In Calculational \nSystem Design, M. Broy and R. Steinbr\u00a8 uggen, Eds. 1999. [3] COUSOT, P., AND COUSOT, R. Abstract interpretation: \nA uni.ed lattice model for static analysis of programs by construction or approximation of .xpoints. \nIn Conference Record of the Fourth ACM Symposium on Principles of Programming Languages (1977), ACM Press, \npp. 238 252. [4] EARL, C., MIGHT, M., AND VAN HORN, D. Pushdown control\u00ad.ow analysis of higher-order \nprograms. In Proceedings of the 2010 Workshop on Scheme and Functional Programming (Aug. 2010). [5] \nFELLEISEN, M., AND FRIEDMAN, D. P. A calculus for assignments in higher-order languages. In POPL 87: \nProceedings of the 14th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages (1987), ACM, \npp. 314+. [6] FLANAGAN, C., SABRY, A., DUBA, B. F., AND FELLEISEN, M. The essence of compiling with continuations. \nIn PLDI 93: Proceedings of the ACM SIGPLAN 1993 Conference on Programming Language Design and Implementation \n(June 1993), ACM, pp. 237 247. [7] KOBAYASHI, N. Types and higher-order recursion schemes for veri.cation \nof higher-order programs. In POPL 09: Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on \nPrinciples of Programming Languages (2009), POPL 09, ACM, pp. 416 428. [8] KODUMAL, J., AND AIKEN, A. \nThe set constraint/CFL reachability connection in practice. SIGPLAN Not. 39 (June 2004), 207 218. [9] \nMELSKI, D., AND REPS, T. W. Interconvertibility of a class of set constraints and context-free-language \nreachability. Theoretical Computer Science 248, 1-2 (Oct. 2000), 29 98. [10] MIDTGAARD, J., AND JENSEN, \nT. P. Control-.ow analysis of function calls and returns by abstract interpretation. In ICFP 09: Proceedings \nof the 14th ACM SIGPLAN International Conference on Functional Programming (2009), pp. 287 298. [11] \nMIGHT, M. Environment Analysis of Higher-Order Languages. PhD thesis, Georgia Institute of Technology, \nJune 2007. [12] MIGHT, M., CHAMBERS, B., AND SHIVERS, O. Model checking via Gamma-CFA. In Veri.cation, \nModel Checking, and Abstract Interpretation (Jan. 2007), pp. 59 73. [13] MIGHT, M., AND SHIVERS, O. Environment \nanalysis via Delta-CFA. In POPL 06: Conference Record of the 33rd ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages (2006), ACM, pp. 127 140. [14] MIGHT,M., AND SHIVERS,O.Improving.owanalysesviaGamma-CFA: \nAbstract garbage collection and counting. In ICFP 06: Proceedings of the 11th ACM SIGPLAN International \nConference on Functional Programming (2006), ACM, pp. 13 25. [15] ONG, C. H. L. On Model-Checking trees \ngenerated by Higher-Order recursion schemes. In 21st Annual IEEE Symposium on Logic in Computer Science \n(LICS 06) (2006), pp. 81 90. [16] REHOF, J., AND F\u00a8Type-based .ow analysis: AHNDRICH, M. From polymorphic \nsubtyping to CFL-reachability. In POPL 01: Proceedings of the 28th ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages (2001), ACM, pp. 54 66. [17] REPS, T. Program analysis via graph reachability. \nInformation and Software Technology 40, 11-12 (Dec. 1998), 701 726. [18] REPS, T., SCHWOON, S., JHA, \nS., AND MELSKI, D. Weighted pushdown systems and their application to interprocedural data.ow analysis. \nScience of Computer Programming 58, 1-2 (2005), 206 263. [19] SHIVERS, O. G. Control-Flow Analysis of \nHigher-Order Languages. PhD thesis, Carnegie Mellon University, 1991. [20] SIPSER, M. Introduction to \nthe Theory of Computation, 2 ed. Course Technology, Feb. 2005. [21] VAN HORN, D., AND MAIRSON, H. G. \nDeciding kCFA is complete for EXPTIME. In ICFP 08: Proceeding of the 13th ACM SIGPLAN International Conference \non Functional Programming (2008), pp. 275 282. [22] VARDOULAKIS, D., AND SHIVERS, O. Cfa2: a Context-Free \nApproach to Control-Flow Analysis. In European Symposium on Programming (ESOP) (2010), vol. 6012 of LNCS, \npp. 570 589. [23] WRIGHT, A. K., AND JAGANNATHAN, S. Polymorphic splitting: An effective polyvariant \n.ow analysis. ACM Transactions on Programming Languages and Systems 20, 1 (Jan. 1998), 166 207.   \n  \n\t\t\t", "proc_id": "2364527", "abstract": "<p>In the static analysis of functional programs, pushdown flow analysis and abstract garbage collection skirt just inside the boundaries of soundness and decidability. Alone, each method reduces analysis times and boosts precision by orders of magnitude. This work illuminates and conquers the theoretical challenges that stand in the way of combining the power of these techniques. The challenge in marrying these techniques is not subtle: computing the reachable control states of a pushdown system relies on limiting access during transition to the top of the stack; abstract garbage collection, on the other hand, needs full access to the entire stack to compute a root set, just as concrete collection does. <i>Introspective</i> pushdown systems resolve this conflict. Introspective pushdown systems provide enough access to the stack to allow abstract garbage collection, but they remain restricted enough to compute control-state reachability, thereby enabling the sound and precise product of pushdown analysis and abstract garbage collection. Experiments reveal synergistic interplay between the techniques, and the fusion demonstrates \"better-than-both-worlds\" precision.</p>", "authors": [{"name": "Christopher Earl", "author_profile_id": "81548018880", "affiliation": "University of Utah, Salt Lake City, UT, USA", "person_id": "P3804385", "email_address": "cwearl@cs.utah.edu", "orcid_id": ""}, {"name": "Ilya Sergey", "author_profile_id": "81436603558", "affiliation": "KU Leuven, Leuven, Belgium", "person_id": "P3804386", "email_address": "ilya.sergey@cs.kuleuven.be", "orcid_id": ""}, {"name": "Matthew Might", "author_profile_id": "81309498719", "affiliation": "University of Utah, Salt Lake City, USA", "person_id": "P3804387", "email_address": "might@cs.utah.edu", "orcid_id": ""}, {"name": "David Van Horn", "author_profile_id": "81337494657", "affiliation": "Northeastern University, Boston, MA, USA", "person_id": "P3804388", "email_address": "dvanhorn@ccs.neu.edu", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364576", "year": "2012", "article_id": "2364576", "conference": "ICFP", "title": "Introspective pushdown analysis of higher-order programs", "url": "http://dl.acm.org/citation.cfm?id=2364576"}