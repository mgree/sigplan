{"article_publication_date": "09-09-2012", "fulltext": "\n Elaborating Intersection and Union Types Joshua Dun.eld Max Planck Institute for Software Systems Kaiserslautern \nand Saarbr\u00a8ucken, Germany jos u ha@mpi-sws.org Abstract Designing and implementing typed programming \nlanguages is hard. Every new type system feature requires extending the metathe\u00adory and implementation, \nwhich are often complicated and fragile. To ease this process, we would like to provide general mechanisms \nthat subsume many different features. In modern type systems, parametric polymorphism is funda\u00admental, \nbut intersection polymorphism has gained little traction in programming languages. Most practical intersection \ntype systems have supported only re.nement intersections, which increase the expressiveness of types \n(more precise properties can be checked) without altering the expressiveness of terms; re.nement intersec\u00adtions \ncan simply be erased during compilation. In contrast, unre\u00adstricted intersections increase the expressiveness \nof terms, and can be used to encode diverse language features, promising an economy of both theory and \nimplementation. We describe a foundation for compiling unrestricted intersec\u00adtion and union types: an \nelaboration type system that generates or\u00addinary .-calculus terms. The key feature is a Forsythe-like \nmerge construct. With this construct, not all reductions of the source program preserve types; however, \nwe prove that ordinary call-by\u00advalue evaluation of the elaborated program corresponds to a type\u00adpreserving \nevaluation of the source program. We also describe a prototype implementation and applications of unrestricted \nintersections and unions: records, operator overload\u00ading, and simulating dynamic typing. Categories and \nSubject Descriptors F.3.3 [Mathematical Logic and For\u00admal Languages]: Studies of Program Constructs Type \nstructure Keywords intersection types 1. Introduction In type systems, parametric polymorphism is fundamental. \nIt en\u00adables generic programming; it supports parametric reasoning about programs. Logically, it corresponds \nto universal quanti.cation. Intersection polymorphism (the intersection type A . B)is less well appreciated. \nIt enables ad hoc polymorphism; it supports irregular generic programming. Logically, it roughly corresponds \nto conjunction1. Not surprisingly, then, intersection is remarkably versatile. 1 In our setting, this \ncorrespondence is strong, as we will see in Sec. 2. Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. ICFP 12, September 9 15, 2012, Copenhagen, Denmark. Copyright \nc &#38;#169; 2012 ACM 978-1-4503-1054-3/12/09. . . $10.00 For both legitimate and historical reasons, \nintersection types have not been used as widely as parametric polymorphism. One of the legitimate reasons \nfor the slow adoption of intersection types is that no major language has them. A restricted form of \nintersection, re.nement intersection, was realized in two extensions of SML, SML-CIDRE (Davies 2005) \nand Stardust (Dun.eld 2007). These type systems can express properties such as bitwise parity: after \nre.ning a type bits of bitstrings with subtypes even (an even number of ones) and odd (an odd number \nof ones), a bitstring concatenation function can be checked against the type (even * even . even) . (odd \n* odd . even) . (even * odd . odd) . (odd * even . odd) which satis.es the re.nement restriction: all \nthe intersected types re.ne a single simple type, bits * bits . bits. But these systems were only typecheckers. \nTo compile apro\u00adgram required an ordinary Standard ML compiler. SML-CIDRE was explicitly limited to checking \nre.nements of SML types, with\u00adout affecting the expressiveness of terms. In contrast, Stardust could \ntypecheck some kinds of programs that used general intersec\u00adtion and union types, but ineffectively: \nsince ordinary SML com\u00adpilers don t know about intersection types, such programs could never be run. \nRe.nement intersections and unions increase the expressive\u00adness of otherwise more-or-less-conventional \ntype systems, allow\u00ading more precise properties of programs to be veri.ed through typechecking. The point \nis to make fewer programs pass the type\u00adchecker; for example, a concatenation function that didn t have \nthe parity property expressed by its type would be rejected. In con\u00adtrast, unrestricted intersections \nand unions, in cooperation with a term-level merge construct, increase the expressiveness of the term \nlanguage. For example, given primitive operations Int.+ : int * int . int and Real.+ : real * real . \nreal, we can easily de.ne an overloaded addition operation by writing a merge: val + = Int.+ ,, Real.+ \nIn our type system, this function + can be checked against the type (int * int . int) . (real * real \n. real). In this paper, we consider unrestricted intersection and union types. Central to the approach \nis a method for elaborating programs with intersection and union types: elaborate intersections into \nprod\u00aducts, and unions into sums. The resulting programs have no inter\u00adsections and no unions, and can \nbe compiled using conventional means any SML compiler will do. The above de.nition of + is elaborated \nto a pair (Int.+, Real.+);usesof + on ints become .rst projections of +, while uses on reals become second \nprojec\u00adtions of +. We present a three-phase design, based on this method, that supports one of our ultimate \ngoals: to develop simpler compilers for full-featured type systems by encoding many features using intersections \nand unions.  Source language Target language ., ., . ., *, + elaboration Program e : A M : T standard \nnondeterministic evaluation evaluation (cbv) (cbv + merge) elaboration Result v : A W : T Figure 1. \nElaboration and computation 1. An encoding phase that straightforwardly rewrites the program, for example, \nturning a multi-.eld record type into an intersec\u00adtion of single-.eld record types, and multi-.eld records \ninto a merge of single-.eld records. 2. An elaboration phase that transforms intersections and unions \ninto products and (disjoint) sums, and intersection and union introductions and eliminations (implicit \nin the source program) into their appropriate operations: tupling, projection, injection, and case analysis. \n 3. A compilation phase: a conventional compiler with no support for intersections, unions, or the features \nencoded by phase 1.  Contributions: Phase 2 is the main contribution of this paper. Speci.cally, we \nwill: develop elaboration typing rules which, given a source expres\u00adsion e with unrestricted intersections \nand unions, and a merg\u00ading construct e1,, e2, typecheck and transform the program into an ordinary .-calculus \nterm M (with sums and products);  give a nondeterministic operational semantics (.*) for source programs \ncontaining merges, in which not all reductions pre\u00adserve types;  prove a consistency (simulation) result: \nordinary call-by-value evaluation ( *) of the elaborated program produces a value  . corresponding to \na value resulting from (type-preserving) re\u00adductions of the source program that is, the diagram in Figure \n1 commutes; describe an elaborating typechecker that, by implementing the elaboration typing rules, \ntakes programs written in an ML-like language, with unrestricted intersection and union types, and generates \nStandard ML programs that can be compiled with any SML compiler. All proofs were checked using the Twelf \nproof assistant (Pfen\u00adning and Sch\u00a8urmann 1999; Twelf 2012) (with the termination checker silenced for \na few inductive cases, where the induction measure was nontrivial) and are available on the web (Dun.eld \n2012). For convenience, the names of Twelf source .les (.elf ) are hyperlinks. While the idea of compiling \nintersections to products is not new, this paper is its .rst full development and practical expression. \nAn essential twist is the source-level merging construct e1,, e2, which embodies several computationally \ndistinct terms, which can be checked against various parts of an intersection type, reminis\u00adcent of Forsythe \n(Reynolds 1996) and (more distantly) the .&#38;\u00adcalculus (Castagna et al. 1995). Intersections can still \nbe intro\u00ad duced without this construct; it is required only when no single term can describe the multiple \nbehaviours expressed by the intersection. Remarkably, this merging construct also supports union elimina\u00adtions \nwith two computationally distinct branches (unlike markers for union elimination in work such as Pierce \n(1991a)). As usual, we have no source-level intersection eliminations and no source\u00adlevel union introductions; \nelaboration puts all needed projections and injections into the target program. Contents: In Section \n2, we give some brief background on inter\u00ad section types, discuss their introduction and elimination \nrules, in\u00adtroduce and discuss the merge construct, and compare intersection types to product types. Section \n3 gives background on union types, discusses their introduction and elimination rules, and shows how \nthe merge construct is also useful for them. Section 4 has the details of the source language and its \n(unusual) operational semantics, and describes a non-elaborating type system including subsumption. Section \n5 presents the target language and its (entirely standard) typing and operational semantics. Section \n6 gives the elaboration typing rules, and proves several key results relating source typing, elaboration \ntyping, the source operational semantics, and the target operational semantics. Section 7 discusses a \nmajor caveat: the approach, at least in its present form, lacks the theoretically and practically important \nproperty of coherence, because the meaning of a target program depends on the choice of elaboration typing \nderivation. Section 8 shows encodings of type system features into inter\u00ad sections and unions, with examples \nthat are successfully elaborated by our prototype implementation (Section 9). Related work is dis\u00ad cussed \nin Section 10, and Section 11 concludes.  2. Intersection Types What is an intersection type? The simplistic \nanswer is that, suppos\u00ading that types describe sets of values, A . B describes the inter\u00adsection of the \nsets of values of A and B.That is, v : A . B if v : A and v : B. Less simplistically, the name has been \nused for substantially different type constructors, though all have a conjunctive .avour. The intersection \ntype in this paper is commutative (A . B = B . A) and idempotent (A . A = A), following several seminal \npapers on intersection types (Pottinger 1980; Coppo et al. 1981) and more recent work with re.nement \nintersections (Freeman and Pfenning 1991; Davies and Pfenning 2000; Dun.eld and Pfenning 2003). Other \nlines of research have worked with nonlinear and/or ordered intersections, e.g. Kfoury and Wells (2004), \nwhich seem less directly applicable to practical type systems (M\u00f8ller Neergaard and Mairson 2004). For \nthis paper, then: What is a commutative and idempotent intersection type? One approach to this question \nis through the Curry-Howard correspondence. Naively, intersection should correspond to logical conjunction \nbut products correspond to logical conjunction, and intersections are not products, as is evident from \ncomparing the standard2 introduction and elimination rules for intersection to the (utterly standard) \nrules for product. (Throughout this paper, k is existentially quanti.ed over {1, 2}; technically, and \nin the Twelf formulation, we have two rules .E1 and .E2,etc.) e : A1 e : A2 e : A1 . A2 .I .Ek e : A1 \n. A2 e : Ak e1 : A1 e2 : A2 e : A1 * A2 *I *Ek (e1, e2) : A1 * A2 projk e : Ak 2 For impure call-by-value \nlanguages like ML, .I ordinarily needs to be restricted to type a value v, for reasons analogous to the \nvalue restriction on parametric polymorphism (Davies and Pfenning 2000). Our setting, however, is not \nordinary: the technique of elaboration makes the more permissive rule safe, though user-unfriendly. See \nSection 6.5.  Here .I types a single term e which inhabits type A1 and type A2: via Curry-Howard, this \nmeans that a single proof term serves as witness to two propositions (the interpretations of A1 and A2). \nOn the other hand, in *I two separate terms e1 and e2 witness the propositions corresponding to A1 and \nA2. This difference was suggested by Pottinger (1980), and made concrete when Hindley (1984) showed that \nintersection (of the form described by Coppo et al. (1981) and Pottinger (1980)) cannot correspond to \nconjunc\u00adtion because the following type, the intersection of the types of the I and S combinators, is \nuninhabited: (A . A) .(A.B.C) . (A.B) . A . C D yet the prospectively corresponding proposition is \nprovable in intu\u00aditionistic logic: (A . A) and(A.B.C) . (A.B) . A . C(*) Hindley notes that every term \nof type A . A is \u00df-equivalent to e1 = .x. x, and every term of type D is \u00df-equivalent to e2 = .x. .y. \n.z. x z (yz),the S combinator. Any term e of type (A . A) . D must therefore have two normal forms, e1 \nand e2, which is impossible. But that impossibility holds for the usual .-terms. Suppose we add a merge \nconstruct e1,, e2 that, quite brazenly, can step to two different things: e1,, e2 . e1 and e1,, e2 . \ne2. Its typing rule chooses one subterm and ignores the other (throughout this paper, the subscript k \nranges over {1, 2}): ek : A mergek e1,, e2 : A In combination with .I, the mergek rule allows two distinct \nimple\u00admentations e1 and e2, one for each of the components A1 and A2 of the intersection: e1 : A1 e2 \n: A2 e1,, e2 : A1 merge1 e1,, e2 : A2 merge2 .I e1,, e2 : A1 . A2 Now (A . A) . D is inhabited: e1,, \ne2 :(A . A) . D With this construct, the naive hope that intersection corresponds to conjunction is realized \nthrough elaboration: we can elaborate e1,, e2 to (e1, e2), a term of type (A . A) * D, which does cor\u00adrespond \nto the proposition (*). Inhabitation and provability again correspond because we have replaced the seemingly \nmysterious intersections with simple products. For source expressions, intersection still has several \nproperties that set it apart from product. Unlike product, it has no elimination form. It also lacks \nan explicit introduction form; .I is the only intro rule for .. While the primary purpose of mergek is \nto derive the premises of .I, the mergek rule makes no mention of intersection (or any other type constructor). \nPottinger (1980) presents intersection A &#38; B as a proposition with some evidence of A that is also \nevidence of B unlike A &#38; B, corresponding to A * B, which has two separate pieces of evidence for \nA and for B. In our system, though, e1,, e2 is a single term that provides evidence for A and B, so it \nis technically consistent with this view of intersection, but not necessarily consistent in spirit (since \ne1 and e2 can be very different from each other).  3. Union Types Having discussed intersection types, \nwe can describe union types as intersections dual: if v : A1 . A2 then either v : A1 or v : A2 (perhaps \nboth). This duality shows itself in several ways. For union ., introduction is straightforward, as elimination \nwas straightforward for . (again, k is either 1 or 2): G e : Ak .Ik G e : A1 . A2 Coming up with a good \nelimination rule is trickier. A number of appealing rules are unsound; a sound, yet acceptably strong, \nrule is G, x1 : A1 E[x1]: C G e0 : A1 . A2 G, x2 : A2 E[x2]: C .E G E[e0]: C This rule types an expression \nE[e0] an evaluation context E with e0 in an evaluation position where e0 has the union type A1 . A2. \nDuring evaluation, e0 will be some value v0 such that either v0 : A1 or v0 : A2. In the former case, \nthe premise x1 : A1 E[x1]: C tells us that substituting v0 for x1 gives a well\u00adtyped expression E[v0]. \nSimilarly, the premise x2 : A2 E[x2]: C tells us we can safely substitute v0 for x2. The restriction \nto a single occurrence of e0 in an evaluation po\u00adsition is needed for soundness in many settings generally, \nin any operational semantics in which e0 might step to different expres\u00adsions. One simple example is \na function f :(A . A . C) . (B . B . C) and expression e0 : A . B,where e0 changes the contents pointed \nto by a reference of type (A . B) ref,before returning the new value. The application fe0 e0 would be \nwell\u00adtyped by a rule allowing multiple occurrences of e0, but unsound: the .rst e0 could evaluate to \nan A and the second e0 to a B. The evaluation context E need not be unique, which creates some dif.culties \nfor practical typechecking (Dun.eld 2011). For further discussion of this rule, see Dun.eld and Pfenning \n(2003). We saw in Section 2 that, in the usual .-calculus, . does not correspond to conjunction; in particular, \nno .-term behaves like both the I and S combinators, so the intersection (A.A) . D (where D is the type \nof S) is uninhabited. In our setting, though, (A.A) . D is inhabited, by the merge of I and S. Something \nsimilar comes up when eliminating unions. With\u00adout the merge construct, certain instances of union types \ncan t be usefully eliminated. Consider a list whose elements have type int . string. Introducing those \nunions to create the list is easy enough: use .I1 for the intsand .I2 for the strings. Now sup\u00adpose we \nwant to print a list element x : int . string,convert\u00ading the ints to their string representation and \nleaving the strings alone. To do this, we need a merge; for example, given a function g :(int . string) \n. (string . string) whose body contains a merge, use rule .Eon gx with E = g [] and e0 = x. Like intersections, \nunions can be tamed by elaboration. Instead of products, we elaborate unions to products dual, sums (tagged \nunions). Uses of .I1 and .I2 become left and right injections into a sum type; uses of .E become ordinary \ncase expressions.  4. Source Language 4.1 Source Syntax Source types A, B, C ::= T | A . B | A . B \n| A . B Typing contexts G ::= \u00b7 | G, x : A Source expressions e ::= x | () | .x. e | e1 e2 | .x x. e \n| e1,, e2 Source values v ::= x | () | .x. e | v1,, v2 Evaluation contexts E ::= [] | E e | v E | E,, \ne | e,, E Figure 2. Syntax of source types, contexts and expressions  The source language expressions \ne are standard, except for the feature central to our approach, the merge e1,, e2. The types A, B, C \nare a top type T (which will be elaborated to unit), the usual function space A . B, intersection A . \nB and union A . B. Values v are standard, but a merge of values v1,, v2 is considered a value, even though \nit can step! But the step it takes is pure, in the sense that even if we incorporated (say) mutable references, \nit would not interact with them.  4.2 Source Operational Semantics ' Source expression e ee1 step E \nE in step.elf steps to e 1 1 e1 e e2 e 1 2 step/app1 step/app2 1 1 e1e2 e1e2 v1e2 v1e 2 step/beta (.x. \ne)v [v/x]e step/.x .x x. e [(.x x. e)/x]e step/unmerge left step/unmerge right e1,, e2 e1 e1,, e2 e2 \n1 1 e1 e1 1 step/merge1 e2 e2 1 step/merge2 e1,, e2 e1,, e2 e1,, e2 e1,, e 2 step/split e e,, e Figure \n3. Source language operational semantics: call-by-value + merge construct The source language operational \nsemantics (Figure 3) is stan\u00ad dard (call-by-value function application and a .xed point expres\u00adsion) \nexcept for the merge construct. This peculiar animal is a descendant of demonic choice : by the step/unmerge \nleft and step/unmerge right rules, e1,, e2 can step to either e1 or e2. Adding to its misbehaviours, \nit permits stepping within itself ( step/merge1 and step/merge2 note that in step/merge2 , we don t require \ne1 to be a value). Worst of all, it can appear by spon\u00adtaneous .ssion: step/split turns any expression \ne into a merge of two copies of e. The merge construct makes our source language operational se\u00admantics \ninteresting. It also makes it unrealistic: -reduction does not preserve types. For type preservation \nto hold, the operational semantics would need access to the typing derivation. Worse, since the typing \nrule for merges ignores the unused part of the merge, \u00adreduction can produce expressions that have no \ntype at all, or are not even closed! The point of the source operational semantics is not to directly \nmodel computation; rather, it is a basis for checking that the elaborated program (whose operational \nsemantics is per\u00adfectly standard) makes sense. We will show in Section 6 that, if the result M of elaborating \ne can step to some M1, then we can step e * e1 where e1 elaborates to M1. 4.3 (Source) Subtyping Suppose \nwe want to pass a function f : A . C to a function g :((A . B) . C) . D. This should be possible, since \nf requires only that its argument have type A; in all calls from g the argument to f will also have type \nB,but f won t mind. With only the rules discussed so far, however, the application gf is not well-typed: \nwe can t get inside the arrow (A . B) . C.For .exibility, we ll incorporate a subtyping system that can \nconclude, for example, A . C = (A . B) . C. The logic of the subtyping rules (Figure 4, top) is taken \nstraight from Dun.eld and Pfenning (2003), so we only brie.y give some intuition. Roughly, A = B is sound \nif every value of type A can be treated as having type B. Under a subset interpretation, this would mean \nthat A = B is justi.ed if the set of A-values is a subset of the set of B-values. For example, the rule \n.R=, if interpreted set\u00adtheoretically, says that if A . B1 and A . B2 then A . (B1 nB2). It is easy to \nshow that subtyping is re.exive and transitive; see sub-refl.elf and sub-trans.elf . (Building transitivity \ninto the structure of the rules makes it easy to derive an algorithm; an explicit transitivity rule would \nhave premises A = B and B = C, which involve an intermediate type B that does not appear in the conclusion \nA = C.) Having said all that, the subsequent theoretical development is easier without subtyping. So \nwe will show (Theorem 1) that, given a typing derivation that uses subtyping (through the usual subsumption \nrule), we can always construct a source expression of the same type that never applies the subsumption \nrule. This new expression will be the same as the original one, with a few additional coercions. For \nthe example above, we essentially .\u00adexpand gf to g (.x.f x), which lets us apply .E1 to x : A . B. Operationally, \nall the coercions are identities; they serve only to articulate the type structure, making subsumption \nunnecessary. Note that the coercion in rule .L= is eta-expanded to allow .E to eliminate the union in \nthe type of x; as discussed later, the subexpression of union type must be in evaluation position.  \n4.4 Source Typing The source typing rules (Figure 4) are either standard or have already been discussed \nin Sections 2 and 3, except for direct. The direct rule was introduced and justi.ed in Dun.eld and Pfenning \n(2003, 2004). It is a 1-ary version of .E, a sort of cut: a use of the typing e0 : A within the derivation \nof E[e0]: C is replaced by a derivations of e0 : A, along with a derivation of E[x]: C that assumes x \n: A. Curiously, in this system of rules, direct is admissible: given e0 : A,use .I1 or .I2 to conclude \ne0 : A . A, then use two copies of the derivation x : A E[x]: C in the premises of .E(a-converting x \nas needed). So why include it? Typing using these rules is undecidable; our implementation (Section 9) \nfollows a bidirectional version of them (where typechecking is decidable, given a few annotations, similar \nto Dun.eld and Pfenning (2004)), where direct is not admissible. (A side bene.t is that direct and .E \nare similar enough that it can be helpful to do the direct case of a proof before tackling .E.) Remark. \nTheorem 1, and all subsequent theorems, are proved only for expressions that are closed under the appropriate \ncontext, even though mergek does not explicitly require that the unexamined subexpression be closed; \nTwelf does not support proofs about ob\u00adjects with unknown variables. Theorem 1 (Coercion). If D derives \nGe : B then there exists an e1 such that D1 derives Ge1 : B,where D1 never uses rule sub. Proof. By induction \non D. The interesting cases are for sub and .E. In the case for sub with A = B, we show that when the \ncoercion ecoerce which always has the form .x. e0 is applied to an expression of type A, we get an expression \nof type B.For example, for .L1= we use .E1. This shows that e1 =(.x. e0) e has type B. For .E, the premises \ntyping E[xk] might separate , say if the .rst includes subsumption (yielding the same E[x1]) and the \nsecond doesn t. Furthermore, inserting coercions could break evaluation positions: given E = f [], replacing \nf with an application (ecoerce f) Source type A is a subtype of source type B, with coercion e of type \n\u00b7 e : A . B   sub A B Coe CoeTyping in typeof+sub.elf 1 B1 = A1 ::: eA2 = B2 ::: e .=TR= 1 A1 . A2 \n= B1 . B2 ::: .f. .x. e (f (ex)) A =T ::: .x. () Ak = B ::: eA = B1 ::: e1 A = B2 ::: e2 .Lk= .R= A1 \n. A2 = B ::: eA = B1 . B2 ::: e1,, e2 A1 = B ::: e1 A2 = B ::: e2 A = Bk ::: e .L= .Rk= A1 . A2 = B ::: \n.x. (.y. e1 y,, e2 y) xA = B1 . B2 ::: e Source expression e has source type A typeof+sub E A in typeof+sub.elf \nGek : A G,x : Ae : A var mergek .x TI G1,x : A, G2 x : A Ge1,, e2 : AG .x x. e : A Gv : T G, x : A e \n: B G e1 : A . B G e2 : A .I .E G .x. e : A . B G e1 e2 : B G e : A1 G e : A2 G e : A1 . A2 .I G e : \nA1 . A2 G e : Ak .Ek G, x1 : A1 E[x1]: C G e0 : A G G, x : A E[e0]: C E[x]: C direct G G e : Ak e : A1 \n. A2 .Ik G e0 : A1 . A2 G G, x2 : A2 E[e0]: C E[x2]: C .E Ge : AA = B ::: ecoerce sub Ge : B Figure \n4. Source type system, with subsumption, non-elaborating means that [] is no longer in evaluation position. \nTo handle these 5.2 Target Typing 2) e induction hypothesis to the derivation of Ge0 : A1 . A2,and 1 \n1 11 01 issues, let e ,where e comes from applying the =(.y. e1,, e The typing rules for the target language \n(Figure 6) lack any form of subtyping, and are completely standard. 0 1 e 1 and e 1 2 come from applying \nthe induction hypothesis to the other 1 0 is in evaluation position, because it followstwo premises. \nNow e  5.3 Target Operational Semantics a .;the mergek typing rule will choose the correct branch. The \noperational semantics M . M1 is, likewise, standard; func- For details, see coerce.elf . We actually \nencode the typings tions are call-by-value and products are strict. As usual, we write for ecoerce as \nhypothetical derivations in the subtyping judgment * M1 for a sequence of zero or more .s. M . itself \n(typeof+sub.elf ), making the sub case here trivial. Naturally, a type safety result holds: Theorem \n2 (Target Type Safety). If \u00b7 M : T then either M is a M1 value, or M . M1 and \u00b7 : T.  5. Target Language \nOur target language is just the simply-typed call-by-value .- Proof. By induction on the given derivation, \nusing a few standard calculus extended with .xed point expressions, products, and sums. lemmas; see tm-safety.elf \n. (The necessary substitution lemma 5.1 Target Syntax Target types T ::= unit | T . T | T * T | T + T \nTyping contexts G ::= \u00b7 | G, x : T Target terms M, N ::= x | () | .x. M | MN | .x x. M | (M1, M2) | projk \nM | injk M | case M of inj1 x1 . N1 | inj2 x2 . N2 Target values W ::= x | () | .x. M | (W1, W2) | injk \nW Figure 5. Target types and terms The target types and terms (Figure 5) are completely standard. comes \nfor free in Twelf.) And to calm any doubts about whether M might step to some other, not necessarily \nwell-typed term: Theorem 3 (Determinism of .). If M . N1 and M . N2 then N1 = N2 (up to a-conversion). \nProof. By simultaneous induction. See tm-deterministic in tm-safety.elf .   6. Elaboration Typing \nWe elaborate source expressions e into target terms M. The source expressions, which include a merge \nconstruct e1,, e2, are typed with intersections and unions, but the result of elaboration is com\u00adpletely \nstandard and can be typed with just unit, ., * and +.  Target term M has target type T  G, x : TM \n: T G1,x : T, G2 x : T var G .x x. M : T .x G () : unit unitintro typeoftm/ typeoftm/ typeoftm/ G, x \n: T1 M : T2 GM1 : T . T 1 GM2 : T typeoftm/ typeoftm/ 1 G .x. M :(T1 . T2) arrintro GM1 M2 : T arrelim \nGM1 : T1 GM2 : T2 GM :(T1 * T2) typeoftm/ typeoftm/ G (M1, M2) :(T1 * T2) prodintro G (projk M): Tk prodelimk \nG, x1 : T1 N1 : T GM : Tk GM : T1 + T2 G, x2 : T2 N2 : T typeoftm/ typeoftm/ G (injk M):(T1 + T2) sumintrok \nG (case M of inj1 x1 . N1 | inj2 x2 . N2): T sumelim Figure 6. Target type system with functions, products \nand sums Target term M steps to M1 M1 . M1 1 M2 . M1 2 M1M2 . M1 1M2 W1M2 . W1M1 2 (.x. M)W . [W/x]M \n.x x. M . [(.x x. M)/x]M M . M1 projk M1 . projk M1 projk (W1, W2) . Wk M1 . M1 1 M2 . M1 2 (M1, M2) \n. (M1 1, M2) (W1, M2) . (W1, M1 2) M . M1 M . M1  injk M . injk M1 case M of MS . case M1 of MS case \ninjk W of inj1 x1 . N1 | inj2 x2 . N2 . [W/xk]Nk Figure 7. Target language operational semantics: call-by-value \n+ products + sums The elaboration judgment Ge : A '. M is read under assumptions G, source expression \ne has type A and elaborates to target term M . While not written explicitly in the judgment, the elaboration \nrules ensure that M has type |A|,the type translation of A (Figure 8). For example, |T . (T.T)| = unit \n* (unit.unit). To simplify the technical development, the elaboration rules work only for source expressions \nthat can be typed without using the subsumption rule sub (Figure 4). Such source expressions can always \nbe produced (Theorem 1, above). The rest of this section discusses the elaboration rules and proves related \nproperties: 6.1 connects elaboration, source typing, and target typing; 6.2 gives lemmas useful for \nshowing that target computations cor\u00adrespond to source computations; 6.3 states and proves that correspondence \n(consistency, Thm. 13); 6.4 summarizes the metatheory through two important corollaries of our various \ntheorems. Finally, Section 6.5 discusses whether we need a value restric\u00adtion on .I. |T| = unit |A1 . \nA2| = |A1| . |A2| |A1 . A2| = |A1| * |A2| |A1 . A2| = |A1| + |A2| Figure 8. Type translation  6.1 \nConnecting Elaboration and Typing Equivalence of elaboration and source typing: The non-elaborating type \nassignment system of Figure 4, minus sub, can be read off from the elaboration rules in Figure 9: simply \ndrop the '. ... part of the judgment. Consequently, given e : A '. M we can always derive e : A: Theorem \n4. If Ge : A '. M then Ge : A (without using rule sub). Proof. By straightforward induction on the given \nderivation; see typeof-erase in typeof-elab.elf . More interestingly, given e : A we can always elaborate \ne,so elaboration is just as expressive as typing: Theorem 5 (Completeness of Elaboration). If Ge : A \n(without using rule sub)then Ge : A '. M. Proof. By straightforward induction on the given derivation; \nsee elab-complete in typeof-elab.elf . Elaboration produces well-typed terms: Any target term M pro\u00adduced \nby the elaboration rules has corresponding target type. In the theorem statement, we assume the obvious \ntranslation |G|,e.g. |x : T,y : T . T| = x : |T|,y : |T . T| = x : unit,y : unit + unit). Theorem 6 (Elaboration \nType Soundness). If Ge : A '. M then |G| M : |A|. Proof. By induction on the given derivation. For example, \nthe case for direct, which elaborates to an application, applies typeoft\u00adm/arrintro and typeoftm/arrelim. \nExploiting a bijection between source types and target types, we actually prove GM : A, interpreting \nA and types in G as target types: . as *,etc.See elab-type-soundness.elf .  Source expression e has \nsource type A  G fe : A .. M elab E A M in elab.elf and elaborates to target term M (of type |A|) Gek \n: A '. M G,x : Ae : A '. M var mergek .x TI G1,x : A, G2 x : A '. x Ge1,, e2 : A '. MG .x x. e : A '. \n.x x.M Gv : T '. () G, x : Ae : B '. M Ge1 : A . B '. M1 Ge2 : A '. M2 .I .E G .x. e : A . B '. .x.M \nGe1 e2 : B '. M1 M2 Ge : A1 '. M1 Ge : A2 '. M2 Ge : A1 . A2 '. M .I .Ek Ge : A1 . A2 '. (M1, M2) Ge \n: Ak '. projk M Ge : Ak '. M .Ik Ge : A1 . A2 '. injk M G, x1 : A1 E[x1]: C '. N1 Ge0 : A '. M0 G, x \n: A E[x]: C '. N Ge0 : A1 . A2 '. M0 G, x2 : A2 E[x2]: C '. N2 direct .E G E[e0]: C '. (.x. N)M0 G E[e0]: \nC '. case M0 of inj1 x1 . N1 | inj2 x2 . N2 Figure 9. Elaboration typing rules 6.2 Relating Source Expressions \nto Target Terms Elaboration produces a term that corresponds closely to the source expression: a target \nterm is the same as a source expression, except that the intersection-and union-related aspects of the \ncomputation become explicit in the target. For instance, intersection elimination via .E2, implicit in \nthe source program, becomes the explicit projection proj2. The target term has nearly the same structure \nas the source; the elaboration rules only insert operations such as proj2, duplicate subterms such as \nthe e in .I, and omit unused parts of merges. This gives rise to a relatively simple connection between \nsource expressions and target terms much simpler than a logical rela\u00adtion, which relates all appropriately-typed \nterms that have the same extensional behaviour. In fact, stepping in the target preserves elab\u00adoration \ntyping, provided we are allowed to step the source expres\u00adsion zero or more times. This consistency result, \nTheorem 13, needs several lemmas. Lemma 7. If e * e 1 then E[e] * E[e 1]. Proof. By induction on the \nnumber of steps, using a lemma (step-eval-context )that ee 1 implies E[e] E[e 1].See step*eval-context \nin step-eval-context.elf .  Next, we prove inversion properties of unions, intersections and arrows. \nRoughly, we want to say that if an expression of union type elaborates to an injection injk M0, it also \nelaborates to M0. For intersections, the property is slightly more complicated: given an expression of \nintersection type that elaborates to a pair, we can step the expression to get something that elaborates \nto the components of the pair. Similarly, given an expression of arrow type that elaborates to a .-abstraction, \nwe can step the expression to a .-abstraction. Lemma 8 (Unions/Injections). If Ge : A1 . A2 '. injk M0 \nthen Ge : Ak '. M0. Proof. By induction on the derivation of Ge : C '. M. The only possible cases are \nmergek and .Ik.See elab-inl and elab-inr in elab-union.elf .  Lemma 9 (Intersections/Pairs). If Ge : \nA1 . A2 '. (M1, M2) then there exist e1 1 and e2 1 such that *1 1 (1) ee1 and Ge1 : A1 '. M1, and *1 \n1 (2) ee2 and Ge2 : A2 '. M2.  Proof. By induction on the given derivation; the only possible cases \nare .Iand mergeSee elab-sect.elf .  . Lemma 10 (Arrows/Lambdas). If \u00b7 e : A . B '. .x. M0 then there \nexists e0 such that e * .x. e0 and x : Ae0 : B '. M0. Proof. By induction on the given derivation; the \nonly possible cases are .Iand mergeSee elab-arr.elf .  . Our last interesting lemma shows that if an \nexpression e elabo\u00adrates to a target value W, we can step e to some value v that also elaborates to W. \nLemma 11 (Value monotonicity). If Ge : A '. W then e * v where Gv : A '. W. Proof. By induction on the \ngiven derivation. The most interesting case is for .I, where we apply the induc\u00ad 11 *1 tion hypothesis \nto each premise (yielding v1,v2 such that ev1 and e * v21 ), apply the step/split rule to turn e into \n(e,, e),and use the step/merge1 and step/merge2 rules to step each part of the merge, yielding v11 ,, \nv21 , which is a value. In the mergek case on a merge e1,, e2, we apply the induc\u00adtion hypothesis to \nek,giving ek * v. By rule step/unmerge , e1,, e2 ek, from which e1,, e2 * v. See value-mono.elf .  Lemma \n12 (Substitution). If G, x : Ae : B '. M and Gv : A '. W then G [v/x]e : B '. [W/x]M. Proof. By induction \non the .rst derivation. As usual, Twelf gives us this substitution lemma for free.  6.3 Consistency \nThis theorem is the linchpin: given e that elaborates to M,we can preserve the elaboration relationship \neven after stepping M, though we may have to step e some number of times as well. The expression e and \nterm M, in general, step at different speeds: M steps while e doesn t for example, if M is inj1 (W1, \nW2) and steps to W1, there is nothing to do in e because the injection corresponds to implicit union \nintroduction in rule .I1;  e may step more than M for example, if e is (v1,, v2) v and M is (.x. x) \nW,then M\u00df-reduces to W,but e must .rst step/unmerge to the appropriate vk, yielding vk v,and then apply \nstep/beta . (Note that the converse if ee 1 then M . * M1 does not hold: we could pick the wrong half \nof a merge and get a source expression with no particular relation to M.) Theorem 13 (Consistency). If \n\u00b7 e : A '. M and M . M1 *1 . M1 then there exists e 1 such that ee 1 and \u00b7 e : A '. Proof. By induction \non the derivation D of \u00b7 e : A '. M.We show several cases here; the full proof is in consistency.elf \n.  Case var, TI, .I : Impossible because M cannot step.  Case .I:  \u00b7 e : A1 '. M1 \u00b7 e : A2 '. M2 D \n:: \u00b7 e : A1 . A2 '. (M1, M2) By inversion, either M1 . M1 1 or M2 . M21 . Suppose the *1 1 former (the \nlatter is similar). By i.h., ee1 and \u00b7 e1 : A1 '. M11 . By step/split , e e,, e. Repeatedly applying \nstep/merge1 gives e,, e * e11 ,, e. 1 . M1 For typing, apply merge1 with premise \u00b7 e1 : A1 '1 and with \npremise \u00b7 e : A2 '. M2. 1 . (M1 Finally, by .I, we have \u00b7 e1,, e : A1 . A2 '1, M2). Case .Ek : \u00b7 e : \nA1 . A2 '. M0 D :: \u00b7 e : Ak '. projk M0 If projk M0 . projk M0 1 with M0 . M01 ,use the i.h. and apply \n.Ek. If M0 = (W1, yielding e * ek 1 Case mergek : W2) and projk M0 . Wk, use Lemma 9, and Gek 1 : Ak \n'. Wk. \u00b7 ek : A '. M D :: \u00b7 e1,, e2 : A '. M By i.h., ek * e 1 and \u00b7 e 1 : A. By rule step/unmerge , \ne1,, e2 ek. Therefore e1,, e2 * e 1 . Case .E: \u00b7 e1 : A.B '. M1 \u00b7 e2 : A '. M2 D :: \u00b7 e1 e2 : B '. M1 \nM2 We show one of the harder subcases (consistency/app/beta in consistency.elf ). In this subcase, M1 \n= .x. M0 and M2 is a value, with M1 M2 . [M2/x]M0. We use several easy lemmas about stepping; for example, \nstep*app1 says that if *1 *1 e1 e1 then e1 e2 e1 e2. Elab1 :: \u00b7 e1 : A . B '. .x. M0 Subd. ElabBody :: \nx : Ae0 : B '. M0 By Lemma 10 StepsFun :: e1 * .x. e0 11 StepsApp :: e1 e2 * (.x. e0)e2 By step*app1 \nElab2 :: \u00b7 e2 : A '. M2 Subd. M2 value Above Elab21 :: \u00b7 e2 * v2 By Lemma 11 \u00b7 v2 : A '. M2 11 (.x. e0)e2 \n* (.x. e0)v2 By step*app2 e1 e2 * (.x. e0)v2 By step*append (.x. e0)v2 [v2/x]e0 By step/beta StepsAppBeta \n:: e1 e2 * [v2/x]e0 By step*snoc ElabBody :: x : Ae0 : B '. M0 Above \u00b7 [v2/x]e0 : B '. [M2/x]M0 By Lemma \n12 (Elab21) Theorem 14 (Multi-step Consistency). * Proof. By induction on the derivation of M . If \u00b7 \ne : A '. M and M . W then there exists v such that e * v and \u00b7 v : A '. W. * W. If M is some value w \nthen, by Lemma 11, e is some value v. The source expression e steps to itself in zero steps, so v * v,and \n\u00b7 v : A '. W is given (e = v and M = W). Otherwise, we have M . M1 where M1 . * W.We want to show \u00b7 e \n1 : A '. M1,where e * e 1. By Theorem 13, either \u00b7 e : A '. M1,or ee 1 and \u00b7 e 1 : A '. M1 . If \u00b7 e \n: A '. M1,let e 1 = e,so \u00b7 e 1 : A '. M1 and e * e 1 in zero steps.  If ee 1 and \u00b7 e 1 : A '. M1, we \ncan use the i.h., showing that e 1* v and \u00b7 v : A '. W.  See consistency* in consistency.elf .  6.4 \nSumming Up Theorem 15 (Static Semantics). If \u00b7 e : A (using any of the rules in Figure 4) then there \nexists e 1 such that \u00b7 e 1 : A '. M and \u00b7 M : |A|. Proof. By Theorems 1 (coercion), 5 (completeness of \nelaboration) and 6 (elaboration type soundness). Theorem 16 (Dynamic Semantics). If \u00b7 e : A '. M and \nM . * W then there is a source value v such that e * v and \u00b7 v : A. Proof. By Theorems 14 (multi-step \nconsistency) and 4. Recalling the diagram in Figure 1, Theorem 16 shows that it commutes. Both theorems \nare stated and proved in summary.elf .Com\u00ad bined with a run of the target program (M . * W), they show \nthat elaborated programs are consistent with source programs.  6.5 The Value Restriction Davies and \nPfenning (2000) showed that the then-standard intersec\u00ad tion introduction (that is, our .I) was unsound \nin a call-by-value se\u00admantics in the presence of effects (speci.cally, mutable references). Here is an \nexample (modeled on theirs). Assume a base type nat with values 0, 1, 2, . . . and a type pos of strictly \npositive naturals with values 1, 2, . . . ; assume pos = nat. let r = (ref 1):(nat ref) . (pos ref) in \nr := 0; (!r): pos Using the unrestricted .Irule, r has type (nat ref) . (pos ref); using .E1 yields r \n: nat ref, so the write r := 0 is well-typed; using .E2 yields r : pos ref, so the read !r produces a \npos.Inan unelaborated setting, this typing is unsound: (ref 1) creates a single cell, initially containing \n1, then overwritten with 0,so !r0, which does not have type pos. Davies and Pfenning proposed, analogously \nto ML s value re\u00adstriction on .-introduction, an .-introduction rule that only types values v. This rule \nis sound with mutable references: v : A1 v : A2 .I (Davies and Pfenning) v : A1 . A2 In an elaboration \nsystem like ours, however, the problematic example above is sound, because our .I elaborates ref 1 to \ntwo distinct expressions, which create two unaliased cells:  ref 1 : nat ref '. ref 1 ref 1 : pos ref \n'. ref 1 .I ref 1 : nat ref . pos ref '. (ref 1, ref 1) Thus, the example elaborates to  let r =(ref \n1, ref 1) in (proj1 r) := 0; (!proj2 r): pos which is well-typed, but does not go wrong in the type-safety \nsense: the assignment writes to the .rst cell (.E1), and the deref\u00aderence reads the second cell (.E2), \nwhich still contains the origi\u00adnal value 1. The restriction-free .I thus appears sound in our set\u00adting. \nBeing sound is not the same as being useful, though; such behaviour is less than intuitive, as we discuss \nin the next section.  7. Coherence The merge construct, while simple and powerful, has serious us\u00adability \nissues when the parts of the merge have overlapping types. Or, more accurately, when they would have \noverlapping types types with nonempty intersection in a merge-free system: in our system, all intersections \nA . B of nonempty A, B are nonempty: if vA : A and vB : B then vA,, vB : A . B by mergek and .I. According \nto the elaboration rules, 0,, 1 (checked against nat) could elaborate to either 0 or 1. Our implementation \nwould elab\u00adorate 0,, 1 to 0, because it tries the left part 0 .rst. Arguably, this is better behaviour \nthan actual randomness, but hardly helpful to the programmer. Perhaps even more confusingly, suppose \nwe are checking 0,, 1 against pos . nat,where pos and nat are as in Sec\u00adtion 6.5. Our implementation \nwould elaborate 0,, 1 to (1, 0),but 1,, 0 to (1, 1). Since the behaviour of the target program depends \non the partic\u00adular elaboration typing used, the system lacks coherence (Reynolds 1991). To recover a \ncoherent semantics, we could limit merges accord\u00ading to their surface syntax, as Reynolds did in Forsythe, \nbut this seems restrictive; also, crafting an appropriate syntactic restriction depends on details of \nthe type system, which is not robust as the type system is extended. A more general approach might be \nto re\u00adject (or warn about) merges in which more than one part checks against the same type (or the same \npart of an intersection type). Im\u00adplementing this seems straightforward, though it would slow type\u00adchecking \nsince we could not skip over e2 when e1 checks in e1,, e2. Leaving merges aside, the mere fact that .I \nelaborates the expression twice creates problems with mutable references, as we saw in Section 6.5. For \nthis, we could revive the value restriction in .I, at least for expressions whose types might overlap. \n 8. Applying Intersections and Unions 8.1 Overloading A very simple use of unrestricted intersections \nis to overload op\u00aderations such as multiplication and conversion of data to printable form. SML provides \noverloading only for a .xed set of built-in op\u00aderations; it is not possible to write a single square \nfunction, as we do in Figure 10. Despite its appearance, (*[ val square : ... ]*) is not a comment but \nan annotation used to guide our bidirectional typechecker (this syntax, inherited from Stardust, was \nintended for compatibility with SML compilers, which saw these annotations as comments and ignored them). \nIn its present form, this idiom is less powerful than type classes (Wadler and Blott 1989). We could \nextend toString for lists, which would handle lists of integers and lists of reals, but not val mul = \nInt.* val toString = Int.toString val mul = mul ,, Real.* (* shadowsearlier mul *) val toString = toString \n,, Real.toString (*[ val square : (int . int) . (real . real) ]*) val square = fn x . mul (x, x) val \n_ = print (toString (mul (0.5, 300.0)) ^ \"; \") val _ = print (toString (square 9) ^ \"; \") val _ = print \n(toString (square 0.5) ^ \"\\n\") Output of target program after elaboration: 150.0; 81; 0.25 Figure 10. \nExample of overloading lists of lists; the version of toString for lists would use the ear\u00adlier occurrence \nof toString, de.ned for integers and reals only. Adding a mechanism for naming a type and then unioning \nit, recursively, is future work. 8.2 Records Reynolds (1996) developed an encoding of records using \nintersec\u00ad tion types and his version of the merge construct; similar ideas ap\u00adpear in Castagna et al. \n(1995). Though straightforward, this encod\u00ad ing is more expressive than SML records. The idea is to add \nsingle-.eld records as a primitive notion, through a type {fld : A} with introduction form {fld= e} and \nthe usual eliminations (explicit projection and pattern matching). Once this is done, the multi-.eld \nrecord type {fld1 : A1, fld2 : A2} is simply {fld1 : A1} . {fld2 : A2}, and the corresponding intro form \nis a merge: {fld1= A1},, {fld2= A2}. More standard concrete syntax, such as {fld1= A1, fld2= A2}, can \nbe handled trivially during parsing. With subtyping on intersections, we get the desired behaviour of \nwhat SML calls .ex records records with some .elds not listed with fewer of SML s limitations. Using \nthis encoding, a function that expects a record with .elds x and y can be given any record that has at \nleast those .elds, whereas SML only allows one .xed set of .elds. For example, the code in Figure 11 \nis legal in our language but not in SML. One problem with this approach is that expressions with du\u00adplicated \n.eld names are accepted. This is part of the larger issue discussed in Section 7.  8.3 Heterogeneous \nData A common argument for dynamic typing over static typing is that heterogeneous data structures are \nmore convenient. For example, dynamic typing makes it very easy to create and manipulate lists containing \nboth integers and strings. The penalty is the loss of compile-time invariant checking. Perhaps the lists \nshould contain integers and strings, but not booleans; such an invariant is not expressible in traditional \ndynamic typing. A common rebuttal from advocates of static typing is that it is easy to simulate dynamic \ntyping in static typing. Want a list of integers and strings? Just declare a datatype datatype int_or_string \n= Int of int | String of string and use int_or_string lists. This guarantees the invariant that the \nlist has only integers and strings, but is unwieldy: each new element must be wrapped in a constructor, \nand operations on the list elements must unwrap the constructor, even when those operations accept both \nintegers and strings (such as a function of type (int . string) . (string . string)).  (*[ val get_xy \n: {x:int, y:int} . int*int ]*) fun get_xy r = (#x(r), #y(r)) (*[ val tupleToString : int * int . string \n]*) fun tupleToString (x, y) = \"(\" ^ Int.toString x ^ \",\" ^ Int.toString y ^ \")\" val rec1 = {y= 11, x=1} \nval rec2 = {x= 2,y =22, extra =100} val rec3 = {x = 3, y = 33, other = \"a string\"} val _ = print (\"get_xy \nrec1 = \" ^ tupleToString (get_xy rec1) ^ \"\\n\") val _ = print (\"get_xy rec2 = \" ^ tupleToString (get_xy \nrec2) ^ \" (extra = \" ^ Int.toString #extra(rec2) ^ \")\\n\") val _ = print (\"get_xy rec3 = \" ^ tupleToString \n(get_xy rec3) ^ \" (other = \" ^ #other(rec3) ^ \")\\n\") Output of target program after elaboration: get_xy \nrec1 = (1,11) get_xy rec2 = (2,22) (extra = 100) get_xy rec3 = (3,33) (other = a string) Figure 11. \nExample of .exible multi-.eld records datatype a list = nil |:: of a * a list type dyn = int . real . \nstring (*[ val toString : dyn . string ]*) fun toString x = (Int.toString ,, (fn s . s : string) ,, Real.toString) \nx (*[ val hetListToString : dyn list . string ]*) fun hetListToString xs = case xs of nil . \"nil\" | h::t \n. (toString h) ^ \"::\" ^ (hetListToString t) val _ = print \"\\n\\n\" val _ = print (hetListToString [1, 2, \n\"what\", 3.14159, 4, \"why\"]) val _ = print \"\\n\\n\\n\" Output of target program after elaboration: 1::2::what::3.14159::4::why::nil \nFigure 12. Example of heterogeneous data In this situation, our approach provides the compile-time invari\u00adant \nchecking of static typing and the transparency of dynamic typ\u00ading. The type of list elements (if we bother \nto declare it) is just a union type: type int_union_string = int . string Elaboration transforms programs \nwith int_union_string into programs with int_or_string. Along these lines, we use in Figure 12 a type \ndyn,de.ned as int . real . string. It would be useful to also allow lists, but the current implementation \nlacks recursive types of a form that could express dyn = ... . dyn list .  9. Implementation Our implementation \nis faithful to the spirit of the elaboration rules above, but is substantially richer. It is based on \nStardust, a type\u00adchecker for a subset of core Standard ML with support for inductive datatypes, products, \nintersections, unions, re.nement types and in\u00addexed types (Dun.eld 2007), extended with support for (.rst-class) \npolymorphism (Dun.eld 2009). We do not yet support all these features; support for .rst-class polymorphism \nlooks hardest, since Standard ML compilers cannot even handle higher-rank predica\u00adtive polymorphism. \nElaborating programs that use ML-style prenex polymorphism should work, but we currently lack any proof \nor even signi.cant testing to back that up. Our implementation does currently support merges, intersec\u00adtions \nand unions, a top type, a bottom (empty) type, single-.eld records and encoded multi-.eld records (Section \n8.2), and induc\u00ad tive datatypes (if their constructors are not of intersection type, though they can \ntake intersections and unions as argument; remov\u00ading this restriction is a high priority). 9.1 Bidirectional \nTypechecking Our implementation uses bidirectional typechecking (Pierce and Turner 2000; Dun.eld and \nPfenning 2004; Dun.eld 2009), an increasingly common technique in advanced type systems; see Dun.eld \n(2009) for references. This technique offers two major bene.ts over Damas-Milner type inference: it works \nfor many type systems where annotation-free inference is undecidable, and it seems to produce more localized \nerror messages. Bidirectional typechecking does need more type annotations. However, by following the \napproach of Dun.eld and Pfenning (2004), annotations are never needed except on redexes. The present \nimplementation allows some annotations on redexes to be omitted as well. The basic idea of bidirectional \ntypechecking is to separate the activity of checking an expression against a known type from the activity \nof synthesizing a type from the expression itself: Ge . Ae checks against known type A Ge . Ae synthesizes \ntype A In the checking judgment, G, e and A are inputs to the typing al\u00adgorithm, which either succeeds \nor fails. In the synthesis judgment, G and e are inputs and A is output (assuming synthesis does not \nfail). Syntactically speaking, crafting a bidirectional type system from a type assignment system (like \nthe one in Figure 4) is a mat\u00ad ter of taking the colons in the Ge : A judgments, and replacing some with \n. and some with . . Except for mergek, our typing rules can all be found in Dun.eld and Pfenning (2004), \nwho argued that introduction rules should check and elimination rules should synthesize. (Parametric \npolymorphism muddies this picture, but see Dun.eld (2009) for an approach used by our implementation.) \nFor functions, this leads to the bidirectional rules G, x : A f e . BG f e1 . A . BG f e2 . A .I .E G \nf .x. e . A . BG f e1 e2 . B The merge rule, however, neither introduces nor eliminates. We implement \nthe obvious checking rule (which, in practice, always tries to check against e1 and, if that fails, against \ne2): Gek . A Ge1,, e2 . A Since it can be inconvenient to annotate merges, we also implement synthesis \nrules, including one that can synthesize an intersection. Gek . A Ge1 . A1 Ge2 . A2 Ge1,, e2 . A Ge1,, \ne2 . A1 . A2  Given a bidirectional typing derivation, it is generally easy to show that a corresponding \ntype assignment exists: replace all . and . with : (and erase explicit type annotations from the expression). \n 9.2 Performance Intersection typechecking is PSPACE-hard (Reynolds 1996). In practice, we elaborate \nthe examples in Figures 10, 11 and 12 in less than a second, but they are very small. On somewhat larger \nexamples, such as those discussed by Dun.eld (2007), the non\u00ad elaborating version of Stardust could take \nminutes, thanks to heavy use of backtracking search (trying .E1 then .E2,etc.) and the need to check \nthe same expression against different types (.I) or with different assumptions (.E). Elaboration doesn \nt help with this, but it shouldn t hurt by more than a constant factor: the shapes of the derivations \nand the labour of backtracking remain the same. To scale the approach to larger programs, we will need \nto consider how to ef.ciently represent elaborated intersections and unions. Like the theoretical development, \nthe implementation has 2-way intersection and union types, so the type A1 . A2 . A3 is parsed as (A1 \n. A2) . A3, which becomes (A1 *A2)*A3.A.at\u00adtened representation A1 * A2 * A3 would be more ef.cient, \nexcept when the program uses values of type (A1 . A2) . A3 where val\u00adues of type A1 . A2 are expected; \nin that case, nesting the product allows the inner pair to be passed directly with no reboxing. Sym\u00admetry \nis also likely to be an issue: passing v : A1 . A2 where v : A2 . A1 is expected requires building a \nnew pair. Here, it may be helpful to put the components of intersections into a canonical order. The \nforegoing applies to unions as well introducing a value of a three-way union may require two injections, \nand so on.  10. Related Work Intersections were originally developed by Coppo et al. (1981) and Pottinger \n(1980), among others; Hindley (1992) gives a use\u00ad ful introduction and bibliography. Work on union types \nbegan later (MacQueen et al. 1986); Barbanera et al. (1995) is a key paper on type assignment for unions. \nForsythe. In thelate1980s3, Reynolds invented Forsythe(Reynolds 1996), the .rst practical programming \nlanguage based on intersec\u00adtion types. In addition to an unmarked introduction rule like .I, the Forsythe \ntype system includes rules for typing a construct p1,p2 a construction for intersecting or merging meanings \n(Reynolds 1996, p. 24). Roughly analogous to e1,, e2, this construct is used to encode a variety of features, \nbut can only be used unambiguously. For instance, a record and a function can be merged, but two func\u00adtions \ncannot (actually they can, but the second phrase p2 overrides the .rst). Forsythe does not have union \ntypes. The .&#38;-calculus. Castagna et al. (1995) developed the .&#38;\u00adcalculus, which has &#38;-terms \nfunctions whose body is a merge, and whose type is an intersection of arrows. In their semantics, ap\u00adplying \na &#38;-term to some argument reduces the term to the branch of the merge with the smallest (compatible) \ndomain. Suppose we have a &#38;-term with two branches, one of type nat . nat and one of type pos . pos. \nApplying that &#38;-term to a value of type pos steps to the second branch, because its domain pos is \n(strictly) a subtype of nat. Despite the presence of a merge-like construct, their work on the .&#38;-calculus \nis markedly different from ours: it gives a semantics to programs directly, and uses type information \nto do so, whereas we elaborate to a standard term language with no runtime type 3 The citation year 1996 \nis the date of the revised description of Forsythe; the core ideas are found in Reynolds (1988). information. \nIn their work, terms have both compile-time types and run-time types (the run-time types become more \nprecise as the computation continues); the semantics of applying a &#38;-term depends on the run-time \ntype of the argument to choose the branch. The choice of the smallest compatible domain is consistent \nwith notions of inheritance in object-oriented programming, where a class can override the methods of \nits parent. Semantic subtyping. Following the .&#38;-calculus, Frisch et al. (2008) investigated a notion \nof purely semantic subtyping, where the de.nition of subtyping arises from a model of types, as op\u00adposed \nto the syntactic approach used in our system. They support intersections, unions, function spaces and \neven complement. Their language includes a dynamic type dispatch which, very roughly, combines a merge \nwith a generalization of our union elimination. Again, the semantics relies on run-time type information. \nPierce s work. The earliest reference I know for the idea of compiling intersection to product is Pierce \n(1991b): a language with intersection types might even provide two different object\u00adcode sequences for \nthe two versions of + [for int and for real] (p. 11). Pierce also developed a language with union types, \nincluding a term-level construct to explicitly eliminate them (Pierce 1991a). But this construct is only \na marker for where to eliminate the union: it has only one branch, so the same term must typecheck under \neach assumption. Another difference is that this construct is the only way to eliminate a union type \nin his system, whereas our .Eis marker\u00adfree. Intersections, also present in his language, have no explicit \nintroduction construct; the introduction rule is like our .I. Flow types. Turbak et al. (1997) and Wells \net al. (2002) use inter\u00ad sections in a system with .ow types. They produce programs with virtual tuples \nand virtual sums, which correspond to the tuples and sums we produce by elaboration. However, these constructs \nare in\u00adternal: nothing in their work corresponds to our explicit intersection and union term constructors, \nsince their system is only intended to capture existing .ow properties. They do not compile the virtual \nconstructs into the ordinary ones. Heterogeneous data and dynamic typing. Several approaches to combining \ndynamic typing s transparency and static typing s guarantees have been investigated. Soft typing (Cartwright \nand Fagan 1991; Aiken et al. 1994) adds a kind of type inference on top of dynamic typing, but provides \nno ironclad guarantees. Typed Scheme (Tobin-Hochstadt and Felleisen 2008), developed to retroactively \ntype Scheme programs, has a .ow-sensitive type sys\u00adtem with union types, directly supporting heterogeneous \ndata in the style of Section 8.3. Unlike soft typing, Typed Scheme guarantees type safety and provides \ngenuine (even .rst-class) polymorphism, though programmers are expected to provide some annotations. \nType re.nements. Restricting intersections and unions to re.ne\u00adments of a single base type simpli.es \nmany issues, and is conserva\u00adtive: programs can be checked against re.ned types, then compiled normally. \nThis approach has been explored for intersections (Free\u00adman and Pfenning 1991; Davies and Pfenning 2000), \nand for inter\u00ad sections and unions (Dun.eld and Pfenning 2003, 2004).  11. Conclusion We have laid \na simple yet powerful foundation for compiling unre\u00adstricted intersections and unions: elaboration into \na standard func\u00adtional language. Rather than trying to directly understand the be\u00adhaviours of source \nprograms, we describe them via their consis\u00adtency with the target programs. The most immediate challenge \nis coherence: While our elabora\u00adtion approach guarantees type safety of the compiled program, the meaning \nof the compiled program depends on the particular elab\u00adoration typing derivation used; the meaning of \nthe source program is actually implementation-de.ned.  One possible solution is to restrict typing of \nmerges so that a merge has type A only if exactly one branch has type A.We could also partially revive \nthe value restriction, giving non-values intersection type only if (to a conservative approximation) \nboth components of the intersection are provably disjoint, in the sense that no merge-free expression \nhas both types. Another challenge is to reconcile, in spirit and form, the un\u00adrestricted view of intersections \nand unions of this paper with the re.nement approach. Elaborating a re.nement intersection like (pos \n. neg) . (neg . pos) to a pair of functions seems pointless (unless it can somehow facilitate optimizations \nin the compiler). It will probably be necessary to have re.nement and unrestricted versions of the intersection \nand union type construc\u00adtors, at least during elaboration; it may be feasible to hide this distinction \nat the source level. Acknowledgments In 2008, Adam Megacz suggested (after I explained the idea of compiling \nintersection to product) that one could use an exist\u00ading ML compiler as a backend . The anonymous ICFP \nreview\u00aders suggestions have (I hope) signi.cantly improved the presen\u00adtation. Finally, I had useful discussions \nabout this work with Yan Chen, Matthew A. Hammer, Scott Kilpatrick, Neelakantan R. Kr\u00adishnaswami, and \nViktor Vafeiadis.  References Alexander Aiken, Edward L. Wimmers, and T. K. Lakshman. Soft typing with \nconditional types. In Principles of Programming Languages, pages 163 173, 1994. Franco Barbanera, Mariangiola \nDezani-Ciancaglini, and Ugo de Liguoro. Intersection and union types: syntax and semantics. Information \nand Computation, 119:202 230, 1995. Robert Cartwright and Mike Fagan. Soft typing. In Programming Language \nDesign and Implementation, pages 278 292, 1991. Giuseppe Castagna, Giorgio Ghelli, and Giuseppe Longo. \nA cal\u00adculus for overloaded functions with subtyping. Information and Computation, 117(1):115 135, 1995. \nM. Coppo, M. Dezani-Ciancaglini, and B. Venneri. Functional characters of solvable terms. Zeitschrift \nf. math. Logik und Grundlagen d. Math., 27:45 58, 1981. Rowan Davies. Practical Re.nement-Type Checking. \nPhD thesis, Carnegie Mellon University, 2005. CMU-CS-05-110. Rowan Davies and Frank Pfenning. Intersection \ntypes and compu\u00adtational effects. In ICFP, pages 198 208, 2000. Joshua Dun.eld. Re.ned typechecking with \nStardust. In Program\u00adming Languages meets Program Veri.cation (PLPV 07), 2007. Joshua Dun.eld. Greedy \nbidirectional polymorphism. In ML Workshop, pages 15 26, 2009. http://www.cs.cmu.edu/ ~joshuad/papers/poly/. \n Joshua Dun.eld. Untangling typechecking of intersections and unions. In 2010 Workshop on Intersection \nTypes and Related Systems, volume 45 of EPTCS, pages 59 70, 2011. arXiv: 1101.4428v1[cs.PL]. Joshua \nDun.eld. Twelf proofs accompanying this paper, March 2012. http://www.cs.cmu.edu/~joshuad/intcomp.tar \nor http://www.cs.cmu.edu/~joshuad/intcomp/. Joshua Dun.eld and Frank Pfenning. Type assignment for intersec\u00adtions \nand unions in call-by-value languages. In Found. Software Science and Computation Structures (FoSSaCS \n03), pages 250 266, 2003. Joshua Dun.eld and Frank Pfenning. Tridirectional typechecking. In Principles \nof Programming Languages, pages 281 292, 2004. Tim Freeman and Frank Pfenning. Re.nement types for ML. \nIn Programming Language Design and Implementation, pages 268 277, 1991. Alain Frisch, Giuseppe Castagna, \nand V\u00b4eronique Benzaken. Se\u00admantic subtyping: dealing set-theoretically with function, union, intersection, \nand negation types. J. ACM, 55(4):1 64, 2008. J. Roger Hindley. Coppo-Dezani types do not correspond \nto propo\u00adsitional logic. Theoretical Computer Science, 28:235 236, 1984. J. Roger Hindley. Types with \nintersection: An introduction. Formal Aspects of Computing, 4:470 486, 1992. Assaf J. Kfoury and J. B. \nWells. Principality and type inference for intersection types using expansion variables. Theoretical \nComputer Science, 311(1 3):1 70, 2004. David MacQueen, Gordon Plotkin, and Ravi Sethi. An ideal model \nfor recursive polymorphic types. Information and Control, 71: 95 130, 1986. Peter M\u00f8ller Neergaard and \nHarry G. Mairson. Types, potency, and idempotency: Why nonlinearity and amnesia make a type system work. \nIn ICFP, pages 138 149, 2004. Frank Pfenning and Carsten Sch\u00a8urmann. System description: Twelf a meta-logical \nframework for deductive systems. In Int l Conf. Automated Deduction (CADE-16), pages 202 206, 1999. Benjamin \nC. Pierce. Programming with intersection types, union types, and polymorphism. Technical Report CMU-CS-91-106, \nCarnegie Mellon University, 1991a. Benjamin C. Pierce. Programming with intersection types and bounded \npolymorphism. PhD thesis, Carnegie Mellon Univer\u00adsity, 1991b. Technical Report CMU-CS-91-205. Benjamin \nC. Pierce and David N. Turner. Local type inference. ACM Trans. Prog. Lang. Syst., 22:1 44, 2000. Garrel \nPottinger. A type assignment for the strongly normalizable lambda-terms. In To H. B. Curry: Essays on \nCombinatory Logic, Lambda Calculus and Formalism, pages 561 577. Academic Press, 1980. John C. Reynolds. \nPreliminary design of the programming lan\u00adguage Forsythe. Technical Report CMU-CS-88-159, Carnegie Mellon \nUniversity, 1988. http://doi.library.cmu.edu/ 10.1184/OCLC/18612825. John C. Reynolds. The coherence \nof languages with intersection types. In Theoretical Aspects of Computer Software, volume 526 of LNCS, \npages 675 700. Springer, 1991. John C. Reynolds. Design of the programming language Forsythe. Technical \nReport CMU-CS-96-146, Carnegie Mellon Univer\u00adsity, 1996. Sam Tobin-Hochstadt and Matthias Felleisen. \nThe design and im\u00adplementation of Typed Scheme. In Principles of Programming Languages, pages 395 406, \n2008. Franklyn Turbak, Allyn Dimock, Robert Muller, and J. B. Wells. Compiling with polymorphic and polyvariant \n.ow types. In Int l Workshop on Types in Compilation, 1997. Twelf. Twelf wiki, 2012. http://twelf.org/wiki/Main_Page. \nPhilip Wadler and Stephen Blott. How to make ad-hoc polymor\u00adphism less ad hoc.In Principles of Programming \nLanguages, pages 60 76, 1989. J.B. Wells, Allyn Dimock, Robert Muller, and Franklyn Turbak. A calculus \nwith polymorphic and polyvariant .ow types. J. Functional Programming, 12(3):183 227, 2002.  \n\t\t\t", "proc_id": "2364527", "abstract": "<p>Designing and implementing typed programming languages is hard. Every new type system feature requires extending the metatheory and implementation, which are often complicated and fragile. To ease this process, we would like to provide general mechanisms that subsume many different features.</p> <p>In modern type systems, parametric polymorphism is fundamental, but intersection polymorphism has gained little traction in programming languages. Most practical intersection type systems have supported only <i>refinement intersections</i>, which increase the expressiveness of types (more precise properties can be checked) without altering the expressiveness of terms; refinement intersections can simply be erased during compilation. In contrast, <i>unrestricted</i> intersections increase the expressiveness of terms, and can be used to encode diverse language features, promising an economy of both theory and implementation.</p> <p>We describe a foundation for compiling unrestricted intersection and union types: an elaboration type system that generates ordinary <i>&#955;</i>-calculus terms. The key feature is a Forsythe-like merge construct. With this construct, not all reductions of the source program preserve types; however, we prove that ordinary call-by-value evaluation of the elaborated program corresponds to a type-preserving evaluation of the source program.</p> <p>We also describe a prototype implementation and applications of unrestricted intersections and unions: records, operator overloading, and simulating dynamic typing.</p>", "authors": [{"name": "Joshua Dunfield", "author_profile_id": "81100605091", "affiliation": "Max Planck Institute for Software Systems, Kaiserslautern and Saarbr&#252;cken, Germany", "person_id": "P3804299", "email_address": "joshua@mpi-sws.org", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364534", "year": "2012", "article_id": "2364534", "conference": "ICFP", "title": "Elaborating intersection and union types", "url": "http://dl.acm.org/citation.cfm?id=2364534"}