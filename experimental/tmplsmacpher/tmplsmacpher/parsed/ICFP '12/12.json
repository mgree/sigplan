{"article_publication_date": "09-09-2012", "fulltext": "\n Operational Semantics Using the Partiality Monad Nils Anders Danielsson Chalmers University of Technology \nand University of Gothenburg nad@chalmers.se Abstract The operational semantics of a partial, functional \nlanguage is often given as a relation rather than as a function. The latter approach is arguably more \nnatural: if the language is functional, why not take advantage of this when de.ning the semantics? One \ncan im\u00admediately see that a functional semantics is deterministic and, in a constructive setting, computable. \nThis paper shows how one can use the coinductive partiality monad to de.ne big-step or small-step operational \nsemantics for lambda-calculi and virtual machines as total, computable functions (total de.nitional interpreters). \nTo demonstrate that the resulting se\u00admantics are useful type soundness and compiler correctness results \nare also proved. The results have been implemented and checked using Agda, a dependently typed programming \nlanguage and proof assistant. Categories and Subject Descriptors F.3.2 [Logics and Mean\u00adings of Programs]: \nSemantics of Programming Languages Oper\u00adational semantics; D.1.1 [Programming Techniques]: Applicative \n(Functional) Programming; E.1 [Data Structures]; F.3.1 [Logics and Meanings of Programs]: Specifying \nand Verifying and Reason\u00ading about Programs Mechanical veri.cation Keywords Dependent types; mixed induction \nand coinduction; partiality monad 1. Introduction Consider the untyped .-calculus with a countably in.nite \nset of constants c: t ::= c | x | .x.t | t1 t2 Closed terms written in this language can compute to \na value (a constant c or a closure .x.t.), but they can also go wrong (crash) or fail to terminate. How \nwould you write down an operational semantics for this language? A common choice is to de.ne the semantics \nas an induc\u00adtively de.ned relation, either using small steps or big steps. For an example of the latter, \nsee Figure 1: . I t . v means that the term t can terminate with the value v when evaluated in the environment \n.. However, as noted by Leroy and Grall (2009), this de.nition provides no way to distinguish terms which \ngo wrong from terms which fail to terminate. If we want to do this, then we can de.ne two more relations, \nsee Figure 2: . I t ., de.ned coinductively, Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. ICFP 12, September 9 15, 2012, Copenhagen, Denmark. Copyright \nc &#38;#169; 2012 ACM 978-1-4503-1054-3/12/09. . . $10.00 . I c . c .(x) = v . I x . v . I .x.t . .x.t. \n. I t1 . .x.t'.' . I t2 . v' .' , x = v ' I t' . v . I t1 t2 . v  Figure 1. A call-by-value operational \nsemantics for the untyped .\u00adcalculus with constants, specifying which terms can terminate with what values \n(very close to a semantics given by Leroy and Grall (2009)). . I t1 . . I t1 t2 . . I t1 . .x.t'.' . \nI t1 . v . I . I t2 . v' . I t1 t2 . .', x = t2 . v' I t' . . I t1 t2 . def . I t ! =\u00ac (.v.. I t . v) \n.\u00ac (. I t .) Figure 2. Two more operational semantics for the untyped .\u00adcalculus with constants, specifying \nwhich terms can fail to termi\u00adnate or go wrong. The de.nition written using double lines is coin\u00adductive, \nand is taken almost verbatim from Leroy and Grall (2009). means that the term t can fail to terminate \nwhen evaluated in the environment .; and . I t ! means that t goes wrong. Now we have a complete de.nition. \nHowever, this de.nition is somewhat problematic: 1. There are four separate rules which refer to application. \nFor a small language this may be acceptable, but for large languages it seems to be easy to forget some \nrule, and rule duplication can be error-prone. 2. It is not immediately obvious whether the semantics \nis deter\u00administic and/or computable: these properties need to be proved. 3. If we want to de.ne an interpreter \nwhich is correct by construc\u00adtion, then the setup with three relations is awkward. Consider the following \ntype-signature, where 1 is the sum type con\u00adstructor:  eval : . . t . (.v.. I t . v) 1 . I t .1 . I \nt ! This signature states that, for any environment . and term t, the interpreter either returns a value \nv and a proof that t can termi\u00adnate with this value when evaluated in the given environment; or a proof \nthat t can fail to terminate; or a proof that t goes wrong. It should be clear that it is impossible \nto implement eval in a total, constructive language, as this amounts to solving the halting problem. \n The situation may have been a bit less problematic if we had de.ned a small-step semantics instead, \nbut small-step semantics are not necessarily better: Leroy and Grall (2009) claim that big-step semantics \nis more convenient than small-step semantics for some applications , including proving that a compiler \nis correct. I suggest another approach: de.ne the semantics as a function in a total meta-language, using \nthe partiality monad (Capretta 2005) to represent non-termination, where the partiality monad is de.ned \ncoinductively as A.= .X. A 1 X. If this approach is followed then we avoid all the problems above: 1. \nWe have one clause for applications, and the meta-language is total, so we cannot forget a clause. 2. \nThe semantics is a total function, and hence deterministic and computable. 3. The semantics is an interpreter, \nand its type signature does not imply that we solve the halting problem:  [] : Term . Environment . \n(Maybe Value). An additional advantage of using a de.nitional interpreter is that this can make it easy \nto test the semantics (if the interpreter is not too inef.cient). Such tests can be useful in the design \nof non-trivial languages (Aydemir et al. 2005). The main technical contribution of this paper is that \nI show that one can prove typical meta-theoretical properties directly for a semantics de.ned using the \npartiality monad: A big-step, functional semantics is de.ned and proved to be classically equivalent \nto the relational semantics above (Sec\u00adtions 3 and 5; for simplicity well-scoped de Bruijn indices are \nused instead of names).  Type soundness is proved for a simple type system with recur\u00adsive types (Section \n4).  The meaning of a virtual machine is de.ned as a small-step, functional semantics (Section 6). \n A compiler correctness result is proved (Section 7).  The language and the type soundness and compiler \ncorrect\u00adness results are extended to a non-deterministic setting in or\u00adder to illustrate that the approach \ncan handle languages where some details like evaluation order are left up to the compiler writer (Section \n8).  Finally Section 9 contains a brief discussion of term equiva\u00ad lences (applicative bisimilarity \nand contextual equivalence).  As far as I know these are the .rst proofs of type soundness or compiler \ncorrectness for operational semantics de.ned using the partiality monad. The big-step semantics avoids \nthe rule duplica\u00adtion mentioned above, and this is re.ected in the proofs: there is only one case for \napplication, as opposed to four cases in some cor\u00adresponding proofs for relational semantics due to Leroy \nand Grall (2009). Related work is discussed further in Section 1.3. 1.1 Operational? At this point some \nreaders may complain that [] does not de.ne an operational semantics, but rather a denotational one. \nPerhaps a better term would be hybrid operational/denotational , but the semantics is not denotational: \nIt is not de.ned in a compositional way: [ t ] is not de.ned by recursion on the structure of t, but \nrather a combination of corecursion and structural recursion (see Section 3). Furthermore the semantic \ndomain is rather syntactic: it in\u00adcludes closures, and is not de.ned as the solution to a domain equation. \n I do not see this kind of semantics as an alternative to denotational semantics, but rather as an alternative \nto usual operational ones. (See also the discussion of term equivalences in Section 9.) 1.2 Mechanisation \nThe development presented below has been formalised in the de\u00adpendently typed, functional language Agda \n(Norell 2007; Agda Team 2012), and the code has been made available to download. In order to give a clear \npicture of how the results can be mech\u00adanised Agda-like code is also used in the paper. Unfortunately \nAgda s support for total corecursion is somewhat limited,1 so to avoid distracting details the code is \nwritten in an imaginary vari\u00adant of Agda with a very clever productivity checker (and some other smaller \nchanges). The accompanying code is written in actual Agda, sometimes using workarounds (Danielsson 2010) \nto con\u00ad vince Agda that the code is productive. There are also other, minor differences between the accompanying \ncode and the code in the paper. 1.3 Related Work Reynolds (1972) discusses de.nitional interpreters, \nand there is a large body of work on using monads to structure semantics and interpreters, going back \nat least to Moggi (1991) and Wadler (1992). The toy language above is taken from Leroy and Grall (2009), \nwho bring up some of the disadvantages of (inductive) big-step semantics mentioned above. The type system \nin Section 4 is also taken from Leroy and Grall, who discuss various formulations of type soundness (but \nnot the main formulations given below). Fi\u00adnally the virtual machine and compiler de.ned in Sections \n6 7 are also taken from Leroy and Grall, who give a compiler correctness proof. Leroy and Grall also \nde.ne a semantics based on approxima\u00ad tions: First the semantics is de.ned (functionally) at recursion \ndepth n; if n = 0, then the result . is returned. This function is similar to the functional semantics \n[] de.ned in Section 3, but de.ned using recursion on n instead of corecursion and the partial\u00adity monad. \nThe semantics of a term t is then de.ned (relationally) to be s if there is a recursion depth n0 such \nthat the semantics at recursion depth n is s for all n ? n0. Leroy and Grall prove that this semantics \nis equivalent to a relational, big-step semantics. This proof is close to the proof in Section 5 which \nshows that [] is equivalent to a relational, big-step semantics. Further comparisons to the work of Leroy \nand Grall is included below. The type soundness proof in Section 4 is close to proofs given by Tofte \n(1990) and Milner and Tofte (1991). They use ordinary, inductive big-step de.nitions to give semantics \nof languages with cyclic closures, de.ne typing relations for values coinductively (as greatest .xpoints \nof monotone operators F), and use coinduction (x . . F if x . X for some X . F(X)) to prove that certain \nvalues have certain types. In this paper the value typing relation is de.ned inductively rather than \ncoinductively. However, another typing relation, that for possibly non-terminating computations, is de.ned \ncoinductively, and the proof still uses coinduction (which takes the form of corecursion, see Section \n2). Capretta (2005) discusses the partiality monad, and gives a se\u00ad mantics for partial recursive functions \n(primitive recursive func\u00adtions plus minimisation) as a function of type . n.(Nn . N) . (N.n . N.). 1 \nThe same applies to Coq (Coq Development Team 2011). Nakata and Uustalu (2009) de.ne coinductive big-step \nand small-step semantics, in both relational and functional style, for a while language. Their de.nitions \ndo not use the partiality monad, but are trace-based, and have the property that the trace can be com\u00adputed \n(productively) for any source term, converging or diverging. My opinion is that the relational big-step \nde.nition is rather tech\u00adnical and brittle; the authors discuss several modi.cations to the design which \nlead to absurd results, like while true do skip having an arbitrary trace. The functional big-step semantics \navoids these issues, because the semantics is required to be a productive func\u00adtion from a term and an \ninitial state to a trace. Nakata and Uustalu have extended their work to a while language with interactive \nin\u00adput/output (2010), but in this work they use relational de.nitions. Paulin-Mohring (2009) de.nes partial \nstreams using (essen\u00adtially) the partiality monad, shows that partial streams form a pointed CPO, and \nuses this CPO to de.ne a functional semantics for (a minor variation of) Kahn networks. Benton et al. \n(2009) use the partiality monad to construct a lift\u00ading operator for CPOs, and use this operator to give \ndenotational semantics for one typed and one untyped .-calculus; the former semantics is crash-free by \nconstruction, the latter uses . to repre\u00adsent crashes. Benton and Hur (2009) de.ne a compiler from one \nof these languages to a variant of the SECD machine (with a rela\u00adtional, small-step semantics), and prove \ncompiler correctness. Ghani and Uustalu (2004) introduce the partiality monad trans\u00adformer, .MA..X. M \n(A 1 X). (In the setting of Agda M should be restricted to be strictly positive.) Goncharov and Schr\u00a8oder \n(2011) use the partiality monad trans\u00adformer (they use the term resumption monad transformer) to give \na class of functional semantics for a concurrent language. Rutten (1999) de.nes an operational semantics \nfor a while lan\u00adguage corecursively as a function, using a non-constructive vari\u00adant of the partiality \nmonad, A.= (A \u00d7 N) 1 {8} (where 8 represents non-termination and the natural number stands for the number \nof computation steps needed to compute the value of type A). With this variant of the monad the semantics \nis not a computable function, because the semantics returns 8 iff a program fails to ter\u00adminate. Rutten \nalso discusses weak bisimilarity and explains how to construct a compositional semantics from the operational \none. Cousot and Cousot (1992, 2009) describe bi-inductive de.\u00adnitions, which generalise inductive and \ncoinductive de.nitions, and give a number of examples of their use. One of their ex\u00adamples is a big-step \nsemantics for a call-by-value .-calculus. This semantics captures both terminating and non-terminating \nbe\u00adhaviours in a single de.nition, with less duplication of rules than in Figures 1 2, but more than \nin Section 3. An operator F on P(Term \u00d7 (Term . {.})), where Term stands for the set of terms and . stands \nfor non-termination, is .rst de.ned by the following inference rules (where v ranges over values): t1 \n.. t1 . vt2 .. v . v t1 t2 .. t1 t2 .. t1 . .x.tt2 . vt[x := v] . r t1 t2 . r These rules should neither \nbe read inductively nor coinductively. The semantics is instead obtained as the least .xpoint of F with \nrespect to the order r de.ned by X r Y = X+. Y +. X-. Y - , where Z+={ (t, s) . Z | s =. } and Z-= Z \n\\ Z+ . F is not monotone with respect to r (which forms a complete lattice), so Cousot and Cousot give \nan explicit proof of the existence of a least .xpoint (for a closely related semantics). 2. The Partiality \nMonad Agda is a total language (assuming that the implementation is bug\u00adfree, etc.). Ordinary data types \nare inductive. For instance, we can de.ne the type Fin n of natural numbers less than n, and the type \nVec A n of A-lists of length n, as follows: data Fin : N . Set where zero : {n : N}. Fin (1 + n) suc \n: {n : N}. Fin n . Fin (1 + n) data Vec (A : Set) : N . Set where [] : Vec A 0 :: : {n : N}. A . Vec \nA n . Vec A (1 + n)  (Cons is an in.x operator, :: ; the underscores mark the argument positions.) Inductive \ntypes can be destructed using structural recur\u00adsion. As an example we can de.ne a safe lookup/indexing \nfunction: lookup : {A : Set}{n : N}. Fin n . Vec A n . A lookup zero (x :: xs) = x lookup (suc i)(x :: \nxs) = lookup i xs The arguments within braces, {...}, are implicit, and can be omitted if Agda can infer \nthem. To avoid clutter most implicit argument declarations are omitted, together with a few explicit \ninstantiations of implicit arguments. Agda also supports in.nite data through the use of coinduc\u00adtion \n(Coquand 1994). Coinductive types can be introduced using suspensions: 8 A is the type of suspensions, \nthat if forced give us something of type A. Suspensions can be forced using b, and cre\u00adated using C: \nb : 8 A . A C : A .8 A (Here C is a tightly binding pre.x operator. In this paper nothing binds tighter \nexcept for ordinary function application.) The partiality monad is de.ned coinductively as follows: data \n. (A : Set) : Set where now : A . A. later : 8 (A.) . A.  You can read this as the greatest .xpoint \n. X.A 1 X.2 The con\u00adstructor now returns a value immediately, and later postpones a computation. Computations \ncan be postponed forever: never : A. never = later (C never) Here never is de.ned using corecursion, \nin a productive way: even though never can unfold forever, the next constructor can always be computed \nin a .nite number of steps. Note that structural recursion is not supported for coinductive types, as \nthis would allow the de.nition of non-productive functions. The partiality monad is a monad, with now \nas its return opera\u00adtion, and bind de.ned corecursively as follows: > = : A.. (A . B.) . B. now x > = \nf = fx later x > = f = later (C (b x > = f ))  If x fails to terminate, then x > = f also fails to terminate, \nand if x terminates with a value, then f is applied to that value. It is easy to prove the monad laws \nup to (strong) bisimilarity, which is a coinductively de.ned relation: 2 This is not entirely correct \nin the current version of Agda (Altenkirch and Danielsson 2010), but for the purposes of this paper the \ndifferences are irrelevant. ~ data = : A.. A.. Set where ~ now : now x = now x ~b ~ later : 8 (b x \n= y) . later x = later y (Note that the constructors have been overloaded.) This equivalence relation \nrelates diverging computations, and it also relates compu\u00adtations which converge to the same value using \nthe same number of steps. ~ Note that = is a type of potentially in.nite proof terms. ~ Proving x = \ny amounts to constructing a term with this type. This proof technique is quite different from the usual \ncoinductive proof technique (where x . . F for a monotone F if x . X for some X . F(X)), so let me show \nin detail how one can prove that bind is associative: associative : (x : A.)(f : A . B.)(g : B . C.) \n. (x > f == (x > . y . fy = = > g) ~= > g) We can do this using corecursion and case analysis on x: \nassociative (now x) fg = ? associative (later x) fg = ? We can ask Agda what types the two goals (?) \nhave. The .rst one has type fx > g ~fx = == > g, and can be completed by appeal to re.exivity (re.-~: \n(x : A.) . x ~x can be proved == separately): associative (now x) fg == (fx = g)re.-~> ~ The second \ngoal has type later s1 = later s2 for some suspensions s1 and s2, so we can re.ne the goal using a later \nconstructor and a suspension: associative (later x) fg = later (C ?) The new goal has type ~ (b x > \n= f > = g) = (b x > = . y . fy > = g), so we can conclude by appeal to the coinductive hypothesis: associative \n(later x) fg = later (C associative (b x) fg) Note that the proof is productive. Agda can see this, \nbecause the corecursive call is guarded by a constructor and a suspension. Strong bisimilarity is very \nstrict. In many cases weak bisimilar\u00adity, which ignores .nite differences in the number of steps, is \nmore appropriate:3 data : A.. A.. Set where now : now x now x b later : 8 (b x y) . later x later \ny b laterl: x y . later x y b laterr: x y . x later y This relation is de.ned using mixed induction \nand coinduction (in\u00adduction nested inside coinduction, .X.\u00b5Y. FXY). Note that later is coinductive, while \nlaterl and laterr are inductive. An in.nite sequence of later constructors is allowed, for instance to \nprove never never: allowed : never never allowed = later (C allowed) However, only a .nite number \nof consecutive laterl and laterr constructors is allowed, because otherwise we could prove never now \nx: 3 Capretta (2005) de.nes weak bisimilarity in a different but equivalent way. disallowed : never \nnow x disallowed = laterl disallowed On the other hand, because the induction is nested inside the coin\u00adduction \nit is .ne to use an in.nite number of laterl or laterr con\u00adstructors if they are non-consecutive, with \nintervening later con\u00adstructors: also-allowed : never never also-allowed = laterr (later (C also-allowed)) \n If we omit the laterr constructor from the de.nition of weak bisimilarity, then we get a preorder . \nwith the property that x . y holds if y terminates in fewer steps than x (with the same value), but not \nif x terminates in strictly fewer steps than y, or if one of the two computations terminates and the \nother does not: data . : A.. A.. Set where now : now x . now x b later : 8 (b x . y) . later x . later \ny b laterl: x . y . later x . y ~ It is easy to prove that x = y implies x . y, which in turn implies \nx y. The three relations above are transitive, but one needs to be careful when using transitivity in \ncorecursive proofs, because other\u00adwise one can prove absurd things. For instance, given re.- : (x : A.) \n. x x and trans- : x y . y z . x z we can prove that weak bisimilarity is trivial: trivial : (xy \n: A.) . x y trivial x y = trans- (laterr (re.- x)) (trans- (later (C trivial x y)) (laterl (re.- y))) \n This proof uses the following equational reasoning steps: x later (C x) later (C y) y. The problem \nis that trivial is not productive: trans- is too strict . This issue is closely related to the problem \nof weak bisimulation up to weak bisimilarity (Sangiorgi and Milner 1992). Fortunately some uses of transitivity \nare safe. For instance, if we are proving a weak bisimilarity, then it is safe to make use of already \nproved greater-than results, in the following way (where y ; z is a synonym for z . y): x . y . y z \n. x z x y . y ; z . x z (Compare Sangiorgi and Milner s expansion up to ; .) Agda does not provide \na simple way to show that these lemmas are safe, but this could be done using sized types as implemented \nin MiniAgda (Abel 2010).4 With sized types one can de.ne x iy to stand for potentially incomplete proofs \nof x y of size (at least) i, and prove the following lemma: . i. x . y . y iz . x iz This lemma is \nnot too strict : the type tells us that the (bound on the) size of the incomplete de.nition is preserved. \nUnfortunately MiniAgda, which is a research prototype, is very awkward to use in larger developments. \nFor more details about coinduction and corecursion in Agda, and further discussion of transitivity in \na coinductive setting, see Danielsson and Altenkirch (2010). 4 The experimental implementation of sized \ntypes in Agda does not support coinduction. 3. A Functional, Operational Semantics This section de.nes \nan operational semantics for the untyped .\u00adcalculus with constants. Let us start by de.ning the syntax \nof the language. Just as Leroy and Grall (2009) I use de Bruijn indices to represent variables, but I \nuse a well-scoped approach, using the type system to keep track of the free variables. Terms of type \nTm n have at most n free variables: data Tm (n : N) : Set where con : N . Tm n --Constant. var : Fin \nn . Tm n --Variable. lam : Tm (1 + n) . Tm n --Abstraction. \u00b7 : Tm n . Tm n . Tm n --Application. Environments \nand values are de.ned mutually: mutual Env : N . Set Env n = Vec Value n data Value : Set where con \n: N . Value --Constant. lam : Tm (1 + n) . Env n . Value --Closure. Note that the body of a closure \nhas at most one free variable which is not bound in the environment. The language supports two kinds \nof effects , partiality and crashes. The partiality monad is used to represent partiality, and the maybe \nmonad is used to represent crashes: [] : Tm n . Env n . (Maybe Value). (Maybe A has two constructors, \nnothing : Maybe A and just : A . Maybe A.) The combined monad is the maybe monad transformer (.MA. M \n(Maybe A)) applied to the partiality monad. We can de.ne a failing computation, as well as return and \nbind, as follows: fail : (Maybe A). fail = now nothing return : A . (Maybe A). return x = now (just x) \n > = : (Maybe A).. (A . (Maybe B).) . (Maybe B). now nothing > = f = fail now (just x)> = f = fx later \nx > = f = later (C (b x > = f )) It should also be possible to use the reader monad transformer to handle \nthe environment, but I believe that this would make the code harder to follow. With the monad in place \nit is easy to de.ne the semantics using two mutually (co)recursive functions: mutual ] : Tm n . Env n \n. (Maybe Value). con i . = return (con i) var x . = return (lookup x .) lam t . = return (lam t .) [ \nt1 \u00b7 t2 ] . = t1 .> = . v1 . > = . v2 . [ t2 ] . v1 v2 : Value . Value . (Maybe Value). con i1 v2 \n= fail lam t1 .1 v2 = later (C ([ t1 ] (v2 :: .1)))  Constants are returned immediately, variables \nare looked up in the environment, and abstractions are paired up with the environment to form a closure. \nThe interesting case is application: t1 \u00b7 t2 is evaluated by .rst evaluating t1 to a value v1, then (if \nthe evaluation of t1 terminates without a crash) t2 to v2, and .nally evaluating the application v1 \nv2. If v1 is a constant, then we crash. If v1 is a closure, then a later constructor is emitted and the \nclosure s body is evaluated in its environment extended by v2. The result contains one later constructor \nfor every \u00df-redex that has been reduced (in.nitely many in case of non-termination). Note that this is \na call-by-value semantics, with functions eval\u00aduated before arguments. Note also that the semantics is \nnot compo\u00adsitional, i.e. not de.ned by recursion on the structure of the term, so it is not a denotational \nsemantics. (It would be if were de.ned prior to []; it is easy to construct a compositional semantics \non top of this one.) Agda does not accept the code above; it is not obvious to the productivity checker \nthat [] and are total (productive) functions. If bind had been a constructor, then Agda would have found \nthat the code uses a lexicographic combination of guarded corecursion and structural recursion: every \ncall path from [] to [] is either 1. guarded by one or more constructors and at least one suspension \n(and nothing else), or 2. guardedness is preserved (zero or more constructors/suspen\u00adsions), and the \nterm argument becomes strictly smaller.  Now, bind is not a constructor, but it does preserve guardedness: \nit takes apart its .rst argument, but introduces a new suspension before forcing an old one in MiniAgda \none can show that bind preserves the sizes of its arguments. For a formal explanation of totality, see \nthe accompanying code.5 The semantics could also have been de.ned using continuation\u00adpassing style, and \nthen we could have avoided the use of bind: mutual : Tm n . Env n . (Value . (Maybe A).) . []CPS (Maybe \nA). con i CPS . k = k (con i) var x CPS . k = k (lookup x .) lam t CPS . k = k (lam t .) . k = t1 . (. \nv1 . [ t1 \u00b7 t2 ] CPS CPS . (. v2 . [ t2 ] CPS (v1 CPS v2) k)) : Value . Value . (Value . (Maybe A).) \n. CPS (Maybe A). (con i1 = fail CPS v2) k (lam t1 .1 CPS v2) k = later (C ([ t1 ]CPS (v2 :: .1) k)) \n This de.nition would not have made the productivity checker any happier (it is productive, though, see \nthe accompanying code). However, it avoids the inef.cient implementation of bind; note that bind traverses \nthe full pre.x of later constructors before encounter\u00ading the now constructor, if any. Before we leave \nthis section, let us work out a small example. The term (.x.xx) (.x.xx) can be de.ned as follows (writing \n0 instead of zero): Q : Tm 0 Q = lam (var 0 \u00b7 var 0) \u00b7 lam (var 0 \u00b7 var 0)  It is easy to show that \nthis term does not terminate: 5 In the accompanying code [] is de.ned using a data type containing the \nconstructors return, > = , fail and later, thus ensuring guardedness. These constructors are interpreted \nin the usual way in a second pass over the result. This technique is explained in detail by Danielsson \n(2010). Q-loops : [ Q ] [] never Q-loops = later (C Q-loops) 4. Type Soundness To illustrate how the \nsemantics can be used, let us de.ne a type system and prove type soundness. I follow Leroy and Grall \n(2009) and de.ne recursive, simple types coinductively as follows: data Ty : Set where nat : Ty : 8 Ty \n.8 Ty . Ty _ Contexts can be de.ned as vectors of types: Ctxt : N . Set Ctxt n = Vec Ty n The type \nsystem can then be de.ned inductively. 1 I t . s means that t has type s in context 1: data I. (1 : Ctxt \nn) : Tm n . Ty . Set where con : 1 I con i . nat var : 1 I var x . lookup x 1 lam : bs :: 1 I t . bt \n. 1 I lam t . s _ t \u00b7 : 1 I t1 . s _ t . 1 I t2 . bs . 1 I t1 \u00b7 t2 . bt The use of negative recursive \ntypes implies that there are well\u00adtyped terms which do not terminate. For instance, Q is typeable with \nany type: Q-well-typed : (t : Ty) . [] I Q . t Q-well-typed t = \u00b7{s = Cs}{t = Ct}(lam (var \u00b7 var)) (lam \n(var \u00b7 var)) where s = Cs _ Ct (Some implicit arguments which Agda could not infer have been given explicitly \nusing the {x = ...} notation.) Let us now prove that well-typed programs (closed terms) do not go wrong. \nIt is easy to state what should be proved: type-soundness : [] I t . s .\u00ac ([ t ] [] fail) Here \u00ac is \nnegation (\u00ac A = A . Empty, where Empty is the empty type). As noted by Leroy and Grall it is harder to \nstate type soundness for usual big-step semantics, because such semantics do not distinguish between \nterms which go wrong and terms which fail to terminate. We can start by de.ning a reusable predicate \ntransformer which lifts predicates on A to predicates on (Maybe A).. If Lift P x holds, then we know \nboth that the computation x does not crash, and that if x terminates with a value, then the value satis.es \nP. Lift is de.ned coinductively as follows: data Lift (P : A . Set) : (Maybe A).. Set where now-just \n: Px . Lift P (return x) later : 8 (Lift P (b x)) . Lift P (later x)  The proof below uses the fact \nthat bind preserves Lift: > =-cong : Lift P x . ({x : A}. Px . Lift Q (fx)) . Lift Q (x > = f ) Let \nus now de.ne some typing predicates for values and com\u00adputations, introduced mainly as part of the proof \nof type soundness. WFV s v means that the value v is well-formed with respect to the type s . This relation \nis de.ned inductively, mutually with a corre\u00adsponding relation for environments: mutual data WFV: Ty \n. Value . Set where con : WFV nat (con i) lam : bs :: 1 I t . bt . WFE 1. . WFV (s _ t) (lam t .) data \nWFE: Ctxt n . Env n . Set where [] : WFE [] [] :: : WFV s v . WFE 1. . WFE (s :: 1) (v :: .) The most \ninteresting case above is that for closures. A closure lam t . is well-formed with respect to s _ t if \nthere is a context 1 such that 1 I lam t . s _ t and . is well-formed with respect to 1. The predicates \nare related by the following unsurprising lemma: lookupwf : (x : Fin n) . WFE 1. . WFV (lookup x 1) (lookup \nx .)  We can use the predicate transformer introduced above to lift WFV to computations: WF. : Ty . \n(Maybe Value).. Set WF. s x = Lift (WFV s) x Non-terminating computations are well-formed, and terminating \ncomputations are well-formed if they are successful (not nothing) and the value is well-formed. The following \nlemma implies that type soundness can be established by showing that [ t ] [ ] is well\u00adformed: does-not-go-wrong \n: WF. s x .\u00ac (x fail) does-not-go-wrong (now-just ) () does-not-go-wrong (later wf )(laterl eq) = does-not-go-wrong \n(b wf ) eq Recall that negation is a function into the empty type. The lemma is proved by structural \nrecursion: induction on the structure of the proof of x fail. The .rst clause contains an absurd pat\u00adtern \n, (), to indicate that there is no constructor application of type return v fail. We can now prove the \nmain lemma, which states that the computations resulting from evaluating well-typed terms in well\u00adformed \nenvironments are well-formed. This lemma uses the same form of nested corecursion/structural recursion \nas the de.nition of the semantics: mutual : 1 I t . s . WFE 1. . WF. s([ t ] .) wf wf con .wf = now-just \ncon wf (var {x = x}).wf = now-just (lookupwf x .wf) wf (lam t.).wf = now-just (lam t. .wf) \u00b7 t2.).wf \n= [] wf (t1. wf t1. .wf > =-cong . fwf . > =-cong . vwf . [] wf t2. .wf wf fwf vwf wf : WFV (s _ t) \nf . WFV (b s) v . WF. (b t) (f v) wf (lam t1. .1wf) v2wf = later (C  []wf t1. (v2wf :: .1wf)) The \nimplicit variable pattern {x = x} is used to bind the variable x, which is used on the right-hand side. \nFinally we can conclude: type-soundness : [] I t . s .\u00ac ([ t ] [] fail) type-soundness t.= does-not-go-wrong \n([]wf t. []) Note that there is only one case for application in the proof above (plus one sub-case \nin wf). The proof of type soundness is formulated for a functional se\u00admantics de.ned using environments \nand closures, whereas Leroy and Grall (2009) prove type soundness for relational semantics de\u00ad.ned using \nsubstitutions. I have chosen to use environments and closures in this paper to avoid distracting details \nrelated to substi\u00adtutions. However, given an implementation of the operation which substitutes a term \nfor variable zero it is easy to de.ne a substitution\u00adbased functional semantics using the partiality \nmonad, and given a proof showing that this operation preserves types it is easy to adapt the proof above \nto this semantics. See the accompanying code for details. The proof above can be compared to a typical \ntype sound\u00adness proof formulated for a relational, substitution-based small\u00adstep semantics. Such a proof \noften amounts to proving progress and preservation: progress : [] I t . s . Value t 1. . t '. t r t ' \npreservation : [] I t . s . t r t '. [] I t '. s Here Value t means that t is a value, r is the small-step \nrelation, and . . t '. ... can be read as there exists a t ' such that. . . . Given these two lemmas \none can prove type soundness using classi\u00adcal reasoning (Leroy and Grall 2009): type-soundness : [] I \nt . s . t r81. . t '. t r* t '\u00d7 Value t ' Here r* is the re.exive transitive closure of r , t r8 means \nthat t can reduce forever, and \u00d7 can be read as and . (Note that this statement of type soundness is \ninappropriate for non-deterministic languages, as it does not rule out the possibility of crashes.) The \nlemma []wf above can be seen as encompassing both progress and preservation, plus the combination of \nthese two lemmas into type soundness. This combination does not need to involve classical reasoning, \nbecause WF. is de.ned coinductively. 5. The Semantics are Classically Equivalent Let us now prove that \nthe semantics given in Section 3 is classically equivalent to a relational semantics. The semantics given \nin Figures 1 2 can be adapted to a setting with well-scoped terms and de Bruijn indices in the following \nway: data I. (. : Env n) : Tm n . Value . Set where con : . I con i . con i var : . I var x . lookup \nx . lam : . I lam t . lam t . ' app : . I t1 . lam t ' . '. . I t2 . v . ' v :: . 'I t '. v . . I t1 \n\u00b7 t2 . v data I. (. : Env n) : Tm n . Set where appl: 8 (. I t1 .) . . I t1 \u00b7 t2 . r app: . I t1 . v \n.8 (. I t2 .) . . I t1 \u00b7 t2 . ' app : . I t1 . lam t ' . '. . I t2 . v . ' 8 (v :: . 'I t '.) . . I t1 \n\u00b7 t2 . I ! : Env n . Tm n . Set . I t ! =\u00ac (. . v . . I t . v) \u00d7\u00ac (. I t .)  Note that I. is de.ned \ninductively and I. coinductively. How should we state the equivalence of I. / I./ I ! and []? The following \nmay seem like a suitable statement: . I t . v . t . return v . I t .. t . never . I t ! . fail [ t \n] . However, in a constructive setting one cannot prove that [ t ] . never implies . I t .. To see why, \nlet us try. Assume that we have a proof p of type [ t1 \u00b7 t2 ] . never. Now we need to construct a proof \nstarting with either appl, appr or app. In order to do this we need to know whether t1 terminates or \nnot, but this is not decidable given only the proof p. It also seems unlikely that we can prove that \n. I t ! implies [ t ] . fail: one might imagine that this can be proved by just executing [ t ] . until \nit terminates and then performing a case analysis, but the fact that t does not fail to terminate is \nnot (obviously) enough to convince Agda that it does terminate. We can avoid these issues by assuming \nthe following form of excluded middle, which states that everything (in Set) is decidable: EM : Set1 \nEM = (A : Set) . A 1\u00ac A  We end up with the following six proof obligations: . I t . v . t . return \nv (1) . I t . . never (2) [ t ] . t . return v . . I t . v (3) EM . never . . I t . (4) [ t ] . EM . \n. I t ! . fail (5) [ t ] . fail . . I t ! (6) [ t ] . The last two follow easily from the previous ones, \nso let us focus on the .rst four: 1. Given p : . I t . v it is easy to prove [ t ] . return v by recursion \non the structure of p. The only interesting case is application. Let us introduce the following abbreviation: \n = x1 > = . v1 . x2 > = . v2 . v1 v2 x1 [\u00b7] x2 We can then proceed as follows (using the same names \nas in the app constructor s type signature): ~ t1 \u00b7 t2 ] . = \u00b7 [ t1 ] . [ t2 ] . return (lam t ' . ' \n) [ \u00b7] return v ' ' [ t ' ] (v :: . ' ) return v The inductive hypothesis is used twice in the second \nstep and once in the last one. 2. One can prove that . I t . implies [ t ] . never using corecursion \nplus an inner recursion on the structure of t. In the case of the app constructor we can proceed as follows: \n~ t1 = \u00b7 t2 ] . \u00b7 [ t1 ] . [ t2 ] . ~ return (lam t ' . ' ) [ \u00b7] return v '= ' later (C [ t ' ] (v :: \n. ' )) never The second step uses (1) twice, once for p1: . I t1 . lam t ' . ' and once for p2: . I t2 \n. v ' , plus the fact that x now v implies that x now v. The last step uses the coinductive hy\u00ad ' pothesis \n(under a guard) for p3: v :: . 'I t '.. The appl case is different: ~ = [ t1 \u00b7 t2 ] . \u00b7 t2 . [ t1 ] \n. ~ never = [ \u00b7] [ t2 ] . never The last step uses the fact that never is a left zero of bind. The second \nstep uses the inductive hypothesis for p : . I t1 .; note that t1 is structurally smaller than t1 \u00b7 t2, \nand that this call is not guarded.  The appr case is similar to the appl one, and omitted. Note that \nthe use of transitivity in this proof is safe, as discussed in Section 2.  3. Given p : [ t ] . return \nv one can observe that p cannot contain the constructors later or laterr: it must have the form laterl \n(... (laterl now) ...), with a .nite number of laterl constructors one for every \u00df-reduction in the computation \nof t .. Let the size of p be this number. One can prove that return v implies . I t . v by complete \ninduction [ t ] . on this size. Only the application case is interesting. We can prove the fol\u00adlowing \ninversion lemma: (x > = f ) return v . ' . . v . (x return v ' ) \u00d7 (fv ' return v) Here the size of \nthe left-hand proof is equal to the sum of the sizes of the two right-hand proofs. If we have [ t1 \u00b7 \nt2 ] . return v, then we can use inversion twice plus case analysis to deduce that [ t1 ] . return \n(lam t ' . ' ) and [ t2 ] . ' return v ' for some t ' , . ' , v ' such that [ t ' ] (v :: . ' ) return \nv. We can .nish by applying app to three instances of the induc\u00adtive hypothesis, after making sure that \nthe proofs are small enough. This proof is a bit awkward when written out in detail, due to the use of \nsizes. 4. Finally we should prove that excluded middle and [ t ] . never imply . I t .. This can be \nproved using corecursion. As before the only interesting case is application. We can prove the following \ninversion lemma by using excluded middle: (x > = f ) never . x never 1 . . v . (x return v) \u00d7 (fv \n never) If x > = f does not terminate, then either x fails to terminate, or x terminates with a value \nv and fv does not terminate. Given a proof of [ t1 \u00b7 t2 ] . never we can use inversion twice to determine \nwhich of appl, appr and app to emit, in each case continuing corecursively (and in the latter two cases \nalso using (3)). 6. Virtual Machine This section de.nes a virtual machine (VM), following Leroy and \nGrall (2009) but de.ning the semantics functionally instead of relationally, and using a well-scoped \napproach. (The accompanying code contains a relational semantics and a proof showing that it is equivalent \nto the functional one.) The VM is stack-based, and uses the following instructions: mutual data Instr \n(n : N) : Set where var : Fin n . Instr n --Push variable. con : N . Instr n --Push constant. clo : Code \n(1 + n) . Instr n --Push closure. app : Instr n --Apply function. ret : Instr n --Return. Code : N . \nSet Code n = List (Instr n) Instructions of type Instr n have at most n free variables. The type family \nCode consists of sequences of instructions. Values and environments (VM-Value and VM-Env) are de.ned \nas in Section 3, but using Code instead of Tm in the de.nition of closures. Stacks contain values and \nreturn frames: data Stack-element : Set where val : VM-Value . Stack-element ret : Code n . VM-Env n \n. Stack-element Stack : Set Stack = List Stack-element The VM operates on states containing three components, \nthe code, a stack, and an environment: data State : Set where ( ,, ) : Code n . Stack . VM-Env n . State \n The result of running the VM one step, starting in a given state, is either a new state, normal termination \nwith a value, or abnormal termination (a crash): data Result : Set where continue : State . Result done \n: VM-Value . Result crash : Result  The function step (see Figure 3) shows how the result is computed. \nGiven step it is easy to de.ne the VM s semantics corecursively: exec : State . (Maybe VM-Value). exec \ns with step s ' ... | continue s = later (C exec s ' ) ... | done v = return v ... | crash = fail In \na state s, run step s. If the result is continue s ' , continue running from s ' ; if it is done v, return \nv; and if it is crash, fail. The function exec is an example of a functional, small-step operational \nsemantics. As before it is clear that the semantics is deterministic and computable, and just as with \na relational small\u00adstep semantics we avoid duplication of rules. However, the use of a wild-card in the \nlast clause of step means that it is possible to forget a rule. If we tried to omit one of the clauses \nfrom the de.nition of [] (Section 3), then the de.nition would be rejected, but this is not the case \nfor the .rst six clauses of step. 7. Compiler Correctness Let us now de.ne a compiler from Tm to Code \nand prove that it preserves the semantics of the input program. The de.nition follows Leroy and Grall \n(2009), but uses a code continuation to avoid the use of list append and some proof overhead (Hutton \n2007, Section 13.7): comp : Tm n . Code n . Code n comp (con i) c = con i :: c comp (var x) c = var x \n:: c comp (lam t) c = clo (comp t [ret]) :: c comp (t1 \u00b7 t2) c = comp t1 (comp t2 (app :: c)) We can \nalso compile values: compv: Value . VM-Value compv (con i) = con i compv (lam t .) = lam (comp t [ret])(map \ncompv .) I state compiler correctness as follows: correct : (t : Tm 0) . exec ( comp t [], [], [] ) ([ \nt ] [] > = . v . return (compv v))  Given a closed term t, the result of running the corresponding compiled \ncode (comp t [ ]) on the VM (starting with an empty stack and environment), should be the same as evaluating \nthe term (in step : State . Result step ( [] , val v :: [] step ( var x :: c, step ( con i :: c, ' step \n( clo c :: c, ' step ( app :: c, val v :: val (lam c ' step ( ret :: c, val v :: ret c . ' step , [] \n)= s,. )= s,. )= s,. )= . ' ) :: s,. )= :: s,. )= =  done v continue ( c , val (lookup x .) :: s,. ) \ncontinue ( c , val (con i) :: s,. ) ' continue ( c , val (lam c .) :: s,. ) ' continue ( c , ret c \n. :: s, v :: . ') ' continue ( c , val v :: s,. ')crash Figure 3. A function which computes the result \nof running the virtual machine one step from a given state. an empty environment) and, if evaluation \nterminates with a value, return the compiled variant of this value. We can compare this statement to \na corresponding statement phrased for relational semantics: * ([] I t . v .( comp t [], [], [] ) r ( \n[], val (compv v) :: [], [] )) \u00d7 ([] I t . .( comp t [], [], [] ) r 8) \u00d7 ([] I t ! .( comp t [], [], \n[] ) ri)  Here r : State . State . Set is the VM s small-step relation, * r its re.exive transitive \nclosure, s r 8 means that there is an in.nite transition sequence starting in s, and s ri means that \nthere is a stuck transition sequence starting in s (i.e., a sequence which cannot be extended further, \nand which does not end with a state of the form ( [], val :: [], [] )). I prefer the statement of correct \nabove: I .nd it easier to understand and get correct. Let us now prove correct. In order to do this the \nstatement can be generalised as follows: correct ' : (t : Tm n) {k : Value . (Maybe VM-Value).}(hyp : \n(v : Value) . exec ( c, val (compv v) :: s, map compv . ) kv) . exec ( comp t c, s, map compv . ) > = \nk) ([ t ] . This statement is written in continuation-passing style to avoid some uses of transitivity \n(which can be problematic, as discussed in Section 2). The statement is proved mutually with the following \none: -correct : (v1 v2: Value) {k : Value . (Maybe VM-Value).} (hyp : (v : Value) . exec ( c, val (compv \nv) :: s, map compv . ) kv) . exec ( app :: c, val (compv v2) :: val (compv v1) :: s, map compv . ) (v1 \n v2 > = k) The statements can be proved using the same recursion structure as : mixed corecursion/structural \nrecursion. []CPS/ CPS The interesting case of correct ' is application, where we can proceed as follows \n(with safe uses of transitivity): exec ( comp t1 (comp t2 (app :: c)), s, map compv . ) ~ t1 .> = . v1 \n. t2 .> = . v2 . v1 v2 > = k = ~ > = > = . v2 . v1 v2)> = k = [ t1 ] .. v1 . ([ t2 ] . ~ > = . v1 \n. > = . v2 . v1 v2)> = k =([ t1 ] . [ t2 ] . > = k [ t1 \u00b7 t2 ] . The last three steps use associativity \nof bind twice. (These uses of associativity could have been avoided by using continuation\u00adpassing style \ninstead of bind when de.ning the semantics. See the accompanying code.) The .rst step is more complicated. \nHere is its proof term: correct ' t1 (. v1 . correct ' t2 (. v2 . -correct v1 v2 hyp)) First an appeal \nto the inductive hypothesis (t1 is structurally smaller than t1 \u00b7 t2), then, in the continuation, another \nappeal to the in\u00adductive hypothesis, and .nally, in the nested continuation, a use of -correct. The interesting \ncase of -correct is when v1 is a closure, lam t1 .1, in which case we need to prove that exec ( app :: \nc, val (compv v2) :: val (compv (lam t1 .1)) :: s, map compv . ) is weakly bisimilar to lam t1 .1 v2 \n> = k. We can start by emitting a later constructor and suspension: later (C ?) The question mark should \nbe replaced by a proof showing that exec ( comp t1[ret], ret c (map compv .) :: s, map compv (v2 :: .1) \n)  is weakly bisimilar to [ t1 ] (v2 :: .1)> = k. This can be proved by appeal to the coinductive hypothesis: \ncorrect ' t1 (. v . laterl (hyp v)) Here the use of laterl corresponds to the reduction of exec ( [ret], \nval (compv v) :: ret c (map compv .) :: s, map compv (v2 :: .1) )  to exec ( c, val (compv v) :: s, \nmap compv . ), which has the right form for the use of hyp. The proof sketch above and especially the \ncompact proof terms may look a bit bewildering. Fortunately one does not have to understand every detail \nof a machine-checked proof. It is more important to understand the statement of the theorem.6 Further\u00admore, \nthe writer of the proof has the support of a proof assistant, that in my case provided much help with \nthe construction of the proof terms. The proof above can be compared to that of Leroy and Grall (2009), \nwho prove the following two implications (in their slightly different setting): * [] I t . v .( comp \nt [], [], [] ) r ( [], val (compv v) :: [], [] ) 8 [] I t . .( comp t [], [], [] ) r 6 With the caveat \nthat one should not put too much trust into Agda, which is a very experimental system. Consider application. \nIn the proof above there is one case for ap\u00adplication, with two sub-cases, one for crashes and one for \nclosures. In the proof of the two implications there are four cases for ap\u00adplication: one in case of \ntermination and three for non-terminating applications. The rule duplication in the semantics shows up \nas rule duplication in the proof. 8. Non-determinism The compiler correctness statement used above is \nsometimes too restrictive (Leroy 2009). For instance, evaluation order may be left up to the compiler. \nThis section illustrates how this kind of situation can be handled by de.ning a non-deterministic language, \nand implementing a compiler that implements one out of many possible semantics for this language. The \nsyntax of the language de.ned in Section 3 is extended with a term-former for non-deterministic choice: \n| : Tm n . Tm n . Tm n The semantic domain is now the maybe monad transformer applied to the partiality \nmonad transformer (.MA..X. M (A 1 X) for strictly positive monads M) applied to a non-determinism monad \n(.A.\u00b5X. A 1 X \u00d7 X; Moggi (1990)), implemented monolithi\u00adcally as follows: data D (A : Set) : Set where \nfail : DA return : A . DA | : DA . DA . DA later : 8 (DA) . DA > = : DA . (A . DB) . DB fail > = f = \nfail return x > = f = fx (x1 | x2)> = f = (x1 > = f ) | (x2 > = f ) later x > = f = later (C (b x > \n= f )) As before the monad laws hold up to strong bisimilarity, which can be de.ned as follows: ~ data \n= : DA . DA . Set where ~ fail : fail = fail ~ return : return x = return x ~~~ | : x1 = y1 . x2 = y2 \n. x1 | x2 = y1 | y2 ~b ~ later : 8 (b x = y) . later x = later y Finally we can extend the semantics \nby adding a clause for choice (note that | is overloaded): = [ t1 | t2 ] . [ t1 ] . | [ t2 ] . It may \nbe worth pointing out that now the semantics is no longer deterministic, despite being de.ned as a function. \nAs an example we can de.ne a call-by-value .xpoint combi\u00adnator (Z = .f . (.g. f (.x. ggx)) (.g. f (.x. \nggx))) and a non\u00addeterministic non-terminating term (t = Z (.fx. fx | fx) 0): Z : Tm 0 Z = lam (h \u00b7 h) \nwhere h = lam (var 1 \u00b7 lam (var 1 \u00b7 var 1 \u00b7 var 0)) t : Tm 0 t = Z \u00b7 lam (lam (var 1 \u00b7 var 0 | var 1 \n\u00b7 var 0)) \u00b7 con 0 The semantics of t, [ t ] [ ], is strongly bisimilar to t-sem: t-sem : D Value t-sem \n= later (C later (C later (C later (C (t-sem | t-sem))))) The virtual machine is unchanged, so the compiler \ncorrectness statement will relate deterministic and non-deterministic computa\u00adtions. To do this we can \nuse the following variant of weak bisimi\u00adlarity: data . : (Maybe A).. DA . Set where fail : now nothing \n. fail return : now (just x) . return x |l: x . y1 . x . y1 | y2 |r: x . y2 . x . y1 | y2 . b later \n: 8 (b xy) . later x . later y b . . laterl: xy . later xy b laterr: x . y . x . later y You can read \nx . y as x implements one of the allowed seman\u00adtics of y . Compiler correctness can now be stated as \nfollows: correct : (t : Tm 0) . exec ( comp t [], [], [] ) . [ t ] [] > = . v . return (compv v) If \nwe extend the compiler in the following way, then we can prove that it is correct using an argument which \nis very similar to that in Section 7: comp (t1 | t2) c = comp t1 c We can also prove type soundness \nfor the non-deterministic language, using the type system from Section 4 extended with the following \nrule: | : 1 I t1 . s . 1 I t2 . s . 1 I t1 | t2 . s Type soundness can be stated using . . Type-correct \nterms should not crash, no matter how the non-determinism is resolved: type-soundness : [] I t . s . \n\u00ac (now nothing . [ t ] [])  It is easy to prove this statement by adapting the proof from Sec\u00adtion 4. \nAll it takes is to extend the Lift type with the constructor | : Lift P x . Lift P y . Lift P (x | y), \n and then propagating this change through the rest of the proof. Note that the new de.nition of Lift \nuses induction nested inside coinduction (as do D and . ). 9. Term Equivalences Let us now return to \nthe deterministic language from Section 3. Weak bisimilarity as de.ned in Section 2 is, despite its name, \na very strong notion of equality for the semantic domain (Maybe Value).. We can lift this equality to \nclosed terms in the following way: = : Tm 0 . Tm 0 . Set t1 = t2 = [ t1 ] [] [ t2 ] [] This is a very \nsyntactic equality, which distinguishes the obser\u00advationally equivalent terms t1 = lam (lam (var 0)) \n\u00b7 con 0 and t2 = lam (var 0), because [ t1 ] [] return (lam (var 0)(con 0 :: [])) return (lam (var 0) \n[]) [ t2 ] []. The relational big-step semantics from Section 5 is no different: [] I t1 . v does not \nimply that we have [ ] I t2 . v. This section de.nes some less syntactical term equivalences. Discussion \nof the .ner points of these equivalences is out of scope for this paper; the main point is that they \ncan be de.ned without too much fuss. Let us start by de.ning a notion of applicative bisimilarity (Abramsky \n1990). Computations are equivalent ( . ) if they are weakly bisimilar, with equivalent (rather than equal) \npossi\u00adbly exceptional values; possibly exceptional values are equivalent ( MV ) if they are of the same \nkind and, in the case of success, contain equivalent values; and values are equivalent ( V ) if they \nare either equal constants, or closures which are equivalent when evaluated with the free variables bound \nto an arbitrary value:7 mutual data . : (Maybe Value).. (Maybe Value).. Set where now : u MV v . now \nu . now v later : 8 (b x . b y) . later x . later y laterl : b x . y . later x . y laterr : x . \nb y . x . later y data MV : Maybe Value . Maybe Value . Set where just : u V v . just u MV just v nothing \n: nothing MV nothing data V: Value . Value . Set where con : con i V con i lam : (. v .8 ([ t1 ] (v :: \n.1) . [ t2 ] (v :: .2))) . lam t1 .1 V lam t2 .2 This is yet again a de.nition which uses induction \nnested inside coinduction. Note that the lam constructor is coinductive. If this constructor were inductive, \nthen the relations would not be re.ex\u00adive: lam (var zero) [ ] would be provably distinct from itself. \nUsing the relations above we can de.ne applicative bisimilarity by stating that terms are equivalent \nif they are equivalent when evaluated in an arbitrary context: T: Tm n . Tm n . Set t1 T = . t2 . . . \n[ t1 ] . [ t2 ] . The de.nition of . is very similar to the de.nition of weak bisimilarity in Section \n2. It is possible to de.ne a single notion of weak bisimilarity, parametrised by a relation to use for \nvalues. The accompanying code uses such a de.nition. Let us now turn to contextual equivalence. Contexts \nwith zero or more holes can be de.ned as follows: data Context (m : N) : N . Set where hole : Context \nm m con : N . Context m n var : Fin n . Context m n lam : Context m (1 + n) . Context m n \u00b7 : Context \nm n . Context m n . Context m n The type Context m n contains contexts whose holes expect terms of type \nTm m. If we .ll the holes, then we get a term of type Tm n: []: Context m n . Tm m . Tm n hole [t] = \nt con i [t] = con i var x [t] = var x lam C [t] = lam (C [t]) (C1 \u00b7 C2) [t] = C1 [t] \u00b7 C2 [t] Contextual \nequivalence can be de.ned in two equivalent ways. The usual one states that t1 and t2 are contextually \nequivalent if C [t1 ] terminates iff C [t2 ] terminates, for any closing context C: . : A.. Set x .=. \n. v . x now v 7 . v . ... means the same as (v : ) . ...; Agda tries to infer the value of the underscore \nautomatically. C: Tm n . Tm n . Set t1 C t2 =. C . [ C [t1] ] [] .. [ C [t2] ] [] . However, we can \nalso de.ne contextual equivalence using weak bisimilarity: ' C: Tm n . Tm n . Set ' . t1 t2 =. C . [ \nC [t1] ] [] [ C [t2] ] [] C Here . is a notion of weak bisimilarity which identi.es all terminating \ncomputations: now : now u . now v It is easy to prove that these two notions of contextual equivalence \nare equivalent. As an aside one can note that the contextual equivalences above are a bit strange, because \nthere is no context which distinguishes con 0 from con 1. This could be .xed by extending the language \nwith suitable constructions for observing the difference between distinct constants. 10. Conclusions \nWhen writing down a semantics I think one of the main priorities should be to make it easy to understand. \nSometimes a more com\u00adplicated de.nition may be more convenient for certain tasks, but in that case one \ncan de.ne two semantics and prove that they are equivalent. I hope I have convinced you that functional \noperational seman\u00adtics de.ned using the partiality monad are easy to understand. I have also used two \nsuch semantics to state a compiler correctness result, and I .nd this statement to be easier to understand \nthan a cor\u00adresponding statement phrased using relational semantics (see Sec\u00adtion 7). The semantics also \nseem to be useful when it comes to proving typical meta-theoretic properties, at least for the simple \nlanguages discussed in this paper. I have proved type soundness and com\u00adpiler correctness directly for \nthe semantics given above. The type soundness proof in Section 4 is given in relatively complete, formal \ndetail, yet it is short and should be easy to follow. Furthermore, as mentioned in Section 7, the compiler \ncorrectness proof avoids some duplication which is present in a corresponding proof for relational semantics. \nAs discussed above the support for total corecursion in lan\u00adguages like Agda and Coq is somewhat limited: \nde.nitions like [] are often rejected. However, my experience with sized types in MiniAgda (see Section \n2) is encouraging. I suspect that a more polished implementation of sized types could be quite satisfying \nto work with. Finally I want to mention a drawback of this kind of semantics: proofs which proceed by \ninduction on the structure of I. when a relational big-step semantics is used can become somewhat awkward \nwhen transferred to this setting, as illustrated by the proof in Section 5 showing that [ t ] . return \nv implies . I t . v. However, it is unclear to me how often this is actually a problem. For instance, \nneither the type soundness proofs nor the compiler correctness proofs in this paper are affected by this \ndrawback. Acknowledgements I want to thank Thorsten Altenkirch for encouraging this line of work, Peter \nDybjer for useful feedback on a draft of the paper, and Tarmo Uustalu for pointing out some related work. \nI would also like to thank the anonymous reviewers for lots of useful feedback. Large parts of this work \nwere done when I was working at the University of Nottingham, with .nancial support from EPSRC (grant \ncode: EP/E04350X/1). I have also received support from the ERC: The research leading to these results \nhas received funding from the European Research Council under the European Union s Seventh Framework \nProgramme (FP7/2007-2013) / ERC grant agreement n. 247219. References Andreas Abel. MiniAgda: Integrating \nsized and dependent types. In Pro\u00adceedings Workshop on Partiality and Recursion in Interactive Theorem \nProvers (PAR 2010), volume 43 of EPTCS, 2010. doi:10.4204/EPTCS. 43.2. Samson Abramsky. The lazy lambda \ncalculus. In Research Topics in Functional Programming. Addison-Wesley, 1990. The Agda Team. The Agda \nWiki. Available at http://wiki.portal. chalmers.se/agda/, 2012. Thorsten Altenkirch and Nils Anders Danielsson. \nTermination checking in the presence of nested inductive and coinductive types. Short note supporting \na talk given at the Workshop on Partiality and Recursion in Interactive Theorem Provers (PAR 2010), 2010. \nBrian E. Aydemir, Aaron Bohannon, Matthew Fairbairn, J. Nathan Foster, Benjamin C. Pierce, Peter Sewell, \nDimitrios Vytiniotis, Geoffrey Wash\u00adburn, Stephanie Weirich, and Steve Zdancewic. Mechanized metatheory \nfor the masses: The PoplMark challenge. In Theorem Proving in Higher Order Logics, 18th International \nConference, TPHOLs 2005, volume 3603 of LNCS, pages 50 65, 2005. doi:10.1007/11541868 4. Nick Benton \nand Chung-Kil Hur. Biorthogonality, step-indexing and com\u00adpiler correctness. In ICFP 09, Proceedings \nof the 2009 ACM SIGPLAN International Conference on Functional Programming, pages 97 107, 2009. doi:10.1145/1596550.1596567. \nNick Benton, Andrew Kennedy, and Carsten Varming. Some domain theory and denotational semantics in Coq. \nIn Theorem Proving in Higher Order Logics, 22nd International Conference, TPHOLs 2009, volume 5674 of \nLNCS, pages 115 130, 2009. doi:10.1007/978-3-642-03359-9 10. Venanzio Capretta. General recursion via \ncoinductive types. Logical Meth\u00adods in Computer Science, 1(2):1 28, 2005. doi:10.2168/LMCS-1(2: 1)2005. \nThe Coq Development Team. The Coq Proof Assistant, Reference Manual, Version 8.3pl3, 2011. Thierry Coquand. \nIn.nite objects in type theory. In Types for Proofs and Programs, International Workshop TYPES 93, volume \n806 of LNCS, pages 62 78, 1994. doi:10.1007/3-540-58085-9 72. Patrick Cousot and Radhia Cousot. Inductive \nde.nitions, semantics and abstract interpretations. In POPL 92, Proceedings of the 19th ACM SIGPLAN-SIGACT \nsymposium on Principles of programming lan\u00adguages, pages 83 94, 1992. doi:10.1145/143165.143184. Patrick \nCousot and Radhia Cousot. Bi-inductive structural semantics. Infor\u00admation and Computation, 207(2):258 \n283, 2009. doi:10.1016/j.ic.2008. 03.025. Nils Anders Danielsson. Beating the productivity checker using \nembedded languages. In Proceedings Workshop on Partiality and Recursion in Interactive Theorem Provers \n(PAR 2010), volume 43 of EPTCS, pages 29 48, 2010. doi:10.4204/EPTCS.43.3. Nils Anders Danielsson and \nThorsten Altenkirch. Subtyping, declaratively: An exercise in mixed induction and coinduction. In Mathematics \nof Pro\u00adgram Construction, 10th International Conference, MPC 2010, volume 6120 of LNCS, pages 100 118, \n2010. doi:10.1007/978-3-642-13321-3 8. Neil Ghani and Tarmo Uustalu. Monad combinators, non-determinism \nand probabilistic choice. Extended abstract distributed at the work\u00adshop on Categorical Methods in Concurrency, \nInteraction and Mobility (CMCIM 2004), 2004. Sergey Goncharov and Lutz Schr\u00a8A coinductive calculus for \nasyn\u00adoder. chronous side-effecting processes. In Fundamentals of Computation Theory, 18th International \nSymposium, FCT 2011, volume 6914 of LNCS, pages 276 287, 2011. doi:10.1007/978-3-642-22953-4 24. Graham \nHutton. Programming in Haskell. Cambridge University Press, 2007. Xavier Leroy. Formal veri.cation of \na realistic compiler. Communications of the ACM, 52:107 115, 2009. doi:10.1145/1538788.1538814. Xavier \nLeroy and Herv\u00b4e Grall. Coinductive big-step operational semantics. Information and Computation, 207(2):284 \n304, 2009. doi:10.1016/j.ic. 2007.12.004. Robin Milner and Mads Tofte. Co-induction in relational semantics. \nTheoretical Computer Science, 87(1):209 220, 1991. doi:10.1016/ 0304-3975(91)90033-X. Eugenio Moggi. \nAn abstract view of programming languages. Technical Report ECS-LFCS-90-113, Lab. for Found. of Comp. \nSci., University of Edinburgh, 1990. Eugenio Moggi. Notions of computation and monads. Information and \nComputation, 93(1):55 92, 1991. doi:10.1016/0890-5401(91)90052-4. Keiko Nakata and Tarmo Uustalu. Trace-based \ncoinductive operational semantics for While: Big-step and small-step, relational and functional styles. \nIn Theorem Proving in Higher Order Logics, 22nd International Conference, TPHOLs 2009, volume 5674 of \nLNCS, pages 375 390, 2009. doi:10.1007/978-3-642-03359-9 26. Keiko Nakata and Tarmo Uustalu. Resumptions, \nweak bisimilarity and big-step semantics for While with interactive I/O: An exercise in mixed induction-coinduction. \nIn Proceedings Seventh Workshop on Structural Operational Semantics (SOS 2010), volume 32 of EPTCS, pages \n57 75, 2010. doi:10.4204/EPTCS.32.5. Ulf Norell. Towards a practical programming language based on depen\u00addent \ntype theory. PhD thesis, Chalmers University of Technology and G\u00a8 oteborg University, 2007. Christine \nPaulin-Mohring. A constructive denotational semantics for Kahn networks in Coq. In From Semantics to \nComputer Science: Essays in Honour of Gilles Kahn, pages 383 413. Cambridge University Press, 2009. John \nC. Reynolds. De.nitional interpreters for higher-order programming languages. In ACM 72, Proceedings \nof the ACM annual conference, volume 2, pages 717 740, 1972. doi:10.1145/800194.805852. J.J.M.M. Rutten. \nA note on coinduction and weak bisimilarity for while programs. Theoretical Informatics and Applications, \n33:393 400, 1999. doi:10.1051/ita:1999125. Davide Sangiorgi and Robin Milner. The problem of weak bisimulation \nup to . In CONCUR 92, Third International Conference on Concur\u00adrency Theory, volume 630 of LNCS, pages \n32 46, 1992. doi:10.1007/ BFb0084781. Mads Tofte. Type inference for polymorphic references. Information \nand Computation, 89(1):1 34, 1990. doi:10.1016/0890-5401(90)90018-D. Philip Wadler. The essence of functional \nprogramming. In POPL 92, Proceedings of the 19th ACM SIGPLAN-SIGACT symposium on Princi\u00adples of programming \nlanguages, pages 1 14, 1992. doi:10.1145/143165. 143169.  \n\t\t\t", "proc_id": "2364527", "abstract": "<p>The operational semantics of a partial, functional language is often given as a relation rather than as a function. The latter approach is arguably more natural: if the language is functional, why not take advantage of this when defining the semantics? One can immediately see that a functional semantics is deterministic and, in a constructive setting, computable.</p> <p>This paper shows how one can use the coinductive partiality monad to define big-step or small-step operational semantics for lambda-calculi and virtual machines as total, computable functions (total definitional interpreters). To demonstrate that the resulting semantics are useful type soundness and compiler correctness results are also proved. The results have been implemented and checked using Agda, a dependently typed programming language and proof assistant.</p>", "authors": [{"name": "Nils Anders Danielsson", "author_profile_id": "81548018887", "affiliation": "Chalmers University of Technology &#38; University of Gothenburg, G&#246;teborg, Sweden", "person_id": "P3804319", "email_address": "nad@chalmers.se", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364546", "year": "2012", "article_id": "2364546", "conference": "ICFP", "title": "Operational semantics using the partiality monad", "url": "http://dl.acm.org/citation.cfm?id=2364546"}