{"article_publication_date": "09-09-2012", "fulltext": "\n Work Ef.cient Higher-Order Vectorisation Ben Lippmeier Manuel M. T. Chakravarty Gabriele Keller Roman \nLeshchinskiy Simon Peyton Jones Computer Science and Engineering Microsoft Research Ltd. University \nof New South Wales, Australia Cambridge, England {benl,chak,keller,rl}@cse.unsw.edu.au {simonpj}@microsoft.com \n Abstract Existing approaches to higher-order vectorisation, also known as .attening nested data parallelism, \ndo not preserve the asymptotic work complexity of the source program. Straightforward exam\u00adples, such \nas sparse matrix-vector multiplication, can suffer a se\u00advere blow-up in both time and space, which limits \nthe practical\u00adity of this method. We discuss why this problem arises, identify the mis-handling of index \nspace transforms as the root cause, and present a solution using a re.ned representation of nested arrays. \nWe have implemented this solution in Data Parallel Haskell (DPH) and present benchmarks showing that \nrealistic programs, which used to suffer the blow-up, now have the correct asymptotic work complexity. \nIn some cases, the asymptotic complexity of the vec\u00adtorised program is even better than the original. \nCategories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs and Features Concurrent \nprogram\u00adming structures; Polymorphism; Abstract data types General Terms Languages, Performance Keywords \nArrays, Data parallelism, Haskell 1. Introduction Data Parallel Haskell (DPH) is an extension to the \nGlasgow Haskell Compiler(GHC)thatoffers nested data parallelism. With nested parallelism, each parallel \ncomputation may spawn further paral\u00adlel computations of arbitrary complexity, whereas with .at paral\u00adlelism, \nthey cannot; so nested data parallelism is vastly more ex\u00adpressive for the programmer. On the other hand, \n.at data paral\u00adlelism is far easier to implement, because .at data parallelism ad\u00admits a simple load \nbalancing strategy and can be used on SIMD hardware (including GPUs). The higher-order vectorisation \n(or .attening) transform [17] bridges the gap, by transforming source programs using nested data parallelism \ninto ones using just .at data parallelism [1, 17]. That is, it transforms the program we want to write \ninto the one we want to run. Unfortunately, practical implementations, including ours, have had a serious \n.aw: the standard transformation only guarantees Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. ICFP 12, September 9 15, 2012, Copenhagen, Denmark. Copyright \n&#38;#169; 2012 ACM 978-1-4503-1054-3/12/09 $15.00. to preserve the parallel depth complexity of the \nsource program, and not its asymptotic work complexity as well. If our benchmark machines had an in.nite \nnumber of processors, this would be of no concern, but alas they do not. Nor is this phenomenon rare: \nwhile working on DPH we have encountered simple programs that suffer a severe, and sometimes even exponential, \nblow-up in time and space when vectorised. This is a well-known problem that arises due to the .at represen\u00adtation \nof nested arrays in vectorised code [3, Appendix C]. Several attempts have been made to solve it, but \nso far they have been either incomplete [15], do not work with higher order languages [10], or give up \non .attening the parallelism [4, 8] or arrays [18] altogether. In this paper, we will show how to overcome \nthe problem for full\u00adscale higher-order vectorisation. Overall, we make the following contributions: \n1. We present the .rst approach to higher-order vectorisation that, we believe, ensures the vectorised \nprogram maintains the asymptotic work complexity of the source program, while al\u00adlowing nested arrays \nto retain their .attened form (\u00a74). We only require that vectorised programs are contained [2, 18], a \nprop\u00aderty related to the standard handling of branches in SIMD-style parallel programming (\u00a75.6). 2. \nWe identify the key problem of mishandled index space trans\u00adforms, which worsen the asymptotic complexity \nof vectorised code using prior .at array representations (\u00a73). 3. We introduce a novel delayed implementation \nof the central in\u00addex space transforms (\u00a74) and discuss the pragmatics of achiev\u00ading good constant factors, \nin addition to the required asymptotic performance (\u00a76). 4. Finally, we present performance .gures for \nseveral realistic pro\u00adgrams, including the Barnes-Hut n-body algorithm. This sup\u00adports our claim that \nour delayed implementation of the in\u00addex space transforms leads to vectorised programs that operate within \nthe required asymptotic bounds (\u00a77).  The claim that our new approach to higher-order vectorisation \nis work ef.cient is supported by experiments with a concrete imple\u00admentation in GHC but not yet by formal \nproof, which we leave to future work. Nevertheless, our work presents a signi.cant ad\u00advance of the state \nof the art on a long-standing problem. Achieving good space complexity is an orthogonal problem that \nwe discuss in \u00a75.5. A reference implementation of our new array representation is available in the companion \ntechnical report [13].  2. The Asymptotic Complexity Problem We start with an example illustrating \nvectorisation. The function retrieve simultaneously indexes several arrays, the xss, each of which is \ndistributed across one subarray of indices contained in iss. It returns a nested array of the results \nand uses nested parallelism an inner parallel computation (mapP indexP xss) is performed for each of \nthe outer ones. retrieve :: [:[:Char:]:] -> [:[:Int:]:] -> [:[:Char:]:] retrieve xss iss = zipWithP mapP \n(mapP indexP xss) iss Here is retrieve applied to two example arrays.1 retrieve [[A B] [C D E] [F G] \n[H]] (xss) [[1 0 1] [2] [1 0] [0]] (iss) ==> [[B A B] [E] [G F] [H]] In the type signature, [:Char:] \nrefers to bulk-strict, parallel, one\u00addimensional arrays. Elements of these arrays are stored unboxed, \nso that demanding any element causes them all to be computed. zipWithP and mapP are parallel versions \nof the corresponding list functions, while indexP is array indexing Figure 1 shows these and other typical \narray operations. The work-complexity of retrieve is linear in the number of leaf elements of the array \niss (seven here), since each is used once for indexing. (Technically it is also linear in the number \nof sub-arrays in iss, since empty arrays in iss would still cost.) The vectorised form of retrieve is \nthe following the ac\u00adcompanying technical report [13] includes the full derivation. retrieve_v :: PA \n(PA Char) -> PA (PA Int) -> PA (PA Char) retrieve_v xss iss = let ns = takeLengths iss in unconcat iss \n$ index_l (sum ns) (replicates ns xss) $ concat iss The type PA is a generic representation type that \ndetermines the layout of the user-visible type [::] in a type-dependent manner [6]. When applied to our \nexample array, the function .rst concatenates iss to yield a .at array of indices, and uses takeLengths \nto get the lengths of the inner arrays of iss: ns = takeLengths iss = [3 1 2 1] iss1=concatiss =[101 \n2 10 0] The replicates function distributes the subarrays of xss across the .at indices array. It takes \nan array of replication counts and an array of elements, and replicates each element by its corresponding \ncount: xss1 = replicates ns xss = replicates [3 1 2 1] [[A B] [C D E] [F G] [H] =[[A B] [A B] [A B] [C \nDE] [F G] [F G][H]] Now we have one sub-array for each of the elements of iss1. Continuing on, we use \nthe lifted indexing operator index_l,which has the following type: index_l :: Int -> PA (PA e) -> PA \nInt -> PA e Given an array of arrays, and an array of indices of the same length, for each subarray-index \npair, index_l retrieves the correspond\u00ading element of the array. In other words, index_l is effectively \nzipWithP indexP, except that it gets the length of the two arrays as an additional .rst argument. 1 The \nconcrete syntax for array literals is [:x1, ..., xn:].To save space, we elide the colon and comma. lengthP \n:: [:e:] -> Int indexP, (!:) :: [:e:] -> Int -> e concatP :: [:[:e:]:] -> [:e:] mapP :: (d -> e) -> [:d:] \n-> [:e:] zipWithP :: (c -> d -> e) -> [:c:] -> [:d:] -> [:e:] foldP ::(e->e->e)->[:e:]->e Figure 1. \nUser Visible Array Operators data PA e = PA {length :: Int, pdata :: PData e} data family PData e data \ninstance PData Int = PInt (Vector Int) data instance PData Char = PChar (Vector Char) data instance PData \n(PA e) = PNested Segd (PData e) data Segd = Segd {lengths, indices :: Vector Int} index ::PAe ->Int ->e \nindex_l :: Int -> PA (PA e) -> PA Int -> PA e replicate :: Int -> e -> PA e replicates :: Vector Int \n-> PA e -> PA e concat :: PA (PA e) -> PA e unconcat :: PA (PA e) -> PA e -> PA (PA e) Figure 2. Baseline \nArray Representation and Parallel Primitives Applying index_l to our example yields the following: xss2 \n= index_l (sum ns) (replicates ns xss) (concat iss) = index_l 7 [[A B] [A B][A B] [C D E][F G] [F G] \n[H]] [1 012 100] =[BA BEGFH] Finally, we use unconcat to reapply the original nesting structure to this \n.at result: xss3 = unconcat [[1 01] [2] [1 0] [0]] [B A BE G FH] = [[B A B] [E] [G F] [H]] In the vectorised \nfunction retrieve_v, all parallelism comes from the implementation of the primitive .at parallel array \noperators such as index_l and replicates. However, simply converting nested parallelism to .at parallelism \nis not suf.cient. We previ\u00adously implemented replicates by physically copying each of the subarrays. \nWith that implementation, suppose we evaluate the fol\u00adlowing expression: retrieve [[A B CD EF GH]] [[0 \n12 34 5 67]] In terms of the source program, this expression takes eight steps, one for each index in \nthe second array. However, in the vectorised program, replicates will also copy [A BC DE FG H] eight \ntimes. As we have the same number of characters in the .rst array as indices in the second array, vectorisation \nturned a function that performs O(n) work into an O(n2) function: Disaster! It turns out that the trouble \nwith replicates is just one of a class of problems related to the mishandling of index space trans\u00adforms \nduring vectorisation. These transforms change the mapping between elements in the source and result arrays, \nbut do not com\u00adpute new element values. In addition to identifying index space transforms as the culprit, \nin the next two sections we contribute a novel delayed implementation, which enables vectorised programs \nto remain within the required asymptotic complexity bounds. What are those bounds? Consider an absolutely \ndirect implementation of DPH, in which a value of type [:a:] is represented by an ordinary array of pointers \nto values of type a. Complexity Goal: for the output of vectorisation to have the same asymptotic work \ncomplexity as the direct im\u00adplementation, but with much better constant factors and amenability to parallelism. \n  3. Baseline Representation of Nested Arrays A key idea of Blelloch s vectorisation transformation \nis to .atten the representation of nested arrays, as well as the parallelism itself. More precisely: \nan array A of sub-arrays A0,A1,...,An-1 (each with its own length) is represented by (a) a single long \narray of data, D =[A0,A1,...,An-1]all laid out in one contiguous block, and (b) a segment descriptor \nthat gives the length of each Ai in the data block D. We call Ai the segments of A. The idea is to divide \nthe data block D evenly over the processors, and process each chunk independently in parallel. This provides \nboth excellent granularity and excellent data locality, which is intended to satisfy the second part \nof our Complexity Goal. There is some book-keeping to do on the segment descriptor; generating that book-keeping \ncode is the job of the vectorisation transformation. Figure 2 gives the representation of nested arrays \nin Haskell, using GHC s data families [5]. An array of type (PA e) is repre\u00adsented by a pair PA nd,where \nn is the length of the array, and d :: PData e contains its data. The representation of PData is type-dependent \n hence, its declaration as a data family.When the argument type is a scalar, matters are simple: PData \nInt is represented merely by a Vector Int, which we take as primitive here2. Arrays of Char are represented \nsimilarly. On the other hand, the data component of a nested array, with type PData (PA e) is represented \nby a pair of a segment descriptor of type Segd,and the data block of type PData e. The segment descriptor \nSegd has two .elds, lengths and indices. The latter is just the scan (running sum) of the former, but \nwe maintain both in the implementation to avoid recomputing indices from lengths repeatedly. Each is \na .at Vector of Int values. Using the example from the previous section, the array xss1 has type (PA \n(PA Char)) and is represented like this: replicates [3 1 2 1] [[A B] [C D E] [F G] [H]] =[[A B][A B] \n[A B] [C DE] [F G] [F G] [H]] -----------------------------------------------(ARR0) PA 7 (PNested (Segd \nlengths: [2 2 2 3 2 2 1] indices: [0 2 4 6 9 11 13]) (PChar [A BA BA B CD EF GF G H])) We show the logical \nvalue of the array above the line, and its physical representation below. The representation is determined \nby the data type declarations in Figure 2. The result array is built with an outer PA constructor, pairing \nits length, 7, with the pay\u00adload of type PData (PA Char).From the data instance for PData (PA e), again \nin Figure 2, we see that the data .eld con\u00adsists of a PNested constructor pairing a segment descriptor \nwith a value of type PData Char. Finally, the latter consists of a PChar constructor wrapping a .at Vector \nof Char values. The process continues recursively in the case of deeper nesting: the reader may care \nto write down the representation of a value of type PA (PA (PA Int)). We will see an example in \u00a74.4. \nNow the problem with replicates becomes glaringly obvi\u00adous. The baseline representation of arrays, which \nwas carefully chosen to give good locality and granularity, is physically inca\u00adpable of representing \nthe sharing between subarrays in the re\u00adsult and losing that sharing leads directly to worsening the \nasymptotic complexity. It is not possible to simply eliminate the call to replicates itself, because \nthis function plays a critical role in vectorisation. In the example from \u00a72, replicates dis\u00adtributes \nshared values from the context of the outer computation (zipWithP mapP) into the inner computation (mapP \nindexP). Since we cannot eliminate replicates, the only way forward is to change the representation of \nnested arrays. 2 It is provided by the vector library. YLUWXDO >>$ %@ >$ %@ >$ %@>&#38; ' (@>) *@ >) \n*@>+@@ + EORFN ) * Figure 3. New Array Representation  4. New Representation of Nested Arrays The \nnew array representation must support all index space trans\u00adforms that vectorisation introduces, in a \nway that allows the vec\u00adtorised program to have the same asymptotic complexity as the original unvectorised \nprogram. This is up to containment which is discussed in \u00a75.6. In most cases this comes down to having \nthe same complexity as the direct representation, where nested arrays are stored as .at arrays of pointers \nto more arrays. However, we cannot use this representation as described, because it would lose the granularity \nand data locality bene.ts of the baseline segmented representation. We need the best of both worlds. \n 4.1 Physical, Virtual and Scattered Segments An example array with the same value as ARR0 is shown in \nFigure 3. Our new representation has the following key features: 1. We distinguish between physical and \nvirtual segments. Physical segments consist of real element data in memory, while virtual segments are \nde.ned by mapping onto physical segments. This distinction enables us to de.ne nested arrays with repeated \nsegments without copying element data. 2. The physical segments of a nested array may now be scattered \nthrough several data blocks, instead of being contiguous. Al\u00adthough we prefer segments to be contiguous \nfor locality rea\u00adsons, we must also allow them to be scattered, so that we can .lter a nested array without \ncopying element data.  In the example, there are seven virtual segments de.ned from four physical segments. \nThe physical segments lie scattered in two data blocks. We will see why we need to allow physical segments \nto lie in separate data blocks in \u00a74.5. The overall segment descriptor is now strati.ed into three layers: \nVSegd (virtual segments); SSegd (scattered segments) and plain Segd (contiguous segments). In our terminology, \nwe refer to all of VSegd, SSegd and Segd as segment descriptors , individually or grouped together. At \nthe bottom layer, Segd gives the length of each segment, and would be suf.cient to describe the array \nif all segments were contiguous in a single block. The SSegd gives the index of the source data block, \nand starting position for each physical segment in its block. The VSegd provides the mapping between \nvirtual and physical segments. We have elided the indices .eld from the diagram for clarity, but also \ninclude this in our new array representation as part of the Segd.  data PA e = PA { length :: Int, pdata \n:: PData e } data family PData e data family PDatas e data instance PData Int = PInt (Vector Int) data \ninstance PDatas Int = PInts (Vector (Vector Int)) data instance PData Char = PChar (Vector Char) data \ninstance PDatas Char = PChars (Vector (Vector Char)) data instance PData (PA e) = PNested { vsegd :: \nVSegd, pdatas :: PDatas e } data instance PDatas (PA e) = PNesteds (Vector (PData (PA e))) data VSegd \n--Virtual-segment descriptor. = VSegd { segmap :: Vector PsId, ssegd :: SSegd } data SSegd --Scattered-segment \ndescriptor. = SSegd { sources :: Vector DbId, starts :: Vector Int } , segd :: Segd } data Segd --Contiguous-segment \ndescriptor. = Segd { lengths :: Vector Int, indices :: Vector Int } type PsId = Int --Physical segment \nId, indexes sources type DbId = Int --Data block Id, indexes pdatas Figure 4. De.nition of the New Array \nRepresentation  4.2 The Concrete De.nition The concrete de.nition of our new array type is given in \nFigure 4. Thedatatype PA is unchanged from Figure 2: a pair of a length and payload. The instances for \nPData Int and PData Char are also unchanged. The difference is in the representation of nested arrays: \ndata instance PData (PA a) = PNested { vsegd :: VSegd, pdatas :: PDatas a } The payload is now a PDatas \n(plural) rather than PData.Where PData represents a single data block, PDatas represents a vector of \ndata blocks. We use the type DbId (short for data-block identi.er) to index this vector of PData values. \nThe vsegd .eld holds the virtual segment descriptor. It consists of a vector of physical segment identi.ers \n(segmap), and a scattered segment descriptor (ssegd). The segmap maps virtual segments onto physical \nsegments and corresponds 1-1 with the outer level of the array being represented. In Figure 3, we have \nseven entries in this map and seven subarrays in the overall nested array. Each entry in the segmap is \na physical segment identi.er,of type PsId.A PsId is the index of one of the physical segments described \nby the SSegd and Segd types. Crucially, the segmap can contain repeated use of the same physical segment. \nIn Figure 3 we have used [0 00 12 23] to indicate three copies of the .rst physical segment, one copy \nof the second, and so on. This is how we represent the sharing de.ned by replicates. Note that we can \nnot just store the replication counts [31 21] directly because we must be able to map virtual segments \nto physical segments in constant time. The SSegd and Segd together describe the physical segments. Together \nthey contain four vectors, all of the same length,two of them nested inside the segd .eld. The sources \nvector gives the data block identi.er, DbId, which is the index of one of the data blocks in the pdatas \n.eld. The next two, starts and lengths, give the starting position and length of the physical segment \nin that data block. Finally indices is, as before, a cached copy of the scan (accumuated sum) of lengths. \nKeeping SSegd and Segd separate is helpful when optimising vectorised code for absolute performance, \nwhich we discuss in \u00a76. Finally, the array representation must obey the following invari\u00adants: 1. The \nlengths of the sources, starts, lengths,and indices .elds must all be the same. 2. Every PsId in the \nsegmap must be less than the length of the sources .eld. 3. Each DbId in sources must be less than the \nlength of the pdatas vector. 4. Each element of starts[i] must be less than the length of pdatas[sources[i]]. \n 5. The indices .eld is equal to init (scan (+) 0 lengths). 6. All physical segments de.ned by the SSegd \nand Segd types must be reachable from the segmap.More precisely,the set of physical segment identi.ers \nin the segmap must cover [0..np-1],where np is the length of the starts, sources, lengths,and indices \n.elds. 7. All pdata blocks must be reachable from the sources .eld. More precisely, the set of sources \nmust cover [0..nb-1], where nb is the length of the pdatas vector.  Invariants 1 to 4 are standard well-formedness \nconditions. In\u00advariant 2 ensures that each physical segment identi.er points to a real physical segment. \nInvariant 3 ensures that each data block identi.er points to a real data block. Invariant 5 says that \nindices is precomputed from lengths. The reason for this is discussed in \u00a76. Invariants 6 and 7 ensure \nthat the size of the internal structure of the array is bounded by the number of virtual segments, which \nis necessary for the complexity bound on append (\u00a74.5). Invari\u00adant 7 is also needed to ensure that the \nparallel implementation of reductions such as sum do not duplicate work (\u00a75.4). However, an implementation \nmay be able to relax these last two invariants in certain cases (\u00a76).  4.3 Replicates again Now let \nus implement replicates using our new array represen\u00adtation. The start is easy, because the result PA \narray must be built with a PA constructor: replicates :: Vector Int -> PA e -> PA e replicates ns arr \n= PA (sum ns) (replicatesPR ns arr) The real work is in replicatesPR. But now we encounter a slight \nproblem: since the representation of PData is indexed by the element type e, we require a type-indexed \nfunction to operate over PData values. That is, we need a type class, with an instance for Int and an \ninstance for (PA e): class PR e where replicatesPR :: Vector Int -> PData e -> PData e ...more methods... \ninstance PR Int where replicatesPR = replicatesI ... instance PR e => PR (PA e) where replicatesPR = \nreplicatesPA ... The PR (Parallel Representation) class is given in Figure 5, and con\u00adveniently collects \nall the necessary primitive operations over arrays. We will see more of them in this section, but replicatesPR \nis one. So, in fact, we lied: the types of replicates and replicatesPR are overloaded thus: replicates \n:: PR e => Vector Int -> PA e -> PA e replicatesPR :: PR e => Vector Int -> PData e -> PData e class \nPR e where emptyPR :: PData e lengthPR :: PData e -> Int  replicatePR :: Int -> e -> PData e replicatesPR \n:: Vector Int -> PData e -> PData e appendPR :: PData e -> PData e -> PData e indexPR :: PData e -> Int \n-> e indexvsPR :: PDatas e -> VSegd -> Vector (Int, Int) -> PData e extractPR :: PData e -> Int -> Int \n-> PData e extractvsPR :: PDatas e -> VSegd -> PData e packPR :: PData e -> Vector Bool -> PData e combinePR:: \nVector Bool -> PData e -> PData e -> PData e lengthdPR :: PDatas e -> Int emptydPR :: PDatas e singletondPR \n:: PData e -> PDatas e appenddPR :: PDatas e -> PDatas e -> PDatas e indexdPR :: PDatas e -> Int -> PData \ne -------Utility functions -------\u00adsumV :: Vector Int -> Int singletonV :: e -> Vector e replicateV :: \nInt -> e -> Vector e replicatesV :: Vector Int -> Vector e -> Vector e Figure 5. Primitive Array Operators \n(In what follows we will often omit the PR => context from types to save space.) Now we are ready to \nimplement the two cases. The case for Int is straightforward: replicatesI :: Vector Int -> PData Int \n-> PData Int replicatesI ns (PInt xs) = PInt (replicatesV ns xs) where replicatesV is the Vector-level \nreplication operation shown in Figure 5. The interesting case is the one for nested ar\u00adrays: instance \nPR e => PR (PA e) where replicatesPR = replicatesPA  replicatesPA :: Vector Int -> PData (PA e) -> PData \n(PA e) replicatesPA lens (PNested segmap pdatas) = PNested (VSegd segmap ssegd) pdatas where segmap = \nreplicatesV lens segmap With our new array representation, we can apply segmented replicate toanarray \nbyusing replicatesV on the segmap .eld. The element data, pdatas, does not need to be copied, and is \nuntouched in the result. Continuing the example from \u00a73, applying replicates to the array from Figure \n3 yields: replicates [0 0 1 1 0 0 1] {Figure 3} = [[A B] [C D E] [H]] ------------------------------------------------(ARR1) \nPA 3 (PNested (VSegd segmap: [0 1 3] (SSegd sources: [0 0 1 1] starts: [1 3 0 4]) (Segd lengths: [2 3 \n2 1] indices: [0 2 5 7])) (PChars 0: [X AB C DE] 1: [F GX X HX XX]) In fact, the above de.nition of replicatesPA \nfunction is not yet complete. Physical segments 0, 1 and 3 are used, but segment 2 is not, which violates \ninvariant 6. We will discuss why this matters in \u00a74.6.  4.4 Plain replicate Vectorisation also uses \na simpler form of replication, which we call replicate (singular). The call (replicate n x) returns an \narray of n elements, each a (virtual) copy of x. This function is introduced when an inner parallel computation \nuses a shared constant or a free variable that is de.ned in an outer context. This is essentially the \nsame reason that the more general replicates function is introduced, though with plain replicate the \nshared value is used uniformly by all inner computations. We will see an example in \u00a76.1. Note that unlike \nreplicates, the result of plain replicate has a greater nesting depth than the source element. The interesting \ncase is for nested arrays: replicatePA :: Int -> PA e -> PData (PA e) replicatePA c (PA n pdata) = replicatesPR \n(singletonV c) $ PNested (singletonVSegd n) (singletondPR pdata) singletonVSegd :: Int -> VSegd singletonVSegd \nlen = VSegd (singletonV 0) (SSegd (singletonV 0) (singletonV 0) (Segd (singletonV len) (singletonV 0))) \nTo perform a replicate we simply add a new segment descriptor on top of the old array. This furnishes \nus with an example array of greater nesting depth: replicate 2 {Figure 3} ------------------------------------------------(ARR2) \nPA 2 (PNested (VSegd segmap: [0 0] (SSegd sources: [0] starts: [0] (Segd lengths: [7] indices: [0]))) \n(PNesteds 0: PNested (VSegd segmap: [0 0 0 1 2 2 3] (SSegd sources: [0 0 1 1] starts: [1 3 0 4]) (Segd \nlengths: [2 3 2 1] indices: [0 2 5 7])) (PChars 0: [X AB CD E] 1: [F GX XH X XX]) Notice that the cost \nof (replicate n x) is O(n), regardless of how much data x contains. With our new representation the complexity \nof replicate is linear in the length of the created segmap, which is also the length of the overall array. \n 4.5 Append Let us consider another important operation: appending two arrays. appendPA :: PA e-> PA \ne-> PA e As mentioned in \u00a74.2 we need invariants 6 and 7 to achieve the Complexity Goal here. Append \nshould be linear in the length of the two argument arrays, regardless of how deeply nested they are. \nThis is impossible with the baseline representation from \u00a73 because we would need to copy all elements \ninto a single data block. With our new representation we do not need to copy array elements. To append \ntwo nested arrays we append the two PDatas and combine the segment descriptor .elds. Although we can \nsimply append the lengths and starts .elds, we need to recompute the indices. We also need to increment \nthe entries in the second segmap and sources .eld to account for the physical segments and data blocks \nde.ned by the .rst array. For this process to have complexity linear in the length of the two argument \narrays, the lengths of their starts, sources, lengths and indices .elds can be no greater than the length \nof their segmap. To put this another way: the number of physical segments can be no greater than the \nnumber of virtual segments. Likewise, the length of the two PDatas can be no greater than the sources \n.elds. These constraints are implied by invariants 6 and 7. The de.nition of appendPR (the version that \nworks on PData) is on the next page.  appendPR :: PData (PA e) -> PData (PA e) -> PData (PA e) appendPR \n(PNested vsegd1 pds1) (PNested vsegd2 pds2) = PNested (appendVSegd (length pds1) vsegd1 vsegd2) (pds1 \n++ pds2) appendVSegd ps1 (VSegd sm1 ssegd1) (VSegd sm2 ssegd2) = VSegd (sm1 ++ map (+ lengthSSegd ssegd1) \nsm2) $ appendSSegd ps1 ssegd1 ssegd2 appendSSegd ps1 (SSegd ss1 us1 segd1) (SSegd ss2 us2 segd2) = SSegd \n(ss1 ++ ss2) (us1 ++ map (+ ps1) us2) $ appendSegd segd1 segd2 appendSegd (Segd ls1 is1) (Segd ls2 is2) \n= let n1 = sum ls1 in Segd (ls1 ++ ls2) (is1 ++ map (+ n1) is2) Here is an example array that we will \nuse in a moment: [[K] [] [L M NO]] -------------------------------------------------(ARR3) PA 3 (PNested \n(VSegd segmap: [0 1 2] (SSegd sources: [0 0 0] starts: [0 1 1]) (Segd lengths: [1 0 4] indices: [0 1 \n1])) (PChars 0: [K L M N O])) Appending the array from Figure 3 with ARR3 above yields: [[AB][AB][AB][CDE]... \n[K][][LMNO] -------------------------------------------------(ARR4) PA 10 (PNested (VSegd segmap:[0001223456] \n(SSegdsources:[0011222] starts:[1304011] (Segd lengths: [2 3 2 1 1 0 4] indices: [0 2 5 7 8 9 9]))) (PChars \n0: [X A BC DE] 1:[FGX XHXXX] 2: [K L MN O])) Thedatablock of ARR3 joins the set of data blocks in the \nresult without any copying.  4.6 Culling Physical Segments As mentioned in \u00a74.5, we need invariants \n6 and 7 to ensure that appendPA has the correct asymptotic complexity. Suppose we wish to append ARR1 \nfrom \u00a74.3 to ARR3 above. Invariant 7 is already sat\u00adis.ed, so this part is .ne. However, as we produced \nARR1 by using a replicates operation with zero valued replication counts, phys\u00adical segment 2 is no longer \nreachable from the segmap, which vio\u00adlates invariant 6. To recover this we use the following operations: \ncullOnSegmap::Vector PsId-> SSegd-> (Vector PsId, SSegd) cullOnSSegd :: SSegd -> PDatas e-> (SSegd, PDatas \ne) The cullOnSegmap function takes the segmap and SSegd for an array. It .lters out the physical segments \nfrom the SSegd that are unreachable from the segmap, returning an updated segmap and SSegd. In the result, \nthe number of physical segments is necessarily bounded by the length of segmap. Likewise, cullOnSSegd \n.lters out data blocks in the PDatas not reachable from the sources .eld of the SSegd. We need this second \noperation because performing just the .rst could leave some data blocks unreachable from the sources \n.eld, thus violating invariant 7. Culling ARR1 yields: [[A B] [C DE] [H]] ------------------------------------------------(ARR5) \nPA 3 (PNested (VSegd segmap: [0 1 2] (SSegd sources: [0 0 1] starts: [1 3 4]) (Segd lengths: [2 3 1] \nindices: [0 2 5])) (PChars 0: [X AB C DE] 1: [F GX X HX XX]) All array operators that .lter out entries \nfrom the segmap need to apply cullOnSegmap and cullOnSSegd to preserve the invariants. For example, the \ninvariant preserving version of replicatesPA is as follows: replicatesPA:: Vector Int -> PData (PA e) \n-> PData (PA e) replicatesPA lens (PNested (VSegd segmap ssegd) pdatas) = PNested (VSegd segmap ssegd \n) pdatas where (segmap , ssegd ) = cullOnSegmap (replicatesV lens segmap) ssegd (ssegd , pdatas ) = cullOnSSegd \nssegd pdatas We will now sketch how cullOnSegmap is implemented, leav\u00ading the full details to the companion \ntechnical report [13]. The oper\u00adation of cullOnSSegd is similar. We start by producing a vector of .ags \nthat record which of the physical segments are reachable from the segmap.For ARR1 this is [TTF T]. The \n.ags are calculated by .rst .lling the target vector with the default value F and then using concurrent \nwrites to set elements referenced by the segmap to T. Then, we use the .ags vector to compute the physical \nseg\u00adment identi.ers that appear in the result: [01 3]. We expand this vector to one that maps between \nthe physical segment identi.ers in the result to the identi.ers in the source: [01 X2].The X in\u00addicates \nan unused element, which the implementation can .ll with any value. Finally, we use this mapping to permute \nthe segmap, sources, starts and lengths .elds of the source array, and then recompute the indices. The \nwork and space complexity of cullOnSegmap is lin\u00adear in the length of the segmap being processed and \nthe num\u00adber of physical segments referenced. Likewise, the complexity of cullOnSSegd is linear in the \nlength of the SSegd and the number of data blocks. This ensures that we do not break the complexity budget \nof operations such as replicates that make use of these functions.  5. Projection, Concatenation and \nReduction The replicates and append operators described in the previous sections highlight the fundamental \nfeatures of our array represen\u00adtation. The work ef.cient implementation of replicates requires that we \nrepresent shared segments without copying element data. As replicates may also drop segments, we must \nhandle scattered segments as well. In addition, the work ef.cient implementation of append requires multiple \ndata blocks with scattered segments as well as the use of the culling operations from \u00a74.6. Culling ensures \nthat the size of the physical representation of an array is bounded by the size of its logical value. \nWe now move on to describe the other operators that we need to support with the new representation when \nvectorising programs. Happily, we can support them with the correct work complexity without any further \nextensions. 5.1 Index and Extract Indexing into a nested array is straightforward. We use the segmap \nto determine the target segment and then extract (slice) it from its data block. We present this operation \nfor expository purposes only: indexing operators in the source program will be vectorised to lifted indexing, \nwhich we discuss in a moment. indexPA (PNested (VSegd segmap (SSegd sources starts (Segd lengths _))) \npdatas) ix = PA len (extractPR pdata start len) where psegid = segmap ! ix source = sources ! psegid \nstart = starts ! psegid len = lengths ! psegid pdata = indexdPR pdatas source  For indexing to be constant \ntime, extractPR must be as well. When the returned value is a Vector Int, or some other vector of scalars, \nthe vector package provides constant time extract by storing a starting index as well as the slice length \nin the returned Vector. To extract a range of subarrays from a nested array we extract their physical \nsegment identi.ers from the segmap and then cull the other .elds to enforce invariants 6 and 7 from \u00a74. \nFor example, extracting the middle two segments from ARR4 yields: [[F G] [F G]] -------------------------------------------------(ARR6) \nPA 2 (PNested (VSegd segmap: [0 0] (SSegd sources: [0] starts: [0] (Segd lengths: [2] indices: [0]))) \n(PInts 0: [F GX X HX XX])) Unfortunately, when indexPA returns a nested array, the called extractPR instance \nmust cull unused physical segments; hence, the overall indexing operation is not constant time. For this \nreason, our new array representation cannot perform all operations that the direct pointer based one \ncould within the same complexity bounds. However, this does not worsen the complexity of vectorised pro\u00adgrams \nrelative to the baseline representation, because only lifted index and extract operators are used in \nvectorised code. We can per\u00adform the lifted operations within the required complexity bounds. Lifted \nindexing itself is a simple wrapper for the indexvsPR function, whose signature is shown in Figure 5. \nindexlPR :: Int -> PData (PA e) -> PData Int -> PData e indexlPR c (PNested vsegd pdatas) (PInt is) = \nindexvsPR pdatas vsegd $ zipV (enumFromN 0 c) is The indexvsPR function takes a set of data blocks, a \nvirtual seg\u00adment descriptor, and an array of pairs of virtual segment identi.ers and element indices \nwithin those segments. As we wish to lookup one element from each segment, we enumerate all the available \nseg\u00adment identi.ers with enumFromN.The indexvsPR function itself implements virtual shared indexing, \nit retrieves several elements from some shared data blocks (pdatas). It uses the index space transform \nexpressed by the vsegd to map the logical view of the array referred to by the segment identi.ers and \nelement indices, to the physical view of the array in terms of the pdatas. The de.ni\u00adtion of indexvsPR \nis similar to indexPR, though we leave the full details for the technical report [13].  5.2 Concatenation \nThe central feature of Blelloch s approach to .attening nested par\u00adallelism is that it does not need \nmultiply lifted versions of source functions in vectorised code. This is achieved by using the concat \nand unconcat operators when vectorising higher order functions such as mapP and zipWithP. Every source-level \napplication of such a function uses a concat/unconcat pair in the vectorised ver\u00adsion. An example of \nthis is shown in retrieve_v from \u00a72. With the baseline array representation from Figure 2, both concat \nand unconcat are constant time operations. To concate\u00adnate an array we simply remove the segment descriptor, \nand to unconcatenate we reattach it. This is possible with the baseline representation, because the form \nof the segment descriptor im\u00adplies that the physical segments lie contiguously in a single, .at data \nblock. The description of the segments consists fundamentally of the lengths .eld, with the indices being \ncomputed directly from it. There is no scattering information such as the starts and sources .elds of \nour SSegd. As we have seen, the limitation of the baseline representation is that it cannot represent \nindex space transformations on nested arrays except by copying element data. In our new representation, \nwe encode such index space transforms in the segment descriptor, which avoids this copying. The price \nwe pay is that the physical segments in a nested array are no longer guaranteed to be contigu\u00adous, so \nwe cannot simply discard the segment descriptor to con\u00adcatenate them. Instead, the concat function must \nnow copy the segment data through the index space transform de.ned by the seg\u00adment descriptor, to produce \na fresh contiguous array. This is essen\u00adtially a gather operation. The main job is done by extractvsPR \nfrom Figure 5, with concat itself being a wrapper for it: concat :: PA (PA e) -> PA e concat (PA _ (PNested \nvsegd pdatas)) = let pdata = extractvsPR pdatas vsegd in PA (lengthPR pdata) pdata The extractvsPR function \ntakes some data blocks, a seg\u00adment descriptor that describes the logical array formed from those blocks, \nand copies out the segment data into a fresh contiguous ar\u00adray. Importantly, although both extractvsPR \nand concat are now linear in the length of the result, this does not worsen the complex\u00adity of the vectorised \nprogram compared with the baseline represen\u00adtation. The reason is that concat/unconcat trick is only \nneeded when vectorising higher order functions such as mapP.In terms of the unvectorised source program, \nmapP is at least linear in the length of its argument array, because it produces a result of the same \nlength. The vectorised version of mapP is implemented by concate\u00adnating the argument array, applying \nthe (lifted) worker function, and then unconcatenating the result. The concat and unconcat functions \ncan then be linear in the length of this result, because the unvectorised version of mapP has this complexity \nanyway. Note that the linear complexity of concat is independent of the depth of nesting of the source \narray. To concatenate an array of type (PA (PA (PA (PA Int)))) we only need to merge the two outer-most \nsegment descriptors. The third level segment descrip\u00adtors, and underlying Int data blocks are not touched. \nThere is an example of this in the accompanying technical report [13].  5.3 Demotion, Promotion and \nUnconcatenation The unconcat function is de.ned in terms of generally useful de\u00admotion and promotion \noperators that convert between the different segment descriptor types. We will discuss these operators \n.rst be\u00adfore continuing onto unconcat. The operators are as follows: demoteVSegd :: VSegd -> SSegd demoteSSegd \n:: SSegd -> Segd promoteSegd :: Segd -> SSegd promoteSSegd :: SSegd -> VSegd Abstractly, demoting a VSegd \nto a SSegd or a SSegd to a Segd discards information about the extended structure of the array, such \nas how segments are shared or scattered through the store. Going the other way, promoting a Segd to a \nSSegd or a SSegd to a VSegd adds redundant information. In our concrete implementation, many array functions \n(including unconcat) are de.ned in terms of these operators. The fact that these functions are de.ned \nthis way is also used when optimising for absolute performance, which we will discuss in \u00a76. 5.3.1 Demotion \nDemoting a segment descriptor eliminates .elds from its represen\u00adtation. Consider the following example: \nvirtual segs: [ [B CD] [G] [] [B C D][E F] [A] ] physical segs: [ [A] [G] [B C D] [E F] [] ] ------------------------------------------------(ARR7) \nPA 6 (PNested (VSegd segmap: [2 1 4 2 3 0] (SSegd sources: [1 0 1 0 0] starts: [0 2 1 0 0] (Segd lengths: \n[1 1 3 2 0] indices: [0 1 2 4 6]))) (PChars 0:[E F G] 1: [AB C D]))  Here we have shown the virtual \nsegments as described by the VSegd, as well as the physical segments described by the SSegd. Note that \nthe virtual segments need not appear in the same order as the physical segments are de.ned, which allows \nus to implement permutation operations on nested arrays by permuting the segmap. Demoting the VSegd to \na SSegd pushes the information about sharing encoded by the segmap into the other .elds of the segment \ndescriptor. It also forces the entries in the SSegd to appear in the same order as the logical array \nthey de.ne: [[BCD] [G] [] [BCD][EF] [A] ] (SSegd sources: [1 0 0 1 0 1] starts: [1 2 0 1 0 0] (Segd lengths: \n[3 1 0 3 2 1] indices: [0 3 4 4 7 9])) (PChars 0: [E FG] 1: [A BC D]) To demote the array we have computed \nnew starts, sources and lengths .elds by permuting the originals using the segmap. In practice, when \nwe demote a VSegd, we must be mindful of the potential for index space over.ow. By this we mean that \nif a nested array consists of many virtual copies of a large sub-array, then the total number of elements \nin the virtual array may be larger than the address space of the machine, even though all the physical \ndata .ts within it. In this case the elements of the indices .eld may no longer .t in a machine word. \nWe will return to this point in \u00a75.4.1. Avoiding index space over.ow is the main reason we use an explicit \nsegmap, instead of representing all arrays with the above demoted form (without a segmap). Continuing \non, we demote a SSegd to a Segd by simply discard\u00ading the outer SSegd wrapper, along with the sources \nand starts .elds. To represent the same logical array, we must then gather the segment data into a fresh \ndata block, similarly to the extractvsPR function described in \u00a75.1. For our example this produces: [[BCD] \n[G] [] [BCD][EF] [A] ] (Segd lengths: [3 1 0 3 2 1] indices: [0 3 4 4 7 9]) (PChars 0: [B CD GB CD E \nFA]) As with the previous demotion, our nested array still has the same logical value as the original. \nHowever, by giving up the sources and starts .elds we have lost information about how the segments were \noriginally scattered through the store. This forces us to copy them into a fresh data block to represent \nthe original logical array, leaving us with the old array representation from Figure 2.  5.3.2 Promotion \nPromoting an array .lls in missing segment descriptor .elds with redundant information. To promote a \nSegd to a SSegd,we reuse the existing indices .eld for starts and .ll the sources with all zeros. This \nindicates that all physical segments lie contiguously in a single .at array. To promote the SSegd to \na VSegd we then enumerate the physical segments in the segmap. Performing both promotions to the demoted \narray from the previous section yields the following: [[B C D] [G] [] [B CD] [E F] [A] ] ------------------------------------------------(ARR8) \nPA 5 (PNested (VSegd segmap: [0 1 2 3 4 5] (SSegd sources: [0 0 0 0 0 0] starts: [0 3 4 4 7 9] (Segd \nlengths: [3 1 0 3 2 1] indices: [0 3 4 4 7 9]))) (PChars 0: [B CD GB CD E FA])) Note that promoting a \nsegment descriptor does not change the logical structure of the array, it just .lls in redundant .elds \nin the representation. In our concrete implementation the initialisation of the segmap and sources .elds \nwith these boring values can often be avoided (\u00a76). 5.3.3 Unconcatenation To unconcatenate an array, \nwe demote the source segment descrip\u00adtor down to a plain Segd and then re-promote it back to a VSegd, \nbefore attaching it to the second array: unconcatPR :: PA (PA a) -> PA b -> PA (PA b) unconcatPR (PA \nn (PNested vsegd _)) (PA _ pdata) = let segd = demoteSSegd $ demoteVSegd vsegd vsegd = promoteSSegd $ \npromoteSegd segd in PA n (PNested vsegd (singletondPR pdata)) We need the demotion-promotion process \nbecause the sharing and scattering information in the VSegd is only relevant to the .rst array, not the \nsecond array (of type (PA b)) that we attach it to. Finally, we can normalise the physical structure \nof an array by concatenating it down to atomic elements and then unconcatenating to re-apply the nesting \nstructure. This eliminates all unused array elements from the data blocks, which improves locality of \nreference for subsequent operations, and is useful when writing arrays to the .le system. Here is the \nversion for triply nested arrays: normalise3 :: PA (PA (PA e)) -> PA (PA (PA e)) normalise3 arr2 = let \narr1 = concat arr2 arr0 = concat arr1 in unconcat arr2 (unconcat arr1 arr0) Creating versions of normalise \nfor other degrees of nesting is straightforward. Normalising the doubly nested ARR7 from \u00a75.3.1 yields \nexactly ARR8 from \u00a75.3.2. Note that if we were to elide the VSegd and SSegd layers, a normalised arrays \nhave the same form as the baseline representation from \u00a73.  5.4 Reduction and Dynamic Hoisting Consider \nthe following function retsum, which indexes several shared arrays, and adds the retrieved value to the \nsum of the array it came from. This has a similar structure to retrieve from \u00a72. retsum :: [:[:Int:]:] \n-> [:[:Int:]:] -> [:[:Int:]:] retsum xss iss = zipWithP mapP (mapP (\\xs i. indexP xs i + sumP xs) xss) \niss Here is retsum applied to some example arrays: retsum [[1 2] [4 5 6] [8]] (xss) [[1 0 1] [1 2] [0]] \n(iss) ==> [[5 4 5] [20 21] [16]] The subexpression sum xs duplicates work for every application of the \ninner function abstraction, because it sums the entire xs array once for each of the integer elements \nin the result. The result of vectorisation, inlining and simplifying retsum is shown below the accompanying \ntechnical report [13] includes the full derivation. retsum_v :: PA (PA Int) -> PA (PA Int) -> PA (PA \nInt) retsum_v xss iss = let ns = lengths iss n = sum ns yss = replicates ns xss in unconcat iss $ add_l \nn (index_l n yss (concat iss)) (sum_l n yss ) In retsum_v, the fact that the original sum expression \ndupli\u00adcates work is revealed in the fact that the lifted version (sum_l)is being applied to a replicated \narray. At runtime, the segments of the .rst array are replicated according to the lengths of the segments \nin the second. The intermediate result (replicates ns xss) is on the next page.  [[1 2] [1 2][1 2] [4 \n5 6][4 5 6] [8]] -----------------------------------------------(ARR9) PA 6 (PNested (VSegd segmap: [0 \n0 0 1 1 2] (SSegd sources: [0 0 0] starts: [0 2 5] (Segd lengths: [2 3 1] indices: [0 2 5]))) (PInts \n0: [1 24 5 68]) Our segmap directly encodes which of the physical segments are being shared. Instead \nof repeatedly summing segments we know to be identical, we can instead sum the physical segments de.ned \nby the SSegd, and replicate the results according to the segmap. By doing this we actually improve the \nasymptotic com\u00adplexity of the original program, by avoiding repeated computation that it would otherwise \nperform. Note that this process depends on Invariant 6 from \u00a74, as we do not wish to sum unreachable \nphysical segments that are not part of the logical array. Avoiding repeated computation in this way achieves \nthe same result as the hoisting or full laziness program transformation, but in a dynamic way. In contrast, \nperforming this transform statically at compile-time would yield the following: retsum xss iss = zipWithP \nmapP (mapP (\\xs. let x = sumP xs in \\i. indexP xs i + x) xss) iss However, the GHC simpli.er will not \nin-fact perform the above transform, as it does not generally improve performance [16]. Fi\u00adnally, although \ndynamic hoisting may seem like an opportunistic improvement, perhaps not worth the trouble, failing to \nperform it has other rami.cations, which we discuss in the next section. 5.4.1 Fused Hylomorphisms and \nIndex Space Over.ow A subtle point about the retsum example is that if an implemen\u00adtation does not perform \ndynamic hoisting, it could risk over.ow\u00ading machine words. This is a general problem with fused hylomor\u00adphisms, \nwith a hylomorphism being a computation that .rst builds a structure (like with replicates) before reducing \nit (like with sum_l). Although it may be possible to fuse these two operations together so the intermediate \nstructure is never actually created, it is problematic when the index space of that structure is larger \nthan the address space of the machine. For example, suppose the xss array from the previous section contains \n10 elements and iss contains 500 million. Although this amount of data is easily stored on current hardware, \nthe total num\u00adber of virtual elements produced by replicates would be 5 x 109. This number is not representable \nin a 32-bit word. This problem is acute because the function that de.nes the intermediate structure (replicates) \nis introduced by vectorisation and does not appear in the source program. Simply telling the user you \ncan t do that would be unreasonable. Managing this problem is the main reason that we include an explicit \nsegmap in our array representation. Without the segmap, we would instead record each virtual segment \nseparately, like with the .rst demoted array of \u00a75.3.1. However, in cases of index-space over.ow, elements \nof the indices .eld would become too large to be stored. The indices .eld itself is needed when partitioning \nthe work in the implementation of sum_l. We also need the total size of the array, which would again \nbe too large. Requiring 64-bit array indices and eliminating the segmap is an alternate solution, but \nit is not clear whether this would be bet\u00adter overall. On 32-bit machines, memory traf.c to the indices \n.eld would double because of the larger word size. On all ma\u00adchines, operations such as replicates would \nneed to process both the sources and starts .eld instead of touching the singular segmap. On the other \nhand, indexing operations would not need to dereference the segmap, or maintain invariant 6, but as as \nwe will see in \u00a76 this can often be avoided anyway. The code to maintain this invariant is localised, \nand very similar to that needed for invari\u00adant 7, so it would not be a signi.cant reduction in implementation \ncomplexity. For now we choose to keep the segmap and leave the quantitative comparison to future work. \n  5.5 Flattening and Space Usage In contrast to the problem with replication outlined in \u00a72, .attening \nnested parallelism can increase the asymptotic space complexity in a way that this paper does not address \n[14, 19]. For example, suppose we vectorise the following function that takes an array of n points and \ncomputes the maximum distance between any pair. The full derivation is in the companion technical report \n[13]. furthest :: PA (Float, Float) -> Float furthest ps = maxP (mapP (\\p. maxP (mapP (dist p) ps)) ps) \n The .attened version is a hylomorphism that .rst computes O(n2) distances before reducing them to determine \nthe maximum. Whereas the un.attened version would run in O(n) space, the .attened ver\u00adsion needs O(n2) \nspace to hold the intermediate vector of distances. Note that vectorisation does not increase the asymptotic \nwork com\u00adplexity, because these distances must be computed anyway.  5.6 Pack and Combine The pack and \ncombine functions from Figure 5 are used in the par\u00adallel implementation of if-then-else.The pack function \ntakes an array of elements, an array of .ags of the same length, and returns only those elements that \nhave their .ag set. This func\u00adtion is used to split the parallel context of if-then-else into the elements \nassociated with each branch. It can be implemented in terms of replicates, using a replication count \nof 1 for True .ags and 0 for False .ags. We mention it separately because pack is the common name for \nthis operation in the literature. The combine function takes an array of .ags, two arrays of ele\u00adments, \nand intersperses the elements according to the .ags. For ex\u00adample combine [T FF T] [12] [3 4]= [13 42].This \nfunction is used to merge the results of each branch once they have been computed. On a high level, the \nimplementation of combine is similar to append because the result contains elements from both source \narrays, though we leave the implementation to [13]. To achieve our Complexity Goal, both pack and combine \nmust be linear in the length of the flags array. This is because entering a branch in the source program \nis a constant time operation. In vectorised code, many branches are entered in one parallel step, so \nthe functions that implement this operation must be linear in the number of elements being processed. \nAchieving this goal with the baseline array representation is not possible, because packing and combining \nnested arrays requires that we copy element data. In contrast, with our new representation we can simply \npack and combine the segment descriptors, leaving the underlying element data untouched. In [1], Blelloch \nsuggested that it would be more ef.cient to work on sparse segments, which we are now able to do. As \nmentioned in \u00a71 vectorisation can only preserve the com\u00adplexity of the source program up to containment. \nThis problem stems from the fact that .attening if-then-else causes the computations that take each branch \nto be executed one after an\u00adother, instead of concurrently. In [18] Riely and Prins give an example recursive \nfunction that calls itself in both branches of an if-then-else, and where vectorisation worsens its asymp\u00adtotic \ncomplexity independent of considerations of the array rep\u00adresentation. Luckily, the containment problem \nis rarely met in practice. Riely and Prins prove that provided one branch in each if-then-else executes \nwith a constant number of parallel steps, the containment problem is avoided. This constraint is met \nby the base case of most recursive functions. However, their language is .rst order, so their proof does \nnot automatically apply to ours.   6. Pragmatics Although our new array representation allows the index \nspace transforms introduced by the vectoriser to have the correct asymp\u00adtotic complexity, there are several \ncases where a direct imple\u00admentation would perform poorly in absolute terms. For example, implementing \npromoteSSegd from \u00a75.3.2 by physically .lling the segmap with [01 2...] leaves something to be desired. \nHowever, in many cases the construction of these .elds can be sidestepped using rewrite rules. For example, \nin our concrete im\u00adplementation we have the following functions: sum_vs :: VSegd -> PDatas Int -> PData \nInt sum_s :: Segd -> PData Int -> PData Int Both of these can be used to implement lifted sum (sum_l)by \nusing a simple wrapper. The difference is that while sum_vs accepts a full VSegd to describe the segmentation \nof the array, sum_s only accepts a plain Segd. The implementation of the latter is simpler, as it does \nnot need to worry about the segmap, starts and sources .elds that de.ne the sharing and scattering of \nsegments. During code transformation, we apply the following rewrite rule: RULE \"sum_vs/promote\" forall \nsegd arr. sum_vs (promoteSSegd (promoteSegd segd)) (singletondPR arr) = sum_s segd arr The rule says \nthat to sum the segments of a nested array de.ned by a promoted Segd, we can just use the Segd directly. \nRules like this one are frequently applicable because the de.nition of key operations such as unconcat \nand extractvsPR explicitly use promoteSegd and so on to construct their results. Note that the ability \nto apply rules such as this depends critically on the split between the VSegd, SSegd and Segd types, \nand the fact that indices .eld is in Segd rather than SSegd. Abstractly, the fact that an array is representable \nwith just a Segd tells us that all the segments lie contiguously in the store. The fact that it is representable \nwith just a SSegd tells us that the number of physical segments matches the number of logical segments, \nthough several entries in the SSegd may still point to the same element data. Another technique we use \nis to store a lazy, pre-concatenated version of the array in the array structure itself. In our concrete \nim\u00adplementation, the PNested structure contains two extra .elds hold\u00ading a plain Segd and the PData corresponding \nto the concatenated version of the overall array. Every function that constructs an array is responsible \nfor initialising these .elds, either with pre-existing concatenated data, such as produced by extractvsPR, \nor a sus\u00adpended computation that will concatenate when demanded. When a consumer, such as mapP, requires \na concatenated version of the array, it can use these .elds instead of explicitly concatenating the data \nitself. With this method array consumers avoid repeatedly con\u00adcatenating (and thus copying) arrays that \nthe producers know are already concatenated. We use a similar method to avoid some applications of the \ncullOnSegmap function discussed in \u00a74.6. The key point here is that while reduction operations like sum_l \nneed invariant 6 to avoid duplicating work, indexing operations are oblivious to unreachable physical \nsegments. In our implementation, we suspend calls to cullOnSegmap with lazy evaluation, and also keep \nan unculled version of the SSegd in the array representation. If, say, a nested array is packed and then \nimmediately indexed, then the indexing operation uses the unculled SSegd, avoiding the need to call cullOnSegmap \nat all. 6.1 Rewrite Rules and Replication A reader may be wondering why we cannot also use a rewrite \nrule to eliminate calls to replication operators in the vectorised program, instead of introducing a \nnew array representation. Suppose we vectorise the following function that gathers multiple character \nvalues from a shared array called table. gather :: [:Char:] -> [:Int:] -> [:Char:] gather table indices \n= mapP (\\ix -> table !: ix) indices The vectorised version is as follows: gather_v :: PA Char -> PA \nInt -> PA Char gather_v table indices = index_l len (replicate len table) indices where len = length \nindices As per \u00a72, index_l is lifted indexing. Note that with the old ar\u00adray representation, this function \nwould have the wrong asymptotic complexity due to the use of replicate. However, suppose we had a second \nversion of indexing (index_s) that could retrieve el\u00adements from a single shared array. This operation \nis also known as backwards permutation. index_l :: Int -> PA (PA a) -> PA Int -> PA a index_s::Int-> \nPAa ->PAInt->PAa Given index_s, a seemingly obvious way to optimise gather_v is to apply the following \nrewrite rule: RULE \"index_l/index_s\" forall c xs ys. index_l c (replicate c xs) ys = index_s c xs ys \nThe problem is that this rule improves the asymptotic complexity of the program, which turns out to be \na bad thing engineering wise. The left of the rule uses work and space O(length xs . length ys) while \nthe right uses O(length ys). These are different because indexing is a projection, which does not inspect \nall of its input data. The trouble is that for the rule to .re, the producer (replicate) and consumer \n(index_l) of the replicated array must come to\u00adgether during code transformation. If the program is written \nin a way that prevents this from happening, then replicate will not be eliminated. For example, suppose \nwe parameterised gather over a function to apply to each index value: gatherFun ::([:Char:] -> Int -> \nChar) -> [:Char:] -> [:Int:] -> [:Char:] gatherFun fun table indices = mapP (fun table) indices Vectorising \nthis function yields the following: gatherFun_v :: PA (PA Char :-> Int :-> Char) -> PA Char -> PA Int \n-> PA Char gatherFun_v (AClo fv fl envs) table indices = fl c envs (replicate c table) $:^ indices where \nc = length indices When we vectorize higher order functions, the parameter func\u00adtion is represented as \nan array closure. The array closure construc\u00adtor AClo bundles up the closure-converted version of the \nfunction (fv), the lifted version (fl) and the environment that was captured in its closure (envs). The \nlifted application operator ($:^) then applies the closure to its .nal argument indices. See [11, 12] \nfor a more detailed explanation. The main point here is that the param\u00adeter function fl is unknown to \nthe vectoriser. With just the code above, it is impossible to eliminate the replicate operation, be\u00adcause \nwe do not know what fl will turn out to be. A tempting hack-around is to force every function in the \npro\u00adgram to be inlined, and hope that follow on code transformation discovers the true identity of fl. \nWe used this approach in our pre\u00advious implementation of DPH, and it turns out to be a slippery slope \nto suffering. Small changes in the structure of the source program, or behaviour of the various transforms, \ncan result in a previously well performing program becoming unrunnable due to the changed asymptotic \ncomplexity. This approach also does not .x recursive programs where the producer and consumer are the \nsame function, as the the same function cannot be inlined into itself inde.nitely. An example of such \na program is given in \u00a77.2. Our solution is to instead provide a new array representation, that guarantees \nthat even with all follow-on optimisations disabled, the program will still run with the correct asymptotic \ncomplexity.   7. Benchmarks In this section we present several programs where the baseline array representation \nworsened the asymptotic complexity of the vectorised program. All benchmarks were taken on an Intel i7 \nQuadCore / 8GB desktop machine. We have opted to present data for the program running in single threaded \nmode only. We have not .nished adapting our parallel stream fusion framework to the new array representation, \nso parallel speedup is currently dominated by the creation of intermediate arrays such as the boring \n.elds described in \u00a75.3.2 and \u00a76. However, all of the underling primitives we use operate on bulk arrays \nand are amenable to parallelisation. 7.1 Sparse Matrix-Vector Multiplication This program multiples a \nsparse matrix by a dense vector and is discussed in [11]. The matrix is represented as an array of rows, \nwhere each row is an pair of a column index and the Double value in that column. smvm :: [:[:(Int, Double):]:] \n-> [:Double:] -> [:Double:] smvm matrix vector = let term (ix, coeff) = coeff * (vector ! ix) sumRow \nrow = sumP (mapP term row) in mapP sumRow matrix As vector is free in the de.nition of term, with the \nold array representation it would be copied once for every non-zero ele\u00adment of the matrix. With the \nnew array representation the vec\u00adtor is not copied and it runs with the same asymptotic complex\u00adity as \nan unvectorised reference implementation written with the Data.Vector package. The Data.Vector version \nis currently faster than with our new representation because stream fusion [7] does a better job at eliminating \nintermediate values. 7.2 Tree Lookup The following microbenchmark exposes the replicate problem in sharp \nrelief. It performs a divide-and-conquer of an indices array, while referring to a top level table. In \nthe base case, a single index is used to access the top-level table, and the table is rebuilt during \nthe return calls. treeLookup :: [:Int:] -> [:Int:] -> [:Int:] treeLookup table indices | lengthP indices \n== 1 = [:table !: (indices !: 0):] | otherwise = let half = lengthP indices div 2 s1 = sliceP 0 half \nindices s2 = sliceP half half indices in concatP (mapP (treeLookup table) [: s1, s2 :]) As table is partially \napplied to treeLookup, with the baseline representation the entire table is copied once for every element \nof indices. In the vectorised version the call to replicate cannot be eliminated with the rewrite rules \ndiscussed in \u00a76.1, because the producer and consumer of the replicated array are in different recursive \ncalls. With our new array representation, the sharing is managed by our segmap and the elements of table \nare not copied.  7.3 Barnes-Hut The Barnes-Hut algorithm performs a two dimensional gravitation simulation \nof many massive bodies. At each time step, the algo\u00adrithm builds a quad-tree to partition the space the \nbodies lie in, and computes the centroid of all bodies in each branch. The tree is then used to compute \nthe force between each body and all the others, approximating the force between distant bodies by using \nthe cen\u00adtroids. Whereas a naive algorithm would use work O(n2) in the number of bodies, the Barnes-Hut \napproximation is O(n.log n). With the baseline array representation, the copying replication problem \nappears at the very top level. Once we have built the quad\u00adtree, we use it to compute the force on each \nbody. Sparse Matrix-Vector Multiplication (1% non-zero elements) Non-Zero Elements Tree Lookup  Vector \nLength Barnes-Hut, 1 step, 1 thread  Bodies Figure 6. Benchmark Runtime Performance This is done by \nthe following function: calcAccels :: Double -> Box -> [:MassPoint:] -> [:Accel:] calcAccels epsilon \nboundingBox points = mapP (\\m -> calcAccel epsilon m tree) points where tree = buildTree boundingBox \npoints As tree is free in the closure passed to mapP, it is copied once for every body. As before, with \nthe new array representation the tree is not copied and the program runs with the same asymptotic complexity \nas an unvectorised reference implementation written with the Data.Vector package. When divide and conquer \nalgorithms such as Barnes-Hut are vectorised, the resulting code increases the nesting level of the source \narray during the division phase (on the way down) and concatenates the result on the way back up. We \nrefer to such algorithms as dynamically nested for this reason. As discussed in \u00a75.2, concat normalises \nthe array representation, so the program effectively switches between the old baseline representation \nand our new scattered representation as it runs.   8. Related Work Approaches to the implementation \nof irregular parallelism roughly fall into two categories: thread-based implementations, like Man\u00adticore \n[8] or Ct [9], and those based on .attening. Both have their advantages and drawbacks. With the former \napproach, scheduling, synchronisation, and granularity control are a concern, as well as a more restricted \nset of target architectures, though they do not suf\u00adfer from the complexity problem described in this \npaper. However, the problem we describe is a fundamental issue for all .attening based approaches, and \nhas been identi.ed and discussed in several publications. The original .rst-order .attening transform \nand array represen\u00adtation shown in Figure 2 was introduced by Blelloch and Sabot in in [1]. In this work \nthe replicate function is called distribute when applied to scalars and distribute-segment when applied \nto arrays. As a possible extension to the handling of conditionals they suggest operating on sparse segments \ninstead of .rst elimi\u00adnating gaps between them with the pack operation. This idea is not elaborated further. \nThe single example program they present (Quicksort) only uses distribute and pack on arrays of scalars, \nand thus does not suffer problems with asymptotic complexity. In [2] Blelloch proves that a subset of \nprograms written with the scan-vector instruction set can be vectorised while preserving their asymptotic \nwork and step complexity. Such programs must be both contained, and not use indirect memory access, which \nis equiva\u00adlent to disallowing functions to have free variables. Appendix C of the NESL manual [3] gives \nthe work complexity of vectorised pro\u00adgrams, and states that the contents of free variables is copied \nacross each iteration of the apply-to-each (map) construct. Finally, in [4] the authors present a provably \ntime and space ef.cient version of NESL, but the operational semantics is based around .ne grained threads \ninstead of SIMD style vectors. In [15], Palmer et al. address the issue by disallowing partial applications \nand removing some of the problematic cases using rewrite rules. For Haskell, ruling out partial applications \nto appear anywhere in a parallel context would be neither desirable nor stat\u00adically enforceable. The \nrewrite rules used do not .re if the offend\u00ading index space transform is applied indirectly as part of \nanother function. This is a general drawback of using rewrite rules, which can be acceptable if the rewriting \nonly leads to a constant improve\u00adment, but not in our case, where the failure to identify problematic \nexpressions results in asymptotically worse performance. In [18], Riely and Prins solve this problem \nby using vectors of references, but at the time the article was written, there was no im\u00adplementation, \nso they could not provide any experimental data as to the absolute performance. To the best of our knowledge, \nthey have not published any further results on this approach. The sug\u00adgested representation is similar \nto one of the states our representa\u00adtion can take on, for example, as a result of creating a nested vec\u00adtor \nby collecting a number of different .at arrays in a nested one. However, the use of purely pointer based \nrepresentations can lead to poor locality and complicates distribution and load balancing. It also increases \ngarbage collection overhead, as every subarray must be traversed individually. In contrast, our approach \naims at keep\u00ading the data representation as .at as possible, and only resorts to the partially .attened \nrepresentation whenever the completely .at representation would lead to worse work complexity. Acknowledgements \nThis work was supported in part by the Aus\u00adtralian Research Council under grant number LP0989507.  References \n[1] G. Blelloch and G. W. Sabot. Compiling collection-oriented languages onto massively parallel computers. \nJournal of Parallel and Distributed Computing, 8:119 134, 1990. [2] G. E. Blelloch. Vector models for \ndata-parallel computing. MIT Press, 1990. [3] G. E. Blelloch. NESL: A nested data-parallel language (version \n3.1). Technical report, Carnegie Mellon University, 1995. [4] G. E. Blelloch and J. Greiner. A provable \ntime and space ef.cient implementation of NESL. In ICFP 1996: International Conference on Functional \nProgramming, pages 213 225, 1996. [5] M. M. T. Chakravarty, G. Keller, S. Peyton Jones, and S. Marlow. \nAs\u00adsociated types with class. In POPL 2005: Principles of Programming Languages, pages 1 13. ACM Press, \n2005. [6] M. M. T. Chakravarty, R. Leshchinskiy, S. Peyton Jones, G. Keller, and S. Marlow. Data Parallel \nHaskell: a status report. In DAMP 2007: Declarative Aspects of Multicore Programming. ACM Press, 2007. \n[7] D. Coutts, R. Leshchinskiy, and D. Stewart. Stream fusion: from lists to streams to nothing at all. \nIn ICFP 2007: International Conference on Functional Programming, 2007. [8] M. Fluet, M. Rainey, and \nJ. Reppy. A scheduling framework for general-purpose parallel languages. In ICFP 2008: International \nConference on Functional Programming, pages 241 252. ACM, 2008. [9] A. Ghuloum, T. Smith, G. Wu, X. Zhou, \nJ. Fang, P. Guo, B. So, M. Ra\u00adjagopalan, Y. Chen, and B. Chen. Future-proof data parallel algorithms \nand software on Intel multi-core architecture. Intel Technology Jour\u00adnal, November 2007. [10] J. Hill, \nK. M. Clarke, and R. Bornat. Vectorising a non-strict data\u00adparallel functional language, 1994. [11] R. \nLeshchincskiy. Higher-Order Nested Data Parallelism. PhD thesis, Technische Universit\u00a8at Berlin, 2006. \n[12] R. Leshchinskiy, M. M. T. Chakravarty, and G. Keller. Higher order .attening. In ICCS 2006: International \nConference on Computational Science, volume 3992, pages 920 928. Springer, 2006. [13] B. Lippmeier, M. \nM. T. Chakravarty, G. Keller, R. Leshchinskiy, and S. P. Jones. Work ef.cient higher-order vectorisation \n(unabridged). Technical Report UNSW-CSE-TR-201208, University of New South Wales, 2012. [14] D. W. Palmer, \nJ. F. Prins, S. Chatterjee, and R. E. Faith. Piecewise exe\u00adcution of nested data-parallel programs. In \nLanguages and Compilers for Parallel Computing, volume 1033 of Lecture Notes in Computer Science, pages \n346 361. Springer-Verlag, 1995. [15] D. W. Palmer, J. F. Prins, and S. Westfold. Work-ef.cient nested \ndata-parallelism. In Proc. of the 5th Symposium on the Frontiers of Massively Parallel Processing, pages \n186 193. IEEE, 1995. [16] S. Peyton Jones, W. Partain, and A. Santos. Let-.oating: Moving bind\u00adings to \ngive faster programs. In ICFP 1996: International Conference on Functional Programming, pages 1 12, 1996. \n[17] S. Peyton Jones, R. Leshchinskiy, G. Keller, and M. M. T. Chakravarty. Harnessing the multicores: \nNested data parallelism in Haskell. In FSTTCS 2008: Foundations of Software Technology and Theoretical \nComputer Science, LIPIcs, pages 383 414. Schloss Dagstuhl, 2008. [18] J. Riely and J. Prins. Flattening \nis an improvement. In Proc. of the 7th International Symposium on Static Analysis, pages 360 376, 2000. \n[19] D. Spoonhower, G. E. Blelloch, R. Harper, and P. B. Gibbons. Space pro.ling for parallel functional \nprograms. In ICFP 2008: Interna\u00adtional Conference on Functional Programming, 2008.  \n\t\t\t", "proc_id": "2364527", "abstract": "<p>Existing approaches to <i>higher-order vectorisation</i>, also known as <i>flattening nested data parallelism</i>, do not preserve the asymptotic work complexity of the source program. Straightforward examples, such as sparse matrix-vector multiplication, can suffer a severe blow-up in both time and space, which limits the practicality of this method. We discuss why this problem arises, identify the mis-handling of index space transforms as the root cause, and present a solution using a refined representation of nested arrays. We have implemented this solution in Data Parallel Haskell (DPH) and present benchmarks showing that realistic programs, which used to suffer the blow-up, now have the correct asymptotic work complexity. In some cases, the asymptotic complexity of the vectorised program is even better than the original.</p>", "authors": [{"name": "Ben Lippmeier", "author_profile_id": "81488641994", "affiliation": "University of New South Wales, Sydney, Australia", "person_id": "P3804360", "email_address": "benl@cse.unsw.edu.au", "orcid_id": ""}, {"name": "Manuel M.T. Chakravarty", "author_profile_id": "81548019082", "affiliation": "University of New South Wales, Sydney, Australia", "person_id": "P3804361", "email_address": "chak@cse.unsw.edu.au", "orcid_id": ""}, {"name": "Gabriele Keller", "author_profile_id": "81548019083", "affiliation": "University of New South Wales, Sydney, Australia", "person_id": "P3804362", "email_address": "keller@cse.unsw.edu.au", "orcid_id": ""}, {"name": "Roman Leshchinskiy", "author_profile_id": "81545396056", "affiliation": "University of New South Wales, Sydney, Australia", "person_id": "P3804363", "email_address": "rl@cse.unsw.edu.au", "orcid_id": ""}, {"name": "Simon Peyton Jones", "author_profile_id": "81100271851", "affiliation": "Microsoft Research Ltd, Cambridge, United Kingdom", "person_id": "P3804364", "email_address": "simonpj@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364564", "year": "2012", "article_id": "2364564", "conference": "ICFP", "title": "Work efficient higher-order vectorisation", "url": "http://dl.acm.org/citation.cfm?id=2364564"}