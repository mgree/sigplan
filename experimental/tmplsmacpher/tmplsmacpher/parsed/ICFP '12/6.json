{"article_publication_date": "09-09-2012", "fulltext": "\n Shake Before Building Replacing Make with Haskell Neil Mitchell ndmitchell@gmail.com Abstract Most \ncomplex software projects are compiled using a build tool (e.g. make), which runs commands in an order \nsatisfying user\u00adde.ned dependencies. Unfortunately, most build tools require all dependencies to be speci.ed \nbefore the build starts. This restriction makes many dependency patterns dif.cult to express, especially \nthose involving .les generated at build time. We show how to eliminate this restriction, allowing additional \ndependencies to be speci.ed while building. We have implemented our ideas in the Haskell library Shake, \nand have used Shake to write a complex build system which compiles millions of lines of code. Categories \nand Subject Descriptors D.3 [Software]: Program\u00adming Languages General Terms Languages Keywords build-system, \ncompilation, Haskell 1. Introduction A build tool, such as make (Feldman 1978), takes a set of build \nrules, plus some input .les, and produces some output .les. Using make, a build rule can be written as: \nresult.tar : .le1 .le2 tar -cf result.tar .le1 .le2 This rule says that the .le result.tar depends on \nthe inputs .le1 and .le2 (.rst line), and provides a command to build result.tar (second line). Whenever \n.le1 or .le2 change, the command will be run, and result.tar will be built. But imagine we want to build \nresult.tar from the list of .les stored in list.txt. The dependencies of result.tar cannot be spec\u00adi.ed \nin advance, but depend on the contents of list.txt. Unfortu\u00adnately, the make dependency system cannot \nexpress this pattern (for workarounds see \u00a77.5). Using the build tool we describe in this pa\u00adper, we \ncan write: . do result.tar *>. need [ list.txt ] contents . readFileLines list.txt need contents system. \ntar $ [ -cf , result.tar ]++ contents Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 12, September 9 15, 2012, Copenhagen, Denmark. Copyright &#38;#169; \n2012 ACM 978-1-4503-1054-3/12/09 $15.00. This rule describes how to build result.tar. We depend on (need)the \n.le list.txt. We read each line from list.txt into the variable contents being a list of the .les that \nshould go into re\u00adsult.tar. Next, we depend on all the .les in contents, and .nally call the tar program. \nIf either list.txt changes, or any of the .les listed by list.txt change, then result.tar will be rebuilt. \nThe key difference from make (and nearly all other build tools) is that rather than specifying all dependencies \nin advance, we allow further dependencies to be speci.ed after examining the results of previous dependencies. \nThis difference is crucial to accurately describe many dependency relationships. Consider the problem \nof dependencies stemming from .les in\u00adcluded by a C source .le. Some build tools require these dependen\u00adcies \nto be speci.ed manually. Other build tools allow two separate phases, where dependencies are computed \nbefore the build starts. But if the build system generates C .les and then compiles them, even a two \nphase system is insuf.cient, as the generated .les are not available during the .rst phase. Our build \ntool has no such lim\u00aditations it is able to easily handle generated .les, even generated .les which \nare only necessary due to being included by other gen\u00aderated .les. 1.1 Contributions We have implemented \nour build tool as a Haskell library, named Shake, which is available online1. Shake provides a concise \nsyntax for writing build systems (\u00a73), along with a high-performance im\u00adplementation (\u00a74). By implementing \nShake as a Haskell library we allow rules to be written using the full power of Haskell, including the \nuse of modules and functions to structure large build systems. In addition to more .exible dependencies \n(\u00a72), Shake also in\u00adcludes the important features of make, such as minimal rebuilds (running only a subset \nof the rules when some subset of the in\u00adputs change, \u00a72.3.2), and parallelising the build (running multiple \nindependent rules at the same time, \u00a74.3.2). We allow rules to op\u00aderate over any values, not limited \nto .les, allowing us to track non\u00ad.le dependencies (\u00a73.4) and properly handle commands producing multiple \noutputs (\u00a76.3). We have built a number of useful tools into Shake, including build rule checking (\u00a75.1), \npro.ling (\u00a75.2) and dependency analysis (\u00a75.3). Various versions of Shake have been used at Standard \nChartered for the past three years (\u00a76). The build system creates over 30,000 build objects, with more \nthan a million lines of source code and a million lines of generated code, in many programming languages. \nWe originally implemented this build system using make,but the result was slow to run, hard to maintain, \nand frequently caused spu\u00adrious compile failures. Switching to Shake made our build system ten times \nshorter, made builds run twice as fast, and has solved our build system problems. 1 http://hackage.haskell.org/package/shake \n  2. Specifying Dependencies Most make-like build tools start by constructing a graph from the dependency \ninformation, then traverse the graph, running the rules to build the required results (or use a topological \nsort, giving a sim\u00adilar effect). However, any approach based on a static dependency graph cannot permit \nadditional dependencies to be speci.ed while running the rules. As we saw in \u00a71, many examples require \naddi\u00adtional dependencies to be speci.ed while running the rules. The solution is simple we reject the \nidea that build tools should use a static dependency graph. In this section we model the dependencies \npermitted by non\u00adrecursive make (Miller 1998), along with our enhanced dependency scheme. We describe \nwhat it means for a build system to be correct, and how to support minimal rebuilds. In \u00a73and \u00a74weshow \nhow to turn these ideas into a practical tool. 2.1 Moving Dependency Speci.cation While make is heavily \n.le and IO based, we choose to model the dependencies without these distractions. Our model uses the \ntype Key for things that can be created or are dependencies (e.g. .le names), and the type Value for \nthe values associated with a Key (i.e. .le contents). With these types, we can de.ne the main build function \nas: build :: Set Rule . Key . Value The build function takes a set of rules and the target Key to build, \nand returns the Value associated with that Key. We restrict our model to building only one target, while \nmake allows multiple targets (i.e. a list of Keys to build). However, we can encode multiple targets \nby creating a distinguished key whose rule depends on the original targets and returns their values, \nand then use that key as the new target. Using build, we can model make with the Rule type: data Rulem \n= Rulem {creates :: Key , depends :: [Key ] , action :: [Value] . Value } A make Rule (Rulem) can be \nmodelled as the Key it creates,the Keysit depends on, and the action that takes the depended upon Values \nand produces the result Value. Note that all dependencies for a rule are speci.ed before running the \naction. Using the same build function, we can model our enhanced dependency scheme as: data Rules = Rules \n{creates :: Key , action :: Action } data Action = Finished Value | Depends Key (Value . Action) AShake \nRule (Rules) can be modelled as the Key it creates, and the action that creates the result. The Action \neither returns the Finished Value, or requires a new dependency with Depends specifying the Key it depends \non, plus a function that takes the Value of that Key and produces a new Action. The big difference from \nRulem is the introduction of dynamic dependencies. A rule can require additional dependencies, based \non the values of previous dependencies. We can easily translate Rulem to Rules, but the reverse is not \npossible Rules is strictly more powerful than Rulem. 2.2 Correctness Assuming a function which .nds \nthe Rule for a given Key, denoted by the operator (!), we can write a function to build Rulem targets \nas follows: buildm rules target = run (rules ! target) where run r = action r (map (buildm rules)(depends \nr)) Starting at the target Key, we .nd the associated Rulem,run buildm on its dependencies, then run \nthe action.A Rulem build system is able to produce the result for a given target iff the expression buildm \nrules target is well-de.ned. If we assume all actions are total, then this expression is well-de.ned \nif you can build a .nite dependency graph for the target with the available rules. This property can \nbe checked without running any actions. We can write a similar function to build Rules targets as follows: \nbuilds rules target = run (action (rules ! target)) where run (Finished val)= val run (Depends dep act)= \nrun (act (builds rules dep)) Starting at the target Key,we .nd the action from the asso\u00adciated Rules, \nand run it. Once we reach Finished we are done; if we encounter a Depends we run buildm on that dependency \nbe\u00adfore continuing. As before, a Rules build system is able to produce a result for a given target iff \nthe expression builds rules target is well-de.ned. However, unlike before, there is no obvious way to \ndetermine if the expression is well-de.ned in advance without detailed information about the action functions. \n 2.3 Minimal Rebuilds The build functions in the previous section may evaluate one rule many times during \na single run, but real build systems should minimise the number of rules run. In a single build run, \nany rule should be run at most once a property that is easy to guarantee with a simple cache. Additionally, \nif a rule s dependencies have not changed since the last time it was run, the rule should not be rerun. \nIn this section we describe how to avoid repeating Rulem rules whose dependencies have not changed, enhancing \nthe scheme followed by make, then apply the same ideas to Rules. 2.3.1 Minimal Rebuilds with Rulem To \navoid repeating rules whose dependencies have not changed, make does not run any rules where the dependent \n.les have older modi.cation times than the result .le. We use a similar scheme, adapted for arbitrary \nKey/Value types. Whenever a rule is run, we create a Resultm: data Resultm = Resultm {created :: Key \n, result :: Value , built :: Time } Resultm contains the Key the rule created,the result Value,and the \nTime when the result was built.We store all Resultm values between build runs using a database, and skip \nrerunning a Rulem if the result was built more recently than its dependencies. In common with make, we \nassume the rules do not change between runs (see \u00a76.2 for workarounds). To determine if we should skip, \nwe require the result for this rule s key from the previous build run (named old) and a way to demand \nresults for this build run (named ask): skipm :: Resultm . (Key . Resultm) . Rulem . Bool skipm old ask \nr = all ((. built old) . built . ask)(depends r) The skipm function returns True if a rule does not need \nrunning. We require the results for all dependencies, then check that they were built before this rule \nwas last run.  The make approach of relying on modi.cation times can fail if the system clock changes, \nif the clock resolution is too coarse, or if a .le has its modi.cation time set to a time in the past \n(such as when extracting a backup). Therefore, instead of using the system time for built, we use the \nnumber of runs of this build system, incrementing Time each run. This approach guarantees that Time is \nmonotonically increasing. A convenient property of make is that no additional data need be stored between \nruns, since the .le system already stores modi.ca\u00adtion times. In contrast, we must store the Time and \nResultm values in a database (interestingly, an additional data store is required for many advanced build \nsystems, see \u00a77). However, for some types of rules, such as when Keys are .lenames and Values are modi.ca\u00adtion \ntimes, the Values are stored in both the Resultm database and the .le system. If an inconsistency is \ndetected, we must discard our stored Resultm. To detect inconsistencies, we require the following function: \nvalidStored :: Key . Value . Bool This function should return True if the Key s Value is not stored elsewhere, \nor if it is stored but the Value is consistent. As an example for .les, validStored should return True \nonly if the .le exists, and has the same modi.cation time.  2.3.2 Minimal Rebuilds with Rules To achieve \nminimal rebuilds with Rulem we rely on having the dependencies available without executing the action, \nsomething that is not available with Rules. To solve this problem, we include the list of dependencies \nin Results, and use them in skips: data Results = Results {created :: Key, result :: Value, built :: \nTime , depends :: [Key ] } skips old ask r = all (( built old) . built . ask)(depends old) Compared to \nskipm, we have made one small change instead of using depends r,we use depends old. For the stored depends \nto be valid we rely on the rule s action not changing, and that the action is pure (see \u00a75.1 for necessary \nrestrictions when we allow IO actions). With this modi.cation we are able to ensure minimal rebuilds \nusing Rules. We still require the validStored check from the previous section. 2.3.3 Unchanging Results \nThe make tool has a requirement that a rule action must modify the .le it creates, otherwise the rule \nwill be repeatedly rerun, as the result will remain older than its dependencies. This requirement stems \nfrom using the modi.cation time as both the result and the built time, but since we store these .elds \nseparately, we can eliminate some unnecessary rebuilds. Instead of storing just the built time, we also \nstore the changed time when the result last changed. Whenever we create a result we use the current \ntime for built, but if the result Value is the same as last time, we use the previous changed time. We \ncan rewrite skips to take advantage of this additional information: data Results = Results {created :: \nKey, result :: Value, built :: Time, depends :: [Key ] , changed :: Time } skips old ask r = all (( built \nold) . changed . ask)(depends old) import Development.Shake import System.FilePath main = shake shakeOptions \n$ do want [ Main ] Main *>.out . do cs . getDirectoryFiles . *.c let os = map (++ .o ) cs need os system. \ngcc $ [ -o , out]++ os *.c.o *>.out . do let c = dropExtension out need [c] headers . cIncludes c need \nheaders system. gcc [ -o , out, -c , c] cIncludes :: FilePath . Action [FilePath] cIncludes x = do (stdout, \n) . systemOutput gcc [ -MM , x] return $ drop 2 $ words stdout Figure 1. A Shake build system for C \ncode. We have made one small change instead of checking against the built time of the dependencies, \nwe check against their changed time. It is important to still compare against built old because running \na rule may not update its changed time, but will always update its built time, thus we avoid rebuilding \nrepeatedly when the result does not change. Since it is always the case that changed built, skips will \nnow return True more often. In some situations, support for unchanging results can reduce rebuild times \nfrom many minutes to seconds. As an example, con\u00adsider a .le generated by the build system. If the generator \nchanges it is necessary to regenerate the .le, but there is a chance the re\u00adsult will not have changed. \nBy supporting unchanging .les we can avoid rebuilding everything depending on that .le.   3. Shake \nin Haskell In this section we use the theory from \u00a72 to create a practical build tool, implemented as \na Haskell library. In particular, we describe how to replace Key and Value with polymorphism, how to \nintegrate IO actions and how to de.ne a set of rules. We present the developer interface to Shake, but \nleave most implementation concerns to \u00a74. 3.1 A Shake Example Figure 1 shows an example build system \nin Shake. Running this program will build Main from all the *.c .les in the current direc\u00adtory. If we \nadd or remove a .c .le, or change any of the .c .les or the header .les they #include, then the necessary \n.les will be rebuilt. The build system produces (wants) the .le Main. To generate Main we list all the \nC .les in the current directory, add the exten\u00adsion .o (object .les), require those .les to be built \n(need them), then call gcc to link them. To build an object .le we take the associated C .le and call \nthe function cIncludes to get the headers it requires. We need those headers, then call gcc to do the \ncompilation. The cIncludes function works by calling gcc -MM, causing gcc to gen\u00aderate the dependency \ninformation on the standard output. This example demonstrates a number of features of Shake based build \nsystems:  data ShakeOptions = ShakeOptions {shakeFiles :: FilePath , shakeThreads :: Int ,... } shakeOptions \n= ... --default set of options data Rules a instance Monad Rules instance Monoid a . Monoid (Rules a) \ndata Action a instance Monad Action instance MonadIO Action class ( Typeable key, Typeable value, Binary \nkey, Binary value, Eq key, Eq value, Hashable key, Hashable value, Show key, Show value, NFData key, \nNFData value ) . Rule key value where validStored :: key . value . IO Bool run :: ShakeOptions . Rules \n() . IO () action :: Action () . Rules () rule, defaultRule :: Rule key value . (key . Maybe (Action \nvalue)) . Rules () apply :: Rule key value . [key] . Action [value] apply1 :: Rule key value . key . \nAction value Figure 2. Primitive operations in Shake It s Haskell The main entry point can call shake \ndirectly, but it can also do command line processing (\u00a76.1), or anything else. We have de.ned a local \nfunction, cIncludes, helping to split the build system into components that can be reused. We make use \nof the existing .lepath library. Expressive dependencies The call to getDirectoryFiles is tracked (\u00a73.4) \n adding or removing .les will trigger a rebuild. We track the dependencies introduced by #include directives. \nWe use system commands We use gcc to compile, to link, and to determine the headers required by the C \n.les. We can freely use both Haskell functions and system commands to generate build results. As a practical \nconcern, for many larger projects there are often multiple compilers that produce object .les with the \n.o extension. We solve this problem by making the C compiler use the extension .c.o, the Haskell compiler \nuse .hs.o etc, allowing different rules for each type of object.  3.2 Core Shake The core interface \nto Shake is given in Figure 2 everything else is de.ned on top. We can run the build system with run, \nspecify targets with action, create new rules with rule/defaultRule,and express dependencies with apply/apply1. \nWe build the targets using the run function, which also takes an options record. Typical options include \nwhich .le to use for the database (shakeFiles) and the number of processors to use (shakeThreads). To \nspecify the targets to build we use action, specifying an action which is always run, typically calling \napply to require keys to be built. Every key/value rule pair used in Shake must be a member of the Rule \nclass. The Rule class de.nes the method validStored to determine whether a value is consistent with any \nvalue stored externally (\u00a72.3). Each key and value type must also be a member of several type classes: \nTypeable We allow multiple types of rules in a single build system. To distinguish the types, we require \na Typeable constraint, allowing us to obtain an explicit TypeRep (L\u00a8ammel and Peyton Jones 2003). Binary \nWe require Binary serialisation, allowing us to store the results between runs, to achieve minimal rebuilds \n(\u00a72.3). Eq We require equality to look up results for keys and to test if values have changed (\u00a72.3.3). \nHashable We require Hashable to accelerate looking up results for keys. The Hashable requirement for \nvalue is currently unused, but is included for consistency. Show We require Show for debugging messages, \npro.ling and analysis (\u00a74.2, \u00a75.2). NFData We require NFData to ensure that values are fully evalu\u00ad ated \nwhen they are computed, ensuring errors occur in a timely manner (\u00a74.2). Most rules are de.ned with rule, \nwhose argument is a function which takes a single key value, and returns Nothing to indicate that this \nrule does not build this key,or Just with the action that builds the associated value. The function defaultRule \nallows a rule to be de.ned with a lower priority, which is used if no rules match (see \u00a73.5). If two \nrules of the same priority match the same key then an error is raised. The Rules type is a commutative \nMonoid, allowing two sets of rules to be joined to produce a new set of Rules. In practice, the syntactic \nsugar supported by Monad offers a very natural way to de.ne rules, allowing a set of rules to be introduced \nwith do and then simply written below each other. To support a Monad instance for Rules we add an additional \ntype parameter a (almost always instantiated to ())and make (> ) join two sets of rules. To de.ne actions \nwe use the Action type, which has a Monad instance to allow actions to be executed sequentially. The \nAction type has an instance for MonadIO, allowing users to call arbitrary IO functions using liftIO to \ntranslate IO a to Action a. Depen\u00addencies can be expressed using the function apply1 which takes a key, \nensures the key is built, and returns the associated value.The apply function can be thought of as mapM \napply1, but may build the necessary keys in parallel (\u00a74.3.2).  3.3 Wildcard File Patterns The make \ntool supports the syntax %.c to match any .les ending with .c. We de.ne a similar notation, allowing \n* to match any part of a .lename and // to match any number of directories, using the de.nitions: type \nFilePattern = String (?=):: FilePattern . FilePath . Bool As an example, *.c ?= foo.c returns True, while \n*.c ?= foo.h returns False.We reuse the FilePattern type in several of our rules.  import quali.ed System.Directory \nas IO data Dir = Dir FilePath FilePattern --plus all necessary instances go :: Dir . IO [FilePath] go \n(Dir dir pat)= liftM (.lter (pat?=)) $IO.getDirectoryContents dir instance Rule Dir [FilePath] where \nvalidStored q a = liftM (= a) $go q getDirectoryFiles :: FilePath . FilePattern . Action [FilePath] getDirectoryFiles \ndir pat = apply1 $ Dir dir pat defaultDir :: Rules () defaultDir = defaultRule $ Just . liftIO . go \n Figure 3. Implementation of getDirectoryFiles.  3.4 De.ning Rule Types A typical Shake build system \nwill use a handful of different Rule instances, usually all provided by the Shake library. To aid end \nusers, we suggest that people de.ning rule types also de.ne sugar functions, as we have done for the \nrule types included with Shake. As an example of de.ning a rule type, we give the code for getDirectoryFiles \nin Figure 3. This function takes a directory, and a .le pattern (\u00a73.3), and returns the list of .les \nthat match. We start by de.ning a key data type (Dir), along with a func\u00adtion that computes the result \n(go). We de.ne a Rule instance map\u00adping from the Dir data type to the result type of [FilePath],which \nuses equality to check if a previous result is still valid. We de\u00ad.ne getDirectoryFiles as a strongly \ntyped wrapper around apply1, and defaultDir as a wrapper around defaultRule. Anyone using getDirectoryFiles \nmust include defaultDir in their rule set, so the defaultRule for Dir is available. We do not export \nthe Dir construc\u00adtor, forcing people to use the wrappers. 3.5 File Based Rules While our build system \nis not restricted to rules dealing with .les, in practice many build systems are .le orientated. When \nimple\u00admenting .le rules, the .lename is an obvious key,but value could be either modi.cation time or \na hash of the .le contents (e.g. SHA1). In practice, we found that using modi.cation time is faster (signi.cantly \nfaster for large .les) and being able to force rebuilds using the touch command is highly convenient \nwhile developing build rules. Of course, our design allows anyone to de.ne a new type of .le rule, based \non .le content hashes. We de.ne .le rules in Figure 4. To force .les to be built, we de.ne need and want.The \nneed action adds a dependency on all the modi.cation times of the .les, and is typically used before \nperforming some IO action that uses the .les. We use want to specify the targets of the build system, \nimplemented by calling need in an action that is always run. We de.ne defaultFile as a rule that checks \nif the .le already exists, and if so uses it. Source .les will have no associated rules to build them, \nso this rule just records their modi.cation time. If a .le has no rules (since any rules would be run \nin preference to the default rule), and does not exist, we raise an error. As with defaultDir, anyone \nusing want/need should include defaultFile in their rule set. We de.ne new .le rules using (?>), which \ntakes a predicate to match against the .le name and an action to run. This function import quali.ed System.Directory \nas IO newtype File = File FilePath --plus all necessary instances getFileTime :: FilePath . IO (Maybe \nClockTime) getFileTime x = do b . IO.doesFileExist x if not b then return Nothing else liftM Just $ IO.getModi.cationTime \nx instance Rule File ClockTime where validStored (File x) t = fmap (= Just t) $ getFileTime x need :: \n[FilePath] . Action () need xs = do apply $ map File xs :: Action [ClockTime] return () want :: [FilePath] \n. Rules () want xs = action $ need xs defaultFile :: Rules () defaultFile = defaultRule $ .(File x) . \nJust $ do res . liftIO $ getFileTime x let msg = Error, .le does not exist and no rule: + x return $ \nfromMaybe (error msg) res (?>):: (FilePath . Bool) . (FilePath . Action ()) . Rules () (?>) test act \n= rule $ .(File x) . if not$test x then Nothing else Just $ do liftIO $ createDirectoryIfMissing True \n$ takeDirectory x act x res . liftIO $ getFileTime x let msg = Error, rule failed to build the .le: + \nx return $ fromMaybe (error msg) res (**>):: [FilePattern] . (FilePath . Action ()) . Rules () (**>) \ntest act =(.x . any (?=x) test) ?> act (*>):: FilePattern . (FilePath . Action ()) . Rules () (*>) test \nact =(test?=) ?> act Figure 4. Implementation of .le rules. ensures the correct key/value types, and \nobtains the modi.cation time afterwards. Before running the action we create the directory containing \nthe output .le, an idea taken from the Ninja build system (Martin 2011). We found that when running a \nlarge set of newly written rules, often one rule would create the output directory while another did \nnot meaning some rule execution orderings worked while others failed. Automatically creating the output \ndirectory removes this source of failure. While (?>) is the ultimate .le creation rule, we de.ne two \naddi\u00adtional operators, using the .le wildcard match operator (?=) from \u00a73.3. We de.ne (*>) for matching \na single pattern, for example *.c *>..., in a similar style to make.We de.ne (**>) for match\u00ading any \none of a set of patterns.  3.6 Automatically Include Default Rules With the rule types already de.ned, \nusers can write a build sys\u00adtem using Shake. Unfortunately, if the user forgets to include the defaultFile \nrule, there is likely to be a runtime error. Instead of re\u00adquiring the user to remember to include the \ndefault rules, we de.ne a wrapper function shake which includes all the standard default rules:  shake \nopts rules = run opts $ do defaultDir --\u00a73.4 defaultFile --\u00a73.5 ... rules In addition to the directory \nand .le rules, we also include rules that query the existence of .les, always force a rule to rerun, \nstore arbitrary con.guration data in a tracked manner and build multiple .les in one action. All these \nrules are de.ned similarly to the directory and .le rules. The astute reader may be wondering why we \ncan t specify de\u00adfault rules as an additional member in the Rule type class, allowing the default rule \nto be found from the type, and avoiding the need for the shake wrapper around run. Alas, that solution \ndoesn t work be\u00adcause we need explicit rules of each type to deserialise dynamically typed values (for \nfull details see \u00a74.1).  3.7 Additional Functions The IO function readFile is only safe if the .le being \nread has previously had need called on it, tracking the dependency (for more IO safety properties see \n\u00a75.1). To help build system authors, we de.neasafewrapper, readFile., which includes the call to need: \nreadFile. :: FilePath . Action String readFile. x = need [x] > liftIO (readFile x) We also de.ne readFileLines \nwhich is like readFile., but splits the contents of the .le into lines (therefore the .rst need call \nin the example from \u00a71 is unnecessary, but not harmful, as readFileLines will also call need). We de.ne \nwriteFileLines for writing .les containing a list of lines. The function writeFileChanged writes a .le, \nbut only if the contents have changed, avoiding some rebuilds due to unchanging results (\u00a72.3.3). We \nde.ne the system. function which runs a system command, but fails if the exit code represents failure, \nand also records pro\u00ad.ling information (see \u00a75.2). The system. function should be used carefully, as \nit cannot tell which .les the system command may depend on, so explicit need commands must be used. We \nrecom\u00admend writing wrappers around system commands which insert the appropriate need calls (see \u00a75.1 \nfor which need calls are required).  4. Implementing Shake We have implemented Shake, and used it extensively. \nIn this section we sketch some of the main implementation challenges and how they can be overcome. We \n.rst describe how to handle different key/value types within a single build system, then how to deal \nwith errors, and .nally how to execute the rules ef.ciently and with maximum parallelism. Readers interested \nin more details are encouraged to download the full implementation (see \u00a71). 4.1 Dynamically Typed Values \nA single Shake program can use multiple types for keys and values. To work with heterogenous values in \nHaskell we de.ne: data Any = Any (. a (Typeable a, Binary a, Eq a , Hashable a, Show a, NFData a) . a) \nThis de.nition, using existentials (L\u00a8aufer and Odersky 1994), allows any type supporting all the required \ntype classes to be stored as type Any.We de.ne Key and Value as synonyms for Any.We can implement Eq, \nHashable, Show and NFData instances for Any without dif.culty, often by appealing to the TypeRep provided \nby the Typeable instance. Implementing a Binary instance for Any is harder. Serialising a value is easy, \nwe serialise the TypeRep followed by the value. However, deserialising is problematic we can deserialise \nthe TypeRep, but to deserialise the value we need to obtain the Binary instance for that type. Our solution \nis to keep a mapping from TypeRep to Any, and after deserialising the TypeRep .nd the associated Any \nand use that Binary instance. As a consequence, we cannot deserialise any .le containing a TypeRep not \npresent in our mapping. We generate the mapping from all rules de.ned in the Rules set. Therefore we \ncannot move defaultRule into the Rule type class, as then a type could be usefully used without being \npresent in the Rules set. When deserialising, if we encounter a type not present in the mapping, we ignore \nthe entire database. This behaviour is pes\u00adsimistic, but safe if the set of rules has changed then the \nbuild system must have changed, which is not tracked (see \u00a76.2). 4.2 Handling Errors To turn Shake into \na practical system, we make a number of changes from the natural implementation, designed to improve \nerror handling. Tracking the stack We maintain a stack while executing rules, listing the keys that cause \na rule to be executed. Whenever an error occurs, either when running a rule or .nding a rule, we print \nthe stack. Whenever we execute an action, we force its result using the NFData instance, ensuring any \nerrors are raised with the correct stack. We raise an error when trying to build a key that is already \non the stack, which would indicate a key depends on itself. This last check provides a clear error message \ninstead of executing an in.nite series of rules. Tracing and diagnostics We provide options to print \nevery rule and system command run. Whenever a system command fails, we reprint the command line after \nthe failure. We provide a diagnostic mode to print detailed information as the build progresses, helping \nto debug build systems. Resuming after errors When running a large build system, it is common for it \nto fail before completing either from a rule raising an error, or the user killing the build process. \nIn these situations it is important that none of the work already done is lost. At startup Shake loads \nits database into memory, and on successful completion it saves the database to .le. To ensure no results \nare lost, every time a rule completes we immediately store the result in a journal .le. If Shake .nishes \nsuccessfully we delete the journal, but if a journal is present on startup, we merge its results.  4.3 \nBuild Algorithm The internal state of Shake includes a mapping from each key to one of six status values. \nInitially every key is either Loaded (was found in the database) or Missing (is not known to the build \nsystem). The build logic of Shake is implemented in a function named build, which modi.es the state to \nensure that a given key is either Ready (a result is available) or Error (there was an exception when \nrunning the rule). The build function is parameterised by a way to check a stored value is valid (using \nvalidStored from \u00a73.2) and a way to build a key (appealing to the de.ned rulesfor that type). Using build, \nit is relatively easy to implement the core of Shake simply run all actionsand make apply call build \nbefore looking up the status of a key. Our implementation of the build function takes 100 lines of Haskell. \nWhen implementing build there are two goals, correctness and ef.ciency.  Figure 5. Building state transitions. \n4.3.1 Correctness For an implementation of build to be correct, it must always execute enough rules to \nensure all results are correct, but never execute rules that could have been safely skipped. We satisfy \nthese constraints with the status transition diagram in Figure 5. At the start of a build run all keys \nare either Loaded or Missing, and after calling build on a key, it is either Ready or Error.We use Checking \nfor keys that are being checked to see if they can be skipped, and Building for rules that are currently \nbeing built. If a key is Missing and is required we have no choice but to start Building it. After Building \nakey, the action will either complete successfully making the result Ready, or fail producing an Error. \nMost of the complexity of build comes from the Checking state, which is necessary to support unchanging \nresults (\u00a72.3.3). When checking a key there are two possibilities either the check succeeds and the \nresult is Ready, or the check fails and we start Building it. We .rst check the stored result using validStored, \nfailing the check if the result is no longer valid. We then build each dependency in order, and fail \nthe check if any dependency is Error, or has changed since we last built this key. If all dependencies \nare checked successfully, we transition to Ready, without running the rule. To support unchanging results, \nit is necessary to build depen\u00addencies before running the rule requiring them only running the rule \nif a dependency has changed. Since the value of earlier de\u00adpendencies may change subsequent dependencies, \nit is important to check dependencies in the order they were required. However, if the build system has \nbeen modi.ed, and a rule no longer requires its previous dependencies, these previous dependencies will \nstill be built, but not used. As a consequence, even if one of these unused dependencies results in an \nError, the build may still complete suc\u00adcessfully. 4.3.2 Ef.ciency When implementing build there are \ntwo separate ef.ciency goals. If no rules need to be run (a common case), build should strive for low \noverhead, as the time taken by build is likely to be a signi.cant proportion of the total time. If rules \ndo need running, build should start the rules as early as possible, to maximise parallelism. In order \nto expose parallelism we make build take a set of keys, and store depends as [[Key ]] instead of just \n[Key ] where each item comes from one call to apply. In some ways the goals of low overhead and high \nparallelism are in con.ict the .rst is best served by being single threaded (avoiding locks and thread \ncontention), while the second suggests spawning many threads whenever we encounter a set of activities \nthat could potentially be run in parallel. Our solution is to use a thread pool for running rules, a \nsingle lock to protect the state (no .ne-grained locking) and a mutex for each Checking/Building state \nto allow other threads to wait for a result to become available. The build function takes the lock and, \non a single thread, performs as many transitions as it can without waiting on a mutex or running any \nrules. Any waiting is performed after the state lock has been released, and any rules are run by adding \nthem to a thread pool and waiting for the result. By using a thread pool we obtain high levels of parallelism, \nand by having a single state lock we can perform a build requiring no rules to be run with no thread \ncontention. Our thread pool obeys the shakeThreads setting (Figure 2), ensuring no more than a given \nmaximum number of rules run in parallel. The thread pool is based around a pool of workers. If a new \ntask is added to the pool, and less than shakeThreads workers are active, a new thread is spawned, otherwise \nit is queued until a worker completes. When a rule is blocked in build, waiting for dependencies to become \navailable, we notify the thread pool to temporarily spawn another worker, ensuring maximum parallelism. \nIn order to reduce contention between processes, we run tasks added to the thread pool in a random order. \nOften different build rules require different resources for example a compiler uses a lot of CPU while \na linker does a lot of disk access. Running tasks in a deterministic order has the potential to always \nrun all compilers followed by all linkers, resulting in lots of resource contention between different \nprocesses. A random ordering avoids the worst case scenario, and gives a noticeable speedup up to 20% \nfor some real build systems.   5. User Tools In this section we describe three features that have been \nbuilt on top of Shake a dependency checking tool to ensure the build system is correct, a pro.ling tool \nto determine what took most time and an analysis tool to query the build dependencies. 5.1 Dependency \nchecking Build systems using the theory from \u00a72 obtain dependencies us\u00ading the Depends constructor, and \ncannot use a dependency without explicitly requesting it. However, practical build systems must in\u00adtegrate \nwith IO (\u00a73), where dependencies are not always explicit. One rule can store some IO state (e.g. create \na .le), and another rule can use that state (e.g. read the .le) without a tracked depen\u00addency, leading \nto inconsistent builds. We have identi.ed three re\u00adquirements Shake build systems must follow: Requirement \n1 If an IO action makes use of some IO state, then the rule must depend on that IO state. As an example, \nif a rule runs the copy command cp from to, then the rule must depend on from. In practice, we weaken \nthis requirement in two ways. Firstly, we allow modi.cation times as a proxy for the contents of a .le, \nwhich is safe assuming any changes to a .le result in changes to its modi.cation time. Secondly, we only \ntrack .le system changes within a speci.ed directory (the users project), allowing the rule calling cp \nto omit the dependency on the cp executable, which is rarely of interest. Requirement 2 If an IO action \nmakes use of some IO state that is modi.ed by the build system, then the rule must depend on that IO \nstate before performing the IO action. As an example, if a rule runs cp from to,and from is generated \nby the build system, then the dependency on from must be given before running cp. Looking at the build \nsystem in \u00a73.1, this build system .rst calls gcc on the source .les, then calls need, ensuring the header \n.les are all dependencies (requirement 1 is satis.ed). However, if we generate one of the header .les, \nrequirement 2 is violated because the need call comes after the .rst use we show how to solve this problem \nin \u00a76.4.  Requirement 3 After some IO state becomes a dependency it must not change for the rest of \nthe build run. As a result, there cannot be two separate rules that modify the same .le. Similarly, after \ngetDirectoryFiles is called (\u00a73.4) the build system cannot create new .les matching the pattern. Requirement \n3 is simple to check after building we run the function validStored on all Ready results in the database \n(\u00a74.3.2). We have implemented this feature as an option to Shake. To check requirements 1 and 2 requires \nknowing which IO state is used by an IO action. For simple IO actions (e.g. readFile) it is easy to determine \nwhich IO state will be used, but these simple actions can usually be wrapped to provide versions which \nare safe by construction (e.g. readFile. , \u00a73.7). For more complex IO actions, in particular the system. \ncommand, determining the dependencies in advance is impossible to do in a general way. The only practical \napproach is to trace which IO state is used, using a system tracing mechanism (such as strace). File \nsystem tracing (such as inotify or checking .le last-access times) can provide an approximation of which \nIO state is used, but cannot determine if the existence of a .le is tested. The challenge when tracing \nIO state is cross-platform portabil\u00adity. Our .rst attempt was based around .le last-access times, but \non modern versions of Windows access times are turned off by de\u00adfault (but can be turned back on by an \nadministrator), only accurate to one second (solvable by adding a one second delay after each IO action), \nand buffered for up to one hour (no feasible solution). There are no cross-platform tracing libraries, \nbut other build sys\u00adtems which rely on tracing have been able to hook system libraries on Windows (Shal \n2009), requiring 2000 lines of C code (more than the total size of Shake). We believe their approach \ncould be reused in Shake, but licensing restrictions prevent us from reusing their code directly.  5.2 \nPro.ling Shake records two separate pieces of pro.ling information. Rule execution times When running \na rule we record the execu\u00adtion time, excluding any time building its dependencies. Execution times can \nbe combined from different build runs, allowing us to estimate the total build time, ignoring parallelism. \nTraced IO actions Most time consuming rules invoke IO actions, typically system commands. To track these \nactions, we provide a trace function: traced :: String . IO a . Action a All actions run by traced are \nrecorded along with a human readable message (the .rst argument), the key being built, and the start \nand end times. We automatically call traced when running system commands. If we examine traced actions \nfrom a single run, we can determine how many traced actions were executing at each point in time allowing \nus to produce a parallelism graph as shown in Figure 6. We have built pro.ling support into the core \nof Shake. Since running a rule is likely to take some time (most rules will be spawning system processes), \nthe overhead of recording pro.ling information is negligible. In previous versions of Shake we only recorded \npro.ling information when explicitly asked, but found that users often wanted to pro.le the build run \nthat had just .nished always recording pro.le information makes that possible. 4 3 2 1 0 Figure 6. Build \nparallelism. 5.3 Analysis The Shake database records the dependencies of each key, allowing a full dependency \ngraph to be produced after the rules have been run. However, for any project of moderate size, a picture \nof the full dependency graph is rarely comprehensible although with judicious .ltering it is possible \nto produce something useful (see Figure 7 for an example). There has been some work on visualising large \nbuild systems, for example by Adams et al. (2007), but we have not yet tried applying it to Shake. Our \napproach to analysing the database is to de.ne queries which allow end users to answer speci.c questions \nabout their build system. Some of the most useful queries include: Why was a particular .le rebuilt? \nShake shows the complete path of dependencies, including the most recently changing dependency.  If \nI modify a .le, what will rebuild? Shake computes the list of rules that depend on that .le, including \nindirect dependencies, but assuming no unchanging results (\u00a72.3.3).  What is the most expensive .le \nto modify? For each leaf of the graph, Shake computes all dependencies, and then uses execution times \nfrom pro.ling to determine which causes most rebuilding.  Do my dependencies follow some layering principle? \nMany large projects are structured into isolated layers, this sepa\u00adration can be validated by the build \nsystem. For example, I would not expect any .les outside Development.Shake.* to import any modules from \ninside that module tree, other than Development.Shake itself.   5.4 Pro.ling and Analysis As an example \nof the pro.ling and analysis tools in practice, see Figures 6 and 7. Both these diagrams are produced \nby building the Shake library and test harness, a 24 module Haskell program, from scratch with a maximum \nof four processors. The entire pro\u00adcess takes 7.41 seconds, but spends 12.91 seconds executing rules, \ngiving a parallel speed up of 1.7 times. Executing the build system with one processor takes 11.83 seconds \n the reduced rule execu\u00adtion time is likely due to reduced disk contention. Figure 6 shows the number \nof traced system commands execut\u00ading at any point during the build. We see a start up period where zero \ncommands are running and the build system is computing de\u00adpendencies, followed by three spikes of using \nfour processors, fol\u00adlowed by a tail of using one processor. The dependency graph in Figure 7 shows the \ndependencies of the .hi .les, after hiding three utility modules which are leaves in the dependency graph \n(they add lots of lines, obscuring the  Figure 7. Dependency graph. ghc Shake-1 Shake-2 make Automatic \ndependencies Yes Yes Yes No Tracks GHC installation Yes Yes No No Build on 1 thread 7.69 11.83 11.77 \n11.75 Build on 4 threads 7.69 7.41 7.34 7.32 No rebuilding 0.54 0.10 0.04 0.02 All times are in seconds. \nShake-1 includes a call to ghc-pkg list to track dependencies on GHC package versions, while Shake-2 \nassumes the GHC installation does not change. Figure 8. Build time comparisons. underlying structure). \nIt is clear the build proceeds in three stages, with bottle-neck dependencies marked 1, 2 and 3. These \nthree bottlenecks account for the three periods of one processor usage. The .nal tail of one processor \nincludes both compilation of the main module (which pro.ling tells us takes 0.23 seconds) and linking \n(which takes 1.54 seconds). This example shows how Shake s pro.ling and analysis reports can be used \nto improve build performance. If the bottleneck mod\u00adules could be split up, or if their compilation time \nwas reduced, the overall build time would decrease. In practice, we have found that for large build systems, \nwhere Shake is building multiple targets, parallelism usually stays at the maximum (or fractionally below \nit) formostofthe build. 5.4.1 Comparison to ghc --make and make Building the same project with the GHC \ncompilation system (The GHC Team 2011), namely ghc --make, takes 7.69 seconds, com\u00adpared to Shake with \n11.83 seconds on one processor and 7.41 sec\u00adonds on four processors, see Figure 8. The reason GHC is \nquicker on one processor is that GHC keeps all interface information and package database information \nin memory, whereas running sepa\u00adrate ghc -c compilation commands requires reloading this infor\u00admation \neach time. However, Shake is able to use parallelism to im\u00adprove the build time, while GHC cannot. To \nrun the build system when nothing needs compiling, GHC takes 0.54 seconds and Shake takes 0.10 seconds. \nOf the 0.10 seconds required by Shake, 0.06 seconds are spent checking if the GHC installation has changed \n(running ghc-pkg list) if the GHC installation is assumed to be constant Shake requires only 0.04 seconds. \nShake is faster because it reads in one .le (the database) then quickly checks validStored on a small \nnumber of .les. GHC must query at least the same .le information, but also has to construct a dependency \ngraph, aggregating information from many .les. Of the 0.04 seconds taken by Shake, 0.03 seconds are spent \nwriting to the database we suspect effort spent improving the binary serialisation would reduce this \noverhead. We can build the same project using make, generating depen\u00addency information with ghc -M. Unlike \nShake and ghc --make, the end user is required to regenerate make rules whenever the dependencies change, \nand to clean the build whenever the GHC installation changes. Allowing make to cope with these changes \nwould be signi.cantly harder, and would slow make down by at least 0.12 seconds (ghc-pkg and ghc -M take \n0.06 seconds each). In all tests, the make solution is about 0.08 seconds faster than Shake, or 0.02 \nseconds faster if Shake avoids tracking the GHC installation. The consistency in the parallel speedup \nbetween make and Shake suggests both systems are able to extract the maximum parallelism in this example. \n  6. Evaluation At Standard Chartered we have been using build systems based on Shake for the last \nthree years. Before Shake we used make,but make was a poor .t for our project, primarily due to a large \nnumber of generated .les. In common with many large projects, we were forced to split our build system \ninto several phases, where one phase generated some .les and make rules which were then used by a subsequent \nphase. Before we switched to Shake, we had over 10,000 lines of make rules which were brittle and hard \nto extend. Our initial Shake based system was under 1,000 lines and compiled our project twice as fast \n primarily due to better parallelism from removing phases, random execution order of dependencies (\u00a74.3.2) \nand faster scanning for dependencies (\u00a76.4). Our Shake based build system has been an unquali.ed success \nwhile the complexity of our project has increased (more .les, more compilers, more generators and more \nplatforms), the build system has coped well. The .rst version of our Shake build system was under 1000 \nlines and matched everything the make system did. Shake has been able to express all the dependencies \ncorrectly and directly, resulting in a robust build system. From experience implementing several build \nsystems using Shake we have learnt a number of lessons both about best prac\u00adtices for structuring build \nsystems, and how Shake can be used to deal with the complexities of real software. In this section we \nshare some of those lessons. 6.1 Command Line Interface While a build system can simply call shake, \nmost systems add some command line handling, such as options to control parallelism and verbosity (see \nShakeOptions in Figure 2). One common feature is a clean command, to delete all build results. Using \nShake we could query the database to .nd all build results and delete them. Alternatively, deleting the \ndatabase will cause a full rebuild. However, we have found the most convenient solution is to create \nall build objects in a directory named .make, and perform a clean by deleting that directory.  Using \nmake, you can specify build targets on the command line. We have implemented an enhanced version of this \nfeature, allowing both individual .les and sets of .les to be enabled/disabled. As an example, a user \nmay write mk !DOCS to disable building documen\u00adtation, or mk index.html to build only index.html. We \ncontrol these targets by passing a modi.ed version of want to the functions specifying rules, which consults \nthe command line arguments: documentation :: (String . [FilePath] . Rules ()) . Rules () documentation \nwants = do wants DOCS [ index.html ] index.html *>.out . ...  6.2 Build rules that change Throughout \nthis paper, we assume the build rules do not change, merely the dependencies of the rules, but that is \nnot true in practice. We use three techniques to minimise the impact of build rule changes: Use con.guration \n.les Most build information, such as which .les a C .le includes, can be computed from source .les. Where \nsuch information is not available, such as which C .les should be linked together to form an executable, \nwe use con.guration .les to provide the information. The rule for linking can use these con.guration \n.les, which can be properly tracked. By moving any regularly changing con.guration into separate .les \nwe signi.cantly reduce the number of build system changes. Depend on the build source We should rerun \na build rule if its action has changed. Lacking equality for functions, one approach is to depend on \nthe build system source in each of the rules, then if any actions change, everything will rebuild. While \nthis option is safe, it causes a signi.cant number of redundant rebuilds. As a restricted version of \nthis technique, for a generated .le we often include a dependency on the generator source and use writeFileChanged \n(\u00a73.7). If the generator changes it will rerun, but typically only a few generated .les will change, \nso little is rebuilt. Use a version number There is a .eld named shakeVersion in the ShakeOptions record \nfrom Figure 2. If the build system changes in a signi.cant and incompatible way, we increment this .eld \nto force a full rebuild. This option is a last resort, but ensures end users do not need to be aware \nwhen the build system changes, and are never required to explicitly clean their build after changes. \n 6.3 Multiple Outputs Some programs, such as the Haskell compiler ghc (The GHC Team 2011), can produce \ntwo outputs with one command compiling Foo.hs produces both Foo.o and Foo.hi. As a .rst approximation, \nthe .o .le depends on the entire contents of the source .le, while the .hi .le depends only on the type \nsignatures. A single ghc invocation needs to do all the work to produce both, but often the .hi .le will \nbe left unchanged. Unfortunately, many build systems (including make) do not handle multiple outputs \nwell. In Shake, it is usually possible to describe multiple outputs in terms of single outputs in this \nexample we can claim that Foo.hi depends on Foo.o with no action and Foo.o depends on Foo.hs by running \nghc. Thanks to support for unchanging .les (\u00a72.3.3), if the .hi .le does not change then its dependencies \nwill not be rebuilt. However, this formulation has two problems: If Foo.hi is deleted without also deleting \nFoo.o,then Foo.hi will not be rebuilt by running the .hi rule, and the build system will raise an error. \n If ghc updates Foo.hi, but manages to determine it does not need to update Foo.o,then Foo.hi will not \nbe marked as dirty and the build will be incorrect.  data Files = Files [FilePath] data FileTimes = \nFileTimes [ClockTime] instance Rule Files FileTimes where validStored (Files xs)(FileTimes ys)= do times \n. mapM getFileTime xs return $ map Just ys = times multipleOutputs = do rule $ .(Files xs) . if xs .= \n[ even.txt , odd.txt ] then Nothing else Just $ do need [ numbers.txt ] system. number-split [] times \n. liftIO $ mapM getFileTime xs return $ FileTimes $ map fromJust times [ even.txt , odd.txt ] **>. . \ndo apply1 (Files [ even.txt , odd.txt ]) :: Action FileTimes return () Figure 9. Rule type to produce \nmultiple outputs. Despite these limitations, a fake dependency is often suf.cient in practice, provided \nwe can assume Foo.hi is not updated indepen\u00addently of Foo.o. However, consider a command that reads num\u00adbers.txt \ncontaining lines of numbers, and produces even.txt and odd.txt each containing only the even or odd \nnumbers but does not update an output .le that does not change. In this situa\u00adtion there is no fake \ndependency that adequately captures the real dependency. We can accurately capture the dependencies using \nthe code in Figure 9, which introduces a new type of rule for actions producing multiple .les. Inside \nmultipleOutputs, the call to rule declares a rule that can build both even.txt and odd.txt with a single \naction. We call the number-split program, and get the .le times for the results. On the **> line we de.ne \ntwo rules to produce the output .les, using the standard .le creation rules from Figure 4, whose action \ncalls apply1 with the list of .les to create. If the build .rst requires even.txt then number-split will \nbe invoked, but a subsequent requirement for odd.txt will not rerun number-split. The Shake library wraps \nup the Files rule type, providing a simple interface using the (*>>) operator, allowing an end user to \nwrite: . do[ even.txt , odd.txt ] *>>. need [ numbers.txt ] system. number-split []  6.4 Transitive \nDependencies In build systems, transitive dependencies are common where a rule depends on its children, \nplus their dependencies. As an example, if foo.c includes bar.h,and bar.h in turn includes baz.h, then \nfoo.c should be recompiled if either bar.h or baz.h changes. In \u00a73.1 we saw a solution to C .le dependencies, \nusing gcc -MM to .nd the transitive dependencies of a .c .le then calling need on the results. This solution \nhas two potential problems: If bar.h is included by many .les, then both it and any headers it includes \nwill be scanned many times. In most cases the overhead is small, but for some projects it can be signi.cant. \n If bar.h is generated by the build system, using gcc will not cause bar.h to be built, since the need \ncall is performed after running gcc (violating requirement 2 from \u00a75.1). If the .le is   *.c.o *>.out \n. do need =< readFileLines (replaceExtension out deps ) system. gcc [ -c , dropExtension out, -o , out] \n*.deps *>.out . do dep . readFileLines $ replaceExtension out dep deps . mapM (readFileLines . (++ .deps \n)) dep writeFileLines out $ nub $ dep + concat deps [ *.c.dep , *.h.dep ] **>.out . do src . readFileLines \n$ dropExtension out let incs =[init y | x . src , Just y . [stripPre.x #include \\ x]] writeFileLines \nout incs Figure 10. Rules to express transitive dependencies for C .les. missing gcc will fail, if it \nis present a stale value will be used when .nding its dependencies. For projects generating header .les, \nusing gcc -MM to scan for headers is unworkable. We can solve these problems by using the rule for *.c.o \nfrom Figure 10. We use a .dep .le to store the immediate dependencies of a .le, and a .deps .le to store \nthe transitive dependencies. For ex\u00adample, foo.c.dep contains the dependency bar.h while foo.c.deps contains \nboth bar.h and baz.h. The three build rules we use are: The *.c.o rule depends on the associated .deps \n.le (ensuring it is up to date) and then depends on its contents.  The *.deps rule takes the .dep .le, \nand all the .deps it points at, producing the transitive dependencies of its immediate depen\u00addencies. \nThis rule can be used to .nd the transitive dependen\u00adcies of anything with .dep rules, for example with \nHaskell .les it would produce the set of .les required for linking (namely the transitive dependencies \nof the imports).  The *.c.dep/*.h.dep rule takes a source .le and .nds all one-level dependencies by \nscanning for lines starting with #include. This rule makes a number of assumptions about the structure \nof the C .les which are not true in general. In particular, it assumes that includes are not skipped \nby #ifdef commands, that there is no extra whitespace, and that local in\u00adcludes are quoted while system \nincludes use angle brackets. These assumptions can be relaxed, but are suf.cient for many projects. \n  7. Related Work Build tools can be divided into two categories those which target single-language \nprojects with .xed rules (e.g. ocamlbuild, ghc --make, Visual Studio projects), and those which allow \nuser speci\u00ad.ed rules (e.g. make and Shake). Focusing on the second category, the defacto standard is \nmake,but there are many make competitors (notably Ant, CMake, Jam, Scons and Waf). Most of these tools \nread a list of rules, generate a dependency graph, then execute com\u00admands while traversing that graph. \nSince the number of build tools is vast, we focus on four build tools which take different approaches \n(Redo, Ninja, Tup and Fab\u00adricate). Interestingly, one thing all four systems have in common is that they \nrequire a database of build data, in addition to the rules and the .le system. Unlike Shake, all these \nbuild systems are lim\u00adited to .les. 7.1 Redo The Redo build system (Pennarun 2011) has a similar dependency \ntheory to Shake. Rules are run starting at the target. A rule may call redo-ifchange (similar to need) \nto ensure that this rule is repeated if any of the .le arguments change. A rule can build either a speci.c \nnamed .le, or a set of .les ending with a particular extension. While Redo has similarities to Shake, \nthe practical implemen\u00adtation is signi.cantly different. Instead of a single rule store, Redo stores \neach rule in a separate .le, and the script language is simply shell script (allowing #! to change the \ninterpreter). The advantage of separate .les is that Redo is able to depend on the actual rule used to \nbuild a result, meaning that build system changes are prop\u00aderly tracked. However, separating build rules \nmakes it harder to reason about the build system, and eliminates many potential uses of abstraction (de \nJonge 2005). Redo does not work on Windows, and has no support for unchanging .les or multiple outputs. \n 7.2 Ninja The Ninja build system (Martin 2011) is designed as a two-stage build system users specify \ntheir build rules in a high-level man\u00adner, which is then translated to a set of Ninja build rules. As \na re\u00adsult, the Ninja build system is not designed to be general purpose and con.guration choices are \nexpected to be resolved by the .rst level. The Ninja target language supports three dependency fea\u00adtures \nbeyond make. Firstly, a rule can depend on the list of .les contained in another .le, allowing additional \ndependencies at build time. Secondly, the command line for each rule is tracked, resulting in a rebuild \nif the rule itself changes. Thirdly, a rule can generate multiple outputs, which are properly tracked. \n 7.3 Tup The Tup build system (Shal 2009) is designed as an incremental build system. Tup has a similar \ndependency structure to make,but a signi.cantly different implementation. Instead of scanning all dependencies, \nit expects the operating system to supply a list of changed .les, avoiding the overhead of checking which \n.les have changed. For large build systems the result can be a signi.cant speed improvement when rebuilding \nonly a few .les. We believe a similar implementation strategy could be applied to Shake. Another difference \nfrom make is the treatment of dead build results. If a rule to build foo is deleted from the rule list, \nthen Tup automatically deletes the .le foo. The problem of dead build results is serious, resulting in \nbuilds succeeding that should have failed, and that will fail as soon as a clean build is performed (to \nreduce this risk, we suggest an overnight build which starts from scratch). However, it is often useful \nto have build modes which generate skeleton .les which are then modi.ed by the user deleting these .les \nwould be most unwelcome. It would be easy to add support for deleting dead build results to Shake, but \nwe choose not to.  7.4 Fabricate The key innovation in the Fabricate build system (Hoyt et al. 2009) \nis that dependencies do not need to be stated explicitly. A build system is a Python program, which primarily \nexecutes system com\u00admands in order. While executing the commands, Fabricate uses sys\u00adtem tracing (strace \non Linux) to record which .les are accessed. In future runs, if the same system command is reached but \nnone of the .les it used have changed, the command is skipped. The result\u00ading build systems are simple, \nand avoid the dif.culties of correctly specifying dependencies. There are two inherent dif.culties for \nbuild systems without ex\u00adplicit dependencies. Firstly, the system tracing mechanisms on dif\u00adferent platforms \nare varied, and on Windows are somewhat fragile (see \u00a75.1). Secondly, parallelism cannot be inferred \nautomatically Fabricate requires explicit grouping annotations to use parallelism.  7.5 Extending \nMake Dependencies Specifying additional dependencies while building is critical for many projects. As \na result, a number of techniques have been developed to specify additional dependencies in make.Most \nof these techniques rely on generating some portion of the make rules .le, either before make starts, \nor invoking make multiple times. Taking the example from \u00a71, we can write it with make as: result.tar \n: list.txt $(shell cat list.txt) cat list.txt | xargs tar -cf result.tar Here make is executing commands \nin two distinct phases the .rst phase generates the rules .le, the second runs it. In many large projects, \nthe .rst phase becomes expensive or complex, resulting in speci.c commands such as make depends to update \nthe de\u00adpendencies (as required in \u00a75.4.1 and \u00a76). Another approach is for make to restart itself partway \nthrough the build, after modifying the build rules. However, multiple phases have many problems: There \nis no limit to the number of build phases required, espe\u00adcially when .les are generated by the build \nsystem. Shake was originally designed after determining a particular build system required seven phases. \n The introduction of phases breaks compositionality, requiring build system authors to globally separate \nrules by phase. The above rule for result.tar fails if list.txt is itself built by the build system, \nwhereas the Shake rule in \u00a71 works in all cases.  These approaches require generating make rules as \ntext, which is then reinterpreted by make. As a result, while the Shake rule from \u00a71 can handle spaces \nin .le names, the make rule cannot.  If all phases are run every time then there is overhead due to \nrestarting make, rechecking previously checked rules and re\u00adducing parallelism opportunities. If different \nphases are invoked manually then the user has to be aware what has changed.  7.6 Haskell Build Libraries \nThere are a surprisingly large number of Haskell libraries imple\u00admenting a dependency aware build system \n we know of ten in addition to Shake (Abba, Blueprint, Coadjute, Cake \u00d7 2, Hake, Hmk, Nemesis, OpenShake \nand Zoom). Of these, the two Cake li\u00adbraries and OpenShake are based on an early presentation of the \nprinciples behind Shake, before the source code was available. The primary difference from the Cake libraries \nis that this paper allows multiple types of build rule, while the Cake libraries only allow .le rules. \nCompared to OpenShake (Bolingbroke 2011), we have opted to have rule/apply based on dynamic types, and \nthen use sug\u00adared versions to regain static guarantees of type safety. In contrast, OpenShake uses type \nfunctions (Schrijvers et al. 2008) to statically track the available rule types, making serialisation \nsimpler (\u00a74.1), but complicating the rest of the library.  8. Conclusions and Future Work We have presented \na dependency model which allows additional dependencies to be speci.ed after the build system starts \nrunning rules. This additional .exibility is essential for many build systems, especially those where \nsource .les are generated by rules. We have implemented our ideas in the Haskell library Shake, producing \na user-friendly interface combined with an ef.cient and robust implementation. We have used Shake extensively \nand .nd it much easier to use than make (\u00a76). Functional programming is important for Shake. The theory \nof build systems is naturally expressed using higher-order functions, where actions are functions from \ndependencies to results. Moving towards a practical build system, a major consideration is the treat\u00adment \nof IO we use monads to restrict where IO can be used, while also using monads to track state in a thread-safe \nway. We make use of the .exible syntax of Haskell to allow Shake rules to be writ\u00adten with minimal syntactic \noverhead. Laziness is not necessary for Shake, and if ignored could cause problems, but restricting laziness \nis simple (\u00a74.2). While we have optimised our build algorithms, saving the database is a noticeable bottleneck \nfor quick builds, taking upto 75% of the time. We suspect this step could be sped up, perhaps by switching \nto a different binary serialisation library. We have pro\u00advided some tools on top of Shake, but improvements \nto the analysis feature would help Shake users, as would fully implementing de\u00adpendency checking. Some \nusers have already begun work on gen\u00aderal purpose build rules for common types of source code, which \ncould reduce the effort required to make use of Shake. The make tool has been ubiquitous for the last \nthirty years, specifying dependencies in advance and de.ning actions with shell scripting and a macro \nsystem. With Shake we offer more power\u00adful dependencies, coupled with the Haskell language for de.ning \nactions. The dependencies allow more complex build systems to be speci.ed in a more direct manner, while \nthe use of Haskell al\u00adlows abstraction and reuse. We hope these advantages are powerful enough to tempt \nmany developers to consider Shake. Acknowledgements Thanks to Standard Chartered, where Shake was initially \ndeveloped, and to Raphael Montelatici for the name Shake. Thanks to Max Bolingbroke and Evan Laforge \nfor many discussions about build systems. Thanks to S\u00a8onke Hahn, Evan Laforge, Roman Leshchinskiy and \nRaphael Montelatici for com\u00admentsondraftsofthispaper. Neil Mitchell is employed by Standard Chartered \nBank. This paper has been created in a personal capacity and Standard Chartered Bank does not accept \nliability for its content. Views expressed in this paper do not necessarily represent the views of Standard \nChartered Bank.  References Bram Adams, Herman Tromp, Kris De Schutter, and Wolfgang De Meuter. Design \nrecovery and maintenance of build systems. In Proc. ICSM 07, pages 214 223. IEEE, October 2007. Max Bolingbroke. \nOpenShake build system. https://github.com/ batterseapower/openshake, 2011. Merijn de Jonge. Build-level \ncomponents. IEEE Transactions on Software Engineering, 31(7):588 600, 2005. Stuart Feldman. Make a program \nfor maintaining computer programs. Technical Report 5, Bell Laboratories, 1978. Berwyn Hoyt, Bryan Hoyt, \nand Ben Hoyt. fabricate the better build tool. http://code.google.com/p/fabricate, 2009. Ralf L\u00a8ammel \nand Simon Peyton Jones. Scrap your boilerplate: a practical design pattern for generic programming. In \nProc. TLDI 03, pages 26 37. ACM Press, March 2003. Konstantin L\u00a8aufer and Martin Odersky. Polymorphic \ntype inference and abstract data types. ACM Transactions on Programming Language Systems, 16:1411 1430, \nSeptember 1994. Evan Martin. Ninja manual. http://martine.github.com/ninja/ manual.html, December 2011. \nPeter Miller. Recursive make considered harmful. Journal of AUUG Inc, 19(1):14 25, 1998. Avery Pennarun. \nredo: a top-down software build system. https:// github.com/apenwarr/redo, December 2011. Tom Schrijvers, \nSimon Peyton Jones, Manuel Chakravarty, and Martin Sulzmann. Type checking with open type functions. \nIn Proc. ICFP 08, pages 51 62. ACM Press, 2008. Mike Shal. Build system rules and algorithms. http://gittup.org/ \ntup/build_system_rules_and_algorithms.pdf, 2009. The GHC Team. The GHC compiler, version 7.2.2. http://www. \nhaskell.org/ghc/, November 2011.   \n\t\t\t", "proc_id": "2364527", "abstract": "<p>Most complex software projects are compiled using a build tool (e.g. make), which runs commands in an order satisfying user-defined dependencies. Unfortunately, most build tools require all dependencies to be specified <i>before</i> the build starts. This restriction makes many dependency patterns difficult to express, especially those involving files generated at build time. We show how to eliminate this restriction, allowing additional dependencies to be specified while building. We have implemented our ideas in the Haskell library Shake, and have used Shake to write a complex build system which compiles millions of lines of code.</p>", "authors": [{"name": "Neil Mitchell", "author_profile_id": "81337491713", "affiliation": "Cambridge, United Kingdom", "person_id": "P3804308", "email_address": "ndmitchell@gmail.com", "orcid_id": ""}], "doi_number": "10.1145/2364527.2364538", "year": "2012", "article_id": "2364538", "conference": "ICFP", "title": "Shake before building: replacing make with haskell", "url": "http://dl.acm.org/citation.cfm?id=2364538"}