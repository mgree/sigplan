{"article_publication_date": "01-24-1983", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1983 ACM 0-89791-090-7 $5.00 syntax of a programming kmgnage: (pm-body) ::= (Cr7Cd) (cd) ::= (identifier) \n:= (ezpr) (crnd) ::= begin (crrtd); (crnd) end (crud) ::= if (ezpr) then (mad) else (crnd) (crnd) ::= \nwhile (ezpr) do (red) (ezpr) ::= (identifier) (ezpr) ::= (ezpr) (ezpr) Corresponding to each production \nis a semantic equation. Here p ranges over environments and K ranges over expression or command continuations, \nand u ranges over stores: P[(proc-body)] = C[(proc-body)] C[(identijler) := (ezpr)] = ~pK. ~[(eZpr)]P(iV. \nStOre(identifier) pKU) C[ begin (crnd)l; (crad), end ] = ~~K.C[(cmd)l]?( C[(cmd)z]pK) C[ if (ezpr) else \nthen(crnd)l(c~d),] = ApK. &#38;[(ezpr)]p(Xti.(v + C[(crnd)l]pK, C[(CrrUi)2]pK)) C[ while (e.zpr) do \n(crnd)] = >prc.Y(XO.f [(ezpr)]p(Av.(u + C[(crnd)]p@, K))) &#38; [(identifier)] = Xptcu.rc(a(p (iderztij%m))) \n&#38;U(6rpr)1 (e$pr),l = XpK. &#38;[(ezpr)l]p(lrh .&#38;[(ezpr)2]p(lo2 .K(u~ w))) In this section \nwe shall summarize how we go about analyzing this example, except for the while-loop, which is left for \nthe main portion of the paper. Our first task is to recast the semantic equations in terms of combinators. \nWe do this analysis in two steps. First, we rewrite each equation in compositional form: z[h] = M(X[(non-terminal) \nl],..., Z[(non-terrnird) fi]) where x denotes a semantic function and M is a combinator, that is, a A-term \nwith no free variables. Then, we compare the M s from the different equations to see if they can be built \nfrom some suitable modules. A key step in this comparison is to observe general patterns of argument-steering. \nIn this example, this analysis arrives at the following r.ombinators: ~~ = hcIBpKZI. .Z.k.CI@(8p/CTI. \n.Z.k) return = XpK. K t.%ik = i@pKZI, .Zk V.V + CIflKZI. .Zk, BpKZI. .Z~ fetCh = ~ idpKU.K(O(p id)) sub \n= APKVIW. K(V1 -IJa) Using these combinators, we can rewrite the semantic equa\u00adtions as: P[(proc-body)] \n= D,(C[(crnd)], return) C[(identij?er) := (ezpr)] = Do(&#38;[(ezpr)], store (iderztijier)) C[ begin (cmd)l; \n(crrsd), end ] = Do(C[(c~d)[], C[(Cmd)*]) C[ if (ezpr) then (crruf), else (cmd),] = ~o(f [(ezpr)], testO(C[(crnd),], \nC[(c~d)J)) &#38; U(identijier)] = fetch (identifier) &#38;[(ezpr), (ezpr),] = DO(FU(ezpr),], D1(f[(ezPr)~], \n~ub)) These equations may be read as a syntax-directed transduc\u00adtion which transforms the parse tree \nof a (proc-body) into a tree with D s and test s in the interior nodes and with return s, jetch \u00ad(identifier) \ns, store(identijier) s and sub s at the leaves. Such a translation is shown in Figure la. We can do better, \nhowever, by observing that in the theory k of the ),-calculus, one can easily prove that Theorem 1. (i) \nD,(DO(CL b), q) = D,+,(a) D,+(O, q)) (ii) Dk(te.tO(fx, e), y)= test~(D~(a, -I), D~(B, T))  (iii) Dk(r6t~rn, \nq) = ~ m We can use these associative laws to rotate to the right any D s or test s which are left sons \nof other D S. The result of this rotation is shown in Figure lb. The resulting term is a (seg), defined \nby: (seq) ::= return (scg) ::= D~((ircs), (seg)) (seg) ::= testk((seq), (seg)) (ins) ::= fetch (identifier) \n(ins) ::= store(iderztifier) (ins) ::= sub If we analyze the reduction of a (seq), we discover that the \nrotated tree is indeed postfix code, and that the reduction mimics the behavior of a stack machine. More \ndetail on the machine may be found in [Wand 82ajb]. The compiler is correct because it can be proved \nin the theory x of the X-calculus that the rotated combinator tree is equal to the original tree. The \nmachine is correct because it simulates a reduction sequence using a complete reduction strategy. These \ncorrectness proofs are greatly simplified because they involve only the syntactic theory of the X-calculus, \nwhich is well-understood, and do not involve any model-or lattice-theoretic considerations. The code \nproduced by such a combinator-based compiler is indubitably tree-like. The obvious way to handle loops \nin this framework is to stack the loop starting address at run time [Wand 80]. Using the Y combinator \neffectively does the same thing. How can we move this from run time to compile time where it clearly \nbelongs? Put another way, how can such a compiler produce code with loops in it, as conventional compilers \ndo? 3 Theoretical Development If we are to analyze loops in programs, we need to do induc\u00adtions. It is \nat this point that we introduce domains in the con\u00adventional theory: if we are dealing with a particular \nmodel (the domain), then we are no longer restricted to the theory X, and we can do inductions if they \nare valid in the domain. However, this often seems to require choices ( e.g. lattices vs. cpo s) which \ndo not bear any obvious relationship to any computational reality or to the basic idea of the proof. \nWe would therefore like some proof-theoretical alternative. As an example, observe that there are two \nplausible com\u00adbinators for while-loops: u,hile(r)a@ = xpLY(M.cl/2(k%rJ + @p8, K)) whik(~f~aj = Y(h(7f7K, \ncxf7(xv.v /3p(@jptG),tc)) IIere, of course, Y denotes the standard fixed-point combinator /\\ /DO\\Do return \nfetch X / 0 fetch< \\ Do /DO\\ / \\ fetch X sub /D \\ fetch Y \\ sub /D \\ fetch Z / fetch Z \\ sub /DO\\ \nsub return (a) (b) Figure 1. Combinator tree for (X Y) Z. (a) before rotation (b) after rotation (but, \nsee below). The first version distributes nicely with the sequencing combinators Dk; the second has a \nnicer expression in terms of the sequencing combinators: ~~~~~f )ae= te.sto(Do(/3, 0), return)) Y(X# \n.DO(a, where testk= AcY/3pKxl. .Zkcl. u + Ccplczl, .Zk, ppxzl. ..z~ Unfortunately, proving that these \ntwo are equal requires some induction (note that the relation between 1?and 8 is like that of moving \na constant outside a loop.) ~here seems to be no way of showing them equal in the pure k-calculus, that \nis, the theory of equalities of k-terms under a-and &#38;conversion [Barendregt 81]. Since we wish to \navoid choices of models; we seek a proof-theoretic alternative. One such alternative is the theory B \nof B6hm trees [Baren\u00addregt 81]. Given a i-term M, we can construct its Bohm tree BT( M) roughly as follows: \ntake the leftmost reduction sequence of M. One of two things may happen. Either it eventually redLtes \nto a term of the form where y is a variable and the Af s are any terms (not necessarily in normal form), \nor it does not. In the latter case we say M is unsolvable, and we let EJ7 (M) be the special symbol Q. \nOtherwise we let ET(M) be kc,. zn.yBT(M, ). .BT(M. ) Here we intend for the recursion to denote the construction \nof a possibly infinite tree. (A more formal presentation can be found in [Barendregt 81]). For example, \nthe B6hm tree of the Y combinator above is Xf.f(f(f, .)) and l-(k8z, gz(8z)) and hz,Y(gz) both have as \ntheir Bohm tree Xz.gx(gz(gz. ,)) The theory B of Bohm trees is defined by setting B I-M = N iff ET(M) \n= BT(N). The following proposition summarizes the key facts about B: Proposition 2. (i) If A~M=N, then \nB+ M=N. (ii) lJM is an~ term and N is any term in normal form, then B h M= Nimplies AFM=N. (iii) A term \nM has a normal form in B iff it has . ~o,mal form in k.  (i.) ~ M has a normal form, then ang quasi \n[eftmo~t reduction scqutnce started on M u,illjind it and terminate, Proof: (i) and (ii) follow from \nthe fact that B is a k-theory; (iii) is an easy consequence of of (i) and (ii). (iv) follows from (iii) \nand the fact that any quasi leftmost reduction strate~ is complete. See [Barendregt 81] for details, \n~ The reduction in strength theorem may now be stated as follows: Propofi!tion 3. Let z denodc a ucctar \naf uariablcs Zl, . . . . z%. Then B * Y(AEgz(#z)) = AEY(gT). Proof: Both have as their Ehhm tree AZ,gZ(gZ, \n,. ). # Proposition 4. B ~ while( ) = white(] ). Proof: Use the previous proposition, with g = XpKO.cYp(XtJ,rJ \n-+ @p8, K). B Let while denote either of these equal terms. We can now state the associativity result \nfor whik: s hlodifying the machine Theorem Proof : 5. B E Dk(whi[eaP , ~) = Y(M.Dk(a, testk(Dk(f3, 0), \n7))) Clearly, the key problem faced by the machine handling of lobeL The machine s job is to simulate \nsequence of the term it is given by the compiler. obvious thing to do is something like: is the correct \na reduction Now, the YA4 + M(Y M) Unfortunately, while k + Y&#38;f = reduce to &#38;f(YM); showing the \nequality step. Thus the obvious reduction is not M(YM), requires justified YA4 does not a backward (yet). \nWe solve this problem by using a different reduction behavior. Let a fixed-point combinator with 4 Modifying \nthe Compiler In order to take advantage of these results, it is convenient to once again allow variables \nin our terms, Since that is the only use we have for variables, we reintroduce them in the guise of a \nstructured binding operator: We may now write the equation for a while-loop as C[ while (ezpr) do (crnd)] \n= label#.DO(&#38;[(expr)], te.sto(Do(C[(cncd)], 0), return)) With this new equation in place, we may \nstill regard the equations as specifying a syntax-dkected transduction. A pro\u00adgram then translates into \na term with possible occurrences of label and 0. The term is, however, always closed, that is, all occurrences \nof 8 are bound by some occurrence of labeL We may then use our associativity laws to rotate occurrences \nof label to the right so that they never occur as the left son of a D. For concreteness, we give the \nrewriting rules in some detail: rot(Dk(DP(z, y), z)) = rot(lh+p(z, h(y, z))) rot (D~(testO(z, u), z))= \nte.stk(rot (Dk(z, z)), rot (Dk(y, z))) rot (Dk(whiie (z, y), z))= kbe/O.rob (Dk(z, testk(Dk(y, 0), z))) \nrot (D~(re~urn, z)) = z rot (Dk(z, u)) = Dk(z, rot(u)) otherwise rot((tmriable)) = (variable) Thk gives \nus a nice linearized form for the output of the compiler. The result of the rot of the syntax-directed \ntransduc\u00adtion of a program is again a (seg), where we add to the definition in Section 2 the two productions \n(seq) ::= (uariable) (seg) ::= Iabel(uariable) .(seq)  Figures 2a and 2b show the terms corresponding \nto a short program, before and after rotation. Note how the statement following the loop has been integrated \ninto the right branch of the test. Since the term output by the compiler is obtained by taking the term \ngiven by the semantics and applying equality-preserving tram+formatbns to it, the output term is equal \n(in 1?) to the term given by the semantics. Therefore the compiler is correct. Then ~ kf + A4($3A4) [Turing \n37, cited in Barendregt 81]. Further\u00admore, in k?, Y = ~, so we may substitute ~ for Y everywhere above. \nWith this background, we can now outline the behavior of the abstract machine. It must simulate the reduction \nof a term of type Answer ; the term consists of a closed (.seg) applied to arguments. The behavior of \n(seq) s of the form return or Dk((ins), (seq)) was considered in [Wand 82a, b], These led to a standard \nfetch-execute cycle, Since the (seg) is closed, it cannot consist of a variable, hence we need only consider \n(.seq) s which are of the form test~((seg)l, (seg)2) or label (uariob~e).(~eq) . It is easy to work out \nthe action of the machine by following the definitions: Hence the machine executes (.seg)l if the the \nvalue on the top of the stack is a true value, and (seq)2 otherwise. (For brevity, we have not distinguished \nbetween boolean and normal values; this can be done in any of the standard ways). The case of label is, \nof course, the interesting one for our cur\u00adrent purposes. Again, we use the definitions of the combinators \nto work out the action of the machine: labeltl. Mptczl. ., Zn + @~.~f)~K2!I. . . Zn 4 (~~. M)(/abe~@ \n.M)pKz l,., Zn + M[labelO, M/8]pKz1. . .Zfi Hence the action of the machine is given by When the machine \nencounters labelO. M, itsubstitutes the term labei8. A4 for every free occurrence of 0 in M, according \nto the usual rules for substitution of terms for free variables. Among other things, this may require \nrenaming of bound variables, but we shall see later how this may be avoided. As before, the machine is \ncorrect because it is simulating a quasi leftmost reduction sequence: if it halts, it gives the right \nanswer, by the Church-Rosser theorem, and if there is a normal form, then any quasi leftmost reduction \nwill find it. /Do\\ olabel @ 1 / \\ /Do return fetch< >ore ~ /Do\\\\ fetch X nzerop tes$ /\\ return /Do\\ \ne ,Do, label 0 store X I /Do /Do\\ /Do\\ fetch X fetch X /Do\\ /D1\\ \\ nzerop tes$ fetch f sub D1 \\/\\ \n/ 0, fetch Z sub / Do fetch X o /\\ / \\ fetch X store Y return (a) /D1\\ fetch Y /Do\\ sub D, / \\ fetch \nZ /DO\\ sub /Do\\ store X e (b) Figure 2. Code for while X # Odo X := (X Y) Z;Y :=X. (a) before rotation \n(b) after rotation 194 6 Putting in the loops In the abstract machine, label does a physical substitution \nof a code sequence for each free occurrence of the Lzbel identifier. This behavior is clearly unacceptable \nfor a real machine. We can avoid it by thinking of the real machine as an implementation of the abstract \nmachine, and using a few implementation tricks. First of all, since the language of code sequences is \na nice, statically scoped language, we can replace actual variables 8 by pointers to their binding occurrences. \n(See Figure 3a). This eliminates the problem of capture of variables. Better yet, since the only thing \nthese variables do is get substituted for, we can replace each variable occurrence by a pointer to the \ncode which will be substituted for it. (See Figure 3b). /\u00ad/ \\ 0 //  7be\\ e / 0 /( \\ tes$ /\\ / \\ \\ \\ \n////w \\ \\. \\ \\ \\ \\ \\ / \\ \\ \\ A I \\ / \\ \\ \\ --   / \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  - \u00ad / / (a) Figure \n9. Elimination of bound variables by pointers (a) to the binding occurrence (b) to the code which will \nbe substituted. If we do this, however, it leaves label with nothing to do! Hence we can eliminate it \nfrom the output code entirely. (See Figure 4). Figure J. Code following elimination of labels. This leaves \nus with code with circular links, as produced by e.g. [Thatcher et. al. 81] or [Sethi 81, 82], and without \nany instances of la bel s. (This justification, by the way, seems considerably simpler than the one which \nwe had previously con\u00adtemplated, which involved running the simplifier on infinite trees). The action \nof replacing occurrences of label variables by pointers to the appropriate code is highly reminiscent \n(at least to us) of the kind of analysis typically performed by assemblers: they take (among other things) \nsymbolic addresses and convert them to real addresses. This leads to a second strategy for deal\u00ading with \n[abe~ regard the compiler output, [abe!s and all, as as\u00adsembly language (with static scoping for label \nidentifiers), and simply say that it is the assembler s job to replace label identifiers with appropriate \nGOTO instructions. Our first solution, there\u00adfore, may be regarded as an argument for the correctness \nof this assembly algorithm. 7 Related Work For a survey of related work on compilers and combinators \nin general, see [Wand 80, 82a, b]. Here we will mention only work on circular structures. The work most \nclosely related to ours is that of [Sethi 81]. He introduces circular structures in the context of handling \ngo-to s. Our technique seems powerful enough to do bis examples, although we at present need language-specific \nsimplification rules rather than his Ianguage-mdependent ones. [Turner 79] used a circular link in his \ntreatment of the Y com\u00adbinat.or (though that idea is doubtless much older: we know of at least one ~-calculus \ninterpreter that used that trick in 1971). [hlilne and Strachey 76] introduce circular links mediated \nby storage addresses. [Raskovsky and Collier 80] introduce circular links in the midst of a variety of \ntransformations on semantic equations, Our concern, however, is with the development of rigorous yet \nsimple formal justifications for these techniques. ; 8 Conclusion In this paper we have presented an \nextension of combinator\u00adbased compilers to produce better code for loops. These new techniques allow \na simple justification for the correctness of the compiler and the machine. Our target language is now \ncon\u00adsiderably richer for the presence of labels and loops. This opens the door for a variety of optimizations \n(loop rotation, dead code elimination, strength reduction) to be done on this target code. Because the \ntarget code has a simple semantics, these optimiza\u00ad tion can be justified on the basis of more than optimism. \nThe technique can also handle other cases of loops in run-time struc\u00adtures, such as jumps to labels, \nmultilevel escapes from loops, and recursive procedures (e. g. letrec). References [Barenclregt 81] Barendregt, \nH.P. The Lambda Calculus: Its S@az ani Semantics, North-Holland, Amsterdam, 1981. [Milne k Strachey 76] \nMilne, R. and Strachey C. A Theory of Programming Language Semantics Chapman &#38; Hall, London, and \nWiley, New York, 1976. [Raskovsky &#38; Collier 80] R askovsky, M. and Collierj P. From Standard to Implementa\u00adtion \nDenotational Semantics in Sermarttics-Directed Corrcpiter Generation (N.D. Jones, cd, ) Lecture Notes \nin Computer Sci\u00adence, Vol. 94, Springer, Berlin, 1980. [Sethi 81] Sethi, R. Circular Expressions: elimination \nof static environ\u00adments Automata, Languages, and Programming, 81h Colloquium, Acre Lecture Notes in Computer \nScience, Vol. 115, Spr ingerj Berlin, 1981. [Sethi 82] Sethi, R. Control Flow Aspects of Semantics Directed \nCompi\u00adling Proc. SIGPLAN 82 Symposium an Campiler Construction (Boston, 1982) SIGPLAN Notices 17, 6 (June, \n1982), 245-260. [Thatcher et, al. 81] Thatcher, J. W., Wagner, E. G., and Wright, J.B. (More on Advice \non Structuring Compilers and Proving Them Correct Theoret. Comp. Sci. 15 (1981), 223-250. [Turing 37] \nTuring, A.M. The p-functions in A-K-conversion J, Symbolic Logic 2 (1937), 164. [Turner 79] Turner, D.A. \nA New Implementation Technique for Appli\u00adcative Languages Software Practice and Experience g (1979), \n31-49, [W and 80] Wand, M. Different Advice on Structuring Compilers and Proving Them Correct , Indiana \nUniversity Computer Science Department Technical Report No. 95 (September, 1980). [\\Yand 82a] tVand, \nM., Semantics -Dire cted Machine Architecture Conf. Rfc. 9th ACLf Symp. on Principles of Prog. Long, \n(1982), 234\u00ad 241. 1 \\,\\;znd, M. [Deriving Target Code as a Representation of Con\u00adtinuation Semantics \nACM Trans. on Prog, Lang. and Systems J, 3 (July, 1982) 496-517.  \n\t\t\t", "proc_id": "567067", "abstract": "In our paper [Wand 82a], we introduced a paradigm for compilation based on combinators. A program from a source language is translated (via a semantic definition) to trees of combinators; the tree is simplified (via associative and distributive laws) to a linear, assembly-language-like format: the \"compiler writer's virtual machine\" operates by simulating a reduction sequence of the simplified tree. The correctness of these transformations follows from general results about the &#955;-calculus. The code produced by such n generator is always tree-like. In this paper, the method is extended to produce target code with explicit loops. This is done by re-introducing variables into the terms of the target language in a restricted way, along with a structured binding operator.", "authors": [{"name": "Mitchell Wand", "author_profile_id": "81100072594", "affiliation": "Indiana University, Bloomington, Indiana", "person_id": "PP39025873", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567067.567086", "year": "1983", "article_id": "567086", "conference": "POPL", "title": "Loops in combinator-based compilers", "url": "http://dl.acm.org/citation.cfm?id=567086"}