{"article_publication_date": "01-24-1983", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1983 ACM 0-89791-090-7 $5.00 Algorithm Restriction Time average usage worst case Space average us age \nworst case Traditional (stacks) (see e.g. /IZnu67/) Schorr-Waite-Deutsch Wegbreit /bleg72/ Lindstrom \nlLin741 Lincistrom /Lin73/ Robson /Rob77/ /Scw67/ trees trees O (n) O(n) O(n) O(n log O(n) O(n) n) O(n) \nO(n) O(n) 0(n2) O(n) O (n) 0(10g2n) O (n) O(log n) o(1) o(1) o(1) O(n log n) O(n) O(n) o(1) o(1) o(1) \nTable 1. Complexity of main list marking algorithms. 2. The working method Before one can hope to develop \na new algorithm, it is essential to understand how the existing algo rithms work. They are invariably \nbased on the stack implementation of the recursion, so we will start by recasting the marking algorithm \nof Section 1 into this form. We assume that a data type stack of nodeptr , for stacking node pointers, \nis available, with the usual stack operations: create (an empty stack) , push (a new pointer into the \nstack), pop (the stack) , top (of the stack) and isempty (is the stack empty). The marking algorithm \nis as follows: procedure MarkingWithStack; var p: nodeptr; s: stack of nodeptr; * create(s) ; p:=root; \nwhile true do begin ~ Shoul~i~) then begin mark(p) ; push(;,p); p:=left(p); end else if not i semi] \nty (s) then begin . . . p:=top(s); pop(s); p:=right(p); end else exit . end end, T-- The Schorr-Waite-Deutsch \nmarking algorithm /ScW67/ is based on the observation that the nodes in the stack always belong to the \npath from the root of the list to the currently scanned node. This path can be stored in the list structure \nby reversing appropriate links of the nodes on the path. An extra bit ia required in each node for distinguishing \nreversed links from original ones, and also for determining which nodes actually be\u00adlong to the stack. \nThe resulting algorithm is somewhat tricky, and it has become almost a standard test case for various \nproof techniques: correctness proofs of the algorithm can be found e.g. in ldeR77/, /YeD77/, /GrieJ9/, \n/Kow79/ and /ToP79f. The methOd Of prO\u00adgram transformations (/Ger75/, /BuD77/) has been found particularly \nuseful. In that technique the correctness of the basic stack algorithm is estab\u00adlished by conventional \nmeans, and the final algo\u00ad rithm is shown correct by deriving it from the basic algorithm using correctness-preservingjpro\u00adgram \ntransformations. Such derivations of the Schorr Wai te Deutsch algorithm are given in /Der801, fGer79/, \n/Grif79/, /LRG79/, IJOI1801, lJon821 and lBrF 821. An often stated reason for advocating the use of program \ntransformations is that the method gives insight into the working of a complex algo\u00adrithm. It has also \nbeen used for finding connec\u00adtions for whole classes of algorithms (/Dar78/, /LRG79/). We therefore decided \ntO use this method as our tool for annlyzing existing marking algo\u00adrithms and for deriving new ones. \nIt should be emphasized that our use of program transformations differs from most previous experi\u00adments \nin one important aspect: we are interested in finding a new, improved algorithm, not in proving the correctness \nof an existing algorithm. We establish the correctness of the transformation steps mainly to support \nour intuitive idea of how the algorithm works. Such a use of program trans\u00adformations has been realized \nbefore (e.g. /Jon80/), but concrete examples are scarce. The first step in using program transformations \nis to establish the correctness of the basic algo rithm. This can be done in a standard way using invariant \nassertions and termination functions , and will not be de,slt with further here (an outline of the proof \nis given in /Man82/) . In seeking an efficient marking algorithm there are two obvious ways to proceed. \nOne possibility is to try to reduce the space requirements of the Schorr-Waite-Deutsch algorithm, i.e. \nto eliminate the tag-bits. Alternatively, one could hope to find a generalization of the bounded workspace \nalgorithms which presently work only for trees. We started off by deriving the Schorr Waite Deutsch algorithm \nfrom our version of the stack algorithm /Man82/. However, elimination of the tag-bits seemed intractable. \nWe therefore soon turned to the other approach. Of the two bounded workspace algorithms mentioned in \nSection 1, Robson s algorithm /Rob77/ is based on the idea of  storing the stack into those link fields \nthat con\u00ad tain null values. Since cyclic lists and dags may not have enough such fields, the generalization \nof this algorithm does not seem possible. Lindstrom s algorithm /Lin73/, on the other hand, appeared \nmore promising. Indeed, this line of,work proved suc cessful. The derivation of an efficient niarliing \nalgorithm for dags from Lindstrom s algorithm is the main purpose of the remaining sections. We will \nfirst generalize the tree algorithm to cope with arbitrary lists, and then derive an efficient algo\u00ad \nrithm for dags from this generalization. 3. Generalizing Lindstrom s algorithm Lindstrom s ori~inal algorithm \n/Lin73/ is based on the observation that when a tree is traversed, each node is visited exactly three \ntimes: it is entered once from each of its three neighbors (father and two sons). In the Schorr Wai te \nDeutsch algorithm a tag-bit is required to tell which of the two links of a node has been reversed to \npoint to the father. Lindstrom s idea is to eliminate the need for this information by arranging things \nso that the link to be followed can always be found in the same field of the node. When a node is entered \nfor the first time, the left link contains a pointer to the left son of the node, Before the left son \nis entered, Lindstromrs algorithm rotates the contents of three pointer fields: the left link, the right \nlink, and a vari\u00adable pointing to the father of the node. Thus, when cOntrOl returns to the node from \nthe left subtree, the left link can again be followed: it now con\u00adtains a pointer to the right son. Performing \nan\u00ad other rotation puts a pointer to the father into the left link, so that the link can again be fol \nlowed upon return from the right subtree. This scheme is illustrated in Figure 1. The node being visited \nis p, and q is the previously visited node. qo on first visit on second visit Po  PqoA on third visit \nafter third visit This scheme works because of the three-visit property of trees. The rotations will \nrestore the original tree structure, simply because rotating three values three times yields the original \nper mutation. It also works for more general struc tures, e.g. for dags, where each node is visited a \nmultiple of three times . This, however, can cause an exponential time requirement in the worst case. \nFor even more general (cyclic) lists the technique fails: the original list structure is not necessarily \nrestored. The reason why this approach does not work for cyclic lists is that it does not distinguish \nthe backward and forward phases of the stack al gorithm. Thus when the left link points to a marked node, \nwe do not know whether the node be longs to a substructure which we already have accessed (in which case \nit should be avoided) or whether we are backing up to the father (which should be entered). To remedy \nthis situation, we will associate a counter n(p) with each node p and initialize n(p) to O. The counter \nwill be incremented by one each time the links of the node are rotated. The stack in the algorithm MarkingWithStack \nwill then consist of those nodes p for which n(p)=l. A left link pointing to a marked node will not be \nfollowed. Instead, the pointers to the current node and its predecessor are swapped, and the list structure \nis traversed (using rOtations) until the topmost node of the stack, i.e. the first node p with n(p)=l, \nis en countered. We also need an auxiliary header node called virtualroot. With these additions the list \nstruc ture is as follows. type nodeptr = hodewithcounters; nodewithcounters = record data: datatype; \nleft, right:-nodeptr; marked: boolean; n: integer end; var root,virtualroot: nodeptr;  We assume that \ninitially marked(p)=false and n(p)=O fOr each nOde P (including virtualroot) in the list structure. In \naddition, we assume that left(virtualroot)=root. We will use the following two procedures for swapping \nand rotating links. procedure swap(var p,q: nodeptr); var r: nodeptr; ~in r:=p; p:=q; q:=r end; procedure \nrotate(var p,q: nodeptr); var r: nodeptr; begin n(p) :=n(p)+l; r:=p; p:=left(p); left(r):=right(r) ; \n right(r) :=q; q:=r Figure 1. The links at successive visits to a node. *;  The next section shows \nin detail how the implementation of the stack is done. The necessary transformation steps are described \nand justified informally. The basic idea is to use an invariant and a representation function to show \nthe corre\u00adspondence between the abstract data structure (the original list and the stack) and the concrete \ndata structure (the modified list) . This method was proposed by Hoare /Hoa72/ in the framework of ab\u00adstract \ndata types. The situation here is slightly more complicated, as we will perform replacements directly \nin the algorithm, replacing statements by other statements, and we will use a shared rep resentation: \nboth the stack and the original list will be represented by the same list structure. Formal proof rules \nfor handling this kind of rep\u00adresentational abstraction is presented in /Bac80/. In Section 5 we consider \nthe problem of im\u00adplementing the counters efficiently. We will show that for general lists, one bit in \neach node is sufficient. Thus the space requirement of the al gorithm is exactly the same as that of \nthe Schorr\u00adWaite-Deutsch algorithm. The same holds for the asymptotic time requirements too, although \nin practice the Schorr-Waite-Deutsch algorithm seems to be faster /Man82/. In the subsequent sections, \nwe show that if the list is acyclic (i.e. a dag), the counters can be implemented in bounded work\u00adspace, \nyielding our final dag marking algorithms. 4. Implementing the stack Embedding the stack of node pointers \ninto the list structure requires that some links are temporarily assigned new values during the marking \nof the list. Care must therefore be taken to ensure that the original list structure is restored when \nmarking is completed. Let G denote the list structure being manipulated by the marking algorithm (the \ncollection of nodes together with the two pointers root and virtual root) , and let GO denote the list \nstructure as it is before the marking. Thus G=GO must hold after the marking. Besides p, we will need \nanother pointer q to traverse the list structure. The information needed to manipulate the stack is determined \nby G, p and q. The variables are used in the fol\u00adlowing way. First, q will always denote the node previously \nvisited by p. This means that one of p and q will always be the father of the other in GO. The possible \narrangements of p and q are shown in Figure 1, assuming p$nil. The counters n(r) will only take values \nO, 1, 2 or 3. More precisely, let p=<r~, . . ..rk> be the path of nodes in GO from the root to p or q \n(whichever comes first) traversed by the algorithm, so that rl=root and rk is either p or q. Then n(r)=l \nor n(r)=2 if and only if r is on the path P. The nodes ri, i=l,2,. ..,1,l, have their link fields changed \nas shown in Figure 2, We assume that rO=virtualroot, All nodes not in P have their original link values. \nFor any node r, marked(r) is equivalent to n(r)*O. Finally, n(r)=2 !.. any node m if and only if r is \nnot in P but r is reachable in GO either r. 1-1 1-1 r. r. r. 11  r. t @ i+~O 1+10 3 n(ri) =1 n(ri) \n=2 Figure 2. Link fields for nodes in P. from some node r EP, where r =l,~ft(ri) in GO for some ri EP, \nor from q and p is the father Of q in GO (intuitively, r is to the left of P or below q) . Let I denote \nthis collection of requirements. Assuming I, it is always possible to find the predecessor ri_l of a \nnode ri in p: if n(ri)=l, then ri_l=right(ri), otherwise ri-l=left(ri). The stack S represented by G, \np and q is the subse\u00ad quence of P consisting of those nodes ri for which n(ri)=l. The original list is \nalso represented by G, p and q. Let H be the list which is constructed from G by changing the link fields \nof nodes in P as follows: if n(ri)=l, then <left(ri),right(ri)>:z=<ri+l, left(ri)>, if n(ri) =2, then \n <left (]-i) ,right(ri) >:=<right(ri) ,ri+l>, where i=l, . . . ,k, nnd rk+l=p if qCP, otherwise rk+l=q. \nThus H=GO states the requirement that it must be possible to reconstruct the original list. Note that \nif P is empty, i.e. if either p or q is virtualroot, then H=G. In conj unction with H=GO this implies \nthat G=GO. We will now implement the stack manipulation operations of the algorithm MarkingWithStack \nby operations on G, p and q which have the same ef\u00adfect on S aa the original operations on the stack \nvariable s. This must be done in such a way that the invariant I and the requirement H=GO are es\u00adtablished \nat the beginning of the loop in the al gorithm and are preserved by each successive it\u00aderation of the \n10C)P. Actually, the stack oper\u00adations will not be. implemented in isolation, as the operations for moving \np in the list must be taken into account. The first operation to be implemented is the creation of the \nstack. We will replace create(s) ; p:=root by q:=virtualroot; p:=root. We must show that after these \nstatements have been executed, 5 is empty and I and H=GO hold. This follows immediately, as P is empty \nand p=root= left(virtualroot)=left(q) . to The next operation is the push-operation. We n(p)=l. The \neffect of the rotation is set will rep lace n(p) 2 (thus removing p from S, without affecting P) , and \nto advance p to the right son of p in GO. mark(p) ; The preservation of I and H=GO is straightforward \npush(s, p) ; to check. p:=left(p) Performing all the replacements gives us the by following algorithm, \nmark(p) ; procedure MarkingWithRotations; rotate(p,q) . var p,q: nodeptr; begin We may assume that I \nand H=GO hold prior to the q:=virtualroot; rotation, as well as that ShouldVisit(p) holds. We p:=root; \nmust show that I and H=GO are preserved by the ro while true do begin tation, and that S and p are updated \ncorrectly, ~ Shoul~isit (p) then begin  i.e. p is pushed onto S and then advanced to mark(p) ; left(p). \nrotate (p, q) end else * . ShouldVisit(p) holds if and only if p is swap (p, q); neither nil nor marked. \nThe latter means that while TopNotFound(p) do n(p)=O. The rotation will extend P with p and set rotate \n(p, q) ; n(p)=l (pushing p onto the stack) and move p to if p=virtualroot then exit; left(p). The left \nand right links of p, as well as ~tate(p, q) q, are updated so that I and H=GO still hold after end \nthe rotation. end end= Before implementing the remaining stack oper ations, we note that the control \nstructure of the Here algorithm can be changed to the form TopNotFound(p) = p*virtualroot and n(p)*l, \n while true do begin ~ Shoul~isit(p) then begin and Shouldvisit(p) is as before. Note that the . . . \n. algorithm only terminates when p=virtualroot. end else begin This implies that P is empty, so (as discussed \nif isempty(s) then exit above) the original list structure is restored Z_ise p:=top (s); upon termination. \npop(s) ; p:=right(p) end 5. Storing the counters end, In this section we digress from our main theme \nof The inner if-then-else construct is implemented by developing an efficient dag marking algorithm and \nshow how the space requirement of the previous swap(p,q); algorithm can be made the same as that of the \nwhile p+virtualroot and n(p)+l do Schorr-Waite Deutsch algorithm. Note first that . rotate(p,q) ; in \nalgorithm MarkingWithRotations the three-visit if p=virtualroot then exit. property of Lindstrom s algorithm \nfor trees has been maintained: the counter of each reachable When ShouldVisit(p) does not hold, i.e. \np is either node obtains the succession of values 0, 1, 2 and nil or marked, p and q are interchanged \nand the 3. At first, it might seem that this requires two path P is traversed backwards until either \np bits for each counter. However, a moment s re\u00adreaches virtualroot (in which case S is empty) or flection \nwill reveal that actually one bit in a node r with n(r)=l is found (in which case r is each node is sufficient. \nthe top of the stack and p is left pointing to this node) . The facts that I and H=GO are preserved, \nas Inspecting the algorithm MarkingWithRotations, well *S that S is not changed, are easily estab-we \nnote that the counter fields are only accessed lished. within the function call TopNotFound(p) . At that \npoint we have n(p)=l or n(p)=2, as p is an element Finally, the operations of P. It follows immediately \nthat the counter can be implemented using a tag-bit whose initial value pop(s) ; is false. If the incrementation \n! n(p) :=n(p)+l p:=right(p) within TopNotFound is replaced by the statement tag(p): =not tag(p) , the \ntest n(p)*l within are implemented by TopNotFou~can be implemented simply as not tag(p) , without affecting \nthe correctness of the rotate(p,q) . algorithm. Thus we have reached the same size bound as for the Schorr \nWai te-Deutsch algorithm. The rotation is done knowing that p=top(S), so 6. Late marking of dags We \nnow return to the problem of finding a bounded workspace algorithm. This requires the elimination of \nthe counters from the algorithm MarkingWith-Rotations. The key idea is to use the mark bits in the same \nrole where the tag-bits were just used. In the case of cyclic list structures this ap\u00adproach fails: to \nprevent the algorithm from looping, nodes must be marked during the first visit. Thus it is impossible \nto use the mark-bits for storing any other information. For dags, things are different. There is no fear \nof looping: therefore the nodes could as well be marked during the first visit. This is still enough \nto prevent the algorithm from traversing substructures several times. Furthermore, before the mark-bit \nis used for its original purpose, it can be used to help in making decisions without auxiliary tag-bits. \nTherefore our scheme will be to first move marking to the third visit, and then to eliminate the counters \naltogether. Before the place of marking is changed, we must make sure that it does not affect the correct\u00adness \nof the algorithm. There is only one place, the function ShouldVisit, where the value of the mark-bit \nis tested. But, as the invariant I implies the assertion n(r)=O if and only if not marked(r), this function \ncan just as well be written in the form if p=nil then false else n(p)=O,  which gives us a free choice \nof the moment when marking is done. After changing ShouldVisit(p) in this way, we can change the marking \nto immediately precede the third visit. This means changing the invariant I by replacing the assertion \nmarked(r) a n(r)+O, for any node r, by marked(r) -n(r)=3 for any node r. Let us call this modified \ninvariant I . There is only one place in the algorithm MarkingWithRotations where rotate(p,q) is per\u00adformed \non a node p with n(p)=2, namely the inner\u00admost while-loop. Therefore marking can be moved to precede \nthe rotation in that loop. Since each node is visited exactly three times, this change maintains the \ncorrectness of the algori thin. The result is called LateMarking and shown in the next column. It is \neasy to see that the invariant I is again preserved by each iteration of the inner and outer loop. procedure \nIatemarking; var p,q: nodeptr; begin q:=virtualroot; p:=root; while true do begin ~ Sho.l~i~) then \n(*n(p)=O *)  rotate (p, q) else begin swap(p,q); while TopNotFound(p) do begin m~rk(p) ; (*n(p)=2 \n*) rotate(p,q) ; end; if p=virtualroot then exit; (*n(p)=l *) rotate (p, q) end end end.  7. Removing \nthe counters We have isolated the use of the counter n in the algorithm LateMarking into the functions \nTopNot-Found and ShouldVisit. In this section we show that this use of the counters is redundant. Con\u00adsider \nfirst the function TopNotFound. There, we know that p is a node in P, so we only need to distinguish \nbetween the cases n(p)=l and n(p)=2. These cases are illustrated in Figure 3. P  qot c) n(e) =1 n(e) \n=2 Figure 3. Testing TopNotFound. Thus, when n(p)=l, right(p) will be in P (if right(p)+virtualroot) \n, so right(p)*nil and n(right(p))=l or 2,, The latter implies (by I ) that right(p) is not marked. Consider \nnow the case n(p)=2. If right(p) is not nil, then we have n(right(p))=3. This is a consequence of 1 and \nthe acyclicity of GO: right(p) is actually left(p) in GO, is not in the path P, but is the left son of \na node in P . Therefore we have that either right(p)=nil or right(p) is marked. Combining the two cases \nwe get n(p)*l if and only if right(p)=nil or marked (right(p)) , assuming p*virtualroot (to be precise, \nwe also need to note that marked(virtualroot)=false, but as virtualroot is never marked, this hOlds triv\u00ad \nially) . Thus we can define Our algorithm was derived using correctness\u00adpreserving program transformations. \nOur result TopNotFound(p) = shows the usefulness of this technique also in p+virtualroot and the derivation \nof new, previously unknown algo\u00ad(if right (p)=nil then true rithms. Of course, the derivation process \nwas  else marked(r: ght(p)) . (and must be) guided by an intuitive idea of how to gain a more efficient \nsolution. Program trans This leaves ShouldVisit as the on v., ~lace formations did, however, help, both \nin obtaining where the counters are needed. Here we again make this intuition and in making the ideas \nmore con use of the dag property. It is easy to check that crete. before th~ test ShouldVisit(p), q is \nalways the father of p in GO. This means that q is the last node in P. Also, it means that p cannot be \nin P, References because then there would be a cycle in GO from q to p to q, contradicting our assumption \nthat /Bac80/ R.J.R.Back, Correctness Preserving GO is a dag. Thus, using our invariant 1 , we Program \nRefinements: Proof Theory and know that n(p)+l and n(p)*2. Also, we have that Applications. Mathematical \nCenter for any node r, n(r)=3 if and only if marked(r). Tracts 131, Mathematical Center, Combining these \narguments we get Amsterdam, 1980. /BaF77/ J.-L.Baer and M.Fries, On the efficiency n(p)=O if and only \nif not marked(p) of some list marking algorithms. In: Information Processing 77, Proceedingsin the call \nShouldVisit(p). Thus we can simply of IFIP Congress 77, B.Gilchrist (cd.), resort to our previous version \nof ShouldVisit(p): North Holland Publ. Co., Amsterdam -New York -Oxford, 1977, 751-756. ShouldVisit(p) \n= if p=nil then false else not marked(p). /BrP82/ M.Broy and P.Pepper, Combining algebraic  and algorithmic \nreasoning: an approach This gives us the desired bounded workspace algo to the Schorr-Waite algorithm. \nACM rithm for dags: the counters have been entirely Transactions on Programming Languages eliminated. \nand Systems 4, 3 (July 1982), 362-381. fBuD77j R.M.Burstall and J.Darlington, A trans-The algorithm can \nbe further shortened by formation system for developing recur\u00admerging the two nested loops. Such transform\u00adsive \nprograms. J. ACM 24, 1 (Jan. 1977), ations do not improve the asymptotic efficiency 44-67. of the algorithm, \nthey just make it shorter. Therefore we will here skip the details and just lDar78/ J.Darlington, A synthesis \nof several. show one possible version of the algorithm. Nodes sorting algorithms. Acts Informatica are \nhere declared as in the first section, i.e. 11, 1 (1978), 1-30. without counters or tag-bits. /Der80/ \nN.Dershowitz, The Schorr Waite marking algorithm revisited. Information Process\u00ad procedure DagMarking; \ning Letters 11,3 (Nov. 1980), 141-143. var p,q: nodeptr; begin /Ger75/ S.L.Gerhart, Correctness-preserving \nq:=virtualroot; program transformations. In: Conf. p:=root; Record of the Second ACM Symposium on if \np*nil then Principles of Programming Languages, repeat Jan. 1975, 54-66. rotate(p,q) ; /Grie79/ D.Gries, \nThe Schorr-Waite graph markingif not ShouldVisit(p) then swap(p,q); algorithm. Acts Informatica 11, 3 \n= ~uldMark(p ,q) then mark(p) (1979), 223-232. untfi p=virtualroot end. lGrif791 M.Griffiths, Development \nof the Schorr\u00ad  Waite algorithm. In: Program Construc Here ShouldVisit is specified as above, and tion, \nF. L. Bauer and M. Broy (eds. ) , ShouldMark denotes the following function. Springer-Verlag, Berlin \n Heidelberg - New York, 1979, 464-471. ShouldMark(p,q) = /Hoa72/ C.A.R.Hoare, Proof of correctness of \nTopNotFound(p) and data representation. Acts Informatica 1, (if q=nil then~e else marked(q)). 4 (1972), \n271-281. /Jon80/ H.B.M.Jonkers, Deriving algorithms by 8. Conclusions adding and removing variable s.. \nReport IW 134/80, Department of Computer We have studied the problem of marking list struc Science, \nMathematical Center, Amsterdam, tures . A bounded workspace algorithm for dags was April 1980. given. \nThis improves the best previously known bounded workspace algorithms, which only are applicable to trees. \n /Jon82/ /Knu67/ /Kow79/ /LRG791 /Lin731 /Lin741 /Man 821 /Rob77/ /deR77/ /scw67/ /Sta80/ /ToP7g/ /~eg72/ \n/Yed771 H.B.M.Jonkers, Abstraction, specification and implementation techniques with an application \nto garbage collection. Ph.D. Thesis, Department of Computer Science, Mathematical Center, Amsterdam, \nFeb. 1982. D.E.Knuth, The Art of Computer Program\u00adming, Vol. 1: Fundamental Algorithms. Addison Wesley \nPubl. Co., Reading, Mass., 1967. T.Kowaltowski, Data structures and cor\u00adrectness of programs. J. ACM \n26, 2 (April 1979) , 283-301. S.Lee, W.P.deRoever and S.L.Gerhart, The evolution of list-copying algorithms \nand the need for structured program verifi cation. [n: COnf. Record of the Sixth Annual ACM Symposium \non Principles of Programming Languages, Jan. 1979, 53 67. G.Lindstrom, Scanning list structures without \nstacks or tag bits. Information Processing Letters 2 (1973), 47-51, G.Lindstrom, Copying list structures \nusing bounded workspace. Comm. ACM 17, 4 (April 1974) , 198-202. H.Mannila, On list marking algorithms. \nIn Finnish. Report C-1982-92, Department of Computer Science, University of Hel\u00adsinki, October 1982. \n J.M.Robson, A bounded storage algorithm for copying cyclic structures. Comm. ACM 20, 6 (June 1977), \n431-433. W.P.deRoever, On backtracking and greatest fixpoints. In: Automata, Lan\u00adguages and Programming, \nFourth Col loquium, A. Salomaa and M. Steinby (eds. ) , Springer-Verlag, Berlin -Heidelberg New York, \n1977, 412-429. H.Schorr and W.M.Waite, An efficient machine-independent procedure for gar\u00adbage collection \nin various list struc tures. Comm. ACM 10, 8 (Aug. 1967), 501-506. T.A.Standish, Data Structure Techniques. \nAddison-Wesley Publ. Co., Reading, Mass., 1980. R.W.Topor, The correctness of the Schorr-Waite list \nmarking algorithm. Acts Informatica 11, 3 (1979), 211-221. B.Wegbreit, A space-efficient list structure \ntracing algorithm. IEEE Transactions on Computers C-21, 9 (Sept. 1972) , 1009-1010. L.Yelowitz and A.G.Duncan, \nAbstractions, instantiations, and proofs of marking algorithms. In: Proc. of the Symposium on Artificial \nIntelligence and Program\u00adming Languages, SIGPLAN Notices 12, 8 (Aug. 1977) , 13-21.  \n\t\t\t", "proc_id": "567067", "abstract": "The best known linear-time list marking algorithms also require a linear amount of workspace. Algorithms working in bounded workspace have been obtained only by allowing quadratic execution time or by restricting the list structures to trees. We improve on this here by deriving a new linear-time, bounded workspace marking algorithm that works for dags. The algorithm is derived using correctness-preserving program transformations, which prove the correctness of the algorithm. Our derivation of the marking algorithm provides an example where this method has actually been used to derive a new, more efficient algorithm, rather than just to establish the correctness of a previously known algorithm.", "authors": [{"name": "R. J. R. Back", "author_profile_id": "81542450756", "affiliation": "University of Helsinki, Tukholmankatu 2, SF-00250 Helsinki 25, Finland", "person_id": "PP94029624", "email_address": "", "orcid_id": ""}, {"name": "Heikki Mannila", "author_profile_id": "81100086722", "affiliation": "University of Helsinki, Tukholmankatu 2, SF-00250 Helsinki 25, Finland", "person_id": "P108656", "email_address": "", "orcid_id": ""}, {"name": "Kari-Jouko R&#228;ih&#228;", "author_profile_id": "81100052864", "affiliation": "University of Helsinki, Tukholmankatu 2, SF-00250 Helsinki 25, Finland", "person_id": "P157036", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567067.567071", "year": "1983", "article_id": "567071", "conference": "POPL", "title": "Derivation of efficient DAG marking algorithms", "url": "http://dl.acm.org/citation.cfm?id=567071"}