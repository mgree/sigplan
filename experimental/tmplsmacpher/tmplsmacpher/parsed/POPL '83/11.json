{"article_publication_date": "01-24-1983", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1983 ACM 0-89791-090-7 $5.00 fiflnifion 1.3 A defining equation is said to be simpLe if the symbol occurring \nin the leftmost position has no other occurrence on the left side of the equation. Definition 1.4: A \nset of defining equations is non circuLar if the relation precedes is a partial order. It is we lL-termed \nif it is non-circular, and if every equation is simple. In order to define a concept of consistency of \na set of equations, it is necessary to specify some subset of terms that are required to remain dis\u00adtinct \nin the equational theory (the pair of atomic terms true and false is a popular choice). We choose the \nentire subalgebra generated by Gen. Definition 1. Z A set of defining equations, E, is consi.sfenf if \neach element of the equivalence class defined by E contains at most one member of the subalgebra Gen. \n* A sufficient condition for consistency is that the argument sequences of the applications on the left \nsides of the defining equations for any given symbol f represent disjoint sets (of sequences) of canonical \nterms. This condition may or may not be decidable, but at least it is well defined, In case the argument \nexpressions of left-side applications are further constrained to consist only of terms from Gen (~), \n(the freely-generated Gen -algebra with variables ~), then consistency is manifestly decidable. This \nconstraint is formalized in the following, Definition 1.6 Let Gbn be a set of generators; a set of defining \nequations is said to be based upon Gen if in each left-hand side term, every symbol occurring is either \na variable letter, an element of Gen, or the symbol being defined. * With constraints upon defining equations, \nand with multi-sorted function symbols, it is pos\u00adsible to give a semantics to equational specifications \nby use of the theory of partially additive monoids [ArM82]. A semantics based upon domains is unnecessary \nbecause the con\u00adstrained equations involving sort-specific terms do not support the definition of functions \nthat may exist only in reflexive domains. Some advantages of partially additive monoids (p. a. m,) over \ndomains are that the theory is much simpler, and that the treatment of equational definitions is more \nnatural in this theory. 2. A semantics for equational specifications A partiuUy additive monoid is an \nalgebra [A, Z], where A is a set of countable sequences, and Z is a partial operation subject to the \nfollowing axioms [ArM82]: PartMm-omociati vity, If A is indexed by the countable set 1, and if rr is \na partion of 1, then for each family (~ : icf) contained in A, (%?npucfness. If (~ : iE1) is a countable \nfamily in A and if ~(~ : -iEF) is defined for every finite subsequence F of 1 then ~(~ : i E1) is defined \nin A. lhzary sum. If a is a one-element family, then ~a=a inA. From algebras in this class, it is possible \nto construct solutions to a broad class of recursion equations. Furthermore, a solution so con\u00adstructed \nis unique, and under interpretations of the equations that coincide with c.p. o. 1s, the solution gotten \nby construction in the p. a.m. coincides with the least fixpoint constructed in the c.p. o. [ArM82]. \n2.1. A quotient algebra which is final Many of the difficulties seemingly inherent in the use of an equational \ntheory as a specification language can be avoided by restricting the defining equations to a well-formed, \ngenerator\u00adbased set, There is then a useful way to restrict the equations to ensure consistency, and \nthereby to ensure the existence of non-trivial models. In fact, there is a term algebra whose quotient \nis a model for the equations, is final, and is comput\u00adable. Let SigO c Sig and let Geno be the Sig O\u00adalgebra] \nof terms generated by the elements of S@O (the generators), and let T% be the S\u00adsorted word algebra generated \nby the elements of Sig. TW is initial in the class of Stg -algebras. We shall extend the notion of a \np. a. m. to that of a S@ -p.a.m. by defining a summation operator to correspond to each of the primitive \nsorts; the domain of X. is the set of sequences of sort s from T~W. Let E( T% (X) ) be a consistent set \nof well\u00adformed defining equations based on GenO, and such that t ~ E tz only if t ~and i!zhave the same \nsort. For the sake of simplicity, assume that E is a set of defining equations for a single function \nsymbol f Of SOrt S1... Sn, S. A partial order imp ose d upon dependent function symbols justifies separate \nconsideration of the definition of each function symbol. For a well-formed, generator-based set of defining \nequations E, consistency can be assured if, for et, ej EE, Umify(hs( ei), h(ej)) = 1 fori #j where Unify \n(z, y ) is the most general unifier of terms z and y [Rob65]. Dej?nition 2.1: Let W s T%, where W is \nan r.e. set, and let Pi! (t) = (~e@ ~ify(t,h( e))(rh.s( e)) E W be a predicate over T~@. 9 This predicate \nselects those terms equated to an element of W in the theory generated by E. p! is partial recursive. \nSince the set of equations, E, is finitely presented and the left-side terms of %roughout the paper, \nwe shall use Sig, rather than the more familiar Z, to denote a signature. This substitute notation has \nbeen adopted to avoid confusion with the use .of Z to denote an additive operator over sequences. distinct \nequations are not unifiable, it is decid\u00adable whether or not there is some member of E whose left-hand \nside unifies with a given ground term t. If there is not, then p~ is false of t; if there is, then the \nunifier applied to the right side of the same equation produces a ground term. Since W is an r.e. set, \nit is semi-decidable whether this ground term belongs to W . Definition 2.2 Let p be a partial recursive \npredi\u00ad cate over A. Then E: is defined by Z: is the disjoint union of sets, each of whose members satisfies \nthe predicate p. Itis easily seen to satisfy both the axioms of partition\u00adassociativity and of compactness. \nThis operator satisfies the first two axioms of a p. a.m.; it lacks the unary sum axiom, instead satisfying \nthe fol\u00adlowing, Recursively enumerable basis axiom: If [t/ is a singleton set, Z: {t } is defined, and \nis equal to [t] ifp(t), and @ otherwise. This axiom provides an r. e. basis for the genera\u00ad tion of a \np.a. m. as does the unary sum axiom, but the basis provided by the r. e. basis axiom might be empty. \nIn order that an algebra pro\u00advides a model for a set of defining equations it must have a nonempty basis. \nIn fact, we want to be assured of more than just the fact that a model exists; there always exists a \ntrivial model which is a S @ -algebra, in which all constants of each sort are equated. The basis introduced \nhere is a Sig -algebra whose elements are not (camot be) equated by the defining equations. By constructing \na model for E from this basis, non-triviality is assured. In particular, let Gen c 7 Sti be a nonem@y \nr.e. set, and let uan(~)=Pi (~) ort=~n PE The existence of an interesting model for the defining equations \nE is then assured by the fol\u00adlowing, where E~wE denotes the sum operator in W GWZ which the predicate \nis PE Theorem 2.1: (Fixpoint Theorem) If E is a well-formed, consistent set of defining equations based \non a nonempty set &#38;n, the r.e. set satisfying WE = &#38;(a@I) is uniquely defined. Furthermore, if \nthe basis set Cen is computable, then so is WE. Proof (sketch): Let W be any r.e. set W C TSti. The following \nsum is defined and is unique: ~~(a@I)= X!C2!(% ~Vv(%@(ej)) #1) : ej~ E) Uniqueness is established by \nthe consistency of E; existence by the partition-associativity and compactness axioms, with a basis provided \nby the r.e. basis axiom, noting that the set Gen is nonempt y. Furthermore, the set of terms defied can \nbe enumerated by diagonal enumeration across elements of the argument sequence, ~, and of the set W in \nwhich E-Equivalence of terms is sought. The order in which elements of W are selected can be chosen arbitrarily. \nHowever, in case we wish actually to compute WE, the chosen order should be that in which defined terms \nare actually produced by expanding the definition of the fixpoint expres\u00adsion, Since the sum is an r.e. \nset, it satisfies the hypotheses under which the properties of X~wE as a p.a.m. were established. (.%rolla~ \n2.1: he quotient algebra WE/ E is the final data type satisfying the equational theory E, and hence is \nthe abstract data type specified by E.= Given a set of generating functions @n and a set of defining \nequations Ef for a function syrr\u00adbol f, the Fixpoint Theorem tells us that Ef defines a unique set of \napplicative expressions, containing all of the defined applications of f to defined arguments. The construction \nof a set of defined terms extends to multiple function symbols as well. Consider a set of defining equations \nE for the function symbols f ~,... f ~, which are ordered by the precedes relation induced by E. The \ngenera\u00ad tors for WE,, are the members of Gene; the gen\u00ad erating set for WEJ8 is @no U WE,,, etc. 2.2. \nAn example: Natural numbers with prede\u00adcessor As the simplest of examples, let us consider the natural \nnumbers (with zero). Following the notation of [ADJ 77], the generators of this alge\u00adbra are: Sigk, jfd \n= [zero} sig~~,~a~ = [WCC j Taken by itself, this algebra is not interesti~. Interesting algebras are \nformed by the addition of dependent operators, and by giving a theory for the enlarged set of terms. \nFor instance, the signature of sort Nat, Nat, can be augmented to: SigN&#38;, Nat = [SUCC,pred] and its \ntheory induced by the single equation pred(succ(z)) = z (1) Unfortunately, this simple expedient doesn \nt do exactly what we want. Letting the variable in (1) take values from the terms generated by Z, the \nfreely generated set of terms now includes not only zero, succ (zero), succ (succ (zero )), but also \npred(ze7-o), pred(succ (zero)) = zero, succ(pred(zero)), Had we been trying to construct a theory which \nadmitted only the standard model of natural numbers with successor and predecessor fwnc\u00adtions, any term \nthat contained pred(ze~o ) as a subterm (or was equivalent to such a term) would be inadmissible. One \ntechnique that has been suggested to cope with this problem is to complete the theory with a naive theory \nof error [Gut 7 7]. The theory as given above is obviously deficient in that it fails to specify an equivalence \nfor the term pred (zero). The suggestion is that such undesired terms be equated to a distinguished error \nelement. pred(zero ) = error The difficulty with this measure as a solution is that error is simply a \nnew symbol, added to the theory without specifying its signature. If it were included as a member of \nthe signature Sigjvat, then it would also be necessary to add two more equations to the theory, suc c \n(error) = error preo! (error) = error It seems preferable not to consider error as a term representing \na natural number, but to be more discriminating than is possible by using sorts alone. Thus, I propose \na theory of data types, con\u00adsistent with the sorts of the underlying many\u00adsorted initial algebras, but \nextending the form of arities which index function signatures to type signatures including the form T \n+ S, where the symbol + may be pronounced as or . One set of type signatures that might be given to the \nfunctions of a theory of natural numbers is: 7@e (ze7-o ) = z Type(succ) = 2+s-s Type (pred) = s~z+s \nType signatures are intended to distinguish cer\u00adtain terms of a word algebra as non-sensible, and others \nas (possibly) sensible. For instance, a term of the form pred(zero ) can be found to be non-sensible \nby applying the type signatures given above, according to the rule of application to be given in the \nfollowing section. Also non\u00adsensible is any term which contains pred (zero ) as a subterm, since this \nsubterm is non-sensible. Type signatures, unlike sorts, cannot simply be assigned to operator symbols, \nsince a type theory will not be useful unless it is consistent with the set of defining equations that \nspecify an abstract data type. When type signatures are assigned to the function symbols, equation (1) \nmay be considered to be typed, by analogy to the use of typed sentences in a programming language. That \nis, the equality is sensible only if the types of its right-and left-hand sides agree. 3. Precise typing \nAs seen from the preceding example, typing the new operators defined by an equational theory on &#38; \nunderlying, freely -genera~ed word algebra sometimes provides a means for discrim\u00adination between sensible \nand non-sensible appli\u00adcations of these operators. An immediate benefit of typing is that when it works, \nit will determine whether or not the equations that constitute a theory are themselves sensible. It is \nimportant to formalize the notion of-typing, to determine exactly its capabilities, and its inherent \nlimitations. 3.1. Types hfinition 3.1: A twing is a homomorphism r: Ts@+A where A is a Ceno-algebra with \na decidable equivalence problem. The word decidable is of the essence in this definition. Typing is \nuseful only if questions of type correctness can be decided by static analysis, Otherwise, we may as \nwell call any other computable property of a program or specification a typing< . &#38;finifion 3. L? \nA typing T is shkt if the target algebra contains a distinguished element, bad in each sort, such that \nevery operator is strict in bad i.e. if 06 Sig~l~n,~ then o(tl,,,,tk_l,h~, tk+l,...= tn)bad fifinition \n3.3 A typing is E-compatible if T is an E-homomorphism and t = WE + T(~) #bad ~ Note that an E-compatible \ntyping may allow some undefined terms to be typed other than as bad Definition 3.4 An E-compatible, strict \ntyping is precise if tsWE e ~(t)#bad~ Definition 3.5 A strict typing is semi-E\u00ad compatible if t~~f > \nT(t) -c T(t)) or )= bad or T(f _r(t)=bad* A semi-E-compatible typing may be overly res\u00ad trictive; some \nwell-defined terms may be typed as bad, Definition 3.6 If T1 and r2 are both E-compatible typings, they \nare related by an approximation ordering (a partial order) T1<T~iff(~t) (T1(t)= bad +Tz(t)= bad). Some \nobservations. If T is precise, and T is any E-compatible typing, then T ST. If a l.u. b. for the class \nof all E-compatible typings exists, then it is a precise typing. The typing that assigns the correct \nsort s in S to each term in T~q is a g.l, b, for the E-compatible typings. This typing always exists \nand is (trivially) computable, Theorem 3,1: There exists a precise typing for E iff E has a decidable \ntheory. Proof ===> Let T : T*+ C be a precise typing for E, For any term t E T5W, if T(t) #bad then tc \nW~. Thus, there is a finite reduction of each term to a canonical term which is E-equivalent. Equivalence \nof terms modulo-E is determined by equality of reduced, canonical terms. <=== Suppose E has a decidable \ntheory, E&#38;no. LetA be the (unique) S@ -algebra whose carrier is S, the set of primitive sorts. If \nt is an arbi\u00adtrarily chosen term of Ts , and belongs to GenO, then it is a member of fi~ by definition \nand is typed by its sort. Otherwise, it is decidable whether or not there is some member of E such that. \nt unifies with its left side (since E is finitely presented). If there is such a unification, then it \nis decidable in the theory E&#38;no whether or not t is equivalent to a term of Geno (in fact, this term \nis computable). Since Geno is a Sig -algebra, the term in Geno equivalent to t provides a sort in S for \nt.If there is no such unification, then t can\u00adnot belong to WE and is typed as bad, 3.2. Construction \nof type signatures In this formalization, types are the elements of a carrier for a specific semantic \nalgebra, which is a model for an abstract data type specification. Types are formed as follows. Let S \nbe a (countable) set of primitive sorts. Let the algebra [S , +] be the free semigroup generated by finite \nstrings of symbols from S, together with the right-associative, binary operator -I . (Intuitively, a \nstring of sorts is interpreted as the cartesian product of the sets represented by individual sorts, \nand right arrow is interpreted as functional mapping. ) Next, we extend this alge\u00adbra by introducing \nan additive operator whose intuitive interpretation is alternation, or copro\u00adduct construction on sets. \nLet A be the set of all subsets of S , and X. be the operation of disjoint union on A. The algebra [A, \nXo] is a partially additive monoid. Furthermore, by extending the definition of + to A in the obvious \nway, Ai+Aj = [%+aj I ~c&#38; andaj EAj~ we obtain a distributive law, Zo% + ZoAj = Zo(~+Aj) and [A, 2., \n+] is a partially additive semiring. The significance of this extension is that it allows the use of \nvariables to stand for sets of sequences. Furthermore, these variables can be incorporated into sequences \nthemselves, using the extended + operator. Elements of the term algebra described above constitute the \ncarrier set for an algebra of types in which type signatures for all terms of a set of defining equations \ncan be computed. We shall demonstrate how this type algebra is made into a Sig -algebra which satisfies \nE, and is thus a semantic interpretation for E. Of course, it is usually only an approximation to the \nfinal alge\u00adbra WE/ E. The paradigm for typing an equa\u00adtional theory is as follows. With each function \nsymbol f E Sig, associate a function jA whose properties are determined by the type-signature of f. The \ndefinition of any such function is obtained from its type-signature by use of the function t~e~pply2. \nThe S@ -algebra of types is given by a homomorphism hA : T% +A u [bad]. Each con\u00ad stant symbol is mapped \nto its type, cA=~e* (c) where the function ~eA will be defined shortly. Each function symbol f is mapped \nto the func\u00ad tion whose (partial) definition is f ~ = twe-pply( ~eA (f )) where type~pply computes the \ntype signature of an applicative expression from the (partial) type signature of the function symbol \noccurring in the left position of the application, and the type sig\u00ad nature of its argument expression \ntie4@y : (AXA)+A . (?~i+Pil ;7j) * (C(;jlPt) if C(~J)+# t and is undefined otherwise where C(i,j )=[i,~ \nI ~i=~j ] @e_apply is a partial function, and a type expression for which C(i ,,j ) = @ has no value \nin A. When an application of f ~ is not defined by the partiaf function type_apply, its value is defied \nto be bad Each function fA is also defined to be strict in bad. The function 7@e4 : S@ + A maps operator \nsymbols into their type signatures. There is some latitude possible in choosing the types of generator \nsymbols; exercise of this latitude determines the precision of the resultant typing. Beginning with the \nrestriction to constant sym\u00adbols, ??@eA : Gen~Ol * SA can be chosen arbi\u00adtrarily, although a 1-1 mapping \nmay be required for precise ty ing. On n-place function symbols, Y ~eA : &#38;?n~n + Atnl where the elements \nof A(n) are type signatures of the form :  p i,=%-n+l and (I...% range over the set which indexes SA. \nThe target type, ~ +I=SA, may be chosen independently for each term of the sum. The specification of \nType4 must of course be finitely presentable. It should now be evident that the type of every term from \nthe generator algebra Tano, when expressed in the Cen O-algebra hA ( T@nO) reduces to an atomic type, \nwhich is the image under hA of a constant symbol, In the example of the abstract type Nat, ~eA can be \ndefined so as to distinguish terms that are zero from e The fwe~~on fWe3mLY gene rdize$ the emventkm \nemployed in [Mi17t3] to reduce the type signatures of appli\u00adcative expressions. terms constructed by \none or more applications ofsucc, Let s~=[z, s] ~e~(zero ) = z PypeA(succ ) = z+s +s Then, for example, \nhA(succ (zero)) = t~e-appl~ ( TypeA(succ ))( TypeA (zero )) = t~eapp~y(z+s+s)(z) However, the intent \nof this exercise is to type each dependent operator which is defined by a set of defining equations. \nToward this pur\u00adpose, the function hA is extended to equations over terms from T,sw (X) and which satisfy \nthe restrictions imposed upon well-formed defining equations: hA(f tl(Z) = t~(~)) &#38;~ ~<h;an,)h~(tl(q)) \n+ h~(t,(q)) Finally, the type of a dependent function symbol is defined as ~pe~(j) ~~ Y( Z h~(ej)) ej \n=% where El is the set of defing equations for f Existence of the fixpoint is guaranteed by the construction \nof the type algebra as partially additive monoid. It is not difficult to prove the following: Theorem \n3.2 If E is a well-formed, consistent set of defining equations, then the type algebra induced by ~peA(E) \nsatisfies E. ~ Turning our attention next to the question of what constitutes a well-typed term, Definition \n3. Z Let r be a typing constructed as an E-compatible S@ -homomorphism. The we of a term tET~M (X) relative \nto T is the value of T(t), if it is defined, Otherwise t is said to be badly-t~ed by T. A well-formed \nequation e has the type which is the value of T(rhs(e )) if it is defined; otherwise e is badly-typed. \n~ Note that the argument expressions occurring in the left-side term of a well-formed defining equa\u00ad \ntion are always well-typed because they are con\u00ad strained to be canonical terms of Ts~ (X). Returning \nthe example of the abstract data type Nat, a type can now be computed for the dependent operator pred, \nby typing its defining equation (1). TypeA @red) = ~~h.A@7 &#38; d(SUCC (Z)) = Z) = ==;,~lh~(succ (Z))+ \nhA(Z7) = ~ (~weapply(z+s -s)(2)) +2, (~ype~pfiy(z+s+ s)(s))+s =~s+z, s+s =S-+z+s The definition of pre \ndA is summarized by the table below: pre dA Z bad Sz+s In the type algebra, the term pred(zero ), which \nhas no definition by E, is easily found to be typed as bad by applying-the definitions of pred~ and zeroz. \nAs the typing is not precise, there are other terms, such as pred(pred (SUCC (zero ))) which also have \nno definitions according to E, but which are found to be well-typed. However, the typing given above \nis more nearly precise than is the trivial typing in which SA =fNut ] Type~, (zero) = Nat ~ex (SUCC ) \n= Nat +Nat In the trivial typing, every term of T~Q is well\u00ad typed with type Nat, whereas in the previously \ngiven typing, terms such as pred (zero) were found to be badly-typed. To obtain a precise typing for \nNat, we can let SA, be the set of strings s * z over alphabet [z ,s } and let ~pe~tl (zero) = z ~pe~( \n(s-ucc ) = ~ t +st tcsfl Solving (1) for TypeA, (y-red) then gives p?WdA,t Z bad st t for all t CS~l} \nThis trick, of making the type algebra be iso\u00admorphic to the semantic algebra, is only possible when \nE has a decidable equivalence, for other\u00adwise there is no assurance that well-typing of terms is decidable. \nWhen an equational theory is not known to be decidable, a. decidable type alge\u00adbra can always be gotten \nby restricting its car\u00adrier, SA, to be a finite set. 3.3. Approximate typings It is interesting to know \nhow to obtain a hierarchy of typings for an equational theory. The following theorem, while by no means \nthe sharpest result possible, illustrates one way to obtain such a hierarchy. Thzorem 3.3: If A and A \nare type algebras and if the following three conditions hold: i) s~ c s# ii) (Vt=Cen~OJ) Wefl(t) = 7kpeA(t) \n(constants are typed the same in both typ\u00ad ings) iii) (Vt=CenO)(VzGSA) (hA(t)=z * hA( t)=z) (terms typed \nin SA by h~, are similarly typed by h* ) the nh~ <hA. -Proof of the theorem proceeds by structural induction \non terms. It relies upon the fact that more detailed type valuation may enable discrimination of cases \nin which the vatues of two different applications of a dependent function are defined by separate equations, \nor may separate a defined application from one that is undefined. 3.4. Polymorphism One of the principal \nmotivations for the theory of types developed in [Mil i 8] was the need to handle polymorphism; that \nis, to give types to operators that may legatly be applied to argu\u00adments of several distinct types. In \nthe theory presented here, polymorphism would be mani\u00adfested by operators which could legally be applied \nto arguments of several different sorts. SorLs play the role of second-order types. Polymorphic types \nare obtained by introducing sort signatures in which there occur variable letters whose bindings range \nover sorts. Milner s theory of polymorphism, when applied to sort signatures, integrates with the theory \ngiven in the present paper to provide a second-order theory of types. In applying this second-order type \ntheory to a system of defining equations, only the genera\u00adtor functions of an abstract type, those belong\u00ading \nto the signature Stgo, are initially assigned sorts. The sorts of all dependent functions are computed \nin an algebra of sorts, using sort appli\u00adcation (the + function as defined in [Mi178]) as the interpretation \nof function application. From the resulting congruence classes induced by the equational theory interpreted \nover the sort algebra, a sort signature is associated with each expression in each equation. In particular, \na sort signature is associated with each element of Def , the set of function symbols defined by the \nequations. The sort algebra does not include the alternation operator + ; conflicts of sort signa\u00adtures \nthat are not resolvable by unification are nat allowed. The second-order type theory allows one to start \nfrom a basis of generating functions for an abstract data type, and arrive at a multi-sorted Sig -algebra \nwhich also includes the defined operators of the type. After all operators defined by equations have \nbeen assigned to sort signa\u00adtures, the first-order theory of types, that pro\u00adposed in this paper, can \nbe applied to the system of defining equations to obtain more precise typ\u00ading. The first-and second-order \ntype theories for systems of equations have been implemented, and produce the expected results, A benefit \nof the second-order theory is that it allows the types of specific instances of higher-order func\u00adtions \nto be inferred, 4. summary and conclusions This paper presents a reasonably self\u00adcontained theory of \ndata types, developed as an approximate semantics for an equational theory, and motivated by abstract \ndata type specifications. The development has been based upon simple algebraic notions; in particular \nupon the theory of partially-additive monoids. The notion of types presented here is much less expressive \nthan that recently developed by MacQueen and Sethi [MQS82] in which types can fully characterize the \ndomains of all expressions in an applicative notation. On the other hand, types in the present theory \nare computable and constructive, and therefore have decidable equivalence, In the theory of [MQS82] it \nis difficult to think of any interesting properties which are decidable. There are two aspects of the \nwork that found interesting from a theoretical point of view; one is that it further clarifies the problem \nof assuring the existence of a satisfactory model for a system of equational specifications. In this \nrespect, the theory of partiatly-additive monoids seems to provide just the right tool. The other aspect \nof interest is the construction of a family of computable type algebras with decidable equivalence, and \nwhich uniformly approximates an exact semantics for an equational theory in which eqkvalence may not \nbe decidable. Undoubtedly the kind of construction given here can be adapted to other notions of static \nseman\u00adtic approximations. Further work needs to be done on the condi\u00adtions necessary to ensure the consistency \nof a set of equations. The syntactic constraints given in this paper are sufficient to guarantee, that \nthe consistency of a set of equations is decidable; these constraints are not, in general, necessary. \nAs matters now stand, interpreted operators such as if-then-else have not been allowed in specifications. \nThere is no essential difficulty in the theory of typing if such an operator is allowed in the expressions \non the right sides of equations, but not allowed on the left side. The reason this distinction (between \nconditional expressions and conditional equations) is needed, is that in a type algebra, a Boolean\u00adsorted \nfunction does not necessarily partition the domain on which it is defined. Take, for instance, the predicate \ne qnum ~sigN~~, ~~ Bool which is defined by the four equations eqnum (zero , zero ) = true eqnum (ze~o, \nsucc (y)) = fake , eqnum (SUCC (z), zero ) = false eqm.un(succ (z), succ (y)) = eqnum. (z, y) If this \nfunction is typed on the primitive sorts S = jiVunz, Boolj with basis elements Smm = [z, s ], SB..1 = \n\\tt, f f ], it acquires the type (Z, z)+tt, (Z, s)+ff, (S, z)-$f, (s, s)+tt+ff Notice that the last element \nof this type signa\u00adture is ambiguous, and would not give a reflexive law under the interpretation of \nthe elements of as truth values. Thus in the limited sBool domain of the type algebra, eqnum is not an \nequivalence relation. In fact, it cannot even be interpreted as a predicate, in spite of the fact that \nit is correctly aromatized for such an interpretation over the free semigroup gen\u00aderated by [zero, wcc \n]. If a conditional term, which might contain an application of eqnum as a subterm, were allowed on the \nleft side of an equation, then it might no longer be decidable whether or not a set of equa\u00adtions was \nconsistent. If on the other hand, a con\u00additional term occurs on the right side of an equa\u00adtion, then \nthe only consequence of the fact that a function such as eqnum does not behave as a predicate in the \ntype algebra is that the typing may be imprecise. A number of people have come to the conclu\u00adsion that \ndata typing is at least as important in specification languages as it is in machine\u00ad executable programming \nlanguages, for the rea\u00adson that the machine is not available to help the user discover errors. The practical \nimportance of this paper is that it illustrates the feasibility of extendi~ the non-declarative data \ntyping first promoted by Milner for use with languages other than the simple applicative languages such \nas the example in [Mili 8]. Furthermore, the present paper shows that specific conditions for type-correctness \nneed not be explicitly embed\u00added in the semantic definition of a language; the y just fall out of the \ntheory. References [Al M82] Arbib, M.A. and Manes, E. G., The pattern-of\u00adcalls expansion is the canonical \ntimoint for recursive definitions, J.A. C,H. 29, pp. 5? 7 \u00ad602, 1982. [ADJ73] Goguen, J. A., Thatcher, \nJ. W., Wagner, E.G. and Wright, J. B., A junction between computer science and category theory: I, Basic \ndefinitions and examples, Part I, IBM Research Report RC 4526, 1973. [ADJ 76] Goguen, J. A., Thatcher, \nJ. W., Wagner, E.G. and Wright, J B., A junction between computer science and category theory I, Basic \ndefinitions and examples, Part 11, IBM Research Report RC 5908, 1976. [ADJ77] Goguen, J. A., Thatcher, \nJ. W., Wagner, E.G. and Wright, J. B., Initial algebra semantics and continuous algebras, J.A CM. 24, \npp. 68-95, 1977. [ADJ78] Goguen, J. A., Thatcher, J.W. and Wagner, E. G., An initial algebra approach \nto the specification, correctness and implementa\u00adtion of abstract data types, in Yeh, R.T. (cd.) Current \nTrends in programming Methodol\u00ad ogy, VOL. Iv Data st~ctufing, prentice-HaL New York, pp. 80-149, 1978 \n[Guti 7] Guttag, J. V., Abstract data types and the development of data structures, C.A. C.M. 20, PP. \n396-404, June, 19?7, [MQS8Z] MacQueen, D B. and Sethi, R., A semantic model for the types of applicative \nlanguages, F+oc. of 1982 ACM Sympos. on LISP and Functional programming, 243-252, Aug., 1982. [Mi176] \nMilner, R., A theory of type polymorphism in programming, J. C S. S 1 7, pp 348-37 5, 197 8. [Rob65] \nRobinson, J. A., A machine-oriented logic based on the resolution principle, J.A. C. M. 12, PP. 32-41, \n1965,\n\t\t\t", "proc_id": "567067", "abstract": "There are two important notions of data types being used in programming languages today. In the concept called <i>abstract data types,</i> types are algebras; the semantics of programs is described in terms of operations in these algebras. Another notion of type found in most of the \"typed\" programming languages in actual use regards types as sets of objects; the elements of types are the objects manipulated by the operators of a programming language. I shall be careful to use \"abstract data type\" when I mean the algebraic notion, and \"data type\" or simply \"type\" to mean the set-based concept.This paper presents a formal theory of types as an approximation to the exact semantics of a language, following the lead of Milner [Mil78]. The semantics is based upon multi-sorted algebras [ADJ73, 76, 77, 78] and is applied to a language consisting of equational specifications that define an abstract data type. The principal results of the paper are to characterize a class of typings as uniform approximations to an exact semantics, to extend Milner's theory of types to include types formed by coproduct construction, and to explicate typing as an (approximate) semantics for an equational theory.In developing a formal theory of abstract data types as multi-sorted algebras, the word \"sort\" is used to designate names used to distinguish various sets of objects that may constitute the domains of operators. Sorts are thus analogous to data types in programming languages. However, the sort signatures given to operators of abstract data types do not themselves constitute a very richly descriptive language. Sort names can be formed into sequences, corresponding to product construction in an object domain, but the theory (multi-sorted &#931;-algebras) does not seem to allow alternation sequences of sorts, corresponding to coproduct construction in an object domain. If this were possible, then sort signatures could actually fulfill the role of data types. We shall see that alternation sequences in type signatures arise naturally as a consequence of the semantics given to an equational theory.", "authors": [{"name": "Richard B. Kieburtz", "author_profile_id": "81100082874", "affiliation": "The Oregon Graduate Center, Beaverton, OR", "person_id": "P242295", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567067.567079", "year": "1983", "article_id": "567079", "conference": "POPL", "title": "Precise typing of abstract data type specifications", "url": "http://dl.acm.org/citation.cfm?id=567079"}