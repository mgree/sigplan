{"article_publication_date": "05-01-1991", "fulltext": "\n Mostly Parallel Garbage Collection Hans-J. Boehm Alan J Demers Scott Shenker Xerox PARC Abstract We \npresent a method for adapting garbage collectors designed to run sequentially with the client, so that \nthey may run concurrently with it. We rely on virtual memory hardware to provide information about pages \nthat have been updated or dirtied during a given period of time. This method has been used to construct \na mostly parallel trace-and-sweep collector that exhibits very short pause times. Performance measurements \nare given. 1. Introduction Garbage collection is an important feature of many modern computing environments, \nThere are basically two styles of garbage collection algorithms: reference-counting collectors and tracing \ncollectors. In this paper we consider only tracing collectors, A straightforward implementation of tracing \ncollection prevents any client action from oceurnng while the tracing operation is performed. When applied \nto a system with a large heap, such stop-the-world implementations cause long pauses. One of the primary \narguments against wide adoption of garbage collection is that these collection-induced pauses are intolerable. \nThere are two common approaches to reducing the pause time in tracing collectors: generational collection, \nand parallel collection. Permission to copy without fee ell or part of this meterial is granted providad \nthat tha copies are not made or distributed for direct commercial advantaga, the ACM copyright notice \nand the title of the publication and its date appaar, and notice is given that copying is by permission \nof the Association for Computing Machinery. To copy otherwise, or to rermblish. reauires a fee end/ar \naDecific Dermisaion. @ l 991 ACM 0-89791.428-7/91/0005/01 57.--$1.50 Proceedings of the ACM SIGPLAN 91 \nConference on Programming Language Design and Implementation. Toronto, Ontario, Canada, June 26-28, 1991. \nGenerational garbage collectors concentrate on reclaiming recently allocated objects. Generational collectors \nhave been implemented in a wide variety of systems and have achieved significantly reduced pause times \n[Ungar 84]. However, a generational collector still needs to run full collections occasionally in order \nto reclaim older objects. Thus, the problem of long pauses is not completely eliminated. Parallel collectors \ntake an orthogonal approach to the problem of reducing collection pause time. Rather than decreasing \nthe total amount of work performed during a particular collection as generational collectors do, parallel \ncollectors merely mitigate the effect of this work by running in parallel with the mutator (client). \nWhile a parallel collector still imposes some overhead cost on the system, it eliminates the long pause \ntimes associated with stop-the\u00adworld collection. This paper discusses a technique called mostly parallel \ntracing collection. In a mostly parallel collector, some small portion of the tracing algorithm must \nrun in a stop-the\u00adworld fashion, but the majority of the work can be done in parallel. We had two goals \nin writing this paper. First was to present a method for transforming a stop-the-world tracing collector \ninto a mostly parallel collector. This method is quite general: it applies to copying as well as non-copying \ncollectors, and to generational as well as non-generational ones. Furthermore, its implementation makes \nfew demands on the operating system beyond the write-protect facilities that are now widely available. \nOur second goal was to describe a particular implementation of a garbage collector that illustrates this \nidea. Combining the notion of mostly parallel tracing collection with our previous work on conservative \n[BoehmWeiser 88] and generational [DemersEtAl 90] collection, we have built a conservative, generationaL \nmostly parallel collector. This collector is able to provide sophisticated garbage collection services \nto rather primitive languages like C which provide no pointer information. Collection pauses on a SparcStation \nII with 15 Megabytes of accessible objects are usually not noticeable. Unlike pure generational collectors, \nour collector achieves this performance even for the periodic full collections needed to reclaim long-lived \nobjects. 2. Making Tracing Collectors Mostly Parallel Basic Idea Every program contains asetof rool \nmemory objects (machine registers, statically-allocated data, etc.) that are always accessible. Atracing \ngarbage collection starts with an immune sel of memory objects that includes all roots, follows the pointers \ncontained therein to other memory objects, and then continues this pointer tracing recursively until \nno more objects can be reached. We use the term marked to denote those objects visited by this tracing \nprocedure. Any marked memory object is reachable from the immune set and should be saved. Unmarked, and \nthus unreachable, objects are garbage and should be reclaimed. Tracing collectors can differ in the immune \nset used (generational), whether or not objects are moved (copying), and many other implementation details. \nWe believe that a wide variety of tracing collectors designed to run in a stop-the-world fashion can \nbe made to run mostly in parallel. We first discuss this in rather general terms and then return in Section \n3 to give a more precise definition for the noncopying case, Assume we are able to maintain a set of \nvirtuaf dirty bits, which are automatically set whenever the corresponding pages of virtual memory are \nwritten to. (An acceptable implementation of this feature can be obtained by write-protecting pages and \ncatching the resulting write faults, with no modifications to the underlying OS kernel; an implementation \nin the OS kernel would of course be more efficient.) For any tracing collector defined for stop\u00adthe-world \noperation, consider the following collection algorithm. At the beginning of the collection, clear all \nvirtual dirty bits. Perfo &#38;n the traditional tracing operation in parallel with the mutator. The \nvirtual dirty bits will be updated to reflect mutator writes. After the tracing is complete, stop the \nworld and trace from all marked objects that lie on dirty pages. (Registers are considered dirty.) At \nthis point. all reachable objects are marked, and garbage can safely be reclaimed, This requires that \nthe tracing operation not invalidate the original data structures seen by the mutator. This is normally \nautomatically true if objects are not moved, In the case of a copying collector, a possible approach \nis presented in the last section. In this algorithm, the parallel tracing phase provides an approximation \nto the true reachable set. The only objects unmarked by this parallel tracing process which are indeed \nreachable must be reachable from marked objects which have been written since being traced. The stop-the-world \ntracing phase traces from all such objects, so that in the end no truly reachable objects remain unmarked. \nThe application of this idea to noncopying collectors will be formalized in the next section. The resulting \nmostly parallel collector is a compromise; it is neither perfectly parallel nor precise. The seventy \nof these drawbacks depends on the writing behavior of the mutator. The duration of the finat stop-the\u00adworld \nphase is related to the number of pages written during the parallel tracing operation. Thus, running \nthis collector during a period of rapid writing could lead to long system pauses. In the worst case, \npause times would be comparable to a stop-the-world collection, but this has never been observed in practice. \nNot all unreachable objects are reclaimed. This occurs when a pointer which has been traced through in \nthe parallel trace phase is changed or deleted before the stop\u00adthe-world phase. However, such an object \nwill be reclaimed by a subsequent collection. Thus, the rate at which pointers are modified will determine \nthe lack of precision in the collection. Related Work Our work is motivated by our search for effective \ngarbage collection algorithms that can operate without any special operating system or mutator cooperation. \nIn particular, we are interested in a collection algorithm usable by programs written in C on a standard \nUNIX system, Thus, algorithms that require reliable pointer identification and possibly mutator cooperation, \nsuch as copying or reference counting, were not pursued to much depth. Thus we emphasize noncopying collectors. \nIn the next section we formalize our mostly parallel technique for this case. There are a number of related \ncollection algorithms that rely on copying live data and thus assume reliable pointer identification. \nThese can generally be made to tolerate some uncertain pointer identifications using the technique of \n[Bartlett 89]. However, this can only accommodate a small number of uncertain pointers. It usually performs \nacceptably only if the uncertainty is limited to pointers in registers and on the stacks. Even then it \nmay occasionally be problematic [DeTreville 90]. In our environment, every pointer identification is \nuncertain, including those from the heap, and this approach is not usable. The advantages of being able \nto accommodate uncertainty in pointer identification are described in [BoehmWeiser 88] and [DemersEtAl \n90]. An analysis of the limitations of the technique under very adverse circumstances is given in [Wentworth \n90]. [Zorn 90] demonstrates that noncopying trace-and-sweep collectors may, at times, outperform copying \ncollectors (though the details of his trace-and-sweep collector are quite different from ours). Parallel \nnoncopying collectors are described by Steele [Steele 75] and Dikstra et al. [DijkstraEtAl 78], among \nothers. [Baker 78] presents a copying collection algorithm that is explicitly interleaved with mutator \noperations. Unlike our work, these algorithms rely heavily on mutator cooperation. Pointer updates, and \nin most cases read accesses, require the mutator to update collector data structures. These algorithms \nare practical on conventional hardware only under unusual circumstances. Baker s algorithm requires reliable \npointer identification. Appel et al. [AppelEllisLi 88] present a parallel copying collector intended \nto run on conventional machines. Their scheme, like ours, takes advantage of virtual memory hardware. \nUnlike our approach, they require intervention when the page on which an object resides is first accessed(either \nwritten or read), whereas our scheme requires intervention only when the page is first written, and then \nonly if the operating system does not allow use of hardware dirty bits. Since their algorithm also copies \nlist structures breadth-first, and thus does not preserve locality in list structures, this may result \nin a flurry of such intervention at the beginning of a collection. [DemersEtAl 90] also describes a parallel \ncollection algorithm based on virtual checkpoints implemented with a copy-on-write strategy. The algorithm \ndescribed here does not incur the copying overhead, is typically easier to implement, and requires no \nadditional memory. Very recently, DeTreville [DeTreville 90] described a parallel trace-and-sweep collector \nwhich, like ours, uses virtual memory hardware instead of explicit mutator cooperation. His collector \nrequires that slightly less work be performed while the mutator is stopped but, like the [AppelEllisLi \n88] collector and unlike ours, it requires that the collector be notified on initial read accesses by \nthe mutator. Furthermore, a single page may be protected and faulted more than once. Based on our experience \nwith pages accessed versus pages written, we believe that our strategy would usually outperform this \napproach, at least in our environment. Comparable performance measurements would be useful, but difficult \nto obtain; they report few quantitative measurements, and those are on completely different hardware, \nwith completely different mutators. An overview of various proposed uses of virtual memory primitives \nby user programs is given in [AppelLi 91]. 3, Sweeping Doesn t Matter The following discussionwill center \non the mark phase of the mark-sweep collector, that is on the processof tracing through and identifying \nreachable objects. The sweep phase does not have a significant impact on garbage collector pause times, \nThere is no reason to sweep the entire heap while the world is stopped waiting for the collection to \ncomplete; it is easy enough to interleave the sweep phase with object allocation. Our collector splits \nthe heap into blocks, Each block contains only objects of a particular size, For small objects, the size \nof the block is a physical page. The mark phasesets a bit for each accessibleobject. We then queue pages \nfor sweeping, keeping a separate queue for each small object size. The allocator alsomaintains separatefree \nlists for each (small) object size. Whenever the allocator finds an empty free list, it sweeps the first \npage in the queue of sweepable pages for that object size, removes it from the queue, and restores unreachable \nobjects to the free list. Large object blocks are swept in large increments during allocations immediately \nfollowing a collection. This requires very little CPU time, and does not force the data pages to become \nresident in physical memory. The net effect of this is that garbage collection times are completely dominated \nby the time it takes to mark accessible objects, and are thus, essentially proportional to the amount \nof accessible space. Object allocation times may become rather long if full pages are scanned before \nan available object is found, but this effect is not noticeable in practice, For the next three sections, \nwe will view garbage collection as the process of marking reachable objects. 4. Formal Statement In a \nprevious paper [DemersEtAl 90] we formalized the notion of a partial collection, i.e. a collection that \nreclaims only a subset of all unreachable objects. We will not review that material here, except to note \nthat these partial collections are characterized by the set T of threatened, i.e., potentially collectible, \nobjects. The complement of that set, the non-collectible or immune objects Z, are the objects to be traced \nfrom as discussed in Section 2. The root set is always a subset of 1. Full collections have 1= roots, \nwhereas partial collections have additional objects in 1. Generational collections are a special case \nof partial collections where the threatened set contains only recently allocated objects. A collection \nis correct if it does not reclaim any objects that are reachable, by tracing pointers, from Z. A way \nof guaranteeing correctness is to reclaim only unmarked objects and ensure that the following closure \ncondition holds: C: Every object in Z is marked and every object pointed to by a marked object is also \nmarked. A stop-the-world collection consists of the following steps: (1) stop the world, (2) clear all \nmark bits, (3) perform the tracing operation TR defined below, and (4) restart the world. TR: Mark all \nobjects in land trace from them. At the completion of this process, condition C holds and we can safely \nreclaim all unmarked objects. To run such a collector in a mostly parallel fashion, we (1) clear all \nmark bits, (2) clear all virtual dirty bits, (3) perform the tracing operation TR, (4) stop the world, \n(5) perform the finishing operation F defined below, and (6) restart the world. F: Trace from all marked \nobjects on dirty pages. Note that here the tracing operation TR is performed in parallel with the mutator. \nThe closure condition C does not hold after step 4, since the mutator could have written new pointers \ninto previously marked objects. However, the weaker condition C does hold at the end of step 4. C : Every \nobject in 1 is marked and every object pointed to by a marked object on a clean page is also marked. \n Notice that this weaker closure condition, once established by the operation TR, remains unchanged by \nthe actions of the mutator. Applying the process F to any state that satisfies condition C will produce \na state that satisfies condition C. This produces a correct mostly parallel collection. However, if the \nmutator has dirtied many pages during the tracing operation the stop-the-world phase can be overly long. \nTo reduce this delay, the collector process can clean the dirty pages in parallel through the use of \nthe process Mapplied to some set of pages P. M (1)Atomically retrieve and clear the virtual dirty bits \nfrom the pages P, and (2) trace from the marked objects on the dirty pages of P. The previous discussion \nfocused on a general notion of partial collection. We now turn to defining a particular generational \nversion of a partial collection, which makes use of the mark bits for object age information. This collector \nis related to Collector I in [DemersEtAl 90]. Consider a partial collection where the set 1 is chosen \nto be the set of currently marked objects. Then, we know that condition C already holds and that steps \n1-3 are unnecessary, We then merely need to stop the world and run the finishing step F to complete the \ncollection. In order to reduce the length of the delay, we perform the operation Al applied to the entire \nheap immediately before the stop-the-world phase. Thus, a mostly parallel version of a generational collector \ncan be described as (1) perform Mon the heap, (2) stop the world, (3) perform F, and (4) restart the \nworld. Once an object has been marked, it will never be reclaimed by this generational collector. Thus, \nwe must occasionally run full (nongenerational) collections to reclaim once\u00admarked objects, An alternate \nway of cleaning dirty pages is the process A 1 M (1) Atomically retrieve and clear the dirty bits from \nthe pages P, (2) for all unmarked objects pointed to by marked objects on dirty pages of P, mark them \nand dirty the pages on which they reside. We can substitute repeated applications of M for a single \napplication of Al Usually M is preferable but if the ratio of virtual to physical memory is extremely \nlarge, it may make sense to run M repeatedly in order to improve locality of the tracing algorithm. 5. \nImplementation Choices The preceding section gives us tools to build a variety of collectors, but it \nis not obvious how to combine them. We have not made a systematic comparison of the options, but we have \nexperimented with a few of them. This section describes some of those experiences. The first choice is \nwhen and how to run &#38;for M before a partial collection. We chose not to use iW~ since its repeated \nuse is likely to be much more expensive than a single execution of Al in our environment. Our experience \nis that it for allocation intensive mutators it occasionally makes sense to run M more than once before \na collection, since the initial execution of &#38;l can take some time, thus giving the mutator a chance \nto dirty a significant number of new pages. However, the cost involved with more than two iterations \nappears rarely to be justified. Further variants of M are possible. It is not essential for correctness \nthat M mark from roots, We maintain dirty bits for some roots, in order to reduce the number of roots \nthat must be examined by F, (In our environment, a megabyte of potential roots is common.) For reasons \nof convenience we clear all dirty bits when M starts. Thus we must mark from roots on known dirty pages. \nBut marking from other roots, such as thread stacks, is optional. We found it to be advantageous to always \nexecute M once before a partial collection, and to run a second iteration if there was a significant \namount of allocation during the first, Furthermore, letting the first iteration of Mmark from all roots \n(other than those known to be clean) can significantly reduce finat pause times. A more difficult decision \nis what constitutes a fidl collection, and how and when we decide to perform one. Initially we triggered \na full collection when we had exhausted the currently allocated heap. The heap was not expanded unless \na full collection had been unsuccessful. The full collection consisted of a partial collection followed \nby a parallel trace operation TR. The hope was that the partial collection would generally reclaim enough \nmemory to let the mutator threads continue. This approach has a number of problems. First, the heap is \noften exhausted by allocation of large blocks of storage. These often require completion of the next \ncollection, and perhaps a heap expansion. before they can be satisfied. Even if this is not the case, \nthere is no opportunity to run M before the partiat collection without stalling the allocating thread \nfor its duration. To make matters worse, the allocating thread may hold a crucial lock, thus also stalling \nother threads. This lead us to a model in which the collector is triggered solely by a daemon thread, \nwhich watches how much allocation has taken place. Full collections are triggered if the amount of apparently \nlive memory exceeds the amount of live memory at the end of the last collection by a certain amount. \nIf a full collection is needed, a normal partial collection is started, including up to two iterations \nof M. This is followed immediately by a completely concurrent execuhon of TR. If the allocator ever exhausts \nmemory, it tries to immediately expand the heap. This policy is a bit dangerous, in that the heap may \ngrow rapidly if the collector falls far behind. To reduce this danger we exercise control over the scheduling \nof the collector and mutator threads, such that the fraction of time allocated to the mutator drops off \nrapidly, but smoothly, as the collector falls behind. Other policy decisions surround the question of \nwhich pages to use for allocation of small objects. We avoid allocation on a page that is already 3/4 \nfull, so that we do not unnecessarily dirty it. It is unknown whether this is a good choice. 6. Empirical \nresults The mostly parallel generational collector described in the previous section has been in routine \nuse on SPARCStations, as part of the Xerox Portable Common Runtime (PCR) and PCedar [Welser 89], for \nseveral months. This paper was edited on a system that uses it. The collector marking code has been quite \nheavily tuned and o?Yimized. However. the same is not true for some other pieces of code run for our \nmeasurements. For example, allocation time (exclusive of collection) could have been reduced by about \n50% by runmng a streamlined, less general, assembly coded allocator, (It could have been reduced still \nfurther if we were operating in a world in which there is no concurrency aside from the collector.) We \nused the PCR preemptive thread-scheduling facility [Weiser 89] to allow the collector to run concurrently \nwith the mutator, All measurements were performed such that all threads were run by a single UNIX process. \nA page fault thus stopped all threads. The code is written to allow more than one UNIX process to run \nthreads, and has often been run in this mode (with slightly worse performance). Similarly, no fundamental \nchanges would be needed if those UNIX processes were scheduled on more than one physical processor, provided \nUNIX shared memory across processors were supported. We did not address the question of running the collector \non more than one processor simultaneously, though aside from the unlikely possibility of extremely deep \nand narrow linked data structures, this would not be terribly difficult to do, The collector was implemented \nso as not to require modification to the vendor supplied operating system. Dirty bit information (on \nvirrual memory pages) was thus not derived from the hardware dirty bits. Instead the entire heap was \nwrite protected. The resulting write faults were caught as UNIX signals at user level, and recorded. \nVarious Portable Common Runtime interfaces to SunOS system calls were modified so as to preclude unrecoverable \nwrite faults in svstem calls. The mimarv cost of this is that the first time a page in the heap is wri~ten \nafter a garbage collection, a signal must be caught and a system call must be executed to unprotect the \npage. The cost of this is variable, but in our environment appears to be somewhat less than half a millisecond \nper page wrrtten. The allocator distinguishes between objects containing pointers and those known never \nto contain pointers. The implementation performs partial collections after allocating approximately one \nquarter as many bytes as there are in pointer-containing objects. (This heuristic N an attempt at bounding \nthe fraction of time spent collecting. In our environment, collection time is very roughly proportional \nto the total size of pointer-containing objects.) We are really interested in measuring interactive response \nm the presence of garbage collection. Subjectively, this improved substantially with the parallel generational \ncollector. However, interactive sessions are difficult to reproduce and measure in different environments. \nThus we resorted to running toy programs. But. since we are interested in the performance of the collector \nin a large single address space system, these toy programs are run m the same address space with the \nCedar window system. the Tioga editor, a mailer, the SchemeXerox system [CurtisRauen 90], and a typical \ncomplement of miscellaneous smaller tools. These summed to roughly 70,000 objects, between 9,5 and 10 \nmegabytes of pointer-free allocated objects and between 2.5 and 3 megabytes of pointer-containing allocated \nobjects, in a 20 megabyte heap. Much of the pointer-free space is used for object code and static data \nfor the Cedar/Mesa program implementing the environment. The static data areas are treated as roots by \nthe collector. We attempted to measure comparable stop-the-world full, generational, and parallel generational \ncollectors, However, it is unfair to run the full collector more frequently than when the heap is exhausted. \nThere is usually little to be gained from more frequent collections, But the other approaches benefit \nfrom more frequent collections. As a compromise, we fixed the heap size at 20 megabytes, ran the full \ncollector only when the heap was full, triggered the other two collectors from a daemon thread. and tuned \nthe parameters of the parallelfgenerational collector such that the heap size would remain at 20 megabytes. \n(The parallel generational collector running Boyer on the 10 MB machine did expand the heap to 21 MB \nnear the end of the run,) This meant that the nonparallel generational collector ended up running more \nfrequently than absolutely necessary. since it did not really need the reserve space for allocation during \ncollection. Overall, this probably also increased its running time relative to the other two, but decreased \npause times. The two programs we consider here are five iterations of the Boyer benchmark, as compiled \nby SchemeXerox. and a simple allocator loop, written in C, The former is described in [Gabriel 85], and \nis often (ab)used as a garbage collector benchmark. The version of the SchemeXerox compiler we used was \nrather preliminary. Thus the absolute execution times are considerably longer than they should be. One \ncause for this is that cons-cells are 16 bytes long. The latter program allocates two and a half million \n8 byte objects and does not preserve any references to any of them. Both programs probably exhibit more \nlocal write behavior then the average interactive session, with the simple allocator presenting the extreme \ncase. But real systems tend to be less allocation intensive than both benchmarks, creating less danger \nof the allocator falling behind. In our experience, real behavior tends to be close to that for the Boyer \nbenchmark. Each program was measured on a 36 Megabyte SPARCStation 2. and also on the same machine reconfigured \nto use only 10 MB of its memory. The machine had a local paging disk. The 36 MB machine does not page \nsignificantly. whereas the 10 MB runs of Boyer were completely disk bound, as can be seen from the time \ndifferences. Note that the thread stacks and PCR are separate from the heap. that the 10 MB figure also \nincludes the UNIX kernel, that the Scheme system itself relies on substantial parts of the Cedar environment, \nand that a number of non-Scheme-related daemon threads run occasionally. All of these no doubt contributed \nto the paging behavior. In each case we report total execution times, number of garbage collections (number \nof full collections in parentheses), and maximum and average pause times for garbage collections. Total \nexecution times are given in seconds, while garbage collection pause times are given in milliseconds. \nTotal execution times were reproducible to within about 10%. Pause time averages occasionally varied \nby up to 20%, but were usually also within 10% of each other. 10 MB, alloc20meg Pause Times Total time \nNo. of coils, Max. Ave. sees (full) msecs msecs full 332.2 3(3) 51350 46323 gen 24.4 20(0) 870 125 gen,par \n32.0 11(0) 350 102 10 MB, Boyer Total time No. ofcoll. Max. Ave. full 512.6 4(4) 63380 56548 gen 360.6 \n22(5) 41840 9291 gen,par 259.6 12(2) 329 169 36 MB, alloc20meg Total time No. ofcoll. Max. Ave. full \n16.4 3(3) 1040 1037 gen 15.5 17(0) 200 81 gen,par 17.2 11(0) 100 76 36 MB, Boyer Total time No. of CO1l. \nMax. Ave. full 51.6 4(4) 1610 1368 gen 60.4 22(5) 1471 528 gen,par 66.1 13(2) 159 134 On a machine configured \nfor 8 MB memory, even the parallel collector pause times went up to an average of about 2 seconds, and \nthe heap grew by 2 megabytes, indicating that some parameters needed to be tuned to keep the mutator \nfrom getting too far ahead during full collections. The average pause time for the generational collector \nrunning Boyer on the small memory machine is completely dominated by the full collection times. The smaller \npartial collection times were around 300 milliseconds. This effect does not arise for the allocator loop, \nsince it requires no full collections, Mostly parallel collection significantly reduces average pause \ntimes below those attainable by pure generational collection, both by avoiding pauses associated with \nfull collections, and by reducing pause times for partial collections. (This is of course less true for \nthe allocator loop, since it touches only the pages it allocates from, and requires no full collections, \nthus making the page cleaning operations less productive. But note again that parallel collection were \neffectively less frequent, since a lot of allocation occurred during each collection. Thus total pause \ntimes were significantly less.) The benefit of hiding full collections is most noticeable on small memory \nmachines. where a fill collection requires large amounts of paging. On memory-rich machines, even full \nstop-the\u00adworld collection times can be sufficiently short that they are only a minor annoyance. In our \nenvironment collection pauses are usually unnoticeable (unlike network related pauses). Short pauses \nare achieved at moderate additional cost in processor time, since roots and dirty objects may be scanned \nrepeatedly. Note that PCedar itself (i.e. the mutator) is barely usable on a 10 megabyte machine. Nonetheless \nthe parallel collector keeps collection pauses tolerable, They are significantly shorter than response \ntime for a command that has not been run recently. and has thus had some of its code paged out. The number \nof full collections observed during the experiments indicates that a relatively large number of short-lived \nobjects are getting marked, and thus surviving to the next full collection. Since full collections are \nusually not disastrous, this problem can be tolerated. However, we are exploring modifications to the \ngenerational collection scheme similar to those in [DemersEtAl 90] that would improve this behavior without \nadding significantly to the required bookkeeping overhead. 7. Mostly Parallel Copying Collectors nonpointer \nfields that occurred since the start of It is possible to apply the same approach to obtain a mostly \nparallel copying collector. Unlike the [AppelEllisLi 88] collector, this approach requires only dirty \nbit information. Unfortunately, it also appears to require additional space to maintain explicit forwarding \nlinks. We assume that every object has an additional field called forward, which is set and examined \nonly by the garbage collector. The underlying collection algorithm can be either traditional breadth-first \ncopying (cf. [Cheney 70]) or one that attempts to preserve better locality of reference (cf. [Moon 84]). \nThe copying collector is invoked concurrently with the mutator. Asusual, thecollector copies allreachable \ncsbjects residing in from-space to a previously unused region of memory referred to as to-space. Links \nin to-space are updated to reflect the new locations of the objects. This concurrent collector is identical \nto the sequential version. except in that 1) Itclears theforwardpointers inJrom-space before it starts. \n(Reassume thatthe collector canwriteforward fields without affecting dirty bits. This may require allocating \nforward pointers separately, e.g. in apart of to-space that will not be immediately needed.) 2) It maintains \ninformation about pages dirtied since the beginning of the collection. 3) It stores the new address of \neach copied object into the forwarding link of each object in from-space. The mutator continues to see \nonly from-space objects. (In the [AppelEllisLi 88] collector, the mutator seesonly to\u00ad.spaceobjects.) \nThis concurrent collection process establishes the condition that if an object residing on a clean page \nhas been copied, then every object it points to has also been copied. Furthermore, ifanobject resideson \na clean page then its copy has the correct contents. With the world stopped, we can then run following \nfinishing operation to ensure that all reachable objects have been copied, and all copies contain the \ncorrect contents: Fc : For every copied object a whose from-space copy resides on a dirty page: 1) Copy \nany objects that the from-space copy of a points to, that have not yet been copied, i.e. that have NIL \nforwarding links. 2) Update pointers in copies to refer to to-space, recursively copying uncopied objects. \n(This can be done without a stack, as with the original copying collector, Breadth first copying is probably \nfine here, since this should be a small collection of objects that have all been referenced within a \nshort time interval.) 3) Recopy a to reflect changes in both pointer and the collection. As in the noncopying \ncollector, it is easy to construct a variant of Fc that can be run concurrently to further reduce the \namount of time expended by the final stop-the-world collection. Again, the amount of time spent with \nthe world stopped is proportional to the number of pages dirtied since the start of the last parallel \ncopying phase, and thus should be quite short. We have not built such a collector. since it is not practical \nin our environment. An empirical performance comparison with the [AppelEllisLi 88] collector would be \ninteresting. Our alternative is most likely to be attractive if the operating system provides inexpensive \ndirty bit access, but relatively expensive trap handling, Acknowledgements Bob Hagmann and Barry Hayes \nsuggested some of the alternatives described in section 5. UNIX is a trademark of AT&#38;T Bell Laboratories. \nSPARCStation is a trademark of Sun Microsystems. References [AppelEllisLi 88] Appel, Andrew, John R. \nEllis, and Kai L,i, Real-time Concurrent Collection on Stock Multiprocessors , Proceedings of the SIGPLAN \n88 Conference on Programming Language Design and Implementation, SIGPLAN No~ices 23, 7 (July 88), pp. \n11-20. [AppelLi 91] Appel, Andrew W., and Kai Li, Virtual Memory Primitives for User Programs , Proceedings \nof the Fourth International Conference on Architectural Support for Programming Languages and Operating \nSystems, 1991. [Bartlett 89] Bartlett, Joel F,, Mostly-Copying Garbage Collection Picks Up Generations \nand C+ + , DEC WRL Technical Note TN-12, October 1989. [BoehmWeiser 88] Boehm, Hans-J. and Mark Weiser, \nGarbage Collection in an Uncooperative Environment , Sojiware Practice &#38; Experience 18, 9 (Sept. \n1988), pp. 807-820. [Cheney 70] Cheney, C., J., A Nonrecursive List Compacting Algorithm , Communications \nof the ACM 13, 11(November 1970), pp. 677-678. [CurtisRauen 90] Curtis, P. and J. Rauen. A Module System \nfor Scheme. Proceedings of the 1990 ACM Conference on LISP and Functional Programming, June 1990, pp. \n13-19. [DemersEtAl 90] Demers, A,, M, Weiser, B. Hayes, H. Boehm, D. Bobrow, S. Shenker, Combining Generational \nand Conservative Garbage Collection: Framework and Implementations , Proceedings of the Seventeenth Annual \nACM Symposium on Principles of Programming Languages, January 1990, pp. 261-269. [DeTreville 90] DeTreville, \nJohn, Experience with Concurrent Garbage Collectors for Modula-2 + , Digital Equipment Corporation, Systems \nResearch Center, Report No. 64. [DikstraEtAl 78] Dijkstra, E. W., L. Lamport, A. Martin, C. Scholten, \nand E. Steffens, On-the-Fly Garbage Collection: An Exercise in Cooperation , Communications o~lhe ACM \n21, 11 (November 78), pp. 966-975. [Gabriel 85] Gabriel, Richard P., Performance and Evaluation of Lisp \nSystems, MIT Press, 1985. [Moon 84] Moon, D., Garbage Collection in Large Lisp Systems , Proceedings \nof the 1984 ACM Symposium on Lisp and Functional Programming, pp. 235-246. [Rovner 84] Rovner, Paul, \nOn Adding Garbage Collection and Runtime Types to a Strongly-Typed, Statically Checked. Concurrent Language \n, Report CSL-84-7, Xerox Palo Alto Research Center. [Steele 75] Steele, Guy L., Multiprocessing Compactlfying \nGarbage Collection , Communications of the ACM 18,9 (September 75), pp. 495-508. [Ungar 84] Ungar, David, \nGeneration Scavenging: a non-disruptive high performance storage reclamation algorithm , Proceedings \nof the ACM SIGSOFVSIGPLAN Software Engineering Symposium on Practical Software Development Environments, \nSIGPLAN No~ices 19,5 (1984), pp. 157-167. [Weiser 89] Weiser, M., A. Demers, and C. Hauser, The Portable \nCommon Runtime Approach to Interoperability , Proceedings of the 13th ACM Symposium on Operating System \nPrinciples (December 1989). [Wentworth 90] Wentworth, E. P., Pitfalls of Conservative Garbage Collection \n, Sofzware Practice &#38; Experience 20,7 (July 1990) pp. 719-727. [Zorn 90] Zom, Benjamin, Comparing \nMark-and-Sweep and Stop-and-Copy Garbage Collection , Proceedings of the 1990 ACM Conference on Lisp \nand Functional Programming, June 1990, pp. 87-98. \n\t\t\t", "proc_id": "113445", "abstract": "", "authors": [{"name": "Hans-J. Boehm", "author_profile_id": "81423595101", "affiliation": "Xerox PARC", "person_id": "PP80029584", "email_address": "", "orcid_id": ""}, {"name": "Alan J. Demers", "author_profile_id": "81100529925", "affiliation": "Xerox PARC", "person_id": "P12362", "email_address": "", "orcid_id": ""}, {"name": "Scott Shenker", "author_profile_id": "81100282775", "affiliation": "Xerox PARC", "person_id": "PP15028147", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/113445.113459", "year": "1991", "article_id": "113459", "conference": "PLDI", "title": "Mostly parallel garbage collection", "url": "http://dl.acm.org/citation.cfm?id=113459"}