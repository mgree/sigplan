{"article_publication_date": "05-01-1991", "fulltext": "\n CML: A Higher-order Concurrent Language* John H. Reppy Cornell University jhr@cs. cornell. eciu 1 Introduction \nConcurrent ML (CML) is a high-level, high-performance lan\u00adguage for concurrent programming. It is cm \nextension of Standard ML (SML)IMTH901, and is implemented on top of Standard MLof New Jersey (SML/NJ)1w871. \nCMLisaprac\u00adticallanguage andisbeing usedto build real systems. It demonstrates that we need not sacrifice \nhigh-level notation in order to have good performance. Although most research in the area of concurrent \nlanguage design has been motivated by the desire to improve perfor\u00admance by exploiting multiprocessors, \nwe believe that concur\u00adrency is a useful programming paradigm for certain applica\u00adtion domains, For example, \ninteractive systems often have a naturally concurrent structure [cpm~ G86? ik891 a901. An\u00adother example \nis distributed systems: most systems for dis\u00adtributed programming provide multi-threading at the node \nlevel (e.g., Isis1BcJ+901 and ~gusILCJ~n). Sequential pro\u00adgrams in these application domains often must \nuse complex and artificial control structures to schedule and interleave activities (e.g., event-loops \nin graphics libraries). They are, in effect, simulating concurrency. These application domains need a \nhigh-level concurrent languagethat provides both effi\u00adcient sequential execution and efficient concurrent \nexecution: CML satisfies this need. 1.1 An overview of CML CML is based on the sequential language SML \niMTH901 and *This work was supported, in part, by the NSF and ONR under NSF grant CCR-85-14862,andby \nthe NSF under NSF grant CCR-89-18233 Permission to copy without fee all or part of this material ia granted \nprovided that the copies are not made or distributed for direct commercial edventege, the ACM copyright \nnotice and the title of the publication and ita date appear, and notice is given that copying is by permission \nof the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or \nspecific permission. @ 1991 ACM 0-89791 -428 -7/91 /0005 /0293 . ..$1 .50 Proceedings of the ACM SIGPLAN \n91 Conference on Programmmg Language Design and Implementation. Toronto, Ontario, Canada, Juna 26-28, \n1991, ~ state-of-the-art module facility. A brief introduction to SML inherits the good features of SML: \nfunctions as first-class values, strong static typing, polymorphism, datatypes and pattern matching, \nlexical scoping, exception handling and a is given as an appendix; also see [Har86]. The sequential \nperformance of CML benefits from the quality of the SML/NJ compiler. In addition CML has the foIlowing \nproperties: CML provides a high-level model of concurrency with dy\u00adnamic creation of threads and typed \nchannels, and rerzdez\u00advous communication. This distributed-memory model fits well with the mostly applicative \nstyle of SML.  CML is a higher-order concurrent language. Just as SML supports functions as first-class \nvalues, CML supports syn\u00adchronous operations as first-class values. These values, called events, provide \nthe tools for building new synchro\u00adnization abstractions. For example, we have found uses for widely \nvarying abstractions, such as remote procedure call, multicast channels and buffered channels. This flex\u00adibility \nis important, as it allows the synchronization and communication abstractions to be tailored to the applica\u00adtion. \nCML S events are an extension of the mechanism described in [Rep88].  CML provides integrated 1/0 support. \nPotentially block\u00ading 1/0 operations, such as reading from an input stream, are full-fledged synchronous \noperations. Low-level sup\u00adport is also provided, from which distributed communica\u00adtion abstractions can \nbe constructed.  CML provides automatic reclamation of threads and chan\u00adnels, once they become in accessible. \nThis permits a tech\u00adnique of speculative communication, which is not possible in other threads packages. \n o CML uses pre-emptive scheduling. To guarantee inter\u00adactive responsiveness, a single thread cannot \nbe allowed to monopolize the processor. Pre-emption insures that a context switch will occur at regular \nintervals, which al\u00adlows off-the-shelf code to be incorporated in a concur\u00adrent thread without destroying \ninteractive responsiveness. 0 CML is efficient. Thread creation, thread switching and message passing \nare very efficient (benchmarks are given in section 5). Experience with CML has shown that it is a viable \nlanguage for implementing usable interactive systems; this is in direct contrast with Haahr s experience \nlt is possible to use polling to implement selective commu\u00ad with concurrency in scheme IHLM901.In fact, \nmessage pass\u00ading in CML is significantly faster than in Sun s light-weight process library. Q CML is \nportable. It is written in SML and runs on essen\u00adtially every system supported by SML/NJ (four different \namhit ectu~es &#38;d many dif fereni operating systems).  1.2 Organization of this paper The rest of \nthe paper has four parts: section 2 describes and motivates the design of CML (a complete description \ncan be found in [Rep90b]); section 3 describes the use of CML in two application areas; sections 4 and \n5 describe the implementa\u00adtion and its performance; and, lastly, section 6 compares CML with related \nwork. A brief introduction to SML is included as an appendix, 2 Basic concurrency primitives A CML program \nconsists of a number of threads, which use message passing on typed channels to communicate and syn\u00adchronize. \nThe signature oft he basic thread and channel oper\u00adations is given in figure 1. The function spawn dynamically \n(* create a new thread .) val spawn : (unit -> unit) -> thread_id (* create a new channel *) val channel \n: unit -> la than (* message passing operations *) val accept : a than -> ,a val send : ( a than W a) \n> unit Figure 1: Basic concurrency primitives creates a new thread to evaluate its argument. Channels \nare also created dynamically, using the function channe 1 ]. The functions accept and send are the synchronous \ncommu\u00adnication operations. When a thread wants to communicate on a channel, it must rendezvous with another \nthread that wants to do a complementary communication on the same channeL Most CSP-style languages (e.g., \noccam EBur881and amber [carsbl) provide similar rendezvous-style communica\u00adtion. In addition, they provide \na mechanism for selective com\u00admunication, which is necessary for threads to communicate with multiple \npartners. *The I in the type variable of channe 1 s result type is the strength of the variable. This \nis a technical mechamsm used to allow polymorphic use of upda~ble ob]ec~ without c~ating type loopholes \nnication, but to do so is awkward and requires busy wait\u00ading. Usually selective communication is provided \nas mul\u00adtiplexed 1/0 operation. This can be a multiplexed input operation, such as occam s ALT constructIBur881; \nor a general\u00adized (or symmetric) select operation that multiplexes both in\u00adput and output communications, \nsuch as Pascal-m s select construct 1AB861.Implementing generalized select on a multi\u00adprocessor can be \ndifficult iB0r861, but, as will be shown in sec\u00adtion 2.2, there are situations in which generalized selective \ncommunication is necessary. There is a fundamental conflict between the desire for abstrac\u00adtion and the \nneed for selective communication, For example, consider a server thread that provides a service via a \nrequest\u00adreply, or remote procedure call (lWC) style, protocol. The server side of this protocol would \nbe something like: fun serverLoop () = if serviceAva~lable () then let val request = accept reqch Ln \nsend (replyCh, doit request) ; serverLoop () end else doSomethingElse () where the function do i t actually \nimplements the service. This protocol requires that clients obey the following two rules: 1. A client \nmust send a request before trying to read a reply. 2 Following a request the client must read exactly \none reply before issuing another request. If all clients follow these rules, then we can guarantee that \neach request is answered with the correct reply. A obvious way to improve the reliability of programs \nthat use this ser\u00advice is to bundle the client-side protocol into a function that hides the details, \nthus ensuring that the rules are followed. The following code implements this abstraction: fun clientCall \nx = (send (reqCh, x) ; accept replyCh) While this insures that the protocol is observed, it hides too \nmuch. If a client blocks on a call to client call (e.g., if the server is not available), then it cannot \nrespond to other com\u00admunications. The client would like to use selective communi\u00ad cation in this situation, \nbut cannot, because the synchronous aspect of the protocol has been hidden by the function abstrac\u00adtion. \nThe next section describes our solution to this dilemma. 2.1 First-class synchronous operations Following \n[Rep88] and [Rep89], we make synchronous op\u00aderations into first-class values by introducing a new kind \nof value, called an event, which represents a potential syn\u00adchronous operation (analogous to the way \na function value describes a potential computation). These values provide an abstraction of a protocol \nimplementation, without obscuring the synchronous aspect of a protocol. Figure 2 gives the sig\u00adnature \nof the basic event operations from the [Rep88] model, CML extends this model in several significant ways, \nwhich val sync : a event -> a Val receive : ( a than -> I a event Val transmit : ( a than * a) -> un~t \nevent Val choose : a event llst -> a event Va 1 wrap : ( a event * ( a -> b)) -> b event Figure 2: \nBasic event operations are discussed in section 2.4. The operator sync forces syn\u00adchronization on an \nevent value. The functions rece ive and t ran smit are used to build the base event values that de\u00adscribe \nchannel communication. The event values returned by receive and transmit are called base event values. \nWe can define accept and send using these and function composi\u00adtion: val accept = sync 0 receive val \nsend = sync 0 transmit The functions choose and wrap are combinators for con\u00adstructing new event values: \nchoose provides a generalized selective communication mechanism and wrap combines an event with a post-synchronization \naction, called the wrap\u00adper. For example, if we have two integer valued channels, chl and ch2, then the \nfollowing expression will block until a message is available on one of the channels: sync (choose [ wrap \n(receive chl, fn x => (2 * x) ) , wrap (reaelve ch2, fn x => (x + 1) ) 1) When a message becomes available,then \nwe say the rece ive event is enabled. If both base events are enabled at the same time, then one will \nbe chosen non-deterministically. When a base event value is synchronized on, it produces a result, which \nto which its wrappers are applied. For example, if the above expression synchronizes on receive ch 1, \nthen the result will be multiplied by 2, CML supports generalized (or symmetric) selective communication; \na choice event value may have both input and output operations in it, A formal operational semantics \nof CML has been developed and will be included in the author s forthcoming Ph.D. thesis IReP91b1. To \nunderstand this the higher-order nature of this mecha\u00adnism, it is helpful to draw an analogy with first-class \nfunc\u00adtion values. Table 1 compares these two higher-order mech\u00adanisms. Property Function values Event \nvalues Type constructor -> event Introduction A-abstraction receive transmit etc. Elimination application \nsync Combinato~ composition choose I map Iwrap etc. etc. Table 1: Relating first-class functions and \nevents  II II The great benefit of this approach to concurrency is that it allows the programmer to \ncreate new first-class synchroniza\u00adtion and communication abstractions. For example, we can define an \nevent-valued function that implements the client\u00adside of the RPC protocol given in the previous section: \nfun clientCallEvt x = wrap ( transmit (reqch, x) , fn () => accept replyCh) Application of the function \ntransmit produces an event value that represents the sending of the request. If the server accepts the \nrequest, then we need to wait for a reply. To do this we wrap the request event with a function that \nwill accept the reply. In the following section, we give a more substantial example. 2.2 An example \nAn example that illustrates a number of key points is an im\u00ad plementation of a buflered channel abstraction. \nBuffered chan\u00adnels provide a mechanism for asynchronous communication, which is similar to the actor \nmailbox 1Agh861. The source code for this abstraction is given in figure 3. The function buf f er creates \na new buffered channel, which consists of a btlffer thread, an input channel and an output channel; the \nfunction buff erSend is an asynchronous send operation; and the function buff erRece i ve is an event-valued \nreceive opera\u00adtion. The buffer is represented as a queue of messages, which is implemented as a pair \nof stacks (lists); the Appendix gives abstype a buffer_chan = BC of ( inch : a than, outch : a than \n ) with fun buffer () = let val ~nCh = channel () and outCh = channel ( ) fun looP ( [1, [1) = loop ([accept \ninch], [1) \\ loop (front as (x: :r) , rear) = sync ( choose [ wrap (receive inCh, fn y => loop (front, \ny: :rear) ) , wrap (transmit (outCh, x) , frl () => loop(rr rear) ) 1) [ loop ([1, rear) = loop (rev \nrear, [1 ) in spawn (fn () => loop ([l, [1)); BC{inch=inCh, outch=outCh} end fun buffer Send (BC{mch, \n. . ), x) = send (inch, x) fun bufferReceive (BC{outch, . . . ) ) = receive Outch end (* abstype ) Figure \n3: Buffered channels more details on this applicative implementation of queues. This example illustrates \nseveral key points: * Buffered channels are a new communication abstraction, which have first-class citizenship. \nA thread can use the buff erRe ce ive function in any context that it could use the built-in function \nreceive, such as selective commu\u00adnication. * The buffer loop usesbothinput and output operations in \nits selective communication. This isanexample of theneces\u00adsity of generalized selective communication. \nIf we have only a multiplexed input construct (e.g., occam s ALT), then we must to use a request/reply \nprotocol to implement the server side of the buf f erRece ive operation (see pp. 37-41 of [Bur88], for \nexample). But if a request /reply pro\u00adtocol is used, then the buf f e rReceive operation cannot be used \nin a selective communication by the client.  b The buffer thread is a good example of a common CML programming \nidiom: using threads to encapsulate state. This style has the additional benefit of hiding the state \nof the system in the concurrency operations, which makes the sequential code cleaner. These threads serve \nthe same role that mo}l ifors do in some shared-memory concurrent languages. o Once created, the buffer \nthread never terminates, which may seem to pose a problem for resource recovery. If a buffered channel \never becomes unreachable from all non\u00adblocked threads, then the buffer thread and channels will be reclaimed \nby the garbage collector. Because the channels and suspended thread state are normal SMLfNJ heap ob\u00adjects, \nwe get thread reclamation for free. In general, threads that communicate infinitely will block and be \ngarbage col\u00adlected if they become disconnected from the active part of the system. There are certain \npathological live-fock situa\u00adtions, in which this fails, but these do not arise in practice. A more complete \nversion of this abstraction 1sincluded m the CML distribution.  2.3 Other synchronous operations One \nof the nice aspects of events is that other primitive syn\u00adchronous operations are easily accommodated \nin the frame\u00adwork. There are three examples of this in CML: synchroniza\u00adtion on thread termination (sometimes \ncalled process join), low-level 1/0 support and time-outs. The function val wait : thread_~d > unit event \nproduces an event for synchronizing on the termination of another thread. This is often used by servers \nthat need to release resources allocated to client threads, Support for 10W\u00adlevel 1/0 is provided by \nthe functions: val syncOnInput : Int > unit event val syncOnOutput : lnt -> unit event val sync OnExcept \n: ~nt > unit event which allow threads to synchronize on the status of file de\u00adscriptions. These operations \nare used in CML to implement a multi-threaded 1/0 stream library. There are two functions for synchronizing \nwith the clock. val wait Until : time -> unit event val timeout : time > unit event The function wait \nunt i I returns an event that will synchro\u00adn~ze at the given time the function t imeout delays the spec\u00adified \ntime from the time sync is applied. CML also provides a polling mechanism val poll : a event -> a option \nevent where the SML type constructor option is datatype a option = NoNE I SOMEof a which budds an event \nfor polling its argument. The event value p o I I (ev ) is always enabled. If it is chosen when involved \nin a synchronization, then it will return (SOME ev ), if e,v is enabled and would return v; otherwise, \nit will return NONE.  2.4 Extending the mechanism The concurrency mechanism described thus far is essentially \nthat presented in [Rep881 and [Rep891. CML extends this model in several important ways, in this section \nwe motivate and describe these extensions. Consider a protocol consisting of a sequence of client-server \ncommunications: CI; CZ;. , ,; Cn. When this protocol is pack\u00adaged up in an event value, one of the c, \nis designated as the commit poitlt; the communication on which this event is chosen in a selective communication. \nIn the mechanism of [Rep881, the only possible commit point is CI. The wrap con\u00adstruct allows on to tack \non c?; ,. ,; c~ after c1 is chosen, but there is no way to make any of the other Ci the commit point. \nThis asymmetry is a serious limitation to the originat mech\u00ad anism. To illustrate this problem, consider \na server that im\u00adplements an input stream abstraction. Since this abstraction should be smoothly integrated \ninto the concurrent model, we make the input operations event-valued; for example, the function val input \n: lnstream -> string event would be used to read a single character. Other operations, such as input_l \nine would also be provided. Let us assume that the implementation of these operations uses a request\u00ad \nreply protocol; thus, a successful input operations involves the communication sequence send (c/~,.q, \nREQ_INPUT) ; aCC@Pt (c&#38;ep; u ) Packaging this L~p as an event (as we did in section 2.1), will make \nthe send communication be the commit point, but this is not the right semantics. To see the problem, \nconsider the case where a client thread wants to synchronize on the choice of reading a character and \na five second timeout; e.g.: sync (choose [ wrap (timeout (T1ME{sec=5, usec=O } ) , fn () => raise Timeout) \n, input instream 1) The server will probably accept the request within the five second limit, even though \nthe wait for input might be indef\u00ad i nite. The right semantics for the 1 nput operation requires making \nthe accept be the commit point. The guard combi\u00ad nator provides a mechanism for doing this. The guard \ncombinator is the dual of wrap; it bundles code to be executed before the commit point; this code can \ninch.lde communications. It has the type val guard : (unit > a event) > a event A guard is essentially \na suspension that is forced when sync is applied to it. As a simple example of the use of guard, the \ntime out function, described above, is actually implemented use waituntil and a guard: fun cImeout t \n= guard ( fn () => waitUnt~l (add_time (t, currentTime () ) ) where cur rent Time returns the current \nwall-clock time. Returning to our RPC example from above, we can now build an abstract RPC operation \nwith the reply as the commit point, The two different versions are: fun clientCallEvtl x = wrap ( transmit \n(reqCh, x) , fn ( ) => accept replyCh) fun cllentCallEvt2 x = guard (fn () => ( send (reqCh, x) ; receive \nreplyCh) where c 1 i ent Ca 11 Evt 1 commits on the server s accep\u00ad tance of the request and c 1 ient \nCal 1 Evt 2 commits on the server s reply to the request. Using guards to generate re\u00adquests like this \nraises a couple of other problems. First of all, if the server cannot guarantee that requests will be \naccepted promptly, then evaluating the guard may cause delays. The solution to this is to spawn a new \nthread to issue the request: fun clientCallEvt3 x = guard (fn () => ( spawn (fn ( ) => send(reqCh, x) \n) ; receive replyCh) Another alternative is for the server to be a clearing-house for requests; spawning \nanew thread to handle each new request. The other problem is more serious: what if this RPC event ]s \nused in a selective communication and some other event is chosen? How does the server avoid blocking \nforever on sending a reply? For idempotent services, this can be handled by having the client create \na dedicated channel for the reply and having the server spawn a new thread to send the reply. The client \nside of this protocol is fun clientCallEvt4 x = guard (fn () => let val replych = channel ( ) in spawn \n(fn () => send (reqCh, (replyCh, x) ) ) ; receive replyCh end) When the server sends the reply it evaluates \nspawn (fn () => send (replyCh, reply) ) If the client has already chosen a different event, then this \nthread blocks and will be garbage collected. For services that are not idempotent, this scheme is not \nSLIf\u00adficient; the server needs a way to abort the transaction. The function val wrapl.bort : ( a event \n* (unit -> unit) ) -> unit is provided for this purpose. The semantics are that if the wrapped event \nis not chosen in a sync operation, then a new thread is spawned to evaluate the second argument, called \nthe abort function. This is the complement of wrap in the sense that if you view every base-event in \na choice as having both a wrapper and and an abort function, then, when sync is applied, the wrapper \nof the chosen event is called and the abort functions of the other base events are spawned off. The client \ncode for the RPC using abort must allocate two channels: one for the reply and one for the abort message: \nda catype abort_msg = ABORT fun clientCallEvt5 x = guard (fn () > let val reply Ch = channel () val abortCh \n= channel () fun abortFn ( ) = send (abortCh, ABORT) in spawn (fn () => send (reqCh, (replyCh, abortCh, \nx) ) ) ; receive replyCh end) When the server is ready to reply (i,e., commit the transac\u00ad tion), it \nsynchronizes on the value choose [ wrap (receive abortCh, fn ABORT => aborf the transaction) , wrap (transmit \n(reply Ch, reply) , f n ( ) => commit the transaction) 1  This mechanism is used to implement the concurrent \nstream 1/0 library in CML. Another extension to [Rep88] is the function: val wrapHandler : ( a event \n* (exn > a) ) -> a event wraps an exception handler around an event z. For example, synch Input will \nraise an exception if the file specified by the descriptor f d has been closed. Using wraPHandle r, we \ncan define a better behaved version of syncon I nput: fun waitForInput fd = wrapHandler ( wrap (syncOnInput \nfd, fn () => true) , fn => false)  Upon synchronization, this will return true if input is avail\u00ad able, \nand false if the file is closed.  2.5 Stream 1/0 CML provides a concurrent version of the SML stream \n1/0 primitives. Input operations in this version are event valued, Zexn is the type of exception values \nwhich allows them to be used in selective communication For example, a program might want to give a user \n60 seconds to supply a password. This can be programmed as: fun getpasswd () = sync (choose [ wrap (t~meoutsec=60, \nusec=O, fn () => NONE), wrap (input_line std_in, SOME) 1) This will retumNONE, if the user fails to \nrespond within 60 sec\u00ad onds, otherwise it wraps SOME around the user s response3. Streams are implemented \nas threads which handle buffer\u00ad ing. The input operations are actually request /reply/abort protocols, \nsimilar to the one discussed above. 3 Applications CML is more than an exercise in language design; it \nis in\u00ad tended to be a useful tool for building large systems. In this section we describe two applications \nof CML, and how they use the features of CML. 3.1 Interactive systems Providing a better foundation \nfor programming interactive systems, such as programming environments, was the origi\u00ad nal motivation \nfor this line of researchIRG861. Because of their naturally concurrent structure, interactive systems \nare one of the most important application areas for CML. Concurrency arises in several ways in interactive \nsystems: User interaction. Handling user input is the most complex aspect of an interactive program. \nMost interactive systems use an event-loop and call-back functions. The event-loop receives input events \n(e.g., mouse clicks) and passes them to the appropriate euent-bundler. This structure is a poor\u00adman s \nconcurrency: the event-handlers are coroutines and the event-loop is the scheduler. Multiple services. \nFor example, consider a document prepa\u00ad ration system that provides both editing and formatting. These \ntwo services are independent and can be naturally organized as two separate threads. Multiple views are \nimplemented by replicating the threads. Interleaving computation, A user of a document prepara\u00adtion system \nmay want to edit one part of a document while another part is being formatted. Since formatting may take \na significant amount of time, providing a responsive inter\u00ad face requires interleaving formatting and \nediting. If the editor and formatter are separate threads, then interleav\u00ading comes for free. 3Since \nSOMEis a constructor function (i.e., SOME : , a -> , a OptlO~), it can be used as a function argument \n Output driven applications. Most windowing toolkits, for example XlibINYe901, provide an input oriented \nmodel, in which the application code is occasionally called in re\u00ad sponse to some external event. But \nmany applications are output oriented, Consider, for example, a computationally intensive simulation \nwith a graphical display of the current state of the simulation, This application must monitor win\u00ad dow \nevents, such as refresh and resize notifications, so that it can redraw itself when necessary, In a sequential \nimple\u00ad mentation, the handling of these events must be postponed until the simulation is ready to update \nthe displayed in\u00ad formation. By separating the display code and simulation code into separate threads, \nthe handling of asynchronous redrawing is easy. The root cause of these forms of concurrency is computer\u00adhuman \ninteraction: humans are asynchronous and slow. CML has been used to build a multi-threaded interface \nto the X protocolIW861, called eXene. This system provides a similar level of function as XlibINYe901, \nbut with a substantially differ\u00adent, and we think better, model of user interaction. Windows in eXene \nhave an envkomnent, consisting of three streams of input from the window s parent (mouse, keyboard and \ncon\u00adtrol), and one output stream for requesting services from the window s parent, For each child of \nthe window, there will be corresponding output streams and an input stream. The input streams are represented \nby event values and the output streams by event valued functions. A window is responsi\u00adble for routing \nmessages to its children, but this can almost always be done using a generic router function provided \nby eXene. Typically, each window has a separate thread for each input stream as well as a thread, or \ntwo, for managing state and coordinating the other threads. By breaking the code up this way, each individual \nthread is quite simple, This model is similar to those of [Pik89] and [Haa901). This structure allows \nus to use delegation techniques to define new behavior from existing implementations. Delegation is an \nobject-oriented technique (so we know it must be good), that originated in concurrent actor systems 1LFsS61.As \nan ex\u00adample, consider the case of adding a menu to an existing text window. We can do this in a general \nway by defining a wrapper that takes a window s environment and returns a new, wrapped, environment. \nThe wrapped environment has a thread monitoring the mouse stream of the old environ\u00adment. Normally, this \nthread just passes messages along to the wrapped window, but when a mouse button down mes\u00ad sage comes \nalong, the thread pops LIp the menu and consumes mouse messages until an item is chosen. Emcien Gansner, \nof AT&#38;T Bell Laboratories, has developed a widget toolkit on top of eXene, which uses these delegation \ntechniques heavily. The implementation of eXene which is currently about 8,500 lines of CML code, uses \nthreads heavily. At the lowest level, threads are used to buffer communication with the X server. There \nare threads to manage shared state, such as graphics contexts, fonts and keycode translation tables. \nBecause the internal threads are fairly specialized and tightly integrated, there is not much use of \nevents as an abstraction mechanism. The use of events as an abstraction mechanism is common at the application \nprogrammer s level. h addition to the event-vah~ed interface of the window environments, there are higher-level \nobjects that have abstract synchronous inter\u00ad faces. One example is terminal (vtty). This a virtualwindow \nprovides a synchronous stream interface to its clients, which is compatible with the signature of CML \nS concurrent 1/0 libra~. If the client-code is implemented as a @zctor[Mac841 (parametrized module), \nthen it can be used with either the concurrent 1/0 library or the vtty abstraction. The vtty abstraction \nis a good example of where user-defined abstract synchronous operations are necessary for program modularity. \nAt any time, the vtty thread must be ready to receive input from the user and output from the applica\u00adtion; \nthus it needs selective communication. The underlying window toolkit (eXene) provides an abstract interface \nto the input stream, but, since it is event-valued, it can be used in the selective communication. Another \nexample of the use of new communication abstrac\u00adtions is a twflered nudticast channel (a simple version \nis de\u00adscribed in [Rep90b]). This abstraction has proven quite useful in supporting multiple views of \nan object. When the viewed object is updated, the thread managing its state sends a no\u00adtification on \nthe multicast channel. The multicast channel basically serves the role of a call-back function, while \nfree\u00ading the viewed object from the details on managing multiple views. All of the details of creating/destroying \nviews and distributing messages are taken care of by the multicast ab\u00adstraction.  3.2 Distributed ML \nAnother project involving CML is the development of a dis\u00adtributed programming toolkit for ML, which \nis being done in collaboration with Bard Bloom, Robert Cooper, Chet Murthy and Tim Teitelbaum at Cornell \nUniversity. The low-level 1/0 support of CML is sufficient to build a structured syn\u00adchronous interface \nto network communication (as was done in our X-windows application). Higher-level linguistic sup\u00adport \nfor distributed programming, such as the promise mech\u00adanism of [LS88], can be built using events to define \nthe new abstractions. Some of these ideas have been prototype by Chet Murthy as part of a re-implementation \nof the Nuprl in\u00adteractive proof system. Nuprl can require vast amounts of system resources when used \nto develop large proofs, but it also provides ample opportunity for coarse-grain parallelism. The system \nis structured as a pool of proof servers distributed across a local area network of workstations. A user \ns ses\u00adsion manager will farm out pieces of the proof to idle and available servers; it uses an object \nsimilar to a promise as a place-holder for the outstanding work. Implementation CML is written entirely \nin SML, using a couple of non\u00adstandard extensions provided by SML/NJ: j?rst-chms contin\u00aduations[Dm911 \nand asynchronous signals IReP90al. We added one minor primitive operation to the compiler (a ten line \nchange in a 30,000 line compiler), which was necessary to guarantee that sync preserve tail-recursion. \nThreads are im\u00adplemented d la [Wan80], using jirst-class continuations, and the SML/NJ asynchronous signal \nfacility is used to implement pre-emptive scheduling, Unlike other continuation-passing style compilers, \nsuch as [Ste781and [KKR+ 861, the code generated by the SML/NJ compiler does not use a run-time stack. \nThis means that c a 11 c c and throw are constant-time operations, While this is possible using a stack \nIHDB901; heap-based implementa\u00ad tions are better suited for implementing light-weight threads (Haahr \ns experience bears this out IHaa901). Event values have a natural implementation in terms of first\u00ad class \ncontinuations. Without the choose operator, an event value could be represented as type r a event = a \ncent -> a with sync being direct ly implemented by c a 11 c c. This representation captures the intuition \nthat an event is just a synchronous operation with its synchronization point con\u00adtinuation as a free \nvariable. The choose operator requires polling, since we need to see which (if any) base events are immediately \navailable for synchronization. Thus, the imple\u00admentation of an event value is a list of base events, \nwith each base event represented by a polling function, a function to call for immediate synchronization \nand a function for block\u00ading. The implementation of a precursor to CML is described in detail in [Rep89]. \nThe support of POI. 1 requires grouping base events that are being polled as a group. Note that pol. \nI has the property that the event poll (poll ev~) is equivalent to wrap (poll etil, SOME) We use this \nproperty to collapse nested applications of poI. 1. The implementation of guard is straight forward: \na guard event value is represented by the guard function, when sync is applied to a guard event, the \nguard function is evaluated. This forcing is recursive, since a guard function might return a guard event. \nWhen a combinator, such as wrap, is applied to a guard event, the suspension is just pulled up one level. \nFor example, the guard case of the wrap implementation is fun wrap (GUARD g, f) = GUARD (fno => wrap \n(go, f)) I wrap ... where GUARD is the internal representation s constructor for guard events. The application \nof choose to a guard event is a little more tricky, since multiple guards maybe involved. The most difficult \nCML feature to support is wrapAbort. If wrapAbort is applied to a choice of several events, then, at \nsynchronization time, we must invoke the abort function if, and only if, none of the events was selected. \nWe handle this by supplying an abort function for each element of the choicer with one designated as \nthe leader. When invoked, the other abort threads send the leader a message; if the leader collects messages \nfrom all of the other threads, then it evaluates the abort function. The abort function will be evaluated \nif, and only if, all of the abort threads are invoked. The implementation consists of about 1,380 lines \nof com\u00admented code. This breaks down into: 810 lines to implement threads, channels, events, low-level \n1/0 support and pre\u00ademptive scheduling; 430 lines to implement the stream 1/0 libra~; and 140 lines to \nhandle initialization and termination. In addition, there is a small library of useful abstractions, \nsuch as buffered channels. Performance 5.2 Garbage collection overhead Providing a better notation for \nprogrammin~ is not enough; it must be efficient enough that users will be willing to write major systems \nin it. To a great extent, SML/NJ has met this goal as an implementation of a high-level language[AJ891. \nOur benchmark results show that CML maintains this stan\u00addard. 5.1 The benchmarks We have conducted a \nseries of benchmarks on three different machines (see table 2). Each benchmarked operation was per\u00adformed \n100,000 times; the loops were unrolled ten times to reduce loop overhead, For each benchmark, we give \nthe com\u00adbined user and system CPU time and the time spent garbage collecting. All times are in micro-seconds. \nThe benchmarks were run using version 0.67 of SML/NJ and version 0.9.3 of , CML. The first set of benchmarks \n(see table 3) measures the cost of some basic operations: Null function call This measures the time required \nto call the null function; this operation is about 12 instructions on the SPARC. Because of the compiler \ntechnology used by SML/NJ the cost of this operation depends heavily on the calling context; if there \nare many registers to be saved, then the cost will be higher. Thread switch This measures the cost of \nan explicit context switch. T bread spawn/exit This measures the time it takes to spawn and run a null \nthread, which includes the cost of two con\u00adtext switches (the spawn operation switches control to the \nnewly spawned thread and a terminating thread must dis\u00adpatch a new thread). Rendezvous This measures \nthe cost of a send/accept ren\u00addezvous between two threads. Event rendezvous This is an implementation \nof the rendez-VOLIS benchmark using transmit/receive and sync. The second set (see table4) measures the \ncost of several differ\u00adent implementations of a simple service. The simple service is essentially a memory \ncell; a transaction sets a new value and returns the old value. The implementations are: Function call \nThis is the sequential implementation, which uses an own variable to keep track of the state between \ncalls. RPC This uses a request/reply exchange implemented using send and accept. Event RPC This implements \nthe request/reply exchange as an event value. The high garbage collection overhead in these benchmarks \nis mostly a result of the way the current SML/NJ collector, which is a simple generational collector, \nkeeps track of in\u00adtergenerational references 1APP891.Each time a mutable object is updated, a record \nof that update is added to the store-list. This store list is examined for potential roots at the begin\u00adning \nof each garbage collection. The implementation of CML uses a small number of very frequently updated \nobjects: the thread ready queue, current thread pointer and channel wait\u00ading queues. This hot-spot behavior \nis the worst-case sce\u00adnario for SML/N~s collector, destroying the 0( ILIVEI ) nor\u00admally expected from \ncop ying collection. The collector also suffers from the problem of poor real-time responsiveness. We \nhave designed a new, multi-generational, collector for SML/NJEReP91al, which uses the page-protection \ntechniques of [Sha871 and [AEL88] to implement the write barrier. This new collector improves the performance \nof CML in two ways: the hot-spot update behavior only incurs a constant cost for garbage collection and \neliminating the store-list reduces the frequency of garbage collection and the cost of update opera\u00adtions. \nAn instruction count analysis predicts a 25% reduction in the cost of a CML context switch. Unfortunately, \nat the time of this writing (March 1991), the new collector is not stable enough to run the CML benchmarks. \n 5.3 Analysis We have noticed a discrepancy between the measured times and instruction counts on the \nSPARC processors. For exam\u00adple; a CML thread switch takes about 100 instructions, which suggests an average \nof W5 cycles per instruction (CPI) on the SPARCstation 1. The SPARCstation 1 has a write-through cache, \nwhich we suspect is causing this high CPI figure. For the DECstation, the number is around 2 CPI, which \nseems more reasonable, The measurements show that the penalty for using abstract interfaces (i.e., hiding \nchannel communication in event val\u00adues) is acceptable. Table 5 gives the ratio between the non-GC time \nof the event version and the non-event version of the two communication protocols we benchmarked. These \nnumbers demonstrate that we can build real system software using our high-level notation, without paying \nan unacceptable performance penalty. With specialized com\u00ad Machine Processor Memory Operating System \nSPARCstation 1 20 MHz SPARC 28Mb SunOS 41.1 Sun 4/490 33 MHz SPARC 32Mb SunOS 4.0.3 DECstation5000/200 \n25 MHz R3000 16Mb ULTRIX 4.1 Table 2: Benchmark machines n Operation I SPARC 1 I Sun 4/490 I DEC 5000 \n11 time (@ ) GC (uS) tune (@) GC (L&#38; ) time (@ ) GC (pS ) Null funchon call 1.9 0 1.0 0 0.7 0 Thread \nswitch 26 8 13 4 8 7 Thread spawn/exit 85 13 38 7 22 12 Rendezvous 94 19 45 12 27 18 Event rendezvous \n163 24 77 14 44 22 Table 3: Basic concurrency operation benchmarks n Machine I Event cost: non-event \ncost n Table 5: Cost of abstraction piler support, such as a dedicated register for the thread ready \nqueue, performance would improve substantially. 5.4 Comparison with the pSystem Lastly, to put our measurements \ninto perspective, we im\u00adplemented a similar (allowing for linguistic differences) set of benchmarks in \nthe ~System, which is a C light-weight process library tBs901. We ran these benchmarks on the same machines; \nthe results are reported in table 6. The times are n Operation I Time (uS) II SPARC 1 Sun 4/490 DEC 5000 \nNull function call 0.3 I 0.2 ] 0.4 Task switch 131 I 54.3 I 9.6 uL Task create 371 126 46.6 Send/receive \n292 119 27.7 Send/receive/reply 308 123 28.4 Table 6: @ystem benchmarks given in micro-seconds and represent \nthe sum of the user and system CPU times; obviously there is no garbage collection overhead. Even though \nthe pSystem provides a lower-level concurrency model (no selective commumcation, for exam\u00ad ple), and \nis implemented in a lower-level language, CML provides as good or better performance, This shows that \nwe can have the advantages of the higher level language without sacrificing performance; a rare situation \nindeed, 6 Related work There are many approaches to concurrent language design (see [AS83] for an overview); \nour approach is an offshoot of the CSP-school of concurrent language design. CML be\u00adgan as a reimplementation \nof the concurrency primitives of PMLIReP881 in SML/NJ, but has evolved into a significantly more powerful \nlanguage. PML in turn was heavily influ\u00adenced by amber [cwgq. There have been other attempts at adding \nconcurrency to various versions of ML. Most of these have been based on message passing ([Ho183], [Mat89], \nand [Ram90] for example), but there is at least one shared memory approachLcM901. As we have shown in \nthis paper, message passing fits very nicely into SML. It allows an applicative style of programming \nto be used most of the time; the state modifying operations are hidden in the thread and channel abstractions. \nCML extends the message passing paradigm by making synchronous operations first-class, which provides \na mechanism for building user-defined synchronization ab\u00adstractions. While this idea was first proposed \nin [Rep881, we have made several sigmficant improvements: CML improves the event type in several ways, \nThe pol 1 operation provides a cleaner semantics than the PML polling mechanism, and the wrapHandler \noperation pro\u00advides needed support for writing wrappers. The guard and wrapAbort operations are important \nnew features that allow substantially more sophisticated protocols to be implemented as events. Because \nCML is implemented in SML, objects such as threads, channels and the scheduling queue are heap al\u00adlocated. \nThis has two advantages: threads cannot over\u00adflow fixed-size stacks (a common problem in many thread \npackages), and the memory resources used by threads and channels are reclaimed by the garbage collector. \nThe latter is heavily exploited in CML programs (see section 2.2). CML threads are significantly lighter-weight \nthan those of most threads packages. Because the memory overhead of CML threads is very small (tens of \nbytes compared to kilo-bytes for PML), a more profligate use of threads is Operation function call RPC \neventRPC time SPARC 1 (PS) GC (PS) 4.8 197 3! 252 35 Sun 4/490 time (uS) GC (wS) 2.3 0 92 20 117 20 DEC \n5000 time (IA ) GC (PS) 1.5 0 54 32 63 33 Table 4: RPC protocol benchmarks possible. CML m-ovides intetmated \nsutmort for both low-level and strea~-based 1/0. - Our implementation techniques are not particularly \nnovel. The use of timers to implement pre-emption is an old tech\u00adnique used by most threads packages, \nand the use of first\u00adclass continuations to implement concurrency goes back, at least, to [Wan80]. A \nnumber of papers have been published on the use of first-class continuations to implement con\u00adcurrency \nin scheme (e.g., [Wan801, [HFW841 and [DH891), but we break new ground in a couple of ways: we de\u00adscribe \nthe implementation of first-class synchronous oper\u00adations using first-class continuations; we describe \na complete language for concurrent programming and its use; and we provide performance figures. The one \npublished applica\u00adtion of continuation-based concurrency in scheme (which we know of) claims that most \nscheme implementations do not implement continuations efficiently enough to support this use of concurrency \nlHaa9q (the techniques of [HDB901 may address this problem). Our performance numbers and ex\u00adperience \nin-the-field suggest that the opposite is true for CML. Using concurrency to implement interactive systems \nhas been proposed and implemented by several people. In [RG86] we made the argument that concurrency \nis vital for the construc\u00adtion of interactive programming environments. [Pik891 and [Haa90] describe \nexperimental window systems built out of threads and channels, but neither of these were fast enough \nfor real use. Conclusions We have described ahigher-orderconcurrent language,CML, and its use in real-world \napplications. CML supports first\u00adclass synchronous operations, which provide a powerful mech\u00adanism for \ncommunication and synchronization abstraction. Our experience with CML in-the-field and our measure\u00adments \nof the performance of the implementation show that CML is a practical tool for building real systems. \nWe feeJ that CML is unique in that it combines a flexible high-level notation with good performance. \nCML is a stable system, and is freely available for distribution. The latest version of both CML and \nits manual are available via anonymous ftp from cs, come 11. edu; for more infor\u00ad mation send electronic \nmail to: cml bugs@cs. cornell. edu Acknowledgements The work on eXene has benefited greatly from the \ncontribu\u00ad tions of Emden Gansner; in the form of both source code and suggestions. Tim Teitelbaum provided \nuseful comments on various drafts of this paper. References [AB861 Abramsky S. and R. Bomat. Pascal-m: \na language for loosely coupled distributed systems. In Paker, Y. and J.-P. Vequs, editom, Distributed \nComputing Systems, pp. 163\u00ad 189. Academic Press, New York, NY., 1986. [AEL88] Appel, A. W., J R. Ellis, \nand K. Li. Real-tune concurrent collection on stock multiprocessors In Proceedings oj the SIGPLAN88 Conference \non Programming Language Design and Itnplemenfation, June 1988, pp. 11 20. [Agh86] Agha, G. Actors: a \nModel of Concurrent Cotnputation in Distributed Systems. The MIT Press, Cambridge, Mass., 1986. [AJ89] \nAppel, A. W. and T. Jim. Continuation-passmg, closure\u00adpassing style. In ConferenceRecord ofthe16thAnnual \nACM Symposium on Principles of Programming Languages, Jan\u00aduary 1989, pp. 293 302. [AM871 Appel, A. W. \nand D. B. MacQueen. A standati ML com\u00adpiler. In Functional Programming Languages and Computer Architecture, \nvolume 274 of Lecture Notes in Computer Sci\u00adence.Springer-Verlag, September 1987, pp. 301 324. [App89] \nAppel, A. W. Simple generational garbage collection and fast allocation. Software -Practice and Experience, \n19(2), February 1989, pp 275-279 [AS83] Andrews, G. R. and F. B. Schneider. Concepts and no\u00adtations for \nconcurrent programming. ACM Computing Surveys, 15(1), Ma~h 1983, pp. 3-43. [BCJ+ 90] Birman, K,, R. Cooper, \nT. A. Joseph, K. MarzuUo, M. Mak\u00adpangou, K. Kane, F. Schmuck, and M. Wood. TheLSIS sys\u00adtem manual, version \n2.0. Computer Science Department, Cornell University Ithaca, NY 14853, March 1990. [Bor86] [BS91JI [Bur88] \n[Car861 [CM901 [CP85] [DH891 [DHM91] [Haa90] [Har861 [HDB901 [HFW84] [H0183] [KKR+ 86] [LCJS87] [ e86] \n[ S88] [Mac84] [Mat89] Bornat, R. A protocol for generahzed occam. So@are Practice and Experience, 16(9), \nSeptember 1986, pp. 783\u00ad 799. Bnhr, P A and 1?,A Stroobosscher The ~system Provid\u00ading light-weight concurrency \non shared-memory multi\u00adprocessor computers runmng urux Software -Practice and Experience, 20(9), September \n1990, pp 929-963 Burnsr A. Programming in occam 2. Addison-Wesley Read\u00ad ing, Mass., 1988, Cardelh, L. \nAmber In Corrcbinators and Furccfional Pro\u00adgramming Languages, volume 272 of Lecture Notes itz Com\u00adputer \nScience, Springer-Verlag, July 1986, pp. 21-47, Cooper, E. C. and J G. Morrisett. Adding threads to standati \nML Technical Report CMLI-CS-90-I 86, School of Computer Science, Carnegie Mellon Umversity, Decem\u00adber \n1990. Cardelh, L. and R, Pike. Squeak a language for com\u00admumcatmg with mice, In SIGGRAPH 85, July 1985, \npp. 199-204. Dybvlg, R K and R Hieb Engines from continuations Conzputi~zg Languages, 14(2), 1989, pp \n109-123. Duba, B,, R, Harper, and D. MacQueen. Type-checking first-class continuations In Conference \nReco?d of the 18th Annual ACM Symposium on Principles of Programming Lan-Suages, January 1991, pp 163-173, \nHaahr, D. Montage: breaking windows mto small pieces In LLSENfX Summer Conference, June 1990, pp. 289-297, \nHarper, R Introduction to standard ML Technical Report ECS-LFCS-86-14, Laboratory for Foundahons of Com\u00adputer \nScience, Computer Science Department, Edinburgh Umverslty August 1986. Hleb, R., R. K. Dybwg, and C Bruggeman \nRepresenting control m the presence of first-class continuations In Proceedings of the SIGPLAN 90 Conference \non Programming Language Design and Implementation, June 1990, pp 66-77 Haynes, C T., D. P. Friedman, \nand M, Wand. Continua\u00adtions and coroutines. In Conference record of tke 1984 ACM Conference on Lisp and \nFunctional Programming, July 1984, pp 293-298. Hohnstrom, S PFL: a functional language for parallel programmmg. \nIn Declarative programming workshop, Apml 1983, pp. 114-139, Kranz, D, R Kelsey J Rees, P. Hudak, I Philbin, \nand N Adams Orbit. &#38; optimizing compiler for scheme In Proceedings of the SIGPLAN 86 Symposium on \nCompiler Construction, July 1986, pp 219-233 Liskov, B , D Curtis, P Johnson, and R. Scheifter, Imple\u00admentation \nof argus In Proceedings of the 11th ACM Sympo\u00adsiunz on Operczt;ng System Principlesr November 1987, pp, \n111-122 Lieberman, H Using prototypical objects to unplement shared behamor m object oriented systems. \nIn OPSLA 86 Procccdings, September 1986, pp 214-223 Llskov, B and L Shrira Promises linguistic support \nfor efficient asynchronous procedure calls in distributed systems. In Proceedings of the SIGPLAN 88 Conference \non Programming Language Design and Implementation, June 1988, pp. 260-267, MacQueen, D, B Modules for \nstandard ML. In Conference record of the 1984 ACM Conference on Lisp and Functional Programming, July \n1984, pp 198-207 Matthews, D C J. Processes for Poly and ML, In Papers on Poly/ML, Technical Report 161. \nUmversdy of Cambridge, February 1989 [MTH90] Mdner, R, M Tofte, and R Harper, The definition of stan\u00addard \nML, The MIT Press, Cambridge, Mass, 1990 [Nye90] Nye, A Xlib programming manual, volume 1. OReilly &#38; \nAssociates, Inc, 1990 [Pik89] Pike, R. A concurrent window system, Computing Sys\u00adtems, 2(2), 1989, pp, \n133-153. [Ram901 Ramsey N Concurrent programming in ML Technical Report CS-TR-262-90, Department of Computer \nScience, Princeton University, April 1990 [Rep88] Reppy J. H Synchronous operations as first-class values, \nIn Proceedings of the SIGPLAN 88 Conference on Progranl\u00adming Language Design and Impkmentationr June \n1988, pp, 250-259, [Rep89] Reppy J, H, Fust-class synchronous operations m stan\u00addard ML Technical Report \n77789-1068, Computer Science Department, Cornell University, December 1989, [Rep90a] ReppK J. H. Asynchronous \nsignals m standatd ML, Teclz\u00adnical Report TR 90-1144, Computer Science Department, Cornell University \nAugust 1990, [Rep90b1 Reppy, J H, Concurrent programming with events -Tht concurrent ML manual, Computer \nScience Department, Cornell Umversltfi Ithaca, [Rep91a] Reppy J H. Two garbage University techincal report, \n[Rep91b] Reppy, J. H. Higher-order uter Science Department, NY, 1991 forthcoming, NY 14853, November \n1990 collecton for SML/NJ Cornell in preparation, 1991 concurrency. PhD thes~, Comp-Cornell University \nIthaca, [RG86] Reppy J. H. and E. R. Gansner, A foundation for pro\u00adgramming envuonmenti. In Proceedings \nof the ACM SIG-SOFT/SIGPLAN Software Engineering Sytnposium on Prac\u00adtical Software Development Environments, \nDecember 1986, pp. 218-227, [SG861 Schetier, R. W. andJ. Gettys, The X Transactions on Graphics, 5(2), \nApril window system 1986, pp. 79-109 ACM [Sha87] Shaw, R A Improving garbage collection performance in \nvirtual memory Technical Report CSL-TR-87-323, Com\u00adputer Systems Laboratory, Stanfod University, 1987. \n[Ste78] Steele thesis, Jr., G. L. Rabbit: MIT, May 1978. a compiler for scheme, Master s [Wan80] Wand, \nM. Continuation-based ~_~Record of the 1980Lisp multiprocessing Conference, August In Con\u00ad1980, pp Appendix \n-A brief introduction to Standard ML This appendix gives a brief introduction to the major aspects of \nStandard ML. SML is formally defined in [MTH90]; for a tutorial introduction see [Har86]. It has the \nfollowing impor\u00ad tant characteristics: SML is a higher-order language: functions are first-class values. \nSML is strongly typed: every expression has a type, which is inferred by the compiler. There are no run-time \ntype errors. SML has a polymorphic type-system: the type of an ex\u00adpression inferred by the compiler is \nthe most general pos\u00adsible type for the expression. SML is Iexically scoped. 304 SML has a pattern matching \nfacility for decomposing struc\u00ad tured values. This facility is used in equational definitions of functions \nand in a generalized c a se-expression. SML has a powerful datatype mechanism: datatype dec\u00ad larations \nintroduce constructors that may be used to build values in expressions and to decompose values in patterns. \nSML has a type-safe exception mechanism. SML has a state-of-the-art module facility. A few examples illustrate \nmost of the features used in this paper. SML has a predefine list type constructor, which is defined \nby the declaration: dat atype a list = nil I :: of ( a r a llst) Infix : : The first line says that I. \ni st is a type constructor with two constructors: n i L which is the polymorphic empty-list, and ,, :: \n(pronounced cons). Constructors are use in expressions to build values, and used in patterns to destruct \nvalues. Note that type constructors are postfix operators (the a is a type variable), with the exception \nof two built-in constructors: -> for function types and * for tuple types. The second line declares : \n: to be an infix operator. Because lists are an important type, SML provides syntactic sugar for list \npatterns and expressions. The syntax [cl, .... e~l is syntactic sugar for el;:ez:: . . . ::en:: nil The \nlist reverse function uses this syntax for the empty list in its patterns: fun rev 1 = let fun rev ([], \n1) = 1 I rev (x::r, 11 = rev (r, x::l) in rev (1, [1) end The tail-recursive function rev is a function \nfrom a pair of lists to a list. It is defined equationally in two clauses. The first clause says to return \nthe second argument if the first is the empty list; the second clause is a tail-recursive call which \nconses the head of the first argument to the second. The function rev is polymorphic; it will work on \nlists of any type. Tail-recursion is the standard way to code loops in SML. A more complicated example \nis the following functional im\u00adplementation of polymorphic FIFO queues: abst ype a queue -Q of (front \n: a list, rear : a list) with fun queue ( ) = Q(front = [1, rear = []) fun insert (x, Q{ front, rear) \n) = Q { front == front, rear = x: :rear) exception EmptyQ fun remove (Q/front = [] , rear -[1 }) = raise \nEmptyQ I remove (Q{ front = [1 , rear)) = remove (Q{ f rent = rev rear, rear =-[1 )) I remove (Q{ front \n= x: :r, rear}) = (x, Q{ front = r, rear = rear)) fun head q=let val (x, _) -remove qin xend end (* abstype \n*) The syntax {i, = el, .... in = en} defines a labeled record, This syntax is also used in patterns \nto destruct record values. It is possible to abbreviate a labeled record pattern in two ways, as illustrated \nby the following example, The abbreviated pattern: (Q{ front, . ..)) is syntactic sugar for the pattern \n(Q{ front = front, rear = rear) ) This abst ype declaration defines a new type constructor, queue, together \nwith a collection of operations. A queue value is represented by the constructor Q applied to a record \nof two fields: f rent and rear, which are both lists. This declaration introduces the following bindings \ninto the envi\u00adronment: type a queue val queue : unit -> r a queue val Insert : a * a queue -> a queue \nexception EmptyQ val remove : a queue -> a * a queue val head : a queue -> a Because this is an abstype \ndeclaration, the representation of a queue is not visible outside the declaration. The type un it is \nthe type with one member the empty tuple ( ) . SML/NJ provides first-class continuations as an experimental \nextensionIDM911. The interface is: type a cent val callcc : ( a cent -> a) -> a val throw : a cent -> \na -> b These are used in the implementation of CML to implement threads.   \n\t\t\t", "proc_id": "113445", "abstract": "", "authors": [{"name": "John H. Reppy", "author_profile_id": "81100590527", "affiliation": "Cornell University", "person_id": "PP14203935", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/113445.113470", "year": "1991", "article_id": "113470", "conference": "PLDI", "title": "CML: A higher concurrent language", "url": "http://dl.acm.org/citation.cfm?id=113470"}