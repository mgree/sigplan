{"article_publication_date": "05-01-1991", "fulltext": "\n Procedure Merging with Instruction Caches Scott McFarling Western Research Laboratory Digital Equipment \nCorporation 100 Hamilton Avenue Palo Alto, CA 94301 mcfarling@decwrl. dec.com (415)-853-6651 formerly \nat Stanford University Abstract This paper describes a method of determining which pro\u00adcedures to merge \nfor machines with instruction caches. The method uses profile information, the structure of the program, \nthe cache size, and the cache miss penalty to guide the choice. Optimization for the cache is assumed \nto follow procedure merging, The method weighs the benefit of removing calls with the increase in the \ninstruc\u00adtion cache miss rate. Better performance is achieved than previous schemes that do not consider \nthe cache. Merg\u00ading always results in a savings, unlike simpler schemes that can make programs slower \nonce cache effects are considered. The new method also has better perfor\u00admance even when parameters to \nsimpler algorithms are varied to get the best performance. 1 Introduction This paper presents a method \nof deciding which pro\u00adcedure calls should be merged to get the best perfor\u00admance on machines with instruction \ncaches. While pro\u00adcedure merging has been studied extensively, the choice of which procedures to merge \nhas remained unclear. In TheMIPS-X project has been supported by the Defense Advanced Research Projects \nAgency under contract NOOO14-S7-K-OS2S. Permission to copy without fee all or part of this material \nis granted provided that the copies are not made or distributed for direct commercial advantege, the \nACM copyright notice and the title of the publication and its date appear, and notice is given that copying \nis by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires \na fee and/or specific permission. @ 1991 ACM ()-89791 -428.7 /91/f) O05/()071 ...$l .50 II Proceedings \nof the ACM SIGPLAN 91 Conference on Programming Language Design and Implemantation. Toronto, Ontario, \nCanada, June 26-28, 1991. 1I 71 most studies, somewhat arbitrary parameters control the decision. Choosing \nthe right parameter involves a trade\u00adoff between the number of instructions executed and the size of \nthe program after merging. For most recent ma\u00adchine designs, the key cost of increasing program size \nis the impact on the instruction cache. This cost is reflected in the probability that the next instruction \nto be executed is not available in the instruction cache or the instruction cache miss rate. Procedure \nmerging can have both positive and nega\u00adtive effects on the instruction cache miss rate. As more procedures \nare merged, code size can increase expo\u00adnentially. The larger programs become, the less likely they are \nto fit the cache and the higher the miss rate. Alternately, merging can reduce the miss rate. Some procedures \nmay be smaller than the call itself. Merging such procedures reduces both the code size and the miss \nrate. However, code size is not the only important factor in determining the miss rate. For example, \nexpanding the amount of code that is never executed has no effect on the cache, Also, merging can reduce \nthe miss rate by improving program locality. Several recent papers have discussed methods of opti\u00admizing \nprograms for instruction caches [McF89, HC89a, PH90]. In this paper, optimization for the cache is as\u00adsumed \nfor two reasons. First, if the instruction cache miss rate is of concern, then programs should be opti\u00admized \nfor the cache. Second, a model of the change in miss rate expected from merging particular calls is needed \nto decide which calls to inline. After optimiza\u00adtion, the cache behaves much like an optimal cache. Here, \nan optimal cache refers to a cache that replaces the instructions used farthest in the future as in Belady \ns page replacement algorithm [Be166]. Optimal caches not only have ideal miss rates, they are also relatively \nsimple to model. For example, the placement of instruc\u00adtions in memory can be ignored. This paper proposes \nan accurate model of optimal caches which makes use of profile information and the structure of the program \nincluding both the call and flow graphs. This model is then used to guide procedure merging. Section \n2 discusses other work on procedure inlining. Section 3 discusses why the decision of which calls to \nmerge is complex. Section 4 describes the model for predicting miss rates. Section 5 uses the model to \npre\u00addict the benefit of merging any given call. Section 6 uses this to determine the set of calls to \nmerge. Section 7 shows that this new algorithm performs better than sim\u00adpler methods that do not explicitly \nconsider the cache. Finally, Section 8 summaries the contributions of this paper. Related Work Numerous \ncompilers implement procedure merging. This section highlights work that discusses the decision of which \nprocedures to merge. Scheifler [Sch77] studied a method of inlining proce\u00ad dures that used profile information. \nCalls were inlined in the following order: 1. procedures so small that inlining reduces overall program \nsize. 2. procedures with the highest ratio of dynamic calls to procedure size until an overall program \nsize limit is reached. 3. procedures called from only one site.  Scheifler justifies using heuristics \nby showing that com\u00ad puting the best procedures to merge is at least NP\u00ad complete. The program size limit \nis arbitrary since the algorithm has no way of trading off program size with the number of instructions \nexecuted. Ball [Bat82] considered how optimization might af\u00ad fect the benefit of doing a merge. Calls \nwith constant arguments may be better to merge since dead code can be removed and arithmetic performed \nat compile time. Ball also discussed inlining only parts of procedures or creating a specialized version \nof procedures to be called from severat sites with common characteristics. Richardson and Ganapathi [RG89a, \nRic90] compared procedure merging to optimization using interprocedural data flow analysis. They showed \nthat the primary gain from procedure merging is primarily from removal of calls and returns. The savings \nfrom merging is largely orthogonal to optimization savings. Using this fact, they propose optimizing \nbefore merging to reduce the execu\u00ad tion time of optimization. Davidson and Holler [DH88, DH89] implemented \na source to source procedure inliner for the language C. Deeply nested calls are inlined first. Inlining \nstops when there are no more registers available to hold the vari\u00adables assigned to registers by the \nprogrammer. If user assignments are ignored, inlining can slow the program down without a sophisticated \nregister allocation pass. The authors found that the main benefits from inlining come from the removal \nof call and return instructions,  parameter movements,  e stack adjustments, and register saves and \nrestores around calls. Chow [Cho83, Sch83] showed that other optimiza\u00adtion are largely independent of \nmerging for a set of small benchmaks. The savings from both merging and optimization is close to the \nsum of each performed inde\u00adpendently. Steenkiste [Ste87] implemented a procedure merger that inlinedcalls \nto procedures smatler than a size thresh\u00ad old. As the threshold was increased, code size increased roughly \nexponentially and the number of instructions ex\u00ad ecuted decreased logarithmically. Combining these two \neffects together, the overall performance went through a maximum improvement of 490. HWU and Chang [HC89b, \nCha87] implemented a pro\u00ad cedure merger that merged catls in decreasing order of the number of times \nthey were executed until the code size increase reached a threshold. For their set of bench\u00ad marks 59% \nof dynamic calls were removed for a code size increase of 1770. 3 Procedure Call Characteristics The \ndecision of which calls to merge depends on two factors: the dynamic manner in which procedures are called \nand the sizes of procedures. If procedures are typically called dynamically from only one place then \nthe decision of which call sites to merge is simple just merge the site that is frequently executed. \nMerging this call actuatly reduces the number of instructions that must be kept in the cache. This is \ntrue however many static calls to each procedure there are. Alternately, if most calls are to small procedures, \nthen the choice of which procedures to merge is again simple. Merging small procedures has little effect \non program size and thus all calls to smatl procedures could conceivably be merged. Unfortunately, neither \nof these simple properties exist in most programs, The set of benchmarks described in Table 1 will be \nused as examples. size (instr) I description bigfm 8231 I graph partitioning Ccal 11526 desk calculator \ncompare 10112 file comparison dnf 11411 logic normalization hopt 16767 compiler optimizer macro 33689 \nmacro expansion pasm 12332 assembler pcomp 35536 pascat compiler simu 18706 disk simulator upas 61795 \npascal front end Table 1: Benchmarks Used for Evaluation Figure 1 shows that most procedures are called \nfre\u00adquently from several sites. For each of the benchmmks, the dynamic distribution of calls is plotted \nagainst the dynamic fraction of calls to each procedure. Let cj,~ be the number of times the k th call \nsite to procedure j is executed. Let Tj = ~k Cj,k, the total number of dy\u00ad namic calls to procedure j, \nand T = ~j ,k cj ,k, the totat number of dynamic calls. Figure 1 plots the function: for each of the \nbenchmarks in Table 1. For any given fraction ~, only those calls are included which account for less \nthan or equal to $ of the calls to that procedure, For example, if each procedure is called from only \none site, then the curve would lie along the x-axis. If each procedure is called frequently from a very \nlarge number of sites, then the curve would follow the line y = 1. A simple program with one subroutine \ncalled the same number of times from two sites would have the distribu\u00adtion: (0 f<o.5 The distributions \nin Figure 1 vary widely between benchmarks. In one benchmark, 40% of the dynamic calls were the only \ncalls executed to their respective callees. However, most procedures are called frequently from multiple \nsites. Over atl the benchmarks, roughly 40% of calls are from sites that constitute less than half the \ncalls to the callee. This shows that if the majority of dynamic calls are to be removed, many procedures \nwill need to be duplicated and the duplicated code will be frequently executed. Figure 2 shows the dynamic \ndistribution of cake sizes for the set often benchmarks, Most calls are to relatively small procedures \nwith fewer than 100 instructions. How\u00adever, very few calls are to procedures as small as the call c .AI \nr := 0,0 0.2 0,4 0,6 0.8 1.0 Fraction of Dynamic Calls to Callee Figure 1: Distribution of Catls to Procedures \nc : 0.4 It 1 10 100 1000 10000 Callee Size (instr) Figure 2: Dynamic Distribution of Callee Size and \nreturn code. In combination with the observation of the previous paragraph, this means that merging will \nhave to increase both the static and dynamic code size to remove the majority of calls. If merging several \nlev\u00adels in the call graph is considered, the situation is even more extreme. Code size can increase exponentially. \nAn ideal merging algorithm must consider both the size and frequency of procedures to get the best results. \n  4 Miss Rate Model for Merging We begin the description of anew method of determining which procedure \ncalls to merge by presenting a model of how instruction caches behave after optimization. In the model, \na single number is calculated for each loop that gives the average size of each loop iteration. Each \ninstruction executed within a loop adds to the average by min ( 1, j) where ~ is the average number of \ntimes the instruction is executed per loop iteration. When ~ < 1, 30 ~ L oi 2345 Miss Rate(%) (S=2048 \nmstr) Figure 3: Prediction Accuracy by Benchmark each instruction adds t to the average loop iteration \nsize. When .f > 1, each instruction adds only one word to the average because each instruction needs \nat most one cache location no matter how many times per iteration it is executed. The average loop iteration \nsize can be used to estimate the number of misses. With cache optimization, each cache location can usually \nhold one useful instruction just like an optimal cache would, If the loop size is larger than the cache, \nthe surplus instructions miss. If an instruction fits in the cache, it hits when repeated. Whether an \ninstruction misses the first time it is executed in a loop depends on whether there is space to keep \nin the cache for the duration of the next outer loop. If the current loop is outermost, the first execution \nalways misses. This analysis leads to the estimate of misses for each loop given in Equation 2. (1) M \n{ = max(O, 1 l)max(O, sl S) (2) where S[ : effective loop body size sb : basic block size f: average \nfrequency block is executed per loop iteration Ml : number of misses per loop instance 1; average number \nof loop iterations s: cache size Figure 3 shows how well the model predicts miss rates for an optimal \ncache for the set of benchmarks described in Table 1 for a cache size of 2048 instructions, For most \nbenchmarks, the average loop size model is quite close. Figure 4 shows the miss rate prediction accuracy \nfor various cache sizes using the average across the ten benchmarks. Again, the prediction is quite close. \n$ 25 o optimal, measured w x optimal, prediction ~ gy3 k 15 10 5 i\\ oLLuJb44 128 256 512 102420484096819216384 \nCache Size (instr) Figure 4: Prediction Accuracy by Cache Size  5 Modeling Merge of One Call Merging \na single call affects performance by reducing the number of instructions executed, and by changing the \ninstruction cache miss rate. The change in the number of instructions executed has several causes: 1.removal \nof call and return code, 2. removal of loads and stores of parameters. 3. opportunities for optimization \nacross procedure boundaries.  Accurate prediction of all these effects is complex. For example, Ball \n[Ba182] spent considerable effort just calculating the degree inlining procedures with constant parameters \nenables additional optimization. However, for the MIPS-X architecture [HCe87], the removal of call and \nreturn code tends to dominate the other fac\u00adtors. Richardson and Ganapathi [RG89bl along with Davidson \nand Holler [DH88] found similar results for other mchitectures, Thus, a simple estimate can be used based \non the typical number of instructions eliminated for each removed call. More complex estimates would \nproduce better results, but this simple method is suffi\u00ad cient to demonstrate the usefulness of considering \nthe cache during procedure merging. To estimate how merging changes the instruction cache miss rate, \nthe loop average size model described in the previous section can be used. Usually, merging a procedure \nincreases code size. To see how this affects the miss rate, the new average sizes of the loops contain\u00ading \nthe call are computed. The new sizes can then be substituted into Equation 2 to calculate the new number \nof misses for each loop. If the procedure to be merged is frequently called from only one place, then \nthe average sizes will be reduced by the amount of the call and return code. If the merged procedure \nis called from multiple corresponds to a small increase in the loop body size as calculated by the model. \nUnless the called procedure is huge, the reduction in the number of call and return instructions executed \nwill more than compensate for any .01 additional cache misses. Ah() Figure 5(c) shows a loop that contains \ncalls to proce- AA dures A and B with B called from one site and A called (a) (b) AA AB AB (c) (d) PB \nA (e) Figure 5: Example Merge Decisions sites, then some of the loop sizes may increase and the model \nwill predict more misses. Whether a given call should be merged depends on what else is in the loops \nthat contain it. Figure 5 shows several examples of how these fac\u00adtors can affect whether or not a merge \nis beneficial. In the figure, circles represent loops, A and B represent procedures, and the arcs represent \ncalls and lexical nest\u00ading. Figure 5(a) shows a procedure called only once in each loop it is in. Merging \nsuch a call will always in\u00adcrease performance because the number of instructions that need to be kept \nin the cache over any loop lifetime is decreased, Similarly, merging is always beneficial if there is \nonly one catl to a procedure or if only one call is ever executed. Figure 5(b) shows a procedure called \nfrom two places in a loop. One call is executed on every iteration and the other is rarely executed. \nIf both calls are merged, the procedure body from the frequent call will need to be in the cache every \niteration. This corresponds closely to the need to keep the original procedure in the cache each iteration. \nThe code from the rare call will demand additional space in the cache, but very infrequently. This from \ntwo sites. Merging B is always worthwhile since this merge reduces the size of the program. Whether A \nshould be merged depends on the sizes of the procedures relative to the size of the cache. If the loop \nbody will fit in the cache even if procedure A is duplicated, then clearly A should be merged. If A is \nlarge and the cache is already full, then A should not be merged since each copied instruction will miss \non each loop iteration. In Figure 5(d), procedures A and B are called from two sites within a loop. Whether \nor not either procedure should be merged depends on the their sizes and the size of the cache, Since \nthe savings in instructions ex\u00adecuted from merging either procedure is approximately the same, it is \nusually better to merge the calls to the smaller procedure first. Subsequently, if there is still space \nin the cache, the calls to the other procedure should be considered. As described in Section 6 in more \ndetail, smaller procedures should be considered for merging be\u00adfore larger procedures called the same \nnumber of times. In Figure 5(e), there are two calls to procedure A nested more deeply than a call to \nprocedure B. Whether or not A should be merged depends on the sizes of the procedures and the number \nof iterations of the inner loop. If procedure B will not fit in the cache if A is copied then the additional \nmisses in B must be weighed against the removal of instructions within the inner loop. This can be calculated \nusing the model from the average number of iterations of the inner loop, the sizes of A and B, and the \nsize of the cache.  6 Deciding What to Merge The previous section discussed how the benefit of merg\u00ad \ning a particular call can be calculated. This section describtk a method for using this knowledge to \ndecide which combination of calls to merge. The problem is dif\u00ad ficult because the decisions for each \ncatl interact. Merg\u00ad ing one call affects how much space is left in the cache and how often other calls \nare executed. From the knap\u00ad sack problem, it can be shown that finding the best set of procedures to \nmerge is at least NP-hard. In addi\u00ad tion, merging one procedure causes the calls within the merged procedure \nto be copied. Deciding whether these new calls should be merged further complicates the prob\u00ad lem. Algorithm \nMergeDecision in Figure 6 shows a greedy Procedure MergeDecision begin while more calls pick aCall with \nhighest (call frequency/callee size) savings := aCaI1.timesCalled * CostOfCall; cost:= addltionalMisses \n* CostPerMiss; if savings < cost then Mark aCall to be merged update data structures end; end, end MergeDecision \nFigure 6: Merge Decision Algorithm using Loop Model algorithm for making the decisions. The calls are \nde\u00adcided in decreasing order of the frequency of the call divided by the average size of the called procedure. \nIn other words, calls are considered in decreasing order of the expected path length savings versus the \namount inlining might increase demand for the cache. Small frequently called procedures are considered \nfirst. Each loop that contains the call is analyzed to determine the expected change in the number of \nmisses. The change in misses is then weighted by the miss penalty or cost of each miss and compared with \nthe expected savings in path length to determine whether merging the call will be beneficial. If the \nmodel recommends merging the call, the representation of the program is modified to reflect the situation \nafter inlining. If the callee has internal calls that have not been considered for merging, both the \norig\u00adinal call and the new copy are placed on the undecided list. Any calls already decided keep their \ncurrent status. Finally, the duplication of the inlined procedure body may create new loops. These loops \nare analyzed during any future merge decisions. Evaluation This section shows that using the loop average \nsize model can increase the benefits of procedure merging. Again, the set often benchmarks described \nin Table 1 are used as the basis for the evaluation. For comparison, two simple methods of deciding which \nprocedures to merge are considered. The first does not use profile information at all, just the sizes \nof procedures. With this method, all calls to procedures with sizes less than a threshold are merged. \nThe second method uses both the size of the callee and the number of times each call site is executed. \nCalls are merged when the ratio of the number of calls to the size of the procedure exceeds a threshold \nvalue. This method is similar to that used by Scheifler [Sch771 except there merging continued until \na target code size increase was reached. Figure 7 shows the average reduction in execution time from \nmerging across the ten benchmmks using both the loop average size model and the size and ra\u00adtio threshold \nmethods for a range of cache miss penal\u00adties. The cache here is direct mapped with the ability to exclude \nsome instructions from the cache, optimized as described in [McF89], and able to hold 2048 instruc\u00adtions. \nFigures 8 and 9 split the performance change into the path length and miss rate components respectively. \nThe average loop size method uses the miss penalty to decide which procedures to merge. The threshold \nmeth\u00adods do not. The best threshold to use for a particulm miss penalty varies. If the penalty is high, \nthen a threshold that merges fewer calls produces a better result. With the loop average size model, \nmerging is more successful than either threshold method with any threshold value. Figure 8 shows that \nas the miss penalty increases, the loop average size model will suggest fewer procedures be merged. As \nFigure 9 shows, this results in progres\u00adsively fewer misses as misses get more expensive. With the threshold \nmethods, the miss rate and the path length are independent of the miss penalty. As the miss penalty increases, \nthe improvement with the threshold methods decreases until the programs are actually substantially slower. \nFigure 9 also shows that unmerged code has a lower miss rate than that of any of the merging de\u00adcision \nmethods considered here. Of course, the higher miss rate is more than made up for with fewer instruc\u00adtions \nexecuted when merging with the loop average size model, As Table 2 shows, a ratio threshold of 2 gives \nabout the same amount of merging as the loop model with a miss penalty of one cycle in terms of the increase \nin code size. Figure 8 shows that the resulting savings in instructions executed is also close. However, \nthe miss rate obtained using the cache model is lower. With the procedure size method, a smaller reduction \nin the number of instructions executed results in a 5570 code size increase. The resulting miss rate \nis substantially higher as well. Merging using the loop model resulted in an increase in code size of \nonly 1470. A small increase is preferable because it minimizes storage costs and the time required to \ncompile the merged code. Again, the primary execution time penatty of increased code size is in the instruction \ncache and as atready shown, the removal of calls more than makes up for this. Figure 10 compares the \nloop model improvement to that with a ratio threshold of 2 for a range of cache sizes with a miss penalty \nof one cycle. The loop model is bet\u00ad ter across most of the cache size range. While the overall amount \nof merging is roughly the same, the loop model 0 0 loop model 0- o ratio >2 A  A ratio >4 o---o ratio \n>16 u- n ratio >256 .... . ...0 o size <400 A..........A size c 200 .......... 0 5 0 o size c 100 \n0 ..........0 size c 50 -5 -lo -15 II ,.I -20 J 124 816 Cache Miss Penalty (cycles) Figure 7: Merging \nSavings with Increasing Miss Penalty (S=2048 instr) o 0 loop model -e -e  -e  -c  a) I-- A - \nA  [ 0- o ratio >2 x h A  A ratio >4 v ._ ._. . _. ._., &#38;.. _.. _.. _.. +_.. _.. _.. _..&#38;. \n_.. ___ &#38; o- 0 ratio >16 c 0 - a ratio >256 5 10 . ................ ................. .........,. \n,..A, ,., ., .,.,.,..1 0 .........0 A A.,. ,,, size c 400 aJ A,. ,., .,, ,.A size e 200 z ~............... \n.0.................o .................o ................< i% 0 ..........0 size <100 l................a \n..............a .. ..............a .. ..............c csize <50 CL 0 .. .. .. .. ..0 .\u00adc5,g o + Q \n+  [ 3 $ I o~ 16 Cache Miss Penalty (cycles) Figure 8: Merging Decrease in Pathlength for Increasing \nMiss Penalty (S=2048 instr) 8 o o loop model J_................0-... -..........0..... ..........0 ..............< \no- o ratio >2 A  A ratio >4 F - - * - -- - - - - *- - - - o---o ratio >16 . .. G................ \nQ............. ...4 0  a ratio >256 -..-..-.,%,-..0 . . . . . . . ...0 a~..-..-..-.$ size c 400 .......... \nA A size c 200 :E+===== 0 .........0 size c 100  0 ..........a size <50 0 n unmerged  2 t Cache \nMiss Penalty (cycles) Figure 9: Miss Rate with Merging for Increasing Miss Penalty (S=2048 instr) ;ize \n<400 ratio> 2 oop model bigfm 1.29 1.08 1.08 ccal 1.59 1.27 1.32 compare 1.38 1.13 1.18 dnf 1.20 1.07 \n1.03 hopt 2.15 1.14 1.10 macro 1.07 1.07 1.04 pdsm 1.50 1.24 1.23 pcomp 1.57 1.07 1.03 simu 1.96 1.27 \n1.32 upas 1.77 1.04 1.05 average 1.55 1.14 1.14 Table2: Relative Code Size Increase (S=2048instr, miss \npenalty=l cycle) E OLLu4J u 128 256 512 102420484096819216384 Cache Size (instr) Figure lO: Merging Savings \nby Cache Size better finds calls that reduce the number of instructions executed with fewer additional \nmisses. However, for very small caches, the ratio method is slightly better, When miss rates are very \nhigh an implicit assumption in the loop model becomes invalid. If a procedure is called multiple times \nwithin a loop then an optimal cache will typically keep it in the cache because of its importance. Merging \nsuch a procedure results in other procedures being forced out of the cache for loops lager than the cache \nsize. This effect is accounted for in Equation 2. However, if the cache size is very small, even the \npro\u00ad cedures kept out of the cache may be executed multiple times per iteration. Merging such a procedure \nincreases the size of the loop but does not result in any additional misses since the procedure always \nmisses anyway. Pro\u00ad cedure mergers for machines with a very small caches, should add this effect to the \nmodel. Since the loop model uses profile information, it is sensitive to how close the programs behave \nfor different different profile ,.,.,,,.,,,, ,,,,,, same profile bigfm ,,,:.,,,:,,,,...,,,,, ccal ,.,,,,,,,,,,,,,,,.,,,.,.,.,,,,,.,.,,,,,.,.,.,.,.,.,.,....,,.,.:.:,;.:,,,,.;...,,:...,., \ncompare :,.,.,.,.,.,.,.,.,.,.,.,.,.,.,., ,.,.,.,.,.,.,.,.,.,.,.,., dnf .,,.,,.,,,,!:,:.?:,,! .,,,,,!,.!,,,hopt \n,,.,,,,., ,.,,,,,,.,,,.,.,,,,,.,.,.,.,.,.,.,,.,,.,.,,,.,.,.,,,.,..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.;.,,~,.;.,.,,,. \nmacro .,,,.,.,,,,,.,.,.,,,,,.,.,.,.,,!.#.,.!.,,!.,,,,#,,,,,,...,,.,.,,.,. ,,,,.,, pasm pcomp !.,!,.,.,./,,.,.J.,..,.,.t.,.,.,.,,.,.,.,.,.,.,.,.,.,.,.,.,.,!,...,... \nsimu ,.,,.7,,,.,..,.,,,,.,.., upas ..,,...,.,.,.,,..,.,.,.,,, ,,,,,,,,,.,.,,,,,.,,, average %.,.,.,.,.,.,.,.,.,.,. \n.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,., + I I I O 5 10 15 20 25 30 Improvement in Performance (%0) \nFigure 11: Merge Savings with Different Profile inputs. Figure 11 shows how the results match when two \ndifferent sets of inputs for each benchmark are used to guide the merger and each benchmrwk is run with \none of the two inputs. As the figure shows, merging is fairly insensitive to changes in the profile data. \nMost of the performance gain remains when the profile information comes from a different set of inputs. \nThis is not true where one set of inputs exercised a completely different part of the benchmark than \nthe other. For best results, the profile information for each program should be collected from several \nruns that accurately reflect how the program is used in practice. 8 Conclusion This paper has shown that \nthe decision of which calls to merge is complicated because typical programs fre\u00adquently call large procedures \nfrom multiple sites. Thus, if most catls are to be removed, increased code size and additional instruction \ncache misses are unavoid\u00adable. A method of choosing which procedures to merge was given that improves \noverall performance consid\u00adering both program path length and the impact on the instruction cache. The \ntechnique is preferable to other methods because it does not use ad hoc thresholds, it improves performance \nacross wide ranges of cache sizes and miss penalties, and it produces better performance than algorithms \nthat do not model the instruction cache. 9 Acknowledgments I would like to thank John Hennessy for several \nuseful comments. I also thank Steve Richardson, Steve Tjiang and the rest of the MIPS-X crew for providing \nthe envi\u00adronment that made this work possible. References [RG89a] S. Richardson and M. Ganapathi. Interproce\u00ad \n[Ba182] [Be166] [Cha87] [CM331 [DH88] [DH89] [HC89a] [HC89b] [HCe87] [McF89] [PH90] J. E. Ball. Program \nImprovement by the $e\u00adlective Integration of Procedure Calls. PhD thesis, University of Rochester, 1982. \nL.A. Belady. A study of replacement algo\u00adrithms for a virtual-storage computer. ZBM Systems J., 5(2):78-101, \n1966. P. H. Chang. Aggressive code improving tech\u00adniques based on control flow analysis. Mas\u00adter s thesis, \nUniversity of Illinois at Urbana-Champaign, 1987. F. Chow. A Portable Machine-Independent Global Optimizer \n-Design and Measurements. PhD thesis, Stanford University, December 1983. J. W. Davidson and A. M. Holler, \nA study of a C function inliner. Software Practice and Experience, 18(8):775 790, 1988. J. W. Davidson \nand A. M. Holler. Subprogram inlining: A study of its effects on program execution time. Technical Report \nTR-89-04, University of Virginia, November 1989. W. W. Hwu and P, H. Chang. Achieving high instruction \ncache performance with an opti\u00admizing compiler. In Proc. 16th Syrn. on Com\u00adputer Architecture, Israel, \nMay 1989. W. W. Hwu and P. H. Chang. Inline function expansion for compiling C programs. In Pro\u00adceedings \nof the SIGPLAN 89 Conference on Programming Language Design and Imple\u00admentation, pages 246 257, Portland, \nOregon, June 1989. ACM. M. Horowitz, P. Chow, and et. al, MIPS-X: A 20 MIPS peak, 32-bit microprocessor \nwith on-chip cache. IEEE Journal of Solid-State Circuits, SC-22(5):790-799, October 1987. S. McFarling. \nProgram optimization for in\u00adstruction caches. In Proceedings of ASPLOS 111,Boston, MA, April 1989. K. \nPettis and R. C. Hansen. Profile guided code positioning. In Proceedings of the ACM SIGPLAN 90 Conference \non Programming Language Design and Implementation, pages 16 27, 1990.  dural analysis vs. procedure \nformation Processing Letters, August 1989. integration. ln\u00ad32(3): 137-142, [RG89b] S. Richardson and \nM. Ganapathi. Inter\u00adprocedurrd optimization: Experimental re\u00adsults. Software -Practice and Experience, \n19(2): 149 169, February 1989. [Ric90] S. Richardson. Evaluating Interprocedural Code Optimization. PhD \nthesis, Stanford Uni\u00adversity, 1990. To appear. [Sch77] R. W. Scheifler. An analysis of inline substi\u00adtution \nfora structured programming language. Communications of the ACM, 20(9):647-654, Sep. 1977. [Sch83] D. \nB. Schnepper. A Transporter s Guide to to the Stanford U-code Compiler System, chap\u00adter 8. Stanford University, \n1983. [Ste87] P. Steenlciste. LISP on a Reduced-Instruction-Set Processor: Characterization and Opti\u00admization. \nPhD thesis, Stanford University, March 1987.   \n\t\t\t", "proc_id": "113445", "abstract": "", "authors": [{"name": "Scott McFarling", "author_profile_id": "81100404297", "affiliation": "Western Research Laboratory, Digital Equipment Corporation, 100 Hamilton Avenue, Palo Alto, CA", "person_id": "PP31040794", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/113445.113452", "year": "1991", "article_id": "113452", "conference": "PLDI", "title": "Procedure merging with instruction caches", "url": "http://dl.acm.org/citation.cfm?id=113452"}