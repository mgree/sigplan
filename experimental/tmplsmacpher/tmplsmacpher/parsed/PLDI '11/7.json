{"article_publication_date": "06-04-2011", "fulltext": "\n Brainy: Effective Selection of Data Structures Changhee Jung 1 Silvius Rus 2 Brian P. Railing 1 Nathan \nClark 3 Santosh Pande 1 1Georgia Institute of Technology {cjung9, brailing, santosh}@cc.gatech.edu Abstract \nData structure selection and their tuning are one of the most criti\u00adcal aspects of developing effective \napplications. By analyzing data structures behavior and their interaction with the rest of the appli\u00adcation, \ntools can make suggestions for alternative data structures. Such a process is quite dependent on the \nexecution ef.ciency of the data structure on a given architecture. Consequently, develop\u00aders can optimize \ntheir data structure usage to make the application conscious of an underlying architecture and a particular \nprogram input. This paper presents the design and evaluation of Brainy, a new program analysis tool that \nautomatically selects the best data struc\u00adture for a given program on a speci.c microarchitecture. The \ndata structures interface functions are instrumented to dynami\u00adcally monitor how the data structure interacts \nwith the application for a given input. The instrumentation records traces of various runtime characteristics \nincluding underlying architecture-speci.c events. These generated traces are analyzed and fed into an \nof\u00ad.ine model constructed using machine learning; this model then selects the best data structure. That \nis, Brainy exploits runtime feedback of data structures to understand the situation an appli\u00adcation runs \non, and selects the best data structure for a given ap\u00adplication/input/architecture combination based \non the constructed model. The empirical evaluation shows that this technique is highly accurate across \nseveral real-world applications with various pro\u00adgram input sets on two different state-of-the-art microarchitectures. \nConsequently, Brainy achieved an average performance improve\u00adment of 27% and 33% on both microarchitectures, \nrespectively. Categories and Subject Descriptors D.2.3 [Software Engineer\u00ading]: Coding Tools and Techniques; \nD.2.5 [Testing and Debug\u00adging]: Diagnostics; D.3.3 [Language Constructs and Features]: Data types and \nstructures General Terms Languages, Algorithms, Performance Keywords Data Structure Selection, Application \nGenerator, Train\u00ading Framework, Performance Counters 1. Introduction Niklaus Wirth famously noted, Algorithms \n+ Data Structures = Programs [35], and it follows that one of the most critical as\u00adpects of creating \neffective applications is data structure selection. Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, USA. Copyright \nc &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 2Google Inc. 3Virtu Financial rus@google.com \nnclark@virtu.nancial.com Data organization is one of the de.ning characteristics in determin\u00ading how \neffectively applications can leverage hardware resources such as memory and parallelism. Indeed, it is \nnot uncommon to .nd situations where simply changing the data structures can result in orders of magnitude \nimprovement in application performance for many important domains. For example, scienti.c applications \nleveraging matrix inversion [3] and matrix multiplication [34], in\u00adformation mining from large databases \n[2], and analyzing genetic data for patterns [10], are instances of criticality of data structure selection \nin an application tuning process. According to [3], proper data structure selection can make the 2-D \ntable implementation used in that study 20 times faster. In one recent study, researchers at Google analyzed \nthe use of the C++ Standard Template Library (STL) [30] on several of their internal applications, and \nfound many instances where expert developers made suboptimal decisions on which data structures to use \n[17]. Simply changing a single data structure in one application resulted in a 17% speedup in that study. \nWhen applying this type of speedup to data-center-sized computations, poor data structure selection can \nresult in millions of dollars in unnecessary costs. Thus, selecting the appropriate data structures in \napplications is an important problem. However, the reality is that most often developers do not select \ndata structure implementations at all; they simply rely on a data structure library and assume that the \nlibrary designer made a good decision for them. Data structure libraries were designed to be effective \nin the common case, and often leave considerable room for improvement in application-speci.c scenarios. \nWhen developers do manually select a data structure implemen\u00adtation, they most frequently utilize asymptotic \nanalysis to guide their decision. Asymptotic analysis is an excellent mathematical tool for understanding \ndata structure properties; however, it of\u00adten leads to incorrect conclusions in real systems. For example, \ncomparing the STL set (implemented as a red-black tree) with unordered set (implemented as a hash table), \nthe set has worse asymptotic behavior but almost always has faster lookup times on modern architectures \nwhen holding fewer than 200 data elements. In other situations data structures have identical asymp\u00adtotic \nbehavior but very different real-world behavior. For example, splay trees [29] almost always perform \nbetter than red-black trees on real-world data though they have the same asymptotic complex\u00adity. Asymptotic \ncomplexity measures were designed as a uni.ed basis for comparing and choosing an algorithm and not data \nstruc\u00adtures. To a large extent, once an algorithm is chosen, attention is rarely paid to the choice of \ndata structures. This can leave substan\u00adtial inef.ciencies on the table. In short, traditional solutions \nleave much to be desired. Unfortunately, selecting the best data structure for a given situa\u00adtion is \na very dif.cult problem. This requires thorough understand\u00ading both of how a program uses a data structure, \nand of the under\u00adlying architecture. Even further, input changes can lead to different optimal data structures. \nThus, a tool that ignores inputs could not possibly make a high-quality decision for selecting the best \ndata structure. To ameliorate the data structure selection problem, this paper presents Brainy, an automated \ntool to develop a repeatable process for creating accurate cost models that predict the best data structure \nimplementation for a given application/input/architecture combination.  In order to construct an input-and \narchitecture-aware cost model, the model must be trained to understand the effect of ar\u00adchitectural behaviors \nwhile taking into account input changes. This is accomplished by .rst constructing a set of synthetic \nprograms that exercise different behaviors of a given data structure under consideration. For example, \nthe test programs will stress all of the data structures interface functions with modeling different \nin\u00adputs by varying data type sizes and various numbers of elements stored in the data structure. Then \nseveral measurements are col\u00adlected through hardware performance counters and code instru\u00admentation in \norder to understand how each data structure behaves. These measurements are then summarized into statistics \nwhich are then fed into a machine learning model. The machine learning model creates a function to accurately \ndetermine the optimal data structure choice for each static program variable. Machine learning characterization \nhas been shown repeatedly to be more effective than human designed models because machine learning picks \nup on subtle interactions human experts often miss [7, 16, 22, 31, 33]. This paper demonstrates that \nleveraging machine learning to gen\u00aderate cost models, which leverage architectural events and dynamic \nsoftware behavior, is signi.cantly more accurate than asymptotic analysis or human designed models for \ndata structure selection. This paper also demonstrates that using these models can result in signi.cant \nperformance improvements in real-world applications. Moreover such techniques are shown to be repeatable \nempirically on two different architectures across a variety of data structures. The vision of this work \nis that the synthetic program generation tool we have developed can be used to tune a cost model once \nfor each target system at install-time. These models can then be used either by a developer manually \n(e.g., as part of a performance debugging tool similar to Intel s VTune), or built into data structure \nlibraries so that the compiler or runtime can automatically select the best implementations for many \nusers of the libraries. Utilizing machine learning to automatically generate cost models for data structure \nselection is a fundamentally new way to analyze data structure behavior; this method is signi.cantly \nmore effective than the traditional asymptotic analysis. The contributions of this work include: A repeatable \nmethodology for characterizing the performance of data structures using architectural events and runtime \nsoft\u00adware properties of the application.  An analysis on what program and hardware properties are most \nimportant to consider when selecting data structure implemen\u00adtations on modern architectures. This paper \npresents several non-intuitive discoveries. For example, branch misprediction rate is a very useful predictive \nfeature.  An empirical demonstration of the machine learning model, compared with traditional hand-constructed \nand asymptotic methods. This paper demonstrates that considering perfor\u00admance counters and dynamic properties \ncan provide signi.cant improvements in application performance.  2. Motivation Effective data structure \nselection requires thorough understanding of how a data structure interacts with the application. Apart \nfrom the asymptotic behavior of data structures, a number of factors should be considered, such as what \ntypes of functions interact with the data, how many times the interface functions are invoked, how big \neach data element is, and so on. It is also important to take into account hardware behavior to understand \nthe effect of the underlying architecture on data structure related code. Given all this, identifying \na function that accurately predicts the best data structure implementation is very challenging. As an \nexample, assume that a developer is deciding between a vector and list data structure from the C++ Standard \nTem\u00adplate Library (STL) [30]. The former is a dynamically-sized array stored contiguously in memory and \nthe latter is a doubly-linked list. The developer might think that vector is almost always bet\u00adter than \nlist because its contiguous data layout better leverages spatial locality in memory hierarchies, and \nthe dynamically adjust\u00ading size will make tail insertions require fewer memory allocations than with \na linked list. In reality, vector is preferable in situa\u00adtions with frequent search or iteration over \ndata elements. However, data insertion into (or removal from) the middle of the structure is extremely \nexpensive for vector, since all data elements located after the insertion point must be moved backwards \n(or forwards) to maintain contiguity. The challenging issue is how to quantify the pros and cons of each \ndata structure to accurately compare them. For example, how many find or iteration operations are enough \nto overcome poor insertion and deletion times for vector to per\u00adform better than list? In some sense, \nwe are looking at perform\u00ading amortized analysis of different operations that are associated with a given \ndata structure. Purely basing such an analysis on the frequency of operations would be a naive simpli.cation \nof the prob\u00adlem, since the operations and their costs are linked to the program state and are continuously \nvarying throughout the execution. It is a challenge about how to come up with such an amortized cost \nmodel without worrying about the deeper notions of the program state; a challenge partially solved by \nthis paper. We .rst delve on this issue of generating an appropriate cost model. Without worrying the \nissues of program state, one could limit oneself to the interface functions and their order of executions, \nand try to approximate the model of behaviors exercised. In general, constructing a cost function is \nmuch more dif.cult than illustrated by the above example, since there are many functions that inter\u00adact \nwith each data structure. The best data structure implementa\u00adtion changes as each interface function \nis invoked more or less fre\u00adquently relative to the others. Beyond just interface functions, any changes \nin data element size, the number of data elements, data search pattern, and so on, which can be affected \nby program inputs, can have a signi.cant impact on the most appropriate data structure implementation. \nFor example, STL s find searches for the .rst instance of a data element located in the structure without \niterat\u00ading over all the elements. This means the data being stored affects how important iteration is \nto the performance of the application. These and other input-dependent factors make it very dif.cult \nto hand-construct accurate data structure cost models. A .nal challenge is that underlying hardware can \nhave a con\u00adsiderable effect on data structure selection results. Even if a pro\u00adgrammer chooses the best \ndata structure, that data structure will not always be the best when it runs on different microarchitec\u00adtures. \nThat is, architectural changes can make the data structure, which was the best, suboptimal as input changes. \nFor instance, in the previous example of data structure selection, a developer might choose a vector \nover a list for fewer cache misses during it\u00aderation, although hardware systems with larger cache sizes \nmight execute list faster than vector. The reason is that list nodes will typically remain cached after \na cold start; however, whenever vector is resized the cold start penalty will have to be paid anew. Thus, \narchitectural events have a very important role in data struc\u00adture selection.   Figure 1. Different \ndata structure selection results on two microar\u00adchitectures: Intel Core2 Q6600 and Intel Atom N270. Each \nbar rep\u00adresents 1000 applications whose best data structure on the Core2 is shown in the x-axis. For \neach application, if the data struc\u00adture remains the same on the Atom, the application is classi.ed as \nagree . Otherwise, the application is classi.ed as disagree . To further motivate the importance of microarchitectural \ndiffer\u00adences for effective data structure selection, this work analyzed sev\u00aderal thousand randomly generated \napplications that exercise differ\u00adent behaviors of C++ STL data structures (further details on the application \ngenerator will be discussed in Section 4.1). Each appli\u00adcation was run on both an Intel Core2 Q6600 and \nan Intel Atom N270 to see what the best data structure implementation for each architecture is. Figure \n1 shows how differently two distinct mi\u00adcroarchitectures can behave. Each bar in the .gure represents \n1000 randomly-generated applications whose best data structure imple\u00admentation on the Core2 is shown \non the x-axis. For example, the left-most bar in the .gure represents 1000 applications whose best data \nstructure on the Core2 was a vector. The dark gray, top por\u00adtion of the bar represents how many of those \nexact same applica\u00adtions the best data structure was not a vector on the Atom archi\u00adtecture. So in 200 \napplications where vector performed best on the Core2, another data structure would perform better on \nthe Atom. This experiment demonstrates that the best data structure choice for each application signi.cantly \ndiffers on the two different mi\u00adcroarchitectures. The degree of such an inconsistency varies across data \nstructures. On average, 43% of the randomly generated appli\u00adcations have different optimal data structures. \nThus, all efforts to construct a data structure cost model without considering architec\u00adtural properties \nwill necessarily be lacking. The complexity of mod\u00adern architectures further motivates the need for an \nautomated tool to construct these models, as human-constructed models will be te\u00addious and likely inaccurate. \nSection 7 shows that it is inherently dif.cult and sometimes impossible for hand-constructed models to \ncapture the architectural events of an alternative data structure. E.g., the number of branch mispredictions \nin the original data structure has no causal relation to that in the alternative data structure. 3. Overview \nThe purpose of this work is to provide a tool that can report the best data structures for different \nsituations due to speci.c input sets and underlying hardware architecture changes. To keep up with the \nvar\u00adious behaviors of an application, this work exploits dynamic pro\u00ad.ling that utilizes runtime instrumentation. \nEvery interface func\u00adtion of each data structure is instrumented to model how that data structure interacts \nwith the application. The instrumentation code observes how the data structure is used by the application \n(i.e, soft\u00adware features), and at the same time monitors a set of performance counters (i.e., hardware \nfeatures) from the underlying architecture. The runtime system maintains the trace information in a context\u00adsensitive \nmanner, i.e., the calling sequences are considered at the data structure s construction time. This helps \ndevelopers know the location in the source code of the data structures to be replaced. Once program execution \n.nishes, the trace .les are fed into a ma-Figure 2. The number of data structure occurrences in all the \ncode registered in Google Code Search. chine learning tool. Finally, the machine learning tool reports \nwhat data structures should be replaced with which alternatives. Due to a signi.cant amount of effort \ninvolved, to train and build machine learning models for the data structures, this paper limits its focus \nto C++ programs using a subset of the STL. It may be noted that as the tool is not fundamentally limited, \nthe approach should be applicable to other data structures expressed in other contexts. To determine \nthe target data structure replacements, we surveyed programs using Google Code Search (GCS) [9]. GCS \nindexes many open-source projects on the Internet. Figure 2 shows the number of static references to \neach data structure type across the entire index. This .gure shows that vector, list, set, and map are \nthe most common STL data structures used, thus this paper will focus on various implementations of these \nstructures. Simply counting the number of static references to each data structure ignores the importance \nof data structure s impact to the application performance at runtime. However, this gives a rough estimate \nfor which data structure needs to be targeted initially. Given this set of target data structures, it \nis also necessary to de\u00ad.ne a set of implementations, and delineate what implementations can be replaced \nby what. Table 1 shows the possible data structure replacements considered, along with the bene.ts and \nlimitations of each. For example, vector can be replaced with list for faster insertion, and with set \nfor faster search. Similarly, if vector is frequently searched with a key for a match, e.g., using std::.nd \nif, then it can be replaced with map. However, vector cannot al\u00adways be replaced by set or map because \nthey are oblivious to the data insertion order (i.e., order-oblivious); Since they internally sort data \nelements, iteration over them leads to the sorted sequence of the elements. Therefore, iterating over \nthe vector precludes these replacement candidates. Those particular implementations in Table 1 were chosen \nbecause they are already implemented within the STL, and other implementations could easily be added \nto the cost model construction system. DS Alternate DS Bene.t Limitation vector list deque set (map) \navl set (avl map) hash set (hash map) Fast insertion Fast insertion Fast search Fast search Fast insertion \n&#38; search None None Order-oblivious Order-oblivious Order-oblivious list vector deque set (map) avl \nset (avl map) hash set (hash map) Fast iteration Fast iteration Fast search Fast search Fast search None \nNone Order-oblivious Order-oblivious Order-oblivious set avl set vector list hash set Fast search Fast \niteration Fast insertion &#38; deletion Fast insertion &#38; search None Order-oblivious Order-oblivious \nOrder-oblivious map avl map hash map Fast search Fast insertion &#38; search None Order-oblivious Table \n1. Data structure replacements considered for each target data structure. With this set of target implementations \nin mind, Figure 3 shows a high-level diagram of the proposed usage model. At compile time, an application \nis linked with a modi.ed C++ Standard Template Li\u00ad  Figure 3. The framework of the data structure selection. \nbrary (STL) so that pro.ling data structures are used instead of the original ones. The pro.ling data \nstructures are inherited from the original STL data structure, and their interface functions contain \ncode which records the behaviors including hardware performance counters, and then calls the original \ninterfaces. All the pro.ling features are recorded in trace .les, which are post-processed and sorted \nby data structure. This sorting takes both relative execution time and calling context into consideration, \nin order to provide de\u00advelopers with a prioritized list of which data structures are most important to \nchange. Once the data is sorted, the machine-learning\u00adbased cost model provides a suggestion of what \ndata structures should be replaced with alternate implementations. Optionally, this output could be fed \ninto a code refactoring tool [18], which could automate the implementation replacements. This type of \noptimiza\u00adtion tool can have a signi.cant impact on the performance of real\u00adworld applications. 4. Model \nConstruction Accurate model construction is essential for effective data struc\u00adture selection. Brainy \nleverages machine learning to construct the model for predicting the best data structure implementations. \nThe model must satisfy three properties to be successful. First, the model should be accurate across \nmany different data structure be\u00adhaviors and usage patterns. Second, the model should be aware of microarchitectural \ncharacteristics of the underlying system. Third, the methodology for characterizing the performance of \ndata struc\u00adtures should be automated and repeatable so that it is easy to con\u00adstruct new models for new \nmicroarchitectures. If these properties are not satis.ed by the model, architectural variations would \neasily make the predicting performance of the model inaccurate. In this case, improving the accuracy \nof the model requires re-training the model on the new microarchitecture. A more serious problem is that \nthe training applications/examples1 painfully-collected to cover the huge design space on the original \nmicroarchitecture might not provide abundant learning capabilities any longer on the new microarchitecture \n(See Figure 1). That is, due to the architectural change, the original training applications could not \nproduce the broad spectrum of the best data structures as before, thus failing to model various data \nstructure behaviors. Therefore, new training applications should be collected again to cover the missing \nportion of the design space. This is extremely time-consuming and requires enormous effort without the \nhelp of the automated and repeatable methodology. This section describes how these issues are addressed. \nIt must be noted that just using machine learning itself cannot satisfy the issues. These issues are \nrather the prerequisites for the success of machine learning. Formally, the description of the data structure \nselection model is as follows: given a set of input features X and a set of data structure implementations \nY as output, the model is to .nd a function f: X . 1 This paper uses the terms training applications \nand training examples interchangeably. Y such that the predicted result y = f(x), where y . Y and x is \na set of features for a data structure in an application, matches the best data structure (BestDS) of \nthe application. The training set of the model is comprised of many pairs of the feature set and the \nbest data struc\u00adture, i.e., (x1, BestDS1), (x2, BestDS2), ..., etc. The features include both software \nfeatures such as the number of interface invocations and hardware features such as cache misses (Section \n5.1 discusses the both features in more detail). Thus, features capture various as\u00adpects of the data \nstructure usage when an application is running. In collecting the training set, Brainy uses an application \ngenerator to prepare a signi.cant quantity of applications and executes each application through two \nphases of data collection: .rst to measure the runtime and second to record the detailed performance \nmetrics. This section describes why so many applications are required, the details of the application \ngenerator, and how it is used in the two phases of data collection. 4.1 Training Set and Over.tting \nCreating an accurate model using machine learning that represents a vast array of different data structure \nbehaviors requires having a large and thorough set of training examples. If the training ex\u00adamples are \nnot representative of the many varied behaviors of real world applications, then the resulting model \ncannot yield accurate predictions. Therefore, training should provide the machine learn\u00ading algorithm \nwith all critical patterns of data structures behaviors in which one implementation performs much better \nthan another. Unfortunately, constructing such a training set is a very dif.cult problem. The main dif.culty \nof constructing effective training example sets is the very large design space. For example, an application \nmay use only a subset of interface functions, or use them with a consistent frequency distribution (e.g., \nalways performing twice as many lookups as insertions). On top of that, there are many hardware-speci.c \ncharacteristics, such as the size of data elements in relation to cache-block size, that make the training \nexample sets constructed for one architecture potentially irrelevant for another. Compounding the problem, \neach portion of the design space must be fully represented in order to avoid over.tting the model. Over.tting \nis a well-documented problem where machine learning algorithms adjust to random features (i.e., noise) \nof the training examples. Since such random features have no causal relation to the prediction function, \nthe resulting prediction performance on unseen data becomes poorer while the performance on the training \nexamples improves [5]. Thus, over.tting misleads the resulting model away from the optimum. This is most \nlikely to become a severe problem for insuf.cient amount of training examples, since the noises are much \nmore outstanding in that case, i.e., the model is inevitably inaccurate. Because of the immense search \nspace and the problems from over.tting, sample benchmarks cannot effectively train a machine learning \nmodel for data structure selection.  Figure 4. Training Framework Phase-I; Generating Applications \nand Measuring Execution Times Figure 5. Training Framework Phase-II; Collecting Software and Hardware \nFeatures 4.2 Application Generator Instead, this work proposes using an application generator to cover \nthe design space suf.ciently with synthetic applications. That is, a tool (the application generator) \ncreates a variety of applications that test different parts of the overall space. Each application mod\u00adels \nparticular behaviors of a single data structure which are ran\u00addomly determined, i.e., a probability distribution \ndetermines how the interface functions should be invoked. Using the application generator, Brainy can \neasily have as many training examples as needed, thereby avoiding the over.tting. Note that if there \nare a suf.cient number of training examples, then the noise would play a vanishingly small role in the \nlearning process. The vision is that the application generator and the con.guration .le can be distributed \nwith the data structure library, and can be used to train the machine learning model at install-time \nfor the speci.c hardware of the sys\u00adtem. The application generator .rst prepares a synthetic application \nwith an abstract data type (ADT) implemented by a C++ template that can take each data structure. The \nmodeling is achieved via ran\u00addomization. To illustrate, the synthetic application runs a function\u00addispatch \nloop. A random number determines which interface func\u00adtion is invoked every iteration of the loop. Thus, \nthe order of inter\u00adface invocations and their invocation frequencies are random. Ran\u00addomization also \ncontrols how the dispatched interface is invoked, e.g., what data element is searched for find. Table \n2 represents what property is randomly determined, and how it is speci.ed in a con.guration .le. In particular, \nthis con.guration only speci.es the total number of all the interface invocations. In each generated \nap\u00adplication, the number of invocations of each interface may vary, but the total number of invocations \nis constant across the applications. To cover the different behaviors of interface invocations, the number \nof invocations for a given interface should be able to vary between zero and the total number. To achieve \nthis goal, Brainy exploits a random number distribution to choose the number of invocations for each \ninterface, such that the sum of the invocations is the con.gured total. After determining how the application \ninteracts with the ADT, the application generator .nally creates a set of applications with interchangeable \ndata structures, based on the replacement limita\u00adtions described in Table 1. This is achieved by simply \nspecifying an actual data structure in the ADT, which is a C++ template. Thus, the behavior of the synthetic \napplications is exactly same, i.e., the only difference is that they have a different data structure. \nSince the random numbers completely determine every behav\u00adior of a data structure, a different sequence \nof random numbers leads to different interactions with the ADT, and thus different sets of applications. \nWith that in mind, the application generator must use a randomization method that has a suf.ciently low \nprobability of generating equivalent random sequences.  4.3 Training Framework Figure 4 and Figure 5 \nshow how the training framework of Brainy functions based on the application generator. The training \nconsists of two phases, each of which are iterative processes. As detailed in Algorithm 1, the .rst phase \n(Phase-I) consists of iterations of gen\u00aderating sets of synthetic applications with the same behavior \nbut different data structures using the application generator. The appli\u00adcations are compiled, run on \nthe target machine, and the execution time is measured to determine which data structure is the best \nfor each application. Then in seed ds pairs, the best data structure is recorded together with the seed \nvalue used to generate the set of the applications 2. Updating need more sets is complex as there is \nno interven\u00adtion or effort to generate applications that are best for a speci.c data structure; so after \nmany iterations some data structures will 2 Brainy records the best data structure only if it is 5% or \nmore faster than any another. This prevents a data structure, which is barely the best, from being selected \nas an alternative.  Data structure behavior determined randomly Speci.cation example Description Total \nnumber of invocations for all interface functions T otalInterfCalls = 1000 Size of data element Maximum \nvalue of data to be inserted Maximum value of data to be removed DataElemSize = {4, 8, 64, ...}MaxInsertV \nal = 65536 MaxRemoveV al = 65536 Maximum value of data to be searched MaxSearchV al = 65536 Maximum number \nof data elements to be iterated MaxIterCount = 65536 Insert a random number between 0 and 65536 on insert \nRemove a random number between 0 and 65536 on erase Search a random number between 0 and 65536 on find \nIterate data elements a random number of times under 65536 on ++/-- Table 2. The behaviors of a data \nstructure which are randomly decided, and the speci.cation example in a con.guration .le. input : data \nstructures from con.g input : need more sets from con.g output: seed ds pairs -pairs of seeds and data \nstructures Map<seed, DS> seed ds pairs .\u00d8 Map<DS, time> runtime .\u00d8 while need more sets do seed . T ime() \nforall the DS . data structures do A . Compiler(AppGen(seed, DS)) A() // run runtime[DS] . GetRuntime() \nend seed ds pairs . seed ds pairs . (seed, F astestDS(runtime)) runtime[DS] .\u00d8 update need more sets \nend Algorithm 1: Training Framework Phase-I have more best applications than others. Brainy stops Phase-I \nwhen a certain number of applications, e.g., ten thousand, is best for each data structure and switches \nto the next step (Phase-II). This threshold number is adjustable, and it is possible to use a different \nthreshold for each data structure through the con.guration .le. It is important to note that the Phase-I \nis very fast since it does not per\u00adform any expensive pro.ling to extract features. Thus, measuring the \napplications execution time to determine the best data structure has minimal overhead. input : data structures \nfrom con.g input : seed ds pairs from Phase-I output: train set -training data for model Map<DS, Map<features,DS>> \ntrain set .\u00d8 forall the seed . seed ds pairs do forall the DS . data structures do A . Compiler(AppGen(seed, \nDS), Instrumentation) A() // run features . GetF eatures() train set[DS] . train set[DS] . (features, \nseed ds pairs[seed]) end end Algorithm 2: Training Framework Phase-II In Phase-II, the application generator \nreplays the executions of the applications in Phase-I by taking the seed value recorded in Phase-I (as \nusing the same seed guarantees producing the same se\u00adquence of random numbers in most pseudo-random number \ngen\u00aderators). Note, using seeds is but one way of retaining the appli\u00adcations between phases. That is, \nthe applications are regenerated, and therefore Brainy can execute millions of training applications \nwithout an explosion in disk space. As shown in Algorithm 2, this phase iterates through the recorded \nseed values (seed ds pairs), regenerates the applications, and compiles them with additional in\u00adstrumentation, \nspeci.cally a modi.ed STL library that has pro.l\u00ading for data structures. With this pro.ling, all of \nthe software and hardware features can be collected during program execution. The pro.ling data structures \nrecord the features in a designated train\u00ading set .le according to the type of the data structure. train \nset is updated with the collected features and the best data structure as observed in Phase-I. Again, \nthe applications generated in each iteration have the exact same behavior, and the only difference be\u00adtween \nthem is the data structure implementation. This iterative pro\u00adcess stops when all the seeds are consumed. \nAt the end, each data structure s training set .le is fed into the machine learning tool to train the \ncorresponding model. In addition, Brainy s training framework is .exible. When long training time is \nunacceptable, users can specify that training occur for only a small number of training applications \nfor each data structure, e.g., train only 1000 applications for each data structure. The two-phase training \nframework can prevent extra applications generated in Phase-I from being fed into Phase-II which performs \na time-consuming feature pro.ling. E.g., if Phase-I generates 1500 and 1000 applications for vector and \nlist, respectively, Phase-II does not accept the rest 500 vector applications. In this way, the framework \ncan dramatically reduce the training time. One might suggest simply using real applications to train \nthe machine learning algorithm. However, this approach is neither practical nor plausible. Assume that \nthere is a good real application which clearly shows list is better than vector. Nevertheless, this real \napplication just shows one particular case among millions of situations where list outperforms vector. \nFor effective data structure selection, the training process must cover as many cases as possible, so \nthat the machine learning model will yield accurate prediction results for unseen applications, which \nare practically in\u00ad.nite. That is, if the model just learns a few cases where one data structure is better \nthan another, the resulting data structure selection is very likely to be inaccurate for real applications \nthat were unseen in the training process. The application generator is a reasonable approach for model\u00ading \nthe myriad cases required for accurate machine learning pre\u00addictions. Furthermore, this framework for \nmodeling has further ad\u00advantages over real applications (or hand constructed benchmarks) by not being \ntied to current implementations / architectures. Oth\u00aderwise, every variation to any part of the system \nwould potentially require constructing a new set of applications. Therefore, it is de\u00adsirable that the \nframework can automatically produce training ex\u00adamples tuned to the speci.c architecture within a reasonable \ntime. 5. Arti.cial Neural Network (ANN) Several machine learning techniques have been proposed over the \nlast few decades, and it remains a question of great debate as to which machine learning technique is \noptimal for a given classi.\u00adcation problem. The accuracy of the machine learning technique is inherently \ndependent on the characteristics of the data set. For example, Arti.cial Neural Network and Support Vector \nMachine generally perform better when the features are continuous and mul\u00adticollinearity is present. \nThey can both deal with a case where rela\u00adtionship between input and output features is non-linear3, \ni.e., data are not linearly separable. [15, 21].  The features generated by instrumentation code show \nboth lin\u00adear and non-linear characteristics. Brainy exploits Arti.cial Neu\u00adral Network (ANN), since it \nis robust to noise as well as effective for linear and non-linear statistical data modeling [11]. This \nseems an appropriate approach in that data structure selection is a highly complex problem domain and \nits training examples may have con\u00adsiderable noise and model-bias, thereby hurting the prediction ac\u00adcuracy. \nThe training of the ANN model in this work leverages a back-propagation algorithm [24]. The ANN model \npredicts the alternative data structure that achieves the best performance in replacing the original \ndata struc\u00adture in an application. The target data structures, determined in Sec\u00adtion 3, have their own \nANN model as shown in Figure 3. That is because the list of features necessary for predicting the best \ndata structure type is different between data structures. For example, vector suffers from resizing when \nits capacity is full, but list does not. In particular, there is another model for vector and list to \naddress the situation when they are used in an order\u00adoblivious manner (where insertion order has nothing \nto do with data organization in the data structure). When they are used in this man\u00adner, vector and list \ncan be replaced with hash set or set. When the underlying hardware system is changed, the ANN mod\u00adels \nfor data structures should be trained and learned again for the new microarchitecture, possibly with \na new set of training exam\u00adples. This is achieved with the help of the application generator. 5.1 Feature \nSelection It is important to determine which subset of features to collect for the training examples. \nBy selecting only the most relevant features, the machine learning model will be more accurate and the \nlearning process will converge faster. Initially, most of interface functions of a data structure and, \nif available, how much work is done on their invocation are collected through instrumentation code. This \nwork calls the latter a cost of each interface invocation. For example, find has a cost to model how \nmany data elements are accessed until the search operation is .nished. Similarly, for erase and insert, \ntheir costs represent how many data elements, located after the insertion and removal point, are moved \nbackwards or forwards. Along with these software features, hardware features are also considered to make \nthe model aware of underlying hardware architecture. Initially, we collected the numbers on L1 and L2 \ncaches, TLB, retired instruction, page faults and processor clock cycles, and so on. Especially, this \nwork omits some features such as L2 cache misses, TLB misses, OS page faults, and bus utilization, since \nman\u00adual feature selection empirically shows that these features rarely af\u00adfect the prediction of the \nbest data structure. Since all the code to be executed becomes entirely different after data structure \nreplace\u00adments, Brainy uses hardware features just to capture how the origi\u00adnal data structures show certain \nbehaviors useful for data structure selection. To perform the feature selection, this work leverages \nthe evo\u00adlutionary approach based on genetic algorithm due to its success especially for large dimensions \nof features [28]. This approach rep\u00adresents a given subset of features as a chromosome, a binary string \n3 Support Vector Machines can also address this case with the help of transformed feature space. A linear \nseparation in the transformed feature space corresponds to a non-linear separation in the original space \n[15]. Figure 6. Correlation between conditional branch misprediction and vector resizing when the data \nstructure is order-aware (a) and order-oblivious (b) with the length of the total number of features. \nIn the chromosome, each binary value represents the presence of a corresponding fea\u00adture. The population \nof chromosomes (different feature selection candidates), evolves toward better solutions. Meanwhile, \nmutation in the genetic algorithm prevents the evolution from getting stuck in local optima, helping \nto approach the global optimum. In partic\u00adular, this work constitutes the chromosome as real-valued weights, \ninstead of binary value, that show which feature has more impact on the resulting model instead of binary \nvalues [12, 13]. Table 3 shows the top .ve features with the highest weight for each ANN model. For each \ndata structure, the order of features shown in the table follows the decreasing order of the weights, \ne.g., the .rst low corresponds to the features with the highest weight. The most important features to \ndecide whether vector should be replaced, no matter if it is order-aware or order-oblivious, con\u00adtain \nthe number of resizes, that is performed on data insertion when the size of vector is full. It is interesting \nthat a mispre\u00addiction rate of conditional branches belongs to the important fea\u00adtures. This results from \nthe fact that such a branch misprediction can model exceptional behaviors of data structures, e.g. invoking \nresize on insert operations of vector and hash table. In other words, data insertion to the data structures \ndoes not suf\u00adfer from performing resize for most of time if the capacity of the dynamic array is not \nfull. Note that once resize is invoked due to insuf.cient capacity, it takes a while to see the recurrence \nof another resize. The reason is that resize extends the ca\u00adpacity, in case there are many more data \ninsertions to again .ll the array. In the insert function, a conditional branch instruction de\u00adtermines \nwhether resize is invoked. The branch predictor could fail to correctly predict the branch instruction \nfor this uncommon path, which is a taken branch to call resize. This is justi.ed in Figure 6 where the \nX-axis corresponds to the branch mispredic\u00adtion rate while the Y-axis to the resize ratio (%) among the \ntotal interface invocations. It turns out that insert and insert cost are relevant fea\u00adtures for vectors. \nThis makes sense since these features capture how much vector suffers from shifting data after the insertion \npoint. The same goes for why erase cost is relevant for the order-oblivious vector. In particular, when \nvector is used in the order-oblivious manner, find is a relevant feature. Note that in this case, there \nis no explicit iteration operation, thus every data access is performed by find. For order-aware and \norder-oblivious lists, L1 cache miss rate is a relevant feature. It can be thought that the miss rate \nwould capture how the nodes of the linked list .t into a cache block. Again, for the order-oblivious \nlist, find-related features are relevant. In particular, push front is relevant when list is used in \nthe order-aware manner. This is understandable given how  vector order-oblivious vector list order-oblivious \nlist set map resizing br miss iterate .nd cost .nd cost L1 miss insert .nd cost push front .nd L1 miss \ndata-size / cache block-size br miss L1 miss L1 miss L1 miss data-size / cache block-size br miss insert \ncost resizing insert erase .nd insert cost iterate erase cost erase cost data-size / cache block-size \ninsert cost .nd cost Table 3. Selected features for each data structure frequently data insertion occurs \nat the beginning of data structures, which can guide whether vector or deque is an appropriate alternative. \nFor set and map, find-related features are most relevant, as their data structure selection highly depends \non how frequently find is performed and how many data elements a find opera\u00adtion accesses. Again, the \ninsert cost and find cost repre\u00adsent the number of data elements accessed while the corresponding operations \nreach the insertion point and the search location, respec\u00adtively. In addition, L1 cache miss rates and \ndata element size per cache block size can capture how long the latency of each data ele\u00adment is on the \nfind operation. Thus, they can quantify the cost of data accesses involved in find operations.  5.2 \nLimitation While Brainy captures many useful properties with synthetic appli\u00adcations created by the application \ngenerator, it also has a limitation that leaves room for future improvement. The synthetic applica\u00adtions \nmight not accurately model the impact of other parts of a real application on the microarchitectural \nstate, e.g., the L1 is polluted by data in intervening instructions. However, it should be noted that \nBrainy is aware of such a microarchitectural behavior, and possibly another synthetic application can \ncapture the polluted L1 cache be\u00adhavior. Even with these drawbacks, it turns out that the training with \nthe synthetic applications can cover real applications. That is it is conjectured that the behaviors \nexhibited in actual execution would be a subset of training behaviors therefore hoping that the actual \nexecution model would be subset of the constructed one. Section 6 demonstrates that for real-world applications, \nBrainy can consistently select optimal data structures across input and architectural changes. 6. Evaluation \nIn order to evaluate the effectiveness of Brainy, we implemented it as a part of C++ Standard Template \nLibrary (STL) for GCC 4.5 [8]. To access hardware performance counters, we used PAPI [6]. Es\u00adpecially, \nto show Brainy s accuracy across different inputs, we se\u00adlected a set of C++ applications where the best \ndata structure varies on input changes. The data structure selection experiments were performed on two \ndifferent systems that have Intel Core2 and Intel Atom microarchitectures, respectively. The detailed \nsystem con.g\u00adurations are described in Table 7. In the next sections, we .rst validate Brainy s data \nstructure se\u00adlection models. Then, we show four case studies with real-world applications. In the .rst \ntwo applications, the optimal data struc\u00adtures vary across inputs and even microarchitectures (Section \n6.3). Thus, they show the dif.culty of accurate data structure selection. In the next two applications, \nthe optimal data structures are rarely affected by input and microarchitecture changes. Thus, we show \ntheir results brie.y compared to the .rst two applications. Figure 8 summarizes the performance improvement \nof each application obtained from Brainy s data structure replacement. In cases where the optimal data \nstructure varies across inputs, only the best performance result Brainy achieved appears in the .gure. \nDesktop CPU Intel Core2 Quad Q6600 2.4 GHz Caches 4 X 32 KB L1 data, 2 X 4 MB L2 uni.ed Memory / DISK \n2 GB SDRAM, 200 GB HDD Operating System 64-bit Ubuntu Desktop 8.04 Compiler GCC 4.5 with libstdc++ 4.5.0 \nLaptop CPU Intel Atom N270 1.6 GHz with HyperThreading Caches 32 KB L1 data, 512 KB L2 uni.ed Memory \n/ DISK 512 MB SDRAM, 8 GB solid state disk (SSD) Operating System 32-bit Ubuntu Netbook Remix 9.10 Compiler \nGCC 4.5 with libstdc++ 4.5.0 Figure 7. Target systems con.gurations Figure 8. Performance improvement \nBrainy achieved Brainy achieved an average performance improvement of 27% and 33% on Core2 and Atom microarchitectures, \nand up to 77% for some case (Section 6.3). 6.1 Model Validation with an Application Generator Validating \nBrainy s data structure selection models leverages the application generator. For an accurate and fair \nevaluation, the ap\u00adplication generator newly produces 1000 random applications for each data structure \nmodel. Note that all these random applications have never been seen by the models, i.e., the model validation \nis performed with completely new applications. Thus, the applica\u00adtions here are not the ones used to \ntrain the models. The accuracy is calculated as follows; T he number of mispredictions accuracy(%) = \n1 - (1) 1000 Figure 9 shows how accurate the prediction results of each data structure model are for \nthe 1000 applications on the Core2 and Atom microarchitectures. Overall, for Core2 microarchitecture, \nthe accuracies of models are between 80% and 90%. This is impres\u00adsive in that the 1000 applications for \neach model capture a variety of behaviors of data structure usages, thus the best data structure is quite \ndifferent across the applications. It needs to be noted that each data structure model attempts to select \nthe best data structure among many replaceable data structures as described in Table 1. For instance, \nthe model for vector selects the best data struc\u00adture among possible six candidates, when it is used \nin the order\u00adoblivious manner. For Atom microarchitecture, the accuracies of models are between 70% and \n80%. This is enough to effectively Figure 9. Accuracy of data structure selection models; for the same \ndata structure, there are two different models for Core2 and Atom microarchitectures, respectively. \n predict the best data structure of a real application as described in the next section.  6.2 Xalancbmk \nXalancbmk is an open source XSLT processor that performs XML to HTML transformations. It takes as inputs \nan XML document and an XSLT style sheet with detailed instructions for the trans\u00adformation. The program \nmaintains a string cache comprised of two levels, m busyList and m availableList, vectors. When a string \nis freed in XalanDOMStringCache::release, it moves the string to the m availableList, provided it is \nfound in the m busyList. To deter\u00admine whether the string is found in the latter list, the data structure, \nvector, performs find operations. In general, these operations are often recurring, but the frequency \nof performing them is varying across program inputs. In addition, each input brings about differ\u00adent \nsearch patterns. To de.ne the accuracy of Brainy for data structure selection, the evaluation process \nleverages comparison with the Oracle scheme which is empirically determined across program inputs on \neach microarchitecture. If the resulting data structure selection agrees with the Oracle s, the result \nare considered accurate. In addition, the evaluation compares Brainy with Per.int, the state-of-the-art \ndata structure advisor that relies on hand\u00adconstructed models [17]. On each interface invocation, Per.int \nassigns the cost taking into account traditional asymptotic anal\u00adysis. As an example, for the cost of \na find operation among N data elements, vector leverages average case for linear search, i.e., 3/4N , \nwhile set uses logN for binary search4. Each cost is multiplied with a coef.cient value, which is determined \nby linear regression analysis for execution time, and accumulated whenever the interface function is \ncalled. In particular, Per.int provides the hand-constructed model for vector-to-set replacement while \nvector-to-hash set is not supported. Each interface invo\u00adcation of the original data structure (vector) \nupdates the costs of both vector and set. Based on comparing the accumulated costs at the end of program \nexecution, Per.int selectively reports the alternative data structure. Figure 10 shows execution times \nof three selected data struc\u00adtures, vector, set, and hash set with those schemes. The ideal data structure \nselection (Oracle), i.e., vector is the best for a train input while hash set for test and reference \ninputs, are identical on both microarchitectures. Especially, set performs dif\u00adferently on the two microarchitectures. \nThat is, for test and refer\u00adence inputs, set outperforms vector on Core2 microarchitec\u00adture while the \ndata structure replacement to set does not achieve signi.cant performance improvement on Atom microarchitecture. \nFigure 11 shows the results of each data structure selection scheme for the two different microarchitectures. \nBaseline repre\u00adsents the original data structure in the .gure. According to the Ora\u00adcle, for test and \nreference inputs, the original data structure, which 4 For binary search, the average and worst cases \nare exactly the same. Figure 10. Normalized execution time across different data struc\u00adtures; The baseline \nexecution times (in second) are on Core are 3s, 74s, and 234s for test, train, and reference, respectively. \nOn Atom, the baseline execution times for these inputs are 18s, 611s, and 1345s, respectively. Brainy \nselects the best data structure for each input of Xalancbmk Input Size Selection Schemes Reported Best \nDS Core2 Atom Baseline vector vector Test Per.int Brainy set hash set set hash set Oracle hash set hash \nset Baseline vector vector Train Per.int Brainy Oracle set vector vector set vector vector Baseline vector \nvector Reference Per.int Brainy set hash set set hash set Oracle hash set hash set Figure 11. Xalancbmk \ns data selection results on Core2 and Atom microarchitectures.  is vector, is desired to be replaced \nwith hash set for better performance. The reason is that the data structure executes many search operations. \nHowever, for a train input where hash set is suboptimal, vector is the best data structure. This is not \neasily understandable and rather surprising. According to the pro.led fea\u00adtures with instrumentation \ncode of Brainy, the application invokes the find function more than 60 millions times for a train input \nas well as for a reference input. On top of that, the train input causes the application to erase the \n.rst data element from the head of the dynamic array almost 30 times more frequently than the refer\u00adence \ninput does, which is pretty problematic for vector. On the other hand, for the test input, the application \nachieves the best per\u00adformance with hash set in spite of a relatively small number of find function invocations, \nwhich is about thirty-seven thousand. Thus, accurate data structure selection is very dif.cult for this \nap\u00adplication. With the help of the pro.led feature results, it turns out that find operation is much \nmore dominant compared to the problem\u00adatic erase operation. What happened behind the scenes related to \nthe find operation is that the number of data elements the opera\u00adtion touched is varying across program \ninputs. This is mainly due to the change of search patterns across inputs. Table 4 presents more detailed \ninformation about this situation. This implies that building an accurate hand-constructed model would \nbe much more dif.cult. Input Size find invocations Touched data elements Test 37,594 32,804,644 Train \n62,438,422 2,569,120,180 Reference 67,720,063 89,454,229,684 Table 4. The number of find invocations \nand the total number of touched data elements for all the invocations across program inputs.  For the \ntraining input, a majority of find operations succeed in searching the designated data element in the \nvery beginning of the dynamic array of the original data structure, vector. In this case, hash set just \ncauses extra memory consumption compared to vector. It is desirable to force the application not to pay \nfor complex operations such as maintaining hash buckets which is not really necessary, thus vector is \npreferable to hash set. Brainy can recognize the search pattern based on find-related features as described \nin Section 5.1. Together with considering other software and hardware features pro.led, Brainy correctly \nreported the same results as the Oracle across different inputs for the both microarchitectures. Meanwhile, \nPer.int failed to consistently report accurate pre\u00addiction results for the best data structure, even \nif it only needs to perform a binary decision between vector and set. For the train input, Per.int incorrectly \nreported that set is preferable to vector. This is problematic because the resulting data structure replacement \nto set causes performance degradation on both mi\u00adcroarchitectures as shown in Figure 10. For the reference \ninput, Per.int reported that set is preferable, which only works on Core2 microarchitecture, i.e., replacing \nvector with set achieves lit\u00adtle performance improvement on Atom microarchitecture. Again, Brainy selected \nthe optimal data structures consistently across all the program inputs on both microarchitectures.  \n6.3 Chord Simulator This application is an open source simulator for Chord, a dis\u00adtributed lookup protocol \nto locate Internet resources. The main work of the simulation is to send query requests for a certain \nre\u00adsource over the network and to record if the lookup fails by check\u00ading the response to the query. \nWhenever the response is received, the simulator drops the message, which corresponds to the resource \nof the response, in a pending list of routing messages. The search performance thus translates to the \nsimulation time reduction. In par\u00adticular, determining the message to be dropped performs std::.nd if \non the pending list, which is implemented using vector, check\u00ading an ID .eld of each message structure. \nThus, the vector can be replaced with map-like data structures using the ID .eld as its key. Brainy suggested \nto replace the original vector with map or hash map, according to different inputs. In the application, \nthe optimal data structure varies across different inputs on both mi\u00adcroarchitectures, as shown Figure \n13. It is important to note that for the Large input, the optimal data structures on both microarchi\u00adtectures \ndo not agree with each other, i.e., vector is optimal on Core2 whereas map performs the best on Atom. \nThis shows the dif\u00ad.culties of the data structure selection in the application. Overall, Brainy correctly \nreported the same results as the Oracle across dif\u00adferent inputs and microarchitectures. It needs to \nbe noted that when vector, the original data structure, is optimal, Brainy correctly selected this data \nstructure. Figure 12 shows the performance re\u00adsults of different data structures across different inputs \nand microar\u00adchitectures. The con.guration of the graph and the table follows the one in the previous \nsection. Again, we compared Brainy with Per.int5. Per.int selected map for all combinations of inputs \nand mircroarchitectures. How\u00adever, for the Large input on Core2, map performs worse than the original \ndata structure, vector. Per.int s suggestion causes per\u00adformance degradation in this case. In contrast, \nBrainy consistently selected the optimal data structures for all combinations of inputs and microarchitectures. \n5 Since Per.int does not support vector-to-map replacement explicitly, this work considers its suggestion \nof set as the replacement to map. We believe that the implementation of the replacement should exactly \nfollow the manner that vector-to-set is implemented. Figure 12. Normalized execution times across different \ndata struc\u00adtures: the baseline execution times (in second) on Core2 are 9s, 19s, and 306s for test, train, \nand reference, respectively. On Atom, the baseline execution times for these inputs are 47s, 203s, and \n2952s, respectively. Brainy selects the best data structure for each input of Chord Simulator. Input \nSize Selection Schemes Reported Best DS Core2 Atom Small Baseline Per.int Brainy Oracle vector map map \nmap vector map map map Medium Baseline Per.int Brainy Oracle vector map hash map hash map vector map \nhash map hash map Large Baseline Per.int Brainy Oracle vector map vector vector vector map map map Figure \n13. Chord simulator s data selection results on Core2 and Atom microarchitectures.  6.4 RelipmoC RelipmoC \nis an open source translator that converts i386 assembly code to C code, i.e., a decompiler for i386 \nassembly. It analyzes the input assembly code and builds a list of basic blocks implemented using STL \nset, thus a red-black tree. On the set data structure, it performs data .ow and control .ow analyses \nto extract high level expressions, and to recover program constructs, e.g., loops and con\u00additional statements, \nalong with the information about their nesting level. It frequently checks if a basic block belongs to \nthe program constructs which are normally a list of basic blocks. In the mean\u00adtime, find and iteration \noperations are executed many times for short lists and long lists of basic blocks, respectively. Brainy \nsug\u00adgested replacing set with avl set, the implementation of which is an AVL tree. By conducting the \nsuggested replacement, we im\u00adproved the execution time of the application on Core2 and Atom microarchitectures \nby 23% and 30% on both microarchitectures, respectively. The baseline execution times (in seconds) of \nthis ap\u00adplication on Core2 and Atom are 41s and 120s. We could not com\u00adpare Brainy with Per.int since \nit does not support any replacement for set.  6.5 Raytrace This application draws a 3D image of groups \nof spheres using a ray tracing algorithm implemented in C++ STL. The spheres are divided into groups \nthat use list to store them. The main compu\u00adtation of the program occurs in a loop on intersect of each \ngroup ob\u00adject. First, the intersection calculation is performed for each group of spheres. If a ray hits \nthe group, it is subsequently performed for its spheres (scenes). Thus the list is heavily accessed and \niterated during the ray tracing, i.e., vector is much preferable. Brainy correctly suggested to replace \nthe list with vector. By taking Brainy s suggestion, we replaced the original data structure with vector \nthereby reducing the execution time of the appli\u00adcation on Core2 and Atom microarchitectures by 16% and \n13%, respectively. The baseline execution times (in seconds) of this ap\u00adplication on Core2 and Atom are \n79s and 347s. This time Per.int selected the optimal data structure just as Brainy did.  7. Related \nWork Selecting the best data structure implementation is often a problem ignored by developers; they \nsimply rely on library developers to choose a good implementation for the average case and accept the \nresults. This leaves signi.cant room for improvement. When developers do select speci.c implementations, \nthey typically rely on asymptotic analysis, even though it can often lead to incorrect decisions in real-world \napplications. As pointed out, asymptotic analysis was always intended to be used in algorithmic selection \nand not in data structure selection/tuning. Several researchers have previously investigated the problem \nof data structure selection in various contexts [14, 17, 25 27]. Jung and Clark propose a dynamic analysis \nthat can automatically iden\u00adtify data structures and their interface functions. They showed that the \nresulting information, e.g., how the functions interact with the data structures, is very useful for \ndata structure selection [14]. Other researchers suggests language level supports for data structure \nse\u00adlection. For example, in high-level programming languages, such as SETL, it is impossible to select \ndata structure implementations; all data structures are speci.ed as abstract data types, and the com\u00adpiler \nmust determine the implementation [25]. Work in this area fo\u00adcused on using only static analysis for \ndata structure selection [26]. While the raised abstraction level of these languages did help pro\u00adductivity, \nthe performance of these tools was generally worse than hand-selected implementations. The Chameleon \n[27] and Per.int [17] projects are the most sim\u00adilar to Brainy. Chameleon and Per.int instrument Java \nand C++ applications, respectively, to collect runtime statistics on behaviors such as interface function \ncalls. Additionally, Chameleon collects heap-related information from the garbage collector. These statis\u00adtics \nare then fed into hand-constructed diagnostics to determine if the data structures should be changed. \nBoth Chameleon and Per.int showed impressive space and performance improvements for real\u00adworld benchmarks. \nIn particular, Brainy considers memory bloat as Chameleon does. Recall that the application generator \nvaries the number of data elements in a data structure as well as the size of each element, thus the \ngenerator can create applications suffering from memory bloat. Brainy extends those prior works by 1) \nusing machine learning to automatically construct more accurate models, instead of relying on hand-construction, \nand 2) incorporating hard\u00adware performance counters into the analysis, thus providing greater accuracy. \nIn particular, unlike Chameleon, Brainy is not restricted to languages that have managed runtime features \nsuch as garbage collection. The prior works have three problems. First, they require many models for \neach data structure replacement. For example, if M data structures can be replaced with N alternative \ndata structures, the prior works require total M x N models. Note that modeling the execution of alternative \ndata structures depends on the original data structure. On the contrary, Brainy needs only M models, \nthus the instrumentation overhead can be greatly reduced. Second, modeling the accurate execution of \nthe alternative data structure is inherently dif.cult and sometimes impossible. For ex\u00adample, in a vector-to-set \ndata structure replacement, it is very dif.cult to know how many data elements are accessed for a find \noperation in the alternative data structure (set) just by in\u00adstrumenting the code of the original data \nstructure (vector); that requires exactly tracking data insertion and deletion, operation or\u00adder, orderedness \nof data values, search patterns, and so on. This subtlety of modeling the execution behavior of the alternative \ndata structure forces the prior works to rely on asymptotic analysis and average case. However, such \napproximation is likely to generate in\u00adaccurate models. Thus we conclude that if the resulting models \nare inaccurate, why pay the cost of heavy instrumentation code for M x N models? In this work, rather \nthan modeling the execution of the alter\u00adnative data structure, Brainy s machine learning-based model \ntries to answer the question, what alternative data structure is desir\u00adable when the original data structure \nbehaves in a certain way? That is, Brainy focuses on modeling how the original data struc\u00adture is executed \nto identify the relation between the execution lo\u00adcation and the alternative data structures suited for \nthe role. Conse\u00adquently, Brainy reduces the number of models required compared to the prior works. The \nlast problem is about using hardware features, which are important as shown in Section 5.1. Unlike software \nfeatures such as the number of function calls and their costs, it is almost impossible to model hardware \nfeatures of the alternative data structure. For example, the number of mispredictions of conditional \nbranches in the original data structure has no causal relation to the number of mispredictions in the \nalternative data structure. Thus, the prior works cannot effectively exploit hardware features while \nBrainy s machine learning-based model can. Again, the hardware features are critical for effective data \nstructure selection. In a different perspective, a body of work has been done to ad\u00address inef.cient \nuse of data structures in terms of memory bloat [19, 20, 36, 37]. In [19], Mitchell and Sevitsky suggest \na systematic ap\u00adproach to detect those data structures that end up with unnecessary memory (bloat). They \nintroduces a new notion, Health, that ana\u00adlyzes how the memory space of a data structure is organized \nand used; and they present judgement schemes based on the notion to determine the inef.ciency of the \ndata structure use [36]. Xu and Rountev also present static and dynamic tools that detect inef.\u00adciently \nused data structures to avoid. They .rst identify interface functions (e.g, ADD/GET) of a data structure \nusing static analy\u00adsis. Then the static or dynamic tools analyze how these interface functions are called \nduring the data structure execution. There are key differences between these prior works and Brainy. \nFirst, they target Java and rely on virtual machine support. Again, Brainy is not restricted to languages \nthat have managed runtime features. Second, they can deal with only case of the bloat-caused inef.ciency \nof data structures. In C/C++, bloat is less of a concern than in Java where garbage collection is very \nimportant. Brainy can deal with many more cases of data structure inef.ciency. Finally, they do not select \na data structure, i.e., they just show if a data struc\u00adture is inef.cient in terms of bloat. In contrast, \nBrainy does provide a solution for inef.cient usage of a data structure by selecting an alternative data \nstructure. Looking beyond data structures, the use of machine learning has become quite popular in the \ndesign of program optimizers [7, 16, 22, 31 33]. This paper applies many of the same techniques to a \nnew domain, and provides insight on what needs to be considered for the success of machine learning in \nthis particular problem. Coons et al. showed that careful feature selections can be helpful in reducing \nthe dimensions of the search space, as well as achieving better solutions for .nding good distributed \ninstruction placements for an EDGE architecture [4]. This paper also considers careful feature selections. \nMany researchers have also investigated hardware effects for high performance computing. Especially, \nin computational science domain, the awareness of underlying architecture is essential for extracting \nthe best performance [23]. One promising approach is ATLAS (Automatically Tuned Linear Algebra Software) \nlibrary. The philosophy of ATLAS exactly follows Brainy s. ATLAS .ne\u00adtunes its computational kernel by \nconsidering underlying hardware architecture during its install-time and adapts the various parame\u00adters \nof the library internals accordingly [1]. Since many develop\u00aders of the system can keep using the optimized \nlibrary, the tuning time is not a problem in general. Similarly, data structure library is one of the \nmost frequently used libraries in many systems; Brainy s training time is not a problem in that sense. \n 8. Summary Data structure selection is one of the most critical aspects in de\u00adtermining program ef.ciency. \nThis paper presents Brainy, a novel and repeatable methodology for generating machine-learning based \nmodels to predict what the best data structure implementation is given a program, a set of inputs, and \na target architecture. The work introduces a random program generator that is used to train the machine \nlearning models, and demonstrates that these models are more accurate and more effective than previously \nproposed hand\u00adconstructed models based on traditional asymptotic analysis for real-world applications. \nThe experimental results show that Brainy achieved an average performance improvement of 27% and 33% \non two real machines with different processors. Acknowledgments Many thanks to Hyojun Kim, Sangho Lee, \nHyunshik Shin, Jonathan C. Kim, Phillip Wright, Haicheng Wu, Nishad Kothari who helped edit initial versions \nof this draft, as well as Ahmad Sharif, Robert Hundt, and the anonymous referees who provided excellent \nfeed\u00adback to help shape this work. Portions of this work were made pos\u00adsible with support from Google. \nThe authors gratefully acknowl\u00adedge the support of NSF grants CCF-1018544 and CCF-0916962. References \n[1] C. W. Antoine, A. Petitet, and J. J. Dongarra. Automated empirical optimization of software and the \natlas project. Parallel Computing, 27:2001, 2000. [2] M. Aref. Discussions on the LogicBlox Datalog Optimization \nEngine,2009. personal communication. [3] I.-H. Chung. Towards Automatic Performance Tuning. PhD thesis, \nUniversity of Maryland, College Park, 2004. [4] K. E. Coons, B. Robatmili, M. E. Taylor, A. Maher, D. \nBurger,and K. S. Mckinley. Feature selection and policy optimization fordistributed instruction placement \nusing reinforcement learning. In PACT 08 : Proceddings of the 17th International Conference on Par\u00adallel \nArchitectures and Compilation Techniques, 2008. [5] S. Q. Ding and C. Xiang. Over.tting problem: a new \nperspective fromthe geometrical interpretation of mlp. pages 50 57, 2003. [6] J. Dongarra, K. London, \nS. Moore, P. Mucci, and D. Terpstra. Usingpapi for hardware performance monitoring on linux systems. \nIn Proceedings of the 2nd International Conference on Linux Clusters:The HPC Revolution, Linux Clusters \nInstitute, 2001. [7] C. Dubach, J. Cavazos, B. Franke, G. Fursin, M. F. P. O Boyle, and O. Temam. Fast \ncompiler optimisation evaluation using code-featurebased performance prediction. In ACM International \nConference on Computing Frontiers, 2007. [8] GCC, the GNU Compiler Collection. the gcc team, 2010. http://gcc.gnu.org. \n[9] Google. Google code search, 2009. http://www.google.com/codesearh. [10] D. Gus.eld. Algorithms on \nStrings, Trees, and Sequences: ComputerScience and Computational Biology. Cambridge University Press, \n1997. [11] M. H. Hassoun. Fundamentals of Arti.cial Neural Networks. MIT Press, Cambridge, MA, USA, 1995. \n[12] F. Hussein. Genetic algorithms for feature selection and weighting, areview and study. In ICDAR \n01: Proceedings of the Sixth Interna\u00adtional Conference on Document Analysis and Recognition, page 1240, \nWashington, DC, USA, 2001. [13] J. Jarmulak and S. Craw. S.: Genetic algorithms for feature selection \nand weighting. in. In Proceedings of the IJCAI 99 workshop onAutomating the Construction of Case Based \nReasoners, pages 28 33, 1999. [14] C. Jung and N. Clark. Ddt: design and evaluation of a dynamicprogram \nanalysis for optimizing data structure usage. In MICRO 42: Proceedings of the 42nd Annual IEEE/ACM International \nSymposiumon Microarchitecture, pages 56 66, New York, NY, USA, 2009. ACM. [15] S. B. Kotsiantis. Supervised \nmachine learning: A review of classi.ca\u00adtion techniques. Informatica (Slovenia), 31(3):249 268, 2007. \n[16] H. Leather, E. Bonilla, and M. O Boyle. Automatic Feature Genera\u00adtion for Machine Learning Based \nOptimizing Compilation. In Proc. of the 2009 International Symposium on Code Generation and Opti\u00admization, \nMar. 2009. [17] L. Liu and S. Rus. per.int: A Context Sensitive Performance Advisorfor C++ Programs. \nIn Proc. of the 2009 International Symposium onCode Generation and Optimization, Mar. 2009. [18] T. Mens \nand T. Tourwe. A survey of software refactoring. IEEE Transactions on Software Engineering, 30(2):126 \n139, 2004. [19] N. Mitchell and G. Sevitsky. The causes of bloat, the limits of health. In Proceedings \nof the 22nd annual ACM SIGPLAN conferenceon Object-oriented programming systems and applications, OOPSLA \n07, pages 245 260, New York, NY, USA, 2007. [20] N. Mitchell, E. Schonberg, and G. Sevitsky. Four trends \nleading to java runtime bloat. IEEE Software, 27:56 63, 2010. [21] T. M. Mitchell. Machine Learning. \nMcGraw-Hill, New York, 1997. [22] A. Monsifrot, F. Bodin, and R. Quiniou. A machine learning ap\u00adproach \nto automatic production of compiler heuristics. In AIMSA 02: Proceedings of the 10th International Conference \non Arti.cial Intelli\u00adgence: Methodology, Systems, and Applications, pages 41 50, 2002. [23] M. Muller-Hannemann \nand S. Schirra, editors. Algorithm engi\u00adneering: bridging the gap between algorithm theory and practice. \nSpringer-Verlag, Berlin, Heidelberg, 2010. ISBN 3-642-14865-4, 978\u00ad3-642-14865-1. [24] D. E. Rumelhart, \nG. E. Hinton, and R. J. Williams. Learning internalrepresentations by error propagation. pages 673 695, \n1988. [25] E. Schonberg, J. T. Schwartz, and M. Sharir. An automatic techniquefor selection of data representations \nin setl programs. ACM Trans. Program. Lang. Syst., 3:126 143, April 1981. [26] J. T. Schwartz. Automatic \ndata structure choice in a language of veryhigh level. In POPL 75: Proceedings of the 2nd ACM SIGACT-SIGPLAN \nsymposium on Principles of programming languages, pages 36 40, 1975. [27] O. Shacham, M. Vechev, and \nE. Yahav. Chameleon: adaptive selectionof collections. In PLDI 09: Proceedings of the 2009 ACM SIGPLANconference \non Programming language design and implementation, pages 408 418, 2009. [28] W. Siedlecki and J. Sklansky. \nA note on genetic algorithms for large\u00adscale feature selection. Pattern Recogn. Lett., 10(5):335 347, \n1989. [29] D. D. Sleator and R. E. Tarjan. Self-adjusting binary search trees. J. ACM, 32(3):652 686, \n1985. [30] A. Stepanov and M. Lee. The standard template library. Technical re\u00adport, WG21/N0482, ISO \nProgramming Language C++ Project, 1994. [31] M. W. Stephenson. Automating the Construction of Compiler \nHeuris\u00adtics Using Machine Learning. PhD thesis, Massachusetts Institute of Technology, 2006. [32] G. \nTournavitis, Z. Wang, B. Franke, and M. F. O Boyle. Towards a holistic approach to auto-parallelization: \nintegrating pro.le-drivenparallelism detection and machine-learning based mapping. In Pro\u00adceedings of \nthe 2009 ACM SIGPLAN conference on Programminglanguage design and implementation, PLDI 09, pages 177 \n187, New York, NY, USA, 2009. ACM. [33] Z. Wang and M. F. O Boyle. Mapping parallelism to multi-cores: \namachine learning based approach. In PPoPP 09: Proceedings of the14th ACM SIGPLAN symposium on Principles \nand practice of parallelprogramming, pages 75 84, 2009. [34] S. Williams, L. Oliker, R. Vuduc, J. Shalf, \nK. Yelick, and J. Demmel.Optimization of Sparse Matrix-Vector Multiplication on EmergingMulticore Platforms. \nIn Proc. Supercomputing 07, 2007. [35] N. Wirth. Algorithms + Data Structures = Programs. Prentice Hall, \n1978. [36] G. Xu and A. Rountev. Detecting inef.ciently-used containers to avoidbloat. In ACM SIGPLAN \n2010 Conference on Programming LanguageDesign and Implementation. ACM, 2010. [37] G. Xu, N. Mitchell, \nM. Arnold, A. Rountev, and G. Sevitsky. Soft\u00adware bloat analysis: .nding, removing, and preventing performanceproblems \nin modern large-scale object-oriented applications. In Pro\u00adceedings of the FSE/SDP workshop on Future \nof software engineer\u00ading research, FoSER 10, pages 421 426, New York, NY, USA, 2010. ACM.   \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Data structure selection is one of the most critical aspects of developing effective applications. By analyzing data structures' behavior and their interaction with the rest of the application on the underlying architecture, tools can make suggestions for alternative data structures better suited for the program input on which the application runs. Consequently, developers can optimize their data structure usage to make the application conscious of an underlying architecture and a particular program input.</p> <p>This paper presents the design and evaluation of Brainy, a new program analysis tool that automatically selects the best data structure for a given program and its input on a specific microarchitecture. The data structure's interface functions are instrumented to dynamically monitor how the data structure interacts with the application for a given input. The instrumentation records traces of various runtime characteristics including underlying architecture-specific events. These generated traces are analyzed and fed into an offline model, constructed using machine learning, to select the best data structure. That is, Brainy exploits runtime feedback of data structures to model the situation an application runs on, and selects the best data structure for a given application/input/architecture combination based on the constructed model. The empirical evaluation shows that this technique is highly accurate across several real-world applications with various program input sets on two different state-of-the-art microarchitectures. Consequently, Brainy achieved an average performance improvement of 27% and 33% on both microarchitectures, respectively.</p>", "authors": [{"name": "Changhee Jung", "author_profile_id": "81100073577", "affiliation": "Georgia Institute of Technology, Atlanta, GA, USA", "person_id": "P2690490", "email_address": "cjung9@cc.gatech.edu", "orcid_id": ""}, {"name": "Silvius Rus", "author_profile_id": "81100618860", "affiliation": "Google Inc., Mountain View, USA", "person_id": "P2690491", "email_address": "rus@google.com", "orcid_id": ""}, {"name": "Brian P. Railing", "author_profile_id": "81485659413", "affiliation": "Georgia Institute of Technology, Atlanta, GA, USA", "person_id": "P2690492", "email_address": "brailing@cc.gatech.edu", "orcid_id": ""}, {"name": "Nathan Clark", "author_profile_id": "81100621262", "affiliation": "Virtu Financial, New York, USA", "person_id": "P2690493", "email_address": "nclark@virtufinalcial.com", "orcid_id": ""}, {"name": "Santosh Pande", "author_profile_id": "81409594751", "affiliation": "Georgia Institute of Technology, Atlanta, GA, USA", "person_id": "P2690494", "email_address": "santosh@cc.gatech.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993509", "year": "2011", "article_id": "1993509", "conference": "PLDI", "title": "Brainy: effective selection of data structures", "url": "http://dl.acm.org/citation.cfm?id=1993509"}