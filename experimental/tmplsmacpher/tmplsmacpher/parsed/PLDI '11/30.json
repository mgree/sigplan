{"article_publication_date": "06-04-2011", "fulltext": "\n Language-Independent Sandboxing of Just-In-Time Compilation and Self-Modifying Code Ulfar Erlingsson, \nElijah Taylor, Brad Chen, Derek L. Schuff, David Sehr, Cliff L. Bif.e, Bennet Yee Jason Ansel Petr Marchenko \nComputer Science and Arti.cial Intelligence Laboratory Massachusetts Institute of Technology jansel@csail.mit.edu \nUniversity College London p.marchenko@cs.ucl.ac.uk \u00b4 Google Inc. {ulfar, elijahtaylor, bradchen, dschu., \nsehr, cbi.e, bsy}@google.com Abstract When dealing with dynamic, untrusted content, such as on the Web, \nsoftware behavior must be sandboxed, typically through use of a language like JavaScript. However, even \nfor such specially\u00addesigned languages, it is dif.cult to ensure the safety of highly\u00adoptimized, dynamic \nlanguage runtimes which, for ef.ciency, rely on advanced techniques such as Just-In-Time (JIT) compilation, \nlarge libraries of native-code support routines, and intricate mechanisms for multi-threading and garbage \ncollection. Each new runtime provides a new potential attack surface and this security risk raises a \nbarrier to the adoption of new languages for creating untrusted content. Removing this limitation, this \npaper introduces general mech\u00adanisms for safely and ef.ciently sandboxing software, such as dynamic language \nruntimes, that make use of advanced, low\u00adlevel techniques like runtime code modi.cation. Our language\u00adindependent \nsandboxing builds on Software-based Fault Isolation (SFI), a traditionally static technique. We provide \na more .exible form of SFI by adding new constraints and mechanisms that allow safety to be guaranteed \ndespite runtime code modi.cations. We have added our extensions to both the x86-32 and x86-64 variants \nof a production-quality, SFI-based sandboxing platform; on those two architectures SFI mechanisms face \ndifferent challenges. We have also ported two representative language platforms to our extended sandbox: \nthe Mono common language runtime and the V8 JavaScript engine. In detailed evaluations, we .nd that sandboxing \nslowdown varies between different benchmarks, languages, and hardware platforms. Overheads are generally \nmoderate and they are close to zero for some important benchmark/platform combinations. Categories and \nSubject Descriptors D.4.6 [Operating Systems]: Security and Protection General Terms Languages, Security \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n11, June 4 8, 2011, San Jose, California, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. \n. . $10.00 Keywords Sandboxing, Security, Software Fault Isolation, Self-Modifying Code, Just-In-Time \nCompilation 1. Introduction The safe con.nement of software behavior, or sandboxing, is a key requirement \nin many contexts. On the Web, sandboxing is especially important since Web applications are a form of \nhighly\u00addynamic, untrusted software, and non-isolated Web software, such as browser plugins and ActiveX \ncontrols, have been, and remain, a leading source of security vulnerabilities [6, 17]. As a result, Web \napplications are mostly written in one of a handful of high\u00adlevel, dynamic programming languages speci.cally \ndesigned for untrusted content most commonly JavaScript [16]. Software safety is in tension with ef.ciency: \neven languages like Java and JavaScript are executed not through simple interpretation, but on top of \nhighly-ef.cient runtime platforms. The safety of those language platforms depends on large amounts of \ntrusted (possibly .awed) native code implementing extensive libraries, as well as advanced mechanisms \nlike runtime code generation and garbage collection [3, 33]. Thus, each such language adds new potential \nmeans of attack, as evidenced by the frequent exploits of Web\u00adbased languages [13, 55]. Fortunately, \nas we show in this paper, sandboxing can be language independent, provide strong safety guarantees, low \noverhead, and do this without restricting language choice or lan\u00adguage implementation options. The entirety \nof dynamic software execution can be sandboxed, including the language platform, even if it uses just-in-time \ncompilation, runtime code modi.cation, or large bodies of legacy code. Despite being comprehensive, such \nsandboxing need induce only moderate slowdowns. As shown by our experimental results, in many important \ncases sandboxing may incur no overhead. Such language-independent sandboxing promises more technology \noptions for untrusted content development in particular, on the Web. Our language-independent sandboxing \nis not based on hardware protection domains, such as the common process abstraction. These offer neither \nhigh assurance nor universal applicability, particularly in cases where a .ne granularity of protection \ndomains is desired. Their use is intricate and error-prone, leading to non\u00adportable implementations and \npartial protection [4, 20, 54]. Also, the performance impact of hardware context switching can severely \nlimit applicability [19]. Instead, our work is based on Software-based Fault Isolation (SFI) [53], which \nprovides high-assurance safety guarantees and is largely independent of the operating system and other \nsystem\u00adlevel details. SFI relies on machine code veri.cation through static analysis and, to date, has \nnot been applicable to sandboxing software that modify machine code at runtime. Removing this obstacle, \nwe present extensions to SFI techniques that allow ef.cient, safe sandboxing of mechanisms such as just-in-time \ncode generation and runtime code modi.cation. Key to our extensions are new safety constraints on the \nstructure of machine code that apply, inductively, even across code modi.cation.  We have implemented \nour extensions in the context of the Native Client open-source project: a production-quality SFI-based \nsandbox [44, 56]. Our extended sandbox provides ef.cient ways to add, modify, and delete code. It transparently \nallows safe reuse of code memory without race conditions and without suspending threads, even on hardware-threaded, \nconcurrent systems. Our extensions add little overhead, partly because our new safety constraints are \nnot onerous, but also because they are veri.ed only when code is modi.ed, not when code is used. We have \nported two popular, representative JIT-compiled language systems to our sandbox: the Mono CLR runtime \n[41], which supports C#, and the V8 JavaScript engine [27]. V8 motivated our work. Its speed compared \nto previous JavaScript engines clearly demonstrates the advantages of runtime code generation over even \nhighly-optimized interpretation. Our design was further in.uenced by V8 s use of code rewriting for inline \ncode caches and the 12x slowdown that we saw V8 incur when we disabled its code cache mechanisms. Porting \nMono and V8 consisted primarily of changing them to output veri.ably-safe code, and inductively maintaining \nsafety across modi.cations to that code. We targeted two commodity hardware platforms: the x86-32 and \nx86-64 instruction set architec\u00adtures (ISAs) [25, 28]. These two ISAs have signi.cantly different characteristics \nfor the purposes of Native Client sandboxing. On x86-32, hardware segments allow low runtime overheads \nand simpli.ed implementation of our extensions. On x86-64, extensive use is made of inline code that \nperforms runtime sandboxing, and this both reduces performance and complicates porting efforts. We found \nthat the Mono and V8 platforms, and their x86-32 and x86-64 variants, spanned a wide range in terms of \nthe porting effort required and the sandboxing slowdown incurred. At one end, Mono-32, porting effort \nwas low and the measured overhead is near negligible. At the other extreme, V8-64, porting took a few \nweeks and sandboxing slowdown is between 51% and 60% on average, but 196% in one benchmark (due to a \nporting shortcut, as explained in Section 4). Notably, in all cases sandboxing overhead was much lower \nthan what might be expected of a highly-ef.cient interpreter, where even favorable workloads incur factors \nof overhead [21, 43]. 1.1 Contributions This paper makes the following contributions: A set of locally-veri.able \nmachine code constraints that allow safe, SFI-based sandboxing even of runtime code modi.cation.  A \ntechnique for safe runtime modi.cation of machine code on commodity hardware, despite the simultaneous \nexecution of that code on other processors by untrusted user threads.  A technique for the safe deletion \nof code memory, and its reuse for new instructions, despite potentially concurrent execution of untrusted \nuser threads in that code memory.  Implementation of our language-independent sandbox for x86\u00ad32 and \nx86-64, as well as ports of the V8 and Mono runtimes, allowing software to embed languages like JavaScript \nand C# as untrusted components.  Experience showing that it can be straightforward to port mod\u00adern, \nadvanced language runtimes to execute within language\u00adindependent sandboxing.  Experimental results \nshowing that, while overhead varies between platforms, sandboxing overhead is generally modest, and that \na sandboxed advanced language runtime incurs far less overhead than the published slowdown of using interpretation. \n A somewhat surprising optimization technique relying on careful selection of even unexecuted NOP instructions. \n To create safe, low-overhead runtime code-modi.cation mech\u00adanisms that were easy to use, we had to \nsimultaneously satisfy a great number of constraints. These include the constraints imposed by the NaCl \nSFI sandbox, the concrete properties of the NaCl runtime system and the operating systems and hardware \nCPUs it runs upon, as well as the practical characteristics of language platform implementations. While \nthe primitives introduced are straightforward, the intricacy of the underlying mechanisms and the lack \nof similar mechanisms in previous SFI systems is evidence of the dif.culty in creating their implementation. \n 1.2 Motivating Application Our work has been motivated by the tantalizing possibility of language-independent \nsoftware development of safe, untrusted Web applications. The foundation for our implementation, Native \nClient has been integrated with the Chrome Web browser, where it provides access to JavaScript Web interfaces \n[44, 56]. Our extended sandboxing allows safe execution of ported language runtimes, and their native \nlibraries, even when they make use of advanced code modi.cation techniques for ef.ciency. Contrast this \nwith today s reality, where rich, interactive Web clients must be written in JavaScript, either from \nscratch, or via source-to-source translation, with resulting dif.culties and inef.ciencies [9, 26]. (The \nalternatives are neither practical nor appealing: asking users to install Web browser plugins for new \nlanguages, or using partially\u00addeployed languages like Java.) Adding our extended sandbox to a Web browser \ncould enable writing a Web page in any language, as long as that language runtime is downloaded as part \nof the page.  1.3 Outline The remainder of this paper is organized as follows. Section 2 provides background \non SFI and the Native Client sandbox. Section 3 covers the design and implementation of our sandboxing \nextensions. Section 4 describes our experience porting language runtimes to our extended sandbox. Section \n5 shows experimental results, examines the sources of overhead, and explains optimiza\u00adtion via NOP instruction \nselection. Finally, Sections 6 and 7 describe related work and draw conclusions. 2. Background This work \nbuilds on the Native Client open-source project [44, 56] commonly abbreviated NaCl when used as an adjective. \nThe NaCl sandbox uses Software-based Fault Isolation (SFI) [32, 53] to restrict what instructions can \nbe executed, in what sequence, and constrain the memory addresses used by instructions. SFI provides \nhigh-assurance safety guarantees by combining static analysis with software guards: short, inline instruction \nsequences that perform runtime safety checks or sandboxing operations. In this, SFI is similar to language-runtime \nmechanisms ranging from dynamic array-bounds checks [39] to concurrency controls such as software\u00adtransactional \nmemory [48]. SFI allows the creation of statically veri.able machine code: code that, through static \nanalysis, can be independently veri.ed to permit only constrained executions, irrespective of how it \nwas Figure 1. Overview of abstract NaCl machine code, with each .xed-width (32 byte) row denoting a NaCl \ninstruction bundle starting at an aligned address. Vertical lines show instruction boundaries, while \nshaded regions show NOP padding; dashed arrows indicate permitted direct and indirect control .ow. Two \nNaCl pseudo instructions are shown as gradient-shaded boxes.  created (e.g., through compilation from \na high-level language). As with Java bytecode veri.cation [30], SFI establishes safety primarily by checking \nsimple, local properties of code, where those properties, in aggregate, imply global execution invariants. \nTo ensure that safety holds for all possible execution paths, SFI restricts both direct and indirect \ncontrol transfers, implementing a form of control-.ow integrity [1]. SFI must, in particular, prevent \ncontrol .ow from circumventing inline software guards as this would allow unconstrained execution, including \ncontrol transfers to disallowed instructions. On top of its SFI sandboxing, Native Client provides a \nproduction-quality, fully-functional platform for the safe execution of untrusted, multi-threaded user-level \nmachine code. Native Client is designed to minimize the overhead of safety: even untrusted, hand-optimized \nmedia codecs can be executed at near full speed, since SFI allows safe use of hand-written assembly and \nmodel\u00adspeci.c instructions, such as the MMX and SSE extensions on x86. The NaCl platform also provides \na programming model for high\u00adlevel languages using ILP32 (32-bit Integers, Longs and Pointers) primitive \ntypes and a portable subset of POSIX-like system calls. Native Client implements a relatively simple \nvariant of SFI, fundamentally based on reliable disassembly: the use of alignment and other machine-code \nconstraints to ensure runtime-reachable instructions can be statically identi.ed. Unlike in more complex \nSFI implementations [20], each NaCl software guard is combined into a pseudo instruction with an adjacent, \npotentially-unsafe instruction, making each guard constrain the behavior of only a single instruction. \nAs in PittSFIeld [32], NaCl machine code is structured as aligned instruction bundles of .xed size (32 \nbytes). NOP padding is used to ensure that no instruction overlaps the boundary of such an aligned instruction \nbundle. Control-.ow instructions must target valid code, and all computed control transfers must target \nthe start of a instruction bundle. Indirect jumps are allowed only via a pseudo-instruction that aligns \nthe target address, and NOP padding is used to ensure CALL instructions appear only at the end of instruction \nbundles, so that return addresses are always aligned. In addition, NaCl execution is constrained to a \nsingle, contiguous code region, with access to a restricted set of NaCl platform support routines, and \nmemory access is limited to a single, contiguous region of untrusted data memory, which also contains \nthe stacks for threads. Figure 1 gives an overview of the structure of NaCl machine code for an abstract \nISA, showing the details of one NaCl code region, comprising .ve NaCl instruction bundles. Native Client \nindependently veri.es the safety of each such code region, one at a time; in our extended sandboxing, \nthis is the region being added or modi.ed. For the .rst instruction, a direct jump forward by 38 bytes \n(or 0x26), NaCl veri.cation establishes that the target is a valid instruction boundary within the code \nregion. The two remaining instructions are NaCl pseudo instructions that use the register R to write \nto memory at address R and call the function at address R. For these pseudo instructions, NaCl veri.cation \nestablishes the correctness of the software guards used to sandbox the register R. For CALL instructions, \nboth their target address and the pushed return address must be the start of an aligned instruction bundle. \nNaCl veri.cation also imposes many structural constraints on machine code; for instance, direct jumps \nmay not target the inner boundaries of pseudo instructions. NOP padding may need to be used to ensure \nproper alignment and, as clearly shown in Figure 1, large amounts of such padding may be required, especially \naround CALL instructions. Native Client additionally prohibits use of the x86 RET opcode. Returns should \nbe implemented with a POP/JMP sequence. Checking the return address in a register avoids a potential \ntime\u00adof-check/time-of-use race if it were checked on the stack. Native Client supports three architectures, \nx86-32, x86-64, and ARM. Like other SFI systems, Native Client also makes use of operating-system and \nhardware support where appropriate, e.g., to ensure that data is not executable, and that code is not \nwritable and is loaded at the correct address. In particular, on the 32-bit x86 platform, Native Client \nrelies on hardware segments, not software guards, to constrain reads and writes to data memory, as well \nas code execution. However, the baseline overhead of Native Client will vary with each platform: on ARM \nand 64-bit x86, bounded segments aren t available, and software guards must be used for each computed \naccess to memory. Our work in this paper extends SFI techniques to be applicable to runtime code generation \nand modi.cation through the addition of new, inductively-maintained safety constraints on the structure \nof machine code. Our motivation is primarily performance: compared to a JIT-compiled runtime, even the \nmost highly\u00adoptimized interpreter on its most favorable workload is likely to be twice as slow [21, 43]. \nOptimized JIT compilation also makes use of runtime code modi.cation for instance, to allow machine-code \nconstants to be modi.ed to point to new code emitted by the JIT compiler, or to make more extensive updates, \nsuch as to the V8 code caches. Instead of modifying immediate constants in machine code, JIT compilers \ncan emit code based on additional levels of indirection; however, such indirection comes at signi.cant \nperformance cost, by pulling in additional cache lines and increasing the rate of memory accesses. Furthermore, \nlanguage runtimes often make use of runtime code generation or modi.cation for various purposes other \nthan performance, ranging from debugging and pro.ling, through various instrumentation, to speci.c mechanisms \nsuch as runtime barriers [2, 10, 23, 29, 38]. Even though this paper focuses on JIT compilation, .exibility \nis another motivation for our work. 3. Core Mechanisms: Design and Implementation This section describes \nthe design and implementation of our extensions to Native Client to support runtime code modi.cation. \nAfter outlining our extensions to the Native Client system call interface, we then describe the implementation \nin detail, and how it supports dynamic code creation, modi.cation, and deletion. 3.1 Programming Interface \nTable 1 lists the interfaces added to the trusted runtime of Native Client to support dynamic code manipulation. \nNaCl machine code comprises one or more code regions. Our extensions allow the addition and deletion \nof code regions, as well as the modi.cation  int nacl_dyncode_create(void* target , void* src, size_ \nt size); int nacl_dyncode_modify(void* target , void* src, size_ t size); int nacl_dyncode_delete(void* \ntarget , size_ t size); Table 1. The interfaces to our NaCl extensions for dynamically adding and deleting \ncode regions, and modifying the instructions within a code region. of code within a region. All code \nregions reside within the same single, contiguous address range of executable memory, whose size is set \nat link time. Executable memory can be modi.ed only through the trusted interfaces, not directly from \nNaCl code. As an example of using our interfaces, consider the JIT compilation of a single function. \nThe JIT compiler, running as untrusted NaCl code, generates machine-code in a temporary buffer in data \nmemory. To install the code, the JIT invokes nacl dyncode create, transferring control into the NaCl \ntrusted runtime. This runtime validates the code and installs it in executable memory, described in detail \nbelow. After creation, the JIT may wish to modify the code, for example, to update a pointer address \nstored in an immediate pointer. The trusted nacl dyncode modify interface supports these modi.cations. \nIf at some point the code is no longer needed, it can be deleted and the memory reused using nacl dyncode \ndelete. As Native Client supports concurrent untrusted user threads, the runtime must verify that no \nthreads are executing in the code before it can be safely reused. As nacl dyncode delete does not block, \nit will return an error code if it cannot verify that all threads have left the deleted region. Section \n3.5 describes the implementation in detail.  3.2 Dynamic Code Creation Supporting dynamic creation of \ncode required only simple ex\u00adtensions to Native Client. Our implementation leverages existing NaCl veri.cation \noutlined in Section 2. Code creation involves the following operations: 1. The target code address is \nveri.ed to be in NaCl executable memory, and aligned to an instruction bundle boundary. 2. To avoid \na time-of-test/time-of-use race condition, the code is copied to the private memory of the trusted NaCl \nruntime. 3. The code is veri.ed using the standard NaCl validator. 4. The target address range in NaCl \nexecutable memory is checked to be unused and also reserved, in one atomic operation. 5. The code is \nsafely copied to the target address.  Each NaCl code region is veri.ed independently, and all control \n.ow between code regions, whether direct or computed, must target the start of a NaCl instruction bundle. \nFor this, NaCl veri.cation relies on a property of HLT instructions: in Native Client, executing a HLT \n(the halt instruction) results in the immediate, permanent termination of all NaCl execution threads. \nTo ensure safety, unused executable NaCl memory is .lled with HLT instructions. For safe copying of veri.ed \ncode regions, the .rst byte of each instruction bundle is written as a HLT instruction until all other \ncode bytes have been copied. Then the .rst byte of each instruction bundle is written with the intended \nvalue. 3.3 NaCl Veri.cation of Runtime Code Modi.cations Practical sandboxing of dynamic language runtimes \nrequires our extended Native Client platform to support runtime code modi.cation. With our design, veri.cation \noverhead is proportional to the number of changed instructions. Veri.cation requires inspection only \nof modi.ed instruction bundles and of instruction bundles targeted by direct control-.ow transfers from \nmodi.ed instructions. Table 2 lists the complete set of code safety constraints necessary for NaCl veri.cation \nof dynamically-modi.ed code. These constraints imply immutability of the instruction boundaries and the \nNaCl guard instructions in the modi.ed code. They maintain the NaCl safety guarantees across code modi.cation, \nsince they preserve all properties established by runtime guards, as well as the structural properties \nof NaCl machine code. These immutability properties restrict the set of allowed code modi.cations, notably \non platforms with variable-length instructions like x86-32. For example, the constraints would prevent \ntwo short, adjacent instructions from being overwritten with a single larger instruction, unless the \nentire code region is deleted .rst. In practice we have not found these restrictions to be onerous, as \ndemonstrated by our porting work described in Section 4, Immutability also helps prevent race conditions: \nour safety guarantees hold even in the presence of concurrent, untrusted threads that are executing the \ncode under modi.cation, as long as individual instructions are updated atomically.  3.4 Atomic Modi.cation \nof Machine-Code Instructions If a thread uses nacl dyncode modify to modify an instruction, then concurrent \nthreads should execute either the old or new instructions, but no other instructions. It is dif.cult \nto provide atomicity without a cost to ef.ciency, especially on multi-core or otherwise hardware-threaded \nsystems. Runtime code modi.cation is relatively uncommon; when used, it is usually performed in a synchronous \nfashion, via the operating system or a trusted language runtime. Therefore, CPU designers have had few \nincentives to provide reliable, simple primitives that allow code modi.cation to appear atomic across \nconcurrently\u00adexecuting hardware threads. Indeed, in order to support mech\u00adanisms such as instruction \nprefetch buffers, AMD and Intel processor documentation outlines a special memory model for updates to \nconcurrently-executing machine-code memory [25, 28]. On multicore and multiprocessor systems, a naive \nimplemen\u00adtation of runtime code modi.cation can lead to the execution of corrupted instructions. To understand \nthe possibility of such instruction stream corruption, we ran highly-concurrent code modi.cation experiments, \nusing straightforward code modi.cation. We found that corruption was indeed possible on all processors \nthat we tested; Sundaresan et al. made similar observations in their development of a Java JIT compiler \n[49]. Fortunately, with careful implementation, both AMD and Intel processors can support safe cross-modi.cation \nof hardware\u00adthreaded machine code from user mode. On Intel processors, regular atomic writes to memory \ncan be used to reliably modify machine-code instructions that fall entirely within a 16-byte aligned \nregion of code memory although instructions that span two such aligned memory regions cannot be updated \natomically. The same holds true for AMD processors, except that only smaller, 8-byte code memory regions \nare supported. We con.rmed these properties through both our experiments and also through a conservative \nreading of the relevant documentation [25, 28]. When instructions span these code memory alignment bound\u00adaries, \nthey can still be modi.ed without instruction-stream cor\u00adruption, through a careful implementation and \nuse of memory synchronization barriers. We crafted such a code-modi.cation mechanism, and conservatively \nchose to always apply AMD s  NEW must satisfy all NaCl safety veri.cation constraints, as outlined \nin Section 2.  Both NEW and OLD must start at the same address, be of equal size, and lie within a single \ncode region.  Any direct control-transfer instructions in NEW must target valid instruction boundaries \nin the same code region.  NEW and OLD must start and end at instruction boundaries, and all instruction \nboundaries between must be identical.  No pseudo instructions are added or removed. NEW may not introduce \nnew pseudo instructions. All pseudo-instructions in OLD must occur in NEW and have identical guard instructions. \n Table 2. Constraints imposed on runtime code modi.cations by our extended NaCl sandboxing, when machine \ncode OLD is replaced with machine code NEW. 8-byte alignment constraints, which ensures our implementation \nexecutes correctly on both AMD and Intel processors. The pseudo code in Figure 2 shows our mechanism \nfor safe, atomic instruction replacement. One instruction is copied at a time. When possible, we copy \nan entire instruction with a single 8\u00adbyte, aligned write to memory, using a fast path modi.cation sequence. \nThis fast path performs a read-modify-write update of the 8-byte, aligned block of of memory around the \nold instruction. This block of code memory is read into a temporary variable, and the old instruction \nbytes within it are replaced with those of the new instruction; then the temporary variable is written \nusing a single aligned 8-byte store to code memory. The above fast path mechanism cannot be used if the \nold instruction straddles an 8-byte alignment boundary. In this case, our implementation works as shown \nin Figure 2: we modify the target instruction bytes in three steps, keeping a one-byte HLT as the .rst \nbyte of the instruction while the instruction is being modi.ed. We use serialization barriers to synchronize \nthe instruction stream and view of code memory for all hardware threads, including other cores or processors \n[25, 28]. Considering all possible interleavings, it is easy to see why the above code allows a series \nof machine-code instructions to be atomically replaced with new, equal-size instructions: Before the \n.rst serialization barrier: The one-byte write will be atomic; a concurrent thread will execute either \nthe original instruction or the HLT instruction.  Between the serialization barriers: No threads can \nexecute the target instruction without executing the HLT instruction encoded in its .rst byte.  After \nthe second serialization barrier: As the one-byte write will be atomic, other threads will execute either \nthe new instruction or the HLT instruction.  Our technique relies on a serialization barrier primitive. \nThe common approach on x86 processors is to use a serializing kernel\u00admode instruction (such as cpuid) \non all hardware threads [25, 28], requiring execution of kernel-mode code. As NaCl sandboxing is user-mode \nonly, we require a serialization barrier that can be trig\u00adgered from user-mode. Conveniently, certain \nsystem calls serialize all processors as a side-effect. We used the mprotect system call, triggering \ninter-processor interrupts of remote hardware threads for a TLB shoot-down , serializing all processors. \nFinally, as mentioned previously, any execution of a HLT instruction will result in complete termination \nof all Native Client threads. Therefore, no thread may ever attempt to execute NaCl code memory while \nit is being updated: doing so may cause // For an instruction pair OLDI and NEWI , // with both instructions \nof size N-1 bytes. // if (diff of (OLDI, NEWI) lies in aligned qword) { // Fast path: Read the aligned \n, 8-byte region // around OLDI , then update with NEWI bytes. // atomic aligned qword write to update \nOLDI; } else { // Slow path: Three -part update sequence , // with two memory serialization barriers. \n// OLDI[0] = 0xf4; /* HLT instruction */ serialize (); /* barrier */ OLDI[1:N] = NEWI[1:N]; serialize \n(); /* barrier */ OLDI [0] = NEWI [0]; } Figure 2. Pseudo code for instruction replacement in the presence \nof untrusted concurrent hardware threads. the thread to execute a HLT. Preventing concurrent execution \nand modi.cation of the same code is the responsibility of the systems using our NaCl code-modi.cation \nprimitives. This is not an onerous duty: language runtimes should already be taking such measures to \nprevent instruction-stream corruption like that we have seen in our experiments.  3.5 Dynamic Code Deletion \nNaCl executable memory comprises a set of code regions, and a dynamically-generated code region can be \ndeleted to reclaim its executable memory. Thereby, executable memory can be reused for new machine code \nwithout the nacl dyncode modify constraint of preserving instruction boundaries. Safety dictates that \nit must not be possible for a sleeping thread to wake up and .nd that it is executing in the middle of \nan instruction, because the executable memory at the thread s instruction-pointer address has been reused \nfor a new NaCl code region. To prevent this, we utilize a thread wind down mechanism: we note all running \nthreads, mark the code region for deletion, and do not allow the executable memory to be reused until \nwe ve con.rmed that no thread is executing in the code region to be deleted. To con.rm this is the case, \nwe wait for each thread to invoke the trusted Native Client runtime. Being in the trusted runtime, we \nknow a thread is not in the deleted region, and further, that any attempt to resume execution in the \ndeleted region, while obviously incorrect, will also be safe with respect to instruction boundaries as \nit will target the aligned start of an instruction bundle. Concretely, our code deletion mechanism will: \n1. Ensure that the code region was created dynamically. 2. To ensure that no new threads enter the code \nregion, write a HLT instruction at the start of each instruction bundle. Recall that NaCl computed control \n.ow and returns always target the start of an instruction bundle. 3. Increment the global generation \nnumber, and record it in the deletion generation for the code region to be deleted. 4. As each thread \nmakes a call to the trusted NaCl service runtime,   LoC total LoC added/changed V8-32 190526 1972 (1.04%) \nV8-64 189969 5005 (2.63%) Mono-32 386300 2469 (0.64%) Mono-64 388123 3240 (0.83%) Table 3. Changed lines \nof code for NaCl ports of V8 and Mono. update that thread s thread generation number. 5. The executable \nmemory can be reused when all threads have a generation number greater than or equal to that of the deleted \ncode region. If only one thread is executing, then invoking our code deletion mechanism will immediately \nperform all of the above. With multiple threads, the .rst call to nacl dyncode delete will return an \nerror code EAGAIN. Re-invoking the interface with the same arguments and seeing a success return code \nindicates deletion is complete. The non-blocking property of the nacl dyncode delete interface allows \nuser threads to perform useful work, while waiting for executable memory to become reusable. 4. Experience \nPorting Language Runtimes This section describes our experience porting both the V8 JavaScript engine \n[27] and the Mono Common Language Run\u00adtime [41] to run inside our extended NaCl sandbox. Each language \nplatform makes use of JIT compilation and also makes use of dynamic code modi.cation techniques. After \nproviding background on each platform, we describe our porting experiences. Because the x86-32 and x86-64 \nJIT compilers are substantially different on both platforms, our work comprised porting and debugging \nfour distinct JIT implementations. Table 3 provides data about code modi.cations required for our sandboxed \nversions of V8 and Mono. Only about 1% or less of code required changes, evidence of the relative simplicity \nof adapting a JIT to support our language-independent sandboxing. 4.1 V8 JavaScript Engine The V8 JavaScript \nengine [27] is used in the Chromium/Google Chrome Web browser, in the Web browser on Android phones, \nand in Palm WebOS. In addition to being JIT compiled, V8 achieves a large performance bene.t from inline \ncaching, a technique .rst introduced in an implementation of Smalltalk 80 [15]. Inline caches store object \nproperties such as member offsets directly in the machine code of functions. The optimized machine code \nof each inline cache .rst checks that object properties haven t changed, invalidating the cache; then, \nin the common case, object members are accessed directly. Inline caches in V8 rely heavily on runtime \nmachine-code modi.cation, making V8 a good stress test for our language-independent sandboxing. Inline \ncaches are vital to the ef.ciency of the V8 engine, a motivation for our support of runtime code modi.cation. \nDisabling V8 inline caches in an otherwise unmodi.ed V8 x86-32 system induces a 12.22x slowdown on the \nV8 Benchmark Suite. With our sandboxing enabled, the slowdown is 14.08x. In both cases the positive impact \nof inline caching is an order of magnitude higher, on all platforms, than the slowdown induced by our \nlanguage\u00adindependent sandboxing. 4.2 Mono Common Language Runtime Mono [41] is an open source, cross-platform \nimplementation of Microsoft s .NET Framework. Mono provides both an of.ine compiler that translates C# \nto Common Intermediate Language (CIL) bytecode and a JIT compiler that reduces CIL bytecode to a number \nof native targets including x86-32 and x86-64. Many languages, including Microsoft Managed C++ and VB.NET \nhave CIL bytecode compilers. Mono also supports Ahead-Of-Time (AOT) compilation of CIL bytecode, a useful \nfacility when JIT compilation is either not possible or not permitted.  4.3 Porting Experiences A primary \ntask in each of our four porting efforts was modifying the JIT compiler to emit code that would satisfy \nNaCl code safety veri.cation. For this, only minimal, isolated modi.cations were required, because NaCl \nveri.cation is based on checking local machine-code properties. We modi.ed the instruction emission phase \nof each JIT to satisfy the NaCl alignment constraints and to emit NaCl pseudo instructions for memory \nreferences and indirect control .ow, as required. Another task arose from a fundamental constraint imposed \nby the Native Client platform: only machine-code instructions and no data may reside in the NaCl executable \nmemory address range. We modi.ed each of the four JITs to allocate their code, and only their code, in \nNaCl code regions. For V8, this required moving relocation records and other meta-data from executable \nmemory into appropriate data segments. We implemented similar modi.cations for Mono, although in a few \ncases we worked around the constraint by embedding data as immediate constants in a non-executed, legal \ninstruction. Such data instructions allow for the creation of code that uses instruction-relative positioning \nfor data constants and still passes NaCl code safety veri.cation. We constructed these data instructions \nby pre.xing a push immediate opcode to the data that needed to be embedded in the code segment; the resulting \npush instruction is never executed at runtime. A number of implementation challenges were speci.c to \nx86\u00ad 64. The x86-64 implementation of Native Client uses the ILP32 data model, to facilitate source code \nportability between x86-32 and x86-64 sandboxes. This tends to con.ict with the LP64 or LLP64 data models \nassumed by the x86-64 implementations of V8 and Mono. In particular, the language implementations assume \nthat a pointer and a register are the same size, which is false in the x86-64 NaCl model. Our Mono and \nV8 ports took different approaches to resolving these issues. For Mono we introduced an explicit distinction \nbetween the register size and pointer size. This approach supports the Mono requirement for C-style structures \nthat are accessed both from managed and unmanaged code. For V8, pointers occupy four bytes on the heap, \nas per the ILP32 model, but eight bytes on the stack. While this representation accommodates the fact \nthat x86-64 does not support four-byte push or pop operations, it also requires numerous changes to code \ngeneration, resulting in a signi.cant, albeit straightforward, engineering effort. The ILP32 data model \nalso interferes with the optimized representation of 32-bit integers in x86-64 V8. On x86-64, V8 encodes \ntype information in the low-order bits of 64-bit registers to differentiate between immediate 32-bit \ninteger values and pointers to boxed integer objects on the heap. For implementation expediency, we modi.ed \nthe x86-64 version of V8 to use the same integer representation as the x86-32 version. V8-32 uses the \nleast-signi.cant bit of a 32-bit word to differentiate immediate and pointers, storing integers larger \nthan 31-bits as objects. This change also required us to reimplement some arithmetic operations. The \ndifference in integer representations has performance implications for code that operates with large \ninteger values, since they are stored as objects on the heap. This had a large impact on single benchmarks \nin the SunSpider100 benchmarks, as discussed in Section 5.  x86-32 x86-64 x86-32 x86-64 Crypto 4380 \n4511 3910 (12%) 3176 (42%) DeltaBlue 6555 5380 4921 (33%) 3825 (41%) EarleyBoyer 20332 19370 15827 (28%) \n13247 (46%) RayTrace 9277 7979 5849 (59%) 4615 (73%) RegExp 3367 3534 2660 (27%) 2035 (74%) Richards \n4911 4659 3864 (27%) 3217 (45%) Splay 15305 14160 13098 (17%) 10188 (39%) GMean 7528 7059 5868 (28%) \n4683 (51%) (a) Unsafe (b) Sandboxed Figure 3. A chart of NaCl sandboxing slowdown (lower is better) \nfor the V8 JavaScript Benchmark Suite, relative to unmodi.ed V8. GMean is the geometric mean of the overheads \nof all benchmarks in the suite. Also shown is a table of the chart s underlying data: raw benchmark scores \n(where higher is better) for native and sandboxed execution, with sandboxing slowdown in parentheses. \n5. Experimental Results and Optimizations Results in this section are from a quad-core Intel Xeon X5550 \nNe\u00adhalem 2.67 GHz processor, except Table 6 as noted. Our test system ran Ubuntu 10.04, kernel version \n2.6.32. Performance results are an average of 10 runs. The observed standard deviation ranged from 0 \nto 2.32%. We summarize performance measurements using the geometric mean [22]. Our implementation extends \nthe latest, up-to-date version of Native Client, which, on x86-64, has added sandboxing of indirect memory \nreads, as well as writes. Therefore, it is not surprising that our extended NaCl sandboxing for x86-64 \nhas higher measured overheads than those reported in [44]. 5.1 Sandboxing Overhead for V8 JavaScript \nand Mono C# Figures 3 and 4 show the overheads for our sandboxed version of V8 when running the V8 Benchmark \nSuite [27], version 6, and the SunSpider Benchmark Suite [50], version 0.9.1. The V8 Benchmark Suite \nis distributed with V8 and the SunSpider Benchmark Suite is distributed with WebKit. The SunSpider suite \nconsists of very small microbenchmarks; therefore, we created and used a variant, SunSpider100, where \neach benchmark is run 100 times, instead of once, to facilitate more accurate timing and to emphasize \nsteady state execution over startup delays. We measure overhead relative to the V8 2.2.19 development \nversion that we forked to make our changes on June 21st, 2010. In the V8 Benchmark Suite, RayTrace showed \nsome of the largest overheads. We investigated the cause of this slowdown on V8-64 using PIN [31], a \nbinary instrumentation tool, and pfmon [52], a performance monitoring tool based on hardware performance \ncounters. Using PIN, we counted executed instruc\u00adtions for RayTrace, both with and without the sandbox. \nWith Figure 4. A chart of NaCl sandboxing slowdown (lower is better) for the SunSpider100 JavaScript \nbenchmarks, relative to unmodi.ed V8. Each bar represents a group of up to four benchmarks. GMean is \nthe geometric mean of all benchmark overheads. Also shown is a table of the chart s underlying data: \nraw benchmark scores (here, lower scores are better) for native and sandboxed execution, with sandboxing \nslowdown in parentheses. x86-32 x86-64 x86-32 x86-64 3D 3097 3434 4230 (37%) 5996 (75%) Access 2867 3248 \n3815 (33%) 5296 (63%) BitOps 2240 2047 2892 (29%) 3235 (58%) ControlFlow 179 199 250 (40%) 318 (60%) \nCrypto 1193 857 1812 (52%) 2538 (196%) Date 2060 2236 2970 (44%) 3541 (58%) Math 2310 2374 2639 (14%) \n3295 (39%) RegExp 1097 957 1359 (24%) 1057 (10%) String 5147 5269 6325 (23%) 7186 (36%) GMean 1693 1676 \n2241 (32%) 2689 (60%) (a) Unsafe (b) Sandboxed NaCl sandboxing, RayTrace instruction counts on V8-64 \ngrew to a factor of 1.8x. The largest contributor is NOP padding to align instruction bundles and CALL \ninstructions, adding 39% of the new instructions. The second largest source of additional instructions \nis software guards for memory references, 38% of the total new instruction. The remaining new instructions \ncame from other software guards and the Native Client runtime. To understand the impact of branch and \ncache behavior, we used pfmon to measure related hardware events during the RayTrace benchmark. NaCl \nsandboxing requires the use of a software-guarded indirect jump, instead of a RET instruction for function \nreturns, which we thought would likely increase branch mispredictions. Indeed, we observed a 4x increase \nin the branch misprediction rate. Sandboxing also increased V8-64 instruction cache pressure, with 2x \nchange in L1 instruction cache misses and 2x change in instruction TLB misses. The SunSpider100 suite \nshowed similar average performance overhead as the V8 Benchmark Suite, with 32% slowdown for sandboxed \nV8-32 and 60% for V8-64, as compared to unmodi.ed V8. On x86-64, the crypto benchmarks were an outlier, \nwith over twice the overhead of any other benchmark. The crypto benchmarks are composed of 3 smaller \nbenchmarks: crypto\u00adaes, with 1.8x slowdown; crypto-md5, with 5.0x slowdown; and crypto-sha1, with 3.9x \nslowdown. The second and third benchmarks depend heavily on 32-bit integer arithmetic operations, and \nimplement these operations through nested use of very small functions, resulting in multiple function \ninvocations per arithmetic operation. Therefore, for these benchmarks, branch misprediction on function \nreturns must be a large source of overhead.  x86-32 x86-64 x86-32 x86-64 FFT 323 332 321 (1%) 281 (18%) \nLU 668 763 665 (0%) 595 (28%) MonteCarlo 109 126 97 (12%) 91 (38%) SOR 886 892 893 (-1%) 863 (3%) SparseMM \n450 507 452 (-1%) 429 (18%) GMean 393 429 384 (2%) 355 (21%) (a) Unsafe (b) Sandboxed Figure 5. A chart \nof NaCl sandboxing slowdown (lower is better) for the SciMark C# Benchmark Suite, relative to unmodi.ed \nMono JIT. GMean is a geometric mean of overheads of all benchmarks in the suite. Also shown is a table \nof the chart s underlying data: raw benchmark scores (where higher is better) for native and sandboxed \nexecution, with sandboxing slowdown in parentheses. However, the main source of overhead results from \nthe change in representation described in Section 4.3: our V8-64 port uses the representation of small \nintegers from V8-32, and therefore stores integers larger than 231 as heap objects. We chose this implementation \nfor expediency, without realizing its effects. As a result of our porting shortcut, half of the 32-bit \narithmetic in the crypto benchmarks will involve boxed heap objects, instead of register values, and, \ncompounding this overhead, NaCl sandboxing on x86-64 requires use of a software guard for each indirect \naccess to heap memory. We could have supported the 64-bit integer representation used in V8-64, since \nNative Client allows safe use of handwritten machine code or assembly modules; we plan to do so in a \nfuture version of our V8-64 port. Turning to Mono, Figure 5 shows our NaCl sandbox overhead for the SciMark \nC# Benchmark Suite. For x86-32 the mean overhead was only 2%, while for x86-64 the overhead was 21%. \nOverheads were higher on x86-64 because of the additional software guards required for NaCl sandboxing \nof loads and stores. The largest overheads were for the MonteCarlo benchmark, whose kernel uses a tight \ninner loop that calls two small functions, resulting in NOP padding and branch misprediction overheads. \nWhile we haven t yet studied all original causes of this slowdown, we note it is consistent with measured \nperformance of the x86-64 NaCl sandbox for C and C++ benchmarks [44].  5.2 Analysis of the Sources of \nSandboxing Overhead Table 4 shows the estimated breakdown of sandboxing overhead for the V8 Benchmark \nSuite. This table was generated by disabling NaCl sandboxing features one at a time. Since the performance \nimpact of these different changes may not be independent, this breakdown serves only as an estimate. \nThe largest estimated slowdown is from NOPs inserted for CALL and instruction bundle alignment. We estimate \nthat fetch and execution penalties from Source of overhead V8-32 V8-64 NOP padding to align bundles 4% \n16% NOP padding to align calls 19% 21% Software guards for function returns 25% 22% Software guards for \nindirect jumps and indirect memory accesses1 17% 24% Runtime validation of code modi.cations 2% 5% 1 \nIndirect memory accesses require software guards only on x86-64. Table 4. Analysis of the sources of \nNaCl sandboxing slowdown, measured using the V8 Benchmark Suite (Figure 3). These measurements were generated \nby disabling NaCl sandboxing features one at a time. Since the performance impact of these features is \nnot independent, these overheads are not additive. these NOPs cause about half of the total slowdown. \nReturn address masking is the next largest source of slowdown. NaCl sandboxing requires replacing RET \ninstructions with a POP/JMP sequence. This interferes with the return address prediction hardware in \nmodern processors. Other overheads (not listed) include invocations of the trusted Native Client runtime, \nslower dynamic code generation, copies required to modify code, and object layout changes required to \nseparate code and code-meta-data. These overheads are small compared to those listed in Table 4.  5.3 \nComparing Sandboxing and Language Overheads Past, published measurements of SFI-based sandboxing slowdown \nhave considered only fully-optimized, ahead-of-time compiled versions of C and C++ benchmarks like SPEC \n[20, 44, 46, 56]. However, the SciMark Benchmark Suite includes C as well as C# implementations of its \nbenchmarks. This allows us to examine one data point for the relative cost of sandboxing native code \nvs. JIT compiled code in a modern language runtime. To facilitate this examination, we measured single-threaded \nSciMark execution, since its C variant runs only single threaded. Table 5 examines the performance of \nthree variations of SciMark, for both x86-32 and x86-64, executing both with and without NaCl sandboxing. \nNative is the original C implementation of SciMark; Mono AOT is the C# port, compiled ahead of time and \nwithout dynamic code modi.cation; last, Mono JIT is the C# port, executed using JIT compilation. For \nx86-32, the NaCl sandboxing slowdown ranges from 0 to 5%, for all implementations. For x86\u00ad64, the slowdown \nranges from 13% to 48%, and is lower for the C# implementations than for C. Despite the higher relative \nsandboxing overhead, the absolute performance is signi.cantly better for the C implementation. On x86-32, \nour language-independent sandboxing of Mono has comparable relative overhead to that of conventionally \ncompiled C and C++ under Native Client [56]. For NaCl sandboxed Mono-64, performance of benchmarks such \nas LU and SparseMM is also consistent with NaCl overheads for other benchmarks whose execution time is \nsensitive to path length and branch prediction effects [44]. Notably, the JIT version of the C# port \nis actually faster than the AOT version, especially on 64-bit platforms. The JIT compiler has knowledge \nof the locations of most of the data and code in the program when it compiles a method. This allows it \nto embed direct calls and data references to these locations in the emitted code. It can further optimize \nthe code by backpatching existing calls to new code as it is generated. By contrast the AOT compiler \nuses indirection techniques such as tables of pointers, resulting in slower execution. This JIT advantage \nstill holds in the sandboxed environment, even if offset slightly by the extra cost of NaCl safety  \n x86-32 x86-64 x86-32 x86-64 Native (C) 717 868 729 (-2%) 586 (48%) Mono AOT 383 360 365 ( 5%) 318 (13%) \nMono JIT 388 426 383 ( 1%) 350 (22%) (a) Unsafe (b) Sandboxed Table 5. Performance of SciMark C/C# Benchmark \nSuite com\u00adpiled from native C code, with gcc 4.4.3, or with the Mono AOT and JIT compilers for C#. Benchmarks \nwere executed natively and on the unmodi.ed Mono CLR (Unsafe), as well as with NaCl sandboxing. Numbers \nshow benchmark scores, in mega.ops (higher is better), and also the NaCl sandboxing slowdown, as a percentage \n(in parentheses). constraints. Overall, these measurements suggest that the relative cost of language-independent \nNaCl sandboxing can be small compared to the overhead of a dynamic language runtime. The performance \ndifference between the C and Mono benchmarks can be seen as the cost of using a managed-language framework. \nFor the native, unsafe benchmark executions, the cost of executing with Mono ranges from 84% to 141% \noverhead, while that overhead ranges from 67% to 99% under sandboxed execution.  5.4 NOP Optimizations \nWe were motivated to optimize the execution of NOP padding, because it is the single largest contributor \nto overall NaCl sandboxing overhead. To our surprise, we found that choice of NOP padding sequences had \na large impact on performance, even when the chosen NOPs were never executed at runtime. For the V8 Benchmark \nSuite on x86-32, different NOP padding choices reduced sandboxing overheads from a factor of 1.62x to \n1.28x. Figure 6 shows a sampling of the search space of possible NOP paddings and the resulting performance \non the V8 benchmark suite. It shows three different strategies for generating NOPs: Shortest NOPs generates \nlong sequences of the single-byte NOP instruction (0x90).  Longest NOPs uses a greedy algorithm to generate \nthe longest NOP instructions allowed. (Using the pre.x/addressing mode variations of the 0x0f1f multi-byte \nNOP opcode listed in the AMD64 Optimization Guide [24].)  Optimized NOPs uses a lookup table containing \noptimized NOP sequences from 1 to 31 bytes in length. The table was generated automatically, in about \none minute, using a microbenchmark that exhaustively searches the space of different combinations of \ninstructions that have no effect. The individual NOP instructions are drawn from the many different inert \nvariations  Figure 6. Sandboxing slowdown (lower is better) for different strategies of generating NOP \npadding for NaCl instruction alignment. The slowdown is measured from the overall GMean of the V8 Benchmark \nSuite executing on x86-32. of the NOP, XCHG, MOV, and LEA opcodes, using different registers and addressing \nmodes. Looking at the tables generated for optimized NOPs, the trend is that variety improves performance: \nNOP padding sequences that vary the opcodes and registers between all the different NOPs execute much \nfaster than NOP padding sequences that are more homogeneous, e.g., repeating the same instruction over \nand over. The fastest measured NOP sequences tend to contain one NOP of each possible type. This is possibly \na result of more possibilities for instruction level parallelism when a mix of different NOP types is \nissued on modern microarchitectures. For long NOP padding, the fastest NOP sequences contain a direct \njump instruction that jumps to the end of the padding. Some\u00adwhat surprisingly, the choice of the unexecuted \nNOP instructions immediately after the direct jump has an effect on performance, despite being unreachable. \nWe observed, on different architectures, between a 1.5% and a 1.8% slowdown when we changed these unreachable \nNOP instructions from optimized sequences of NOPs to sequences of the shortest, single-byte NOPs. We \nassume that those unexecuted NOP instructions impact some microarchitectural bottleneck in instruction \nfetching and decoding. NOP padding performance will vary with microarchitecture, but optimized tables \ncan be generated on each platform. Figure 6 shows the performance effects of different choices for directly \njumping to the end of NOP padding sequences on the overall score of the V8 benchmark suite. The left \nside of the graph ( 2 on the x-axis) shows V8-32 performance measured when all NOP padding sequences \nstart with a direct jump (that jump occupies two bytes). The right side of the graph ( 32 on the x-axis) \nshows performance when NOP padding never starts with a direct jump. Notably, starting with a direct jump \nis not the fastest strategy for all NOP padding lengths. For the optimized NOP selection strategy, a \ndirect jump is faster only when NOP padding is longer than about 24 bytes. A related optimization is \nto avoid execution of padding before a CALL instruction by using an explicit PUSH of the would-be return \naddress followed by a JMP to the function entrypoint address. This optimization replaces a call of the \nform 1 ...padding ... 2 call FOO with the sequence  x86-32 x86-64 x86-32 x86-64 Intel Xeon X5550 Nehalem \n2.7GHz 7528 7059 5869 (28%) 4683 (51%) Intel Core2 Quad Q6600 2.4GHz 5612 5128 4535 (24%) 3296 (56%) \nAMD Phenom II X4 905E 2.5GHz 5030 4793 4026 (25%) 3390 (41%) AMD Athlon 4450E 2.3GHz 3853 3447 2856 (35%) \n2385 (45%) AMD Opteron 8214 HE 2.2GHz 3633 3224 2701 (35%) 2226 (45%) Intel Atom N450 1.7GHz 1395 1176 \n1041 (34%) 589 (100%) (a) Unsafe (b) Sandboxed Table 6. Performance scores (higher is better) on different \nmicroarchitectures for the V8 Benchmark Suite running natively (Unsafe) and in our language-independent \nsandbox. Sandboxing slowdown is shown in in parentheses. 1 push retloc 2 jmp FOO 3 ... padding ... 4 \nretloc : avoiding the need to execute the padding NOPs. This optimization provides modest performance \ngains, of about 3 percent, and is included in the measurements of Figure 6. Similar to direct jumps over \npadding, this technique provides largest bene.t when only applied when skipping NOP padding sequences \nof length 20 bytes or more.  5.5 Overhead Variability between CPU Architectures Table 6 compares the \noverhead of our language-independent sandboxing when running V8 benchmarks on several modern processors, \nimplementing different microarchitectures. For V8 on x86-32 overheads are consistent, ranging from 28% \nto 34%. For x86-64 overheads range from 41% to 56%, and the numbers seem to suggest consistently less \nrelative overhead on AMD processors than on the fast Intel processors. The Intel Atom is a notable outlier, \nwith 100% sandboxing slowdown measured for V8-64. While we haven t yet fully explored the Atom s outlier \nperformance, we note that these results match those previously reported for the x86-64 NaCl sandbox [44]. \nInterestingly, raw performance is better on x86\u00ad32 for both the unsafe and sandboxed versions, most likely \nbecause V8 has been more heavily optimized for x86-32.  5.6 Application to the new Crankshaft V8 Concurrently \nto our efforts described so far in porting a fork of the V8 code base to Native Client, the developers \nof V8 substantially extended the V8 JavaScript platform to use highly\u00addynamic, pro.le-driven optimizations. \nThis Crankshaft version of V8 has since been released as part of the Chrome Web browser for the x86-32 \narchitecture [34]. Crankshaft greatly improves the performance of V8, through use of SSA-based optimizations, \nloop-invariant code motion, better register allocation, and function inlining. Also, Crankshaft allows \nfast, unboxed use of all small integers less than 232 (cf. the old V8, as discussed on page 6). To gain \nfurther insights into the applicability of our work, we ported the x86-32 Crankshaft V8 (version 3.1.4) \nto use our code\u00admodi.cation primitives. We were pleased to see that our existing NaCl sandboxing port \nwas insensitive to the higher-level changes to V8, such as the mechanisms for SSA-based optimizations. \nAlso, the low-level x86-32 code-emission in the V8 backend remained mostly unchanged, allowing us to \nreuse a majority of our earlier porting work. All in all, we modi.ed 3,483 lines in the x86-32 Crypto \n3910 (12%) 12521 (14%) 12583 (14%) DeltaBlue 4921 (33%) 13718 (20%) 14413 (14%) EarleyBoyer 15827 (28%) \n1030 (2095%) 17294 (31%) RayTrace 5849 (59%) 8923 (29%) 8908 (30%) RegExp 2660 (27%) 2274 (21%) 2298 \n(19%) Richards 3864 (27%) 10862 (13%) 10955 (12%) Splay 13098 (17%) 3704 (13%) 3699 (13%) GMean 5868 \n(28%) 5459 (79%) 8250 (19%) Figure 7. A chart showing NaCl sandboxing slowdown (lower is better) for \nthe old V8 and Crankshaft V8 platforms running the V8 JavaScript Benchmark Suite. A table of the chart \ns underlying raw benchmark scores (where higher is better) for NaCl sandboxed execution, with sandboxing \nslowdown in parentheses. Crankshaft' denotes the NaCl-tuned version of Crankshaft. Crankshaft V8 codebase \n(cf. Table 3). We also made two small tweaks to our port, to tune Crankshaft s mechanisms to the characteristics \nof the NaCl sandbox. First, we increased the threshold for the function-invocation count at which Crankshaft \nwill specialize a function to its arguments and modify the function s code. Thus, we reduced code modi.cation \nrates to account for the increased cost of code modi.cation (V8 is tuned for faster, single threaded \ncode modi.cation). Second, we saw that a lot of NOP padding was needed to align indirect jump targets \nin the middle of the code for general-purpose functions; specialized functions jump to this code if they \ndetect that their specialization does not apply. To avoid the NOP overhead, we used a small table of \ndirect-jump trampolines, placed after the general-purpose function code, to implement these calls. We \nre-ran the benchmarking experiments on both versions of our NaCl port of the Crankshaft V8 platform. \nThe results can be seen in Figure 7. After tuning, the absolute performance of the NaCl sandboxed Crankshaft \nlanguage runtime beats that of the unmodi.ed, unsafe x86-32 V8 version we used previously (see Figure \n3). It is particularly gratifying that in a span of a few months, the original overhead of our language-independent \nsandboxing has been more than offset by the independent optimization of the language runtime. As Figure \n7 shows, the relative overhead of NaCl sandboxing is also reduced by almost a third, going from 28% to \n19% for the tuned Crankshaft benchmarks. We believe this decrease in relative overhead is primarily due \nto Crankshaft s function inlining, which reduces both NaCl NOP padding as well as function-return branch \nmispredictions. The SunSpider100 benchmarks exhibited a similar absolute performance improvement, and \nalso saw sandboxing slowdown fall from 32% to 24%.  6. Discussion and Related Work In this paper, we \nhave presented our techniques for safe runtime code generation and modi.cation using the terminology \nof the Native Client platform upon which our implementation is based. Even so, we are con.dent that our \ntechniques apply more widely. In particular, we believe that the safety constraints of Table 2 could \nbe easily reformulated for other SFI-based platforms (e.g., XFI [20]), and still provide the immutability \nguarantees necessary for safe runtime code modi.cation. Our con.dence derives from the fundamental basis \nof our work, which lies not in NaCl-speci.c properties, but in the use of local code inspection to inductively \nestablish global execution invariants a common characteristic of many execution monitoring mechanisms. \nOur experience porting JIT-based runtime platforms to our language-independent sandbox suggest that it \nis possible to combine SFI-based sandboxing with dynamic code generation, yielding a system that combines \nbene.ts from both techniques. Although the performance impact of sandboxing is not negligible, we believe \nthe resulting system is still viable for a large set of practical use cases, especially considering that \nsome of the relevant languages are still commonly implemented with interpreters. Some will argue that \na JIT-based language runtime is safe enough without an SFI sandbox. We note that the verity of this statement \nrelies on the quality of the language implementation, including the language runtime and any extensions. \nIn all cases, it can be expected that a fully-featured, advanced language runtime will comprise a signi.cant \namount of complex, trusted code even when legacy libraries are not considered. Note the total line counts \nfor V8 and Mono in Table 3. Furthermore, in cases where a language implementation is used as a scripting \nengine for a larger system, such as a Web browser, it is often desirable to sandbox the entire composed \nsystem [4, 42]. Like Native Client and other SFI-based mechanisms, our language-independent sandboxing \nis designed to provide high\u00adassurance guarantees of clearly-de.ned safety properties, even in the face \nof malicious software crafted by an adaptive attacker. In comparison, many other software protection \nsystems such as Nooks [51], to name just one provide a weaker form of safety by making only a best-effort \nattempt at containing faults. Many software protection systems have been implemented using a combination \nof static analysis of machine code and inline, machine-code software guards that perform runtime checks \nor sandboxing operations. The .rst use of these techniques may have been in the late 60 s, to allow the \nkernel execution of untrusted code in a pro.ling system for the SDS-940 [14]. Since then, these techniques \nhave been used in the original work on SFI [53], subsequent SFI implementations such as MiSFIT [46], \nSASI x86 [18], XFI [20], and PittSFIeld [32], and in a number of other systems. Compared to Native Client, \nsome of these systems offer .ner-granularity safety guarantees for certain aspects of software execution \nalbeit typically at the cost of higher enforcement overhead. For example, CFI [1] can guarantee that \nmachine-code execution follows a permitted control-.ow graph, XFI [20] can enforce integrity properties \nfor the runtime stack, and DFI [11] and its successors like BGI [12] can maintain data-.ow integrity \nproperties for even values in heap memory. However, it remains unclear if the techniques of these systems \ncan be used to implement a production-quality, practical execution platform like Native Client, that \nis portable across both operating systems and hardware architectures with good performance. Furthermore, \nwe know of no such system that provides safety guarantees in the face of runtime code generation and \nmodi.cation. Programming languages and runtime software mechanisms are recognized as an effective approach \nto providing safety guarantees and enforcing security policies. Software isolation on the Burroughs B-5000 \nsystem depended on applications being written in the Algol high-level language [5] and a similar approach \nhas been taken in later, experimental operating systems such as SPIN [7]. Commonly, language-based isolation \nis enforced through exe\u00adcution on top of a virtual machine, which is implemented using a trusted compiler \nor interpreter, and typically makes use of extensive libraries of trusted support routines based on (legacy) \nnative code [45]. In comparison, approaches like Typed Assembly Language (TAL) [35] and Proof-Carrying \nCode (PCC) [37] provide guarantees about the machine code that is executed on actual hardware machines. \nSFI, like TAL and PCC, has the attractive characteristic of allowing independent, static safety veri.cation \nof the machine code to be executed; this not only decouples the execution platform from the language \ntoolchain, but also reduces the size of the trusted computing base [40]. A long line of research aims \nto preserve the semantic properties of high-level programming languages through translation to lower\u00adlevel \nlanguages. Typed assembly language derives from this .eld and, in that context, Smith et al. have considered \nrestricted forms of runtime code generation [47]. Recently, this .eld has seen great progress, starting \nwith Xavier Leroy s work on certifying compilation from C-like languages to PowerPC machine code with \nfull, formal proofs of semantic preservation. This work has been extended to handle incremental runtime \ncode generation, and even self-modifying code, .rst by Cai et al. [8] and then, most recently, by Magnus \nO. Myrren [36] in this later work formally certifying the correctness of a JIT compiler from a small \nbytecode language to x86 machine code. Our mechanisms also give strong safety guarantees and use techniques \namenable to formal veri.cation [32]. However, our language-independent sandboxing does not aim to preserve \nhigh-level language semantics, and the implementation of our mechanisms is unencumbered by those semantics. \n7. Conclusions Through use of language-independent, software-based fault isola\u00adtion, it is possible to \nsafely and ef.ciently sandbox programs that make use of self-modifying machine code. It suf.ces to extend \ntraditional SFI techniques with a few new features, including new safety constraints that apply inductively \non the structure of machine code, even across code modi.cation. These new safety features are not dif.cult \nto implement in practice, e.g., as part of Native Client, an existing, production-quality SFI-based sandboxing \nplatform. It is also rather straightforward to port V8 and Mono, two disparate, modern JIT-compiled languages, \nto run within a thus extended sandboxing platform. Such language\u00adindependent sandboxing holds the promise \nof facilitating the deployment of new language and technology options for the development of untrusted \nsoftware, in particular, on the Web. Acknowledgments We thank Seth Abraham and Richard Winterton at Intel \nfor their helpful discussions about Intel processor behavior in the presence of cross modifying code. \nReferences \u00b4Control-Flow Integrity: Principles, implementations, and applications. TISSEC, 2009. [1] \nMart\u00b4in Abadi, Mihai Budiu, Ulfar Erlingsson, and Jay Ligatti. [2] Matthew Arnold and Barbara G. Ryder. \nA framework for reducing the cost of instrumented code. In PLDI, 2001. [3] John Aycock. A brief history \nof just-in-time. CSUR, 2003. [4] A. Barth, C. Jackson, C. Reis, and Google Chrome Team. The security \narchitecture of the chromium browser. Technical report, Stanford  University, 2008. URL http://crypto.stanford.edu/websec/ \nchromium/chromium-security-architecture.pdf. [5] R. S. Barton. A new approach to the functional design \nof a digital computer. In IRE-AIEE-ACM (Western), 1961. [6] Mark Barwinski, Cynthia Irvine, and Tim Levin. \nEmpirical study of drive-by-download spyware. Technical report, Naval Postgraduate School, 2006. [7] \nB. N. Bershad, S. Savage, P. Pardyak, E. G. Sirer, M. E. Fiuczynski, D. Becker, C. Chambers, and S. Eggers. \nExtensibility safety and performance in the spin operating system. In SOSP, 1995. [8] Hongxu Cai, Zhong \nShao, and Alexander Vaynberg. Certi.ed self\u00admodifying code. In Proc. PLDI 07, 2007. [9] Benjamin Canou, \nVincent Balat, and Emmanuel Chailloux. O Browser: Objective Caml on browsers. In Workshop on ML, 2008. \n[10] Bryan M. Cantrill, Michael W. Shapiro, and Adam H. Leventhal. Dynamic instrumentation of production \nsystems. In ATC, 2004. [11] Miguel Castro, Manuel Costa, and Tim Harris. Securing software by enforcing \ndata-.ow integrity. In OSDI, 2006. [12] Miguel Castro, Manuel Costa, Jean-Philippe Martin, Marcus Peinado, \nPeriklis Akritidis, Austin Donnelly, Paul Barham, and Richard Black. Fast byte-granularity software fault \nisolation. In SOSP, 2009. [13] Blazakis D. Interpreter exploitation: Pointer inference and JIT spraying. \nIn Black Hat DC, 2010. [14] P. Deutsch and C. A. Grant. A .exible measurement tool for software systems. \nIn IFIP, 1971. [15] Peter Deutsch and Allan Schiffman. Ef.cient implementation of the Smalltalk-80 system. \nIn POPL, 1984. [16] ECMA, 2001. URL http://www.ecma-international.org/ publications/files/ECMA-ST/Ecma-327.pdf. \n[17] Manuel Egele, Engin Kirda, and Christopher Kruegel. Mitigating drive-by download attacks: Challenges \nand open problems. In iNetSec 2009 Open Research Problems in Network Security, 2009. \u00b4 policies: A retrospective. \nIn NSPW, 1999. [18] U. Erlingsson and Fred B. Schneider. SASI enforcement of security \u00b4http://www.cs.cornell.edu/home/ulfar/cuba/paper. \n[19] Ulfar Erlingsson. High-performance binary applets, 1997. URL \u00b4George C. Necula. X.: software guards \nfor system address spaces. In OSDI, 2006. [20] Ulfar Erlingsson, Mart\u00b4in Abadi, Michael Vrable, Mihai \nBudiu, and [21] M. Anton Ertl, David Gregg, Andreas Krall, and Bernd Paysan. Vmgen: a generator of ef.cient \nvirtual machine interpreters. Software: Practice and Experience, 2002. [22] Philip J. Fleming and John \nJ. Wallace. How not to lie with statistics: the correct way to summarize benchmark results. CACM, 1986. \n[23] Jonathon T. Gif.n, Mihai Christodorescu, and Louis Kruger. Strengthening software self-checksumming \nvia self-modifying code. In ACSAC, 2005. [24] Advance Micro Devices Inc. Software Optimization Guide \nfor AMD64 Processors, 2005. [25] Advance Micro Devices Inc. AMD64 Architecture Programmers Manual Volume \n1: Application Programming, 2009. [26] Google Inc. Google web toolkit, . URL http://code.google.com/ \nwebtoolkit. [27] Google Inc. The V8 JavaScript engine, . URL http://code. google.com/p/v8. [28] Intel \nInc. Intel 64 and IA-32 Architectures Software Developers Manual Volume 3A: System Programming Guide, \nPart 1, 2010. [29] Yuichiro Kanzaki, Akito Monden, Masahide Nakamura, and Ken-ichi Matsumoto. Exploiting \nself-modi.cation mechanism for program protection. In COMPSAC, 2003. [30] T. Lindholm and F Yellin. The \nJava Virtual Machine Speci.cation. Addison-Wesley, 1996. [31] Chi-Keung Luk, Robert Cohn, Robert Muth, \nHarish Patil, Artur Klauser, Geoff Lowney, Steven Wallace, Vijay Janapa Reddi, and Kim Hazelwood. Pin: \nbuilding customized program analysis tools with dynamic instrumentation. In PLDI, 2005. [32] S. McCamant \nand G. Morrisett. Evaluating SFI for a CISC architecture. In Usenix Security, 2006. [33] John McCarthy. \nRecursive functions of symbolic expressions and their computation by machine, part i. CACM, 1960. [34] \nKevin Millikin and Florian Schneider, 2010. URL http://blog. chromium.org/2010/12/new-crankshaft-for-v8.html. \n[35] G. Morrisett, D. Walker, K. Crary, and N. Glew. From System F to typed assembly language. In POPL, \n1998. [36] Magnus O. Myreen. Veri.ed just-in-time compiler on x86. In Proc. of POPL 10, 2010. [37] George \nC. Necula. Proof-carrying code. In Proc. of POPL 97, 1997. [38] James Newsome and Dawn Song. Dynamic \ntaint analysis for automatic detection, analysis, and signature generation of exploits on commodity software. \nIn NDSS, 2005. [39] Thi Viet Nga Nguyen and Franc\u00b8ois Irigoin. Ef.cient and effective array bound checking. \nTOPLAS, 2005. [40] Department of Defense. Trusted computer system evaluation criteria (orange book), \n1985. [41] The Mono Project. The Mono language runtime. URL http://www. mono-project.com. [42] Charles \nReis and Steven D. Gribble. Isolating web programs in modern browser architectures. In Proc. 4th ACM \nEuropean conf. on Computer systems, EuroSys 09, pages 219 232, New York, NY, USA, 2009. ACM. doi: http://doi.acm.org/10.1145/1519065.1519090. \n[43] Theodore H. Romer, Dennis Lee, Geoffrey M. Voelker, Alec Wolman, Wayne A. Wong, Jean-Loup Baer, \nBrian N. Bershad, and Henry M. Levy. The structure and performance of interpreters. In ASPLOS, 1996. \n[44] David Sehr, Robert Muth, Cliff Bif.e, Victor Khimenko, Egor Pasko, Karl Schimpf, Bennet Yee, and \nBrad Chen. Adapting software fault isolation to contemporary cpu architectures. In USENIX Security, 2010. \n[45] Joseph Siefers, Gang Tan, and Greg Morrisett. Robusta: taming the native beast of the jvm. In CCS, \n2010. [46] C. Small and M. I. Seltzer. MiSFIT: Constructing safe extensible systems. IEEE Concurrency: \nParallel, Distributed and Mobile Computing, 1998. [47] Fred Smith, Dan Grossman, Greg Morrisett, Luke \nHornoff, and Trevor Jim. Compiling for template-based runtime code generation. J. of Functional Programming, \n13(3), 2003. [48] Michael F. Spear. Lightweight, robust adaptivity for software transactional memory. \nIn SPAA, 2010. [49] Vijay Sundaresan, Daryl Maier, Pramod Ramarao, and Mark Stoodley. Experiences with \nmulti-threading and dynamic class loading in a java just-in-time compiler. In CGO, 2006. [50] SunSpider \nBenchmark Suite. URL http://www2.webkit.org/ perf/sunspider/sunspider.html. [51] Michael M. Swift, Brian \nN. Bershad, and Henry M. Levy. Improving the reliability of commodity operating systems. TOCS, 2005. \n[52] The perfmon2 hardware-based performance monitoring interface for Linux. URL http://perfmon2.sourceforge.net. \n[53] Robert Wahbe, Steven Lucco, Thomas E. Anderson, and Susan L. Graham. Ef.cient software-based fault \nisolation. In SOSP, 1993. [54] Robert Watson, Jonathan Anderson, Ben Laurie, and Kris Kennaway. Capsicum: \npractical capabilities for unix. In USENIX Security, 2010. [55] Tao Wei, Tielei Wang, Lei Duan, and Jing \nLuo. Secure dynamic code generation against spraying. In CCS, 2010. [56] Bennet Yee, David Sehr, Gregory \nDardyk, J. Bradley Chen, Robert Muth, Tavis Orm, Shiki Okasaka, Neha Narula, and Nicholas Fullagar. Native \nClient: A sandbox for portable, untrusted x86 native code. In IEEE Symposium on Security and Privacy, \n2009.    \n\t\t\t", "proc_id": "1993498", "abstract": "<p>When dealing with dynamic, untrusted content, such as on the Web, software behavior must be sandboxed, typically through use of a language like JavaScript. However, even for such specially-designed languages, it is difficult to ensure the safety of highly-optimized, dynamic language runtimes which, for efficiency, rely on advanced techniques such as Just-In-Time (JIT) compilation, large libraries of native-code support routines, and intricate mechanisms for multi-threading and garbage collection. Each new runtime provides a new potential attack surface and this security risk raises a barrier to the adoption of new languages for creating untrusted content.</p> <p>Removing this limitation, this paper introduces general mechanisms for safely and efficiently sandboxing software, such as dynamic language runtimes, that make use of advanced, low-level techniques like runtime code modification. Our <i>language-independent sandboxing</i> builds on Software-based Fault Isolation (SFI), a traditionally static technique. We provide a more flexible form of SFI by adding new constraints and mechanisms that allow safety to be guaranteed despite runtime code modifications.</p> <p>We have added our extensions to both the x86-32 and x86-64 variants of a production-quality, SFI-based sandboxing platform; on those two architectures SFI mechanisms face different challenges. We have also ported two representative language platforms to our extended sandbox: the Mono common language runtime and the V8 JavaScript engine. In detailed evaluations, we find that sandboxing slowdown varies between different benchmarks, languages, and hardware platforms. Overheads are generally moderate and they are close to zero for some important benchmark/platform combinations.</p>", "authors": [{"name": "Jason Ansel", "author_profile_id": "81314480768", "affiliation": "Massachusetts Institute of Technology, Cambridge, MA, USA", "person_id": "P2690581", "email_address": "jansel@csail.mit.edu", "orcid_id": ""}, {"name": "Petr Marchenko", "author_profile_id": "81361608349", "affiliation": "University College London, London, United Kingdom", "person_id": "P2690582", "email_address": "p.marchenko@cs.ucl.ac.uk", "orcid_id": ""}, {"name": "&#218;lfar Erlingsson", "author_profile_id": "81100067935", "affiliation": "Google Inc., Mountain View, CA, USA", "person_id": "P2690583", "email_address": "ulfar@google.com", "orcid_id": ""}, {"name": "Elijah Taylor", "author_profile_id": "81485650231", "affiliation": "Google Inc., Mountain View, CA, USA", "person_id": "P2690584", "email_address": "elijahtaylor@google.com", "orcid_id": ""}, {"name": "Brad Chen", "author_profile_id": "81485645229", "affiliation": "Google Inc., Mountain View, CA, USA", "person_id": "P2690585", "email_address": "bradchen@google.com", "orcid_id": ""}, {"name": "Derek L. Schuff", "author_profile_id": "81540910656", "affiliation": "Google Inc., Mountain View, CA, USA", "person_id": "P2690586", "email_address": "dschuff@google.com", "orcid_id": ""}, {"name": "David Sehr", "author_profile_id": "81100461045", "affiliation": "Google Inc., Mountain View, CA, USA", "person_id": "P2690587", "email_address": "sehr@google.com", "orcid_id": ""}, {"name": "Cliff L. Biffle", "author_profile_id": "81479660465", "affiliation": "Google Inc., Mountain View, CA, USA", "person_id": "P2690588", "email_address": "cbiffle@google.com", "orcid_id": ""}, {"name": "Bennet Yee", "author_profile_id": "81100560095", "affiliation": "Google Inc., Mountain View, CA, USA", "person_id": "P2690589", "email_address": "bsy@google.com", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993540", "year": "2011", "article_id": "1993540", "conference": "PLDI", "title": "Language-independent sandboxing of just-in-time compilation and self-modifying code", "url": "http://dl.acm.org/citation.cfm?id=1993540"}