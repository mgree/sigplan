{"article_publication_date": "06-04-2011", "fulltext": "\n Higher-Order Test Generation Patrice Godefroid Microsoft Research pg@microsoft.com Abstract Symbolic \nreasoning about large programs is bound to be imprecise. How to deal with this imprecision is a fundamental \nproblem in pro\u00adgram analysis. Imprecision forces approximation. Traditional static program veri.cation \nbuilds may over-approximations of the pro\u00adgram behaviors to check universal for-all-paths properties, \nwhile automatic test generation requires must under-approximations to check existential for-some-path \nproperties. In this paper, we introduce a new approach to test generation where tests are derived from \nvalidity proofs of .rst-order logic formulas, rather than satisfying assignments of quanti.er-free .rst\u00adorder \nlogic formulas as usual. Two key ingredients of this higher\u00adorder test generation are to (1) represent \ncomplex/unknown pro\u00adgram functions/instructions causing imprecision in symbolic ex\u00adecution by uninterpreted \nfunctions, and (2) record uninterpreted function samples capturing input-output pairs observed at exe\u00adcution \ntime for those functions. We show that higher-order test generation generalizes and is more precise than \nsimplifying com\u00adplex symbolic expressions using their concrete runtime values. We present several program \nexamples where our approach can exer\u00adcise program paths and .nd bugs missed by previous techniques. We \ndiscuss the implementability and applications of this approach. We also explain in what sense dynamic \ntest generation is more powerful than static test generation. Categories and Subject Descriptors D.2.4 \n[Software Engineer\u00ading]: Software/Program Veri.cation; D.2.5 [Software Engineer\u00ading]: Testing and Debugging; \nF.3.1 [Logics and Meanings of Pro\u00adgrams]: Specifying and Verifying and Reasoning about Programs General \nTerms Testing, Veri.cation Keywords Automatic Test Generation, Software Model Check\u00ading, Uninterpreted \nFunctions 1. Introduction Automatic code-driven test generation aims at proving existential properties \nof programs: does there exist a test input that can ex\u00adercise a speci.c program branch or statement, \nor follow a speci.c program path, or trigger a bug? Test generation dualizes traditional program veri.cation \nand static program analysis aimed at prov\u00ading universal properties which holds for all program paths, \nsuch as there are no bugs of type X in this program . Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, USA. Copyright \nc &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 Symbolic reasoning about large programs is \nbound to be impre\u00adcise. If perfect bit-precise symbolic reasoning was possible, static program analysis \nwould detect standard programming errors with\u00adout reporting false alarms. How to deal with this imprecision \nis a fundamental problem in program analysis. Traditional static pro\u00adgram veri.cation builds may over-approximations \nof the pro\u00adgram behaviors in order to prove correctness, but at the cost of reporting false alarms. Dually, \nautomatic test generation requires must under-approximations in order to drive program executions and \n.nd bugs without reporting false alarms, but at the cost of pos\u00adsibly missing bugs. Most of the program \nanalysis literature discusses program veri\u00ad.cation for universal properties. Yet, except for static type \nsystems, the biggest practical impact of program analysis so far has been bug .nding, not proving the \nabsence of bugs. The study of effective pro\u00adgram veri.cation techniques for existential properties (i.e., \nsound bug .nding ) has recently experienced quite a resurgence. A cat\u00adalyst is arguably recent work on \nsystematic dynamic test genera\u00adtion [15], and related extensions and tools (e.g., [2, 6, 17, 23, 24]). \nOver the last few years, these techniques have been made more scalable [16], and have been used to .nd \nmany new security vul\u00adnerabilities in Windows [12] and Linux [22] applications. Work on automatic code-driven \ntest generation can roughly be partitioned into two groups: static versus dynamic test generation. Static \ntest generation [20] consists of analyzing a program P stat\u00adically, by reading the program code and using \nsymbolic execution techniques to simulate abstract program executions in order to at\u00adtempt to compute \ninputs to drive P along speci.c execution paths or branches, without ever executing the program. On the \nother hand, dynamic test generation [21] consists of executing the program P starting with some given \nor random concrete inputs, gathering sym\u00adbolic constraints on inputs at conditional statements along \nthe ex\u00adecution, and then using a constraint solver to infer variants of the previous inputs in order \nto steer the next execution of the program towards an alternative program branch; this process can be \nrepeated with the goal of systematically executing all (or as many as possi\u00adble) feasible program paths, \nwhile checking each execution using run-time checking tools (like Purify, Valgrind or AppVeri.er) for \ndetecting various types of errors [15]. It is argued in [15] that dynamic test generation is more pow\u00aderful \nthan static test generation because imprecision in symbolic execution can be alleviated using concrete \nvalues and randomiza\u00adtion: whenever symbolic execution does not know how to generate a constraint for \na program statement depending on some inputs, one can always simplify this constraint using the concrete \nruntime val\u00adues of those inputs. To illustrate this point, consider the following program example [11]: \nint obscure(int x, int y) { if (x == hash(y)) return -1; // error return 0; // ok }  Assume the constraint \nsolver cannot symbolically reason about the function hash (perhaps because it is too complex or simply \nbecause its code is not available). This means that the constraint solver cannot generate two values \nfor inputs x and y that are guaranteed to satisfy (or violate) the constraint x == hash(y).In this case, \nstatic test generation cannot generate test inputs to drive the execution of the program obscure through \neither branch of the conditional statement: static test generation is helpless for a program like this. \nNote that, for test generation, it is not suf.cient to know that the constraint x == hash(y) is satis.able \nfor some values of x and y, it is also necessary to generate speci.c values for x and y that satisfy \nor violate this constraint. In contrast, dynamic test generation can easily generate, for a .xed value \nof y,a value of x that is equal to hash(y) since the latter concrete value is known at runtime. By picking \nrandomly and then .xing the value of y, we can, in the next test execution, set the value of the other \ninput x either to hash(y) or to something else in order to force the execution of the then or else branches, \nrespectively, of the test in the function obscure. In summary, static test generation is unable to generate \ntest inputs to control the execution of the program obscure, while dynamic test generation can easily \ndrive the executions of that same program through all its feasible program paths. In realistic programs, \nimprecision in symbolic execution typically creeps in in many places, and dynamic test generation allows \ntest generation to recover from that imprecision. Dynamic test generation can be viewed as extending \nstatic test generation with additional runtime information, and is therefore more general and powerful. \nBut how much more powerful? How often can this concretiza\u00adtion trick be used? It would not work in the \ncase of a constraint like hash(x)==hash(y)+1. Does there exist an algorithm to determine in which cases \nconcretization works and when it does not? Can concretization be modeled symbolically and therefore simulated \nby static symbolic execution and test generation? If so, what is the fun\u00addamental difference between \nstatic and dynamic test generation? Can one formalize both and prove (and clarify how and why) they are \ndifferent? Is it possible to deal with imprecision in symbolic reasoning differently, in order to enable \neven more powerful test generation? The purpose of this paper is to answer all these questions, which \nare central to test generation and program analysis. We start by carefully formalizing concretization \nas introduced in [15], and show that it may or may not generate sound path constraints (Sec\u00adtion 3). \nWe then introduce (Section 4) a new more general form of test generation, which we call higher-order \nbecause it uses a higher-order logic representation of program paths. Higher-order test generation uses \nuninterpreted functions to represent unknown functions or instructions during symbolic execution, records \nun\u00adinterpreted function samples capturing concrete input-output pairs observed at execution time for \nthose functions, and generates new test inputs from validity proofs of .rst-order logic formulas with \nuninterpreted functions. We then show (in Section 5) that higher\u00adorder test generation can not only fully \nsimulate concretization when the latter is done in a sound manner, but that it is also more general and \npowerful. We discuss how to implement this approach in practice in Section 6, and present an application \n(in Section 7) which requires the power of higher-order test generation: parsers with input lexers using \nhash functions for fast keyword recognition. We conclude (in Section 9) by clarifying in what sense dynamic \ntest generation is more powerful than static test generation.  2. Background: Systematic Dynamic Test \nGeneration Dynamic test generation (see [15] for further details) consists of running the program P under \ntest both concretely, executing the actual program, and symbolically, calculating constraints on values \nstored in program variables v and expressed in terms of input pa\u00adrameters. Side-by-side concrete and \nsymbolic executions are per\u00adformed using a concrete store M and a symbolic store S,which are mappings \nfrom memory addresses (where program variables are stored) to concrete and symbolic values respectively. \nA sym\u00adbolic value is any expression e in some theory Twhere all free variables are exclusively input \nparameters. For any program vari\u00adable v, M(v) denotes the concrete value of v in M, while S(v) denotes \nthe symbolic value of v in S. For notational convenience, we assume that S(v) is always de.ned and is \nsimply M(v) by de\u00adfault if no symbolic expression in terms of inputs is associated with v in S.When S(v) \nis different from M(v), we say that that pro\u00adgram variable v is symbolic , meaning that the value of \nprogram variable v is a function of some input(s) which is represented by the symbolic expression S(v) \nassociated with v in the symbolic store. We also extend this notation to allow M(e) to denote the concrete \nvalue of symbolic expression e when evaluated with the concrete store M. The notation + for mappings \ndenotes updating; for ex\u00adample, M\" = M +[m.e] is the same map as M, except that M\" (m)= e. The program \nP manipulates the memory (concrete and sym\u00adbolic stores) through statements, or commands, that are abstrac\u00adtions \nof the machine instructions actually executed. We assume a command can be an assignment of the form v \n:= e (where v is a program variable and e is an expression), a conditional statement of the form if e \nthen else C\"\" where e denotes a boolean C\" expression, and C\" and C\"\" denote the unique1 next command \nto be evaluated when e holds or does not hold, respectively, or stop corresponding to a program error \nor normal termination. Given an input vector I assigning a concrete value Ii to the i\u00adth input parameter, \nthe evaluation of a program de.nes a unique .nite2 program execution s0 .C1s1 ... C.nsn that executes \nthe .nite sequence C1 ...Cn of commands and goes through the .nite sequence s1 ...sn of program states. \nEach program state is a tuple (C, M, S, pc)where C is the next command to be evaluated, and pc is a special \nmeta-variable that represents the current path constraint. For a .nite sequence w of commands (i.e., \na control path w), a path constraint pcw is a quanti.er-free .rst-order logic formula over theory Tthat \nis meant to characterize the input assignments for which the program executes along w. The path constraint \nis sound and complete when this characterization is exact, i.e., when the two following conditions are \nsatis.ed. DEFINITION 1. A path constraint pcw is sound if every input as\u00adsignment satisfying pcw de.nes \na program execution following path w. DEFINITION 2. A path constraint pcw is complete if every input \nassignment following path w is a satisfying assignment, or model, of pcw. Path constraints are generated \nduring dynamic symbolic exe\u00adcution by collecting input constraints at conditional statements, as illustrated \nin Figure 2. Figure 1 illustrates how to symbolically evaluate expressions e occurring in individual \nprogram instructions (line 14 should be ignored for now). The notation &#38;v denotes the 1 We assume \nprogram executions are sequential and deterministic. 2 We assume program executions terminate. In practice, \na timeout prevents non-terminating program executions and issues a runtime error.  1 evalSymbolic( e \n)= 2 match ( e ): 3 case v : // Program variable v 4 return S(&#38;v) 5 case +(e1 , e2 ): // Addition \n6 f1 = evalSymbolic( e1 ) 7 f2 = evalSymbolic( e2 ) 8 if f1 and f2 are constants 9 return evalConcrete( \ne) 10 else ' 11 return createExpression ( '+,f1 ,f2 ) 12 etc. 13 default : // default for unhandled \nexpression V 14 // pc = pc . (xi = Ii) xi.e 15 return evalConcrete( e) Figure 1. Symbolic expression \nevaluation. 1 P roc e dure execut e S y m bol i c ( P , I )= 2 in iti a liz e M0 and S0 3 p a t h c o \nn s t r a i n t pc = true 4 C = getNextCommand ( ) 5 w hile ( C = st o p ) 6 match ( C ): 7 case ( v \n:= e ): 8 M = M +[&#38;v . eval Concr e t e(e)] 9 S = S +[&#38;v .eval S y m bol i c(e)] 10 case ( i \nf e the n C' el s e C'' ): 11 b = eval Concr e t e(e) 12 c =eval S y m bol i c(e) 13 i f b the n pc = \npc . c 14 e l s e pc = pc .\u00acc 15 C = getNextCommand ( ) / / end o f w h i l e l o o p Figure 2. Symbolic \nexecution. address at which the value of program variable v is stored. To sim\u00adplify the presentation, \nwe assume that all program variables have some unique initial concrete value in the initial concrete \nstore M0, and that the initial symbolic store S0 identi.es the program vari\u00adables v whose values are \nprogram inputs (for all those, we have S0(v)= xi where xi is the symbolic variable corresponding to the \ninput parameter Ii). Initially, pc is de.ned to true. By con\u00adstruction, all symbolic variables appearing \nin pc are variables xi corresponding to program inputs Ii. Systematic dynamic test generation [15] consists \nof systemati\u00adcally exploring all (or in practice many) feasible control-.ow paths of the program under \ntest by using path constraints and a constraint solver. Given a program state s = (C, M, S, pc)and a \nconstraint solver for theory T,if C is a conditional statement of the form if e then C \" else C \"\" , \nany satisfying assignment of the for\u00admula pc .c (respectively pc .\u00acc)where c = evalSymbolic(e)in state \ns, de.nes program inputs that will lead the program to exe\u00adcute the then (resp. else) branch of the conditional \nstatement. By systematically repeating this process, such a directed search can enumerate (in theory) \nall possible path constraints and eventually execute all feasible program paths. The search is exhaustive \nprovided that the generation of the path constraint (including the underlying symbolic execution) and \nthe constraint solver for the given theory Tare both sound and com\u00adplete, that is, for all program paths \nw, the constraint solver returns a satisfying assignment for the path constraint pcw if and only if the \npath is feasible (i.e., there exists some input assignment lead\u00ading to its execution). If those conditions \nhold, in addition to .nd\u00ading errors such as the reachability of bad program statements (like assert(false)), \na directed search can also prove their absence, and therefore obtain a form of program veri.cation. THEOREM \n1. (adapted from [15]) Given a program P as de.ned above, a directed search using a path constraint generation \nand a constraint solver that are both sound and complete exercises all feasible program paths exactly \nonce. Thus, if a program statement has not been executed when the search is over, this statement is not \nexecutable in any context. In practice, path constraint generation and constraint solving are usually \nnot sound and complete. Note that the above formalization and theorem do apply to programs containing \nloops or recursion, as long as all program executions terminate. However, in the presence of a single \nloop whose number of iterations depends on some unbounded input, the number of feasible program paths \nbecomes in.nite. In practice, search termination can always be forced by bounding input values, loop \niterations or recursion, at the cost of potentially missing bugs.  3. Sound and Unsound Concretization \n3.1 Concretization and Must Abstraction When a program expression cannot be expressed in the given theory \nTdecided by the constraint solver, it can be simpli.ed using concrete values of sub-expressions, or replaced \nby the concrete value of the entire expression. This case corresponds to line 13 of Figure 1. Let us \ncall concretization the process of replacing a symbolic expression by its current concrete value during \ndynamic symbolic execution. In the presence of concretizations, path constraint generation is in general \nno longer sound and complete since constraints be\u00adcome approximate and path constraints no longer capture \naccu\u00adrately program path feasibility. (In the original DART algorithm of [15], some completeness .ag \nwould then be set off and the outer loop in Figure 2 of [15] would run forever.) Moreover, Theorem 1 \nno longer holds since its assumptions are no longer satis.ed. Loosely speaking, concretizing a symbolic \nexpression under\u00adapproximates its set of possible values by a singleton set containing its unique current \nruntime value. In that sense, concretization can be viewed as a must abstraction which is sound for bug-.nding. \nMust abstractions capture existential reachability properties that hold on some but not all program executions. \nA sound path constraint (see De.nition 1) is an example of must abstraction [17]. Note that, if a sound \npath constraint pcw is satis.able, then the corresponding program path w is feasible. But the converse \ndoes not necessarily hold: an algorithm for generating sound path constraints may fail to generate path \nconstraints for some feasible program paths, and hence may fail to exercise some code and may miss bugs. \n 3.2 Unsound Concretization Strictly speaking, however, concretization alone does not guarantee a sound \npath constraint generation. Consider the following program example. int foo(int x, int y) { if (x == \nhash(y)) { ... if (y == 10) return -1; // error } ... } Assume that the function hash is unknown , that \nthe program is run with the input values x=567 and y=42,that hash(42) is 567, and hence that the execution \ntakes the then branch of the .rst conditional statement. The path constraint generated by the DART algorithm \nof Figures 1 and 2 (i.e., without line 14 of Figure 1) is x = 567 .y =10  Indeed, the expression hash(y) \nwhich (we assume) is outside Tis replaced by its concrete value 567 by line 15 of Figure 1. But the algorithm \ndoes not record this concretization at the .rst conditional statement, and allows a symbolic constraint \ny =10 to be generated on y later on. This path constraint correctly captures the current concrete execution \n(since x is indeed 567 and y is indeed different from 10 for this run), but it is not sound:for x equal \nto 567 and some value of y different from 10, the input assignment satis.es the path constraint but does \nnot de.ne a program execution following the same execution path if hash(y) is not 567. By negating the \nlast constraint of this unsound path constraint and solving the new path constraint x = 567 .y =10 one \ngets a new test input that should drive the program towards the error, but results instead in a divergence \n[15], i.e., an unexpected program path being taken if hash(10) is different from 567. The risk of divergences \nin the presence of unsound path con\u00adstraints is not a new observation: it is discussed in [15] and moti\u00advates \nthe need for comparing the actual path taken by the program under test with the expected path w derived \nfrom each path con\u00adstraint pcw. When additional constraints are automatically injected in path constraints \nfor checking additional program properties such as the absence of buffer over.ows, every new test input \ngenerated violating such injected constraints should be executed to con.rm the bug before reporting it \nto the user, in order to avoid reporting false alarms due to divergences from unsound path constraints. \n 3.3 Sound Concretization To generate sound path constraints, we propose the following new variant of \nthe DART algorithm: whenever a symbolic expression e is concretized during symbolic execution, for all \nsymbolic variables xi occurring in e,a new concretization constraint xi = Ii is added to the path constraint, \nas illustrated in line 14 of Figure 1, which we now assume is un-commented. This implies that the value \nof each such symbolic variable xi is .xed to a constant equal to the corresponding current input value \nIi below in the path constraint. Let us call this procedure sound concretization. Indeed, we now show \nthat sound concretization results in sound path constraints. THEOREM 2. The algorithm of Figures 1 and \n2 with sound con\u00adcretization, i.e., including line 14 of Figure 1, generates sound path constraints. \nProof: The proof relies on the assumption that all sources of impre\u00adcision in symbolic execution are \ndetected and trigger the default case in the procedure evalSymbolic shown in Figure 1. In ev\u00adery such \ncase, line 14 is executed and a concretization constraint is injected in the path constraint. Otherwise, \nin all other cases, sym\u00adbolic execution of individual instructions (assignments or condi\u00adtional statements) \nis assumed to be precise, i.e., both sound and complete. Consider a path constraint pcw generated by \nthis algorithm during the execution of a program path w with an input vector I = (Ii|.i). For every symbolic \nvariable xi (generalizing program input Ii) occurring in pcw, two cases are possible. Either there is \na concretization constraint forcing xi to be equal to Ii.Orall constraints on xi in pcw are both sound \nand complete (symbolic execution is precise so far for all individual instructions involving xi). Either \nway, all values of xi satisfying pcw satisfy all the tests on inputs along w and hence lead to a program \nexecution following the same path w. Since the same argument holds for all symbolic variables xi, pcw \nis sound. Unlike ordinary constraints derived from conditional statements executed by the program under \ntest, concretization constraints should not be negated later in the directed search, because negating \nthese constraints will not de.ne alternate path constraints corre\u00adsponding to new program paths. The \nonly purpose of concretization constraints is to guarantee soundness of path constraints. EXAMPLE 1. \nConsider again the example of function foo shown in Section 3.2. Assume again we run with program with \ninputs x=567 and y=42,and that hash(42) is 567. With sound con\u00adcretization, a concretization constraint \ny =42 is generated when symbolically evaluating hash(y) in the .rst conditional statement, and dynamic \nsymbolic execution generates the sound path con\u00adstraint y =42 .x = 567 .y =10 After negating the last \nconstraint, the resulting constraint y =42 .x = 567 .y =10 is not satis.able, and no new test is generated \nto try to cover the then branch of the second conditional statement. Sound concretization generates \nsound path constraints and elim\u00adinates divergences. But in practice, sound concretization is not nec\u00adessarily \nbetter than DART s default unsound concretization, for two reasons. First, a drawback of sound concretization \nis that it reduces the ability to generate new tests. EXAMPLE 2. Consider the following program using \nthe same hash function: int foo-bis(int x, int y) { if (x != hash(y)) { ... if (y == 10) return -1; // \nerror } ... } Assume the program is run with inputs x=33 and y=42,and that hash(42) is 567. Sound concretization \ngenerates the sound path constraint y =42 .x = 567 .y =10 After negating the last constraint, the resulting \nconstraint y =42 .x = 567 .y =10 is not satis.able, no new test is generated to try to cover the then \nbranch of the second conditional statement, and the error is missed. In contrast, unsound concretization \nwould generate the path constraint x = 567 .y =10 After negating the last constraint, a constraint solver \nwould easily solve the (unsound) path constraint x = 567 .y =10 and generate a new test that is likely \n(but not guaranteed) to hit the error, assuming hash(10) is likely different from the value of x whatever \nits value is. This is an example of a good divergence . Second, and perhaps most importantly, sound \nconcretization is much harder to implement than unsound concretization, since it requires detecting explicitly \nall sources of imprecision in sym\u00adbolic execution including conservatively estimating all pos\u00adsible \ninputs and outputs of all individual instructions and all unknown/library/operating-system functions \nused by the program under test , while unsound concretization can simply be imple\u00admented by handling \nsome program instructions and ignoring the others.  Finally, note that adding line 14 of Figure 1 is \njust one way to in\u00adject concretization constraints and that other variants are possible. For instance, \nthe injection of concretization constraints for sym\u00adbolic variables xi occurring in a concretized expression \ne could be delayed during symbolic execution until e is actually being used in some constraint (if any) \nin the path constraint pcw.This way, examples such as ... x := hash(y); if (y == 10) return -1; // error \n... could be handled with sound concretization by postponing injecting a concretization constraint for \ny from when hash(y) is computed to when program variable x is being tested (if at all), and a con\u00adstraint \nto cover the other branch of the test (y == 10) could be generated and solved.  4. Higher-Order test \nGeneration We now introduce a more general form of test generation, which we call higher-order because \nit uses a higher-order logic representa\u00adtion of path constraints. Higher-order test generation requires \nthree steps: 1. uninterpreted functions are used to represent unknown func\u00adtions or instructions during \nsymbolic execution; 2. new test inputs are derived from validity proofs of .rst-order logic formulas \nwith uninterpreted functions; 3. concrete input-output value pairs need be recorded as uninter\u00adpreted \nfunction samples that are used when generating new con\u00adcrete test inputs.  We now discuss these three \nsteps in detail one by one. 4.1 Symbolic Execution with Uninterpreted Functions Another well-known approach \nfor reasoning about unknown func\u00adtions is to represent those using uninterpreted functions. Figure 3 \npresents a more general algorithm for dynamic symbolic execution where unknown functions or instructions \nare represented explicitly using uninterpreted function symbols. This algorithm extends the standard \nsymbolic execution procedure of Figure 2 with the new lines marked with *. Whenever an unknown function \nor instruction f is encountered during symbolic execution (line 10 of Figure 3), an uninterpreted function \nsymbol f uniquely representing the func\u00adtion/instruction is used to represent the symbolic return value \nof the function call, which is de.ned as the application of the func\u00adtion to its symbolic input arguments \n(line 12). Symbolic execution resumes after the function returns. By unknown function, we mean any function \nwhose code is not available or not precisely representable by a symbolic expression of the theory Thandled \nby the constraint solver for whatever reason (such as hash or crypto functions, operating-system functions, \nen\u00advironment/library functions outside of the main scope of analysis, etc.). Similarly, by unknown instruction, \nwe mean any atomic pro\u00adgram instruction not handled by the symbolic evaluation procedure, i.e., involving \nsome symbolic expression previously concretized in line 13 of Figure 1. For simplicity, we represent \nsuch unknown in\u00adstructions by uninterpreted functions as well; line 13 of Figure 1 is thus no longer \nreachable, by construction, with the new algorithm.3 In Figure 3, args denotes a list of arguments. Each \nargument is a variable v whose value is an input to the function call (we consider a call-by-value function \nmodel here, for simplicity). 3 Any symbolic expression e including an unknown function/instruction ap\u00adplication \nf(args) as sub-expression is equivalent to vf(args) := f(args) followed by e where f(args) is replaced \nby vf(args). Consider again the example of function foo showninSec\u00adtion 3.2. When symbolically executing \nthe .rst conditional state\u00adment (x == hash(y)), a fresh uninterpreted function symbol h is introduced \nto represent the unknown function hash.If the then branch of the .rst conditional statement is taken, \nthe path constraint generated is then x = h(y) The new symbolic execution performed by the algorithm \nof Fig\u00adure 3 typically generates more symbolic values than the standard symbolic execution procedure \nof Figure 2, since it represents un\u00adknown functions with symbolic uninterpreted functions instead of \nusing concretization and falling back on concrete values. There\u00adfore, the new algorithm typically generates \nmore symbolic con\u00adstraints in the path constraint pc (lines 17 and 18). We can prove that those path \nconstraints are always sound. THEOREM 3. The algorithm of Figure 3 generates sound path con\u00adstraints. \nProof: The proof relies on the assumption that all sources of im\u00adprecision in symbolic execution are \ndetected in line 10 of the pro\u00adcedure executeSymbolic in Figure 3 and are representable by un\u00adinterpreted \nfunctions (line 12), which implies that every unknown function/instruction is deterministic and with \na known input-output signature. For all other cases, symbolic execution of individual in\u00adstructions (assignments \nor conditional statements) is assumed to be precise, i.e., both sound and complete. Consider a path constraint \npcw generated by this algorithm during the execution of a program path w with an input vector I = (Ii|.i). \nAt any time during the symbolic execution along w, all direct dependencies on inputs are tracked precisely \nvia the symbolic store, either in sound and complete manner via the pro\u00adcedure evalSymbolic of Figure \n1, or using uninterpreted function applications. Therefore, at every conditional statement C executed \nalong w, if a constraint c involving some symbolic variable xi is added in C to the path constraint pcw, \nall input values of xi satis\u00adfying c take the same branch as the current concrete value Ii of xi. Since \nthe same argument holds for all symbolic variables xi and all symbolic constraints in pcw, every input \nassignment I \" satisfying the path constraint pcw de.nes a program execution following the given path \nw, which means that pcw is sound. The previous theorem states that, if an input assignment satis.es \na path constraint pcw generated by the algorithm of Figure 3, then the corresponding program execution \nwill follow path w. For instance, considering again our running example, any input assignment to the \nvariables x and y that satis.es the path constraint x = h(y) will take the then branch of the conditional \nstatement in function foo. But this result alone does not prescribe how to compute such values and generate \ntests from path constraints with uninterpreted function symbols. This problem is discussed next.  4.2 \nGenerating Tests from Validity Proofs When uninterpreted functions are used in path constraints to model \nimprecision in symbolic execution, test generation from such path constraints must be performed from \nvalidity proofs, instead of sat\u00adis.ability proofs, as will be shown shortly. This requires path con\u00adstraints \nto be post-processed before calling the validity checker: every ordinary symbolic variable representing \na program input is existentially quanti.ed, resulting in a .rst-order logic formula of the form .x : \nf(f, x) while every uninterpreted function symbol f is implicitly left uni\u00adversally quanti.ed in the \nvalidity check. Remember that .rst-order logic does not allow explicit quanti.cation over functions: \nuniver\u00adsal function quanti.cation is implicit when checking validity, while  1 Procedure executeSymbolic( \nP , I )= 2 initialize M0 and S0 3 path constraint pc = true 4 C = getNextCommand () 5 while ( C = stop) \n6 match ( C ): 7 case ( v := e ): 8 M = M +[&#38;v . evalConcrete(e)] 9 S = S +[&#38;v .evalSymbolic(e)] \n 10 * case ( v := f(args) ): // f is an unknown function or instruction 11 * M = M +[&#38;v . evalConcrete(f(args))] \n' 12 * S = S +[&#38;v . createExpression ( f ' , evalSymbolic( args ))] ' 13 * Add ( M(&#38;v), createExpression \n( f ' , evalConcrete( args ))) to IOF ; 14 case (if e then C ' else C '' ): 15 b = evalConcrete(e) 16 \nc = evalSymbolic(e) 17 if b then pc = pc . c 18 else pc = pc .\u00acc 19 C = getNextCommand() // end of while \nloop Figure 3. Symbolic execution with uninterpreted functions. existential function quanti.cation is \nimplicit when checking satis\u00ad.ability.4 We emphasize that representing unknown functions by uninter\u00adpreted \nfunction symbols in validity queries is not new in program veri.cation. Indeed, for veri.cation, the \nset of possible behaviors of unknown functions needs to be over-approximated to guaran\u00adtee a may abstraction \nthat can be used to prove correctness, hence the use of (implicit) universal quanti.cation.However,what \nis new here (to the best of our knowledge) is our use of (implicit) univer\u00adsal quanti.cation for uninterpreted \nfunction symbols for test gen\u00aderation, instead of (implicit) existential quanti.cation with satis.\u00adability \nqueries as usual in the context of test input generation. We discuss this further in Section 8. We now \nillustrate this important difference, and why we need it. Consider again the example of the obscure function \nused in the introduction: int obscure(int x, int y) {if (x == hash(y)) return -1; // error return 0; \n// ok } Let us assume again that the function hash is unknown , that the program is run .rst with the \ninput values x=33 and y=42,and that hash(42) is 567 and hence that the .rst execution takes the else \nbranch of the conditional statement. With the standard symbolic execution of Figure 2, the single constraint \nappearing in the path constraint pc is x = 567 Next, the satis.ability of the negation of this constraint, \nnamely x = 567 is checked by the constraint solver. Since it is satis.able, the sat\u00adisfying assignment \nreturned by the constraint solver is transformed into a new input vector, namely x=567 and y=42, that \nwill drive the next execution of the program along the then branch of the condi\u00adtional statement. Note \nhow input variable x is existentially quanti\u00ad.edinthe satis.ability check performed by the constraint \nsolver. In contrast, with the new symbolic execution procedure of Fig\u00adure 3, the single constraint appearing \nin the path constraint is now x = h(y) 4 A logic formula is satis.able if there exists a variable assignment \nthat makes the formula true, and it is valid if all variable assignments make the formula true. where \nh denotes the uninterpreted function symbol representing the unknown function hash. After post-processing, \nthe validity of the formula .x, y : x = h(y) is checked by the constraint solver (i.e., for all h). If \nthe formula is valid, a test-generation strategy is derived from the validity proof of the formula, viewed \nas a strategy for making the formula always true. In this case, the formula is valid and the strategy \nis .x y,thenset x to the value h(y) . In other words, with the new algorithm, new tests are derived from \nvalidity proofs, instead of satisfying assignments as usual. Indeed, we have no choice: if uninterpreted \nfunctions are used to model imprecision in symbolic execution, test generation can no longer be performed \nfrom satis.ability checks. In the above example, checking the satis.ability of the formula x = h(y) (where \nh, x and y are thus all implicitly quanti.ed existentially) may return satisfying assignments that are \nunusable for test gen\u00aderation since the existential quanti.er over h allows the constraint solver to \ninvent some speci.c arbitrary function h that helps it prove satis.ability. For instance, the constraint \nsolver may de.ne function h such that h(0) = 0 and then return x=0 and y=0 as satisfying assignments. \nSince such a function h may differ from the speci.c unknown function hash called in the program under \ntest, sound test generation is not possible when existentially quantifying h.  4.3 The Need for Uninterpreted \nFunction Samples Test strategies derived from validity proofs are necessary but not suf.cient to compute \nconcrete input vectors, which is required in test generation. For instance, with the above test strategy, \nthe value h(y) is not derived from the validity proof: a concrete value for x can be obtained only when \nsome values for y and h(y) are known. In general, the value of h(y) for a given y can only be known at \nruntime. (Unless the function h is completely known and not too complex to be represented as a logic \nformula; then a constraint solver using constant propagation starting from some concrete input value \ny could simulate the execution of h with value y as argument and compute the value h(y);however, even \nin this case, constant propagation is orders of magnitude slower and less scalable than simply running \nthe actual code implementing the function h with value y as argument.)  In the above example, we need \nto know that if y is set to 42, then h(y) is 567 in order to set x to that value following the test\u00adgeneration \nstrategy derived from the validity proof. In other words, the new symbolic execution algorithm using \nun\u00adinterpreted functions also needs to record runtime concrete values to allow for test generation of \nspeci.c concrete input values. Let us call this step uninterpreted function sampling. Speci.cally, we \ncan record the concrete value of any function application such as h(y) during dynamic symbolic execution \nas well as the concrete value of each of its arguments, as shown in line 13 of Figure 3: a pair (c, f(evalConcrete(args))) \nis recorded for each function application where evalConcrete(args) denotes the list of concrete values \nof each function argument and c denotes the concrete return value of the function applied to those concrete \nargument values. In the above example, the record pair is thus (567,h(42)), meaning that 567 = h(42). \nThese pairs (c, f(evalConcrete(args))) of recorded values have two purposes. They are used to interpret \na test generation strategy derived from a validity proof in order to assign concrete values to function \napplications (such as h(y)) appearing in the strategy and generate concrete values to new input tests. \n They can also be used to generate additional constraints of the form c = f(evalConcrete(args)) as an \nantecedent to the path constraint that is passed to the constraint solver. Such constraints restrict \nthe possible interpretations for uninterpreted function symbol f, and increases the chance of validity. \n The latter can be more powerful and is necessary for higher-order test generation to always subsume \nsound concretization, as will be shown in the next section. Therefore, we adopt this second option in \nwhat follows. To sum up, given a path constraint pc using a set X of sym\u00adbolic variables, a set F of \nuninterpreted functions and a set IOF of recorded input-output function samples, the post-processed for\u00admula \nPOST (pc) obtained by post-processing pc in high-order test generation is the .rst-order logic formula \nde.ned by POST (pc)= .X : A .pc where .X denotes that all symbolic variables xi .X are ex\u00adistentially \nquanti.ed, .denotes logical implication, and A is the conjunction of equality constraints c = f(evalConcrete(args)) \nfor all (c, f(evalConcrete(args))) .IOF .Inwhatfollows,we call A the antecedent of POST (pc). For instance, \nconsider again our running example with a path constraint pc containing a single constraint x = h(y) \nand a single recorded pair (567,h(42)).Then POST (pc) is .x, y : (567 = h(42)) .(x = h(y)) Sometimes, \nthe antecedent does not help the validity proof it\u00adself, as in the previous example, and only helps for \ngenerating ac\u00adtual concrete test values. But sometimes, the antecedent is neces\u00adsary to prove validity, \nas shown in Section 5.3. In practice, recording all concrete arguments and return values of all uninterpreted \nfunction applications used in a path constraint can be prohibitively expensive for long program executions. \nMore\u00adover, it is unfortunately hard to predict which concrete values will be needed later in the path \nconstraint, i.e., which concrete values are concretizations of symbolic expressions with uninterpreted \nfunc\u00adtions on which there are tests below in the path constraint. How\u00adever, it is possible to track only \nsome sources of imprecision and only represent those using uninterpreted functions, and to track and \nrepresent only some input-output pairs for tracked functions. Imple\u00admentability issues will be discussed \nfurther in Section 6.  5. Comparison In this section, we compare the test-generation power of higher\u00adorder \ntest generation (Section 4) with sound and unsound con\u00adcretization (Section 3). 5.1 Higher-Order Test \nGeneration and Unsound Concretization are Incomparable As discussed at the end of Section 3.3, sound \nand unsound con\u00adcretization are incomparable in general, since unsound concretiza\u00adtion can lead to (bad \nor good) divergences that will not occur with sound concretization. Similarly, by Theorem 3, higher-order \ntest generation generates sound path constraints and is thus incompara\u00adble to unsound concretization \nin general, for the same reasons. EXAMPLE 3. Consider the function int bar(int x, int y) { // x,y are \ninputs if ((x == hash(y)) AND (y == hash(x))) { ... // error } ... } Given random inputs x =33 and y \n=42 and assuming hash(42)=567 and hash(33)=123, unsound concretization will generate an unsound path \nconstraint x = 567 .y = 123 whose negation x = 567 .y = 123 is satis.able and generates a new test input \npair (x = 567,y = 123)which will likely lead to a divergence. In contrast, higher-order test generation \nwill generate a sound path constraint x = h(y) .y = h(x) After post-processing, the validity of the formula \n.x, y : x = h(y).y = h(x) will be checked. But no new test will be generated since this formula is invalid \n(in general, unless we learn some additional property of h such as there exists an x such as x = h(h(x)), \nfor instance).  5.2 Higher-Order Test Generation is as Powerful as Sound Concretization In the remainder \nof this section, we will therefore restrict the comparison of higher-order test generation to sound concretization. \nBoth algorithms generate sound path constraints (see Theorems 2 and 3). We now show that high-order test \ngeneration is at least as powerful as test generation with sound concretization. V Given a path constraint \npc = ci,let ALT (pc) denote 1=i=n the new alternate path constraint de.ned by the conjunction of the \nnegation of the last constraint cn of pc with all previous constraints cj with j<i in pc. We thus have \n^ ALT (pc)= \u00accn . 1=i=(n-1) Remember that, as explained in Section 2, all nonempty pre.xes of a path \nconstraint are also path constraints (except those ending with a concretization constraint). Let pc SC \ndenote a path constraint generated for a program path w w with sound concretization (Section 3.3) and \nwhose last constraint UF is not a concretization constraint. Let pcw be the path constraint generated \nwith higher-order test generation (Section 4.1) for the same program path w. Given any theory T,let T.TEUF \ndenote the theory combining Twith the theory of equality with uninter- SC SC preted functions (EUF). \nIf pcw and ALT (pcw ) are quanti.er- UF UF free formulas over T,then pcw and ALT (pcw ) are quanti.er\u00ad \n UF free formulas over T.TEUF , while POST (ALT (pcw )) is a .rst-order logic formula over T.TEUF , \nby construction. THEOREM 4. (Simulation Theorem) SC UF If ALT (pcw ) is satis.able, then POST (ALT (pcw \n)) is valid. Proof: UF We show how to derive a validity proof for POST (ALT (pcw )) SC from any satisfying \nassignment for ALT (pcw ). Whenever a complex/unknown expression e(xi) .Toccurs during symbolic execution \nwith sound concretization, a concretiza- SC tion constraint xi = Ii is introduced in pcw , e(xi) becomes \ne(Ii), and all future expressions e \" (xi) depending on xi become e \" (Ii). In contrast, in higher-order \ntest generation, every occurrence of a complex/unknown expression e(xi) .Tbecomes fe(xi) where fe is \nan uninterpreted function symbol representing e,and the pair (evalConcrete(e(Ii)),fe(Ii)) is being recorded. \nConsider any symbolic variable xi .X for which there is a concretization constraint xi = Ii in ALT (pc \nSC). Consider any w expression e(xi) .Tconcretized into e(Ii) and occurring in SC UF ALT (pcw ).In POST \n(ALT (pcw )), e(xi) is represented by fe(xi) and evalConcrete(e(Ii)) = fe(Ii) is in the antecedent. In \nPOST (ALT (pc UF )), repeat the following process for w all the symbolic variables xi with a concretization \nconstraint in ALT (pc SC) and for all the functions fe using those variables as w arguments: substitute \nall the occurrences of xi by Ii andthenall the occurrences of any function fe(Ii) by evalConcrete(e(Ii)).(Note \nthat this last step would not be possible if evalConcrete(e(Ii)) = fe(Ii) was not present, i.e., known \nand recorded, in the antecedent of POST(ALT(pc UF )).) At the end, we are left with a formula f(X \" ) \nwhere X \" denotes the set of all remaining symbolic variables xi \" .X for which there SC are no concretization \nconstraints in ALT (pcw ). Therefore, we know that all expressions of the form e(xi\" ) in f(X \" ) are \nin T, that they did not introduce imprecision in symbolic execution, and that they are represented in \nthe exact same way in ALT (pc SC). w Thus, by construction, the consequent of f(X \" ) is syntacti\u00adcally \nequivalent to ALT (pc SC) when all its concretization con\u00ad w straints are removed. Since all occurrences \nof all uninterpreted function symbols fe have been eliminated from the consequent of f(X \" ), the universal \nquanti.cation over those functions in f(X \" ) becomes void intuitively. The same holds for the existential \nquan\u00adti.cation for all symbolic variables xi .X \" that no longer ap\u00adpear in f(X \" ). Since the consequent \nof f(X \" ) is logically equiv- SC \" alent to ALT (pcw ), if the latter is satis.able, then .X : A . SC \nUF ALT (pcw ) is valid. This implies that .X : A .ALT (pcw ) is valid (by setting the value of each variable \nxi .X \\X \" to Ii). We emphasize that the previous theorem holds only if uninter\u00adpreted function samples \nare used. Otherwise, higher-order test gen\u00aderation may not be able to simulate sound concretization, \nas illus\u00adtrated by the following example. EXAMPLE 4. Consider the function int pub(int x, int y) { // \nx,y are inputs if ((hash(x) > 0) AND (y == 10)) return -1 // error ... } Given random inputs x =1 and \ny =2 and assuming hash(1)=5, sound concretization will generate a sound path constraint x =1 .y =10 (after \nsimplifying 5 > 0 to true). The alternate path constraint x =1 .y =10 is satis.able and generates a new \ntest input pair (x =1,y =10)to cover the then branch of the conditional statement. In contrast, higher-order \ntest generation without uninter\u00adpreted function samples will generate a sound path constraint h(x) > \n0 .y =10 However, after post-processing of the alternate path constraint at\u00adtempting to cover the then \nbranch, the validity of the formula .x, y : h(x) > 0 .y =10 will be checked. But no new test will be \ngenerated since this formula is invalid (to see this, consider the function h such that h(x)=0 for all \nx, for instance). If instead we consider higher\u00adorder test generation with uninterpreted function samples, \nwe then obtain after post-processing the formula .x, y :(h(1) = 5) .(h(x) > 0 .y = 10) which is valid \n(by setting (x =1,y =10)). An important remark is that Theorem 4 only compares the path\u00adconstraint generation \ncapabilities of higher-order test generation and sound concretization. But it does not state that if \nthere exists SC a constraint solver that can prove the satis.ability of ALT (pcw ), then there exists \na constraint solver that can prove the validity UF of POST (ALT (pcw )). Thus, when we say that higher-order \ntest generation is as powerful as sound concretization , we assume we are given perfect constraint solvers \nfor both satis.ability and validity checking.  5.3 Higher-Order Test Generation is More Powerful Than \nSound Concretization The previous theorem states that higher-order test generation is at least as powerful \nas sound concretization. Is it more powerful? The answer is yes, for three reasons. First, since higher-order \ntest generation uses T.TEUF , it can infer test strategies thanks to axioms included in the theory of \nequality with uninterpreted functions (EUF), which are not avail\u00adable to sound concretization, which \nonly uses T. EXAMPLE 5. Higher-order test generation can generate tests from validity proofs of post-processed \npath constraints such as .x, y : f(x)= f(y) thanks to the theory of equality with uninterpreted functions. \n(So\u00adlution strategy: set x = y). In contrast, sound concretization would force the concretization of \nx, y, f(x) and f(y), and would not be able to generate a test to cover a path with such a path constraint. \n Second, higher-order test generation can sometimes leverage concrete input-output pairs that are part \nof the antecedent of a post\u00adprocessed path constraint in order to prove the validity of formulas that \nwould otherwise be invalid. EXAMPLE 6. Consider the post-processed path constraint .x, y : f(x)= f(y)+1 \nThis formula is in general invalid (to see this, consider a function f that always returns 0). However, \nassume that it is dynamically observed that f(0) = 0 and f(1) =1. Then these recorded pairs can be part \nof the antecedent of the post-processed path constraint, which becomes .x, y :(f(0) = 0 .f(1) = 1) .f(x)= \nf(y)+1 This formula is valid (solution strategy: set x =1 and y =0). In either case, sound concretization \nwould force the concretization of x, y, f(x) and f(y) and would not be able to generate new tests. Third, \nhigher-order test generation can sometimes generate test strategies that involves a sequence of new tests, \nwhose purpose is to collect additional function samples in a targeted manner, instead of a single new \ntest as usual. Let us call this new type of test generation multi-step test generation.  EXAMPLE 7. \nConsider again the example of function foo of Sec\u00adtion 3.2, reproduced here for convenience: int foo(int \nx, int y) { if (x == hash(y)) { ... if (y == 10) return -1; // error } ... } Starting with x =33 and \ny =42 and assuming hash(42)=567, this .rst test takes the else branch of the .rst conditional statement. \nAfter negating the last constraint, we obtain the post-processed alternate path constraint .x, y :(h(42) \n= 567) .x = h(y) This formula is valid and we generate a new input vector (x = 567,y =42). We run this \nnew test and we now take the then branch of the .rst conditional statement followed by the else branch \nof the second conditional statement. After negating the last constraint, we obtain the post-processed \nalternate path constraint .x, y :(h(42) = 567) .(x = h(y) .y = 10) This formula is valid, and a test \nstrategy derived from the validity proof is set y =10,set x = h(10) . However, since the value of h(10) \nhas never been sampled, it is currently unknown! Anew intermediate test with, say, (x = 567,y =10)is \nnecessary to learn the value of h(10), say 66. Only then can a second input vector (x =66,y =10)be generated \nto .nish interpreting the previous test strategy, to exercise the then branch of the second conditional \nstatement and hit the error. This is an example of two-step test generation. Of course, such examples \ncan easily be generalized to k-step test generation for any k bounded by the number of program inputs. \nAnother related yet orthogonal suggestion would be to include in the antecedent of post-processed alternate \npath constraints gener\u00adated with higher-order test generation, not only all the input-output value pairs \nobserved for the current run, but also all value pairs observed during all previous runs.  6. Discussion: \nImplementability As explained in the introduction, the main purpose of this paper is to carefully study \nthe power of recent test generation techniques such as DART which are quickly gaining popularity. It \nis also to understand the fundamental difference between static and dynamic test generation. In the process, \nwe proposed higher-order test gen\u00aderation as a powerful test generation technique generalizing sound \nconcretization. How practical is higher-order test generation? For large applications such as those targeted \nby whitebox fuzzing [16], exhaustively tracking all sources of imprecision dur\u00ading symbolic execution \nis problematic. Such imprecision can be due to unhandled individual instructions (for instance, the complete \nx86 instruction set contains hundreds of instructions described in a 1,000+ pages manual with exotic \nbit-manipulations, .oating\u00adpoint/SSE instructions, etc.), operating-system calls (should kernel execution \nbe symbolic and if so up to what depth?), complex func\u00adtions (for hashing, encrypting, compressing, encoding, \nCRC-ing data), etc. For instance, a single symbolic execution of Excel with 45K input bytes executes \nnearly a billion x86 instructions (see Fig\u00adure 6 of [16]), including many input-tainted unhandled ones \nand many system calls. Moreover, some of this imprecision is hard to capture using uninterpreted functions \nbecause the real functions may look nondeterministic and/or with complex or unknown input\u00adoutput signatures \n(such as malloc, rand, fork, etc. which take as inputs large/unknown parts of the operating-system state \nand may have many hidden side effects). Finally, capturing at execution time all observed input-output \nvalue pairs is problematic as well. For large applications, all this would slow down an already slow \nsym\u00adbolic execution and generate gigantic path constraints that would overwhelm even the best engineered \nconstraint solvers. Therefore, we envision a more focused role for higher-order test generation in practice, \ntargeted at reasoning about speci.c user\u00adidenti.ed complex or unknown functions that must be dealt with \nin order to properly test an application. One such application is presented in the next section. Another \nobstacle to the implementability of higher-order test generation is the relative lack of support for \ngenerating validity proofs by existing constraint solvers such as SMT solvers. Indeed, a .rst-order logic \nformula .X : f(F, X) can be proved valid by checking whether its negation .X : \u00acf(F, X) is unsatis.able \nwith a Satis.ability-Modulo-Theories solver. For .rst-order logic formulas like those considered here, \nvalidity (equivalently unsatis\u00ad.ability) is usually proved using saturation techniques [3]. Better tool \nsupport for generating saturation-based proofs (not just mod\u00adels for satis.able instances) that are parsable \nby other tools would help extracting a test generation strategy from such proofs. More work is needed \nin this area. In fact, our paper can be viewed as a requirement speci.cation for next-generation SMT \nsolvers for test generation, a growing application area for those, by presenting higher-order test generation \nas a new possible application for those tools.  7. Application In this section, we present an application \nwhich requires the power of high-order test generation: test generation for parsers with input lexers \nusing hash functions for fast keyword recognition. As observed in [14], dynamic test generation can be \nineffective when testing applications with highly-structured inputs. Examples of such applications are \ncompilers and interpreters. These appli\u00adcations process their inputs in stages, such as lexing, parsing \nand evaluation. Unfortunately, lexers often detect language keywords by comparing their pre-computed \nhash values with the hash val\u00adues of strings read from the input. This effectively prevents sym\u00adbolic \nexecution and constraint solving from ever generating input strings that match those keywords since hash \nfunctions cannot be inversed (i.e., given a constraint x == hash(y) and a value for x, one cannot compute \na value for y that satis.es this constraint). In those cases, test generation is defeated already in \nthe .rst process\u00ading stages. A typical code pattern is shown in Figure 4 in the appendix. This C code \nis an excerpt from the open-source .ex lexer. Initially, the function addsym is called with every input-language \nkeyword so that each of those are hashed (with function hashfunct)and stored in a hash table table. Once \nthe hash table is populated, the parsing of the input starts. The input is being divided into chunks \ndelimited by blank-spaces/tabs/etc. Each of those chunks are then parsed and the function findsym is \ncalled to check whether a chunk matches a keyword. Because of the presence of function hashfunct, dynamic \ntest generation may not be able to generate input strings ( chunks ) matching speci.c keywords. In [14], \nit is shown how such a prob\u00adlematic lexer can be bypassed altogether for test generation of the subsequent \ninput-processing stages by (1) instrumenting the lexer so that its return symbol values become symbolic \ninputs during symbolic execution, and (2) lifting the input space from charac\u00adter strings to sequences \nof symbols (token ids) using a grammar speci.cation of the input language being parsed. Unfortunately, \nin\u00adstrumenting a lexer this way can be problematic for complex lexers, and this approach requires a user-supplied \ninput-grammar speci.\u00adcation.  In contrast, higher-order test generation provides a more auto\u00admated approach \nto test generation through such lexers. The key but only thing the user is required to specify is the \nname of the func\u00adtion hash (like hashfunct or possibly a hash-function wrapper like findsym in the example \nof Figure 4) whose calls are then tracked during symbolic execution and represented using an un\u00adinterpreted \nfunction exactly as described in Section 4. During ini\u00adtialization, all the pairs (hashvalue, hash(keyword))are \nbeing recorded to be included in the antecedent of post-processed path constraints. Whenever test generation \nneeds a speci.c symbol to drive the parser through a new speci.c program branch, the the\u00adory of equality \nwith uninterpreted functions combined with all the input-output value pairs recorded for hash makes it \npossible to effectively inverse this hash function for the .nitely many key\u00adwords of the input language, \nwhich is suf.cient for test generation for such applications. For instance, when an assignment statement \nof the form symbol = hash(inputChunk) is followed by a con\u00additional statement of the form if (symbol \n== 52) ..., observ\u00ading that hash( while ) = 52 is suf.cient for higher-order test generation to generate \nan inputChunk equal to while in order to exercise the then branch of the conditional statement. Note \nthat, in some lexers, hash values are pre-computed and hard-coded in the source code. Then, it is not \npossible to observe at execution time all relevant input-output value pairs for such hash functions at \nthe beginning of each execution. However, such input\u00adoutput pairs could still be learned over time by \nstarting the testing session with a representative set of well-formed inputs, observing the hash values \nof all the language keywords those inputs contain, and then using all pairs recorded in all previous \nexecutions in subsequent symbolic executions. We have performed preliminary experiments with higher-order \ntest generation in such a targeted manner in conjunction with the whitebox fuzzer SAGE [16] and using \nthe Z3 SMT solver [9]. Since Z3 does not support the generation of saturation-based proofs, these experiments \nwere conducted with an ad-hoc pre-processing step to eliminate uninterpreted functions in path constraints \nbefore calling Z3 for a satis.ability check as usual: (1) all uninterpreted func\u00adtion samples h(c1)= \nc2 are collected in a table IOF (where c1 and c2 denote constants), and then (2) whenever a constraint \nof the form h(x)= c2 occurs in a path constraint, it is replaced by a disjunction of constraints x = \nc1 for all c1 such that h(c1)= c2 (to handle hash collisions). This procedure is simple to implement \nbut handles only limited cases and is far from simulating the full reasoning power of T.TEUF . Nevertheless, \nexperiments with a simple parser including a lexer similar to Figure 4 show that this partial implementation \nof higher-order test generation is suf.cient to accurately drive program executions through the lexer. \nIn con\u00adtrast, regular dynamic test generation is no better than blackbox random testing because it is \nnot able to drive executions through tests involving the hash function in the lexer.  8. Other Related \nWork Abstracting program functions using uninterpreted functions is a well-known technique in veri.cation-condition \ngeneration for pro\u00adgram veri.cation of universal properties (e.g., [4]). In that context, the set of \nall program behaviors is over-approximated in presence of program-analysis imprecision, and veri.cation \nis established by checking the validity of a logic formula representing the entire pro\u00adgram (or module). \nUninterpreted function symbols in the formula are therefore implicitly universally quanti.ed as in our \nwork. In the context of test generation, uninterpreted functions have been used for representing symbolic \ntest summaries in composi\u00adtional symbolic execution [1, 17]. There, a function summary is represented \nby a .rst-order logic formula using an uninterpreted function symbol representing the function. A function \nsummary is de.ned as a disjunction (i.e., a set) of intraprocedural path con\u00adstraints expressed in terms \nof the function inputs and outputs. Func\u00adtion summaries can be computed incrementally, to include more \nand more intraprocedural path constraints as they are discovered during a directed search. Test generation \nwith function summaries is performed as usual by a satis.ability check, where all uninter\u00adpreted functions \nare therefore implicitly existentially quanti.ed. This use of uninterpreted functions for function summaries \nis thus different from their use in higher-order test generation where un\u00adinterpreted functions represent \nimprecision in symbolic execution in individual path constraints. Both types of uninterpreted func\u00adtions \ncould actually be used simultaneously, as they are orthogonal, for higher-order compositional test generation \n. Note that func\u00adtion summaries do not have to be represented using uninterpreted functions, and can \nbe encoded directly in propositional logic in\u00adstead [11]. We do not know of any other work where tests \nare derived from validity proofs, or where uninterpreted functions are used to model imprecision in symbolic \nexecution for test generation. The (implicit) alternation of universal function quanti.ers and existential \nvariable quanti.ers in our post-processed path con\u00adstraints can be viewed as a game between an unknown \nenviron\u00adment (controlling the unknown functions) and a test generator (controlling test inputs). To view \ntest generation as a game is not new [5, 25]. Model-driven test generation for conformance test\u00ading, \ni.e., checking whether a blackbox implementation conforms to a whitebox speci.cation, can be viewed as \na game and, under speci.c assumptions, can be encoded logically using quanti.er alternation, for instance \nusing Quanti.ed Boolean Formulas. How\u00adever, we are not aware of any work on model-based test generation \nusing uninterpreted functions or validity proofs of .rst-order logic formulas as in our work. Given a \nprogram and a set of input parameters, test genera\u00adtion refers to the problem of generating input tests \nin order to ex\u00adercise a speci.c program path, branch or statement. In contrast, static, dynamic and higher-order \ntest generation denote speci.c ap\u00adproaches to solving the test generation problem. Test generation is \nonly one way of proving existential reachability properties of pro\u00adgrams, where speci.c concrete input \nvalues are generated to exer\u00adcise speci.c program paths. More generally, such properties can be proved \nusing so-called must abstractions of programs, without nec\u00adessarily generating concrete tests. A must \nabstraction is de.ned as a program abstraction that preserves existential reachability proper\u00adties of \nthe program. For instance, in predicate abstraction [13, 17], a must transition from an abstract state \nA1 to an abstract state A2 implies that .c1 .A1 : .c2 .A2 : c1 .c2 that is, for every concrete state \nc1 abstracted by A1, there exists a program execution from c1 to a concrete state c2 such that c2 is \nabstracted by A2. Must transitions can be chained together to prove existential reachability properties \nof programs, i.e., .nd bugs in a sound manner. Sound path constraints are particular cases of must abstractions \n[17]. Note the analogy between the alternation of universal and existential quanti.ers in the de.nition \nof must transition and in our post-processed path constraints. Other related work includes [8, 18] where \nmust abstractions are built backwards from error states using static program analy\u00adsis. This approach \ncan detect program locations and states prov\u00adably leading to error states (no false alarms), but may \nfail to prove reachability of those error states back from whole-program initial states, and hence may \nmiss bugs or report unreachable error states. Imprecision in symbolic reasoning, e.g., due to system \ncalls or un\u00adknown functions, is modeled by assigning nondeterministic values to all possible modi.ed \n(output) variables, which is less precise than using uninterpreted functions yet still assumes all unknown \nfunctions have known sets of possible outputs/side-effects. Build\u00ading must abstractions statically can \nbe fast but requires symbolic reasoning about the whole program. On the other hand, dynamic test generation \nis slower but more precise by allowing symbolic ex\u00adecution to degrade gracefully using concrete runtime \nvalues when\u00adever symbolic reasoning is dif.cult.  Static test generation can be extended to concretize \nsymbolic values whenever static symbolic execution becomes imprecise [19]. This approach not only requires \nto detect all sources of imprecision, but also one call to the constraint solver for each concretization \nto ensure that every synthesized concrete value satis.es prior sym\u00adbolic constraints along the current \nprogram path. For the reasons discussed in Section 6, such requirements are not practical for large applications. \nIn contrast, dynamic test generation avoids these two limitations by leveraging a speci.c concrete execution \nas an auto\u00admatic fall back for symbolic execution [15]. Dynamic test generation is currently an active \narea of research and many other extensions and applications have been proposed, such as [2, 6, 10, 23, \n24] to name just a few (see [7] for a recent survey). This other related work does not speci.cally focus \non how to deal with imprecision in symbolic execution and could bene.t from the techniques introduced \nin our work.  9. Conclusion We presented higher-order test generation, a powerful new form of test generation, \nwhich can also be expensive as it requires tracking explicitly sources of imprecision in symbolic execution, \nusing un\u00adinterpreted functions, recording input-output function samples, and checking validity of .rst-order \nlogic formulas. We showed how this approach can perform novel forms of test generation, such as multi\u00adstep \ntest generation, and drive the executions of input parsers with lexers using hash functions for fast \nkeyword recognition. We also showed that the key property of dynamic test genera\u00adtion that makes it more \npowerful than static test generation is only its ability to observe concrete values and to record those \nin path constraints. In contrast, the process of simplifying complex sym\u00adbolic expressions using concrete \nruntime values can be accurately simulated using uninterpreted functions. However, those concrete values \nare necessary to effectively compute new input vectors, a fundamental requirement in test generation. \nAcknowledgments. I thank Leonardo de Moura for several insight\u00adful discussions related to this work. \nI also thank Nikolaj Bjorner, Yuri Gurevich and Mihalis Yannakakis for helpful comments, and Andreas \nPodelski and the anonymous reviewers for their construc\u00adtive comments to improve the presentation.  \nReferences [1] S. Anand, P. Godefroid, and N. Tillmann. Demand-Driven Compo\u00adsitional Symbolic Execution. \nIn Proceedings of TACAS 2008,vol\u00adume 4963 of Lecture Notes in Computer Science, pages 367 381, Bu\u00addapest, \nApril 2008. Springer-Verlag. [2] S. Artzi, A. Kiezun, J. Dolby, F. Tip, D. Dig, A. M. Paradkar, and M. \nD. Ernst. Finding Bugs in Web Applications Using Dynamic Test Generation and Explicit-State Model Checking. \nIEEE Trans. Software Eng., 36(4):474 494, 2010. [3] L. Bachmair and H. Ganzinger. Resolution Theorem \nProving. In Handbook of Automated Reasoning, pages 19 99. 2001. [4] M. Barnett, B. E. Chang, R. DeLine, \nB. Jacobs, and K. R. M. Leino. Boogie: A modular reusable veri.er for object-oriented programs. In Proceedings \nof FMCO 2005, volume 4111 of Lecture Notes in Computer Science, pages 364 387. Springer-Verlag, September \n2006. [5] A. Blass, Y. Gurevich, L. Nachmanson, and M. Veanes. Play to Test. In Proceedings of FATES \n2005, Edinburgh, July 2005. [6] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill, and D. R. Engler. EXE: \nAutomatically Generating Inputs of Death. In ACM CCS, 2006. [7] C. Cadar, P. Godefroid, S. Khurshid, \nC.S. Pasareanu, K. Sen, N. Till\u00admann, and W. Visser. Symbolic Execution for Software Testing in Practice \n Preliminary Assessment. In Proceedings of ICSE 2011, Honolulu, May 2011. [8] S. Chandra, S. J. Fink, \nand M. Sridharan. Snugglebug: A Powerful Approach to Weakest Preconditions. In Proceedings of PLDI 2009, \nDublin, June 2009. [9] L. de Moura and N. Bjorner. Z3: An Ef.cient SMT Solver. In Pro\u00adceedings of TACAS \n2008, volume 4963 of Lecture Notes in Computer Science, pages 337 340, Budapest, April 2008. Springer-Verlag. \n[10] M. Emmi, R. Majumdar, and K. Sen. Dynamic Test Input Generation for Database Applications. In Proceedings \nof ISSTA 2007, pages 151 162, 2007. [11] P. Godefroid. Compositional Dynamic Test Generation. In Proceed\u00adings \nof POPL 2007, pages 47 54, Nice, January 2007. [12] P. Godefroid. Software Model Checking Improving Security \nof a Billion Computers. In Proceedings of SPIN 2009, volume 5578 of Lecture Notes in Computer Science, \npage 1, Grenoble, June 2009. Springer-Verlag. [13] P. Godefroid, M. Huth, and R. Jagadeesan. Abstraction-based \nModel Checking using Modal Transition Systems. In Proceedings of CON\u00adCUR 2001, volume 2154 of Lecture \nNotes in Computer Science, pages 426 440, Aalborg, August 2001. Springer-Verlag. [14] P. Godefroid, A. \nKiezun, and M. Y. Levin. Grammar-based Whitebox Fuzzing. In Proceedings of PLDI 2008, pages 206 215, \nTucson, June 2008. [15] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed Automated Random Testing. \nIn Proceedings of PLDI 2005, pages 213 223, Chicago, June 2005. [16] P. Godefroid, M.Y. Levin, and D. \nMolnar. Automated Whitebox Fuzz Testing. In Proceedings of NDSS 2008, pages 151 166, San Diego, February \n2008. [17] P. Godefroid, A.V. Nori, S.K. Rajamani, and S.D. Tetali. Composi\u00adtional May-Must Program Analysis: \nUnleashing The Power of Alter\u00adnation. In Proceedings of POPL 2010, pages 43 55, Madrid, January 2010. \n[18] J. Hoenicke, K. R. M. Leino, A. Podelski, M. Schaf, and Th. Wies. It s doomed; we can prove it. \nIn Proceedings of 2009 World Congress on Formal Methods, 2009. [19] Sarfraz Khurshid, Corina S. P.as.areanu, \nand Willem Visser. General\u00adized Symbolic Execution for Model Checking and Testing. In Pro\u00adceeding of \nTACAS 2003, April 2003. [20] J. C. King. Symbolic Execution and Program Testing. Journal of the ACM, \n19(7):385 394, 1976. [21] B. Korel. A Dynamic Approach of Test Data Generation. In IEEE Conference on \nSoftware Maintenance, pages 311 317, San Diego, November 1990. [22] D. Molnar, X. C. Li, and D. Wagner. \nDynamic test generation to .nd integer bugs in x86 binary linux programs. In Proc. of the 18th Usenix \nSecurity Symposium, Aug 2009. [23] P. Saxena, D. Akhawe, S. Hanna, F. Mao, S. McCamant, and D. Song. \nA Symbolic Execution Framework for JavaScript. In IEEE Symposium on Security and Privacy, pages 513 528, \n2010. [24] N. Tillmann and J. de Halleux. Pex -White Box Test Generation for .NET. In Proceedings of \nTAP 2008, volume 4966 of Lecture Notes in Computer Science, pages 134 153. Springer-Verlag, April 2008. \n[25] M. Yannakakis. Testing, Optimization, and Games. In Proceedings of LICS 2004, pages 78 88, Turku, \nJuly 2004.  / * addsym - add symbol and definitions to symbol table * *-1 is returned if the symbol \nalready exists , and the change not made. */ def , int def , table , table  size ) register char sym[]; \nchar * str static int addsym (sym, str  def ; int int   def ; hash   table table ; int table  \n size ; {  val = hashfunct (sym, table size ); register struct hash entry *sym entry = table [ hash \nval ]; register struct hash int hash entry *new entry ; register struct hash  entry * successor ; \n while ( sym entry ) {if (!strcmp (sym, sym entry->name )) { / * entry already exists */ return -1; } \nsym entry = sym entry->next ; } / * create new entry */ new entry = ( struct hash entry *) flex  alloc \n(sizeof (struct hash entry )); if ( new entry == NULL) flexfatal (  ( symbol table memory allocation \nfailed )); if (( successor = table [ hash val ]) != 0) { new entry->next = successor ; successor ->prev \n= new  entry ; } else new entry->next = NULL;  entry->prev = NULL; new entry->name = sym; new entry->str \nval = str new def ; new entry->int val = int def ; table [ hash val ] = new entry ; return 0; } / \n* findsym - find symbol in symbol table */ entry *findsym (sym, table , table  size ) register const \nchar *sym ; hash static struct hash table table ; int table  size ; { static struct hash entry empty \nentry = {(struct hash entry *)0, ( struct hash  entry *)0, (char *) 0, (char *)0,0, }; register struct \nhash entry *sym entry = table[hashfunct (sym, table size )]; while ( sym entry ) { if (!strcmp (sym, \nsym entry->name )) return sym  entry ; sym entry = sym entry->next ; } return &#38;empty entry ; } \n Figure 4. Code excerpt from the .ex lexer (.le sym.c, .ex-2.5.35, February 2008).  \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Symbolic reasoning about large programs is bound to be imprecise. How to deal with this imprecision is a fundamental problem in program analysis. Imprecision forces approximation. Traditional static program verification builds \"may\" over-approximations of the program behaviors to check universal \"for-all-paths\" properties, while automatic test generation requires \"must\" under-approximations to check existential \"for-some-path\" properties.</p> <p>In this paper, we introduce a new approach to test generation where tests are derived from <i>validity proofs</i> of first-order logic formulas, rather than <i>satisfying assignments</i> of quantifier-free first-order logic formulas as usual. Two key ingredients of this <i>higher-order test generation</i> are to (1) represent complex/unknown program functions/instructions causing imprecision in symbolic execution by <i>uninterpreted functions</i>, and (2) record <i>uninterpreted function samples</i> capturing input-output pairs observed at execution time for those functions. We show that higher-order test generation generalizes and is more precise than simplifying complex symbolic expressions using their concrete runtime values. We present several program examples where our approach can exercise program paths and find bugs missed by previous techniques. We discuss the implementability and applications of this approach. We also explain in what sense dynamic test generation is more powerful than static test generation.</p>", "authors": [{"name": "Patrice Godefroid", "author_profile_id": "81100504535", "affiliation": "Microsoft Research, Redmond, USA", "person_id": "P2690556", "email_address": "pg@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993529", "year": "2011", "article_id": "1993529", "conference": "PLDI", "title": "Higher-order test generation", "url": "http://dl.acm.org/citation.cfm?id=1993529"}