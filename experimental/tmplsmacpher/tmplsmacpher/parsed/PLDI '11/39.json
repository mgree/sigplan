{"article_publication_date": "06-04-2011", "fulltext": "\n Kremlin: Rethinking and Rebooting gprof for the Multicore Age Saturnino Garcia,Donghwan Jeon, Chris \nLouie, andMichaelBedfordTaylor Department of Computer Science&#38; Engineering University of California, \nSanDiego La Jolla,CA, USA {sat,djeon,cmlouie,mbtaylor}@cs.ucsd.edu Abstract Manyrecent parallelization \ntools lower the barrier for parallelizing a program, but overlook one of the .rst questions that a program\u00admer \nneeds to answer: which parts of the program should I spend time parallelizing? This paper examines Kremlin, \nan automatic tool that, given a serial version of a program, will make recommendations to the user as \nto what regions (e.g. loops or functions) of the program to attack .rst. Kremlin introduces a novel hierarchical \ncritical path analysis and develops a new metric for estimating the potential of parallelizing a region: \nself-parallelism.We further introduce the concept of a parallelism planner, which provides a ranked order \nof speci.c regions to the programmer that are likely to have the largest performance impact when parallelized. \nKremlin supports multiple planner personalities, which allow the planner to more effectively target a \nparticular programming environment or class of machine. We demonstrate the effectiveness of one such \npersonality, an OpenMP planner, by comparing versions of programs that are par\u00adallelized according to \nKremlin s plan against third-party manually parallelized versions. The results show that Kremlin s OpenMP \nplanner is highly effective, producing plans whose performance is typically comparable to, and sometimes \nmuch better than, manual parallelization. At the same time, these plans would require that the user parallelize \nsigni.cantly fewer regions of the program. Categories and Subject Descriptors D.2.2[Software Engineer\u00ading]: \nDesign Tools and Techniques; D.1.3 [Programming Tech\u00adniques]: ConcurrentProgramming ParallelProgramming \nGeneralTerms Measurement,Performance Keywords Hierarchical Critical Path Analysis, Self-Parallelism, \nParallelismPlanner,Parallel Software Engineering 1. Introduction The emergence of multicore processors \nhas profoundly impacted the way in which future software performance gains will be achieved. In order \nto take advantage of the resources available in Permission to make digital or hard copies of all or part \nof this work for personal or classroomuseisgrantedwithout feeprovidedthat copies arenot madeordistributed \nforpro.torcommercialadvantage andthatcopiesbearthisnoticeandthefullcitation onthe .rstpage.To copy otherwise,torepublish,topostonserversortoredistribute \ntolists,requirespriorspeci.cpermission and/ora fee. PLDI 11, June4 8,2011, SanJose, California,USA. Copyright \nc &#38;#169; 2011ACM978-1-4503-0663-8/11/06. . .$10.00 Figure 1. A Taxonomy of Parallelization Tools. \nThe taxonomy categorizes parallelization tools based on which of .ve fundamen\u00adtal parallelization stages \ntheyassist with. Automatically paralleliz\u00ading compilers like Polaris [7] and SUIF [12] attempt to perform \nall .ve without programmer assistance, while tools like OpenMP, Cilk++ [27], and X10 [33] focus on the \nlast two. The paper s tool, Kremlin, targets the .rst two stages. multicore processors, existing sequential \nsoftware will need to be refactored for parallel execution. The task of parallelizing software has proved \nto be extremely dif.cult. To address this dif.culty, recent mainstream tools have largely emphasized \nthe easeofexpressing parallelism; languageex\u00adtensions such as OpenMPand Cilk++ [27] have greatly reduced \nthe effort involved in expressing opportunities for parallel execution in a program. Other tools guide \nthe programmer in debugging perfor\u00admance or correctness problems in their parallelized code [4, 14, 35]. \nWhile these tools increase the ef.ciency of parallel programmers, there is still a need to assist the \nearlier stages of parallelization, whereprogrammers must decidehowtotransforma serialprogram. Theprogrammerrequiresnew \ntoolsfor these earlier stagesofparal\u00adlelization that will complement existing tools and form a complete \ntool.ow for parallelization. This paper examines Kremlin, a new tool that, given a serial version of \na program, answers the question: which parts of the program shouldI parallelize .rst? This question is \nnot altogether unlike the question that gprof attempts to answer for serial programs: which parts of \nthe program should I try to optimize .rst? In this paper, we rethink the design of a gprof-like tool \nthat applies to the parallelization of serial pro\u00adgrams rather than their serial optimization. Although \nthe motiva\u00adtion, goals, and user interface are quite similar to gprof, we .nd that pursuing parallelism \nrequires a new approach that is quite dif\u00adferent, and leads to a tool whose underlying architecture is \na total reboot, as it were, of the underlying architecture of a serial perfor\u00admance pro.ler like gprof. \n ATaxonomy ofParallelization Stages To explainKremlin s role in the spectrum of parallelization tools, \nwe introduce a taxonomy that describes the basic stages involved in parallelizing a program. Figure 1 \nshows this taxonomy. Parallelization begins with Paral\u00adlelism Discovery, which is the process of identifying \nregions of a program that have exploitable parallelism. Locating these regions of the program is especially \nonerous for large, complex programs or when as is often the case the parallel programmer is not the original \nauthor of the program. The next stage, Parallelism Plan\u00adning, determines which subset of these regions \nshould be paral-lelized.Ideally, this planwouldfactorin important constraints such as the number of cores \navailable and the system s ability to support different types of parallelism. The third step is Enabling \nTrans\u00adforms. These are source-level transformations that the user per\u00adforms in order to enhance the parallelizability \nof the code used in subsequent stages. The parallelization process concludes with the .nal two steps \nof Parallel Code Generation, where parallel or threaded code is generated, and RuntimeManagement, wherearun\u00adtime \nsystem tries to optimize the ef.ciencyof parallel execution. As shown in Figure 1, automatic parallelizing \ncompilers such as Polaris [7],RawCC [26], and SUIF[12] seek to automate all of the stages in the parallelization \ntaxonomy. Although theyeliminate the need for manual intervention, the performance of code generated \nby these compilers often pales in comparison with code generated manually. This lack of performance stems \nfrom the dif.culty of manyof these steps; in manycases, the compiler cannot effectively perform them \nwithout the bene.t of runtime information or without otherwise unsound semantic changes by the user. \nWhile additional information could potentially improve performance, accomplishing this integration has \nproven a dif.cult problem. Without this addi\u00adtional input, parallelizing compilers have an all-or-nothing \nfeel: the compiler either does all of the work or none of it. An alternative to the fully-automated approach \nis to separate the parallelization process into the stages shown in Figure1 and make use of parallel \nprogramming tools to automate as much of the work as possible. These tools would relieve most of the \nburden on the programmer and allow them to focus on the Enabling Transforms stage where automated tools \nare most limited1. Recent tools such as OpenMP, Cilk++ [27], X10 [33], andFastTrack [17]exemplify how \nuser-centered tools can improve the productivity of parallel programmers. These tools provide extensions \nto standardized lan\u00adguages that allow a programmer to explicitly specify parallel re\u00adgions and synchronization \npoints, automatically handling the .nal two stages of parallelization. However, by the time a programmer \ncan utilize these tools, they must have already performed the initial stages of parallelization without \nassistance. Kremlin We have developedKremlin to aid programmers in both the parallelism discovery and \nparallelism planning stages of par\u00adallelization. Kremlin s parallelism discovery phase utilizes criti\u00adcal \npath analysis [23], or CPA, to quantify the amount of innate parallelism that exists in a piece of code. \nKremlin extends tra\u00additional critical path analysis by automatically incorporating the nested structure \nof the program s regions (e.g. loops and functions) into its analysis. Kremlin s hierarchical critical \npath analysis, or HCPA, performs critical path analysis across many nested regions 1Nonetheless, some \nresearchers have developed tools which help perform speci.crefactoring tasksin the EnablingTransformsstage[10, \n40]. in a program. By comparing the amount of parallelism that exists in each parent region to the amount \nthat exists in its children, we are able to localize parallelism to speci.c regions of the program, revealing \nthe amount of parallelism in each code region. To accomplish this, Kremlin introduces a new metric, self\u00adparallelism, \nwhich given a parent region, can factor out the par\u00adallelism of subregions, much like gprof s self-time \nmetric factors out the time spent in subregions. Our results show that HCPA is highly effective in identifying \nthose code regions that are prime candidates for parallelization. In addition to its support for parallelism \ndiscovery,Kremlin per\u00adforms parallelism planning by incorporating hierarchical data from parallelism \ndiscovery as well as additional constraints. The plan\u00adner supports the concept of planning personalities, \nwhich incorpo\u00adrates the impact of parallelization system (e.g. OpenMP) and ma\u00adchine properties. As an \nexample of one such personality, Kremlin includes an OpenMP planner which has been validated on a multi\u00adcore \nsystem with 32 cores. Our results, acquired by applying Kremlin to serial versions of the NAS Parallel \nBenchmark Suite [6], and all of the C-language Spec OMP2001 [2] benchmarks, show that our approach is \nquite effective. Kremlin s recommendations, which required no manual intervention, and relied only on \ninformation extracted from the se\u00adrial version of the program, comprise only 3.0% of the original pro\u00adgrams \nregion count.Comparingtoa3rd-partyparallelizedversion, Kremlin required 1.57\u00d7 fewer regions to be parallelized. \nIn cases where therecommended parallelization planwas similar,Kremlin s performance averaged within 3.8% \nof manual parallelization, close enough that applying the saved time to serial optimization would likelyproducea \nbetter outcome.In cases whereKremlin s planwas signi.cantly different, Kremlin s plan exceeded the manual \nplan s performance by 85%. To summarize, this paper makes the following contributions: We introduce \nthe technique of hierarchical critical path analy\u00adsis. Traditional critical path analysis techniques \nare unable to localize parallelism to speci.c code regions, which is a funda\u00admental limitation that prevents \nits widespread use in practical end-programmer tools. Unlike dependence-testing approaches that focus \non loop bodies, HCPA allows parallelism in serial program regions to be identi.ed even if the program \ns current form (e.g. loop nesting structure) does not expose it, which can reveal opportunities where \nnon-intuitive code restructuring can yield large bene.ts.  We introduce a new metric, self-parallelism, \nwhich is the criti\u00adcal step inextendingCPA toHCPA. Self-parallelism is able to quantify the parallelism \nof a parent region independent of its children. We show that high self-parallelism is well-correlated \nwith achieving real parallel speedup. This metric is analogous to self-time in the gprof pro.ling tool. \n We develop the concept of a parallelism planner as a key step in the manual parallelization process; \nthat is to say, because of the complexity of the task, we believe pro.lers for parallel programming should \nnot only provide self-parallelism, work, and other information about program regions but also combine \nthese factors with Amdahl s Law and target system properties to estimate which regions are worth pursuing. \n We introduce the concept of planning personalities that tai\u00adlor the planning process based on the target \nsystem and lan\u00adguage. We describe in detail one such personality, a planner for a multicore processor \nusing OpenMP. Combined with par\u00adallelism planners, thisisapracticalwayofbridging thegap be\u00adtween abstract \nCPA analysis and realistic constraints of today s execution environments.   We demonstrate Kremlin \ns OpenMP planner s ability to pro\u00adduce concise plans whose performance is typically comparable to and \nsometimes far exceeds manual parallelization that required many trial-and-error iterations and was able \nto take advantage of post-parallelization measurements. At the same time, these plans would require that \nthe user parallelize signi.\u00adcantly fewer regions of the program. The rest of this paper is organized \nas follows. Section 2 mo\u00adtivates the need for improved parallelism discovery and planning tools, and \nformalizes these concepts. Section3presentsa high-level overview ofKremlin. Sections4and5describe the \nimplementation of the pro.ling and planning aspects ofKremlin. Section6demon\u00adstrates the capabilities \nofKremlin in identifying parallelism as well as creating an effective parallelization plan. Related work \nis de\u00adtailedin Section7, and Section8 concludes.  2. ExaminingParallelismDiscovery and Planning In this \nsection we will .rst motivate the need for tools that discover and plan for parallelism. We then discuss \nthe challenge of quanti\u00adfying parallelism in speci.c parts of a program. Finally, we de.ne the problem \nof parallelism planning informally and then formally. 2.1 Motivation Despite recent research into parallel \nprogramming tools, manypro\u00adgrammers still rely on a relatively painful methodology that em\u00adploys serial \npro.ling tools such as gprof in order to direct their parallelization activities. The process starts \nwith a serial hotspot list, which ranks regions by the amount of time spent inside them. This list effectively \nbecomes the order that they examine the func\u00adtions to improve their performance. It is at this point \nthat the process gets especially onerous. The programmer starts lea.ng through the code trying to puzzle \nthrough the dependencies in the code, and the granularity at which to try to exploit it. Since the programmer \nhas no indication of whether a hotspot is parallelizable, they frequently give up before they are able \ntorecognize subtlebut large parallelism opportunities, or they spend excessive amounts of time fruitlessly \nmodifying serial parts of the code. Alternatively, even if parallelism does exist, it may not be large \nenough to yield speedup, or when combined with lower coverage, the overall speedup may not justify the \neffort. Finally, interference between nested parallel regions may prevent speedup. Our experience watching \ngraduate students struggle to paral\u00adlelize serial code led us to realize that the inability to quantify \nparal\u00adlelism in these program regions was indirectly responsible for large amounts of wasted time. To \nour surprise, providing them with a tool that quanti.es parallelismwas not quite enough.Rather, paral\u00adlelization \nalso requires planning tools that help process this infor\u00admation and apply both parallel programming \nsystem and machine constraints. With the ability to positively identify the existence of parallelism,andalsotoprioritizeregions, \nuserscaninvest theirtime more productively, attacking the correct portions of the program.  2.2 QuantifyingParallelism \nAmdahl s Law provides guidance to the programmer by de.ning the basic relationship between parallelizability \nand speedup. Ac\u00adcording to this law, two factors directly impact speedup: the per\u00adcentage of time spent \nin a section of code and the amount of paral\u00adlelism within that code. While gprof and similar tools offer \nready\u00admade solutions for determining the work coverage, quantifying par\u00adallelism requires additional \ntools and techniques. Promise of Critical Path Analysis Approaches One promising approach for quantifying \nparallelism is to use a critical path analy\u00adsis [23], or CPA. CPA is a dynamic analysis that .nds the \nstring of for(i=win..rows-win) { for(j=win..cols-win) { currLambda = lambda[i][j]; ... for(k=0..nFeatures) \n{ if(features[2][k] < currLambda) { ... features[0][k] = j; features[1][k] = i; features[2][k] = currLambda; \n} }}} Figure 2. Localizing Parallelism. In this nested loop from the .llFeatures function in feature \ntracking, only the innermost loop (overk)is parallel.TraditionalCPA would erroneouslyreport par\u00adallelism \nin the outer loops because theycontain the innermost. dependencies that forms a lower bound on the execution \ntime (the critical path) of a piece of code. The critical path in turn creates an approximate upper bound \non the parallelism available, with the ideal parallel implementation performing all non-critical operations \nin parallel with the critical path operations. The work and critical path de.ne the average amount of \nparallelism available according to the equation p = work/lengthcp. We refer to parallelism cal\u00adculated \nwith this equation as the total-parallelism. The basicpremise behindKremlinand otherparallelism discov\u00aderytools \nthat employ critical path analysis [5, 21 23]is to evaluate the application s potential for parallelization \nunder relatively opti\u00admistic assumptions based on observation of the program s dynamic execution.Most \nparallelizing compilers,in contrast, must takerel\u00adatively pessimistic views because they are responsible \nfor guaran\u00adteeing correctness. For example, parallelizing compilers may not be able to prove that two \npointers do not alias, while a critical path analysis will at least report that it did not observe such \ndependen\u00adcies in the actual execution of the program. The basic idea is to elevate to the user awareness \nof the at least circumstantial evidence of parallelism in the program, so that users can apply their \nunder\u00adstanding of the real application constraints (as opposed to what is encoded in program source) \nand refactor to exploit the parallelism. CriticalPathAnalysis sInability toLocalizeParallelism Unfor\u00adtunately, \ntraditional critical path analysis has not found widespread use as a parallelism quanti.cation tool for \nparallel programmers because it has one important limitation: it cannot localize the par\u00adallelism to \na particular level of the nested hierarchy of a program s regions. This limitationis illustratedbya code \nsnippetfrom the fea\u00adture tracking benchmark from the San Diego Vision Benchmark Suite [20], shown in \nFigure 2. In this example, only the innermost loopisparallel.TraditionalCPA wouldonly detect thatparallelism \nexists somewhere among the three loops, not just the innermost. Localizing Parallelism to Speci.c Regions \nKremlin avoids the aforementioned limitation through two novel contributions: hier\u00adarchical critical \npath analysis and a new metric, self-parallelism. Hierarchical critical path analysis calculates the \namount of paral\u00adlelism within every nested region in a program. Self-parallelism uses this hierarchical \ndata to factor out the parallelism contributed by a region s subregions, much like gprof s self-time \nmetric fac\u00adtors out the time spent in a region s subregions. These two features combinetohelpKremlin \nlocalizeparallelismto speci.cregionsof aprogram. Section4 will de.ne andexplore them more formally. What \nIs a Region? Kremlin uses the concept of a region to denote a region of code whose parallelism is to \nbe measured from the time that region is entered until the time it is exited. In order for the self-parallelism \nmetric to work, regions must obey a proper nesting structure: regions must not partially overlap, but \nthey may nest or be siblings with the same parent region. Based on this nesting structure, we can de.ne \na dynamic region graph which shows the relationship between parent and children regions in the dynamic \nexecution of the program.  Although more arbitrary delineations of regions are possible, Kremlin places \nregions around all loops and functions, since they tend to correspond well to constructs that users understand \nwell and relate more directly to the process of parallelization.  2.3 CreatingaParallelism Plan Informally, \nparallelism planning is the problem of producing a se\u00adquence of program regions for the programmer to \nparallelize, or\u00addered according to their expected impact on program execution. While the self-parallelism \nand self-time metrics improve our abil\u00adity to create an effective parallelism plan, factors outside of \nwork coverage and parallelism will also impact planning. One such con\u00adstraint is the risk of over-parallelizing \nthe program: since parallel execution often incurs some overhead in terms of work and/or re\u00adsource contention, \nexpressing more parallelism than there are cores availabletoexploit canresultinslowdown.For instance,we \nfound thatin OpenMP, on ourexperimental setup,itwas seldompro.table to parallelize a child region of \na region that had already been paral\u00adlelized. Another constraint is that synchronization and data move\u00adment \ncosts in the system often affect the smallest parallel region that can attain speedup. We now formally \nde.ne the problem of parallelism planning so that we may later solve it algorithmically. Let RP be the \nset of parallelizable regions in a program P . A parallelism plan creates an ordering on this set such \nthat the relation de.ning the ordering, <, is true for A<B if A should be parallelized before B. A set \nof constraints, C, will help to de.ne the ordering on RP . Examples of these constraints range from architecture-speci.c \nconstraints (e.g. the number of cores available), to language\u00adspeci.c constraints (e.g. inability to \nexpress pipeline parallelism in OpenMP), and even human factors (e.g. the desire to achieve large speedups \nas soon as possible). These constraints are com\u00adbined to form a personality for the planner. A planner \npersonality may range from detailed (e.g. .ne-grained parallelism on a 100\u00adcore Tilera machine) to general \n(e.g. coarse-grained parallelism), depending on the goal of the user;detailed planners will have better \nperformance on targeted systems while broader personalities will have more robust performance across \na broader range of machines. 2.4 Limitations ofKremlin and Other Pro.le-BasedTools Needless to say, \nKremlin is naturally affected by the same limi\u00adtations that apply to other pro.ling tools, like gprof, \nthat make use of dynamic information that is input-dependent and does not necessarily predict the program \ns execution with other inputs. Our experience in varying inputs suggests that in many cases, the addi\u00adtional \ninformationgainedby dynamic analysis outweighsthedraw\u00adbacks. Further,Kremlin supports aggregation of \ndata from multiple runs, which reduces these risks. Another limitation is that Krem\u00adlin cannot predict \nthe enhanced parallelism that might be attained by changing algorithms, although a report of low parallelism \nmay surprise the user into realizing theyneed a more parallel algorithm. CPA-based tools can also be \nlimited by unnecessary dependen\u00adcies that are still true dependencies. Although no tool can handle all \nsuch cases, Kremlin handles many common cases by breaking such dependencies via induction and reduction \nvariable analysis.  3. Kremlin Overview In this section, we overview Kremlin s user interface and its \nhigh\u00adlevel system architecture. As shown in Figures 3 and 4, Kremlin takes in unmodi.ed source code and \nproduces an instrumented bi\u00adnary. The user executes this binary as they would the uninstru\u00admented program. \nThis binary produces a parallelism pro.le that $> make CC=kremlin-cc $> ./tracking data $> kremlin tracking \n--personality=openmp File (lines) Self-P Cov.(%) 1 imageBlur.c (49-58) 145.3 9.7 2 imageBlur.c (37-45) \n145.3 8.7 3 getInterpPatch.c (26-35) 25.3 8.86 4 calcSobel dX.c (59-68) 126.2 8.1 5 calcSobel dX.c (46-55) \n126.2 8.1 ... ... ... ... Figure 3. Kremlin s User Interface. After compiling and exe\u00adcuting the program,Kremlin \nproduces an ordered parallelism plan based on the selected planner personality. Regions are ordered by \ntheir estimated program speedup. In addition to location, Kremlin displays the average amount of region-speci.c \nparallelism (self\u00adparallelism) and theexecution coverage.Results shown are for the feature tracking benchmark \n[20]. Kremlin s parallelism planner uses, along with the speci.ed plan\u00adner personality, to produce a \nparallelism plan. Figure3also shows the parallelism plan for the feature tracking benchmark as it would \nbe displayed to the user. The plan presents an ordered list of regions for the programmer to parallelize \nalong with the self-parallelism and work coverage of those regions. Kremlin sorts the list according \nto decreasing whole-program po\u00adtential speedup. The list contains only those regions that are ex\u00adpected \nto meet a minimum speedup threshold; the programmer can expect to obtain nearly all the performance bene.ts \npossible if they parallelize all the regions in the list. Once the programmer has the plan, the basic \nusage model is that theyvisit these regions of code in the speci.ed order and determine how to expose \nthe underlying parallelism that was detected by Kremlin.Intheeventthatthe useris unableor unwillingtoexploit \nthe parallelism in a region, they can rerun the planner with a list of excluded regions and receive an \nupdated plan. The results in this paper were generated without using the exclusion list feature. Having \nexplained the user s view of the tool, we now examine theKremlin System Architecture, shown in Figure \n4. Static Instrumentation Kremlin s discovery components are split into two instrumentation steps: critical \npath instrumentation andregion instrumentation. The .rst step helps quantify parallelism via critical \npath analysis while the second step helps uncover the program s structure and localize parallelism to \nspeci.c regions. Both stages of the discovery phase utilize LLVM s [25] static instrumentation infrastructure. \nStatic instrumentation has two im\u00adportant bene.ts over dynamic instrumentation. First, it allows for \na deeper analysis of the program since the full program source is available. In our experience, tasks \nsuch as identifying induction variables, reduction variables, and region boundaries are challeng\u00ading \nin dynamic infrastructures such as Valgrind [30] but are easy when performed statically. Second, by statically \ninserting instru\u00admentation, Kremlin can heavily optimize the code to produce a more ef.cient instrumented \nbinary. This helps to lower the over\u00adhead associated with the heavyweight analysis infrastructure re\u00adquired \nfor hierarchical critical path analysis.Kremlin performs this optimization after instrumentation occurs \nso that it does not taint the analysis. During the critical path and region instrumentation stages, Kremlin \ninserts calls to instrumentation functions that calculate the critical paths of the program and track \nregion entries and ex\u00adits. These instrumentation functions are implemented inside the  Source Code Ordered \nParallelism Plan  Figure 4. Overview of Kremlin System Architecture. Starting with a program s source \ncode, Kremlin statically instruments the code to insert the proper pro.ling code and extract the region \nstruc\u00adture (i.e.regiongraph)from theprogram.Running the instrumented binary produces a parallelism pro.le \nfor each of the program re\u00adgions. Combined with the region graph, the parallelism pro.le is used by the \nparallelism planner to provide the user with a speci.c list of regions to parallelize (the parallelism \nplan). KremLib library. Section 4 provides more details on Kremlin s hierarchical critical path analysis. \nLinking and Execution Kremlin next links in the KremLib in\u00adstrumentation library to produce the instrumented \nbinary. When run, the instrumented binaryalsoproducesa parallelismpro.le out\u00adput .le in addition to its \nnormal outputs that contains parallelism information for each dynamic instance of a program region. Since \nregions in a program may be executed many times, Kremlin per\u00adforms an online, dictionary-based compression \nto greatly reduce the size of the parallelism pro.le. Kremlin Planner With the parallelism pro.le and \nregion graph produced by the discovery phase, Kremlin can begin to create an effective plan to utilize \nthe parallelism in the program. To begin, Kremlin combines the pro.le data with the region graph informa\u00adtion \nto calculate, among other things, the self-parallelism and work metrics for regions in the program, as \ndescribed in Section 4.3. After calculating the self-parallelism for each region, Kremlin designs an \nordered plan for the programmer that describes which regions should be parallelized. Kremlin uses both \ncoverage and self-parallelism to estimate the speedup associated with paralleliz\u00ading speci.c regions, \nusing this speedup information to order the regions. Kremlin uses planning personalities that incorporate \nboth target-(e.g. OpenMP)and machine-speci.c parameters in order to improve accuracy; detailed discussion \nresides in Section 5.  4. ParallelismDiscovery As we discussed earlier, traditional critical path analysis \nis poor at localizing parallelism to speci.c code regions. The following subsections describe how Kremlin \nperforms an enhanced form of analysis, hierarchical critical path analysis, and how our new self\u00adparallelism \nmetric is calculated. They also describe a compression technique that reduces the resource requirements \nof the system. 4.1 CriticalPath Analysis This section describes aspects of hierarchical critical path \nanaly\u00adsis, including how Kremlin calculates critical path lengths using shadow memory and how it handles \nboth false dependencies and control dependencies. Calculating CriticalPathLengthWith ShadowMemory Critical \npath analysis calculates parallelism by quantifying both the amount of workdone and the minimum time \nneeded to do that work(i.e. the cp(R)\u00a0=\u00a0cpi cp(R)\u00a0=\u00a0n\u00a0*\u00a0cpi ... ...  n\u00a0*\u00a0cpi n\u00a0*\u00a0cpi SP\u00a0(SERIAL)\u00a0= \n=\u00a01 SP\u00a0(PAR)\u00a0= =\u00a0n n\u00a0*\u00a0cpi cpi Figure 5. Examples Demonstrating Self-Parallelism (SP) Met\u00adric. SP identi.es \nthe parallelism local to a region by relating its critical path to the sum of its children s critical \npaths and its self\u00adwork. Shown in the example are SP calculations for two regions; one whose children \nmust execute serially, and one whose children can execute in parallel. length of the critical path). \nThe ratio of work to critical path length indicates the average number of instructions that can be executed \nin parallel in the ideal case.Kremlin ef.ciently determines both of these values through the use of shadow \nmemory[30, 45]. Kremlin s shadow memoryinfrastructure works by tracking the earliest possible time that \na value stored in a memory location can be calculated. This availability time is a function of the longest \nstringof operationsrequiredto calculate thatvalue.Kremlin calcu\u00adlates the availability time of each operation \nby looking up the times of all instructions it depends upon, .nding the maximum value, and then adding \nthe operation s latency. Kremlin tracks true data and control dependencies but factors out false dependencies \nsuch as anti and output dependencies. Kremlin utilizes two techniques to limit the overhead associated \nwith shadow memory: dynamic allocation of shadow memory and shadow register tables for local variables. \nDynamic shadow mem\u00adoryallocation is enabled by the use of a two-level table that equally splits the whole \naddress space.Kremlin allocates table entries only when they are needed, utilizing calls to malloc and \nfree as sig\u00adnals of the need to allocate or deallocate. Kremlin uses directly addressable shadow register \ntables for all local variables. This re\u00adduces access time for the common case of reading from local rather \nthan global variables. ResolvingFalse andEasy-to-BreakDependencies Amajor chal\u00adlenge for any critical \npath analysis infrastructure is to mitigate the effects of false and easy-to-break dependencies. Many \nof these false dependencies, such as unnecessary reuse of a variable, are eliminated by the use of SSA \nform in LLVM s IR. However, the easy-to-break dependencies associated with induction and reduc\u00adtion variables \nare more challenging. These types of dependencies can create the false impression of seriality in an \notherwise parallel region. Kremlin statically identi.es these dependencies and breaks them by using a \nspecial shadow memory update rule that ignores the dependency on their old value. Managing Control Dependencies \nKremlin performs static con\u00adtrol dependence analysis to identify which values a basic block is control \ndependent upon. Unfortunately, static analysis cannot fully resolve all control dependencies. Kremlin \nhandles control depen\u00addencies through the use of a control dependence stack similar to one proposed in \n[42]. Kremlin pushes a dependency onto the con\u00adtrol stack at the beginning of a control dependent region, \npopping it off whenexiting thatregion.Availability timesin the control stack can only increase. Therefore, \nKremlin incorporates control depen\u00addencies by checking only the top of the stack.  4.2 Hierarchical \nShadowMemory Hierarchical analysis introduces a new requirement to the shadow memoryinfrastructure described \nearlier: we must run separate criti\u00adcal path analyses across each nested dynamic region, and thus must \neffectively maintain many versions of the shadow memory. When we enter a new region, for the purposes \nof that region, we start at time =0, work =0, ignoring any dependencies that the parent region is aware \nof and is tracking. As we execute instructions in the program, we update the dependencytimes in the shadow \nmem\u00adoryand the work count for each active region. When we exit a new region, we record a summery of a \ndynamic region. This summary contains the static region ID, the total work in the region, and the critical \npath length. To implement shadow memory for the evolving set of dynam\u00adically nested regions as the program \nruns, each location in the shadow memoryand register tables is associated with a set of avail\u00adability \ntimes rather than just one. This set expands when a region is entered and shrinks when a region is exited. \nKremlin optimizes hierarchical shadow memory performance by maintaining a .xed-sized array of shadow \ndata for every mem\u00adory location. Kremlin assigns a region to a slot based on its depth in theregiongraph.For \ninstance, the main function (the root in the graph) might occupy slot 0, while its children will use \nslot 1, and soon.Acommandline.agcanvarytherangeofregiondepthsthat are collected,facilitating parallel \ndata collection for theHCPA. This assignment method leads to multiple regions at the same depth being \nmapped to the same slot although theywill never use itatthe same time andthereforeKremlin mustprovidea \nmecha\u00adnism toavoid datareuse acrossregion boundaries.Kremlin solves this problem by assigning a unique \nID to every region instance and taggingevery shadow memory write with theIDof the writer. Kremlin compares \nthe tag with the ID of readers, discarding the data if there is a mismatch and assuming time 0 instead. \n 4.3 Self-Parallelism Kremlin incorporates both the parallelism information and the program s structure \nto calculate a region s self-parallelism. Self\u00adparallelism factors out the parallelism that comes from \nsubregions to determine the amount of parallelism speci.c to a region. Kremlin uses the following equation \nto determine SP (R), the self-parallelism of a region R: .n cp(child(R, k)) + SW (R) SP (R)= k=1 (1) \ncp(R) where n is the number of children of R, child(R, k) is the kth child of R, and cp() is the critical \npath length of the region. SW (R) represents the amount of work that is performed exclusively in region \nR (i.e. self-work) and is calculated by the equation: n SW (R)= work(R) - work(child(R, k)) (2) k=1 Self-parallelism \nfactors out the children s parallelism by sum\u00adming the critical path lengths of the children rather than \ntheir work, thereby eliminating the parallelism that would otherwise come from the children. Self-parallelism \nadds work exclusive to the re\u00adgion to capture any remaining parallelism outside of the children. The \nself-parallelism metric also allows Kremlin to estimate the speedup from parallelizing a region, R. If \nthe execution time of a R is ET (R), then the execution time after the region is parallelized will be \nbounded by ET (R)/SP (R). This lower bound on execution time of a parallelized region is used by the \nplanner when determining which regions will bring the largest speedup. To illuminate the effectiveness \nof self-parallelism, we will ex\u00adamine the self-parallelism in two cases, shown in Figure 5: a region \nwith n children that can execute in parallel, and a region where all n children mustexecute serially \ndue to dependencies.For simplic\u00adity, we assume that parent regions have no self work and that all children \nhave the same measured critical path length, cpi. For the parallel region, its measured critical path \nwill be equal to a single child (i.e. cp(R)= cpi). Thus, the computed self\u00ad n*cpi parallelism, will be \ncpi = n; this is as expected because its parallelism is equal to the number of children. Now consider \na parent whose childregions mustbeexecuted completely serially.In this case, the measured cp(R) will \nbe equal to n *cpi and therefore n*cpavg the computed self-parallelism will be =1; again, this is n*cpavg \nexpected because it cannot overlap execution of the regions. In addition to resolving simple cases like \nthese, the SP heuris\u00adtic also computes reasonable upper-bounds estimates on self\u00adparallelism for cases \nwhere there is self-work in the parent node, and where there are dependencies between child regions that \nallow partial overlap in execution.  4.4 CompressedRepresentation Performing whole-program shadow memory \ntracing and region analysis is nominally a compute-and memory-intensive endeavor. In order to manage \nboth execution time and storage requirements, Kremlin employs a novel compressed trace representation \nthat en\u00adables the planning algorithm to operate on the data without actually decompressing it (analogous \nto [36] but in a different domain). In this subsection, we describe our implementation and quantify its \nbene.ts. Runtime Compression Technique Kremlin produces a paral\u00adlelism pro.le for each dynamic region \nthat is executed. The number of regions is based on the program structure deeply nested loops can lead \nto a large number of regions and the input to the instru\u00admented program and can quickly grow to multiple \ngigabytes for some programs. Kremlin takes advantage of the fact that many of the region summaries are \nidentical and therefore compression can be used. This reduces not only the amount of data that needs \nto bewrittentodiskduringthe instrumentedprogram sexecutionbut also the amount of data that needs to be \nprocessed by the planner. Kremlin utilizes a dictionary-based compression algorithm. When the .owofexecutionexitsaregion,Kremlin \nchecks the tuple of (static region, critical path, work, children)for the region against the current \nalphabet of unique regions. If there is no match, a new character is added to the alphabet. If there \nis a match, the associated character is used. The alphabet necessarily starts with leafregions.For children,Kremlin \nsummarizes child regions via a sorted list of characters, representing compressed re\u00adgions, and their \nfrequencies. Thus, the children used in the tuple are de.ned in terms of the existing alphabet rather \nthan the raw region info. Starting from the leaves, the alphabet expands to regions that contain only \nleaves for children and so on to the root (i.e. main). When the Kremlin planner makes use of the trace \n.les to cal\u00adculate self-parallelism, it does not need to decompress the data; instead, it operates on \neach character in the dictionary s alphabet directly. Kremlin exploits the dictionary representation \ns ability to summarize the critical path and work across recursively nested re\u00adgions. This can accelerate \nthe calculation of self-parallelism be\u00adcause each dictionary entry essentially summarizes repetitive \nse\u00adquences of large numbers of dynamic regions; processing each character therefore corresponds to processing \nthousands of dy\u00adnamic regions. Bene.ts We have found that this approach is quite effective. Our original \nlog sizes for the NPB benchmarks [6], using theWinputs, ranged from 750 MB to 54 GB, and averaged 17.9 \nGB. After compression, they were reduced to between 5 KB and 774 KB, with an average of 150 KB. This \nwas a net average reduction of ~119,000x for log size, and a typically proportional factor for planning \ntime from minutes to small fractions of a second. Code instrumented with our infrastructure, which is \nnot heavily optimized, is currently about 50\u00d7 slower than gprof-instrumented code; however the parallelism \ndiscoveryprocess can be sped up by running instrumentation of disjoint code regions in parallel.   \n5. Parallelism Planning In this section we will discuss Kremlin s OpenMP planning per\u00adsonality, andbrie.yoverviewaCilk++ \nplanning personality. 5.1 OpenMP Planner OpenMP is a popular parallel programming environment with a \nstrong focus on parallelization of loops. Programmers insert pragma statements into their source code \nand the OpenMP com\u00adpiler generates the necessary threaded code for them to run. While it does support \nnested parallelism, the overhead is often too high for it to be effective: the number of execution contexts \navailable is often not enough to handle the extra threads that are spawned and thus the cost of spawning \nnew threads is never amortized. Further\u00admore, OpenMP requires the programmer to transform loops into \nparallel (i.e.DOALL) loops in order to achieve good performance. Kremlin contains a planner that takes \ninto account the major constraints associated with OpenMP. The planner disallows nested parallel regions \nto avoid the performance penalty we observed on our experimental setup. OpenMP supports reduction variables \nin parallel loops, but they have signi.cant overheads [8]. We found that the amount of work in a region \nshould be large enough to amortize these costs. For instance, reduction-based loops in the SPEC OMP2001 \n[2] benchmarks art and ammp have too little work to overcome overheads. On the other hand, ep, from the \nNASParallelBenchmarks[6]( NPB ),hasareduction-based main function that should be parallelized because \nit has ample work. Based on these constraints for OpenMP planning, we can for\u00admulate the problem as follows. \nGiven a region graph G, select a set of regions to parallelize, R, such that in anymulti-node path, P \n, in G there is at most one node in R (i.e. |P nR|= 1). The optimal solution will minimize the time required \nto execute the program. OpenMPPlanningAlgorithm Anaive algorithm for determining whichregionstoparallelizewouldbetorepeatedly \nselecttheregion with the largest potential speedup among all regions considered for parallelization. \nWhen a region is selected by the planner, any region that can reach or can be reached from a selected \nregion would then be excluded from consideration to avoid nested parallelization. In some cases,thisalgorithmmayleadto \noptimalresultsbutinmany casesitis suboptimal.Forexample,aparentregionmighthavethe highest single potential \nspeedup, but collectively, a set of its child regions couldoffera higher combined speedup.Agreedy algorithm \nwould select the parent, precluding the more optimal solution of selecting the set of child regions. \nSpeci.cally, this problem was observed in two of the NPB benchmarks: ft and lu. Kremlin s OpenMP planner \nemploys a bottom-up dynamic\u00adprogramming algorithm. At each level, if we have an optimal plan for parallelizing \nall of the children, we can make an optimal plan for parallelizing the current node by comparing the \nexpected speedup of the parent versus the cumulative expected speedup of paralleliz\u00ading the children \naccording to their optimal plan. At the leaves, we select the node by default if it has expected positive \nspeedup. Additional Constraints for OpenMP and Machine Overheads As part of Kremlin s support for planner \npersonalities, Kremlin can be con.gured with a few parameters that attempt to capture the system s abilitytoexploitparallelism.Inshared \nmemoryandlarge\u00adscale NUMA machines using runtime schedulers, the cost of data movement and synchronization \ncan be relatively high compared to .ner-grained research machines, which impairs their ability to exploit \nregions with .ne-grained parallelism or synchronization. Clearly many parameters could be incorporated \nto try to more accurately model the underlying system. However, we would gen\u00aderally prefer to have relatively \nsimple parameters that are useful across a range of systems. As a result, we strove for parameters that \nareexpressedinarelativelyarchitecture-independentfashion. For the OpenMPplanner personality,we found \nthat it was effec\u00adtive to use a set of three threshold parameters. The .rst is a thresh\u00adoldthat determinesa \nminimumlevelof self-parallelismforaregion to be exploited. This mechanism indirectly accounts for the \nover\u00adhead of the the OpenMP scheduler and also the cost of migration between nodes. The second and third \nthresholds are the minimum required ideal whole-program speedup due to a DOALL region and due to a DOACROSS \nregion. We differentiate between these two kinds ofregions becauseDOACROSSregions are much more synchronization \nintense (and thus less likely to pay off), and re\u00adquire more programmer effort, and so require a higher \nideal whole\u00adprogram speeduptobe justi.ed.As discussedin Section4.3,Krem\u00adlin identi.es DOALL loops by \nchecking for equivalence between self-parallelism and iteration count. In this paper, we employ 5.0 as \nthe cutoff for self-parallelism, 0.1% speedup forDOALL loops and 3% speedup for DOACROSS loops. Our sensitivity \nanalysis suggests that Kremlin is not particularly sensitive to minor varia\u00adtions in the settings of \nthese parameters. Our initial prototype of the OpenMP planner also included the number of cores as a \nconstraint. This initial version capped the speedup of any region at the number of cores available. However, \nwe found that including this constraint had a negative impact on plan quality. With this cap in place, \nthe planner could not differ\u00adentiate between regions with self-parallelism of N (the number of cores) \nand those which much higher self-parallelism. Our results suggest that high self-parallelism is correlated \nwith large speedup: a region with much higher self-parallelism likely has more oppor\u00adtunities to amortize \nparallelization overhead and more .exibility in restructuring to improve memorylocality. 5.2 Cilk++ \nPlanningPersonality Kremlin also contains a Cilk++ [27] planner that accounts for Cilk++ s support for \nnested-and .ner-grained parallelism. It em\u00adploys the same self-parallelism metric as the OpenMP plannerbut \nwith lower thresholds for self-parallelism and ideal speedup, ac\u00adcounting for Cilk++ s lower underlying \ncosts; it also uses a nesting\u00adaware planning algorithm. Kremlin was originally developed with a Cilk++ \nplanner, which was used by a group of graduate students in a recent parallel ar\u00adchitecture class. Although \nstudents found the tool useful, the rel\u00adative lack of a large, established Cilk++ benchmark suite (and \nIn\u00adtel s acquisitionofCilkArts)barredusfromperforminga quantita\u00adtive evaluation for publication, motivating \nthe development of the OpenMP planner.  5.3 Developing PlanningPersonalities Planning personalities \nprovide an avenue for the user to tailor plan\u00adning recommendations to different systems. Underlying the \ndevel\u00adopment of new planning personalities is a fundamental tension be\u00adtween accuracyand portability. \nThe designer of a planning person\u00adality must decide the level of architectural independence that is part \nof the personality. Architectural independence is a desirable prop\u00aderty for portability, allowing the \nplanning results to be useful over a wide range of systems, but may need to be sacri.ced in order to \nattain suf.cient accuracy. The development of the OpenMP and Cilk++ personalities pro\u00advided some insight \ninto the portability-accuracy trade-off. These  Benchmark MANUAL ammp 6 Kremlin Overlap Reduction 3 \n2 2.00x art 3 4 1 0.75x equake 10 6 6 1.67x bt 54 27 27 2.00x cg 22 9 9 2.44x ep 1 1 1 1.00x ft 6 6 5 \n1.00x is 1 1 0 1.00x lu 28 11 11 2.55x mg 10 8 7 1.25x sp 70 Overall 211 58 47 1.21x 134 116 1.57x 1.85x \n1.8 1.6 1.4 6.84x 1.2 1 0.8 0.6 0.4 0.2 0 ammp art equake bt cg ep ft is lu mg sp mean (a)Plan Size \nComparison (b)Relative SpeedupofKremlin ComparedtoMANUAL withAbsolute Speedup Relative Speedup Figure \n6. Evaluation ofKremlin-BasedParallelization. Table (a) showsMANUAL plan sizes are signi.cantly larger \n(1.57\u00d7 on average) than Kremlin plan sizes. Surprisingly, the majority of regions in Kremlin plans are \noverlapping with MANUAL. Even though Kremlin proposes substantially smaller number of regions to a user, \n(b) demonstrates that the resulting performance is generally quite close to the manually-parallelized \nversions, ranging from 12% slower to 85% faster. Note that Kremlin formulated its plans solely by examining \nthe executionofthe unmodi.ed serial code.Inordertoreducetheexperimentaleffectsofdifferenteffortlevelsanddifferentprogrammersfor \nhand tuning,weevaluatedtheplansforKremlinbyusingtheparallelizedcoderegionsinthe manually-parallelized \nversion. Inthe caseof SP andIS,Kremlin srecommendations were signi.cantly different, so we had to manually \napply those optimizations. personalities required that we model only fundamental parame\u00adters of the parallel \nmachines: synchronization costs, loop type, and region granularity. These parameters are likely to port \nwell to other parallelization systems, reducing the work necessary to de\u00advelop new planners for these \nother systems. We found that while machine-speci.c parameters such as cache size, page size, and memory \nbandwidth do in.uence parallel performance, and in.u\u00adence how code should be transformed, they have limited \nimpact on the set of regions that should be parallelized. These machine\u00adspeci.c parameters therefore \nare of greater import during the En\u00adablingTransform stage in Figure1 than during the Planning stage. \n  6. Experimental Evaluation We evaluated Kremlin using all 8 programs in the NAS Parallel Benchmarks \n(NPB)[6] and all3C-language programs in the SPEC OMP2001 [2] benchmark suite. For NPB, we used the third-party \nOpenMP manually-parallelized version of these programs [1] as a point of comparison for Kremlin s ability \nto create an effective parallelization plan. For SPEC OMP2001, we ran our tool on the corresponding serial \nversions of the programs in the SPEC 2000 benchmarksuite, and then comparedKremlin s plans against those \nparallelized by humans in the SPEC OMP2001 versions. For art and ammp, SPEC OMP versions bene.t from \nserial optimizations compared to their SPEC 2000 counterparts [38]. To exclude the effect of serial optimizations, \nwe applied those optimizations on the SPEC 2000 code beforerunningKremlin. Ourevaluation included only \nthird-party benchmarks that have preexisting parallel versions tofacilitate comparisonandtomakeourresultsmorecredible.The \nprograms vary greatly in terms of speedup (1.5x to 25.89x, Figure 6(b)), but low coverage, low parallelism, \nparallelization overhead, and otherfactors signi.cantlyreducethepercentageofregions that are good candidates \nfor parallelization (Figure 9). One might expect that iterative, trial-and-error manual paral\u00adlelization \nwould do signi.cantly better than Kremlin, because the user has the bene.t of performing iterative runtime \nmeasurements as theyincrementally parallelize the program.We found that paral\u00adlelization withKremlin \ncame surprisingly close in terms of perfor\u00admance on all but two benchmarks, and in those cases, it did \nmuch better. At the same time, it achieved these results with substantially smaller numbers of regions \nthat needed to be parallelized. 6.1 Methodology We .rst ran Kremlin on the unmodi.ed, serial versions \nof the benchmarks to generate a parallelism plan for each program. The resulting plan was used to create \na parallelized version of the serial program.In cases whereKremlin s parallelism plansrecommended regions \nthat had also been parallelized in the third-party, manually\u00adparallelized version of the benchmark ( \nMANUAL ), we reused the parallelized regions from the MANUAL version. This allowed us to control for \nvariances in performance that could result from slightly different parallel implementations of the same \nregion. To generate and evaluate parallelism plans, the W input set was used for NPB benchmarks while \nthe train input was used for SPECOMP.Kremlinrelieson dynamic analysisand thereforemay be affected by \nvarying inputs. To test for input-related sensitivi\u00adties, we reused the parallelized program based on \nthe train input parallelism plan to measure the speedup numbers for SPEC OMP benchmarks with the larger \nref input.We found thatKremlin\u00adbased parallelization remained equally competitive on both input sizes, \ndespite requiring a much smaller set of parallelized regions. Program performance was tested on 32-core \nsystem (8\u00d7 AMD 8380 Quad-coreprocessors)with 256GBof memoryrunningonthe Linux 2.6.18Kernel.Programs were \ncompiled with gcc version 4.1 with OpenMP and -O3 .ags speci.ed. We executed the programs using con.gurations \nof 1, 2, 4, 8, 16, and 32 cores. As is typical for these kinds of systems, performance can decline as \nlocality effects start to trump the bene.ts due to parallelization. For each parallel version, we determined \nthe con.guration with the best performance and report that number.  6.2 Evaluation ofParallelism Planning \nKindsofParallelismFound andTransformationsImplied Krem\u00adlin detects parallelism of all forms: nested-loop-parallelism \ninclud\u00adingDOACROSS andDOALL, pipelined parallelism between loops and functions, ILP, and thread and task-level-parallelism. \nAll of these exist in our benchmark suite, although Kremlin only recom\u00admends regions that are predicted \npro.table to parallelize according to the planner and personality in use. Exposing the parallelism detected \nby Kremlin required user transformations such as: privatization; loop restructuring, fusion and interchange; \ninsertion of OpenMP constructs; and refactoring of code and data structures to eliminate false sharing \nand con\u00adtention. These transformations range in dif.culty from trivial to dif.cult, that is, from requiring \nless than an hour of work to re\u00adquiring several hours. As we will show in the following sections, Kremlin \nis able to signi.cantly reduce the number of regions that must be parallelized, thereby signi.cantly \nreducing the total effort needed to parallelize the program. Kremlin also provides a mech\u00adanism whereby \nthe user can specify a set of regions that are too dif.cult to parallelize and rerun the planner, which \nrecomputes the optimal plan excluding that region.  Plan size comparison Kremlin seeks to focus the \nprogrammer s efforts on a small subset of regions that have the most poten\u00adtial for speedup from parallelization. \nTo test Kremlin s effective\u00adness in this regard, we compared Kremlin s recommended regions ( plans ) \nto the set of regions that were parallelized in the third party-parallelized version of the benchmark \nsuite, referred to as MANUAL. Figure 6(a) provides this plan size comparison. Across all of the regions \nin the benchmarks, the MANUAL version included 1.57\u00d7 more regions than the plan provided by Kremlin. \nFor small benchmarks (e.g. ep, ft, and is) there was littleroom for improvement,but larger, more complex \nbenchmarks showedlargersavings comparedtotheaverage.Attheextremeend, lu s manually-parallelized plan \nsize was 2.55\u00d7the size ofKremlin. The programmer using Kremlin would have had far fewer regions to parallelize \nthan the original third party parallelizers2. Performance comparison withMANUAL Next, weevaluated the \nspeedup of parallelized versions based on Kremlin s parallelism plan against the MANUAL version. Figure \n6(b) shows the results of this comparison. The Kremlin version of sp and is performed signi.cantly better \n(1.85\u00d7, 1.46\u00d7) than MANUAL as Kremlin was able to identify parallelism that was missed in the MANUAL \nversion. In this case, Kremlin recommended a coarse-grained par\u00adallelization, requiring privatization \nand refactoring. Other bench\u00admarks saw a slight degradation in performance, averaging about 3.8%. Kremlin \ngenerally selected the same regions as MANUAL, but decided to stop earlier because of the diminishing \nreturns. Togain additional insight, Figure7 shows the marginal bene.t attained by applying each of the \nrecommendations, in order, from Kremlin s plans. Also shown in the graphs are the marginal bene.ts of \nregions parallelized in MANUAL but not recommended by Kremlin (regions to the right of the dotted line). \nIna large majorityof cases,regions notrecommendedbyKrem\u00adlin but parallelized by MANUAL provide negligible \nbene.t. Ad\u00additionally, we can see that, although Kremlin s plans are well\u00adprioritized overall, the incremental \ncontribution of a parallelizing a region can be somewhat noisy. For instance, in several cases, the second \nrecommended region attains a much higher incremen\u00adtal speedup than the .rst recommended region this is \nbecause as more of the program is parallelized, less data migration happens in the NUMA machine. Often \nit is groups of regions that must be parallelized before anyspeedup is observed. Overall, Kremlin does \nan excellent job of eliminating regions that offer little bene.t. Even for those few regions that were \nelim\u00adinated by Kremlin but had some marginal bene.t, the bene.ts are slight. Given the savings in the \nnumber of regions parallelized by Kremlin, we suspect that the programmer could easily make up the difference \nby applying serial optimizations rather than attempting to parallelize the additional regions. 2Programmer \neffortmetrics for theEnablingTransformspartof paralleliza\u00adtion is clearly a hard problem. We have also \nexplored other metrics, like lines of code, as proxies for programmer effort in Kremlin, since it could \nperhapsbea betterproxy for parallelization complexity.However, our im\u00adpression from the benchmarks is \nthat, at least, for OpenMP, region count is a better, albeit imperfect, approximation of programmer effort. \nFraction of Kremlin Plan Applied First First First All Benchmark 25% 50% 75% 100% ammp 74.7 % 100.0 % \n100.0 % 100.0 % art 100.0 % 100.0 % 100.0 % 100.0 % equake 82.5 % 89.2 % 99.0 % 100.0 % bt 48.9 % 85.8 \n% 92.2 % 100.0 % cg 84.9 % 86.7 % 93.5 % 100.0 % ep 100.0 % 100.0 % 100.0 % 100.0 % ft 44.7 % 78.9 % \n100.0 % 100.0 % is 100.0 % 100.0 % 100.0 % 100.0 % lu 45.8 % 84.0 % 95.4 % 100.0 % mg 35.6 % 73.0 % 79.5 \n% 100.0 % sp 9.6 % 62.1 % 94.5 % 100.0 % average bene.t 56.2 % 86.4 % 95.6 % 100.0 % marginal average \nbene.t 56.2 % 30.2 % 9.2 % 4.4 % Figure 8. Marginal Bene.t of Region Parallelization. A well\u00adprioritized \nparallelism plan will show decreasing marginal bene.ts as more of the recommended regions are parallelized. \nThis table shows the average marginal bene.t of 25% increments in the frac\u00adtion of regions parallelized. \nThe .nal row shows that a majority (56.2%) of bene.t comes from the .rst 25% of regions with the following \nintervals showing decreasing average marginal bene.ts. This suggests that Kremlin s parallelism planner \nis effective at re\u00adgion prioritization. Effectiveness of Region Prioritization An important aspect of \nplanning is to ensure not only that the regions with the most bene.t are selectedbut also that they are \nprioritized correctly. The planner attempts to place regions with the largest bene.t at the beginning \nof the plan. Meeting this goal maximizes the productivity of the pro\u00adgrammer by focusing their efforts \nwhere they are most valuable. Toevaluate theeffectivenessof theorderingproducedbyKremlin, we measured \nthefractionof totalrealizedexecute timereduction at\u00adtainedby following increasingportionsofKremlin s \nplans, includ\u00ading the .rst 25%, .rst 50%, .rst 75%, and all 100% of the plan.We would expect well-prioritized \nplans to generally produce monoton\u00adically decreasing bene.ts for each additional fraction that is added. \nAsshowninFigure8,Kremlin splansare well-prioritized.The.rst 25% of the plans average 56.2% of the bene.t, \nthe next 25% aver\u00adages 30.2% of the bene.t, while the following 25% yields 9.2%, and the last 25% yields \n4.4% of the bene.t. In.uences on Plan Size Next, we evaluated how plan size is reduced as additional \ninformation is taken into account. Thefactors that we looked at were work coverage, self-parallelism, \nand usage of the full OpenMP planner personality. Figure 9 illustrates the impact of each of these factors \non the programs. Programmers that take into account only work information (e.g. a gprof-based approach) \nwould be left with an average of approximately 59% of the total regions to analyze and attempt to parallelize. \nWith the additionof self-parallelism information for eachregion, theaverage plan size is cut to 25.4% \nof all regions. Finally, when using the full planner an average of only 3.0% of the regions are included \nin the plan. As we have shown in Figure 6, despite only parallelizing  60 50 40 15 30  Time Reduction \n(%) Time Reduction (%) Time Reduction (%) Time Reduction (%) 10 5 20 10 0 0 0 0 5 101520 bt cgmg 7 \n35 30  Time Reduction (%) Time Reduction (%) 30 25 20 15 10 5 25 20 15 10 5 0 0 0 012345678 sp ft \n100 100 50 70 40   35 30 25 20 15 10 5 Time Reduction (%) 80 60 40 20 60 50 40 30 20 10 80 60 40 20 \n0 0 0 0 0 01234567 012345678 equake art ammp is ep Figure 7. Effectiveness of Region Prioritization. \nKremlin provides a list of regions prioritized by their estimated speedup so that users can maximize \ntheir productivity. The graphs above show the marginal decrease in execution time, relative to the original \nprogram run time, as each region in Kremlin plan is parallelized. We also included regions that were \n.ltered out in the Kremlin plan but were chosen to be parallelized by the expert third party (MANUAL). \nThese regions are shown to the right of the dotted line. As the graphs illustrate, little bene.t camefromregions \nthat were parallelizedby the third-partybut that were not suggestedbyKremlin. a fraction of the regions, \nKremlin achieves performance that is comparable to the highly-tunedMANUALversion. Effectiveness of Self-ParallelismMetric \nTo determine the ability of self-parallelism s ability to reduce the number of parallelism false positives \n(i.e. serialregions that arereported as being parallel), we calculated the self-parallelism and total-parallelism \nnumbers for all 2535regions that appearin the benchmarks, and classi.ed them according to whether their \nparallelism is greater than or less than ( high or low ) a threshold value of 5.0. The total-parallelism \nmetric identi.ed 25.8%ofregionsashav\u00ading low parallelism, while the self-parallelism metric identi.ed \n58.9% of regions as having low parallelism, a reduction of 2.28\u00d7.  7. RelatedWork Parallelism Discovery \nand Dependence Testing Approaches for parallelism-related pro.ling have generally fallen into two cate\u00adgories: \ncritical path analysis (CPA) and dependence testing. Crit\u00adical path analysis dates back several decades, \nwith early important works including [5, 23]. These approaches measured the number of concurrent operations \nat each time step along the critical path of the program. More recent work includes application of CPA \nto Java [13] as well as a modi.ed CPA for the purpose of function\u00adlevel parallelism in Java programs \n[32]. Unlike these approaches, Kremlin s hierarchical critical path analysis is able to localize par\u00adallelism \nwithin nested program regions, and provide concrete guid\u00adance on which program regions to parallelize. \nAllen et al. [3] performed static analysis of Fortran programs in an attempt to automatically identify \nthe correct granularity of parallelism for a target architecture. Kremlin is also able to iden\u00adtify the \nproper granularity of parallelism through the use of self\u00adparallelism and planning personalities. However, \nthe work in [3] was limited to structured, Fortran code; Kremlin is able to work with unstructured code \nthat contains pointers which cannot be ana\u00adlyzed statically. Furthermore,Kremlin focuses on enabling \nthe user to parallelize complicated code with which automatic parallelizing compilers have traditionally \nstruggled. Kulkarni et al. [22] used a critical path based analysis to bring insight into the parallelism \ninherent in the execution of irregular algorithms.In contrast toKremlin s focus on localizing parallelism \nto concrete code regions via HCPA, Kulkarni s approach attempts to transcend the details of the implementation \nand to quantify the amount of latent parallelism in irregular programs that exhibit amorphous data parallelism. \nCilkview [14] is a recent tool that takes an already-parallelized Cilk++ program and estimates how that \nprogram s performance will change as the number of cores is increased. Similar to Krem\u00adlin, Cilkview \nleverages runtime information, and analyzes runtime dependenciesin theprogram.However, Cilkviewexamines \ndepen\u00addencies between pre-parallelized threads in a work-queuing run\u00adtime system rather than between \ninstructions. Another approach to parallelism-related pro.ling has been to use dependence testing to \nuncover the dependencies between dif\u00adferent regions in the program. pp [24] is an early important work \nthat proposed hierarchical dependence testing to estimate the paral\u00adlelism in loop nests. Notable recent \nworks include Alchemist [43] and SD3[19], which reduces runtime and memory overhead of de\u00adpendence testing \nthrough the use of parallelization and compres\u00adsion. Although dependence testing andKremlin sHCPAshare \nsim\u00adilar goals, Kremlin focuses on localizing and quantifying paral\u00adlelism across many different, nested \nprogram regions rather than establishing independence of pre-existing regions. As a result, it can identify \nmore nuanced forms of parallelism even though sig\u00adni.cant transformation is required to expose it. Dependence \ntest\u00ading is generally more pessimistic and sensitive to existing program structure.  A number of works \nhave used dependence testing to deter\u00admine the probability that speci.c dependencies will occur [39, \n41]. DProf [41] uses a compiler to identify may dependencies and then determine the probability that \nthese dependencies will occur. von Praun et al. [39] introduced the dependence density metric to de\u00adscribe \nthe probability that two random tasks would have a depen\u00addency.Both of these approaches target optimistic \nconcurrencysuch as TLS or transactional memory. The main difference between Kremlin s parallelism discovery \nand dependence testing frameworks is in the stage of parallelization (Figure1) thatpro.ling targets.Kremlin \ns parallelism discoveryis meantto quantifytheparallelisminafashionthatisnotasstrongly tied to the program \ns current structure, exposing hidden sources of parallelism. In contrast, dependence testing-based approaches \nare more aligned with the enabling transforms stage of parallelization as they enable identifying speci.c \nchanges that need to be made to enable parallelism. In the absence of discovery and planning tools, [43] \norders regions by total execution time. An interesting possibility would be to augment [43] s approach \nwith the improved analysis provided by Kremlin. ParaScope [18] used static analysis to expose dif.cult-to-analyze \ndependencies to the user so that they could circumvent them via refactoring. The discovery phase takes \nadvantage of a compression scheme thatresembles whole-program path compression schemes [44].We achieve \nmuch higher compression levels because we do not need to store information about the relative ordering \nof child subregions. Parallelism Planning The task of parallelism planning has been mostly overlooked \nin the context of manual parallelization. Outside of manual parallelization, automatic parallelizing \ncompilers such as SUIF [12] andPolaris [7] implicitly perform planning.Because these tools do not target \nuser-assisted parallelization, their planning phases focus on .nding thresholds for pro.table exploitation. \nSpeculative parallelization systems [31, 34] have created new opportunities for compilers to exploit \nparallelism even in the face of dif.cult-to-analyze code, or infrequent dependencies that result in overly \nconservative execution. These systems typically have a memory speculation system, often in special hardware \nbut some\u00adtimes in software, which removes the burden of proving the cor\u00adrectness of potential parallelizations, \nallowing the compiler to focus on selecting the parallelizations that maximize performance. TLS compilers \n[9, 11, 29, 31, 37, 46] also bene.t from detecting par\u00adallelism and often use dynamic critical path or \ndependence testing analyses in order to establish regions which are likely to be prof\u00aditable for TLS-style \nexecution. Kremlin s HCPA can be used in a complementary manner by providing a way to guide programmers \nin restructuring their code to improve parallelism for execution on TLS. This can enable an even larger \nclass of transformations than these systems natively support. RecentworkbyTournavitisetal.[38]providesa \nsemi-automated approach to parallelization. This approach automates parallelism discovery using a form \nof dependence testing and uses machine learning to pick a set of regions to be parallelized. The selected \nregions are automatically annotated with OpenMP pragmas. The work self parallelism full planner Plan \nSize (% to all regions) 80 70 60 50 40 30 20 10 0 Figure 9. Evaluating Plan Size Reduction Due to Each \nof Kremlin s Planning Components. Plans based only on workcov\u00aderage comprised 58.9% of all regions on \naverage. Using self\u00adparallelism to eliminate low parallelism regions cut this more than half (25.4%, \non average). Finally, using the full OpenMP planner personality, the plan size was reduced to only 3.0% \nof the total re\u00adgions. presumption is that the user will verify the correctness of the par\u00adallelization. \nWhile this approach has promise, it is limited by the compiler s ability to perform the Enabling Transforms \nphase of parallelization. In contrast, Kremlin has a more optimistic view of parallelism and is able \nto report regions with parallelism even if the compiler is not up to the task of exploiting it automatically. \nSystems such as SUIF Explorer [28] and CAPO-Paraver [16] share Kremlin s focus on empowering the user \nduring paralleliza\u00adtion. SUIFExplorer s novelty focuses around its use of static inter\u00adprocedural program \nanalysis including pointer analysis and slicing; its use of dynamic analysis is very brie.y described \nbut appears to detect the absence or presence of memory dependencies within loops, and to provide time \npro.les for regions. CAPO-Paraver ex\u00adtends the CAPO parallelizing compiler to allow it to insert instru\u00admentation \nthat helps the user understand the load balancing prop\u00aderties of parallelized code. A short paper on \nKremlin appeared in PPoPP [15].  8. Conclusion Kremlin strives to simplify the task of parallelization \nby address\u00ading the question: what parts of the program should I spend time parallelizing? Beginning with \nunmodi.ed serial source code and sample inputs, Kremlin produces a list of regions in the order that \ntheyshould be parallelized. AttheheartofKremlinisanextensionofthecriticalpath anal\u00adysis technique. Critical \npath analysis, which was invented in 1988, is rarely used in current-day performance pro.ling tools. \nIn this paper, we extend that work by proposing the hierarchical critical path analysis (HCPA) technique, \nthe self-parallelism metric, and the idea of using a planner algorithm that models the execution of the \nprogram on the machine. Given how conceptually straightfor\u00adward HCPA appears to be, it seems surprising \nthat it has not been proposed earlier, closer to the inception of CPA in the 80 s. Al-thoughHCPAappearsinretrospecttobestraightforward,the \nhard part of the research is making the jump from the output of the HCPA algorithm to the creation of \nan effective parallel plan. The self-parallelism metric and planner concept are thekeysteps in do\u00ading \nthis, and took many people-years of iteration for us to arrive at. One of the challenges with this research \nis .guring out exactly what information is needed to make meaningful recommendations, andhowto decimatethe \ninformationateachstageoftheprocess.A valid approach must work without the collection of traces that are \nproportional to the execution time of the program, which can easily amount to terabytes. Further optimization \ndetail is required for cre\u00adating the multi-versioned shadow memorydata-structures and rules that enableHCPA \ntorun quicklyandwithlowoverhead.  Kremlin sresults arevery strong.Typically,byexamining only the original \nserial code, the tool beats iterative parallelization by experts.It reducesthe numberof unnecessarilyparallelizedregions \nby 1.57x, attains better average performance, and in two out of the eleven benchmarks, improves speedups \nsubstantially by factors of 1.86x and 1.46x. Our results also show that Kremlin is effective at prioritizing \nregions: 56.2% of the bene.t is captured in the .rst quarter of recommendations, and 86.4% comes from \nthe .rst half of recommendations. All of these results suggest that Kremlin is likely to be highly effective \nat reducing programmer effort.  Acknowledgement This research was funded by the US National Science \nFoundation under CAREER Award 0846152, and under Awards 0725357 and 1018850.  References [1] NASParallelBenchmarks \n2.3; OpenMP C. www.hpcc.jp/Omni/. [2] Spec OMP2001Benchmarks. http://www.spec.org/omp. [3] F. Allen, \nM. Burke, R. Cytron, J. Ferrante, W. Hsieh, and V. Sarkar. A framework for determining useful parallelism. \nIn Proceedings of the 2nd international conference on Supercomputing,ICS 88, 1988. [4] T. E. Anderson, \nand E. D. Lazowska. Quartz: A tool for tuning parallel program performance. In SIGMETRICS, vol. 18, 1990. \n[5] T. Austin, and G. S. Sohi. Dynamic dependencyanalysis of ordinary programs. In ISCA, 1992. [6]Bailey \netal. TheNASparallel benchmarks. InSC, 1991. [7] W. Blume, R. Doallo, R. Eigenmann, J. Grout, J. Hoe.inger, \nT.Lawrence,J. Lee,D.Padua,W.Paek,Y.Pottenger,L.Rauchwerger, andP.Tu. Parallel programming withPolaris. \nIEEEComputer, Aug 2002. [8]J.M.Bull,andD. O Neill. Amicrobenchmark suitefor openmp 2.0. SIGARCH Comput. \nArchit.News,December 2001. [9] M. K. Chen, and K. Olukotun. The Jrpm system for dynamically parallelizingJava \nprograms. In ISCA, 2003. [10]D.Dig,J.Marrero,andM.D.Ernst. Refactoringsequentialjava code for concurrencyvia \nconcurrent libraries. In ICSE, 2009. [11] Z. H. Du, C. C. Lim, X. F. Li, C. Yang, Q. Zhao, and T. F. \nNgai. A cost-driven compilation framework for speculative parallelization of sequential programs. In \nPLDI, 2004. [12] M.W.Hall,J.M. Anderson, S.P. Amarasinghe,B.R.Murphy, S.-W. Liao, and E. Bu. Maximizing \nmultiprocessor performance with the SUIFcompiler. IEEE Computer, Aug 1996. [13] C. Hammacher, K. Streit, \nS. Hack, and A. Zeller. Pro.ling java programs for parallelism. InProceedings of the 2009ICSEWorkshop \nonMulticore SoftwareEngineering,IWMSE 09, 2009. [14] Y. He, C. Leiserson, and W. Leiserson. The Cilkview \nScalability Analyzer. InSPAA, 2010. [15] D.Jeon, S. Garcia, C. Louie, S.KotaVenkata, andM.Taylor. Krem\u00adlin: \nLike gprof,but forParallelization. In Principles and Practice of ParallelProgramming, 2011. [16] G. Jost, \nH. Jin, J. Labarta, and J. Gimenez. Interfacing computer aided parallelization and performance analysis. \nIn Computational Science ICCS 2003, vol. 2660 of LectureNotes in Computer Science, 715 715. 2003. [17] \nK. Kelsey, T. Bai, C. Ding, and C. Zhang. Fast track: A software system for speculative program optimization. \nInCGO, 2009. [18] K. Kennedy, K. S. McKinley, and C. W. Tseng. Interactive parallel programming using \nthe parascope editor. IEEE TPDS, 1991. [19] M. Kim, H. Kim, and C.-K. Luk. SD3: A scalable approach to \ndynamic data-dependence pro.ling. Microarchitecture, IEEE/ACM International Symposium on, 2010. [20] \nS.KotaVenkata,I. Ahn,D.Jeon,A. Gupta,C. Louie,S. Garcia,S.Be\u00adlongie, and M. Taylor. SD-VBS: The San Diego \nVision Benchmark Suite. InIISWC, 2009. [21] D.Kuck,Y.Muraoka, and S.-C. Chen. On the number of operations \nsimultaneously executable in fortran-like programs and their resulting speedup. IEEETransactions on Computers,Dec. \n1972. [22] M. Kulkarni, M. Burtscher, R. Inkulu, K. Pingali, and C. Casc\u00b8aval. How much parallelism is \nthere in irregular applications? In PPoPP, 2009. [23] M. Kumar. Measuring parallelism in computation-intensive \nscien\u00adti.c/engineering applications. IEEETOC, Sep 1988. [24] J. R. Larus. Loop-level parallelism in \nnumeric and symbolic pro\u00adgrams. IEEETrans.Parallel Distrib. Syst., 1993. [25] C. Lattner, and V. Adve. \nLLVM: A compilation framework for lifelongprogram analysis&#38; transformation. In CGO,Mar 2004. [26] \nW. Lee, R. Barua, M. Frank, D. Srikrishna, J. Babb, V. Sarkar, and S. Amarasinghe. Space-time scheduling \nof instruction-level paral\u00adlelism onaRaw machine. InASPLOS, October 1998. [27] C. E. Leiserson. The Cilk++ \nconcurrencyplatform. In DAC, 2009. [28] S.-W. Liao, A. Diwan, R. P. Bosch, Jr., A. Ghuloum, and M. S. \nLam. Suif explorer: an interactive and interprocedural parallelizer. In Proceedings of the ACM SIGPLAN \nsymposium on Principles and practice of parallel programming, 1999. [29] W. Liu, J. Tuck, L. Ceze, W. \nAhn, K. Strauss, J. Renau, and J. Tor\u00adrellas. POSH: a TLS compiler that exploits program structure. In \nPPoPP, 2006. [30] N. Nethercote, and J. Seward. Valgrind: A framework for heavy\u00adweight dynamic binaryinstrumentation. \nIn PLDI, 2007. [31] L.Rauchwerger, andD.Padua. TheLRPD test:speculativerun-time parallelization of loops \nwith privatization and reduction paralleliza\u00adtion. InPLDI, 1995. [32] A. Rountev, K. Van Valkenburgh, \nD. Yan, and P. Sadayappan. Un\u00adderstanding parallelism-inhibiting dependences in sequential java pro\u00adgrams. \nIn Software Maintenance (ICSM), 2010 IEEE International Conference on, Sept 2010. [33] V. A. Saraswat, \nV. Sarkar, and C. von Praun. X10: concurrent programming for modern architectures. In PPoPP, 2007. [34] \nG. Sohi, S. Breach, and T. Vijaykumar. Multiscalar processors. In ISCA, 1995. [35] N. R. Tallent, and \nJ. M. Mellor Crummey. Effective performance measurement and analysis of multithreaded applications. \nIn PPoPP, 2009. [36] W. Thies, S. Hall, and S. Amarasinghe. Manipulating lossless video in the compressed \ndomain. InACMMultimedia, 2009. [37] C. Tian, M. Feng, V. Nagarajan, and R. Gupta. Copy or discard execution \nmodel for speculative parallelization on multicores. In MICRO, 2008. [38] G.Tournavitis, Z.Wang,B. Franke, \nandM.F.P. O Boyle. Towards a holistic approach to auto-parallelization: integrating pro.le-driven parallelism \ndetection and machine-learning based mapping. InPLDI, 2009. [39] C.vonPraun,R.Bordawekar, andC. Cascaval. \nModeling optimistic concurrency using quantitative dependence analysis. In PPoPP, 2008. [40] J. Wloka, \nM. Sridharan, and F. Tip. Refactoring for reentrancy. In FSE, 2009. [41] P. Wu, A. Kejariwal, and C. \nCas\u00b8caval. Compiler-driven dependence pro.ling to guide program parallelization. InLCPC, 232 248. 2008. \n[42] B. Xin, and X. Zhang. Ef.cient online detection of dynamic control dependence. InISSTA, 2007. [43] \nX. Zhang, A. Navabi, and S. Jagannathan. Alchemist: A transparent dependence distance pro.ling infrastructure. \nInCGO, 2009. [44]Y.Zhang,andR.Gupta. Timestamped wholeprogrampathrepresen\u00adtation and its applications. \nIn PLDI, 2001. [45] Q. Zhao, D. Bruening, and S. Amarasinghe. Umbra: Ef.cient and scalable memory shadowing. \nInCGO, 2010. [46] H. Zhong, M. Mehrara, S. Lieberman, and S. Mahlke. Uncovering hidden loop level parallelism \nin sequential applications. In HPCA, 2008.  \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Many recent parallelization tools lower the barrier for parallelizing a program, but overlook one of the first questions that a programmer needs to answer: <i>which parts of the program should I spend time parallelizing</i>?</p> <p>This paper examines Kremlin, an automatic tool that, given a serial version of a program, will make recommendations to the user as to what regions (e.g. loops or functions) of the program to attack first. Kremlin introduces a novel <i>hierarchical critical path analysis</i> and develops a new metric for estimating the potential of parallelizing a region: <i>self-parallelism</i>. We further introduce the concept of a <i>parallelism planner</i>, which provides a ranked order of specific regions to the programmer that are likely to have the largest performance impact when parallelized. Kremlin supports multiple <i>planner personalities</i>, which allow the planner to more effectively target a particular programming environment or class of machine.</p> <p>We demonstrate the effectiveness of one such personality, an OpenMP planner, by comparing versions of programs that are parallelized according to Kremlin's plan against third-party manually parallelized versions. The results show that Kremlin's OpenMP planner is highly effective, producing plans whose performance is typically comparable to, and sometimes much better than, manual parallelization. At the same time, these plans would require that the user parallelize significantly fewer regions of the program.</p>", "authors": [{"name": "Saturnino Garcia", "author_profile_id": "81100378592", "affiliation": "University of California, San Diego, La Jolla, CA, USA", "person_id": "P2690621", "email_address": "sat@cs.ucsd.edu", "orcid_id": ""}, {"name": "Donghwan Jeon", "author_profile_id": "81453639831", "affiliation": "University of California, San Diego, La Jolla, CA, USA", "person_id": "P2690622", "email_address": "djeon@cs.ucsd.edu", "orcid_id": ""}, {"name": "Christopher M. Louie", "author_profile_id": "81453654901", "affiliation": "University of California, San Diego, La Jolla, CA, USA", "person_id": "P2690623", "email_address": "cmlouie@ucsd.edu", "orcid_id": ""}, {"name": "Michael Bedford Taylor", "author_profile_id": "81100517791", "affiliation": "University of California, San Diego, La Jolla, CA, USA", "person_id": "P2690624", "email_address": "mbtaylor@ucsd.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993553", "year": "2011", "article_id": "1993553", "conference": "PLDI", "title": "Kremlin: rethinking and rebooting gprof for the multicore age", "url": "http://dl.acm.org/citation.cfm?id=1993553"}