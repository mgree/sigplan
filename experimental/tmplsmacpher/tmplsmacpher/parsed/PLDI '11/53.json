{"article_publication_date": "06-04-2011", "fulltext": "\n Composable Asynchronous Events Lukasz Ziarek, KC Sivaramakrishnan, Suresh Jagannathan Purdue University \n {lziarek, chandras, suresh}@cs.purdue.edu Abstract Although asynchronous communication is an important \nfeature of many concurrent systems, building composable abstractions that leverage asynchronyis challenging. \nThis is because an asyn\u00adchronous operation necessarily involves two distinct threads of control the \nthread that initiates the operation, and the thread that discharges it. Existing attempts to marry composability \nwith asynchrony either entail sacri.cing performance (by limiting the degree of asynchronypermitted), \nor modularity (by forcing natural abstraction boundaries to be broken). In this paper, we present the \ndesign and rationale for asynchronous events, an abstraction that enables composable construction of \ncomplex asynchronous protocols without sacri.cing the bene.ts of abstraction or performance. Asynchronous \nevents are realized in the context of Concurrent ML s .rst-class event abstraction [16]. We discuss the \nde.nition of a number of useful asynchronous ab\u00adstractions that can be built on top of asynchronous events \n(e.g., composable callbacks) and provide a detailed case study of how asynchronous events can be used \nto substantially improve the modularity and performance of an I/O-intensive highly concurrent server \napplication. Categories and Subject Descriptors: D.1.1 [Programming Tech\u00adniques] Applicative (functional) \nprogramming; D.3.1[Program\u00adming Languages]:Formal De.nitions and Theory; D.3.2[Pro\u00adgramming Languages]:Language \nClassi.cations-Concurrent, dis\u00adtributed, and parallel languages, ML; D.3.3[Programming Lan\u00adguages]: Language \nConstructs and Features -Concurrent program\u00adming structures General Terms: Design, Languages, Theory \nKeywords: Asynchrony, Concurrent ML, First-Class Events, Com\u00adposability, Message-Passing 1. Introduction \nSoftware complexity is typically managed using programming ab\u00adstractions that encapsulate behaviors within \nmodules.Amodule s internal implementation can be changed without requiring changes to clients that use \nit, provided that these changes do not entail modi\u00adfying its signature.For concurrent programs, the speci.cations \nthat can be described by an interface are often too weak to enforce this Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page.To copyotherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, \nUSA. Copyright c &#38;#169; 2011ACM 978-1-4503-0663-8/11/06... $10.00 kind of strong encapsulation, especially \nin the presence of commu\u00adnication that spans abstraction boundaries. Consequently,changing the implementation \nof a concurrencyabstraction by adding, modi\u00adfying, or removing behaviors often requires pervasivechange \nto the users of the abstraction. Modularity is thus compromised. This is particularly true for asynchronous \nbehavior generated in\u00adternally within a module. An asynchronous operation initiates two temporally distinct \nsets of actions, neither of which are exposed in its enclosing module s interface. The .rst set de.nes \npost-creation actions these are actions that must be executed after an asyn\u00adchronous operation has been \ninitiated, without taking into account whether the effects of the operation have been witnessed by its \nre\u00adcipients. For example, a post-creation action of an asynchronous send on a channel might initiate \nanother operation on that same channel; the second action should take place with the guarantee that the \n.rst has already deposited its data on the channel. The sec\u00adond are post-consumption actions these de.ne \nactions that must be executed only after the effect of an asynchronous operation has been witnessed.Forexample,a \npost-consumption action mightbe a callback that is triggered when the client retrieves data from a channel \nsent asynchronously. Inthispaper, we describehowtobuildand maintain asynchronous concurrency abstractions \nthat give programmers the ability to express composable and extensible asynchronous protocols. By weaving \nprotocols through the use of post-creation and post\u00adconsumption computations, we achieve composability \nwithout sac\u00adri.cing modularity,enabling reasoning about loosely coupled com\u00admunication partners that \nspan logical abstraction boundaries. To do so, we enable the construction of signatures and interfaces \nthat specify asynchronous behavior via abstract post-creation and post\u00adconsumption actions.We present \nourextensionsin the contextof the ConcurrentML s (CML) .rst-class communicationevents [16]. Just as CML \ns synchronous events provide a solution to compos\u00adable, synchronous message-passing that could not be \neasily ac\u00adcommodated using .-abstraction and application, the asynchronous events de.ned here offer a \nsolution for composable asynchronous message-passing not easilyexpressible using synchronous commu\u00adnication \nand explicit threading abstractions. There are three over\u00adarching goals of our design: 1. Asynchronous \ncombinators should permit uniform composition of pre/post-creation and consumption actions. This means \nthat protocols should be allowed to extend the behavior of an asyn\u00adchronous action both with respect \nto the computation performed before and after it is created and consumed. 2. Asynchronous actions should \nprovide sensible visibility and or\u00addering guarantees.Apost-creation computation shouldexecute with the \nguarantee that the asynchronous action it follows has been created, even if that action has not been \nfully discharged. The effects of consumed asynchronous actions should be con\u00adsistent with the order in \nwhich they were created.   spawn : (unit -> a) -> threadID sendEvt : a chan * a -> unit Event recvEvt \n: a chan -> a Event alwaysEvt : a -> a Event never : a Event sync : a Event -> a wrap : a Event * ( a \n-> b) -> b Event guard : (unit -> a Event) -> a Event choose : a Event list -> a Event Figure 1: CML \nevent operators. 3. Communication protocols should be agnostic with respect to the kinds of actions they \nhandle. Thus, both synchronous and asynchronous actions should be permitted to operate over the same \nset of abstractions (e.g., communication channels). Contributions. 1. We present a comprehensive design \nfor asynchronous events, and describe a family of combinators analogous to their syn\u00adchronousvariantsavailablein \nCML.Tothe bestof ourknowl\u00adedge, this is the .rst treatment to consider the meaningful inte\u00adgrationof \ncomposable CML-styleevent abstractions with asyn\u00adchronous functionality.  2. We provide implementations \nof useful asynchronous abstrac\u00adtions such as callbacks and mailboxes (buffered channels), along with \na number of case studies extracted from realistic concurrent applications (e.g., a concurrent I/O library, \nconcur\u00adrent .le processing, etc.). Our abstractions operate over ordi\u00adnary CML channels, enabling interoperability \nbetween syn\u00adchronous and asynchronous protocols.  3. We discuss an implementation of asynchronous events \nthat has been incorporated into Multi-MLton, a parallel extension of MLton [14], a whole-program optimizing \ncompiler for Stan\u00addard ML, and present a detailed case study that shows how asynchronous events can help \nimprove the expression and per\u00adformance of highly concurrent server application.  The paper is organized \nas follows. Sec. 2 provides a brief intro\u00adduction to Concurrent ML. Additional motivation for asynchronous \neventsisgivenin Sec.3. Sec.4describes the asynchronous com\u00adbinators and abstractions we support. Sec.5givesa \nformal opera\u00adtional semanticsfor asynchronousevents.Adetailed casestudyis presented in Sec. 6. Related \nwork and conclusions are provided in Sec.7and Sec.8. 2. Background: Concurrent ML Context: We explore \nthe design of asynchronous events in the contextof ConcurrentML[16] (CML).CMLisaconcurrentexten\u00adsion \nof Standard ML that utilizes synchronous message passing to enable the construction of synchronous communication \nprotocols. Threads perform send and recv operations on typed channels; these operationsblock untila matching \nactiononthe same channel is performedby another thread. CML also provides .rst-class synchronous events \nthat abstract syn\u00adchronous message-passing operations. An event value of type a event when synchronized \non yields a value of type a . An event value represents a potential computation, with latent effect until \na thread synchronizes uponitby calling sync . The following equiv\u00adalences thus therefore hold: send(c, \nv) = sync(sendEvt(c,v)) and recv(c) = sync(recvEvt(c)) . Notably, thread creation is not encoded as an \nevent the thread spawn primitive simply takes a thunk to evaluate as a separate thread, and returns \na thread identi.er that allows access to the newly created thread s state. Besides sendEvt and recvEvt \n, there are other base events pro\u00advided by CML. The never event, as its name suggests, is never available \nfor synchronization; in contrast, alwaysEvt is always available for synchronization. These events are \ntypically generated based on the (un)satis.ability of conditions or invariants that can be subsequently \nused to in.uence the behavior of more complex eventsbuilt from theevent combinators described below. \nMuch of CML s expressive power derives from event combina\u00adtors that construct complexeventvalues from \notherevents.We list some of these combinators in Fig. 1. The expression wrap (ev, f) creates an event \nthat, when synchronized, applies the result of synchronizing on event ev to function f . Conversely, \nguard(f) creates an event that, when synchronized, evaluates f() to yield event ev and then synchronizes \non ev . The choose event com\u00adbinator takes a list of events and constructs an event value that rep\u00adresents \nthe non-deterministic choice of the events in the list; for example, sync(choose[recvEvt(a),sendEvt(b,v)]) \nwill ei\u00adther receive a unit value from channel a , or send value v on chan\u00adnel b . Selective communication \nprovided by choice motivates the need for .rst-class events. We cannot, for example, simply build complex \nevent combinators using function abstraction and com\u00adposition because function closures do not allow \ninspection of the computations theyencapsulates, a necessary requirement for com\u00adbinators like choice \n. 3. Motivation Given CML synchronous events, we can envision a simple way to express asynchronyin terms \nof lightweight threads that encapsulate synchronous operations: fun asyncEvt (evt) = wrap(alwaysEvt(), \nfn() => spawn(sync(evt))) Evaluating asyncEvt(evt) yields an event that, when synchro\u00adnized,spawnsanew \nthreadto performthe actions de.nedby evt . (The use of alwaysEvt ensures that the event is always available \nfor synchronization.) Thus, fun asend(c,v) = sync(asyncEvt(sendEvt(c,v))) de.nes a function that asynchronously \nsends value v on channel c ,when applied.The useofexplicit user-de.ned threadstoexpress asynchronyinthisway,however,failstoprovide \nsensible ordering guarantees.Forexample,in theexpression: let val evt1 = asend(c,v) val evt2 = asend(c,v \n) in recvEvt(c) end the value returned when this expression is synchronized may be either v or v (depending \non the implementation of the underly\u00ading thread scheduler), even though evt1 is synchronized before evt2 \n. Besides not preserving desired ordering, there are more fundamen\u00adtal issues at play here. Suppose we \nwish to add post-creation and post-consumption actions to an asynchronous event; post-creation actions \nare to be performed once the thread is spawned, and post\u00adconsumptions actions must be performed once \nthe communication actionis complete.Wecouldmodifythe de.nitionof asyncEvt so that post-creation and post-consumption \nactions are supplied when the event is constructed:  Figure 2: The .gure shows theeventsbuiltupby the \nthree modules that comprise our abstract server. The events created by the processor and con\u00adnection \nmanager,depicted with thick squares,are opaque to the orchestrator and cannot be deconstructed. Notably, \nthis means the orchestrator does not have the ability to modify or extend the behavior of the thread \ncreated by processorEvt (shown in grey) using only synchronous event combina\u00adtors. fun asyncEvt(f,g,evt) \n= wrap(alwaysEvt(), fn() => (spawn(fn() => sync(wrap(evt, f))); g())) Giventhis de.nition,an asynchronoussendeventmightbe \nde.ned to perform a post-consumption action, here f (e.g., an action that waits for an acknowledgment \nindicating the sent data was received with no errors). Similarly, the event may be equipped with a post\u00adcreation \naction, here g (e.g., an operation that performs local clean\u00adup or .nalization). To illustrate the composability \nand modularity issues that arise in using asyncEvt de.ned in this way, consider the de.nition of a simple \nresource manager (like a web-server) that consists of three modules: (1)a connection manager that listens \nfor and accepts new connections, (2)a processor that processes and sends data based on input requests, \nand (3) an orchestrator that enables different kinds of interactions and protocols among clients, the \nprocessor, and the connection manager. If each established connection represents an independent group \nof actions (e.g., requests), we can leverage asynchronyto allow multiple requests to be serviced concurrently. \nWe discuss this design in more detail in Sec. 6. Onesimple de.nitionofan orchestratorisa procedurethat \nchooses between the communication event de.ned by the processor (call it processorEvt)and the connection \nmanager (call itmanagerEvt). Suppose processorEvt internally leveraged our de.nition of asyncEvt to perform \na send asynchronously and then executed some post-creation action g and post-consumption action f. Even \nifthe detailsofthe communication protocolusedbythe connection manager and processor were visible to the \norchestrator, the orches\u00adtrator would not be able to change their internal functionality since they are \nencapsulated within events, which abstract the computa\u00adtion actions and effects theyperform. Nonetheless, \nthe orchestrator is still free to augment these protocols to yield additional behavior. For example, \nthe following de.nition: fun orchestrate(processorEvt, managerEvt) = sync(choose([processorEvt, managerEvt])) \nuses choiceto non-deterministically select whichevereventisavail\u00adable to be synchronized against. This \nde.nition allows the execu\u00adtion of the managerEvt if a new connection is available, or the processorEvt \nif the current input request has been satis.ed, or a non-deterministic choice among the two if both can \nexecute. Figure 3: The .gure shows how asynchronous events can alleviate the problems illustrated in \nFig. 2. By making creation and consumption actions explicit in processorEvt s de.nition, we are able \nto specify logRequestEnd as a post consumption action correctly extending the pro\u00adtocol in the orchestrator. \nUnfortunately,composing moreexpressiveasynchronous protocols in this way is dif.cult. To see why, consider \na further modi.ca\u00adtion to the orchestrator that incorporates logging information.We can wrap our processor \nevent with a function that logs requests and our connection manager with one that logs connection de\u00adtails. \nThe guard event combinator can be used to specify pre\u00adsynchronization actions. In this example, these \nactions would be logging functions that record the startofa connection or request. 1 fun orchestrate(processorEvt, \nmanagerEvt) = sync(choose([guard(fn () => logRequestStart(); wrap(processorEvt, logRequestEnd)), guard(fn \n() => logConnStart(); wrap(managerEvt, logConnEnd))])) This code does not provide the functionality we \ndesire, however. Since the processor handles its internal protocols asynchronously, wrapping logRequestEnd \naround processorEvt speci.es an ac\u00adtion that will occur in the main thread of control after the exe\u00adcution \nof g , the post-creation action de.ned when the event was created (see Fig. 2). However, the request \nshould only be com\u00adpleted after the post-consumption action f , which is executed by the thread created \ninternally by the event. Since this thread is hid\u00adden bytheevent, thereisnowaytoextendit. Moreover, thereis \nno guarantee that the request has been successfully serviced even after g completes.We could recover \ncomposabilityby either (a) not spawning an internal thread in asyncEvt , (b) weaving a pro\u00adtocol that \nrequired g to wait for the completion of f , effectively yielding synchronous behavior, or (c) modifying \nprocesorEvt and managerEvt to handle the post-consumption action explic\u00aditly. The .rst two approaches \nforce f and g tobeexecuted priorto logRequestEnd,but a synchronous solution of this kind would not allow \nmultiple requests to be processed concurrently; approach (c) retains asynchrony,but at the cost of modularity, \nrequiring server functionality to be modi.ed anytime clients wish to express addi\u00adtional behaviors. The \nheart of the problem is a dichotomy in language abstractions; asynchrony is fundamentally expressed using \ndistinct threads of control, yet composablity is achieved through event abstractions that are thread-unaware. \nThe result is that CML events cannot be directly applied to build post-consumption actions for realizing \ncomposable asynchronous communication protocols. Fig. 3 diagrammatically shows how extensible post-creation \nand post-consumption actions can be leveraged to achieve our desired 1In CML, we could also use the withNack \ncombinator to avoid .ring both the logRequestStart and logConnStart during the choice [16].  behavior.In \nSection4.1,weshowamodi.ed implementationofthe orchestrator using the asynchronous event primitives and \ncombina\u00adtors we de.ne in the following section that captures the behavior shown in the .gure. Putting \nit All Together. Although synchronous .rst-class events alleviate the complexity of reasoning about arbitrary \nthread in\u00adterleavings, and enable composable synchronous communication protocols, using threads to encode \nasynchrony unfortunately re\u00adintroduces these complexities. Our design introduces .rst-class asynchronous \nevents with the following properties to alleviate this drawback: (i)theyareextensible both with respecttopre-and \npost\u00adcreation as well as pre-and post-consumption actions; (ii) theycan operate over the same channels \nthat synchronous events operate over, allowing both kinds of events to seamlessly co-exist; and, (iii) \ntheir visibility, ordering, and semantics is independent of the underlying runtime and scheduling infrastructure. \n4. Asynchronous Events In order to provide primitives that adhere to the desired proper\u00adties outlined \nabove, we extend CML with the following two base events: aSendEvt and aRecvEvt ,to create an asynchronous \nsend event and an asynchronous receive event, resp. The differences in their type signature from their \nsynchronous counterparts re.ect the split in the creation and consumption of the communication action \ntheyde.ne: sendEvt : a chan * a -> unit Event aSendEvt : a chan * a -> (unit, unit) AEvent recvEvt : \na chan -> a Event aRecvEvt : a chan -> (unit, a) AEvent An AEvent value is parametrized with respect \nto the type of the event s post-creation and post-consumption actions.In the case of aSendEvt , both \nactions are of type unit :when synchronized on, theevent immediately returnsa unit value and places its \na argu\u00adment value on the supplied channel. The post-consumption action also yields unit . When synchronized \non, an aRecvEvt returns unit ;the type of its post-consumption action is a re.ecting the type of value \nread from the channel when it is paired with a send. As an example, consider Fig 3, where the processorEvt \nevent upon synchronization initiates an asynchronous action to place the value v on channel c and then \nexecutes g . When the send is paired with a receive, f is .rst executed, and then logRequestEnd. In this \ncase, the type of the computation would be: (return-type-of g, return-type-of logRequestEnd) AEvent The \nsemantics of both asynchronous send and receive guarantees that successive communication operations performed \nby the same thread get witnessed in the order in which they were issued. In this respect, an asynchronous \nsend event shares functionality with a typical non-blocking send of the kind found in languages like \nEr\u00adlang [1] or libraries like MPI. However, an asynchronous receive does not exhibit the same behavior \nas a typical non-blocking re\u00adceive. Indeed, CML already provides polling methods that can be used to \nimplement polling loops found in most non-blocking re\u00adceive implementations. The primary difference between \nthe two is that an asynchronous receive places itself on the channel at the point where it is synchronized \n(regardless of the availability of a matching send), while a non-blocking receive typically only queriesfortheexistenceofavalueto \nmatchagainst,butdoesnot alter the underlying channel structure. By actually depositing itself on the \nchannel, an asynchronous receivethus providesaconvenient mechanism to implement ordered asynchronousbuffers \nor streams Figure 4: The .gure shows a complex asynchronous event ev ,built from a base aSendEvt , being \nexecuted by Thread 1. When the event is syn\u00adchronized via. aSync , the value v is placed on channel c \nand post\u00adcreation actionsareexecuted(see(a)). Afterwards, control returnsto Thread 1. When Thread2consumes \nthevalue v from channel c ,an implicit thread of control is created to execute anypost-consumption actions \n(see (b)). successive asynchronous receives are guaranteed to receive data fromamatchingsendintheorderinwhichtheywere \nsynchronized. In addition to these new base events, we also introduce a new synchronization primitive: \naSync , to synchronize asynchronous events. The aSync operation .res the computation encapsulated by \nthe asynchronouseventof type ( a, b) AEvent and returns a value of type a , corresponding to the return \ntype of the event s post-creation action (see Fig. 4). sync : a Event -> a aSync : ( a, b) AEvent -> \na Unlike their synchronous variants, asynchronous events do not blockif no matching communicationis present.Forexample,exe\u00adcuting \nan asynchronous send event on an empty channel places the value being sent on the channel and then returns \ncontrol to the exe\u00adcuting thread (see Fig. 4(a)). In order to allowthis non-blocking be\u00adhavior, an implicit \nthread of control is created for the asynchronous event when the event is paired, or consumed as shown \nin Fig. 4(b). Ifa receiveris presentonthe channel,the asynchronoussendevent behaves similarly to a synchronous \nevent; it passes the value to the receiver.However,itstill createsa new implicit threadof controlif there \nare anypost-consumption actions to be executed. Similarly, the synchronization of an asynchronous receive \nevent does not yield the value received (see Fig. 5); instead, it sim\u00adply enqueues the receiving action \non the channel. Therefore, the thread which synchronizes on an asynchronous receive always gets the value \nunit, even if a matching send exists. The actual value consumed by the asynchronous receive can be passed \nback to the thread which synchronized on the event through the use of com\u00adbinators that process post-consumption \nactions. This is particu\u00adlarly well suited to encode reactive programming idioms: the post\u00adconsumption \nactions encapsulate a reactive computation. Toillustrate the differences between synchronous and asynchronous \nprimitive events, consider the two functions f and af shown be\u00adlow: 1.fun f()= 2. (spawn (fn () => sync \n(sendEvt(c, v))); 3. sync (sendEvt(c, v )); 4. sync (recvEvt(c))) 5. fun af ()= 6. (spawn (fn () \n=> sync (sendEvt(c, v))); 7. aSync (aSendEvt(c, v )); 8. sync (recvEvt(c)))   Figure 5: The .gure \nshows a complex asynchronous event ev ,built from a base aRecvEvt , being executed by Thread 1. When \nthe event is syn\u00adchronized via aSync , the receive action is placed on channel c and post\u00adcreation actionsareexecuted(see(a)). \nAfterwards, control returnsto Thread 1. When Thread2sends thevalue v to channel c , an implicit thread \nof control is created to execute any post-consumption actions passing v as the argument (see (b)). The \nfunction f , if executed in a system with no other threads will always block because there is no recipient \navailable for the send of v on channel c . On the other hand, suppose there was another thread willing \nto accept communication on channel c . In this case, the only possible value that f could receive from \nc is v . This occurs because the receive will only happen after the value v is consumed from the channel. \nNotice that if the spawned thread enqueues v on the channel before v , the function f will block evenif \nanotherthreadiswillingtoreceiveavaluefromthechannel, since a function cannot synchronize with itself. \nThe function af will never block. The receive may see either the value v or v since the asynchronous \nsend event only asserts that the value v has been placed on the channel and not that it has been consumed. \nIf we swapped lines 6 and 7, the receive operation on line 8 is guaranteed to read v . While asynchronous \nevents do not block, theystill enforce ordering constraints that re.ect the order in which theywere synchronized. \n 4.1 Combinators In CML, the wrap combinator allows for the speci.cation of a post-synchronization action. \nOnce the event is completed the function wrappingtheeventisevaluated.For asynchronousevents, this means \nthe wrapped function is executed after the action the event encodes is placed on the channel and not \nnecessarily after that action is consumed. sWrap : ( a, b) AEvent * ( a -> c) -> ( c, b) AEvent aWrap \n: ( a, b) AEvent * ( b -> c) -> ( a, c) AEvent To allow for the speci.cation of both post-creation and \npost\u00adconsumption actions for asynchronous events, we introduce two new combinators: sWrap and aWrap . \nsWrap is used to specify post-creation actions. The combinator aWrap , on the other hand, is usedtoexpress \npost-consumption actions.We can apply sWrap and aWrap to an asynchronous event in anyorder. sWrap(aWrap(e, \nf) g) = aWrap(sWrap(e, g), f) We can use sWrap and aWrap to encode a composable variant of asyncEvt (presented \nin the motivation) whichis also parameter\u00adized by a channel c and value v .We create a base asynchronous \nsend event to send v on c and use sWrap and aWrap to specify g and f as a post-creation action and a \npost-consumption action, resp.: fun asyncEvt(f,g,c,v) = aWrap(sWrap(aSendEvt(c,v),g), f) Since post-creation \nactions have been studied in CML extensively (theyactas post-synchronization actionsinasynchronous context), \nwe focus our discussion on aWrap and the speci.cation of post\u00adconsumption actions. Consider the following \nprogram fragment: fun f() = let val = channel() clocal in aSync (aWrap(aSendEvt(c, v),fn () => send(clocal \n, ()))); g(); recv(clocal ); h() end The function f .rst allocates a local channel clocal and then exe\u00adcutes \nan asynchronous send aWrap -ed with a function that sends on the local channel. The function f then proceedstoexecute \nfunc\u00adtions g and h with a receive on the local channel between the two function calls.Weuse the aWrap \nprimitiveto encodeasimple bar\u00adrier based on the consumption of v .We are guaranteed that h ex\u00adecutes \nin a context in which v has been consumed. The function g , on the other hand, can make no assumptions \non the consump\u00adtion of v . However, g is guaranteed that v is on the channel. Therefore, if g consumes \nvalues from c , it can witness v and, similarly, if it places values on the channel, it is guaranteed \nthat v will be consumed prior to the values it produces. Of course, v could always have been consumed \nprior to g s evaluation. If the same code was written with a synchronous wrap, we would have no guarantee \nabout the consumption of v .Infact, the codewould block, as the send encapsulated by the wrap would be \nexecuted by the same thread of control executing f . Thus, the asynchronous event implicitly creates \na new evaluation context and a new thread of control;the wrapping functionisevaluatedinthis context,notin \nthe context associated with thread that performedthe synchroniza\u00adtion. This simple example illustrates \nthe essential ingredients of a ba\u00adsic callback mechanism. The code shown below performs an asyn\u00adchronous \nreceive and passes the result of the receive to its wrapped function. The value received asynchronously \nis passed as an argu\u00adment to h by sending on the channel clocal . let val = channel() clocal in aSync \n(aWrap(aRecvEvt(c), fn x => send(clocal , x))); ... h(recv(clocal )) ... end Although this implementation \nsuf.ces as a basic callback, it is not particularly abstract and cannot be composed with other asyn\u00adchronousevents.We \ncan create an abstract callback mechanism us\u00ading both sWrap and aWrap around an input event. callbackEvt \n: ( a, c) AEvent * ( c -> b) -> ( b Event, c) AEvent fun callbackEvt(ev, f) = let val = channel() clocal \nin sWrap(aWrap(ev, fn x => (aSync(aSendEvt(clocal , x)); x)), fn => wrap(recvEvt(clocal ), f)) end If \nev contains post-creation actions when the callback event is synchronized on, they are executed, followed \nby execution of the sWrap as shown in Fig. 6(a). The event returned by the sWrap (call it ev ),which \nwhen synchronized on will .rst receiveavalue on the local channel(clocal)and then apply the function \nf to this value. Synchronizing on this event (which need not happen at the point where the callback event \nitself is synchronized) will subse\u00adquently block until the event ev is discharged. Once ev com\u00adpletes, \nits post-consumption actions are executed in a new thread of control since ev is asynchronous (see Fig. \n6(b)). The body of  Figure 6: The .gure shows a callback event constructed from a complex asynchronous \nevent ev and a callback function f . When the callback event is synchronized via aSync , the action associated \nwith the event ev is placed on channel c and post-creation actions areexecuted.A new event ev is createdandpassedto \nThread1(see(a)).An implicit threadof controlis createdafterthebaseeventof ev is consumed. Post-consumption \nactions are executed passing v , the result of consuming the base event for ev , as an argument (see \n(b)). The result of the post-consumption actions, v is sent on clocal . When ev is synchronized upon, \nf is called with v (see (c)). the aWrap -ed function simply sends the result of synchronizing on ev (call \nit v )on clocal and then passes the value v to any further post-consumption actions. Thisis done asynchronously \nbe\u00adcause the complexevent returnedby callbackEvt can be further extended with additional post consumption \nactions. Those actions should not be blocked if there is no thread willing to synchronize on ev .Thus, \nsynchronizingona callbackeventexecutesthebase event associated with ev and createsanewevent asapost-creation \naction, which when synchronized on, executes the callback func\u00adtion synchronously. Wecan thinkofthedifference \nbetweenacallbackandan aWrap of an asynchronous event in terms of the thread of control which ex\u00adecutes \nthem. Both specify a post-consumption action for the asyn\u00adchronousevent,butthe callback,when synchronized \nupon,isexe\u00adcuted potentially by an arbitrary thread whereas the aWrap is al\u00adways executed in the implicit \nthread created when the asynchronous event is consumed. Another difference is that the callback can be \npostponed and only executes when two conditions are satis.ed: (i) the asynchronous event has completed \nand (ii) the callback is syn\u00adchronized on. An aWrap returns once it has been synchronized on, and does \nnot need to wait for other asynchronous events or post\u00adconsumption actions it encapsulates to complete. \nA guard of an asynchronous event behaves much the same as a guardofa synchronousevent does;it speci.es \npre-synchronization actions (i.e. pre-creation computation): aGuard : (unit -> ( a, b) AEvent) -> ( a, \nb) AEvent To see how we might use asynchronous guards, notice that our de.nition of callbackEvt has the \ndrawback that it allocates a new local channel regardless of whether or not the event is ever synchronized \nupon. The code belowuses an aGuard to specify the allocation of the local channel only when the event \nis synchronized on: fun callbackEvt(ev, f) = aGuard(fn () => let val = channel() clocal in sWrap(aWrap(ev, \nfn x => (aSync(aSendEvt(clocal , x));x)), fn => wrap(recvEvt(clocal ), f)) end) Figure 7: The .gure \nshows Thread 1 synchronizing on a complex asyn\u00adchronous event ev ,built from a choice between two base \nasynchronous sendevents; one sending v on channel c and the other v on c . Thread 2is willing to receive \nfrom channel c . One of the most powerful combinators provided by CML is a non\u00addeterministic choice over \nevents. The combinator choose picks an active event from a list of events. If no events are active, it \nwaits until one becomes active. An active event is an event which is available for synchronization. We \nde.ne an asynchronous ver\u00adsion of the choice combinator, aChoose , that operates over asyn\u00adchronous events. \nSince asynchronous events are non-blocking, all eventsinthe list are consideredactive. Therefore, the \nasynchronous choice always non-deterministically chooses from the list of avail\u00adable asynchronousevents.We \nalso providea synchronousversion of the asynchronous choice, sChoose , which blocks until one of the \nasynchronous baseevents has been consumed. Post-creation ac\u00adtions are notexecuted until the choice has \nbeen made. 2 choose : a Event list -> a Event aChoose : ( a, b) AEvent list -> ( a, b) AEvent sChoose \n: ( a, b) AEvent list -> ( a, b) AEvent To illustrate the difference between aChoose and sChoose , con\u00adsider \na complex event ev de.ned as follows: val ev = aChoose[aSendEvt(c, v), aSendEvt(c ,v )] If there exists \na thread only willing to receive from channel c , aChoose will, with equal probability, execute the asynchronous \nsend on c and c (see Fig. 7). However, if we rede.ned ev to utilize sChoose instead, the behavior of \nthe choice changes: val ev = sChoose[aSendEvt(c, v), aSendEvt(c ,v )] Since sChoose blocksuntiloneofthebase \nasynchronouseventsis satis.able,if thereisonlyathreadwillingto accept communication on c (seeFig.7),the \nchoicewillonly selecttheevent encodingthe asynchronous send on c . We have thus far provided a mechanism \nto choose between sets of synchronous events and sets of asynchronous events. However, we would like \nto allow programmers to choose between both syn\u00adchronous and asynchronous events. Currently, their different \ntype structure would prevent such a formulation. Notice, however, that an asynchronous event with type \n( a, b) AEvent and a syn\u00adchronous event with type a Event both yield a in the thread which synchronizes \non them. Therefore, it is sensible to allow choice to operate over both asynchronous and synchronous \nevents provided the type of the asynchronous event s post-creation action is the same as the type encapsulatedby \nthe synchronousevent.To facilitate this interoperability, we provide combinators to transform asynchronous \nevent types to synchronous event types and vice\u00adversa: aTrans : ( a, b) AEvent -> a Event sTrans : a \nEvent -> (unit, a) AEvent 2This behavior is equivalent to a scheduler not executing the thread which \ncreated the asynchronous action until it has been consumed.  The aTrans combinator takes an asynchronous \nevent and creates asynchronousversionbydropping the asynchronous portion of the event from the type (i.e. \nencapsulating it). As a result, we can no longer specify post-consumption actions for the event. However, \nwe can still apply wrap to specify post-creation actions to the resulting synchronous portion exposed \nby the a Event . Asyn\u00adchronous events that have been transformed and are part of a larger choose event \nare only selected if their base event is satis.able. Therefore, the following equivalence holds for two \nasynchronous events, aEvt1 and aEvt2 : choose[aTrans(aEvt1), aTrans(aEvt2)] = aChoose[aEvt1, aEvt2] The \nsTrans combinator takes a synchronous event and changes it into an asynchronous event with no post-creation \nactions. The wrapped computation of the original event occurs now as a post\u00adconsumption action. We can \nencode an asynchronous version of alwaysEvt from its synchronous counterpart. Similarly, we can encode \nan asynchronous variant of never . aAlwaysEvt : a -> (unit, a) AEvent aNever : (unit, a) AEvent aAlwaysEvt(v) \n= sTrans alwaysEvt(v) aNever = sTrans never Orchestrator revisited: Armed with asynchronousevents and \nthe combinators discussed above, we can now implement a compos\u00adable orchestrator module from our simple \nabstract server exam\u00adple given in Sec. 3. We use aGuard to specify pre-creation ac\u00adtions and aWrap for \nasynchronous post-consumption actions. If managerEvt de.nes a synchronous protocol (since it merely lis\u00adtens \nfor and accepts newconnects), and processorEvt de.nes an asynchronous one (since it can process and communicate \ndata con\u00adcurrently withother ongoing requests), we can use aTrans to hide its post-consumption actions \nfrom the orchestrator. This allows us to freely choose between the asynchronous processorEvt and the \nsynchronous managerEvt . fun orchestrate(processorEvt, managerEvt) = sync(choose([aTrans aGuard(fn () \n=> logRequestStart(); aWrap(processorEvt, logRequestEnd)), guard(fn () => logConnStart(); wrap(managerEvt, \nlogConnEnd))])) Mailboxes and Multicast: Using asynchronousevents we can en\u00adcode other CML structures \nsuch as mailboxes(i.e.,buffered chan\u00adnels with asynchronous send and synchronous receive semantics) and \nmulticasts channels, reducing code size and complexity. Asyn\u00adchronous events provide the components from \nwhich a mailbox structure can be de.ned, allowing the construction of mailboxes fromregularCML channels(afacilitynotavailableinCML),and \nproviding a mechanism to de.ne asynchronous send events on the mailbox trivially using the base asynchronous \nsend event. Having an asynchronous send event operation de.ned for mailboxes al\u00adlows for their use in \nselective communication. Additionally, asyn\u00adchronouseventsnowprovidethe abilityfor programmersto specify \npost-creation and post-consumption actions. Using asynchronous events, we reduced the original CML mailbox \nimplementation from 240 LOC to 70 LOC, with a corresponding 52% improvement in performance on synthetic \nstress tests exercising various producer/\u00adconsumer con.gurations. Similarly, we were able to express \nmul\u00adticast channels in 60 LOC, compared to 87 LOC in CML, with a roughly 19% improvement in performance. \n5. Semantics Our semantics(seeFig.8)is de.nedin termsofacore call-by-value functional language with threading \nand communication primitives. Communication between threads is achieved using synchronous channels and \nevents. Our language extends a synchronous-event core language with asynchronous constructs. For perspicuity, \nthe language omits many useful event combinators such as choose (and its variants); a semantics formalizing \nthe full set of combina\u00adtors discussedinthis paperisavailablein an accompanying techni\u00adcal report [19]. \nIn our syntax, v ranges over values, p over primitive event con\u00adstructors, and e over expressions. Besides \nabstractions, a value can be a message identi.er, used to track communication actions, a channel identi.er, \nor anevent context.Anevent context(e[])de\u00admarcateseventexpressions that arebuilt from asynchronousevents \nand their combinators 3 that are eventually supplied as an argu\u00adment to a synchronization action. The \nrules use function composi\u00adtion f .g = .x. f (g(x)) to sequenceevent actions and computations. The semantics \nalso includes a new expression form, {e1, e2}to denote asynchronous communication actions; the expression \ne1 corresponds to the creation (and post-creation) of an asyn\u00adchronous event, while e2 corresponds to \nthe consumption (and post-consumption) of an asynchronous event. For convenience, both synchronous and \nasynchronous events are expressed in this form.Fora synchronousevent, e2 simply corresponds to an unin\u00adteresting \naction.We refer to e1 as the synchronous portion of the event, the expression which is executed by the \ncurrent thread, and e2 as the asynchronous portion of the event, the expression which isexecutedbya newly \ncreated thread (see ruleSYNCEVENT). Aprogram state consistsofa setof threads(T ), a communication map(.), \nanda channel map(C). The communication map is used to track the state of an asynchronous action, while \nthe channel map records the state of channels with respect to waiting (blocked) ac\u00adtions.Evaluationis \nspeci.ed viaa relation(.)that maps one pro\u00adgram state to another. Evaluation rules are applied up to \ncommuta\u00adtivity of parallel composition(I). Encoding Communication: Acommunication action is split into \ntwo message parts: one corresponding to a sender and the other to a receiver. A send message part is, \nin turn, composed of two conceptual primitiveactions:a send act (sendAct(c, v))andasend wait (sendWait): \nsendAct :(ChannelId \u00d7 Val). MessageId . MessageId sendWait:MessageId . Val The send act primitive, when \nappliedtoamessage identi.er,places the value(v)on the channel(c), while the send wait, when applied to \na message identi.er, blocks until the value has been consumed off of the channel, returning unit when \nthe message has been consumed. The message identi.er m, generated for each base event (see rule SyncEvent \n)is used to correctly pair the act and wait . Similarly, a receive message part is composed of receive \nact (recvAct(c))and areceive wait (recvWait)primitives: recvAct :ChannelId . MessageId . MessageId recvWait:MessageId \n. Val A receive wait behaves as its send counterpart.A receive act re\u00admoves a value from the channel \nif a matching send action exists; 3We describe the necessity of a guarded event context when we introduce \nthe combinators later in this section.  e . Exp := v | x | pe | ee E := | Ee | vE | pE | sync E |{e, \ne'} | spawn e | sync e | ch() | sendEvt(E,e) | sendEvt(c, E) | sendEvt(e,e) | recvEvt(e) | aSendEvt(E, \ne) | aSendEvt(c,E) | aSendEvt(e, e) | aRecvEvt(e) | recvEvt(E) | aRecvEvt(E) | aWrap(e,e) | sWrap(e,e) \n| aGuard(e) | aWrap(E,e) | sWrap(E,e) | aWrap(v,E) | sWrap(v, E) v . Val := unit | c | m | .x. e | e[e] \n| aGuard(E) p . Prim := sendAct(c,v) | sendWait | recvAct(c) | recvWait m . MessageId T . Thread :=(t,e) \nc . ChannelId T . ThreadCollection := 0/ | T | T || T e[e], e[e]g . Event . . CommMap := MessageId . \nVal A . Action := Ar | As C . ChanMap := ChannelId . Action Ar . ReceiveAct := Rcm (T).,C . State := \n(T,CommMap,ChanMap) As . SendAct := Sm c,v APP CHANNEL SPAWN c fresh t' f resh ((t,E[(.x.e) v]) || T).,C \n. ((t,E[ch()]) || T).,C .((t,E[c]) || T).,C[c((t,E[spawn e]) || T).,C . o.0/] ((t,E[e[v/x]]) || T).,C \n((t',e) || (t,E[unit]) || T).,C SENDEVENT ASENDEVENT ((t, E[sendEvt(c,v)]) || T).,C .((t, E[aSendEvt(c, \nv)]) || T). . ((t,E[e[{sendWait . sendAct(c,v), .x.unit}]]) || T).,C ((t, E[e[{sendAct(c,v), sendWait \n}]]) || T).,C RECVEVENT ARECVEVENT ((t,E[recvEvt(c)]) || T).,C .((t, E[aRecvEvt(c)]) || T).,C . ((t, \nE[e[{recvWait . recvAct(c), .x.unit}]]) || T).,C ((t,E[e[{recvAct(c), recvWait}]]) || T).,C SYNCEVENT \nMESSAGE m f resh t' f resh '., Scm ,v . .[m o. unit] .,Rcm ,v . .[m o. v] ((t,E[sync e[{e, e'}]]) || \nT).,C .((t,E[em]) || (t, e' m) || T).,C SENDMATCH RECVMATCH '' C(c)= R m:Ar C(c)= Sm:As cc,v '' . .' \n.',R m, v . .'' .' ,v . .'' ., Sm .,Sm. .' ,R m c,vc c,vc ((t, E[(sendAct(c, v)) m]) || T).,C .((t,E[m]) \n|| T).'' ((t,E[(recvAct(c)) m]) || T).,C .((t, E[m]) || T).'' ,C[co.Ar ] ,C[co.As ] SENDBLOCK RECVBLOCK \nC (c)= As C ' = C [c o. As :Sm ] C(c)= Ar C' = C[c o. Ar :R m] c,vc ((t,E[(sendAct(c,v)) m]) || T).,C \n.((t,E[m]) || T).,C'((t,E[(recvAct(c)) m]) || T).,C .((t,E[m]) || T).,C' SENDWAIT RECEIVEWAIT .(m)= unit \n.(m)= v ((t, E[sendWait m]) || T).,C .((t, E[unit]) || T).,C ((t, E[recvWait m]) || T).,C .((t,E[v]) \n|| T).,C Figure 8: Acore language for asynchronous events. if none exists, it simply records the intention \nof performing the re\u00adceive on the channel queue.We can think of computations occur\u00adring after an act \nas post-creation actions and those occurring aftera wait as post-consumption actions. Splitting a communication \nmes\u00adsage part into an act and a wait primitive functions allows for theexpressionof manytypesof message \npassing.For instance,a traditional synchronoussendissimplythe sequencingofa send act followed by a send \nwait:sendWait . sendAct (c,v). This encod\u00ading immediately causes the thread executing the operation to \nblock after the value has been deposited on a channel, unless there is a matching receive act currentlyavailable.Asynchronous \nreceiveis encoded in much the same manner. We use the global communication map(.)to track act and wait \nactions for a given message identi.er. A message id is created at a synchronization point, ensuring a \nunique message identi.er for each synchronized event. Once a send or receive act occurs, . is updated \nto re.ect the value yielded by the act (see Rule MESSAGE)throughan auxiliary relation(.). When a send \nact occurs the communication map will hold a binding to unit for the corresponding message, but when \na receive act occurs the communication map binds the corresponding message to the value received.Thevaluesstoredinthe \ncommunicationmaparepassedto the wait actions corresponding to the message (Rules SEND WAIT andRECV WAIT). \nBase Events: There are four rules for creating base events, (SENDEVENT) and (RECVEVENT)for synchronous \nevents, and (ASENDEVENT) and (ARECVEVENT) for their asynchronous counterparts. From base act and wait \nactions, we de.ne asyn\u00adchronous events(e[{sendAct(c, v), sendWait}]). The .rst com\u00adponent of an asynchronous \nevent is executed in the thread in which the expression evaluates, and is the target of synchroniza\u00adtion(sync \n), while the second component de.nes the actual asyn\u00adchronous computation. For asynchronous events we \nsplit the act from the wait. Synchronous events can also be encoded using this notation: e[{sendWait \n. sendAct(c,v), .x.unit}]. In a syn\u00adchronous event both the act and its corresponding wait occur in the \nsynchronous portion of the event. The base asynchronous portion is simply a lambda that yields a unit \nvalue. Event Evaluation: As mentioned above,events are deconstructed bythe sync operatorinrule(S YNCEVENT).Itstripstheevent \ncon\u00adtext(e[]),generatesanewmessage identi.er for the baseevent, cre\u00adatesanewthreadof control,and triggerstheevaluationofthe \ninter\u00adnal expressions. The asynchronous portion of the event is wrapped in a new thread of control and \nplaced in the regular pool of threads. If theevent abstraction being synchronizedwas generatedbyabase \nsynchronous event, the asynchronous portion is an uninteresting value (e.g. , .x.unit). The newly created \nthread, in the case of an asynchronous event, will not be able to be evaluated further as it blocks until \nthe corresponding act for the base event comprising the complex asynchronous event is discharged. Communication \nand Ordering: There are four rules for com\u00admunicatingover channels(SENDMATCH,RECVMATCH,SEND-BLOCK, andRECVBLOCK. \nThe channel map(C)encodes abstract channel states mappingachanneltoasequenceof actions(A).This sequence \nencodesa FIFO queue and provides ordering between ac\u00adtions on the channel. The channel will have either \na sequence of send acts(As)or receive acts(Ar),but never both at the same time. This is because if there \nare, for example, send acts enqueued on it, a receive action will immediately match the send, instead \nof need\u00ading to be enqueued and vice versa (rulesSENDMATCH andRECV-MATCH). If a channel already has send \nacts enqueued on it, any thread wishing to send on the channel will enqueue its act and vice versa (rules \nSENDBLOCK)and (RECVBLOCK). After enqueueing its action, a thread can proceed with its evaluation. Ordering \nfor asynchronous acts and their post consumption actions as well as blocking of synchronous events is \nachieved by rules (SENDWAIT)and (RECVWAIT). Both rules block the evaluation of a thread until the corresponding \nact has been evaluated. In the case of synchronous events, this thread is the one that initiated the \nact; in the case of an asynchronous event, the thread that creates the act is different from the one \nthat waits on it, and the blocking rules only block the implicitly created thread. For example, the condition \n.(m)= unit in rule SENDWAIT is established either by rule SENDMATCH, in the case of a synchronous action \n(created by SENDEVENT), or rules SENDBLOCK and RECVMATCH for an asynchronous one (createdbyAS ENDEVENT). \nCombinators: Complexevents arebuilt from the combinators de\u00adscribed earlier; their de.nitions are shown \nin Figure 9.We de.ne twovariantsof wrap, SWRAP for specifyingextensionstothe syn\u00adchronous portion of \nthe event and AWRAP for specifying exten\u00adsion to the asynchronous portion of the event. In the case of \na synchronous event, we have SWRAP extend the event with post\u00adconsumption actions as the base event will \nperform both the act and wait in the synchronous portion of the event. Similarly, lever\u00adaging AWRAP on \na synchronous event allows for the speci.cation of general asynchronous actions.Ifthe baseeventis asynchronous, \nSWRAPexpressespost creation actionsand AWRAPpost consump\u00adtion actions. The speci.cation of the guard \ncombinator is a bit more complex. Since a guard builds an event expression out of a function, that whenexecuted \nyieldsanevent,the concreteeventisonly generated at the synchronization point. This occurs because the \nguardis only executed when synchronized upon. The ruleGUARDsimply places the function applied to a unit \nvalue (the function is really a thunk) ina specialized guardedevent context(e[(.x.e)unit]g). The rule \nSYNC GUARDED EVENT simply strips the guarded event context and synchronizes on the encapsulated expression. \nThis expression, when evaluated, will yield an event. Guarded events cannot be immediatelyextended with \nan SWRAPorAWRAPas theexpression contained within a guarded event context is a function. Instead, wrapping \nan event in a guarded context simply moves the wrap expression into the event context. 6. Case Study: \nA Parallel Web-server We have implemented asynchronous events in Multi-MLton, an open source, multi-core \naware implementation of MLton [14]. Our implementation closely follows the semantics given in Section \n5, and comprises roughly 4K LOC wholly written in ML. Swerve [14] is an open-source, third-party, multithreaded \nweb\u00adserver wholly written in CML and is roughly 16K lines of CML code.We brie.y touch upon three aspects \nof Swerve s design that were amenable to using asynchronous events, and show how these changes lead to \nsubstantial improvement in throughput and perfor\u00admance. To better understand the utility of asynchronous \nevents, we con\u00adsider theinteractionsof fourof Swerve s modules: the Listener, the File Processor,theNetwork \nProcessor,and theTimeout Manager. The Listener module receives incoming HTTP requests and delegates .le \nserving requirements to concurrently execut\u00ading processing threads. For each new connection, a new listener \nis spawned; thus, each connection has one main governing en\u00adtity. The File Processor module handles access \nto the under\u00adlying .le system. Each .le that will be hosted is read by a .le processor thread that chunks \nthe .le and sends it via message\u00ad  SWRAP AWRAP ((t,E[sWrap(e[{e, e ' }],.x.e '')]) || T).,C . ((t,E[e[{.x.e \n'' . e, e ' }]]) || T).,C ((t,E[aWrap(e[{e, e ' }],.x.e '')]) || T).,C . ((t,E[e[{e, .x.e '' . e ' }]]) \n|| T).,C GUARD SYNC GUARDED EVENT ((t,E[aGuard(.x.e)]) || T).,C . ((t,E[e[(.x.e) unit]g]) || T).,C ((t,E[sync \ne[e]g]) || T).,C . ((t,E[sync e]) || T).,C SWRAP GUARDED EVENT AWRAP GUARDED EVENT ((t,E[sWrap(e[e]g,.x.e \n')]) || T).,C . ((t,E[e[sWrap(e,.x.e ')]g]) || T).,C ((t,E[aWrap(e[e]g,.x.e ')]) || T).,C . ((t,E[e[aWrap(e,.x.e \n')]g]) || T).,C Figure 9: Combinator extension for a core language for asynchronous events. passing \nto the Network Processor. The Network Processor, like the File Processor, handles access to the network. \nThe File Processor and Network Processor execute in lock-step, requiring the Network Processor to have \ncompleted sending a chunkbeforethenextoneisreadfromdisk.Timeoutsare processed by the Timeout Manager \nthrough the use of timed events. Lock-step File and Network I/O: Swervewas engineered assum\u00ading lock-step \n.le and network I/O. While adequate under low re\u00adquest loads, this design has poor scalability characteristics. \nThis is because (a) .le descriptors, a bounded resource, can remain open for potentially long periods \nof time, as manydifferent requests are multiplexedamongasetof compute threads,and(b)foragivenre\u00adquest, \na .le chunk is read only after the network processor has sent the previous chunk. Asynchronous events \ncan be used to alleviate both bottlenecks. To solve the problem of lockstep transfer of .le chunks, we \nmight consider using simple asynchronous sends. However, Swerve was engineered to require the .le processor \nto be responsible for detect\u00ading timeouts.Ifatimeout occurs,the.le processorsendsanoti.ca\u00adtion to the \nnetwork processor on the same channel used to send .le chunks. Therefore,if asynchronywasusedtosimplybufferthe.le \nchunks, a timeout would not be detected by the network processor until all the chunks were processed. \nChanging the communication structure to send timeout noti.cations on a separate channel would entail \nsubstantial structural modi.cations to the code base. The code shown in Fig. 10 is a simpli.ed version \nof the .le pro\u00adcessing module modi.ed to use asynchronous events. It uses an ar\u00adbitrator de.ned within \nthe .le processor to manage the .le chunks produced by the fileReader. Now, the fileReader sends .le \nchunks asynchronously to the arbitrator on the channel arIn (line 12) as a post-consumption action. Each \nsuch asynchronous send acts as an arbitrator for the next asynchronous send (lines 18-20). The arbitrator \naccepts .le chunks from the fileReader on this channel and synchronously sends the .le chunks to the \nconsumer as long as a timeout has not been detected. This is accomplished by choosing between an abortEvt \n(used by the Timeout man\u00adagertosignalatimeout)andreceivingachunkfrom.le processing loop (lines 13-20). \nWhen a timeout is detected, an asynchronous message is sent on channel arOut to notify the .le processing \nloopof thisfact (line9); subsequent .le processing then stops. This loop synchronously chooses between \naccepting a timeout noti.ca\u00adtion (line 17), or asynchronously processing the next chunk (lines 11 -12). \ndatatype Xfr = TIMEOUT | DONE | X of chunk 1. fun fileReader name abortEvt consumer = 2. let 3. val \n(arIn, arOut) = (channel(), channel()) 4. fun arbitrator() = sync 5. (choose [ 6. wrap (recvEvt arIn, \n 7. fn chunk => send (consumer, chunk)), 8. wrap (abortEvt, fn () => 9. (aSync(aSendEvt(arOut, ())); \n 10. send(consumer, TIMEOUT)))]) 11. fun sendChunk(chunk) = 12. aSync(aWrap(aSendEvt(arIn, X(chunk)),arbitrator)) \n 13. fun loop strm = 14. case BinIO.read (strm, size) 15. of SOME chunk => sync 16. (choose [ 17. \nrecvEvt arOut, 18. wrap(alwaysEvt, 19. fn () => (sendChunk(chunk); 20. loop strm))]) 21. | NONE => \naSync(aSendEvt(arIn, DONE)) 22. in 23. case BinIO.openIt name of 24. NONE => () 25. | SOME strm => \n(loop strm; BinIO.closeIt strm) 26. end  Figure 10: Asimpli.ed version of the .le processing module \nin Swerve. Since asynchronousevents operateover regular CML channels, we were able to modify the .le \nprocessor to utilize asynchronywithout having to change anyof the other modules or the communication \npatterns and protocols they expect. Being able to choose between synchronousand asynchronouseventsinthe \nfileReader function also allowed us to create a buffer of .le chunks, but stop .le processing .le if \na timeout was detected by the arbitrator. Parallel Packetizing: In CML, channels are often used to im\u00adplement \nshared input/output buffered streams. For example, in Swerve, the network processor uses a buffered stream \nto collect concurrently-processed data chunks generatedbythe .le processor. These chunks are subsequently \ntransformed into packets amenable for transmission back to the client. Asynchronous receives allow parallel \nprocessing of these chunks that automatically preserves the order in which these chunks were generated. \nAssociated with each elementinthebuffered streamisathreadthat asynchronously waitsforthe elementtobe \ndeposited, processesthe chunkintoa packet, and sends it on a dedicated local channel. This functional\u00adity \nis encapsulated within an event (that leverages an asynchronous receive) that is eventually synchronized \nby a collator thread which waits for packets to be generated before sending the result back to the client: \n 1. fun packetEvt(is) = 2. aGuard(fn () => 3. let val c = channel() 4. in sWrap(aWrap(aRecvEvt(is), \n 5. fn x => send(c, packetize(parse(x))), 6. fn () => recvEvt(c))) 7. end)  When theevent returnedby \npacketEvt is synchronized, an asyn\u00adchronousreceiveeventis depositedontheinput stream( is ),anda neweventis \nreturned, which, when synchronizedin turn, will yield the .nal packet to be sent on the network. Given \na parameter, bufferSize , of how many packets we wish to processes in parallel, we can express the collate \nfunction as follows: 1. fun collate(bufferSize) = 2. let fun createEvents(0, evts) = evts 3. | createEvents(x, \nevts) = 4. createEvents(x-1, evts@[sync(packetEvt(is))]) 5. fun sendPackets([]) = () 6. | sendPackets(e::evts) \n= 7. (networkIO.send(socket,sync(e)); 8. sendPackets(evts)) 9. in sendPackets(createEvents(bufferSize, \n[])) 10. end  The auxiliary function createEvents synchronizes on bufferSize number of parseAndPacketEvts \n. This results in a list of events which, when synchronized, will yield the .nal packets. This list of \nevents consists of the synchronous receive events over local chan\u00adnels returned by parseAndPacketEvts \n. Without asynchronous events, the concurrency afforded by this implementation couldbe realizedbyhavinga \ncollectionofexplicit packet-izing threads all contending on the stream, waiting for a new element to \nbe deposited. However, because these threads can process the chunks out-of-order, additional metadata \nsuch as a sequence number must be provided in the deposited chunks. This requires modifying the module \nwhich is responsible for the input stream to embed relevant metadata, as well as augmenting the collator \nto make sure to stitch things back into correct order using these sequence numbers. Asynchronous receives \nimplicitly provide these ordering guarantees, alleviating the burden of weaving this metadata management \nin the protocol, resulting in cleaner, more modular, code. Underlying I/O and Logging: Toimprovescalability \nand respon\u00adsiveness, we also implemented a non-blocking I/O library com\u00adposedofa language-level interfaceand \nassociated runtime support. The library implementsall MLtonI/O interfaces,but internallyuti\u00adlizes asynchronousevents.The \nlibraryis structured around callback events as de.ned in Sec. 4.1 operating over I/O resource servers. \nInternally, all I/O requests are translated into a potential series of callback events. Web-servers utilize \nlogging for administrative purposes.For long running servers, logs tend to grow quickly. Some web-servers \n(like Apache) solve this problem by using a rolling log, which automat\u00adically opens a new log .le after \na set time period (usually a day). In Swerve, all logging functions were done asynchronously. Using asynchronous \nevents, we were able to easily change the logging infrastructure to use rolling logs. Post consumption \nactions were utilized to implement the rolling log functionality, by closing old logs and opening new \nlogs after the appropriate time quantum. In addition, Swerve s logging infrastructure is tasked with \nexiting the system if a fatal error is detected. The log notates that the occurrence of the error, .ushes \nthe log to disk, and then exits the system. This ensure that the log contains a record of the error prior \nto the system s exit. Unfortunately, for the modules that utilize logging, this poses additional complexity \nand breaks modularity. Instead of logging the error at the point which it occurred, the error must be \nlogged after the module has performed any clean up actions because of the synchronous communication protocol \nbetween the module and the log. Thus, if the module logs any actions during the clean up phase, they \nwill appear in the log prior tothe error.We canleverage asynchronous callbackeventsto extend the module \nwithout changing the communication protocol to the log. 1:let val logEvt = aSendEvt(log, fatalErr) 2: \nval logEvt = callbackEvt(logEvt, 3: fn () => (Log.flush(); 4: System.exit())) 5: val exitEvt = aSync(logEvt \n) 6:in ( clean up; sync(exitEvt)) 7:end In the code above, logEvt corresponds to an event that encapsu\u00adlates \nthe communication protocol the log expects: a simple asyn\u00adchronous send on the log s input channel log. \nThe event logEvt de.nes a callback. This event, when synchronized, will execute an asynchronous send \nto the log and will create a new event that be\u00adcomes bound to exitEvt. When exitEvt is synchronized upon, \nwe are guaranteed that the log has received the noti.cation of the fatal error.Withthis simpli.cationwecanalso \nsimplifythelogby removing checksto seeifa logged message correspondstoafatal error and the exit mechanism; \nlogging and system exit are now no longer con.ated. 6.1 Results To measure the ef.ciencyof our changes \nin Swerve, we leveraged the server s internal timing and pro.ling output for per-module accounting. The \nbenchmarks were run on an AMD Opteron 865 serverwith8processors,each containingtwosymmetric cores,and \n32 GB of total memory, with each CPU having its own local mem\u00adoryof4GB.The resultsaswellasthechangestothelargestmod\u00adules \nare summarizedinTable1.Translatingthe implementationto use asynchronousevents leadstoa4.7X performance \nimprovement as well as a 15X reduction in client-side observed latency over the original, with only 103 \nlines of code changed out of 16KLOC. Not surprisingly, the results show that asynchronous commu\u00adnication, \nwhen carefully applied, can yield substantial perfor\u00admancegains. More signi.cantly, however, is that \nthesegains were achieved with only small changes to the overall structure of the application. These changes \nwere almost always mechanical, often just involving the replacement of a synchronous event combinator \nwith an asynchronous one. No changes were required to module interfaces or the program s overall logical \nstructure. Toputthe performancegainsin perspective, our modi.edversion of Swerve with asynchronous events \nhas a throughput within 10% ofApache2.2.15onworkloadsthat establishupto1000 concurrent connections and \nprocess small/medium .les at a total rate of 2000 requests per second. For server performance measurements \nand workload generation we used httperf a tool for measuring web\u00adserver performance.  Module LOC LOC \nmodi.ed improvement Listener 1188 11 2.15 X File Processor 2519 35 19.23 X Network Processor 2456 25 \n24.8 X Timeout Manager 360 15 4.25 X Swerve 16,000 103 4.7 X Table 1: Per module performance numbers \nfor Swerve. 7. Related Work Many functional programming languages such as Erlang [1], Jo-Caml [10], and \nF# [18] provide intrinsic support for asynchronous programming. In Erlang, message sends are inherently \nasyn\u00adchronous. In JoCaml, complex asynchronous protocols are de\u00ad.ned using join patterns [2, 11] that \nde.ne synchronization pro\u00adtocols over asynchronous and synchronous channels. In F#, asyn\u00adchronous behavior \nis de.ned using asynchronous work .ows that permit asynchronous objects to be created and synchronized. \nCon\u00advenient monadic-style let! -syntax permits callbacks, represented as continuations, to be created \nwithin an asynchronous computa\u00adtion. While these different techniques provide expressive ways to de.ne \nasynchronous computations, theydo not focus on issues of composability (our primary interest in this \npaper), especially with respect to asynchronous post-consumption actions. There havealso been efforts \nto simplify asynchronous programming in imperative languages [3] by providing new primitives that are \namenable to compiler analysis; here again, the primary focus is not on compos\u00adability or modularity of \nasynchronous event-based protocols. Reactive programming [12] is an important programing style often \nfound in systems programming that uses event loops to react to outside events (typically related to I/O). \nIn this context, events do not de.ne abstract communication protocols (as theydo in CML), but typically \nrepresentI/O actions delivered asynchronouslyby the underlying operating system. While understanding \nhow reactive events and threads can co-exist is an important one, we believe such efforts are orthogonal \nto the focus of this work.Indeed we can encode reactive style programming idioms inACML through the use \nof asynchronous receive events and/or lightweight servers. Asynchronous exceptions as discussed in [13] \nprovide abstractions that concurrent applications can use to allow one thread to seam\u00adlessly and asynchronously \nsignal another. Kill-safe abstractions [8] provide a related solution to safely terminate a cooperative \nuser\u00adlevel thread without violating sensible invariants on shared objects. While asynchronous events \nare a general mechanism for compos\u00adable and modular asynchronous programming, and thus were not designed \nspeci.cally with these purposes in mind, we believe they can be used to serve such roles effectively \nas well, as described in the logging infrastructure example given in Sec. 6. There have been incarnations \nof CML in languages and systems other than ML (e.g., Haskell [4, 17], Scheme [8], and MPI [5]). There \nhas also been much recent interest in extending CML with transactional support[6,7]and other.avorsof \nparallelism[9].We believe transactional events [6, 7] provide an interesting platform upon whichto implementa \nnon-blockingversionof sChoose that retains the same semantics. Additionally, we expect that previous \nwork on specialization of CML primitives [15] can be applied to improve the performance of asynchronous \nprimitives. 8. Concluding Remarks This paper presents the design, rationale, and implementation for asynchronousevents,aconcurrencyabstraction \nthat generalizes the behavior of CML-based synchronous events to enable composable construction of asynchronous \ncomputations. Our experiments indi\u00adcate that asynchronous events can seamlessly co-exist with other CML \nprimitives, and can be effectively leveraged to improve per\u00adformance of realistic highly-concurrent applications. \nAcknowledgements. This work is supported by the National Sci\u00adence Foundation under grants CCF-0701832 \nand CCF-0811631, and a gift from Samsung Corporation. References [1] Joe Armstrong, RobertVirding, ClaesWikstrom, \nand MikeWilliams. Concurrent Programming in Erlang. Prentice-Hall, 2nd edition, 1996. [2] Jean-Pierre \nBan etayer. ProgrammingbyMultiset atreand DanielLeM\u00b4 Transformation. Commun. ACM, 36(1), 1993. [3] Prakash \nChandrasekaran, Christopher L. Conway, Joseph M. Joy, and Sriram K. Rajamani. Programming asynchronous \nlayers with clarity. In FSE, pages 65 74, 2007. [4] Avik Chaudhuri. AConcurrent Ml Library in Concurrent \nHaskell. In ICFP, pages 269 280, 2009. [5] Erik Demaine. First-Class Communication in MPI. In MPIDC 96: \nProceedings of the Second MPI Developers Conference, 1996. [6] Kevin Donnelly and Matthew Fluet. Transactional \nEvents. The Journal of Functional Programming, pages 649 706, 2008. [7] Laura Ef.nger-Dean, MatthewKehrt, \nand Dan Grossman. Transac\u00adtional Events for ML. In ICFP, pages 103 114, 2008. [8] Matthew Flatt and Robert \nBruse Findler. Kill-safe Synchronization Abstractions. In PLDI, pages 47 58, 2004. [9] Matthew Fluet, \nMike Rainey, John Reppy, and Adam Shaw. Implicitly-ThreadedParallelism in Manticore. In ICFP, pages 119 \n130, 2008. [10]C\u00b4edricFournet,FabriceLe Fessant,Luc Maranget,andAlan Schmidt. JoCaml:ALanguage for Concurrent \nDistributed and Mobile Program\u00adming. In Advanced Functional Programming, pages 129 158. 2002. [11] C\u00b4edric \nFournet and Georges Gonthier. The re.exive cham and the join-calculus. In POPL, pages 372 385, 1996. \n[12] Peng Li and Steve Zdancewic. Combining Events and Threads for Scalable Network Services, and Evaluation \nof Monadic, Application-Level ConcurrencyPrimitives. In PLDI, pages 189 199, 2007. [13] Simon Marlow,Simon \nPeyton Jones, AndrewMoran, and John Reppy. Asynchronous Exceptions in Haskell. In PLDI, pages 274 285, \n2001. [14] MLton. http://www.mlton.org. [15] John Reppy and Yingqi Xiao. Specialization of CML Message-Passing \nPrimitives. InPOPL, pages 315 326, 2007. [16] John H. Reppy. Concurrent Programming in ML. Cambridge \nUniver\u00adsity Press, 1999. [17] George Russell. Events in Haskell, and How to Implement Them. In ICFP, \npages 157 168, 2001. [18] Don Syme, Adam Granicz, and Antonio Cisternino. Expert F#. Apress, 2007. [19] \nLukasz Ziarek, K.C. Sivaramakrishnan, and Suresh Jagannathan. Composable Asynchronous Events. Technical \nReport TR-11-09, Dept. of Computer Science, Purdue University, 2011.   \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Although asynchronous communication is an important feature of many concurrent systems, building <i>composable</i> abstractions that leverage asynchrony is challenging. This is because an asynchronous operation necessarily involves two distinct threads of control -- the thread that initiates the operation, and the thread that discharges it. Existing attempts to marry composability with asynchrony either entail sacrificing performance (by limiting the degree of asynchrony permitted), or modularity (by forcing natural abstraction boundaries to be broken).</p> <p>In this paper, we present the design and rationale for <i>asynchronous events</i>, an abstraction that enables composable construction of complex asynchronous protocols without sacrificing the benefits of abstraction or performance. Asynchronous events are realized in the context of Concurrent ML's first-class event abstraction. We discuss the definition of a number of useful asynchronous abstractions that can be built on top of asynchronous events (e.g., composable callbacks) and provide a detailed case study of how asynchronous events can be used to substantially improve the modularity and performance of an I/O-intensive highly concurrent server application.</p>", "authors": [{"name": "Lukasz Ziarek", "author_profile_id": "81318492573", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2690671", "email_address": "lziarek@cs.purdue.edu", "orcid_id": ""}, {"name": "KC Sivaramakrishnan", "author_profile_id": "81442594976", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2690672", "email_address": "chandras@cs.purdue.edu", "orcid_id": ""}, {"name": "Suresh Jagannathan", "author_profile_id": "81100208907", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2690673", "email_address": "suresh@cs.purdue.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993572", "year": "2011", "article_id": "1993572", "conference": "PLDI", "title": "Composable asynchronous events", "url": "http://dl.acm.org/citation.cfm?id=1993572"}