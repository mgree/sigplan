{"article_publication_date": "06-04-2011", "fulltext": "\n The Tao of Parallelism in Algorithms * Keshav Pingali1,3, Donald Nguyen1, Milind Kulkarni5 , Martin \nBurtscher4, M. Amber Hassaan2, Rashid Kaleem1, Tsung-Hsien Lee2, Andrew Lenharth3 , Roman Manevich3, \nMario M\u00b4endez-Lojo3, Dimitrios Prountzos1, Xin Sui1 1Department of Computer Science, 2Electrical and \nComputer Engineering and 3Institute for Computational Engineering and Sciences The University of Texas \nat Austin 4Department of Computer Science, Texas State University San Marcos 5School of Electrical and \nComputer Engineering, Purdue University Abstract For more than thirty years, the parallel programming \ncommunity has used the dependence graph as the main abstraction for reason\u00ading about and exploiting parallelism \nin regular algorithms that use dense arrays, such as .nite-differences and FFTs. In this paper, we argue \nthat the dependence graph is not a suitable abstraction for algorithms in new application areas like \nmachine learning and net\u00adwork analysis in which the key data structures are irregular data structures \nlike graphs, trees, and sets. To address the need for better abstractions, we introduce a data\u00adcentric \nformulation of algorithms called the operator formulation in which an algorithm is expressed in terms \nof its action on data structures. This formulation is the basis for a structural analysis of algorithms \nthat we call tao-analysis. Tao-analysis can be viewed as an abstraction of algorithms that distills out \nalgorithmic proper\u00adties important for parallelization. It reveals that a generalized form of data-parallelism \ncalled amorphous data-parallelism is ubiqui\u00adtous in algorithms, and that, depending on the tao-structure \nof the algorithm, this parallelism may be exploited by compile-time, inspector-executor or optimistic \nparallelization, thereby unifying these seemingly unrelated parallelization techniques. Regular algo\u00adrithms \nemerge as a special case of irregular algorithms, and many application-speci.c optimization techniques \ncan be generalized to a broader context. These results suggest that the operator formulation and tao\u00adanalysis \nof algorithms can be the foundation of a systematic ap\u00adproach to parallel programming. Categories and \nSubject Descriptors D.1.3 [Programming Tech\u00adniques]: Concurrent Programming Parallel Programming; D.3.3 \n[Programming Languages]: Language Constructs and Features Frameworks General Terms: Algorithms, Languages, \nPerformance Keywords: amorphous data-parallelism, Galois system, irregular programs, operator formulation, \ntao-analysis. * This work is supported in part by NSF grants 0923907, 0833162, 0719966, and 0702353 and \nby grants from IBM, NEC and Intel. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, USA. Copyright c &#38;#169; \n2011 ACM 978-1-4503-0663-8/11/06. . . $10.00. 1. Introduction n. /tau/, /dau/: 1. a. the source and \nguiding principle of all reality as conceived by Taoists; b. process which is to be followed for a life \nof harmony. Origin: Chinese d` ao, literally, way. (adapted from Merriam-Webster) Dense matrix computations \narise naturally in high-performance implementations of important computational science methods like .nite-differences \nand multigrid. Therefore, over the years, the par\u00adallel programming community has acquired a deep understanding \nof the patterns of parallelism and locality in these kinds of regular algorithms. In contrast, irregular \ndata structures such as sparse graphs, trees and sets are the norm in most emerging problem do\u00admains \nsuch as the following. In social network analysis, the key data structures are extremely sparse graphs \nin which nodes represent people and edges rep\u00adresent relationships. Algorithms for betweenness-centrality, \nmax.ow, etc. are used to extract network properties [10].  Machine-learning algorithms like belief propagation \nand survey propagation are based on message-passing in a factor graph, a sparse bipartite graph [44]. \n Data-mining algorithms like k-means and agglomerative clus\u00adtering operate on sets and multisets [59]. \n Simulations of electrical circuits and battle.elds often use event-driven (discrete-event) simulation \n[49] over networks of nodes.  Optimizing compilers perform iterative and elimination-based data.ow analysis \non structures like inter-procedural control\u00ad.ow graphs [1].  Even in computational science, n-body methods \nuse spatial decomposition trees [6], and .nite-element methods use 2D and 3D meshes produced using algorithms \nlike Delaunay mesh generation and re.nement [11].  Unfortunately, we currently have few insights into \nthe struc\u00adture of parallelism and locality in irregular algorithms, and this has stunted the development \nof techniques and tools that make it easier to produce parallel implementations. Domain specialists have \nwrit\u00adten parallel programs for some of the algorithms discussed above (see [5, 20, 31, 33] among others). \nThere are also parallel graph li\u00adbraries such as Boost [22] and STAPL [2]. However, it is dif.cult to \nextract broadly applicable abstractions, principles, and mechanisms from these implementations. Another \napproach is to use points-to and shape analysis [19, 27, 30] to .nd data structure invariants that might \nbe used to prove independence of computations. This ap\u00adproach has been successful in parallelizing n-body \nmethods like Barnes-Hut that are organized around trees [17], but most of the applications discussed \nabove use sparse graphs with no particular structure, so shape analysis techniques fail to .nd any parallelism. \nThese dif.culties have seemed insurmountable, so irregular algo\u00adrithms remain the Cinderellas of parallel \nprogramming in spite of their central role in emerging applications. In this paper, we argue that these \nproblems can be solved only by changing the abstractions that we currently use to reason about parallelism \nin algorithms. The most widely used abstraction is the dependence graph in which nodes represent computations, \nand edges represent dependences between computations; for programs with loops, dependence edges are often \nlabeled with additional in\u00adformation such as dependence distances and directions. Computa\u00adtions that \nare not ordered by the transitive closure of the dependence relation can be executed in parallel. Dependence \ngraphs produced either by studying the algorithm or by compiler analysis are re\u00adferred to as static dependence \ngraphs. Although static dependence graphs are used extensively for implementing regular algorithms, they \nare not adequate for modeling parallelism in irregular algo\u00adrithms. As we explain in Section 2, the most \nimportant reason for this is that dependences between computations in irregular algo\u00adrithms are functions \nof runtime data values, so they cannot be rep\u00adresented usefully by a static dependence graph. To address \nthe need for better abstractions, Section 3 introduces a data-centric formulation of algorithms, called \nthe operator for\u00admulation of algorithms. In the spirit of Niklaus Wirth s aphorism Program = Algorithm \n+ Data Structure [63], we express algo\u00adrithms in terms of operations on abstract data types (ADTs), in\u00addependently \nof the concrete data structures used to implement the abstract data types. This formulation is the basis \nof a structural analysis of algorithms that we call tao-analysis after the three key dimensions of the \nanalysis. In the literature on parallel program\u00adming, there are many abstractions of parallel machines, \nsuch as a variety of PRAM models [32]. Tao-analysis can be viewed as an abstraction of algorithms that \ndistills out properties important for parallelization, hiding unnecessary detail. Tao-analysis reveals \nthat a generalized data-parallelism called amorphous data-parallelism is ubiquitous in algorithms, as \nwe dis\u00adcuss in Section 4. We also show that depending on the tao-structure of the algorithm, this parallelism \nmay be exploited by compile\u00adtime, inspector-executor or optimistic parallelization, thereby uni\u00adfying \nthese seemingly unrelated techniques by consideration of the binding time of scheduling decisions. In \naddition, regular algo\u00adrithms emerge as special cases of irregular algorithms. In Section 5, we show \nhow these concepts can be applied to the parallelization of many important algorithms from the literature. \nSome of the techniques discussed in this paper have been incor\u00adporated into the Galois system1. In Section \n6, we give experimen\u00adtal results for three full applications that demonstrate the practical utility of \nthese ideas. Extensions to the amorphous data-parallelism model are discussed in Section 7. We summarize \nthe main contri\u00adbutions in Section 8.  2. Inadequacy of static dependence graphs The need for new algorithmic \nabstractions can be appreciated by considering Delaunay Mesh Re.nement (DMR) [11], an irregular algorithm \nused extensively in .nite-element meshing and graphics. The Delaunay triangulation for a set of points \nin a plane is the tri\u00adangulation in which each triangle satis.es a certain geometric con\u00adstraint called \nthe Delaunay condition [14]. In many applications, triangles are required to satisfy additional quality \nconstraints, and this is accomplished by a process of iterative re.nement that re\u00ad 1 Available from http://iss.ices.utexas.edu/galois \n Figure 1. Fixing bad triangles 1 Mesh mesh = // read in initial mesh 2 Worklist <Triangle > wl ; 3 \nwl.add(mesh.badTriangles()); 4 while (wl.size() != 0) { 5 Triangle t = wl. poll (); // get bad triangle \n6 if ( t no longer in mesh) continue ; 7 Cavity c = new Cavity(t ); 8 c.expand(); 9 c.retriangulate(); \n10 mesh.update(c); 11 wl.add(c.badTriangles()); 12 } Figure 2. Pseudocode of the mesh re.nement algorithm \n peatedly .xes bad triangles (those that do not satisfy the quality constraints) by adding new points \nto the mesh and re-triangulating. Re.ning a bad triangle by itself may violate the Delaunay prop\u00aderty \nof triangles around it, so it is necessary to compute a region of the mesh called the cavity of the bad \ntriangle and replace all the triangles in the cavity with new triangles. Figure 1 illustrates this process; \nthe darker-shaded triangles are bad triangles, and the cavities are the lighter shaded regions around \nthe bad trian\u00adgles. Re-triangulating a cavity may generate new bad triangles, but it can be shown that, \nat least in 2D, this iterative re.nement process will ultimately terminate and produce a guaranteed-quality \nmesh. Different orders of processing bad triangles lead to different meshes, although all such meshes \nsatisfy the quality constraints and are acceptable outcomes of the re.nement process [11]. This is an \nexample of Dijkstra s don t-care non-determinism (also known as committed-choice non-determinism) [16]. \nFigure 2 shows the pseu\u00addocode for mesh re.nement. Each iteration of the while-loop re\u00ad.nes one bad triangle; \nwe call this computation an activity. DMR can be performed in parallel since bad triangles whose cavities \ndo not overlap can be re.ned in parallel. Note that two triangles whose cavities overlap can be re.ned \nin either order but not concurrently. Unfortunately, static dependence graphs are in\u00adadequate for exposing \nthis parallelism. In Delaunay mesh re.ne\u00adment, as in most irregular algorithms, dependences between loop \niterations (activities) are functions of runtime values: whether or not two iterations of the while-loop \nin Figure 2 can be executed concurrently depends on whether the cavities of the relevant trian\u00adgles overlap, \nand this depends on the input mesh and how it has been modi.ed by previous re.nements. Since this information \nis known only during program execution, a static dependence graph for Delaunay mesh re.nement must conservatively \nassume that ev\u00adery loop iteration might interfere with every prior iteration, serial\u00adizing the execution. \nA second problem with dependence graphs is that they do not model don t-care non-determinism. In dependence \ngraphs, compu\u00adtations can be executed in parallel if they are not ordered by the dependence relation. \nIn irregular algorithms like Delaunay mesh re.nement, it is often the case that two activities can be \ndone in ei\u00adther order but cannot be done concurrently, so they are not ordered by dependence and yet \ncannot be executed concurrently. Exploit\u00ading don t-care non-determinism can lead to more ef.cient parallel \nimplementations, as we discuss in Section 4. Event-driven simulation [49], which is used in circuit simula\u00adtions \nand system modeling, illustrates a different kind of complex\u00ad    (a) Initial state (b) State after \nA and B have .red Figure 3. Con.icts in event-driven simulation ity exhibited by some irregular algorithms. \nThis application simu\u00adlates a network of processing stations that communicate by sending messages along \nFIFO links. When a station processes a message, its internal state may be updated, and it may produce \nzero or more messages on its outgoing links. Sequential event-driven simulation is implemented by maintaining \na global priority queue of events called the event list and processing the earliest event at each step. \nIn this irregular algorithm, activities correspond to the processing of events. In principle, event-driven \nsimulation can be performed in paral\u00adlel by processing multiple events from the event list simultaneously, \nrather than one event at a time. However, unlike in Delaunay mesh re.nement, in which it was legal to \nprocess bad triangles concur\u00adrently provided they were well-separated in the mesh, it may not be legal \nto process two events in parallel even if their stations are far apart in the network. Figure 3 demonstrates \nthis. Suppose that in a sequential implementation, node A .res and produces a message time-stamped 3, \nand then node B .res and produces a message time-stamped 4. Notice that node C must consume this message \nbefore it consumes the message time-stamped 5. Therefore, in Fig\u00adure3(a), theeventsat A and C cannot \nbe processed in parallel even though the stations are far apart in the network. However, notice that \nif the message from B to C had a time-stamp greater than 5, it would have been legal to process in parallel \nthe events at nodes A and C. To determine if two activities can be performed in parallel at a given point \nin the execution of this algorithm, we need a crystal ball to look into the future! In short, static \ndependence graphs are inadequate abstractions for irregular algorithms for the following reasons. 1. \nDependences between activities in irregular algorithms are usu\u00adally complex functions of runtime data \nvalues, so they cannot be usefully captured by a static dependence graph. 2. Many irregular algorithms \nexhibit don t-care non-determinism, but this is hard to model with dependence graphs. 3. Whether or \nnot it is safe to execute two activities in parallel at a given point in the computation may depend on \nactivities created later in the computation. It is not clear how one models this with dependence graphs. \n  3. Operator formulation of algorithms These problems can be addressed by a data-centric formulation \nof algorithms, called the operator formulation, in which an algorithm is viewed in terms of its action \non data structures. The operator formulation can be de.ned for any abstract data type, and we will use \nthe graph ADT to illustrate the key ideas. As is standard, a graph is (i) a set of nodes V , and (ii) \na set of edges E . V \u00d7 V between these nodes. Graphs can be directed or undirected, and nodes and edges \nmay be labeled with values. We will not discuss a particular concrete representation for the graph ADT. \nThe implementation is free to choose the concrete representation that is best suited for a particular \nalgorithm and machine: for example, cliques may be represented using dense arrays, while sparse graphs \nmay be represented using adjacency lists. This is similar to the approach taken in relational databases: \nSQL programmers use the relation ADT in writing programs, and the underlying DBMS system is free to implement \nthe ADT using B-trees, hash tables, and other concrete data structures. Figure 4. Active elements and \nneighborhoods 3.1 Active elements, neighborhoods and ordering Active elements: At each point during \nthe execution of a graph algorithm, there are certain nodes or edges in the graph where computation might \nbe performed. These nodes and edges are called active elements; to keep the discussion simple, we assume \nfrom here on that active elements are nodes. To process an active node, an operator is applied to it, \nand the resulting computation is called an activity. Neighborhoods: Performing an activity may require \nreading or writing other nodes and edges in the graph. Borrowing terminology from the literature on cellular \nautomata, we refer to the set of nodes and edges that are read or written while performing an activity \nas the neighborhood of that activity. Figure 4 shows an undirected sparse graph in which the .lled nodes \nrepresent active nodes, and shaded regions represent the neighborhoods of those active nodes. Note that \nin general, the neighborhood of an active node is distinct from its neighbors in the graph. Ordering: \nIn general, there are many active nodes in a graph, so a sequential implementation must pick one of them \nand perform the appropriate activity. In some algorithms such as Delaunay mesh re.nement, the implementation \nis allowed to pick any active node for execution. We call these unordered algorithms. In contrast, some \nalgorithms dictate an order in which active nodes must be processed by a sequential implementation; we \ncall these ordered algorithms. Event-driven simulation is an example: the sequential algorithm for event-driven \nsimulation processes messages in global time order. The order on active nodes may be a partial order. \nWe illustrate these concepts using the algorithms from Sec\u00adtion 2. In DMR, the mesh is usually represented \nby a graph in which nodes represent triangles and edges represent adjacency of trian\u00adgles. The active \nnodes in this algorithm are the nodes representing bad triangles, and the neighborhood of an active node \nis the cav\u00adity of that bad triangle. In event-driven simulation, active nodes are stations that have \nmessages on their input channels, and neighbor\u00adhoods contain only the active node. 3.2 From algorithms \nto programs A natural way to write these algorithms is to use worklists to keep track of active nodes. \nHowever, programs written directly in terms of worklists, such as the one in Figure 2, encode a particular \nor\u00adder of processing worklist items and do not express the don t-care nondeterminism in unordered algorithms. \nTo address this problem, we can use the Galois programming model, which is a sequential, object-oriented \nprogramming model (such as sequential Java), aug\u00admented with two Galois set iterators [40]: DEFINITION \n1. Galois set iterators: Unordered-set iterator: foreach (e in Set S) {B(e)} The loop body B(e) is executed \nfor each element e of set S. The order in which iterations execute is indeterminate and can be chosen \nby the implementation. There may be dependences between the iterations. When an iteration executes, it \nmay add elements to S.  Ordered-set iterator: foreach (e in OrderedSet S) {B(e)} This construct iterates \nover an ordered set S. It is similar to the unordered set iterator above, except that a sequential im\u00adplementation \nmust choose a minimal element from S at every iteration. When an iteration executes, it may add elements \nto S. 1 Mesh mesh = // read in initial mesh 2 Workset<Triangle > ws ; 3 ws.add(mesh.badTriangles()); \n4 foreach ( Triangle t in Set ws ) { 5 if (t no longer in mesh) continue ; 6 Cavity c = new Cavity(t \n); 7 c.expand(); 8 c.retriangulate(); 9 mesh.update(c); 10 ws.add(c.badTriangles()); 11 } Figure 5. DMR \nusing an unordered Galois set iterator Iterators over multi-sets can be de.ned similarly. In principle, \nunordered iterators are a special case of ordered iterators, but they are suf.ciently important in applications \nthat we give them spe\u00adcial treatment. Allowing break statements in the body of a Galois iterator permits \nearly exits out of iterators. This can be useful for search problems. Some unordered algorithms can also \nbe written using divide-and-conquer, as discussed in Section 7. Set iterators were .rst introduced in \nthe SETL programming language [57] and can now be found in most object-oriented lan\u00adguages such as Java \nand C++. However, new elements cannot be added to sets while iterating over them, which is possible with \nGa\u00adlois set iterators. Note that the iterators have a well-de.ned sequen\u00adtial semantics. The unordered-set \niterator speci.es the don t-care nondeterminism of unordered algorithms. The Galois system provides a \n(concurrent) data structure library, similar in spirit to the Java collections library, containing imple\u00admentations \nof key ADTs such as graphs, trees, grids, work-sets, etc. Application programmers write algorithms in \nsequential Java, us\u00ading the appropriate library classes and Galois set iterators. Figure 5 shows pseudocode \nfor Delaunay mesh re.nement, written using the unordered Galois set iterator. The body of the Galois \nset iterator is the implementation of the operator. Note that neighborhoods are de.ned implicitly by \nthe calls to the graph ADT; for example, if the body of the iterator invokes a graph API method to get \nthe out\u00adgoing edges from an active node, these edges become part of the neighborhood for that activity. \nTherefore, in general, the neighbor\u00adhood of an activity is known only when that activity is completed. \nThis has important implications for parallelization, as we discuss in Section 4.  3.3 Tao-analysis of \nalgorithms Structured Topology Semi-structured Unstructured Topology-driven Location Data-driven Active \nAlgorithms Nodes Unordered Ordering Ordered Morph Operator Local computation Reader Figure 6. Structural \nanalysis of algorithms The operator formulation permits a natural structural analysis of algorithms along \nthree dimensions (shown in Figure 6): Topology, Active nodes and Operator. The topology describes the \ndata struc\u00adture on which computation occurs. The active nodes dimension de\u00adscribes how nodes become active \nand how active nodes should be ordered, providing a global view of an algorithm. Finally, the opera\u00adtor \ndescribes the action of the operator on an active node, providing a local view of an algorithm. We call \nthis tao-analysis. Exploiting this structure is key to ef.cient parallel implementations as we dis\u00adcuss \nin Section 4. 1. Topology: We classify graph topologies according to the (Kol\u00admogorov) complexity of \ntheir descriptions. Highly structured topologies can be described concisely with a small number of parameters, \nwhile unstructured topologies require verbose de\u00adscriptions. The topology of a graph is an important \nindicator of the kinds of optimizations available to algorithm implemen\u00adtations; for example, algorithms \nin which graphs have highly structured topologies may be amenable to static analysis and optimization. \n Structured: An example of a structured topology is a graph consisting of labeled nodes and no edges: \nthis is isomorphic to a set or multiset. Its topology can be described by a single number, which is the \nnumber of elements in the set/multiset. If the nodes are totally ordered, the graph is isomorphic to \na sequence or stream. Cliques (graphs in which every pair of nodes is connected by a labeled edge) are \nisomorphic to square dense matrices (row/column numbers are derived from a total ordering of the nodes). \nTheir topology is com\u00adpletely speci.ed by a single number, which is the number of nodes in the clique. \nThe .nal example we will consider in this paper is the rectangular grid; its topology is determined completely \nby two numbers, its height and width.  Semi-structured: We classify trees as semi-structured topolo\u00adgies. \nAlthough trees have useful structural invariants, there are many trees with the same number of nodes \nand edges.  Unstructured: General graphs fall in this category.  2. Active nodes: This dimension describes \nhow nodes become active and the order in which they must be processed. Location: Nodes can become active \nin a topology-driven or data-driven manner. In topology-driven algorithms, the ac\u00adtive nodes are determined \nby the graph, so the execution of the operator at some active node does not cause other nodes to become \nactive. Common examples are algorithms that it\u00aderate over all the nodes or edges of a graph. In data-driven \nalgorithms, an activity at one node may cause other nodes to become active, so nodes become active in \na data-dependent and unpredictable manner. Some examples are the pre.ow\u00adpush algorithm for max.ow computation \nin graphs and al\u00adgorithms for event-driven simulation.  Ordering: As discussed above, active nodes in \nsome algo\u00adrithms are ordered whereas others are unordered.  3. Operator: We classify operators based \non how they modify the graph. Morph: A morph operator may modify its neighborhood by adding or deleting \nnodes and edges, and it may also update values on nodes and edges. The Delaunay mesh re.nement operator \nis an example; other examples are discussed in Section 5.1.  Local computation: A local computation \noperator may up\u00addate values stored on nodes and edges in its neighbor\u00adhood, but it does not change the \ngraph connectivity. Finite\u00addifference computations are the classic example; other ex\u00adamples are discussed \nin Section 5.2.   r LR m m GH r' Figure 7. Graph rewriting: single-pushout approach Reader: An operator \nis a reader for a data structure if it does not modify it in any way. For example, the ray-tracing operator \nis a reader for the scene being rendered; other examples are discussed in Section 5.3. These de.nitions \ncan be generalized in the obvious way for algorithms that deal with multiple data structures. In that \ncase, neighborhoods span multiple data structures, and the classi.cation of an operator is with respect \nto a particular data structure. For example, in matrix multiplication C = AB, the operator is a local \ncomputation operator for C and a reader for matrices A and B.  3.4 Discussion As mentioned above, under-speci.cation \nof the order of process\u00ading active nodes in unordered algorithms is an instance of don t\u00adcare non-determinism. \nIn some unordered algorithms, the output is independent of the order in which active nodes are processed, \na property that is referred to as the Church-Rosser property since the most famous example of this behavior \nis \u00df-reduction in .-calculus. Data.ow graph execution [4, 15] and the pre.ow-push algorithm for computing \nmax.ow [12] also exhibit this behavior. In other al\u00adgorithms, the output may be different for different \nchoices of active nodes, but all such outputs are acceptable, so the implementation can still pick any \nactive node for execution. Delaunay mesh re.ne\u00adment and Petri net simulation are examples. The pre.ow-push \nal\u00adgorithm also exhibits this behavior if the algorithm outputs both the min-cut and the max-.ow. Even \nfor unordered algorithms, iteration execution order may affect cache performance and the number of executed \niterations, so control of iteration order is useful for ef.\u00adciency. Nguyen and Pingali describe a notation \nand an implemen\u00adtation for doing this [50]. The metaphor of operators acting on neighborhoods is reminis\u00adcent \nof notions in term-rewriting systems, such as graph grammars in particular [18, 42]. The semantics of \nfunctional language pro\u00adgrams are usually speci.ed using term rewriting systems that de\u00adscribe how expressions \ncan be replaced by other expressions within the context of the functional program. The process of applying \nrewrite rules repeatedly to a functional language program is known as string or tree reduction. Tree \nreduction can be generalized in a natural way to graph reduction by using graph grammars as rewrite rules \n[18, 42]. A graph rewrite rule is de.ned as a morphism in the category C of labeled graphs with partial \ngraph morphisms as arrows: r : L . R, and a rewriting step is de.ned by a single pushout diagram [42] \nas shown in Figure 7. In this diagram, G is a graph, and the total morphism m : L . G, which is called \na redex, identi.es the portion of G that matches L, the left-hand side of the rewrite rule. The application \nof a rule r at a redex m leads to a direct derivation (r, m): G . H given by the pushout in Figure 7. \nIn graph reduction, rewrite rules are applied repeatedly to the text of the program until a normal or \nhead-normal form is reached; in the operator formulation on the other hand, the operator is ap\u00adpliedtothe \ndata structure until there are no more active nodes. In addition, we do not require operators to be expressible \nas a .nite set of syntactic rewrite rule schemas (it is not clear that Delau\u00adnay mesh re.nement, for \nexample, can be speci.ed using graph grammars, although some progress along these lines is reported by \nPanangaden and Verbrugge [60]). Nevertheless, the terminology of graph grammars may be useful for providing \na theoretical founda\u00adtion for the operator formulation of algorithms. For example, in the context of \nFigure 7, the graph structure of L and R are identical for local computation operators, while for reader \noperators, the rewrite rule r is the identity morphism. We also note that whether operators make imperative-style \nin-place updates to graphs or create modi.ed copies of the graph in a functional style can be viewed \nas a matter of implementation.  4. Amorphous data-parallelism The operator formulation of an algorithm \nis not explicitly paral\u00adlel, but Figure 4 shows intuitively how opportunities for exploiting parallelism \narise in an algorithm: if there are many active nodes at some point in the computation, each one is a \nsite where a proces\u00adsor can perform computation, subject to neighborhood and ordering constraints. When \nactive nodes are unordered, the neighborhood constraints must ensure that the output produced by executing \nthe activities in parallel is the same as the output produced by execut\u00ading the activities one at a time \nin some order. For ordered active elements, this order must be the same as the ordering on active el\u00adements. \nDEFINITION 2. Given a set of active nodes and an ordering on active nodes, amorphous data-parallelism \nis the parallelism that arises from simultaneously processing active nodes, subject to neighborhood and \nordering constraints. Amorphous data-parallelism is a generalization of conventional data-parallelism \nin which (i) concurrent operations may con.ict with each other, (ii) activities can be created dynamically, \nand (iii) activities may modify the underlying data structure. Not surpris\u00adingly, the exploitation of \namorphous data-parallelism is more com\u00adplex than the exploitation of conventional data-parallelism. In \nthis section, we present a baseline implementation that uses optimistic or speculative execution. 4.1 \nBaseline: speculative parallel execution In the baseline execution model, the graph is stored in shared\u00admemory, \nand active nodes are processed by some number of threads. A thread picks an active node from the work-set \nand specu\u00adlatively applies the operator to that node, making calls to the graph API to perform operations \non the graph as needed. The neighbor\u00adhood of an activity can be visualized as a blue ink-blot that begins \nat the active node and spreads incrementally whenever a graph API call is made that touches new nodes \nor edges in the graph. To en\u00adsure that neighborhoods are disjoint, the concurrent graph class can use \nexclusive logical locks: each graph element has an exclu\u00adsive lock that must be acquired by a thread \nbefore it can access that element. Locks are held until the activity terminates. If a lock cannot be \nacquired because it is already owned by another thread, a con.ict is reported to the runtime system, \nwhich rolls back one of the con.icting activities. Lock manipulation is performed entirely by the methods \nin the graph class; in addition, to enable rollback, each graph API method that modi.es the graph makes \na copy of the data before modi.cation, as is done in other systems that use speculation such as transactional \nmemory and thread-level specu\u00adlation [25, 29, 55, 61]. If active elements are not ordered, the activity \ncommits when the application of the operator is complete, and all acquired locks are then released. If \nactive elements are ordered, active nodes can still be processed in any order, but they must commit in \nserial or\u00adder. This can be implemented using a data structure similar to a reorder buffer in out-of-order \nprocessors [40]. In this case, locks are released only when the activity commits (or is aborted). Exclu\u00adsive \nlogical locks can be implemented by using a compare-and-set instruction to mark a graph element with \nthe id of the activity that touches it. Neighborhoods of concurrent activities can be permitted to overlap \nif these activities do not modify nodes and edges in the intersection of these neighborhoods (consider \nactivities i3 and i4 in Figure 4). Therefore, additional concurrency is possible if we recognize read-only \ndata structures and do not lock their elements; reader/writer locks are another solution. The most general \nsolution is to use commutativity conditions; this allows iterations to exe\u00adcute in parallel even if they \nperform reduction operations on shared variables, for example. To keep the discussion simple, we do not \ndescribe these alternatives here but refer the interested reader to Kulkarni et al. [39]. The literature \non PRAM algorithms has ex\u00adplored similar variations such as the EREW and combining CRCW models [32, 62]. \n4.1.1 Parallelism pro.les For an algorithm like matrix multiplication for which a static de\u00adpendence \ngraph can be generated, it is possible to give closed-form estimates of the critical path length and \nthe amount of parallelism at each point of execution (these estimates are usually parameter\u00adized by the \nsize of the input). For example, in multiplying two N \u00d7 N matrices using the standard algorithm, there \nare N3 multi\u00adplications that can be performed in parallel. In contrast, amorphous data-parallelism in \nirregular algorithms is usually a function of run\u00adtime values, and closed-form estimates are not generally \npossible. One measure of amorphous parallelism in irregular algorithms is the number of active nodes \nthat can be processed in parallel at each step of the algorithm for a given input, assuming that (i) \nthere is an unbounded number of processors, (ii) an activity takes one time step to execute, (iii) the \nsystem has perfect knowledge of neighborhood and ordering constraints so it only executes ac\u00adtivities \nthat can complete successfully, and (iv) a maximal set of non-con.icting activities is executed at each \nstep. This is called the available parallelism at each step, and a graph showing the avail\u00adable parallelism \nat each step of execution of an irregular algorithm for a given input is called a parallelism pro.le. \nFor algorithms for which a static dependence graph can be generated, the available parallelism at any \nstep corresponds to the width of the dependence graph at that step. In this paper, we will present parallelism \npro.les produced by the ParaMeter tool [38]. Figure 8 shows the parallelism pro.les of Boruvka s and \nPrim s minimal spanning tree (MST) algorithms; the input is a random graph. As explained in Section 5.1, \nBoruvka s algorithm is un\u00adordered while Prim s algorithm is ordered. At .rst sight, it is sur\u00adprising \nthat an ordered algorithm like Prim has any parallelism, but an intuitive explanation is that processing \nactive nodes in the spec\u00adi.ed order is suf.cient but not necessary to produce correct results. A parallel \nimplementation can process active nodes out of order, and as long as no con.icts are detected before \nthe activity com\u00admits, the output produced by the parallel execution will be correct. This is similar \nto how out-of-order execution processors .nd paral\u00adlelism in sequential machine language programs. In \nour experience, many problems can be solved by both ordered and unordered algo\u00adrithms, but the critical \npath is shorter for the unordered algorithm although it may perform more work than its ordered counterpart \n(see Hassaan et al. [26] for more details).  4.2 Exploiting structure to reduce overheads The overheads \nof the baseline system can be reduced by exploiting structure when it is present. The following structure \nis very impor\u00adtant in applications. DEFINITION 3. An implementation of an operator is said to be cautious \nif it reads all the elements of its neighborhood before it modi.es any of them. ParallelismParallelism \n250 200 150 100 50 0 Computation Step (a) Boruvka s unordered MST algorithm 250 200 150 100 50 0 Computation \nStep (b) Prim s ordered MST algorithm Figure 8. MST parallelism pro.les of a random graph with 10,000 \nnodes and 35,605 edges; the edges have random, uniformly dis\u00adtributed weights between 1 and 1,000. Operators \ncan usually be implemented in different ways: for ex\u00adample, one implementation might read node A, write \nto node A, read node B, and write to node B, in that order, whereas a different implementation might \nperform the two reads before the writes. By De.nition 3, the second implementation is cautious, but the \n.rst one is not. In our experience, the natural implementations of most operators such as Delaunay mesh \nre.nement are cautious2. In con\u00adtrast, the operator for the well-known Delaunay triangulation algo\u00adrithm \nof Guibas, Knuth and Sharir [23] does not have a naturally cautious implementation. It performs graph \nmutations called edge .ips, which are done incrementally. Unordered algorithms with cautious operator \nimplementations can be executed speculatively without buffering updates or making backup copies of modi.ed \ndata because all con.icts are detected during the read-only phase of the operator execution. Blandford \net al. [7] exploit this optimization in their DMR implementation; phrasing this optimization in terms \nof algorithmic structure permits a general-purpose system like Galois to use it for other algorithms \n(see M\u00b4 endez-Lojo et al. [47]). Prountzos et al. [54] present a shape analysis for determining cautiousness \nusing static analysis. 4.3 Exploiting structure for coordinated scheduling Compile-time Coordinated \nJust-in-time Strategy Scheduling Run-time Autonomous Figure 9. Scheduling strategies The scheduling \nstrategy implemented in the baseline system can be called autonomous scheduling because activities are \nexe\u00adcuted in an uncoordinated way, requiring online con.ict detection and rollback for correct execution. \nSpeculative overheads are elim\u00adinated if we ensure that only non-con.icting iterations are sched\u00aduled \nfor simultaneous execution, a strategy that we call coordinated scheduling. Figure 9 shows a number of \ncoordinated scheduling strategies. All of these strategies are based on constructing a de\u00adpendence graph \neither explicitly or implicitly, but they do so at dif\u00adferent points during program compilation and execution. \n2 In principle, every operator has a trivial cautious implementation that touches all graph elements \nbefore beginning the computation (equivalently, it locks the whole graph). The obvious disadvantage is \nthat this approach eliminates all parallelism. In terms of the operator formulation, construction of \nthe de\u00adpendence graph involves the following steps: (i) determine all ac\u00adtive nodes, (ii) determine neighborhoods \nand ordering of the cor\u00adresponding activities, and (iii) create a partial order of activities that respects \nneighborhood and ordering constraints. Activities can then be executed in parallel without speculation \nbut with proper synchronization to ensure that the partial order of activities is re\u00adspected. Although \nthis approach seems obvious, ordered, data\u00addriven algorithms like event-driven simulation cannot in general \nbe parallelized using this approach: the execution of one activity may cause a new node to become active, \nand this new activity may have higher priority than and con.ict with existing activities. It is likely \nthat optimistic parallelization is the only general-purpose approach for parallelizing ordered, data-driven \nalgorithms, even if they are expressed in a functional language. All other classes of algorithms can \nbe executed without speculation as described below. 4.3.1 Runtime coordination Unordered data-driven \nalgorithms: These algorithms can be par\u00adallelized without speculation by interleaving the construction \nof the dependence graph with execution of activities. The execution of the algorithm proceeds in rounds. \nIn each round, a set of non\u00adcon.icting activities is selected and executed in parallel without synchronization. \nAny newly created activities are postponed to the next round at which point they are considered for execution \nto\u00adgether with unprocessed activities from the current round. Imple\u00admenting this strategy requires solving \ntwo problems: (i) how do we compute the neighborhoods of activities, and (ii) given a set of activities \nand their neighborhoods, how do we .nd a set of non\u00adcon.icting activities? In general, we must execute \nthe operator completely to .nd the neighborhood of an activity, and this may cause side-effects to global \ndata structures. If an activity is not chosen for execution in the current round (because of con.icts), \nthese side-effects must be undone for correct execution. One solution is to privatize these updates as \nis done in some versions of transactional memory. In effect, activities are executed twice in each round: \nonce with pri\u00advatization to determine neighborhoods, and then again for real if they are chosen for execution \nin the current round. Implemented literally, this strategy is not very ef.cient; fortunately, most algo\u00adrithms \nhave structure that can be exploited to eliminate the need for repeated execution. In all data-driven \nlocal computation algorithms we have studied (see Section 5.2.2), the neighborhood of an activity is \njust the active node and its immediate neighbors in the graph. In morph algorithms, most operator implementations \nare cautious, so the neighborhood of an activity can be determined by executing it partially up to the \npoint where it starts to make modi.cations to its neighborhood. If the activity is chosen for execution \nin that round, execution simply continues from that point. Once the neighborhoods of all activities have \nbeen determined, we can build a con.ict graph in which nodes represent the active nodes from the algorithm, \nand edges represent con.icts between activities. Luby s randomized parallel algorithm can be used to \n.nd a maximal independent set of activities [43], and this set of activities can be executed in parallel \nwithout synchronization. This approach can be viewed as building and exploiting the dependence graph \nlevel by level, with barrier synchronization between levels. The DMR implementation of Hudson et al. \nuses this approach [31]. Topology-driven algorithms: In these algorithms, activities do not create new \nactive nodes, so both unordered and ordered al\u00adgorithms can be executed using runtime coordination. Unordered \ntopology-driven algorithms can be executed in rounds as de\u00adscribed above. A variation of this approach \ncan be used for ordered topology-driven algorithms. In this case, we .nd a maximal pre.x of the sequence \nof active nodes (rather than a maximal independent set of the set of active nodes) such that all active \nnodes in the pre.x have non-interfering neighborhoods, and execute these nodes in parallel. This process \ncan then repeated with the remaining suf.x of active nodes. Notice that runtime coordination can be \nused for all irregular algorithms other than ordered, data-driven algorithms. 4.3.2 Just-in-time coordination \nFor some topology-driven algorithms, the dependence graph is independent of the labels on nodes and edges \nof the graph and it is a function purely of the graph topology. Therefore, a dependence graph can be \ngenerated at runtime after the input graph is given but before the program is executed. We call this \nstrategy just-in-time coordination, and it is a generalization of the inspector-executor method of Saltz \net al. [64]. For topology-driven algorithms, active nodes are known once the input is given, so the remaining \nproblems are the determination of neighborhoods and ordering. In local computation algorithms amenable \nto just-in-time scheduling, these can usually be deter\u00admined from an inspection of the graph and the \nresulting code is called the inspector. A well-known example is the implementation of sparse iterative \nsolvers on distributed-memory computers. The distribution of the graph between processors is known only \nat run\u00adtime, so inspection of the graph is required to determine input de\u00adpendences for use in communication \nschedules, as advocated by Saltz et al. [64]. Other examples are parallel top-down and bottom\u00adup walks \nof trees. In a bottom-up walk, a recursive descent from the root sets up the dependences, and the bottom-up \ncomputations can then be done in parallel with appropriate synchronization; an example is the center-of-mass \ncomputation in n-body methods. For topology-driven morph algorithms amenable to just-in-time scheduling, \ninspection of the graph may be insuf.cient since the structure of the graph can be modi.ed during the \nexecution of the algorithms, changing neighborhoods and dependences. For these algorithms, neighborhoods \nand ordering can be determined by a symbolic execution of the algorithm. Parallel sparse Cholesky fac\u00adtorization \nis the most famous example of this approach [20]. The algorithms is unordered but heuristics like minimal \ndegree order\u00ading are used to order the active nodes for ef.ciency. The algorithm is executed symbolically \nto compute the dependence graph (this phase is called symbolic factorization and the dependence graph \nis called the elimination tree). The elimination tree is then used to perform the actual factorization \nin parallel (this phase is known as numerical factorization). Symbolic factorization is done ef.ciently \nusing Boolean operations, and for large matrices, it takes little time relative to numerical factorization. \nJust-in-time coordination can\u00adnot be used for sparse LU factorization with pivoting since its de\u00adpendence \ngraph is affected by pivoting, which depends on the data values in the matrix. 4.3.3 Compile-time coordination \nSome algorithms amenable to just-in-time coordination have struc\u00adtured input graphs. In that case, the \ndependence graph, suitably pa\u00adrameterized by the unknown parameters of the input graph, can be produced \nat compile-time. For example, if the graph is a grid as it is in .nite-difference methods, the dependence \ngraph is parameter\u00adized by the dimensions of the grid. Other important examples are dense Cholesky and \nLU factorization (the input graph is a clique), the dense Basic Linear Algebra Subroutines (the input \ngraph is a clique), and FFTs (sequences or sequences of sequences). Given the importance of these algorithms \nin high-performance computing, it is not surprising that automatic generation of depen\u00addence graphs for \nthis class of algorithms has received a lot of at\u00adtention. These techniques are known as dependence analysis \nin the literature, and methods based on integer linear programming are successful for regular, dense \narray programs in which array sub\u00adscripts are af.ne functions of loop indices [35]; LU with pivoting \nrequires fractal symbol analysis [48]. Compile-time coordination is also possible regardless of the \ntopology if the algorithm is a topology-driven local computation and the neighborhood of an activity \nis just the active node itself, ignoring read-only data structures. In this case, activities are triv\u00adially \nindependent (subject to ordering constraints) because each one modi.es a disjoint portion of the graph. \nA typical example is com\u00adputing some result for each node in a graph. The output is a vector indexed \nby node. Each activity reads some portion of the graph but only writes to the node-speci.c portion of \nthe output vector. In the literature, most PRAM algorithms and algorithms written using DO-ALL loops \nfall in this category.  4.4 Discussion To the best of our knowledge, the .rst use of optimistic paralleliza\u00adtion \nwas in Jefferson s Timewarp system for event-driven simu\u00adlation [33]. However, Timewarp was not a general-purpose \nparal\u00adlel programming system. Thread-level speculation (TLS) was pro\u00adposed by Rauchwerger and Padua [55] \nfor parallelizing array pro\u00adgrams in which subscripts could not be analyzed by the compiler. This work \nwas very in.uential, and it inspired a lot of work on architectural support for speculative execution \n[61]. TLS systems were designed for languages like FORTRAN and C, so there was no support for don t-care \nnon-determinism or unordered algorithms. Moreover, data abstractions do not play a role in the implementa\u00adtion \nof TLS. Another in.uential line of work is the transactional memory (TM) work of Herlihy, Moss, Harris \nand others [25, 29]. In contrast to our approach, the application programming model is explicitly parallel; \nthreads synchronize using transactions, and the overheads of executing this synchronization construct \nare re\u00adduced using optimistic synchronization. In addition, most TM sys\u00adtems other than boosted systems \n[28] perform memory-level con\u00ad.ict checking rather than ADT-level con.ict checking. This results in spurious \ncon.icts that prevent ef.cient parallel execution. For example, if an iteration of an unordered iterator \nis rolled back, the concrete state of the work-set must also be restored to its original state, and all \nother iterations that were executed since that iteration must also be rolled back [40]. Relatively little \nis known about automatic generation of depen\u00addence graphs for runtime and just-in-time coordination. \nThe dis\u00adcussion in this section shows that there is no sharp dichotomy be\u00adtween regular and irregular \nalgorithms: instead, regular algorithms are a special case of irregular algorithms in the same way that \nmet\u00adric spaces are a special case of general topologies in mathematics. Note that although coordinated \nscheduling seems attractive because there is no wasted work from mis-speculation, the overhead of gen\u00aderating \na dependence graph may limit its usefulness even when it is possible to produce one.  5. Case studies \nof algorithms In this section, we discuss how the tao-analysis described in Sec\u00adtion 3 and the implementation \nstrategies described in Section 4 can be applied to important algorithms. The discussion is organized \nby the type of the operator. 5.1 Morph algorithms Morphs are the most complex variety of operators. \nAlthough they can be viewed abstractly as replacing sub-graphs with other graphs, it is more intuitive \nto classify them as follows. Re.nement: A re.nement operator makes the graph bigger by adding new nodes \nand edges, possibly removing a few nodes and edges in the process. Parallelism 800 600 400 200 0 Computation \nStep Figure 10. Available parallelism in Delaunay mesh re.nement Coarsening: A coarsening operator clusters \nnodes or sub\u00adgraphs together, replacing them with a smaller sub-graph that represents the cluster.  \nGeneral morph: All other operations that modify the graph structure fall in this category.  5.1.1 Re.nement \nData-driven re.nement algorithms usually operate on a single graph. Most topology-driven re.nement operators \noperate on two data structures Gi and Go; Gi is read-only and its topology deter\u00admines the active nodes \nin the algorithm, while Go is morphed by each activity. Map-reduce: In the map-reduce programming model \n[13], a map operation applies a function point-wise to each element of a set or multi-set Si to produce \nanother set or multi-set So.The active nodes are the elements of Si, and they can be processed in any \norder. This is a topology-driven, unordered algorithm, which is a re.nement morph for So since elements \nare added incrementally to So during execution. Streams: A stream operator in languages like StreamIt \n[21] is a re.nement morph from its input streams to its output streams (streams are non-strict sequences \n[53]). Stateless and stateful stream operators can be expressed using unordered and ordered iteration \non sequences. Prim s MST algorithm: Most algorithms that build trees in a top-down fashion use re.nement \nmorphs. Figure 11 shows one implementation of Prim s algorithm for computing MSTs; it is a topology-driven, \nordered algorithm in which the operator is a reader for the graph g and a re.nement morph for tree mst.Ini\u00adtially, \none node is chosen as the root of the tree and added to the MST, and all of its edges are added to the \nordered work-set, or\u00addered by weight. In each iteration, the smallest edge (s, t) is re\u00admoved from the \nwork-set. Note that node s is guaranteed to be in the tree. If t is not in the MST, (s, t) is added to \nthe tree, and all edges (t, u) are added to the work-set, provided u is not in the MST. When the algorithm \nterminates, all nodes are in the MST. This al\u00adgorithm has the same asymptotic complexity as the standard \nalgo\u00adrithm in textbooks [12], but the work-set contains edges rather than nodes. The standard algorithm \nrequires a priority queue in which node priorities can be decreased dynamically. It is unclear whether \nit is worth generalizing the implementation of ordered-set iterators in a general-purpose system like \nGalois to permit dynamic updates to the ordering. N-body tree-building: Top-down tree construction is \nalso used in n-body methods like Barnes-Hut [6] and fast multipole. The tree is a recursive spatial partitioning \nin which each leaf contains a single particle. Initially, the tree is a single node, representing the \nentire space. Particles are then inserted into the tree, splitting leaf nodes so that each leaf node \ncontains only a single particle. The work-set in this case is the set of particles. In contrast to Prim \ns algorithm, this algorithm is unordered because particles can be inserted into the tree in any order. \nAndersen-style inclusion-based points-to analysis: This com\u00adpiler algorithm [3] is an example of a re.nement \nmorph on general graphs. It builds a points-to graph in which nodes represent pro\u00ad 1 Graph g = // read \nin input graph 2 Tree mst ; // create empty tree 3 mst . setRoot ( r ); // r is an arbitrary vertex in \ng 4 OrderedWorkset<Edge> ows ; // ordered by edge weight 5 ows.add(g.getEdges(r)); 6 foreach (Edge (s,t) \nin OrderedSet ows ) { 7 if (mst . contains ( t )) continue ; 8 mst.addEdge(s,t); // s becomes parent \nof t 9 foreach (Edge (t ,u) in Set g. getEdges ( t )) {10 if (!mst.contains(u)) ows.add((t,u)); 11 }12 \n} Figure 11. Top-down tree construction: Prim s MST algorithm c c b nb n cc b unb n v m am am ama (a) \nEdge contraction (b) Node elimination Figure 12. Two kinds of coarsening operators gram variables, and \nan edge (a, b) asserts that variable a may point to b at some point in the program. Each iteration of \nthe algorithm may discover new points-to facts, and if it does, it adds new edges to the points-to graph. \nThis is an unordered, data-driven algorithm that uses a re.nement morph on the graph. Delaunay mesh re.nement: \nThis is an unordered, data-driven morph algorithm on an unstructured graph (see Section 2). Discussion: \nRe.nement algorithms in which graph elements are only added and never removed are called strong re.nement \nalgo\u00adrithms. All the algorithms listed above other than DMR are strong re.nement algorithms. Section \n6.3 describes how this property can be exploited to produce ef.cient implementations. Although parallelism \nin most irregular algorithms is very input dependent, algorithms that use re.nement morphs have a character\u00adistic \npro.le when executed with randomized input data. Figure 10 shows the parallelism pro.le for DMR for an \ninput of 100,000 tri\u00adangles. Available parallelism starts at some level, increases as the data structure \ngets larger (because there is less likelihood of con\u00ad.icts), and then ramps down as work is completed. \nThe parallelism pro.le for Prim s algorithm, shown in Figure 8(b), has a similar pattern in this algorithm, \nthe available parallelism is very small initially since only one activity succeeds in growing the tree \nfrom the root. As the MST gets larger, there are more sites where the tree can grow, so parallelism ramps \nup and then ramps down as the MST is completed. Tree-building in Barnes-Hut exhibits a similar parallelism \npro.le, as can be seen in Figure 13(a).  5.1.2 Coarsening There are three main ways of doing coarsening: \nedge contraction, node elimination and sub-graph contraction. Edge contraction An edge is eliminated \nfrom the graph by fus\u00ading the two nodes at its end points and removing redundant edges from the resulting \ngraph, as shown in Figure 12(a). When redundant edges are eliminated, the weight on the remaining edge \nis adjusted in application-speci.c ways. In sparse graphs, each edge contrac\u00adtion affects a relatively \nsmall neighborhood, so in suf.ciently large graphs, many edge contraction operations can happen in parallel. \nBoruvka s MST algorithm: Boruvka s algorithm [12] computes MSTs bottom-up by performing edge contraction \non the input graph until there is only one node left. A separate graph represents the MST as it is built \nbottom-up. The MST is initialized with every node in the input graph forming its own single-node tree, \ni.e., a forest. The active nodes are the nodes remaining in the input graph. In each iteration, an active \nnode n .nds the minimum weight edge (n, m) incident on it and performs edge contraction along this edge. \nThis edge is added to the MST where it connects two previously disjoint trees. A new node nm is created \nin the input graph to represent the merged nodes n and m. If there are redundant edges during edge contraction, \nonly the least weight edge is kept. Finally, nm is added back to the work-set. When the input graph has \nbeen contracted to one node, the MST graph will be the correct minimal spanning tree of the input graph. \n Figure 8(a) shows a parallelism pro.le for Boruvka s algorithm. Interestingly, Kruskal s algorithm [12] \nalso .nds MSTs by per\u00adforming edge contraction, but it iterates over an ordered work-set of edges, sorted \nby edge weight. Metis graph partitioner: Graph coarsening by edge contraction is a key step in the Metis \ngraph partitioner [34]. This algorithm builds a sequence of successively coarser graphs until a coarse\u00adenough \ngraph is obtained; this graph is then partitioned, and the partitioning is interpolated back to the original \ngraph. Each of the coarsening steps is performed by an unordered, topology-driven morph (the nodes of \nthe .ner graph are the active nodes). The parallel implementation of Metis uses runtime coordinated scheduling. \nThe problem of .nding a maximal independent set of edges that can be contracted in parallel can be solved \nby .nding maximal matchings [12]. Ef.cient heuristics are known for comput\u00ading maximal cardinality matchings \nand maximal weighted match\u00adings in graphs of various kinds. Metis uses randomized matching since that \nseems to perform well in practice; this strategy is well\u00adsuited for autonomous scheduling as well. Agglomerative \nclustering and map/reduce: Agglomerative clus\u00adtering, a well-known data-mining algorithm, also uses a \ncoarsening morph. The input is (i) a data-set, and (ii) a measure of the dis\u00adtance between items in the \ndata-set. At each step, the two closest points in the data-set are clustered together and replaced by \na sin\u00adgle new point that represents the new cluster. The location of this new point may be determined \nheuristically [59]. The greedy strict consensus merger (SCM) algorithm for phylogeny reconstruction implements \nthis algorithm for a set of trees. These algorithms can be expressed using an ordered set iterator. The \nreduce operation in the map-reduce model [13] can be implemented in many ways; an in-place reduction \ncan be implemented by an unordered iterator in which the operator replaces randomly chosen pairs of elements \nfrom the set with the result of applying the reduction operation to these elements. Node elimination \nGraph coarsening can also be based on node elimination. Each step removes a node from the graph and inserts \nedges as needed between its erstwhile neighbors to make a clique, adjusting weights on the remaining \nnodes and edges appropriately. In Figure 12(b), node u is eliminated, and edges (b, v), (v, n) and (n, \nb) are inserted to make {b, v, n} a clique. Node elimination is the graph-theoretic foundation of matrix \nfactorization algorithms such as Cholesky and LU factorizations. Sparse Cholesky factorization in particular \nhas received a lot of attention in the numerical linear algebra community. The new edges inserted by \nnode elimination are called .ll since they correspond to zeroes in the original matrix that become non-zeros \nas a result of the elimination process. Different node elimination orders result in dif\u00adferent amounts \nof .ll in general; therefore, although the basic algo\u00adrithm is unordered, practical implementations of \nsparse Cholesky factorization use heuristic orderings for node elimination to mini\u00admize .ll. One heuristic \nis minimal-degree ordering, which greedily picks the node with minimal degree at each elimination step. \nJust\u00adin-time coordination is used to schedule computations [20]. Sub-graph contraction Graphs can be \ncoarsened by contracting entire sub-graphs at a time (edge contraction is a special but im\u00adportant sub-case). \nIn the compiler literature, elimination-based al\u00adgorithms perform data.ow analysis on control-.ow graphs \nby con\u00adtracting structured sub-graphs whose data.ow behaviors have a concise description. Data.ow analysis \nis performed on the reduced graph, and within contracted sub-graphs, interpolation is used to determine \ndata.ow values. This idea can be used recursively on the reduced graph. Sub-graph contraction can be \nperformed in paral\u00adlel. This approach to parallel data.ow analysis has been studied by Ryder [41] and \nSoffa [37].  5.1.3 General morph Some applications make structural updates that are neither re.ne\u00adments \nnor coarsenings, but many of these updates may nevertheless be performed in parallel. Some algorithms \nbuild trees using complicated structural ma\u00adnipulations that cannot be classi.ed neatly as top-down or \nbottom\u00adup construction. For example, when values are inserted into a heap or a red-black tree, the .nal \ndata structure is a tree, but each in\u00adsertion may perform complex manipulations [12]. The structure of \nthe .nal heap or red-black tree depends on the order of insertions, but for most applications, any of \nthese .nal structures is adequate, so this is an example of don t-care non-determinism, and it can be \nexpressed with an unordered set iterator. Algorithms that perform general morph operations on trees usu\u00adally \nrequire optimistic parallelization. The simple con.ict detec\u00adtion policy described in Section 4.1, which \nensures disjointness of neighborhoods, is not adequate for these applications since every neighborhood \ncontains the root of the tree. This class of algorithms may bene.t from mechanisms like transactional \nmemory that use more sophisticated con.ict detection policies [29]; in fact, the par\u00adallelization of \nred-black tree operations is a standard microbench\u00admark in the literature on transactional memory. Graph \nreduction of functional language programs and social network maintenance [10] are general morphs on graphs. \n 5.2 Local computation algorithms We divide our discussion of local computation algorithms based on \nwhether their active nodes are topology-driven or data-driven. 5.2.1 Topology-driven local computation \nalgorithms Cellular automata: Cellular automata operate on grids of one or two dimensions. Grid nodes \nrepresent cells of the automaton, and the state of a cell c at time t is a function of the states at \ntime t-1 of cells in some neighborhood around c. This iterative scheme can be written using unordered \niterators. A large variety of neighborhoods (stencils) are used in cellular automata. Finite-differences: \nA similar state update scheme is used in .nite-difference methods for the numerical solution of partial \ndif\u00adferential equations (PDEs) where it is known as Jacobi iteration. In this case, the grid arises from \nspatial discretization of the do\u00admain of the PDE, and nodes hold values of the dependent variable of \nthe PDE. A disadvantage of Jacobi iteration is that it requires two arrays for its implementation to \nhold the states at the current and previous time steps. More complex update schemes have been designed \nto get around this problem. Intuitively, all these schemes blur the sharp distinction between old and \nnew states, so nodes are updated using both old and new values. For example, red-black ordering, or more \ngenerally multi-color ordering, assigns a min\u00adimal number of colors to nodes in such a way that no node \nhas the same color as the nodes in its neighborhood. Nodes of a given color therefore form an independent \nset that can be updated con\u00adcurrently. These algorithms can be expressed using unordered set iterators \nwith one loop for each color. Methods like Gauss-Seidel can be expressed using ordered set iterators. \nIn all these algorithms, active nodes and neighborhoods can be determined from the grid structure, which \nis known at compile\u00adtime. As a result, compile-time scheduling can be very effective for coordinating \nthe computations. Most parallel implementations of Jacobi iteration partition the grid into blocks, and \neach proces\u00adsor is responsible for updating the nodes in one block. This data distribution requires less \ninter-processor communication than other distributions such as row or column cyclic distributions. Tree \ntraversals: Top-down and bottom-up are classic exam\u00adples of tree traversals. The center-of-mass computation \nfor cells in Barnes-Hut and other n-body methods are performed using a bottom-up walk over the spatial \ndecomposition tree. This traversal can be expressed using an ordered iterator. For a tree, the amount \nof parallelism decreases as the computation advances up the tree, as can be seen in Figure 13(a). Sparse \nMVM: The key operation in iterative linear system solvers like the conjugate-gradient method and GMRES \nis sparse matrix-vector multiplication (MVM), y = Ax, in which the matrix A is an N \u00d7 N sparse matrix \nand x and y are dense vectors. Such a matrix can be viewed as a graph with N nodes in which there is \na directed edge from node i to node j with weight Aij if Aij is non-zero. This algorithm can be expressed \nusing unordered itera\u00adtion over the nodes of the graph. The inspector-executor method is used to produce \nef.cient communication schedules on distributed\u00admemory machines, as discussed in Section 4.3. Compile-time \ncoor\u00addination is possible on shared-memory machines since the operator is a reader for A and x, and it \nis trivial to determine that each iteration writes into a different element of y. 5.2.2 Data-driven \nlocal computation algorithms In these algorithms, there is an initial set of active nodes, and per\u00adforming \nan activity may cause other nodes to become active, so nodes become active in an unpredictable, data-driven \nfashion. Ex\u00adamples include the pre.ow-push algorithm [12] for the max.ow problem, AI message-passing \nalgorithms such as belief propaga\u00adtion and survey propagation [44], Petri nets, and discrete-event sim\u00adulation \n[33, 49]. In other algorithms, such as some approaches to solving spin Ising models [56], the pattern \nof node updates is de\u00adtermined by externally-generated data such as random numbers. Although graph topology \nis typically less important for data\u00addriven algorithms than it is in topology-driven ones, it can neverthe\u00adless \nbe useful for reasoning about certain algorithms. For example, belief propagation is an exact inference \nalgorithm on trees, but it is an approximate algorithm when used on general graphs because of the loopy \npropagation problem [44]. Grid structure is exploited in spin Ising solvers as well to reduce synchronization \n[56]. Pre.ow-push algorithm: This max.ow algorithm is the archety\u00adpal example of a data-driven local \ncomputation operator. Active nodes are nodes that have excess in-.ow at intermediate stages of the algorithm. \nThe algorithm also maintains at each node a value called height, which is a lower bound on the distance \nof that node to the sink. Two operations, push and relabel, are performed at ac\u00adtive nodes to update \nthe .ow and height values respectively until termination. The algorithm is unordered. Event-driven simulation: \nIn the literature, there are two ap\u00adproaches to parallel event-driven simulation, called conservative \nand optimistic event-driven simulation [49]. Conservative event\u00addriven simulation reformulates the algorithm \nso that in addition to sending data messages, processing stations also send out-of-band messages to update \ntime at their neighbors. Each processing sta\u00adtion can operate autonomously without fear of deadlock, \nand there is no need to maintain an ordered event list. This is an example of algorithm reformulation \nthat replaces an ordered work-set with an unordered work-set. In contrast, Timewarp [33] is an optimistic \npar\u00adallel implementation of event-driven simulation. It can be viewed as an application-speci.c implementation \nof ordered set iterators as described in Section 4.1, with two key differences. First, threads are allowed \nto work on new events created by speculative activities that have not yet committed. This increases parallelism \nbut opens up the possibility of cascading roll-backs. Second, instead of the global commit queue in the \nimplementation of Section 4.1, there are periodic sweeps through the network to update global virtual \ntime [33]. Both of these features can be implemented in a general\u00adpurpose way in a system like Galois, \nbut more study is needed to determine if this is worthwhile.  5.2.3 Discussion Solving .xpoint equations: \nIterative methods for computing solu\u00adtions to systems of equations can usually be formulated in both \ntopology-driven and data-driven ways. A classic example is itera\u00adtive data.ow analysis in compilers. \nSystems of data.ow equations can be solved by iterating over all the equations using a Jacobi or Gauss-Seidel \nformulation until a .xed point is reached; these are topology-driven approaches. Alternately, the classic \nworklist algo\u00adrithm processes an equation only if its inputs have changed; this is a data-driven approach \n[1]. The underlying graph in this applica\u00adtion is the control-.ow graph, and for .ow-sensitive problems, \nthe data.ow values are implemented as labels on nodes or edges. Speeding up local computation algorithms: \nLocal computation algorithms can often be made more ef.cient by a preprocessing step that coarsens the \ngraph, since this speeds up the .ow of information across the graph. The multigrid method for solving \nlinear systems is a classic example. This idea is also used in data.ow analysis of programs [1]. An elimination-based \ndata.ow algorithm is used .rst to coarsen the graph. If the resulting graph is a single node, the solution \nto the data.ow problem is read off by inspection; otherwise, iterative data.ow analysis is applied to \nthe coarse graph. In either case, the solution for the coarse graph is interpolated back into the original \ngraph. One of the .rst hybrid data.ow algorithms along these lines was Allen and Cocke s interval-based \nalgorithm for data.ow analysis. This algorithm .nds and collapses intervals, which are single-entry, \nmultiple-exit loop structures in the control\u00ad.ow graph of the program. Some local computation algorithms \ncan be sped up by period\u00adically computing and exploiting global information. The global\u00adrelabel heuristic \nin pre.ow-push is an example of such an oper\u00adation. Pre.ow-push can be sped up by periodically performing \na breadth-.rst search from the sink to update the height values [12]. In the extreme, global information \ncan be used in every iteration. For example, iterative linear solvers often precondition the matrix iterations \nwith another matrix that is obtained by a graph coarsen\u00ading computation such as incomplete LU or Cholesky \nfactorization.  5.3 Reader algorithms An operator that reads a graph without modifying it in any way \nis a reader operator for that graph. Operators that perform multiple traversals over a .xed graph are \na particularly important category. Each traversal maintains its own state, which is updated during the \ntraversal, so the traversals can be performed concurrently. Force computation in n-body algorithms like \nBarnes-Hut [6] is an exam\u00adple. The force calculation is an unordered iteration over particles that computes \nthe force on each particle by making a top-down traversal of a pre.x of the tree. This step is completely \nparallel since each particle can be processed independently. The only shared data structure in this phase \nis the octree, which is not modi.ed. Another classic example is ray-tracing. Each ray is traced through \nthe scene. If the ray hits an object, new rays may be spawned to account for re.ections and refraction; \nthese rays must also be processed. After the rays have been traced, they are used to construct the rendered \nimage. The key concern in implementing such algorithms is exploiting locality. One approach to enhancing \nlocality in algorithms such as ray-tracing is to chunk similar work together. Rays that will prop\u00adagate \nthrough the same portion of the scene are bundled together and processed simultaneously by a given processor. \nBecause each ray requires the same scene data, this approach can enhance cache locality. A similar approach \ncan be taken in Barnes-Hut: particles in the same region of space are likely to traverse similar parts \nof the octree during the force computation and thus can be processed together to improve locality [58]. \n In some cases, reader algorithms can be more substantially transformed to further enhance locality. \nIn ray-tracing, bundled rays begin propagating through the scene in the same direction but may eventually \ndiverge. Rather than using an apriori grouping of rays, groups can be dynamically updated as rays propagate \nthrough a scene, maintaining locality throughout execution [52]. 5.4 Discussion Some irregular applications \nhave multiple phases, and each phase may use a different operator. N-body methods like Barnes-Hut are \ngood examples; the tree-building phase uses a re.nement morph whereas the force computation phase uses \na reader operator since it does not modify the spatial decomposition tree. This is discussed in more \ndetail in Section 6.1. The structural analysis of algorithms presented in this section is different from \nthe many efforts in the literature to identify paral\u00adlelism patterns, such as the work of Mattson et \nal. [45], Snir s Par\u00adallel Processing Patterns [36] and the Berkeley motifs [51]. These approaches place \nrelated algorithms into categories (dense linear algebra, n-body methods, etc.), whereas this paper proposes \nstruc\u00adtural decompositions of irregular algorithms. For example, n-body methods fall into a single category \nin the Berkeley motifs whereas we distinguish between the operators in the different phases of n\u00adbody \nmethods. To use a biological metaphor, existing approaches produce classi.cations like the Linnaean taxonomy \nin biology, whereas the approach in this paper is more like molecular biology, producing genetic pro.les \nof algorithms. On the other hand, ex\u00adisting classi.cations are broader in scope than ours since they \nseek to categorize implementation mechanisms such as whether task\u00adqueues or the master-worker approach \nis used to distribute work.  6. Case studies of applications In this section, we present experimental \nresults for three algorithms introduced previously: Barnes-Hut n-body simulation, Delaunay mesh re.nement \nand inclusion-based points-to analysis. These al\u00adgorithms were implemented using the Galois system, and \nillustrate how the principles of tao-analysis (in particular, Section 4.3) can be used to optimize performance. \nWe used two machines for our experimental results. The .rst contains two quad-core Intel Xeon X5570 processors \nfor a total of eight cores. The second contains four six-core Intel Xeon X7540 processors for a total \nof 24 cores. Both run Linux 2.6.32. 6.1 Barnes-Hut n-body simulation Barnes-Hut shows how tao-analysis \ncan be used to leverage compile\u00adtime optimizations even though the Galois system uses optimistic parallelization \nas its baseline. Figure 13(a) shows the parallelism pro.le for one time-step of the algorithm. There \nare four phases, each with a different structural classi.cation. 1. Tree build: The .rst phase builds \nthe spatial decomposition tree top-down by inserting particles into the tree and splitting nodes as needed \nso there is one particle per leaf node (topology: tree, operator: re.nement morph, active nodes: topology-driven \nand unordered). Note that the parallelism pro.le is similar to the parallelism pro.les of other re.nement \nmorphs shown in Figure 10.  Computation Step 1 4 8 12 16 20 24 28 (a) Parallelism pro.le for 10,000 \nbodies Threads 24 Figure 14. Speedup for Delaunay mesh re.nement. The input 20 is randomly generated. \nInitially, there are 1,999,998 triangles 16 (951,964 bad triangles). Sequential runtime is 22.2 s. 12 \n8 20 204 Speedup  1 Runtime (s) 15 10 5 15 10 5 Threads (b) Speedup for 1,000,000 bodies; sequential \nruntime is 122.2 s. Figure 13. Parallelism pro.le and speedup for Barnes-Hut. All inputs initialized \nusing the Plummer model. 2. Summarize: The second phase computes the center-of-mass and total mass of \neach internal node using a bottom-up walk of the octree (tree, local computation, topology-driven and \nordered). 3. Force computation: The third phase computes the force acting upon each particle by traversing \nparts of the octree (tree, reader, unordered). 4. Force update: The last phase moves each particle to \na new po\u00adsition (set, local computation, topology-driven and unordered).  Figure 13(b) shows the speedup \non the 24 core machine. Most of the execution time is spent in the force computation phase. By default, \nthe Galois system would use speculative execution for this phase, but tao-analysis reveals that it is \npossible to use compile\u00adtime coordinated scheduling. Using this information, we can exe\u00adcute activities \nnon-speculatively, taking advantage of reduced run\u00adtime overheads. The machine supports simultaneous \nmultithread\u00ading (SMT), and we show a few data points with more than 24 threads, which correspond to adding \nSMT threads. Performance scales well up to 24 threads. After that point, each additional SMT thread improves \nperformance slightly, which suggests that there is room for locality improvements.  6.2 Delaunay mesh \nre.nement Figure 14 shows results for Delaunay mesh re.nement on the 24 core machine. We take advantage \nof the cautious property of the op\u00aderator implementation to reduce some overheads of speculative ex\u00adecution. \nAs before, we show data points for additional SMT threads as well. This application is .oating-point \nintensive. Performance scales well up to 24 threads, but after that point, SMT threads share .oating-point \nresources, which limits continued scalability.  6.3 Inclusion-based points-to analysis Inclusion-based \npoints-to analysis is an example of how properties of operators can be used to reduce synchronization \noverheads. The algorithm performs a context-insensitive, .ow-insensitive analysis that determines the \nvariables that a pointer variable might point to during the execution of a program. A pass through the \nprogram generates a system of set constraints that implicitly de.nes the points-to set for each variable \nin the program. These constraints can be represented as a graph in which nodes represent variables, and \nedges represent constraints. The process of solving these set 0 0 Threads Threads (a) Gimp input (b) \nMplayer input Figure 15. Points-to analysis times. Horizontal line is performance of the reference implementation. \nBest speedup over reference for gimp and mplayer are 3.63 and 3.62 respectively. constraints can be viewed \nin terms of the application of three graph rewrite rules to the constraint graph [46]. Each rewrite rule \nadds edges to the graph but does not re\u00admove existing nodes or edges, so the operator is a strong re.ne\u00adment \nmorph. The baseline implementation described in Section 4.1 would acquire abstract locks on all the nodes \nparticipating in the rewrite rule. However, because the operator is a strong re.nement morph, it is only \nnecessary to acquire a lock on the node at which the new edge is added, reducing synchronization costs. \nFigure 15 shows the performance of this approach on the eight core machine compared to a highly optimized \nsequential reference implementation written by Hardekopf [24]. The results are for two of the benchmarks \nfrom Hardekopf s suite. This is the .rst successful parallelization of Andersen-style points-to analysis. \n 7. Extensions to the amorphous data-parallelism model In this section, we discuss two kinds of parallelism \nthat are not exploited by the basic amorphous data-parallel execution model described in Section 4.1: \nnested amorphous data-parallelism and pipeline parallelism. We also discuss how the task-parallel execu\u00adtion \nmodel .ts into our framework. 7.1 Nested amorphous data-parallelism The pattern of parallelism described \nin this paper arises from ap\u00adplying an operator at multiple active nodes in a graph as shown in Figure \n4. Since the neighborhood of each activity is some re\u00adgion of the graph, an activity can itself be executed \nin parallel; we call this parallelism intra-operator parallelism to distinguish it from the .rst variety \nof parallelism that we can call inter-operator parallelism. Inter-operator parallelism is the dominant \nparallelism pattern in problems for which neighborhoods are small compared to the overall graph since \nit is likely that most activities do not con.ict; in these problems, intra-operator parallelism is usually \n.ne-grain, instruction-level parallelism. Conversely, when each neighborhood is a large part of the graph, \nactivities are likely to con.ict and intra\u00adoperator parallelism may be more important. Inter/intra-operator \nparallelism is an example of nested data-parallelism [8]. The sparsity of the graph usually plays a \nmajor role in this bal\u00adance between inter-and intra-operator parallelism. For many opera\u00adtors, neighborhoods \ninclude all the neighbors of the active node, so if the graph is very densely connected, a single neighborhood \nmay encompass most of the graph and intra-operator parallelism is dom\u00adinant. An extreme case is the factorization \nof dense matrices: the underlying graph is a clique, and each factorization step updates the entire graph, \nas explained in Section 5.1.2, so the only parallelism is intra-operator parallelism. In factorizing \nsparse matrices, inter\u00adoperator parallelism dominates for the .rst few steps; after some number of coarsening \nsteps, the residual graph becomes dense enough that most high-performance sparse matrix codes switch \nto dense matrix techniques to exploit intra-operator parallelism [20].  7.2 Pipeline parallelism In \nsome applications, a data structure is produced incrementally by a computation called the producer and \nread incrementally by an\u00adother computation called the consumer. If it is possible to overlap the executions \nof the producer and consumer, the resulting paral\u00adlelism is called pipeline parallelism. The key problem \nin exploiting pipeline parallelism is determining when the producer has com\u00adpleted all the modi.cations \nit will ever make to an element the consumer wants to read. This problem is undecidable in general, so \none approach to exploiting pipeline parallelism is to execute the consumer speculatively in parallel \nwith the producer, rolling the consumer back if the producer overwrites data read by the con\u00adsumer. This \napproach is unlikely to be practical since the consumer cannot commit any work until the producer has \n.nished execution. Pipeline parallelism becomes practical if the producer is a strong re.nement morph \nsince in that case, each iteration of the producer may add new elements to the graph but it does not \nmodify elements that have already been produced. As long as the con\u00adsumer does not test for the absence \nof an element, the producer and consumer can be executed safely in parallel. This amorphous data-parallel \nview of pipeline parallelism generalizes the standard view of pipeline parallelism in which the shared \ndata structure is restricted to be a stream (sequence), as in StreamIt [21]; for exam\u00adple, we can pipeline \nthe execution of a client of points-to analysis information with the execution of the points-to analysis \nalgorithm described in Section 6.3 since the operator is a re.nement morph.  7.3 Task parallel execution \nTask parallel execution can be used to exploit amorphous data\u00adparallelism by using a divide-and-conquer \nformulation of algo\u00adrithms rather than an iterative formulation. Divide-and-conquer al\u00adgorithms are naturally \ndata-centric since they partition the data structure and execute the algorithm recursively on each partition; \nintuitively, the division step is a way of clustering active nodes based on their location in the data \nstructure. If all data depen\u00addences are subsumed by call/return control dependences, the re\u00adcursive calls \ncan be executed safely in parallel. The Cilk project has explored this approach to exploiting parallelism \n[9]. This approach obviously requires an ef.cient partitioner for the data structure. Partitioning is \nstraightforward for structured and semi-structured topologies, so most task-parallelism studies have \nfocused on algorithms that deal with sets, sequences (ar\u00adrays), cliques (dense matrices), grids and trees. \nPartitioning general graphs is more dif.cult, and for many algorithms, the partition\u00ading step can be \nmore expensive than the algorithm itself. Further\u00admore, ordered algorithms like event-driven simulation \ndo not lend themselves to a natural divide-and-conquer formulation. Therefore, our view of task parallel \nexecution is that it is a way of exploiting amorphous data-parallelism in unordered algorithms that deal \nwith structured and semi-structured topologies: at each stage of the di\u00advision process, activities whose \nneighborhoods lie entirely within a partition are executed during the processing of that partition while \nactivities whose neighborhoods span partitions at that level can be executed when returning from the \nrecursive calls.  8. Conclusions Dependence graphs have been used for more than thirty years by the \nparallel programming community to reason about parallelism in algorithms. In this paper, we argued that \nthis program-centric abstraction is inadequate for most irregular algorithms. To address this problem, \nwe proposed a data-centric formulation of algorithms called the operator formulation, which led to a \nstructural analysis of algorithms called tao-analysis. Tao-analysis reveals that a general\u00adized form \nof data-parallelism called amorphous data-parallelism is ubiquitous in algorithms, and that depending \non the tao-structure of the algorithm, this parallelism may be exploited by compile-time, inspector-executor \nor optimistic parallelization, thereby unifying these seemingly unrelated parallelization techniques. \nParalleliza\u00adtion of regular algorithms is just one special case, and tao-analysis allows many application-speci.c \noptimizations to be generalized. An extensive survey of key algorithms and experimental results from \nthree applications provided evidence for these claims. Parallel programming today is burdened by abstractions \nlike de\u00adpendence graphs that are inadequate for many algorithms and by a plethora of application-speci.c \noptimizations and isolated mecha\u00adnisms. In many ways, this state of the art resembles alchemy rather \nthan a science like chemistry. To move forward, we need a sys\u00adtematic way of understanding parallelism \nand locality a way to generalize from speci.c cases and a way to apply generalizations to speci.c cases. \nIn short, we need a science of parallel program\u00adming. We believe that the operator formulation and tao-analysis \nof algorithms are key elements of such a science.  That which has form is not real; only the amorphous \nendures. When you understand this, you will not return to illusion. Ashtavakra Gita(1:18)  References \n[1] A. Aho, R. Sethi, , and J. Ullman. Compilers: principles, techniques, and tools. Addison Wesley, \n1986. [2] P. An, A. Jula, S. Rus, S. Saunders, T. Smith, G. Tanase, N. Thomas, N. Amato, and L. Rauchwerger. \nSTAPL: An adaptive, generic parallel C++ library. In LCPC, 2003. [3] L.O.Andersen. Program Analysis and \nSpecialization for the C Pro\u00adgramming Language. PhD thesis, DIKU, University of Copenhagen, 1994. [4] \nArvind and R.S.Nikhil. Executing a program on the MIT tagged-token data.ow architecture. IEEE Trans. \non Computers, 39(3), 1990. [5] D. Bader and G. Cong. Fast shared-memory algorithms for computing the \nminimum spanning forest of sparse graphs. Journal of Parallel and Distributed Computing, 66(11):1366 \n1378, 2006. [6] J. Barnes and P. Hut. A hierarchical o(n log n) force-calculation algorithm. Nature, \n324(4), December 1986. [7] D. K. Blandford, G. E. Blelloch, and C. Kadow. Engineering a com\u00adpact parallel \nDelaunay algorithm in 3D. In Symposium on Computa\u00adtional Geometry, pages 292 300, 2006. [8] G. Blelloch. \nProgramming parallel algorithms. Communications of the ACM, 39(3), March 1996.  [9] R. D. Blumofe, C. \nF. Joerg, B. C. Kuszmaul, C. E. Leiserson, K. H. Randall, and Y. Zhou. Cilk: an ef.cient multithreaded \nruntime system. SIGPLAN Not., 30(8):207 216, 1995. [10] U. Brandes and T. Erlebach, editors. Network \nAnalysis: Methodologi\u00adcal Foundations. Springer-Verlag, 2005. [11] L. P. Chew. Guaranteed-quality mesh \ngeneration for curved surfaces. In SCG, 1993. [12] T. Cormen, C. Leiserson, R. Rivest, and C. Stein, \neditors. Introduction to Algorithms. MIT Press, 2001. [13] J. Dean and S. Ghemawat. Mapreduce: Simpli.ed \ndata processing on large clusters. In OSDI, 2004. [14] B. Delaunay. Sur la sphere vide. Izvestia Akademii \nNauk SSSR, Otdelenie Matematicheskikh i Estestvennykh Nauk,, 7:793 800, 1934. [15] J. Dennis. Data.ow \nideas for supercomputers. In CompCon, 1984. [16] E. Dijkstra. A Discipline of Programming. Prentice Hall, \n1976. [17] P. Diniz and M. Rinard. Commutativity analysis: a new analysis technique for parallelizing \ncompilers. ACM TOPLAS, 19(6), 1997. [18] H. Ehrig and M. L\u00a8owe. Parallel and distributed derivations \nin the single-pushout approach. Theoretical Computer Science, 109:123 143, 1993. [19] R. Ghiya and L. \nHendren. Is it a tree, a dag, or a cyclic graph? a shape analysis for heap-directed pointers in C. In \nPOPL, 1996. [20] J. R. Gilbert and R. Schreiber. Highly parallel sparse Cholesky fac\u00adtorization. SIAM \nJournal on Scienti.c and Statistical Computing, 13:1151 1172, 1992. [21] M. I. Gordon, W. Thies, and \nS. Amarasinghe. Exploiting coarse\u00adgrained task, data, and pipeline parallelism in stream programs. In \nASPLOS, 2006. [22] D. Gregor and A. Lumsdaine. Lifting sequential graph algorithms for distributed-memory \nparallel computation. In OOPSLA, 2005. [23] L. J. Guibas, D. E. Knuth, and M. Sharir. Randomized incremen\u00adtal \nconstruction of delaunay and voronoi diagrams. Algorithmica, 7(1):381 413, December 1992. [24] B. Hardekopf \nand C. Lin. The ant and the grasshopper: fast and accurate pointer analysis for millions of lines of \ncode. In PLDI, 2007. [25] T. Harris and K. Fraser. Language support for lightweight transactions. In \nOOPSLA, pages 388 402, 2003. [26] M. A. Hassaan, M. Burtscher, and K. Pingali. Ordered vs. unordered: \na comparison of parallelism and work-ef.ciency in irregular algorithms. In PPoPP, 2011. [27] L. Hendren \nand A. Nicolau. Parallelizing programs with recursive data structures. IEEE TPDS, 1(1):35 47, January \n1990. [28] M. Herlihy and E. Koskinen. Transactional boosting: a methodology for highly-concurrent transactional \nobjects. In PPoPP, 2008. [29] M. Herlihy and J. E. B. Moss. Transactional memory: architectural support \nfor lock-free data structures. In ISCA, 1993. [30] S. Horwitz, P. P.effer, and T. Reps. Dependence analysis \nfor pointer variables. In PLDI, 1989. [31] B. Hudson, G. L. Miller, and T. Phillips. Sparse parallel \nDelaunay mesh re.nement. In SPAA, 2007. [32] J. JaJa. An Introduction to Parallel Algorithms. Addison-Wesley, \n1992. [33] D. R. Jefferson. Virtual time. ACM TOPLAS, 7(3), 1985. [34] G. Karypis and V. Kumar. Multilevel \nk-way partitioning scheme for irregular graphs. JPDC, 48(1):96 129, 1998. [35] K. Kennedy and J. Allen, \neditors. Optimizing compilers for modern architectures. Morgan Kaufmann, 2001. [36] F. Kjolstad and M. \nSnir. Ghost cell pattern. In Workshop on Parallel Programming Patterns, 2010. [37] R. Kramer, R. Gupta, \nand M. L. Soffa. The combining DAG: A tech\u00adnique for parallel data .ow analysis. IEEE Transactions on \nParallel and Distributed Systems, 5(8), August 1994. [38] M. Kulkarni, M. Burtscher, R. Inkulu, K. Pingali, \nand C. Cascaval. How much parallelism is there in irregular applications? In PPoPP, 2009. [39] M. Kulkarni, \nD. Nguyen, D. Prountzos, X. Sui, and K. Pingali. Ex\u00adploiting the commutativity lattice. In PLDI, 2011. \n[40] M. Kulkarni, K. Pingali, B. Walter, G. Ramanarayanan, K. Bala, and L. Chew. Optimistic parallelism \nrequires abstractions. In PLDI, 2007. [41] Y. Lee and B. G. Ryder. A comprehensive approach to parallel \ndata .ow analysis. In Supercomputing, pages 236 247, 1992. [42] M. Lowe and H. Ehrig. Algebraic approach \nto graph transformation based on single pushout derivations. In Workshop on Graph-theoretic concepts \nin computer science, 1991. [43] M. Luby. A simple parallel algorithm for the maximal independent set \nproblem. SIAM J. Comput., 15, 1986. [44] D. Mackay. Information Theory, Inference and Learning Algorithms. \nCambridge University Press, 2003. [45] T. Mattson, B. Sanders, and B. Massingill. Patterns for Parallel \nProgramming. Addison-Wesley Publishers, 2004. [46] M. M\u00b4endez-Lojo, A. Mathew, and K. Pingali. Parallel \nAnderson-style points-to analysis. In OOPSLA, 2010. [47] M. M\u00b4endez-Lojo, D. Nguyen, D. Prountzos, X. \nSui, M. A. Hassaan, M. Kulkarni, M. Burtscher, and K. Pingali. Structure-driven optimiza\u00adtions for amorphous \ndata-parallel programs. In PPoPP, 2010. [48] V. Menon, K. Pingali, and N. Mateev. Fractal symbolic analysis. \nACM TOPLAS, March 2003. [49] J. Misra. Distributed discrete-event simulation. ACM Comput. Surv., 18(1):39 \n65, 1986. [50] D. Nguyen and K. Pingali. Synthesizing concurrent schedulers for irregular algorithms. \nIn ASPLOS, 2011. [51] D. Patterson, K. Keutzer, K. Asanovica, K. Yelick, and R. Bodik. Berkeley dwarfs. \nhttp://view.eecs.berkeley.edu/. [52] M. Pharr, C. Kolb, R. Gershbein, and P. Hanrahan. Rendering complex \nscenes with memory-coherent ray tracing. In SIGGRAPH, 1997. [53] K. Pingali and Arvind. Ef.cient demand-driven \nevaluation. part 1. ACM Trans. Program. Lang. Syst., 7, April 1985. [54] D. Prountzos, R. Manevich, K. \nPingali, and K. McKinley. A shape analysis for optimizing parallel graph programs. In POPL, 2011. [55] \nL. Rauchwerger and D. A. Padua. The LRPD test: Speculative run\u00adtime parallelization of loops with privatization \nand reduction paral\u00adlelization. IEEE Trans. Parallel Distrib. Syst., 10(2):160 180, 1999. [56] E. E. \nSantos, S. Feng, and J. M. Rickman. Ef.cient parallel algorithms for 2-dimensional Ising spin models. \nIn IPDPS, 2002. [57] J. T. Schwartz, R. B. K. Dewar, E. Dubinsky, and E. Schonberg. Programming with \nsets: An introduction to SETL. Springer-Verlag, 1986. [58] J. P. Singh, C. Holt, T. Totsuka, A. Gupta, \nand J. L. Hennessy. Load balancing and data locality in adaptive hierarchical n-body methods: Barnes-hut, \nfast multipole, and radiosity. Journal Of Parallel and Distributed Computing, 27, 1995. [59] P.-N. Tan, \nM. Steinbach, and V. Kumar, editors. Introduction to Data Mining. Pearson Addison Wesley, 2005. [60] \nC. Verbrugge. A Parallel Solution Strategy for Irregular, Dynamic Problems. PhD thesis, McGill University, \n2006. [61] T. N. Vijaykumar, S. Gopal, J. E. Smith, and G. Sohi. Speculative versioning cache. IEEE Trans. \nParallel Distrib. Syst., 12(12):1305 1317, 2001. [62] U. Vishkin et al. Explicit multi-threading (xmt) \nbridging models for instruction parallelism. In SPAA, 1998. [63] N. Wirth. Algorithms + Data Structures \n= Programs. Prentice-Hall, 1976. [64] J. Wu, R. Das, J. Saltz, H. Berryman, and S. Hiranandani. Distributed \nmemory compiler design for sparse problems. IEEE Transactions on Computers, 44, 1995.  \n\t\t\t", "proc_id": "1993498", "abstract": "<p>For more than thirty years, the parallel programming community has used the <i>dependence graph</i> as the main abstraction for reasoning about and exploiting parallelism in \"regular\" algorithms that use dense arrays, such as finite-differences and FFTs. In this paper, we argue that the dependence graph is not a suitable abstraction for algorithms in new application areas like machine learning and network analysis in which the key data structures are \"irregular\" data structures like graphs, trees, and sets.</p> <p>To address the need for better abstractions, we introduce a data-centric formulation of algorithms called the <i>operator formulation</i> in which an algorithm is expressed in terms of its action on data structures. This formulation is the basis for a structural analysis of algorithms that we call <i>tao-analysis</i>. Tao-analysis can be viewed as an abstraction of algorithms that distills out algorithmic properties important for parallelization. It reveals that a generalized form of data-parallelism called <i>amorphous data-parallelism</i> is ubiquitous in algorithms, and that, depending on the tao-structure of the algorithm, this parallelism may be exploited by compile-time, inspector-executor or optimistic parallelization, thereby unifying these seemingly unrelated parallelization techniques. Regular algorithms emerge as a special case of irregular algorithms, and many application-specific optimization techniques can be generalized to a broader context.</p> <p>These results suggest that the operator formulation and tao-analysis of algorithms can be the foundation of a systematic approach to parallel programming.</p>", "authors": [{"name": "Keshav Pingali", "author_profile_id": "81100554731", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690452", "email_address": "pingali@cs.utexas.edu", "orcid_id": ""}, {"name": "Donald Nguyen", "author_profile_id": "81435601909", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690456", "email_address": "ddn@cs.utexas.edu", "orcid_id": ""}, {"name": "Milind Kulkarni", "author_profile_id": "81331496893", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2690457", "email_address": "milind@purdue.edu", "orcid_id": ""}, {"name": "Martin Burtscher", "author_profile_id": "81100246199", "affiliation": "Texas State University--San Marcos, San Marcos, TX, USA", "person_id": "P2690458", "email_address": "burtscher@txstate.edu", "orcid_id": ""}, {"name": "M. Amber Hassaan", "author_profile_id": "81453621929", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690459", "email_address": "ahassaan@ices.utexas.edu", "orcid_id": ""}, {"name": "Rashid Kaleem", "author_profile_id": "81485658532", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690460", "email_address": "rashid@ices.utexas.edu", "orcid_id": ""}, {"name": "Tsung-Hsien Lee", "author_profile_id": "81542653956", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690461", "email_address": "zongsian@ices.utexas.edu", "orcid_id": ""}, {"name": "Andrew Lenharth", "author_profile_id": "81331497544", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690462", "email_address": "andrewl@lenharth.org", "orcid_id": ""}, {"name": "Roman Manevich", "author_profile_id": "81100232411", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690463", "email_address": "roman@ices.utexas.edu", "orcid_id": ""}, {"name": "Mario M&#233;ndez-Lojo", "author_profile_id": "81388602261", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690453", "email_address": "marioml@ices.utexas.edu", "orcid_id": ""}, {"name": "Dimitrios Prountzos", "author_profile_id": "81388601660", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690454", "email_address": "dprountz@cs.utexas.edu", "orcid_id": ""}, {"name": "Xin Sui", "author_profile_id": "81542944756", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690455", "email_address": "xinsui@ices.utexas.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993501", "year": "2011", "article_id": "1993501", "conference": "PLDI", "title": "The tao of parallelism in algorithms", "url": "http://dl.acm.org/citation.cfm?id=1993501"}