{"article_publication_date": "06-04-2011", "fulltext": "\n Caisson:A Hardware Description Languagefor Secure Information Flow XunLi MohitTiwari JasonK. Oberg* \nVineeth Kashyap FredericT. Chong TimothySherwood Ben Hardekopf Department of Computer Science *Department \nof Computer Science and Engineering University of California, Santa Barbara University of California, \nSan Diego Santa Barbara, CA San Diego, CA {xun,tiwari,vineeth,chong,sherwood,benh}@cs.ucsb.edu jkoberg@cs.ucsd.edu \nAbstract Information .ow is an important security property that must be in\u00adcorporated from the ground \nup, including at hardware design time, toprovideaformal basisforasystem srootof trust.Weincorporate insights \nand techniques from designing information-.ow secure programming languages to provide a new perspective \non design\u00ading secure hardware.We describea new hardware description lan\u00adguage, Caisson, that combines \ndomain-speci.c abstractions com\u00admon to hardware design with insights from type-based techniques used \nin secure programming languages. The proper combination of these elements allows for an expressive, provably-secure \nHDL that operatesatafamiliarlevelof abstractiontothetarget audienceof the language, hardware architects. \nWehave implementeda compilerfor Caissonthat translatesde\u00adsigns intoVerilog and then synthesizes the designs \nusingexisting tools.Asanexampleof Caisson s usefulnesswehave addressedan open problem in secure hardware \nby creating the .rst-ever prov\u00adably information-.ow secure processor with micro-architectural features \nincluding pipelining and cache.We synthesize the secure processor and empirically compare it in terms \nof chip area, power consumption, and clock frequencywith both a standard (insecure) commercial processor \nand alsoa processor augmented at thegate level to dynamically track information .ow. Our processor is \ncom\u00adpetitive with the insecure processor and signi.cantly better than dynamic tracking. Categories and \nSubject Descriptors B.6.3[Design Aids]: Hard\u00adware Description Languages General Terms Security,Veri.cation, \nLanguages Keywords Hardware Description Language, Non-interference, State Machine 1. Introduction High-assurance \nembedded systems such as those used in banks, aircraft and cryptographic devices all demand strong guarantees \non information .ow. Policies may target con.dentiality, so that secret Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page.To copyotherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, \nUSA. Copyright c . 2011ACM 978-1-4503-0663-8/11/06... $10.00 information never leaks to unclassi.ed outputs, \nor they may tar\u00adget integrity, so that untrusted data can never affect critical system data. The high \ncost of a policyviolation ensures that these systems are evaluated extensively before being deployed; \nfor instance, cer\u00adtifying systems using Common Criteria [2] or FIPS [3] requires a painstaking process \nat a cost of millions of dollars over multiple years [4]. Information .ow policies are expressed using \na lattice of secu\u00adrity levels [14] such that higher elements in the lattice correspond to information \nwith more restricted .ow (i.e., secret information for con.dentiality or untrusted information for integrity).Asimple \nexample of a security lattice would be the typical military clas\u00adsi.cation levels: Unclassified . Secret \n. Top Secret. An important information .ow policy based on such lattices is non\u00adinterference [18], which \nrequires that no information at a given level in the lattice can .ow anywhere except to higher elements \nin the lattice (e.g., Secret information can .ow to Top Secret, but not vice-versa). High-assurance systems \nrequire a static guar\u00adantee of non-interference and depend on a hardware-based root of trust to enforce \nthis policy.We presenta new hardware description language named Caisson that meets this need by extending \nHDLs like Verilog with language abstractions that enable precise static veri.cation of secure synchronous \nhardware designs. 1.1 Secure Hardware Design While ciphers providea sound theoretical primitive forbuilding \nse\u00adcure systems, their actual implementations have been shown to be a rich sourceof vulnerabilities. \nNumerous attacksexploit hardware structures such as shared data caches [35], instruction caches [6], \nand branch predictors[5,7]to leak information aboutprivatekeys. Other studies have found vulnerabilities \nlurking in obscure and even undocumented corners of hardware designs [41], e.g., when the .oating point \nregisters are persistent across context switches. Complete information .ow security must begin with a \nprincipled approach to designing hardware that accounts for the intricate in\u00adteraction among different \nhardware components, analyzes the hard\u00adware design in its entirety,and does so ef.ciently enough to be \nuse\u00adful in practice. Note that non-digital side channels such as power analysis [25] are not within the \nscope of this paper. Existing work has explored using hardware assistance to dy\u00adnamically track information \n.owand prohibit leaks [12, 13, 38, 43]. However, most such systems only track information .ow at the \nISA level or above, ignoring micro-architectural features such as caches and branch predictors that can \nleak information. These sys\u00adtems cannot protect against the attacks outlined above. One existing system, \nGLIFT [46], dynamically tracks informa\u00adtion .ow at the gate-level and does take micro-architectural fea\u00adtures \ninto account; however, this technique requires the informa\u00adtion tracking logic to be physically instantiated \nin the synthesized circuit, greatly increasing chip area and power consumption. Also, GLIFT only detects \npolicyviolations at runtime; it cannot guaran\u00adtee statically that no violations will occur. GLIFT is \ncurrently the only alternativefor enforcing information .owfor an entire proces\u00adsor below the ISA level \nof abstraction, and we use GLIFT as our main comparison point in our evaluation.  1.2 OurApproach In \ncontrast to existing approaches, we take language-level tech\u00adniques for secure information .ow and apply \nthem to domain\u00adspeci.c abstractions for hardware design (speci.cally, .nite state machines) to create \na new Hardware Description Language (HDL) named Caisson. Our goal is to enable the creation of synchronous \nhardware designs that are statically-veri.able as secure. Additional bene.ts of Caisson are that it allows \nhardware designers to operate at familiar level of abstraction, enables architects to quickly and easily \niterate through potential designs without having to wait for synthesis and simulation to test security \nproperties, and the result\u00ading designs do not suffer from the crippling overhead that comes with dynamic \ntracking in terms of additional chip area and power consumption While there are existing HDLs based on \n.nite state machines, none target security as a .rst-class concern. Caisson employs two novel features \non top of .nite state machines, nested states and parameterized states (described in \u00a72) to enable precise \nand expressive enforcement of security policies. To demonstrate the utility of these features and of \nCaisson in general, we design an information-.ow secure processor in Caisson. Designing secure hardware \ncontrollers is an active research area, and specifying a statically-veri.able secure general-purpose \nprocessor is an open problem. Such processors have an important application in high\u00adassurance embedded \nsystems such as those found in aircraft and automobiles [27]. Current tools and methodologies for secure \nhard\u00adware design are laborious and expensive (taking millions of dollars and multiple years to complete \neven simple designs); a general\u00adpurpose processor with microarchitectural features such as pipelin\u00ading \nand cache is notorious in the hardware community for being too complicated to design in a veri.ably secure \nmanner. Caisson is based onkey insights into secure hardware design, and it provides language-level support \nfor these design patterns. We believe, and have found in our own experience, that Caisson promotes thinking \nabout secure hardware design in new, useful ways that don tnaturally arise in existing languages.  1.3 \nContributions This paper makes the following speci.c contributions: Wedescribe Caisson,ahardware description \nlanguage targeting statically-veri.able information-.ow secure hardware design.  We formally prove that \nCaisson enforces timing-sensitive non\u00adinterference.  We design and implementaveri.ably information-.ow \nsecure processor with complex micro-architectural features including pipelining and cache.  Wesynthesize \nour design and empirically compare it with an in\u00adsecure commercial CPU design as well asaGLIFT CPU design \nthat dynamically tracks information .ow.We .nd that Caisson introduces much less overhead than GLIFT \nover the baseline processor in terms of chip area (1.35\u00d7 vs. 3.34\u00d7), clock fre\u00adquency(1.46\u00d7 vs. 2.63\u00d7)and \npower (1.09\u00d7 vs. 2.82\u00d7).  The rest of the paper is organized as follows.We begin in \u00a72 by informally \ndescribing the Caisson language and motivating its Figure 1. State Machine Diagram of Execution Lease \nController features. In \u00a73we formalize the language description and providea proof sketch of its security \nproperties. In \u00a74we describe the design of a secure processor in Caisson and empirically evaluate the \nchar\u00adacteristics of the synthesized design against a comparable GLIFT hardware design. \u00a75discusses related \nwork, and\u00a76concludes. 2. Overview of Caisson Inthis sectionweprovideanoverviewofthe Caisson languageand \nmotivate its design viaa simple hardwareexample.For concrete\u00adness, we speci.cally address the issue of \nintegrity using a 2-level lattice Trusted . Untrusted1 (though Caisson can be used for arbitrary lattices).We \ndemonstrate the Caisson language using an Execution Lease secure hardware controller [45].We .rst review \nthe concept of execution leases, then demonstrate how Caisson can createastatically-veri.able instantiationofanexecution \nlease con\u00adtroller. Execution Leases An execution lease is an architectural mech\u00adanism used to allow trusted \ncode to grant untrusted code limited access to machine resources. One use-case is to allow a trusted \nseparationkernel[24]to securely multiplexmultiple untrustedpro\u00adcesses on a CPU. One can think of a lease \nas a space-time sandbox that allows an untrusted process to take over the CPU and execute code using \nonly a limited range of memory and a limited amount of time; the lease mechanism forces untrusted code \nto relinguish control back to the trusted code when its time allotment expires. Figure1givesa state-machine \ndiagramof theexecution lease con\u00adtroller. The trusted master state sets a timer and transfers control \nto either the untrusted set of slave states (S1 and S2) or the trusted set of slave states (S3 and S4). \nEach set of slave states can transition among themselves arbitrarily during the lease,but once the timer \nexpires, control is relinguished back to the trusted master state. Caisson Language Finite-state representations \nof hardware con\u00adtrol systems, such as in Figure 1, are popular in hardware design. Existing tools such \nas Altera Quartus, Xilinx ISE, Statecharts [20], and Esterel [44] are widely used to model systems explicitly \nas state machines. In designing Caisson we wish to capitalize on this trendandallowhardware designersto \noperateatafamiliarlevelof abstraction, allowing hardware designs to be easily and transpar\u00adently modeled \nusing Caisson.For this reason,we base the Caisson language on .nite-state machines.To illustrate this \nconcept, Fig\u00adure 2(a) shows a Caisson implementation of the lease controller. This implementation is \nsecure (i.e., does not leak Untrusted in\u00adformation),but it is not typable in the Caisson type system \nwe in\u00adtroducein Section3.Wewillusethisversionofthe implementation to motivate and introduce twofeatures \nof Caisson: nested states and parameterized states. First, though, we give a quick illustration of the \nCaisson language using Figure2(a). The name of the entire program is lease, and it uses four hard\u00adware \nregisters: timer, data1, data2, and mode. Each register has 1This ordering can be confusing,but is correct: \nUntrusted is high in the lattice because the .ow of untrusted information should be more restricted than \nthe .ow of trusted information.  Figure 2. Implementation of the Lease Controller in Caisson language. \n(a) Implementation only with the ability to explicitly de.ne each individual state (b) Implementation \nwith nested states (c) Implementation with parameterized states. typeL(low, i.e. Trusted)except for data1, \nwhichisH(high, i.e. Untrusted). There are .ve states corresponding to the .ve states in Figure 1; master, \nS3, and S4 are Trusted, while S1 and S2 are Untrusted. The master state uses mode to alternately transfer \ncontrol (using the goto command) to either S1 or S3. Each of S1 S4 are similar: theydecrement timer, \ncheck whether timer is 0, and if so transition back to the master state. Otherwise, depend\u00ading on thevalueof \ndata1 (data2), theytransition to themselves or their fellow slave state. Each state corresponds to a \ncombinational hardware logic circuit and takes exactly one cycle to execute. The reason that Figure 2(a) \nis not typable is that timer is decremented in states S1 and S2. These states are Untrusted, yet theymanipulate \nTrusted information (i.e., timer). This manipu\u00adlation can create an implicit information leak from the \nhigh secu\u00adrity level(Untrusted)to thelow securitylevel(Trusted) if the Untrusted states modify the Trusted \nregister timer in different ways, thenthevalueof timer would depend on which Untrusted states are executed. \nIntuitively, however, we can see that the de\u00adsign actually is secure: since every state is guaranteed \nto decre\u00adment timer inexactlythe sameway,in reality thereisno informa\u00adtion leakage nothing about the \nUntrusted states or transitions between those states can be inferred from the value of timer. Nested \nStates This observation motivates the .rst Caisson lan\u00adguage feature, nested states. Nested states allow \nthe designer to factor out shared code among states to identify exactly such situa\u00adtions. Figure2(b) \ngives a valid (i.e., typable) Caisson implementa\u00adtion of the same designbut using nested states. This \ndesign nests states S1 and S2 into the same group state group1, and similarly nests S3 and S4 into group2. \nIn each group, the code common to the nested (or child)states has been factored out and associated with \nthe group state containing those child states. The semantics of nested states effectively treats the \ncommand of a group state as if it were inlined into the command of each child state, so the code in Figure2(b) \nhas the same behavior as the code in Figure2(a).For example, each time the code transitions from S1 to \nS2 using goto, the command for group1 that decrements and checks timer exe\u00adcutes before the command for \nS2. The fall command signals that the group state s command is complete and to begin executing the appropriate \nchild state s command. When transitioning to a group state (as in the master state s command goto group1 \nin Fig\u00adure2(b)), the defaultfall-through state is the .rst listed state (e.g., S1 for group state group1). \nThe bene.t of nested states is that Caisson is allowed to type a group state separately from the its \nchild states.In Figure2(b) state group1 is typedL(low, or Trusted)while its child statesS1 and S2 are \ntypedH(high, or Untrusted). As explained above, this is safe because the semantics of Caisson guarantees \nthat group1 s command executes identically in each child state, and so no in\u00adformation is leaked even \nthough group1 s command modi.es Trusted information. Note that nested states are distinct from the related \nconcept of hierarchical states in languages like Statecharts [20]. In State\u00adcharts, child states specialize \nparent states. If an event is not han\u00addledbyachildstate,thentheparentstatesarecheckedto determine if \ntheycan handle the event (somewhat like OOP virtual methods). Caisson s nested states have different \nsemantics, as explained in\u00adformally above and formally in \u00a73. Nested states can also be seen as a concept \ndual to the notion of linear continuations [16, 55]. Whereas linear continuations identify code that \nis guaranteed to be executed afterwards byfactoring the code out intoa continuation, nested states identify \ncode thatis guaranteedtobeexecuted before\u00adhand byfactoringit out intoa group state. Parameterized States \nWhile Figure2(b) is a valid Caisson pro\u00adgram, it is not as ef.cient as it could be. Note that group1 \nand group2 have identical logic; the only difference is that group1 operates on Untrusted data(data1)while \ngroup2 operates on Trusted data(data2).Thereforethetwogroupsmustbekeptsep\u00adarate. When synthesizing this \ndesign, each group would be com\u00adpiled down to its own separate logic circuit. It would be more ef\u00ad.cient \nin terms of chip area to synthesize the same logic circuit for the two groups and reuse that circuit \nby securely multiplexing the different data(data1 vs data2)onto that circuit. This observa\u00adtion motivates \nthe second Caisson language feature, parameterized states. Figure2(c) shows the same program as Figure2(b) \nexcept using parameterized states.  This new implementation has a single group state that now has a \nparameter:a variable that represents some register on which the state will operate. Since the exact register \nthat the state will operate on can vary each time the state executes, Caisson uses a type variable A \nto represent the parameter s type and speci.es a set of type constraints that the type variable must \nobeyin order to guarantee security(inthisexample,theonly requirementisthatA must be no less than L). \nThe Caisson implementation assumes the given type constraints are valid when it type-checks group. When \ntransitioningtoaparameterized state,the goto command must specify a particular register to pass as the \ntarget state s pa\u00adrameter.In Figure2(b), the master state transitions to group with two different arguments \ndepending on mode: either data1, repli\u00adcating the behavior of the original group1, or data2, replicating \nthe behavior of the original group2. The Caisson implementation staticallyveri.es that anyargumentsgiventoa \nparameterized state must necessarily satisfy the given type constraints, thereby stati\u00adcally guaranteeing \nthe security of the design. The bene.t of parameterized states is that Caisson can synthe\u00adsizeasingle \nlogic circuit that can safelybe usedat multiple security levels. In other words, the data being operated \non (the Caisson reg\u00adisters) musthave distinct types,but the logic operating on thedata (theCaissonstates)canbe \nparameterizedoverthetypesofthedata, making the synthesized circuit much more ef.cient. 3. Formal Description \nof Caisson Inthis sectionwe formally describeacore subsetof Caissonandits type system and prove that \nCaisson enforces timing-sensitive non\u00adinterference. The actual implementation of Caisson incorporates \na large subsetofVerilog, allowingexistingVerilog designstobe eas\u00adily refactored into Caisson programs. \nThis subset ofVerilog does not add anything of interest to the formal presentation and so we omit the \nfull details from this section. Figure3describes Caisson s abstract syntax (which uses types as described \nin Figure 5 we defer discussion of types to \u00a73.2). Registers in the language correspond to registers \nin hardware and hold integervalues.Variables rangeover registers rather thanval\u00adues (i.e., a variable \nmaps to a register) and act as state parameters to abstract a state s behavior from speci.c registers. \nACaisson program consists of a list of registers followed by a list of nested state de.nitions. The nested \nstate de.nitions form a hierarchyof states with a single root state.We de.nea leaf state as a state at \nthe bottom of the state hierarchy; these states each specify a single command.A group state is anynon-leaf \nstate and speci.es both (1) a nested list of states and (2) a command. The goto command triggersastate \ntransition. Caisson describes synchronous hardware designs, hence the language implementation enforces \nthat the length of time between any two state transitions (i.e., gotos)isexactly onecycle.Within eachcycle, \nCaisson enforces the followinginvariant: beforeexecutingthe commandofanystate S, Caissonexecutesthe commandsofallof \nS s ancestor states (the intended semantics of nested states). The fall command forces execution to fall-through \nfrom the current state to one of its child states: it ends evaluation of the current state s command \nand begins the evaluation of the child state s command. Falling from a state to its child does not count \nasa state transition (i.e.,a fall command does not end a cycle, only a goto command can do that). By \ndefault the target child state of r . Register v . Variable x . Register . Variable n . Z .. Operator \nl . Program Label prog . Prog ::= prog l = r.l in d d . Def ::= let .s in c | c s . State ::= state lt \n(v.a) . = d e . Exp ::= n | x | e . e c . Cmd ::= skip | x := e | c ; c | falll | goto l(.x) | if e then \nc else c p . Phrase ::= prog | d | s | e | c Figure 3. Abstract syntax. Type annotations l, a, t, and \n. are describedin Figure5 a fall command is the .rst child state in the list of nested state de.nitions; \nthis state is called the default child state of that group state. The target child state for a fall may \nchange during program execution as described in the next subsection. Tosimplify the formal presentation \nof the language we makethe following assumptions withoutexplicitly enforcing them (thoughit is simple \nto do so in practice): All the variables and type variables have distinct names.  Adefault child state \ncan not take anyparameters.  Every goto targets a de.ned label and can only target a state in the same \ngroup and at the same nested depth2.  For each falll, the subscript label l must be the label of the \nstate containing that fall command (the label is a syntactic convenience for the semantics and type system; \nit can be left outof the concrete syntax).Aleaf state can not containa fall.  Either both branches of \nan if command must execute a goto or fall or neitherofthemdo.Allpaths throughastateendin either a goto \nor a fall.  The structureofaprogram de.nesatreeof state de.nitions(the state hierarchy) with prog being \nat the root. From this structure we derive different versions of a function F : l .. (.v . p . l) that \nfor each program label l gives the following mappings: Fpnt(l) maps to the label of state l s parent \nstate.  Fdef (l) maps to the label of state l s default child state.  Fcmd(l) maps to state l s command. \n Fprm(l) maps to state l s parameters.  In addition, Froot maps to the root command of the prog pro\u00adgram \nphrase. 3.1 Semantics Figure 4 shows the small-step operational semantics of Caisson. This .gure gives \nthe abstract machine con.guration, de.nes the evaluation context, and gives the small-step transition \nrules. 2This requirement is due to the semantics of nested states: the target of a goto in.uences which \nancestor states commands execute, which could leak information without this restriction. This restriction \ndoes not greatly impact expressiveness: we can still get from anystate to anyother state by constructing \na sequence of gotos, though we won tnecessarily get there in a single cycle.  . . Env :(v .. r) . (l \n.. l) s . Store : r .. n d . Time: NC . Con.g : .p, ., s, d. E ::= D | E . e | n . E | x := E | E ; c \n| prog l = r.l in E | let .s in E .E[r], ., s, d. .E[s(r)], ., s, d. (REG) .E[v], ., s, d. .E[s(.(v))], \n., s, d. (VAR) of nested states: upon each state transition to a state l, we must maintain the invariant \nthat all of l s ancestor states commands execute before executing l s command. Hence, the goto sets the \nnext command to Froot rather than the command of the target state. Whenevaluatingastate scommandit willeventuallyexecute \neither another goto (restarting this whose process) or a fall. The environment must map each state s \ntarget child state such that a sequence of falls will follow the correct path down the state hierarchyto \neventually reach l, the original target of the goto that began the current cycle. The .rstpremise usesa \nhelper function Reset, which we de.ne here: Reset takes an environment . and a state label l and returns \n' a new environment . identical to . except that label l and the labels of all states that are descendents \nof l in the state hierarchy .E[n1 . n2], ., s, d. .E[n1 . n2], ., s, d. (OP) are mapped to their default \nchild states (the same as their initial values). This ensures that each time the program transitions \nto a .E[r := e], ., s, d. .E[skip], ., s[r .. n],d. * ..e,.,s,d .n, ., s, d. state group, anyprior evaluations \nof that state group do not affect (ASSIGN-R) the current evaluation. The second premise looks up l s \nparent state(Fpnt(l))and sets the parent state s target child state to be l. This ensures that when evaluating \nthe parent state s command and executing a fall, exe\u00ad .E[v := e], ., s, d. .E[skip], ., s[.(v) .. n],d. \n* ..e,.,s,d .n, ., s, d. (ASSIGN-V) cution willfall-through to the correct child state (i.e., l). The \nlast premise maps the target state l s parameters to the arguments of the { c1 : n =0 goto command. \n.E[if e then c1 else c2], ., s, d. .E[c * ..e,.,s,d ' .n, ., s, d. c = c2 : n . =0 (IF) ' ], ., s, d. \n3.1.1 Example Consider the codein Figure2(b) and assume mode is initialized to 0andtimer is initialized \nto 3. Note that Froot is the outermost fall command(atthe bottomofthecode).Executionwillproceedinthe \nfollowing manner,whereC.X. representscycleXin theexecution: .E[skip ; c], ., s, d. .E[c], ., s, d. (SEQ) \n.E[falll], ., s, d. .Fcmd(.(l)), ., s, d. (FALL) .1 = Reset(., l) .2 = .1[Fpnt(l) .. l] .3 = .2[Fprm(l) \n.. .(.x)] .E[goto l(.x)], ., s, d. .Froot, .3, s, d+1. (GOTO) C0 The outermost fall command is executed, \nwhich bydefault falls through to state master. Since the if guard is true, mode is set to 1and the commandgoto \ngroup1 is executed. The GOTO rule changes the environment so that the fall-through state is now group1 \ninstead of master and resets the next command to be * Figure4. Small-stepsemanticrulesforCaisson( ive \ntransitive closure of ). The abstract machine con.guration consists of the current pro\u00adgram phrase p, \nan environment ., a store s, and a time value d. The environment . maps variables (state parameters) \nto registers and maps state labels to other state labels; the store s maps reg\u00adisters to values; and \nd is the current time measured in cycles. The mapping from labels to labels in . records for each state \nl its target child state (i.e.,the commandtobeginevaluatingif l executesafall command we initialize the \nmapping to the default child states). The rules arefairly standard except for fall and goto, which we \nnowdescribein detail. The FALL rule applies when executing a falll command. The rule looks up in . the \ntarget child state for the current state l (recall that we require l for a command falll to be the label \nof the current state) and begins executing that target child state s command. The GOTO rule applies when \nexecuting a goto command. The ruledoesthreethings:(1) createsanewenvironment . as described below; (2) \nincrements the time d, since a state transition marks the beginning of a new cycle; and (3) begins evaluating \nthe root command at the top of the state hierarchy. The most complex part of the GOTO rule is the set \nof premises that create the new environment .3 with which we evaluate the root command. The key is to \nunderstand the intended semantics is the re.ex-Froot. C1 The outermost fall command is executed. Because \nof the changed environment, control falls through to state group1. timer is decrementedto2; since timer \nis not0the else branch is taken and the fall command is executed. By default, control falls through to \nstateS1. Assume that data1 = 0; then the com\u00admand goto S2 is executed. This changes the environment so \nthat thefall-through state for group1 is now S2 instead of S1 and resets the next command to be Froot. \nC2 The outermost fall command is executed. As previously, con\u00adtrolfalls through to state group1 and timer \nis decremented to 1. Since timer isnot0theelse branchistakenandthe fall com\u00admand is executed. Because \nof the changed environment control falls through to stateS2. Assume data1 is now1; then the com\u00admand \ngoto S2 is executed, which leaves the environment un\u00adchanged and resets the next command to be Froot. \nC3 The outermost fall commandisexecuted.Aspreviously,control falls through to state group1 and timer \nis decremented to 0. Since timer isnow0,the true branchistakenandthe command goto master is executed; \nthis changes the environment so group1 sfall-through stategoesbacktoitsdefault(i.e., S1)and the root \nfall-through state is now master instead of group1, and resets the next command to be Froot. C4 The logic \nfrom cycle C0 is repeated, except that mode =1and so the program will transition to group2 instead of \ngroup1.  l .L security labels t ::= l | a base types, type variables . ::= {t <:t }| .1 . .2 type constraints \n. ::= t | cmdt | stt (.phrase types a, .) Figure 5. Types  3.2 TypeSystem Figure5gives the types usedby \nour language. The base types are elements of the security lattice L.Type variables range over base types \nand are implicitly universally quanti.ed. We assume each state uses a disjoint set of type variables. \nThe type variables are bounded by the type constraints . which specify required subtype relations amongthe \ntypevariables and base types. The type system statically checks that all goto commands satisfy these \nconstraints. Expressions have type t , commands have type cmdt , and states have type stt (. a, .). We \nomit the standard subtyping rules: ex\u00adpression types are covariant(e : t means that e contains no vari\u00adables \nor registers greater than t ); command types are contravariant (c : cmdt means that c does not change \nthe state of any variable or register less than t ); and state types are invariant(s : stt (. a, .) means \nthat, assuming the state parameters have types a.that satisfy the constraints in ., the state s command \nis type cmdt ). The program syntax explicitly notes the types of each register and state; we use this \ninformation to initialize the type environment r:(r .. l) . (v a,.)) . .. r maps all .. a) . (l .. stt \n(.registers to a base type, all state parameters to a type variable, and all state labels to a state \ntype, and also records the type constraints in all .. The whole program (i.e. the root state) is always \nmapped to st.( , ). r also records the subtype relations between base types (i.e., security labels)asgiveninthe \nsecurity lattice. Since r remains constant, wefactorit outof the individual type rules. Most of the rules \nare standard (see, e.g., Volpano et al [51]) except for rules T-FALL and T-GOTO which we now explain \nin de\u00adtail. Rule T-FALL states that if the type of the default child state s command is cmdt then so \nmust be the type of the current state s command. This requirement is due to the differing semantics of \nfall and goto commands:a fall command immediately begins exe\u00adcuting the child state scommand, whereasa \ngoto beginsexecuting the root command Froot.Without this rule, if a conditional with a high guard has \na goto in one branch and a fall in the other then a low observer might be able to observe the outcome \nof the con\u00additional based on whether execution proceeds from Froot or not. The rule only needs to check \nthe type of the default child state s command(Fcmd(Fdef (l)))even thoughat runtimea state canfall\u00adthrough \nto anychild state. Since we require transitions must be to neighbor states in the state hierarchy, other \nchild states can only be reached via the default child state. Thus, typing consistencybe\u00adtween the parent \nstate and all its child states is enforced indirectly bya combinationof the T-FALL andT-GOTO rules. Themost \ncomplicatedtyperuleis T-GOTO.The goto command has a target state l and a list of arguments .x. The type \nrule must accomplish two things: It must verify that the arguments .x given to the goto satisfy the type \nconstraints . of the target state l. This requirement is checkedby the .rst premise on the second lineof \nthe type rule. State l s type constraints . are modi.ed to map the type of each state parameter to the \ntype of its corresponding argument (via .[a... r(.x)]); then the resulting type constraints are veri.ed \nto be valid assertions (i.e., that the constraints can be derived using the sub-typing rules and the \ninformation in r). n : . (T-CONST) r(x) = t x : t (T-REG/VAR) e1 : t e2 : t e1 . e2 : t (T-OP) r(x) = \nt e : t x := e : cmdt (T-ASSIGN) e : t c1 : cmdt c2 : cmdt if e then c1 else c2 : cmdt (T-IF) c1 : cmdt \nc2 : cmdt c1 ; c2 : cmdt (T-SEQ) skip : cmd. (T-SKIP) r(l)= stt (.Fcmd(Fdef (l)) : cmdt a, .) (T-FALL) \nfalll : cmdt r(l)= stt (. a, .) . .[a... r(.x)] t ' = t[a... r(.x)] (T-GOTO) goto l(.x): cmdt ' r(l)= \nstt (.d : cmdt a, .) (T-STATE) state lt (v.a) . = d : stt (. a, .) si : stti (a.i,.i) c : cmdt (T-DEF) \nlet .s in c : cmdt d : cmdt (T-PROG) prog l = r.l in d : cmdt Figure 6. Caisson type rules It must also \ncon.rm the type of the goto command in the conclusionof the rule. Thisis con.rmedby the last premise \non the second line of the rule. The target state has type stt (. a, .), meaning that its command has \ntype cmdt . However, we cannot simply make the type of the goto command be type cmdt t may be a type \nvariable, and we assume that the sets of type variables used in any two states are disjoint. Therefore, \nthe rule must translate type t, valid for the target state, into an appropriate type t ', valid for the \nsource state. The rule uses the same substitution operator as used earlier to perform this translation. \nWesketchaproofthatthe Caissontypesystem enforcestiming\u00adsensitive noninterference in Appendix A. 3.2.1 \nExample Hereweusethetyperulestoshowthat speci.cpartsoftheexample programin the previous section are well-typed.We \ndon tshow the entire type derivation,but wedo showhow both the T-GOTO and T-FALL rules are used. Consider \nthe codein Figure2(c), and speci.cally the command goto group(data1). The rule T-GOTO.rst con.rms that \nthe type of the argument (i.e., data1, which is type H) satis.es the type constraints of the target group, \ni.e., thatL <:H this is true. The rule then .nds a suitable type for the goto command based on the typeof \nthe target state(group, which is type L); hence the type of the goto command is cmdL.  Now consider \nthe command goto group(data2). By the same logic this command is also typed cmdL, except that when checking \nthat the argument (i.e., data2, which is type L) satis.es the type constraints, the rules con.rms thatL \n<:L, which is also true. Since mode is type L, the type of the if statement is cmdL which matches the \ndeclared type of state master. From the abovewe can con.rm that all transitions to group sat\u00adisfy the \ntype constraints. When typing group itself, we assume that the type constraints are met, i.e., thatL \n<:A. Hence, when typing the false branch of the if command in group the fall command, using rule T-FALL, \nis initially typed as cmdA. However, by con\u00adtravariance and sinceL <:A, it can also be typed as cmdL. \nSince the true branch is typed cmdL (by the T-GOTO rule), the if com\u00admand is well-typed as cmdL, which \nmatches the declared type of state group. When checking state S1, the declared type (i.e., stA(L <:A)) \nforces the if command to be type cmdA;theT-GOTO rules con.rms that is true for both branches of the if \ncommand. The same holds true for state S2. Therefore each state of the program, and the entire program \nitself, is well-typed. 4. Information-Flow Secure Processor In this section we concretely demonstrate \nthe utility of Caisson by designing andevaluating an information-.owsecure processor that safely muliplexesexecutionof \ntrusted and untrusted code. Securely executing mixed-trust programs has historically been dif.cult to \nget right. For instance, all known cache attacks stem from the basic problem that cache controllers must \nuse both trusted and untrusted information to decide which lines to evict from a cache [35, 54]. Information \nhas been also shown to leak through branch predictor history table [5] or through the instruction cache \nlines [6]. More generally, any perturbation in the execution of a trusted program based on untrusted \ndata is a vulnerability, and we must prevent all possible sources of such information leaks. We begin \nthe section with a description of a complete four\u00adstage processor pipeline that securely implements a \nRISC ISA. We then extend the processor to include a cache hierarchythat is veri.ably secure against all \nknown attacks [35, 54]. These designs demonstrate that Caisson s language abstractions allow the CPU \ntobe cleanly speci.edina naturalfashionand enablea statically\u00adveri.able,ef.cientdesign.Forthis processordesignweemploythe \nsame two-level lattice Trusted . Untrusted as used in \u00a72. 4.1 Secure CPU Design The public interface \nof a CPU is its Instruction Set Architecture (ISA).Table1describestheISAofour processor;thisisastandard \nISA (derived from the commercial Altera Nios processor) . The ISA is implementedusinga combinationofhardwaredata-and \ncontrol\u00ad.ow controlledby theexecution pipeline. Figure7shows the four\u00adstage pipeline of our processor,with \nstages Fetch, Decode, Execute, and Commit. Additional microarchitectural features such as caches, prefetchers, \nand branch predictors can be attached to the pipeline to improveprocessor performance. Our processor \nimplementsacache to illustrate how these microarchitectural features can be designed for security; the \nother features can be implemented using similar strategies. The easiest method to ensure that Untrusted \ndata can never affect Trusted computationistophysically isolate them, i.e.,have two separate instances \nof the CPU, one for Trusted computation and one for Untrusted computation. While simple and easy to verify, \neconomic reality means that this is not a practical solution. Even in high assurance systems the hardware \ncomponents are often shared, e.g., the Boeing 787 trusted aircraft control network shares thephysicalbus \nwith the untrusted passenger network [15]. Table 1. The ISA of our RISC processor Figure 7. Atypical \nCPU pipeline and its interaction with memo\u00adries, registers and other components. Our CPU design implements \nall parts in bold. The only alternative solution is to time multiplex the Trusted and Untrusted computation \non the same physical hardware. The keyto secure hardware design is to guarantee that anystate changes \ndue to Untrusted computation never affect any Trusted compu\u00adtation even when the computations share the \nsame pipeline stages, cache, and other processor features. Caisson s language abstrac\u00adtions and type \nsystem collaborate to provide the hardware designer with the tools needed to easily encode and verify \na secure design. In the remainder of the section we describe in detail the Caisson implementation of \nour processor.  4.2 Secure Execution Pipeline The execution pipeline is the backbone of the processor \nand the foundation of a secure design. Our goal is to take a trusted context (i.e., registers and memory) \nand a separate untrusted context and use the same physical processor logic circuits to safely operate \non both. The resulting processor is a 32-bit RISC processor with 128KB each of Instruction and Data memory \n(64KB for the trusted context and 64KB for the untrusted context), twoprogram counters, and 16 general \npurpose registers (split evenly between the trusted and untrusted contexts). Thereisa single four-stage \npipeline shared between the trusted and untrusted contexts (as well as a 2K shared data cache, described \nin the next subsection). Figure 8 shows a state-machine diagram of the pipeline design. This design interweaves \nthe Trusted and Untrusted compu\u00adtation at a coarse granularity. There is a Reset state that resets the \nhardware state to its initial conditions and a Master state that con\u00adtrols the pipeline logic. The Master \nstate sets a timer and allows the pipeline to be used in alternate time intervals by the Trusted and \nUntrusted computation. In this design, every stage of the pipeline contains data from the sameexecution \ncontext(Trusted or Untrusted). Figure9shows the hardware diagram of the cor\u00adFigure 8. State Machine Diagram \nof the Coarse-Grained Time\u00admultiplexed Pipeline. The memory hierarchyshown in the dash box does not represent \nanyconcrete state in the state machine,but it is included in our CPU and accessed by the pipeline.  \n  Figure 9. Synthesized hardware implementation of the Coarse-Grained Time-multiplexed Pipeline CPU \nlogic when the entire pipeline is multiplexed between high and low code. responding synthesized circuit. \nFigure 10 gives a skeleton of the Caisson code that implements the pipeline design (where High-Context \nand LowContext stand for the untrusted and trusted con\u00adtexts, respectively). Note that the design uses \nnested states to al\u00adlow veri.cation of the design and parameterized states to share the physicallogic.Infact,thisdesignis \nsimilartotheExecutionLease controller design in \u00a72. 4.2.1 Fine-Grained Sharing of Execution Pipeline \nOne possible drawback of the previous pipeline design is that the sharing between Trusted and Untrusted \ncomputation is coarse\u00adgrained; the time intervals during which they each have control of the pipeline \nmust be suf.ciently large to counteract the cost of stalling the pipeline each time the context is switched \nbetween them. An alternative design can share the pipeline at a much .ner granularity, so that eachpipeline \nstage continuously alternates be\u00adtween Trusted and Untrusted computation at each cycle. This design may \nbe an attractive option when the computation at each security level requires a low latencyresponse. Figure \n12 shows the intuition behind this design, along with a state-machine diagram illustrating the design. \nFigure 11 gives a skeleton of the Caisson code that implements the design. Each pipeline stage is initialized \nat a particular security level, so that Fetch is Trusted,Decode isUntrusted,Execute isTrusted,and Commit \nis Untrusted. In each cycle (i.e., at each state transition goto), the security context at one stage \nis passed on to the next stage in turn.  4.3 Secure Cache Design A secure execution pipeline prevents \ninformation leaks via hard\u00adware data-and control-.ow, but information can still be leaked via microarchitectural \nfeatures such as cache memory.Forexam\u00adple, there are well-known security attacks that exploit a shared \nmemory to covertly communicate between two supposedly iso\u00adlated processes by selectively causing page \nfaults and/or cache misses[5,35].We implementa secure cachefor our processorde\u00adsign to illustrate how \nto secure microarchitectural features; other features, such as branch predictors, can be securely implemented \nusing similar strategies. As with the execution pipeline, there are two basic approaches to securing \nthe cache: physical isolation (statically partitioning the cache between Trusted and Untrusted data) \nor time multi\u00adplexing (sharing the cache,but .ushing it each time the processor switches between the \nTrusted and Untrusted contexts). In this case, unlike the pipeline, the extreme cost of .ushing the cache \nat each context switch means that partitioning the cache is the pre\u00adferred solution. Other existing work \nhas come to the same conclu\u00adsion [54]. Our contribution is not the design of a secure cache it\u00adself, \nbut the fact that a secure cache can be easily implemented and statically veri.ed using Caisson, as well \nas securely integrated into a larger secure system (i.e., our processor). Static veri.cation is important \nprevious work on secure cache design [54] has been shown to possess subtle .aws that violate security \n[26].  In Caisson, the implementationofa partitioned cacheis simple: the design passes the particular \ncache partition each context should use as part of the context information for the parameterized states. \nIn Figure 10, the cache partitions would be part of HighContext and LowContext . Equally as important \nas the cache memory itself is the cache controller the logic that processes cache hits and misses. Unlike \nthe cache memory, the cache controller can be shared among the different security levels in the same \nmanner as the execution pipeline.  4.4 Evaluation Wehaveproven that Caissongauranteesthe securityof \nour proces\u00adsor design,but an interesting question is how the resulting design performs in comparison \nto existing processor designs, both tradi\u00adtional insecure processors and other processors designed for \nse\u00adcurity. The relevant performance metrics are: synthesis time (how longittakesto transformahigh-leveldesignintoanactualcircuit); \nchip area (how large the resulting circuit is); delay (inversely pro\u00adportional to clock frequency); and \npower (the power consumption of the circuit). 4.4.1 Synthesis Methodology To quantify the hardware design \noverhead introduced by our ap\u00adproach we compare our processor design(Caisson)with a non\u00adsecured, simpli.ed \nversion of the commercial Nios Processor (Base)and the same Nios processor augmented to dynamically track \ninformation .ow using GLIFT(GLIFT)[46]. GLIFT imple\u00admentsfull system information.ow trackingatthelogicgatelevel: \nit associates each bit in the system with a taint bit indicating its securitylevel, and augments eachgatein \nthe hardware design with additionalgates that compute taint propagation. All CPUs have identical functionality \nand con.guration. How\u00adever both Caisson and GLIFT can only utilize half of the cache and memory capacity \neffectively although theyhave identical con\u00ad.guration as the Base processor. The reason is that in our \nCaisson design the memory and cache have to be partitioned into two parts with different security levels, \nwhile GLIFT needs to associate a one-bit tag for each bit in the memory and cache. Increasing the cache \nand memory utilization ef.ciencyfor Caisson is part of our future work. We implemented the Base processor \n(from the Nios design) in Verilog with no additional security features. To get the Cais\u00adson implementation \nwe remodeled the Base implementation using Table 2. Synthesized results of the different CPU designs: \nthe simpli.ed Nios Processor (Base), the GLIFT-based CPU, and the Caisson-based CPU. security widgets \nprovided by the Caisson language and statically partitioned all registers, caches, and memories into \nTrusted and Untrusted. To get the GLIFT implementation, we .rst synthe\u00adsized the Base design intoagatelevel \nnetlistand then augmented the netlist with shadow logic to track information .ow. We passed the Base \nand Caisson designs through Altera s QuartusII v8.0 tool tosynthesizethedesignsontoaStratixIIFPGAfor \nfunctionaltest\u00ading and veri.cation. We then obtain the area, timing and power results using the Synopsis \nDesign Compiler and the SAED 90nm technologylibrary[1] assuminga switchingactivityfactorof50% for the \ncircuit.  4.4.2 Results Almost as important as the quantitative performance results are the qualitative \nresults of how easy each design was to implement this is an important test for the usability of a language. \nWe .nd anecdotally that Caisson is easily usable by a programmer trained inVerilog. The original Base \ndesign required709 linesofVerilog the corresponding Caisson design required only 724 lines and took little \nadditional time to implement. By contrast, GLIFT required us to make a hard choice: we could either (1) \nmanually design the gate-level netlist at a structural level (i.e., manually place the logic gatesto \ncreatethe design), whichin ourexperienceis infeasiblefor suchacomplexdesign;or(2) generateagate-level \nnetlistfromthe behavioralVerilog design using anexisting tool, then automatically generate the GLIFT \nshadow logic using the resulting netlist. We used the latter option, and while it simpli.es the process \nfor the programmer the resulting design is intractably dif.cult to debug and optimize. Table2gives the \nperformance .gures for each design.Wegive the concrete numbers for all three designs as well as normalized \nnumbers for Caisson and GLIFT (using Base as a baseline). The area numbers do not include the memory \nhierarchysince all three designs use an identical memory con.guration. The power num\u00adbers include both \ndynamic and leakage power. The GLIFT design comeswithalargeoverheadinallfour performance categoriesdue \nto the shadow logic that GLIFT introduces to the processor. This shadow logic takes a long time to synthesize, \nrequires a large chip area, consumesagreatdealofpower,and drasticallyslowsthepro\u00adcessor cycle frequency. \nCaisson,in contrast, hasa muchloweroverhead, thoughitis certainly not free. This overhead mainly comes \nfrom two sources: the duplicated state (i.e., registers) and the additional encoders and decoders used \nto multiplex the partitioned state onto the same logic circuits.We note that theoverhead generatedby \nthe Caisson de\u00adsign does not grow with CPU complexity (e.g., number of func\u00adtional units) a more powerful \nand complex CPU would not re\u00adquire anyadditionaloverhead, while the GLIFT design soverhead would proportionately \nwith the CPU complexity.For perhaps the most important performance metric, power, Caisson s overhead \nis almost negligible. The synthesis time for the Caisson design in\u00adcludes type-checking, which is suf.cient \nto verify the design s se\u00adcurity. The GLIFT synthesis time does not include veri.cation GLIFT only detect \nsecurity violations at runtime.  These results showthat designingasecure processor using Cais\u00adson not \nonly provides a strong static guarantee about information .owsecurity,butalso(1)allowsamore straightforwardand \nnatural way of designing a secure processor, and (2) introduces much less area, timing and power overhead \nthan dynamic tracking techniques such as GLIFT. 5. RelatedWork Secure information .ow has been widely \nstudied; a survey by Sabelfeld and Myers [39] gives a comprehensive summary of this work. Here we concentrate \non (1) hardware-assisted secure infor\u00admation .ow, and (2) analyzing hardware designs for secure infor\u00admation \n.ow, for both secrecyand integrity. Although the concept of integrity has sometimes been generalized \nto include other prop\u00aderties such as program correctness [17, 30], we deal only with in\u00adformation integrity \nin this paper. Anumber of papers deal with timing-sensitive secure informa\u00adtion .ow for programming languages \n[8 10, 21, 37, 42, 52, 56]. These papers enforce timing-sensitivityby restricting computation, e.g., \nby not allowing any branches or loops on high information. These restrictions wouldn t allow for anyuseful \nhardware designs and so these works can t be used in Caisson; instead, we take ad\u00advantage of the characteristics \nof sychronous hardware to enforce timing sensitivity (as explained in Appendix A). 5.1 Hardware-Assisted \nSecure Information Flow Secure information .ow has been enforced at a variety of lev\u00adels of abstraction \nin computer systems. At the programming lan\u00adguage level information .ow can be enforced statically (e.g., \nvia a type system [33, 53]) or dynamically [29, 36]. At lower levels of abstraction dynamic enforcement \nis the norm. Projects such as LoStar [59], HiStar [58] and Flume [28] apply distributed informa\u00adtion \n.ow control (DIFC) [57] through general-purpose operating system abstractions.Tag-based tracking at the \nvirtual machine, ar\u00adchitecture, or ISA levels is a popular dynamic solution that tracks information .ows \nthrough all registers and memory [12, 13, 34, 38, 43, 49, 50]. However,even hardware-assisted secure-information \n.owtrack\u00ading does not go below the ISA abstraction level to account for mi\u00adcroarchitectural features \nsuch as pipelining and cache. There are existing dedicated secure cache [54] and memory controller [32] \ndesigns, however these designs only enforce information .ow poli\u00adcies for speci.c components in the computer \narchitecture; this ex\u00adisting work does not address the entire processor design, nor does it provide a \ngeneral methodology for designing secure hardware. 5.2 Information Flow Analysisfor Hardware Design \nThe traditional method for checking the security of a hardware designisto simulateandextensively testthe \ndesign,alaboriousand expensive process. While static analysis [19, 22, 23, 40] and model checking [11] \nare often used for functional veri.cation, theyare not oftenusedtocheck security.Tolstrupetal[47,48] \ndescribeatype\u00adsystem based information .ow analysis to verify hardware security policies for VHDL designs. \nTheir work is limited to analyzing simple cryptographic hardware designs, and as pointed out by Li et \nal [31], directly applying conventional information .ow analysis toexisting hardware description languagesoftenleadsto \nimprecise results. Unlike the existing work, Caisson extends HDLs like VHDL andVerilog with language \nabstractions that speci.cally target pre\u00adcise static veri.cation of hardware designs. 6. Conclusion Hardware \nmechanisms for information .ow control often form the root of trust in high assurance systems and are \nused to enforce poli\u00adcies such as non-interference. While programming language tech\u00adniques have been \nused extensively for creating secure software, languages to create information-.ow secure hardware have \nnot re\u00adceived much attention.We combine insights from traditional type\u00adbased secure languages with domain-spec.c \ndesign patterns used for hardware design and presenta new hardwaredescription lan\u00adguage, Caisson, for \nconstructing statically-veri.able secure hard\u00adware designs. By formalizing certain security design patterns \nand providing direct language support for enforcing their correct use, Caisson promotes thinking about \nsecure hardware design in new, useful ways that don t naturally arise in existing languages. Using Caisson, \nwe are able to express information .ow control mecha\u00adnisms in a natural manner and quickly verify a variety \nof novel secure hardware designs. In particular, we show how the insights gained from developing Caisson \nallow us to design the .rst ever implementation of a pipelined processor that veri.ably enforces noninterference. \nA. Proof of Noninterference We sketch a proof that Caisson enforces timing-sensitive nonin\u00adterference \nbetween security levels. The invariant that we wish to enforce is that an observer at security level \nl cannot distinguish between two runs of the same program that differ only in the in\u00adformation at security \nlevels l ' .. l. Because Caisson models syn\u00adchronous hardware designs there are two important implications \nthat we leverage: (1) observers can see the stores only at the end of each cycle, i.e., theycannot see \nchanges to the store that happen during a cycle until that cycle ends; and (2) the length of time be\u00adtween \ntwo sequential goto commands is always exactly one cycle, regardless of the number of semantic steps \ntaken. These twofacts are justi.ed by the synchronous nature of the hardware: the .ip\u00ad.ops only read \nin new values on a clock edge, and the clock fre\u00adquencyis set so that each state (corresponding to a \ncombinational circuit) is guaranteed to have completed within one cycle. We de.ne distinguishability \nusing theL-equivalence relation de.nedbelow.Wethengiveasetof lemmasandourmain nonin\u00adterference theorem. \n    A.1 L-equivalence First we de.ne the set of security types L that an observer at secu\u00adrity level \nl can observe. This includes base types that are subtypes of l as well as type variables of state parameters \nthat the current environment . maps to registers whose base types are subtypes of l.Formally, for a given \nsecurity level l and environment . let L = the minimum .xpoint of {l ' | l ' . l}.{a |.v . dom(.).v : \na . .(v) . L}. Then let H = {t | t ./L}, i.e., the security types that an observer at level l can t distinguish.Types \nL and H are always with respect to some environment .. We lift the type constructors and typing relation \nto operate on L and H in the obvious way. We now use L and H to de.ne the L-equivalence relation ~L on \nstores, environments, commands, and con.gurations such that L-equivalent items are indistinguish\u00adable \nfrom each other for an L-observer. Environment: Two environments are equivalent(.1 ~L .2) if they cannot \nbe used to create effects distinguishable by an L-observer. This means that (1) any writable L-typed \nstate parameter (i.e., not from an H-typed state) must be mapped to the same register in both environments; \nand (2) if .1 maps a label l to an L-typed state then so must .2 and vice-versa:  For all parametersv \nof any state l : stL(.v : L w.r.t. a, .), either .1 or .2 . .1(v)= .2(v), and .l..1(l):stL(.a,.) . .1(l)= \n.2(l) a, .) . .2(l):stL(. Store: Two stores are equivalent if theyagree on all values that canbe seenbyan \nL-observer. Let the JL operator project out all registers with type H from a store (since registers always \nhave a base type we don tneed . to determine H); then s1 ~L s2 if (s1 JL)=(s2 JL)  Command: Two commands \nare equivalent w.r.t. an environ\u00adment . (c1 ~.  L c2)if (1) theyare the same command and both typed \ncmdL w.r.t. ., hence will modify state in the same way; or (2) both commands are typed cmdH w.r.t ., \nhence cannot modify state that is L-observable: c1 = c2 . c1 :cmdL . c2 : cmdL, or (c1 : cmdH . c2 : \ncmdH ) Con.guration: Twocon.gurations are equivalent(C1 ~L C2) if their stores, environments, and commands \nare equivalent and theyhave the same time: .. s.t. .1 ~L . . .2 ~L . . c1 ~. L c2 . s1 ~L s2 . d1 = d2 \n A.2 Lemmas This section introduces a set of lemmas that we use for the non\u00adinterference proof. Simple \nsecurity states that an expression e : L contains only low sub-expressions, while con.nement states that \nc : cmdH cannot create anyeffects involving L-typedvariables. The types L and H are with respect to a \nwell-formed environment .. Lemma1 (Simple Security). e : L . no sub-expression of e has type H. Proof. \nBy induction on the structure of e. Lemma2 (Con.nement). c : cmdH . evaluating c using environ\u00adment . \nand some store s does not modify the value of any variable or register with type L. Proof. By induction \non the structure of c. Lemma3 (Subject Reduction). .c, ., s, d..c ' ,. ' ,s ' ,d. and c : cmdH w.r.t. \n. . c ' : cmdH w.r.t. . ' Proof. By induction on the structure of c.  A.3 Noninterference We now come \nto the noninterference theorem itself, which holds for all well-typed Caisson programs. Recall that because \nthe lan\u00adguage models synchronous hardware, we assume that changes to the store are only visible upon \na state transition and that time only increments at state transitions (regardless of the number of seman\u00adticstepstaken).Withthatinmind,wegivethe \nnoninterferencethe\u00adorem below. It states that given two con.gurations CA and CB , both of which are L-equivalent \nand start at the root command, when the resulting evaluations each reach a state transition (i.e., a \ngoto) the resulting new con.gurations must also be L-equivalent. Theorem1 (Noninterference). Let CA = \n.Froot,.A,sA,dA. C ' A,s ' A = .Froot,. ' A,dA +1. CB = .Froot,.B,sB ,dB . C ' B = .Froot,. B' ,s B ' \n,dB +1. Then * C'* C' CAA . CBB . CA ~L CB . CA ' ~L C' B Proof. By induction on the steps of the computation \nand Lemmas 1,2, and3. The proof itself is straightfoward and omitted for space. Note that the noninterference \ntheorem is timing-sensitive: it guarantees that given two L-equivalent con.gurations, a Caisson program \nmust make identical L-observable changes at the same times under both con.gurations (where time is measured \nas number of cycles). Acknowledgments This researchwas supportedby theUS Departmentof Defense un\u00adder \nAFOSR MURI grantFA9550-07-1-0532. The views and conclusions contained herein are those of the au\u00adthors \nand should not be interpreted as necessarily representing the of.cial policies or endorsements, either \nexpressed or implied, of the sponsoring agencies. References [1] 90nm generic CMOS library,Synopsys University \nprogram, Synopsys Inc. [2] Common critera evaluation and validation scheme. http://www.niap\u00adccevs.org/cc-scheme/cc \ndocs/. [3] Validated FIPS 140-1 and FIPS 140-2 cryptographic modules. http://csrc.nist.gov/groups/STM/cmvp/documents/140-1/140val\u00adall.htm. \n[4] What does CC EAL6+ mean? http://www.ok\u00adlabs.com/blog/entry/what-does-cc-eal6-mean/. [5] O. Accigmez, \nJ. pierre Seifert, and C. K. Koc. Predicting secret keys via branch prediction. InThe Cryptographers \nTrackat the RSA Conference, pages 225 242. Springer-Verlag, 2007. [6] O. Aciic\u00b8mez. Yet another microarchitectural \nattack: Exploiting i\u00adcache. In CCS Computer SecurityArchitectureWorkshop, 2007. [7] O. Aciic\u00b8mez, J.-P. \nSeifert, and C. K.Koc. Micro-architectural crypt\u00adanalysis. IEEE Security and Privacy, 5:62 64, July 2007. \n[8] J. Agat. Transforming out timing leaks. In Proceedings of the 27th ACM SIGPLAN-SIGACT symposium on \nPrinciples of programming languages, POPL 00, pages 40 53, New York, NY, USA, 2000. ACM. [9] G. Barthe, \nT. Rezk, and M. Warnier. Preventing Timing Leaks ThroughTransactional Branching Instructions. Electronic \nNotes The\u00adoretical Computer Science, 153:33 55, May 2006. [10] G. Boudol and I. Castellani. Noninterference \nfor concurrent programs. pages 382 395, 2001. [11] E. M. Clarke, O. Grumberg, and D.Peled. Model Checking. \nMIT Press, 2000. [12] J.R. Crandall andF.T. Chong. Minos: Control data attack prevention orthogonal to \nmemory model. In Micro, pages 221 232, 2004. [13]M. Dalton,H. Kannan,andC.Kozyrakis. Raksha:A.exible \ninforma\u00adtion .ow architecture for software security. In ISCA, pages 482 493, 2007. [14] D.E. Denning \nandP.J.Denning. Certi.cationof programs for secure information .ow. Communicationsof theACM, 20(7):504 \n513, 1977. [15] F. A. A. (FAA). Boeing model 787-8 airplane; systems and data networks security-isolation \nor protection from unauthorized passenger domain systems access. http://cryptome.info/faa010208.htm. \n[16] A. Filinski. Linear continuations. In Proceedings of the 19thACM SIGPLAN-SIGACT symposium on Principles \nof programming lan\u00adguages, POPL 92, pages 27 38,NewYork,NY, USA, 1992.ACM. [17] C.Fournet andT. Rezk. \nCryptographically sound implementations for typed information-.ow security. In POPL, pages 323 335, 2008. \n [18] J. A. Goguen and J. Meseguer. Security policies and security models. In IEEE Symposium on Security \nand Privacy, 1982. [19] C. Hankin. Program analysis tools. InternationalJournal on Software Tools forTechnologyTransfer, \n2(1), 1998. [20] D. Harel. Statecharts:Avisual formalism for complex systems. Sci\u00adenceof ComputerProgramming8, \n1987. [21] D. Hedin and D. Sands. Timing aware information .ow security for a javacard-like bytecode. \n141(1):163 182, 2005. [22] C. Hymans. Checking safety properties of behavioral VHDL descrip\u00adtions by \nabstract interpretation. In International Static Analysis Sym\u00adposium, pages 444 460. Springer, 2002. \n[23] C. Hymans. Design and implementation of an abstract interpreter for VHDL. D.Geist and E.Tronci, \neditors, CHARME, 2860 of LNCS, 2003. [24] G. Klein,K. Elphinstone,G. Heiser,J. Andronick,D. Cock,P. Derrin, \nD. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H.Tuch,andS.Winwood. seL4: formalveri.cationofanOSkernel. \nIn SOSP, pages 207 220, 2009. [25] P. C. Kocher, J. Jaffe, and B. Jun. Differential power analysis. In \nProceedings of the 19th Annual International Cryptology Conference on Advances in Cryptology, pages 388 \n397, 1999. [26] J.Kong, O. Aciic\u00b8mez, J.-P. Seifert, and H. Zhou. Deconstructing new cache designs for \nthwarting software cache-based side channel attacks. In Proc. of the 2nd ACM workshop on Computer security \narchitectures, pages 25 34, 2008. [27] K.Koscher,A. Czeskis,F. Roesner,S.Patel,T.Kohno,S. Checkoway, \nD. McCoy, B. Kantor, D. Anderson, H. Shacham, and S. Savage. Ex\u00adperimental security analysis of a modern \nautomobile. IEEE Sympo\u00adsium on Security and Privacy, pages 447 462, 2010. [28] M. Krohn, A.Yip, M. Brodsky, \nN. Cliffer, M. Frans, K. Eddie, and K. R. Morris. Information .ow control for standard OS abstractions. \nIn SOSP, 2007. [29] L. C. Lam and T.-c. Chiueh. A general dynamic information .ow tracking framework \nfor security applications. In Proceedings of the 22nd Annual Computer Security Applications Conference, \npages 463 472, 2006. [30]P.Li,Y.Mao,andS. Zdancewic. Information integrity policies. In ProceedingsoftheWorkshoponFormal \nAspectsin SecurityandTrust, 2003. [31]X.Li,M.Tiwari,B. Hardekopf,T.Sherwood,andF.T.Chong. Secure information \n.owanalysis for hardware design: Using the right abstrac\u00adtion for the job. TheFifthACM SIGPLANWorkshop \nonProgramming Languages and Analysis for Security(PLAS), June 2010. [32] O. Mutlu andT. Moscibroda. Stall-timefair \nmemory access schedul\u00ading for chip multiprocessors. In Micro, pages 146 160, 2007. [33] A. C. Myers, \nN. Nystrom, L. Zheng, and S. Zdancewic. Jif: Java information .ow. Software release. http://www.cs.cornell.edu/jif, \nJuly 2001. [34] J. Newsome and D. Song. Dynamic taint analysis for automatic detection, analysis,and \nsignature generationofexploitson commodity software. In NDSS, 2005. [35] C. Percival. Cache missing for \nfun and pro.t. In Proc. of BSDCan, 2005. [36] F. Qin, C. Wang, Z. Li, H.-s. Kim, Y. Zhou, and Y. Wu. \nLift: A low-overhead practical information .ow tracking system for detecting security attacks. In Micro, \npages 135 148, 2006. [37] A. Russo, J. Hughes, D. Naumann, and A. Sabelfeld. Closing internal timing \nchannels by transformation. pages 120 135, 2007. [38] O. Ruwase,P. B. Gibbons,T. C. Mowry,V. Ramachandran, \nS. Chen, M. Kozuch, and M. Ryan. Parallelizing dynamic information .ow tracking. In SPAA, pages 35 45, \n2008. [39] A. Sabelfeld and A. C. Myers. Language-based information-.ow security. IEEEJournal on Selected \nAreas in Communications, 21(1), Jan. 2003. [40] M. Schlickling and M. Pister. A framework for static \nanalysis of VHDL code. 7th International Workshop on Worst-Case Execution Time (WCET) Analysis, 2007. \n[41]O. Sibert,P.A. Porras,andR. Lindell.An analysisofthe intel 80x86 security architecture and implement \nations. IEEE Transactions on Software Engineering, 22(5):283 293, 1996. [42]G.SmithandD.Volpano. Secure \ninformation.owinamulti-threaded imperative language. pages 355 364, 1998. [43] G. E. Suh, J. W. Lee, \nD. Zhang, and S. Devadas. Secure program execution via dynamic information .ow tracking. In ASPLOS, pages \n85 96, 2004. [44] E.Technologies. The Esterel v7 Reference Manual, version v7.30 \u00adinitial IEEE standardization \nproposal edition. 2005. [45] M.Tiwari, X. Li, H.Wassel,F. Chong, andT. Sherwood. Execution leases: A \nhardware-supported mechanism for enforcing strong non\u00adinterference. In Micro, 2009. [46]M.Tiwari,H.Wassel,B. \nMazloom,S.Mysore,F.Chong,andT.Sher\u00adwood. Complete information .ow tracking from thegates up. In AS-PLOS, \nMarch 2009. [47] T. K. Tolstrup. Language-based Security for VHDL. PhD thesis, Technical University of \nDenmark, 2006. [48] T. K. Tolstrup, F. Nielson, and H. R. Nielson. Information .ow analysis for VHDL. \nvolume 3606 of LNCS, 2005. [49]N.Vachharajani,M.J. Bridges,J. Chang,R.Rangan,G. Ottoni,J.A. Blome, G. \nA. Reis, M. Vachharajani, and D. I. August. Ri.e: An architectural framework for user-centric information-.ow \nsecurity. In Micro, pages 243 254, 2004. [50] G.Venkataramani, I. Doudalis,Y. Solihin, and M. Prvulovic. \nFlexi\u00adTaint:Aprogrammable accelerator for dynamic taint propagation. In HPCA, pages 196 206, 2008. [51]D.Volpano,C. \nIrvine,andG. Smith.Asoundtype systemfor secure .ow analysis. J. Comput. Secur., 4:167 187, January 1996. \n[52] D. Volpano and G. Smith. Eliminating covert .ows with minimum typings. page 156, 1997. [53] D.Volpano \nand G. Smith. A type-based approach to program secu\u00adrity. In In Proceedings of the 7th InternationalJoint \nConference on the Theory and Practice of Software Devel-opment, pages 607 621. Springer, 1997. [54] Z.Wang \nand R. B. Lee. New cache designs for thwarting software cache-based side channel attacks. In ISCA,pages \n494 505,NewYork, NY, USA, 2007.ACM. [55] S. Zdancewic and A. C. Myers. Secure information .ow via linear \ncontinuations. 15(2-3):209 234, 2002. [56] S. Zdancewic and A. C. Myers. Observational determinism for \ncon\u00adcurrent program security. pages 29 43, 2003. [57] N. Zeldovich, S. Boyd-Wickizer,and D.Mazieres. \nSecurity distributed systems with information .ow control. In NSDI, pages 293 308, Apr. 2008. [58] N. \nZeldovich,S.Boyd-Wickizer,E.Kohler, andD. Mazi`eres. Making information .ow explicit in HiStar. In OSDI, \n2006. [59] N. Zeldovich, H. Kannan, M. Dalton, and C. Kozyrakis. Hardware enforcement of application \nsecurity policies using tagged memory. In OSDI, Dec. 2008.  \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Information flow is an important security property that must be incorporated from the ground up, including at hardware design time, to provide a formal basis for a system's root of trust. We incorporate insights and techniques from designing information-flow secure programming languages to provide a new perspective on designing secure hardware. We describe a new hardware description language, Caisson, that combines domain-specific abstractions common to hardware design with insights from type-based techniques used in secure programming languages. The proper combination of these elements allows for an expressive, provably-secure HDL that operates at a familiar level of abstraction to the target audience of the language, hardware architects.</p> <p>We have implemented a compiler for Caisson that translates designs into Verilog and then synthesizes the designs using existing tools. As an example of Caisson's usefulness we have addressed an open problem in secure hardware by creating the first-ever provably information-flow secure processor with micro-architectural features including pipelining and cache. We synthesize the secure processor and empirically compare it in terms of chip area, power consumption, and clock frequency with both a standard (insecure) commercial processor and also a processor augmented at the gate level to dynamically track information flow. Our processor is competitive with the insecure processor and significantly better than dynamic tracking.</p>", "authors": [{"name": "Xun Li", "author_profile_id": "81448599690", "affiliation": "University of California, Santa Barbara, Santa Barbara, CA, USA", "person_id": "P2690499", "email_address": "xun@cs.ucsb.edu", "orcid_id": ""}, {"name": "Mohit Tiwari", "author_profile_id": "81416603909", "affiliation": "University of California, Santa Barbara, Santa Barbara, CA, USA", "person_id": "P2690500", "email_address": "tiwari@cs.ucsb.edu", "orcid_id": ""}, {"name": "Jason K. Oberg", "author_profile_id": "81414616009", "affiliation": "University of California, San Diego, San Diego, CA, USA", "person_id": "P2690501", "email_address": "jkoberg@cs.ucsd.edu", "orcid_id": ""}, {"name": "Vineeth Kashyap", "author_profile_id": "81485654147", "affiliation": "University of California, Santa Barbara, Santa Barbara, CA, USA", "person_id": "P2690502", "email_address": "vineeth@cs.ucsb.edu", "orcid_id": ""}, {"name": "Frederic T. Chong", "author_profile_id": "81100287682", "affiliation": "University of California, Santa Barbara, Santa Barbara, CA, USA", "person_id": "P2690503", "email_address": "chong@cs.ucsb.edu", "orcid_id": ""}, {"name": "Timothy Sherwood", "author_profile_id": "81100522468", "affiliation": "University of California, Santa Barbara, Santa Barbara, CA, USA", "person_id": "P2690504", "email_address": "sherwood@cs.ucsb.edu", "orcid_id": ""}, {"name": "Ben Hardekopf", "author_profile_id": "81331494259", "affiliation": "University of California, Santa Barbara, Santa Barbara, CA, USA", "person_id": "P2690505", "email_address": "benh@cs.ucsb.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993512", "year": "2011", "article_id": "1993512", "conference": "PLDI", "title": "Caisson: a hardware description language for secure information flow", "url": "http://dl.acm.org/citation.cfm?id=1993512"}