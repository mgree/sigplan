{"article_publication_date": "06-04-2011", "fulltext": "\n NDSeq: Runtime Checking for Nondeterministic Sequential Speci.cations of Parallel Correctness Jacob \nBurnim Tayfun Elmas George Necula Koushik Sen Department of Electrical Engineering and Computer Sciences, \nUniversity of California, Berkeley {jburnim,elmas,necula,ksen}@cs.berkeley.edu Abstract We propose to \nspecify the correctness of a program s parallelism using a sequential version of the program with controlled \nnondeter\u00adminism. Such a nondeterministic sequential speci.cation allows (1) the correctness of parallel \ninterference to be veri.ed independently of the program s functional correctness, and (2) the functional \ncor\u00adrectness of a program to be understood and veri.ed on a sequential version of the program, one with \ncontrolled nondeterminism but no interleaving of parallel threads. We identify a number of common patterns \nfor writing nondeter\u00administic sequential speci.cations. We apply these patterns to spec\u00adify the parallelism \ncorrectness for a variety of parallel Java bench\u00admarks, even in cases when the functional correctness \nis far too com\u00adplex to feasibly specify. We describe a sound runtime checking technique to validate that \nan execution of a parallel program conforms to its nondeter\u00administic sequential speci.cation. The technique \nuses a novel form of con.ict-serializability checking to identify, for a given inter\u00adleaved execution \nof a parallel program, an equivalent nondetermin\u00adistic sequential execution. Our experiments show a signi.cant \nre\u00adduction in the number of false positives versus traditional con.ict\u00adserializability in checking for \nparallelization bugs. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program \nVeri.cation; D.2.5 [Software Engineer\u00ading]: Testing and Debugging; F.3.1 [Logics and Meanings of Pro\u00adgrams]: \nSpecifying and Verifying and Reasoning about Programs General Terms Algorithms, Reliability, Veri.cation \n1. Introduction The spread of multicore processors and the end of rapidly growing single-core performance \nis increasing the need for programmers to write parallel software. Yet writing correct parallel programs \nwith explicit multithreading remains a dif.cult undertaking. A program\u00admer must ensure not only that \neach part of his or her program com\u00adputes the correct results in isolation, but also that the uncontrolled \nand nondeterministic interleaving of the program s parallel threads cannot cause harmful interference, \nleading to incorrect .nal results. This need to simultaneously reason about sequential functional cor\u00adrectness \nand the correctness of parallel interleavings poses a great Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, \nUSA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 challenge both for programmers \nwriting, understanding, and testing their software and for tools analyzing and verifying such software. \nWe previously proposed nondeterministic sequential (NDSeq) speci.cations [9] as a means to separate the \ncorrectness of the par\u00adallelism of a program from its sequential functional correctness. The key idea \nis for a programmer to specify the intended or al\u00adgorithmic nondeterminism in a program using annotations, \nand then the NDSeq speci.cation is a version of the program that is sequential but includes the annotated \nnondeterministic behavior. The only valid parallel behaviors are those allowed by the NDSeq speci.cation \nany additional nondeterminism is an error, due to unintended interference between interleaved parallel \nthreads, such as data races or atomicity violations. Thus, a program with such annotated nondeterminism \nserves as its own NDSeq speci.cation for the correctness of its parallelism. Showing that a parallel \nprogram conforms to its NDSeq speci\u00ad.cation is a strong statement that the program s use of parallelism \nis correct. The behavior of the program can be understood by con\u00adsidering only the NDSeq version of the \nprogram, as executing the program in parallel cannot produce any different results. Testing, debugging, \nand veri.cation of functional correctness can be per\u00adformed on this sequential version, with no need \nto deal with the uncontrolled interleaving and interference of parallel threads. We show in this work \nthat NDSeq speci.cations for parallel applica\u00adtions can be both written and checked in a simple manner, \nindepen\u00addent of an application s complex functional correctness. In this paper, we propose several patterns \nfor writing NDSeq speci.cations, and we apply these patterns to specify the paral\u00adlelism correctness \nof a number of Java benchmarks. We .nd that, with a few simple constructs for specifying intended nondetermin\u00adistic \nbehavior, adding such speci.cations to the program text was straightforward for a variety of applications. \nThis is despite the fact that, for many of these applications, writing a traditional functional correctness \nspeci.cation would be extremely dif.cult. (Imagine, for example, specifying the correct output of an \napplication to ren\u00adder a fractal, or to compute a likely phylogenetic tree given genetic sequence data.) \nFor many of our benchmarks, verifying that the .\u00adnal output is correct even for a single known input \nis challenging. We propose a novel sound runtime technique for checking that a structured parallel program \nconforms to its NDSeq speci.ca\u00adtion. Given a parallel execution of such a program, we perform a con.ict-serializability \ncheck to verify that the same behavior could have been produced by the NDSeq version of the program. \nBut .rst, our technique combines a dynamic dependence analysis with a pro\u00adgram s speci.ed nondeterminism \nto show that con.icts involving certain operations in the trace can be soundly ignored when per\u00adforming \nthe con.ict-serializability check. Our experimental results show that our runtime checking technique \nsigni.cantly reduces the number of false positives versus traditional con.ict-serializability in checking \nparallel correctness.  1: coforeach (i in 1,...,N) { 1: nd-foreach (i in 1,...,N) { 1: coforeach (i \nin 1,...,N) { 2: b = lower_bound_cost(i); 2: b = lower_bound_cost(i); 2: b = lower_bound_cost(i); 3: \nt = lowest_cost; 3: t = lowest_cost; 3: t = lowest_cost; 4: if (b>=t) 4: if (* &#38;&#38;(b>=t)) 4: if \n( true* &#38;&#38; (b >= t)) 5: continue; 5: continue; 5: continue; 6: c = expensive_compute_cost(i); \n6: c = expensive_compute_cost(i); 6: c = expensive_compute_cost(i); 7: atomic { 7: atomic { 7: atomic \n{ 8: t = lowest_cost 8: t = lowest_cost 8: t = lowest_cost 9: if (c<t){ 9: if (c<t){ 9: if (c < t) { \n10: lowest_cost = c; 10: lowest_cost = c; 10: lowest_cost = c; 11: best_soln = i; 11: best_soln = i; \n11: best_soln = i; 12:}}} 12:}} } 12:}} } (b) Nondeterministic sequential (c) Parallel search with embedded \n(a) An example parallel search procedure. speci.cation for parallel search procedure. nondeterministic \nsequential speci.cation. Figure 1. An example parallel search procedure (Figure 1(a)) and a nondeterministic \nsequential speci.cation (NDSeq) for its parallel correctness (Figure 1(b)). Since a parallel program \nand its NDSeq speci.cation look very similar, in practice, we do not write the NDSeq speci.cation of \na parallel program separately, but embed it in the parallel program itself. Figure 1(c) shows the parallel \nsearch procedure with its NDSeq speci.cation embedded in the parallel code. The boxed constructs have \ndifferent semantics when viewed as parallel code or as nondeterministic sequential speci.cation. 2. Overview \nIn this section, we discuss an example program in detail to moti\u00advate NDSeq speci.cations and to informally \ndescribe our runtime checking that a parallel program is parallelized correctly with re\u00adspect to its \nNDSeq speci.cation. In Section 3, we then give a formal de.nition of parallelization correctness. In \nSection 4, we illustrate the generality of these speci.cations and of our checking approach on several \nexamples highlighting different parallelization patterns. Section 5 describes the details of the runtime \nchecking algorithm. We discuss the experimental results in Section 6 and conclude in Section 8 by pointing \nout signi.cance and possible future applica\u00adtions of NDSeq speci.cations. 2.1 Motivating Example Consider \nthe simpli.ed version of a generic branch-and-bound pro\u00adcedure given in Figure 1(a). This program takes \nas input a list of N possible solutions and computes lowest cost, the minimum cost among the possible \nsolutions, and best soln, the index of a solu\u00adtion with minimum cost. Function expensive compute cost(i) \ncomputes the cost of solution i. Because this computation is ex\u00adpensive, the program .rst computes a \nlower bound for the cost of solution i with lower bound cost(i). If this lower bound is no smaller than \nthe lowest cost found so far (i.e. lowest cost), then the program skips computing the exact cost for \nsolution i. The program is a parallel search the coforeach loop allows different iterations to examine \ndifferent potential solutions in par\u00adallel. Thus, updates to lowest cost and best soln at Lines 8 11 \nare enclosed in an atomic block, a synchronization mechanism that enforces that these lines be executed \natomically that is, all\u00adat-once and without interruption by any other thread. Functions expensive compute \ncost and lower bound cost have no side\u00adeffects and do not read any mutable shared data (i.e., lowest \ncost or best soln), and thus require no synchronization.  2.2 Nondeterministic Sequential Speci.cations \nWe would like to formalize and specify that the search procedure in Figure 1(a) is parallelized correctly, \nand we would like some way to verify or test this parallel correctness. If we could specify the full \nfunctional correctness of our ex\u00adample program i.e. specify precisely which outputs are correct for each \ninput then this speci.cation would clearly imply that the parallelization of the program was correct. \nBut writing a full func\u00adtional correctness speci.cation is often a very dif.cult task. For our example \nsearch procedure, the cost of a possible solution may be a complex function whose behavior we are unable \nto specify, short of reimplementing the entire expensive compute cost in a speci.cation/assertion language. \nEven if we could write such a speci.cation, verifying the full functional correctness could simi\u00adlarly \nrequire very complex reasoning about the internals of the cost and lower bound computations. We argue \nthat we should seek to specify the correctness of the parallelism in our example program independently \nof the program s functional correctness. More generally, we aim to decompose our effort of verifying \nor checking the correctness of the program into two parts: (1) addressing the correctness of the parallelism, \ninde\u00adpendent of the complex functional correctness and (2) addressing the functional correctness independent \nof any reasoning about the interleaving of parallel threads. A natural approach to specifying parallel \ncorrectness would be to specify that the program in Figure 1(a) must produce the same results i.e. compute \nthe same lowest cost and best soln as a version of the program with all parallelism removed. But if we \nsimply replace the coforeach with a traditional foreach-loop that iterates i sequentially from 1 to N, \nwe do not get an equivalent program. Rather, the parallel program has two freedoms the sequential program \ndoes not: ND1 First, the parallel search procedure is free to execute the par\u00adallel loop iterations \nin any nondeterministic order. If there are multiple solutions of minimum cost, then different runs of \nthe procedure may return different values for best soln, depend\u00ading on the order in which the loop iterations \nare scheduled. The hypothetical sequential version, on the other hand, would be deterministic it would \nalways .rst consider solution 1, then solution 2, ..., up to solution N. ND2 Second, the parallel program \nis free, in a sense, to not perform the optimization in Lines 2 5, in which the rest of an iteration \nis skipped because the lower bound on the solution cost is larger than the minimum cost found so far. \nConsider two iterations with the same cost and with lower bounds equal to their costs. In the hypothetical \nsequential ver\u00adsion, only one of the iterations would proceed to compute its cost. In the parallel code \nin Figure 1(a), however, both itera\u00adtions may proceed past the check in Line 3 (as lowest cost is initially \n8). We propose to specify the correctness of the parallelism by com\u00adparing our example parallel program \nto a version that is sequential but contains the nondeterministic behaviors ND1 and ND2. Such Figure \n2. A parallel execution of three iterations (i=1,2,3) of the parallel search procedure. The vertical \norder of events shows the interleaving. Each assignment shows in parentheses the value being assigned. \nThe thin dotted arrows denote data dependencies. The thick solid and thick dashed arrows denote transactional \ncon.icts. Our analysis proves that the transactional con.ict e2 --+ e12 can be safely ignored for the \nserializability check.  a version of the program is a nondeterministic sequential (ND-Seq) speci.cation \nfor the program s parallel correctness. For the program in Figure 1(a), our NDSeq speci.cation is listed \nin Fig\u00adure 1(b). The NDSeq speci.cation differs from the parallel program in two ways: 1. The parallel \ncoforeach loop at Line 1 is replaced with a sequential but nondeterministic nd-foreach loop, which can \nrun its iterations in any order. 2. The * &#38;&#38; is added to the condition at Line 4. This expression \n* can nondeterministically evaluate to true or false, allow\u00ading the sequential speci.cation to run the \nrest of a loop iteration even when lower bound cost(i) = lowest cost.  This speci.cation is a completely \nsequential version of the pro\u00adgram, executing its loop iterations one-at-a-time with no interleav\u00ading \nof different iterations. It contains only the controlled nondeter\u00adminism added at the two above points. \nWe say that a parallel pro\u00adgram conforms to its NDSeq speci.cation when every .nal result of the parallel \nprogram can also be produced by an execution of the NDSeq speci.cation. Section 3 elaborates the semantics \nof NDSeq speci.cations and our precise de.nition of parallelism correctness. Note the close similarity \nbetween the parallel program in Fig\u00adure 1(a) and its NDSeq speci.cation in Figure 1(b). Rather than maintaining \nour parallel search procedure and its NDSeq speci.\u00adcations as separate artifacts, we embed the NDSeq \nspeci.cations into the parallel code, as shown in Figure 1(c). Here we show in boxes the coforeach and \ntrue* &#38;&#38; to indicate that these two constructs are interpreted differently when we consider Figure \n1(c) as a parallel program or as nondeterministic sequential one. That is, in the parallel interpretation, \ncoforeach is a standard parallel for-loop and true* always evaluates to true, yielding the exact behavior \nof Figure 1(a). But when interpreted as nondeterministic Figure 3. An execution of the nondeterministic \nsequential version of the search procedure. This execution is a serialization of the parallel execution \nin Figure 2, producing the same .nal result. The thick solid and thick dashed arrows denote transactional \ncon.icts. Note that the order of con.icts e12 . e15 and e12 . e18 is the same as in Figure 2, while con.ict \ne12 --+ e2, involving irrelevant event e2, has been .ipped. sequential constructs, coforeach is treated \nas a nd-foreach and true* can nondeterministically evaluate to true or false, yielding exactly the behavior \nof Figure 1(b). With these annotations, the ex\u00adample program in Figure 1(c) embeds its own NDSeq speci.cation \nfor the correctness of its parallelism.  2.3 Runtime Checking of Parallel Correctness We now give an \noverview of our proposed algorithm for the runtime checking that a parallel program conforms to its NDSeq \nspeci.ca\u00adtion. We will present the algorithm in full formal detail in Section 5. Figure 2 illustrates \na possible parallel execution of our example program in Figure 1(c) on N =3 possible solutions. The three \niterations of the parallel for-loop are shown in separate boxes, with the i =1 iteration running in parallel \nwith the i =2 iteration, followed by the i =3 iteration. Although the i =1 compute a lower bound and \ncompare it against lowest cost, iteration i = 2 is .rst to compute the full cost of its solution and \nto update lowest cost =4 and best soln =2. We would like to verify that the parallelism in this execution \nis correct. That is, the .nal result produced is also possible in an ex\u00adecution of the NDSeq speci.cation. \nThe key will be to show that parallel loop iterations together are serializable [29] i.e. there ex\u00adist \nsome order such that, if the iterations are executed sequentially in that order, then the same .nal result \nwill be produced. A common restriction of serializability that can be ef.\u00adciently checked and is thus \noften used in practice is con.ict\u00adserializability [29]. Given a collection of transactions in this case, \nwe think of each parallel loop iteration as a transaction we form the con.ict graph whose vertices are \nthe transactions and with a con.ict edge from transaction tr to trl if tr and trl contain con\u00ad.icting \noperations op and opl with op happening before op . (Two operations from different threads are con.icting \nif they operate on the same shared global and at least one of them is a write; in our example the con.icts \nare shown with thick solid or thick dashed arrows.) It is a well-known result [29] that if there are \nno cycles in the con.ict graph, then the transactions are serializable.  But con.ict-serializability \nis too strict for our example in Fig\u00adure 2. There are three pairs of con.icting operations in this execu\u00adtion: \na read-write con.ict between e2 and e12, a write-read con.ict between e12 and e15, and a write-read con.ict \nbetween e12 and e18. In particular, the i =1 and i =2 transactions are not con.ict\u00adserializable because \nthe i =2 transaction s write of lowest cost at e12 comes after the read of lowest cost at e2 but before \nthe read at e15. In this paper, we generalize con.ict-serializability by determin\u00ading, using a dynamic \ndata dependence analysis, that the only use of the value read for lowest cost at e2 is in the branch \ncondition at e6. (The data dependence edges in each thread are shown in Fig\u00adure 2 with the thin dashed \narrows.) But because of our added nonde\u00adterminism at Line 4 of our example program, this branch condition \nis gated by the nondeterministic condition at e5. Our data depen\u00addence analysis tells us that no operation \nperformed inside the if (true*) opened at e5 has any local or global side-effects thus, in the equivalent \nsequential execution whose existence we are try\u00ading to show, we can choose this nondeterministic condition \nto be false, in which case the read of lowest cost at e2 will never be used. This shows that the read-write \ncon.ict involving e2 and e12 is irrelevant, because, once we choose the nondeterministic condition to \nbe false, the value read at e2 has no effect on the execution. With only the remaining two relevant con.icts, \nthe con.ict graph has no cycles, and thus we will conclude that the loop itera\u00adtions are serializable. \nFigure 3 shows a serial execution whose exis\u00adtence we have inferred by verifying that there are no con.ict \ncycles. Note that the two relevant con.icts, e12 . e15 and e12 . e18, are preserved they both appear \nin the serial execution in the same order. But the irrelevant con.ict has been .ipped. The write of lowest \ncost at e12 now happens before the read at e2, but this change does not affect the .nal result of the \nexecution, because the value read for lowest cost does not affect the control-.ow or any writes to global \nvariables. Now suppose that the execution in Figure 2 produces an incor\u00adrect result, i.e., violates a \nfunctional speci.cation of the parallel program. Because we showed above that this execution is equiva\u00adlent \n(with respect to the .nal relevant state) to the computed serial execution in Figure 3, then the nondeterministic \nsequential execu\u00adtion exhibits the same functional bugs as the parallel execution. Thus, we can simply \ndebug the serial execution without worrying about thread interleavings. 3. Parallelism Correctness with \nNondeterministic Sequential Speci.cations In this section, we formally de.ne our programming model, our \nnondeterministic sequential (NDSeq) speci.cations, and our notion of parallel correctness. As discussed \nin Section 2.2, we embed the NDSeq speci.cations for a parallel program in the program itself. We achieve \nthis both by overloading parallel language constructs and by adding a couple of new constructs. The syntax \nfor the language is shown in Figure 4. To simplify the presentation we consider a program P to consist \nof a single procedure. We omit discussion of multiple procedures and object-oriented concepts, and we \nassume that each global vari\u00adable refers to a distinct location on the shared heap and that each local \nvariable refers to a distinct location on the stack of a thread. Handling these details in our dynamic \nanalysis is straightforward. For each program P, we de.ne two sets of executions ParExecs(P) and NdSeqExecs(P), \ndescribed below. The correct\u00adness of a parallel program is then given by relating ParExecs(P) and NdSeqExecs(P). \ng . Global l . Local Var = Global . Local x . Var ::= l | g b ::= l | true* | false* s . Stmt ::= l = \nl op l | l = constant | l = l | g = l | l = g | s; s | if(b) s | if(l) s else s | while(l) s | for (l \nin l) s | continue | break | return | \u00b7\u00b7\u00b7 | atomic s | coforeach (l in l) s | cobegin s; ...; s Figure \n4. Selected statements of our language. The constructs with a different semantics in the parallel program \nand the sequential speci.cation are shown in boxes. Parallel executions: ParExecs(P) contains the parallel \nexecu\u00adtions of P where each cobegin and coforeach statement creates implicitly new threads to execute \nits body. cobegin s1; ...; sn is evaluated by executing each of s1, ..., sn on a separate, newly cre\u00adated \nthread. coforeach is evaluated by executing each iteration of the loop on a separate, newly created thread. \nFollowing struc\u00adtured fork/join parallelism, a parallel execution of a cobegin and coforeach statement \nterminates only after all the threads created on behalf of the statement terminate. Assignments, the \nevaluation of conditionals, and entire atomic statements, are executed as atomic steps without interruption \nby other threads. In the parallel seman\u00adtics, true* and false* always evaluate to true and false, respectively. \nSequential executions: NdSeqExecs(P) contains the (nondeter\u00administic) sequential executions of P where \nall statements are evaluated sequentially by a single thread. Under the sequential semantics, the statements \nother than if with *, cobegin, and coforeach are interpreted in the standard way. Each evaluation of \ncobegin s1; ...; sn is equivalent to running a nondeterministic permutation of statements s1, ..., sn, \nwhere each si.[1..n] executes sequentially. A statement coforeach is evaluated similarly to its deterministic \nversion (for) except that the elements of the collec\u00adtion being iterated over are processed in a nondeterministic \norder. This, in essence, abstracts the semantics of the collection to an un\u00adordered set. Keyword atomic \nhas no effect in the sequential case, so atomic s is simply equivalent to s. Finally, true* or false* \nyield nondeterministic boolean values each time they are evaluated. Parallelism Correctness. We describe \nexecutions of P using a standard notion of small-step operational semantics extended with nondeterministic \nevaluation of cobegin and coforeach, and nonde\u00adterministic branches (true* and false*). The parallelism \ncorrectness for P means that every .nal state reachable by a parallel execution of the program from a \ngiven initial state is also reachable by an NDSeq execution from the same initial state. Therefore, parallel \nexecutions have no unintended nondeter\u00adminism caused by thread interleavings: either the nondeterminism \nis prevented using synchronization, or it is expressed by the nonde\u00adterministic control .ow in the sequential \nspeci.cation. While de.ning parallel correctness, we distinguish a set of global variables as focus variables, \nwhich contain the .nal results of a program. Then, we reason about the equivalence of executions on the \n.nal values of the focus variables. De.nition 1 (Parallelism correctness) A program P conforms to its \nNDSeq speci.cation with respect to a set Focus . Global iff for every parallel execution E . ParExecs(P), \nthere exists a nondeterministic sequential execution El .NdSeqExecs(P), such that the initial states \nof E and El are the same and the .nal states agree on the values of all variables in Focus.  4. Nondeterministic \nSpeci.cation Patterns The use of nondeterministic sequential speci.cations is an attrac\u00adtive way to specify \nparallel correctness, yet it is not immediately clear where to introduce the nondeterministic constructs \ninto the speci.cation (1) without breaking the functional correctness while (2) capturing the nondeterminism \ndue to thread interleavings. Figure 5 shows the pseudo-code for three common patterns that we encountered \nrepeatedly in our experiments. Each of these patterns considers parallel worker tasks where there is \na potential for con.icting accesses to shared data. In contrast, applications where shared data is distributed \nstrictly disjointly between tasks do not require use of if(true*) speci.cations. Next, we discuss these \npatterns in detail. 4.1 Optimistic Concurrent Computation This pattern is a manually implemented analogue \nof software trans\u00adactional memory (STM) [37]. A parallel task performs its work optimistically in order \nto reduce the synchronization with other threads. It reads the shared data (shared) required for its \nwork to a local variable (local) and performs the computation (do work) without further access to shared \ndata. Before committing the re\u00adsult of the computation back to the shared space, it checks if the input \nit read previously has been modi.ed by another thread (is conflict). In that case it retries the work. \nThis pattern is used when the time spent for the local computation dominates the time for checking con.ict \nand committing, and the contention on the same regions of shared memory is low. Such fail-retry behaviors \nare not normally con.ict-serializable when another thread updates shared during do work. The up\u00addate \ncon.icts with the read of shared before and after do work. However, in those situations we expect is \nconflict to return true and the commit to be skipped. The true* &#38;&#38; allows the NDSeq program to \nnondeterministically skip the con.ict check\u00ad ing and the commit. This captures that (1) it is acceptable \nfrom a partial-correctness point of view to skip the commit nondeterminis\u00adtically even without checking \nis conflict, and (2) if the commit is skipped then the read of shared data before and after do work are \nirrelevant and can be ignored for con.ict serializability purposes. Examples: This pattern is used in \nnon-blocking data structures, e.g., stacks and queues, to implement optimistic concurrent access to the \ndata structure without locks. These data structures imple\u00adment the atomic block in the pseudo code using \na compare-and\u00adswap (CAS) operation [18]. We have also encountered this pattern when parallelizing a mesh \nre.nement program from the Lonestar benchmark suite (see Section 6). Our parallelization instantiates \nthe pattern in Figure 5 as follows: // Processing cavity of a node N: while (true) { local_cavity = read \ncavity of N from shared mesh; refined_cavity = refine the cavity locally; atomic { if ( true* &#38;&#38; \nmesh still contains all nodes in local_cavity) { replace old cavity in mesh with refined_cavity; break; \n}}} Appendix A gives more examples of NDSeq speci.cations for non-blocking implementations following \nthe same pattern. 4.2 Redundant Computation Optimization In contrast with optimistic computation where \neach parallel task must complete its work, in the redundant computation pattern, each thread may choose \nto skip its work when it detects that the work is no longer necessary (is work redundant). Here synchronizing \nthe check for redundancy and the actual work may not be practical when the latter is a long running operation. \nOptimistic Concurrent Computation Pattern while (true) { local = shared; local = do_work(local); atomic \n{ if ( true* &#38;&#38; !is_conflict(local,shared)) { shared = local ; // commit result break; }}} Redundant \nComputation Optimization Pattern if ( true* &#38;&#38; is_work_redundant(shared)) { // work is unnecessary; \nskip the work } else { do_work(); // accesses shared } Irrelevant Computation Pattern do_work(local, \nshared); if ( true* ){ do_irrelevant_work(); } Figure 5. Common concurrency patterns and use of true* \nand false* to express the nondeterminism. Threads operating under this pattern are not con.ict serializable \nif another thread updates the shared state while our thread calls is work redundant and .nds that it \nreturns false. Those updates con.ict with the shared read before calling is work redundant and while \nexecuting do work. The true* &#38;&#38; allows the NDSeq program to nondeterministi\u00adcally skip the call \nto is work redundant and do the work anyway. This expresses that (1) it is acceptable from a partial-correctness \npoint of view to skip the redundancy check and to do the actual work, and also that (2) if we skip the \nredundancy check, then the initial read of shared state is not relevant to the computation and can be \nignored for con.ict-serializability purposes. Examples: This pattern is often used when a solution space \nis ex\u00adamined by multiple threads to improve convergence to an optimal solution. Our running example in \nSection 2.1 follows this pattern: Lines 2 5 in Figure 1 test the lower bound of the current solution \nto decide if the computation at Line 6 can produce a better solution. The phylogeny benchmark from the \nParallel Java Library follows a similar bound check to prune the search space for optimal phy\u00adlogenetic \ntrees. Programs using caches to avoid multiple computa\u00adtions of a function for the same input also use \nthis pattern.  4.3 Irrelevant Computation This pattern generalizes tasks that perform some computation \n(shown in the if(true*) branch) that does not affect the rest of the execution path and does not produce \na result that .ows into shared state that is relevant to core functional correctness. One can ignore \nthe irrelevant part of the program when reasoning about the pro\u00adgram in the sequential semantics, since \neither (1) it does not affect the focus state, or (2) it is only necessary for the parallel executions \nof the program. Examples: A prevalent instance of case (1) is when updating a statistic counter to pro.le \nthe procedures of a program. For example, in the following we use if(true*) to mark the increment of \na statistic counter as an irrelevant operation. Updates to counter do not affect the .nal result (with \nrespect to focus variables) of the program. However, without using the if(true*), con.icts due to counter \nwill not be ignored by our analysis. By surrounding the if statement with if(true*), the programmer indicates \nthat the if branch is not relevant for the .nal result, and con.icts due to the accesses to counter when \nexecuting the branch should not affect the parallel correctness of the program. In fact, one can easily \nprove statically that, given counter is not a focus variable, skipping the conditional at all is safe \nfor the functionality.  do_work(shared, local); // access shared variables exclusively if ( true* ){ \nif (counter < MAX_INT) { counter = counter + 1; } } Moreover, rebalancing a tree, garbage collection \nand com\u00ad paction, maintaining a cache, and load balancing are operations that are performed to improve \nthe performance of a parallel program, but when implemented correctly do not affect the core function\u00ad \nality of the program and thus are considered irrelevant. An instance of (2) is when using a locking library \nto ensure atomicity of the relevant computation. In contrast with the statistics counters, locks are \nessential for the correctness of the parallelism, though the locking-state is often irrelevant for reasoning \nabout the core functionality of the program in a sequential run. 5. Runtime Checking of Parallel Correctness \nAmong the various possible techniques for checking parallelization correctness, we describe here a runtime \nchecking algorithm. We use dynamic data-.ow analysis to determine parts of the executions that are not \nrelevant to the .nal valuation of the focus variables. At the same time the analysis determines appropriate \nassignments of boolean values to the if(true*) nondeterministic branches in the NDSeq execution, in order \nto eliminate as many serialization con\u00ad .icts as possible. Therefore, data .ow analysis and NDSeq spec\u00ad \ni.cations play key roles in improving the applicability of con.ict serializability for reasoning about \nparallelism in real programs. In the rest of this section, we describe the details of the checking al\u00ad \ngorithm and we sketch its correctness. In order to simplify the presentation of the runtime checking \nalgorithm for parallelism correctness we make the following as\u00ad sumptions about the parallel program \nbeing checked: A1. Branch predicates are either true* or a local variable. A2. The body of an if(true*) \ndoes not contain unstructured control .ow (e.g., continue, break, return), and there is no else clause. \nThese assumptions can be established using standard program refactoring. For example, Lines 4 5 from \nFigure 1(c) can be trans\u00adlated to: bool cond = false; if( true* ){ l = (b >= t); if(l){ cond = true; \n}} if(cond) continue; where cond and l are new local variables. Our checking algorithm operates on an \nexecution trace de\u00ad scribed as a sequence of execution events. Let t denote a trace and e an event. For \neach event e we have the following information: Type(e) is the type of the event, de.ned as follows: \nT ::= x = x l | branch(l) | branch(true*) The x = x l event type corresponds to the assignment and bi\u00adnary \noperation statements in our language (shown in Figure 4; recall that metavariable x stands for both locals \nand globals). We use a simple assignment in our formal description to sim\u00adplify the presentation; unary \nand binary operators do not pose notable dif.culties. We assume that an event can read a global, or write \na global, but not both. The branch(l) event marks the execution of a branch operation when the boolean \ncondi\u00adtion denoted by local l evaluates to true. The case of a branch when the negation of a local is \ntrue is similar. Finally, the branch(true*) marks the execution of an if(true*) branch, which in the \nparallel execution is always taken. Our algorithm does not require speci.c events to mark the start and \nend of procedures or atomic blocks. We write e : T when e has type T . Thread(e) denotes the thread \nthat generates the event e. Re\u00adcall that new threads are created when executing cobegin and coforeach \nstatements.  Guard(e) denotes the event of type branch(true*) that corre\u00adsponds to the most recent invocation \nof the innermost if(true*) that encloses the statement generating e. For events outside any if(true*) \nthis value is nil.  For example, in the trace shown in Figure 2, Guard(e6)= e5, Guard(e8)= e7, Guard(e20)= \nGuard(e21)= e19, and Guard(e)= nil for all other events e. The checking algorithm operates in two stages, \nshown in Fig\u00adure 6. The .rst stage computes a subset of the events in the trace that are relevant (Section \n5.1), and the second stage determines whether the relevant part of the trace is con.ict serializable \n(Section 5.2). 5.1 Selecting Relevant Events A standard con.ict-serializability algorithm [29] considers \nall events in a trace. We observed that in many concurrent programs it is common for partial work to \nbe discarded when a con.ict is later detected. In such cases, some of the computations based on previously \nread values of shared variables are discarded and are not relevant to the rest of the execution. If we \ncan ignore such ir\u00adrelevant reads of shared variables we can prove that more paths are con.ict serializable. \nSimilarly, we can ignore writes that do not af\u00adfect a relevant control .ow and do not .ow into the .nal \nstate of the focus variables. Our experiments show that this makes a differ\u00adence for most benchmarks \nwhere traditional con.ict serializability reports false alarms. Informally, an assignment event is relevant \nif it targets a location that is eventually used in the computation of a .nal value of a focus variable, \nor in the computation of a deterministic branch. To track this relevance aspect we compute a dynamic \ndata-dependence relation between events. For trace t , we de.ne the dependence relation --+ as follows: \nD1. (Intra-Thread Data Dependence). For each local variable read ej : x = l or branch ej : branch(l), \nwe add a depen\u00addence (ei --+ ej ) on the last ei : l = x l that comes before ej in t . This dependence \nrepresents an actual data .ow through lo\u00adcal l from ei to ej in the current trace. Both of these events \nare in the same thread (since they operate on the same local) and their order and dependence will be \nthe same in any serialization of the trace. These dependence edges are shown as thin dashed arrows in \nFigure 2. D2. (Inter-Thread Dependence). For each global variable read ej : l = g we add dependencies \n(ei --+ ej ) on events ei : g = ll as follows. From each thread we pick the last write to g that comes \nbefore ej in t , and the .rst write to g that comes after ej in t . This conservative dependence is necessary \nbecause the relative order of reads and writes to the global from different threads may change in a serialization \nof the trace. Section 5.3 explains the importance of this detail for correctness. In the example shown \nin Figure 2, we have such dependence edges from e12 to all events that read lowest cost: e2, e4, e10, \ne18. Let --+* denote the transitive closure of --+.  Algorithm ComputeRelevant(t, Focus) // Collecting \nrelevant events for the serializability check // Add all writes to focus globals 1 Relevant = {e : g \n= l . t | g . Focus . e is last write to g in Thread (e)}// Start with all top-level deterministic branches \n2 Relevant = Relevant .{e : branch(l) . t |Guard(e)= nil} 3 Compute data dependency relation --+ from \nt 4 repeat // Add events that some relevant events data-depend on 5 Relevant = Relevant .{e . t |.el \n. Relevant. e --+* el} // Add nondeterministic branches containing relevant events 6 Relevant = Relevant \n. {e : branch(true*) . t |.el . Relevant. Guard(el)= e} // Add deterministic branches nested inside relevant \nif (true*) s 7 Relevant = Relevant . {e : branch(l) . t | Guard(e) . Relevant}8 until Relevant does not \nchange 9 return Relevant Algorithm CheckCycle(t, Focus) // Check serializability of trace 10 Relevant \n= ComputeRelevant(t, Focus) 11 Compute con.ict relation . between threads 12 if exists a cycle t . tl \n. * t 13 Report unserializable thread t 14 else 15 Declare the execution serializable 16 end if Figure \n6. The algorithm for checking parallelism correctness. Figure 6 lists the algorithm ComputeRelevant to \ncompute the set of relevant events. We seed the set of relevant events with all the events that assign \nto the global focus variables (Line 1) and the deterministic branches outside any nondeterministic blocks \n(Line 2). In Line 5 we add the assignment events on which existing relevant events have data dependence \non. The crucial factor that allows us to .nd a signi.cant number of irrelevant events is that we can \nchoose to skip the events (assign\u00adments and branches) corresponding to nondeterministic if(true*) blocks, \nas long as those blocks are irrelevant in the trace. We extend the relevance notion from assignment events \nto branches as follows. A branch(true*) event is relevant if and only if it corresponds to the execution \nof an if(true*) block with at least one relevant assign\u00adment event (Line 6). For this step we use the \npreviously introduced Guard function to relate events inside if(true*) blocks with the corresponding \nbranch(true*) event. We also say that a branch(l) event is relevant if it represents control .ow that \nmust be preserved (it is not nested inside an irrelevant if(true*) block). This is en\u00adforced in Lines \n2 and 7. The computation in Lines 5 7 must be repeated to a .xed point since the additional relevant \ndeterministic branches added in Line 7 can lead to new relevant assignments due to data dependencies. \nFor example, in the trace in Figure 2, relevant events are e9-13 from thread with i =2, e14-16 from thread \nwith i =1, and e17-21 from thread with i =3. Since the nondeterministic branch events e5 and e7 are irrelevant \n(no events in the rest of the trace data\u00addepend on their bodies), the branch events e6 and e8 are not \nmarked as relevant. Thus, events e1-2 from thread with i =1 and e3-4 from thread with i =2 have no data-dependents \nin Relevant and they remain as irrelevant.  5.2 Checking Serializability of Transactions The .nal stage \nin our runtime checking algorithm is a con.ict serializability check implemented as a cycle detection \nproblem similar to [12, 16]. The added element here is that we ignore the con.icts induced by irrelevant \nevents, and we have the .exibility to alter the nondeterministic control .ow in order to remove con.icts. \nFirst we de.ne the con.ict relation between individual events. De.nition 2 (Con.icting events) Two events \ne, e l . t are con\u00ad.icting (written e r e l) iff (a) e occurs before e l in t, and (b) both events operate \non the same shared global variable, and at least one of them represents a write, and (c) both events \nare Relevant in trace t. Next we lift the con.ict relation from events to threads. When comparing two \nthreads for con.icts we need to consider their events and all the events of their descendant threads. \nThus, for a thread t we de.ne its transaction as the set of events Trans (t) that includes all the events \nof t and of the descendant threads of t. De.nition 3 (Con.icting threads) Two threads t, tl are con.ict\u00ading \nin trace t (written t r tl) iff (a) their transaction sets are disjoint (i.e., one is not a descendant \nof the other), and (b) there ex\u00adist two events e . Trans (t) and e l . Trans (tl) that are con.icting \n(e r e l). The relation t r * tl is the transitive and re.exive clo\u00adsure of the thread con.ict relation. \nThe main runtime checking algorithm for parallelism correct\u00adness is shown in Lines 10 16 in Figure 6. \nFor the example trace shown in Figure 2 the event e2 is not relevant, which allows the algorithm CheckCycle \nto ignore the con.ict between e2 and e12 (shown with thick dashed arrow in Figure 2). Without the dependence \nanalysis we could not show that the trace is serializable.  5.3 Algorithm Correctness The correctness \nof our runtime checking algorithm can be argued by showing that when the CheckCycle algorithm succeeds, \nthe input trace t . ParExecs(P) can be transformed incrementally into a trace tl . NdSeqExecs(P) such \nthat the .nal states in both traces agree on the values of the focus variables. Each in\u00adcremental transformation \npreserves the validity of the trace and the .nal condition on focus variables. Some of the intermediate \ntraces in this process will belong to the larger space of nonde\u00adterministic parallel executions NdParExecs(P), \nwhich allow both interleavings (as in ParExecs(P)) and nondeterministic branches (as in NdSeqExecs(P)). \nFor these executions the nondeterministic branches true* and false* are resolved at runtime nondeterministi\u00adcally \nto true or false. The .rst trace transformation that we perform is to eliminate the events corresponding \nto if(true*) blocks that were found irrelevant by ComputeRelevant. The second transformation is to commute \nadjacent events from different threads that are not in con.ict, either because they do not operate on \na shared global, or because one of them is irrelevant. The correctness of these steps, i.e., they preserve \nthe validity of the trace and the .nal values of focus variables, is established by Lemma 1 and Lemma \n2. The rest of the correctness algorithm builds on a standard result from database theory: a trace is \ncon.ict serializable if it can be transformed into an equivalent serial trace by commuting adjacent, \nnon-con.icting operations of different threads. This is possible if and only if the transactional con.ict \ngraph is acyclic [29]. Lemma 1 (Skip irrelevant nondeterministic blocks) If t . ParExecs(P), let t l \nbe the subtrace of t ob\u00adtained by eliminating all events e such that Guard(e) ./ComputeRelevant(t, Focus). \nThen tl is a valid trace in NdParExecs(P), meaning that t l re.ects the correct control .ow of the program \nP with the corresponding irrelevant true* resolved to false, and tl agrees with t on the .nal values \nof Focus variables. Furthermore, ComputeRelevant(t l , Focus) returns the same answer as for trace t \n.  The proof of this lemma relies .rst on the assumption (A2) stated earlier that the body of any if(true*) \nhas only normal exits and no else clause. This means that by removing all the events in any such body \nresults in a trace where control .ows properly to the statement after the skipped if(true*). All assignment \nevents eliminated in this step are irrelevant since their guard is irrelevant (Line 6 in Figure 6). Therefore \nsubsequent control .ow and the .nal value of focus variables are preserved. The set of relevant events \ndoes not change through this transformation because its computation does not depend on irrelevant events. \nLemma 2 (Commutativity of irrelevant events) Consider a trace t . NdParExecs(P) and two adjacent events \ne1 and e2 in t, such that the events are from different threads, they operate on a shared global g, at \nleast one is a write event, and at least one is irrelevant (not in ComputeRelevant(t, Focus)). Then the \ntrace obtained by commuting e1 and e2 is still a valid trace in NdParExecs(P) and it agrees with t on \nthe .nal value of Focus variables. Proof Sketch: Considering the types of events we can have in the trace \nand the conditions of the Lemma, we have three possible cases: Read-after-write: e1 : g = l and e2 : \nll = g. If e2 were relevant then e1 would also be relevant (Line 5 in the algorithm, with data-dependence \nrule D2). Thus it must be that e2 is irrelevant, hence the value of ll does not affect the subsequent \ncontrol .ow or .nal values of Focus variables. Therefore we can commute the events and the trace remains \nin NdParExecs(P). The rele\u00advant events computation does not change, since l = ll (different threads), \nand the relative order of relevant reads and writes to global does not change.  Write-after-read: e1 \n: l = g and e2 : g = ll. If e1 were relevant then e2 would also be relevant (Line 5 in the algorithm, \nwith data-dependence rule D2; this is a crucial part of the correctness argument that depends on the \nconservative form of the data\u00addependence rule D2). Thus, e1 is irrelevant, and the rest of this case \nfollows the same arguments as in the read-after-write case.  Write-after-write: e1 : g = l and e2 : \ng = ll. It must be that there is no nearby relevant read of the global g in the trace, or else both events \nwould be relevant (again due to data\u00addependence rule D2). This means that it does not matter what we \nwrite to g. The relevant set does not change after the swap because we do not change the dependence relation \n--+. It is for this reason that we require the dependence rule D2 to consider the nearest write to a \nglobal from each thread.  o With these results it is straightforward to prove our main cor\u00adrectness \nresult given below using standard con.ict-serializability results using our relaxed notion of con.icts, \nas proved adequate in Lemma 2. Theorem 1 (Correctness) Let t be the trace generated by a parallel execution \nof E . ParExecs(P) of a program P. If CheckCycle(t, Focus) does not report any unserializable trans\u00adaction, \nthen there exists a nondeterministic sequential execution El .NdSeqExecs(P), such that the initial states \nof E and El are the same and the .nal states agree on the value of all variables in Focus. The theorem \nimplies that if we explore, using a model checker, all parallel executions of the program and show that \nall these exe\u00adcutions are serializable, then we can conclude that the parallel pro\u00adgram conforms to its \nNDSeq speci.cation. 6. Experimental Evaluation In this section, we describe our efforts to experimentally \nevaluate our approach to specifying and checking parallel correctness using NDSeq speci.cations. We aim \nto evaluate two claims: (1) That it is feasible to write NDSeq speci.cations for the parallel correctness \nof real Java benchmarks, (2) Our runtime checking algorithm produces signi.cantly fewer false positives \nthan a traditional con.ict-serializability analysis in checking parallel correctness of these benchmarks. \n To evaluate these claims, we wrote NDSeq speci.cations for the parallel correctness of a number of \nJava benchmarks and then used our runtime checking technique on these speci.cations. 6.1 Benchmarks We \nevaluate our technique on a number of benchmarks that have been used in previous research [8, 12, 16] \non parallel correct\u00adness tools. Note that we focus on parallel applications, which use multithreading \nfor performance but fundamentally are performing a single computation that can be understood sequentially. \nWe do not consider concurrent benchmarks, such as reactive systems and stream-based systems, because \nit is not clear whether or not such programs can be understood sequentially. The names, sizes, and brief \ndescriptions of the benchmarks we used are listed in Table 1. Several benchmarks are from the Java Grande \nForum (JGF) benchmark suite [38], the Parallel Java (PJ) Library [20]. We report on all benchmarks that \nwe looked at except tsp [46], for which we have not yet found an easy way to write the NDSeq speci.cation \n(see Section 6.5). We also applied our tool to two large benchmarks in the DaCapo benchmark suite [4]. \nBenchmark meshrefine is a sequential application from the Lon\u00adestar benchmark suite [22] that we have \nparallelized (by convert\u00ading the application s main loop into a parallel loop). Benchmarks stack [39] \nand queue are non-blocking concurrent data structures. For each data structure, we construct a test harness \nthat performs several insertions and removals in parallel (i.e., in a cobegin). The queue is similar \nto the Michael and Scott queue [26], but eagerly updates the queue s tail with a 4-word compare-and-swap. \nThis change simpli.ed signi.cantly the NDSeq speci.cation.  6.2 Implementation Although these benchmarks \nare written in a structured parallel style, Java does not provide structured parallelism constructs such \nas coforeach or cobegin. Thus, we must annotate in these bench\u00admarks the regions of code corresponding \nto the bodies of parallel loops and cobegin s. Typically, these regions are the bodies of run methods \nof subclasses of java.lang.Thread. Similarly, some of these benchmarks use barrier synchronization. As \nbarriers have no sequential equivalent, we treat these programs as if they used a se\u00adries of parallel \ncoforeach constructs, ending one parallel loop and beginning another at each barrier. (This is a standard \ntransforma\u00adtion [45] for such code.) We similarly treat each PJ benchmark, which employ sequential loops \ninside each of a .xed number of worker threads, as instead consisting of structured parallel loops. In \norder to write NDSeq speci.cations, we implemented a sim\u00adple library for annotating in Java programs \nthe beginning and end of the bodies of if(*), coforeach, and cobegin constructs, as well as which locations \n(.elds, array elements, etc.) are focus variables. Columns 4, 5, and 6 of Table 1 list, for each benchmark, \nthe number of such annotated parallel constructs, annotated if(*), and state\u00adments added to mark focus \nvariables. We implemented our checking technique in a prototype tool for Java, which uses bytecode instrumentation \nvia Soot [42]. In addition to the details described in Section 5, for Java it is necessary  Benchmark \nBenchmark Description Approximate Lines of Code (App + Library) # of Parallel Constructs Size of Spec \n# of if(*) # of focus stmts Size of Trace All Events Irrelevant Events Distinct Serializability Warnings \nCon.ict-Serializability Our Technique JGF sor successive over-relaxation 300 1 0 1 1,600k 112 0 0 matmult \nsparse matrix-vector multiplication 700 1 0 1 962k 8k 0 0 series coef.cients of Fourier series 800 1 \n0 5 11k 140 0 0 crypt encryption and decryption 1100 2 0 3 504k 236 0 0 moldyn molecular dynamics simulation \n1300 4 0 1 4,131k 79k 0 0 lufact LU factorization 1500 1 0 1 1,778k 6k 0 0 raytracer ray tracing 1900 \n1 0 1 6,170k 44k 1 1 (bug) montecarlo Monte Carlo derivative pricing 3600 1 0 1 1,897k 534k 2 0 PJ pi3 \nMonte Carlo approximation of p 150 + 15k 1 0 1 1,062k 141 0 0 keysearch3 cryptographic key cracking 200 \n+ 15k 2 0 4 2,059k 91k 0 0 mandelbrot fractal (Mandelbrot set) rendering 250 + 15k 1 0 6 1,707k 954 0 \n0 phylogeny branch-and-bound search 4400 + 15k 2 3 8 470k 5k 6 6 (bug) DaCapo sunflow image rendering \nusing ray tracing 24k 4 4 3 24,250k 2,264k 28 3 (no bugs) xalan XML to HTML transformation 302k 1 3 4 \n16,540k 887k 6 2 (no bugs) stack Treiber non-blocking stack [39] 40 1 2 8 1,744 536 5 0 queue non-blocking \nqueue [26] 60 1 2 8 846 229 9 0 meshrefine Delaunay mesh re.nement 1000 1 2 50 747k 302k 30 0 Table \n1. Experimental results. Note that the six warnings reported for phylogeny are all true violations caused \nby a single bug. to handle language features such as objects, exceptions, casts, etc. Any Java bytecode \ninstruction that can throw an exception e.g., a .eld dereference, an array look-up, a cast, or a division \nmust be treated as an implicit branch instruction. That is, changing the values .owing into such an instruction \ncan change the control-.ow by causing or preventing an exception from being thrown. Limitations. While \nour implementation supports many intrica\u00adcies of the Java language, it has a couple of limitations: First, \nour implementation tracks neither the shared reads and writes nor the .ow of data dependence through \nuninstrumented native code. Thus, we may report an execution as having correct parallelism despite unserializable \ncon.icts in calls to native code. Second, our tool does not instrument all of the Java standard li\u00adbraries. \nThis may cause our tool to miss data dependencies carried through the data structures in these libraries, \nas well as shared reads and writes inside such data structures. To address this limitation, for certain \nshared data structure objects we introduced fake shared vari\u00adables and inserted reads or writes of those \nvariables whenever their corresponding objects were accessed. This allows us to conserva\u00adtively approximate \nthe con.icts and data dependencies for certain critical standard Java data structures.  6.3 Results: \nFeasibility of Writing Speci.cations Writing an NDSeq speci.cation for each benchmark program con\u00adsisted \nof two steps: (1) adding code to mark which parts of the pro\u00adgram s memory were in focus i.e. storage \nlocations whose values are relevant in the .nal program state, and (2) adding if(*) con\u00adstructs to specify \nintended or expected nondeterminism. For all of our benchmarks besides tsp, it was possible to write \nan NDSeq speci.cation for the benchmark s parallel correctness. The Size of Spec columns of Table 1 lists \nthe number of if(*) constructs added to each benchmark and the number of statements added to mark storage \nlocations as in focus. These numbers show that, overall, the size of the speci.cation written for each \nbench\u00admark was reasonably small. We further found adding nondetermin\u00adism via if(*) to be fairly straightforward, \nas all necessary nonde\u00adterminism fell under one of the NDSeq speci.cation patterns dis\u00adcussed in Section \n4. Identifying which storage locations were rel\u00adevant to the .nal program result was similarly straightforward. \nAs an example, we show in Appendix A.2 the complete NDSeq speci\u00ad.cation for the stack benchmark. Though \nfurther work is needed to evaluate the general applica\u00adbility of NDSeq speci.cations for parallel correctness, \nwe believe it is promising preliminary evidence that we were able to easily write such speci.cations \nfor a range of parallel applications.  6.4 Results: Runtime Checking For each benchmark, we generated \n.ve parallel executions on a single test input using a simple form of race-directed parallel fuzzing \n[36]. On each such execution, we checked our NDSeq spec\u00adi.cation both using our technique and using a \ntraditional, strict con.ict-serializability analysis [16]. We report in Column Size of Trace; All Events \nof Table 1 the size of a representative execution trace of each benchmark. The size is the number of \nreads and writes of shared variables and the number of branches executed during the run. Note that most \nof our benchmarks generate a few hundred thousand or a few million events during a typical execution \non a small test input. For a dynamic analysis, this is a more relevant measure of benchmark size than \nstatic lines of code. Column Size of Trace; Irrelevant Events reports the number of these events found \nto be irrelevant by our algorithm ComputeRelevant in Figure 6. The fraction of events found to be irrelevant, \nand therefore not considered during our algorithm s serializability checking, range from 0-40%. The Distinct \nSerializability Warnings columns of Table 1 re\u00adport the number of serializability warnings produced by \na tradi\u00adtional con.ict-serializability check and by our technique. Note that, in a trace of a benchmark, \na con.ict involving a few particular lines of code may generate many cycles among the dynamic events \nof the trace. We report only the number of distinct cycles corresponding to different sets of lines of \ncode. Both techniques .nd the two real parallelism bugs a data race in raytracer due to the use of the \nwrong lock to protect a shared checksum, and an atomicity violation in the phylogeny branch-and-bound \nsearch involving the global list of min-cost so\u00adlutions found. (The six warnings for phylogeny are all \nreal vio\u00adlations caused by this single bug.) Because of these bugs, neither raytracer nor phylogeny is \nequivalent to its NDSeq spec. A traditional con.ict-serializability analysis also gives false warnings \nfor six benchmarks incidents where there are cycles of con.icting reads and writes, but the parallel \ncode is still equiva\u00adlent to its NDSeq speci.cation. In four of these cases, our algo\u00adrithm leverages \nits dynamic dependence analysis and speci.ed non\u00addeterminism and focus variables to verify that these \ncon.icts in\u00advolve reads and writes irrelevant to the .nal program result. In this way, our algorithm \neliminates all false warnings for benchmarks montecarlo, stack, queue, and meshrefine. For benchmarks \nsunflow and xalan, our checking algorithm eliminates 25 and 4 false warnings, respectively, produced \nby strict con.ict-serializability checking, but generates 3 of the same false warnings for sunflow and \n2 for xalan. We discuss in greater detail below these false warnings that our analysis was and was not \nable to eliminate.  Note that previous work on atomicity checking, such as [16], typically evaluate \non such benchmarks by checking whether or not each individual method is atomic. Thus, a single cycle \nof con.icting reads and writes may lead to multiple warnings, as every method containing the cycle is \nreported to be non-atomic. (Conversely, multiple cycles may be reported as a single warning if they all \noccur inside a single method.) Our numbers of reported violations are not directly comparable, as we \nare interested only in whether each execution of an entire parallel construct is serializable and thus \nequivalent to an execution of its sequential counterpart. montecarlo Benchmark. Each parallel loop iteration \nof the montecarlo benchmark contains several con.icting reads and writes on shared static .elds. (The \nreads and writes occur inside the constructor of a temporary object created in each iteration.) To a \nna\u00a8ive, traditional con.ict-serializability analysis, these reads and writes make it appear that no equivalent \nserial execution ex\u00adists. However, it turns out that the values written to and read from these static \n.elds are never used they affect neither the control .ow nor the .nal program result. Thus, our analysis \ndetermines that these events are irrelevant and need not be considered during serializability checking. \nThe remaining, relevant events are serial\u00adizable, and thus our technique reports that the observed executions \nof montecarlo conform to its nondeterministic sequential speci.\u00adcation. stack, queue, and meshrefine \nBenchmarks. Benchmark meshrefine employs the Optimistic Concurrent Computation pat\u00adtern described in \nSection 4. Each parallel iteration reads from the shared triangular mesh that is being re.ned, and then \noptimistically computes a re-triangulation of a region of the mesh. It then atom\u00adically checks that no \ncon.icting modi.cations have been made to the mesh during its computation and either: (1) commits its \nchanges to the mesh if there are no con.icts, or (2) discards its optimistic computation and tries again. \nWhen con.icting modi.cations oc\u00adcur, an execution of meshrefine is clearly not strictly con.ict\u00adserializable. \nHowever, when we specify with an if(*) that the se\u00adquential execution is free to nondeterministically \ndiscard its opti\u00admistic computation and retry, even when there are no con.icts, our analysis can verify \nthat con.icts involving these shared reads and optimistic computation are not relevant when the optimistic \nwork is discarded. And the remaining relevant events are serializable, so our analysis reports no false \nwarnings in this case. The stack and queue benchmarks are also instances of the Op\u00adtimistic Concurrent \nComputation pattern, where shared reads are performed, but these reads are only relevant when a later \ncompare\u00adand-swap operation succeeds. Con.icts leading to failing CAS op\u00aderations in these benchmarks \nlead to false positives for a strict con.ict-serializability analysis, but our technique determines that \nthese con.icts are not relevant to the .nal program result. sunflow and xalan Benchmarks. Benchmarks \nsunflow and xalan cause false alarms due to the following lazy initialization pattern: 1: if ( true* \n&#38;&#38; flag == true) { 2: // skip initialization 3: } else { 4: atomic { 5: if (flag == false) { \n6: initialize shared object 7: flag = true; }}} In the above pattern, each thread checks if some shared \nobject has been initialized and, if not, initializes the object itself. The flag variable, which is initially \nfalse, indicates whether the object has been initialized. This pattern has two potential sources of false \nalarms: 1. One thread may read that flag is false at Line 1, and then another thread may initialize the \nobject and set flag to true, so that the .rst thread then reads that flag is true at Line 5. This is \na violation of con.ict-serializability. This is an instance of the Redundant Computation Optimization \nPattern described in Section 4, as a thread can always choose to skip the check at Line 1, since flag \nwill be checked again at Line 5. By annotating the .rst check with true* &#38;&#38;, our analysis ignores \nirrelevant con.icts involving threads reading that flag is false at Line 1 and eliminates this kind of \nfalse warning. 2. When one thread initializes the shared object and sets flag to true, and then other \nthreads read both flag and the shared object, our analysis sees con.ict edges from the initializing thread \nto the other threads. These can lead to con.ict cycles if the initializing thread later performs any \nrelevant reads of data written by other threads. Our technique will report these cycles as violations. \n But such reports are false warnings, because it does not matter which thread performs this kind of \nlazy initialization, and it is possible to serialize such executions despite outgoing con.icts from the \ninitialization code. Future work is needed to handle this pattern in our NDSeq speci.cations and dynamic \nchecking.  6.5 Caveats While we could easily write the speci.cations for our benchmarks, NDSeq speci.cations \nmust be used with care. First, one must be careful to not introduce so much nondeterminism that the result\u00ading \nNDSeq program exhibits undesired behavior. A catalog of speci.cation patterns, along the lines of those \npresented in Sec\u00adtion 4 can guide programmers to use this technique without break\u00ading functional correctness. \nSecond, we note that when introduc\u00ading if(true*) one can easily introduce nontermination (as shown in \nseveral examples in this paper). This is safe as long as we consider only the partial correctness properties \nof the NDSeq speci.cation. Our runtime algorithm reduces the number of false positives compared to a \nstandard notion of con.ict serializability. However, it can still give false positives for the following \nreasons: We do not apply semantic-level analyses, such as commutativ\u00adity analysis [33]. However, there \nare parallel patterns that rely on commutativity, in which it is necessary to ignore low-level con.icts \nthat are part of larger, commutative operations (such as reductions). Two commutative updates on a focus \nvariable (e.g., addition) can have con.icts yet still be serializable when the updates are considered \nat a semantic level. We are exploring ways to address this limitation.  We only search for NDSeq executions \nfor which the control\u00ad.ow path outside if(true*) branches is the same as in the parallel execution. Thus, \nwe might miss an equivalent NDSeq path, and falsely report lack of con.ict-serializability. One can eliminate \nthis source of imprecision by exploring executions of the program with different control .ows.  tsp \nBenchmark. For reasons stemming from the limitations given above, we have not found an easy way to write \nand check the NDSeq speci.cation for the tsp [46] benchmark. Figure 7(a) gives the original form of the \nmain search routine. Each thread is implemented as a loop (Lines 2 10): At each iteration it obtains \na work w from the shared queue Q (Line 4), searches the region repre\u00adsented by w (Line 6) and updates \nthe shared variable MinTourLen  1: cobegin <1,...,N> { cowhile (!isEmpty(Q)) {2: while (!isEmpty(Q)) \n{ 1: 3: atomic { 2: atomic { 4: w = get_work(Q); 3: w = get_work(Q); 5:} 4:} 6: s = recursive_solve(w); \n5: s = recursive_solve(w); 7: atomic { 6: atomic { 8: if (s < MinTourLen) 7: if (s < MinTourLen) 9: MinTourLen \n= s; 8: MinTourLen = s; 10:}}} 9:}}} (a) Original search routine (b) Rewritten form of the search Figure \n7. TSP benchmark. (Lines 8 9). In order to show that each thread as implemented in Figure 7(a) is serializable, \none needs to prove that executions of get work are commutative. This requires a nontrivial reasoning \nbecause procedure get work may split the work items in Q and submit new work items to Q, which creates \na dependency from a thread processing a work item created by a call to get work by another thread. We \nfound that Figure 7(a) has the equivalent func\u00adtionality to the rewritten form of the search in Figure \n7(b), where each thread performs only one iteration of the while loop. In this case, one can show that \neach iteration at Lines 2 9 in Figure 7(b) is serializable, as procedure recursive solve is a thread-local \noperation and the (atomic) update of MinTourLen at Lines 7 8 is commutative. 7. Related Work Several \ngeneric parallel correctness criteria have been studied for shared memory parallel programs that separates \nthe concerns about functionality and parallelism at different granularities of execution. These criteria \ninclude data-race freedom [27, 46], atomicity [14], linearizability [19]. All these criteria provides \nthe separation be\u00adtween parallel and functional correctness partially, as the restric\u00adtion on thread \ninterleavings is limited, for example, to atomic block boundaries. NDSeq develops this idea up to a complete \nseparation between parallelism and functionality so that the programmer can reason about the intended \nfunctionality by examining a sequential or nearly sequential program. NDSeq speci.cation differs from \nde\u00adterminism speci.cation and checking [5, 8, 34] in that NDSeq not only allows to specify that some \npart of the .nal state is indepen\u00addent of the thread schedule, but also allows to specify that the part \nof the .nal state that depends on thread schedule is equivalent to the state arising due to nondeterministic \nchoices in the NDSeq. We formulate the checking of parallelism correctness to a gen\u00aderal notion of atomicity. \nVarious static [10, 14, 40, 41] and dy\u00adnamic [7, 12, 16, 25, 44, 48, 49] techniques for checking atom\u00adicity \nand linearizability has been investigated in the literature. The main challenge in these techniques is \nto reason about con.icting accesses that are simultaneously enabled but ineffective on the rest of the \nexecution. In the Purity work [15] Flanagan et al. provide a static analysis to rule out spurious warnings \ndue to such con.icts by abstracting these operations to no-op s. Elmas et al. general\u00adize this idea in \na static proof system called QED [11]. They pro\u00adgressively transform a parallel program to an equivalent \nsequential program with respect to functional speci.cations expressed using assertions. They abstract \nreads and writes of shared variables; how\u00adever, they need to consider functional speci.cation when applying \nthe abstractions to guarantee that the abstraction does not introduce functional bug in the new program. \nIn addition, both Purity and QED are based on Lipton s reduction theory [24], whereas we ap\u00adply the idea \nto relax the checking of con.ict serializability [2] for nondeterministic speci.cations. Atomic-set serializability \n[43] is an weaker notion of atomicity, which groups storage locations into atomic sets and requires, \nfor each atomic set, all atomic blocks are con.ict-serializable with respect to the locations in the \nset. Dynamic techniques for detecting violations of atomic-set serializability has been proposed [17, \n23]. Recently, several platforms and languages have been developed to guarantee that parallel programs \ngive deterministic results, i.e. there is no bug due to parallelization. Kendo [28] enforces a de\u00adterministic \ninterleaving of parallel tasks by controlling synchro\u00adnization operations (particularly locks) in the \nmeantime targeting to achieve a load-balancing of parallel tasks close to the nonde\u00adterministic case. \nIn Deterministic Parallel Java (DPJ) [5] Bocchino et al. allow programmers to write parallel programs \nthat are deter\u00administic by design (ensured at compile time). DPJ also allows pro\u00adgrammers to explicitly \nmark parallel constructs with nondetermin\u00adistic sequential semantics and compose them safely with other \nde\u00adterministic constructs without breaking the determinism-by-default guarantees [6]. On the other hand \nthe Galois project [21], Praun et al. [47], and Prabhu et al. [30] aim to exploit the opportuni\u00adties \nin parallelizing irregular, inherently sequential programs. The sequential model ensured by these systems \nallows nondeterminis\u00adtic ordering of parallel loops and pipelines. Praun et al. [47] pro\u00adpose the programming \nmodel IPOT that allows programmers to ex\u00adplicitly mark portions of the program for speculative multithreaded \nand transactional execution. Its tryasync construct resembles our cobegin construct. IPOT allows internal \nnondeterminism in that intermediate states may differ from the corresponding sequential execution, but \nguarantees external determinism where the .nal state only depends on the inputs, not the thread interleavings. \nTheir run\u00adtime technique aims to preserve, rather than checking, sequential semantics. Prabhu et al. \n[30] propose speculative composition and iteration as programming constructs to parallelize parts of \nthe pro\u00adgram with explicit dependencies. They guarantee the obedience to sequential semantics by running \na sequential version of the pro\u00adgram that veri.es the speculated values of each parallel part. Saltz \net al. [35], and Rauchwerger et al. [32] present runtime checks for parallelizing executions of loops. \nTheir runtime techniques com\u00adplement static transformations by tracking at runtime data depen\u00addencies \nacross parallel loop iterations similarly to our runtime al\u00adgorithm does to identify true con.icts between \nthreads. 8. Conclusion We proposed the use of nondeterministic sequential speci.cations to separate functional \ncorrectness from parallelism correctness of parallel programs. Our proposal has several advantages. First, \nNDSeq speci.cations are lightweight. Unlike tradi\u00adtional mechanisms for functional speci.cation, e.g., \ninvariants and pre/post-conditions, NDSeq speci.cations do not require one to learn a complex logic or \nlanguage. The original parallel program along with a few if(true*) serves as the speci.cation and can \nbe used alone to detect various parallelism-related bugs. Second, once we verify parallelism correctness, \nproving the functional partial correctness of the parallel program amounts to checking the functional \ncorrectness of the NDSeq program. Threads being absent, this can be done using well-developed tech\u00adniques \nfor verifying sequential programs. Note that veri.cation of sequential programs (even with nondeterminism) \nis much sim\u00adpler than veri.cation of parallel programs. For example, model checking of Boolean multithreaded \nprograms is undecidable [31], whereas model checking of Boolean nondeterministic sequential programs \nis decidable [13]. The latter fact has been exploited by several well-known model checkers for nondeterministic \nsequen\u00adtial programs [1, 3]. Similarly, NDSeq speci.cations also simplify the reasoning about other concurrency-related \nproperties such as determinism and linearizability.  Third, NDSeq speci.cations can simplify debugging \nof func\u00adtional correctness bugs. When investigating a parallel execution that exhibits a bug, the programmer \ncan be presented with the equivalent, hence similarly buggy, NDSeq execution. This allows the programmer \nto analyze the bug by examining a sequential be\u00adhavior of the program, which is much easier to debug \nthan its par\u00adallel counterpart. We proposed a runtime checking algorithm for parallelism cor\u00adrectness. \nOur algorithm is based on a combination of simple dy\u00adnamic data.ow analysis and con.ict serializability \nchecking. The NDSeq speci.cation is the key factor that improves the precision of con.ict serializability \nby indicating the con.icts that can be safely be ignored by the analysis. We believe that a similar veri.cation \ncan be done statically; such an extension remains a future work. A key aspect of our checking algorithm \n(unlike static proof systems [11] and type systems [14]) is that it does not need to refer to functional \ninvariants which often complicates the veri.cation process. Acknowledgments We would like to Nicholas \nJalbert, Pallavi Joshi, and our anony\u00admous reviewers for their valuable comments on this paper. This \nresearch supported in part by Microsoft (Award #024263) and In\u00adtel (Award #024894) funding and by matching \nfunding by U.C. Discovery (Award #DIG07-10227), by NSF Grants CNS-0720906, CCF-101781, CCF-0747390, CCF-1018729, \nand CCF-1018730, and by a DoD NDSEG Graduate Fellowship. The last author is supported in part by a Sloan \nFoundation Fellowship. Additional support comes from Oracle (formerly Sun Microsystems), from a gift \nfrom Intel, and from Par Lab af.liates National Instruments, NEC, Nokia, NVIDIA, and Samsung. References \n[1] T. Ball, A. Podelski, and S. K. Rajamani. Boolean and cartesian abstraction for model checking C \nprograms. In Tools and Algorithms for the Construction and Analysis of Systems (TACAS), pages 268 283, \n2001. [2] P. A. Bernstein, V. Hadzilacos, and N. Goodman. Concurrency Con\u00adtrol and Recovery in Database \nSystems. Addison-Wesley, 1987. [3] D. Beyer, T. A. Henzinger, R. Jhala, and R. Majumdar. The software \nmodel checker Blast: Applications to software engineering. Int. J. Softw. Tools Technol. Transf., 9:505 \n525, October 2007. [4] S. M. Blackburn, R. Garner, C. Hoffmann, A. M. Khang, K. S. McKin\u00adley, R. Bentzur, \nA. Diwan, D. Feinberg, D. Frampton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss, \nA. Phansalkar, D. Stefanovi\u00b4 c, T. VanDrunen, D. von Dincklage, and B. Wiedermann. The DaCapo benchmarks: \nJava benchmarking development and anal\u00adysis. In Object-oriented Programming Systems, Languages, and Ap\u00adplications \n(OOPSLA), pages 169 190, 2006. [5] R. L. Bocchino, Jr., V. S. Adve, D. Dig, S. V. Adve, S. Heumann, R. \nKomuravelli, J. Overbey, P. Simmons, H. Sung, and M. Vakilian. A type and effect system for Deterministic \nParallel Java. In Object-Oriented Programming, Systems, Languages, and Applications (OOP-SLA), pages \n97 116, 2009. [6] R. L. Bocchino, Jr., S. Heumann, N. Honarmand, S. V. Adve, V. S. Adve, A. Welc, and \nT. Shpeisman. Safe nondeterminism in a deterministic-by-default parallel language. In Principles of Program\u00adming \nLanguages (POPL), pages 535 548, 2011. [7] S. Burckhardt, C. Dern, M. Musuvathi, and R. Tan. Line-up: \nA com\u00adplete and automatic linearizability checker. In Programming Lan\u00adguage Design and Implementation \n(PLDI), pages 330 340, 2010. [8] J. Burnim and K. Sen. Asserting and checking determinism for multithreaded \nprograms. In Foundations of Software Engineering (FSE), 2009. [9] J. Burnim, G. Necula, and K. Sen. Separating \nfunctional and parallel correctness using nondeterministic sequential speci.cations. In Hot Topics in \nParallelism (HOTPAR), 2010. Position paper. [10] R. Colvin, L. Groves, V. Luchangco, and M. Moir. Formal \nveri.cation of a lazy concurrent list-based set algorithm. In Computer Aided Veri.cation (CAV), 2006. \n[11] T. Elmas, S. Qadeer, and S. Tasiran. A calculus of atomic actions. In Principles of Programming \nLanguages (POPL), pages 2 15, 2009. [12] A. Farzan and P. Madhusudan. Monitoring atomicity in concurrent \nprograms. In Computer Aided Veri.cation (CAV), pages 52 65, 2008. [13] A. Finkel, B. Willems, and P. \nWolper. A direct symbolic approach to model checking pushdown systems. In Workshop on Veri.cation of \nIn.nite State Systems (INFINITY), 1997. [14] C. Flanagan and S. Qadeer. A type and effect system for \natomicity. In Programming Language Design and Implementation (PLDI), 2003. [15] C. Flanagan, S. N. Freund, \nand S. Qadeer. Exploiting purity for atom\u00adicity. In International Symposium on Software Testing and Analysis \n(ISSTA), pages 221 231, 2004. [16] C. Flanagan, S. N. Freund, and J. Yi. Velodrome: A sound and complete \ndynamic atomicity checker for multithreaded programs. In Programming Language Design and Implementation \n(PLDI), pages 293 303, 2008. [17] C. Hammer, J. Dolby, M. Vaziri, and F. Tip. Dynamic detection of atomic-set-serializability \nviolations. In International Conference on Software Engineering (ICSE), pages 231 240, 2008. [18] M. \nHerlihy and N. Shavit. The Art of Multiprocessor Programming. Morgan Kaufmann, March 2008. [19] M. P. \nHerlihy and J. M. Wing. Linearizability: A correctness condition for concurrent objects. ACM Trans. Prog. \nLang. Syst., 12:463 492, July 1990. [20] A. Kaminsky. Parallel Java: A Uni.ed API for Shared Memory and \nCluster Parallel Programming in 100% Java. In Parallel and Distributed Processing Symposium (IPDPS), \nMarch 2007. [21] M. Kulkarni, K. Pingali, B. Walter, G. Ramanarayanan, K. Bala, and L. P. Chew. Optimistic \nparallelism requires abstractions. In Program\u00adming Language Design and Implementation (PLDI), 2007. [22] \nM. Kulkarni, M. Burtscher, C. Cascaval, and K. Pingali. Lonestar: A suite of parallel irregular programs. \nIn International Symposium on Performance Analysis of Systems and Software, (ISPASS), April 2009. [23] \nZ. Lai, S. C. Cheung, and W. K. Chan. Detecting atomic-set serial\u00adizability violations in multithreaded \nprograms through active random\u00adized testing. In International Conference on Software Engineering (ICSE), \npages 235 244, 2010. [24] R. J. Lipton. Reduction: A method of proving properties of parallel programs. \nCommunications of the ACM, 18(12):717 721, 1975. [25] S. Lu, J. Tucek, F. Qin, and Y. Zhou. AVIO: Detecting \natomicity violations via access interleaving invariants. In Architectural Support for Programming Languages \nand Operating Systems (ASPLOS), 2006. [26] M. M. Michael and M. L. Scott. Simple, fast, and practical \nnon\u00adblocking and blocking concurrent queue algorithms. In Principles of Distributed Computing (PDOC), \n1996. [27] R. H. B. Netzer and B. P. Miller. What are race conditions?: Some issues and formalizations. \nACM Lett. Prog. Lang. Syst., 1(1):74 88, 1992. [28] M. Olszewski, J. Ansel, and S. Amarasinghe. Kendo: \nEf.cient deter\u00administic multithreading in software. In Architectural Support for Pro\u00adgramming Languages \nand Operating Systems (ASPLOS), pages 97 108, 2009. [29] C. Papadimitriou. The theory of database concurrency \ncontrol. Com\u00adputer Science Press, Inc., 1986. [30] P. Prabhu, G. Ramalingam, and K. Vaswani. Safe programmable \nspec\u00adulative parallelism. In Programming Language Design and Implemen\u00adtation (PLDI), pages 50 61, 2010. \n[31] G. Ramalingam. Context-sensitive synchronization-sensitive analysis is undecidable. ACM Trans. Prog. \nLang. Syst., 22(2):416 430, 2000.  class Stack : class Node {int value; Node next;} Node TOP; int TOP_version; \nvoid push(int x) { Node local_top, new_top; int local_version; boolean done = false; new_top = new Node(); \nnew_top.value = x; while (!done) { atomic { local_top = TOP; local_version = TOP_version; } new_top.next \n= local_top; if ( true* ){ if (CAS2(TOP, TOP_version, local_top, local_version, new_top, local_version+1)) \ndone = true; }}} int pop() { Node local_top, new_top; int local_version; boolean done = false; int value \n= EMPTY; while (!done) { atomic { local_top = TOP; local_version = TOP_version; } if ( true* ){ if (local_top \n== null) { done = true; } else { new_top = local_top.next; if (CAS2(TOP, TOP_version, local_top, local_version, \nnew_top, local_version+1)) { done = true; value = local_top.value; }}}} return value; } void harness() \n{ Stack stack = new Stack(); coforeach (i = 1 .. 30) { // make a call to stack if(randomBoolean()) { \nstack.push(randomInt()); } else { int t = stack.pop(); mark_focus(t) ; }} // traverse the stack and mark \n// the final contents relevant mark_focus(stack.TOP) ; Node node = stack.TOP; while(node != null) { mark_focus(node.next) \n; mark_focus(node.value) ; node = node.next; }} Figure 8. A non-blocking stack implementation with its \nnondeterministic sequential speci.cation embedded. [32] L. Rauchwerger and D. Padua. The lrpd test: speculative \nrun-time par\u00adallelization of loops with privatization and reduction parallelization. In Programming Language \nDesign and Implementation (PLDI), pages 218 232, 1995. [33] M. C. Rinard and P. C. Diniz. Commutativity \nanalysis: A new analysis framework for parallelizing compilers. In Programming Language Design and Implementation \n(PLDI), pages 54 67, 1996. [34] C. Sadowski, S. Freund, and C. Flanagan. SingleTrack: A Dynamic Determinism \nChecker for Multithreaded Programs. In European Sym\u00adposium on Programming (ESOP), 2009. [35] J. Saltz, \nR. Mirchandaney, and K. Crowley. Run-time parallelization and scheduling of loops. Computers, IEEE Transactions \non, 40(5):603 612, 1991. [36] K. Sen. Race directed random testing of concurrent programs. In ACM SIGPLAN \nConference on Programming Language Design and Implementation (PLDI 08), 2008. [37] N. Shavit and D. Touitou. \nSoftware transactional memory. In Princi\u00adples of Distributed Computing (PODC), pages 204 213, 1995. [38] \nL. A. Smith, J. M. Bull, and J. Obdrz\u00b4alek. A parallel Java Grande benchmark suite. In Supercomputing \n(SC), 2001. [39] R. K. Treiber. Systems programming: Coping with parallelism. Tech\u00adnical Report RJ 5118, \nIBM Almaden Research Center, Apr. 1986. [40] V. Vafeiadis. Shape-value abstraction for verifying linearizability. \nIn Veri.cation, Model Checking, and Abstract Interpretation (VMCAI), pages 335 348, 2009. [41] V. Vafeiadis, \nM. Herlihy, T. Hoare, and M. Shapiro. Proving correct\u00adness of highly-concurrent linearisable objects. \nIn Principles and Prac\u00adtice of Parallel Programming (PPOPP), 2006. [42] R. Vall\u00b4ee-Rai, P. Co, E. Gagnon, \nL. Hendren, P. Lam, and V. Sundare\u00adsan. Soot -a Java bytecode optimization framework. In Centre for Advanced \nStudies on Collaborative Research (CASCON), pages 125 135, 1999. [43] M. Vaziri, F. Tip, and J. Dolby. \nAssociating synchronization con\u00adstraints with data in an object-oriented language. In Principles of Pro\u00adgramming \nLanguages (POPL), pages 334 345, 2006. [44] M. Vechev, E. Yahav, and G. Yorsh. Experience with model \nchecking linearizability. In SPIN Workshop on Model Checking Software, pages 261 278, 2009. [45] M. Vechev, \nE. Yahav, R. Raman, and V. Sarkar. Verifying determinism of structured parallel programs. In Static Analysis \nSymposium (SAS), 2010. [46] C. von Praun and T. R. Gross. Object race detection. In Object Oriented Programming, \nSystems, Languages, and Applications (OOP-SLA), pages 70 82, 2001. [47] C. von Praun, L. Ceze, and C. \nCas\u00b8caval. Implicit parallelism with ordered transactions. In Principles and Practice of Parallel Program\u00adming \n(PPoPP), pages 79 89, 2007. [48] L. Wang and S. D. Stoller. Runtime analysis of atomicity for multi\u00adthreaded \nprograms. IEEE Trans. Softw. Eng., 32:93 110, 2006. [49] J. M. Wing and C. Gong. Testing and verifying \nconcurrent objects. J. Parallel Distrib. Comput., 17(1-2):164 182, 1993. A. NDSeq Speci.cation Examples \n   A.1 Non-blocking Concurrent Reduction Consider the simple parallel program in Figure 9. The program \nconsists of a parallel for-loop, denoted coforeach each iteration of this loop attempts to perform a \ncomputation (Line 6) based on the shared variable x, which is initially 0. In particular, each iteration \nuses an atomic compare-and-swap (CAS) operation to update the shared variable x. If multiple iterations \ntry to concurrently update x, some of these CAS s will fail and those parallel loop iterations will recompute \ntheir updates to x and then will try again. The NDSeq speci.cation of the program, which is embedded \nin the parallel program in Figure 9, indicates two nondeterministic aspects. First, the box around the \ncoforeach construct in Line 1 speci.es that the loop iterations can run in any permutation of the set \n1,...,N. This part of the speci.cation captures the intended nondeterministic behavior of the parallel \nprogram: x can be updated by threads in an arbitrary order due to nondeterministic scheduling of threads. \nSecond, the if(true*) annotation in Line 4 speci.es that 1: coforeach (i in 1,...,N) { 2: bool done = \nfalse; 3: while (!done) { 4: if ( true* ){ 5: int prev = x; 6: int curr = i*prev + i; 7: boolc= CAS(x,prev,curr); \n8: if(c){ 9: done = true; 10: } 11:}} } 12: mark_focus(x) ; Figure 9. Simple parallel program to perform \nthe reduction in Line 6 for the integers {1,. . . ,N}, in some arbitrary order.  the iteration body \nmay be skipped nondeterministically, at least from a partial correctness point of view; this is acceptable, \nsince the while loop in this program fragment is already prepared to deal with the case when the effects \nof an iteration are ignored following a failed CAS statement. The mark focus annotation in Line 12 indicates \nthat x is the only focus variable. That is, the functional correctness of the program depends only on \nthe .nal value of x after all the threads created by coforeach terminate.  A.2 Non-blocking Concurrent \nStack In Figure 8, we give the Java-like code for the NDSeq speci.cation of our non-blocking stack benchmark. \nThe stack is represented as a null-terminating, singly-linked list of Node objects. The head of the list \nis pointed by the TOP .eld of the stack. In order avoid the ABA problem, we use a version number (TOP \nversion), which is increased whenever TOP is updated. The push and pop methods implement the Optimistic \nConcur\u00adrent Computation pattern in Section 4 using a loop that iterates until the operation succeeds. \nEach method .rst reads the TOP of the stack without any synchronization and then uses an atomic CAS2 \n(dou\u00adble compare-and-swap) operation to check for con.icts by compar\u00ading TOP and TOP version with local \ntop and local version. If TOP=local top and TOP version=local version then CAS2 commits the operation \nby writing new top to TOP and increment\u00ading TOP version and returns true. Otherwise, CAS2 returns false \nand the operation retries. In the speci.cation, an if(true*) statement is placed around the critical \nCAS2 in push, and around the check whether or not local top is null in pop. These if(true*) s indicate \nthat the sequential version of the program is free to nondeterministically retry as if there had been \na con.ict. This added nondeterminism enables our dynamic analysis to mark as irrelevant the reads of \nTOP and TOP version by loop iterations in which the CAS2 fails. The harness method creates a number of \nthreads, each of which calls push with a random input or calls pop. In the code, we mark the focus variables \nusing mark focus . The focus variables are: (1) the values popped by the harness threads (marked after \neach call to pop), and (2) the last contents of the stack (marked at the end of the harness).  \n\t\t\t", "proc_id": "1993498", "abstract": "<p>We propose to specify the correctness of a program's parallelism using a sequential version of the program with controlled nondeterminism. Such a <i>nondeterministic sequential specification</i> allows (1) the correctness of parallel interference to be verified independently of the program's functional correctness, and (2) the functional correctness of a program to be understood and verified on a sequential version of the program, one with controlled nondeterminism but no interleaving of parallel threads.</p> <p>We identify a number of common patterns for writing nondeterministic sequential specifications. We apply these patterns to specify the parallelism correctness for a variety of parallel Java benchmarks, even in cases when the functional correctness is far too complex to feasibly specify.</p> <p>We describe a sound runtime checking technique to validate that an execution of a parallel program conforms to its nondeterministic sequential specification. The technique uses a novel form of conflict-serializability checking to identify, for a given interleaved execution of a parallel program, an equivalent nondeterministic sequential execution. Our experiments show a significant reduction in the number of false positives versus traditional conflict-serializability in checking for parallelization bugs.</p>", "authors": [{"name": "Jacob Burnim", "author_profile_id": "81442603382", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P2690602", "email_address": "jburnim@cs.berkeley.edu", "orcid_id": ""}, {"name": "Tayfun Elmas", "author_profile_id": "81100211898", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P2690603", "email_address": "elmas@cs.berkeley.edu", "orcid_id": ""}, {"name": "George Necula", "author_profile_id": "81100295630", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P2690604", "email_address": "necula@cs.berkeley.edu", "orcid_id": ""}, {"name": "Koushik Sen", "author_profile_id": "81100399070", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P2690605", "email_address": "ksen@cs.berkeley.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993545", "year": "2011", "article_id": "1993545", "conference": "PLDI", "title": "NDSeq: runtime checking for nondeterministic sequential specifications of parallel correctness", "url": "http://dl.acm.org/citation.cfm?id=1993545"}