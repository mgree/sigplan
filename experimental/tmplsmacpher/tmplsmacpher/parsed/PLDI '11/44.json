{"article_publication_date": "06-04-2011", "fulltext": "\n Mining Hot Calling Contexts in Small Space Daniele Cono D Elia Camil Demetrescu Irene Finocchi Dept. \nofComputer and System Sciences Dept. of Computer and System Sciences Dept. of Computer Science Sapienza \nUniversityof Rome Sapienza UniversityofRome Sapienza UniversityofRome danielecono.delia@gmail.com demetres@dis.uniroma1.it \n.nocchi@di.uniroma1.it Abstract Calling context trees(CCTs) associateperformance metrics with paths \nthrough a program s call graph, providing valuable infor\u00admation for program understanding and performance \nanalysis. Al\u00adthoughCCTs are typically much smaller than call trees,in real ap\u00adplications they might easily \nconsist of tens of millions of distinct calling contexts:this sheer size makesthemdif.cultto analyze \nand mighthurt execution times due topoor access locality.Forperfor\u00admance analysis, accurately collectinginformation \nabouthot calling contexts may be more useful than constructing an entire CCT that includesmillionsof \nuninterestingpaths.As we showfor a variety ofprominentLinux applications, thedistribution of calling \ncontext frequenciesis typicallyvery skewed.In thispaper we showhow to exploit thisproperty to reduce \ntheCCT size considerably. Weintroduce a novelrun-timedata structure, called HotCalling Context Tree(HCCT), \nthat offers an additional intermediate point in the spectrum of data structures for representing interprocedural \ncontrol .ow.TheHCCTisasubtreeof theCCT thatincludesonly hotnodes and their ancestors.We showhow to computetheHCCT \nwithout storingthe exactfrequency of all calling contexts,by using fastand space-ef.cient algorithmsforminingfrequentitemsindata \nstreams. With this approach, we can distinguish between hot and cold contexts on the .y, while obtaining \nvery accurate frequency counts. We show both theoretically and experimentally that the HCCT achieves \na similar precision as the CCT in a much smaller space, roughlyproportional to the number ofdistincthot \ncontexts: this is typically several orders of magnitude smaller than the total number of calling contexts \nencountered during a program s exe\u00adcution. Our space-ef.cient approach can be effectively combined with \nprevious context-sensitive pro.ling techniques, such as sam\u00adplingandbursting. Categories and Subject \nDescriptors C.4 [Performance of Sys\u00adtems]: Measurement Techniques; D.2.2 [Software Engineering]: ToolsandTechniques \nprogrammerworkbench; D.2.5[Software Engineering]:TestingandDebugging diagnostics,tracing GeneralTerms \nAlgorithms,Measurement,Performance. Keywords Performance pro.ling, dynamic program analysis, data streaming \nalgorithms, frequent items, program instrumenta\u00adtion. Permission to make digital or hard copies of all \nor part of this work for personal or classroom useisgranted without feeprovided that copies are not made \nordistributed forpro.tor commercial advantage andthat copiesbearthis notice and thefull citation onthe \n.rstpage.Tocopy otherwise,torepublish,topost onserversortoredistribute tolists, requiresprior speci.cpermission \nand/or afee. PLDI 11, June4 8,2011,SanJose,California,USA. Copyright c &#38;#169; 2011ACM978-1-4503-0663-8/11/06. \n. .$10.00 1. Introduction Context sensitive pro.ling provides valuable information for pro\u00adgram understanding,performance \nanalysis,and runtimeoptimiza\u00adtions.Previous workshavedemonstratedits effectivenessfor tasks such as residual \ntesting[30,35],functioninlining[12], statistical bugisolation[15,23], object allocation analysis[29], \nor anomaly\u00adbased intrusion detection[11]. A calling context is a sequence of routine calls that are concurrently \nactive on the run-time stack and that lead to a program location. Collecting context information in modern \nobject-oriented software is very challenging: application functionalities are divided into a large number \nof small routines, and the high frequency of function calls and returns might result in considerable \npro.ling overhead, Heisenberg effects, and huge amounts of contexts tobe analyzedby theprogrammer. Several \ndata structures have long been used to maintain infor\u00admation about interprocedural control .ow. In a \ncall graph, nodes represent routines and arcs caller-callee relationships. The use of callgraphpro.leswaspionereedbygprof[17],that \nattributesthe timefor each routinetoits callersbypropagatingtimes along edges of the call graph.Although \nvery space-and time-ef.cient, this ap\u00adproachcanleadto misleading results, aspointed outin[31,34].On the \nother side, each node of a call tree represents a different rou\u00adtine invocation. This yields very accurate \ncontext information, but requires extremely large(possibly unbounded) space.Theinaccu\u00adracy of call graphs \nand the huge size of call trees have motivated theintroduction of calling context trees(CCT) [2]:differentlyfrom \ncalltrees,CCTsdo notdistinguishbetweendifferentinvocations of thesameroutinewithinthesamecontext. Whilemaintaininggood \naccuracy, typically CCTs are several orders of magnitude smaller than call trees: the number of nodes \nmay be large in the presence of recursion,but thisis seldom the caseinpractice.The exhaustive approach \nto constructing a CCT is based on the instrumentation of each routine call and return, incurring considerable \nslowdown even using ef.cientinstrumentationmechanisms[2,37].Sampled stack-walking reduces slowdown,but \nat theprice of accuracy.The adaptivebursting mechanismproposedin[37] selectively inhibits redundant pro.ling, \ndramatically reducing the overhead over the exhaustive approach whilepreservinggoodpro.le accuracy. As \nnoticedinprevious works[11,37],even calling contexttrees may be very large and dif.cult to analyze in \nseveral applications. Moreover, their sheer size might hurt execution time due to poor access locality \nduring construction and query. As an example, in Table 1 we report the number of nodes of the call graph, \ncall tree, and calling context tree for a variety of off-the-shelf applications in a typicalLinuxdistribution.These \nnumbers havebeen obtained from shortruns of each application, whichyield millions of calling contexts. \nThe optimistic assumption that each CCT node requires 20bytes(previous works uselarger nodes[2,34])already \nresultsin almost1GB neededjustto storeaCCT with48 million nodesfor an applicationsuch asOpenOf.ce calc.Tofacethisspaceissue,the \nTable 1. Number of nodes of call graph, call tree, calling context tree, and number ofdistinct call sitesfordifferent \napplications.  Application |Callgraph| Callsites |CCT||Call tree| amarok 13754 113362 13794470 991112563 \nark 9933 76547 8171612 216881324 audacity 6895 79656 13131115 924534168 blue.sh 5211 64239 7274132 248162281 \ndolphin 10744 84152 11667974 390134028 .refox 6756 145883 30294063 625133218 gedit 5063 57774 4183946 \n407906721 ghex2 3816 39714 1868555 80988952 gimp 5146 93372 26107261 805947134 gwenview 11436 86609 9987922 \n494753038 inkscape 6454 89590 13896175 675915815 oocalc 30807 394913 48310585 551472065 ooimpress 16980 \n256848 43068214 730115446 oowriter 17012 253713 41395182 563763684 pidgin 7195 80028 10743073 404787763 \nquanta 13263 113850 27426654 602409403 sudoku 5340 49885 2794177 325944813 vlc 5692 47481 3295907 125436877 \napproachproposedin[11] maintains a one-wordprobabilistically unique valueper context, achieving minimal \nspace overhead when all contextshave to be stored, but speci.c information about them is unnecessary. \nAs notedin[11], even this approach,however, can run out of memory onlargetraces withtens of millions \nof contexts. Although very useful, e.g., in bug or intrusion detection appli\u00adcations, probabilistic calling \ncontext was not designed for pro.l\u00ading with the purpose of understanding and improving application performance, \nwhere it is crucial to maintain for each context the sequence of active routine calls along with performance \nmetrics. In this scenario, only the most frequent contexts are of interest, since they represent the \nhot spots to which optimizations must be directed.Asobservedin[37]: Accurately collectinginformation \nabout hot edges may be more useful than accurately constructing an entire CCT that includes rarely called \npaths. Figure 1 shows that,fordifferent applications, only a smallfraction of contexts are hot:in accordance \nwiththe well-knownParetoprinciple,morethan 90%of routine calls takeplacein only10% of contexts.The skew\u00adness \nof context distribution suggests that space could be greatly reduced by keeping information about hot \ncontexts only and dis\u00adcarding on the .y contexts that are likely to be cold, i.e., to have lowfrequencyor \nto require small timethroughoutthe entire execu\u00adtion. Our Contributions. In this paper we introduce a \nnovel run-time data structure, called Hot CallingContext Tree(HCCT), that com\u00adpactly represents all the \nhot calling contexts encountered during a program s execution, offering an additional intermediate point \nin the spectrum of data structures for representing interprocedural control .ow.TheHCCTisasubtreeof theCCT \nthatincludesonly hot nodes and their ancestors. For each hot calling context, it also maintains an estimate \nofitsperformance metrics(for simplicity, we focus onfrequency countsthroughoutthepaper,butourapproach \ncan be easily extended to arbitrary metrics such as execution time, cache misses, or instruction stalls). \nOur main contributions can be summarized asfollows: We formalize the concept of Hot Calling Context Tree \nand we cast the problem of identifying the most frequent contexts into a data streaming setting: we show \nthat the HCCT can be computed without storing the exact frequency of all calling contexts,byusingfast \nand space-ef.cient algorithmsformining frequent items in data streams. With this approach, we can Cumulative \nfrequencies % of the total number of calls(degree of overlap with full CCT) 100 80 60 40 20 0  amarok \naudacity firefox gedit oocalc pidgin quanta vlc 0 10 20 30 40 50 60 70 80 90 100 % of hottest calling \ncontexts   Figure 1. Skewness of calling contextsdistribution on a represen\u00adtative subset ofbenchmarks. \ndistinguish between hot and cold contexts on the .y, while obtaining very accuratefrequency counts. \nWeimplementthreevariantsofspace-ef.cient context-sensitive pro.lersbasedon threedifferent streaming algorithms.For \none of the algorithms, we devise a highly tuned implementation that is more ef.cient in practice than \nthe one proposed by the authors and that mightbe ofindependentinterest.  We integrate our space-ef.cient \napproach with previous tech\u00adniques aimed at reducing time overhead: wefocusinparticular onstaticburstingand \nadaptiveburstingwithre-enablement[37], which offer verygood time-accuracy tradeoffs.  We perform an \nextensive experimental analysis of perfor\u00admances and accuracy on a variety of prominent Linux appli\u00adcations.We \ntest manydifferentparameter settings and consider several metrics,includingdegree of overlap andhot edge \ncover\u00adage usedinprevious works.The experiments not only con.rm, butreinforcethetheoreticalprediction, \nshowingthattheHCCT representsthehotportions ofthefullCCT very well using only an extremely smallpercentage \nof the space requiredby the en\u00adtire CCT. Even when the peak memory usage of our pro.lers is only1%of \nstandard context-sensitivepro.lers, we can show thefollowing:  allthehottestcallingcontextsare alwaysidenti.edcorrectly \n(nofalse negatives); frequency counters are very close to the true values; the number offalsepositives(cold \ncontexts that are consid\u00adered ashot)is very small; usingbursting,the runningtime overhead canbekept under \ncontrol without affecting accuracyin a substantial way. The rest of thispaper is organized as follows. \nSection 2givespre\u00adliminaryde.nitionsaboutcalling contexts anddatastream algorith\u00admics. Section 3 introduces \nthe HCCT and describes our approach. Section4 focuses onimplementation and engineering aspects, and Section5presentstheoutcome \nofourexperimentalstudy.Relations with related work arediscussedinSection6. 2. Background 2.1 Calling \nContext Tree Thedynamic callingcontext of a routineinvocationisthe sequence of un-returned callsfromtheprogram \ns rootfunctiontothe routine invocation. The calling context tree (CCT) compactly represents all calling \ncontexts encounteredduringthe execution of aprogram. CCT nodes correspond to routines and apathfrom a \nnode v to the tree root represents the calling context of v. A routine with multi\u00adple contexts willappear \nmore than oncein aCCT,but each calling contextis representedjust once and metricsforidentical contexts \nare aggregated,tradingprecisionfor space.Slightly extendeddef\u00adinitions can be given to bound the depth \nof a CCT in thepresence of recursion and todistinguish calls that takeplace atdifferent call sites of \nthe same callingprocedure[2].  A CCT can be constructed on-the-.y during the execution of a program.Letv \nbe a cursorpointerthatpointstothe currentroutine context,i.e., to the CCT node corresponding to the calling \ncontext of the currently active routine (v is initialized to the CCT root node). At each routine invocation, \nthe algorithm checks whether v has a child associated with the called routine. If this is the case, the \nexisting child is used and its metrics are updated, if necessary. Otherwise, a new child of v is added \nto the CCT. In both cases, the cursor is moved to the callee. Upon routine termination, the cursoris \nmovedback to theparent nodein theCCT.This approach can beimplemented eitherbyinstrumenting every routine \ncall and return orbyperforming stack-walkingif samplingis usedtoinhibit redundantpro.ling[5,36,37]. \n 2.2 Frequent Items in Data Streams In recent years there has been much interest in the design of al\u00adgorithms \nable to perform near-real time analyses on massive data streams, where input data come at a very high \nrate and cannot be stored entirelydue totheirhuge,possibly unbounded size[14,28]. This line of research \nhas been mainly motivated by networking and database applications: for instance, a relevant IP traf.c \nanal\u00adysis task consists of monitoring the packet log over a given link in order to estimate how many \ndistinct IP addresses used that link in a given period of time. Since the stream may be very long and \nstreamitems may alsobedrawnfrom a verylarge universe(e.g., theset of source-destinationIP addresspairs),space-ef.cientdata \nstreaming algorithms can maintain a compactdata structure thatis dynamically updated upon arrival of \nnew input data, supporting a variety of application-dependentqueries.Approximate answers are allowed \nwhenitisimpossibleto obtain an exact solution using only limitedspace.Streaming algorithms are thereforedesigned \nto opti\u00admize four mainperformance measures: space required to store the data structure, updatetime(i.e.,per-itemprocessing \ntime),query time, andguaranteed solutionquality. The frequent items (a.k.a. heavy hitters)problem has \nbeen ex\u00adtensively studiedindata streaming computational models.Given a frequency threshold f . [0,1]and \na stream oflenght N, theprob\u00adlem(initssimplestformulation) isto .nd allitemsthatappearin thestream atleast.fN. \ntimes,i.e.,havingfrequency=.fN..For instance,forf =0.1theproblems seeks allitemsthatappearinthe stream \nat least 10% of the times. At most 1/fitems can have fre\u00adquency larger than .fN.. It can beproved that \nany algorithm that outputs an exact solution requires O(N)bits, even using random\u00adization[28].Hence, \nresearchfocused on solving an approximate version of theproblem: DEFINITION 1. (f,e)-heavyhittersproblem. \nGiven twoparame\u00adters f,e . [0,1], with e<f, return all items with frequency =.fN. and noitem withfrequency \n=.(f- e)N.. Inthe approximate solution,false negatives cannotexist,i.e., all frequentitems mustbe returned.Instead, \nsomegoodfalsepositives are allowed,buttheiractualfrequencyisguaranteed tobeatmost eN-far from the threshold \n.fN.. Variations of the problem arise when,besides returningtheheavyhitters,itis necessaryto estimate \n1 100 40 50 10  (a) (b) (c) Figure 2. (a) CCT;(b) HCCT; and(c) (f,e)-HCCT. Hot nodes are darker. The \nnumber close to each node is the frequency count of the corresponding calling context. In this example \nN = 581, f =1/10, and e =1/30: the approximate HCCT includes all contexts with frequency =.fN. = 58 and \nno context with frequency=.(f- e)N. =38. accurately their true frequencies, when the stream length N \nis not knownin advance, and when theitems aregiven weights. Many different algorithms for computing (f,e)-heavy \nhitters have been proposed in the literature in the last ten years. In this paper we focus on counter-based \nalgorithms that, according to ex\u00adtensiveexperimental studies[13],havesuperiorperformancewith respect \nto space, running time, and accuracy. Counter-based algo\u00adrithms track a subset of items from the input \nand monitor counts associated with them. For each new arrival, the algorithms decide whetherto storetheitem \nor not, and,if so, what countsto associate withit.There are three main embodiments of this approach: \nSpace Saving, StickySampling,and LossyCounting.StickySampling[25] isprobabilistic:itfailstoproducethe \ncorrectanswer with a minus\u00adcole probability, say d, and uses at most 2 e log(f-1 d-1 ) entries initsdata \nstructure.SpaceSaving[27] andLossyCounting[25] are deterministic and use 1 e and e 1 log(eN) entries, \nrespectively. The theoretical results are even better when stream items have a skeweddistribution(e.g.,Zip.an).In \nageneral-purposeimplemen\u00adtation of counter-based algorithms, the update times aredominated bya small(constant) \nnumber ofdictionary orheap operations. 3. HCCT: Hot Calling Context Tree The execution trace of routineinvocations \nand terminations canbe naturally regarded as a stream of items. Each item is a triple con\u00adtaining routine \nname, call site, and eventtype.As showninTable1, the number ofdistinct routines(i.e.,the number of nodes \nofthe call graph)is smallcomparedtothe streamlength(i.e.,tothenumber of nodes of the call tree), evenfor \ncomplex applications.Hence, non\u00adcontextualpro.lers such asvertexpro.lers canmaintainahash table of size \nproportional to the number of routines, using routine names as hash keys in order to update the corresponding \nmetrics. This may be dif.cult in the case of contextual pro.ling, when the number ofdistinct calling \ncontexts(i.e.,the number ofCCT nodes) is toolarge andhashingwouldbeinef.cient.Motivatedby thefact that \nexecutiontraces aretypically verylong andtheiritems(calling contexts) are taken from a large universe, \nwe cast the problem of identifyingthe mostfrequentcontextsinto adata streaming setting. 3.1 Approach \nLet N be the number of calling contexts encountered during a program s execution: N equals the number \nof nodes of the call tree, the sum of the frequency counts of CCT nodes, as well as the number routine \ninvocations in the execution trace. Given a frequency threshold f . [0,1], we will regard a calling context \nas hotifthefrequency count of the correspondingCCT nodeislarger than .fN.. All the other contexts are \nconsidered cold. We de.ne Figure 3. Tree data structures and calling contexts classi.cation. We use graphical \nnotation S . T to indicate that T is the minimal subtree of theCCT spanning all nodesinS.  the HotCallingContextTree(HCCT)asthe(unique) \nsubtree ofthe CCTobtainedbypruning all cold nodes that are not ancestors of a hotnode.Ingraphtheory,theHCCT \ncorrespondstotheSteinertree of the CCT with hot nodes used as terminals, i.e., to the minimal connected \nsubtreeof theCCT spanninghotnodes.Anexample of HCCTisgiveninFigure2(b).Itis worthnoticingthat allhot \nnodes areincludedin theHCCT and that allitsleaves are necessarilyhot (the converse,however,is not true). \nThe HCCT is the most compact data structure representing information about hot calling contexts. The \nspace lower bound for the heavy hitters problem (see Section 2.2) extends to the problem ofcomputingtheHCCT, \nthat cannotbe calculated exactly in small space(inparticular, using a space asymptotically smaller than \nthe entire CCT). Hence, we relax the problem and compute an Approximate Hot Calling Context Tree, which \nwe denote by (f,e)-HCCT, where e<f controls the degree of approximation. The (f,e)-HCCT contains allhot \nnodes(truepositives),but may possibly contain some cold nodes withouthotdescendants(false positives). \nThe true frequency of these false positives, however, is guaranteed to be at least .(f- e)N.. Similarly \nto the HCCT, the (f,e)-HCCT can be thought of as a minimal subtree of the CCT spanning a set of (f,e)-heavy \nhitters.Differentlyfrom theHCCT, a (f,e)-HCCTisnot uniquelyde.ned, sincethe set of (f,e)-heavy hitters \nis not unique: in particular, nodes with frequencies smaller than .fN. and larger than .(f- e)N. may \nbe either included in such a set or not. The Venn diagram in Figure 3 summarizes some important relations: \n H. A, where H is the set of hot contexts and A is a set of (f,e)-heavyhitters.NodesinA \\ H arefalsepositives. \n H. HCCT. Nodes in HCCT\\ H are cold nodes that have a descendantinH.  A.(f,e)-HCCT. Nodes in (f,e)-HCCT \n\\ A are cold nodes thathave adescendantinA.  HCCT.(f,e)-HCCT, as implied by the previous inclusions. \nBothof them are connected subtrees of thefullCCT.  Figure 3 also introduces two additional sets: the \nset M of moni\u00adtored nodes and the subtree MCCT spanning all nodes in M. To compute the set A of (f,e)-heavy \nhitters, we use as subroutines counter-based streaming algorithms that monitor a slightly larger setM \n. A. Whenauserquery asksforthemostfrequent contexts, these algorithms prune M and return A. In addition \nto M, our al\u00adgorithm maintains the subtreeMCCTof theCCT consisting of the nodesin M and of all their \nancestors.Atquery time, the MCCTis appropriatelypruned and the (f,e)-HCCT . MCCTis returned. Discussion \nand Example. To understand why the heavy hitters andthe approximateHCCT are not maintaineddirectly,butderived \nprune(x,MCCT): 1. V . update(x,M) 2. for each context v . V \\{x} 3. while (v is aleafinMCCT. v . M)do \n 4. remove v fromMCCT 5. v . parent(v)  Figure 4. On-linepruningalgorithm. by pruning M and MCCT, respectively, \nconsider the following example: the execution trace contains the initial invocation of the main function, \nwhich in turn invokes once a routine p and N - 2 times adifferentroutine q.Assumethat N = 8, e =1/4, \nf =1/2, and that the counter-based streaming subroutine can maintain at least three counters. Then only \nnode q has frequency larger than .(f - e)N. andis a (f,e)-heavy hitter, but the algorithm will maintain \nin M both p and q together with their exact frequencies. Sincephasfrequency1,itwouldbe an error returningit \nas aheavy hitter. For this reason, M needs to be post-processed in order to eliminatelow-frequencyitemsthat \nmaybeincluded whenthere are more available countersthanheavyhitters.Details on updating and queryingMandMCCT \naregiveninSection3.2.  3.2 Data Structures Update and Query At each function call, the set M of monitored \ncontexts is updated by acounter-basedstreaming algorithm(seeSection2.2). When M is changed, the subtree \nMCCT spanning nodes in M needs to be brought up to date as well. To describe how this happens, we assume \nthat the interface of the streaming algorithm provides two mainfunctions: update(x,M). V:given a calling \ncontext x, update M to re.ect the new occurrence of x inthe stream(e.g.,if x was already monitoredinM,itsfrequency \ncount maybeincreasedby one). The update function might return a set V of victim contexts that werepreviously \nmonitoredinM and are evictedduringthe update(as a special case, x itselfmaybe considered as a victim \nif the algorithmdecides not to monitorit). query(M). A: remove low-frequency items from M and return \nthe subsetA of (f,e)-heavyhitters(seeFigure3). Details ontheimplementation ofupdate and query dependonthe \nspeci.c streaming algorithm. Similarly to the CCT, during the construction of the MCCT we maintain a \ncursor pointer that points to the current calling context, creating a new nodeifthe current context x \nis encountered for the .rst time (see Section 2.1). Additionally, we prune the MCCT according to the \nvictim contexts returnedby the streaming update operation(these contexts are nolonger monitoredinM). \nThe pseudocode of the pruning algorithm is given in Figure 4. Sincethetree mustremain connected, victims \ncanbe removedfrom the MCCT only if they are leaves. Moreover, removing a victim might exposeapath of \nunmonitored ancestorsthatnolongerhave descendants in M: these nodes are pruned as well. The current context \nx is never removed from the MCCT, even if it is not necessarily monitored in M. This guarantees that \nno node in the path from the tree root to x will be removed: these nodes have at least x as adescendant \nandtheleaftest(line3inFigure4) will alwaysfail. A similar pruning strategy can be used to compute the \n(f,e)-HCCT from the MCCT. The streaming query operation is .rst invoked on M, returning the support A \nof the (f,e)-HCCT. All MCCT nodes that have no descendant in A are then removed, followingbottom uppathtraversals \nasin theprune operation.  3.3 Discussion Compared to the standard approach of maintainingthe entireCCT, \nour solution requiresto storetheheavyhittersdata structureM and the subtree MCCT spanning nodes in M. \nThe space required by M depends on the speci.c streaming algorithm that is used as a subroutine, and \nis roughlyproportional to 1/e(seeSection 2.2 for the exact bounds). This space can be customized by appropriately \nchoosing e, e.g., according to the amount of available memory.An appropriate choice of eappearstobe crucialforthe \neffectiveness of our approach: smaller values of e guarantee more accurate results (less falsepositives \nandmoreprecise counters),but imply a larger memory footprint. As we will see experimentally in Section \n5, thehigh skewness of contextfrequencydistributionguarantees the existence of very convenienttradeoffsbetween \naccuracy and space. The MCCT consists of nodes corresponding to contexts moni\u00adtored in M and of all their \nancestors, which may be cold contexts without a corresponding entry in M. Hence, the space required by \ntheMCCTdominatesthe space requiredbyM.The number of cold ancestors cannot be analyzed theoretically: \nit depends on proper\u00adties of the execution trace and on the structure of the calling con\u00adtext tree. In \nSection 5 we will show that in practice this amount is negligible with respect to the number of entriesinM. \nUpdates of the MCCT can be performed very quickly. As we will see in Section 4, the streaming update \noperation requires constant time. Moreover, our implementation hinges upon very simple and cache-ef.cient \ndata structures, with no need for time\u00adconsuming hashing. Simple amortized analysis arguments also show \nthat the amortized running time of treepruningis constant. Differently from previous approaches such \nas, e.g., adaptive bursting[37], theMCCT adapts automatically to the case where the hot calling contexts \nvary over time, and new calling patterns are not likely to be lost. Contexts that are growing more popular \nare added to the tree as theybecome morefrequent, while contexts that lose their popularity are gradually \nreplaced by hotter contexts and are .nallydiscarded.Thisguaranteesthatheavyhittersqueries canbeissued \nat anypointin time, and will alwaysbe able to return the set ofhot contexts up to that time. Our data-streaming \nbased approach is orthogonal to previ\u00adous techniques and can be integrated, e.g., with sampled stack\u00adwalking[5,36] \nor with more recenttechniques such as static and adaptivebursting[37].In additiontofrequency counts,it \ncanbe extended to support arbitrary performance metrics, exploiting the ability of some streaming algorithms \nto compute the heavy hitters in weighteditem sets. 4. Implementation and Engineering We implemented in \nC three variants of the HCCT construction al\u00adgorithm described in Section 3, based on three different \nstream\u00ading algorithms for the computation of frequent items: Space Sav\u00ading[27],StickySampling[25], andLossyCounting[25].In \nour experiments, Sticky Sampling consistently proved itself to be less ef.cient and accuratethanits competitors, \nso we will not mentionit anyfurther.All ourimplementations(includingthe construction of the entireCCT) \nare castin a commonframeworkin whichdifferent streaming algorithms canbepluggedin. Weusea .rst-child,next-siblingrepresentationforcalling \ncon\u00adtext trees. Each MCCT node also contains a pointer to its parent, theroutineID,thecall site,and theperformancemetrics.The \n.rst\u00adchild, next-sibling representation is very space-ef.cient and still guarantees that the children \nof each node can be explored in time proportional to their number. According to our experiments with \nseveral benchmarks, the average number of scanned children is a small constant around 2-3, so this representation \nturns out to be convenient alsofor checking whether a routineID already appears among the children of \na node. The parent .eld, which is needed toperformtreepruning ef.ciently(seeFigure4),is not required \nin CCT nodes. As routineID, we use the routine address. Overall, CCTandMCCT nodes require20 and24bytes, \nrespectively, on32 bit architectures. Using the bit stealing technique, we also encode in one of the \npointer .elds a Boolean .ag that tells if the calling context associated withthe nodeis monitoredinthe \nstreamingdata structureM, withoutincreasing the number ofbytesper node. Toimprovetimeandspace ef.ciency, \nweallocatenodesthrough a custom, page-based allocator, which maintains blocks of .xed size. Any additional \nalgorithm-speci.c information needed to maintain the heavy hitters is stored as trailing .elds within \nfat MCCTnodes. We now describe our implementation of the streaming algo\u00adrithms,focusing onSpaceSaving(SS) \nandLossyCounting(LC). 4.1 Space Saving Space Saving [27] monitors a set of 1/e = |M| pairs of the form \n(item,count), initialized by the .rst 1/edistinct items and their exact counts. After the init phase, \nwhen a calling context c is observed in the stream the update operation(see Section 3.2) works asfollows: \n1. if c is monitored, the correspondingcounterisincremented; 2. if c is not monitored, the (item,count)pair \nwith the smallest countis chosen as a victim andhasitsitem replaced with c and its count incremented. \nHeavy hitters queries are answered by returning entriesin M such that count =.fN..  The update time \nis bounded by the dictionary operation of check\u00ading whether anitemis monitored, andby thepriorityqueue \noper\u00adations of .nding and maintaining the item with minimum count. In our setting, we can avoidthedictionary \noperation using the cur\u00adsor pointer to the MCCT: using this pointer, we can directly ac\u00adcess the monitored \n.ag of the MCCT node associated with the current context. The priority queue must support two operations, \nfind-min and increment, which return the item with minimum count andincrement a counter, respectively.In[27],itis \nsuggested to use an orderedbucketlist,where eachbucketpointsto alistof items(MCCTnodes) with the same \ncount, andbuckets are ordered byincreasing count values. In addition to theimplementation realizedby \ntheSpaceSaving authors[27], wedevised a more ef.cient variantbased on alazy priorityqueue. We will refer \nto ourimplementation as Lazy Space Saving(LSS).Weusean unorderedarrayMofsize1/e, where each array entrypoints \nto anMCCT node.We also(lazily) maintain the value min ofthe minimum counter andthe smallestindex min-idx \nof an array entry that points to a monitored node with counter equal to min. The increment operationdoes \nnot change M, since counters are storeddirectlyinsideMCCT nodes.However, min and min-idx maybecometemporarily \nout ofdate after an increment: this is why we call the approach lazy. The find-min operation described \nin Figure 5 restores the invariant property on min and min-idx: it .nds the next index in M with counter \nequal to min. If such anindexdoes not exist,it completely rescansMin order to .nd a new min value andits \ncorresponding min-idx. LEMMA 1. After a find-min query, the lazy priority queue cor\u00adrectly returns the \nminimum counter valueinO(1) amortized time. PROOF. Counters are never decremented. Hence, at any time, \nif a monitoreditem with counter equalto min exists,it mustbefoundin apositionlarger than or equal to \nmin-idx.Thisyields correctness. To analyze the running time, let . be the value of min after k find-min \nand increment operations. Since there are |M| coun\u00adters = ., counters areinitialized to 0, and each increment \noper\u00adation adds1 to the value of a single counter,it mustbe k =|M|..  find-min(): 1. while (M[min-idx] \n= min . min-idx = M)do 2. min-idx . min-idx +1 3. if (min-idx >M)then 4. min . minimumin M 5. min-idx \n. smallestindex jsuch that M[j]= min 6. return min  Figure 5. find-min operation usedinLazySpaceSaving. \nFor eachdistinctvalue assumedby min, the arrayis scanned twice. We therefore have at most 2. array scans \neach of length |M|, and the total cost of find-min operations throughout the whole sequence of operationsis \nupperboundedby 2|M|..Itfollowsthat the amortized costis (2|M|.)/k= 2. 0  4.2 Lossy Counting Lossy Counting \n[25] maintains a set M of triples of the form (item, count, .), where count represents the exact frequency \nof the item since it was last inserted in M and . is the maximum possible underestimation ofcount: the \nalgorithmguarantees that at any time the true frequency of a monitored item is = count+.. The incoming \nstream is conceptually divided into bursts of width .1/e..Duringburst i,if anitem x arrives that already \nexistsinM, the corresponding countisincremented.Otherwise: if x corresponds to a node v with count c \nthatis an ancestor of another node in M, we increment c by 1, leave . untouched, and then add (x,c, .) \ntoM; otherwise, we add (x, 1,i - 1)toM. We slightly modi.ed the insertion algorithm of [25] to achieve \nbetter precision by exploiting the advantages of the MCCT data structure. At the end of burst i, M ispruned \nby deleting entries such that (count+.) = i: the set V of victims returned by the update operation (see \nSection 3.2) is therefore always empty, except at burst boundaries. Heavy hitters queries are answered \nby returning entries in M such that count +. =.fN.; again, we modi.ed the original algorithm to reduce \n sometimes considerably the number offalsepositives returnedin the answer. Since triples are dynamically \nadded to and deleted from M, it is convenient to maintain M using an unordered linked list. For the sake \nof ef.ciency, in our implementation we superimpose M on the MCCT by allocating fat MCCT nodes containing \n. and the pointer to the next element of M in addition to the standard .elds. Hence, Lossy Counting uses \n28 bytes per node. Checking whether an item is monitored can be done quickly as described in Section \n4.1. Every .1/e. operations M is scanned and removed items are marked unmonitored and pruned from the \nMCCT as describedinFigure4. 5. Experimental Evaluation In this section, we present an extensive experimental \nstudy of our data-streaming based pro.ling mechanism. We implemented sev\u00aderal variants of space-ef.cient \ncontext-sensitive pro.lers and we analyzed their performances and the accuracy of the produced (f,e)-HCCT \nwith respect to several metrics and using many dif\u00adferent parameter settings. Our test suite includes \npro.lers based on the threedifferent streaming algorithmsdiscussedinSection4: LazySpace Saving(LSS),BucketSpace \nSaving(BSS), andLossy Counting(LC).Besidestheexahustive approach, where each rou\u00adtine call and return \nis instrumented, we integrate our implementa\u00adtionswithprevioustechniquesaimedat reducingtimeoverhead:we \nfocusinparticular on staticbursting and adaptivebursting with re\u00adenablement[37], which offer very convenienttime-accuracy \ntrade\u00adoffs. The experimental analysis not only con.rms, but reinforces the theoreticalprediction: the \n(f,e)-HCCT represents thehotpor\u00adtions of thefullCCT very well using only an extremely smallper\u00adcentage \nofthe space requiredbythe entireCCT: allthehottest call\u00ading contexts are alwaysidenti.ed correctly, their \ncounters are very accurate, and the number of false positives is rather small. Using the bursting technique, \nthe running time overhead can be kept un\u00adder control without affecting accuracyin a substantial way.Before \ndiscussing the results, we present the details of our experimental methodology, focusing on benchmarks \nand accuracy metrics, and wedescribehowtheparameters ofthe streaming algorithms canbe tuned. 5.1 Methodology \nand Experimental Setup Benchmarks. Tests were performed on a variety of large-scale Linux applications,includinggraphicsprograms(inkscape \nand gimp),anhexadecimal .leviewer(ghex2), audio players/editors (amarok and audacity), an archiver (ark), \nan Internet browser (firefox), anHTMLeditor(quanta), a chatprogram(pidgin), the Open Of.ce suite for \nword processing (oowriter), spread\u00adsheets(oocalc), anddrawing(ooimpress).To ensuredeterminis\u00adtic replay \nof the execution of theinteractive applicationsin out test suite, we used thePINdynamicinstrumentationframework[24] \nto record timestamped execution traces for typical usage sessions. After the startup,in each session \nweinteractively used the applica\u00adtion for approximately ten up to twenty minutes: e.g., we created a \n420 \u00d7 300 pixel image with gimp applying a variety of graphic .lters and color effects, we reproduced \n.fty images in slideshow mode with gwenview, we played a ten minutes audio .le with amarok, and we wrote \natwopagesformattedtext,includingtables, with oowriter. Statistical information about test sets is shown \nin Table 1: even short sessions of a few minutes result in CCTs con\u00adsistingoftens of millionsof callingcontexts,whereasthe \ncallgraph has onlyafewthousands nodes.The number ofdistinct call sitesis roughly one order of magnitudelarger \nthan the callgraph. Metrics. We test the accuracy of the (f,e)-HCCT produced by ourpro.lers according \nto a variety of metrics: 1.Degree of overlap,consideredin[4,5,37],is used to measure the completeness \nof the (f,e)-HCCT with respect to the full CCTandde.ned asfollows: X 1 overlap((f,e)-HCCT,CCT)= w(e) \nN arcs e.(f,e)-HCCT where N isthetotalnumber of routine activations(correspond\u00ading to the CCT total weight) \nand w(e)is the true frequency of the target node of arc e in theCCT. 2. Hotedge coverage,introducedin[37], \nmeasuresthepercentage of hot edges of the CCT that are covered by the (f,e)-HCCT, using an edge-weightthreshold \nt . [0,1]todeterminehotness. Since(f,e)-HCCT.CCT,hotedge coverage canbede.ned as follows: |{e . (f,e)-HCCT: \nw(e) = tH}| cover((f,e)-HCCT,CCT,t)= |{e . CCT:w(e) = tH}| where H is the weight of thehottestCCT arc. \n3. Maximum frequency of uncovered calling contexts, where a contextis uncoveredifis notincludedin the \n(f,e)-HCCT: w(e) maxUncov((f,e)-HCCT,CCT) = max \u00d7100 e.CCT\\(f,e)-HCCT H1 Averagefrequencyof uncovered \ncontextsisde.ned similarly.  Table 2. Typical thresholds Largest value of f that guarantees a given \ndegree of overlap HCCTnodes HCCTnodes HCCTnodes 1 amarok audacity Benchmark f = 10-3 f = 10-5 f = 10-7 \n0.1 bluefish audacity 112 9181 233362 firefox gedit dolphin 97 14563 978544 0.01 gwenview gimp 96 15330 \n963708 oocalc 0.001 pidgin inkscape 80 16713 830191 quanta oocalc 136 13414 1339752 vlc 0.0001 Max f \nquanta 94 13881 812098 1e-05 1e-06 4. Number of false positives, i.e., |A\\ H|: the smaller this num\u00adber, \nthe better the (f,e)-HCCT approximates the exact HCCT obtainedfromCCTpruning. 5. Counter accuracy, i.e., \nmaximum error in the frequency coun\u00adters of (f,e)-HCCT nodes with respecttotheirtrue valueinthe fullCCT: \n |w(e) -we(e)| maxError((f,e)-HCCT) = max \u00d7 100 e.(f,e)-HCCT w(e) where w(e)and we(e)are the true and \nthe estimatedfrequency of context e, respectively. Average counter error is de.ned similarly. An accurate \nsolution should maximize degree of overlap and hot 1e-07 1e-08 1e-09 10 20 30 40 50 60 70 80 90 100 Degree \nof overlap (%) Figure 6. Relation between f and degree of overlap between the exactHCCT and thefullCCT \non a representative subset ofbench\u00admarks. Avg/max frequency of contexts not included in (f,e)-HCCT Uncovered \nfrequency (% of the hottest context) 100 LSS avg LSS max 10  edge coverage, and minimize the remaining \nmetrics. Platform. Our experiments were performed on a 2.53GHz Intel Core2DuoT9400with128KB ofL1data \ncache,6MB ofL2 cache, and 4 GB of main memory DDR3 1066, running Ubuntu 8.04, LinuxKernel2.6.24,32bit. \n 5.2 Parameter Tuning Before describing our experimental .ndings, we discuss how to choose parameters \nf and e to be provided as input to the stream\u00ad ing algorithms. According to the theoretical analysis, \nan accurate choice of f and e mightgreatly affectthespace usedby thealgo\u00adrithms and the accuracy ofthe \nsolution.In our study we considered manydifferent choices of fand eacross ratherheterogeneous sets of \nbenchmarks and execution traces, always obtaining similar re\u00ad  1 0.1 0.01 0.001 0.0001 1e-05 sultsthat \nwe summarizebelow. Arule ofthumb about fand evalidatedbyprevious experimen\u00adtal studies[13] suggests thatitis \nsuf.cient to choose e = f/10 in order to obtain high counter accuracy and a small number of false positives. \nWe found this choice overlypessimistic in our scenario: theextremelyskewed cumulativedistributionof callingcontextfre\u00adquencies \nshown in Figure 1 makes it possible to use much larger values of e without sacri.cing accuracy. This \nyields substantial bene.tsonthespace usage, whichisroughlyproportional to 1/e. Unless otherwise stated,in \nall our experiments we used e = f/5. Let us now consider the choice of f: f is thehotness threshold with \nrespect to the stream length N, i.e., to the number of routine enter events. However, N is unknown a \npriori during pro.ling, and thus choosing f appropriately may appear to be dif.cult: too large values \nmight resultin returning veryfewhot calling contexts (even no context at all in some extreme cases), \nwhile too small values might resultin usingtoo much space and returningtoo many contexts without being \nable to discriminate accurately which of them are actuallyhot.Our experiments suggest that an appropriate \nchoice of fis mostlyindependentofthe speci.cbenchmark and of the stream length: as shown inTable 2, differentbenchmarkshave \nHCCT sizes of the same order of magnitude when using the same f threshold(resultsfor omittedbenchmarks \nare similar).Thisis a consequence of the skewness of context frequency distribution, andgreatly simpli.es \nthe choice of finpractice.Unless otherwise stated, in our experiments we used f = 10-4 , which corresponds \nto mining roughly thehottest1000 calling contexts. Benchmarks Figure 7. Maximum andaveragefrequency of \ncalling contexts not includedin the(f,e)-HCCTgeneratedbyLSS.ResultsforLC are almostidentical and are \nnot shownin the chart.  5.3 Accuracy: exact HCCT We .rst discuss the accuracy of the exact HCCT with \nrespect to the full CCT. Since the HCCT is a subtree of the (f,e)-HCCT computed by our algorithms, the \nresults described in this section apply to the (f,e)-HCCT, as well. In particular, the values of degree \nof overlap andhot edge coverage on theHCCT are alower bound to the corresponding values in the (f,e)-HCCT, \nwhile the frequencyof uncovered contextsis an upperbound. It is not dif.cult to see that the cumulative \ndistribution of call\u00ading context frequencies shown in Figure 1 corresponds exactly to the degree of overlap \nwith the full CCT. This distribution roughly satis.esthe 10%-90%rule:hence, with only 10%ofhot contexts, \nwe have a degree of overlap around 90% on all benchmarks. Fig\u00adure6illustratesthe relationshipbetweendegree \nof overlap andhot\u00ad ness threshold,plottingthe value feof thelargesthotness threshold for which a given \ndegree of overlap d can be achieved: using any f = fe, the achieved degree of overlap will be larger \nthan or equal to d.The value of fedecreases asdincreases:ifwe wantto achieve a larger degree of overlap, \nwe must include in the HCCT a larger number of nodes, which correspondsto choosing a smallerhotness nomenon: \ntheCCT contains ahuge number of calling contextsthat  Figure 10. False positives in the (f,e)-HCCT \nas a function of e on a representative subset of benchmarks. The value of f is .xed to 10-4 . of the \ntotal number of tree nodes in the worst case), and Lazy SpaceSavingconsistentlyprovedtobebetterthanLossyCounting. \nFigure 10 also shows that the number of false positives decreases considerably as we decrease e, getting \nvery close to 0% on most benchmarks when the ratiof/eislarger than10. A very interesting feature of our \napproach is that counter esti\u00admates are very close tothe truefrequencies, as showninFigure11. Lossy Counting \non average achieves almost exact counters for the hot contexts(0.057%averagedifferencefrom the truefrequency), \nand even the maximum errorin the worst case is smaller than 8%. Lazy Space Saving as described in this \npaper computes less ac\u00adcurate counters. The error, however, can be considerably reduced and made comparable \nto Lossy Countingby maintaining,for each monitored context,the maximumpossible overestimation resulting \nfrom the initialization of the counter when the context waslast in\u00adsertedin thedata structure[27].Due \nto thelack of space, wedefer thedetails of thisimprovement to thefull version of thispaper.  12 15 18 \nAvg/max error (%) Avg/max counter error among hot elements (% of the true frequency) LSS avg error LC \navg error LSS max error LC max error 9 6 3 0amarokark audacitybluefishd inkscapeoocalcooimpressoowriterpidginquantavlc \namarokark audacitybluefishdolphinfirefoxgeditghex2gimpsudokugwenviewinkscapeoocalcooimpressolphinfirefoxgeditghex2gimpsudokugwenview \noowriterpidginquantavlc Figure 11. Accuracy of contextfrequencies computedbyLSS andLC, measured onhot \ncontextsincludedin the (f,e)-HCCT.  Avg Max Benchmarks  Benchmarks  5.5 Performance To analyze time \nand space performances of our pro.lers we con\u00adsiderLSS,LC,BSS(omittedfromthepreviousdiscussions asit \ncomputes exactly the same (f,e)-HCCT as LSS), and the combi\u00adnation of these algorithms with static and \nadaptivebursting. Memory Usage. We .rst evaluate how much space can be saved by our approach. Figure \n12 plots the peak memory usage of our pro.lers as apercentage of thefullCCT.We recall thatduring the \ncomputation we storethe minimal subtreeMCCT oftheCCT span\u00adning all monitored contexts. This subtree is \neventually pruned to obtainthe (f,e)-HCCT(seeSection3.1).Thepeak memory usage is proportional to the \nnumber of MCCT nodes, which is typically much larger than the actual number of hot contexts obtained \nafter pruning.In spite ofthis,a considerable amount of spaceis savedby all algorithms.On manybenchmarks, \nourpro.lersuselessthan 1% of the space required by the full CCT, and even in the worst case the space \nusage is about 6.5%. Space Saving is always more ef.\u00adcient than Lossy Counting, and the lazy approach \nis preferable to thebucket-basedimplementation.It shouldbe noted,however, that the space usedinpracticebyLossyCountingis \nmuch smaller than the theoretical prediction. Quite surprisingly, static bursting also improves space \nusage(resultsfor adaptivebursting are similar and are not reported in the chart). This depends on the \nfact that sam\u00adpling reduces the variance of calling context frequencies: MCCT cold nodes that have a \nhot descendant are more likely to become hot when sampling is active, and monitoring these nodes reduces \nthe totalMCCT size.Thehistogram also shows that staticbursting alone(i.e., without streaming)is not suf.cient \nto reduce the space substantially: in addition to hot contexts, a large fraction of cold contextsisalsosampled \nandincludedintheCCT.Onthe oocalc benchmark, even adaptiveburstingwithout re-enablement requires 127 times \nmore space than LSS. We also observed that the larger theapplications,thelargerthespace reduction ofour \napproachover burstingalone. Since the average node degree is a small constant, cold HCCT nodesaretypicallyafractionofthetotalnumberofnodes,asshown \nin Figure 9 for f = 10-4 . In our experiments we observed that this fraction strongly depends on the \nhotness threshold f, and in particulardecreases with f: cold nodes that have ahot descendant areindeed \nmorelikely tobecomehot when fis smaller. TimeOverhead. We concludeby analyzing running times.Since our \napproachisindependent of any speci.cinstrumentation mech\u00adanisms, and different techniques for tracing \nroutine enter and exit events might incur rather different overheads in practice, we fo\u00adcus on the time \nrequired by the analysis routines only, omitting instrumentation times. Compared to the the standard \nconstruction of the CCT, streaming algorithms incur a small overhead, which can be considerably reduced \nby exploiting sampling and bursting techniques:inFigure13, weplot the speedup that canbe obtained by \ncombining our approach with static bursting and with adaptive bursting.We comparedtheperformance of six \nvariants(from slow\u00adest to fastest) for both LSS and LC: full (f,e)-HCCT construc\u00adtion(ontheentire routineenter/exitstream), \nstaticbursting,adap\u00adtivebursting with re-enable ratio equal to 20%, 10%, and 5%, and adaptivebursting \nwithout re-enablement(for adescription ofthe adaptivebursting technique, we refer theinterested reader \nto[37]). We also consideredburstingalone(both static and adaptive), while we omitted sample-driven stack \nwalking, whichhasbeen shown to belargelyinferiortoburstingwith respecttothe accuracy[37].The construction \noftheHCCTgreatlybene.tsfrombursting, achieving speedups upto 35\u00d7.LSSis alwaysfasterthanLC,butboth ofthem \nare slowerthanbursting without streaming:the speedupdifference, however,is moderate andforLSSis typicallysmaller \nthan2. AsshowninFigure14,the accuracyoftheHCCT(andinpartic\u00adularthehot edge coverage)is not affected substantiallybythe \ncom\u00adbination of streaming andbursting(exceptfor adaptive sampling without re-enablement). We take as \nan example the vlc bench\u00admark consideredinFigure13for t =0.025: theHCCT computed  Comparison of analysis \nrunning times using static and adaptive bursting Comparison of hot edge coverage results using static \nand adaptive bursting  No sampling Sampling interval = 2 msSampling interval = 10 ms Figure 13. Speedup \nanalysis relative to full CCT construction on the vlc benchmarkforLSS/LC, static and adaptivebursting[37], \nand LSS/LC combined with static and adaptive bursting: (1) no sampling(lefthistogram);(2) samplinginterval2 \nmsec andburst length0.2 msec(middlehistogram);(3) samplinginterval10 msec andburstlength0.2 msec(righthistogram).TheCCT \nconstruction baselineis about1.5secondsfor 2.5\u00b7 108 routine enter/exit events. withoutburstinghas coverage \n100%, whichis also achieved using static busting and adaptive bursting with re-enable ratio 20%. The \nhotedge coveragedecreases as samplingbecomes more aggressive, butin this experimentis alwayslarger than \n78%and 91%forLSS andLC, respectively. 6. Related Work This section describes research on context sensitive \npro.ling: it focuses on calling context trees and brie.y considers other forms of contextualpro.ling \natbothinter andintraprocedurallevel. Earlyapproaches. The utilityof calling contextinformation was already \nclear in the 80s:gprof[17] approximates context sensitive pro.les by associating procedure timing with \ncaller-callee pairs rather than with single procedures. This single level of context sensitivity, however, \nmay yield to several inaccuracies [31, 34]. Goldberg andHall[19] introduce callpathpro.les of monotonic \nprogram resources and show how they can be computed in Unix processes using interval-based sampling: \na call path is a sequence offunctionpairsina caller-calleerelationship,and thepro.leisa sortedlist of \ncallpaths and oftheirperformance metrics.The space usage with this approach can be prohibitive, since \nat each sample pointmetrics are recorded along with the entire call stack. Callingcontext trees. Callingcontexttreeshavebeenintroduced \nin[2] as apracticaldata structureto associateperformance metrics with paths through a program s call \ngraph: Ammons, Ball, and Larus suggest to build a CCT by instrumenting procedure code and to compute \nmetrics by exploiting hardware counters available in modern processors. It has been later observed, however, \nthat exhaustiveinstrumentation canlead tolarge slowdown. Time-ef.ciency vs.pro.le accuracy. To reduce \noverhead,Bernat and Miller [8] generate path pro.les including only methods of interest, while statisticalpro.lers[5,16,19,36] \nattribute metrics to calling contexts throughperiodic sampling of the call stack.For call-intensiveprograms,sample-drivenstack-walkingcanbeorders \nof magnitudefaster than exhaustiveinstrumentation,but mayincur signi.cant loss of accuracy with respect \nto the complete CCT: sampling guarantees neither high coverage [11] nor accuracy ofFigure 14. Hot edge \ncoverage analysis on the vlc benchmark for LSS/LC combined with static and adaptive bursting [37] for \nt =0.025, with f =4 \u00b7 10-5 , o = f/2, sampling interval 2 msec, andburstlength0.2 msec.Static and adaptivebursting \nalone always achieve100%hot edge coveragein this experiment and are not reported. performancemetrics[37],anditsresultsmaybehighlyinconsistent \nindifferent executions. A variety of works explores the combination of sampling with bursting[4,20,37].Mostrecently,Zhuang \net al. suggesttoperform stack-walking followed by a burst during which thepro.ler traces every routinecall \nand return[37]: experimentsshowthatadaptive bursting canyield very accurate results.In[33],thepro.lerinfre\u00adquentlycollectssmallcalltracesthataremerged \nafterwardstobuild large calling context trees: ambiguities might emerge during this process, and the \nlack of information about where thepartialCCTs shouldbe merged todoes not allowit to reconstructthe entireCCT \nunivocally. The main goal of all these works is to reduce pro.l\u00ading overhead without incurring signi.cant \nloss of accuracy. Our approach is orthogonal to this line of research and regards space ef.ciency as \nan additional resource optimization criterion besides pro.leaccuracyand timeef.ciency. Whenthepurposeofpro.ling \nis to identify hot contexts, exhaustive instrumentation, sampling, and bursting might all be combined \nwith our approach and bene.t of our space reduction technique. Reducing space. A few previous works have \naddressed tech\u00adniquesto reducepro.ledata(or atleast the amount ofdatapre\u00adsented to the user) in context \nsensitive pro.ling. Incremental call\u00adpath pro.ling lets the user choose a subset of routines to be an\u00adalyzed \n[8]. Call path re.nement helps users focus the attention onperformance bottlenecksby limiting and aggregating \nthe infor\u00admation revealed tothe user[18].These works arequitedifferent in spirit from our approach, where \nonly hot contexts are pro.led andidenti.ed automaticallyduringprogram s execution.Quite re\u00adcently,probabilisticcalling \ncontextshavebeenintroduced as an ex\u00adtremely compact representation(justa32-bitvaluepercontext), especially \nuseful for tasks such as residual testing, statistical bug isolation,and anomaly-basedintrusiondetection[11]. \nBond and McKinley target applications where coverage ofbothhot and cold contextsis necessary.Thisis not \nthe caseinperformance analysis, whereidentifying afewhot contextsis typically suf.cient toguide code \noptimization.Hence, although sharing with[11] the common goal of space reduction, our approach targets \na ratherdifferent ap\u00adplication context.  Pathpro.ling. At the intraprocedurallevel, the seminal work \nof Ball andLarus[6] hasspawned much research on .owsensitive pro.ling[1 3,7,9,10,21,22,35].Ball-Laruspathpro.lingcom\u00adputes \na unique number through each possible path in the control .ow graph [6]: a path pro.le determines how \nmany times each acyclicpathin a routine executes, extending the more commonba\u00adsic block and edge pro.ling. \nMelski and Reps have proposed in\u00adterprocedural path pro.ling in order to capture both inter-and in\u00adtraprocedural \ncontrol .ow[26].However,theirapproachdoesnot scale due to the large number of statically possible paths \nexisting acrossprocedureboundaries. 7. Conclusions Calling context trees offer a compact representation \nof all calling contexts encounteredduring aprogram s execution.Evenfor short runs of medium-sized applications, \nCCTs can be rather large and dif.cult to analyze. Motivated by the observation that only a very smallfraction \nof calling contexts arehot,inthispaper wehavepre\u00adsented a novel technique for improving the space ef.ciency \nof the full calling context tree without sacri.cing accuracy. By adapting modern data mining techniques, \nwe have devised an algorithmfor interproceduralcontextualpro.lingthat candiscard onthe .y cold contextsand \nappearstobeextremelypractical.Wehaveevaluated our approach on several large-scale Linux applications, \nshowing signi.cant space saving with respect to thefullCCT. Webelieve that a careful use of data mining \ntechniqueshas the potential bene.t of enabling some previously impossible dynamic program analysis tasks, \nwhich would otherwise be too costly. In particular, our techniques couldbe appliedto certainforms ofpath \npro.ling: e.g., they could help leverage the scalability problems encountered when collecting performance \nmetrics about interpro\u00adceduralpaths(i.e., acyclicpathsthat may crossprocedurebound\u00adaries) [26] or k-iteration \npaths (i.e., intraprocedural cyclic paths spanning up to k loop iterations) for large values of k [32]. \nWe plan toinvestigate these applicationsinfuture work. Acknowledgments We thank the anonymous reviewers \nfor their valuable comments. This workis supportedinpartbytheItalianMinistryforEducation, University,andResearch(MIUR)underthePRINnationalresearch \nproject AlgoDEEP:Algorithmicchallengesfordata-intensivepro\u00adcessing on emerging computingplatforms . References \n[1] G.Ammons andJ.R.Larus. Improving data-.ow analysiswithpath pro.les. SIGPLANNot.,39(4):568 582, 2004. \n[2] G. Ammons, T. Ball, and J. R. Larus. Exploiting hardware perfor\u00admance counters with .ow and context \nsensitive pro.ling. SIGPLAN Not.,32(5):85 96,1997. ISSN0362-1340. [3] T. Apiwattanapong and M. J. Harrold. \nSelective path pro.ling. In Proc. ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools \nand engineering,pages35 42.ACM,2002. [4] M. Arnold and B. Ryder. A framework for reducing the cost of \ninstrumented code. In PLDI,pages168 179. ACM,2001. [5] M.ArnoldandP.Sweeney.Approximating the calling \ncontexttreevia sampling. TechnicalReportRC21789,IBMResearch,2000. [6] T. Ball and J. R. Larus. Ef.cient \npath pro.ling. In MICRO 29: Proceedings of the 29th annual ACM/IEEE international symposium onMicroarchitecture,pages46 \n57,1996. [7] T.Ball,P.Mataga, andM.Sagiv.Edgepro.lingversuspathpro.ling: the showdown. In POPL,pages134 \n148.ACM,1998. [8] A.R.BernatandB.P.Miller.Incremental call-pathpro.ling.Techni\u00adcal report,University \nofWisconsin,2004. [9] M. D. Bond and K. S. McKinley. Continuous path and edge pro.l\u00ading. In Proc. 38th \nannual IEEE/ACM International Symposium on Microarchitecture,pages130 140. IEEEComputerSociety,2005. \n[10] M.D.Bond andK.S.McKinley.Practicalpathpro.lingfordynamic optimizers. In CGO,pages205 216. IEEEComputerSociety,2005. \n[11] M. D. Bond and K. S. McKinley. Probabilistic calling context. SIG-PLAN Not. (proceedings of the \n2007 OOPSLA conference), 42(10): 97 112,2007. [12] P.P.Chang,S.A.Mahlke,W.Y.Chen, andW.meiW.Hwu. Pro.le\u00adguided \nautomatic inline expansion for c programs. Softw., Pract. Exper.,22(5):349 369, 1992. [13] G. Cormode \nand M. Hadjieleftheriou. Finding frequent items in data streams. Proceedings of theVLDBEndowment,1(2):1530 \n1541, 2008. [14] C. Demetrescu and I. Finocchi. Algorithms for data streams. In HandbookofAppliedAlgorithms:SolvingScienti.c,Engineering, \nand PracticalProblems.JohnWiley andSons,2007. [15] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and \nW. Gong. Anomaly detection using call stack information. In Proc. 2003 IEEE Symposium on Security and \nPrivacy, SP 03, pages 62 . IEEE Com-puterSociety,2003. ISBN0-7695-1940-7. [16] N. Froyd, J. Mellor-Crummey, \nand R. Fowler. Low-overhead call path pro.ling of unmodi.ed, optimized code. In Proc. 19th Annual International \nConf. onSupercomputing,pages81 90.ACM,2005. [17] S.L.Graham,P.B.Kessler, andM.K.McKusick.gprof: a callgraph \nexecutionpro.ler(with retrospective).InK.S.McKinley, editor, Best ofPLDI,pages49 57.ACM,1982. ISBN1-58113-623-4. \n[18] R.J.Hall. Callpath re.nementpro.les. IEEE Trans.Softw. Eng., 21 (6):481 496,1995. [19] R. J. Hall \nand A. J. Goldberg. Call path pro.ling of monotonic pro\u00adgram resources in UNIX. In Proc. Summer 1993 \nUSENIX Technical Conference,pages1 19.USENIXAssociation,1993. [20] M. Hirzel and T. Chilimbi. Bursty \ntracing: A framework for low-overhead temporal pro.ling. In Proc. 4th ACM Workshop on Feedback-Directed \nandDynamicOptimization,2001. [21] R. Joshi, M. D. Bond, and C. Zilles. Targeted path pro.ling: Lower \noverhead path pro.ling for staged dynamic optimization systems. In CGO,page239.IEEEComputerSociety,2004. \n[22] J. R. Larus. Whole program paths. SIGPLAN Not., 34(5):259 269, 1999. [23] B.Liblit,A.Aiken,A.X.Zheng, \nandM.I.Jordan. Bugisolationvia remoteprogram sampling. In PLDI,pages141 154.ACM,2003. [24] C.-K.Luk,R.Cohn,R.Muth,H.Patil,A.Klauser,G.Lowney,S.Wal\u00adlace, \nV. J. Reddi, and K. Hazelwood. Pin: building customized pro\u00adgram analysis tools with dynamic instrumentation. \nIn PLDI, pages 190 200,2005. [25] G. S. Manku and R. Motwani. Approximate frequency counts over data \nstreams. In VLDB,pages346 357.MorganKaufmann,2002. [26] D. Melski and T. W. Reps. Interprocedural path \npro.ling. In S. J\u00a8 ahnichen, editor, CC, volume 1575 of Lecture Notes in Computer Science,pages47 62.Springer,1999. \nISBN3-540-65717-7. [27] A. Metwally, D. Agrawal, and A. E. Abbadi. An integrated ef.cient solution for \ncomputing frequent and top-k elements in data streams. ACMTrans.DatabaseSyst.,31(3):1095 1133, 2006. \n[28] S.Muthukrishnan. Datastreams:Algorithms andapplications. Foun\u00addations andTrendsinTheoreticalComputerScience,1(2),2005. \n[29] N.Nethercote andJ.Seward. Valgrind: aframeworkforheavyweight dynamicbinaryinstrumentation. In PLDI,pages89 \n100,2007. [30] C.Pavlopoulou andM.Young. Residualtestcoveragemonitoring. In ICSE,pages277 284, 1999. \n[31] C.Ponder andR.J.Fateman.Inaccuraciesinprogrampro.lers. Softw., Pract.Exper.,18(5):459 467, 1988. \n[32] S.RoyandY.N.Srikant.Pro.lingk-iterationpaths:Ageneralization of theball-laruspro.lingalgorithm.In \nCGO,pages70 80,2009.  [33] M.Serrano andX.Zhuang.Buildingapproximate callingcontextfrom partial calltraces. \nIn CGO,pages221 230,2009. [34] J.M.Spivey.Fast, accurate callgraphpro.ling. Softw.,Pract.Exper., 34(3):249 \n264, 2004. [35] K.Vaswani,A.V.Nori, andT.M.Chilimbi. Preferentialpathpro.l\u00ading:compactly numberinginterestingpaths.In \nPOPL,pages351 362. ACM,2007. [36] J. Whaley. A portable sampling-based pro.ler for Java virtual ma\u00adchines. \nIn Proceedings of theACM2000Conference onJavaGrande, pages78 87.ACMPress,2000. [37] X. Zhuang, M. J. \nSerrano, H. W. Cain, and J.-D. Choi. Accurate, ef.cient, and adaptive calling contextpro.ling. In PLDI,pages \n263 271,2006.    \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Calling context trees (CCTs) associate performance metrics with paths through a program's call graph, providing valuable information for program understanding and performance analysis. Although CCTs are typically much smaller than call trees, in real applications they might easily consist of tens of millions of distinct calling contexts: this sheer size makes them difficult to analyze and might hurt execution times due to poor access locality. For performance analysis, accurately collecting information about hot calling contexts may be more useful than constructing an entire CCT that includes millions of uninteresting paths. As we show for a variety of prominent Linux applications, the distribution of calling context frequencies is typically very skewed. In this paper we show how to exploit this property to reduce the CCT size considerably.</p> <p>We introduce a novel run-time data structure, called <i>Hot Calling Context Tree (HCCT)</i>, that offers an additional intermediate point in the spectrum of data structures for representing interprocedural control flow. The HCCT is a subtree of the CCT that includes only hot nodes and their ancestors. We show how to compute the HCCT without storing the exact frequency of all calling contexts, by using fast and space-efficient algorithms for mining frequent items in data streams. With this approach, we can distinguish between hot and cold contexts on the fly, while obtaining very accurate frequency counts. We show both theoretically and experimentally that the HCCT achieves a similar precision as the CCT in a much smaller space, roughly proportional to the number of distinct hot contexts: this is typically several orders of magnitude smaller than the total number of calling contexts encountered during a program's execution. Our space-efficient approach can be effectively combined with previous context-sensitive profiling techniques, such as sampling and bursting.</p>", "authors": [{"name": "Daniele Cono D'Elia", "author_profile_id": "81485656450", "affiliation": "Sapienza University of Rome, Rome, Italy", "person_id": "P2690639", "email_address": "danielecono.delia@gmail.com", "orcid_id": ""}, {"name": "Camil Demetrescu", "author_profile_id": "81100357279", "affiliation": "Sapienza University of Rome, Rome, Italy", "person_id": "P2690640", "email_address": "demetres@dis.uniroma1.it", "orcid_id": ""}, {"name": "Irene Finocchi", "author_profile_id": "81100246662", "affiliation": "Sapienza University of Rome, Rome, Italy", "person_id": "P2690641", "email_address": "finocchi@di.uniroma1.it", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993559", "year": "2011", "article_id": "1993559", "conference": "PLDI", "title": "Mining hot calling contexts in small space", "url": "http://dl.acm.org/citation.cfm?id=1993559"}