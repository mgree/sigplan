{"article_publication_date": "06-04-2011", "fulltext": "\n Path-based Inductive Synthesis for Program Inversion Saurabh Srivastava Sumit Gulwani University of \nCalifornia, Microsoft Research, Berkeley Redmond saurabhs@cs.berkeley.edu sumitg@microsoft.com Abstract \nIn this paper, we investigate the problem of semi-automated in\u00adversion of imperative programs, which \nhas the potential to make it much easier and less error prone to write programs that natu\u00adrally pair \nas inverses, such as insert/delete operations, compres\u00adsors/decompressors, and so on. Viewing inversion \nas a subprob\u00adlem of program synthesis, we propose a novel synthesis technique called Path-based Inductive \nSynthesis (PINS) and apply it to inver\u00adsion. PINS starts from a program P and a template T for its inverse. \nPINS then iteratively re.nes the space of template instantiations by exploring paths in the composition \nof P and T with symbolic ex\u00adecution. PINS uses an SMT solver to intelligently guide the re.ne\u00adment process, \nbased on the paths explored so far. The key idea mo\u00adtivating this approach is the small path-bound hypothesis: \nthat the behavior of a program can be summarized with a small, carefully chosen set of its program paths. \nWe evaluated PINS by using it to invert 14 programs such as compressors (e.g., Lempel-Ziv-Welch), encoders \n(e.g., UUEn\u00adcode), and arithmetic operations (e.g., vector rotation). Most of these examples are dif.cult \nor impossible to invert using prior tech\u00adniques, but PINS was able to invert all of them. We also found \nthat a semi-automated technique we developed to mine a template from the program to be inverted worked \nwell. In our experiments, PINS takes between one second to thirty minutes to synthesize inverses. We \nbelieve this proof-of-concept implementation demonstrates the viability of the PINS approach to program \nsynthesis. Categories and Subject Descriptors I.2.2 [Automatic Program\u00adming]: Program Synthesis; D.2.5 \n[Testing and Debugging]: Sym\u00adbolic Execution General Terms Languages, Algorithms, Theory Keywords PINS, \nProgram Inversion, Inductive Synthesis, Sym\u00adbolic execution, Testing-inspired Synthesis 1. Introduction \nRecently, there has been signi.cant interest in program synthe\u00adsis, in which an automated tool helps \nthe programmer derive pro\u00adgram source code from its speci.cation [28, 27, 38, 33, 26, 13]. One particularly \ninteresting synthesis subproblem is program in\u00adversion, which is the task of constructing a P -1 given \na pro- Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n11, June 4 8, 2011, San Jose, California, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. \n. . $10.00 Swarat Chaudhuri Jeffrey S. Foster Pennsylvania State University University of Maryland, swarat@cse.psu.edu \nCollege Park jfoster@cs.umd.edu gram P such that executing P followed by P -1 is the identity function. \nPairs of inverses are quite common in software, e.g., insert/delete operations on data structures, encryption/decryption, \ncompression/decompression, rollback in transactions, etc.. Auto\u00admatic program inversion could potentially \nallow programmers to write only one of each inverse pair, halving the time required to write and maintain \nsuch code and eliminating bugs due to inconsis\u00adtencies between the inverses. However, existing program \nsynthesis techniques are not well\u00adsuited to the inversion task. Proof-theoretic synthesis [38] requires \ninferring loop invariants, which are unrealistic for programs such as compressors or encoders. Counterexample-guided \ninductive syn\u00adthesis [33] requires .nitizing the domain (e.g., specifying a bound on loop unrollings \nand lengths of arrays), and we have found this is a signi.cant burden. Other approaches that are speci.cally \nfor inversion, rather than general program synthesis, are either hard to implement [8, 12] or are quite \nrestricted in the programs that can be inverted [11, 24, 41, 11]. In this paper, we present a new program \nsynthesis algorithm, Path-based inductive synthesis (PINS), that takes a major step in addressing these \nchallenges. At a high level, the PINS algorithm is straightforward. It iteratively uses symbolic execution \nto simulate paths through a known program P concatenated with a template of an unknown program P -1. \nThe template contains an ordinary pro\u00adgram, except it can contain unknown expressions and predicates, \ni.e., holes that need to be .lled in. The template also includes sets .e of candidate expressions and \n.p of candidate predicates that can instantiate unknowns. PINS uses the path conditions gener\u00adated from \nsymbolic execution to create a query for an SMT solver, and the solution of the query assigns elements \nof .e and .p to the unknowns such that P followed by P -1 is an inverse along the corresponding paths. \nThe key idea that underlies PINS is what we call the small path\u00adbound hypothesis: for many programs, \nall behavior can be sum\u00admarized by examining a small, carefully chosen set of its program paths. This \nsame hypothesis underlies program testing, and just as in testing, it is critical that PINS picks the \nright set of paths to explore and this is potentially quite challenging in synthesis, in which we are \ntrying to .nd useful paths through a program with unknowns. Thus, PINS includes a heuristic technique \nthat tries to guide symbolic execution down program paths likely to reinforce correct solutions and eliminate \nincorrect solutions. This heuristic helps ensure that when PINS .nishes, its output is highly likely \n(though not guaranteed) to be correct. To further validate correct\u00adness, the programmer can use a range \nof techniques. In our ex\u00adperiments, we used manual code inspection, testing with concrete instantiations \nof the paths explored by PINS, and bounded model checking [1] to validate PINS s output. PINS has a number \nof attractive features compared to other synthesis approaches. First, by using symbolic execution, PINS \nis able to reason about program paths precisely, but without needing strong loop invariants that prove \nfunctional correctness. Second, PINS need not .nitize the problem domain, since it relies on SMT solving. \nFinally, SMT solving has another bene.t: it allows PINS to model external library functions with axioms, \nrather than needing source code. For example, we can add axioms about string library functions such as \n.s, c : strlen(append(s, c)) = strlen(s)+1, where s and c are string and character types, respectively. \nThis makes the synthesis task smaller and more modular.  One challenge in using PINS, or any other template-based \nsynthesis approach (e.g., proof-theoretic synthesis [38], invariant\u00adbased synthesis for hybrid systems \n[39] or Sketching [33]), is de\u00adtermining what template to use. For program inversion, we have developed \na semi-automated technique for mining the template from the program to be inverted. In our approach, \nan automated tool generates initial guesses for .p and .e based on the original program text, and the \nprogrammer similarly constructs a template program based on the control .ow of the original program. \nThe user then runs PINS, using its output to further guide manual re\u00ad.nement of the template. We have \nfound that this approach is much easier than other synthesis techniques that require constructing a template \nfrom scratch [38, 39, 33]. We implemented PINS and used it to invert 14 small but complex programs ranging \nin size from 5 to 25 lines of code. Our benchmarks include several compressors (e.g., Lempel-Ziv-Welch), \nencoders (e.g., UUEncode), and arithmetic operations (e.g., rotation of a vector). For these benchmarks, \nPINS worked well in reducing the huge space of possible template instantiations to only a few .nal candidates. \nIn 11 cases, PINS produced 1 can\u00addidate inverse, which was correct. In the remaining 3 cases, PINS produced \nat most 4 candidates, at least one of which was correct. For these benchmarks, we found that our semi-automated \ntem\u00adplate mining strategy worked well; we needed only a few changes from the initial template for synthesis \nto succeed. We also found that the ability to add axioms was critical for our benchmarks, 8 of which \ncalled external libraries. Our results also support the small path-bound hypothesis. Syn\u00adthesizing inverses \nfor our benchmarks required exploring between 1 and 14 paths, with a median of 5 paths. The running time \nof PINS varied signi.cantly, ranging from 1 second to 30 minutes. The high variability is due to the \nlarge semantic differences between pro\u00adgrams and the unpredictable nature of SMT/SAT solving. More en\u00adgineering \nmay reduce these times much further, but we think that for a prototype, these times are still encouraging, \nespecially as pro\u00adgrammer time is far more expensive than processing time. We believe that PINS takes \nan important step forward in pro\u00adgram synthesis, and presents a promising new approach to the pro\u00adgram \ninversion program. 2. Path-based Inductive Synthesis We begin our presentation by describing the PINS \nalgorithm. As a running example, we will consider synthesizing an inverse to the function shown in Figure \n1, which performs in-place run-length en\u00adcoding of an input array A of length n. The function imperatively \nupdates the arrays A (destructively) and N to hold the compressed output and the count of how often each \ncompressed element ap\u00adpeared in the input, respectively. The output variable m gives the length of the \ncompressed output. Our aim is to invert this function, i.e., to produce code that generates a new AI \nto contain the original contents that were in A, using the counts in N. 2.1 Synthesis templates To constrain \nthe search space for synthesis, PINS uses a synthesis template supplied by the programmer. In PINS, a \ntemplate is a triple (P, .e, .p), where P is a program that may contain unknown expressions e and unknown \npredicates ., and .e and .p are sets runlength(inout datatype *A, in int n, out int *N, out int m) { \nint i, r; assume(n = 0); i:=0; m:=0; while (i<n) r := 1; while (i +1 <n . A[i]= A[i + 1]) r := r +1; \ni := i +1; A[m] := A[i]; N[m] := r; m := m +1; i := i +1; } Figure 1. In-place run length encoding of \nan array A of n data elements, where the encoded output is of length m. Another output array N holds \nthe counts. of expressions and predicates (without unknowns) that e and ., respectively, may range over. \nFormally, template programs P are de.ned by the following language: P, s ::= x, . . . , x := e,..., e \n| s; s | if(*) s else s | while(*) s | assume(p) | exit | in(x, . .) | out(x, . .) e ::= e | x | e opa \ne | sel(e, e) | upd(e, e, e) | f(ee) p ::= . |*| e opr e Program statements consist of parallel assignments \nto variables, se\u00adquencing, conditionals, while loops, and assume statements. We also add a form exit, \nto mark the exit of the program, and in and out, which indicate which program variables are inputs and \nout\u00adputs, respectively. These last two forms are used to help construct the synthesis template (Section \n3). Note that conditionals and loops are non-deterministic in our language. As is standard, we can encode \nif(p) s1 else s2 in our language as if(*)(assume(p); s1) else (assume(\u00acp); s2), and while(p) s as (while(*)(assume(p); \ns)); assume(\u00acp). For notational convenience, we may use the skip statement as well, which can be modeled \nin the language as assume(true). Expressions may either be unknown expressions e, variables x, arithmetic \noperations e opa e, array reads sel(e1,e2) (read ele\u00adment e2 from array e1), non-destructive array writes \nupd(e1,e2,e3) (return a new array that is the same as e1, except element e2 has value e3), and uninterpreted \nfunction symbols f (used to model external library calls). Similarly, predicates used in assume ex\u00adpressions \nmay be unknown . or known predicates p, which are known expressions compared with relational operators \nopr. Then .e is a set of expressions that do not contain occurrences of e, and analogously for .p. As \nmentioned in the introduction, for program inversion we construct a template for the inverse and then \nconcatenate that to the original program to produce the synthesis template for PINS. We defer discussion \nof exactly how the inverse template is constructed until Section 3. For our running example, the input \nto PINS is shown in Figure 2. For clarity, we have written while loops with guards, though as mentioned \nabove we actually encode these with non-deterministic choice and assume. Lines 1 11 are the same as in \nFigure 1, except they have been translated into our formal language. Lines 12 18 contain the inverse \ntemplate. Notice that in this particular example, the inverse template has essentially the same shape \nas the original program, and that the primed variables used by the inverse arise from (unprimed) variables \nused in the original program. The sets .e and .p range over expressions extracted from the original program, \nbut translated to work over both primed and selected unprimed variable names.  1 in(A, n); 2 assume(n \n= 0); 3 i, m:=0, 0; 4 while (i<n) 5 r := 1; 6 while (i +1 <n . sel(A, i)= sel(A, i + 1)) 7 r, i := r \n+1,i +1; 8 A := upd(A, m, sel(A, i)); 9 N := upd(N, m, r); 10 m, i := m +1, i +1; 11 out(A, N, m); I \n12 iI,m:= e1,e2; 13 while (.1) 14 rI := e3; 15 while (.2) 16 rI,iI,AI := e4,e5,e6; 17 mI := e7; 18 out(AI,iI); \nexit;  0, 1,mI +1,mI - 1,rI +1,rI - 1,iI +1,iI - 1, .e = upd(AI,mI, sel(A, iI)), upd(AI,iI, sel(A, mI)), \nsel(N, mI) .p =mI < m,rI > 0, sel(AI,iI)= sel(AI,iI + 1) Figure 2. Program from Figure 1 composed with \nthe template.  2.2 Symbolic execution of templates As discussed in the introduction, PINS iteratively \nuses symbolic execution to simulate chosen paths through a template. Symbolic execution has been studied \nextensively in the literature [25], but our use of symbolic execution has an interesting twist: we need \nto simulate programs containing unknowns. What makes this possible is that the only unknowns we permit \nare expressions and predicates, both of which are pure, and thus their evaluation does not affect the \nprogram state. At each step of symbolic execution, we maintain a path condi\u00adtion f that describes the \npath taken and the current and past state of all program variables. To distinguish different de.nitions \nof the same variable, we maintain a version map V that assigns a version number to each variable. As \nvariables are reassigned, their version numbers monotonically increase, similarly to variable renaming \nin static single assignment form. As a slight abuse of notation, we will use the version map 0 to denote \nassigning all variables the version number 0. When an unknown expression e or predicate . is eval\u00aduated, \nwe simply pair it with the version map V at that program point, which we write as eV or .V . Then at \nthe end of symbolic execution, since the path condition contains the history of all vari\u00adables, it gives \nus suf.cient information to interpret uses of e and . at any point during the prior execution. For notational \nconve\u00adnience, we use the same evaluation strategy for known expressions and predicates, and we write \ne V or p V for the (known or unknown) expression or predicate evaluated under version map V . As symbolic \nexecution is a subroutine in PINS, it takes two auxiliary inputs. First, our symbolic executor is given \na solution S, which is an assignment from unknown expressions and predicates to known expressions and \npredicates, respectively. The solution arises from a previous iteration of PINS, and is used to guide \nsymbolic execution down paths that tend to more quickly re.ne the solution space; we discuss this further \nin Section 2.3. Second, our symbolic executor is given a path condition set F, which is the set of path \nconditions that have been previously explored and hence should not be simulated again. Figure 3 formalizes \nour symbolic executor as a judgment of the form S;F f(s; f; V ).(fI; V I), which says that, using solution \nS and avoiding path condition set F, evaluating statement ASSN vi = V (xi)+1 V I = V [xi . vi] .i . 1..n \n= vj V fI = f . (x = ej ) j j.1..n S;F f((x1,...xn := e1,..., en); f; V ).(fI; V I) ASSUME V f . (S(p))V \n. false fI = f . p S;F f(assume(p); f; V ).(fI; V ) SEQ S;F f(s1; f; V ).(f1; V1) EXIT S;F f(s2; f1; \nV1).(f2; V2) f . F S;F f((s1; s2); f; V ).(f2; V2) S;F f(exit; f; V ).(f; V ) COND S;F f(si; f; V ).(fI; \nV I) i =1 or 2 S;F f((if(*) s1 else s2); f; V ).(fI; V I) LOOP S;F f(if(*)(s; while(*) s) else skip; \nf; V ).(fI; V I) S;F f(while(*) s; f; V ).(fI; V I) INOUT io . in, out S;F f(io(x, . .); f; V ).(f; V \n) Figure 3. Symbolic execution with unknowns. s beginning with path condition f and version map V yields \na new path condition fI and version map V I . Wediscusstherulesbrie.y.InRule ASSN,weincrementthever\u00adsion \nnumbers of all assigned variables to yield a new version map V I, and we create a new path condition \nfI containing equalities for the newly assigned variables. Notice here we pair the expressions ej with \nthe old version map V , since the ej are evaluated at the start of the assignment. In Rule ASSUME, we \nwrite S(p) to mean the predicate p with unknowns replaced according to S. Note that S may be a partial \nmap, and if S does not provide a mapping for p then S(p) equals p. Thus, this rule requires that the \nconjunction of the current path condition and the assumed predicate is satis.able according to the solution. \nIn our implementation, we use an SMT query to determine the satis.ability of this constraint. Rule SEQ \nis standard. Rule EXIT ensures that the path has not previously been explored. Rule COND non-deterministically \nexe\u00adcutes one of its branches. Rule LOOP unrolls a loop one time. Fi\u00adnally, Rule INOUT ignores in and \nout expressions, which are only used for constructing the synthesis template and the speci.cation formula \nfor inversion.  2.3 Synthesis algorithm Given a synthesis template P, the goal of PINS is to .nd a solu\u00adtion \nS that assigns known expressions and predicates to unknown expressions and predicates, such that S(P) \nsatis.es a given spec\u00adi.cation. For program inversion, the speci.cation is particularly simple at a high \nlevel, the program should be the identity func\u00adtion. In our running example, at the end of execution, \nthe array A should contain the same elements as at the beginning. While in this paper our focus is on \nprogram inversion, PINS is a general algo\u00adrithm, and we believe it can also be used for other synthesis \nprob\u00adlems. The PINS algorithm is shown as Algorithm 1. The input to the algorithm is a synthesis template \n(P, .e, .p), a speci.cation spec, and a bound m on the number of solutions to request from  Input: Synthesis \ntemplate (P, .e, .p), speci.cation spec, bound m on number of solutions from solver. Output: Solution \nS or No Solution. 1 begin 2 F := \u00d8; 3 C := terminate(P); 4 while (true) do 5 sols := solve(C, .p, .e,m); \n6 if sols = \u00d8 then 7 return No Solution ; /* Re.ne abstraction */ 8 if stabilized(sols,m) then 9 return \nsols; 10 S := pickOne(sols); 11 S;F f(P; true;0).(f; V I); 12 F := F .{f}; 13 C := C . safepath(f, V \nI , spec); 14 end Algorithm 1: The PINS algorithm. the solver (discussed below). We next give an overview \nof the algorithm, deferring details of the subroutines terminate, solve, stabilized, pickOne, and safepath \nuntil after the overview. Throughout its execution, PINS maintains a set F of program paths that have \nbeen symbolically executed so far, and a constraint C that includes constraints gathered from prior symbolic \nexecu\u00adtions. As the algorithm progresses, F increases and C accumulates additional constraints. F is \ninitially empty, and C is initially set to terminate(P), which constrains loops in P to terminate. The \nmain loop of PINS iteratively re.nes the space of solutions as follows. On line 5, we compute (at most) \nm solutions to the constraints C, using .p and .e for the possible values of unknown predicates and expressions \nin C. If the resulting set of solutions sols is empty, then there is no valid template instantiation \nthat satis.es spec. Typically this means the template needs to be re.ned; we describe this process in \nSection 3. If sols has stabilized, meaning it did not change from the last iteration, then we exit and \nreturn sols. Otherwise, we re.ne the solution space. On line 10, we set S to be one of the computed solutions, \nchosen by the heuristic pickOne. Then we symbolically execute P, using the solution S to guide the execution, \nand begin\u00adning with the path condition true and the version map that assigns version 0 to all variables, \nwhich we write simply as 0. Recall that in Rule ASSUME of Figure 3, we require that the guard p is satis.able \naccording to S thus, the path taken in the symbolic execution on line 11 is a feasible path in the program \nS(P). As we will discuss below, this means that the path taken will tend to generate con\u00adstraints that \neither reinforce S if it is a valid solution, or contradict S if it is an invalid solution. Finally, \nwe add the path condition f from the symbolic execu\u00adtion to F, and we add to C the constraint safepath(f, \nV I , spec), which speci.es that the path taken meets the speci.cation spec. We then repeat this process \nuntil no solutions are possible, or the set of solutions has stabilized. Next, we discuss the subroutines \nused by PINS in more detail and how PINS handles uninterpreted functions. Safety constraints The constraint \ngenerated by safepath on Line 13 speci.es that the symbolic execution, which generated path condition \nf and .nal version map V I, satis.es spec: . V i safepath(f, V I , spec)= .X : f . spec where X is the \nset of all program variables at all versions. Notice V i that in spec , program variables in spec will \nbe interpreted in terms of V I, i.e., at their .nal values at the end of execution. EXAMPLE 1. Suppose \nin Figure 2 we take a path that immediately exits the loop on line 4, enters the loop on line 13, exits \nthe loop on line 15, exits the loop on line 13, and then exits the program. The safety constraint (left) \ngenerated for this path (right) is: n0 = 0 . i1 =0 . m1 =0. ...n = 0; i, m := 0, 0; V1 I1 V1 i1 = n0 \n. iI1 = e. m= e. ...i = n; iI,mI := e1,e2; 12 V2 I1 V2 .. r= e. ....1; rI := e3; 13 V3 I2 V3 \u00ac.. m= \ne. ... \u00ac.2; mI := e7; 27 V4 \u00ac.1 ... \u00ac.1 V4 . spec where we abbreviate the version maps as V1 = {n . 0,m \n. 1,i . 1}.0, V2 = V1 .{m I . 1,iI . 1}, V3 = V2 .{r I . 1}, and V4 is V3 but with m I . 2. The identity \nspeci.cation spec is derived syntactically from in(A, n) and out(AI,iI)) as n 0 = iIV4 . A0[k] ..k :0 \n= k<n0 = AIV4 [k]. This path turns out to be infeasible for the actual synthesized inverse (shown in \nSection 3), but this does not mean that the path is redundant during synthesis. To the contrary, the \npath imposes constraints on the unknown expressions and predicates that eliminate any candidate for which \nthis path is feasible, thereby pruning the search space. Termination constraints The termination constraints \ngenerated on Line 3 serve two important purposes. First, they prevent syn\u00adthesis of programs that diverge, \nsince such programs trivially sat\u00adisfy any partial speci.cation but are uninteresting in this domain. \nSecond, they ensure that the symbolic execution runs on Line 11 themselves terminate, since those runs \nare guided by a solution to the constraints. We generate termination constraints by reasoning about each \nloop separately. Consider a loop l = while(*){assume(.l); Bl}, where the guard .l is an unknown and the \nbody is Bl. We assume there is a corresponding ranking function .l that is an unknown, ranging over a \nset of expressions .r (discussed below). We impose two kinds of constraints on .l to ensure the loop \nterminates. First, we assume the ranking function is related to the loop guard .l, and generate a constraint \n. 00 bounded(l)= .X. .l . (.l = 0) that the guard implies a lower bound on the ranking function. Notice \nthat this constraint does not involve any path condition, and hence the relationship it implies must \nhold across all possible values of the program variables. Next, we need to generate a constraint that \nthe ranking function decreases on every iteration through the loop. We introduce an unknown loop invariant \n.I l, and generate the following constraints: . decrease(l)= .X. f . .IV . (f,V ).init l . .IV .X. \nf . .I0 . (f,V ).body ll .X. f . .0 l . .I0 . .lV <.l 0 (f,V ).body l where body is a set of tuples \n(f; V ) from symbolic executions of the loop body, and init is a set of tuples from symbolic executions \nthat start at the program entry and end at the loop entry. From top to bottom, these constraints specify \nthat the invariant holds at the beginning of the loop; that it is maintained during an execution of the \nloop body; and that the invariant and the loop guard imply that the ranking function decreases on each \niteration. Note that although these constraints look complex, in fact the loop invariant required for \ntermination is often far simpler than a loop invariant required for functional correctness. For example, \ntypically we only required an invariant that is a linear relation (real programs shown terminating by \nothers [5, 6] illustrate that linear relations typically suf.ce), and we never required a quanti.ed invariant. \n To compute body and init, we use two heuristics. First, to compute body we symbolically execute all \npossible paths through the loop body (starting with the empty path conditions and empty version map 0), \nalways taking the exit branch of any inner loop to keep the set of paths .nite. Thus, we are assuming \nthat inner loops do not affect the termination of outer loops. Second, we initialize init to be empty, \nand each time PINS symbolically executes some path on Line 11, we take the pre.x of that path up to the \nstart of the loop, and add the corresponding init-related constraint to C. Thus, we are only constraining \nthe invariant to hold on a .nite number of paths, rather than on every path, similar to dynamic approaches \nthat infer likely invariants [10]. Other than the (transition) invariant involving decrease and bounded, \nin our experiments, additional inductive safety invariants are typically not required to prove termination. \n(An example of where we might need an inductive invariant, e.g., C> 0, might be when x := x + C is the \niteration counter increment.) Other work also shows that termination for typical programs can be proven \nwithout inductive reasoning [19].In this simpler case, the SMT/SAT solver discovers it can set the invariant \nto simply be true, in which case decrease(l) simpli.es to (f,V ).body .X : f..0 l . .lV < .l 0 . Putting \nbounded and decrease together, we have . terminate(P)=decrease(l) . bounded(l) l.loops(P) where loops(P) \nis the set of all loops in P. EXAMPLE 2. Consider the loop, let us call it l1, on Line 13 in Fig\u00adure \n2. The loop guard is .1, and we assume an unknown rank\u00ading function .l1 . For clarity we show the simpli.ed \nversion of decrease (assuming a loop invariant is not required) as above. Then the termination constraint \nfor the loop is: I1 V1 I1 V1 V2 .0 . r= e0 .\u00ac.. m= e. (.l1 <.l1 0) .. decrease(l1) 132 7 .0 . (.l1 \n0 = 0) .. bounded(l1) 1 where V1 = {r I . 1}. 0 and V2 = {m I . 1}. V1. We will show later that the valid \ninverse to this program instantiates the unknowns as {.1 . (m I <m),.2 . (r I > 0),e3 . (sel(N, mI)),e7 \n. (m I + 1),.l . (m - m I - 1)} in which case each conjunct reduces as follows. bounded(l) reduces to \nthe following trivial constraint: (mI <m)0 . ((m - mI - 1)0 = 0) Also, decrease(l) reduces to (mI <m)0 \n. rI1 =(sel(N, mI))0 .\u00ac(rI > 0)V1 . mI1 =(mI + 1)V1 . ((m - mI - 1)V2 < (m - mI - 1)0) which if we keep \nthe relevant conjuncts simpli.es to m I0 <m0 . I1 I0 I1 I0 m = m +1 . (m 0 - m <m0 - m ), which holds. \nOne issue we have not yet discussed is how to determine .r, the expressions .l may range over. We could \nask the user to supply .r as part of the synthesis template, but we have found that we can derive .r \nas follows: For each inequality in .p, we convert it into an equivalent relation of the form e = 0 using \nsimple symbolic manipulation, and add e to .r. For example, if (n>s) . .p, we convert it to n - s - 1 \n= 0 and thus add n - s - 1 to .r. We found this simple approach to be effective in practice. Solving \nfor and enumerating m solutions As we can see from the de.nitions of safepath and terminate, the constraint \nC maintained by PINS has the form .X.CI, where X is the set of program variables (note that we have lifted \nthe quanti.cation over X to the top level). We wish to solve for the unknown predicates and expressions, \nand thus the solve procedure tries to .nd m solutions for a constraint ..iej .l.l..X.CI where the unknown \npredicates, expressions, ranking functions, and dynamic invariants can range over .p, .e, .r, and .p, \nrespectively. Our implementation of solve builds upon our earlier work, which uses constraint-based invariant \ninference [36, 38, 17, 18]. The invariant inference problem is to solve a constraint of the form .Ik.X.vc, \nwhere the Ik are unknowns in a template assumed for the invariant, X is the set of program variables, \nand vc is a veri.cation condition. Notice that this constraint is similar in shape to the constraints \ngenerated by PINS, and thus we can adapt the solving strategy from this prior work to solve our constraints. \nVery brie.y, constraint-based invariant inference works by call\u00ading an SMT solver a polynomial number \nof times to extract infor\u00admation from each constraint in vc. It then uses that information to construct \na SAT formula that contains boolean indicator variables, whose solution maps back to an assignment of \neach Ik to one of the possible predicates it may range over [36]. During invariant inference using a \nprogram s vc (which is a conjunction of implications, each constructed from some fragment of the program), \nthe unknowns Ik in the invariant templates appear at most twice in each vc implication: at the beginning \nof the loop, and at the end. However, the constraints generated in PINS can include unknown predicates \nand expressions that are paired with many different version maps. We therefore needed to extend the earlier \nwork to handle version maps. It turns out that the core theory and algorithm we previously developed \n[36] holds under multiple versions, and so we only need to make the following implementation changes \nto build solve: (a) we added version maps to track states of variables, (b) we incorporated a stack depth \nparameter so we can distinguish variable versions across recursive calls, and (c) we replaced the veri.cation \ncondition generator with the symbolic executor from Figure 3. One nice property of using an SMT/SAT-based \nreduction for solve is that we can easily ask for m different solutions from the solver: Given one solution \nS for C, we can then pass the constraint e C . (ai= S(ai)) to the solver to get a different solution, \nwhere ai . dom(S). As we discuss next, we use this enumeration of possible solutions to determine when \nto halt iteration of PINS. Stabilization of solutions PINS stops iteration and returns the current set \nof solutions when that set is the same as in the last iteration and its size is less than m (Line 8). \nWe actually perform this check by comparing the sizes of the current and last value of sols since the \nset of constraints C is only added to, if the size of sols is the same from one iteration to the next, \nthe solutions themselves must also be the same. When PINS exits, it is not guaranteed that the returned \nsolutions are correct; this should be clear, because PINS typically only ex\u00adplores a subset of the possible \npaths through the template program. In our experiments, stabilization happened when only one to four \nsolutions remained, and thus PINS winnowed down a very large space of solutions to only a small set of \npossibilities. Given this set, the programmer can validate the solutions using other approaches, such \nas as manual inspection, test case generation, or model check\u00ading. We discuss these approaches more in \nSection 2.5. Picking one solution On Line 10 of the PINS algorithm, we pick one solution out of sols \nfor subsequent symbolic execution. Ideally, we will choose an incorrect solution Sbad . sols. Since incorrect \nsolutions are usually incorrect on many paths, we expect that if we explore a path that is feasible in \nSbad , the constraints generated will show that Sbad violates spec, and thus Sbad will be pruned from \nthe search space (as will many more incorrect solutions, most likely). We found that a good heuristic \nfor picking such a solution is to .nd one that contradicts many constraints in F. More precisely, we \nde.ne infeasible(S)= |{f . F | S(f) . false}|  and then pick a solution S . sols with the highest infeasible(S). \nWe break ties randomly. To understand why this heuristic works, consider an incorrect solution Sbad . \nsols. Since Sbad has survived previous iterations of PINS, it must agree with C, which was generated \nfrom many paths. But as the number of paths represented by C increases, the chance that Sbad survived \nbecause it satis.es spec along paths in F diminishes. Instead, it is much more likely that Sbad survived \nbe\u00adcause the paths in F are infeasible in Sbad , i.e., Sbad (f) is false for f . F. (Notice this makes \nthe left-hand side of the implication in safepath false, and hence safepath is trivially satis.ed.) Thus, \nif we pick a solution S with a high infeasible(S), there is a good chance it is an incorrect solution. \nNote that even if pickOne selects a solution S that is valid, it will still tend to help PINS converge: \nSince S is valid, it will survive the next round of iteration, but the additional constraints it imposes \non the symbolically executed path should help prune out invalid solutions. We experimentally compared \nusing infeasible to implement pickOne versus random selection, and we found that random selec\u00adtion yields \nruntimes that are 20% longer than with infeasible. Axiomatization for modular synthesis Our language \nfor template programs includes calls of the form f(e ), where f is an uninter\u00adpreted function. In PINS, \nthese are used to model calls to external libraries. Not surprisingly, library calls are common in practice \nin our experiments, 8 of 14 benchmarks use library calls. Because PINS uses SMT/SAT solving over symbolic \ncon\u00adstraints, we can readily model the behavior of these library calls as additional axioms over the \nuninterpreted functions, which are passed directly through to the solver. For example, in our experi\u00adments \nwe model strings as an abstract data type with three functions append, strlen, and empty that satisfy \naxioms such as: strlen(empty()) = 0 .x, y. strlen(append(x, y)) = strlen(x)+ strlen(y) .x, c. strlen(append(x, \nc )) = strlen(x)+1 In another instance, we treat an angle as an abstract data type, with trigonometric \ninterface functions cos and sin. We also use such abstract reasoning for operations that are dif.cult \nfor SMT solvers, e.g, we can add an axiom .x =0.mul(x, div(1,x)) = 1 to allow enhanced reasoning about \nmultiplication and division. Overall, we found the ability to axiomitize library calls to be extremely \nuseful, and as a general technique it helps split the synthesis problem into more modular pieces.  2.4 \nDiscussion Now that we have presented the PINS algorithm, we can revisit the small path-bound hypothesis \ndescribed in the introduction: That for many programs, all behavior can be summarized by examining a \nsmall, carefully chosen set of paths. PINS is designed around this hypothesis. In each iteration, it \nex\u00adplores one path, and then uses the constraints safepath(f, V I , spec) from that exploration to further \nrestrict the solution space. Speci.\u00adcally, PINS .nds a solution S to constraints C and uses S to guide \nsymbolic execution on the next iteration. As discussed earlier, if S is incorrect, it will likely be \neliminated, and if S is correct, it will be reinforced and will likely eliminate other, incorrect solutions. \nContrast this with, for example, random path exploration. Sup\u00adpose a template program contains two nested \nloops in sequence, as does the run-length example in Figure 2. For this example, a single element array \nresults in the identity compression. For a two element array, the elements can be identical or different. \nInterest\u00ading compression happens only in an array of length three or more. So, we would want to explore \nthe program s behavior on such non\u00adtrivial cases. But even if we only consider paths that traverse each \nloop at most three times, there are still 7,225 unique paths. We tried random path exploration, but we \nfound it did not work even for the simplest examples. The path-bound hypothesis underlies the idea of \nsoftware test\u00ading as well, and we think it holds for synthesis for the same reasons: a small set of carefully \nchosen paths can cover both the main be\u00adhavior and the corner cases of a program because that is typically \nhow programs and algorithms are designed. While the set is small, it needs to be carefully constructed. \nIn the case of software testing, these paths are either provided by a human, or possibly through symbolic \nexecution. For synthesis, we propose PINS s mechanism of directing path exploration using candidate solutions. \n 2.5 Validating solutions When PINS terminates, it outputs a set of solutions that satisfy all of the \nprogram paths explored during iteration. As discussed earlier, this does not guarantee that the synthesized \noutput is correct over all possible paths, and so to gain further con.dence in the output solutions, \ndevelopers can take several additional steps. First, developers can manually inspect the solutions for \ncorrect\u00adness. In our experience, this was fairly easy. For 11 out of 14 of our benchmarks, there was \na single solution to inspect, and in all 11 cases it was correct. For the other three benchmarks, there \nwere at most 4 remaining solutions. In one benchmark, we found that the remaining two solutions were \nindeed both valid, while in the other two benchmarks, we found that only one solution was valid. In each \nof the three cases, the solutions differed in at most one assignment, so it was no harder to understand \nthe set of solutions than a single solution. We believe that PINS helps the programmer because it can \nbe easier to check a program for correctness than create it. Second, developers can examine the set of \npaths explored by PINS. For each path condition f, our implementation uses the SMT solver to output a \nconcrete input that will take that path (by solv\u00ading (.X.f) restricted to input variables at version \n0). These inputs are concrete test cases that necessarily meet the speci.cation, and we found them very \nhelpful in understanding the generated solu\u00adtion. More particularly, the concrete tests helped us intuitively \nun\u00adderstand the solution s behavior, without needing to trace through long symbolic paths. Finally, the \nprogrammer can use formal veri.cation techniques to validate the solution. For example, in our experiments \nwe tried using the bounded model checker CBMC [1] to check the synthe\u00adsized inverses, and we succeeded \nin doing so for 6 of the 14 bench\u00admarks (more details in Section 4). One limitation of CBMC is that it \ncannot incorporate new axioms (which we use to model library functions); other formal reasoning techniques \nthat can support ax\u00adioms may be able to verify the remaining cases. 3. Semi-automated template mining \nIn this section, we discuss how we construct a synthesis template (P, .e, .p) for a program inverse. \nOur approach is inspired by an insight from Dijkstra, who observed that in some cases, a program can \nbe inverted by reversing its control .ow edges and assignment statements [8]. Based on this observation, \nwe help the programmer derive the template components from the text of the program to be inverted. We \nshould emphasize that our approach is meant to assist the programmer in constructing a template, but \nit is still up to a human to identify the .nal template to use. We begin by automatically mining candidate \nsets for .p and .e, in three steps. First, we traverse the original program text and return all expressions \ne that appear in assignments x := e, and all predicates p that appear in assumptions assume(p). (Re\u00adcall \nthis is the only place predicates can appear, since we have transformed conditionals and while loops \nto use non-deterministic choice and assume.) We also record which variables are used with in and out. \nNext, to these sets we apply projections that, given an input expression or predicate, return a set of \ncandi\u00addate expressions and predicates. For inversion some of the pro\u00adjections we use are the identity \n.x.{x}; subtraction inversion .(e1 - e2).{e1 + e2}; addition inversion .(e1 + e2).{e1 - e2}; copy inversion \n.upd(A, i, sel(B, j)).{upd(B, j, sel(A, i))}; and array read .(sel(A, i) opr X).{sel(A, i)}. We also \nhave a pro\u00ad  jection that uses the out call over ints to construct a predicate as .out(m).{m I <m}, \nfor integer m. In essence, these projections capture speci.c domain knowledge in this case, that program \nin\u00ad had an off-by-one bug in it, and inspection of the paths generated by PINS led us to .nd the bug. \nInverting a run-length encoder To give more insight into the process of inverting a program with PINS, \nwe describe how to invert the running example from Figure 2. Running the .rst step of template mining \nyields the following predicates and expressions:  0, 1,m +1,r +1,i +1, upd(A, m, sel(A, i)), upd(N, \nm, r) sel(A, i)= sel(A, i + 1),n = 0,i +1 < n,i < n Then applying the projections and renaming variables \nyields:version often requires inverting operations. In total, we use eight . . .. . . .. projections, \nincluding the ones above, for inversion, and we apply all projections to all possible inputs. For example, \nsince identity is 0, 1,m I +1,m I - 1,r I +1,r I - 1,iI +1,iI - 1, upd(AI ,m I, sel(AI,iI)), upd(AI,iI, \nsel(AI ,m I)), one of our projections, all of the expressions and predicates in the upd(N, mI ,r I), \nsel(N, mI) original program are included in the output of the projection phase. Finally, we rename the \nvariables after projection to fresh names. . .. sel(AI,iI)= sel(AI,iI + 1), sel(AI,iI), m I < m,rI > \n0 . .. We leave it up to the programmer to choose the structure of the template program P. For inversion, \nwe found that a good starting place is to make a template program with the same control .ow structure \nthe original program text, but replacing guards with un\u00adknowns. For each assignment statement, we either \nsimply replace its right-hand side with an unknown, or we opt to invert it, replacing an assignment x \n:= e with a parallel assignment of unknowns to all program variables in e. We also decide whether to \nkeep sequences as-is or reverse them. In general, we found it was not hard to use this heuristic to come \nup with the inversion template. For instance, the inverse template in our running examples (Lines 12 \n18 in Fig\u00adure 2) corresponds to the original program, with the control .ow as-is in the outer loop and \nreversed in the inner loop, intuitively be\u00adcause the inverse needs to traverse the array in order, but \nthen undo the run-length encoding (.ipping the direction of the inner loop). The output of the mining \nprocedure is candidates for .p and .e. In practice, the automatically mined sets are typically too large \nfor synthesis to succeed if we use them directly, as the space of candi\u00addate programs is exponentially \nrelated to the number of unknowns and the number of predicate and expression options. However, they give \nthe programmer an excellent starting place for developing the .nal candidate sets for the template. Making \nsome guesses, we pick a subset of the mined sets and a template program, and then attempt synthesis. \nIf PINS succeeds, we are done. If PINS times out, we choose a smaller or different subset. If PINS eliminates \nall solutions, then we examine the paths explored by PINS (see Sec\u00adtion 2.5), which typically provide \nenough information to determine how to change .p and .e either by modifying some element in the chosen \nsubset, or by adding some new predicates and expres\u00adsions that were not mined. In rare cases, these paths \nalso indicate missing assignments, which leads us to add those to the program template. In our experiments, \nwe found that once we identi.ed the correct subset of .p and .e, we only needed to manually modify Notice \nthat since n does not have a corresponding variable in the decoder, all expressions and predicates referring \nto it are au\u00adtomatically deleted. The last two predicates come from an inver\u00adsion projector that scans \nloop iterators and out statements. Now we want to remove elements of this set that are unneeded, since \nthey will slow down the synthesis process. We can see right away that we can remove upd(N, mI ,r I), \nbecause the decoder will have no need to modify the array of counts N, and sel(AI,iI), since AI holds \nthe compressed data, which the decoder should only write to and not read from. Next we select a template \nprogram P. Since we expect the de\u00adcoder to scan its input starting at the beginning, we choose an outer \nloop that has assignments to the same variables in the same order. Since we expect the decoder to be \nreversing the compression pro\u00adcess for each element, we choose an inner loop where the body is reversed, \ni.e., for the variables read from A, r, i, and n (A and n are read in the loop guard) their renamed versions \nAI ,r I and iI are written to. We then try running PINS, and discover that constraint solving has bogged \ndown. With a little more experimentation, we remove the assignment to iI,AI and N that corresponds to \nassign\u00adments between lines 8 10 in Figure 2, yielding the template pro\u00adgram at the bottom of that .gure. \nWe run PINS again, and this time it terminates but claims no solution exists. It provides the three paths \nthat were used to elimi\u00adnate all solutions. We examine the paths, and notice that the third one enters \nthe inner loop of the template program and assigns to AI. We examine of current .e, and we notice that \nit contains no expressions that read from A, the array containing the compressed data thus clearly there \nis a problem, since AI should contain data expanded from A. As a .x, we opt to change occurrences of \nsel(AI ,x) to sel(A, x) within the upd expressions in .e, yielding a .p . .e of .. .. at most a few \npredicates and expressions, which we easily inferred from the paths explored by PINS. 0, 1,m I +1,m I \n- 1,r I +1,r I - 1,iI +1,iI - 1, upd(AI ,m I, sel(A, iI)), upd(AI,iI, sel(A, mI)), sel(N, mI), sel(AI,iI)= \nsel(AI,iI + 1),m I < m,rI > 0  .. Debugging templates using PINS The PINS approach is also a signi.cant \nstep forward from previous template-based approaches, e.g., Sketch and proof-theoretic synthesis [38], \nin providing user guidance when synthesis fails. Both these previous systems simply fail with UNSAT when \nthe template is not expressive enough, with little further assistance. In contrast, if PINS terminates \nwithout .nding an inverse, the paths explored by PINS provide a witness to the non-invertibility using \nthe template there is no instantiation of the template that makes all of those paths valid inverses. \nIn our experience, by inspecting those paths we can understand why PINS failed, and distinguish cases \nin which the template needs to be extended from cases in which inversion is impossible. In fact, our \ninitial implementation of LZ77 (see Section 4 and Appendix A) Using the current template, PINS then takes \n7 iterations and 36 seconds total to prune the search space down to one candidate: iI,mI := 0, 0; while \n(mI <m) rI := sel(N, mI); while (rI > 0) rI,iI,AI := rI - 1,iI +1, upd(AI,iI , sel(A, mI)); I m:= mI \n+1; This is a dramatic reduction in the search space; for this particular )2 230 example, there were \n117 \u00d7 (23possible inverses given the synthesis template. (Note that each unknown predicate can be instantiated \nwith a subset, denoting conjunction, from .p.)  We then manually inspected the inverse to ensure it \nwas correct, and we also veri.ed it using CBMC with bounds of 10 loop un\u00adrollings and at an array A of \nlength at most 4 (n = 4). We also attempted to synthesize the inverse using the Sketch tool [33]. We \nrewrote our template as a sketch (it takes 53 lines of code in that format), and Sketch was able to synthesize \nthe solution in 156 sec\u00adonds, using the same bounds of 10 unrollings and n = 4. (See Section 4.3 for \nmore discussion.) 4. Experiments We implemented a symbolic executor based directly on rules in Figure \n3, and used it to implement PINS.1 As discussed earlier, our implementation of solve is an extension \nof our prior work [36, 37]. We use Z3 [7] as an SMT solver. Recall that PINS is parameterized by the \nnumber of solutions m to request from the solver. In our experiments, we chose m = 10, which we found \nworked well it provided enough solutions so that our pickOne heuristic could work effectively, while \nnot requiring too much solver time. Benchmarks We used PINS to synthesize inverses for the 14 programs \nlisted in the leftmost column of Table 1. All of these programs are small, but they are also complex. \nPINS succeeded in inverting all of these programs, and we should emphasize that, to our knowledge, no \nother automated technique is able to do so given the same information. The .rst group of programs is \ncompressors. We have already discussed the run-length encoder, and we include two variants, one that \ncompresses and decompresses in place, as in Figure 1, and one that uses a separate array for the compressed \ndata. We also invert two well-known compression algorithms, Lempel-Ziv 77 (LZ77) and Lempel-Ziv-Welch \n(LZW) [42, 40]. We coded the compressors in C from a description of the algorithm [2]. The second group \nof programs convert among different formats. The Base64 program converts binary input to printable ASCII \nchar\u00adacters. UUEncode outputs four printable characters for every three bytes of binary input, plus adds \na header and a footer to the output. Again, we coded the compressors in C from their standard descrip\u00adtions. \nPkt wrapper wraps a data object (with a set of .elds inside) into a variable length packet format by \ntraversing the .elds and adding a preamble (the length of the .eld) to the data bytes for the .eld. Serialize \nis a toy data structure serialization program that re\u00adcursively walks over data objects (recursing into \nany non-primitive types) and writes out a .attened representation. Our serializer is small because it \nrelies on external functions to check whether a .eld is primitive, get the next .eld, etc.. We encode \nthe behavior of these external functions using axioms. The last group of programs perform arithmetic \ncomputations. i is a simple iterative computation that adds i to a running sum in the ith iteration. \n(Our inverse works by iteratively subtracting i from the sum, rather than trying to solve the quadratic \nn(n+1)/2.) Vector shift, Vector scale, and Vector rotate perform the named operation on a set of points \non the Euclidean plane, represented as a pair of arrays X and Y . In practice, a programmer would realize \nthat these computations can be reversed by negating the inputs to the program, but that is domain-speci.c \nknowledge the synthesizer does not have. Instead, the synthesizer discovers a specialized un-shifter, \n-scaler, and -rotater that iterate through the vectors, semantically negating the operation performed. \nThis is non-trivial for scaling, where the synthesizer needs to be able to reason about 1/x, and for \nrotation, where the inverse of (x I ,y I := IIII I xcos(t) - ysin(t),xsin(t)+ ycos(t)) is (x ,y := x \ncos(t)+ y Isin(t),y I cos(t) - x Isin(t)). 1 Our implementation of PINS is available on the web [3] Benchmark \nLoC .p . .e Inv. LoC Num. Axms Mined Subset Mod In-place RL 12 16 14 1 10 0 Run length 12 16 10 0 10 \n0 LZ77 22 16 10 3 13 0 LZW 25 20 15 4 20 15 Base64 UUEncode Pkt wrapper SerializeS 22 12 10 8 13 10 2 \n8 7 4 12 8 1 7 7 1 16 11 16 8 3 3 2 6 i 5 8 6 2 5 0 Vector shift 8 11 7 0 7 0 Vector scale 8 9 7 2 7 \n1 Vector rotate 8 13 7 0 7 1 Permute count 11 12 7 2 10 0 LU decomp 11 14 9 0 12 2 Table 1. Template \nmining characteristics. The Permute count program is Dijkstra s permutation program from his original \nnote on program inversion [8]. He considered a program that, given a permutation p, computes for the \nith element of p the number of elements between 0 ..i that are less that p(i). The inverse program computes \nthe permutation from an array of these counts. Dijkstra manually derived it from the original pro\u00adgram, \nwhile PINS synthesizes the inverse from the template. Finally, LU-decomposition performs that operation \nin-place on a matrix using the Doolittle algorithm [30]. The inverse, which has been manually derived \nbefore [4] and which we synthesize using the synthesis template, is a program that multiplies the lower \ntriangular and upper triangular matrices in-place. 4.1 Template construction Table 1 summarizes the \nresults of the template mining process on our benchmarks. For each benchmark, we .rst list its size in \nterms of lines of code, followed by three columns that measure the size of .p . .e. First, we list the \nsize of the candidate sets mined from the original program; then, we give the size of the subset we guessed \ninitially; and lastly, we list the number of modi.cations we needed to make to elements within the chosen \nsubset for successful synthesis. The second-to-last column lists the size of the portion of the template \nprogram containing the inverse (e.g., Lines 12 and below in Figure 1). In this measure, we count loop \nguards as being on their own line, and we count a parallel assignment to k variables as k lines (since \nthat is what it will ultimately be expanded to). We found that picking the subset of .p ..e was fairly \nstraight\u00adforward, as we could easily eliminate obviously redundant or use\u00adless elements. Then an initial \nrun of PINS gave us enough infor\u00admation to infer the few changes to .p . .e we needed to make. Overall, \nthe template mining process proved tremendously helpful in coming up with a synthesis template. Although \nit was still non\u00adtrivial to .nd the correct .nal template, we found it was much easier to tweak a candidate \ntemplate than come up with one from scratch. The rightmost column in Table 1 reports the number of axioms \nwe used during synthesis, as discussed in Section 2.3. These ax\u00adioms are quite generic over the uninterpreted \nfunctions we were abstracting, e.g., the axioms over strings from Section 2.3, and can be reused across \nmany different program synthesis problems that use the same ADTs. In the current implementation, we select \nax\u00adioms for each benchmark because of current limitation of SMT solvers speci.cally, quanti.er instantiation \nis expensive, and so we limit how often it occurs by limiting the number of axioms. However, SMT solvers \nare evolving rapidly, and we expect in the future to write standard libraries of axioms once and use \nthe same libraries across many different synthesis problems.  Benchmark Srch. Sp. Num. Total Redn Iter. \nTime (s) |SAT| In-place RL 230 .1 7 36.16 837 Run length 225 .1 7 26.19 668 LZ77 225 .2 6 1810.31 330 \nLZW 231 .2 4 150.42 373 Base64 UUEncode Pkt wrapper Serialize S 237 .4 220 .1 220 .1 211 .1 12 7 6 14 \n1376.82 34.00 132.32 55.33 598 177 2161 69 i 215 .1 4 1.07 51 Vector shift 216 .1 3 4.20 187 Vector scale \n216 .1 3 4.41 191 Vector rotate 216 .1 3 39.51 327 Permute count 23 .1 1 8.44 4 LU decomp 25 .1 1 160.24 \n10 Table 2. Performance of PINS  4.2 Performance Table 2 shows the performance for PINS on our benchmarks. \nThe second column reports the approximate size of the search space and the number of solutions returned \nwhen PINS terminates. For example, for the in-place run-length encoder, the synthesis template has roughly \n230 possible instantiations, and PINS eliminates all but one of them. PINS returned one solution for \n11 of the 14 benchmarks, and only a few solutions in other cases. Thus, we can see that PINS is highly \neffective in re.ning the set of possible inverses. For all programs PINS found at least one correct solution; \nwe defer a more detailed discussion of correctness to Section 4.3. The next column in Table 2 reports \nthe number of full loop iter\u00adations until PINS converges. Since PINS calls solve at the top of the loop \nbefore deciding whether to exit, i full loop iterations corre\u00adsponds to i+1 solver calls (see Algorithm \n1). On each full iteration, we explore one program path, so these numbers support our path\u00adbound hypothesis: \nfor these programs, indeed only a small number of paths were required to characterize the programs behavior. \nThe third column in the table lists the running times for PINS. We can see that the time varies widely, \nfrom one second for i up to 30 minutes for LZ77. Even so, these times may be shorter than the time required \nfor a programmer to manually write the inverses. The variability of the times arises from the large semantic \ndifferences between these programs and the vagaries of SMT/SAT solvers. We also separately measured how \nmuch of the running time was due to each of the various steps within PINS, and we found that symbolic \nexecution (which makes SMT queries) and SMT reduction to SAT take more than 90% of the running time. \nThe actual SAT formulas produced are quite small, as shown in the last column of the table, and solving \nthose and computing our pickOne heuristic take little of the running time. (The detailed distribution \nfor individual benchmarks is available in Appendix B.)  4.3 Validation After PINS terminates, we need \nto validate the inverses, since PINS does not guarantee their correctness. Table 3 shows the results \nof validation following the methodology outlined in Section 2.5. The second column counts how many solutions \nwere correct according to manual inspection. We can see that most of the solutions returned by PINS were \nin fact correct. For the three benchmarks that yielded multiple solutions, LZ77, LZW, and Base64, the \nsolutions were very similar, differing by a single assignment in most cases. Thus, after inspecting one \nsolution, it was easy to understand the others. When PINS exits, it also outputs concrete test cases, \nwhich are concrete assignments to the inputs that will cause the .nal solutions to take the paths PINS \nexplored. The third column of the table lists Benchmark Validation Sketch Manual Tests CBMC In-place \nRL ok 2 34.59s 157s Run length ok 2 0.62s 30s LZ77 1 of 2 ok 5 1.93s 29s LZW 2 of 2 ok 3 Base64 1 of \n4 ok 4 UUEncode ok 6 Pkt wrapper ok 1 SerializeS ok 5 i Vector shift Vector scale Vector rotate Permute \ncount LU decomp ok 2 ok 1 ok 1 ok 1 ok 1 ok 1 1.15s 113.74s  1.06s fail 2s  172s Table 3. Validating \nthe solutions generated by PINS. the number of such test cases; note that it might be smaller than the \nnumber of iterations, since some of the previously explored paths may be infeasible in the .nal solutions. \nWe found these tests helpful when doing our manual inspection. The fourth column reports the time for \nrunning the bounded model checker CMBC [1] to verify the .nal solutions. Note that to run CBMC, we needed \nto bound the number of loop unrollings and, in many cases, the sizes of arrays. Using CMBC gives us fur\u00adther \ncon.dence that the synthesized programs are correct. How\u00adever, most of the benchmarks needed axioms for \nlibrary functions, and we found no easy way to apply CBMC to those programs we would instead need to \nwrite implementations of the library func\u00adtions. For some axioms, such as .x =0.mul(x, div(1,x)) = 1, \neven an implementation would be insuf.cient, as this particular ax\u00adiom essentially adds a capability \nto the solver. Sketch For comparison, we tried running Sketch [33] on the same synthesis templates we \nused in our experiments. As with CBMC, Sketch does not have a way to include axioms to model library \nfunctions, and so we could only run Sketch on 6 of our bench\u00admarks; we felt that writing the library \nfunctions would signi.cantly change the input to the synthesizer, and thus would not be a mean\u00adingful \ncomparison. For instance, it dramatically changes the syn\u00adthesis problem to have an implementation for \ninv(x)=1/x as opposed to the axiom .x =0.mul(x, div(1,x)) = 1, or to have implementations for cos(t) \nand sin(t) as opposed to the axiom .t.cos 2(t)+ sin2(t)=1. Sketch also requires that the user spec\u00adify \nbounds on array sizes. Sketch was able to synthesize an inverse for 5 out of the 6 benchmarks that did \nnot make external calls; the running times are reported in the rightmost column of Table 3. Sketch only \nfailed on one benchmark we let it run for an hour, and even after we eliminated all unknown predicates \nfrom the template, Sketch still did not terminate. In this case, the program forces Sketch to unroll \na loop maxint times, which by default is 32 in Sketch (which sets integers to be 5 bits), and this large \nnumber of unrollings seems to cause the timeout. It may be possible to synthesize this example by reducing \nthe number of bits in integers below 5. For LZ77, Sketch resolves the template an order of magnitude \nfaster than PINS, but note that this is only after we spent consider\u00adable effort getting it to terminate, \nwhich happened only when we reduced the bound on the array size to 4. In general, we found that using \nSketch was more challenging than we expected, as it took us a signi.cant amount of experimen\u00adtation to \ncome up with the right bounds. This bounds requirement also highlights a key difference between PINS \nand Sketch: PINS solves for all possible input values along a small set of paths, but Sketch ensures \ncorrect synthesis on all paths within the .nitized space. The details of the parameters we found through \nexperimen\u00adtation are available in Appendix B.  4.4 Limitations and future work Our results show that \nPINS is promising, but it still has several lim\u00aditations. Scalability is clearly a challenge, both for \nPINS and for other program synthesis tools. It would be interesting future work to investigate when synthesizing \nsmall components of larger appli\u00adcations would be useful, and to improve the scalability of PINS it\u00adself. \nAnother challenge is the need to discover templates. We think that templates are a useful tool they give \nthe developer a way to narrow the search space for synthesis, but, at least in our experi\u00adence, they \nare much easier to develop than the programs to be syn\u00adthesized. For inversion in particular, our template \nmining approach proved very helpful. It would be worthwhile to study whether sim\u00adilar mining approaches \ncould be used for other domains, and user studies of synthesis could shed light on how much input a human \nis willing to provide to a synthesis tool. Finally, PINS relies on SMT solving, and more scalable and \npowerful SMT solvers would enable larger, less-constrained search spaces and faster synthesis. An interesting \ndirection for future work is to automatically re\u00ad.ne templates, rather than requiring the user to do \nso. One logi\u00adcal starting place is CEGAR, as the paths explored by PINS are analogous to the counterexamples \nused by CEGAR (although we have observed that CEGAR s re.nement cannot be used directly). Inverting many-to-one \nprograms is another interesting question. There are two formulations of the problem we could consider. \nFirst, we could try to .nd an inverse that returns some, instead of all, el\u00adements of the original program \ns input. We believe it is possible to handle this formulation with PINS directly, with just a different \ntemplate. Second, we could try to .nd an inverse that generates all of the original inputs. This is more \ndif.cult; we believe it requires that we specify a different speci.cation than identity, but that the \ncore of PINS should still be applicable. 5. Related Work Deriving program inverses A range of techniques \nfor program inversion have been previously proposed. Dijkstra [8] and Gries [12] suggest using a set \nof proof rules to derive an inverse. Our tem\u00adplate mining approach is inspired by this idea, but it is \nhard to envision this approach succeeding in an automated way on many examples. A related proposal uses \nlocal inversion plus proof rules that compose the locally inverted fragments into a complete pro\u00adgram \n[4, 9, 31]. These techniques work if all values in the reversed computation can be obtained analytically, \nwhich can be a challenge. To our knowledge, these systems have not been automated. One very interesting \ninversion technique consists of approxi\u00admating the behavior of the program with a grammar. If the output \nof the original program can be parsed using a deterministic gram\u00admar, then the inverse of the grammar \n(written using local inversion, i.e., reading the grammar backwards) corresponds to the program inverse \n[11, 24, 41]. Grammar-based inversion only works when the input to the program to be inverted has the \nright (context-free) form grammar-based approaches can invert run-length encoding, but not the dictionary-constructing \ncompressors LZW and LZ77. Also, grammar-based inversion has been applied to functional pro\u00adgrams, where \nthere are no destructive state updates and thus in\u00adversion is arguably simpler. Additionally, it is also \nnot clear to us if grammar-based inversion works on any of the arithmetic examples. Program inverses \nfor restricted cases have been considered in the context of some larger problems. As part of an approach \nto generate divide-and-conquer parallel functional programs, Morita et al show how to compute a weak \nright inverse to a program frag\u00adment [29]. It is unclear whether this approach can handle loops. Kanade \net al propose a simple inversion subroutine to aid repre\u00adsentation dependence testing [23]. This latter \napproach is based on proof rules, and seems hard to use in the general case. Inductive and deductive \nprogram synthesis Inductive synthe\u00adsis generalizes from .nite instances to yield an in.nite state pro\u00adgram \n[21]. Deductive synthesis, in contrast, re.nes a speci.cation to derive the program [28, 32]. Our approach \nis mostly inductive synthesis since we generalize from a .nite set, but it has elements of deductive \nsynthesis because we use paths and symbolic reason\u00ading. Since we use symbolic paths and not concrete \ntraces, each ad\u00additional path captures the behavior of multiple concrete runs, and more of the space \nis explored in each iteration. Additionally, while inductive synthesis cannot provide the full formal \nguarantees of de\u00adductive synthesis, symbolic paths provide a close approximation. Lastly, while previous \ninductive synthesizers re.ne using either only positive reinforcing examples or only negative counterexam\u00adples, \nwe re.ne using both positive and negative example paths. Proof-theoretic synthesis [38] and similar approaches \nfor hybrid systems [39] are deductive synthesis techniques, which encode the synthesis problem as a search \nfor invariants, and therefore needs to infer complicated invariants (and requires a formal veri.er with \nsupport for such reasoning). In contrast, PINS relies on directed path exploration and symbolic execution-based \nreasoning, and does not reason about invariants. Thus, PINS allows us to synthesize inverses that are \ninfeasible using proof-theoretic synthesis. As discussed earlier, Sketching [33] is an inductive synthesis \ntechnique that uses a model checker to re.ne the space of candi\u00addates. PINS differs from Sketch in several \nways. First, Sketch uses domain speci.c reductions to .nitize loops for stencil [33], con\u00adcurrent [34], \nand bit-streaming [35] programs, and is engineered to solve the resulting loop-.nitized problem. In contrast, \nPINS .ni\u00adtizes the solution space using templates, but does not .nitize loops or the input. We found \nthat this is an important consideration, be\u00adcause in our experiments it was tricky to choose the right \n.nitiza\u00adtion for Sketch; smaller sizes lead to faster solving, but may restrict the space such that the \nsynthesized candidates are correct only on the bounded values but not for arbitrary inputs. It took us \nseveral hours to get the .nitization right for our experiments. Second, PINS prunes using symbolic paths, \nwhile Sketch prunes using concrete executions; since multiple concrete executions may follow a single \npath, a few iterations of PINS suf.ce for the synthesis. Lastly, PINS uses SMT reasoning to generate \nconcise SAT instances that are eas\u00adily solved; Sketch uses bit-blasting, which generates large formulas \nthat may be hard to solve [15]. Some previous synthesis techniques can successful synthesize acyclic \nprograms. Gulwani et al have developed SMT-based tech\u00adniques for synthesizing acyclic programs over a \nuser-speci.ed set of components, which they apply to the synthesis of bit-vector pro\u00adgrams [15, 22]. \nGulwani et al have also shown that exhaustive search pruned by heuristics, inspired by techniques from \nthe ar\u00adti.cal intelligence community, can synthesize ruler and compass\u00adbased macros for geometrical drawings \n[16]. Kuncak et al have developed decision procedures for synthesis of functions speci.ed within a decidable \nlogic [26]. While these techniques do not rely on templates, they are restricted to loop-free programs, \nin contrast to PINS, which synthesizes programs with loops. Gulwani et al have developed synthesis techniques \nbased on divide-and-conquer paradigm that can synthesize loopy programs for string [14] and table manipulation \n[20]. However, these tech\u00adniques are based primarily on inductive synthesis, and are well\u00adsuited for \nend-users, who .nd it easy to provide examples, but would .nd the task of providing a formal speci.cation \nquite daunt\u00ading. In contrast, the technique presented in this paper can leverage formal logical speci.cations. \n 6. Conclusion We have presented a program synthesis approach called PINS that synthesizes programs \nby exploring relevant paths in a template program and ensuring that the program meets the speci.cation \nover those paths. PINS leverages symbolic execution and SMT solving to synthesize programs that take \nunbounded inputs and may have unbounded loops. An important consideration is .nding the right set of \npaths to ef.ciently prune the space of possible candidates, for which PINS includes a directed path exploration \nstrategy that is parameterized by a remaining candidate solution. We apply PINS to the task of semi-automated \nprogram inversion. We show that it is possible to mine the synthesis template using domain-speci.c projection \noperators, which signi.cantly reduces the burden on the user. Our results on inverting 14 small benchmarks \nsuggest that PINS is a promising new approach to inversion in particular, and, we believe, to program \nsynthesis in general. Acknowledgments This work was supported in part by NSF grant 1019343 to the Computing \nResearch Association for the CIFellows Project, and by NSF grants CCF-0346982 and CCF-0953507. References \n[1] CBMC. http://www.cprover.org/cbmc/. [2] LZW and LZ77. http://en.wikipedia.org/wiki/Lempel-Ziv-Welch \nand http://en.wikipedia.org/wiki/LZ77_and_LZ78. [3] PINS. http://www.cs.umd.edu/~saurabhs/vs3/PINS/. \n[4] Wei Chen. A formal approach to program inversion. In CSC: Proc. of the ACM conference on Cooperation, \npages 398 403, 1990. [5] Byron Cook, Sumit Gulwani, Tal Lev-Ami, Andrey Rybalchenko, and Mooly Sagiv. \nProving conditional termination. In CAV 08. [6] Byron Cook, Andreas Podelski, and Andrey Rybalchenko. \nTermina\u00adtion proofs for systems code. In PLDI, pages 415 426, 2006. [7] Leonardo de Moura and Nikolaj \nBj\u00f8rner. Z3, 2008. http:// research.microsoft.com/projects/Z3/. [8] Edsger W. Dijkstra. Program inversion. \nIn Program Construction, http://www.cs.utexas.edu/~EWD/ewd06xx/EWD671.PDF, pages 54 57, London, UK, 1979. \nSpringer-Verlag. [9] David Eppstein. A heuristic approach to program inversion. In IJCAI, pages 219 \n221, 1985. [10] Michael D. Ernst, Jeff H. Perkins, Philip J. Guo, Stephen McCamant, Carlos Pacheco, \nMatthew S. Tschantz, and Chen Xiao. The Daikon system for dynamic detection of likely invariants. Science \nof Computer Programming, 69(1 3):35 45, December 2007. [11] Robert Gl\u00a8 A method for automatic uck and \nMasahiko Kawabe. program inversion based on LR(0) parsing. Fundam. Inf., 66(4):367 395, 2005. [12] David \nGries. The Science of Programming. Springer-Verlag New York, Inc., 1987. [13] Sumit Gulwani. Dimensions \nin program synthesis (invited talk paper). In ACM Symposium on PPDP, 2010. [14] Sumit Gulwani. Automating \nstring processing in spreadsheets using input-output examples. In POPL, pages 317 330, 2011. [15] Sumit \nGulwani, Susmit Kumar Jha, Ashish Tiwari, and Ramarathnam Venkatesan. Synthesis of loop-free programs. \nIn PLDI, 2011. [16] Sumit Gulwani, Vijay Korthikanti, and Ashish Tiwari. Synthesizing geometry constructions. \nIn PLDI, 2011. [17] Sumit Gulwani, Saurabh Srivastava, and Ramarathnam Venkatesan. Program analysis as \nconstraint solving. In PLDI, 2008. [18] Sumit Gulwani and Ashish Tiwari. Constraint-based approach for \nanalysis of hybrid systems. In CAV, pages 190 203, 2008. [19] Sumit Gulwani and Florian Zuleger. The \nreachability-bound problem. In PLDI 10, pages 292 304, 2010. [20] William R. Harris and Sumit Gulwani. \nSpreadsheet table transforma\u00adtions from examples. In PLDI, 2011. [21] Shachar Itzhaky, Sumit Gulwani, \nNeil Immerman, and Mooly Sagiv. A simple inductive synthesis methodology and its applications. In OOPSLA, \npages 36 46, 2010. [22] Susmit Jha, Sumit Gulwani, Sanjit Seshia, and Ashish Tiwari. Oracle\u00adguided component-based \nprogram synthesis. In ICSE, 2010. [23] Aditya Kanade, Rajeev Alur, Sriram Rajamani, and G Ramalingam. \nRepresentation dependence testing using program inversion. In FSE, 2010. [24] Masahiko Kawabe and Robert \nGl\u00a8uck. The program inverter lrinv and its structure. In PADL, pages 219 234, 2005. [25] James C. King. \nSymbolic execution and program testing. Communi\u00adcations of the ACM, 19(7):385 394, 1976. [26] Viktor \nKuncak, Mikael Mayer, Ruzica Piskac, and Philippe Suter. Complete functional synthesis. In PLDI, 2010. \n[27] Zohar Manna and Richard Waldinger. A deductive approach to program synthesis. ACM Trans. Program. \nLang. Syst., 2(1), 1980. [28] Zohar Manna and Richard J. Waldinger. Toward automatic program synthesis. \nCommunications of the ACM, 14(3):151 165, 1971. [29] Kazutaka Morita, Akimasa Morihata, Kiminori Matsuzaki, \nZhenjiang Hu, and Masato Takeichi. Automatic inversion generates divide-and\u00adconquer parallel programs. \nIn PLDI 07. [30] William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. LU \nDecomposition and Its Applications, chapter 2.3, pages 34 42. 1993. [31] Brian J. Ross. Running programs \nbackwards: The logical inversion of imperative computation. Formal Asp. Comput., 9(3):331 348, 1997. \n[32] D. R. Smith. Kids: A semiautomatic program development system. IEEE Trans. Softw. Eng., 16:1024 \n1043, 1990. [33] Armando Solar-Lezama, Gilad Arnold, Liviu Tancau, Rastislav Bodik, Vijay Saraswat, and \nSanjit Seshia. Sketching stencils. In PLDI, pages 167 178, 2007. [34] Armando Solar-Lezama, Christopher \nGrant Jones, and Rastislav Bodik. Sketching concurrent data structures. In PLDI, 2008. [35] Armando Solar-Lezama, \nRodric Rabbah, Rastislav Bod\u00b4ik, and Kemal Ebcio.glu. Prog. by sketching for bit-stream. prgs. In PLDI, \npages 281 294, 2005. [36] Saurabh Srivastava and Sumit Gulwani. Program veri.cation using templates over \npredicate abstraction. In PLDI, 2009. [37] Saurabh Srivastava, Sumit Gulwani, and Jeffrey S. Foster. \nVS3: SMT solvers for program veri.cation. In CAV, 2009. [38] Saurabh Srivastava, Sumit Gulwani, and Jeffrey \nS. Foster. From program veri.cation to program synthesis. In POPL, 2010. [39] Ankur Taly, Sumit Gulwani, \nand Ashish Tiwari. Synthesizing switching logic using constraint solving. In VMCAI, pages 305 319, 2009. \n[40] T. A. Welch. A technique for high-performance data compression. Computer, 17(6):8 19, 1984. [41] \nDaniel M. Yellin. Attribute grammar inversion and source-to-source translation. Springer-Verlag New York, \nInc., 1988. [42] J. Ziv and A. Lempel. A universal algorithm for sequential data compression. IEEE Transactions \non Information Theory, IT\u00ad23(5):337 343, 1977. A. Code examples: LZ77 and LZW To illustrate concretely \nthe dif.culty in inverting these benchmarks, Figure 4 shows the code for LZ77 and LZW compressors that \nwe invert. This code and the code for the other benchmarks is available  void main(int n, BitString \nA) {BitString *D; int *B, i, p, k, j, r, size, x, go; void main(int *A, int n) { in(A,n); int *P, *N, \n*C; assume(n = 1); int i, j, k, c, p, r; D[0] =\"0\"; D[1] =\"1\"; in(A, n); i := 0; p := 2; k := 0; assume(n \n= 0); while (i<n) { i := 0; k := 0; j := i; r := 0; size := -1; while (i<n) { while (j<n . r = -1) { \nc := 0; p := 0; j := 0; x := 0; r := -1; while (j < i) { r := 0; while (i + r<n - 1 . A[j + r]= A[i + \nr]) r := x; r := r +1; x := x +1; if (c<r) } c := r; p := i - j; if (r = -1) j := j +1; { go := r; size \n:= j - i +1; } j := j +1; } B[k] := go; k := k +1; D[p] := substr(A, i, j - 1); p := p +1; i := i + size; \n} } out(B, D, k); } (a) (b) Figure 4. The compressors for (a) LZ77, and (b) LZW, inverted by PINS. Percentage \nof total time Benchmark Sym. Exe. SMT Red. SAT Sol. pickOne Total Time (s) In-place RL 41% 51% 6% 2% \n36.16 Run length 45% 45% 7% 3% 26.19 LZ77 98% 1% <0.1% <0.1% 1810.31 LZW 68% 29% <1% 3% 150.42 Base64 \nUUEncode Pkt wrapper SerializeS 42% 84% 1% 92% 57% 12% 96% 7% <1% 1% 3% <1% <1% 3% <1% <1% 1376.82 34.00 \n132.32 55.33 i 50% 38% 4% 8% 1.07 Vector shift 21% 73% 2% 4% 4.20 Vector scale 21% 73% 2% 4% 4.41 Vector \nrotate 6% 93% <1% <1% 39.51 Permute count 96% 2% <1% 2% 8.44 LU decomp 88% 11% <0.1% 1% 160.24 Table \n4. Breakdown of PINS running time. on the web [3]. Note that for both programs, none of the dictionary \nconstruction has been abstracted away. The only abstraction used is in LZW to model strings, e.g., the \ncall to substr extracts a substring between two indices from the given string. (Also note that we assume \nall pointers point to valid memory.) B. Experimental parameters and details This appendix contains some \nadditional details on the reported experimental results. Table 4 breaks down the time taken by PINS into \nthe four steps of the algorithm that involve constraint solving. The second column gives the time spent \nin the symbolic executor (which needs to perform SMT queries to determine which branches are feasible; \nsee ASSUME in Figure 3). The third column gives the time spent in SMT reduction in solve, which transforms \nthe constraints into a SAT formula, using SMT queries in the process. The fourth column gives the time \nspent in SAT solving, and the .fth column gives the Table 5. Parameters required and running times for \nCBMC and Sketch. CBMC Sketch Benchmark Unroll Size Unroll Size |SAT| In-place RL Run length LZ77S 10 \n4 10 8 5 4 10 10 8 5 8 4 2,183k 718k 12,456k i Vector shift Permute count 10 8 5 8 10 5 fail 10 8 fail \n5 8 fail 35k 1.76k time spent in pickOne. Clearly the vast majority of the time is spent in the .rst \ntwo steps. Table 5 lists the bounds we chose in running CBMC and Sketch, discussed in Section 2.5. We \nonly list the programs that did not need axioms for library functions. For both tools we give the bound \non loop unrollings and the bound on sizes of input arrays. For Sketch, we also list the average size \nof the SAT formula it produces (these are averages of the .nd values, as opposed to the check values, \nacross the algorithm). We arbitrarily started with 10 as the number of unrollings, and then reduced that \nsuf.ciently to ensure termination. For CBMC, in half of the benchmarks we had to specify a bound on the \nsize of the input arrays, to get it to terminate. We experimentally found a low enough size for veri.cation, \nwhich was 5 in one case and 4 in two others. Sketch always requires the input arrays be bounded. We arbitrarily \ntried a value of 8, which worked for two programs, but had to come down to 5 and 4 for others. Note these \nbounds are on the sizes of the input arrays. Sketch internally also bounds the bit\u00adwidths of all primitive \ntypes, e.g., integers are 5 bit wide. Because these systems bit-blast the formula, they are also susceptible \nto the types of the variables used. For instance, loops can be unrolled much more if instead of ints \nwe use chars. PINS explores the right set of paths that allow it to effectively search as vast a space \nas explored through bit-blasting over a small .nitized space.   \n\t\t\t", "proc_id": "1993498", "abstract": "<p>In this paper, we investigate the problem of semi-automated inversion of imperative programs, which has the potential to make it much easier and less error prone to write programs that naturally pair as inverses, such as insert/delete operations, compressors/decompressors, and so on. Viewing inversion as a subproblem of program synthesis, we propose a novel synthesis technique called Path-based inductive synthesis (PINS) and apply it to inversion. PINS starts from a program <i>P</i> and a template <i>T</i> for its inverse. PINS then iteratively refines the space of template instantiations by exploring paths in the composition of <i>P</i> and <i>T</i> with symbolic execution. PINS uses an SMT solver to intelligently guide the refinement process, based on the paths explored so far. The key idea motivating this approach is the <i>small path-bound hypothesis</i>: that the behavior of a program can be summarized with a small, carefully chosen set of its program paths.</p> <p>We evaluated PINS by using it to invert 14 programs such as compressors (e.g., Lempel-Ziv-Welch), encoders (e.g., UUEncode), and arithmetic operations (e.g., vector rotation). Most of these examples are difficult or impossible to invert using prior techniques, but PINS was able to invert all of them. We also found that a semi-automated technique we developed to <i>mine</i> a template from the program to be inverted worked well. In our experiments, PINS takes between one second to thirty minutes to synthesize inverses. We believe this proof-of-concept implementation demonstrates the viability of the PINS approach to program synthesis.</p>", "authors": [{"name": "Saurabh Srivastava", "author_profile_id": "81100062128", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P2690631", "email_address": "saurabhs@cs.berkeley.edu", "orcid_id": ""}, {"name": "Sumit Gulwani", "author_profile_id": "81100315615", "affiliation": "Microsoft Research, Redmond, Redmond, WA, USA", "person_id": "P2690632", "email_address": "sumitg@microsoft.com", "orcid_id": ""}, {"name": "Swarat Chaudhuri", "author_profile_id": "81309496839", "affiliation": "Pennsylvania State University, University Park, PA, USA", "person_id": "P2690633", "email_address": "swarat@cse.psu.edu", "orcid_id": ""}, {"name": "Jeffrey S. Foster", "author_profile_id": "81338488852", "affiliation": "University of Maryland, College Park, College Park, CA, USA", "person_id": "P2690634", "email_address": "jfoster@cs.umd.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993557", "year": "2011", "article_id": "1993557", "conference": "PLDI", "title": "Path-based inductive synthesis for program inversion", "url": "http://dl.acm.org/citation.cfm?id=1993557"}