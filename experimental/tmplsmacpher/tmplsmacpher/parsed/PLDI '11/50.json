{"article_publication_date": "06-04-2011", "fulltext": "\n Scaling Abstraction Re.nement via Pruning Percy Liang UC Berkeley pliang@cs.berkeley.edu Abstract \nMany static analyses do not scale as they are made more precise. For example, increasing the amount of \ncontext sensitivity in a k\u00adlimited pointer analysis causes the number of contexts to grow exponentially \nwith k. Iterative re.nement techniques can mitigate this growth by starting with a coarse abstraction \nand only re.ning parts of the abstraction that are deemed relevant with respect to a given client. In \nthis paper, we introduce a new technique called pruning that uses client feedback in a different way. \nThe basic idea is to use coarse abstractions to prune away parts of the program analysis deemed irrelevant \nfor proving a client query, and then using .ner abstractions on the sliced program analysis. For a k-limited \npointer analysis, this approach amounts to adaptively re.ning and pruning a set of pre.x patterns representing \nthe contexts relevant for the client. By pruning, we are able to scale up to much more expensive abstractions \nthan before. We also prove that the pruned analysis is both sound and complete, that is, it yields the \nsame results as an analysis that uses a more expensive abstraction directly without pruning. Categories \nand Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation General Terms Algorithms, \nExperimentation, Theory, Veri.ca\u00adtion Keywords heap abstraction, static analysis, concurrency, abstrac\u00adtion \nre.nement, pruning, slicing 1. Introduction Making a static analysis more precise requires increasing \nthe com\u00adplexity of the underlying abstraction in pointer analysis, by in\u00adcreasing the amount of context/object \nsensitivity [7, 8, 12, 13, 16, 22]; or in model checking, by adding more abstraction predi\u00adcates [1, \n3]. However, the complexity of these analyses often grows exponentially as the abstraction is re.ned. \nMuch work has been done on curbing this exponential growth (e.g., client-driven [4] and demand-driven \n[5] approaches in pointer analysis; lazy abstraction [6, 11] and other iterative re.nement approaches \nin model check\u00ading). We refer to these techniques as selected re.nement, where the main idea is to only \nre.ne an abstraction along components deemed relevant according to client feedback. In this paper, we \nintroduce pruning, a new and orthogonal ap\u00adproach which represents a signi.cant departure from existing \nse\u00adlected re.nement techniques. Pruning is applicable to static analy- Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, \nUSA. Copyright &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 c Mayur Naik Intel Labs Berkeley \n mayur.naik@intel.com ses expressed as a set of inference rules where a program property of interest \n(a client query) is proven by the inability to derive a des\u00adignated fact using the given rules. For concreteness, \nassume that the static analysis is expressed as a Datalog program. A Datalog pro\u00adgram takes a set of \ninput tuples and derives new tuples via a set of inference rules. These inference rules capture the abstract \nseman\u00adtics of the static analysis and the evaluation of the client query using the analysis result; the \ninput tuples encode the program we are an\u00adalyzing and the abstraction we are using. The program property \nis proven if a designated query tuple cannot be derived. The key idea behind pruning is to identify input \ntuples which are provably irrelevant for deriving the query tuple and remove these tuples completely \nfrom analysis. Consequently, when the ab\u00adstraction is re.ned, only the relevant tuples are re.ned, potentially \nresulting in major computational savings. It is helpful to think of pruning in terms of generalized program \nslicing, where irrelevant parts of the program (irrelevant input tuples) are removed, resulting in a \nsmaller program that is cheaper to analyze. Existing selected re.nement techniques attempt to keep the \nset of input tuples small by simply not re.ning some of them; pruning keeps the set small by removing \nsome of them entirely. Pruning can be a dangerous affair though. With selected re.ne\u00adment, we are always \nperforming a static analysis with respect to an abstraction and therefore inherit the soundness guarantees \nof ab\u00adstract interpretation. However, once we start pruning input tuples, we are no longer running a \nvalid static analysis on the original pro\u00adgram. Soundness therefore is no longer automatic, though we \ndo prove that our method is sound with respect to a given client. While soundness is trivial for selected \nre.nement but requires some argument for pruning, the situation is reversed for complete\u00adness. By completeness, \nwe mean that the analysis is as precise as if we had re.ned all the components of an abstraction. Selected \nre\u00ad.nement only re.nes a subset of an abstraction, so it is unclear that the resulting abstraction is \nas precise as an abstraction obtained by re.ning all components. However, with pruning, we conceptually \nwork with the fully-re.ned abstraction; by removing input tuples, we cannot prove fewer queries; thus, \ncompleteness is automatic. To capitalize on the idea of pruning, we propose an algorithm, which we call \nthe Prune-Re.ne algorithm. The idea is to start with a coarse abstraction and prune the irrelevant input \ntuples before re.ning the abstraction; the algorithm iterates until the query is proven or a speci.ed \ncomputational budget is reached. We prove that the Prune-Re.ne algorithm computes the same answers to \nclient queries as directly using a re.ned abstraction without prun\u00ading, which would be precise but possibly \ninfeasible. We apply pruning to the k-object-sensitivity abstraction [12], where objects in the heap \nare abstracted using chains of allocation sites; these chains are the input tuples we maintain. To facilitate \npruning, we introduce two new heap abstractions: The .rst abstrac\u00adtion truncates chains to avoid repeating \nallocation sites; this allows us to increase k without getting bogged down by long chains cre\u00adated due \nto recursion. The second abstraction replaces allocation sites by types (a generalization of [17]). We \nshow that these ab\u00adstractions can be composed to further improve the effectiveness of pruning. We ran \nour experiments on .ve Java benchmarks using three clients that depend heavily on having a precise pointer \nanalysis: downcast safety checking, monomorphic call site inference, and race detection. We show that \nwith pruning, our Prune-Re.ne al\u00adgorithm enables us to perform a k-object-sensitive pointer analysis \nwith a substantially much .ner abstraction (larger k) compared to a full k-object-sensitive pointer analysis \nor even using the selected re.nement strategy of [10]. In a few cases, the non-pruning ap\u00adproaches hit \na wall around k =3 but the Prune-Re.ne algorithm is able to go well beyond k = 10. 2. Preliminaries Our \npruning technique works on Datalog, a general language which can be used to express static analyses declaratively \n[2, 21]. Nor\u00admally, these analyses and their underlying abstractions are encoded by one monolithic Datalog \nprogram which evaluates a query ab\u00adstractly. For us, it will be convenient to consider the Datalog pro\u00adgram, \nwhich evaluates a query concretely,1 as distinct from the ab\u00adstraction, which transforms the input to \nthe Datalog program, re\u00adsulting in an abstract evaluation of the query. This separation al\u00adlows us to \nmake theoretical statements comparing the behavior of the same Datalog program across different abstractions. \nWe .rst de.ne Datalog and the computation of a concrete query (Section 2.1). Then, we focus on the abstraction \n(Section 2.2), which interacts with the Datalog program by transforming the input tuples. Throughout \nthis section, we will use Figure 1 as a running example. 2.1 Datalog A Datalog program consists of a \nset of constants C (e.g., 0, [03] . C), a set of variables V (e.g., i, j .V), and a set of relations \nR (e.g., edge .R). A term t consists of a relation t.r .R and a list of arguments t.a, where each argument \nt.ai is either a variable or a constant, (that is, t.ai .V.C) for i =1,..., |t.a|. We will write a term \nin any of the following three equivalent ways: t = t.r(t.a) = t.r(t.a1, . . . , t.a|t.a|). (1) For example, \next(j, c, c') is a term. We call a term whose argu\u00adments are all constants a tuple (e.g., ext(0, [], \n[0])). Note that the tuple includes the relation as well as the arguments. We let xQ denote a designated \nquery tuple (e.g., common(G1, G2, 3)), whose truth value we want to determine. Let Z denote the set of \nrules, where each rule z .Z consists of a target term z.t and a set of source terms z.s. We write a rule \nwith z.t = t and z.s = {s1,...,sk} as t . s1,...,sk. (2) An assignment is a function f : V .C which maps \nvariables to constants. To simplify notation later, we extend an assignment f so that it can be applied \n(i) to constants (f(c)= c for c .C), and (ii) to terms by replacing the variables in the term with constants \n(f(t)= t.r(f(t.a1),...,f(t.a|t.a|))). Derivations A Datalog program takes a set of input tuples and derives \nnew tuples. To formalize this computation, we de.ne the notation of a derivation. A derivation (of the \nquery xQ) with respect to a set of input tuples X is a sequence x =(x1,...,xn) such that 1 We refer to \nthis computation as concrete to contrast with abstract com\u00adputation we will consider later, but note \nthat this concrete computation could already contain some level of abstraction. For example, the Datalog \nprogram might correspond to 8-object-sensitivity without abstraction and k-object-sensitivity with abstraction. \nGraph Example Input relations: edge(g, i, j) (edge from node i to node j in graph g) head(c, i) (.rst \nelement of array c is i) ' ext(i, c, c') (i prepended to c yields c': c=[i]+ c) Rules: path(g, [0]). \npath(g, c') . path(g, c), head(c, i), edge(g, i, j), ext(j, c, c'). common(g1,g2,i) . path(g1,c), path(g2,c), \nhead(c, i). Query tuple: xQ = common(G1, G2, 3). Constants: C = {G1, G2, 0, 1, 2, 3, [0], [01],... }. \n Figure 1. A simple example illustrating Datalog: Suppose we have two graphs G1 and G2 de.ned on the \nsame set of nodes {0, 1, 2, 3}, and we want to compute the query tuple common(G1, G2, 3), asking whether \nthe two graphs have a common path from node 0 to node 3. Given the input tuples encoding the graph, the \nDatalog program computes a set of derived tuples from the rules. In this case, the absence of common(G1, \nG2, 3) from the derived tuples means the query is false (proven). C (concrete values) P(C) (abstract \nvalues) a : C .P(C) (abstraction, maps to equivalence class) xQ (designated query tuple) D(X) (derivations \nof xQ using input tuples X) E(X) (tuples involved in deriving xQ) P(X) (input tuples relevant to deriving \nxQ) Ak (abstract input tuples after k iterations) A k (relevant abstract input tuples after pruning) \nFigure 2. Notation. (i) for each i =1,...,n, we have xi . X; or there exists a set of indices J such \nthat (J, i) satis.es the following two conditions: j<i for each j . J, and there is a rule z .Z and an \nassignment f such that f(z.t)= xi and {xj : j . J} = {f (s): s . z.s};  (ii) xn = xQ; and  (iii) for \neach j =1,...,n-1, there exists J such that j . J and an index i such that (J, i) satis.es the two conditions \nin (i). De.ne D(X) to be the set of all derivations with respect to the input tuples X. Condition (i) \nsays that each tuple in a derivation should either be given as an input tuple (xi . X) or be the result \nof some rule z .Z. Condition (ii) says that the query tuple xQ is derived at the end. Condition (iii) \nsays that in the derivation of xQ, every tuple is somehow relevant for deriving xQ. We say that the \nquery xQ is false (proven) if and only if D(X) is empty. Although this answer to the query is the ultimate \nquantity of interest, the Datalog program can be used to provide more information, which will be useful \nfor pruning. Speci.cally, we de.ne E(X) as the set of all tuples used in any derivation (of xQ) and P(X) \nto be the subset of E(X) which are input tuples: [ E(X) . x, (3) x.D(X) P(X) . X n E(X). (4) We call \nP(X) the set of relevant input tuples. As we will see later, any tuple not in this set can be safely \npruned. In fact, P(X) also tells us whether the query is true or false. In particular, D(X)= \u00d8 if and \nonly if P(X)= \u00d8 (assuming xQ cannot be derived trivially without inputs). This equivalence suggests that \nproving and pruning are intimately related; in some sense, proving the query is just pruning away the \nquery tuple. In the remainder of the paper, we will make heavy use of P as the principal proving/pruning \noperator. In our graph example, D(X)= P(X)= \u00d8, but as we will see later, this is not true if we apply \nan abstraction to X. Computation Given input tuples X, a Datalog solver returns the set of derived tuples \nY ; the query is proven if xQ . Y . Note that Y is a superset of the relevant derived tuples E(X), which \nitself is a superset of the relevant input tuples P(X), which is needed for pruning. We can compute P(X) \nby using the Datalog program trans\u00adformation technique described in [10]: We augment our existing Datalog \nprogram with a set of new relations R ' = {r ' : r . R}. For a term t = t.r(t.a) we let t ' = t.r ' (t.a) \nbe the term that uses the corresponding new relation t.r '. We then add the following new Datalog rules: \nx ' Q . xQ , (5) s ' . z.t ' , z.s for each z .Z and s . z.s. (6) For example, the last rule of the original \nDatalog program in Fig\u00adure 1 generates the following three new rules: path ' (g1,c) . common ' (g1,g2,i), \npath(g1,c), path(g2,c), head(c, i). path ' (g2,c) . common ' (g1,g2,i), path(g1,c), path(g2,c), head(c, \ni). head ' (c, i) . common ' (g1,g2,i), path(g1,c), path(g2,c), head(c, i). The key is that a tuple x \n' is derived by the new Datalog program if and only if x . E(X). Rules generated by (5) and (6) construct \nE(X) recursively: The base case (5) states that the query tuple xQ . E(X). The recursive case (6) states \nthat if x . E(X) and a rule z (with some assignment f) was used to produce x, then for every source term \ns . z.s of that rule, we also have f(s) . E(X). Having obtained E(X), we get P(X) by keeping only tuples \nin X. The advantage of this technique is that we can use any Datalog solver as a black-box to compute \nP(X). In practice, we will not actually run P on concrete input tuples X, but on abstract input tuples. \nFrom the point of view of the Datalog solver, there is no difference between the two. We consider constructing \nabstract tuples next.  2.2 Abstractions Given a Datalog program, an abstraction is an equivalence relation \nover constants C. In particular, we represent the abstraction as the function which maps each constant \nto its equivalence class. De.nition 1. An abstraction is a function a : C.P(C) such that for each set \ns . range(a), we have a(c)= s for all c . s. We will refer to constants C as the concrete values and \nrange(a) as the abstract values. We assume the natural partial order on {[0]}{[1]}{[00]}{[01]}{[10]}{[11]}[000]* \n[001]* [010]* [011]* [100]* [101]* [110]* [111]* Figure 3. The 14 abstract values de.ned by the k-limited \nabstrac\u00adtion pk with H = {0, 1} and k =3. Speci.cally, pk maps each chain c . H* to one of the values \nabove. abstractions, where a1 . a2 if and only if a1(c) . a2(c) for all c that is, a2 is .ner than a1. \nExample: k-limited abstraction The main abstraction we will work with in this paper is the k-limited \nabstraction [12, 16]. Our general theory does not depend on this particular choice, but we present the \nabstraction here so we can use it as a running example. First, we de.ne some notation. Let Hbe an arbitrary \nset; for the graph example of Figure 1, let H = {0, 1, 2, 3} be the nodes of the graph; later, H will \nbe the set of allocation sites in a program. De.ne a chain c . H* to be a .nite sequence of elements \nfrom this set. Let |c| denote the length of the chain. Let c[i] be the i-th element of c (starting with \nindex 1) and let c[i..j] be the subchain [c[i] \u00b7\u00b7\u00b7 c[j]] (boundary cases: c[i..j] = [] if i>j and c[i..j]= \nc[i..|c|] if j> |c|). For two chains c1 and c2, let c1 + c2 denote their concatenation. The k-limited \nabstraction partitions chains based on their length k pre.x. First, for a chain c, let c* denote the \nset of all chains with pre.x c; formally: c* . {c ' . H* : c ' [1..|c|]= c}. (7) For an integer truncation \nlevel k = 0, de.ne the k-limited abstrac\u00adtion pk as follows: ( {c} if |c| <k pk(c) . (8) c[1..k]* if \n|c|= k. If the concrete chain c is shorter than length k, we map it to the singleton set {c}; otherwise, \nwe map it to the set of chains that share the .rst k elements. It is easy to verify that pk is a valid \nabstraction under De.nition 1. For example, if c = [01], then we have that p1(c) = [0]* = {[0], [00], \n[01], [000],... } are the chains that start with [0]. As another example, Figure 3 shows the range of \np3. It is important that we represent {c} and c* as distinct abstract values. In contrast, traditional \nk-limited analyses are parametrized by a set S of abstract values c , where each abstract c represents \nthe set of concrete chains whose longest matching pre.x in S is c. With this setup, every concrete chain \nwould map to some abstract value regardless of S (note that we must have [] . S). Therefore, pruning \nwould be impossible using this representation. Extending the abstraction Given an abstraction a, it will \nbe useful to extend the de.nition of a to not just concrete values, but also to abstract values, and \n(sets of) concrete/abstract tuples. First, we extend a from concrete values c to abstract values s as \nfollows: a(s) . {a(c): c . s},s .P(C). (9) Note that a(s) returns a set of abstract values. This allows \nus to naturally de.ne the composition of two abstractions. In particular, given two abstractions, a and \n\u00df, de.ne their composition to be: (a . \u00df)(c) . .s.a(\u00df(c))s. (10)  Note that the composition a . \u00df need \nnot be an abstraction even if a and \u00df are.2 Therefore, when we compose abstractions in Sec\u00adtion 3.2, \nit will be important to check that the resulting composi\u00adtions are valid abstractions. An important case \nin which compositions yield valid abstrac\u00adtions is when a\u00df (\u00df is .ner than a). In this case, a . \u00df = \na, corresponding to the fact that applying a .ner abstraction .rst has no impact. Next, we extend a to \nconcrete tuples x and sets of concrete tuples X in the natural way: a(x) x.r(a(x.a1),...,a(x.a|x.a|)), \n(11) a(X) {a(x): x . X}. (12) Here, a(x) is an abstract tuple (one where the arguments are abstract values) \nand a(X) is a set of abstract tuples. For example: p1(ext(1, [0], [10])) = ext(1, [0]*, [1]*). Finally, \nwe extend a to abstract tuples b and sets of abstract tuples B: a(b) {b.r(s1,...,s|b.a|): .i, si . a(b.ai)}, \n(13) a(B) .b.Ba(b). (14) (13) applies the abstraction function to each component of b and takes the cross \nproduct over the resulting abstract values; the result is a set of abstract tuples. (14) aggregates these \nsets of abstract tuples. For example: p1(ext(1, [00]*, [10]*)) = {ext(1, [0]*, [1]*)}. Using the abstraction \nGiven an abstraction a, we want to run the Datalog program to compute an abstract answer to the query. \nWe do this by applying the abstraction to the concrete input tuples X, producing a set of abstract input \ntuples a(X). We then feed these tuples into the Datalog program to produce P(a(X)). (Note that the Datalog \nprogram is oblivious to whether the tuples are abstract or concrete.) Figure 4 shows an example of performing \nthis computation on the graph example from Figure 1 with the k-limited abstraction p1. We say the query \nis proven by a if P(a(X)) = \u00d8. Because abstraction is sound, this happens only if the query is actually \nfalse (P(X)= \u00d8). This fact is stated formally below (see Appendix A for the proof): Proposition 1 (Abstraction \nis sound). Let a be an abstraction and let X be any set of input tuples. If P(a(X)) = \u00d8 (the query is \nfalse abstractly), then P(X)= \u00d8 (the query is false concretely). If a is coarse, P(a(X)) will be imprecise; \nbut if a is .ne, P(a(X)) will be expensive to compute. The next section shows how pruning can allow us \nto use a .ne abstraction a without incurring the full cost of computing P(a(X)). 3. General theory We \n.rst describe the core idea behind pruning (Section 3.1) and then show how it can be used in the Prune-Re.ne \nalgorithm (Sec\u00adtion 3.2). 3.1 Pruning Recall that the central operation of a static analysis is P, which \nserves two roles: (i) determining if the query is proven (when P returns \u00d8); and (ii) returning the relevant \ninput tuples. The following 2 For example, suppose C = {1, 2, 3}; a(1) = a(2) = {1, 2}, a(3) = {3}; and \n\u00df(1) = \u00df(3) = {1, 3}, \u00df(2) = {2}. Then (a . \u00df)(1) = {1, 2, 3} but (a.\u00df)(2) = {1, 2}. Therefore, a.\u00df is \nnot a valid abstraction. theorem provides the key equation that drives everything in this paper (see \nAppendix A for the proof): Theorem 1 (Pruning is sound and complete). Let a and \u00df be two abstractions \nsuch that \u00dfa (\u00df is coarser than a). Then for any set of concrete input tuples X, we have: P(a(X)) = P(a(X) \nn a(P(\u00df(X)))). (15) The left-hand side of (15) corresponds to running the analysis with respect to a. \nThe right-hand side corresponds to .rst pruning the input tuples X with \u00df and then running the analysis \nwith a. The theorem states that the two procedures obtain identical results (the right-hand side is sound \nand complete with respect to the left-hand side). The signi.cance of this is that the right-hand side \nis often much cheaper to compute than the left-hand side. Let us decipher (15) a bit more. On the right-hand \nside, the abstract input tuples \u00df(X) are fed into the Datalog solver which computes P(\u00df(X)), which is \nthe subset of input tuples, namely those that participate in any derivation of the abstract query tuple \n\u00df(xQ ). These relevant tuples are then re.ned via a to yield a set of tuples which are used to prune \na(X). The resulting subset is fed into the analysis P. On the left-hand side, P(a(X)) is the result of \ndirectly running the analysis on the abstract tuples a(X) without pruning. To obtain some intuition behind \npruning, consider the following simpler idea: .rst run the analysis with \u00df; if the query is proven, stop \nand declare proven; otherwise, run the analysis with a and output that answer. It is easy to see that \nthis two-step procedure returns the same answer as just running a: Because \u00dfa, if \u00df proves the query, \nthen so does a (Proposition 1). (15) can be thought of as an extension of this basic idea: instead of \nusing \u00df to just determine whether the query tuple is proven, we obtain more information, namely the whole \nset of input tuples that are relevant. The complexity of an analysis is largely determined by the num\u00adber \nof input tuples. Traditionally, the abstraction alone determines the set of input tuples and thus also \nthe complexity of the analysis. In our case, however, the set of input tuples is pruned along the way, \nso the abstraction only partially determines the complexity. As we will see later, with suf.cient pruning \nof the input tuples, we can use a very re.ned abstraction at a low cost. 3.2 The Prune-Re.ne algorithm \nWe now turn Theorem 1 into a full algorithm, which we call the Prune-Re.ne algorithm. Figure 5 shows \nthe pseudocode of the algorithm and a diagram showing the computation of the various abstract input tuples \ncomputed. This algorithm essentially applies (15) repeatedly. We .rst present a simpli.ed version of \nthe algorithm which ignores the pre-pruning step (we take At = t). We are given a sequence of A ' successively \n.ner abstractions a0,a1,... (e.g., at = pt for the k-limited abstractions) and a set of input abstract \ntuples A0, which is computed under the initial abstraction a0. Then the algorithm alternates between \na pruning step and a re.ning step, maintaining only the abstract input tuples that could participate \nin a derivation of the query tuple xQ. On iteration t, our current input tuples At are .rst pruned to \nA t using P; this is subsequently re.ned to At+1. Figure 6 shows an example of running this algorithm \non the graph example from Figure 1; the .rst pruning step is shown in Figure 4. Now we discuss pre-pruning. \nPre-pruning requires the user to provide another sequence of successively .ner abstractions \u00df0,\u00df1,... \nwhich are coarser than a0,a1,... , respectively. These abstractions will also be used to prune the input \ntuples. The idea is that before re.ning At to At+1, we perform two steps of pruning: (i) .rst we use \n\u00dft in a pre-pruning step; (ii) then we use at during the main pruning step.  Figure 4. Computation of \nP(p1(X)) on the graph example from Figure 1, where X is the set of concrete input tuples, and p1 is the \n1\u00adlimited abstraction which maps each path onto the set of paths with the same .rst element. In the .gure, \neach abstract tuple is derived by a rule whose source terms are connected via incoming edges. Relevant \ninput tuples (P(p1(X)), shown in green) are the ones which are reachable by following the edges backwards; \nones which are not backwards-reachable are pruned (p1(X)\\P(p1(X)), shown in red). Prune-Re.ne algorithm \nInput: Sequence of abstractions: a0 a1 a2 \u00b7\u00b7\u00b7 [Auxiliary abstractions: \u00dft at,t =0, 1, 2,... ] A0 = a0(X), \nset of tuples For t =0, 1, 2,... : [Pre-prune: A ' t . At n at(P(\u00dft(At)))] Prune: A t = P(A ' t). If \nA t = \u00d8: return proven. Re.ne: At+1 = at+1(A t). Figure 5. The pseudocode and the schema for the Prune-Re.ne \nalgorithm. The algorithm maintains a set of (abstract) input tuples which could be involved in some derivation \nof the query xQ and attempts to prune down this set. The basic version of the algorithm, which excludes \nthe lines in square brackets and the dotted boxes, simply alternates between pruning and re.ning. The \nfull version includes a pre-pruning step, which uses auxiliary abstractions to further reduce the number \nof tuples. Pre-pruning requires a sequence of auxiliary abstractions (\u00dft) which are coarser than the \nmain abstractions (at). A standard way to obtain auxiliary abstractions is by composing the main abstrac\u00adtions \nwith another abstraction t; formally, \u00dft = at . t. We can use any t for which at . t yields a valid abstraction, \nbut the speedup we obtain from pre-pruning depends on the relationship between t and at. If t is the \ntotal abstraction (t(c)= C), then pre-pruning will be fast but nothing will be pre-pruned, so we get \nno speedup. If t is no abstraction (t(c)= c), then pre-pruning is equivalent to just running the pruning \nstep, so we again get no speedup. A good rule of thumb is that t should be complementary to at (we will \nsee some examples in Section 5). Theorem 2 states that the Prune-Re.ne algorithm is both sound and complete. \nIn other words, pruning has no impact on the answer to a query. The proof is given in Appendix A and \nuses Theorem 1.  Figure 6. The abstract input tuples computed by the Prune-Re.ne algorithm on the graph \nexample from Figure 1 (without pre\u00adpruning). We are using k-limited abstractions (at = pt). During the \n.rst pruning step, ext(2, [0]*, [2]*) is pruned from A0, yield\u00ading A 0. In the re.nement step, we expand \n[1]* to {[1]} and [10]*. In the second pruning step, we prove the query (pruning everything). Theorem \n2 (Correctness of the Prune-Re.ne algorithm). At itera\u00adtion t, using the incrementally pruned abstraction \nAt is equivalent to using the full abstraction at(X) in that P(at(X)) = P(At). Consequently, if the algorithm \nreturns proven, then P(X)= \u00d8 (the query is actually false). 4. k-limited Pointer Analysis We now introduce \nour k-object-sensitive pointer analysis [12], on which we will apply the Prune-Re.ne algorithm. Each \nnode in the control-.ow graph of each method m . M is associated with a simple statement (e.g., v2 = \nv1). We omit statements that have no effect on our analysis (e.g., operations on data of primitive type). \nFor simplicity, we assume each method has a single argument and no return value.3 Figure 7 describes \nthe Datalog program corresponding to this analysis. The analysis represents both contexts and abstract \nobjects us\u00ading chains of allocation sites (C = H*). Contexts are extended into new contexts via the ext \nrelation, which prepends an allocation site to a chain (e.g., ext(3, [12], [312])). Note that these chains \nare not truncated in the Datalog program, and therefore, running the Data\u00adlog program directly (ignoring \nthe fact that it might not terminate) corresponds to performing an 8-object-sensitivity analysis. Although \nthis Datalog program itself is an approximation to the concrete program semantics it is .ow-insensitive, \ndoes not handle primitive data, etc., we will informally say that a client query computed with respect \nto this analysis yields a concrete answer. In contrast, we obtain an abstract answer by computing the \nclient query with respect to a k-limited abstraction, which we will discuss in Section 4.2. We now brie.y \ndescribe the Datalog rules in Figure 7. Rule (1) states that the main method mmain is reachable in a \ndistinguished context []. Rule (2) states that a target method of a reachable call 3 Our actual implementation \nis a straightforward extension of this simpli.ed analysis which handles multiple arguments, return values, \nclass initializers, and objects allocated through re.ection. Input relations: Domains: body . M\u00d7 P \n(method contains statement) (method) m . M = {mmain, ...} trgt . I\u00d7 M (call site resolves to method) \nargI . I\u00d7 V (call site s argument variable) (local variable) v . V argM . M\u00d7 V (method s formal argument \nvariable) (global variable) g . G ext . H\u00d7 C\u00d7 C (extend context with site) (object .eld) f . F (method \ncall site) i . I = {(h, c, [h]+ c): h . H,c . C} (allocation site) h . H Output relations: (statement) \np . P (method context) c . C = H* reachM . C\u00d7 M (reachable methods) (abstract object) o . O = H* reachP \n. C\u00d7 P (reachable statements) ptsV . C\u00d7 V\u00d7 O (points-to sets of local variables) p ::= v = new h | v2 \n= v1 | g = v | v = g | ptsG . G\u00d7 O (points-to sets of static .elds) v2.f = v1 | v2 = v1.f | i(v) heap \n. O\u00d7 F\u00d7 O (heap graph) cg . C\u00d7 I\u00d7 C\u00d7 M (call graph) Rules: reachM([],mmain). (1) reachM(c, m) . cg(*, \n*, c, m). (2) reachP(c, p) . reachM(c, m), body(m, p). (3) ptsV(c, v, o) . reachP(c, v = new h), ext(h, \nc, o). (4) ptsV(c, v2,o) . reachP(c, v2 = v1), ptsV(c, v1,o). (5) ptsG(g, o) . reachP(c, g = v), ptsV(c, \nv, o). (6) ptsV(c, v, o) . reachP(c, v = g), ptsG(g, o). (7) heap(o2, f, o1) . reachP(c, v2.f = v1), \nptsV(c, v1,o1), ptsV(c, v2,o2). (8) ptsV(c, v2,o2) . reachP(c, v2 = v1.f), ptsV(c, v1,o1), heap(o1, f, \no2). (9) cg(c, i, o, m) . reachP(c, i), trgt(i, m), argI(i, v), ptsV(c, v, o). (10) ptsV(c, v, c) . reachM(c, \nm), argM(m, v). (11) Figure 7. Datalog implementation of our k-object-sensitivity pointer analysis with \ncall-graph construction. Our abstraction a affects the analysis solely through ext, which speci.es that \nwhen we prepend s to c, we truncate the resulting sequence to length as. site is also reachable. Rule \n(3) states that every statement in a reach\u00adable method is also reachable. Rules (4) through (9) implement \nthe transfer function associated with each kind of statement. Rule (10) analyzes the target method m \nin a separate context o for each ab\u00adstract object o to which the distinguished this argument of method \nm points, and rule (11) sets the points-to set of the this argument of method m in context o to the singleton \n{o}. This pointer analysis computes the reachable methods (reachM), reachable statements (reachP), and \npoints-to sets of local variables (ptsV), each with the associated context; the context-insensitive points-to \nsets of static .elds (ptsG) and heap graph (heap); and a context-sensitive call graph (cg). 4.1 Clients \nThe core pointer analysis just described is used by three clients, which each de.nes a set of queries. \nMonomorphic call site detection Monomorphic call sites are dy\u00adnamically dispatched call sites with at \nmost one target method. These can be transformed into statically dispatched ones which are cheaper to \nexecute. For each call site i . Iwhose target is a virtual method, we create a query poly(i) asking whether \ni is polymor\u00adphic. This query can be computed with the following rule: poly(i) . cg(*, i, *,m1), cg(*, \ni, *,m2),m1 = m2. (16) Downcast safety checking A safe downcast is one that cannot fail because the object \nto which the downcast is applied is guaranteed to be a subtype of the target type. Therefore, safe downcasts \nobviate the need for run-time cast checking. We create a query for each downcast statement of the form \nv1 = v2 where the declared type of v2 is not a subtype of the declared type of v1. The query can be computed \nwith the following rule: unsafe(v1,v2) . ptsV(*,v2,o), typeO(o, t2), typeV(v1,t1), \u00acsubtype(t1,t2). \n(17) Here, typeV is a relation on a variable and its declared type and typeO is a relation on an abstract \nobject and its type (computed by inspecting the initial allocation site of o). Race detection In race \ndetection, each query consists of a pair of heap-accessing statements of the same .eld in which at least \none statement is a write. We implemented the static race detector of [14], which declares a (p1,p2) pair \nas racing if both statements may be reachable, may access thread-escaping data, may point to the same \nobject, and may happen in parallel. All four components rely heavily on the context-and object-sensitive \npointer analysis. 4.2 Relationship to general notation We now describe the k-object-sensitive pointer \nanalysis (Figure 7) in terms of our general notation presented in Section 2. The set of concrete values \nC is the union of all the domains (e.g.., allocation sites H = {1, 2, 3,... }, abstract objects C = H*, \netc.). The input tuples X are speci.ed by the input relations (e.g., X = {body(mmain,x = new 3), ext(3, \n[12], [312])}). Each of the three clients de.nes a set of possible query tuples, for example, xQ = unsafe(v4, \nv8) for downcast safety checking of an assignment v4 = v8. Recall that P(X) corresponds to obtaining \nan answer to a client query with respect to 8-object-sensitivity. To obtain k-object\u00adFigure 8. An example \nillustrating the repetition of allocation sites. The points-to set of y1 using 8-object-sensitivity is \n{[01], [001], [0001],... } (any positive number of zeros followed by a 1), and the points-to set of y2 \nis {[02], [002], [0002],... }. While these two sets are disjoint, if we use a k-limited abstraction for \nany .nite k, we would conclude erroneously that both variables might point to 0k *, where 0k is a chain \nof k zeros. Incidentally, this demonstrates an intrinsic limitation of the k-object-sensitivity abstraction. \nUsing the barely-repeating k-limited abstraction, we can increase k while avoiding chains longer than \n[00] since [00] is barely-repeating. This results in computational savings, and in this case, in no loss \nin precision. class A { f() { 1: x1 = new A 0: v = new A 2: x2 = new A } if (*) return v else return \nv.f() y1 y2 = = x1.f() x2.f() } sensitivity, we .rst apply the k-limited abstraction pk to the in\u00adput \ntuples and run the Datalog program on these abstract tuples (P(pk(X))). Note that only the ext tuples \nare affected by the ab\u00adstraction. 5. Abstractions We have already de.ned the k-limited abstraction, which \ncorre\u00adsponds to k-object-sensitivity. We now present two orthogonal vari\u00adants of this basic abstraction: \none that additionally limits the repe\u00adtition of allocation sites (Section 5.1) and one that further abstracts \nallocation sites using type information (Section 5.2). 5.1 Barely-repeating k-limited abstraction When \nwe applied the k-limited abstraction in practice, we noticed empirically that a major reason why it did \nnot scale was the seem\u00adingly unnecessary combinatorial explosion associated with chains formed by cycling \nendlessly through the same allocation sites. For k-CFA, this repetition corresponds to recursion. For \nk-object\u00adsensitivity, this corresponds to recursive allocation, as illustrated in Figure 8.4 We therefore \nwish to de.ne an abstraction that not only truncates chains at length k but also truncates a chain when \nit starts repeating. For a sequence c, we say c is non-repeating if all its elements are distinct. We \nsay c is barely-repeating if (i) c excluding the last element (c[1..|c|- 1]) is non-repeating and (ii) \nthe last element of c is repeated earlier in c. Let d(c) be the length of the longest pre.x of c that \nis barely-repeating, if it exists, and 8 otherwise: ( maxm/:c[1..m/] is barely-repeating m ' if m ' exists, \nd(c) (18) 8 otherwise. For example, d([10010]) = 3 because [100] is barely-repeating, but [1001] is not. \nWe now de.ne the barely-repeating k-limited abstraction p k as follows: p k(c) pmin{k,d(c)}(c), (19) \nFigure 9 shows an example of p k. We show that p k is a valid abstraction: 4 Incidentally, the example \nin the .gure also gives an interesting example where k-object-sensitivity for any .nite k (no matter \nhow large) is less precise than 8-object-sensitivity. {[0]}{[1]} [00]*{[01]}{[10]} [11]* [010]* [011]* \n[100]* [101]* Figure 9. For the barely-repeating k-limited abstraction for H = {0, 1} and k =3, we show \nthe equivalence classes under p k. Com\u00adpare this with the classes for the k-limited abstraction (Figure \n3). Note that, for example, [000]* and [001]* are collapsed into [00]* since [000] and [001] are not \nbarely-repeating, but [00] is. Proposition 2. The function p k de.ned in (19) is a valid abstrac\u00adtion \n(De.nition 1). Proof. We consider two cases: (i) for {c}. range( pk), we have p k(c)= {c}; and (ii) for \nany c*. range( pk), either |c| = k or c is barely-repeating; in either case, it is easy to see that any \nextension c ' . c* will have p k(c ' )= c*. Remark: one might wonder why we de.ned the abstraction using \nthe barely-repeating criterion as opposed to the simpler non\u00adrepeating criterion. It turns out that using \nthe latter in (18) would not result in a valid abstraction. If p k were de.ned using the non\u00adrepeating \ncriterion, then p 3([00]) = [0]*. But for [01] . [0]*, we have p 3([01]) = {[01]} = [0]*. 5.2 Type-based \nabstraction We now introduce an abstraction that we will use in the pre-pruning step of the Prune-Re.ne \nalgorithm. We start by de.ning an equiva\u00adlence relation over allocation sites H, represented by a function \nt : H .P(H) mapping each allocation site h . Hto its equivalence class. In the graph example, we might \nhave t (0) = t(1) = {0, 1}and t (2) = t (3) = {2, 3}. Given such a t , we extend it to sequences by taking \nthe cross product over elementwise applications: t (c)= t (c[1]) \u00d7\u00b7 \u00b7\u00b7\u00d7 t(c[|c|]),c . H* . (20) In the \nrunning example, t ([02]) = {[02], [03], [12], [13]}. To construct t for k-limited pointer analysis, \nwe consider using two sources of type information associated with an allocation site, motivated by [17]: \nI(h)= declaring type of allocation site h (21) C(h)= type of class containing allocation site h (22) \n Using these two functions, we can construct three equivalence relations, tI, tC, and tI\u00d7C as follows: \ntf (h)= {h ' : f(h)= f(h ' )}, (23) for f .{I, C, I \u00d7 C}. Now we have three choices for t: one that \nuses the declaring type (tI), one that uses the type of the containing class (tC), and one that uses \nboth (tI\u00d7C). Recall that all three are complementary to the k-limited abstraction pk: Speci.cally, t \nabstracts a chain by abstracting each site uniformly, whereas pk performs no abstrac\u00adtion on the .rst \nk sites, but performs a total abstraction on the rest of the chain. Recall that this complementarity \nis desirable for effec\u00adtive pre-pruning. Since t is not coarser than pk, we cannot use it directly in \nthe Prune-Re.ne algorithm. We must compose t with pk or p k to yield another abstraction which is coarser \nthan pk or p k, respectively. But in what order should we compose? We must be careful because the composition \nof two abstractions is not necessarily an abstrac\u00adtion. Fortunately, the following proposition shows \nwhich composi\u00adtions are valid: Proposition 3. The functions (i) pk . t and (ii) t . pk are valid abstractions \n(see De.nition 1) and equivalent; (iii) p k . t is also valid, but (iv) t . p k is not. Proof. For each \nof these four composed functions, each set s in the range of the function must be either of the form \ns = w1 \u00d7\u00b7\u00b7\u00b7\u00d7wm for m<k (case 1) or s = w1 \u00d7\u00b7 \u00b7\u00b7\u00d7 wm \u00d7 H* for some m = k (case 2), where wi . range(t) \nfor each i =1,...,m. For (i) and (ii), it is straightforward to check that (pk . t )(c)= (t . pk)(c)= \ns for each c . s. Intuitively, the truncation (pk) and coarsening (t ) operate independently and can \nbe interchanged. For (iii) and (iv), the two dimensions do not act independently; the amount of truncation \ndepends on the amount of coarsening: the coarser t is, the more truncation one might need to limit repetitions. \nShowing that p k . t is valid proceeds in a similar manner to Proposition 2. If s falls under case 1, \nnote that no c . s is repeating because the wi s must be disjoint; therefore p k(t (c)) = s. If s falls \nunder case 2, note that for any c[1..m] . s must be barely-repeating but any longer pre.x is not, and \ntherefore, p k(t (c)) = s. To show that (iv) is not an abstraction, consider the following counterexample: \nlet H = {0, 1, 2}, and de.ne t(h)= H for all h . H(there is one equivalence class). Consider applying \nt . p 3 to two elements [01] and [00]: For [01], we have p 3([01]) = {[01]}, so t ( p3([01])) = H2; for \n[00], we have p 3([00]) = [00]*, so t( p3([00])) = H2 \u00d7 H*. But H2 SH2 \u00d7 H* (notably, the two sets are \nneither equal nor disjoint), so t . p 3 does not de.ne a valid abstraction. In light of this result, \nwe will use the valid abstractions pk . t and p k . t, which work by .rst applying the type-based abstraction \nt and then applying pk or p k. 6. Experiments In this section, we apply the Prune-Re.ne algorithm (Section \n3.2) to k-object-sensitivity for our three clients (Section 4.1): downcast safety checking (DOWNCAST), \nmonomorphic call site inference (MONOSITE), and race detection (RACE). Our main empirical result is that \nacross different clients and benchmarks, pruning is effective at curbing the exponential growth, which \nallows us to run analyses using abstractions .ner than what is possible without pruning. 6.1 Setup Our \nexperiments were performed using IBM J9VM 1.6.0 on 64\u00adbit Linux machines. All analyses were implemented \nin Chord, an extensible program analysis framework for Java bytecode,5 which uses the BDD Datalog solver \nbddbddb [21]. We evaluated our analyses on .ve Java benchmarks shown in Table 1. In each run, we allocated \n8GB of memory and terminated the process when it ran out of memory. We experimented with various combinations \nof abstractions and re.nement algorithms (see Table 2). As a baseline, we consider running an analysis \nwith a full abstraction a (denoted FULL(a)). For a, we can either use k-limited abstractions (p =(pk)8 \nk=0), in which case we recover ordinary k-object-sensitivity, or the barely\u00adrepeating variants ( p =( \npk)8 k=0). We also consider the site\u00adbased re.nement algorithm of [10], which considers a sequence of \nabstractions a =(a0,a1,... ) but stops re.ning sites which have been deemed irrelevant. This algorithm \nis denoted SITE(a). As for the new algorithms that we propose in this paper, we have PR(a), which corresponds \nto the Prune-Re.ne (PR) algo\u00adrithm using a sequence of abstractions a with no pre-pruning; and PR(a,t), \nwhich performs pre-pruning using \u00dft = at . t for 5 http://code.google.com/p/jchord/ Abstractions p =(pk)8 \nk=0 (k-limited abstractions (8)) p =( k=0 (barely-repeating k-limited abstractions (19)) pk)8 tI (abstraction \nusing type of allocation site) tC (abstraction using type of containing class) tI\u00d7C (abstraction using \nboth types) Algorithms FULL(a) (standard analysis using an abstraction a) SITE(a) (site-based re.nement \n[10] on abstractions a) PR(a) (PR algorithm using a, no pre-pruning) PR(a,t ) (PR algorithm using a, \nusing a . t to pre-prune)  Table 2. Shows the abstractions and algorithms that we evalu\u00adated empirically. \nFor example, PR(p ,tI\u00d7C ) means running the Prune-Re.ne algorithm on the barely-repeating k-limited abstrac\u00adtion \n(ak = p k), using a composed abstraction based on the type of an allocation site (tI) and the type of \nthe declaring class (tC) to do pre-pruning (speci.cally, \u00dfk = p k . tI\u00d7C). t =0, 1, 2,... . We consider \nthree choices of t which use different kinds of type information (tI ,tC ,tI\u00d7C). In our implementation \nof the Prune-Re.ne algorithm, we de\u00adpart slightly from our presentation. Instead of maintaining the full \nset of relevant input tuples, we instead maintain only the set of al\u00adlocation site chains which exist \nin some relevant input tuple. This choice results in more conservative pruning, but reduces the amount \nof information that we have to keep. We can modify the original Datalog program so that the original \nPrune-Re.ne algorithm com\u00adputes this new variant: Speci.cally, .rst introduce new input tuples active(c) \nfor each c . H*. Then encode existing ext input tu\u00adples as rules with no source terms; ext is no longer \nan input rela\u00adtion. Finally, add active(c) to the right-hand side of each existing rule that uses a chain-valued \nvariable. Computing the relevant in\u00adput tuples in this modi.ed Datalog program corresponds exactly to \ncomputing the set of relevant allocation site chains. 6.2 Results We ran the four algorithms of Table \n2 using k-limited abstractions, seeing how far we could increase k until the analyses ran out of memory. \nFor each analysis, we also measured the number of input tuples given to the Datalog solver; this quantity \nis denoted as |A ' t|(see Figure 5). In this section, the number of iterations t is the same as the k \nvalue. Figure 10 plots the number of tuples |A ' t| as a function of number of iterations t. We see that \nthe non-pruning algorithms completely hit a wall after a few iterations, with the number of tuples exploding \nexponentially. On most benchmark-client pairs, the pruning algorithms are able to continue increasing \nk much further, though on several pairs, pruning only manages to increase k by one beyond the non-pruning \nalgorithms. We also observed that pruning does yield speedups, although these are less pronounced than \nthe differences in the number of tuples. Nonetheless, pruning overcomes the major bottleneck that standard \nk-limited analyses run out of memory even for moderate k. By curbing the growth of the number of tuples, \npruning makes it possible to run some analyses at all. However, there are several caveats with pruning: \nFirst, we are using BDDs, which can actually handle large numbers of tuples so long as they are structured; \npruning destroys some of this structure, yielding less predictable running times. Second, pruning requires \nsolving the transformed Datalog program for computing P(X), which is more expensive than the original \nDatalog program. Fi\u00adnally, we must solve the Datalog program several times, not just description # classes \n# methods # bytecodes |H| elevator discrete event simulation program 154 629 39K 637 hedc web crawler \n309 1,885 151K 1,494 weblech website downloading and mirroring tool 532 3,130 230K 2,545 lusearch text \nindexing and search tool 611 3,789 267K 2,822 avrora simulation and analysis framework for AVR microcontrollers \n1,498 5,892 312K 4,823 Table 1. Benchmark characteristics: the number of classes, number of methods, \ntotal number of bytecodes in these methods, and number of allocation sites (|H|) deemed reachable by \n0-CFA. |Bt||At| | Bt||Bt| |A/t||At| | At||At| |At+1||At| DOWNCAST/hedc 0.28 0.72 0.68 0.65 1.63 DOWNCAST/weblech \n0.19 0.18 0.26 0.19 3.28 DOWNCAST/lusearch 0.17 0.04 0.03 0.02 1.89 DOWNCAST/avrora 0.21 0.03 0.05 0.03 \n1.57 MONOSITE/elevator 0.10 0.55 0.21 0.21 1.67 MONOSITE/hedc 0.22 0.30 0.36 0.29 3.78 MONOSITE/weblech \n0.19 0.18 0.25 0.18 3.33 MONOSITE/lusearch 0.26 0.10 0.15 0.12 3.39 MONOSITE/avrora 0.30 0.05 0.04 0.03 \n1.85 RACE/elevator 0.10 0.57 0.22 0.21 1.58 RACE/hedc 0.28 0.28 0.34 0.25 4.01 RACE/weblech 0.19 0.18 \n0.27 0.18 3.43 RACE/lusearch 0.30 0.15 0.18 0.14 3.96 RACE/avrora 0.38 0.08 0.08 0.06 2.71 Average 0.23 \n0.24 0.22 0.18 2.72 Table 3. Shows the shrinking and growth of the number of tu\u00adples during the various \npruning and re.nement operations (see Fig\u00adure 5) for our best algorithm PR(p,tI\u00d7C ) across all the clients \nand benchmarks, averaged across iterations. The columns are as fol\u00ad lows: First, |Bt| measures the number \nof tuples after projecting |At|down to the auxiliary abstraction \u00dft = pt . tI\u00d7C for pre-pruning; note \nthat running the analysis using types instead of allocation sites Bt| is much cheaper. Next, | shows \nthe fraction of abstract values |Bt| kept during pre-pruning; When we return from types to allocation \n| t sites, we see that the effect of pre-pruning carries over ( |A/). Next, |At|At| pruning kept | of \nthe chains. Finally, |At+1| measures the ratio |At||At| between iterations, which includes both pruning \nand re.nement. Note that there is still almost a three-fold growth of the number of tuples (on average), \nbut this growth would have been much more unmanageable without the pruning. once. These three caveats \nalso apply to the site-based re.nement algorithm of [10] (SITE), so pruning is at least a strict improvement \nover that algorithm. We found that the best instantiation of the Prune-Re.ne algo\u00adrithmis PR(p,tI\u00d7C ), \nwhich involves pre-pruning with both kinds of type information (tI\u00d7C); this works better than both no \npre-pruning and pre-pruning with only tI or tC alone. Table 3 provides more details on the quantitative \nimpact of pruning for PR(p,tI\u00d7C ). We see that pre-pruning has a signi.cant impact: we can eliminate \nabout three-quarters of the tuples by just operating on the coarser level of types rather than allocation \nsites Bt| (see the | column). Importantly, the effect of this pruning carries |Bt| | t over to the original \nk-limited abstraction (see the |A/column). |At| So far, we have been using the k-limited abstraction; \nwe now compare this abstraction with the barely-repeating k-limited ab\u00adstraction introduced in Section \n5.1. As Figure 11 shows, for a few cases, the barely-repeating k-limited abstraction requires fewer tu\u00adples \nthan the k-limited abstraction; but in most cases, it does not improve scalability. The reason is that \nthe barely-repeating abstrac\u00adTable 4. The number of unproven queries (unsafe downcasts, poly\u00admorphic \nsites, races) for each of the clients and benchmarks over the .rst .ve iterations. All analyses obtain \nthe exact results on it\u00aderations where they obtain an answer. Bolded numbers refer to k values reached \nby PR(p,tI\u00d7C ) but not by any non-pruning algo\u00adrithm. While pruning enables to increase k more, we get \nstrictly more precise results for only two of the client/benchmark pairs (DOWNCAST/hedc and DOWNCAST/lusearch). \nThis points out in\u00adherent limitations of this family of k-limited abstractions. client/benchmark \\ k \n1 2 3 4 5 DOWNCAST/elevator 0 - - - - DOWNCAST/hedc 10 8 3 2 2 DOWNCAST/weblech 24 14 6 6 - DOWNCAST/lusearch \n36 14 6 5 5 DOWNCAST/avrora 12 10 6 6 6 MONOSITE/elevator 1 1 1 1 1 MONOSITE/hedc 164 149 149 149 - MONOSITE/weblech \n273 258 252 252 - MONOSITE/lusearch 593 454 447 447 - MONOSITE/avrora 288 278 272 - - RACE/elevator 475 \n440 437 437 437 RACE/hedc 23,033 22,043 21,966 - - RACE/weblech 7,286 4,742 4,669 - - RACE/lusearch 33,845 \n23,509 16,957 - - RACE/avrora 62,060 61,807 61,734 - -  tion curbs re.nement, but often, somewhat paradoxically, \nit is ex\u00adactly the re.nement which enables more pruning. Finally, Table 4 shows the effect on the number \nof queries proven. While pruning enables us to increase k much more than before, it turns out that our \nparticular analyses for these clients saturate quite quickly, so over all the clients and benchmarks, \nwe were only able to prove two queries more than using the non\u00adpruning techniques. On the surface, these \n.ndings seem to contra\u00addict [9], which showed a sharp increase in precision around k =4 for k-CFA. However, \nthis discrepancy merely suggests that our .ow-insensitive analyses are simply limited: since [9] offers \nup\u00adper bounds on precision, we know for sure that low k values are insuf.cient; the fact that we don \nt see an increase in precision for higher k suggests that the non-k-related aspects of our analyses are \ninsuf.cient. Given that our pruning approach is general, it would be interesting to tackle other aspects \nof program analysis such as .ow-sensitivity. 7. Related Work There is a wealth of literature which attempts \nto scale static anal\u00adyses without sacri.cing precision. One general theme is to work with a .exible family \nof abstractions, which in principle allows us to conform to the needs of the client. Milanova et al. \n[12, 13] consider abstractions where each local variable can be indepen\u00addently treated context-sensitively \nor context-insensitively, and dif\u00adferent k values can be chosen for different allocation sites. Lhot\u00b4 \nak and Hendren [7, 8] present Paddle, a parametrized framework for BDD-based, k-limited pointer analyses. \n[17] scale up k-object\u00adsensitivity, increasing k by one using types rather than allocation sites. However, \nin all of this work, which parts of the abstraction should be more re.ned is largely left up to the user. \n  Client-driven approaches use feedback from a client query to determine what parts of an abstraction \nto re.ne. Plevyak and Chien [15] use a re.nement-based algorithm for type inference, where context-sensitivity \nis driven by detecting type con.icts. Guyer and Lin [4] present a pointer analysis for C which detects \nloss of precision (e.g., at merge points) and introduce context\u00adsensitivity. Our method for determining \nrelevant input tuples is similar in spirit but more general. Section 3.1 of Liang et al. [10] (not the \nfocus of that work) also computes the set of relevant tuples by running a transformed Datalog program. \nHowever, what is done with this information is quite different there. [10] merely stops re.ning the irrelevant \nsites whereas we actually prune all irrelevant tuples, thereby exploiting this information more fully. \nAs we saw in Section 6, this difference had major rami.cations. Demand-driven analyses [5, 23] do not \nre.ne the abstraction but rather try to compute an analysis on an existing abstraction more ef.ciently. \nSridharan et al. [19] presents an algorithm which casts pointer analysis as a CFL-reachability problem \nand relaxes the problem by introducing additional match edges. Our Prune-Re.ne algorithm has a client-driven \n.avor in that we re.ne our abstraction, but also a demand-driven .avor in that we do not perform a full \ncomputation (in particular, ignoring tuples which were pruned). However, there are two important differences \nbetween the present work and the work described earlier: First, while most of that work is speci.c to \npointer analysis, our Prune-Re.ne algorithm is applicable to any Datalog program. Second, past work is \nbased on selected re.nement, which is orthogonal to pruning. Selected re.nement merely governs the abstractions \n(at)8 t=0 that we use, whereas pruning focuses on removing input tuples. Given that the input tuples \nencode the program analysis, pruning is analogous to program slicing.  Other forms of pruning have been \nimplemented in various set\u00adtings. [20] uses dynamic analysis to prune down the set of paths and then \nfocuses a static analysis on these paths. [18] uses pruning for type inference in functional languages, \nwhere pruning is simply a heuristic which shortcuts a search algorithm. As a result, pruning can hurt \nprecision. One advantage of our pruning approach is that it comes with strong soundness and completeness \nguarantees. 8. Conclusion We have introduced pruning as a general technique for scaling up static analyses \nwritten in Datalog. The basic idea is to run an anal\u00adysis using a coarse abstraction, only keeping input \ntuples deemed relevant, and then using a .ner abstraction on the remaining tuples. Theoretically, we \nshowed that pruning is both sound and complete (our analysis is valid and we lose no precision). Empirically, \nwe showed that pruning enables us to scale up analyses based on k\u00adobject-sensitivity much more than previous \napproaches. Acknowledgments We thank Mooly Sagiv and Hongseok Yang for discussion and useful feedback. \nWe also thank the anonymous reviewers for their insightful comments. References [1] T. Ball, R. Majumdar, \nT. Millstein, and S. Rajamani. Automatic predicate abstraction of C programs. In PLDI, pages 203 213, \n2001. [2] M. Bravenboer and Y. Smaragdakis. Strictly declarative speci.cation of sophisticated points-to \nanalyses. In OOPSLA, pages 243 262, 2009. [3] S. Graf and H. Saidi. Construction of abstract state graphs \nwith PVS. Computer Aided Veri.cation, 1254:72 83, 1997. [4] S. Guyer and C. Lin. Client-driven pointer \nanalysis. In SAS, pages 214 236, 2003. [5] N. Heintze and O. Tardieu. Demand-driven pointer analysis. \nIn PLDI, pages 24 34, 2001. [6] T. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre. Lazy abstrac\u00adtion. \nIn POPL, 2002. [7] O. Lhot\u00b4 ak and L. Hendren. Context-sensitive points-to analysis: is it worth it? \nIn CC, pages 47 64, 2006. [8] O. Lhot\u00b4ak and L. Hendren. Evaluating the bene.ts of context-sensitive \npoints-to analysis using a BDD-based implementation. ACM Transac\u00adtions on Software Engineering and Methodology, \n18(1):1 53, 2008. [9] P. Liang, O. Tripp, M. Naik, and M. Sagiv. A dynamic evaluation of static heap \nabstractions. In OOPSLA, pages 411 427, 2010. [10] P. Liang, O. Tripp, and M. Naik. Learning minimal \nabstractions. In POPL, 2011. [11] K. McMillan. Lazy abstraction with interpolants. In CAV, pages 123 \n136, 2006. [12] A. Milanova, A. Rountev, and B. Ryder. Parameterized object sensi\u00adtivity for points-to \nand side-effect analyses for Java. In ISSTA, pages 1 11, 2002. [13] A. Milanova, A. Rountev, and B. Ryder. \nParameterized object sensi\u00adtivity for points-to analysis for Java. ACM Transactions on Software Engineering \nand Methodology, 14(1):1 41, 2005. [14] M. Naik, A. Aiken, and J. Whaley. Effective static race detection \nfor Java. In PLDI, pages 308 319, 2006. [15] J. Plevyak and A. Chien. Precise concrete type inference \nfor object\u00adoriented languages. In OOPSLA, pages 324 340. [16] O. Shivers. Control-.ow analysis in Scheme. \nIn PLDI, pages 164 174, 1988. [17] Y. Smaragdakis, M. Bravenboer, and O. Lhotak. Pick your contexts well: \nUnderstanding object-sensitivity. In POPL, 2011. [18] S. A. Spoon and O. Shivers. Demand-driven type \ninference with subgoal pruning: Trading precision for scalability. In ECOOP, 2004. [19] M. Sridharan \nand R. Bod\u00b4ik. Re.nement-based context-sensitive points-to analysis for Java. In PLDI, pages 387 400, \n2006. [20] V. Vipindeep and P. Jalote. Ef.cient static analysis with path pruning using coverage data. \nIn International Workshop on Dynamic Analysis (WODA), 2005. [21] J. Whaley. Context-Sensitive Pointer \nAnalysis using Binary Decision Diagrams. PhD thesis, Stanford University, 2007. [22] J. Whaley and M. \nLam. Cloning-based context-sensitive pointer alias analysis using binary decision diagrams. In PLDI, \npages 131 144, 2004. [23] X. Zheng and R. Rugina. Demand-driven alias analysis for C. In POPL, pages \n197 208, 1998. A. Proofs Instead of directly proving Proposition 1, we state a more general theorem which \nwill be useful later: Theorem 3 (Soundness). Let a and \u00df be two abstractions with \u00dfa (\u00df is coarser), \nand let X be any set of input tuples. For any derivation a . D(a(X)), de.ne b =(b1,...,b|a|) where each \nbi is the unique element in \u00df(ai). Then b . D(\u00df(X)). Proof of Theorem 3. De.ne A = a(X) and B = \u00df(X). \nConsider a . D(A) and let b be as de.ned in the theorem. For each position i, we have two cases. First, \nif ai . A, then bi . (\u00df . a)(X)= \u00df(X)= B. Otherwise, let z .Z be the rule and J be the indices of the \ntuples used to derive ai. The same rule z and the corresponding tuples {bj : j . J} can also be used \nto derive bi. Therefore, b . D(B). Proof of Proposition 1 (abstraction is sound). Apply Theorem 3 with \n\u00df = a and a as the identity function (no abstraction). Before we prove Theorem 1, we state a useful lemma. \n Lemma 1 (Pruning is idempotent). For any set of tuples (concrete or abstract) X, P(X)= P(P(X)). Proof. \nSince P(X) . X by de.nition and P is monotonic, we have P(P(X)) . P(X). For the other direction, let \nx . P(X). Then x is part of some derivation (x . x . D(X)). All the input tuples of x (those in x n X) \nare also in P(X), so x . D(P(X)). Therefore x . P(P(X)). Proof of Theorem 1 (pruning is sound and complete). \nWe de.ne variables for the intermediate quantities in (15): A = a(X) and B = \u00df(X), B = P(B), A = a(B \n), and A ' = A n A . We want to show that pruning is sound (P(A) . P(A ' )) and complete (P(A) . P(A \n' )). Completeness follows directly because A . A ' and P is monotonic (increasing the number of input \ntuples can only increase the number of derived tuples). Now we show soundness. Let a . P(A). By de.nition \nof P ((3)), there is a derivation a . D(A) containing a. For each ai . a, let bi be the unique element \nin \u00df(ai) (a singleton set because \u00dfa), and let b be the corresponding sequence constructed from the bis. \nSince \u00dfa, we have b . D(B) by Theorem 3, and so each input tuple in b is also in P(B)= B ; in particular, \n b . B for \u00df(a)= {b}. Since \u00dfa, a . a(b), and so a . A . We have thus shown that P(A) . A . Finishing \nup, P(A ' )= P(A n A ) . P(A n P(A)) = P(P(A)) = P(A), where the last equality follows from idempotence \n(Lemma 1). We now show that the Prune-Re.ne algorithm is correct, which follows from a straightforward \napplication of Theorem 1. Proof of Theorem 2 (correctness of the Prune-Re.ne algorithm). First, we argue \nthat pre-pruning is correct. For each iteration t, we invoke Theorem 1 with a = at,\u00df = \u00dft and X be such \nthat a(X)= At. The result is that P(At)= P(A ' t), so without loss of generality, we will assume At = \nA ' t for the rest of the proof. Now .x an iteration t. We will show that P(at(X)) = P(At) by induction, \nwhere the inductive hypothesis is P(at(X)) = P(at(A s)). For the base case (s = -1), we de.ne A-1 = {X}, \nwe get a tautology. For the inductive case, apply the theorem with applied to \u00df = as,a = at and X such \nthat as(X)= as(A s-1), we get that P(at(A s-1)) = P(at(P(as(A s-1)))) = P(at(A s)). When s = t - 1, we \nhave P(at(X)) = P(at(A t-1)) = P(At), completing the claim. Finally, if the algorithm returns proven, \nwe have \u00d8 = P(At)= P(at(X)) . P(X).    \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Many static analyses do not scale as they are made more precise. For example, increasing the amount of context sensitivity in a <i>k</i>-limited pointer analysis causes the number of contexts to grow exponentially with <i>k</i>. Iterative refinement techniques can mitigate this growth by starting with a coarse abstraction and only refining parts of the abstraction that are deemed relevant with respect to a given client.</p> <p>In this paper, we introduce a new technique called <i>pruning</i> that uses client feedback in a different way. The basic idea is to use coarse abstractions to prune away parts of the program analysis deemed irrelevant for proving a client query, and then using finer abstractions on the sliced program analysis. For a <i>k</i>-limited pointer analysis, this approach amounts to adaptively refining and pruning a set of prefix patterns representing the contexts relevant for the client. By pruning, we are able to scale up to much more expensive abstractions than before. We also prove that the pruned analysis is both sound and complete, that is, it yields the same results as an analysis that uses a more expensive abstraction directly without pruning.</p>", "authors": [{"name": "Percy Liang", "author_profile_id": "81323492904", "affiliation": "University of California at Berkeley, Berkeley, CA, USA", "person_id": "P2690661", "email_address": "pliang@cs.berkeley.edu", "orcid_id": ""}, {"name": "Mayur Naik", "author_profile_id": "81100223912", "affiliation": "Intel Labs Berkeley, Berkeley, CA, USA", "person_id": "P2690662", "email_address": "mayur.naik@intel.com", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993567", "year": "2011", "article_id": "1993567", "conference": "PLDI", "title": "Scaling abstraction refinement via pruning", "url": "http://dl.acm.org/citation.cfm?id=1993567"}