{"article_publication_date": "06-04-2011", "fulltext": "\n Partial-Coherence Abstractions for Relaxed Memory Models Michael Kuperstein Martin Vechev Eran Yahav \n* Technion, Haifa, Israel IBM T.J. Watson Research Center Technion, Haifa, Israel mkuper@cs.technion.ac.il \nmtvechev@us.ibm.com yahave@cs.technion.ac.il Abstract We present an approach for automatic veri.cation \nand fence infer\u00adence in concurrent programs running under relaxed memory mod\u00adels. Veri.cation under relaxed \nmemory models is a hard problem. Given a .nite state program and a safety speci.cation, verifying that \nthe program satis.es the speci.cation under a suf.ciently re\u00adlaxed memory model is undecidable. For stronger \nmodels, the prob\u00adlem is decidable but has non-primitive recursive complexity. In this paper, we focus \non models that have store-buffer based semantics, e.g., SPARC TSO and PSO. We use abstract interpre\u00adtation \nto provide an effective veri.cation procedure for programs running under this type of models. Our main \ncontribution is a fam\u00adily of novel partial-coherence abstractions, specialized for relaxed memory models, \nwhich partially preserve information required for memory coherence and consistency. We use our abstractions \nto au\u00adtomatically verify programs under relaxed memory models. In ad\u00addition, when a program violates \nits speci.cation but can be .xed by adding fences, our approach can automatically infer a correct fence \nplacement that is optimal under the abstraction. We implemented our approach in a tool called BLENDER \nand applied it to verify and infer fences in several concurrent algorithms. Categories and Subject Descriptors \nD.1.3 [Concurrent Pro\u00adgramming]; D.2.4 [Program Veri.cation] General Terms Algorithms, Veri.cation Keywords \nConcurrency, Synthesis, Abstract Interpretation, Re\u00adlaxed Memory Models, Weak Memory Models 1. Introduction \nIn the early 1990s, features like out-of-order execution and multi\u00adlevel caches became common in commodity \nCPU architectures. These features drastically improved performance in a programmer\u00adtransparent fashion: \ntheir introduction did not change the semantics of existing (sequential) programs. With the advent of \nsymmetric multiprocessing and multi-core CPUs, preserving the illusion of in-order memory operations \nbecame more dif.cult. One possible approach is to keep the illusion known as sequential consistency [20] \nin a multi-processor setting and sacri.ce performance. The other is to de.ne architectural relaxed memory \nmodels (RMMs) that allow improved performance at the cost of weaker semantics. * Deloro Fellow Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 11, June 4 \n8, 2011, San Jose, California, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 \n A relaxed memory model allows observable executions that can\u00adnot occur if instructions running on different \nprocessors are sim\u00adply interleaved. As a result, a program that runs correctly on the sequentially-consistent \nmodel may violate its speci.cation when running on a relaxed memory model. In practice, relaxed mem\u00adory \nmodels are used by all major CPU designs, among them In\u00adtel x86 [33], SPARC [36] and PowerPC [16]. To \nenforce order between memory operations, these architectures provide special memory fence instructions. \nInformally, inserting a fence instruction prohibits certain re-orderings, thus restricting the set of \nrelaxed ex\u00adecutions. For example, a fence inserted between two store instruc\u00adtions will force these two \nstores to appear to execute in-order. It is the programmer s (or the compiler s) responsibility to correctly \nplace fences. Program Veri.cation and Fence Inference To place fences, the programmer must .rst be able \nto know whether the program is correct given a fence placement -in other words, she needs to be able \nto verify the program. However, veri.cation of concur\u00adrent programs is not an easy task even under the \nsequentially con\u00adsistent memory model. Relaxed memory models make reasoning about program correctness, \nboth manually and automatically, even harder, as they require reasoning about non sequentially-consistent \nexecutions. Even for .nite-state programs, automatic veri.cation under relaxed memory models is a hard \nproblem. Given a .nite state program and a safety speci.cation, verifying that the program satis.es a \nspeci.cation under a suf.ciently relaxed memory model (e.g., SPARC RMO) is undecidable. For somewhat \nstronger mem\u00adory models (e.g., SPARC TSO, PSO), the problem is decidable but has non-primitive recursive \ncomplexity [2]. Even given a veri.cation procedure, inserting fences is still non\u00adtrivial. On the one \nhand, since each fence incurs a heavy perfor\u00admance penalty, the programmer should not insert fences unless \nthey are strictly required for correctness. On the other hand, missing a fence may lead to subtle concurrency \nbugs. Store Buffers Relaxed memory models allow two basic relax\u00adations of sequential consistency: memory \noperations may be re\u00adordered with respect to each other, and stores may be executed non\u00adatomically across \nprocessors [1]. Some relaxations can be naturally modeled using store buffers [25], emulating the actual \nhardware implementation. In store-buffer based semantics, one or more FIFO queues ( store buffers ) are \nassociated with each processor. Mem\u00adory writes are split into two phases: a store phase and a .ush phase. \nThe store phase adds a value into a local store buffer, and the .ush phase propagates the stored value \nto main memory (or directly to other processors). The basic hurdle for automatic veri.cation under those \nmodels is that store buffers can grow without a bound, even for programs that are otherwise .nite state. \nTo enable automatic program veri.\u00adcation and fence inference on relaxed memory models, we need a technique \nthat can represent those buffers in a bounded way. Existing Approaches Existing approaches either employ \nunder\u00adapproximations such as bounded checking [5] and testing [8], or side-step the problem by focusing \non a restricted class of pro\u00adgrams. For instance, [32] considers data-race free programs, and [28] focuses \non programs free from a particular ( triangular ) type of data races. Bounded checking and testing are \nvaluable, but can\u00adnot establish that the program satis.es its speci.cation on all exe\u00adcutions. When used \nfor automatic fence inference, bounded tech\u00adniques (e.g., [5, 18]) might miss required fences. Targeting \nonly race-free programs simpli.es the problem by allowing considera\u00adtion of only sequentially-consistent \nexecutions. However, it is of\u00adten unrealistic, as many concurrent programs contain benign data races \n[27]. For example, some mutual exclusion algorithms, such as Dekker s algorithm, contain benign triangular \ndata races. Thus we cannot apply the results of [28], even if we restrict attention only to the TSO model. \nIn contrast to these approaches, our technique over-approximates possible program behaviors and is able \nto verify programs execut\u00ading under RMMs. When used for fence inference, our technique is guaranteed \nto produce all required fences. Our Approach We present a technique for automatic veri.ca\u00adtion and fence \ninference in .nite-state programs running on relaxed memory models. Based on abstract interpretation \n[9], we introduce a family of partial-coherence abstractions for store buffers. Our abstractions provide \na bounded representation for (potentially) un\u00adbounded store buffers. We use the term abstract memory \nmodel to refer to a memory model that uses an abstract structure to represent store buffers. Our approach \nprovides a range of abstractions with varying precision, enabling successive abstraction re.nements of \na given abstract memory model MA. Given a program P , a speci.cation S and an abstract mem\u00adory model \nMA, the question we are trying to answer is whether P |=MA S, that is, whether the program satis.es the \nspeci.cation under the given abstract memory model. When P |=MA S, it is possible to: Re.ne the abstraction: \nre.ne MA and try to .nd a more precise memory model MAl under which P |=MS. Al Restrict the program: \n.nd a program P I obtained from P by adding memory fences that restrict the permitted re-orderings during \nexecution, such that P I |=MA S. In this work, we focus on restricting the program by inserting fences, \nand show how using different abstract memory models affects the precision of the resulting fence placement. \nWe focus on a family of abstractions for the TSO and PSO memory models, as those models are implemented \nin common hardware (e.g., Intel x86 [29], SPARC) and have simple concrete operational semantics. Partial-Coherence \nAbstractions The challenge for abstractions of store buffers is to provide a bounded representation that \n(par\u00adtially) preserves the following three key properties (described in more detail in Section 2): Intra-process \nmemory coherence: a process should only see its own most recently written value to a variable.  Inter-process \nmemory coherence: a process should observe val\u00adues written by another process in the order they were \nwritten.  Fence semantics: a fence executed by a process writes to mem\u00ad  ory the most recent value \nwritten by the process. The main idea behind our abstractions is to preserve only a limited amount of \norder inherent in a store buffer. In particular, our abstract buffer representation preserves information \nabout: i) the most re\u00adcent store to a buffer, and ii) the order between a bounded number of the oldest \nstores in the buffer. While inter-process coherence is only partially preserved, we show this choice \nis particularly effec\u00adtive for verifying concurrent algorithms running on relaxed mem\u00adory models (see \nSection 4 for details). Process 0: Process 1: 1 while(true) 1 while(true) 2 { 2 { 3 store ent0 = true; \n3 store ent1 = true; 4 store turn = 1; 4 store turn = 0; 5 do 5 do 6 { 6 { 7 load e = ent1; 7 load e \n= ent0; 8 load t = turn; 8 load t = turn; 9 } 9 } 10 while(e==true &#38;&#38; t==1); 10 while(e==true \n&#38;&#38; t==0); 11 //Critical Section 11 //Critical Section 12 store ent0 = false; 12 store ent1 = \nfalse; 13 } 13 } Figure 1. Peterson s Algorithm with explicit memory operations Process 0: Process 1: \n1 while(true) 1 while(true) 2 { 2 { 3 store ent0 = true; 3 store ent1 = true; 4 fence; 4 fence; 5 store \nturn = 1; 5 store turn = 0; 6 fence; 6 fence; 7 do 7 do 8 { 8 { 9 load e = ent1; 9 load e = ent0;  10 \nload t = turn; 10 load t = turn; 11 } 11 } 12 while(e==true &#38;&#38; t==1); 12 while(e==true &#38;&#38; \nt==0); 13 //Critical Section 13 //Critical Section 14 store ent0 = false; 14 store ent1 = false; 15 } \n15 } Figure 2. Peterson s Algorithm with fences that guarantee mutual exclusion under the PSO memory \nmodel. Fences were automati\u00adcally inferred by our approach. 1.1 Main Contributions The main contributions \nof this paper are as follows: We describe a family of parametric abstractions that enable automatic \nveri.cation of safety properties for programs under relaxed memory models.  When a program violates \nits speci.cation but can be .xed by adding fences, our approach can automatically infer a correct fence \nplacement that is optimal under the given abstraction.  We have implemented our approach in a tool called \nBLENDER and applied it for veri.cation and fence inference of several challenging concurrent algorithms. \n  2. Overview 2.1 Motivating Example -Peterson s Algorithm Fig. 1 shows the code of Peterson s mutual \nexclusion algorithm [31]. In this algorithm, two processes repeatedly enter and exit a criti\u00adcal section. \nWe would like to show that the algorithm satis.es the mutual exclusion property: it is impossible for \nboth processes to be in the critical section simultaneously. Indeed, Peterson s algo\u00adrithm satis.es mutual \nexclusion under a sequentially-consistent (SC) memory model. Unfortunately, under relaxed memory mod\u00adels, \nsuch as Partial Store Order (PSO), the algorithm does not satisfy the property. To see why, we .rst give \na brief explanation of the PSO memory model. The Partial Store Order (PSO) Memory Model PSO is one of \nthree memory consistency models de.ned for the SPARC architec\u00adture [36]. In PSO, a store to some memory \nlocation l may become Figure 3. Store buffers for Peterson s algorithm of Fig. 1 under the PSO memory \nmodel. Note that buffers can grow without a bound.  visible to other processes only after the storing \nprocess executes later loads and stores to different memory locations. The PSO model can be formalized \noperationally by associating with each processor a set of FIFO queues (store buffers), one for each variable, \nas shown in Fig. 3. The informal semantics of store buffers for PSO can be summarized as follows: Store \nbuffering: A store issued by process pi to variable x is written into the store buffer associated with \n(pi,x).  Store forwarding: A load by pj from y is performed from its local store buffer (associated \nwith (pj ,y)) if it is not empty, or from the global memory otherwise.  Flushing: The oldest value stored \nin the buffer may be written to the global memory and removed from the buffer at non\u00addeterministic points \nin the execution.  The Problem: Delayed Stores Under the PSO model, the follow\u00ading execution of Peterson \ns algorithm is possible: p0 runs alone until line 11, however the store to ent0 in line 3 is written \nonly to the buffer but not .ushed.  p1 runs. Since the store to ent0 is delayed, it is not visible to \np1.  p1 enters the critical section, and mutual exclusion is violated. Peterson s algorithm relies on \nordering of loads and stores for synchronization. It requires p0 s store to ent0 to be visible to p1 \nbefore p0 loads ent1, and symmetrically on p1 s store to ent1 to be visible to p0 before p1 loads ent0. \nWhen the underlying memory model does not preserve this order, Peterson s algorithm, as it appears in \nFig. 1, does not satisfy mutual exclusion. Restoring Order with Fences To allow programmer control over \nordering in relaxed memory models, processors provide special memory fence instructions. Intuitively, \nthe semantics of a fence are that memory operations issued before the fence must take global effect before \nmemory operations after the fence may execute. In general, there are different kinds of fences (e.g., \nstore-load, store\u00adstore) that impose order between different types of operations. A store-load fence \nexecuted by a processor forces all stores issued by that processor to complete before any new loads by \nthe same processor start. In this paper we assume the model provides the strongest type of fence (a full \nmemory barrier ) that restricts reordering of any memory operations. In Fig. 2 the fences in lines 4 \nand 6 prevent the erroneous execution above (and other possible related bugs) by forcing the stores in \nlines 3 and 5 to take global effect before the storing process can advance. Unfortunately, fence instructions \nare very costly in terms of CPU cycles. Thus, we wish to place fences only when they are required for \ncorrectness. Ef.cient Fence Placement The programmer s challenge is, then, in .nding a fence placement \nthat permits as much re-ordering as possible but does not allow the speci.cation to be violated. To .nd \nan ef.cient placement of fences, we need to observe what re\u00adorderings lead to violation of the speci.cation, \nand .nd a minimal placement (often, there are multiple non-comparable solutions) that prevents these \nre-orderings. When the program is .nite-state, we can enumerate all reachable program states, identify \nerror states and .nd fences that prevent execution from reaching those states (c.f [18]). Unfortunately, \nPeterson s algorithm without fences run\u00adning on PSO has an in.nite state-space. The length of the store \nbuffers generated by the program is not bounded: running p0 alone for t iterations of the outer loop \nwithout .ushing will generate a buffer of length 2t for the ent0 variable. 2.2 Abstraction To handle \nprograms that have an unbounded state-space, we intro\u00adduce a family of parametric abstractions that provide \na conservative bounded representation. Our abstractions induce a hierarchy of (ab\u00adstract) memory models \nwith varying degrees of consistency. Before describing the abstraction, we note that concrete PSO semantics \npreserve the following 3 properties. 1. Intra-process coherence: If a process stores several values to \nshared variable x, and then performs a load from x, it should not see any value it has itself stored \nexcept the most recent one. 2. Inter-process coherence: A process pi should not observe values written \nto shared variable x by process pj in an order different from the order in which they were written. \n3. Fence semantics: If a process pi executes a fence when its buffer for variable x is non-empty, the \nvalue of x visible to other processes immediately after the fence should be the most recent value pi \nwrote.  The properties above are phrased in terms of PSO semantics (store buffer per variable), but \nit is easy to formulate similar properties for other memory models. For example, for TSO, the only change \nis that inter-process coherence is global and not per variable. In that case, the desired property may \nbe called inter-process consistency. Partial-Coherence Abstraction The challenge in designing an abstraction \nfor store-buffer based memory models lies in preserving properties 1-3 (to the greatest possible extent) \nusing a bounded rep\u00adresentation of each buffer. To preserve intra-process coherence, our abstractions \nmaintain recency information per variable. To preserve inter-process coherence, our abstractions preserve \norder between stores up to some constant bound (a parameter of our abstraction), and treat the remaining \nstores as an unordered set. While property 2 is not fully preserved, this partial coherence is often \nsuf.cient in practice. The intuition is that if a process stores many (possibly different) values to \nthe same shared variable without an intervening fence, the order in which they become visible is not \nimportant for the correctness of the algorithm. Fig. 4 shows a schematic view of a partial-coherence \nabstraction of PSO store buffers for the Peterson algorithm of Fig. 1. In this abstraction, a store buffer \nis represented by treating items after a bounded head (of length k) of the buffer as a set, and additionally \nrecording the most recently stored value for each buffer. In Section 3, we give a formal concrete semantics \nfor the PSO memory model and in Section 4 present our abstract semantics. Us\u00ading this abstraction with \nthe fence inference algorithm of Section 5, our approach automatically infers the fences shown in Fig. \n2. In Section 6, we show that we can use different parameters to achieve more scalable abstractions and \nstill get reasonable results. We also show that there is a tradeoff between the precision of the abstraction \nand the quality of the inferred fences. Finer abstractions lead to suc\u00adcessful inference with fewer fences, \nwhile restricting the program by adding fences enables veri.cation with a coarser abstraction. In particular, \nour partially disjunctive abstraction (see Section 4.3) produces non-trivial fence placements for programs \nfor which the fully disjunctive abstraction leads to state-space explosion.  Figure 4. A partial-coherence \nabstraction of PSO store buffers for the Peterson algorithm of Fig. 1. In this abstraction, a store buffer \nis given a bounded representation by representing items after a bounded head of the buffer as a set, \nand recording the recently stored value for each buffer. 3. Operational Semantics for Relaxed Memory \nModels In this section, we present an operational semantics for the PSO memory model. It is easy to give \nsimilar semantics for other con\u00adceptually close models such as TSO, NTSO and NPSO [24]. 3.1 Preliminaries \nSequence Notation Given a .nite domain D, we use Seqn(D) to denote the set of all sequences of length \nn over D, Seq=n(D) to denote the set of all sequences shorter than or equal in length to n over D, Seq(D) \nto denote the set of all .nite sequences over D, |w| to denote the length of a sequence w and E to denote \nan empty sequence. We denote the concatenation of two sequences w1,w2 by w1 \u00b7 w2. For k> |w|, we de.ne \nhead(w, k) as the subsequence consisting of the .rst k items in w and tail(w, k) as the subsequence consisting \nof the last k items in w. For 0 <k = |w| we de.ne head(w, k)= tail(w, k)= w and for k = 0, head(w, k)= \ntail(w, k)= E. We de.ne last(w) to be the only element in tail(w, 1), or . if tail(w, 1) = E . We de.ne \nSet(w) to be the set of elements in the sequence w. Finally, we de.ne UT ail(w, k) as Set(tail(w, |w|- \nk)) the set of all but the .rst k elements of w. Program Syntax We consider programs written in a simple \nassembly-like programming language with the operations load, store, branch, CAS (compare and swap) and \nsequential and paral\u00adlel composition. Our language also contains a full fence operation. We assume that \ninstructions in our programs are labeled, and the labels used in the code of process are unique. We denote \nthe set of program labels by Labs. Program Semantics A transition system for a program P under a memory \nmodel M is a tuple (s0, S,T ), where S is a set of states, s0 . S is the initial state of P , and T is \na set of transitions t t s -. sI. A transition s -. sI is in T if s, sI . S, and execution from state \ns according to the semantics of M can result in state sI. A trace p of the program is a (possibly in.nite) \nsequence of transitions s0 . s1 . s2 . ..., where for all i, si -. si+1 . T . In all of our semantics, \na single transition will correspond to action taken by a single process. Thus we will associate a transition \nt with that process, and denote the associated process proc(t).A transition tp is enabled for process \np in state s if p = proc(tp) and tp there exists some s2 such that s -. s2 . T . Throughout the paper \nwe present the semantics in a standard operational style as a set of inference rules. To simplify presenta\u00adtion, \nwhen updating mappings, we use MI(x)= v as a shorthand for MI = M[x . v]. Components not updated in the \ninference rule are assumed to be left unchanged. 3.2 Store Buffers In our memory model semantics we \nfollow [2, 7, 25] and assume that processes execute their programs sequentially, and any vio\u00adlations \nof sequential consistency happen within the memory sub\u00adsystem. This is in contrast to other formulations \nthat combine the memory and processor effects (e.g., [30, 35, 41]). Our formulation is based on store-buffers, \nand our concrete semantics uses the following semantic domains: G. . SV ar where SV ar = Shared . D. \nValuation of shared variables from the domain D.  L. . Env where Env = PID . (Local . D). Valuation \nof local variables for each process.  pc. . PC where PC = PID . Labs. Program counters.  B. . SB where \nSB differs between different memory models, and is intentionally left unspeci.ed at this stage. A representa\u00adtion \nof the store buffers.  Here D represents the domain from which the variables in the program take values. \nA state s = (Gs.,L.s, pcs,Bs.). C. is a tuple where C. = SV ar \u00d7 Env \u00d7 PC \u00d7 SB. We use next(pc(p)) to \nmean the instruction following pc(p) in the program code. Furthermore, we will omit the p when the referenced \nprocess is clear from the context. 3.3 Partial Store Order (PSO) Model Concrete Semantics For PSO, a \nseparate FIFO store buffer is maintained for every (process, variable) pair. That is, formally, SB = \nPID . (Shared . Seq(D)) Semantics 1 Operational semantics de.ning transition from (G, L, pc, B) to (GI,LI \n, pc I,BI) under PSO. stmt(pc)= loadx,r B(x)= EG(x)= v (LOAD-G) Ll(r)= v pc l = next(pc) stmt(pc)= loadx,r \nB(x)= b \u00b7 v ll (LOAD-B) L(r)= v pc = next(pc) stmt(pc)= storer,x B(x)= bL(r)= v (STORE) Bl(x)= b \u00b7 v \npc l = next(pc) B(x)= v \u00b7 b (FLUSH) Bl(x)= bGl(x)= v stmt(pc)= fence .x.B(x)= E (FENCE) pc l = next(pc) \nstmt(pc)= cas x,r,s,q G(x)= L(r) L(s)= vB(x)= E lll (CAS-T) G(x)= vL(q)= true pc = next(pc) stmt(pc)= \ncasx,r,s,q G(x) = L(r) B(x)= E ll (CAS-F) L(q)= false pc = next(pc) Sem. 1 shows the concrete operational \nsemantics of the PSO model. Each inference rule applies only to a single process. Thus, the p parameter \nis consistently omitted in all inference rules pre\u00adsented. However it is always implicitly existentially \nquanti.ed. For example, the premise of the LOAD-G rule should be read as .p.stmt(pc(p)) = load x, r \n. B(p)(x)= E . G(x)= v The semantics show the role played by the store buffer for stor\u00ading and loading \nvalues to/from main memory (STORE, LOAD-G, LOAD-B, FLUSH). The FENCE and CAS rules have memory fence \nsemantics. These two rules are enabled only when the buffer of the executing process is empty. This means \nthat when a process en\u00adcounters, e.g., a fence instruction, it cannot continue execution until all of \nthe buffers are .ushed. For simplicity we omit the se\u00admantics of instructions that do not access shared \nmemory (regis\u00adter operations, branches) and leave expression evaluation implicit. That is, L(r) is extended \nto the evaluation of complex expressions r. Such a complex expression may only depend on local variables \nexpression evaluation may not cause a memory access. The premise of all rules except FLUSH depends on \nthe program counter of the process. They are enabled only if pc(p) points to an instruction of a speci.c \ntype. The FLUSH rule, on the other hand, is always enabled for a given buffer B(p)(x) if that buffer \nis not empty. This captures the fact that .ushes can be performed non\u00addeterministically at any stage \nof program execution.  3.4 Total Store Order (TSO) Model The TSO concrete state differs from the PSO \nconcrete state only in the de.nition of the store buffer. For TSO, there is only a single, buffer for \nall variables of a process. That is, SB = PID . Seq(Shared \u00d7 D). The semantics must also be updated to \ntake the difference into account. The .avor of the required changes can be seen in the TSO version of \nthe LOAD-G rule in Sem. 2. Note that as the difference between PSO and TSO lies purely in the grouping \nof shared variables into store buffers, we can treat them as special cases of the same general model. \nSemantics 2 LOAD-G rule for concrete TSO stmt(pc)= load x, r .(y, d) . B.y = xG(x)= v ll (LOAD-G) L(r)= \nv pc = next(pc) 4. Partial-Coherence Abstractions In this section, we present a family of abstract memory \nmodels that abstract the concrete semantics of Section 3. The presentation fo\u00adcuses on abstractions of \nthe SPARC PSO model, but the adapta\u00adtion to TSO is straight-forward. The main idea behind our partial\u00adcoherence \nabstractions is to vary how much of the order between memory operations we preserve. The ability to vary \nthe precision is useful as different algorithms can be veri.ed with different lev\u00adels of precision and \ncost. When the abstraction is used for fence inference, Section 6 shows that there exists a trade-off \nbetween the precision of the analysis (which affects the state-space size) and the quality of inferred \nfences. 4.1 Abstract Domain The abstract domain is designed to represent store buffers in a bounded \nway by losing order information between items past a certain bound. To achieve this goal, we represent \na concrete buffer B by a tuple (l, S, H). The l . D element records the latest (most recent) value that \nwas written into the buffer. H . Seq=k(D) records the k oldest values in the buffer (in the original \norder) if those are known. S . D records a set of values that were written into the buffer, abstracting \naway the order between them, as well as the number of times each elements appears in the buffer. Formally, \nwe de.ne, for a buffer B : \u00dfB (B )= (last(B ), UT ail(B ,k), head(B ,k)) An abstract state s is a tuple \n(G, L, pc, B) where G, L and pc are de.ned as in the concrete semantics. B maps a (process, shared variable) \npair to the tuple (l, S, H) de.ned earlier. To simplify notation, we will use short-hands such as lp(x) \nto represent the l element of B(p)(x). As in the concrete semantics, we will often omit the p. We denote \nby A the set of all abstract states. To de.ne the abstract domain, we de.ne several order relations. \nThe order gb is de.ned on (l, S, H) tuples: (l1,S1,H1)gb (l2,S2,H2) if l1 = l2 and: .t.H2 = head(H1,t) \n. S2 = S1 . UT ail(H1,t) Intuitively, (l2,S2,H2) is produced from (l1,S1,H1) by removing part of the \ntail end of H1 and adding all the removed elements into the set. We then use gb to de.ne a partial order \ngs on abstract states s1 = (G1,L1, pc1,B1),s2 = (G2,L2, pc2,B2): s1 gs s2 if the two states coincide \non G, L, pc and: .p, x.B1(p)(x) gb B2(p)(x) Finally, we de.ne our abstract domain A . 2A as the set \nof all antichains of A. That is: A = {S . A |.s, . . S.s = . . s gs .} The order relation g: A\u00d7 Ais \nde.ned as: S1 g S2 iff .s1 . S1..s2 . S2.s1 gs s2 The join operator over A, implied by the above order, \nis: S1 U S2 = {s . S1 . S2 |.. . (S1 . S2).s = . . s g .} We de.ne the abstraction function a:2C. A \nusing an extraction function \u00df : C . A: a(S) = {\u00df(s)} s.S \u00df(s)= (Gs,Ls, pcs,\u00df B ) \u00df B = .p, x.\u00dfB (Bs(p)(x)) \n The intuition behind this abstraction is shown in Fig. 3. That .gure can, however, be slightly misleading: \nit is important to note the entire concrete buffer is covered by the concatenation of values from S to \nH. Speci.cally, l does not need to be concatenated to the end. Thus if S = \u00d8, then l is always equal \nto the last element of H and is in fact redundant. If S = \u00d8, then l . S is an invariant. A more precise \nrepresentation of the abstraction is given in Fig. 5. Fig. 5(a) shows the case in which the concrete \nbuffer is longer than k and Fig. 5(b) shows the case in which the concrete buffer is of length at most \nk. The Importance of Recency Our abstraction uses l to record the most recent value stored for a variable. \nThis is motivated by the need to preserve the intra-process coherence requirement that a process storing \nseveral values to a shared variable x, and then performing a load from x, should not see any value it \nhas itself stored except the most recent one. This is a very basic property and abstractions that do \nnot preserve this information will fail to verify many reasonable programs. Partial Inter-Process Coherence \nThe abstract domain only par\u00adtially preserves the inter-process coherence requirement. For ex\u00adample, \nsuppose processor p stores the values a and then b to the variable x. The resulting concrete buffer Bp(x) \nis ab . Taking k =0, the abstract buffer is B = \u00dfB( ab ) = (a, {a, b},E). Note that, for example, \u00dfB \n( ab ) = \u00dfB( aba ). So given the abstract buffer B we must allow a different process q to observe the \nval\u00adues being written in the opposite order. Worse, since, for example,  (a) The length of the buffer \nis higher than k (b) The length of the buffer is at most k Figure 5. Abstraction of a single buffer \n\u00dfB ( ab ) = \u00dfB ( abab ) it is possible for process q to observe the stores in the opposite order, and \nfor a third process r to observe them in the original order. This behavior occurs only if a process performs \nmore than k stores to the same memory location without an intervening fence or CAS. As long as at most \nk stores to a memory location are performed without an intervening fence, the abstract domain is fully \nprecise. Abstract Domain Design One of our observations is that in a correct program a process rarely \nperforms an unbounded number of stores to a memory location without a fence. When a process does perform \na large number of stores to a memory location without a fence, it means that the order in which these \nstores are performed is not important for program correctness. Following this observation, our abstraction \nis designed to: (i) preserve the order between a small number of stores to the same memory location; \n(ii) abstract away the order in long sequences of stores but preserve the stored values, such that values \ncannot appear out of thin air . Given that programmers do not normally think in terms of unordered stores, \nwe expect many correct programs to only utilize very short buffers. This is validated by our results \n(c.f Section 6) correct versions of the benchmark algorithms could be veri.ed using k =1. However, there \nare examples of correct programs where buffers may become very long. One such example is the Sieve of \nEratosthenes implementation in [3], which only requires that values do not appear out of thin air. Furthermore, \nwe wish our veri.cation procedure to remain sound for arbitrary programs. This is impossible using bounded \nbuffers, as it is trivial to construct an incorrect program which would appear to be correct using bounded \nbuffers of some given length k. Similarly, when the abstraction is used for fence infer\u00adence, we wish \nto always infer a correct placement. This is impossi\u00adble if we simply bound the buffer length. Domain \nof Variables Throughout this paper we do not specify the domain D from which local and shared variables \ntake values. However, the domain is in fact critically important to the effective\u00adness of the abstraction. \nLet d be the number of values a shared vari\u00adable may potentially take during the execution of a program. \nThen the number of possible H values for that variable is dk, and the number of possible S values is \n2d. Since in the worst case, d = |D|, we may expect an increase in state-space size (w.r.t state-space \nun\u00adder SC) that is exponential in |D|. The examples we used for our experiments do not suffer from this \nproblem, as the variables only take a small number of values in any given execution. However, for different \nprograms this may become a real issue. Note, however, that our abstraction can be trivially composed \nwith value abstrac\u00adtions (e.g., sign abstraction, parity abstraction, interval abstraction [10]). Instead \nof using the concrete domain D, we can replace it with an abstract value domain D.. We can then store \nthose abstract values in the buffer and perform local operations on values accord\u00ading to the semantics \ndictated by D., retaining a sound abstraction.  4.2 Abstract Semantics Sem. 3 shows the abstract semantics \nwith partial coherence pa\u00ad def rameterized by k. In the .gure, we use the shorthand emp(x)= H(x)= E \n. S(x)= \u00d8. Loading Values and Recency In the concrete semantics, a pro\u00adcess may load the latest value \nit wrote by reading its own store buffer. Correspondingly, in the abstract semantics, the rule LOAD-B \nreads the most recent value recorded in l. Had we not recorded the most recent value l that a process \nwrote, a process p that performs a load when Sp(x)= \u00d8 would have to conservatively explore all possible \nvalues in the set Sp(x). The rule LOAD-G is similar to the concrete semantics: when the buffer is known \nto be empty, the value is loaded from global store. Storing Values In the abstract semantics, store is \nsplit into two cases STORE-H and STORE-S, based on whether the size of the buffer H(x) has reached the \nbound k. As long as |H(x)| <k and S(x)= \u00d8, the contents of the buffer are known precisely. Thus, similarly \nto the concrete semantics, the effect of a store follows STORE-H, adding the value to the tail of the \nbuffer H(x) and updating the most recent value l(x). When |H(x)| = k, the size of the buffer H has been \nexceeded and no more values can be stored in H. Therefore, the new value is stored in the (unordered) \nset of values S(x) (as shown in the rule STORE-S) and the most recent value l(x) is updated accordingly. \nWhen S(x)= \u00d8 we have lost the information on the precise number of elements on the buffer, and thus are \nalso forced to keep updating the set. Flushing Values In the abstract semantics, flush is split into \nthree cases: FLUSH-H, FLUSH-SN and FLUSH-SD. When we have H(x)= E then FLUSH-H behaves as the FLUSH rule \nin the concrete semantics: it selects the oldest element in H(x), writes it to G(x) and updates H(x). \nHowever, when H(x)= E and S(x)= \u00d8, any of the values in S(x) become possible candidates for .ushing (since \nS(x) is unordered, we do not know which value is the oldest one). The rules FLUSH-SD (.ush from set, \ndestructive) and FLUSH-SN (.ush from set, non-destructive) then only differ on whether the value selected \nto be .ushed is removed from S(x) or kept in it. This is required since we do not know how many times \nevery value appears in the buffer. Thus, in the concrete domain, FLUSH-SD of a value v represents a .ush \nof the last occurrence of v in the buffer. In contrast, FLUSH-SN represents the situation in which more \ninstances of v remain. We improve the precision of the analysis by disabling the FLUSH-SD rule when we \nknow that the resulting abstract states do not represent any possible concrete states and will only intro\u00adduce \nimprecision. In particular, if v = l(x) and S(x)= {v}, FLUSH-SD need not .re. If we apply the concrete \nFLUSH rule to any concretization of such a state, the value v will stay in the (concrete) buffer, while \nif we .ush v from the abstract state using FLUSH-SD, it will remove v from the abstract buffer, leading \nto abstract states that could not arise in the concrete semantics. Example: Motivating Recency and Order \nNext, we illustrate via an example why maintaining recency and order is important for ver\u00adi.cation and \ninference. Consider a naive set abstraction for the store buffers, and a version of Peterson s algorithm \nwith fences shown in Fig. 2 (in Section 2). Under standard concrete semantics of PSO, Semantics 3 Abstract \noperational semantics de.ning transition from (G, L, pc, B) to (GI,LI , pc I,B) stmt(pc)= load x, r \nemp(x) v = G(x) ll (LOAD-G) L(r)= v pc = next(pc) stmt(pc)= load x, r \u00acemp(x) v = l(x) (LOAD-B) Ll(r)= \nv pc l = next(pc) stmt(pc)= store r, x S(x)= \u00d8 H(x)= h |h| <k L(r)= v (STORE-H) Hl(x)= h \u00b7 vll(x)= v \npc l = next(pc) stmt(pc)= store r, x S(x)= ss = \u00d8.|H(x)| = kL(r)= v (STORE-S) lll S(x)= s .{v} l(x)= \nv pc = next(pc) H(x)= v \u00b7 h (FLUSH-H) Hl(x)= hGl(x)= v H(x)= Ev . S(x) l(FLUSH-SN) G(x)= v H(x)= Ev \n. S(x) \u00ac(v = l(x) . S(x)= {v}) ll(FLUSH-SD) G(x)= vS(x)= S(x) \\ v stmt(pc)= fence .x.emp(x) (FENCE) \npc l = next(pc) stmt(pc)= cas x,r,s,q emp(x) L(r)= G(x) L(s)= v lll (CAS-T) G(x)= vL(q)= true pc = next(pc) \nstmt(pc)= casx,r,s,q emp(x) L(r)= G(x) ll (CAS-F) L(q)= false pc = next(pc) those fences guarantee that \nit is impossible for both processes to be concurrently executing line 13. Let us consider an abstract \nmemory model where order and recency are not maintained, that is, we only maintain Sp(x) but without \nmaintaining lp(x) and Hp(x). Then, we cannot show that the algorithm is correct. Consider the follow\u00ading \nexecution: 1. Initially both processes start with empty buffers, and ent0= ent1= turn =0. 2. Process \n0 runs through one iteration of the outer loop (executes lines 1-14 inclusively), without performing \na .ush after line 14. 3. Process 0 then tries to enter the critical section again and executes lines \n1-3 inclusively. At this stage, Sp0 (ent0) = {true, false}. 4. Two .ush actions are performed on Sp0 \n(ent0), .rst .ushing true and then false. At this point G(ent0) = false. 5. Process 0 completes entering \nthe critical section. 6. Process 1 loads ent0 from global store and since ent0 is false  process 1 \nalso enters the critical section. The above example would not have been possible had we kept either: \ni) ordering information via Hp(ent0) for at least two values (i.e., k =2) or ii) recency information \nvia lp(ent0). In the .rst case, the order in which {true, false} are .ushed would have been consistent \nwith the order in which the values were written: we would have .rst .ushed false and then true. In the \nsecond case, the fence in line 4 would have forced fully .ushing Sp0 (ent0), resulting in writing out \nthe most recent value (i.e., G(ent0) = true). While in this case we could have used either lp(ent0) or \nHp(ent0) with k =2, in other examples both of these re.nements with respect to a set are required.  \n4.3 A Partially Disjunctive Abstraction for Store Buffers The abstraction of Section 4.1 distinguishes \ntwo abstract buffers B1 = (l1,S1,H1),B2 = (l2,S2,H2) even when they differ only on the contents of their \nunordered sets S1 = S2. This leads to distinctions between abstract states that are often more precise \nthan necessary. We observe that a more ef.cient abstraction can be obtained without a signi.cant sacri.ce \nin precision by merging such states. In Section 6, we show that combining such states leads to a more \nscalable abstraction, while keeping a suf.cient level of precision. The one distinction that we do wish \nto preserve regarding the S component is the difference between an empty set and a non-empty set, as \nmany of the rules in Sem. 3 distinguish between these two cases. To capture this, we change the de.nition \nof gb as follows: The order g t is de.ned on (l, S, H) tuples. b (l1,S1,H1)gt (l2,S2,H2) b if l1 = l2 \nand one of the two following conditions holds: (1) H1 = H2 = E . S1 = S2 = \u00d8 (2) S1 = \u00d8..t.H2 = head(H1,t) \n. S2 . S1 . UT ail(H1,t) The orders gst and g t are then de.ned exactly as before but with respect to \ng t instead of gb. at is also de.ned as before, but b using t instead of . Note that this small change \nin the formalism drastically changes the intuitive meaning of the set S. Let B = (l, S, E) be an abstract \nbuffer, and B a concrete buffer such that \u00dfB (B ) g t B. In the fully-disjunctive abstraction, this implies \nb that Set(B )= S. This means that a value v was in S if and only if it appeared at least once in B \n. In the partially-disjunctive abstraction, this is no longer true. Consider the concrete buffer a . \nAssuming k =0, \u00dfB ( a ) = (a, {a},E)gb (a, {a, b},E). If a value appears at least once in B then it is \nnecessarily in S, but the converse does not hold. The new abstraction also implies a change to the abstract \ntrans\u00adformer. In the fully disjunctive abstraction, .ushes from S were split into two cases: FLUSH-SD \nto represent .ushing the last in\u00adstance of a value from the buffer, and FLUSH-SN to represent an instance \nthat is not the last one. The case split for the partially dis\u00adjunctive abstraction is slightly different. \nThe new .ush semantics are shown in Sem. 4. The rule FLUSH-NE covers the case in which a .ush leaves \nS non-empty, while FLUSH-E represents .ushing the only remaining element of the concretization of the \nabstract buffer. Note that it s possible for both types of .ush rules to be enabled for the same buffer. \nSemantics 4 Partially-disjunctive .ush semantics H(x)= Ev . S(x) (FLUSH-NE) Gl(x)= v H(x)= ES(x)= \u00d8 \n(FLUSH-E) ll G(x)= l(x) S(x)= \u00d8 5. Fence Inference In this section, we introduce a new technique for \ninferring mem\u00adory fences under store-buffer based abstract memory models. For our algorithm, we follow \nthe same general recipe as outlined in [40]: (i) Construct (a possibly abstract) transition system and \n.nd the reachable error states. (ii) Construct a boolean formula that de\u00adscribes how traces leading to \nthose error states can be avoided. (iii) Implement satisfying assignments of the formula using syn\u00adtactic \nconstructs. The main challenge in implementing this general recipe is in de.ning which transitions may \nbe avoided, and how they can be avoided syntactically. Next, we present the de.nitions that are ap\u00adpropriate \nfor each of our semantics: concrete, fully-disjunctive and partially-disjunctive. We also show an example \ndemonstrating the interplay between the precision of the abstraction and the quality of inferred fences. \n 5.1 Recoverability of Sequential Consistency Before we introduce the details of the inference algorithm, \nwe note that the problem always has a trivial (inef.cient) solution under concrete memory models. However, \nfor some abstract memory models, the problem no longer has a solution. We would like to restrict attention \nto abstractions in which the existence of a solution is guaranteed. Consider a program P that satis.es \nits speci.cation S under the sequentially consistent memory model, P |= SC S, but violates it under a \nweaker memory model M, P |= M S. We say that M is SC-Recoverable (SCR) when for any such P there exists \na program P I obtained from P by adding fences such that P I |= M S. For SC-Recoverable memory models, \nwhen P |= SC S, the trivial solution in which fences are added after every memory store in P always exists. \nThis property might seem trivial, however it is easy to design seemingly reasonable abstract models for \nwhich it does not hold. For instance, as demonstrated in Section 6, a partial\u00adcoherence abstraction with \nrecency and k =0 does not satisfy the SCR property. For the partial coherence abstractions of Section \n4, k = 1 guarantees SC-Recoverability. If we place a fence immediately after every store instruction, \nthen i) |H| can never grow above 1 so stores cannot become visible out of order and ii) the store cannot \nbe observed by the process itself before it is .ushed. In effect this makes the store and .ush operations \natomic, reducing the program s behaviors to those possible under sequential consistency.  5.2 Fence \nInference under Concrete Semantics Buffers of Labeled Stores The semantics given in Section 3 do not \npreserve enough information about program execution to en\u00adable fence inference. Using those semantics, \nit is not possible to determine that a given memory operation was delayed by exam\u00adining only the source \nstate and the transition associated with the operation. Therefore, we instrument the concrete semantics \nwith additional information about the instruction that stored each value. To achieve this, for a process \np and variable x, we extend the store buffer Bp(x) . Seq(Labs \u00d7 D) to be a sequence of pairs (l, v). \nFor every value stored we also record the label of the program in\u00adstruction that stored the value. Avoiding \nError States Let P be a program, and (s0, S,T ) be the program s transition system. Every transition \nt . T that is not a .ush transition is associated with a instruction in the code that caused the transition. \nWe denote by lt the label of this instruction. Our goal is to construct a program P I by inserting fences \ninto P such that the state-space of P I does not contain any error states. To remove a state from the \nstate-space, we must prohibit all program traces that contain it. The question then becomes how can a \nprogram trace be prohibited? The intuition behind the recipe of [40] is that program traces can be classi.ed \nas either avoidable and unavoidable. The classi.cation is performed according to the syntactic device \nwe have to eliminate traces. In our setting, the syntactic device used to prohibit traces is a tp memory \nfence. If a trace p contains a store transition si -. si+1 by process p which is not immediately followed \nby a .ush of the stored value, we can prohibit p by placing a fence immediately after the store. This \nmeans a trace is unavoidable if and only if every store is immediately followed by a .ush.We can re.ne \nthe concept of an avoidable trace and talk about avoidable transitions. A transition tp performed by \nprocess p is avoidable if it is a memory operation (store, load or CAS), and some store buffer associated \nwith p is non-empty. t Formally, let t be the transition s -. t. Let v be a value written by the instruction \nat label lv such that (l, v) appears in some buffer Bs,p(x). Then t is avoidable, and can be avoided \nby placing fences on all program paths between lv and lt, forcing the value v to be .ushed before lt \nis reached. We formalize this by de.ning ordering constraints: we say an ordering constraint [lv -lt] \nis enforced if a fence is placed on all program paths between lv and lt. We say the constraint is violated \nby a transition if lt is executed while a value stored by lv is in the buffer. A constraint is violated \nby a trace if it is violated by one of its transition. Note that if a constraint is enforced by a fence, \nit cannot be violated by any transition. This implies a trace p of P cannot appear in P I if at least \none of the constraints it violates is enforced in P I. This fact gives us a complete characterization \nof how a state can be removed from the state-space: by enforcing at least one constraint that is violated \nby each trace leading to that state. We call this characterization the avoid formula of a state. A direct \nimplementation of the method described above to com\u00adpute the avoid formulae would be very inef.cient, \nas it requires enumerating all program traces. Below we give a brief description of a more ef.cient algorithm. \nA fuller description, albeit in a dif\u00adferent setting, is given in [18]. As a .rst stage in the algorithm \nwe construct the transition sys\u00adtem (s0, S,T ). We then label every state s . S with a propo\u00adsitional \nformula that captures how s can be made unreachable (avoided) through the use of ordering constraints. \nIntuitively, a state s can be avoided by avoiding all incoming transitions to s in the program s transition \nsystem. In turn, a single transition \u00b5 . s can be avoided by either avoiding its source state \u00b5 or by \nprohibiting the transition itself. We associate with each transition t . T a formula:  prevent(t)={[l \n-lt] |.x, v.(l, v). Set(Bsrc(t),proc(t)(x))} Here, we use proc(t) to denote the process that executes \nthe tran\u00adsition t and src(t) to denote the source state of the transition. This formula captures all \npossible ordering constraints that would prohibit execution of t. Formally, it is a disjunction because \nit is enough to enforce one of the constraints to make t unreachable. To compute how a state s . S can \nbe avoided, we de.ne a labeling function L and: avoid(L, s)={(L(\u00b5) . prevent(t)) | t =(\u00b5 . s) . T } \n We then de.ne a transformer that updates the labeling function: infer(L)= L[s . (L(s) . avoid(L, s))] \n Given an initial mapping L0 that maps all unavoidable states to false and the rest to true, the greatest \n.xed point of infer(L0) describes all the possible ways in which any state s can be avoided. The greatest \n.xed point is computed with respect to implication partial order L1 g L2 =.s . S.L1(s) . L2(s). Using \nthe provided speci.cation, we identify a set E . S of reachable error states. We then compute the overall \nconstraint formula . by taking the conjunction of avoid constraints for all error states: k . = {L(s) \n| s . E}. A satisfying assignment to this formula is guaranteed to represent a correct fence placement. \n 5.3 Inference under Abstract Semantics We can extend the abstract model in the same way we extended \nthe concrete model. That is, Hp(x) and Sp(x) will contain (label, value)pairs. 5.3.1 Inference under \nDisjunctive Abstraction Using the abstract semantics of Sec. 4.2, we can construct an ab\u00adstract transition \nsystem for the program, and apply the same reason\u00ading as in the concrete semantics, except that we adjust \nprevent(t): Qs,p(x)= Ss,p(x) . Set(Hs,p(x)) prevent(t)= {[l -lt] |.x, v.(l, v). Qsrc(t),proc(t)(x)} \nThis adjustment is safe because we know that if (lv,v). Qp(x), then for any concretization s of s, Bs \n(x) must contain (lv,v) ,pat least once. This means that placing a fence between any such lv and lt is \nsuf.cient to avoid t from s . Note that it is possible to infer more fences than necessary due to the \nimprecision of the abstraction. Consider the simple example in Fig. 6, with the speci.cation that in \na .nal state r1 = r2. If we attempt to execute this program under partial-coherence semantics with k \n=0, we may get a trace where in the .nal state we have r1=2, r2=1: (a) Process 1 performs both stores. \n(b) Process 1 .ushes the value 2. (c) Process 2 performs the load at line 1. (d) Process 1 .ushes the \nvalue 1. (e) Process 2 performs the load at line 2. The single avoidable transition in this trace is \nthe execution of the second store by process 1. The only way to avoid this transition is by placing a \nfence between the two stores. However, if we increase the precision of the abstraction and use k =1, \nwe will not produce this (spurious) trace and will not infer the redundant fence. Process 1: Process \n2: 1 store x = 1; 1 load r1 = x; 2 store x = 2; 2 load r2 = x; Figure 6. Fully disjunctive partial-coherence \nabstraction with k = 0 leads to a redundant fence between the stores in Process 1, while with k = 1 the \ninference algorithm determines that no fences are necessary.  5.3.2 Inference under Partially Disjunctive \nAbstraction For the abstract semantics of Sec. 4.3, we need to adjust prevent(t): prevent(t)= {[l -lt] \n|.x, v.(l, v). Qsrc(t),proc(t)(x)} The only change from the fully disjunctive abstraction is in re\u00ad ok \nplacing with . The reason for this change becomes clear once we examine the concretization function for \nthe partially disjunc\u00adtive abstraction. As pointed out in the previous section, given an abstract state \ns and a non-empty Ss,p(x), there exist concretized states which do not contain all values in Ss,p(x). \nSince prohibit\u00ading a transition from s requires prohibiting that transition from all concrete states \nrepresented by s, prevent(t) must be a conjunc\u00adtion over the possible prevent formulas in the concrete \ndomain. For many transitions, this formula will be stronger than the opti\u00admal one, potentially leading \nto a fence placement worse than the one produced by the fully disjunctive abstraction with the same k \nvalue.  5.4 Fine-grained fence inference The inference algorithm described above generates sets of con\u00adstraints \nthat must be enforced so that the speci.cation is satis.ed. One simple way to enforce a constraint [l1 \n-l2] is by placing a full fence on every path between l1 and l2 on the control-.ow graph of the program. \nIf .ner-grained fences are available on the architecture we can use information encoded in the constraint \nto implement it more ef.ciently. For example if the architecture pro\u00advides separate store-store and store-load \nfences we can place the appropriate fence based on whether the instruction at l2 is a store or a load. \nIf the architecture provides fences that enforce .ushing only one variable (e.g., CAS in our concrete \nPSO semantics) then we can place the correct fence type based on the variable written to by l1. For simplicity, \nin Section 6 we assume the only fence available is a full fence. However, whenever inference succeeds \nwe could trivially place .ner-grained fences. 6. Experience We implemented our abstractions together \nwith the veri.cation and inference algorithms in a tool called BLENDER. Using BLENDER, we demonstrate \nthe effectiveness of our abstractions by successfully verifying and inferring the required fences in \na number of challeng\u00ading algorithms. None of these algorithms could be handled by exist\u00ading approaches. \nFurther, we illustrate an inherent trade-off between the optimality of fence inference and the state-space \nsize dictated by the abstraction. BLENDER is implemented in Java and uses the JavaBDD library to represent \navoid formulae as BDDs. All experiments were con\u00adducted on an 8-CPU Xeon 1.6GHz with 16GB memory running \na 64-bit Sun JVM on Red Hat Linux. Abstractions In our experiments, we consider a range of abstract memory \nmodels, all of which are abstractions of the concrete PSO memory model: Set: an abstraction of the store \nbuffer to a set, without any additional information such as recency.  FD: the partial coherence abstraction \nshown in Sem. 3, with varying k.  PD: the partially disjunctive abstraction described in Sec. 4.3. \n Note that the Set abstraction and FD/PD with k =0 are generally not SC-Recoverable. Thus, it is possible \nthat during fence inference, BLENDER will report the program as impossible to .x. 6.1 Benchmarks To evaluate \nour tool, we chose various classic concurrent algo\u00adrithms such as well-known mutual exclusion algorithms \n(mutex) and synchronization barrier algorithms. All algorithms were exer\u00adcised in a loop by two concurrent \nprocesses ( repeated entry ): Dekker s Algorithm [11]. To evaluate both inference and veri.\u00ad cation \nwe used two versions: Dek0: has no added fences and is incorrect under the PSO memory model. Dek2: has \ntwo added fences and is known to be correct.  Peterson s Algorithm [31], using two versions, Pet0 and \nPet2.  A variation of Lamport s Bakery [19] using two versions, Lam0 and Lam2. To make this algorithm \n.nite-space we manually bounded the maximum ticket number at 2.  Lamport s Fast Mutex [21] using two \nversions, Fast0 and Fast3.  CLH queue lock [26] using two versions, CLH0 and CLH2  Centralized sense-reversing \nsynchronization barrier [14] using  two versions Sense0 and Sense1. For the mutual exclusion, the speci.cation \nis that there cannot be more than one process inside the critical section. Release seman\u00adtics for operations \nwithin the critical section are not enforced. The benchmarks were selected based on two criteria: Novelty \nThe benchmarks could not be handled by any of the pre\u00advious approaches. For instance, as mutual exclusion \nalgorithms in\u00adherently contain benign data races, using techniques like delay set analysis [34] would \nresult in a gross over-estimation of the required fences. Furthermore, some of the benchmarks for instance \nDek and Fast contain benign triangular data races (as de.ned in [28]). Thus, even if we focus squarely \non the TSO memory model, we could not use the results of [28] to establish the correctness of the algorithms \nby focusing only on sequentially consistent execu\u00adtions. Finally, all of the benchmarks contain unbounded \nspin-loops, and as such, they cannot be handled directly using the bounded techniques of [18] or [5]. \n Simplicity Our focus in this work has been abstracting the effect of the relaxed memory model in isolation \nfrom other sources of unboundedness. Hence, we chose our algorithms to be .nite-state when executed under \nthe SC model. We defer the problem of ver\u00adifying in.nite-state programs using abstract memory models \n(e.g., by composing our abstractions with heap or predicate abstractions) to future work.  6.2 Veri.cation \nTab. 1 shows the veri.cation results produced by BLENDER with three abstractions. The programs we used \nhere are the ones we know to be correct under the concrete PSO semantics, that is, appropriate fences \nhave been placed in advance. All veri.cation runs completed within 30 seconds. Each entry in the table \ncontains the total number of states explored (in thousands). A mark is placed if veri.cation succeeded \nand a 0 mark if a spurious (ab\u00adstract) counter-example was found. In some of the runs of CLH2, BLENDER \nexhausted the available memory, and thus we do not re\u00adport the state-space size. However, in both those \ncases an (abstract) counter-example was found before BLENDER ran out of memory. Prog. Set F Dk=0 F Dk=1 \nSense1  0.6 1.7 0.8 Pet2 0 7.7 2.4 1.8 Dek2 0 9.7 4.5 3.1 Lam2 0 41.2 22.2 9 Fast3 0 22.2 0 \n16.4 11.1 CLH2 0 M 0 M 68.8 Table 1. Veri.cation results and number of states (in thousands). 6.2.1 \nDiscussion As Tab. 1 shows, none of the correct examples could be veri.ed using the naive set abstraction, \nhowever all of them could be veri\u00ad.ed using FD with k =1. Since veri.cation of all examples suc\u00adcessfully \ncompleted with FD, there was no need to use the PD ab\u00adstraction. The table also shows FDk=0 generated \nspurious counter\u00adexamples for CLH2 and Fast3 but not the other algorithms. When k =0, the partial-coherence \nabstraction (FDk=0) reduces to the set abstraction with recency information. This is enough to verify \nthe simpler algorithms, however it fails on the more complex ones. The example of Lamport s fast mutex \nis particularly interest\u00ading, as it demonstrates the type of executions possible with non SC-recoverable \nabstractions. Consider the code in Fig. 7. In this implementation a process can enter the critical section \neither along the fast path (the if condition in line 15 is false) or along the slow path (the conditions \nis true). Under an abstract model with k =0, the following execution is possible: Process 1 enters the \ncritical section along the fast path, executes it, and runs until line 29.  Process 1 executes line \n29. At this point S1(y)= {0}.  Process 1 .ushes y non-destructively, using the FLUSH-SN rule. Now G(y)=0. \n Process 2 enters the critical section. Since G(y)=0 it enters along the fast-path setting y =2 in the \nprocess. This is .ushed destructively using the FLUSH-SD rule. At this point G(y)= 2, S1(y)= {0}, S2(y)= \n\u00d8.  Process 1 resumes. It .rst performs a .ush of y, setting G(y)=  0. Then it proceeds to enter the \ncritical section again, using the fast path. This execution relies on the fact p1 only stored the value \n0 to y once, but this store is .ushed twice. In effect, p2 observed this store as if it happened before \nits own, and p1 observed it as if it happened after the store of p2. This coherence violation would have \nbeen prevented if we kept more information in the content of the buffer, by using k> 0. Indeed, with \nk =1, Fast3 passes veri.cation. 1 while(true) 15 if (x = i) { 2 { 16 store b[1] = false; 3 start: 17 \ndo { 4 store b[i] = true; 18 load other_b = b[3-i]; 5 store x = i; 19 } while (other_b = 0); 6 load local_y \n= y; 20 load local_y = y; 7 if (local_y = 0) { 21 if (local_y = i) 8 store b[i] = false; 22 { 9 while(local_y \n= 0) 23 while(local_y = 0) 10 load local_y = y; 24 load local_y = y; 11 goto start; 25 goto start; 12 \n} 26 } 13 store y = i; 27 } 14 load local_x = x; 28 //Critical Section 29 store y = 0; 30 store b[i] \n= false; 31 } Figure 7. A version of Lamport s fast mutex algorithm for 2 pro\u00adcessors. The code given \nis for process i.  6.3 Inference In Tab. 2 we show the state-space size and inference results for 5 \nof the under-fenced implementations. A mark of means the optimal fences were inferred, ( 0 means that \nsub-optimal fences were inferred, and 0 means that BLENDER was unable to infer fences as according to \nthe analysis any fence placement would leave the program incorrect. M appears if BLENDER ran out of memory. \nProg. F Dk=0 F Dk=1 P Dk=0 P Dk=1 P Dk=2 Sense0 (0 57.6 58.6 (0 31.9 44.3 6.1 Pet0 69.2 524.5 (0 \n25.3 (0 244.7 1124.2 Dek0 424.2 3238.1 (0 16.5 (0 358.1 2350.0 Lam0 M M - (0 421.0 (0 4045.9 M - \nFast0 M - M - 0 220.6 M - M - Fast1a (0 139.0 105.2 0 33.0 88.1 41.9 Fast1b (0 832.9 972.3 0 78.6 \n(0 501.6 878.4 Fast1c M - M - 0 110.4 (0 1173.4 1858.1 CLH0 M - M - M - M - M - Table 2. Inference \nresults and number of states (in thousands). 6.3.1 Discussion Initially, we used BLENDER to perform \nfence inference with abstrac\u00adtions FDk=0 and FDk=1. However, BLENDER ran out of memory for Lam0, Fast0, \nand Fast1c. Using the partially disjunctive ab\u00adstraction PDk=0 enabled us to run the inference algorithm \nfor both Lam0 and Fast1c and obtain a sound fence placement for both. Fur\u00adthermore, despite the loss \nof precision in the PD abstraction, in both cases the inferred fences are not trivial. 6.3.2 Peterson \ns Algorithm Our results for Peterson s algorithm demonstrate the inherent trade\u00adoffs between inference \noptimality and abstraction precision: With the FD abstraction BLENDER was able to infer the optimal \nfence placement with k =0. With the PD abstraction it required k =2 and a much larger state-space.  \nWith the PDk=0 abstraction we can produce a smaller state space but the result is suboptimal: 3 fences \nare required instead of 2. In addition to the two fences shown in Fig. 2, another fence, immediately \nafter the store in line 14, is inferred.  The same trade-off can also be observed when using a similar \npartial-coherence abstraction of the TSO model. For k =0 and k =1 suboptimal fence placement is generated, \nwhile with k =2 the result is optimal (for TSO).  6.3.3 Lamport s Fast Mutex For both Fast0 and Sense0, \nwe experienced a loss of precision when using a k value that is too small. In the case of Fast0, the \ninference algorithm reported the program as un.xable when using PDk=0. This is due to the fact the counter-example \npresented for Fast3 under this abstract model cannot be .xed with any number of fences. Unfortunately, \nBLENDER was unable to build the state-space of Fast0 under PDk=1. Thus, we ve run a complementary set \nof experiments in which 1 of the 3 required fences was placed. The 3 versions of Lamport s fast mutex \n(Fig. 7) we have ran had a single fence inserted: (i) between lines 5 and 6 (Fast1a), (ii) between lines \n13 and 14 (Fast1b), (iii) between lines 29 and 30 (Fast1c). As expected, for all 3 programs, when running \nunder PDk=0 the program was un.xable. However, in all 3 cases we were able to infer a correct fence placement \nusing PDk=1. Furthermore, for Fast1a and Fast1b the optimal placement of the two other fences was found \nwhen using PDk=2. For Fast1c even with k =2 the placement was still suboptimal. This demonstrates another \nexample of the interplay between the placed fences and the precision of the required abstraction. Even \nthough for Fast1c we could not infer the optimal fence placement using PDk=1, had we placed them manually, \nthis abstraction could be used to verify them. 7. Related Work Data-Race Freedom Guarantee A common technique \nto reduce the complexity of analyzing programs under relaxed memory mod\u00adels is to focus only on programs \nthat have no data-races under sequentially consistent executions. For such programs the funda\u00admental \nproperty of memory models [32] (also known as the DRF theorem) ensures that there can be no sequentially \ninconsistent exe\u00adcutions. Owens (in [28]) studies a generalization of this theorem for the x86-TSO model. \nTo guarantee correctness under this model one needs only to prove sequentially consistent executions \nsatisfy tri\u00adangular race-freedom , a property weaker than general data race\u00adfreedom. In our work, we \nfocus on abstractions of arbitrary pro\u00adgrams and unlike these methods, we can handle programs that con\u00adtain \ndata-races, such as common lock-free algorithms and mutual exclusion primitives. Checking Equivalence \nTo Sequential Consistency In [6] and [7] algorithms are presented that can, based only on sequentially \nconsistent executions, .nd violations of sequential consistency un\u00adder the TSO and PSO memory models. \nSimilarly, it is possible to place fences to preserve only SC executions using Delay Set Anal\u00adysis ([34]), \nfor instance as implemented in the Pensieve compiler ([12, 22]). However, a violation of SC does not \nnecessarily cause a violation of any high-level properties. Thus those algorithms are of\u00adten needlessly \nconservative. Our approach, on the other hand, uses a high-level speci.cation and allows a trade-off \nbetween precision and optimality of the solution. Explicit Model Checking for Relaxed Memory Models [17, \n18, 30] describe explicit-state model checking under the Sparc RMO model. Among those, [18] focuses on \nfence inference. [15] also describes an explicit-state model checking and inference technique for the \n.NET memory model, but it suffers from signi.cant tech\u00adnical drawbacks (c.f. [18]). However, the techniques \npresented in [18] are not applicable in our setting. (i) The FENDER algorithm described in [18] can only \ninfer fences for programs that are .nite\u00adstate under the relaxed memory model, and not under the sequen\u00adtially \nconsistent model. While this distinction might seem subtle, it is in fact signi.cant. For example, FENDER \nrelies on .nite clients of lock-free data structures being .nite-state. Unfortunately, there is no guarantee \nthat a data structure that is lock-free under SC will stay lock-free under a relaxed model. More generally, \nany code that uses a spin-loop with a store in the loop body will always be in.nite-state under a relaxed \nmodel, unless the store is followed by a fence. Since classical implementations of synchronization prim\u00aditives \nuse this code pattern, it is not possible to use FENDER to in\u00adfer fences in those implementations. In \ncontrast, the technique we present in this paper requires the input to be .nite-state only under SC. \n(ii) More technically, the algorithm is phrased in terms of ex\u00adecution buffer semantics. Adapting it \nto store-buffer semantics is challenging, especially in the abstract case. In [5], Burckhardt et. al \ntake a different approach to veri.cation under RMM. Instead of working with operational memory mod\u00adels \nand explicit model-checking, they convert programs into a form that can be checked against an axiomatic \nmodel speci.cation. This technique still suffers from the same limitation it must unroll loops at a \npreprocessing stage. Thus it cannot verify programs that contain unbounded spinning. In contrast, our \nveri.cation approach is based on abstract interpretation and is sound for any input pro\u00adgram and any \nvalues of the abstraction parameters. An alternative approach, in the spirit of [5, 18], is to assume \na bound on the size of buffers or the number of loop iterations. Combined with iter\u00adative increase of \nthe bound, this may work for some examples but not in the general case. In addition, using an abstraction \nis bene\u00ad.cial not only when the buffers are unbounded. Even if the buffer is bounded, the concrete state-space \nmay simply be too large while in fact representing the buffers with full precision is not important \nto the correctness of the algorithm. Synchronization Inference In [38, 40], the authors propose al\u00adgorithms \nthat automatically infer synchronization constructs such as atomic sections and conditional critical \nregions. These works assume sequential consistency and do not support weak memory models. The approach \nof [38] is close to our work in spirit, and deals with inferring synchronization under abstraction, but \nit enu\u00admerates traces explicitly, which does not scale to our setting. In [37, 39], inference of synchronization \nis performed by syn\u00adtactic exploration of placements of atomic sections to create can\u00addidate algorithms, \nand using a backing veri.er to attempt veri.ca\u00adtion of each candidate. In principle, a similar approach \ncan be em\u00adployed for fence inference by exploring candidate algorithms with all possible fence placements. \nIn contrast, our constraint-based ap\u00adproach lays the ground for inference of more advanced fences, such \nas fence per variable, and conditional fences, for which syntactic exploration will yield a non-feasible \nnumber of candidates. Alternative Buffer Abstractions In [23] the authors use automata as symbolic representation \nof store buffers in the TSO memory model. Their approach uses an acceleration technique that does not \nguarantee termination. Furthermore, their automata-based rep\u00adresentation preserves redundant information, \nand as noted by the authors themselves, ends up being too expensive to be of practical interest. Since \nstore buffers are similar to FIFO channels in commu\u00adnicating FSMs (CFSMs), it is tempting to employ techniques \nfrom CFSMs in our context as well. These techniques include algorithms based on symbolic representation \nof channel content (e.g., [4]), and conservative abstractions for FIFO channels (e.g., [13]). Abstrac\u00adtion \nof FIFO channels, as presented in [13], is similar in spirit to our approach in that it guarantees termination \nby using approxima\u00adtion. However, their abstraction preserves a slightly different kind of information \nthan the information required for reasoning about store buffers. They use a regular abstraction of queue \ncontent and an expensive widening operation to establish correct usage of pro\u00adtocols. This is more than \nwhat is required in our setting in terms of characterization of buffer content, and often less than needed \nin terms of recency information. In contrast to these, our technique guarantees termination by using \nconservative approximation, and our abstractions are tailored to relaxed memory models. 8. Conclusions \nand Future Work We present an approach for automatic veri.cation and fence infer\u00adence for concurrent \nprograms running under relaxed memory mod\u00adels. Our approach is based on abstract interpretation, and \nits tech\u00adnical core is a family of partial-coherence abstractions that provide a (parametric) bounded \nrepresentation for potentially unbounded store buffers. Our abstractions enable us to automatically verify \nconcurrent algorithms without worrying about the size of the un\u00adderlying store buffers. Because partial \ncoherence abstractions are designed to be SC-Recoverable, they can be used for automatic in\u00adference of \nmemory fences. We have implemented our approach in a tool called BLENDER and applied it to verify several \ncorrectly\u00adfenced concurrent algorithms and automatically infer fences in under-fenced versions of these \nalgorithms. In the future, we plan to combine our abstractions with heap abstractions to enable veri\u00ad.cation \nof heap-manipulating programs under RMMs. Acknowledgments The authors wish to thank Noam Rinetzky and \nGreta Yorsh for their comments on earlier drafts of this paper. This research was partially supported \nby The Israeli Science Foundation (grant no. 965/10). References [1] ADVE, S. V., AND GHARACHORLOO, K. \nShared memory consis\u00adtency models: A tutorial. IEEE Computer 29 (1995), 66 76. [2] ATIG, M. F., BOUAJJANI, \nA., BURCKHARDT, S., AND MUSUVATHI, M. On the veri.cation problem for weak memory models. In POPL (2010), \npp. 7 18. [3] BOEHM, H.-J. Threads cannot be implemented as a library. SIGPLAN Not. 40, 6 (2005), 261 \n268. [4] BOIGELOT, B., GODEFROID, P., WILLEMS, B., AND WOLPER, P. The power of QDDs. In SAS (1997), Springer, \npp. 172 186. [5] BURCKHARDT, S., ALUR, R., AND MARTIN, M. M. K. Check-Fence: checking consistency of \nconcurrent data types on relaxed mem\u00adory models. In PLDI (2007), pp. 12 21. [6] BURCKHARDT, S., AND MUSUVATHI, \nM. Effective program veri.\u00adcation for relaxed memory models. In CAV (2008), pp. 107 120. [7] BURNIM, \nJ., SEN, K., AND STERGIOU, C. Sound and complete mon\u00aditoring of sequential consistency in relaxed memory \nmodels. Tech. Rep. UCB/EECS-2010-31. [8] BURNIM, J., SEN, K., AND STERGIOU, C. Testing concurrent pro\u00adgrams \non relaxed memory models. Tech. Rep. UCB/EECS-2010-32. [9] COUSOT, P., AND COUSOT, R. Abstract interpretation: \nA uni.ed lat\u00adtice model for static analysis of programs by construction of approxi\u00admation of .xed points. \nIn POPL (1977), pp. 238 252. [10] COUSOT, P., AND COUSOT, R. Systematic design of program analysis frameworks. \nIn POPL (1979), pp. 269 282. [11] DIJKSTRA,E.Cooperatingsequentialprocesses,TREWD-123.Tech. rep., Technological \nUniversity, Eindhoven, 1965. [12] FANG, X., LEE, J., AND MIDKIFF, S. P. Automatic fence insertion for \nshared memory multiprocessing. In ICS (2003), pp. 285 294. [13] GALL, T. L., JEANNET, B., AND JRON, T. \nVeri.cation of commu\u00adnication protocols using abstract interpretation of FIFO queues. In AMAST (2006), \npp. 204 219. [14] HENSGEN, D., FINKEL, R., AND MANBER, U. Two algorithms for barrier synchronization. \nInt. J. Parallel Program. 17, 1 (1988), 1 17. [15] HUYNH, T. Q., AND ROYCHOUDHURY, A. Memory model sensitive \nbytecode veri.cation. Form. Methods Syst. Des. 31, 3 (2007). [16] IBM. Power ISA v.2.05. 2007. [17] JONSSON, \nB. State-space exploration for concurrent algorithms under weak memory orderings: (preliminary version). \nSIGARCH Comput. Archit. News 36, 5 (2008), 65 71. [18] KUPERSTEIN, M., VECHEV, M., AND YAHAV, E. Automatic \ninfer\u00adence of memory fences. In FMCAD (2010), pp. 111 119. [19] LAMPORT, L. A new solution of Dijkstra \ns concurrent programming problem. Commun. ACM 17, 8 (1974), 453 455. [20] LAMPORT, L. How to make a multiprocessor \ncomputer that correctly executes multiprocess program. IEEE Trans. Comput. 28, 9 (1979), 690 691. [21] \nLAMPORT, L. A fast mutual exclusion algorithm. ACM Trans. Comput. Syst. 5, 1 (1987), 1 11. [22] LEE, \nJ., AND PADUA, D. A. Hiding relaxed memory consistency with a compiler. IEEE Trans. Comput. 50, 8 (2001), \n824 833. [23] LINDEN, A., AND WOLPER, P. An automata-based symbolic ap\u00adproach for verifying programs \non relaxed memory models. In SPIN (2010), pp. 212 226. [24] MADOR-HAIM, S., ALUR, R., AND MARTIN, M. \nM. K. Generating litmus tests for contrasting memory consistency models. In CAV (2010), pp. 273 287. \n[25] MADOR-HAIM, S., ALUR, R., AND MILO, M. Plug and Play Com\u00adponents for the Exploration of Memory Consistency \nModels. Tech. Rep. MS-CIS-10-02, University of Pennsylvania, 2010. [26] MAGNUSSON, P. S., LANDIN, A., \nAND HAGERSTEN, E. Queue locks on cache coherent multiprocessors. In Proceedings of the Int. Symp. on \nParallel Processing (1994), IEEE, pp. 165 171. [27] NARAYANASAMY, S., WANG, Z., TIGANI, J., EDWARDS, \nA., AND CALDER, B. Automatically classifying benign and harmful data races using replay analysis. In \nPLDI (2007), pp. 22 31. [28] OWENS, S. Reasoning about the implementation of concurrency abstractions \non x86-TSO. In ECOOP (2010). [29] OWENS, S., SARKAR, S., AND SEWELL, P. A better x86 memory model: x86-TSO. \nIn TPHOLs (2009), pp. 391 407. [30] PARK, S., AND DILL, D. L. An executable speci.cation and veri.er \nfor relaxed memory order. IEEE Trans. on Computers 48 (1999). [31] PETERSON, G. L. Myths about the mutual \nexclusion problem. Inf. Process. Lett. 12, 3 (1981), 115 116. [32] SARASWAT, V. A., JAGADEESAN, R., MICHAEL, \nM., AND VON PRAUN, C. A theory of memory models. In PPoPP (2007), ACM, pp. 161 172. [33] SARKAR, S., \nSEWELL, P., NARDELLI, F. Z., OWENS, S., RIDGE, T., BRAIBANT, T., MYREEN, M. O., AND ALGLAVE, J. The se\u00admantics \nof x86-cc multiprocessor machine code. In POPL (2009), pp. 379 391. [34] SHASHA, D., AND SNIR, M. Ef.cient \nand correct execution of parallel programs that share memory. ACM Trans. Program. Lang. Syst. 10, 2 (1988), \n282 312. [35] SHEN, X., ARVIND, AND RUDOLPH, L. Commit-reconcile &#38; fences (CRF): a new memory model \nfor architects and compiler writers. SIGARCH Comput. Archit. News 27, 2 (1999), 150 161. [36] SPARC INTERNATIONAL, \nINC. The SPARC architecture manual (version 9). Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 1994. \n[37] VECHEV, M., AND YAHAV, E. Deriving linearizable .ne-grained concurrent objects. In PLDI (2008), \npp. 125 135. [38] VECHEV, M., YAHAV, E., AND YORSH, G. Abstraction-guided synthesis of synchronization. \nIn POPL (2010), pp. 327 338. [39] VECHEV, M. T., YAHAV, E., BACON, D. F., AND RINETZKY, N. CGCExplorer: \na semi-automated search procedure for provably cor\u00adrect concurrent collectors. In PLDI (2007), pp. 456 \n467. [40] VECHEV, M. T., YAHAV, E., AND YORSH, G. Inferring synchroniza\u00adtion under limited observability. \nIn TACAS (2009), pp. 139 154. [41] YANG, Y., GOPALAKRISHNAN, G., AND LINDSTROM, G. UMM: an operational \nmemory model speci.cation framework with integrated model checking capability. Concurr. Comput. : Pract. \nExper. 17, 5-6 (2005), 465 487.     \n\t\t\t", "proc_id": "1993498", "abstract": "<p>We present an approach for automatic verification and fence inference in concurrent programs running under relaxed memory models. Verification under relaxed memory models is a hard problem. Given a finite state program and a safety specification, verifying that the program satisfies the specification under a sufficiently relaxed memory model is undecidable. For stronger models, the problem is decidable but has non-primitive recursive complexity.</p> <p>In this paper, we focus on models that have store-buffer based semantics, e.g., SPARC TSO and PSO. We use abstract interpretation to provide an effective verification procedure for programs running under this type of models. Our main contribution is a family of novel <i>partial-coherence</i> abstractions, specialized for relaxed memory models, which partially preserve information required for memory coherence and consistency. We use our abstractions to automatically verify programs under relaxed memory models. In addition, when a program violates its specification but can be fixed by adding fences, our approach can automatically infer a correct fence placement that is optimal under the abstraction. We implemented our approach in a tool called BLENDER and applied it to verify and infer fences in several concurrent algorithms.</p>", "authors": [{"name": "Michael Kuperstein", "author_profile_id": "81485643328", "affiliation": "Technion, Haifa, Israel", "person_id": "P2690536", "email_address": "mkuper@cs.technion.ac.il", "orcid_id": ""}, {"name": "Martin Vechev", "author_profile_id": "81100269652", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P2690537", "email_address": "mtvechev@us.ibm.com", "orcid_id": ""}, {"name": "Eran Yahav", "author_profile_id": "81100285431", "affiliation": "Technion, Haifa, Israel", "person_id": "P2690538", "email_address": "yahave@cs.technion.ac.il", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993521", "year": "2011", "article_id": "1993521", "conference": "PLDI", "title": "Partial-coherence abstractions for relaxed memory models", "url": "http://dl.acm.org/citation.cfm?id=1993521"}