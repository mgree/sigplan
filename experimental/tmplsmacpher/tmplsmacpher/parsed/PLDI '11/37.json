{"article_publication_date": "06-04-2011", "fulltext": "\n Cause Clue Clauses: Error Localization using Maximum Satis.ability * Manu Jose Rupak Majumdar University \nof California, Los Angeles MPI-SWS, Kaiserslautern &#38; mjose@cs.ucla.edu University of California, \nLos Angeles rupak@mpi-sws.org Abstract Much effort is spent by programmers everyday in trying to reduce \nlong, failing execution traces to the cause of the error. We present an algorithm for error cause localization \nbased on a reduction to the maximal satis.ability problem (MAX-SAT), which asks what is the maximum number \nof clauses of a Boolean formula that can be simultaneously satis.ed by an assignment. At an intuitive \nlevel, our algorithm takes as input a program and a failing test, and com\u00adprises the following three \nsteps. First, using bounded model check\u00ading, and a bound obtained from the execution of the test, we \nencode the semantics of a bounded unrolling of the program as a Boolean trace formula. Second, for a \nfailing program execution (e.g., one that violates an assertion or a post-condition), we construct an \nun\u00adsatis.able formula by taking the formula and additionally asserting that the input is the failing \ntest and that the assertion condition does hold at the end. Third, using MAX-SAT, we .nd a maximal set \nof clauses in this formula that can be satis.ed together, and output the complement set as a potential \ncause of the error. We have implemented our algorithm in a tool called BugAssist that performs error \nlocalization for C programs. We demonstrate the effectiveness of BugAssist on a set of benchmark examples \nwith injected faults, and show that in most cases, BugAssist can quickly and precisely isolate a few \nlines of code whose change eliminates the error. We also demonstrate how our algorithm can be modi.ed \nto automatically suggest .xes for common classes of errors such as off-by-one. Categories and Subject \nDescriptors D.2.5 [Software Engineer\u00ading]: Testing and Debugging Fault-localization; F.3.2 [Log\u00adics and \nMeaning of Programs]: Semantics of Programming Languages Program Analysis General Terms Veri.cation,Reliability \nKeywords Debugging, Fault localization, Maximum Satis.ability * This research was sponsored in part by \nthe NSF grant CCF-0546170 and the DARPA grant HR0011-09-1-0037. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, \nUSA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 1. Introduction A large part \nof the development cycle is spent in debugging, where the programmer looks at a long, failing, trace \nand tries to localize the problem to a few lines of source code that elucidate the cause of the problem. \nWe describe an algorithm for fault localization for software that automates this process. The input to \nour algorithm is a program, a correctness speci.cation (either a post-condition, an assertion, or a golden \noutput ), and a program input and corre\u00adsponding execution (called the failing execution) that demonstrates \nthe violation of the speci.cation. The output is a minimal set of program statements such that there \nexists a way to replace these statements such that the failing execution is no longer valid. Internally, \nour algorithm uses symbolic analysis of software based on Boolean satis.ability, and reduces the problem \nto maxi\u00admum Boolean satis.ability. It takes as input a program and a failing test case and performs the \nfollowing three steps. First, it constructs a symbolic trace formula for the input program. This is a \nBoolean formula in conjunctive normal form such that the formula is sat\u00adis.able iff the program execution \nis feasible (and every satis.able assignment to the formula corresponds to the sequence of states in \na program execution). The trace formula construction proceeds identically to symbolic execution or bounded \nmodel checking al\u00adgorithms [2, 6, 15]. Second, it extends the trace formula by conjoining it with con\u00adstraints \nthat ensure the initial state satis.es the values of the failing test and the .nal states satisfy the \nprogram post-condition that was failed by the test. The extended trace formula essentially states that \nstarting from the test input and executing the program trace leads to a state satisfying the speci.cation. \nObviously, the extended trace formula for a failing execution must be unsatis.able. Third, it feeds the \nextended trace formula to a maximum satis.\u00adability solver. Maximum satis.ability (MAX-SAT) is the problem \nof determining the maximum number of clauses of a given Boolean formula that can be satis.ed by any given \nassignment. Our tool computes a maximal set of clauses of the extended trace formula that can be simultaneously \nsatis.ed, and takes the complement of this set as a candidate set of clauses that can be changed to make \nthe entire formula satis.able. Since each clause in the extended trace formula can be mapped back to \na statement in the code, this process identi.es a candidate localization of the error in terms of program \nstatements. Note that there may be several minimal sets of clauses that can be found in this way, and \nwe enumerate each minimal set as candidate localizations for the user. In our experiments, we have found \nthat the number of minimal sets enumerated in this way re\u00admains small. More precisely, our algorithm \nuses a solver for partial MAX-SAT. In partial MAX-SAT, the input clauses can be marked hard or soft, \nand the MAX-SAT instance .nds the maximum number of soft clauses that can be satis.ed by an assignment \nwhich satis.es every hard clause. In our algorithm, we mark the input constraints (that ensure that the \ninput is a failing test) as well as constraints arising from the speci.cation are hard. This is necessary: \notherwise, the MAX-SAT algorithm can trivially return that changing an input or changing the speci.cation \ncan eliminate the failing execution. In addition, in our implementation, we group clauses arising out \nof the same program statement together, thus keeping the resulting MAX-SAT instance small.  We have \nimplemented our algorithm in a tool called BugAssist for fault localization of C programs.1 BugAssist \ntakes as input a C program with an assertion, and a set of failing test cases, and returns a set of program \ninstructions whose replacement can remove the failures. It builds on the CBMC bounded model checker for \nconstruction of the trace formula and an off-the-shelf MAX-SAT solver [20] to compute the maximal set \nof satis.ed clauses. We demonstrate the effectiveness of BugAssist on 5 programs from the Siemens set \nof benchmarks with injected faults [8]. The TCAS program in the test suite is run with all the faulty \nversions in detail to illustrate the completeness of the tool. In each case, we show that BugAssist can \nef.ciently and precisely determine the exact (to the human) lines of code that form the bug . The other \n4 programs are used to show the scalability of the tool when used in conjunction with orthogonal error \ntrace reduction methods. We can extend our algorithm to suggest .xes for bugs automat\u00adically, by noticing \nthat the MAX-SAT instance can be used not only to localize problems, but also to suggest alternate inputs \nthat will eliminate the current failure. In general, this is an instance of Boolean program synthesis, \nand the cost of the search can be pro\u00adhibitive. However, we have experimentally validated that automatic \nsuggestions for .xes is ef.cient when we additionally restrict the search to common classes of programmer \nerrors, such as replace\u00adment of comparison operators (e.g., < by =) or off-by-one arith\u00admetic errors. \nFor these classes of systems, BugAssist can automat\u00adically create suggestions for program changes that \neliminate the current failure. Error localization is an important step in debugging, and im\u00adproved automation \nfor error localization can speed-up manual de\u00adbugging and improve the usability of automatic error-detection \ntools (such as model checkers and concolic testers). Based on our implementation and experimental results, \nwe feel BugAssist is a simple yet precise technique for error localization. Related Work. Fault localization \nfor counterexample traces has been an active area of research in recent years [1, 12, 13, 22, 23]. Most \npapers perform localization based on multiple program runs, both successful and failing, and de.ning \na heuristic metric on program traces to identify locations which separate failing runs from successful \nones. Griesmayer et al. [12] gives a fault localization algorithm for C programs that constructs a modi.ed \nsystem that allows a given number of expressions to be changed arbitrarily and uses the counter example \ntrace from a model checker. This requires in\u00adstrumenting each expression ei in the program with (diag \n== i?nondet() : ei), where diag is a non deterministic variable and nondet() is a new variable with the \nsize equal to that of ei. The number of diagnosis variables is equal to the number of compo\u00adnents that \nare faulty in the program and need to be analyzed before creating the modi.ed system. So each expression \nin the program requires a new variable in the modi.ed system along with the di\u00adagnosis variables which \ncould blow up the size of the instrumented program under consideration. In this work we avoid these draw\u00ad \n1 The tool, Eclipse plugin, and test cases can be downloaded from our web page http://bugassist.mpi-sws.org. \nbacks using selector variables and ef.cient MAX-SAT instance for\u00admulation using clause grouping technique. \nMany existing algorithms for fault localization [1, 13, 23, 33] use the difference between the faulty \ntrace and a number of suc\u00adcessful traces. For example, Ball, Naik, and Rajamani [1] use mul\u00adtiple calls \nto a model checker and compare the counterexamples to a successful trace. The faults are those transitions \nthat does not ap\u00adpear in a correct trace. Our approach does not require comparing the traces or a successful \nrun of the program as benchmark. We re\u00adport the exact locations where the bug could be corrected instead \nof a minimal code fragment or a fault neighbor location. Alternate approaches to reducing the cognitive \nload of debug\u00adging are delta debugging [33], where multiple runs of the program are used to minimize \nthe relevant portion of the input, and dy\u00adnamic slicing [30], where data and control dependence information \nis used to remove statements irrelevant to the cause of failure. Our technique is orthogonal to delta-debugging \nand dynamic slicing, and can be composed pro.tably. In fact, we demonstrate in our ex\u00adperiments how a \ncombination of dynamic slicing and delta debug\u00adging, followed by our technique, can allow us to localize \nfaults in long executions. While we describe our algorithm in pure symbolic execution terms, our algorithm \n.ts in very well with concolic execution [3, 11, 25], where symbolic constraints are generated while \nthe concrete test case is run. Our motivation for using CBMC was the easy integration with MAX-SAT solvers, \nbut in our implemen\u00adtation, we performed some optimizations (such as using concrete values for external \nlibrary calls in the trace formula and constant\u00adfolding input-independent parts of the constraints) similar \nto con\u00adcolic execution. Unsatis.ability cores and MAX-SAT have been used suc\u00adcessfully for design debugging \nof gate-level hardware circuits [5, 24]. Unsatis.ability cores have also been used to localize over\u00adconstrains \nin declarative models [26]. 2. Motivating Example Program 1 A simple example. int Array[3]; int testme(int \nindex) { . .................. 1 if ( index != 1) /* Potential Bug 2 */ 2 index = 2; 3 else 4 index = \nindex + 2; /* Potential Bug 1 */ . ................... . ................... . 5 i = index; 6 return \nArray[i]; //assert(i >= 0 &#38;&#38; i < 3) } We start with an informal description of BugAssist. Consider \nthe function testme in Program 1 which returns a value at a new location from an array of size 3. The \nglobal array Array has 3 elements. The function takes in the current index value, does computation on \nthis value (shown in lines 1 4) to .nd a new index and returns the value in the array at the new index \n(line 6). The array dereference on line 5 generates implicit assertions about the array bounds shown \nin line 6. The program has a bug. If the input index is equal to 1, then the else-branch sets index to \n3, and the subsequent array dereference on line 6 is out of bounds. Testing the program with this input \nwill .nd the bug, and return a program trace that shows the array bounds violation at the end. But testing \nor model checking returns a full execution path, including details irrelevant to the speci.c bug, and \ndo not give the reason for failure, or the cause of the bug. The localization algorithm in BugAssist \nhelps to nail down the issue to a few potential bug locations in the program where the correction has \nto be made.  BugAssist works as follows. Starting with the test input index =1 and the program, it .rst \nconstructs a symbolic trace formula TF encoding the program semantics: TF = guard1 =(index1= 1) . index2 \n=2 . index3 = index1 +2. i = guard1?index2 : index3 Every satisfying assignment to the trace formula \ngives a possible execution of the program, and conversely. We assume that integers and integer operations \nare encoded in a bit-precise way, and with\u00adout loss of generality, the trace formula is a Boolean formula \nin conjunctive normal form. In case there are loops in the program, we unroll loops up to a bound computed \nfrom the execution of the test input on the program (roughly, we take the bound as the maxi\u00admum number \nof times any loop gets executed along the execution, taking nesting into account). We omit the details \nof the standard encoding from imperative programs to Boolean formulas (see, e.g., [6]). Clearly, at the \nend of the trace, the assertion i < 3 does not hold for all inputs to the program. Consider now the formula \nF = index1 =1. TF. i < 3 ' 'Tl 'Tl Tl test input trace formula assertion which is unsatis.able. Intuitively, \nthe formula captures the execu\u00adtion of the program starting with the error-inducing test input, and asserts \nthat the assertion holds at the end (a contradiction, by choice of the input). We convert F to conjunctive \nnormal form (CNF) and feed it to a partial MAX-SAT solver [20]. A partial MAX-SAT solver takes as input \na Boolean formula in CNF where each clause is marked hard or soft, and returns the maximum number of \nsoft clauses (as well as a subset of clauses of maximum cardinality) that can be simultaneously satis.ed \nby an assignment satisfying all the hard clauses. In case of F, we make the constraints coming from the \ntest input (index1 =1) and the assertion (i < 3) as hard, and leave the clauses in the trace formula \nsoft. Intuitively, we ask, given that the input and the assertion are .xed, which parts of the trace \nformula are consistent with the input and the assertion? The partial MAX-SAT solver then tries to .nd \na set of soft clauses of maximum cardinality which can be simultaneously satis.ed while satisfying all \nthe hard clauses. The complement of a set of maximally satis.able clauses (CoMSS) gives a set of soft \nclauses of minimum cardinality whose removal would make F satis.able, i.e., consistent with the view \nthat the test input does not break the assertion. By tracing the origins of the clauses in this set to \nthe program, we get a set of program locations that are potential indicators of the error. Using clause \ngrouping, described in Section 3, each line in the program is mapped to a bunch of its soft clauses which \nare enabled and disabled simultaneously. In our example, the hard and soft clauses are: Hard :index1 \n=1 . i < 3 Soft :TF MAX-SAT returns that a possible CoMSS maps to the line 4 in the program. This is \nthe unsatis.able core whose removal or correction can satisfy the formula F. We claim that is a potential \nerror location for the program and a .x would be to change the constant to any integer less than 2 and \ngreater than -2. If the programmer decides this is not a correct localization, we can generate additional \nlocalization candidates as follows. We iterate by making another call to MAX-SAT, but this time make \nclauses arising out of line 4 hard, i.e., asking the MAX-SAT for possible CoMSS where line 4 is kept \nunchanged. This reveals another potential bug location in the code. We repeat this process until MAX-SAT \n.nds the formula to be unsatis.able and such that no clauses can be removed to make the instance satis.able. \nThe error locations reported by BugAssist are underlined in Program 1. On a closer look, these are all \nthe places where the correction can be made. Either changing the constant value at line 4 or the conditional \nstatement at line 1 can .x the program. Our method is limited by the existing code: we cannot localize \nerrors that can only be .xed by adding additional code. Notice that our technique is stronger than simply \ntaking the backward slice of the program trace, and gives .ne-grained infor\u00admation about potential error \nlocations. The backward slice for this trace contains all the lines 1, 4, and 5. Our algorithm returns \nlines 1 and 4 separately as potential error locations. However, slicing is an orthogonal optimization \nwhich can be applied before applying our technique. So far we have focused on error localization. The \nmethodology can be modi.ed to suggest program repairs as well. Intuitively, the fault localization returns \na set of program commands that are likely to be wrong. One can then ask, what are potential replacements \nto these commands that .xes the error? In general, the space of potential replacements is large, and \nsearching this space ef.ciently is a dif.cult problem of program synthesis [27, 29]. Instead, we take \na pragmatic approach and look for possible .xes for common programmer errors. Speci.cally, we demonstrate \nour idea by .xing off by one errors. In this example, the error occurs due to accessing an out of bound \narray element by one. When BugAssist comes back with line 4 as a potential bug location, we try to .x \nthe bug by changing the constant whose new value is one off its current value. So we change the value \n2 in this line to 3 or 1 and check if either of these values satisfy the properties. This involves modifying \nthe trace formula appropriately and checking if the failing program execution becomes infeasible with \neither change. So in this case we create two programs with new constants at line 4 as follows. P rogram1: \nindex = index +3 \u00d7 v P rogram2: index = index +1 The new value 1 ensures that the error path is infeasible, \nand this can be used as a suggestion for repair for the program. The same procedure can be used to check \nfor operator errors like use of plus instead of minus, division instead of multiplication, performing \nas\u00adsignment instead of equality test, etc., which are common program\u00admer error patterns. 3. Preliminaries \n 3.1 Programs: Syntax and Semantics We describe our algorithm on a simple imperative language based on \ncontrol-.ow graphs. For simplicity of description, we omit fea\u00adtures such as function calls or pointers. \nThese are handled by our implementation. A program G =(X, L,e0, T ) consists of a set X of Boolean\u00advalued \nvariables, a set L of control locations, an initial location e0 .L and a set T of transitions. Each transition \nt .T is a tuple (e, ., el) where e and el are control locations and . is a constraint over free variables \nfrom X . Xl, where the variables from Xl denote the values of the variables from X in the next state. \n For a constraint ., we sometimes write .(X, Xl) to denote that the free variables in . come from the \nset X . Xl. Our notation is suf.cient to express common imperative pro\u00adgrams (without function calls): \nthe control .ow structure of the program is captured by the graph of control locations, and oper\u00adations \nsuch as assignments x := e and assumes assume(p) cap\u00ad e tured by constraints xl = e .{yl = y | y . X \n\\{x}} and e p .{xl = x | x . X} respectively. A program is loop-free if there is no syntactic loop in \nthe graph of control locations. A state of the program P is a mapping from variables in X to Booleans. \nWe denote the set of all program states by v.X.A computation of the program is a sequence (m0,s0)(m1,s1) \n... . (L\u00d7 v.X) *, where m0 = e0 is the initial location, and for each i .{0,...,k - 1}, there is a transition \n(mi,.i,mi+1) .T such that (si,si+1) satis.es the constraint .i. An assertion p is a set of program states. \nA program violates an assertion p if there is some computation (m0,s0) ... (mk,sk) such that sk is not \nin p. Typically, assertions can be given as language\u00adlevel correctness requirements (e.g., no null pointer \ndereference ), as programmer-speci.ed asserts in the code, or as post-conditions.  3.2 Trace Formulas \nGiven a program and a bound k> 0, we can unwind the graph of control locations to get a simpli.ed program \nwithout loops whose computations all have length at most k and such that each computation of the simpli.ed \nprogram is also a computation of the original program. From such a loop-free program, we can derive a \n(quanti.er-free) Boolean formula, called the trace formula, such that the set of satisfying assignments \nto the formula correspond exactly to computations of the program. We brie.y describe the construction; \nsee [6] for details. The construction of the trace formula takes a loop-free program P, all of whose \ncomputations have length at most k, and recur\u00adsively constructs a Boolean formula as follows. Let X0,...,Xk \nbe independent copies of the set of variables X. For each e .L and i .{0,...,k - 1}, let z\u00a3be a Boolean \nvariable, and de.ne a i constraint f(e, i) as follows: \u00a3! zi\u00a3 ..(Xi,Xi+1) . zi+1 (1) (\u00a3,.,\u00a3!).T The \ntrace formula is then de.ned to be the conjunction over e .L and i .{0,...,k - 1} of the constraints \nin Equation (1), together \u00a30 with the conjunct z0 : \u00a30 z0 .f(e, i) (2) \u00a3.L,i.{0,...,k-1} The construction \nis well-de.ned because P is loop-free. While we have described trace formulas for our simple pro\u00adgrams, \na C program with .nite bit width data, e.g., 32-bit integers, can be converted into an equivalent Boolean \nprogram by separately tracking each bit of the state, and by interpreting .xed-width arith\u00admetic and \ncomparison operators as corresponding Boolean opera\u00adtions on each individual bit. In particular, our \nimplementation han\u00addles all features of ANSI-C, including function calls and pointers. We omit the (standard) \ndetails, see e.g., [6, 32]. 3.3 Partial Maximum Satis.ability Given a Boolean formula in conjunctive \nnormal form, the maxi\u00admum satis.ability (MAX-SAT) problem asks what is the maximum number of clauses \nthat can be satis.ed by any assignment [16]. The MAX-SAT decision problem is NP-complete; note that a \nformula is satis.able iff all its clauses can be satis.ed by some assignment. The partial maximum satis.ability \n(pMAX-SAT) problem takes as input a Boolean formula F in conjunctive normal form, and a marking of each \nclause of F as hard or soft, and asks what is the maximum number of soft clauses which can be satis.ed \nby an assignment to the variables which satis.es all hard clauses. Intuitively, each hard clause must \nbe satis.ed, and we look for the maximum number of soft clauses which may be satis.ed under this constraint. \nRecent years have seen a tremendous improvement in engineer\u00ading ef.cient solvers for MAX-SAT and pMAX-SAT. \nThe widely used algorithm for MaxSAT is based on branch-and-bound search [17], supported by effective \nlower bounding and dedicated infer\u00adence techniques. Recently, unsatis.ability based MaxSAT solvers by \niterated identi.cation of unsatis.able sub-formulas was pro\u00adposed in [10]. This approach consist of identifying \nunsatis.\u00adable sub-formulas and relaxing clauses in each unsatis.able sub\u00adformulas by associating a relaxation \nvariable with each such clause. Cardinality constraints are used to constrain the number of relaxed clauses \n[19, 20]. In addition to solving the decision problem, MAX-SAT solvers also give a set of clauses of \nmaximum cardinality that can be simul\u00adtaneously satis.ed. The complement of these maximum satis.able \nsubsets (MSS) are a set of clauses whose removal makes the in\u00adstance satis.able (CoMSS). Since the maximum \nsatis.ability sub\u00adset is maximal, the complement of this set is minimal [18]. In this work we make use \nof these CoMSS which refers to the clauses whose removal can make the system satis.able. Since we represent \na C program as a boolean satis.ability problem with constraints and properties, the CoMSS are oracles \nfor potential bug locations.  3.4 Ef.cient Compilation to MAX-SAT A single transition can lead to multiple \nclauses in the conjunctive normal form of the trace formula. In this section we provide a method to simplify \nthe MAX-SAT problem by grouping together clauses arising out of a single transition in the program. For \neach transition t =(m, ., ml) .T , we introduce a new Boolean variable .t . Let .= {.t | t .T}. Let CNF(.) \nbe a conjunctive normal form representation of .. We augment each clause in CNF(.) with .t . For example, \nsuppose (c11 . ...) . (c12 ....) is a conjunctive normal form representation of ., then the augmented \nrepresentation is (\u00ac.t . c11 . ...) . (\u00ac.t . c12 . ...). The augmentation with .t has the following effect. \nWhen .t is assigned true, the original clauses in the CNF representation of . must be satis.ed, while \nwhen .. is assigned false, each augmented clause is already satis.ed. This helps to enable and disable \nthe clauses corresponding to each transition by setting and unsetting the .t variable respectively. The \n.-variables are called selector variables. We now augment trace formulas with selector variables. Let \nfl(e, i, .) be the formula in which each clause arising out of t =(\u00b7, ., \u00b7) is augmented with .t . Instead \nof Equation (2) for the trace formula, we use the form: \u00a30 l z0 .f(e, i, .) ..t (3) \u00a3.L,i.{0,...,k-1} \nt.T ' Tl' Tl TF2TF1 where we label the two parts of the formula TF1 and TF2 for later reference. Intuitively, \nclauses from TF1 will be marked as hard clauses to the MAX-SAT solver, and clauses from TF2 will be marked \nsoft. Thus, the MAX-SAT solver will explore the space of possible program statements whose replacement \nwill cause the error to go away.  Algorithm 1 Localization Algorithm Input: Program P and assertion \np Output: Either p holds for all executions or potential bug locations 1: (test,s) = GenerateCounterexample(P, \np) 2: if s is None then 3: return No counterexample to p found 4: else 5: FH =[ test] . p . TF1(s) 6: \nFS = TF2(s) 7: while true do 8: BugLoc = CoMSS(FH , FS ) 9: if BugLoc = \u00d8 then 10: return No more suspects \n11: else 12: output Potential bug at CoMSS BugLoc p 13: \u00df = {.i | .i . BugLoc} 14: FS =FS\\\u00df and FH =FH \n. \u00df Notice that we allocate a selector variable for each transition of the program, so the number of \nselector variables is bounded by the size of the program. However, in a trace, the same program transition \nmay occur multiple times (e.g., on unrolling a loop), and there is a distinct clause for each of these \noccurrences all tagged with the same selector variable. We use the abstraction technique on transitions, \nwhich corre\u00adspond to line numbers of code in our implementation, but it is also possible to group the \nclauses from modules and recursively narrow down the problem to a module, and then to a line. 4. Algorithm \nWe now describe the algorithm for BugAssist. There are two phases of the algorithm: .rst, generate a \nfailing execution (and a test demonstrating a failing execution), and second, .nd a minimal set of transitions \nthat can render the failing execution infeasible. 4.1 Generating Failing Tests In our implementation, \nwe use either failing test cases from a test suite as a starting point. If there are no available tests, \nwe use bounded model checking [2, 6] to systematically explore program executions and look for potential \nassertion violations. Once a fail\u00ading execution is found, the bounded model checking procedure can generate \na concrete initial state that leads to the assertion violation as well as the trace formula. 4.2 The \nLocalization Algorithm Algorithm 1 shows the BugAssist localization algorithm. Line 1 calls the procedure \nto generate failing executions for the assertion. If no failing executions are found, the procedure returns. \nOtherwise, we get a concrete test case test as well as a trace s demonstrating the failure of the assertion. \nUsing the test, the failing execution, and the assertion, we construct two formulas (lines 5,6). The \nformula FH consists of three parts. The .rst part, [ test] , is a formula asserting that the initial \nstate coincides with the test case that caused the failure. Formally, for a program state s, the constraint \n[ s] is de.ned as e {x = s(x) | x . X}. The second part is the assertion p. The third part is the .rst \npart TF1(s) of the trace formula from Equa\u00adtion (3). The formula FS is the second part TF2(s) of the \ntrace formula from Equation (3). Notice that FH . FS is unsatis.able. (Intuitively, it says that if the \nprogram is run with the test input test, then at the end of the execution trace s, the assertion p holds.) \nIn subsequent calls to pMAX-SAT, clauses in FH are treated as hard clauses, and clauses in FS are treated \nas soft clauses. Intuitively, treating FS as soft clauses enables us to explore the effect of changing \neach subset of transitions to see if the failing transition can be made infeasible. The search for localizations \nis performed in the while loop of lines 7 14. During each iteration of the while loop, we call the pMAX-SAT \nsolver and get a CoMSS for the current (FH , FS) pair. Each of these clauses returned by CoMSS gives \npotential bug locations in the code, and is output to the programmer. Whenever we report a potential \nbug, we add a hard blocking clause for the corresponding CoMSS, so that in subsequent it\u00aderations, this \nCoMSS is not explored again as a potential cause of error. In many of our experiments, the CoMSS returns \na sin\u00adgle .. clause as the indicator of error. In general, it returns more than one selector variable \nwhich indicates that the program cannot be .xed by changing any one line but must be changed at mul\u00adtiple \nlocations. (This does happen in experiments.) Adding each of these .. variables as a new hard clause \nblocks the occurrence of these clauses in a different clause combination. To avoid this problem, we compute \na blocking clause \u00df (lines 13) and make the blocking clause hard. For example, suppose the coMSS returned \nis, BugLoc = {.1,.2,...,.k}. This means that the bug can be .xed by making simultaneous changes to these \nk locations. In the next iteration, we add a new hard clause (.1 . ... . .k) which en\u00adsures that this \nparticular CoMSS is not encountered again, but other combinations of these locations are still allowed. \n 4.3 Dealing with Multiple Locations BugAssist may return multiple locations where a correction is possible. \nThe experimental results in section 6.1 shows that the number of potential error locations returned is \nquite small and, in most cases, the exact bug location is reported using a single failing execution. \nHowever, for reliability and further re.nement of bug locations, we use a ranking mechanism for bug locations \nby running the localization algorithm repeatedly with different failing program traces and ranking the \nbug locations based on their frequency of appearance in each of these runs. For test cases, this requires \naccess to a set of tests that all fail the assertion. For counterexample generation using bounded model \nchecking, we take the Boolean formula constructed by the bounded model checker and generate multiple \nsatisfying assignments by changing the order of variables in the SAT algorithm [7] or by doing a random \nrestart of the solver. Running BugAssist with these new values gives a another set of potential bug locations. \nRepeating this process and ranking the bug locations can narrow down the search to a few lines in the \nprogram. 5. Extensions We now describe two extensions to the basic algorithm. 5.1 Extension 1: Automated \nRepair BugAssist can be extended to suggest potential repairs automati\u00adcally. In general, program repair \nreduces to program synthesis. We sacri.ce generality for practicality by focusing on speci.c program \nrepairs inspired by program mutation testing and checking if there is a possible repair from this class \nthat can remove the current test failures. For example, if there is a constant used in a potential error \nlocation, we try to synthesize a new constant which can .x the code [12], or if there is an operator \nused in a potential error location, we try to generate a repair by mutating the operator to a different \none. We demonstrate this capability by generating suggestions for .xing off-by-one errors [31] in the \nprogram. These are a common class of logical errors in programs arising when programmers use an ex\u00adpression \ne in the program when they should be using e \u00b1 1. For example, this can happen if programmers forget \nthat a sequence starts at zero rather than one (e.g. array indices in many languages like C, C++). It \nis also caused during boundary check conditions by using a < instead of = or vice versa.  During the \ncode parsing phase, we mark lines which have con\u00adstants in them. After running BugAssist on the code, \nwe look at po\u00adtential error locations, and for each constant c in this set, we intro\u00adduce an indicator \nvariable ic that takes values in the set {-1, 0, 1}. We replace the constant c with the expression c \n+ ic in the code. Now, we ask if there exist values to the indicator variables that en\u00adsures that the \nnew trace is infeasible. This is a S2 query (does there exist values of ic such that for all inputs the \ntrace formula is infeasi\u00adble), and cannot be directly solved by a SAT solver (see [28, 29] for extensions \nto SAT solvers to solve this problem). In our implemen\u00adtation, we restrict the number of non-zero indicator \nvariables and iteratively call a SAT solver for each assignment of the indicator variables.  5.2 Extension \n2: Debugging Loops Bugs within loop bodies can be particularly hard to debug as they might be hidden \nin initial iterations and only visible afterwards. The usual bounded model checking methodology to verify \nproperties is by unwinding loops by duplicating the loop body K times for a limit K on the number of \nunwindings. The programmer would be interested in knowing the iteration at which the assertion is violated \nto get a better idea about the cause of the error. We suggest a method to catch the potential iteration \nof the loop where the bug appeared .rst. We can do this by grouping clauses and assigning weights to \nthe soft clauses in the pMAX-SAT instance, and using a weighted version of the pMAX-SAT algorithm. Each \ntime a loop body is duplicated (till the bound K), we create a new selector variable. For example, for \na transition t =(m, ., ml) .T in the loop body, during the ith unwinding, we augment each clause arising \nout of . with .it . We add these selector variables as soft clauses to the pMAX-SAT instance as before, \nbut additionally assign a weight as follows: Weight(.ti )= a + K - i (4) for each i =1,...,K, where a \nis some default weight for soft clauses. This makes sure that the clauses corresponding to the initial \niterations of the loop gets a higher weightage. The weights assigned to the soft clauses in the pMAX-SAT \ncan be thought of as the penalty that has to be paid to falsify the clauses. The solver extracts the \nCoMSS in such a way that clauses from initial iterations are preferred over clauses from later iterations, \nsince the former have higher weights. This helps to localize the .rst iteration of the loop which can \nreproduce the failure. 6. Experimental Results We now demonstrate the capability of the tool by showing \nthe results from running programs from the Siemens test suite [8]. The Siemens test suite is widely used \nin the literature for bug localization studies [12, 23]. In Section 6.1, we analyze a simple TCAS program \nfrom the Siemens suite [14] in depth and in Section 6.2 we illustrate the scalability of our method using \nmore complex examples. In our implementation, we used the bounded model checker CBMC [6] to generate \nfailing test inputs as well as to construct the trace formula for an unrolling of the program. For solving \nthe pMAX-SAT instances, we used the Maximum Satis.ability with UNsatis.able COREs (MSUnCORE) tool [20], \nwhich can handle large and complex weighted partial MAX-SAT problems. Fixes for off-by-one errors were \nsynthesized using the MiniSAT2 [9] SAT 1 int Inhibit_Climb () { 2 return (Climb_Inhibit?Up_Sep+300:Up_Sep); \n3 /*return (Climb_Inhibit?Up_Sep+100:Up_Sep);*/ 4 } 5 int Non_Crossing_Climb() { 6 upward_preferred=Inhibit_Climb()>Down_Sep; \n7 if (upward_preferred) { 8 result = !(Own_Below_Threat()) || (!(Down_Sep >= ALIM())); } 9 else{ 10 result \n= (Cur_Vertical_Sep >= 100) &#38;&#38; (Up_Sep >= ALIM()); } 11 return result; 12 } 13 int Non_Crossing_Descend() \n{ 14 upward_preferred=Inhibit_Climb()>Down_Sep; 15 if (upward_preferred) {16 result = Own_Below_Threat() \n&#38;&#38; (Cur_Vertical_Sep >= 100) &#38;&#38; (Down_Sep >= ALIM()); }17 else{18 result = !(Own_Above_Threat()) \n|| ((Own_Above_Threat()) &#38;&#38; (Up_Sep >= ALIM())); } 19 return result; 20 } 21 int alt_sep_test() \n{ 22 enabled = true; /*conditions omitted*/ 23 alt_sep = UNRESOLVED; 24 if (enabled) { 25 need_upward_RA=Non_Crossing_Climb()&#38;&#38; \nOwn_Below_Threat(); 26 need_downward_RA=Non_Crossing_Descend() &#38;&#38; Own_Above_Threat(); 27 if (need_upward_RA \n&#38;&#38; need_downward_RA) 28 alt_sep = UNRESOLVED; 29 else if (need_upward_RA) 30 alt_sep = UPWARD_RA; \n31 else if (need_downward_RA) 32 alt_sep = DOWNWARD_RA; 33 34 }return alt_sep; 35 } 36 int main() {/*inputs \nomitted*/ 37 assert(alt_sep_test() == DOWNWARD_RA); 38 } Figure 1. Sample TCAS code. Potential bug locations \nidenti.ed by BugAssist are underlined. Original code on line 3; mutation on line 2 engine. All our experiments \nare preformed on an 3.16 GHz Intel Core 2 Duo CPU with 7.6 GB RAM. 6.1 TCAS Experiments The TCAS task \nof the Siemens test suite implements an aircraft collision avoidance system. It consists of 173 lines \nof code. The authors have created 41 versions of the program by injecting one or more faults. Their goal \nwas to introduce faults that were as realistic as possible, based on their experience with real programs. \nWe refer to the versions as v1 to v41 . The Siemens test suite also contains 1600 test cases which are \nvalid inputs for the program. We created the golden outputs for these 1600 test cases by running the \noriginal version of the program. Then for each of the faulty versions, we ran those 1600 test vectors \nand matched with the golden outputs to segregate the failing test cases. Since the program does not contain \na speci.cation, we use the failing test cases as counterexamples and the correct value as its speci.cation. \nTable 1 shows the result of running BugAssist on the TCAS test suite. BugAssist ran 1440 times over all \nversions and 1367 of these runs pin-pointed the exact bug location, i.e., in 95% of the total runs. The \nTC# in the table is the number of failed test cases  Version TC# Error# Detect# Size Reduc% Run Time \nError Type  Version TC# Error# Detect# Size Reduc% Run Time Error Type v1 132 1 132 8.6 0.016 op v21 \n16 1 16 8.6 0.108 op v2 69 1 69 4.6 0.068 const v22 11 1 11 5.7 0.056 code v3 23 1 13 9.8 0.096 op v23 \n42 1 41 6.3 0.100 code v4 26 1 26 9.2 0.104 op v24 7 1 7 8.6 0.092 op v5 10 1 10 8.6 0.120 assign v25 \n3 1 3 6.9 0.068 code v6 12 1 12 8.6 0.108 op v26 11 1 11 9.2 0.108 addcode v7 36 1 36 9.2 0.072 const \nv27 10 1 10 10.9 0.108 addcode v8 1 1 1 8.6 0.112 const v28 76 1 58 5.7 0.080 Branch v9 9 1 9 5.2 0.092 \nop v29 18 1 14 5.7 0.092 code v10 14 2 14 9.2 0.136 op v30 58 1 58 5.7 0.064 code v11 14 2 14 6.3 0.080 \nop v31 14 2 14 10.9 0.008 addcode v12 70 1 48 9.2 0.164 op v32 2 2 2 10.9 0.004 addcode v13 4 1 4 9.2 \n0.080 const v34 77 1 77 8.6 0.100 op v14 50 1 50 8.1 0.028 const v35 76 1 58 5.7 0.060 code v15 10 3 \n10 7.5 0.104 const v36 126 1 126 2.9 0.024 op v16 70 1 70 9.2 0.104 init v37 93 1 93 8.6 0.040 index \nv17 35 1 35 9.2 0.096 init v39 3 1 3 6.9 0.088 op v18 29 1 29 6.9 0.124 init v40 126 2 126 6.3 0.088 \nassign v19 19 1 19 9.2 0.112 init v41 20 1 20 8.6 0.120 assign v20 18 1 18 9.2 0.120 op Table 1. Results \nof running BugAssist on the TCAS task of the Siemens Test Suite Error Type Explanation for the error \nop Wrong operator usage e.g.: <= instead of < code Logical coding bug assign Wrong assignment expression \naddcode Error due to extra code fragments const Wrong constant value supplied e.g.: off-by-one error \ninit Wrong value initialization of a variable index Use of wrong array index branch Error in branching \ndue to negation of branching condition Table 2. Type of error for each version. We ran BugAssist with \neach of these failing test cases as failing program executions and the golden output as the assertion \nto be satis.ed. The column Error# shows the number of errors injected in to each version. Most versions \nhave only 1 error but some have 2 and 3 errors. Detect# is the number of runs of BugAssist which detected \nthe correct (human-veri.ed) bug location. SizeReduc% is the percentage reduction in the code size given \nby the tool to locate the bug, the ratio of bug locations returned by the tool to the total number of \nlines in the code. The RunT ime shows the run time for each run of BugAssist in seconds and they are \nnegligible. The last column is the type of bug which is explained in Table 2. For example, the version \nv2 has one error injected and has 69 failing test cases. We collected the bug locations reported during \nthese 69 runs of the tool which gave 8 potential bug locations, which is 4.6% of the total line number \ns in the program. The exact location of the fault is contained in the localizations obtained from all \nthe 69 runs. Except for a few versions like v12, v28 and v35, BugAssist detected the correct bug location \nfor all the runs. For the remaining ones, when we rank locations based on frequency of being reported \nas bugs, exact bug locations had a count more than half of the total number of runs. The runs in which \nexact location was not reported did give clues about the real bug. For example, some test cases had wrong \nconstant value assignment to an array element, for which the tool reported the fault at places where \nthat array is accessed rather than the line at which the bad assignment occurred. By analyzing the error \nlocations it is quite evident that the error is due to a wrong value in that array location. On average \nthe number of lines to check for potential bug is reduced to 8% of the total code. It should be noted \nthat most of the single runs of the faulty version have captured the exact bug location. Figure 1 gives \nan overview of a version of tcas (v2). The bug is in line 2 (and the original code is shown commented \nout in line 3). The bug is injected in function Inhibit Biased Climb at line 2 by changing the constant \nvalue. The declaration and initialization of variables, functions, and conditional statements that are \nnot relevant to this bug are omitted in the .gure. The program needs to satisfy the safety property alt \nsep test() should return DOWNWARD RA and is given as assertion at line 37. There were 69 failing test \ncases for this version. We ran all these test cases and the tool returned 8 potential bug locations which \nare shown underlined in Figure 1. There is no error reported in function Non Crossing Climb() because \nthe call for that function at line 25 needs the function Own Below Threat() to be true, but that is false \nbased on a com\u00adparison on the input parameters which are made hard clauses. Now lets take a closer look \nat the reported errors. 1. Line 34 is too weak for a .x because changing the return value can make the \nassertion always true and that does not serve as a suitable .x. 2. In line 26, setting the need downward \nRA variable to true can pick the right value for alt sep. This decision is made by an evaluation of the \ntwo functions in that statement. The function Own Above Treat() returns true based on the input and it \nis clear that the correction needs to be done to the function call Non Crossing Decend(). 3. The function \nNon Crossing Decend() has a call for the actual faulty function at line 14. It also shows that the repair \ncould be done by changing the return value of this function at line 19 (which we ignore as in case 1 \nabove), or where the wrong evaluation happens (lines 15,16).   4. The actual bug at line 2 is reported \nas a potential bug location in all the runs.  6.2 Larger Examples To show the performance and applicability \nof our approach for larger programs and in the presence of complex pointers and loops, we chose a set \nof other test cases with function calls, recursion, dy\u00adnamic memory allocation, loops, and complex programming \ncon\u00adstructs. The TCAS test cases were small enough to allow the MAX-SAT solver to deal with the Boolean \ntrace formula without additional optimizations. However, for larger programs, the trace formula obtained \nby unrolling a program, and the corresponding MAX-SAT instance, was beyond the capacity of the MAX-SAT \nsolver. Therefore, we combine our technique with existing trace reduction techniques like program slicing \n(S) [30], concolic execution (C) [11], and isolating failure-inducing input using delta debugging (D) \n[34]. Table 3 shows the result of running BugAssist on 4 other pro\u00adgrams from the Siemens suite, each \nwith one injected fault. Pro\u00adgram shows the name of the program from the Siemens testsuite. LOC# is the \ntotal lines of code in the program and Proc# , the number of procedure calls. The kind of reduction technique \nis spec\u00adi.ed in Reduc and assign# shows the size of the dynamic error trace as the number of assignment \nexpressions before and after per\u00adforming the reduction technique. The var# and clause# is the number \nof boolean variables and clauses in the MAX-SAT repre\u00adsentation of the error trace both before and after \nthe reduction step (the unit m denotes million). The number of potential fault lo\u00adcations returned by \nthe tool is given under Fault# . The column Time shows the runtime in seconds (s) or (in one case) hours \n(h). We picked a faulty version of the program and one test input that reveals the bug. The golden output \nfrom the non-faulty program with the same input is given as a post condition on the return value of the \nfaulty version. Trace reduction techniques are applied to the program execution with this input to generate \na smaller trace formula and given as input to BugAssist. The tool reported the exact bug location in \nall programs except one (Program 2: print token). Trace reduction techniques signi.cantly reduced the \nresulting trace and the size of the MAX-SAT instance, as shown in Before and After sizes in Table 3. \nThe cardinality of the potential fault location set for each of these programs turns out to be small. \nIn all cases, the run time of the tool was smaller than our human effort required to isolate the fault \non the original trace. This shows the applicability of the approach. The error inducing input to Program \ntotinfo was the rows and columns of a matrix. The bug was in the constant value of a con\u00additional operator \non checking the product of rows and columns after a few other operations. A simple program slicing removed \nthe assignments irrelevant to the assertion being checked and reduced the number of assignments to 21 \nand the run time to less than a second.  Program print token contained a recursive function next token \nand the input to the program required the loops to be unrolled 8 times in the symbolic trace formula \ngeneration. This made the recursive function to have 64 instances in the symbolic trace and the number \nof assignments went up to 65K without concolic execution. Using concrete execution for the recursive \nfunction and variables, the number of assignment statements was bought down to 239. It should be noted \nthat the limitation in using a concrete execution would be to assume that the bug is not present in the \nfunctions and loops which are concretized. However, this methodology .ts well in programs using functions \nfrom a reliable library or for functions which  are already veri.ed to be bug free. This program did \nnot show error at the exact location, which was a comparison on a variable which got the value from the \nconcrete execution. This was because the constant propagation used by the symbolic trace generator abstracted \naway the variable since its value was a constant. Instead, the error was shown in the assignment of the \nvariable to the constant. The priority scheduler program 3 and 4, contained a large er\u00adror inducing input \nwhich called a number of procedures be\u00adfore deviating from the golden output of the original program. \nThe trace size was signi.cantly reduced after isolating the er\u00adror inducing input using delta debugging, \nbut was still quite big (about 400 and 5400 assignment operations respectively). In program 3, the off-by-one \nerror on .ushing the number of processes was detected by the presence of a single process cre\u00adation (leading \nto a trace of about 400 assignments). However, program 4 required a much larger input and more procedures \nto expose the failure, resulting in a longer trace. It took BugAssist almost 11 hours to .nd the exact \nlocation (excluding the time taken for input minimization using delta debugging). Each ex\u00adecution of \nMAX-SAT took around 30 minutes to identify one potential fault location. Program 2 The strncpy program \nwith an off-by-one error 1 #define SIZE 15 2 void MyFunCopy (char *s) 3 { 4 char buf[SIZE]; 5 memset(buf, \n0, SIZE); 6 strncat(buf, s, SIZE); 7 /*Last argument should be: SIZE-1 */ 8 return; 9 } /*Standard \nC implementation of strncat*/ 10 char *strncat(char *dest, const char *src, size t n) 11 { 12 char *ret \n= dest; 13 while (*dest) 14 dest++; 15 while (n--) 16 if (!(*dest++ = *src++)) 17 return ret; 18 *dest \n= 0; /*Problem cause*/ 19 return ret; 20 }  6.3 Fixing Off-By-One Errors We demonstrate the repair capability \nof BugAssist by synthesizing .xes for off-by-one errors in the use of standard C library routines. We \nfocus on off-by-one errors arising out of the misuse of the C strncat string manipulation function [21]. \nA common misconcep\u00adtion with strncat is that the guaranteed null termination will not write beyond the \nmaximum length. In reality, strncat can write a terminating null character one byte beyond the maximum \nlength speci.ed. The Program 2 shows an instance of the bug in the function MyFunCopy, which takes a \nstring s and uses the strncat routine to copy the contents to a string buf of length SIZE. The lines \n10 20 shows a standard C implementation of strncat. Note that after Program LOC#  Proc# Reduc assign# \nvar# clause# Fault# time Before After Before After Before After 1 totinfo 565 7 S 734 21 0.797m 400 \n1.822m 1225 2 0.19s 2 print tokens 726 18 C 65698 239 5.507m 7439 53.483m 22634 13 25s 3 schedule 564 \n21 DS 5914 391 5.173m 0.053m 15.379m 0.142m 13 28s 4 schedule 564 21 DS 41942 5412 78.982m 4.517m 239.385m \n13.788m 25 11h 5 totinfo 565 7 CS 865 454 0.862m 0.734m 4.156m 3.728m 3 225s 6 schedule2 374 16 S 398 \n 275 0.021m 0.015m 0.062m 0.048m 9 20s Table 3. Running BugAssist on larger benchmark programs from \nthe Siemens Test Suite copying the n characters at line 17, the implementation writes to the (n + 1)st \nlocation of the string dest on line 18. This implies that the function MyFunCopy should be using SIZE \n- 1 as the last argument to strncat. We ran BugAssist on this function, checking whether array ac\u00adcesses \nare within bounds. We made the assumption that library functions cannot be modi.ed, and the error lies \nin the client code. That is, in the pMAX-SAT problem formulation, we made con\u00adstraints arising out of \nlibrary functions (strncat in this case) hard clauses. BugAssist located line 6 as a potential bug location \nin the code. This location is marked during preprocessing as a statement with a constant; so BugAssist \nnow tries to .x it by changing the value to SIZE - 1 and SIZE +1 as explained before. This cre\u00adates two \nSAT instances with the new constant values, and we use a SAT solver to check if the error is still feasible. \nIn this example, the change to SIZE - 1 eliminated the bug. Program 3 The nearest integer square root \nfunction with a bug at line 12 1 int squareroot() 2 { 3 int val = 50; 4 int i =1; 5 int v =0; 6 int res \n=0; 7 while(v < val) 8 { 9 v = v + 2*i +1; 10 i = i+1; 11 } 12 res = i; 13 /* res = i -1; */ 14 assert( \n(res*res <= val) &#38;&#38; ((res+1)*(res+1) > val); 15 return res; }  6.4 Finding Faulty Loop Iterations \nProgram 3 contains a function to .nd the nearest integer square root of a value. The post condition is \nspeci.ed as an assertion, and states that the result res should be the closest square root for val. The \nbug locations reported by BugAssist are underlined. The correct code is given as a comment on line 13. \nEven though the actual bug is not in the loop body, it requires an analysis of the loop body to conclude \nthat the right .x is at line 12. We gave the unwinding limit 50 to CBMC and BugAssist reports a potential \nrepair at line 10 in the 8th iteration of the loop. This gives clue to the programmer that the error \noccurs if the loop is iterated atleast 8 times. 7. Discussions Program analysis based on Boolean satis.ability \nhas been ex\u00adtremely successful in detecting subtle errors in large software pro\u00adgrams [4, 6, 32]. We \nshow that techniques based on Boolean MAX-SAT can be similarly effective in localizing program errors \n(as well as in identifying potential .xes). Our fault localization algorithm depends on the underlying \nBoolean transform of the program to clauses, and is limited by the scalability of bounded model checking \ntools. In most cases, a single failing input was suf.cient to locate the exact error location. Each of \nthe potential error locations are the unsatis.ed clauses in each iteration of the MAX-SAT solver. Our \nfault correction algorithm works by changing existing clauses. We cannot detect or correct code omission \nfaults. Our experimental results show that trace reduction techniques are crucial in making our implementation \nscale to reasonably large examples. Trace reduction techniques, such as delta-debugging or slicing, are \northogonal to our approach, and we can build on the extensive literature in these .elds. Additionally, \nthe performance can be improved by using an incremental SAT solver for iterative applications of MAX-SAT. \nWhile we have described error localiza\u00adtion at the line-number (or program statement) level, our reduction \nto pMAX-SAT is general, and can be used at different levels of granularity. For example, to localize \nbugs at the function or mod\u00adule level, we can group clauses coming from the same function or module in \nthe pMAX-SAT instance. To improve the usability of our tool, we have built an Eclipse plugin to use BugAssist \ninteractively during the development pro\u00adcess. The plugin marks potential bugs in the code under develop\u00adment \nand assists in analyzing the right .x. References [1] Thomas Ball, Mayur Naik, and Sriram K. Rajamani. \nFrom symptom to cause: localizing errors in counterexample traces. In POPL 03: Principles of Programming \nLanguages, pages 97 105, 2003. ACM. [2] A. Biere, A. Cimatti, E. M. Clarke, M. Fujita, and Y. Zhu. Symbolic \nmodel checking using sat procedures instead of bdds. In DAC 09: Design Automation Conference, pages 317 \n320, 1999. ACM. [3] Cristian Cadar, Daniel Dunbar, and Dawson Engler. Klee: unassisted and automatic \ngeneration of high-coverage tests for complex systems programs. In OSDI 08: Operating Systems Design \nand Implementa\u00adtion, pages 209 224, 2008. USENIX Association. [4] Cristian Cadar, Vijay Ganesh, Peter \nM. Pawlowski, David L. Dill, and Dawson R. Engler. Exe: automatically generating inputs of death. In \nCCS 06: Computer and Communications security, pages 322 335, 2006. ACM. [5] Yibin Chen, Sean Safarpour, \nAndreas Veneris, and Joao Marques-Silva. Spatial and temporal design debug using partial maxsat. In GLSVLSI \n09: Great Lakes Symposium on VLSI, pages 345 350, 2009. ACM. [6] Edmund Clarke, Daniel Kroening, and \nFlavio Lerda. A tool for checking ANSI-C programs. In TACAS 04: Tools and Algorithms  for the Construction \nand Analysis of Systems, volume 2988 of Lecture Notes in Computer Science, pages 168 176, 2004. Springer. \n[7] Martin Davis and Hilary Putnam. A computing procedure for quan\u00adti.cation theory. J. ACM, 7:201 215, \nJuly 1960. [8] Hyunsook Do, Sebastian Elbaum, and Gregg Rothermel. Supporting controlled experimentation \nwith testing techniques: An infrastructure and its potential impact. Empirical Softw. Engg., 10(4):405 \n435, 2005. [9] Niklas E\u00b4en and Niklas S\u00a8orensson. Minisat v2.0 (beta). In SAT-Race, 2006. http://fmv.jku.at/sat-race-2006/. \n[10] Zhaohui Fu and Sharad Malik. On solving the partial MAX-SAT problem. In SAT 06: Theory and Applications \nof Satis.ability Testing, volume 4121 of Lecture Notes in Computer Science, pages 252 265, 2006. Springer. \n[11] Patrice Godefroid, Nils Klarlund, and Koushik Sen. Dart: directed automated random testing. In PLDI \n05: Programming Language Design and Implementation, pages 213 223, 2005. ACM. [12] Andreas Griesmayer, \nStefan Staber, and Roderick Bloem. Automated fault localization for C programs. ENTCS, 174:95 111, 2007. \n[13] Alex Groce, Sagar Chaki, Daniel Kroening, and Ofer Strichman. Error explanation with distance metrics. \nInt. J. Softw. Tools Technol. Transf., 8:229 247, 2006. [14] Monica Hutchins, Herb Foster, Tarak Goradia, \nand Thomas Ostrand. Experiments of the effectiveness of data.ow-and control.ow-based test adequacy criteria. \nIn ICSE 94: International Conference on Software Engineering, pages 191 200, 1994. IEEE Computer Society. \n[15] James C. King. Symbolic execution and program testing. Commun. ACM, 19:385 394, July 1976. [16] \nChu Min Li and Felip Many`a. MaxSAT, hard and soft constraints. In Handbook of Satis.ability, volume \n185 of Frontiers in Arti.cial Intelligence and Applications, chapter 19, pages 613 631. IOS Press, 2009. \n[17] Chu Min Li, Felip Many`a, and Jordi Planes. New inference rules for MAX-SAT. J. Artif. Int. Res., \n30:321 359, October 2007. [18] Mark H. Lif.ton and Karem A. Sakallah. On .nding all minimally unsatis.able \nsubformulas. In SAT 05: Theory and Applications of Satis.ability Testing, volume 3569 of Lecture Notes \nin Computer Science, pages 173 186, 2005. Springer. [19] Joao Marques-Silva. Minimal unsatis.ability: \nModels, algorithms and applications (invited paper). In ISMVL 10: International Symposium on Multiple-Valued \nLogic, pages 9 14, 2010. IEEE Computer Society. [20] Joao Marques-Silva and Jordi Planes. Algorithms \nfor maximum satis\u00ad.ability using unsatis.able cores. In DATE 08: Design, Automation and Test in Europe, \npages 408 413, 2008. ACM. [21] Todd C. Miller and Theo de Raadt. strlcpy and strlcat: consistent, safe, \nstring copy and concatenation. In USENIX Annual Technical Conference, pages 175 178, 1999. USENIX Association. \n[22] Dawei Qi, Abhik Roychoudhury, Zhenkai Liang, and Kapil Vaswani. Darwin: an approach for debugging \nevolving programs. In ESEC/FSE 09: European Software Engineering Conference and Foundations of Software \nEngineering, pages 33 42, 2009. ACM. [23] Manos Renieres and Steven P. Reiss. Fault localization with \nnearest neighbor queries. In ASE 03: Automated Software Engineering, pages 30 39, 2003. IEEE Computer \nSociety. [24] Sean Safarpour, Hratch Mangassarian, Andreas Veneris, Mark H. Lif\u00ad.ton, and Karem A. Sakallah. \nImproved design debugging using max\u00adimum satis.ability. In FMCAD 07: Formal Methods in Computer-Aided \nDesign, pages 13 19, 2007. IEEE Computer Society. [25] Koushik Sen, Darko Marinov, and Gul Agha. CUTE: \na concolic unit testing engine for C. In ESEC/FSE 05: European Software Engineering Conference and Foundations \nof Software Engineering, pages 263 272, 2005. ACM. [26] Ilya Shlyakhter, Robert Seater, Daniel Jackson, \nManu Sridharan, and Mana Taghdiri. Debugging overconstrained declarative models using unsatis.able cores. \nASE 03: Automated Software Engineering, pages 94 105, 2003. IEEE Computer Society. [27] Armando Solar-Lezama, \nRodric Rabbah, Rastislav Bod\u00b4ik, and Ke\u00admal Ebcio.glu. Programming by sketching for bit-streaming pro\u00adgrams. \nPLDI 05: Programming Languages Design and Implemen\u00adtation, pages 281 294, 2005. ACM. [28] Armando Solar-Lezama, \nLiviu Tancau, Rastislav Bod\u00b4ik, Sanjit A. Seshia, and Vijay A. Saraswat. Combinatorial sketching for \n.nite programs. In ASPLOS 06: Architectural Support for Programming Languages and Operating Systems, \npages 404 415, 2006. ACM. [29] Saurabh Srivastava, Sumit Gulwani, and Jeffrey S. Foster. VS3: SMT solvers \nfor program veri.cation. In CAV 09: Computer-Aided Veri.cation, volume 5643 of Lecture Notes in Computer \nScience, pages 702 708, 2009. Springer. [30] F. Tip. A survey of program slicing techniques. Journal \nof Program\u00adming Languages, 3:121 189, 1995. [31] Wikipedia. Off-by-one error, the free encyclopedia, \n2004. [Online; accessed 28-March-2010]. [32] Yichen Xie and Alex Aiken. Scalable error detection using \nboolean satis.ability. In POPL 05: Principles of Programming Languages, pages 351 363, 2005. ACM. [33] \nAndreas Zeller. Isolating cause-effect chains from computer programs. In FSE 10: Foundations of Software \nEngineering, pages 1 10, 2002. ACM. [34] Andreas Zeller and Ralf Hildebrandt. Simplifying and isolating \nfailure-inducing input. IEEE Trans. Softw. Eng., 28:183 200, 2002.    \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Much effort is spent by programmers everyday in trying to reduce long, failing execution traces to the <i>cause</i> of the error. We present an algorithm for error cause localization based on a reduction to the maximal satisfiability problem (MAX-SAT), which asks what is the maximum number of clauses of a Boolean formula that can be simultaneously satisfied by an assignment. At an intuitive level, our algorithm takes as input a program and a failing test, and comprises the following three steps. First, using bounded model checking, and a bound obtained from the execution of the test, we encode the semantics of a bounded unrolling of the program as a Boolean <i>trace formula</i>. Second, for a failing program execution (e.g., one that violates an assertion or a post-condition), we construct an <i>unsatisfiable</i> formula by taking the formula and additionally asserting that the input is the failing test and that the assertion condition does hold at the end. Third, using MAX-SAT, we find a maximal set of clauses in this formula that can be satisfied together, and output the complement set as a potential cause of the error.</p> <p>We have implemented our algorithm in a tool called BugAssist that performs error localization for C programs. We demonstrate the effectiveness of BugAssist on a set of benchmark examples with injected faults, and show that in most cases, BugAssist can quickly and precisely isolate a few lines of code whose change eliminates the error. We also demonstrate how our algorithm can be modified to automatically suggest fixes for common classes of errors such as off-by-one.We have implemented our algorithm in a tool called BugAssist that performs error localization for C programs. We demonstrate the effectiveness of BugAssist on a set of benchmark examples with injected faults, and show that in most cases, BugAssist can quickly and precisely isolate a few lines of code whose change eliminates the error. We also demonstrate how our algorithm can be modified to automatically suggest fixes for common classes of errors such as off-by-one.</p>", "authors": [{"name": "Manu Jose", "author_profile_id": "81466640752", "affiliation": "University of California, Los Angeles, Los Angeles, CA, USA", "person_id": "P2690614", "email_address": "manujose@ucla.edu", "orcid_id": ""}, {"name": "Rupak Majumdar", "author_profile_id": "81100319213", "affiliation": "Max Planck Institute for Software Systems &#38; University of California, Los Angeles, Kaiserslautern, Germany", "person_id": "P2690615", "email_address": "rupak@mpi-sws.org", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993550", "year": "2011", "article_id": "1993550", "conference": "PLDI", "title": "Cause clue clauses: error localization using maximum satisfiability", "url": "http://dl.acm.org/citation.cfm?id=1993550"}