{"article_publication_date": "06-04-2011", "fulltext": "\n Systematic Editing: Generating Program Transformations from an Example Na Meng Miryung Kim Kathryn \nS. McKinley The University of Texas at Austin mengna152173@gmail.com, miryung@ece.utexas.edu, mckinley@cs.utexas.edu \nAbstract Software modi.cations are often systematic they consist of simi\u00adlar, but not identical, program \nchanges to multiple contexts. Exist\u00ading tools for systematic program transformation are limited because \nthey require programmers to manually prescribe edits or only sug\u00adgest a location to edit with a related \nexample. This paper presents the design and implementation of a program transformation tool called SYDIT. \nGiven an example edit, SYDIT generates a context\u00adaware, abstract edit script, and then applies the edit \nscript to new program locations. To correctly encode a relative position of the edits in a new location, \nthe derived edit script includes unchanged statements on which the edits are control and data dependent. \nFur\u00adthermore, to make the edit script applicable to a new context us\u00ading different identi.er names, the \nderived edit script abstracts vari\u00adable, method, and type names. The evaluation uses 56 systematic edit \npairs from .ve large software projects as an oracle. SYDIT has high coverage and accuracy. For 82% of \nthe edits (46/56), SYDIT matches the context and applies an edit, producing code that is 96% similar \nto the oracle. Overall, SYDIT mimics human programmers correctly on 70% (39/56) of the edits. Generation \nof edit scripts seeks to improve programmer productivity by relieving develop\u00aders from tedious, error-prone, \nmanual code updates. It also has the potential to guide automated program repair by creating program \ntransformations applicable to similar contexts. Categories and Subject Descriptors D.2.7 [Software Engineer\u00ading]: \nDistribution, Maintenance, and Enhancement restructuring General Terms Algorithm, Measurement, Experimentation \nKeywords Software evolution, program transformation, program differencing, empirical study 1. Introduction \nA typical software life-cycle begins with design, prototyping, and new code development. After deployment, \nsoftware enters a phase where developers spend time .xing bugs, refactoring, and adding functionality \nto existing code. Recent work observes that many changes are systematic programmers add, delete, and \nmodify code in numerous classes in similar, but not identical ways [15, 16, 25]. For example, Kim et \nal. .nd that on average, Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. \n. . $10.00 75% of structural changes to mature software are systematic. They .nd that these changes \nare not identical, but that their contexts have similar characteristics, such as calling the same method \nor accessing the same .eld. Nguyen et al. .nd that 17% to 45% of bug .xes are recurring .xes that involve \nsimilar edits to numer\u00adous methods [25]. Another class of systematic changes occur when API changes require \nall the API clients to update their code [12]. Performing systematic edits is currently tedious and error \nprone. Existing tools offer limited support for systematic edits. The search and replace feature in a \ntext editor is the most popular approach, but it supports only simple text replacements and can\u00adnot handle \nnon-contiguous edits, nor edits that require customiza\u00adtion for different contexts. Integrated Development \nEnvironments (IDEs), such as Eclipse, help with refactorings, but are con.ned to a prede.ned set of semantics-preserving \ntransformations. Re\u00adcent work proposes approaches for systematic editing, but none derive and apply context-aware \nedit scripts that use different vari\u00adable, method, and type names in a new context. Nguyen et al. suggest \nnew locations to edit based on changes to similar code fragments with an example, but require programmers \nto edit the code manually [23, 25]. With simultaneous editing, programmers edit pre-speci.ed clones in \nparallel, na\u00a8ively propagating exactly the same edit to all clones without regard to context, which leads \nto errors [7, 22, 29]. Programmers can also encode systematic ed\u00adits in a formal syntax using a source \ntransformation language, but this approach forces programmers to plan edit operations in ad\u00advance [4, \n5]. Andersen and Lawall s patch inference derives a more general edit from diff output, but its expressiveness \nis con.ned to term-replacements [1, 2]. Furthermore, it does not model the con\u00adtrol and data dependence \ncontext of edits, and it does not encode the edit positions with respect to relevant context nodes. This \npaper describes the design and implementation of an auto\u00admated program transformation tool called SYDIT. \nSYDIT generates edit scripts from program differences and their context, and then ap\u00adplies scripts to \nsimilar code fragments. SYDIT characterizes edits as Abstract Syntax Tree (AST) node additions, deletions, \nupdates, and moves. It uses control and data dependence analysis to capture the AST change context, i.e., \nrelevant unchanged program fragments that depend on the edits or on which edits depend. It abstracts \nedit positions and the names of variables, methods, and types to create a generalized program transformation \nthat does not depend on exact locations nor concrete identi.ers. We call these transformations, abstract, \ncontext-aware edit scripts. Given a new target location, SYDIT generates concrete AST transformations \ncustomized to the new context. SYDIT then transforms the code accordingly. To evaluate SYDIT, we create \nan oracle test suite of 56 sys\u00adtematic edit pairs where two method locations are at least 40% similar \nin terms of their syntactic contents, and experience at least one common edit between two program versions. \nWe draw this test suite directly from systematic updates performed by pro\u00adgrammers in jEdit, Eclipse \nJDT core, Eclipse debug, Eclipse core.runtime and Eclipse compare plug-ins. SYDIT takes as in\u00adput a source \nexemplar edit, which consists of an old and a new program fragment, and generates an edit script. In \nthis study, the programmer selects the target, and SYDIT generates concrete edits and applies them to \nthe target. SYDIT produces syntactically valid transformations for 82% of the target methods (46/56). \nIt perfectly mimics developer edits on 70% (39/56) of the targets. Syntactic program differencing considers \nthe human generated version and the SYDIT generated version 96% similar. Therefore, it would likely require \nonly modest manual effort to correct SYDIT s version. SYDIT achieves similar results on a suite of six \nsystematic edits applied to .ve or more method locations from open-source projects. The key contributions \nof this paper are: (1) how to generalize a program transformation from an example to make it applicable \nto similar but not identical contexts, and (2) a rigorous empirical validation of SYDIT. Our systematic \nediting approach seeks to improve programmer productivity when developers .x similar bugs, refactor multiple \nmethods similarly, migrate code when APIs change [12, 23, 27], and add similar features to multiple related \ncode locations. This approach is very .exible since developers can .rst develop and test a modi.cation \nin a single context and then apply it to multi\u00adple contexts. Although in this paper, the programmer is \nrequired to select the target edit location and then examine the results, we en\u00advision more automated \nuse cases as well. Given an example trans\u00adformation, additional analysis could automate .nding potential \nedit locations based on code similarity. By integrating SYDIT with au\u00adtomated compilation and testing, \ndevelopers can have more con\u00ad.dence about the correctness of generated edits before reviewing them. Furthermore, \nthis functionality could help guide automatic program repair by creating transformations applicable to \nsimilar contexts, applying them, and running regression tests on the SYDIT generated program version. \nThe rest of the paper is organized as follows. Section 2 illus\u00adtrates SYDIT s edit script generation \nand application on a motivat\u00ading example from the Eclipse debug plug-in. Section 3 presents our algorithms \nfor edit script generalization and application. Section 4 shows the effectiveness of SYDIT using a test \nsuite of independently developed systematic changes gathered from open-source projects. Section 5 compares \nour approach to related work and Section 6 dis\u00adcusses the limitations of our approach and ways to improve \nSYDIT s precision. 2. Motivating Example This section overviews our approach with a running exam\u00adple \ndrawn from revisions to org.eclipse.debug.core on 2006-10\u00ad05 and 2006-11-06. Figure 1 shows the original \ncode in black, additions in bold blue with a + , and deletions in red with a - . Consider methods mA \nand mB: getLaunchConfigurations\u00ad(ILaunchConfigurationType type) and getLaunchConfigura\u00adtions(IProject \nproject). These methods iterate over elements received by calling getAllLaunchConexfigurations(), process \nthe elements one by one, and when an element meets a certain condition, add it to a prede.ned list. Suppose \nthat Pat intends to apply similar changes to mA and mB. In mA, Pat wants to move the declaration of variable \nconfig out of the while loop and add code to process config as shown in lines 4, and 6-10 in mA. Pat \nwants to perform a similar edit to mB, but on the cfg variable instead of config. This example typi.es \nsystem\u00adatic edits. Such similar yet not identical edits to multiple methods cannot be applied using the \nsearch and replace feature or existing refactoring engines in IDE, because they change the semantics \nof a program. Even though these two program changes are similar, Aold to Anew 1. public ILaunchConfiguration[] \ngetLaunchConfigurations (ILaunchConfigurationType type) throws CoreException { 2. Iterator iter = getAllLaunchConfigurations().iterator(); \n 3. List configs = new ArrayList(); 4. + ILaunchCon.guration con.g = null; 5. while (iter.hasNext()) \n{ 6. -ILaunchConfiguration config = (ILaunchConfiguration)iter.next(); 7. + con.g = (ILaunchCon.guration)iter.next(); \n 8. + if (!con.g.inValid()) {  9. + con.g.reset(); 10. + }  11. if (config.getType().equals(type)) \n{ 12. configs.add(config); 13. } 14. } 15. return (ILaunchConfiguration[])configs.toArray  (new \nILaunchConfiguration[configs.size()]); 17.} SYDIT s replication of relevant edits on Bold, resulting \nin Bnew 1. protected List getLaunchConfigurations(IProject project) { 2. Iterator iter = getAllLaunchConfigurations().iterator(); \n 3. + ILaunchCon.guration cfg = null; 4. List cfgs = new ArrayList(); 5. while (iter.hasNext()) { \n6. -ILaunchConfiguration cfg = (ILaunchConfiguration)iter.next(); 7. + cfg = (ILaunchCon.guration)iter.next(); \n 8. + if (!cfg.inValid()) {  9. + cfg.reset(); 10. + }  11. IFile file = cfg.getFile(); 12. if (file \n!= null &#38;&#38; file.getProject().equals(project)) { 13. cfgs.add(cfg); 14. } 15. } 16. return \ncfgs; 17.}  Abstract edit script Figure 1. Systematic edit from revisions of org.eclipse.debug.core \nwithout assistance, Pat must manually edit both methods, which is tedious and error-prone. Using SYDIT, \nPat applies the change only to mA and then SYDIT creates an edit script and applies it to mB. SYDIT applies \na syntac\u00adtic program differencing algorithm to mAold and mAnew and then characterizes the exemplar edit \n(lines 4, and 6-10) in terms of a se\u00adquence of inserts, deletes, moves, and updates. For each edit, it \nper\u00adforms data and control dependence analysis to determine the edit s corresponding context. It then \nabstracts variable, method, and type names and encodes edit positions relative to the extracted context. \nThis identi.er and edit position abstraction makes the edits appli\u00adcable to similar yet not identical \ncontexts. Pat next identi.es mB as a target for this edit script. Based on the extracted context and \nthe abstract names in the edit script, SYDIT matches the extracted context against the mB target and \nidenti.es relevant code fragments that the edits are applicable to (i.e., lines 2, 5, and 6 in mB). It \nthen creates concrete edits customized to mB, and applies them to mB. The bottom of Figure 1 illustrates \nthe content of the abstract edit script derived from the two versions of mA. Currently, SYDIT does not \nguarantee to generate an edit script containing the fewest edits. Context extraction. SYDIT extracts \nthe context of edits through data and control dependence analysis, which makes it possible to apply the \nedit script to code fragments that share similar data and control .ows but are not identical to mA. For \nexample, the location of the updated ILaunchConfiguration declaration is the child position 0 inside \nthe while loop. Position 0 means the .rst AST child node of the while loop. The updated statement is \ncontrol dependent on the while (line 5), and data dependent on the iterator declaration (line 2). We \ntherefore include both lines 2 and 5 in the abstract context of this update. Identi.er abstraction. SYDIT \nabstracts all variable, method, and type names to make the edits applicable to contexts that use differ\u00adent \nidenti.er names. For instance, in the example, it abstracts the config variable in mA to v2. Edit position \nabstraction. SYDIT encodes the syntactic position of each edit with respect to the extracted context \nnodes. For example, the source of the moved ILaunchConfiguration declaration is child position 0 of the \nwhile (i.e., its .rst AST child node), and the target is child position 1 of the method declaration node \n(i.e., its second AST child node). Edit script application. To apply an abstract edit script to a tar\u00adget \ncontext, SYDIT matches the abstracted context against the target method and concretizes the abstract \nidenti.er names and edit posi\u00adtions with respect to the target method. For example, it concretizes v2 \nto cfg, and encodes the target move position as the child posi\u00adtion 1 of mB s method declaration node. \nThis automatic program transformation approach offers a .ex\u00adible mechanism for improving programmer productivity. \nSystem\u00adatic editing simpli.es the tedious task of applying similar changes to multiple locations. Context \nabstraction and concretization in\u00adcreases the chance to apply systematic edits correctly and consis\u00adtently. \nIn this paper, the programmer selects both the source and tar\u00adget method and audits the result. With \nintegration with automated compilation and testing, examining the correctness of SYDIT gener\u00adated edits \ncould be further automated. In all cases, the programmer should audit SYDIT generated versions through \ntesting, inspection, or both. The coverage and accuracy of the edit scripts depend on the choice of the \nsource exemplar edit, how context and abstract names are represented, and the algorithm that matches \nthe extracted edit context to a target. 3. Approach This section describes the two phases of SYDIT. Phase \nI takes as input an old and new version of method mA as its exemplar edit, and creates an edit script \nfrom mAo and mAn. Phase II applies the edit script to a new context, mB, producing a modi.ed method mBs. \nWe .rst summarize the steps in each phase and then describe each step in detail. Phase I: Creating Edit \nScripts SYDIT compares an exemplar edit, mAo and mAn, and describes the differences as a sequence of \ninsertions, deletions, updates, and moves: .A = {eo,e1,...,en}. SYDIT identi.es the context of the edit \n.A based on data, control, and containment dependences between each ei and other statements in mAo and \nmAn.  SYDIT abstracts the edit, ., by encoding each ei position with respect to its extracted context \nand by replacing all con\u00adcrete variable, method, and type names with abstract identi.er names.  Phase \nII: Applying Edit Scripts SYDIT matches the abstract context for . to mB s syntax tree.  If they match, \nSYDIT generates a concrete edit .B by translat\u00ading abstract edit positions in . into concrete positions \nin mB and abstract identi.ers in . into concrete identi.ers in mB.  SYDIT then applies .B to mB, producing \nmBs.  3.1 Phase I: Creating Abstract Edit Scripts This section explains how SYDIT create an abstract \nedit script. 3.1.1 Syntactic Program Differencing SYDIT compares the syntax trees of an exemplar edit, \nmAo and mAn, using a modi.ed version of ChangeDistiller [9]. ChangeDis\u00adtiller generates deletes, inserts, \nmoves, and updates. We chose ChangeDistiller in part because it produces concise AST edit op\u00aderations \nby (1) representing related node insertions and deletions as moves and updates and (2) aggregating multiple \n.ne-grained expression edits into a single statement edit. ChangeDistiller computes one-to-one node mappings \nfrom the original and new AST trees for all updated, moved, and unchanged nodes. If a node is not in \nthe mappings, ChangeDistiller generates deletes or inserts as appropriate. It creates the mappings bottom-up \nusing: bigram string similarity for leaf nodes (e.g., statements and method invocations), and subtree \nsimilarity for inner nodes (e.g., while and if statements). It .rst converts each leaf node to a string \nand computes its bigram the set of all adjacent character pairs. The bigram similarity of two strings \nis the size of their bigram set intersection divided by the average of their sizes. If the similarity \nis above an input threshold, s, ChangeDistiller includes the two leafs in its pair-wise mappings. It \nthen computes subtree similarity based on the number of leaf node matches in each subtree, and establishes \ninner node mappings bottom up. We modify ChangeDistiller s matching algorithms in two ways. First, we \nrequire inner nodes to perform equivalent control-.ow functions. For instance, the original algorithm \nsometimes mapped a while to an if node. We instead enforce a structural match, i.e., while nodes only \nmap to while or for nodes. Second, we match leaf nodes to inner nodes using bigram string similarity. \nThis change overcomes inconsistent treatment of blocks. For example, ChangeDistiller treats a catch clause \nwith an empty body as a leaf node, but a catch clause with a non-empty body is an inner node. Given a \nresulting set of AST node mappings, SYDIT describes edit operations with respect to the original method \nmAo as follows: delete (Node u): delete node u from mAo. insert (Node u, Node v, int k): insert node \nu and position it as the (k + 1)th child of node v. move (Node u, Node v, int k): delete u from its current \nposition in mAo and insert u as the (k + 1)th child of v. update (Node u, Node v): replace u in mAo with \nv. This step in\u00adcludes changing the AST type in the resulting tree to v s type and maintaining any of \nu s AST parent and children relation\u00adships in v. The resulting sequence of syntactic edits is .A = {ei|ei \n.{delete (u), insert (u,v,k), move (u,v,k), update (u,v)}}. We use a total order for ei to ease relative \npositioning of edits. Figure 2 presents the mapping for our example, where O is a node in the old version \nmAo and N is a node in the new version mAn. Below we show the concrete edit script .A that transforms \nmAo into mAn for our example: 1. update (O6, N4) O6 = ILaunchConfiguration config = (ILaunchConfiguration) \niter.next(); N4 = ILaunchConfiguration config = null; 2. move (O6, N1, 2) 3. insert (N7, N5, 0) N7 = \nconfig = (ILaunchConfiguration) iter.next(); 4. insert (N8, N5, 1) N8 = if (!config.inValid()) 5. insert \n(N9, N8, 0) N9 = then 6. insert (N10, N9, 0) N10 = config.reset();   3.1.2 Extracting Edit Contexts \nSYDIT extracts relevant context from both the old and new versions. For each edit ei . .A, SYDIT analyzes \nmAo and mAn to .nd the unchanged nodes on which changed nodes in ei depend. These dependences include \ncontainment dependences and the source and sink of control and data dependences. We call these nodes \ncontext. Context information increases the chance of generating syntac\u00adtically valid edits and also serves \nas anchors to position edits cor\u00adrectly in a new target location. First, in order to respect the syntax \nrules of the underlying programming language, we include AST nodes that the edits require. For example, \ninsertion of a return statement must occur inside a method declaration subtree. This context increases \nthe probability of producing a syntactically valid, compilable program. Second, we use control dependences \nto de\u00adscribe the position to apply an edit, such as inserting a statement at the .rst child position \nof while loop. While the edit may be valid outside the while, positioning the edit within the while increases \nthe probability that the edit will be correctly replicated. Third, con\u00adtext helps preserve data dependences. \nFor example, consider an edit that inserts statement S2: foo++; after S1: int foo = bar;. If we require \nS1 to precede S2 by including S1 in the context of S2, the resulting edit will guarantee that foo is \nde.ned before it is incremented. However, including and enforcing more dependence requirements in the \nedit context may decrease the number of target methods that will match and thus may sacri.ce coverage. \nFormally, node y is context dependent on x if one of the follow\u00ading relationships holds: Data dependence: \nnode x uses or de.nes a variable whose value is de.ned in node y. For example, N10 uses variable config, \nwhose value is de.ned in N7. Therefore, N10 is data dependent on N7.  Control dependence: node y is \ncontrol dependent on x if y may or may not execute depending on a decision made by x. For\u00admally, given \na control-.ow graph, node y is control dependent on x, if: (1) y post-dominates every vertex p in x r \ny, p = x, and (2) y does not strictly post-dominate x [6].  Containment dependence: node y is containment \ndependent on x if y is a child of x in the AST. For instance, N4 is containment dependent on N1.  To \nextract the context for an edit script, we compute control, data, and containment dependences on the \nold and new versions. The context of an edit script .A is the union of these dependences. The containment \ndependence is usually redundant with immediate con\u00adtrol dependence of x, except when loops contain early \nreturns. To combine dependences, SYDIT projects nodes found in the new ver\u00adsion mAn onto corresponding \nnodes in the old version mAo based on the mappings generated by the modi.ed version of ChangeDis\u00adtiller. \nFor each ei . .A, we determine relevant context nodes as follows. delete (u): The algorithm computes \nnodes in mAo that depend on the deleted node, u. insert (u, p, k): Since u does not exist in mAo, the \nalgorithm .rst computes nodes in mAn on which u depends and then projects them into corresponding nodes \nin mAo. move (u, v, k): The algorithm .nds the dependent nodes in both mAo and mAn related to u. The \nnodes in the new version help guarantee dependence relationships after the update. It projects the nodes \nfrom mAn into corresponding nodes in mAo and then unions the two sets. update (u, v): The algorithm .nds \nthe dependent nodes in mAo related to the updated node, u. It also .nds dependent nodes in mAn related \nto the node v. It projects the nodes from mAn into corresponding nodes in mAo and then unions the two \nsets. Consider insert (N7, N5, 0) from Figure 2. The inserted node N7 is control dependent on N5, and \ndata dependent on N2 and N4. Mapping these nodes to the old version yields the context node set {O2, \nO4, O6}. The move (O6, N1, 2) operation is more complicated because O6 depends on the node set C1 = {O4, \nO2}in the old version, while N4, N1 s child at position 2, depends on the node set C2 = {N1} in the new \nversion. After deriving the two sets, we project C2 onto nodes in mAo, which yields C3 = {O1}. Finally, \nwe union C1 and C3 to get the context node set {O1, O2, O4} for the move operation. Figure 2 illustrates \nthe result, marking irrelevant nodes with dotted lines and context nodes in gray. SYDIT allows the user \nto con.gure the amount of context. For example, the number of dependence hops, k, controls how many surrounding, \nunchanged nodes to include in the context. Setting k =1 selects just the immediate control and data dependent \nnodes. Setting k = 8 selects all control and data dependent nodes. We can restrict dependences to reaching \nde.nitions or include the nodes in a chain of de.nitions and uses depending on k. SYDIT differentiates \nupstream and downstream dependences. Upstream dependences precede the edit in the text, whereas downstream \ndependences follow the edit. The default setting of SYDIT is k =1 with control, data, and containment \nupstream dependences, which was best in practice. Section 4 shows how varying context affects SYDIT s \ncoverage and accuracy. 3.1.3 Abstracting Identi.ers and Edit Positions At this point, the edit script \nand its context use concrete identi.er names and edit positions from the exemplar edit. To make the edit \nscript more applicable, we abstract identi.er names and edit positions in the edit script. To abstract \nidenti.ers, we replace all concrete variable, method, and type names with equivalent abstract representations: \nT$x, m$x, and v$x respectively. Each unique concrete identi.er corresponds to a unique abstract one. \nFor example, we convert the concrete expression !config.inValid() in Figure 2 to !v2.m5() in Figure 3. \nWe abstract the position of edits to make them applicable to code that differs structurally from the \noriginal source example. We encode an edit position as a relative position with respect to all the context \nnodes, instead of all nodes in the original syntax tree. For example, we convert the concrete edit move \n(O6, N1, 2) to an abstract edit move (AO4, AN1, 1). In this case, the abstract edit position is child \nposition 1 of the while because the context of the edit includes the de.nition of ILaunchConfiguration \nat abstract child position 0 and no other dependences. This relative position ensures that ILaunchConfiguration \nis de.ned by some  Figure 3. Abstract edit script Figure 4. Syntactic edit suggestion for mB statement \nbefore it is used, but requires no other statements in the 3.2 Phase II: Applying Abstract Edits while. \nWhen we apply the edit, we require the context to match This section describes how SYDIT applies an edit \nscript . to a and apply edits relative to the context position in the target, not the method mB, producing \na modi.ed method mBs. concrete positions in the original method. Abstracting edit positions is essential \nfor applying an edit when the target method satis.es the context dependences, regardless of the exact \npositions of the 3.2.1 Matching Abstract Contexts statements in the code. The goal of our matching algorithm \nis to .nd nodes in the target method that match the context nodes in . and that induce one-to\u00adone mappings \nbetween abstract and concrete identi.er names. To simplify this process, we .rst abstract the identi.ers \nin mB. We use the procedure as described in Section 3.1.3 to create mBAbstract from mB. For concision \nin this section, we simply use mB instead of mBAbstract. This problem can be posed as the labeled subgraph \nisomorphism problem. Although we experimented with an off-the-shelf imple\u00admentation [20], adapting it \nto match nodes while simultaneously requiring one-to-one symbolic identi.er mappings is dif.cult. Yet \nthese two features are essential requirements for applying edits to new contexts. See Section 3.2.2 for \nmore details. The algorithm we propose below tolerates inexact label matches for unchanged context nodes \nwhile enforcing one-to-one symbolic identi.er map\u00adpings. The intuition behind our algorithm is to .rst \n.nd candidate leaf matches and then use them to match inner nodes. We .nd as many candidate matches as \npossible between leaf nodes in the abstract context and leaf nodes in the target tree, x . AC, y . mB, \nwhere x and y form an exact match, i.e., the equivalent AST node types and node labels (see below). Based \non these exact matches (x, y), we add node matches (u, v), where u and v are on paths from the respective \nroot nodes, u . (rootAC r x) and v . (rootmB r y). We add (u, v) type matches bottom\u00adup, requiring only \ntheir node types to be equivalent. Finally for each unmatched leaf in the abstract context, we .nd additional \ntype matches based on the established set of matches. We repeat these steps until the set of candidate \nleaf matches, CL, does not increase any more. We de.ne two types of node matches and one type of path \nmatches: Type match: Given two nodes u and v,(u,v) is a type match if their AST node types match. For \nexample, both are ifs or one is a while and the other is a for. The conditions need not match. Exact \nmatch: Given two nodes u and v,(u,v) is an exact match if it is a type match and their AST labels are \nequivalent. We de.ne the label as the abstract strings in the statements and ignore numerics in abstract \nidenti.ers. For example, T1 v1 = null; and T2 v2 = null; are equivalent since we ignore the numeric and \nconvert them both to T v = null; . Path match: Given two paths p1 and p2, (p1,p2) is a path match if \nfor every node u on p1, there exists node v on p2 where (u, v) is a type match. For example, given two \nleaf nodes x and y, the paths match if parent(x) and parent(y) type match, parent(parent(x)) and parent(parent(y)) \ntype match, and so on. We use these de.nitions to map the nodes in the abstract context AC in . to mB \nin the following four steps, which Algorithm 1 describes procedurally. 1. SYDIT .nds all exact leaf matches \nbetween AC and mB and adds each (x, y) pair to a set of candidate leaf matches, CL. 2. Based on CL, \nSYDIT then tries to .nd the best path match for each leaf node x where (x, y) . CL and .nds node matches \nbased on the best path match. Let p1= rootAC r x and p2= rootmB r y. This step is broken into three cases, \nfor each node match (x, y) in CL, (a) If there exists one path match (p1,p2) between AC and mB, we add \nall its constituent node matches (u, v) on these paths to M. (b) If there exists multiple path matches, \ne.g., (p1,(rootmB r y1)) and (p1,(rootmB r y2)), and one of these path matches contains more constituent \nnodes already in the set established matches M, we select the best of these path matches and add constituent \n(u, v) matches to M. (c) If there exists multiple path matches with the same num\u00adber of constituent \nnode matches in M, SYDIT leverages sib-   Algorithm 1: Matching Abstract Context to Target Tree Input: \nAC, mB /* abstract context and abstract target tree */ Output: M /* a set of node matches from AC to \nmB */ /* 1. create candidate leaf exact matches */ CL := \u00d8; M := \u00d8; foreach leaf node x . AC do foreach \nleaf node y . mB do if exactMatch(x, y) then CL:= CL .{(x, y)}; end end end repeat /* 2(a). create matches \nbased on path matches */ foreach (x, y) . CL such that . (x, z) . CL . y= z do p1 =(rootAC . x); p2 =(rootmB \n. y); if pathMatch(p1,p2) then M:= M .{(u, v) | u . p1 , where (u,v) is a type match and v . p2 and u \nand v appear in the same position on paths p1 and p2}; end end /* 2(b). select the best path match and \nadd new node matches it induces */ foreach (leaf node x . AC such that (x, y) . CL . (x,y) ./M) do p1 \n=(rootAC . x); p2 =(rootmB . y); select y with the maximum pathMatchScore(p1, p2, M); M:= M .{(u, v) \n| u . p1 and v . p2, where (u,v) is a type match and u and v appear in the same position on paths p1 \nand p2}; end /* 2(c). disambiguate path matches based on the sibling order of matched leaf nodes in \nM */ foreach (leaf node x . AC such that (x, y) . CL . (x,y) ./M) do select y with the maximum LCSMatchScore(x,y,M); \nM:= M .{(u, v) | u . p1 and v . p2, where (u,v) is a type match and u and v appear in the same position \non paths (rootAC . x) and (rootmB . y}; end /* 3. establish symbolic identifier mappings */ S:= \u00d8; foreach \n(u, v) . M do S:= S .{(T$n, T$m), (v$i, v$j), and/or (m$k, m$l) that are supported by (u, v)}; end removeConflicts(S, \nM); /* 4. relax constraints to add leaf candidates */ CL:= CL . relaxConstraints(AC, M); until CL reaches \nits .x point ; ling ordering relationships among the leaf nodes to dis\u00adambiguate the best path match. \nGiven a leaf node x . AC, suppose that path p1 matches with multiple paths, e.g., (p2= rootmB r y2), \n(p3= rootmB r y3), with the same score and assume that y2 precedes y3 in sibling order. If a node match \n(u, v) exists in M in which u precedes x in terms of sibling order, and v is a sibling between y2 and \ny3, SYDIT prefers a path match ((rootAC r x), (rootmB r y3)), since this choice is consistent with an \nalready estab\u00adlished match (u, v). Similarly, based on this path match, we add constituent node matches \non the matched paths to  M. While this approach is similar to how the longest com\u00admon subsequence (LCS) \nalgorithm align nodes [14], our ap\u00adproach matches leaf nodes based on established matches in M. 3. SYDIT \nestablishes mappings between symbolic identi.ers in AC and mB by enumerating all node matches in M. For \nexample, if the label of matched nodes are T1 v1 = null; and T2 v2 = null; , we add the symbolic identi.er \nmappings (T1, T2) and (v1, v2) to S. While collecting identi.er mappings, the algorithm may encounter \ninconsistencies, such as (T1, T3), which violates an already established mapping from T1 to T2. To remove \nthe con.ict between (T1, T2) and (T1, T3), SYDIT counts the number of node matches that support each \nmapping. It keeps the mapping with the most support, and removes other mappings from S and all their \nsupporting node matches from M. 4. SYDIT leverages the parent-child relationship of matched nodes in \nM to introduce type matches for unmatched leaf(s) in AC. For each unmatched leaf z in AC, SYDIT traverses \nbottom-up along its path to root in order to .nd the .rst ancestor u which has a match (u, v) . M . Next, \nif it .nds an unmatched node w in the subtree rooted at v and if (z, w) is a type match, SYDIT adds it \ninto CL. We repeat steps 2 to 4 until step 4 does not add any to  CL. At any point in this process, \nif every node in the abstract context AC has a match in M, then we proceed to derive concrete edits customized \nto mB, described in Section 3.2.3. If we fail to .nd a match for each node, SYDIT reports to the user \nthat the edit context does not match and it cannot replicate the edit on the target context.  3.2.2 \nAlternative matching algorithms Standard labeled subgraph isomorphism is a promising alternative approach \nfor matching abstract context in . to a new target method mB that we also explored. We formulated both \nthe abstract con\u00adtent and target method as graphs in which nodes are labeled with their AST node types, \nand edges are labeled with constraint rela\u00adtionships between nodes, such as containment, data, and control \ndependences. To preserve a one-to-one mapping between abstract and concrete identi.ers, we included additional \nlabeled nodes to represent the sequence of symbols appearing in the statement. We included variable names, \nmethod names, type names, as well as constants like null and operators like = as node labels. Next, we \nconnected all the identi.ers with the same name with edges labeled same name. We thus converted our problem \nto .nding an isomor\u00adphic labeled subgraph in the target method s graph for the abstract context s graph. \nFunction pathMatch(path p1, path p2) t1 := p1 s bottom-up iterator; t2 := p2 s bottom-up iterator; while \nt1.hasP rev() . t2.hasP rev() do u := t1.prev(); v := t2.prev(); if !EquivalentNodeT ype(u, v) then return \nfalse; end end if t1.hasP rev() then return false; end return true; Function pathMatchScore(path p1, \npath p2, matches M ) counter := 0; t1 := p1 s bottom-up iterator; t2 := p2 s bottom-up iterator; while \nt1.hasP rev() . t2.hasP rev() do u := t1.prev(); v := t2.prev(); if (u, v) . M then counter ++; end \nend return counter; Function LCSMatchScore(node x, node y, matches M) score := 0; /* identify left siblings \nof x and y */ l1 := left children(parent(x),x); l2 := left children(parent(y),y); /* identify right siblings \nof x and y */ r1 := right children(parent(x),x); r2 := right children(parent(y),y); /* compute the size \nof longest common sequences of l1 and l2 and r1 and r2 respectively with respect to M. */ score := LCS(l1,l2,M)+ \nLCS(r1,r2,M); return score; Function removeConflicts(mappings S, matches M) foreach (s1,s2) . S do T \n= {t | (s1,t) . S }; if |T | > 1 then select t with the most supporting matches; T = T -(s1, t); foreach \ns2 . T do S := S -{(s1,s2)}; M := M -{(u, v)|(u, v) supports (s1,s2)}; end end end Function relaxConstraints(context \nAC, matches M) CL := \u00d8 foreach leaf node z . AC such that .(z, w) . M do u := z; repeat u := parent(u); \nuntil u=null ..(u, v) . M ; if u =null then CL := CL .{(z, w)|w is a node in the subtree rooted at v, \nwhere (z, w) is a type match and w is not matched}; end end return CL; A problem with this direct conversion \nis that it requires each symbol in the abstract context must match a symbol in the target method. This \nrequirement is needlessly strict for the unchanged context nodes. For instance, consider inserting a \nchild of an if in the target. When the guard condition of the target if is a little differ\u00adent from the \nknown if, i.e., field != null vs. this.getField() != null, exact graph isomorphism fails in this case. \nAlthough our algorithm is a little messy compared with an off-the-shelf labeled subgraph isomorphism \nalgorithm [20], the heuristics for identi.er replacements and siblings alignment work well in practice. \nSpec\u00adifying which node matches to relax, and when and how to relax them is the key contribution of the \nalgorithm we present above.  3.2.3 Generating Concrete Edits To generate the concrete edit script .B \nfor mB, SYDIT substitutes symbolic names used in . and recalculates edit positions with respect to the \nconcrete nodes in mB. This process reverses the abstraction performed in Section 3.1.3. The substitution \nis based on the symbolic identi.er mappings established in Section 3.2.1, e.g., (T1, T2), and the abstract\u00adconcrete \nidenti.er mappings established in Section 3.1.3, e.g., (T1, int), (T2, int). For this speci.c case, each \ntime T1 oc\u00adcurs in ., SYDIT uses int in .B. Some edits in . use symbolic identi.ers that only exist in \nthe new version, thus the name does not exist in the original code of mAo or mBo and this name thus has \nno match. In this case, we borrow the identi.er name from mAn. For example, the identi.er inValid used \nin Figure 1 only exists in mAn, and is not in mBo, nor should we ever expect it to appear in mAo. We \nthus just use the name from mAn, stored in . for .B . We make edit positions concrete with respect to \nthe concrete nodes in mB. For instance, with the node match (u, v), an abstract edit which inserts a \nnode after u is translated to a concrete edit which inserts a node after v. Using the above algorithms, \nSYDIT produces the following concrete edits for mB (see Figure 4). 1. update (O6, N3), N3 = ILaunchConfiguration \ncfg = null; 2. move (O6, N1, 1) 3. insert (N7, N5, 0), N7 = cfg = (ILaunchConfiguration) iter.next(); \n 4. insert (N8, N5, 1), N8 = if (!cfg.inValid()) 5. insert (N9, N8, 0), N9 = then 6. insert (N10, N9, \n0), N10 = cfg.reset();  This edit script shows that mB is changed similarly to mA. It differs because \nof the move (O6, N1, 1), which puts the designated node in a different location compared to mA. This \ndifference does not compromise the edit s correctness since it respects the relevant data dependence \nconstraints encoded in .. SYDIT then converts .B to Eclipse AST manipulations to produce mBs. 4. Evaluation \nTo assess the coverage and accuracy of SYDIT, we create an ora\u00adcle data set of 56 pairs of example edits \nfrom open source projects, which we refer to simply as the examples. To examine the capabil\u00adities of \nSYDIT, we select a range of simple to complex examples, and show that SYDIT produces accurate edits across \nthe examples. We compare SYDIT to common search and replace text editor func\u00adtionality and demonstrate \nthat SYDIT is much more effective. We evaluate the sensitivity of SYDIT to the source and target method. \nMost correct edits are insensitive to this choice, but when there is a difference, choosing a simpler \nedit as the source method typically leads to higher coverage. We also study the best way to character\u00adize \nedit context. We .nd that more context does not always yield more accurate edits. In fact, minimal, but \nnon-zero context seems to be the sweet spot that leads to higher coverage and accuracy. Con.guring SYDIT \nto use an upstream context with k =1 yields the highest coverage and accuracy on our examples. For the \nevaluation data set, we collected 56 method pairs that ex\u00adperienced similar edits. We included 8 examples \nfrom a prior study of systematic changes to code clones from the Eclipse jdt.core plug-in and from jEdit \n[16]. We collected the remaining 48 exam\u00adples from 42 releases of the Eclipse compare plug-in, 37 releases \nof the Eclipse core.runtime plug-in, and 50 releases of the Eclipse Identical Single node SI Multiple \nnodes Contiguous Non-contiguous CI NI examples matched 7 5 7 7 11 8 compilable correct 5 5 7 7 8 8 coverage \n71% 100% 73% accuracy 71% 100% 73% similarity 100% 100% 100% Abstract SA CA NA examples 7 12 12 matched \n7 9 10 compilable 6 8 9 correct 6 6 7 coverage 100% 75% 83% accuracy 86% 50% 58% similarity 86% 95% \n95% Total coverage 82% (46/56) Total accuracy 70% (39/56) Total similarity 96% (46)  Table 1. SYDIT \ns capabilities, coverage, and accuracy for k=1, upstream control and data dependences debug plug-in. \nFor each pair, we computed the syntactic differ\u00adences with Change Distiller. We identi.ed method pairs \nmA and mB that share at least one common syntactic edit between the old and new version and their content \nis at least 40% similar. We use the following similarity metric: |matchingNodes(mA, mB)| similarity(mA, \nmB) = (1) size(mA)+ size(mB) where matchingNodes(mA, mB) is the number of matching AST node pairs computed \nby ChangeDistiller, and size(mA) is the num\u00adber of AST nodes in method mA. We manually inspected and \ncategorized these examples based on (1) whether the edits involve changing a single AST node vs. multiple \nnodes, (2) whether the edits are contiguous vs. non\u00adcontiguous, and (3) whether the edits content is \nidentical vs. ab\u00adstract. An abstract context requires type, method, or variable name abstraction. To \ntest this range of functionality in SYDIT, we chose at least 7 examples in each category. Table 1 shows \nthe number of examples in each of these six categories. The systematic change examples in the data set \nare non-trivial syntactic edits that include on average 1.66 inserts, 1.54 deletes, 1.46 moves, and 0.70 \nupdates. Coverage and accuracy. For each method pair (mAo, mBo) in the old version that changed similarly \nto become (mAn, mBn) in the new version, SYDIT generates an abstract, context-aware edit script from \nmAo and mAn and tries to apply the learned edits to the target method mBo, producing mBs. In Table 1, \nmatched is the number of examples for which SYDIT matches the learned context to the target method mBo. \nThe compilable row is the number of examples for which SYDIT produces a syntactically-valid program, \nand correct is the number of examples for which SYDIT replicates edits that are semantically identical \nto what the programmer actually did. matched correct Coverage is ,and accuracy is . We also measure \nexamples examples syntactic similarity between SYDIT s output and the expected output according to the \nabove similarity formula (1). This table uses our best con.guration of k=1, upstream context only, i.e., \none source node for each control and data dependence edge in the context, in addition to including a \nparent node of each edit. For this con.guration, SYDIT matches the derived abstract Aold to Anew private \nvoid paintSides(GC g, MergeSourceViewer tp, Canvas canvas, boolean right) {... -g.setLineWidth(LW); + \ng.setLineWidth(0 /* LW */); ... } Bold to Bnew private void paintCenter(Canvas canvas, GC g) { ... if \n(fUseSingleLine) { ... -g.setLineWidth(LW); + g.setLineWidth(0 /* LW */); ... } else { if(fUseSplines){ \n... -g.setLineWidth(LW); + g.setLineWidth(0 /* LW */); ... } else { ... -g.setLineWidth(LW); + g.setLineWidth(0 \n/* LW */); }} ... } Figure 5. A non-contiguous identical edit script (NI) for which SYDIT cannot match \nthe change context (org.eclipse.compare: v20060714 vs. v20060917) Aold to Anew 1. public IActionBars \ngetActionBars() { 2. + IActionBars actionBars = fContainer.getActionBars(); 3. -if (fContainer == null) \n{ 4. + if (actionBars == null &#38;&#38; !fContainerProvided) {  5. return Utilities.findActionBars(fComposite); \n 6. } 7. -return fContainer.getActionBars(); 8. + return actionBars; 9. }  Bold to Bnew 1. public \nIServiceLocator getServiceLocator() { 2. + IServiceLocator serviceLocator = fContainer.getServiceLocator(); \n 3. -if (fContainer == null) { 4. + if (serviceLocator == null &#38;&#38; !fContainerProvided) {  5. \nreturn Utilities.findSite(fComposite); 6. } 7. -return fContainer.getServiceLocator(); 8. + return \nserviceLocator; 9. }  Bold to Bsuggested 1. public IServiceLocator getServiceLocator() { 2. + IServiceLocator \nactionBars = fContainer.getServiceLocator(); 3. -if (fContainer == null) {  4. + if (actionBars == \nnull &#38;&#38; !fContainerProvided) { 5. return Utilities.findSite(fComposite); 6. } 7. -return fContainer.getServiceLocator(); \n 8. + return actionBars; 9. }  Figure 6. A non-contiguous, abstract edit script for which SYDIT produces \nedits equivalent to the developer s (org.eclipse.compare: v20061120 vs. v20061218) SI: single, identical \nedit 8 targets 8 matched 8 correct 100% coverage (8/8) 100% accuracy (8/8) 100% similarity CI: contiguous, \nidentical edits 5 targets 4 matched 4 correct 80% coverage (4/5) 80% accuracy (4/5) 100% similarity NI: \nnon-contiguous, identical edits 6 targets 4 matched 0 correct 67% coverage (4/6) 0% accuracy (0/6) 67% \nsimilarity SA: single, abstract edit 5 targets 5 matched 5 correct 100% coverage (5/5) 100% accuracy \n(5/5) 100% similarity CA: contiguous, abstract edits 4 targets 4 matched 4 correct 100% coverage (4/4) \n100% accuracy (4/4) 100% similarity NA: non-contiguous, abstract edits 4 targets 4 matched 4 correct \n100% coverage (4/4) 100% accuracy (4/4) 100% similarity Table 2. Replicating similar edits to multiple \ncontexts context for 46 of 56 examples, achieving 82% coverage. In 39 of 46 cases, the edits are semantically \nequivalent to the programmer s hand editing. Even for those cases in which SYDIT produces a different \nedit, the output and the expected output are often similar. For the examples SYDIT produces edits, on \naverage, its output is 96% similar to the version created by a human developer. In the examples where \nSYDIT cannot match the abstract con\u00adtext, the target method was usually very different from the source \nmethod, or the edit script needs to be applied multiple times in the target method. In Figure 5 (from \norg.eclipse.compare: v20060714 vs. v20060917), g.setLineWidth(LW) was replaced with g.setLineWidth(0) \nonce in the source method. The same edit needs to be replicated in three different control-.ow contexts \nin the target. Additional user assistance would solve this problem. Figure 6 shows a complex example \n(from org.eclipse.compare v20061120 vs. v20061218) that SYDIT handles well. Although the methods mAo \nand mBo use different identi.ers, SYDIT successfully matches mBo to the abstract context AC derived from \nmA, creating a version mBs, which is semantically equivalent to the manually crafted version mBn. In \naddition to these 56 pairs, we collected six examples that perform similar edits on multiple contexts \non at least 5 different methods. Table 2 shows the results. In four out of six categories, SYDIT correctly \nreplicates similar edits to all target contexts. In the CI category, SYDIT misses one of .ve target methods \nbecause the target does not fully contain the inferred abstract context. In the NI category, SYDIT produces \nincorrect edits in two out of six tar\u00adgets because it inserts statements before the statements that de.ne \nvariables used by the inserts, causing a compilation error. To pre\u00advent unde.ned uses, SYDIT should, \nand in the future will, adjust its insertion point based on data dependences. Comparison with search \nand replace. The search and replace (S&#38;R) feature is the most widely used approach to systematic \nedit\u00ading. Though SYDIT s goal is not to replace S&#38;R but to complement it, we nevertheless compare \nthem to assess how much additional ca\u00adpability SYDIT provides for automating repetitive edits. 32 of \nthe 56 examples in our test suite require non-contiguous and abstract edit scripts. S&#38;R cannot perform \nthem in a straightforward manner be\u00adcause even after a developer applies one or more S&#38;R actions, \nhe or she would have to customize either the type, method, and/or vari\u00adable names. For those 32 examples, \nSYDIT produces correct edits in 20 cases. For the remaining 24 examples, we categorize typical user-speci.ed \nS&#38;R sophistication into three levels:  Level 1: Search for a single line and replace it.  Level \n2: Search for several contiguous lines and replace them.  Level 3: Perform multiple S&#38;R operations \nto modify several non-contiguous lines.  On the remaining 24 examples, SYDIT handles 7 of 11 Level 1 \nexamples, 5 of 5 in Level 2, 7 of 8 in Level 3. Even though Level 1 examples are straightforward with \nS&#38;R, SYDIT misses cases like the one in Figure 5. Overall, SYDIT is much more effective and accurate \nthan S&#38;R. Self application of a derived edit script. To assess whether SYDIT generates correct program \ntransformations from an example, we derive an edit script from mAo and mAn and then apply it back to \nmAo. We then compare the SYDIT generated version with mAn. Similarly, we derive an edit script from mBo \nand mBn and compare the application of the script to mBo with mBn. In our experiments, SYDIT replicated \nedits correctly in all 112 cases. Selection of source and target method. SYDIT currently requires the \nuser to select a source and target method. To explore how robust SYDIT is to which method the user selects, \nwe switched the source and target methods for each example. In 35 of 56 examples (63%), SYDIT replicates \nedit scripts in both directions correctly. In 9 of 56 examples (16%), SYDIT could not match the context \nin either direction. In 7 out of 56 examples (13%), SYDIT replicates edit scripts in only one direction. \nIn the failed cases, the source method experiences a super set of the edits needed in the target. Additional \nuser guidance to select only a subset of edits in the source would solve this problem. Context characterization. \nTable 3 characterizes the number of AST nodes and dependence edges in each edit script with the best \ncon.guration of k =1 upstream only dependences. On average, an edit script involves 7.66 nodes, 2.77 \ndata dependence edges, 5.63 control dependence edges, 5.04 distinct type names, 4.07 distinct method \nnames, and 7.16 distinct variable names. These results show that SYDIT creates and uses complex abstract \ncontexts. Table 4 explores how different context characterization strate\u00adgies affect SYDIT s coverage, \naccuracy, and similarity for the 56 examples. These experiments vary the amount of control and data dependence \ncontext, but always include the containment context (see Section 3.1.2). The .rst part of the table shows \nthat SYDIT s results degrade slightly as the number of hops of control and data dependence chains in \nthe context increases. k =1 selects context nodes with one direct upstream or downstream control or data \ndependence on any edited node. We hypothesized that the inclusion of more contextual nodes would help \nSYDIT produce more accurate edits without sacri.cing coverage. Instead, we found the opposite. The second \npart of Table 4 reports on the effectiveness of iden\u00adti.er abstraction for variable (V), method (M), \nand type (T) names. As expected, abstracting all three leads to the highest coverage, while no abstraction \nleads to the lowest coverage. The third part of the same table shows results when varying the setting \nof upstream and downstream dependence relations for k = 1. All uses both upstream and downstream dependence \nrelations to characterize the context, containment only neither uses upstream nor downstream data or \ncontrol dependences, and upstream only uses only upstream dependence relations. Surprisingly, upstream \nonly which has neither the most nor fewest contextual nodes gains the best coverage and accuracy. ChangeDistiller \nsimilarity threshold. SYDIT uses ChangeDis\u00adtiller to compute AST-level edits between two program versions. \nWhen comparing the labels of AST nodes, ChangeDistiller uses a bigram similarity threshold and if the \nsimilarity between two node Size Min Max Median Average nodes 1 56 3.5 7.66 data dependences 0 34 0.5 \n2.77 control dependences 1 38 3 5.63 Abstraction types 0 17 4 5.04 methods 0 17 2 4.07 variable 0 26 \n4.5 7.16 Table 3. SYDIT s context characterization matched correct % coverage % accuracy % similarity \n Varying the number of dependence hops k=1 44 37 79% 66% 95% k=2 42 35 75% 63% 95% k=3 42 35 75% 63% \n95% Varying the abstraction settings abstract V T M 46 39 82% 70% 96% abstract V 37 31 66% 55% 55% abstract \nT 37 31 66% 55% 55% abstract M 45 38 80% 68% 96% no abstraction 37 31 66% 55% 55% Control, data, and \ncontainment vs. containment only vs. upstream only all (k=1) 44 37 79% 66% 95% containment only 47 38 \n84% 68% 90% upstream only (k=1) 46 39 82% 70% 96% Table 4. SYDIT s sensitivity to context characterization \ns matched correct % coverage % accuracy % similarity 0.6 46 39 82% 70% 96% 0.5 46 39 82% 70% 96% 0.4 \n46 39 82% 70% 96% 0.3 46 39 82% 70% 96% 0.2 45 33 80% 59% 86% Table 5. SYDIT s sensitivity to input \nthreshold s used in ChangeDistiller labels is greater than s, it matches the nodes. Our experiments use \na default setting of 0.5 for s. Since our edit script generation capa\u00adbility depends heavily on ChangeDistiller \ns ability to compute syn\u00adtactic edits accurately in the source example, we experimented with different \nsettings of s. Table 5 shows that when s is in the range of 0.3 to 0.6, SYDIT s accuracy does not change. \nWhen s is 0.2, the relaxed similarity criterion leads AST node mismatches, which produce incorrect updates \nor moves, and consequently SYDIT s cov\u00aderage, accuracy and similarity decrease. In summary, SYDIT has \nhigh coverage and accuracy, and is relatively insensitive to the thresholds in ChangeDistiller and the \nnumber of dependences in the context. The best con.guration is upstream with k =1 for SYDIT and s = 0.5 \nfor ChangeDistiller, which together achieve 82% coverage, 70% accuracy, and 96% similarity. 5. Related \nWork The related work includes program differencing, source transfor\u00admation languages, simultaneous text \nediting, and example-based program correction. Program differencing. Program differencing takes two program \nversions and matches names and structure at various granularities, e.g., lines [14], abstract syntax \ntree nodes [9, 32], control-.ow graph nodes [3], and program dependence graph nodes [13]. For example, \nthe ubiquitous tool diff computes line-level differences per .le using the longest common subsequence \nalgorithm [14]. JD\u00adiff computes CFG-node level matches between two program ver\u00adsions based on similarity \nin node labels and nested hammock struc\u00adtures [3]. ChangeDistiller computes syntactic differences using \na hierarchical comparison algorithm [9]. It matches statements, such as method invocations, using bigram \nstring similarity, and con\u00adtrol structures using subtree similarity. It outputs tree edit opera\u00adtions \ninsert, delete, move, and update. More advanced tools group sets of related differences with similar \nstructural characteristics and .nd exceptions to identify potentially inconsistent updates [15, 17]. \nSYDIT extends ChangeDistiller and goes beyond these approaches by deriving an edit script from program \ndifferences, abstracting the script, and then applying it elsewhere. Refactoring. Refactoring is the \nprocess of changing a software system that does not alter the external behavior of the code, yet improves \nthe internal structure [21]. Refactorings often require ap\u00adplying one or more elementary transformations \nto multiple code locations, and refactoring engines in IDEs automate many com\u00admon types of refactorings \nsuch as replace a magic number with a constant [10, 26]. While refactoring engines are con.ned to pre\u00adde.ned, \nsemantic-preserving transformations, SYDIT can automate semantic-modifying transformations. Source transformation \nlanguages. Source transformation tools reduce programmer burden by exhaustively applying repetitive, \nerror-prone updates. Programmers use special syntax to specify the code location and transformation [8, \n11, 18, 27, 30]. The most ubiq\u00aduitous approach is simple text substitution, e.g., .nd-and-replace in \nEmacs. More sophisticated systems use program structure informa\u00adtion. For example, A* and TAWK expose \nsyntax trees and primitive data structures, and Stratego/XT uses algebraic data types and term pattern \nmatching [11, 18, 30]. TXL borrows syntax from the under\u00adlying programming language to express systematic \ntree edits [5]. These tools require programmers to understand low-level program representations. To make \nthis approach easier for programmers, Boshernitsan et al. provide a visual language and an interactive \nsource transformation tool [4]. All these tools require programmers to plan and create edit scripts, \nwhereas SYDIT generates an abstract program transformation from an example edit. Simultaneous editing. \nSimultaneous text editing automates repet\u00aditive editing [7, 22, 29]. Users interactively demonstrate \ntheir edit in one context and the tool replicates identical lexical edits on the pre-selected code fragments. \nIn contrast, SYDIT learns an edit script from program differences and performs similar yet different \nedits by instantiating a syntactic, context-aware, abstract transformation. The Clever version control \nsystem detects inconsistent changes in clones and propagates identical edits to inconsistent clones [24]. \nWhile Clever and SYDIT both replicate similar edits, SYDIT exploits program structure and generates abstracts \nedits applicable to con\u00adtexts using different identi.ers. Suggesting edit locations. LibSync helps client \napplications mi\u00adgrate library API usages by learning migration patterns [23] with respect to a partial \nAST with containment and data dependences. Though it suggests what code locations to examine and shows \nex\u00adample API updates, it is unable to transform code. Furthermore, its .exibility is limited by its inability \nto abstract variable, method, and type names. FixWizard identi.es code clones based on object usage and \nin\u00adteractions, recognizes recurring bug-.xes to the clones, and sug\u00adgests a location and example edit \n[25]. FixWizard identi.es edit lo\u00adcations automatically only in pre-identi.ed clones. It does not gen\u00aderate \nsyntactic edits, nor does it support abstraction of variables, methods, and types. These limitations \nleave programmers with the burden of manually editing the suggested .x-location, which is error-prone \nand tedious. Example based program migration and correction. Program\u00adming-by-example [19] (PBD) is a \nsoftware agent-based approach that infers a generalized action script that corresponds to user s recorded \nactions. SMARTedit [19] instantiates this PBD approach to automate repetitive text edits by learning \na series of functions such as move a cursor to the end of a line. However, this approach is not suitable \nfor editing a program as it does not consider a program s syntax, control, or data dependences. The most \nclosely related work focuses on API migration [2, 23]. Andersen and Lawall .nd differences in the API \nusage of client code, create an edit script, and transform programs to use updated APIs [1, 2, 27]. Compared \nto SYDIT, their approach is limited in two respects: the edit scripts are con.ned to term-replacements \nand they only apply to API usage changes. Similar to our approach, Andersen and Lawall use control and \ndata dependence analysis to model the context of edits [1]. However, the context includes only inserted \nand deleted API method invocations and control and data dependences among them. Their context does not \ninclude un\u00adchanged code on which the edits depend. Thus, when there is no deleted API method invocation, \nthe extracted context cannot be used to position edits in a target method. SYDIT is more .exible because \nit computes edit context that is not limited to API method invocations and it can include unchanged statements \nrelated to ed\u00adits. Therefore, even if the edits include only insertions, SYDIT can correctly position \nedits by .nding corresponding context nodes in a target method. Furthermore, Andersen and Lawall only \nevaluate their approach on a few examples, whereas we perform a compre\u00adhensive evaluation on open-source \napplications. Automatic program repair generates candidate patches and checks correctness using compilation \nand testing [28, 31]. For example, it generates patches that enforce invariants observed in correct executions \nbut are violated in erroneous executions [28]. It tests patched executions and selects the most successful \npatch. Weimer et al. [31] generate their candidate patches by replicating, mutating, or deleting code \nrandomly from the existing program and thus far have focused on single line edits. SYDIT automates sophisticated \nmulti-line edits that can add functionality or .x bugs. Integrating SYDIT into a testing framework to \nautomate validation is a promising future direction. 6. Discussions and Conclusions SYDIT is the .rst \ntool to perform non-contiguous, abstract edits to different contexts, signi.cantly improving the capabilities \nof the state-of-the-practice developer tools such as line-based GNU patch or the search and replace feature \nin text editors. This approach is however amenable to additional user guidance and automation. To learn \nand apply a systematic edit, users must provide a source and target method. It would be relatively straight-forward \nto extend SYDIT to help programmers select a subset of edits to be replicated. Users may also want to \ncon.gure SYDIT to update multiple locations within a target method, or to select a speci.c location to \nperform learned edits. SYDIT does not recognize naming patterns between related types and variables such \nas IServiceLocator and serviceLocator, as shown in Figure 6. Thus, developers may not easily understand \nthe output, even when SYDIT produces semantically equivalent code. By leveraging systematic naming patterns \nin program dif\u00adferences [17], it should be possible to produce edits that better mimic human developers. \nSYDIT relies on ChangeDistiller to detect syntactic differences between two versions. In some cases, \nChangeDistiller fails to re\u00adport a minimal concrete edit and thus SYDIT s derived edit script may include \nsuper.uous contextual nodes. For example, instead of selecting one contextual node relevant to an update, \nit may select multiple contextual nodes relevant to an insert and a corresponding delete. We leave to \nfuture work how the choice of program differ\u00adencing algorithm affects the .exibility of the learned edit \nscripts. This paper focuses on single method updates, but it may be pos\u00adsible to generalize the approach \nfor higher-level changes. For ex\u00adample, Kim et al. show that a large percentage of API-level refac\u00adtorings \nand class hierarchy changes consist of similar edits to dif\u00adferent class and method contexts [15, 17]. \nFor instance, the extract super class refactoring moves a set of related .elds and methods from subclasses \nto a super class. This type of functionality will re\u00adquire more sophisticated context representations \nand matching al\u00adgorithms. Another area for future work is automated target selection. For example, exhaustively \nexamining every method in the program may prove useful. When a programmer .xes a bug, SYDIT could generate \nan edit, then apply it to all applicable code regions, and test the SYDIT generated version. While prior \nwork suggests edit locations for recurring bug-.xes [25], SYDIT could actually apply the edit, automating \nsome program repair and modi.cation tasks. Furthermore, library component developers could use SYDIT \nto automate API usage updates in client applications by shipping an edit script together with changed \nlibrary components. In summary, SYDIT provides needed functionality that helps de\u00advelopers make simple \nand complex changes that span large pro\u00adgrams. By using context extraction, identi.er abstraction, and \nedit position abstraction, SYDIT learns and applies edits with high cov\u00aderage and accuracy. This approach \nfor program evolution opens a new way of providing higher con.dence to developers when they add features \nand .x bugs. A. Appendix We include example edits to show the limitations and power of the current implementation \nof SYDIT. Figure 7 shows one of the reasons that prevent SYDIT from mapping an abstract context with \na target method. Both source and target share all changes except deletion of line 14 and insertion of \nline 19. In mA, line 14 is a return statement, while in mB, line 14 is an expression statement. The two \nstatements have different AST node types. As a result, they cannot be matched by SYDIT. Figure10showsanexampleinwhich \nSYDIT establishesmatches successfully but produces incorrect edits. In this case, both mA and mB have \na method invocation replaced with the other method in\u00advocation. However, when calling the new method, \nmA and mB pass different input arguments: monitor object in the source vs. null in the target. The target \nmethod does not provide enough clues on why null must be passed as an argument. Figure 8 shows an example \nthat SYDIT produces edits that are not entirely identical to the programmer s actual edits, because the \ncontext and the edit content are slightly different between the source and the target. In both methods, \nthe programmer updates some statements, moves some statements out of the for loop, and inserts and deletes \nsome statements within the loop to make pro\u00adgrams more concise. However, the task involves different \nnumber of edits in the two methods. When SYDIT replicates learned edits to the target, three lines in \nmBsuggested diverge from mBnew (see Figure 9): (1) line 19 is incorrectly inserted with LIST ENTRY; (2) \nline 22 is not deleted since it does not have a counterpart in the abstract context and there is no edit \ndealing with it; (3) line 25 is incorrectly inserted since map.put(...) is not mapped correctly to list.add(...). \nDespite the three incorrect edits, SYDIT still makes the rest of the edits correctly in mB, alleviating \npart of this program\u00adming task. Aold to Anew 1. public boolean isMigrationCandidate (ILaunchConfiguration \ncandidate) throws CoreException { 2. -if(getAttribute(MIGRATION_DELEGATE) != null) { 3. -if(fDelegates \n== null) { 4. -fDelegates = new Hashtable(); 5. -} 6. -Object delegate = fDelegates.get(MIGRATION_DELEGATE); \n 7. -if(delegate == null) { 8. -delegate = getConfigurationElement() 9. .createExecutableExtension(MIGRATION_DELEGATE); \n 10. -fDelegates.put(MIGRATION_DELEGATE, delegate); 11. -} 12. -if(delegate instanceof 13. ILaunchConfigurationMigrationDelegate) \n{ 14. -return ((ILaunchConfigurationMigrationDelegate) 15. delegate).isCandidate(candidate); 16. -} \n 17. + initializeMigrationDelegate(); 18. + if(fMigrationDelegate != null) { 19. + return fMigrationDelegate.isCandidate(candidate); \n 20. }  21. return false; 22.} Bold to Bnew 1. public void migrate(ILaunchConfiguration candidate) throws \nCoreException { 2. -if(getAttribute(MIGRATION_DELEGATE) != null) { 3. -if(fDelegates == null) { 4. \n-fDelegates = new Hashtable(); 5. -} 6. -Object delegate = fDelegates.get(MIGRATION_DELEGATE); 7. \n-if(delegate == null) { 8. -delegate = getConfigurationElement() 9. .createExecutableExtension(MIGRATION_DELEGATE); \n 10. -fDelegates.put(MIGRATION_DELEGATE, delegate); 11. -} 12. -if(delegate instanceof 13. ILaunchConfigurationMigrationDelegate) \n{ 14. -((ILaunchConfigurationMigrationDelegate) 15. delegate).migrate(candidate); 16. -}  17. + initializeMigrationDelegate(); \n 18. + if(fMigrationDelegate != null) { 19. + fMigrationDelegate.migrate(candidate); 20. }  21. return \nfalse; 22.} Figure 7. A contigous, abstract edit script (CA) for which SYDIT cannot match the change \ncontext Acknowledgments This work was supported in part by the National Science Founda\u00adtion under grants \nCCF-1043810, SHF-0910818, and CCF-0811524. We thank anonymous reviewers for their thorough comments on \nour earlier version of the paper. References [1] J. Andersen. Semantic Patch Inference. Ph.D. Dissertation, \nUniversity of Copenhagen, Copenhagen, Nov. 2009. Adviser-Julia L. Lawall. [2] J. Andersen and J. L. Lawall. \nGeneric patch inference. In ASE 08: Proceedings of the 2008 23rd IEEE/ACM International Conference on \nAutomated Software Engineering, pages 337 346, Washington, DC, USA, 2008. IEEE Computer Society. ISBN \n978-1-4244-2187-9. [3] T. Apiwattanapong, A. Orso, and M. J. Harrold. A differencing al\u00adgorithm for object-oriented \nprograms. In ASE 04: Proceedings of the 19th IEEE International Conference on Automated Software En\u00adgineering, \npages 2 13, Washington, DC, USA, 2004. IEEE Computer Society. ISBN 0-7695-2131-2.  Aold to Anew Bold \nto Bsuggested 1. protected void setMapAttribute(Element element) throws CoreException { 2. -String listKey \n= element.getAttribute(\"key\"); 3. + String listKey = element.getAttribute(KEY); 4. NodeList nodeList \n= element.getChildNodes(); 5. int entryCount = nodeList.getLength(); 6. List list = new ArrayList(entryCount); \n 7. + Node node = null; 8. + Element selement = null; 9. for (int i = 0; i < entryCount; i++) { 10. \n-Node node = nodeList.item(i); 11. + node = nodeList.item(i); 12. -short type = node.getNodeType(); \n 13. -if (type == Node.ELEMENT_NODE) { 14. -Element subElement = (Element) node; 15. -String nodeName \n= subElement.getNodeName(); 16. -if (!nodeName.equalsIgnoreCase(\"listEntry\")) {  17. + if (node.getNodeType() \n== Node.ELEMENT.NODE) { 18. + selement = (Element) node; 19. + if (!selement.getNodeName(). equalsIgnoreCase(LIST \nENTRY)) {  20. throw getInvalidFormatDebugException(); 21. } 22. -String value = getValueAttribute(subElement); \n 23. -list.add(value); 24. + list.add(getValueAttribute(selement)); 25. } 26. } 27. setAttribute(listKey, \nlist); 28.}  Bold to Bnew 1. protected void setMapAttribute(Element element) throws CoreException { \n 2. -String mapKey = element.getAttribute(\"key\"); 3. + String mapKey = element.getAttribute(KEY); 4. \nNodeList nodeList = element.getChildNodes(); 5. int entryCount = nodeList.getLength(); 6. Map map = \nnew HashMap(entryCount); 7. + Node node = null; 8. + Element selement = null; 9. for (int i = 0; i \n< entryCount; i++) { 10. -Node node = nodeList.item(i); 11. + node = nodeList.item(i); 12. -short \ntype = node.getNodeType(); 13. -if (type == Node.ELEMENT_NODE) { 14. -Element subElement = (Element) \nnode; 15. -String nodeName = subElement.getNodeName(); 16. -if (!nodeName.equalsIgnoreCase(\"mapEntry\")) \n{  17. + if (node.getNodeType() == Node.ELEMENT.NODE) { 18. + selement = (Element) node; 19. + if \n(!selement.getNodeName(). equalsIgnoreCase(MAP ENTRY)) {  20. throw getInvalidFormatDebugException(); \n 21. } 22. -String key = getKeyAttribute(subElement); 23. -String value = getValueAttribute(subElement); \n 24. -map.put(key, value); 25. + map.put(getKeyAttribute(selement), getValueAttribute(selement)); 26. \n} 27. } 28. setAttribute(mapKey, map); 29.}  Figure 8. A non-contiguous, abstract edit script example \n[4] M. Boshernitsan, S. L. Graham, and M. A. Hearst. Aligning develop\u00adment tools with the way programmers \nthink about code changes. In CHI 07: Proceedings of the SIGCHI conference on Human factors in computing \nsystems, pages 567 576, New York, NY, USA, 2007. ACM. ISBN 978-1-59593-593-9. [5] J. R. Cordy. The txl \nsource transformation language. Science of Computer Programming, 61(3):190 210, 2006. ISSN 0167-6423. \n1. protected void setMapAttribute(Element element) throws CoreException { 2. -String mapKey = element.getAttribute(\"key\"); \n 3. + String mapKey = element.getAttribute(KEY); 4. NodeList nodeList = element.getChildNodes(); 5. \nint entryCount = nodeList.getLength(); 6. Map map = new HashMap(entryCount); 7. + Node node = null; \n 8. + Element selement = null; 9. for (int i = 0; i < entryCount; i++) { 10. -Node node = nodeList.item(i); \n 11. + node = nodeList.item(i); 12. -short type = node.getNodeType(); 13. -if (type == Node.ELEMENT_NODE) \n{ 14. -Element subElement = (Element) node; 15. -String nodeName = subElement.getNodeName(); 16. -if \n(!nodeName.equalsIgnoreCase(\"mapEntry\")) {  17. + if (node.getNodeType() == Node.ELEMENT.NODE) { 18. \n+ selement = (Element) node; 19. + if (!selement.getNodeName() .equalsIgnoreCase(LIST.ENTRY)) {  20. \nthrow getInvalidFormatDebugException(); 21. } 22. String key = getKeyAttribute(subElement); 23. -String \nvalue = getValueAttribute(subElement); 24. -map.put(key, value); 25. + map.add(getValueAttribute(selement)); \n 26. } 27. } 28. setAttribute(mapKey, map); 29.}  Figure 9. A non-contiguous, abstract edit script \nfor which SYDIT produces output different from the developer s version Aold to Anew public void flush(IProgressMonitor \nmonitor){ -saveContent(getInput()); + .ushContent(getInput(), monitor); } Bold to Bnew public void run() \n{ -saveContent(getInput()); + .ushContent(getInput(), null); } Figure 10. A single, abstract edit script \n(SA) for which SYDIT cannot produce correct edits [6] R. Cytron, J. Ferrante, B. Rosen, M. Wegman, and \nK. Zadeck. Ef.\u00adciently computing static single assignment form and the control de\u00adpendence graph. ACM \nTransactions on Programming Languages and Systems, 13(4):451 490, Oct. 1991. [7] E. Duala-Ekoko and M. \nP. Robillard. Tracking code clones in evolv\u00ading software. In ICSE 07: Proceedings of the 29th International \nCon\u00adference on Software Engineering, pages 158 167, Washington, DC, USA, 2007. IEEE Computer Society. \nISBN 0-7695-2828-7. [8] M. Erwig and D. Ren. A rule-based language for programming soft\u00adware updates. \nIn RULE 02: Proceedings of the 2002 ACM SIGPLAN workshop on Rule-based programming, pages 67 78, New \nYork, NY, USA, 2002. ACM. ISBN 1-58113-606-4. [9] B. Fluri, M. W\u00a8ursch, M. Pinzger, and H. C. Gall. Change \ndistilling tree differencing for .ne-grained source code change extraction. IEEE Transactions on Software \nEngineering, 33(11):18, November 2007. [10] W. G. Griswold. Program Restructuring as an Aid to Software \nMain\u00adtenance. PhD thesis, University of Washington, 1991. [11] W. G. Griswold, D. C. Atkinson, and C. \nMcCurdy. Fast, .exible syntactic pattern matching and processing. In WPC 96: Proceedings of the 4th International \nWorkshop on Program Comprehension, page 144, Washington, DC, USA, 1996. IEEE Computer Society. ISBN 0-8186-7283-8. \n[12] J. Henkel and A. Diwan. Catchup!: Capturing and replaying refactor\u00adings to support api evolution. \nIn ICSE 05: Proceedings of the 27th International Conference on Software Engineering, pages 274 283, \nNew York, NY, USA, 2005. ACM. ISBN 1-59593-963-2. [13] S. Horwitz. Identifying the semantic and textual \ndifferences between two versions of a program. In PLDI 90: Proceedings of the ACM SIGPLAN 1990 conference \non Programming language design and implementation, pages 234 245, New York, NY, USA, 1990. ACM. ISBN \n0-89791-364-7. [14] J. W. Hunt and T. G. Szymanski. A fast algorithm for computing longest common subsequences. \nCommunications of the ACM, 20(5): 350 353, 1977. ISSN 0001-0782. [15] M. Kim and D. Notkin. Discovering \nand representing systematic code changes. In ICSE 09: Proceedings of the 2009 IEEE 31st International \nConference on Software Engineering, pages 309 319, Washington, DC, USA, 2009. IEEE Computer Society. \nISBN 978-1\u00ad4244-3453-4. [16] M. Kim, V. Sazawal, D. Notkin, and G. Murphy. An empirical study of code \nclone genealogies. In ESEC/FSE-13: Proceedings of the 10th European Software Engineering Conference held \njointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pages 187 \n196, New York, NY, USA, 2005. ACM. ISBN 1-59593-014-0. [17] M. Kim, D. Notkin, and D. Grossman. Automatic \ninference of struc\u00adtural changes for matching across program versions. In ICSE 07: Proceedings of the \n29th International Conference on Software Engi\u00adneering, pages 333 343, Washington, DC, USA, 2007. IEEE \nCom\u00adputer Society. ISBN 0-7695-2828-7. [18] D. A. Ladd and J. C. Ramming. A*: A language for implementing \nlanguage processors. IEEE Transactions on Software Engineering, 21 (11):894 901, 1995. ISSN 0098-5589. \n[19] H. Lieberman, editor. Your Wish is My Command: Programming by Example. Morgan Kaufmann Publishers, \n2001. [20] A. Matzner, M. Minas, and A. Schulte. Ef.cient graph matching with application to cognitive \nautomation. In A. Schrr, M. Nagl, and A. Zndorf, editors, Applications of Graph Transformations with \nIndustrial Relevance, volume 5088 of Lecture Notes in Computer Science, pages 297 312. Springer Berlin \n/ Heidelberg, 2008. [21] T. Mens and T. Tourwe. A survey of software refactoring. IEEE Transactions on \nSoftware Engineering, 30(2):126 139, 2004. ISSN 0098-5589. [22] R. C. Miller and B. A. Myers. Interactive \nsimultaneous editing of multiple text regions. In Proceedings of the General Track: 2002 USENIX Annual \nTechnical Conference, pages 161 174, Berkeley, CA, USA, 2001. USENIX Association. ISBN 1-880446-09-X. \n [23] H. A. Nguyen, T. T. Nguyen, G. W. Jr., A. T. Nguyen, M. Kim, and T. Nguyen. A graph-based approach \nto api usage adaptation. In  OOPSLA 10: Proceedings of the 2010 ACM SIGPLAN International Conference \non Systems, Programming, Languages and Applications, page 10 pages, New York, NY, USA, 2010. ACM. [24] \nT. T. Nguyen, H. A. Nguyen, N. H. Pham, J. M. Al-Kofahi, and T. N. Nguyen. Clone-aware con.guration \nmanagement. In ASE 09: Proceedings of the 2009 IEEE/ACM International Conference on Automated Software \nEngineering, pages 123 134, Washington, DC, USA, 2009. IEEE Computer Society. ISBN 978-0-7695-3891-4. \ndoi: http://dx.doi.org/10.1109/ASE.2009.90.  [25] T. T. Nguyen, H. A. Nguyen, N. H. Pham, J. Al-Kofahi, \nand T. N. Nguyen. Recurring bug .xes in object-oriented programs. In ICSE 10: Proceedings of the 32nd \nACM/IEEE International Conference on Software Engineering, pages 315 324, New York, NY, USA, 2010. ACM. \nISBN 978-1-60558-719-6. [26] W. F. Opdyke and R. E. Johnson. Refactoring: An aid in designing application \nframeworks and evolving object-oriented systems. In Pro\u00adceedings of the Symposium on Object Oriented \nProgramming Empha\u00adsizing Practical Applications (SOOPPA), 1990. [27] Y. Padioleau, J. Lawall, R. R. Hansen, \nand G. Muller. Documenting and automating collateral evolutions in linux device drivers. In Eu\u00adrosys \n08: Proceedings of the 3rd ACM SIGOPS/EuroSys European Conference on Computer Systems 2008, pages 247 \n260, New York, NY, USA, 2008. ACM. ISBN 978-1-60558-013-5. [28] J. H. Perkins, S. Kim, S. Larsen, S. \nAmarasinghe, J. Bachrach, M. Carbin, C. Pacheco, F. Sherwood, S. Sidiroglou, G. Sullivan, W.-F. Wong, \nY. Zibin, M. D. Ernst, and M. Rinard. Automatically patching errors in deployed software. In SOSP 09: \nProceedings of the ACM SIGOPS 22nd symposium on Operating systems principles, pages 87 102, New York, \nNY, USA, 2009. ACM. ISBN 978-1-60558-752-3.  [29] M. Toomim, A. Begel, and S. L. Graham. Managing duplicated \ncode with linked editing. In VLHCC 04: Proceedings of the 2004 IEEE Symposium on Visual Languages -Human \nCentric Computing, pages 173 180, Washington, DC, USA, 2004. IEEE Computer Soci\u00adety. ISBN 0-7803-8696-5. \n[30] E. Visser. Program transformation with Stratego/XT: Rules, strate\u00adgies, tools, and systems in StrategoXT-0.9. \nDomain-Speci.c Program Generation, 3016:216 238, 2004. [31] W. Weimer, T. Nguyen, C. Le Goues, and S. \nForrest. Automatically .nding patches using genetic programming. In ICSE 09: Proceed\u00adings of the 31st \nInternational Conference on Software Engineering, pages 364 374, Washington, DC, USA, 2009. IEEE Computer \nSoci\u00adety. ISBN 978-1-4244-3453-4. [32] W. Yang. Identifying syntactic differences between two programs. \nSoftware Practice &#38; Experience, 21(7):739 755, 1991.  \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Software modifications are often <i>systematic</i> ---they consist of similar, but not identical, program changes to multiple contexts. Existing tools for systematic program transformation are limited because they require programmers to manually prescribe edits or only suggest a location to edit with a related example. This paper presents the design and implementation of a program transformation tool called SYDIT. Given an example edit, SYDIT generates a <i>context-aware, abstract edit script</i>, and then applies the edit script to new program locations. To correctly encode a relative position of the edits in a new location, the derived edit script includes unchanged statements on which the edits are control and data dependent. Furthermore, to make the edit script applicable to a new context using different identifier names, the derived edit script abstracts variable, method, and type names. The evaluation uses 56 systematic edit pairs from five large software projects as an oracle. SYDIT has high coverage and accuracy. For 82% of the edits (46/56), SYDIT matches the context and applies an edit, producing code that is 96% similar to the oracle. Overall, SYDIT mimics human programmers correctly on 70% (39/56) of the edits. Generation of edit scripts seeks to improve programmer productivity by relieving developers from tedious, error-prone, manual code updates. It also has the potential to guide automated program repair by creating program transformations applicable to similar contexts.</p>", "authors": [{"name": "Na Meng", "author_profile_id": "81323493934", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690573", "email_address": "mengna152173@gmail.com", "orcid_id": ""}, {"name": "Miryung Kim", "author_profile_id": "81335492829", "affiliation": "The University of Texas at Austin, Austin, USA", "person_id": "P2690574", "email_address": "miryung@ece.utexas.edu", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "The University of Texas at Austin, Austin, USA", "person_id": "P2690575", "email_address": "mckinley@cs.utexas.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993537", "year": "2011", "article_id": "1993537", "conference": "PLDI", "title": "Systematic editing: generating program transformations from an example", "url": "http://dl.acm.org/citation.cfm?id=1993537"}