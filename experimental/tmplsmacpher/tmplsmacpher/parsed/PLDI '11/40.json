{"article_publication_date": "06-04-2011", "fulltext": "\n AutomaticParallelization via Matrix Multiplication Shigeyuki Sato Hideya Iwasaki The Universityof Electro-Communications,Tokyo, \nJapan sato@ipl.cs.uec.ac.jp iwasaki@cs.uec.ac.jp Abstract Existing work that deals with parallelization \nof complicated reduc\u00adtions and scans focuses only on formalism and hardly dealt with implementation.To \nbridge thegap between formalism and imple\u00admentation, we have integrated parallelization via matrix multipli\u00adcation \ninto compiler construction. Our framework can deal with complicatedloopsthatexisting techniquesin compilers \ncannotpar\u00adallelize. Moreover, we have sophisticated our framework by devel\u00adoping two sets of techniques. \nOne enhances its capability for paral\u00adlelization by extracting max-operators automatically, and the other \nimproves the performance of parallelized programs by eliminating redundancy.We have also implemented \nour framework and tech\u00adniques as a parallelizer in a compiler. Experiments on examples that existing \ncompilers cannot parallelize have demonstrated the scalability of programs parallelized by our implementation. \nCategories and Subject Descriptors D.3.4[Programming Lan\u00adguage]: Processors Compilers, Optimization; \nD.1.2[Program\u00admingTechniques]: Automatic Programming General Terms Experimentation, Languages, Design, \nAlgorithms Keywords automatic parallelization, loop, reduction, scan, matrix multiplication, semiring, \nlinear recurrence equation 1. Introduction Since 2005, processor vendors have generally adopted multi-core \narchitectures instead of boosting the clock rate of processors. This means that sequential programs cannot \nbe made run faster with\u00adout parallelization. Thus, we cannot avoid parallel programming in striving for \nhigher performance. However, parallel programming is a challenge for most programmers. The easiest way \nfor program\u00admerstomakeprograms parallelisto use automatic parallelization. The most commonly used methodology \nfor automatic paral\u00adlelization of loops is doall parallelization [1, 2], whose core is to guarantee the \nindependence of each iteration, i.e., the parallelism among iterations,byanalyzing loop-carried data \ndependence. This framework suf.ces for simple data parallelism,but does not suf.ce for reduction, which \nis a generalization of summation. Standard doall parallelizers can recognize simple reductions, e.g., \none that just computes the sum of an array: x . 0; fori =1 to n do x . x + a[i] done. Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page.To copyotherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, \nSan Jose, California, USA. Copyright c &#38;#169; 2011ACM 978-1-4503-0663-8/11/06... $10.00 P n This \nloop is equivalent to x . 0+ i=1 a[i]. As is well known, the summation can be computed in parallel owing \nto the associativity of the addition; the parallel summation is computed in O(n/p + log p) time, where \np is the number of threads. Although this loop hasaloop-carried data dependence with respectto x (i.e., \nwriting x after reading x over an iteration), its doall parallelization succeeds because the de.nition \nand use of x are recognized as a reduction. The summation is a trivial reduction. There are, however, \nmore unobvious and non-trivial reductions.Forexample, the following loopevaluatesapolynomialexpression \nthrough the Horner scheme, Pni i.e., i=0 a[n - i]c = a[n]+ c(a[n - 1] + c(a[n - 2] + \u00b7\u00b7\u00b7 + c(a[1] + \nc(a[0] + c \u00b7 0)) \u00b7\u00b7\u00b7 )). x . 0; fori =0 to n do x . c \u00b7 x + a[i] done. Doall parallelizers cannot recognize \nthis loop as a reduction. As a result, this loop-carried data dependence with respect to x makes its \ndoall parallelization impossible. However, we can rewrite this loop into x . x0; fori =0 to n do x . \nAi \u00d7 x done, \u00ab \u00ab \u00ab x 0 ca[i] where x = , x0 = ,Ai = . 1 101 `Q\u00b4 n This loop is equivalent to x . i=0 \nAn-i \u00d7 x0. It is the same as the summation except for changing the addition into the matrix multiplication. \nSince the matrix multiplication is an associative operation, we can also compute the product of matrices \nin O(n/p+ log p) time. Thus, this loop can be parallelized. As shown above, if we can transform a loop \nbody into a matrix multiplication form, we can obtain an ef.cient parallel version of its loop. This \ntechnique is known as a parallel algorithm for solving linear recurrence equations [10]. There is work \nthat applies a generalization of this idea to automatic parallelization [6, 8, 13, 14, 21]. Although \nthe formalism developed in such work is promising for parallelizing complicated loops, no one connects \nthe formalism with the implementation aspect.We have resolved this problemby integrating the formalism \ninto doall parallelization. Ourworkto bridgethegap between formalismand practicalim\u00adplementation includes \na solution to an important problem concern\u00ading the max-operator, which plays a key role in parallelizing \ndy\u00adnamic programming.Inpriorworkon algebra-based parallelization [13, 21], this operator is assumed to \nbe given, even though in real\u00adistic programs the max-operation is usually described by means of if-statements.Wehavedevelopeda \ntechnique forextracting max\u00adoperators automatically from if-statements. Our work has resulted in the \nfollowing important contributions. We have developed a novel framework for loop parallelization (Sections \n3 and 4). The formalization of a loop body by us\u00ading matrix multiplication over a semiring enables paralleliza\u00adtion \nof various loops, especially one with a complicated body that contains loop-carried data dependence and \nif-statements. This parallelization is more powerful than the standard doall parallelization. Our framework \nis an integration of doall paral\u00adlelizationandtheexisting formalism[6,8,13,14,21].Tothe best of our knowledge, \nour work is the .rst to deal seriously with the implementation aspect of deriving associative opera\u00adtors \nfor automatic parallelization.  We have developed a technique for extracting max-operators automatically \nand semantically from if-statements by using an off-the-shelf Satis.ability Modulo Theories (SMT) solver \n(Sec\u00adtion 5). This technique plays an important role in our frame\u00adwork for parallelizing various loops \nwhose bodies contain if\u00adstatements. Automaticextractionof max-operatorshasnotbeen addressedin algebra-based \nparallelization [13, 21].To the best ofourknowledge,ourworkisthe.rsttodeal seriouslywiththe max-plus \nsemiring in the practical context of automatic paral\u00adlelization.  We have developed optimization techniques \nfor loops that are parallelized by our framework (Section 6). Because these tech\u00adniques reduce the intrinsic \noverhead caused by our paralleliza\u00adtion, theyare essential in practical situations. One of these tech\u00adniques \nis also helpful for doall parallelization (Section 6.4).  We have implemented our framework and techniques \nas a par\u00adallelizerina realistic compiler.Wehave then conductedexper\u00adiments onexamples whose doall parallelizationfails \nandhave con.rmed the scalability of these versions parallelized by our implementation (Section 7).  \n2. Preliminaries 2.1 Notations For program description in this paper, we use a mixture of mathe\u00admatical \noperators and syntax constructs of standard procedural lan\u00adguages likeFortran andC. The two sides of \nan assignment are connected by .. If each side is a vector, it is a vectorized assignment, which denotes \nsimul\u00adtaneous assignment of every entry on the right side to the corre\u00adsponding entry on the left side. \nNote that vector and matrix in this paper are virtual, i.e., not an actual data structure. They are simply \nsyntax constructs for expressing vectorized assignment and matrix multiplication. Operators \u00b7 and \u00d7 denote \nscalar and matrix multi\u00adplication, respectively.We omit \u00b7 when it is obvious.A sequence enclosed by brackets, \ne.g., [a1,...,an], is an extensible notation of an array, i.e., enumerated values are stored in the array \nin order. Statement are separatedbya semicolon. fori =1 to n do b done isafor-loopwitha controlvariableof \ni anda bodyof b. Unless otherwise noted, n denotes the number of iterations. if e then b1 else b2 endif \nis an if-statement. (e1)? e2 : e3 is a conditional expression using the syntax of C. parallel k . {1,...,p} \ndo b done is a parallel block in which b is executed by p threads in parallel, where k denotes thread \nID. Unless otherwise noted, p denotes the number of threads. Here, the shared memory model, i.e., EREW \nPRAM, and p . n are assumed.  2.2 Terminologies Techniques for identi.cation and parallelization of \nthedoall loop, which is a loop whose all iterations can be executed in parallel, have been well studied \n[1, 2]. In this paper, we use the term doall parallelization for these techniques. To identify a loop \nas a doall loop, a doall parallelizer analyzes the loop-carried data dependence. There is a loop-carried \n(true) data dependence with respect to a variable (or array element) x iff x is de.ned in an iteration \nand x is used in the succeeding iterations where its de.nition reaches. If there is no loop-carried data \ndependence in a loop, the loop is identi.ed as a doall loop. Consider fori =1 to n do x . ai done. Because \nthere is no loop-carried data (true) dependence, we can transform this loop intoits doallversion.However,inits \nparallelizedversion,the result of x is nondeterministic. In this case, at the end of the loop, x must \nbe an, which is called the .nal value of x, due to its sequential semantics.Aguarantee that the .nalvaluesofvariables \nde.nedin a parallelized loop coincide with those in its sequential version is called the .nal value guarantee. \nWe de.ne several terms here. De.nition1 (Accumulator). Ascalar variablex is an accumulator iffthere \nis loop-carried data dependence with respect to x. Unless otherwise noted, x is an accumulator. De.nition2 \n(Recurring expression and symbolically constant ex\u00adpression). An expression e in a loop is a recurring \nexpression iff e is computed from some loop-carried value. If e is not a recurring expression, we call \ne asymbolically constantexpression.C denotes the set of symbolically constant expressions in a given \nprogram. 2.3 Target Loops The target of the proposed parallelization is a non-nested loop the body of \nwhich contains neither jumps (e.g., goto, break, and con\u00adtinue), labels, pointers, indirect access to \narrays, nor function calls; i.e., a target loop body contains only assignments, if-statements, and side-effect-freeexpressions.Wecallasequenceof \nassignments and if-statements a block. For convenience, the start value of the control variable of each \ntargetloopis normalizedto1using inductionvariable transforma\u00adtion [1, 2]. There are two characteristic \nrestrictions on target loops: There is no loop-carried data dependence with respect to any array element. \n If an accumulator occurs in the condition-part of an if-statement, there is no assignment to the accumulator \nin either the then-part or else-part.  We can overcome the .rst restriction by using scalar replacement \n[5].Atechnique forovercoming the second restrictionis presented in Section5,buttheexplanationin Sections3and4supposes \nthis restriction. This paper does not deal with programs that cause run\u00adtime errors, and ignores arithmetic \nover.ow and round-off errors. 2.4 Parallel Primitives We introduce parallel primitives, which are generic \npatterns of parallel computation. The de.nitions of primitives used are: reduce(8, [x1,...,xn]) = xn \n8 \u00b7 \u00b7\u00b7 8 x1 scan(8, e, [x1,...,xn]) = [e, x1 8 e, . . . , xn-1 8 \u00b7 \u00b7\u00b7 8 x1 8 e], where 8 is an associative \noperator. Although the de.nitions of reduce and scan above are a bit different from these traditional \nde.nitions for convenience, it does not matter essentially. The reduce algorithm consists of two phases: \nlocal reduction and global reduction. In the local reduction, p threads reduce n elements into p elements \nindependently. In the global reduction, p threads reduce the result of the local reduction into the .nal \nresult cooperatively. For example, consider reduce(+, [a1,...,an]). In Pkn/p the local reduction, the \nk-th thread computes rk . ai. (k-1)n/p+1 PP In the global reduction, p threads compute n 1 ai through \np 1 ri. The time complexity of the local reduction is O(n/p) and that of the global reduction is O(log \np). O(p) space is used. The scan algorithm consists of three phases: local reduction, global scan, and \nlocal scan. The local reduction is the same as that of reduce. In the global scan, p threads produce \nnew p el\u00adements from the result of the local reduction cooperatively. In the local scan, p threads compute \nthe .nal result from the re\u00adsult of the global scan and the input sequence. For example, is not used \nafter this loop for convenience. The start position of the consider scan(+, e, [a1,...,an]). In the local \nreduction, the k-mts is important for application; e.g., if a[i] be the price of a stock th thread computes \nrk . Pkn/p ai. In the global scan, at time i, x2 is the time when the price of the stock began to rise. \n P (k-1)n/p+1 P1 p-1 p threads compute r . ri . In . e, e + 1 3.1 Matrix MultiplicationForm ri, ...,e \n+ 1 P(k-1)n/p h the local scan, the k-th thread computes Pkn/p-1 i e + ai, ..., Recall the example of \npolynomial evaluation shown in Section 1; 1 itsloophasaloop-carrieddata dependencewith respectto x,which \nfrom r .[k - 1] and the subarray of a. The time e + ai makes doall parallelization impossible. However,we \ncan transform complexity of the global scan is O(log p) and that of the local scan is O(n/p). O(p) space \nis used for intermediate data. its loop body into the following form: \u00ab \u00ab x . Ai \u00d7 x, where x = In \nthe shared memory model, we can simply describe each of the local reduction and local scan asaparallel \nloop with an iteration c a[i] 01 x ,Ai =. 1 spacethatis block-partitioned.Wecanmergeadoallloopfollowed \nby a scan or reduce into the local reduction of the reduce or the local scan of the scan if the number \nof iterations in the doall loop is the same as the length of an array that the scan or reduce computes. \nThe global reduction and global scan are described in detail elsewhere [18]. 3. Formalization based on \nMatrix Multiplication Before describing our framework for parallelization, we present examples that are \nused in this section. Example 1. Although the following loop containsasimple assign\u00adment other than a \nreduction, doall parallelizers can also handle it. x . 0; fori =1 to n do x . x + a[i]; a[i] . a[i]+1 \ndone. Doall parallelizers deal with the above loopby recognizing part of a trivial reduction in an ad \nhoc way. Thus, they cannot paral\u00adlelize non-trivial reductions that they cannot recognize as reduc\u00adtion. \nAn example of non-trivial reductions is the polynomial evalu\u00adation shown in Section 1. Another example \nis as follows. Example 2. The following loop computes the maximum tail\u00adsegment sum (mts) of a given array, \ni.e., the maximum sum of a contiguous segment that contains the last element of a given array; e.g., \nthe mts of [2, -1, -3, 5, 0, -4, 6] is 5+0+(-4)+6 = 7. Note that the second entry of the result of Ai \n\u00d7 x is always 1.We permitaconstanttobeintheleftsideofan assignmentifbothsides are always the same. From \nthe above transformation, the loop turns out to be equivalent to x . An \u00d7 \u00b7 \u00b7\u00b7 \u00d7 A0 \u00d7 x. Owing to the \nassociativity of \u00d7, we obtain the following assignment: x . reduce (\u00d7, [A0,...,An]) \u00d7 x. Since we can \ntransform this loop into a reduce, we can compute it in O(n/p + log p) time. Note that we can combine \nthe generation of Ai from array element a[i] with the local reduction of reduce. Thekeypoint of this \nparallelization is to transform the loop body into matrix-vector multiplication by introducing x and \nAi. Then, by unfolding all iterations, we can obtain a chain of matrix multi\u00adplications, i.e., a reduction. \nWe can generalize the above idea over a semiring1. We use (R, ., .) to denote a semiring, and 0 and 1 \nto denote identity elements regarding . and ., respectively. An operator \u00d7{E,@}denotes matrix multiplication \nover (R, ., .), i.e., . and . of \u00d7{E,@} correspond to + and \u00b7 of \u00d7, respectively. (R, +, \u00b7), (R . {-8}, \n., +), and ({0, 1}, ., .), where . is the max-operator de.ned as x . y =(x<y)? y : x, are useful instances \nof semirings. De.nition 3 (Matrix multiplication form). A block is in matrix multiplication form iffit \nis structured as follows: 10 1 010 x1 e11 \u00b7\u00b7\u00b7 e1m e10 x1 x . 0; fori =1 to n do if x + a[i] = 0 then \nx . x + a[i] else x . 0 endif done. BB@ . . . xm 1 CCA . BB@ CCA \u00d7{E,@} BB@ CCA , . .. . . . . ... . \n.. .. \u00b7\u00b7\u00b7 em1 e1m em0 xm 10 \u00b7\u00b7\u00b7 01 This is a non-trivial reduction because its loop body contains an \nwhere ejk .C. if-statement whose condition-part contains an accumulator. Theorem 1. If a loop body is \nin matrix multiplication form, the In addition, doall parallelization cannot support using the inter-loop \ncan be computed in O(n/p + log p) time through reduce. mediate results of reduction for other computations. \nAs an example, consider Example 2, which has a body of P Example 3. The following loop computes the \npre.x sum of an ar\u00ad P1 if x + a[i] = 0 then x . x + a[i] else x . 0 endif. n ray, i.e., a[i] . Although \nit resembles sum\u00ad a[i], \u00b7\u00b7\u00b7 , i=1 i=1 mation, its doall parallelizationfails due to a[i] . x. If this \nif-statement is equivalent to an assignment x . (x + a[i]) . 0, it can be transformed into the following \nmatrix multiplication x . 0; fori =1 to n do x . x + a[i]; a[i] . x done. form over (R. {-8}, ., +). \n\u00ab \u00ab a[i]0 . -8 0 Example 4. The followingloop resembles Example2;it computes x x . Ai \u00d7{*,+} x, where \nx = ,Ai = 0 the start position of the mts of an array. For example, the start position of the mts of \n[2, -1, -3, 5, 0, -4, 6] is 4. x1 . 0; x2 . 1; fori =1 to n do if x1 + a[i] = 0 then x1 . x1 + a[i] else \nx1 . 0; x2 . i +1 endif done, where x1 is the mts and x2 is its start position. Note that x2 . i+1 implicitly \nuses the intermediate result of x1 since it is in an if\u00adstatement whose condition-part uses x1. Here, \nwe assume that x1 Thus, this loop becomesaparallel reduction: x . reduce(\u00d7{*,+}, [A1,...,An]) \u00d7{*,+} \nx. The success of this parallelization owes much to the transformation of the original if-statement into \nan ex\u00adpressionbymeansofthe max-operator.Thus,inour parallelization, it is quite important to extract \nthe max-operator from the original loop body, which contains (possibly nested) if-statements. Section \n5shows our solution to the problem of max-operator extraction. 1A semiring is an algebraic structure \nsimilar to a ring, but without the requirement that each element must have an additive inverse. Of course, \nwe can also transform a simple reduction that doall parallelizers can recognize intoa matrix multiplication \nform.For instance,theloopbodyofthe summationloopin Section1is: \u00ab \u00ab x 1 a[i] x . Ai \u00d7{+,\u00b7} x, where x \n= ,Ai = . 1 01  3.2 NormalForm Although the matrix multiplication form covers non-trivial reduc\u00adtions, \nit is not satisfactory because it cannot express either doall computation, e.g., Example 1, or use of \nthe intermediate results of reduction for other computations, e.g., Examples3 and 4. There\u00adfore,weneedamoregeneralwayof \nparallelizationbasedonmatrix multiplication to enhance its applicability in practical situations. To \nunderstand this generalization, recall the loop of Example 1: fori =1 to n do x . x + a[i]; a[i] . a[i]+1 \ndone. Its loop body consists of a reduction part(x . x + a[i])and an increment part(a[i] . a[i]+1). We \ncannot transform this body into a matrix multiplication form. However, observing that the reduction and \nincrement parts are independent computations, we .nd that this example s loop can be divided into two \nloops: fori =1 to n do x . x + a[i] done; fori =1 to n do a[i] . a[i]+1 done. Both of these two loops \nare parallelizable; the .rst is a summation loopshownin Section1andthe secondisasimpledoallloop.In this \nway, we parallelize the loop of Example 1. Next, recall the loop of Example 3: fori =1 to n do x . x \n+ a[i]; a[i] . x done. Again, it is impossible to transform this loop body into a matrix multiplication \nform. However, by computing and storing all inter\u00admediate values of x into a temporary array in advance, \nwe can di\u00advide this loop into the following two loops: fori =1 to n do t[i] . x; x . x + a[i] done; fori \n=1 to n do a[i] . a[i]+ t[i] done. These two loops are parallelizable because the .rst is equivalent \nto t . scan(+, x, a); x . x + t[n] and the second is a doall loop. Here, we can eliminate t completely \nby fusing the local scan of scan(+, x, a) and the doall version of the second loop. We can use the above \ntechniques to generalize the matrix mul\u00adtiplication form to the following normal form. De.nition4 (Normal \nform). Ablock is in the normal form iffit is structured as follows: t . A \u00d7{E,@} x; b; x . t, where t \nis a vector of temporary variables, A \u00d7{E,@} x is the same as the right hand side of the matrix multiplication \nform, and b is a block of computations that contain no assignment to any accumulator.We call b the auxiliary \npart. Note that a matrix multiplication form can be transformed into a normal form the auxiliary part \nof which is empty. The normal form is used to easily distinguish the reduce or scan computation that \ncan be expressed by means of matrix multiplica\u00adtion from other computations. After obtaining a body in \nthe normal form, we can straightforwardly parallelize a loop that has the body by dividing it into two \nparallel computations: 1) reduce or scan with \u00d7{E,@} and2)adoall computation for the auxiliary part. \nNote that the latter can be ef.ciently embedded into the former. Theorem 2. If a loop body is in the \nnormal form, the loop can be computed in O(n/p+log p) time with O(p) space for intermediate data,by using \nthe reduce algorithm or the scan algorithm.  3.3 Separable NormalForm Sometimes, a single loop contains \ntwo (or more) reduction/scan computations. In such cases, although it is impossible to transform the \nloop body into a single normal form, we can extract a normal form from the body and thereby obtain a \nsequence of loops, each of which has a normal form. For example, recall the loop body of Example 4: if \nx1 + a[i] = 0 then x1 . x1 + a[i] else x1 . 0; x2 . i +1 endif . This loop body has two reduction computations \nfor x1 and x2. The .rst is x1 . (x1 + a[i] = 0) ? x1 + a[i]:0. The second is x2 . (x1 + a[i] = 0) ? x2 \n: i +1.We can transform the .rst into the following normal form: t . Ai \u00d7{*,+} x; x . t, \u00ab \u00ab \u00ab ta[i]0 \nwhere t = ,Ai = , x = x1 . 0 -8 00 `\u00b4 T Now, weexpand t to an array and de.ne ti = t[i]1 . Because t[i] \ncontains thevalueof x1 used in the second statement at the i-th iteration of the loop, we can transform \nthe original loop as follows: fori =1 to n do ti . Ai \u00d7{+,\u00b7} x; x . ti done; fori =1 to n do x2 . (t[i]+ \na[i] = 0) ? x2 : i +1 done. Next, we can transform this second loop s body: . . ... t . Ai \u00d7{+,\u00b7} x \n; x . t , \u00ab \u00ab tx2 where t . =0 . , x . =0 ,c =(t[i]+ a[i] = 0), \u00ab . c ?1:0 c ?0: i +1 A= . 01 We can \nparallelize both loops on the basis of Theorem 2. Thus, we have obtained a sequence of parallelizable \nloops: fori =1 to n do ti . Ai \u00d7{*,+} x; x . ti done; .. .. fori =1 to n do t . Ai \u00d7{+,\u00b7} x ; x . t . \ndone. In this case, the second loop encodes the .nal value guarantee for x2. We can implement the .nal \nvalue guarantee more ef.ciently (see Section 6.4). De.nition5 (Separable normal form). Let b1; b2 be \na sequence of two blocks. b1 is a separable normal form iff b1 is in the normal form and no accumulator \nupdated in b1 is updated in b2. In addition, if b2 is also a separable normal form, we call b1; b2 a \nsequence of separable normal forms. Corollary 1. If a loop body is a sequence of separable normal forms, \nthe loop can be computed in O(n/p + log p) time. 4. Parallelization Algorithm As shown in Section 3, \nonce we have obtained a normal form (or a sequence of separable normal forms) of a given loop body, we \ncan parallelize the loop straightforwardly in a divide-and-conquer manner: reduce or scan. Therefore, \nthe core of parallelization al\u00adgorithmsof our frameworkistoextracta normal form fromagiven loop body. \nIn this section, we describe algorithms for extracting it. 4.1 Extractinga NormalForm We describe an \nalgorithm for transforming a loop body into a normal form. It consists of two phases: separation and \nextraction. In the separation phase, a given block b is split into blocks b1 and b2 such that b1 contains \nonly the updating of accumulators found in b, and b2 corresponds to the residual computation. We call \nb1 the reduction part and b2 the residual part. For example, consider the following loop body: if a[i] \n< 0 then x . x + a[i] else x . 2x endif a[i] . x +1. We can split this loop body into a reduction part, \nif a[i] < 0 then x . x + a[i] else x . 2x endif, and a residual part, if a[i] < 0 then tx . x+a[i] else \ntx . 2x endif; a[i] . tx +1, where tx is a temporary variable. The residual part directly corre\u00adsponds \nto the auxiliary part in the normal form. In the extraction phase, a matrix multiplication form is ex\u00adtracted \nfrom the reduction part. First, all if-statements are converted into assignments with conditional expressions, \nby inserting self\u00adassignmentsof accumulators as needed.Forexample, if a[i] < 0 then x . x + a[i] else \nendif, can be converted into x . (a[i] < 0) ? x + a[i]: x. Next, the reduction part, which is a sequence \nof assignments, is converted into a single vectorized assignment by using symbolic substitution of de.nitions \nof accumulators to uses of accumulators as needed.Forexample, x1 . x1 + x2 + a[i]; x2 . a[i] \u00b7 x1 + x2, \ncan be converted into \u00ab \u00ab x1 x1 + x2 + a[i] . . x2 a[i] \u00b7 (x1 + x2 + a[i]) + x2 Finally, each entry \non the right side of the vectorized assignment is transformed into a matrix multiplication form, by expanding \nand simplifying each expression on the basis of the axioms of a semiring. For example, the vectorized \nassignment above can be transformed into 010 101 x1 11 a[i] x1 @x2A . @a[i] a[i]+1 a[i] \u00b7 a[i]A \u00d7{+,\u00b7} \n@x2A . 1 001 1 We intuitively and informally sketches how to extract a coef.cient matrix as follows \n(see [19] for the details of its formal algorithm). Algorithm1 (Extraction of coef.cient matrix). Let \nj, k .{1,..., `\u00b4 T `\u00b4 T m}. Let x1 \u00b7\u00b7\u00b7 xm . e1 \u00b7\u00b7\u00b7 em be a given vec\u00adtorized assignment. Here, we regard \nej as a function over a given semiring whose parameters are x1,...,xm. An expression e . de\u00adnotes an \nentry of an extracted coef.cient matrix; e.g., e . is the jk (j, k)-th entry.Acoef.cient matrixisextracted \nas follows: ejk . is obtained by differentiating ej with respect to xk. Then, the linearity of ej is \nalso checked.  e . is obtainedby substituting 0 to all accumulators in ej .  j(m+1) e . = 0, and e \n. = 1. (m+1)k (m+1)(m+1) After these two phases, the normal form is immediately ob\u00adtained.We summarize \ntheoverall algorithm as follows. Algorithm2 (Extraction of normal form). Let b be a loop body. Semirings \nare given. 1. Split b into b1 and b2, where b1 contains only updating of each accumulator and b2 correspondstoaresidual \ncomputation, Note that b1 is a sequence of assignments. 2. Convert b1 into a vectorized assignment. \n 3. Extract a coef.cient matrix from the right side of b1 by using Algorithm1;Tryit for all semirings \nuntilit succeeds. 4. Transform b1, which is in matrix multiplication form, into a normal form and insert \nb2 into its auxiliary part.  Due to space limitations, we omit the algorithm used to trans\u00adform a loop \nbody into a sequence of separable normal forms. The main difference from Algorithm 2 is to analyze the \ndependence among accumulators. See [19] for the details. 4.2 HeuristicforDivision When an accumulator \nin a loop body occurs in an expression of divisorsordividends,thebody cannotbe transformedintoanormal \nformbyusingonlythe axiomsofa semiring.However,the axioms of another algebra can be used to transform \nsuch a loop body into a normal form.Forexample, consider the following loop: fori =1 to n do x . (a[i] \n\u00b7 x + b[i])/(c[i] \u00b7 x + d[i]); y[i] . x done. Inthisbody,aM\u00a8obius transformationis recurrently appliedto \nx. Let fi be thisM\u00a8obius transformation.By meansof the projective matrix representation of fi, we obtain \n` \u00b4 T (fn .\u00b7 \u00b7\u00b7. f1)(z)=(d . fn . .\u00b7 \u00b7\u00b7. f1. ) z 1 , a[i] \u00b7 z + b[i] . where fi(z)= ,fi (z)= Hi \u00d7 z, \nc[i] \u00b7 z + d[i] \u00ab \u00ab\u00ab a[i] b[i] w1 w1 Hi = ,d = . c[i] d[i] w2 w2 By using this relation, we can transform \nthe above loop into the following loop with a body in normal form: x1 . x; x2 . 1; fori =1 to n do t \n. A \u00d7{+,\u00b7} x; y[i] . t1/t2; x . t done, 01 0 101 t1 a[i] b[i]0 x1 @ @ A@A where t = t2A,A = c[i] d[i]0 \n, x = x2 . 1 001 1 Wecan generalize this transformationoveradivision semiring2. (R, +, \u00b7) and (R . {-8}, \n., +) are useful instances of division semirings. Note that the division over (R, +, \u00b7) is /, that over \n(R. {-8}, ., +) is -. Theorem 3. Arecurrence equation that appliesaM\u00a8 obius trans\u00adformationoveradivision \nsemiringtoan accumulator canbetrans\u00adformed into a normal form. We use Theorem 3 as a heuristic for divisions \nin extracting normal forms.We omit the details of its transformation algorithm due to space limitations. \nSee [19] for the details. 5. Max-operator Extraction The max-operator . is notabuilt-in operator in most \nlanguages, but, as shown in the parallelization of Example 2, it is quite help\u00adful for parallelization. \nIn this section, we describe a technique for extracting max-operators from if-statements by exploiting \nan SMT solver, which is, informally, a SATsolver extended to handle num\u00adbers, arrays, conditional expressions, \netc. First, we convert a loop body into a conditional vectorized assignment (CVA), whose right side is \na conditional expression 2Adivision semiringis similartoasemiring,but with requirement that each element \nmust have a multiplicative inverse. returningavector.Forexample, consider the following loop body3: \nif x1 + a[i] > 0 then x1 . x1 + a[i] else x1 . 0 endif; if x1 >x2 then x2 . x1 else endif. By iterating \nsymbolic substitution, we convert this body into an equivalent CVA: x . (x1 + a[i] > 0)? (x1 + a[i] >x2)? \nx1 . : x2 . : (0 >x2)? x3 . : x4. , \u00ab \u00ab . x1 + a[i] . x1 + a[i] where x1 = , x2 = , x1 + a[i] x2 \u00ab \u00ab \n\u00ab . 0 . 0 x1 x = , x4 = , x = . 3 0 x2 x2 Next, we eliminate infeasible subexpressions from the right \nside of the CVA.We can use an SMT solver to detect them. In the above CVA, the right side has no infeasible \nsubexpression. Now observe ... . that x1, x2, x3, and x4 can be assigned to x. If it is possible to convert \nthe conditional expressions into max-expressions, we obtain a vectorized assignment: \u00ab \u00ab x1 (x1 + a[i]) \n. 0 . . (1) x2 (x1 + a[i]) . x2 . 0 This is only an assumption. Then, we con.rm this assumption by checking \nthat each assigned value is larger than or equal to other candidate values under the precondition for \nassigning the value. In the above example, for x1 . (x1 + a[i]) . 0, we check .x1,x2,a[i](x1 + a[i] > \n0 . x1 + a[i] >x2 . x1 + a[i] = 0), .x1,x2,a[i](x1 + a[i] > 0 . x1 + a[i] = x2 . x1 + a[i] = 0), .x1,x2,a[i](x1 \n+ a[i] = 0 . x1 + a[i] >x2 . 0 = x1 + a[i]), .x1,x2,a[i](x1 + a[i] = 0 . x1 + a[i] = x2 . 0 = x1 + a[i]). \nTo encode this problem into satis.ability problems, we convert. into . bynegating each formula. Then,by \nusing an SMT solver,we test the satis.ability of x1 + a[i] > 0 . x1 + a[i] >x2 . x1 + a[i] < 0, x1 + \na[i] > 0 . x1 + a[i] = x2 . x1 + a[i] < 0, x1 + a[i] = 0 . x1 + a[i] >x2 . 0 <x1 + a[i], x1 + a[i] = \n0 . x1 + a[i] = x2 . 0 = x1 + a[i]. If all these formulae are unsatis.able, we obtain x1 . (x1+a[i]) \n. 0.We similarly obtain x2 . (x1 + a[i]) . x2 . 0. Finally, we obtain (1), a set of linear recurrence \nequations over (R. {-8}, . , +), which we can parallelize on the basis of Theorem 2. The steps above \nare thekeytoextracting max-operators.If they are applied na\u00a8ively, however, max-operators may not be \nextracted from a CVAthat has a symbolically constant condition-part on the right side.Forexample, consider \nthe loop body if x + a[i] = 0 then x . (a[i] > 0) ? x + a[i]: x + a[i]+1 else x . 0 endif. One set of \ncandidate values assigned to x is {x + a[i],x + a[i]+ 1, 0}, and the assumption from this set is x . \n(x + a[i]) . (x + a[i] + 1) . 0. Because x + a[i] <x + a[i]+1, this assump\u00adtion is incorrect. However, \nanother set is {(a[i] > 0) ? x + a[i]: x + a[i]+1, 0}, and the assumption from this set is x . ((a[i] \n> 0) ? x + a[i]: x + a[i] + 1) . 0. This assumption is correct.A conditional expression whose condition-part \nis a symbolically con\u00adstant expression is unharmful for parallelization. Therefore, before extractionof \nmax-operators,wemakean unharmful conditionalex\u00ad 3Aloop that has this body is part of mss described in \nSection 7. pression coalesce intoavector.Forexample, we make the follow\u00ading conditional expression: \n\u00ab \u00ab e11 e21 c ?: , where c .C, e12 e22 coalesce into the following vector: \u00ab c ? e11 : e21 . c ? e21 \n: e22 We summarize these techniques as follows. Algorithm3 (Extraction of max-operators). ACVAwhose \nright side, e, has no infeasible subexpression is given. Iterate Steps 1 4 until e becomes a vector. \n1. Make all unharmful conditional expressions in e coalesce into vectors. 2. Extract the most deeply \nnested conditional subexpression whose all condition-parts are recurring expressions from e. 3. Test \nthe extracted one on the basis of its precondition (using an SMT solver) and obtain its equivalent max-expression. \n 4. Replacetheextracted conditionalexpressionin e with its equiv\u00adalent max-expression.  We can simply \nincorporate Algorithm3into Algorithm 2. Af\u00adter Step 1, we convert a reduction part(b1)into a singly nested \nif-statement, and then convert it into an equivalent CVA, by insert\u00ading self-assignments as needed. Next, \nwe eliminate its infeasible subexpressions (possiblyby using an SMT solver). Then, we apply Algorithm3to \nthisCVAand obtainavectorized assignment.The restof the process follows Steps3and4of Algorithm2. 6. Optimizationsfor \nOur Framework Unfortunately, our parallelization imposes intrinsic overhead on parallelized programs. \nConsidera sequentialloop whosebodyisin matrix multiplication form and its parallelizedversion. The original \nsequential version iterates matrix-vector multiplication, while the parallelized version iterates matrix-matrix \nmultiplication. Hence, overhead in proportion to the size of a coef.cient matrix is im\u00adposed on the parallelizedversion.To \nobtain good performancein practice, optimizations to minimize intrinsic overhead are impor\u00adtant. In this \nsection, we describe several optimizations for paral\u00adlelized programs. Due to space limitations, we do \nnot explain all optimizations. See [19] for the details. 6.1 Accurate Method of Abstract Matrix Multiplication \nMatsuzaki et al. [13] presented an optimization on the basis of abstract matrix multiplication4 for parallelized \nreductions on trees. It eliminates redundancy in matrix multiplication. Their original method is a conservative \none. We have developed an accurate method for loops parallelizedby our framework. We describe how to \noptimize a loop whose body is a matrix multiplication form with a coef.cient matrix A. First, we abstract \nthe values of the entries of A to four values Z, I, C, and V . Z and I denote 0 and 1, respectively. \nC denotes anyconstant value other than 0 and 1. V denotesany non-constantvalue, i.e.,thevalueof a variable. \nThen, we simulate runtime matrix multiplication over abstract matrices. Let AD0 be the abstract matrix \nof A. Updating of abstract matrices is de.ned as AD= AD0 \u00d7{E*,@*} AiD-1, where i = 1 and the semantics \nof .D and .D is de.ned in Figure 1. Here, an updating series of abstract matrices (i.e., AD0,...,ADi \n,...) reaches a stationary state (constant or periodic) since the size of each matrix is .xed and the \ndomain of each entry is .nite. i 4Note that [13] contains incorrectdescriptions concerning abstract \nmatrix multiplication, which were .xed in [11]. .D Z I C V .D Z I C V Z Z I C V Z Z Z Z Z I I V V V \nI Z I C V C C V V V C Z C V V V V V V V V Z V V V Figure1. Semanticsoftwooperatorsoverthefour abstractvalues. \nIntuitively, AD i indicates how many variables we require for ac\u00adcumulatingexponentiation of A andhowwe \nupdate thesevariables with compile-time constants.Forexample, the updating seriesof abstract matrices \nde.ned as follows converges at a constant state: \u00ab \u00ab IV VV AD AD 0 = , i =(i = 1). ZI ZI This indicates \nthat, once we have computed a square of A, we re\u00adquire always only two loop-carried scalar variables \nfor exponen\u00adtiating A. Concretely, An over (R, ., .) can be implemented as follows: . ... i . 0; A. A; \ni . 1; A. A \u00d7{E,@} A; fori =2 to n do A.. . A \u00d7{E,@} A.. done, \u00ab \u00ab . 1 v2 .. v1 v2 where A= ,A= . 01 \n01 For convergence at a .nite set of periodic states, we convert it into a constant state by loop unwinding. \nDue to space limitations, we omit the details. See [19] for the details. The primary effect of this technique \nis, of course, elimination of non-trivial redundancy; i.e., it realizes non-trivial copypropagation and \nconstant folding. In addition, this technique has an important secondary effect: elimination of storing \n0 into variables. 0 over (R . {-8}, ., +) is -8. This is a troublesome value because its annihilation \nproperty (i.e., -8 + a = a +(-8)= -8) is dif.cult to ef.ciently implement. This technique enables us \nto identify and eliminate 0 in compile-time. The main difference between our method and Matsuzaki et \nal. s [13] is the semantics of updating of abstract matrices. Their method is conservativewith respectto \nconvergence, i.e.,over-approximates the stationary state of an updating series of abstract matrices. \nAs a result, their method cannot deal with periodic states effectively and avoid storing 0 into variables, \nwhereas our method can do these successfully by using loop unwinding together.  6.2 Splitting up shift \nSometimes, reduce and scan computations include a kind of doall computation. Such computation appears \nin a coef.cient matrix as its row whose entries are 0 except for the rightmost entry. For example, consider \nthe following loop: fori =1 to n do x . A \u00d7{+,\u00b7} x done, 0 101 a[i]1 0 x1 @ @A where A =00 a[i]A , x \n= x2 . 001 1 The second row, i.e., x2 . a[i], represents doall computation.We can splitup the rowby introducinga \ntemporary array t as follows: fori =1 to n - 1 do t[i] . a[i] done; t[0] . x2; fori =1 to n do x . . \nA. \u00d7{+,\u00b7} x . done, \u00ab \u00ab a[i] t[i - 1] x1 where A. = , x . = . 01 1 The .rst loop is obviously a doall \nloop. The second loop, whose body is in the matrix multiplication form, is more ef.cient than the original \nloop because the size of A. is smaller than that of A. This ef.ciencymake an effect on matrix-matrix \nmultiplication of the parallelized version. Although this transformation causes O(n) space overhead due \nto the introduction of t, this space overhead is completely eliminated by fusion as mentioned later. \n This split up doall computation corresponds to shift [7], a pat\u00adtern of parallel computation, and this \ntransformation corresponds to the combination of scalar expansion and loop .ssion in doall parallelization. \n 6.3 Fusion Consider a scan followed by a reduce.We can compute both the local scan of the preceding \nscan and the local reduction of the succeeding reduce simultaneously. If the result of the preceding \nscan is used onlybythe succeeding reduce,we can eliminateO(n) space for the intermediate data that the \nscan produces and that the reduce consumes. Such kind of transformation is called fusion. The transformation \ndescribed above is the fusion of scan and reduce [12].Itis,of course, applicableto onesextractedbyour \nframework. Furthermore, the fusion of shift with scan or reduce [7] is also applicable.We omit the detailsof \nthese fusion methods. 6.4 Specializationof FinalValue Guarantee Sometimes, a loop body contains the \nfollowing assignment: x . c1 ? x : c2, where c1,c2 .C. We observe that this updating ofx does not use \nthe current value of x because self-assignment means no updating. Based on this observation, we can compute \nthe result of x in parallel by using a parallel loop and a reduce.For example, consider the following \nloop derived from parallelization process of Example 4: fori =1 to n do x2 . (t[i]+ a[i] = 0) ? x2 : \ni +1 done. Its parallelized version is: parallel k .{1,...,p} do v[k] . x2; b[k] . False; fori =1+(k \n- 1)n/p to kn/p do if t[i]+ a[i] = 0 then else v[k] . i + 1; b[k] . Trueendif done done; x . reduce(C, \n[v1,..., vp]), \u00ab \u00ab x2 v[i] where x = , vi = , vi C vj =(b[j]) ? vj : vi. b[0] b[i] In this program, \nv is an array whose k-th element is the partial result computed by the k-th thread and b is an array \nwhose k\u00adth element is the .ag to denote that the k-th thread update its partial result. Because this \nparallelized program does not use matrix multiplication, it is more ef.cient than one shown in Section \n3.3. From the viewpoint of doall parallelization, this computa\u00adtion corresponds to a .nal value guarantee \nfor a conditional as\u00adsignment. In doall parallelization, this kind of guarantee has not been dealt seriously \nwith. In fact, ICC 11.1 with -parallel -par-threshold0 options did not parallelize a loop that contains \nthis assignment because ICC cannot deal with it. Therefore, the presented technique here is also helpful \nfor doall parallelization. 7. Experiments We have implemented our framework and techniques as a paral\u00adlelizerina \ncompiler infrastructure, COINS5, which includes aC frontend,a doall analyzer, andaCcode generator. Our \nimplemen\u00adtation employs an SMT solver,Yices6. Figure2 shows the entire 5http://coins-compiler.sourceforge.jp/international/ \n6http://yices.csl.sri.com/  Figure 2. The entire structure of our implementation. HIR is the high-level \nintermediate representation of COINS. Our parallelizer communicates withYices through inter-process communication. \nstructure of our implementation. Our implementation produces par\u00ad allelizedCprograms that employOpenMP \nconstructs. To con.rm the scalability of programs parallelized by our im\u00ad plementation, we conductedexperiments \non the followingexample programs, eachof whose doall parallelizationfails. poly It computes polynomialevaluation \nthrough the Horner scheme. Its parallelized version executes reduce with \u00d7{+,\u00b7} of 2-by-2 matrices. The \norder of a given polynomial was 227 and it was evaluated with double arithmetic. mss It solves the maximum \nsegment sum problem, which is to computethe maximum sumofa contiguoussegmentofagiven array. It is known \nas a programming pearl. Its parallelized version executes reduce with \u00d7{*,+} of 3-by-3 matrices. The \nlength of a given array was 227 and its each element was int. mtsp It is equivalent to Example 4; it \ncomputes the mts of a given array and its start position. Its parallelized version executes scan with \n\u00d7{*,+} of 2-by-2 matrices and executes the .nal value guarantee for a conditional assignment. The length \nof a given array was 227 and its each element was int. ld It computes the Levenshtein distance between \ntwo given strings through dynamic programming. Our parallelization worked to divide the longer sides \nof the memo table whose element was int. Its parallelized version executes scan with \u00d7{*,+} of 2\u00adby-2 \nmatrices. The length of one given string of char was 227 and that of the other was 6. tls It is a solver \nfor tridiagonal linear systems. It consists of three parallelizable loops. The .rst executes LU decomposition, \ni.e., obtains LUx = b. It was parallelized by using Theorem 3. Its parallelized version executes scan \n\u00d7{+,\u00b7} of 3-by-3 matrices. The second solves Ly = b, and the third solves Ux = y. The parallelized versions \nof the second and third execute scan with \u00d7{+,\u00b7} of 2-by-2 matrices. The parallelized solver is equivalent \nto [20]. The dimension of a given system was 226 and it was solved with double arithmetic. fdm It solves \na one-dimensional heat equation through an in-place .nite difference method (FDM). The parallelization \nof stan\u00addard implementations of FDM to use a buffer where values in the next time-step are stored is \ntrivial, but that of in-place ones is non-trivial. Its parallelized version does not compute matrix multiplication \nbecause its coef.cient matrix can shrink completely through splitting up shift and its fusion. Its parallel \ncomputation is thus done only through the local reduction. The number of space cells was 227, that of \ntime steps was 10, and the values of temperature were double. Figure 3. Scalability of parallelized versions \nof six examples. poly mss mtsp ld tls fdm seq. (ms) 360 522 351 1807 487 2483 par. (ms) 578 265 633 2383 \n1083 3261 seq./par. (%) 62.2 197 55.4 75.8 45.1 76.1 Table 1. Execution time of original sequential \nversions and paral\u00adlelized single-threaded versions of six examples. p 12345678 r 1.73 1.80 2.41 2.22 \n2.56 2.63 3.02 3.44 Table 2. Ratio of speed of our parallelized mss to that of Fisher and Ghuloum [8] \ns mss; r and p denote ratio of speed (higher is better) and number of threads, respectively. We used \na server equipped with dual Xeon X5550 (4 cores; 3.06 GHz; HT disabled) and 12 GB of memory (DDR3-1333) \nrunning Ubuntu 10.04 (64-bit), and we compiled each program to its executable by employing ICC 11.1 with \nthe O3 optimization. As shown in Figure 3, the parallelized versions of poly, mtsp, mss, and ld achieved \nnear-linear scalability and nearly6 or more times speeds with8threads. These results re.ected the theoretical \nscalability (shown in Theorem 2). In contrast, the speed of par\u00adallelized fdm peaked out on 4 threads \nand the speedup of paral\u00adlelized tls degraded. Because these do relatively much memory ac\u00adcess, memory \nbandwidth bound their performance. As mentioned in Section 6, our parallelization causes intrinsic runtime \noverhead. Table1shows theexecution timeof the original sequentialversion and parallelized single-threadedversion \nfor each program. Eachex\u00adample had expected performance, except for mss. This is because the original \nsequential version of mss was abnormally slow for un\u00adknown reasons. However, this aberration is independent \nof the cor\u00adrectness and utility of our parallelization. Overall, without memory bandwidth issues, our \nparallelization achieved good scalability. Fisher and Ghuloum [8] s method parallelizes mss automati\u00adcally \ninto the compositionofa scan and reduction, unlike ours.We tested theversion parallelizedbyusing their \nmethod.Table2shows the ratio of the speed of our parallelized mss to that of their paral\u00adlelized mss. \nOur framework and techniques enabled the compiler to produce the more ef.cient parallel mss than theirs. \nThe SMT problem is not easier than the SATproblem, which is NP-complete. Therefore, to exploit an SMT \nsolver requires high costs potentially. Our implementation exploits Yices to extract max-operators. Our \nimplementation can dump each query forYices as a .le. We measured the execution time of Yices for queries. \n example mss mtsp ld number of queries 8 2 2 total time (ms) 11 4 4 Table 3. ExecutiontimeforYicestoextract \nmax-operators. Yices s version was 1.0.27. Table 3 shows the results. The exe\u00adcution time for each program \nwas short enough for practical use. Moreover, because we can test each query independently, we can obtain \nbetter performance by exploiting process-levelparallelism. Therefore, our approach based on an SMT solver \nis very practical. 8. Discussion 8.1 PriorWork and Our Improvement The most signi.cant prior work is \none by Fisher and Ghuloum [8]. Theypioneered in automatic parallelization of loops by extracting associative \noperators.We brie.y describe their formalization and technique, and compare ours with theirs. Theirkeyobservationisthat,owingtothe \nassociativityofthe function composition, applicationofacomposite function can com\u00adpute in parallel by \ncomputing the function composition per se. Theirkey ideais that,ifa functionis closed under composition, \nits composition canbe computedef.ciently.Forexample, fi(x)= aix+bi,fi is closed under composition: (f1 \n.f2)(x)=(a1a2)x+ (a1b2 + b1). The computation of . in f1 . f1 corresponds to that of a1a2 and a1b2 + \nb1. Concretely, they formalized a loop that computes reduction or scan as an application of a composite \nfunc\u00adtion consisting of its modeling function, which represents its loop body, and then parallelized \nthe loop into a version that computes the composition of the modeling function in parallel. Obviously, \ntheir formalization is more general and powerful than ours. The modeling function of the matrix multiplication \nform is the af.ne function over a semiring, which is closed under com\u00adposition. Hence, our formalizationisonlya \nspecial caseoftheirs. However, our framework is more practical because it is easier to implement in compilers \nand to derive ef.cient parallel programs. The test of closure under composition is potentially very dif.\u00adcult \nand costly because it necessitates searching in enormous space. This dif.culty derives fromafact that \nproofof disclosureby coun\u00adterexample is almost impossible because the closure property is too abstract. \nIn contrast, to derive matrix multiplication, we have only to check the linearity of recurrence equations. \nThe linearity is eas\u00adier to check, and moreover we can .nd a counterexample of the linearity immediately. \nOf course, they had noticed this dif.culty. They developed a heuristic to test the closure by checking \nstructural isomorphism of simpli.ed nested conditional expressions. However, this approxi\u00admation has \nseveral problems. First, the generality of this heuristic is such a little that it managed to enable \nus to extract a single max\u00adoperator. Second, to avoid a complicated conditional expression, they split \na loop body into as small ones as possible. Then, they parallelized computations for dependent accumulators \nas indepen\u00addently as possible. As a result, they transform a loop potentially parallelized as a single \nreduction into a composition of a reduc\u00adtion and scans. Infact, they parallelized mss asa compositionof \na scan and reduction, whose performance is worse than its single\u00adreductionversion (seeTable2). In contrast, \nwe extract max-operators before trying paralleliza\u00adtion. We can then easily parallelize recurrence equations \nover (R . {-8}, ., +). Matrix multiplication can deal with depen\u00addent (as well as independent) accumulators \nas a vector. Therefore, our framework can deriveasingle reduction from computations for dependent accumulators, \ne.g., mss. In addition, they did not per\u00adformexhaustive search for its complexity,but we easilydoitby \nexploiting an SMT solver.Focusing on max-operators signi.cantly simpli.es analysis for parallelization \nand affords optimizations. Overall, our framework focuses on techniques rather than for\u00admalism and on \npracticality rather than generality. In spite of the less generality, our framework can deal with all \ntheirexamples, and fur\u00adthermore, derive more ef.cient programs than theirs did. It demon\u00adstrates that \nthe power of our framework is empirically no less than that of theirs, and that our framework is more \npractical. 8.2 Parallelization of Recursive Functions Matsuzaki et al. [13] dealt with parallelization \nof a reduction of trees and presented a model of matrix multiplication over a semir\u00ading. Hence, our formalization \nper se is not so novel and is a vari\u00adation specialized for loops. Their framework does not deal with \naccumulationand assumesthe max-operatortobegiven. Although their semi-automated code generator is equipped \nwith an optimiza\u00adtion mechanism (see also Section 6.1), theydid not showanyexper\u00adimental result on the \nperformance of parallelized programs. There\u00adfore, we do not consider their work as fully automatic paralleliza\u00adtion \nin practical situations. Chin et al. [6] presented the context preservation theorem that formalizes the \nidea of [8] in a functional language, and an algo\u00adrithm for parallelizinga linear self-recursive function \nintoa list ho\u00admomorphism[4], whichisanaturally parallelizable recursiveform. Xuetal.[21] presenteda type-based \napproachto parallelization on the basis of the context preservation theorem. Their focus was on the analysis \nthat uses an algebra similar to a semiring even though their implementation can generate list homomorphisms. \nThey hardly dealt with higher-order linear recurrences, whereas we have dealt seriously with them. Since \nthey assumed the max\u00adoperatortobegiven,didnotdealwith optimization,and conducted no experiment on programs \nparallelized by their implementation, we therefore judge that their work is not one for fully automatic \nparallelization in practical situations. Morihata and Matsuzaki [14] presented that quanti.er elimina\u00adtion \nby virtual substitution (QEVS) enables us to directly extract associative operators based on the context \npreservation theorem from recursive functions, and demonstrated that their QEVS-based implementation \nwith simple heuristics can parallelize non-linear, non-self-recursive, and accumulative functions. Although \nQEVS is modular, however, QEVS is too costly to implement in compilers, and their technique has less \nscalability to the number of variables. Morita et al. [15] presented an algorithm to extract associative \noperators based on inversion of functions and the third homomor\u00adphism theorem. Theirworkisvery interesting,but \ntheir paralleliza\u00adtion is impractical because the third homomorphism theorem ne\u00adcessitates two equivalent \nfunctions for one target problem. 8.3 Linear Recurrence Equation and Scan Apart from work on automatic \nparallelization, Kogge and Stone [10] presented a parallel algorithm, which is now an algorithm of scan, \nfor solving a general class of linear recurrence equations by formalizing the class with matrix operations. \nStone [20] presented a parallel algorithm for solving a tridiagonal linear system on the basisof scan \nanda projective matrixofM\u00a8obius transformation. Cyclic reduction [9] is another parallel algorithm for \nsolving it. From this historical background, it is quite natural to parallelize computation of linear \nrecurrence equations through scan with ma\u00adtrix multiplication. Although generalizationover an algebra \n(e.g.,a semiring) is not explicitly mentioned in [10, 20], these algorithms are suf.ciently generic. \nTherefore, there is no dif.culty in dealing with computation of linear recurrence equations. From the \nperspec\u00adtive of automatic parallelization, the dif.culty is to discover this computation from a given \nloop automatically. Redon and Feaurier [17] presented methods to detect sequential scans in thepolytope \nmodel.With respect to parallelization, their methods fundamentally depend on the detection of trivial \nbuilt\u00adin associative operators by pattern matching. Although they men\u00adtioned derivation of matrix multiplication \nfrom a .rst-order linear recurrence equation andM\u00a8obius transformation, they considered each of these \nas a special case and did not generalize these at all. Theydid not deal with parallelization of a loop \nthat has a compli\u00adcated body such as one containing if-statements and one containing computations other \nthan linear recurrence equations. Nistor et al. [16] presented optimization techniques for ma\u00adtrix multiplication \nderived from parallelized linear recurrence equa\u00adtions. Their techniques reduce the space used in matrix \nmultiplica\u00adtion by recovering an expression of one entry from an expression of another entry on the basis \nof linear relations between these ex\u00adpressions. Because their techniques are independent of ours, we \ncan apply them to our framework.  8.4 StandardApproachin DoallParallelization Doall parallelization \n(and alsovectorization [3]) fundamentally ne\u00adcessitates eliminating every loop-carried data dependence \nin tar\u00adget loops by employing loop transformation. For example, loop skewing [2] eliminates loop-carried \ndata dependence and exposes wavefront parallelism in a nested loop such as ld. Whereas our framework \nincorporates reduction as a fundamental part, doall par\u00adallelization handles reduction as a special case \nof eliminating loop\u00adcarried data dependence. The book on the standard doall parallelization [2] tells \nreduc\u00adtions have three essential properties: 1) they reduce the elements of some vectorsor array dimension \ndown to one element ,2) only the.nalresultofthereductionisusedlater;useofan intermediate result voids \nthe reduction , and 3) there is no variation inside the intermediate accumulation; that is, the reduction \noperates on the vector and nothing else. Besides, reduction operators are almost always assumed asbuilt-in \nassociative commutative ones. Our framework relaxes these properties that are regarded as essential ones. \nBecause our framework can parallelize computation for mutually dependent accumulators, our framework \nrelaxes the .rst. The use of scan overcomes the second and third. Therefore, our framework is a natural \ngeneralization of doall parallelization. 9. Conclusion We have presented novel techniques to parallelize \nvarious loops. Our techniques extend doall parallelization. We think that there is room for future work \nregarding deal\u00ading with nested loops. The most popular framework for optimizing nested loops is the polyhedral \nmodel, which often accompanies par\u00adallelization.The tie-up between our techniques and the polyhedral \nmodel is an innovative work. In addition, we think that our tech\u00adnique to extract max-operators is helpful \nfor vectorization. There\u00adfore, the exploitation of .ne-grained data parallelism by using our techniques \nis another innovative work. Acknowledgments We would like to thank Masato Takeichi and Zhenjiang Hu for \nencouraging our research. We are grateful to Akimasa Morihata, Kento Emoto, and Kiminori Matsuzaki for \ntechnical discussions with the .rst author. References [1] A. V. Aho, M. S. Lam, R. Sethi, and J. D. \nUllman. Compilers: Principles,Techniques, andTools. AddisonWesley, second edition, 2006. [2] R. Allen \nand K.Kennedy. Optimizing Compilers for Modern Archi\u00adtectures:ADependence-Based Approach. Morgan Kaufmann, \n2001. [3] A. J. C. Bik, M. Girkar,P. M. Grey, and X.Tian. Automatic Intra-Register Vectorization for \nthe Intel RInt. J. Parallel \u00aeArchitecture. Program., 30(2):65 98, 2002. [4] R. S. Bird. An Introduction \nto the Theory of Lists. In Logic of Programming and Calculi of Discrete Design, volume 36 of NATO ASI \nSeriesF, pages 3 42. Springer-Verlag, 1987. [5] D. Callahan,S. Carr, andK.Kennedy. ImprovingRegister \nAllocation for SubscriptedVariables. In ProceedingsoftheACM SIGPLAN 1990 Conference on Programming Language \nDesign and Implementation (PLDI 90), pages 177 187.ACM, 1990. [6]W.-N. Chin,A.Takano,andZ.Hu.Parallelizationvia \nContext Preser\u00advation. InProceedings of IEEE International Conference on Computer Languages (ICCL 98), \npages 153 162. IEEE CS Press, 1998. [7] K. Emoto, K. Matsuzaki, Z. Hu, and M.Takeichi. Domain-Speci.c \nOptimization Strategy for Skeleton Programs. In Euro-Par 2007Par\u00adallel Processing, volume 4641 of Lecture \nNotes in Computer Science, pages 705 714. Springer, 2007. [8] A. L. Fisher and A. M. Ghuloum. Parallelizing \nComplex Scans and Reductions. In Proceedings of theACM SIGPLAN 1994 Conference on Programming Language \nDesign and Implementation (PLDI 94), pages 135 146.ACM, 1994. [9] W. Gander and G. H. Golub. Cyclic Reduction \n History and Ap\u00adplications. In Proceedings of theWorkshop on Scienti.c Computing, 1997. [10]P.M.Kogge \nandH.S. Stone. AParallel Algorithm for theEf.cient Solution of a General Class of Recurrence Equations. \nIEEETrans. Comput., 22(8):786 793, 1973. [11] K. Matsuzaki. Parallel Programming with Tree Skeletons. \nPhD thesis, Graduate School of Information Science andTechnology, The UniversityofTokyo, 2007. [12] K. \nMatsuzaki andK. Emoto. Implementing Fusion-EquippedParallel Skeletonsby ExpressionTemplates. In Implementation \nand Applica\u00adtion of Functional Languages (IFL 09),volume 6041 ofLectureNotes in Computer Science, pages \n72 89. Springer, 2010. [13]K. Matsuzaki,Z.Hu,andM.Takeichi.Towards AutomaticParalleliza\u00adtionofTree Reductionsin \nDynamic Programming. In Proceedings of the 18th AnnualACM Symposium onParallelism in Algorithms and Architectures \n(SPAA 06), pages 39 48.ACM, 2006. [14]A. MorihataandK. Matsuzaki. AutomaticParallelizationof Recursive \nFunctions using Quanti.er Elimination. In Functional and Logic Pro\u00adgramming (FLOPS 10), volume 6009 of \nLecture Notes in Computer Science, pages 321 336. Springer, 2010. [15] K. Morita, A. Morihata, K. Matsuzaki, \nZ. Hu, and M.Takeichi. Au\u00adtomatic Inversion Generates Divide-and-Conquer Parallel Programs. In Proceedings \nof the 2007ACM SIGPLAN Conference on Program\u00adming Language Design and Implementation (PLDI 07), pages \n146 155, 2007. [16] A. Nistor,W.-N. Chin,T.-S.Tan, andN.Tapus. Optimizing the paral\u00adlel computation of \nlinear recurrences using compact matrix represen\u00adtations. J.Parallel Distrib. Comput., 69(4):373 381, \n2009. [17] X. Redon andP. Feautrier. Detectionof Scansin the Polytope Model. Parallel Algorithms Appl., \n15(3 4):229 263, 2000. [18] J. H. Reif, editor. SynthesisofParallel Algorithms. Morgan Kaufmann Pub, \n1993. [19] S. Sato. AutomaticParallelization via Matrix Multiplication. Master s thesis, The University \nof Electro-Communications, 2011. [20] H. S. Stone. An Ef.cient Parallel Algorithm for the Solution of \na Tridiagonal Linear System of Equations. J.ACM, 20(1):27 38, 1973. [21] D. N. Xu, S.-C. Khoo, and Z. \nHu. PType System:A Featherweight Parallelizability Detector. In Programming Languages and Systems (APLAS \n04), volume 3302 of Lecture Notes in Computer Science, pages 197 212. Springer, 2004.    \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Existing work that deals with parallelization of complicated reductions and scans focuses only on formalism and hardly dealt with implementation. To bridge the gap between formalism and implementation, we have integrated parallelization via matrix multiplication into compiler construction. Our framework can deal with complicated loops that existing techniques in compilers cannot parallelize. Moreover, we have sophisticated our framework by developing two sets of techniques. One enhances its capability for parallelization by extracting max-operators automatically, and the other improves the performance of parallelized programs by eliminating redundancy. We have also implemented our framework and techniques as a parallelizer in a compiler. Experiments on examples that existing compilers cannot parallelize have demonstrated the scalability of programs parallelized by our implementation.</p>", "authors": [{"name": "Shigeyuki Sato", "author_profile_id": "81453606747", "affiliation": "The University of Electro-Communications, Tokyo, Japan", "person_id": "P2690625", "email_address": "sato@ipl.cs.uec.ac.jp", "orcid_id": ""}, {"name": "Hideya Iwasaki", "author_profile_id": "81100065591", "affiliation": "The University of Electro-Communications, Tokyo, Japan", "person_id": "P2690626", "email_address": "iwasaki@cs.uec.ac.jp", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993554", "year": "2011", "article_id": "1993554", "conference": "PLDI", "title": "Automatic parallelization via matrix multiplication", "url": "http://dl.acm.org/citation.cfm?id=1993554"}