{"article_publication_date": "06-04-2011", "fulltext": "\n A Security Policy Oracle: Detecting Security Holes Using Multiple API Implementations Varun Srivastava \nMichael D. Bond Kathryn S. McKinley Vitaly Shmatikov Yahoo! The Ohio State University The University \nof Texas at Austin varun iiit@yahoo.co.in mikebond@cse.ohio-state.edu {mckinley,shmat}@cs.utexas.edu \n Abstract Even experienced developers struggle to implement security poli\u00adcies correctly. For example, \ndespite 15 years of development, stan\u00addard Java libraries still suffer from missing and incorrectly applied \npermission checks, which enable untrusted applications to execute native calls or modify private class \nvariables without authorization. Previous techniques for static veri.cation of authorization enforce\u00adment \nrely on manually speci.ed policies or attempt to infer the pol\u00adicy by code-mining. Neither approach guarantees \nthat the policy used for veri.cation is correct. In this paper, we exploit the fact that many modern \nAPIs have multiple, independent implementations. Our .ow-and context\u00adsensitive analysis takes as input \nan API, multiple implementations thereof, and the de.nitions of security checks and security-sensitive \nevents. For each API entry point, the analysis computes the secu\u00adrity policies enforced by the checks \nbefore security-sensitive events such as native method calls and API returns, compares these poli\u00adcies \nacross implementations, and reports the differences. Unlike code-mining, this technique .nds missing \nchecks even if they are part of a rare pattern. Security-policy differencing has no intrinsic false positives: \nimplementations of the same API must enforce the same policy, or at least one of them is wrong! Our analysis \n.nds 20 new, con.rmed security vulnerabilities and 11 interoperability bugs in the Sun, Harmony, and \nClasspath implementations of the Java Class Library, many of which were missed by prior analyses. These \nproblems manifest in 499 entry points in these mature, well-studied libraries. Multiple API imple\u00admentations \nare proliferating due to cloud-based software services and standardization of library interfaces. Comparing \nsoftware im\u00adplementations for consistency is a new approach to discovering deep bugs in them. Categories \nand Subject Descriptors D. Software [D.2 Software Engineering]: D.2.4 Software/Program Veri.cation; K. \nComput\u00ading Milieux [K.6 Management of Computing and Information Sys\u00adtems]: K.6.5 Security and Protection \nGeneral Terms Languages, Security, Veri.cation Keywords Security, Authorization, Access Control, Static \nAnaly\u00adsis, Java Class Libraries Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, USA. Copyright c &#38;#169; \n2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 1. Introduction Demand for secure software is increasing, \nbut ensuring that soft\u00adware is secure remains a challenge. Developers are choosing memory-safe systems \n[9, 39] and languages such as Java and C# in part because they improve security by reducing memory\u00adcorruption \nattacks. Even memory-safe systems, however, rely on the access-rights model to ensure that the program \nhas the appro\u00adpriate permissions before performing sensitive actions. Unfortu\u00adnately, even experienced \ndevelopers .nd it dif.cult to specify and implement access-rights policies correctly. Consequently, semantic \nmistakes such as missing permission checks which enable mali\u00adcious code to bypass protection have become \na signi.cant cause of security vulnerabilities [26]. This paper presents a new approach to .nding security \nvulner\u00adabilities in software libraries, also known as Application Program\u00adming Interfaces (APIs). We \nleverage the increasing availability of multiple, independent implementations of the same API. By de\u00adsign, \nthese implementations must be interoperable and must im\u00adplement semantically consistent security policies. \nA security pol\u00adicy in the access-rights model consists of a mapping between secu\u00adrity checks, such as \nverifying permissions of the calling code, and security-sensitive events, such as writing to a .le or \nthe network. We exploit this consistency requirement to build a security policy oracle, which accurately \n(i) derives security policies realized by each implementation and (ii) .nds incorrect policies. Previous \nstatic analysis techniques for .nding security vulner\u00adabilities either rely on manual policy speci.cation \nand/or veri.ca\u00adtion, or infer frequently occurring policies by code-mining. For ex\u00adample, Koved et al. \nderive a policy and then require programmers to check by hand that permissions held at all sensitive \npoints in the program are suf.cient [22, 28]. Sistla et al. take as input manu\u00adally speci.ed check-event \npairs and verify that all occurrences of the event are dominated by the corresponding check [30]. These \napproaches are error-prone and limited in expressiveness. There are hundreds of potential security-sensitive \nevents and 31 poten\u00adtial checks in the Java Class Library; some policies involve multi\u00adple checks and \nsome checks do not always dominate the event. It is easy to overlook a security-sensitive event or omit \na rare check\u00adevent pair in a manual policy. Koved et al. and Sistla et al. reported no bugs for the Sun \nJava Development Kit (JDK) and Apache Har\u00admony implementations of the Java Class Library. By contrast, \nour analysis uncovered multiple, exploitable security vulnerabilities in the same code. Another approach \nis code-mining, which infers policies from frequently occurring patterns and .ags deviations as potential \nbugs [10, 14, 35]. These techniques fundamentally assume that the same pattern of security checks and \nsecurity-sensitive opera\u00adtions occurs in many places in the code, and they are thus likely to miss vulnerabilities \nthat violate a unique policy such as the Har\u00admony bug described in Section 2. Frequent patterns may or \nmay not represent actual policies, resulting in false positives and negatives. Code-mining techniques \nface an inherent tradeoff between cover\u00adage and the number of false positives. As the statistical threshold \nis lowered to include more patterns, they may .nd more bugs, but the number of false positives increases \nsince deviations from rare patterns can be mistakenly .agged as bugs.  Cross-implementation consistency \nas a security policy oracle. Our key idea is to use any inconsistency in security semantics be\u00adtween \nimplementations of the same API as an oracle for detecting incorrect policies. Unlike approaches that \nrely on explicit policies or frequent patterns, this technique completely avoids the need to determine \nwhether the policy is correct, replacing it by a much eas\u00adier task of determining whether two policies \nare consistent. Our use of consistency checking is very different from the code\u00admining approaches. In \nour case, there are no benign inconsisten\u00adcies! Any semantic inconsistency between two implementations \nof the same API is, at the very least, an interoperability bug or, in the worst case, a security hole. \nIn theory, policy differencing has no in\u00adtrinsic false positives. In practice, imprecision in conservative \nstatic analysis results in a very small number of false positives. Further\u00admore, our technique can discover \na missing permissions check even if this type of check occurs in a single place in the code. It may pro\u00adduce \nfalse negatives if exactly the same semantic bug occurs in all implementations of a given library routine. \nThis case is unlikely if the implementations are developed independently, as is the case for our main \ntest subject, the Java Class Library. Finding semantic inconsistencies with static analysis. Our analy\u00adsis \ntakes as input two or more Java API implementations, security\u00adsensitive events, and security checks. \nOur de.nitions of security\u00adsensitive events and checks directly re.ect the Java security model. Security-sensitive \nevents include calls to the Java Native Interface (JNI), which is the only mechanism by which Java code \ncommu\u00adnicates to the network, .le system, or other external devices. Since user code may change the internal \nstate of the Java Virtual Machine (JVM) using the Java Class Library, we include API returns in the set \nof security-sensitive events. Application code should not be able to reach security-sensitive events \nwithout proper permissions. In the Java security model, security checks verify permissions held by user \ncode by calling methods in the SecurityManager class. For every API entry point, we take all implementations \nand, for each one, produce context-sensitive policies using .ow-and context-sensitive interprocedural \nanalysis together with interproce\u00addural constant propagation. The policies specify which checks may and \nmust precede each security-sensitive event. We compare the policies for all events relevant to this entry \npoint and report any differences. Case study: The Java Class Library. We demonstrate the effec\u00adtiveness \nof our approach by applying it to the Java Class Library. This prominent, large, widely used API has \nmultiple, independent implementations: Sun JDK, GNU Classpath, Apache Harmony, and several others. For \nexample, JDK was announced in 1996 and is very broadly deployed. It is the product of hundreds of program\u00admers \nand its source code has been actively studied since Sun pub\u00adlished it in 2007. Different implementations \nof the Java Class Li\u00adbrary API are intended to be fully interoperable. Together, these implementations \ncomprise over 1.7 million lines of code. Any context-sensitive analysis must be concerned with ef.ciency. \nOurs uses context memoization [38]. Analyzing each library takes 20 minutes or less, which is likely \nto be acceptable as part of testing. The three pairings share approximately 4,100 entry points, and over \n230 of these methods perform security checks. Our analysis derives between 8,000 and 16,000 may and must \nsecurity policies per API. Our analysis is very precise. It produces only 3 false positives, while .nding \n20 new security vulnerabilities (6 in JDK, 6 in Har\u00admony, 8 in Classpath) and 11 interoperability bugs \nthat manifest in 499 API entry points. Example vulnerabilities include opening network connections and \nloading libraries without properly check\u00ading permissions of the calling code. We reported all vulnerabilities \nfound by our analysis to the developers of the respective libraries, who accepted and immediately .xed \nmany of them [31 33]. In summary, our analysis uncovered multiple security vulnera\u00adbilities in three \nmature implementations of the Java Class Library, with a minimal number of false positives. This paper \ndemonstrates that our approach (i) scales to industrial implementations of real\u00adworld software libraries \nand (ii) is capable of discovering deep bugs even in well-studied, tested, widely used code. Although \nwe describe our design and implementation with respect to the Java programming language, our approach \nis applicable to other lan\u00adguages, such as C#, that use a similar access-rights model. Current software \nengineering trends are likely to increase the applicability of comparative API analysis. For example, \nthe pro\u00adliferation of distributed, multi-layer software services encourages separation of APIs from their \nimplementations, and thus multiple implementations of the same API. Many platforms are adopting the Software-As-A-Service \n(SaaS) model [1, 16, 20, 29], which en\u00adcourages multiple implementations of the same functionality and \nthus provides the input material for our security policy oracle. Widely used APIs sometimes have an open-source \nversion, which programmers can use as a reference policy oracle even when their own code is proprietary. \nEven if all implementations of the same API are proprietary, developers may be willing to share security \npolicies with each other without sharing the actual code. 2. Motivating Example Figure 1 motivates our \napproach with an example from the JDK and Harmony implementations of the Java Class Library. In Figure \n1(a), the JDK implementation of DatagramSocket.connect calls ei\u00adther checkMulticast, or checkConnect \nand checkAccept be\u00adfore connecting to the network with a JNI call inside the method invocation at line \n16. For clarity of presentation, this and all other examples elide unrelated code and the test for a \nnon-null security manager required by all security checks. In Figure 1(b), the Har\u00admony implementation \ncalls either checkMulticast, or check-Connect before the equivalent method invocation at line 11. Figure \n2 illustrates some of the security policies inferred for this code. Each policy includes a security-sensitive \nevent and a (possibly empty) set of security checks. Consider the API\u00adreturn event for JDK. There is \na must and a may policy for this event. The must check is the empty set and the may checks are {{checkMulticast} \nor {checkConnect, checkAccept}}. The call to checkAccept before the API return and, more impor\u00adtantly, \nbefore using JNI to make a network connection as a result of invoking impl.connect, are missing in the \nHarmony may policy, introducing a vulnerability. The security-checking pattern in connect is unique. \nThe checkMulticast call is very rare and there is no other place in the JDK library where it occurs together \nwith checkAccept and checkConnect. The bugs as inconsistencies methods [14, 35] are not only likely to \nmiss this bug, but may even wrongly .ag the JDK implementation because the pattern incorrectly used by \nHar\u00admony is more common than the correct pattern used by JDK. The rarity of this pattern and the fact \nthat it involves multiple checks mean that a manual policy is likely to miss it, too. Both Harmony and \nJDK implement a may policy: there is no single check that dominates all paths to the security-sensitive \nevent. Even if the manual policy happens to include all the right event-check pairs, analyses that require \nthe same check(s) on every  1 // JDK 2 public void connect(InetAddress address , 3 int port) { 4 ... \nconnectInternal(address , port); ... 5 } 6 private synchronized void connectInternal(  InetAddress address \n, int port) {  7 ... 8 if (address.isMulticastAddress()) { 9 securityManager . checkMulticast ( address \n);  10 } else { 11 securityManager . checkConnect ( address . getHostAddress(), port); 12 securityManager \n. checkAccept ( address . getHostAddress(), port); 13 } 14 if (oldImpl) { 15 connectState = ST_CONNECTED_NO_IMPL; \n16 } else { 17 ... getImpl().connect(address , port); ... 18 } 19 connectedAddress = address; 20 connectedPort \n= port; 21 ... 22 } (a) JDK implementation of DatagramSocket.connect 1 // Harmony 2 public void connect(InetAddress \nanAddr , 3 int aPort ) { 4 synchronized (lock) { 5 ... 6 if (anAddr.isMulticastAddress()) { 7 securityManager \n. checkMulticast ( anAddr ); 8 } else { 9 securityManager . checkConnect ( anAddr . getHostName(), aPort); \n10 } 11 ... 12 impl.connect(anAddr , aPort);  13 ... 14 address = anAddr ; 15 port = aPort ;  16 ... \n17 } 18 } (b) Harmony implementation of DatagramSocket.connect Figure 1: Security vulnerability in Harmony: \ncheckAccept is missing. The correct security policy is unique to this method. MUST check: {} Event: API \nreturn from DatagramSocket.connect MAY check: {{checkMulticast},{checkConnect, checkAccept}} Event: \nAPI return from DatagramSocket.connect (b) JDK DatagramSocket.connect security policies MUST check: \n{} Event: API return from DatagramSocket.connect MAY check: {{checkMulticast},{checkConnect}} Event: \nAPI return from DatagramSocket.connect (b) Harmony DatagramSocket.connect security policies Figure 2: \nExample security policies path [7, 22, 28, 30] will produce a warning for both implementa\u00adtions, which \nis a false positive for the correct JDK implementation. Our analysis .nds this vulnerability using (1) \nprecise, .ow-and context-sensitive interprocedural analysis that computes both may and must policies, \nand (2) differencing of policies from multiple implementations. 3. Security Policies This section explains \nsecurity policies in the access-rights model in more detail. Section 4 explains how we compute the policies \nimplemented by a given API entry point and Section 5 describes our algorithm for comparing policies. \nA security policy in the access-rights model is a mapping from security-sensitive events to one or more \nsecurity checks for each event. Our analysis takes events and checks as input. A security\u00adsensitive event \nis a program event, such as a write to a .le, that the application should not be able to execute unless \nit holds cer\u00adtain rights or privileges. A security check veri.es that the appli\u00adcation holds a particular \nright. The access-rights model is the cor\u00adnerstone of Java security. For example, unchecked native method \ncalls can give user applications unauthorized network access, while unchecked returns of internal JVM \nstate, i.e., the value of a pri\u00advate variable, can leak data. The de.nitions of security checks and events \nthat we use in this paper directly re.ect Java s security model. A security policy maps an event to a \ncheck if the check occurs before the event. Our analysis computes both must and may policies. A must \npolicy means that the check in question must occur on every execution path leading to the event. A may \npolicy means that the check is predicated on some condition. At .rst glance, may policies may appear \ninsecure, but they are often needed to implement the correct security logic. For example, Figure 2(a) \nshows a policy that always performs one or more checks, but the particular check differs depending on \ncontrol .ow. Security checks. The SecurityManager class in Java provides 31 methods that perform security \nchecks for user code and libraries. For example, checkPermission() veri.es that the calling context holds \na particular permission and throws an exception otherwise. We restrict our analysis to these methods, \nalthough programmers can de.ne their own, additional security checks. Our analysis keeps track of which \nof the 31 security checks is invoked at any given point. For example, it differentiates between checkPermission() \nand checkConnect(). Our analysis does not ensure that the parameters to security checks are the same \nas the ones used by the security event. This imprecision could be a source of false negatives. Security-sensitive \nevents. The Java Native Interface (JNI) de.nes all interactions with the outside environment for Java \nprograms, e.g., opening .les, connecting to the network, and writing to the console. We therefore de.ne \nall calls to native methods as security\u00adsensitive events. In addition, we consider all API returns to \nbe security-sensitive events. If a method performs security checks but does not use the JNI, these checks \nare thus included in its security policy. Such checks are used in API implementations that give user \ncode ac\u00adcess to internal JVM state or private variables, or store parame\u00adter values for later use. These \naccesses should be secured consis\u00adtently in all implementations of an API because they reveal internal \nJVM or library state to untrusted applications and/or enable ap\u00adplications to modify this private state. \nBy including API returns, we broaden the de.nition of security-sensitive events as compared to prior \nwork [22, 28, 30]. This broader de.nition helps us .nd more vulnerabilities. For example, Figure 6 shows \nand Section 6.2  1 // Implementation 1 2 public Obj A(Obj obj) { 3 if (condition) { 4 checkRead (); \n5 obj . add ( data1 ); 6 return obj ; 7 } else { 8 return null ; 9 } 10 checkRead (); 11 obj . add( \ndata2 ); 12 // Private data1 and data2 returned in obj 13 return obj; 14 } 15 16 // Implementation 2 \n17 public Obj A(Obj obj, Data data1, Data data2) { 18 if (condition) { 19 obj . add ( data1 ); 20 return \nobj ; 21 } else { 22 return null ; 23 } 24 checkRead (); 25 obj . add( data2 ); 26 // Private data1 and \ndata2 returned in obj 27 return obj; 28 } Figure 3: Hypothetical bug showing the need for a broad de.nition \nof security-sensitive events. describes a vulnerability that we detect because our de.nition of security-sensitive \nevents is not limited to JNI calls only. Broader de.nition of security-sensitive events. Our analysis \ncan further broaden the de.nition of security-sensitive events. In addi\u00adtion to JNI calls and API returns, \nwe experimented with including individual accesses to private variables, JVM state, and API param\u00adeters. \nIn particular, security-sensitive events could include all reads, writes, and method invocations on API \nparameters and private vari\u00adables, as well as reads, writes, and method invocations on variables that \nare data-dependent on API parameters and private variables. For this de.nition of security-sensitive \nevents, we computed data dependencies using a simple interprocedural data.ow analy\u00adsis that propagated \nan event tag. It marked all statements in the de.nition-use chains involving private variables and API \nparame\u00adters, and propagated the mark interprocedurally through parameter binding in method invocations. \nIf there were multiple instances of the same event type, e.g., two returns or two accesses to the same \nparameter, we combined the corresponding policies. This de.ni\u00adtion of security-sensitive events is very \nliberal and marks many more events as sensitive. It generates over 90,000 security policies for each \nJava Library implementation, whereas restricting security\u00adsensitive events to JNI calls and API returns \nresults in 16,700 or fewer policies for each implementation. This broad de.nition of security-sensitive \nevents did not result in .nding more bugs, nor generating more false positives during our analysis of \nthe Java Class Library, but it helped us diagnose the cause of differences in the implementations respective \nsecurity policies. For other APIs, this broad de.nition may more accurately capture the semantics of \nlibrary implementations and thus .nd er\u00adrors missed with a narrower de.nition of security-sensitive events. \nFor example, this broad de.nition is needed to detect the in\u00ad consistency between implementations in \nthe hypothetical example shown in Figure 3. Restricting security-sensitive events to JNI calls and API \nreturns results in a {checkRead} may policy for the API\u00adreturn event in both implementations. If we instead \nconsider the reads of private variables data1 and data2 as distinct security\u00adsensitive events, the analysis \ninfers (1) a {checkRead} must policy for the read of data1 in the .rst implementation and (2) an empty \nmust policy for the same event in the second implementation. The analysis will thus report an inconsistency. \n4. Computing Security Policies Given an API and multiple implementations thereof, our approach extracts \nand compares security policies realized by the implemen\u00adtations. The analysis computes the security checks \nthat each API always performs (must analysis) or may perform (may analysis) before each security-sensitive \nevent. The analysis uses a .ow-and context-sensitive interprocedural algorithm enhanced with .ow\u00adand \ncontext-sensitive forward constant propagation [17, 36]. Any context-sensitive analysis must be concerned \nwith scalability. To reduce analysis time and guarantee convergence, we do not iterate over recursive \ncall paths. We further eliminate useless re-analysis with a form of memoization [38] that records security \npolicies and relevant parameters at each method invocation. We implement the analysis in the Soot static \nanalysis frame\u00adwork1 [25] and use Soot s method resolution analysis, alias analy\u00adsis, and intraprocedural \nconstant propagation. Call graph. The analysis starts by building call graphs rooted at all public and \nprotected API entry points, and derives separate policies for each API entry point. Protected methods \nare included because API clients can potentially call them by overriding the correspond\u00ading class. These \nmethods thus represent unintended paths into the API and are important to analyze. In theory, any static \nanalysis is incomplete in the presence of dynamic class loading since the code is not available until \nrun time. In practice, the Java Class Library and many other APIs are closed-world and do not depend \non dy\u00adnamic class loading. Soot computes application call graphs, but its analysis is en\u00adgineered for \napplications with a single entry point. Because APIs have many entry points, we build the call graph \non the .y, using Soot s method resolution analysis which resolves 97% of method calls in the Java libraries. \nIf Soot does not resolve a method in\u00advocation, our implementation does not analyze it. This inaccuracy \ncould be a source of false negatives or positives, but did not produce false positives in our evaluation. \nAs shown in prior work, type\u00adresolving events, such as allocation, make simple type hierarchy analysis \nvery effective at resolving method invocations [11, 34]. The Java libraries coding conventions for example, \nthe use of .\u00adnal methods further improve the precision of method resolution. Analysis overview. Computing \nsecurity policies is essentially a reaching de.nitions analysis where the de.nitions are security checks \nand the uses are security-sensitive events. The data.ow lattice is the power set of the 31 security-checking \nmethods. The analysis propagates checks (de.nitions) to events (uses). After con\u00adverging, the resulting \nsecurity policy is a mapping from event state\u00adments to the checks that reach them. We perform interprocedural \nand context-sensitive analysis, propagate constants across method calls, and eliminate the result\u00ading \ndead code, for the following reasons. It is typical for an API method to .rst call a method that performs \na security check and then call another method that contains a security-sensitive event. It is also common \nto perform the security check(s) conditionally, based on the value of a parameter (see Section 4.2 for \nan example). 1 http://www.sable.mcgill.ca/soot/  Algorithm 1 Intraprocedural Security Policy Data.ow \nAnalysis procedure SPDA {Initialize data.ow values} for all vEAllStatements do if MUST then OUT(v) .. \nelse {MAY} OUT(v) .T end if NOTVISITED . NOTVISITED . v end for {Propagate data.ow values} worklist \n. EntryPoint while worklist = f do v . getNode(worklist) if MUST then n IN(v) . OUT(p) p.PRED(v) else \n{MAY} IN(v) . OUT(p) p.PRED(v) end if OUT(v) . IN(v) . SP(v) if OUT(v) changed . v . NOTVISITED then \nworklist . worklist . SUCC(v) NOTVISITED . NOTVISITED - v end if end while Algorithm 2 Interprocedural \nSecurity Policy Analysis procedure ISPA(m, SP, paramConsts) if hashTable.hasKey((m, SP, paramConsts)) \nthen {Same analysis state, so return hashed result} return hashTable.lookup((m, SP, paramConsts)) else \n{Compute result for this analysis state} newSP . SPDA(m, SP, paramConsts) hashTable.put((m, SP, paramConsts), \nnewSP) return newSP end if 4.1 Intraprocedural analysis For ease of presentation, we .rst describe the \nintraprocedural com\u00adponent of the analysis. Algorithm 1 shows our intraprocedural se\u00adcurity policy data.ow \nanalysis (SPDA), which propagates secu\u00adrity checks. The MUST and MAY analyses differ in (i) the meet \nfunction, performing intersection for MUST and union for MAY, and (ii) the initial .ow values, which \nare . for MUST and T for MAY. SPDA assigns a unique identi.er to each of the 31 security\u00adchecking methods. \nIt initializes OUT(v) of each statement that per\u00adforms a check to the corresponding identi.er, i.e., \nOUT(v)= SP = {check}. For all other statements, it initializes SP = \u00d8. Because SPDA is a reaching de.nition \nanalysis and uses a lattice that is a powerset, it is rapid, converging in two passes with structured \ncontrol .ow [27].  4.2 Interprocedural, context-sensitive analysis This section explains how we extend \nthe intraprocedural data.ow analysis to make it interprocedural and context sensitive. ISPA, our interprocedural \nsecurity policy analysis, is shown in Algorithm 2. When ISPA encounters a statement v that contains a \nmethod in\u00advocation, it invokes the analysis recursively on the target method. As mentioned above, our \nimplementation ignores method invoca\u00adtions that Soot cannot resolve to a unique target, which may lead \nto false negatives and positives. ISPA performs interprocedural con\u00adstant propagation together with the \nsecurity analysis, tracking con\u00adstant parameter values (described below). The analysis binds any current \nconstant data.ow values to the parameters and uses them together with the current policy as the initial \nstate to analyze the target method. This analysis does not scale because it analyzes every statically \npossible calling context separately. In practice, however, many of the method s calling contexts have \nthe same data.ow values. We eliminate redundant work via the following memoization scheme. The .rst time \nour analysis encounters a call to some method, it analyzes the method, passing in the initial policy \nand any constant parameters. If analyzing the method changes the policy, we store the policy and the \nconstant parameters. Otherwise, we simply store the initial policy. When the analysis encounters the \nsame method in a different calling context but with the same policy .ow values, it reuses the stored \npolicy and avoids re-analyzing the method. We use ISPA to analyze each API entry point. The algorithm \ntakes as input a method m and the current analysis state, which consists of the current security policy \nSP and any known constant parameters paramConsts to m. The algorithm is mutually recursive with SPDA \n(Algorithm 1), which invokes ISPA at method invoca\u00adtions with the current values of SP and paramConsts. \nThus, the computation of OUT(v) in the while loop requires a change a re\u00adcursive call to gather SP(v), \nif v is a resolved method invocation. SPDA uses IN(v) as the initial .ow value of the method s entry \nbasic block and seeds constant propagation with the incoming con\u00adstant parameters (both not shown). Constant \npropagation. For better precision, our analysis propa\u00adgates constants intraprocedurally and interprocedurally. \nThe secu\u00adrity policy from Harmony in Figure 4 motivates this analysis. It shows a common pattern in which \na parameter determines whether a security check is performed. This code uses two URL constructors. The \n.rst constructor always passes null as the handler parameter to the second constructor, which correctly \nperforms no security checks. In other contexts, however, the second constructor performs one security \ncheck (line 7). Interprocedural constant propagation is required to accurately differentiate these two \ncontexts and prevent false positives. Soot supports Wegman-Zadeck intraprocedural constant propa\u00adgation \n[36]. Soot s algorithm propagates integer and boolean con\u00adstants and null reference assignments into \nconditional statements and eliminates unexecutable statements. We extend the analysis at method invocations \nto pass constant parameters to the target method. Because constant parameters are an essential part of \nthe analysis state, our memoization scheme includes them as data.ow values: both the policy SP and the \nconstant parameters paramCon\u00adsts must match in order to reuse previous results. Convergence. SPDA and \nISPA are guaranteed to converge be\u00adcause they are monotone and distributive. Constant propagation is \na monotone forward analysis. Intraprocedural constant propagation is guaranteed to converge on the structured \ncontrol-.ow graphs in Java, but because the call graph is recursive and not structured, context-sensitive \ninterprocedural constant propagation is not guar\u00adanteed to converge. For example, if a call passes in \na constant pa\u00adrameter that the callee increments until it reaches some limit, each context would be considered \nunique. In a context-sensitive analysis, constant propagation can produce an unbounded number of unique \nconstant parameters due to method recursion. We prevent this case by terminating early on recursive methods. \nIn our implementation, if the analysis encounters a recursive call, i.e., a call to a method that is \nalready on the call stack, it does not re-analyze the method. An alternative implementation could instead \nbound the number of traversals of a recursive subgraph.  1 // Harmony 2 public URL ( String spec ) { \n3 this (( URL ) null , spec , 4 (URLStreamHandler) null ); 5 } 6 public URL ( URL context , String spec \n7 URLStreamHandler handler) { 8 if (handler != null ) { 9 securityManager . checkPermission ( specifyStreamHandlerPermission \n); 10 strmHandler = handler; 11 } 12 ... protocol = newProtocol; ... 13 } Figure 4: A context-sensitive \nmay policy. Note that deriving the precise policy associated with the .rst entry point requires propa\u00adgating \nthe null constant into the handler parameter. Scalability. Making context-sensitive analysis ef.cient \nis dif.\u00adcult in general [18]. Our memoization is similar to Wilson and Lam [38], who record context-sensitive \nalias sets to avoid redun\u00addant analysis. As described above, we memoize context-sensitive security policies \nand any relevant constant parameters. Unlike context-sensitive, whole-program pointer analyses that must \nstore large sets, our analysis deals with a relatively small number of se\u00adcurity checks which must or \nmay precede security-sensitive events. Even though our analysis essentially explores every call path, \nit performs well in practice. Section 6 shows that reusing data.ow analysis values for identical incoming \n.ow values improves per\u00adformance signi.cantly. Other properties of our analysis, such as not analyzing \nrecursive calls and ignoring method invocations that Soot cannot resolve to a unique target, improve \nscalability as well. We .nd that calls to a method in the same or other contexts often have the same \nincoming .ow values. Nonetheless, context sensitiv\u00adity, which differentiates contexts that have different \n.ow values, is key to the precision of our approach. 5. Comparing Security Policies Given two implementations \nof the same API entry point, we com\u00adpute the policies realized by each implementation using the analysis \ndescribed in the previous section. Our analysis combines distinct occurrences of calls to the same JNI \nroutine and API returns. For example, if a method calls the same JNI routine three times with different \npolicies, we combine all three must and may policies. We perform intersection to combine must policies \nand union to com\u00adbine may policies. Although this step causes a loss of precision for must policies in \nparticular and thus may lead to false positives, we did not .nd it to be a problem in practice. This \nstep does not in\u00adtroduce false negatives when distinct instances of the same JNI call use different must \npolicies, but may introduce false negatives when combining may policies. A more precise analysis could \ntry to order and align each instance of a security-sensitive event, but we did not .nd this necessary. \nAfter combining security-sensitive events in each API, the anal\u00adysis then compares two policies as follows: \n1. If neither implementation has any security policies, or both im\u00adplementations have identical security \npolicies, the comparison analysis reports no error. 2. If one implementation has no security policy, \nbut the other im\u00adplementation has one or more security policies, the comparison analysis reports an error. \n 3. Otherwise, the comparison analysis matches events that occur in both implementations. We ignore \nevents unique to one im\u00adplementation. Matched events are compared as follows: (a) If the two implementations \nhave different sets of security checks for the same event, the comparison analysis reports an error. \n (b) If the two implementations have the same security checks, but at least one check is may in one implementation \nand must in the other, the comparison analysis reports an error.  Case 2 is responsible for most of \nthe security vulnerabilities and in\u00adteroperability bugs we found. Case 3(a) produced one vulnerability, \none interoperability bug, and one false positive. Case 3(b) produced one interoperability bug. 6. Evaluation \nWe evaluate our approach by applying it to recent versions of three mature implementations of the standard \nJava Class Library. The li\u00adbraries perform two critical functions in Java. First, they make Java portable \nby providing an abstract interface to I/O, user interfaces, .le systems, the network, operating system, \nand all other machine\u00addependent functionality. Second, they provide standard, optimized implementations \nof widely used data structures and abstractions, such as sets and queues. All Java programs rely on the \nsecurity and correctness of these libraries. We analyze three implementations of the Java Class Library, \nlisted below. For each implementation, we analyze the main pack\u00adages: java.io, java.lang, java.nio, java.security, \njava.text, java.util, javax.crypto, javax.net, javax.security, and java.net. 1. JDK: Sun JDK, version \n1.6.0 07, .rst released in 1996. 2. Classpath: GNU Classpath, version 0.97.2, started in 1998. 3. Harmony: \nApache Harmony libraries, version 1.5.0, svn revi\u00adsion r761593, started in 2005.  Note that two of the \nimplementations are well over 10 years old, yet our approach still found security errors in them. Together, \nthese libraries total about 2.5M lines of code. Table 1 summarizes the non-comment lines of code, API \nentry points, and characteristics of security policies for each library. We analyze all public and protected \nmethods because applications can invoke them either directly or via a derived class. Because of this, \nthe number of API entry points varies from implementation to implementation. We analyze the entire call \ngraph rooted at each of these API entry points. The third row in Table 1 shows that only a small subset \nof methods performs security checks. The analysis computes between 4,208 and 9,580 must and may security \npolicies for each implementation. We only compare policies for the API entry points that are identical \nin two implementations over 4,100 entry points for each pair shown in the .rst row of Table 3. The sheer \nvolume of policies demonstrates that any approach that relies on developers to manually examine inferred \npolicies to detect errors is unlikely to succeed. Analysis time. Table 2 shows the time in minutes to \ncompute must and may policies for each of the three libraries. For both may and must policies, the .rst \nrow shows the analysis time without memoization of method summaries (Section 4). The second and third \nrows show time with memoization. In the second row, method summaries are reused only within the same \nAPI entry point. In the third row, they are reused across the entire library. Reuse of summaries within \nthe same entry point yields a factor of 1.5 to 13 improvement and reuse across the entire library yields \nan additional factor of 3 to 18, resulting in the overall factor of 15 to  JDK Harmony Classpath JDK \nHarmony Classpath Non-comment lines of code 632K 572K 563K MAY No summaries 300 190 340 Entry points \n6,008 5,835 4,563 Summaries (per entry point) 180 130 190 Entry points w/ security checks 239 262 250 \nSummaries (global) 10 13 20 may security policies 9,580 7,126 4,652 MUST No summaries 560 290 650 must \nsecurity policies 7,181 6,757 4,208 Summaries (per entry point) 50 40 50 Summaries (global) 10 12 10 \n Table 1: Library characteristics Table 2: Analysis time in minutes Classpath v Harmony JDK v Harmony \nJDK v Classpath Matching APIs 4,161 4,449 4,758 False positives eliminated by ICP 4 (63) 4 (35) 4 (74) \nFalse positives 3 (3) 3 (3) 0 (0) Root cause of policy difference Intraprocedural 1 (1) 5 (6) 2 (3) Interprocedural \n14 (140) 13 (43) 16 (300) MUST/MAY difference 0 (0) 1 (5) 0 (0) Total differences 15 (142) 19 (54) 18 \n(303) Total interoperability bugs 3 (115) 9 (39) 5 (222) Classpath Harmony JDK Harmony JDK Classpath \nSecurity vulnerabilities in 5 (12) 4 (11) 1 (2) 6 (10) 5 (21) 8 (60) Total security vulnerabilities JDK \n6 (23) Harmony 6 (11) Classpath 8 (61) The table reports distinct errors with manifestations in parentheses: \ndistinct (manifestations). Table 3: Security vulnerabilities and interoperability errors detected by \nsecurity policy differencing analysis 65 improvement in performance due to memoization. Although our \nanalysis is still not blazingly fast, it is intended to be used relatively infrequently, as part of correctness \nand interoperability testing. 6.1 Analysis results We categorize the results of our analysis as follows: \nVulnerability: A semantic difference that can be exploited to per\u00adform some security-sensitive action \nwithout permission. Interoperability bug: A semantic difference that causes interop\u00aderability problems. \nThese differences do not, on the surface, en\u00adable applications to perform security-sensitive actions \nwithout permission, but could be part of a multi-stage attack. False positive: Policies are identical, \nbut a difference is mistakenly reported due to imprecision of our analysis. False negative: A security \nvulnerability not reported by our anal\u00adysis. False negatives may arise if identical may policies apply \nunder different conditions, or if two policies are identical but incorrect. Although these cases seem \nunlikely, their frequency is hard to quantify. The remainder of this section surveys the results of security-policy \ndifferencing and how different algorithmic features of our analysis contribute to the results. Sections \n6.2 and 6.3 discuss the security vulnerabilities and interoperability errors in detail and include ex\u00adamples \nof each. Section 6.4 explains in more detail why our analy\u00adsis can have false positives and false negatives. \nTable 3 shows the results of our analysis. We compare each implementation to the other two. The analysis \n.nds most errors in both comparisons, but because some entry points differ between implementations, each \npairwise comparison .nds a few unique errors. To reduce the number of reports the developer must read, \nour analysis automatically combines reports when the error stems from the same root cause, i.e., when \nthe method containing the error is called from multiple API entry points. The number of entry points \n(manifestations) that can exploit the error is shown in parentheses. We manually examined all root causes \nto determine the responsible library implementation and classify the bug. The ICP row shows that interprocedural \nconstant propagation eliminates 4 false positives that have over 70 manifestations, re\u00adsulting in the \noverall false-positive rate of less than 1%: 3 of 499 manifestations. The Intraprocedural, Interprocedural, \nand MUST/-MAY rows show that every component of our analysis contributes to .nding errors. Intraprocedural \nanalysis, which only computes policies local to a method, would miss the majority of the errors. Differences \ndue to a must policy in one implementation and a may policy in the other revealed one bug. Not shown \nin a dedicated row in the table is the small number of vulnerabilities revealed by dif\u00adferences between \ntwo may policies, including the one in Figure 1. Finding most errors requires context-sensitive interprocedural \nanal\u00adysis. Overall, our analysis found 20 security vulnerabilities and 11 interoperability bugs across \nall three library implementations, not just in the least mature one. These errors witness how dif.cult \nit is for programmers to get access-rights policies correct. For example, even though more than a hundred \ndevelopers worked on the JDK implementation for over 15 years, it is still not error-free. We reported \nall vulnerabilities to the respective implementors, who recognized all of them as bugs and .xed some \nof them [31 33].  6.2 Security vulnerabilities This section explains a few of the security vulnerabilities \nuncov\u00adered by our analysis. To demonstrate the power of implementation  1 // JDK 2 class Runtime { 3 \npublic void loadLibrary(String libname) { 4 loadLibrary0 ( System . getCallerClass () , 5 libname ); \n6 return ; 7 } 8 synchronized void loadLibrary0( 9 Class fromClass , String libname) { 10 ... securityManager.checkLink(libname); \n... 11 ClassLoader.loadLibrary(fromClass , libname , 12 false ); 13 } 14 } 15 16 class ClassLoader { \n17 static void loadLibrary(Class fromClass ,  String name, boolean isAbsolute) {  18 ... loadLibrary0(fromClass \n, libfile); ... 19 } 20 private static boolean loadLibrary0( 21 Class fromClass , final File file ) { \n 22 ... 23 NativeLibrary lib = 24 new NativeLibrary(fromClass , name); 25 lib . load ( name );  26 \n... 27 } 28 } (a) JDK implementation of Runtime.loadLibrary 1 // Classpath 2 class Runtime { 3 public \nvoid loadLibrary(String libname) { 4 loadLibrary(libname , VMStackWalker. getCallingClassLoader ()); \n 5 return ; 6 } 7 void loadLibrary(String libname , ClassLoader loader ) { 8 ... securityManager.checkLink(libname); \n... 9 ... loadLib(filename , loader); ... 10 } 11 private static int loadLib(String filename , ClassLoader \nloader) {  12 ... 13 securityManager . checkRead ( filename );  14 ... 15 return VMRuntime.nativeLoad(filename \n,  loader ); 16 } 17 } (b) Classpath implementation of Runtime.loadLibrary Figure 5: Security vulnerability: \nJDK is missing checkRead that Classpath performs before loading a library at run time. differencing, \neach vulnerability is accompanied by a correct imple\u00admentation from another library. Figure 5 shows one \nof the six vulnerabilities in JDK. The JDK code returns from Runtime.loadLibrary having called only checkLink \non a dynamically loaded library. By contrast, the Classpath implementation calls both checkLink and checkRead. \nDetecting this vulnerability requires interprocedural analysis. The other .ve JDK vulnerabilities are \ndetected when our anal\u00adysis compares JDK with Classpath. They arise because JDK per\u00adforms some security \nchecks inside a privileged block. Security checks inside a privileged block always succeed. Therefore, \nthey 1 // Harmony 2 public URLConnection openConnection( 3 Proxy proxy) throws IOException { 4 ... \n5 return 6 strmHandler.openConnection( this , proxy); 7 } (a) Harmony implementation of URLConnection.openConnection \n1 // JDK 2 public URLConnection openConnection( 3 Proxy proxy ) { 4 ... 5 if ( proxy . type () != Proxy \n. Type . DIRECT ) { 6 InetSocketAddress epoint = 7 (InetSocketAddress) proxy.address(); 8 if (epoint.isUnresolved()) \n{ 9 securityManager . checkConnect ( epoint . getHostName(), epoint.getPort()); 10 } else { 11 securityManager \n. checkConnect ( 12 epoint . getAddress (). getHostAddress () , 13 epoint . getPort ()); 14 } 15 } 16 \nreturn handler.openConnection( this , proxy); 17 } (b) JDK implementation of URLConnection.openConnection \nFigure 6: Security vulnerability: Harmony is missing check-Connect that JDK performs before opening a \nnetwork connection. are semantic no-ops and our analysis correctly ignores them. It seems especially \ndif.cult for developers to detect this kind of error through manual inspection because a call to the \nsecurity-checking method is actually present in the source code. Figure 6 shows one of the six vulnerabilities \nin Harmony, de\u00adtected when our analysis compared it to JDK. Finding the vulnera\u00adbility in OpenConnection \nrequires using API returns as security\u00adsensitive events because OpenConnection does not actually per\u00adform \nnetwork reads and writes with JNI calls. The user must subse\u00adquently call getInputStream() or getOutputStream() \nto read or write to the network. In Harmony, OpenConnection calls a method on the private strmHandler \nvariable and returns internal API state to the application without any checks. By contrast, the JDK implementation \nhas a may policy that calls checkConnect before returning internal API state to the application. Figure \n7 shows one of the eight vulnerabilities in Class\u00adpath. Classpath omits all security checks in the Socket.connect \nmethod, whereas JDK always calls checkConnect. This error seems simple to spot, but the method is called \nin many contexts, some of which do perform checks. Since this method is directly accessible by an application, \nthis vulnerability is easy to exploit and has now been .xed.  6.3 Interoperability bugs Some interoperability \nproblems arise because Classpath performs much more dynamic class loading than the other implementations. \nFor example, it dynamically loads the CharsetProvider class, whereas JDK statically loads it at boot \ntime. The reason may be that Classpath is trying to reduce the size of its JVM when running on an embedded \nplatform. Because of this difference, Classpath contains code that performs checkPermission(new RuntimePermission(\"charsetProvider\")), \nwhereas JDK and Harmony do not.  1 // JDK 2 class Socket { 3 public void connect(SocketAddress , int \n) { 4 ... 5 securityManager.checkConnect (...);  6 ... 7 impl.connect (...); 8 } 9 }  (a) JDK implementation \nof Socket.connect 1 // Classpath 2 class Socket { 3 public void connect(SocketAddress , int ) { 4 ... \n5 getImpl().connect(endpoint , timeout); 6 } 7 } (b) Classpath implementation of Socket.connect Figure \n7: Security vulnerability: Classpath is missing check-Connect that JDK performs before opening a network \nconnection. 1 // JDK 2 class String { 3 public byte [] getBytes() { 4 return 5 StringCoding.encode(value, \noffset, count); 6 } 7 } 8 9 class StringCoding { 10 static byte [] encode(...) { 11 try { 12 return \nencode(\"ISO -8859-1\", ca, off, len); 13 } catch (UnsupportedEncodingException x) { 14 System . exit (1) \n; 15 return null ; 16 } 17 } 18 } (a) JDK implementation of String.getBytes 1 // Harmony 2 class String \n{ 3 public byte [] getBytes() { 4 ByteBuffer buffer = 5 defaultCharset().encode (...); 6 ... 7 } 8 private \nCharset defaultCharset () { 9 if (DefaultCharset == null ) { 10 DefaultCharset = 11 Charset.forName(\"ISO \n-8859-1\"); 12 } 13 ... 14 } 15 } (b) Harmony implementation of String.getBytes Figure 8: Interoperability \nbug: JDK requires checkExit permis\u00adsion to call System.exit(), whereas Harmony throws an excep\u00adtion. \nInteroperability problems also arise due to additional function\u00adality in one of the implementations. \nFigure 8 shows an exam\u00adple from String.getBytes. If the default ISO-8859-1 char\u00adacter set decoder is \nnot present, JDK terminates the application by calling System.exit(), whereas forName in Harmony throws \nUnsupportedEncodingException. To perform System.exit(), the application needs checkExit permission which \nis not needed in the Harmony implementation.  6.4 False positives and negatives The main reason for \nfalse positives is inherent to any static anal\u00adysis it is conservative because it includes all possible \nprogram paths and not just the actual paths taken during code execution. In practice, our analysis produced \nonly three false positives when analyzing the three implementations of the Java Class Library, all of \nthem due to questionable coding practices in the Harmony implementation. For example, in java.security.Security. \ngetProperty(String), JDK uses checkPermission(), where\u00adas Harmony uses checkSecurityAccess(). There is \na mis\u00admatch between required permissions, but both checks achieve the same goal. In this example, both \nimplementations should have used checkPropertyAccess(). Similarly, Harmony unnecessar\u00adily uses checkConnect() \nto check address reachability inside the getInetAddresses() method, whereas JDK simply returns the result \nof InetAddrImpl.isReachable(). There are two causes of false negatives. First, two libraries may both \nimplement the security policy incorrectly and in the same way. The second cause is imprecision of our \nanalysis. For example, our analysis is not .eld or variable sensitive. If the library sends the wrong \nparameter to the security-checking method, or if it checks one variable and then makes a JNI call on \nanother, our analysis will not report an error. Furthermore, our analysis does not determine the potential \ntargets of unresolved method invocations for incom\u00adplete call graphs. Since 97% of method invocations \nwere resolved, we did not perform additional analysis, and this inaccuracy may result in false negatives. \nFinally, our comparison of may policies does not consider the conditions under which the checks are ex\u00adecuted. \nChanging our analysis to report these conditions is easy, but would result in an overwhelming number \nof reports. Verifying whether the conditions for two may policies are equivalent is dif.\u00adcult. We examined \nsome of the reports by hand and did not .nd any false negatives. A quantitative evaluation of false negatives \nwould require an enormous amount of time and expertise from the devel\u00adopers. 7. Related Work This section \ndescribes the closest related work on static analysis for .nding security errors and other bugs, as well \nas program differenc\u00ading. None of the prior work exploits multiple API implementations to automatically \nderive correctness criteria for security policies. 7.1 Static analysis and model checking The closest \nrelated static analysis techniques for verifying security mediation in Java code are by Koved et al. \n[22, 28] and Sistla et al. [30]. Koved et al. take security checks as inputs and use a .ow\u00adand context-sensitive \ninterprocedural must analysis to compute, for each point in the program, the set of checks performed \nprior to reaching it. The programmer must manually identify all security\u00adsensitive operations and verify \nwhether the computed checks are suf.cient. Our must polices are similar, but our policy differencing \neliminates the error-prone, manual veri.cation. Sistla et al. take as input a manual policy speci.ed \nas pairs of security checks (calls to the security manager) and security events (only JNI calls in their \nmodel). They use .ow-and context-sensitive interprocedural must analysis to .nd bad paths that reach \na secu\u00adrity event without performing the corresponding check. The MOPS project [7] applied a similar, \nbut .ow-insensitive, approach to C programs.  As our analysis shows, correct security enforcement sometimes \nrequires multiple checks. Furthermore, the check(s) may not dom\u00adinate the event (e.g., see Figure 1), \nnecessitating may analysis. In addition to native calls, the set of security events should also in\u00adclude \nat least API returns. The .nal and most signi.cant de.ciency of these prior approaches is that they provide \nno mechanism for determining whether the policy used for veri.cation is correct and complete. These de.ciencies \nare signi.cant in practice. Sistla et al. ana\u00adlyzed the JDK and Harmony libraries, while Koved et al. \nanalyzed JDK but neither paper reports any actual bugs. By using differ\u00adences between API implementations \nas an oracle for detecting in\u00adcorrect policies, we found multiple, con.rmed security vulnerabil\u00adities \nin JDK, Harmony, and Classpath, many of which were missed by prior analyses. Furthermore, our analysis \nproduces precise se\u00adcurity policies speci.c to concrete security-sensitive events. There is an enormous \namount of research on model checking that aims to prove programs correct using precise speci.cations \n[4 6, 8, 13]. In general, model checking does not yet scale to inter\u00adprocedural security analysis of \nlarge programs, and rigorous spec\u00adi.cation of security policies and vulnerability patterns has proven \nelusive so far. Whaley et al. extract .nite-state models of the interface of a class and its accesses \nto common data structures [37]. Security policies do not always follow their model. For instance, consider \nthe following simple example: 1 securityManager.checkPermission (); 2 doSensitiveOperation () ; Their \nanalysis cannot detect that doSensitiveOperation() should be dominated by checkPermission() because there \nis no data structure shared between the two methods. Furthermore, their analysis is not context sensitive. \nOur approach could be con\u00ad.gured to use arbitrary data structure accesses as security-sensitive events, \nbut we did not .nd it necessary. Ganapathy et al. use concept analysis to extract security\u00adsensitive \nevents [15]. Their approach is complementary to ours, since our analysis could take as input the security-sensitive \nevents they generate.  7.2 Bugs as inconsistencies Mining programs for static and dynamic models of \ncorrect behavior has become a popular approach for .nding bugs [2, 10, 14, 35]. In general, this approach \n.nds bugs that reveal themselves as anoma\u00adlies in common patterns of correct behavior. The fundamental \nas\u00adsumption is that correct patterns occur many times in the program and are thus easy to recognize. \nMining algorithms must be tuned to ignore unique or rarely observed behavior, or else they produce an \noverwhelming number of false positives. Because security policies are often unique to a particular API, \nthe bugs as inconsistencies approach is likely to miss many vulnerabilities (e.g., see Section 2). AutoISES \nstatically mines security patterns in C code and .ags deviations from frequent patterns as vulnerabilities \n[35]. Its anal\u00adysis targets security checks performed prior to security-sensitive operations in SELinux \nkernel routines. The AutoISES paper claims that the analysis is context sensitive and .ow insensitive, \nbut does not describe the actual algorithm or convergence criteria. It does mention that the analysis \npartitions the call graph into modules for scalability, thus missing security patterns and bugs on cross-module \ncall paths, although the authors argue that maintainable security policies should not cross modules at \nleast in C programs. In our experience with the Java libraries, both .ow and context sensitivity are \nessential for precision. Engler et al. statically extract intraprocedural patterns of correct behavior, \nincluding some security policies, and use them to detect anomalies [14]. Their policy descriptions include \na call to A al\u00adways or sometimes dominates a call to B and are thus similar to ours. However, these local \npatterns are not interprocedural they do not include .ow-and context-sensitive policies in which the \nsecurity check occurs in a different method than the operation it protects. Furthermore, the approach \nof Engler et al. ignores rare patterns. Dillig et al. .nd bugs by detecting static inconsistencies in \nthe program [10]. For example, they detect if the program con\u00adtains both if (x==NULL) foo.m(); and *x=y; \nwhich in\u00addicate both that x may be null and that x is de.nitely non-null. This analysis .nds local contradictions \nrather than semantic differ\u00adences. It captures neither rare events, nor interprocedural patterns. Both \napproaches will miss many vulnerabilities in Java code, where security-sensitive events and the corresponding \nchecks often occur in different methods. Another approach to mining speci.cation is to observe policies \nat run time. For example, Ammons et al. observe dynamic traces of method call sequences and use machine \nlearning to create API us\u00adage speci.cations in the form of .nite-state machines [2]. Dynamic mining approaches \nare at a disadvantage when policies are unique and/or rarely or never exercised by the test inputs. Kim \net al. use a database of previously .xed bugs to .nd their re\u00adcurrences in new code [21]. Hovemeyer and \nPugh use programmer\u00adde.ned bug patterns to .nd their occurrences [19]. To avoid false positives, these \ntools require well-de.ned bug patterns that apply to all contexts. These types of patterns are useful \nfor describing coding conventions, but generally do not capture context-speci.c semantics. Because many \nsecurity policies are context dependent and unique, these techniques cannot classify them as correct \nor in\u00adcorrect. Our work is also distantly related to program differencing. We .nd inconsistencies between \nimplementations of the same API us\u00ading identical API entry points, but do not assume that the imple\u00admentations \nare identical or even very similar. In our experience, dif\u00adferent implementations often choose different \nalgorithms and data structures. Techniques for .nding method clones methods that implement semantically \nsimilar functionality within the same pro\u00adgram [3, 12, 23, 24] are thus unlikely to classify two methods \nthat implement the same API as clones. However, it might be possible to leverage clone detection by .rst \n.nding clones, then extracting and comparing their security policies. We leave this exploration to future \nwork. In summary, our interprocedural, .ow-sensitive and context\u00adsensitive analysis is more precise than \nprior approaches. It does not require multiple instances of correct behavior within the same program \nand can thus .nd bugs in very rare patterns, such as the missing checkAccept in the example of Section \n2. It does, however, require at least two independent implementations of the same API. 8. Discussion \nand Conclusions This paper shows how to use precise, .ow-and context-sensitive security policy analysis \nto infer thousands of relationships between security checks and security-sensitive events in Java code, \nand how to use this information to compare implementations of the same li\u00adbrary API. The number of check-event \nrelationships in these imple\u00admentations is so large that it is clearly impractical for developers to \nanalyze them manually. In fact, prior techniques that produced sim\u00adilar policies for each implementation \nin isolation did not .nd any errors. By comparing precise policies from multiple implementa\u00adtions, we \ncreate a security policy oracle: any policy difference be\u00adtween two implementations of the same functionality \nindicates an error! Our approach uncovered many security vulnerabilities and interoperability bugs in \nthree large, mature, widely used implemen\u00adtations of the Java Class Library.  Of course, security-policy \ndifferencing requires multiple, inde\u00adpendent implementations and thus limits the applicability of our \napproach. However, many critical APIs, such as the Java, C#, and C libraries, have multiple implementations. \nFurthermore, they are an essential component of virtually every substantial application writ\u00adten in these \nlanguages. At least one open-source version of widely used APIs is often available and can be used as \na reference. In this use case, programmers of proprietary versions may not even need to read the open-source \ncode, but only study any reported differ\u00adences in security policies. If all API implementations are propri\u00adetary, \ndevelopers could use this approach to make their respective implementations more secure if one or more \nof them are willing to share extracted policies. Security vulnerabilities and other semantic errors in \npopular li\u00adbraries open the door to attacks that can compromise many systems, not just a single application. \nWith the advent of cloud computing and increasing demand for portability and architecture-speci.c op\u00adtimizations, \nthe prevalence of multiple implementations of the same API is likely to grow. This work shows for the \n.rst time how to leverage multiple implementations to improve the interoperability and security of each. \nOur approach may be applicable to other types of interoperabil\u00adity bugs. As Figure 8 shows, semantic \ndifferences sometimes ac\u00adcidentally show up as security-policy differences. A generalization of our analysis \nthat extracts and compares more general semantics of API implementations seems promising. For example, \ndifferences in how implementations access parameters, private variables, return values, and .ow values \nfrom parameters to private variables and re\u00adturn values may reveal interoperability bugs. Similar analysis \ncould detect differences in exceptions that may get thrown by each imple\u00admentation and in the semantic \ninformation carried by return values. Acknowledgments Thanks to Andrew John Hughes for his generous help \nwith verify\u00ading Classpath bugs and for feedback on the paper text; Sam Guyer for useful discussions about \nstatic analysis; and the anonymous re\u00adviewers for helpful feedback on the text. The research described \nin this paper was partially supported by the NSF grants CNS-0746888, CCF-0811523, CNS-0905602, SHF-0910818, \nand CCF-1018721, Google research award, and the MURI program under AFOSR Grant No. FA9550-08-1-0352. \nReferences [1] Amazon. Amazon Web Services. http://aws.amazon.com/. [2] G. Ammons, R. Bod\u00b4ik, and J. \nR. Larus. Mining speci.cations. In ACM Symposium on the Principles of Programming Languages, pages 4 \n16, 2002. [3] B. S. Baker. On .nding duplication and near-duplication in large soft\u00adware systems. In \nIEEE Working Conference on Reverse Engineering, pages 86 95, 1995. [4] T. Ball and S. K. Rajamani. The \nSLAM project: Debugging system software via static analysis. In ACM Symposium on the Principles of Programming \nLanguages, pages 1 3, 2002. [5] T. Ball, E. Bounimova, B. Cook, V. Levin, J. Lichtenberg, C. McGar\u00advey, \nB. Ondrusek, S. K. Rajamani, and A. Ustuner. Thorough static analysis of device drivers. In ACM European \nConference on Com\u00adputer Systems, pages 73 85, 2006. [6] D. Beyer, T. A. Henzinger, R. Jhala, and R. Majumdar. \nThe software model checker BLAST. International Journal on Software Tools for Technology Transfer, 9(5-6):505 \n525, 2007. [7] H. Chen and D. Wagner. MOPS: An infrastructure for examining security properties of software. \nIn ACM Conference on Computer and Communications Security, pages 235 244, 2002. [8] E. M. Clarke, E. \nA. Emerson, and A. P. Sistla. Automatic veri.cation of .nite-state concurrent systems using temporal \nlogic speci.cations. ACM Transactions on Programming Languages and Systems, 8(2): 244 263, 1986. [9] \nC. Cowan, P. Wagle, C. Pu, S. Beattie, and J. Walpole. Buffer over\u00ad.ows: Attacks and defenses for the \nvulnerability of the decade. In DARPA Information Survivability Conference and Exposition, pages 119 \n129, 2000. [10] I. Dillig, T. Dillig, and A. Aiken. Static error detection using semantic inconsistency \ninference. In ACM Conference on Programming Lan\u00adguage Design and Implementation, pages 435 445, 2007. \n[11] A. Diwan, K. S. McKinley, and J. E. B. Moss. Using types to analyze and optimize object-oriented \nprograms. ACM Transactions on Programming Languages and Systems, 23(1):30 72, 2001. [12] S. Ducasse, \nM. Rieger, and S. Demeyer. A language independent ap\u00adproach for detecting duplicated code. In IEEE International \nConfer\u00adence on Software Maintenance, pages 109 118, 1999. [13] E. A. Emerson and E. M. Clarke. Characterizing \ncorrectness properties of parallel programs using .xpoints. In Colloquium on Automata, Languages and \nProgramming, pages 169 181, 1980. [14] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and B. Chelf. Bugs \nas deviant behavior: A general approach to inferring errors in systems code. In ACM Symposium on Operating \nSystems Principles, pages 57 72, 2001. [15] V. Ganapathy, D. King, T. Jaeger, and S. Jha. Mining security\u00adsensitive \noperations in legacy code using concept analysis. In ACM International Conference on Software Engineering, \npages 458 467, 2007. [16] Google. Google Apps. http://www.google.com/apps/. [17] D. Grove and L. Torczon. \nInterprocedural constant propagation: A study of jump function implementations. In ACM Conference on \nProgramming Language Design and Implementation, pages 90 99, 1993. [18] S. Z. Guyer and C. Lin. Error \nchecking with client-driven pointer analysis. Science of Computer Programming, 58(1-2):83 114, 2005. \n[19] D. Hovemeyer and W. Pugh. Finding bugs is easy. In ACM OOPSLA Onward!, pages 92 106, 2004. [20] \nIBM. Cloud Computing. http://ibm.com/developerworks/ cloud/. [21] S. Kim, K. Pan, and E. E. J. Whitehead, \nJr. Memories of bug .xes. In ACM Symposium on the Foundations of Software Engineering, pages 35 45, 2006. \n[22] L. Koved, M. Pistoia, and A. Kershenbaum. Access rights analysis for Java. In ACM Conference on \nObject Oriented Programming, Systems, Languages, and Applications, pages 359 372, 2002. [23] J. Krinke. \nIdentifying similar code with program dependence graphs. In IEEE Working Conference on Reverse Engineering, \npages 301 309, 2001. [24] A. M. Leitao. Detection of redundant code using R2D2 . Software Quality Control, \n12(4):361 382, 2004. [25] O. Lhot\u00b4Context-sensitive points-to analysis: Is ak and L. Hendren. it worth \nit? In International Conference on Compiler Construction, pages 47 64, 2006. [26] Z. Li, L. Tan, X. Wang, \nS. Lu, Y. Zhou, and C. Zhai. Have things changed now? An empirical study of bug characteristics in modern \nopen source software. In Workshop on Architectural and System Support for Improving Software Dependability \n(ASID), pages 25 33, 2006. [27] T. J. Marlowe and B. G. Ryder. Properties of data .ow frameworks. Acta \nInformatics (ACTA), 28(2):121 163, 1990.  [28] M. Pistoia, R. J. Flynn, L. Koved, and V. C. Sreedhar. \nInterproce\u00addural analysis for privileged code placement and tainted variable de\u00adtection. In European \nConference on Object-Oriented Programming, pages 362 386, 2005. [29] Salesforce. Salesforce Platform. \nhttp://www.salesforce.com/ platform/. [30] A. P. Sistla, V. N. Venkatakrishnan, M. Zhou, and H. Branske. \nCMV: Automatic veri.cation of complete mediation for Java Virtual Ma\u00adchines. In ACM Symposium on Information, \nComputer and Commu\u00adnications Security, pages 100 111, 2008. [31] V. Srivastava. Vulnerabilities submitted \nto Classpath, Dec 2009 Jan 2010. http://gcc.gnu.org/bugzilla/show_bug.cgi?id= 42390. [32] V. Srivastava. \nVulnerabilities submitted to Harmony, Nov 2009. https://issues.apache.org/jira/browse/HARMONY-6367. [33] \nV. Srivastava. Vulnerabilities submitted to Sun JDK, Jan Oct 2010. http://bugs.sun.com/bugdatabase/view_bug.do? \nbug_id=6914460. [34] V. Sundaresan, L. Hendren, C. Raza.mahefa, R. Vall\u00b4ee-Rai, P. Lam, E. Gagnon, and \nC. Godin. Practical virtual method call resolution for Java. In ACM Conference on Object Oriented Programming, \nSystems, Languages, and Applications, pages 264 280, 2000. [35] L. Tan, X. Zhang, X. Ma, W. Xiong, and \nY. Zhou. AutoISES: Auto\u00admatically inferring security speci.cations and detecting violations. In USENIX \nSecurity Symposium, pages 379 394, 2008. [36] M. N. Wegman and F. K. Zadeck. Constant propagation with \ncondi\u00adtional branches. ACM Transactions on Programming Languages and Systems, 13(2):181 210, 1991. [37] \nJ. Whaley, M. C. Martin, and M. S. Lam. Automatic extraction of object-oriented component interfaces. \nIn ACM International Sympo\u00adsium on Software Testing and Analysis, pages 218 228, July 2002. [38] R. P. \nWilson and M. S. Lam. Ef.cient context-sensitive pointer anal\u00adysis for C programs. In ACM Conference \non Programming Language Design and Implementation, pages 1 12, 1995. [39] B. Yee, D. Sehr, G. Dardyk, \nJ. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar. Native Client: A sandbox for \nportable, untrusted x86 native code. Communications of the ACM, 53(1):91 99, 2010.   \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Even experienced developers struggle to implement security policies correctly. For example, despite 15 years of development, standard Java libraries still suffer from missing and incorrectly applied permission checks, which enable untrusted applications to execute native calls or modify private class variables without authorization. Previous techniques for static verification of authorization enforcement rely on manually specified policies or attempt to infer the policy by code-mining. Neither approach guarantees that the policy used for verification is correct.</p> <p>In this paper, we exploit the fact that many modern APIs have <i>multiple, independent</i> implementations. Our flow- and context-sensitive analysis takes as input an API, multiple implementations thereof, and the definitions of security checks and security-sensitive events. For each API entry point, the analysis computes the security policies enforced by the checks before security-sensitive events such as native method calls and API returns, compares these policies across implementations, and reports the differences. Unlike code-mining, this technique finds missing checks even if they are part of a rare pattern. Security-policy differencing has no intrinsic false positives: implementations of the same API <i>must</i> enforce the same policy, or at least one of them is wrong!</p> <p>Our analysis finds 20 new, confirmed security vulnerabilities and 11 interoperability bugs in the Sun, Harmony, and Classpath implementations of the Java Class Library, many of which were missed by prior analyses. These problems manifest in 499 entry points in these mature, well-studied libraries. Multiple API implementations are proliferating due to cloud-based software services and standardization of library interfaces. Comparing software implementations for consistency is a new approach to discovering \"deep\" bugs in them.</p>", "authors": [{"name": "Varun Srivastava", "author_profile_id": "81464659461", "affiliation": "Yahoo!, Sunnyvale, CA, USA", "person_id": "P2690577", "email_address": "varun iiit@yahoo.co.in", "orcid_id": ""}, {"name": "Michael D. Bond", "author_profile_id": "81100148693", "affiliation": "The Ohio State University, Columbus, OH, USA", "person_id": "P2690578", "email_address": "mikebond@cse.ohio-state.edu", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690579", "email_address": "mckinley@cs.utexas.edu", "orcid_id": ""}, {"name": "Vitaly Shmatikov", "author_profile_id": "81338491121", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2690580", "email_address": "shmat@cs.utexas.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993539", "year": "2011", "article_id": "1993539", "conference": "PLDI", "title": "A security policy oracle: detecting security holes using multiple API implementations", "url": "http://dl.acm.org/citation.cfm?id=1993539"}