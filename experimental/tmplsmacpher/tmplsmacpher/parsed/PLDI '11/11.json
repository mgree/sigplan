{"article_publication_date": "06-04-2011", "fulltext": "\n Languages as Libraries * Sam Tobin-Hochstadt Vincent St-Amour Ryan Culpepper Matthew Flatt Matthias \nFelleisen Northeastern University Northeastern University University of Utah University of Utah Northeastern \nUniversity Abstract Programming language design bene.ts from constructs for extend\u00ading the syntax and \nsemantics of a host language. While C s string\u00adbased macros empower programmers to introduce notational \nshort\u00adhands, the parser-level macros of Lisp encourage experimentation with domain-speci.c languages. \nThe Scheme programming lan\u00adguage improves on Lisp with macros that respect lexical scope. The design \nof Racket a descendant of Scheme goes even fur\u00adther with the introduction of a full-.edged interface \nto the static se\u00admantics of the language. A Racket extension programmer can thus add constructs that \nare indistinguishable from native notation, large and complex embedded domain-speci.c languages, and \neven optimizing transformations for the compiler backend. This power to experiment with language design \nhas been used to create a series of sub-languages for programming with .rst-class classes and mod\u00adules, \nnumerous languages for implementing the Racket system, and the creation of a complete and fully integrated \ntyped sister language to Racket s untyped base language. This paper explains Racket s language extension \nAPI via an im\u00adplementation of a small typed sister language. The new language provides a rich type system \nthat accommodates the idioms of un\u00adtyped Racket. Furthermore, modules in this typed language can safely \nexchange values with untyped modules. Last but not least, the implementation includes a type-based optimizer \nthat achieves promising speedups. Although these extensions are complex, their Racket implementation \nis just a library, like any other library, re\u00adquiring no changes to the Racket implementation. Categories \nand Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs and Features General Terms \nLanguages, Design 1. Growing Many Languages I need to design a language that can grow. Guy Steele, 1998 \nVirtual machines inspire language experimentation. For example, the Java Virtual Machine and the .NET \nCLR attracted many im\u00adplementors to port existing languages. Their goal was to bene.t from the rich set \nof libraries and runtime facilities, such as garbage * A preliminary version of this work appeared at \nthe Workshop on Scheme and Functional Programming (Culpepper et al. 2007). This work has been supported \nby the DARPA, Mozilla Foundation, NSERC, and NSF. Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. collectors and thread abstractions, that these platforms offer. \nBoth platforms also inspired language design projects that wanted to ex\u00adperiment with new paradigms and \nto exploit existing frameworks; thus Clojure, a parallelism-oriented descendant of Lisp, and Scala, a \nmulti-paradigm relative of Java, target the JVM, while F# is built atop .NET. In all of these cases, \nhowever, the platform is only a target, not a tool for growing languages. As a result, design experi\u00adments \non these platforms remain costly, labor-intensive projects. To follow Steele s advice on growing a language \n(1998) re\u00adquires more than a reusable virtual machine and its libraries; it demands an extensible host \nlanguage that supports linguistic reuse (Krishnamurthi 2001). Thus, a derived language should be able \nto reuse the scoping mechanisms of the host language. Simi\u00adlarly, if the host language offers namespace \nmanagement for iden\u00adti.ers, a language designer should have the freedom to lift that management into \nan experimental language. Providing such freedoms to designers demands a range of ex\u00adtension mechanisms. \nA programmer may wish to manipulate the surface syntax and the AST, interpose a new context-sensitive \nstatic semantics, and communicate the results of the static semantics to the backend. Best of all, this \nkind of work can proceed without any changes to the host language, so that the resulting design is essen\u00adtially \na library that supplements the existing compiler. In this paper, we present the Racket1 (Flatt and PLT \n2010) platform, which combines a virtual machine and JIT compiler with a programming language that supports \nextension mechanisms for all phases of language implementation. With Racket s arse\u00adnal of extension mechanisms, \na programmer may change all as\u00adpects of a language: lexicographic and parsed notation, the static semantics, \nmodule linking, and optimizations. The Racket devel\u00adopment team has exploited this extensibility for \nthe construction of two dozen frequently used languages, e.g., language extensions for classes (Flatt \net al. 2006) and ML-style functors (Flatt and Felleisen 1998; Culpepper et al. 2005), another for creating \nin\u00adteractive web server applications (Krishnamurthi et al. 2007), two languages implementing logic programming2 \nand a lazy variant of Racket (Barzilay and Clements 2005). This paper is itself a pro\u00adgram in Racket \ns documentation language (Flatt et al. 2009). Racket derives its power from a carefully designed revision \nof a Scheme-style macro systems. The key is to make language choice speci.c to each module. That is, \nindividual modules of a program can be implemented in different languages, where the language implementation \nhas complete control over the syntax and semantics of the module. The language implementation can reuse \nas much of the base language as desired, and it can export as much of the module s internals as desired. \nIn particular, languages can reuse Racket s macro facilities, which is supported with a mechanism for \nlocally expanding macros into attributed ASTs. 1 Formerly known as PLT Scheme. PLDI 11, June 4 8, 2011, \nSan Jose, California, USA. 2 Schelog (1993) http://docs.racket-lang.org/racklog Copyright &#38;#169; \n2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 Datalog (2010) http://docs.racket-lang.org/datalog  For \nsimplicity, we demonstrate the idea of true language ex\u00adtensibility via a single example: the Typed Racket \nimplementation. Typed Racket (Tobin-Hochstadt and Felleisen 2008) is a statically typed sister language \nof Racket that is designed to support the grad\u00adual porting of untyped programs. Its type system accommodates \nthe idioms of Racket, its modules can exchange values with untyped modules, and it has a type-driven \noptimizer all implemented as plain Racket libraries. The remainder of this paper starts with a description \nof Racket s language extension facilities and the challenges posed by the Typed Racket extension. Following \nthese background sections, the paper shows how we use syntactic extension to introduce Typed Racket notation; \nhow we splice the type checker into the tool chain; how we enable inter-language linking; and how we \nadd realistic op\u00adtimizing transformations via a library. Finally, we relate our ap\u00adproach to existing \nfacilities for meta-programming with static se\u00admantics as well as extensible compiler projects. 2. Language \nExtension in Racket Racket provides a range of facilities for language extension. In this section, we \noutline the most relevant background as well as extension mechanisms provided with Racket. 2.1 Macros \nFrom Lisp (Steele Jr. 1994) and Scheme (Sperber et al. 2009), Racket takes hygienic macros as the basis \nof its syntactic exten\u00adsion mechanisms. In Racket, macros are functions from syntax to syntax, which \nare executed at compile time. During compilation, Racket s macro expander recursively traverses the input \nsyntax. When it reaches the use of a macro, it runs the associated function, the transformer, and continues \nby traversing the result. Macros may use arbitrary Racket libraries and primitives to compute the result \nsyntax. The following macro queries the system clock at compile time: (define-syntax (when-compiled stx) \n(with-syntax ([ct (current-seconds)]) # ct)) This macro computes, at compile time, the current time \nin seconds, and uses the with-syntax form to bind the identi.er ct to a syntax object representing this \nnumber. Syntax objects are the ASTs of Racket, and contain syntactic data as well as metadata such as \nsource location information. The # form (analogous to for lists) constructs syntax objects and can refer \nto identi.ers bound by with-syntax in its context. In the following function, we use the when-compiled \nmacro: (define (how-long-ago?) (-(current-seconds) (when-compiled))) Since the when-compiled form expands \ninto the current date in seconds at the time the form is compiled and since the value of (current-seconds) \ncontinues to change, the value produced by how-long-ago? continually increases > (how-long-ago?) 0 > \n(sleep 1) > (how-long-ago?) 1 Most macros generate new expressions based on their input: (define-syntax \n(do-10-times stx) (syntax-parse stx [(do-10-times body:expr ...) # (for ([i (in-range 10)]) body ...)])) \n> (do-10-times (display \"*\") (display \"#\")) *#*#*#*#*#*#*#*#*#*# The do-10-times macro consumes a sequence \nof expressions and produces code that runs these expressions 10 times. To this end, it .rst decomposes \nits input, stx, with the syntax-parse form (Culpepper and Felleisen 2010), a pattern matcher designed \nfor implementing macros. The pattern requires a sequence of subexpressions, indicated with ..., named \nbody, each of which is constrained to be an expr. The resulting syntax is a for loop that contains the \nbody expressions. Thanks to macro hygiene, if the bodys use the variable i, it is not interfered with \nby the use of i in the for loop.  2.2 Manipulating Syntax Objects Since syntax objects are Racket s \nprimary compile-time data struc\u00adture, roughly analagous to the ASTs of conventional languages, syntax \nobjects come with a rich API. Constructors and Accessors Besides with-syntax and # for constructing and \nmanipulating syntax objects, the remainder of the paper also uses the following forms and functions: \n syntax->list converts a non-atomic syntax object to a list;  free-identifier=? compares two identi.ers \nto deter\u00admine if they refer to the same binding;  the # and #, forms implement Lisp s quasiquote and \nunquote for syntax object construction.  Syntax properties Racket macros can add out-of-band informa\u00adtion \nto syntax objects, e.g., source locations, dubbed syntax proper\u00adties. The syntax-property-put and syntax-property\u00adget \nprocedures attach and retrieve arbitrary key-value pairs on syntax objects, which are preserved by the \nmacro expander. Thus syntactic extensions may communicate with each other without in\u00adterfering with each \nother. Local Expansion The local-expand procedure expands a syntax object to core Racket. This explicitly \nspeci.ed core lan\u00adguage consists of approximately 20 primitive syntactic forms that implement Racket; \nsee .gure 1 for a subset of this grammar. Using local-expand, a language extension may analyze an arbitrary \nexpression, even if that expression uses macros. For example, the following macro requires that its argument \nbe a . expression: (define-syntax (only-. stx) (syntax-parse stx [(_ arg:expr) (define c (local-expand \n# arg expression ())) (define k (first (syntax->list c))) (if (free-identifier=? # #%plain-lambda k) \nc (error \"not .\"))])) The only-. macro uses local-expand on the arg subexpres\u00adsion to fully expand it: \n> (only-. (. (x) x)) #<procedure> > (only-. 7) not . If we add a de.nition that makes function the same \nas ., we still get the correct behavior. > (only-. (function (x) x)) #<procedure> The only-. macro can \nsee through the use of function be\u00adcause of the use of local-expand.  2.3 Modules and Languages Racket \nprovides a .rst-order module system that supports import and export of language extensions (Flatt 2002). \nFor the purposes  mod-form = expr | (#%provide provide-spec) | (define-values (id) expr) | ... expr \n= id | (#%plain-lambda (id ...) expr ...+) | (if expr expr expr) | (quote datum) | (#%plain-app expr \n...+) | ... Figure 1: Racket s core forms (abbreviated) of this paper, two aspects of the module system \nare crucial. First, modules can export static bindings, such as macros, as well as value bindings, such \nas procedures, without requiring clients to distin\u00adguish between them. Thus, value bindings can be replaced \nwith static bindings without breaking clients. Second, each module is compiled with a fresh store. That \nis, mutations to state created dur\u00ading one compilation do not affect the results of other compilations. \nEvery module speci.es in the .rst line of the module the language it is written in. For example, #lang \nracket speci.es racket as the module s language, and #lang datalog speci.es datalog instead, a language \nextension with different lexical syntax, static and dynamic semantics from plain Racket. For the purposes \nof this paper, a language L is a library that provides two linguistic features: a set of bindings for \nL, including both syntactic forms such as define and values such as +, which constitute the base environment \nof modules written in the language, and  a binding named #%module-begin, which is used to imple\u00adment \nthe whole-module semantics of L.  The #%module-begin form is applied to the entire module before the \nmacro expander takes over. For example, here is the #%module-begin form for the count language: (define-syntax \n(#%module-begin stx) (syntax-parse stx [(#%module-begin body ...) # (#%plain-module-begin (printf \"Found \n~a expressions.\" #,(length (syntax->list # (body ...)))) body ...)])) The #%plain-module-begin form \nis the base module wrap\u00adper, adding no new static semantics. When this language is used, it prints the \nnumber of top-level expressions in the program, then runs the program as usual. For example, consider \nthe following module written in count: #lang count (printf \"*~a\" (+ 1 2)) (printf \"*~a\" (-4 3)) When \nrun, this module prints: Found 2 expressions.*3*1. The #%module-begin language mechanism allows a lan\u00adguage \nauthor to implement arbitrary new whole-module static se\u00admantics using macro rewriting. 3. Typed Racket \nas a Library Typed Racket combines a type system for enriching Racket mod\u00adules with sound type information \nand a mechanism for linking typed and untyped modules. Its implementation not only bene.ts from, but \ndemands, as much linguistic reuse as possible. After all, Typed Racket must implement the same semantics \nas Racket plus purely syntactic type checking; there is no other way to provide a smooth migration path \nthat turns Racket programs into Typed Racket programs on a module-by-module basis. And the best way to \nimplement the same semantics is to share the compiler. At the same time, linguistic reuse poses novel \nchallenges in addition to those faced by every implementer of a typed language. In this section, we explain \nthese challenges with examples; in the remainder of the paper we explain our solutions. As for the particular \nchallenges, we show how to: 1. annotate bindings with type speci.cations; 2. check type correctness \nin a context-sensitive fashion; 3. type check programs written in an extensible language; 4. integrate \ntype checking with separate compilation of modules; 5. provide safe interaction with untyped modules; \nand 6. optimize programs based on type information.  3.1 Layering Types on an Untyped Language Consider \nthis trivial Typed Racket program: #lang typed/racket (define: x : Number 3) It speci.es that x has type \nNumber. To implement define:, Typed Racket reuses the plain define provided by Racket. Thus we must associate \nthe type declaration for x out-of-band. Further, although modern languages come with a wide variety of \nsyntactic forms, most can be reduced to simpler forms via rewrite rules implemented as macros, e.g.: \n(define-syntax (let: stx) (syntax-parse stx [(let ([x:id : T rhs:expr]) body:expr) # ((.: ([x : T]) body) \nrhs)])) For Typed Racket, these rewriting rules must preserve the speci.ed type information without interfering \nwith the implementation of the typechecker. These are two instances of Typed Racket s linguistic reuse. \nThis linguistic reuse is comprehensive through all layers of Typed Racket. Modules in Typed Racket are \nsimply Racket modules. The same is true of functions and variables, which map directly to their Racket \nequivalents. At the intermediate level, Typed Racket reuses Racket s binding forms, such as define and \n., with additions for the speci.cation of types as described above. At the lowest level, runtime values \nare shared between Racket and Typed Racket. Returning to our example, the plain Racket de.nition form \nis: (define x 3) There is no place in such a de.nition for a type annotation. Hence, the macro must store \nthe type information out-of-band. Fortunately, syntax properties allow for define: to record precisely \nsuch additional information: (define-syntax (define: stx) (syntax-parse stx [(define: name:id : ty rhs:expr) \n(with-syntax ([ann-name (syntax-property-put # name type-annotation # ty)]) # (define ann-name rhs))])) \n Here, ann-name is the original name, but with a syntax property indicating that it is annotated with \nthe type ty. With this implemen\u00adtation, later stages of processing can read the type annotation from \nthe binding, but the type annotation does not affect the behavior of Racket s define, allowing reuse \nas desired.  3.2 Challenges Next we turn to the challenges of other processing phases. Context-sensitive \nChecking Type checking is inherently context\u00adsensitive. For example, this Typed Racket program: #lang \ntyped/racket (: f (Number -> Number)) (define (f z) (sqrt (* 2 z))) (f 7) relies on contextual information \nabout the type of f when check\u00ading the function application (f 7). Tracking this information de\u00admands \nan implementation that typechecks the entire module, rather than just the syntax available at a particular \nprogram point; in other words, it is a whole-module analysis. Checking an Extended Language Typed Racket \nprogrammers expect to use the numerous libraries provided by Racket, many of which provide syntactic \nabstractions. For example, this module uses match, a syntactic form implemented in a library written \nin plain Racket, rather than a primitive form as in ML or Haskell, but nonetheless indistinguishable \nfrom a language primitive: #lang racket (match (list 1 2 3) [(list x y z) (+ x y z)]) Naturally, Typed \nRacket programmers want to reuse such conve\u00adnient libraries, ideally without modi.cations, so that the \nabove be\u00adcomes a valid Typed Racket module by using typed/racket. Therefore, we must either extend our \ntypechecker to handle match, or translate match into a simpler form that the type\u00adchecker understands. \nThe former solution works for existing lan\u00adguage extensions, but in Racket, programmers can write new \nlan\u00adguage extensions at any time, meaning that Typed Racket cannot possibly contain a catalog of all \nof them. Supporting Modular Programs Racket programs consist of mul\u00adtiple modules; Typed Racket therefore \nsupports modules as well. The types of bindings de.ned in one module must be accessible in other typed \nmodules without the need to repeat type declarations. For example: #lang typed/racket ;; module server \n(: add-5 : Integer -> Integer) (define (add-5 x) (+ x 5)) ;; export add-5 from the module (provide add-5) \n#lang typed/racket ;; module client (require server) (add-5 7) ;; type checks correctly Because modules \nare compiled separately, the server module is compiled before the client module, but must communicate \nthe static information about the type of add-5 to client. Therefore, compiling a Typed Racket module \nmust produce a persistent record of the types of exported bindings. Integrating with Untyped Modules \nRacket comes with hundreds of thousands of lines of libraries, almost all of which are written without \ntypes. Effective use of Typed Racket, therefore, requires interoperation with untyped modules. Typed \nRacket supports such interoperation in both directions. First, typed modules can import untyped bindings \nby specifying their types: #lang typed/racket (require/typed racket/file [file->lines (Path -> (Listof \nString))]) (file->lines \"/etc/passwd\") Second, untyped modules can import typed bindings: #lang racket \n;; client (require server) (add-5 12) ;; safe use (add-5 \"bad\") ;; unsafe use Typed Racket must protect \nits soundness invariants and check value .ow across the boundary between typed and untyped programs. \nIt must also avoid, however, imposing unnecessary dynamic checks between typed modules. Optimizing with \nType Information Type information enables a wide variety of optimizations. Tag checking, ubiquitous in \nuntyped Racket programs, is unnecessary in typed programs. For example, this program need not check that \nthe argument to first is a pair: #lang typed/racket (: p : (List Number Number Number)) (define p (list \n1 2 3)) (first p) Of course, with type information, more signi.cant optimizations are also possible. \nThe following loop is transformed into one that performs only machine-level .oating-point computation: \n#lang typed/racket (: count : Float-Complex -> Integer) (define (count f) (let loop ([f f]) (if (< (magnitude \nf) 0.001) 0 (add1 (loop (/ f 2.0+2.0i)))))) In particular, the type information should assist the compiler \nback\u00adend with the treatment of complex and .oating-point numbers. 4. A Single-Module Typechecker This \nsection presents the single-module core of a simply-typed version of Typed Racket. It concludes with \nan explanation of how to scale the system to the full typechecker of Typed Racket. 4.1 An Example Assume \nour language is available from the simple-type library. Thus, we can write modules like the following: \n#lang simple-type (define x : Integer 1) (define y : Integer 2) (define (f [z : Integer]) : Integer (* \nx (+ yz))) Such a module is .rst fully expanded to the appropriate core forms and then typechecked. Thus, \ntype-incorrect de.nitions and expressions signal compile-time errors. (define w : Integer 3.7) typecheck: \nwrong type in: 3.7 Modules with type errors are not executable.  4.2 Wiring Up the Typechecker Typechecking \na module is a context-sensitive process and therefore demands a whole-module analysis via #%module-begin. \nSince Racket provides a rich mechanism for syntactic exten\u00adsion, many important language features are \nimplemented as lan\u00adguage extensions. Major examples are pattern matching, keyword arguments, and even \nsimple conditional forms such as case and cond. Providing appropriate type rules for every syntactic \nexten\u00adsion, however, is clearly impossible, because programmers can in\u00advent new extensions at any time. \nInstead, we consider only the  (define-syntax (#%module-begin stx) (syntax-parse stx [(_ forms ...) \n(with-syntax ([(_ core-forms ...) (local-expand # (#%plain-module-begin forms ...) module-begin ())]) \n(for-each typecheck (syntax->list # (core-forms ...))) # (#%plain-module-begin core-forms ...))])) Figure \n2: The Top-level Driver (define (typecheck t [check #f]) (define the-type (syntax-parse t [v:identifier \n(lookup-type # v)] [(quote n:number) (cond [(exact-integer? (syntax-e # n)) IntT] [(flonum? (syntax-e \n# n)) FloatT] [else NumberT])] [(if e1 e2 e3) (typecheck # e1 BooleanT) (unless (equal? (typecheck # \ne2) (typecheck # e3)) (type-error \"if branches must agree\")) (typecheck # e3)] [(#%plain-lambda formals \nbody:expr) (define formal-types (map type-of (syntax->list # formals))) (for-each add-type! (syntax->list \n# formals) formal-types) (make-fun-type formal-types (typecheck # body))] [(#%plain-app op . args) (define \nargtys (map typecheck (syntax->list # args))) (match (typecheck # op) [(struct fun-type (formals ret)) \n(unless (and (= (length argtys) (length formals)) (andmap subtype argtys formals)) (type-error \"wrong \nargument types\" t)) ret] [t (type-error \"not a function type\" # op)])] [(define-values (id) rhs) (add-type! \n# id (type-of # id)) (typecheck # rhs (type-of # id))])) (when (and check (not (subtype the-type check))) \n(type-error \"wrong type\" t)) the-type) ;; get the type of a binding (define (type-of id) (unless (syntax-property-get \nid type) (type-error \"untyped variable\" id)) (parse-type (syntax-property-get id type))) Figure 3: The \nTypechecker small .xed set of core forms of .gure 1, and reduce all other forms to these before type \nchecking. Given an implementation of the typechecker, we must connect it to the program so that it receives \nappropriate fully-expanded syntax objects as input. The basic driver is given in .gure 2. The driver \nis straightforward, performing only two functions. Once we have fully expanded the body of the module, \nwe typecheck each form in turn. The typechecker raises an error if it encounters an untypable form. Finally, \nwe construct the output module from new core forms, thus avoiding a re-expansion of the input. The strategy \nof reducing syntactic sugar to core forms is com\u00admon in many other languages, and even speci.ed in the \nstandards for ML (Milner et al. 1997) and Haskell (Marlow 2010). In a lan\u00adguage with syntactic extension, \nwe need more sophisticated sup\u00adport from the system to implement this strategy, and that support is provided \nin Racket by local-expand. For successful typechecking, we must also provide an initial en\u00advironment. \nThe initial environment speci.es types for any identi\u00ad.ers that the language provides, such as +, as \nwell as the initial type names. Finally, we provide the define and . binding forms that attach the appropriate \nsyntax properties for type annotations to the bound variables, as described in section 2.1.  4.3 Typechecking \nSyntax Figure 1 displays the grammar for our simple language. It is a sub\u00adset of the core forms of full \nRacket. Modules consist of a sequence of mod-forms, which are either expressions or de.nitions. Figure \n3 speci.es the typechecker for this core language. The typecheck function takes a term and an optional \nresult type. Each clause in the syntax-parse expression considers one of the core forms described in \n.gure 1. Two aspects of the typechecker are distinctive. First, the type en\u00advironment uses a mutable \ntable mapping identi.ers to types based on their binding; the table is accessed with lookup-type and \nup\u00addated with add-type!. Shadowing is impossible because identi\u00ad.ers in fully-expanded Racket programs \nare unique with respect to the entire program. We update the type environment in the clauses for both \n#%plain-lambda and define-values. Using an identi.er-keyed table allows reuse of the Racket binding structure \nwithout having to reimplement variable renaming or environments.  The second distinctive feature of \nthe typechecker is the type\u00adof function. It reads the syntax properties attached by forms such as define: \nin section 3.1 with a known key to determine the type the user has added to each binding position.  \n4.4 Scaling to Typed Racket While this module-level typechecker is simple, the full implemen\u00adtation for \nTyped Racket employs the same strategy. The impor\u00adtant differences concern mutual recursion and complex \nde.nition forms. Mutual recursion is implemented with a two-pass type\u00adchecker: the .rst pass collects \nde.nitions with their types, and the second pass checks individual expressions in this type context. \nComplex declarations, such as the de.nition of new types, are also handled in the .rst pass. They are \nrecognized by the typechecker, and the appropriate bindings and types are added to the relevant environments. \nOf course, the Typed Racket type system is much more com\u00adplex (Strickland et al. 2009; Tobin-Hochstadt \nand Felleisen 2010) than the one we have implemented here, but that complexity does not require modi.cations \nto the structure of the implementation it is encapsulated in the behavior of typecheck on the core forms. \n5. Modular Typed Programs The typechecker in section 4 deals only with individual modules. To deal with \nmultiple modules, we must both propagate type infor\u00admation between typed modules, and also persist type \ninformation in compiled code to support separate compilation. For the .rst point, we reuse some Racket \ninfrastruture. Names\u00adpace management in a modular language is a complex problem, and one that Racket \nalready solves. In particular, identi.ers in Racket are given globally fresh names that are stable across \nmodules dur\u00ading the expansion process. Since our type environment is keyed by identi.ers, type environment \nlookup reuses and respects Racket s scoping. An identi.er imported from one module maintains its identity \nin the importing module, and therefore the typechecker is able to look up the appropriate type for the \nbinding. The second step is to maintain the type environment across com\u00adpilations. Since each module \nis compiled in a separate and fresh store, mutations to the type environment do not persist between compilations. \nTherefore, Typed Racket must incorporate the type environment into the residual program, because that \nis the only per\u00adsistent result of compilation. Our strategy due to Flatt (2002) is to include code \nin the resulting module that populates the type environment every time the module is required. In our \nexample system, we implement this by adding a single rewriting pass to the #%module-begin form for Typed \nRacket. Expressions and de.nitions are left alone; an appropriate compile\u00adtime declaration is added for \neach export: (provide n) ; The original export ; ==> (is rewritten into) (with-syntax ([t (serialize \n(type-of # n))]) # (begin (#%provide n) ; The core export form (begin-for-syntax (add-type! # n t)))) \nThe resulting code uses #%provide to maintain the original ex\u00adport. The type declaration is wrapped in \nbegin-for-syntax, meaning that it is executed at compile time to declare that n is mapped to the serialization \nof its type in the type environment. (define-syntax (require/typed stx) (syntax-parse stx [(_ module \n[id ty]) # (begin-ignored ; Stage 1 (require (only-in module [id unsafe-id])) ; Stage 2 (begin-for-syntax \n(add-type! # id (parse-type # ty))) ; Stage 3 (define id (contract #,(type->contract (parse-type # ty)) \nunsafe-id (quote module) typed-module)))])) Figure 4: Import of Untyped Code 6. Safe Cross-Module Integration \nA module in Typed Racket should have access to the large col\u00adlection of untyped libraries in Racket. \nConversely, our intention to support gradual refactoring of untyped into typed systems de\u00admands that \ntyped modules can export bindings to untyped mod\u00adules. However, untyped programs are potentially dangerous \nto the invariants of typed modules. To protect these invariants, we auto\u00admatically generate run-time \ncontracts from the types of imported and exported bindings (Tobin-Hochstadt and Felleisen 2006). However, \na large library of untyped modules is useless if each must be modi.ed to work with typed modules. Therefore, \nour im\u00adplementation must automatically wrap imports from untyped code, and protect exports to untyped \ncode, without requiring changes to untyped modules. Further, communication between typed modules should \nnot involve extra contract checks, since these invariants are enforced statically. 6.1 Imports from \nUntyped Modules Typed Racket requires the programmer to specify the types of imports from untyped modules: \n(require/typed file/md5 [md5 (Bytes -> Bytes)]) This speci.cation imports the md5 procedure, which computes \nthe MD5 hash of a byte sequence. The procedure can be used in typed code with the speci.ed type, and \nthe type is converted to a con\u00adtract and attached to the procedure on import. This translation and interposition \nis implemented in the require/typed form; see .gure 4 for an implementation for our simple-type language. \nThe implementation of require/typed works in three stages. Stage 1 imports the speci.ed identi.er, id \nfrom mod\u00adule under the new name unsafe-id. Stage 2 parses and adds the speci.ed type to the table of \ntypes with add-type!. Finally, stage 3 de.nes the identi.er id as a wrapper around unsafe-id. The wrapper \nis a generated contract and establishes a dynamically enforced agreement between the original module \n(named module) and the typed module (with the placeholder name).3 The entire out\u00adput is wrapped in begin-ignored \nso that the type checker does not process this meta-information. In our example, we would now be able \nto use the md5 function in typed code according to the speci.ed type, getting a static type error if \nmd5 is applied to a number, for example. Conversely, if the 3 In practice, type checking renders the \ndomain contract super.uous.  file/md5 library fails to return a byte string value, a dynamic contract \nerror is produced, avoiding the possibility that the typed module might end up with a value that it did \nnot expect.  6.2 Exports to Untyped Modules Unlike imports into a typed module, exports from such a \nmodule pose a serious problem because the Typed Racket language imple\u00admentation is not necessarily in \ncontrol of the use site. After all, an exported identi.er may be used in both typed and untyped contexts. \nSince typed modules statically verify that uses of typed identi.ers accord with their types, no contracts \nare necessary for exports to such modules. In contrast, exports from typed to untyped modules require \nthe insertion of dynamic checks to ensure type safety. To implement this behavior without cloning every \nmodule, we adopt a novel two-stage module compilation strategy. First, each export is replaced with an \nindirection that chooses whether to ref\u00aderence the contracted or plain version of the exported binding. \nSecond, the compilation of typed modules sets a .ag inside the #%module-begin transformer before expansion \nof the module s contents; the exported indirections choose which version to ref\u00aderence based on this \n.ag. Since each module is compiled with a fresh state, this .ag is only set during the compilation of \ntyped modules untyped modules have no way to access it. Therefore, during the compilation of untyped \nmodules, the export indirections correctly choose the contract-protected version of bindings. The compilation \nof typed modules, in contrast, see the set version of the .ag and are able to use the uncontracted versions \nof bindings. Implementation Exported identi.ers are rewritten in the same stages as imported identi.ers. \nSince this rewriting occurs after typechecking, however, it is performed by the #%module-begin form, \njust as declarations are added to exports: (#%provide n) ; An export of n ; ==> (is rewritten to) # (begin \n... the declaration from section 5 ... ; Stage 1 (define defensive-n (contract #,(type->contract (typecheck \n# n)) n typed-module untyped-module)) ; Stage 2 (define-syntax (export-n stx) (if (unbox typed-context?) \n# n # defensive-n)) ; Stage 3 (provide (rename-out [export-n n]))) First, we de.ne a defensive version \nof the identi.er n, which uses a contract generated from the type of n. Second, we de\u00ad.ne an export-n \nversion of the identi.er n, which selects be\u00adtween n and defensive-n depenending on the value of typed\u00adcontext?. \nThird, we provide export-n under the name n, making the indirection transparent to clients of the typed \nmodule. The second part comes in the de.nition of the language: (define-syntax (#%module-begin stx) (set-box! \ntyped-context? #t) ... check and transform stx, as in .gure 2 ... ... rewrite provides, as above ...) \n The initial .ag setting means that the expansion of the module, and in particular the expansion of the \nindirections imported from other typed modules, see the typed-context? .ag as set to #t. Finally, because \nthe typed-context? .ag is accessible only from the implementation of the simple-type language, it is \nsimple to verify that the .ag is only set to #t in the #%module\u00adbegin form. Therefore, the implementation \ncan rely on this .ag as an indicator, without the possibility that untyped code might be able to deceive \nthe typechecker.  6.3 Scaling to Typed Racket The full implementation of module integration in Typed \nRacket follows the strategy outlined. The major complication is the export of macros and other static \ninformation from typed modules. Since macros from typed modules can refer to internal identi.ers not \nprotected by contracts, expanding such macros in untyped modules could potentially allow untyped modules \nto violate the invariants of typed modules. Therefore, Typed Racket currently prevents macros de.ned \nin typed modules from escaping into untyped modules. 7. Optimization via Rewriting Source-to-source transformations \ncan express large classes of opti\u00admizations, which makes it possible to apply them in the front end of \nthe compiler. With the right language extension mechanisms, we can express these transformations as libraries \nand use them to build competitive optimizers. 7.1 Compiler architecture Since Typed Racket is built as \na language extension of Racket and the Racket compiler is for an untyped language, Typed Racket has to \napply typed optimizations before handing programs to the Racket compiler. In contrast, compilers for \ntyped languages can keep track of types across all phases in the compiler and use them to guide optimizations. \nHence, Typed Racket features a type\u00addriven optimization pass after typechecking. This optimization pass \ntransforms the code that the front end of Typed Racket generates, using the validated and still accessible \ntype information. To support realistic optimizers as libraries, the host language must provide ways for \nlanguage extensions to communicate their results to the compiler s backend. As part of its language exten\u00adsion \nfeatures, Racket exposes unsafe type-specialized primitives.4 For instance, the unsafe-fl+ primitive \nadds two .oating-point numbers, but has unde.ned behavior when applied to anything else. These type-specialized \nprimitives are more ef.cient than their generic equivalents; not only do these primitives avoid the run\u00adtime \ndispatch of generic operations, they also serve as signals to the Racket code generator to guide its \nunboxing optimizations. Typed Racket s optimizer generates code that uses these prim\u00aditives. In .gure \n5, we show an excerpt from the optimizer that specializes .oating-point operations using rewrite rules; \nthe opti\u00admizer rewrites uses of generic arithmetic operations on .oating\u00adpoint numbers to specialized \noperations. 7.2 Scaling to Typed Racket Typed Racket uses the same techniques as the simple optimizer \npre\u00adsented here, but applies a wider range of optimizations. It supports a number of .oating-point specialization \ntransformations, eliminates tag-checking made redundant by the typechecker and performs ar\u00adity raising \non functions with complex number arguments.  7.3 Results Untyped Racket is already competitive among \noptimizing Scheme compilers. The addition of a type-driven optimizer makes a notice\u00adable difference and \nmakes it an even more serious contender. We show the impact of our optimizer on micro-benchmarks taken \nfrom the Gabriel (1985) and Larceny (Clinger and Hansen 1994) benchmark suites and the Computer Language \nBenchmark Game,5 as well as on large benchmarks: the pseudoknot (Hartel 4 Initially these primitives \nwere provided because some programmers wanted to hand-optimize code. 5 http://shootout.alioth.debian.org \n  (define (optimize t) (syntax-parse t [(#%plain-app op:id e1:expr e2:expr) (with-syntax ([new-op (if \n(and (equal? FloatT (type-of # e1)) (equal? FloatT (type-of # e2))) (cond [(free-identifier=? # op # \n+) # unsafe-fl+] [(free-identifier=? # op # -) # unsafe-fl-] [else # op]) # op)]) # (#%plain-app new-op \n#,(optimize # e1) #,(optimize # e2)))] ... structurally recur on the other forms ...)) Figure 5: The \nOptimizer Figure 6: Results on the Gabriel and Larceny benchmarks (smaller is better) Figure 7: Results \non the Computer Language Benchmark Game (smaller is better)  Figure 8: Results on pseudoknot (smaller \nis better)  et al. 1996) .oating-point benchmark, a ray tracer, an industrial strength FFT and the implementation \nof two purely functional data structures (Prashanth and Tobin-Hochstadt 2010). Each benchmark comes in \ntwo versions: the original version and a translation to Typed Racket. The typed versions have type annotations \nand extra predicates where required to typecheck the program. The typed version runs in Racket 5.0.2 \nusing our type-driven op\u00adtimizer and the untyped version in Racket 5.0.2, Gambit 4.6.0 (Fee\u00adley and Miller \n1990), Larceny 0.97 (Clinger and Hansen 1994) and Bigloo 3.5a (Serrano and Weis 1995), using the highest \nsafe optimization settings in each case. Benchmarks from the Com\u00adputer Language Benchmarks Game and our \nsample applications use Racket-speci.c features and cannot be measured with other Scheme compilers. Bigloo \nfails to compile the cpstack and pseu\u00addoknot benchmarks. All our results are the average of 20 runs on \na Dell Optiplex GX270 running GNU/Linux with 1GB of memory. These benchmarks fall into two categories: \nbenchmarks where Racket is already competitive with other well-known optimizing Scheme compilers, and \nbenchmarks where Racket does not per\u00adform as well. In some cases where Racket is slower than the compe\u00adtition, \nTyped Racket s optimizer helps bridge the gap. For instance, it is responsible for a 33% speedup on the \nfft benchmark and a 123% speedup on pseudoknot. The large applications bene.t even more from our optimizer \nthan the microbenchmarks. The results presented in this section demonstrate (a) that the Racket compiler \nand runtime are already competitive with leading compilers for Scheme, and (b) that Typed Racket s optimizer, \nwrit\u00adten entirely as a library, nonetheless provides noticeable speedups on both widely-used benchmarks \nand existing Racket programs. Figure 9: Results on large benchmarks (smaller is better)  8. Related \nWork While many individual aspects of our extensible language have long histories, some are novel and \nso is the combination as a whole. In this section, we sketch the history of each of these aspects. 8.1 \nExtensible Static Semantics Macros have a long history in Lisp and Scheme (Kohlbecker 1986; Steele Jr. \nand Gabriel 1993; Dybvig et al. 1992). Several aspects of Racket s macro system improve on prior techniques. \nFirst, the #%module-begin macro offers control over the en\u00adtire module. Many Lisp programmers have approximated \nit with explicit wrappers. Second, many Lisp systems provide analogues of local-expand under the names \nexpand or macroex\u00adpand. These features are more limited, however. Most importantly, they do not compose \nwith other macros (Culpepper and Felleisen 2010). Third, Chez Scheme (Dybvig 2009) provides a define\u00adproperty \nform, which simulates identi.er-keyed tables for the same purposes described in section 5. Chez Scheme \ns form is less general than Racket s: while define-property would support Typed Racket s maintenance \nof type environments, it would not work for the interoperability mechanism described in section 6.2. \nFisher and Shivers (2006; 2008) present a system for handling analysis of programs written in an extensible \nlanguage. Speci.\u00adcally, their system can implement static analyses, such as type sys\u00adtems, on top of \nextensible languages, without requiring the anal\u00adysis to know about every possible language extension. \nThe sys\u00adtem employs a dispatch mechanism so that each extension can an\u00adswer the static analysis question \nabout its own use. This approach is extensible and expressive, but inherently unsound, because lan\u00adguage \nextensions may provide analysis results that disagree with their runtime behavior. Our solution using \nlocal-expand relies on the inference of high-level properties from core forms and re\u00adspects soundness, \nthough it imposes limits on some macro uses in language extensions. In the functional-logic programming \nworld, the Ciao Prolog system (Hermenegildo et al. 2008) comes close to Racket. It also al\u00adlows programmers \nto annotate their programs with new static asser\u00adtions and to control when these assertions are checked. \nThis strat\u00adegy accommodates customizable static semantics and enabling new optimizations. In contrast \nto our system, Ciao builds the assertion language into the compiler, which furthers tight integration \nwith its existing static analyzers and compiler, but prevents users from developing truly new semantics \nand whole program checking. The ArBB and Rapidmind (Ghuloum et al. 2010) tools take the approach of embedding \nlanguages for novel execution models within C++. In contrast with the approach we present, their embed\u00adding \ndemands the use of the C++ type system and necessitates the creation of ad-hoc replacements for fundamental \nlanguage features such as if and for statements, thus limiting linguistic reuse. Ad\u00additionally, because \nindividual constructs see only a portion of the program, the scope for an analysis is necessarily local, \nin contrast to Typed Racket which can check an entire module. 8.2 Extensible Compilers Since compilers \nare valuable and complex pieces of software, many projects have designed extensible compilers. Extensibility \nmeans that programmers can add front-ends, backends, optimizations, analyses, or other plug-ins (Bravenboer \nand Visser 2004; Cox et al. 2008; Nystrom et al. 2003; Bachrach and Playford 2001). All of these systems \ndiffer signi.cantly from our implementation of a language as a library. First, they require interoperation \nat the level of the compiler rather than the language. Language extensions in Racket are implemented \nas Racket programs, operate on Racket programs, and produce Racket programs; they operate without any \nreliance on the details of the underlying compiler or runtime. This higher level of abstraction means \nthat the compiler can be mod\u00adi.ed without breaking existing extensions, and extensions need not depend \non the specialized representations and analyses in the compiler implementation. Second, extensible compilers \nare not libraries in the same sense as ordinary libraries. Instead, they are plug-ins to a different \napplication the compiler, which may be written in a different lan\u00adguage using a different architecture. \nThis means compiler plugins cannot take advantage of the same library distribution mechanisms, debugging \nmechanisms, tools, and the rest of the software infras\u00adtructure around the language. This difference \nmakes them both more dif.cult to develop and to use for programmers, thus limiting language experimentation. \n 8.3 Rewriting-based Optimization The speci.c optimization techniques described in section 7 are not \nnew to Typed Racket. Kelsey (1989) presents a transformational compiler that expresses optimizations \nas rewritings from the source language, an extended continuation-passing style lambda calculus, to itself. \nThese transformations are encoded inside the compiler, however, which places them off-limits for programmers. \nThe Glasgow Haskell Compiler (Peyton Jones 1996) also ex\u00adpresses optimizations as rewrite rules. Unlike \nKelsey s work, GHC makes it possible for programmers to supplement these rules with their own. To preserve \nsafety, the compiler enforces that all rewrite rules must preserve types; that is the result of applying \na rewrite rule must be of the same type as the original term. In contrast to Racket, the GHC rewrite \nrules are expressed in a limited domain\u00adspeci.c language. It would be impossible to implement the arity-raising \ntransfor\u00admation mentioned in section 7.2 in the GHC rewriting framework; such optimizations are instead \nbuilt in to GHC. 9. Conclusion In Growing a Language, Steele writes if we grow the language in these \nfew ways, then we will not need to grow it in a hundred other ways; the users can take on the rest of \nthe task. In this paper, we have explained how Racket s small number of language extensibil\u00adity mechanisms \nempower the application programmer to grow even a highly sophisticated language. While these mechanisms \ncontinue the long tradition of Lisp and Scheme macros, they also go far beyond macros. Most importantly, \nRacket programmers can use #%module-begin to create libraries that process modules in a context-sensitive \nmanner without interfering with macros. Fur\u00adther, the syntax system can use attributed ASTs to communicate \nout-of-band information. As a result, programmers can interpolate context-sensitive analyses and source-based \noptimizations where the latter may exploit the result of the former. One running example, Typed Racket, \nillustrates the range of Racket s extensibility mechanism. Speci.cally, the implementation of Typed Racket \ncovers almost all aspects of language experimenta\u00adtion, from the front end to the back end. As our benchmarks \ndemon\u00adstrate, the current backend of Typed Racket delivers competitive performance. What reduces the \nperformance from highly compet\u00aditive to just competitive is the lack of Racket APIs for process\u00ading intermediate \nrepresentations and/or JIT compiler information. Until such APIs are available, compiler optimizations \nfor language extensions remain limited to source-level transformations. Acknowledgments Robby Findler \nand Shriram Krishnamurthi have contributed to this design over many years. Numerous members of the Northeastern \nPRL provided feedback on earlier drafts of this paper. Mitch Wand suggested the title.  Bibliography \nJonathan Bachrach and Keith Playford. The Java syntactic extender. In Proc. Conf. Object-Oriented Programming \nSystems, Languages, and Applications, pp. 31 42, 2001. Eli Barzilay and John Clements. Laziness Without \nAll the Hard Work. In Proc. Works. Functional and Declarative Programming in Education, pp. 9 13, 2005. \nMartin Bravenboer and Eelco Visser. Concrete syntax for objects: domain\u00adspeci.c language embedding and \nassimilation without restrictions. In Proc. Conf. Object-Oriented Programming Systems, Languages, and \nApplications, pp. 365 383, 2004. John Clements, Matthias Felleisen, Robert Bruce Findler, Matthew Flatt, \nand Shriram Krishnamurthi. Fostering Little Languages. Dr. Dobb s Journal, pp. 16 24, 2004. William D. \nClinger and Lars Thomas Hansen. Lambda, the ultimate label or a simple optimizing compiler for Scheme. \nIn Proc. Conf. on LISP and functional programming, pp. 128 139, 1994. Russ Cox, Tom Bergan, Austin T. \nClements, Frans Kaashoek, and Eddie Kohler. Xoc, an extension-oriented compiler for systems programming. \nIn Proc. Conf. Architectural Support for Programming Languages and Operating Systems, pp. 244 254, 2008. \nRyan Culpepper and Matthias Felleisen. Debugging hygienic macros. Sci\u00adence of Computer Programming 75(7), \npp. 496 515, 2010. Ryan Culpepper and Matthias Felleisen. Fortifying macros. In Proc. Inter\u00adnational \nConf. on Functional Programming, pp. 235 246, 2010. Ryan Culpepper, Scott Owens, and Matthew Flatt. Syntactic \nabstraction in component interfaces. In Proc. Conf. Generative Programming and Component Engineering, \npp. 373 388, 2005. Ryan Culpepper, Sam Tobin-Hochstadt, and Matthias Felleisen. Advanced Macrology and \nthe Implementation of Typed Scheme. In Proc. Scheme and Functional Programming, 2007. R. Kent Dybvig. \nChez Scheme Version 8 User s Guide. Cadence Research Systems, 2009. R. Kent Dybvig, Robert Hieb, and \nCarl Bruggeman. Syntactic abstraction in Scheme. Lisp and Symbolic Computation 5(4), pp. 295 326, 1992. \nMarc Feeley and James S. Miller. A parallel virtual machine for ef.cient Scheme compilation. In Proc. \nConf. on LISP and Functional Program\u00adming, pp. 119 130, 1990. Matthias Felleisen, Robert Bruce Findler, \nMatthew Flatt, and Shriram Kr\u00adishnamurthi. Building Little Languages With Macros. Dr. Dobb s Jour\u00adnal, \npp. 45 49, 2004. David Fisher and Olin Shivers. Static semantics for syntax objects. In Proc. International \nConf. on Functional Programming, pp. 111 121, 2006. David Fisher and Olin Shivers. Building language \ntowers with Ziggurat. J. of Functional Programming 18(5-6), pp. 707 780, 2008. Matthew Flatt. Composable \nand compilable macros: you want it when? In Proc. International Conf. on Functional Programming, pp. \n72 83, 2002. Matthew Flatt, Eli Barzilay, and Robert Bruce Findler. Scribble: closing the book on ad-hoc \ndocumentation tools. In Proc. International Conf. on Functional Programming, pp. 109 120, 2009. Matthew \nFlatt and Matthias Felleisen. Units: Cool modules for HOT lan\u00adguages. In Proc. Conf. on Programming Language \nDesign and Imple\u00admentation, pp. 236 248, 1998. Matthew Flatt, Robert Bruce Findler, and Matthias Felleisen. \nScheme with classes, mixins, and traits. In Proc. Asian Symp. on Programming Lan\u00adguages and Systems, \npp. 270 289, 2006. Matthew Flatt and PLT. Reference: Racket. PLT Inc., PLT-TR-2010-1, 2010. http://racket-lang.org/tr1/ \n Richard P. Gabriel. Performance and Evaluation of LISP Systems. MIT Press, 1985. Anwar Ghuloum, Amanda \nSharp, Noah Clemons, Stefanus Du Toit, Rama Malladi, Mukesh Gangadhar, Michael McCool, and Hans Pabst. \nArray Building Blocks: A Flexible Parallel Programming Model for Multicore and Many-Core Architectures. \nDr. Dobb s Journal, 2010. Pieter H. Hartel, Marc Feeley, Martin Alt, Lennart Augustsson, Peter Bau\u00admann, \nMarcel Beemster, Emmanuel Chailloux, Christine H. Flood, Wolfgang Grieskamp, John H. G. van Groningen, \nKevin Hammond, Bogumil Hausman, Melody Y. Ivory, Richard E. Jones, Jasper Kam\u00adperman, Peter Lee, Xavier \nLeroy, Rafael D. Lins, Sandra Loose\u00admore, Niklas R\u00a8ojemo, Manuel Serrano, Jean-Pierre Talpin, Jon Thack\u00adray, \nStephen Thomas, Pum Walters, Pierre Weis, and E.P. Wentworth. Benchmarking implementations of functional \nlanguages with pseudo\u00adknot a .oat-intensive benchmark. J. of Functional Programming 6(4), pp. 621 655, \n1996. Manuel V. Hermenegildo, Francisco Bueno, Manuel Carro, Pedro Lopez, Jos\u00b4e F. Morales, and German \nPuebla. An overview of the Ciao multi\u00adparadigm language and program development environment and its de\u00adsign \nphilosophy. In Concurrency, Graphs and Models. Springer-Verlag, pp. 209 237, 2008. Richard Andrew Kelsey. \nCompilation by Program Transformation. PhD dissertation, Yale University, 1989. Eugene Kohlbecker. Syntactic \nExtensions in the Programming Language Lisp. PhD dissertation, Indiana University, 1986. Shriram Krishnamurthi. \nLinguistic Reuse. PhD dissertation, Rice Univer\u00adsity, 2001. Shriram Krishnamurthi, Peter Walton Hopkins, \nJay McCarthy, Paul T. Graunke, Greg Pettyjohn, and Matthias Felleisen. Implementation and use of the \nPLT Scheme web server. Higher-Order and Symbolic Com\u00adputing 20(4), pp. 431 460, 2007. Simon Marlow. Haskell \n2010 Language Report. 2010. Robin Milner, Mads Tofte, Robert Harper, and David MacQueen. The De.nition \nof Standard ML, Revised Edition. MIT Press, 1997. Nathaniel Nystrom, Michael Clarkson, and Andrew Myers. \nPolyglot: an extensible compiler framework for Java. In Proc. International Conf. on Compiler Construction, \npp. 138 152, 2003. Simon L Peyton Jones. Compiling Haskell by program transformation a report from the \ntrenches. In Proc. European Symp. on Programming, pp. 18 44, 1996. Hari Prashanth K R and Sam Tobin-Hochstadt. \nFunctional data structures for Typed Racket. In Proc. Works. Scheme and Functional Program\u00adming, pp. \n1 7, 2010. Manuel Serrano and Pierre Weis. Bigloo: a portable and optimizing com\u00adpiler for strict functional \nlanguages. In Proc. Static Analysis Symp., pp. 366 381, 1995. Michael Sperber, Matthew Flatt, Anton Van \nStraaten, R. Kent Dybvig, Robert Bruce Findler, and Jacob Matthews. Revised6 report on the algorithmic \nlanguage Scheme. J. of Functional Programming 19(S1), pp. 1 301, 2009. Guy L. Steele Jr. Common Lisp: \nThe Language. Second edition. Digital Press, 1994. Guy L. Steele Jr. Growing a language, Keynote at OOPSLA \n1998. Higher-Order and Symbolic Computation 12(3), pp. 221 236, 1999. Guy L. Steele Jr. and Richard P. \nGabriel. The evolution of Lisp. In Proc. Conf. on History of Programming Languages, pp. 231 270, 1993. \nT. Stephen Strickland, Sam Tobin-Hochstadt, and Matthias Felleisen. Prac\u00adtical Variable-Arity Polymorphism. \nIn Proc. European Symp. on Pro\u00adgramming, 2009. Sam Tobin-Hochstadt and Matthias Felleisen. Interlanguage \nrefactoring: from scripts to programs. In Proc. Dynamic Languages Symp., pp. 964 974, 2006. Sam Tobin-Hochstadt \nand Matthias Felleisen. The design and implemen\u00adtation of Typed Scheme. In Proc. Symp. on Principles \nof Programming Languages, pp. 395 406, 2008. Sam Tobin-Hochstadt and Matthias Felleisen. Logical types \nfor untyped languages. In Proc. International Conf. on Functional Programming, pp. 117 128, 2010.  \n   \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Programming language design benefits from constructs for extending the syntax and semantics of a host language. While C's string-based macros empower programmers to introduce notational shorthands, the parser-level macros of Lisp encourage experimentation with domain-specific languages. The Scheme programming language improves on Lisp with macros that respect lexical scope.</p> <p> The design of Racket---a descendant of Scheme---goes even further with the introduction of a full-fledged interface to the static semantics of the language. A Racket extension programmer can thus add constructs that are indistinguishable from \"native\" notation, large and complex embedded domain-specific languages, and even optimizing transformations for the compiler backend. This power to experiment with language design has been used to create a series of sub-languages for programming with first-class classes and modules, numerous languages for implementing the Racket system, and the creation of a complete and fully integrated typed sister language to Racket's untyped base language.</p> <p>This paper explains Racket's language extension API via an implementation of a small typed sister language. The new language provides a rich type system that accommodates the idioms of untyped Racket. Furthermore, modules in this typed language can safely exchange values with untyped modules. Last but not least, the implementation includes a type-based optimizer that achieves promising speedups. Although these extensions are complex, their Racket implementation is just a library, like any other library, requiring no changes to the Racket implementation.</p>", "authors": [{"name": "Sam Tobin-Hochstadt", "author_profile_id": "81319502825", "affiliation": "Northeastern University, Boston, MA, USA", "person_id": "P2690509", "email_address": "samth@ccs.neu.edu", "orcid_id": ""}, {"name": "Vincent St-Amour", "author_profile_id": "81485646095", "affiliation": "Northeastern University, Boston, MA, USA", "person_id": "P2690510", "email_address": "stamourv@ccs.neu.edu", "orcid_id": ""}, {"name": "Ryan Culpepper", "author_profile_id": "81337488807", "affiliation": "University of Utah, Salt Lake City, UT, USA", "person_id": "P2690511", "email_address": "ryan@cs.utah.edu", "orcid_id": ""}, {"name": "Matthew Flatt", "author_profile_id": "81100490544", "affiliation": "University of Utah, Salt Lake City, UT, USA", "person_id": "P2690512", "email_address": "mflatt@cs.utah.edu", "orcid_id": ""}, {"name": "Matthias Felleisen", "author_profile_id": "81100323458", "affiliation": "Northeastern University, Boston, MA, USA", "person_id": "P2690513", "email_address": "matthias@ccs.neu.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993514", "year": "2011", "article_id": "1993514", "conference": "PLDI", "title": "Languages as libraries", "url": "http://dl.acm.org/citation.cfm?id=1993514"}