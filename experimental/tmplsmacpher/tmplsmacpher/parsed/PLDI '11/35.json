{"article_publication_date": "06-04-2011", "fulltext": "\n Garbage Collection for Monitoring Parametric Properties * Dongyun Jin Patrick O Neil Meredith Dennis \nGrif.th Grigore Ros\u00b8u Department of Computer Science, University of Illinois at Urbana-Champaign {djin3, \npmeredit, dgri.3, grosu}@cs.illinois.edu Abstract Parametric properties are behavioral properties over \nprogram events that depend on one or more parameters. Parameters are bound to concrete data or objects \nat runtime, which makes parametric properties particularly suitable for stating multi-object relationships \nor protocols. Monitoring parametric properties independently of the employed formalism involves slicing \ntraces with respect to parameter instances and sending these slices to appropriate non\u00adparametric monitor \ninstances. The number of such instances is theoretically unbounded and tends to be enormous in practice, \nto an extent that how to ef.ciently manage monitor instances has become one of the most challenging problems \nin runtime veri.cation. The previous formalism-independent approach was only able to do the obvious, \nnamely to garbage collect monitor instances when all bound parameter objects were garbage collected. \nThis led to pathological behaviors where unnecessary monitor instances were kept for the entire length \nof a program. This paper proposes a new approach to garbage collecting monitor instances. Unnecessary \nmonitor instances are collected lazily to avoid creating undue overhead. This lazy collection, along \nwith some careful engineering, has resulted in RV, the most ef.cient parametric monitoring system to \ndate. Our evaluation shows that the average overhead of RV in the DaCapo benchmark is 15%, which is two \ntimes lower than that of JavaMOP and orders of magnitude lower than that of Tracematches. Categories \nand Subject Descriptors D.2.4 [Software Engineer\u00ading]: Assertion checkers, Class invariants, Formal methods, \nReliabil\u00adity; D.2.5 [Software Engineering]: Debugging aids, Error handling and recovery, Monitors; D.3.2 \n[Programming Languages]: Object\u00adoriented languages; D.3.4 [Programming Languages]: Code gener\u00adation, \nMemory management General Terms Languages, Performance, Reliability, Veri.cation Keywords runtime veri.cation, \nruntime monitoring, testing, de\u00adbugging, aspect-oriented programming, garbage collection * Supported \nin part by NSF grants CCF-0916893, CNS-0720512, and CCF\u00ad0448501, by NASA contract NNL08AA23C, and by \nan NSA grant, a UIUC Campus Research Board Award, and a Samsung SAIT grant. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 11, June 4 8, 2011, San Jose, California, \nUSA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. . . $10.00 Figure 1. Typestate description \nfor HASNEXT 1. Introduction Monitoring is an effective technique for ensuring software reliability. The \nwell known concept of typestate [31] property can be enforced by using monitoring techniques. Typestates \nre.ne the notion of type by stating not only what operations are allowed by a particular object, but \nalso what operations are allowed in what contexts. Figure 1 shows the typestate description for HASNEXT. \nThe HASNEXT typestate says that it is invalid to call the next() method on an Iterator object when there \nare no more elements in the underlying Collection, i.e., when hasnext() returns false, or when it is \nunknown if there are more elements in the Collection, i.e., hasnext() is not called. From the unknown \nstate, it is always an error to call the next() method because such an operation could be unsafe. If \nhasnext() is called and returns true, it is safe to call next(),sothe typestate enters the more state. \nIf, however, the hasnext() method returns false, there are no more elements, and the typestate enters \nthe none state. In the more and none states, calling the hasnext() method provides no new information. \nIt is safe to call next() from the more state, but it becomes unknown if more elements exist, so the \ntypestate reenters the initial unknown state. Finally, calling next() from the none state results in \nan error. Typestate Property Example-It is straightforward to encode this, and all typestate properties, \nas particular (one-parameter) para\u00admetric properties. Figure 2 shows this property using the RV system \npresented in this paper. For demonstration purposes, we specify the same property using two different \nformalisms. The .rst formalism is a direct translation of the typestate diagram using the .nite state \nmachine (FSM) capabilities of RV, and is denoted by the fsm key\u00adword. Each state in the typestate is \nwritten as a name followed by its transitions (i.e., monitored events) in brackets. The .rst state in \nthe FSM description (unknown) is always considered to be the initial state of a .nite state machine in \nthe RV system. The second formal\u00adism is linear temporal logic (LTL), pre.xed by the keyword ltl. The \n HasNext(Iterator i) {event hasnexttrue after(Iterator i) returning(boolean b) : call(* Iterator.hasNext()) \n&#38;&#38; target(i) &#38;&#38; condition(b) {}event hasnextfalse after(Iterator i) returning(boolean \nb) : call(* Iterator.hasNext()) &#38;&#38; target(i) &#38;&#38; condition(!b) {}event next before(Iterator \ni) : call(* Iterator.next()) &#38;&#38; target(i) {} fsm : unknown [ hasnexttrue -> more hasnextfalse \n-> none next -> error ] more [ hasnexttrue -> more next -> unknown ] none [ hasnextfalse -> none next \n-> error ] error [ ] @error { System.out.println(\"improper Iterator use found!\"); } ltl: [](next => \n(*)hasnexttrue) @violation { System.out.println(\"improper Iterator use found!\"); }} Figure 2. HASNEXT \nproperty in RV using FSM and LTL LTL formula here states that any call to next() must always ([]) be \nimmediately preceded ((*)) by a call to hasnext() that returned true. The RV system supports multiple \nlogical formalisms, and as this example demonstrates, some formalisms can lead to much more succinct \nand easy to understand speci.cations. The monitored events are pre.xed by the keyword event and are encoded \nusing slightly extended AspectJ [26] pointcuts. One such extension is the condition pointcut, which is \nsimilar to the if pointcut: it ensures that the given pointcut is only applied if its condition is true, \nbut unlike the if pointcut, it is able to refer to variables bound by returning advice. Thus, the hasnexttrue \nevent is only generated if hasnext() returns true, and the hasnextfalse is only generated if hasnext \nreturns false. The per Iterator nature of the HASNEXT typestate is encoded by using one Iterator parameter. \nFor each property, the code block following it is referred to as a handler. The handler is executed when \na condition of its correspond\u00ading speci.cation is met. For instance, the FSM handler in Figure 2 is executed \nwhen the machine enters the error state, while the LTL handler is executed when the LTL formula is violated. \nHandlers may contain any arbitrary Java code, but here they simply print messages. Such behavior is useful \nfor debugging and testing purposes. Parametric properties properly generalize typestates, as we shall \nsee, by allowing more parameters. This allows us to specify not only properties about a given object \nsuch as the HASNEXT example, but also properties that specify relationships between objects. General \nParametric Property Examples-Figure 3 shows a property for the unsafe use of Collection and Iterator.The \nproperty .ags it as an error if an Iterator is created, its underlying Collection is modi.ed, and then \nthe Iterator is used again. Here we use the extended regular expression (ERE) capabilities of the RV \nsystem, as speci.ed by the ere keyword. The occurrence of update * at the beginning of the pattern allows \nany number of updates before the .rst create event, in which the Iterator is .rst created. We wish to \ncatch this behavior because Java Collections do not allow concurrent modi.cation. The JVM usually throws \na runtime exception when this occurs, but the exception is not guaranteed to be thrown in a multi-threaded \nenvironment. UnsafeIter(Collection c, Iterator i) { event create after(Collection c) returning(Iterator \ni) : call(Iterator Collection.iterator()) &#38;&#38; target(c) {} event update after(Collection c) : \n(call(* Collection.remove*(..)) || call(* Collection.add*(..)) || call(* Collection.clear(..))) &#38;&#38; \ntarget(c){} event next before(Iterator i) : call(* Iterator.next()) &#38;&#38; target(i){} ere : update* \ncreate next* update+ next @match {System.out.println(\"improper Concurrent Modification found!\"); }} Figure \n3. UNSAFEITER property in RV using the ERE plugin SafeLock(Lock l, Thread t){event acquire before(Lock \nl, Thread t): call(* Lock.acquire()) &#38;&#38; target(l) &#38;&#38; thread(t) {}event release before(Lock \nl, Thread t): call(* Lock.release()) &#38;&#38; target(l) &#38;&#38; thread(t) {}event begin before(Thread \nt) : execution(* *.*(..)) &#38;&#38; thread(t) &#38;&#38; !within(Lock+) {}event end after(Thread t) \n: execution(* *.*(..)) &#38;&#38; thread(t) &#38;&#38; !within(Lock+) {} cfg : S -> S begin S end | S \nacquire S release | epsilon @fail { System.out.println(\"improper Lock use found!\"); }} Figure 4. SAFELOCK \nproperty in RV using the CFG plugin Figure 4 shows a speci.cation for the safe use of reentrant locks, \ncalled SAFELOCK, stating that the number of calls of an acquire() in a given method is balanced with \nthe number of calls to release(). This property is parametric both in the Lock in question and in the \nThread, and is speci.ed using the context-free grammar (CFG) plugin of the RV system. The events begin \nand end refer to the beginning and end of every method. The thread pointcut is also an RV extension of \nstandard AspectJ pointcuts that allows for binding the current Thread of execution in the monitored program. \nThe pattern for the speci.cation, pre.xed by the keyword cfg, has S for its start symbol. The .rst symbol \nseen is always assumed the start symbol. The CFG pattern requires that begin and end events are matched \nand properly nested with acquire and release events, which must also be matched. Monitoring parametric \nproperties in their full generality is a complex task. Several parametric monitoring systems such as \nEagle [20], J-Lo [11, 12, 30], Tracematches [4, 8], JavaMOP [16, 17], PTQL [23], PQL [27], QVM [5], SpoX \n[24], PoET [22], and RuleR [9] have been proposed in recent years. In parametric moni\u00adtoring systems, \nthe parameters are dynamically bound to objects at runtime, thus resulting in a potentially unlimited \nnumber of monitor instances, one per combination of parameter bindings. The main challenge underlying \nthe monitoring of parametric properties is therefore how to effectively manage these monitor instances, \nin particular how to ef.ciently retrieve all the monitor instances inter\u00adested in an event when it takes \nplace, and how to ef.ciently garbage collect monitor instances which have become unnecessary. Earlier \nattempts such as Tracematches [4, 8] are careful to manage their memory, but hardwire their property \nspeci.cation formalism (regular expression only). JavaMOP [16, 17] is generic in speci.cation formalisms, \nbut, however, it has memory leaks. Due to JavaMOP s creation of separate monitor instances in order to \nhandle each separate parameters instantiation, recognizing and removing unnecessary monitor instances \nis quite challenging. JavaMOP is only able to collect a monitor instance when all the bound parameters \nare garbage collected, which ensures that no event can happen to the corresponding monitor instance. \nThe problem with this method of garbage collection can be clearly seen in the UNSAFEITER property from \nFigure 3. Because it is the next event at the end of the pattern that actually causes the error, there \nis no way to ever match the pattern if the Iterator bound to a given monitor instance is garbage collected. \nHowever, JavaMOP is only able to collect the associated monitor instance if both the Collection and the \nIterator are garbage collected. Unfortunately, in most realistic programs, Collections have much longer \nlifetimes than the Iterators created from them. Because of this, JavaMOP would have large numbers of \nmonitor instances when monitoring most programs that could never possibly match the pattern because their \nbound Iterators had been collected. The RV system, which is presented in this paper, is a commercial \ngrade system developed by Runtime Veri.cation, Inc. RV is able to collect these monitor instances, as \nwell as many others that JavaMOP does not collect.  To collect monitor instances that JavaMOP is unable \nto collect, we implement, in RV, a means to prune unnecessary monitor instances based on a static analysis \nof the monitored property. The results of the static analysis, which we refer to as coenable sets, are \nused at runtime to determine when a monitor instance can no longer reach a triggering state, and can \nthus be garbage collected. For example, in UNSAFEITER (Figure 3), the coenable sets associated to event \nupdate consist of all those subsets of events which can potentially make update a relevant event for \na monitor for UNSAFEITER, that is, {next}, {next, update}, and {next, create, update}. Indeed, in any \nmatching trace containing update, the event update is followed by precisely all the events in one of \nthese subsets. Consider now a monitor M for UNSAFEITER corresponding to a particular parameters instance, \nsay c.c1 and i.i1, and suppose that an event update is just being dispatched to M. At this moment, M \nknows that it has a future only if all the events in at least one of the coenable sets of update are \npossible. In particular, if the Iterator i1 has already been garbage collected, then M will never match, \nsince each of the coenable sets of update contains a next, which can only be generated by i1. Thus, M \ncan safely terminate itself and be garbage collected in this situation. Removing unnecessary monitors \nis still an expensive task, and in the interest of making it as ef.cient as possible, a lazy collection \nmethod is used. This technique makes RV the most ef.cient parametric monitoring system to date, by a \nlarge margin (see Section 5). Our monitor garbage collection technique is orthogonal to other optimization \ntechniques for parametric monitoring. More precisely, our technique is aimed at improving the base performance \nof para\u00admetric monitoring by means of keeping the number of monitor instances low without relying on \n(expensive) knowledge about the source program or on minimizing the distance between events and their \nmonitors. Other optimizations can be applied on top of our garbage collection technique and thus start \nfrom this base per\u00adformance and improve it. For example, staged indexing (or de\u00adcentralized indexing), \nwhich has been proposed and implemented in [6, 8, 17], piggy-backs indexing trees onto parameter instances. \nThis reduces the cost of lookup due to better cache locality and fewer hash lookups. Also, signi.cant \nruntime overhead reductions have been achieved using program static analysis [14, 15, 21, 27], by removing \nunnecessary instrumentation. RV supports both staged indexing and program static analysis via the Clara \napproach [15]. Nevertheless, we deliberately disabled these orthogonal optimiza\u00adtions in our evaluation, \nto properly measure the effectiveness of the proposed garbage collection technique. Enabling these orthogonal \noptimizations would only hide the inef.ciency of base monitoring. We evaluate our RV garbage collection \ntechnique and compare it to those in JavaMOP and Tracematches in Section 5. We picked these two systems \nfor comparison because they are known for their ef.ciency (the best so far). The average overhead of \nRV in version 9.12 of the DaCapo [10] benchmark suite is 15%, even with no static or decentralized indexing \noptimizations, which is two times lower than 33% of JavaMOP and nine times lower than the 142% of Tracematches \ndisregarding those cases where Tracematches failed to terminate. Even the largest overhead of RV in two \nversions of DaCapo, from UNSAFEITER-bloat, is only 251%, while in JavaMOP, 7 cases show overhead higher \nthan 251%, and in Tracematches, 20 cases show higher overhead and 9 cases do not terminate. Outline The \nrest of this paper is as follows: Section 2 provides a brief overview of parametric monitoring; Section \n3 explains the theory of the coenables sets used for pruning unnecessary monitor instances, and shows \nsome examples; Section 4 discusses our data structures to ef.ciently garbage collect monitors by using \ncoenables sets, as well as how the coenable sets are actually used during the monitoring process; Section \n5 presents our experimental data; and Section 6 provides some concluding remarks. 2. Parametric Properties \nand Monitoring To explain the garbage collection of unnecessary monitor instances, we .rst introduce \nsome background theory on parametric monitoring. For consistency, we follow the notation and terminology \nrecently proposed by the JavaMOP authors in [18]. We begin by introducing the notions of event, trace, \nand property, .rst non-parametric and then parametric. Trace slicing is then de.ned as a reduct operation \nthat forgets events that are unrelated to the given parameter instance. De.nition 1. Let Ebe a .nite \nset of (non-parametric) events, called base events or simply events.An E-trace, or simply a (non\u00adparametric) \ntrace when Eis understood or not important, is any .nite sequence of events in E, that is, an element \nin E*. If event e .Eappears in trace w .E* then we write e .w. E is the empty trace. For UNSAFEITER in \nSection 1, the set of events Eis {create, update, next}, and a possible trace is create next update next \n. De.nition 2. An E-property P , or simply a (base or non-parametric) property, is a function P : E* \n.Cpartitioning the set of traces into (verdict) categories C. In general, Cmay be any set. Consider again \nUNSAFEITER. The match traces are those matching the pattern, e.g., create next update next . There are \nalso traces that have not matched yet, but may still match in the future, such as update create , which \nwe call ? (unknown) traces. Lastly, there are traces that may never match again, such as create update \nnext next , which we refer to as fail traces. Thus we pick Cto be the set {match, fail, ?}, and de.ne \nits property PUNSAFEITER : E* .Cas follows: PUNSAFEITER (w)= match if w is in the language of the UNSAFEITER \nere, PUNSAFEITER (w)= ? if w is a pre.x of a string in the language of the ere, and PUNSAFEITER (w)= \nfail otherwise. We next extend the above de.nitions to the parametric case. Let [A .B] be the set of \ntotal functions, and let [A-B] be the set of partial functions from A to B. De.nition 3. (Parametric \nevents and traces). Let X be a .nite set of parameters and let V be a set of corresponding parameter \nvalues. If Eis a set of base events like in De.nition 1, then let E(X)be the set of corresponding parametric \nevents e(.), where e is a base event in Eand . is a partial function in [X-V ]. Partial functions . in \n[X-V ] are called parameter instances.A parametric trace is a trace with events in E(X), that is, a word \nin E(X)* . A parametric trace for UNSAFEITER could be update(c.c1)update(c.c2)create(c.c1,i.i1)next(i.i1) \n. To simplify writing we often assume the parameter set implicit, as in the following, which is the same \ntrace: update(c1)update(c2)create(c1,i1)next(i1) . De.nition 4. Let X be a .nite set of parameters. If \nEis a set of base events like in De.nition 1, we de.ne a parametric event de.nition, or event de.nition \nfor short, as a function D: E.P(X), where Pis the power set, that maps each event e to a set of parameters \nD(e) that will be instantiated by e at runtime. Dis extended to E* as D(E)= \u00d8and D(ew)= D(e) .D(w), and \nto P(E) as D(\u00d8)= \u00d8and D({e}.E)= D(e) .D(E). Parametric event e(.)is D\u00adconsistent if dom(.)= D(e). Parametric \ntrace t is D-consistent if e(.)is D-consistent for each e(.).t.  The UNSAFEITER property contains the \nparametric event de.nition D(create)= {c, i}, D(update)= {c}, D(next)= {i}. It states that, for example, \nparameters c and i will be instantiated at runtime when a parametric event create(.)is received. For \na trace create update , D(create update) is {c, i}. De.nition 5. ., .' .[A-B] are compatible if for any \nx .dom(.) ndom(.'), .(x)= .'(x). We can combine compatible instances . and .', written . u.', as follows: \n. . .(x) if .(x) is de.ned (. u.')(x)= .'(x) if .'(x) is de.ned . unde.ned otherwise . u.' is also called \nthe least upper bound (lub) of . and .'. . is less informative than .', written . ..', if for any x .X,if \n.(x) is de.ned then .'(x) is also de.ned and .(x)= .'(x). uis extended to Pf ([X-V ]) in the natural \nway. Here Pf is the .nite power set. De.nition 6. (Trace slicing) Given parametric trace t .E(X)* and \n. in [X-V ], let the .-trace slice t I. .E* be the non\u00adparametric trace de.ned as: EI. = E (recall that \nE is the empty trace) { (tI.) e if .' .. (te(.'))I.= tI. otherwise The trace slice tI. .rst .lters out \nall the parametric events that are not relevant for the instance ., i.e., which contain instances of \nparameters that . does not care about, and then, for the remaining events relevant to ., it forgets the \nparameters so that the trace can be checked against base, non-parametric properties. It is crucial to \ndiscard events from parameter instances that are not relevant to . during the slicing, including those \nmore informative than .. Referring back to our parametric trace from above, the non\u00adparametric trace \nslice for parameter instance (c2)is update , that for (c1)is update , the slice for (c1,i1)is update \nnext , and the slice for (i1)is next . De.nition 7. Let X be a .nite set of parameters together with \ntheir corresponding parameter values V , like in De.nition 3, and let P : E* .Cbe a non-parametric property \nlike in De.nition 2. Then we de.ne the parametric property .X.P as the property (over traces E(X)* and \nverdict categories [[X-V ] .C]) .X.P : E(X)* .[[X-V ] .C] as (.X.P )(t)(.)= P (tI.) for each t .E(X)* \n, . .[X-V ]. A parametric property is therefore similar to a normal property, but one partitioning parametric \ntraces in E(X)* into verdict categories in [[X-V ] .C], that is, original (as in the non-parametric property) \nverdict categories indexed by parameter instances. This allows the parametric property to associate an \noriginal category for each parameter instance from [X-V ]. Next we de.ne monitors and parametric monitors. \nLike for parametric properties, which are just properties over parametric traces, parametric monitors \nare also just monitors, but for parametric events and with instance-indexed states and verdict categories. \nDe.nition 8. A monitor M is a tuple (S, E, C, i,s,.), where S is the set of states, Eis the set of input \nevents, Cis the set of verdict categories, i .S is the initial state, s : S \u00d7E.S is the transition function, \nand . : S .Cis the verdict function. The transition function is extended to handle traces, i.e., s : \nS \u00d7E* .S where Algorithm MONITOR(M =(S, E, C, i,s,.)) function main(t ) 1. ..;.(.) .i;T .{.} 2 foreach \ne(.)in order in t do 3: foreach .' .{.}uT do 4 ::.(.') .s(.(max{.'' .T |.'' ..'}),e) 5 ::G(.') ..(.(.')) \n 6: endfor 7:T .{.,.}uT 8 endfor Figure 5. Monitoring Algorithm s(s, E)= s and s(s, ew)= s(s(s, e),w). \nM =(S, E, C, i,s,.) is a monitor for property P : E* .Cif .(s(i,w)) = P (w) for each w .E*. Monitor M \nde.nes the property PM : E* .Cwith PM (w)= .(s(i,w)). Monitors M and M' are equivalent iff PM = PMI . \nWe next de.ne parametric monitors starting with a base monitor and a set of parameters: the corresponding \nparametric monitor can be thought of as a set of base monitors running in parallel, one for each parameter \ninstance. De.nition 9. Given parameters X with corresponding values V and monitor M =(S, E, C, i,s,.), \nthe parametric moni\u00adtor .X.M is the monitor ([[X-V ] .S], E(X), [[X-V ] .C],...i, .X.s, .X..), with .X.s \n:[[X-V ] .S] \u00d7E(X).[[X-V ] .S] .X.. :[[X-V ].S] .[[X-V ].C] de.ned as { s(d(.),e) if .' .. (.X.s)(d, \ne(.'))(.)= d(.) otherwise (.X..)(d)(.)= .(d(.)) for each d .[[X-V ] .S] and each ., .' .[X-V ]. Therefore, \na parametric monitor .X.M maintains a state d(.) of M for each parameter instance ., takes parametric \nevents as input, and outputs categories indexed by parameter instances (one category of M per instance). \nIntuitively, one can think of a parametric monitor as a collection of monitor instances . Each monitor \ninstance, which is indexed by a parameter instance, keeps track of the state of one trace slice. The \nrule for .X.s can be read as stating that when an event with parameter instance .' is evaluated, it updates \nthe state for all monitor instances more informative than the instance for .', and the instance for .' \nitself, leaving all other monitor instances untouched. The rule for .X.. simply states that . is applied \nto a state, as normal, but the state is found by looking up the state of the monitor instance for .. \nOne of the major results in [18] states that if M is a monitor for P , parametric monitor .X.M is a monitor \nfor the parametric property .X.P . Figure 5 shows the basic abstract monitoring algorithm for parametric \nproperties from [18]. Given parametric property .X.P and M a monitor for P , MONITOR(M ) yields a monitor \nthat is equivalent to .X.M , that is, a monitor for .X.P . The functions [[X-V ] .S] and [[X-V ] .C] \nof .X.M are encoded by MONITOR(M) as tables . and G with entries indexed by parameter instances in [X-V \n] and with contents states in S and verdict categories in C, respectively. Such tables will have .nite \nentries because each event e binds only a .nite number of parameters de.ned by D(e). The monitoring algorithm \n.rst clears ., which contains the monitor state for each parameter instance, then assigns i, the initial \nstate, to .(.). T, which contains all known parameter instances, is initialized to contain only the empty \npartial function ..For  each event e(.)that arrives during program execution (line 2), MONITOR(M) generates \nevery compatible parameter instance by combining . with all the previously known compatible parameter \ninstances (line 3). It then updates the state of every one of these compatible parameter instances (. \n') with the state, transitioned by event e, of the monitor instance corresponding to the largest parameter \ninstance less than or equal to . ' (line 4). At the same time we also calculate the verdict category \ncorresponding to that monitor instance and store it in table G (line 5). Rather than storing a whole \nslice as in De.nition 6, the knowledge of the slice is encoded in the state of the monitor instance for \n. '. After the algorithm completes, G contains the verdict category for each possible trace slice. An \nactual implementation is free to report a verdict category of interest (e.g., match or fail) as soon \nas it is discovered. 3. Coenable Sets When monitoring parametric properties, it is easy to generate a \nlarge number of monitor instances. For example, as seen in Section 5, the program bloat generates 1.9 \nmillion monitor instances when monitored for the UNSAFEITER property. After some time, some of these \nmonitor instances may become unnecessary, e.g., because they have no hope of reaching a verdict category \nin G. Indeed, as seen in Section 5, the RV garbage collection technique .ags 1.8 million of these monitor \ninstances as unnecessary. Chen et al. [19] proposed a formalism-independent method, called ENABLE sets \n, to avoid needlessly creating monitors that will never trigger. Here we show how a dual method can be \nderived to avoid needlessly retaining monitors that will never trigger. Computing the coenable sets is \nexpected to be a quick static operation in practice, because they are a function of the speci.cation \nto monitor (which is expected to be small) and not of the program (which is expected to be large). De.nition \n10. Given w .E* and e, e ' .w,welet e .w e ' denote that e ' occurs after e in w. Let COENABLEw(e)= {e \n' |e .w e ' }be the trace coenable set of e. Given property P : E* .Cand a subset of verdict categories \nof interest (or goal) G.C, the property coenable set is de.ned as the map COENABLEP,G : E.P(P(E)) where \nCOENABLEP,G(e)= {COENABLEw(e) |w .E* s.t. P (w) .G,e .w, COENABLEw(e)= \u00d8}for each e .E. Intuitively, \nif event e is encountered during monitoring, but none of the event sets of COENABLEP,G(e) are possible \nin the future, it is impossible to reach any verdict category in G, so a monitor for P observing e will \nnever trigger. We drop all \u00d8s from COENABLEP,G because they can cause monitor instances to be retained \nthat are unnecessary. An \u00d8in COENABLEP,G(e) means that the trace suf.x consisting of only the event e \ncan lead to a category in Gfor some trace pre.x. However, our interest is in the ability to reach Gagain \nin the future. If there is a trace suf.x that can lead to a state in Gfrom e, then its events will be \nadded to COENABLEP,G(e). If there is no trace suf.x that can lead back to a state in G, there is no reason \nto maintain the monitor instance after it has executed the proper handler due to the occurrence of e. \nFSM Example We de.ne .nite state machines in the spirit of De.nition 8. A .nite state machine is a tuple \n(S, E, C, i,s,.) where Eis a .nite alphabet, S is a .nite set of states, i .S is the initial state, s \n: S \u00d7E-S a partial transition function, Ca set of verdict categories, and . : S .Cthe verdict function. \nThe property monitored by an FSM classi.es a trace w into .(s(i,w)), where s is extended to strings in \nthe natural way, and fail if s(i,w) is unde.ned. We can .nd COENABLEP,G, for the property monitored by \nan FSM, by the least .xed point of the following equations. Recall that G.Cis the set of verdict categories \nof interest:  ' SEEABLE(s)= {{e}.T |T .SEEABLE(s )} s(s,e)=sI  ' COENABLEP,G(e)= SEEABLE(s ) s(s,e)=sI \nWe can use the equations above to generate coenable sets for our example from Figure 3, one need simply \ngenerate a .nite state machine from the property s ERE. For P = UNSAFEITER and G= {match}, the COENABLEP,G \nsets are: COENABLEP,G(create)= {{next, update}} {} {next}, {next, update}, COENABLEP,G(update)= {next, \ncreate, update} COENABLEP,G(next)= {{next, update}} Note that if we did not remove \u00d8s, COENABLEP,G(next) \nwould contain \u00d8. Each inner set can be thought of as a conjunction of events that must occur at least \nonce for a verdict category in Gto still be reachable, while the outer sets are a disjunction (see Section \n4.2.2). For example, if the event seen by monitor instance M is update and next can still be seen at \nsome future point, then M is still necessary. Likewise, if the event seen by M is next, then both next \nand update must be possible for M to ever match. In particular, if the corresponding Collection object \ninstance is already dead then we know that the event update will never be possible, so we can safely \ngarbage collect M. De.nition 11 formalizes this notion. CFG Example A CFG is a tuple (N, E, S, .) where \nN is a .nite set of nonterminals, Eis a .nite set of terminals, S .N is the initial nonterminal, and \n. is a set of productions of the form A .\u00df where A .N and \u00df .(N .E) *. The monitor for a CFG classi.es \ntraces that are in the language of the grammar into the verdict category match. For a CFG, to compute \nCOENABLEP,{match} we .nd the least .xed point of the following equations: G(E)= {\u00d8}G(e)= {{e}}G(A)= \nG(\u00df) A.\u00df G(\u00df1\u00df2)= {T1 .T2 |T1 .G(\u00df1),T2 .G(\u00df2)} { } A .\u00df1x\u00df2, C(x)= T1 .T2 T1 .C(A),T2 .G(\u00df2)COENABLEP,{match}(e)= \nC(e) Informally, G(A) is the set of events generated by the CFG, if the symbol A were used as the initial \nnonterminal of the CFG. The equation G(\u00df1\u00df2)= {T1 .T2 |T1 .G(\u00df1),T2 .G(\u00df2)}generalizes this notion to \nentire traces of symbols (where symbols are either events or non-terminals). C is the coenable sets function \ngeneralized to traces that include both non-terminals and events. For a production, A .\u00df1B\u00df2, C(B) needs \nto cope with the fact that A has its own coenable sets. Thus its de.nition unions possible coenable sets \nof A with the sets of symbols that are generated by \u00df2. The rest of RV only needs to know coenable sets \nfor events so coenables is just the restriction of C to events. De.nition 11. Given property P : E* .C, \ngoal G.C, set of parameters X and event de.nition D: E.P(X) (see Def\u00adinition 4), the property parameter \ncoenable set is de.ned as the map COENABLEX P,G(e)= P,G : E.P(P(X)) where COENABLEX {D(E) |E .COENABLEP,G(e)}for \neach e .E. The COENABLEX sets tell us which parameter objects must P,G be alive for a verdict category \nin Gto be reachable. For P = UNSAFEITER, G= {match}, and X = {c, i}, the COENABLEX P,G  sets are: X \nCOENABLEP,G(create)= {{c, i}} X COENABLEP,G(update)= {{i}, {c, i}} X COENABLEP,G(next)= {{c, i}} Now \nwith the COENABLEX sets we can explicitly decide when a P,G monitor instance may be collected. For example, \nin UNSAFEITER we know that if, at any time, the Iterator bound to i is garbage collected, then a match \ncan never occur because i occurs in every one of the inner sets. This makes sense because the event that \ncauses a match in the UNSAFEITER pattern is use of the Iterator. As men\u00adtioned in Section 1, this situation \ncould produce a very large memory leak in JavaMOP [17] where long living Collections would cause monitor \ninstances for dead Iterators to be retained because it could not remove a monitor instance unless all \nbound parameter objects were collected. We prove this concept by showing that certain pa\u00adrameters speci.ed \nby COENABLEX ' must be P,G(e) for a trace wew able to occur in w ' for a verdict category to be reached. \nTheorem 1. Consider the same assumptions as in De.nition 11, and a trace slice wew ' .E*. If for each \nY P,G(e) .COENABLEX there exists some y .Y such that y .D(w ' ) then P (wew ' ) .G. Proof. Suppose, for \nthe sake of contradiction, that P (wew ' ) .Gand that each Y .P,G(e) contains a y such that COENABLEX \ny .D(w ' ). By De.nition 10, because P (wew ' ) .Gthere must be some E .COENABLEP,G(e) that contains \nexactly those events in w '. Then, by De.nition 11, there must be Y .COENABLEX P,G(e) containing exactly \nthe parameters in D(w ' ). Contradiction. Discussion The COENABLEX P,G sets are a conservative approxima\u00adtion \nof the situations in which a monitor instance may be collected. From De.nition 6 we know that an event \ne where x .D(e) can only occur in a trace-slice tI. if .(x) is still alive in the system. If .(x) has \nbeen garbage collected, there is no way for any e with x .D(e) to occur in trace slice for .. This is \nprecisely how monitoring arrives in the situation presented in Theorem 1, where all possible suf.xes \nw ' of the trace slice wew ' do not contain at least one parameter in each set of the COENABLEX P,G(e), \nand it becomes impossible to reach a verdict category in G. Clearly, if it is impossible for the . trace \nslice to ever reach a verdict category in G, there is no reason to keep the monitor instance for .. The \nTracematches system uses a more precise formulation, which is similar, but based on the state of the \nmonitor. Intuitively, the Tracematches garbage collection technique can be thought of as coenables sets \nindexed by state rather than events, but the formulation as presented in [8] is considerably different. \nWhile theirs is more precise, our empirical results, presented in Section 5, show that the coenable set \ntechnique is able to reduce memory usage in the RV system to comparable levels with Tracematches, while \nthe RV system has considerably lower runtime overhead. More importantly, the Tracematches garbage collection \ntechnique is limited to .nite logics, such as the regular expressions of Tracematches. However, our coenable \napproach is extensible to any underlying monitor implementation. We have a coenables sets generation \nalgorithm for the context-free grammar plugin. A static state-based technique, such as the one used by \nTracematches, could not be used for context\u00adfree properties because the state space is unbounded. The \ncoenables technique reclaims much more memory than JavaMOP s garbage collection, which, as already explained, \nhas to wait for all bound parameter objects to be collected (see Section 5). (c, i)-Tree (c)-Tree (i)-Tree \n m1 m2 m3 Figure 6. Indexing trees for UNSAFEITER 4. Implementation The data structures used by previous \nruntime monitoring sys\u00adtems [4, 17, 20] are not suf.cient for ef.cient garbage collection of monitor \ninstances. The challenge is how to ef.ciently garbage collect unnecessary monitor instances that are \ncontained in the data structures. Using the standard data structures of previous systems, the overhead \nof instance removal easily overwhelms the bene.t of having fewer instances. Our specialized data structures, \nintroduced here, track the garbage collection of parameter objects and remove unnecessary monitor instances \nwhen discovered using coenable sets (Section 3). In this section, we present the modi.ed indexing trees \nused by RV as well as the mechanism by which unnecessary monitors are garbage collected. 4.1 Indexing \nTrees The RV system builds upon the Indexing Tree technique of the JavaMOP system presented in [17]. \nThe indexing trees are an ef.cient means to represent the tables . and G from the monitoring algorithm \nin Figure 5. Locating the correct monitor instances to update for each received event is one of the most \nimportant and expensive tasks of a runtime monitoring system that supports formalism-independent parametric \nproperties like JavaMOP and RV. Whenever a parametric event e(.)is processed, all monitor instances corresponding \nto parameter instances more informative than . must be updated. Thus we need a mapping from parameter \ninstances to sets of monitor instances more informative than that instance. Each value in the map is \neither the next level of the tree or, at the leaves, the appropriate set of monitor instances. Once we \nhave this set we update all the contained monitor instances. For example, processing update(c2)for UNSAFEITER \n(Figure 3) requires that we update the monitor instances that are more informa\u00adtive than (c2). Thus we \nlookup (c2)in the (c)-tree of Figure 6 to .nd the set of monitor instances more informative than (c2)and \nupdate each instance. Multiple indexing trees can exist since each event may contain a different subset \nof parameters; each subset of possible parameters receives its own tree. As an example, for UNSAFEITER \nwe have a (c)-tree, an (i)-tree, and a (c, i)-tree.  4.2 Collecting Unnecessary Monitors There are two \nperformance bene.ts to garbage collecting unneces\u00adsary monitors: reduced memory usage, and reduction \nin the time needed to update monitor instances because many of the moni\u00adtor instances that would be updated \nare no longer necessary. As an example of the latter, consider UNSAFEITER again. If we have a monitor \ninstance for (c1,i1)and i1 is garbage collected, even  (c, i)-Tree (c)-Tree (i)-Tree m1 m2 (c, i)-Tree \n(c)-Tree (i)-Tree m1 m2 Figure 7. (A) Notifying monitors for garbage collected (c2)in the (c)-tree. \n(B) Cleaning up the broken mapping in the (c)-tree though it is impossible to match the UNSAFEITER pattern, \nall future update events are sent to (c1,i1). Unfortunately, collecting monitor instances introduces \noverhead; we must keep this overhead low so that it does not outweigh the bene.ts of garbage collection. \nEager garbage collection of unnecessary monitors introduces a very large amount of runtime overhead, \nwhich almost always overwhelms any bene.ts. This is because eager collection requires propagating the \ninformation regarding liveness of parameter objects to monitor instances far too frequently. Additionally, \neager collection can result in removing instances from some data structures that will never be used again. \nTherefore, we use a lazy garbage collection scheme. We iter\u00adate monitor instances and propagate the information \nof garbage collections of parameter objects lazily, and we remove unneces\u00adsary monitors lazily. When \nan indexing tree containing a garbage collected parameter object is accessed and the tree detects this, \nit informs all the relevant monitor instances contained within itself. Then, the monitor instance decides \nif it can still possibly reach a verdict category in Gin the absence of the parameter object that has \nbeen garbage collected. Later when more space is needed in the data structure or when monitor instances \nare updated, we remove mon\u00aditor instances from the accessed data structure but not from other data structures. \nA monitor instance is garbage collected when it is removed from all data structures. This is similar \nto mark-and-sweep garbage collection. If a data structure itself is garbage collected, any contained \nmonitor instances never need to be garbage collected separately. The next sections explain this process \nin detail. 4.2.1 Parameter Object Garbage Collection Noti.cation Propagation of parameter object garbage \ncollection information starts from the mappings in the indexing tree. The mappings used Figure 8. A compaction \nin RVSet when some monitor instances are collectable in the RV are implemented as a class called RVMap. \nRVMap uses WeakReferences for its keys. A WeakReference in Java does not stop the garbage collector from \ncollecting its referent; when the referent is garbage collected, the WeakReference points to null. Whenever \nan operation (put or get) is performed on an RVMap or the hash table underlying the map needs to be expanded \nto store more entries it looks through a subset of its entries for keys with null referents. When there \nis a key with a null referent due to a garbage collection, RVMap noti.es all of the monitor instances \nbelow itself in the indexing tree. For example, Figure 7 (A) shows a possible scenario where (c2)is garbage \ncollected and the (c)-tree is accessed. The (c)-tree noti.es all of the monitor instances below (c2). \n 4.2.2 Determining When Monitor Instances are Unnecessary When a monitor is noti.ed of a newly garbage \ncollected parame\u00adter object, it decides whether it can still reach a verdict category of interest in \nthe absence of garbage collected parameter objects by using the coenable sets introduced in Section 3. \nEach mon\u00aditor instance stores the last event it receives, e, so that it may check COENABLEX P,G(e), when \nthis noti.cation takes place. The monitor instance need simply check if all the parameter objects of \nany set in COENABLEX P,G(e) are alive. RV statically translates COENABLEX P,G(e) to a minimized boolean \nformula to make this check as ef.cient as possible: V ALIVENESS(e)= livex S . COENABLEX (e)x . S P,G \nwhere livex is a boolean that is true only if the parameter object of parameter x has not been garbage \ncollected. Then, ALIVENESS(e) is true only if the monitor is necessary. Maintaining livex variables in \na given monitor instance for each parameter and checking the generated boolean expression at runtime \nis suf.cient for determining when said instance becomes unnecessary. Continuing our example from the \nlast section, the monitor instances noti.ed of garbage collected parameters in Figure 7 (A) check their \nALIVENESS to determine if they are unnecessary. Here, m1 and m3 are unnecessary and therefore marked. \nNote that the set under (c2)is not altered because other RVMaps in the index tree still point to it. \nIn Figure 7 (B), the RVMap removed the broken map entry index by c2. m1 and m3 will be removed at some \nfuture time when the (c, i)-tree or (i)-tree are accessed or expanded, as we explain in the next section. \n5. Evaluation of the RV System We evaluate our formalism-independent garbage collection for parametric \nmonitoring implemented into RV. Also, we compare the performance of RV to JavaMOP and Tracematches, two \nof the most optimized monitoring systems in runtime and memory, respectively. 5.1 Experimental Settings \nFor our experiments, we used a Pentium 4 2.66GHz / 2GB RAM / Ubuntu 9.10 machine and version 9.12 of \nthe DaCapo (DaCapo 9.12)  HASNEXT UNSAFEITER UNSAFEMAPITER UNSAFESYNCCOLL UNSAFESYNCMAP ALL (A) ORIG \n(sec) TM MOP RV TM MOP RV TM MOP RV TM MOP RV TM MOP RV RV bloat jython 3.6 8.9 2119 448 116 13 0 0 19194 \n569 251 11 0 1 81203 178 150 18 3 1359 746 212 11 1 1 1942 716 130 10 0 0 982 4 avrora 13.6 45 54 55 \n637 311 118 8113 42 75 144 80 54 74 16 275 batik 3.5 3 2 3 355 9 8 88 5 208 9 9 5 3 0 28 eclipse 79.0 \n-2 4 -1 0 -1 -1 5 -3 0 -4 2 1 8-1 -1 0 fop 2.0 200 49 48 350 21 13 858 14 878 25 871 19 133 h2 18.7 89 \n17 13 128 9 4 1350 21 6 868 21 4 83 20 5 23 luindex 2.9 0 0 1 0 0 1 1 4 1 1 1 1 2 0 0 1 lusearch 25.3 \n-1 1 0 1 2 2 2 2 0 4 0 1 3 1 1 3 pmd 8.3 176 84 59 1423 162 123 8571 188 1818 192 76 8144 26 620 sun.ow \n32.7 47 5 3 7 2 0 9 4 1 13 6 5 17 6 6 6 tomcat 13.8 8 1 1 37 1 1 3 1 1 2 0 1 2 1 3 1 tradebeans 45.5 \n0 -1 1 1 1 2 5 3 -1 -1 1 2 3 1 5 2 tradesoap 94.4 1 3 0 2 1 1 2 0 1 0 0 1 2 2 5 1 xalan 20.3 4 2 2 27 \n7 2 10 5 2 3 2 3 4 4 3 4 (B) ORIG (MB) TM MOP RV TM MOP RV TM MOP RV TM MOP RV TM MOP RV RV bloat jython \n4.9 5.3 56.8 19.3 13.2 5.7 4.6 4.8 7.7 146.8 79.0 4.9 4.6 4.8 8173.4 56.1 6.0 19.5 4.7 6.8 127.9 48.3 \n5.3 4.5 4.4 6.9 55.4 12.7 5.9 4.8 5.1 340.9 4.7 avrora 4.7 4.6 12.4 9.1 4.4 136.2 15.8 814.7 8.5 4.3 \n28.0 12.6 4.4 13.0 4.9 22.3 batik 79.1 79.2 78.7 79.3 75.2 93.6 86.6 891.2 79.6 78.2 93.2 85.1 79.9 86.9 \n76.7 104.3 eclipse 95.9 100.8 107.6 97.1 98.3 100.0 110.3 106.9 93.8 101.1 100.4 109.2 90.1 898.6 98.7 \n98.9 fop 20.7 97.4 47.1 52.5 24.3 24.2 29.4 869.2 28.1 854.8 24.8 855.9 25.2 47.5 h2 265.0 267.8 598.5 \n565.2 267.2 266.2 262.4 312.4 688.3 268.2 271.4 690.3 265.5 271.0 718.3 270.0 283.7 luindex 6.8 5.6 5.5 \n5.6 6.3 6.9 6.8 7.4 8.2 6.9 7.4 7.4 7.5 7.1 7.4 11.0 11.8 lusearch 4.6 4.7 4.4 4.8 4.6 4.8 4.2 4.0 4.3 \n4.8 4.5 4.5 4.6 4.6 4.8 4.7 4.7 pmd 18.0 56.9 59.8 48.5 17.2 146.3 86.4 8212.7 93.6 20.3 238.4 84.6 8117.1 \n32.9 420.0 sun.ow 4.4 4.5 4.8 4.9 4.8 4.3 4.7 4.7 4.4 4.4 5.1 4.3 4.9 4.5 4.7 4.5 4.6 tomcat 11.6 11.4 \n12.3 11.4 12.5 11.0 11.5 11.9 11.4 11.0 11.3 11.3 11.3 11.4 11.4 11.8 11.8 tradebeans 63.2 62.9 62.7 \n62.1 63.7 63.9 64.1 63.3 62.5 62.7 63.2 62.8 62.0 64.0 62.8 64.0 62.5 tradesoap 64.1 61.8 62.3 63.3 63.4 \n63.1 64.4 64.1 63.5 62.0 60.7 65.0 65.9 65.5 64.5 65.6 64.5 xalan 4.9 4.9 5.0 5.1 4.9 4.9 4.9 4.9 4.5 \n4.9 5.0 4.8 5.0 5.1 4.9 4.9 5.0 Figure 9. Comparison of Tracematches (TM), JavaMOP (MOP), and RV: (A) \naverage percent runtime overhead; (B) total peak memory usage in MB. (convergence within 3%, 8: not terminated \nafter 1 hour) benchmark suite [10], the most up-to-date version. We also present the result from the \nprevious version, 2006-10 MR2 of DaCapo (DaCapo 2006-10), but only for the bloat and jython benchmarks. \nDaCapo 9.12 does not provide the bloat benchmark from the Da-Capo 2006-10, which we favor because it \ngenerates large overheads when monitoring Iterator-based properties. The bloat benchmark with the UNSAFEITER \nspeci.cation causes 19194% runtime over\u00adhead (i.e., 192 times slower) and uses 7.7MB of heap memory in \nTracematches, and causes 569% runtime overhead and uses 147MB in JavaMOP, while the original program \nuses only 4.9MB. Also, although the DaCapo 9.12 provides jython, Tracematches cannot instrument jython \ndue to an error. Thus, we present the result of jython from the DaCapo 2006-10. The default data input \nfor Da-Capo was used and the -converge option to obtain the numbers after convergence within \u00b13%. We \nalso looked into other benchmarks in\u00adcluding Java Grande [29] and SPECjvm 2008 [2], and saw little to \nno overhead even with our Iterator-based properties. Instrumentation introduces a different garbage collection \nbehavior in the monitored program, sometimes causing the program to slightly outperform the original \nprogram; this accounts for the negative overheads seen in both runtime and memory. We used the Sun JVM \n1.6.0 for the entire evaluation. The AspectJ compiler (ajc) version 1.6.4 is used for weaving the aspects \ngenerated by JavaMOP and RV into the target benchmarks. Another AspectJ compiler, abc [7] 1.3.0, is used \nfor weaving Tracematches properties because Tracematches is part of abc and does not work with ajc.For \nJavaMOP, we used the most recent release version, 2.1.2, from the JavaMOP website [1]. For Tracematches, \nwe used the most recent release version, 1.3.0, from [3], which is included in the abc compiler as an \nextension. To .gure out the reason that some examples do not terminate when using Tracematches,we also \nused the abc compiler for weaving aspects generated from RV properties. Note that RV is AspectJ compiler \nindependent. RV shows similar overheads and terminates on all examples when using the abc compiler for \nweaving as when ajc is used. Because the overheads are similar, we do not present the results of using \nabc to weave RV generated aspects in this paper. However, using abc to weave RV properties con.rms that \nthe high overhead and non-termination come from Tracematches itself, not from the abc compiler. The following \nproperties are used in our experiments. They were borrowed from [13, 14, 19, 28]. HASNEXT: Do not use \nthe next element in an Iterator without checking for the existence of it (see Figure 2);  UNSAFEITER: \nDo not update a Collection when using the Iterator interface to iterate its elements (see Figure 3); \n UNSAFEMAPITER: Do not update a Map when using the Iterator interface to iterate its values or its keys; \n UNSAFESYNCCOLL:Ifa Collection is synchronized, then its iterator also should be accessed synchronously; \n UNSAFESYNCMAP:Ifa Collection is synchronized, then its iterators on values and keys also should be \naccessed in a synchronized manner.  All of them are tested on Tracematches, JavaMOP, and RV for comparison. \nWe also monitored all .ve properties at the same time in RV, which was not possible in other monitoring \nsystems for performance reasons or structural limitations. We have tested several non-Iterator based \nproperties: HASHSET, SAFEENUM, SAFEFILE, and SAFEFILEWRITER [13, 14, 19, 28]. None of these properties \nproduce overheads above 5% in any of the DaCapo benchmarks, thus their results are not presented in this \npaper in detail. Complete results for non-Iterator based properties, as well as performance improvements \nfor RV when combined with Clara can be found in [25].  HASNEXT UNSAFEITER UNSAFEMAPITER UNSAFESYNCCOLL \nUNSAFESYNCMAP E M FM CM E M FM CM E M FM CM E M FM CM E M FM CM bloat jython 156M 1.9M 1.9M 1.8M 106 \n50 47 26 81M 1.9M 1.8M 1.6M 179K 50 38 38 73M 3.6M 44K 3.5M 179K 101K 94 101K 143M 4.1M 0 3.7M 156 100 \n0 83 161M 3.4M 0 3.4M 256 150 0 122 avrora 1.5M 909K 850K 765K 1.4M 909K 860K 808K 1.3M 1.2M 18 1.2M \n2.4M 1.8M 0 1.7M 1.5M 909K 0 904K batik 49K 24K 21K 21K 125K 24K 21K 10K 55K 33K 140 27K 73K 50K 0 34K \n50K 26K 0 26K eclipse 226K 7.6K 5.3K 2.9K 119K 6.6K 5.1K 2.6K 113K 22K 2.2K 7.8K 233K 15K 0 7.5K 241K \n18K 0 9.2K fop 1.0M 184K 74K 151K 709K 7.7K 7.2K 1.8K 499K 177K 67 160K 1.2M 239K 0 217K 1.2M 231K 0 \n213K h2 27M 6.5M 6.0M 5.6M 12M 3.7K 3.3K 1.3K 12M 6.6M 9 6.5M 27M 6.5M 0 6.5M 27M 6.5M 0 6.5M luindex \n371 66 40 2 4.4K 65 39 0 378 183 2 59 436 132 0 30 472 125 0 25 lusearch 1.4K 131 196 114 748K 130 210 \n18 20K 944 338 1.4K 1.7K 262 0 402 1.8K 263 0 158 pmd 8.3M 789K 694K 571K 6.4M 551K 473K 382K 4.3M 1.3M \n110K 1.1M 8.8M 1.5M 0 1.3M 8.6M 1.1M 0 999K sun.ow 2.7M 101K 101K 100K 1.3M 2 0 0 1.3M 83K 0 83K 2.7M \n101K 0 101K 2.7M 101K 0 101K tomcat 25 6 0 0 132 4 0 0 68 26 0 0 29 10 0 0 33 12 0 0 tradebeans 11 3 \n0 0 31 2 0 0 29 13 0 0 13 5 0 0 15 6 0 0 tradesoap 11 3 0 0 31 2 0 0 29 13 0 0 13 5 0 0 15 6 0 0 xalan \n11 3 0 0 8.9K 2 0 0 119K 20K 0 20K 13 5 0 0 15 6 0 0 Figure 10. Monitoring statistics: number of events \n(E), number of created monitors (M), number of .agged monitors (FM), number of collected monitors (CM). \n 5.1.1 Removing Unnecessary Monitor Instances Monitor instances are removed lazily because in many cases \nthe maps and sets containing monitor instances .agged for removal may be garbage collected themselves. \nEager removal would result in unnecessary work in such cases. For example, in Figure 7 (B), if the (c2)-subtree \nin the (c, i)-tree is going to be garbage collected, there is no reason to remove .agged monitor instances \nfrom it. Unnecessary monitor instances are only removed when an indexing tree is accessed. Whenever an \nRVMap looks for keys with null referents it also checks the values of mappings which do not have null \nreferents. The value can be either a monitor instance, a set, or a lower level map. If the value is a \n.agged monitor instance or an empty data structure, it removes the mapping. If it is a set, it must be \nchecked for internal monitor instances that have been .agged for removal. When a set is checked for unnecessary \nmonitor instances, all of the instances are collected, and the remaining necessary monitor instances \nare compacted in one pass, as can be seen in Figure 8.  5.2 Results and Discussions Figures 9 and 10 \nsummarize the results of the evaluation. Note that the structure of the DaCapo 9.12 allows us to instrument \nall of the benchmarks plus all supplementary libraries that the benchmarks use, which was not possible \nfor DaCapo 2006-10. Therefore, fop and pmd show higher overheads than the benchmarks using DaCapo 2006-10 \nfrom [19]. While other benchmarks show overheads less than 80% in JavaMOP, bloat, avrora, and pmd show \nprohibitive overhead in both runtime and memory performance. This is because they generate many iterators \nand all properties in this evaluation are intended to monitor iterators. For example, bloat creates 1,625,770 \ncollections and 941,466 iterators in total while 19,605 iterators coexist at the same time at peak, in \nan execution. avrora and pmd also create many collections and iterators. Also, they call hasNext() 78,451,585 \ntimes, 1,158,152 times and 4,670,555 times and next() 77,666,243 times, 352,697 times and 3,607,164 times, \nrespectively. Therefore, we mainly discuss those three examples in this section, although RV shows improvements \nfor other examples as well. Figure 9 (A) shows the percent runtime overhead of Tracematches, JavaMOP, \nand RV. Overall, RV averages two times less runtime overhead than JavaMOP and orders of magnitude less \nruntime over\u00adhead than Tracematches (recall that these are the most optimized runtime veri.cation systems). \nWith bloat, RV shows less than 260% runtime overhead for each property, while JavaMOP always shows over \n440% runtime overhead and Tracematches always shows over 1350% for completed runs and crashed for UNSAFEMAPITER. \nWith avrora, on average, RV shows 62% runtime overhead, while JavaMOP shows 139% runtime overhead and \nTracematches shows 203% and hangs for UNSAFEMAPITER. With pmd, on average, RV shows 94% runtime overhead, \nwhile JavaMOP shows 231% runtime overhead and Tracematches shows 1139% and hangs for UNSAFEMAPITER and \nUNSAFESYNCMAP. Also, RV was tested with all .ve properties together and showed 982%, 275%, and 620% overhead, \nrespectively, which are still faster or comparable to monitoring one of many properties alone in JavaMOP \nor Tracematches. The overhead for monitoring all the properties simultaneously can be slightly larger \nthan the sum of their individual overheads since the additional memory pressure makes the JVM s garbage \ncollection behave differently. Figure 9 (B) shows the peak memory usage of the three systems. RV has \nlower peak memory usage than JavaMOP in most cases. The cases where RV does not show lower peak memory \nusage are within the limits of expected memory jitter. However, memory usage of RV is still higher than \nthe memory usage of Tracematches in some cases. Tracematches has several .nite automata speci.c memory \noptimizations [8], which cannot be implemented in a formalism-independent system like RV. Although Tracematches \nis sometimes more memory ef.cient, it shows prohibitive runtime overhead monitoring bloat and pmd. There \nis a trade-off between memory usage and runtime overhead. If RV more actively removes terminated monitors, \nmemory usage will be lower, at the cost of runtime performance. Overall, our monitor termination optimization \nachieves the most ef.cient parametric monitoring system with reasonable memory performance. Figure 10 \nshows the number of triggered events, of created monitors, of monitors .agged as unnecessary by the coenable \nset technique, and of monitors collected by the JVM. Among the DaCapo examples, bloat, avrora, h2, pmd \nand sun.ow generated a very large number of events (more than a million) in all properties, resulting \nin millions of monitors created in most cases. h2 does not exhibit large overhead because monitor instances \nin h2 have shorter lifetimes, therefore the created monitor instances are not used heavily like in bloat. \nsun.ow has millions of events but does not create as many monitor instances as as other benchmarks. When \nmonitoring the HASNEXT and UNSAFEITER properties, the coenable sets technique effectively .agged monitors \nas unnecessary and most were collected by the JVM.  6. Conclusion We presented an effective novel garbage \ncollection technique for monitoring parametric properties. Previous techniques were either completely \nagnostic to the property to monitor, thus incurring pro\u00adhibitive runtime overheads due to memory leaks, \nor were intrinsi\u00adcally dependent on particular speci.cation formalisms, thus being hard or impossible \nto use in other contexts. Our technique is the .rst which is both formalism-generic and ef.cient. As \nextensive evaluation shows, it is in fact signi.cantly more ef.cient than the existing techniques, both \nformalism-generic and formalism-speci.c. Our results have at least two implications. On the one hand, \nthey show that runtime monitoring of complex speci.cations can be used not only for testing, but also \nas an integral part of the deployed system in many cases. Indeed, in most practical cases the runtime \noverhead is negligible, so a well-designed recovery schema implemented by means of speci.cation handlers \ncan ensure highly dependable systems by simply not letting them go wrong at runtime. Note that the combinations \nprogram/property selected for evaluation in this paper were speci.cally chosen to be bad. On the other \nhand, our results set a solid ground for further optimizations. For example, static analyses of the program \nto monitor, like those in [14, 15, 21, 27], can be used to remove unnecessary instrumentation and thus \nnot even generate many of the monitors. Similarly, staged/decentralized indexing techniques, like those \nin [6, 8, 17], can reduce the distance between events and their monitors and thus reduce the overhead \ntaken to dispatch events to monitors. References [1] JavaMOP. http://javamop.com. [2] SPECjvm 2008. http://www.spec.org/jvm2008/. \n[3] Tracematches Benchmarks. http://abc.comlab.ox.ac.uk/tmahead. [4] C. Allan, P. Avgustinov, A. S. Christensen, \nL. J. Hendren, S. Kuzins, O. Lhot\u00b4 ak, O. de Moor, D. Sereni, G. Sittampalam, and J. Tibble. Adding trace \nmatching with free variables to AspectJ. In Object-Oriented Programming, Systems, Languages and Applications \n(OOP\u00adSLA 05), pages 345 364. ACM, 2005. [5] M. Arnold, M. Vechev, and E. Yahav. Qvm: an ef.cient runtime \nfor de\u00adtecting defects in deployed systems. In Object-Oriented Programming Systems, Languages, and Applications \n(OOPSLA 08), pages 143 162. ACM, 2008. [6] P. Avgustinov and C. Church. Trace Monitoring with Free Variables. \nPhD thesis, Oxford University, 2009. [7] P. Avgustinov, A. S. Christensen, L. Hendren, S. Kuzins, J. \nLhotak, O. Lhotak, O. de Moor, D. Sereni, G. Sittampalam, and J. Tibble. ABC: an extensible AspectJ compiler. \nIn Aspect-Oriented Software Development (AOSD 05), pages 87 98. ACM, 2005. [8] P. Avgustinov, J. Tibble, \nand O. de Moor. Making trace monitors feasible. In Object Oriented Programming, Systems, Languages and \nApplications (OOPSLA 07), pages 589 608. ACM, 2007. [9] H. Barringer, D. Rydeheard, and K. Havelund. \nRule systems for run\u00adtime monitoring: from EAGLE to RULER. J. Logic Computation, November 2008. [10] \nS. M. Blackburn, R. Garner, C. Hoffman, A. M. Khan, K. S. McKin\u00adley, R. Bentzur, A. Diwan, D. Feinberg, \nD. Frampton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4 \nc, T. VanDrunen, D. von Dincklage, and B. Wiedermann. The DaCapo benchmarks: Java benchmarking development \nand analy\u00adsis. In Object-Oriented Programming, Systems, Languages and Appli\u00adcations (OOPSLA 06), pages \n169 190. ACM, 2006. [11] E. Bodden. J-LO, a tool for runtime-checking temporal assertions. Master s thesis, \nRWTH Aachen University, 2005. [12] E. Bodden and V. Stolz. Tracechecks: De.ning semantic interfaces with \ntemporal logic. In Software Composition, pages 147 162, 2006. [13] E. Bodden, L. Hendren, and O. Lhot\u00b4 \nak. A staged static program analysis to improve the performance of runtime monitoring. In European Conference \non Object Oriented Programming (ECOOP 07), volume 4609 of LNCS, pages 525 549. Springer, 2007. [14] E. \nBodden, F. Chen, and G. Ros\u00b8u. Dependent advice: A general approach to optimizing history-based aspects. \nIn Aspect-Oriented Software Development (AOSD 09), pages 3 14. ACM, 2009. [15] E. Bodden, P. Lam, and \nL. Hendren. Clara: A framework for partially evaluating .nite-state runtime monitors ahead of time. In \nRuntime Veri.cation (RV 10), volume 6418 of LNCS, pages 183 197. Springer, 2010. [16] F. Chen and G. \nRos\u00b8u. Java-MOP: A monitoring oriented programming environment for Java. In Tools and Algorithms for \nthe Construction and Analysis of Systems (TACAS 05), volume 3440 of LNCS, pages 546 550. Springer, 2005. \n[17] F. Chen and G. Ros\u00b8u. MOP: An ef.cient and generic runtime veri.cation framework. In Object-Oriented \nProgramming, Systems, Languages and Applications (OOPSLA 07), pages 569 588. ACM, 2007. [18] F. Chen \nand G. Ros\u00b8u. Parametric trace slicing and monitoring. In Tools and Algorithms for the Construction and \nAnalysis of Systems (TACAS 09), volume 5505 of LNCS, pages 246 261. Springer, 2009. [19] F. Chen, P. \nMeredith, D. Jin, and G. Ros\u00b8u. Ef.cient formalism\u00adindependent monitoring of parametric properties. In \nAutomated Soft\u00adware Engineering (ASE 09), pages 383 394. IEEE, 2009. [20] M. d Amorim and K. Havelund. \nEvent-based runtime veri.cation of Java programs. ACM SIGSOFT Software Engineering Notes, 30(4): 1 7, \n2005. [21] M. Dwyer, R. Purandare, and S. Person. Runtime veri.cation in context: Can optimizing error \ndetection improve fault diagnosis. In Runtime Veri.cation (RV 10), volume 6418 of LNCS, pages 36 50. \nSpringer, 2010. [22] U. Erlingsson and F. B. Schneider. Irm enforcement of java stack inspection. In \nSymposium on Security and Privacy (SP 00), pages 246 . IEEE, 2000. [23] S. Goldsmith, R. O Callahan, \nand A. Aiken. Relational queries over program traces. In Object-Oriented Programming, Systems, Languages \nand Applications (OOPSLA 05), pages 385 402. ACM, 2005. [24] K. W. Hamlen and M. Jones. Aspect-oriented \nin-lined reference monitors. In Programming languages and analysis for security (PLAS 08), pages 11 20. \nACM, 2008. [25] D. Jin, P. O. Meredith, D. Grif.th, and G. Ros\u00b8u. Garbage collection for monitoring parametric \nproperties. Technical Report http:// hdl.handle.net/2142/18751, Department of Computer Science, University \nof Illinois at Urbana-Champaign, 2011. [26] G. Kiczales, E. Hilsdale, J. Hugunin, M. Kersten, J. Palm, \nand W. G. Griswold. An overview of AspectJ. In European Conference on Object Oriented Programming (ECOOP \n01), volume 2072 of LNCS, pages 327 353. Springer, 2001. [27] M. Martin, V. B. Livshits, and M. S. Lam. \nFinding application errors and security .aws using PQL: a program query language. In Object Oriented \nProgramming, Systems, Languages and Applications (OOPSLA 07), pages 365 383. ACM, 2005. [28] P. Meredith, \nD. Jin, F. Chen, and G. Ros\u00b8u. Ef.cient monitoring of parametric context-free patterns. J. Automated \nSoftware Engineering, 17(2):149 180, June 2010. [29] L. A. Smith, J. M. Bull, and J. Obdrz\u00b4A parallel \njava grande alek. benchmark suite. In Supercomputing (SC 01), pages 8 8. ACM, 2001. [30] V. Stolz and \nE. Bodden. Temporal Assertions using AspectJ. In Runtime Veri.cation (RV 05), volume 144 of ENTCS, pages \n109 124. Elsevier, 2005. [31] R. E. Strom and S. Yemeni. Typestate: A programming language concept for \nenhancing software reliability. IEEE Transactions on Software Engineering, 12:157 171, January 1986. \n   \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Parametric properties are behavioral properties over program events that depend on one or more parameters. Parameters are bound to concrete data or objects at runtime, which makes parametric properties particularly suitable for stating multi-object relationships or protocols. Monitoring parametric properties independently of the employed formalism involves <i>slicing</i> traces with respect to <i>parameter instances</i> and sending these slices to appropriate non-parametric <i>monitor instances</i>. The number of such instances is theoretically unbounded and tends to be enormous in practice, to an extent that how to efficiently manage monitor instances has become one of the most challenging problems in runtime verification. The previous formalism-independent approach was only able to do the obvious, namely to garbage collect monitor instances when all bound parameter objects were garbage collected. This led to pathological behaviors where unnecessary monitor instances were kept for the entire length of a program. This paper proposes a new approach to garbage collecting monitor instances. Unnecessary monitor instances are collected lazily to avoid creating undue overhead. This lazy collection, along with some careful engineering, has resulted in RV, the most efficient parametric monitoring system to date. Our evaluation shows that the average overhead of RV in the DaCapo benchmark is 15%, which is two times lower than that of JavaMOP and orders of magnitude lower than that of Tracematches.</p>", "authors": [{"name": "Dongyun Jin", "author_profile_id": "81392590994", "affiliation": "University of Illinois at Urbana-Champaign, Urbana, IL, USA", "person_id": "P2690607", "email_address": "djin3@cs.illinois.edu", "orcid_id": ""}, {"name": "Patrick O'Neil Meredith", "author_profile_id": "81387597514", "affiliation": "University of Illinois at Urbana-Champaign, Urbana, IL, USA", "person_id": "P2690608", "email_address": "pmeredit@cs.illinois.edu", "orcid_id": ""}, {"name": "Dennis Griffith", "author_profile_id": "81485647421", "affiliation": "University of Illinois at Urbana-Champaign, Urbana, IL, USA", "person_id": "P2690609", "email_address": "dgriffi3@cs.illinois.edu", "orcid_id": ""}, {"name": "Grigore Rosu", "author_profile_id": "81100069676", "affiliation": "University of Illinois at Urbana-Champaign, Urbana, IL, USA", "person_id": "P2690610", "email_address": "grosu@cs.illinois.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993547", "year": "2011", "article_id": "1993547", "conference": "PLDI", "title": "Garbage collection for monitoring parametric properties", "url": "http://dl.acm.org/citation.cfm?id=1993547"}