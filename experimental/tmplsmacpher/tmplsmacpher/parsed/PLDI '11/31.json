{"article_publication_date": "06-04-2011", "fulltext": "\n Cruiser: Concurrent Heap Buffer Over.ow Monitoring Using Lock-free Data Structures Qiang Zeng Dinghao \nWu Peng Liu Department of Computer Science &#38; College of Information Sciences &#38; College of Information \nSciences &#38; Engineering, Pennsylvania State Technology, Pennsylvania State Technology, Pennsylvania \nState University, University Park, PA 16802 University, University Park, PA 16802 University, University \nPark, PA 16802 quz105@cse.psu.edu dwu@ist.psu.edu pliu@ist.psu.edu Abstract Security enforcement inlined \ninto user threads often delays the pro\u00adtected programs; inlined resource reclamation may interrupt pro\u00adgram \nexecution and defer resource release. We propose software cruising, a novel technique that migrates security \nenforcement and resource reclamation from user threads to a concurrent monitor thread. The technique \nleverages the increasingly popular multicore and multiprocessor architectures and uses lock-free data \nstructures to achieve non-blocking and ef.cient synchronization between the monitor and user threads. \nAs a case study, software cruising is applied to the heap buffer over.ow problem. Previous mitigation \nand detection techniques for this problem suffer from high per\u00adformance overhead, legacy code compatibility, \nsemantics loyalty, or tedious manual program transformation. We present a concur\u00adrent heap buffer over.ow \ndetector, CRUISER, in which a concur\u00adrent thread is added to the user program to monitor heap integrity, \nand custom lock-free data structures and algorithms are designed to achieve high ef.ciency and scalability. \nThe experiments show that our approach is practical: it imposes an average of 5% perfor\u00admance overhead \non SPEC CPU2006, and the throughput slowdown on Apache is negligible on average. Categories and Subject \nDescriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; D.2.5 [Software Engineer\u00ading]: \nTesting and Debugging; D.1.3 [Programming Techniques]: Concurrent Programming General Terms Security, \nVeri.cation, Languages, Algorithms Keywords Software cruising, buffer over.ow, program monitor, multicore, \nconcurrency, lock-free, non-blocking algorithms 1. Introduction Despite extensive research over the \npast few decades, buffer over\u00ad.ow remains as one of the top software vulnerabilities. In 2009, 39% of \nthe security vulnerabilities published by US-CERT [67] were related to buffer over.ows. As of September \n2010, 12 of the 20 most severe vulnerabilities ranked by US-CERT were buffer over.ow related. Vulnerabilities \nlisted by security websites such as Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nSecurityFocus [60] and Securiteam [54] manifest a similar pattern. The related exploits, such as CodeRed \n[10] and SQLSlammer [12], have in.icted billions of dollars worth of damages [38]. A buffer over.ow occurs \nwhen a program, while writing data to a buffer, overruns the buffer s boundary and overwrites adjacent \nmemory. There are mainly two types of buffer over.ows accord\u00ading to the over.owed buffer s memory region, \nnamely stack-based buffer over.ows and heap-based buffer over.ows. Stack-based buffer over.ows are the \nmost exploited vulnerabil\u00adity, as the return addresses for function calls are stored together with buffers \non stack. By over.owing a local buffer, the return address can be overwritten so that, when the function \nreturns, the control .ow is redirected to execute malicious code, which is called stack smashing [3]. \nOther forms of stack-based buffer over.ow attacks overwrite frame pointers and local variables, e.g. \nfunction point\u00aders, to affect program behaviors [8, 50]. Many countermeasures against stack-based buffer \nover.ow attacks have been devised, such as StackGuard [17], StackShield [64], Non-executable stack [63] \nand Libsafe [66], some of which have been widely deployed. Exploitation of a heap-based buffer over.ow \nis similar to that of a stack-based buffer over.ow, except for that there are no return addresses or \nframe pointers on heap. For some widely deployed memory allocators, such as Doug Lea s malloc [36] for \nthe glibc library, altering memory management information to achieve arbi\u00adtrary memory overwrites is \na general way to exploit a heap-based buffer over.ow [11, 33]. More recently non-control data based ex\u00adploits \n[12, 13, 15], by means of tampering the content of a memory block adjacent to the over.owed buffer, have \nbeen increasing. As stack-based buffer over.ow attacks are better understood and defended, heap-based \nbuffer over.ows have gained growing attention of attackers. According to the National Vulnerability Database \n[43], 177 heap-based buffer over.ow vulnerabilities were published in 2009. As of September 2010, 287 \nheap-based buffer over.ow vulnerabilities had been published in that year. Related exploits have affected \nwidely deployed programs [11, 12]. Current buffer over.ow detectors can be roughly classi.ed into two \ncategories: static and dynamic approaches. Static analysis tools usually have high false alarm rates; \ndynamic buffer over.ow de\u00adtectors can provide precise detection and generally there can be no false alarms \n[71]. However few dynamic heap buffer over.ow detectors are widely deployed due to one or more of the \nfollow\u00ading reasons: (1) Most countermeasures result in high performance overhead [1, 5, 9, 22, 27, 34, \n52, 68]; (2) Some only protect spe\u00adci.c libc functions [5, 19]; (3) A few of them only work with spe\u00ad \n for pro.t or commercial advantage and that copies bear this notice and the full citation ci.c memory \nallocators [2, 19]; (4) Many require source code for on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute recompilation [1, 4, 9, 31, 34, 42, 52]; (5) Some are incompatible \nto lists, requires prior speci.c permission and/or a fee. with legacy code [4, 31, 42]; and (6) Some \nrequire special platforms PLDI 11, June 4 8, 2011, San Jose, California, USA. or hardware supports that \nare rarely available [1, 34]. cCopyright &#38;#169; 2011 ACM 978-1-4503-0663-8/11/06. . . $10.00  In \nthis paper, we present Cruiser a novel dynamic heap buffer over.ow detector which does not have those \nlimitations. The key ideas are (1) to create a dedicated monitor thread, which runs con\u00adcurrently with \nuser threads to cruise over, or keep checking, dy\u00adnamically allocated buffers against buffer over.ows; \nand (2) to uti\u00adlize lock-free data structures and non-blocking algorithms, through which user threads \ncommunicate with the monitor thread with min\u00adimum overhead and without being blocked. Buffer addresses \nare collected in a lock-free data structure ef.ciently without blocking user threads. By traversing the \ndata structure, buffers on heap are under constant surveillance of the concurrent monitor thread. Each \ndynamically allocated buffer is surrounded by two canary words; as long as a canary is found corrupted, \na buffer over.ow is detected. Different from conventional methods that detect buffer over\u00ad.ows inside \nuser threads, which evidently delays protected pro\u00adgrams, we propose to move the detection work out of \nuser threads and enforce it in a separate thread, which we call software cruising. The approach leverages \nthe hardware evolution trend that multi\u00adcore processors and multiprocessor machines are more and more \npopular, which allows us to deploy dedicated monitor threads run\u00adning concurrently with user threads \nto enhance application security. However applications may be signi.cantly slowed down due to the overhead \nof communication and synchronization between the mon\u00aditor threads and user threads. We address this problem \nby design\u00ading highly ef.cient lock-free data structures and non-blocking algo\u00adrithms; their scalability \nimplies the approach can be applied to not only single-threaded programs but also large-scale multithreaded \napplications. Our experiments show that the software cruising ap\u00adproach is practical it only imposes \nan average of 5% performance overhead on SPEC CPU2006, and the throughput slowdown on Apache is negligible \non average. Our contributions include: To the best of our knowledge, this is the .rst work reported \nin the open literature that utilizes concurrent threads to detect buffer over.ows.  Among existing buffer \nover.ow detectors, this is the .rst work that utilizes and designs lock-free data structures to support \nlarge-scale applications.  Cruiser can detect buffer over.ows that occur in any function, rather than \nspeci.c libc functions. In addition, Cruiser can de\u00adtect buffer under.ows, duplicate frees, and memory \nleakage.  Cruiser is legacy code compatible and can be applied to protect binary executables transparently, \nthus no source code or binary rewriting is needed. In addition, Cruiser does not rely on spe\u00adci.c memory \nallocation algorithms; it can work with any mem\u00adory allocator. Hence, Cruiser can be directly applied \nto shrink\u00adwrapped software, and can be deployed easily to large-scale systems such as data centers and \nserver farms in an automated manner.  We propose a novel concurrent program monitoring method\u00adology \ncalled software cruising, which leverages multicore ar\u00adchitectures and utilizes non-blocking data structures \nand algo\u00adrithms to achieve good ef.ciency and scalability; it can be ap\u00adplied to background security \nenforcement, as demonstrated in this paper, and concurrent resource reclamation (Section 7).  The remainder \nof the paper is organized as follows. In Sec\u00adtion 2 we brie.y discuss lock-free synchronization and review \nre\u00adlated work. We discuss our motivations in Section 3 and present the design overview in Section 4. \nIn Section 5 we describe the de\u00adsign and implementation. In Section 6 we present the evaluation results. \nWe discuss applications of software cruising beyond buffer over.ows in Section 7 and conclude with Section \n8.  2. Background 2.1 Lock-free Synchronization A conventional approach to multithreaded programming \nis to use locks to synchronize access to shared resources. However, the lock\u00adbased approach causes many \nproblems, one of which is lock con\u00adtention. No matter whether the thread holding a lock is running or \ndescheduled, other threads waiting for the lock are blocked, which limits concurrency and scalability. \nAnother problem is priority in\u00adversion, i.e. a low priority thread holding the lock cannot get sched\u00aduled \nwhile high priority threads are waiting for the lock. Although .ne-grained locking reduces lock contention, \nit introduces more lock overhead and increases the risk of deadlock. In contrast to the lock-based approach, \nlock-free and wait-free algorithms allow high concurrency and scalability. An algorithm is lock-free \nif in a .nite number of execution steps, at least one of the program threads makes progress, while an \nalgorithm is wait-free if in a .nite number of steps, every thread makes progress [28]. All wait-free \nalgorithms are lock-free but the reverse is not necessarily true. Both are non-blocking and, by de.nition, \nthey are immune to deadlock and priority inversion. Lock-free algorithms commonly rely on hardware synchro\u00adnization \nprimitives. A typical primitive is Compare-And-Swap (CAS) [30]; it takes three arguments (addr, expval, \nnewval) and performs the following atomically: if (*addr != expval) return false; *addr = newval; return \ntrue; Speci.cally, if the memory location addr does not hold the ex\u00adpected value expval, the Boolean \nfalse is returned; otherwise the new value newval is written to it and the Boolean true is returned, \natomically.  2.2 Related Work We divide the existing countermeasures against buffer over.ow at\u00adtacks \ninto the following seven categories. Given extensive research in this area, this is not intended to be \nexhaustive. Bounds checking: Many static analysis tools fall under this category [20, 69], which detect \nbuffer over.ows by examining source code statically and automatically. This approach usually suffers \nfrom high false positive or negative rate [71]. Some dynamic approaches [4, 31, 42] change the C pointer \nrepresentation to carry buffer size information with pointers to enable bounds checking, i.e. fat pointer, \nwhich is incompatible with legacy library code. CRED [52], built on the work of Jones and Kelly [32], \ndoes not change pointer representations but associates a buffer bound lookup with each pointer reference. \nHowever, the performance overhead is more than 2X. A recent work, baggy bounds checking [2], reduces \nthe cost of bounds lookups by relaxing bounds checking precision, which however may lead to false negative, \nand it relies on speci.c memory allocators. Some library-based countermeasures [5, 19, 66] provide bounds \nchecking only for speci.c functions in the C standard library. Canary checking: Canary was .rstly proposed \nin Stack-Guard [17], which tackles stack smashing attacks by placing a ca\u00adnary word before the return \naddress on stack. Attempts to overwrite the return address would corrupt the canary value .rst. Although \nthere are arguments that canary-based countermeasures can be by\u00adpassed [8, 50], the wide deployment and \nsuccesses of StackGuard and its derivation ProPolice [29] have manifested their effective\u00adness. Robertson \net al. [51] .rst proposed to use canary to protect heap chunk metadata. A canary is placed at the beginning \nof each chunk, thus when a buffer on heap is over.owed, the canary of the adjacent chunk is corrupted, \nwhich, however, is not detected until the adjacent chunk is coalesced, allocated or deallocated; therefore \nthe detection relies on program execution.  Return address (RA) shadow stack or stack split: Stack-Shield \n[64], RAD [14] and their derivations [23, 49] maintain an RA shadow stack, i.e. a copy of the RA is saved \non the shadow stack at the prologue of a function call and is compared against the RA on the conventional \nstack at the epilogue. If the two RAs di\u00adverge, a buffer over.ow is detected. In [70], the stack is split \ninto an RA stack and a data stack, such that return addresses are pro\u00adtected from buffer over.ows. Non-executable \n(NX) memory: By setting the memory pages as non-executable, NX memory [63, 65] prevents code injected \nonto stack and heap from being executed. However it can be by\u00adpassed by a return-to-libc attack, which \noverwrites function point\u00aders or return addresses with function addresses in libc, e.g. sys\u00adtem(). Non-accessible \nmemory: Both Purify [27] and Valgrind [68] insert guard zones, which are marked as inaccessible, surround\u00ading \ndynamically allocated buffers, and track all memory references. When a guard zone access is detected, \ne.g. due to buffer over.ows, an error is reported. Eletric Fence [22] places an inaccessible mem\u00adory \npage immediately after (or before) each dynamically allocated buffer. If a buffer is over.owed (or under.owed), \na segmentation fault is signaled. Tools in this category result in signi.cant memory and performance \noverhead. Randomization and obfuscation: Address Space Layout Ran\u00addomization (ASLR) [7, 65] randomizes \nthe locations of stack, heap and/or variable locations for each execution, such that a buffer over\u00ad.ow \nattack, such as return-to-libc, cannot be achieved reliably; that is, probabilistic protection is provided. \nHowever as it requires pro\u00adgrams to be compiled into position-independent executables, it is incompatible \nwith legacy code. In addition, it may be defeated by brute-force attacks or bypassed by partial overwrite \nattacks on the least signi.cant bytes of a pointer [21]. PointGuard [16] encrypts pointers stored in \nmemory and decrypts them before loading them into registers, such that pointers corrupted by attackers \nwill not be decrypted to intended values. This countermeasure is incom\u00adpatible with legacy code and cannot \nprotect non-pointer data. In\u00adstead of randomizing pointers, instruction set randomization [6] keeps instructions \nencrypted, and decrypts them only before they are fetched into processors, which, however, results in \nsubstantial performance overhead. It can be bypassed by return-to-libc attacks. Execution monitoring: \nProgram shepherding [34] monitors control .ow transfer in order to enforce a security policy. Buffer \nover.ow attacks that lead to deviant control .ow transfer are pre\u00advented. Control-.ow integrity [1] determines \na program s control .ow graph beforehand and ensures that the control .ow adheres to it. Castro et al. \n[9] proposed to compute a data-.ow graph using static analysis and monitor whether the program data .ow \nadheres to the graph. Like Cruiser, n-variant execution [18, 53] also takes advantage of multicore and \nmultiprocessor architectures to enhance security. It runs a few variants of a single program simultaneously; \nbehavioral divergences among the variants raise alarms. Execution monitoring usually imposes high performance \noverhead. Despite so many countermeasures, only a few of them, such as StackGuard, ASLR, and NX memory, \nare widely deployed in production systems. Table 1 summarizes the properties of these three approaches \nand compares them with Cruiser. The common properties of these approaches include low performance overhead, \neasiness to deploy and apply, no false alarms,1 compatibility with 1 As described in Section 5.2, one \nvariant of Cruiser does incur false alarms, however, at an extremely low probability (1/264 in 64-bit \nOS) and can be safely ignored in practice. StackGuard ASLR NX v v v Cruiser v Low performance overhead \nEasy to deploy and apply No false alarms Mainstream platform compatible Program semantics loyalty Legacy \ncode compatible No need for recompilation Able to locate corrupted buffers v v v v v v v v v v v v v \nv v v v v v v v v Table 1. Comparison of some widely deployed countermeasures and Cruiser. mainstream \nplatforms and program semantics loyalty. In addition to having all the advantages, Cruiser have three \nother important properties: compatibility with legacy code, no need for recompila\u00adtion, i.e. working \nwith binary executables, and ability to precisely locate corrupted buffers, which is critical for testing, \ndebugging, and security monitoring.  3. Motivations 3.1 Why Concurrent Detection and Challenges There \nare mainly two categories of dynamic heap-based buffer over.ow detectors. One category [51] detects buffer \nover.ows in\u00adside memory allocation functions such as malloc and free, while the other [5, 19] enforces \ndetection inside speci.c libc functions such as strcpy and gets. Both execute detection code inside user \nthreads, which inevitably affects application performance, and the performance overhead is proportionally \ncorrelated with the invoke density of related functions. In addition, because detection is en\u00adforced \nin speci.c functions, they suffer from either severe temporal limitations, i.e. buffer over.ows are not \ndetected until one of the malloc function family is called, or spatial limitations, i.e. only a few libc \nfunctions are protected. Approaches that enforce bounds checking for each buffer reference do not have \nsuch limitations; however, they usually incur high performance overhead [32, 52] or falsenegativerate[2]. \nWe propose to move detection code out of user threads and ex\u00adecute it in a separate monitor thread, which \nconstantly cruises over buffers on heap, such that user threads are not delayed. Rich com\u00adputational \nresources on modern machines, especially widely avail\u00adable multicore and multiprocessor architectures, \nenable us to run a dedicated monitor thread without competing too much resources with user threads, in \nother words, applications can potentially gain enhanced security with no pain. However, synchronization \nis one of the major challenges. In Cruiser, a collection of heap buffer addresses needs to be main\u00adtained, \nso that the monitor thread surveils live buffers, and in the meanwhile avoids checking deallocated buffers, \nwhich would oth\u00aderwise incur false alarms or segfaults. Therefore, the user threads and monitor thread \nhave to be synchronized when buffers are al\u00adlocated or deallocated. A conventional approach to achieving \nsyn\u00adchronization is to use locks; however, it has various limitations, such as severe performance degradation \ndue to lock contention and low scalability, which is manifested by our .rst attempt. In our .rst attempt, \na lock-based red-black tree was used to collect buffer addresses. Inside a malloc call, the address of \nthe newly allocated buffer is inserted into the tree with O(log n) time complexity where n is the number \nof collected addresses. Simi\u00adlarly inside a free call, the address of the released buffer is removed \nfrom the tree with O(log n) complexity also. Meanwhile a monitor thread traverses the tree to check the \nbuffers. All the buffer ad\u00address insert, delete and traverse operations are synchronized using locks. \nOur experiments showed that user threads were signi.cantly delayed. The problem becomes more severe as \nmore user threads contend locks and the tree grows.  Size Head canary User buffer Tail canary  3.2 \nWhy Lock-free and Challenges The limitations of lock-based approach pushed us towards lock\u00adfree synchronization \nin order to avoid lock contention and improve scalability. However, the dif.culty of designing non-blocking \nalgo\u00adrithms is well recognized, which often thwarts the application of this approach. We escaped the \nproblems in our second attempt by utilizing the state-of-the-art extensible lock-free hash table algorithm \nproposed by Shalev and Shavit [62], such that the user threads and mon\u00aditor thread can operate on the \nhash table concurrently, and each buffer address can be inserted into or removed from the hash table \nin O(1) time. Although good scalability is achieved, the operation time is signi.cant compared to malloc \nand free calls. Speci.cally, the slowdown of each pair of malloc and free calls observed in our experiment \nis more than 5X on average. The overhead is un\u00adacceptable for many applications with massive dynamic \nmemory allocation. To address these challenges, we have designed our own lock\u00adfree data structures and \nnon-blocking algorithms to achieve concur\u00adrent detection with low overhead and high scalability, which \nwill be presented in Section 4 and 5.  4. Design Overview In addition to custom lock-free data structures, \ntwo design choices were made. First, as presented above, removing buffer addresses inside free calls \nmay signi.cantly delay user threads. In Cruiser the free function marks the buffer with a tombstone .ag; \nwhen the monitor thread checks the buffer and .nds it no longer alive, the monitor thread removes the \nbuffer address from the collection of heap buffer addresses, such that the concern of delaying freesis \nresolved and the data structure representing the buffer address col\u00adlection can be simpli.ed. The details \nare covered in Section 5.2. Second, instead of modifying a speci.c memory allocator, Cruiser is implemented \nas a dynamic shared library to interpose the malloc function family and it passes the allocation requests \nto the corre\u00adsponding memory allocator functions, therefore Cruiser can work with any memory allocator \nand it can be applied to protecting bi\u00adnary executables without instrumenting them. 4.1 Buffer Structure \nOur method inserts two canary words around each buffer, namely head canary and tail canary, as shown \nin Figure 1, so that when\u00adever a buffer is over.owed (under.owed), the tail (head) canary is corrupted. \nThe size .eld, which is the encryption (XOR) result of the buffer size and a secret key, is used to locate \nthe tail canary given a buffer address. As buffer size information is encrypted, it is not leaked to \nattackers, and it is more dif.cult for attackers to counterfeit. The head canary is the encryption result \nof another se\u00adcret key, the buffer size and the buffer address. If the head canary and the size .eld \ncannot be decrypted to consistent size values, a buffer over.ow is detected. As the buffer address is \nused to gener\u00adate the canary, each buffer has a unique head canary, thus even if the canary of a buffer \nis leaked, it is dif.cult for attackers to forge the canary of another buffer without knowing the buffer \nsizes and addresses. The tail canary is encrypted and veri.ed the same way using a different secret key. \nAll the keys are initialized as random numbers when the monitored program is started. 4.2 Cruiser Our \nprevious attempts maintain a collection of buffer addresses but lead to high overhead. To ef.ciently \ncollect memory allocation in- Figure 1. Buffer structure. formation, we design the cruiser information \ncollection (CIC) ar\u00adchitecture which is composed of (1) a lock-free express data struc\u00adture onto which \nuser threads put information, (2) a lock-free ware\u00adhouse data structure that supports multiple threads \nto concurrently insert, delete and access information, and (3) a non-blocking de\u00adliver thread to copy \nthe information from the express to the ware\u00adhouse data structure. Instead of inserting information into \nthe ware\u00adhouse directly, user threads put the information onto the express data structure highly ef.ciently, \nand the deliver thread takes care of the rest of the information collection work, thus performance im\u00adpact \non user threads is minimized. In addition, as the warehouse structure supports concurrent operations, \nCIC scales well. User Threads CIC malloc Deliver Monitor hook Thread Thread  malloc hook Figure 2. \nCruiser architecture. Based on CIC, we present a dynamic heap-based buffer over\u00ad.ow detector Cruiser, \nwhich uses CIC to collect memory allo\u00adcation information, e.g. buffer addresses and sizes. As shown in \nFigure 2, the malloc calls are hooked to place the buffer allocation information onto the express data \nstructure and return promptly; the deliver thread then .nishes the information collection. From the perspective \nof Cruiser, the life cycle of a dynamically allocated buffer can be divided into three phases: Pre-checking: \nInside a malloc call, a buffer that is three words larger than what the user thread requests is allocated. \nThe buffer is .lled as speci.ed in Section 4.1, and the buffer allocation information used for over.ow \ndetection, such as the buffer address, is put onto the express data structure. Then the malloc call returns \nthe address of the user buffer (see Figure 1). Checking: The pre-checking phase ends when the deliver \nthread moves the address from the express to the warehouse data structure, which is traversed by the \nmonitor thread to detect buffer over.ows. Post-checking: Inside the free call, the buffer is marked with \na tombstone .ag by encrypting the head canary once again using another key; later when the monitor thread \nchecks the buffer and .nds it no longer alive, the dated buffer information is removed from the warehouse \nby the monitor thread, so it is the monitor thread rather than user threads that tides up dated metadata \ninformation.  5. Design and Implementation This section describes the design and implementation of \nCruiser. Section 5.1 describes the data structures in CIC and how CIC is used in Cruiser to maintain \nbuffer information. Section 5.2 presents the algorithms to release buffers and delete dated metadata \ninforma\u00adtion. We elaborate special issues on extensions and optimizations in Section 5.3.  5.1 Collection \nof Buffer Information 5.1.1 Express data structure We implement the express data structure based on the \nsingle\u00adproducer single-consumer FIFO wait-free ring buffer proposed by Lamport [35]. Lamport s algorithm \nallows a producer thread and a consumer thread to operate concurrently on a ring. The synchro\u00adnization \noverhead between the producer and the consumer is low, as two threads are synchronized via read/write \ninstructions on the two control variables head and tail. Because of its high ef.ciency, the data structure \nhas been applied to Gigabit network packet pro\u00adcessing systems [24, 37]. To avoid the failure of Enqueue \noperation when the ring is full, we extend the basic ring to a linked list of rings, called CruiserRing, \nas shown in Figure 3. Whenever the ring is full and a new element is produced, instead of returning failure \nin Enqueue as in Lamport s algorithm, the producer creates a new ring with doubled capacity and links \nit after the full ring; the producer proceeds to insert elements into the new ring. Accordingly, in Dequeue \nwhen the ring is consumed up and another ring is linked after it, the consumer destroys the empty ring \nand proceeds to work on the next one. Because the ring size grows exponentially, as long as the speed \nof the consumer matches that of the producer, CruiserRing will converge to a stable state quickly. (The \nspeed mismatch problem is addressed in Section 5.3.) Unless the new ring creation fails, CruiserRing \nensures the success of the producer, which implies that the producer always moves on without dropping \ndata. As each CruiserRing supports one producer thread, a Cruiser-Ring is needed for each producer thread. \nThe method AddCruiser-Ring (see Figure 3) shows how to construct a list of CruiserRings in a lock-free \nmanner, such that a single consumer thread can walk along the list to access all CruiserRings.  5.1.2 \nWarehouse data structure We implement the warehouse data structure as a custom lock-free list, called \nCruiserList. CruiserList is a linked list of segments, each of which is a linked list itself with a never-removed \ndummy node as the segment head, as shown in Figure 4 and 5. The basic form of CruiserList contains one \nsegment, which supports a single insert thread to insert nodes and a single traverse thread to traverse \nthe list concurrently. The method CheckNode is invoked in Traverse to check each node and returns whether \nthe node should be deleted. New nodes are always inserted between the dummy node and the .rst genuine \nnode (the node linked immediately after the dummy node). If the .rst genuine node is determined to be \ndeleted (Line 63), it should not be removed directly, as it may otherwise lead to list corruption or \nnode loss. Speci.cally, if the .rst genuine node is removed between the execution of Line 51 and Line \n52 when a new node is being inserted, the list is corrupted, because the newly inserted node has been \nlinked to a deleted node. An\u00adother situation is when the .rst genuine node M is determined to be deleted, \na new node N is inserted, which is not known by the traverse thread. Consequently, by removing node M, \nthe dummy node is linked to the node after node M, such that node N is lost. The contention between node \ninsertion and deletion is a common problem in lock-free data structures. A conventional method to resolve \nthe contention problems in non-blocking algorithms is to use CAS in a loop to insert or delete a node, \nas in the CruiserRing method AddCruiserRing (see Fig\u00adure 3). However, CAS is relatively expensive and \ndue to contention concurrent operations may experience frequent failure and retry of CAS instructions, \nwhich delays the progress of concurrent threads. In CruiserList, we essentially eliminate the contention \nand thus CAS is not needed, as shown in the method Traverse. In our al\u00ad 1 struct Ring { 2 Element *buffer; \n3 unsigned int size; 4 unsigned int head, tail; 5 Ring *next; // next Ring 6 }; 7 8 struct CruiserRing \n{ 9 Ring *pr, *cr; // producer ring and consumer ring 10 CruiserRing *next; // next CruiserRing 11 }; \n12 13 CruiserRing *Head; // head of CruiserRing list 14 15 NEXT(index, size) { return (index + 1) % size; \n} 16 17 Enqueue(pr, data) { 18 if (NEXT(pr->head, pr->size) == pr->tail) { 19 newRing = createRing(2 \n* (pr->size)); 20 if (null == newRing) 21 return failure; 22 pr->next = newRing; 23 pr = newRing; 24 \n} 25 pr->buffer[pr->head] = data; 26 pr->head = NEXT(pr->head, pr->size); 27 return success; 28 } 29 \n30 Dequeue(cr, data) { 31 if (cr->head == cr->tail) { 32 if (null == cr->next) 33 return failure; 34 \ntemp =cr;cr =cr->next; 35 destroy(temp); 36 return Dequeue(cr, data); 37 } 38 data = cr->buffer[cr->tail]; \n39 cr->tail = NEXT(cr->tail, cr->size); 40 return success; 41 } 42 43 AddCruiserRing(cruiserRing) { 44 \ndo { 45 cruiserRing->next = oldValue = Head; 46 } while (!CAS(&#38;Head, oldValue, cruiserRing)); 47 \n} Figure 3. CruiserRing (Express data structure). Figure 4. CruiserList. gorithm, the .rst genuine node \nis never removed until new nodes have been inserted, thus new nodes can always be inserted between the \ndummy node and the .rst genuine node safely by the insert thread, while the traverse thread never touches \nthe link between the dummy node and the .rst genuine node. Therefore, the node inser\u00adtion and deletion \noperations essentially play in different arenas, and thus have no contention. Speci.cally, when the .rst \ngenuine node is determined to be deleted, it is marked as to-be-deleted by calling the method MarkDelete, \nwhich .lls a special null value in the data .eld of the node, or sets the least signi.cant bit (LSB) \nof the next pointer of the node, as the node address is usually word-aligned and the LSB of  48 Node \n*head; // head of CruiserList 49 50 Insert(dummy, node) { 51 node->next = dummy->next; 52 dummy->next \n= node; 53 } 54 55 Traverse() { 56 Node *prev, *cur, *next; 57 cur = leftBoundary->next; 58 if (cur == \nnull) 59 return; 60 61 /*Process the .rst genuine node*/ 62 if (!IsMarkedDelete(cur)) 63 if (CheckNode(cur) \nreturns PLEASE DELETE ME) 64 /*Node removal is deferred to avoid contention*/ 65 MarkDelete(cur); 66 \n67 /* Process the rest genuine nodes */ 68 prev = cur; cur = cur->next; 69 while (cur != rightBoundary) \n{ 70 next = cur->next; 71 if (IsMarkedDelete(cur) || 72 CheckNode(cur) returns PLEASE DELETE ME) { 73 \nprev->next = next; 74 DeleteNode(cur); 75 } 76 else 77 prev = cur; 78 cur = next; 79 } 80 } 81 82 AddSegment() \n{ 83 Node *newDummy = AllocateDummyNode(); 84 do { 85 newDummy->next = oldValue = head; 86 } while (!CAS(&#38;head, \noldValue, newDummy)); 87 return newDummy; 88 }   Figure 5. CruiserList (Warehouse data structure). \nthe next pointer is thus not used. Then the marked node is removed in a future round of traverse when \nit is no longer the .rst genuine node. Figure 6 shows the process of removing the .rst genuine node A. \nIt is .rst marked, but not deleted. After a new node C is inserted, it will be deleted shortly. It is \npossible that no more new nodes are inserted and the marked node sticks in the list; however, there is \nonly one such node in a segment and normally this occurs only in the residual period of program execution. \nNote that the user buffer is freed; only the .rst metadata node may stay alive after the corresponding \nbuffer is released. We can resolve this using CAS if it becomes a serious issue. The Insert method inserts \na node, just as in a single-threaded list, between the never-removed dummy node and the .rst genuine \nnode which is never removed directly. The technique of marking a node as to-be-deleted was .rst used \nin the lock-free FIFO queue algorithm [48] proposed by Prakash et al., then used in Harris s [26] and \nMichael s [40] lock-free lists, respectively. All of them use this technique to prevent new nodes from \nbeing linked to a marked node. As insertion and deletion may operate on the same node, contention still \nexists; and they rely on CAS. Our algorithm allows new nodes to be linked to a marked node. Only simple \nreadsand writes are needed. The basic CruiserList can be easily extended to multiple seg\u00adments using \nthe method AddSegment, so that it can support mul\u00adtiple insert and traverse threads. Each insert thread \nhas a thread\u00adprivate variable pointing to the dummy node of a different segment, MarkDelete(node A) \n A new node C is inserted Delete the marked node A Figure 6. Deletion of the .rst genuine node. into \nwhich this thread inserts nodes. On the other hand, the seg\u00adments can be partitioned into multiple disjoint \ngroups; each tra\u00adverse thread walks on a different group denoted by two thread\u00adprivate variables leftBoundary \nand rightBoundary, which point to the dummy nodes of segments. If there is only one traverse thread, \nits segment group consists of the whole CruiserList. For the sake of simplicity, the Traverse method \nin Figure 5 is only for one-segment groups. The time for a traverse thread to cruise through its segment \ngroup once is called a cruise cycle. Compared to general-purpose lock-free lists, CruiserList is highly \nef.cient and has the following advantages: (1) Wait-free access and zero-contention: Both insert and \ntraverse threads keep making progress, and node insertion and deletion are executed in different arenas; \n(2) No ABA problem: The ABA problem [30] is historically associated with CAS. It happens if in a thread \na shared location with a value A was read, then CAS comparing the current value of the shared location \nagainst A succeeds though it should not, as between the read and the CAS other threads change the value \nof the shared location from A to B and back to A again. The only CAS in Line 86 has no ABA problem, because \nit is impossi\u00adble for head, which was changed from the address of the dummy node A to that of the dummy \nnode B, to change back to A without removing any dummy nodes; and (3) No special memory reclama\u00adtion \nneeded: For a typical lock-free data structure, when a node is removed by a thread, its memory cannot \nbe released immediately because other threads may be accessing it. So special memory reclamation mechanisms \nare needed, such as reference counters and hazard pointers [39]. On a given segment of the CruiserList, \nthe traverse thread is the only thread that deletes nodes, so it is not concerned with accessing nodes \nbeing released by other threads. It is not a problem for the insert thread either, as it only accesses \nthe content of the dummy node, which is never removed.  5.1.3 Applying CIC in Cruiser Cruiser uses the \nCIC mechanism to collect memory allocation in\u00adformation (see Figure 2). The malloc calls of user threads \nare hooked and memory allocation information is put on the Cruis\u00aderRings. The deliver thread moves the \ninformation from Cruiser-Rings to CruiserList, while the monitor thread calling Traverse of CruiserList \ncruises over buffers to detect over.ow according to the collected information in CruiserList. The buffer \nover.ow detec\u00adtion code is executed in CheckNode (see Figure 5), which returns PLEASE DELETE ME if the \nbuffer is found no longer alive. More details about CheckNode are described in Section 5.2. Cruiser is \nimplemented as a dynamic shared library to inter\u00adpose the malloc function family. It contains a constructor \n(initial\u00adization) function, which gets executed when the monitored program is started. Inside the constructor \nfunction, the keys are initialized with random numbers in /dev/urandom, the CruiserList is created and \ninitialized, and the deliver thread and the monitor thread are created, which share the same address \nspace as user threads. Each user thread creates its CruiserRing when it invokes its .rst malloc call. \nAll the memory blocks used by Cruiser (the data structures and keys) are allocated using mmap with two \ninaccessible guard pages [22] surrounding each of them, such that they cannot be over\u00ad.owed.    5.2 \nBuffer Release and Node Removal Once a buffer is freed, the node in the CruiserList containing the corresponding \nbuffer information becomes dated and should be removed; otherwise, buffer over.ow checks over the buffer \nmay incur false alarms or segmentation faults, as the buffer memory may have been reused or unmapped. \nRemoving dated nodes inside free calls may signi.cantly delay user threads. We address the problem with \nthe following two approaches; both enable the monitor thread to tidy-up CruiserList. The .rst approach \nis a lazy two-step memory reclamation al\u00adgorithm. First, when a free call is intercepted, the target \nbuffer is marked with a tombstone .ag by encrypting the head canary with another key, called the release \nkey;the free call returns without re\u00adleasing the buffer, which becomes a zombie buffer. Second, when \nthe monitor thread checks the buffer and .nds it marked with a tombstone, the method CheckNode in Figure \n5 releases the buffer and returns PLEASE DELETE ME. This approach removes dated information effectively \nwithout incurring false alarms or segfaults. The drawback is that buffer release is delayed; however, \nsince all zombie buffers are bound to be released no later than the next cruise cycle, the delay should \nbe reasonably short. The second approach does not delay memory reclamation; how\u00adever, it requires some \nchanges about the head and tail canaries and needs the assistance of recovery techniques. The head canary \n.eld is .lled with a random number (rather than the encrypted size value), while the tail canary is the \nencryption (XOR) result of the head canary value and a key. The random number along with the buffer address \nis collected in CruiserList. Inside the free call, the target buffer is checked against buffer over.ow \nby decrypting the tail canary and comparing with the head canary.2 If they are dif\u00adferent, a buffer over.ow \nis detected; otherwise the head canary is set as zero, after which the buffer is released and the free \ncall re\u00adturns. When the monitor thread checks a buffer and .nds the num\u00adber stored in the head canary \nis not the same as that stored in the CruiserList, it assumes the buffer has been released and then the \ncorresponding dated node is removed from the CruiserList. After a buffer is released and reused, the \nmemory location of the origi\u00adnal head canary may happen to be written with the same value as that before \nthe buffer was released, so that when the monitor thread checks the node using the dated buffer information, \nit would incor\u00adrectly determine this buffer is still alive and thus false alarms are possible; however, \nthe probability is extremely low (in 64-bit OS, it is 1/264), which can be safely ignored in practice. \nThree scenarios need to be considered for the second approach. First, when a buffer is tampered due to \nan over.ow occurred in its preceding adjacent buffer, it would be incorrectly determined as a released \nbuffer by the monitor thread; however, this does no harm and as the adjacent buffer is under surveillance, \nthe over.ow can still be detected. Second, when a buffer is under.owed, the monitor thread would also \ntreat it as a released buffer. Under.ows are rare compared to over.ows; moreover we can address the problem \nby saving the buffer size in the CruiserList node, against which the size .eld of each buffer is checked \nby the monitor thread in CheckNode to detect under.ows. 2 If the size .eld has been corrupted, the tail \ncanary cannot be located cor\u00adrectly. As a result, the read of the tail canary may incur segfault, which, \nhowever, essentially exposes buffer over.ows. If necessary, the same re\u00adcovery technique described here \ncan be used to deal with segfault.  Third, when the monitor thread checks a buffer that has been re\u00adleased \nand the corresponding memory page(s) has been unmapped, a segfault is triggered. The problem can be addressed \nusing some recovery techniques [47]. In Linux, a SIGSEGV signal handler can be installed .rstly. Each \ntime before the monitor thread accesses a buffer, it calls sigsetjmp to save the calling environment. \nOnce a SIGSEGV signal is triggered due to an invalid access, the monitor thread is trapped to the SIGSEGV \nhandler, and the calling envi\u00adronment can be recovered by calling siglongjmp. Windows also has similar \nrecovery mechanism called Structured Exception Han\u00addling [41]. Cruisers with the two approaches are called \nLazy Cruiser and Eager Cruiser, respectively. We have implemented both in Linux.  5.3 Extensions and \nOptimizations 5.3.1 Extensions Flexible deployment options: The deployment of Cruiser is .ex\u00adible. One \nmethod is to implement Cruiser as a dynamic shared li\u00adbrary. By setting the LD PRELOAD environment variable \nto the path of the Cruiser library, an administrator can selectively enable Cruiser for certain applications. \nWith this method the malloc func\u00adtion family are interposed by Cruiser, which invokes the memory allocation \nfunctions in the system library to enforce dynamic mem\u00adory allocation, thus no system library is altered. \nThis is the deploy\u00ading method we adopt in the experiments. A second method is to integrate Cruiser with \nthe system dy\u00adnamic library for dynamic memory allocation. The advantage is that memory and performance \noverhead can be reduced. For exam\u00adple, the overhead due to malloc function family interposition can be \navoided; some memory allocators, such as dlmalloc [36], place the buffer size information in the beginning \nof each chunk, so Cruiser does not need to maintain that information additionally. A third method is \nto implement Cruiser as a static library and integrate it into the compiler. Considering the two methods \nabove cannot be applied to statically linked applications, the third method is complementary to them. \nRegardless of the deploying method, Cruiser has no effect on applications that perform their own mem\u00adory \nmanagement, neither can it detect buffer over.ows inside a structure currently, which is a limitation \nshared by other techniques that detect buffer over.ows at the level of memory blocks [2, 5, 19, 22, 27, \n51, 68]. However, Cruiser can be extended to monitor buffers inside a struct by inserting canary words. \nMore Cruiser threads: Although our experiments show that the Cruiser con.guration with one deliver thread \nand one monitor thread is suf.cient for common applications, it may be desirable to extend Cruiser with \nmultiple deliver and monitor threads. For ex\u00adample, there may be many user threads requesting dynamic \nmem\u00adory intensively that a single deliver thread cannot match the speed of buffer allocation; or the \nCruiserList is so long that it takes much time for a monitor thread to traverse through the CruiserList \nonce. As both CruiserList and the list of CruiserRings support multiple threads, Cruiser can be easily \nextended with more cruiser threads to protect various applications.  5.3.2 Optimizations Memory reuse: \nTo mitigate memory allocation intensity and speed up node insert and delete in CruiserList, a ring buffer \nis adopted to store the addresses of removed nodes with the monitor thread as the producer and the deliver \nthread as the consumer. Nodes removed from CruiserList are not deleted but stored in the ring unless \nit is full. Accordingly when the deliver thread needs a node, it .rst tries to retrieve a node from the \nring; only when the ring is empty, a new node is allocated. The simple ring buffer can be replaced with \nother advanced wait-free queues, such as a CruiserRing, to support more ef.cient nodes buffering strategy. \n On the other hand, each user thread requesting dynamic mem\u00adory owns a CruiserRing. Considering some \napplications fork and kill threads frequently, instead of allocating and releasing Cruis\u00aderRings intensively, \nwe reuse CruiserRings. A Boolean .ag indi\u00adcating whether the CruiserRing is available for reuse is added \ninto the CruiserRing structure. As the deliver thread traverses along the list of CruiserRings, if it \ndetects a user thread has exited, it marks the related CruiserRing as available for reuse. When a user \nthread needs a CruiserRing, it will try to reuse an available CruiserRing before allocating a new one. \nBackoff strategies: Although our experiments show that Cruiser imposes low overhead, the performance \ncan be further improved with backoff strategies, for example, by inserting NOP instructions or sleep \ncalls inside the monitor thread. Reduced monitor intensity leads to less memory access interference, \nthus decreases perfor\u00admance impact. Cruiser can also switch to monitor buffers selec\u00adtively, for example, \nbuffers involved in data .ows stemming from networks or user inputs. For Lazy Cruiser, it is a good choice \nto ig\u00adnore large buffers and hence release them inside free calls directly under intense memory pressure. \nMore advanced monitor strategies based on computational resource dynamics can be adopted as well. Variants \nof the deliver thread: In Cruiser, the deliver thread is busy polling CruiserRings. Actually it can go \nto sleep when there is no information to deliver and be waken up by user threads via signals. To avoid \nsending a signal per malloc call, a global status .ag indicating whether the deliver thread is asleep \ncan be used. The .ag is set as awake or asleep by the deliver thread; a wake-up signal is sent to the \ndeliver thread only when it is asleep. Another variant is to combine the deliver thread and the monitor \nthread; we can have the hybrid thread delivering information and monitoring nodes alternatively, such \nthat only one busy thread is needed and the data structures can be further simpli.ed. The drawback is \nthat the monitoring may be interrupted frequently. Better ring algorithms: Based on Lamport s ring [35], \nsome other ring algorithms have been proposed [24, 37]. We used the ring algorithm proposed by Lee et \nal. [37] in our experiments to mitigate the false sharing problem in Lamport s ring.   6. Evaluation \nWe evaluated the effectiveness of Cruiser, its performance and memory overhead, and analyzed the detection \nlatency issue. This section presents our results. 6.1 Effectiveness We evaluated the effectiveness of \nCruiser with two experiments. Our .rst experiment was carried out using the SAMATE Reference Dataset \n(SRD) [44] maintained by NIST. The dataset contains 12 test cases on heap-based buffer over.ows due to \ncontiguous writes, which are caused by assignments, memcpy, strcpy, snprintf,etc., and another 10 test \ncases that .x the over.ows. Cruiser detects all the over.ows in the 12 test cases and there is no false \npositive for the 10 sound test cases. The second experiment tested the effectiveness against both well-known \nhistoric exploits (wu-ftpd [57], Sudo [61], CVS [55]) and recently published vulnerabilities (libHX [58], \nLynx [59], Fire\u00adfox [56]), shown in Table 2. Each vulnerable program was run with Cruiser and attacks \nwere launched on them. Each attack was exe\u00adcuted 50 times and Cruiser detected all the over.ows, duplicate \nand invalid frees. These experiments demonstrate that our technique is effective in detecting not only \nheap-based buffer over.ows but also memory leakage and heap corruption including duplicate freesand freeson \ninvalid pointers. Therefore, Cruiser is a good candidate for .nding heap corruption and memory leakage \ndefects during development as well as monitoring production systems.  Program Vulnerability wu-ftpd \n2.6.1 Free calls on uninitialized pointers Heap-based buffer over.ow Sudo 1.6.4 Duplicate free calls \nCVS 1.11.4 Heap-based buffer over.ow libHX 3.5 Heap-based buffer over.ow Lynx 2.8.8 dev.1 Heap-based \nbuffer over.ow Firefox 3.0.1 Table 2. The effectiveness experiment against real-world vulnera\u00adbilities. \n2 Lazy Cruiser Eager Cruiser DieHarder1.8 1.6 1.4 1.2 1 0.8 0.6 0.4 0.2 0 Normalized execution time \nFigure 7. Execution time with Cruiser (normalized by the execu\u00adtion time without Cruiser), compared with \nDieHarder. The last set of bars is the geometric mean of the execution time of all bench\u00admarks. 6.2 \nPerformance and Memory Overhead We evaluated the performance and memory overhead of Cruiser us\u00ading the \nSPEC CPU2006 Integer benchmark suite. The experiments were performed on a Dell Precision Workstation \nT5500 with two 2.26GHz Intel Xeon E5507 quad-core processors and 4GB of RAM running 32-bit Linux 2.6.24. \nCruiser was implemented as a dynam\u00adically linked library and loaded by setting the LD PRELOAD en\u00advironment \nvariable. In all the experiments, Cruiser created one de\u00adliver thread and one monitor thread with the \noptimizations memory reuse and better ring algorithms enabled. We ran each experiment three times and \npresent the average result. The variance was negli\u00adgible. We evaluated both Lazy Cruiser and Eager Cruiser, \nand com\u00adpared with DieHarder [45], which also provides probabilistic heap safety. Figure 7 shows the \nexecution time of the two implementa\u00adtions normalized by the execution time of original programs. The \naverage performance overhead is 12.5% for Lazy Cruiser and 5% for Eager Cruiser, while DieHarder imposes \n20% penalty on av\u00aderage. For the majority of the benchmark programs, the overhead imposed by Cruiser \nis negligible. The perlbench has the highest overhead due to its signi.cantly dense dynamic memory alloca\u00adtion. \nEager Cruiser performs generally better than the lazy version, mainly because the former allows immediate \nmemory reclamation and reuse. The experiments show that Cruiser can be deployed in .eld practically. \nIn addition to the three-word tag associated with each buffer, the memory overhead of Cruiser is mainly \ndue to its data structures CruiserRings and CruiserList. For Lazy Cruiser, zombie buffers are another \nsource. To precisely analyze the memory overhead, as shown in Table 3, we measured the maximum size of \nCruiserRing and the maximum and average lengths of CruiserList normalized by the live buffer counts at \nsample time (we sampled at the end of each cruise cycle), respectively, from which we can get the percent\u00adage \nof dated nodes and zombie buffers. As the CruiserList length is normalized, the maximum length can be \nless than the average  Bench-Maximum Maximum Average Average mark CruiserRing CruiserList CruiserList \ncruise size length length cycle (\u00b5s) perlbench 8192 (1024) 1.06 (1.16) 1.02 (1.06) 4.3e4 (1.2e5) bzip2 \n1024 (1024) 1.00 (1.00) 1.00 (1.00) .43 (1.2) gcc 2048 (2048) 1.02 (1.05) 1.00 (1.01) 1.3e3 (3.5e3) mcf \n1024 (1024) 1.00 (1.00) 1.00 (1.00) .35 (.59) gobmk 1024 (1024) 1.00 (1.00) 1.00 (1.00) .37 (1.6) hmmer \n1024 (1024) 1.11 (1.29) 1.00 (1.00) 26 (1.6e2) sjeng 1024 (1024) 1.11 (1.00) 1.00 (1.00) .36 (0.82) libquantum \n1024 (1024) 1.00 (1.00) 1.00 (1.00) .16 (0.49) h264ref 1024 (1024) 1.00 (1.00) 1.00 (1.00) 3.3e2 (1.7e3) \nomnetpp 2048 (1024) 1.08 (1.08) 1.02 (1.08) 9.8e4 (3.2e5) astar 4096 (2048) 1.04 (1.06) 1.00 (1.00) 19 \n(88) xalancbmk 2048 (1024) 1.00 (1.00) 1.02 (1.07) 7.3e4 (1.5e5) Table 3. Memory overhead and cruise \ncycle (Results of Ea\u00adger Cruiser are enclosed in parentheses; the maximum/average CruiserList lengths \nare normalized by the maximum/average heap buffer counts, respectively). one, as in the case of xalancbmk. \nThe initial CruiserRing has 1024 elements; the size of each element is one word in Lazy Cruiser and two \nwords in Eager Cruiser, respectively. For the majority of bench\u00admarks, the CruiserRing does not grow, \nwhile the maximum Cruis\u00aderRing in perlbench test with Lazy Cruiser experienced 3 times of growth (recall \nthat the ring grows exponentially). The length of CruiserList is close to the count of live buffers on \nheap. In other words, the percentage of dated nodes and zombie buffers is low, and on average it is negligible. \n 6.3 Scalability To evaluate the scalability of our approach on multithreaded pro\u00adgrams, we compared \nthe throughputs of the Apache web server with and without Cruiser. We ran Apache 2.2.8 on the same work\u00adstation \nspeci.ed in Section 6.2, and used ApacheBench 2.3, which ran on a machine with a 2.4GHz Intel Core 2 \nDuo processor, 4GB of RAM, and Mac OS X 10.6.4, to measure the Apache through\u00adput over a Gbit LAN network. \nWe issued repeated requests for a 5KB HTML page with various numbers of concurrent clients. We observed \nthat Apache allocated two heap buffers per request; ApacheBench issued one million requests for each \nconcurrency number. Figure 8 shows the throughputs of Apache (labeled as baseline) and Apache with Lazy \nCruiser and Eager Cruiser, respec\u00adtively. The throughputs of Apache with the two versions of Cruiser \nare almost the same. The maximum 3% slowdown appears around concurrency number 7, while the average slowdown \nis negligible. For concurrency numbers greater than 11, the throughputs with and without Cruiser are \nalmost identical. We measured until concur\u00adrency number 110 when the client s CPU was saturated, and \nthe throughput slowdown remained negligible. The machine running Apache has 8 cores in processors, thus \nthe Cruiser threads com\u00adpete processor time since concurrency number 6; however as the working threads \nin Apache increase, the percentage of processor time used by the Cruiser threads decreases, and thus \nthe slowdown declines. 6.4 Detection Latency Heap-based buffer over.ows can be divided into two classes \n[51]. One class of attacks alter memory allocators metadata. Exploits in this class are often achieved \nby releasing a corrupted buffer [33]. Cruiser defeats this kind of exploits completely, as all buffers \nare checked before release. The other class comprises attacks that over.ow a buffer to al\u00adter the content \nof its adjacent memory block. This kind of exploits 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n20 Concurrency Figure 8. Throughtputs of the Apache web server for varying numbers of concurrent requests. \nare not achieved until the corrupted content is used; the attacks are not detected until corrupted buffers \nare checked by a monitor thread. Like DieHarder, Cruiser provides probabilistic heap safety for this \nkind of attacks. Assume an attack takes time E to achieve the exploit after canary smashing and a cruise \ncycle takes time C, if E = C, Cruiser can detect the over.ow before the exploit is achieved; otherwise, \nassume the detection latency (elapsed time since the over.ow until detection) is uniformly distributed \non the interval (0,C], the probability P for Cruiser to detect an exploit be\u00adfore it completes is E/C. \nAs shown in Table 3, with Lazy Cruiser, 5 of the 12 benchmarks average cruise cycles are shorter than \n0.5\u00b5s, and 8 of them are not longer than 0.5ms; with Eager Cruiser, 5 benchmarks average cruise cycles \nare not longer than 1.6\u00b5s, and 7 of them are shorter than 0.2ms. The average cruise cycles for Apache \ntest are 16\u00b5s and 78\u00b5s for Lazy and Eager Cruisers, re\u00adspectively. Considering C = NT ,where N is the \nnumber of nodes in the CruiserList and T is the average time for a monitor thread to check a node, we \ncan expect a high prevention probability by keep\u00ading N small. One way is to divide the CruiserList into \nseveral seg\u00adment groups and create the same number of monitor threads, each of which cruises over a shorter \npart of CruiserList. For example, by dividing the CruiserList into two parts and running one more mon\u00aditor \nthread on either part in omnetpp test, the average cruise cycle decreased by 42% and 47% for Lazy Cruiser \nand Eager Cruiser, respectively. Another way is to only monitor suspicious buffers, for example, those \nbuffers involved in data .ows that stem from net\u00adworks or user inputs. Considering Cruiser shares the \nsame address space as user pro\u00adgrams, an attacker with arbitrary memory access privileges of the compromised \nprogram can bypass Cruiser theoretically. Otherwise a reliable and precise attack against Cruiser is \nhard to build. In Cruiser, the canaries of a buffer are the XOR result of the buffer s address, size \nand the keys which were initialized using random numbers, so it is dif.cult to predict or restore a canary. \nFor ex\u00adample, an elaborate attack that exploits other vulnerabilities, such as format string [50], to \nobtain the keys still needs the target buffer size and address information to calculate its canaries. \nBlind access for Cruiser s data structures will normally incur segfault, as they are surrounded by inaccessible \nguard pages. The function pthread kill can be interposed by Cruiser to prevent Cruiser threads from be\u00ading \nkilled, and Cruiser threads can detect the liveness of each other when running, thus it is very unlikely \nto subvert Cruiser. Detection can be evaded by terminating the process, which, however, explic\u00aditly exposes \nthe attack and is not a usual way of real attacks.   7. Software Cruising We have applied the software \ncruising technique to ef.cient heap over.ow detection by moving the detection work out of user threads. \nPotentially all the inlined veri.cation, monitoring and re\u00adsource reclamation work can be migrated from \nuser threads to one or more monitor threads for concurrent execution in background. This section discusses \nother applications of software cruising, some of which we are currently working on as an extension of \nthis work.  Background Software Monitoring: Depending on the security policies enforced, inlined security \nenforcement may incur high per\u00adformance overhead. Software cruising takes a very different way by moving \ninlined security enforcement out of user threads and executing them in concurrent monitor threads, which \ncan reduce considerable performance overhead. Although synchronization and race conditions between user \nand monitor threads are potential challenges, they can be solved using lock-free data structures as in \nCruiser. For example, we can implement a call trace collector by instrumenting the call instruction in \nthe binary and placing the tar\u00adget address in a CruiserRing. A concurrent monitor thread analyzes the \ncall trace to evaluate whether speci.c control-.ow policies are followed. As simple examples, some control \ntransfers are suspi\u00adcious; or a control-.ow policy may require that a certain function is called no more \noften than another function (such restrictions may be desirable to prevent some confused deputy attacks \n[25]). The monitor thread can detect abnormalities based on the call trace and a .nite automaton or simple \ncounting. Other straightforward appli\u00adcations include integrity-checking of important program structures \nsuch as the Global Offset Table. OS Kernel Cruising: It is desirable to adopt software cruising to monitor \nOS kernel memory integrity and other safety and live\u00adness properties. We plan to develop a prototype \nthat can monitor integrity of OS kernel memory. One of the challenges of cruising OS kernels is how to \nminimize the impact on the kernel memory layout since kernel code contains many low-level programming \nid\u00adioms that rely on certain memory layouts. One way to solve this problem is to selectively monitor \nsome buffers and make manual transformation. Concurrent Resource Reclamation: Software Cruising can also \nbe applied to implement ef.cient resource reclamation, for example safe memory reclamation for lock-free \ndata structures. For lock-free dynamic objects, when a thread removes a node, it is possible that some \nother thread has earlier read a reference to that node, and is about to access its contents, therefore \nthe memory occupied by the node should not be released or reused directly. When designing lock-free data \nstructures, safe memory reclamation is a major concern. Recent progress was made by Michael [39]. The \ncore idea is to associate a number of pointers, called hazard pointers, with each thread. A hazard pointer \npoints to a node that may be accessed later by that thread; whenever a thread frees a retired node, it \nhas to scan hazard pointers of other threads to make sure the node is not pointed to by any of the hazard \npointers. To achieve a low amortized overhead, a thread does not free retired nodes until it accumulates \na certain number of retired nodes. The inlined batch processing of retired nodes inevitably delays user \nthreads and memory reclamation. The problem can be solved elegantly by deploying a concurrent thread, \nwhich takes over the work of memory reclamation by scanning hazard pointers to determine which retired \nnodes can be released safely. The original methodology is complementary to this solution in case too \nmany retired nodes are accumulated.  8. Conclusion We have introduced a novel technique, software cruising.The \ncore idea is to mitigate inlined veri.cation, monitoring and resource reclamation work from user threads \nto a concurrent monitor thread. Through lock-free data structures and non-blocking algorithms the monitor \nthread and user threads can be synchronized with low overhead and high scalability. We have applied this \ntechnique to Cruiser, a dynamic heap\u00adbased buffer over.ow detector on the Linux platform. It is straight\u00adforward \nto adapt Cruiser to other platforms such as Windows and Mac. We have evaluated Cruiser on a variety of \nprograms to show its effectiveness. The performance overhead of monitoring SPEC CPU2006 benchmark is \nabout 5% on average, and negligible in the majority of cases. Cruiser also scales well on multithreaded \nprograms; the slowdown on the Apache throughput with different numbers of concurrency is negligible on \naverage and 3% maximal. The experiments show that Cruiser is feasible to be applied.  Acknowledgments \nThe authors would like to thank Ori Shalev and Nir Shavit for shar\u00ading the non-blocking hash table code \n[62], Maged M. Michael for pointing to us the open source project Amino Concurrent Build\u00ading Blocks [46], \nAndrew Appel and Xi Xiong for their valuable comments, and the anonymous reviewers for their comments \nthat helped shape the .nal version of this paper. This work was partially supported by AFOSR FA9550-07\u00ad1-0527 \n(MURI), ARO W911NF-09-1-0525 (MURI), NSF CNS\u00ad0905131, and AFRL FA8750-08-C-0137.  References [1] M. \nAbadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-.ow integrity. In CCS 05, pages 340 353. [2] \nP. Akritidis, M. Costa, M. Castro, and S. Hand. Baggy bounds check\u00ading: an ef.cient and backwards-compatible \ndefense against out-of\u00adbounds errors. In Usenix Security 09, pages 51 66. [3] AlephOne. Smashing the \nstack for fun and pro.t. Phrack, 7(49), 1996. [4] T. M. Austin, S. E. Breach, and G. S. Sohi. Ef.cient \ndetection of all pointer and array access errors. In PLDI 04, pages 290 301. [5] K. Avijit and P. Gupta. \nTied, libsafeplus, tools for runtime buffer over.ow protection. In Usenix Security 04, pages 4 4. [6] \nE. G. Barrantes, D. H. Ackley, T. S. Palmer, D. Stefanovic, and D. D. Zovi. Randomized instruction set \nemulation to disrupt binary code injection attacks. In CCS 03, pages 281 289. [7] E. Bhatkar, D. C. Duvarney, \nand R. Sekar. Address obfuscation: an ef.cient approach to combat a broad range of memory error exploits. \nIn Usenix Security 03, pages 105 120. [8] Bulba and Kil3r. Bypassing StackGuard and StackShield. Phrack,10 \n(56), May 2000. [9] M. Castro, M. Costa, and T. Harris. Securing software by enforcing data-.ow integrity. \nIn OSDI 06, pages 147 160. [10] CERT Advisory, CA-2001-19 CodeRed worm. [11] CERT Advisory, CA-2002-33 \nHeap Over.ow Vulnerability in Mi\u00adcrosoft Data Access Components. [12] CERT Advisory, CA-2003-20 SQLSlammer \nworm. [13] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer. Non-control\u00addata attacks are realistic \nthreats. In Usenix Security 05, pages 177 192, 2005. [14] T. Chiueh and F. Hsu. RAD: A compile-time solution \nto buffer over.ow attacks. In ICDCS 01, pages 409 417. [15] M. Conover. w00w00 on heap over.ows, 1999. \nwww.w00w00.org/ .les/articles/heaptut.txt. [16] C. Cowan and S. Beattie. PointGuard: protecting pointers \nfrom buffer over.ow vulnerabilities. In Usenix Security 03, pages 91 104. [17] C. Cowan and C. Pu. StackGuard: \nautomatic adaptive detection and prevention of buffer-over.ow attacks. In Usenix Security 98, pages 63 \n78, January 1998. [18] B. Cox, D. Evans, A. Filipi, J. Rowanhill, W. Hu, J. Davidson, J. Knight, A. Nguyen-Tuong, \nand J. Hiser. N-variant systems: a se\u00adcretless framework for security through diversity. In Usenix Security \n06, pages 105 120.  [19] E. D.Berger. HeapShield: Library-based heap over.ow protection for free. Tech. \nreport, Univ. of Massachusetts Amherst, 2006. [20] N. Dor, M. Rodeh, and M. Sagiv. CSSV: towards a realistic \ntool for statically detecting all buffer over.ows in C. In PLDI 03, pages 155 167, June 2003. [21] T. \nDurden. Bypassing PaX ASLR protection. Phrack, 2002. [22] E. Fence. Malloc debugger. http://directory.fsf.org/project/ElectricFence/. \n[23] M. Frantzen and M. Shuey. Stackghost: Hardware facilitated stack protection. In Usenix Security \n01, pages 55 66. [24] J. Giacomoni, T. Moseley, and M. Vachharajani. Fastforward for ef.cient pipeline \nparallelism: a cache-optimized concurrent lock-free queue. In PPoPP 08, pages 43 52. [25] N. Hardy. The \nconfused deputy. ACM Oper. Syst. Rev., 22(4):36 38. [26] T. L. Harris. A pragmatic implementation of \nnon-blocking linked lists. In DISC 01, pages 300 314. [27] R. Hastings and B. Joyce. Purify: Fast detection \nof memory leaks and access errors. In the Winter 1992 Usenix Conference, pages 125 136. [28] M. Herlihy. \nA methodology for implementing highly concurrent data structures. In PPoPP 90, pages 197 206. [29] IBM. \nProPolice detector. www.trl.ibm.com/projects/security/ssp/. [30] IBM System/370 Extended Architecture, \nPrinciples of Operations. IBM Publication No. SA22-7085, 1983. [31] T. Jim, J. G. Morrisett, D. Grossman, \nM. W. Hicks, J. Cheney, and Y. Wang. Cyclone: A safe dialect of C. In Usenix ATC 02, pages 275 288, June \n2002. [32] R. W. M. Jones and P. H. J. Kelly. Backwards-compatible bounds checking for arrays and pointers \nin C programs. In the International Workshop on Automatic Debugging, 1997. [33] M. Kaempf. Vudo malloc \ntricks. Phrack, 11(57), 2001. [34] V. Kiriansky, D. Bruening, and S. P. Amarasinghe. Secure execution \nvia program shepherding. In Usenix Security 02, pages 191 206. [35] L. Lamport. Proving the correctness \nof multiprocess programs. IEEE Trans. Softw. Eng., 3(2):125 143, 1977. [36] D. Lea. dlmalloc. http://g.oswego.edu/. \n[37] P. Lee, T. Bu, and G. Chandranmenon. A lock-free, cache-ef.cient multi-core synchronization mechanism \nfor line-rate network traf.c monitoring. In IPDPS 10, pages 1 12. [38] R. Lemos. Counting the cost of \nSlammer, 2003. http://news.cnet.com/ Counting-the-cost-of-Slammer/2100-1002 3-982955.html. [39] M. M. \nMichael. Hazard pointers: Safe memory reclamation for lock\u00adfree objects. IEEE Trans. Parallel Distrib. \nSyst., 15(6):491 504, 2004. [40] M. M. Michael. High performance dynamic lock-free hash tables and list-based \nsets. In SPAA 02, pages 73 82. [41] MSDN. Structured exception handling. http://msdn.microsoft.com/ en-us/library/ms680657(VS.85).aspx. \n[42] G. C. Necula, J. Condit, M. Harren, S. McPeak, and W. Weimer. CCured: type-safe retro.tting of legacy \nsoftware. ACM Trans. Pro\u00adgram. Lang. Syst., 27(3):477 526, 2005. [43] NIST. National Vulnerability Database. \nhttp://nvd.nist.gov/. [44] NIST. SAMATE Reference Dataset. http://samate.nist.gov/SRD. [45] G. Novark \nand E. D. Berger. Dieharder: securing the heap. In CCS 10, pages 573 584. [46] Open Source project. Amino \nconcurrent building blocks. http://amino\u00adcbbs.sourceforge.net/. [47] Open Source Project. libsigsegv. \nhttp://libsigsegv.sourceforge.net/. [48] S. Prakash, Y.-H. Lee, and T. Johnson. A nonblocking algorithm \nfor shared queues using compare-and-swap. IEEE Trans. Comput., 43(5): 548 559, 1994. [49] M. Prasad and \nT. Chiueh. A binary rewriting defense against stack based buffer over.ow attacks. In Usenix ATC 03, pages \n211 224. [50] G. Richarte. Four different tricks to bypass StackShield and Stack-Guard protection. Tech. \nreport, Core Security Tech., 2002. [51] W. Robertson, C. Kruegel, D. Mutz, and F. Valeur. Run-time detection \nof heap-based over.ows. In LISA 03, pages 51 60. [52] O. Ruwase and M. S. Lam. A practical dynamic buffer \nover.ow detector. In NDSS 04, pages 159 169. [53] B. Salamat, T. Jackson, A. Gal, and M. Franz. Orchestra: \nintrusion detection using parallel execution and monitoring of program variants in user-space. In EuroSys \n09, pages 33 46. [54] SecuriTeam. http://www.securiteam.com/. [55] SecurityFocus. CVS directory request \ndouble free heap corruption, 2003. [56] SecurityFocus. Mozilla Firefox and Seamonkey regular expression \nparsing heap buffer over.ow, 2009. [57] SecurityFocus. Wu-ftpd .le globbing heap corruption, 2001. [58] \nSecurityFocus. libHX HX split() remote heap-based buffer over.ow, 2010. [59] SecurityFocus. Lynx browser \nconvert to idna() function remote heap based buffer over.ow, 2010. [60] SecurityFocus. http://www.securityfocus.com/. \n[61] SecurityFocus. Sudo password prompt heap over.ow, 2002. [62] O. Shalev and N. Shavit. Split-ordered \nlists: Lock-free extensible hash tables. J. ACM, 53(3):379 405, 2006. [63] Solar Designer. Non-executable \nuser stack, 1997. http://www.open wall.com/linux/. [64] StackShield. http://www.angel.re.com/sk/stackshield/, \nJanuary 2000. [65] The PaX project. http://pax.grsecurity.net/. [66] T. K. Tsai and N. Singh. Libsafe: \nTransparent system-wide protection against buffer over.ow attacks. In DSN 02, pages 541 541. [67] US-CERT. \nVulnerability notes database. www.kb.cert.org/vuls. [68] Valgrind. http://valgrind.org/. [69] D. Wagner, \nJ. S. Foster, E. A. Brewer, and A. Aiken. A .rst step towards automated detection of buffer overrun vulnerabilities. \nIn NDSS 00, pages 3 17. [70] J. Xu, Z. Kalbarczyk, S. Patel, and R. Iyer. Architecture support for defending \nagainst buffer over.ow attacks. In Workshop Evaluating &#38; Architecting Sys. Depend., 2002. [71] M. \nZhivich, T. Leek, and R. Lippmann. Dynamic buffer over.ow detection. In Workshop on the Evaluation of \nSoftware Defect Detection Tools, 2005.    \n\t\t\t", "proc_id": "1993498", "abstract": "<p>Security enforcement inlined into user threads often delays the protected programs; inlined resource reclamation may interrupt program execution and defer resource release. We propose <i>software cruising</i>, a novel technique that migrates security enforcement and resource reclamation from user threads to a concurrent monitor thread. The technique leverages the increasingly popular multicore and multiprocessor architectures and uses <i>lock-free</i> data structures to achieve <i>non-blocking</i> and efficient synchronization between the monitor and user threads. As a case study, software cruising is applied to the heap buffer overflow problem. Previous mitigation and detection techniques for this problem suffer from high performance overhead, legacy code compatibility, semantics loyalty, or tedious manual program transformation. We present a concurrent heap buffer overflow detector, Cruiser, in which a concurrent thread is added to the user program to monitor heap integrity, and custom lock-free data structures and algorithms are designed to achieve high efficiency and scalability. The experiments show that our approach is practical: it imposes an average of 5% performance overhead on SPEC CPU2006, and the throughput slowdown on Apache is negligible on average.</p>", "authors": [{"name": "Qiang Zeng", "author_profile_id": "81485641205", "affiliation": "Pennsylvania State University, University Park, PA, USA", "person_id": "P2690590", "email_address": "quz105@cse.psu.edu", "orcid_id": ""}, {"name": "Dinghao Wu", "author_profile_id": "81485644983", "affiliation": "Pennsylvania State University, University Park, PA, USA", "person_id": "P2690591", "email_address": "dwu@ist.psu.edu", "orcid_id": ""}, {"name": "Peng Liu", "author_profile_id": "81350592574", "affiliation": "Pennsylvania State University, University Park, PA, USA", "person_id": "P2690592", "email_address": "pliu@ist.psu.edu", "orcid_id": ""}], "doi_number": "10.1145/1993498.1993541", "year": "2011", "article_id": "1993541", "conference": "PLDI", "title": "Cruiser: concurrent heap buffer overflow monitoring using lock-free data structures", "url": "http://dl.acm.org/citation.cfm?id=1993541"}