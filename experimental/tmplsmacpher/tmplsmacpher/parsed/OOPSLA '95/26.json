{"article_publication_date": "10-01-1995", "fulltext": "\n Object Database Behavior, Benchmarks, and Performance Workshop Addendum Benjamin G. Zorn Akmal B. Chaudhri \nDepartment of Computer Science Systems Architecture Research Centre (SARC) University of Colorado Computer \nScience Department Boulder, CO 80309 USA The City University London, United Kingdom Abstract The goal \nof this workshop was to bring together peo-ple interested in object database performance and/or performance \ncharacterization. The participants of the workshop represent diverse groups including ODBMS vendors, \nODBMS users, and academics researching the performance of object databases. By bringing together a community \ninterested in these issues, our hope is that better measurements, better benchmarks, and ul-timately \nbetter performance characterizations will be developed. Organizers Rick Cattell Sun Microsystems, Inc. \nAkmal Chaudhri City University, London, UK Michael Franklin University of Maryland Eliot Moss University \nof Massachusetts Allen Otis Gemstone Systems Inc. Benjamin Zorn (chair) University of Colorado  Introduction \nApproximately 40 individuals attended this work-shop, representing 5 countries, 11 companies, and 18 \nuniversities and institutions. As we had hoped, the participants represented a very diverse set of in- \ndividuals and organizations, all with different and significant ideas about issues related to the per-formance \nand functionality of object database sys-tems. A primary goal of the workshop was to bring together in \none room individuals representing users, implementors, and researchers interested in the performance \nof object database systems. Once together, we attempted to find common ground in terms of understanding \nhow object databases behave, how to evaluate their performance, what functionality users expect from \nthese systems, and how users, implementors, and researchers can in-teract more closely in the future. \nIn introducing the workshop, the dependencies between the different communities were outlined. In particular, \nbesides the obvious transfer of money and systems between users and implementors, significant interactions \nbetween researchers, users, and implementors were noted. Researchers need a better understanding of how \nreal systems behave in order to design and evaluate new systems more effectively. The workshop was structured \nas a l-day mini-conference, with 2 morning sessions and 2 after-noon sessions. 19 speakers presented \nlo-20 minute talks on topics in the areas of evaluation and met-rics, analytic models, benchmarking, \nand perfor-mance evaluation. Significant opportunities for dis- cussion arose due to the small number \nof partici- pants. In an effort to expand communication and par- ticipation beyond the scope of the l-day \nworkshop, an effort was made to make as many of the work-shop materials as possible on-line via the \nInternet. As a result, electronic copies of all the position pa-pers, many of the presentations, additional \nrelated papers, the workshop program, and a list of partic- ipants is currently available at: http://uua.cs.colorado.edu/homes/ \nzorn/public,html/DDPSLA95-Workshop.htrnl The remainder of this addendum identifies sig-nificant issues \nthat arose during the discussions. These issues fall naturally into the categories of ODBMS requirements, \nODBMS performance, and ODBMS evaluation. ODBMS Requirements The following issues arose during the discussions \nthat relate to what capabilities ODBMS s need to support. Database Availability (7x24) Somnath Banerjee \nexpressed the importance of supporting fault-tolerant, on-line operation over a period of days and weeks. \nThe question of whether existing ODBMS systems can provide both high performance and fast recovery under \nthese conditions was raised. The Need for Garbage Collection Some users and implementors expressed the \nper-spective that most commercial ODBMS users view the objects in the database much the way they view \nexisting non-electronic record keeping. For exam-ple, an object represents a customer. With such a perspective, \nthe concept of connectivity-based storage reclamation is not appropriate (i.e., a com- pany would not \nexpect a physical folder represent-ing a customer to disappear if the customer decided to no longer order \nfrom the company). On the other hand, in uses of ODBMS s for manufacturing, where the database is being \nused to provide persis-tent semantics to program objects, connectivity-based reclamation is significant \nand important. What are ODBMS s being Used For? Akmal Chaudhri reported that based on a survey that \nhe conducted as part of his PhD thesis, a ma- jority of ODBMS applications are commercial and business-related. \nThis result brings in to question the appropriateness of using the 007 benchmark to compare performance, \nas the underlying data model represents a CAD-like application. Using ODBMS Systems for Management Workflow \nAnthony tem was Bonner described how being used for workflow an ODBMS management sys-in a genome laboratory. \nIssues that arise in such sys-tems include rapidly changing workflow processes, where processes can change \nin mid-stream. In addi- tion, the need to capture and query historical infor-mation about the process \nwas determined to be of significant importance. Such an application raises the important issue of dynamic \nschema evolution. The position paper by Ferrandina, Meyer, and Zi-cari investigates the performance of \nsuch function-ality in more detail. How to Migrate Existing RDBMS Applications George Copeland discussed \nthe issue of migrating traditional record database applications to include object semantics and support. \nBecause so many existing systems use RDBMS technology, as a practical matter it is far more likely that \nmany of these will be upgraded via a migration path than that they will be reimplemented. Using RDBMS \nTechnology to Support Objects Arthur Keller described an approach to providing object semantics using \nexisting relational database technology. The major advantage of this approach is that it leverages the \nknown, mature relational technology. Supporting Very Large Distributed Object Databases In the future, \nit is clear that very large collections of objects (e.g., the contents on the Web), or very large objects \n(e.g., image data) will be manipulated routinely by distributed object database systems. Donald Kossman \ndescribed work to investigate im-plementation approaches that will be required in such architectures. \nIn particular, he described the need for flexible execution policies (that dynam-ically decide where \nto carry out database opera-tions) and dynamic query optimization. 3 Improving ODBMS Application Performance \nIt was acknowledged that ODBMS performance relies critically on applications being suitably de-signed. \nSeveral of the presentations and discussions revolved around how to facilitate such design. Impact of \nApplication Design Martin Dragomirecky described his experiences in training new users of an ODBMS, and \npointed how important it is that the application programmer have a feel for the cost of different kinds \nof operations. He described a series of simple exercises that are used to guide the developers through \nscenarios that give them an understanding of performance. His experience was that by providing users \nwith a basic understanding of performance trade-offs, they are able to design and implement applications \nwith high-performance. Built-in Performance Monitors Martin also indicated that a very valuable part \nof the performance tuning was the availability of performance monitors as part of the system. Having \nthe ,appropriate information available when the system does not perform as expected greatly facilitates \nmaking the modifications necessary to improve performance. Cost Estimation Techniques Eric Hughes raised \nthe issue of how to evaluate the performance of a design without actually executing it. Because application \ndesign has a significant impact on performance, accurate cost estimation mechanisms made available early \nin a design would be invaluable. Evaluating ODBMS s A central part of the workshop involved discussing \nhow to effectively evaluate the performance of ODBMS s. The questions revolve around the effectiveness \nof benchmarks as a characterization of typical application behavior, and the metrics that are used to \nevaluate the performance of ODBMS s. Microbenchmarks A significant issue was raised by Laurent Amsa-leg \nabout the appropriate structure of benchmarks. Basically, the issue revolves around benchmark complexity \nand how close a benchmark emulates real application behavior. The sense was that existing benchmarks \nattempt to emulate real ap-plication behavior, but in doing so, they introduce significant levels of \nbehavioral complexity. As a result, current macrobenchmarks may not pro-vide insight about performance \nissues because their behavior cannot be controlled appropriately. The alternative, microbenchmarks , \nwith much sim-pler, well-understood behavior, allow the evaluator to control and better understand the \nrelationship between application behavior and implementation performance. An obvious downside to microbench- \nmarks is the issue of oversimplification. What/How Benchmarks Test Ashutosh Tiwary raised the issue \nthat a bench-mark can be used for two distinct purposes. A system benchmark would be used by the ODBMS \nimplementors to understand and improve the per-formance of their system. An application bench-mark would \nbe used by ODBMS users to under-stand how well a particular application is going to run on a particular \nODBMS. The different goals of users and implementors will result in different benchmark structures. Many \nexisting benchmarks do not distinguish between these different goals, and as a result may not address \neither groups needs well. Paul Wilson cautioned against the use of proba- bility distributions to generate \nbenchmark behav-ior. Existing studies show that probablistic mod-els of behavior can result in significant \nerrors when compared to metrics of real applications. Evaluation Metrics Antony Hosking pointed out \nthat in object database systems much attention is focused on the macro-scale metrics (i.e., I/O operations) \nwhereas there is significant cost in fine-grained aspects of perfor- mance (such as maintaining the write \nbarrier). Also, performance characterization at the macro-scale should be improved. Dave Munro described \nwork in characterizing application I/O behavior using a more appropriate model of physical I/O operations \nthan the simplistic uniform cost model. The goal is to make the reported metrics more likely to be translatable \ninto observed performance. Eliot Moss described a proposed trace format that captures this characterization. \n Benchmark Availability Michael F ranklin explained that the scarcity of rec- ognized benchmarks leads \nto programmers taking existing behavior models and modifying them to better suit their needs. The perspective \nis that by using someone else s benchmark in research gives more validity to the results. A major problem \nwith the phenomenon is that it does not address the real problem, which is that a better understanding \nand characterization of real applications is needed. Fur-thermore, by modifying someone else s benchmark, \nthe researcher may fail to understand and recognize the original limitations of the original model. Mike \noffered the following important piece of advice: a benchmark user must know two things: what you are \nmeasuring, as well as what you are not mea-suring.  Improving ODBMS s Based on the experience of the \nworkshop, a number of issues arose in our minds that represent the current needs of the community. Here \nwe indicate some of the most important of these, and indicate how the discussions at the workshop related \nto them. More Studies of Real Applications The few case studies presented (e.g. Somnath Banerjee, Louis \nRamos, Ashutosh Tiwary), illus-trated that while synthetic benchmarks can serve a useful purpose, only \nby undertaking actual perfor-mance studies will we (users, vendors, academics) get a better understanding \nof ODBMS perfor-mance. None of the case studies presented and dis-cussed could be represented in any \nsense by current benchmarks. Laurent Amsaleg also commented on the need to look at real applications \nwithin the con- text of garbage collection. It appears that a single generic benchmark is not app ropriate, \nbut perhaps classes of benchmarks are.  Holistic Benchmarks Several researchers commented on the need \nfor more holistic benchmarks in their position papers (e.g. Tony Hosking, Eric Hughes), rather than just \nfocusing on low-level primitives. The performance of applications is comprised of combinations of such \nprimitives. This ties-in with the the need for more case studies, since Somnath Banerjee also commented \non the need to consider the overall environment rather than just measure traversals, updates, etc. Common \nTrace Formats Some researchers proposed tracing as a useful way to collect information about ODBMS applications \n(e.g. Dave Munro, Eliot Moss, Ashutosh Tiwary). However, there should be some effort to try and agree \non common formats for this, so that traces can be exchanged between research groups. Such common formats \ncould be used as an encourage-ment to industrial users, who by generating a par- ticular trace, would \nget the benefit of having many potential researchers use it in their studies. Multi-User Benchmarks \nThere was very little reported work in this area at the workshop. This is not surprising, since such \nbenchmarks are very difficult to develop in a generic sense. Hartmut Schreiber reported some work in \nthis area, but these results are only serve as a starting point. Perhaps more performance studies in \nthis area will help, but will be difficult to undertake without user participation. Understanding Time-varying \nBehavior As was discussed by Hartmut Schreiber, the time-varying behavior of the structure of an object \ndatabase system has a critical impact on the performance of the system. Any attempt to optimize a system \nfor better reference locality using reorganization techniques depends directly on how the interconnected \nstructure of objects varies over time. Similarly, the effectiveness of storage management and reclamation \nalgorithms depends directly on such behavior. Unfortunatly, little information about such behavior in \nreal applications was discussed at the workshop. More information about the time-varying behavior of \nreal object databases would be valuable to the community. Understanding the Impact of Design The papers \nby Arthur Keller and Martin Dragomirecky illustrated the need to understand application de-sign and the \nimplications of alternative design de-cisions upon performance. More performance stud-ies are needed \nto see how much impact application design decisions and methods can have on perfor-mance. Better Communication/Cooperation \nIt is clear that there is a need for participants from all the constituent groups, users, implementors, \nand researchers, to work together more closely. Some of this cooperation would be facilitated by having \ncommon ground on which to stand (i.e., trace formats, benchmarks, or metrics). Communi- cation can be \nfacilitate using existing internet tech-nology such as mailing lists, internet sites, etc. The Web page \nassociated with the workshop is one such effort to bring together information and pointers to facilitate \nthe interaction between individuals and rapid dissemination of ideas and methods.  \n\t\t\t", "proc_id": "260094", "abstract": "", "authors": [{"name": "Benjamin G. Zorn", "author_profile_id": "81100190820", "affiliation": "Department of Computer Science, University of Colorado, Boulder, CO", "person_id": "P28972", "email_address": "", "orcid_id": ""}, {"name": "Akmal B. Chaudhri", "author_profile_id": "81100048562", "affiliation": "Systems Architecture Research Centre (SARC), Computer Science Department, The City University, London, United Kingdom", "person_id": "P11911", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/260094.260272", "year": "1995", "article_id": "260272", "conference": "OOPSLA", "title": "Object database behavior, benchmarks, and performance: workshop addendum", "url": "http://dl.acm.org/citation.cfm?id=260272"}