{"article_publication_date": "10-01-1995", "fulltext": "\n Implementing a Rea .I-Time, Embedded, Telecommunication Switching System in Smalltalk John Radford DNA \nEnterprises Inc. info@dna.metronet.com Abstract The cross connect system is a high speed, large capacity \ntelecommunication switching system implemented in Smalltalk. This presentation describes some of the \nproblems in timing and memory management and our solutions to these problems. Themes emphasized include \nthe interaction and coexistence of the garbage collection subsystem in an application with real-time \n requirements, quantitative measurements of performance as well as the tools and techniques used for \ndetermining the measurements.  Introduction The topic of this presentation was a very exciting project \nthat allowed us to bring together issues relating to real-time, object oriented design and Smalltalk. \nDNA s experience with OOD and Smalltalk within the telecom industry dates back about six years, admittedly \nwith much skepticism in the beginning. By the time last year when we approached this project, we had \nmore confidence but also a healthy respect for the pitfalls in both the technical and management areas. \n Scope I will start with a brief overview of the architecture and objectives of our telecommunications \nsystem. I ll then discuss what we viewed apriori as the main real time development issues. This is followed \nwith a presentation of a set of design rules and techniques used to keep control of various performance \nand memory issues. Next I ll then talk about the resultant system s performance against the objectives. \nFinally I ll briefly discuss the implementation process we utilized.  System Overview The real-time \nsystem under discussion is a wideband cross-connect containing the hardware necessary to terminate broadband \nhigh speed optical and electrical signals, and multiplex these signals to slower wideband rates, for \nexample DSl for the domestic market or VC 12 for the international markets, and cross-connect any wideband \nsignal to any other wideband signal in various ways. A wideband signal carries the equivalent of about \n30 phone calls and this system can cross-connect about 100,000 wideband ports (for as many as 50,000 \ntwo way connections). This capacity represents over a million simultaneous phone calls or over a terabit \nper second of data. The system receives external requests to form connections and must process a connection \nrequest within a latency of 400 milliseconds. Due to the other functions such as maintenance performed \nby the system, we imposed an execution limit for the processing of these requests of 80 mills or 20% \nof our latency requirements. Meeting this objective allows us to use the remaining 80% for the many significant \ntasks required to maintain a system of this magnitude.  Hardware Architecture The hardware configuration \nof the system consists of a three stage matrix, each stage comprised of hundreds of physical cards, devices \nto terminate the broadband signals and devices to demultiplex the broadband signals into wideband signals, \npotentially another 1000 cards. Controlling the matrix and signal termination devices is a three level \nprocessor hierarchy, supporting up to 1000 pairs of redundant processors with at least one pair of SPARC \n10 s acting as administration for the rest of the complex. The software handles connection processing, \ndevice and port state maintenance. The connection process flow begins with the arrival of a connection \nrequest to the user interface image in the Admin. This image then formats and sends a connection request \nto a second fabric image in the same Admin processor via a socket. The fabric image processes the request \nand sends a response to the first image. The processing by the fabric image generates up to 5 messages \nto lower level controllers to properly condition the matrix and port termination devices. These 68040 \nbased controllers host a single Smalltalk image. Our objective was to keep the processing of a single \nconnection request to 80 mills in any one processor. Ideally the Admin would execute for 80 mills and \nthen the processors associated with this request would execute in the next 80 mills, while Admin was \nworking on the next request, for a total latency of 160 milliseconds. As we will see later, we actually \ndid much better than this. Software Subsystems To summarize, the software is composed of several major \nsubsystems. Connection processing as we just discussed. System maintenance which deals with configuring \ndevices and ports as well as fault isolation which can determine the lowest replaceable unit to swap \nin the case of a failure. The infrastructure subsystem deals primarily with communication via sockets, \nbetween images in the same processor or to images in different controllers. In the Admin complex we used \nObjectworks 4.1 from ParcPlace. In the controllers we used a version of the same ported to an embedded \noperating system. Issues for Real-Time Systems This is a set of issues we face on all real-time telecom \nprojects: . Performance . Memory Requirements . Programming in the large . Documentation . Training \nThey are interesting in this context only because we knew that our need to use OOD and Smalltalk made \nthe issues worse in several ways. Historically the projects in the telecom industry are, compared to \nwhat the audience is probably used to, quite crude. Often systems are extremely large, with millions \nof lines of code, but they are built with relatively little upfront design. A large percentage of the \nproject time is reserved for implementation and integration test. We had the usual critical project time \nframe with a fixed end point. Therefore since OOD techniques require a fair amount of initial design, \nwe knew the implementation period would be squeezed. We would have to make this up with decreased test \ntime. Also this industry is notorious for skimpy design documentation. Sometimes a well run project might \nhave a few hundred page document to lead off with, consisting of simple structured diagrams, data flows \nand module descriptions. In contrast our current documentation set for this project is approaching 2000 \npages. Training, when using something as novel in this world as both OOD and Smalltalk can present a \nproblem to find people who are skilled on your methodology and your implementation techniques. Austin, \nTX October 1519,1995 Most important for this discussion, there were predictable performance and memory \nissues due to both OOD and Smalltalk involvement in project. This system presented additional interesting \nproblems in adapting object concepts to a problem set that on the one hand has some very clear and easy \nto define real world objects relating to the hardware but on the other hand we needed hundreds or thousands \nof them.  Execution Timing Analysis A big aspect of our starting strategy was a two pronged approach \nto timing and performance evaluations. First we performed a concept evaluation function upfront in parallel \nwith our object oriented requirements analysis and object oriented design. This concept evaluation function \nwas responsible for generating timing data to develop prudent design rules relating to the use of our \nresources (Smalltalk, UNIX, our embedded OS) Among other areas we determined the execution times, in \nboth the SPARC and controller images, for calls to user primitives, collection type operations, socket \ncommunications between images on the different processors, and for context switching. The measurements \nwere obtained by timing repeated executions, often hundreds or thousands of events, to average out the \nimpact of any background activities. The second part of the concept evaluation phase was to build a performance \nprototype of our overall software architecture as the design evolved. For this multiple image model we \ncombined measured times for infrastructure functions along with budgeted times for feature processing. \nWhere the logic for connection processing wasn t developed yet we would insert a delay of our budgeted \ntime of 80 mills, and combine this with actual message sends or calls to primitive operations. This gave \nus confidence early in the process that we would be able to meet our performance requirements. Execution \nTiming Analysis The second prong of our approach was to develop a comprehensive implementation evaluation \nprocess to assure that our design rules were met and our performance objectives realized. The process \nutilized a rigorous subsystem test philosophy that required a through test suite for each and every feature. \nThese tests were contrived to not only functionally prove that the implementation was correct, but also \nto prove the execution was reliable in that we could run for long periods of time without memory leaks \nor other forms of degradation. We also leveraged this by instrumenting the test suites to capture, over \nboth short and long runs, the feature execution time and memory usage profile. The execution times are \nelapsed times measured within each processor, yielding the time for the first execution of a feature, \nthe average time over the run, the maximum time and the minimum. In the future we intend to modify the \nVM to provide actual execution times. The average time is the strongest measurement against our 80 mill \nobjective, but the others are interesting as well. We use the lSt time to gauge the effect of compilation \ninto the code cache. We use the delta between the minimum and average as a gauge of the effect of the \ngarbage collector. The maximum is the least useful as it is aberrated by other processes, however we \nneed to verify that these aberrations don t significantly effect the average. We also were able to measure \nthe amount of time spent in garbage collection.  Design Rules With this strategy in place and with the \ndata from the concept evaluation, we adopted these design rules. All objects must be pre-instantiated \nand placed in per-m space. This avoids most garbage collection problems as the garbage collector not \nonly doesn t have to release any objects, it doesn t even see any. As part of the startup process, before \nwe begin real-time execution, we perform an initial image initialization where all objects are newed, \nand We use a couple of pooled object types to avoid instantiation of the potentially hundreds of thousands \nof objects in the Admin image. The 1 type is useful as accessors to linear databases comprised of larger \ntables of uninterpreted bytes. The 2 d type is used to encapsulate both the use of accessors and the \nbehavior of the object class itself, thus we have 10 actual instances of port objects which represent \n100,000 physical ports, of course at any instant in time only 10 ports are being worked on. a perm save \nis performed. Next we reload the image and perform an activate, after which time system operation commences. \n You can think of the pooled objects as magnifying glasses into the system database. From an external \nviewpoint they look like objects with properly constructed interfaces. Outside of the issues of dynamic \nallocation and release they behave in every other respect as if they are persistent members of the object \nset. The application of this idea, along with other system concepts, saved many megabytes of memory and \nmade persistence of this data much easier to achieve. Having gone to the efforts just described to avoid \nthe creation of new objects with our code we also avoided foundation class methods, such as select, that \ninstantiate other objects. We did not condone the use of Smalltalk process switching since our concept \nevaluation tests pointed out how slow it is. Rather than a multi-process design, we tended to use a more \nstate driven approach, even though that forced us to develop tools within our class infrastructure to \nmake that more practical. For example in the controllers we make extensive use of a transaction deferral \nscheme which allows us to essentially yield control to another transaction and resume our current transaction \nat later times. Our design in the Admin complex is currently composed of two images which communicate \nvia sockets. Design Techniques In addition we adopted some techniques which I wouldn t state we felt \nso strong about that we called them rules, (i.e. you would flunk a unit test if you didn t follow them), \nbut from a timing viewpoint they are significant. We avoided the use of large positive integers. The \ndifference between using a small positive integer and taking advantage of the next three bits to extend \nto large positive integers is around two orders of magnitude in execution speed. Therefore, while many \ndata structures and algorithms would naturally be represented by 32 bit values we would design with 16 \nbit units. Another area we optimized was bit map management. In this case we would evaluate and store \nmasks for different bit accesses and then apply these masks at run time as opposed to direct bit manipulation. \nAt some point in time we plan to implement primitives to efficiently perform 32 bit operations. In several \ncases we would examine entire algorithms, again often related to the manipulation of bit maps, and replace \nthe algorithms with table lookup operations. Finally, based on the initial timing analysis during our \nconcept evaluation phase we minimized the use of user primitives and CPOK calls. However user primitives \nare far more preferable than CPOK calls. Timing Results During the first phase of the project we performed \nan implementation timing analysis utilizing the metrics obtained during the execution of our subsystem \ntests. This chart presents a summary of the results for a connection request. To we developed total of \nclasses Event 1 First 1 Max 1 Min 1 Avg 1 with 8300 methods almost 84000 of Smalltalk As the shows their \na significant of code between the in the and the processors. These do not the code to support extensive \nunit subsystem tests we performed. fact an amount of was written test as execution on target system. \n Usage In to the results shown All times are in milliseconds. execution and of the tests provided with \nthe counts and In particular, the average column on the right-hand usage statistics here. side is the \none which is most comparable to our original performance goals. The sequence begins in Description Admin \nController the admin complex on a SPARC processor. As you can see it was measured at an average time \nof 25 Count After 70,660 94,336 milliseconds, vs. our budget of 80 mills, so we were Init significantly \nbelow our requirements, using only Object After 70,685 94,296 30% of the allowed average time. Activate \nCount After 70,69 1 94,353 All the rest of the events occur in the lower level Test controllers, setting \nup matrix paths and conditioning Object Memory After 9,126,640 4,457,428 the external circuits and execute \npretty much in Init I parallel with each other. However, even in the worst Object Memory After / 9,127,703 \n1 4,420,028 1 case of serial execution of all controller events, the Activate additive time of 124 mills \nis far below our 400 mill latency requirement.  Code Metrics This table is to give you an idea of the \namount of code developed. The values are shown for three distinct states we define for our system. As \ndiscussed earlier the first # Classes # Lines of state is following the pre-instantiation of all objects. \nMethods Code The next state is after image activate. The third state is after the system has executed \na number of Admin 378 5,747 43,725 different subsystems tests multiple times. Controller 290 4,923 55,060 \nCommon 160 2,304 15,188 As stated earlier, a critical design goal was to Total Unique 508 8,366 83,597 \nsignificantly constrain the creation of new objects in order to control the impact of garbage collection. \nAs these numbers show we succeeded, with a growth in the number of objects during execution of less than \n4/l 00 of 1% in the Admin image and even better in the controller image. The amount of memory allocated \nfor objects reflects these same results for the different system states. The final row presents the amount \nof memory, in the form of uninterpreted bytes, used for the database controlled through the pooled objects \ndiscussed earlier. This is one area which we expect to growth in the future as additional features are \nimplemented. As there is no requirement for persistent storage in the controllers, and the number of \nobjects to be managed is much smaller we directly represent all database entities as unique objects so \nthere is no separate database allocation in the controller image. Implementation Process I feel we did \na good job of tightly controlling our costs across the board in terms of time to develop, in terms of \nperformance and in terms of memory usage. This work was performed on a fixed cost basis and came in on \nschedule. That came about because of a fairly disciplined and rigorous implementation process. The project \nwas operated in two distinct phases, Analysis and Design followed by coding, test and integration. However \nthere was extensive iteration within and between the phases. The first A &#38; D phase was performed \nwith 6 staff who were later paired with new engineers in a buddy system to implement a new feature or \nfeatures. This addressed the twin issues of how to transfer the design technology to new staff as well \nas providing as rapid of implementation phase as possible. Other keys to the success of the project were \nthe construction of a hardware simulator in Smalltalk. This provided support for a comprehensive set \nof test cases. We had 100% code coverage, where we were required to execute every line of code, (although \nobviously not with every permutation of data). We did execute all error conditions. In fact no problems \nwere found during integration test that should have been found earlier. All problems which were found \nwere due to changes in the design of some of the hardware ASIC s from the original specifications. We \ngenerated extensive timing, object allocation and garbage collection reports. These were used throughout \nthe review process to ensure all design rules and guidelines were met. Finally the Smalltalk browser \nwas an excellent vehicle for conducting on-line code reviews, projected onto a large screen, where we \nwould not only read the code but execute it as well. In summary we are very pleased with the results. \nThis has been an exciting project allowing us to apply Smalltalk to the domain of real-time systems design. \nWe wholeheartedly feel that Smalltalk can be used very effectively for real-time systems when used with \na controlled design process. We would encourage others to consider Smalltalk for real-time systems and \nexpect to continue to push the envelope of possible applications where Smalltalk can be applied. \n\t\t\t", "proc_id": "260094", "abstract": "", "authors": [{"name": "John Radford", "author_profile_id": "81332522404", "affiliation": "DNA Enterprises Inc.", "person_id": "P145625", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/260094.260245", "year": "1995", "article_id": "260245", "conference": "OOPSLA", "title": "Implementing a real-time, embedded, telecommunication switching system in Smalltalk", "url": "http://dl.acm.org/citation.cfm?id=260245"}