{"article_publication_date": "10-01-1995", "fulltext": "\n Semantic integration in complex systems: collective behavior in business rules and software transactions \nHaim Kilov (IBM; kilov@watson.ibm.com), Bill Harvey (Robert Morris College; harvey@robert-morris.edu), \nKevin Tyson (IISA, Inc.; kpt@iisa.com) Introduction This workshop is about thinking in specifications. \nIt is the fourth behavioral specification workshop at OOPSLA[2-41. When we organized the first one (long \nago, in 1992), concepts like precondition were considered to be too academic by some; too far from the \nreal world of delivering workable systems. To-day, such concepts are successfully used by business modeling \npractitioners (and some popular method-ologies are starting to use them). However... things are still \nfar from being acceptable. Precise specifications of system semantics are essen- tial to understand business \nrules and to create soft-ware systems satisfying these rules. We use them to describe properties of a \nsystem which does not yet exist in the real world; but some client, with money to pay, would like to \nsee it brought into existence. . . . [The system should be described] as clearly and di- rectly as possible, \nin terms of what behavior is to be exhibited and what is to be avoided. The specitica- tion may be part \nof a formal contract between the client and the team engaged to implement the prod- uct. [l]. Understanding \nsystems is essential for their interoperability. However, certain 00 methodologies still split a specification \ninto data , process and behavior components, without precisely defining them, only to merge these components \nafterwards. Dogmatic adherence to 00 approaches used in leg- acy 00 languages requires the analyst to \nmake pre- mature choices (e.g., where do I put this opera-tion? ) and often precludes us from seeing \ndifferent users viewpoints separately. Legacy wrapping has become a key concern in recent years. Certain \nproducts offer integration at the engi- neering levels while ignoring the issues of semantic integration \nof the new and old worlds. CORBA s Object Transaction Service (OTS) raises new issues of semantic integration: \nthe naturally occurring ACID properties of Business Transactions must be mapped to the behaviors supported \nby OTS. This requires precise behavior specifications of both the underlying services and the user s \nbusiness requirements. It will also be necessary to extend the OMG s Object Man- agement Architecture \n(OMA) to support the defini- tion of relationships not owned by a single object. Semantic integration \nof (precisely specified!) dis-tributed objects, transactions and workflows defines the leading edge of \nobject technology research and practice. Proceedings of our Workshop have been published by Robert Morris \nCollege. The submissions cover a wide range of issues, both theoretical and practical. Sometimes it is \ndifficult to categorize a paper in this way because it deals with both; and we need more papers and discussions \nof this kind. Finally, we recognize that we are not alone: several other OOPSLA 95 workshops consider \nsome of these issues. We would obviously want to cooperate.  Workshop Presentations Business Modeling \nand Related Issues Guus Ramackers (Oracle, UK) The warm and fuzzy feeling after a $3000-a-day con-sultant \ncreated a business model is certainly not sufficient. We need a set of concepts -understand- What follows \nare interpretations of the presentations. These sketchy and biased interpretations were made by the workshop \norganizers and may or may not correspond to what the presentation authors wanted to state. However, a \npreliminary draft of this paper has been emailed to all pre- senters in search of feedback and comments; \nall authors comments have been incorporated. Organizers comments are in square brackets. Addendum to \nthe Proceedings OOPSLA 95 able by the domain expert and end user -for a good tool. We use Petri nets \nfor formal specifications; but any formal framework will do. User specification layer is needed to talk \nto customers; and it is not just a drawing tool for a paper-based methodology. We want to integrate many \ndifferent, partially over-lapping views, and therefore an active repository (that supports integrity) \nis needed. We don t want to enforce a particular way of working (object, or proc- ess, or event-driven). \nQuestion (Q) by Aksit: Business processes or busi- ness products (ie things that processes generate eg \ndocuments)? Answer (A): Products reinforce the current situation say BPR consultants. But Oracle s CASE \ntool does not enforce a decision of this kind! Methods are attached to objects. Rules are specified not \nat the level of tables, but at the level of object types (eg NOT ELEMENT OF). Ease of understand- ing \nwas stressed.  How to Understand and Specify Behav-ioral Semantics Doug Bryan (Andersen Consulting, \nUSA) The problem: 11 years of research that were not used. Formal methods were not approachable by a \nuser, although they provide exactness and clarity. There is a need for CORBA IDL extensions: specifi-cations \nand protocols. We include pre- and postcon- ditions and invariants a la Meyer s work, but use C- like \nsyntax (no first-or second-order expressions). Are pre- and postconditions sufficient for expressing \ninteractions between objects? Components: untyped collections of interfaces that are distributed and \nreused because classes are too small to reuse -otherwise the situation is too much like [traditional] \nprogramming. Interfaces to a com- ponent are provided and required. Quote: Ifvou know C++ you know 90% \nof IDL. The solution: add pre- and postconditions and a very simple state model to IDL. The C++ programmers \ncan read and write them, but you don t tell them it s a state machine. We move very slowly not to frighten \nC++ programmers: we will add pre- and postcondi- tions to component interfaces. Natural language paraphrasing \n(there are too many graphical notations). One of the major goals is for the user not to see and not to \nrealize that there is a theo- rem prover. Q: Compare the extension of C++ with Eiffel. A: it is based \non Eiffel, but not compiled into Eiffel. The goal is to do static verification of formal parts. We are \nproducing our own compiler. The goal is to be ORB-independent (distributed-broker-indepen-dent). Pre- \nand postconditions will not be used for method resolution. Try to get users to understand simple things. \n Charles Richter (Objective Engineering, Inc., USA) We need to precisely specify single systems: they \nare precise and abstract, but not too difficult to under- stand. And for a system function, we need to \nknow how a function starts (triggers -initiated by an ex- ternal event or by the system), where it starts \n(pre) and where it ends (postcondition). Typically in 00 modeling methodologies you specify how objects \ninteract, and don t specify functions. System functions are to be specified in terms of pre- and postconditions. \nBut people were afraid to use them. On the other hand, [traditional] use cases in-clude a fair amount \nof handwaving. Object interaction diagrams [event traces] emphasize what messages are exchanged, but \nwe d like to talk about effects, NOT messages. Hundreds of event traces express something quite different \nfrom what the customers wanted to do. Fusion: we would like something that doesn t look threatening to \ndevelopers! Nevertheless, Fusion is the way to go, although not in North America . Instance diagrams \nare used. An instance diagram is formulated in programming terms, apparently more comfortable to programmers. \nExample: the function to create a buy order includes pre- and postconditions. Pictures may enforce more \ndiscipline than text; but texts may lead to fairy tales in specifications (texts need to be specified \nin a very disciplined way). Requirements are not the same as interaction diagrams. Q: graphical notations \nmay be ambiguous. A: encour- age them to be precise. Most projects use Power-point, and don t use official \nCASE tools. Jean Stanford (Hestia Systems, USA) You don t know [in analysis] where to start - where \nis the top . We cannot derive actors from the top level of a use case. Primary actors at the refinement \nlevel may be quite different from the actor(s) at the top level. We have to explore these additional \nactors, or else we miss important properties of the domain. This is missing from Jacobsen s book. The \nfilling in of bingo cards about products, for example, is a transaction of value to the enterprise, not \nto a particular process. We extended use case methodology (the Jacobsen book one). Look not only at the \nmarketing stove-pipes, for example (don t miss eg the lawyer who is not a member of the department): \ncheck for external actors.  Formal Specifications Haim Kilov (IBM, USA) How do we specify an object-oriented \nsystem, based on abstraction, using a formal, but flat, nota- tion like Z? First of all, is a formal \nnotation under-standable? A [good] Cprogrammer should be able to understand (read) Z specljkations. It \nis possible to provide guidelines for Z specifiers who want to describe, in a precise manner, important \ngeneric object concepts like object , object s in-variant , type , subtype , refinement , etc. -the subject \nmatter of the IS0 Reference Model for Open Distributed Processing [5]. There may, however, be a need \nto provide syntactical support for doing so by extending Z eg with parameterized modules that de- scribe \ncollections of related classes. Q: is encapsulation needed? A: yes if you have a complex system and use \nrefinement (even informal) -to understand a detailed specification consisting of several hundred (or \nseveral) pages. In other words, structuring facilities are essential for this purpose. The Europe - US \ncontroversy was shortly discussed. Kasi Periyasami (University of Manitoba, Can-ada) The topic of the \nfirst paper is OMT and formaliza- tion. We wanted to embed verification strategies in an analysis and \ndesign tool. Goal: to get a clearer un- derstanding of the application domain; and to analyze whether \nthe requirements are consistent. Notations do not enforce semantic correctness: you can specify that \nstudent inherits from course, for ex- ample. A true methodology for analysis (verification strategy) \nis lacking. Some rules for verifying inheritance were demon-strated. The topic of the second paper is \na graphical notation to understand Z specifications. The goal is to convince managers that use of formal \nspecifications is really helpful. Mathematical means that you cannot have two different interpreta-tions. \nIf you don t know mathematics, you can use an informal notation (picture) to understand a Z specifi- \ncation. However, even half-a-page Z specifications may be quite complicated. Example: mailboxes and sending, \nreceiving, etc. Any ambiguity in the graphical representation can be explained by referring back to the \nZ specification. Kinds of relationships (eg functions or injective functions) are currently not on diagrams, \nbut planned for. Q: are graphical notations easier to read and un-derstand? This is context-dependent \n[Russel Winder] . The proposed graphical notation explains the struc-ture, but not behavior. The behavior \n(eg invariants) is textually explained, in structured -stylized -English. This is informal, but rigorous; \nand achieved by parsing of the Z specification. The approach is difficult for longer Z specifications. \n Classification Issues in Specification and Implementation Jim Ode11 (USA) Old IS world: neither modeling \nthe business, not formal (example: data flow diagrams). Attach wing to plane -where [in which object] \ndoes this opera- tion go? What do you mean by operations not at-tached to a particular object? What is \nthe meaning of dynamic and multiple classi-fications? Concepts have intension (what s a pawn ? Is this \na pawn or not?) and extension (pEPawn). But we need to be able to state that Peter is a Man, Peter is \na Per- son, and Peter is a Property Owner. What do you do with that in 00 programming? A lot of expert \nsystem tools have no problem with that: they use multiple classifications. This is often encountered \nin the health- care environment, etc. You can do this with 00 languages, but this is not pretty! The \nneed for doing so is essential, although programmers often say it need not (cannot) be done. Some languages \nsupport this: Neuron Data, Kappa, etc. But we need better support. Is there a difference between inheritance \nand aggre- gation? It depends upon how these concepts are de- fined at the implementation level. They \nmay be de- fined differently at the specification level. [Comments: Aggregation vs. subtyping? What hap- \npens when a component s properties are exposed to the composition? Are all of them true for the com-posite? \nInheritance is not the same as subtyping; for example, not all properties of a component -con-juncts \nof the component s type (predicate) -are satisfied by composite instances.]  Ian Simmonds (IBM, USA) \nBusinesses separate concerns along business, rather than technical lines, therefore it is natural to \nsys- Addendum to the Proceedings OOPSLA 95 tematically understand, specify and implement sys-tems from \na set of business viewpoints. Viewpoint is the generic notion behind information modeling s [6] dynamic \nsupertypes (used in business analysis) and the 00 programming notion of subject. Example: a homeowner \nis a dynamic supertype at-tached to eg a person, a business, a charity, a gov- ernment body, etc. We \nseek to combine these, and so maintain a business viewpoint-driven modularity from analysis through to \ncode. All appropriate con-cepts exist for viewpoint-driven analysis. Subject composition is currently \nat the class level, and the building of systems by composing subjects is cur-rently limited to static \ncomposition; even so, subject composition already allows unanticipated system ex-tension, such as for \nthe addition of new business viewpoints (features) to a system. Q: what about composition filters (Aksit, \nECOOP 92 and 93)?  From Specification of Semantics to Its Implementation Todd Blanchard (Evolving Systems, \nInc., USA) A large amount of business knowledge in a phone company is hidden in yellow sticky format \nstuck to the sides of users screens. Each sticky captures some piece of volatile business knowledge and \nis in the form of when . . . do (or don t ). We have to use C++. It is used to model business model components, \nthis creates a meta-model in C++ that is used to model the business. The business objects are not C++ \nobjects, but their components are. The yellow sticky knowledge is implemented as production rules using \na commercial inference engine that understands the meta-model components. The only real behavior of the \nbusiness model is for creation/destruction of ob- jects and state flags such as valid , mandatory to \nbe kept correct and their changes broadcast to ob-servers. The production rules are runtime interpreted \nand easy to change. David Redberg (A T&#38; T, USA) Network Management applications. Second level of \ndreaming -when you go down from the second level, you are still dreaming (on the first level). We have \nwritten The Book many years ago (on C), and are still writing systems the same way. Where is your model? \nIt s there, in the code. . ..We equate in- formation model with data model and object model and lose \nsemantics, so most semantics is in the code. People try to define data model first, and then con- sider \nonly application-specific behavioral require- ments [not looking for generic reusable concepts]. Discussion: \nSpecification classes and relationships need not be the same as implementation classes and relationships; \nand the linking invariant should be provided (and maintained). Patterns in problem space should be represented \nby [possibly different] existing patterns in the solution space. Quote from one of the previous viewgraphs: \norganize tools in accordance with the users meta-model. Kevin Tyson (IISA, Inc., USA) Many firms use \nproducts that support the exchange of data between several computer systems. While this level of interoperability \nis of great value, it often fails to produce solutions to the business problems faced by these firms. \nSoftware systems are, at best, imper- fect models of business reality. The enterprise-wide problems faced \nby many firms require more than data exchange between systems, they require semantic integration between \nsystems. Semantic integration requires that systems interoper- ate in meaningful ways. Specifications \nof behavioral semantics serve as contracts between parties involved in appropriate operations. Such meaningful \ninterac-tions can serve as building blocks for semantic inte-gration; but who enforces the contract? \nTransaction Management is a readily available soft-ware technology -used for several decades -which does \nsupport enforcement. Transaction man-agement systems enforce a consistency contract be-tween multiple \nparticipants leading to both recover-able data and serialized operations on the data. TP Monitors extend \nthese properties to software proc-esses. Transactional Workflow Management Systems promise similar benefits \nfor automated business processes. Traceability between business and software behav-iors requires a framework \nthat organizes our thinking about both. Such a framework should support rigor- ous specification of business \nrules and behaviors; rigorous specification of software behaviors; refine-ment from business to software \nbehaviors; and de- monstrable conformance of software behaviors to business behaviors [observed behavior \nshould con- form to the specified behavior]. Fortunately, such a framework is available: it is IS0 Reference \nModel for Open Distributed Processing [5]. By consistently applying this framework, we can achieve semantic \nintegration in large-scale systems and create software artifacts that can be used to compose new solutions \nto business requirements. Bill Harvey (Robert Morris College, USA) The importance and role of end user \nhas been em-phasized (eg co-author, Greg Shorr, is an end user -a medical dostor). Views are determined \nby the SMEs (health professionals), by standard applica-tions specified by SMEs. And flexibility is essential \nin responding to end-user requirements. ( Interface is crummy, but integration is superior. ) FILEMAN \nhad some form of automatically sup-ported referential integrity for more than 12 years. SMEs requested \nseveral different views [comment: compare with dynamic supertyping and subject-orientation]. Medical \npeople would like to see sepa-rate datatypes for different procedures (eg tests): da- tatypes as objects. \nTrue encapsulation is very diffi- cult to provide in an M-technology environment. Comment by Peter Wegner: \ntotal lack of correspon- dence between the problem as defined by politicians (eg medicare) and what s \ngoing on in practice ( money-grabbing in the real world ); and a totally different -technical -heterogeneous \ndata prob- lem.  Guest Speakers Cory Casanave (Data Access Corp., USA; Chair of OMG s BOMSIG) Had shown \nthe OMG common facilities RFP. There is a need to have a (precisely defined) set of common business objects \n-interoperable components. These things work if you have a top-down view. . . . You have plug-and-play \ncomponents to represent business things. Business semantics has to be repre- sented, including one for \ncollections of business ob-jects. Q: diluted nature of semantics? Is there a movement to handle this? \nA: you [will?] have to be able to talk about relations, rules, etc. But we do not have yet standard syntactic \nways to represent these. Generally, an RFP is a question, so people can submit proposals. Some of the \nenhanced object models will have to deal with that. Q: what to do with different nature of eg accounting \nin US and UK? A: the common business object layer will not include these application-specific objects. \nIt will include objects like trade . And a US frame- work is completely acceptable as an extension. \n Shai Ben-Yehuda (Israel) Problem: need to have very flexible and fast simula- tion. The design issues \nin C++ become the main is- sues; the analysts do not understand them. [Comment: should they? Specification \nconcerns should be separated from implementation ones [5,6] .] Sofhuare runs away from the analysis. \nWe wanted to have a language that will cover 80% of the specifi- cation. It was successful, and C++ programmers \nused it. By inheritance, aggregation, and attributes you can put 80% into simulation; but what to do \nwith the rest ie with behavior? C++ programmers just wrote pro-grams for that, so that C-t+ behavior \ncan be added. Versions were also considered. Patterns of behavior were implemented as strategies [ behaviors \nsepa-rated from objects ] representing a separate hierarchy for simulation objects. Strategy example: \nhow does a unit move? There are many ways a unit can move; and if the way of moving changes we get another \nclass. The system consists of 2000 lines of C++, 100 lines of yacc. A classification module classifies \nan object like a neural network; and then the behavior of an object is known. This is done each time \nan object changes: an object can easily change its class to any other class.  Peter Wegner (Brown University, \nUSA) Models of interaction. We come from an algorithmic culture -one step at a time; and now we have \nto model interactions where things change. This broader class of models cannot be captured by Turing \nmachines which shut up the world during the computation . An interaction ma-chine is a Turing machine \nextended with input and output actions ( read and write statements). Example: driving from home to work \nis algorithmic, due to interactive traffic conditions. Another exam-ple: smart bombs are smart because \nthey interact. Interaction is more like a marriage contract. Turing machines are non-interactive. We \ncannot model interaction machines by sound and complete first-order logic. Interactive machines can express \nmore powerful behavior than these logics. Objects (including business objects) are more accu-rately modeled \nby interaction machines than Turing machines. Church s thesis (that intuitive computing is computing \nby Turing machines) is inapplicable: what people actually compute is not algorithms. We try to reduce \nit to algorithms, and it s the wrong thing to do. Structured 00 programming: a buzzword (objects working \ntogether: a pattern). Robin Milner said that interaction and concurrency are two sides of the same coin. \nThis is wrong: these things are different. An interactive system need not be distributed at all; these \nconcepts have to be clearly Addendum to the Proceedings OOPSLA 95 separated. The emphasis is on interaction, \nNOT dis- tribution. There are almost no discussions about the relation- ship of the interactive paradigm \nto the declara-tive/imperative paradigm. Pure paradigms are low-level. Turing machines are too strong \nand restrict be- havior too much, but interaction machines are weaker and do not restrict behavior in \nthat way. Harness constraints: both restrict the behavior and harness (focus) behavior. We cannot describe \nthe elephant, but can describe the parts. Quote from Isaiah Berlin about foxes (can do little things) \nand hedgehogs (can do one big thing). The system in general will be unspeciliable -and there is NO shame \nin that -, but its partial interface behaviors will be specifiable. [Comment: How about dynamic supertypes?] \nPlato s cave. We should be able to model things richer than de-scribed in the syntax!  Final After \na very heated debate, the participants came to some violent agreements. We achieved unanimous consent \non the following: There is no such thing as a complete spectjication ; diRerent viewpoints of interest \nhave to be precise and explicit. There exist at least two viewpoints: the analyst/end user and the designer/developer \nones, Correspon- dence between these viewpoints should be explicitly spectfied by means of a linking \ninvariant. The observed behavior should conform to the speci- fied behavior. Dynamic super-types -multiple \ndynamic inheritance -exist. Collections of classes and objects together with their relationships and \nbehavior are useful reusable frag- ments. Isolated objects are not semantically rich enough for reusability. \nGraphical notations may not be easier to understand than textual ones. Exactness may sometimes be traded \nin for clarity.  Authors Who Submitted Papers: Anilkumar Bhate (Stevens Institute of Technology, USA), \nTodd Blanchard (Evolving Systems, Inc., USA), Doug Bryan (Andersen Consulting, USA), Anthony Earl (USA), \nWilliam Harrison (IBM, USA), Bill Harvey (Robert Morris College, USA), Maritta Heisel (Technische Universitaet \nBerlin, Germany), Randolph Johnson (DOD, USA), Haim Kilov (IBM, USA), Jose Lee (MPR Teltech, Canada), \nTorbjoern Lundmark (Erisoft AB, Sweden), Joseph Morabito (Merry11 Lynch &#38; Co., USA), James J.Odell \n(USA), Harold Ossher (IBM, USA), Kasi Periyasami (University of Manitoba, Canada), Guus Ramackers (Oracle, \nUK), David Redberg (AT&#38;T, USA), Charles Richter (Objective Engineering, Inc., USA), Greg Shorr (Medical \nInformatics, USA), Ian Simmonds (IBM, USA), Jean Stanford (Hestia Systems, USA), Kevin P. Tyson (IISA, \nInc., USA) Additional Workshop Participants: Mehmet Aksit (University of Twente, Netherlands), Colin \nAshford (Bell-Northern Research, Canada), Shai Ben-Yehuda (Israel), Jean Bezivin (University of Nantes, \nFrance), Cory Casanave (Data Access Corp., USA), Robert Howard (Tower Technology, USA), Kristsana Nithikethkul \n(George Washington University, USA), Jens Palsberg (MIT, USA), Alain Pirotte (University of Louvain, \nBelgium), Sentail Subramanian (University of Manitoba, Canada), Pe- ter Wegner (Brown University, USA), \nRussel Winder (University College London, UK)  References 1. C.A.R.Hoare. Mathematical models for computing \nscience. Oxford, UK, August 1994, p. 29. 2. H. Kilov and B. Harvey. Object-Oriented Reason-ing in Information \nModeling: Workshop Report. In OOPSLA 92 Addendum to the Proceedings, pp. 75  79. 3. B. Harvey, H. Kilov, \nand H. Mili. Specification of Behavioral Semantics in Object-Oriented Information Modeling: workshop \nreport. In Addendum to the OOPSLA 93 Proceedings, pp. 85-89. 4. B.Harvey, H.Kilov. Precise behavioral \nspecifica-tions in 00 information modeling. In OOPSLA 94 Addendum to the Proceedings, ACM Press, 1995, \npp. 137-142. 5. ISO/IEC, Open Distributed Processing - Reference Model -Part 2: Foundations (IS 10746-2 \n/ ITU-T Recommendation X.902, March 1995). 6. H.Kilov and J.Ross. Information Modeling: an Object-oriented \nApproach. Englewood Cliffs, NJ: Prentice-Hall, 1994.   \n\t\t\t", "proc_id": "260094", "abstract": "", "authors": [{"name": "Haim Kilov", "author_profile_id": "81100225658", "affiliation": "IBM", "person_id": "PP31082367", "email_address": "", "orcid_id": ""}, {"name": "Bill Harvey", "author_profile_id": "81100589635", "affiliation": "Robert Morris College", "person_id": "P30438", "email_address": "", "orcid_id": ""}, {"name": "Kevin Tyson", "author_profile_id": "81100126040", "affiliation": "IISA,Inc", "person_id": "PP14054894", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/260094.260259", "year": "1995", "article_id": "260259", "conference": "OOPSLA", "title": "Semantic integration in complex systems: collective behavior in business rules and software transactions", "url": "http://dl.acm.org/citation.cfm?id=260259"}