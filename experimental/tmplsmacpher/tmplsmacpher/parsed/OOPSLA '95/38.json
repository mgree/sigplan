{"article_publication_date": "10-17-1995", "fulltext": "\n SmartFiles: An 00 Approach to Data File Interoperability* Matthew Haines Computer Science Department, \nlinzversity of Wyoming <hainesQcs.uwyo.edu> Piyush Mehrotra ICASE, !VAS A Langley Research Center <pmQicase.edu> \n John Van Rosendale ICASE, NASA Langley Research Center <jvr@lcase.edu> Abstract Data files for scientific \nand engineering codes typically consist of a series of raw data values whose description is buried in \nthe programs that interact with these files. In this situation. making even minor changes in the file \nstructure or sharing files between programs (interoper-ability) can only be done after careful examination \nof the data files and the I/O statements of the programs interacting with this file. In short, scientific \ndata files lack self-description, and other self-describing data tech-niques are not always appropriate \nor useful for scientific data files. By applying an object-oriented methodol-ogy to data files, we can \nadd the intelligence required to improve data interoperability and provide an elegant mrchanism for supporting \ncompiex, evolving, or multi-disciplinary applications, while still supporting legacy codes. As a result, \nscientists and engineers should be able to share datasets with far greater ease, simplify-ing multidisciplinary \napplications and greatly facilitat-ing remote collaboration between scientists. This research was supported \nin part by the National Aero-nautics and Space Administration under NASA Contract No. NASl-19480 while \nthe authors were in residence at ICASE, NASA Langley Research Center, Hampton, VA 23681. Au-thors can \nbe reached at mdh@unyo .edu, pm@icase .edu, and jvr@icass .gov. More information on SmartFiles can be \nfound at http://nnn.icase.edu/-haines/html/smart.h~ml. Permission to make digital/hard copy of part \nor all of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for profit or commercial advantage, the copyright notice, the title of the publication \nand its date appear, and notice is given that copying is by permission of ACM, Inc. To copy otherwise, \nto republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or \na fee. OOPSLA 95 Austin, TX, USA 0 1995 ACM O-89791-703~0195/0010...$3.50 I Introduction Data files \nplay a fundamental role in scientific com-puting. While there are scientific programs that require no \ninput and produce little output, most large scien-tific programs interact with a number of data files \nfor both input and output. Moreover, scientific programs are often coupled via data files with other \nprograms LO create large systems. These systems provide the basis for multidisciplinary applications, \nsuch as those used for aircraft design and environmental simulation. Data files are in many ways idea1 \nfor coupling pro-grams and sharing inforrnation between researchers. They are persistent, they can be \naccessed from differ-ent languages, and they do not create problems with overlapping name spaces. Unfortunately, \ndata files usu-ally consist only of a series of bytes. whose syntax and semantics are implicitly defined \nby the programs that interact with them. In consequence, the narrow in-terface between programs that \nfile I/O might otherwise provide is lost. leaving one with a very broad and un-wieldy interface. The \nbasic problem with the current situation is that the structure and meaning of a data file is implicot \nin the programs interacting with it, the comments (if any) in the file, the directory in which the file \nis stored, the name of the file, and so on. Thus trying to use a file pro-duced elsewhere is roughly \nanalogous to the problem of interacting with external data structures without hav- 453 ing access to \nthe routines that create and manipulate the data structures. Object-oriented programming lan-guages provide \na solution to the latter problem, by cou-pling the data structures with the routines that manipu-late \nthem. We believe that the object-oriented method-ology extends naturally to data files as well. yielding \nmany of the same benefits to data files as it does m the context of programming languages. Our approach \nto the software engineering issues in-herent in data files is to replace current data files with smart \nfiles, object-oriented analogs of current dumb files. A smart file consists of a file desc.riptor, the \ndata itself, and a set of associated library routines for inter-acting with the data at a relatively \nhigh level of abstrac- tion. The access routines can also provide novel filtering capabilities, such \nas units conversion and consistency checks, not available with dumb files. Our goal is to apply the principles \nof encapsulation, modularity, and inheritance to data files, resulting in a cleaner file ab-straction \nand greatly simplifying the interaction of users with complex scientific and engineering programs. This \npaper describes the concepts of the SmartFile system. In section 2 we provide an overview of the sys-tem \nand its capabilities, and a comparison to related research is provided in Section 3. In section 4 we \nde-scribe file types and the language used to define file types: DAFT (mta File Types). Section 5 describes \nthe interaction between SmartFiles and legacy systems; Section 6 describes the mechanisms for supporting \nauto-matic conversions; and Section 7 introduces the core ac-cess routines used to interact with the \nfiles. In section 8, we provide an example of a SmartFile for unstructured grids, and we provide current \nstatus and future direc-tions in section 9.  Overview The notion of self-describing data implies that \na SmartFile must at least contain both raw data and descriptive data (meta data in database terminology). \nTherefore, as depicted in Figure 1, a SmartFile consists of two main sections: . a file descriptor, which \ndescribes the syntactic and semantic contents of this file; and SmartFile Figure 1: Logical view of \na SmartFile . a file data section, containing the actual data needed by application programs. For various \nreasons related to performance and 1egac.y system support, the physical definition of a SmartFile may \nor may not resemble this logical view of a Smart-File. However, it is important that from the user s \nper-spective, both sections of the file are contained within a single Unix file, thus allowing the standard \nIJnix com-mands (cp, mv, tar, ci, . . .) to operate on Smart-Files. To do otherwise would mean providing \nseparate interfaces for all Unix commands applicable to files. Currently, the SmartFile descriptor consists \nof three components: a file type, which can be a stand-alone type or a member of a complex hierarchy \nof file types; a layout, which provides a detailed syntactic de-scription of the organization of the \nraw data in re-lation to the abstractions (fields) defined by the file type; and the attributes, which \nprovide file-specific ancillary mformation (e.g. data, author, etc.) necessary for proper interpretation \nof the data file. File types define a collection of abstractions or fields composed from data types, \nparameters, and attributes. The data types may be simple (e.g. double) or com- plex (e.g. struct), and \narrays of any data type are supported. Parameters provide for generalized file types on the basis of \nvariable-length fields, by allowing arrays to be defined in terms of an abstract parameter value rather \nthan being restricted to fixed sizes. Attributes provide ancillary information about a field, file type, \nor file. Examples of common attributes include units of measure, date/time stamps, system of mapping \nused, etc. A detailed description of file types is given in Sec-tion 4. The following example illustrates \nthe specification of a field called pressure, defined as an array of doubles whose length is based on \na parameter named nnodes, and whose units are specified in pounds per square inch: field pressureCnnodes.1: \ndouble <units=psi>; In addition to providing descriptive information, at-tributes can be used to automatically \ndrive conversion and filtering tools provided by the system or as user routines. From our example. if \npressure is desired in millimeters of Mercury rather than pounds per square inch, then an automated conversion \nmechanism (<mnHg> = <psi>*51.7151) can be invoked to make the conver-sion on-the-fly. Section 6 provides \nmore details on using attributes to trigger automatic conversions. 2.1 System Organization The SmartFile \nsystem is organized into three exten-sible components (as depicted in-Figure 2): file types. conversion \ntables, and access routines. Each data file is an instantiation of a given file type? similar to the \nrelationship between an object and a class. The file types are either provided by the core SmartFile \nsystem, provided by a domain-specific extension, or pro-vided by the user. File types can be created \nstand-alone or from other file types, using inheritance to create a file type hierarchy. Section 4 details \nfile types and the DAFT language used for creating them. Conversion tables are used to direct the conversion \nof data elements from one form to another, or from one dat,a structure representation to another. For \nunits con-version, automated tables are available [ll], and in the case of data structure conversions \nthe user must provide the routines that are triggered by the attributes. Sec-tion 6 describes the details \nof conversion tables and how conversions are initiated. The access routines provide the user with a simple \ninterface with which to create and query a SmartFile. The interface can easily be supported in both C \nand Fortran, and users are free to extend the interface as needed by writing higher-level routines in \nterms of the given, low-level routines. Section 7 details the SmartFile access routines. The extensible \ndesign of the SmartFile system allows application areas (such as computational fluid dynam-ics) to provide \ncommon file types, conversion tables and access routines that can be shared among users of that community. \nAdditionally, user s can extend the system to further refine its operation for their exact needs.  2.2 \nCapabilities The current modus operandi for scientific program-mers is to use the standard I/O routines \nprovided through either Fortran or C to create data files with arbitrary representation. The goal of \nSmartFiles and other related systems is to elevate the programmer to a higher level of abstraction so \nthat interaction with a file can be done at an abstract, conceptual level rather than at a raw, byte \nlevel. In the process of designing SmartFiles, we have identified the following capabilities as being \nessential towards achieving this goal: Interacting with file data using user-defined ab-stractions (fields). \nSpecifying general file types that are related to data files as classes are related to objects. Providing \nthe ability for the user to extend all por-tions of the design, including file types conver-sion/filtering \ncapabilities, and access/interface rou-tines. Providing consistency checks to ensure that written data \nconforms to the file type specification. Providing an automatic filtering mechanism by combining attribute \ninformation with conversion tables/routines. Supporting legacy data files and programs. Since many scientific \nprogrammers are using legacy pro-grams or interoperating with people who are, sup-port for legacy files \nand systems is tantamount to interoperability. SmartFiles conforms to Booth s specification of an object-oriented \nsystem [3] by supporting abstractzon, Figure 2: SmartFile encapsulalion, modularity. and hierarchy. \nAbstraction and encapsulation are supported by interfacing with the file using access routines that are \ndriven by the file type information. Thus, a software layer is placed between the user and the data file, \nallowing for filtering, consis-tency checks, and performance optimizations. Modular-ity is supported \nin the ability to decouple the segments of a SmartFile for support of legacy systems. Hierar-chy (inheritance) \nis supported by allowing the user to specialize file types, conversion tables and routines, and access \nroutines from general abstractions.  Related Research The notion of adding syntactic and semantic de-scriptions \nto files is not new: Pablo [2] utilizes a self-describing data format for performance trace files; netCDF \n[9] provides a self-describing format for multi-dimensional tabular data (such as sensor data); and HDF \n[S] is a self-defining file format for transfer of var-ious types of data (n-dimensional data, raster \nimages) between different machines. These systems all impose a specific structure on the data that can \nbe represented (such as multidimensional tables), in a sense restrict-ing their users to a single file \ntype whose field names and values may vary. SmartFiles allows for true user-system organization defined \nfile types! where the user is in complete con-trol over both the structure and content of the data fields. \nThus a representation for a graph structure can be done as easily as a multidimensional table. This is \ncrucial for many engineering programs, such as adap-tive mesh refinement in computational fluid dynamics, \nwhich use data files to store grid configurations. Addi-tionally, SmartFile data types can be generalized \nfor a wide variety of similar data files by incorporating run-time values called parameters into their \ndefinition. This allows for the same field type to occur in different quan-tity for different data files \nand yet still belong to the same file type. There are also a variety of standardized, application-specific \ndata formats, including FITS [7] for astronom-ical data, GRIB [lo] for meteorological data, PDS [6] for \nspace mission data, SDTS [4] for geographical data, and a variety of graphical data formats, including \nTIFF, GIF, and JPEG. SmartFiles does not restrict the user to a specific format; rather. the user is \nallowed to create new formats (file types) from scratch or from existing file types through inheritance. \nELFS [5] describes an object-oriented approach to high-performance file I/O, in which files are treated \nas typed objects. The file objects encapsulate the details of obtaining high-performance I/O on a variety \nof parallel and distributed machines. While ELFS and SmartFiles both apply 00 methodology to file access, \nthe goals and implementations are different. ELFS strives for encap-sulation to support high-performance \nI/O in a parallel or distributed system, whereas SmartFiles strives for creating files that are self-aware \nand can perform con-versions and consistency checks. ELFS is implemented as an 00 system in Mentat (C++), \nwhereas SmartFiles supports a simple language to allow the user to specify the file type. or simply use \nan existing file type, and the interface is supported in both C and Fortran. On the other side of the \ncapabilities spectrum for self-describing data files are object-oriented databases. Al-though SmartFiles \ndo support some OODBMS features, such as self-describing data and the ability for the end-user to create \nhierarchical data abstractions, they do not attempt supporting the more difficult (and resource consuming) \nfunctions such as concurrency control. au-tomatic. recovery, and complex query facilities [l]. By omitting \nthese capabilities unnecessary for their in-tended use, we can create a much faster, easier to use, and \ncompact tool. Perhaps the single largest problem with many of the existing solutions to improving data \nfiles is the lack of support for legacy systems. We have provided support for integration of legacy files \nand programs into the sys-tem so that data file interoperability can occur even when legacy systems continue \nto use raw data formats. 4 File Types In the object-oriented language C++, a class is used to provide \na semantic description for a set of abstrac-tions that will apply to a new data type. Objects, in C++, \nare then instantiations of this new data type with a given set of values for the abstractions. Even though \nthe objects themselves may differ, it is always the case that two objects with the same data type, or \nclass, will represent the same physical abstractions. SmartFiles extends this idea to files by introducing \na mechanism for creating and specifying file types that are to be associated with data files. Similar \nto data types. file types provide a semantic description for a set of abstractions, called fields, within \na file. A Smart-File is then an instantiation of a given file type with filetype sf-point-t = C <type=sf-point-t>; \nparameter npoints ; x, y : int <units=inches>; field point[npointsl : (x,y) <system=cartesian>; **+ SF-TYPE \n(sf-point-t) *** *** SF-LAYOUT ( 65) *** 5 0 1 12 23 34 45 +*+ SF-FIELD (npoints 37 I) *** *** SF-FIELD \n(point 40 5) *** Figure 3: Sample SmartFile a particular set of values for the fields. However, un-like \na C++ class, the arrangement and storage of fields within a file type may differ from file to file of \nthe same type. For example, two data files representing unstruc-tured grids may both be of the same file \ntype, but may have a different arrangement of the fields within the file type. To accommodate this flexibility \nin represen-tation, a SmartFile descriptor (cf. Figure 1) consists of both a file type, which defines \nthe field abstractions in the file, and a layoul, which defines how the fields for the given file type \nare mapped to the physical storage of a file. Thus, SmartFile objects are instances of gen-eral file \ntypes coupled with a file-specific layout. Note, however, that file layouts are maintained automatically \nby the SmartFile access routines and, except for legacy systems (cf. Section 5), are transparent to the \nuser. Figure 3 depicts a sample SmartFile with its file type . layout, and data. SmartFiles may be physically \nstored in binary or ASCII form (in this case ASCII), and the user is given the option when the file is \ncreated. The definition of a file type, specified using the DAFT specification language, consists of \nthree types of decla- For illustration purposes, we have included the actual DAFT description for the \nsf-point-t file type, when in reality only the file type name would actually appear in the SmartFile \ndescriptor. rations: attributes, parameters, and fields 4.1 Attributes Attributes provide a mechanism \nfor associating ancil-lary, descriptive information relating to the elements of a SmartFile, including \nthe fields, file types, and files themselves. Attributes consist of a pair of <name, valve> strings, \nwhere the the value of the string is open for mterpretatlon by the user. Most commonly, actual string \nvalues are used, such as <units=crn>, though nu-meric values are possible as well using the standard \nC routines sprintf and atof/atoi. In addition to providing the user with general infor-mation about the \nfile and its fields, attributes can be used as a triggering mechanism for implicit filtering of the data \nas its being read or written (cf. Section 6). For example, using the udunits [ll] library, attributes \nspecifying units of physical measure can automatically and efficiently be converted as the data is being \nread or written. Although file attributes are not new, comments are a kind of unstructured attribute \nthat have been the norm for scientific data files, using them as a triggering mechanism for implicit \nconversions is a useful and novel approach for scientific data files.  4.2 Parameters Parameters provide \na method for generalizing file types by providing a mechanism for specifying symbolic size and shape \nrelationships for fields. Depending on when the symbolic parameter is bound to a value, called bznding \ntime, the effect can range from a static field size to a dynamic field size. This makes it possible, \nfor exam-ple, to use the same file type given in Figure 3 for a file with 5 points as well as for a file \nwith 5000 points, since the number of points is specified as a parameter. How-ever, even though the files \ncontain a different amount of information, they can both be considered to be of the same type and therefore \nthe same abstractions are avail-able to the user, in this case points. Since parameters are always used \nto indicate size, they must be a posi-tive integral type, or in the case of our implementation, unsigned \nints. The binding time for parameters can potentially occur at any point from the specification of a \nfile type to its use, but we have identified three times that seem to be the most useful: 1. slalic, \nwhere the parameter is bound to a static value in the file type description; 2. early, where the parameter \nis bound by the user (using a sf-bind call) before accessing any field based on that parameter: or 3. \nlate, where the parameter is bound by the Smart-File system at file closing based on the number l)f items \nthat were written for the fields based on that parameter.  While late binding provides flexibility and \nease-of-use for a user, static and early binding provide the oppor-tunity to provide coherence checks \non the values used to create a field, ensuring that the number of elements put into a field match the \npre-spec.ified parameter value for that field. For late binding, the only coher-ence check possible is \nsymbolic, such as that two fields based on the same parameter have the same number of elements each. \nUsing parameters to obtain flexible file types and to provide automated coherency checks is another novel \nfeature of SmartFiles. 4.3 Fields Fields provide the mechanism that allows the user to define data abstractions \nthat will be used for interacting with the file data, constituting the heart of the file type. Specifically, \nfields provide persistent, user-defined dat(a structures, and in this way SmartFiles are similar to OODBMS. \nFields may be defined as simple data types int, float, double, . . .), or arbitrary struc- (eg.$ tures \nrecursively constructed from simple types. For example, the point field defined in Figure 3 is a complex \nstructure consisting of two integer subfields, x and y, A field is classified as a subfield if it is \nused to construct a larger field and lacks the field keyword, meaning that it cannot be used as a data \nabstraction for the get/put primitives. As an example of how fields are used to access data elements \nwithin a file, consider again the point field from Figure 3. A point element can be retrieved from the \nfile using the sf-get primitive: The inheritance mechanism for SmartFile file types filetype sf-point-t \n= ( parameter npoints; x9 Y : int; field PointCnpoints] : (x,y) <system=Cartesian> ; field Length[npoints] \n: double <units=meters>; 3 filetype sf-my-point-t : sf-point-t = { field Line [npoints] : int ; field \nLengthCnpoints] : double <units=f eet>; 3 Figure 4: Example of file type derivation err = sf-get (sf \n, point , &#38;point-arr, &#38;count, system=Cartesian ) ; as opposed to the standard method: for (i=O; \ni<count; ++i) ( fscanf (fd, %i%i , &#38;point-arr [il . x, &#38;point-arr [il . y) ; 3  4.4 Derived \nFile Types One of the most powerful features of any object-oriented system is hierarchy (inheritance): \nthe ability to build new objects from existing objects. SmartFiles provides for file type hierarchies \nby allowing the user to derive new file types from existing file types. Under derivation, the abstractions \ndefined in the base file type are available in the derived file type for extension or modification. All \ndeclarations in the base file type are present in the derived file type, unless redefined: and additional \ndeclarations may be made in the derived file type. For example, in Figure 4 the file type sfmy-point-t \nis derived from the file type sf-point-t, where a new field, Line, is defined and the attribute value \nfor an existing field, Length, is modified. forms an is-a relationship hierarchy, and any file can be \nopened using the type with which it was created or using any base type from which the actual file type \nwas derived. This provides the ability for two scientists to interpret the same data file in different \nways, which is necessary for supporting interoperability.  4.5 The DAFT Language The DAFT (DAta File \nType) language is used to de-clare the fields, parameters, and attributes that com-prise a SmartFile \nfile type. The syntax, shown in Fig-ure 5. was chosen to be both simple and powerful, al-lowing attributes \nto be associated with subfields, fields. and file types. Parameters must be declared before their use, \nsince a one-pass compiler will be used to parse the language, and the field keyword is applied to any \ndata item which is to be vzsiblc to the user via the SmartFile access routines. Specification of the \nsyntax in Figure uses [item] to indicate an optional item and { item . ..} to indicate zero or more occurrences \nof item. The DAFT compiler takes the file type declarations and produces an enhanced symbol table that \nis used by the SmartFile access routines. The point at which the compilation takes place is still under \ninvestigation. Cur-rently. a file type is associated with a SmartFile when the file is opened. and is \nspecified in the form of a string that refers to a file containing the DAFT syntax. A search path similar \nto the Unix BINPATH is used to lo-cate the DAFT file description. Once found, the speci-fication is compiled \n(interpreted) and the results added to the global file type symbol table. We are also investi-gating \nthe approach of pre-compiling the DAFT syntax and storing binary representations of symbol table en-tries \nthat can quickly be added to the global table upon opening a SmartFile.  5 Legacy Systems A shortfall \nof many existing systems for supporting improved access to data files is their inability to effec-tively \nintegrate legacy data files and programs with the system. While creating a new data system out of whole \ncloth is attractive, this all-or-nothing approach would clearly hinder users who want to utilize the \nnew features, filetype-desc spec-part spec-item param-decl param-item attr-list attr-item struct-decl \nstruct-def struct-item field-decl subfield-decl subfield-item bounds-list bounds-item type scalar-type \n-+ filetypeid[ :J id] =) { spec-part } t spec-item ; J ( spec-item ; . . . } -+ param-decl 1 attr-list \n) struct-decl 1 field-decl 1 subfield-decl + parameter param-item { I, param-item . ..} t param-id \n[ =) integer-const ] -+ <) attr-item { , J attr-item . ..} 0 + attr-id =) attr-value + struct struct-id \nstruct-def attr-list t { J struct-item { ; ) struct-item . ..} } -+ subfield-id  ( subfield-decl -+ \nfield subfield-decl + subfield-item { , J subfield-item . ..} : type attr-list + subfield-id { \nCJ bounds-list 1 } + bounds-item { ) J bounds-item . ..} -+ param-id integer-const. -+ scalar-type \n 1 struct-def -+ int 1 float 1 double  Figure 5: DAFT Syntax The resulting SmartFile would then resemble \nthe file 5 0 I 12 23 34 45 Figure 6: Sample legacy file for plotting program yet still maintain compatibility \nwith legacy programs and existing data files, or to interact with others in the community who are not \nusing the new system. In consequence, the SmartFile system was designed to allow interoperability with \nlegacy users and systems. This is done by providing an easy and automated way of creating a SmartFile \nfrom a legacy file and vice versa. To create a SmartFile from a legacy file. the user must provide three \nthings: the legacy data file, a file type desc.riptor that contains the SmartFile abstractions, and a \nlayout descriptor that maps the given abstractions to physical locations in the data file. These three \nelements are then passed to a special routine, sf-pack, which parses the file type and layout descriptors \nand creates a correctly-formatted SmartFile. The layout descriptor is simply a series of declara-tions \nof the form <fieldname:count>, where the or-der of the declarations specifies the corresponding order \nfor the data file. For example, consider the data for a plotting program that consists of some number \nof two-dimensional coordinate pairs preceded by the number of points in the file (as depicted in Figure \n6). A possible file type descriptor might be: filetype sf-point-t = C parameter npoints; x,y: int; field \npoint [npointsl : cx,y>; > and the corresponding layout descriptor would then be: npoints : I point:npoints \nin Figure 3. Note that the layout descriptor can also make use of the specified parameters, so that the \nsame layout descriptor can be re-used when a new legacy data file needs to be re-packed. This is an important \nconsid-eration because it allows the file type and layout de-scriptors to remain unchanged and still \naccommodate new versions (updated datasets) of the legacy data file. To extract the legacy portion of \na SmartFile, the sf-unpack routine is used to simply strip away the lay- out and file type information. \nBy providing a clean and un-cumbersome method for interoperating with legacy systems, SmartFiles of- \n fers scientific programmers the unique opportunity to gradually convert programs from standard language \nI/O primitives to SmartFile primitives while still remaining compatible with older datasets. Moreover, \nthe user who has completely made the transition to the SmartFiles paradigm can still effectively cooperate \nwith colleagues who continue to use raw data files. This is an important consideration that is often \noverlooked by many software system designers.  6 Data Conversion One of the most common programming \noperations that scientific programmers undertake is writing filters to convert the output data from one \nprogram into a suit- able format as input data for another program. Large scientific applications are \noften written as a collection of programs forming a pipeline, with such filters at each step of the pipeline, \nand changes in one program can cause a ripple in the pipeline that necessitates changes in all of the \nsubsequent filtering programs. SmartFiles attempts to remedy this situation by firstly de-coupling the \ndependence that a program has on physical file formats, using data abstractions instead of/actual I/O \nstatements. Secondly, they provide a trig- dering mechanism (via the attributes) to apply implicit filtering \ntechniques when data abstractions are being read or written. Since SmartFile data is not just pas- sive \nASCII data, but has attached semantic content, via the file type and the attributes of the file, the \nsys- tem can perform whatever supported data conversions are requested during insertion or extraction \nof infor- canonical units : cm % length kg % mass newton % force conversion factors: 1 inch = 2.54 \ncm % length 1 foot = 12 inch % length 1 barleycorn = 0.3333 inch % length 1 furlong = 660 foot % length \n = 1000 gram % mass 1 kg I dyne = I gm cm / set-2 % force 1 erg = 1 gm cm-2 / set-2 % energy Figure 7: \nSample conversion table mation. For example, if a file contains a field of dis-tances in meters, but \none prefers distances in feet, the sf-get command can perform this conversion by spec-ifying the attribute \n<units=f eet>. The SmartFile library notes the difference between the requested at-tribute and the stored \nattribute, and consults the con-version tables for a meters to feet equation, finding <feet> = <meters>*3.28084. \nIJnits conversion is but one example of the kinds of conversions frequently needed with scientific data. \nThe set of conversions envisioned for support include: 1. Change of physical units (e.g. furlong to barPeycorn2). \nL. Change of coordinate systems (e.g. polar to Cartesian). 3. Conversion between different sels of physical \nquan-tities (e.g. momentum and density to velocity and pressure). 4. Change of data structure representation \n(e.g. cell-centered nodes to vertex-centered nodes). 5. Interpolations and smoothing operations.  The \nfirst three of these conversions can be done with conversion tables. such as the one depicted in Figure \n7. At runtime, when a conversion is needed, these tables *A barleycorn is i inch, as the astute reader \nmust surely know. are consulted to determine if there exists an appropriate path from the known value \nto the desired value. Ex-ternal conversions systems, such as Unidata s udunits package [ll], can also \nbe consulted. The set of equa-tions defined by the conversion path is then applied t,o each data element \nas it is being streamed into or out of the system. Table-driven interpretation has several advantages. \nFor one, it is easy to inherit and specialize tables for extending the system to new disciplines. For \nexample, an astronomer may need units like solar-masses. and parsecs, in addition to the units in the \ndefault tables, and these new units can easily be added. Also. table-driven interpretation is quite powerful. \nAs a trivial ex-ample, compound units like newton-cm /src2 create no problem -as long as the system understands \nnewton, cm, and set separately, it can treat the whole as an algebraic composite of these simpler units. \nSimilarly, given equations relating density, energy, velocity, pressure, and so on, the system can derive \nnew equa-tions to provide conversions not explicitly provided. The last two conversions listed, change \nof data struc-tures and the various smoothing and interpolation op-erations, require the user to provide \nadditional code to perform the conversions. There is, for example, no aut#o-mated method for converting \nfrom cell-centered nodes to vertex-centered nodes. However, while the user is required to provide such \ncode, the system provides the triggering mechanism to automatically invoke t,hese con-versions depending \non the way in which user s want t,he data to be retrieved/stored. 7 Access Routines The access routines \nprovided by the SmartFile core library support opening and closing a file, getting and putting fields \nfrom a file, and inquiring and setting at-tributes. The routines support both C and Fortran in-terfaces, \nand we envision also supporting this interface from a C++ class. For simplicity, we detail the interface \nroutines using the C interface. int sf-open (const char *fileName, const char *fileType, sf-openmode-t \nopenMode, sf-filemode-t fileMode, sf-file **smartFile); . The sf-open routine attempts to open a Smart-File \neither for creation or as an existing file. The fileType is used to locate the corresponding de-scriptor \nfile. fileType.sfd, located in the file type directory path. The filetype descriptor contains the DAFT \ncode that declares the available abstrac-tions. The declarations are parsed and loaded into a symbol \ntable associated with the active Smart-File descriptor defining this file. Additionally, the fields are \nflattened for optimal reading/writing. The openMode specifies whether the file should be written (create) \nor read. and the fileMode deter-mine whether the file is ASCII or binary. int sf-close (sf-file *smartFile); \n. The sf-close routine closes a SmartFile and per-forms the integrity checks. There are two types of \nintegrity checks: cornpleleness and coherence. The first, completeness, determines if all fields exist \nin the file as specified by the file type. This check is important when the file will be used later. \nby an-other program that will expect certain information to exist. The second check, coherence, determines \nwhether parameter-based fields have the appropri-ate number of elements based on their parameter values. \nAll unbound parameters are also bound at closing time. int sf-get (sf-file *smartFile, const char *fieldName, \nvoid *getLocation, char *desiredAttr, int *getCount) ; . The sf-get routine retrieves the data stored \nin a given field of a SmartFile. The address where the data is t,o be stored is given by getLocation, \nand getcount is used to return the number of items read. To avoid problems with ordering of matrices, \nall field names must return either a scalar value or an array of values, such that they will be stored \ncon-tiguously starting from getlocation. If getCount is specified as input, then only that many items \nwill be read. If getcount is zero on input, then the entire field will be read. Successive reads from \nthe same field will keep track of their place, so that the user can incrementally access the field data. \nThis ability is needed to check for read-termination con-ditions that are based on the data being read \n-a common technique for scientific programming. The desiredAttr argument can be used to specify how the \nuser expects the data to arrive, and is compared against the actual attributes for the specified field \nin the file type. If there is a mismatch, then the system searches for a conversion path in the conver-sion \ntables. If found, the appropriate conversions are made as the data is being read, otherwise an error \nis reported. int sf-put (sf-file *smartFile, const char *f ieldName, void +putLocation, char *desiredAttr, \n int *putCount); . The sf-put routine writes the data that is stored starting at putLocation into the \nfield specified by f ieldName. As with sf-get, successive puts to the same field will keep track of their \nplace, and putcount is used to specify how many field values are to be written. The desiredAttr argument \ncan be used to specify information about the data to be placed into the specified field so that the system \ncan apply conversions as necessary. int sf-bind (sf-file *smartFile, const char *parameterName, unsigned \nint value); . The sf-bind routine allows the user to bind a value to a parameter that is not statically-bound \nby the file type, so that consistency checks performed when the file is closed can be more accurate. \nOf the three binding times mentioned in Section 4.2. sf -bind performs early binding. int sf-pack (const \nchar *fileType, const char *rawDataFile,  a const char *layoutDescFile, const char *smartFile); . The \nsf-pack routine creates a SmartFile from a raw data file, file type, and layout descriptor as explained \nin Section 5. int sf-unpack (const char *smartFile, const char *rawDataFile); . The sf -unpack routine \ncreates a raw data file from a SmartFile by simply stripping away the SmartFile components of the file. \nint sf-inqattr (sf-file *smartFile, const char *fieldName, const char *attrName, const char **attrValue); \n. The sf-inqattr routine retrieves the attribute in- formation for a given field or file (if field is \nNULL). The name of the attribute is specified, and a pointer to a string containing the value of the \nattribute is returned. int sf-addattr (sf-file *smartFile, const char *fieldName, const char *attrName, \nconst char +attrValue); . The sf-addattr routine allows the user to assign the given value to the attribute \nspecified for the field or file (if field is NULL). Example In this section, we give a brief example \nof a SmartFile and its use. Figure 8 depicts the file type descriptor for an unstructured grid file type, \nuseful in computational fluid dynamics. The fields in this file type include: an edgelist, describing \nthe mesh topology (essentially a pla- nar graph), a coords list giving the location of the mesh points, \nand lists describing edges on solid, viscous, and far-field boundaries. Parameters control the number \nof nodes, number of edges, number of cells, and number of filetype Unstructured = < <type=Unstructured> \nparameter nnodes, nedges, ncells, nsedges, nvedges, nfedges; nodel, node2, celll, cell2 : int; field \nedgelist [nedgesl : {nodel, node2, celli, ce112); field slist [nsedges] : int ; field vlist [nvedges] \n: int ; field flist[nfedgesI : int; x,y : double ; field coords[nnodes] : cx,y> <system=cartesian>; 1 \nFigure 8: Example of unstructured grid file type edges for solid, viscous, and far-field boundaries. \nThis is a simple, yet realistic, example of the data required to represent an unstructured grid. Figure \n9 depicts a program fragment which produces an ASCII file of type unstruct-t, and Figure 10 gives a analogous \nfragment for reading such a file. This exam-ple illustrates a few of the simplest SmartFile capabil-ities. \nFirst, fields can be read and written in different order, since the programmer is only concerned with \nthe field abstractions, not their actual layout in the data file. Second, one of the fields is read repeatedly, \nwhile another is never read. There is complete freedom on reading; writing is more constrained. Every \nfield spec-ified by the file type must be written or the sf-close statement (in Figure 9) would fail \non an incomplete type error. 9 Status and Direction The goal of SmartFiles is to elevate the programmer \nto a higher level of abstraction, so that interaction with data files can be done at an abstract, conceptual \nlevel rather than at the level of integers and floats. In addition to the benefits of abstraction, it \nis also possi-ble to do units conversion or other kinds of intelligent processing. The SmartFile system \nis actively being developed at by a collaboration of computational scientists and main()( sf-file *ugrid-file; \nstruct edge{ int nodel, node2, celll, ce112; 1 edges[~~~~-~~l; struct coord{ double x, y; 3 coordsC~0~~-~01; \n err = sf-open(\"unstruct.dat\", \"Unstructured\", SF-WRITE, SF-ASCII, &#38;grid-file); . . . err = sf-bind(ugrid-file, \n\"nnodes\", nnodes); err = sf-bind(ugrid-file, 'hedges\", nedges); I . . err = sf-put(ugrid-file, \"coords\", \ncoords, NODE-NO, NULL); err = sf-put(ugrid-file, \"edgelist\", edges, EDGE-NO, NULL); . . . err = sf-close(ugrid-file); \n3 Figure 9: Program fragment writing unstructured grid data main()( sf-file *ugrid-file; int nnodes; \nstruct edge< int nodei, node2, celll, ce112; 1 ~~~~~CEDGE-NO~; struct coordC double x, y; 1 coordsC~0~~-~01; \n err = sf-open(\"ugrid-data\", \"Unstructured\", SF-READ, SF-ASCII, &#38;ugrid-file); . ~~ err = sf-get(ugrid-file, \n\"edgelist\", edges, hedges, NULL); err = sf-get(ugrid-file, \"coords\", coords, bnnodes, NULL); . ~. err \n= sf-close(ugrid-file); 3 Figure 10: Program fragment reading unstructured grid data computer scientists \nat the University of Wyoming and Science, University of Illinois UC, March 1992. Re- ICASE. Prototype \nsoftware for the interface is available, vised July, 1994. and the DAFT compiler is currently being completed. \n Grady Booth. Object-Oriented Analysis and De- [31 We are also working on the integration of the udunits \nsign. The Benjamin/Cummings Series in Object- package that will allow for automatic units conversion \nOriented Software Engineering. based on the units attribute, and several unstructured Benjamin/Cummings, \nsecond edition, 1994. ISBN CFD codes and their associated data files are begin con-o-8053-5340-2. verted \nto use the system. The support for legacy sys- tems allows the old version of the programs to continue \nPI Robin G. Fegeas, Janette L. Cascio, and Robert A. operating with the newer SmartFiles version. Lazar. \nAn overview of fips 173, the spatial data transfer standard. Cartography and Geographic In- Future plans \nfor the system include developing addi-formation Systems, 19(5), December 1992. Spe- tional conversion \ntables, interfacing with existing soft-cial Issue: Implementing the Spatial Data Transfer ware systems \nfor data files (such as netCDF), and au-Standard. tomatic generation of layout descriptors for legacy \nsys-tems. We are also planning to construct an MD0 appli-John F. Karpovich, Andrew S. Grirnshaw, and \n[51 cation for aircraft design using SmartFiles as the cou- James C. French. Extensible file systems \n(elfs): An pling devices between the codes. Finally, though per- object-oriented approach to high performance \nfile formance has not been a major issue, we are looking at i/o. In Proceedings of the 9th Annual Conference \non optimization techniques to improve the I/O system per- Object-Oriented Programming Languages, Systems, \n formance. For example, one idea is to flatten the fields and Applications, pages 191-204, October 1994. \nwith subfields so that the entire field (or multiple fields) NASA/Jet Propulsion Laboratory. Planetary \nData can be read in a single operation. PI System Standards Reference Manual, August 1994. In summary, \nwe have designed and are currently im-Version 3.1. plementing a system for applying object-oriented \nprin- ciples to data files. The goal of our work is to provide a NASA/Science Office of Standards and \nTechnology. [71 solid, sensible approach to data file interoperability for A User? Guide for the Flexible \nImage Transport scientific and engineering codes. System, May 1994. Version 3.1. National Center for \nSupercomputing Applic.ations 181 Acknowledgments (NCSA). The HDF Reference Manual, February 1994. Version \n3.3. We wish to thank the anonymous reviewers for their Russ Rew, Glen Davis, and Steve Emmerson. PI \ninsightful comments and Scott Leutenegger for his NetCDF User s Guide. Unidata Program Center,thoughts \non object-oriented database systems. April 1993. Version 2.3. John D. Stackpole. A Guide to GRIB: The \nWorld DOI  References Meteorological Organization Form for the Storage of Weather Product Information \nand the Exchange Malcom Atkinson, Francois Bancilhon, David De- PI of Weather Product Messages in Gridded \nBinary witt, Klaus Dittrich, David Maier, and Stanley Form. National Meteorological Center, National \nZdonik. The object-oriented database system man-Weather Service, NOAA, 1.0 edition, February ifesto. \nIn Proceedings of the 1st International Con- 1994. ference on Distributed and Object-Oriented Desagn, \npages 946-954, 1989. I111 UNIDATA. Udunits: A library for manipulating units of physical quantity. PI \nRuth A. Aydt. The Pablo self-defining data for-http://www.unidata.ucar.edu/packages/udunits/. mat. Technical \nreport, Department of Computer  \n\t\t\t", "proc_id": "217838", "abstract": "Data files for scientific and engineering codes typically consist of a series of raw data values whose description is buried in the programs that interact with these files. In this situation, making even minor changes in the file structure or sharing files between programs (interoperability) can only be done after careful examination of the data files and the I/O statements of the programs interacting with this file. In short, scientific data files lack self-description, and other self-describing data techniques are not always appropriate or useful for scientific data files. By applying an object-oriented methodology to data files, we can add the intelligence required to improve data interoperability and provide an elegant mechanism for supporting complex, evolving, or multidisciplinary applications, while still supporting legacy codes. As a result, scientists and engineers should be able to share datasets with far greater ease, simplifying multidisciplinary applications and greatly facilitating remote collaboration between scientists.", "authors": [{"name": "Matthew Haines", "author_profile_id": "81100474760", "affiliation": "Computer Science Department, University of Wyoming", "person_id": "PP14165643", "email_address": "", "orcid_id": ""}, {"name": "Piyush Mehrotra", "author_profile_id": "81100294582", "affiliation": "ICASE, NASA Langley Research Center", "person_id": "PP39036414", "email_address": "", "orcid_id": ""}, {"name": "John Van Rosendale", "author_profile_id": "81100016729", "affiliation": "ICASE, NASA Langley Research Center", "person_id": "P146369", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/217838.217882", "year": "1995", "article_id": "217882", "conference": "OOPSLA", "title": "SmartFiles: an OO approach to data file interoperability", "url": "http://dl.acm.org/citation.cfm?id=217882"}