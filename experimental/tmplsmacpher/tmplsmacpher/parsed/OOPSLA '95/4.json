{"article_publication_date": "10-01-1995", "fulltext": "\n Application of Domain Analysis to Object-Oriented Systems Steven Fraser, Honna Segel, Bell Northern \nResearch; Jim Coplien, AT&#38;T; Judith White, Addison-Wesley; Honna Segel honna@bnr.ca 613-763-2082 \n Abstraci: A variety of domain analysis techniques exist. One definition of domain analysis is that it \nidentifies variability and commonality in a family of systems for the purposes of organizational learning, \ndeci-sion-making, establishing the basis for systematic re-use, structuring and eliciting requirements, \nand analyzing existing systems. The collective heritage of domain analysis techniques crosses the frontier \nbetween the procedurally-oriented and the object- oriented paradigms. In the New World of object- oriented \nsystems, there is as yet no consensus on what problems are best addressed using domain analysis, how \nto choose the best technique for a par- ticular environment, or how to best implement a strategy for \ndomain analysis. The workshop sought to address best practices in these areas. Each participant submitted \na paper on their view and experience of domain analysis. The compilation of these papers is available \nfrom the Honna Segel. What is the definition of dumailt? In the spirit of developing a shared vocabulary, \nthe par- ticipants arrived at alternative definitions of domain. A domain is characterized by: . a set \nof problems with similar functional, tech- nical, operational and quality requirements for which there \nexists or will exist a family of soft- ware applications sharing some common func- tionalities: . a well-defined, \nsemantically coherent collec- tion of concepts which is largely self-referen- tial; . a family of systems, \nor application area which has shared functionality and definable aspects of commonality and variability; \n . a body of knowledge of interest. What are the applications of domain analysis? reuse communication \nof domain knowledge, consen-sus building, and shared understanding product-technology mapping; different \ntech-nologies can provide solutions to different products; different products can use the same technology. \nThis kind of reuse is made visible through a domain model. domain model is used as a basis for framework \ndevelopment cost reduction plan for change identify common requirements arnoung dift er-ent products \nre-engineering of existing products and pro- cesses How do application analysis and domain analy-sis \ntechniques differ? Both application and domain analysis techniques distinguish commonality and variability \nand . capture structure and behaviour of a system. Application analysis focuses on one system, one appli- \ncation, one solution, while domain analysis deals with a family of systems, applications and solutions. \nScoping and partitioning activities yield a structural view of the system, captured, for example, using \na class diagram. Use-case enactment, information-flow and interaction modelling yield a bchavioural view \nOI the system, captured. for example. in Harcl sla~c charls. What are the steps in domain analysis? This \ndifference in focus results in the ihllowing gcncral steps in domain analysis: scoping. usin: an organiya-tiondl \nmissions statement and requirements; con~cxI modelling, identifying the domains and how I~c \\. in~cr-- \nAustin, TX October 15-19, 1995 act. antl clcrlnain modcilin~. Is domain analysis the same for legacy \nand greenfields? Whether the domain model under development is intended lo suppon a legacy system or \ngreenfields (new system) development u ill strongly influence how domain analysis methods are used. While \nthe domain modclling sops outlined above are the same in both cases. the inputs and therefore how the \nactivities are done are quite di lt crent When in greenfields develop- mcnl. Ilic inpul to the analysis \nactivity is requirements: thus ~hc scoping activity rakes the form of requirements analysis, while in \nlegacy the activity would take the form of mining for patterns in the existing solution space. In general. \nthe activities will differ in that legacy inputs arc in the solution space, and greenfeilds input in \nthe prohleni space. Best practices in domain analysis Each par-tic:Ipant I~i&#38;lightcd their best practices \nand harriers. Most of the points below were endorsed by al participants. Best practices:~undal~zentals \n. Do 311 organizational mission analysis to clar- ify and justify the scope of the domain analy-sis. \nThe goal of this analysis is to clarify the goal of the organization, the problems that stand in the \nway of reaching that goal, and where domain analysis can be most effectively applied. Using the organizational \nmission analysis, see how available technologies map to product requirements. One technology can be used \nin several products-conversely, several different products can use the same technology. Results of this \nmapping can be used to correct and rebne the organizational mission.  Figure 1: Mission, technology \nand products cupping and re$rtement activities \\ \\ \\ I II Pr / / / / J Set predetermined closure criteria; \nbe very specific about the scope of the analysis exercise and pro- vide some criteria at the beginning \nfor testing when the scope has been achieved. Ensure that basic good practice is covered: have an executive \nsponsor; buy or manage subject-matter experts; use small, experienced teams; prototype and iterate! In \nthe first iteration of domain analysis, choose a domain that falls into one organizational group rather \nthan spanning groups. This will lower the organizational impedance. Use systematic team techniques, such \nas brain- storming, elicitation questions, identifying organizational trade-offs. Use transitioning techniques, \nsuch as pilots, roles, mentoring, etc. Do early validation of the domain model through use of a paper \nmodel. Best practices: methodology &#38; tools Establish what you want your method to elicit and capture; \nuse whatever notations and tools are convenient. Your method should promote reuse and permit tra- cability \nbetween different views of a system. It should capture data, variability, commonality, pri- oritization. \n(Feature-Oriented Domain Analysis (FODA) is a popular technique.) Add scenaries and categories (or roles) \nto OMT. If the domain is UI intensive, then extend scenarios with task and user role analy- sis to model \nthe user context Use roles as an analysis tool: roles as dynamic classification , another form of delegation \ni.e. a person object becomes an employee and acquires access to the data and methods needed for an employee \nonly then. Use convenient notations and tools. Stay as close as possible to application analysis methods \nand tools, to lower the impedance through tool and knowledge reuse.  Barriers to domain analysis Doing \nthe opposite of any of the best practices men-tioned above is certain to create a barrier - for example, \nan unclear mission and lack of closure criteria will make the domain analysis activity unfocused and \nits success immeasurable. Some specific barriers that were experienced by work- shop participants were: \npoor access to subject-matter experts (SME) no buy-in by SMEs: often creation of a domain model can lead \nto application development that will remove the jobs of subject-matter experts. This can be a factor \nin obtaining sub-ject-matter expert (SME) participation. lack of management buy-in lack of training insufficient \nproblem definition lack of criteria for closure of domain analysis -not knowing when to stop. problem \nstated as re-engineering the software when its the company that needs to be re-engi- neered management-defined \nownership of objects rather than domain partitions difficulty keeping domain model and applica- tions \ndeveloped in synch Domain analysis activities grouped by level of detail and ordered in time. A key \nactivity of the workshop was the creation of a wall of domain analysis activities, roughly ordered by \nthe level of detail of the activity and how the activities would be ordered in time. The goal of this \nworkshop activity was to derive a view of domain analysis activi- ties that transcended particular rncthodologics. \nA scc- ondary goal was IO help build a shred voc;lhular~: iI was discovered that the same acliviry was \ndisguised hy the use of very difkrenl labels. a circumslancc Ihal impedes brisk communication. Below \nis the list ofdomr!in analysis aclivilies, scrial- ized. The most abstract activities that should occur \nearly on appear first, and the most detailed activities that should appear later occur last: scoping: \n. establish business context . identify market cr,nstraints through hu.~irlzss analysis . organizational \nmission analysis . define problem . decide if domain analysis is appropriate . select systems to be \nanalyzed -legacy, green- field? . map technologies to products. and reti11e orga- nizational mission \nstatement context modelling: . scope domains (e.g. boundaries) . identify sub-domains . identify requirements \nand constraints build state model of domain partition user and system function . requirements mapping \ndomain modelling: identify features walkthrough scenarios prototype scenarios get feedback from experts, \ncustomers, users -include programmers investigate functional and non-functional con-straints map from \napplication domain (problem) to solution analysis produce final domain report iterate until desired granularity \not description is reached keep and review modelling workbook Austin, TX October 15-19, 1995 Lessons learned \nand observations mature domain) may be unstable due to the imma- Companies in different domains are investing \nin turity of the processes used to develop the domain rhe crearion and maintenance of domain models. \nmodel. Examples of immature process are poor Examples: telecom (CSELT/Sodalia (Italian telcos) capture \nand communication of the domain model, and BNR); shipping (OOCL); sensor devices lack of facilitation \nand consensus-building in (Schlumberger). One company is building a small- agreement on the domain model, \nlack of tools to talk implementation of their domain model as a capture the models. basis for application \ndevelopment. . In the cxpcrience workshop participants domain models add value in the short term (e.g. \nin the first application b.ased on the domain model) because it lormali/.cs the front-end processes needed \nto clar- ify and scope requirements. In the longer term (fol- lowing applications) the domain model is \nan asset that can be utilized to achieve the benefits (listed more fully under What are the applications \nof domain analysis? , above) such as reuse, improved planning, identification 01 commonality across domains. \netc. Its difficult to keep the domain model both general and synchronized with applications. The domain \nmodel always lags behind first application development. When separate orga- nizational groups develop.for \nreuse (develop- ers of domain model) and with reuse (developers of applications based on the domain model), \nthere is difficulty of synchro- nizins applications with the domain model they re based on. However. \nwhen the same qanlzation group develops both for and with reuse (i.e. they develop both the domain model \nand the applications based on the domain model) the domain model tends to become too narrow and based \non those specific applica- tions. . The fact that a domain is mature doesn t necessar- ily imply that \nthe domain model will be stable - slability of a domain model is more a reflection of organizational \nmaturity. Two factors identified as affecting the stability of the domain model are changing problem \nscope of the problem and matu- rity ot. organizational processes. Scoping: A nar- row problem scope allows \nsimplification of the domain model. When the scope is broadened, the domain model does not simply extend \n- deeper changes may be necess ary. Unstable processes: For example. a domain model based in physics \n(a  \n\t\t\t", "proc_id": "260094", "abstract": "", "authors": [{"name": "Steven Fraser", "author_profile_id": "81339499863", "affiliation": "Bell Northern Research", "person_id": "PP35043323", "email_address": "", "orcid_id": ""}, {"name": "Honna Segel", "author_profile_id": "81342510684", "affiliation": "Bell Northern Research", "person_id": "PP43124813", "email_address": "", "orcid_id": ""}, {"name": "Jim Coplien", "author_profile_id": "81100241805", "affiliation": "AT&T", "person_id": "PP14093302", "email_address": "", "orcid_id": ""}, {"name": "Judith White", "author_profile_id": "81332535119", "affiliation": "Addison-Wesley", "person_id": "P150420", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/260094.260221", "year": "1995", "article_id": "260221", "conference": "OOPSLA", "title": "Application of domain analysis to object-oriented systems", "url": "http://dl.acm.org/citation.cfm?id=260221"}