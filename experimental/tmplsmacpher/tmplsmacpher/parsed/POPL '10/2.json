{"article_publication_date": "01-17-2010", "fulltext": "\n Coarse-Grained Transactions EricKoskinen MatthewParkinson MauriceHerlihy University ofCambridge University \nofCambridge BrownUniversity Abstract Traditional transactional memory systems suffer from overly con\u00adservative \ncon.ict detection, yielding so-called false con.icts, be\u00adcausethey arebased on .ne-grained,low-level \nread/writecon.icts. In response, the recent trend has been toward integrating various abstractdata-typelibraries \nusing ad-hoc methods ofhigh-level con\u00ad.ictdetection. These proposals have led to improved performance \nbut alack of a uni.ed theoryhasled to confusion in theliterature. We clarify these recent proposals by \nde.ning a generaliza\u00adtion of transactional memory in which a transaction consists of coarse-grained (abstract \ndata-type) operations rather than simple memory read/write operations.Weprovide semanticsforbothpes\u00adsimistic(e.g.transactionalboosting) \nand optimistic(e.g.traditional TMs and recent alternatives) execution. We show that both are in\u00adcluded \nin the standard atomic semantics, yet .nd that the choice imposes different requirements on the coarse-grained \noperations: pessimistic requires operations be left-movers, optimistic requires right-movers. Finally, \nwe discuss how the semantics applies to numerousTMimplementationdetailsdiscussed widelyintheliter\u00adature. \nCategories and Subject Descriptors D.1.3 [Programming Techniques]: Concurrent Programming Parallel Program\u00adming; \nD.3.1 [Programming Languages]: Formal De.nitions and Theory Semantics; D.3.2 [Programming Languages]: \nLanguage Classi.cations Concurrent, distributed, and parallel languages; D.3.3 [Programming Languages]: \nLanguage Con\u00adstructs and Features Concurrent programming structures; F.3.2 [Logics and Meanings of Programs]: \nSemantics of Programming Languages Operational semantics GeneralTerms Languages,Theory Keywords Coarse-grainedtransactions, \nabstractdata-types,trans\u00adactional memory, transactionalboosting, commutativity, movers 1. Introduction \nTransactional Memory (TM) comes in many varieties: hardware [13], software[7,10,28], andmixtures ofboth[6,24].Commonto \nall these approaches is the need to de.ne and detect synchroniza\u00adtion con.icts: circumstances under which \ntwo transactions cannot proceed inparallel.Existing TMsystems detect con.icts at a .ne\u00adgrained level: \neach transaction maintains a read set, encompassing Permission to make digital or hard copies of all \nor part of this work for personal or classroomuseisgranted withoutfeeprovided that copiesarenot madeordistributed \nforpro.tor commercial advantage andthat copiesbearthis notice andthefull citation onthe .rstpage.Tocopy \notherwise,torepublish,topostonserversortoredistribute tolists, requiresprior speci.cpermission and/or \nafee. POPL 10, January17 23,2010,Madrid,Spain. Copyright c . 2010ACM978-1-60558-479-9/10/01. . .$10.00 \n the locations it read, and a write set, encompassing the locations it wrote. Two transactions are deemed \nto con.ict if one s write set intersects the other s read or write set. De.ning a synchronization con.ict \nto be read/write con.ict is appealing because it is usually easy to classify operations, whether in hardware \nor software, as reads or writes. Nevertheless, there is an increasing realization that read/write con.icts \nsupportinsuf.cientlevels of concurrency for objects sub\u00adject to contention.Con.ictdetection on thebasis \nofread/write sets is conservative: two high-level operations may not logically con\u00ad.ict even though they \nshare memorylocations.For example,iftwo threads insert distinct items in a shared collection, then, logically, \nneither one shouldbe affectedby the other s actions.Butifthe col\u00adlectiontypeisimplemented, say, as alinkedlist,thentheir \nreadand write sets mayinadvertentlyintersectin aharmless way,producing an unnecessary false con.ict. \nIn response we have suggested replacing this low-level notion of read/write con.ict with ahigh-level \nnotion of con.ictsbetween methods of abstract data-types, leveraging sequential method se\u00admantics[11].Moreover, \nothershavebegundeveloping automated techniquestodiscoverhigh-level semantics[2,8,27].Aswehave shown,the \nresultingTMs often offerperformanceimprovements of atleast an order of magnitude. At present, despite \ndecades of previous work in the database community, there is no formal account for these high-level ap\u00adproachesinthecontext \nofprogramminglanguages.Consequently, theliterature tends to be ad-hoc and numerous questions are open: \nWhatexecution models arepossible?Howdothesehigh-level ap\u00adproaches relate to traditional read/write-based \ntransactional mem\u00adory? What, precisely, are the requirements imposed on abstract data-types?Would a uni.ed \ntheory uncover other opportunitiesfor improvementin the state-of-the-art? In thispaper we unify these \nad-hoc techniquesinto a theory we call coarse-grained transactions, generalizing transactional mem\u00adory \nwith a semantics that answers these open questions. A coarse\u00adgrained transaction consists of operations \non abstract data-types rather than simple memory read/write operations. Wepresent both optimistic and \npessimistic execution semantics of coarse-grained transactions,and showthatboth abidethestandard atomicseman\u00adtics. \nRather than using a general notion of commutativity, we pre\u00adcisely characterize the requirements of operations \nin terms of left\u00admovers and right-movers [22]. We .nd that the pessimistic exe\u00adcution requires that outstanding \noperations be left-movers with re\u00adspect to each other, whereas the optimistic execution requires that \noperationsbe right-movers with respect to committed operations. We then discuss how our semantics can \nbe used to model a va\u00adriety of implementation detailsin the literature.Our semantics en\u00adcompassesboth \n.ne-grained operations(e.g.,memory read/write) and coarse-grained operations (e.g., transactional boosting \n[11]). Our pessimistic execution semantics model, again, transactional boosting[11], whereas the optimistic \nexecution semantics model STMimplementations withlazy update strategies[7,28] as well as recent work \nwhich resembles coarse-grained transactions [3]. Finally we discuss our treatment of a variety of other \nissues in the literature including (closed) nested transactions [25], check\u00adpoints[17]anddeadlock detection[18]. \n Example T1: atomic { T2: atomic { x := 3; z++; z++; y:= 4; }} The transactions T1 and T2 in the example \nabove execute a series of statements which read or write values from locations on the shared heap(x,y,z).Ifexecuted \nconcurrently the transactions will con.ictbecauseboth write to z, and one willbe aborted. However, if \nwe assume incrementing z is a single instruction, notice any execution is serializable. This observation \nstems from thefactthatincrementsto z commute: applyingthemin either order yieldsthesame .nalstate.Therefore,aninterleaved \nexecution: T1: (x:=3) (z++) (cmt) T2: (z++) (y:=4) (cmt) is equivalent to a serial execution which preserves \nthe commit order: T1: (x:=3) (z++) (cmt) T2: (z++) (y:=4) (cmt) Thisserialorder canbe obtainedbyreasoning \nabout moverness[22] of the operations performed by transactions. A read(a) operation can move to theleft \nor right of a write(b:=e) operation(fromdis\u00adtinct transactions) when a and b are distinct and a is not \nfree in e. For example, to construct the serial history above, we moved the operation T2:(y:=4) to the \nright of T1:(z++). Moreover, incre\u00admenting z can be applied in either order and reach the same .nal state. \nCoarse-GrainedTransactions We saw abovethattwo operations which each increment a variable commute, i.e. \ncan move to the left or to the right of each other.Thisillustratedhow theimprecise con.ict detection \nin traditional STM implementations is unable to detect the serializability of some executions at the \n.ne-grained level of memory options. Now consider a higher level of abstraction, where transactions perform \ncoarse-grained operations. In the following example two transactionsperform operations on adata structure: \nglobal SkipList Set ; T1: atomic { T2: atomic { Set .add(5); if (Set . contains (6)) Set .remove(3); \nSet .remove(7); } } Thisillustrates the changing focus in the transactional memory community. The old \nread/write operations are replaced with arbi\u00adtrary, coarse-grained operations. A transaction consists \nof opera\u00adtions(represented as object methods)on regions of theheap(rep\u00adresented as object state)which \nwe will assume to be disjoint. The shared state aboveis a Setdata structure,in this caseimplemented as \na(linearizable) skip-list.Each transaction thenproceeds byper\u00adforming Setmethod calls: insert(x), remove(y), \ncontains(z). Now at this coarse-grained level, how can operations be syn\u00adchronized? Because high-level \noperations may share memory lo\u00adcations,using a .ne-grained synchronizationtechnique(detecting read/write \ncon.icts) impairsperformance[11].The solutionisto instead base synchronization on how one method moves \nwith re\u00adspect to another. In the example above assuming SkipList is linearizable any of the methods can \nmove to the left or right of any of the other methods provided their arguments are distinct. In other \ncases some operations may only move in one direction. For example, a semaphore increment operation can \nmove to the left of adecrement operationbut not vice-versa. Recently, ad-hoc techniques have appeared \nin the literature which appeartobe exploitingleft-moversand right-moversto some degree,yet they lack \na formal footing[3,11,20].In thispaper we show how these and future proposals can be characterized in \na semanticsbased onleft-movers and right-movers. Semantics In the remainder ofthispaper wegive a semanticsfor \nageneralized notion of transactions, which we call coarse-grained transactions, where transactions perform \nabstract data-type oper\u00adations rather than simple memory read/write operations. Despite having a single \natomic semantics, there are two execution seman\u00adtics and each imposes different requirements on the moverness \nof the transactional operations: 1. Pessimistic Execution Semantics (Section 3.1) Transactions willbedelayed \nfrom taking stepsin the semanticsif the opera\u00adtions theyintend toperformdo not commute withthe outstand\u00ading \noperations of other active transactions. This semantics requires that operations be left-movers with \nre\u00adspect to other uncommitted transactions. This semantics is subject to deadlock [11]though recovery \nis possible [18] via inverse operations. This left-mover require\u00adment alsopermits a transaction toperform \naninverse operation that annihilates the transaction s most recent operation. Since all thepending operationstotherightmustbeleft \nmovers,the most recent operation canbe moved to thefar right. 2. OptimisticExecutionSemantics(Section3.2) \nTheshared state is logically duplicated into transaction-local state and, thus, method call steps in \nthe semantics are always enabled. How\u00adever, when transactions attempt to commit, they may be re\u00adquired \nto abort if they have performed method calls that do not commute with other concurrent transactions. \nOtherwise transaction-local changes are mergedinto the shared state. This semantics requires that operations \nbe right-movers with respect to operations of other committed transactions. This se\u00admantics includes \ntraditional read/write software transactional memory withlazy update strategies[7,28] as well as recent \nalternatives whichinvolve user-de.ned con.ict resolution[3]. This semanticsis also subject tolivelock \n(asisSTM).  We show(Section5)thatbothofthe abovehigh-level semantics are equivalent to atomic semantics.Wethendiscuss(Sections6,7) \nhow the semantics applies to numerousTMimplementationdetails discussed widelyin theliterature. Limitations \nCoarse-grained transactions have two other require\u00adments not addressed here. First, operations must be \nlinearizable a property guaranteed in traditional TM since read/write opera\u00adtions are typically atomic. \nSecond, for simplicity we require that moverness take isolation into consideration. If two objects share \nmemory one may not be able to reason about them independently. Type systems or alias analyses couldpotentiallyprovide \nsuchguar\u00adantees. 2. Semantics 2.1 Preliminaries We willuse thefollowinglanguage: c ::= c; c | e := e \n| if b then c else c s ::= s; s | c | beg; t; end t ::= t; t | c | o.m  . ..,c; c ' .,T,ssh -.A ..,c \n' .,T, .c.ssh . ..,s; s ' .,T,ssh -.A ..,s ' .,T, .s.ssh .t,t.,T,ssh -A .t,skip.,T,s ' . * sh (t,beg)\u00b7(t,o.m)\u00b7\u00b7\u00b7(t,end) \n.., beg;t;end.,T,ssh --------------.A .., skip.,T,s ' sh Figure1:AbridgedAtomic semantics - .A The language \nconsists of standard commands c such as assign\u00adment and branching, statements s which can be commands \nor initiate transactions, and transactions t which can be commands or coarse-grained operations (represented \nas method calls m on shared objects o). Expressions e are standard and involve vari\u00adables, constants, \nalgebraic expressions, .-abstraction and applica\u00adtion. Boolean expressions b are similar. Thread-local \nstate can be modeled as shared objects that are only touchedby one thread.For simplicity we assume aparallel \ncomposition rather than an explicit treatment of fork. Transactions operate on a shared store of objects, \nmanipulated with theircorresponding methods.Wedenotetheshared store ssh, andit contains shared objects, \neachdenoted o.The shared store s0 sh isde.ned as: . 0 ssh = {.o . objects(P).o .. init(o)} where objects \nis the obvious function which returns the set of all objects used by the program P, and init returns \nthe initial state of thegiven object. The language has the abridged atomic semantics given in Fig\u00adure1(thefull \natomic semantics with all reductions and adetailed treatment ofthelabelingisgivenin ourTechnicalReport[19]). \nThe semantics is a labeled transition system. A con.guration is a pair T,ssh representing the transactions \nT and the shared store of objects ssh. The initial con.guration is a parallel composition of threads: \nC0 a = {T0 ,T1 , ...,Tn},s0 = sh where each Ti ..,Pi. is atuple of transactionidenti.er(initially .)and \nthe program text for the ith transaction. Steps are taken when one element of T is selected and any enabled \nreduction is taken. The domain of labels is .. (N \u00d7 (o.m .{beg, cmt, abt})), where the .rst element is \nthe transactionidenti.er, and the second elementis either the oper\u00adationperformed orasymbolicrepresentationof \ntransactionbegin, commit or abort. The above semantics is atomic: all operations performed by a transaction \nare applied to the shared statein one step,in which the transitionislabeled witheach ofthetransaction \nsoperations .Inthe remainder of this paper we present two execution semantics, one pessimistic andone \noptimistic, whichimposedistinct requirements onthe shared objects.Wethen showthatboth are atomic(and,in \nSection6.1, opaque[9]).  2.2 Moverness We now formally de.ne the notions of left-and right-moverness \nwhichisdue toLipton[22].We will use moverness to characterize the necessary restrictions placed on the \nobject in the pessimistic and optimistic semantics. De.nition2.1. (LeftMover)o.m is aleft-mover withp.n,denoted \no.m . p.n,if and onlyiffor any state s p.no.m {s '' |.s ' .s --. s ' . s ' --. s '' } . {s ''' . s ''' \n} o.mp.n |.s ' .s --. s ' . s ' -- Thisde.nitiongives the conditions under which one stepin the semanticsis \naleft mover with respect to another step.Speci.cally, in agiven execution wheretwo methods are executed,the \ncondition is that the set of states reached is included in the set of possible states reached had the \nmethods occurred in the opposite order. Of course when o is adistinctobjectfrom p,thenfor anytwo methods, \nthe two areboth movers with respect to each other: It is important to note that in De.nition 2.1, the \nrelationship is an inclusion rather than an equivalence. The left-hand side of theinclusionis typically \na concrete execution where speci.c states are known. By contrast, the right-hand side must account for \nnon\u00addeterminism in the sequential speci.cations of the objects. For example,let o be apriorityqueue, \nandthe methodm betheremoval ofthehighest-priority element.Ifthere are multiple elementsinthe queue withthehighestpriority,thenthe \nsemantics ofthequeue may state that any of them will be returned. Thus, s ' in the right-hand sideis \na set of states, asis the entire right-hand side. We will later show that inclusion is suf.cient for \nproving seri\u00adalizability of execution traces.Whereaspreviousproofs of serializ\u00adability were based on \n.nding one equivalent sequential execution for aninterleavedexecution, ourprooftechniqueinstead showsthat \na given interleaved execution is contained within a set of execu\u00adtions, all of whom are sequential. De.nition2.2. \n(RightMover.,BothMover ..)De.nedsimilarly. De.nition2.3. (LiftedMovers)We de.ne left mover lifted to \nsets, denoted ., asfollows: . M1 .M2 = .(o.m,p.n) . (M1 ,M2 ). o.m.p.n Lifted versions of ., .. are \nsimilar and denoted ., ...  3. ExecutionSemantics In this section we present the two high-level semantics \none for pessimistic execution and one for optimistic execution. These se\u00admantics illustrate how different \nexecution models place different requirements onthe moverness ofthe coarse-grained operations.In the \nsubsequent sections we will showthattracesin either semantics are serializable, matching the atomic semanticsgiveninFigure1. \n3.1 PessimisticExecutionSemantics Con.gurationsinthepessimistic execution semantics are similarto the \natomic semantics given in Section 2.1. However, the elements of T are of the form .t,s,M,st., where t \n. N. identi.es the transactionif oneis currently running, s denotes theprogram code, M denotes the sequence \nof object methods that t has applied, and st is the transaction-local state. The initial con.guration \nis a parallel composition of threads: C0 p = },s0 {T0 ,T1 , ...,Tnsh, where each Ti = ..,Pi, \u00d8,s0 . and \ns0 is as de.ned in the previous sh section. The relevant reductions for pessimistic execution are given \nin Figure 2 (for the complete semantics, see our Technical Re\u00adport [19]). The PCMD step involves a thread \nexecuting a state\u00adment which impacts only thread-local state and control-.ow. In the PBEG rule the system \nmakes a transition in which a thread begins to execute a transaction. The effect is that the sequence \nof applied operations M is initialized to the empty sequence and the new transaction tuple is added to \nthe set of active transactions. t . N and the predicate fresh(t) indicates that t is fresh and strictlyincreasing(the \nmonotonicity requirementis unneededhere, but required for the optimistic execution semanticsdiscussed \nnext, which use t as a timestamp). PCMD . .t,s .{:=,if}; s ' ,M,st.,T,ssh -.P .t,s ' ,M,.s.st.,T,ssh \nPBEG fresh(t),beg ..,beg; s,M,st.,T,ssh -------.P .fresh(t),s,[],st.,T,ssh {o.m} . meths(T) PAPP t,o.m \n .t,x := o.m; s,M,st.,T,ssh - --.P .t,s,M :: ( x := o.m; s ,st, o.m ),st[x .. rv(.o.ssh.m)].,T,ssh[o \n.. .o.ssh.m] PUNDO t,o.m-1 .t,s,M :: (s ' ,st' , o.m ),st.,T,ssh - ----.P .t,s ' ,M,st' .,T,ssh[o .. \n.o.ssh.m-1 ] PCMT t,cmt .t,end; s,M,st.,T,ssh ---.P ..,s,\u00d8,st.,T,ssh meths(\u00d8) = \u00d8 ' meths(T . {.t,C,M,st.}) \n= methsM(M) . meths(T ' ) methsM([]) = \u00d8 ' methsM(M :: (s,st, o.m )) = methsM(M ' ) .{( o.m )} Figure2:PessimisticSemantics \n- .P The PAPP rule allows a transaction to apply a method m on a shared object o. The rule indicates \nthe initiation of a method call, whichis appended to the sequence ofoperations.Thelogalso includes the \ncurrent state andprogram counter, which maybe used laterinthePUNDOrule.The return value(givenbyrv)is \nstoredin the thread-local variable x.(Note that we assume the shared object islinearizable.) Inthesepessimisticexecution \nsemantics synchronizationis con\u00adsideredthroughout atransaction ratherthan simplyat commit-time. Thus \nthe PAPPstepinvolves a check. The commit order of the ac\u00adtive transactions is not determined a priori, \nso any active transac\u00adtion may commit at any time. Therefore there is a restriction for the reduction: \nthe new method call must be a left-mover with re\u00adspect to all other active method calls. Left-moverness \nensures that the current transaction could commitbefore allof the others. Since synchronization is considered \nduring the PAPP rules, the commit rule PCMT is trivial. We will see in the next section that these pessimistic \nsemantics stand in contrast to the optimistic se\u00admantics in which the PAPP rule is always enabled, but \na synchro\u00adnization checkisperformedin the commit rule. The commit rule PCMT merely involves discarding \nthe set of active methods and terminating the transaction. All effects have alreadybeen applied to the \nshared state. Finally the PUNDO rule allows a transaction to move back\u00adwards to theprogram location immediatelypreceding \nthe most re\u00adcently applied object method.Longerjumps arepossibleby multi\u00adple uses ofthePUNDOrule.PUNDOis \nalways enabledwhen M is non-empty.ThePUNDOrule(as wediscussinSection6)is useful to allow transactions \nto escapefromdeadlock[18]. Thereis no moverness requirementforthePUNDOoperation thereis a subtle reason \nwhyitis unneeded.As we showformallyin Section5.1,the doomed operationthatthetransactionisundoing is, \nin effect, a right-mover since all subsequent operations from other transactions areleft-movers.Thus, \nthedoomed operation can be moved to the far right and then annihilated with the inverse operation.  \n3.2 OptimisticExecutionSemantics We now present the optimistic execution semantics. We then, in Section3.3,compareittothepessimisticcounterpart.The \nmostsig\u00adni.cantdifferencebetween the twois that the optimistic semantics ensure synchronization at commit-time,whereasthepessimistic \nse\u00admantics ensure synchronization witheach operation. Before we continue, we emphasize that even though \nour model involves thread-local copies of the shared state, in many cases this is not a performance problem \nsince (i) copies are unneeded when operations are read-only and(ii)copy-on-write canbe used elsewhere.The \nexistingTL2[7]andIntel[28]implementations are evidence of thisfact. Con.gurationsinthe optimistic semantics \nare atripleT,ssh,lsh where T is a set of per-transaction state, ssh is the same as the pessimistic shared \nstate, and lsh is a log of pairs: each committed transaction and the operations ithasperformed.Elements \nof T are . - of the form .t,s,st,st,lt.. t is a unique transaction identi.er, s is the next code to \nbe executed, st is the transaction-local copy . - of the shared objects, st is aback-up copy of the \nstate(usedfor aborting), and lt is a log of the operations performed during a transaction(tobe usedto \ncheck moverness at commit-time).The initial con.guration is a parallel composition of threads: C0 opt \n= {T0 ,T1 , ...,Tn},s0 ..,Pi,s0 ,s0 , [].. sh, [], where eachTi = Labeled transitions occur when an \nelement of T is selected and one ofthe reductionsgiveninFigure3 applies(forthe complete semantics, see \nourTechnicalReport[19]).LikePCMD,theOCMD reduction merely applies changes to the local state, and leaves \n. - st unchanged. TheOBEGreduction represents theinitiation of a transaction. A new identi.er is generated, \nand the existing thread\u00ad . - local state is copied to st to be used if the transaction is later aborted. \nA snapshot snap(s,ssh) is taken of the current state of all shared objects, duplicating them from the \nshared store to the local . - store.The current s is also storedin st. In the reduction OAPP, a transaction \napplies a method. The operationisapplied tothelocal store(containing copies of shared objects), and the \noperation is logged so it can be replayed on the . - shared statelater at commit. st is unchanged. TheOCMTreduction \n.rstidenti.esthisset ofrecentlycommit\u00adted transactions by comparing the timestamp of committed trans\u00adactions \nwith the begin timestamp of the current transaction. The reductionis onlytakenifall ofthe transaction \ns methods are right\u00admovers with respect to methods of the recentlycommitted transac\u00adtions.If the reduction \nis taken, the thread-local operations from lt OCMD .- . .t,s .{:=,if}; s,st,st,lt.,T,ssh,lsh -..O .t,s,.s.st,s-t,lt.,T,ssh,lsh \nOBEG (t,beg) . - ..,beg; s,st,st,[].,T,ssh,lsh ----.O .fresh(t),s,snap(st,ssh),st[stmt .. beg; s ],[].,T,ssh,lsh \nOAPP (t,o.m) .- . - .t,x := o.m; s,st,st,lt.,T,ssh,lsh -----.O .t,s,st[o .. (.o.ssh).m,x .. rv((.o.ssh).m)],st,lt \n:: ( o.m ).,T,ssh,lsh .(tcmt ,lt' ) . lsh.tcmt >t . lt .lt' OCMT (t,cmt) . .t,end; s,st,s-t,lt.,T,ssh,lsh \n- ---.O .t,s,zap(st),zap(st),[].,T,merge(ssh,lt),lsh :: (fresh(tcmt ),lt) OABT (t,abt) .- ... --- .t,s,st,st,lt.,T,ssh,lsh \n----.O ..,st[stmt],st,st,[].,T,ssh,lsh snap(st,ssh) . = st[o .. .o.m .ssh] .o . objects(P) zap(st) . \n= st[o .. .] .o . objects(P) merge(ssh,[]) = ssh merge(ssh,lt :: ( o.m )) = merge(ssh[o .. (.o.ssh).m],lt) \n Figure3:OptimisticSemantics - .O are propagated to the shared state ssh via the merge function, and \na new timestamp(denoted fresh(tcmt))is appendedto the commit log. The reduction then clears the thread \nlocal state, restoring it to s0 . t =[\u00b7 .. .], clearing the thread-local log lt and discarding the . \n- unused st. The last rule OABT corresponds to aborting a transaction. The . - saved thread-local store \nst restored, code(i.e.program counter) . - is restored via st, and thelogisdiscarded. Remark: Partial \nAborts Note that by contrast to the pessimistic version,this semanticsdoes not allowpartial aborts[17].Adding \nsuch a facility can certainly be accomplished, but for ease of pre\u00adsentation, and since no existing implementations \nprovide it, we have omittedit.  3.3 Comparison As noted above, the most signi.cant distinction between \nthe two semanticsis when synchronization occurs.Thepessimistic seman\u00adtics perform a check (left-moverness) \nwith each coarse-grained operation, whereas the optimistic semantics perform a check (right-moverness)at \ncommit-time. Intuitively, the pessimistic left\u00admoverness preserves the invariant that any live transaction \ncan commit at any time. By contrast, the optimistic right-moverness checks to see if a transaction s \nthread-local store is logically con\u00adsistent given that other transactions may have committed since the \ncopy was made. There are several considerations involved in the choicebetween execution semantics: Aborts \nOptimistictransactions can alwaysproceed withoper\u00adationsimmediatelymodifying their thread-local store,however \nthey may need to be aborted. Pessimistic transactions are al\u00adways able to commit (modulo deadlock) but \nmay have to be delayedbefore applying an operation.  State Duplication The optimistic semantics require, \nat least logically, thread-local duplication of the shared state. Some\u00adtimes duplication can be reduced \n(e.g. with copy-on-write strategies)or even eliminated(e.g. when a return valueis un\u00adneeded or can be \notherwise calculated). Alternatively, the pes\u00adsimistic semanticsdoes not requireduplication.  Merge \nThe optimistic semanticsinvolve a commit-time merge ofoperationsintothe sharedstate.Inthe worst casethis \nmayin\u00advolve replaying the entire operation, perhaps favoring the pes\u00adsimistic semantics.However,there \nmaybeinstances(suchasin read/writeSTMs)where merge canbeimplementedef.ciently.  Inverses When transactions \nare aborted, the pessimistic se\u00admanticsperforms inverse operations(PUNDO).If these opera\u00adtions are expensive \nor dif.cult to de.ne, the optimistic seman\u00adtics may be preferred, which simply discards the thread-local \nscratchpad.  Objects In some applications, left-movers are more common than right-movers or vice-versa. \nIn such instances the corre\u00adsponding semantics(pessimistic or optimistic, respectively)is more amenablebecause \nmore concurrency ispossible.  Some examples ofthetwo semantics areasfollows.Anexample ofthe optimistic \nsemantics aretheTL2[7]STMimplementation andIntelSTM compiler[28], which wediscussinSection6.In each, \nlocks are used at commit-time, ensuring the left-moverness of pending updates. Another example of the \noptimistic semantics, discussed in Section 7.2, is recent work [3] in which operations are more coarse-grainedandcon.icts \nare resolvedbyprogrammer\u00adprovided rules.Finally,transactionalboosting[11]is an example of pessimistic \ncoarse-grained transactions. We discuss boosting in Section 7.1. A side-by-side empirical evaluation \nof pessimism versus optimismisleftforfuture work. Remark One might wonder whether the optimistic semantics \nare contained withinthepessimistic semantics(or vice-versa).Unfor\u00adtunately this is not the case because \nof the fundamental differ\u00adences described earlier, and leads to a more-or-less disjoint union of the \ntwo semantics. Whereas the pessimistic semantics maintain an commutativityinvariant(viathePAPPreduction), \nthe optimistic semantics check at commit.The two semanticshavedifferentkind oflogs: optimistictransactionshave \nintentionlogs (lt)where as pessimistictransactionshave undologs (M). One might try to thinkoftheintentionlogs \nasbeingemptyforpessimistic semantics and vice-versa,but then neitheris contained within the other.  \n 4. ExecutionTraces In this section wede.ne execution traces andprove severalimpor\u00adtantproperties of \nthem.ThesepropertieswillbeusedinSection5 to show that pessimistic and optimistic execution models are \nboth serializable. Recall that labels are given by the reductions in the seman\u00adtics (either -.O). They \nare taken from the domain .. .P or -(N \u00d7 (o.m .{beg, cmt, abt})), representing transaction com\u00admencement, \ncompletion and abortion, as well as applying opera\u00adtions on the shared objects. De.nition4.1. (ExecutionTrace)Atrace \no is a series oflabels: o = L0\u00b7L1\u00b7L2\u00b7\u00b7\u00b7 Wedenote an empty execution trace as .. De.nition 4.2. (Finals) \n.n is an inductively de.ned predicate, mapping a set of initial con.gurations and an execution trace \n(sequenceoflabels)toaset of .nal con.gurations: . [.n C .]= C . L' [.n C L\u00b7o]=[.n {C ' |.C . C.C -. C \n} o] For shorthand, we often use a single con.guration as the .rst argument to .n, though we mean the \nusual singleton set. Observe that we can always expand subsequences of any execution: Property4.1. (Containment \nFolding) [.n C o\u00b7o ' ]=[.n [.n C o] o ' ] Proof: Proof by induction on o. For details see our Technical \nReport[19]. Lemma 4.1. (Liftingcontainment) C . C ' . [.n C L] . [.n C ' L] Proof: Unrolling .n once \nand then proof by contradiction. For details see ourTechnicalReport[19]. De.nition4.3. (Movers liftedtolabels) \nL1 . L2 .. .C.[.n C L2\u00b7L1 ] . [.n C L1\u00b7L2 ] bRight-and both-movers b. and .. bare similarlylifted. Property4.2. \no.m . p.n .. (t,o.m) b. (t ' ,p.n) and similar forb. and ..b. Proof:Correspondenceisde.nitional.Fordetails \nseeourTechnical Report[19]. De.nition4.4. (Execution containment) . o . o ' = .C.[.n Co] . [.n Co ' ] \n Lemma 4.2. oa . ob . oa \u00b7o ' . ob \u00b7o ' Proof: By induction on o ' . For details see our Technical Re\u00adport[19]. \n 4.1 SerialTraces Recall that execution traces are given as series of labels in the transition systems \nof the appropriate operational semantics. For example,hereis a trace of two transactions: '' ' o =(t,beg)\u00b7(t,o.m)\u00b7(t, \nbeg)\u00b7(t , o.m)\u00b7(t, cmt)\u00b7(t,cmt) The following atomicity predicate indicates whether a transac\u00adtion occurs \nwithin an execution trace without anyinterleavedlabels from other transactions. De.nition4.5. (SerialTrace)Aserial \ntraceisgivenby thefollow\u00adingpredicate, inductively de.ned over an execution o: t,t .{t}. serial o .,t \n. serial o t/. t .,t . serial (t,beg)\u00b7o t,t . serial (t,cmt)\u00b7o t,t . serial o t,t . serial (t,o.m)\u00b7o \n.,t . serial . Thisde.nition statesthatatraceis serialif eachtransaction appears in the trace without \nanyinterleaved eventsfrom other transactions. We now show that the atomic semantics given in Figure 1 \nare serializable: Lemma4.3. (AtomicSerializability) Ca . * serial o .o = 0 -A Ca Proof: Trivial since \nall executions are of theform (t,beg)\u00b7(t,o.m)\u00b7(t,p.n)\u00b7\u00b7\u00b7 (t,cmt)\u00b7 ''' ' (t, beg)\u00b7(t ,o.m)\u00b7(t ,p.n)\u00b7\u00b7\u00b7 \n(t, cmt) \u00b7\u00b7\u00b7 Fordetails see ourTechnicalReport[19]. In thefollowinglemma,letLit denote an operation \ncorrespond\u00ading to transaction t.  Lemma4.4. serial o . serial o\u00b7(t,beg)\u00b7L0 t\u00b7\u00b7\u00b7Lnt \u00b7(t,cmt) when none \nof thelabelsin o correspond to t. Proof: By derivation over serial. For details see our Technical Report[19]. \n 5. Serializability 5.1 PessimisticExecutionModel We nowgive our serializabilityresultforthepessimistic \nsemantics. The structure of our proof of serializability of executions is stan\u00addard.We show thatfor any \nexecution of the semantics, there exists an equivalent execution in which all transactions appear in \na serial order(withoutinterleavings of operationsfrom other transactions). Left-moverness Invariant \nAn important part of the correctness of the pessimistic semantics is the fact that an invariant is maintained \nabout method calls of all active transactions. This is a result of the PAPP reduction. We de.ne a predicate \non a con.guration which holds if all operations of uncommitted transactions are left-movers with respect \nto all operations of other uncommitted transactions.Note that we use the notation Lt to mean anylabelinvolving \nt,i.e. (t, ). De.nition5.1. (ActiveLeft-Movers) . comm. = .o..Lt, Lt' . o.Lt b. Lt' where t .= t '  \nLemma5.1. comm. o ..t.o . ot \u00b7oU\\t Proof:Doubleinduction(i)showing thatforthe .rst t-label Lt = (t, \n) ino,that comm. o . oa \u00b7Lt \u00b7ob .Lt \u00b7oa \u00b7ob and(ii) showingthat comm. o . o . ot \u00b7oU\\t byinduction on \nthe sequence of t-labels occurringin o.Fordetails see ourTechnicalReport[19]. De.nition 5.2. (Active \ntransactions) The function active returns the set of transaction identi.ers in o whichhave not committed: \n. active(.,A)= A . active((t,beg)\u00b7o,A)= active(o,A.{t}) . active((t,cmt)\u00b7o,A)= active(o,A\\{t}) . active((t,abt)\u00b7o,A)= \nactive(o,A\\{t}) . active((t, )\u00b7o,A)= active(o,A) De.nition 5.3. (Live methods) The function live(o,t \n) takes an execution o and set of active transactions t and returns the set of operationsperformed by \ntransactions whichhave not committed: . live(., t )= \u00d8 . ({o.m}. live(o,t ) if t . t live((t,o.m)\u00b7o,t \n)= live(o,t ) otherwise . live(( , )\u00b7o,t )= live(o,t ) Note that the (t,abt) is not used in the pessimistic \nsemantics, but will appear in the optimistic semantics. The following predicate holdsifbothan execution \ntrace and a con.guration agree onthe set of all operations of uncommitted transactions. De.nition5.4. \n(Uncommittedconsistency) . consist(o,T)= meths(T)= live(o,active(o,\u00d8))  Moverness inPessimisticSemantics \nWe now show some moverness relationships which are speci.c to thepessimistic semantics and used throughout \ntheproof. Lemma 5.2. (t,beg) .. (t ' , ) (1) b' (t,cmt) . (t, ) (2) bProof: By showing that reordering \nthe executionleads to the same .nal con.guration .n.Fordetails see ourTechnicalReport[19]. Note that \n(t,cmt) is not a right-mover with (t ' , ). The proof wouldfailinthe .nal caseforEqn.2 where [.n C (t \n' ,o.m)\u00b7(t,cmt)] = \u00d8 Moving an operation to theleft of a commit maylead to an execu\u00adtion which is not \nvalid since the antecedent of the PAPP rule may nothold.Informally, the transactionperforming the operation \nmay need to wait until the other commits. In thefollowing let o\u00act denote an execution which contains \nno labels corresponding to t. Corollary 5.3. (ToLemma5.1)In thepessimistic semantics, comm. o\u00act . o\u00act \n\u00b7(t,cmt) . (t,cmt)\u00b7o\u00act Proof:Thisis animmediate consequence ofLemma5.1, notingthe moverness of (t,cmt) \ngivenbyEquation2. Lemma 5.4. (Impliedright-moverness) comm. o . o\u00b7(t,o.m)\u00b7o\u00act . o\u00b7o\u00act \u00b7(t,o.m) Proof: \nTrivialinduction.Fordetails see ourTechnicalReport[19].  Serializability Thenexttheoremshowsthatexecutions \nof thepessimisticseman\u00adtics are strictly serializable. The theorem proceeds by showing in\u00adclusionin another \nexecution oftwoparts: apre.xin which all com\u00admitted transactions appearin a serial order(using serial)and \na suf\u00ad.x of uncommitted operations in which comm. is invariant. We must also maintain asinvariantthe \nconsistency(consist(o,Cp.T )) between operations of uncommitted transactions in the execution trace and \noperations of uncommitted transactions as given by the con.guration. Finally, note that when the PUNDO \nrule is taken, the correspondingdoomed operationis moved tothe right and then annihilatedby theinverse \noperations. Theorem5.5. (PessimisticSerializability) For any o = 0 -P , Cp . * Cp .oC \u00b7oU.serial oC \n. comm. oU . consist(oU, Cp.T ) . o . oC \u00b7oU Proof: Weprovethetheoremby induction onthe executiontrace. \nconstructing an appropriate oC \u00b7oU at each step.Consider the empty execution o = ., which starts in con.guration \nC0 p. We can de.ne oC = oU = .. serial oC holds by axiom. comm. oU and consist(oU, Cp .T ) hold trivially.We \nnow show that .oC \u00b7oU.o . oC \u00b7oU . serial oC . comm. oU . consist(oU, Cp.T ) Lo ' .o -.P . ''' ' .oCo\u00b7U \n.o ' . oCo\u00b7U ' .serial oC ' .comm. oU ' .consist(oU , Cp' .T ) We case split on L. Case L = .: o ' = \no.Trivial. Case L =(t,beg): Let oC ' = oC and oU ' = oU \u00b7(t,beg). o ' . '' ' oC \u00b7 oU \u00b7 (t,beg) by Lemma \n4.2. serial oC holds because ' , Cp' serial oC holds. consist(oU .T ) holds because no new operationshavebeenperformed.Equation1 \nmaintainsthetruth of comm. oU ' . Case L =(t,o.m): Let oC ' = oC and oU ' = oU \u00b7(t, o.m). o ' . '' ' \noC \u00b7oU \u00b7(t, o.m) by Lemma 4.2. serial oC holds because serial oC holds. By the PAPP rule, Cp' .T = Cp.T \n.{o.m} and it is easy to see that live(oU ' , \u00d8)= live(oU, \u00d8) .{o.m}. '' ' Thus consist(oU , Cp .T ) \nholds. comm. oU holds because comm. oU and PAPP requires that {o.m} . meths(Cp.T ). Liftingthe antecedent, \nwehave that . L '' .L ' . oU.L b=. .L1 , L2 . oU .L1 . L2 ' b =. comm. oU Case L =(t,o.m-1 ): Without \nloss of generality, let oU = oa \u00b7 (t,o.m)\u00b7o\u00act.ByLemma5.4 weknowthat oU . oa \u00b7o\u00act \u00b7(t, o.m). Now weappend(t,o.m-1 \n) tobothsides, andthen chose oU ' = oa \u00b7o\u00act. Case L =(t,cmt): We .rstshowthefollowinginclusion: o ' = \no\u00b7(t,cmt) . oC \u00b7oU \u00b7(t,cmt) I.H.o . oC \u00b7oU . oC \u00b7ot \u00b7oU\\t \u00b7(t,cmt) Lemma 5.1 . oC \u00b7ot \u00b7(t,cmt)\u00b7oU\\t Corollary5.3 \nNowlet oC ' = oC \u00b7ot \u00b7(t,cmt). serial oC ' holdsbyLemma4.4. Letting oU ' = oU\\t, observe that oU ' is \na subsequence of oU, so comm. oU ' holds. 5.2 OptimisticExecutionModel Wenowprove serializabilityofthe \noptimisticmodel.Unfortunately we cannot reuse theproof of thepessimistic model.The optimistic model is \nfundamentally different: shared memory is not modi.ed in-place. Instead transactions modify local copies \nof memory and update the shared state at commit. The optimistic execution model performs synchronization \nat commit-time ratherthan synchronizing with each operation.The ef\u00adfectistwo-fold:(i)Ifa transaction \naborts then recoveryis achieved by simply discarding the transaction-local copy rather than invok\u00adinginverse \noperations.(ii) When atransaction t commits it must check that its operations can be moved to the right \nof operations corresponding to any transaction t ' which has committed after t began. Thisis why, for \nexample, in TL2[7]at commit-time trans\u00adactions acquire alockfor each modi.ed memorylocation.  Moverness \ninOptimisticSemantics Lemma 5.6. In the optimistic semantics, (t,beg) .. (t ' , beg) (3) b' (t,beg) .. \n(t ,o.m) (4) b' (t,o.m) .. (t ,p.n) (5) b (t,cmt) .. (t ' ,o.m) (6) b' (t,cmt) . (t, beg) (7) b' (t,cmt) \n\u00b7 (t, cmt) (8) (t,beg) . (t ' , abt) (9) b' (t,abt) . (t, abt) (10) b Proof: Fordetails see ourTechnicalReport[19]. \nTheproofofthe aboveLemmainvolves showingthatreordering the execution leads to the same .nal con.guration \n.n. Eqn. 3 holds because swapping the order of which transaction begins .rst has no effect on the eventual \ncommit order. Eqns. 4 and 5 hold because o.m operations are applied to transaction-local copies of the \nsharedstate anddoes notimpact concurrenttransactions.Eqn.7 holds because moving (t,cmt) to the left of \n(t ' , beg) reduces the burden on t ' when it ultimately tries to commit t ' begins with a newer copy \nof the shared state and can ignore the effects of t when scanning the commit log. Eqn. 8 holds because \nif a commit is moved to the left it may prevent the other transaction from committing since the commit \nlog will be longer. Finally, Eqns. 10 and 9 hold because the OABT rule discards transaction\u00adlocal changes. \n AbortingaTransaction Lemma 5.7. In the optimistic semantics, (t,beg)\u00b7ot \u00b7(t,abt) .. where ot is an execution \nconsisting oflabels of theform (t,o.m). Proof: First we show that this holds when ot = ., which requires \nus to show that [.n C (t,beg)\u00b7(t,abt)] . [.n C .].Or rather that [.n C (t,beg)\u00b7(t,abt)] = C. From the \noptimistic semantics it is easy to see that the OABT reduction restores the state which held beforetheOBEG \nreduction .red. The lemma can now be proven by a rather trivial induction on ot.Inthebase case when ot \n=(t,o.m),the claim above stillholds because OAPP1 and OAPP2 only perform changes to transaction\u00adlocal \nst and lt, which arediscardedbytheOABT reduction.This of courseholdsfor anylarger ot. Lemma 5.8. In the \noptimistic semantics, o\u00b7(t,beg)\u00b7oU \u00b7(t,abt) . o\u00b7oU\\t Proof: Usinginduction and themovernessgiveinEqns. \n4and 6, itis easyto show that o\u00b7(t, o.m)\u00b7o\u00act . o\u00b7o\u00act \u00b7(t,o.m) where o\u00act consists oflabels oftheform (t \n' ,o.m) or (t ' , beg).We then show that the set of all nt-labelsin o, that n 1 n 1 o\u00b7Lnt \u00b7o\u00act\u00b7\u00b7\u00b7Lt 1 \n\u00b7o\u00act . o\u00b7o\u00act \u00b7\u00b7\u00b7 o\u00act\u00b7Ltn \u00b7\u00b7\u00b7Lt 1 Fordetails see ourTechnicalReport[19].  Serializability We prove the \ntheorem again by showing that executions are con\u00adtainedwithin an alternate serialexecution.However,there \nare some differences. Since transactions operate on thread-local state, the (t,o.m) labels appearbutdo \nnotcorrespondto modi.cationstothe shared state.We arethereforefreetodiscard theselabels(solong as a commitlabelhas \nnot appeared).Thus when atransaction takes theOCMTstepit can move allofits operations tothe right ofother \ncommitted transactions because of the antecedent and it need not consider other uncommittedtransactions(because \nwetemporarily abort them). Theproofdepends on thefollowinglemmata.Weintroduce the notation o{t,t' ,...} \nto refer to an execution consisting of operations performedbyt,t ' , or anyothertransactions.The notations \no{t,...}, o{t,t' } and o{t' ,...} are similar. Lemma5.9. (Rightof committed)If lt .lt' then ' o\u00b7o{t,t' \n,...} \u00b7(t,cmt)\u00b7(t,cmt)\u00b7o ' . ' o\u00b7o{t' ,...} \u00b7(t,cmt)\u00b7o{t} \u00b7(t,cmt)\u00b7o ' Proof:First,byinduction we can \nmove allt operations tothe right within o{t,t' } because of Eqn. 5. Then each (t,o.m) can move to the \nright of (t ' , cmt) because lt .lt' . For details see our TechnicalReport[19]. Lemma5.10. (Move ops \nright) o\u00b7(t,beg)\u00b7o{t1 ,...,tn} \u00b7(t1 ,cmt)\u00b7o{t2 ,...,tn} \u00b7(t2 ,cmt)\u00b7\u00b7\u00b7 (tn,cmt)\u00b7ot . o\u00b7(t,beg)\u00b7o{t,t1 \n,...,tn} \u00b7(t1 ,cmt)\u00b7o{t,t2,...,tn} \u00b7(t2 ,cmt)\u00b7\u00b7\u00b7 (tn,cmt) Proof: Induction on n, usingLemma5.9.Fordetails \nsee ourTech\u00adnicalReport[19]. Lemma 5.11. (Movebeg right)Let ooc t be an execution consist of operations \nand commits of transactions other than t. If lt .lt' for all t ' . t then o\u00b7(t,beg)\u00b7ooc t \u00b7o{t} \u00b7(t,cmt) \n. o\u00b7ooc t \u00b7(t,beg)\u00b7o{t} \u00b7(t,cmt) Proof: Induction and Eqn. 7. For details see our Technical Re\u00adport[19]. \nDe.nition5.5. (AbortFactory) . oabt (o,A)=(t1 , abt)\u00b7\u00b7\u00b7 (tn, abt) .ti . active(o,\u00d8) Theorem5.12. (OptimisticSerializability) \nCopt Copt . * For any o = 0 -O , .oS. serial oSoabt (o,\u00d8) . o\u00b7oabt (o,\u00d8) . oSoabt (o,\u00d8) Proof:Byinduction \nonthe execution trace, where alluncommitted transactionshavebeen removed(i.e. aborted).Speci.cally, at \neach stepoftheproofwe construct an appropriate serialoS for whichwe can show oisincluded solongasbothare \nappendedbyoabt (oU, \u00d8). Base case: Consider the empty execution o = ., which starts in con.guration C0 \nopt . We can de.ne oS = .. serial oS holds by axiom, and . holds trivially.We now show that Lo ' .oS. \nserial oS \u00b7oabt (o,\u00d8) . o\u00b7oabt (o,\u00d8) . oS \u00b7oabt (o,\u00d8) . o -.O . '' '' .oS . serial oS \u00b7oabt (o ' , \u00d8) \n. o ' \u00b7oabt (o ' , \u00d8) . oS \u00b7 oabt (oS , \u00d8) Now case split on L. Case L = .: o ' = o.Trivial. Case L \n=(t,beg): LetoS ' = oS \u00b7(t,beg). Thepredicateserial oS ' \u00b7oabt (o ' , \u00d8) is equivalent(byLemma5.8) to \nserial oS \u00b7oabt (o,\u00d8) which holds by induction. Again using Lemma 5.8 and the inductive hypothesis, the \nother obligation holds:  '' '' o \u00b7oabt (o, \u00d8) . oS o\u00b7 abt (oS , \u00d8) Case L =(t,cmt): Firstwe show o\u00b7(t,cmt)\u00b7oabt(o1 \n,\u00d8) . oS \u00b7(t,cmt)\u00b7oabt(o1 ,\u00d8) . o{t' ,U} \u00b7(t,beg)\u00b7o{1 t,t\u00b7(t,cmt)\u00b7oabt(o1 ,\u00d8) (Rewrite) ' ,U} . (t,beg)\u00b7o1 \n\u00b7(t,cmt) (Lm.5.8) o{t' } \u00b7{t,t' } . o{t' } \u00b7o1 \u00b7(t,beg)\u00b7o1 \u00b7(t,cmt) {t' }{t} The last step is accomplished \nby induction with Lemmas 5.10 and 5.11. Now let o ' = o{t' } \u00b7o{1 t' } \u00b7(t,beg)\u00b7o{1 t} \u00b7(t,cmt).By the \ninductive hypothesis, serial o{t' } \u00b7o1 {t' } holds and it is easy to show that serial (t,beg)\u00b7o1 {t} \n\u00b7(t,cmt) holds. Thus serial o ' holds. Case L =(t,abt): Let oS ' = oS \u00b7(t,abt). Predicate serial oS ' \n\u00b7 oabt (o ' , \u00d8) holdsbecauseserial oS \u00b7oabt (o,\u00d8) holds andappending an abort t canbe removedbyLemma5.8(and \noabt now has a lesser obligation).Soitis also trivialto show that '' '' o \u00b7oabt (o, \u00d8) . oS \u00b7oabt (o, \n\u00d8) Case L =(t,o.m): Let oS ' = oS \u00b7(t,o.m). Predicate serial oS ' \u00b7 oabt (o ' , \u00d8) holdsbecauseserial \noS \u00b7oabt (o,\u00d8) holds andappending a single operation adds an event that will be removed by oabt . Usingsimilar \nreasoning and we can show that '' '' o \u00b7oabt (o, \u00d8) . oS \u00b7oabt (o, \u00d8)  6. Traditional(Fine-grained)STM \nMosttransactional memory systems[7,28]usethe optimistic se\u00admantics at the .ne-grained level of memory \nread/write operations. Transactions concurrently execute operations and when they try to commit they \neither succeed, in which case their effects atomically become visible, or abort, in which case their \neffects are discarded and the transactions restarts. Formally, our optimistic semantics uses per-transaction \ncopies ofthe shared state.Forperformance reasons,however, manytrans\u00adactional memoryimplementationsdoin-place \nmodi.cations of the sharedstate.Theyrelyon undo-logs(ratherthan our intention-logs) to reverse the effects \nof aborted transactions. Since the operations (read and write memory locations)aresimple,itiseasy tokeep \nundo-logs which consist ofprevious memory values. We now formalize traditional transactional memory using \nour semantics. Let L : N be a set of locations and V : N be a set of values. The shared store ssh consists \nof a single object . representing a memory, as well as per-transaction return values: ssh = ..,rt1 ,rt2 \n, .....Wede.ne the two method calls asfollows: .ti : ..read x.ssh = ssh[rti .. .[x]] .ti : ..write xv.ssh \n= ssh[.[x .. v]] When transaction ti reads x from the shared store, the rti compo\u00adnent of the shared \nstore is updated to contain the current value of x in .. The write operation updates . such that the \nvalue of x is v. Movernessisintuitive(let x,y and v,w each be distinct and \u00b7 means neither . nor .): \n..read x .. ..read y (11) ..write xv .. ..write yw (12) ..read x .. ..write yv (13) ..read x .. ..read \nx (14) ..write xv .. ..write xv (15) ..write xv \u00b7 ..write xw (16) ..read x \u00b7 ..write xv (17) Existing \ntransactional memory implementations mostly abide by the above rules.However theytypicallydo not considerEqn.15 \nto be aboth-mover. Invisible reads Invisible reads[12,33]and otherforms of read\u00adonlyaccessintransactionalmemoryimplementations \nexploitEqns. 11 and 14.Since read operations are alwaysboth movers withre\u00adspectto eachother,itis always \nsoundto allow read-onlyworkloads to interleave in any order. Implementations have various ways of handling \nthe advent of write operationsin such workloads. Eager Con.ict Detection in TL2 The TL2 implementation \nin\u00advolves an added optimization: eager con.ictdetection.Rather than keeping a thread-local view of memory \nand checking con.icts at commit, with each read/write operation, TL2 checks the location timestamp and \ncompares it with the transaction-local begin times\u00adtamp. Transactions are aborted if a con.ict is detected \n con.icts correspond to any instance of read/write operations on the same location (Eqns. 14, 15, 16, \n17). Eager con.ict detection can be over-approximated in our semantics as simply a non-deterministic \nchoice to take theOABTrule. Checkpoints andNestedTransactions Oursemanticsisamenable tothe checkpoints \nalternative[17]tonested transactions.Wein\u00adtentionally designed our semantics to be non-deterministic: \nthe UNDO rule can be invoked at any point during a transaction, al\u00adlowing the implementation to decide \nhow many times to apply theUNDO rule.Checkpoints allow us to model(i) nested trans\u00adactions[17] and(ii) \nmechanisms which escapedeadlock[18] as described next. Deadlock The pessimistic semantics may deadlock. \nConsider a con.guration in which T includes .t,o.m; C,{p.n},s. and ' '' .t ,p.n ; C, {o.m ' },s ' ..Ifneither \no.m . o.m ' nor p.n . p.n ' , then neither transaction will be able to take the PAPP step in the semantics. \nThere are implementation techniques for detecting such dead\u00adlock[18].Thesetechniques can recoverfromdeadlockbyperform\u00ading \neither a full abort (reverting all of a transaction s operations through multipleinstances ofUNDO)orpartial \nabort(reverting a subset of operations).Ideally, recoverywould onlyrevert the oper\u00adations necessary to \nallow another transaction to makeprogress. 6.1 Opacity In addition to serializability, recent work has \nproposed a new cor\u00adrectness condition called opacity [9]whichholds for most modern implementations oftransactionalmemory[7,28].Opacityinvolves \nserializabilityas well as two new requirements. We now show that both of our execution semantics are \nopaque. De.nition 6.1. (Opacity) An execution o is opaque, denoted opaque oif and only if 1. o is serial(serial \no). 2. Operationsperformed by an aborted transaction are never vis\u00adible to other transactions. 3. Every \ntransaction observes a consistent version of the state.  Proposition 6.1. (Opacityof Pessimistic Execution)For \nany exe\u00adcution o given by - .P, opaque o. Proof: Intuitively, the proposition holds because transactions \nonly performPAPPifallconcurrent operations(includingthose oftrans\u00adactions which have or may abort)are \nleft-movers, the transaction logicallyonly observes the state of the system at commit-time.For details \nsee ourTechnicalReport[19]. Proposition6.2. (OpacityofOptimisticExecution)For anyexecu\u00adtion o givenby \n- .O, opaque o.  Proof: Followsfrom thefact that the shared stateis updated atom\u00adically in OCMT and \nthat transactions duplicate the shared state in OBEG.Fordetails see ourTechnicalReport[19].  7. Coarse-grainedImplementations \n7.1 PessimisticCoarse-Grained(TransactionalBoosting) In recent work we have given a methodology for en\u00adabling \ntransactional access to concurrent data structures, say a ConcurrentSkipList, which already have built-in \nthread synchro\u00adnization[11].The methodology isbased onpessimism, and allows us to use such off-the-self \nconcurrent objectsin a transactional set\u00adtingwithoutthepitfallsthat would come with.ne-grained synchro\u00adnization. \nThe methodology also makes one particular choice about how coarse-grained synchronization is accomplished: \nabstract locks. The user de.nes an abstract locking discipline such that, for any two transactions executing \nconcurrent method calls, thelocks con\u00ad.ictif the method callsdo not commute. Hereis an example: global \nSkipList Set; global AbsLock keys[10]; T1: atomic { with(lock(keys[5])) { Set.add(5); with(lock(keys[3])) \n{ Set.remove(3); }}} T2: atomic { with(lock(keys[6])) { if (Set.contains(6)) { with(lock(keys[7])) { \nSet.remove(7); }}}} The above exampleinvolves a SkipList implementation ofa Setof integers. Set has the \nstandard operations add(x), remove(y), and contains(z). add(x) commutes with add(y) ifx and yaredistinct. \nAn examplelockingdiscipline(as above) istode.ne one abstract lock per key(i.e. x,y,z). Thus, the abstract \nlocks foradd(x) and add(y) do notcon.ict when x and y aredistinct, so these calls can proceedinparallel. \nWith our semantics in place, we can formalize the examples wedescribed earlier[11].Moreover, we canbe \nmoreprecise and consider . and . in addition to .. (commutativity): Multi-set The moverness of a multi-set \nis similar to the commutativity of the Set given in Figure 1 of our previous work [11]. However, a multi-set \nhas the following additional movers: contains(x)/true. insert(x)/true remove(x)/true. insert(x)/true \nPriorityQueue(Heap) We gave the commutativity of a pri\u00adorityqueueinFigure4 of ourprevious work[11].Themethod \ninsert(x) inserts an element into the heap and the method removeMin()/y returns the minimal element.Figure4 \nof [11] canbe re.ned: insert(x). removeMin()/x Infact we noticed a mistake.Figure4 of [11] claims that \ninsert(x).. removeMin()/y .y = x butwhen x = y, only . holds. Queue Similar to the multi-set, a queue \nhas an operation whichis aleft-moverbut not a right-mover: enqueue(x). dequeue() Semaphore The standard \nsemaphoreis represented as aninte\u00adger whose valueisinitially0with methods incr(increments the value) \nand decr (decrements the value). Applying decr when the valueis0is either unde.ned orblocks.Therefore, \nincr . decr.  7.2 OptimisticCoarse-Grained(BaldassinandBurckhardt) Recently,BaldassinandBurckhardtproposed \nanewprogramming model which resembles coarse-grainedtransactions[3].Intheir ex\u00adperience adaptingagame \napplication to transactions, theydescribe atechniquebased on user-provided speci.cations(i.e.moverness) \nto resolve con.icts. We nowdiscuss theirimplementation, usingparenthetical com\u00adments to refer back to \nthe corresponding rule in our optimistic execution semantics in Section 3.2. Baldassin and Burckhardt \nde\u00adscribe transactions which begin(OBEG) with a replica(st)of the shared state(ssh).Transactions then \nexecuteperformingoperations (OAPP) on their local copies, and when they commit their local updatesare \npropagated toall otherreplicas (logicallyequivalent to merge(ssh,lt) in OCMT) and when transactional \noperations are read-only, a single shared stateis used(direct equivalence to merge(ssh,lt)). We nowgive \naformaltreatmentforthe objectsdescribed[3]. In the following, the .rst two are base objects where any \nwrite is treated as a con.ict(i.e. non-moverness) while concurrent reads are acceptable(i.e.both-moverness).The \nremaining three usehigher\u00adorder moverness. Values (base) get .. get set \u00b7 get set \u00b7 set Collections (base) \nGetRO .. GetRO GetRW\u00b7GetRO GetRW\u00b7GetRW SharedGrowingList (wrapper) This object appears to be a multiset \nwhere the order of elementinsertiondoes not matter: insert(x)..insert(y) for all x,y.  SharedObjectWithPriority(wrapper) \nThisobject allowstrans\u00adactions to associate a priority with the operations performed on an object and \nat commit, con.icts are resolved according to priority. Note that this violates serializability, and \nmay rely on application-speci.cinvariants orbehaviorsfor soundness.  SharedObjectWithMerge (wrapper) \nThis general wrapper al\u00adlows a user to de.ne a commit-time merge procedure which computes new valuesinthe \nshared store(ssh)given the values desiredby committing transactions(st,st' , etc.).This can be thought \nof as a speci.cform of applying the operationallog lt to the shared statein merge(ssh,lt). Since this \nmerge procedure is provided, the assumption is that alltransactional operations onthese objects areboth-movers \nor, in case ofcon.icts, operations canbeinverted without aborting the transaction.  Inthegame application \nconcurrent transactions are alignedon a per-framebasis, allbeginningand committing(roughly) simultane\u00adously.They \nmust assumethat anybegin order waspossible andthus all operationsmustberight moverswith respecttoeach \nother i.e. every operation mustbe aboth-mover.By addingbegintimestamps this requirement could be relaxed, \nand operations need only move to the right of committed operations.In a moregeneral setting(not aligned \ntoframes) right moverness maybe useful.  8. RelatedWork Our work is the .rst formal treatment of coarse-grained \ntrans\u00adactions, which captures the trend in the recent literature away from low-level memory synchronization \ntowards more ef.cient, higher-level synchronization. Our semantics, encompassing both pessimistic and \noptimistic execution models, uni.es a wide range of ad-hoc techniques: traditional transactional memory \n[7, 28], transactional boosting [11], and recent optimistic techniques [3]. Moreover, our work provides \na formal basis for an emerging new wave of research [2,27] which uses automated techniquestodis\u00adcover \nmoverness. TransactionalBoosting Inpriorwork[11]weprovedthecorrect\u00adness ofTransactionalBoosting usinghistories \nof events[14,32]. Boostingispessimistic andtheproofinthispaper ofthepessimistic execution semantics roughly \ncorresponds tothepreviousproof[11] when labels are aligned with events. Nonetheless, our treatment herehas \nnovelties: 1. Wede.ne a coarse-grainedlanguage ofprograms(ratherthan a library-style methodology) and \nprovide a formal proof of serializabilityfor thislanguage. 2. We have added support for non-determinism, \nshowing equiva\u00adlence by containment of an execution in a set of serial execu\u00adtions,ratherthanby.nding \nasingleserial execution. 3. We have added a second, optimistic semantics (boosting is purely pessimistic) \nwhich models modern read/write STMs such asTL2[7] andIntel sSTMcompiler[28], as wellas recent attempts \natlargergranularity[3] asdescribedinSection7.2.  PreviousSemantics ofSTM In a similar vein,the workbyJagan\u00adnathan \net al. gives a semantics for both pessimistic and optimistic read/writetransactional memory[15].Our work \ncanbe seen as a generalization in which the operations are over abstract data-types rather than simple \nmemory operations. Other previous works on semantics of transactions are orthog\u00adonal and have focused \ninstead on isolation of transactions (i.e. theprivatizationproblem[30]).Thesesemanticsarepurely .ne\u00adgrained,and \ntackletheissueof ensuring shared memory isnot ac\u00adcessed outside of a transaction. By contrast, in our \nsemantics the shared/localdistinctionis assumed and wefocus onthe correctness criteriafor coarsergranularities. \nFor example, the ATOMSFAMILY presented by Moore and Grossman[23]involves ataxonomyof semantics which \nvarybased on degrees of isolation, availability of abort, and allowed parallel nesting. Another example \nis the semantics of Automatic Mutual Exclusion (AME) given by Abadi et al. [1]. The programming model \nof AME is substantially different from ours; its execution model involves spawning asynchronous method \ncalls which are scheduled such that only non-con.icting code runs concurrently. This programming model \ncan be used to model .ne-grained opti\u00admisticimplementations,with eager updates.Wenextdiscussthe distinctionbetween \neager andlazy. Another important distinction is the choice of which form of optimism to model: eager \nor lazy updates to memory. The eager version mayperformbetterbutis subject to transactions observing \ninconsistent states(i.e. not opaque[9] asdiscussedinSection6.1), which appears to have signi.cant drawbacks. \nAME discusses dis\u00adtinction and why they choseto modellazy updates.The ATOMS\u00adFAMILYexploresbothlazy(StrongBasic)and \neager(Weak),using a type system to ensure serializabilityin thelatter case. In our work, lazy updates \nare fundamentally part of the model (in- .O the shared store is only updated in the OCMT rule). Our model \nmatches that ofTL2[7] andIntel s transactional memory compiler[28]. Commutativity The notion of commutativity, \nmore precisely moverness[22],isfundamental indatabases andparallelprogram\u00adming.TheliteratureincludesBernstein[5],Steele[31],Weihl[32], \nSchwartz and Spector [29], Beeri [4], and Korth [16]. More re\u00adcently,theJadeprogramminglanguage[21,26]hasbeendeveloped \nwhichincludes supportforprogrammer-provided speci.cationsas to whether certainfunctions are commutative. \nIn the very recent literature there have been some techniques which attempttodetect commutativity.This \nworkisinspiredbyRi\u00adnard andDiniz[27] whose commutativity analysis checkedfor con\u00adcrete equivalence mostly \nviaheapdisjointness, andleveraged some limited arithmetic identities. Recently, Aleen and Clark presented \na commutativity analysis[2].Their workis a whole-program anal\u00adysis for checking whether context-sensitive \nprocedure invocations commute. To check equivalence of re-orderings they use random interpretation.Their \nwork is orthogonal to ours, and couldbe used to detect or prove moverness of certain objects. Some effort \nmay be needed since(1) their workisforparallelizing compilers, not transactions and(2) precision couldbeimprovedby \nconsidering left-and right-moverness rather than simplyboth-moverness. 9. Conclusion In the recent literature \nthere has been a new trend of broadening transactional operations from .ne-grained memory operations \nto more coarse-grained operations, often drastically improving per\u00adformance. We have presented a semantics \nwhich uni.es a broad range of such ad-hoc techniques, encompassing both pessimistic (e.g.transactionalboosting) \nand optimistic(e.g.traditionalSTM and recent coarse-grained work[3]) execution semantics.Wehave proven \nserializabilityandfoundthatthe choice ofexecution seman\u00adticsimposesdifferent requirements, expressedin \nterms ofleft-and right-movers, on the coarse-grained operations themselves. Our work serves also as aformalfoundationfor \nrecent automated tech\u00adniquesfordiscovering moverness[2,27].Weexpectthatthis will be apromising researchdirectionfor \nthefuture. Acknowledgments We thank Byron Cook, Tim Harris, Michael Hicks and Peter Sewell for their \ncomments on an earlier draft. We acknowledgefundingfrom aGates scholarship(Koskinen), a RoyalAcademy \nofEngineeringResearchFellowship(Parkinson), andNSFgrant0811289(Herlihy).  References [1] ABADI,M.,BIRRELL,A.,HARRIS,T., \nAND ISARD,M. Semantics of transactional memory and automatic mutual exclusion. In The35th ACM SIGPLAN \nSIGACT Symposium on Principles of Programming Languages (POPL 08) (2008), G. C. Necula and P. Wadler, \nEds., ACM,pp.63 74. [2] ALEEN, F., AND CLARK, N. Commutativity analysis for software parallelization: \nletting program transformations see the big picture. In Proceedings of the 14th international conference \non Architectural supportforprogramminglanguages and operating systems(ASPLOS-XII) (2009),M.L.Soffa andM.J.Irwin,Eds.,ACM,pp.241 \n252. [3] BALDASSIN,A., AND BURCKHARDT,S.Lightweight softwaretrans\u00adactions for games. In Proceedings of \nthe First USENIX Workshop on HotTopicsin Parallelism(HotPar 09) (2009). [4] BEERI, C., BERNSTEIN, P., \nGOODMAN, N., LAI, M.-Y., AND SHASHA, D. A concurrency control theory for nested transactions (preliminary \nreport). In Proceedings of the 2nd annual ACM sympo\u00adsium onPrinciples ofdistributed computing(PODC 83) \n(New York, NY,USA,1983),ACMPress,pp.45 62. [5] BERNSTEIN,A. Analysisofprogramsforparallelprocessing. \nIEEE Transactions onElectronicComputers15,5(1966),757 763. [6] DAMRON, P., FEDOROVA, A., LEV, Y., LUCHANGCO, \nV., MOIR, M., AND NUSSBAUM,D.Hybrid transactional memory.In Proceed\u00adings of the 12th international conference \non Architectural support for programminglanguages and operating systems(ASPLOS-XII) (New York,NY,USA,2006),ACMPress,pp.336 \n346.  [7] DICE, D., SHALEV, O., AND SHAVIT, N. Transactional locking II. In Proceedings of the 20th \nInternational Symposium on Distributed Computing(DISC 06) (September 2006). [8] FLANAGAN, C., FREUND, \nS. N., AND YI, J. Velodrome: a sound and completedynamicatomicity checkerformultithreadedprograms. In \nPLDI 08: Proceedings of the 2008 ACM SIGPLAN conference on Programming language design and implementation \n(New York, NY, USA,2008),ACM,pp.293 303. [9] GUERRAOUI,R., AND KAPALKA,M.Onthecorrectnessof transac\u00adtional \nmemory.In Proceedings ofthe13thACMSIGPLANSymposium onPrinciples andpractice ofparallelprogramming(PPoPP \n08) (New York,NY,USA,2008),ACM,pp.175 184. [10] HARRIS, T., MARLOW, S., JONES, S. L. P., AND HERLIHY, \nM. Composable memory transactions. Commun. ACM 51, 8(2008), 91 100. [11] HERLIHY, M., AND KOSKINEN, E. \nTransactional boosting: A methodology forhighly concurrenttransactional objects. In Proceed\u00adings ofthe13thACMSIGPLANsymposium \nonPrinciples andpractice ofparallelprogramming(PPoPP 08) (2008). [12] HERLIHY, M., LUCHANGCO, V., MOIR, \nM., AND SCHERER, III, W. N. Software transactional memory for dynamic-sized data struc\u00adtures. In Proceedings \nof the 22nd annual symposium on Principles of distributed computing(PODC 03) (2003),ACMPress,pp.92 101. \n[13] HERLIHY,M., AND MOSS,J.E.B.Transactional memory: architec\u00adtural support for lock-free data structures. \nIn Proceedings of the 20th AnnualInternationalSymposium onComputerArchitecture(ISCA 93) (1993),ACMPress,pp.289 \n300. [14] HERLIHY, M. P., AND WING, J. M. Linearizability: a correctness condition for concurrent objects. \nACMTransactions onProgramming Languages andSystems(TOPLAS)12,3(1990),463 492. [15] JAGANNATHAN, S. VITEK, \nJ., WELC, A., HOSKING, A. A Trans\u00adactional object calculus. Science of Computer Programming. 57, 2 (August2005),164 \n186. [16] KORTH,H.F.Lockingprimitivesinadatabasesystem. J.ACM30,1 (1983),55 79. [17] KOSKINEN, E., AND \nHERLIHY, M. Checkpoints and continuations instead of nested transactions. In Proceedings of the twentieth \nannual symposium onParallelismin algorithms and architectures(SPAA 08) (NewYork,NY,USA,2008),ACM,pp.160 \n168. [18] KOSKINEN, E., AND HERLIHY, M. Dreadlocks: ef.cient deadlock detection. In Proceedings of the \ntwentieth annual symposium on Parallelism in algorithms and architectures (SPAA 08) (New York, NY,USA,2008),ACM,pp.297 \n303. [19] KOSKINEN,E.,PARKINSON,M., AND HERLIHY,M.Coarse-grained transactions. Tech. Rep. 759, Computer \nLaboratory, University of Cambridge,2009. [20] KULKARNI, M., PINGALI, K., WALTER, B., RAMANARAYANAN, \nG., BALA, K., AND CHEW, L. P. Optimistic parallelism requires abstractions. In Proceedings of the ACM \nSIGPLAN 2007 Conference on Programming Language Design and Implementation (PLDI 07) (2007),J.Ferrante \nandK.S.McKinley,Eds.,ACM,pp.211 222. [21] LAM, M., AND RINARD, M. Coarse-grain parallel programming \nin Jade. In Proceedings of the third ACM SIGPLAN symposium on Principles andpractice ofparallelprogramming(PPoPP \n91) (1991), ACMNewYork,NY,USA,pp.94 105. [22] LIPTON,R.J. Reduction:amethod ofprovingpropertiesofparallel \nprograms. Commun.ACM18,12(1975),717 721. [23] MOORE, K. F., AND GROSSMAN, D. High-level small-step opera\u00adtional \nsemantics for transactions. In Proceedings of the 35th annual ACM SIGPLAN-SIGACT symposium on Principles \nof programming languages(POPL 08)(NewYork,NY,USA,2008),ACM,pp.51 62. [24] MORAVAN, M. J., BOBBA, J., \nMOORE, K. E., YEN, L., HILL, M. D., LIBLIT, B., SWIFT, M. M., AND WOOD, D. A. Supporting nested transactional \nmemoryinlogtm. In Proceedings of the 12th in\u00adternational conferenceonArchitectural supportforprogramminglan\u00adguages \nand operating systems(ASPLOS-XII) (New York, NY, USA, 2006),ACMPress,pp.359 370. [25] MORAVAN, M. J., \nBOBBA, J., MOORE, K. E., YEN, L., HILL, M. D., LIBLIT, B., SWIFT, M. M., AND WOOD, D. A. Supporting nested \ntransactional memoryinlogtm. SIGOPSOper.Syst. Rev.40,5 (2006),359 370. [26] RINARD,M., AND LAM,M. Thedesign,implementation,and \neval\u00aduation of Jade. ACM Transactions on Programming Languages and Systems(TOPLAS)20,3(1998),483 545. \n[27] RINARD, M. C., AND DINIZ, P. C. Commutativity analysis: A new analysistechniqueforparallelizing \ncompilers. ACM Transactions on Programming Languages and Systems (TOPLAS) 19, 6 (November 1997),942 991. \n[28] SAHA,B.,ADL-TABATABAI,A.-R.,HUDSON,R.L.,MINH,C.C., AND HERTZBERG, B. McRT-STM: a high performance \nsoftware transactional memory systemfor a multi-core runtime. In Proceedings of theeleventhACMSIGPLAN \nsymposiumonPrinciples andpractice of parallel programming (PPoPP 06) (New York, NY, USA, 2006), ACM,pp.187 \n197. [29] SCHWARZ, P. M., AND SPECTOR, A. Z. Synchronizing shared abstract types. ACM Transactions on \nComputer Systems 2, 3(1984), 223 250. [30] SPEAR, M. F., MARATHE, V. J., DALESSANDRO, L., AND SCOTT, \nM. L. Privatization techniques for software transactional memory. In Proceedingsofthetwenty-sixth annualACM \nsymposiumonPrinciples of distributed computing (PODC 07) (New York, NY, USA, 2007), ACM,pp.338 339. \n[31] STEELE, JR, G. L. Making asynchronous parallelism safe for the world. In Proceedings of the 17th \nACM SIGPLAN-SIGACT sympo\u00adsium onPrinciples ofprogramminglanguages(POPL 90) (NewYork, NY,USA,1990),ACMPress,pp.218 \n231. [32] WEIHL,W.E.Data-dependent concurrency control and recovery(ex\u00adtended abstract). In Proceedings \nof the second annual ACM sympo\u00adsium onPrinciples ofdistributed computing(PODC 83) (New York, NY,USA,1983),ACMPress,pp.63 \n75. [33] WILLIAM N.SCHERER,I., AND SCOTT,M.L.Advanced contention managementfordynamic software transactional \nmemory. In Proceed\u00adings of the 24th annual ACM symposium on Principles of distributed computing(PODC \n05) (New York,NY,USA,2005),ACM,pp.240 248.  \n\t\t\t", "proc_id": "1706299", "abstract": "<p>Traditional transactional memory systems suffer from overly conservative conflict detection, yielding so-called false conflicts, because they are based on fine-grained, low-level read/write conflicts. In response, the recent trend has been toward integrating various abstract data-type libraries using ad-hoc methods of high-level conflict detection. These proposals have led to improved performance but a lack of a unified theory has led to confusion in the literature.</p> <p>We clarify these recent proposals by defining a generalization of transactional memory in which a transaction consists of coarse-grained (abstract data-type) operations rather than simple memory read/write operations. We provide semantics for both pessimistic (e.g. transactional boosting) and optimistic (e.g. traditional TMs and recent alternatives) execution. We show that both are included in the standard atomic semantics, yet find that the choice imposes different requirements on the coarse-grained operations: pessimistic requires operations be left-movers, optimistic requires right-movers. Finally, we discuss how the semantics applies to numerous TM implementation details discussed widely in the literature.</p>", "authors": [{"name": "Eric Koskinen", "author_profile_id": "81350575010", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1911028", "email_address": "", "orcid_id": ""}, {"name": "Matthew Parkinson", "author_profile_id": "81406598777", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1911029", "email_address": "", "orcid_id": ""}, {"name": "Maurice Herlihy", "author_profile_id": "81100151794", "affiliation": "Brown University, Providence, RI, USA", "person_id": "P1911030", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706304", "year": "2010", "article_id": "1706304", "conference": "POPL", "title": "Coarse-grained transactions", "url": "http://dl.acm.org/citation.cfm?id=1706304"}