{"article_publication_date": "01-17-2010", "fulltext": "\n Type Inference for Datalog with Complex Type Hierarchies Max Sch\u00a8Oege de Moor afer Semmle Ltd., Oxford, \nUnited Kingdom {max,oege}@semmle.com Abstract Type inference for Datalog can be understood as the problem \nof mapping programs to a sublanguage for which containment is de\u00adcidable. To wit, given a program in \nDatalog, a schema describing the types of extensional relations, and a user-supplied set of facts about \nthe basic types (stating conditions such as disjointness, im\u00adplication or equivalence), we aim to infer \nan over-approximation of the semantics of the program, which should be expressible in a suitable sublanguage \nof Datalog. We argue that Datalog with monadic extensionals is an appro\u00adpriate choice for that sublanguage \nof types, and we present an infer\u00adence algorithm. The inference algorithm is proved sound, and we also \nshow that it infers the tightest possible over-approximation for a large class of Datalog programs. Furthermore, \nwe present a prac\u00adtical containment check for a large subset of our type language. The crux of that containment \ncheck is a novel generalisation of Quine s procedure for computing prime implicants. The type system \nhas been implemented in a state-of-the-art industrial database system, and we report on experiments with \nthis implementation. Categories and Subject Descriptors H.2.3 [Database Manage\u00adment]: Languages General \nTerms Algorithms, Languages, Theory Keywords Type Inference, Datalog, Type System 1. Introduction We \naim to infer precise types for queries where the entities in the database satisfy complex conditions \nregarding subtyping, disjoint\u00adness and so on. To illustrate, consider the Datalog program in Figure 1, \nwhich is a slight adaptation of an example in [1]. It assumes a database that contains monadic extensional \nrelations for employee, senior, junior, parttime, student and manager. These monadic relations capture \nthe entities that are manipulated by queries, and they are the building blocks of types. There is furthermore \nan extensional relation salary(x, z). In the program, additional intensional relations are de.ned: bonus(x, \ny) computes the bonus y that an employee x will get. Non-students x get a bonus y that is computed by \nmultiplying x s salary z by a factor f , which is returned by factor(x, f ). The factor depends on the \nseniority of the employee. For students, the bonus is Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 10, January 17 23, 2010, Madrid, Spain. Copyright c &#38;#169; \n2010 ACM 978-1-60558-479-9/10/01. . . $10.00 bonus(x, y) ..z, f .( salary(x, z) . factor(x, f ) . y = \nf \u00d7 z .\u00acstudent(x)) . (y = 50 . employee(x) . student(x)) factor(x, y) . (junior(x) . y =0.1) . (senior(x) \n. y =0.15) query(x, y) . bonus(x, y) . senior(x) . manager(x) Figure 1. Example Datalog program employee(x) \n. junior(x) . senior(x) \u00ac(junior(x) . senior(x)) parttime(x) . employee(x) student(x) . employee(x) . \nparttime(x) manager(x) . employee(x) manager(x) .\u00acparttime(x) Figure 2. Example type hierarchy always \n50, independent of their salary. Finally, the program de.nes a query, which is to .nd the bonus of all \nsenior managers. The entity types are expected to satisfy many interesting facts that are useful in reasoning \nabout types, for instance those shown in Figure 2. We call such a set of facts the type hierarchy. Note \nthat the type hierarchy goes well beyond the usual notion of subtyping in traditional programming languages, \nin that one can state other relationships besides mere implication or equivalence. An example of such \nan interesting fact is the last statement, which says that managers cannot be part-time employees. The \nprogrammer will have to state these facts as part of the database de.nition, so that they can be checked \nwhen information is entered, and to enable their use in type inference and optimisation. To do type inference, \nwe of course also need to know some facts about extensional relations. For instance, salary(x, z) . employee(x) \n. .oat(z) states that the .rst column of the extensional relation salary will contain values of type \nemployee, and the second one will contain .oating point numbers. A schema provides this column-wise typing \ninformation for every extensional relation. Given the schema and the hierarchy, type inference should \ninfer the following implications from the de.nitions in the program: bonus(x, y) . employee(x) . .oat(y) \nfactor(x, y) . employee(x) . .oat(y) query(x, y) . senior(x) . manager(x) . .oat(y)  Note how these \ndepend on facts stated in the type hierarchy: for example, in inferring the type of factor, we need to \nknow that employee is the union of junior and senior. Type inference will catch errors: when a term is \ninferred to have the type ., we know that it denotes the empty relation, independent of the contents \nof the database. Also, the programmer may wish to declare types for intensional relations in her program, \nand then it needs to be checked that the inferred type implies the declared type. The bene.ts of having \nsuch type inference for queries is not con.ned to merely checking for errors. Precise types are also \nuse\u00adful in query optimisation. In particular, the above query can be op\u00adtimised to: query(x, y) . manager(x) \n. senior(x). salary(x, z) . y =0.15 \u00d7 z This rewriting relies on the fact that we are asking for a manager, \nand therefore the disjunct in the de.nition of bonus that talks about students does not apply: a student \nis a parttime employee, and man\u00adagers cannot be parttime. Again notice how the complex type hi\u00aderarchy \nis crucial in making that deduction. The elimination of disjuncts based on the types in the calling context \nis named type specialisation; type specialisation is very similar to virtual method resolution in optimising \ncompilers for object-oriented languages. Similarly, the junior alternative in the de.nition of factor \ncan be eliminated. Once type specialisation has been applied, we can elim\u00adinate a couple of super.uous \ntype tests: for instance, \u00acstudent(x) is implied by manager(x). That is called type erasure. The key \nto both type specialisation and type erasure is an ef.cient and com\u00adplete test for type containment, \nwhich takes all the complex facts about types into account. Overview The general problem we address is \nas follows. Given the class of all Datalog programs P, we identify a sublanguage T of type programs. \nType inference assigns an upper bound Ipl in the language of type programs to each program p. To say \nthat Ipl is an upper bound is just to say that p (plus the schema and the type hierarchy) implies Ipl. \nThe idea of such upper envelopes is due to Chaudhuri [8, 9]. In Section 2 we propose a de.nition of the \nclass of type pro\u00adgrams: any program where all extensionals called are monadic. Type programs can, on \nthe other hand, contain (possibly recursive) de.nitions of intensional predicates of arbitrary arity. \nWe then de\u00ad.ne a type inference procedure Ipl, and prove that its de.nition is sound in the sense that \nIpl is truly an upper bound of p. Further\u00admore, it is shown that for negation-free programs p, the inferred \ntype Ipl is also optimal: Ipl is the smallest type program that is an upper bound of p. For negation-free \nprograms, the de.nition of Ipl is in terms of the semantics of p, so that the syntactic presentation \nof a query does not affect the inferred type. It follows that the application of logical equivalences \nby the programmer or by the query optimiser does not affect the result of type inference. The restriction \nthat programs be negation-free can be relaxed to allow negation to occur in front of sub-programs that \nalready have the shape of a type program. Not much more can be hoped for, since sound and optimal type \ninference for programs with arbitrary negations is not decidable. To also do type checking and apply \ntype optimisations, we need an effective way of representing and manipulating type programs. To this \nend, we identify a normal form for a large and natural class of type programs in Section 3. The class \nconsists of those type programs where the only negations are on monadic extensionals (i.e. entity types). \nThere is a simple syntactic containment check on this representation, inspired by our earlier work reported \nin [13]. That simple containment check is sound but not complete. A ge\u00adometric analysis of the incompleteness \nin Section 4 suggests a gen\u00aderalisation of the celebrated procedure of Quine [22] for computing prime \nimplicants. We present that generalised procedure, and show that the combination of the simple containment \ncheck plus the com\u00adputation of prime implicants yields a complete algorithm for testing containment of \ntype programs. The algorithm we present is very different from the well-known approach of propositionalisation, \nwhich could also be used to de\u00adcide containment. The merit of our novel algorithm is that it allows an \nimplementation that is ef.cient in common cases. We discuss that implementation in Section 5. We furthermore \npresent experi\u00adments with an industrial database system that con.rm our claims of ef.ciency on many useful \nqueries. Finally, we discuss related work in Section 6, and conclude in Section 7. In summary, the original \ncontributions of this paper include: The identi.cation of a language of type programs for Datalog, suitable \nboth for precise error checking and for type-based optimisations.  The de.nition of a very simple type \ninference procedure that is proved sound and optimal.  A containment check for type programs that relies \non a novel generalisation of Quine s method of computing prime impli\u00adcants.  Experiments in an industrial \ndatabase system that show that this containment algorithm is ef.cient and useful.  2. Type Programs \nIt is customary to write Datalog programs as a sequence of rules as seen in Fig. 1, but this syntax is \ntoo imprecise for our purposes. In the remainder of the paper, all Datalog programs will be written as \nformulae of Strati.ed Least Fixpoint Logic (SLFP) over signatures without function symbols. This logic, \npresented for example in [10], extends .rst order logic (including equality) with .xpoint de.nitions \nof the form [r(x1,..., xn) = .].. Here, r is an n-ary relation symbol, the xi are pairwise different \nelement variables, and . and . are formulae. Intuitively, the formula de.nes r by the formula ., which \nmay contain recursive occurrences of r, and the de.ned relation can then be used in .. The xi are considered \nbound in . and free in ., whereas the relation r is free in . and bound in .. To ensure strati.cation, \nfree relation symbols are not allowed to occur under a negation, which avoids the problematic case of \nrecursion through negation. For example, the formula . [s(x, y) = x = y ..z.e(x, z) . s(z, y)]s(x, y) \n(1) de.nes the relation s to be the re.exive transitive closure of e. By way of illustration (and only \nin this example), free occurrences of element variables and relation variables have been marked up in \nbold face. The formula is trivially strati.ed since no negations occur anywhere. In this program, the \nrelation symbol s is an intensional predicate since it is given a de.ning equation. On the other hand, \nrelation e is an extensional, which we assume to be de.ned as part of a database on which the program \nis run. We will denote the set of intensional relation symbols as Iand that of extensional relation symbols \nas E, and require them to be disjoint. Model-theoretically, the role of the database is played by an \ninterpretation I which assigns, to every n-ary relation symbol e . E, a set of n-tuples of some non-empty \ndomain. To handle free variables we further need an assignment s that maps free element variables to \ndomain elements and free relation variables to sets of tuples. Just as in .rst order logic, we can then \nde.ne a modelling judge\u00adment I|= s . stating that formula . is satis.ed under interpreta\u00adtion I and assignment \ns. In particular, strati.cation ensures that formulae can be interpreted as continuous maps of their \nfree rela\u00adtion variables, so that .xpoint de.nitions can be semantically inter\u00adpreted by the least .xpoints \nof their de.ning equations. For a formula . with a single free element variable x, we set [.]I := {c \n|I|= x:=c .}, omitting the subscript I where unambiguous. Just as the semantics of the intensional predicates \nis determined with respect to the semantics of the extensional predicates, the types of the intensional \npredicates are derived with respect to the types of the extensional predicates. These are provided by \na schema S which assigns, to every n-ary extensional predicate, an n-tuple of types. As is customary, \ntypes are themselves monadic predicates from a set T . Eof type symbols. For consistency, we require \nthat the schema assigns a type symbol to itself as its type. For the program in (1), for example, we \nmight have two type symbols a and b, with the schema specifying that S (e)=(a, b) and of course S (a)=(a), \nS (b)=(b). Semantically, we understand this to mean that in every interpre\u00adtation of the extensional \nsymbols conforming to the schema, the extension of a given column of an extensional symbol should be \nexactly the same as the extension of the type symbol assigned to it by the schema. We can de.ne a .rst \norder formula, likewise denoted as S , which expresses this constraint: For every n-ary relation symbol \ne . E\\ Tand every 1 = i = n where u . Tis the type assigned to the i-th column of e, the formula S contains \na conjunct .xi.(.x1,..., xi-1, xi+1,..., xn.e(x1,..., xn)) . u(xi) (2) Our example schema above, for \ninstance, would be expressed by the formula (.x.(.y.e(x, y)) . a(x)) . (.y.(.x.e(x, y)) . b(y)) In the \nliterature, the types assigned by the schema are often not required to .t exactly, but merely to provide \nan over-approximation of the semantics. We could achieve this by relaxing (2) to use an implication instead \nof a bi-implication. Instead, we take a more general approach by allowing arbitrary additional information \nabout the types to be expressed through a hierarchy formula H . Our only requirements about this formula \nare that it be a closed .rst order formula containing only type symbols (and no other relation symbols). \nIn particular, the hierarchy may stipulate subtyping relations; in our example, the hierarchy could be \n.x.a(x) . b(x), expressing that a is a subtype of b. Perhaps more interestingly, it can also express \ndisjointness of types, e.g. by stating that .x.\u00aca(x) .\u00acb(x); we could then deduce that in the de.nition \nof the re.exive transitive closure e can, in fact, be iterated at most once. Many other kinds of constraints \nare just as easily expressed, and provide opportunities for advanced optimisations. We now approximate \nprograms by type programs, which are programs that only make use of type symbols (and no other ex\u00adtensional \nrelation symbols), and do not contain negation1. To ev\u00adery SLFP formula . we assign a type program I.l \nby replacing negated subformulae with T and approximating every use of an extensional relation symbol \nby the conjunction of its column types. The complete de.nition is given in Fig. 3. For our example program, \nwe would obtain the type . [s(x, y) = x = y ..z.a(x) . b(z) . s(z, y)]s(x, y) 1 Compare this with the \nhierarchy which can contain negations, but no .xpoint de.nitions. I.l = . .. It1 = t2l = t1 = t2 Ie(t1,..., \ntn)l = u1(t1) . ... . un(tn) for e . Ewith S (e)=(u1,..., un) Ir(t1,..., tn)l = r(t1,..., tn) for r . \nI I\u00ac.l = T I. . .l = I.l.I.l I. . .l = I.l.I.l I.x..l = .x.I.l I[r(1x) = .].l =[r(1x) =I.l]I.l Figure \n3. Rules for type inference which is semantically equivalent to . x = y . a(x) . b(y) We will see in \nthe next section that, in fact, .xpoint de.nitions can always be eliminated from such type programs, \nyielding for\u00admulae of monadic .rst order logic. As the example suggests, the types assigned to programs \nseman\u00adtically over-approximate them in the following sense: Theorem 1 (Soundness). For every program \n. we have S , H ,. |= I.l That is, every interpretation and assignment satisfying the schema, the hierarchy \nand . also satis.es I.l. Proof Sketch. We can show by induction on . the following stronger version of \nthe theorem: For any interpretation I with I|= S and any two assignments s and s', which assign the same \nvalues to element variables, and where s(r) . s'(r) for every r . I, we have I|= s' I.l whenever I|=s \n.. From this, of course, it follows that S ,. |= I.l, and again S , H ,. |= I.l by monotonicity of entailment. \nPerhaps more surprisingly, our type assignment also yields the tightest such over-approximation, in spite \nof our very lax restric\u00adtions on the hierarchy: Theorem 2 (Optimality). For a negation-free program . \nand a type program ., if we have S , H ,. |= . then also S , H , I.l|= . To prove this theorem, we \nneed a monotonicity result for the type assignment. Lemma 3. For two negation-free programs . and ., \nif it is the case that S , H ,. |= . then also S , H , I.l|= I.l. An easy way to prove this result is \nto make use of carte\u00adsianisation, which is the semantic equivalent of the typing oper\u00adator I\u00b7l. For a \nrelation R . Dn, we de.ne its cartesianisation cart(R)= p1(R) \u00d7 ... \u00d7 pn(R) to be the cartesian product \nof the columns of R. Likewise, the cartesianisation cart(I) of an inter\u00adpretation I is the interpretation \nwhich assigns cart(I(e)) to every relation symbol e. It is then not hard to see that cart(I) |=s . .. \nI|=s I.l (3) for any negation-free formula ., interpretation I and assignment s whenever I|= S . Also, \ncart(I) |= S if I|= S , and cart(I) |= H iff I|= H . From this observation, we easily get the Proof \nof Lemma 3. Assume S , H ,. |= ., and let I, s be given with I|= S , I|= H and I|= s I.l. By (3), we \nhave cart(I) |= S , cart(I) |= H and also cart(I) |= s ., so by assumption cart(I) |= s ., but then by \napplying (3) again we get I|= s I.l. We brie.y pause to remark that Lemma 3 also shows that type in\u00adference \nfor negation-free programs respects semantic equivalence: If . and . are semantically equivalent (under \nS and H ), then so are their types. This does, of course, not hold in the presence of negation, for given \na type symbol u, we have Iu(x)l = u(x) yet I\u00ac\u00acu(x)l = T. Continuing with our development, we can now \ngive the Proof of Theorem 2. Assume S , H ,. |= .; by Lemma 3 this means S , H , I.l|= I.l. But since \n. is a type program we have I.l = ., which gives the result. So far we have handled negation rather crudely, \ntrivially approx\u00adimating it by T. In fact, we can allow negations in type programs and amend the de.nition \nof I\u00b7l for negations to read ( \u00ac. if . is a type program I\u00ac.l = T otherwise All the above results, including \nsoundness and optimality, go through with this new de.nition, and the optimality and monotonic\u00adity results \ncan be generalised to hold on all programs which contain only harmless negations, i.e. negations where \nthe negated formula is a type program. There is little hope for an optimality result on an even larger \nclass of programs: Using negation, equivalence checking of two programs can be reduced to emptiness, \nand a program is empty iff its optimal typing is .. As equivalence is undecidable [23], any type system \nthat is both sound and optimal for all programs would likewise have to be undecidable. Our proposed de.nition \nof type programs is signi.cantly more liberal than previous proposals in the literature. Fr\u00a8uhwirth et \nal. in a seminal paper on types for Datalog [16] propose the use of conjunctive queries, with no negation, \nno disjunction, no equalities and no existentials. As an example where the additional power is useful, \nconsider a database that stores the marriage register of a somewhat tradi\u00adtionally minded community. \nThis database might have types male and female, speci.ed to be disjoint by the type hierarchy, and an \nextensional relation married with schema (female, male)2. Using our above terminology, we have T = {male, \nfemale} and E = T.{married}; H is .x.\u00acmale(x) .\u00acfemale(x). Let us now de.ne an intensional predicate \nspouse: [spouse(x, y) = married(x, y) . married(y, x)]spouse(x, y) What is the type of spouse(x, y)? \nIn the proposal of [16], we could only assign it (female(x).male(x)).(female(y).male(y)), so both arguments \ncould be either male or female. By contrast, when employing our de.nition of type programs, the inferred \ntype is (female(x) . male(y)) . (male(x) . female(y)) This accurately re.ects that x and y must be of \nopposite sex. By properly accounting for equality, we can also infer that the query . spouse(x, y) . \nx = y has type . under the hierarchy: nobody can be married to themselves. 2 Note that this means that \nall male and female entities in the database are married, i.e. occur somewhere in the married relation. \n 3. Representing Type Programs For query optimisation and error checking, the single most impor\u00adtant \noperation on types is containment checking, i.e. we want to decide, for two type programs . and . ', \nwhether H . . |= . ' , which we will write . |= H . ' for short. As mentioned in the introduction, we \nare often interested in checking whether a formula is unsatis.able, that is whether it always gives an \nempty set of results regardless of the interpretation of the extensional relations. If such a formula \noccurs in a user program, it is regarded as a type error and the user is alerted to this fact; if it \noccurs during optimisation, it provides an opportunity for logical simpli.cation. By the results of the \nprevious section, a formula . containing only harmless negations is unsatis.able iff its type is equivalent \nto ., that is iff I.l|= H .. Our type programs only make use of monadic extensionals, and their containment \ncan be decided by a straightforward exten\u00adsion of the well-known decision procedure for monadic .rst \norder logic [6]. This construction, however, incurs an exponential blowup in formula size and does not \ndirectly yield a practical algorithm. Under some mild restrictions on the class of type programs and \nthe hierarchy, however, we can represent type programs in a compact manner that allows ef.cient containment \nchecking in practice. The class of type programs we deal with falls in between the two classes discussed \nin the previous section by allowing negation, but only in front of type symbols (and never before equalities). \nThe de.nition of I\u00b7l is easily changed to accommodate this by setting I\u00ac.l = \u00ac. if . is of the form u(t) \nfor u . T, and T otherwise. We call a possibly negated application of a type symbol to a variable a type \nliteral. Furthermore, we require the hierarchy H to be of the form .x.h(x), where h(x) does not contain \nquanti.ers or equations, and only a single free variable x. The basic unit of our representation are \ntype propositions, which are Boolean combinations of type symbols, all of them applied to the same variable. \nIn other words, a type proposition is a quanti.er\u00adfree type program without .xpoint de.nitions or free \nrelation vari\u00adables, having precisely one free element variable. For example, the subformula h(x) of \nH is a type proposition. A type proposition . behaves essentially the same as the propo\u00adsitional formula \n|.| that results from it by replacing every atom u(x) with the propositional letter u; for example, it \nis easily seen that .x.. is (.rst order) valid iff |.| is (propositionally) valid [20]. Hence we will \nsometimes identify the two notationally. For example, if a and b are type symbols, then a(x) .\u00acb(x) is \na type proposition with |a(x) .\u00acb(x)| = a .\u00acb. For the restricted class of type programs under consideration, \n.xpoint de.nitions can be eliminated. To see this, recall that .x\u00adpoint de.nitions can be expanded into \nin.nite disjunctions [10]. It thus suf.ces to show that the type programs without free relation variables \nand without .xpoint de.nitions (which we shall hence\u00adforth call .at) form a complete lattice, so that \neven a prima facie in.nite disjunction can in fact be represented by a single formula. Lemma 4. The .at \ntype programs form a complete lattice under the order |= H . Proof. The lattice structure is obviously \ngiven by the logical op\u00aderations of conjunction and disjunction. To show completeness, we show that the \nset of .at type programs is .nite (modulo equivalence under |= H ). Notice that every .at type program \nwith m free element vari\u00adables from X = {x1,..., xm} can be written in prenex form as ^^ _ .y1,..., yn. \n[ .i,j(xj) . .i,k(yk) . .] i 1=j=m 1=k=n  for a set Y = {y1,..., yn} of element variables, where all \nthe .i,j and .i,k are type propositions, and . is a conjunction of equations between element variables \nfrom X . Y. Existentials distribute over disjunctions, and also over conjunc\u00adtions if the variable they \nbind is only free in one of the conjuncts. . Also, note that .x.(x = y . .) is semantically equivalent \nto . with y substituted for x. Hence we can further bring the type program into the form ^ ^  each component \nti is a type proposition,  p is an equivalence relation over {1,..., n},  C is a set of type propositions \ncalled inhabitation constraints, such that  for all 1 = i, j = n with i ~p j(i.e., i and j belong to \nthe same partition of p) we have ti = tj,  C is lean,  _ ' '' [ .i,j(xj) . (.yk..i,k(yk)) . . ] \nfor all 1 = k = n we have C <: tk. i 1=j=m 1=k=n where . ' now contains only variables from X. We will \nsay that a formula of this shape is in solved form. Clearly, there are only .nitely many different formulae \nin solved form (modulo semantic equivalence), since there are only .nitely many type propositions. Notice \nthat the set of .at type programs is no longer .nite if we allow negated equalities. Indeed, for every \nnatural number n, let en be a formula asserting that there are at least n different individuals; If \np is a relation, we write p to mean the smallest equivalence relation containing it. The equivalence \nclass of an element x under p is written [x]p, where we omit the subscript p if it is clear from context. \nWe call an equivalence relation q .ner (or, more precisely, no coarser) than p if whenever x ~qy then \nalso x ~py. Whenever we have a pre-TTC t =(t1,..., tn | p | C) that does not satisfy one of the requirements, \nwe can build a TTC that does by setting dtd := (dt1dp,..., dtndp | p | min(C .{t1,..., tn})) V ij{t |~}j \n.q For a TTC t =(t1,..., tn (and every component tj where i ~pj) by r and adding r to the where dtidq \n. for example, e2 is .x1, x2.\u00acx1 = x2. Then \u00acen |= H \u00acen+1 for every n, yet all the en are semantically \ndistinct; so the lattice is not = | p | C), we de.ne ti := ti, and is the TTC resulting from t by replacing \nthe component ti even of .nite height anymore. ti:=r Corollary 5. Every type program without free relation \nvariables inhabitation constraints. is semantically equivalent to a .at type program, and hence to a \nformula of monadic .rst order logic. The formula represented by a TTC is easily recovered: De.nition \n2. Given a list of n different element variables x1,..., xn, we de.ne the type program [t](x1,..., xn) \ncorresponding to a TTC Here is an example of how a type program (with only a single disjunct) can be \nbrought into solved form. ^ 0@ 1A ^ | p | C) as t =(t1,..., tn 0@ . xi = xj 1A^ ..y.c(y) .. .z.a(x) \n. z = y . b(y) . c(x) . x = y .\u00acc(z) ! {sorting by variable}.z.a(x) . c(x) . b(y) . x = ti(xi) . .. = \ny . z = y .\u00acc(z) i~pj c.C 1=i=n ={pushing in .} .. a(x) . c(x) . b(y) . x = y ..z.z = y .\u00acc(z) . ={eliminating \n= under .} . a(x) . c(x) . b(y) . x = y .\u00acc(y) ={sorting again} . a(x) . c(x) . b(y) .\u00acc(y) . x = y \nWe will now introduce data structures that represent formulae in solved form, and develop a containment \nchecking algorithm that works directly on this representation. We de.ne an order on type propositions \nby taking .<: . to mean |= |h|.|.|.|.|, where |h| is the propositional formula corresponding to H as \nde.ned above. It is not hard to see that this holds precisely when . |= H .. In the remainder, we will \nidentify type propositions that are equivalent under <: so that it becomes a partial order. Where needed, \nwe make equivalence under <: explicit by writing it as =H . If t is a single type proposition and C a \nset of type propositions, we write t <: C (C <: t) to mean that t <: c (c <: t) for some c . C. The order \n<: can be extended to sets of type propositions by de.ning C <: D to mean that for any d . D there is \nsome c . C with c <: d. This order is clearly re.exive and transitive, and is A TTC is called degenerate \nif . is among its inhabitation constraints; it represents an unsatis.able formula. The equivalence relation \nis called trivial if it is in fact the identity relation id, and the set of inhabitation constraints \nis called trivial if it only constrains the component types to be inhabited. When writing a TTC, we will \noften leave out trivial partitionings or inhabitation constraints. We extend the order <: to TTCs component-wise: \n De.nition 3. For two n-ary TTCs t =(t1,..., tn | p | C) and '' ' t =(t1' ,..., tn ' | p | C' ) we de.ne \nt<: t to hold iff for every 1 = i = n we have ti <: ti ' ,  p ' is .ner than p,  C <: C' .  It is \nroutine to check that this de.nes a partial order with maxi\u00admal element TTTC =(T,..., T), with binary \nmeets de.ned by ' | C ' (t1,..., tn | p | C) 7 (t1' ,..., tn ' | p )= d(t1 . t '' | C . C ' 1,..., tn \n. tn ' | p . p )d (4) Since all type programs can be brought into solved form, we can represent them \nas sets of TTCs. De.nition 4. A lean set of non-degenerate TTCs is called a typing. The formula represented \nby a typing is anti-symmetric (and hence a partial order) on lean sets, i.e. sets C '' [T] := where \nc <: c for c, c . C implies c = c '. One way of making a _ [t ] t.T set of type propositions lean is \nto discard its non-minimal elements, which we write as min(C). The order <: is extended to typings by \nde.ning T <: T' to hold '' ' We can represent every disjunct of a formula in solved form if, for every \nt . T there is a t . Twith t<: t . using the following data structure: To convert any set of TTCs into \na typing we can eliminate all De.nition 1. An n-ary type tuple constraint, or TTC, t is a struc-non-maximal \nand degenerate TTCs from it; this operation we will ture (t1,..., tn | p | C) where denote by max.. \nThe order on typings is again a partial order with least element \u00d8 and greatest element {TTTC }. Binary \nmeets can be de.ned point\u00adwise as ' ''' T 7 T = max .({t 7 t | t . T,t . T }) (5) and joins are given \nby T . T ' = max .(T . T ' ) (6) We will now show that every type program can be translated to a typing. \nWe already have enough structure to model conjunction and disjunction; existential quanti.cation is also \nnot hard to support. De.nition 5. The i-th existential of a TTC t =(t1,..., tn | p | C), where 1 = i \n= n, is de.ned as .i(t) := (t1,..., ti-1, ti+1,..., tn | p ' | min(C .{ti})) where p' is the restriction \nof p to {1,..., i - 1, i +1,..., n}. The existential of a typing is de.ned pointwise: .i(T) := max .{.i(t \n) | t . T} To see that this models the existential quanti.er on type pro\u00adgrams, we can easily convince \nourselves of the following: Lemma 6. Let t be an n-ary TTC, I an interpretation and s a statement. Then \nI|=s [.i(t)] iff there is a domain element d such that I|=s,xi:=d [t]. An analogous statement holds for \ntypings. Although typings cannot directly represent type programs with .xpoint de.nitions or free relation \nvariables, we can translate every closed type program to a typing by eliminating de.nitions. Let us start \nwith a translation relative to an assignment to free relation symbols. De.nition 6. Let . be a type program \nwithout .xpoint de.ni\u00adtions containing the intensional relation variables r1,..., rm and the element \nvariables x1,..., xn. We translate it to a mapping (.): Typingm . Typing by recursion on the structure \nof .: (.)(1T)= \u00d8 . (xi = xj)(1T)= {(T,..., T | {{i, j}})}{TTTC (u(xj))(1T)= j:=u} (\u00acu(xj))(1T)= {TTTC \nj:=\u00acu} (ri(1x))(1T)= Ti (. . .)(1T)= (.)(1T) 7 (.)(1T) (. . .)(1T)= (.)(1T) . (.)(1T) (.xi..)(1T)= .i((.)(1T)) \nIt is easy to check that (.) is a monotonic mapping for every . with respect to the order <:, and since \nthe set of typings is .nite its least .xpoint can be computed by iteration. Thus we can translate every \ntype program . which does not have free relation variables into a typing (.) which represents it: Lemma \n7. For every type program . without free relation vari\u00adables, we have . =||= H [(.)]. Proof Sketch. In \nfact, we can show that, for any type program . with m free relation variables and every m-tuple 1T of \ntypings, we have the equivalence .([1T]) =||=[(.)(1T)], where [1T] is the m\u00adtuple of type programs we \nget from applying [\u00b7] to every component of 1T. This can be proved by structural induction on . by showing \nthat [(\u00b7)] commutes with the logical operators (using Lemma 6 for the case of existentials) and with \n.xpoint iteration. The lemma then follows for the case m =0.  (b . c, a) (a . b, a) (c . d, a) Figure \n4. Example for Incompleteness of <:  (a . b, a . b | {{1, 2}}) (a, a) (b, b) Figure 5. Further Example \nfor Incompleteness of <: 4. Containment Checking We are now going to investigate the relation between \nthe orders <: (component-wise or syntactic subtyping) and |= H (semantic subtyping). The former is convenient \nin that it can be checked component-wise and only involves propositional formulae, so it would be nice \nif we could establish that T1 <: T2 iff [T1] |= H [T2]. Unfortunately, this is not true. The ordering \n<: is easily seen to be sound in the following sense: Theorem 8. For any two typings T and T', if T <: \nT' then [T] |= H [T' ]. However, it is not complete. Consider, for example, the typings T = {(b . c, \na)} and T' = {(a . b, a), (c . d, a)}. Clearly we have [T] |= H [T' ], yet T <: T' . If we interpret \ntype symbols as intervals of real numbers, this example has an intuitive geometric interpretation, shown \nin Fig. 4. The individual TTCs then become rectangles in the two\u00addimensional plain, and it is easy to \nsee that the single TTC in T (depicted by the single rectangle in heavy outline .lled with ver\u00adtical \nlines) is contained in the union of the TTCs in T' (the two rectangles .lled with slanted lines), but \nnot in either one of them in isolation. A similar problem can arise from the presence of equality con\u00adstraints: \nConsider the typings T = {(a . b, a . b | {{1, 2}})}and T' = {(a, a), (b, b)}. The former appears in \nFig. 5 as a heavy slanted line, which is not contained in either of the two squares representing the \nTTCs in T', but only in their union. Intuitively, the problem is that <: tests containment of TTCs in \nisolation, whereas the semantic inclusion check considers contain\u00adments between sets of TTCs. The following \nlemma paves the way for a solution: Lemma 9. The mapping [\u00b7] is the lower adjoint of a Galois con\u00adnection, \ni.e. there is a mapping .\u00b7. from type programs to typings such that [T] |= H . iff T <: ... Proof. As \nwe have established, typings and type programs form complete lattices under their respective orders. \nSince [\u00b7] distributes over joins it must be the lower adjoint of a Galois connection between these lattices. \n An immediate consequence of this is that [T1] |= H [T2] implies T1 <:[T2] . To check, then, whether \nT1 is semantically contained in T2, we compute [T2] and check for component-wise inclusion. One possible \nimplementation of \u00b7 comes directly from the de.nition of the Galois connection: For any type program \n., . is the greatest typing T such that [T] |= H ., and since there are only .nitely many typings and \ncontainment is decidable we could perform an exhaustive search to .nd this T. Clearly, this algorithm \nis not ideal, since one of our goals is to avoid having to explicitly decide the relation |= H . Inspiration \nfor a better solution comes from a perhaps somewhat unexpected direction, namely the theory of Boolean \nfunction minimisation: Quine [22] introduces an algorithm whose .rst part determines the set of prime \nimplicants of a Boolean formula, which are conjunc\u00adtive formulae such that every conjunctive formula \nthat implies the original formula implies one of the prime implicants. Generalising from conjunctions \nto TTCs and from propositional formulae to typings, we will introduce a saturation mapping sat that generates \nthe set of all prime implicant TTCs for a typing, which are TTCs such that every TTC that (semantically) \nentails the typing entails one of them component-wise. Hence whenever [T1] |= H [T2] we have T1 <: sat(T2), \nso sat is an implemen\u00adtation of [\u00b7] . The saturation mapping also preserves semantics, so the other direction \nof the implication holds as well. We can follow Quine s de.nitions and proofs almost paragraph\u00adby-paragraph, \nstarting with the generalisation of the consensus operation: De.nition 7. The consensus t .J t ' over \nJ of two n-ary TTCs t and t ', where J .{1,..., n} is an index set, is de.ned by (t1,..., tn | p | C) \n.J (t1' ,..., tn ' | p ' | C ' )= d(u1,..., un | p . p ' . J \u00d7 J | C . C ' )d where (V V j.J tj . j.J \ntj ' if i . J ui = ti . ti ' otherwise VV We will sometimes write J t for j.J tj. Roughly, the consensus \noperation equates all columns in J and preserves all other equalities and inhabitation constraints of \nits operands, takes disjunctions over the columns in J, and conjunc\u00adtions over all the others. For example, \nin the example shown in Fig. 5 we can take the consensus of (a, a) and (b, b) over J = {1, 2} to obtain \nthe TTC (a . b, a . b | {{1, 2}}), which is precisely the missing piece to show that T is a subtype of \nT' . In the particular case where J = {j} is a singleton set, and both partitions and inhabitation constraints \nare trivial, the consen\u00adsus takes conjunctions on all columns except j, where it takes a dis\u00adjunction. \nThis is a generalisation of the behaviour of the consensus operator used in the minimisation of Boolean \nfunctions. For example, in Fig. 4 we can take the consensus of (a . b, a) and (c . d, a) on J = {1} to \nobtain the TTC (a . b . c . d, a) which covers (b . c, a). We need another kind of consensus to deal \nwith inhabitation constraints: De.nition 8. The existential consensus of two n-ary TTCs t and t ' is \nde.ned by ' | C ' (t1,..., tn | p | C) .. (t1' ,..., t ' | p )= n d(t1 . t1' ,..., tn . tn ' | p . p \n' | C . C ' )d where C . C' = {c . c ' | c . C, c ' . C' }. Algorithm 1 SATURATE(T) Require: A typing \nT of arity n. Ensure: A saturated typing semantically equivalent to T. 1: repeat 2: Told . T 3: for \nt, t ' . Told do 4: T . max .(T . ALL-CONSENSUS(n, t, t ' )) 5: until Told = T 6: return T Algorithm \n2 ALL-CONSENSUS(n,t,t ' ) Require: Two TTCs t and t ' of arity n. Ensure: The lean set of all their consensus \nTTCs. 1: S .\u00d8 2: for J .{1,..., n} do 3: S . max .(S .{t .J t ' }) 4: S . max .(S .{t .. t ' }) 5: return \nS To see why this is necessary, assume we have type symbols a, b, c with H |= .x.a(x) . b(x) . c(x), \nand consider typings T = {(c | id | a . b)} and T' = {(c | id | a), (c | id | b)}. Clearly, [T]= c(x1) \n..z.(a(z) . b(z)) = [T' ], yet T <: T' since {a . b} <: {a} and {a . b} <: {b}. However, if we add the \nexistential consensus (c | id | a . b) to T', we will be able to prove that T <: T' . It is not hard \nto verify that adding the consensus of two TTCs to a typing does not change its semantics. Lemma 10. \nFor two TTCs t, t ' and an index set J we have [t .J t ' ] |= H [{t, t ' }] and [t .. t ' ] |= H [{t, \nt ' }]. Proof Sketch. Clearly, if J = \u00d8 the consensus is just the meet, so nothing needs to be proved. \nOtherwise, let I and s be given such that I|= s [t .J t ' ]. Then, VV for some i . J, either I|=s j.J \ntj(xi) or I|=s j.J tj ' (xi); in the former case I|= s [t ], and in the latter case I|= s [t ' ]. For \nthe existential consensus, assume I|= s [t .. t ' ] and further assume there is some inhabitation constraint \nc of t such that I |= .y.c(y) (for otherwise I|= s [t ] is immediate). We must have I|= .y.c(y) . c ' \n(y) for all inhabitation constraints c ' of t ' , so certainly I|= .y.c ' (y). We then easily see that \nI|= s [t ' ]. Remember that typings do not contain non-maximal elements. The following result shows that \nwe do not lose anything by elimi\u00adnating them. Lemma 11. Consensus formation is monotonic in the sense \nthat for TTCs s, s ' ,t,t ' with s<: s ' and t<: t ' and for an index set J we have s .J t<: s ' .J t \n' and s .. t<: s ' .. t ' Proof Sketch. The components of the two TTCs are combined us\u00ading conjunction \nand disjunction, which are monotonic with respect to subtyping, and the partitionings and inhabitation \nconstraints are combined using set union which is also monotonic. De.nition 9. An n-ary typing T is said \nto be saturated if the consensus of any two TTCs contained in it is covered by the typing; i.e. for any \nt, t ' . T and any index set J .{1,..., n} we have t .J t ' <: T and t .. t ' <: T. Lemma 12. Every \ntyping T can be converted into a semantically equivalent, saturated typing sat(T) by exhaustive consensus \nfor\u00admation. Proof. We use Algorithm 2 to collect all consensus TTCs of two given TTCs. As shown in Algorithm \n1, this is performed for every pair of TTCs in the typing, and this procedure is repeated until a .xpoint \nis reached. Notice that in each iteration (except the last) the set of TTCs covered by the typing becomes \nlarger, and since there are only .nitely many TTCs, the termination condition must become true eventually. \nWe now generalise the concepts of implicants and prime impli\u00adcants. De.nition 10. A TTC t is an implicant \nfor a typing T' if we have [t ] |= H [T' ]; it is a prime implicant if it is a <:-maximal implicant. \nMore explicitly, a TTC p is a prime implicant for a typing T' if 1. p is an implicant of T' 2. For any \nt with p<: t and [t ] |= H [T' ], we have t<: p.  The second condition is equivalent to saying that \nfor any t with p<: t and t<: p we have [t ] |= H [T]. Lemma 13. Every implicant implies a prime implicant. \nProof. The set of all implicants of a typing is .nite, so for any implicant t there is a maximal implicant \np with t<: p, which is then prime by de.nition. Remark 14. If p is a prime implicant of T, then p<: T \niff p . T. Proof. The direction from right to left is trivial. For the other direction, suppose p<: T, \ni.e. p<: p ' for some p ' . T. Certainly [p ' ] |= H [T], so p ' <: p since p is prime. But this means \nthat p = p ' . T. We want to show that sat(T) contains all prime implicants of T, so we show that saturation \ncan continue as long as there is some prime implicant not included in the saturated set yet. Lemma 15. \nIf there is a prime implicant p of T with p . T, then T is not saturated. Proof. Let p be a prime implicant \nof T with p . T. Consider the set M := {t | [t ] |= H [p],t <: T}This set is not empty (it contains p \nby the preceding remark) and it is .nite, so we can choose a <:-minimal element . . M. The proof proceeds \nby considering three cases. In the .rst, we shall show that a consensus step is possible, thus proving \nthat T is not saturated. In the second, we show that an existential consensus step can be made, again \nproving non-saturation. Finally, we show that either the .rst or second case must apply, as their combined \nnegation leads to a contradiction. Assume there is an index i for which .i =H r ' . r '' for two r ' \n, r '' neither of which equals .i. Then we form . ' := .i:=r ' and . '' := .i:=r '' . Observe that . \n' and . '' are strictly smaller than ., so they cannot be in M. They both, however, entail p, so there \nmust be . ' ,. '' . T with . ' <: . ' <: . '' and . '' . Note that . = . ' .[i] . '', where [i] is the \nequivalence class of i in .. By Lemma 11, this means that .<: . ' .[i] . '', and since .[i] . '' .<: \nT we also have . ' <: T, which shows that T is not saturated. Assume for some c . C, where C is the set \nof inhabitation ' '' ''' constraints of ., we have c =H r . r for two r , r neither of which equal c. \nWe form . ' from . by setting the inhabitation constraints to C \\{c}.{r ' } and minimising, and similarly \nfor . ''. As above, those two are strictly smaller than . and we can .nd . ' and . '' . The proof goes \nthrough as in the previous case, since it is easy to see that . = . ' .. . '' . ''' ''' Otherwise, for \nany index i and r , r with .i =H r . r we have either .i =H r ' or .i =H r '' (i.e. every .i is join\u00adirreducible) \nand likewise for all c . C. We will show that in this case .<: T, contrary to our assump\u00adtions. We know \nthat [.] |= H [T], so any interpretation I and assignment s with I|= H and I|=s [.] will satisfy some \nTTC t . T. Put differently, if I|=s (H . .i)(xi) for all i and I|= .y.(H . c)(y) for all inhabitation \nconstraints c and moreover s satis.es the partition of ., then we will .nd t . T with I|=s [t ]. Observe \nthat for every i the (propositional) formula |h|.|.i| can be written as a conjunction li,1 . ... . li,mi \nof type literals. We can moreover assume that every type symbol occurs in precisely one of these literals, \nfor if, say, type t does not occur, then li,1 . ... . li,mi . t . li,1 . ... . li,mi .\u00act is a join reduction \nof |h|.|.i|. Let such a decomposition be .xed and let Li := {li,1,..., li,mi }. Since .i = .j whenever \ni and j are in the same partition, we can clearly choose the decomposition such that Li = Lj in this \ncase. Likewise, for every inhabitation constraint c we can write |h|.|c| as lc,1 . ... . lc,mc , and \nde.ne Lc by analogy. We de.ne an interpretation I over the domain {x[1],..., x[n]}. C of variables modulo \nthe partition of . plus the inhabitation constraints by I(b)= {x[i] | b . Li}.{c | b . Lc} for every \ntype symbol b. The assignment is simply de.ned by s(xi)= x[i]. It is easy to see that x[i] . [l] iff \nl . Li for all 1 = i = n, and c . [l] iff l . Lc for all inhabitation constraints c, from which we deduce \nI|=s (H ..i)(xi) for all i, and I|= .y.(H .c)(y) for all inhabitation constraints c. By de.nition, s \nsatis.es the partition of .. So we have some t . T with I|=s [t ]. We claim that .<: t. Indeed, let an \nindex 1 = i = n be given. Then we can write ti as a disjunction of conjunctions, such that one of its \ndisjuncts, of the form l' i,1 .....l' , is satis.ed under I and s, meaning that i,m ' i x[i] . [li' ,j]I \nfor all j, so all the l' i,j are in fact in Li, so .i <: ti. Since s satis.es the partition of t, this \npartition must be .ner than the partition of .. Finally, let an inhabitation constraint d of t be given. \nSince I|= .y.(H . d)(y), the interpretation of H . d cannot be empty. As above, we can write H . d in \na disjunctive form such that all the literals in one of its disjuncts are non-empty in I. So there must \nbe some domain element that occurs in the denotation of all these literals. If it is one of the x[i], \nthen we have .i <: d, which implies c <: d for some inhabitation constraint c of .; if it is an inhabitation \nconstraint c, then we have c <: d directly. Taking these facts together, we get .<: t , whence .<: T. \nThis contradicts our assumption, and we conclude that this subcase cannot occur.  Now we can declare \nvictory: Theorem 16. If [T1] |= H [T2], then T1 <: sat(T2). Proof. Assume [T1] |= H [T2] and let t . \nT1 be given. Then [t ] |= H [T2], so certainly [t ] |= H [sat(T2)], since saturation does not change \nthe semantics. By Lemma 13 this means that there is a prime implicant p of sat(T2) with t<: p. By Lemma \n15 we must have p . sat(T2), so t<: sat(T2). Since this holds for any t . T1 we get T1 <: sat(T2). 5. \nImplementation It is not immediately clear that the representation for type programs proposed in the \npreceding two sections can be implemented ef.\u00adciently. While the mapping I\u00b7l from programs to type programs \nis, of course, easy to implement and linear in the size of the program, the translation of type programs \ninto their corresponding typings involves .xpoint iterations to eliminate de.nitions. Saturation is also \npotentially very expensive, since we have to compute the con\u00adsensus on every combination of columns for \nevery pair of TTCs in a typing, and repeat this operation until a .xpoint is reached. We report in this \nsection on our experience with a prototype implementation based on Semmle s existing type checking tech\u00adnology \nas described in [13]. The type checker computes typings for programs and immediately proceeds to saturate \nthem to prepare for containment checking. It uses a number of simple heuristics to de\u00adtermine whether \na consensus operation needs to be performed. This drastically reduces the overhead of saturation in practice \nand makes our type inference algorithm practically usable. TTCs can be compactly represented by encoding \ntheir compo\u00adnent type propositions as binary decision diagrams. The same can be done for the hierarchy, \nso checking containment of type propo\u00adsitions can be done with simple BDD operations. As with any use \nof BDDs, it is crucial to .nd a suitable variable order. We choose a very simple order that tries to \nassign neigh\u00adbouring indices to type symbols that appear in the same conjunct of the hierarchy formula \nH . For example, if the hierarchy contains a subtyping statement u1(x) . u2(x) or a disjointness constraint \n\u00ac(u1(x) . u2(x)), then u1 and u2 will occupy adjacent BDD vari\u00adables. This heuristic is simple to implement \nand yields reasonable BDD sizes as shown below. To mitigate the combinatorial explosion that saturation \nmight bring with it, we avoid useless consensus formation, i.e. we will '' ' not form a consensus t . \nt if t . t<: {t, t ' } or t . t is degenerate. The following lemma provides a number of suf.cient conditions \nfor a consensus to be useless: Lemma 17. Let t =(t1,..., tn | p | C) and t ' =(t1' ,..., tn ' |p ' | \nC' ) be two TTCs and J .{1,..., n} a set of indices. Then the following holds: 1. IfN. := {i | ti . ti \n' = .} . J then t .J t ' is degenerate. VV 2.If j.J tj = . or j.J tj ' = ., then t .J' t ' <: {t, t ' \n} for any J' . J. VV 3. Ifwe havel . J with j.J tj <: tland j.J tj ' <: tj ', then t .J.{l} t ' <: t \n.J t ' . VV 4.If j.J tj <: j.J tj ' or vice versa, then t .J t ' <: {t, t ' }. 5. Forj . J, j' . J with \nj ~ j' we have t .J t ' <: t .J.{j' } t ' . p.p ' 6. IfN. = \u00d8, then t .. t ' is degenerate. Proof. Recall \nthat t .J t ' = d(u1,..., un | p.p ' .J \u00d7J | C.C' )d where (V V j.J tj . j.J tj ' if i . J ui = ti . \nti ' otherwise We prove the individual claims: ' Algorithm 3 ALL-CONSENSUS-OPT(n, t, t ) Require: Two \nTTCs t and t ' of arity n. Ensure: The lean set of all their consensus TTCs. 1: . . t 7 t ' 2: N. .\u00d8 \n3: l, r .T 4: for i =1 to n do 5: if .i = . then 6: 7: N. . N. . {i}l, r . l . ti, r . t ' i ' 8: S \n. ALL-CONSENSUS-REC(n, ., t, l,t , r, N. , 1) 9: if N. = \u00d8 then 10: S . max .(S .{t .. t ' }) 11: return \nS 1. Indeed, assume k . N. V\\ J, then uk = tk . tk ' = .. 2. Assume, for example, j.J tj = . and let \nJ' . J be given,  V V then j.J' tj = ., so ui = j.J' tj ' <: t ' if i . J, and i ti . t ' <: t ' ' ui \n= ii otherwise, so t .J' t<: t '. If the other disjunct is ., we see that t .J' t ' <: t by a similar \nargument. V VV V 3. Note that j.J.{l} tj = j.J tj and j.J.{l} tj ' = j.J tj ' , so '' t .J.{l} t<: t \n.J t . 4. The argument is similar to 2. 5. Writing J' for J .{j' }, we see that the partitioning will \nbe the same for J and J'. Now consider the ith component of t .J t ' . If i ~ i' for some i' . J, then \ni ~ j', so we have  (t .J t ' )i VV V =( j.J tj . j.J tj ' ) .{tk . tk ' | k ~ i, k . J} VV =( j.J tj \n. j.J tj ' ) . (tj' . tj' ' ). V {tk . tk ' | k ~ i, k . J' } (t ' VV t ' = j' . j.J' tj . tj' . j.J' \nj ). V {tk . tk ' | k ~ i, k . J' } VV V <:( j.J' tj . j.J' tj ' ) .{tk . tk ' | k ~ i, k . J' }=(t .J' \nt ' )i ' ' ' Otherwise we have (t .J t )i =(t .J' t )i, so overall t .J t<: t .J' t ' . 6. Obvious, since \nthe components of t .. t ' are obtained by forming the meet. This suggests an improved implementation \nof Algorithm 2, shown in two parts as Algorithm 3 and Algorithm 4, which straight\u00adforwardly exploit the \nabove properties to avoid performing use\u00adless consensus operations whose result would be discarded by \nthe max . operator anyway. In the latter, we make use of an operation PART(., i) which returns the equivalence \npartition index i belongs to in TTC .. To show that these improvements make our type inference al\u00adgorithm \nfeasible in practice, we measure its performance on some typical programs from our intended application \ndomain. The Dat\u00adalog programs to be typed arise as an intermediate representation of programs written \nin a high-level object-oriented query language named .QL [14, 15], which are optimised and then compiled \nto one of several low-level representations for execution. We measure the time it takes to infer types \nfor the 89 queries in the so-called Full Analysis that ships with our source code analysis tool SemmleCode. \nThese queries provide statistics and overview data on structural properties of the analysed code base, \ncompute code metrics, and check for common mistakes or dubious coding practices. Algorithm 4 ALL-CONSENSUS-REC(n, \n., t, l,t ' , r, J, i) Require: Two TTCs t and t ' of arity n, their meet ., a set J . {1,..., n}, an \nindex 1 = i = n, and two partial results VV l = {j . J | tj}, r = {j . J | tj ' }. Ensure: The lean set \nof all consensus TTCs of t and t ' over index sets J' . J such that J n{1,..., i - 1} = J' n{1,..., i \n- 1}. 1: if l = .. r = . then 2: return \u00d8 3: if i = n then 4: if l <: r . r <: l then 5: return \u00d8 6: \nreturn {t .J t ' } ' 7: S . ALL-CONSENSUS-REC(n, ., t, l,t , r, J, i + 1) 8: if i . J . l <: ti . r \n<: ti ' then 9: return S 10: l, r . l . ti, r . ti ' 11: J . J . PART(., i) 12: i . i +1 13: S . max \n.(S . ALL-CONSENSUS-REC(n, ., t, l,t ' , r, J, i)) 14: return S A type inference for the query being \ncompiled is performed at three different points during the optimisation process, giving a total of 267 \ntime measurements. All times were measured on a machine running a Java 1.6 virtual machine under Linux \n2.6.28-13 on an Intel Core2 Duo at 2.1 GHz with four gigabytes of RAM, averaging over ten runs, and for \neach value discarding the lowest and highest reading. Of the 267 calls to type inference, 65% .nish in \n0.5 seconds or less, 71% take no more than one second, 93% no more than two, and in 98% of the cases \ntype inference is done in under three seconds. Only two type inferences take longer than four seconds, \nat around 4.5 seconds each. The size of the programs for which types are inferred varies greatly, with \nmost programs containing between 500 and 1500 sub\u00adterms, but some programs are signi.cantly larger at \nmore than 3000 subterms. Interestingly, program size and type inference time are only very weakly correlated \n(.< 0.4), and the correlation between the number of strati.cation layers (which roughly corresponds to \nthe number of .xpoint computations to be done) and type inference time is also not convincing (.< 0.6). \nThe low correlation is evident in Fig. 6 which shows the type inference time plotted on the y-axis versus \nthe depth (i.e., number of layers) of the program on the x-axis. In particular, the two cases in which \ntype inference takes longer than four seconds are both of medium size and not among the deepest either. \nThis suggests that the asymptotic behaviour of the algorithm in terms of input size is masked by the \nstrong in.uence of implemen\u00adtation details (at least for the kind of programs we would expect to deal \nwith in our applications), and we can expect signi.cant perfor\u00admance gains from .ne tuning the implementation. \nOur experiments also show that saturation, while extremely expensive in theory, is quite well-behaved \nin practice: in 78% of all cases, no new TTCs are added during the .rst iteration of Algorithm 1, so \nthe typing is already saturated. In another 17% of all cases we need only one more iteration, and we \nalmost never ( 0.01%) need to do more than four iterations. Although in every individual iteration we \npotentially have to take the consensus over every combination of columns, our heuris\u00adtics manage to exclude \nall combinations of more than one column in 94% of all cases, and sometimes (14%) can even show that \nno consensus formation is needed at all.  Figure 6. Depth of Programs and Type Inference Time Since \nour type inference algorithm makes heavy use of BDDs, some statistics about their usage may also be of \ninterest. We use about 300 BDD variables (one for every type symbol), with most of the BDDs constructed \nduring type checking being of rather mod\u00aderate size: the BDD to represent the type hierarchy (which encodes \nabout 800 constraints automatically derived during translation from .QL to Datalog) occupies around 4000 \nnodes, while the BDDs for individual type propositions never take more than 100 nodes. While we have \nanecdotal evidence to show that the optimisation techniques we have presented in earlier work [13] bene.t \ngreatly from combining them with the richer type hierarchies our type system supports, we leave the precise \ninvestigation of this matter to future work. 6. Related Work We now discuss the relation of the present \npaper to previous work of others, as well as an earlier paper by ourselves. Type inference for logic \nprograms The present paper builds on a long and rich tradition of type inference for logic programs. \nAn early proposal is thatofFr\u00a8uhwirth et al. [16], which computes types on a .eld-by-.eld basis. Heintze \nand Jaffar [19] extract a system of set constraints from a logic program that likewise yield a .eld-by\u00ad.eld \ntyping. The advantage of these approaches is the ef.ciency of type checking, but as we have already indicated, \nin our experience it leads to an unacceptable loss of precision. Many others have since applied abstract \ninterpretation to infer types for logic programs, e.g. [21, 18, 17, 5]. Interestingly, Bachmair et al. \n[3] have shown that Heintze and Jaffar s set constraints correspond to formulae of monadic .rst\u00adorder \nlogic, so there is yet another connection between this logic and types for logic programs, albeit of \na very different character. In earlier work of our own, we put forward a type inference procedure for \nDatalog that bears a super.cial resemblance to the present proposal [13]. The differences are however \nprofound: In [13], we employed a similar notion of TTCs, but the notion of typing was syntactic rather \nthan semantic: in particular, we used the syntactic check <: for subtype inclusion. The most important \nadvance made here is a clean semantic framework (separating the syntactic procedure from the semantic \ngoal of over-approximation), and the use of prime implicants to make the syntactic check complete.  \n Furthermore, in [13] we placed restrictions on the type hierar\u00adchy, in particular we assumed just a \nsubtype order and did not allow separate statements (of disjointness, equivalence and so on) as we do \nhere. This is a very important improvement in practice, as realistic databases require such complex type \nhier\u00adarchies. Indeed we were forced to make this generalisation at the insistence of a client of our \ncompany.  Also, we have found in practice it is very important to handle negated types, so that predicates \nlike employee(x).\u00acstudent(x) are bona .de types that can be inferred. In our earlier work, it was impossible \nto handle negated types accurately.  Finally, here we handle inhabitation constraints (existentials \nin type programs) precisely. There was no support for that in [13].  In summary, we have made substantial \nimprovements over our own earlier proposal with a clean semantic approach and an elegant, natural choice \nof type language. Recently, Zook et al. [27] of LogicBlox, Inc., have presented a type checking algorithm \nfor Datalog that supports inclusion con\u00adstraints. One of their main goals is to be able to implement \nthe al\u00adgorithm itself in Datalog, so it has to be polynomial time and hence cannot be complete. We achieve \nmore pleasing theoretical properties and can support a richer language of type constraints by sacri.cing \npolynomial time guarantees, although our experiments show that this is a reasonable tradeoff for our \napplication area. Upper envelopes We have already alluded to the earlier work of Chaudhuri and Kolaitis \nin this area [8, 9]. They investigate the ap\u00adproximation of a Datalog program by a disjunction of conjunctive \nqueries: an over-approximation is called an upper envelope, and an under-approximation a lower envelope. \nThey show that in general it is not possible to compute a tightest upper envelope. The conjunctive queries \nin an upper envelope are akin to our TTCs. However, while upper envelopes can contain extensional relation \nsymbols of arity greater than one, TTCs are restricted to monadic extensionals. We have demonstrated \nthat with this de.ni\u00adtion, it is possible to compute a tightest upper envelope. Chaudhuri shows that \nwhen Cartesian products are forbidden (in so-called connected envelopes) tightest envelopes can be computed \nas well; this restriction seems unnatural in the context of type inference, but it would be interesting \nto see whether his techniques can be adapted to our setting. Containment checking We have already mentioned \nthe landmark result of Shmueli [23] that precludes decidability of general pro\u00adgram containment. Much \nresearch has been done on restricted classes of programs for which containment is decidable, such as \nthe classic result by Chandra and Merlin [7] showing NP-completeness of the containment problem for conjunctive \nqueries. Recently, Wei and Lausen [24] have investigated the contain\u00adment problem for conjunctive queries \nin the presence of negation. While their algorithm also reduces the containment check to a se\u00adries of \nchecks on a family of extended queries, which is some\u00adwhat reminiscent of our reduction to component-wise \nchecking, the technical details are quite different and not directly related to type checking. Containment \nof monadic Datalog programs was proved decid\u00adable by Cosmadakis et al. [11]. In contrast to our work, \nhowever, they handle Datalog programs in which all intensional predicates are monadic (and extensionals \ncan be of arbitrary arity), whereas our type programs have monadic extensionals (and put no restric\u00adtion \non the arities of intensional predicates). Alternative Implementations While the performance of our pro\u00adtotype \nimplementation is promising, other implementation ap\u00adproaches certainly exist and may be worth exploring. \nBachmair et al. [4] develop a decision procedure for monadic .rst order logic based on the superposition \ncalculus. Since type programs can readily be expressed as monadic .rst order formulae, their algorithm \ncould be used to decide type containment. Another pos\u00adsibility would be to use Ackermann s translation \nfrom monadic .rst order logic to equality logic [2], and then employ a decision procedure for this latter \nlogic. 7. Conclusion We have presented a type inference procedure that assigns an upper envelope to \neach Datalog program. That envelope is itself a Datalog program that makes calls to monadic extensionals \nonly. The algo\u00adrithm is able to cope with complex type hierarchies, which may include statements of implication, \nequivalence and disjointness of entity types. The type inference procedure is itself an extremely simple \nsyn\u00adtactic mapping. The hard work goes into an ef.cient method of checking containment between type programs. \nWe achieve this via a novel adaption of Quine s algorithm for the computation of the prime implicants \nof a logical formula. Generalising from logical formulae to type programs, we bring types into a saturated \nform on which containment is easily checked. As shown by our experiments, the algorithm for inferring \na type and saturating it works well on practical examples. While it may still exhibit exponential behaviour \nin the worst case, such extreme cases do not seem to arise in our application area. Thus our algorithm \nis a marked improvement over well-known simpler constructions that always require an exponential overhead. \nMany avenues for further work remain. Perhaps the most chal\u00adlenging of these is the production of good \nerror messages when type errors are identi.ed: this requires printing the Boolean for\u00admulae represented \nvia TTCs in legible form. We have made some progress on this, employing Coudert et al. s restrict operator \non BDDs, which is another application of prime implicants [12]. There is also substantial further engineering \nwork to be done in the implementation. Careful inspection of the statistics show that our use of BDDs \nis very much unlike their use in typical model checking applications [26], and we believe this could \nbe exploited in the use of a specialised BDD package. For now we are using JavaBDD [25], which is a literal \ntranslation of a C-based BDD package into Java. Finally, we will need to investigate how to best exploit \nthe advanced features offered by our type system. In particular, much experience remains to be gained \nin how to make it easy and natural for the programmer to specify the constraints making up the type hierarchy, \nand which kinds of constraints bene.t which kinds of programs. Acknowledgments We would like to thank \nMolham Aref for insisting that type infer\u00adence must handle complex type hierarchies including statements \nof disjointness, implication and equivalence. His enthusiasm has been an inspiration throughout this \nproject. Damien Sereni has contributed crucial insights to this paper, in particular he pointed out the \nincompleteness of the syntactic sub\u00adtyping check and came up with the geometric interpretation. Pavel \nAvgustinov showed incredible tenacity in tracking down insidious bugs. Julian Tibble suggested the BDD \nvariable ordering and made sure we got it right in our implementation. Michael Benedikt, Damien Sereni, \nand the anonymous review\u00aders provided valuable comments on earlier versions of this paper. Notice The \ntechnology described in this paper is proprietary; U.S. and other patents pending. For licensing information, \nwrite to licenses@semmle.com. References [1] Serge Abiteboul, Georg Lausen, Heinz Uphoff, and Emmanuel \nWaller. Methods and rules. In ACM SIGMOD International Conference on Management of Data, pages 32 41. \nACM Press, 1993. [2] Wilhelm Ackermann. Solvable Cases of the Decision Problem. North-Holland Publishing \nCompany, Amsterdam, 1954. [3] Leo Bachmair, Harald Ganzinger, and Uwe Waldmann. Set constraints are the \nmonadic class. In Logic in Computer Science, pages 75 83, 1993. [4] Leo Bachmair, Harald Ganzinger, and \nUwe Waldmann. Superposition with Simpli.cation as a Decision Procedure for the Monadic Class with Equality. \nIn KGC 93: Proceedings of the Third Kurt G\u00a8 odel Colloquium on Computational Logic and Proof Theory, \npages 83 96, London, UK, 1993. Springer-Verlag. [5] Sacha Berger, Emmanuel Coquery, Wlodzimierz Drabent, \nand Artur Wilk. Descriptive Typing Rules for Xcerpt and their soundness. In Franc\u00b8ois Fages and Sylvain \nSoliman, editors, Principles and Practice of Semantic Web Reasoning, volume 3703 of LNCS, pages 85 100. \nSpringer, 2005. [6] George S. Boolos and Richard C. Jeffrey. Computability and Logic. Cambridge University \nPress, 3rd edition, 1989. [7] Ashok K. Chandra and Philip M. Merlin. Optimal Implementation of Conjunctive \nQueries in Relational Data Bases. In STOC 77: Pro\u00adceedings of the ninth annual ACM symposium on Theory \nof computing, pages 77 90, New York, NY, USA, 1977. ACM. [8] Surajit Chaudhuri. Finding nonrecursive \nenvelopes for Datalog pred\u00adicates. In Principles of Database Systems (PODS), pages 135 146, 1993. [9] \nSurajit Chaudhuri and Phokion G. Kolaitis. Can Datalog be approx\u00adimated? In Principles of Database Systems \n(PODS), pages 86 96, 1994. [10] Kevin J. Compton. Strati.ed least .xpoint logic. Theoretical Com\u00adputer \nScience, 131(1):95 120, 1994. [11] Stavros Cosmadakis, Haim Gaifman, Paris Kanellakis, and Moshe Vardi. \nDecidable Optimization Problems for Database Logic Pro\u00adgrams. In Proceedings of the 20th annual ACM Symposium \non Com\u00adputing, pages 477 490, 1988. [12] Olivier Coudert, Christian Berthet, and Jean Christophe Madre. \nVer\u00adi.cation of synchronous sequential machines based on symbolic ex\u00adecution. In Automatic Veri.cation \nMethods for Finite State Systems, volume 407 of Lecture Notes in Computer Science, pages 365 373. Springer, \n1989. [13] Oege de Moor, Damien Sereni, Pavel Avgustinov, and Mathieu Ver\u00adbaere. Type Inference for Datalog \nand Its Application to Query Op\u00adtimisation. In PODS 08: Proceedings of the twenty-seventh ACM SIGMOD-SIGACT-SIGART \nsymposium on Principles of database sys\u00adtems, pages 291 300, New York, NY, USA, 2008. ACM. [14] Oege \nde Moor, Damien Sereni, Mathieu Verbaere, Elnar Hajiyev, Pavel Avgustinov, Torbj\u00a8orn Ekman, Neil Ongkingco, \nand Julian Tib\u00adble. .QL: Object-oriented queries made easy. In Ralf L\u00a8ammel, Jo ao Saraiva, and Joost \nVisser, editors, Generative and Transformational Techniques in Software Engineering, LNCS. Springer, \n2007. [15] Oege de Moor, Mathieu Verbaere, Elnar Hajiyev, Pavel Avgustinov, Torbj\u00a8 orn Ekman, Neil Ongkingco, \nDamien Sereni, and Julian Tibble. .QL for source code analysis. In Source Code Analysis and Manipu\u00ad lation \n(SCAM 07), pages 3 16. IEEE, 2007. [16] Thom W. Fr\u00a8uhwirth, Ehud Y. Shapiro, Moshe Y. Vardi, and Eyal \nYardeni. Logic programs as types for logic programs. In Logic in Computer Science (LICS), pages 300 309. \nIEEE Computer Society, 1991. [17] John P. Gallagher, Kim S. Henriksen, and Gourinath Banda. Tech\u00adniques \nfor Scaling Up Analyses Based on Pre-Interpretations. In M. Gabbrielli and G. Gupta, editors, International \nConference on Logic Programming (ICLP 05), volume 3668 of LNCS, pages 280 296. Springer, 2005. [18] \nJohn P. Gallagher and Germ\u00b4an Puebla. Abstract Interpretation over Non-deterministic Finite Tree Automata \nfor Set-Based Analysis of Logic Programs. In Practical Aspects of Declarative Languages (PADL), volume \n2257 of LNCS, pages 243 261. Springer, 2002. [19] Nevin C. Heintze and Joxan Jaffar. A .nite presentation \ntheorem for approximating logic programs. In Symposium on Principles of Programming Languages (POPL), \npages 197 209, 1990. [20] David Hilbert and Wilhelm Ackermann. Grundz\u00a8uge der Theoretischen Logik. Julius \nSpringer, Berlin, 1928. [21] Kim Marriott, Harald S\u00f8ndergaard, and Neil D. Jones. Denotational Abstract \nInterpretation of Logic Programs. ACM Transactions on Programming Languages and Systems, 16(3):607 648, \n1994. [22] Willard V. Quine. On Cores and Prime Implicants of Truth Functions. The American Mathematical \nMonthly, 66(9):755 760, Nov. 1959. [23] Oded Shmueli. Equivalence of Datalog Queries is Undecidable. \nJour\u00adnal of Logic Programming, 15(3):231 241, 1993. [24] Fang Wei and Georg Lausen. Containment of Conjunctive \nQueries with Safe Negation. In ICDT 03: Proceedings of the 9th International Conference on Database Theory, \npages 346 360, London, UK, 2002. Springer-Verlag. [25] John Whaley. JavaBDD. http://javabdd.sourceforge.net/, \n2007. [26] Bwolen Yang, Randal E. Bryant, David R. O Halloran, Armin Biere, Olivier Coudert, Geert Janssen, \nRajeev K. Ranjan, and Fabio Somenzi. A Performance Study of BDD-Based Model Checking. In 2nd Inter\u00adnational \nConference on Formal Methods in Computer-Aided Design, volume 1522 of Lecture Notes in Computer Science, \npages 255 289. Springer, 1998. [27] David Zook, Emir Pasalic, and Beata Sarna-Starosta. Typed Data\u00adlog. \nIn Practical Aspects of Declarative Languages, pages 168 182. Springer Berlin/Heidelberg, 2009. \n\t\t\t", "proc_id": "1706299", "abstract": "<p>Type inference for Datalog can be understood as the problem of mapping programs to a sublanguage for which containment is decidable. To wit, given a program in Datalog, a schema describing the types of extensional relations, and a user-supplied set of facts about the basic types (stating conditions such as disjointness, implication or equivalence), we aim to infer an over-approximation of the semantics of the program, which should be expressible in a suitable sublanguage of Datalog.</p> <p>We argue that Datalog with monadic extensionals is an appropriate choice for that sublanguage of types, and we present an inference algorithm. The inference algorithm is proved sound, and we also show that it infers the tightest possible over-approximation for a large class of Datalog programs. Furthermore, we present a practical containment check for a large subset of our type language. The crux of that containment check is a novel generalisation of Quine's procedure for computing prime implicants. The type system has been implemented in a state-of-the-art industrial database system, and we report on experiments with this implementation.</p>", "authors": [{"name": "Max Sch&#228;fer", "author_profile_id": "81381592942", "affiliation": "Semmle Ltd., Oxford, United Kingdom", "person_id": "P1911056", "email_address": "", "orcid_id": ""}, {"name": "Oege de Moor", "author_profile_id": "81100198102", "affiliation": "Semmle Ltd., Oxford, United Kingdom", "person_id": "P1911057", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706317", "year": "2010", "article_id": "1706317", "conference": "POPL", "title": "Type inference for datalog with complex type hierarchies", "url": "http://dl.acm.org/citation.cfm?id=1706317"}