{"article_publication_date": "01-17-2010", "fulltext": "\n A Theory of Indirection via Approximation Aquinas Hobor * Robert Dockins Andrew W. Appel National \nUniversity of Singapore Princeton University Princeton University hobor@comp.nus.edu.sg rdockins@cs.princeton.edu \nappel@princeton.edu Abstract Building semantic models that account for various kinds of indirect reference \nhas traditionally been a dif.cult problem. Indirect refer\u00adence can appear in many guises, such as heap \npointers, higher-order functions, object references, and shared-memory mutexes. We give a general method \nto construct models containing indi\u00adrect reference by presenting a theory of indirection . Our method \ncan be applied in a wide variety of settings and uses only simple, elementary mathematics. In addition \nto various forms of indirect reference, the resulting models support powerful features such as impredicative \nquanti.cation and equirecursion; moreover they are compatible with the kind of powerful substructural \naccounting re\u00adquired to model (higher-order) separation logic. In contrast to pre\u00advious work, our model \nis easy to apply to new settings and has a simple axiomatization, which is complete in the sense that \nall mod\u00adels of it are isomorphic. Our proofs are machine-checked in Coq. Categories and Subject Descriptors \nD.3.1 [PROGRAMMING LANGUAGES]: Formal De.nitions and Theory Semantics; F.3.1 [LOGICS AND MEANINGS OF \nPROGRAMS]: Specifying and Verifying and Reasoning about Programs Logics of pro\u00adgrams; F.4.1 [MATHEMATICAL \nLOGIC AND FORMAL LAN-GUAGES]: Mathematical Logic Mechanical theorem proving General Terms Languages, \nTheory, Veri.cation Keywords Indirection theory, Step-indexed models 1. Introduction A recurring problem \nin the semantics of programming languages is .nding semantic models for systems with indirect reference. \nIndi\u00adrection via pointers gives us mutable records; indirection via locks can be used for shared storage; \nindirection via code pointers gives us complex patterns of computation and recursion. Models for pro\u00adgram \nlogics for these systems need to associate invariants (or asser\u00adtions, or types) with addresses in the \nstore; and yet invariants are predicates on the store. Tying this knot has been dif.cult, espe\u00adcially \nfor program logics that support abstraction (impredicativity). * Supported by a Lee Kuan Yew Postdoctoral \nFellowship. Supported in part by NSF awards CNS-0627650 and CNS-0910448, and AFOSR award FA9550-09-1-0138. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n10, January 17 23, 2010, Madrid, Spain. Copyright c &#38;#169; 2010 ACM 978-1-60558-479-9/10/01. . . \n$10.00 Consider general references in the polymorphic .-calculus. Here is a .awed semantic model of types \nfor this calculus: value = loc of address + num of N + ... type = (memtype \u00d7 value) . T (1) memtype \naddress -type Values are a tagged disjoint union, with the tag loc indicating a memory address. T is \nsome notion of truth values (e.g., the propositions of the metalogic or a boolean algebra) and a natural \ninterpretation of the type A . Tis the characteristic function for a set of A. We write to mean we wish \nwe could de.ne things this way and A-B to indicate a .nite partial function from A to B. The typing judgment \nhas the form . f v : t, where . is a memory typing (memtype), v is a value, and t is a type; the semantic \nmodel for the typing judgment is . f v : t = t (., v). Memory typings are partial functions from addresses \nto types. The motivation for this attempt is that the type ref t can use the memory typing to show that \nthe reference s location has type t : ref t = .(., v). .a. v = loc(a) . .(a)= t. That is, a value v has \ntype ref t if it is an address a, and according to the memory typing ., the memory cell at location a \nhas type t . Unfortunately, this series of de.nitions is not well-founded: type contains a contravariant \noccurrence of memtype, which in turn contains an occurrence of type. A standard diagonalization proves \nthat no solution to these equations exists in set theory. A recent approach to tackle this problem is \nto employ strati.\u00adcation, yielding a well-founded de.nition of an appropriate seman\u00adtic model [AAV03, \nAhm04, AMRV07]. A key strength of these models is that they can express general (impredicative) quanti.ed \ntypes even though they are strati.ed. Unfortunately, these models have a disturbing tendency to leak \ninto any proofs utilizing them, making modularization dif.cult, obscuring their essential features, needlessly \nlimiting their power, and contributing to unpleasant te\u00addium. Also, all of these models are specialized \nto the problem of mutable references, and even for the expert it can be daunting to modify the techniques \nto apply to other domains. Hobor et al. applied these techniques to Hoare logics, devel\u00adoping a model \nfor a concurrent separation logic (CSL) with .rst\u00adclass locks and threads [HAZ08]. This model was extremely \ncom\u00adplex to construct because the substructural accounting was woven throughout the strati.cation. It \nwas also complex to use, exposing more than .fty axioms.Even then, the axiom set was incomplete: from \ntime to time the CSL soundness proof required the statement and proof of additional properties (which \nwere provable from the model). Like the mutable reference models, Hobor et al. s model was a solution \nto a speci.c problem, and could not be applied to other problems not even to other concurrent separation \nlogics. We present a single solution, indirection theory, that can handle these domains as well as numerous \nothers. Our model is character\u00adized by just two axioms, an order of magnitude better than the sim\u00adplest \nof the previous solutions. The axioms are equational, orthog\u00adonal, and complete, and have greater expressive \npower and cleaner modularity. The modularity enables a graceful extension for sub\u00adstructural accounting \nthat does not need to thread the accounting through the strati.cation. Moreover, the axioms provide greater \nin\u00adsight into the model by directly exposing the approximation at the heart of the strati.cation technique. \n As we show in \u00a72, a key observation is that many domains can be described by the pseudoequation: K \n F ((K \u00d7 O) . T), (2) where F (X) is a covariant functor, O is some arbitrary set of other data and K \nis the object that we wish to construct. The earlier cardinality argument guarantees we cannot construct \nK (in set theory), but indirection theory lets us approximate it: K -N\u00d7 F ((K \u00d7 O) . T) (3) Here X -Y \nmeans the small type X is related to the big type Y by two functions: squash : Y . X and unsquash : X \n. Y . The squash function packs an element y of the big type Y into an element of the small type X, applying \nan approximation when the structure of y is too complex to .t into X. The unsquash function reverses \nthe process, unpacking an element of X into an element of Y ; since Y is bigger than X, unsquash is lossless. \nThe squash and unsquash functions form a section-retraction pair, meaning that squash . unsquash : X \n. X is the identity function and unsquash . squash : Y . Y is an approximation function. Thus X -Y is \nalmost an isomorphism, and informally one can read X -Y as X is approximately Y . With equation (3), \nindirection theory says that left hand side of pseudoequation (2) is approximately equal to a pair of \na natural number and the right hand side of pseudoequation (2). Contributions. \u00a72 We show numerous examples \ncontaining indirect reference and show how they can be characterized with a covariant functor. \u00a73 We \npresent the two axioms of indirection theory. \u00a74 We show how to apply the axioms to two of the examples. \n\u00a75 We explore some implications of indirection theory. \u00a76 We induce an impredicative logic from indirection \ntheory. \u00a77 We combine indirection theory and substructural accounting. \u00a78 We show a simple way to construct \nthe model once and for all, avoiding the need for application-speci.c models. \u00a79 We prove that the axioms \nof indirection theory completely characterize our model (that is, all models are isomorphic). Our proofs \nare completely machine-checked. The Coq imple\u00admentation of the axioms of indirection theory from \u00a73, \nthe logics and constructions from \u00a76 and \u00a77, the model construction from \u00a78, the uniqueness proof from \n\u00a79, and the worked example of using indirection theory to prove the type soundness of the polymorphic \n.-calculus with references from \u00a72.1, are available at: http://msl.cs.princeton.edu/ 2. Applications \nfor indirection theory Here we examine a selection of examples involving indirect refer\u00adence. In each \ncase intuition leads to an impossible model that we can approximate with indirection theory. We do not \nexplain the ex\u00adamples in great detail, and refer interested readers to the original papers, which explain \nthe full motivation and original models. In each case, constructing the original model was a dif.cult \ntask. 2.1 General references in the .-calculus Ahmed et al. constructed the .rst model of a type system \nfor the polymorphic .-calculus with general references [AAV03]. Follow\u00ading (1), we want a solution to \nthe pseudoequation memtype address -((memtype \u00d7 value) . T), which falls neatly into the pattern of \npseudoequation (2) with F (X) = address -X O = value. By equation (3), indirection theory constructs \nthe approximation memtype -N\u00d7 (address -((memtype \u00d7 value) . T)), and by folding the de.nition of type \n(from eqn. 1) we reach memtype -N\u00d7 (address -type). This model is suf.cient to de.ne a powerful type \nsystem for the polymorphic .-calculus with mutable references. In \u00a74.1, we will show how to construct \nthe types nat and ref t. 2.2 General references in von Neumann machines Modeling a type system with \ngeneral references for von Neumann machines was solved .rst by Ahmed [Ahm04], and then later in a more \nsophisticated way by Appel et al. [AMRV07]. The key is that whereas in the .-calculus types are based \non sets of values, on a von Neumann machine types are based on sets of register banks. Here is the intuition \nfor a von Neumann machine with 32-bit integer memory addressing and m 32-bit integer registers: rbank \n= ... int32\u00d7 m-2 \u00d7int32 type = (memtype \u00d7 rbank) . T memtype int32 -type. The intuition is thus very \nsimilar to the .-calculus case. We set F (X) = int32 -X O = rbank, and indirection theory constructs \nthe approximation memtype -N\u00d7 (int32 -type). In the .-calculus, the memory maps addresses to values, \nand values are the O used in constructing the model for types. In the von Neumann machine, the memory \nmaps 32-bit integer addresses to 32-bit integer values; however, O is not a single 32-bit integer but \ninstead a register bank of m 32-bit integers. This minor mismatch makes the type ref t slightly harder \nto de.ne in the von Neumann case, but does not cause any fundamental dif.culties.  2.3 Object references \nHrit\u00b8cu and Schwinghammer modeled general references in the setting of Abadi and Cardelli s object calculus \n[HS08]. The object calculus setting introduces a number of new issues: object creation, method updates, \nand bounded subtyping. To model the storage of methods in the heap, Hrit\u00b8cu and Schwinghammer would like \nto build the following impossible model: type = (heaptype \u00d7 value) . T heaptype address -type. Again \napplying our recipe, we choose F and O as F (X) = address -X O = value, which yields the approximate \nmodel heaptype -N\u00d7 (address -type).  Pleasingly, the normal complications of objects do not appear in \nthe construction of the semantic model. Objects, subtyping and quanti.cation are all dealt with on top \nof the same simple model of memory/heap typings used for general references.  2.4 Substructural state \nAhmed et al. used substructural state to model the uniqueness types found in languages such as Clean, \nCyclone, and TAL [AFM05]. Here the intuitive model has two changes: quals ={U, R, A, L} type = (memtype \n\u00d7 quals \u00d7 value) . T memtype address -quals \u00d7 type. The quals indicate substructural restrictions: U \nindicates unre\u00adstricted data, R indicates relevant, A indicates af.ne, and L in\u00addicates linear. This \nmodel differs from the previous two by putting quals in both contravariant and covariant positions. We \ncan set F (X) = address -(quals \u00d7 X) O = quals \u00d7 value, and use indirection theory to construct the approximation \nmemtype -N\u00d7 (address -(quals \u00d7 type)). 2.5 Embedding semantic assertions in program syntax Consider \na Hoare logic for a language with function pointers and an assert statement. The predicate f : {P }{Q} \nmeans that f is the address of a function with precondition P and postcondition Q. The statement assert(P \n) means that logical assertion P holds at the current program point. This assert is much more powerful \nthan a traditional assert because it takes an assertion in the logic instead of a program expression; \ni.e., P need not be computable.1 There are two ways to represent assertions P : A syntax for assertions, \nwith an associated interpretation;  A semantic predicate of the metalogic (e.g., CiC).  We choose to \nuse semantic assertions because they give additional .exibility and save quite a bit of effort. With \nsyntactic assertions, the syntax of assertions must be .xed at the same time as the syntax of the language. \nHowever, it is not until one is writing programs (well after the syntax of the language is .xed) that \none knows which assertions will be required. With semantic assertions, one can enrich the assertion language \nat any time by simply de.ning its meaning in the metalogic. This late binding allows users of the programming \nlanguage to de.ne entire type disciplines or program logics, should they wish. Moreover, by using semantic \nassertions we get to reuse the binding structure of the metalogic for free, which relieves us of the \nburden of encoding binding structure for quanti.ers using de Bruijn indices or some other technique. \nIn a conventional semantics of Hoare logic with function point\u00aders, f : {P }{Q} is de.ned as f is a function \nwith body b such that {P } b {Q} [Sch06, AB07]. This means that assertions are predi\u00adcates over program \nsyntax. This is simple if assertions are not also embedded in syntax, but if they are then one desires \nthe following: predicate = (program \u00d7 memory \u00d7 ...) . T syntax = assert of predicate + assign of ident \n\u00d7 expr + ... program address -syntax. Here the Hoare logic assertions (predicate) judge the program, \nthe memory, and other unspeci.ed objects (e.g., local variables). The program is used to check function-pointer \nassertions. Program 1 It is not that we intend to build a machine that can compute whether some arbitrary \nassertion P holds; it is that we can use P to reason statically about the program, and then erase to \nan executable program. syntax is a tagged disjoint sum and includes the assert statement as well as numerous \nothers (e.g., assignment, function call, loops). The program is a partial function from addresses to \nsyntax. We set F (X) = address -(assert of X + ...) O = memory \u00d7 ..., and use indirection theory to construct \nthe approximation program -N\u00d7 (address -syntax). This model for assertions has not been presented previously; \nthe conventional presentation of embeddable assertions requires syntactic predicates. Modifying the techniques \nof Ahmed et al. [AAV03, Ahm04], Appel et al. [AMRV07], etc. to build a model for this situation appears \nintimidating. The reason directly stratifying over syntax seems dif.cult is not an issue of theoretical \npower but rather one of proof engineering. The strati.cation in those models needs to be built through \nprogram syntax, which greatly increases the number of tedious details in the construction. The key innovation \nthat makes constructing the model easy in our approach is the introduction of the functor F , which abstracts \naway the boring plumbing .  2.6 Concurrent separation logic with .rst-class locks Concurrent Separation \nLogic (CSL) is a novel way to reason about concurrent programs [O H07]. However, originally it had several \nlimitations, most importantly a lack of .rst-class locks (locks that can be created/destroyed dynamically). \nHobor et al. and Gotsman et al. independently extended CSL to handle .rst-class locks as well as a number \nof other features [HAZ08, GBC+07]. The key idea in CSL is that acquiring a lock allows a thread access \nto additional resources (memory), and releasing a lock re\u00adlinquishes said resources. The shape of the \nresources acquired or relinquished is described by a predicate of separation logic. First\u00adclass locks \nare challenging to model because the resource invariant of one lock can describe the binding of a resource \ninvariant to an\u00adother lock. The intuitive model for this contains a circularity: res = VAL of value + \nLK of (share \u00d7 bool \u00d7 pred) pred = (heap \u00d7 locals) . T heap address -res Heaplets (heap) are partial \nfunctions mapping locations to re\u00adsources (res): either regular data (VAL) or locks (LK). Regular data \nlocations contain values. Since multiple threads can each own part of a lock, each lock is associated \nwith a share, which tracks how much of the lock is controlled. Locks also have a boolean, which is true \nif this thread holds the lock; and a predicate (pred) specifying the lock s resource invariant. We set \nF (X) = address-(VAL of value +LK of (share\u00d7bool \u00d7X)) O = locals, and then can use indirection theory \nto construct the approximation heap -N\u00d7 (address -res). This example is particularly interesting because \nthe resource maps play dual roles: not only do resource maps allow us to solve the indirect reference \nproblems arising from .rst-class locks, but they also give us a way to de.ne a separation logic. In \u00a74.2 \nwe will show how to de.ne the points-to and is-a-lock assertions, and in \u00a76 and \u00a77 will develop the rest \nof a higher-order separation logic. Inversion. In reasoning about resources one wants to do inversion \n(case analysis) on the res type; in reasoning about syntax (\u00a72.5), one wants to do inversion on syntax. \nIndirection theory supports full inversion, unlike our previous models [HAZ08, Hob08].  2.7 Industrial-strength \nCSL model for Concurrent C minor Indirection theory is not only mathematically elegant, but also capable \nof constructing signi.cantly more complicated models than the previous examples. We have used indirection \ntheory to build a model for CSL for Concurrent C minor, a dialect of C with dynamic locks, function pointers, \n.rst-class threads, pointer arithmetic, byte and word addressability, and sophisticated sequential control \n.ow [Ler06, HAZ08, Hob08]. Required features included: First-class function pointer speci.cations that \ncan relate func\u00adtion pre-and postconditions and arguments/return values.  Language independence, i.e., \nassertions are not predicates over program syntax. This is (therefore) a different treatment of the Hoare \ntriple than sketched in \u00a72.5; see [Hob08, Ch. 10].  First-class locks (i.e., the resource invariant \nof a lock can refer to other locks, function pointers, etc.).  Impredicative universal and existential \nquanti.cation (to enable general polymorphic lock pointers, etc.).  Equirecursive invariants (to describe \nlist data structures, etc.).  Semantic assertions embeddable in program syntax.  Support for a stack \npointer, and both local and global variables.  Substructural accounting to model separating conjunction, \nus\u00ading the sophisticated share models of Dockins et al. [DHA09].  Byte addressability, along with a \nrequirement that the four bytes of a word-sized lock must not get separated.  Thus, the model requires \na signi.cant superset of the features provided by the models in \u00a72.5 and \u00a72.6. Hobor et al. developed \nthe .rst model that combined all these elements, but it was extremely complicated [HAZ08]; later Hobor \npresented a partially simpli.ed model, which took dozens of pages to explain [Hob08]. Indirection theory \ncan de.ne the model much more easily. kind = VAL + LK + FUN + CT + RES pred = (rmap \u00d7 mem \u00d7 locals \u00d7 \nsp \u00d7 gmap) . T preds = S(A : Type). list (A . pred) res = NO + YES of (kind \u00d7 share \u00d7 preds) wf rm :(address \n. res) . T = ` ... .a,p,P. .(a)= YES(LK, p, P ) . (a mod 4 = 0) . \u00b4 .(a + 1) = .(a + 2) = .(a + 3) = \nYES(CT, p, (unit, nil)) rmap S(. : address . res). wf rm(.) For further explanation see Hobor et al. \n[HAZ08, Hob08]. The function wf rm enforces alignment for locks. The point is that indirection theory \nhandles this model just like previous examples: rmap -N\u00d7 (S(. : address . res). wf rm(.)).  2.8 Applications \nusing indirection theory In each of these applications, F is covariant (and the circular pseu\u00addoequation \non K is contravariant). The point is that it is possible to think of .nding all the instances of X inside \nthe data structure and performing some operation on each of them. In \u00a710 we discuss extensions to indirection \ntheory, including to bivariant functors. Most of the applications presented above have been previously \nsolved with a step-indexing model (either on paper or machine\u00adchecked). What is new here is the discovery \nof a uniform pattern into which each of the above examples .t. We have used indirection theory to prove \nthe type soundness of the polymorphic .-calculus with references (from \u00a72.1) in Coq. The proofs took \napproximately one week to develop. As mentioned in \u00a72.7, we also use indirection theory to mechan\u00adically \nprove the soundness of a concurrent separation logic with .rst-class locks and threads for Concurrent \nC minor [Hob08]. 3. Axiomatic characterization Input. Suppose we are given a type O ( other data ), a \ntype T ( truth values ) with distinguished inhabitant ., and a covariant functor F . That is, let Type \nstand for the types of the metalogic; then equip F : Type . Type with a function fmap :(A . B) . F (A) \n. F (B) that satis.es the following two axioms:2 fmap idA = idF(A) (4) fmap f . fmap g = fmap (f . g) \n(5) The function fmap can be thought of as a generalization of map from functional languages, which applies \na function to all the ele\u00adments in a list. Thus, fmap(g) should apply g to every X within an F (X). For \nexample, here is fmap for the case of general references in the .-calculus from \u00a72.1: fmap = .g. ... \ng . . Clearly equations (4) and (5) hold for this fmap. The de.nition of fmap is normally straightforward \nwhen the structure of F is known. Output. Indirection theory now provides provides the following: K : \nType (6) pred = K \u00d7 O . T (7) squash : (N\u00d7 F (pred)) . K (8) unsquash : K . (N\u00d7 F (pred)) (9) The de.nitions \nof K (also called knot), squash, and unsquash are abstract. A predicate (pred) is a function in the metalogic \nfrom a pair of a knot K and other data O to truth values. As explained previously, squash and unsquash \nare coercion functions between the small type knot (K) and the big type N\u00d7 F (pred). To coerce an object \nfrom the small type to the big one is lossless, but to go from big to small requires approximation. Equations \n(10) and (11) de.ne the approximation used in indirection theory: level : K . N = fst . unsquash (10) \napprox: pred . pred = n ( p (k, o) level k<n (11).p. .(k, o). . level k = n. The key idea is that knots \nhave levels. A knot with a higher level is able to store more information than a knot with a lower level. \nThe way to determine the level of a knot is to unsquash it and then take the .rst component (equation \n10). The approxn function (equation 11) does the actual approximation by forgetting how a predicate behaves \non knots with levels greater than or equal to n. When an approximated predicate is passed a knot of too \nhigh level it just returns the default value .; if the level is low enough then the underlying original \npredicate is used. The behavior of squash and unsquash are speci.ed by the following two axioms, which \nconstitute all of indirection theory: squash (unsquash k)= k (12) unsquash (squash(n, x)) = (n, fmap \napproxn x). (13) Equation (12) guarantees that squash and unsquash form a section\u00adretraction pair, and \ndemonstrate that unsquash is lossless. In con\u00adtrast, squash is lossy; equation (13) precisely speci.es \nwhere the information is lost. When an F (pred) is squashed to level n, all of the predicates inside \nit are approximated to level n. The simplicity of the axioms is a major strength of indirection theory. \nThe axioms are parametric over F (X), whereas previous models exposed numerous axioms specialized to \ntheir domains. For 2 Readers familiar with category theory will see the obvious inspiration; others will \n.nd that they do not need category theory to follow this paper.  example, Hobor et al. s model for higher-order \nCSL for Concurrent C minor (outlined in \u00a72.7) had more than .fty axioms, all of which follow from equations \n(12) and (13) once F (X) is chosen. We view this pleasing fact as evidence that the axiomatization is \nright. In \u00a79 we prove something stronger: the axiomatization is categorical. Corollaries. There are easy \ncorollaries to the axiomatization of squash and unsquash. First, equation (12) directly implies that \nunsquash is injective and that unsquash . squash is idempotent. (These two facts hold of any section-retraction \npair.) Second, any predicate (pred) pulled out of an unsquashed knot has already been approximated to \nthe level of the knot: unsquash k =(n, F ) . F = fmap approxn F (14) That is, whenever (n, F ) is the \nresult of an unsquash then F is unaffected by approximating it to level n. All the information above \nn has already been lost, so throwing it away again has no effect. The proof is straightforward from equations \n(12) and (13). Third, a predicate P approximated to level n and then approxi\u00admated again to level m is \nequal to P approximated to min(n, m): approx. approx= approxmin(n,m) (15) nm Proof: directly from the \nde.nition of approxn in equation (11). Fourth, if a knot of level n is .rst unsquashed and then resquashed \nto a different level m, the predicates in the result have been approximated to level min(m, n): unsquash \nk =(n, F ) . unsquash(squash (m, F )) = (m, F ') . (16) F ' = fmap approxmin(n,m) F Proof: follows directly \nfrom equations (14), (13), (5), and (15). Implementation. In \u00a78 we give a model to prove the soundness \nof indirection theory. We have implemented the soundness proof as a module in Coq matching the Input \nand Output signatures; as Appendix A shows, the axiomatization is remarkably concise. Both signatures \nare matched opaquely, guaranteeing clean modularity. Trustworthiness. In \u00a72.8 we explained that both \nof the examples from \u00a72.1 and \u00a72.7 have been established using machine-checked indirection theory i.e., \nusing the interface given in Appendix A. Since the proofs are machine checked in Coq, we have a high \ndegree of con.dence that they do not have mistakes. But perhaps the proofs, while correct, are proofs \nof the wrong theorems! How do we know that the approximations we get with indirection theory are powerful \nenough to prove nontrivial proper\u00adties? Could the axioms presented above admit a one-point model? We \naddress this question in several parts by examining our type soundness proof of the polymorphic .-calculus \nwith references. First, we took great care that the de.nition of safety is entirely standard: for any \nreachable state, the machine can take another step or it has reached a value. That is, the de.nition \nof safety does not refer to approximation or indirection theory. Since we de.ne safety in the standard \nway, at the end of the day we know that we have proved something whose meaning is well-understood. Second, \nour typing rules (proved as lemmas from our typing de.nitions, including those given in \u00a74.1) are entirely \nstandard. It is simple to use the typing rules to type a wide variety of expressions, including expressions \nthat manipulate the heap in interesting ways, run forever, and so forth. Thus we know that our semantic \ntypes are powerful enough to use with meaningful programs. The combination of these two points mean that \nthe axioms preclude a one-point model: if our typing judgment were always true, then we would have a \nmechanical proof that the polymorphic .-calculus with references never gets stuck, a contradiction; on \nthe other hand, if our typing judgment were always false then we would not be able to prove the standard \ntyping rules of the calculus and/or would be unable to apply our typing rules to any programs. Finally, \nas mentioned earlier, in \u00a78 we will present a construc\u00adtion, which the reader can examine to determine \nif it is reason\u00adable (for example, that it has more than one point). Since in \u00a79 we present a proof that \nall models of the axioms are isomorphic, it is quite reasonable to think about the axioms and the construction \nwe present as two sides of the same coin. Just as in the polymorphic .-calculus with references example, \nin the soundness proof for concurrent separation logic for Concur\u00adrent C minor (which uses indirection \ntheory), the .nal result is es\u00adtablished on a concurrent machine with reasonable semantics (al\u00adthough \nwe assume sequential consistency) [Hob08, Ch. 5]; we also establish a usable set of Hoare rules for proving \npartial correctness of concurrent programs, and apply them to examples. The combina\u00adtion guarantees that \nwe have demonstrated something meaningful. Indirection theory is a reformulation of previous step-indexed \ntechniques. Step-indexed models have also been extensively used in mechanical type soundness proofs for \ngeneral references in von Neumann machines as covered in \u00a72.2. In particular, the FPCC project [AAR+09] \nused a step-indexed model to prove the safety of the output of the SPARC code emitted by a Standard ML \ncompiler. 4. Using indirection theory Indirection theory constructs models that support a number of powerful \nbut historically dif.cult to model features. Many of these features, such as impredicative quanti.cation \nand equirecur\u00adsive predicates, do not depend on the structure of F (X); in \u00a76 we will give models for \nthese kinds of features. Here we examine mod\u00adeling features that do depend on the structure of F (X), \nfocusing on two of the examples presented previously in \u00a72. Applying these ideas to other F (X) is usually \nnot dif.cult. 4.1 General references in the .-Calculus We return to the example of modeling a type system \nwith general references in the polymorphic .-calculus from \u00a72.1. Set F (X) = address -X O = value, and \nindirection theory constructs the model value = loc of address + num of N + ... type = (memtype \u00d7 value) \n. T memtype -N\u00d7 (address -type). Recall that X -Y implies the existence of the squash/unsquash section-retraction \npair. Substituting F (X) into equations (8) and (9) demonstrates that in this model squash/unsquash have \nthe types squash :(N\u00d7 (address -type)) . memtype unsquash : memtype . (N\u00d7 (address -type)). Thus squash \nand unsquash provide easy access to the model. The semantics of the typing judgment k f v : t , pronounced \nin the context of memory typing k, value v has type t, is t (k, v). It is simple to use this model to \nde.ne both the basic type nat as well as the historically dif.cult to model type ref t . A value v has \ntype nat if the value is a num(n) for some n: nat = .(k, v). .n. v = num(n). (17) This is natural, and \nthe de.nition of ref t is only slightly harder. The intuition is that a value v has type ref t if the \nvalue is an address a and according to the memory typing ., the memory cell at location a has type t. \nThat is, ? ref t = .(k, v). let (n, .)= unsquash k in (18) .a. v = loc(a) . .(a)= t.  The only problem \nis that since .(a) has been extracted from a knot k of level n, by equation (14) we know that .(a) has \nbeen approximated to level n that is, .(a)= approxn .(a). Comparing .(a) to t, which may not have been \napproximated, is too strong. Instead we introduce the idea of approximate equality: P = n Q = approxn \nP = approxn Q. (19) That is, two predicates (type in this model) are approximately equal at level n if \nthey are equal on all knots of level less than n. With approximate equality it is easy to .x equation \n18: ref t = .(k, v). let (n, .)= unsquash k in (20) .a. v = loc(a) . .(a)=n t This de.nition for ref \nt is correct and can type general references in the polymorphic .-calculus.3 We will return to this example \nin \u00a75.1 to show how a memory and a memory typing are related; we also refer readers interested in more \ndetails to the mechanization.  4.2 Concurrent separation logic with .rst-class locks Our second example \nis modeling the assertions of a Concurrent Separation Logic with .rst-class locks from \u00a72.6. We set F \n(X) = address-(VAL of value +LK of (share \u00d7bool\u00d7X)) O = locals, and indirection theory constructs the \nmodel res = VAL of value + LK of (share \u00d7 bool \u00d7 pred) pred = (heap \u00d7 locals) . T heap -N\u00d7 (address -res). \nRecall that a share p tracks how much of a lock is owned since multiple threads can each own part of \nthe same lock. Here we will p de.ne the assertions points-to a . v and is-a-lock a . P . The points-to \nassertion is standard; is-a-lock has a share p that indicates how much of the lock is controlled and \na predicate P that is the lock s resource invariant. Both of these assertions depend on the structure \nof F (X). In \u00a77 we will show how to de.ne the separating conjunction and the rest of separation logic \napplicable to any F(X) that forms a separation algebra. The intuition for points-to is that if a points \nto v (a . v), then the heaplet f contains VAL(v) at location a and nothing else: a . v = .(k, .). let \n(n, f)= unsquash k in f(a)= VAL(v) . domain(f)= {a}. (21) De.ning the is-a-lock assertion is equally \nstraightforward if one uses the notion of approximate equality given in equation (19): p a . P = .(k, \n.). let (n, f)= unsquash k in '' ' .P,b. f(a)= LK(p, b, P ) . domain(f)= {a}. P = n P. (22) That is, \nlocation a is a lock with share p and resource invariant P if the resource map f contains a LK(p, b, \nP ' ) for some boolean b and predicate P ' at location a, f is empty everywhere else, and P is approximately \nequal to P '. We do not restrict b because is-a-lock gives permission to (attempt to) lock the lock, \nbut not to read the lock value. This de.nition is suf.cient to model .rst-class locks. 5. Aging the knot \nWe return to the example of general references in the polymorphic .-calculus from \u00a72.1 and \u00a74.1 to demonstrate \nsome aspects of using indirection theory. All of the de.nitions we give here except 3 A reader may worry \nthat it would be easy to write the incorrect de.nition (18) by mistake. However, in \u00a75.3 we will de.ne \na restricted class of hereditary predicates (types) which reject (18) but allow (20). (23), (25) (28), \nand (32) are parametric over F (X) and therefore applicable to any domain. It is usually not dif.cult \nto modify the domain-speci.c de.nitions to other F (X). As in section 4.1, we outline the major aspects \nof using indirec\u00adtion theory, but do not cover the type soundness proof for the poly\u00admorphic .-calculus \nwith references in exhaustive detail here. We encourage readers interested in the nuts and bolts of a \nfull sound\u00adness proof to examine the mechanization. 5.1 A multimodal logic One remaining question is \nhow a memory typing is related to a memory (function from address . value). The intuition is that the \nmemory typing k is a valid typing of the memory m (written k f m valid) if all the values in m have the \ntype given by k:4 k f m valid = ? let (n, .)= unsquash k in (23) .a. k f m(a): .(a). Unfortunately, this \nde.nition is not quite right. The .rst problem is that as the .-calculus with references steps it allows \nnew memory cells to be allocated, such as during the execution of the expression new e. To type the new \nlocation, the memory typing must grow as well. But how do we know that our old locations are still well-typed \nunder the new memory typing? There are several choices; here we follow the multimodal pattern of Dockins \net al. [DAH08]. A world w is a pair of knot k and other data o. Given a relation R : world . world, de.ne \nthe modal operator DR as usual:5 DR t = .w. .w ' . wRw ' . t (w ' ). (24) We call this setting multimodal \nbecause we allow several different relations R, depending on which part of the world we want to reason \nabout. Our next task is thus to de.ne a relation that will let us reason about the extension of the memory \ntyping. De.ne the relation E (for Extends) as follows: (k, o)E(k ' ,o) = let (n, .)= unsquash k in let \n(n ' ,. ' )= unsquash k ' in (25) n = n ' . .a. a . dom(.) . . ' (a)= .(a). That is, (k, o)E(k ' ,o \n' ) if k has the same level as k and k ' agrees with k everywhere in the domain of k, and is otherwise \nunre\u00adstricted; we also require o = o '. Note that E is re.exive and transi\u00adtive. Now de.ne the modal \noperator . , pronounced extendedly , as follows: .t = DE t. (26) Thus, k f v : . t means that k ' f v \n: t for any k ' that is an extension of k. With this operator, we can change (23) into: k f m valid = \n? let (n, .)= unsquash k in (27) .a. k f m(a): ..(a). Since the issue of types being stable under the \nextension of the memory typing is orthogonal to the action of approximation, we will not comment further \non this issue and instead refer readers interested in this aspect to the mechanization.  5.2 Applying \nan extracted predicate to its knot There is a problem with (27) as well. Notice that . .(a) is being \napplied to k the very same knot from which . was extracted. 4 Recall that the typing judgment k f v : \nt is modeled as t(k, v). 5 Until this point, we have not required any special structure for Tother than \nthe existence of a distinguished element .. To simplify the presentation, from now on we will assume \nthat T = Prop, the propositions of the metalogic, and that . is the proposition False. One could choose \nsome other T, e.g. any complete Heyting algebra.  Corollary (14) implies .(a) has been approximated \nto level n: .(a)= approxn .(a) Thus, in (27), k f m(a): ..(a) is always k f m(a): .., which in turn is \njust k f m(a): .. This is exactly where we weaken the pseudomodels to achieve a sound de.nition: predicates \ncannot say anything meaningful about the knot whence they came. We must weaken (27) so that k is valid \nif the types in it describe the memory after k has been approximated further: k f m valid = let (n, .)= \nunsquash k in '' ' (28) .a,n .n > n . squash (n ,.) f m(a): ..(a) By equation (16), squash (n ' ,.) is \nthe same as k except the predicates inside it have been further approximated to level n ' . We call the \nprocess of unsquashing a knot and then resquashing it to a lower level, causing it to become more approximate, \naging the knot. Since we must do so whenever we wish to use a predicate that we pull out of a knot, we \nhave developed some useful auxiliary de.nitions. The age1 function reduces the level of a knot by .rst \nunsquashing and then resquashing at one level lower, if possible: ( Some (squash (n, x)) unsquash k =(n+1,x) \nage1 k =(29) None unsquash k = (0,x). The relation A relates k to its aged version and holds o constant: \n(k, o) A (k ' ,o) = age1 k = Some k ' . (30) Note that A is noetherian (i.e., the world can only be aged \na .nite number of times) because the level of k ' is always decreasing towards 0. Let A+ denote the irre.exive \ntransitive closure of A.6 Now de.ne an operator C from predicate to predicate: Ct = DA+ t. (31) Pronounced \napproximately P , CP (w) means that P holds on all strictly more approximate worlds reachable from w \nvia A+ . We can use the C operator to rephrase equation (28): k f m valid = let (n, .)= unsquash k in \n(32) .a. k f m(a): C ..(a). Equation (32) is pleasing because it is quite close in form to the intuitive \nbut .awed (27), with the added bene.t of being correct.7 The key to de.ning the correct (32) instead \nof the .awed (27) is to remember a simple rule: to apply a predicate P to the knot from which it was \nextracted, one must guard P with the C operator.  5.3 Hereditary predicates Let A * denote the re.exive, \ntransitive closure of A, and de.ne the modal operator D as follows: Dt = DA * t. Let P be a predicate \nand w be a world such that P (w). Suppose we have a (possibly) more approximate world w ' (i.e., wA * \nw '). We say that P is hereditary if P (w ' ) that is, once P holds on w then it will hold on all further \napproximations of w: .w. P (w) . DP (w). (33) Now observe that since A * is re.exive, we always have \n.w. DP (w) . P (w). 6 Here we follow the strategy of Appel et al. [AMRV07]; what is new is that we have \nexplicitly built A+ from the operations of indirection theory. 7 The . and . operators commute, so the \nlast line of (32) could just as easily have been written .a. k f m(a): . ..(a). For comparison with Appel \net al. [AMRV07], their . is the same as our .. ; we have found it easier to reason about these actions \nseparately [DAH08]. Thus we can rephrase (33) very concisely P is hereditary iff P = DP. (34) Are all \npredicates hereditary? Unfortunately not: for example, the .awed initial de.nition for ref t (18) is \nnot. However, it is easy to de.ne new hereditary predicates using the logical operators de.ned in \u00a76. \nMoreover, the correct de.nitions for references (20), points-to (21) and is-a-lock (22) are all hereditary. \nIn addition, applying the C operator makes a predicate hereditary since CP = D C P. (35) Thus, types \npulled out of a valid memory typing (32) are hereditary.  5.4 Finite-step proofs and initial knot construction \nIn soundness proofs that utilize indirection theory, we usually have some knot k, for example modeling \nthe memory typing or a re\u00adsource map. One must age this knot whenever the proof needs to pull a pred \nP out of k, since the application P (k, o) will always be .. For our polymorphic .-calculus with mutable \nreferences, we need to age at least on memory access, although in the proofs we choose to age on every \nstep to make the action uniform. For our Concurrent Separation Logic with .rst class locks and threads, \nwe age at function-call, lock-acquire/release, and fork. Since our knots have only a .nite level, we \ncan age only a .nite number of times. Therefore, once we have our initial knot, our safety proof is only \ngood for a number of steps equal to the level of that initial knot. Fortunately, constructing an initial \nknot of arbitrary level is easy. For example, let us construct a knot (i.e., memory typing) of level \nn for the .-calculus with references. To make it more interesting, suppose the initial memory typing \nshould have nat (equation 17) at location 0 and ref nat (equa\u00adtion 20) at location 1. If . is this partial \nfunction, then kinit is: kinit = squash(n, .). One strength of indirection theory is that the construction \nof the initial knot is much simpler than in previous step-indexed models. Our proofs are good for any \nnumber of steps since it is possible to construct an initial knot of any level. 6. Modal/intuitionistic \nlogic We can use the theory of indirection to construct a possible-worlds model of a modal logic in the \nstyle of Appel et al. s Very Modal Model (VMM) [AMRV07]. In fact, we do better: the VMM is almost a Kripke \nsemantics of intuitionistic logic, but lacks the important condition that all the proposition symbols \nare hereditary. To .x this problem, we construct the Kripke model for (proposi\u00adtional) intuitionistic \nlogic, explicitly maintaining the invariant that predicates are hereditary. Let predH be the subset of \nthe predicates that are hereditary. We build a Kripke semantics for our logic in the standard way, with \nW = K\u00d7O, and forcing |=: (W\u00d7predH ) . T is just reversed function application. Then we have: w |= true \n=T w |= false =. w |= p . q = w |= p . w |= q w |= p . q = w |= p . w |= q ''' ' w |= p . q =.w.wA * \nw . (w |= p) . (w |= q) w |= .x : A. P (x) =.x : A. w |= P (x) w |= .x : A. P (x) =.x : A. w |= P (x), \nwhere the left-hand ., ., ., ., . are the synthesized operators of our logic, and the right-hand ., ., \n., ., . are operators of the metalogic. It is straightforward to verify that these de.nitions are hereditary. \nNote that we directly lift . and . from the metalogic,  which extends the logic into a higher-order \nlogic. The metavariable its associated fmap function preserves the property of being a join A is any \ntype of the metalogic (e.g., A:Type in Coq), so the homomorphism. If f is a join homomorphism, then so \nis fmapf. quanti.cation is fully impredicative: A = predH works just .ne. Let (A, B A .) and (B, .) be \nSAs. We say that a function f : A . These de.nitions form the standard Kripke model of intuition- B is \na join homomorphism iff, for all x, y, z . A istic logic, to which we add the modal operators C and D. \nIn com\u00adparison to the VMM, the D operator is now less important, as all of our logical operators produce \nhereditary formulae from heredi- B A x . y = z . f(x) . f(y)= f(z). (42) tary subformulae; in contrast, \nthe VMM s implication operator did We equip the naturals Nwith the trivial join relation, i N . j = k \nnot do so. However D is still useful for coercing an arbitrary pred iff i = j = k. We require that T \nbe equipped with some join (which might not be hereditary) into a predH . We de.ne recursive predicates \nover contractive operators in the style of the VMM [AMRV07]. We support full equirecursion and so do \nnot require dummy operational steps to pack and unpack recursive data. This gives us the power to reason \nabout traditionally T relation, and that . be an identity for that relation: ... = .. We also require \nthat the type O of other data be equipped with a join relation; if there is no interesting separation \nto be done on O, then the trivial join relation will suf.ce. Now we build an SA on unsquashed knots. \nWe start by build\u00addif.cult low-level constructs such as compiled function closures. 7. Separation logic \n ing the SA over K\u00d7O . Tby de.ning the join relation pointwise: T p . q = r i. .k o.p (k, o) . q (k, \no)= r (k, o). (43) Indirection theory, like previous models of impredicative indirec\u00adtion, is used to \nreason about higher-order invariants on the con\u00adtents of state, e.g., mutable references, locks, objects, \nor function pointers. On the other hand, Separation Logic is useful for reason\u00ading about the aliasing \nand noninterference of these resources. One wants to use both kinds of reasoning simultaneously. Separation \nLogic combines much more smoothly with indirection theory than with previous models. We proceed by extending \nthe Kripke semantics of \u00a76 to encom\u00adpass the the connectives of the logic of Bunched Implications (BI). \nOur Kripke semantics is similar but not identical to those of Pym [Pym02, Chapter 4] and Restall [Res00, \nChapter 11]. We take inspiration from Calcagno et al. [COY07], who de.ne structures they call separation \nalgebras (SA), which they use as se\u00admantic models of separation logic. The main idea is that SAs de.ne \na partial operation . which combines two disjoint resources. The operation . is used to give semantics \nto the separating conjunction. A separation algebra (SA) is a tuple (A, .) where A is a set (or Type) \nand . = is a ternary relation on A satisfying: x . y = z1 . x . y = z2 . z1 = z2 (36) x1 . y = z . x2 \n. y = z . x1 = x2 (37) x . y = z . y . x = z (38) x . y = a . a . z = b . (39) .c. y . z = c . x . c \n= b .x. .u. u . x = x (40) a . a = b . a = b (41) Note that we do not need an SA over K for this de.nition. \nNext, we get an SA on F (K \u00d7 O . T) because we required F to be a functor over SAs. Finally, we get an \nSA over N\u00d7 F (K \u00d7 O . T) by joining componentwise (with the trivial SA on N). Verifying the SA axioms \nfor these constructions is straightforward [DHA09]. The SA on knots is de.ned by simply stating: k1.k2 \n= k3 . unsquash k1.unsquash k2 = unsquash k3. (44) The SA axioms for this construction follow from the \nfact that squash . unsquash is the identity function (one of the axioms of indirection theory) and the \nfact that unsquash . squash is a join homomorphism. This follows because F preserves join homomor\u00adphisms \nand because approxn is a join homomorphism, which we deduce from its de.nition and the fact that . is \nan identity element. Thus we see that the separation algebra on knots is determined by the SA structure \nembedded in the functor F , which allows the user to specify the interesting part of the SA as input. \nAn example. Consider the model for .rst-class locks from \u00a72.6: F (X) = address-(VAL of value + LK of \n(share \u00d7bool \u00d7X)) O = locals. Given an SA over X, we want to de.ne an SA over F (X). The intuition here \nis that we want the partial functions to join pointwise such that unde.ned locations join with any de.ned \nlocation, value locations join only with unde.ned locations, and lock locations join provided that at \nmost one thread holds the lock at a time. Formally, we add an extra (pseudo)element u to the right-hand \nside of -to represent unowned locations. Assume we have a join relation on shares (see [DHA09]). De.ne \nan SA on booleans: B This de.nition of separation algebras is somewhat different from Calcagno et al. \ns. First, our de.nition uses ternary relations rather than partial binary operations. Second, Calcagno \net al. present a more restrictive version of axiom (40): .u. .x. u . x = x. Their axiom requires that \nan SA have a unique unit, while axiom (40) allows different elements of an SA to have different units. \nThis permits knots to be considered as SAs; each strati.cation level will have its own unit. Third, Calcagno \net al. lack axiom (41); this axiom is useful and well-justi.ed, but is unrelated to indirection theory. \nWe refer the reader to our paper on separation algebras for further discussion of the advantages of our \nde.nition [DHA09]. b1 . b2 = b3 i. (b1 &#38;&#38; b2 = F) . (b1 || b2 = b3). The join relation of the \nRHS is the smallest relation such that: u . a = a (a) a . u = a (b) X B S s1 . s2 = s3 . b1 . b2 = b3 \n. x1 . x2 = x3 (c) . LK (s1,b1,x1) . LK (s2,b2,x2)= LK (s3,b3,x3). In equation (c), the si are required \nto be nonunit shares. Finally we de.ne the SA over heaplets pointwise on the address: A bunched-implication \nindirection model. In \u00a73, we presented an input signature for indirection theory; one of the elements \nof this signature is a covariant functor F (X) in the category of types with total functions. Here we \ninstead require that F be a functor in the category of separation algebras with join homomorphisms (de.ned \nbelow). This means that F is function between SAs and f . g = h i. .J.f(J) . g(J)= h(J) This model gives \nrise to an SA where heaplets must have dis\u00adjoint value domains, but where separated heaplets may each \nhave some share of a lock. The SA over shares keeps track of lock visibil\u00adity (the ability to compete \nto acquire the lock) whereas the boolean value keeps track of whether this thread holds the lock.  When \nde.ning an SA over O (the local variables), we can either choose to use a trivial SA, or we can choose \nto de.ne a similar pointwise SA. The second choice leads to a variables as resources [PBC06] style of \nseparation logic, whereas the former choice leads to a presentation where local variables are not separated. \nSAs for other models can be built by using various combinations of products, coproducts, and functions, \netc. See Dockins et al. for examples and explicit constructions of share models [DHA09]. Operators of \nseparation logic. Using the separation algebra over knots we are almost ready to state the Kripke semantics \nfor BI. The Kripke semantics is de.ned over pairs K \u00d7 O, so we lift the SA over K to pairs, componentwise. \nw |= emp = w . w = w w |= p * q =.w1 w2.w1 . w2 = w . w1 |= p . w2 |= q w |= p - * q =.w ' w1 w2.w A \n* w ' . w ' . w1 = w2 . w1 |= p . w2 |= q In order for these de.nitions to be valid, we must show that \nthey are hereditary. The fact that - * is hereditary follows immediately from the de.nition. In order \nto show that emp and * are hereditary, we require the following technical facts about knots: .k1 k2 k3 \nk1' .k1 . k2 = k3 . k1Ak ' . 1 (45) .k2 ' k3' .k1 ' . k2 ' = k3 ' . k2Ak2 ' . k3Ak3 ' .k1 k2 k3 k3' .k1 \n. k2 = k3 . k3Ak3 ' . (46) .k1 ' k2' .k1 ' . k2 ' = k3 ' . k1Ak1 ' . k2Ak2 ' These facts follow easily \nfrom the de.nition of the SA over knots, the de.nition of A, and the fact that approxn is a join homo\u00admorphism. \nHereditarity for emp and * then follows by induction on the transitivity of A *, using (45) and (46) \nin the base cases. It is relatively easy to show that these de.nitions, together with the de.nitions \nfrom \u00a76, form a model of the logic of Bunched Implications. This is most easily done by proving that \nthe model satis.es the axioms of a Hilbert system of BI [Pym02, Table 3.1]. 8. Model construction Here \nwe construct a model for the axioms in \u00a73. Indirection theory is built in the Calculus of Inductive Constructions \n(CiC) with the axiom of functional extensionality.8 Our model uses a step-indexing technique originally \ndeveloped by Ahmed et al. [AAV03], but we have made many improvements and simpli.cations. Indirection \ntheory is so compact that the de.nition, construc\u00adtion, and soundness proofs require only 400 lines to \nimplement in Coq. The construction is parameterized over F (X), making it directly applicable to all \nof the examples given in \u00a72. Moreover, the construction is more powerful than previous models; for exam\u00adple, \nas explained in \u00a72.6, indirection theory supports full inversion while the previous models of Hobor et \nal. do not [HAZ08, Hob08]. Use of dependent types. The proofs are tricky to mechanize due to the dependent \ntypes in the indexed-model construction. There are no dependent types in the axiomatization, so users \nof indirection theory are not burdened with them. This means that indirection theory can be used (although \nnot, we conjecture, proved sound) in metalogics without dependent types, such as the simple theory of \ntypes (HOL). This is a signi.cant strength of our approach. Presentation. We elide the handling of the \nother data O which appears in the axiomatization. Adding it presents no fundamental dif.culties, but \nit clutters the explanation. 8 We have also developed an axiom-free version by working in the category \nof setoids (whose objects are types equipped with an equivalence relation and whose morphisms are equivalence-preserving \nfunctions). The proofs are not much more dif.cult to carry out, just more dif.cult to state. 8.1 Tying \nthe knot. We wish to de.ne a type K that is similar to the pseudode.nition in equation (2), reproduced \nhere (without O): K F (K . T). We proceed by de.ning an approximation to pred called predn,a .nitely \nstrati.ed type constructor indexed by the natural n: ( unit n =0 predn = (47) prednl \u00d7 (F (prednl ) . \nT) n = n ' +1. For all n> 0, P : predn is a pair whose second component P.2 is an approximation to the \nrecursive pseudode.nition (2) and whose .rst component P.1 is a simpler approximation P ' : predn-1. \nA knot (K) hides the index with a dependent sum: K = S(n : N).F (predn). (48) That is, a knot is a dependent \npair of a natural n and an F with elements of predn inside. De.ne the level of a knot k as: |k| = k.1 \nthat is, |(n, f)| = n. (49) A knot s level gives how many layers of strati.cation it contains. Now we \ncan de.ne the type of predicates (pred): pred = K . T. (50) A pred is an in.nitely strati.ed predn that \ncan judge a knot containing any amount of strati.cation.  8.2 Strati.cation and unstrati.cation. We \nde.ne a function stratn : pred . predn that collapses an in.nitely strati.ed pred into a .nitely strati.ed \npredn: ( () n =0 stratn(P )= `\u00b4 (51) stratnl (P ), .f. P (n ' ,f) n = n ' +1. The stratn function constructs \nthe list structure of predn by recur\u00adsively applying P to knots of decreasing level. The .nitely strati.ed \ntype predn is not big enough to store the behavior of P on knots of level = n, and so that information \nis thrown away. The stratn function is a standard feature in step-indexing con\u00adstructions [AAV03, AMRV07, \nHob08]. A key innovation in our new construction is the de.nition of a partial inverse to stratn.9 First \nwe de.ne a .oor operator that given a P : predn+m con\u00adstructs a P ' : predn by stripping off the outer \nm approximations: ( Pm =0 LP Jm = l (52) n LP.1Jm m = m ' +1. n Now observe that for any a, b . N, b>a \n..m. b = a + m +1. (53) We now de.ne unstratn : predn . pred, which takes a .nitely strati.ed predn and \nconstructs an in.nitely strati.ed pred from it. We use (53) to take cases and apply (52) in a constructive \nway: ( (LP Jm |k|+1.2) k.2 n = |k|+m+1 unstratn(P )= .k. (54) . n =|k|. When given a knot of level <n, \nthe unstratn function uses the .oor operator to look up how to behave. When applied to a knot k of level \n= n, the unstratn function returns . since the predn P does not contain any way to judge k. 9 Although \nthe supporting proofs for VMM [AMRV07] contained a similar inverse, it was not explained in the paper \nand played only a supporting role. Here we show that unstrat is actually of central importance.  Below \nwe will need the following two technical facts. First, the .oor operation commutes with taking the .rst \nprojection: n+1.1= LP.1Jm (55) LP Jmn Proof of (55). By induction on m. Due to the dependent types, the \nstatement of this lemma and its proof are somewhat more complicated in the Coq development; nonetheless, \nthe overall proof idea is straightforward. The second technical lemma speci.es what happens when two \nsimilar .nitely strati.ed predicates are restrati.ed at a lower level. LP1Jm1 = LP2Jm2 . nn (56) (stratn. \nunstratn+m1 ) P1 =(stratn. unstratn+m2 ) P2 If P1 : predand P2 : predare two .nitely strati.ed n+m1 n+m2 \npredicates that are equal in their .rst n layers, then they are equal after they have gone through unstratn+j \nfollowed by stratn. Proof of (56). By induction on n. The base case is easy; the induc\u00adtive case follows \nby the induction hypothesis and (55).  8.3 Composing stratn and unstratn. What happens when we compose \nstratn and unstratn? We take this in two parts. First we wish to show: stratn. unstratn = idpredn (57) \nwhere ida is the identity function on type a (i.e., ida = .x : a. x). Proof of (57). By induction on \nn. In the base case, the claim fol\u00adlows because strat0f = () for all f and the unit type has a unique \nvalue. In the inductive case, where n = n ' +1, after unfolding stratnl+1 we must show (for arbitrary \nP and f): stratnl (unstratnl+1 P )= P.1 and unstratnl+1(P )(n ' ,f)= P.2 f. To demonstrate the .rst equation, \n.rst observe LP J1 l = LP.1J0 l nn so we may rewrite using (56) into stratnl (unstratnl (P.1)) and apply \nthe induction hypothesis. In the second equation, note that n ' +1= |(n ' ,f)| +0+1, which means that \nunstratn' ,f )=(LP J0 l+1.2) ((n ' ,f).2) = P.2 f. l+1(P )(n n This completes the .rst part. For unstratn \n. stratn, we cannot do as well since stratn for\u00adgets information that unstratn cannot recover. Give Ta \n.at partial order by de.ning as the minimal relation such that: x x re.exivity (58) . x pointedness (59) \nIt is clear that is antisymmetric. With we can state three cases: (unstratn. stratn) Pk Pk .|k| (60) \nPk (unstratn. stratn) Pk |k| <n (61) (unstratn. stratn) Pk . |k|= n (62) Proof of (60). By induction \non n. In the base case n =0 and unstrat0(P )= . for all P ; the claim follows from (59). In the inductive \ncase n = n ' +1. Consider the two subcases of the de.nition of unstrat. When n =|k|, unstratn(P )= . \nfor all P , and we are done, again by (59). In the case where n = |k|+ m +1, we proceed by subcases on \nthe value of m. If m =0, then observe that n ' = |k|, and we have: unstratnl+1(stratnl+1 P ) k =(Lstratnl+1 \nP J|0 k|+1.2(k.2) =(stratnl+1 P ).2(k.2) = P (n ' , k.2) = P (|k|, k.2) = P k. Then the claim follows \nby (58). In the case that m = m ' +1, then: unstratnl+1(stratnl+1 P ) k l+1 =(Lstratn|k|+1 .2) (k.2) \nl+1 P Jm l =(L(stratn|k|+1.2) (k.2) l+1 P ).1Jm l l P Jm =(Lstratn|k|+1.2) (k.2) =(unstratnl (stratnl \n(P )) k The .nal line follows n ' = |k| + m ' +1, which allows us to fold unstratnl . Now we apply the \ninduction hypothesis. Proof of (61). By induction on n. In the base case n =0, and |k| < 0 yields a contradiction. \nIn the inductive case, we have n = n ' +1. Since |k| <n, we must have n = |k| + m +1 for some m. As before, \nwe inspect the value of m. if m =0, the claim follows by (58) and calculation identical to the preceding. \nIf m = m ' +1 then we again perform similar calculation as above and apply the induction hypothesis. \nWe must only verify that |k| <n ' , which follows because n ' = |k| + m ' +1. Proof of (62). Immediate \nfrom the de.nition of unstrat. Since is pointed and antisymmetric, (60), (61), and (62) imply: ( Pk |k| \n<n (unstratn. stratn) Pk = (63) .|k|= n.  8.4 Squashing and unsquashing. De.ne squash and unsquash to \nfmap stratn and unstratn: squash(n, f) = (n, fmap stratn f) (64) unsquash(k) = (|k|, fmap unstrat|k| \nk.2). (65) Recall from \u00a73 the de.nitions of level and approx(without O): n level = fst . unsquash (66) \n( Pk level k<n approxn Pk = (67) . level k = n. It follows immediately from (64) and (66) that level \nk = |k|. Applying this equality to (63) and (67) shows: approxn = unstratn . stratn. (68) We now prove \nthe two axioms of indirection theory. Proof of (12): squash (unsquash k) = squash (|k|, fmap unstrat|k| \nk.2) (65) =(|k|, fmap strat|k| (fmap unstrat|k| k.2)) (64) =(|k|, fmap (strat|k| . unstrat|k|) k.2)) \n(5) =(|k|, fmap idpred|k| k.2) (57) =(|k|, idF (pred|k|) k.2) (4) = k (49)  The second axiom (13) follows \nin a similar way: unsquash (squash (n, f)) = unsquash (n, fmap stratn f) (64) = (n, fmap unstratn (fmap \nstratn f)) (65) = (n, fmap (unstratn . stratn) f)) (5) = (n, fmap approxn f) (68) This completes the \nconstruction. 9. Uniqueness of the model One remarkable property of the axiomatization given in \u00a73 is \nthat it is categorical: the axioms determine the model uniquely up to isomorphism. We prove this by constructing \na bijection between any two models and prove that the bijection preserves the squash and unsquash operations. \nFor simplicity, we will elide the type O. Input. We assume that we have a single input (F , fmap). We \nthen take two (possibly different) constructions A and B. To distinguish the functions and properties \nde.ned on one construction from the other, we will write, e.g., squashA or squashB . Informal goal and \ncore proof idea. Our goal is to construct an isomorphism f : KA . KB . At .rst this seems quite easy: \nf = ? squashB . unsquashA. (69) That is, take a kA : KA, unsquash it to get to a common form (of type \nN\u00d7 F (pred)), and then squash it into an element of type KB . Unfortunately, this approach does not work \nsince unsquashA pro\u00adduces an element of type N\u00d7 F (predA), while squashB requires an element of type \nN \u00d7 F (predB ). We cannot assume that predA is compatible with predB without begging the question, so \n(69) is invalid. Part of what makes the problem tricky is that the types are isomorphic but need not \nbe equal, so we must build up signi.cant machinery to coerce the types from one construction to the other. \nFormal goal. We want a pair of functions f : KA . KB and g : KB . KA. These functions will be inverses: \nf . g = idKB (70) g . f = idKA . (71) Thus, f and g are bijective. To be isomorphisms they must also \nbe homomorphisms (preserve squash and unsquash); for this we introduce two derived functions, F: F (predA) \n. F (predB): F = fmap (.PB .PB . g), (72) and G: F (predB) . F (predA): G = fmap (.PA.PA . f). (73) Since \nf and g are inverses, and fmap distributes over function composition (equation 5), F and G are inverses \nas well: F . G= idF (predB) (74) G . F= idF (predA). (75) We can now state that f and g are homomorphisms \nas follows: f(squashA(n, .A)) = squashB(n, F(.A)) (76) g(squashB(n, .B )) = squashA(n, G(.B )) (77) unsquashB(f(kA)) \n= (n, F(.A)) (78) where (n, .A)= unsquashA(kA) unsquashA(g(kB )) = (n, G(.B)) (79) where (n, .B )= unsquashB \n(kB). This will complete the proof that A and B are isomorphic. Proof sketch. The formal details of the \nproof are quite technical; here we give an informal outline. We have implemented our proof in Coq and \nrefer readers seeking more detail to the mechanization. We construct f and g from a sequence of approximations \n(f0,g0),. . . ,(fm,gm),. . . . A pair of functions (fi,gi) are inverses and homomorphisms on knots of \nlevel = i. First we construct f0 and g0. By equation (14), all of the pred\u00adicates inside knots of level \n0 are approximated to level 0 that is, they are all constant functions returning .. We write .a to mean \nthe constant function from type a to . (i.e., .a = .a : a. .). The functions f0 and g0 simply swap .KA \nwith .KB and vice versa:10 f0(kA) = let (n, .A)= unsquashA kA in squashB (n, [PA ..KB ] .A) (80) g0(kB) \n= let (n, .B )= unsquashB kB in squashA(n, [PB ..KA ] .B). (81) Lemma. (f0,g0) is an isomorphism pair \non knots of level 0. Next, given (fi,gi) we wish to construct the next pair in the series (fi+1,gi+1). \nThe trick is that due to the contravariance of pred, fi+1 is built from gi, and gi+1 is built from fi: \nf (.)(kA) = let (n, .A)= unsquashA kA in squashB (n, [PA . PA . .] .A) (82) g (f)(kB ) = let (n, .B)= \nunsquashB kB in squashA(n, [PB . PB . f] .B ). (83) Lemma. If (f, g) is isomorphism pair for knots of \nlevel = i, then (f (g),g (f)) is an isomorphism pair for knots of level = i +1. Now de.ne the function \nh that takes n and produces (fn,gn): ( (f0,g0) n =0 h(n) = (84) ''''' ' let (f ,g )= h(n ) in (f (g ),g \n(f )) n = n +1. The h function works by bouncing back and forth; note that even\u00adnumbered fi have f0 as \ntheir base while odd-numbered fi have g0. The gi are mirrored: even gi use g0 for a base while odd gi \nuse f0. Now we are ready to de.ne f and g. The idea is that we will look at the knot k that we have been \ngiven and use the h function to construct an fi or gi of the appropriate level: `\u00b4 f(kA) = (fst . h . \nlevelA)(kA)(kA) (85) `\u00b4 g(kB) = (snd . h . levelB)(kB)(kB). (86) Theorem. (f ,g) is an isomorphic pair \nfor knots of any level. Implications. Categorical axiomatizations are suf.ciently un\u00adcommon that we examine \nthe implications. Most importantly, the axioms of indirection theory given in \u00a73 are in some sense com\u00adplete: \nthey de.ne a particular class of models in a de.nitive way. Moreover, there seems to be little point \nin developing alternatives to the construction we presented in \u00a78, at least in CiC. We view these facts \nas powerful evidence that our axioms are the correct way to characterize current step-indexing models. \n10. Extensions of indirection theory Although many problem domains of interest fall into the simple form \nof pseudoequation (2), some problem domains require pred\u00adicates to appear in negative positions (the \nleft side of arrows). For example, the recent result of Ahmed et al., which applies step\u00adindexing to \nreason about data abstraction [ADR09], requires such .exibility. We have de.ned, on paper and in Coq, \na straightforward 10 Keeping with our informal style, we will abuse notation by writing [Pa . X] . to \nmean the substitution of the predicates preda in . with X. Formally this is written fmap (.Pa.X) .. Note \nPa can appear in X.  extension to indirection theory that handles bifunctors, which allow equations \ncontaining mixed variance. In our axiomatization of indirection theory, nonhereditary pred\u00adicates can \npop out of the unsquash function. If we make sure to place D in front of any predicate taken from a knot, \nwe avoid this problem; but it is not clear that this approach extends to the bifunc\u00adtor case. Instead, \nwe can do something even more powerful: we have an alternate axiomatization that guarantees that all \npredicates in knots are hereditary. We have a model proved in Coq (and on pa\u00adper), but unfortunately \nit is not as straightforward to construct. We hypothesize that this model could be used to mechanize \nthe recent result of Dreyer et al. [DNRB10]. 11. Limitations of indirection theory Indirection theory \nis a powerful technique for those problems to which it applies, but it is worthwhile to examine some \nlimitations. First, indirection theory only builds solutions for the particular class of recursive domain \nequations given by pseudoequation (2). Although, as seen in \u00a72, the form of this pseudoequation was carefully \nchosen to cover many problem domains of interest, it is manifestly not applicable to equations of other \nforms (although in \u00a710 we cover some possible extensions). Second, our insistence on remaining in the \nsimple category of sets (or types) means that any solution we build must necessarily involve approximation; \nas we previously noted, a simple cardinality argument shows that we cannot obtain isomorphism solutions. \nWe have found this cost to be quite manageable, especially when man\u00adaged using the framework of the Very \nModal Model [AMRV07]. Finally, step-indexing techniques have thus far been applied only to questions \nof safety, partial correctness, and program equiv\u00adalence. It is unclear how, or if, step indexing approaches \ncan be applied to questions of liveness and total correctness. 12. Related work Syntactic methods. There \nis a long history of using syntactic methods to handle indirection. Early papers on Hoare logic used \nsyntactic representations of program text to reason about function calls [CO78]. Syntactic accounts of \ngeneral references have been studied by Harper [Har94], Harper and Stone [HS97], Wright and Felleisen \n[WF94], and others. Crary developed TALT, a typed as\u00adsembly language which had indirection due to both \ndata references and code pointers [Cra03]. De.ning Hoare-style logics using syntactic methods is a com\u00admon \nchoice [Sch97, Ohe01, Sch06]. However, even when the Hoare derivations are syntactic, it is nearly ubiquitous \nin mechan\u00adically veri.ed proofs for the assertion language to be purely se\u00admantic; that is, assertions \nare identi.ed with predicates on program states (perhaps together with other auxiliary data) [Nip02]. \nIn these applications, indirection helps solve problems of indirect reference, especially if one wishes \nto embed semantic assertions (or types) into program syntax or operational semantics. One could instead \nuse a fully syntactic approach, where asser\u00adtions are also treated as syntax. Using syntactic assertions \nremoves the need to solve tricky contravariant domain equations. Instead, one is left with the problem \nof adequately representing the syntax and semantics of the assertion logic, a nontrivial problem in its \nown right. A logic supporting higher-order quanti.cation is especially troublesome to handle in most \nmechanized proof systems. Domain theory. Domain theory is an alternate approach to cre\u00adating semantic \nmodels of programming languages [GHK+03]. Do\u00admain theory is primarily concerned with solving recursive \ndomain equations that describe the desired form of the model. Using do\u00admain theory, one can construct \nactual isomorphism solutions to equations such as pseudoequation (2). Indeed, one can construct models \nusing domain theory for applications where indirection the\u00adory does not appear well suited (e.g. denotational \nmodels of the untyped .-calculus). The price one pays is that the solution is con\u00adstructed in some category \nof domains rather than in simple sets. Working in higher categories is especially inconvenient in mechanized \nhigher-order logics. Simply building up the required theory takes quite a bit of effort. Many attempts \nhave been made to mechanize domain theory [Mil72, MNOS99, Age06], including a recent effort in Coq by \nBenton et al. [BKV09]. However, all these systems seem to stop short of developing a full suite of domain \ntheory. For example, we are aware of no mechanization which de\u00advelops as far as the theory of algebraic \nbounded-complete partial orders (i.e. Scott domains). Benton et al. have developed one of only very few \nmechanizations that includes an inverse-limit con\u00adstruction, allowing the solution of recursive domain \nequations. Fur\u00adthermore, once the required base theory is developed, the tedium of verifying the properties \nof structured morphisms (e.g, mono\u00adtonicity, continuity, etc.) can still be a major hurdle. Much of the \ndevelopment effort in HOLCF [MNOS99] was devoted to allevi\u00adating this pain, and Benton et al. claim that \ndealing with all the structural morphisms is still awkward in their system [BKV09]. Ultrametric Spaces. \nBirkedal et al. solve recursive domain equa\u00adtions using certain classes of ultrametric spaces [BST09]. \nTheir ap\u00adproach is similar in spirit to domain theory, where semantic do\u00admains are built in some higher \ncategory, but uses a foundation built on metric spaces rather than partially ordered sets. Given a suf.\u00adcient \nbasis of analysis and category theory, the metric space setup seems to afford a nice simpli.cation of \nsimilar domain-theoretic results. To our knowledge, no attempt has yet been made to mech\u00adanize this metric \nspace approach. BI Hyperdoctrines. BI hyperdoctrines are category-theoretic models of higher-order bunched \nimplications [BBTS07]. BI hy\u00adperdoctrines provide: higher-order logic, the standard BI connec\u00adtives, \nrecursive de.nitions, and impredicative quanti.cation. But the published BI-hyperdoctrine model does \nnot appear to support indirection, i.e. the kinds of settings in \u00a72. The techniques used for domain-theoretic \nmodels of indirection (e.g. Day s construction in functor categories [Lev02]) could perhaps be applied \nto BI hyper\u00addoctrines. Like the domain-theoretic methods, methods based on advanced category theory require \na great deal of background in the .eld to understand and utilize. Mechanizing models based on BI hyperdoctrines \nwould require considerable effort to build up the necessary base theory. Very Modal Model. Appel et al. \ns Very Modal Model (VMM) provides a way to simplify the handling of step-indexing models by building \na modal logic for reasoning about the indexes [AMRV07]. In our current paper we also simplify the application \nof step\u00adindexed models, so the techniques are super.cially similar. How\u00adever, although indirection theory \nwas designed to dovetail with the VMM, they are in fact orthogonal and either system can be used without \nthe other. After Appel et al., both Benton and Tabareau [BT09] and Ahmed et al. [ADR09] constructed modal \nmodels without indirection theory. Indeed, it is possible and useful to build a modal logic even when \nthe setting does not have the contravariant circularities that motivate the current work [BT09, DAB09]. \nMore\u00adover, although we build a modal logic on top of indirection theory in \u00a76, one can easily work directly \nwith the axioms. In addition, the logic constructed in \u00a76 is superior to the one from Appel et al. because \nit properly recognizes and handles the heredity condition. The na\u00a8ive interpretation of implication found \nthere does not preserve heredity. This leads to less elegant reason\u00ading because the operator D must be \ninserted in nonobvious places. Neither do Appel et al. show how to incorporate the substructural elements \nrequired for separation logic, which we do here.  Finally, the VMM suffers from the same .aw as other \nstep\u00adindexing models: the construction is hardcoded to a particular do\u00admain and is dif.cult to adapt \nto other settings. Indirection theory is simpler, more powerful, and applies to a wide variety of domains. \nConcurrent separation logic. Both Hobor et al. [HAZ08] and Gotsman et al. [GBC+07] developed formulations \nof a Concurrent Separation Logic with .rst-class locks and threads. Both presen\u00adtations use a semantic \nmodel of propositions; however, they take very different paths to handle the contravariant circularity \ninvolved in modeling lock invariants. Hobor et al. use a purely semantic method that grew out of the \nVMM, whereas Gotsman et al. use a syntactic rei.cation of the logic to handle the contravariance issue. \nThat is, Gotsman et al. associate each occurrence of a concurrent statement (e.g., lock, unlock, etc.) \nwith a static handle (a lock sort ) pointing into a lookup table of resource invariants. This technique \nis displeasing from a mathematical perspective: it is preferable to have a semantic model that is independent \nof syntax. Signi.cantly, the syntactic rei.cation weakens Gotsman et al. s model: for example, there \nis no polymorphism over lock sorts, so it is impossible to specify the simple function that takes an \narbitrary lock and locks it: Spec : .x,p,R. f : {x p R}{R * x p R} Body : f(x)=(lock x). Instead, Gotsman \net al. would have to create one version of this function for each lock sort and then somehow determine \nwhich one to call at a given program point. In contrast, indirection theory can handle this case easily \nwith impredicative quanti.cation over R. Finally, the models of Hobor et al. and Gotsman et al. are dif.\u00adcult \nto understand. Hobor subsequently made some improvements in mathematical modularity but the model was \nstill much more complex than the theory of indirection presented here [Hob08]. We hope that the formulation \nof indirection theory as a section\u00adretraction pair (squash-unsquash) makes life easier for the reader. \n13. Conclusion Indirection theory is a new approach to modeling impredicative in\u00addirection. It is immediately \napplicable to a wide variety of settings and has an extremely simple, categorical axiomatization. Indirec\u00adtion \ntheory embeds easily into type theory, and its axiomatization embeds easily into the simple theory of \ntypes (HOL). Finally, it is powerful: we have used indirection theory as the basis for a machine-checked \nsoundness proof for the Concurrent Separation Logic for Concurrent C minor described in \u00a72.7. Acknowledgments. \nWe would like to thank Amal Ahmed, Nick Benton, Matthew Parkinson, Andrew Pitts, Peter Sewell, Konrad \nSlind, and the anonymous referees for their helpful suggestions on earlier drafts of this paper. References \n[AAR+09] Amal Ahmed, Andrew W. Appel, Christopher D. Richards, Kedar N. Swadi, Gang Tan, and Daniel C. \nWang. Semantic foundations for typed assembly languages. ACM. Trans. on Programming Languages and Systems, \n2009. [AAV03] Amal Ahmed, Andrew W. Appel, and Roberto Virga. An indexed model of impredicative polymorphism \nand muta\u00adble references. http://www.cs.princeton.edu/ appel/papers/ impred.pdf, January 2003. [AB07] \nAndrew W. Appel and Sandrine Blazy. Separation logic for small-step C minor. In 20th Int l Conference \non Theorem Proving in Higher-Order Logics (TPHOLs), pages 5 21, 2007. [ADR09] Amal Ahmed, Derek Dreyer, \nand Andreas Rossberg. State\u00addependent representation independence. In POPL 09: Proc. 36th annual ACM \nSIGPLAN-SIGACT Symposium on Princi\u00adples of Programming Languages, pages 340 353, 2009. [AFM05] Amal Ahmed, \nMatthew Fluet, and Greg Morrisett. A step\u00adindexed model of substructural state. In ICFP 05: Proceed\u00adings \nof the tenth ACM SIGPLAN International Conference on Functional programming, pages 78 91, 2005. [Age06] \nSten Agerholm. Domain theory in HOL. In Higher Order Logic Theorem Proving and Its Applications, LNCS, \npages 295 309. Springer, 2006. [Ahm04] Amal J. Ahmed. Semantics of Types for Mutable State. PhD thesis, \nPrinceton University, Princeton, NJ, November 2004. Tech Report TR-713-04. [AMRV07] Andrew W. Appel, \nPaul-Andre Melli`es, Christopher D. Richards, and Jer ome Vouillon. A very modal model of a mod\u00adern, \nmajor, general type system. In Proc. 34th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages (POPL 07), pages 109 122, January 2007. [BBTS07] Bodil Biering, Lars Birkedal, and Noah Torp-Smith. \nBi\u00adhyperdoctrines, higher-order separation logic, and abstraction. ACM Trans. Program. Lang. Syst., 29(5):24, \n2007. [BKV09] Nick Benton, Andrew Kennedy, and Carsten Varming. Some domain theory and denotational semantics \nin coq. In Theo\u00adrem Proving in Hogher Order Logics, LNCS, pages 115 130. Springer, 2009. [BST09] Lars \nBirkedal, Kristian St\u00f8vring, and Jacob Thamsborg. The category-theoretic solution of recursive metric-space \nequa\u00adtions. Technical report, 2009. TR-2009-119. [BT09] Nick Benton and Nicolas Tabareau. Compiling functional \ntypes to relational speci.cations for low level imperative code. In TLDI 09: Proc. 4th international \nworkshop on Types in language design and implementation, pages 3 14, 2009. [CO78] Robert Cartwright and \nDerek Oppen. Unrestricted procedure calls in Hoare s logic. In POPL 78: Proceedings of the 5th ACM SIGACT-SIGPLAN \nsymposium on Principles of Pro\u00adgramming Languages, pages 131 140, 1978. [COY07] Cristiano Calcagno, Peter \nW. O Hearn, and Hongseok Yang. Local action and abstract separation logic. In LICS 07: Pro\u00adceedings of \nthe 22nd Annual IEEE Symposium on Logic in Computer Science, pages 366 378, 2007. [Cra03] Karl Crary. \nToward a foundational typed assembly language. In POPL 03: 30th ACM Symp. on Principles of Programming \nLanguages, pages 198 212, 2003. [DAB09] Derek Dreyer, Amal Ahmed, and Lars Birkedal. Logical step\u00adindexed \nlogical relations. In Proceedings 24th Annual IEEE Symposium on Logic in Computer Science (LICS 09), \n2009. [DAH08] Robert Dockins, Andrew W. Appel, and Aquinas Hobor. Multi\u00admodal separation logic for reasoning \nabout operational seman\u00adtics. In 24th Conference on the Mathematical Foundations of Programming Semantics, \npages 5 20. Springer ENTCS, 2008. [DHA09] Robert Dockins, Aquinas Hobor, and Andrew W. Appel. A fresh \nlook at separation algebras and share accounting. In The 7th Asian Symposium on Programming Languages \nand Systems. Springer ENTCS, 2009. To appear. [DNRB10] Derek Dreyer, Georg Neis, Andreas Rossberg, and \nLars Birkedal. A relational modal logic for higher-order stateful adts. In POPL 10: Proc. 37th annual \nACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, 2010. To appear. [GBC+07] Alexey \nGotsman, Josh Berdine, Byron Cook, Noam Rinetzky, and Mooly Sagiv. Local reasoning for storable locks \nand threads. In Proceedings 5th Asian Symposium on Programming Languages and Systems (APLAS 07), 2007. \n[GHK+03] G. Gierz, K. H. Hofmann, K. Kiemel, J. D. Lawson, M. Mis\u00adlove, and D. S. Scott. Continuous Lattices \nand Domains, vol\u00adume 93 of Encylopedia of Mathematics and its Applications. Cambridge University Press, \nCambridge, UK, 2003.  [Har94] Robert Harper. A simpli.ed account of polymorphic refer\u00adences. Information \nProcessing Letters, 51:201 206, 1994. [HAZ08] Aquinas Hobor, Andrew W. Appel, and Francesco Zappa Nardelli. \nOracle semantics for concurrent separation logic. In Proc. European Symp. on Programming (ESOP 2008) \n(LNCS 4960), pages 353 367. Springer, 2008. [Hob08] Aquinas Hobor. Oracle Semanatics. PhD thesis, Princeton \nUniversity, Princeton, NJ, November 2008. [HS97] Robert Harper and Chris Stone. A type-theoretic inter\u00adpretation \nof Standard ML. http://foxnet.cs.cmu.edu/papers/ rwh-interpret.ps, 1997. [HS08] C.at.alin Hrit\u00b8cu and \nJan Schwinghammer. A step-indexed se\u00admantics of imperative objects. International Workshop on Foundations \nof Object-Oriented Languages (FOOL 08), 2008. [Ler06] Xavier Leroy. Formal certi.cation of a compiler \nback-end, or: programming a compiler with a proof assistant. In POPL 06, pages 42 54, 2006. [Lev02] Paul \nBlain Levy. Possible world semantics for general stor\u00adage in call-by-value. In Computer Science Logic, \n16th Inter\u00adnational Workshop, CSL 2002, volume 2471 of LNCS, pages 232 246, Edinburgh, Scotland, UK, \nSeptember 2002. Springer. [Mil72] Robin Milner. Logic for computable functions: description of a machine \nimplementation. Technical report, Stanford, CA, USA, 1972. [MNOS99] Olaf M\u00a8uller, Tobias Nipkow, David \nvon Oheimb, and Oskar Slotosch. HOLCF = HOL + LCF. Journal of Functional Programming, 9:191 223, 1999. \n[Nip02] Tobias Nipkow. Hoare logics for recursive procedures and un\u00adbounded nondeterminism. In Computer \nScience Logic, volume 2471/2002 of LNCS, pages 155 182. Springer, 2002. [O H07] Peter W. O Hearn. Resources, \nconcurrency and local rea\u00adsoning. Theoretical Computer Science, 375(1):271 307, May 2007. [Ohe01] David \nvon Oheimb. Analyzing Java in Isabelle/HOL: Formal\u00adization, Type Safety and Hoare Logic. PhD thesis, \nTechnische Universit\u00a8unchen, 2001. at M\u00a8[PBC06] Matthew Parkinson, Richard Bornat, and Cristiano Calcagno. \nVariables as resource in Hoare logics. Proc. of 21st Annual IEEE Symp. on Logic in Computer Science, \n0:137 146, 2006. [Pym02] David J. Pym. The Semantics and Proof Theory of the Logic of Bunched Implications, \nvolume 26 of Applied Logic Series. Kluwer Academic Publishers, 2002. [Res00] Greg Restall. An Introduction \nto Substructural Logics. Rout\u00adledge, London, England, 2000. [Sch97] Thomas Schreiber. Auxiliary variables \nand recursive proce\u00addures. In TAPSOFT 97: Proceedings of the 7th Interna\u00adtional Joint Conference CAAP/FASE \non Theory and Practice of Software Development, pages 697 711, London, UK, 1997. Springer-Verlag. [Sch06] \nNorbert Schirmer. Veri.cation of Sequential Imperative Pro\u00adgrams in Isabelle/HOL. PhD thesis, Technische \nUniversit\u00a8at M\u00a8 unchen, 2006. [WF94] Andrew K. Wright and Matthias Felleisen. A syntactic ap\u00adproach to \ntype soundness. Information and Computation, 115(1):38 94, 1994. A. Axiomatization in Coq Module Type \nTY FUNCTOR. Parameter F : Type . Type. Parameter fmap : forall {AB}, (A . B) . FA . F B. Axiom fmap id \n: forall A : Type , fmap (@id A) = @id (F A). Axiom fmap comp : forall A B C (f:B . C) (g:A . B), compose \n(fmap f) (fmap g) = fmap (compose f g). Parameter T : Type. Parameter T bot : T. Parameter other : Type. \n End TY FUNCTOR. Module Type KNOT. Declare Module TF:TY FUNCTOR. Import TF. Parameter knot : Type. De.nition \npredicate := (knot * other) . T. Parameter squash : (nat * F predicate) . knot. Parameter unsquash : \nknot . (nat * F predicate). De.nition level (x:knot) : nat := fst (unsquash x). (*le gt decnm:forallnm:nat, \n{n <= m} + {n > m} *) De.nition approx (n:nat) (p:predicate) : predicate := fun w . if le gt dec n (level \n(fst w)) then T bot else p w. Axiom squash unsquash : forall x, squash (unsquash x) = x. Axiom unsquash \nsquash : forall n x', unsquash (squash (n,x')) = (n,fmap (approx n) x'). End KNOT. Module Knot (TF:TY \nFUNCTOR) : KNOT with Module TF:=TF.    \n\t\t\t", "proc_id": "1706299", "abstract": "<p>Building semantic models that account for various kinds of indirect reference has traditionally been a difficult problem. Indirect reference can appear in many guises, such as heap pointers, higher-order functions, object references, and shared-memory mutexes.</p> <p>We give a general method to construct models containing indirect reference by presenting a \"theory of indirection\". Our method can be applied in a wide variety of settings and uses only simple, elementary mathematics. In addition to various forms of indirect reference, the resulting models support powerful features such as impredicative quantification and equirecursion; moreover they are compatible with the kind of powerful substructural accounting required to model (higher-order) separation logic. In contrast to previous work, our model is easy to apply to new settings and has a simple axiomatization, which is complete in the sense that all models of it are isomorphic. Our proofs are machine-checked in Coq.</p>", "authors": [{"name": "Aquinas Hobor", "author_profile_id": "81388591155", "affiliation": "National University of Singapore, Singapore, Singapore", "person_id": "P1911062", "email_address": "", "orcid_id": ""}, {"name": "Robert Dockins", "author_profile_id": "81314493788", "affiliation": "Princeton University, Princeton, NJ, USA", "person_id": "P1911063", "email_address": "", "orcid_id": ""}, {"name": "Andrew W. Appel", "author_profile_id": "81100498630", "affiliation": "Princeton University, Princeton, NJ, USA", "person_id": "P1911064", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706322", "year": "2010", "article_id": "1706322", "conference": "POPL", "title": "A theory of indirection via approximation", "url": "http://dl.acm.org/citation.cfm?id=1706322"}