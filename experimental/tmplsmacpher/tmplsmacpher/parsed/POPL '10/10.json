{"article_publication_date": "01-17-2010", "fulltext": "\n Dependent Types from Counterexamples * Tachio Terauchi Tohoku University terauchi@ecei.tohoku.ac.jp \nAbstract Motivated by recent research in abstract model checking, we present a new approach to inferring \ndependent types. Unlike many of the existing approaches, our approach does not rely on program\u00admers to \nsupply the candidate (or the correct) types for the recursive functions and instead does counterexample-guided \nre.nement to automatically generate the set of candidate dependent types. The main idea is to extend \nthe classical .xed-point type inference rou\u00adtine to return a counterexample if the program is found untypable \nwith the current set of candidate types. Then, an interpolating the\u00adorem prover is used to validate the \ncounterexample as a real type error or generate additional candidate dependent types to refute the spurious \ncounterexample. The process is repeated until either a real type error is found or suf.cient candidates \nare generated to prove the program typable. Our system makes non-trivial use of linear intersection types \nin the re.nement phase. The paper presents the type inference system and reports on the experience with \na prototype implementation that infers dependent types for a subset of the Ocaml language. The implementation \ninfers dependent types containing predicates from the quanti.er\u00adfree theory of linear arithmetic and \nequality with uninterpreted function symbols. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: \nSoftware/Program Veri.cation Model checking; F.3.1 [Log\u00adics and Meaning of Programs]: Specifying and \nVerifying and Rea\u00adsoning about Programs Mechanical veri.cation; F.3.2 [Logics and Meaning of Programs]: \nSemantics of Programming Languages Program analysis; F.3.3 [Logics and Meaning of Programs]: Stud\u00adies \nof Program Constructs Type structure General Terms Algorithms, Languages, Theory, Veri.cation Keywords \nDependent types, Intersection types, Interpolation, Counterexamples, Type inference 1. Introduction \nThis paper follows the work on applying dependent types to check\u00ading complex properties of programs that \nare beyond the reach of conventional type systems like ML types. In this paper, by depen\u00addent types, \nwe mean re.nement types [14] that embed .rst-order * This work was supported by MEXT KAKENHI 20700019 \nand 20240001. Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n10, January 17 23, 2010, Madrid, Spain. Copyright c . 2010 ACM 978-1-60558-479-9/10/01. . . $10.00 let \nrecmult xy = if x<= 0 ||y <=0 then 0 else x+ mult x (y-1) in assert (100 <= mult 100 100) Figure 1. The \nmultiplication example. logic formulas. For instance, suppose we want to check that the as\u00adsertion never \nfails in the program shown in Figure 1. (Here, we use the Ocaml syntax.) One way to check the assertion \nis by giving mult the following dependent type.1 x : int . y : int . {u : int | (x = 0 . y> 0 . u = x) \n.(y = 0 . u = 0)} The type says that mult takes integers x and y, and returns an integer that is at least \nas large as x if x = 0 and y> 0,and a non-negative integer if y = 0. (As usual, . binds weaker than other \nlogical operators, and . associates to the right.) Indeed, the type is a valid type for mult and is suf.cient \nto prove that the assertion does not fail. Note that the type is neither the strongest (i.e., the most \nprecise) type nor the weakest necessary type that can be assigned to mult to prove the assertion. The \nstrongest type for mult would be x : int . y : int . {u : int | (x> 0 . y> 0 . u = x \u00d7 y) .(x = 0 . y \n= 0 . u =0)} which contains non-linear arithmetic, as expected. This paper presents a method for inferring \nsuf.ciently strong dependent types to check the given properties of a program. Our approach avoids computing \nthe strongest or the weakest necessary type, and instead returns some type that is suf.cient to prove \nthe property when terminating with success. Many existing dependent type systems (e.g., [4, 10, 38]) \nrequire the programmer to annotate recursive functions like mult with the correct types. Other systems \n[14, 33] require the domain of candidate types to be pre-de.ned and form a .nite-height lattice so that \nthe type checking can be implemented as a .xed-point algorithm that infers the strongest types in a bottom-up \nmanner. We propose a different approach to checking and inferring de\u00adpendent types that does not require \na pre-de.ned set of correct or candidate dependent types. Our approach is inspired by research in counterexample \nguided abstraction re.nement (CEGAR) for model checking [3, 9, 16, 28]. The core of our system is a CEGAR \nloop that iteratively re.nes the lattice of candidate dependent types until either the program is found \nto be actually untypable or the lattice 1 The type syntax is borrowed from Augustsson [1] (also used \nin [12, 22, 23, 33, 36]).  . d ::= d .{F -x = e}|\u00d8 e ::= x | c | F | let x = e1 in e2 | ex | if x then \ne1 else e2 | assert e Figure 2. The syntax of the simple functional language. becomes re.ned enough to \ntype check the program. We start with a coarse lattice containing few candidates and gradually add types \nthat are suf.cient to refute the spurious counterexamples encoun\u00adtered during the CEGAR iteration. A \ncounterexample in our system is an unwound slice of the program that is untypable with the current candidates. \nThe re.ne\u00adment phase decides whether the slice can be typed if the types are not con.ned to the candidates, \nand if so, generates new candidates from the inferred typing (if not, then the program is really unty\u00adpable). \nFor this, we employ recent techniques from both type sys\u00adtems and model checking research: linear intersection \ntypes [21] and interpolation [27]. We use linear intersection type inference to infer a type derivation \nshape that is suf.cient for typing the coun\u00adterexample, and we use an interpolating theorem prover to \nquickly compute good candidate types from the type derivation (in particu\u00adlar, without explicit quanti.er \nelimination). The rest of the paper is organized as follows. Section 2 intro\u00adduces the language and the \ndependent type system. The main con\u00adtribution of the paper is the CEGAR-inspired type inference system \ndescribed in Sections 3, 4, 5, and 6. While the paper mostly focuses on the assertion checking application \nfor simplicity, it is easy to ex\u00adtend the system to more general program speci.cation checking as discussed \nin Section 7. Section 8 describes the prototype imple\u00admentation for a subset of the Ocaml language, Section \n9 discusses related work, and Section 10 concludes. The proofs of the key re\u00adsults appear in the extended \nreport [35].  2. Preliminaries We focus on a small functional language shown in Figure 2. We brie.y \ndescribe the syntax. A program, d, is a .nite set of function - . de.nitions, Fx = e, which de.nes a \nfunction named F with the .. formal parameters -x and the body e. The notation -a denotes a possibly \nempty sequence. We often use letters u, x, y, z, ui,etc. to range over program variables and .rst-order \nlogic variables, and letters F , G, H, Fi, etc. to range over function names. Functions can be mutually \nrecursive in that the body of a function may refer to other functions, including itself. We assume that \neach function is closed (except for the free function names). We also assume that every function name \nis unique and that there is a function named main that takes no arguments. Note that nested function \nde.nitions can be supported via lambda lifting [19]. An expression, e, is a variable, a constant c, a \nfunction name, a let expression let x = e1 in e2, a (constant or function) application ex, a conditional \nbranch if x then e1 else e2, or an assertion assert e. Constants include integer and boolean constants \nsuch as 0 and true, as well as integer and boolean operations such as + and =. For simplicity, we restrict \nbranch condition and function arguments to just variables.2 We restrict the body of a function to continuation \npassing style (CPS) so that a function does not return. We also impose the CPS restriction to the body \nof a let expression (i.e., e . in let x = e in e .) and those of a branch (i.e., e1 and e2 in if x then \ne1 else e2) so that they are also non-returning. As usual, non-returning expres\u00adsions (i.e., non-partial \nfunction applications, let expressions, and conditional expressions) are restricted to occur only in \na continua- E ::= let x = E in e | Ee | vE Figure 3. The non-CPS evaluation contexts. -. .. Fx = e . \nd |-x | = |-v | APP . .. F -v .d e[-v/-x ] . arity(c)= |-v | CST -. . E[cv ] .d E[[[c]](-v )] let x \n= v in e .d e[v/x] LET if true then e1 else e2 .d e1 IF1 if false then e1 else e2 .d e2 IF2 E[assert \ntrue] .d E[0] AS1 E[assert false] .d fail AS2 Figure 4. The semantics of the simple functional language. \ntion context (i.e., not in a non-CPS evaluation context E shown in Figure 3). CPS is only enforced on \nuser-de.ned functions so that constant operations need not be CPS. The CPS restriction is imposed only \nto simplify the exposition. Non-CPS expressions may be supported indirectly via CPS conver\u00adsion or directly \nby extending the type system with conditional types and union (i.e., disjunctive) types.3 The rest of \nthe syntax is straightforward. As usual, a function application associates to the left so that e0 e1 \ne2 =(e0 e1) e2.We - . write e0 e for the series of applications e0 e1 e2 ... en where - . e = e1,e2,...,en. \nWe write e1; e2 for let x = e1 in e2 such that x/. free(e2). Without loss of generality, we assume that \nbound variables are distinct. Note that, because of higher-order functions and partial applica\u00adtions, \nfunction calls are not syntactically obvious, and one syntactic occurrence of a function name may end \nup being called from mul\u00adtiple places. We de.ne the call-by-value semantics of the language as a small-step \nreduction relation from states to states. A state is a run\u00adtime expression e that extends the source \nexpressions with values v and a special failure state, de.ned as follows. v ::= c | F | v1 v2 e ::= \u00b7\u00b7\u00b7 \n| v | fail (We overload the symbol e to range over run-time expressions when - . it is clear from the \ncontext.) We restrict the application Fv (resp. - . cv ) to be a value only when it is partial, that \nis, only when the arity . of F (resp. c) is greater than |-v |. Note that a partial application denotes \na closure value. Figure 3 de.nes the non-CPS evaluation contexts. Figure 4 shows the reduction rules. \nThe reduction rules are mostly straight\u00adforward. In CST, the notation arity(c) denotes the arity of the \ncon\u00adstant operation c. Here, [[c]] is the relation denoting the semantics of c, so that, for example \n[[+]](i, j)= i + j for all integers i and j. AS1 returns a dummy value 0,and AS2 aborts the program with \nan assertion failure. Note that, because of CPS, APP, LET, IF1,and IF2 only occur at the top-level. \n2 The implementation lifts this restriction by online A-normalization [13]. 3 The latter approach is \ntaken in the implementation discussed in Section 8. t ::= . |{u:B | .}| x:s . t s ::= t | s1 . s2 Figure \n5. The syntax of dependent types. sty(x) is base sty(x) is not base VaB VVaF G; . . x : {u:B | u = x} \nG,x:ti; . . x : ti i VFun Cst G,F :i ti; . . F : ti G; . . c : ty(c) G . e : t G1; . .. e : s1 G2; . \n.. e : s2 Int1 Int2 G; . .. e : t G1 . G2; . .. e : s1 . s2 G1; . .. e1 : s G2,x:s; . . e2 : . Let G1 \n. G2; . . let x = e1 in e2 : . G1; . . e : y:s . t G2; . .. x : s. G2; . . s. = s App G1 . G2; . . ex \n: t [x/y] G1; . . x = true . e1 : . G2; . . x = false . e2 : . If G1 . G2; . . if x then e1 else e2 \n: . G; . .. e : s G; . . s ={u:bool | u = true} Assert G; . . assert e : {u:int | u =0} Figure 6. The \ntype checking rules. We de.ne a run of a program to be a sequence of reductions from the initial state \nemain where main () = emain . d.(Here, () denotes the empty argument sequence.) We write e . * d e . \nfor zero or more reductions from e to e . . We assume that a program is typable with the standard simple \ntype system4 so that it is guaranteed to not get stuck, for example, by trying to use an integer as a \nfunction. Therefore, a program either runs forever safely (due to CPS, a program cannot return), or aborts \nwith an assertion failure. We call a program safe if its run does not cause an assertion failure. DEFINITION \n2.1 (Safety). A program d is said to be safe if emain ..d * fail where main () = emain . d. Being simply-typable \ndoes not imply safety. In the following, we present a dependent type system that guarantees the safety \nof ty\u00adpable programs. 2.1 Dependent Type System Our dependent type system is essentially the previous \nsystems [12, 33, 36] extended with intersection types. The reason for adding intersection types is not \njust to increase expressibility; it is actually crucial to the type inference system described later \nin the paper. Recall that a program is simply-typed. For each expression e in the program, we write sty(e) \nto denote its simple type. A simple type, s, is formally de.ned by the following grammar: B ::= int | \nbool s ::= . | B | s . s . Here, B is called base type, and the dummy type . represents the type of a \nCPS expression. Figure 5 shows the syntax of dependent types. Here, {u:B | .}is a re.nement base type \nthat re.nes the base type B by the formula 4 See the extended report [35] for the de.nition of the simple \ntype system. . which is a formula in some .rst-order theory. We sometimes abbreviate {u:B | .} simply \nas B when . is a tautology (e.g., {u:int |.} = int). Intuitively, {u:B | .} denotes the type of some \nvalue u of the base type B satisfying the formula .. The type x : s . t is a dependent function type \nconsisting of the argument type s and the return type t . Intuitively, x:s . t denotes the type of a \nfunction (or a constant operation) that returns a value of the type t [y/x] when applied to any argument \ny of the type s. The type {x:B | .} binds x within .. Likewise, x : s . t binds x in t (but not in s). \nWe sometimes abbreviate x:s . t as s . t when x does not occur free in t . Types are equivalent up to \nrenaming of bound variables. We use the symbol s to distinguish types with possible top-level intersections \nfrom those without (for which we use t ). Here, the intersection operator . is associative, commutative, \nand idempotent V (ACI), so that, for example, t . t = t . We sometimes write ti V i or T for the type \nt1 . t2 .\u00b7\u00b7\u00b7 . tn such that {t1,...,tn} = T is a non-empty set. Note that, because of ACI, any s can \nbe written in such a form. V For any intersection of types i ti, we enforce that each ti is of the same \nsimple-type shape. Formally, the simple-type shape of s is the simple type simple(s) de.ned inductively \nas follows: simple(x:s . t )= simple(s) . simple(t ) simple({u:B | .})= B simple(.)= . V simple({t, . \n. .})= simple(t ) V Then, we enforce that for any type T ,simple(t )= simple(t .) for all t, t . . T \n. This does not reduce expressibility because the type system is a re.nement type system [14] of the \nsimple type system, and so only the types of the same simple-type shape are meaningful to intersect. \nWithout loss of generality, we implicitly assume that any dependent type s assigned to e in the dependent \ntype system satis.es simple(s)= sty(e). Figure 6 shows the type checking rules of the dependent type \nsystem. The judgements are of the form G; . . e : t where G is a type environment mapping variables and \nfunction names to types possibly containing top-level intersections (i.e., s s), and . is a formula. \nThe formula . is used to accumulate the assumptions from nesting branch conditions. We discuss each typing \nrule. VaB types base-type variables. Note that the rule ignores the environment. Expressibility is not \nreduced, however, because the assumption about x in the environ\u00adment gets discharged at subtyping. The \nrule is borrowed from pre\u00advious work [31, 33, 36]. VaF types function-type variables by looking up the \nenvironment and selecting a type from the intersec\u00adtion. Here, as usual, G,x : s denotes the mapping \nG .{x .. s}if x/. dom(G), and is unde.ned otherwise. Fun is exactly like VaF except that it is for function \nnames. Cst types constants. Here, ty(c) is some sound5 dependent type for the constant c (e.g., ty(+) \n= x:int . y:int .{u:int | u = x + y}). Int1 and Int2 introduce intersection types. Here, G1 . G2 is de.ned \nas follows. G1 . G2 = {x .. G1(x) . G2(x) | x . dom(G1) n dom(G2)}.{x .. G1(x) | x . dom(G1) . x/. dom(G2)}.{x \n.. G2(x) | x/. dom(G1) . x . dom(G2)} We could have used a simpler set of rules that shares the environ\u00adments \nof the sub-judgements because intersections are non-linear (recall that . is ACI), but this format makes \nthe introduction of the linearity restriction smoother later in Section 5.2. Note that we write .. to \ndistinguish judgements that can introduce top-level in\u00adtersections. 5 See the extended report [35] for \nthe de.nition of a sound constant type.  SubC G; . . . = . u/. free([[G]]) ([[G]] . . . .1) . .2 SubB \nG; . .{u:B | .1}={u:B | .2} G; . . s2 = s1 G,x : s2; . . t1 = t2 SubF G; . . x:s1 . t1 = x:s2 . t2 .i.(G; \n. . ti = t ) .i.(G; . . s = ti) VSubI1 VSubI2 G; . . i ti = t G; . . s = i ti Figure 7. The subtyping \nrules. Let is self-explanatory. Note that the typing for e1 may intro\u00adduce top-level intersections. App \ntypes applications. Here, t [x/y] is the usual capture-avoiding substitution. App checks that the ac\u00adtual \nargument conforms to the formal argument type via the sub\u00adtyping G2; . . s. = s. Figure 7 shows the subtyping \nrules, which are a straightforward extension of those of the previous sys\u00adtems [12, 33, 36] with intersection \ntypes. In SubB, [[G]] is the .rst\u00adorder logic formula denoting the assumptions about the base-type variables, \nand is formally de.ned as follows. VVV [[G]] = {.i[x/u] | G(x)= {u:B | .i}} ii The If rule types conditional \nexpressions. Note that the assump\u00adtion about the branch condition (i.e., x) is recorded in the environ\u00adment. \nFinally, Assert checks the assertion via subtyping. We say that a type is closed if it has no free variables. \nLet . be a top-level type environment mapping function names to types. We say that s is a well-formed \ntype for F if s is closed and simple(s)= sty(F ). We say that . is a well-formed top\u00adlevel type environment \nif .(F ) is well-formed for each F .Unless mentioned otherwise, we restrict . to range only over well-formed \ntop-level type environments in the rest of the paper. . Let us write x- :s . t to abbreviate the function \ntype x1 :s1 . \u00b7\u00b7\u00b7 . xn :sn . t - . where x:s = x1 : s1,...,xn : sn. We de.ne the notion of a well\u00adtyped \nprogram. DEFINITION 2.2 (Well-typed program). We write . . d if for -. - . each function Fx = e . dV, \nwe have .,x:s; .. e : . for each - . ti = x:s . . in .(F )= i ti. We say that a program d is well-typed \n(equivalently, typable) if there exists . such that . . d. Assuming that the types of the constants ty(c) \nare sound, the type system ensures that a well-typed program does not cause an assertion failure. THEOREM \n2.3 (Soundness). If . . d then d is safe. The proof is analogous to that of the soundness result for \nsimilar dependent type systems [12, 33, 36] and is omitted. EXAMPLE 2.4. Let d consist of the following \nthree functions. (We elide A-normalization for readability.) sum xyk = if x = 0 then ky else sum (x - \n1) (x + y) k check x = assert (100 = x); check x main () = sum 100 0 check Note that sum is a function \nthat, given integers x and y, computes P y + i and applies the continuation k to the result. i.{0,...,x} \nP Therefore, d runs safely forever if 100 = i,and i.{0,...,100} aborts with an assertion failure otherwise \n(i.e., it will run forever). Assume that we are given the following constant types. ty(=)= x:int . y:int \n.{u:bool | u = x = y} ty(-)= x:int . y:int .{u:int | u = x - y} ty(+) = x:int . y:int .{u:int | u = x \n+ y} ty(i)= {u:int | u = i} where i .{0, 1, 100} We show that we can prove d to be safe with our type \nsystem assuming that the underlying theory supports booleans and linear arithmetic. Let . be the following \ntyping environment. .(main)=() . . .(check)= {u:int | u = 100}. . V .(sum)= T where T = { x:{u:int | \nu = 100}. y:{u:int | u = 0}.({u:int | u = 100}. .) . ., x:int . y:int . ({u:int | u = y}. .) . . } (Here, \n() . . is the special function type for main having an empty sequence of arguments. See De.nition 2.2.) \nIt is a routine to check that . . d. Note that the type of sum does not say that it actually returns \n(i.e., calls the continuation with) P y + i, but only that it returns some integer at least as i.{0,...,x} \nlarge as 100 when called with x = 100 and y = 0,and some integer at least as large as y unconditionally, \nwhich is suf.cient for typing d.  3. Type Inference Overview We now present our CEGAR-inspired procedure \nthat checks if the given program d is typable, and if so, returns . such that . . d. The inference procedure \nis a semi-algorithm as it is not guaranteed to terminate, but it is sound and complete in that it is \nguaranteed to return some correct typing when terminating with success and reject the program as untypable \nonly if it is actually untypable. (In practice, we make the procedure give up after some number of iterations, \nreturning unknown. ) The type inference maintains a lattice of candidate top-level type environments, \nand repeatedly executes the following two al\u00adgorithms, one after the other. The .xed-point type inference \nalgorithm checks if there exist a typing for the program within the current candidates via a .xed-point \niteration over the lattice of candidate top-level type environments. The algorithm returns a counterexample \nif the program is found untypable with the current candidates. The counterexample records the number \nof times the .xed-point iteration was executed to reach the type error. Otherwise, the program is found \ntypable and the process exits by returning the inferred typing. (Section 4)  Given a counterexample, \nthe re.nement algorithm unwinds the recursive de.nitions the number of times recorded in the coun\u00adterexample, \ngenerating a non-recursive program slice. Then, the algorithm decides the slice s typability completely \n(i.e., not re\u00adstricted to any candidates). If the slice is found untypable, then so is the original, \nand the process exits. Otherwise, the depen\u00addent types that are used to type the slice are added as the \nnew candidates to re.ne the lattice. This phase uses linear intersec\u00adtion type inference and interpolation \nto infer types for the un\u00adwound program slice. (Section 5)   The two components are both algorithms \nin that they are guaranteed to terminate. The following sections describe the two components in detail. \n 4. Fixed-point Type Inference A candidate set T is a mapping from function symbols to a non\u00adempty .nite \nset of dependent types with no top-level intersections such that for all t . T(F ), t is closed and simple(t \n)= sty(F ). V T induces the lattice T de.ned as follows.6 VV T= {. |.F..(F )= T where T . T(F )} V For \n.1, .2 . T,we order .1 . .2 if for all F ,we have VV T1 . T2 where .1(F )= T1 and .2(F )= T2. It is easy \nto VV see that T with . forms a lattice with the mapping .F. \u00d8 as V the top element and .F. T(F ) as \nthe bottom element. Note that except for the ones containing \u00d8,any . . T is a well-formed top-level type \nenvironment. V VV We de.ne the algorithm InferNext that takes . . T and re- V turns the strongest typing \n.. . T for d that can be typed with . (d is an implicit parameter to InferNext). More precisely, for \n. a V type environment (i.e., for all F , .(F ) .\u00d8), InferNext(.) = = . .. such that for each F -x = \ne . d, V . - . ..(F )= {x- :s . . . T(F ) | .,x:s; .. e : .} If . is not a type environment, then we \ntake InferNext(.) = .. InferNext(.) can be effectively computed assuming that we can decide the typing \njudgements G; . . e : t . The main com\u00adplexity involved here is deciding the subtyping relation SubB \n(cf. Figure 7), which can be done by the help from a theorem prover supporting the underlying .rst order \ntheory. It is easy to see that if a .xed point of InferNext is a type environment then it is a valid \ntyping for d.That is, V THEOREM 4.1. Suppose . . T is a type environment such that InferNext(.) = .. \nThen, we have . . d. Moreover, it is easy to show that InferNext is monotonic. Then, the V following \ntheorem is immediate from the fact that T is a .nite (and therefore, a complete) lattice. THEOREM 4.2. \nThe least .xed point . of InferNext is a type V environment if and only if there exists .. . T such that \n.. . d. Therefore, to decide if d is typable with the current can\u00addidate set, it suf.ces to compute the \nleast .xed point .= FV V i.. InferNexti(.F. T(F )) and check that .(F ) .\u00d8 for = all F .Ifsuch . exists, \nwe stop the CEGAR process and return . as the inferred typing for d. V Otherwise, we have .= InferNexti(.F. \nT(F )) such that V .(F )= \u00d8 for some F at some iteration i. In this case, we pass the pair (F, i) as \nthe counterexample to the re.nement algorithm described in Section 5. EXAMPLE 4.3. Let d consist of the \nfollowing four functions. Fxy = if x then Fyx else Gxy Gxy = assert y; Fyx Hx = assert x; Hx main () \n= if true then F true false else H false Let the current candidate set be T shown below. T(main)= {() \n. .}T(F )= {bool . bool . ., {u:bool | u = true}.{u:bool | u = false}. .}T(G)= {{u:bool | u = false}.{u:bool \n| u = true}. .}T(H)= {{u:bool |.}. .} 6 Here, . s are allowed to range over non type environments. V \nLet .0 be the least element of the lattice T,that is, VV .0 = {main .. T(main),F .. T(F ), VV G .. T(G),H \n.. T(H)} Then, InferNext(.0)=.1 where .1(main)=() . . .1(F )= {u:bool | u = true}.{u:bool | u = false}. \n. .1(G)= {u:bool | u = false}.{u:bool | u = true}. . .1(H)= {u:bool |.}. . .1 is a type environment but \n.1 . =.0. Therefore, iterating one more time, we get InferNext(.1)=.2 where .2(main)= .1(main), .2(G)=.1(G), \n.2(H)=.1(H),but .2(F )= V \u00d8. Because .2(F ) is not a type, we have reached the .xed point and can return \n(F, 2) as the counterexample.  5. Re.nement Recall that the goal of the re.nement phase is to check \nif the coun\u00adterexample is spurious by constructing a non-recursive program fragment from the counterexample \nand checking if the fragment is typable, not restricted to any candidate set. And if so, we build new \ncandidates from the inferred typing, and otherwise, we can reject the program as untypable. We separate \nthe re.nement phase into the following three sub\u00adphases, executed in order. We take the counterexample \n(F, i) and unwind the recursive de.nitions i times from F to produce a non-recursive program fragment. \n(Section 5.1)  We infer the type derivation shape that is suf.cient for typing the unwound fragment \nvia linear intersection type inference. (Section 5.2)  Given the linear derivation shape, we generate \nconstraints con\u00adsisting of .rst-order logic formulas and predicate variables, and check if the constraints \nare satis.able by using an interpolat\u00ading theorem prover. If not, then the unwound fragment is unty\u00adpable, \nand we stop the CEGAR process declaring the program untypable. Otherwise, from the typing inferred for \nthe fragment, we produce new candidate types that are suf.cient to refute the counterexample. (Sections \n5.3 and 5.4)  Next, we describe the three sub-phases in detail. 5.1 Unwinding The unwinding phase is \nthe simplest phase of the re.nement pro\u00adcess. Given a counterexample (F, i), we inline recursive de.nitions \ni times from F in d, leaving leaf function name occurrences with no de.nitions. The resulting program \nfragment, d., is then guaranteed to be free of recursive de.nitions. We demonstrate the process by unwinding \nthe program d from Example 4.3. Recall that we are given the counterexample (F, 2). Then, unwinding produces \nthe following program slice d.: G1 xy = assert y; F4 yx F2 xy = if x then F3 yx else G2 xy F1 xy = if \nx then F2 yx else G1 xy Here, F1,F2,F3,F4,G1,G2 are inlined function names created fresh. Note that F3, \nF4,and G2 are leaf functions. We maintain the mapping Inames that maps the original function names of \nd to the set of its inlined copies in d. . In the above example, Inames(F )= {F1,F2,F3,F4}, Inames(G)= \n{G1,G2},and Inames(H)= Inames(main)= \u00d8. Note that the unwinding only contains functions that are involved \nin the counterexample, that is, main and H (as well as F and G beyond depth 2) are sliced out.7  We \ndiscuss the key properties of unwinding. First, because d is simply typable, d. is also simply typable, \nand we assume that sty(e) is given for each expression e in d.. Let us extend the type judgement . to \nleaf function name occurrences in the obvious way by allowing any well-formed type for the function to \nbe assigned. The following is immediate. THEOREM 5.1. Suppose . . d and d. is an unwinding of d. Let \n.. be a top-level type environment for d. such that for each G . Inames(F ), ..(G)=.(F ). Then, .. . \nd. . Therefore, showing that d. is untypable is suf.cient for showing that d is untypable. As a contrapositive, \nwe show that the current candidate set is insuf.cient for typing d., using candidates for the originals \nfor the inlined functions. THEOREM 5.2. Let d. be the unwinding of d produced from the counterexample \npassed from the .xed-point type inference phase using the candidate sets T.Let T. be a candidate set \nfor d. such that for each G . Inames(F ), T.(G)=T(F ). Then, there exists V no . . T. such that . . d. \n. The above theorems justify us calling (F, i) a counterexample. That is, the unwinding d. produced from \n(F, i) is a counterexample to the typability of d under the current candidate set.  5.2 Linear Intersection \nTypes The goal of the rest of the re.nement phase is to check if the un\u00adwinding d. is typable, without \ncon.ning the types of the functions to any candidate set. An issue here is that the type system allows \nunboundedly many intersections, and so we cannot naively derive a type inference algorithm from the type \nchecking rules from Sec\u00adtion 2.1. To overcome the issue, we use the observation that only linear intersections \nare needed for typing d. and that the linear in\u00adtersection shapes can be inferred. The crucial properties \nof d. that enable this is that d. does not contain recursive de.nitions and is simply typable. Linearity \nis also important to the constraint solving phase of the re.nement algorithm because it ensures the acyclicity \nof the generated constraints (cf. Section 5.3). Informally, in the linear intersection dependent type \nsystem .1 , for a non-base-type binding x : s, the top-level intersections of s determine how the variable \nx is used. For example, it is possible to derive G2; ..1 if y then xy else xy : . where G2 = y ::bool,x:(bool \n. .) . (bool . .),but G1; . ..1 if y then xy else xy : . G3; . ..1 if y then xy else xy : . where G1 \n= y :: bool,x : bool . . and G3 = y :: bool,x : (bool . .) . (bool . .) . (bool . .). Essentially, .1 \nis equivalent to . except that it disallows non\u00adlinear use of function-type bindings. The linearity restriction \nis only imposed on function types; base types are used non-linearly. We formally de.ne the type system \n.1. The syntax of linear intersection types is equivalent to that of . (cf. Figure 5). But now, . is \nneither associative, commutative, nor idempotent. We also modify the typing rules so that the rules in \nFigure 8 replace VaB, VaF, Fun, Cst and Let from Figure 6 and SubI1 and SubI2 from Figure 7. The rest \nof the rules remain the same, just replacing . with .1,and .. with .1 .. We eliminate any intersection \nof base types via the equivalence {u:B | .1}.{u:B | .2} = 7 The implementation performs additional optimizations \nthat can further reduce the size of the unwinding by slicing out more irrelevant parts. sty(x) is base \nisBaseEnv(G ) VaB1 G; . .1 x : {u:B | u = x} sty(x) is not base isBaseEnv(G ) VaF1 G,x:t ; . .1 x : t \nisBaseEnv(G ) F is leaf isBaseEnv(G ) Cst1 Fun11 G; . . c : ty(c)G,F :t ; . .1 F : t dom(G.) are all \nfunction names isBaseEnv(G ) -. - . Fx = e . d. G. ,x:s \\X; ..1 e : . . X = {xi .{-x }\\ free(e) | sty(xi) \nnot base} G, G.x- :s . .; . .1 . Fun21 .- ,F : F : x:s . . G1; . .1 G2,x:s \\X; . .1 e2 : . . e1 : s \nX = {x | x/. free(e2) and sty(x) not base} Let1 G1 . G2; . .1 let x = e1 in e2 : . G .1 s1 = s. G .1 \ns2 = s. 12 SubI1 G .1 s1 . s2 = s1 . . s2 . Figure 8. The key .1 typing rules. {u:B | .1 . .2}. As with \n., we assume that any type s assigned to an expression e satis.es simple(s)= sty(e). We discuss the new \nrules. VaB1 replaces VaB. Here, the condition isBaseEnv(G ) says that all bindings in G are base types, \nthat is, dom(G) does not contain function names and for all x . dom(G), G(x) is a base type. VaF1 replaces \nVaF and requires that the only function-type binding in the environment is x. Similarly, Cst1 replaces \nCst and requires that G contains no function-type bindings. Fun11 and Fun21 replace Fun. Fun11 types \nleaf function names and is much like VaF1 . Fun21 types non-leaf function names. (Note that judgements \nare implicitly parameterized by the unwound fragment d..) Unlike Fun, it type checks the body of the \nfunction in the sub-derivation. Note that this does not lead to an in.nite derivation tree because d. \ndoes not contain recursive de.\u00ad - . - . nitions. Here, x:s \\X denotes the bindings x:s with the bindings \nfor X removed. We need this because linearity implies that a non\u00adbase-type variable that are not used \nin e cannot be bound in the environment. Let1 similarly takes care of unused non-base vari\u00adable bindings. \nFinally, SubI1 replaces SubI1 and SubI2 from Figure 7. It just structurally applies subtyping inside \nintersections. Note that any unwound program fragment has a unique root function from where the unwinding \nstarted and whose name does not occur free in the unwinding. We de.ne the notion of linearly typable \nprograms. DEFINITION 5.3 (Linearly typable programs). Let d. be an un\u00adwound program fragment with F as \nthe root function. Then, we write . .1 d. if . .1 F : t for some t . (Incidentally, it must be the case \nthat t =.(F ).) The following theorem states that we can decide if d. is typable by deciding if d. is \nlinearly typable. THEOREM 5.4. Let d. be an unwound program fragment. Then, the following are equivalent. \n(1) There exists . such that . .1 d. . (2) There exists . such that . . d. .   We defer the proof \nto the extended report [35]. Unlike ., .1 is completely structural because the shape of a derivation, \nincluding the number of intersections in the types, is determined by how variables occur in d.. To infer \nthe derivation shape, we adopt the expansion-variable-based inference algorithm of Kfoury and Wells [21], \nmodi.ed so that expansions are not ap\u00adplied to base-type bindings. For space, we refer to their paper \n[21] for the details of the algorithm. The inferred shape satis.es all the structural requirements of \n.1, that is, everything except for the log\u00adical validity premise at SubB. More precisely, we introduce \nshape-only types that have holes - in place of .rst-order logic formulas, de.ned as follows. t ::= . \n|{x:B |-} | x: s . t s ::= t | s 1 . s 2 Let shape-only type environment G be a mapping from variables \nand function names to s s, and top-level shape-only type environ\u00adment . be a mapping from functions names \nto s s. Then, linear in\u00adtersection type shape inference judgement G; -. 1e : t consists of .1 rules, \nbut using t (resp. s )wherever t (resp. s) appears, using the hole - for formulas, and replacing SubB \nwith the following rule. G; -. 1{u:B |-}= {u:B |-} We also replace formulas in constant types ty(c) \nwith holes, pro\u00adhibit intersection of base types, and use types containing no inter\u00adsections for the \nunused bindings X at Fun21 and Let1. Then, the linear intersection type shape inference infers a shape-only \nderiva\u00adtion . . The fact that such a derivation exists is the conse\u00ad .1d. quence of the fact that d. \nis recursion free and is simply typable,8 and follows from well-known properties of intersection types \n(see, e.g., [21]). The linear intersection type shape inference is non-trivial in the presence of higher-order \nfunctions. In fact, it is known that the complexity of the inference is non-elementary time hard [29, \n34]. But the expansion-variable-based algorithm appears to work well in practice, perhaps because functions \nof high ranks,9 which could cause the inference to explode, are used sparingly in practice.  5.3 Constraint \nGeneration and Constraint Solving Having generated the derivation shape for d., the next step is to check \nif the shape can be turned into an actual .1 derivation by .lling in the holes with .rst-order logic \nformulas. To this end, we introduce predicate variables that serve as placeholders for .rst-order logic \nformulas in the derivation. We use large letters P, Q, etc. to range over predicate variables. We generate \nconstraints containing predicate variables and formulas from the underlying theory, and use an interpolating \ntheorem prover to solve for the predicate variables. We extend the syntax of dependent types to allow \npredicate variables in place of formulas in re.nement base types: . ::= e | ., [x/y] t ::= \u00b7\u00b7\u00b7 | {u:B \n| P.} (We overload t to range over the extended types when it is clear from the context.) The sequence \nof substitutions . is called pend\u00ading substitutions [33] (or delayed substitutions [23]). Pending sub\u00adstitutions \nrecords the substitutions t [x/y] made at App so that, for example, {u:B | P }[x/y]= {u:B | P [x/y]}. \n(The empty substi\u00adtution e is elided.) 8 Actually, typability under any type system that ensures normalization \nof recursion-free terms is suf.cient. 9 Roughly, a rank is the number of times a type can be nested in \nthe left hand side of .. Let . . 1d. be the inferred derivation shape. . is a mapping from non-root \nfunctions in d. to shape-only types. We build a function type template . from .(F )= \u00a8 . such that for \neach s, we have .(F )= s where s is s with its holes .lled with fresh \u00a8 predicate variables with empty \npending substitutions. For example, from the shape .= {F .. x:{u:int |-} . ., G .. x:{u:int |-}. .} \nwe make the template \u00a8 .= {F .. x:{u:int | P }. ., G .. x:{u:int | Q}. .} \u00a8 where P .. to emphasize that \nit may contain = Q. (Here, we write predicate variables.) To generate constraints, we convert .1 type \nchecking rules to constraint generation rules by modifying the base-type subtyping rule SubB so that \ninstead of checking logical validity, the premise \u00a8\u00a8 \u00a8 [[G]] . . . .1 . .2 is recorded as a constraint. \nHere, we use \u00a8 the symbol . to range over formulas possibly containing predicate variables, (and reserve \n. for concrete formulas that do not contain \u00a8 predicate variables). Then, having the template . at hand, \nwe follow the derivation shape and record the constraints that occur at each SubB instance. Let C be \nthe set of constraints obtained this way. Note that C is a set of formulas containing predicate variables. \nTo de.ne a solution for the constraints, we de.ne the scope \u00a8 variables of each P in the template ., \nwritten scopevars(P ),to be the set of variables that are allowed to appear free in a solution. Formally, \nscopevars is a mapping from predicate variables to the largest set of variables such that for any mapping \nS from predicate variables to concrete formulas with free(S(P )) . scopevars(P ) for all P , S(s) is \nclosed for all s . ran(\u00a8 .). Here, S(s) denotes s with its predicate variables P replaced by the concrete \nformula S(P ). Scope variables can be computed by a linear scan over \u00a8 the template. For example, scopevars(P \n)= {x, u} for .= {F .. x:s . y:{u:int | P }. .}. We say that S is a solution for C, written S |= C,if \nS(P ) . scopevars(P ) for all P and for each . .C, S(.\u00a8) is valid. It is \u00a8 easy to see that if S is a \nsolution, then S(.)\u00a8 .1 d. where S(\u00a8 .) is de.ned {F .. S(\u00a8 .(F )) | F . dom(.)}. 5.3.1 Least Solution \nTo solve the constraints, we .rst compute the least solutions for the predicate variables. The least \nsolutions are used when comput\u00ading interpolants in the second phase of the constraint solving (cf. Section \n5.3.2). Note that each constraint in the generated set of constraints C is either of the following forms. \n(Recall that . binds the weakest.) (1) . . . . .. (2) . . . . P.  where . and .. do not contain predicate \nvariables and . is a conjunction of predicate variables with pending substitutions: . ::= .| . . P. Predicate \nvariables appearing in a constraint are guaranteed to be distinct. Furthermore, C is acyclic in the following \nsense. THEOREM 5.5. The generated set of constraints C does not con\u00adtain constraints of the form {Pi.i \n. .\u00a8 i . Pi+1.. i | 1 = i = n}for some n = 1 with P1 = Pn+1. We defer the proof to the extended report \n[35]. The result follows from the fact that the derivation is linear. Indeed, cyclic constraints could \nbe generated if we had used the simple types to obtain the derivation shape as seen Example 5.6 below. \n Because of acyclicity, we can totally order predicate variables via topological sort so that if there \nis a constraint of the form P. . . \u00a8 . Q.. in C,then P<Q. EXAMPLE 5.6. Thisexampleillustratestheimportanceoflinearity \nin avoiding cyclic constraints. Let the unwound fragment d. consist of the following functions.10 Hf \nk = f 0(Gf k) Gf kx = fxk Fxk = kx Kx = assert x = 0; Kx main () = HFK Let . . 1d. be the inferred linear \nintersection type shape. Then, .(H)= f : t . t . k:(x:{u:int |-}. .) . . where t = {u:int |-} . ({u:int \n|-} . .) . ..From . , \u00a8\u00a8 we get the template . such that .(H)= f :t1 . t2 . ... where t1 = {u:int | P1}. \n... and t2 = {u:int | P2}. ...,for P1 and P2 fresh. The set of constraints C generated from .\u00a8 .1 d. \nis acyclic, but induces the ordering P1 <P2. Hence, if we had used simple-type shapes so that t . ... \ninstead, then we .(H)= f : would have P1 = P2, and the constraints become cyclic. . Thanks to acyclicity, \nwe can systematically derive the least solution for C in a bottom up manner, that is, in the ascending \norder of <. (Although we call it the least solution, it is an actual solution only if C is satis.able.) \nWe describe the method to obtain the least solution for P having obtained the least solutions for all \nQ<P .Let \u00a8\u00a8 {.\u00a8 1 . P.1,.2 . P.2,..., .n . P.n} be the set of constraints in C of the form . \u00a8 . P.. \nWe set the least solution for P to be _ -1 Least(P )= .X. Least (.\u00a8 i).i i W where X = free(i Least (.\u00a8 \ni).i -1) \\ scopevars(P ). We explain the construction. We .rst concretize each lowerbound .\u00a8 i of P.i \nby substituting the least solutions for the predicate variables appearing free in .\u00a8 i. Note that such \nleast solutions are already obtained. Then, we reverse substitute the pending substitutions .i to obtain \nthe concretized lowerbounds for P ,thatis, Least (\u00a8 i for each i. .i).-1 The correctness of the construction \nrequires the targets of .i to not occur free in Least (.\u00a8 i), which can be met by renaming the bound \nvariables in the types. Finally, we take the disjunction of the concretized lowerbounds, and existentially \nquantify all free variables except for the scope variables of P . The latter ensures that free(Least \n(P )) . scopevars(P ). The following is immediate from the construction of Least . THEOREM 5.7. If C \nis satis.able, then Least is the least solution for C. That is, Least |= C, and for all solutions S such \nthat S |= C, Least (P ) . S(P ) for all P . Thus, to check C s satis.ability, it suf.ces to check whether \nLeast (.\u00a8) is logically valid for each constraint . \u00a8 .C.And if so, we have Least(\u00a8 .) .1 d., and we \ncan obtain new candidate types from Least (.)\u00a8 . (Recall that .\u00a8 is the template obtained from . such \nthat . . 1d..) While this is a sound and complete way to solve C and generate new candidates, it tends \nto produce suboptimal candidates. There are two problems with using Least (\u00a8 .) as the new can\u00addidates. \nOne problem is that the least solutions may contain exis\u00adtential quanti.ers that need to be eliminated \nbefore using them as candidates so that the .xed point type inference phase only needs to work with quanti.er-free \nformulas. 10 The code is somewhat contrived because of the CPS restriction. The essence is F being applied \nto the return value of another instance of itself. sum1 xyk = if x = 0 then ky else sum2 (x - 1) (x + \ny) k check1 x = assert (100 = x); check2 x main1 () = sum1 100 0 check1 Figure 9. Example 2.4 unwound \ntwice from main. The second, more critical, issue is that the least solutions are often too strong as \ncandidates. We illustrate the problem using the summation program d from Example 2.4. Suppose we are \ngiven the counterexample (main, 2). Unwinding d twice from main,we obtain d. shown in Figure 9. Then, \nusing the least solutions, we obtain the following top-level type environment .= Least (\u00a8 .). .(sum2)= \nx:{u:int | u =99}. y:{u:int | u = 100}.({u:int |.} . .) . . .(sum1)= x:{u:int | u = 100}. y:{u:int | \nu =0}.({u:int |.} . .) . ({u:int |.} . .) . . .(check1)=.(check2)= {u:int |.}. . Note that . says that \nsum2 (resp. sum1) can only take 99 (resp. 100) as its .rst argument. Nevertheless, we have . .1 d.,and \nso . is suf.cient for typing d.. However, it is too strong to type the original program. Indeed, if we \nhad used the least solutions to build candidates every time, then we would be generating a hundred candidate \ntypes to type the original program. More generally, the least solutions are too strong when the un\u00adwinding \nis incomplete, which is often the case for programs con\u00adtaining recursive functions. We would suffer \nfrom the dual problem had we used the greatest solutions instead, that is, they would be too weak. To \novercome these issues, we use interpolation [11] to .nd a quanti.er-free solution Interp that can be \nweaker than Least (i.e., Least(P ) . Interp(P )) but is still strong enough to type d. (i.e., Interp \n|= C).  5.3.2 Interpolants We compute Interp via interpolation and the least solution Least obtained \nby the process in Section 5.3.1. We brie.y review the basic properties of interpolation. Interpolation \nReview Given formulas .1 and .1 where .1 . .2, an interpolant between .1 and .2, written ..1,.2., is \na formula . such that .1 . ., . . .2,and free(.) . free(.1) n free(.2).It is known that quanti.er-free \ninterpolants exist and can be computed for many useful .rst-order theories, such as the quanti.er-free \ntheory of linear arithmetic and uninterpreted function symbols [5, 20, 27]. Recall the total ordering \nof predicate variables < from Sec\u00adtion 5.3.1. We compute Interp(P ) for each P in the descending order \nof <. We describe how to compute Interp(P ) having com\u00adputed Interp(Q) for all Q>P .Let {P.1 . .\u00a8 1 . \n.\u00a8 1,P.2 . .\u00a8 2 . .\u00a8 2,...,P.n . .\u00a8 n . .\u00a8 } n \u00a8\u00a8 be the set of constraints in C of the form P. . . . \n...We set Interp(P )= .Least (P ),.. if Least (P ) . . where ^ . = S(.\u00a8 i . .\u00a8 i.).-i 1 i where S is \nthe substitution such that S(Q)= Interp(Q) if P<Q and S(Q)= Least (Q) if Q<P .(P is guaranteed to not \nappear  \u00a8 in .\u00a8 i . .i..) Otherwise, Least (P ) .. . and we reject d.,and therefore also the original \nprogram d, as untypable. We explain the construction of the upperbound . above. First, .\u00a8. we concretize \nthe upperbound of each P.i (i.e., .\u00a8 i . i) by sub\u00adstituting formulas for the free predicate variables \nvia S. Some free \u00a8 .\u00a8. predicate variables in .i . i may not have its Interp computed yet, and so S uses \nLeast for such predicate variables. However, because of acyclicity, such predicate variables are guaranteed \nto appear only negatively (i.e., to the left of .). Then, we reverse substitute .i to obtain the concretized \nupperbounds for P ,that is, S(\u00a8 .\u00a8 i.).-1 for each i. The correctness of the construction re\u00ad .i . i \nquires that the targets of .i do not occur free in S(.\u00a8 i . .\u00a8 i.),which can again be ensured by renaming \nof bound variables. Finally, we take the conjunction of the concretized upperbounds to obtain .. The \nfollowing theorem states that the above algorithm .nds a correct Interp if and only if C is satis.able. \nTHEOREM 5.8. The algorithm computes Interp such that Interp |= C if and only if C is satis.able. The \nproof is by induction on the (totally-ordered) predicate vari\u00adables. See the extended report [35] for \ndetails. Note that because free(Least (P )) . scopevars(P ),we have free(Interp(P )) . scopevars(P ) \nfrom the property of interpolants. From the construction, we have Least(P ) . Interp(P ) for all P . \nAlthough Theorem 5.8 does not imply that Interp .Least , = interpolating theorem provers tend to produce \nsmall interpolants that often work better as candidates than do the least solutions. Computing without \nQuanti.ers It is possible to compute the interpolant .Least (P ),.. by renaming the existentially quanti.ed \nvariables in the least solutions with fresh variables. This approach is justi.ed by the following lemma \nand the fact that existential quanti.ers appear only positively in Least(P ) and only negatively in .. \nLEMMA 5.9. Aformula . is an interpolant between .X..1 and . (.Y..2) . .3 if and only if it is an interpolant \nbetween .1[-x/X] ... and .2[-y/Y ] . .3 where -x and -y are fresh variables. Thus, we can check for the \nsatis.ability of C and obtain a quanti.er\u00adfree Interp without explicit quanti.er elimination by using \na the\u00adorem prover that can produce quanti.er-free interpolants for the formulas in the underlying theory. \n  5.4 New Candidate Types Given Interp, we generate the new candidates suf.cient for typ\u00ading the counterexample. \nRecall that we have Interp(\u00a8 d. . .) .1 Interp(\u00a8 .) is a mapping from function names in d. to their types. \nRecall that Inames maps the original function names in d to their inlined copies in d. . We de.ne the \nnew candidates T. as follows: for each F in d, V T.(F )= {ti | ti .)(G) where G . Inames(F )}. i = Interp(\u00a8 \nThen, we pass T. to the .xed-point type inference component which updates the candidates by T:=T . T.,where \nT . T. is the point-wise union .F.T(F ) . T.(F ). From the property free(Interp(P )) . scopevars(P ), \nthe new types are guaranteed to be closed, and so the updated T is a valid candidate set. Fur\u00adthermore, \nbecause Interp(\u00a8 .) . d., it follows from Theorem 5.2 that the updated candidate set is suf.cient to \neliminate the spuri\u00adous counterexample from future CEGAR iterations, as stated in the following theorem. \nTHEOREM 5.10. Suppose that the lattice of candidates was re.ned by refuting the counterexample (F, i). \nThen, for any counterexam\u00adple (F, j) reported in future, j>i. Figure 10. The type inference CEGAR loop. \nIt is worth noting that the theorem would hold true even if Least had been used instead of Interp. Nonetheless, \nthe idea is that Interp is likely to eliminate other spurious counterexamples that we would see in future \nhad we used Least instead.  6. Putting Type Inference Components Together Figure 10 summarizes our CEGAR-inspired \ntype inference pro\u00adcess. The .xed-point type inference algorithm checks if the pro\u00adgram d is typable \nunder the current set of candidates T.,and if so, returns Typable with the inferred typing ., and otherwise, \npasses the counterexample (F, i) to the re.nement algorithm. The re.nement algorithm creates the unwinding \nd. from the counterex\u00adample and decides d. s typability completely. If d. is found unty\u00adpable, then the \nre.nement algorithm returns Untypable with the real counterexample d., and otherwise, returns new candidates \nT. that is suf.cient for typing d.. The .xed-point routine re.nes the candidates by updating T:= T . \nT., and the CEGAR iteration repeats. As remarked before, while the .xed point type inference and re\u00ad.nement \nalgorithms are each guaranteed to terminate, the CEGAR loop may iterate forever, producing an ever more \nre.ned set of can\u00addidates. But, the type inference is sound and complete in the sense that it always \nreturns the correct answer when it terminates. 6.1 Initializing Candidates The remaining question is \nabout priming the CEGAR loop, that is, how to pick the initial set of candidates. In principle, any T \nsuch that each T(F ) is a .nite non-empty set of well-formed types can be used as the starting set of \ncandidates. One approach to building a sensible initial T is to run the re\u00ad.nement process with arti.cial \ncounterexamples (F, i) for each F for some i, and take the point-wise union of T. produced from each \ncounterexample as the initial T. The implementation discussed in Section 8 takes this approach with i \n=1. Another possible approach is to heuristically create the initial candidates by scanning the program \ntext, for example, by using expressions appearing in branch conditions as the formulas in the re.nement \nbase types. This is also the approach taken in Rondon et al. [33] for building the domain of possible \ntypes. Finally, we may allow the programmer to suggest additional candidates (e.g., as type annotations). \n 6.2 Example Recall the summation program d from Example 2.4. Suppose that the current set of candidates \nis T shown below: T(sum)= {int . int . (int . .) . ., {u:int | u = 100}.{u:int | u = 0}. ({u:int | u \n= 100}. .) . .}T(main)= {() . .}T(check)= {{u:int | u = 100}. .}  VV Then, InferNext2(.F. T(F ))= . \nwith .(main)= \u00d8,and so the counterexample (main, 2) is reported. Hence, we unwind from main twice, and \nobtain d. shown earlier in Figure 9. Next, linear intersection type shape inference infers . such that \n. . 1d..From . we obtain the template .\u00a8 such that \u00a8 .(sum1)= x:{u:int | P1}. y:{u:int | P2}.k:(z:{u:int \n| P3}. .) . (z:{u:int | P4}. .) . . \u00a8 .(sum2)= x:{u:int | Q1}. y:{u:int | Q2}. k:(z:{u:int | Q3}. .) \n. . where the predicate variables are fresh. (We omit the templates for main1, check1,and check2.) Generating \nconstraints and solving for the least solutions, we obtain Least(P1) . u = 100 Least (Q1) . u =99 Least(P2) \n. u =0 Least (Q2) . u = 100 Least (P3) . Least (P4) . Least (Q3) .. As remarked in Section 5.3.1, these \nsolutions, while correct, are stronger than desired. It is possible, though not guaranteed, for an interpolating \ntheorem prover to generate the following Interp. Interp(P1) . Interp(Q1) .. Interp(P2) . Interp(Q2) .. \nInterp(P3) . Interp(P4) . Interp(Q3) . u = y From Interp(\u00a8 .), we obtain the new candidates T. such that \nT. (sum)= x:int . y:int . ({u:int | u = y}. .) . . V Then, as shown in Example 2.4, there exists . . \n(T . T.) such that . . d, and the .xed-point type inference algorithm returns Typable(.).  7. Beyond \nAssertion Checking We have shown that our system can be used to check the absence of assertion failures. \nThis section presents an extension that checks more general program properties speci.ed via user-provided \ntypes. Speci.cally, we allow the user to provide a mapping . from func\u00adtion names to types and ask if \nthere exists a typing . . d such that \u00d8; .. .(F ) = .(F ) for all F . Such a speci.cation conformance \ncheck can be handled by a simple extension outlined below. Note that this can also be used to force the \nsystem to infer a typing of a desired precision. We assume that .(F ) is well-formed for each F . We \nmod\u00adify the .xed-point type inference algorithm from Section 4 so that InferNext reports the counterexample \n(F, i) if it reaches . such that \u00d8; . .. .(F ) = .(F ) at the ith .xed-point iteration. Other\u00adwise, a \n.xed point . such that for all F , \u00d8; .. .(F ) = .(F ) is reached and the system declares that d conforms \nto .. We also extend the re.nement algorithm from Section 5 so that given the counterexample (G, i), \nit unwinds d to get d. as before, and then checks if there exists . such that . . d. and for all F ,for \nall F . . Inames(F ), \u00d8; .. .(F .) = .(F ).If so, the re.nement algorithm returns new candidates T. constructed \nfrom such ., and otherwise, declares that d does not conform to .. Note that the additional conditions \n\u00d8; .. .(F .) = .(F ) can be reduced to constraints that can be solved by the constraint solving algorithm. \n 8. Implementation and Experiments We have implemented a prototype of the type inference system, Depcegar, \nwhich takes a subset of Ocaml programs corresponding Program Time T-TP T-INT Candidates bool.ip sum sum-acm \nsum-all mult mult-cps mult-all 0.2 0.1 0.5 0.1 0.6 1.0 0.5 95% 97% 98% 93% 99% 98% 98% 72% 26% 14% 46% \n31% 31% 50% 10 6 9 9 6 13 10 Table 1. Experiment results -typable programs. Program Time T-TP T-INT \nCandidates bool.ip-e sum-e sum-acm-e sum-all-e mult-e mult-cps-e mult-all-e 0.2 2.8 9.9 0.3 13.9 42.1 \n1.1 95% 99% 99% 97% 99% 99% 98% 79% 85% 94% 75% 91% 90% 71% 8 9 10 9 9 16 10 Table 2. Experiment results \n-untypable programs. to the simple functional language (cf. Figure 2) extended to direct\u00adstyle syntax. \nDepcegar handles non-CPS expressions by extending the type system with conditional types and union types, \nand handles non-A-normal forms by online A-normalization [13]. Depcegar is implemented as a modi.cation \nto the Ocaml 3.10.2 compiler. We use Ocaml s parser and ML-type inference as the front-end to parse the \nprogram and obtain the simple types.11 We use CSIsat 1.2 [5] as the interpolating theorem prover. CSIsat \nsup\u00adports the quanti.er-free .rst-order theory of uninterpreted func\u00adtion symbols and linear arithmetic \n(EUF+LA). CSIsat supports real arithmetic but not integer arithmetic, and so integers are approx\u00adimated \nas reals in Depcegar (it does not affect the examples in this paper). For convenience, we use CSIsat \nboth to generate in\u00adterpolants in the re.nement phase and to decide base-type subtyp\u00ading judgements in \nthe .xed-point type inference phase (i.e., SubB from Figure 7). The implementation contains about 5000 \nlines of original code. A web demo of Depcegar and the benchmark pro\u00adgrams are available online [35]. \nWe have conducted experiments on small hand-crafted pro\u00adgrams, including the ones used as examples in \nthe paper. Table 1 summarizes the results. Here, the .rst column is the program name and the second column \nis the running time in seconds. The col\u00adumn T-TP is the fraction of the running time spent by the inter\u00adpolating \ntheorem prover CSIsat (both interpolant computation and subtyping judgements), and the column T-INT is \nthe fraction of the running time CSIsat spent computing interpolants. The times do not include the parsing \nand ML-type inference time. The column Candidates shows the total number of candidates generated (for \nall functions combined). The experiments were conducted on a Intel Core 2 Extreme 3GHz machine with 2GB \nof ram, running Linux. All of the programs in Table 1 are typable. We brie.y describe each program. The \nprogram boolflip is the boolean program from Example 4.3. The program sum-acm is the summation pro\u00adgram \nfrom Example 2.4, sum is the same summation program writ\u00adten in direct-style (i.e., without using the \naccumulation parameter y), and sum-all is sum recursively applied to all non-negative inte- P gers (i.e., \nit asserts x = i for all x = 0). The program i.{0,...,x} mult is the multiplication program from Figure \n1, mult-cps is the same program written in CPS, and mult-all is mult recursively 11 Depcegar does not \ntake advantage of ML s parametric polymorphism, but in principle, let polymorphism can be handled by \ninlining.  applied to all non-negative integers, that is, it replaces the last line of mult with the \nfollowing:12 and f y = assert (y <= mult y y); f (y+1) and main () =f 0 Depcegar was able to successfully \ninfer a typing for each of the programs. The Candidates column shows that relatively few candi\u00addates \nare generated to type the programs, con.rming our hypothesis that the interpolation-based candidate generation \nmethod is quite effective at generating good candidates. To test Depcegar on untypable programs, we injected \nassertions errors into each of the programs. For example, mult-e replaces the last line of mult with \nthe following to assert that 600 = 100 \u00d7 5: and main () = assert (600 <= mult 100 5) and boolflip-e applies \nF to yy instead of yx inside the body of F (cf. Example 4.3). Depcegar successfully detected the type \nerror in all of the pro\u00adgrams. Table 2 summarizes the results. Note that the interpolation fraction T-INT \ntends to be higher for the untypable programs. This is primarily because their run ends during the last \nre.nement phase, whereas for typable programs, the run ends when the last .xed\u00adpoint type inference phase \nhas .nished. The results also show that Depcegar quickly detects that boolflip-e (and sum-all-e and mult-all-e) \nare untypable, but is quite slow on mult-e (and sum-acm-e and mult-cps-e). More generally, we have observed \nthat while Depcegar can of\u00adten quickly detect typable programs to be typable by generating good candidates \nearly in the CEGAR loop, for untypable programs, it must iterate the CEGAR loop long enough until a real \ncounterex\u00adample is encountered. This may result in a large unwinding for a type error that only occurs \ndeep in the program. A similar is\u00adsue occurs in CEGAR-based model checking when detecting errors that \ntake many steps from the initial state to reach [2, 25]. One pos\u00adsible remedy is to multiply the unwinding \ndepth by an increasing factor as the CEGAR loop progresses. We leave for future work to address the issue \nin a more depth. We also observe that Depcegar s running times are almost com\u00adpletely dominated by that \nof theorem proving, with a non-negligible fraction dedicated to computing interpolants. As discussed \nin Sec\u00adtion 9.3, interpolating theorem provers are fairly new technology and are actively being researched. \nHence, we expect the running times to improve as interpolating theorem provers mature. A possi\u00adble optimization \nis to use a faster, non-interpolating theorem prover for deciding subtyping judgements and use an interpolating \ntheo\u00adrem prover only for computing interpolants. Finally, we note that while the interpolation-based \nre.nement guarantees the elimination of the given spurious counterexample, it does not guarantee the \nconvergence of our system on all typable programs.13 An interesting future research direction is to investi\u00adgate \na more complete approach to candidate generation.  9. Related Work 9.1 Inferring Dependent Types Inferring \ncomplex types via .xed-point type inference iteration is a classic idea. For instance, Freeman and Pfenning \n[14] infers the strongest re.nement types given a user-provided lattice of re.ne\u00adment types. The recent \nwork by Rondon et al. [33] can be casted as an instance of this approach to dependent types. Their system \nchooses a .nite set of candidate formulas by a syntactic scan of 12 Depcegar does not handle arithmetic \nover.ows. 13 However, it is trivial to show that the system is guaranteed to converge on programs with \nonly .nitary-data base types (e.g., just booleans). the program text and the user-provided set of formulas, \nand infers the strongest types within the lattice of dependent types con.ned to these formulas via .xed-point \niteration and theorem proving, sim\u00adilar to the .xed-point type inference phase of our system. Lacking \nautomatic re.nement, these approaches require the lattice of candi\u00addate types to be pre-de.ned and be \nof .nite height. In contrast, our system automatically infers candidate types within an in.nite do\u00admain \nof types (i.e., unbounded intersections and arbitrary formulas) via counterexample analysis. One advantage \nof our approach is that the type inference be\u00adcomes complete. That is, when the system declares the program \nto be untypable, the user is assured that it is actually untypable rather than wondering if more candidates \nwere needed. A conse\u00adquence of this is that the inferred types may not be the strongest. But, this is \ngenerally unavoidable as the strongest types may not even be .nitely expressible within the underlying \ntheory, as in, for example, the mult program from Figure 1. However, as remarked in Section 7, the system \ncan be made to infer types of the user\u00adspeci.ed strength. Concurrent to our work, Unno and Kobayashi \n[36] have pro\u00adposed to infer dependent types via interpolation and iterative un\u00adrolling of recursive \nconstraints. Chin et al. [6, 7] have also sug\u00adgested a constraint unrolling approach with the Omega test \n[32] as the backend solver. These approaches use neither candidate types nor a .xed-point type inference \nroutine, but they resemble the re\u00ad.nement phase of our work in that they also reduce the infer\u00adence problem \nto .nding a solution to a set of .rst-order logic con\u00adstraints. One issue with these purely constraint-based \napproaches is the presence of false constraint cycles like the one shown in Ex\u00adample 5.6.14 In contrast, \nour approach divides type inference into the .xed-point type inference phase and the constraint-solving \nre\u00ad.nement phase so that the latter is able to leverage unwinding and linear intersection types to ensure \nconstraint acyclicity. We note that none of the previous systems listed above supports unbounded intersection \ntypes. To the best of our knowledge, our system is the .rst dependent (or re.nement) type inference system \nthat can infer unbounded intersection types embedded with arbi\u00adtrary formulas from a .rst-order theory. \n 9.2 Inferring Intersection Types The success of our system owes much to intersection types. Not only \ndo intersection types make the underlying dependent type system more expressive by being able to type \nmore safe programs, they are also crucial to the re.nement phase of the system that uses linear intersection \ntype inference [21] to infer a derivation shape that is suf.cient for ensuring both type inference completeness \nand constraint acyclicity. Linear intersection type inference cannot be applied directly to programs \ncontaining recursive de.nitions as linear intersection types are not even de.ned for such programs. Our \napproach cir\u00adcumvents the issue by iteratively producing non-recursive program fragments as counterexamples, \nand then checking if the candidate types inferred for the fragments are also suf.cient for typing the \noriginal, recursive program. In our system, intersection types are restricted to only intersect types \nof the same simple-type shape, but intersection type inference algorithms are capable of inferring arbitrary \nintersection of types, as well as inferring principal typing [37], which we also do not utilize in this \nwork. We leave for future work to capitalize on the full potential of intersection type inference. 14 \nFor [6, 7], if extended to higher-order functions.  9.3 Model Checking Counterexample-guided abstraction \nre.nement has been used with great success in hardware and software model checking (see, e.g., [3, 9, \n16]). However, most of the existing software model checkers only target low-level imperative programs \nsuch as device drivers written in C, and are unsuitable for functional programs because they cannot accurately \nmodel higher-order functions and function closures. Recently, researchers have proposed model checking \nalgorithms for typed higher-order functional programs by leveraging their equivalence to higher-order \npushdown systems [24, 30]. However, these algorithms only handle .nite data domains, whereas our sys\u00adtem \nsupports in.nite data domains such as integers by utilizing an interpolating theorem prover. Interpolation \nhas found various applications in model checking, such as predicate abstraction [15, 18] and reachable \nstate approx\u00adimation [26, 28]. We have shown that interpolation is also quite effective for inferring \ndependent types. Algorithms for computing interpolants for various theories are actively being researched \n(e.g., [5, 8, 17, 20]). As future work, we plan to extend our system to other data types, such as lists \nand arrays, by using interpolating theorem provers for their theories.  10. Conclusion We have presented \na new approach to inferring dependent types. The key to the success is the iterative re.nement of candidate \nde\u00adpendent types via counterexample analysis, utilizing linear inter\u00adsection type inference and interpolation. \nWe have shown that the approach enables a sound and complete type inference of an ex\u00adpressive dependent \ntype system that allows unbounded intersection types embedding arbitrary formulas from a .rst order theory. \n References [1] L. Augustsson. Cayenne -a language with dependent types. In ICFP, pages 239 250, 1998. \n[2] T. Ball, O. Kupferman, and M. Sagiv. Leaping loops in the presence of abstraction. In CAV, pages \n491 503, 2007. [3] T. Ball and S. K. Rajamani. The SLAM project: debugging system software via static \nanalysis. In POPL, pages 1 3, 2002. [4] J. Bengtson, K. Bhargavan, C. Fournet, A. D. Gordon, and S. Maffeis. \nRe.nement types for secure implementations. In CSF, pages 17 32, 2008. [5] D. Beyer, D. Zufferey, and \nR. Majumdar. CSIsat: Interpolation for LA+EUF. In CAV, pages 304 308, 2008. [6] W.-N. Chin and S.-C. \nKhoo. Calculating sized types. Higher-Order and Symbolic Computation, 14(2-3):261 300, 2001. [7] W.-N. \nChin, S.-C. Khoo, and D. N. Xu. Extending sized type with collection analysis. In PEPM, pages 75 84, \n2003. [8] A. Cimatti, A. Griggio, and R. Sebastiani. Ef.cient interpolant gen\u00aderation in satis.ability \nmodulo theories. In TACAS, pages 397 412, 2008. [9] E. M.Clarke, O.Grumberg,S.Jha,Y.Lu,and H.Veith. Counterexample-guided \nabstraction re.nement. In CAV, pages 154 169, 2000. [10] J. Condit, M. Harren, Z. R. Anderson, D. Gay, \nand G. C. Necula. Dependent types for low-level programming. In ESOP, pages 520 535, 2007. [11] W. Craig. \nLinear reasoning. a new form of the Herbrand-Gentzen theorem. J. Symb. Log., 22(3):250 268, 1957. [12] \nC. Flanagan. Hybrid type checking. In POPL, pages 245 256, 2006. [13] C. Flanagan, A. Sabry, B. F. Duba, \nand M. Felleisen. The essence of compiling with continuations. In PLDI, pages 237 247, 1993. [14] T. \nFreeman and F. Pfenning. Re.nement types for ML. In PLDI, pages 268 277, 1991. [15] T. A. Henzinger, \nR. Jhala, R. Majumdar, and K. L. McMillan. Ab\u00adstractions from proofs. In POPL, pages 232 244, 2004. [16] \nT. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre. Lazy abstrac\u00adtion. In POPL, pages 58 70, 2002. \n[17] H. Jain, E. M. Clarke, and O. Grumberg. Ef.cient Craig interpolation for linear Diophantine (dis)equations \nand linear modular equations. In CAV, pages 254 267, 2008. [18] R. Jhala and K. L. McMillan. Interpolant-based \ntransition relation approximation. In CAV, pages 39 51, 2005. [19] T. Johnsson. Lambda lifting: Transforming \nprograms to recursive equations. In FPCA, pages 190 203, 1985. [20] D. Kapur, R. Majumdar, and C. G. \nZarba. Interpolation for data structures. In SIGSOFT FSE, pages 105 116, 2006. [21] A. J. Kfoury and \nJ. B. Wells. Principality and type inference for intersection types using expansion variables. Theor. \nComput. Sci., 311(1-3):1 70, 2004. [22] K. Knowles and C. Flanagan. Compositional reasoning and decidable \nchecking for dependent contract types. In PLPV, pages 27 38, 2009. [23] K. W. Knowles and C. Flanagan. \nType reconstruction for general re.nement types. In ESOP, pages 505 519, 2007. [24] N. Kobayashi. Types \nand higher-order recursion schemes for veri.ca\u00adtion of higher-order programs. In POPL, pages 416 428, \n2009. [25] D. Kroening and G. Weissenbacher. Counterexamples with loops for predicate abstraction. In \nCAV, pages 152 165, 2006. [26] K. L. McMillan. Interpolation and SAT-based model checking. In CAV, pages \n1 13, 2003. [27] K. L. McMillan. An interpolating theorem prover. Theor. Comput. Sci., 345(1):101 121, \n2005. [28] K. L. McMillan. Lazy abstraction with interpolants. In CAV, pages 123 136, 2006. [29] P. M. \nNeergaard and H. G. Mairson. Types, potency, and idempotency: why nonlinearity and amnesia make a type \nsystem work. In ICFP, pages 138 149, 2004. [30] C.-H. L. Ong. On model-checking trees generated by higher-order \nrecursion schemes. In LICS, pages 81 90, 2006. [31] X. Ou, G. Tan, Y. Mandelbaum, and D. Walker. Dynamic \ntyping with dependent types. In IFIP TCS, pages 437 450, 2004. [32] W. Pugh. The Omega test: a fast and \npractical integer programming algorithm for dependence analysis. In SC, pages 4 13, 1991. [33] P. M. \nRondon, M. Kawaguchi, and R. Jhala. Liquid types. In PLDI, pages 159 169, 2008. [34] R. Statman. The \ntyped lambda-calculus is not elementary recursive. Theor. Comput. Sci., 9:73 81, 1979. [35] T. Terauchi. \nDependent types from counterexamples, 2009. http://www.kb.ecei.tohoku.ac.jp/~terauchi/. [36] H. Unno \nand N. Kobayashi. Dependent type inference with inter\u00adpolants. In PPDP, pages 277 288, 2009. [37] J. \nB. Wells. The essence of principal typings. In ICALP, pages 913 925, 2002. [38] H. Xi and F. Pfenning. \nDependent types in practical programming. In POPL, pages 214 227, 1999.  \n\t\t\t", "proc_id": "1706299", "abstract": "<p>Motivated by recent research in abstract model checking, we present a new approach to inferring dependent types. Unlike many of the existing approaches, our approach does not rely on programmers to supply the candidate (or the correct) types for the recursive functions and instead does counterexample-guided refinement to automatically generate the set of candidate dependent types. The main idea is to extend the classical fixed-point type inference routine to return a counterexample if the program is found untypable with the current set of candidate types. Then, an interpolating theorem prover is used to validate the counterexample as a real type error or generate additional candidate dependent types to refute the spurious counterexample. The process is repeated until either a real type error is found or sufficient candidates are generated to prove the program typable. Our system makes non-trivial use of \"linear\" intersection types in the refinement phase.</p> <p>The paper presents the type inference system and reports on the experience with a prototype implementation that infers dependent types for a subset of the Ocaml language. The implementation infers dependent types containing predicates from the quantifier-free theory of linear arithmetic and equality with uninterpreted function symbols.</p>", "authors": [{"name": "Tachio Terauchi", "author_profile_id": "81100563652", "affiliation": "Tohoku University, Sendai, Japan", "person_id": "P1911052", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706315", "year": "2010", "article_id": "1706315", "conference": "POPL", "title": "Dependent types from counterexamples", "url": "http://dl.acm.org/citation.cfm?id=1706315"}