{"article_publication_date": "01-17-2010", "fulltext": "\n Threesomes,With andWithout Blame * Jeremy G. Siek Philip Wadler University of Colorado at Boulder University \nof Edinburgh jeremy.siek@colorado.edu wadler@inf.ed.ac.uk Abstract How to integrate static and dynamic \ntypes? Recent work focuses on casts to mediate between the two. However, adding casts may degrade tail \ncalls intoanon-tail calls, increasing space consumption from constant to linear in the depth of calls. \nWe present a new solution to this old problem, based on the notionofa threesome.Acastis speci.edbya sourceandatarget \ntype atwosome.Anytwosomefactors intoadowncast fromthe source to an intermediate type, followed by an \nupcast from the intermediate to the target a threesome. Anychain of threesomes collapses to a single \nthreesome, calculated by taking the greatest lower bound of the intermediate types.We augment this solution \nwith blame labels to map any failure of a threesome back to the offending twosome in the source program. \nHerman, Tomb, and Flanagan (2007) solve the space prob\u00adlem by representing casts with the coercion calculus \nof Henglein (1994). While they provide a theoretical limit on the space over\u00adhead, there remains the \npractical question of how best to imple\u00adment coercion reduction. The threesomes presented in this paper \nprovide a streamlined data structure and algorithm for represent\u00ading and normalizing coercions. Furthermore, \nthreesomes provide a typed-based explanation of coercion reduction. Categories and Subject Descriptors \nD.3.3[Language Constructs and Features]: Procedures, functions, and subroutines GeneralTerms Languages, \nTheory Keywords casts, coercions, blame tracking, lambda-calculus 1. Introduction The old question of \nhowto mix static and dynamic typing is attract\u00ading renewed interest. On one side, Hejlsberg (2008) brings \ntype dynamic to C# 4.0, and on the other side, Tobin-Hochstadt and Felleisen (2008) integrate static \ntypes into Scheme andWall (2009) adds optional static types to Perl 6. In these mixed settings, pro\u00adgrammers \nand compilers should still be able to trust the results of the static type checker, so run-time checks \nare needed to safeguard the invariants established by the static type system. Recent work mediates between \nstatic and dynamic regions using casts. * Apreliminary version of this paper appeared in the informal \nproceedings ofthe2009WorkshoponScriptto ProgramEvolution. Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page.To copyotherwise, to republish, to post on servers or to redistribute to lists, \nrequires prior speci.c permission and/or a fee. POPL 10, January 17 23, 2010, Madrid, Spain. Copyright \nc . 2010ACM 978-1-60558-479-9/10/01... $10.00 Building on the higher-order contracts of Findler and \nFelleisen (2002), Wadler and Findler (2009) design the blame calculus to serveas an intermediate language \nthat integrates static and dynamic typing. The blame calculus earns its name by tracking blame: it maps \nrun-time type errors back to their origin in the source program. The Blame Theorem asserts that statically \ntyped regions of a program can never be blamed for run-time type errors. However, there is concern that \nthe casts used in the blame calculus impose too much run-timeoverhead. Findler and Felleisen (2002) observed \nthat contractsmaydegradeatail call intoanon-tail call and Herman et al. (2007) noted that the same is \ntrue for casts. This concern prompted the ECMAScript 4.0 committee (Hansen 2007) and the designers of \nThorn (Wrigstad et al. 2009) to consider compromises such as like types that do not require casts. Herman \net al. (2007) use the coercion calculus of Henglein (1992, 1994) to represent and compress sequences \nof casts. Any coercion normalizestoacoercionof bounded size, thereby limiting the run-timespaceoverheadtoa \nconstantfactor.Sieketal.(2009) augment the coercion calculus with blame tracking to obtain a space-ef.cient \nimplementation of the blame calculus. In this paper we present a new solution to the space problem, basedonthe \nnotionofathreesome.Traditionally,acastis speci.ed by a source and a target type a twosome. We show that \nany twosomefactorsintoadowncastfromthe sourcetoan intermediate type, followed by an upcast from the intermediate \nto the target a threesome.Wealsoshowthatanychainof threesomes collapsesto asingle threesome,calculatedbytakingthe \ngreatestlower boundof the intermediate types.We thenaugment this solution with blame labelssoastomapanyfailureofa \nthreesomebacktotheoffending twosome in the source program. Threesomes are designed to correspond to twosomes \nand two\u00adsomes are designed to correspond to Henglein s coercions. So it is not surprising that threesomes \ncorrespond to Henglein s coer\u00adcions. Nonetheless, it is a pleasant validation of our design that threesomes \nturn out to be exactly isomorphic to Henglein s coer\u00adcions in normal form. Coercion normalization is \nan iterative pro\u00adcess, whereas composition of threesomes is a direct recursive de.\u00adnition. Thus, we believe \nthat the alternative view offered by three\u00adsomesmaymakepossibleamoreef.cient implementationthanone based \ndirectly on the coercion calculus. The rest of the paper begins with a review of the blame calcu\u00adlus \n(Section 2). Then, tofactor the presentation of the threesome calculus, we present a simpli.ed version \nthat captures the main in\u00adtuitions and detects castfailures appropriately,but does not track blame (Section3).Weprovethatthe \nsimpli.edversionis correct and spaceef.cient. Section4presents the complete threesome cal\u00adculus with \nsupport for blame tracking and proves that it is correct (equivalent to the blame calculus). Section5shows \nthat the three\u00adsome calculus is isomorphic to a coercion-based calculus of Siek et al. (2009). Some of \nthe proofs are in-line and the rest are in the Appendix.Weexplain the relationship between our results \nand prior work in Section 6. 2. Twosomes m = m. If a program halts with blame m, the term contained \nin\u00adside the cast labeled m failed to produce a value of the appropriate The de.nition of the blame calculus \n(minus subset types) is shown type.Ifa program halts with blame m, the context surrounding the in Figure \n1. This blame calculus is the simply-typed lambda calcu\u00adcast labeled m misused the cast value, that is, \napplied it to a value lusextended with the dynamic type, written *,andcastsofthe form of an inappropriate \ntype. .S.s.We sometimes elide the blame label l onacast when the label is not relevant. The meta-variable \nx ranges over variables, k l .*..*.Bool .*..* mm .T The blame calculus checks higher-order casts lazily, \nreporting blame for an incompatible cast on a function only when the func\u00adover constants, and B over \nbase types (such as Int and Bool).We tionis applied.Forexample, give function application higher precedence \nthan casts. The meta\u00ad variablesl,m and n rangeover blame labels.Inan implementation, let g = .Int . Int \nblame labelswouldnotbe visibletothe programmer,butwouldbe inserted automatically by the parser and would \nprovide access to information such as the location of the cast in the source program. The dynamic semantics \nof the cast is straightforward in the case of .rst-order values such as integers: the run-time check \neither succeeds and the cast acts like the identity function, or the check fails and the downcast is \nblamed. .Int.4 .-. .Int .Int.4 .-. 4 m l .Int .Bool . Bool.f willfail onlyif g is applied. Thisis achievedby \ntesting for shallow incompatibility between types.We write S # T to indicate shallow n incompatibility. \nDistinct base types are shallowly incompatible, a function is shallowly incompatible with anybase type, \nand the type . is shallowly incompatible with anytype. In the de.nition of values, we add a side condition \non values of in \u00b7\u00b7\u00b7 the form .S. . T . l . S . T .v.We require that not all S, T, S. and T . be * because \notherwise rule (3) would apply. , .Int.4 .-. .Bool .Int.4 .-. blame m Higher-Order Casts The semantics \nof casts is more subtle in the case of higher-order values such as functions. The complication is that \none cannot immediately check whether a function respects the targettypeofthe cast.Intheexamplebelow,whenthe \nfunction f of type Int.* is cast to Int.Int, there is no way to immediately tell if the function will \nreturn an integer every time it is called. .Int.2 m m l letf =(.x:Int. if In this paper we restrict our \nattention to lazy checking. Siek et al. (2009) discuss other design points, such as eager checking (where \nany incompatibility is reported as soon as possible). An initial assessment indicates that it would be \nstraightforward to apply the techniques in this paper to the other designs. Space Ef.ciency Herman et \nal. (2007) observe two circum\u00adstances where the wrappers used for higher-order casts can lead to unbounded \nspace consumption. First, some programs repeatedly apply caststothe same function, resultinginabuild-upof \nwrap\u00ad 0 = x then .* .Bool.true) l pers. In the following example, a wrapper is added each time the .* \nelse in function bound to k is passed between even and odd, causing a .Int . *.f So long as g is only \ncalled with non-negativenumbers, the behavior of f respects the cast. If g isever called withanegativenumber, \nthe return value of f will induce a cast error. The standard solution defers the check until the function \nis appliedto an argument. Whena function passes througha cast, the castis not reducedbut remains asa \nwrapper around the function. When the cast-wrapped function is applied to a value, then the n cast is \ndistributed to the argument and result as speci.ed by the following reduction rule. Note that the direction \nof the cast on the argument is .ipped, as usual. (Also the blame label of the cast on the argument is \nnegated; we discuss this further below.) .Int . Int let in g= ... space leak proportional to n. let \nrec even(n : Int, k : *.Bool) : Bool = if (n=0) then k(.*.Bool.true) else odd(n -1, .Bool.Bool .*.Bool.k) \n and odd(n : Int, k : Bool.Bool) : Bool = if (n = 0) then k(false) else even(n -1, .*.Bool .Bool.Bool.k) \n Second, some casts break tail recursion. Consider the following example in which the return type of \neven is * and odd is Bool. let rec even(n : Int) : * = if(n= 0)then .*.Bool.true else .*.Bool.odd(n \n-1) l l .T . v(.S .S BlameTracking Because a higher-order cast is not checked im-if (n = 0) then false \nmediately, it might fail at a location far removed from where it else .Bool .*.even(n -1) was originally \napplied. Continuing the above example, the cast- Assuming tail call optimization, cast-free versions \nof the evenwrapped function bound to g may be applied at some point much and odd functions require only \nconstant space. However, with the later in the program. presence of casts, the calls to even and odd \nare not tail calls, so l...-.. ST ) Tvw (.S .T .w) and odd(n : Int) : Bool = the run-time stack grows \nwith each call and space consumption is n .Int . *.f proportional to n. The following reduction sequence \nfor a call to (-1) \u00b7\u00b7\u00b7 .Int . Int let in g= \u00b7\u00b7\u00b7 g even shows the unbounded growth. Blame tracking helps \nto diagnose such failures by mapping cast failures back to their origin in the source program. The above \nexample reduces to blame n, indicating that the cast surrounding f caused the failure. Figure 1 shows \nthe reduction rules we use in this paper. The formulation here differs in minor ways from the rules ofWadler \nand Findler (2009) that will prove technically convenient. The most signi.cant changes are that we allow \ncasts between any two types, even if they are not compatible; and we introduce an empty type ., such \nthat no value has type . and . is incompatible with every type. Blame labels come equipped witha negation \noperator thatis an involution. That is, if m is a blame label then m is its negation and even(n) .-. \n.* . Bool.odd(n - 1) .-. .* . Bool..Bool . *.even(n - 2) .-. .* . Bool..Bool . *..* . Bool.odd(n - 3) \n.-. \u00b7 \u00b7 \u00b7 Herman et al. (2007) recover space ef.ciencyin a cast calculus without blame by 1) using the \ncoercion calculus (Henglein 1994) to compactly represent sequences of casts, and 2) normalizing sequences \nof coercions that appear in tail-position before making function calls. Siek et al. (2009) extend this \nwork by integrating blame tracking into the coercion calculus, thereby achieving a Syntax types R, S, \nT, U ::= B | S.T | * |. terms s, t ::= k | x | .x: S.t | st | l .T .S.s ground types G, H ::= B | *.* \nl values v, w ::= k | .x :S.t | .* .G.v | l .S. . T . .S . T .v contractums r ::= t | blame l l eval. \ncontexts E ::= . | Et | vE |.T .S.E AdditionalTyping Rules G . t : T G . s : S l G ..T .S.s : T Shallow \nIncompatibility S # T = B. B . B # B. B # T .T . T .T . # B . # T T # . Reductions s -. r (.x : S. t) \nv -. [x := v]t (1) kk. -. d(k, k.) (2) l .G .G.v -. v (3) l .*.*.v -. v (4) mlm .H .*..* .G.v -. .H .G.v \n(5) lll .*.S.T .v -. .* .*.*..*.* .S.T .v if S . T .(6) = *.* lll .S.T .*.v -. .S.T .*.*..*.* .*.v if \nS.T .(7) = *.* .. l. ll (.S.T .S.T .v) w -. .T .T . v(.S .S..w) if not S.T = S..T . = *.* (8) l .T .S.v \n-. blame l if S # T (9) Single-step evaluation s .-. r t -. t. t -. blame l E[t] .-. E[t.] E[t] .-. blame \nl Figure 1. Twosomes space-ef.cient implementation of the blame calculus. In this paper we explore an \nalternative based on threesomes. 3. ThreesomesWithout Blame The goal of the threesome calculus is to \nachieve space ef.ciency while maintaining the high-level nature of the blame calculus, that is, expressing \ncasts with types. The key to space ef.ciency is to compress sequences of casts while maintaining the \nsame behav\u00adior. There are two aspects to the behavior of a cast: 1) detecting castfailuresand2) allocating \nblametothe appropriate castinthe source program. In this section we describe a simpli.ed version of the \nthreesome calculus that focuses on detecting cast failures. In relating the simpli.ed threesome calculus \nto the blame calculus, we ignore all blame labels in the blame calculus. In Section4 we present the complete \nthreesome calculus with blame tracking. When discussing a sequence of casts, we abbreviate .Tn . Tn-1.\u00b7\u00b7\u00b7.T3 \n. T2..T2 . T1. as follows to avoid repeating types. .Tn . Tn-1 \u00b7\u00b7\u00b7 T3 . T2 . T1. Towards understanding \nhow to compress casts, consider the following sequence: .*.* . Bool .* . *.Int . *.*. This sequence, \nwhen applied to a function, forces the function to accept an argument of type Bool and to return a result \nof type Int; anyother argument or result induces an error. Thus, the above se\u00adquence of casts is equivalent \nto just two casts where the intermedi\u00adate type is Bool . Int. .*.* . Bool .Int . *.*. The type Bool \n. Int represents a stronger cast, one that is more likelytofail,than eitherofthetwointermediatetypesinthe \noriginal sequence.This notionof strongeris capturedbythe naive subtyping relation, written <:n, of Wadler \nand Findler (2007) (de.ned in Figure 2); similar relations include the . ordering on coercions of Henglein \n(1994) and the .. ordering on retracts of Scott (1976). Ourideaisto compressa sequenceofcastintojusttwocastswhere \nthe intermediate type is the greatest lower bound of the types in the original sequence. Naive subtyping \nis covariant in the domain of function types instead of contravariant like ordinary subtyping. It is \ninteresting to compare taking the greatest lower bound with respect to naive subtyping versus ordinary \nsubtyping. In the above example, with naive, covariant subtyping we have Bool . Int <:n *. Int <:n *.* \nBool . Int <:n Bool .* <:n *.*  and so the greatest lower bound of the original casts with regard to \n<:n is Bool . Int, which has the desired effect. In contrast, with ordinary, contravariant subtyping \n(written <:)we have *. Int <: *.* <: Bool .* So the greatest lower bound of the original casts with \nregard to <: is *. Int. Using this as the intermediate type gives a different collapsed cast .*.* . *.Int \n. *.*. But this cast is too lenient; it correctly requires the result to be Int but does not require \nthe argument to beBool. We write S &#38; T for the greatest lower bound of S and T with respect to <:n; \nwe also sometimes call this the meet of S and T . In general, an arbitrary sequence of casts can collapse \nto a contextually equivalent pair of casts where the intermediate type is the meet of all the types in \nthe sequence, so .Tn . Tn-1 . \u00b7 \u00b7\u00b7 . T2 . T1.t is equivalent to .Tn . Tn &#38; Tn-1 &#38; \u00b7\u00b7\u00b7 &#38; \nT2 &#38; T1 . T1.t We introducea special notation for castsof this kind.For anythree types R, S, T with \nR<:n S and R<:n T , and anyterm t of type S, we write R .T .= S.t and call it a threesome. It is equivalent \nto the pair of casts .T .R..R .S.t The syntaxofthe threesome calculus without blameisgiveninFig\u00adure \n2. Analogously to the side condition on values for twosomes, we require that in a value of the form .T \n. T . R.= R. S . S..u, . not all of T,T ., R, R.,S and S. can be *. Greatest lower bounds can be computed \nby the algorithm for S &#38; T de.ned in Figure 2. The algorithm is straightforward: the meet of identical \nbase types is that base type, of two function types is a function from the meet of the domains to the \nmeet of the ranges, of anytype with * is the other type, and of anyshallowly incompatible types is .. \nNote that the greatest lower bound always exists thanks to the inclusion of the emptytype .. Since S \n&#38; T is symmetric,the readermaywonderwhywe write T &#38;S in the clause for function types; thisis \nforeshadowing modi.cations requiredin the next section for tracking blame. Our .rst result is to con.rm \nthat the algorithm in Figure 2 computes greatest lower bounds. Proposition1 (Meet algorithm returns the \ngreatest lower bound). 1. S &#38; T<:n S and S &#38; T<:n T 2. If R<:n S and R<:n T , then R<:n S &#38; \nT .  The operational semantics of the threesome calculus is given in Figure 2. Most of the reduction \nrules are a straightforward adapta\u00adtionfromtwosomesto threesomes.Forexample,rule(13)isequiv\u00adalent to \ntwo applications of rule (3) from the blame calculus. The main difference is the addition of rule (16), \nwhich is responsible for compressingapairof threesomesintoasingle threesomebytaking the meet of the two \nintermediate types. The source and target types of a threesome do not play a role in the reduction rules \nand could be erasedbut their presence streamlines the meta-theorybygiving us unicity of types. To make \nsure that sequences of casts do not accumulate in tail position, we change evaluation contexts to recognize \nsequences of casts that need to be compressed. Our evaluation strategy reduces sequences outside-in, \nrepeatedly compressing the two outermost casts in a sequence. An F context represents a location that \nis not immediately insidea cast(F is for cast free ), which indicates an appropriate location to apply \na cast-reducing rule. The context E includes both the F contexts and contexts containing sequences of \ncasts with length at most one. This formulation of evaluation contexts differs from the con\u00adtexts used \nin Herman et al. (2007). Unique decomposition does not hold for their contexts, for example, in a sequence \nof three casts, either the outer two or the inner two can be merged. However, be\u00adcause the coercion calculus \nis con.uent, the lack of unique decom\u00adposition does not pose a serious problem. Nevertheless, we prefer \nto use evaluation contexts that ensure a unique decomposition. Proposition2 (Unique Decomposition). For \na well-typed closed t, either t is a value or there is a unique decomposition into a redex t. and an \nevaluation context E such that t = E[t.]. Thevaluesofthe threesome calculusdifferinan importantway from \nthe blame calculus, which re.ects the improved space ef.\u00adciency. In the blame calculus, a value of type \nT . T . may contain an arbitrary number of outermost casts. In the threesome calculus, a value of type \nT . T . may contain at most one outermost cast. Lemma1 (CanonicalForms). 1. If \u00d8. v : B, then v is a \nconstant. 2. If \u00d8. v : T . T ., then v has one of the following forms: k,  .x :S.t, or .T . T . R..= \nR. S . S..u. 3. If \u00d8. v : *, then v has the form .*.R= S.u. 4. No value has type ..  Proof. The proofs \nare by case analysis on v and inversion on the typing rules. Syntax terms s, t ::= k | x | .x : S.t \n| st |.T .R=S.s uncoerced val. u ::= k | .x:S. t values v, w ::= u | .* .R= S.u | .T . T . R.R. .= S \n. S..u contractums r ::= t | blame cast-free contexts F ::= . | E[. t] | E[v .] eval. contexts E ::= \nF | F [.T .R=S..]  Naive subtyping S<:n T S<:n T<:n S. T . B<:n B S<:n *. <:n T S . S. <:n T . T . \n Additional typing rules G . t : T G . s : S R<:n S R<:n T R G ..T .=S.s : T Meet algorithm (computes \nthe greatest lower bound) S &#38; T * &#38; T = T S &#38; * = S B &#38; B = B (S . S.)&#38;(T . T .)=(T \n&#38; S) . (S. &#38; T .) S &#38; T = . if S # T Reductions t -. t (.x : S.t) v -. [x := v]t (10) kk. \n-. d(k, k.) (11) . R.R. .. R. .R (.T .T .= S.S.u) w -. .T .= S.u (.S .=T .w) if not T .T = R.R= S.S= \n*.* (12) Cast reductions t -.c r .G.G=G.u -.c u (13) .*.* =*.u -.c u (14) .T ..=S.u -.c blame (15) R. \n.. RR.&#38;R .T .=S..S.= S.s -.c .T .= S.s (16) Single-step evaluation t .-. r t -. t. t -.c t. t -.c \nblame E[t] .-. E[t.] F [e] .-. F [t.] F [t] .-. blame Figure 2. Threesomes without blame 3.1 Correspondence \nBetweenTwosomes and Threesomes We translate from the blame calculus to the threesome calculus by mapping \ncasts of the form .T . S.s to .T T.&#38;= S S.s. The def\u00adinitions for compiling twosomes to threesomes, \nand decompiling threesomes to twosomes, written ..t.. and ..t..-1 respectively, are given in Figure 3. \nThe proof that the threesomes calculus without blame is equiv\u00adalent to the blame calculus (ignoring blame \nlabels) hinges on two facts. First, the cast.T . S. is equivalent to .T . T &#38; S . S.. This is necessary \nto justify the compilation from twosomes to three\u00adsomes. Second, .T . R. . S. . R . S. is equivalent \nto ..t.. = t ..t..-1 = t Compilation from twosomes to threesomes ..x.. = x ..k.. = k ...x : S. t.. = \n.x : S. ..t.. ..ts.. = ..t.. ..s.. T &#38;S ...T .S.s.. = .T .= S...s.. Decompilation from threesomes \nto twosomes ..x..-1 = x ..k..-1 = k ...x : S. t..-1 = .x : S. ..t..-1 ..ts..-1 = ..t..-1 ..s..-1 ...T \n.R= S.s.. -1 = .T .R..R .S...s..-1 Figure 3. From twosomes to threesomes and back again. .T . R. &#38; \nR . S. provided R. <:n T , R. <:n S. , R<:n S. , and R<:n S. Thisfact is necessary to justify the threesome \nre\u00adduction rule (16), which compresses two threesomes. Both of these facts are corollaries of the following \nfundamental lemma. In a se\u00adquence .T . R . S., it is safe to bypass R if going from S &#38; T to R is \nan upcast. Towards formalizing this in terms of contextual equivalence, we de.ne contexts and results \nas follows. contexts C ::= . | Ct | tC | .x:S. C |.T .S.C results f ::= v | blame Aprogramt is said to \nconverge,writtent .,if.f. t .-. * f,where .-. * is the re.exive, transitive closure of .-.. These de.nitions \nfor twosomes carry over easily to the threesome calculus. De.nition 1. A term t is contextually equivalent \nto another term t., written t = ctx t., if for any context C, C[t] . iff C[t.] .. Lemma2 (Fundamental \nProperty of Casts). If T &#38; S<:n R, then .T . R . S.t = ctx .T . S.t. The proof of the fundamental \nproperty of casts is in the Ap\u00adpendix.Withthis propertyinhandwecanprovethetwokeyfacts. Corollary 1. 1. \n.T . S.s = ctx .T . T &#38; S . S.s, and 2. .T . R. . S. . R . S.s = ctx .T . R. &#38; R . S. provided \nR. <:n T , R. <:n S. , R<:n S., and R<:n S.  Proof. 1. Note that subtyping is re.exive and then apply \nthe fundamental property of casts. 2. To prove the second part, we apply the fundamental property of \ncasts several times as follows.  .T . R. . S. . R . S.s = ctx .T . R. . R . S.s = ctx .T . R. . R. &#38; \nR . R . S.s = ctx .T . R. &#38; R . R . S.s = ctx .T . R. &#38; R . S.s Weneedafew morefacts beforeprovingthe \ncorrectness theorem. Lemma 3. t = ctx ....t....-1 . Proof. The proof is by induction on t. The case for \ncasts relies on Corollary1(part 1). Lemma 4. . .-1 1. If t = ctx ..t3..-1 and t3 .-. * t3, then t = \nctx ..t3... 2. If t3 = ctx ..t.. and t .-. * t., then t3 = ctx ..t....  Proof. 1. Theproofisby inductionon \nt3 .-. * t3 . andby cases on -.. The case for rule (16) relies on Corollary1(part 2). The other cases \nrely on thefact t .-. t. implies t = ctx t. . 2. The proof is by induction on t .-. * t. and by cases \non -.. The cases rely on Lemma 2 and the fact t3 .-. t. 3 implies t3 = ctx t3. Applying compilation \nor decompilation to results produces terms that converge. Lemma 5. ..f.. . and ..f3..-1 .. Proof. The \nproofs areby induction on f and f3. We can now state and prove the correctness theorem. Theorem1 (Correctness \nof the threesome calculus without blame). ..t.. . if and only if t .. Proof. By Lemma3 wehave t = ctx \n....t....-1 . 1. (=.) Wehaveanf3 such that ..t.. .-. * f3. ThenbyLemma4 (part 1) we have t = ctx ..f3..-1. \nThenby Lemma5, t .. 2. (.=) We have an f such that t .-. * f. Thenby Lemma4 (part 2) we have ..t.. = \nctx ..f... Thenby Lemma5, ..t.. ..  3.2 Space Ef.ciency The main task in bounding the size of casts \nduring execution is to putaboundontheresultofmergingtwo casts.The approachtaken byHermanetal.(2007)forthe \ncoercion calculusistoshowthatthe height of a composed coercion is no greater than the height of the two \ncoercions. Then, because normalized coercions are trees with limited branching,itfollowsthatthesizeofthe \ncomposed coercion is bounded by roughly 2h where h is the height. We obtain a tighter bound for the threesome \ncalculus that takes into account that when two casts are composed, there is often con\u00adsiderable overlap \nbetween the two intermediate types, and there\u00adfore the resulting size of the new intermediate type is \nnot much larger. (We take the size of a type to be the number of nodes in the type when considered as \nan abstract syntax tree.)A strawman for the bound is the size of the greatest lower bound of all the \ntypes that occur in the program. The problem with this strawman is that the greatest lower bound of two \ntypes can sometimes be smaller, thereby not providing an upper bound on size.Forexam\u00adple, Int &#38;(*.*)= \n.. Instead we need to take the maximum ofthe structureofthetwo types.To accomplishthiswemap types to \ntheir shadow, written .T ., and then compute the greatest lower bound.We de.ne the shadowofa type as \nfollows. .B. = * .S . T . = .S...T . .*. = * ... = * With the previous example, we have.Int. &#38; .* \n. *. = *.*. Proposition3 (Properties of shadows). 1. size(T )= size(.T .). 2. If R<:n .S. and R<:n .T \n. then R<:n .S &#38; T .. 3. If .S. <:n .T ., then size(.T .) = size(.S.).   Weprovethat the sizes \nof types in the program during reduction are bounded above by the greatest lower bound of the shadows \nof the types in the original program. The main lemma below shows that the greatest lower bound remains \na lower bound during reduc\u00adtion.We can then apply the above property3to show that the size of the greatestlower \nbound is an upper bound on the size of any typein the program.Towards formally stating these properties, \nwe give the following de.nitions. T . t = type T syntactically occurs in term t .t. = {.T .| T . t} S<:n \nT =.T .T .S<:n T &#38;{T1,...,Tn}= T1&#38; \u00b7\u00b7\u00b7 &#38;Tn Lemma6 (Preservation of lower bounds). If T<:n \n.t., and t -. t., then T<:n .t... Lemma7 (Preservation of compilation). If T<:n .t., then T<:n ...t.... \nTheorem2 (Bound on size of types and therefore casts). If ..t.. -. * t., then for any T . t. , size(T \n) = size(&#38;.t.). Let |t| be the term t with all the casts erased. The size of a threesome program \nduring execution does not differ by more than a constantfactor compared to itself with all the casts \nerased. Theorem3 (Space ef.ciency). For any program t, if t -. * t., then size(t .) = size(&#38;.t.) \n\u00b7 size(|t .|). Proof. The proof is essentially the same as in Herman et al. (2007), except we use Theorem2for \nthe bound on the sizeof types. 4. Threesomes with Blame In the previous section we showed that a simpli.ed \nthreesome calculus implements the blame calculus ignoring blame labels.We now turn our attention to adding \ncorrect blame allocation to the threesome calculus. Consider what would happen if we were to naively \nadd blame labels to threesome casts, say, writing the blame label next to the intermediate type. When \nmerging two casts, we would need to choose between label m and l. U,m. R,lU&#38;R,n .T .=S...S.= S.s \n-. .T .= S.s Should n be m or l? Unfortunately, either choice is wrong. Con\u00adsider the following example \nin which different casts within the same sequence are allocated blame. lnm g = .f : *. * . .*.* . Bool.* \n. *.Bool . *.*.f op g (.x : *. .*.Int.1) .*.Bool.true -. * blame m o g (.x : *.x) .*.Int.1 -. * blame \nl Having just one blame label per cast is not enough. The solution we propose is to incorporate blame \nlabels into the intermediate type of a threesome. The above function g is then represented in the threesome \ncalculus as follows. Booll..Boolm g = .f : *.*. .*.* .= * . *.f The label on the codomain of the intermediate \ntype is m because cast m is the .rst (from right to left) to project from * to Bool in the codomain. \nThe label on the domain is l because cast l isthe .rst (from left to right) to project from * to Bool. \nThe function type itself is given the empty label . because in this sequence of casts, the function type \ncannot induce blame. The de.nition of the threesome calculus with blame is given in Figure 4. The erasure \nof a labeled type P to a type is written |P |. Syntax optional labels p, q ::= l | . labeled types P, \nQ ::= Bp | P .p Q |* |.lGp terms s, t ::= k | x | .x:S.t | st | P .T .= S.s values v, w ::= u | .* .P= \nS.u | .S. . T . P ..Q .= S . T .u contractums r ::= t | blame l cast-free contexts F ::= . | E[. t] \n| E[v .] evaluation contexts E ::= F | F [.T .P= S..] Additional typing rules G . t : T G . s : S |P \n| <:n S |P | <:n T P G ..T .=S.s : T Composition Q . P Bq . Bp = Bp P .* = P *. P = P Hm Gp = .mGp Q. \nP . if G = H Q ..mGp = .mGp .mGq Gp = .mGp . P .mHl Gp = .lGp . P if G =.H (P ..qQ.) . (P .pQ)=(P . P \n.) .p (Q. . Q) Reductions s -. r (.x : S.t) v -. [x := v]t (17) kk. -. d(k, k.) (18) P . . P ..P . ...P \n(.T .T .= S.S.u) w -. .T .= S.u (.S .=T .w) if not T .T . = |P ..P .| = S.S. = *.* (19) Cast reductions \nt -.c r G. .G.= G.u -.c u (20) .*.* =*.u -.c u (21) .lG. .T .= S.u -.c blame l (22) Q.. PQ.P .T .=S..S.= \nS.s -.c .T .= S.s (23) Single-step evaluation t .-. r t -. t. t -.c t. t -.c blame l E[t] .-. E[t.] F \n[e] .-. F [t.] F [t] .-. blame l Figure 4. Threesomes with blame We require that in a value of the form.S. \n. T . P .= .Q S . T .u, . not all of S.,T ., P, Q, S, and T can be *. Next we discuss the semantics \nof the threesome calculus.With the addition of blame labels, we must replace the meet operator with something \nthat takes blame into account. The orderoffailure becomes observable so the operator is no longer symmetric. \nThus, we call the new operator composition and use the symbol .. Before giving the de.nition of the composition \noperator, we establish some auxiliary notation.We write gnd(P )= Gp, where G is the ground type that \nis shallowly compatible with |P |, and p is the topmost blame label in P . gnd(Bp)= Bp gnd(P .p Q)=(*.*)p \nIn patterns, we write P Gp to indicate that P is a labeled type with gnd(P )= Gp. The composition of \nlabeled types is de.ned in Figure 4. In general, the label on the right-hand type takes precedence over \nthe left-hand type. This is because the right-hand type induces a cast error before the left-hand side. \nThe composition of two function types is a function type whose blame label is taken from the right-hand \nfunction type, whose range is the composition of the ranges of the two function types and whose domain \nis the reverse composition of the domains. This reversal mimics the contravariant behavior of function \ncasts in the blame calculus; see rule (8). Our treatment of the labeled bottom type .lGp deserves some \nexplanation.We initially tried to label bottom types witha single label, as in .l. However, that approachfails \nto capture the correct blame tracking behavior. Consider the following examples. lmno .Int .* . Bool \n.* . Int.1 -. blame n lmno .Int .* . Bool .* . Bool.true -. blame l Recallthat in the threesome calculus, \ncasts are merged outside-in. The two outermost casts would be merged into cast with middle type .l. For \nthe next merge, we could choose to produce either .l or .n. However, either choice would be wrong for \none of the aboveexamples.Our solutionistolabel bottomtypeswithnotonly a label, but also with a labeled \nground type. So in this case, the second merge results in .lBooln . One might wonder whythe bottom type \nonly needs to remem\u00adbertwo labelsandnot more.Aclose inspectionofthe composition rules dealing with bottom \nreveals whythis is the case. When com\u00adposing .mHq with a labeled type P Gp on the right, either H is \nequal G, so p overshadows q and the result is .mGp, or H is not equal to G,andwehaveanew castfailurethat \nneedsto blame q. So we can forget the label m and the result is .qGp The following proposition expresses \nthe relationship between composition and meet. Proposition 4. |Q . P | = |Q| &#38; |P | The main difference \nbetween the reduction rules for the three\u00adsome calculus, shown in Figure 4, and the rules for the simpli.ed \ncalculus is the use of the composition operator . in place of the meet operator &#38; in rule (23). \n4.1 Correspondence BetweenTwosomes and Threesomes The compilation of the blame calculus to the threesome \ncalculus, written ..t.., is given in Figure 5. The case for casts is a bit more complicated than for \nthe simpli.ed calculus in that we must also de.ne how to propagate labels into the intermediate type; \nfunction l ..T . S.. performs this duty and is de.ned in Figure 5. Its de.nition is straightforward, \nthough two things are worth pointing out. The label is negated when going under the left-hand side of \na function type and we put the empty label . on types in situations where the cast could not produce \nblame, such asidentity casts and l injections. The following is the relationship between ..T . S.. and \nmeet. l Proposition 5. |..T . S..| = T &#38; S. With the addition of blame labels, it is not as straightforward \nto establish the equivalence between the threesome calculus and the blame calculus because we can no \nlonger merge casts in the blame calculus itself. However, we are able to construct a bisimulation l \nCompile casts to labeled types ..T . S.. = P llll ..B . B.. = B. ..* . *.. = * ..B . *.. = Bl ..* . \nB.. = B. l . S.. = .lG. ..T if S # T, where G = gnd(S) lll ..S..T . . S . T .. = ..S . S... .. ..T . \n. T .. lll ..S . T . *.. = ..* . S.. .l ..T . *.. lll ..* . S . T .. = ..S . *.. .. ..* . T .. Compile \nblame terms to threesome terms ..t.. = t ..x.. = x ..k.. = k ...x:S. t.. = .x : S. ..t.. ..ts.. = ..t.. \n..s.. lRl ...T .S.s.. = .T .=S...s.. where R = ..T . S.. Figure 5. Compilation of twosomes to threesomes \n(with blame) s2 s3 t2 t3 k kx x s2 t2 s3 t3 s2 s3 blame l blame l .x : S. s2 .x : S. s3 l s2 \n s3 P = ..T . S.. (24) lP .T .S.s2 .T .= S.s3 Pl s2 .T .=S.s3 Q = ..U . T .. (25) lQ.P .U .T .s2 .U .= \nS.s3 l P..T1.U1.. t2 (.T1.T2 .=S.s3)(.T1 .= U1.t3) l Q = ..U1.U2 . T1.T2.. \u00ac(T1 . T2 = |P | = S) lQ.P \n.U2 .T2.t2 (.U1.U2 .= S.s3) t3 (26) l ..S1.U1.. l t2 s3 (.S1 .= U1.t3) Q = ..U1.U2 . S1.S2.. lQ .U2 \n.S2.t2 (.U1.U2 .=S1.S2.s3) t3 (27) Figure 6. Bisimulation relating twosomes and threesomes relation, \nshown in Figure 6, linking reduction in the two systems. The bisimulation relates a sequence of twosomes \nwith a single threesome.To accomplishthis,rule(25)peelsoff atwosomefrom the sequence and recursively \nrelates a modi.ed threesome with the rest of the sequence. The modi.cation removes the contribution of \nthe one twosome from the threesome s intermediate type. Rule (26) is necessary to relate states during \nthe application of a cast-wrapped function to a value. On the blame calculus side, the function is wrapped \nin a sequence of casts and there is a sequence of reductions via rule (8). On the threesome side, there \nis only one cast and one reduction via rule (19). Rule (26) therefore relates the intermediate steps \nof the blame calculus back to the state of the threesomes before the reduction via rule (19). Rule (27) \nis similar to rule (26)but handles the special case when T1.T2 = |P | = S. Lemma8 (Bisimulation between \nthe blame and threesome calculi). If s2 s3 and both s2 and s3 are well typed, then 1. if s2 .-. r2, \nthen s3 .-. * r3 and r2 r3 for some r3. 2. if s3 .-. r3, then s2 .-. * r2 and r2 r3 for some r2. \n  Towards proving the correctness of the threesome calculus, we show that compilation returns a threesome \ncalculus program that is bisimilar to the source program. Lemma9 (Compilation returns a bisimilar program.). \nt ..t.. Also, we show that the bisimulation is sound with respect to ob\u00adservable behavior. Lemma 10. \nIf t2 t3, then t2 . if and only if t3 .. The correctness of the threesome calculus is a straightforward \nconsequence of these lemmas. Theorem4 (Correctness of the threesome calculus). ..t.. . if and only if \nt ..  4.2 Space Ef.ciency The addition of labels to the intermediate types of the threesomes only adds \na constant factor increase in space, so the proof of space ef.ciencyfrom Section 3.2 carries over to \nthe full threesome calculus in a straightforward manner. 5. Relation to the Coercion Calculus Henglein \n(1994) introduces a sub-language named the coercion calculus to express casts. Instead of casts of the \nform .T . S.s, Henglein uses casts of the form .c.s where c is a term of the coer\u00adcion calculus. The \ncoercion calculus is not intended to be directly usedby programmers,but instead castsofthe form .T . \nS.s are compiled into casts of the form .c.s. The coercion calculus pre\u00addates blame tracking,but Siek \net al. (2009) augment the coercion calculus with blame, obtaining the calculus shown in Figure 7. The \ncoercion G! injectsavalue into * whereas the coercion G?l projects a value out of *, blaming location \nl in the case of a type mismatch. The identity coercion .T behaves like the identity func\u00adtion. The type \nannotation T on the identitycoercion is always either a ground type or *.Afunction coercion c.d applies \ncoercion c to a function s argument and d to its return value. Coercion composi\u00adtion d .c applies coercion \nc then coercion d.Weconsider coercions equal up to associativity of composition. In addition to Henglein \ns coercions, there is the Faill T .S coercion of Herman et al. (2007), which compactly represents coercions \nthat are destined tofailbut have not yet been applied to a value. The coercion reduction system we present \nhere corresponds to Henglein s notion of f-reduction: G?l . G! -. .G. Henglein also studied .-reduction: \nG! . G?l -. .G. While .-reduction is useful when considering how best to compile dynamically typed languages \n(as in Henglein s work), .-reduction is not suitable in our setting as it would allow some errors to \ngo uncaught. Rule (34) for composingfailures on the left is subtle. Herman et al. (2007) instead use \nthe reduction Fail . c -. Fail However, with the addition of blame tracking, that rule would make the \ncalculus non-deterministic. Siek et al. (2009) restrict c to injections. FailTl .S . G! -. FailTl .G \nBut that rule is useless becausefailure coercions never have * as a source type.To see whythis is the \ncase, .rst consider rule (29) which introducesfailures:the sourcetypeis G. Next, the only other wayto \nobtainafailure with source type * would be to have a rule of the form FailTl .S . G?p -. FailTl .* (Hypothetical!) \n but we certainly don twant such a rule because that would intro\u00adduce non-determinism. (The presence \nof the useless rule in the se\u00admantics of Siek et al. (2009) does not invalidate anyof their results.) \nIn this paper, because we are using lazy cast checking, we can allowthe coercionontherighttobea function \ncoercion.Withlazy checking, any errors in the domain or codomain of a cast appear after errors concerning \nthe function type itself, even if the error concerningthe functiontype appears laterina seriesof casts.For \nexample, the following program allocates blame to l4 even though there is also a potential error at l2. \nl4l3l2l1 .Bool .* . Int.Bool .* . Int.Int..x : Int.x .-. blame l4 We give an inductive characterization \nof thef-normal forms of the coercion calculus in Figure 7, writing nm c for this inductive predicate. \nProposition 6. Suppose . c : T . S. nm c if and only if ..c . .c .-. c . . Figure9gives the de.nitionofa \ncoercion-based calculus with blame tracking similar to that of Siek et al. (2009). In this presen\u00adtation \nwe choose to keep coercions in normal form and perform coercion normalization in rule (39). The correspondence \nbetween the threesome calculus and the coercion-based calculus is quite strong: threesome casts are iso\u00admorphictowell-typed \ncoercionsin normal form. Figure8de.nes the function and its inverse that witnesses this isomorphism. \nProposition7 (.\u00b7. produces a coercion in normal form.). If P<:n T and P<:n S, then nm .T .P= S.. Lemma \n11 (Bijection between threesomes and coercions). -1 If |P P| <:n S and |P -|1<:n T and nm c, then ..T \n.P= S..= .T .= S., and ..c.. = c. Theisomorphismis structure-preserving with respectto reduc\u00adtion.To \nprove that the coercion-based reduction rule (39)is equiv\u00adalent to the threesome rule (23), we need to \nestablish that Q.PQ.. P .T .= S. . .S.= S. .-. * .T .= S. To prove this, we need to establish that mapping \nfrom coercions back to threesomes is invariant with respect to coercion reduction. Lemma 12 (Coercion \nreduction preserves .\u00b7.-1.). -1 .-1 Suppose c is well-typed. If c .-. * c ., then .c.= .c . QPQ.P Corollary \n2. .T .= R. . .R .= S. .-. * .T .= S. QPQ&#38;P Proof. First, we have ..T .= R. . .R .= -1 = T .= S. \nS.. Then because coercion reduction is strongly normalizing, there is a c . such that .T .Q= R. . .R \n.P= S. .-. * c . and nm c. Then by Lemma 12 we have .c .-1 = T Q.&#38;= P S and therefore Q&#38;P . \nc . = .T .= S.. Putting these results together,we havean isomorphism between the threesome calculus and \nthe coercion-based calculus of Figure 7. Theorem5 (Isomorphism between the threesome calculus and the \ncoercion-based calculus). -1 -1 1. .\u00b7. is bijective, that is ..t3..= t3 and ..tc.= tc given that t3 \nand tc are well-typed. 2. .\u00b7. is structure (reduction) preserving, that is, t3 .-. t3 . if and only \nif .t3. .-. .t3. ..   Syntax coercions c, d ::= .T | G! | G?l | d . c | c.d | Faill T .S contexts C \n::= C . c | d . C | C.d | c.C Well-typed coercions c : T . S .T : T . T Faill G!: *. G T .S : T . S \nc : S . Td : T . . S. G?l : G .* c.d :(T .T .) . (S.S.) d : U . T . c : T . S d . c : U . S Additional \ntyping rules G . t : T G . s : Sc : T . S G ..c.s : T l Compile casts to coercions ..T . S.. = c ll ..B \n. B.. = .B ..* . *.. = .* lll ..* . B.. = B! ..B . *.. = B? lll ..* . S . T .. =(*.*)! . (..S . *.....* \n. T ..) llll ..S . T . *.. =(..* . S.....T . *..) . (*.*)? .. ll.. l ..S. T . S . T .. = ..S . S.....T \n. T .. Coercion reductions c -. c G?l . G! -. .G (28) H?l . G! -. Faill if G .(29) = H (d1.d2) . (c1.c2) \n-. (c1 . d1).(d2 . c2) (30) .T . c -. c (31) d . .T -. d (32) d . FailTl .S -. Faill if d : U . T (33) \nH.G U.S FailUl .T . (c.d) -. FailUl .S if c.d : T . S (34) Single-step evaluation c .-. c c = C[c0] c0 \n-. c1 c . = C[c1] c .-. c . Normal forms nm .T nm G?l nm G! nm G! . G?l nm FailTl .S nm FailTl .G . G?m \nnm c nm d nm c nm d nm (*.*)! . (c.d) nm c.d nm c nm d nm c nm d nm c nm (c.d) . (*.*)?l nm (*.*)! . \n(c.d) . (*.*)?l Figure 7. Coercion calculus with blame 6. RelatedWork The integration of static and dynamic \ntyping has roots in the 1970 s and 1980 s, with the any type and force expression in CLU (Liskov et al. \n1979) and the Dynamic type and coerce ex\u00ad .T P= S. = c Map threesomes to coercions . G. .= G. = .G .G \n* . .* = *. = .* Gl .G .= *. = G?l G. .= G. = G! .* Gl .*.= *. = G! . G?l .lH. .T .= S. = FailTl .S if \nS =.* .lGm .T .= *. = FailTl .G . G?m P1..P2 P1P2  .T1.T2 .= S1.S2. = .S1 .= T1...T2 .= S2. P1.lP2 P1..P2 \n.T1.T2 .= *. = .T1.T2 .= *.*. . (*.*)?l P1.lP2 P1..P2 .*.= *. =(*.*)! . .*.* .= *.*. . (*.*)?l P1..P2 \nP1.P2 .= S1.S2. =(*.*)! . .*.* .= S1.S2. .* Map coercions to threesomes -1 = .S .P= T . .c. G. -1 = .G \n.= G. ..G. ..*.-1 * = .* .= *. G. -1 = .* .= G. .G!. Gl -1 .G?l= .G .= *. .lG. T .S.-1 .Faill = .T .= \nS. where gnd(S)= G P1..P2 -1 = .T1.T2 .= S1.S2. .c.d. P1P2 where .T1 .= S1. = .c., .T2 .= S2. = .d. Q.P \n-1 = .T .= S. .d . c. PQ where .R .= S. = .c., .T .= R. = .d. Figure 8. Isomorphism between threesomes \nand coercions pression in Amber (Cardelli 1986). Similar constructs appear in Cedar (Lampson 1983), \nModula-2 (Rovner 1986), and Modula\u00ad3 (Cardelli et al. 1989). Casts are generalized to typecase in Modula-2and3their \nsemanticsis formalizedbyAbadietal. (1989, 1991). In this early work on casts and the Dynamic type, run-time \nchecks are based on type equality. Thatte (1990) observes that type equality requires programmers to \nexplicitly reason about the run-time tags onvalues.To relax this restrictionhe proposes that casts succeed \nwhenever the value can be coerced to the target type, similar to the coercion based models of subtyping \n(Mitchell 1984, Breazu-Tannen et al. 1989). Thatte s work includes upcasts and downcasts, with Dynamic \nas top. In studying the compilation of dynamically typed languages to statically typed languages, Henglein \n(1992, 1994) develops the coercion calculus,asub-languageforexpressingcastsinvolvingthe type Dynamic.We \nnotice similarities between Henglein s coercion calculus and the retractsof Scott (1976)but we are notawareof \nanywork that formally connects retracts and the coercion calculus. Henglein shows that his coercions \nfactor: any coercion is f\u00adreducible to a sequence consisting of a negative, neutral, and posi\u00adtive coercion: \nc + . c * . c -.Anegative coercion is a downcast with Syntax terms s, t ::= k | x | .x:S.t | st | .c.s \nwhere nm c uncoerced values u ::= k | .x : S.t values v, w ::= u |.c.u where nm c contractums r ::= t \n| blame l cast-free contexts F ::= . | E[. t] | E[v .] evaluation contexts E ::= F | F [.c..] Additional \ntyping rules G . t : T G . s : S . c : T . S G ..c.s : T Compile blame calculus to coercion-based calculus \n..t.. = t ..x.. = x ..k.. = k ...x : S. t.. = .x : S. ..t.. ll ..ts.. = ..t.. ..s.. ...T .S.s.. = ...T \n. S.....s.. Reductions s -. r (.x : S.t) v -. [x := v]t (35) kk. -. d(k, k.) (36) (.c . d.u) w -. .d. \nu(.c.w) (37) Cast reductions t -.c r ..T .u -.c u (38) .d..c.s -.c .c ..s if d . c .-. * c . and nm c \n. (39) .FailTl .S .u -. blame l (40) Single-step evaluation t .-. r t -. t. t -.c t. t -.c blame l E[t] \n.-. E[tF [e] .-. F [tF [t] .-. blame l Figure 9. Coercion-based lambda calculus with blame respect to \n<:n, a positive coercion is an upcast, and a neutral coer\u00adcion representsfailure.We conjecture thata \nthreesome .T .R= S., where R does not contain .,isequivalenttoa cast withfactoring c + . c * . c - where \nc - is a downcast from S to R, and c * is the identity coercion on R, and c + is an upcast from R to \nT . The primarygoalof Henglein sworkwasto minimizethe num\u00adber of casts inserted during compilation, which \nexplains his use of the .-reduction to remove projection-injection pairs. In contrast, the focus of this \npaper is on integrating static and dynamic typing, and the boundary between static and dynamic regions \nrequire cer\u00adtain run-time checksto maintaintheintegrityofthe staticregion.To maintain the integrity of \nthe static types, we only use f-reduction. That being said, an interesting direction for future work \nwould be to try and reduce the number of inserted casts using Henglein s techniques while remaining sound. \nGray et al. (2005) propose adding the type Dynamic to Java and apply the technology of contract checking \nto casts. Towards for\u00admalizingthe ideasofGrayetal. (2005),SiekandTaha(2006)and Gronski et al. (2006) \ngeneralize Thatte s up and down-casts to a single cast capable of up, down, and cross casts. Furthermore, \nSiek and Taha (2006) observe that subtyping is not suitable for stati\u00adcally characterizing casts involving \ntype Dynamic and propose the compatibility relation, written ~,to .llthis role. These generalized casts \nplay an important role in the intermediate languages of grad\u00adual typing (Siek andTaha 2006, 2007) and \nhybrid typing (Gronski et al. 2006, Flanagan 2006, Flanagan et al. 2006). Tobin-Hochstadt and Felleisen \n(2006) formalize the interaction between static and dynamic typing at the granularity of modules anddevelopa \nprecursortothe Blame Theorem.Wadlerand Find\u00adler (2007, 2009) design the blame calculus, adding blame \ntrack\u00adingtothe generalizedcastsofSiekandTaha (2006)and Gronski et al. (2006), drawing on the blame tracking \nof higher-order con\u00adtracts (Findler and Felleisen 2002).Wadler and Findler (2009) for\u00admulate and prove \nthe Blame Theorem: statically typed regions of a program can t be blamed for a cast error. Gronski and \nFlanagan (2007) show that casts with a single blame label are just as expres\u00adsive as casts with two blame \nlabels or labels with polarity. Herman et al. (2007) observe that in a straightforward imple\u00admentation \nof the generalized casts, there can be unbounded run\u00adtime spaceoverhead.To solve this problem, Herman \net al. (2007) perform stack inspection to .nd sequences of casts and use the co\u00adercion calculus of Henglein \n(1994) to compress those sequences. SiekandTaha (2007) describea partial solutiontothe spaceef.\u00adciency \nproblem using a merge operator that is a precursor to the meet algorithm given in this paper. Siek et \nal. (2009) show how to augment the coercion calculus with blame tracking, thereby obtain\u00ading a theoretical \nbound on space consumption for blame calculus implementations. 7. Conclusion In this paper we present \nthreesomes, a typed-based solution to the space-ef.ciency problemof higher-order casts.We .rst presenta \nsimpli.ed threesome calculus where sequences of casts are com\u00adpressed by taking the greatest lower bound \nwith respect to naive subtyping. We prove that the simpli.ed threesome calculus is equivalent to the \nblame calculus (ignoring blame allocation) and we prove that the simpli.ed threesome calculus is space \nef.cient. We then present the threesome calculus with full support for blame trackingandprovethatitisequivalenttothe \nblame calculus.We prove that threesomes are isomorphic to Henglein s coercions in normal form and that \nthreesome composition is equivalent to coer\u00adcion composition followedby normalization. References M. \nAbadi, L. Cardelli, B. Pierce, and G. Plotkin. Dynamic typing in a statically-typed language. In POPL \n89: Proceedings of the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming lan\u00adguages, pages \n213 227,NewYork,NY, USA, 1989.ACM. Mart\u00b4in Abadi, Luca Cardelli, Benjamin Pierce, and Gordon Plotkin. \nDy\u00adnamic typing in a statically typed language. ACM Transactions on Pro\u00adgramming Languages and Systems, \n13(2):237 268, April 1991. V. Breazu-Tannen,T. Coquand,C. Gunter, andA. Scedrov. Inheritance and explicit \ncoercion. In Proceedings of the Fourth Annual Symposium on Logic in computer science, pages 112 129, \nPiscataway, NJ, USA, 1989. IEEE Press. L.Cardelli,J.Donahue,M.Jordan,B.Kalsow,andG.Nelson.The modula \n3type system. InPOPL 89: Proceedings of the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming \nlanguages, pages 202 212,NewYork,NY, USA, 1989.ACM. Luca Cardelli. Amber. In Combinators and Functional \nProgramming Languages, volume 242, pages 21 70, 1986. R. B. Findler and M. Felleisen. Contracts for higher-order \nfunctions. In ACM International Conference on Functional Programming, October 2002. Cormac Flanagan. \nHybrid type checking. In POPL 2006: The 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages, pages 245 256, Charleston, South Carolina, January 2006. Cormac Flanagan, Stephen N. Freund, \nand Aaron Tomb. Hybrid types, invariants,and re.nementsfor imperativeobjects.In FOOL/WOOD 06: International \nWorkshop on Foundations and Developments of Object-Oriented Languages, 2006. Kathryn E. Gray,Robert Bruce \nFindler,and MatthewFlatt. Fine-grained in\u00adteroperability through mirrors and contracts. In OOPSLA 05: \nProceed\u00adings of the 20th annual ACM SIGPLAN conference on Object oriented programming systems languages \nand applications, pages 231 245, New York,NY, USA, 2005.ACM Press. Jessica Gronski and Cormac Flanagan. \nUnifyinghybrid types and contracts. In Trends in Functional Prog. (TFP), 2007. Jessica Gronski,Kenneth \nKnowles, AaronTomb, Stephen N. Freund, and Cormac Flanagan. Sage: Hybrid checking for .exible speci.cations. \nIn Scheme and Functional Programming Workshop, pages 93 104, 2006. Lars T. Hansen. Evolutionary programming \nand gradual typing in EC-MAScript 4 (tutorial). Technical report, ECMA TG1 working group, November 2007. \nAnders Hejlsberg. The future of C#. http://channel9.msdn.com/pdc2008/TL16/, October 2008. Fritz Henglein. \nDynamic typing. In ESOP 92: Proceedings of the 4th European Symposium on Programming, pages 233 253, \nLondon, UK, 1992. Springer-Verlag. Fritz Henglein. Dynamic typing: syntax and proof theory. Science of \nComputer Programming, 22(3):197 230, June 1994. David Herman, AaronTomb, and Cormac Flanagan. Space-ef.cient \ngrad\u00adual typing. In Trends in Functional Prog. (TFP), page XXVIII, April 2007. ButlerW. Lampson.Adescriptionof \nthe Cedar language.Technical report, XeroxPARC, 1983. Barbara Liskov, Russ Atkinson,Toby Bloom, Eliot \nMoss, Craig Schaffert, Bob Schei.er, and Alan Snyder. CLU reference manual. Technical Report LCS-TR-225, \nMIT, October 1979. John C. Mitchell. Coercion and type inference. In POPL 84: Proceed\u00adings of the 11th \nACM SIGACT-SIGPLAN symposium on Principles of programming languages, pages 175 185, NewYork, NY, USA, \n1984. ACM Press. P. Rovner. Extending Modula-2 to build large, integrated sys\u00adtems. IEEE Software, 3(6):46 \n57, 1986. ISSN 0740-7459. doi: http://doi.ieeecomputersociety.org/10.1109/MS.1986.229476. Dana Scott. \nData types as lattices. SIAM Journal on Computing, 5(3): 522 587, 1976. JeremyG.SiekandWalidTaha. Gradualtypingfor \nfunctional languages.In Scheme and Functional Programming Workshop, pages 81 92, Septem\u00adber 2006. Jeremy \nG. Siek andWalidTaha. Gradual typing for objects. In ECOOP 2007,volume 4609 ofLCNS,pages 2 27. SpringerVerlag, \nAugust 2007. JeremyG.Siek,RonaldGarcia,andWalidTaha. Exploringthedesignspace of higher-order casts. In \nEuropean Symposium on Programming, March 2009. Satish Thatte. Quasi-static typing. In POPL 1990, pages \n367 381, New York,NY, USA, 1990.ACM Press. Sam Tobin-Hochstadt and Matthias Felleisen. Interlanguage \nmigration: From scripts to programs. In OOPSLA 06 Companion, pages 964 974, NY, 2006.ACM. SamTobin-Hochstadt \nand Matthias Felleisen. The design and implemen\u00adtation of Typed Scheme. In POPL 2008: The 35th ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, January 2008. Philip Wadler and Robert Bruce Findler. \nWell-typed programs can t be blamed. In Workshop on Scheme and Functional Programming, pages 15 26, 2007. \nPhilip Wadler and Robert Bruce Findler. Well-typed programs can t be blamed. In European Symposium on \nProgramming, 2009. LarryWall. Synopsis2: Bits and pieces.Technical report, June 2009. Tobias Wrigstad,Patrick \nEugster, John Field, Nate Nystrom, and JanVitek. Software hardening:Aresearch agenda. In International \nWorkshop on Script to Program Evolution, July 2009. Appendix 7.1 Correctness of Simpli.ed Threesomes \nProof of Proposition 1. Theproofisbystrong inductiononthesum of the height of S and T . We de.ne the \nappend operation@ for contexts as follows. E@. = E E@E.[. t]=(E@E.)[. t] E@E.[v .]=(E@E.)[v .] E@F [.T \n.R= S.l.]=(E@F )[.T .R= S.l.] R. if E@F ..[.T . = S..l.] = F . Proof of Unique Decomposition 2. The \nproof is by induction on the typing derivation \u00d8. t : T . 1. \u00d8. k : typeof (k):k is a value. 2. \u00d8. x \n: T :vacuously true. 3. \u00d8. .x : S.s:.x : S.s is a value. \u00d8. s : T . S \u00d8. t : T  4. :Eithers is a value, \nor not.  \u00d8. st : S (a) Suppose s is a value. Either t is a value, or not. i. Suppose t isavalue.Bythe \ncanonical forms lemma, s is eithera functionora functionalcast.In either case st is a redex. Furthermore, \nthe only context that decomposes st into a redex is .. ii. Suppose t is not a value. Then we apply the \ninduction hypothesis to get a unique contextE and redex t. where t = E[t.]. The unique context for st \nis therefore .[s.]@E. (b) Suppose s is not a value. Then we apply the induction hypothesistogetaunique \ncontextE and redex s . where s = E[s .]. The unique context for st is therefore .[.t]@E.  \u00d8. s : S 5. \n:Eithers is a value, or not. R \u00d8..T .= S.s : T (a) Suppose s is a value. Then either .T .R= S.s is also \na value or it is a redex. If it is a redex, then the unique context is .. (b) Suppose s is not a value. \nWe have two cases to consider. If s is a cast, then .T .R= S.s is a redex and the unique context is .. \n(Any other context that puts the hole inside s would contain adjacent casts, which is impossible.) If \ns is not a cast, we apply the induction hypothesis to get a unique context E and redex s . where s = \nE[s .]. The unique context for .T .R= S.s is therefore .[.T .R= S..]@E.  Because s is not a cast, the \ntop of E is not a cast and appending .[.T .R= S..] with E will not resultin adjacent casts and therefore \nproduces a well-formed context. Towards proving the fundamental property of casts, we de.ne the bisimulation \nrelation .by closing the following two rules with respect to contexts. The second rule is necessary for \n.to bea bisimulation. t .t. T &#38;S<:n Rt .t. .T . S.t .. t .S . T . S . T .t. .T . R . S.t. Lemma \n13 (Substitution preserves .). If s .t and vs .vt, then [x := vs]s .[x := vt]t. Proof. The proof is by \ninduction on the derivation of s .t. Lemma 14 ( .is a weak bisimulation.). Suppose s .t. 1. If s .-. \nrs, then there exists rt where t .-. * rt and rs .rt.  2. If t .-. rt, then there exists rs where s \n.-. * rs and rs .rt. Proof. 1. The proof is by a lengthy case analysis on s .-. rs. The case for function \napplication uses Lemma 13. 2. The proof is by a lengthy case analysis on t .-. rt. The case for function \napplication uses Lemma 13.  Lemma 15. If s .t, then s . if and only if t .. Proof. 1. (=.) The proof \nis by induction on the reduction s .-. * f. (a) Case s = f:Froms .t and Lemma 14 we have t .-. * f. and \ntherefore t .. (b) Case s .-. s . and s . .-. * f: From s .t and Lemma 14 we have t .-. * t. with s \n. .t.. Then by the induction hypothesis,t ..  2. (.=) The proof is symmetric to the above case. Lemma \n16. If s .t, then C[s] .C[t]. Proof. The proof by induction on C. Lemma 17. If s .t, then s = ctx t. \nProof. We .xC and need to show that C[s] . if and only if C[t] .. By Lemma 16 we have C[s] .C[t]. We \nconclude by applying Lemma 15. Lemma 18. t .t Proof. By induction on t. Proof of Lemma 2. Assuming T \n&#38;S<:n R, we need to show that .T . S.t = ctx .T . R . S.t.We have t .t and therefore .T .S.t . .T \n. R . S.t.We conclude by Lemma 17.  7.2 Proof of Space Ef.ciency Proof of Proposition 3. 1. The proof \nis a straightforward induction on the type T . 2. The proof is by strong induction on the sum of the \nheights of S and T . 3. The proof is by induction on type T with case analysis on S.  Proof of Lemma \n6. The proofisbyinversion on t .-. t. and cases on -.. The case for rule (16) uses Proposition3(part \n2). Proof of Lemma 7. The proof is by induction on t. The only inter\u00adesting caseis for casts.Wehave T<:n \n..R . S.s. and therefore T<:n .R. and T<:n .S.. Thenby Proposition3 (part2) we have that T<:n .R&#38;S.. \nBy the induction hypothesis we have T<:n ..s... Therefore T<:n ..R R.&#38;= S S...s.... Proof of Theorem \n2. First, we have &#38;.t. <:n .t. byProposition 1. We have &#38;.t. <:n ...t... by Lemma 7. We then \nproceed by induction on ..t.. .-. * t. . 1. In the base case we have t. = ..t... So &#38;.t. <:n .t.. \nand thenby Proposition3(part3) we can conclude that size(T ) = size(&#38;.t.) for any T in t. . 2. For \nthe induction step, we have ..t.. .-. t1 and t1 .-. * t. . By Lemma 6 we have &#38;.t. <:n t1. Then by \nthe induction hypothesis we have&#38;.t. <:n t..We conclude that size(T ) = size(&#38;.t.) for any T \nin t. by applying Proposition3 (part1 and 3).   7.3 Correctness of Threesomes Proof of Proposition \n5. Theproofisbyinductiononthesumofthe heights of S and T . Proof of Proposition 4. Theproofisbyinductiononthesumofthe \nheights of Q and P . .lG. Lemma 19. Suppose s2 .T .= S.u. Then s2 .-. * blame l. Proof of Lemma 8. 1. \nThe proofisby case analysis on t2 .-. r2. 2. The proof is by case analysis on t3 .-. r3. In the case \n .lG. F [.T .= S.u] .-. blame l, we apply Lemma 19 to show that t2 .-. * blame l. Proof of Lemma 9. \nThe proof is by induction on the term t, using rule (24) for relating casts. Proof of Lemma 19. The proof \nis by induction on the derivation of .lGp s2 .T .= S.v. Proof of Lemma 10. We need to show that ift2 \n t3, then t2 . if and only if t3 .. 1. (=.) The proofisby induction on the reduction t2 .-. * f2. 2. \n(.=) The proofisby induction on the reduction t3 .-. * f3.  Proof of Theorem 4. We need to show that \n..t.. . iff t .. By Lemma9wehave t ..t...We concludeby Lemma 10. 7.4 Isomorphism Between Threesomes \nand Coercions Proof of Proposition 6. 1. To show that nm c implies ..c . .c .-. c ., perform induction \non the derivation of nm c. 2. We need to show that ..c . .c .-. c . implies nm c.Towards a contradiction, \nwe assume \u00acnm c.We proceed by induction on  c. Each of the base cases is vacuously true. In the case \nwhere c = c1 . c2, we apply the induction hypothesis to get a reduction in c1 or c2 and therefore a contradiction. \nIn the case where c = c2 . c1, there are manycasesto consider,butin each case there is a reduction. \nProof of Proposition 7. The proof is by induction on P . Proof of Lemma 11. -1 1. We prove ..T .P= S..= \n.T .P= S. by induction on P . 2. We prove ..c.-1. = c by induction on the derivation of c.  Proof \nof Lemma 12. The proof is by induction on the reduction sequence, with case analysis on each reduction. \nProof of Theorem 5. 1. The proof of ..t3..-1 = t3 is by induction on the typing derivation for t3 and \nthe proof of ..tc.-1. = tc isby induction on the typing derivation of tc. 2. We prove that t3 .-. t3 \n. if and only if .t3. .-. .t3. ..  (a) We show that t3 .-. t3 . implies .t3. .-. .t3. .. The proof is \nby cases on reduction, using Corollary2for rule (23). (b) We show that .t3. .-. .t3. . implies t3 .-. \nt3. . The proof is by cases on reduction, using Corollary2for rule (39).    \n\t\t\t", "proc_id": "1706299", "abstract": "<p>How to integrate static and dynamic types? Recent work focuses on casts to mediate between the two. However, adding casts may degrade tail calls into a non-tail calls, increasing space consumption from constant to linear in the depth of calls.</p> <p>We present a new solution to this old problem, based on the notion of a threesome. A cast is specified by a source and a target type--a twosome. Any twosome factors into a downcast from the source to an intermediate type, followed by an upcast from the intermediate to the target---a threesome. Any chain of threesomes collapses to a single threesome, calculated by taking the greatest lower bound of the intermediate types. We augment this solution with blame labels to map any failure of a threesome back to the offending twosome in the source program.</p> <p>Herman, Tomb, and Flanagan (2007) solve the space problem by representing casts with the coercion calculus of Henglein (1994). While they provide a theoretical limit on the space overhead, there remains the practical question of how best to implement coercion reduction. The threesomes presented in this paper provide a streamlined data structure and algorithm for representing and normalizing coercions. Furthermore, threesomes provide a typed-based explanation of coercion reduction.</p>", "authors": [{"name": "Jeremy G. Siek", "author_profile_id": "81100437231", "affiliation": "University of Colorado at Boulder, Boulder, CO, USA", "person_id": "P1911120", "email_address": "", "orcid_id": ""}, {"name": "Philip Wadler", "author_profile_id": "81100173596", "affiliation": "University of Edinburgh, Edinburgh, United Kingdom", "person_id": "P1911121", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706342", "year": "2010", "article_id": "1706342", "conference": "POPL", "title": "Threesomes, with and without blame", "url": "http://dl.acm.org/citation.cfm?id=1706342"}