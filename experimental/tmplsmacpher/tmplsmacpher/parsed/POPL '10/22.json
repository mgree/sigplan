{"article_publication_date": "01-17-2010", "fulltext": "\n Structuring the Veri.cation of Heap-Manipulating Programs Aleksandar Nanevski Viktor Vafeiadis Josh \nBerdine IMDEA Software, Madrid Microsoft Research, Cambridge Microsoft Research, Cambridge aleks.nanevski@imdea.org \nviktorva@microsoft.com jjb@microsoft.com Abstract Most systems based on separation logic consider only \nrestricted forms of implication or non-separating conjunction, as full sup\u00adport for these connectives \nrequires a non-trivial notion of variable context, inherited from the logic of bunched implications (BI). \nWe show that in an expressive type theory such as Coq, one can avoid the intricacies of BI, and support \nfull separation logic very ef.\u00adciently, using the native structuring primitives of the type theory. Our \nproposal uses re.ection to enable equational reasoning about heaps, and Hoare triples with binary postconditions \nto fur\u00adther facilitate it. We apply these ideas to Hoare Type Theory, to obtain a new proof technique \nfor veri.cation of higher-order im\u00adperative programs that is general, extendable, and supports very short \nproofs, even without signi.cant use of automation by tactics. We demonstrate the usability of the technique \nby verifying the fast congruence closure algorithm of Nieuwenhuis and Oliveras, em\u00adployed in the state-of-the-art \nBarcelogic SAT solver. Categories and Subject Descriptors F.3.1 [Logics and Mean\u00adings of Programs]: Specifying \nand Verifying and Reasoning about Programs Logic of programs General Terms Languages, Veri.cation Keywords \nType Theory, Hoare Logic, Separation Logic, Monads  1. Introduction While separation logic [25, 26] \nhas proved to be extremely effective in reasoning about heap-manipulating programs in the presence of \naliasing, most practical systems such as Smallfoot [6], HIP [22], SLAyer [5], Space Invader [8] or Xisa \n[10] address only a restricted fragment of assertions, roughly described by the grammar: P := atomic \n| emp |T| x . y | P1 * P2 |.x. P. (*) Here emp is an assertion which holds of the empty heap, the points-to \npredicate x . y holds of the singleton heap with location x whose contents is y,and P1 * P2 holds of \na heap if it can be split into disjoint subheaps satisfying P1 and P2, respectively. One important omission \nin (*) is the customary non-separating connectives such as implication, conjunction and universal quan\u00adti.cation. \nTo see why these are omitted, consider the entailments (1) G f P1 * P2 . Q and (2) G f P1 . P2 . Q,inthe \nse\u00adquent calculus for BI [24]. Separation assertion logic is a theory of Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed BI, obtained by specializing the model of heaps and adding the \n. predicate; thus, all the above tools perform proof search by using some form of a sequent calculus \nfor BI. Proving either of the se\u00adquents has to break up the implication at some point, and move P1 and \nP2 into the context G. But then, one needs two different context constructors in order to record that \nP1 and P2 are conjoined by * in the .rst case, and by . in the second. This is semantically im\u00adportant, \nbecause in the .rst case, P1 and P2 hold of separate heaps, while in the second case, they hold of the \nsame heap. Thus, con\u00adtexts in the presence of both * and . cannot be implemented in the usual manner \nas lists of hypotheses, but must be more involved and subject to much more complicated rules for context \nmanipulation. There have been a few systems that consider proofs and proof search in BI [4, 13], but \nto the best of our knowledge, none has been extended to support general-purpose reasoning about heaps. \nInstead, separation logic systems simply restrict conjunction P . Q and implication P . Q to assertions \nP that are pure;that is, independent of the underlying heap. If P is pure, then list\u00adlike contexts suf.ce. \nOf course, this comes at the expense of the generality of the implemented logic. An alternative is to \nexplicitly introduce an abstract type of heaps into the formal logic, and represent separation assertions \nas predicates over this type. Then heap variables can explicitly name the various heaps during proving. \nFor example, the entailments (1) and (2) can be transformed to G(h1 h2),P1 h1,P2 h2 f Q (h1 h2) and \nG h, P1 h, P2 h f Qh, respectively. Here, the variable contexts are list-like, h, h1, h2 are fresh heap \nvariables, and h1 h2 is a disjoint union of h1 and h2. To someone working in separation logic, adding \nthe type of heaps as above may look like a signi.cant loss of abstraction, and explicit reasoning about \ndisjointness and heap union may be dif.cult to automate. Even in interactive provers like Coq, where \nautomation is not always a priority, this may lead to large and tedious proof obligations. Thus, all \nCoq embeddings of separation logic that we know of [1, 11, 12, 17, 18] effectively focus only on the \n(*) fragment, extended with pure predicates. Our .rst contribution in this paper is to show that by choos\u00ading \nsomewhat less straightforward de.nitions of heaps and of heap union in Coq, we can obtain effective reasoning \nin the presence of abstract heap variables, and hence support full separation asser\u00adtion logic while \nusing only native hypothesis contexts, and without excessive proof obligations. The de.nition uses dependently-typed \nprogramming, and the idea of re.ection, whereby decidable opera\u00adtions on a type are implemented as functions \nwith codomain bool. Its important aspect is to make heaps satisfy the algebraic proper\u00adties of partial \ncommutative monoids [9]. To test our new de.nition in practice, we apply it to the imple\u00admentation of \nHoare Type Theory (HTT) [11, 20, 21], which extends for pro.t or commercial advantage and that copies \nbear this notice and the full citation the type theory of Coq to integrate separation logic into it. \nIn such a on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute setting, \none can develop higher-order stateful programs, carry out to lists, requires prior speci.c permission \nand/or a fee. proofs of their full functional correctness, and check the proofs me- POPL 10, January \n17 23, 2010, Madrid, Spain. chanically. Programs and proofs can be organized into veri.ed li\u00ad cCopyright \n&#38;#169; 2010 ACM 978-1-60558-479-9/10/01. . . $10.00  braries, with interfaces at an arbitrary level \nof abstraction, thus en\u00adabling code and proof reuse. The existing implementations of HTT, however, either \nallowed general separation logic [21], but lead to a prohibitive overhead in the size and number of proof \nobligations about heap disjointness [15], or provided aggressive proof automa\u00adtion by tactics (and hence \nvery short proof scripts), but sacri.ced expressiveness by focusing on the (*) fragment and omitting \nmost structural rules of separation logic [11]. As our second contribution, we reformulate HTT to support \nboth properties. We rely on the new de.nition of heaps to avoid generating excessive obligations, and \nkeep the proofs short in the presence of non-separating connectives. We rely on Hoare triples with postconditions \nthat are binary, rather than unary relations on heaps, to make the system general and extendable. We \nshow that the binary setting supports the standard structural rules of separation logic, but also that \nthe user can extend the system with her own auxiliary structural rules typically, after proving a simple \nlemma thus implementing new proving strategies. We develop one such strategy, and con.rm that it behaves \nwell in practice. For example, for the linked data structures such as stacks, queues and hash tables, \nwe derive explicit full correctness proofs that are of comparable size to the proof scripts or proof \nhints for similar examples in related systems for full veri.cation such as Ynot [11] and Jahob [27]. \nThis despite the fact that the related systems allow large parts of the proofs to be omitted by the user, \nas these will be recovered by the proving automation. As our third contribution, we demonstrate that \nthe technique can be effectively applied to more realistic and complex exam\u00adples. We verify the fast \ncongruence closure algorithm of Nieuwen\u00adhuis and Oliveras [23], deployed in the state-of-the-art Barce\u00adlogic \nSAT solver. Our developments are carried out in Ssre\u00ad.ect [14], which is a recent extension of Coq that \nsimpli.es dealing with re.ection. All our .les are available on the web at http://software.imdea.org/~aleks/htt.tgz. \n 2. Re.ecting heap disjointness The most natural and we argue, naive semantic de.nition represents \nheaps as functions from locations to some kind of values. For example, in [21], heaps are de.ned as loc.option \ndynamic, where the type of locations loc is isomorphic to natural numbers and dynamic is the record type \n{tp:Type, val:tp}, packaging a value val with its type tp. The main problem with this de.nition shows \nup when one considers heap union. 8 <h2 x if h1 x = None h1 h2 = fun x. Some v if h1 x = Some v and \nh2 x = None : None if h1 x = Some v and h2 x = Some w We could make a different choice and instead of \nreturning None when h1 and h2 overlap, give preference to the value stored in one of them [11, 12, 17]. \nIn either case, we are immediately faced with proving some basic algebraic properties. commute : h1 \nh2 = h2 h1 assoc : disjoint h1 h2 . disjoint h2 h3 . disjoint h3 h1 . h1 (h2 h3)=(h1 h2) h3 where \ndisjoint h1 h2 = .xv.h1 x = Some v . h2 x = None. An inadequacy of this de.nition lies in the disjointness \nconditions that pre.x the associativity law. Associativity is used so frequently in practice that discharging \nits preconditions quickly becomes a serious burden. If we choose the alternative de.nition of which \ngives preference to one heap over the other when they overlap, then commutativity becomes conditional, \nwhich is even worse. Most of this inadequacy can be hidden if one avoids explicit heap variables and \n and uses only separating conjunction * in\u00adstead. Assertions conjoined by * are explicitly made to operate \non disjoint heaps, so * is commutative and associative, uncondition\u00adally. However, it is unclear how \nto avoid explicit heaps and in the presence of non-separating connectives, so it is worth .nding de.nitions \nthat support unconditional algebraic laws for . The main problem is that is a partial operation which \nis not really supposed to be applied to overlapping heaps. The common way of dealing with partial operations, \nof course, is to complete them. We will thus adjoin a new element to the type of heaps call this element \nUndef which will be used as a default result of in case we try to union non-disjoint heaps. For the \nlatter to work smoothly in Coq, it has to be possible to decide if two heaps are disjoint. We need a \nterminating proce\u00addure disj:heap.heap.bool,which re.ects disjointness; that is, disj h1 h2 evaluates \nto true if and only if disjoint h1 h2 holds. The difference between the two expressions is that disj \nh1 h2 is a boolean, while disjoint h1 h2 is a proposition. The .rst can be branched on in conditionals, \nwhile the second cannot. We will use this property of disj to give a new de.nition of below. We also \nneed heaps to be canonical, in the sense that two heaps are equal iff they store equal values into equal \nlocations. These two require\u00adments can be satis.ed in many ways, but here we choose to model heaps as \nlists of location-value pairs, sorted in some strictly increas\u00ading order with respect to locations. In \nthis case, disj is conceptually easy to de.ne; it merely traverses the lists of location-value pairs, \nreturning false if it .nds an overlap in the location components, and true when it reaches the end. The \nde.nition of heaps and heap operations then takes roughly the following form. heap = Undef | Def of {l \n: list (loc\u00d7dynamic), : sorted l} empty = Def (nil, sorted nil) [x . v]= if x == null then Undef else \nDef ((x, v)::nil, sorted cons xv) h1 h2 = if (h1,h2) is (Def (l1, ), Def (l2, )) then if disj l1 l2 \nthen Def (sort (l1 ++ l2), sorted cat l1 l2) else Undef else Undef def h = if h is Undef then false else \ntrue Since the de.nition packages each list l with a proof of sorted l,the operations require dependently-typed \nprogramming in order to pro\u00adduce various sortedness proofs on-the-.y. For example, the de.ni\u00adtion of \n applies the lemma sorted cat:.l1 l2. sorted(sort(l1 ++ l2)) to l1 and l2 to convince the typechecker \nthat sort(l1 ++ l2) is indeed sorted. Similarly, the de.nitions of empty heap and sin\u00adgleton heap [x \n. v], require lemmas sorted nil:sorted nil and sorted cons : .xv. sorted((x, v)::nil). Of course, we \nwill hide the intricacies of this de.nition, and keep heaps as an abstract type, only exposing several \nalgebraic properties. Main among them are the following unconditional equations which, together with \nthe def predicate, show that heaps with form a partial commutative monoid. We will use the equa\u00adtions \nas rewrite rules for reordering heap unions during proofs. unC : h1 h2 = h2 h1 unCA : h1 (h2 h3)= \nh2 (h1 h3) unAC :(h1 h2) h3 =(h1 h3) h2 unA :(h1 h2) h3 = h1 (h2 h3) un0h : empty h = h unh0 \n: h empty = h For example, iterated rewriting by unCA or unAC can bring a heap expression from the \nmiddle of a large union to the front or the end of it, without the steep price of proving disjointness \nat every step. Even more important is the def predicate, which we use to state disjointness of heaps. \nFor example, we can de.ne P1 * P2 = fun h. .h1 h2.h = h1 h2 . def h . P1 h1 . P2 h2. The real signi.cance \nof def, however, is that it can operate on arbi\u00adtrary heap expressions, and can thus state simultaneous \ndisjointness of a series of heaps in a union. This will allow us to freely move between assertions in \nseparation logic, to assertions with explicit heaps, without incurring a signi.cant blowup in size. Indeed, \ncon\u00adsider the separation logic assertion P1 *P2 *(P3 ..x. P4 x) . P5, which is outside the (*) fragment. \nIf we want to destruct this impli\u00adcation and move P1,...,P4 into the Coq hypothesis context, we can make \nthe heap variables explicit and write P1 h1 . P2 h2 . P3 h3 . (.x. P4 xh3) . def (h1 h2 h3) . P5 (h1 \n h2 h3) This is more verbose than the original, but only slightly,as we have to keep track of only one \ndef predicate per sequence of iterated * s. With the naive de.nition, exposing the heap variables is \na non\u00adstarter, as we would have to separately assert that each pair of heaps in the series h1,h2,h3 is \ndisjoint, and possibly later prove disjointness for any partitioning of the series (e.g., h1 is disjoint \nfrom h2 h3, h2 is disjoint from h1 h3, etc.). Thisleadstoan exponential blowup, whereas with the new \nde.nition, propositions and proofs are proportional to their separation logic originals. Of course, we \nwill have to devise methods to make inferences from and about def predicates. Example 1. A frequently \nused law related to non-separating con\u00adjunction is the following. (x . v1)*P1 .(x . v2)*P2 . v1 = v2 \n.(x . v1)*(P1 .P2) The law can be proved in our setting as well, but we have found that a somewhat different \nformulation, which states a variant of the cancellation property for , is much more convenient to use. \ncancel : def([x -v1] h1) . ([x -v1] h1 =[x -v2] h2) . v1 = v2 . def h1 . h1 = h2. The conclusion of \ncancel produces new facts def h1 and h1 = h2, to which cancel can be applied again. This way, we can \niterate and chain several cancellations in one line of proof, obtaining de.nedness of sub-unions, out \nof de.nedness of larger heap unions. Example 2. Consider the predicate lseq plh, which states that the \nheap h contains a singly-linked list headed at pointer p, and stores elements from the purely-functional \nlist l. Fixpoint lseq (p : loc)(l : list T ): heap . Prop = if l is x::xt then fun h. .qh'.h =[p -x] \n [p+1 -q] h' . lseq qxth' . def h else fun h. p = null . h = empty Imagine we want to prove that lseq \nis functional in the l argument; that is lseq func : .l1 l2 ph. lseq pl1 h . lseq pl2 h . l1 = l2. We \nwill use the following easy helper lemmas. lseq nil : .lh. lseq null lh . l = nil . h = empty lseq cons \n: .lph.p = null . lseq plh . .xqh'.l = x::tail l . h =[p -x] [p+1 -q] h' . lseq q (tail l) h' . def \nh def null : .pxh. def ([p -x] h) . p= null The proof is by induction on l1.If l1 = nil,then lseq pl1 \nh implies p = null and the result follows by applying the lemma lseq nil to the hypothesis lseq pl2 h.Otherwise,let \nl1 = x1 :: xt,let IH be the induction hypothesis .l2 ph. lseq pxt h . lseq pl2 h . xt = l2. From lseq \npl1 h and the de.nition of lseq, we know that there exist q1,h1 such that h =[p -x1] [p+1 -q1] h1,and \nlseq q1 xt h1 and def ([p -x1] [p+1 -q1] h1). Call the last two facts H and D, respectively. It suf.ces \nto show lseq pl2 ([p -x1] [p+1 -q1] h1) . x1 :: xt = l2. The hypothesis lseq pl2 ([p -x1] [p+1 -q1] \n h1) and the fact that p = null (proved by def null and D) can now be used with the lemma lseq cons, \nto obtain x2,q2 and h2, and reduce the goal to [p -x1] [p+1 -q1] h1 =[p -x2] [p+1 -q2] h2 . lseq \nq2 (tail l2) h2 . x1 :: xt = x2 :: tail l2 By applying cancel to D and the antecedent of this implication, \nwe get x1 = x2 as well as def ([p+1 -q1] h1) and [p+1 -q1] h1 = [p+1 -q2] h2. By chaining cancel again \nover this def predi\u00adcate and equation, we further get q1 = q2 and h1 = h2, reduc\u00ading the goal to lseq \nq1 (tail l2) h1 . x1 :: xt = x1 :: tail l2.But,if lseq q1 (tail l2) h1,thenby IH and H, itmustbe xt = \ntail l2,and thus x1 :: xt = x1 :: tail l2. Notice that the proof did not require any overwhelming reason\u00ading \nabout heap disjointness, despite the explicit heap variables. In fact, the whole argument can be captured \nby the following quite concise formal proof in Ssre.ect. elim . [ |x1 xt IH] l2 ph; .rst by case ...; \ncase/lseq nil. case . q1 [h1][.] HD. case/(lseq cons (def null D)) . x2 [q2][h2][.]. do 2![case/(cancel \nD) .. {D} D] ... by case/(IH H) ... In Section 4, we return to the issue of chaining the reasoning \nabout def predicates, and show how it applies when proving prop\u00aderties of Hoare triples. But .rst, we \ndescribe the basic ideas behind our representation of Hoare triples in type theory. 3. Hoare type theory \nfor separation logic The most common approach to formalizing Hoare logic in proof assistants like Coq \nis by deep embedding where one reasons about the abstract syntax of the programming language in ques\u00adtion \n[17, 18]. This reasoning indirection via syntax is often quite burdensome. For example, a deep embedding \nof a typed functional language will usually involve explicit manipulation of de Bruijn representation \nof bound variables, formalization of a type checker for the embedded language, etc. In contrast, HTT \nformalizes separation logic via types; a triple {p} e {q} in HTT becomes a type ascription e : STsep \nA (p, q), where A is the type of the return value of the command e.The type STsep A (p, q) is a monad \n[20], which makes it possible for commands e to perform side-effects, without compromising the soundness \nof the whole system. Moreover, commands can freely use the purely-functional programming fragment of \nCoq, including inductive types, higher-order functions, type abstraction and .rst\u00adclass modules, which \nremoves a level of indirection and stream\u00adlines the programming and reasoning in HTT. Encoding via types, \nhowever, is not straightforward, and requires a reformulation of the inference rules of separation logic. \nThese inference rules are presented in Figure 1, and they come in two .avors. The .rst .avor includes \nrules that infer proper\u00adties based on program s top command, where the commands are: move xv for assigning \na value v to the variable x; store xv for writing v into the location x; load yx for reading the value \nstored in location x and assigning it to variable y; alloc yv for allocating a new location initialized \nwith v, and storing the address into y; dealloc x for deallocating the location x;and e1; e2 for sequential \ncomposition of commands e1 and e2. The second .avor includes the structural rules. These vary across \nsystems, but here we take them to include the rules of {emp} move xv {x = v . emp}{x .-} store xv {x \n. v} {x . v} load yx {x . v . y = v} {emp} alloc yv {y . v}{x .-} dealloc x {emp} {p} e1 {q}{q} e2 {r} \n[seq] {p} e1; e2{r} {p} e {q} [frame] {p * r} e {q * r} ' '' p . p {p ' } e {q } q . q [consequence] \n{p} e {q} {p} e {q1}{p} e {q2}{p} e {q} x . FV(e, p) [.][.] {p} e {q1 . q2}{p} e {.x. q} {p1} e {q}{p2} \ne {q}{px} e {q} x . FV(e, q) [.][.] {p1 . p2} e {q} {.x. p} e {q} Figure 1. Inference rules of separation \nlogic. frame, consequence, conjunction and disjunction in both binary and quanti.ed (i.e., universal \nand existential) variants. Separation logic also includes the rule of substitution, which allows inferring \n{sp} se {sq} out of {p} e {q}, for any variable substitution s, but we will not explicitly consider such \na rule in this paper, as we will inherit it from the underlying substitution principles of Coq. Ignoring \nthe rule of frame for a second, the role of the other structural rules is, informally, to present the \nview of commands as relations between the input and output heaps. Intuitively, if {p} e {q},then e implements \nthe relation {(h1,h2) | ph1 . qh2}, and e does not crash. The structural rules then simply expose how \nlogical connectives interact with the implication in this relation (e.g., implication distributes over \nconjunction in the consequent, and disjunction in the antecedent, etc.). The dif.culty with structural \nrules is that they cannot easily be encoded as typing rules. One problem is that the universal and existential \nrules require a side-condition that x is not a free variable of e, and this property of e cannot be expressed \nfrom within the system. Another problem is that the structural rules use the same e both in premisses \nand conclusions, thus making it impossible to de.ne the typing judgment by induction on the structure \nof expressions, which is one of the main design principles of Coq. Our proposal for solving these problems \nis to switch to binary postconditions. If Hoare triples have binary postconditions, this quite directly \nexposes the relational nature of commands, which is what the role of structural rules was to start with: \nintuitively, if a command e has a binary postcondition q, then it must implement a relation on heaps \nwhich is a subset of q. Then reasoning about e can be reduced to reasoning about q and can be carried \nout in the logic of assertions, rather than in the logic of Hoare triples. Of course, this only works \nsmoothly if the assertion logic can express properties of relations, and quantify over them. This is \nnot a problem for us, as Coq already includes higher-order logic. To present the semantics of STsep, \nwe brie.y sketch a deno\u00adtational model based on predicate transformers. The related proofs are carried \nout in Coq, and can be found on our web site. We repre\u00adsent preconditions as elements of the type heap.Prop, \nand post\u00adconditions as elements of A.heap.heap.Prop, for any given type A. In addition to abstracting \nover two heaps, the postcondi\u00adtions also abstract over values of type A, because commands in HTT are \nvalue-returning, so the postconditions must be able to re\u00adlate the value to the input and the output \nheap of the computation. Despite this, we still refer to the postconditions as binary , as the type A \ndoes not introduce any signi.cant complications. Given the type A, precondition p:heap.Prop, and binary \npost\u00adcondition q:A.heap.heap.Prop, our predicate transformers are elements of the type model pA = ideal \np . A . heap . Prop. The transformers should only transform predicates that are stronger than p,sowe \nde.ne ideal p as: ideal p = {f : heap . Prop | f c p} where r1 c r2 iff .h:heap.r1 h . r2 h. We further \nonly need transformers that are monotone and bounded by q: ST A (p, q)= {F :model pA | monotone F . bounded \nFq} where monotone F = .r1 r2:ideal p. r1 c r2 ..x.F r1 x c Fr2 x bounded Fq = .rx.F rx c fun h. (.i.r \ni . qxih). The elements of type ST A (p, q) can be used to model programs that return values of type \nA, and have a precondition p and postcon\u00addition q in ordinary Hoare logic,where p and q describe the \nbehav\u00adior of the program on the whole heap. But in separation logic, p and q only describe the part of \nthe heap that the program actually reads from or modi.es during execution; the information that the rest \nof the heap remains invariant is implicit in the semantics. To capture this aspect of separation logic, \nwe next select a speci.c subset of predicate transformers out of ST. Given a pre/postcondition pair s, \nwe de.ne spatial extension s ,and a new STsep type, as follows. s =(pre s * fun h. T, fun x. pre s -post \nsx) STsep As = ST As where pre and post are the projections out of the pair, and p -q = {(i, m) |. i1 \nh. i = i1 h . def i . pi1 . .m1.m = m1 h . def m . qi1 m1}.  Spatial extension allows that heaps on \nwhich a transformer is ap\u00adplied be extended with portions that the transformer keeps invari\u00adant. For \nexample, transformers in STsep A (p, q) takeapredicate describing a heap i which contains a subheap i1 \nsatisfying p,and transform it into a predicate stating that the rest of i (here called h) remains unchanged. \nThe unchanged heap h can be arbitrary, as the precondition only requires h to satisfy T. We note that \nthe def\u00adinition of -is quite similar to the notion of best local action from [9], and has also been used \npreviously in [19]. We can now transcribe the inference rules about commands as typing rules about elements \nof STsep. We only list the relevant types, and defer to the Coq scripts for the de.nitions and proofs. \nIn all the types, i and m stand for the initial and ending heap of a computation, and y is the name for \nthe return value. We further adopt names that are traditional in functional programming, and use return \nfor move, := for store and ! for load. return :.v:A. STsep A (emp, fun yim.y = v . emp m) := :.x:loc \nv:A. STsep unit (x .-, fun yim. (x . v) m . y =()) ! :.x:loc. STsep A (x .-, fun yim. .v. (x . v) i . \n(x . v) m . y = v) alloc :.v:A. STsep loc (emp, fun yim. (y . v) m) dealloc :.x:loc. STsep unit (x .-, \nfun yim. emp m . y =()) We also have a command for allocation of a block of n consecutive locations, \ninitialized with the value v: allocb :.v:A. .n:nat. STsep loc (emp, fun yim.m = iter nyv) iter nyv = \nif n is n ' +1 then [y -v] iter n ' (y +1) v else empty  And, we require a .xed-point combinator with \nthe type below. In our ST model, this combinator computes the least .xed point of the monotone completion \nof the argument function. .x : ((.x:A. STsep (Bx)(sx)) . .x:A. STsep (Bx)(sx)) . .x:A. STsep (Bx)(sx) \nTranscribing the rule for sequential composition is somewhat more involved. The command e1 now returns \na value of type A1,and thus e2 must be a function which takes that value as an argument. We will have \na typing rule as follows bind :.e1:STsep A1 s1. .e2:(.x:A1. STsep A2 (s2 x)). STsep A2 (bind s s1 s2), \n where s1 and s2 x are pairs of pre/postconditions for e1 and e2 x, respectively, and bind s s1 s2 is \nthe following pre/postcondition pair. (fun i. pre s1 i ..xh. post s1 xih . pre (s2 x)h, fun yim. .xh. \npost s1 xih . post (s2 x) yhm). The precondition in this pair states that in order to execute the se\u00adquential \ncomposition, we must ensure that the precondition pre s1 holds, so that e1 can run in a subheap of the \ninitial heap i.After e1 is done, we will have an intermediate value x and heap h satisfying post s1 \nxih, so we need to show pre (s2 x) h in order to execute e2. The postcondition states that there exists \nan intermediate value x and heap h, obtained after running e1 but before running e2.In the model of ST, \nbind is implemented as the functional composi\u00adtion of the transformers for e1 and e2. We now turn to \nthe structural rules. For a command e : ST As, we consider what can be inferred about e just by looking \nat the type A and speci.cation s. Quite directly, it must be that pre si and post syim hold of the initial \nheap i, .nal heap m and return value y. Thus, given a property q:A.heap.Prop, we can show that qym holds \nafter running e if we can prove verify isq,where verify isq = pre si ..ym. post syim . qy m. This de.nition \nassumes that s describes how e acts on the whole heap i.If e:STsep As,then s describes the action of \ne only on a subheap of i. Following the de.nition of STsep,in order to show that qym holds after running \ne, it then suf.ces to prove verify is q. The verify predicate can now be used to represent Hoare triples \nas assertions. For example, given e:STsep As, the separation logic triple {p} e {q} can be written as \n.i.p i . verify is q.This property will let us encode the standard structural rules, as well as many \nother useful rules, as simple derived lemmas about the verify predicate. Hence, our system will be inherently \nextendable, as the user is free to derive her own structural rules, and thus design custom reasoning \nprinciples and strategies. Moreover, the de.nition of verify does not involve the command e, but only \nthe speci.cation s, making any lemma about verify independent of our particular model of ST. We will \nbe able in the future to develop different models for HTT, while preserving the lemmas and the veri.cation \ntechnique we describe here. As a .rst illustration of working with verify, we show the fol\u00adlowing variants \nof the binary and quanti.ed conjunction rules. conj : verify isq1 . verify isq2 . verify is (fun yh.q1 \nyh . q2 yh) all :(.x:B. verify is (qx)) . B . verify is (fun ym. .x:B.q xy m) Several interesting twists \nappear here. First, the rules use impli\u00adcation and quanti.cation, and cannot be stated in the (*) fragment \nalone. Thus, here we are making an essential use of our formulation of heaps from Section 2. Second, \nthe rules omit the precondition pi as it is invariant across implications. They also omit the side\u00adcondition \nx/. FV s, because s is declared outside of the scope of x. Finally, the all rule requires that B is a \nnon-empty type. Otherwise .x:B.q x y is trivially true, but this does not suf.ce to establish the verify \npredicate, as the latter additionally requires the precondition to hold of the initial state, no matter \nwhat the postcondition is. This makes the semantics of HTT fault-avoiding [9]; that is, it ensures that \nwell-typed commands are safe to execute. On the other hand, the binary and quanti.ed disjunction rules \ndo not require any special treatment. For example, we can prove disj :(p1 i . verify isq) . (p2 i . verify \nisq) . p1 i . p2 i . verify isq exist :(.x.p x . verify isq) . (.x.p x) . verify isq but these are just \ninstances of the usual elimination rules for . and ., and therefore do not require separate lemmas. The \nframe rule can be formulated in several different ways, but we choose the following: frame : verify is \n(fun ym. def (m h) . qy (m h)) . def (i h) . verify (i h) s q. When read bottom-up, this lemma \nreplaces a goal about the heap i h and a postcondition q, with a new goal involving the heap i alone, \nand a postcondition recording that q should eventually be proved of the ending heap m extended with h. \nWe have chosen this formulation because it applies to goals where q is arbitrary, whereas the usual formulation \nfrom Figure 1 requires .rst rewriting q into a form q ' * r, and this if often tedious in the presence \nof higher-order operations and binary postconditions. Finally, we need to connect STsep types with the \nverify pred\u00adicate. The structural rules all show how to change a speci.cation of a command under certain \nconditions. We match that ability at the level of typing rules, by introducing a construct for changing \nan STsep type of a command, which essentially implements the rule of consequence. do : STsep As1 . (.i. \npre s2 i . verify is 1 (fun ym. post s2 yim)) . STsep As2 In our model of ST, do is an identity predicate \ntransformer. With this connective, we have embedded all the rules of separation logic from the beginning \nof this section. Example 3. It is possible to use Coq s purely-functional pattern\u00admatching to build pattern-matching \nconstructs with side-effectful branches. For example, in the case of booleans, we have: If :.b:bool. \nSTsep As1 . STsep As2 . STsep A (if b then s1 else s2) = fun be1 e2. if b then (do e1) else (do e2) \nThe do s in the branches serve to weaken the types of ei into the common type of the conditional. Both \ndo e1 and do e2 require a (simple) proof that if b equals true (resp. false),then s1 (resp. s2) can be \nweakened into if b then s1 else s2. To reduce clutter, in the rest of the paper we blur the distinction \nbetween purely-functional if and side-effectful If, and use if for both. Example 4. The following functions \ninsert and remove an element from the head of a singly-linked list pointed to by p. insert (p : loc)(x \n: T ): STsep loc (fun i. .l. lseq pl i, fun yim. .l. lseq pli . lseq y (x :: l) m)= do (y . allocb p \n2; y := x; return y)  remove (p : loc): STsep loc (fun i. .l. lseq pl i, fun yim. .l. lseq pli . lseq \ny (tail l) m)= do (if p == null then return p else y . !(p +1); dealloc p; dealloc (p +1); return y) \nHere, we have used the standard abbreviation x . e1; e2 for bind e1 (fun x. e2),and e1; e2 when x/. FV(e2). \nFor both func\u00adtions, the STsep type gives the speci.cation that we want to prove about the functions. \nThe preconditions show that the functions can execute safely, as long as the initial heap contains a \nvalid linked list, no matter what values l are stored in it. The postconditions show that the new list \nnow contains x :: l and tail l, respectively, and that the returned value y is a pointer to the new head. \nThe speci.cation pattern seen in these examples, where the predicate from the precondition is, somewhat \nredundantly, repeated in the postcondition, is characteristic to the setting with binary postconditions, \nthough it is by no means always used. Fortunately, this redundancy will not cause an explosion in proof \nobligations, and in Section 4, we show how to quickly remove it. The typing rules are designed so that \nthey can now generate the proof obligation required to verify the programs. For insert,we get .pxi. (.l. \nlseq pli) . verify i (bind s (allocb s p 2) (fun y. bind s (write s yx) fun . return s y)) (fun ym. .l. \nlseq pli . lseq y (x::l) m) and for remove .pi. (.l. lseq pli) . verify i (if p == null then return s \np else bind s (read s (p +1) (fun x. bind s (dealloc s p) (fun . bind s (dealloc s (p +1)) fun . return \ns x)))) (fun qm. .l. lseq pli . lseq q (tail l) m) The proof obligations essentially copy the original \ncommand, ex\u00adcept that the various primitive commands are replaced by their pre/\u00adpostcondition pairs from \nthe beginning of this section. For example, return s p is the pair (emp, fun yi m.y = p.emp m), read \ns x is (x .-, fun yi m. .v. (x . v) i . (x . v) m.y = v),etc. In the case of a call to an already veri.ed \nnon-primitive side-effectful command (not used in insert and remove, but used in programs in Section \n5), the command is not copied, but the pre/postcondition pair from the type of the called command is \nsimply spliced in. Calls to .x are similar, except that a separate obligation is generated to prove that \nthe body of .x satis.es the provided type. Thus, the type of the .xed point serves as the loop invariant. \n 4. Structural rules and veri.cation As structural rules are now simply lemmas over the verify predi\u00adcate, \none is free to prove and use additional ones, that may be use\u00adful for the proof at hand. For example, \nthe following is a variant of the rule for universal quanti.ers, which pulls a quanti.er and an implication \nout of a postcondition, both at the same time. all imp :(.x:B.p x) . (.x:B.p x . verify is (fun ym. qxym)) \n. verify is (fun ym. .x:B.p x . qxym) This rule can be used to simplify the proof obligation from Exam\u00adple \n4, by removing the occurrence of lseq from the postcondition. If p uniquely determines x in the current \ncontext of hypotheses, we may use the following rule to instantiate the quanti.er with the unique value \nfor x. all imp1 : .t:B. (.x:B.p x . t = x) . verify is (qt) . verify is (fun ym. .x:B.p x . qxym) Sometimes, \np may not uniquely determine x, but determines just enough of x to establish q. For example, p may force \nx to be in an equivalence relation to a predetermined t. Then we are justi.ed in instantiating x with \nt, as long as q only makes statements about the common equivalence class of x and t. all imp2 : .t:B. \n(.x:By m.px . qtym . qxym) . verify is (qt) . verify is (fun ym. .x:B.p x . qxym) We also have additional \nrules to help us discharge the proof obligations generated by typechecking. As Example 4 shows, these \nshould be lemmas about how verify interacts with pre/\u00adpostcondition pairs such as bind s, read s, etc. \nThe main lemma of the system serves to simplify proof obligations that are ob\u00adtained when verifying commands \nof the form bind e1 e2 where e1,e2 are arbitrary commands, with types e1 : STsep A1 s1 and e2 :.x:A1. \nSTsep A2 (s2 x), respectively. bnd do : pre s1 i1 . (.xi ' 1. post s1 xi1 i ' 1 . def (i ' 1 i2) . verify \n(i ' 1 i2)(s2 x) r) . def (i1 i2) . verify (i1 i2)(bind s s1 s2) r Applying this lemma to a goal \nof the form def (i1 i2) . verify (i1 i2)(bind s s1 s2) r essentially corresponds to sym\u00adbolically executing \ne1 in the subheap i1. The lemma .rst issues a proof obligation that the precondition pre s1 of e1 is \nsatis.ed in i1, then replaces i1 with a fresh heap variable i ' 1, inserts the knowledge that i ' 1 satis.es \nthe postcondition of e1, and reduces to verifying the continuation e2 in the changed heap. We can further \ninstantiate this lemma to exploit additional knowledge that we may have about e1. For example, if e1 \nstarts with one of the primitive commands, we have the following in\u00adstances, where we omit the def predicate \nif the command does not change the heap. bnd ret : verify i (s2 v) r . verify i (bind s (return s v) \ns2) r bnd read : verify ([x . v] i)(s2 v) r . def ([x . v] i) . verify ([x . v] i)(bind s (read s \nAx) s2) r bnd write :(def ([x . v] i) . verify ([x . v] i)(s2 ()) r) . def ([x . w] i) . verify ([x \n. w] i)(bind s (write s xv) s2) r bnd alloc :(.x:loc. def ([x . v] i) . verify ([x . v] i)(s2 x) r) \n. def i . verify i (bind s (alloc s v) s2) r bnd allocb :(.x:loc. def (iter nxv i) . verify (iter nxv \n i)(s2 x) r) . def i . verify i (bind s (allocb s vn) s2) r bnd dealloc :(def i . verify i (s2 ()) r) \n. def ([x . v] i) . verify ([x . v] i)(bind s (dealloc s x) s2) r bnd bnd : verify i (bind s t1 (fun \nx. bind s (t2 x) s2)) r . verify i (bind s (bind s t1 t2) s2) r  The above lemmas apply only when verifying \ncompound com\u00admands (i.e., command starting with a bind). We need another set of lemmas for atomic commands. \nFor example: val ret : rvi . def i . verify i (return s v) r, and similarly for the other commands. \n                 Veri.cation of any given command in HTT then works basically by applying \none of the lemmas above, or one of the structural rules, as may be required, updating the heap accordingly, \nand stripping off the commands from the goal one at a time. This process inter\u00adacts very well with the \npartiality of heap union from Section 2, as we have instrumented the lemmas to chain the def predicates \nfrom one application to the next, changing the predicates to re.ect the changes to the heaps. During \nveri.cation, it may be necessary to reorder the involved heap unions and bring the subheap required by \nthe current command to the top of the expression, or else the corresponding lemma will not apply. The \nreordering, however, is quite inexpensive, using the unconditional rewrite rules from Sec\u00adtion 2. Once \nthe commands are exhausted, we have to show that the heap obtained at the end satis.es the desired postcondition. \nAt this point, we usually require some mathematical knowledge that is speci.c to the problem at hand, \nand has to be developed separately. Example 5. We now proceed to discharge the proof obligation for insert. \nWe .rst break up the obligation into p:loc, x:T , l:list T , hypothesis H:lseq pli, and the goal verify \ni (bind s (allocb s p 2) (fun y. bind s (write s yx) fun . return s y)) (fun ym. .l. lseq pli . lseq \ny (x::l) m). We apply the lemma all imp1 to remove the quanti.er over l and the antecedent lseq pli from \nthe postcondition, to obtain verify i (bind s (allocb s p 2) (fun y. bind s (write s yx) fun . return \ns y)) (fun ym. lseq y (x::l) m). The hypothesis of all imp1 is easily satis.ed, using H and the lemma \nlseq func proved in Example 2. Next, by hypothesis H and helper lemma lseq def:lseq pli . def i, we obtain \ndef i.Using this and bnd allocb, we reduce the goal to def (([y -p] [y+1 -p] empty) i) . verify (([y \n-p] [y+1 -p] empty) i) (bind s (write s yx)(fun . return s y)) (fun ym. lseq y (x::l) m) where y is \na fresh variable. We next want to bring the singleton heap [y -p] to the top of the union, so we remove \nempty, and apply the associativity law. After that, we can apply bnd write to obtain verify ([y -x] \n[y+1 -p] i) (return s y) (fun ym. lseq y (x::l) m) under hypothesis D : def ([y -x] [y+1 -p] i).By \nval ret,it suf.ces to show lseq y (x::l)([y -x] [y+1 -p] i), which by de.nition of lseq equals .qh \n' . [y -x] [y+1 -p] i =[y -x] [y+1 -q] h ' . lseq qlh ' . def ([y -x] [y+1 -p] i). One can now \ninstantiate q and h ' with p and i, respectively, or alter\u00adnatively, introduce uni.cation variables, \nand let the system instan\u00adtiate q and h ' from the heap equation in the goal. The argument can be summarized \nby the following Ssre.ect proof. apply:(all imp1 l) . [?|]; .rst by apply: lseq func. apply: bnd allocb \n(lseq def H) . y; rewrite unh0 unA. apply: bnd write . D; apply: val ret . //. by do !econstructor. \n 5. Fast congruence closure To put our proof technique to the test, we implemented and veri.ed in HTT \none of the fastest practical algorithms for computing the congruence closure of a set of equations, designed \nby Nieuwen\u00adhuis and Oliveras [23], and used in the Barcelogic SAT Solver whose ef.ciency has been con.rmed \nin various SAT-solving com\u00adpetitions [3]. The algorithm simultaneously uses several stateful data structures \nsuch as arrays, hash tables and linked lists, which all interact in very subtle ways, governed by highly \nnon-trivial in\u00advariants. The algorithm starts with a set of equations between expres\u00adsions, all of which \ncontain symbols drawn from a .nite set symb. Each expression is either a constant symbol, or an application, \ni.e. our type of expressions is exp = const of symb | app of exp \u00d7 exp. Of course, we will use the customary \nshorthand and, for example, abbreviate const c = app (const c1)(const c2) as c = c1 c2. De.nition 6. \nA binary relation R on expressions is monotone iff .f1 f2 e1 e2. (f1,f2) . R . (e1,e2) . R . (f1 e1,f2 \ne2) . R. R is a congruence iff it is monotone and an equivalence. The congruence closure of R is the \nsmallest congruence containing R, T and is de.ned as closure R = {C|C is congruence and R . C}. The \nalgorithm internally maintains a data structure that repre\u00adsents the congruence closure of a set of equations. \nIts interface consists of two methods: (1) merge (t1 = t2), extends the cur\u00adrently represented congruence \nwith a new equation t1 = t2,that is, it combines the congruence classes of t1 and t2,and (2) check t1 \nt2 determines whether the pair (t1,t2) belongs to the represented con\u00adgruence. Additionally, the algorithm \nassumes that the equations passed to merge are in .attened form in the sense that they are either simple \nequations of the form c1 = c2 or compound equa\u00adtions of the form c = c1 c2,where c, c1, c2 are symbols,rather \nthan general expressions. We will need a data type of equations to capture this distinction, which we \nde.ne as Eq = simp of symb \u00d7 symb | comp of symb \u00d7 symb \u00d7 symb. Any system of equations can be brought \ninto a .attened form. For example, the non-.at equation c = c1 c2 c3 can be .attened by in\u00adtroducing \na fresh symbol c4, and then decomposing into two equa\u00adtions: c = c4 c3 and c4 = c1 c2. It turns out that \nin the setting of SAT solvers, it suf.ces to .atten the expressions from the original SAT formula once \nand for all, as the intervening computations of congruence closure will not require additional .attening \nand gen\u00aderation of new symbols [23]. Knowing the number of symbols ahead of time makes it pos\u00adsible to \nimprove the ef.ciency by storing some of the data into arrays rather than linked structures. For example, \nthe algorithm stores: (1) The array r of representatives. For each symbol c, r[c] is the selected representative \nof the congruence class of c. To reduce clutter, we will abbreviate r[c] simply as c ' . (2) The array \nclist of class lists: for each representative symbol c, clist[c] is (a pointer to) the (singly-linked) \nlist of symbols in the congruence class of c. (3) The array ulist of use lists: for each representative \nsymbol c, ulist[c] is (a pointer to) the (singly-linked) list of compound equa\u00adtions c1 = c2 c3,where \nc = c ' 1 or c = c ' 3 or both. If during the execution c stops being a representative because its congruence \nclass is merged into another, the use list of c gives an upper bound on the set of expressions and equations \naffected by this change. To restore the internal soundness of the data structures, it will suf.ce to \nreprocess only the equations in ulist[c]. (4) The pointer p to the list of pending simple equations. \nIf the equation c1 = c2 is in the pending list, it indicates that the congruence classes of c1 and c2 \nneed to be merged in order to restore the internal soundness. When the pending list is empty, the data \nstructures are in a consistent state. (5) The lookup table htab, is a hash table storing for each pair \nof representatives (r1,r2) some compound equation c = c1 c2 such that r1 = c1 ' and r2 = c2' . If no \nsuch equation exists, the lookup  Module Array array : .nType . Type . Type shape : array IT . (I . \nT ) . Prop read :.a:array IT. .k:I. STsep T (fun i. .f. shape af i, fun yim. .f. shape af i . y = fk \n. i = m) write :.a:array IT. .k:I. .x:T. STsep unit (fun i. .f. shape af i, fun yim. .f. shape af i . \nshape af[k . x] m) Module Hashtab kvmap : eqType . Type . Type shape : kvmap KV . (K . option V ) . Prop \nlookup :.t:kvmap KV. .k:K. STsep (option V )(fun i. .f. shape tf i, fun yim. .f. shape fi . shape tf \nm . y = fk) insert :.t:kvmap KV. .k:K. .x:V. STsep unit (fun i. .f. shape tf i, fun yim. .f. shape tf \ni . shape tf[k . Some x] m) Figure 2. Relevant parts of array and hash table signatures. table contains \nno entries for (r1,r2). This table is the main data structure from which one can read off the represented \ncongruence. For example, to check if the pair (c, c1 c2) is in the congruence, it suf.ces to search the \nlookup table for the key (c1' ,c2' ). If the lookup returns some equation d = d1 d2,then d ' is the representative \nsym\u00adbol for c1 c2,and (c, c1 c2) is in the congruence iff d ' = c ' . Since we require arrays and hash \ntables, we implemented li\u00adbraries for both, but here only summarize in Figure 2 the signatures of the \ntype constructors, predicates and methods that we use in this section. The actual libraries are much \nmore general, and are avail\u00adable on our web site. Each module exports a type representing the data structure. \nBoth type array IT and kvmap KV are imple\u00admented as loc, but the signature hides that fact. Arrays expect \nthe index type I to be .nite, and hash tables expect the type of keys K to be eqType, that is, it supports \na decidable equality function == : K . K . bool. The later is also a property required of .nType s. Both \nmodules export an abstract predicate shape,which relates the layout of each data structure with a mathematical \nentity that the structure represents. In the case of arrays, this entity is a function of type I . T \n, and in the case of hash tables, it is a func\u00adtion of type K . option V , re.ecting the fact that the \nhash table need not contain a value for every key. In our libraries, we also cap\u00adture the fact that the \nhash table can contain values for only .nitely many keys, but for this discussion, the above weaker abstraction \nsuf.ces. For both arrays and hash tables, we write f[k . x] to describe a function obtained from f by \nchanging the value at k into x. Now the stateful data structures described above can be declared as the \nfollowing .ve variables which are global to the methods of the algorithm: r : array symb symb, clist, \nulist : array symb loc, htab : kvmap (symb\u00d7symb)(symb\u00d7symb\u00d7symb),and p : loc. Since we are interested \nin the functional veri.cation of the algorithm, we need to capture the contents of these arrays, hash \ntables and linked lists as appropriate mathematical values. We do this with the following record type. \ndata = {rep : symb . symb; class : symb . list symb; use : symb . list (symb \u00d7 symb \u00d7 symb); lookup : \nsymb\u00d7symb . option (symb\u00d7symb\u00d7symb); pending : list (symb \u00d7 symb))} The intention is that, given D:data, \nthe function rep D represents the contents of the array r, and similarly class D, use D, lookup D and \npending D capture the contents of clist, ulist, htab and p.The formal correspondence is established \nby the following predicate. shape (D : data)(h : heap): Prop := .ct ut:symb . loc. .q:loc. Array.shape \nr (rep D) * Array.shape clist ct * \u00aec.symb lseq (ct c)(class Dc) * Array.shape ulist ut * \u00aec.symb lseq \n(ut c)(use Dc) * Hashtab.shape htab (lookup D) * p . q * lseq q (pending D)) h Here we freely use the \nseparation logic * (asde.nedinSection2) and its iterated version \u00ae. In the proofs, we will unfold their \nde.nitions in terms of explicit heaps, when needed. The shape ' predicate captures the layout of the \nstructures in the heap, but we also need to capture the relationships between these structures. shape \n(R : exp \u00d7 exp . Prop)(h : heap): Prop = .D:data. shape Dh . rep idemp D . class inv D . use inv D . \nlkp inv D . use lkp inv D . lkp use inv D . pending D = nil . CRel D = r R In shape, we list that the \narray r must be idempotent: rep idemp D = .c. rep D (rep Dc)= rep Dc. The class lists invert the representative \narray: class inv D = .xc. (rep Dx == c)=(x . class Dc). Use lists store only equations with appropriate \nrepresentatives: use inv D = .acc1 c2.a . reps D . (c, c1,c2) . use Da . rep Dc1 = a . rep Dc2 = a, \nwhere reps D is the list of symbols that are representatives, that is, they appear in the range of the \nfunction rep D. Next, the hash table stores equations with appropriate representatives: lkp inv D = .abcc1 \nc2.a . reps D . b . reps D . lookup D (a, b)= Some (c, c1,c2) . rep Dc1 = a . rep Dc2 = b. For each \nequation in a use list, there is an appropriate equation in the hash table, and vice versa: use lkp inv \nD = .acc1 c2.a . reps D . (c, c1,c2) . use Da . .dd1 d2. lookup D (rep Dc1, rep Dc2)= Some (d, d1,d2) \n. rep Dc1 = rep Dd1 . rep Dc2 = rep Dd2 . rep Dc = rep Dd lkp use inv D = .abdd1 d2.a . reps D . b . \nreps D . lookup D (a, b)= Some (d, d1,d2) . (.cc1 c2. (c, c1,c2) . use Da . rep Dc1 = a . rep Dc2 = b \n. rep Dc = rep Dd) . (.cc1 c2. (c, c1,c2) . use Db . rep Dc1 = a . rep Dc2 = b . rep Dc = rep Dd). The \nshape predicate will be used for the speci.cation of the main methods of the algorithm. Hence it also \nrequires that pending D = nil, i.e., the structures are in a consistent state, and CRel D = r R, i.e., \nthe relation R is the congruence represented by the structures. Here, CRel D is de.ned as the congruence \nclo\u00adsure of all the equations in lookup D, pending D as well as the equations c = rep Dc,for all c. The \noperator = r is the equality on relations: R1= rR2 = .t. R1 t . R2 t. On the other hand, shape ' will \nbe used to specify the helper functions, where some of the above properties may be temporarily invalidated. \nThe main functions of the algorithm are now implemented as HTT code in Figure 3. The type of merge quite \ndirectly states that merge starts with the internal state representing some congruence relation R, and \nchanges the internal state to represent the congru\u00adence closure of the extension of R with the argument \nequation eq. We emphasize that the code does not contain any other kind of an\u00adnotations, such as for \nexample framing conditions, and in general looks very close to what one would write in an ordinary imperative \nlanguage. If merge is passed a simple equation a = b, it places the pair (a, b) onto the head of the \npending list, and invokes the helper function hpropagate, de.ned in Figure 5, to merge the congruence \n 1. merge (eq : Eq): 2. STsep unit (fun i. .R. shape pR i, 3. fun yim. .R. shape pRi . 4. shape p \n(closure (R . rel of eq)) m)= 5. match eq with 6. simp ab . 7. do (q . !p;  8.x . insert q (a, b); \n 9.p := x; 10. hpropagate) 11. | comp cc1 c2 .  ' 12. do (c1 . Array.read rc1; ' 13.c2 . Array.read \nrc2; '' 14.v . Hashtab.lookup htab (c1,c2); 15. match v with 16. None .  '' 17. Hashtab.insert htab \n(c1,c )(c, c1,c2); 2 18.u1 . Array.read ulist c ' 1; 19.x . insert u1 (c, c1,c2); 20. Array.write ulist \nc ' 1 x; 21.u2 . Array.read ulist c ' ; 2 22.x . insert u2 (c, c1,c2); 23. Array.write ulist c ' 2 x \n 24. | Some (b, b1,b2) .  25.q . !p; 26.x . insert q (c, b); 27.p := x; 28. hpropagate 29. end) \n30. end 31. check (t1 t2 : exp): 32. STsep bool (fun i. .R. shape pR i, 33. fun yim. .R. shape pRi \n. shape pRm .  34.y = true . R (t1,t2)) = 35. do (u1 . hnorm t1; 36.u2 . hnorm t2; 37. return (u1 == \nu2)) where rel of (eq : Eq): exp \u00d7 exp . Prop := match eq with simp ab . fun t. t.1= const a . t.2= const \nb | comp cc1 c2 . fun t. t.1= const c . t.2= app (const c1)(const c2) end Figure 3. The main functions \nof the fast congruence closure algo\u00adrithm, and their speci.cations. classes of a and b (lines 7 10). \nIf merge is passed a compound equation c = c1 c2, then the lookup table is queried for an equation v \nof the form b = b1 b2,where bi and ci have the same representa\u00adtives (lines 12 14). If such an equation \nexists, then to extend R with eq, it suf.ces simply to join the congruence classes of b and c.This is \naccomplished by putting the pair (b, c) on the top of the pending list, and again invoking hpropagate \n(lines 25 28). If an equation v does not exist, then it suf.ces to insert the equation c = c1 c2 directly \ninto the lookup table for future queries (line 21), and add the equation to the use lists of c1 ' and \nc2 ' (lines 18 23). The type of check declares that the return boolean value y shows whether the pair \n(t1,t2) is in the congruence relation R represented by the internal state. check .rst normalizes t1 and \nt2;thatis, it expresses t1 and t2 in terms of representatives, using the helper function hnorm de.ned \nin Figure 4. Then the obtained normal forms are compared for syntactic equality (lines 35 37). Next we \nhave to implement and verify the helper functions. There will be four of them: hpropagate and hnorm are \ndirectly used by the main functions, and hjoin class (Figure 6) and hjoin use (Figure 7), are called \nfrom within hpropagate. In the veri.cation 38. hnorm (t : exp)= 39. .x (fun hnorm (t:exp). 40. do (match \nt with 41. const a .  ' 42.a . Array.read ra; ' 43. return (const a ) 44. | app t1 t2 .  45.u1 . \nhnorm t1; 46.u2 . hnorm t2; 47. match u1,u2 with 48. const w1, const w2 .  49.v . Hashtab.lookup htab \n(w1,w2); 50. match v with 51. None . return (app u1 u2) 52. | Some (b, , ) . 53.b ' . Array.read rb; \n 54. return (const b ' ) 55. end 56. | ,  . return (app u1 u2) 57. end 58. end)) t  Figure 4. Helper \nfunction for normalizing expressions. of the helper functions we adopt the following strategy. We .rst \nim\u00adplement the purely-functional variants propagate, norm, join class and join use, which is possible \nsince the logic of Coq already in\u00adcludes pure lambda calculus with terminating recursion, and all of \nthe helper functions are terminating loops. The pure variants will operate on the values of the data \nrecord, rather than on the pointers themselves. Of course, the pure variants do not exhibit the desired \nrun-time complexity and ef.ciency, so we only use them for speci\u00ad.cation and reasoning. In particular, \nas a .rst phase of veri.cation, we prove that each helper method exhibits the same behavior on the underlying \nstateful structures as that described by its pure variant. The .rst phase takes care of all the reasoning \nabout pointers, alias\u00ading and heap disjointness. Then in the second phase, we show that the pure variants \ncombine to correctly compute congruence clo\u00adsure, but our task will be simpli.ed by not having to worry \nabout pointers anymore. In Figures 4-7, we present the helper functions, but omit the de.nitions of the \npure variants, as these we hope can easily be reconstructed from our discussion of the code. To reduce \nclutter, we also omit the types and the various loop invariants, since at this .rst phase these are not \nparticularly involved: they all basically state that the helper function and its pure variant correspond \nto each other. For example, the types of hnorm and hpropagate are normT =.t:exp. STsep exp (fun i. .D. \nshape pD i, fun yim. .D. shape pDi . shape pDm . y = norm Dt) propagateT = STsep unit (fun i. .D. shape \npD i, fun yim. .D. shape pDi . shape p (propagate D) m)  which show that the result of hnorm is speci.ed \nby norm,and the behavior of hpropagate is speci.ed by propagate. We start our description with the function \nhnorm for computing normal forms of expressions, given in Figure 4. If the expression t is a constant \nsymbol a, then the normal form of t is the repre\u00adsentative a ' , as read from the array of representatives \n(lines 42-43). Otherwise, t is an expression of the form t1 t2. To compute its nor\u00admal form, we recursively \ncompute the normal forms u1 and u2 of t1 and t2, respectively (lines 45-46). In case u1 and u2 are themselves \nconstant symbols w1 and w2, then the lookup table may contain an equation of the form b = w1 w2 which \nwould imply that the normal form should be b ' (lines 53-54). Otherwise, we return the application u1 \nu2 as the result (lines 51 and 56). 59. hpropagate = 60. .x (fun loop (x:unit). 61. do (q . !p; 62. \nif q == null then return () 63. else 64. eq . !q; 65. next . !(q +1);  66.p := next; 67. dealloc \nq; 68. dealloc (q +1);  ' 69.a . Array.read r (eq.1); 70.b ' . Array.read r (eq.2);  ' 71. if a == \nb ' then loop () 72. else  ' 73. hjoin class ab ' ; ' b ' 74. hjoin use a ; 75. loop ())) ()  Figure \n5. Helper function for propagating the pending equations. ' 76. hjoin class (ab ' : symb)= 77. .x (fun \nloop (x : unit). 78. do (ua . Array.read clist a ' ; 79. ub . Array.read clist b ' ; 80. if ua == \nnull then return() 81. else  82.s . !ua; 83. next . !(ua +1); 84. ua +1 := ub; 85. Array.write clist \nb ' ua; 86. Array.write clist a ' next; 87. Array.write rsb ' ; 88. loop ())) ()  Figure 6. Helper \nfunction for merging the class lists of a ' and b ' . The function hpropagate from Figure 5 is the main \nloop of merge. Its role is to empty the list of pending simple equations, by merging these equation into \nthe other structures. Each pend\u00ading equation is represented as a pair of symbols eq =(a, b),de\u00adnoting \nthat the congruence classes of a and b should be merged. hpropagate reads off the equations from the \npending list one\u00adby-one (lines 61 68), computes the representatives a ' and b ' of the .rst and second \nelements of eq, respectively (lines 69-70). If a ' and b ' are equal, then the equation is redundant. \nOtherwise, hpropagate calls helper functions hjoin class and hjoin use to merge the classes of a ' and \nb ' and adjust the various pointers and array .elds accordingly (lines 71-75). The function hjoin class \ntakes two distinct symbols a ' and b ' and modi.es the state of the algorithm so that the congruence \nclass of a ' is appended onto the congruence class of b ' . This involves obtaining the pointers to the \nclass list of a ' and b ' (lines 78-79), then iterating to remove the head symbols s from the class list \nfor a ' , push s onto the class list of b ' (lines 82-86), and then change the representative of s to \nb ' (line 87). A call to hjoin class joins the immediate data representing the congruence classes of \na ' and b ' , but a bit more work has to be done. For example, if the lookup table stores equations of \nthe form a ' b = c and b ' b = d,then merging a ' and b ' must be followed by a merge of c and d,inorder \nto restore internal consistency. This is the job of hjoin use. A naive implementation of hjoin use maybe \nsimplyto tra\u00adverse the lookup table, merging outstanding classes as they are discovered. A more ef.cient \nimplementation, shown in Figure 7, exploits the property that it suf.ces to revisit only the equations \nstored in the use list of a ' . If the use list of a ' contains the equation c1 = c2 c3, represented \nas a triple eqc =(c1,c2,c3), we query the lookup table for the key (c2' ,c3' ) (lines 97 99). If some \nequation ' d '' d ' eqd =(d1,d2,d3) is discovered, then c2 = 2, c3 = 3,bythe invariants of the algorithm, \nbut there is no guarantee that c1 and ' b ' 89. hjoin use (a : symb)= 90. .x (fun loop (x:unit). 91. \ndo (ua . Array.read ulist a ' ; 92. if ua == null then return () 93. else 94. eqc . !ua; 95. next \n. !(ua +1); 96. Array.write ulist a ' next;  ' 97.c2 . Array.read reqc.2 ' 98.c3 . Array.read reqc.3 \n'' 99.v . Hashtab.lookup htab (c2,c ); 3 100. match v with 101. None .  '' 102. Hashtab.insert htab \n(c2,c ) eqc; 103. ub . Array.read ulist b ' ; 104. ua +1 := ub; 105. Array.write ulist b ' ua; 106. \nloop () 107. | Some eqd . 108. dealloc ua; 109. dealloc (ua +1);  3 '  110.p . !p; 111.q . insert \np ' (eqc.1,eqd.1); 112.p := q; 113. loop () 114. end)) ())  Figure 7. Helper function for adjusting \nthe use lists and the lookup table, after the class lists of of a ' and b ' have been merged. d1 are \ncongruent. Thus, we schedule the pair (c1,d1) for merging, by placing it onto the pending list (lines \n110 112). If the query re\u00adturns no equations, then we simply insert the equation eqc into the lookup \ntable (line 102). We also move eqc onto the use list of b ' ,to be considered in the future, when and \nif b ' is equated to some other symbol (lines 103 105). Either way, eqc has to be removed from the use \nlist of a ' (lines 96 and 108 109). The .rst phase of veri.cation now closely follows the approach outlined \nin Section 4, of applying the various structural lemmas and reordering heap unions so as to indicate \nthe subheap that the current command modi.es. For all the six methods in this section, it took 276 lines \nof proof to complete. One minor hurdle was de.ning the iterated operator \u00ae from the shape ' predicate. \nIt is best to iterate \u00ae over .nite sets, rather than lists, which was our .rst attempt. If s is a set \nof symbols, one can show x . s . \u00ae Pi = r Px * \u00ae Pi. i.si.s\\{x} We used this lemma to expose the heaps \nstoring the class and use lists of concrete symbols. If s were a list, the corresponding lemma requires \na spurious condition that s contains x only once. In our development, we were able to reuse Ssre.ect \ns extensive library of .nite sets over types with decidable equality. The second veri.cation phase mainly \ninvolves showing that the various properties listed in the shape predicate hold after the execution of \nthe pure variants of the helper functions. For example, one of the easier properties was that the predicate \nclass inv is preserved between the calls to the helper functions in hpropagate (lines 73-74), and after \nthe call to hpropagate in merge (lines 10 and 28). It is established by the following lemmas. ' = b ' \n' 1.a .. class inv D . class inv (join class Da ' b ' ) = b ' 2.a .. class inv D . class inv (join use \nDa ' b ' ) 3. class inv D . class inv (propagate D)  Most of the other predicates from the de.nition \nof shape were much more dif.cult to establish, primarily because they are actu\u00adally invalidated at various \npoint of the execution, but are then re\u00adestablished at the end. Thus, we needed to generalize these predi\u00adcates \nto properly capture how the code works at all stages, and then show that at the end of merge, the more \ngeneral versions imply the original de.nitions. This was, of course, the most dif.cult part of the whole \ndevelop\u00adment, as the dependencies between the congruence data structures are extremely subtle. The generalizations \nended up being very in\u00advolved, and took about 120 lines of Coq de.nitions, just to state. For example, \nit turns out that in cases when the pending list is not empty, the appropriate generalization of the \nuse lkp inv property which relates the use lists with the lookup table is: use lkp inv0 D = .acc1 c2.a \n. reps D . (c, c1,c2) . use Da . .dd1 d2. lookup D (rep Dc1, rep Dc2)= Some (d, d1,d2) . rep Dc1 = rep \nDd1 . rep Dc2 = rep Dd2 . similar Dcd Here, similar Dcd holds if the symbols c and d are in the congru\u00adence \nrelation generated by the equations x = rep Dx for all x, as well as the equations in the pending list. \nThe property of similarity justi.es the algorithm to save time when processing the use lists, and sometimes \nomit equations as redundant, on the grounds that their involved symbols will eventually be equated once \nthe pending list is emptied. ' b ' After an equation a = is removed from the pending list ' b ' in hpropagate, \nand before a call to hjoin class a (line 73), another property use lkp inv1 D is required. This one replaces \nsimilar Dcd in the de.nition of use lkp inv0 with similar1 Dcd which makes it possible that c and d are \nrelated via an equation a ' = b ' as well. Yet another property use lkp inv2 is required to describe \nthe relation between the use lists and the lookup table after a call to hjoin class, and during the call \nto hjoin use, etc. Similar generalizations have to be made to lkp use inv as well, and then one has to \nprove that these properties indeed hold in the various stages of the program. In these proofs, we may \nneed to rely on some of the other invariants. For example, we have a lemma ' b ' join classP (D : data)(a \n: symb): '' = b ' a . reps D . b ' . reps D . a .. rep idemp D . use inv D . lkp inv D . use lkp inv1 \nDa ' b ' . lkp use inv1 Da ' b ' . use lkp inv2 (join class Da ' b ' ) a ' b ' . lkp use inv2 (join class \nDa ' b ' ) a ' b ' , which states that the above properties hold after a call to hjoin class, assuming \nthat appropriate properties held before the call. Then similar lemmas have to be proved for join use \nand propagate in all combinations with the properties from the de.nition of shape. Altogether, these \nproofs took 645 lines of proof, re.ecting the subtlety of the invariants of the fast congruence closure \nalgorithm, which is required for its practical ef.ciency. Of course, before we were able to carry out \nthese proofs, we .rst had to develop a number of facts about congruences and closures, de.ne the data \ntypes, de.ne the pure variants of the helper function and prove them terminating, and de.ne the generalized \ninvariants themselves. This background development took another 632 lines.  6. Using Coq and Ssre.ect \nIn our developments, we have kept the proofs fully explicit, always naming hypotheses as they are introduced, \ndestructed, or modi.ed. We have found this explicitness to be quite helpful when refactoring larger developments, \nsuch as our veri.cation of fast congruence closure. When proofs are explicit in this sense, making changes \nto the de.nitions and lemmas usually causes the proofs to break exactly at the point where the error \nintroduced by the changes actually is, rather than somewhere at random later in the proof. Furthermore, \nwe have used only a few simple custom-made tactics that we describe below, and have otherwise relied \non only the standard primitives of Coq and Ssre.ect for introduction and destruction of hypotheses, lemma \napplication and rewriting. All of these have direct analogues in the natural deduction rules for Coq. \nDespite the full explicitness and general absence of automation, our proofs are perhaps somewhat surprisingly \n still quite short and comparable in size with other approaches, such as Ynot and Jahob, which use very \naggressive automation (we discuss the relation to Ynot and Jahob in Section 7). Even in the case of congruence \nclosure, whose full proof was quite large, the phase of the proof related to pointers and aliasing was \nproportional in size to the veri.ed program. We attribute these properties not only to our new techniques, \nbut also to the very prudent design of the Ssre.ect language and libraries.         The tactics \nthat we have used are the following. 1. heap cancel takes a hypothesis in the form of an equation be\u00adtween \nheaps, such as for example [x -v1] h1 =[x -v2] h2, and derives consequences from it, like v1 = v2 and \nh1 = h2, which it prepends onto the goal of the sequent. In exam\u00adple 2, we have used a simple iteration \nof the cancellation lemma for this purpose, but heap cancel is more general, as it does not rely on the \norder of heaps in the union. 2. heap congr is dual to heap cancel. It takes a goal in the form of a \nheap equation, and produces subgoals needed to discharge it. In the above example, it would produce exactly \nthe subgoals v1 = v2 and h1 = h2. 3. defcheck takes an implication of the form def h1 . def h2, where \nh1 and h2 are unions of heaps, and tries to discharge it by matching all the locations in the heaps in \nh2 to locations in the heaps in h1, irrespectively of the order in which they appear. Thus, it effectively \nchecks if the domain of the union h2 is a subdomain of h1. 4. hauto combines the generation of uni.cation \nvariables (the econstructor primitive of Coq), with heap cancel and defcheck. 5. heval pattern-matches \nagainst the goal in the form of a verify predicate, to determine the .rst command appearing in it, so \nthat it can choose which bnd command or val command lemma from Section 4 to apply.  All of these tactics \nare conceptually simple, and only modify goals of sequents, but not the hypotheses; thus they do not \nbreak the ex\u00adplicit nature of our proofs. However, because Coq s tactic language is interpreted and untyped, \nwe have still found them to be some\u00adwhat slow in practice, and quite dif.cult to debug and maintain. \nIn future work, we plan to remove even these tactics, and replace them with equivalent lemmas and rewrite \nrules, which could possibly be built using ideas based on re.ection. 7. Related work HTT and Ynot Just \nlike the current paper, the original implemen\u00adtations of HTT and Ynot [20, 21] used Hoare triples with \nbinary postconditions. However, those papers did not recognize the con\u00adnection between binary postconditions \nand structural rules which we proposed here. In particular, they used a different de.nition of the verify \npredicate from the one we used in Section 3, and which in our current notation can be presented roughly \nas follows. verify isq = .hi1.i = i1 h . def i . pre si1 . .ymm1.m = m1 h . def m . post syi1 m1 . \nqyim This de.nition existentially abstracts over the invariant part h of the heap, and thus directly \nbakes in the frame rule into the semantics of Hoare triples. In this sense, it is closely related to \nthe recent semantic models of separation logic by Birkedal et al. [7]. However, abstracting h on the \noutside causes this de.nition to not support the rules of conjunction (binary or quanti.ed), without \nadditional requirements such as, for example, that pre s determines a unique subheap of i (i.e., that \npre s is a precise predicate, in separation logic terminology). Our de.nition from Section 3 does not \nimpose such additional requirements. Furthermore, the implementation in [21] relied on a naive de.\u00adnition \nof heaps from Section 2, which caused an explosion in proof obligations. This problem was already observed \nby Krishnaswami et al. [15], who attempted to use the system to verify the .y\u00adweight OO-design pattern, \nbut could not .nish the proof. This motivated Chlipala et al. [11] to revert to the (*) fragment, unary \npostconditions and no explicit heap variables, as well as to develop a number of tactics for automating \nthe reasoning in separation logic. This is an appealing idea, as binary postconditions come with a redundancy \nexhibited in our Example 4, where the type of remove had to repeat the precondition as an antecedent \nof an implication in the postcondition. With unary postconditions, one could write this type simply as \nremove p : STsep loc (lseq pl, fun q. lseq q (tail l)). The latter, however, opens the question of where \nand how the variable l should be bound. One cannot use the ordinary dependent function type and write \n.l:list T. STsep loc (lseq pl, fun q. lseq q (tail l)), because this allows l to be used in commands \nof the above type, and l is supposed to only be a logical variable; that is, it can appear in speci.cations, \nbut not in the commands. Chlipala et al. propose that logical variables be coerced into proofs, and write \nroughly .l:inhabited(list T ). STsep loc (let pack l = x in lseq pl, fun q. let pack l = x in lseq q \n(tail l)) where inhabited A is the proposition .x:A. T,and pack : A . inhabited A is the single constructor \nof proofs of this proposition. Coq s type theory makes it impossible to unpack l within an executable \nprogram, and Coq s extraction mechanism for remove would, appropriately, not produce a closure which \nabstracts over l. This coercion, however, comes with signi.cant logical com\u00adplexity. Even if l cannot \nbe unpacked in a command e, it does not prevent l from being used in e, albeit packed. Thus, it is not \nclear that the technique can support structural rules where one needs to test if l/. FV(e), such as the \nrule for existentials. Indeed, the sys\u00adtem in [11] does not support this rule (nor any other structural \nrule beyond frame and consequence), which is a restriction that leads to loss of abstraction. The existential \nrule is frequently used to push a logical variable into the pre/post-conditions, so that it can be re\u00admoved \nlater by applying the rule of consequence. Without the ex\u00adistential rule, it seems that logical variables \nmust remain bound in the type, even if they are not needed anymore. Working with the coercions further \nrequires adding an axiom pack injective : .T :Set. .xy:T. pack x = pack y . x = y, which compares proofs \nfor equality, and is thus unsound in the presence of important features such as proof irrelevance or \nclassical logic. It may be possible that the recent extension of the calculus of constructions with a \nvariant of intersection types [2], may offer a way out of these logical problems, and allow structural \nrules to be encoded as typing rules, rather than as logical formulas. But even then, questions remain \nas to the practicality of such an encoding. For example, Chlipala et al. encode the frame rule as a typing \nrule; as a result, programs written in their system often have to be ex\u00adplicitly annotated with framing \npredicates, as well as with instanti\u00adations for various ghost variables. In our opinion, this signi.cantly \nobscures the structure of the programs. Our approach with binary postconditions does not require such \nannotations, as witnessed by our examples in Section 5. Binary postconditions also allow the user to \nderive auxiliary structural rules, thus implementing custom veri.cation strategies, while it is not clear \nthat this can be done in the alternative approach.  Moreover, binary postconditions do not lead to \nproof explosion, as the redundancy that they exhibit can be removed in proofs merely by one application \nof all imp, or one of the related lemmas. And indeed, on the examples that we have implemented in common \nwith [11], our developments are of comparable size, even if we do not use signi.cant automation by tactics. \nFor example, in the release current at the time of our writing, the veri.cations of stacks, queues and \nhash tables in the system of [11] take respectively 86, 199 and 397 lines of code, speci.cations, lemmas, \ntactics and proofs, whereas in our system, these numbers are 66, 116 and 160. Separation logic in type \ntheory Appel [1] de.nes heaps as .nite lists of location-value pairs, just like we do, but does not re.ect \nthe disjointness predicate. As a consequence, he observes that ... the nonlinear conjunction of separation \nlogic is not well suited to the assumptions of tactical provers... , and restricts to the (*) fragment. \nMarty et al. [17] de.ne heaps in a similar way too, but they use a union operator which is not commutative, \nand thus also treat only the (*) fragment. McCreight [18] de.nes heaps following the memory model of \nLeroy et al. [16], which allows him to de.ne a union operator that is commutative and associative, but \nhis operator does not propagate the disjointness information, and hence there is no equivalent of our \ndef predicate, which is crucial for ef.cient work. Thus, McCreight too admits only the (*) fragment. \nAll of these systems target deeply embedded programs and languages, unlike HTT which uses shallow embedding. \nVeri.cation of linked data structures Jahob [27] is another higher-order system in which veri.cation \nof interesting pointer\u00adbased data structures has been performed. Jahob computes the veri\u00ad.cation conditions \nfor Java programs, and then feeds the conditions to automatic provers for discharging. The programmer \nhas the op\u00adtion of including proof hints with the code, which can be used to guide the automation. In \nthis respect, the proof hints in Jahob are similar to our explicit proofs. In the case of hash tables, \nJahob takes 343 lines of proof hints and invariants, which is comparable in size to our proofs. One important \ndifference between HTT and Jahob is that Java, unlike Coq, has not been designed with proofs in mind, \nand thus lacks the ability to package together programs, properties and proofs, and parametrize libraries \nwith respect to such packages. We have used this in Section 5 to parametrize the implementation of congruence \nclosure with respect to the signatures for arrays and hash tables. This makes it possible for us to freely \nplug in any veri.ed implementation of these signatures, without changing the code or the proofs of congruence \nclosure. We have not found a dis\u00adcussion or a theorem in [27] of whether similar substitutability is \npossible in Jahob as well. Higher-order separation logic Krishnaswami et al. [15] has re\u00adcently developed \na higher-order separation logic for programs writ\u00adten in the core fragment of an ML-like language, and \napplied it to a veri.cation of several object-oriented patterns. One difference from HTT is that the \nlanguage in [15] is simply typed, and thus does not support .rst-class structures and functors that come \nfor free with the dependent types of Coq, and are important for pro\u00adgramming and proving in-the-large. \nBirkedal et al. [7] consider a higher-order separation logic and its interaction with higher-order frame \nrules and parametricity. In the current paper, we have not considered these issues, but believe that \nit is an important future work to build models for HTT that reconcile these features with dependent types. \n 8. Conclusions The most common approach to program veri.cation in separation or other logics is to \ninvestigate how to automate the discharging of the proof obligations in order to reduce the burden on \nthe human veri.er. Automation works very well when the properties of interest are relatively simple, \nbut in the case of full functional veri.cation, it is frequently insuf.cient. In this paper, we instead \ninvestigate how to exploit the structuring primitives of type theory, to prevent the proof obligations \nfrom being generated in the .rst place. Our .rst example was a new de.nition of heaps, which let us work \nef.ciently with ordinary logical connectives, without in\u00adducing a blowup in the proof obligations about \nheap disjointness. The de.nition involved advanced type theoretic features, such as dependently-typed \nprogramming and re.ection, but its main point was to ensure that heaps satisfy the algebraic properties \nof a par\u00adtial commutative monoid (PCM). PCMs have been considered be\u00adfore in the semantics of separation \nlogic [9], but here we show that if heaps are PCMs, then it becomes quite practical to unfold the de.nitions \nof separating connectives such as *, and work directly with heap variables and disjoint unions. The latter \nwas necessary for supporting non-separating connectives such as conjunction, im\u00adplication and universal \nquanti.cation. Our second example was embedding and reformulating a sep\u00adaration logic for partial correctness \ninto type theory with the use of binary postconditions. This made it possible to derive custom structural \nrules that helped in proofs. Moreover, stating the rules in this way essentially depends on our de.nition \nof heaps, because it requires a logic that ef.ciently supports implication and universal quanti.cation. \nWe have used our approach successfully to verify a number of smaller programs such as modules for arrays, \nlinked lists, stacks, queues and hash tables. In all the cases, we were able to produce correctness proofs \nof size proportional to the size of the programs. We have shown that the approach scales to larger examples \nas well, by verifying one of the fastest known congruence closure algorithms, used in the Barcelogic \nSAT solver. 9. Acknowledgment We thank Georges Gonthier for introducing us to Ssre.ect,and Nick Benton \nand Martin Hofmann for discussions regarding de\u00adpendent types.  References [1] A. W. Appel. Tactics \nfor separation logic. Available at http://www.cs.princeton.edu/ appel/papers/septacs.pdf, 2006. [2] B. \nBarras and B. Bernardo. The implicit calculus of constructions as a programming language with dependent \ntypes. In FoSSaCS 08, pages 365 379. [3] C. Barrett, M. Deters, A. Oliveras, and A. Stump. Design and \nresults of the 4th annual satis.ability modulo theories competition (SMT-COMP 2008). To appear. [4] J.M.L.Bean. \nRibbon Proofs A Proof System for the Logic of Bunched Implications. PhD thesis, Queen Mary University \nof London, 2006. [5] J. Berdine, C. Calcagno, B. Cook, D. Distefano, P. W. O Hearn, T. Wies, and H. \nYang. Shape analysis for composite data structures. In CAV 07, pages 178 192.  [6] J. Berdine, C. Calcagno, \nand P. W. O Hearn. Smallfoot: Modular au\u00adtomatic assertion checking with separation logic. In Formal \nMethods for Components and Objects, pages 115 137, 2006. [7] L. Birkedal and H. Yang. Relational parametricity \nand separation logic. Logical Methods in Computer Science, 4(2:6):1 27, 2008. [8] C. Calcagno, D. Distefano, \nP. O Hearn, and H. Yang. Compositional shape analysis by means of bi-abduction. In POPL 09, pages 289 \n300. [9] C. Calcagno, P. W. O Hearn, and H. Yang. Local action and abstract separation logic. In LICS \n07, pages 366 368. [10] B.-Y. E. Chang and X. Rival. Relational inductive shape analysis. In POPL 08, \npages 247 260. [11] A. J. Chlipala, J. G. Malecha, G. Morrisett, A. Shinnar, and R. Wis\u00adnesky. Effective \ninteractive proofs for higher-order imperative pro\u00adgrams. In ICFP 09, pages 79 90. [12] X. Feng, Z. Shao, \nY. Dong, and Y. Guo. Certifying low-level programs with hardware interrupts and preemptive threads. In \nPLDI 08, pages 170 182. [13] D. Galmiche and D. M\u00b4ery. Semantic labelled tableaux for proposi\u00adtional \nBI. Journal of Logic and Computation, 13(5):707 753, 2003. [14] G. Gonthier and A. Mahboubi. A small \nscale re.ection extension for the Coq system. Technical Report 6455, INRIA, 2007. [15] N. R. Krishnaswami, \nJ. Aldrich, L. Birkedal, K. Svendsen, and A. Buisse. Design patterns in separation logic. In TLDI 09, \npages 105 116.  [16] X. Leroy and S. Blazy. Formal veri.cation of a C-like memory model and its uses \nfor verifying program transformations. J. Autom. Reason., 41(1):1 31, 2008. [17] N. Marty and R. Affeldt. \nA certi.ed veri.er for a fragment of separa\u00adtion logic. Computer Software, 25(3):135 147, 2008. [18] \nA. McCreight. Practical tactics for separation logic. In TPHOL 09, pages 343 358. [19] A. Nanevski, G. \nMorrisett, and L. Birkedal. Polymorphism and sepa\u00adration in Hoare Type Theory. In ICFP 06, pages 62 73. \n[20] A. Nanevski, G. Morrisett, and L. Birkedal. Hoare type theory, polymorphism and separation. Journal \nof Functional Programming, 18(5&#38;6):865 911, 2008. [21] A. Nanevski, G. Morrisett, A. Shinnar, P. \nGovereau, and L. Birkedal. Ynot: Dependent types for imperative programs. In ICFP 08, pages 229 240. \n[22] H. H. Nguyen and W.-N. Chin. Enhancing program veri.cation with lemmas. In CAV 08, pages 355 369. \n[23] R. Nieuwenhuis and A. Oliveras. Fast congruence closure and exten\u00adsions. Information and Computation, \n205(4):557 580, 2007. [24] P. O Hearn. On bunched typing. Journal of Functional Programming, 13(4):747 \n796, 2003. [25] P. O Hearn, J. Reynolds, and H. Yang. Local reasoning about pro\u00adgrams that alter data \nstructures. In CSL 01, pages 1 19. [26] J. C. Reynolds. Separation logic: A logic for shared mutable \ndata structures. In LICS 02, pages 55 74. [27] K. Zee, V. Kuncak, and M. Rinard. An integrated proof \nlanguage for imperative programs. In PLDI 09, pages 338 351.  \n\t\t\t", "proc_id": "1706299", "abstract": "<p>Most systems based on separation logic consider only restricted forms of implication or non-separating conjunction, as full support for these connectives requires a non-trivial notion of variable context, inherited from the logic of bunched implications (BI). We show that in an expressive type theory such as Coq, one can avoid the intricacies of BI, and support full separation logic very efficiently, using the native structuring primitives of the type theory.</p> <p>Our proposal uses reflection to enable equational reasoning about heaps, and Hoare triples with binary postconditions to further facilitate it. We apply these ideas to Hoare Type Theory, to obtain a new proof technique for verification of higher-order imperative programs that is general, extendable, and supports very short proofs, even without significant use of automation by tactics. We demonstrate the usability of the technique by verifying the fast congruence closure algorithm of Nieuwenhuis and Oliveras, employed in the state-of-the-art Barcelogic SAT solver.</p>", "authors": [{"name": "Aleksandar Nanevski", "author_profile_id": "81100503327", "affiliation": "IMDEA Software, Madrid, Spain", "person_id": "P1911088", "email_address": "", "orcid_id": ""}, {"name": "Viktor Vafeiadis", "author_profile_id": "81100493655", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P1911089", "email_address": "", "orcid_id": ""}, {"name": "Josh Berdine", "author_profile_id": "81100298282", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P1911090", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706331", "year": "2010", "article_id": "1706331", "conference": "POPL", "title": "Structuring the verification of heap-manipulating programs", "url": "http://dl.acm.org/citation.cfm?id=1706331"}