{"article_publication_date": "01-17-2010", "fulltext": "\n * Generating Compiler Optimizations from Proofs RossTate Michael Stepp Sorin Lerner University of California, \nSan Diego {rtate,mstepp,lerner}@cs.ucsd.edu Abstract We present an automated technique for generating \ncompiler op\u00adtimizations from examples of concrete programs before and after improvements have been made \nto them. The key technical insight of our technique is that a proof of equivalence between the original \nand transformed concrete programs informs us which aspects of the programs are important and which can \nbe discarded. Our technique therefore uses these proofs, which can be produced by translation validation \nor a proof-carrying compiler, as a guide to generalize the original and transformed programs into broadly \napplicable op\u00adtimization rules. We present a category-theoretic formalization of our proof gen\u00aderalization \ntechnique. This abstraction makes our technique appli\u00adcable to logics besides our own. In particular, \nwe demonstrate how our technique can also be used to learn query optimizations for re\u00adlational databases \nor to aid programmers in debugging type errors. Finally, we show experimentally that our technique enables \npro\u00adgrammers to train a compiler with application-speci.c optimiza\u00adtions by providing concrete examples \nof original programs and the desired transformed programs.Wealsoshowhowit enablesa com\u00adpiler to learn \ne.cient-to-run optimizations from expensive-to-run super-optimizers. Categories and Subject Descriptors \nD.3.4 [Programming Lan\u00adguages]: Processors Compilers; Optimization General Terms Languages, Performance, \nTheory 1. Introduction Compilers are one of the core tools that developers rely upon, and as a result \nthey are expected to be reliable and provide good perfor\u00admance. Developing good compilers however is \ndi.cult, and the op\u00adtimization phase of the compiler is one of the trickiest to develop. Compiler writers \nmust develop complex transformations that are correct, do not have unexpected interactions, and provide \ngood per\u00adformance, a task that is made all the more di.cult given the number of possible transformations \nand their possible interactions. The broad focus of our recent work in this space has been to provide \ntools that help programmers with the di.culties of writing compiler optimizations. In this context, we \nhave done work on automatically proving correctness of transformation rules, on * This work was supported \nby NSF CAREER grant CCF-0644306. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage.To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 10, January 17 23, 2010, Madrid, Spain. Copyright c . 2010ACM 978-1-60558-479-9/10/01... \n$10.00 generating provably correct data.ow analyses, and on mitigating the complexity of how transformation \nrules interact. Despite all these advances, programmers who wish to imple\u00adment optimizations often still \nhave to write down the transforma\u00adtion rules that make up the optimizations in the .rst place. This task \nis error prone and tedious, often requiring multiple iterations to get the rules to be correct. It also \noften involves languages and inter\u00adfaces that are notfamiliar to the programmer: eithera language for \nrewrite rules that the programmer needs to become familiar with, or an interface in the compiler that \nthe programmer needs to learn. These di.culties raise the barrier to entry for non-compiler-experts who \nwish to customize their compiler. In this paper, we present a new paradigm for expressing com\u00adpiler optimizations \nthat drastically reduces the burden on the pro\u00adgrammer. To implement an optimization in our approach, \nall the programmer needs to do is provide a simple concrete example of what the optimization looks like. \nSuch an optimization instance consists of some original program and the corresponding trans\u00adformed program. \nFrom this concrete optimization instance, our sys\u00adtem abstracts away inessential details and learns a \ngeneral opti\u00admization rule that can be applied more broadly than on the given concrete examples and yet \nis still guaranteed to be correct. In other words, our system generalizes optimization instances into \ncorrect optimization rules. Our approach reduces the burden on the programmer who wishes to implement \noptimizations because optimization instances are much easier to develop than optimization rules. There \nis no more need for the programmer to learn a new language or inter\u00adface for expressing transformations. \nInstead, the programmer can simply write down examples of the optimizations that they want to see happen, \nand our system can generate optimization rules from these examples. The simplicity of this paradigm would \neven enable end-user programmers, who are not compiler experts, to extend the compiler using what is \nmost familiar to them, namely the source language theyprogram in. In particular, if an end-user programmer \nsees that a program is not compiled as they wish, they can simply write down the desired transformed \nprogram, and from this con\u00adcrete instance our approach can learn a general optimization rule to incorporate \ninto the compiler. Furthermore, optimization instances can also be found by simply running a set of existing \nbenchmarks through some existing compiler, thus allowing a programmer to harvest optimization capabilities \nfrom several existing compilers. The key technical challenge in generalizing an optimization instance \ninto an optimization rule is that we need to determine which parts of the programs in the optimization \ninstance mattered, and how they mattered. Consider for example the very simple concrete optimization \ninstance x+(x-x) .x, in which the variable . x is used three times in the original program. This optimization \nhowever does not depend on all three uses referring to the same variable x. All that is required is that \nthe uses in (x-x) refer to the same variable, whereas the .rst use of x can refer to another variable, \nor more broadly, to an entire expression.  Our insight is that a proof of correctness for the optimization \ninstance can tell us precisely what conditions are necessary for the optimization to apply correctly. \nThis proof could either be gener\u00adated by a compiler (if the optimization instance was generated from \na proof-generating compiler), or more realistically, it can be gener\u00adated by performing translation validation \non the optimization in\u00adstance. Since the proof of correctness of the optimization instance captures precisely \nwhat parts of the programs mattered for correct\u00adness, it can be used as a guide for generalizing the \ninstance. In particular, while keeping the structure of the proof unchanged, we simultaneously generalize \nthe concrete optimization instance and its proof of correctness to get a generalized transformation and \na proof that the generalized transformation is correct. In the example above, the proof of correctness \nfor x+(x-x) .x does not rely on . the .rst use of x referring to the same variable as the other uses \nin (x-x), and so the optimization rule we would generate from the proof would not require them to be \nthe same. In this way we can generalize concrete instances into optimization rules that apply in similar,but \nnot identical, situations while still being correct. Our contributions can therefore be summarized as \nfollows: We present a technique for generating optimization rules from optimization instances by generalizing \nproofs of correctness and the objects that these proofs manipulate (Section 2).  We formalize our technique \nas a category-theoretic framework that can be instantiated in various ways by de.ning a few key categories \nand operations on them (Section 3). The general na\u00adture of our formalism makes our technique broadly \napplicable.  We illustrate the generality of our framework by instantiating it not only to compiler \noptimizations (Section 4), but to other domains (Section 5). In the database domain, we show that proof \ngeneralization can be used to learn e.cient query opti\u00admizations. In the type-inference domain, we show \nthat proof generalization can be used to improve type-error messages.  We used an implementation of \nour approach in the Peggy com\u00adpiler infrastructure[22]tovalidatethe following threehypothe\u00adses about \nour approach: (1) our approach can learn complex op\u00adtimizations not performed by gcc -O3 from simple \nexamples provided by the programmer (2) it can learn optimizations from Peggy s expensive super-optimization \nphase (3) it can learn op\u00adtimizations that are useful on code that it was not trained on.  2. Overview \nThe goal that we are trying to achieve is to generalize optimization instances into optimization rules. \nThe key to our approach is to use a proof of correctness of the optimization instance as a guide for \ngeneralization. The proof of correctness tells us precisely what parts of the program mattered and how, \nso that we can generalize them in a way that retains the validity of the proof structure. Intuitively, \nour approach is to .x the proof structure, and then try to .nd the most general optimization rule that \na proof of that structure proves correct. Focusing on a given proof structure also has the added advantage \nthat, once the structure is .xed, we will be able to show that there exists a unique most general optimization \nrule that can be inferred from the proof structure, something that does not hold in general. For example, \nconsider the optimization instance 0 . * 0 . 0. This transformation has two incomparable generalizations, \nX * 0 .. 0 and 0 * X . . 0, depending on whether one uses the axiom .x.x*0 = 0or .x.0*x = 0to prove correctness. \nHowever, once we settle on a given proof of correctness, not only does there exists a most general optimization \nrule given the proof structure,but we can also show that our algorithm infers it. In this section, we \nstart by giving some examples of proof-based generalization (Section 2.1), explain some of the challenges \nbe\u00adhind generalization (Section 2.2),give anoverviewof our technique (Section 2.3), and .nally describe \na way of decomposing optimiza\u00adtions we generate into smaller independent ones (Section 2.4). 2.1 Generalization \nexamples Figure 1 shows an example of how our approach works. We de\u00adscribe the process at a high-level, \nand then describe the details of each step. At a high-level, we start with two concrete programs, presenting \nan example of what the desired transformation should do parts (a) and (b); we convert these programs \ninto our own in\u00adtermediate representation parts (c) and (d); we then prove that the two programs are \nequivalent, a process known as translation vali\u00addation part (e); from the proof of equivalence we then \ngeneralize into optimization rules parts (f) and (g) show two possible gener\u00adalizations.We now go through \neach of these steps in detail. The optimization that is illustrated in parts (a) and (b) of Fig\u00adure1is \ncalled loop-inductionvariable strength reduction (LIVSR). The optimization essentially replaces a multiplcation \nwith an addi\u00adtion inside of a loop. As we will show in Section 3, our approach is general and can be \napplied to manykinds of intermediate representations, and even to domains other than compiler optimizations. \nHowever, to make things concrete for our examples, we will use the PEG and E-PEG intermediate representations \nfrom our previous work on the Peggy compiler [22] (this is also the representation we use in our implementation \nand evaluation). Part (c) of Figure 1 shows a Program Expression Graph (PEG) representing the use of \ni*5 in the code of part (a).APEG contains nodes representing operators (for example + and * ), and edges \nrepresenting which nodes are arguments to which other nodes. The arguments to a node are displayed below \nthe node. The top of the PEG contains a multiply node representing the multiply from i*5. The . node \nrepresents the value of i inside the loop. In particular, the . node states that the initial value of \ni (the left child of .)is 0, and that the next value of i (the right child of .)is1plus the current value \nof i. Similarly, part (d) of the .gure shows the PEG for the use of i in part (b). Now that we have represented \nthe two programs in our interme\u00addiate reprensentation, we must prove that they are equivalent. We do \nso using an E-PEG, which is a PEG augmented with equality information between nodes. Graphically, we \nrepresent two nodes being equal witha dotted edge between then, althoughin our imple\u00admentation we represent \nequality by storing the equivalence classes of nodes. Part (e) of Figure 1 is an E-PEG, constructed by \napply\u00ading four equality axioms to the original PEG: edge .ais added by applying the axiom .(x,y)* z = \n.(x * z,y* z); edge b . is added by applying the axiom( x + y)* z = * z;edge c x * z + y. is added by \napplying the axiom 1 * x = d x; and edge . is added by applying the axiom0 * x = 0. This E-PEG represents \nmanydi.erent versions of the original program, depending on how we choose to compute each equivalence \nclass. By picking . to compute the {*,.}equiva\u00adlence class, and + to compute the {*, +} equivalence class, \nwe get the PEG from Figure 1(d), and as a result, the E-PEG therefore shows that the PEGs from parts \n(c) and (d) are equivalent. In our Peggy compiler, there are two ways of arriving at the E-PEG in Figure \n1(d). The .rst is as described above: we convert two programs into PEGs and then repeatedly add equalities \nuntil the result of the two programs become equal. The other approach is to start with just an original \nprogram and PEG, say the ones from Figure 1(a) and 1(c), and construct an E-PEG by repeatedly applying \naxioms to infer equalities. A pro.tability heuristic can then select which PEG is the most e.cient way \nof computing the results in the E-PEG, which in our case would be the PEG from Figure 1(d).  Original \nPrograms Translated PEGs Translation Validation Possible Generalized Optimizations i := 0 while(...){ \nuse(i*5) i := i+1 } (a) . +0 1 * 5 (c) . +0 1 * 5 . * 5 +* 0 5 0 * 1 5 5 a c d b (e) . +0 1 * (f) C . \n+0 C i := 0 while(...){ use(i) i := i+5 } (b) . +0 5 (d) . OP2C2 C3 OP1 C1 (g) . OP2C2 C1 where: distributes(OP1, \nOP2zero(C2, OP1) identity(C3, OP1) ) Figure 1. Loop InductionVariable Strength Reduction (LIVSR) Whichever \napproach is used, the starting point of generalization is the E-PEG from Figure 1(e), which represents \na proof that the PEGs from Figure 1(c) and Figure 1(d) are equivalent. In particular, edges adthe steps \nof the . through . in the E-PEG represent equivalence proof. Our goal is to take the conclusion of the \nproof in this case edge aand determine how one can generalize the E-PEG so that the . proof encoded \nin the E-PEG is still valid. Figures 1(f) and 1(g) show two possible generalized optimizations that can \nresult from this process.We representa generalized optimization as an E-PEG which contains a single equality \nedge, representing the conclusion of the proof. There are two ways of interpreting such E-PEGs. One is \nthat it represents a transformation rule, with the single equality edge representing the transformation \nto perform. The direction of the rule is determined by which of the two programs in the instance was \nthe original, and which was the transformed. Another way to interpret these rules is that theyrepresent \nequal\u00ad ity analyses to be used in our Peggy optimizer [22]. Optimizations in Peggy take the form of equality \nanalyses that infer equality infor\u00ad mation in an E-PEG. Starting with some original program, Peggy converts \nthe program to a PEG, and then repeatedly applies equality analyses to construct an E-PEG. It then uses \na global pro.tability heuristic to select the best PEG represented in the computed E- PEG, and converts \nthis PEG back to a program, which is the result of optimization. Section 7 will show that our generated \noptimiza\u00ad tions, when used as equality analyses, make Peggyfaster while still producing the same results. \nFurthermore, as equality analyses, our generated optimizations will just infer additional information \nfrom which the pro.tability heuristic can choose. We therefore do not have to worry about whether a generated \noptimization will always be just as pro.table as the optimization instance. Figure 1(f) showsa generalization \nwhere the constant5has been replaced with an arbitrary constant C. The key observation is that the particular \nchoice of constant does not a.ect the proof if we have a proof of LIVSR for 5, the same proof holds \nfor an arbitrary constant. Note that PEGs abstract away the details of the control .ow graph. As a result \nthe generalizations of Figure 1(f) could be applicapletoaPEGevenif there were manyother nodesinthePEG \nrepresenting various kinds of loops or statements not a.ecting the induction variable being optimized. \nFigure 1(g) shows a more sophisticated generalization, where instead of just generalizing constants, \nwe also generalize operators. In particular, the * and + operators have been generalized to OP1 and OP2, \nwith the added side condition that OP1 distributes over OP2 (there is no need to add a side-condition \nstating that OP1 distributesover .since all operators distributeover .). Furthermore,  + - -  ++ \nX0Y Z (b) Figure 2. Example showing the need for splitting the constants 0 and 1 have been generalized \nto C2 and C3 with the additional side conditions that C2 is a zeroing constant for OP1 and C3 is an identity \nconstant for OP2. The generalization in Figure 1(g) can apply to operators that have the same algebraic \nproperties as integer plus/multiply, for example boolean OR/AND, vector plus/multiply, set union/intersection, \nor any other operators for which the programmer states that the side conditions from Figure 1(g) hold. \nThe choice of axioms is what makes the di.erence between the above two generalizations. Figure 1(g) results \nfrom a proof expressed with more general axioms. Instead of the axiom(x +y)* z = x * z + y* z, the proof \nuses: OP1(OP2(x,y),z)= OP2(OP1(x,z),OP1(y,z)) where distributes(OP1, OP2) and instead of0 * x = 0, the \nproof uses: OP(C, x)= C where zero(C,OP) The LIVSR example therefore shows that the domain of axioms \nand proofs a.ects the kind of generalization that one can perform. More general axioms typically lead \nto more general generaliza\u00adtions. By using category theory to formalize our algorithm, we will be able \nto abstract away the domain in which axioms and proofs are expressed, thus separating the particular \nchoice of domains from the description of our algorithm. As a result, our algorithm as ex\u00adpressed in \ncategory theory will be general enough so that it can be instantiated with many di.erent kinds of domains \nfor proofs and axioms, including those that produce the di.erent generalizations presented above (and \nmanyothers too).  2.2 Challenge with obtaining the most generalform Looking at the LIVSR example, one \nmay think that generaliza\u00adtion is as simple as replacing all nodes and operators in an E-PEG with meta-variables, \nand then constraining the meta-variables  0 5 77 (a) (b) (c) Figure 3. Example showing how generalization \nworks based on the axioms that were applied. Although this approach is very simple, it does not always \nproduce the most general optimiza\u00adtion rule for a given proof. Consider for example the E-PEG from Figure \n2(a), where ais some PEG expression. Edge a . is produced by axiom x+0 = . by x-x 0; edge c= x;edge b= \n. by(x+y)-yx; edge .dby0 + x = x;and edge .eby transitivity of edges c . and d .. This E-PEG therefore \nrepresents a proof that the plus expression at the top is equivalent to a. If we replace nodes with meta-variables \nand constrain the meta-variables based on axiom applications, one would simply generalize a to a meta-variable. \nHowever, the most general optimization rule from the proof encoded in Figure 2(a) is shown in Figure \n2(b). Thekey di.erence is that by duplicating the shared + node, one can constrain the arguments of the \ntwo new plus nodes di.erently. However, because PEGs can contain cycles, one cannot simply duplicate \nevery node that is shared, as this would lead to an in.nite expansion. The main challenge then with getting \nthe most general form is determining precisely how much to split.  2.3 OurApproach Instead of generalizing \nthe operators in the .nal E-PEG to meta\u00advariables and then constraining the meta-variables, our approach \nis to start with a near empty E-PEG, and step through the proof back\u00adwards, augmenting and constraining \nthe E-PEG as each axiom is applied in the backward direction. This allows us to solve the above splitting \nproblem by essentially turning the problem on its head: in\u00adstead of starting with the .nal E-PEG and \nsplitting, we gradually add new nodes to a near-empty E-PEG, constraining and merging as needed. Our \nalgorithm therefore merges only when required by the proof structure,keeping nodes separate when possible. \nWe illustrate our approach on a very simple example so that we can show all the steps. Consider the E-PEG \nof Figure 3(a), where two axioms have been applied to determine equality edges a . and b .. The axioms \nare shown in Figure 3(c), with each axiom being an E-PEG where one edge has been labeled P for Premise \n, and one edge has been labeled C for Conclusion . The in the axioms represent meta-variables to be \ninstantiated. The .rst axiom states x - x = 0, and the second axiom states x + 0 = x. Our process is \nshown in Figure 3(b). We start at the top with a single equality edge representing the conclusion of \nthe proof, and then work our way downward by applying the proof in reverse order: in step 1 we apply \nthe second axiom backward, and then in step 2 we apply the .rst axiom backward. Each time we apply an \naxiom backward, we create and/or constrain E-PEG nodes in order to allow that axiom to be applied. Figure3shows \nusing .ne-dotted 1 51 Figure 4. One E-PEG with two conceptual optimizations edges how the Premise and \nConclusion edges of the axioms map onto the E-PEGs being constructed.Forexample, note thatin step 1, \nwhen the second axiom is applied backward, we remove the .nal conclusion edge, and instead replace it \nwith an E-PEG that essentially represents + 0. There is an alternate way of viewing our approach. In \nthis alternate view, we instantiate all the axioms that have been applied in the proof with fresh meta-variables, \nand then use uni.cation to stitch these freshly instantiated axioms together so that they connectinthe \nrightwaytomakethe proofwork.With thisviewin mind, we showin Figure3how the .rst and second axiomswould \nbe stitched together using a bi-directional arrow. This section has only given an overview of how our \napproach works. Sections3and4will formalize our approach using category theory and revisit the above \nexample in much more detail.  2.4 Decomposition Even though our algorithm .nds the most general transformation \nrule for a given proof, the produced rule may still be too speci.c to be reused. This can happen if the \ninput-output example has several conceptually di.erent optimizations happening at the same time. Consider \nfor example the optimization instance shown in Figure 4. The top of the Figure shows the original and \ntransformed code. There are two independent high-level optimizations. The .rst is LIVSR, which replaces \nthe i*5 with a variable j that is incremented by 5 each time around the loop; the second is specialization \nfor the true case of the if(!p) branch, so that it immediately returns. The corresponding E-PEG is shown \nat the bottom of the Figure. The E-PEG does not show all the steps instead it just displays the .nal \nequality edge ab ., and an additional edge ., which we will discuss shortly. This E-PEG uses three new \nkinds of nodes (all of which were introduced in [22]): f(p, et, ef )evaluates to et if p is true and \nef otherwise; eval(s,i)returns the ith element from the sequence s;andpass(s)returns the index of the \n.rst element in the boolean sequence s that is true. The eval/pass operators are used to extract the \nvalue of a variable after a loop. Consider for example the top-leftmost . in Figure 4, which represents \nthe sequence of values that the variable sum takes throughout the loop. The pass node computes the index \nof the last loop iteration, and the result of pass is used to index into the sequence of values of sum. \nIn the E-PEG, the two optimizations manifest themselves as fol\u00adlows: LIVSR happens using steps similar \nto those from Figure1 on the PEG rooted at the * b  node (producing edge .); the special\u00adization optimization \nhappens by pulling the f node up through the =, pass and eval nodes (producing edge a .). Each of these \nopti\u00admizations takes several axiom applications to perform, introducing various temporary nodes that \nare not shown in Figure 4. If we simply apply the generalization algorithm outlined in Sec\u00adtion 2.3, \nwe will get a single rule (although generalized) that applies the two optimizations together. However, \nthese two optimizations are really independent of each other in the sense that each can be applied fruitfully \nin cases where the other does not apply. Thus, in order to learn optimizations that are more broadly \napplicable, we further decompose optimizations that have been generalized into smaller optimizations. \nOne has to be careful, however, because de\u00adcomposing too much could just produce the axioms we started \nwith. To .nd a happymedium, we decompose optimizations as much as possible, subject to the following \nconstraint: we want to avoid generating optimization rules that introduce and/or manipulate tem\u00adporary \nnodes (i.e. nodes that are not in the original or transformed PEGs). The intuition is that these temporary \nnodes really embody intermediate steps in the proof, and there is no reason to believe that these intermediate \nsteps individually would produce a good optimization. To achieve this goal, we pick decomposition points \nto be equal\u00adities between nodes in the generalized original and transformed PEGs (and not intermediate \nnodes). In particular, we perform de\u00adcomposition in two steps. In the .rst step, we generalize the entire \nproof without any decomposition, which allows us to identify the nodes that are part of the generalized \noriginal or .nal terms. We call such nodes required, and equalities between them represent decomposition \npoints. In the second step, we perform generaliza\u00adtion again, but this time, if we reach an equality \nbetween two re\u00adquired nodes we take that equality as an assumption for the current generalization, and \nstart another generalization beginning with that equality. In the example of Figure 4, we would .nd one \nsuch equality edge, namely edge bdecomposition algorithm .. As a result, our would perform two generalizations. \nThe .rst one starts at the con\u00adclusion a. is ., going backwards from there,but stops when edge breached \n(i.e. edge b . is treated as an assumption). This would pro\u00adduce a branch-lifting optimization. Separately, \nour decomposition algorithm would perform a generalization starting with b . as the conclusion, which \nwould essentially produce the LIVSR optimiza\u00adtion.  3. Formalization Having seen an overview of how \nour approach works, we now give a formal description of our framework for generalizing proofs using category \ntheory. The generality of our framework not only gives us .exibility in applying our algorithm to the \nsetting of compiler optimizations by allowing us to choose the domain of axioms and proofs, but it also \nmakes our framework applicable to settings beyond compilers optimizations. After a quick overview of \ncategory theory (Section 3.1), we show how axioms (Section 3.2) and inference (Section 3.3) can be encoded \nin category theory.We then de.ne what a generalization is (Section 3.4), and .nally show how to construct \nthe most general one (Section 3.5). 3.1 Overview of category theory A category is a collection of objects \nand morphisms from one object to another. For example, the objects of the commonly used Set category \nare sets, and its morphisms are functions between sets. Not all categories use functions for morphisms, \nand the concepts we present here apply to categories in general, not only to those where morphisms are \nfunctions. Nonetheless, thinking of the case where morphisms are functionsisa goodwayofgaining intuition. \nGiven two objects A and B in a category, the notation f : A . B indicates that f is a morphism from A \nto B. This same information is displayed graphically as follows: f . . . . . . . . . . . . . A ... B \nIn addition to de.ning the collection of objects and morphisms, a category must also de.ne how morphisms \ncompose. In particular, for every f : A . B and g : B . C the category must de.ne a morphism f ;g : A \n. C that represents the composition of f and g . The composition f ;g is also denoted g .f . Morphism \ncomposition in the Set category is simply function composition. Morphism composition must be associative. \nAlso, each object A of a category must have an identity morphism id A : A . A such that id A is an identity \nfor composition (that is to say:(id A;f )= (f ;id A)= f , for anymorphism f ). Information about objects \nand morphisms in category theory is often displayed graphically in the form of commuting diagrams. Consider \nfor example the following diagram: f . . . . . . . . . . . . . A ... B .. .. .. .. .. .. .. .. .. .. \n.. .. .. .. .. .. .. .. g ..... ..... .. .. .. ... ... h .. .. .. .. .. .. .. ... ... .. .. .. .. .. \n.. .. .. .. . . . . . . . . . . . . . . . . . . . . C i ......... D By itself, this diagram simply \nstates the existence of four objects and the appropriate morphisms between them. However, if we say that \nthe above diagram commutes then it also means that f ;h = g ;i . In other words, the two paths from A \nto D are equivalent. The above diagram is known as a commuting square. In general, a diagram commutes \nif all paths between any two objects in the diagram are equivalent. Commuting diagrams are a useful visual \ntool in category theory, and in our exposition all diagrams we show commute. Although there are many \nkinds of categories, we will be focus\u00ading on structured sets. In such categories, objects are sets with \nsome additional structure and the morphisms are structure-preserving functions. The Set category mentioned \npreviously is the simplest example of such a category, since there is no structure imposed on the sets. \nA more structured example is the Rel category of bi\u00adnary relations. An object in this category is a binary \nrelation (rep\u00adresented, say, as a set of pairs), and a morphism is a relation\u00adpreserving function. In \nparticular, the morphism f : R1 . R2 is a function from the domain of R1 to the domain of R2 satisfying: \n.x, y . xR1 y =. f(x) R2 f(y). Informally, there are also cat\u00adegories of expressions, even recursive \nexpressions, and the mor\u00adphisms are substitutions of variables. As shown in more detail in Section 4, \nin the setting of compiler optimizations, we will use a category in which objects are E-PEGs and morphisms \nare substitu\u00adtions.  3.2 Encoding axioms in category theory Manyaxioms canbeexpressed categoricallyas \nmorphisms[1].For example, transitivity(.x, y, z. xRy .yRz . xRz)can be expressed as the following morphism \nin the Rel category:  xy trans .. . . . . . (1) where trans is the function (x .. x,y .. y, z .. z) \n(we display a relation graphically as a listing of pairs the left object above is the relation {(x, \ny),(y,z)}). In this case, the axiom is identity\u00adcarried , meaning the underlying function (namely trans \n) is the identity function,but that need not be the case in general.  Now consider an object A in the \nRel category.We will see how ing square could acually contain more entries, say(a,a), and the to state \nthat this object (relation) is transitive. In particular, we say diagram would still commute. To address \nthis issue, we use the that A satis.es trans if for every morphism f : {(x,y),(y,z)}. A, concept of pushouts \nfrom category theory. ' there exists a morphism f : {(x,y), (y, z), (x,z)}. A such that the Definition \n1 (Pushout). A commuting square [A, B, C, D] is said following diagram commutes: to bea pushout square \nif for any object E that makes [A, B, C,E] xy a commuting square, there exists a unique morphism from \nD to E trans ... . . . . . . . . . . . . yz . such that the following diagram commutes: . . . . . . \n. . . . . . . . . . . . . . . .  ... ...........xz f . . . . . . . .. . .. . .. . .. . . .. . .. .. \n. .. .. ....... (2) .. f ...... ............ ........ . . . . . . . . . . . . . .. . .. ... \n. .... . . ... . .. . .. ...... . .. ...........f ' AB . . . . . . . .. . . .. .. . .. . . .. .. .. \n.. .... ........ . . .. ... ... ... . .. . .. . .. . .. . .. . .. . . .. . .. . .. g ..... ..... ...... \n.. .. .. .. . .. . . . . . . . . . . .. To see how this de.nition of AA satisfying trans implies that \nA ............ . .. . . .... i.... h........... .. .. . . .... ........................ .. . . . .C \n.. D ...... . . . .. . . .. . . is a transitive relation, consider a morphism f from {(x, y), (y,z)}to \n........................... ...... .... ........... . .. . .. .. ... .... ... ... . .. .. . .. ... \n . .. . ... .. . . .. . .. . . . . .. . .. .. . .. . .. .. . .  A. This morphism is a function that \nselects three elements a,b, c in ........ ..................... ... . .. .. ... ...... . .. the domain \nof A such that aAb and bAc. Since trans is the identity E function, a morphism f ' will exist if and \nonly if aAc also holds. Furthermore, given A, B, C, f and g in the diagram above, the Since this has \nto hold for any f (i.e. any three elements a, b,c in pushout operation constructs the appropriate D, \ni and h that makes the domain of A with aAb and bAc), A will satisfy trans precisely [A,B,C, D] a pushout \nsquare. When the morphisms are obvious when the relation de.ned by A is transitive. from context, we \nomit them from the list of arguments to the pushout Similarly, our E-PEG axioms can be encoded as identity-carried \noperation, and in such cases we use the notation B +A C for the morphisms which simply add an equality. \nThe axiom x * 0 = 0 is result D of the above pushout operation. encoded as the identity-carried morphism \nfrom the E-PEG x * y, Pushouts in general are useful for imposing additional structure. with y equivalent \nto 0, to the E-PEG x * y, with y equivalent to 0 Intuitively, when constructing pushouts, A represents \nglue thatand x * yequivalent to 0. Thus, an E-PEG satis.es this axiom if for will tie together B and \nC: f says where to apply the glue in B;every x * y node where y is equivalent to 0, the x * y node is \nalso g says where to apply the glue in C. The pushout produces D byequivalent to 0. More details on our \nE-PEG category can be found gluing B and C together where indicated by f and g .For example,in Section \n4. in a category of expressions, pushouts can be used to accomplish 3.3 Encoding inference in category \ntheory uni.cation: if A is the expression consisting of a single variable x, and f and g map x to the \nroot of expressions B and C respectively, Inference is the process of taking some already known informa\u00adthen \nthe pushout D is the uni.cation of B and C. If the expressionstion and applying axioms to learn additional \ninformation. In the cannot be uni.ed, then no pushout exists. E-PEG setting, inference consists of applying \naxioms to learn Going back to our example, to encode the application of theequality edges. To start with \na simpler example, consider the re\u00adtransitivity axiom, we require that the commuting square in dia\u00adlation \n{(a, b),(b,c), (c, d)}, and suppose we want to apply transi\u00adgram (4) be a pushout square. The pushout \nsquare property appliedtivity to(a, b) and(b,c) to learn(a, c). Applying transitivity .rst to diagram \n(4) ensures that, for any relation E such that aEc, thereinvolves selecting the elements on which we \nwant to apply the will be a morphism from the bottom right object in the diagramaxiom. This can be modeled \nas a morphism from {(x, y),(y,z)} to (call it D)to E, meaning that E contains as much or more informa\u00ad{(a, \nb),(b, c), (c,d)}, speci.cally(x .. a,y .. b,z .. c). This pro\u00adtion than D, which in turn means that \nD encodes the least relation duces the following diagram:  that includes(a, c). This is exactly the \nresult we want from applying xy transitivity on our example. trans ... . . . . . . . . . . . . yz . \n Furthermore, we can obtain the bottom right coner of dia\u00ad xz gram (4) by taking the pushout of diagram \n(3). Thus, inference . . . . . . . . . . . . . .x .. a, ..... . . . .. is the process of repeatedly \nidentifying points where axioms can . . . . . . . . . . . . . . y .. b, ...... (3) . . ... apply and \npushing out to add the learned information. . This pro\u00ad . . . . . . . . . . .. . .. ... z .. c ....... \n. ...  . .. .... duces a sequence of pushout squares whose bottom edges all chain  ab  together. For \nexample, in the diagram below, app1 states where to bc apply axiom1 in E0, and the pushout E0 +A1 C1 \nproduces the result cd E1;in the second step,app2 states where to apply axiom2 in E1, and the pushout \nE1 +A2 C2 produces E2; this process can continue toAdding(a,c)completes the diagram into a commuting \nsquare: produce an entire sequence Ei, where each Ei encodes more infor\u00ad xy mation than the previous \none. trans .. . . . . . . . . . . . . . yz . axiom1 axiom2 .. .. .. .. . .. . .. .. . .. . . . .. .. \n. .. . . .  .. xz A1 .....C1 A2 .....C2 . . . . . . . . . . . . . . . . . .. . . .x .. a, ...... ..... \nx .. a, . .... . . ... .. .. . .. . .. . .. . .. .. . . .. . .. .. . . .. .. . .. . .. . .. . .. \n. . . ... . . ... . . .... . .. . ... .... (5) . .... . .. ..... ... . .. .. app1 .. .. app2 ... . \n.... . .. .. . .. . .. .. . .. y .. b, ..... .... y .. b, (4) .................... ..... .... .................... \n...... ... .... . .. .. . . . . . . . .  . . . . . . . . .  . . . . . . . . . . . . . . \n.. . . . . .. . . . . .. . . .. . . .. ... . .. . . .. . . .. . .. . . .z .. c ..... .... z .. c . .. \n . .. .. . .. .. .. . .. .. .. . .. .. ..ab .. .. . . . . . .. .. . .. .. . E0 ... E1 ... E2. . \n  In the E-PEG setting, each Ei will be an E-PEG, and each axiom ab bc . . . . . . . . . . . . . . \n. bc application will add an equality edge. The entire sequence above . cd cd constitutes a proof in \nour formalism: it encodes both the axioms ac being applied (axiom 1, axiom 2, etc.), how they are applied \n(app1, The above commuting diagram therefore encodes that transivity app2, etc.), and the sequence of \nconclusions that are made(E0, E1, was usedto learn information,in particular(a,c),but unfortunately, \nE2, etc.). Traditional tree-style proofs (such as derivations) can be it does not state that nothing \nmore than transivitywas learned.For linearized into our categorical encodingof proofs (see Section6for \nexample, the bottom-right object (relation) in the above commut-more details on how this can be done). \n  3.4 De.ning generalization in category theory O now identi.es where the resultof the application and \nthe property overlap. Proof generalization involves identifying a property of the result Ageneralization \nofE is an object G with a morphism gen : G .of an inference process and determining the minimal information \nE (see diagram (6) below). A generalization of app is a morphismnecessary for that proof to still infer \nthat property. We represent a app: A . G with app;gen = app. We apply axiom to theproperty as a morphism \nto the .nal result of the inference process. GGgeneralized application appby taking the pushout to produce \nG ' . For example, in the Rel category, a morphism from {(x,y)} to the G Lastly, we want our property \nto hold in G ' for the same reason.nal result of inference would identify a related a and b whose that \nit holds in E ' ; that is, any information added by axiom toinferred relationship we are interested in \ngeneralizing.For E-PEGs, make the property prop hold in E ' should also make the propertya morphism from \na \u00df to an E-PEG E identi.es two equivalent hold in G ' . We enforce this by requiring an additional \nmorphismnodes in E, phrasing the property these two nodes are equivalent . prop: P . G ' . To summarize, \nthen, a generalization of applyingGeneralization applied to this property will produce a generalized \nG E-PEG for which the proof will make those two nodes equivalent. axiom via app to produce prop is an \nobject G with morphisms gen , We start by looking at thelast axiom application in the inference GG app, \nand propmaking the following diagram commute: process, the one that produces the .nal result. In this \ncase we have: .. O . . . . . ... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. \n. . . . . . .. . .. axiom ......................... .. .. .. .. . .. . . ............ axiom ... .. \n. ..... ..... .. .. . . . AC ....... ..... .. . .. . . .. . .. .. A .. C ..... . . . . . ... . .. \n. .. ... . .. ... .. .. ... .. . .. .. . .. .. . .. .. .... . .. .. . .. .. .. .... . . ... .. .. \n...... ...... ' ...... ....... app...... ........ .... . ..... . ... . . .. . ..... G ..... . app \n...... ...... app .... .......... ..... ......... (6) ... ... P ... ........ . ... . ....... . .. ... \n... .. .... . ... ....... . prop .. .. . . .. .. ............... ............... ......... ..... \n..... G .. ... . .. .. . . . . .. .... . . . .. ... . . . .. ... . . . .. ... . . . .. .. . . ... \n. . . .. .. .. ........ .................app ........... G . .......... .......... G ' . ........ P \n . . prop ....... ...... ...... .... ........... .. . .. . ... .. . ... .. ... . ... . .. .. .. \n. .. .. . .. . . .. .......... E ' ........ ......... ........ ..... ................ . E ....... \n........ . .. . ...... ... ........... ...... .... . gen ............... . .. . . ...... . . . ..... \n... ....... .... . .......................... .. . . . . . . . .. axiom app .. ... . . . . . . . . \n A - -. C is the (last) axiom being applied. A - . E is where the E .......E ' .. ....... ................ \nprop axiom is being applied. E ' is the result of pushing out axiom and app. G ' Recall that in the \nabove diagram is the pushout of axiom and prop P - -. E ' is the property of E ' for which we want a \ngeneralized appG. The dashed line from G ' to E ' is the unique morphism induced proof. by that pushout \n(note that there is a morphism from G to E ' passing Next we need to identify which parts of P the last \naxiom ap-through E). plication concludes. This step is necessary because, in general, P The above diagram \nde.nes a generalization for the last step of may only be partially established by the last step of inference. \nFor the inference process. A generalization for an entire sequence of example, in the Rel category, we \nmay be interested in generalizing steps such as diagram (5) is an initial G0 and a morphism gen a proof \nwhose conclusion is that the .nal relation includes (a,b) from G0 to E0 with a sequence of generalized \naxiom applications and(b, c). In this case, it is entirely possible that the last step of such that the \nproperty holds in the .nal Gn. inference produced(a, b)whereas an earlier step produced(b,c). 3.5 Constructing \ngeneralizations using category theory To identify which parts of P the last axiom application con\u00adcludes, \nwe use the concept of pullbacks from category theory. Pull-Above we have de.ned what a generalization \nis, but not how to backs are the dual concept to pushouts. construct one. Furthermore, our goal is not \njust to construct some generalization; after all E is a trivial generalization of itself. We Definition \n2 (Pullback). A commuting square [A,B,C,D]is said would like to construct the most general generalization, \nmeaning to bea pullback square if for any object E that makes [E,B,C, D] that not only does it generalize \nE, but it also generalizes any other a commuting square, there exists a unique morphism from E to A generalization \nof E. such that the following diagram commutes: In order to express our generalization algorithm, we \nintroduce a E ..............new category-theoretic operation called a pushout completion. . . . . . . \n.. .. . .. . .. . . . . . . . .. . .. . .. .. .. . .. . . .. .. .. .. .. .. . ... . .. .. . .. . .. . \n. .. . . . . . . . . . .. . . .. . . . . .. . .... . ... . .. .. .. .. . .. . . .. .. . .. .. .. \n ......... .... ............ Definition 3 (Pushout completion). Given a diagram .. .. . .. . .. . . \n. .. .. . . . . ...... A . B . . . . . . . . . . ..... f ...... .... .... f .. . .. . .. . .. . .. \n. .. . . .. .. .. . . . . .. . . ... . . ... . . .  ....... ...... g ...... A ......B .. .. . .. \n.......... ....... ....... h . .. . . .. .. .. .. . .. .. .. .... ... .... .. .. . . . .. .. . .. \n.. .. . . . . . . . . . .. . . . . . . . . . . . . . . . ........... ......g . . . . . . . \n . . . . .C ... D i .......  D Furthermore, given B, C, D, i and h in the diagram above, the the pushout \ncompletion of [A, B, D,f ,g ] is a pushout square pullback operation constructs the appropriate A, f \nand g that [A,B,C, D] with the property that for any other pushout square makes [A,B,C,D] a pullback \nsquare. When the morphisms are [A,B,E,F] in which the morphism from B to F passes through obvious from \ncontext, we omit them from the list of arguments to the D, there is a unique morphism from C to E (shown \nbelow with a pullback operation, and in such cases we use the notation B \u00d7D C dashed arrow) such that \nthe following diagram commutes: for the result A of the above pullback operation. f . Whereas pushouts \nare good for imposing additional structure, ....... . . . . .A ... B . . . . . .. . .. . . .. . .. . \n.. . .. . . .. . .. . pullbacks are good for identifying common structure.Forexample, ......... ...... \n............ .. ............... ......g .. . .. . . . . . . . . . . . . . in the Set category with \ninjective functions, B \u00d7D C would intu-............... .. . .... ... .. ... . ... . . . .. .. . .. . \n. ... C .. D . . . . . . . itively be the intersection of the images of B and C in D. ........... .... \n...... . .. . .. . .. . .. .. .. . .. . . .. . .. .. .. .. .. ... ... ... ... . .. .. Returning to \nour diagram, we take the pullback C \u00d7E ' P: .... .. ....... . . ............... ... ... .... ... .. ....... \n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . ... .. .. .. .. .. .. .. .. . . .. . \n. . . . . . . .. .. . ..  axiom . ...............O ......... When the morphisms are obvious from context, \nwe omit them from E ... F . . . . .. .. .. . ..A .. C ..... . . ..  ....... ........... ........ . \n...... the list of arguments to the pushout completion, and in such cases . .. .. .. .. .. .. .. .. \n.. .. .. .. .. .. ... .... .. we use the notation D -A B for the result C of the above pushout .. .. \n' . app ........ ........ app P .. .. .. .. . .. .. ... .  .......... ... .... ..... ........ . ........ \n..... .................... completion (the minus notation is used because in the above dia\u00ad . . . . . \n. . ........ ... .. ......... .......... prop gram we have D = B +A C). . .E ...... E '  The intuition \nis that C captures the structure of D minus the structure of B (re.ected into D through g ) while keeping \nthe structure of A (re.ected into D through f ;g ). For example, in the Rel category, intuitively we \nwould have: C = (D \\ B). A (where A, B, C and D are sets of tuples that represent relations). Our requirement \nfor constructing generalizations is that, for ev\u00ad axiom ery axiom A - -. C, there is a pushout completion \nfor any mor\u00adphism f from C to any object. There is encouraging evidence that axioms with pushout completions \nare quite common. In particular, all of our PEG axioms satisfy this condition. More generally, all identity-carried \nmorphisms in Rel or the category of expressions satisfy this condition. Furthermore, an accompanying \ntechnical re\u00adport [21] shows how to loosen this condition in a way that allows all morphisms in Set and \nRel to qualify as generalizable axioms. Now that we have all the necessary concepts, the diagram below \nand the subsequent description explain the steps that our algorithm takes to construct the best generalization: \n..O . . . . . ... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . .. . \n.. . . . .. . .. . ... . .. .. . .. .. .. .. ... .. .. . .. . . . . . . .. . axiom .. . ... ...... \n. .. .. .. . .. .. . . . . .. . .. .. . .. .. AC ..... . . . . . . . . . ... .. ... ... . .. .. ... .... \n. .. .. .... ........ . ..... ....... . ......... .... (7) .. .. .. . .. .. .. .... . .. .. .... . \n .. .... . .. ... . .. .... ... ... . ... ... ... . .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. \n.. .. .. .. .. . ... .. .. . .. app ....... P ' . ...... .......... \u00af. ........... . .. ... ... . P \n. P .. .. .. .. . ... . . . .. . . .. . . . .. . . . .. . . .. . . . .. . ... .. . . .. . .. . .. . .. \n... . . .. . ... . . . .. . .. .. .. . .. ... .. ... .. ... ... . . . .. ... ... . .. ... . . .. .. ... \n.. ... . . .. . .. .. . .. ... ................. prop . .. .. .. . . . .. . . . .. . .. . . .. . . . \n.. . . . . .. . . .. . . . . . . . . .. .. . .. . .. . . . . . . . . . . . . . . . . . . . . . ...... \nE ' E .. 1. O is constructed by taking the pullback C \u00d7E ' P. \u00af  2. P is constructed by taking the pushout \nC +O P. The pushout \u00af  P intuitively represents the uni.cation of property P with the assumptions and \nconclusions of axiom (which are represented by C). The dashed morphism from P\u00afto E ' is induced by the \n\u00af pushout property of P; it identi.es how this uni.ed structure .ts in E ' . 3. P ' is constructed by \ntaking the pushout completion P\u00af-A C. The pushout completion P ' intuitively represents the informa\u00adtion \nin P\u00afbut with the inferred conclusion of axiom removed. The dashed morphism from P ' to E is induced \nby the pushout \u00af property of P; it identi.es the minimal information necessary in E so that applying \naxiom produces property P. Let us return to the larger context of a chain of axioms rather than applying \njust one axiom. In diagram (7) above, E would be the result of an earlier axiom application. P ' then \nidenti.es the prop\u00aderty of E that needs to be generalized in that axiom application. This process of \ngeneralization can be repeated backwards through the chain of axioms until we arrive at the original \nE0 that the in\u00adference process started with. The generalized property of E0 at that point is then the \nbest generalization of E0 so that the proof infers the property P we started with in diagram (7). The \nfact that this solution is the most general falls immediately from the pushout and pushout-completion \nproperties of the construction. In partic\u00adular, suppose that in diagram (7) there is another generalization \nG, which essentially means that we merge diagrams (6) and (7) to\u00adgether.We need to show that thereexistsa \nmorphism from P ' to G. First, the pushout property on P induces a morphism from P to G ' . \u00af\u00afSecond, \nthe pushout-completion property on P ' induces the desired morphism from P ' to G. The above process \nprovides a parameterized pseudo-algorithm for generalizing proofs. The algorithm is parameterized by \nthe choice of category used to represent the inference process, along with the details of implementing \npushouts, pullbacks, and pushout completions on this category. 4. E-PEG instantiation We now show how \nto instantiate the parameterized algorithm from Section3with E-PEGs. The category of E-PEGs can be formalized \nin a straghtforward way using well established categories such as partial algebras PAlg and relations \nRel [1]. The full formal description, however, is lengthy to expose, so we provide here a semi-formal \ndescription. An object in the E-PEG category is simply an E-PEG, where an E-PEG is a set of possibly \nrecursive expressions (think recursive abstract syntax trees), with equalities between some of the nodes \nin these expressions. These E-PEG expressions can have free vari\u00adables, and a morphism f from one E-PEG \nA to another E-PEG B is a map from the free variables of A to nodes of B such that, when the substitution \nf is applied to A, the resulting E-PEG is a sub\u00adgraph of B. The substitution is also required to map \nexpressions that are known to be equal in A to expressions that are equal in B. The three operations \nthat need to be de.ned on the E-PEG category intuitively work as follows: The pullback A \u00d7C B treats \nA and B as sub-E-PEGs of C and takes their intersection.  The pushout A +C B treats C as a sub-E-PEG \nof both A and B and uni.es A and B along the common substructure C.  The pushout completion C -A B removes \nfrom C the equalities in B that are not present in A.  We now revisit the example from Figure 3, and \nthis time ex\u00adplain it using our category theoretic algorithm. Figure 5 shows the generalization process \nfor this example using E-PEGs. The objects (boxes) in this .gure are E-PEGs, and the thin arrows between \nthem are morphisms. The example has two axiom applications, and so Figure 5 consists essentially of two \nside-by-side instantiations of diagram (7). The thick arrows identify the steps taken by inference and \ngeneralization. The equality edges in each E-PEG are labeled with either a circle or a triangle to show \nhow these equality edges map from one E-PEG to another through the morphisms. In this example the inference \nprocess uses two axioms to infer that5+ (7 -7) is equal to 5. First, it applies the axiom x - x = 0to \nlearn that7-7 = 0, and then x+0 = x to learn that5+(7-7) = 5. We use the Copy arrows just for layout \nreasons these copy operations are not actually performed by our algorithm. Once the inference process \nis complete, we identify the equality we are interested in generalizing by creating an E-PEG containing \nthe equality a \u00df (with a and \u00df fresh) and a morphism from this E-PEG to the .nal result of inference \nwhich maps a to5 and \u00df to the + node. Thus we are singling out the triangle-labeled equality in the .nal \nresult of inference to generalize. Having singled out which equality we want to focus on, we gen\u00aderalize \nthe second axiom application using our three step approach from Section 3: a pullback, a pushout, and \nthen a pushout comple\u00adtion. The pullback identi.es how the axiom is contributing to the equalities we \nare interested in in this case it contributes through the triangle-labeled equality. The pushout then \nuni.es the equality we are interested in generalizing with a freshly instantiated version of the axiom \ns conclusion (with a and b being fresh). Finally, the pushout completion essentially runs the axiom in \nreverse, removing the axiom s conclusion. In particular, it takes the substitution from the uni.cation \nand applies it to the premise of the axiom to produce the E-PEG[a + b\u00b7\u00b7\u00b7 0]. This E-PEG, which is the \nresult of generalizing the second ax\u00adiom application, is then used as a starting point for generalizing \nthe .rst axiom application, again using our three steps. The pullback identi.es that the .rst axiom establishes \nthe circle-labeled equality edge. The pushout uni.es[a + b\u00b7\u00b7\u00b7 0] with a freshly instantiated version \nof the axiom s conclusion (with c being fresh). Note that  Figure 5. Example of generalization using \nE-PEGs the circle-labeled equality edge in[a + b\u00b7\u00b7\u00b7 0] must unify with the corresponding equality edge \nin the axiom s conclusion, and so b gets uni.ed with the minus node. Finally, the pushout completion \nruns the .rst axiom in reverse, essentially removing the axiom s conclusion. The result is our generalized \nstarting E-PEG for that proof. We then generate a rule stating that whenever this starting E-PEG is found, \nthe .nal conclusion of the proof is added, in this case the triangle-labeled equality. The details of \nhow our E-PEG category is designed a.ects the optimizations that our approach can learn. For example, \nthe cate\u00adgory described above has free variables, but they only range over E-PEG nodes. For additional \n.exiblity, we can also introduce free variables that range over node operators, such as variables OP1 \nand OP2 in Figure 1. This would allow us to generate optimizations that are valid for anyoperator, for \nexample pulling an operation out of a loop if its arguments are invariant in the loop. For even more \n.ex\u00adibility, we can augment our E-PEG catgory with domain-speci.c relationships on operator variables, \nwhich could be used to indi\u00adcate that one operator distributesover another.With this additional .exiblity, \nwe can learn the more general version of LIVSR show in Figure 1. In all these cases, to learn the more \ngeneral optimizations, one has to not only add .exiblity to the category,but also re-express the axioms \nso that they take advantage of the more general cate\u00adgory (as was shown in Section 2.1). The E-PEG category \ncan also be augmented with new structure in order to accommodate anal\u00adyses not based on equalities. For \nexample, an alias analysis could add a distinctness relation to identify when two references point to \ndi.erent locations. This would allow our generalization technique to apply beyond the kinds of equality-based \noptimizations that our Peggy compiler currently performs [22]. 5. Other applications of generalization \nThe main advantage of having an abstract framework for proof gen\u00aderalization is that it separates the \ndomain-independent components of proof generalization how to combine pullbacks, pushouts, and pushout \ncompletions from the domain-speci.c components of the algorithm how to compute pullbacks, pushouts, \nand pushout completions. As a result, not only does this abstraction provides us with a signi.cant degree \nof .exibility within our own domain of E-PEGs, as described in Section 4,but it also enables applications \nof proof generalization to problems unrelated to E-PEGs.We illus\u00adtrate this point by showing how our \ngeneralization framework from Section 3 can be used to learn e.cient query optimizations in re\u00adlational \ndatabases (Section 5.1) and also assist programmers with debugging static type errors (Section 5.2). \nAdditional applications of our proof generalization framework, such as type generalization and contract \ndebugging, can be found in the technical report [21]. 5.1 Database query optimization In relational \ndatabases, a small optimization in a query can produce massive savings. However, these optimizations \nbecome more ex\u00adpensive to .nd as the query size grows and as the database schema grows. We focus here \non the setting of conjunctive queries, which are existentially quanti.ed conjunctions of the predicates \nde.ned in the database schema.Forexample, the query .y. R(x, y).R(y,z) returns all elements x and z for \nwhich there exists a y such that (x, y)and(y,z)are in the R table (relation).For sake of brevity, we \ndiscuss only conjunctive queries without existential quanti.cation. Aconjuctive query can itself be represented \nas a small database. For example, the query q := R(x,y, z, 1) . R(x ' , y,0, 1) can be represented by \nthe following database (our notation assumes there is one table in the database called R and just lists \nthe tuples in R): xy z 1 Q:= x ' y 01 Anyresult produced by qon a database instance I corresponds with \na relation-preserving and constant-preserving function from Qto I. One nice property of this representation \nis that the number of joins required to execute a query is exactly one less than the number of rows in \nthe small database representing the query. Thus, reducing the number of rows means reducing the number \nof joins. Most databases have some additional structure known by the designer. One such structure could \nbe that the .rst column of R determines the third column (we will use A, B, C, and D to refer to the \ncolumns of R). This is known as a functional dependency, noted by A . C. Functional dependencies .t into \nthe broader class of equality-generating dependencies since they can be used to in\u00adfer equalities. A \nquery optimizer can exploit this information to reduce the number of variables in a query, identify better \nopportu\u00adnities for joins, or even identify redundant joins. Unfortunately, the functional dependency \nA . C provides no additional information for our example query, at least not yet. Another form of dependencies \nis known as tuple-generating dependencies. These dependencies take the form if these tuples are present, \nthen so are these . One common example is known as multi-valued dependencies. Suppose in our example \ndatabase, the designer knows that, for a .xed element in B, column A is completely independent of C and \nD. In other words, R(a,b,c, d).  '' '' R(a ,b,c , d ' )impliesR(a,b, c ,d ' ), as well as R(a ,b,c,d). \nThis is denoted as B : A or equivalently as B : CD. Adding tuples to a query in general is harmful because \neach added tuple represents an additional join. However, combined with equality-generating dependencies, \nthese additional tuples can be used to infer useful equalities, which can then simplify the query. Let \nus apply an algorithm known as the chase [6] to optimize our example query using A . C and B : A: xy \nz 1 B:A A.C xy z 1 xy 01 |= =. |= =. x ' y 01 x ' y 01 x ' y 01 xy 01 The added tuple was used to infer \nthat z must equal 0, which then simpli.es the rightmost database above into two tuples. The optimizer \ncan use this to select only tuples with C equal to0before joining, a potentially huge savings. Although \nthis example was bene.cial, many times adding tuples is harmful because it adds additional joins which \ncan be ine.cient. Thus, a query optimizer prefers to infer equalities without introducing unnecessary \ntuples. Our framework from Section 3, instantiated to the database setting, can use instances of optimized \nqueries to identify general rules for when adding tuples to a query is helpful. In particular, in the \nabove example, it could identify exactly what properties of the original query led to the inferred equality. \nThe category we will use in this example is like Rel but with quaternary relations. The axiom A . C can \nbe expressed categorically by the morphism c, c '.. c\u00af ab cd ab c\u00afd - ----. b '' d ' b ' d ' ac ac\u00af The \naxiom B : A can be expressed using the morphism ab cd ab cd d ' a ' bc ' . a ' bc ' d ' ' d ' ab c Applying \nour framework to our sample query optimization se\u00adquence will produce the theorem c, c '.. c\u00af ab cd ab \nc\u00afd - ----. '' d ' ' d ' ab c ab c\u00af or simply B . C. Thus, our framework can be used to learn equality-generating \ndependencies, removing the need for the in\u00adtermediate generated tuples. This was possible because the \nde\u00adpendencies involved, namely A . C and B : A, could be ex\u00adpressed categorically as morphisms.We have \nproven that our learn\u00ading technique can be used so long as all the dependencies can be expressed in this \nmanner. Although the primary purpose of apply\u00ading our framework to database optimizations was to demonstrate \nthe .exibility of our framework, discussions with an expert in the database community [5] have revealed \nthat our technique is infact a promising approach that would merit further investigation.  5.2 Type \ndebugging As type systems grow more complex, it also becomes more di.cult to understandwhya program does \nnot type check.Type systems re\u00adlying on Hindly-Milner type inference [18] are well known for pro\u00adducing \nobscure error messages since a type error can be caused by anexpressionfar removed from where the errorwas \n.nally noticed by the compiler. Below we show how to apply our framework as a type-debugging assistant \nthat is similar to [12],but is also easily adaptable to additional language features such as type classes \n[21]. In Haskell, heap state is an explicit component of a type. For example, readSTRef is the function \nused to read references. This is a stateful operation, so it has type .sa. STRef sa . ST sa. STRef sa \nis the type for a reference to a in heap s. ST sa stands for a stateful computation using heap s to produce \na value of type a. In order to use this stateful value, Haskell uses the type class Monad to represent \nsequential operations such as stateful operations. Thus ST s is an instance of Monad for anyheap s.Aproblem \nthat quickly arises is that operations such as + take two Ints, not two ST s Ints. Thus, + has to be \nlifted to handle e.ects. To do this, there is a function liftM2 which lifts binary functions to handle \ne.ects encoded using anyMonad. Likewise, liftM lifts unary functions. Now consider the task of computing \nthe maximum value from a list of references to integers. If the list is empty, the returned value should \nbe -8. In Haskell, integers with -8 are encoded using the Maybe Int type: the Nothing case represents \n-8 and the Just n case represents the integer n. Conveniently, max de.ned on Int automatically extends \nto Maybe Int. The following program would seem to accomplish our goal: maxInRefList refs = case refs \nof [] -> Nothing ref : tail -> liftM2 max (liftM Just (readSTRef ref)) (maxInRefList tail) Since readSTRef \nis a stateful operation, the lifting functions liftM2 and liftM allow max and Just to handle this state. \nUnfor\u00adtunately, this program does not type check. The Glasgow Haskell Compiler, when run on the above \nprogram using do notation for the recursive call, produces the error readSTRef ref has inferred type \nST sa but is expected to have type Maybe a . This error mes\u00adsage does not point directly to the problem, \nso the programmer has to examine the program, possibly even callers of maxInRefList, to understand whythe \ncompiler expects readSTRef ref to have a di.erent type. Within maxInRefList alone there are many possi\u00adblities, \nsuch as the lifting operations, dealing with Maybe correctly, and the recursive call. Here we can apply \nproof generalization to limit the scope of where the programmer has to search, thereby helping identify \nthe cause of the type error. Type inference can be encoded categorically using a category of typed expressions. \nAn object is a set of program expressions and a map from these program expressions to type expressions, \nalthough this map is not required to be a valid typing. Program expressions can have program variables, \nand type expressions can have typevariables.A morphism from A to B is a type-preserving substitutionof \nprogram and typevariablesin A to program and type expressions in B such that when the substitution is \napplied to A, the resulting expressions are sub-expressions of the ones in B. In this category, typing \nrules canbe encoded as morphisms.Forexample, function application can be encoded as: a .. (\u00df . .) . . \n. . . . . . . . . . . . . . . ((f : a)(x : \u00df)) : . ((f : \u00df . .)(x : \u00df)) : . This states that, for any \nprogram expressions f and x where x has type \u00df, f must have type \u00df . . for fx to have type .. Hence, \nthe type a of f is mapped to \u00df . . by the morphism. In e.ect, applying this axiom uni.es the type of \nf with \u00df . .. Rules for polymorphic values can also be encoded as mor\u00adphisms.Forexample, the rule for \nNothing can be encoded as: a .. Maybe \u00df . . . . . . . . . . . . . . . . . . . Nothing : a Nothing : \nMaybe \u00df This states that, for the value Nothing to have type a, there must exist a type \u00df such that a \nequals Maybe \u00df. As before, applying this axiom uni.es the type of Nothing with Maybe \u00df.  Putting aside \ntype classes for simplicity, the rule for liftM is: a .. ... .. . . . . . . . . . . . . . . liftM :(\u00df \n. .). M \u00df . M . This rule uses a type variable M, which is treated like other type variables except \nit maps to unary type constructors, such as Maybe or the partially applied type constructor ST s. Going \nback to the maxInRefList example, since the compiler expects readSTRef ref to have type Maybe a, the \ntype inference process could be made to produce a proof that this fact must be true for the program to \ntype check. This proof can be expressed categorically using the above encoding, which allows us to now \napply our generalization technique.We ask the question Whydoes readSTRef ref need to have type Maybe \na? categorically using a morphism from object(x : Maybe .)that mapsx to readSTRef ref and . to a. We \nthen proceed backwards through the inference process. For each step, we determine whether it contributes \nto the property; if it does, we generalize it, otherwise we skip the step entirely so as not to needlessly \nconstrain the program. The .rst useful step to generalize is the function application rule where the \nfunction is liftM Just and the argument is readSTRef ref. During inference, before applying this axiom, \nliftM Just had type Ma . M (Maybe a)for someM, a, and a;liftM Just (readSTRef ref) had type Maybe \u00df for \nsome \u00df;andreadSTRef ref still had the unconstrained type .. Applying the function ap\u00adplication rule during \ninference causes . to be uni.ed with Ma and M (Maybe a) with Maybe \u00df. In turn, this forces M to unify \nwith Maybe, contributing to the reason whyreadSTRef ref must have type Maybe a. Generalization can analyze \nthis axiom application to determine that readSTRef ref has type Maybe a because of two key properties: \n(1) liftM Just had type Ma . M d (where d generalizes Maybe a)and (2) liftM Just (readSTRef ref) had \ntype Maybe \u00df (the same as the non-generalized type). Generalizing property (1) eventually recognizes \nliftM as an important value in the program, whereas Just is not. Generalizing property (2) reaches similar \nkinds of conclusions in the rest of the program. In this manner, generalization identi.es exactly which \ncomponents of the program are causing the compiler to expect readSTRef ref to have type Maybe a. The \nresulting skeleton program is shown below, using dots for irrelevant expressions: . = case . of . -> \nNothing . -> liftM2 . (liftM . .) . The skeleton program makes it clear that only the two cases, the \nlifting operations, and the use of Nothing are causing the incor\u00adrectexpectation. Combining these threefacts, \nthe programmer can quickly realize that they forgot to lift the stateless value Nothing into the stateful \ne.ect ST s, easily .xed by passing Nothing to the return function. This mistake was hidden before because \nMaybe is coincidentally an instance of Monad, so the lifting functions were interpreted as lifting Maybe \nrather than ST s. The mistake was in a di.erent case than where the error was reported, misleading the \nprogrammer into examining the wrong part of the program. Gener\u00adalization, however, helps the programmer \npinpoint the problem by removing parts of the program that do not contribute to the error. 6. Manipulating \nproofs Givena proofof correctness, our generalization technique produces the most general optimization \nfor which the same proof applies. This still allows di.erent proofs of the same fact to produce in\u00adcomparable \ngeneralizations. However, by changing proofs intelli\u00adgently, we can ensure better generalizations. Below \nwe illustrate three classes of proof edits that we use to produce more broadly applicable optimizations: \nsequencing axiom applications, remov\u00ading irrelevant axiom applications, and decomposing proofs. 6.1 Sequencing \naxiom applications Our generalization technique requires proofs to be represented as a sequence of linear \nsteps. However, proofs are often expressed as trees, in which case one needs to linearize the tree before \nour technique is applicable. The most faithful encoding of a proof tree is to use parallel axiom applications \n(which are formalized in the technical report [21]) to directly encode the tree: each step in the linearized \nproof corresponds to the parallel application of all axioms in one layer of the proof tree. This encoding \nis the most faithful linearization of a proof tree because the tree can be reconstructed from the linearization. \nA simpler linearization is to .atten the tree so that each axiom application in the linearized proof \ncorresponds to an axiom applica\u00adtion in the proof tree. In this setting, axiom applications that are \nun\u00adordered in the tree must somehow be ordered. Unfortunately, when two axiom applications have overlapping \nconclusions, di.erent or\u00adders in the linearized proof can lead to di.erent and incomparable generalizations. \nNonetheless, we have shown that no matter what order is selected, the generalized result will be equal \nto or possibly better than the result of using the parallel encoding which keeps the tree structure intact. \nAs a result, since sequencing can only help, our implementation sequences axiom applications before general\u00adizing, \nrather than retaining the parallel encoding. 6.2 Removing irrelevant axiom applications Sometimes certain \naxiom applications infer information that is ir\u00adrelevant to the .nal property that we are interested \nin concluding. An irrelevant axiom application can overly restrict the generalized optimization by making \ncertain equalities (those required by the axiom) seem important to the optimization when theyare not. \nPrior to generalization, it is di.cult to identify which steps of the proof are relevant to the optimization. \nHowever, since generalization pro\u00adceeds backwards through the proof, each step of the algorithm can easily \nidentify when an axiom application is not contributing to the current property being generalized and \nsimply skip it. In essence, our algorithm edits the original proof on the .y, as generalization proceeds, \nto remove steps not useful for the end goal.  6.3 Decomposition As mentioned in Section 2.4, we decompose \ngenerated optimiza\u00adtions into smaller optimizations that are more broadly applicable. We can view decomposition \nas taking the original proof and cut\u00adting it up into smaller lemmas before applying generalization. In \nthe context of E-PEGs, performing decomposition requires us to determine the set of inferred equalities \nalong which we want to cut the proof (the .rst step mentioned in Section 2.4). Formally, we represent \nthe set of cut-points as an object S and a morphism sub : S . En, where En is the .nal inferred result \nof the proof. Then, in each step of generalization, we check whether the current property propm being \ngeneralized is contained within sub by deter\u00admining whether there exists a morphism from Pm to S such \nthat the following diagram commutes: Am .. . . . . . . . .. . . . . . . axiom m Cm Pm ? ... . . . . . \n. . ... . . . . . . S . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n. . . . . . . . . . . . . . . . appm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. .. . propm . . . . \n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n. sub . . . Em-1.. . . . . . . . .. .. . . . . .. . . . . . . . .. .. . . . . Em .. . . . . . . . .. \n.. . . . . . . . .. . . . . . . . .. .. . . . . En This morphism essentially describes how to contain \npropm within sub . If this is possible, we conclude propm implies propn asa generalized lemma. We then \ncontinue generalizing, but now propm will be the conclusion of the next generalized lemma.We do this \nat each point where propm can be contained within sub, thus splitting the proof into smaller lemmas each \nof which is generalized.  Optimization Description LIVSR Loop-induction variable SR Inter-loop-SR SR \nacross two loops LIVSR-bounds Optimizes loop bounds after LIVSR ILSR-bounds Optimizes loop bounds after \nInter-loop-SR Fun-speci.c-opts Function-speci.c optimizations Spec-inlining Inline only for special parameter \nvalues Partial-inlining Inline only part of the callee Tmp-obj-removal Remove temporary objects Loop-op-Factor \nFactor op out of loop Loop-op-Distr Distribute op into loop to cancel other ops Entire-loop-SR Replace \nentire loop with one op Array-copy-prop Copyprop through array elements Design-pats-opts Remove overhead \nof design patterns Figure 6. Learned optimizations (SR = Strength Reduction) for (i=0; i<h; i++) for \n(i=0; i<h*w; i+=w) .. = for (j=0; j<w; j++) for (j=i; j<i+w; j++) img[i*w+j] /= 2; img[j] /= 2; (a) Concrete \nexample for (I=E1; I<E2; I++) for (I=E1; I<E2*E3; I+=E3) for (J=0; J<E3; J++) .. = for (J=I; J<I+E3; \nJ++) E4(I*E3+J) E4(J) where E1 , E2 , E3 , and E4 are anyloop-invariant expressions (b) Generated optimization \nrule Figure 7. Generalized inter-loop strength reduction 7. Experimental evaluation We used the Peggy \ninfrastructure [22] and E-PEGs to implement our technique for generating optimizations (as was illustrated \nin Sections2and4).In this section,weexperimentally validate three hypotheses about our technique: (1) \nour technique allows a pro\u00adgrammer to easily extend the compiler by sketching what an op\u00adtimization looks \nlike with before-and-after examples (2) our tech\u00adnique can amortize the cost of expensive-to-run super-optimizers \nby generating fast-to-run optimizations and (3) our technique can even learn optimizations that are signi.cantly \npro.table on code that the compiler was not trained on. 7.1 Extending the compiler through examples \nWhen the compiler does not perform an optimization that the pro\u00adgrammer would like to see, our technique \nallows the programmer to train the compiler by providing a concrete example of what the desired optimization \ndoes. By using our implementation to learn a variety of optimizations in this way, we demonstrate experimen\u00adtally \nthat our technique enables the compiler to be extensible in an easy-to-program way, without the programmer \nhaving to learn any new language or compiler interface. The optimizations that our system learned from \nexamples are listed in Figure 6. It took on average 3.5 seconds to learn each ex\u00adample (including translation \nvalidation). The only optimizations in this list that are performed by gcc -O3 are LIVSR and Array-copy\u00adprop. \nThis demonstrates the bene.t of our system: it allows an end\u00aduser programmer to easily implement non-standard \noptimizations targeting application domains with high-performance needs, such as computer graphics, image \nprocessing, and scienti.c computing. The LIVSR optimization was already shown in Section 2. Op\u00adtimizations \nLIVSR-bounds through Loop-op-Factor will be cov\u00adered throughout the remainder of Section 7. We start \nwith Inter\u00adloop-SR and ILSR-bounds. These optimizations apply to a com\u00admon programming idiom in image \nprocessing, which is shown in len = array.length; sum = 0; for (i=0; i<len; i++) sum += array[i] * 7; \n.. = len = array.length; sum = 0; for (i=0; i<len; i++) sum += array[i]; sum *= 7; (a) Concrete example \nX=0 X=0 while (E1) .. = while (E1) X += E2X+=E2 *E3 X *= E3 where E3 is a loop-invariant expression (b) \nGenerated optimization rule Figure 8. Loop-operationfactoring the left part of Figure 7(a). The img variable \nis a two-dimensional image represented as a one-dimensional array in row-major form. Programmers commonly \nuse this kind of representation to e.\u00adciently store dynamically-sized two-dimensional images. The orig\u00adinal \ncode in Figure 7(a) uses a convenient way of iterating over such arrays, whereas the transformed code \nuses the more e.cient, yet harder to program, formulation that programmers typically use (it removes \nthe multiplication and addition from the inner loop). From the concrete instance, our generalizer determines \nthat the img array is actually insigni.cant (the only part that matters is the i*w +j computation); it \ndetermines that the starting point of the outer loop is insigni.cant; and that the bounds on both loops \ncan be gen\u00aderalized into loop invariant expressions. Furthermore, although we show the learned optimization \nas one rule, our decomposition algo\u00adrithm would split this into two optimizations: one which optimizes \nthe body of the loop(Inter-loop-SR), and one which optimizes the bounds of the loop(ILSR-bounds).Asimilar \ndecomposition when learning LIVSR would also produce LIVSR-bounds. Also, all our generated optimization \nrules including the one in Figure 7(b) can apply to programs containing other statements in the loops \nthat do nota.ect the signi.cant program fragments being optimized. When traditional compilers like gcc \n-O3 do not perform the optimization described above, an image-processing programmer would be forced to \nuse the more e.cientbut error-proneversionof the code.With our system, the programmer can use the simplerver\u00adsion \nand rely on the compiler to optimize it into the more e.cient one. Furthermore, if the programmer encounters \na new instance of the programming pattern that the generated rule does not cover, the programmer can \ntrain the compiler with another example. This sce\u00adnario emphasizes how easy it is for non-compiler-experts \nto bene.t from our system. Extending the compiler is as simple as provid\u00ading a single concrete example, \nwithout having to worry about the side conditions required for correctness or having to learn a new language \n like the language in Figure 7(b), including expression variables like E1 and side conditions like E1 \nis loop-invariant . We next show another example of an optimization not per\u00adformed by gcc -O3, loop-operationfactoring(Loop-op-Factor \nin Figure 6). The concrete example that we used to sketch the op\u00adtimization is shown in Figure 8(a). \nThe multiplication inside the loop gets factored out of the loop through the additions. The gen\u00aderalization \nthat our system generates is shown in Figure 8(b). Our generalizer determined that the use of the array \nis insigni.cant and the format of the loop is insigni.cant, as is the constant 7, which caninfactbe anyloop-invariantexpression. \nFinally, we show how our system can learn several optimiza\u00adtions for the power function from Figure 9. \nStarting with the con\u00adcrete optimization p) pow(b, p) . instance pow(a, * . pow(a * b, p), our generalizer \nshows that the two concrete programs are equivalent, and then generalizes the example into the optimiza\u00ad \n int pow(int base, int power) int prod = 1; for (int i = 0; i < power; i++) prod *= base; return prod; \n Figure 9. The power function for integers tion .x,y, z . int. pow(x,z)* .* y,z). This pow(y,z). pow(x \nis an example of Fun-speci.c-opts from Figure 6. Similarly, we were able to get our generalizer to learn \nthe non-trivial optimiza\u00adtion: .x . uint. pow(2, x) ..1 \u00ab x (which is an example of Spec-inlining in \nFigure 6). Here again, neither of these optimiza\u00adtions are performed by gcc -O3, whereas our approach \nallows the programmer to easily specify these optimizations by example.  7.2 Learning from super-optimizers \nAnother possible use of our approach is to amortize the cost of run\u00adning a super-optimizer. Given an \ninput program, a super-optimizer performs a brute force exploration through the large space of trans\u00adformed \nprograms to .nd the (near) optimal version of the input program. Our approach can mitigate the cost of \nrunning super\u00adoptimizers by learning optimizations from one run of the super\u00adoptimizer, and then applying \nonly the learned optimizations to get much of the bene.t of the super-optimizer at a fraction of the \ncost. The Peggy compiler at its core performs a super-optimizer-style brute-forceexplorationby applying \naxioms tobuild an E-PEG that compactly represents exponentially many di.erent versions of the input program, \nand then using a pro.tability heuristic to .nd the best PEG represented in this E-PEG. To evaluate our \napproach in the setting of super-optimizers, we used Peggy to super-optimize some microbenchmarks and \nSpecJVM, and used our technique on the original and transform programs to learn optimizations. Several \nof the optimizations learned using before-and-after examples in Section 7.1 cannot be learned by using \nthe super\u00adoptimizer they really do require a programmer to give an input-output example. For instance, \nif the Peggy super-optimizer were given pow(a,p)*pow(b,p) to optimize using basic axioms, it would not \nbe able to .nd the desired transformed program pow(a*b,p) because, even though it can decompose the original \nexpression into smaller pieces, it cannot guess how to reassemble them into pow(a*b,p). However, Peggy \ncan prove the original and transformed programs equivalent because it sees the pow(a*b,p) term to which \nit can apply axioms. In essence it is easier to apply axioms on the original and transformed programs, \nand meet in the middle, rather than derive the transformed program from the origi\u00adnal.With the proof, \nour approach can learna new optimization that the Peggy super-optimizer would not have performed. Our \nsuper-optimizer experiments also show how inlining com\u00adbined with generalization produces useful and \nunconventional opti\u00admizations. Inlining in Peggy simply adds the information that a call node is equivalent \nto the body of the called function. Adding this equality does not force Peggy to choose the inlined version; \nit just provides more options in the caller s E-PEG for the pro.tability heuristic to choose from. When \nrunning on code that uses the pow function from Figure 9, the super-optimizer applied the inlining ax\u00adiom \non pow, thus pulling the body of pow into the E-PEG. Peggy thenexploited thefact that pow does not a.ect \nthe heap to optimize the surrounding context,but chose not to inline pow in the .nal re\u00adsult. From this \nour generalizer learned the optimization that pow is heap-invariant; in future compilations, Peggy can \nimmediately use thefact that pow does not a.ect the heap to optimize the surround\u00ading context without \nthe expensive process of inlining pow. This is an example of what we call partial inlining (Partial-inliningin \nFig\u00adure 6), where the optimizer exploits the information learned from inlining without opting to inline \nthe function. Another example of partial inlining we observed involved a large function that modi\u00ad.es \nthe heapbutalways returns0.By applying the inlining axiom, Peggy was able to optimize the surrounding \ncontext with the infor\u00admation that the return value was 0, but then chose not to inline the called function \nbecause it was too large. In this case the generalizer would learn that the function always returns 0, \nwhich can be used in future compilations without having to apply the inlining axiom. We evaluate the \ne.ectiveness of amortizing the cost of a super\u00adoptimizer on the SpecJVM suite. For each class in SpecJVM, \nas a .rst step we used the Peggy super-optimizer to compile the class using basic axioms, and used our \ngeneralization technique to generate a set of optimizations for that class. As a second step, we removed \nall the basic axioms from Peggy and re-optimized the class using the axioms that were learned in the \n.rst step. Across all benchmarks, it took on average 11.15 seconds to generalize a method, and the average \ncost of compiling each method went down from 26.64 seconds in the .rst step to 1.47 seconds in the second \nstep, while still producing the same output programs. These experiments show that, for expensive super-optimizers, \nour technique can improve compilation time while still produc\u00ading the same result. Furthermore, our benchmark-speci.c \noptimiza\u00adtions can still apply even if small changes are made to the code. As a result, we can avoid \na super-optimizing compile after each small change, while still retaining manyof the bene.ts of the super\u00adoptimizer. \nEventually, however, the learned optimizations will go out of date, at which point a super-optimizing \ncompile would be needed. Thus, we envision that our approach could be used to per\u00adform an expensive super-optimization \nrun every so often while us\u00ading the generated optimizations in between.  7.3 Cross-training The above \nexperiment illustrates the bene.ts of learning optimiza\u00adtions when compiling exactly the same code that \nwas learned on. We now show some encouraging evidence that even cross-training is possible. Our hypothesis \nis that many libraries are used in styl\u00adized ways, and so training with Peggy s super-optimizer on some \nuses of a library can discover optimizations that would be useful on previously unseen code that uses \nthe same library. We conducted a preliminary evaluation of this hypothesis on a Java ray tracer that \nuses a functional vector library. Peggy s optimization phase improves this benchmark s performance by \n7%, compared to only using Sun s Java 6 JIT, by removing the short\u00adlived temporary objects(Tmp-obj-removal \nin Figure 6). Most of thesegains come from one important method, call it m. We identi.ed another vector-intense \nmethod, call it f, to train our learning optimizer on. Using only the axioms learned from opti\u00admizing \nthe expressions within f, Peggy was able to optimize m to produce a 3.1% runtime improvement on the ray \ntracer, instead of the 7.1% speed-upgainedby fully optimizing m. Alternatively, us\u00ading a slightly larger \ntraining set produces a 5.1% speed-up. Upon further investigation, we found that the learned optimizations \nper\u00adform large-step simpli.cations of common usage patterns of the vector library (for example, a vector-scale \nfollowed by a vector\u00adadd). Furthermore, if in addition to the learned optimizations from either training \nset, we allow Peggy to also use those original ax\u00adioms which infer equalities without creating any new \nterms (41% of all axioms), Peggy produces the fully optimized m. The purpose of these axioms is to simplify \na program, so they cannot lead the optimizer down a fruitless path. Using simplifying axioms alone on \nm produces only a 0.6% speed-up. Thus, the optimizations learned from either training set lead the optimizer \nin the right direction, and the remaining axioms simplify the resulting expressions into the fully optimized \nm. These .ndings show that our technique can be e.ective at cross-training even on a small training set. \n 8. Related work There has been a long line of work on making optimizers extensible or easier to develop, \nincluding Sharlit [23], Whit.eld and So.a s Gospel system [24], the Broadway extensible compiler [11], \nand the Rhodium system for expressing optimizations [14, 15]. In all these systems, however, the programmer \nhas to learn a new lan\u00adguage or compiler interface to express optimizations. In contrast, our approach \nlearns an optimization from a single example pro\u00advidedbythe programmerina language alreadyfamiliarto \nthem. In the context of machine learning, our approach is an instance of Explanation-Based Learning (EBL) \n[9]. EBL refers to learning from a single example using an explanation of that example. EBL has been \napplied to a wide variety of domains, such as Prolog op\u00adtimization [10], logic circuit designs [8], and \nsoftware reuse [3]. Many of these applications use algorithms based on uni.cation or Prolog [7, 8, 10]. \nThe declarative components of Prolog can be en\u00adcoded in our framework by combining categories of expressions \nwith categories of relations. Furthermore, most EBL implementa\u00adtions provide no guarantees on what is \nlearned, while we can prove that our technique learns the most general lesson for a given expla-nation.Within \nEBL, ourworkis closely related thatof Dietzen and Pfenning [7]. They use .Prolog to extend EBL to higher-order \nand modal logic, and apply this framework to various settings including program transformations. However, \nthey do not investigate ways to automatically train the optimizer, relying instead on the user to prove \nthe transformation correct using tacticals. As a consequence, they do not attempt to decompose an optimization \ninto subopti\u00admizations, since a user manually proving an optimization would already do this. Furthermore, \nwe experimentally demonstrate that generalization can be useful for extending compilers and amortiz\u00ading \nthe cost of super-optimizers. Aside from EBL, there have been other uses of machine learning in the context \nof compiler optimizations. Techniques like genetic algorithms, reinforcement learning, and supervised \nlearning, have been used to generate e.ective heuristics for instruction schedul\u00ading [17, 20], register \nallocation [20], prefetching [20], loop-unroll factors [19], and for optimization ordering [4]. In all \nthese cases, the parts being learned are not the transformation rules themselves, but pro.tability heuristics, \nwhich are functions that decide when or where to apply certain transformations. As a result, these tech\u00adniques \nare complementary to our technique: we generate the opti\u00admization rules themselves,but not the pro.tability \nheuristics (we use a single global pro.tability heuristic for all optimizations). Also, while modern \nmachine learning techniques use statistical methods over large data sets, our EBL-based approach can \nlearn from a very small dataset, even from just one example. The idea of discovering optimizations has \nalso been been explored in the setting of super-optimizers [2, 13, 16]. Super\u00adoptimizers try to discover \noptimizations by a brute-force explo\u00adration of possible transformed programs for a given input program. \nTraditional super-optimizers .nd concrete optimization instances, whereas our approach starts with optimization \ninstances, and tries to generalize the instances into reusable optimization rules. As such, our work \nis complementary to super-optimization tech\u00adniques. However, Bansal and Aiken s recent super-optimizer \n[2] does achieve a simple form of generalization, namely abstraction of register names and constants. \nIn contrast, we perform a more sophisticated kind of generalization based on the reasons why the original \nand transformed programs are equivalent. Acknowledgments We thank Suresh Jagannathan, Todd Mill\u00adstein, \nZachary Tatlock and the anonymous reviewers for their in\u00advaluable feedback on earlier drafts of this \npaper, as well as Alin Deutsch, Daan Leijen, and Rustan Leino for their feedback on al\u00adternative applications \nof proof generalization. References [1] J. Ad\u00b4amek, H. Herrlich, and G. E. Strecker. Abstract and Concrete \nCategories: TheJoy of Cats. JohnWiley&#38;Sons, 1990. [2] S. Bansal and A. Aiken. Automatic generation \nof peephole superoptimizers. In ASPLOS, 2006. [3] R. Bergmann. Explanation-based learning for the automated \nreuse of programs. In CompEuro, 1992. [4] K. D. Cooper, D. Subramanian, and L.Torczon. Adaptive optimizing \ncompilers for the 21st century. The Journal of Supercomputing, 23(1):7 22, Aug. 2002. [5] A. Deutsch. \nAuthor of [6]. Personal communication, July 2009. [6] A. Deutsch, A. Nash, and J. Remmel. The chase revisited. \nIn PODS, 2008. [7] S. Dietzen and F. Pfenning. Higher-order and modal logic as a framework for explanation-based \ngeneralization. Machine Learning, 9(1):23 55, June 1992. [8] T. Ellman. Generalizing logic circuit designs \nby analyzing proofs of correctness. In IJCAI, volume 1, pages 643 646, 1985. [9] T. Ellman. Explanation-based \nlearning: a survey of programs and perspectives. ACM Computing Surveys, 21(2):163 221, June 1989. [10] \nM. Gandhe and G. Venkatesh. Improving prolog performance by inductive proof generalizations. In Knowledge \nBased Computer Systems, 1990. [11] S. Z. Guyer and C. Lin. Broadway: A compiler for exploiting the domain-speci.c \nsemantics of software libraries. Proceedings of IEEE, 93(2), 2005. [12] C. Haack and J. B. Wells. Type \nerror slicing in implicitly typed higher-order languages. Science of Computer Programming, 50(1\u00ad3):189 \n224, 2004. [13] R. Joshi, G. Nelson, and K. Randall. Denali: a goal-directed superoptimizer. In PLDI, \nJune 2002. [14] S. Kundu, Z. Tatlock, and S. Lerner. Proving optimizations correct using parameterized \nprogram equivalence. In PLDI, 2009. [15] S. Lerner, T. Millstein, E. Rice, and C. Chambers. Automated \nsoundness proofs for data.ow analyses and transformations via local rules. In POPL, 2005. [16] H. Massalin. \nSuperoptimizer: a look at the smallest program. In ASPLOS, 1987. [17] A. McGovern, J. E. B. Moss, and \nA. G. Barto. Building a basic block instruction scheduler with reinforcement learning and rollouts. Machine \nLearning, Special Issue on Reinforcement Learning, 49(2/3):141 160, May 2002. [18] R. Millner. Atheory \nof type polymorphism in programming. Journal of Computer and System Sciences, 1978. [19] M. Stephenson \nand S. Amarasinghe. Predicting unroll factors using supervised classi.cation. In CGO, Mar. 2005. [20] \nM. Stephenson, S. Amarasinghe, M. Martin, and U.-M. O Reilly. Meta optimization: Improving compiler heuristics \nwith machine learning. In PLDI, June 2003. [21] R.Tate, M. Stepp, and S. Lerner. Generating compiler \noptimizations from proofs. Technical report, University of California, San Diego, Nov. 2009. [22] R. \nTate, M. Stepp, Z. Tatlock, and S. Lerner. Equality saturation: a new approach to optimization. In POPL, \nJan. 2009. [23] S. W. K. Tjiang and J. L. Hennessy. Sharlit A tool for building optimizers. In PLDI, \n1992. [24] D. L. Whit.eld and M. L. So.a. An approach for exploring code improving transformations. ACM \nTransactions on Programming Languages and Systems, 19(6):1053 1084, Nov. 1997.    \n\t\t\t", "proc_id": "1706299", "abstract": "<p>We present an automated technique for generating compiler optimizations from examples of concrete programs before and after improvements have been made to them. The key technical insight of our technique is that a proof of equivalence between the original and transformed concrete programs informs us which aspects of the programs are important and which can be discarded. Our technique therefore uses these proofs, which can be produced by translation validation or a proof-carrying compiler, as a guide to generalize the original and transformed programs into broadly applicable optimization rules.</p> <p>We present a category-theoretic formalization of our proof generalization technique. This abstraction makes our technique applicable to logics besides our own. In particular, we demonstrate how our technique can also be used to learn query optimizations for relational databases or to aid programmers in debugging type errors.</p> <p>Finally, we show experimentally that our technique enables programmers to train a compiler with application-specific optimizations by providing concrete examples of original programs and the desired transformed programs. We also show how it enables a compiler to learn efficient-to-run optimizations from expensive-to-run super-optimizers.</p>", "authors": [{"name": "Ross Tate", "author_profile_id": "81392610098", "affiliation": "University of California, San Diego, CA, USA", "person_id": "P1911128", "email_address": "", "orcid_id": ""}, {"name": "Michael Stepp", "author_profile_id": "81336493326", "affiliation": "University of California, San Diego, CA, USA", "person_id": "P1911129", "email_address": "", "orcid_id": ""}, {"name": "Sorin Lerner", "author_profile_id": "81100399150", "affiliation": "University of California, San Diego, CA, USA", "person_id": "P1911130", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706345", "year": "2010", "article_id": "1706345", "conference": "POPL", "title": "Generating compiler optimizations from proofs", "url": "http://dl.acm.org/citation.cfm?id=1706345"}