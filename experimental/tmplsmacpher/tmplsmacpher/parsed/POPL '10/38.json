{"article_publication_date": "01-17-2010", "fulltext": "\n Nested Interpolants Matthias Heizmann Jochen Hoenicke Andreas Podelski University of Freiburg, Germany \n Abstract In this paper, we explore the potential of the theory of nested words for partial correctness \nproofs of recursive programs. Our conceptual contribution is a simple framework that allows us to shine \na new light on classical concepts such as Floyd/Hoare proofs and predicate abstraction in the context \nof recursive programs. Our technical contribution is an interpolant-based software model checking method \nfor recursive programs. The method avoids the costly construction of the abstract transformer by constructing \na nested word automaton from an inductive sequence of nested interpolants (i.e., interpolants for a nested \nword which represents an infeasible error trace). Categories and Subject Descriptors D.2.4 [Software \nEngineer\u00ading]: Software/Program Veri.cation; F.3.1 [Logics and Meanings of Programs]: Specifying and \nVerifying and Reasoning about Pro\u00adgrams General Terms Languages, Theory, Veri.cation. Keywords Nested \nwords, interpolants, recursion, static analysis, abstract interpretation, software model checking, abstraction \nre\u00ad.nement, Floyd-Hoare logic. 1. Introduction A recent trend in software veri.cation tools in the line \nof [5, 8, 9, 12, 14, 15, 16, 19, 20] is to use interpolants in order to avoid the construction of the \nabstract transformer for the underlying pro\u00adgram analysis. The idea is to generate an inductive sequence \nof interpolants from a false positive (a spurious error trace ) returned by the program analysis. Roughly, \nthe inductiveness expresses that the interpolants can be used to form a sequence of Hoare triples which \nproves the infeasibility of the spurious error trace. The in\u00adductiveness thus entails the elimination \nof the false positive. While the approach is incarnated with great success in the lazy abstrac\u00adtion with \ninterpolants scheme for non-procedural programs [19], it is not clear how one can extend it to a principled \nmethod for the general class of programs with procedures, possibly recursive ones. What we are interested \nin here is a general foundation that allows us to systematically reason about interpolant-based correctness \nproofs for recursive programs. In this paper, we propose to base such a foundation on the theory of nested \nwords [2, 3]. The motivation to use nested words stems directly from the observation that the stack-based \nsemantics of recursive programs Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 10, January 17 23, 2010, Madrid, Spain. Copyright c &#38;#169; \n2010 ACM 978-1-60558-479-9/10/01. . . $10.00 is not appropriate for our purpose. If we model a state \nas a stack of valuations of program variables and generate interpolants from a trace modeled as a sequence \nof states, then the interpolants cannot be restricted to contain variables of the local calling context. \nThis defeats the very purpose of interpolants (to carry a minimal amount of information needed locally \nat a given position in the trace). The theory of nested words (and nested word automata) offers an interesting \npotential as an alternative to the low-level view of a recursive program as a stack-based device that \nde.nes a set of traces. A nested word expresses not only the linear order of a trace but also the nesting \nof calls and returns. A nested word automaton does not need a stack. If we model the execution of a recursive \nprogram as a nested word, we can reason directly on the nesting, instead of having to recover the nesting \nwith the help of a stack. We thus trade an operationally complex device de.ning a set of simple objects \n(traces) for an operationally simple device de.ning a set of rich objects (nested traces). The insight \nput forward in this work is that the increase of the object complexity is irrelevant since we reduce \nthe reasoning of program correctness to the emptiness of the de.ned set of objects (the objects are existentially \nquanti.ed and thus projected out ). In this paper, we explore the potential of the theory of nested words \nas a foundation for correctness proofs for the general class of recursive procedures. Our conceptual \ncontribution is a simple framework that allows us to shine a new light on classical concepts such as \nFloyd/Hoare proofs and predicate abstraction for recur\u00adsive programs. Our technical contribution is to \ngive, to our knowl\u00adedge for the .rst time, a principled method that constructs an ab\u00adstract proof for \nrecursive programs from interpolants (avoiding the construction of the abstract transformer). The method \nconstructs a nested word automaton from an inductive sequence of nested in\u00adterpolants (i.e., interpolants \nfor the nested trace of the recursive program). Related Work. Given the huge body of work on the treatment \nof recursion and the use of interpolants in software veri.cation, we will discuss only the most related \nwork. We pick up the line of work on using nested words to provide a basis for software veri.cation [2, \n3]. A basic observation in [2, 3] is that the set of nested words generated by an abstract recursive \nprogram is de.nable by a .nite nested word automaton. This ob\u00adservation refers to the setting where one \nhas already constructed an abstract recursive program (from the program to be veri.ed). This construction \namounts to the construction of the abstract trans\u00adformer, a costly step that current research tries to \noptimize, or to avoid altogether [5, 7, 8, 9, 12, 14, 15, 16, 19, 20] . Our work refers to the general \nsetting of software model checking, where this step is not or not yet performed. I.e., we investigate \ndifferent ways to construct a .nite nested word automaton directly from the program to be veri.ed. This \nallows us to give a foundation for interpolant\u00adbased proofs for recursive programs. We distinguish two \nmethods to use interpolants for software veri.cation. The .rst method, as used, e.g., in [13, 19], generates \nan  procedure m(x) returns (res) {T} e0: if x>100 {x = 101} e1: res:=x-10 else {x = 100} e2: xm := x+11 \n{xm = 111} e3: call m {resm = 101}e4: xm := resm {xm = 101} e5: call m {resm = 91} e6: res := resm {res \n= 91 . (x = 101 . res = x - 10)} e7: assert (x<=101 -> res=91) return m Figure 1. McCarthy s 91 function \ntogether with a Floyd-Hoare style annotation with invariant assertions. The program is correct if the \nassert statement never fails. inductive sequence of interpolants from the spurious error trace of a non-recursive \n(non-procedural) program. The interpolants form the labels in the abstract reachability tree (in conjunctions \nin [19], and in tuples in [13]). The method thus constructs an interpolant-based proof and avoids the \nconstruction of an abstract transformer. The second method, as used, e.g., in [11, 14, 17], generates \na not necessarily inductive sequence of interpolants from the spuri\u00adous error trace of a recursive program. \nThe interpolants are used solely for de.ning new predicates (by subformulas). The method does construct \nan abstract transformer. The proof is constructed by .xpoint iteration. The iterates (i.e., not the interpolants) \nform a se\u00adquence of Hoare triples which proves the infeasibility of the spuri\u00adous error trace. I.e., \nthe inductiveness of sequences of interpolants is irrelevant in [11, 14]. To summarize, the .rst method \ndoes not account for recursion, and the second one does not consider inductive sequences of in\u00adterpolants \n(or other ways to avoid the construction of the abstract transformer). In contrast, we use nested words \nto formalize in\u00adductive sequences of interpolants for traces of recursive programs (and nested word automata \nto avoid the construction of the abstract transformer). 2. Preliminaries In this section, we .x the notation \nfor recursive programs (follow\u00ading [21]) and for nested words (following [2, 3]). 2.1 Recursive Programs \nInformal Presentation. We consider a simple procedural pro\u00adgramming language in a BoogiePL-like syntax \n[6]. As usual, we impose a number of restrictions and conventions in order to sim\u00adplify the formal exposition. \nThe language has no pointers, no global variables and only call-by-value procedure calls. It is forbidden \nto write to the input variables of a procedure. A procedure p has one input parameter x and one output \nparameter res. Procedure calls appear in the following form. resp := call p(xp) Figure 2. Recursive \ncontrol .ow graph for the recursive program P91 implementing McCarthy s 91 function. The initial location \nis e0. The error location eerr is used to encode the correctness of the program. In Section 3 we will \nintroduce a different reading of the graph, namely as a particular nested word automaton (over the alphabet \nof statements st), the control automaton AP91 . If procedure p with formal parameter x is called, the \nargument (actual parameter) is a special variable xp. On return, the value of the procedure s output \nvariable res is stored into the special variable resp of the caller. Before calling procedure p, the \ncaller writes the input value to the variable xp. The callee accesses the value through the variable \nx. The callee stores the result value into the variable res. The result value is returned to the caller \nthrough the variable resp. Procedures with arbitrarily many input and output parameters can be treated \nin an analogous way. A global variable can be modeled by adding an input and an output variable to each \nprocedure that directly or indirectly (via a recursive function call) accesses the global variable. Figure \n1 shows an implementation of McCarthy s 91 function (if the argument x is not greater than 101, the function \nreturns 91) in a code fragment that meets our restrictions and conventions. Formal Presentation: Recursive \nControl Flow Graph. Follow\u00ading [21], we present a recursive program formally as a recursive control .ow \ngraph; see Figure 2 for an example. Each node is a program location e. Each edge is labeled with a statement \nst, which is either an assignment y:=t , an assume , a call return For each procedure p, the recursive \ncontrol .ow graph contains p s control .ow graph. The edges between internal nodes are la\u00adbeled with \nassignment or assume statements. The nodes of p s con\u00adtrol .ow graph are the program locations of p, \nsay ep,...,ep where 0n the node ep 0 is the entry location of p and epn its exit location. To model that \nprocedure p is called from procedure q at program loca\u00adtion eqj (in q s control .ow graph), an edge labeled \n goes from eqj to ep 0, the entry location of p,  state label of edge (e, e') successor state side condition \nassignment assume call return S.(e, .) S.(e, .) S.(e, .) S.(e< , .< ).(e, .) y:=t f call p return p .e< \nS.(e', .') S.(e', .) S.(e, .).(e', .') S.(e', .') .' = . . {y . .(t)} . |= f .'(x) = .(xp) .' = .< .{resp \n. .(res)} Figure 3. Semantics of statements in the context of a recursive control .ow graph (where a \nstatement is used to label an edge between two nodes e and e'). A state is a stack of local states/location-valuation \npairs; the current local state is the topmost/rightmost one. an edge labeled return p . eq goes from \nep , the exit location jn of p, to the location ejq +1 in q s control .ow graph, where eq is the successor \nlocation of eq with respect to the call of j+1 j procedure p. In Figure 2, we use a thick gray edge in \norder to depict the successor location of a call location, with respect to the procedure calls initiated \nby call m . The thick gray edges are not edges of the recursive control .ow graph. The assert statement \nfrom Figure 1 is translated to an edge which is labeled with an assume statement and leads to a special \nerror location. Semantics. A valuation . is a function that maps program vari\u00adables to values. A (local) \nstate of a procedure is a pair (e, .), con\u00adsisting of a program location and a valuation. A state S of \nthe (whole) program is a stack of local states, i.e., location-valuation pairs, which we write as a sequence \nS =(e0,.0).(e1,.1) ... (en,.n). Each element corresponds to a called (and not yet returned) proce\u00addure. \nThe topmost/rightmost element represents the actual calling context. Each statement st induces a transition \nrelation between states; see Figure 3. We use the usual notation for a transition from a state S to a \nsuccessor state S'. st S -. S' Traces p. A trace p is a sequence of statements, p = st0 . . . stn-1. \nWe extend the transition relation from single statements to traces in the usual way and use the same \nnotation also for traces. p' S -. S A trace p is a feasible error trace of the program P if there exists \nan initial valuation .0, a stack of local states S and a .nal valuation .n such that the triple p (e0,.0) \n-. S.(eerr,.n) is a transition of the program (where e0 is the initial location of the main procedure \nof P and eerr is an error location of P). Program Correctness = No Feasible Error Traces. The recursive \ncontrol .ow graph encodes program correctness through special nodes corresponding to error locations. \nWe de.ne the correctness of the program through the non-reachability of an error location eerr by a program \nexecution. Formally, a program P is correct if it has no feasible error trace. The classical notion of \npartial correctness can be accommodated by representing precondition and postcondition by assume state\u00adments \nand assert statements (the latter is translated to an edge that leads to the error location).  2.2 Nested \nWords Following [2, 3], a nested word over an alphabet S is a pair (w, ) consisting of a word w = a0 \n...an-1 over the alphabet S and the nesting relation . The fact that is a nesting relation for w means \nthat we have a relation between the n positions of w, formally .{0,...,n - 1}\u00d7{0,...,n - 1, 8} which \nis left-unique, right-unique, and properly nested, formally: i1 j, i2 j, j = i2 = 8 implies i1 i j1,i \nj2 implies j1 = j2 8 < i1 <j1 <i2 <j2 i1 j1,i2 j2,i1 = i2 implies or : i1 = i2 <j2 = j1. The idea is \nthat the relation between the position i of a call and the position j of a matching return is expressed \nby i j. Positions appearing on the left (resp. right) in pairs in are called call (resp. return positions). \nAll other positions are internal positions. The index 8 is used as return position for all un.nished \ncalls. For a return position j 8, the corresponding call position (i.e., the = unique position i such \nthat i j) is the call predecessor of j. In contrast with [3], we do not allow -8 as a call predecessor. \nIn contrast with [2], we do allow 8 as a return position. Possibly In.nite Nested Word Automata (NWA). \nA nested word automaton over an alphabet S is a tuple ),Qinit,Q.n A =(Q, (din,dca,dre) consisting of \n a (not necessarily .nite) set of states Q,  a triple (din,dca,dre) of transition relations for, respectively, \ninternal, call, and return positions,  din . Q \u00d7 S \u00d7 Q dca . Q \u00d7 S \u00d7 Q dre . Q \u00d7 Q \u00d7 S \u00d7 Q a set of \ninitial states Qinit . Q,  a set of .nal state Q.n . Q.  A run of a nested word automaton A over the \nnested word (a0 ...an-1, ) is a sequence q0,...,qn of states that starts in an initial state, i.e., q0 \n. Qinit, and that is consecutive, i.e., for each i =0,...,n - 1, (qi,ai,qi+1) . din if i is an internal \nposition, (qi,ai,qi+1) . dca if i is a call position, (qi,qk,ai,qi+1) . dre if i is a return position \nand k i. The run is accepting if it ends in a .nal state, i.e., qn . Q.n . The nested word automaton \nA accepts the nested word (w, ) if it has an accepting run over (w, ). The language of nested words recognized \nby A is the set L(A) consisting of the nested words accepted by A.  0 1 2  3 4 5 6 nested trace p1 \n1 .1 4 .0 1  .1 2 .2 3 .3  .4 4 5 .5 6 .6  .7 7 .8 nested trace p2 2 .2 5 x xm resm res 97 * * * \n97 * * * 97 108 * * 108 * * * 108 * * * 108 * * 98 97 108 98 * 97 108 98 98 97 108 98 98 0 1 2 3 4 \n 5 nested trace p3 2 .3 8 Figure 4. Examples of nested traces (over the alphabet of statements used \nin the recursive program P91 implementing McCarthy s 91 function). The indentation of the statements \nindicates the nesting relation. The nested trace p3 is accepted by the control automaton AP91 ; the two \nothers are not. The nested trace p2 is accepted by the data automaton AS (the sequence .0,...,.8 is an \naccepting run); the two others are not. Deviating from [2, 3], we do not require that the set of states \nof a nested word automaton is .nite. In the next section, we will de.ne the data automaton as a possibly \nin.nite nested word automaton. All other automata considered in this presentation are .nite. The notion \nof regularity does not deviate from [2, 3]. A language of nested words is regular if it is recognized \nby a .nite nested word automaton. Regular languages of nested words enjoy the standard properties of \nregular language theory, of which we will use the closure under intersection and complement, and the \ndecidability of emptiness [2, 3]. 3. An NWA View of Program Correctness The .rst step to formulate a \nview of program correctness in terms of nested words is to .x the alphabet, namely as the set of statements. \nOnce we have done that it is very natural to give a view of Pro\u00adgram correctness, to de.ne a new proof \nrule based on nested word automaton, and to give a new formulation of predicate abstraction based on \nnested word automata. 3.1 An NWA characterization of Program Correctness We assume a .xed set of statements \nwhich we note S. We will view S as an alphabet, statements st as letters and traces st0 . . . stn-1 as \nwords; i.e., st0 . . . stn-1 . S * . We de.ne a nested trace to be a nested word p =(st0 . . . stn-1, \n) over the alphabet S of statements. Given a nested trace over the alphabet S whose letters include call \nand return statements, it makes sense to re.ne the notion of nesting. We say that p =(st0 . . . stn-1, \n) is well-nested if the nesting relation between its positions is consistent with the letters at the \nrespective positions; i.e., we have the letter sti is a call statement if and only if i is a call position, \nand  the letter sti is a return statement if and only if i is a return position.  Example 1. Figure \n4 depicts three examples of nested traces (over the alphabet of statements used in the McCarthy example). \nThe three corresponding nesting relations are given below. 1 1 4 2 2 5 2 3 8 In the .gure we use indentation \nto indicate the nesting relation. Nested Traces and Possible Program Executions. The notion of a nested \ntrace does not refer to a speci.c program (in fact, it may not correspond to a path in the given program \ns recursive control .ow graph), and it does not take into account the semantics of statements (it may \nnot correspond to a possible execution of any program). We will next introduce two properties of a nested \ntrace which together imply the fact that it corresponds to a possible execution of the given program. \nThe two properties characterize two orthogonal aspects ( control vs. data ) of this fact. Each of the \ntwo properties will be presented as a nested word automaton, AP resp. AS. The .rst property characterizes \nthe fact that the nested trace complies with the control .ow prescribed by the recursive program graph \n(and that it is well-nested). This property is a regular lan\u00adguage of nested words; we will use the control \nautomaton AP ,a .nite nested word automaton, to present it. The second property characterizes that the \nnested trace complies with the semantics of statements as manipulators of data (and that it is well-nested). \nThis property is in general not a regular language of nested words; we will use the data automaton AS, \nan in general in.nite nested word automaton, to present it. Control. From now on, we assume a .xed program \nP given formally as a recursive control .ow graph. The set of nested traces that comply with the control \nexpressed by P (ignoring the data) can be formally de.ned by the recursive program graph viewed as a \nnested word automaton. I.e., the edges of the recursive program graph de.nes the three kinds of transition \nrelations; the initial location de.nes the set of initial states; the error location de.nes the set of \n.nal states.  De.nition 1 (Control Automaton AP , Nested Error Trace). Given the program P, the control \nautomaton AP is the nested word automaton init.n AP =(Q, (din,dca,dre),Q,Q) where the set of states \nQ is the set of nodes (i.e., program locations),  the three transition relations din, dca, dre are the \nedge relations;  i.e., if the edge (e, e ' ) is labeled with: the assignment or assume statement st, \nthen (e, st, e ' ) . din the call statement (e, call p ,e ' ) . dca the return statement (with call \nlocation e< ) . e< , then (e, e< ' ) . dre the set of initial states Qinit consists of the initial location \nof the main procedure, init main Q= {e } 0 the set of .nal states Q.n consists of the error location, \nQ.n = {eerr}. A nested error trace is a nested word accepted by the control automaton AP . An alternative, \nricher way to de.ne the regular language of nested error traces uses the automata-theoretic product of \ntwo nested word automata. The .rst one is the recursive program graph (without error locations) viewed \nas a nested word automaton (just as we did for AP ) where every program location is a .nal state; i.e., \nQ.n = Q. The second one is the nested word automata that corresponds to the negation of the CaRet property \nthat de.nes the program correctness [1]. Example 2. The control automaton AP91 of the program P91 is \ngiven in Figure 2. In the .gure, a return edge labeled by a return statement together with the call location \nrepresents a transition in dre. For example, the edge labeled (e7, return . e5,e6) represents the transition \n(e7,e5, return ,e6) in dre. We next take the three nested traces from Example 1 (given in Figure 4) and \ninvestigate whether they are accepted by AP91 . The nested trace p1 is not accepted because position \n1 is a call position according to the nesting relation (and hence the successor state should be given \nby the transition relation dca), but the letter at position 1 is not a call statement (and hence there \nis no successor state according to the transition relation dca). The nested trace p2 is not accepted. \nThe run r = e0,e2,e3,e0,e1,e7,e6,e7,eerr is possible according to the graph structure of AP91 . However, \nPo\u00adsition 5 of p2 is a return position, and position 2 its call predeces\u00ad m ,e6) was a transition in \ndre (corre\u00adsponding to a return edge of AP91 ), r would be a valid run. This (the fact that the nested \ntrace p2 is not accepted) illustrates that the control automaton enforces the call/return discipline; \ni.e., return statements leading to e6 can only return from procedures called from location e5. The nested \ntrace p3 is accepted by AP91 . This illustrates the fact that the control automaton accepts traces with \nunmatched call statements. The example also illustrates that the existence of a nested error trace (i.e., \nthe non-emptiness of the control automaton AP ) does not yet imply a violation of the correctness speci.cation \n( control is not enough; we also need data ). Data. We next de.ne the data automaton AS. This (in general \nin.nite) nested word automaton recognizes an (in general non\u00adregular) set of nested traces. This set \ncontains the well-nested traces that are possible according to the semantics of statements (whose execution \nmanipulates data). We call these traces feasible nested traces. This is the only point in the presentation \nwhere we de.ne an in.nite nested word automaton. In fact, from now on we will construct .nite nested \nword automata that approximate the in.nite data automaton AS (i.e., recognize a superset). De.nition \n2 (Data Automaton AS, Feasible Nested Trace). Given the set of statements S, the data automaton init.n \nAS =(Q, (din,dca,dre),Q,Q) is the (in general in.nite) nested word automaton where the set of states \nQ is the (in general in.nite) set of valuations .,  the three transition relations din, dca, dre are \nthe transition rela\u00ad  tions induced by the statements in S; i.e., if the statement is: the assignment \nstatement y:=t , then (., y:=t ,. .{y . .(t)}) . din the assume statement , then (., ,.) . din if . |= \nf the call statement '' ) . dca if . (x)= .(xp) the return statement  p ,.< .{resp . .(res)}) . dre \n. every state is an initial state (i.e. Qinit = Q),  every state is a .nal state (i.e. Q.n = Q).  \nA feasible nested trace is a nested word is accepted by the data automaton. Example 3. We take the three \nnested traces from Example 1 (given in Figure 4) and investigate whether they are accepted by AS. The \nnested trace p1 is not accepted; the same explanation as with AP applies. In fact, both a control automaton \nand a data automaton accept only well-nested traces. The nested trace p2 is accepted (i.e., it is a feasible \nnested trace). The sequence .0,...,.8 is an accepting run. The nested trace p3 is not accepted because \nthere is no valua\u00adtion/state . with a run that reads the three letters: the assume state\u00adment and the \nassume state\u00adment . Theorem 1 (Characterizing Program Correctness by NWA s). The program P is correct \nif and only if the intersection between the control automaton and the data automaton is empty, formally \nL(AP ) nL(AS)= \u00d8. Proof. Using the three notions of: feasible error trace (de.ned in Section 2.1), nested \nerror trace (i.e., accepted by AP ), and feasible nested trace (i.e., accepted by AS), we can rephrase \nthe theorem as follows. A trace st0 . . . stn-1 is a feasible error trace of P if and only if there exists \na nesting relation such that the nested trace (st0 . . . stn-1, ) is at the same time a nested error \ntrace and a feasible nested trace.  We show a more general statement by induction on the length n of \nthe trace. For every nesting relation such that . {0,...,n - 1}\u00d7{0,...,n - 1, 8}, every sequence of loca\u00adtions \ne0,...,en and every sequence of valuations .0,...,.n the following two statements are equivalent. The \nsequence of locations e0,...,en is a run of AP for (st0 . . . stn-1, ) and the sequence of valuations \n.0,...,.n isarun of AS for (st0 . . . stn-1, ).  The nested trace (st0 . . . stn-1, ) is well-nested \nand there is a sequence of stacks  st0st1stn-1 (e0,.0) -. S1.(e1,.1) -. \u00b7 \u00b7\u00b7 -. Sn.(en,.n) according \nto the transition relation of P. In that case Si = (ek0 ,.k0 ) ... (ekm ,.km ) such that the nesting \nrelation contains k00,...,km and k0 < \u00b7\u00b7\u00b7 <km <i = k ' = k ' k ' \u00b7\u00b7\u00b7 = k0 ' holds. mm  3.2 Proof Rule \nBased on Finite NWA The following proof rule for the correctness of recursive programs uses a .nite nested \nword automaton A as a proof argument: if A recognizes a superset of the set of feasible nested traces \nand it does not intersect with the control automaton, then the program is correct. L(A) .L(AS), L(A) \nnL(AP )= \u00d8 =.P is correct (1) The proof rule is interesting by the theory of regular languages of nested \nwords; once we have constructed a .nite nested word au\u00adtomaton A that approximates the data automaton, \nthe emptiness of its intersection with the control automaton can be tested effec\u00adtively [2, 3]. The soundness \nof the proof rule (1) follows from the only-if di\u00adrection of Theorem 1. The question is: if the program \nP is correct, is there always a proof argument in the form of a .nite nested word automaton A? Perhaps \nsurprisingly, the answer is yes: the proof rule is complete. Completeness notoriously holds (if it holds) \nby a disappointingly trivial line of reasoning with no indication on how to .nd the proof argument. For \nthe proof rule (1), it is suf.cient to take the complement of AP as a candidate for A. Clearly its inter\u00adsection \nwith AP is empty. Since AP does not accept any feasible nested trace (otherwise P would not be correct), \nor: it recognizes a subset of infeasible nested traces, its complement recognizes a superset of feasible \ntraces. We summarize our discussion by the following statement. Theorem 2 (Soundness and Completeness \nof Proof Rule (1)). The program P is correct if and only if there exists a .nite nested word automaton \nA that recognizes a superset of the set of feasible nested traces (i.e., L(A) .L(AS)) and that does not \nintersect with the control automaton (i.e., L(A) nL(AP )= \u00d8). In the remainder of this presentation, \nwe will investigate sys\u00adtematic ways to construct candidate proof arguments for a .nite nested word automaton \nA.  3.3 Predicate Abstraction In this section, we automate the proof rule given in the previous section \nby giving a predicate abstraction-based proof method for the correctness of a recursive program. The \nproof method uses predicate abstraction to construct a .nite nested word automaton APred which recognizes \na superset of the set of feasible nested error traces. The proof succeeds if the intersection of APred \nwith the control automaton AP is empty. Intuitively, the proof method constructs APred by abstracting \nthe data automaton AS. The abstraction consists essentially of trans\u00adforming the triple of transition \nrelations between concrete valu\u00adations (the states of AS) into a triple of transition relations be\u00adtween \nabstract valuations. Abstract valuations are de.ned in terms of predicates; we will formally introduce \nabstract valuations as bitvectors. Predicates. In our context, a predicate is a set of valuations. Such \na set may be de.ned by an assertion, e.g., x = 101. Bitvectors. Given a .nite set of predicates, say \nPred = {p1,...,pm} we call an m-tuple b .{0, 1}m a bitvector. Assuming a .xed order on the predicates, \na bitvector b = (b1,...,bm) has a meaning de.ned by [ (b1,...,bm)] = {. |.j .{1,...,m}.. . pj . bj =1}. \nNested Post Operators (postin, postca, postre). The triple of nested post operators (postin, postca, \npostre) de.ned in Figure 5 are in direct connection with the triple of transition relations (din,dca,dre) \nof the data automaton AS. Namely, for a set V of valuations, we have: postin(V, st)= {. ' |. . .V :(., \nst, . ' ) . din} postca(V, st)= {. ' |. . .V :(., st, . ' ) . dca} postre(V, V<, st)= {. ' |. . .V. .< \n.V< : .(x)= .<(xp), (., .<, st, . ' ) . dre} ### Abstract Nested Post Operators (post, postca , postre \n). The in translation of the triple (postin, postca, postre) of nested post oper\u00ad ### ators into the \ntriple (post, postca, postre ) of abstract nested post in operators (over bitvectors) is as one expects; \nsee Figure 5. De.nition 3 (Predicate Automaton APred). Given the set of predi\u00adcates Pred, the predicate \nautomaton init.n APred =(Q, (din,dca,dre),Q,Q) is the .nite nested word automaton where the set of states \nQ consists of all bitvectors,  every state is initial, i.e., Qinit = Q,  every state is .nal, i.e., \nQ.n = Q,  the triple of transition relations (din,dca,dre) corresponds to the triple (post # , post# \n, post#) of abstract nested post op\u00ad  care in erators; i.e., if st is an assignment or assume statement, \nthen # (b b, st, b ' ) . din if b ' . postin (b b, st), if st is a call statement, then b ' # (b b, \nst, b ' ) . dca if . postca(b b, st), if st is a return statement, then # (b b, b <, st, b ' ) . dre \nif b ' . postre (b b, b <, st). Theorem 3. The predicate automaton APred recognizes a superset of the \nset of feasible nested traces, i.e., L(APred) .L(AS). Proof. An accepting run .0,...,.n of the data automaton \nAS on a nested trace p gives rise to an accepting run b 0,...,b n of the predicate automaton APred on \np where the i-th bitvector contains the i-th valuation, formally .i . [ b i] for i =0,...,n.  = {. \n.{y . .(t)}| . . V} postin(V, )= {. | . .V,. |= f} = {. ' |{x . .(xp)}. . ' ,. . V} = {.< .{resp . .(res)}| \n.(x)= .<(xf ),.< .V<,. . V} post # (b = {b ' | postin([[b ] , y:=t ) n [ b ' ] = \u00d8} in post #(b b, \n)= {b ' | postin([[b ] , ) n [ b ' ] = \u00d8} in post #(b = {b ' | postca([[b ] , call p ) n [ b ' ] = \u00d8} \nca # postre (b = {b ' | postre([[b ] , [ b <] , return p ) n [ b ' ] = \u00d8} Figure 5. The triple (postin, \npostca, postre) of nested post operators (over sets of valuations V) is in correspondence with the triple \nof ### transition relations of the data automaton AS. The triple (post, postca, postre ) of abstract \nnested post operators (over bitvectors) is in in correspondence with the triple of transition relations \nof the predicate automaton APred. 4. Nested Interpolant Automata We now de.ne a class of .nite nested \nword automata which recog\u00adnize subsets of the set of infeasible traces. That is, we will use their complement \nfor the nested word automaton A that serves as proof argument in the proof rule (1) of the previous section. \nIn many of the settings that we consider, we have a sequence of predicates I0,I1,...,In (we refer to \nthe predicates as interpolants for reasons that will become apparent later); this sequence is related \nto a nested error trace p; it may be generated, for example, by the proof of the infeasibility of p. \nThe general notion of an interpolant automaton that we intro\u00adduce below, however, does not refer to an \nerror trace. It refers to an arbitrary sequence of predicates I0,I1,...,In. Given such a se\u00adquence, we \nwill associate each predicate Ii with an automaton state qi. The automaton states are not necessarily \npairwise distinct; i.e., we may associate two different predicates Ii and Ij with the same automaton \nstate, and we may associate the same predicate with two different states (i.e., we may have Ii = Ij ,qi \n= qj and we may have Ii = Ij ,qi = qj ). The non-constructive de.nition below ac\u00adcommodates a wide range \nof possible constructions. The de.nition of a canonical interpolant automaton in Section 5 is constructive. \nDe.nition 4 (Nested Interpolant Automaton AI). Given a se\u00adquence of predicates ( interpolants ) I = I0,I1,...,In, \nthe nested interpolant automaton ),Qinit ,Q.n AI =(Q, (din,dca,dreII ) is a .nite nested word automaton \nif we can index its set of states QI with the set of indices of the sequence {0,...,n}, i.e., QI = {q0,...,qn} \nand thus associate each interpolant Ii with a state qi, such that the following three conditions hold. \nThe sequence of interpolants is inductive wrt. the triple of transition relations (din,dca,dre), i.e., \n (qi, y:=t ,qj ) . din . postin(Ii, y:=t ) . Ij (qi, ,qj ) . din . postin(Ii, ) . Ij p ,qj ) . dca . \npostca(Ii, call p ) . Ij Each interpolant associated with a .nal state is the false predi\u00adcate. .n qi \n. QI . Ii = . Theorem 4. A nested interpolant automaton AI recognizes a subset of infeasible nested traces. \nL(AI ) nL(AS)= \u00d8 Proof. We show by induction on the length of a nested trace p = (st0, . . . , stn-1, \n) the following. If q0,...,qn is a run of AI for st0, . . . , stn-1 then .0,...,.n is a run of AS only \nif .i . Ii for i =0,...,n. We proof the induction step for the case where the last position of the sequence \nis an internal position as follows. Let q0,...,qn+1 be a run of AI for p =(st0, . . . , stn, ), let .0,...,.n+1 \nbe a run of AS for p, let position n be an internal position of p. By induction hypothesis .n . In. Since \n(.n, stn,.n+1) . din, the state .n+1 is in postin(In, stn). The transition relation of AI contains the \ntriple (qn, stn,qn+1). Hence the inclusion postin(In, stn) . In+1 is valid. Thus, .n+1 . In+1 holds. \nThe cases where n is a call position or a return position can be proven analogously. Assume q0,...,qn \nis an accepting run of AI for a nested trace p. Therefore In, the interpolant associated to qn, is the \nfalse predicate ., which is not satis.ed by any valuation. According to the preceding inductive argument \nthere is no run of AS for p, hence p is infeasible. Nested Interpolant Automata from Floyd-Hoare Style \nProofs. Given a Floyd-Hoare style proof of partial correctness for the pro\u00adgram P in the form of a sequence \nof inductive invariant assertions I =(I\u00a3)\u00a3 (the sequence is indexed by the program locations e of P, \nlike in Figure 1), we obtain readily that we can use the control automaton AP as a nested interpolant \nautomaton AI . In fact, the conditions in De.nition 4 translate exactly the inductiveness of the invariant \nassertions in the Floyd-Hoare style proof (as presented, e.g., in [4]). Completeness of Nested Interpolant \nAutomata. We may ask whether the proof rule (1) is still complete if we require that the nested word \nautomaton A used a proof argument must be the complement of a nested interpolant automaton. By the discussion \nabove, we obtain the relative completeness in the same sense as for the Floyd-Hoare proof rule. 5. Interpolant \nAutomata from Proofs p ,qj ) . dre p ) . Ij In this section we will give a constructive proof method \nfor program Each interpolant associated with an initial state is the true correctness. In the .rst step \nof the method, an inductive sequence predicate. of Craig interpolants is generated from an infeasibility \nproof of a init qi . QI . Ii = nested error trace (Section 5.3). In the second step, this sequence \nare embedded in a counterexample-guided abstraction re.nement if sti = and v = y, i or sti = and v \n= resp, scheme (Section 5.5). 8 >>>>>< >>>>>: Before we present the generation of the inductive sequence \nof index(v, i+1)= or i is call position, index(v, k) else if ki (i is return position), index(v, i) else \n(i is internal position). Craig interpolants, we give the de.nition of an inductive sequence of nested \ninterpolants (Section 5.1) and we show how the infeasi\u00ad bility of a nested error trace can be characterized \nas the satis.ability of a formula (Section 5.2). 5.1 Inductive Sequence of Nested Interpolants We generalize \nthe concept of a sequence of interpolants [13] to account for the nesting structure. The key idea is \nthat on a return statement the predicate describing the calling context can be com\u00ad bined with the predicate \nbefore the return statement that captures the post-condition of the procedure. This is a necessary prerequi\u00ad \nsite to obtain predicates that only restrict the variables in the current The function index is de.ned \nrecursively and follows the trace from i backwards to the statement where v is assigned to. The assignment \ncan be either explicitly by an assignment or implicitly, e.g., when a variable is used uninitialized \nin a procedure. If a variable is used without prior initialization it returns the index of the procedures \ncall statement and the index -1 in the case where this procedure is the main procedure of the program. \nThe rules for call, return, and internal positions ensure that the index of the variable renamei(y) is \nin the same procedure as i. To prove the correctness of our interpolation scheme we need the following \nproperties of the calling context. renaming function. De.nition 5 (Inductive Sequence of Nested Interpolants). \nGiven a nested trace Lemma 1. The function index in De.nition 6 for a well-nested p =(st0 . . . stn-1, \n) , an inductive sequence of nested interpolants is a sequence of pred\u00adicates I0,...,In such that I0 \n= ,  In = .,  For i =0,...,n - 1: postin(Ii, sti) . Ii+1 if i is an internal position, postca(Ii, sti) \n. Ii+1 if i is a call position, postre(Ii,Ik, sti) . Ii+1 if i is a return position and ki. Remark. If \na nested trace p has an inductive sequence of nested interpolants, then p must be infeasible. In our \nsetting we are only interested in the case were p is an infeasible nested error trace. In Section 5.3 \nwe explain how an inductive sequence of nested interpolants can be obtained from Craig interpolants in \nthat case.  5.2 Infeasibility Proof for Nested Traces From now on, we assume that the terms in assignment \nstatements and the formulas in assume statements are given in some (.rst-or higher-order) theory with \nequality. For a well-nested trace (p, ) we construct a formula in this theory, called the single static \nassignment (SSA) for the trace, which is unsatis.able if and only if the nested trace is infeasible. \nIf the theory is decidable this allows us to obtain a proof of infea\u00adsibility for (p, ) automatically, \nby deciding satis.ability of the SSA. The single static assignment contains a fresh logical variable \nfor each assignment statement in the trace. This allows us to ex\u00adpress these statements by equalities. \nFor recursive programs the variables of different calling contexts have to be kept separate. We use the \nnesting structure to replace each program variable by the last assigned logical variable that belongs \nto the same procedure. De.nition 6 (SSA). The single static assignment (SSA) for a well\u00adnested trace \np =(st0, . . . , stn-1, ) is the sequence of formulas .0,...,.n-1 where .i is de.ned as y i = renamei(t) \nif sti = renamei(f) if sti = ,  x i = renamei(xp) if sti =  res pi = renamei(res) if sti = . The \nfunction renamei replaces every variable v by vj where j = index(v, i) is the largest index before i \nin the same calling context trace p =(st0 . . . stn-1, ) has the following properties: 1. Every variable \nis assigned before the current position, i.e., index(v, i) <i. 2. If kj, and k<i = j, then k = index(v, \ni), i.e., the variable is assigned inside the current procedure. This also holds for an un.nished call, \ni.e., k 8 and k<i. 3. If kj, and k<j<i, i.e., position i is after the position a procedure returns, \nthen either index(v, i) = j or index(v, i) < k, i.e., the variable was not assigned inside that procedure \ncall. 4. If sti =  then for all j>i: index(y, j)= index(y, i), i.e., later statement will never see \nthe value overwritten by statement i. 5. If sti =  and k is the corresponding call position (i.e. \nki) then index(resp,j)= index(resp,k) for all j>i, i.e., the previous value of the result variable that \nwas overwritten by the return is not visible after the return. Proof. 1. This is easily shown by induction \nover i. 2. Follows by induction and the fact that (a) index(v, k +1) = k and (b) there can be no nesting \nk ' j ' with k ' <k<j ' < i<j due to proper nesting. 3. Follows by induction. For the induction step \nrecall that there is no nesting k ' j ' with k = k ' = j<j ' due to proper nesting. 4. By induction: \nFor j = i +1, we have index(y, i) <i = index(y, j). Now assume the hypothesis for j>i holds. The cases \nindex(y, j +1) = j> index(y, i) and index(y, j +1) = index(y, j)= index(y, i) are obvious. If index(y, \nj +1) = index(y, k) with kj there are two cases. If k>i, then index(y, k)= index(y, i) by induction hypothesis. \nOtherwise, k<i<j, hence index(y, k) <k = index(y, i). Since the trace is well-nested, i must be an internal \nposition, so k = i is not possible. This shows that index(y, j)= index(y, i) for all j>i. 5. This is \nanalogous to 4.  We can check the feasibility of a nested trace by checking the satis.ability of its \nSSA. Theorem 5. Given the SSA .0,...,.n-1 for the well-nested trace p. The trace p is feasible if and \nonly if the conjunction .0 .\u00b7 \u00b7\u00b7. .n-1 is satis.able. Proof. We obtain a run of the data automaton AS \non the trace p from a model M of .0 . \u00b7\u00b7\u00b7 . .n-1 if we set .i(v) to  .0 : x-1 =100 1 .1 : x=x-1 +11 \nm .2 : x2 =x1 m .3 : x2 >100 4 .4 : res=x2-10 .5 : res5 =res4 m .6 : x6 =res5 mm .7 : x7 =x6 m .8 : x7 \n>100 9 .9 : res=x7-10 .10 : res10 =res9 m 11 10 .11 : res=res m 11 .12 : x-1 = 100 . res= 91: after the \nreturn of the procedure would be allowed to appear in the Craig interpolants for the called procedure. \nHowever, this variable is not in the scope of the called procedure and leads to interpolants which are \nnot suitable for a modular analysis. Therefore, we seek Craig interpolants containing only variables \nthat belong to the cur\u00adrent calling context. By moving the instructions of the parent procedure to the \nend of the sequence as in [14], it is possible to obtain interpolants that are local to the current calling \ncontext. We additionally require that the sequence of interpolants is inductive. Therefore, we follow \nthe basic idea of [14] but compute the interpolants from front to back, using the previously computed \ninterpolant as summary that replaces its preceding statements. Instead of conjuncting all preceding statements \nof the parent procedure we use the previously computed interpolant directly preceding the call statement. \nThis algorithm gives us an inductive sequence of nested interpolants. De.nition 7 (Inductive Sequence \nof Nested Craig Interpolants). Given an SSA .0 ...,.n-1 and a nesting relation , an inductive sequence \nof nested Craig interpolants is a sequence .0 ....n, where .0 is .  If .0,...,.i (i .{0,...,n - 1}) \nare given, we obtain .i+1 as follows. We de.ne  ^ 8 >>>< n-1.+ i+1 = .j . (.k . .k), j=i+1 k . j, \nFigure 6. The nested trace p4 (a nested error trace of AP91 ) and k<i+1<j its SSA. =8 which is the conjunction \nof the statements following position i +1 and the pre-conditions of the calls which are pending at M(renamei(v)). \nVice versa, we obtain a model from a run position i +1, and ^ .0,...,.n if we assign to v i the value \n.i+1(v). .i . .i if i is internal position,Example 4. Consider the nested trace p4 in Figure 6 and its \nSSA. .i . .i if i is call position,i 8, -  The nested trace is infeasible, since the conjunction of \nthe formulas . = i+1 if i is call position,i 8, .i . .i . .k . .k if i is return position,k i. >>>: in \nthe SSA is unsatis.able. In fact 76542 1 -1 x = xm = resm = res = x -10 = xm -10 = x +1 = 101 together \nwith x 7 > 100 implies x 7 = 101. This implies 11 10 97 res = resm = res = x - 10 = 91, which contradicts \n.12.  5.3 Inductive Sequence of Nested Craig Interpolants In this section we give a method to generate \nan inductive sequence of nested interpolants. The method is based on Craig interpolants, which can be \ncomputed automatically from unsatis.ability proofs. Craig Interpolant. Given two formulas .- and .+ whose \ncon\u00adjunction is unsatis.able, a Craig interpolant is a formula . such that .- implies ., the conjunction \n. . .+ is unsatis.able, and . contains only variables that occur in both, .- and .+ .  In the remaining \nsection we assume the SSA is given in a theory where each pair of formulas .- and .+ whose conjunction \nis un\u00adsatis.able has a Craig interpolant. The concept of Craig interpola\u00adtion can be lifted to a sequence \nof formulas whose conjunction is unsatis.able [18] and applied to the SSA of an infeasible trace. For \na .at program execution, Craig interpolants derived this way can be used to generate an inductive sequence \nof interpolants. If we apply this method to the SSA of a nested trace, a variable of the parent context \nthat is set before calling a procedure and read Then we obtain .i+1 as a Craig interpolant of .i- +1 \nand .i+ +1. The following lemma is needed for the correctness of the inter\u00adpolation scheme. Lemma 2. \nGiven an infeasible well-nested trace p =(st0 . . . stn-1, ) and its SSA .0,...,.n-1. 1. For i =1,...,n, \nthe conjunction .i - . .i + in De.nition 7 is unsatis.able, and therefore the Craig interpolant exists. \n 2. For i =0,...,n, the interpolant .i contains only the variables renamei(v) for program variables v. \n 3. For i =0,...,n - 1, .i . .i . .i+1 if i is an internal or a call position and .i . .i . .k . .k . \n.i+1 if i is a return positions and ki. 4. .n = ..  Proof. 1. We show this by induction over i. For \ni =1 the conjunc\u00adtion .1 - ..1+ is equal to .0 .\u00b7\u00b7\u00b7..n-1, which is unsatis.able by Theorem 5. For the \ninduction step note that the conjunction .- . .+ has exactly the same conjuncts as .i . .i + . Since \ni+1 i+1 .i was obtained as the Craig interpolant of .i - and .i + (which exists by induction hypothesis), \nthe formula .i . .i + is unsat\u00adis.able. 2. This is also shown by induction. For i =0 this is obvious \nas .0 = . Now assume that .k contains only the variables  renamek(v) for k = i. All variables appearing \nin .i+1 must also appear in .i- +1 and .i+ +1. If sti = y:=t then .i- +1 contains only renamei(v) and \ny i. By de.nition renamei+1(v)= renamei(v) except for v = y. It remains to show that the variable renamei(y) \ndoes not appear V n-1 in .+ . The formula .i contains only renamej (y) for i+1j=i+1 j>i. Lemma 1.4 ensures \nrenamej (y)= renamei(y). The second conjunction of .i+ +1 contains the variables renamek(v), and x k \nfor procedure calls kj with k<i +1 <j< 8. Lemma 1.2 ensures index(v, k) <k = index(y, i), hence renamek(v)= \nrenamei(y). Since the input variable x is never written, x = y. If sti = f , then by the induction hypothesis \nand the de.nition of .i, .i- +1 = .i . .i contains only the variables renamei(v). By de.nition, renamei+1(v)= \nrenamei(v). Thus, .i+1 con\u00adtains only the allowed variables. If sti = call p is an un.nished call statement, \ni.e., i 8, then .i- +1 = .i . .i contains the variables renamei(v) and x i. The formula .i + contains \nonly variables renamej (v) with j>i (due to proper nesting there is no call kj with k<i< j< 8). By Lemma \n1.2 index(v, i) <i = index(v, j), hence renamei(v)= renamej (v). The variable x i = renamei+1(x) is allowed \nto appear in .i+1. If i is a call position with i 8, then .i- +1 = hence .i+1 does not contain any variable. \nIf sti = return p and ki is the corresponding call posi\u00adtion, then .i- +1 = .i . .i . .k . .k contains \nthe variables renamei(v), renamek(v), x k, and respi . It is renamei+1(v)= renamek(v) except for v = \nresp and renamei+1(resp)= respi . It remains to show that renamei(v), renamek(resp), and x k do not appear \nin .+ The formula .+ contains i+1. i+1 k' j ' renamej (v) for j>i, renamek' (v), and x for k ' with k \n' <i<j '. By proper nesting k ' <k holds. For j>i we have index(resp,j)= index(resp,k) by Lemma 1.5 and \nfor k ' <k<j ' Lemma 1.2 gives index(resp,k) = k ' > index(resp,k ' ). Hence renamek(resp) does not appear \nin .i+ +1. The indices of the variables x k and renamei(v) are all be\u00adtween k inclusive and i exclusive. \nFor j>i Lemma 1.3 gives index(v, j) = i or index(v, j) <k and for k ' <k the index of renamek' (v) and \nx k' is smaller than k. Therefore, the variables x k and renamei(v) do not appear in .i+ +1. 3. These \nimplications follow directly from the property .i- +1 . .i+1 of Craig interpolants. 4. Finally, .n = \nn , because .nn is  . follows from .+ = . .+ unsatis.able. We extend the renaming function to valuations \nrenamei(.)= {renamei(v) . .(v) | v is variable}. Since the Craig interpolant .i contains only renamei(v) \nas vari\u00adables, we can associate it with the set of valuations . such that renamei(.) |= .i. Theorem 6. \nGiven a well-nested trace p, its SSA .0,...,.n-1, and its inductive sequence of nested Craig interpolants \n.0,...,.n, the sequence of predicates I0,...,In with Ii = {. | renamei(.) |= .i} for i =0,...,n is an \ninductive sequence of nested interpolants of p. Proof. For brevity, we write .i |= .i for renamei(.i) \n|= .i, which means .i . Ii Similarly, for .i,.j we write .i,.j |= . as short- I0 : T I3 : T  I4 : T \n I9 : x=101 Figure 7. Inductive sequence of nested interpolants I = (I0,...,I13), obtained from the \nCraig interpolants of the SSA in Figure 6. For better legibility the sequences are depicted in an in\u00adterleaved \narrangement. hand for renamei(.i) . renamej (.j ) |= .. This is well-de.ned if .i(v)= .j (v) whenever \nrenamei(v)= renamej (v). sti = y:=t : Given .i+1 . postin(Ii, sti), by de.nition there is .i . Ii (hence \n.i |= .i), such that .i+1 = .i .{y . .i(t)}. Since .i is y i = renamei(t), we get .i,.i+1 |= .i. From \nthe previous lemma we have .i . .i . .i+1, hence .i,.i+1 |= .i+1. The latter formula contains only variables \nrenamei+1(v), hence .i+1 . Ii+1. This shows postin(Ii, sti) . Ii+1. sti = f : Let .i+1 . postin(Ii, \nsti), hence .i+1 . Ii and .i+1 |= f. Since renamei(v)= renamei+1(v) for all variables v and .i is renamei(f), \nthis implies .i+1 |= .i . .i and with the previous lemma .i+1 |= .i+1. Hence, .i+1 . Ii+1.  sti = call \np : Let .i+1 . postca(Ii, sti). By de.nition there is .i . Ii and .i+1(x)= .i(xp). By de.nition of .i, \nthis implies .i,.i+1 |= .i. With .i |= .i and .i . .i . .i+1 this implies .i,.i+1 |= .i+1. Thus, .i+1 \n. .i+1.  sti = return p : Then i is a return position and ki. Let .i+1 . postre(Ii,Ik, sti). Then there \nis .i . Ii, .k . Ik with .i(x)= .k(xp) and .i+1 = .k .{resp = .i(res)}. Since .i is res ip = renamei(res), \nthis implies .i,.i+1 |= .i. Furthermore .i |= .i and .k |= .k and .k,.i |= .k, since .k is x k = renamek(x) \nand renamei(x)= x k. With the previous lemma it follows .k,.i,.i+1 |= .i+1. Hence, .i+1 . Ii+1.   \nFigure 8. Canonical interpolant automaton ApI 4 for the inductive sequence of nested interpolants depicted \nin Figure 7. For better leg\u00adibility we omitted the edges (q8, x>100 ,q4), (q9, res:=x-10 ,q5), ,q6), \nwhich are not needed to prove correctness of P91 . Example 5. Figure 7 shows the sequence of nested interpolants \nfor the nested trace p depicted in Figure 6. The interpolants were computed as Craig interpolants.  \n5.4 Canonical Interpolant Automaton We use an inductive sequence of nested interpolants for a nested \nerror trace p to construct a nested interpolant automaton. The following construction accepts p and other \ntraces that are infeasible for the same reason as p. De.nition 8 (Canonical Interpolant Automaton Ap \nI). Given an in\u00adductive sequence of nested interpolants I = I0,I1,...,In of an infeasible error trace \np =(st0 . . . stn-1, ) along the sequence of locations e0,...,en (the run of the program automaton), \nwe intro\u00adduce pairwise different states q0,...,qn and de.ne the canonical interpolant automaton Ap I \nfor p and I as follows. init.n Ap I = (Q, (din,dca,dre),Q,Q) QI = {q0,...,qn}  din = {(qi, stj ,qj+1) \n| j is an internal position, i, j =0,...,n-1,j = i, ei = ej , postin(Ii, stj ) . Ij+1}dca = {(qi, stj \n,qj+1) | j is a call position,  i, j =0,...,n-1,j = i, ei = ej , postca(Ii, stj ) . Ij+1}dre = {(qi,qk, \nstj ,qj+1) | j is a return position,k j i, j =0,...,n-1,j = i, ei = ej , postre(Ii,Ik, stj ) . Ij+1} \nQinit = {q0} I Q.n = {qn} I I2 : I0 : I1 : I3 : x=101 . T x=101 . res = x-10 any Figure 9. Interpolant \nautomaton ApI 3 that accepts all well-nested traces with the suf.x . . . In combination with the interpolant \nautomata ApI 4 this automaton is suf.cient to prove correctness of the program P91 with our proof rule. \nThe canonical interpolant automaton Ap I accepts the nested er\u00adror trace p. This follows from the de.nition \nof an inductive se\u00adquence of nested interpolants. In general Ap I recognizes an in.nite set of traces. \nIn a sense, Ap I accepts exactly the traces that are in\u00adfeasible for the same reason as p. More precisely, \nin order to prove the infeasibility of a trace accepted by Ap I, we can use the same sequence of nested \ninterpolants (up to repetition of subsequences) as in the proof of infeasibility of p. For j = i the \nconditions in din, dca, and dre hold by De.\u00adnition 5. Thus, after having generated the inductive sequence \nof nested interpolants I (for the proof of the infeasibility of the trace p), one needs additional theorem \nprover calls only for each in\u00adclusion postin(Ii, stj+1) . Ii+1, postca(Ii, stj+1) . Ii+1, resp. postre(Ii,Ik, \nstj+1) . Ii+1 where j<i and ei = ej . Thus, the number of additional theorem prover calls is bounded \nby the num\u00adber of repeated locations in the sequence of locations along the er\u00adror trace p. Example 6. \nFigure 8 shows the canonical interpolant automaton for the trace p in Figure 6 and its inductive sequence \nof nested interpolants in Figure 7. The interpolant automaton is not suf.cient to prove the correct\u00adness \nof the program using proof rule (1). The automaton ApI 4 does not accept the nested error trace p3 from \nFigure 4. Hence, for the complement automaton Ap4 the precondition of proof rule (1) I L(ApI 4 ) nL(AP \n)= \u00d8 does not hold. Figure 9 shows a second interpolant automaton ApI 3 that ac\u00adcepts p3 and infeasible \nnested traces similar to p3. The product automaton of the complemented interpolant automata ApI 4 nApI \n3 still recognizes a superset of feasible traces L(Ap4 nAp3 ) .L(AS). II It can be mechanically checked \nthat L(Ap I nApI 3 ) nL(AP91 )= \u00d8 which proves the correctness of P91 with proof rule (1).  5.5 Counterexample-Guided \nAbstraction Re.nement The example of the last section motivates the iterated re.nement scheme depicted \nin Figure 10, similar to the classical check\u00adanalyze-re.ne loop [5, 10]. We start with a coarse abstraction \nA of the data automaton AS, e.g., the automaton that accepts any nested trace. If the abstraction is \nnot a proof for correctness, it accepts a nested error trace, say p. We check whether p is infeasible. \nIf this is the case, we obtain a nested interpolant automaton AI that accepts p. This automaton can be \nthe canonical interpolant automaton Ap I. We re.ne our  A := An AI and repeat the loop with the new \nabstraction. If we construct a deterministic interpolant automaton AI, com\u00adplementing the automaton boils \ndown to inverting the set of .\u00adnal states. The intersection of the program automaton and the in\u00adterpolant \nautomaton can be computed by unfolding the program automaton, annotating the nodes with the interpolants \nof the in\u00adterpolant automaton and merging nodes with the location and same interpolant. This is essentially \nan extension of the algorithm from [19] to recursive programs. recursive program P P is correct P is \nincorrect 6. Conclusion In this paper, we have explored the potential of the theory of nested words as \na foundation for correctness proofs for the general class of recursive procedures. Our conceptual contribution \nis a simple framework that allows us to shine a new light on classical concepts such as Floyd/Hoare proofs \nand predicate abstraction for recursive programs. Our technical contribution is to give, to our knowledge \nfor the .rst time, a principled method that constructs an abstract proof for recursive programs from \ninterpolants (avoiding the con\u00adstruction of the abstract transformer). We have used nested words to formalize \nthe concept of inductive sequences of interpolants for traces of recursive programs. The construction \nof nested word au\u00adtomata from inductive sequences interpolants is interesting because it avoids the construction \nof the abstract transformer. As pointed out in [19], the interpolation-based proof method can be made \nto scale if one exploits the modular structure of procedural programs (i.e., using procedure summaries). \nOur work provides the foundation to explore different realizations of this approach. Acknowledgments \nWe thank Neil Jones and Domagoj Babi\u00b4 c for comments on the pre\u00adsentation of this paper. This work was \npartly supported in part by the German Research Foundation (DFG) as part of the Transre\u00adgional Collaborative \nResearch Center Automatic Veri.cation and Analysis of Complex Systems (SFB/TR 14 AVACS). References [1] \nR. Alur, K. Etessami, and P. Madhusudan. A temporal logic of nested calls and returns. In TACAS 04, pages \n467 481. Springer, 2004. [2] R. Alur and P. Madhusudan. Adding nesting structure to words. In DLT 06, \npages 1 13. Springer, 2006. [3] R. Alur and P. Madhusudan. Adding nesting structure to words. JACM, 56(3), \n2009. [4] K.-R. Apt, F. de Boer, and E.-R. Olderog. Veri.cation of sequential and concurrent programs. \nThird, extended edition. Springer, 2009. [5] T. Ball and S. K. Rajamani. The SLAM project: debugging \nsystem software via static analysis. In POPL 02, pages 1 3. ACM, 2002. [6] M. Barnett, B.-Y. E. Chang, \nR. DeLine, B. Jacobs, and K. R. M. Leino. Boogie: A modular reusable veri.er for object-oriented programs. \nIn FMCO 05, pages 364 387. Springer, 2005. [7] N. Beckman, A. V. Nori, S. K. Rajamani, and R. J. Simmons. \nProofs from tests. In ISSTA 08, pages 3 14. ACM, 2008. [8] I. Br\u00a8uckner, K. Dr\u00a8ager, B. Finkbeiner, and \nH. Wehrheim. Slicing abstractions. In FSEN 07, pages 17 32. Springer, 2007. [9] S. Chaki, E. M. Clarke, \nA. Groce, S. Jha, and H. Veith. Modular veri.cation of software components in C. IEEE Trans. Software \nEng., 30(6):388 402, 2004. [10] E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith. Counterexample-guided \nabstraction re.nement. In CAV 00, pages 154 169. Springer, 2000. [11] J. Esparza, S. Kiefer, and S. Schwoon. \nAbstraction re.nement with Craig interpolation and symbolic pushdown systems. JSAT, 5:27 56, June 2008. \nSpecial Issue on Constraints to Formal Veri.cation. [12] B. S. Gulavani, S. Chakraborty, A. V. Nori, \nand S. K. Rajamani. Automatically re.ning abstract interpretations. In TACAS 08, pages 443 458. Springer, \n2008. [13] M. Heizmann, J. Hoenicke, and A. Podelski. Re.nement of trace abstraction. In SAS 09, pages \n69 85. Springer, 2009. [14] T. A. Henzinger, R. Jhala, R. Majumdar, and K. L. McMillan. Abstractions \nfrom proofs. In POPL 04, pages 232 244. ACM, 2004. [15] T. A. Henzinger, R. Jhala, R. Majumdar, and G. \nSutre. Lazy abstraction. In POPL 02, pages 58 70. ACM, 2002. [16] F. Ivancic, I. Shlyakhter, A. Gupta, \nand M. K. Ganai. Model checking C programs using F-SOFT. In ICCD 05, pages 297 308. IEEE Computer Society, \n2005. [17] R. Jhala and K. L. McMillan. Interpolant-based transition relation approximation. In CAV 05, \npages 39 51. Springer, 2005. [18] R. Jhala and K. L. McMillan. A practical and complete approach to predicate \nre.nement. In TACAS 06, pages 459 473. Springer, 2006. [19] K. L. McMillan. Lazy abstraction with interpolants. \nIn CAV 06, pages 123 136. Springer, 2006. [20] A. Podelski and A. Rybalchenko. ARMC: The logical choice \nfor software model checking with abstraction re.nement. In PADL 07, pages 245 259. Springer, 2007. [21] \nT. W. Reps, S. Horwitz, and S. Sagiv. Precise interprocedural data.ow analysis via graph reachability. \nIn POPL 95, pages 49 61. ACM, 1995.   \n\t\t\t", "proc_id": "1706299", "abstract": "<p>In this paper, we explore the potential of the theory of nested words for partial correctness proofs of recursive programs. Our conceptual contribution is a simple framework that allows us to shine a new light on classical concepts such as Floyd/Hoare proofs and predicate abstraction in the context of recursive programs. Our technical contribution is an interpolant-based software model checking method for recursive programs. The method avoids the costly construction of the abstract transformer by constructing a nested word automaton from an inductive sequence of `nested interpolants' (i.e., interpolants for a nested word which represents an infeasible error trace).</p>", "authors": [{"name": "Matthias Heizmann", "author_profile_id": "81442617810", "affiliation": "University of Freiburg, Freiburg, Germany", "person_id": "P1911148", "email_address": "", "orcid_id": ""}, {"name": "Jochen Hoenicke", "author_profile_id": "81100629058", "affiliation": "University of Freiburg, Freiburg, Germany", "person_id": "P1911149", "email_address": "", "orcid_id": ""}, {"name": "Andreas Podelski", "author_profile_id": "81100130920", "affiliation": "University of Freiburg, Freiburg, Germany", "person_id": "P1911150", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706353", "year": "2010", "article_id": "1706353", "conference": "POPL", "title": "Nested interpolants", "url": "http://dl.acm.org/citation.cfm?id=1706353"}