{"article_publication_date": "01-17-2010", "fulltext": "\n Dynamically Checking Ownership Policies in Concurrent C/C++ Programs Jean-Phillipe Martin Michael Hicks \n* Manuel Costa Microsoft Research University of Maryland, College Park Microsoft Research jpmartin@microsoft.com \nmwh@cs.umd.edu manuelc@microsoft.com Periklis Akritidis University of Cambridge pa280@cl.cam.ac.uk \n Abstract Concurrent programming errors arise when threads share data in\u00adcorrectly. Programmers often \navoid these errors by using synchro\u00adnization to enforce a simple ownership policy: data is either owned \nexclusively by a thread that can read or write the data, or it is read owned by a set of threads that \ncan read but not write the data. Un\u00adfortunately, incorrect synchronization often fails to enforce these \npolicies and memory errors in languages like C and C++ can vio\u00adlate these policies even when synchronization \nis correct. In this paper, we present a dynamic analysis for checking own\u00adership policies in concurrent \nC and C++ programs despite mem\u00adory errors. The analysis can be used to .nd errors in commodity multi-threaded \nprograms and to prevent attacks that exploit these errors. We require programmers to write ownership \nassertions that describe the sharing policies used by different parts of the program. These policies \nmay change over time, as may the policies means of enforcement, whether it be locks, barriers, thread \njoins, etc. Our compiler inserts checks in the program that signal an error if these policies are violated \nat runtime. We evaluated our tool on several benchmark programs. The run-time overhead was reasonable: \nbe\u00adtween 0 and 49% with an average of 26%. We also found the tool easy to use: the total number of ownership \nassertions is small, and the asserted speci.cation and implementation can be debugged to\u00adgether by running \nthe instrumented program and addressing the er\u00adrors that arise. Our approach enjoys a pleasing modular \nsoundness property: if a thread executes a sequence of statements on variables it owns, the statements \nare serializable within a valid execution, and thus their effects can be reasoned about in isolation \nfrom other threads in the program. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: \nTesting and Debugging Testing tools; F.3.2 [Logics and * Work performed while this author was visiting \nMicrosoft Research, Cam\u00adbridge, and the University of Cambridge Computer Laboratory. Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 10, January 17 23, \n2009, Madrid, Spain. Copyright c &#38;#169; 2010 ACM 978-1-60558-479-9/10/01. . . $10.00 Miguel Castro \nMicrosoft Research mcastro@microsoft.com Meanings of Programs]: Specifying and Verifying and Reasoning \nabout Programs Speci.cation Techniques General Terms Reliability, Security, Theory, Veri.cation. Keywords \nConcurrency, Debugging, Dynamic analysis, Security, Testing, Tools 1. Introduction Concurrent programming \nerrors arise when the executions of two or more threads interfere while operating on the same data. Pro\u00adgrammers \navoid these problems by using synchronization mecha\u00adnisms to enforce a simple policy: a thread may access \na piece of data so long as it owns it. A single thread can own memory exclu\u00adsively, meaning the thread \nmay read and write the data, or many threads can own the data collectively, meaning that all may read \nit, but none may write it. Unfortunately, incorrect synchronization often fails to enforce these ownership \npolicies and memory errors in languages like C and C++ can violate these policies even when synchronization \nis correct. This paper develops a dynamic analysis for checking that mem\u00adory ownership policies are properly \nenforced in multi-threaded C and C++ programs despite memory errors. The analysis can be used to .nd \nunwanted interference during concurrent executions and to prevent attacks that exploit these errors. \nTo use our analy\u00adsis, a programmer adds assertions to indicate the current ownership policy for a piece \nof data. For example, suppose the program uses a shared queue that contains jobs to be processed by worker \nthreads. We might annotate the worker thread code with assertions as 1 struct job *j = dequeue(q); 2 \nownEx(j, sizeof(*j)); 3 /* ... process job, accessing *j freely ... */ 4 relEx(j, sizeof(*j)); 5 enqueue(q,j); \n After extracting the job from the queue, on line 2 the current thread asserts that it owns j s data \nexclusively no other thread should access j s data at this point. After processing the job, the thread \nreleases ownership (line 4) and places the job back in the queue. Another thread may now dequeue the \njob and take ownership of it for further processing. Ownership assertions constitute a speci.cation. \nIt isuptothe programmer to implement this speci.cation. For example, to im\u00adplement the speci.cation above, \nthe programmer must ensure that the queue does not have more than one pointer to the same job and dequeue \nmust use synchronization to ensure that only one thread can extract a particular job. Our dynamic analysis \nchecks that the programmer implements the ownership speci.cation. In particular, given a program containing \nownership assertions, our run-time sys\u00adtem tracks the ownership state of each memory location, and our \ncompiler instruments reads and writes to check whether they re\u00adspect the target data s ownership state. \nFor the example above, the ownEx assertion would change the ownership state of j s data to grant exclusive \nownership to thread t. Thus, the inserted checks would signal an ownership violation if another thread \nattempted to access j s data, e.g., as the result of an error in the queue implemen\u00adtation or a memory \nerror anywhere in the program. We also insert checks to ensure that ownership assertions are themselves \nlegal, e.g., it is a violation for one thread to claim exclusive ownership of a location already owned \nby another thread. We formalize the semantics of ownership checking on multi\u00adthreaded program traces \n(Section 3), and prove that ownership assertions can be used to establish serializability: if a thread \nt successfully acquires ownership of some set of memory locations L, then we can prove that subsequent \noperations on L will appear as if they executed serially, without interleaving by (valid) operations \nof other threads, until ownership is released. Our serializability property is modular in the sense that \nit holds regardless of what other threads do: a properly annotated block will either exhibit a serial \nexecution or the program will fail due to an ownership violation by another thread. Previous work proposes \ntools to check that code properly uses synchronization to implement atomic blocks or lower-level data \nsharing patterns. SharC [2] and its successor Shoal [3] specify shar\u00ading policies by annotating types \nin C/C++ programs, using dynamic casts to change policies. These policies are checked using a combi\u00adnation \nof static and dynamic analysis. They provide weaker guar\u00adantees than our analysis because they fail to \ndetect policy violations due to memory errors. Additionally, they tie ownership policies to speci.c synchronization \nconstructs and impose restrictions on dy\u00adnamic policy changes that can be cumbersome. Our annotations \nare conceptually simpler and more expressive. The number of an\u00adnotations required by our analysis and \nits performance overhead are comparable to those in Shoal. There are also atomicity check\u00ading tools such \nas Velodrome [11] and Atomizer [9] for type safe languages like Java. They provide strong guarantees \nbut can slow down execution by several factors. We have implemented our analysis as a compiler and run-time \nsystem for multi-threaded C and C++ programs (Section 4), extend\u00ading our work on preventing memory errors \n[1]. We evaluated our tool on seven benchmark programs, totaling more than 265 KLOC (Section 5). Our \nexperiments reveal four bene.ts of our system: Expressiveness. We found that ownership assertions were \nex\u00adpressive enough to capture sharing patterns used in practice. No\u00adtably, our benchmarks often employed \ndynamic changes in owner\u00adship, such as the ownership transfer between threads via the shared queue in \nour example. Ease of use. Annotating programs was never burdensome; in the worst case, the added assertions \nand small program changes were 6% of the program size, and they were easy to come by. In total, we annotated \nor changed roughly 500 lines in all benchmarks, con\u00adstituting less than 0.2% of the total program sizes. \nBy default, data is exclusively owned by the thread that allocated it, so executing a program without \nassertions quickly reveals sharing patterns that we can convert into reasonable speci.cations. Low overhead. \nThe overhead of our dynamic analysis is reason\u00adable: programs are slower by 26%, and use 10% more memory, \non average, compared to the original versions. We achieve low over\u00adheads by using ef.cient datastructures \nto perform ownership check-  Figure 1. Core ownership states. ing, by avoiding atomic operations in \nmost ownership checks, and by eliminating redundant ownership checks at compile-time. We prove that these \noptimizations preserve our serializability result. Utility. In testing our benchmark programs, we found \nseveral er\u00adrors, both memory errors and concurrency errors. Our overhead is low enough for some programs \nthat we could imagine deploying these programs with ownership checking enabled, towards improv\u00ading both \nsoftware security and our ability to diagnose concurrency errors in the .eld. 2. Dynamic Ownership Checking \nThis section overviews our dynamic ownership analysis. We de\u00adscribe basic ownership policies, some extensions \nto shorten speci\u00ad.cations and improve performance, and target applications. Basic ownership policies. \nMemory ownership policies place each byte of memory into one of four states, which determine the legal \noperations on that memory, as depicted in Figure 1: in\u00adaccessible; owned exclusively by a single thread \npermitted to read and write it; read-owned by possibly several threads permitted to read it; and not \nowned by any thread. Memory begins as inacces\u00adsible, and then is exclusively owned by the thread that \nallocates it. Exclusive ownership is explicitly released by the relEx asser\u00adtion, which places memory \nin the unowned state. From this state, a thread could either claim exclusive ownership again via ownEx, \nor could claim read-ownership via ownRd. From the read-owned state, other threads may assert read-ownership \nof the same data. Read ownership is released through relRd; when all read-owners have released ownership, \nthe memory returns to the unowned state. Accesses to unowned memory are illegal. Figure 2 shows ownership-annotated \ncode for a FIFO queue based on similar code in the pfscan benchmark. Ignoring the ownership assertions \nfor the moment, we can see the basic code implements a standard thread-shared queue. The Q structure \nstores queued pointers in a .xed-size array accessible from its buf .eld, and synchronizes access to \nthe array using a lock stored in the mtx .eld. The current and maximum size of the queue are stored in \nthe occupied and size .elds, respectively, and nextin records the next free slot in buf. When enqueuing \nan item,the enqueue code .rst checks whether the queue is full (line 23); if so, it waits on condition \nvariable q. less to be signaled by dequeue when an item is removed. The code then stores the item (line \n29), performs some bookkeeping (lines 31 32), and on the last line signals condition variable q. more \nto awaken any threads waiting in dequeue for items to become available. The ownership assertions together \nspecify the high-level policy that only one thread at a time may access the queue. For example, at line \n22 the assertion ownEx(q,DATA SZ) speci.es that at this point, the current thread should have exclusive \nownership over the .rst four .elds of the q structure. Line 28 similarly asserts the current thread exclusively \nowns q. buf. The programmer enforces this policybyusing q. mtx to mediate access to this data: as long \nas all accesses take place with q. mtx held, only one thread will ever access the data at a time. Notice \nthat ownership is released prior  1 2 typedef struct Q {int size, occupied, nextin; 3 void ** buf; \n4 #de.ne DATA SZ o.setof(Q,mtx) 5 Mutex mtx; 6 ConditionVariable less, more; 7 #de.ne SYNC SZ sizeof(Q)-DATA \nSZ 8 9 } Q; 10 11 Q* queueInit(size tn) {Q* ret = malloc(sizeof(Q)); 12 ret. buf = malloc(n*sizeof(void*)); \n13 initQheader(ret, n); 14 relEx(ret, DATA SZ); 15 makeRO(&#38;ret.mtx, SYNC SZ); 16 relEx(ret.buf, n*sizeof( \nvoid*)); 17 return ret; 18 19 } 20 21 void enqueue(Q *q, void *item) {lock(&#38;q. mtx); 22 ownEx(q, \nDATA SZ); 23 24 while (q. occupied = q. size) {relEx(q, DATA SZ); 25 condwait(&#38;q. less, &#38;q. mtx); \n26 ownEx(q, DATA SZ); 27 28 }ownEx(&#38;q.buf[q.nextin], sizeof(void*)); 29 q. buf[q. nextin] = item; \n30 relEx(&#38;q.buf[q.nextin], sizeof(void*)); 31 q. nextin = (q. nextin+1) % q. size; 32 q. occupied++; \n33 relEx(q, DATA SZ); 34 unlock(&#38;q. mtx); 35 signal(&#38;q. more); 36 37 } 38 Q *q; 39 40 main() \n{q = queueInit(20); 41 makeRO(&#38;q, sizeof(q)); ... 42 } Figure 2. Code sample. to releasing the lock \nvia calls to condwait (line 24), and unlock (line 33), and acquired just after acquiring the lock (line \n22) or reacquiring it via condwait (line 26). The objects put in the queue are protected using ownership \nassertions in client code as shown in the Introduction, the client releases ownership before enqueuing \na job, and asserts ownership when dequeuing one. Checking correct enforcement. We would like to check \nwhether a program properly enforces its declared ownership policy. In other words, is it true that under \nall possible executions, when some thread t is executing lines 23, 29, 31, or 32, no thread but t will \naccess q s .rst four .elds or its q. buf array? The dynamic na\u00adture of ownership policies and C s lack \nof memory safety would make it dif.cult to write a static checker that is sound (no missed errors), precise \n(few false alarms), and scalable (works to large pro\u00adgrams). Therefore, we choose to check proper ownership \npolicy enforcement during program execution. Doing so allows our tool to be precise and scalable, though \npotentially missing some latent errors. In our approach, we associate shadow state with the pro\u00adgram \ns run-time memory, and implement ownership assertions to change that state according to Figure 1. We \ncompile the program to insert checks to verify that reads, writes, and ownership transi\u00adtions are legal \naccording to the target memory s ownership state, as shown in the .gure. 1 2 Q* queueInit(size tn) {Q* \nret = malloc(sizeof(Q)); 3 Cluster cluster = allocCluster(); 4 ret. buf = malloc(n*sizeof(void*)); 5 \ninitQheader(ret,n); 6 giveToCluster(ret, DATA SZ, cluster); 7 makeRO(&#38;ret.mtx, SYNC SZ); 8 giveToCluster(ret.buf, \nn*sizeof(void*),cluster); 9 return ret; 10 11 } 12 #de.ne lockCluster(mtx,ptr) lock(mtx);ownClusterEx(ptr) \n13 #de.ne unlockCluster(mtx,ptr) relClusterEx(ptr);unlock(mtx) 14 #de.ne condwaitCluster(cond,mtx,ptr) \n\\ 15 relClusterEx(ptr); condwait(cond,mtx); ownClusterEx(ptr) 16 17 18 void enqueue(Q *q, void *item) \n{lockCluster(&#38;q.mtx,q); 19 20 while (q. occupied = q. size) {condwaitCluster(&#38;q.less, &#38;q.mtx, \nq); 21 22 } ... unlockCluster(&#38;q.mtx,q); ... 23 } Figure 3. Cluster code fragment. Even though \nthe FIFO code snippet reveals no bug, our dynamic checker can reveal problems in other parts of the code \nthat would violate the intended policy. For example, some other thread might access *q without .rst grabbing \nthe queue mutex q. mtx.More perniciously, an out-of-bounds access anywhere in the code might cause some \nother thread to overwrite q or what it points to. In both cases, our inserted checks would signal violations \nof the declared policy; we halt execution at the point of violation, making it easy to .nd the source \nof the problem. As hinted by these examples, and proved in the next section, it turns out that the core \nof the enqueue function enjoys the following pleasingly modular property: either the execution of lines \n26 33 will be serializable in that their effects will be just as if they were executed serially, despite \ninterleaving with other threads or there will be an ownership violation, e.g., because some other thread \nillegally modi.ed the q data structure. A key contribution of our paper is to show how to provide this \nproperty regardless of what other threads do. As we detail in Section 4, we implement several mechanisms \nto prevent threads from bypassing our checks, corrupting heap management, or corrupting the shadow state. \nA nice feature of our system is that ownership assertions are easy to add or debug by simply running \nthe code and addressing the resulting violations. For example, we might have thought that enqueue should \nacquire the entire queue structure exclusively, and not just its .rst four .elds. But on running the \ncode under such a policy, we would discover an ownership violation when a second thread tried to synchronize \non the q. mtx .eld and/or the condi\u00adtion variables. Hence we annotate queueInit to assert these .elds \nare read-only for all threads by adding makeRO(&#38;ret. mtx,SYNC SZ) on line 15. This notational shorthand \nallows each thread to avoid explicitly acquiring read-only ownership of the mutex each time it goes to \nsynchronize on it. We would likewise discover that the global variable q needs to be read-only, e.g., \nto access mtx,and so assert it is read-only on line 41. Finally, we would .nd that some data in the mutex \nstructure pointed to by q. mtx may be read/writ\u00adten by several threads at once, using operations like \ncompare-and\u00adswap to implement the lock s semantics. Therefore we place this data in a special unchecked \nstate (not shown in Figure 1), permitting any thread to read or write it. This state is also useful for \nprogram variables subject to benign races, e.g., performance counters.  1 2 void HandleSession(int \nsocket) {int uid = Authenticate(socket); 3 UserInfo* uinfo = &#38;userTable[uid] 4 ProcessRequests(uinfo, \nsocket); 5 6 } 7 8 ProcessRequests(UserInfo* uinfo, int socket) {// loop processing requests 9 10 while \n(true) switch (command) {... 11 case buy: ... 12 case deleteAccount: 13 // allow uinfo to be reused 14 \nmemset(uinfo, 0, sizeof(UserInfo)); 15 return; 16 ... 17 18 } } Figure 4. An exploitable concurrency \nerror. Clusters. A single ownership assertion like ownEx applies to a contiguous chunk of memory. As \na result, several assertions would be needed to take/release ownership of entire linked data structures, \nwhich is tedious to the programmer and adds run-time overhead. To alleviate these concerns, we extend \nour system with the abstrac\u00adtion of a cluster of memory chunks. Threads can dynamically al\u00adlocate clusters \nand assign chunks of memory they exclusively own to a cluster using the assertion giveToCluster. Having \ndone this, a thread can release or own the entire cluster at once using asser\u00adtions relClusterEx and \nownClusterEx, respectively. Each call takes a pointer as its argument and changes the state of the cluster \nof the pointed-to memory. A memory location can be in at most one clus\u00adter at any one time. (The full \nstate graph, which includes clusters and unchecked states, is shown later in Figure 9.) Figure 3 shows \nwhat some of the queue code would look like us\u00ading clusters and macros. The queueInit function allocates \na cluster for the queue (line 3), then assigns the queue s relevant memory to that cluster (lines 6, \n8). The macros (lines 12 14) simplify annotat\u00ading locks; similar macros can be written for other synchronization \nprimitives. With clusters and macros, the enqueue function is again very simple it now has three total \nassertions that are comingled with the three synchronization calls (lines 18, 20, 22), and does not need \nseparate assertions to take ownership of buf since it belongs to the cluster. Although the example does \nnot show it, it is possible to take read-ownership of clusters. Our experience is that code does not \nrequire many ownership as\u00adsertions. Figure 2 is atypical in this respect: we chose it speci.cally because \nit shows many assertion types. The worst-case benchmark has fewer than 4% of annotation lines, and on \naverage we annotate only 0.1% of the lines. Applications. We envisage several applications for our dynamic \nownership analysis. The most obvious is .nding concurrency and memory errors during development and testing. \nOur analy\u00adsis can also be used during production to diagnose errors in the .eld [13] and to improve security. \nSince our dynamic analysis ensures control-.ow integrity and detects sequential buffer over\u00ad.ows and \nunder.ows [1], it prevents the most common attacks that exploit low level defects in C and C++ programs. \nOur analysis can also prevent some exploits of concurrency errors. For exam\u00adple, consider the code in \nFigure 4, which illustrates a hypothetical session-based commerce server. Each session is handled by \na dif\u00adferent thread but the programmer assumed incorrectly that each user has at most one active session. \nSuppose a user A somehow starts two sessions, each pointing to the same slot in userTable,and one of \nthe sessions deletes the account. If a new user B reuses Domains u, t . Tid x . Var v . Value e . Expr \ns . Heap = Var . Value  Operations a . Operation ::= rd(t, x, v) | wr(t, x, v) | sync(t, op,x,v1...vn) \n| b b . OwnOper ::= ... a . Trace ::= \u00b7| a, a Semantics s -.rd(t,x,v) (Read) s where s(x)= v s -.wr(t,x,v) \n(Write) s[x . v] s -.sync(t,op,x,v1...vn) (Sync) dop,x,t(s, v1...vn) where fop,x,t(s, v1...vn) (Monitor) \ns -.b s [TSTEP] II a f ei -. ei s -.a stid(a)= i s; e1||...ei...||en -.a sI ; e1||...eiI ...||en Figure \n5. Semantics of Multithreaded Programs that slot in the userTable,user A could use its second session \nto buy goods using B s account. Our tool forces the programmer to make all assumptions about sharing \nexplicit. In the example, the programmer would have to assert that uinfo is owned exclusively to allow \nreads and writes during request processing. Therefore, our tool would prevent user A from exploiting \nthis error by signalling a policy violation when the user starts the second session.  3. Formalism This \nsection presents a formalism to describe our dynamic owner\u00adship checking analysis. The presentation proceeds \nin three steps. First, we de.ne a semantics of multi-threaded traces, where a trace is a sequence of \nbasic operations (e.g., reads, writes, and synchro\u00adnization operations) performed by any number of threads, \nand char\u00adacterizes their effect on memory. Second, we de.ne ownership checking as a judgment on traces, \nreferring to this judgment as trace validation. In our implementa\u00adtion, we perform ownership checking \nat run-time, essentially co\u00admingling trace validation with the operational semantics. Formal\u00adizing these \ntwo separately simpli.es the theoretical development. We prove that in valid traces, sequences of operations \nby a single thread on locations owned by that thread can be serialized. Finally, we present an alternative \nrelaxed semantics in which ownership checks are made .rst-class operations that appear in traces, allowing \nthem to be implemented more ef.ciently, and po\u00adtentially optimized away. In the basic semantics, trace \nvalidation views a read (or other operation) as occurring atomically along with the necessary ownership \ncheck. Making the ownership check a sep\u00adarate operation avoids forcing the check and the operation to \nbe per\u00adformed atomically. We prove that when separating the check from all but the operations for acquiring \nownership, the system is sound and complete with respect to the basic semantics, so that once again validity \nimplies serializability. We also prove that many ownership checks can be removed without compromising \ntrace validity. 3.1 Multithreaded program traces The semantics of multithreaded programs is shown in \nFigure 5. It de.nes legal operations a on memory s. We make no distinction between global and local (per-thread) \nmemory, nor do we consider allocating/deallocating memory. Memory is indexed by variables x, which can \nbe viewed as memory addresses. An operation is either a read or write of a value v by a thread t from/to \na variable x,a synchronization operation op by a thread t that may read or write variable x, or an ownership-related \noperation b, the details of which we consider in the next subsection. The semantics de.nes two judgments. \nThe judgment s -.a sI de.nes the effect of operation a on a memory s. Reads and writes on variables have \nthe obvious semantics. The semantics of synchronization operations is parametrized by a predicate f and \na function d, indexed by the operation s details. In particular, thread t may perform synchronization \noperation op involving variable x so long as the heap satis.es the predicate fop,x,t;asa result the heap \nis transformed according to the function dop,x,t.If the operation requires additional parameters, they \nare passed to the function/predicate as needed. As an example, we could model a semaphore x with operations \nseminit, wait and signal, de.ning d and f as follows: fseminit,x,t = .(s, n). true dseminit,x,t = .(s, \nn).s[x . n] fwait,x,t = .s. s(x) > 0 dwait,x,t = .s. s[x . s(x) - 1] fsignal,x,t = .s. true dsignal,x,t \n= .s. s[x . s(x)+ 1] As one can use semaphores to implement mutual exclusion locks, reader/writer locks, \nbarriers, and other synchronization operations, it should be evident that using d and f to model synchronization \noperations is suitably expressive for our purposes. The second judgment s; e1||...ei...||en -.a sI; e1||...eiI \n...||en de.nes the execution of a multi-threaded program where a (non\u00addeterministically chosen) thread \nei takes a step, potentially modi\u00adfying the heap. We do not de.ne individual thread transitions, but \nwrite a f e -. e I to indicate that e transitions to e I, according to the action a. A trace a is a list \nof actions ai, and is termed an execution if it arises from the semantics. De.nition 1 (Execution). Atrace \na = a, a I , ..., a II is an execution ! iff there exists some s, sI, ..., sII such that s -.a sI -.a \n!! sII ... -.a.  3.2 Basic trace validation The formalism de.nes basic operations b for owningmemoryex\u00adclusively \nor for reading-only. Additionally modeling clusters and permanent read-only states would be straightforward. \nOwnership checking is speci.ed as a judgment on traces, ., . f0 a r .I,.I, which we call trace validation,shown \nin Figure 6. (As mentioned earlier, in practice we interleave own\u00adership checking with actual execution.) \nHere, . and .I are write\u00adownership maps (or, simply write maps) from variables x to the thread that owns \nthem for writing. . and .I are read-ownership maps (or, simply read maps) from variables to sets of threads \nthat are allowed to read the variable. If no thread exclusively owns a variable x,we have .(x)= .. Only \nvariables owned by T may be used in synchronization operations. Ownership by T models the unchecked state \ndescribed in the previous section, needed because synchronization operations often fail to obey proper \nownership. Ownership by T is invariant throughout a program execution. We write .S . for a write map \nthat maps all variables to unowned except those in S, which are used for synchronization; we write .. \nwhen the precise de.nition of S is unimportant. We use .\u00d8 to indicate the empty read map, which maps \nall variables to the empty-set \u00d8. In the judgment, . and . represent the maps prior to validat\u00ading trace \na,and .I and .I indicate the state of the maps at the conclusion of validation. Rule [C-Trace] appeals \nto the judgment [C-OWNEX] .(x)= . .(x)= \u00d8 ., . f0 ownEx(t, x) r .[x . t],.[x .{t}] [C-OWNRD] .(x)= . \n., . f0 ownRd(t, x) r ., .[x . .(x) .{t}] [C-RELEX] .(x)= t ., . f0 relEx(t, x) r .[x ..],.[x .\u00d8] [C-RELRD] \nt . .(x) ., . f0 relRd(t, x) r ., .[x . (.(x) \\{t})] [C-READ] t . .(x) ., . f0 rd(t, x, v) r ., . [C-WRITE] \n.(x)= t ., . f0 wr(t, x, v) r ., . [C-SYNC] .(x)= T ., . f0 sync(t, op,x,v1...vn) r ., . [C-TRACE] \nII II IIII ., . f0 a r .,..,.f0 a r .,. ., . f0 a, a r .II,.II where b . OwnOper ::= ownEx(t, x) | ownRd(t, \nx) | relEx(t, x) | relRd(t, x) . . ExclOwnership = Var . (Tid .{T, .}) . . ReadOwnership = Var . 2Tid \n.S . = .x.if x . S then T else . .\u00d8 = .x.\u00d8 Figure 6. Basic trace validation ., . f0 a r .I,.I to validate \nan individual action a,where the maps resulting from validating a arethenusedtovalidatethe remainder \nof the trace a. The rules for validating operations are straightforward, following the transition diagram \nin Figure 1. No\u00adtice that rule [C-OwnEx] checks/modi.es both maps . and .,since exclusive ownership grants \nboth read and write access. One might expect .(x)= {t} as an additional premise of [C-RelEx], and .(x)= \n. as a premise of [C-RelRd], symmetrical to the mod\u00adi.cations to the maps made by [C-OwnEx] and [C-OwnRd], \nre\u00adspectively. Without these checks, a legal trace may perform an ownEx(t, x) followed by relRd(t, x),so \nthat x may only be ac\u00adcessed for writing from then on. While perhaps odd, removing the checks simpli.es \nthe development of relaxed checking in the next subsection, and poses no problems for soundness. Serializability. \nThe mainpropertyweprove is serializability.In particular, by using ownership speci.cations in a particular \nway, a programmer can ensure that, for valid traces, a sequence of thread operations will always execute \nin a manner that is equivalent to one in which the operations occur in sequence. More precisely, a code \nsequence will be serializable if it adheres to a discipline of two-phase ownership, in which all ownEx \n(and ownRd) operations strictly precede relEx (and relRd) operations, with reads/writes on owned data \ninterleaved among them. For example, the code snippet in the introduction trivially follows this discipline, \nas there is a single ownEx followed by some reads/writes and .nally a single relEx. Lines 26 33 in Figure \n2 exhibit two-phase ownership as well, this time starting with two ownEx operations, with reads/writes \ninterleaved between the two .nal relEx operations. We prove serializability using the method of reduction \ndue to Lipton [16]. Reduction is a means of reasoning that two execu\u00adtions a and aI are equivalent, where \naI differs from a in having commuted two different threads events. That two events may be commuted is \njusti.ed by the fact that one is either a left mover or a right mover, de.ned as follows for our setting. \nDe.nition 2 (Right mover). Operation o is a right mover iff for all a, a, b, aI,.,.I,., .I,if a, a, b, \naI is an execution with ., . f0 a, a, b, aI r .I,.I , op(a)= o and tid(a) .= tid(b),then a, b, a, aI \nis also a valid execution with ., . f0 a, b, a, aI r .I,.I. I.e., we can move op. a right in the trace, \nswapping it with b. De.nition 3 (Left mover). A left mover has the same de.nition as a right mover (Def. \n2), replacing the precondition op(a)= o with op(b)= o. I.e., we can move b left in the trace, swapping \nit with a. Given these de.nitions, we can prove that various operations are left movers, right movers, \nor both. Lemma 4 (Movers). 1. ownEx and ownRd operations are right movers. 2. relEx and relRd operations \nare left movers. 3. rd and wr operations are both left and right movers.  The proof of this Lemma is \ngiven in the Appendix. Whether synchronization operations sync(t,op,x,v1...vn) are movers depends on \ntheir semantics. Under a standard multi\u00adthreading semantics, semaphore operations wait and signal are \nright-and left-movers, respectively [16]. Because synchronization operations on variables x require .(x)= \nT,and T-ownership of x must be invariant for an entire trace, commuting synchronization operations with \nother operations has no effect on ownership maps, so wait and signal are right-and left-movers in our \nsetting as well. Many other synchronization operations are also movers; e.g., lock\u00ading a reader/writer \nlock, or a mutex, is right mover, while releasing a lock or mutex is a left mover. With these de.nitions \nin mind, we can de.ne the conditions under which a thread s actions can be serialized. First, we de.ne \nthe notion of a sub-trace: sub(\u00b7,t)= \u00b7 sub((a, aI),t)= a, sub(aI,t) where t = tid(a) sub((a, aI),t)= \nsub(aI,t) . where t = tid(a) With this, we can prove that sub-traces adhering to a certain form are \nserializable:1 Lemma 5 (Serializable sequences). Given an execution a such that ., . f0 a r .I,.I, if \nthe sub-trace sub(a, t) de.nes a sequence of right movers followed by a sequence of left movers, then \nthere exists an execution aI , sub(a, t),aII that is equivalent to a and is valid such that ., . f0 aI \n, sub(a, t),aII r .I,.I . Proof. (Sketch) The equivalent execution can be constructed by re\u00adpeatedly \nmoving t s right-movers to the right in the trace, swapping them with operations of other threads, and \nlikewise moving t s left\u00admovers to the left in the trace, until they both meet in the middle, leaving \nall of t s events serial. 1 We could allow at most one non-mover in between the sequences of right-movers \nand left-movers, but non-movers never arise in valid traces. De.nition 6 (Two-phase ownership). Atrace \na exhibits two-phase ownership if for all a, a I such that a = a0,a,a1,a I,a2 (where ai could be empty), \na = relEx(t, x) or relRd(t, x) for some x implies a I . = ownEx(t, y) or ownRd(t, y) for all y.In other \nwords, no ownership operations may follow release operations by the same thread. Any synchronization \noperations in the trace should be right movers up until no later than the .rst release operation, then \nfollowed by left movers. Theorem 7 (Validity implies serializability). A valid trace a in which thread \nt s events exhibit two-phase ownership implies that t s events are serializable. Proof. This follows \neasily from Lemma 5, since sub(a, t),in being valid and adhering to two-phase ownership, is sure to be \na series of right movers followed by left movers. Our system does not enjoy a strong completeness property. \nFor example, given an execution trace a devoid of any ownership op\u00aderations, we might wish to prove that \nwe can rewrite the trace to an equivalent one exhibiting two-phase ownership if a is serializable (where \nwe consider all of a given thread s events as part of single transaction). But it is easy to see that \nthis is not the case. Consider the following simple trace (where we have used pseudocode rather than \nlower-level events, for clarity): Thread 1 Thread 2 lock(m); tmp=x; y=x; x = tmp+1; unlock (m);  This \ntrace is serializable (e.g., Thread 2 s operation can be moved to the start of the trace), as indeed \nare all possible interleavings of these two transactions. But annotating this code with two-phase ownership \nwould force x to be owned by Thread 1, and therefore signal an ownership violation when Thread 2 accesses \nit. Thus there is a race on x; we conjecture that two-phase ownership is suf.cient to specify serializable \ntransactions that do not contain races. 3.3 Relaxed Validation If we imagine implementing basic validation \nwith an on-line mon\u00aditor, then the rules in Figure 6 imply that ownership checks (the premises of the \nrules) must be performed atomically with an ac\u00adtion, e.g., a read or write. Likewise, ownership acquirement \nand release operations are assumed to check and update the ownership maps atomically. A straightforward \nway to ensure atomicity is to use locking. For example, prior to performing a read of variable x, thread \nt acquires a lock, checks the read ownership map, and then performs the read of x. Implementing ownership \nchecking this way could add signif\u00adicant overhead. While we must still be careful that accesses and modi.cations \nto ownership maps are thread-safe, this subsection shows that we do not need ownership checks to occur \nindivisibly when performed as part of read, write, or release operations. In par\u00adticular, we prove that \nrelaxed trace validation in which ownership checks are proper operations separate from reads, writes, \netc. is sound and complete with respect to basic trace validation. Thus we are able to reduce the overhead \nof performing ownership checking without reducing its utility. Figure 7 depicts the relaxed validation \njudgment. All of the op\u00aderations that we had before are unchanged, but we add separate operations ownWr?(t, \nx) and ownRd?(t, x) for checking that t owns x exclusively (for writing), or for reading, respectively. \nThe relaxed checking semantics permits read, write, sync, and release operations to be validated unconditionally \n(according to rules (CX-Read), (CX-Write), (CX-Sync), (CX-RelEx), and (CX-RelRd)), [CX-READ] [CX-WRITE] \n., . f rd(t, x, v) r .,. .,. f wr(t, x, v) r ., . [CX-RELEX] ., . f relEx(t, x) r .[x ..],.[x . (.(x) \n\\{t})] [CX-RELRD] ., . f relRd(t, x) r ., .[x . (.(x) \\{t})] [CX-SYNC] ., . f0 sync(t, op, x, v1...vn) \nr ., . [CX-OWNEX] .(x)= . .(x)= \u00d8 ., . f ownEx(t, x) r .[x . t],.[x .{t}] [CX-OWNRD] .(x)= . ., . f ownRd(t, \nx) r ., .[x . .(x) .{t}] [CX-CHECKWR] [CX-CHECKRD] .(x)= o t . .(x) ., . f ownWr?(o, x) r ., . ., . \nf ownRd?(t, x) r ., . [CX-TRACE] ., . f a r .I,.I .I,.I f a r .II,.II . f a, a r .II,.II where o . Owners \nb . OwnOper ::= ::= t |T... | ownWr?(o, x) | ownRd?(t, x) Figure 7. Relaxed trace validation but ownEx \nand ownRd events are checked as before, and the sep\u00adarate ownership checks are checked similarly, according \nto (CX-CheckWr) and (CX-CheckRd). In this setting, we are presuming the program has been changed to emit \na separate ownership test prior to each read, write, sync, and release operation, while ownership operations \nremain atomic checking the conditions for allowing ownership and acquirement of ownership happen indivisibly. \nWe formalize this assumption below. Equivalence to basic validation. We can prove that the relaxed validation \nis sound and complete with respect to the basic valida\u00adtion, and as such that validity in the relaxed \nsemantics implies seri\u00adalizability. To establish this requires a means to relate traces in the basic \nand relaxed settings. First we de.ne a way to strip explicit ownership checks for a relaxed-setting trace, \nresulting in a trace that can be subject to basic validation: [\u00b7]= \u00b7 [a, aI]=[aI] where op(a) .{ownWr?, \nownRd?} [a, aI]= a, [aI] otherwise Conversely, we de.ne a way to add explicit ownership checks to a trace \nthat lacks them: (\u00b7) = \u00b7 (a, aI) = ownWr?(tid(a), var(a)),a, (aI) where op(a) .{wr, relEx} (a, aI) = \nownWr?(T, var(a)),a, (aI) where op(a)= sync (a, aI) = ownRd?(tid(a), var(a)),a, (aI) where op(a) .{rd, \nrelRd}(a, aI) = a, (aI) otherwise Finally, we de.ne the well-formedness judgment C fwf a to formalize \nthe requirement that all read, write, release, and sync actions in a are preceded by an ownership check. \nThe rules for this judgment appear in Figure 8. Here, the check map C maps triples (t, x, p) to either \n. or \u00d7, with p .{r, w}. We write C\u00d7 to denote the map which maps all triples to \u00d7.In the rules, C(t, \nx, p)= . implies that thread t has previously checked that it owns x, either for reading if p is r or \nexclusively if p is w. Thus rule [WF-CheckRd] sets C(t, x, r) to . when checking the remainder of the \ntrace upon seeing action ownRd?(t, x), while rules [WF-Rd] and [WF-RelRd] each require that t has previously \nperformed a read check. Though trace well-formedness is super.cially similar to trace validation, we \nemphasize that it only guarantees that a thread t precedes accesses to x with an appropriate check; this \ncheck is by no means guaranteed to succeed. The rules for writes and sync operations are similar to those \nfor reads (cf. rules [WF-CheckWr], [WF-Sync], [WF-Wr] and [WF-Rel]). Rules [WF-Own] and [WF-OwnRd] treat \ntheir respective ownership operations similarly to ownership checks since owner\u00adship checking is part \nof the semantics of ownEx and ownRd (cf. rules [CX-OwnEx] and [CX-OwnRd] in Figure 7). Likewise, oper\u00adations \nrelEx(t, x) and relRd(t, x) invalidate any prior checks made by t for variable x. Optimized checking. \nWhile it is straightforward to see that for all basic traces a that C\u00d7 fwf (a) i.e., that it admits traces \nin which all operations by thread t are preceded by a check in t s sub\u00adtrace the well-formedness judgment \nadmits even more optimized traces. For example, in the trace ownEx(t, x),aI , ownWr?(t, x),aII , wr(t, \nx, v), where no event a in aI or aII has tid(a)= t, we can safely remove the ownWr?(t, x) event from \nthe trace. This is be\u00adcause ownership is invariant once a thread t acquires ownership of some variable \nx, no other thread can change x s ownership to not include (or be) t. This implies that if the ownEx(t, \nx) event in the above trace is valid, then the wr(t, x, v) also will be (assum\u00ading the intervening traces \na, aI are valid as well). We have both C\u00d7 fwf ownEx(t, x),aI , ownWr?(t, x),aII , wr(t, x, v) and C\u00d7 \nfwf ownEx(t, x),aI,aII , wr(t, x, v). The bottom of Figure 8 also de.nes a compatibility judgment between \na check map C and ownership maps . and ., for purposes of establishing proper inductive hypotheses in \nthe proofs. Now we can prove soundness and completeness. Lemma 8 (Soundness). If .; . f a where C fwf \na and .; . f C then .; . f0 [a]. Lemma 9 (Completeness). If .; . f0 a r .I; .I then .; . f (a) r .I; \n.I . The proofs are by straightforward induction on the given deriva\u00adtions. Note that we cannot prove \nthe more symmetric completeness result, i.e., .; . f0 [a] r .I; .I implies .; . f a r .I; .I . As a counterexample, \nfor trace a = ownRd?(t, x), ownEx(t, x), rd(t, x, v) we cannot prove ..; .\u00d8 f a but we can prove ..; \n.\u00d8 f0 [a]. Theorem 10 (Relaxed Validity Implies Serializability). For a relaxed-semantics trace a in \nwhich thread t s events exhibit two\u00adphase ownership, .; . f a and C\u00d7 fwf a implies t s events are serializable. \n 4. Implementation This section describes the implementation of our dynamic own\u00adership analysis. There \nis a runtime library with de.nitions for the ownership assertions and wrappers for library functions, \nand a com\u00adpiler that adds memory access checks to the code. The compiler uses a simple static analysis \nto elide access checks that can be [WF-RD] [WF-WR] C(t, x, r)= . C(t, x, w)= . C fwf aC fwf a C fwf \nrd(t, x, v),a C fwf wr(t, x, v),a [WF-REL] C(t, x, w)= . C[(t, x, w) .\u00d7][(t, x, r) .\u00d7] fwf a C fwf relEx(t, \nx),a [WF-RELRD] C(t, x, r)= . C[(t, x, r) .\u00d7] fwf a C fwf relRd(t, x),a [WF-CHECKWR] [WF-CHECKRD] C[(o, \nx, w) . .] fwf aC[(t, x, r) . .] fwf a C fwf ownWr?(o, x),a C fwf ownRd?(t, x),a [WF-SYNC] C(T,x, w)= \n. C fwf a C fwf sync(t,op,v,x),a [WF-OWN] C[(t, x, w) . .][(t, x, r) . .] fwf a C fwf ownEx(t, x),a [WF-OWNRD] \n[WF-EMPTY] C[(t, x, r) . .] fwf a C fwf \u00b7 C fwf ownRd(t, x),a [WF-COMPATIBILITY] .t,x,o. C(t, x, r)= \n. . t . .(x) . C(o, x, w)= . . o = .(x) .; . f C where p . RWop C . WFmap ::= ::= r | w Owners \u00d7 Var \n\u00d7 RWop .{\u00d7, .} Figure 8. Well-formed, optimized execution traces proven not to fail. We used the Phoenix \nframework [18] to imple\u00adment a compiler for C and C++ programs running on 32-bit x86 processors. We start \nby explaining the access checks and runtime library and then we describe the static analysis. 4.1 Memory \nownership states and data structures Figure 9 shows the full transition diagram for memory ownership \nstates in our implementation, expanding the simpler diagram shown in Figure 1. We record the ownership \nstate of memory using two data structures: the ownership table and the cluster table. The ownership table \nmaintains one byte of state for each eight byte slot in virtual memory. This byte encodes not accessible, \nnot owned, read-only, unchecked, a thread identi.er when the slot is owned exclusively by a thread, or \na cluster identi.er if the slot has been given to a cluster. Thread identi.ers are allocated dynamically \nwhen threads start and are freed when they exit. Cluster identi.ers are allocated and freed dynamically \nfrom the same space. The virtual memory for the ownership table is reserved by our runtime library at \nprogram startup time and we install a page fault handler to allocate physical pages to the table on demand. \nThere\u00adfore, this table introduces a space overhead of approximately 12.5%  while supporting up to 250 \nthreads and clusters. The compiler aligns global and local variables on eight-byte boundaries to en\u00adsure \nthat different variables can have different ownership states (as in [1]). The standard memory allocators \nalso align heap allocations on eight byte boundaries. But if different .elds in the same struc\u00adture can \nhave different ownership states, the programmer must use alignment pragmas to ensure they are in different \nslots. The cluster table records the ownership state for clusters. It has a .xed size of 256 entries \nso that it can be indexed ef.ciently using a cluster identi.er. Each entry has a 4-byte status word and \na bitmap with 256 bits. The status word is null if the cluster is not owned; it records a thread identi.er \nif the cluster is owned exclusively by a thread or records a count of the number of readers (ored with \n0x80000000) if the cluster is owned for reading by a set of threads. The bitmap tracks each thread that \nowns the cluster for reading. The cluster table introduces a .xed space overhead of 9KB. As shown in \nFigure 9, we support setting individual memory slots to the read-only state (which allows any thread \nto read) but we do not support the read-owned state unless a slot is given to a cluster. We made this \ndecision to keep the space overhead low because supporting this state with up to 250 threads for individual \nmemory slots would increase the space overhead from 12.5% to 400%. As mentioned in Section 2, the unchecked \nstate is used to label synchronization variables or data with otherwise benign races: any thread can \nread or write unchecked memory. The read-only and unchecked states are sticky: the state of a memory \nslot cannot change once it is set to read-only or unchecked, which implies the memory cannot be freed \n(which would require moving it to the not-accessible state). Otherwise, accesses through dangling references \ncould allow threads to read or write data owned by other threads, which would violate our modular soundness \nprop\u00aderty. Therefore we do not allow stack variables to be in these states and we delay frees of memory \nin one of these states until the pro\u00adgram terminates. These restrictions may seem overly burdensome but \nthey are easy to overcome using custom allocators for objects with read\u00adonly or unchecked .elds. For \nexample, our implementation will delay freeing a queue from Figure 2 to the global heap because the queue \nhas read-only .elds that point to synchronization objects. But nothing prevents the programmer from writing \na custom al\u00adlocator that implements free by adding freed queues to a list and malloc by reusing a queue \nfrom the list (or allocating a new one if the list is empty). Reusing a queue does not violate the owner\u00adship \npolicy because it requires re-initializing the .elds that are not read-only (size,occupied,nextin,buf) \nbut it does not require changes to the read-only .elds that point to synchronization variables. Since \nwe believe this is a common pattern, we provide a generic imple\u00admentation in our runtime library. The \nprogrammer can create one of these allocators for an object type by specifying a function to al\u00adlocate \nobjects when the list is empty (like queueInit in our example) and a function to reuse objects from the \nlist.  4.2 Compiler The compiler inserts ownership checks before read and write ac\u00adcesses to memory. \nThese checks consult the memory ownership and cluster tables to determine whether to allow the access. \nAs we prove in Section 3.3, a check and the memory access it precedes do not need to happen indivisibly. \nThis allows us to use ef.cient code sequences to implement the checks, which is important be\u00adcause they \nare executed frequently. Figure 10 shows an example code sequence that implements a read check. In this \nexample, the address of the memory about to be read is in the eax register. The sequence starts by loading \nthe state of the slot pointed to by eax from the memory ownership table into al. Then it checks if the \nrun\u00adning thread owns the slot exclusively by comparing the state with the thread s identi.er. The thread \nidenti.er is stored in per-thread memory at thread creation time and is loaded into a stack variable \nat the start of each function. The second check determines if the slot is in the read-only state (encoded \nas 8). If either of these checks succeeds, the read is allowed. Otherwise, the sequence calls the slowPathR \nAL function to check if the slot was given to a cluster the thread owns or is in the unchecked state. \nThis slow path check is also ef.cient: the function expects the ownership state in register al and it \nuses pre-computed information that is stored in per-thread memory to access the bitmap in the cluster \ntable without using other registers. If the slow path fails, we execute the x86 instruction int 3, which \nsignals a failure by triggering a breakpoint; otherwise, we al\u00adlow the read. The other code sequences \nare similar. All are short, use a single register, and are inserted in an early compilation phase within \nPhoenix to expose them to further optimizations. 1 shr eax,3 2 movzx eax,byte ptr [eax+40000000h] 3 cmp \nal,byte ptr [esp+4Ch] 4 je L1 5 cmp al,8 6 je L1 7 call slowPathR AL 8 L1: Figure 10. Code sequence that \nimplements ownRd?.   In addition to ownership checks, the compiler inserts code to update the memory \nownership table on function entry to grant ex\u00adclusive ownership of arguments and local variables to the \nrunning thread. The function epilogues are modi.ed to revert this memory to the not-accessible state \nafter checking that it is owned exclu\u00adsively by the running thread. These checks prevent deallocation \nof memory that may be in use by other threads. We remove most of these checks with a simple static analysis \n(Section 4.4). We implement control-.ow integrity as in [5] to prevent mem\u00adory errors from bypassing \nour checks. We assign a special own\u00adership value to the start of functions whose address is taken, and \nuse a check similar to the one in Figure 10 to ensure that indirect calls only target these functions. \nWe prevent errors from subverting other indirect control .ow transfers by ensuring that the memory locations \nwith their targets are always in the not-accessible state; for example, return addresses are always in \nthe not accessible state. The compiler also inserts guard objects adjacent to global vari\u00adables and those \nlocal variables whose address is taken (as in [1]). These guard objects are always in the not-accessible \nstate. While guard objects are not strictly necessary, with them we can ef.\u00adciently detect sequential \nbuffer over.ows and under.ows, which are a common exploitable error.  4.3 Runtime library The runtime \nlibrary implements the ownership assertions and wrap\u00adpers for library functions. The ownership assertions \nare listed next to the edges in Figure 9 and they can only be called in the states shown in the .gure. \nThe implementation of these functions is straightforward: they .rst check that the memory or cluster \nthey receive as an argument is in the appropriate state and then they modify the state in the memory \nor ownership table according to the .gure. As we prove in Section 3.3, the check and modi.ca\u00adtion do \nnot need to be atomic except for ownEx, ownClusterEx,and ownClusterRd. We implement ownEx by performing \na sequence of atomic cmpxchg instructions on the affected ownership table entries. As an optimization, \nour implementation performs cmpxchg on four en\u00adtries at a time when possible. If any of the cmpxchg instructions \nfails to update the table because the state is no longer unowned, the function triggers a breakpoint. \nownClusterEx uses cmpxchg on the cluster status to set it to the thread identi.er. ownClusterRd uses \ncmpxchg to increment the count of readers in the cluster sta\u00adtus and an atomic bit manipulation instruction \n(btc) to update the cluster s bitmap (relClusterRd is implemented in a similar way be\u00adcause several threads \ncan acquire and release the cluster for reading concurrently). We de.ne wrappers for common library functions \nand system calls. These wrappers perform ownership checks on the memory that is accessed by the functions \nthey wrap. For example, the wrap\u00adper for memcpy checks that the source buffer is readable and that the \ndestination buffer is writable. The compiler replaces direct and indirect calls to the original functions \nwith calls to the wrappers. The wrappers for malloc and free are the most interesting. The wrapper for \nmalloc sets the ownership table entries for the allocated memory to the identi.er of the calling thread. \nIn addition, it sets the entry corresponding to the allocator metadata to a special heap guard state. \nThis state is used to prevent freeing of pointers to non-heap memory or to the middle of heap allocations. \nThreads executing instrumented code cannot read or write memory in the heap guard state. Therefore, this \nalso prevents sequential buffer over.ows and under.ows that cross heap allocation boundaries. The wrapper \nfor free checks that the slot before the memory being freed is in the heap guard state and that the memory \nbeing freed is owned exclusively by the calling thread. Frees of memory blocks that contain slots in \nthe read-only or unchecked states are delayed until the end of the execution. Attempts to free memory \nin other states raise an error. This implementation ensures that incorrect heap management cannot violate \nthe ownership policies. To prevent delaying frees from causing unbounded memory leaks, we enforce the \nfollowing restriction: after free is called on memory in the read-only or unchecked state, calls to makeRO \nor makeUnchecked signal an error. 4.4 Static Analysis As discussed in Section 3.3, it is not necessary \nto insert ownership checks before every memory access because ownership is invari\u00adant: once memory becomes \nowned by a thread t, no other thread can revoke that ownership. Similarly, memory in the read-only or \nunchecked states can never be made otherwise. As such, if an ac\u00adcess to location x is preceded by an \nacquirement or check of the needed ownership of x, and there is no intervening release, we can elide \nthe check. We use static analysis to elide these checks. The basic idea is to use an intraprocedural \ndata.ow analysis to compute the set of memory locations that must be owned exclu\u00adsively, or for reading \nonly, by the current thread at a given program point. Reads or writes to locations that are covered by \nthese known\u00adexclusive sets, or reads covered by the known-readable sets, do not require any checks. Ignoring \nthe effects of function calls for the mo\u00adment, locations are added to the known-exclusive set (gen) for \neach ownEx, ownClusterEx, and write, and they are removed (kill) for each free, relEx, relClusterEx,and \ngiveToCluster. Gen and kill func\u00adtions for the known-readable set are similar, and in both cases sets \nare intersected at joins in the control-.ow graph. We also allow the programmer to write assertOwnedEx \nand assertOwnedRd to force checks on particular memory locations, which add locations to the known-exclusive \nand known-readable sets, respectively. These as\u00adsertions can help reduce the total number of checks by \neffectively hoisting checks above complicated control .ow that might other\u00adwise foil the check-elimination \nanalysis. There are two further complications in the analysis. First, build\u00ading the sets above requires \nmemory locations to be unambiguously identi.ed when adding them to the set, which is complicated by aliasing \nand pointer arithmetic. Second, we must account for the possible effects on the ownership state of intervening \nfunction calls. We handle these issues fairly simply, to avoid an expensive whole\u00adprogram analysis. For \nthe .rst case we also run a variant of the analysis that keeps track not of sets of memory locations, \nbut of sets of symbolic (pointer,length) pairs. The intuition is that if we insert a check for a write \nto *p, we may be able to elide the check for a second write through the same pointer. We must however \nbe careful that what p points to did not change in between the two calls. To ensure this, the kill function \nwill remove a pair if the location of either symbol leaves the known-exclusive set or when a write may \noverlap with the location holding the symbol itself. We can elide checks from reads or writes through \na pointer+offset as long as the pointer isinthe setand 0=offset<length. Both offset and length may be \nsymbolic expressions: we use a simple symbolic evaluation to determine, for example, that symbolic offset \nn is less than symbolic length n +1, if we know that n +1 is not an over.ow. There is a similar analysis \nfor eliding read checks. To avoid the pessimistic assumption that a function could re\u00adlease ownership \nof any memory location, we perform a simple bottom-up interprocedural analysis to summarize the release\u00adbehavior \nof each function, tracking the set of locations that may be released from exclusive (or freed) and the \nset of locations that may be released from read. Thus, when the intraprocedural anal\u00adysis encounters \na call to a function, it uses the summary to adjust the known-readable and known-exclusive sets appropriately. \nWe do not summarize the acquire-behavior of functions, though we could do so to improve precision.  \n 5. Evaluation We used seven C and C++ programs to evaluate our dynamic own\u00adership checking tool. We \nstarted by annotating the programs with ownership policies and assessing the required changes. Then we \nran experiments to measure the time and space overheads intro\u00adduced by our tool. This section presents \nour results and discusses several concurrency and memory errors that we found. 5.1 Programs, annotations, \nand bugs We annotated seven multi-threaded programs: pfscan, aget, pbzip2, stunnel, genome, ctrace, and \nnullhttpd. We chose the .rst four pro\u00adgrams to facilitate a comparison with SharC [2]. These four pro\u00adgrams \nsynchronize threads using mutexes, condition variables, and thread joins. We also chose programs that \nuse different synchro\u00adnization primitives to demonstrate the generality of our ownership assertions: \ngenome, taken from the STAMP benchmark suite [4], uses barriers and ctrace uses semaphores. The nullhttpd \nWeb server lines changes annotations aget 1098 6 0.55% 11 1.00% ctrace 1408 8 0.57% 33 2.34% genome 9645 \n56 0.58% 63 0.65% nullhttpd 3030 3 0.00% 10 0.33% pbzip2 15188 21 0.14% 81 0.53% pfscan 1073 22 2.05% \n40 3.73% stunnel 235366 94 0.04% 14 0.01% total 266808 210 0.08% 252 0.09% Table 1. Change and annotation \ncounts. is known to be buggy. We chose nullhttpd to evaluate our tool s ability to .nd bugs. We annotated \nthe programs using the following methodology. First, we ran the programs with no annotations using our \ntool. Since the default ownership policy prevents sharing, the tool signaled an error whenever a variable \nwas shared in one of these executions. Then we inspected the source code to understand how these vari\u00adables \nshould be shared and we inserted annotations to enforce the appropriate ownership policy. We repeated \nthis process with dif\u00adferent test inputs until the tool stopped signaling errors. In several cases, we \ninserted annotations right next to matching comments in the code but our analysis showed that some of \nthese comments were wrong. Concurrent programs are subtle and specifying and enforcing the right ownership \npolicy without the support of a tool like ours can be tricky. We found that our incremental methodol\u00adogy \nworks well: it allows programmers to debug the program and ownership policies together. Table 1 tabulates \nthe total lines of code we changed or annotated for each program. Since we maintain ownership state for \neight-byte memory slots, a common change was the addition of alignment pragmas to structure de.nitions \nto ensure that different .elds are in different slots. These pragmas are only needed if different .elds \nin the same structure can have different ownership states. The annotation count is small compared with \nthe size of the annotated programs. In the worst case, we changed 6% of the lines in a benchmark but \nwe changed less than 0.2% of the lines in total. SharC [2] has lower annotation counts in the .rst four \nbenchmarks but it provides weaker guarantees; in particular, it will fail to catch problems due to memory \nsafety violations. We obtained versions of aget, pbzip2, and pfscan with both SharC and Deputy [7] annotations \nfrom the authors of SharC. We found that adding Deputy [7] annotations to achieve spatial memory safety \nincreases their annotation counts to be greater than ours on average. We found eight bugs in the benchmark \nprograms using our tool: three serious races and .ve buffer under.ows. Next, we describe the benchmarks, \nthe annotations, and the bugs in more detail. The pfscan program searches for strings in .les. The main \nthread .nds the paths of all .les that need to be searched and inserts them in a queue. Worker threads \nloop taking a path from the queue and searching the corresponding .le. This queue is very similar to \nthe one in Figures 2 and 3, and requires similar annotations. In addition, the main thread uses a shared \nvariable protected by a mutex to synchronize with the workers on completion. We inserted ownEx annotations \nfor this variable after the mutex is acquired and relEx before it is released. The rest of the annotations \nare for variables that are initialized by the main thread and are read-only for the rest of the execution. \nWe inserted makeRO annotations for these variables right after their initialization. Aget parallelizes \n.le downloads. The main thread obtains the size of the .le and initializes an array with structures describing \ndisjoint byte ranges. Then it forks a worker thread to download each range and waits to join them. We \ninserted a relEx annotation for the structure describing the range before each fork and a corresponding \nownEx annotation after each join. We also added a ownEx annota\u00adtion for the structure at the start of \nthe worker routine and a cor\u00adresponding relEx annotation at the end. These annotations acquire and release \nownership of all the .elds in the structure except for the .eld with the thread identi.er. This .eld \nis owned exclusively by the main thread throughout the execution to allow its use as an ar\u00adgument to \nthe join. Our tool found a benign race on a variable used to print a progress bar. We added an annotation \nmakeUnchecked to make this variable unchecked. Our tool found a buffer under.ow in aget that can cause \nthe program to read a byte before the start of a string. Pbzip2 is a parallel implementation of the \nbzip2 compression algorithm. A producer thread reads blocks from a .le and places a structure describing \neach block in a queue. Several consumer threads take blocks from the queue and compress (or decompress) \nthem. The consumers put compressed (or decompressed) blocks in an array that is protected by a mutex. \nA writer thread scans this array and writes the blocks to disk. The annotations that we inserted for \nthe queue and the shared array are similar to those in pfscan. Additionally, we inserted annotations \nto mark variables read-only and to mark a variable with a benign race unchecked. The stunnel program \nprovides a tunneling service for TCP over SSL. The main thread accepts connections in a loop and forks \na client thread to manage each connection. Most of the data is shared read-only between threads or is \nthread private. We inserted makeRO annotations to mark this data read-only after initialization and our \ndefault annotations were suf.cient for thread private data. Stunnel uses the OpenSSL library to perform \nencryption. We also instrumented this library. The genome benchmark program takes a large number of DNA \nsegments and matches them to reconstruct the original source genome [4]. We modi.ed the original benchmark, \nwritten to use software transactional memory, to use locks instead. The algorithm runs in several phases \nwith barriers between them. The .rst phase uses a hash set to create a set of unique segments from the \ninitial segment pool. We associate a cluster with the hash set. We insert a single ownClusterEx before \nupdating the hash set and a matching relClusterEx after. After the barrier at the end of the .rst phase, \nwe insert an ownClusterRd for the cluster because the hash set is read-only for the rest of the execution. \nThis is another example of dynamic change in ownership policy. In the second phase of the algorithm, \nthreads match unique segments using shared arrays and hash tables. The third phase computes the .nal \nsequence. The an\u00adnotations that we inserted in the code for these phases resemble ones already described. \nThe ctrace library provides tracing functionality for multi\u00adthreaded programs. The key data structure \nis a hash table with per-thread information. The hash table is protected with a read\u00adwrite lock implemented \nusing semaphores. We associated a cluster with the hash table and we inserted annotations in the read-write \nlock implementation to take and release exclusive or read own\u00adership of the cluster as appropriate. We \nused the makeUnchecked annotation to deal with several benign races. The nullhttpd Web server has a concurrency \npattern similar to the one in stunnel: the main thread accepts connections in a loop and forks a client \nthread to handle each connection. There is an array of per-connection data structures. Client threads \nreceive a pointer to one of these entries initialized by the main thread and they mark this entry as \nnot in use when they exit. The main thread scans this array looking for free entries. Client threads \nexit when their connection is closed or is idle for more than a timeout. The annotations we inserted \nin this program are similar to those used in aget except that we marked one of the .elds in each connection \ndata structure unchecked because it has a benign race. Our tool found three serious concurrency bugs \nin nullhttpd. The .rst is a race on a handle .eld in the per-connection data structure. The main thread \ninitializes a thread handle .eld in this structure after it creates a thread. A client thread may close \nan invalid handle if it accesses this .eld before it is initialized by the main thread. The second bug \nis a race on the per-connection data structure that can lead to a double free. Before exiting, a client \nthread frees data pointed to by its connection data structure and uses memset both to zero the pointers \nto the freed data and to signal main that the data structure is no longer in use. This can cause the \nmain thread to free the data again if it reuses the data structure before the pointers are zeroed by \nthe client thread. The last bug is a race on a static variable used to implement a readdir-like function \nin the Windows version of nullhttpd. The tool also found four buffer under.ows in nullhttpd that can \ncause the program to write data to bytes before the beginning of a buffer. We found the bugs described \nin this section by running the benchmarks in the next section and simple tests to increase code coverage. \nIt was not necessary to explore different thread sched\u00adules to uncover these bugs. Dynamic ownership \nanalysis can sig\u00adni.cantly increase the set of schedules that uncover a bug. For example, our analysis \nuncovers the last bug we described in any execution where a thread other than main accesses the static \nvari\u00adable. Without our analysis, the bug has no adverse effects unless two threads use the readdir-like \nfunction concurrently. We would likely .nd more bugs by combining dynamic ownership analysis with tools \nlike Chess [17] that explore different thread schedules systematically. 5.2 Performance measurements \nWe also measured the overhead introduced by our tool. We com\u00adpiled the benchmarks with and without dynamic \nownership anal\u00adysis. We used the Phoenix [18] compiler with the -O2 (maxi\u00admize speed) option in both \ncases. Phoenix is a production-quality compiler for example, it achieves SPEC Int 2000 performance within \n10% of the C/C++ compiler shipped with Microsoft Vi\u00adsual Studio. Then we ran experiments comparing the \nelapsed time, throughput, and memory usage of the two versions. Memory usage is the peak working set \nsize as reported by the Windows PSAPI interface. We averaged the elapsed time, throughput, and memory \nusage across at least 10 runs of each experiment. The standard de\u00adviation was below 3% of the computed \naverage in all experiments. We report the percent increase in average elapsed time and memory usage and \nthe percent decrease in average throughput. All the experiments ran on HP xw4600 workstations with an \nIntel Core2 Duo CPU at 2.66 GHz and 4GB of RAM, running the Windows Vista Enterprise SP1 operating system. \nThe workstations were connected with a Buffalo LSW100 100 Mbps switching hub for the experiments involving \nthe network. The experiments used to evaluate the .rst four programs attempt to reproduce the experiments \ndescribed in [2]. To evaluate pfscan, we searched for the string HELLO in three copies of the PDF .les \nfrom the proceedings of DSN 2005, 2007 and 2008. We elim\u00adinated I/O overhead by ensuring that the .les \n.t in the operating system buffer cache and by warming up the cache before the ex\u00adperiment. We used aget \nto fetch a compressed .le with 182MB from an idle Microsoft IIS server connected to the hub. The ex\u00adperiment \nto evaluate pbzip2 compressed a 4MB .le. We evaluated stunnel by encrypting three connections to a simple \necho server and measuring the time to send and receive 10,000 messages. We ran the genome benchmark with \ng=16E3, n=16E6, s=32 and t=2 and we ran the simple benchmark in the ctrace distribution with two threads \nthat write 500000 messages to a trace .le. We measured the throughput of nullhttpd with the default con.guration \n(which lim\u00adits the maximum number of simultaneous connections to 50) using time space aget 0.0% 0.0% \nctrace 27.0% 6.5% genome 44.2% 12.5% nullhttpd 0.0% 10.4% pbzip2 49.0% 18.6% pfscan 37.2% 14.0% stunnel \n20.8% 8.7% average 25.8% 10.4% Table 2. Overhead in time and space. the apache benchmark. We increased \nthe number of simultaneous clients until the throughput stopped increasing. The results reported were \nobtained with 30 simultaneous clients fetching a small Web page 10,000 times. The middle column of Table \n2 shows the percentage increase in elapsed time due to our dynamic ownership analysis (for nullhttpd \nit shows the percentage decrease in thoughput). The average over\u00adhead across all benchmarks is 26%. For \nmemory intensive bench\u00admarks like pbzip2, the overhead can be as high as 49%, which is probably too high \nfor our tool to be used during production but low enough for use during testing. The overhead is negligible \nfor nullhttpd and aget. To investigate why, we measured the increase in CPU time due to our instrumenta\u00adtion \nin aget and nullhttpd. We used the GetSystemTimes function in Windows to measure the CPU time. We found \nthat our instrumen\u00adtation does not measurably increase the CPU time for aget because most of the CPU \ntime is consumed executing operating system code that we wrap but do not instrument. Our instrumentation \nincreases the CPU time for nullhttpd by 24%. We believe that these over\u00adheads are suf.ciently low for \nour tool to be used during production to improve security and diagnosability of concurrency errors. The \nrightmost column of Table 2 shows the memory overhead incurred by the various benchmarks. Since we have \none byte in the ownership table for each eight byte memory slot, we would expect the space overhead introduced \nby our technique to be around 12.5%. The average space overhead across all the benchmarks is 10%. Values \nbelow the expected 12.5% are due to memory that is touched in libraries that we do not instrument and \nvalues above are due to updating ownership table entries for memory that is allocated but never touched \nin the benchmark (the operating system faults pages on demand for large allocations). The time overhead \nof Shoal [3], the new version of SharC that improves expressiveness, seems to be similar to ours but \nAnderson et al. reported lower time overhead for pfscan, pbzip2, and stunnel using SharC [2]. Both Shoal \nand SharC provide weaker guarantees than our dynamic ownership analysis. In particular, they do not enforce \nsharing annotations in the presence of memory errors. Most of our overhead in these benchmarks is due \nto the checks to prevent ownership policy violations due to memory errors. Our static analysis can frequently \nprove that the target object for an access is owned without being able to prove that the access is within \nbounds. We believe that a more sophisticated static analysis would be able to close the performance gap. \nThe space overhead of our technique is lower than SharC s on average despite the fact that we support \nup to 250 threads whereas SharC only supports up to seven to keep the space overhead low.  6. Related \nWork Many static and dynamic analyses have been developed to detect concurrency-related problems. Static \nanalyses, e.g., for ensuring race-freedom [19] or atomicity [12], have the advantage that they cover \npotentially all program executions, but the disadvantage that they often have many false alarms or fail \nto scale. Dynamic analy\u00adses such as ours have the opposite properties. The coverage prob\u00adlem can be mitigated \nby employing active testing tools, such as Cal-Fuzzer [15], or employing hybrid static/dynamic analysis \n[6]. For brevity, we focus predominantly on dynamic analyses, organized according to the concurrency \nproblem detected. Data races are a well-known class of error in which two threads access the same memory \nlocation without using appropriate syn\u00adchronization, and at least one access is a write. Many dynamic \nanalyses for detecting races have been developed, from imprecise lockset-based detectors such as Eraser \n[21], which work by ensur\u00ading that a shared location is always accessed with a particular lock held, \nto precise detectors such as Goldilocks [8] and FastTrack [10], that track some form of happens-before \nrelation. We could imple\u00adment a dynamic data race detector with our system by wrapping every read and \nwrite with ownership assertions for reading and ex\u00adclusive access, respectively. Though useful, the lack \nof data races is not suf.cient to ensure correctness. Protecting each individual ac\u00adcess by a lock, for \nexample, trivially makes any program data race\u00adfree, but concurrency errors would remain. Moreover, data \nraces are not always problematic; programs often exhibit so-called be\u00adnign races. On the other hand, \ndata race detection tools are easy to use, requiring no direct input from the programmer. Atomicity violations \nare a better indicator of concurrency errors. Using a tool such as Velodrome [11], Wang et al. [22], \nor the Atomizer [9], a programmer may specify whether a method or code block should execute atomically, \nand the tool veri.es that it does so. Velodrome is both sound and complete: atomicity violations occurring \nwithin a given execution are precisely .agged; Wang et al. is similarly very accurate. Atomizer is nearly \nsound (it admits some data races), and is incomplete in that some atomic executions are erroneously .agged; \nsimplistically, this can be explained by the fact that some serializable executions may have data races. \nWhen used to enforce serializability, our system is sound (see Theorem 10), but is similarly incomplete. \nAtomizer is also limited in that it is lockset-based, whereas our approach is indifferent to the synchronization \nstrategy used in the program. On the other hand, atomicity speci.cations are higher-level than our ownership \nassertions, and therefore may be easier to use. Sharing violations. Our tool is one of several that consider \nen\u00adforcement of data-centric sharing policies, which in some cases may imply properties like atomicity. \nUsing SharC [2] and its successor Shoal [3], programmers an\u00adnotate standard types with one of .ve sharing \nquali.ers.For ex\u00adample, the quali.er private designates thread-local data, readonly indicates shared \nbut read-only data, and locked(m) indicates shared data accessible only when lock m is held. Programmers \ncan switch the sharing strategy using a sharing cast to assign data a differ\u00adent quali.er. This cast \nsucceeds if the source pointer is unique,a restriction enforced by reference counting. Compared to SharC, \nour speci.cations are conceptually sim\u00adpler: to read or write a location, a thread asserts ownership \nof that location for reading or writing, respectively the synchronization strategy is immaterial. Our \nsimpler speci.cations also come with fewer restrictions: SharC and Shoal require some contortions to \nsatisfy the unique pointer constraint and thus change the sharing strategy. In contrast, our ownership \npolicies may be changed freely, as may be the means employed by the program to enforce them. On the other \nhand, SharC s higher-level speci.cations are more terse, leading to fewer annotations. SharC uses whole-program \nanalysis to provide some compile-time guarantees, e.g., that data declared private is never accessed \nby multiple threads. As such, it relies on static analysis for soundness: if the analysis is too conservative \nand rejects a correct program, it would have to be modi.ed before it can be run at all. In contrast, \nconservative analysis in our system can only lead to missed optimization opportunities. SharC does not \ninclude the memory-safety checks needed for soundness. In our ex\u00adperience, these checks add overhead \nand remove optimization op\u00adportunities; one of the SharC authors suggested to us that combin\u00ading SharC \nwith Deputy to provide similar assurances could bring overheads closer to 2x. This combination would \nalso increase the number of annotations to be greater than ours in the benchmarks we used in common. \n Isolator [20] dynamically enforces a programmer-speci.ed locking discipline, which states that a particular \nlock must be held to access particular shared data. Threads that adhere to this disci\u00adpline are protected \nfrom interference by ill-behaved threads; this is similar to how data owned by a thread in our approach \nis protected from interference by other threads. Our approach is more general in not being tied to lock-based \nsynchronization, though it is possible that our speci.cations are more verbose as a result. Finally, \nHammer et al. [14] use a dynamic tool to enforce atomicity-set serializability, a more inclusive property \nthan tra\u00additional serializability. The idea is that certain data belong to an atomic set and should be \nupdated atomically by designated units of work (UoW). As one UoW may invoke other UoWs during process\u00ading, \nit may be spuriously considered non-serializable, even though the nested UoWs are effectively independent. \nWe conjecture we could enforce atomic-set serializability by asserting ownership of the appropriate atomic \nsets at the outset of a UoW, releasing own\u00adership at its conclusion. Hammer at al. have found that atomic \nsets and units of work can be inferred effectively from the structure of class declarations, and we suspect \nthat ownership annotations could be similarly inferred from class structure; writing ownership assertions \nby hand would be more verbose. All these tools either provide weaker guarantees than ours, have higher \noverhead, or both. FastTrack s slowdown ranged from 0.9x to 14.8x for the benchmarks they considered; \nGoldilocks was up to 11.4x given integrated VM support. Velodrome s slowdown is be\u00adtween 1.1x and 70x, \nand Atomizer s up to 48x, with Wang et al. re\u00adporting similar overhead. SharC s overhead is no higher \nthan 14%, whereas Shoal s was up to 42%; SharC exhibited lower overhead than our system in three out \nof the four benchmarks in common. On the other hand, SharC is unsound in the presence of memory errors, \nand deals awkwardly with changes in ownership due to its unique pointer restriction (though this can \nbe worked around at some ad\u00additional performance cost). Isolator has a low overhead (their worst case \nis a microbenchmark with only 20% slowdown) but it is also unsound in the presence of memory errors and \nsharing policies can\u00adnot change. Hammer et al. s tool has a slowdown factor between 1.3x and 45x depending \non the benchmark.  7. Conclusions Concurrency and memory errors are hard to debug and they can be exploited \nby attackers. We presented a dynamic analysis tool for C/C++ programs that can .nd these errors and prevent \nattackers from exploiting them. Programmers declare an ownership policy by annotating their code with \nsimple assertions and our tool inserts access checks that detect policy violations at runtime. We proved \na modular serializability property that allows local reasoning about program correctness: if a thread \nexecutes a sequence of statements on variables it owns, the statements are serializable within a valid \nexecution. We implemented our analysis carefully to ensure this property regardless of what other threads \ndo. We also proved that a check and the access it precedes do not need to be atomic and that many checks \ncan be removed. This allowed us to implement ef.cient access checks and to use static analysis to remove \nchecks. We evaluated our tool using seven benchmarks. The results show that annotating the benchmarks \nwith ownership assertions required adding or changing only 0.2% of the total number of lines and that \nthe overhead is low. We believe our analysis can be used in practice to .nd bugs and prevent attacks; \nit found eight bugs in our benchmark programs.  Acknowledgments We thank Peter Sewell, Matthew Parkinson, \nand Tim Harris, who contributed to the development of this work, and Eric Koski\u00adnen, Avik Chaudhuri, \nNikhil Swamy, Iulian Neamtiu, Polyvios Pratikakis, and Elnatan Reisner who provided useful comments on \nearlier drafts. Hicks was supported by Microsoft Research as a Visiting Researcher, and in part by NSF \ngrants CCF-0541036 and CNS-0346989. References [1] P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and \nM. Castro. Preventing memory error exploits with WIT. In IEEE Symposium on Security and Privacy, May \n2008. [2] Z. Anderson, D. Gay, R. Ennals, and E. Brewer. SharC: Checking data sharing strategies for \nmultithreaded C. In PLDI, 2008. [3] Z. Anderson, D. Gay, and M. Naik. Lightweight annotations for controlling \nsharing in concurrent data structures. In PLDI, 2009. [4] C. Cao Minh, J. Chung, C. Kozyrakis, and K. \nOlukotun. Stamp: Stanford transactional applications for multi-processing. In IISWC, 2008. [5] M. Castro, \nM. Costa, J. Martin, M. Peinado, P. Akritidis, A. Donnelly, P. Barham, and R. Black. Fast byte-granularity \nsoftware fault isolation. In SOSP, 2009. [6] Q. Chen, L. Wang, Z. Yang, and S. D. Stoller. HAVE: Detecting \natomicity violations via integrated dynamic and static analysis. In FASE, 2009. [7] J. Condit, M. Harren, \nZ. Anderson, D. Gay, and G. Necula. Dependent types for low-level programming. In ESOP, 2007. [8] T. \nElmas, S. Qadeer, and S. Tasiran. Goldilocks: a race and transaction-aware Java runtime. In PLDI, 2007. \n[9] C. Flanagan and S. N. Freund. Atomizer: A dynamic atomic\u00adity checker for multithreaded programs. \nSci. Comput. Program., 71(2):89 109, 2008. [10] C. Flanagan and S. N. Freund. FastTrack: ef.cient and \nprecise dy\u00adnamic race detection. In PLDI, 2009. [11] C. Flanagan, S. N. Freund, and J. Yi. Velodrome: \nA sound and complete dynamic atomicity checker for multithreaded programs. In PLDI, 2008. [12] C. Flanagan \nand S. Qadeer. A type and effect system for atomicity. In PLDI, 2003. [13] K. Glerum, K. Kinshumann, \nS. Greenberg, G. Aul, V. Orgovan, G. Nichols, D. Grant, G. Loihle, and G. Hunt. Debugging in the (very) \nlarge: Ten years of implementation and experience. In SOSP 09, 2009. [14] C. Hammer, J. Dolby, M. Vaziri, \nand F. Tip. Dynamic detection of atomic-set-serializability violations. In ICSE, 2008. [15] P. Joshi, \nM. Naik, C.-S. Park, and K. Sen. CalFuzzer: An extensible active testing framework for concurrent programs. \nIn CAV, 2009. [16] R. J. Lipton. Reduction: a method of proving properties of parallel programs. Commun. \nACM, 18(12):717 721, 1975. [17] M. Musuvathi, S. Qadeer, T. Ball, G. Basler, P. A. Nainar, and I. Neamtiu. \nFinding and reproducing heisenbugs in concurrent pro\u00adgrams. In OSDI, 2008. [18] Phoenix. http://connect.microsoft.com/phoenix. \n[19] P. Pratikakis, J. S. Foster, and M. Hicks. Context-sensitive correlation analysis for detecting \nraces. In PLDI, 2006. [20] S. Rajamani, G. Ramalingam, V. P. Ranganath, and K. Vaswani. Iso\u00adlator: dynamically \nensuring isolation in comcurrent programs. In AS-PLOS, 2009.  [21] S. Savage, M. Burrows, G. Nelson, \nP. Sobalvarro, and T. Anderson. Eraser: a dynamic data race detector for multithreaded programs. ACM \nTrans. Comput. Syst., 15(4):391 411, 1997. [22] L. Wang and S. D. Stoller. Accurate and ef.cient runtime \ndetection of atomicity errors in concurrent programs. In PPoPP, 2006. A. Proof of Lemma 4 De.nition \n11 (Ownership map well-formedness). Ownership maps are well-formed, written f ., ., iff for all x, t: \n.(x)= t implies .(x) .{t}; and t . .(x) implies either .(x)= . or .(x)= t. Lemma 12 (Ownership map well-formedness \npreservation). For all a, ., ., .I,.I,t,x such that ., . f0 a r .I,.I we have f ., . implies f .I,.I \n. Proof. By induction on validation derivations. Lemma 4 (Movers, page 6): Proof. It is suf.cient to \nconsider traces a, b, \u00b7 since lengthier traces can easily be constructed by adding to the beginning or \nend of the two-element trace. Moreover, it is easy to see that for a valid execution trace, if var(a) \n.var(b),events a and b operate on = disjoint parts of the heap and ownership maps, so they can always \nbe safely commuted. Thus we must only consider the cases where var(a)= var(b). First we consider op(a) \n.{ownEx, ownRd, rd, wr},the right movers.For op(a)= ownEx, we can show that no valid trace can have var(a)= \nvar(b), so the result follows immediately. For op(a)= ownRd, the only operations by a thread tI with \nvar(a)= var(b) are ownRd, relRd, rd.As ownRd places no constraints on the heap, nor does it modify it, \ngiven s -.ownRd(t,x) s -.b sI -.ownRd(t,x) we easily have s -.b sI sI . Validity follows essentially \nbecause reader-oriented operations are independent a read or acquirement/release of read ownership by \none thread in no way affects the ownership/non-ownership for reading by another thread. The arguments \nfor op(a)= wr and op(a)= rd are similar to the arguments for op(a)= ownEx and op(a)= ownRd, respectively. \nNow we consider op(b) .{relEx, relRd, rd, wr},the left movers.For op(b)= relEx, we can show that no valid \ntrace can have var(a)= var(b). This relies on showing that .1; .1 f0 relEx(t, x) r .2,.2 implies that \n.1(x)= t, which implies that for any a with tid(a) .t,we must have .0(x)= = t in .0,.0 f0 a r .1,.1. \nBy Lemma 12, .0(x)= t im\u00adplies .0(x) .{t}.For op(b)= relRd, we .rst establish that op(a) .{ownRd, relRd, \nrd}; this again relies on Lemma 12, this time to get t . .0(x) implies .0(x)= . or t. Again, validity \nfol\u00adlows essentially because these reader-oriented operations operate essentially independently on the \nvarious maps, and the heap is not modi.ed. The argument for op(b)= rd is similar to op(b)= relRd and \nthe argument for op(b)= wr is similar to op(b)= relEx.  \n\t\t\t", "proc_id": "1706299", "abstract": "<p>Concurrent programming errors arise when threads share data incorrectly. Programmers often avoid these errors by using synchronization to enforce a simple ownership policy: data is either <i>owned exclusively </i> by a thread that can read or write the data, or it is <i>read owned </i> by a set of threads that can read but not write the data. Unfortunately, incorrect synchronization often fails to enforce these policies and memory errors in languages like C and C++ can violate these policies even when synchronization is correct.</p> <p>In this paper, we present a dynamic analysis for checking ownership policies in concurrent C and C++ programs despite memory errors. The analysis can be used to find errors in commodity multi-threaded programs and to prevent attacks that exploit these errors. We require programmers to write ownership assertions that describe the sharing policies used by different parts of the program. These policies may change over time, as may the policies' means of enforcement, whether it be locks, barriers, thread joins, etc. Our compiler inserts checks in the program that signal an error if these policies are violated at runtime. We evaluated our tool on several benchmark programs. The run-time overhead was reasonable: between 0 and 49% with an average of 26%. We also found the tool easy to use: the total number of ownership assertions is small, and the asserted specification and implementation can be debugged together by running the instrumented program and addressing the errors that arise. Our approach enjoys a pleasing modular soundness property: if a thread executes a sequence of statements on variables it owns, the statements are serializable within a valid execution, and thus their effects can be reasoned about in isolation from other threads in the program.</p>", "authors": [{"name": "Jean-Phillipe Martin", "author_profile_id": "81350573613", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P1911142", "email_address": "", "orcid_id": ""}, {"name": "Michael Hicks", "author_profile_id": "81100060959", "affiliation": "University of Maryland, College Park, MD, USA", "person_id": "P1911143", "email_address": "", "orcid_id": ""}, {"name": "Manuel Costa", "author_profile_id": "81338488060", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P1911144", "email_address": "", "orcid_id": ""}, {"name": "Periklis Akritidis", "author_profile_id": "81309500767", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1911145", "email_address": "", "orcid_id": ""}, {"name": "Miguel Castro", "author_profile_id": "81100104616", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P1911146", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706351", "year": "2010", "article_id": "1706351", "conference": "POPL", "title": "Dynamically checking ownership policies in concurrent c/c++ programs", "url": "http://dl.acm.org/citation.cfm?id=1706351"}