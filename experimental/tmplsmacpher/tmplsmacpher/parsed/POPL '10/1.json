{"article_publication_date": "01-17-2010", "fulltext": "\n On the Veri.cation Problem for Weak Memory Models Mohamed Faouzi Atig Ahmed Bouajjani LIAFA, University \nParis Diderot, Paris, France {atig,abou}@liafa.jussieu.fr Abstract We address the veri.cation problem \nof .nite-state concurrent pro\u00adgrams running under weak memory models. These models capture the reordering \nof program (read and write) operations done by mod\u00adern multi-processor architectures for performance. \nThe veri.cation problem we study is crucial for the correctness of concurrency li\u00adbraries and other performance-critical \nsystem services employing lock-free synchronization, as well as for the correctness of compiler backends \nthat generate code targeted to run on such architectures. We consider in this paper combinations of three \nwell-known program order relaxations. We consider .rst the write to read relaxation, which corresponds \nto the TSO (Total Store Ordering) model. This relaxation is used in most hardware architectures avail\u00adable \ntoday. Then, we consider models obtained by adding either (1) the write to write relaxation, leading \nto a model which is essen\u00adtially PSO (Partial Store Ordering), or (2) the read to read/write relaxation, \nor (3) both of them, as it is done in the RMO (Relaxed Memory Ordering) model for instance. We de.ne \nabstract operational models for these weak memory models based on state machines with (potentially unbounded) \nFIFO buffers, and we investigate the decidability of their reachability and their repeated reachability \nproblems. We prove that the reachability problem is decidable for the TSO model, as well as for its extension \nwith write to write relax\u00adation (PSO). Furthermore, we prove that the reachability problem becomes undecidable \nwhen the read to read/write relaxation is added to either of these two memory models, and we give a con\u00addition \nunder which this addition preserves the decidability of the reachability problem. We show also that the \nrepeated reachability problem is undecidable for all the considered memory models. Categories and Subject \nDescriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation. General Terms Veri.cation, Theory, \nReliability. Keywords Program veri.cation, Relaxed memory models, In.\u00adnite state systems, Lossy channel \nsystems. 1. Introduction Shared-memory multiprocessor architectures are now ubiquitous. For performance \nreasons, most contemporary multiprocessors im\u00adplement relaxed memory consistency models [Adve and Ghara- \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n10, January 17 23, 2010, Madrid, Spain. Copyright c &#38;#169; 2010 ACM 978-1-60558-479-9/10/01. . . \n$10.00 Sebastian Burckhardt Madanlal Musuvathi Microsoft Research, Redmond, WA, USA {sburckha,mandanm}@microsoft.com \nchorloo 1996]. Such memory models relax the ordering guarantees of memory accesses. For example, the \nmost common relaxation is that writes to shared memory may be delayed past subsequent reads from memory. \nThis write-to-read relaxation is commonly attributed to store buffers between each processor and the \nmain memory. The corresponding memory model is historically called TSO, for total\u00adstore-order. Similarly, \nmany models relax under certain conditions read-to-read order, read-to-write order, and write-to-write \norder. Programmers usually assume that all accesses to the shared memory are performed instantaneously \nand atomically, which is guaranteed only by the strongest memory model, sequential con\u00adsistency (SC) \n[Lamport 1979]. Nevertheless, this assumption is in fact safe for most programs. The reason is that the \nrecommended methodology for programming shared memory (namely, to use threads and locks in such a manner \nas to avoid data races) is usu\u00adally suf.cient to hide the effect of memory ordering relaxations. This \neffect is known as the DRF guarantee, because it applies to data-race-free programs. However, while very \nuseful for mainstream programs, the DRF guarantee does not apply in all situations. For one, the implemen\u00adtors \nof the synchronization operations need to be fully aware of the hardware relaxations to ensure suf.cient \nordering guarantees (it is their responsibility to uphold the DRF guarantee). For ex\u00adample, Dekker s \nmutual exclusion protocol does not function cor\u00adrectly on TSO architectures (Fig. 1). Secondly, many \nconcurrency libraries and other performance-critical system services (such as garbage collectors) bypass \nconventional locking protocol and em\u00adploy lock-free synchronization techniques instead. Such algorithms \nneed to be aware of the memory model. They may either be im\u00admune to the relaxations by design, or contain \nexplicit memory or\u00addering fences to prevent them. Most algorithms choose the latter option; however, \ntwo recent implementations of a work-stealing queue [Michael et al. 2009, Leijen et al. 2009] are using \nalgorithms that are speci.cally written to perform well on TSO architectures without requiring fences. \nReasoning about the behavior of such algorithms on relaxed memory models is much more dif.cult than for \nsequentially con\u00adsistent memory, and it is not clear how to apply standard reasoning techniques or .nite-state \nabstractions. This highlights the need for more research on automatic veri.cation techniques for programs \non relaxed memory models [Burckhardt et al. 2007, Huynh and Roy\u00adchoudhury 2006, Park and Dill 1995, Yang \net al. 2004]. Classic results show that for .nite-state programs under SC, the reachability problem, \nas well as the repeated reachability prob\u00adlem (relevant for checking liveness properties), are both PSPACE\u00adcomplete \n[Sistla and Clarke 1985]. To our knowledge, no analo\u00adgous decidability/complexity results are known for \nrelaxed mem\u00adory models. We thus investigate in this paper the veri.cation prob\u00adlem for several variations \nof shared-memory systems with different relaxations. We start by building a formal model of concurrent \n.nite-state programs executing on a TSO system that is, a shared-memory sys\u00adInitially: X = Y = 0  Proc1 \nProc2 a: X = 1 b: r1 = Y c: if(r1 == 0) enter crit p: Y = 1 q: r2 = X r: if(r2 == 0) enter crit Eventually: \nr1 = r2 = 0 and X = Y= 1  Figure 1. Snippet of Dekker s mutual exclusion protocol (top). The sequence \n(bottom) is possible on most contemporary multi\u00adprocessors and shows how the protocol fails to achieve \nmutual ex\u00adclusion on TSO. tem with the w . r relaxation. This model consists of a .nite-state control \nrepresenting the local program states of each thread along with unbounded FIFO queues representing the \ncontents of the store buffers. Note that although the store buffers in actual machines are necessarily \n.nite, we may not assume any .xed bound, so a .nite\u00adstate model is not suf.cient to verify a general \nalgorithm. At this point, it is not clear yet whether the reachability/repeated reach\u00adability problems \nis decidable at all, because general FIFO queue automata are Turing powerful. To solve this problem, \nwe establish a close connection between TSO systems and lossy FIFO channel machines. Speci.cally, we \n.rst prove that TSO systems can be simulated by lossy FIFO chan\u00adnel machines, which implies that their \ncontrol point reachability problem is decidable [Abdulla and Jonsson 1993]. The translation to lossy \nchannel machines is not trivial since turning simply (TSO) store buffers to lossy channels is obviously \nunsound. Conversely, we prove that TSO systems can simulate lossy FIFO channel ma\u00adchines, which implies \nthat the complexity of their reachability prob\u00adlem is non-primitive recursive [Schnoebelen 2002] and \nthat their re\u00adpeated reachability problem (and therefore their veri.cation prob\u00adlem for liveness properties) \nis undecidable [Abdulla and Jonsson 1994]. Next, we consider models obtained by adding either (1) the \nw . w relaxation (leading to a model which is essentially PSO), or (2) the r . r/w relaxation, or (3) \nboth of them (as it is done in the RMO model for instance). In fact, it is not dif.cult to show that \nall the results for TSO hold also for its write-to-write relaxation (PSO). Moreover, we prove that adding \nthe r . r/w relaxation to either TSO or PSO makes the reachability problem undecidable. This is due to \nthe fact that allowing writes to overtake reads amounts to guess for each delayed read operation the \nvalue it will have later when it will be executed. Then, undecidability comes from the fact that there \nmight be an unbounded number of such guessed read values. Intuitively, allowing writes to overtake an \nunbounded number of reads requires memorizing unbounded sequences of values (the guessed read values) \nin order to validate all of them later, and this requires in some sense the use of perfect unbounded \nFIFO queues (instead of lossy ones). However, when we impose that at each point in time the number of \nguessed read values is bounded, then the state reachability problem becomes decidable (again by reduction \nto the reachability in lossy channel machines) since the amount of information that needs to be stored \nin a perfect manner is always bounded (and can be encoded using strong symbols in the channels). 1.1 \nRelation to Commercial Multiprocessor Architectures In general, it is quite dif.cult to establish a precise \nrelationship between abstract memory models (described as a collection of re\u00adlaxation rules in the style \nof [Adve and Gharachorloo 1996]) and actual memory models of commercially available multiprocessors. \nMany of those models are not fully formalized. The of.cial spec\u00adi.cations are often quite complicated, \nincomplete, and sometimes simply incorrect [Owens et al. 2009]. Since the goal of this paper is foundational \nresearch, we focus on building precise and simple models that contain just a few of the most common relaxations. \nOur main model (a shared-memory system with the w . r re\u00adlaxation) corresponds to the SPARC TSO weak \nmemory model [Weaver and Germond 1994] and the latest formalization of the x86 memory model, x86-TSO \n[Owens et al. 2009]. Traditionally, TSO is speci.ed using both formal axiomatic and informal operational \ndescriptions [Burckhardt and Musuvathi 2008. Extended Version as Tech Report MSR-TR-2008-12, Microsoft \nResearch, Park and Dill 1995, Sindhu et al. 1991, Weaver and Germond 1994]. Equiv\u00adalence proofs of the \ntwo appear in [Owens et al. 2009] and the ap\u00adpendix of [Burckhardt and Musuvathi 2008. Extended Version \nas Tech Report MSR-TR-2008-12, Microsoft Research]. Our opera\u00adtional model follows the general structure \nof those models (but adds a .nite-state control to represent the program state). Note that our operations \nare suf.cient to model most synchronization operations on SPARC TSO and x86-TSO: the atomic read-write \ncan represent the atomic SWAP, LDSTUB, and CAS instruction on SPARC TSO and locked operations on x86-TSO, \nand it can simulate a full fence (because a fence is equivalent to executing an atomic-read-write to \nan irrelevant location). 1.2 Related Work Previous work on verifying programs on relaxed memory models \nhas used underapproximation to keep the problem .nite-state, and falls into two categories: (1) explicit-state \nmodel checking with op\u00aderational .nite-state models [Huynh and Roychoudhury 2006, Park and Dill 1995], \nand (2) bounded model checking with axiomatic memory models [Burckhardt et al. 2007, Yang et al. 2004]. \nOur work, in contrast, precisely handles the in.nite state introduced by unbounded store buffers. Much \nprevious work has also addressed the loosely related, but qualitatively quite different problem of verifying \nwhether a hard\u00adware implementation properly implements a given memory model. For instance, it is known \nto be undecidable whether a .nite-state memory system implementation guarantees sequential consistency \n[Alur et al. 1996]. Compared to our work, the latter work consid\u00aders a tougher correctness condition \n(sequential consistency instead of reachability) but a simpler model of the hardware (.nite state instead \nof FIFO queues). For practical purposes, approximative al\u00adgorithms [Roy et al. 2005, Baswana et al. 2008] \nand the TSOTool [et al. 2004] are useful to check whether a given individual execu\u00adtion trace satis.es \nthe desired memory model, a problem which is known to be NP-complete for SC [Gibbons and Korach 1992]. \n  2. Preliminary de.nitions and notations Let k . N such that k = 1. Then, we denote by [k] the set \nof integers {1,..., k}. Let S be a .nite alphabet. We denote by S* (resp. S+) the set of all words (resp. \nnon empty words) over S, and by e the empty word. We denote by Se the set S .{e}. The length of a word \nw is denoted by length(w). (We assume that length(e)= 0.) For every i . [length(w)], let w(i) denote \nthe symbol at position i in w. For a . S and w . S*. We write a . w if a appears in w, i.e., .i . [length(w)] \ns.t. a = w(i).  Given a sub-alphabet Q . S and a word u . S*, we denote by u|Q the projection of u over \nQ , i.e., the word obtained from u by erasing all the symbols that are not in Q . A substitution s over \nS is a mapping from S to S. We write w[s] to denote the word such that for every i . [length(w)], w[s](i)= \ns(w(i)).This de.nition is generalized to sets of words as follows: For every L . S* , L[s]= {w[s] | w \n. L}. Assume that S = {a1,..., an}. Then, to de.ne the substitution s applied to a word w, we use the \nnotation w[s(a1)/a1,..., s(an)/an] where, for the sake of conciseness, we omit s(ai)/ai when s(ai)= \nai, for any i . [n]. This notation is extended straightforwardly to sets of words. Let k = 1 be an integer \nand E be a set. Let e =(e1,..., ek) . Ek be a k-dim vector over E. For every i . [k], we use e[i] to \ndenote the i-th component of e (i.e., e[i]= ei). For every j . [k] and e '. E, we de.nedasfollows:over \nE' the k-dimvector e] ' e . .denoteby e[j e ' [ j]= e ' and e ' [l]= e[l] for all l= j. Let E and F be \ntwo sets. We denote by [E . F] the set of all mappings from E to F. Assume that E is .nite and that E \n= {e1,..., ek} for some integer k = 1. Then, we sometimes identify a mapping g . [E . F] with a k-dim \nvector over F (i.e., we consider that g . Fk with g[i]= ei for all i . [k]).  3. TSO/PSO concurrent \nsystems We introduce in this section an operational semantics for concur\u00adrent systems under the TSO memory \nmodel (corresponding to the w . r program order relaxation). A similar operational model can be de.ned \nin order to take into account both w . r and w . w relaxations, leading to the PSO memory model. 3.1 \nShared memory concurrent systems Let D be a .nite data domain, and let X = {x1,..., xm} be a .nite set \nof variables valued in D. From now on, we denote by M the set Dm, i.e., the set of all possible valuations \nof the variables in X. Then, for a given .nite set of process identities I, let W (I, D, X)  3.2 An \noperational model for TSO Our operational model consists in associating with each process a FIFO buffer. \nThis buffer is used to store the write operations performed by the process (Write to store). Memory updates \nare then performed by choosing nondeterministically a process and by executing the .rst write operation \nin its buffer (Update). A read operation by the process Pi to the variable xj can overtake the write \noperations stored in its own buffer if all these operations concern variables that are different from \nxj (Read memory). When the buffer contains some write operations to xj, then the read value must correspond \nto the value of the last of such a write operation (Read own write). Finally, atomic read-write operation \ncan be executed only when the buffer is empty (ARW). Let us now de.ne formally the model. Let P = P1 \n\u00d7\u00b7\u00b7\u00b7\u00d7 Pn and for every i . [n], let Bi = {i}\u00d7 [m] \u00d7 D be the alphabet of the store buffer associated \nwith Pi.A con.guration of N is a tuple (p, d, u) where p . P, d . M, and u . B* 1 \u00d7\u00b7\u00b7\u00b7\u00d7B* n is a valuation \nof the store buffers. We de.ne the transition relation .N on con.gurations of N to be the smallest relation \nsuch that, for every p, p '. P, for every u, u '. B* 1 \u00d7\u00b7\u00b7\u00b7\u00d7B* , and for every d, d'. M, we have (p, \nd, u).N n(p ' , d' , u ') if there is an i . [n], and there are p, p '. Pi, such that ,andoneofthefollowingcaseshold:] \n' p . .p[i= ' p[i]= p, p nop 1. Nop: p- -.ip ' , d = d', and u = u ' . w(i,xj ,d) =i,j, d)u[i]],andd( \n. .u[i= ' u, ' ip.- ----pWritetostore:2. d' . )]i](i,j, d[ ' u . .i[ 'D.u = u.d..]m[.j.,and' p = pUpdate:3. \n]d . .d[ j= ' and d r(i,xj ,d) 4. Read: p-----.ip ' , d = d' , u = u ', and ( Read own write: .u1, u2 \n. Bi * . u[i]= u1(i, j, d)u2 and ) .(i, k, d' ) . u1. k= j. Read memory: .(i, k, d' ) . u[i]. k= j, \nand d[ j]= d. arw(i,xj ,d,d' ) 5. ARW: p--------.ip ' d'  , u[i]= e, u = u ', and d[ j]= d, and .] \n'd . .j[d= be the smallest set of operations which contains (1) the no opera\u00ad tion nop, (2) the read \noperations r(i, x, d), (3) the write operations w(i, x, d), and (4) the atomic read-write operations \narw(i, x, d, d' ), Let .* denote the re.exive-transitive closure of .N . N In the rest of the paper, \nwe call (w . r)-relaxed memory system where i . I, x . X, and d, d'. D. A concurrent system over D and \nX is a tuple N =(P1,..., Pn) where for every i . [n], Pi =(Pi, Di) is a .nite-state process where (1) \nPi is a .nite set of control states, and (2) Di . Pi \u00d7 W ({i}, D, X) \u00d7 Pi is a .nite set of labeled transition \nrules. For con\u00ad op venience, we write p--.ip ' instead of ( p, op, p ' ) . Di, for any p, p '. Pi and \nop . W ({i}, D, X). The behaviors of concurrent systems are usually de.ned accord\u00ading to the interleaving \nsemantics. The weak semantics correspond\u00ading to the w . r program order relaxation is obtained by allowing \nthat read operations overtake (along a computation) write opera\u00adtions performed by the same process when \nthese operations concern different variables, i.e., a sequence of operations w(i, y, d' )r(i, x, d) (executable \nfrom left to right), where x= y, can always be replaced by the sequence r(i, x, d)w(i, y, d' ). However, \nin this semantics the order between write operations performed by the same process must be maintained, \nand each atomic read-write is considered as an operation that cannot permute with no other operation \nof any kind. Moreover, a cancellation rule is applied which consists in considering that any sequence \nw(i, x, d)r(i, x, d) of a write followed by a read of the same value to the same variable by the same \npro\u00adcess is equivalent to the operation w(i, x, d). In the next section, we de.ne an operational model \nthat captures this weak memory model. a concurrent system N with the operational semantics induced by \nthe transition relation .N de.ned above.  3.3 Adding the w . w relaxation The w . w relaxation consists \nin allowing that write operations overtake other write operations by the same process if they concern \ndifferent variables. The consideration of both w . r and w . w relaxations leads to a memory model which \nis essentially the PSO model. An operational model for (w . r/w)-relaxed memory systems can be de.ned \nby modifying the model in the subsection 3.2 so that each process has m store buffers instead of a single \none (one per variable). Then, two consecutive write operations w(i, xj, d) and w(i, xk, d' ) by the same \nprocess Pi are stored in two different buffers, which allows to reorder these write operations. We omit \nhere the formal description of the model since it should be quite obvious to the reader.  3.4 Reachability \nproblems We assume that we are given a (w . r)-relaxed memory system N . Then, the state reachability \nproblem is to determine, for two given vectors of control states p, p '. P, and two given memory states \nd, d'. M, whether (p, d, en).* (p ' , d' , en). N  The repeated state reachability problem is to determine, \nfor given p, p '. P and d, d'. M, whether there is an in.nite sequence (p0, d0, u0)(p1, d1, u1)\u00b7\u00b7\u00b7 such \nthat: (1) (p, d, en).* (p0, d0, u0), N and (2) (pi, di, ui).* (pi+1, di+1, ui+1), pi = p ', and di = \nd' for N all i = 0. The de.nitions of the two problems above can be extended straightforwardly to the \ncase of (w . r/w)-relaxed memory sys\u00adtem. We address in the next sections the decidability of these prob\u00adlems. \nNotice that we consider in the de.nition of the state reachability problem that the buffers at the targeted \ncon.guration must be empty instead of being arbitrary. This is only for the sake of simplicity and does \nnot constitute at all a restriction. Indeed, we can show that the arbitrary buffer state reachability \nproblem is reducible to the empty buffer state reachability problem. The idea of the reduction is to \nadd to the system a special process, let us call it O (for observer), that guesses nondeterministically \nthe moment when the system reaches the targeted control and memory states. An ad\u00additional shared variable \nis used as a .ag. This .ag is (1) checked by all the original processes in the system before each of \ntheir op\u00aderations, and (2) it is switched (using an atomic read-write opera\u00adtion) by O when it guesses \nthat the target state is reached in order to signal to the other processes that they must stop their \ncomputa\u00adtions (and stay at their control location). After switching the .ag, the process O checks that \nthe memory state is indeed the targeted one. Then, since the buffers can always be .ushed by executing \nall pending write operations (which potentially modi.es the memory state but keeps unchanged the control \nstates of all processes), it suf\u00ad.ces to check (as an empty buffer state reachability problem) that each \nprocess is at its targeted control state (and some memory state among the .nitely many possible states). \n  4. Perfect/Lossy Channel Machines FIFO channel machines are .nite control machines supplied with unbounded \nFIFO queues on which they can perform send and receive operations. When the channels are lossy, symbols \nin the channels can be lost at any position and at any time. We give in this section the formal de.nition \nof these machines, and we recall results concerning the decidability and the complexity of their reachability \nand repeated reachability problems. In fact, we need to use in this paper a version of these machines \nwhich extends (syntactically) the basic version usually considered in the literature (e.g., in [Abdulla \nand Jonsson 1993, 1994, Sch\u00adnoebelen 2002]). In our version, machines can also check regular constrains \non the channels, and apply a substitution on symbols oc\u00adcurring in the channels. Moreover, we admit that \nthere is a bounded number of special symbols (called strong symbols) that cannot be lost by the channels. \nThe extensions that we consider do not in\u00adcrease the power of the lossy channel machines, but they are \nuseful for describing our results in the next sections. 4.1 Channel constraints and operations Let C \nbe a set of channels. We consider that the content of each channel is a word over S (i.e., an element \nof S*). Guards: For a given channel c . C,a regular guard on c is a constraint of the form c . L , where \nL . S* is a regular set of words. Given a guard c . L , and a word u . S*, we write u |= c . L if and \nonly if u . L. For notational convenience, we write (1) a . c instead of c . S* aS* , (2) c = e instead \nof c .{e} , and (3) c : A instead of c . A* , for any A . S. A regular guard over C is a mapping g that \nassociates a regular guard with each channel c . C. Let Guard(C) be the set of regular guards over C. \nThe de.nition of |= is extended to regular guards over C and to mappings from C to S* as follows: For \nevery g . Guard(C) and u . [C . S*], we write u |= g iff u(c) |= g(c) for all c . C. Operations: For \na given channel c . C,a channel operation on c is either a nop (no operation), or an operation of the \nform c?a (receive) for some a . S, or of the form c[s]!a (send), where a . S and s is a substitution \nover S. We write simply c!a instead of c[s]!a when s is the identity substitution. The operation c?a \nchecks if the .rst element of c is equal to a and then erases it, whereas c[s]!a applies the substitution \ns to c and then adds a to the end of the channel (as the last element). Formally, we associate with each \noperation a relation over words (channel contents) as follows: For every u, u '. S*, we have (1) [[nop]](u, \nu ' ) iff u = u ', (2) [[c[s]!a]](u, u ' ) iff u ' = a \u00b7 u[s], and (3) [[c?a]](u, u ' ) iff u = u '\u00b7 \na. A channel operation over C is a mapping op that associates with each channel c . C a channel operation \non c. Let Op(C) be the set of channel operations over C. The de.nition of [[ \u00b7 ]] is extended to channel \noperations over C and to pairs of mappings from C to S* as follows: For every g . Guard(C) and u, u '. \n[C . S*], we have [[op]](u, u ' ) if and only if [[op(c)]](u(c), u ' (c)) holds for all c . C. 4.2 FIFO \nchannel machines A channel machine is a tuple M =(Q,C, S, L, D) where Q is a .nite set of control states, \nC is a .nite set of channels, S is a .nite channel alphabet, L is a .nite set of transition labels, and \nD . Q \u00d7 Le \u00d7 Guard(C) \u00d7 Op(C) \u00d7 Q is a set of transitions. We l,g|op write q----.D q ' instead of (q, \nl, g, op, q ' ) . D. A con.guration of M is a pair (q, u) where q . Q and u . [C . S*]. Let Conf (M ) \ndenote the set of con.guration of M . Given a con.guration g= (q, u), let State(g)= q. This de.nition \nis generalized to sequences of con.gurations as follows: For every g1,..., gm . Conf (M ), State(g1 \u00b7\u00b7\u00b7gm)= \nState(g1) \u00b7\u00b7\u00b7State(gm). l For every l . Le, the transition relation =.M , between con.g\u00adurations of M \n, is de.ned as follows: For every q, q '. Q and u, u '. l l,g|op [C . S*], (q, u) =.M (q ' , u ') if \nand only if there is q----.D q ' S l such that u |= g and [[op]](u, u ' ). Let .M ==and let l.Le .M .* \nbe the re.exive-transitive closure of .M . M Given (q, u), (q ' , u ') . Conf (M ),a .nite run r of M \nfrom (q, u) to (q ' , u ') is a .nite sequence (q0, u0)l1(q1, u1)l2 \u00b7\u00b7\u00b7lm(qm, um) such that the following \nconditions are satis.ed: (1) q0 = q and li qm = q ', (2) u0 = u and um = u ', and (3) (qi-1, ui-1)=.M \n(qi, ui) for all i . [m] . The trace of a .nite run r is the sequence of labels * r|L . We write (q, \nu) =l .M (q ' , u ') when there is a run r from (q, u) to (q ' , u ') with a trace l (i.e., r|L = l). \nLet q, q '. Q be two control states. We denote by T(q,q ')(M ) the set of traces of all .nite runs of \nM from the con.guration (q, e|C|) to the con.guration (q ' , e|C|). Given a control state q . Q, an in.nite \nrun of M starting from q is an in.nite sequence (q0, u0)l1(q1, u1)l2 \u00b7\u00b7\u00b7 such that q0 = q, li u0 = e|C|, \nand (qi-1, ui-1)=.M (qi, ui) for all i = 1.  4.3 Lossy Channel Machines In this section, we de.ne the \nsemantics of channel machines when the channels may loose some of their contents. Subword relations: \nLet j. S*\u00d7 S* be the subword relation de.ned as follows: For every u = a1 \u00b7\u00b7\u00b7an . S*, and every v = b1 \n\u00b7\u00b7\u00b7bm . S* , u j v if and only if there are i1,..., in . [m] such that i1 < i2 < ... < in and aj = bij \nfor all j . [n].  Let S . S be a set of strong symbols and let k . N. Then, for every u, v . S*, let \nu jkS v hold if and only if u j v, u|S = v|S, and length(u|S) = k. (Notice that j0 0/ =j.) The subword \nrelations de.ned above are extended to mappings from C to S* as follows: For every u, v . [C . S*], u \njkS v holds if and only if u(c) jkS v(c) holds for all c . C. l Lossy transitions: Now, we de.ne a transition \nrelation =.(M ,S,k) between con.gurations of M by allowing that the channels can loose some of their \nsymbols, provided that these symbols are not in S, and under the restriction that the number of S symbols \nin each channel is bounded by k. Formally, for every l . Le, q, q '. Q, and l u, u '. [C . S*], (q, u) \n=.(M ,S,k) (q ' , u ') if and only if there are l v, v '. [C . S*] such that v jkS u, v =.M v ', and \nu 'jkS v ' . The notions of a .nite/in.nite run and of a .nite trace are de.ned as in the non-lossy case \nby replacing .M with .(M ,S,k). Given two control states q, q '. Q, we denote by LT(S,k)(M ) the (q,q \n' )set of traces of all .nite runs of M from the con.guration (q, e|C|) to the con.guration (q ' , e|C|) \naccording to the semantics de.ned by .(M ,S,k). Notice that, by de.nition of .(M ,S,k), in all reachable \ncon.gurations along runs of M , the channels contain less than k symbols in S. In the rest of the paper, \nwe say that M is an (S, k)-LCM (or simply a LCM if no confusion is possible) when its operational semantics \nis de.ned by .(M ,S,k). Basic Lossy Channel Machines: A basic LCM is a (0/, 0)-LCM where all the guards \nare trivial (i.e., of the form c . S*) and all the substitutions s in the send operations c[s]!a are \nequal to the identity substitution. We can prove the following fact. PROPOSITION 1. Let M =(Q,C, S, L, \nD) be a (S, k)-LCM for some ' S . S and k . N. Then, it is possible to construct a basic LCM M = (Q' \n,C, S' , L, D' ), with Q . Q' and S . S', such that LT(S,k)(M )= (q,q ') LT(0/ ,0)(M ' ) for all q, q \n'. Q. (q,q ' ) Applying substitutions can be easily simulated using channel rotations. A channel rotation \nover c . C corresponds to send a special marker . to c to delimit the current tail position, and then \niterate, using some extra control states, a sequence of receive, check/substitute, and send operations, \nuntil . is found. Channel rotations are also used to check regular guards. Given a guard ' c . L, the \nmachine M uses during the rotation of c the content of this channel as input to simulate the runs of \nsome given .nite state automaton that recognizes the regular language L. Then, if the marker . is encountered \nin a non accepting state of this automaton, ' M goes to a special blocking control state. To guarantee \nthat all ' the strong symbols in the channels of M are not lost, the machine ' M stores in its control \nstate (in addition to the control state of M ) their sequences corresponding to each of the channels. \n(Remember that these sequences are of bounded sizes by assumption). We consider that the control state \nof M ' corresponding to a control state q . Q of M coupled with an empty sequence of strong symbols is \nidenti.ed with q. Then, after each simulation of an operation of M , the machine updates the sequences \nof strong symbols in its control state, and also checks, using channel rotations over all its channels, \nthat all strong symbols that are supposed to be in the channels are indeed present. If for some channel \nthe sequence of strong symbols ' is different from the one stored in its control state, the machine M \ngoes to a blocking control state.  4.4 Product of channel machines: We de.ne the synchronous product \nbetween channel machines in the usual manner: Given two machines M 1 =(Q1,C1, S, L, D1) and M 2 =(Q2,C2, \nS, L, D2) such that C1 n C2 = 0/, let M 1 . M 2 = (Q1 \u00d7 Q2,C1 . C2, S, L, D12) denote the product of \nM 1 and M 2 where D12 is de.ned by synchronizing transitions having the same label in L and gathering \ntheir guards and operations (notice that they concern disjoint sets of channels), and letting e-transitions \nasynchronous. The following fact is easy to show: PROPOSITION 2. Let q1, q ' 1 . Q1,q2, q ' 2 . Q2, and \nlet q =(q1, q2) and q ' =(q ' 1, q2' ). Then, T(q,q ')(M 1 . M 2)= T(q1,q ' 1)(M 1) n T(q2,q ' 2)(M \n2), and  LT(S,k)(M 1 .M 2)= LT(S,k)(M 1) nLT(S,k)(M 2), for every  (q,q ' )(q1,q ' 1)(q2,q ' 2) S . \nS and k . N. The product operation . can be extended straightforwardly to any .nite number of channel \nmachines.  4.5 Decision problems on LCM Let M =(Q,C, S, L, D) be an (S, k)-LCM for some S . S and k \n. N. The control state reachability problem is to determine whether, for two given control states q and \nq ', there is a .nite run r of M from (q, e|C|) to (q ' , e|C|). Clearly, this is equivalent to check \nwhether LT(S,k)(M )= 0/. (q,q ' )The repeated control state reachability problem is to determine whether, \nfor two given control states q and q ', there is an in.nite run r of M starting from (q, e|C|) such that \nq ' occurs in.nitely often in State(r|Q\u00d7([C.S*]) ). PROPOSITION 3. For every S . S and k . N, the control \nstate reachability problem for (S, k)-LCM s is decidable, whereas their repeated control state reachability \nproblem is undecidable. The proposition above follows immediately from Proposition 1 and from well-known \nresults on the reachability and the repeated reachability problems in basic lossy channel machines [Abdulla \nand Jonsson 1993, 1994]. The decidability of the control state reachability problem of basic lossy channel \nmachines is based on the theory of well-structured systems [Abdulla et al. 1996, Finkel and Schnoebelen \n2001]. Actually, it is also possible to prove that this problem is de\u00adcidable for (nonbasic) (S, k)-LCM \ndirectly using the same theory, without going through the simulation of Proposition 1. For that, it suf.ces \nto see that (1) jkS is a well-quasi ordering on the set of words with less than k symbols in S (which \nfollows from the fact that j is well-known to be a WQO (by Higman s lemma), and that WQO s are closed \nunder product and disjoint union), and that (2) jkS de.nes a simulation relation on the con.gurations \nof (S, k)-LCM s (if a con.guration can perform a transition, a greater con\u00ad.guration w.r.t. this ordering \ncan also perform the same transition to reach the same target). Then, by standard results in [Abdulla \net al. 1996, Finkel and Schnoebelen 2001], a simple iterative back\u00adward reachability analysis procedure \nfor (S, k)-LCM s (using .nite representations of jkS-upward closed sets of con.gurations by their minimals) \nis guaranteed to always terminate. It has been shown in [Schnoebelen 2002] that this procedure may take \nin general a non\u00adprimitive recursive time to converge. Nevertheless, ef.cient algo\u00adrithms and tools for \nthe analysis of well-structured systems such as vector addition systems and lossy channel machines have \nbeen developed, based on complete abstract reachability analysis tech\u00adniques [Geeraerts et al. 2006, \nGanty et al. 2006].   5. Simulating TSO/PSO by lossy channels We show that the state reachability problem \nfor (w . r)-relaxed memory systems can be reduced to the control state reachabil\u00adity problem for lossy \nchannel machines. From this reduction and Proposition 3, we obtain the following fact. THEOREM 1. The \nstate reachability problem for (w . r)-relaxed memory systems is decidable. The rest of the section is \nmainly devoted to the description of the reduction. We address in a last subsection the extension of \nTheorem 1 to the case of PSO models. Given a concurrent system N =(P1,..., Pn) over D and X = {x1,..., \nxm}, we construct n lossy channel machines M 1,..., M n, one per process in N , such that the reachability \nproblem in N can be reduced to the reachability problem in the product of M 1,..., M n. Turning simply \nthe store buffers to lossy channels (i.e., skipping some write operations) leads to unsound memory states \n(w.r.t. the TSO semantics). For example, consider two processes P and P ' sharing two variables x and \ny, and assume that the transitions w(x,1)w(y,1) of P are p0 ----. p1 ----. p2 and that the transitions \nof P ' r(x,1)r(y,0) are p ' - --. p ' - --. p2' . (We omit here the identities of the 01 processes in \nthe description of the actions.) Then, assuming that the starting state is ( p0, p ' 0, x = 0, y = 0), \nit can be checked that, according the TSO semantics, the state ( p2, p ' 2, x = 1, y = 0) is not reachable. \nHowever, if the operation w(y, 1) of process P is lost by its store buffer (if we consider it as a lossy \nchannel), then this state becomes reachable. In fact, lossyness can be tolerated only if the information \nin the channels is always suf.cient to obtain sound memory state when read operations must be performed. \nThen, the idea is that channels should contain sequences of sound memory states. This means that for \nthe simulation, instead of sending in the channel a write operation, a process must send the state that \nthe memory (in the simulated system) will have right after the execution of this write operation (i.e., \nat the moment when in the simulated system this operation will be taken from the store buffer and used \nfor updating the memory state). For instance, in the example above, the sequence of sound memory states \nthat must be considered is (x = 0, y = 1)(x = 1, y = 1). Assume now that process P has sent this sequence \n(from left to right) to its channel, and that the memory is updated successively by copying these states \nto the global store, but some state, say (x = 0, y = 1), has been lost. In this case the state of the \nmemory goes directly from (x = 0, y = 0) to (x = 1, y = 1). But this is perfectly sound since several \nmemory updates are possible before any process can observe the changes in the memory state. Now, let \nus see how a process can send a sequence of sound states to its channel. Obviously, if the process is \nthe only one in the system to perform write operations (as in the example above), knowing what is the \nmemory state after executing a write opera\u00adtion is easy to determine: The process can maintain in its \ncontrol state the last memory state sent to the channel, and then, for the next write operation, the \nprocess can compute a new state that is (memorized in its control state and) sent to the channel. The \ndif.\u00adculty comes of course from the fact that in presence of concurrency, the memory state that the process \nshould send to the channel must take into account the interferences of the other processes. There\u00adfore, \neach process must guess the sequence of memory update op\u00aderations (along a computation) resulting from \nthe write operations performed by all the processes in the system. In other words, the process has to \nguess the write operations by all processes as well as the order (after their interleaving) in which \nthey will be executed. Given such a sequence of write operations, the simulation of the behavior of a \nprocess by a lossy channel machine can be done. In fact, since the buffer contains a sequence of sound \nmemory states, loosing some of the channel content can be seen as skipping unob\u00adservable states. Indeed \na process observes the memory only at the moment read operations are performed. Between these moments \nseveral changes to the memory (due to the writes sent by different processes) may occur, but even if \nthe intermediary memory states resulting from these changes are not observed (and can be consid\u00adered \nas lost by the channel), each observed state is sound since it accumulates the effect of all the operations \nperformed so far. For this simulation, a control state of M i is composed by a con\u00adtrol state of Pi, \na vector of data dc . M corresponding to the current memory state, and a vector of data dg representing \nthe (guessed) memory state that should be obtained after executing all the opera\u00adtions in the buffer. \nThen, an element of the channel alphabet of M i is of the form (k, j, d) where k . [n], j . [m] and d \n. Dm. (We will see shortly that we need also some other kind of elements.) The vector of data d in such \nan element represents the memory state supposed to be reached after executing the operation w(k, xj , \nd[ j]). There is however a technical issue which requires some care: In order to simulate correctly Read \nown write operations, it is nec\u00adessary to forbid the loss of the states stored in the channel that cor\u00adrespond \nto the last write operation on each of the variables. Fortu\u00adnately, the number of such states is bounded \n(since X is .nite), and therefore we can consider them as strong symbols (see de.nition of sub-word relations). \nTechnically, these special states in the channel are marked and have the form ((k, j, d),.); let S2 be \nthe set of these marked states. Then, the alphabet of the channel includes also S2, and after each write \noperation, the marking in the channel must of course be maintained coherent. In order to impose that \nmarked states are not lost, we consider M i to be a (S2, m)-LCM. Now, the last step is to check that \nall processes have guessed the same sequence of write operations and the same ordering of their execution. \nFor that, each machine makes visible the transitions cor\u00adresponding to its own write operations, as well \nas to the guessed write operations (concerning the other processes), and then, the product of these machines \nis taken with synchronization on the al\u00adphabet of write operations. In fact, if the machines agree on \nthe se\u00adquence of write operations, they have necessarily stored the same sequence of states in their \nchannels. Although each channel is lossy (and the different channels may loose different elements), the \nse\u00adquence of observations made by each process (using the informa\u00adtions in its own channel and control \nstate) is guaranteed to be sound. Therefore, the reachability problem in the original system is re\u00adducible \nto a reachability problem in a lossy channel machine. In or\u00adder to be able to present the correctness \nproof (which will be given in the next section), we need to label also update transitions (and not only \ntransitions corresponding to write operations), although this is not necessary for the decision procedure \nitself. (We will use this labeling to relate sequences of updates and writes along com\u00adputations.) Let \nus now give the formal description of the reduction. 5.1 Constructing the machines M i Let i . [n]. \nThen, M i =(Qi, {ci}, S, L, Di) where: Qi = Pi \u00d7 M \u00d7 M where M = Dm .  ci is the single channel of \nM i.  S = S1 . S2 where S1 =[n] \u00d7 [m] \u00d7 Dm and S2 = S1 \u00d7{.}.  L = Lw . Lupd . Larw where:  Lw = {w(k, \nxj , d) : k . [n], j . [m], d . D}  Larw = {arw(k, xj, d, d' ) : k . [n], j . [m], d, d'. D}  Lupd \n= {upd(k, xj, d) : k . [n], j . [m], d . D}   Di is the smallest set of transitions such that .p, p \n'. Qi, and .dc, dg . M, nope, ci:S|nop Nop: If p- -.ip ' then ( p, dc, dg)- -----.Di ( p, dc, dg) op \nWrite to store: If p--.ip ', where op = w(i, xj, d) for some j . [m] and d . D, then for every d . M, \nop, (a,.).ci |ci [a/(a,.)]!a ' ( p, dc, dg)---------------.Di ( p ' , dc, d' g) op, ci :Q |ci !a ' ( \np, dc, dg)--------.Di ( p ' , dc, d' g) ,and),.)g'i, j, d((= 'd],a . .dg[ j= ' where a =(i, j, d), d \ng Q = S \\ ({i}\u00d7{ j}\u00d7 M). Guess write: .k . [n]. k = i, . j . [m], .d . D, w(k,xj ,d), ci :S|ci !a ( \np, dc, dg)- ----------.Di ( p, dc, dg' ) .)g'd] and a =(k, j, d . .dg[ j= ' where d g Update: .k . \n[n], . j . [m], .d . M, op, ci :S|ci ?(k, j,d) ( p, dc, dg) -----------.Di ( p, d' c, dg) op, ci :S|ci \n?((k, j,d),.) ( p, dc, dg) -------------.Di ( p, d' c, dg) .]d . .dc[ j= ' where op = upd(k, xj, d[ \nj]) and d c r(i,xj ,d) Read: If p-----.ip ' for some j . [m] and d . D, then .d . M. d[ j]= d, e, (a,.).ci \n|nop ( p, dc, dg)---------.Di ( p ' , dc, dg) . Di e, ci:Q |nop ( p, d, dg)-------.Di ( p ' , d, dg) \nwhere a =(i, j, d) and Q = S \\ ({i}\u00d7{ j}\u00d7 M). arw(i,xj ,d,d' ) ARW: If p--------.ip ' for some j . [m] \nand d, d'. D, then .d . M. d[ j]= d, arw(i,xj ,d,d' ), ci =e|nop ( p, d, d)- -------------.Di ( p ' , \nd' , d' ) .] 'd . .d[ j= ' where d 5.2 Composing the machines M i To simulate the system N , we consider \nfor each i . [n] the (S2, m)\u00ad ' LCM M i obtained from M i by substituting each transition label arw(k, \nxj, d, d' ) by a label w(k, xj, d' ), and each label upd(k, xj, d) ' by e, and then we take simply the \n. product of the machines M i. This ensures that the machines agree on the sequences of write operations \nperformed in the simulated system. (Here atomic read\u00adwrite operations are also considered as write operations.) \nThe precise link between N and the so obtained (S2, m)-LCM is given by the following proposition: PROPOSITION \n4. Let p, p '. P, and let d, d'. M. Then, n \\ (p, d, en). * (p ' , d' , en)iff (LT(S2,m)(M i)[sw ])|Lw \n= 0/ N (qi,q ' i )i=1 where, for every i . [n], qi =(p[i], d, d) and q' i =(p ' [i], d' , d' ), and sw \n=(w(k, xj, d' )/arw(k, xj, d, d' ))k.[n]; j.[m];d,d'.D. Theorem 1 follows immediately from Proposition \n4. The proof of this proposition is presented in the Section 6. 5.3 The case of PSO We prove the same \nresult as Theorem 1 for (w . r/w)-relaxed memory systems. It is indeed again possible for these systems \nto reduce the state reachability problem to the control state of lossy channel machines. The reduction \nis even simpler in this case. In fact, while turning store buffer to lossy channels is unsound for TSO \nsystems, it can be shown that this is actually possible for PSO. Consider again the example given in \nthe beginning of the proof of Theorem 1. This time, since we are considering the PSO se\u00admantics, the \noperations w(x, 1) and w(y, 1) are stored in different buffers. Then, it is possible to reach the state \n( p2, p ' 2, x = 1, y = 0) since it is possible to update the variable x before the variable y. Therefore, \nloosing the operation w(y, 1) does not lead in this case to an unsound state. In general, since all the \nwrite operations in a same channel concern a same variable, skipping some operations can be seen as equivalent \nto executing a sequence of updates to a same variable, and therefore, the reached state corresponds to \nthe last update to this variable (and it is necessarily sound). Some care has to be taken, however, concerning \nthe last operation in the buffer. If the process using this buffer does not read on its corresponding \nvariable (as in the example above), then loosing this operation is not a problem. However, to simulate \nin general the read operations, the last write operation in each buffer must be kept since the process \nmust read its value if this operation has not been executed yet. Then, by marking the last symbol in \neach channel and considering it as a strong symbol, the translation to lossy channel machines is straightforward. \nTHEOREM 2. The state reachability problem is decidable for (w . r/w)-relaxed memory systems.  6. Correctness \nproof We present the proof of Proposition 4 in three steps. First we relate the reachability problem \nin (w . r)-relaxed memory system to the reachability problem in perfect channel ma\u00adchines. We show that \nchecking state reachability in N is equivalent to check the control state reachability in the product \nof the M i s, seen as perfect channel machines, when they are synchronized over the udpate transitions \n(see Proposition 5). Showing that the product of the channel machines simulates N is rather straightforward. \nThe reverse direction is proved by establishing a kind of weak simula\u00adtion relation between the con.gurations \nof the two systems. Then, we observe that when the M i s are considered as perfect channel machines, \nthe reachability problem in their synchronous product over update transitions, and the same problem considered \nin the synchronous product over write transitions, are mutually re\u00adducible to each other (see Proposition \n6). (We consider that atomic read-writes are considered both as writes and updates.) This is sim\u00adply \ndue to the fact that for a perfect channel the sequence of inputs is always equal to the sequence of \noutputs. Finally, we prove that checking the reachability problem in the synchronous product of the perfect \nmachines M i over the write transitions is equivalent to checking the same problem in the syn\u00adchronous \nproduct of the lossy channel machines M i over the write transitions (see Proposition 7). The proof is \nbased on the fact that our encoding of the memory states stored in the channels is robust w.r.t. lossyness. \nLet us state these fact more formally. We need .rst to in\u00adtroduce a notion of consistent con.guration. \nA con.guration (( p, dc, dg), u). Con f (M i) is consistent if, either u = e and dc = dg, or u .{(k, \nj, dg)w : k = i, j . [m], w . S*}, or u . {(i, j, dg),.)w : j . [m], w . S*}. Consistency means simply \nthat the value of the memory state obtained after executing the oper\u00adations in the buffer coincides with \nthe one encoded in the con\u00adtrol state of the con.guration. In all the relations between sys\u00adtems described \nabove, the con.guration consistency of the channel machines is assumed. This is not a restriction since \ninitially we consider con.gurations of the form (( p, d, d), en) that are clearly consistent, and it \ncan easily be checked that the transitions in each M i preserve consistency.  Now, let us consider the \nfollowing notation. For h .{w, upd}, let fh be the mapping from L* to L* h such that, for every u . L* \n, fh(u)=(u[sh])|Lh where sh =(h(k, xj, d' )/arw(k, xj, d, d' ))k.[n]; j.[m];d,d' .D This de.nition is \ngeneralized to sets of words. We state hereafter the relation between the reachability prob\u00adlems in N \nand in the product of the perfect channel machines M i. PROPOSITION 5. Let p, p '. P and d, d'. M. Then, \n(p, d, en) .* N T n (p ' , d' , en) iff i=1 fupd(T(qi,qi ' )(M i)) = 0/ where, for every i . [n], qi \n=(p[i], d, d) and q' i =(p ' [i], d' , d' ). The only if direction is easy and omitted here. To prove \nthe if direction we need to de.ne a mapping which converts consistent con.gurations in the product of \nthe M i s to con.gurations in N . Let d . M, and for each i . [n], let gi = (qi, ui) be a con\u00adsistent \ncon.guration of M i such that qi[2]= d. Then, we de.ne \u00b5(g1,..., gn) to be the con.guration (p, d, u) \nof N such that, for every k . [n], p[k]= qk[1] and u[k]=(ui[s1][s2])|Bi , where s1 = (a/(a,.))a.S1, and \ns2 = ((l, j, d[ j])/(l, j, d))l.[n]; j.[m];d.M. (Re\u00adcall that Bi = {i}\u00d7 [m] \u00d7 D.) Then, Proposition 5 \nfollows from the two next lemmas. LEMMA 1. For every i . [n], let gi = (qi, ui) be a consistent con.guration \nof M i. Assume that .i, l . [n]. qi[2]= ql [2]. Then, * li M i w ' ' .i . [n], .gi . Conf (M i), if gi \n=. gi for some li . L* , then '' \u00b5(g1,..., gn) .* \u00b5(g1,..., g N n). ' LEMMA 2. For every i . [n], let \ngi = (qi, ui) and g = (q ' i, ui') be i consistent con.gurations of M i, and let li . Lupd . Larw . Assume \nthat .i, j . [n]. qi[2]= qj[2],q ' i[2]= q ' j[2], and fupd(li)= fupd(l j). li ' '' Then, .i . [n], if \ngi =.M i gi, then \u00b5(g1,..., gn) .N \u00b5(g1,..., gn). Lemma 1 and 2 state that \u00b5de.nes a simulation relation \nbetween N and the product of the M i synchronized on the update transitions. Lemma 1 concerns the case \nof sequences of transitions without updates, whereas Lemma 2 concerns the case where the M i s must synchronize \non some update operation. The proofs of these lemmas are not dif.cult and are omitted here. The following \nproposition follows, as said in the introduction of this section, from the de.nition of perfect .fo channels \n(i.e., the sequence of inputs is equal to the sequence of outputs). PROPOSITION 6. .i . [n], .q, q '. \nQi, fupd(T(q,q ')(M i)) = 0/ iff fw (T(q,q ')(M i)) = 0/. Finally, we establish the link between computations \nin perfect channel and lossy channel machines. PROPOSITION 7. For every i . [n], and for every q, q '. \nQi, fw (T(q,q ')(M i)) = fw (LT(S2,m)(M i)). (q,q ') The proof of the left-to-right inclusion is straightforward. \nFor the other direction, we establish the following fact which states that there is a simulation relation \nbetween the lossy and the perfect channel systems. LEMMA 3. For every consistent con.gurations (q, u), \n(q ' , u ') of l M i, and for every l . Le, if (q, u) =.(M i,S2 ,m) (q ' , u '), then .v . S* s.t. u \njm v and (q, v) is consistent, .v '. S* , .l . L* s.t. (1) S2 (q ' , v ') is a consistent, (2) u'jmv \n', (3) fw (l)= fw (l), and (4) S2 * (q, v) =l .M i (q ' , v '). Proof. For every j . [m], let Q j = S \n\\ ({i}\u00d7{ j}\u00d7 M) be a set of labels and G = g .{ci : S, ci : Q j, (a,.) . ci | j . [m], a . S1} be a set \nof guards. It is easy to see that, for any guard g . G, if u |= g then v |= g since u jmv. S2 l Now, \nlet us suppose that (q, u) =.M i (q ' , u '). This implies l,g|op that there is a transition d = q----.Diq \n' such that u |= g, and [[op]](u, u ' ). Then, we consider the four cases depending on the type of the \nlabel l: If l = e, then op = nop, u = u ', and g . G. This implies that l (q, v) =.M i (q ' , v) because \nv |= g. If l . Lw , then op = ci[s]!a ', for some a '. S and substitution l s, u ' = a '\u00b7u[s], and g \n. G. This implies that (q, v) =.M i (q ' , v ') with v ' = a '\u00b7 v[s] since v |= g. If l . Larw , then \nop = nop, g .{ci = e}, q[2]= q[3], and u ' = u = e. This implies that v can be any sequence in S* 1 since \nu jmv. Moreover, the perfect channel machine M i can apply a S2 sequence of update operations in order \nto empty its buffer. This l' means that M i has a run (q, v) =.M i (q, e) where l'. L* , upd since (q, \nv) is consistent and q[2]= q[3]. From the con.guration (q, e), the perfect channel machine M i can apply \nthe transition l d to reach the con.guration (q ' , e). Thus, (q, v) =.M i (q ' , e) is a .nite run of \nM i where l = l' l. Notice that we have indeed fw (l)= fw (l). If l . Lupd, then op = ci?a ' for some \na '. S, g .{ci : S}, and u = u '\u00b7 a '. Since u jmv, there are w . S1 * and v '. S* S2 such that v = v \n'\u00b7 a '\u00b7 w and u jmv '\u00b7 a '. Moreover, the perfect S2 channel machine M i can apply starting from (q, \nv) a sequence of update operations corresponding to the sequence w. This means that M i has the following \nrun (q, v) =l'(q '' , v '\u00b7 a ') .M i .Now,)d] if w(0)=(k, j, d . .2]=q[2[ ''and q *L.'where l upd from \nthe con.guration (q '' , v '\u00b7 a '), the machinne M i can apply * a ' l (q ' , v ') the transition d since \nv '\u00b7 |= g. Therefore, (q, v) =.M i is a .nite run of M i, where l = l' l. Notice that we have again fw \n(l)= fw (l). o Let qi, q ' i . Qi, and let r be a .(M i,S2 ,m)-run of the lossy channel machine M i between \nqi and q ' i. Then, using Lemma 3 it is possible to construct a .M i -run r ' of the perfect channel \nmachine M i from qi to q ' i such that r and r ' have the same sequence of write transitions, i.e., fw \n(r|L )= fw (r '|L ). This terminates the proof of Proposition 7.  7. Simulating lossy channels by TSO/PSO \nWe show hereafter that basic lossy channel machines can be simu\u00adlated by (w . r)-relaxed memory systems. \nTHEOREM 3. The control state reachability problem as well as the repeated control state reachability \nproblem for basic lossy channel machines are reducible to their corresponding problems for (w . r) relaxed \nmemory systems. Proof. Let M =(Q,C, S, L, D) be a basic LCM. We assume w.l.o.g. that M has a single channel \nc (since every basic LCM can be simulated by a single-channel basic LCM [Abdulla and Jonsson 1993]), \nand that L = 0/. We simulate M using a (w . r)-relaxed memory system with two processes P1 and P2 and \ntwo variables x1  write . . . (1, 1, a) . (1, 1, b) . . . .  update read read update write x2 . . \n. (2, 2, c) . (2, 2, d) . . . . Figure 2. The communication graph of a (w . r)-relaxed memory system \nsimulating a basic lossy channel machine and x2. As shown in Figure 2, the process P1 (resp. P2) writes \nto the variable x1 (resp. x2) and reads from the variable x2 (resp. x1). A send operation c!a of M is \nsimulated by a write operation of the value a to the variable x1 by the process P1. A receive operation \nc?a of M is simulated by a read operation of the value a from x2 by P1. (A nop operation of M is simulated \nby a nop operation of P1.) The role of P2 is to transfer the successive values of x1 to x2 (so that they \ncan be read by P1 in the FIFO order). To avoid multiple reads of the same value of x2 by P1 (which would \ncorrespond to multiple receptions in M of a same message), we introduce a marker . such that every read \n(resp. write) of a value a . S (by any of the processes) is followed by a read (resp. write) of .. Then, \nthe sequence of values written to x1 and x2 alternate values from S with .. This ensures that a write \noperation of P1 (resp. P2) can validate at most one read operation of P2 (resp. P1). Observe that, however, \nthe read operations performed by P2 can miss some of the values written by P1, and conversely. This is \ndue to the asynchrony of the two processes (i.e., N can execute pending writes more often than the reads). \nTherefore, the sequence of values transfered to x2 by P2 (and that can be read by P1) can be any subsequence \nof the sequence of values written by P1 to x1. Moreover, the sequence of values read by P1 can also be \nany subsequence of the sequence of values written by P2 to x2. Therefore, P1 can read from x2 any subsequence \nof values written by itself to x1. This encodes the lossyness of the channel of M . Formally, let D = \nS .{.} be the .nite data domain and X = {x1, x2} be the set of two variables valued in D. The (w . r)\u00adrelaxed \nmemory system N =(P1, P2) is de.ned from M as follows: P1 =(P1, D1) is a .nite-state process where: (1) \nP1 = Q . (Q \u00d7 {!, ?}) is a .nite set of control states, and (2) D is the smallest set of transition rules \nsuch that: e, c:S|nopnop Nop: If q------.D q ', then q- -.1 q ' e, c:S|c!a Send: If q------.D q ', \nthen w(1,x1,a) w(1,x1,.) q------.1(q ' , !) and (q ' , !) - ----.1 q ' e, c:S|c?a Receive: If q------.D \nq ', then r(1,x2,a)r(1,x2,.) q- ----.1(q ' , ?) and (q ' , ?) -----.1 q ' P2 =(P2, D2) is a .nite-state \nprocess where: (1) P2 = {p1, p2}. (D \u00d7{!}) is a .nite set of control states, and (2) D2 is the smallest \nset of transition rules such that for every symbol a . S, we have: r(2,x1,a)w(2,x2,a) p1- ----.2(a, !)(a, \n!)------.2 p2 r(2,x1,.)w(2,x2,.) p2-----.2(., !)(., !)- ----.2 p1 Theorem 3 is an immediate consequence \nof the following lemma: LEMMA 4. Let q, q '. Q. The control state q' is (in.nity often) reachable by \nM from q iff (p ' , d) is (in.nity often) reachable by N from (p, d) where p =(q, p1), p ' =(q ' , p1), \nd =(., .). The proof of the lemma above is straightforward. It consists in establishing a bisimulation \nrelation between N and M . o From Theorem 3, [Schnoebelen 2002] and [Abdulla and Jons\u00adson 1994], we deduce \nthat: THEOREM 4. The state reachability problem for (w . r)-relaxed memory systems is non-primitive recursive, \nand their repeated state reachability problem is undecidable. The same results established above in this \nsection still hold when we consider in addition the w . w relaxation. In fact, in the system N built \nfor the proof of Theorem 3 each process writes to only one single variable, which implies that the behavior \nof N remains the unchanged if we also consider the w . w relax\u00adation. Therefore, our results concerning \nthe TSO model hold for its w . w relaxation (PSO) as well. THEOREM 5. The state reachability problem \nfor (w . r/w)-relaxed memory systems is non-primitive recursive, and their repeated state reachability \nproblem is undecidable.  8. Adding the r . r/w relaxation In addition to the w . r relaxation, we consider \nnow that a read or a write operations on some variable xj can overtake a read operation (by the same \nprocess) if the latter concerns a variable different from xj. As before, we consider that atomic read-write \noperations cannot permute with any operation, and we also consider the cancellation rule concerning a \nread that immediately follows a write of the same value on the same variable (by the same processes). \n 8.1 An operational model We de.ne hereafter an operational model to capture this semantics. Our model \nhas again one buffer per process, but this time the buffer is used to store write operations as well \nas read operations. Write operations are stored as before in the buffer to allow overtakes by read operations \n(Write to store). When a write operation to a variable xj is present in the buffer of a process Pi, assume \nthat w(i, xj, d) is the last of such an operation, then if a read operation r(i, xj, d) is the next operation \nperformed by Pi concerning xj, this operation is validated immediately (Read own write). If the previous \nsituation does not hold and a read operation r(i, xj, d) is performed, then the read operation is stored \nin the buffer. This corresponds to guessing that xj will have the value d sometime in the future (Guess). \nThe guess is validated when r(i, xj, d) becomes the .rst operation on xj in the buffer, and the value \nassigned to xjin the global memory at that time is precisely d (Validate). Finally, memory updates are \ndone by executing an operation w(i, xj, d) which must be the .rst (read or write) operation in the buffer \nof Pi concerning xj, i.e., it can only be preceded by read operations on different variables (Update). \nThe formal de.nition of the model is as follows. Let P = P1 \u00d7 \u00b7\u00b7\u00b7\u00d7 Pn and for every i . [n], let Bi = \n{w, r}\u00d7 {i}\u00d7[m] \u00d7D.A con.guration of N is a tuple (p, d, u) where p . P, d . M, and u . B1 * \u00d7\u00b7\u00b7\u00b7\u00d7 Bn* \n. We de.ne the transition relation .N on con.gurations of N to be the smallest relation such that, for \nevery p, p '. P, for every u, u '. B* 1 \u00d7\u00b7\u00b7\u00b7\u00d7B* n, and for every d, d'. M, we have (p, d, u).N (p ' , \nd' , u ') if there is an i . [n], and there are p, p '. Pi, such that ,andoneofthefollowingcaseshold:] \n' p . .p[i= ' p[i]= p, p nop 1. Nop: p- -.ip ' , d = d', and u = u ' . w(i,xj ,d) .]]w, i,j, d)u[i( \n. .u[i= ' u,and'd = d, ' ip.- ----pWritetostore:2. 3. Update: p = p ', and . j . [m]. .d . D. .u1, u2 \n. B* i such that: (a) u[i]= u1(w, i, j, d)u2, and .(op, i, k, d' ) . u2. (op = r and k = j), ,]d . .d[ \nj= 'd(b) (c) u ' [i]= u1u2, and .k = i. u ' [k]= u[k] r(i,xj ,d) 4. Read: p-----.ip ' , d = d', and \nRead own write: u = u ' if .u1, u2 . B* i such that: (a) u[i]= u1(w, i, j, d)u2, and (b) .(op, i, k, \nd' ) . u1. k = j, or otherwise.]]r, i,j, d)u[i( . .u[i= ' uGuess: 5. Validate: p = p ' , d = d', and \n. j . [m]. .d . D. .u1, u2 . Bi * s.t. (a) u[i]= u1(r, i, j, d)u2, and .(op, i, k, d' ) . u2. k = j, \n (b) d[ j]= d,  (c) u ' [i]= u1u2, and .k = i. u ' [k]= u[k]. arw(i,xj ,d,d' ) 6. ARW: p--------.ip \n' , u[i]= e, u = u ', and d[ j]= d, and d' .] 'd . .j[d= to x2 the index ij, and (4) reads ij from x4, \nfor j ranging backward from k to 1. Moreover, each write (resp. read) operation to (resp. from) a variable \nis followed by a write (resp. read) operation of the marker .. The insertion of the markers allows to \nensure that a written value to a variable by one of the processes can be read at most once by the other \nprocess. In parallel, process P2 also guesses the solution of PCP and performs the same operations as \nP1, except that it writes (resp. reads) symbols of the words vij and the indices ij to x3 and x4 (from \nx1 and x2), respectively. Then, we prove that PCP has a solution if and only if it is possible to reach \na state of the system N where both store buffers are empty. In other words, a full computation of N checks \nthat the two processes have guessed the same sequence of indices and that this sequence is indeed a solution \nfor the considered PCP instance. The only if direction can be shown using the fact that the ordering \nin the buffers between reads and writes (as well as between reads and other reads) can be relaxed, it \nis possible to construct a run of the N where the execution of each write done by one of the processes \nis immediately followed by its corresponding read operation done by the other process. The argument for \nthe reverse direction is the following: If there is a run which empties both buffers, then it can be \nseen that, due to the fact that a read can validate at most one write, the sequence of read symbols by \nprocess P2 is a subword of the sequence of written symbols by P1, and vice versa. The same holds also \nfor We call {w . r, r . r/w}-relaxed memory system a concurrent the sequences of indices guessed by both \nprocesses. (Here again system N .* N with the operational semantics de.ned by .N . Let permuting operations \nin the buffers is necessary in order to match denote as usual the re.exive-transitive closure of .N \n. The reads by one of the processes to writes by the other one.) These state reachability, and the repeated \nstate reachability problems are de.ned as in the case of TSO systems in Section 3.4.  8.2 Adding the \nw . w relaxation Again, the w . w relaxation can be taken into account in addition to {w . r, r . r/w} \nsimply by associating to each process m dif\u00adferent buffers instead of a single one, one per variable, \nsimilarly to the relaxation from TSO to PSO.  9. (Un)decidability results We prove in this section that \nthe addition of the r . r/w relaxation to either TSO or PSO models leads to the undecidability of the \nstate reachability problem. On the other hand, if we consider models where the number of (guessed) reads \nstored in the buffers is always bounded, this problem becomes decidable. 9.1 The general case We prove \nhereafter the following fact: THEOREM 6. The state reachability problem is undecidable for {w . r, r \n. r/w}-relaxed memory systems. The proof of Theorem 6 is by a reduction of the Post s Cor\u00adrespondence \nProblem (PCP), well-known to be undecidable [Post 1946]. We recall that PCP consists in, given two .nite \nsequences {u1,..., un} and {v1,..., vn} of nonempty words over some alpha\u00adbet S, checking whether there \nis a sequence of indices i1,..., ik . [n] such that ui1 \u00b7\u00b7\u00b7uik = vi1 \u00b7\u00b7\u00b7vik . Then, let {u1,..., un} \nand {v1,..., vn} be an instance of PCP. We construct a system N with two processes P1 and P2 sharing \na set of four variables X = {x1, x2, x3, x4} such that, two speci.c states in M are related by a run \nif and only if PCP has a solution for the considered instance. The idea of the reduction is as follows: \nProcess P1 guesses the solution of PCP as a sequence of indices i1,..., ik and performs iteratively a \nsequence of operations: It (1) writes successively to x1 the symbols of uij , (2) reads from x3 the symbols \nof uij , (3) writes facts imply that the processes have indeed guessed the same (right) solution to the \ngiven instance of PCP. Let us de.ne more formally the reduction. Let D = S.{., -} . [n] be the set of \ndata manipulated by processes P1 and P2. To simplify the presentation, we need to introduce some nota\u00adtions. \nLet i . [2], j . [4], s . D* , op .{w, r}, m = length(s) and op(i,xj ,s) such that m = 2. We use the \nmacro transition p------.ip ' to op(i,xj ,s(1))denote the sequence of consecutive transitions p- ------.ip1, \nop(i,xj ,s(l+1))op(i,xj ,s(m)) pl ---------.i pl+1 for all l . [m-2], and pm-1 --------.ip ' where p1,..., \npm are extra intermediary control states of Pi that are not used anywhere else (and that we may omit \nfrom the set of con\u00adtrol states of Pi). We use also (op, i, j, s) to denote the fact that the store buffer \nof Pi contains the following sequence of consecutive operations (op, i, j, s(1)) \u00b7\u00b7\u00b7(op, i, j, s(m)). \nLet n be a mapping from S* to D* such that for every word u = a1 \u00b7\u00b7\u00b7am . S* , n(u)= . \u00b7 a1 \u00b7\u00b7\u00b7. \u00b7 am. \nThen, a computation of the process P1 (resp. P2) is a sequence of phases where each phase consists in \nthe following operations: 1. Choose a number l . [n]: nopnop p- -.1 pl (resp. q- -.2 ql ) 2. Write the \nsequence of data n(ul ) (resp. n(vl )) to x1 (resp. x3): w(1,x1,n(ul ))w(2,x3,n(vl )) pl --------.1 p1 \n(resp. ql --------.2 q1 ll ) 3. Read the sequence of data n(ul ) (resp. n(vl )) from x3 (resp. x1): r(1,x3,n(ul \n))r(2,x1,n(vl )) p1 - ------.1 p2 (resp. q1 - ------.2 q2 l lll ) 4. Write the sequence of data . \u00b7 l \nto x2 (resp. x4): w(1,x2,.\u00b7l)w(2,x4,.\u00b7l) p2 - -----.1 p3 (resp. q2 - -----.2 ql 3) l ll 5. Read the \nsequence of data . \u00b7 l from x4 (resp. x2): r(1,x4,.\u00b7l) r(2,x2,.\u00b7l) p3 ------.1 p (resp. q3 ------.2 \nq) ll  Next, we establish the link between the state reachability prob\u00adlem for the {w . r, r . r/w}-relaxed \nmemory system N and the existence of a solution for the PCP. LEMMA 5. There is i1,..., ik . [n] such \nthat ui1 \u00b7\u00b7\u00b7uik = vi1 \u00b7\u00b7\u00b7vik if and only if the con.guration (( p, q), (., ., ., .), e2) is reachable \nin N from the initial con.guration (( p, q), (-, -, -, -), e2). Proof. (The if direction:) Assume that \n(( p, q), (., ., ., .), e2) is reachable in N from (( p, q), (-, -, -, -), e2). This means that all the \nread operations of P1 and P2 have been validated. Then, assume that ik,..., i1 is the sequence of indices \nchosen by P1 and that jh,..., j1 is the sequence of indices chosen by P2. We use the facts that (1) write \nand read operations by a same process to a same variable cannot be reordered, and that (2) each write \noperation of P1 can only validate a unique read operation of P2 and vice-versa (but of course some written \nvalues can be missed since processes are asynchronous), to show that the following relations hold: ui1 \nui2 \u00b7\u00b7\u00b7uik j vj1 vj2 \u00b7\u00b7\u00b7v jh .  vj1 vj2 \u00b7\u00b7\u00b7v jh j ui1 ui2 \u00b7\u00b7\u00b7uik .  i1i2 \u00b7\u00b7\u00b7ik j j1 j2 \u00b7\u00b7\u00b7 jh.  j1 \nj2 \u00b7\u00b7\u00b7 jh j i1i2 \u00b7\u00b7\u00b7ik.  This implies that ui1 ui2 \u00b7\u00b7\u00b7uik = vj1 vj2 \u00b7\u00b7\u00b7v jh and i1i2 \u00b7\u00b7\u00b7ik = j1 j2 \u00b7\u00b7\u00b7 \njh. (The only-if direction:) Assume that there is a sequence of in\u00addices i1,..., ik . [n] such that ui1 \n\u00b7\u00b7\u00b7uik = vi1 \u00b7\u00b7\u00b7vik . Then, we can construct the following run of N from the initial con.guration (( \np, q), (-, -, -, -), e2) to the con.guration (( p, q), (., ., ., .), e2): First, P1 chooses the sequence \nof indices ik,..., i1 and stores in its buffer seq1 \u00b7\u00b7\u00b7seqk where, for every l . [k], seql is the sequence \nof operations stored by P1 during its lth phase (i.e., (r, 1, 4,. \u00b7 il )(w, 1, 2,. \u00b7 il )(r, 1, 3, n(uil \n))(w, 1, 1, n(uil ))).  Then, P2 chooses the sequence of indices ik,..., i1 and stores in its buffer \nseq ' 1 \u00b7\u00b7\u00b7seq ' k where for every l . [k], seq ' is the l sequence of operations stored by P2 during \nits lth phase (i.e., (r, 2, 2,. \u00b7 il )(w, 2, 4,. \u00b7 il )(r, 2, 1, n(vil ))(w, 2, 3, n(vil ))).  Finally, \nN adopts the following run in order to execute the writes and validate the reads in the buffers. This \nrun is divided into two steps:  In the .rst step, N performs alternately the following ac\u00adtions: (1) \nexecute the .rst write operation in the buffer of P1 concerning some variable x say, and then (2) validate \nthe corresponding read operation in the buffer of P2. This read operation is the .rst read operation \non x in the buffer of P2. However, this read operation may occur behind some other operations in the \nbuffer, but by construction, they are all on other variables. Therefore the read operation can be vali\u00addated \ndue to the relaxed memory semantics we consider. The relaxation rules are also necessary to be able to \ntake successively write operations in the buffer of P1 since this requires overtaking the reads that \noccur between the writes.  In the second step, the role of P1 and P2 are interchanged.   This terminates \nthe proof of Lemma 5. o Finally, Theorem 6 is an immediate consequence of Lemma 5. Let us again mention \nthat the same result holds when we addition\u00adally consider the w . w relaxation. In fact, the system N \nwe con\u00adstruct in the proof of Theorem 6 can be (re)used with the more relaxed semantics. The effect of \nthe relaxation is simply to split the buffer of each of the processes into four different buffers, but \nthis does not affect the reasoning concerning the relations between the sequences of reads and their \ncorresponding sequences of writes. THEOREM 7. The state reachability problem is undecidable for {w . \nr/w, r . r/w}-relaxed memory systems.  9.2 Bounded-guess r . r/w relaxation The undecidability result \nin the previous section uses the fact that it is possible to perform an unbounded number of guesses on \nread values before validating them. Therefore, a natural idea is to bound the number of guesses made \nby a process at each time. This corresponds to impose a bound on the number of reads stored in each buffer \n(without bounding the number of writes in the buffers). Let us call bounded-guess relaxed memory systems \nthe so restricted systems. (It is of course straightforward to adapt the models we have de.ned previously \nto impose this restriction for a given bound on the number of reads in each buffer.) Under the bounded-guess \nrestriction, the state reachability prob\u00adlem becomes decidable. The reason is that it is possible to \nconstruct lossy channel machines for these systems by adapting the construc\u00adtion of Section 5. Indeed, \nit suf.ces to consider that the stored read operations in the channels are strong symbols (in the sense \nthat they cannot be lost). This is clearly possible since the number of these reads is bounded by hypothesis. \nTHEOREM 8. The state reachability problem for bounded-guess {w . r, r . r/w}-relaxed memory systems is \ndecidable. The same holds for bounded-guess {w . r/w, r . r/w}-relaxed memory systems.  10. Conclusion \nWe have investigated the boundary between decidability and unde\u00adcidability for the veri.cation problem \nof programs under various weak memory models. We have considered models classi.ed ac\u00adcording to the type \nof the order relaxations they involve (following the style of [Adve and Gharachorloo 1996]). We have \nshown that the reachability problem is decidable for w . r-relaxed memory systems (TSO) as well as for \ntheir w . w relaxation (PSO). This result is obtained through a non-trivial translation to lossy channel \nmachines. We have shown that, however, when the r . r/w relax\u00adation is added to these models, the reachability \nproblem becomes undecidable. On the other hand, if we consider that the number of read operations that \nare delayed (overtaken by other operations) is always bounded (i.e., at any point in time but not necessarily \nif we consider the whole computation), then this problem is decidable, since in this case it can again \nbe reduced to the reachability prob\u00adlem for lossy channel machines. Moreover, we have established the \ncomplexity of the reachabil\u00adity problem for these memory models (when it is decidable). We have proved \nthat lossy channel machines can be simulated by TSO (as well as by its relaxations we consider such as \nPSO), which im\u00adplies that the reachability problem for these models is non-primitive recursive. This \nshows that there is (in theory) an important jump in the complexity of the reachability problem when \nmoving from the SC model (PSPACE-complete) to weak memory models. However, the high theoretical complexity \nis not necessarily an obstacle for exploiting our decidability results in practice. Indeed, it could \nbe possible to use for instance ef.cient veri.cation techniques, com\u00adbining effective symbolic representations \nand iterative under/upper approximate analysis, that are complete for well-structured sys\u00adtems such as \nlossy channel machines (see, e.g., [Geeraerts et al. 2006, Ganty et al. 2006]). The design of ef.cient \ntools based on these techniques that are tailored for the automatic veri.cation of programs/algorithms \nunder weak memory models is a challenging topic for future work.  The ability of relaxed memory systems \nto simulate lossy chan\u00adnel machines implies also that the repeated state reachability prob\u00adlem (and therefore \nverifying liveness properties) for these systems is undecidable. Investigating conditions under which \nliveness prop\u00aderties can be automatically and ef.ciently veri.ed for weak mem\u00adory systems is again an \ninteresting topic for future work.  Acknowledgments The two .rst authors were partially supported by \nthe project ANR\u00ad06-SETI-001 AVERISS.  References P. Abdulla and B. Jonsson. Verifying programs with \nunreliable channels. In LICS, pages 160 170. IEEE Computer Society, 1993. P. Abdulla and B. Jonsson. \nUndecidable veri.cation problems for programs with unreliable channels. In ICALP, LNCS 820, pages 316 \n327. Springer, 1994. P. Abdulla and B. Jonsson. Verifying programs with unreliable channels. Inf. Comput., \n127(2):91 101, 1996. P. Abdulla, K. Cerans, B. Jonsson, and Y-K. Tsay. General decidability theorems \nfor in.nite-state systems. In LICS, pages 313 321, 1996. S. Adve and K. Gharachorloo. Shared memory consistency \nmodels: a tutorial. Computer, 29(12):66 76, 1996. R. Alur, K. McMillan, and D. Peled. Model-checking \nof correctness conditions for concurrent objects. In Logic in Computer Science (LICS), pages 219 228, \n1996. S. Baswana, S. Mehta, and V. Powar. Implied set closure and its application to memory consistency \nveri.cation. In Computer-Aided Veri.cation (CAV), 2008. S. Burckhardt and M. Musuvathi. Effective program \nveri.cation for relaxed memory models. In Computer-Aided Veri.cation (CAV), pages 107 120, 2008. Extended \nVersion as Tech Report MSR-TR-2008-12, Microsoft Research. S. Burckhardt, R. Alur, and M. Martin. CheckFence: \nChecking consistency of concurrent data types on relaxed memory models. In PLDI, pages 12 21, 2007. S. \nHangal et al. TSOtool: A program for verifying memory systems using the memory consistency model. In \nInternational Symposium on Computer Architecture (ISCA), 2004. A. Finkel and Ph. Schnoebelen. Well-structured \ntransition systems everywhere! Theor. Comput. Sci., 256(1-2):63 92, 2001. P. Ganty, J. F. Raskin, and \nL. Van Begin. A complete abstract interpretation framework for coverability properties of WSTS. In VMCAI \n06, LNCS 3855, pages 49 64. Springer, 2006. G. Geeraerts, J. F. Raskin, and L. Van Begin. Expand, enlarge \nand check: New algorithms for the coverability problem of wsts. J. Comput. Syst. Sci., 72(1):180 203, \n2006. P. B. Gibbons and E. Korach. The complexity of sequential consistency. In Parallel and Distributed \nProcessing, pages 317 325. IEEE, 1992. T. Q. Huynh and A. Roychoudhury. A memory model sensitive checker \nfor C#. In Formal Methods (FM), LNCS 4085, pages 476 491. Springer, 2006. L. Lamport. How to make a multiprocessor \ncomputer that correctly executes multiprocess programs. IEEE Trans. Comp., C-28(9):690 691, 1979. Daan \nLeijen, Wolfram Schulte, and Sebastian Burckhardt. The design of a task parallel library. In OOPSLA, \npage to appear, 2009. Maged Michael, Martin Vechev, and Vijay Saraswat. Idempotent work stealing. In \nPPoPP, pages 45 54, 2009. S. Owens, S. Sarkar, and P. Sewell. A better x86 memory model: x86-TSO (extended \nversion). Technical Report UCAM-CL-TR-745, Univ. of Cambridge, 2009. S. Park and D. L. Dill. An executable \nspeci.cation, analyzer and veri.er for RMO. In Symposium on Parallel Algorithms and Architectures (SPAA), \npages 34 41, 1995. ISBN 0-89791-717-0. E. L. Post. A variant of a recursively unsolvable problem. Bull. \nof the American Mathematical Society, 52:264 268, 1946. A. Roy, C. Fleckenstein, S. Zeisset, and J. Huang. \nFast and generalized polynomial time memory consistency veri.cation. In Computer-Aided Veri.cation (CAV), \n2005. Ph. Schnoebelen. Verifying lossy channel systems has nonprimitive recursive complexity. Information \nProcessing Letters, 83(5):251 261, September 2002. P. Sindhu, J.-M. Frailong, and M. Cekleov. Formal \nspeci.cation of memory models. Technical Report CSL-91-11, Xerox Palo Alto Research Center, 1991. A. \nP. Sistla and E. M. Clarke. The complexity of propositional linear temporal logics. J. ACM, 32(3):733 \n749, 1985. D. Weaver and T. Germond, editors. The SPARC Architecture Manual Version 9. PTR Prentice Hall, \n1994. Y. Yang, G. Gopalakrishnan, G. Lindstrom, and K. Slind. Nemos: A frame\u00adwork for axiomatic and executable \nspeci.cations of memory consistency models. In IPDPS, 2004. doi: 10.1109/IPDPS.2004.1302944.  \n\t\t\t", "proc_id": "1706299", "abstract": "<p>We address the verification problem of finite-state concurrent programs running under weak memory models. These models capture the reordering of program (read and write) operations done by modern multi-processor architectures for performance. The verification problem we study is crucial for the correctness of concurrency libraries and other performance-critical system services employing lock-free synchronization, as well as for the correctness of compiler backends that generate code targeted to run on such architectures.</p> <p>We consider in this paper combinations of three well-known program order relaxations. We consider first the \"write to read\" relaxation, which corresponds to the TSO (Total Store Ordering) model. This relaxation is used in most hardware architectures available today. Then, we consider models obtained by adding either (1) the \"write to write\" relaxation, leading to a model which is essentially PSO (Partial Store Ordering), or (2) the \"read to read/write\" relaxation, or (3) both of them, as it is done in the RMO (Relaxed Memory Ordering) model for instance.</p> <p>We define abstract operational models for these weak memory models based on state machines with (potentially unbounded) FIFO buffers, and we investigate the decidability of their reachability and their repeated reachability problems.</p> <p>We prove that the reachability problem is decidable for the TSO model, as well as for its extension with \"write to write\" relaxation (PSO). Furthermore, we prove that the reachability problem becomes undecidable when the \"read to read/write\" relaxation is added to either of these two memory models, and we give a condition under which this addition preserves the decidability of the reachability problem. We show also that the repeated reachability problem is undecidable for all the considered memory models.</p>", "authors": [{"name": "Mohamed Faouzi Atig", "author_profile_id": "81384612637", "affiliation": "LIAFA, University of Paris Diderot, Paris, France", "person_id": "P1911024", "email_address": "", "orcid_id": ""}, {"name": "Ahmed Bouajjani", "author_profile_id": "81100358502", "affiliation": "LIAFA, University of Paris Diderot, Paris, France", "person_id": "P1911025", "email_address": "", "orcid_id": ""}, {"name": "Sebastian Burckhardt", "author_profile_id": "81350574118", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1911026", "email_address": "", "orcid_id": ""}, {"name": "Madanlal Musuvathi", "author_profile_id": "81100333862", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1911027", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1706299.1706303", "year": "2010", "article_id": "1706303", "conference": "POPL", "title": "On the verification problem for weak memory models", "url": "http://dl.acm.org/citation.cfm?id=1706303"}