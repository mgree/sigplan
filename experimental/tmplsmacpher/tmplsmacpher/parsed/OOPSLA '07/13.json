{"article_publication_date": "10-21-2007", "fulltext": "\n The Causes of Bloat, The Limits of Health Nick Mitchell Gary Sevitsky IBM T.J. Watson Research Center \n19 Skyline Drive Hawthorne, NY 10532 USA {nickm,sevitsky}@us.ibm.com Abstract Applications often have \nlarge runtime memory require\u00adments. In some cases, large memory footprint helps accom\u00adplish an important \nfunctional, performance, or engineering requirement. A large cache, for example, may ameliorate a pernicious \nperformance problem. In general, however, .nd\u00ading a good balance between memory consumption and other \nrequirements is quite challenging. To do so, the develop\u00adment team must distinguish effective from excessive \nuse of memory. We introduce health signatures to enable these distinc\u00adtions. Using data from dozens of \napplications and bench\u00admarks, we show that they provide concise and application\u00adneutral summaries of \nfootprint. We show how to use them to form value judgments about whether a design or implemen\u00adtation \nchoice is good or bad. We show how being indepen\u00addent of any application eases comparison across disparate \nimplementations. We demonstrate the asymptotic nature of memory health: certain designs are limited in \nthe health they can achieve, no matter how much the data size scales up. Fi\u00adnally, we show how to use \nhealth signatures to automatically generate formulas that predict this asymptotic behavior, and show \nhow they enable powerful limit studies on memory health. Categories and Subject Descriptors D.2.8 Metrics \n[per\u00adformance measures] General Terms Memory Footprint, Data Structure Design, Characterization Keywords \nbloat, memory footprint, metrics, limit studies Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. OOPSLA 07, October 21 25, 2007, Montr\u00b4eal, Qu\u00b4ebec, Canada. Copyright \nc . 2007 ACM 978-1-59593-786-5/07/0010. . . $5.00 1. Introduction It is fairly easy these days to design \nand implement a data model in a way that consumes a large amount of memory. For example, we have seen \nJava server applications that require a gigabyte of memory to support a few thousand users. That a data \nstructure is big is of course a sign for concern. We propose that the health of a data structure s use \nof memory depends not so much on its size, but rather on the relationship between actual data and structural \noverhead. The makeup of memory depends on the design of data types, and the way instances of these types \nare glued to\u00adgether into collections [19, 20]. Consider an example data model with entities E1, E2, and \nE3; each instance of E3 has a single byte .eld of actual data, each E2 contains one or more E3 instances, \nand each E1 contains one or more E2 in\u00adstances. Developers must choose how to map this model to a physical \nimplementation. In an object oriented language, one typically maps each entity to a class, and uses a \nstandard collection, such as the Java LinkedList, to store the multi\u00advalued relationships. Unfortunately, \nthis implementation re\u00adsults in an extremely unhealthy heap. With fan-out of 1000 at each level, this \nimplementation s fraction of actual data is only 10%. Furthermore, as Section 4 shows, the fraction of \nactual data can never be better than 10% no matter how many instances of E2 or E3 there are to amortize \nbookkeep\u00ading overheads. In this paper, we .rst introduce a scheme for exposing the underlying causes \nof such poor health. Second, we leverage this scheme to introduce a way to determine whether a data design \nwill ever be good. The Causes of Bloat Depending on the data type design, each instance will use its \nbytes for a variety of purposes. Section 2.1 introduces an instance health categorization sys\u00adtem that \ndivides the bytes of each instance into one of four application-neutral [18] categories: primitive data, \nheader bytes, pointers, and null pointers. For example, each instance of E3 above has only a single byte \nof primitive data, but 12 bytes of JVM-imposed object header. Depending on the collection design, each \ninstance will serve one of a number of purposes. For example, each in\u00adstance of LinkedList serves as \na wrappers to the collection as a whole. A consequence of this design is that, when LinkedLists are nested \n[2], the wrapper cost is magni.ed. Section 2.2 introduces a collection health categorization system that \ndivides instances into one of four application\u00adneutral categories based on the role they play in collections. \nCombining these two classi.cation schemes yields deeper insight into whether bytes are serving a useful \npurpose. For example, when we contrast the two primitive .elds in each LinkedList instance, used for \nbookkeeping purposes, with the primitive byte .eld in E3, we see that not all primitive data should be \njudged equally. The role of an object can give valuable clues into the purpose of its bytes. Section \n2.3 introduces the health signature, the composition of the col\u00adlection and instance health categorizations; \nit is formed by intersecting the two categorizations. We present health sig\u00adnatures from a variety of \napplications and benchmarks. To tie questions about features of a design to their mem\u00adory consequences, \nSection 3 introduces health judgment schemes. A judgment scheme maps a set of features to the design \ns health signature. Features of interest will vary de\u00adpending on the analysis. We introduce two schemes. \nThe overhead judgment scheme highlights, as features of the de\u00adsign, the various ways overhead is introduced. \nFor example, we can analyze the amount of pointer overhead that a design incurs. Section 3.1 shows that \na HashMap of 2-characters Strings will devote 29% of its space to pointer overhead. The scaling judgment \nscheme is focused on collections, and the .xed and per-element costs they incur. The mem\u00adory impact of \ncollection choices can be dif.cult to predict, particularly when using standard collections whose imple\u00admentations \nare hidden. The scaling judgment scheme helps to surface these costs. For example, Section 3.3 shows \na real application that devotes a surprising 74% of its memory to collection .xed and per-element costs. \nAnother bene.t of judgment schemes is as a concise health summary. We present these summaries for dozens \nof applications, to illustrate the great variety of health charac\u00adteristics. The application neutrality \nof the health signature enables comparison of these disparate applications. In addi\u00adtion, Section 3.3 \nprovides a detailed example of how each scheme offers distinct insights into a real-world memory problem. \nThe Limits of Health From a health judgment, we can derive a health metric: the ratio of actual data \nto the total. We have observed that this ratio has asymptotic behavior. For example, our LinkedList of \nLinkedLists of E3 objects will never contain more than 10% actual data; the application discussed in \nSection 3.3 can never contain more than 17%. Section 4 demonstrates this behavior, and presents a way \nto derive scaling formulas that predict it. We show how the scaling properties of a nested data structure \ndepend upon the structure of that nesting. We introduce the content schematic, a concise summary of this \nnesting structure. The content schematic of a data structure identi.es the distinct contexts in a data \nstructure that may vary in size as the application runs. We show how to combine a scaling judgment scheme \nwith the content schematic in order to automatically derive formulas. We present several example studies \nto demonstrate the power of scaling formulas in pinpointing the limits of health for a given design. \nSummary This paper presents the following contributions: two application-neutral systems that classify \nthe role of bytes in objects, and the role of objects in collections  health signatures that distinguish \nthe role of bytes based on the role of objects in collections  a judgment scheme to distinguish the \nsources of overhead in a design, and a second scheme to expose the design s scaling properties  a technique \nfor .nding and summarizing the data struc\u00adtures in a heap snapshot into content schematics  an algorithm \nfor automatically constructing scaling for\u00admulas to gauge the asymptotic health of a data structure \n 2. The Health Signature We summarize a heap snapshot, or a subset of a snapshot, to identify potential \ninef.ciencies in the way memory is struc\u00adtured. A health signature is a two-dimensional summary us\u00ading \ntwo distinct categorizations of memory: instance health: for each object, categorize its bytes according \nto the function those bytes serve.  collection health: for each data collection, categorize its constituent \nobjects according to the function each serves in implementing the collection s functionality.  In both \ncases, the categories are application-neutral, in the sense that they are not in terms of data types, \nor any other such application-speci.c artifacts. We begin by introducing the categories, and then show \nhow to derive health signatures from them. 2.1 Instance Health Every instance of a data type consumes \na certain number of bytes in the runtime heap. Some of these bytes store the type s instance variables, \nwhile some store information needed by the underlying runtime, such as for garbage col\u00adlection or lightweight \nsynchronization. We categorize the bytes of an object in this way: by what purpose those bytes implement \nor facilitate. Table 1 shows the four categories of instance health. The .rst category covers all primitive \ndata, whether from prim\u00aditive .elds of objects, or from arrays of primitive data. In Java, each primitive \nelement consumes one, two, four, or eight bytes. The second category accounts for the bookkeep\u00ading information \nthat the runtime sets aside to help manage each object, commonly termed object header . The runtime Table \n1. The categories of instance health, with sizes for a typical 32-bit Java VM. category explanation # \nbytes primitive prim. array elements, prim. .elds 1 8 header space imposed by VM 12 16 pointer references \nbetween objects 4 null unused pointers 4 category explanation example head head of a collection HashMap, \nString array array backbone HashMap$Entry[] entry list-style element HashMap$Entry contained anything \nelse char[] header pointer null pointers (a) An data structure composed of an array of strings, showing \none string with its three primitive .elds and that string s 2-element character array. primitive header \npointer null total 16 40 8 8 72 (b) The instance health categorization of this data structure, with \ncategory sizes in bytes. Figure 1. An example of instance health. uses this header to facilitate tasks \nsuch as garbage collection, lightweight synchronization, and re.ection. The size of each object header \nis usually independent of the instances type; many Java virtual machines impose a 12-or 20-byte object \nheader, depending on whether it uses 32-or 64-bit address\u00ading. The header of array instances differs \nfrom that of ob\u00adject instances. For example, in Java, it is common to have a twelve-byte object header, \nwith an additional 1 4 bytes to keep track of an array s length.1 The .nal two categories cover bytes \nset aside for pointers between objects. Each pointer slot, whether from a .eld of an object or from an \narray of pointers, consumes one word (either 32 or 64 bits on most contemporary virtual machines). This \nis the same even if the pointer is null. Null array slots occur in the common case of an application \nthat allocates an array with some default capacity, but only makes use of a smaller number of elements \nduring the course of its run. The third category includes bytes from pointer slots that refer to extant \nobjects, and the fourth category includes the null case. 1 There are two other cases of per-instance \nvariation of object header size: fragmentation due to object alignment, and hashcodes stored in object \nheaders. This information is available only in some JVMs. In cases where we do have it we include it \nin the object header category. Table 2. The categories of collection health. Figure 1 illustrates an \ninstance health categorization. The .gure shows an array of Java String objects, the one String in that \narray, and the character array object which underlies that String. On a 32-bit platform with 12-byte \nobject headers and 8-byte alignment, this example will consume a total of 72 bytes: 40 from object headers, \n8 from pointers, 8 from null pointers, and only 16 from primitive data. Furthermore, of those 16 bytes, \nonly 4 come from the true data of this structure: the two characters in the String s character array. \nTo come to this conclusion requires a categorization of ob\u00adjects that distinguishes the String from its \ncharacter array. 2.2 Collection Health We now address sources of bloat that stem from the way individual \nobjects are glued together into larger collections. Inside every collection will of course be the actual \ndata in\u00adtended to be collected together. Unfortunately, the actual data may only occupy a small fraction \nof the collection s to\u00adtal size. Everything else represents the infrastructure costs. This dichotomy, \nbetween actual data and collection infras\u00adtructure, is the basis for our second categorization scheme. \nWhereas the instance health breaks down the bytes of each instance, the collection health analysis categorizes \nthe ob\u00adjects of a collection. Each instance inside a collection serves one of four pri\u00admary roles [15]. \nTable 2 shows these four categories of col\u00adlection health. First, every collection consists of a number \nof backbones that allow the collection to contain a variable number of objects. Some backbones are arrays, \nwhich are commonly used when append-only random access is needed. Other backbones have a chained or recursive \nstructure, to allow for ef.cient random insertion and deletion. We label these as entry instances. For \nexample, in the Java stan\u00addard libraries, instances of the data type LinkedList$Entry fall into this \ncategory. Next, many data structure implementations include a data type that represents the collection \nas a whole; in the Java standard libraries, such data types include HashSet and LinkedList. In fact, \nevery implementation in the Java collec\u00adtions library was designed so as to devote one instance to serve \nthis role. The head category includes these heads of collections. In general, we include in this category \nany in\u00adstance that points to to an array or entry instance. The .nal category, contained, includes what \nremains; it includes the non-infrastructure instances inside collections.2 2 It also includes the relatively \nfew instances outside any collection.  head of collection HashMap HashMap$Entry[] array of refs  list-style \nentries HashMap$Entry  head of collection String char[] contained objects (a) A data structure composed \nof a hash set containing three strings, and showing each string with its 2-entry character array. contained \nhead array entry total 48 144 76 96 364 (b) The collection health categorization of this data struc\u00adture, \nwith category sizes in bytes. Figure 2. An example of collection health. Figure 2 shows an example collection \nhealth categoriza\u00adtion. This heap contains a HashMap whose keys and values are Java Strings, and the \nStrings in turn contain character ar\u00adrays. We consider the case where the key and value point to the \nsame object,3 and show only a single edge to the Strings, to reduce clutter in the .gure. The top-most \nnode in the .g\u00adure, representing the HashMap , falls into the head category. The Strings also fall into \nthe head category, since they refer to the arrays of primitive characters. Using instance sizing information \nfrom IBM Java 1.5, this heap consumes a to\u00adtal of 364 bytes. Of that, 144 bytes, 40% of the total, be\u00adlongs \nto the head category: three strings, each 32 bytes, and one hash map; 76 bytes belongs to the array category, \nfrom the four-element array; 96 bytes, 26% of the total, belong to the entry category: three hash map \nentry objects; and 48 bytes, only 13%, belong to the contained category: three 2-element primitive arrays. \n 2.3 Composing the Two Classi.cations The composition of instance health and collection health lets us \nstudy the role of an instance s bytes in the context of a collection. For example, bytes that seem reasonable \n(e.g. primitive data) may come mostly from objects that serve an infrastructure role, and that one did \nnot realize would incur such a great memory overhead. Conversely, bytes that seem to be excessive (e.g. \npointer bytes) may come from infras\u00adtructure objects that enable a useful function (e.g. offering random \ninsertion and deletion). With four categories in each categorization system, a health signature is a \n4 \u00d7 4 matrix. Each entry is the number 3 This is a common situation used to pool objects, since the Java \nHashSet does not support a lookup() method. primitive header pointer null total contained 12 36 0 0 48 \nhead 56 60 16 12 144 array 0 12 8 56 76 entry 12 48 16 20 96 total 80 156 40 88 364 Table 3. The health \nsignature for the example in Figure 2. of bytes in the intersection of a collection health category and \nan instance health category. In Table 3 we show the health signature for the data struc\u00adture in Figure \n2. The leftmost column shows the distribution of primitive bytes, which at the surface we might consider \nto be the actual data of the data structure. We see, how\u00adever, that most of the primitive bytes are found \nin head ob\u00adjects. Each String in Java contains three primitive .elds for bookkeeping purposes: a memo \nof the string s hash code, the string s length, and an offset, in case the underlying charac\u00adters are \nshared. Each HashMap, also a head instance, de\u00advotes .ve primitive .elds to bookkeeping. The only actual \ndata in this data structure is found in the String s charac\u00adter array, the 12 bytes shown in the contained-primitive \ncell. Similarly, each HashMap has four pointer .elds, three of which are null by default. These are used \nfor caching in cases which may not occur. We contrast them with the 56 bytes in the array-null category, \na sign that an array may have been sized too large. By taking into account the context in which bytes \nare used, the health signature allows us to make these .ner distinctions about the ways a design spends \nits bytes. Figure 3 presents health signatures from four snapshots, and illustrates the very different \nsignatures that show up in practice. Figure 3(a) shows the health signature of a Da-Capo benchmark called \nantlr. The signature indicates that antlr devotes 70% of its bytes to primitive bytes within con\u00adtained \nobjects; the number of bytes spent in pointers, arrays and list-style entries are all small fractions \nof the total heap size. Figure 3(b) shows the very different health signature of javac, a benchmark from \nthe SPECJVM98 suite. In contrast to antlr, javac spends only 20% of its bytes in the primitive\u00adcontained \nintersection. In addition, object headers and point\u00aders show up in much greater concentration. The health \nsigna\u00adture of Figure 3(c) comes from application S. Its health sig\u00adnature seems to indicate some severe \nproblems with memory health. In particular, contained objects do not consume a plu\u00adrality of the heap, \nand primitive data appears mostly in heads of collections. The fourth snapshot, from a J2EE [22] server \napplication, has characteristics in common with each of the other three applications.  2.4 Implementation \nDetails To automatically categorize by instance or collection health, our implementation analyzes heap \nsnapshots. To collect fraction of heap consumed 100% 90% 90% 80% 80% 70% 70% 60% 60% 50% 50% 40% 40% \n30% 30% 20% 20% 10% 10% 0% 0% contained head of arrays of list-style contained heads of arrays of list-style \nobjects container refs entries objects container refs entries (a) DaCapo s antlr (b) SPECJVM98 s javac \n 100% 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% 100%90% 80% 70% 60% 50% 40% 30% 20% 10% 0% contained heads \nof arrays of list-style contained head of arrays of list-style objects container refs entries objects \ncontainer refs entries (c) application S (d) application O Figure 3. Four example health signatures. \nsnapshots, we used the built-in facilities of Java virtual ma\u00adchines (JVM) to trigger writing a snapshot \nto disk. In some cases, the JVM produced a snapshot upon heap exhaustion. In other cases, we explicitly \nrequested them. 2.4.1 Instance Health Implementation Membership of bytes in a category is a local property \nof each object. Therefore, categorizing bytes is mostly a straightfor\u00adward task: for each instance, count \nup the header and pointer bytes, and consider primitive bytes to be the instance s total size minus that \nsum. Depending on the richness of informa\u00adtion provided by the heap snapshot format, however, there may \nbe several wrinkles. First, it may not be possible to distinguish null .eld slots from primitive data \nbytes with certainty. For example, most heap snapshot formats do not describe the .eld layout; rather, \nthey specify the size of each type s instances, and, for each instance, its number of outgoing non-null \nreferences. In this situation, we conservatively estimate the number of null references by computing \nthe maximum number of non-null references, over all instances of each type. Second, it is usually infeasible \nto detect uninitialized primitive data. Therefore, the numbers reported in this paper are based on the \nassumption that the bytes of a primitive array always contain meaningful data.  2.4.2 Collection Health \nImplementation The heap snapshot is a graph, where nodes correspond to objects and edges correspond to \nreferences between objects. We .rst compute a spanning forest over the graph. The forest we use is based \non the dominator relation [15] because it eliminates back edges in a reliable way one that does not \ndepend on an arbitrary ordering of graph roots. We categorize data types based on a purely structural \nanalysis of the spanning forest (so that refers to below means in the spanning forest). From the categorization \nof types, it is trivial to categorize objects, based on their type. Every array of reference type belongs \nto the array cate\u00adgory. Now consider a type having an instance that immedi\u00adately refers to a different \ninstance of that type. All instances of such types belong to the entry category. This strategy under-approximates \nthe set of all list-style and recursive data types. Computing this property in general from only a struc\u00adtural \nanalysis of the graph is a challenge for future research. Then, we categorize as head any type with an \ninstance that immediately points to to an object whose type is either cate\u00adgorized array, entry, or is \na primitive array. Any remain\u00ading data types are considered to be contained. This implementation maps \nevery object to a single cate\u00adgory, except in the case of nested collections. Whenever a collection contains \nother collections, each collection head is also a contained object. For this paper, we prioritize the \ncategories, to ensure that each object falls into one category: we give priority to the array and entry \ncategories, fol\u00adlowed by head, and then contained objects. In this way, all of the LinkedList objects \nin a list of lists will be consid\u00adered to be heads of collections. 3. Judgment Schemes For a developer \nexperienced with a code base and with mem\u00adory health analysis, a health signature can provide a neces\u00adsary \nlevel of detail for problem resolution. For developers new to the code or to memory analysis, a summary \nthat in\u00adcorporates some amount of a priori judgment may be nec\u00adessary. A health signature imposes no \nvalue judgments on whether an application s use of memory is good or bad. Moreover, a health signature \nis a two-dimensional summary. A one-dimensional summary can make deviations from ex\u00adpected norms quickly \napparent. It can also enable bulk com\u00adparisons across versions, data structures, diverse applica\u00adtions, \nand varying load scenarios. header pointer null primitive head overhead array glueentry data small objects \npointeroverhead Table 4. The overhead health judgment scheme. overhead judgment size data 24 primitive \noverhead 56 small objects 156 pointer overhead 104 collection glue 24 total 364 Table 5. The overhead \njudgment scheme applied to the ex\u00adample in Figure 2. In this section we introduce health judgment schemes, \none-dimensional summaries of memory health signatures. Health judgment schemes can be designed for speci.c \nanal\u00adysis tasks, combining elements in health signatures to bring out certain features. We demonstrate \ntwo health judgment schemes. An overhead judgment scheme, described in Sec\u00adtion 3.1, highlights common \nways in which overhead is introduced into a design. A scaling judgment scheme, de\u00adscribed in Section \n3.2, can help evaluate collection choices and can expose how a data structure will scale. In Section \n3.3 we apply these two judgment schemes to a real-world mem\u00adory problem. 3.1 The Overhead Judgment Scheme \nWe introduce the overhead judgment scheme to help distin\u00adguish the data in a data structure from the \nstructure s over\u00adhead. We consider the ways in which space for primitive .elds, object headers, and pointers \nmay be introduced into a design. Table 4 shows how this scheme judges the cate\u00adgories from a health signature. \nA design may use primitive .elds to store actual data or bookkeeping information. As we saw earlier with \nString, we can use the role an object plays in a collection to help distinguish the purpose of its primitive \n.elds. The over\u00adhead judgment scheme classi.es contained-primitive bytes, such as the characters in a \nString s character array, as data; it classi.es head-primitive bytes, like those in the String proper, \nas primitive overhead. We also consider entry-primitive bytes as data, rather than primitive over\u00adhead. \nWe do this so as not to penalize applications that com\u00adbine entry and contained functionality into a \nsingle type.4 4 The Java LinkedList, Hashtable, etc. use distinct data types for these two roles; the \nGNU Trove [9] collection classes often do not. A collection health categorization that better distinguished \nthese scenarios would allow for more precise health judgment for entry-primitive bytes. Object headers \nand some pointers are introduced during class design when deciding which .elds to include in a class, \nwhere to use subclassing, and where to delegate .elds to sep\u00adarate classes. We classify bytes spent on \nobject header as an indicator of small objects instances with few .elds, or arrays with few elements. \nWe classify pointer and null bytes as pointer overhead, an infrastructure cost of a highly delegated \nor highly interconnected design. Pointers may also be employed for a different purpose: to maintain one-to\u00admany \nrelationships. We make this distinction by classify\u00ading non-null pointer bytes in array or entry objects \nas collection glue. We classify null pointers from array and entry objects, however, as pointer overhead; \nthey are the overhead of oversized arrays or very short linked lists. Table 5 shows the overhead judgment \nscheme applied to the data structure in Figure 2. The large values for small ob\u00adjects and pointer overhead \nhighlight the degree of delegation in this design. Figure 4 shows the application of this scheme to a \ndiverse assortment of snapshots. Table 6 lists the applications in our corpus. We study snapshots from \na large number of real ap\u00adplications: under-test and deployed servers, and standalone and Eclipse-based \n[12] clients. These heap snapshots range in size from 50 megabytes to 2 gigabytes; the largest snap\u00adshots \ncontain as many as 20-40 million live objects. Our corpus also includes snapshots from two benchmark \nsuites, SPECJVM98 [24] and DaCapo [3] (using dacapo\u00adbeta051009.jar). For each benchmark, we con.gure \nit to run its largest con.guration, and acquire several dozen heap snapshots during the run. We generally \npick the largest snapshot from among those collected.5 It is worth noting that none of the benchmarks \nhave heaps bigger than 10 megabytes. Most of the benchmark snapshots were consid\u00aderably smaller than \nthat. 3.2 The Scaling Judgment Scheme The scaling judgment scheme distinguishes contained ob\u00adjects from \ncollection implementations, exposing how each contributes to overhead. Table 7 shows how it is derived \nfrom the health signature. The primary distinction is between contained objects (the .rst row in the \ntable) and head, array, and entry objects (the remaining rows). Within each we de.ne two .ner categories. \nFor contained data, we label as data any primitive .eld data, just as we did in the overhead judgment \nscheme. We label the rest of the bytes object headers and null and non-null pointers as data overhead. \nFor objects implementing collection infrastructure, we di\u00advide their bytes into .xed and variable collection \noverhead. Fixed collection overhead includes all of the bytes in head\u00adof-collection objects, and the \nobject header portion of arrays 5 In cases where one snapshot was marginally smaller but considerably \nmore unhealthy, we chose to present, in Figure 4, the unhealthy one. description A, P Eclipse-based programs \nC, G, H, I, L,M .nancial services server E, Q catalog management server B, N, F Java clients D, J, K, \nO,R collaboration servers S standalone Java program serverbench application server benchmark dacapo the \nDaCapo benchmark suite specjvm the SPECJVM98 benchmark suite Table 6. Our corpus of Java heap snapshots, \ntaken from real applications and benchmarks. The real applications have 50MB to 2GB of live objects. \nThe DaCapo and SPECJVM benchmarks are both relatively tiny in this regard. data primitive bloat small \nobjects collection glue pointer bloat dacapo xalan dacapo fop spec compress spec mpegaudio dacapo antlr \nB dacapo batik C A serverbench dacapo chart specjvm jack D F E dacapo ps K G H dacapo bloat I J L M N \nO spec mtrt dacapo hsqldb spec jess Q P dacapo jython spec javac spec db R dacapo pmd S 0% 20% 40% 60%fraction \nof heap consumed 80% 100% Figure 4. A judgment scheme, in this case the overhead judgment scheme, allows \nfor quick comparison of the health of disparate applications. For example, application Q has 780M of \nlive objects, of which only 234M is actual data. contained primitive data header pointer null data overhead \nhead .xed collection overhead array entry variable collection overhead Table 7. The scaling health judgment \nscheme. scaling judgment size data 12 data overhead 36 .xed collection overhead 156 variable collection \noverhead 160 total 364 Table 8. The scaling judgment scheme applied to the exam\u00adple in Figure 2. of references. \n6 Variable collection overhead includes bytes allocated for the elements of arrays of references, whether \nnull or non-null, and all of the bytes of entry objects. Table 8 shows the scaling judgment scheme applied \nto the example in Figure 2. This breakdown highlights the degree to which memory is devoted to collection \noverhead, both .xed and variable.  3.3 An Example: Applying Health Judgment Schemes In this section \nwe walk through an example from a real\u00adworld application with large footprint problems, to demon\u00adstrate \nthe power of the two health judgment schemes. The ex\u00adample also illustrates the variety of memory problems \nseen in industrial applications. The application is a planning sys\u00adtem, application S in Table 6. It \nwas at the prototype stage of development, and as such, the primary concern was pro\u00adducing a working \nalgorithm quickly. Like many industrial applications, even those much closer to production, memory usage \nwas not taken into account until a problem appeared. The primary data structure is a level graph where \nthe same vertex may appear with different edges at multiple lev\u00adels of the graph. We explore one particularly \nexpensive data structure: the representation of the edges. Figure 7 shows a schematic view of that portion \nof the data, which cost 42MB in this run. Each node in the .gure represents instances hav\u00ading the same \nownership context; some intermediate classes have been elided (explained formally in Section 4.2). The \nnode labels re.ect the cost of all instances at that node, in\u00adcluding those of elided classes. Edges \nare labeled with their average fan out. In the application s level graph, each edge is stored as an Edge \nobject pointing to its source and tar\u00adget vertices. There are two indexes for looking up the edges for \na (vertex, level) pair: one for in-and one for out-edges. The indexes are implemented as HashMaps (the \nleft-most 6 In Java there are no per-array primitive .elds. If there were, they would be included in \nthis category. scaling judgment outer HashMap Arrays$ArrayList HashSet data 2.6M 0.3M 2.4M data overhead \n9.0M 0.8M 8.2M .xed collection overhead 7.4M 3.0M 4.4M variable collection overhead 24.5M 0.8M 21.2M \ntotal 43.5M 4.9M 36.2M Table 9. The scaling judgment scheme applied to a large data structure of application \nS. The size of each category represents the sum of bytes categorized that way for all objects under the \ngiven collection. HashMaps in the .gure). The key is a 2-element ArrayList, containing an Integer level \nnumber and a pointer to a ver\u00adtex. The value is a HashSet of Edges. In this run, there were approximately \n148,000 edges. The .rst column of Table 9 shows the scaling judgment scheme applied to this data. We \ncan see that a very small portion of the bytes, 6%, are devoted to actual data, while 74% are devoted \nto collections. While we would expect an index, especially one mapping each key to many values, to involve \na signi.cant amount of overhead due to collections, we would not expect it to so completely swamp the \ndata. What is more telling is how much memory (7.4MB or 17%) is devoted to collection .xed overhead costs. \nAccording to the developer, this was a production-scale run, not a small test. We would expect the collection \n.xed costs to be amor\u00adtized across a run with 148,000 edges. The fact that they are so large suggests \nthat some of these costs are being magni\u00ad.ed rather than amortized. We next compute scaling judgments \nover the two subor\u00addinate data structures, .rst the keys and then the values, since each may have different \ncharacteristics. According to the de\u00adveloper, the Arrays$ArrayList class was chosen not because a one-to-many \nrelationship was needed, but rather for expe\u00addiency of coding, since it enabled a coding idiom where \ntest cases with constant vertex/values pairs could be coded in a single line. The second column in Table \n9 shows the cost of using a collection class for this purpose: high .xed and vari\u00adable collection overhead \ncosts. The high .xed component (73% of the keys cost) is due to requiring two instances, an ArrayList \nand array, to store just two elements. The use of an ArrayList also required the programmer to box the \nlevel number into an Integer, adding to the data overhead and vari\u00adable collection costs. The overhead \njudgment scheme can provide another view into this design, shedding light on overall overhead costs across \ncontained and collection data. The .rst column in Ta\u00adble 10 illustrates this analysis for the keys. The \nhigh value for small objects is a consequence of the two levels of del\u00adegation, from Arrays$ArrayList \nto Object array to Integer. The developer can easily replace this design with a single class: Pair {int \nlevel; Object vertex;}. The second column in Table 10 shows the reduction that would be achieved. The \nthird column of Table 9 shows the scaling judg\u00adment over the values: the HashSets and the Edges they \nhold. Notice that the majority of the cost is due to collec\u00adtion overhead here as well, with signi.cant \n.xed and vari\u00adable components. The standard Java HashSet, which stores a set of unique values, is implemented \nby delegating to the more general HashMap, which in turn points to an array of HashMap$Entry objects \nthat point to keys and values, and to each other.7 The delegation of HashSet to HashMap raises the .xed \ncollection overhead for each of these nested HashMaps; the overgenerality of HashMap raises both the \n.xed and variable overhead costs: the HashMap has book\u00adkeeping .elds that are not relevant to this use, \nand all of the inner HashMap$Entry objects point to the same (unused) singleton value. Note that overall, \na HashMap$Entry, con\u00adtaining four .elds, is larger than the Edge object that it is indexing. This is \none of the reasons behind the high vari\u00adable collection overhead cost in our data structure. Note also \nthat the .xed collection overhead cost is high because each HashMap holds only 4 5 elements on average. \n(current) (proposed) overhead judgment Arrays$ArrayList Pair data 0.3M 0.3M primitive overhead 0.3M 0M \nsmall objects 3.2M 1.1M pointer overhead 0.3M 0.3M collection glue 0.8M 0M total 4.9M 1.7M Table 10. \nThe overhead judgment scheme helps to compare current and proposed implementations of a HashMap s keys \nin a large data structure of application S.  The choice of ArrayList seemed to the developer like an \ninappropriate choice once the costs were known. The choice of HashSet seemed more reasonable for the \nintended use. The developer wanted the code to be safe by guaranteeing uniqueness, and assumed that the \nwidely-used standard Java HashSet would be well optimized. One can easily imagine refactored HashSet \nand HashMap classes that shared code while optimizing for these two different uses. 7 We use framework \nknowledge to classify the HashSet as head of collec\u00adtion, though it would not normally be classi.ed as \nsuch solely on the basis of structure. 4. Asymptotic Analysis Ideally, health should improve as input \nsize increases, be\u00adcause .xed infrastructure costs are amortized over increas\u00adingly large amounts of \ndata. Unfortunately, with multiple data structures and nested collections, this may not be the case. \nIn many situations, the fraction of actual data in an application reaches an asymptotic value. In this \nsection, we .rst present a simple example that illustrates the asymptotic behavior of memory health. \nTo model this behavior, we in\u00adtroduce a de.nition of a data structure and a summary of its internal structure. \nWe then provide an algorithm for automat\u00adically constructing formulas, on a per-data structure basis. \nEach formula predicts how a data structure s memory health changes as the sizes of its components vary. \nFinally, we give examples of scaling studies that are enabled by having these formulas, and demonstrate \nthem on an application from our test suite. 4.1 Observations of Asymptotic Behavior Consider a linked \nlist that stores data structures each of which has a collection health categorization of 4 bytes of contained, \n24 bytes of head, and 8 bytes of entry. The linked list itself imposes 4 bytes of entry per contained \nstructure and 12 bytes of head. We focus on these cate\u00adgories to keep this motivating example simple. \nWith one contained structure, the relevant portion of the collection health categorization, (contained, \nhead, entry), will be (4, 36, 12); with two contained structures (8, 60, 20); with n entries, (4n, 24n \n+12, 8n +4). In absolute terms, all three categories approach in.nity. However, any one category, rel\u00adative \nto the whole, approaches an asymptotic value. When we normalize, we get (8%, 69%, 23%) with one entry, \nand (9%, 68%, 22%) with two entries. In the limit of large n, this will approach (11%, 67%, 22%). OBSERVATION \n1. The ratio of any health signature cate\u00adgory to the sum of all health signature categories approaches \nan asymptotic value. This value is governed by the health of the collections and contained structures. \nTo illustrate asymptotic behavior in more depth, we ex\u00adperiment with three variations of a collection \nof collections of primitive bytes (recall this example from the introduc\u00adtion). The .rst uses the standard \nJava LinkedList collection for both the outer and the inner collections, and a distinct data type T to \nstore the primitive byte .eld: a LinkedList of LinkedLists of instances of T . The second has the same \nshape, but replaces the Java list implementation with one from GNU Trove [9]. Trove avoids the entry \ncosts, by re\u00adquiring that T implement the next and previous pointers it\u00adself. The third uses an array \nof primitive byte arrays.8 Figure 5 shows the asymptotic behavior of these three im\u00adplementations, as \nthe size of the inner and outer collections vary. We use the overhead judgment scheme to categorize 8 \nA two-dimensional primitive byte array would further reduce bloat. 0% 20% 40% 60% 80% 100% fraction \nof heap consumed Figure 6. The overhead health judgments for the four largest data structures of application \nO . the bytes of each scenario. The x-axis of each chart plots an increasing size of the outer collection; \nthe four columns of charts show the behavior of an inner collection size of, in order from left to right, \n10, 102 , 103, and 104.Wehavean\u00adnotated the fraction of data in each chart. For example, the standard \nJava LinkedList approaches 8 10% data and the Trove implementation approaches 8 17% data. Because the \ndesign of these structures is so poor, Trove improves health by only a small amount. In contrast, the \narray of primitive byte arrays scales in a much more healthy way. The asymp\u00adtotic health ranges from \n34% to 98%. In addition, with large enough inner collections, the health improves as data size increases. \nThe health of the whole heap varies depending on how each data structure within the heap changes. The \nresults shown in Figure 5 and in previous sections were the result of analyzing the heap as a whole. \nAn unhealthy data structure may become more healthy as it increases in size. But, if a second, healthier \ndata structure stays .xed in size, while an unhealthy one increases in size, the combined effect of the \ntwo will show the downwards trend, as in most of the experiments of Figure 5. In those examples, the \nJVM itself includes some unchanging data structures that, compared to the ones experimented with, are \nrelatively healthy.  4.2 The Content Schematic To study the asymptotic behavior of health, we must analyze \nat a .ner granularity than the whole heap. We show how to decompose the heap into data structures, and \nhow to arrange each data structure into a tree of regions that may possibly change in size. We refer \nto this data structure summary as a content schematic. First, we de.ne data structures by unique ownership, \ndrawing on earlier work [15]. DEFINITION 1. Given a heap snapshot considered as an object reference graph \nG,a data structure of G rooted at type t is the equivalence class of trees in the dominator spanning \nforest of G whose root node has type t. 9 9 In the case of diamond structures or root sharing, we refer \nthe reader to [16] and [15]. For these situations, we chose to use the heuristic for handling shared \nownership described in [16]. 100% 100% 100% 100% 80% 80% 80% 80% pointer overhead 60% 59% 55% 60% 56 \n% 60% 60% collection glue 40% 35 % 40% 38% 40% 38% 40% small ob\u00adjects 20% 11% 8% 8% 20% 13 % 10% 10% \n20% 13% 10% 10% 20% 13 % 10 % 10% primitive overhead 0% 0% 0% 0% data 10 10^2 10^3 10^4 10^5 10^6 10 \n10^2 10^3 10^4 10^5 10 10^2 10^3 10^4 10 10^2 10^3 outer collection size outer collection size outer \ncollection size outer collection size (a) Java s LinkedList of LinkedLists of Objects, each with a single \nbyte .eld fraction of heap consumed 100% 100% 100% 100% fraction of heap consumed 10 10^2 10^3 10^4 \n10^5 0% 20% 40% 60% 80% 60% 56% 36 % 11% 8% outer collection size 10^6 8% 10 10^2 10^3 10^4 0% 20% 40% \n60% 80% 57% 39% 13% 10% outer collection size 10^5 10% 10 10^2 10^3 0% 20% 40% 60% 80% 50% 27% 17% outer \ncollection size 10^4 17% 10 10^2 0% 20% 40% 60% 80% 27% 17% outer collection size 10^3 17 % pointer overhead \ncollection glue small ob\u00adjects primitive overhead data (b) GNU Trove s TLinkedList of TLinkedLists of \nObjects, each with a single byte .eld 100% 100% 97%  100% 98 % 100% 83% 85 % fraction of heap consumed \n86% 76 % pointer 80% 80% 80% overhead 65 % 66% 60% 61 % 75% 60% 60 % 59 % 59% 67% 61%  collection \n60% 60% 60% 40% 35% 34 % 40% 40% 50% glue small ob\u00ad 10 0% 20% 10^2 10^3 10^4 10^5 outer collection size \n10^6 10 0% 20% 10^2 10^3 10^4 outer collection size 10^5 10 0% 20% 10^2 10^3 outer collection size 10^4 \n10 0% 25% 10^2 outer collection size 10^3 jects primitive overhead data (c) Array of primitive byte arrays \n Figure 5. The overhead judgment scheme illustrates the asymptotic behavior of memory health. The three \nrows show three implementations of a collection of collections of bytes. The four columns show inner \ncollections of size 10, 100, 1000, and 1000. The x-axis of each plot corresponds to increasing the size \nof the outer collection. Memory health varies widely across the data structures of an application. For \nexample, Figure 6 shows the overhead judgment scheme applied to the four largest data structures of application \nO. Each has a distinct health signature. To model the scaling properties of a data structure, we must \nidentify its expansion points. To do so, we leverage the backbone-folding and type-indistinguishable \nequivalence re\u00adlations introduced in [15] to group objects into regions . The backbone-folding equivalence \nrelation folds any array or entry object into the nearest head, and any contained object into the nearest \nparent contained object that is a child of an array or entry object. In this way, container\u00adrelated infrastructure \nobjects are grouped with the own\u00ading container, and the constituents of contained data struc\u00adtures are \nsimilarly uni.ed with the head of contained struc\u00adtures. The type-indistinguishable relation creates \na class for head objects that share the same path-to-root of head and contained data types; similarly, \nit creates a class for contained objects with the same paths-to-root.10 DEFINITION 2. Given an object \ni that dominates a set of objects O,a region of i is the subset of objects in O equivalent according \nto the backbone-folding and type\u00adindistinguishable equivalence relations. The heads ofare\u00adgion are those \nobjects at the head of a chain of backbone folding. When we refer to the region type of a region, we \nmean the type of the head objects. Finally, the number of elements in a region is the number of head \ninstances of that region. Under this de.nition, observe that a region is capable of changing in size \nif the region type of its parent region is 10 The composition of these two equivalence relations is similar \nto the calling context tree [1], except in how it deals with recursive structures, and how it folds contained \nstructures together. overhead be Jr. We de.ne the scaling formula of r to be: 1 33,444  1 33,444 1 \nEdg e inde xes 4.45 V a lues Figure 7. The largest regions in a 40MB data structure of application \nS. The average number of elements of each region is shown on the incoming edge label. Each region is \nlabeled with the size of objects that fall into its equivalence class. Small regions are drawn as circles. \nclassi.ed head. Furthermore, since we de.ne regions over the dominator forest, the regions under any \ngiven object form a tree. DEFINITION 3. For a region r, the parent p(r)of r is the region headed by objects \nthat most closely dominate objects that point to the heads of r. The average number of elements of r \nis the ratio of the number of elements in r to the number of elements in p(r). Given a data structure \ni, the content schematic of i is the tree of regions comprising i. For example, Figure 7 shows the content \nschematic for a subset of the largest data structure in application S (the same subset studied in Section \n3.3). The .gure labels each node with the region type of that region, and with the sum of the instance \nsizes of objects that fall into the equivalence class of that region. The .gure labels an edge between \nregions r1 and r2 with the average number of elements in r2.  4.3 Scaling Formulas The health of a data \nstructure depends upon the contribu\u00adtions of its constituent regions. To construct a formula that predicts \nits health, we .rst de.ne the incremental contribu\u00adtion of every region to the cumulative health. DEFINITION \n4. Given a region r, the base health signature of r is the health signature H computed over just those \nob\u00adjects that belong to r. The per-element base health signature of r is its base health signature normalized \nby the average number elements of r. For every region in a data structure, we generate a for\u00admula that \npredicts its cumulative health i.e. the health of that region and all its descendants. In this paper, \nwe derive one formula for the primitive-contained category of the health signature, and a second formula \nfor the other, infras\u00adtructural, categories. Observation 1 hypothesized that the ra\u00adtio of either of \nthese to the total has asymptotic behavior. DEFINITION 5. Given a region r, let the cumulative amount \nof actual data in r be Dr. Let the cumulative amount of Jr +Dr Jr Sr = =1+ Dr Dr Note that we have de.ned \nS to be the total number of bytes divided by the data bytes, rather than the other way around. We do \nthis only because it leads to simpler formulas. To explore the limits of memory health, and to make predictions \nof health under various conditions that might not have been captured by any dynamic run, we express the \nscaling formula symbolically. A symbolic scaling formula is a function of three main data structure properties: \nthe data structure s nesting of regions, the health of collections, and the health of contained objects. \nTable 11 summarizes the independent variables that we consider. We now de.ne these factors and show how \nto derive the set of symbols for a given region i.e. the domain of the scaling formula S. After deriving \nthe set of unknowns, we then express D and J in terms of those unknowns. The Expansion Factors of a Content \nSchematic The con\u00adtent schematic s nesting of regions in part governs how its health changes. For a given \ncontent schematic, we identify three ways in which the nesting structure governs changes in a data structure \ns health. We term these governors of size expansion factors. First, as the application runs, the number \nof elements in each region may change. For example, this kind of expansion factor captures the number \nof distinct keys or values in a hash map. Observe that this quantity is the same as the average number \nof elements in a region. We term these primary expansion factors. Second, certain collection implementations \nmay overlap the variable collection overheads among the child regions. Consider the outer Java HashMap \nin Figure 7: it maps keys of type Arrays$ArrayList to values of type HashSet. The content schematic includes \nthree regions, one for this outer HashMap, one for the keys, and one for the values. The HashMap$Entry \nobjects of the outer HashMap region are variable collection overhead that is shared between the key and \nvalue regions. In some instances, the magnitude of the overlap for a region is a .xed constant times \nthe sum of the primary expansion factors of its child regions. For example, in a Java HashMap with distinct \nand never-null key and values, the overlap factor will always be one half the sum of the child expansion \nfactors: in this situation, a HashMap of size 100 will have 100 keys and 100 values. However, it is often \nimportant to consider this overlap has an expansion factor distinct from the primary expansion factors \n e.g. when key and values overlap, or are sometimes null. We term these overlap expansion factors. Finally, \nit is often helpful to study the effect of varying the size of primitive arrays. For example, in an application \nthat uses Java BigDecimals or Strings, studying the limiting ef\u00ad meaning n r m r dr jr ct e t type t \net ct ArrayList 4 16 LinkedList 24 20 HashSet 28 52 TreeSet 36 52 average number of elements in region \nr overlap of efor the children of region r per-contained structure actual data in r per-contained structure \noverhead in r region r jr dr Integer 12 4 Edge 24 8 (b) contained costs for re\u00adgions head by the given \ntype (a) container costs .xed collection overhead of container type t amortized variable collection overhead \nof t Table 12. For data types inferred to be heads of collections Table 11. The independent variables \nin a scaling formula In Section 4.4, we show how treating these factors as either unknowns or constants \nallows exploration of the asymptotic behavior of the scaling formula S. fect of the underlying primitive \narray sizes can highlight de\u00adsign problems. We term these primitive expansion factors.11 DEFINITION 6. \nConsider a content schematic T with k re\u00adgions. We denote the primary expansion factors of T by the symbols \nn1,...,nk, and the overlap expansion factors of T by the symbols m1,...,mk. An expansion factor may be \nleft as an unknown, or it may be hard-wired to have a positive constant expansion factor. For example, \nthe data structure shown in Figure 7 has six primary expansion factors. Three of these correspond to \nregions whose region heads are classi.ed head (i.e. heads of collections): n1 for the outer HashMap, \nn2 for the HashSet, and n3 for the Arrays$ArrayList. The scaling properties of the entire structure s \nhealth, and of each enclosed structures, depends in part upon these expansion factors. Consider the case \nof n2: as it increases, the variable overhead of HashSet collections and the .xed overhead of the Edge \ndata structures are magni.ed, but the .xed costs of the outer HashMap are amortized. It is often helpful \nto use the properties of a particular snapshot to hard-wire the values of certain expansion factors. \nFor example, given a heap snapshot, it is possible to hard\u00adwire a primary expansion factor nr to the \naverage number of elements that belong to r in that heap snapshot. One can calculate the average or maximum \nsize of primitive arrays in a certain region, and hard-wire that value for the primitive expansion factors \nwithin that region. Section 4.4 explores various scenarios of selectively hard-wiring expansion fac\u00adtors. \nIt is also possible to estimate a constant value for the over\u00adlap expansion factor of a region from a \nheap snapshot: .nd all entry objects in that region, and compute the number of graph edges v in the snapshot \nthat point from one en\u00adtry object to objects in more than one child region. In many cases, the maximum \nvalue of v is a reasonable choice for hard-wiring that region s overlap expansion factor. 11 Our current \nimplementation does not make primitive expansion factors explicit, but instead models primitive array \ngrowth by treating the d cost (described below) as an unknown. or heads of contained structures, we can \noptionally hard-wire c, e, j, and dto the numeric values given by the per-element base scaling judgment \nscheme for those collection types. This table gives some example values, in bytes, from various Java \nstandard collections and for the contained structures in the application from Figure 7. The Effects of \nCollection Choices The scaling properties of a data structure also depend on the kinds of collections \nused, and how those collections scale. Each collection im\u00adplementation incurs a .xed infrastructure cost \nthat can be amortized across all elements in the collection, and an in\u00adfrastructure cost for every contained \ndata structure. DEFINITION 7. Given a region r with a head of container type t, the .xed infrastructure \ncost of r is denoted by ct; when we write cr, we mean this as shorthand for the numeric value 0, if the \nheads of r are not heads of containers, or ct otherwise. Likewise, we de.ne et and the shorthand er to \nbe the variable infrastructure cost. We say that ct or et is hard\u00adwired if it is assigned a non-negative \nconstant value. This de.nition assigns a single pair (ct,et) to each col\u00adlection type t, rather than \none pair for each instance of a collection type. This accurately re.ects the scaling behav\u00adior of most \ncollections. However, in some cases there will be ecosts that are amortized over a number of contained \nel\u00adements. Consider the case of a Java HashMap, which uses explicit chaining to handle hash collisions. \nFor this collec\u00adtion implementation, the pointer bytes for the base array are amortized over all contained \nelements with the same hash code. We have chosen to simplify the presentation for this paper, and so \ndo not account for these amortized ecosts. To compute ct and et, we can leverage the scaling judg\u00adment \nscheme introduced in Section 3.2. First, pick an in\u00adstance of collection type t, and compute its per-element \nbase scaling judgment. Then set ct to be the size of the .xed col\u00adlection overhead category of the judgment; \nset et to be the size of the variable collection overhead category. For example, we can account for the \ndifferences in the way a HashMap and a LinkedList scale. Table 12(a) provides values of c and e for four \ncollection implementations from the standard Java library. These values were automatically generated \nusing our implementation of the above algorithm. In generating a scaling formula, one may choose to hard\u00adwire \ncand eto numeric values in this way, or may treat them as unknowns. The former analysis enables one to \nstudy the Dr = dr + nr, Dr, r,.kids(r) Jr = cr + jr -mrer + nr, (er + Jr, ) r,.kids(r) Figure 8. For \na region r, the formulas for the cumulative actual data Dr and infrastructure overhead Jr. scaling effects \nof a given set of collection choices, while the latter allows one to study the effect of swapping one \ncollec\u00adtion implementation for another. In this paper, we focus on the former. The Effects of Contained \nStructure Design Finally, the scaling formula of a region depends upon the health of the contained data \nstructures. DEFINITION 8. Given a region r, we denote the per-element actual data to be dr, and the per-element \ninfrastructure cost to be jr. Observe that the values of dr and jr can be computed just as we did for \nct and et. First, compute a per-element base scaling judgment for r. Then dr and jr are the values of \nthe judgment from the data category and the data overhead categories, respectively. For example, Table \n12(b) shows the values of d and j derived automatically for the application S. Each of the two rows corresponds \nto a region from Fig\u00adure 7 whose region heads are classi.ed as contained. The Integer object has the \nexpected four bytes of data per ele\u00adment, plus twelve bytes of data overhead (since this analysis was \nperformed on a snapshot from a JVM with twelve-byte object headers). The Edge object has proportionally \nhigher costs of each: 8 and 24 bytes, respectively. Scaling Formulas For a region r, the scaling formula \nSr depends on the expansion factors, the c and e overheads, and on the d and j costs. We model the data \nand overhead Dr and Jr with the recursive formulas shown in Figure 8. The cumulative amount of actual \ndata Dr in region r is its per-element actual data plus the sum of its children s actual data, weighted \nby their primary expansion factors. The cumulative amount of infrastructure in r, Jr,isgiven by its e \noverhead and j costs, plus the sum of its children s infrastructure costs, weighted by their primary \nexpansion factors. The infrastructure of r also includes at most one e cost for every element in the \nchild regions. This may over count, in the case of overlap. Therefore, the formula for Jr must subtract \noff mre, i.e. one e cost for every degree of variable-cost overlap among the child regions. Table 13 \nshows four simple examples of scaling formulas, generated automatically by our implementation. The rows \nof the table show formulas for data structures that contain Strings in various ways. On its own, a String \nwith d char\u00adacters has a scaling formula of 1+ 28 , while an n-element d ArrayList of 2-element HashSets \nof Strings has a formula 1+ 84 8 + . d nd  4.4 Using Scaling Formulas for Limit Studies Simple data \nstructures have simple scaling formulas. In gen\u00aderal, however, the formulas grow quite complicated. Even \nwith simple cases such as shown in Table 13, the formulas alone are not the .nal story. Rather, they \nenable a user to perform a variety of asymptotic studies that illuminate the limits of health for a given \ndesign, or a given use case. For example, a scaling formula of S1 =1+ 28 , corre\u00ad d sponding to the String \ndata structure in Table 13, has the property 1 =S1 =29. This structure, on its own, is asymp\u00adtotically \nperfectly healthy: longer and longer Strings become increasingly healthy until the ratio of total to \nactual data is 1. Compare this with an ArrayList of 2-element HashSets of 10-character Strings (note \nthat in Java, each character 2 consumes two bytes). In this case, S2 =5.2+ , whose 5n bounds are 5.2 \n=S2 = 5.6. No matter how many entries in the ArrayList, the actual data will consume no more than 1/5.2 \n19% of the heap. The health of this second case is bounded because of poor design choices made for enclosed \nstructures: short Strings, and small HashSets. Hard-wiring the expansion factors of the inner regions \nto be small lets us explore the limits to which infrastructure costs can be amor\u00adtized. In any limit \nstudy, one must .x certain unknowns and let others vary. We experiment with the effect of scaling the \nbig regions, and also of scaling the average d (the actual data in contained objects). In the former, \nwe .x what s inside large collections, to explore how well health scales given those lower-level decisions. \nIn the latter, we see how healthy the contained structures need to be to achieve good health overall, \ngiven a .xed nesting of collections. To perform a limit study, .rst choose a region to analyze. Then, \nchoose which factors to hard-wire, and which to leave as unknowns. In the case of a big-regions limit \nstudy, hard\u00adwire the expansion factors of not-big regions contained un\u00adder the chosen region to the average \nvalues observed in the heap snapshot used for analysis. Furthermore, hard-wire the dr and jr to the average \nvalues for region r, as described above. Use the recursive formulas shown in Figure 8 to gen\u00aderate S. \nIn our implementation, we then use a symbolic alge\u00adbra system, Maxima [7], to simplify the formulas. \nWe then use Maxima to compute limits. In some cases, the limit of Sapproaches 1 as the unknowns increase; \nthis is usually the case when treating d as an unknown (with increasing actual data in one s data structures, \nthe health increases monotoni\u00adcally). In this situation, we can use Maxima to solve for the value of \nd necessary to achieve good health, e.g. S < 1.2 (which corresponds to a fraction of at least 80% actual \ndata). We .rst present results for some simple structures. The third and fourth columns of Table 13 give \nthe results of these two studies for our simple examples. Observe that a String must have at least 140 \ncharacters in order to achieve an S <1.2 (i.e. no more than 80% actual data). When Strings are placed \nin a standard Java HashSet, they must have at least 270 characters to achieve this level of health. On \nthe .ip side, placing 10-character Strings into a HashSet will result in an Sof no less than 3.7 (i.e. \nno more than 27% actual data), no matter how many Strings are placed into the HashSet. data structure \nscaling formula (S) vary nwith d=20 dnecessary for S<1.2 String with d bytes of characters 1+ 28 d S=2.4 \nd>140 n-elt. ArrayList of Strings 1+ 32 d + 16 nd 2.6 =S=3.4 d>160 n-elt. HashSet of Strings 1+ 52 d \n+ 16 nd 3.7 =S=4.4 d>270 n-elt. ArrayList of 2-elt. HashSets of Strings 1+ 84 d + 8 nd 5.2 =S=5.6 d>420 \nTable 13. Four example scaling formulas and two limit studies: for Strings with 20 bytes of characters \nthe bounds of health that each structure can achieve, and the size of the Strings necessary in order \nto achieve good health (S<1.2).  We now perform the two limit studies on the subset of application S \nanalyzed in Section 3.3 (and visualized in Fig\u00adure 7). We have omitted the complete formula; it has a \nlarge number of unknowns, and offers an unnecessary level of de\u00adtail. Each limit study hard-wires many \nof the unknowns, and results in formulas that can be more easily studied. Table 14 shows the scaling \nformulas for the two limit studies. The .rst row shows the limit study which varies the number of keys \nand values. The formula has two unknowns: mand n, denot\u00ading the expansion factors of the two regions \nthat were large in the given snapshot. These correspond to the HashSet and ArrayList nodes in Figure \n7. This study shows that this sub\u00adset of the largest data structure of application S is doomed to have \na fraction of actual data between 13% and 17%. Ob\u00adserve from Figure 4 that application S has a fraction \nof ac\u00adtual data lower than either .gure. The largest data structure in the snapshot we analyzed was 170MB, \nof which 40MB came from the subset studied here. The remaining space was largely preallocated, but as \nyet un.lled, collections! The su\u00adperposition of these two structures resulted in a overall frac\u00adtion \nof actual data of around 8%. The second row poses the hypothetical study of adding more primitive data \nto the leaf\u00admost regions. It shows that, in order to achieve S <1.2 (at least 80% actual data), the Edge \nand Integer structures must each have at least 242 bytes of data. This study highlights the severe inef.ciencies \nof the application s data model. 5. Related Work This work has been inspired by a variety of research.12 \nWork on dynamic metrics [8] provides insight by quantifying pro\u00adgram bloat. It does not do so in application-neutral \nterms, nor does it provide predictive models. There are many powerful memory pro.ling tools [23, 25] \nthat identify suspicious data types, or memory leaks [11, 21, 16, 4, 13]. None of them study the underlying \ndesign causes of memory bloat or its asymptotic behavior. Others have worked on graph summa\u00adrization \n[1, 19, 20, 15]. Each of these works has its strengths, such as for execution time pro.ling [1] or for \nmore close coupling with source code [20]. We are aware of no sum\u00admarization techniques that place the \nfocus on containers and contained data structures that the content schematic offers. Automatic heap sizing \n[27] assumes the program s health as written. Conventional asymptotic analysis of algorithms [6] says \nnothing about the underlying causes of poor asymptotic behavior. Finally, there are a number of works \nthat characterize var\u00adious aspects of the program, whether its con.guration com\u00adplexity [5], its defects \n[14, 26] or general behavior [10], or its performance bloat [18]. Many of these use application\u00adneutral \ncategories, but none is targeted to memory consump\u00adtion, nor provides an asymptotic formulation. 6. Future \nDirections Analyzing heap snapshots biases our analysis towards the longer-lived objects; we are extending \nthis work to cover shorter-lived data. We can also leverage static information, and richer type information \nsuch as given by generic type systems, to possibly infer an approximation of health signa\u00adtures from \nsource code. We also see interesting possibilities in using health signatures and asymptotic analysis \nin devel\u00adopment tools, to assist in better design, earlier in the devel\u00adopment lifecycle. One limitation \nof the current work is its inability to infer certain kinds of design intent. For example, to populate \na structure may require random insertion and deletion. It is possible that, by incorporating knowledge \nabout runtime access patterns, we can aid tool users in teasing out these cases. For example, it would \nbe helpful to point out cases where a bloated structure is used well beyond the point where its construction \nhas been completed. The user may then consider having two distinct forms: one optimized for construction, \nand a second optimized for read-only access. 7. Conclusion 12 A preliminary version of the work presented \nin this paper appeared A development team should assess the runtime conse\u00adin [17]. quences of their design \nand implementation choices. Ideally, limit study scaling formula (S) limit vary big structures 20m+119n+67 \n2m+16n+6 5.8 =S=7.4 dnecessary for S<1.2 1+ 48 d d>242 Table 14. Two limit studies for Figure 7 (subset \nof application S).  this assessment should happen early and often, especially since ameliorating memory \nbloat may not be possible later on. In reality, teams often feel a sense of fatalism with re\u00adspect to \nmemory consumption, that this is an inexorable con\u00adsequence of the object oriented paradigm. Fortunately, \nthis is not the case, but it requires knowing whether an applica\u00adtion s memory consumption is out of \nline with its needs. As a step in that direction, we presented application\u00adneutral characterizations \nof the health of a design. They offer the ability to compare one implementation to another and to known \nideas of goodness, and to study the limits of the health of a design. By describing the nature of bloat, \nthey can also serve to educate developers and managers of the trade-offs inherent in data structure design. \nAcknowledgments We would like to thank Tim Klinger, Palani Kumanan, and Edith Schonberg for their help \nwith this work. References [1] G. Ammons, T. Ball, and J. R. Larus. Exploiting hardware performance counters \nwith .ow and context sensitive pro.l\u00ading. In Programming Language Design and Implementation, pages 85 \n96, 1997. [2] J. Berdine, C. Calcagno, B. Cook, D. Distefano, P. W. O Hearn, T. Wies, and H. Yang. Shape \nanalysis for composite data structures. Technical Report MSR-TR-2007\u00ad13, Microsoft Research, 2007. [3] \nS. M. Blackburn and et. al. The DaCapo benchmarks: Java benchmarking development and analysis. In OOPSLA \n06: Proceedings of the 21st annual ACM SIGPLAN conference on Object-Oriented Programing, Systems, Languages, \nand Applications, New York, NY, USA, Oct. 2006. ACM Press. [4] M. D. Bond and K. S. McKinley. Bell: Bit-encoding \nonline memory leak detection. In Architectural Support for Programming Languages and Operating Systems, \npages 61 72, 2006. [5] A. B. Brown, A. Keller, and J. L. Hellerstein. A model of con.guration complexity \nand its application to a change management system. In Integrated Management, 2005. [6] T. H. Cormen, \nC. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to Algorithms. MIT Press and McGraw-Hill, second \nedition, 2001. [7] P. N. de Souza, R. J. Fateman, J. Moses, and C. Yapp. The Maxima Book, 2004. http://maxima.sourceforge.net. \n[8] B. Dufour, K. Driesen, L. J. Hendren, and C. Verbrugge. Dynamic metrics for java. In Object-oriented \nProgramming, Systems, Languages, and Applications, pages 149 168, 2003. [9] GNU Trove: High performance \ncollections for Java. http: //trove4j.sourceforge.net. [10] M. J. Harrold, G. Rothermel, R. Wu, and L. \nYi. An empirical investigation of program spectra. In SIGPLAN/SIGSOFT Workshop on Program Analysis For \nSoftware Tools and Engineering, pages 83 90, Montreal, Canada, June 1998. [11] R. Hastings and B. Joynce. \nPurify fast detection of memory leaks and access errors. In USENIX Proceedings, pages 125 136, 1992. \n[12] S. Holzner. Eclipse. O Reilly Media, Inc., .rst edition, Apr. 2004. [13] M. Jump and K. S. McKinley. \nCork: dynamic memory leak detection for garbage-collected languages. In Symposium on Principles of Programming \nLanguages, pages 31 38, 2007. [14] M. R. Lyu, editor. Handbook of Software Reliability Engineering, chapter \n9 (Orthogonal Defect Classi.cation). IEEE Computer Society Press, 1995. [15] N. Mitchell. The runtime \nstructure of object ownership. In The European Conference on Object-Oriented Programming, volume 4067 \nof Lecture Notes in Computer Science, pages 74 98. Springer-Verlag, July 2006. [16] N. Mitchell and G. \nSevitsky. Leakbot: An automated and lightweight tool for diagnosing memory leaks in large Java applications. \nIn The European Conference on Object-Oriented Programming, volume 2743 of Lecture Notes in Computer Science, \npages 351 377. Springer-Verlag, July 2003. [17] N. Mitchell, G. Sevitsky, P. Kumanan, and E. Schonberg. \nData structure health. In International Workshop on Dynamic Analysis, Minneapolis, Minnesota, United \nStates, May 2007. [18] N. Mitchell, G. Sevitsky, and H. Srinivasan. Modeling runtime behavior in framework-based \napplications. In The European Conference on Object-Oriented Programming, volume 4067 of Lecture Notes \nin Computer Science, pages 429 451. Springer-Verlag, July 2006. [19] S. Pheng and C. Verbrugge. Dynamic \ndata structure analysis for java programs. In International Conference on Program Comprehension, June \n2006. [20] D. Rayside, L. Mendel, and D. Jackson. A dynamic analysis for revealing object ownership and \nsharing. In Workshop on Dynamic Analysis, 2006. [21] R. Shaham, E. K. Kolodner, and M. Sagiv. Automatic \nremoval of array memory leaks in java. In Computational Complexity, pages 50 66, 2000. [22] Java 2 Platform, \nEnterprise Edition. http://java.sun. com/j2ee. [23] Quest Software. . Memory Debugger. JProbe Rhttp: \n//www.quest.com/jprobe, 2005. [24] SPEC Corporation. The SPEC JVM Client98 benchmark suite. http://www.spec.org/osg/jvm98, \n1998. [25] Yourkit LLC. Yourkit pro.ler. http://www.yourkit. com. [26] T. Xie and D. Notkin. Checking \ninside the black box: Regression testing based on value spectra differences. In International Conference \non Software Maintenance, pages 28 37, Chicago, Illinois, Sept. 2004. [27] T. Yang, M. Hertz, E. D. Berger, \nS. F. Kaplan, and J. E. B. Moss. Automatic heap sizing: Taking real memory into ac\u00adcount. In International \nSymposium on Memory Management, 2004.   \n\t\t\t", "proc_id": "1297027", "abstract": "<p>Applications often have large runtime memory requirements. In some cases, large memory footprint helps accomplish an important functional, performance, or engineering requirement. A large cache,for example, may ameliorate a pernicious performance problem. In general, however, finding a good balance between memory consumption and other requirements is quite challenging. To do so, the development team must distinguish effective from excessive use of memory.</p> <p>We introduce <i>health signatures</i> to enable these distinctions. Using data from dozens of applications and benchmarks, we show that they provide concise and application-neutral summaries of footprint. We show how to use them to form value judgments about whether a design or implementation choice is good or bad. We show how being independent ofany application eases comparison across disparate implementations. We demonstrate the <i>asymptotic</i> nature of memory health: certain designsare limited in the health they can achieve, no matter how much the data size scales up. Finally, we show how to use health signatures to automatically generate formulas that predict this asymptotic behavior, and show how they enable powerful limit studies on memory health.</p>", "authors": [{"name": "Nick Mitchell", "author_profile_id": "81100359733", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY", "person_id": "P346052", "email_address": "", "orcid_id": ""}, {"name": "Gary Sevitsky", "author_profile_id": "81100222382", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY", "person_id": "PP39085288", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1297027.1297046", "year": "2007", "article_id": "1297046", "conference": "OOPSLA", "title": "The causes of bloat, the limits of health", "url": "http://dl.acm.org/citation.cfm?id=1297046"}