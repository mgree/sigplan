{"article_publication_date": "10-21-2007", "fulltext": "\n Probabilistic Calling Context * Michael D. Bond Kathryn S. McKinley Department of Computer Sciences \nThe University of Texas at Austin {mikebond,mckinley}@cs.utexas.edu Abstract Calling context enhances \nprogram understanding and dy\u00adnamic analyses by providing a rich representation of pro\u00adgram location. \nCompared to imperative programs, object\u00adoriented programs use more interprocedural and less in\u00adtraprocedural \ncontrol .ow, increasing the importance of con\u00adtext sensitivity for analysis. However, prior online meth\u00adods \nfor computing calling context, such as stack-walking or maintaining the current location in a calling \ncontext tree, are expensive in time and space. This paper introduces a new on\u00adline approach called probabilistic \ncalling context (PCC) that continuously maintains a probabilistically unique value rep\u00adresenting the \ncurrent calling context. For millions of unique contexts, a 32-bit PCC value has few con.icts. Computing \nthe PCC value adds 3% average overhead to a Java virtual machine. PCC is well-suited to clients that \ndetect new or anomalous behavior since PCC values from training and pro\u00adduction runs can be compared \neasily to detect new context\u00adsensitive behavior; clients that query the PCC value at ev\u00adery system call, \nJava utility call, and Java API call add 0-9% overhead on average. PCC adds space overhead proportional \nto the distinct contexts stored by the client (one word per context). Our results indicate PCC is ef.cient \nand accurate enough to use in deployed software for residual testing, bug detection, and intrusion detection. \nCategories and Subject Descriptors D.2.5 [Software Engi\u00adneering]: Testing and Debugging Monitors, Testing \ntools General Terms Reliability, Security, Performance, Exper\u00adimentation * This work is supported by \nan Intel fellowship, NSF CCF-0429859, NSF CCR-0311829, NSF EIA-0303609, DARPA F33615-03-C-4106, In\u00adtel, \nIBM, and Microsoft. Any opinions, .ndings and conclusions expressed herein are the authors and do not \nnecessarily re.ect those of the sponsors. Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. OOPSLA 07, October 21 25, 2007, Montr\u00b4eal, Qu\u00b4ebec, Canada. Copyright \nc . 2007 ACM 978-1-59593-786-5/07/0010. . . $5.00 Keywords Calling Context, Dynamic Context Sensitivity, \nProbabilistic, Residual Testing, Anomaly-Based Bug Detec\u00adtion, Intrusion Detection, Managed Languages \n1. Introduction Several trends are making it harder for developers to under\u00adstand, test, debug, and optimize \napplications. Due to feature demand, one trend is that applications are larger, more com\u00adplicated, and \noften combine modules from disparate sources. Another trend is that more software is written in managed \nlanguages, such as Java and C# [46]. Development prac\u00adtices in these languages divide functionality into \nsmall meth\u00adods and thus express context as interprocedural control .ow rather than intraprocedural control \n.ow. Together the conse\u00adquences of these trends are that (1) programmers have more dif.culty understanding \nan entire application, (2) exhaustive testing is infeasible and even attaining high testing coverage \nis challenging, and (3) static analyses are less effective. As a result, developers are turning to dynamic \ntools to understand, test, and optimize their programs. Dynamic calling context is the sequence of active \nmethod invoca\u00adtions that lead to a program location. Previous work in testing [9, 11, 16, 20, 35, 39], \ndebugging and error report\u00ading [18, 31, 36, 41], and security [14, 23] demonstrates its utility. Calling \ncontext is powerful because it captures in\u00adterprocedural behavior and yet is easy for programmers to \nunderstand. For example, programmers frequently exam\u00adine calling context, in the form of error stack \ntraces, during debugging. Untested behavior such as unexercised calling contexts are called residuals \n[37]. If residual calling con\u00adtexts are observed in deployed software, they are clues to unmet test coverage \nobligations and potential bugs. Anoma\u00adlous sequences of calling contexts at system calls can reveal security \nvulnerabilities [14, 23]. Computing calling context cheaply is a challenge in non\u00adobject-oriented languages \nsuch as C, and it is even more challenging in object-oriented languages. Compared with C programs, Java \nprograms exacerbate this problem because they generally express more control .ow interprocedurally in \nthe call graph, rather than intraprocedurally in the control .ow graph. Our results show that Java has \nmore distinct contexts than comparable C programs [2, 42]. For example, large C programs such as GCC \nand 147.vortex have 57,777 and 257,710 distinct calling contexts respectively [2, 42], but the remaining \nsix SPEC CPU C programs in Ammons et al. s workload have fewer than 5,000 contexts. In contrast, we .nd \nthat 5 of 11 DaCapo Java benchmarks [10] contain more than 1,000,000 distinct calling contexts, and 5 \nothers contain more than 100,000 (Section 5). The simplest method for capturing the current calling context \nis walking the stack. For example, Valgrind walks the stack at each memory allocation to record its context\u00adsensitive \nprogram location, and reports this information in the event of a bug [36, 41]. If the client of calling \ncontexts very rarely needs to know the context, then the high over\u00adhead of stack-walking is easily tolerated. \nAn alternative to walking the stack is to build a calling context tree (CCT) dy\u00adnamically and to track \ncontinuously the program s position in the CCT [2, 42]. Unfortunately, tracking the program s current \nposition in a CCT adds a factor of 2 to 4 to pro\u00adgram runtimes. These overheads are unacceptable for \nmost deployed systems. Recent work samples hot calling contexts to reduce overhead for optimizations \n[52]. However, sam\u00adpling is not appropriate for testing, debugging, or checking security violations since \nthese applications need coverage of both hot and cold contexts. This paper introduces an approach called \nprobabilistic calling context (PCC) that continuously maintains a value that represents the current calling \ncontext with very low overhead. PCC computes this value by evaluating a func\u00adtion at each call site. \nTo differentiate calling contexts that include the same methods in a different order, we require a function \nthat is non-commutative. To optimize a sequence of inlined method calls into a single operation, we prefer \na function whose composition is cheap to compute. We show the computation V . 3\u00d7V +cs has these properties, \nwhere V is the current value of the calling context, and cs is a hash value for the current call site. \nWe show in theory and practice that this function produces a unique value for up to millions of contexts \nwith relatively few con.icts (false negatives). If necessary, a 64-bit PCC value can probabilistically \ndifferen\u00adtiate billions of unique calling contexts. PCC is well suited to adding context sensitivity \nto dy\u00adnamic analyses that detect new or anomalous program be\u00adhavior such as coverage testing, residual \ntesting, anomaly\u00adbased bug detection, and intrusion detection. These clients naturally have a training \nphase, which collects program be\u00adhavior, and a production phase, which compares behavior against training \nbehavior. Calling contexts across runs can be compared easily by comparing PCC values: two different \nPCC values de.nitely represent different contexts. Although a new PCC value indicates a new context, \nthe context is not determinable from the value, so PCC walks the stack when it encounters anomalous behavior \nto report the calling context. Using Jikes RVM [1, 26], we demonstrate on the DaCapo Benchmarks, SPEC \nJBB2000, and SPEC JVM98 that con\u00adtinuously computing a 32-bit PCC value adds on average 3% overhead. \nClients add additional overhead to query the PCC value at client-speci.c program points. We approximate \nthe overhead of querying the PCC value by looking up the value in a hash table on each query. Querying \nat every call in the application increases execution times by an average of 49% and thus is probably \nonly practical at testing time. In sev\u00aderal interesting production scenarios, we demonstrate that querying \nthe PCC value frequently is feasible: querying at every system call adds no measurable overhead, at every \njava.util call adds 3% overhead; and examining it at ev\u00adery Java API call adds 9% overhead. Computing \nthe PCC value adds no space overhead, but clients add space over\u00adhead proportional to the number of distinct \ncontexts they store (one word per context), which is millions in some cases but still much smaller than \nall statically possible contexts. In contrast, other approaches use space proportional to all contexts \nand/or use many words per context. To our knowl\u00adedge, PCC is the .rst approach to achieve low-overhead \nand always-available calling context. We believe this functional\u00adity can enable new online client analyses \nthat improve pro\u00adgram correctness, reliability, and security.  2. Motivation This section motivates \nef.cient tracking of calling context for improving testing, debugging, and security. Some pre\u00advious work \nshows dynamic context sensitivity helps these tasks [9, 14, 31, 23]. However, most prior work uses in\u00adtraprocedural \npaths or no control-.ow sensitivity for these tasks [3, 18, 20, 24, 47, 48] since paths are often good \nenough for capturing program behavior and calling context is too expensive to compute. Because developers \nmore of\u00adten now choose object-oriented, managed languages such as Java and C# [46], calling context is \ngrowing in impor\u00adtance for these tasks. In essence, Java programs use more method invocations (i.e., \ninterprocedural control .ow) and fewer control .ow paths (i.e., intraprocedural control .ow) compared \nwith C programs. This paper seeks to help enable the switch to dynamic context-sensitivity analyses by \nmak\u00ading them ef.cient enough for deployed systems. Testing. Half of application development time is spent \nin testing [6, 35]. A key part of testing is coverage, and one metric of coverage is exercising unique \nstatements, paths, calling contexts [9], and calling sequences that include the order of calls and returns \n[20, 39]. Residual testing identi.es untested coverage, such as paths, that occur at production time \nbut were not observed during testing [37, 47]. PCC is well-suited to context-sensitive residual testing \nsince it identi.es new contexts with high probability while adding low enough overhead for deployed software. \nDebugging. Identifying program behavior correlated with incorrect execution often helps programmers .nd \nbugs. Pre\u00advious work in anomaly-based bug detection (also called invariant-based bug detection and statistical \nbug isolation) tracks program behavior such as variables values across multiple runs to identify behavior \nthat is well-correlated with errors [19, 30, 32]. We are not aware of work that uses calling context \nfor anomaly-based bug detection, although the high time and space overhead may be a factor. Some previous \nwork uses a limited amount of calling context in features in bug detection. Liu et al. use behavior graphs, \nwhich include call relationships (essentially one level of con\u00adtext sensitivity), to help identify call \nchains correlated with bugs [31]. Clarify uses call-tree pro.ling, which measures two levels of context \nsensitivity as well as the order of calls, to classify program executions for better error reporting, \na task similar to bug-.nding [18]. We note that programmers already appreciate the usefulness of calling \ncontext in debug\u00adging tasks. For example, developers typically start with an error stack trace to diagnose \na crash and Valgrind, a testing\u00adtime tool, reports context-sensitive allocation sites for heap blocks \ninvolved in errors [36]. Artemis provides a framework for selectively sampling bug detection instrumentation \nto keep overhead low [13]. The key idea is to track contexts and to avoid sampling con\u00adtexts that have \nalready been sampled. Artemis s de.nition of context includes values of local and global variables but \ndoes not include calling context, possibly because of the cost of computing it. PCC makes it viable to \nadd calling context to Artemis. Security. Anomaly-based intrusion detection seeks to de\u00adtect new attacks \nby identifying anomalous (i.e., previously unseen) program behavior [14, 24, 48]. Existing approaches \ntypically keep track of system calls and .ag system call se\u00adquences that deviate from previously-observed \nbehavior and may indicate an attacker has hijacked the application. Wag\u00adner and Soto show that attackers \ncan circumvent these ap\u00adproaches by mimicking normal application behavior while still accomplishing attacks \n[48]. Adding context sensitivity to the model of acceptable behavior constrains what attack\u00aders can do \nwithout getting caught, and recent work on in\u00adtrusion detection uses calling context to identify program \ncontrol-.ow hijacking [14, 23, 51]. Inoue on page 109 in his dissertation writes the following [23]: \nAdding context by increasing the number of observed stack frames can make some attacks signi.cantly more \ndif.cult. So-called mimicry attacks take advantage of the inner workings of applications to attack while \nstill behaving simi\u00adlarly to the attacked application. Adding context makes this more dif.cult because \nit restricts the attacker to using only methods usually invoked from within the enclosing method that \nthe exploit attacks, instead of any method invoked by the entire application. Zhang et al. show that \nk-length interprocedural paths gath\u00adered with hardware reveal possible security violations [51]. Feng \net al. utilize a single level of context sensitivity by in\u00adcluding each system call s return address \nin the sequence of system calls, constraining possible attacks [14]. We show that the expense of walking \nthe stack stands in the way of deployed use of context-sensitive system calls but that PCC permits cheap \ncomputation of context sensi\u00adtivity (Section 5). An intrusion detection system could use PCC to record \nthe calling context for each system call in sequences of system calls. Because PCC is probabilistic, \nit may incur false negatives if it misses anomalous calling con\u00adtexts that map to the same value as an \nalready-seen calling context. However, the con.ict rate is very low, 0.1% or less for up to 10 million \ncontexts with 32-bit values, and 64-bit values provide even fewer con.icts. A determined attacker with \nknowledge of PCC could potentially engineer an at\u00adtack using an anomalous calling context with a con.icting \nPCC value. We believe randomizing call site values on the host would make a con.ict attack virtually \nimpossible, al\u00adthough we do not prove it. In summary, existing work shows dynamic calling con\u00adtext is \nuseful for residual testing, anomaly-based bug detec\u00adtion, and intrusion detection. Trends toward managed \nlan\u00adguages and more complex applications are likely to make dynamic context sensitivity more essential, \nand PCC has the potential to help make it feasible. 3. Probabilistic Calling Context This section describes \nour approach for ef.ciently comput\u00ading a value that represents the current calling context and is unique \nwith high probability. 3.1 Calling Context The current program location (method and line number) and \nthe active call sites on the stack de.ne dynamic calling con\u00adtext. For example, the .rst line below is \nthe current program location, and the remaining lines are the active call sites: at com.mckoi.database.jdbcserver.JDBCDatabaseInterface. \nexecQuery():213 at com.mckoi.database.jdbc.MConnection. executeQuery():348 at com.mckoi.database.jdbc.MStatement. \nexecuteQuery():110 at com.mckoi.database.jdbc.MStatement. executeQuery():127 at Test.main():48  3.2 \nProbabilistic Approach Probabilistic calling context (PCC) keeps track of an integer value, V , that \nrepresents the current calling context. Our goal is to compute random, independent values for each context. \nTo determine the feasibility of this approach, we assume a random number generator and use the following \nformula to determine the number of expected con.icts given population size n and 32-or 64-bit values \n[34]: Random Expected con.icts values 32-bit values 64-bit values 1,000 0 (0.0%) 0 (0.0%) 10,000 0 (0.0%) \n0 (0.0%) 100,000 1 (0.0%) 0 (0.0%) 1,000,000 116 (0.0%) 0 (0.0%) 10,000,000 11,632 (0.1%) 0 (0.0%) 100,000,000 \n1,155,170 (1.2%) 0 (0.0%) 1,000,000,000 107,882,641 (10.8%) 0 (0.0%) 10,000,000,000 6,123,623,065 (61.2%) \n3 (0.0%) Table 1. Expected con.icts for various populations of ran\u00addom numbers using 32-bit and 64-bit \nvalues. ..n m - 1 E[con.icts]:=n - m +m m where m is the size of the value range (e.g., m =232 for 32-bit \nvalues). Table 1 shows the expected number of con\u00ad.icts for populations ranging in size from one thousand \nto ten billion. For example, if we choose 10 million random 32-bit numbers, we can expect 11,632 con.icts \non average. Applied to the calling context problem, if a program exe\u00adcutes 10 million distinct calling \ncontexts, we expect to miss contexts at a rate of just over over 0.1%, which is likely good enough for \nmany clients. The programs we evaluate execute fewer than 10 million distinct calling contexts (except \neclipse with the large input; Section 5.1). For programs with many more distinct calling contexts, or \nfor clients that need greater probability guarantees, 64-bit values should suf.ce. For example, one can \nexpect only a handful of con.icts for as many as 10 billion distinct calling contexts.  3.3 Computing \nCalling Context Values The previous section shows that assigning randomly-chosen PCC values results in \nan acceptably small level of con.icts (i.e., distinct calling contexts with the same value). This section \nintroduces an online approach for computing a PCC value that has the following properties: PCC values \nmust be distributed roughly randomly so that the number of value con.icts is close to the ideal.  The \nPCC value must be deterministic, i.e., a given calling context always computes the same value.  Computing \nthe next PCC value from the current PCC value must be ef.cient.  We use a function f(V,cs) where V is \nthe current calling context value and cs is the call site at which the function is evaluated. We add \ninstrumenta\u00adtion that computes the new value of V at each call site by applying f as follows: method() \n{ int temp = V; // ADDED: load PCC value ... V = f(temp, cs_1); // ADDED: compute new value cs_1: calleeA(...); \n// call site 1 ... V = f(temp, cs_2); // ADDED: compute new value cs_2: calleeB(...); // call site 2 \n... }  We have two requirements for this function: non-commutativity and ef.cient composability. Non-commutativity. \nWe have found that our benchmarks contain many distinct calling contexts that differ only in the order \nof call sites. For example, we want to differenti\u00adate calling context ABC from CAB. We therefore require \na function that is non-commutative and thus computes a distinct value when call sites occur in different \norders. Ef.cient composability. We want to handle method inlin\u00ading ef.ciently and gracefully because \nof its widespread use in high-performance static and dynamic compilers. For example, suppose method A \ncalls B calls C calls D. If the compiler inlines B and C into A,now A calls D. We want to avoid evaluating \nf three times before the in\u00adlined call to D. By choosing a function whose composi\u00adtion can be computed \nef.ciently ahead-of-time, we can statically compute the inlined call site value that repre\u00adsents the \nsequence of call sites B, C, D. We use the following non-commutative but ef.ciently com\u00adposable function \nto compute PCC values: f(V,cs):=3\u00d7 V +cs where \u00d7 is multiplication (modulo 232), and +is addition (modulo \n232). We statically compute cs for a call site with a hash of the method and line number. The function \nis non-commutative because evaluating call sites in different orders do not give the same value in general: \nf(f(V,csA),csB )= 9\u00d7 V +(3\u00d7 csA)+csB) .f(f(V,csB),csA)= = 9\u00d7 V +(3\u00d7 csB)+csA) since in general (3\u00d7 csA)+csB \n.=(3\u00d7 csB)+csA Non-commutativity is a result of mixing addition and multi\u00adplication (which are commutative \noperations by themselves). At the same time, the function s composition is ef.cient be\u00adcause addition \nand multiplication are distributive with re\u00adspect to each other: f(f(V,csA),csB)= 3\u00d7 (3\u00d7 V +csA)+csB \n= 9\u00d7 V +(3\u00d7 csA +csB) Note that (3 \u00d7 csA + csB) is a compile-time constant, so the composition is as \nef.cient to compute as f. Gropp and Langou et al. use similar functions to compute hashes for Message \nPassing Interface (MPI) data types [17, 28]. We experimented with these and other related func\u00adtions. \nFor example, multiplying by 2 is attractive because it is equivalent to bitwise shift, but bits for methods \nlow on the stack are lost as they are pushed off to the left. Circular shift (equivalent to multiplication \nby 2 modulo 232 -1) solves this problem, but when combined with addition modulo 232 - 1 (necessary to \nkeep ef.cient composability), we lose infor\u00admation about multiple consecutive recursive calls; i.e., \n32 consecutive recursive calls computes f32(V,cs),which for this function is simply V for any V and cs. \n 3.4 Querying Calling Context Values This section describes how clients can query PCC values at program \npoints. In any given method, V represents the cur\u00adrent dynamic context, except for the position in the \ncurrently executing method. To check V at a given program point, we simply apply f to V using the value \nof cs for the current site (not necessary a call site), i.e., current local method and line number: method() \n{ ... cs: query(f(V, cs)); // ADDED: query PCC value statement_of_interest; // application code ... } \nPCC is most applicable to clients that detect new or anoma\u00adlous behavior, which naturally tend to have \ntwo modes, training and production. In training, clients can query PCC values and store them. In production, \nclients query PCC val\u00adues and determine if they represent anomalous behavior; if so, PCC walks the stack \nto determine the calling context represented by the anomalous PCC value. Many anoma\u00adlous contexts in \nproduction could add high overhead because each new context requires walking the stack. However, this \ncase should be uncommon for a well-trained application.  4. Implementation PCC s approach is suitable \nfor implementation in ahead\u00adof-time or dynamic compilation systems. This section de\u00adscribes how we implement \nPCC in Jikes RVM 2.4.6, a high\u00adperformance Java-in-Java virtual machine [4, 26]. PCC is publicly available \non the Jikes RVM Research Archive [27]. Jikes RVM uses two compilers at run time. When a method .rst \nexecutes, Jikes RVM compiles it with a non\u00adoptimizing baseline compiler. When a method becomes hot, Jikes \nRVM recompiles it with an optimizing compiler at successively higher levels of optimization. We modify \nboth compilers to insert PCC instrumentation. Computing the PCC value. PCC adds instrumentation to maintain \nV that computes f(V,cs) at each call site, where cs is an integer representing the call site. PCC could \nassign each call site a random integer using a lookup table, but this approach adds space overhead and \ncomplicates comparing PCC values across runs. Instead, PCC computes a hash of the call site s method \nname, declaring class name, descriptor, and line number. This computation is ef.cient because it occurs \nonce at compile time and produces the same results across multiple program executions. Implicitly, V \nis a global variable modi.ed at each call site. To implement PCC in the context of multiple threads and \nprocessors, we use per-thread PCC values. Since multi\u00adple threads map to a single processor, each processor \nkeeps track of the PCC value for the current thread. When a proces\u00adsor switches threads, it stores the \nPCC value to the outgoing thread and loads the PCC value from the incoming thread. Accessing the PCC \nvalue is ef.cient in Jikes RVM because it reserves a register for per-processor storage. In systems without \nef.cient access to per-processor storage, an imple\u00admentation could modify the calling conventions to \nadd the PCC value as an implicit parameter to every method. While this alternative approach is elegant, \nwe did not implement it because it would require pervasive changes to Jikes RVM. To compute PCC values, \nthe compiler adds instrumenta\u00adtion that (1) at the beginning of each method, loads V into a local variable, \n(2) at each call site, computes the next call\u00ading context with f and updates the global V , and (3) at \nthe method return, stores the local copy back to the global V (this redundancy is helpful for correctly \nmaintaining V in the face of exception control .ow). At inlined call sites, the compiler combines multiple \ncall site values ahead-of-time into a single value and inserts a function that is an ef.cient composition \nof multiple instances of f (Section 3.3). Querying the PCC value. Clients may query PCC values at different \nprogram points, and they may use PCC val\u00adues differently. For example, an intrusion detection client \nmight query the PCC value at each system call, recording se\u00adquences of consecutive context-sensitive \nprogram locations (in the form of PCC values) during training, then detect\u00ading anomalous sequences during \nproduction. A client per\u00adforms work per query that is likely to be similar to hash ta\u00adble lookup, so \nour implementation looks up the PCC value in a global hash table at each query point. The hash table \nimplements open-address hashing and double hashing [12] using anarrayof 2k 32-bit slots. To look up a \nPCC value, the query indexes the array using the low k bits of V ,and checks if the indexed slot contains \nV . In the common case, the slot contains V , and no further action is needed. In the uncommon case, \neither (1) the slot is empty (contains zero), in which case PCC stores V in the slot; or (2) the slot \nholds another PCC value, in which case the query performs sec\u00adondary hashing by advancing s +1 slots \nwhere s is the high 32 - k bits of V . Secondary hashing tries three times to .nd a non-con.icting slot, \nthen gives up. For ef.ciency, we inline the common case into hot, opti\u00admized code. For simplicity in \nour prototype implementation, we use a .xed-size array with 220 =1, 048, 576 elements (4 MB of space), \nbut a more .exible implementation would ad\u00adjust the size to accommodate the number of stored PCC val\u00adues \ncollected during training (e.g., intrusion detection clients could use much less space since there are \nrelatively few dis\u00adtinct contexts at system calls). The hash table approach is ef.cient as long as the \ntable size is roughly at least twice the size of the number of entries in the table, or table con.icts \nwill lead to high overhead. Of our benchmarks, pmd queries the most distinct PCC values, over 800,000 \nat Java API calls (Table 3), for which a hash table with a million elements is probably not quite large \nenough for good performance. We also measure the overhead of querying the PCC value at ev\u00adery call as \nan upper bound for a PCC client (Figure 1); for several benchmarks with millions of distinct contexts, \nthe hash table is not large enough, resulting in many hash ta\u00adble lookup failures, but the time overhead \nshould still be a representative upper bound. De.ning calling context. Our implementation distinguishes \nbetween VM methods (de.ned in Jikes RVM classes), Java library methods (java.* classes), and application \nclasses (all other classes). The implementation does not consider VM and library call sites to be part \nof calling context, since call sites in these methods are probably not interesting to de\u00advelopers and \nare often considered black boxes. All appli\u00adcation methods on the stack are considered part of the calling \ncontext, even if VM or library methods are above them. For example, container classes often access application-de.ned \nequals() and hashCode() methods: at result.Value.equals():164 at java.util.LinkedList.indexOf():406 at \njava.util.LinkedList.contains():176 at option.BenchOption.getFormalName():80 at task.ManyTask.main():46 \n Our implementation considers this context to be simply at result.Value.equals():164 at option.BenchOption.getFormalName():80 \nat task.ManyTask.main():46 Similarly, sometimes the application triggers the VM, which calls the application, \nsuch as for class initialization: at dacapo.TestHarness.<clinit>():57 at com.ibm.JikesRVM.classloader.VM_Class. \ninitialize():1689 at com.ibm.JikesRVM.VM_Runtime. initializeClassForDynamicLink():545 at com.ibm.JikesRVM.classloader. \nVM_TableBasedDynamicLinker.resolveMember():65 at com.ibm.JikesRVM.classloader. VM_TableBasedDynamicLinker.resolveMember():54 \nat Harness.main():5 Our implementation considers this context to be at dacapo.TestHarness.<clinit>():57 \nat Harness.main():5  PCC implements this de.nition of calling context. PCC in\u00adstruments application \nmethods only, and in these methods it instruments call sites to application and library methods. In cases \nwhere the application calls the VM directly, and the VM then invokes the application (e.g., for class \ninitializa\u00adtion), PCC walks the stack to determine the correct value of V , which is feasible because \nit happens infrequently. 5. Results This section evaluates the performance and accuracy of probabilistic \ncalling context (PCC). The methodology sub\u00adsection .rst describes deterministic calling context pro.ling, \nwhich we use to measure the accuracy of PCC, and experi\u00admental con.gurations, benchmarks, and platform. \nThen we present the query points we evaluate, which correspond to potential clients of PCC. Next we evaluate \nPCC s accuracy at identifying new contexts at these query points, then mea\u00adsure PCC s time and space \nperformance and compare it to walking the stack. Finally we evaluate PCC s ability to iden\u00adtify new contexts \nnot observed in a previous run and the power of calling context to detect new program behavior not detectable \nwith context-insensitive pro.ling. 5.1 Methodology Deterministic calling context pro.ling. To evaluate \nthe accuracy of PCC and to collect other statistics, we also im\u00adplement deterministic calling context \npro.ling. Our imple\u00admentation constructs a calling context tree (CCT) and main\u00adtains the current position \nin the CCT throughout execution. Our implementation is probably less time and space ef.\u00adcient than the \nprior work (Section 6) because (1) it collects per-node statistics during execution, and (2) for simplicity, \nwe modify only the non-optimizing baseline compiler and disable the optimizing compiler for these experiments \nonly. Since we only use it to collect statistics, we are not con\u00adcerned with its performance. VM con.gurations. \nJikes RVM runs by default using adaptive methodology. Initially it uses a baseline non\u00adoptimizing compiler. \nThen it dynamically identi.es frequently\u00adexecuted methods and recompiles them at higher optimiza\u00adtion \nlevels. Because Jikes RVM uses timer-based sampling to detect hot methods, the adaptive compiler is nondetermin\u00adistic. \nTo measure performance, we use replay compilation methodology, which is deterministic [22]. Replay compila\u00adtion \nforces Jikes RVM to compile the same methods in the same order at the same point in execution on different \nexecu\u00adtions and thus avoids high variability due to sample-driven compilation. Replay compilation uses \nadvice .les produced by a previ\u00adous well-performing adaptive run (best of .ve). The advice .les specify \n(1) the optimization level for compiling each method, (2) the dynamic call graph pro.le, and (3) the \nedge pro.le. Fixing these inputs, we execute two consecutive it\u00aderations of the application. During the \n.rst iteration, Jikes RVM optimizes code using the advice .les. The second it\u00aderation executes only the \napplication with a realistic mix of unoptimized and optimized code. We execute performance results using \na generational mark-sweep collector and a .xed heap size of three times the minimum for each benchmark. \nWe report the minimum of .ve trials since it represents the deterministic run least perturbed by external \neffects. Benchmarks. We use the DaCapo benchmarks (version 2006-10), a .xed-workload version of SPEC \nJBB2000 called pseudojbb, and SPEC JVM98 [10, 43, 44]. We ex\u00adclude xalan from performance results because \nwe could not get it to run correctly with replay compilation, with or with\u00adout PCC. We use the large \ninput size for all performance and statistics runs, except we use medium for eclipse s statis\u00adtics runs \nsince with large our deterministic calling context implementation runs out of memory: eclipse s large \ninput executes at least 41 million distinct contexts. Platform. We perform experiments on a 3.6 GHz Pentium \n4 with a 64-byte L1 and L2 cache line size, a 16KB 8\u00adway set associative L1 data cache, a 12K\u00b5ops L1 \ninstruction trace cache, a 2MB uni.ed 8-way set associative L2 on-chip cache, and 2 GB main memory, running \nLinux 2.6.12.  5.2 Potential PCC Clients PCC continuously keeps track of a probabilistically unique \nvalue that represents the current dynamic calling context. To evaluate PCC s use in several potential \nclients, we query the PCC value at various program points corresponding to these clients needs. System \ncalls. Anomaly-based security intrusion detection typically collects sequences of system calls, and adding \ncontext-sensitivity can strengthen detection (Section 2). To explore this potential client, we add a \ncall to PCC s query method before each system call, i.e., each call that can po\u00adtentially throw a Java \nsecurity exception. The callees roughly correspond to operations that can affect external state, e.g., \n.le system I/O and network access. Our benchmarks range in behavior from very few to many system calls. \nPrograms most prone to security intrusions, such as web servers, are likely to have many system calls. \nJava utility calls. Residual testing seeks to determine whether behavior seen at production time deviates \nfrom be\u00adhavior seen at testing time [37, 47]. Residual testing of a software component at production \ntime detects if the com\u00adponent is called from a new, untested context. These contexts may indicate errors \nin the application or poor test coverage. While application developers often perform residual testing \non a component of their own application, we use the Java utility libraries as a surrogate for exploring \nresidual testing on a component library. These libraries provide function\u00adality such as container classes, \ntime and date conversions, and random numbers. This choice is justi.ed because these libraries are heavily \nused by our benchmarks and other pro\u00adgrams. At each call to a java.util.* method, instrumen\u00adtation queries \nthe PCC value. Java API calls. We also explore residual testing using the Java API libraries as a surrogate. \nThis library is a superset of java.util. We add instrumentation to query the PCC value at each call to \na method in java.*. This simulates residual testing of a larger component, since calls to java.* methods, \nespecially java.lang.* methods, are extremely frequent in most Java programs (e.g., all String operations \nare in the API libraries). The results for Java API calls show that PCC scales well to a frequently-used \ncomponent invoked from many distinct contexts. All calls. In addition, we evaluate querying the PCC value \nat every call site. This con.guration would be useful for measuring code coverage and generating tests \nwith good code coverage [9, 20, 39], and it represents an upper bound on overhead for possible PCC clients. \nWe .nd querying PCC values at every call is too expensive for deployed use but can speed up testing time \ncompared with walking the stack. 5.3 PCC Accuracy Table 2 shows calling context statistics for the .rst \nthree potential clients from the previous section. Dynamic is the number of dynamic calls to query. For \nexample, for sys\u00adtem calls, Dynamic is the dynamic number of system calls. Distinct is the number of \ndistinct calling contexts that occur at query points. Conf. is the number of PCC value con.icts that \noccur for these calling contexts. Con.icts indicate when PCC maps two or more distinct calling contexts \nto the same value (k contexts mapping to the same value count as k - 1 con.icts). We summarize the dynamic \nand distinct counts using geometric mean. The benchmarks show a wide range of behavior with re\u00adspect \nto system calls. Seven benchmarks perform more than 1,000 dynamic system calls, and two benchmarks (antlr, \njython) exercise more than 1,000 distinct contexts at sys\u00adtem calls. No PCC value con.icts occur between \ncontexts. As expected, the programs make signi.cantly more calls into the utility libraries and the entire \nJava API. For the utility libraries, dynamic calls range from about a thou\u00adsand for several SPEC JVM98 \nbenchmarks to a billion for bloat, and the number of unique contexts ranges from 176 to 442,845. For \nthe Java API, the dynamic calls are up to 2 billion for xalan, and distinct contexts range from 905 to \n847,108. These potential clients will therefore require many PCC value queries, but as we show in the \nnext section, PCC is ef.cient even with this high load. The numerous zero entries in the Conf. columns \nshow that PCC is completely accurate in many cases. The con.icts are low at most 79 for pmd s 847,108 \ndistinct contexts at API calls and are consistent with the ideal values from Table 1. Table 3 presents \ncalling context statistics for all executed contexts, as well as average and maximum call depth. To \nSystem calls Java utility calls Java API calls  Program Dynamic Distinct Conf. Dynamic Distinct Conf. \nDynamic Distinct Conf. antlr 211,490 1,567 0 698,810 8,010 0 24,422,013 128,627 3 bloat 12 10 0 1,030,955,346 \n143,587 3 1,159,281,573 600,947 40 chart 63 62 0 43,345,653 44,502 0 258,891,525 202,603 4 eclipse 14,110 \n197 0 3,958,510 54,175 0 132,507,343 226,020 5 fop 18 17 0 5,737,083 25,528 0 9,918,275 37,710 0 hsqldb \n12 12 0 90,324 267 0 81,161,541 16,050 0 jython 5,929 4,289 0 76,150,625 131,992 2 543,845,772 628,048 \n48 luindex 2,615 14 0 5,437,548 1,024 0 39,733,214 102,556 0 lusearch 141 11 0 23,183,861 176 0 113,511,311 \n905 0 pmd 1,045 25 0 372,159,946 442,845 24 537,017,118 847,108 79 xalan 137,895 59 0 744,311,518 6,896 \n0 2,105,838,670 17,905 0 DaCapo geo 843 60 19,667,815 12,689 163,072,787 85,963 pseudojbb 507,326 145 \n0 18,944,200 475 0 30,340,974 3,410 0 compress 7 5 0 1,018 682 0 8,138 1,081 0 jess 50 6 0 4,851,299 \n2,061 0 16,487,052 5,240 0 raytrace 7 5 0 1,078 684 0 5,331,338 3,383 0 db 7 5 0 65,911,710 767 0 90,130,132 \n1,439 0 javac 7 5 0 6,499,455 55,994 0 24,677,625 255,334 4 mpegaudio 7 5 0 874 682 0 7,575,084 1,668 \n0 mtrt 7 5 0 880 682 0 5,573,455 3,366 0 jack 7 5 0 14,987,342 14,718 0 21,771,285 29,461 0 SPEC geo \n30 7 199,386 1,724 7,074,200 5,410 Geomean 188 23 2,491,316 5,168 39,734,213 24,764 Table 2. Statistics \nfor calling contexts at several subsets of call sites. Dynamic and distinct contexts, and PCC value con.icts, \nfor (1) system calls, (2) Java utility calls, and (3) Java API calls. All contexts Call depth Table \n3. Statistics for every calling context executed. Dynamic and distinct contexts, PCC value con.icts, \nand average and maximum size (call depth) of dynamic contexts. pro.le every context, we query calling \ncontext at every call site, as well as every method prologue in order to capture leaf calls. The table \nshows six programs execute over one million distinct contexts and another .ve over one hundred thousand \ncontexts. The last two columns show that programs spend a lot of time in fairly deep call chains: average \ncall depth is almost 20, and maximum call depth is over 100 for several benchmarks.  5.4 PCC Performance \nThis section evaluates PCC s run-time performance. We evaluate PCC alone without a client and also measure \nthe additional cost of using PCC with four sets of query points corresponding to potential clients (Section \n3.4). These ex\u00adperiments report application time only using replay compi\u00adlation, which produces a deterministic \nmeasurement. Figure 1 shows the run-time overhead of PCC, normal\u00adized to Base, which represents execution \nwithout any instru\u00admentation. PCC is the execution time of PCC alone: instru\u00admentation keeps track of \nthe PCC value throughout execu\u00adtion but does not use it. The .nal four bars show the execu\u00adtion time \nof examining the PCC value at call sites correspond to potential clients: system calls, Java utility \ncalls, Java API calls, and all calls. PCC actually improves chart s perfor\u00admance, but this anomaly is \nmost likely because of architec\u00adtural sensitivities due code modi.cations that may affect the trace cache \nand branch predictor. PCC by itself adds only 3% on average and 9% at most (for hsqldb). Since system \ncalls are relatively rare, checking the context at each one adds negligible overhead on average. PCC \nvalue checking at Java utility and API calls adds 2% and 9% on average over PCC tracking, respectively, \nwhich is interesting given the high frequency of these calls (Table 2). The highest overhead is 47%, \nfor bloat s API calls. Compilation overhead. By adding instrumentation to ap\u00adplication code, PCC increases \ncompilation time. We mea\u00adsure compilation overhead by measuring time spent in the baseline and optimizing \ncompilers during the .rst iteration of replay compilation. Figure 2 shows compilation time overhead. \nPCC instrumentation alone adds 18% compila\u00adtion overhead on average. Adding instrumentation to query \nthe PCC value increases compilation time by an additional 0-31% for system, utility, and API calls, and \nup to 150% for all calls, although this overhead could be reduced by not inlining the query method. Per-phase \ncompiler timings show that most of the compilation overhead comes from com\u00adpiler phases downstream from \nPCC instrumentation, due to the bloated intermediate representation (IR). Although PCC adds a greater \npercentage to compilation than application time, many adaptive optimizers control the fraction of time \nspent in compilation. Therefore by design, compilation time is a small fraction of overall execution \ntime. In our exper\u00adiments, the time spent in the application is on average 20 times greater than the \ntime spent in compilation, for each of the PCC con.gurations shown in Figure 2. Space overhead. Computing \nthe PCC does not add space overhead to keep track of the PCC value, but of course the clients use space \nproportional to the number of PCC values they store. Our experiments that test potential clients simply \nuse a .xed-size hash table with 220 =1, 048, 576 slots (4 MB), as described in Section 4, but real clients \nwould use space proportional to their needs. Clients storing PCC values in a large data structure could \npotentially hurt execution time due to poor access locality. PCC also adds space overhead by increasing \nthe size of generated machine code. We .nd that on average, PCC in\u00adstrumentation adds 18% to code size. \nAdding instrumenta\u00adtion to query the PCC value at system calls, utility calls, API calls, and all calls \nadds an additional 0%, 2%, 6%, and 14%, respectively. Comparison with stack-walking. An alternative to \nPCC is to walk the stack at each query point (Section 6). We evaluate here how well stack-walking performs \nfor the call sites cor\u00adresponding to potential clients. We implement stack-walking by simply calling \na method that walks the entire stack at each query point; we do not add any PCC instrumentation for these \nruns. Stack-walking implementations would typi\u00adcally look up a unique identi.er for the current context \n[36], and they could save time by walking only the subset of calls occurring since the last walk [49], \nbut we do not model these costs here. Figure 3 shows the execution time overhead of walking the stack \nat various points corresponding to three potential clients: system calls, Java utility calls, and Java \nAPI calls (we omit all calls because its overhead is greater than for Java API calls, which is very high). \nSince most benchmarks have few dynamic system calls, stack-walking adds negligi\u00adble overhead at these \ncalls. However, for the two benchmarks with more than 200,000 dynamic system calls, antlr and pseudojbb, \nstack-walking adds 67% and 62% overhead, re\u00adspectively. These results show the substantial cost of walking \nthe stack even for something as infrequent as system calls. Applications prone to security attacks such \nas web servers are likely to have many system calls. 5.5 Comparing Calling Contexts Between Runs The \nprevious sections demonstrate that PCC is an ef.cient mechanism for identifying new context-sensitive \nbehavior in a variety of potential clients. This section explores the sensitivity of calling context \nbehavior to different program inputs by comparing calling context pro.les between two runs of each benchmark, \nthe large and medium input sets. We note that while some benchmarks execute many new distinct contexts \nwith the large input not seen with medium (which is not surprising since it is a larger workload by design), \nwe do not expect so much new behavior in production mode on well-trained applications. Nonetheless, the \nresults are 2.3 2.8 2.1 Figure 1. Application execution time overhead of maintaining the PCC value and \nquerying it at (1) system calls, (2) Java utility calls, (3) Java API calls, and (4) all calls. 2.3 2.2 \n2.5 Figure 2. Compilation time overhead due to adding instrumentation to maintain the PCC value and \nquery it at (1) system calls, (2) Java utility calls, (3) Java API calls, and (4) all calls. >10.0 >10.0 \n>10.0 >10.0 >10.0 >10.0 >10.0 >10.0 >10.0 >10.0 >10.0 >10.0 >10.0 3.1 >10.0 7.1 >10.0 >10.0>10.0 >10.0 \n8.9 >10.0 >10.0 >10.0 3.5 >10.0 >10.0 >10.0 2.7 >10.0 Figure 3. Application execution time overhead \nof walking the stack at (1) system calls, (2) Java utility calls, and (3) Java API calls.  Relative \nincrease of large input compared to medium input Java utility calls Java API contexts  Program Dyn. \nNew distinct Conf. Dyn. New distinct Conf. antlr 2.5x 0 (0.0%) 0 2.5x 8 (0.0%) 0 bloat 11.8x 74,536 (51.9%) \n3 10.2x 320,864 (53.4%) 33 chart 2.3x 31,419 (70.6%) 0 2.5x 139,599 (68.9%) 4 eclipse* 4.2x 15,114 (27.9%) \n0 5.8x 121,939 (54.0%) 4 fop 1.0x 0 (0.0%) 0 1.0x 0 (0.0%) 0 hsqldb 6.0x 0 (0.0%) 0 2.5x 13 (0.1%) 0 \njython 7.5x 12,705 (9.6%) 0 7.3x 59,202 (9.4%) 5 luindex 1.0x 0 (0.0%) 0 1.0x 7,398 (7.2%) 0 lusearch \n2.0x 0 (0.0%) 0 2.0x 0 (0.0%) 0 pmd 4.4x 368,862 (83.3%) 24 4.4x 711,223 (84.0%) 79 xalan 10.0x 0 (0.0%) \n0 10.0x 15 (0.1%) 0 Dacapo geo 3.5x 3.3x compress 1.1x 0 (0.0%) 0 2.2x 0 (0.0%) 0 jess 61.5x 530 (25.7%) \n0 56.7x 1,827 (34.9%) 0 raytrace 1.0x 0 (0.0%) 0 11.0x 25 (0.7%) 0 db 71.6x 25 (3.3%) 0 61.4x 72 (5.0%) \n0 javac 39.9x 36,419 (65.0%) 0 36.9x 163,916 (64.2%) 6 mpegaudio 1.0x 0 (0.0%) 0 10.9x 32 (1.9%) 0 mtrt \n1.0x 0 (0.0%) 0 7.7x 25 (0.7%) 0 jack 8.5x 0 (0.0%) 0 8.5x 0 (0.0%) 0 SPEC geo 6.0x 14.7x Geomean 4.4x \n6.2x Table 4. Comparing calling contexts at API calls between large and medium inputs. *Medium vs. small \nfor eclipse. interesting because they give an indication of how calling context behavior differs from \none run to the next and how well PCC identi.es new context-sensitive behavior. Table 4 compares the calling \ncontexts at Java utility and Java API calls for runs with the medium and large inputs. We do not show \ndata for system calls since they vary very little between medium and large inputs: only .ve benchmarks \nex\u00adecute new calling contexts at system calls (chart executes the most, 38). We omit pseudojbb since \nit has only one input size. We use small and medium for eclipse (Sec\u00adtion 5.1). In the table, Dyn. is \nthe factor increase of dynamic calling contexts in the large run vs. the medium run. All DaCapo programs \nexcept fop and luindex exercise substantially more dynamic calls to the utility libraries and to the \nwhole Java API. New distinct is the number of new distinct calling contexts occurring in the large but \nnot in the medium run, and the percentage is the value relative to all distinct call\u00ading contexts from \nthe large run. Conf. is the number of PCC value con.icts that occur when adding the new PCC values seen \nonly in the large run, to the set of PCC values seen in the medium run. For example, pmd executes more \nthan four times as many dynamic Java API calls in the large as in the medium run, and 711,223 distinct \ncontexts occur in the large run that were not observed in the medium run. These con\u00adtexts account for \n84% of the large run s distinct contexts; and PCC values for these new calling contexts have 79 con\u00ad.icts \nwhen added to the PCC values from the medium run, so the probability of a particular new calling context \nnot being identi.ed as new is about 1 in 10,000. Eleven of the pro\u00adgrams execute few if any new distinct \ncalling contexts, even if they execute many times more dynamic calls to Java utility and API methods, \nwhile .ve benchmarks execute hundreds of thousands of new distinct calling contexts. The programs generate \nabout 1 con.ict for every 10,000 new contexts at worst, which should be a reasonable false negative rate \nfor most clients.  5.6 Evaluating Context Sensitivity This section compares calling context pro.ling \nto call site pro.ling, which is context insensitive, to evaluate whether calling context detects signi.cantly \nmore previously unob\u00adserved behavior than call sites alone. Table 5 compares call\u00ading contexts and call \nsites. The .rst two columns are counts of distinct calling contexts and call sites for calls to Java \nAPI methods (the calling context .gures are the same as in Table 2). For most programs, there are many \nmore calling contexts than call sites, which indicates that call sites are in\u00advoked from multiple calling \ncontexts. The .rst two columns show that thousands of call sites generate hundreds of thou\u00adsands of calling \ncontexts. Large input Large-medium diff Contexts w/ new Program Contexts Call sites Contexts Call sites \ncall sites antlr 128,627 4,184 8 0 0 bloat 600,947 3,306 320,864 82 1,002 chart 202,603 2,335 139,599 \n379 9,112 eclipse* 226,020 9,611 121,939 1,240 46,206 fop 37,710 2,225 0 0 0 hsqldb 16,050 947 13 0 0 \njython 628,048 1,830 59,202 1 1 luindex 102,556 654 7,398 0 0 lusearch 905 507 0 0 0 pmd 847,108 1,890 \n711,223 48 388 xalan 17,905 1,530 15 2 2 Dacapo geo 85,963 1,897 pseudojbb 3,410 846 17 0 0 compress \n1,081 1,017 0 0 0 jess 5,240 1,363 1,827 22 22 raytrace 3,383 1,215 25 2 5 db 1,439 1,105 72 4 4 javac \n255,334 1,610 163,916 9 201 mpegaudio 1,668 1,072 32 1 4 mtrt 3,366 1,190 25 2 5 jack 29,461 2,173 0 \n0 0 SPEC geo 5,410 1,242 Geomean 24,764 1,568 Table 5. Comparing call site pro.les with calling context \non Java API calls. *Medium vs. small inputs for eclipse. Finally, we consider the power of residual calling \ncon\u00adtext pro.ling compared to residual call site pro.ling on the medium versus the large inputs. Columns \nunder Large\u00admedium diff count the distinct calling contexts and call sites seen in a large run but not \na medium run. In several pro\u00adgrams many new distinct calling contexts occur, but many fewer new call \nsites occur, and luindex in particular ex\u00adecutes 7,398 new contexts without executing any new call sites. \nThe .nal column shows the number of new, distinct calling contexts that correspond to the new call sites \nin the large run. This column shows how well residual call site pro.ling would do at identifying new \ncalling context be\u00adhavior. If every new call site (i.e., call site seen in large but not medium run) \ntriggered stack-walking, call site pro.ling would identify only a small fraction of the new calling con\u00adtexts \nfor most programs.  6. Related Work This section discusses related work in calling context pro\u00ad.ling. \nIt .rst considers stack-walking, then heavyweight ap\u00adproaches that construct a calling context tree (CCT), \nand .\u00adnally sampling-based approaches. We also consider related forms of pro.ling. Walking the stack. \nOne approach for identifying the cur\u00adrent calling context is to walk the program stack, then look up \nthe corresponding calling context identi.er in a call\u00ading context tree (CCT) [36, 41]. Unfortunately, \nwalking the stack more than very infrequently is too expensive for pro\u00adduction environments, as shown \nin Section 5.4. Calling context tree. An alternative approach to walking the stack is to build a dynamic \ncalling context tree (CCT) where each node in the CCT is a context, and during execu\u00adtion maintain the \ncurrent position in the CCT [2, 42]. This instrumentation slows C programs down by a factor of 2 to 4. \nThe larger number of contexts in Java programs and the compile-time uncertainty of virtual dispatch further \nincrease CCT time and space overheads. The size of CCT nodes are 100 to 500 bytes in previous work, whereas \nPCC values are very compact in comparison, since each one only needs 32 or 64 bits, and storing them \nin a half-full hash table achieves good run-time performance, as shown in Section 5.4. Sampling-based \napproaches. Sampling-based and trunca\u00adtion approaches keep overhead low by identifying the call\u00ading context \ninfrequently [8, 15, 21, 49, 52]. Clients use hot context information for optimizations such as context\u00adsensitive \ninlining [21] and context-sensitive allocation sites for better object lifetime prediction and region-based \nalloca\u00adtion [25, 40]. Hazelwood and Grove sample the stack peri\u00adodically to collect contexts to drive \ncontext-sensitive inlin\u00ading [21]. Zhuang et al. improve on sampling-based stack\u00adwalking by performing \nbursty pro.ling after walking the stack, since it is relatively cheap to update the current posi\u00adtion \nin the CCT on each call and return for a short time [52]. Bernat and Miller limit pro.ling to a subset \nof methods [8]. Froyd et al. use unmodi.ed binaries and achieve extremely low overhead through stack \nsampling [15]. Sampling is use\u00adful for identifying hot calling contexts, but it is not suitable for clients \nsuch as testing, security, and debugging because sampling sacri.ces coverage, which is key for these \nclients. Although PCC primarily targets clients requiring high coverage, it could potentially improve \nthe accuracy-overhead trade-off of sampling-based approaches. Zhuang et al. s call\u00ading context pro.ling \napproach avoids performing bursty sampling at already-sampled calling contexts [52]. Currently they walk \nthe stack to determine if the current context has been sampled before, but instead they could use PCC \nto quickly determine, with high probability, if they have al\u00adready sampled a calling context. Dynamic \ncall graph pro.ling. Dynamic optimizers of\u00adten pro.le call edges to construct a dynamic call graph (DCG) \n[5, 29, 38, 45], which informs optimizations such as inlining. DCGs lack context sensitivity and thus \nprovide less information than calling context pro.les. Path pro.ling. Ball-Larus path pro.ling computes \na unique number through each possible path in the control .ow graph [7]. An intriguing idea is applying \npath pro.ling in\u00adstrumentation to the dynamic call graph and computing a unique number for each possible \ncontext. However, this approach is problematic because call graphs, which have thousands of nodes for \nour benchmarks, are typically much larger than control .ow graphs (CFGs). The number of pos\u00adsible paths \nboth through CFGs and call graphs is exponential in the size of the graph in practice, so the statically \npossible contexts cannot be assigned unique 32-or even 64-bit val\u00adues. Other challenges include: (1) \nrecursion leads to cyclic graphs; (2) dynamic class loading modi.es the graph at run time; and (3) virtual \ndispatch obscures call targets and com\u00adplicates call edge instrumentation. Wiedermann computes a unique \nnumber per context at run time by applying Ball-Larus path numbering to the call graph, but does not \nevalu\u00adate whether large programs can be numbered uniquely [50]. His approach uses C programs, avoiding \nthe challenges of dynamic class loading and virtual dispatch, and handles re\u00adcursion by collapsing strongly-connected \ncomponents in the call graph. Melski and Reps present interprocedural path pro.ling that captures both \ninter-and intraprocedural con\u00adtrol .ow, but their approach does not scale because it adds complex call \nedge instrumentation, and there are too many statically possible paths for nontrivial programs [33]. \nAs Section 2 points out, much prior work uses path pro\u00ad.ling to understand dynamic behavior in testing, \ndebugging, and security, but dynamic object-oriented languages need calling context, too, since it captures \nimportant behavior. Paths and calling contexts are largely orthogonal since paths capture intraprocedural \ncontrol .ow while calling context provides interprocedural control .ow. One could imagine combining PCC \nand path pro.ling for best-of-both-worlds approaches in residual testing, anomaly-based bug detection, \nand intrusion detection.  7. Conclusion Complex object-oriented programs motivate calling context as \na program behavior indicator in residual testing, anomaly\u00adbased bug detection, and security intrusion \ndetection. Previ\u00adous techniques are too expensive for use in production envi\u00adronments. We present a probabilistic \ncalling context (PCC) approach suited to detecting new behavior that is ef.cient enough to use in deployed \nsystems. PCC maintains a value representing the current calling context in a probabilistically unique \nvalue. PCC adds just 3% overhead on average to a Java VM. Querying the PCC value at points corresponding \nto testing and security clients adds 0 to 9% additional over\u00adhead, and querying at every call adds 49%, \nwhile missing relatively few new contexts due to con.icts (0.1% at worst). These results show that PCC \nis ef.cient and accurate enough to add context sensitivity to dynamic analyses that detect new or anomalous \nprogram behavior.  Acknowledgments Many thanks to Vitaly Shmatikov for feedback and advice regarding \nsecurity applications. Thanks to Samuel Guyer, Jungwoo Ha, Nicholas Nethercote, Ben Wiedermann, and Emmett \nWitchel for helpful discussions. Thanks to Jungwoo Ha, Calvin Lin, Ben Wiedermann, and the anonymous \nre\u00adviewers for valuable feedback on the paper. References [1] B. Alpern, C. R. Attanasio, J. J. Barton, \nM. G. Burke, P. Cheng, J.-D. Choi, A. Cocchi, S. J. Fink, D. Grove, M. Hind, S. F. Hummel, D. Lieber,V.Litvinov,M.Mergen, \nT. Ngo, J. R. Russell, V. Sarkar, M. J. Serrano, J. Shepherd, S. Smith, V. C. Sreedhar, H. Srinivasan, \nand J. Whaley. The Jalape no Virtual Machine. IBM Systems Journal, 39(1):211 238, 2000. [2] G. Ammons, \nT. Ball, and J. R. Larus. Exploiting Hardware Performance Counters with Flow and Context Sensitive Pro.ling. \nIn ACM Conference on Programming Language Design and Implementation, pages 85 96, Las Vegas, NV, 1997. \n[3] T. Apiwattanapong and M. J. Harrold. Selective Path Pro.ling. In ACM Workshop on Program Analysis \nfor Software Tools and Engineering, pages 35 42, 2002. [4] M. Arnold, S. J. Fink, D. Grove, M. Hind, \nand P. F. Sweeney. Adaptive Optimization in the Jalape no JVM. In ACM Conference on Object-Oriented Programming, \nSystems, Languages, and Applications, pages 47 65, 2000. [5] M. Arnold, M. Hind, and B. G. Ryder. An \nEmpirical Study of Selective Optimization. In International Workshop on Languages and Compilers for Parallel \nComputing, pages 49 67, London, UK, 2001. Springer-Verlag. [6] T. Ball. The SLAM Toolkit: Debugging System \nSoftware via Static Analysis, 2001. [7] T. Ball and J. R. Larus. Ef.cient Path Pro.ling. In IEEE/ACM \nInternational Symposium on Microarchitecture, pages 46 57, 1996. [8] A. R. Bernat and B. P. Miller. Incremental \nCall-Path Pro.ling. Concurrency and Computation: Practice and Experience, 2006. [9] D. Binkley. Semantics \nGuided Regression Test Cost Reduction. IEEE Transactions on Software Engineering, 23(8):498 516, 1997. \n[10] S. M. Blackburn, R. Garner, C. Hoffman, A. M. Khan, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, \nD. Frampton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4c, \nT. VanDrunen, D. von Dincklage, and B. Wiedermann. The DaCapo Benchmarks: Java Benchmarking Development \nand Analysis. In ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications, \npages 169 190, 2006. [11] A. Chakrabarti and P. Godefroid. Software Partitioning for Effective Automated \nUnit Testing. In ACM &#38; IEEE International Conference on Embedded Software, pages 262 271, 2006. [12] \nT. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to Algorithms, chapter 11. The \nMIT Press, McGraw-Hill Book Company, 2nd edition, 2001. [13] L. Fei and S. P. Midkiff. Artemis: Practical \nRuntime Monitoring of Applications for Execution Anomalies. In ACM Conference on Programming Language \nDesign and Implementation, pages 84 95, 2006. [14] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and \nW. Gong. Anomaly Detection Using Call Stack Information. In IEEE Symposium on Security and Privacy, page \n62. IEEE Computer Society, 2003. [15] N. Froyd, J. Mellor-Crummey, and R. Fowler. Low-Overhead Call Path \nPro.ling of Unmodi.ed, Optimized Code. In ACM International Conference on Supercomputing, pages 81 90, \n2005. [16] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed Automated Random Testing. In ACM Conference \non Programming Language Design and Implementation, pages 213 223, 2005. [17] W. Gropp. Runtime Checking \nof Datatype Signatures in MPI. In European PVM/MPI Users Group Meeting on Recent Advances in Parallel \nVirtual Machine and Message Passing Interface, pages 160 167, London, UK, 2000. Springer-Verlag. [18] \nJ. Ha,C.J.Rossbach, J. V. Davis, I.Roy, H. E.Ramadan, D. E. Porter, D. L. Chen, and E. Witchel. Improved \nError Reporting for Software that Uses Black Box Components. In ACM Conference on Programming Language \nDesign and Implementation, pages 101 111, 2007. [19] S. Hangal and M. S. Lam. Tracking Down Software \nBugs Using Automatic Anomaly Detection. In ACM International Conference on Software Engineering, pages \n291 301, 2002. [20] M. J. Harrold, G. Rothermel, K. Sayre, R. Wu, and L. Yi. An Empirical Investigation \nof the Relationship Between Spectra Differences and Regression Faults. Software Testing, Veri.cation \n&#38; Reliability, 10(3):171 194, 2000. [21] K. Hazelwood and D. Grove. Adaptive Online Context-Sensitive \nInlining. In IEEE/ACM International Symposium on Code Generation and Optimization, pages 253 264, 2003. \n[22] X. Huang, S. M. Blackburn, K. S. McKinley, J. E. B. Moss, Z. Wang, and P. Cheng. The Garbage Collection \nAdvantage: Improving Program Locality. In ACM Conference on Object-Oriented Programming, Systems, Languages, \nand Applications, pages 69 80, 2004. [23] H. Inoue. Anomaly Detection in Dynamic Execution Environments. \nPhD thesis, University of New Mexico, 2005. [24] H. Inoue and S. Forrest. Anomaly Intrusion Detection \nin Dynamic Execution Environments. In Workshop on New Security Paradigms, pages 52 60, 2002. [25] H. \nInoue, D. Stefanovi\u00b4c, and S. Forrest. On the Prediction of Java Object Liftimes. ACM Transactions on \nComputer Systems, 55(7):880 892, 2006. [26] Jikes RVM. http://www.jikesrvm.org. [27] Jikes RVM Research \nArchive. http://www.jikesrvm.org/\u00adResearch+Archive. [28] J. Langou, G. Bosilca, G. Fagg, and J. Dongarra. \nHash Functions for Datatype Signatures in MPI. In European Parallel Virtual Machine and Message Passing \nInterface Conference, pages 76 83, 2005. [29] B. Lee, K. Resnick, M. D. Bond, and K. S. McKinley. Correcting \nthe Dynamic Call Graph Using Control Flow Constraints. In International Conference on Compiler Construction, \n2007. [30] B. Liblit, M. Naik, A. X. Zheng, A. Aiken, and M. I. Jordan. Scalable Statistical Bug Isolation. \nIn ACM Conference on Programming Language Design and Implementation, pages 15 26, 2005. [31] C. Liu, \nX. Yan, H. Yu, J. Han, and P. S. Yu. Mining Behavior Graphs for Backtrace of Noncrashing Bugs. In SIAM \nInternational Converence on Data Mining, pages 286 297, 2005. [32] S. Lu, J. Tucek, F. Qin, and Y. Zhou. \nAVIO: Detecting Atomicity Violations via Access-Interleaving Invariants. In ACM International Conference \non Architectural Support for Programming Languages and Operating Systems, pages 37 48, 2006. [33] D. \nMelski and T. Reps. Interprocedural Path Pro.ling. In International Conference on Compiler Construction, \npages 47 62, 1999. [34] M. Mitzenmacher and E. Upfal. Probability and Computing: Randomized Algorithms \nand Probabilistic Analysis.Cam\u00adbridge University Press, New York, NY, USA, 2005. [35] G. J. Myers. The \nArt of Software Testing. Wiley, 1979. [36] N. Nethercote and J. Seward. Valgrind: A Framework for Heavyweight \nDynamic Binary Instrumentation. In ACM Conference on Programming Language Design and Implementation, \npages 89 100, 2007. [37] C. Pavlopoulou and M. Young. Residual test coverage montoring. In ACM International \nConference on Software Engineering, pages 277 284, May 1999. [38] F. Qian and L. Hendren. Towards Dynamic \nInterprocedural Analysis in JVMs. In USENIX Symposium on Virtual Machine Research and Technology, pages \n139 150, 2004. [39] A. Rountev, S. Kagan, and J. Sawin. Coverage Criteria for Testing of Object Interactions \nin Sequence Diagrams. In Fundamental Approaches to Software Engineering,LNCS 3442, pages 282 297, 2005. \n[40] M. L. Seidl and B. G. Zorn. Segregating Heap Objects by Reference Behavior and Lifetime. In ACM \nInternational Conference on Architectural Support for Programming Languages and Operating Systems, pages \n12 23, 1998. [41] J. Seward and N. Nethercote. Using Valgrind to Detect Unde.ned Value Errors with Bit-Precision. \nIn USENIX Annual Technical Conference, pages 17 30, 2005. [42] J. M. Spivey. Fast, Accurate Call Graph \nPro.ling. Softw. Pract. Exper., 34(3):249 264, 2004. [43] Standard Performance Evaluation Corporation. \nSPECjvm98 Documentation, release 1.03 edition, 1999. [44] Standard Performance Evaluation Corporation. \nSPECjbb2000 Documentation, release 1.01 edition, 2001. [45] T. Suganuma, T. Yasue, M. Kawahito, H. Komatsu, \nand T. Nakatani. A Dynamic Optimization Framework for a Java Just-in-Time Compiler. In ACM Conference \non Object-Oriented Programming, Systems, Languages, and Applications, pages 180 195, 2001. [46] TIOBE \nSoftware. TIOBE programming community index, 2007. http://tiobe.com.tpci.html. [47] K. Vaswani, A. V. \nNori, and T. M. Chilimbi. Preferential Path Pro.ling: Compactly Numbering Interesting Paths. In ACM Symposium \non Principles of Programming Languages, pages 351 362, 2007. [48] D. Wagner and P. Soto. Mimicry Attacks \non Host-Based Intrusion Detection Systems. In ACM Conference on Computer and Communications Security, \npages 255 264. ACM Press, 2002. [49] J. Whaley. A Portable Sampling-Based Pro.ler for Java Virtual Machines. \nIn ACM Conference on Java Grande, pages 78 87. ACM Press, 2000. [50] B. Wiedermann. Know your Place: \nSelectively Executing Statements Based on Context. Technical Report TR-07-38, University of Texas at \nAustin, 2007. [51] T. Zhang, X. Zhuang, S. Pande, and W. Lee. Anomalous Path Detection with Hardware \nSupport. In International Conference on Compilers, Architectures and Synthesis for Embedded Systems, \npages 43 54, 2005. [52] X. Zhuang, M. J. Serrano, H. W. Cain, and J.-D. Choi. Accurate, Ef.cient, and \nAdaptive Calling Context Pro.ling. In ACM Conference on Programming Language Design and Implementation, \npages 263 271, 2006.  \n\t\t\t", "proc_id": "1297027", "abstract": "<p><i>Calling context</i> enhances program understanding and dynamic analyses by providing a rich representation of program location. Compared to imperative programs, object-oriented programs use more interprocedural and less intraprocedural control flow, increasing the importance of context sensitivity for analysis. However, prior online methods for computing calling context, such as stack-walking or maintaining the current location in a calling context tree, are expensive in time and space. This paper introduces a new online approach called <i>probabilistic calling context</i> (PCC) that continuously maintains a probabilistically unique value representing the current calling context. For millions of unique contexts, a 32-bit PCC value has few conflicts. Computing the PCC value adds 3% average overhead to a Java virtual machine. PCC is well-suited to clients that detect new or anomalous behavior since PCC values from training and production runs can be compared easily to detect new context-sensitive behavior; clients that query the PCC value at every system call, Java utility call, and Java API call add 0-9% overhead on average. PCC adds space overhead proportional to the distinct contexts stored by the client (one word per context). Our results indicate PCC is efficient and accurate enough to use in deployed software for residual testing, bug detection, and intrusion detection.</p>", "authors": [{"name": "Michael D. Bond", "author_profile_id": "81100148693", "affiliation": "University of Texas at Austin, Austin, TX", "person_id": "PP39089298", "email_address": "", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "University of Texas at Austin, Austin, TX", "person_id": "P157900", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1297027.1297035", "year": "2007", "article_id": "1297035", "conference": "OOPSLA", "title": "Probabilistic calling context", "url": "http://dl.acm.org/citation.cfm?id=1297035"}