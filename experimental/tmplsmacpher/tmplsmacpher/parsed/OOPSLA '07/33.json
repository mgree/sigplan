{"article_publication_date": "10-21-2007", "fulltext": "\n Living In The Comfort Zone Martin Rinard Department of Electrical Engineering and Computer Science Computer \nScience and Arti.cial Intelligence Laboratory Massachusetts Institute of Technology Cambridge, MA 021139 \n rinard sail.mit.edu Abstract A comfort zone is a tested region of a system s input space within which \nit has been observed to behave acceptably. To keep systems operating within their comfort zones, we ad\u00advocate \nthe interposition of recti.ers between systems and their input sources. Recti.ers are designed to transform \nin\u00adputs to ensure that they are within the comfort zone before they are presented to the system. Recti.ers \nenforce a highly constrained input format and, if necessary, discard informa\u00adtion to force inputs to \nconform to this format. Potential ben\u00ade.ts of this approach include the elimination of errors and vulnerabilities, \nthe excision of undesirable excess function\u00adality from large, complex systems, and a simpli.cation of \nthe computing environment. We have developed a recti.er for email messages and used this recti.er to \nforce messages into a speci.c con\u00adstrained form. Our results show that this recti.er can suc\u00adcessfully \nproduce messages that keep the Pine email client strictly within code previously con.rmed (during a small \ntesting and training session) to function acceptably. Our re\u00adsults also show that the recti.er completely \neliminates a se\u00adcurity vulnerability in the Pine email client. And .nally, the recti.er is able to accomplish \nthese goals while still preserv\u00ading an acceptable amount of information from the original messages. Categories \nand Subject Descriptors D.2.1 [Software En\u00adgineering]: Requirements/Speci.cations; D.2.3 [Software Engineering]: \nCoding Tools and Tech\u00adniques; D.2.5 [Software Engineering]: Testing and Debugging; D.3.3 [Programming \nLanguages]: Language Constructs and Features Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. OOPSLA 07, October 21 25, 2007, Montr\u00b4eal, Qu\u00b4ebec, Canada. Copyright \nc &#38;#169;2007 ACM 978-1-59593-786-5/07/0010. . . $5.00 General Terms Design, Languages, Reliability, \nSecurity Keywords Comfort Zone, Acceptability Properties, Repair, Monitoring, Recti.cation  1. Introduction \nBy the time a typical software system is deployed, its devel\u00adopers have tested its behavior on a range \nof inputs and veri\u00ad.ed that the behavior is acceptable. And in fact, the deployed system usually works \nwell on inputs that are similar to those in the test suite. To exercise an error or vulnerability, one \nmust typically .nd an anomalous input with some unusual feature that manages to take the system into \na poorly tested region of its execution space. Conceptually, the system has a comfort zone a collection \nof inputs that is similar to those that it has seen before and for which it is almost certain to deliver \nexpected and acceptable behavior. Ideally, one would never run a system on an input outside its comfort \nzone. Indeed, the goal of much of the effort that goes into testing and debugging is to maximize the \nsize of the comfort zone by 1) exercising as much of the function\u00adality of the system as possible and \n2) eliminating as many unacceptable errors within the exercised part of the system as possible. In this \nway the developers hope to minimize the likelihood of the system encountering an input outside its comfort \nzone that causes it to behave unacceptably. Despite the tremendous effort devoted to testing and de\u00adbugging, \nhowever, it is almost always possible to .nd inputs that cause the system to behave in unanticipated \nor unaccept\u00adable ways. This problem can become a source of frustration for users who inadvertently stumble \nacross such inputs and are consequently unable to obtain their desired results. The problem can be especially \nsevere for systems (such as web browsers, servers, and email clients) that are placed in the position \nof having to process arbitrary inputs from poten\u00adtially untrusted sources many successful security attacks \ninvolve unusual inputs that exercise unanticipated function\u00adality or outright errors hidden within an \notherwise success\u00adfully operating system [18]. 1.1 Our Approach This paper presents a complementary approach \nto eliminat\u00ading unanticipated and unacceptable system behavior. Instead of attempting to make the system \nbehave acceptably on all possible inputs, we instead propose to con.gure the envi\u00adronment surrounding \nthe system with the goal of ensuring that the system only executes within an appropriately chosen comfort \nzone. The basic idea is to interpose a recti.er (a set of transformations) between the input sources \nand the soft\u00adware system. Together, these transformations are designed to move all inputs that were originally \noutside the comfort zone into the comfort zone. Ideally, this approach would eliminate the anomalies \nthat come from processing problematic inputs while preserving the desired behavior of the system. There \nare two potential issues associated with this ap\u00adproach. First, the recti.er may destroy information \nin the original input, with this information destruction causing the system to produce an inappropriate \nresult. Second, the rec\u00adti.er may fail to completely remove some problematic fea\u00adtures of the input, \nleaving the input presented to the system outside the comfort zone. We address these issues as follows. \nIn some cases the problematic features of the input may occur in the way the information is formatted \nor presented in the input rather than in the content of the information itself. In these cases appro\u00adpriately \nstructured transformations may be able to leave the information completely intact (although the presentation \nof the information to the user may change). In other cases the problematic features may occur in information \nthat is tan\u00adgential to the primary purpose of the system. In these cases appropriately structured transformations \nmay be able to pre\u00adserve the most important information, leaving the system able to deliver most of its \ndesired functionality. And in all cases, we propose to generate reports that users can exam\u00adine to determine \nthe potential consequences of applying the transformations. Recti.ers that may sometimes fail to move \nan input into the comfort zone can leave systems vulnerable to errors or exploits. We propose to ameliorate \nthis problem in two ways. First, we advocate the use of aggressive recti.ers that produce a very narrow, \ntightly constrained class of inputs. The goal is to enforce broad, sweeping restrictions that rule out \nall potentially anomalous inputs. Second, we propose to check all inputs for membership in the comfort \nzone as the program executes. Speci.cally, we propose to train the sys\u00adtem on a set of validated inputs \nand record the blocks of code that execute during this training process. Any signi.cant de\u00adviation from \nfrom this set of previously executed blocks is taken as an indication that the input is outside the comfort \nzone. The appropriate action to take depends on the context in which the system is used we are able \nto take any action from terminating the system as soon as it attempts to execute a new block of code \nto simply recording the new blocks that execute as the system processes the input. We anticipate that \nboth the transformations and the over\u00adall success of the proposed approach will depend on the spe\u00adci.c \nsystem and the context in which the system is deployed. To explore how well this approach works, we have \nbuilt a recti.er for the Pine email client [13] and performed a series of experiments that explore how \nwell the recti.er works. Our results show that it is possible, for this application, to build a recti.er \nthat can effectively move even problematic inputs (such as attacks that would otherwise exploit security \nvul\u00adnerabilities) into the comfort zone of the system for safe pro\u00adcessing. The transformations are simple \nto implement and in most cases preserve virtually all of the important informa\u00adtion in the original email \nmessages. And when the recti.er does remove information, it generates informative recti.ca\u00adtion logs \nthat users can quickly examine to determine the changes that the recti.er made. 1.2 Usage Scenarios \nWe have presented input recti.cation as a way to avoid unanticipated errors or vulnerabilities in software \nsystems. It is clear, however, that this technique can be productively applied to solve a variety of \nother problems that arise in using software systems: . Functionality Elimination: Many large systems \ncon\u00adtain signi.cantly more functionality than any single user or organization will ever use. In some \ncases this excess functionality may be undesirable consider, for exam\u00adple, a feature in Microsoft Word \nthat executes scripts when reading in Word .les. When Word is used as a document editor in the Outlook \nemail client to prepare forwarded messages, this feature causes Word to auto\u00admatically execute any scripts \nthat may have been present in the original email sent to the user (a clear security violation) [7]. Note \nthat script execution is an intended feature in Word and arguably made sense in the context in which \nWord was originally deployed. An appropri\u00adately designed recti.er can eliminate this kind of unde\u00adsirable \nfunctionality (for example, by simply eliminating all scripts from Word documents), making it possible \nto safely use the original system in a new context in spite of the undesirable functionality. Systems \ntend to accrete functionality over time, to the point that too much functionality can become as much \nor more of a problem as too little functionality. Identify\u00ading a narrow comfort zone and using input \nrecti.cation to enforce that comfort zone can make it possible to effec\u00adtively use a single existing \nfunctionality-laden system in many different contexts and for many different purposes without incurring \nthe risks and complications associated with the excess functionality normally present. This can be a \nsigni.cant improvement over the alternative (devel\u00adoping multiple systems, each tailored for use in its \nown context). We note that in many cases nobody understands all of the functionality that a given system \nmay offer. We there\u00adfore advocate the use of aggressive recti.ers that look for input patterns that they \nrecognize as safe (and block any\u00adthing else) rather than less aggressive recti.ers that look for speci.c \ninput patterns to block (and pass through any\u00adthing else). . Incorrect Inputs: Most systems contain input \ncorrect\u00adness checks designed to verify that the input is in a form that the system can successfully process. \nIf an input fails a correctness check, the system typically refuses to pro\u00adcess the input. In some cases, \nhowever, a user may need the system to process the information in the input even if the input itself \nis malformed (and therefore fails the correctness check). This can occur if the system that pro\u00adduced \nthe input has an error or is simply somewhat in\u00adcompatible with the system that should process the input. \nIn this case an appropriately designed recti.er may be able to produce an input that the .rst system \nwill accept and process. . Test-Suite Directed Development: Much of the code in many systems is present \nonly to handle cases that occur infrequently. This code increases the size, development cost, and complexity \nof the .nal system. A suf.ciently aggressive recti.er may be able to substantially reduce the number \nof input cases that the system must process (and therefore eliminate the need for the code that would \notherwise be required to handle these cases). In fact, it may be desirable to refuse to code any case \nuntil there is an input in the test suite that exercises that code af\u00adter all, any input that exercises \nthat code will be outside the comfort zone. The result could be a lazy code devel\u00adopment process that \ndoes not implement any case until there is an input in the test suite that hits that case. And if a new \ninput in the test suite does happen to hit an unim\u00adplemented case, the developer would have two options: \ncode up the case, or modify the recti.er to eliminate the features of the input that caused it to hit \nthe unimple\u00admented case. . Reduced Testing Burden: Systems with many features require lots of testing. \nEliminating functionality can make it possible to reduce the amount of testing required to develop con.dence \nin the system. For suf.ciently nar\u00adrow comfort zones, it may even be possible for users to perform enough \ntests to become con.dent that the sys\u00adtem will work for them even though their tests do not come close \nto exploring the full functionality present in the system. . Eliminating Input Correctness Checks: In \npractice, in\u00adput correctness checks can be a problematic source of er\u00adrors. Because the code that implements \nthese checks is not usually exercised during the normal operation of the system, it may receive less \nattention during development and testing (with the result that it may contain more er\u00adrors when the system \nmoves into production). Because the developer can make no assumptions whatsoever about the input, he \nor she may overlook cases, leaving the sys\u00adtem open to exploitation by inputs that target these over\u00adlooked \ncases. An appropriately designed recti.er can completely elim\u00adinate all of these problems by always producing \ncorrectly formed inputs. Moreover, such a recti.er would make it possible to completely eliminate the \nerror checking code altogether. The resulting bene.ts can include a dramatic simpli.cation of the input \nprocessing code and the elim\u00adination of errors and vulnerabilities. . New Input, Old System: New versions \nof systems often produce data with enhanced features that old versions are unable to correctly process. \nIn this case rectifying data produced by the new version may produce an input that the old version can \nsuccessfully process. Possible motivations for continuing to use the old version include reluctance to \nabandon a version that is working well, an aversion to paying upgrade costs, or errors in the new version \nthat prevent it from working as well as the old version. . Old Input, New System: The dual problem arises \nwhen a new version may be unable to process inputs produced by the old version. In this case the recti.er \nmay be able to produce inputs that the new version can successfully process. 1.3 Why Our Approach Makes \nSense The basic concept behind our approach is to change the en\u00advironment to work around limitations \nor inappropriate fea\u00adtures of the software system. In theory, this may make little sense. After all, \nsoftware should be one of the most .exible technologies ever developed the medium itself is extraor\u00addinarily \nmalleable, and changes can be implemented and dis\u00adseminated at little cost. It may seem that, if there \nis a prob\u00adlem, it makes more sense to change the software to deal with the environment rather than the \nother way around. In practice, however, most deployed software systems are extremely dif.cult to work \nwith. Even if the source code is available, the sheer size and complexity of most systems make it virtually \nimpossible for anyone except the developers and maintainers to update the system. Moreover, deployed \nsystems vary widely in quality and are often known to contain errors or security vulnerabilities. Nevertheless, \nusers are locked in if an error or vulnerability shows up that compromises the ability of the system \nto acceptably satisfy the needs of some of its users, the users typically have little choice except to \nwait for the developers to update the software and release a new version. This situation can be especially \nproblematic if it takes a long time to develop and release the updates or if the software is no longer \nmaintained (in which case the update may never come through). Our proposed technique, using recti.cation \nto move in\u00adputs into the comfort zone of the system, can enable users to make productive use of .awed \nsystems by adapting the en\u00advironment to eliminate problems that would otherwise make the system dif.cult \nor even impossible to work with. As the world becomes ever more full of large and imperfect sys\u00adtems, \nwe believe that these kinds of techniques will play an increasingly important role in keeping our software \ninfras\u00adtructure functioning acceptably. 1.4 Large Systems The primary focus of this paper is on using \nrecti.ers at system boundaries to move external inputs into the comfort zone of a single system. But \nis of course also possible to use recti.ers within a large system to mediate interactions between the \ncomponents of the system. In this scenario, each recti.er would interpose itself at some abstraction \nlayer, then rectify information passing through that abstraction layer. A key question is the abstraction \nlayer and the interposi\u00adtion mechanism. If the components interact by reading and writing .les, the recti.er \ncan simply read the original input .le, then write the recti.ed input .le. The component then reads the \nrecti.ed input .le instead of the original input .le. If components interact via network connections, \nthe recti\u00ad.er can be structured as an intermediate process that splits the original direct connection \ninto two connections, one of which carries the unrecti.ed input into the recti.er, the other of which \ncarries the recti.ed input out of the recti.er to the component that reads it. Other interactions can \nrequire more involved interposi\u00adtion mechanisms. If components interact via procedure or system calls, \nfor example, there are a variety of mechanisms that one can use to intercept the calls, especially in \nthe pres\u00adence of interface structuring techniques such as the Windows Import Address Table [11]. Recti.cation \nwithin a system may be especially appro\u00adpriate if the system contains poorly understood or overly general \ncomponents whose original interfaces support much more functionality than the system needs. It may also \nbe a useful way to eliminate poorly documented or poorly under\u00adstood parts of a component s interface. \n 1.5 Simplicity in a Complex World Our existing computing environment is the result of decades of system \nevolution. The retention of features from the past combined with the systematic and purposeful addition \nof new features has produced an environment of unprecedented complexity. Indeed, this complexity has \nreached the point where it can hamper the ability of users to work productively within the environment. \nComplex environments also support complex ecosystems; our computing environment is unfortu\u00adnately now \nso complex that it supports a thriving community of abusers who participate in the environment primarily \nto exploit other users. We believe that our approach can help simplify this com\u00adplex environment. Tightly \nfocused comfort zones can elim\u00adinate many of the features that make modern environments so complex. We \nhave so far focused on how this kind of sim\u00adplicity can help protect users against errors and vulnerabili\u00adties. \nBut this simplicity can also reduce the cognitive load of using the system and eliminate many of the \ndistracting and extraneous details that prevent users from focusing fully on the task at hand. In the \nend, this may be the most important potential bene.t that our approach may have to offer. One of the \nmost important impediments to achieving sim\u00adplicity is the well-known fact that most users will almost \nalways choose the system that promises the most features, even if they will never use most of the features \nand even if the excess features make the system more dif.cult to use. Indeed, this phenomenon may be \nlargely responsible for motivating organizations to relentless add new features as their systems evolve \nover successive releases. Ideally, our approach may be able to help users obtain the best of both worlds \n the burst of elation that comes from acquiring a system that has every feature one could ever possibly \ndesire combined with the quiet satisfaction of using a simple sys\u00adtem that enables one to work smoothly \nand ef.ciently with little excess stress and clutter. 1.6 Paper Structure The remainder of the paper \nis structured as follows. In Sec\u00adtion 2 we present the concepts of our approach in more de\u00adtail. In Section \n3 we discuss our experience developing a recti.er for the Pine email client and using the recti.er to \nplace email messages within the Pine comfort zone. Sec\u00adtion 4 presents experimental results that characterize \nthe ef\u00adfect of using this recti.er on a corpus of email messages. We discuss related work in Section \n5 and conclude in Section 6.  2. Conceptual Framework We make the de.nition of a comfort zone precise \nas follows. A comfort zone is a property of a system and a training suite. The exercised region of the \nprogram consists of all blocks of code that execute when the system processes inputs in the training \nsuite. The comfort zone is then the set of all inputs that cause the system to remain within the exercised \nregion when it processes the input. Note that it is usually important to verify that the system behaves \nin an expected, acceptable way for all of the inputs in the training suite (otherwise the comfort zone \nwill include inputs that can cause the system to behave in unexpected or unacceptable ways, which is \nusually not the intended effect). Also note that the same system may have different comfort zones for \ndifferent training suites indeed, as we discuss in Section 1.2, different comfort zones may be appropriate \nin different contexts. 2.1 Feature Selection As stated, the de.nition of comfort zone can be dif.cult \nto work with determining whether a given input is in the comfort zone or not requires reasoning about \nthe behavior of the program on that input. We therefore advocate designing recti.ers with the aid of \na set of features. Each feature is simply a property of the input. When designing a recti.er for text \ninputs, for example, one might choose features such as the presence or absence of certain characters \nin the inputs, the lengths of various .elds or lines, or the overall size of the input. The features \nshould be chosen to enable comfort zone membership recognition it should be possible to determine, with \nhigh likelihood, if a given input is in the comfort zone by simply looking at the input features rather \nthan at the input itself. 2.2 Constraints Given a set of features, the next step is to select a set \nof con\u00adstraints that involve the features. For example, a constraint might require certain characters \nto be absent or present in the input. Or a constraint could require the length of a given line to be \nless than a certain number of characters. The con\u00adstraints should be chosen so that if an input satis.es \nthe con\u00adstraints, it is highly likely to be within the comfort zone. 2.3 Constraint Enforcement The \nnext step is to develop transformations that, together, enforce all of the constraints. There is typically \none trans\u00adformation for each constraint; the speci.c algorithm that the transformation employs typically \ndepends on the con\u00adstraint. If a constraint states that certain characters must not be present in the \ninput, for example, the corresponding trans\u00adformation could simply delete all such characters from the \ninput. Or if a constraint requires all lines to be less than a certain number of characters long, the \ntransformation could either truncate overly long lines or insert line breaks to bring all lines within \nthe stated limit. One obvious goal is that the transformations should at\u00adtempt to preserve as much information \nfrom the original in\u00adput as possible. In particular, it would be desirable for the transformations to \nleave inputs intact if they do not violate any of the constraints. We anticipate that the precise transfor\u00admation \nalgorithms will vary depending on the kind of con\u00adstraints they are intended to enforce and the context \nin which they will be used. Finally, the transformations should generate a record of the changes they \nmake. The recti.er will later combine these records to make a recti.cation report for each input. Users \ncan access this report to obtain an understanding of the effect of applying the transformation. 2.4 \nRecti.cation The next step is to bundle all of the transformations together to obtain a recti.er. The \nrecti.er applies the transformations in turn to each input to ensure that the input satis.es all of the \nconstraints. It also combines the modi.cation records to generate the recti.cation report. The recti.er \nis then inserted between the input generators and the system so that it recti\u00ad.es all inputs before the \ninput processes them. 2.5 Monitoring We expect that in most cases the constraints will mostly, but not \ncompletely, characterize the comfort zone. We therefore monitor the execution of the system as it processes \neach in\u00adput to .nd any violations of the exercised region. The re\u00adsponse to such violations varies depending \non the context. In some cases it may make sense to query the user to see if the behavior of the program \nwas acceptable in spite of the violation. If so, it may make sense to add the newly exe\u00adcuted blocks \nof code to the executed region. In other cases users may be willing to live with small violations of \nthe exe\u00adcuted region (as measured by the number of newly executed blocks). In yet other cases it may \nmake sense to terminate the program before it can execute any block outside the exe\u00adcuted region. Our \nimplemented system supports all of these options. 2.6 Practical Considerations In principle, it should \nbe possible to use any effective pro.l\u00ading and monitoring system to .nd and enforce the comfort zone. \nIn practice there are a variety of issues that can compli\u00adcate these two tasks. These issues may include \nthe dif.culty of monitoring code in dynamically-linked libraries, poor per\u00adformance of the monitoring \nsystem, and failure to handle all of the features present in large systems. Fortunately, there are a \nnumber of robust code instrumentation systems avail\u00adable that can effectively address these issues[17, \n6, 8]. We used the DynamoRIO [17, 2] system for our experi\u00adments. Instead of executing the binary directly \non the pro\u00adcessor, DynamoRIO executes all code out of a cache of re\u00adcently executed code blocks. When \nDynamoRIO encounters a branch to a block of code that is not in the cache, it fetches the block from \nthe address space of the executing program and presents it to the monitoring system. The monitoring system \ncan then take a variety of actions, including chang\u00ading the instructions in the code block before the \ncode block is inserted into the cache and executes. The DynamoRIO implementation has been engineered \nover the course of several years, to the point that it is now a robust system that fully supports Windows \nx86 executables. It imposes relatively little overhead and monitors all of the code at the application \nlevel including dynamically linked libraries. As the system processes the inputs in the training suite, \nour comfort zone discovery system records all of the ex\u00adecuted code blocks. Together, these code blocks \ncomprise the executed region that de.nes the comfort zone of the sys\u00adtem. During production, our monitoring \nsystem checks every block inserted into the code cache to verify that it is part of the executed region. \nIf it is not, our system can either ter\u00adminate the system before the new block executes or simply record \nthe new block and let the application continue. Dy\u00adnamoRIO supports all of these actions. 2.7 Empirical \nPreconditions One of the concepts implicit in our our approach is that each implemented system has an \nempirical precondition that its inputs must satisfy for the system to execute correctly. Unlike standard \npreconditions, which are typically identi\u00ad.ed during the design phase to provide the developer with a \nspeci.cation of the properties that he or she can assume that inputs will satisfy, the empirical precondition \nis de.ned by the behavior of the system. Speci.cally, an input satis\u00ad.es the empirical precondition if \nthe program produces the correct (or, in some contexts, an acceptable) output when it processes the input. \nNote that the presence of errors in the system can cause the empirical precondition to be stronger than \nthe standard precondition that is, there are inputs that the implemented system 1) was designed to process \ncorrectly, but 2) fails to process correctly in practice because of errors in the imple\u00admentation.1 It \nis usually the case (in part because of such errors) that nobody can completely predict the entire behav\u00adioral \nrange of a large software system. This fact means that the empirical precondition is almost always only \npartially known to the users and developers of the program. It is also only partially known to the developer \nof the recti.er. The question then becomes how does one obtain an effective rec\u00adti.er with only partial \nknowledge of the empirical precondi\u00adtion? Our conceptual framework provides one answer to this question. \nSpeci.cally, use features and constraints to obtain a (hopefully) conservative approximation to the (only \npar\u00adtially known) empirical precondition. The structure present in this approach helps the developer \nof the recti.er identify properties that characterize the kinds of common, expected inputs that the system \nwill have repeatedly encountered (and therefore have been made to successfully process) in the past. \nTogether, these properties constitute a recti.er precon\u00addition that the recti.er forces all inputs to \nsatisfy. Given that the recti.er developer has only partial knowledge of the em\u00adpirical precondition, \nthe goal is usually to obtain a conser\u00advative recti.er precondition that is, in practice, stronger than \n1 Of course, it is also possible for the implemented system to exceed its speci.cation and process some \ninputs correctly even though these inputs do not satisfy the standard precondition. This can happen if \nthe implementor decided to build a more general system than required, if the system is built out of more \ngeneral components than are absolutely necessary to provide the desired functionality, if the presence \nof ambiguities or errors in the spec\u00adi.cation caused the developer to conservatively work from a weaker \nstan\u00addard precondition, if the developer misunderstood the requirements, or if the program simply happens \nto produce a correct output (for whatever reason) for some inputs that do not satisfy the standard precondition. \nIn general, we would expect the empirical precondition and the standard precondition to be incomparable. \nThat is, we would expect some inputs to satisfy the standard precondition but not the empirical precondition \nand vice-versa. the empirical precondition. A strong recti.er precondition minimizes the undesirable \npossibility of the system encoun\u00adtering an input that satis.es the recti.er precondition but not the \nempirical precondition.  3. Pine Email Client To illustrate how to apply our approach in practice, we \npresent our experience applying our approach to the Pine [13] email client. Our goal is to use Pine as \na simple email reader for text messages. We explicitly wish to eliminate function\u00adality associated with \nprocessing more complex types of mes\u00adsages (such as messages with attachments of various types). Pine \nprovides a variety of views for email messages. Our goal is to support list views (a view that lists \nthe messages in a folder, with one line for each message) and message views (a view that displays the \ncontents of a single message on the screen). 3.1 Pine Comfort Zone The .rst step is to obtain a training \nsuite of representative messages that we can use to establish a comfort zone for Pine. Our training suite \nconsists of 450 email messages sent to the author between July 1997 and February 1998. We con.gure Pine \nto process each message in the training suite in both the list and message views. We then record, for \neach view, all of the blocks of code that Pine executes as it processes each message. The goal is to \nuse our training suite to obtain complete statement coverage for an acceptable comfort zone (in other \nwords, our goal is to execute every instruction required to successfully process simple text email messages). \nWe note in passing that obtaining complete statement coverage for any sizable software system is considered \nto be a dif.cult task and that a training set of our size would usually be woe\u00adfully inadequate for this \ntask. The difference is that we have no intention of supporting the full functionality of the sys\u00adtem. \nIndeed, our goal is instead to use the recti.er to narrow down the required functionality as much as \npossible. Our ex\u00adperimental results show that this approach can make it pos\u00adsible to obtain full code \ncoverage of an acceptable part of the system with a relatively small training suite indeed, a training \nsuite so small that almost any organization consid\u00adering using Pine as an email reader can easily obtain \nsuch a training suite and verify that Pine acceptably processes the messages in the suite. 3.2 Pine \nRecti.er The Pine recti.er is designed to take arbitrary email mes\u00adsages and transform them into a simple \ntext message format. Pine (like many email clients) is designed to process mes\u00adsages stored in mbox format. \nIn this format each message starts with a line of the form Fromand ends with a blank line. The message \nitself may have a header with various .elds such as From:, To:, etc. A blank line separates the header \nfrom the message body. Here is a sample message stored in mbox format [20]. Note that the From:.eld is \ndistinct from the Fromline that indicates the start of the email message. From\"Retifier\"WedDe2020:31:222006 \nTo:me mit.edu From:someone sail.mit.edu Subjet:Example Date:Thu,28Aug199715:15:27-0400 Thisisanexampleofasimpletextmessage. \nOur Pine recti.er is designed to produce messages that closely follow the format of this example. 3.2.1 \nMessage Features Our recti.er works with the following set of features: .From Line: The contents of the \nFromline. .Header Fields: The set of .elds in the header, as identi\u00ad.ed by the names of the .elds as \nfound in the header (for example, From:, To:,etc.). .Header Field Contents: The contents of the To:, \nFrom:, Subjet:,and Date:header .elds.  . Line Lengths: The lengths of the lines in the message. . Body \nLines: The number of lines in the body of the message. . Characters: The characters that appear in the \nbody of the message. 3.2.2 Constraints The recti.er enforces the following set of constraints: .From \nLine: TheFromlinemustbe: From\"Retifier\"WedDe2020:31:222006. . Header Fields: The message contains a To:,a \nFrom:,a Subjet:,and a Date:.eld, in that order. It contains no other .elds. .To: Field: The To:.eld consists \nof a single line con\u00adtaining a sequence of comma-separated email addresses. Each email address must be \nin a form similar to the ad\u00address me mit.edu. Speci.cally, each email address must match the following \nPerl[10] match expression: /(\\w[-.\\w]+\\@[-.\\w]+\\.\\w{2,3})\\W/ . From: Field: The From:.eld consists of \na single email address in the same form as the email addresses in the To:.eld. . Subject: Field: The \nSubjet:.eld may contain only reasonable characters. Speci.cally, the subject .eld may contain only the \ncharacters identi.ed by the follow\u00ading Perl character expression: \\n ! #&#38; ()*+,\\-.\\/0-9:;<>?@A-Za-z[] \n\u00ad  . Date Field: The Date:.eld consists of a single line in a form similar to Thu,28Aug199715:15:27-0400. \nSpeci.cally, the date consists of a three-character day, a one or two digit day of the month, a three-character \nmonth, a four-digit year, a time speci.er consisting of three two-digit time components separated by \ncolons, and a .ve-character time zone speci.er. . Line Lengths: No line in the message exceeds 80 char\u00adacters \nin length. . Body Lines: The body of the message contains no more than 10,000 lines. . Characters: The \nmessage body contains only reason\u00adable characters. Speci.cally, the message body may contain only the \ncharacters identi.ed by the following Perl character expression: \\n\\t ! #$%&#38; ()*+,\\-.\\/0-9:;<.>?@A-Z[\\\\] \n a-z{I}\u00ad 3.2.3 Constraint Enforcement The recti.er processes each message to enforce the con\u00adstraints \nas follows. It is structured as a pipeline of two trans\u00adformers, the attachment transformer and the content \ntrans\u00adformer. The attachment transformer processes the message to eliminate all attachments. It expands \nall plain text attach\u00adments into the body of the message and deletes all other attachments, leaving behind \na line in the body of the mes\u00adsage indicating that the attachment was deleted. Both the at\u00adtachment transformer \nand the content transformer are imple\u00admented in Perl. The attachment transformer consists of 94 lines \nof Perl code; the content transformer consists of 151 lines of Perl code. We note that these transformers \nare small enough for even organizations with few resources to develop and/or inspect to gain trust in \nthe recti.er. As the content transformer processes the message header, it looks for the To:, From:, Subjet:,and \nDate:.elds. When it encounters the line containing the To:.eld, it looks for consecutive, non-overlapping \nsubstrings within the line that match the email address pattern described above in Sec\u00adtion 3.2.2. It \nthen stores a comma-separated list of these sub\u00adstrings, omitting any substrings that would cause the \npro\u00adduced To:.eld to exceed 80 characters in length. Similarly, when it encounters the line containing \nthe From:.eld, it looks for the .rst substring within the line that matches the email address pattern \ndescribed above in Section 3.2.2. It then stores the substring. When the content transformer encounters \nthe Date:.eld, it looks for a substring that matches the date pattern de\u00adscribed above in Section 3.2.2. \nIt then stores the substring. Finally, when it encounters the line containing the Subjet: .eld, it removes \nany unreasonable characters (as de.ned above in Section 3.2.2) and, if necessary, truncates the line \nat 80 characters. It then stores the line away. When the content transformer reaches the end of the mes\u00adsage \nheader, it prints out, in order, the Fromline described above in Section 3.2.2, a To:.eld containing \nthe stored list of email addresses, a From:.eld containing the stored email addresses, a Subjet:.eld \ncontaining the stored subject string, and a Date:.eld containing the stored date. If the recti.er fails \nto .nd a .eld as it processes the header, or if a .eld fails to contain any of the substrings that the \ntrans\u00adformer looks for, the transformer simply prints out a de\u00adfault .eld that satis.es the .eld constraints. \nNote that this approach results in the deletion of any line in the header that is not in one of the .elds \nthat the transformer looks for. As the content transformer processes the body of the mes\u00adsage, it removes \nany unreasonable characters (as de.ned above in Section 3.2.2). It also inserts line breaks as neces\u00adsary \nto keep all of the lines in the body less than 80 charac\u00adters in length. Finally, it keeps track of the \nnumber of lines in the body, truncating the message when the number of lines reaches 10,000. 3.2.4 Report \nGeneration For each message, the attachment transformer produces a report indicating how many attachments \nit found, how many attachments it deleted, and (implicitly) how many plain text attachments it expanded \ninto the body of the message. The content transformer produces a report indicating which header lines \nit removed, which header lines it changed, how many body characters it removed, how many newlines it \nin\u00adserted into the body, and how many lines it dropped if it truncated the body. The user can examine \nthis report and if desired, use an appropriate tool (such as a text editor or the Unix atcommand) to \nexamine the original message (the transformers preserve this message) for more details. The user can \nalso use a separate tool to extract any attach\u00adments or even (if he or she is feeling lucky and is suf.ciently \nmotivated) use an email reader to view the original message.  4. Experimental Results To evaluate the \neffectiveness of our recti.er in moving mes\u00adsages into the comfort zone while preserving an acceptable \namount of information from the original messages, we ap\u00adplied our recti.er to several test collections \nof messages. We used Pine on our training suite of 450 messages to estab\u00adlish a comfort zone for both \nlist views and message views. We then applied Pine to the messages in our test collections both before \nand after recti.cation, testing both the list view and the message view for each message. We ran Pine \nunder the control of our monitoring system, counting the number of executed blocks not in the exercised \nregion (instead of terminating Pine as soon as it attempted to execute the .rst such block). Here are \nthe test collections we used: . Normal: A set of 40 normal messages sent to the au\u00adthor in January and \nFebruary of 1998. These messages were the next 40 messages received after the 450 mes\u00adsages in the training \nsuite. . Unusual: A set of 40 unusual messages received by the author between January and April of 2002. \nWe selected this set by .rst running Pine on 6497 messages received between 1997 to 2001 (without recti.cation), \nrecording the executed blocks of code, then selecting messages from among 2167 messages received between \nJanuary and April of 2002 that caused Pine to execute new blocks of code. The goal was to obtain a set \nof outlier messages that exercise rarely executed blocks of code. . Exploit: A message that exploits \na vulnerability in cer\u00adtain versions of Pine. Pine version 4.44 has a string over\u00ad.ow vulnerability associated \nwith a failure to allocate enough memory to hold a parsed string corresponding to certain From:.elds \nin the list view [12]. We obtained Pine version 4.64, reinserted the vulnerability from ver\u00adsion 4.44 \n(this vulnerability was removed between ver\u00adsion 4.44 and version 4.64), and used this version of Pine \nin all of our experiments. We obtained a message that exploited this vulnerability and veri.ed that it \ncaused Pine to crash when it attempted to create a list view including this message. We veri.ed that \nif someone sends this message to a user running a version of Pine with the vulnerability, it will cause \nPine to crash as soon as the user attempts to view the list of new messages. While we did not verify \nthat it is possible to exploit this vulnerability to execute arbitrary injected code, it is typically \npossible to exploit this kind of vulnerability for this purpose. 4.1 Normal Message Set None of the unrecti.ed \nversions of the normal messages are in Pine s comfort zone. The new block counts for the list view range \nfrom a high of 130 new blocks to a low of 68 new blocks with a median of 93 new blocks. The new block \ncounts for the message view range from a high of 1233 (this is a signi.cant outlier; the next highest \nnew block count is 212) to a low of 68 with a median of 100 new blocks. We attribute this result to the \nfact that the content transformer discards information from the header of every message in the normal \nmessage set. Common kinds of discarded infor\u00admation include the name of the sender (headers often con\u00adtain \nthis information in addition to the email address of the sender) and various header lines that summarize \nvarious as\u00adpects of the message content and history (for example, if the message was sent as a reply \nto some other message). The recti.er had made almost no changes to the message bod\u00adies with one exception, \nit left all of the message bodies unchanged. For that message body it expanded a text attach\u00adment and \nremoved an HTML attachment. After recti.cation, all of the normal messages are in the comfort zone for \nboth views Pine can successfully pro\u00adcess all of the messages without executing any new blocks at all. \n 4.2 Unusual Message Set None of the unrecti.ed versions of the unusual messages are in Pine s comfort \nzone. The new block counts for the list view range from a high of 296 new blocks to a low of 108 new \nblocks with a median of 142 new blocks. The new block counts for the message view range from a high of \n338 to a low of 129 with a median of 176 new blocks. Note that the new block counts are generally higher \nthan for the normal message set, with the exception of the outlier high new block count of 1233 for the \nnormal message view. Upon inspection, it is clear that the unusual messages tend to have unusual features \nsuch as strange characters in the message headers, HTML message bodies, complicated attachments, and \nlong provenance information. The unusual nature of the messages is re.ected in the increased new block \ncounts in comparison with the messages in the normal message set. After recti.cation, all but one of \nthe 40 messages is in the comfort zone for the list view (this message causes Pine to execute 7 new blocks); \nall but three messages are in the com\u00adfort zone for the message view (these messages cause Pine to execute \n15, 15, and 7 new blocks). The two messages that cause the Pine message view to execute 15 new blocks \nap\u00adpear to be two versions of the same message. This message has a fairly unusual HTML body. The single \nmessage that caused both the list view and the message view to execute 7 new blocks also has an unusual \nHTML body. Potential op\u00adtions for moving these messages into the comfort zone in\u00adclude adding more messages \nwith HTML bodies to the test collection of messages or developing a recti.er that elimi\u00adnates all but \nthe most basic HTML commands. We would recommend the second option since it reduces the size of the exercised \nregion while preserving much of the important information in the original messages. 4.3 Exploit Message \nSet The unrecti.ed exploit message causes Pine to execute 441 new code blocks. After recti.cation the \nmessage is in Pine s comfort zone. The key change is the replacement of the From:.eld in the original \nmessage header (which does not comprise a standard email address) with the default From: .eld. The recti.er \nleft the message body unchanged (the message body is not involved in the exploit and exhibits no unusual \nfeatures). We note that the version of DynamoRIO that we are using will successfully intercept and prevent \nremote code injection attacks [17, 2]. We also note that any monitor that terminates the execution as \nsoon as the application attempts to execute a new code block will also intercept and prevent such attacks. \nAn examination of the code that the exploit triggers shows that the recti.er will never produce an input \nthat would trigger the exploit to trigger the exploit, the From: .eld of the message must contain backslash \ncharacters. The recti.er will never produce a From:.eld that has such char\u00adacters. 4.4 Discussion From \nour perspective, our recti.er is fairly aggressive, at least as applied to the header of the message. \nAs it enforces its tightly constrained header format, it will modify virtually all messages encountered \nin practice. Nevertheless, it still manages to maintain the most important information in the header \n the sender s email address (required to reply to messages), the email address to which the message was \nsent, and the date and subject. It is of course possible to develop a recti.er that preserves more of \nthe structure of the header. The trade-off is that such a recti.er would produce a wider range of headers, \nwhich would, in turn, require a larger training suite to obtain an acceptable comfort zone. Our inclination \nis to minimize the size of the required comfort zone and the size of the corresponding training suite \nby making the recti.er as aggressive as possible. The starting point of our research is that one can \nalmost always .nd inputs that existing systems fail to process ac\u00adceptably. But for our proposed approach \nto work, the recti\u00ad.er itself must be able to correctly process every conceiv\u00adable input. One may legitimately \nwonder why it is feasible to construct recti.ers that accomplish this goal when it is apparently so dif.cult \nto construct systems that do so. There are several reasons why we believe it is feasible to build successful \nrecti.ers. First, the recti.er is under no obli\u00adgation to preserve all of the information in the input. \nUnlike the system, which has usually been designed to provide as many features as possible and therefore \naspires to support a broad range of inputs, the recti.er can focus on extract\u00ading only those pieces of \ninformation that it needs to gener\u00adate its tightly focused set of inputs. Second, the recti.er is a stand-alone \nsystem with a clear, narrow goal. Unlike the developers of the system, the developer of the recti.er \ncan focus on this goal in isolation, free of the distractions and requirements of operating within a \nlarger development en\u00advironment. Also unlike the developers of the system, who must typically use a general-purpose \nlanguage that has been designed to support a wide range of programs, the developer of the recti.er can \nuse a language and development style tai\u00adlored to support the speci.c kinds of tasks that the recti.er \nmust perform. We elaborate on these points further below. One of the keys to building successful recti.ers \nis to iden\u00adtify a tightly constrained input format (substantially more constrained than most current \nsystems are designed to pro\u00adcess) for the recti.er to produce. Ideally this input format would take the \nform of a template with slots for items from the original input. Once this rigid format is in place, \nthe rec\u00adti.er can use pattern matching to carefully chose pieces of the original input to place into \nthe slots in the template. Ev\u00aderything else in the original input is simply discarded. Our content transformer \nuses this approach to generate a highly constrained class of headers. Because it uses only the most basic \nfunctionality, users can have a high degree of con.dence that the email client will be able to process \nthe generated headers without problems. Of course, there is a trade-off most email clients are designed \nto support a much broader class of headers. With our approach the functionality associated with this \nbroader class is, by design, unavailable. Pine is, like many existing systems, coded in the C pro\u00adgramming \nlanguage. C is notoriously ill-suited for the kinds of text processing tasks that the recti.er must perform. \nAnd, in fact, the version of Pine that we used in our experiments exhibits a classic string over.ow error \nin which the devel\u00adoper failed to allocate a string large enough to hold all po\u00adtential inputs. Our recti.er, \non the other hand, is written in a scripting language (Perl) speci.cally suited for string pro\u00adcessing. \nBecause many of Perl s constructs support the kinds of string-processing tasks that the transformers \nmust per\u00adform, it is relatively easy to develop the transformers and, we believe, the transformers tend \nto have fewer errors than they would if they were developed in a language with less support for this \nspeci.c task. Moreover, the Perl language model completely eliminates some common kinds of errors (such \nas string over.ow errors) that can easily occur when coding up these kinds of tasks in C. Our experience \ndevel\u00adoping the Pine recti.er supports these points we found Perl to be well-suited to the task of quickly \nwriting a small (less than 250 lines of code) recti.er. We believe that coding up the recti.er in C would \nhave required substantially more time and effort.  5. Related Work Email is one of the most prominent \ninterfaces between users and the external world and one of the most widely used at\u00adtack carriers. The \nubiquity of email and its abuse have in\u00adspired the development of a range of email .ltering tech\u00adnologies, \nthe most widely used of which are spam .lters and virus .lters. The goal of both of these .ltering technologies \nis to intercept and eliminate problematic email messages be\u00adfore they are presented to the email client. \nStandard spam .ltering techniques use feature extraction and machine learning to automatically recognize \nmessages that are likely to be spam[1]. Virus .lters often use virus sig\u00adnatures to recognize message \nthat may contain viruses [9]. The drawback of this approach is that new viruses may avoid the virus signature \ndatabases, which only contain signatures of known viruses. Another approach is to simply remove at\u00adtachments \nof .le types (such as .scr or .js) that have been known to carry viruses. Yet another approach is to \nhave the email client associate document types (such as Microsoft Of.ce documents) that have been used \nin the past to carry viruses with non-standard programs that may be less vul\u00adnerable to the viruses. \nSo, for example, one might associate Word .les with WordPad instead of Word because WordPad does not \nexecute macros in Word .les (which may contain viruses that are activated when the macro is executed). \nWe note that this last example shows how excess functionality can become a serious liability for users \nof the system. Unlike spam and virus .lters, our goal is not to eliminate problematic messages before \nthey reach the email client. In\u00adstead, our goal is to use recti.cation to make every message innocuous \nso that it can be safely presented to the email client. By monitoring the email client as it processes \nmes\u00adsages, we can automatically detect comfort zone violations and, if desired, abort the computation \nbefore any undesirable functionality can be triggered. Despite these differences, there are also some \nconceptual similarities between the ap\u00adproaches. One could view the application of monitoring to con.ne \nthe system to its exercised region as an automated way of obtaining a new system without the harmful \nexcess functionality present in the original system. This could be viewed as similar in spirit to associating \ncertain kinds of doc\u00adument types with alternate programs in the email client, but with the advantage \nthat it does not require the availability of a separate system. The pervasive presence of Internet attacks \nhas motivated the development of a variety of tools to .lter out such at\u00adtacks. Firewalls, for example, \nare often con.gured to discard packets incoming on ports that attacks have successfully tar\u00adgeted in \nthe past [19]. Conceptually, one can view blocking certain ports as a coarse-grain form of recti.cation \nthat is designed to completely eliminate access to the services typ\u00adically present on those ports. Our \napproach is designed to operate at a much .ner granularity to enable access to a sim\u00adple part of a complex \nmonolithic application implemented as a single binary. Firewalls can also blacklist IP or MAC addresses. \nWhile it would be possible to develop recti.ers that perform similar actions based on the identity of \nthe in\u00adput source, our basic philosophy is to, whenever possible, present the transformed input to the \ntarget system. We there\u00adfore see recti.cation as discussed in this paper as orthogonal and complementary \nto techniques that discard inputs based on the identity of the input source. Web browsers can often be \ncon.gured to block or disable certain potentially problematic features such as pop-ups and cookies [5]. \nRecti.ers can provide similar functionality by eliminating these features as they arrive in the input. \nWe understand that input format mismatches and other input anomalies occur frequently when people use \ncomput\u00aders, and that various input conversion programs are often used to make it possible to successfully \nprocess otherwise problematic inputs. Our goal is much broader. Speci.cally, we aim to signi.cantly limit \nthe functionality that the in\u00adputs exercise and are willing, within reason, to discard in\u00adformation to \naccomplish this goal. Moreover, we advocate the pervasive and aggressive use of recti.cation as a means \nto simplify the overall computing environment. The bene.ts of our approach include the ability to use \nexisting complex, functionality-laden systems in simple ways without risking exposure to errors or vulnerabilities \nthat lie outside the ex\u00adercised region and a reduced cognitive load on the users and maintainers of the \ncomputing environment. Input recti.cation can be seen as a form of acceptability\u00adoriented computing [14, \n15]. Speci.cally, the set of con\u00adstraints that the recti.er enforces can be seen as a set of acceptability \nproperties that every input must satisfy to be acceptable. Input recti.cation is also similar in spirit \nto data structure repair [4] in that it enforces a set of properties whose violation might otherwise \ncause problems for the sys\u00adtem. One difference is that the goal of data structure repair is to keep a \nsystem executing acceptably even though it en\u00adcounters errors that corrupt its data structures. The goal \nof input recti.cation, on the other hand, is to move inputs into the system s sweet spot to avoid encountering \nerrors in the .rst place. Common Lisp and ZetaLisp lambda-lists enable a func\u00adtion to treat its argument \nlist as data [16]. My understanding is that this feature was used to develop functions that exam\u00adined \nand, if necessary, changed argument lists to values that invoked functions could successfully handle. \n 6. Conclusion The complexity of the systems in our current computing en\u00advironment leads inevitably to \nerrors, security vulnerabilities, and a large cognitive burden on users. Despite these prob\u00adlems, users \nare locked in it is usually close to unthinkable to attempt to build a simpler environment (or even \nsignif\u00adicant components of a simpler environment) from scratch. But hidden within almost every large, \ncomplex system is a well-tested core that almost always performs acceptably. The identi.cation and enforcement \nof appropriate comfort zones can extract these cores and eliminate the excess function\u00adality (along with \nthe associated errors and vulnerabilities) currently present in virtually every deployed system. As always, \nsimplicity requires renunciation. The in\u00adevitable price for this reduction in complexity is the elim\u00adination \nof information that would otherwise exercise the dis\u00adcarded functionality. Based on our experience with \nthe Pine email recti.er, we expect that it will be possible, in many cases, to obtain a simple recti.er \nthat successfully moves inputs into the comfort zone while preserving the most im\u00adportant information. \nThe pervasive adoption of such recti\u00ad.ers may dramatically simplify our computing environment and eliminate \nfrustrating or even dangerous problems while preserving the key bene.ts that it delivers to its users. \n 7. Acknowledgements I would like to thank Sam Larsen for his invaluable help with DynamoRIO. The implemented \ncomfort zone discovery and monitoring system uses a (slightly modi.ed) hash table im\u00adplementation developed \nby Christopher Clark [3]. References [1] Apache SpamAssassin Project. http://www.spamassassin.apahe.om. \n [2] Derek Bruening. Ef.cient, Transparent, and Comprehensive Runtime Code Manipulation. PhD thesis, \nMassachusets Institute of Technology, September 2004. [3] Christoper Clark. Hash table implementation. \nhttp://www.l.am.a.uk/ w22/hashtable/. [4] Brian Demsky and Martin Rinard. Data structure repair using \ngoal-directed reasoning. In Proceedings of the 2005 International Conference on Software Engineering \n, St. Louis, MO, May 2005. [5] Firefox Options Page. http://www.mozilla.org/support/frefox/options. \n[6] Chi-Keung Luk, Robert Cohn, Robert Muth, Harish Patil, Artur Klauser, Geoff Lowney, Steven Wallace, \nVijay Janapa Reddi, and Kim Hazelwood. Pin: Building Customized Program Analysis Tools with Dynamic Instrumentation. \nIn Proceedings of the ACM SIGPLAN 2005 Conference on Programming Language Design and Implementation (PLDI), \nChicago, IL, June 2005. [7] Microsoft word scripting vulnerability. http://www.mirosoft.om/tehnet/seurity/Bulletin/MS02-021.mspx. \n[8] Nicholas Nethercote and Julian Seward. Valgrind: A Frame\u00adwork for Heavyweight Dynamic Binary Instrumentation. \nIn Proceedings of the ACM SIGPLAN 2007 Conference on Pro\u00adgramming Language Design and Implementation \n(PLDI),San Diego, CA, June 2007. [9] Norton AntiVirus, marketed by Symantec. http://www.symante.om. \n[10] Perl website. http://www.perl.om. [11] Matt Pietrek. Windows 95 Programming Secrets. John Wiley \n&#38; Sons, November 1995. [12] Pine exploit. www.seurityfous.om/bid/6120/disussion. [13] Pine website. \nwww.washington.edu/pine/. [14] Martin Rinard. Acceptability-oriented computing. In 2003 ACM SIGPLAN Conference \non Object-Oriented Program\u00adming Systems, Languages, and Applications Companion (OOPSLA 03 Companion), \nAnaheim, CA, October 2003. [15] Martin Rinard, Cristian Cadar, and Huu Hai Nguyen. Exploring the acceptability \nenvelope. In 2005 ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages, and Applications \nCompanion (OOPSLA 05 Companion) , San Diego, CA, October 2005. [16] G. Steele and R. Gabriel. The evolution \nof lisp. In Proceedings of the Second ACM SIGPLAN Conference on the History of Programming Languages, \nCambridge, MA, April 1993. [17] Gregory Sullivan, Derek Bruening, Iris Baron, Timothy Gar\u00adnett, and Saman \nAmarasinghe. Dynamic native optimization of interpreters. In Proceedings of the ACM Workshop on In\u00adterpreters, \nVirtual Machines, and Emulators (IVME-03),San Diego, CA, June 2003. [18] Wikipedia Buffer Over.ow Article. \nhttp://en.wikipedia.org/wiki/Buferoverfow. [19] Wikipedia Firewall Article. http://en.wikipedia.org/wiki/Firewall{networking). \n[20] Wikipedia Mbox Article. http://en.wikipedia.org/wiki/Mbox.   \n\t\t\t", "proc_id": "1297027", "abstract": "<p>A comfort zone is a tested region of a system's input space within which it has been observed to behave acceptably. To keep systems operating within their comfort zones, we advocate the interposition of <i>rectifiers</i> between systems and their input sources. Rectifiers are designed to transform inputs to ensure that they are within the comfort zone before they are presented to the system. Rectifiers enforce a highly constrained input format and, if necessary, discard information to force inputs to conform to this format. Potential benefits of this approach include the elimination of errors and vulnerabilities, the excision of undesirable excess functionality from large, complex systems, and a simplification of the computing environment.</p> <p>We have developed a rectifier for email messages and used this rectifier to force messages into a specific constrained form. Our results show that this rectifier can successfully produce messages that keep the Pine email client strictly within code previously confirmed (during a small testing and training session) to function acceptably. Our results also show that the rectifier completely eliminates a security vulnerability in the Pine email client. And finally, the rectifier is able to accomplish these goals while still preserving an acceptable amount of information from the original messages.</p>", "authors": [{"name": "Martin C. Rinard", "author_profile_id": "81100087275", "affiliation": "Massachusetts Institute of Technology, Cambridge, MA", "person_id": "P192533", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1297027.1297072", "year": "2007", "article_id": "1297072", "conference": "OOPSLA", "title": "Living in the comfort zone", "url": "http://dl.acm.org/citation.cfm?id=1297072"}