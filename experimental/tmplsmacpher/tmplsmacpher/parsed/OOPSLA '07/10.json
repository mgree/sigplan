{"article_publication_date": "10-21-2007", "fulltext": "\n Transactions with Isolation and Cooperation Yannis Smaragdakis Anthony Kay Reimer Behrends Michal Young \nDepartment of Computer and Information Science University of Oregon Eugene, OR 97403-1202 {yannis,tkay,behrends,michal}@cs.uoregon.edu \nAbstract We present the TIC (Transactions with Isolation and Co\u00adoperation) model for concurrent programming. \nTIC adds to standard transactional memory the ability for a transaction to observe the effects of other \nthreads at selected points. This allows transactions to cooperate, as well as to invoke non\u00adrepeatable \nor irreversible operations, such as I/O. Cooper\u00adating transactions run the danger of exposing intermediate \nstate and of having other threads change the transaction s state. The TIC model protects against unanticipated \ninterfer\u00adence by having the type system keep track of all operations that may (transitively) violate \nthe atomicity of a transaction and require the programmer to establish consistency at ap\u00adpropriate points. \nThe result is a programming model that is both general and simple. We have used the TIC model to re-engineer \nexisting lock-based applications including a substantial multi-threaded web mail server and a memory \nallocator with coarse-grained locking. Our experience con\u00ad.rms the features of the TIC model: It is convenient \nfor the programmer, while maintaining the bene.ts of transactional memory. Categories and Subject Descriptors \nC.5.0 [Computer Sys\u00adtems Implementation]: General; D.1.3 [Programming Tech\u00adniques]: Concurrent Programming \nparallel programming; D.3.3 [Programming Languages]: Language Constructs and Features concurrent programming \nstructures General Terms Design,Languages Keywords transactional memory, nested transactions, open-nesting, \nTIC, punctuation Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. OOPSLA 07, October 21 25, 2007, Montr\u00b4ebec, Canada. eal, Qu\u00b4Copyright &#38;#169; 2007 ACM 978-1-59593-786-5/07/0010...$5.00 \n1. Introduction and Motivation Transactions as a programming language construct have been proposed to \nsimplify concurrent application program\u00adming and avoid programming errors. Complexity and error proneness \nin conventional concurrent programming mod\u00adels is a consequence of the essential non-locality of rea\u00adsoning \nabout lock (or monitor) acquisition order and con\u00addition signaling. Transactional programming (whether \nsup\u00adported by a hardware transactional memory, software trans\u00adactional memory, or source-to-source translation \nto conven\u00adtional locking code) aims to reduce the programmer s burden to a single, local design decision \nabout which sequences of actions should execute as if atomic. To relieve the programmer from non-local \nreasoning about concurrency, the programming model presented by transaction support must have certain \nessential properties: It must compose, in the sense that the decision to make a region of code in one \nmethod transactional is indepen\u00addent of whether called or calling methods are transactional. This further \nimplies that any restrictions or special condi\u00adtions on enclosing a method call in a transaction should \nbe tracked by the type system, rather than requiring a pro\u00adgrammer to inspect source code of other classes. \n It must be general enough that common operations can be (transitively) enclosed in transactions, and \nthat com\u00admon concurrent programming idioms can either be used unchanged or have suitable replacements. \n Existing proposals for transaction support still fall short of these requirements. For example, atomic \nsections com\u00admonly need to roll back and undo their effects. (An op\u00adtimistic concurrency control implementation \nneeds to roll back when it detects interference from another transaction. A pessimistic implementation \nneeds to roll back, in order to avoid deadlock, when it fails to acquire a lock.) Roll-back is incompatible \nwith operations that cannot be undone, such as I/O. Although I/O can be automatically buffered (e.g., \nput off until the end of a transactional section) [27], this is not al\u00adways consistent with the program \ns logic, particularly when a read follows a write. Thus, performing irreversible opera\u00adtions becomes \na global property in transactional systems: A transaction needs to be aware of irreversible operations \nin all methods it calls, directly or indirectly. Past solutions to this problem have been draconian: \nEither irreversible operations have been completely disallowed in atomic sections [29], or concurrency \nis disabled and only a single transaction with irreversible operations can be run at a time [10, 11]. \nA related problem is that of transaction nesting. The most reasonable semantics is closed-nesting: The \neffects of a nested transaction are not externally visible until the out\u00adermost transaction completes. \nHowever, this approach is not modular. Transactional code that needs to communicate its results to the \noutside world needs to be careful to avoid be\u00ading used inside another transaction. This makes thread \ncoop\u00aderation harder. Transactional models often allow depending on external conditions through guards \nfor atomic sections [28] or through plain use of a retry statement that restarts the transaction, undoing \nits current effects [29]. These ap\u00adproaches suf.ce only at the outermost level of nested trans\u00adactions. \nHarris and Fraser [28] propose evaluating all guards of inner transactions at the outermost level. An \nalternative is to restart the outermost transaction if an inner transac\u00adtion s guard fails. Both approaches \nare insuf.cient for allow\u00ading threads to cooperate. For instance, consider the simplest thread coordination \na barrier: void barrier() { atomic { count++; } atomic(count == NUMTHREADS) { /* barrier reached */ } \n} (We use a Harris-and-Fraser-like Java extension for this example note the Conditional Critical Region \nsyntax of the second atomic section.) The guard of the second atomic sec\u00adtion will only become true when \nall threads have .nished the .rst atomic section. Yet if we want good composabil\u00adity properties, the \nbarrier itself should be usable inside an atomic section. Such use can possibly be completely acci\u00addental, \nin an atomic section protecting other, unrelated data from interference: atomic { ... barrier(); ... \n} For ease of exposition, we show the result of inlining the barrier code, so that the nesting becomes \nsyntactic: atomic { ... atomic { count++; } atomic(count == NUMTHREADS) { /* barrier reached */ } ... \n} It is hard to see what would be a reasonable semantics for the atomic sections in this case. Clearly, \nthe Harris and Fraser approach [28] of evaluating nested guards at the out\u00adermost transaction s level \ndoes not apply. The outer atomic section cannot block at entry until the condition of the inner section \nbecomes true the condition itself depends on the execution of the .rst inner atomic section. Restarting \nthe out\u00adermost transaction upon reaching the unsatis.ed inner guard does not work either this would undo \nthe effect of the .rst inner atomic section, making the guard unsatis.able. Indeed, the word atomic itself \nseems a misnomer in this case: The in\u00adtended behavior is that execution of the outer atomic section will \nnot be atomic, but will instead be interrupted, allow\u00ading other threads to observe its results, and itself \nobserving the results of other threads at the point of evaluation of the inner atomic section s guard. \nThis is the essence of thread cooperation: We want to allow observing the results of other threads in \na controlled manner, even if the code happens to be called inside an atomic section. I/O can even be \nviewed as a special case of a cooperation pattern with the cooperating thread provided by the I/O device. \nIn this paper, we present a concurrent programming model that attempts to allow freedom in how the code \nis structured, while handling uniformly both irreversible oper\u00adations and thread cooperation. We call \nthe model TIC for Transactions with Isolation and Cooperation. TIC allows temporarily suspending a transaction \ns atomicity and isola\u00adtion properties in the middle of an atomic block. The type system tracks all occurrences \nof such suspending operations and ensures that the user provides a way to recover from them. For instance, \nour barrier example can be written as: void barrierTIC() { atomic { count++; Wait(count == NUMTHREADS); \n} } The Wait keyword is a TIC addition to a conventional Transactional Memory (TM) programming model. \nIt sig\u00adni.es that transactional isolation is suspended until the condition of the Wait statement (in \nthis case count == NUMTHREADS ) becomes true. Based on our previous discus\u00adsion, the interesting case \nis that of a Wait that does not oc\u00adcur lexically nested inside an atomic section, but in a transi\u00adtively \ncalled routine. In this case, TIC dictates that the type system keep track of operations that possibly \nWait.All such operations need to occur inside a block of code designated by expose(<methodcall>) establish \n<stmt> . Thus, our barrierTIC routine can be called inside an atomic section as: atomic { ... expose(barrierTIC()) \nestablish { ... } ; ... } The statement block following the establish keyword is responsible for re-establishing \nlocal invariants that the rest of the atomic section expects at this point in the execution. Importantly, \nthe type system does not allow invocations of barrierTIC, unless under an expose ... establish,even if \nthese invocations occur transitively. That is, if a method foo calls a method bar,and bar in turn calls \nbarrierTIC,then both the call to barrierTIC and the call to bar need to be under expose ... establish \nexpressions. (We discuss later how this requirement is relaxed with a checked programmer\u00adsupplied type \nannotation.) The above example showcases some of the main ele\u00adments of the TIC model. Later sections \nde.ne the full model more precisely. Note that TIC is orthogonal to many per\u00adformance and implementation \nconsiderations. TIC is a pro\u00adgramming model, not an implementation technique, and is intended to be compatible \nwith a variety of different imple\u00admentation techniques with different performance character\u00adistics and \ndemands on program analysis. In order to evaluate the expressiveness and ease of use of the TIC model \nfor real\u00adistic concurrent applications, we produced initial implemen\u00adtations based on Harris and Fraser \ns libstm [28] and Dice et al. s TL2 [17]. Overall, the TIC behavior can be emulated with tradi\u00adtional \natomic transactions, but not without signi.cant code reorganization. A reasonable way to view the bene.ts \nof TIC is as a way to relax the severe restrictions of existing tech\u00adniques, while maintaining the assurance \nthat the programmer has considered the impact of transaction suspension. Other authors (e.g., Carlstrom \net al. [11]) have advocated mapping condition-variable waits in lock-based code to transaction suspension, \nbut with no type system warning of this behav\u00adior to the authors of surrounding transactions. In short, \nour paper makes the following contributions: We de.ne the TIC concurrent programming model that ex\u00adtends \ntransactions to also allow thread cooperation. TIC re\u00adtains all the bene.ts of traditional transactions \nin the com\u00admon case of atomic sections that do not Wait.At the same time, it offers a single, uniform \nmechanism that allows both operations that Wait and operations that perform irre\u00adversible actions to \nbe used inside transactional code, while enabling the transaction to recover from inconsistencies.  \nWe demonstrate the simplicity of the model with several examples. The type system support of the TIC \nmodel was found to be useful for TIC implementations but also for detecting errors in lock-based code \n(e.g., locks held during high-latency network operations).  TIC offers a more disciplined alternative \nto many uses of open-nested transactions. For instance, a long-running op\u00aderation can be delegated to \na different thread, with Wait used for inter-thread coordination. Nevertheless, the main TIC features \nare complementary to open-nesting. Indeed, our current formulation of TIC integrates open-nesting ideas \nto cover some interesting cases. We allow nested transactions to be open, if they occur in a method that \nspec\u00adi.es compensating actions.  We offer an optimistic implementation of the TIC model. We use this \nimplementation to evaluate the model in prac\u00adtice for realistic multi-threaded applications. The rest \nof this paper is organized as follows. We .rst present an overview of the TIC model (Section 2) and then \ndiscuss our experience with implementing concurrent appli\u00adcations with TIC (Section 3). We describe in \nmore detail the TIC type system and implementation in Section 4. Section 5 discusses the TIC nesting \nmodel, as well as connections be\u00adtween TIC and open-nested transactions. We then contrast with related \nwork (Section 6) and conclude (Section 7). 2. Isolation and Cooperation Hell is a place where people \nlive in pairs, tied back-to-back so they can t see each other s face. Eastern European popular tradition. \nHell is other people. Jean-Paul Sartre. We next describe in more detail the TIC programming model. There \nare two interesting cases that TIC intends to handle similarly: transactions that Wait and transactions \nthat call external operations incompatible with transactional semantics. Such operations typically access \nsome resource outside the control of the transactional memory system e.g., I/O and either directly expose \ntheir results to other transactions, or are irreversible. We begin our discussion 1 with the case of \ntransactions that call Wait. 2.1 Transactions that Wait We discuss the TIC model in the context of an \nidealized ex\u00adtension of the Java language for simplicity of exposition. The same principles can be adapted \nto other languages and differ\u00adent integration techniques. Indeed, as we describe later, our actual prototype \nis a C++ library which hides many of the .ner details but still requires manual code instrumentation. \nThe syntax of a TIC transaction (using the conventions of the Java Language Speci.cation [22]) is: AtomicStatement: \natomic Statement An AtomicStatement is a Java statement and in practice the statement that follows keyword \natomic is usually a com\u00adposite statement (block): atomic { statements } Atomic sections can nest arbitrarily, \nboth in lexical and in dynamic scope (i.e., an atomic section can include calls to methods that include \nother atomic sections). We follow by default a closed-nesting semantics, where nested trans\u00ad 1 We use \nthe term to call Wait for convenience, although Wait is a statement. actions do not truly commit until \nthe outermost transaction does. For the most part, our idealized Java extension matches the decisions \nof the Harris and Fraser design [28]. E.g., Our transactions have exactly-once execution semantics. \n All program data can transparently participate in a trans\u00adaction.  All regular Java control .ow (including \nmethod returns and exceptions) can be used inside a transaction and result in normal termination (i.e., \ncommit) of the transaction.  Nevertheless, whereas Harris and Fraser implement Hoare s Conditional Critical \nRegions (CCRs) [35] program\u00adming model, we do not support conditional atomic sections, as these are supplanted \nby our Wait concept. An atomic block can call a Wait(Expression) operation, with a boolean Expression \nrepresenting the condition of Wait.This has the effect of checking the condition, and, if it is not true, \ncom\u00admitting the current transaction and suspending the thread ex\u00adecuting it until the condition becomes \ntrue.2 Once the con\u00addition becomes true, the transaction restarts from the state\u00adment following Wait. \nFor all purposes, the transaction be\u00adfore the execution of a Wait and that after it are two sep\u00adarate \ntransactions we call them the top and bottom trans\u00adactions, relative to each Wait statement. The starting \npoint of the bottom transaction (e.g., for re-trying purposes) is the Wait statement, no matter where \nthis is found in the program. We use the terms suspending and resuming the transaction for committing \nthe top transaction and beginning the bottom one. We also use the term punctuating the transaction for \nthe overall effects of calling Wait. Clearly, having a Wait operation is unnecessary if it is unconditionally \nand directly called inside a single atomic statement. For instance, a section such as atomic { statementBlockA \nWait(condition); statementBlockB } can be written equivalently with a CCR: atomic { statementBlockA } \natomic (condition){ statementBlockB } The bene.t of having an explicit Wait statement is that it can \nbe used at any point in a transaction. Thus, a Wait could be invoked nested deeply inside a conditional \nstatement, or from a method called transitively from other methods invoked inside an atomic.A Wait statement \npunctuates all 2 We use the same mechanism as Harris and Fraser [28] for checking when a condition has \npossibly changed value namely, we observe what updates get committed to locations that the waiting transaction \naccessed. A desirable property for the condition expression is that it be side-effect free, but we do \nnot currently try to enforce this automatically. the nested transactions in whose dynamic scope it occurs, \nand not only its directly enclosing transaction. We have already seen in the Introduction an example \nwhere the use of Wait allows transactions to cooperate. Wait adds power to atomic sections, but it violates \ntransactional semantics. Not only can a transaction that Waits observe the results of other transactions \n(loss of isolation)but it also exposes its own intermediate results to other threads (loss of atomicity). \nThis is an unavoidable consequence of sup\u00adporting communication (through conditions) in the midst of \ntransactional code, as preserving isolation would prevent communication. Since we cannot avoid breaching \nisolation where processes communicate, we must instead take mea\u00adsures to make this consequent evident \nto the programmer, even when the Wait appears at several removes of proce\u00addure calls from the transaction \nthat it may punctuate. The TIC model offers type system support for keeping track of Waiting operations \n(as well as other kinds of operations that violate transactional semantics, as discussed in the next \nsec\u00adtion). The programmer can then decide whether the code can be reorganized so that the operation is \nperformed outside the atomic section, or if the operation is safe inside the atomic section with an establish \nclause used to re-establish the in\u00advariants of the transaction after its suspension. More speci.cally, \nwe de.ne waiting methods to be those that contain a call either to Wait or to another waiting method \n(that is, all methods that may call Wait directly or indirectly). A call to a waiting method is not legal \nunless it occurs inside an expose ... establish expression. The syntax of the expose ... establish expression \nis expose (Expression) [establish Statement] where Expression is a single call to a waiting method and \nthe return value of the method becomes the value of the entire expose ... establish expression. The establish \nclause is optional omitting it is equivalent to an empty statement following the establish keyword. If \nthe call to the waiting method results in the transaction being suspended by a Wait, then, when the transaction \nresumes and the method call returns, Statement is executed. Subsequently, if the bottom transaction later \naborts and re-tries, the establish clause is also always executed (on return of control .ow to this method). \nNevertheless, if the transaction is never actually suspended, either because its control .ow does not \nreach the Wait statement, or because the condition of the Wait is already true when .rst checked, then \nStatement is not executed. For illustration, consider a waiting method foo and a transaction calling \nit: void foo() { Wait(x > 0); } void bar() { atomic { y=0; expose(foo()) establish {y=1;}; } } The value \nof y at the end of the atomic block will de\u00adpend on whether the transaction is ever punctuated. If the \ntransaction commits as a whole by reading an x greater than zero, which prevents the Wait statement from \nsuspending the transaction, then the establish block is not executed, and the value of y is zero. Otherwise, \nthe value of y is 1. Note that, according to our requirement, method bar itself cannot be called outside \nan expose ... establish state\u00adment. The reason is that the use of bar in an atomic state\u00adment can cause \nthe suspension of the transaction with its top part (up to the call to bar) committed and the rest of \nit ex\u00adecuting independently and possibly being retried. Code pre\u00adceding the call to bar has to establish \nglobal invariants, in anticipation of a possible suspension. The establish clause (and code following \nit) is then used to ensure consistent ex\u00adecution by re-establishing local invariants. (Section 3 offers \nusage examples in real scenarios and argues why this is a good approach for modularity purposes.) The \nprogrammer can suppress the requirement for an expose ... establish around a method s calls, if the method \nis certain to never be used inside an atomic section. This is done with the annotation toplevel. The \ntype system disallows calls to a toplevel method in transactions. For in\u00adstance, method bar in our example \nabove contains a transac\u00adtion, but it could itself be prevented from ever being called inside a transaction \nif its type signature is changed to: toplevel void bar() { ... /* as before */ } In this case, calls \nto bar no longer need to be under an expose ... establish clause. Naturally, methods that call toplevel \nmethods are also not usable in transactions a property veri.ed by our type system. It is important to \nrealize that the requirement for an expose clause is the type system reminder to the program\u00admer that \nhe/she needs to ful.ll two obligations: ensure that atomicity can be relaxed, so that other threads can \nobserve current results consistently, and ensure that isolation can be relaxed so that the current transaction \ncan observe the effects of other threads (after the Wait returns) without violating its consistency properties. \nThe .rst of these properties is typi\u00adcally handled by the code preceding the call to Wait and not by \nthe code following Wait (including the establish clause in callers), whose purpose is to handle the second \nproperty. 2.2 Handling Suspending Operations Waiting methods are not the only ones that require special \ntreatment in transactions. Any method that violates either atomicity or isolation needs to be handled \nspecially. Typi\u00adcally this is due to irreversible actions affecting external re\u00adsources. We call all \nnon-waiting methods that require special handling suspending methods. The treatment of suspending methods \nin TIC is almost identical to the treatment of wait\u00ading methods, described previously. This uniformity \nis an in\u00adteresting feature of TIC. Nevertheless, there are some sub\u00adtleties. First, we need to conceptually \nidentify which meth\u00adods are the root suspending methods so that method type signatures at the interface \nwith system code are correctly la\u00adbeled. Second, as is also common in other transactional set\u00adtings, \na programmer is allowed to specify undo actions to allow suspending methods to be safely used in transactions. \nFinally, the behavior of retrying a transaction is slightly dif\u00adferent in the case of suspending methods, \ncompared to wait\u00ading methods. We discuss these points next. An (external) operation is safe to use inside \na transaction without surrounding code being aware, if both: 1. its effects are not exposed to other \nthreads in a way that may violate application correctness and  2. its effects can be reversed.  Some \napproaches (e.g., [16]) propose weakening the sec\u00adond condition to the operation is idempotent: Re-executing \nit has the same effects and result as executing it once . How\u00adever, this is not correct in a general \nprogramming model. Even if an operation is idempotent, retrying a transaction af\u00adter a change to shared \ndata can result in the operation now being outside the control-.ow of the transaction, or being called \nwith different arguments. Establishing the idempo\u00adtency of an entire transaction body after a change \nto shared data is generally infeasible. Thus, neither reusing previous results and effects of a suspending \noperation nor re-running it are generally safe in the course of retrying a transaction. In the TIC model, \nmethods that have effects that violate the requirements of the transactional memory system can be labeled \nusing the annotation suspending in the method declaration. This annotation is best applied to system-level \noperations (e.g., native methods in Java). Any method that calls a suspending method is also implicitly \nsuspending we use the term root suspending operations to distinguish the base methods that have the suspending \nannotation. For instance, a JDK implementation will likely declare method write in java.io.RandomAccessFile \nas: public suspending native void write(int b) throws IOException; External operations that can be reversed \nrepresent the easy case of handling suspending methods. Following the example of open-nesting transactional \nmodels [46, 45, 52], we allow the user to specify for each forward operation an undo operation and an \non-commit operation (collec\u00adtively called compensating operations ). These are desig\u00adnated by annotations \nundo and oncommit, respectively, on the forward operation. Both operations are methods on the same object \nas the forward operation. Additionally, compen\u00adsating operations accept arguments of the same type as \nthe forward operation, plus extra arguments of the same type as the return type of the forward operation \n(if non-void) and any exception types the forward operation may throw. For in\u00adstance, a common pattern \nis that of an operation release as the undo operation for method allocate (but not vice versa). This \nwould be speci.ed as: undo(release) Entity allocate(String name, int length); void release(Entity e, \nString n, int l); Every method that has an undo annotation causes the out\u00adermost transaction it contains \nto have open-nesting seman\u00adtics, relative to the method s enclosing transactional context. This means \nthat the transaction commits at its end, indepen\u00addently of any parent transaction, thus making its results \nim\u00admediately visible to other threads. If the parent transaction (i.e., the transaction surrounding the \nmethod) needs to roll back and retry, the system calls the method s undo operation to reverse prior committed \neffects of the nested transaction. Root suspending operations in a method with an undo anno\u00adtation are \nalso handled similarly. A root suspending opera\u00adtion is treated as if it were an open-nested transaction. \nIt is considered to commit if control .ow reaches it, which causes (upon method completion) the undo \naction of the surround\u00ading method to get registered for a possible compensating ac\u00adtion in the future. \nThe TIC model for compensating actions is slightly unconventional, in that the on-commit operation in \nTIC is independent of nesting semantics: a method can have an oncommit annotation either with or without \nhaving an undo annotation and open-nested transactions in it. The on\u00adcommit operation is registered upon \nreturn of the annotated method. If/when the innermost open-nested transaction, or (if all transactions \nare closed-nested) the outermost transac\u00adtion surrounding the method validates its reads and is ready \nto commit, the system calls the on-commit operation of the method. We later give a more precise description \nof the TIC nest\u00ading model, as well as a comparison with traditional open\u00adnesting (Section 5). Until then, \nwe focus more on TIC s transaction punctuating features and compare the model to standard closed-nested \ntransactions. The interesting case of external operations concerns those that are not called under a \nmethod with an undo operation. Such suspending operations are treated much like waiting ones. A transaction \ncan call a suspending operation only un\u00adder an expose ... establish clause. The transaction will again \nbe punctuated: It will commit immediately before the root suspending operation call, just as it commits \nbefore blocking on a Wait.The establish statement is expected to re-establish the transaction s invariants \nafter the suspend\u00ading call and the resulting loss of isolation. There is a subtle difference, however. \nIn case of a transaction retry, the root suspending method call is not repeated. Instead, execution resumes \nfrom the return point of the root suspending oper\u00adation, making the corresponding establish clause the \n.rst statement executed. For instance, consider a transaction: atomic { if (!balanceUpdated()) { bal \n= compute(); expose(print(\"Balance:\" + bal)) establish { if (balanceUpdated()) // someone raced us return; \n}; updateBalance(bal); } } The transaction computes a result based on shared vari\u00adables and exposes it \nwith an external, irreversible operation (print). At this point, the transaction commits and a dif\u00adferent \nthread may have raced to .ll in the needed result. In this case, the transaction conservatively chooses \nto avoid the .nal update. If the transaction proceeds to updateBalance and this encounters contention \nthat causes a retry, then the transaction will restart from the point right after the execu\u00adtion of the \nexternal operation that is, from the statement under establish. If the user wants to repeat the suspending \noperation in case of a transaction retry (perhaps with differ\u00adent arguments) an explicit loop should \nbe placed around the code containing expose ... establish. For instance, con\u00adsider the following example: \natomic { balance = compute(); print(\"Your balance is \" + balance); bet = input(\"How much will you wager?\"); \nif (bet <= balance) register(bet); } If print and input are irreversible operations, then this is not \nvalid TIC code expose ... establish clauses need to be used. Nevertheless, this example represents a \nhopeless case. There is no way to re-establish the transaction s invari\u00adants with an expose ... establish \nclause if the external world (human user) observes a balance that is no longer cor\u00adrect. The only reasonable \nrecovery in this case is to retry the whole transaction. The user s input is based on prior output, and, \nhence, needs to be obtained again. We can do this with an explicit loop: atomic { while (true) { balance \n= compute(); expose(print (\"Your balance is \" + balance)) ; bet = expose(input(\"How much will you wager?\")) \nestablish { if (balance == compute()) break; }; } if (bet <= balance) register(bet); } This creates the \nobligation to handle transaction sus\u00adpension in all possible transactions surrounding the cur\u00adrent code. \nFor this example, since no recovery of any kind is meaningful and we need to repeat the entire transac\u00adtion, \nwe have an alternative that places a lower burden on clients: We can use the undo annotation to prevent \ntransac\u00adtion punctuation and remove the obligation of using expose ... establish clauses in all surrounding \ntransactions. An empty undo action causes the suspending operations to be\u00adhave as if they are perfectly \nreversible. In this way we also avoid the explicit loop, in favor of the natural looping behav\u00adior of \ntransaction retry. For instance, we wrap the print and input methods: undo(doNothingString) void myprint(String \ns) { print(s); } undo(doNothingintString) int myinput(String s) { return input(s); } Using the wrapped \nmethods in place of the originals achieves the desired effect without a need for a loop or expose ... \nestablish.  3. Applications and Experience We next discuss examples of the applicability and bene.ts \nof TIC relative to existing transactional programming mod\u00adels. We use C, C++, and Java realizations of \nTIC in our examples see Section 4 for an implementation discussion. 3.1 Shortcomings of Traditional Models \nand TIC TIC arose from our experience in implementing multi\u00adthreaded applications and trying to express \nthem or restruc\u00adture them to work with transactional memory mechanisms. Despite assertions regarding \nthe composability of transac\u00adtions in comparison to locking [28, 29], we have found trans\u00adactions to \nnot compose well because of the presence of non\u00adtransactional operations. We saw an example in the Introduc\u00adtion, \ninvolving a barrier pattern. In practice, many common patterns have to do with system-level suspending \noperations and not with the need to cooperate with other threads.3 A general pattern that we observed \nseveral times in prac\u00adtice is the following: An atomic section would normally have a suspending operation \ninside it. With some code restructur\u00ading and minor bookkeeping, the operation may be movable outside \nthe transaction: void methodWithTransaction() { atomic { ... <set bookkeeping data> ... } <use bookkeeping \ndata to perform external op> } Nevertheless, this has rarely been suf.cient. Other code using a transaction \n(possibly to protect some entirely dis\u00ad 3 It is unrealistic to expect that eventually all system-level \noperations will acquire transactional semantics. Even though transactional memory alloca\u00adtors or transactional \n.le systems already exist, transactional network I/O, or user I/O is nearly infeasible. In general, much \nof the external world is deeply not transactional, as effects cannot be undone. tinct data than the above \ntransaction) often needs to call methodWithTransaction (and may even do so inside a loop): atomic { ... \nmethodWithTransaction(); ... } Now the external operation suddenly .nds itself exe\u00adcuted as part of a \ntransaction, and possibly (erroneously) re\u00adpeated when the transaction retries. The operation needs to \nbe moved again, this time outside the atomic section in the caller method. This may require signi.cant \ncode restructur\u00ading: Functional abstraction may need to be violated, trans\u00adactions may need to be split, \netc. The unfortunate conclu\u00adsion is that transactions do not compose well. A transaction can be oblivious \nto the synchronization strategies of methods it calls, but it cannot be oblivious to suspending operations \nin these methods. In short, in transactional code, perform\u00ading an irreversible operation is a global \nproperty,just as, in lock-based code, holding locks is a global property. Sus\u00adpending operations have \nthe potential to render incorrect all transactions under whose dynamic scope they execute, and not just \nthe immediately surrounding transaction. The problem of transactional code not composing in the presence \nof waiting or suspending operations is unavoid\u00adable and TIC offers no magical solution. What the model \ndoes is expose to the programmer the points where extra glue needs to be applied and enable him/her to \nhandle the composition of transactional code, by restoring only local invariants every time. The programmer \nalways has the op\u00adtion to revert to standard techniques for handling suspend\u00ading/waiting in transactional \nprograms, such as moving code outside transactions. In many cases, however, using TIC re\u00adsults in signi.cantly \nsimpler and more modular code, in ad\u00addition to helping avoid bugs. We give some speci.c exam\u00adples from \nactual code. 3.2 Recovering from Suspending Operations We reengineered the version of the Kingsley memory \nallo\u00adcator supplied with the Heap Layers suite [6] to work with transactions, as opposed to .ne grained \nlocking. The pattern we present, however, is typical of multiple memory alloca\u00adtors. It is a good example \nfor the TIC model, because it ex\u00adposes complexity without being overwhelming. The Kingsley allocator \nis one of the fastest general\u00adpurpose memory allocators [6]. The allocator divides free blocks into power-of-two \nsize classes. A fragment of the code in the main allocation routine (using transactions but not using \nthe TIC model) is shown in Figure 1. The code uses an atomic section to consistently access a shared \ndata struc\u00adture. In the middle of multiple accesses to shared data, the code calls operation morecore \nto get more memory from the operating system if the appropriate free list is empty. Func\u00adtion morecore, \nhowever, calls sbrk, which is an irreversible system operation. (Even if the operating system allows \nlow\u00adering the brk pointer, another thread could have moved it void *kmalloc(int sz) { .../* determine \nwhich free list to use, based on size, see if free blocks are available */ atomic { if ((op = nextf[bucket]) \n== NULL) { morecore(bucket); if ((op = nextf[bucket]) == NULL) { return (NULL); } } /* remove from linked \nlist */ nextf[bucket] = op->ov_next; op->ov_magic = MAGIC; op->ov_index = bucket; ... } ... } Figure \n1. The main structure of the Kingsley allocator s malloc routine. by that time.) Thus, if the transaction \nnaively retries, sbrk will be called twice, leaking OS resources. The code for morecore is shown (only \nvery slightly simpli.ed) in Fig\u00adure 2. The purpose of showing this code is to demonstrate where suspending \ncall sbrk is in the program logic, as well as to show accesses to the shared data structure (rooted at \nar\u00adray nextf) which depend on the result of the sbrk, yet need to be under the surrounding atomic. Consider \nthe code reorganization required to remove sbrk from inside transactional code. This would require breaking \nmorecore in two parts, top and bottom, and moving sbrk into the body of kmalloc. Since the top and bottom \nparts of morecore need to communicate data, their interfaces need to include extra arguments (e.g., nblks, \nop). The modularity of the original code is lost: kmalloc now needs to be directly aware of the functionality \nthat used to be inside morecore. For this example, one can also envision a solution with a pair of unstructured \nbeginAtomic/endAtomic primitives, instead of a block structured atomic section. Yet this would be a very \nerror prone programming model. Furthermore, note that (unlike with locks) a programmer cannot use a block \nstructured atomic to build unstructured primitives. The TIC approach solves the problem cleanly. The \ntrans\u00adaction is committed before calling sbrk and the call to sbrk is never repeated, even if the rest \nof the transaction re\u00adtries. The potential consistency problem with suspending the transaction at the \npoint of calling sbrk is that a differ\u00adent thread can race and may happen to replenish the same bucket. \nThe original code overwrites the link to such up\u00addated entries in the bucket, as it assumes that nextf[bucket] \nis NULL. An easy rewrite of the part of morecore following the call to sbrk is enough to ensure that \nthe result of sbrk is consistently added to the data structure, even if another thread has changed the \nbucket. The new code does not as\u00adsume that the bucket is still empty after the potentially sus\u00adpending \nsbrk call. Indeed, with the rewritten code, even an static void morecore(int bucket) { register union \noverhead *op; register long sz; /* size of desired block */ long amt; /* amount to allocate */ int nblks; \n/* how many blocks we get */ sz = 1 << (bucket + 3); if (sz <= 0) return; if (sz < pagesz) { amt = pagesz; \nnblks = amt / sz; } else { amt = sz + pagesz; nblks = 1; } op = (union overhead *)sbrk(amt); /* no \nmore room! */ if ((long)op == -1) return; /* * Add new memory allocated to that on * free list for \nthis hash bucket.  */ nextf[bucket] = op; while (--nblks > 0) { op->ov_next = (union overhead *)((caddr_t)op \n+ sz); op = (union overhead *)((caddr_t)op + sz); } } Figure 2. The routine to get more system memory \ninside the Kingsley allocator. Moving the sbrk call outside the en\u00adclosing transaction (in the calling \nroutine, kmalloc) requires major code reorganization. empty establish clause is suf.cient. The result \nis correct re\u00adgardless of whether the data structure was concurrently mod\u00adi.ed by another thread: static \nvoid morecore(int bucket) { union overhead *fst = NULL; ... // as before op = expose ((union overhead \n*)sbrk(amt)); fst = op; while (--nblks > 0) { op->ov_next = (union overhead *)((caddr_t)op + sz); op \n= (union overhead *)((caddr_t)op + sz); } op->ov_next = nextf[bucket]; nextf[bucket] = fst; } Similarly, \nthe kmalloc routine is easily .xed to be unaf\u00adfected by the transaction suspension caused by sbrk inside \nmorecore.An empty establish clause would be suf.cient, but note that the suspending operation morecore \nwill cause the punctuation of any user-level transactions that happen to use kmalloc. Even though the \ndepth of transaction nesting is expected to be low in typical applications [16], we still would not want \nto impose on users the burden of handling punctuation at every level of their transactions every time \nthey call kmalloc. Instead, it is easy to supply an undo rou\u00adtine for kmalloc (a wrapper around kfree) \nso that its atomic section commits independently of any surrounding transac\u00adtions, and has its results \nreversed if the surrounding transac\u00adtion retries. The changes are shown below. undo(myKfree) void *kmalloc(int \nsz) { ... // as before expose (morecore(bucket)); ... } 3.3 Cooperating Threads The TIC ability to Wait \ninside a transaction enables thread cooperation without disrupting transactional coding pat\u00adterns. Barrier \npatterns, such as the one shown in the Intro\u00adduction are a simple case of applicability for TIC. TIC \nmakes expressing barriers easy by allowing a Wait statement to cir\u00adcumvent atomicity by exposing results, \nand to disable iso\u00adlation so that effects of other threads can be observed. This means that a barrier \ncall requires special handling in all en\u00adclosing transactions, with an expose ... establish clause. It \nshould be noted that the semantics of Wait in TIC is consistent with prior experience in re-engineering \nmulti\u00adthreaded applications. Chung et al. [16, 12] rewrote 35 lock\u00adbased applications to use transactions. \nThey note that the most reasonable simulation of condition variable waitsin the transactional world is \nto map wait to an END marker (end previous transaction) and a BEGIN marker (start new transaction) pair \n[16]. This is directly analogous to our treatment of Wait. In a different study, the same authors write: \nwe have never seen a benchmark or system that ex\u00adhibits a problem treating wait as commit [12]. Neverthe\u00adless, \nthey also note that if we treat wait as a commit, it is easy to come up with contrived programs that \nwill not match the previous semantics . The TIC ability to identify these cases and recover with an expose \n... establish clause is unique, to our knowledge. For an actual example where recovery is easy but necessary, \nFigure 3 shows two methods, rewritten in a transactional form, from the code of the Zimbra Col\u00adlaboration \nSuite. (The routines are slightly simpli.ed intermediary methods were removed, as was the code for throwing \nand handling some database exceptions.) There are two atomic sections, one in each method. Method setConnectionProvider \nhas a transaction that may be suspended at various points. There are three expose ... establish clauses \nshown in the code. Two of these are for suspending operations, such as destroy or start. One of the calls \nis to getConnection, which is a waiting method. If a connection is not available in a shared pool, the \nthread will wait until another thread returns a connection to the pool. In all cases, the transaction \nonly needs to worry about its own invariants in case of suspension. Recovery is quite easy: The public \nstatic void setConnectionProvider(ConnectionProvider provider) { atomic { if (connectionProvider != null) \n{ ConnectionProvider old = connectionProvider; expose(connectionProvider.destroy()) establish { if (connectionProvider \n!= old) return; }; } connectionProvider = provider; expose(connectionProvider.start()) establish { if \n(connectionProvider != provider) return; }; // Now, get a connection to determine meta data. Connection \ncon = null; con = expose(connectionProvider.getConnection()) establish { if (connectionProvider != provider) \nreturn; }; setMetaData(con); ... // multiple other uses of con } } public Connection getConnection() \n{ ConnectionWrapper con = null; while(true) { atomic { // if shutting down, don t create connections \nif (shutdownStarted) return null; Wait(connectionAvailable); con = getCon(); if(con != null) { con.checkedout \n= true; con.lockTime = System.currentTimeMillis(); return con; } // else someone got it before us, try \nagain } } } Figure 3. getConnection is a waiting method. Calling it requires an expose ... establish \nclause, which is quite easy to write. connectionProvider is a shared variable. routine can just return \nif any other thread has raced to over\u00adwrite the connectionProvider shared variable. 3.4 Temporary Violations \nof Atomicity Long-running operations in the middle of a transaction in\u00adcrease the probability of the \ntransaction aborting due to con\u00adtention. TIC allows a long-running computation to move to an independent \nthread and the transactions to coordinate us\u00ading Wait. In the easiest case, the long-running operation \nonly needs to signal its completion to the main transaction. TIC then also allows labeling the operation \nas suspending,in which case the transaction will commit just before perform\u00ading it and a new transaction \nwill start after it. The latter also corresponds to a common lock-based pro\u00adgramming pattern: releasing \na lock only to reacquire it after an operation. We counted at least 8 instances of this pattern for different \ntasks in AOLserver, all for long-running oper\u00adations. (AOLserver is an open-source web server, originally \nby America Online. See http://www.aolserver.com .) For in\u00adstance, AOLserver uses code of the following \nform in its in\u00adterface to the Tcl interpreter. lock(l); ... do{ ... unlock(l); ... // call Tcl interpreter \nwith script arg lock(l); } while(cond); ... unlock(l); In the TIC model, this corresponds to committing \na trans\u00adaction and starting a new one after the Tcl interpreter invo\u00adcation, without any need for establishing \nconsistency. That is, the Tcl invocation operation is labeled suspending,and called under an expose call \nwith no establish clause. 3.5 Type System Warnings In the TIC model, the type system does not guarantee \ntrans\u00adaction safety, but serves as a reminder to ensure that the pro\u00adgrammer has not overlooked waiting \nor suspending opera\u00adtions. This is often suf.cient for detecting serious function\u00adality or performance \nerrors. We encountered a representative example in our rewrite of the AlphaMail server [38], which we \nre-engineered to use transactions. AlphaMail s functionality of interest is an IMAP web cache: a middleware \nsystem that facilitates communica\u00adtion between the web server software and an IMAP server. AlphaMail \nuses a cache data structure that holds data about recently accessed IMAP data folders, including a per\u00adsistent \nconnection to the network folder. This is a C++ map<string,shared ptr<IMAPFolder> > data structure: an \nassociative map from strings to reference-counted pointers to IMAPFolder objects. A cleaning thread runs \nperiodically over the data structure to remove entries corresponding to folders not accessed recently. \nThis traversal is a standard data structure removal: atomic { ... for(i=cache_map.begin(); i!=cache_map.end(); \ni++) if(getIdleTime(i->second) > timeout) cache_map.delete(i->first); } The seemingly innocuous code \nresults in undesirable in\u00adteractions with synchronization code. The delete call re\u00admoves the item from \nthe map, and, if this was the last ref\u00aderence to the item in the program, then the shared ptr de\u00adstructor \ndeletes the IMAPFolder object itself. Irreversible op\u00aderations (network .ush and close) can then occur \nthrough a complex chain: Destroying the IMAPFolder destroys an iostream object, which destroys a streambuffer \nobject, whichshutsdowna TCPStream, which contains the offend\u00ading operations. This is a standard case \nwhere our type sys\u00adtem warns of suspending operations, similarly to other ex\u00adamples we discussed earlier. \nAlthough the operations are deeply nested, an expose ... establish clause is needed at every level to \nallow them to be used in a transaction. In\u00adterestingly, however, the above sequence was also a serious \nbug in an earlier lock-based version of AlphaMail. The code is holding a lock while the connection is \nbeing closed, which prevents concurrency during a long-running operation. In the worst case, the connection \nto the IMAP folder is experienc\u00ading network problems, making hundreds of other users hang until the network \nconnection times out. 3.6 On-Commit Operations Often we can postpone suspending operations until the \nsur\u00adrounding transaction can commit. This can be done with an on-commit operation. We consider an example \nfrom Al\u00adphaMail [38]. AlphaMail is written in C++ and is linked against a non-transactional memory allocator. \n(Although memory allocation can be built so that it integrates seam\u00adlessly with transactions [37], there \nmay be performance reasons to prefer a multithreaded allocator utilizing .ne\u00adgrained locking, e.g., [5]. \nFurthermore, there are always low\u00adlevel libraries that use their own allocation routines (e.g., OpenSSL \ns SSL CTX new/delete). It is not reasonable to ex\u00adpect a close integration for all such libraries.) The \ninterface of an application with a memory allocator is narrow, consisting only of operators new and delete \n(or malloc and free). Therefore, it is reasonable to expect that combining a transactionally implemented \napplication with a .ne-grained locking allocator should be easy. Yet, although it is relatively easy \nto write an undo routine for new (using delete) it is not similarly easy to write a satisfactory undo \nroutine for delete.(Reversing a delete is not possible even if the allocator internals are known: once \nthe object has been reclaimed, some other thread could have raced and reused the space.) delete is also \nquite hard to handle since it is a lightweight enough operation that it is likely to be used in many \ntransactions (unlike I/O operations that have high la\u00adtency and will likely need to be moved outside \nof critical sections). One of the uses of delete in AlphaMail is in a ref\u00aderence counted shared pointer \nclass. As commonly expected, the assignment operator of a shared pointer decrements the reference count \nof the object that the pointer used to point to and calls delete on it if the count is zero. It is relatively \neasy to move the call to delete outside the atomic section, by in\u00adtroducing variables to remember whether \nthe object should be deallocated and doing so later. The relevant code frag\u00adment is shown in Figure 4. \n(The code is slightly simpli.ed notably it does not include the common intrusive reference counting optimization \n[3, ch.7].) Nevertheless, this hardly .xes the problem. Shared point\u00aders are used in several places in \nthe application inside trans\u00adactions. Consider a seemingly innocuous statement such as: template<class \nT> class shared_ptr { ... public: shared_ptr<T> &#38;operator=(const shared_ptr<T> &#38;b) { bool delete_old_object \n= false; int *old_count; T *old_obj; atomic { old_count = shared_count; old_obj = obj; obj = b.obj; \nshared_count = b.shared_count; (*shared_count)++; (*old_count)--; if(*old_count == 0) delete_old_object \n= true; } if(delete_old_object) { delete old_count; delete old_obj; } } private: T *obj; int *shared_count; \n}; Figure 4. A shared pointer class that makes sure the deal\u00adlocation is performed outside the atomic \nsection, since delete is not transaction-safe. atomic { ... p= q; ... } For p of type shared ptr<int>, \nthe assignment calls shared ptr<int>::operator= which contains the call to delete. If the transaction \nretries, delete will be called twice. Fixing this problem by moving code requires destroying the encapsulation \nof the shared pointer class and moving some of its functionality outside all transactional code. Thus, \nthis is the standard problem we discussed in Section 3.1: Calling delete is a property visible to all \nclients of the operator. In this case, we can postpone the results of the delete call until the end of \nthe transaction. This is easy to do by just creating an on-commit operation for shared ptr<int>::operator=. \nThe transaction code is then free of suspending operations, but makes a record of deleted objects available \nto the on\u00adcommit operation. In the current formulation, the easiest way for the two routines to share \ndata is through arguments and return values. (In the future, one can imagine adding richer support for \nsharing data with compensating actions this is an aspect orthogonal to TIC s main features.) Thus, we \ncan make an intermediate routine release item,which operator= calls with the objects to delete as arguments. \nThe on-commit operation, free item is attached to this routine. The system stores the arguments and makes \nthem available to the on-commit operation, which performs the deletion: template<class S> oncommit(free_item<S>) \nvoid release_item(S *c) { // no-op. Transaction system records params } template<class S> void free_item(S \n*param1) { delete(param1); } The above on-commit operation does not need any con\u00adcurrency control, as \nit accesses no shared data. An important point, however, is that the on-commit operation can con\u00adtain \ntransactions, which execute open-nested in the current context. Thus, it can roll back and retry, which \nrenders sus\u00adpending operations problematic. Therefore, on-commit op\u00aderations themselves can have the \nsame need as regular code to include expose ... establish clauses, in order to re\u00adcover from transaction \npunctuation. The exact nesting model of TIC, as well as the interactions between nested transac\u00adtions, \ncompensating actions, and transaction punctuation are discussed in detail in Section 5.  4. Type System \nand Implementation Discussion We next discuss more precisely some aspects of the TIC design, as well \nas our prototype implementations. 4.1 Language Summary and Type System To summarize the previous sections, \nthe elements of the TIC programming model are: The atomic keyword to designate transactions.  The Wait \nkeyword to explicitly suspend transactions until a condition is satis.ed.  The toplevel method annotation, \nwhich makes a method unusable inside a transaction.  The expose ... establish syntax for calling waiting \nor suspending methods.  The suspending method annotation designating a root suspending method.  The \nundo and oncommit method annotations that specify compensating actions for the method and (in the case \nof undo) cause a method to commit its transactions indepen\u00addently of external nesting.  Note that many \nof these do not have run-time semantics, but only static semantics. That is, they exist purely for typ\u00ading \npurposes. They enable the type system to keep track of code that requires special handling in transactions, \nin order to remind the programmer appropriately. Overall, our type system is straightforward, as it is \npropositional: It only adds three true/false .ags to program methods. The .rst .ag de\u00adnotes waiting operations, \nthe second denotes suspending op\u00aderations, while the third denotes operations guaranteed to be unusable \ninside transactions. The .ags propagate as follows: A Wait statement sets .ag waiting for the method \nthat contains it, unless the method also has a toplevel .ag.  A suspending method annotation sets .ag \nsuspending for the method. A method with a suspending annotation can\u00adnot also have an undo annotation \nor a toplevel annotation.  A toplevel method annotation sets .ag toplevel for the method.  On a method \ncall, if the callee has a suspending .ag, the same .ag is set on the caller, unless the caller has the \ntoplevel .ag or an undo annotation.  On a method call, if the callee has a waiting .ag, the same .ag \nis set on the caller, unless the caller has the toplevel .ag.  On a method call, if the callee has the \ntoplevel .ag, the same .ag is set on the caller, unless the caller has an undo annotation.  (Note that \nwe phrased the rules as inferences with negation e.g., has ... unless the caller has... . In general \nthis might lead to ambiguity. The reader can verify that nega\u00adtion is strati.ed, however, hence we can \nget a consistent .ag assignment by letting the rules run to .xpoint.) As discussed earlier, the consequences \nof these .ags are straightforward. A method .agged toplevel cannot be used in a transaction. A method \n.agged waiting or suspending needs to be under an expose ... establish clause when used in a transaction. \nThe above rules assume a known caller-callee graph. In an object-oriented language our type system needs \nto be conservative, in order to support dynamic dispatch and an unknown set of subclasses: Overriding \nmethods are only allowed to be more broadly applicable than the methods they override. Then we need to \nintroduce an explicit method annotation waiting and some additional rules: A waiting method annotation \nsets .ag waiting for the method, unless the method also has a toplevel .ag.  A method with the suspending, \nwaiting,or toplevel .ag cannot override one without the same .ags.  A method with an undo annotation \ncannot be overridden by one without it.  Note that the last two are not propagation rules. The rules \ndo not cause the overridden/overriding method s .ag to be set. Instead they dictate that if the .ag is \nnot set under the propagation rules, the overriding is illegal. These rules are safe, but restrictive. \nE.g., they force every client of an interface method to make a call under an expose ... establish if \neven one implementation of the method is suspending. 4.2 TIC Prototypes We described our language extensions \nin an idealized setting (as new keywords with full language support). As is stan\u00addard practice, however, \nwe approximate these features with simpler extensions that offer an easier transition path from existing \nlanguages. Our original prototype was a back-end C library, based on Harris and Fraser s libstm back-end \nlibrary [28] a fully optimistic concurrency implementation, with read and write logging. Our changes \nto the library implement the main back-end features of TIC namely, the full contin\u00aduation support, explained \nnext, and the TIC nesting model (including open nesting support) described in Section 5. The libstm implementation \ngave us a way to evaluate a proto\u00adtype quickly. Nevertheless, it was not ideal for practical use, mainly \nbecause of its lazy validation policy: Since the library does not detect inconsistent data reads until \nexplicit valida\u00adtion time, client programs needed to be hardened in multiple ways (typically using signal \nhandlers, but also by ensuring no in.nite loops occur) to avoid anomalies from reading in\u00advalid data. \nFor a more practical library, our current working prototype is based on TL2 [17]: an optimistic concurrency \nimplementation with eager read validation. To experiment with our library in actual applications, we \ncreated a C++ wrapper library, containing macros (for atomic, expose, establish), and a set of classes \nto support threads, semi-automatic nesting, and compensating actions. The user still needs to carefully \nensure that the desired mem\u00adory actions are performed through the transaction system, but the C++ wrapper \noffers rudimentary syntactic sugar and safety checks. (As for other C libraries, the biggest challenge \nfor seamless use in C++ is that the user needs to explicitly compensate for the implicit semantics of \nC++ operations e.g., destructors that are not preserved by our runtime ma\u00adnipulations.) We have not yet \ncreated a mature implementa\u00adtion for Java (currently the user needs to directly call the C back-end) \nbut it is straightforward to employ the standard ap\u00adproach of Java 5 method-level annotations [22, section \n9.7] for syntax extension and bytecode transformation for adding semantics, without needing to change \nthe source compiler. Our propositional type system easily translates to existing constructs in the Java \ntype system (e.g., require an expose ... establish clause through Java s static check for excep\u00adtion \ncatching). The recent literature is rich with mechanisms applicable in our context for translating transactional \nexten\u00adsions down to regular Java [1, 30, 31, 34, 40, 46]. There\u00adfore, this aspect of the implementation \nis well-understood, and we concentrate next on elements unique to TIC that are currently captured by \nour back-end library. 4.3 Implementation Discussion The TIC model has slightly higher implementation \nrequire\u00adments than a standard transactional programming model. This is due to the need for full continuations \nwhen a transac\u00adtion needs to retry after it is suspended. Consider our earlier example of kmalloc with \nan atomic section that contains a call to morecore, which contains a suspending operation. undo(myKfree) \nvoid *kmalloc(int sz) { ... atomic {... expose(morecore(bucket));...} ... } void morecore(int bucket) \n{ register union overhead *op; register long sz; /* size of desired block */ long amt; /* amount to allocate \n*/ int nblks; /* how many blocks we get */ union overhead *fst = NULL; ... op = expose ((union overhead \n*)sbrk(amt)); ... } Just before the call to sbrk, the transaction consisting of all program actions from \nthe beginning of the atomic block up until the sbrk statement commits. A new transac\u00adtion is started, \nimmediately after the call. If that new trans\u00adaction encounters contention and needs to retry, its starting \npoint is immediately after the sbrk call even though func\u00adtion morecore has returned. This means that \nthe transaction system needs to have captured the full continuation corre\u00adsponding to the state right \nafter the sbrk call. This should in\u00adclude the state of stack variables, such as sz, bucket, op,etc. (We \nassume a conventional stack/heap state split, although clearly a runtime system may choose any alternative \nimple\u00admentation.) The requirement for full continuations is only a modest increase from the bookkeeping \nrequired in standard (non\u00adpunctuating) transactional models. The heap portion of a program s state, as \nwell as the state of the topmost stack frame, need to be tracked by conventional transaction mech\u00adanisms \nanyway. For instance, consider the above routine kmalloc with a standard block-structured atomic section. \nOn a transaction retry, the implementation still needs to be able to restore the stack state of kmalloc \nas of the beginning of the atomic block. However, a conventional implementation does not need to track \nthe stack state of suspending methods called by kmalloc. This modest cost of creating and using full \ncontinuations is actually incurred rarely. Full continuations are needed only in atomic sections that \nhave an expose clause or a Wait operation, and only if transaction suspension actually occurs that is, \nif the condition of the Wait operation is false, or an innermost suspending operation is indeed exe\u00adcuted. \nOur implementation relies on the existing TL2 mecha\u00adnisms for handling con.icts when concurrent atomic \nsec\u00adtions access global or heap data and to discover when a trans\u00adaction needs to be aborted. Changes \nwere necessary only to handle saving and restoring local state (i.e., registers and stack frames) when \na transaction commences and aborts, re\u00adspectively. Our implementation speci.cs (modulo open-nesting, \nde\u00adscribed in the next section) are fairly straightforward. Read and write operations to global and heap \nlocations are imple\u00admented with calls to the underlying library s word-level read and write primitives. \nEntry to and exit from an outermost atomic section results in the beginning and attempt to com\u00admit, respectively, \nof a TL2 transaction. Innermost (i.e., root) suspending operations attempt to commit the transaction. \nIf the transaction successfully commits, the suspending oper\u00adation is executed and a new transaction \nbegins immediately after it. In case of a Wait,we .rst test the Wait condition and attempt to commit \nthe transaction if it is false. The new transaction begins with an evaluation of the Wait condition. \nWe had to enhance the base TL2 library to include a block\u00ading primitive, which was modeled after STMWait \nin libstm. When a con.ict is discovered, the commit operation can\u00adnot complete, and the current transaction \nmust be rolled back to its initial state. The base library takes care of restoring global variables and \nheap data; to restore the state of any lo\u00adcal variables and the program counter we use our own imple\u00admentation \nof continuations. This is architecture speci.c, but straightforward, as we are not concerned with heap \nspace. The implementation saves continuations when transactions are punctuated (via the expose and establish \nmacros). The management of continuations is handled behind the scenes by calling semi-portable routines, \nsuch as memcpy (to copy the stack), setjmp,and longjmp. As discussed, continuations are created only \nwhen a Wait statement is reached and its condition is false or a call is made to a root suspending op\u00aderation. \nOur measurements show that the cost of saving/restoring full continuations is modest, and becomes negligible \nif one considers how rarely it is incurred (only on actual suspen\u00adsion). For our kmalloc example, we \nmeasured a cost of 230 cycles for saving the registers and stack frames for a full con\u00adtinuation (all \nnumbers are for single-threaded execution on a 2.16GHz Intel Core 2 Duo and report the median of seven \nruns, each averaged over 30,000+ iterations). However, the overhead of setjmp is already incurred by \nTL2 on all trans\u00adactions as part of setup for possible transaction retries. This means that the cost \nof a continuation is reduced to the cost of a memcpy for the current thread s active stack frames. For \nexample, a transaction containing no function calls and two writes takes 900 cycles. The same code with \nthe transaction punctuated between the two writes takes 1650 cycles, which is almost identical to two \nseparate single-write transactions at 1640 cycles.  5. Nesting in TIC We next discuss topics concerning \nTIC and transaction nest\u00ading. We .rst examine the relationship of TIC to the idea of open-nesting in \ngeneral. Then, we describe in more detail the TIC nesting model. We also discuss the safe use of open\u00adnesting \ntransactional systems in general, and interesting in\u00adteractions of transaction punctuation with open-nesting. \n5.1 Relation to Open-Nesting The main feature of the TIC model is transaction punctuation through waiting \nor suspending operations. Nevertheless, TIC also integrates open-nesting features, such as open transac\u00adtions \nand compensating (undo and on-commit) actions. It is interesting, therefore, to ask how TIC compares \nwith open\u00adnested programming models. The answer is twofold: TIC has distinctly different goals than open \nnesting: Rather than addressing scalability and performance con\u00adcerns, TIC aims to support thread communication \nand irre\u00adversible operations, while maintaining the high-level prop\u00aderties of transactions. Nevertheless, \nTIC can sometimes be used to address performance concerns, as an alternative to open-nesting. Consider \nthe example of a fairly independent but long-running operation that needs to be executed in the middle \nof a transaction. (We saw such examples in Sec\u00adtion 3.4.) Open-nesting allows long-running operations \nto commit independently, in an open transaction. TIC allows them to move to a different thread and have \nthe two threads coordinate using Wait statements. Alternatively, TIC al\u00adlows the programmer to label \nthe long-running operation with a suspending annotation, which punctuates the main transaction and returns \nto it on completion. In principle, open-nesting could also be used for some of the main TIC tasks of \nthread communication and irre\u00adversible operations. Yet open-nesting offers a lower-level programming \nmodel, delegating to the user the responsibil\u00adity for establishing higher level properties using (regular \nor abstract) locks [13, 45].4 Without user intervention, the de\u00adfault semantic guarantees of open-nesting \nare much weaker than those of TIC. Agrawal et al. [2] offer examples where open-nesting violates fundamental \nproperties of transac\u00adtional memory, such as serializability and composability. The difference between \nTIC and open-nesting is not in the violation of serializability, however. Transaction punctu\u00adation also \nviolates serializability for a punctuated atomic section as a whole, guaranteeing instead serializability \nfor individual transaction parts. The difference is that open\u00adnesting also violates program order (i.e., \nthe logical or\u00adder of operations in a single thread). For instance, when an open-nested transaction commits \nmemory changes, the preceding changes in parent transaction data remain un\u00adcommitted. In this way, the \neffects of an open-nested trans\u00adaction may appear to take place before parent transaction 4 Note that, \noriginally, in the database setting, the term open-nested referred to the anarchic version of multi-level \ntransactions [23], which have no semantic restrictions between parent and child transactions (i.e., no \nseman\u00adtic locking). Some authors follow this distinction in the transactional mem\u00adory literature [13] \nbut most, like us, use the term to include the possibility of locks for expressing high-level constraints \n[44, 45, 46]. actions that caused the open-nested transaction s execu\u00adtion. Additionally, with open-nesting \nthere is no guarantee (again, without explicit user intervention) that compos\u00ading individually atomic \noperations in a single atomic sec\u00adtion will yield an atomic operation. The excellent Agrawal et al. example \n[2] is illustrative: An open-nested transac\u00adtion can be checking some shared memory location, m, and \nstoring the result in a local variable, c, thus affecting the control (or data) .ow of its parent transaction. \nNev\u00adertheless, the transactional system is not aware that c is invalidated when m s contents change. \nThe problem af\u00adfects all (closed-nested) transactions that contain the open\u00adnested one, making the operation \ncontaining the open\u00adnested transaction non-composable with others. TIC punc\u00adtuation raises similar issues, \nbut, unlike in open-nesting, the programmer does not need to look inside the composed operations to determine \nthat they may cause violations of atomicity: The type system warns when this is the case and requires \nthe user to supply expose...establish clauses. In a sense, open-nesting punctures a transaction instead \nof punctuating it. Open-nesting exposes results both to and from the parent transaction, which can violate \nisolation and atomicity, respectively. We believe that a disciplined ap\u00adproach calls for transaction \npunctuation when this occurs. Nevertheless, this forces on the user the obligation to write correct expose...establish \nclauses at every nesting level. This may be undesirable, even though each level s reason\u00ading is local \n(i.e., deals only with that level s invariants). There are elements that TIC just inherits from open\u00adnesting \nmodels, since the main TIC feature (punctuation) is largely orthogonal to open-nesting. We pro.tably \nused TIC open-nesting features in our examples to stop propagation of the need for expose ... establish \nclauses in caller methods. This is the main use of open-nesting in TIC: When an externally visible operation \ncan be reversed (with an undo action, possibly combined with an on-commit ac\u00adtion to postpone some effects) \nthe operation can be safely used in transactions without punctuating them and forcing the programmer \nto re-establish invariants. (For this to be valid, the possibility of other threads observing the exter\u00adnal \neffects should not affect application-level correctness, as discussed in Section 2. This is a strict \ncondition, which could be relaxed by adding locks to the model to let the user prevent operations that \nmight con.ict.) We believe that this is a modest, but desirable, use of open-nesting, which is well-aligned \nwith the principles of correct open\u00adnesting usage [45]: The open-nested transaction is at a sep\u00adarate, \nlower level of abstraction than its parent transaction. The TIC open-nesting model is currently limited. \nFor in\u00adstance, our set of compensating actions only contains on\u00adabort (i.e., undo), and on-commit actions. \nMore handlers (on-validate, on-top-commit) may offer extra power to open-nesting models, especially in \nconjunction with lock\u00ading support (which brings out the need to distinguish val\u00adidation from commitment) \nand with more advanced data sharing between forward and compensating actions. We have not found the current \nlimitations to be seriously con\u00adstraining, since transaction punctuation can replace many uses of open-nesting. \nIn the future, the TIC open-nesting features can be enriched without affecting the main ele\u00adments of \nthe model. 5.2 The TIC Nesting Model We next describe more precisely the current TIC nesting se\u00admantics. \nThis allows us to answer questions such as what is the execution context and concurrency model of an \nundo operation? and what happens when a suspending operation occurs inside an open-nested transaction? \nThis also exposes in more detail the current open-nesting support of TIC. We believe that this behavior \ncan largely be tuned without affect\u00ading the main features of the model, but the current speci.ca\u00adtion \n.ts well with our notion of correct open-nesting usage, as we will demonstrate. We make an effort to \ndistinguish the description of the nesting behavior from our current imple\u00admentation, so we avoid referring \nto implementation artifacts (e.g., locks or read/write logs) except when explicitly com\u00adparing implementation \ntechniques. Let us .rst de.ne how language constructs affect open\u00ador closed-nesting. There are two kinds \nof relevant scoping language constructs, which nest dynamically. The .rst is methods with an undo annotation, \nas well as undo and on\u00adcommit actions themselves we call their scope an open context. The second is atomic \nsections and root suspending operations an atomic context. That is, we treat transactions inside an undo \nor on-commit action as open-nested (as Ni et al. [46] do), and we treat root suspending operations as \nif designating a separate transaction for the purposes of nesting behavior. The behavior of the system \nin each context is determined by the contexts surrounding it in dynamic scope: we process contexts from \nouter to inner, or caller to callee. The rules are simple: (We write context1 + context2 to mean that \nthe rule applies for code whose immediate context is context2 when context2 is dynamically nested directly \ninside context1 with no other context between.) atomic + atomic : The inner atomic section is closed\u00adnested \n(more precisely, .at-nested [2]) in the outer one, forming a single transaction, for all intents.  atomic \n+ open : The code in the open context is out\u00adside the control of the transactional system. (If such code \nneeds concurrency control, it should contain atomic sec\u00adtions, thus creating an atomic context.) The \nparent transac\u00adtional context is recorded for possible later use. If the open context is a method with \nan undo annotation, the undo ac\u00adtion is registered at the method s point of invocation. The action is \nnot enabled, however. (It will not be unless the method includes an atomic context.)  open + open : \nNo change. Code in the inner context re\u00admains non-transactional, the recorded parent transactional context \nremains the same. open + atomic : The atomic section starts a new transac\u00adtion, open-nested in the current \nparent transactional con\u00adtext. If the open context corresponds to a method with an undo annotation, the \nundo action at the point of method call return is enabled for execution during the parent trans\u00adaction \nroll-back process. Most of our treatment of open-nesting and compensat\u00ading actions follows standard conventions. \nE.g., undo actions are called in the reverse order they are registered, an outer undo action prevents \ninner ones from being executed, etc. For issues of read-write and write-write con.icts between an open-nested \ntransaction and its parent, we follow an ap\u00adproach similar to Ni et al. [46] (e.g., updating the parent \ns log). Nevertheless, some elements require clari.cation or are unconventional. These are listed next: \n Transaction punctuation affects only the current real transaction i.e., all atomic sections up to the \ninnermost open-nesting boundary, or up to the top-level atomic sec\u00adtion (if no open-nesting has taken \nplace). This is also con\u00adsistent with our type system de.nitions of Section 4.  All open-nested transactions \nroll back to their beginning point and never cause the parent transaction to abort. Re\u00adcall that, per \nour previous de.nitions, open-nested transac\u00adtions are started at the top-level atomic section of a method \nwith an undo operation, as well as a method that is itself called as an undo or on-commit action.  Open-nested \ntransactions can see the local (i.e., non\u00adshared memory) effects of their parent transaction, as well \nas a consistent view of shared memory. This permits mul\u00adtiple implementations: A consistent view of shared \nmem\u00adory can be the current committed state, or the state that would result if the parent transaction \nwere to commit at this point in case, of course, its actions are still valid. (An ex\u00adplicit validation \ncall is required for an implementation with lazy validation.)  To see the rationale for the above behavior, \nwe next con\u00adsider some examples. It is a general requirement in open-nested transactions that on-abort \nactions (i.e., our undo operations) should be able to abort and commit independently (i.e., restart from \ntheir beginning when retrying, instead of restarting the par\u00adent transaction). The requirement comes \nfrom the use of undo operations: it makes no sense for an undo to cause a parent abort, since it was \nthe parent abort that necessitated the undo in the .rst place. In TIC, it is natural to extend the above \nrequirement from just undo actions to all kinds of open-nested transactions be\u00adcause of the possibility \nof transaction punctuation. Consider the following example: (We try to keep the examples concise by using \npseudo-keywords. We use openatomic in place of a separate method with an undo annotation and an atomic \nsection in it, and undo for an undo method with an atomic section in it.) atomic { ... openatomic { ... \np = expose(sbrk()); ... } undo { ... } } The top part of the open-nested transaction can commit independently \nat the point of suspension (call to sbrk used just as an example of a suspending operation). If, however, \nthe bottom part of the open-nested transaction (i.e., after the sbrk) needs to abort and retry, it cannot \nrestart at the top of its parent transaction (since this would repeat the top part of the open-nested \ntransaction, as well, and the suspending operation has already committed its results to memory). Instead, \nthe punctuated open-nested transaction commits and aborts independently of its parent. As stated above, \nopen-nested transactions see a consis\u00adtent view of shared memory (i.e., cannot see partial trans\u00adaction \nresults, unless these come from the parent transac\u00adtion and have not been invalidated). Typical implementa\u00adtions \nof open-nesting are pessimistic/lock-based with undo logging: Information is kept to allow undoing shared \nmem\u00adory effects. In this case, shared memory already re.ects the uncommitted effects of the parent transaction, \nso it is rea\u00adsonable for the open-nested transaction to access them. An optimistic implementation, however, \nwill typically store the parent transaction s effects in a log until the parent commits (redo logging). \nIn this case, it may not be reasonable to al\u00adlow the open-nested transaction to see the uncommitted ef\u00adfects \nof its parent. For instance, in the case of an undo oper\u00adation, the parent transaction s state is not \na valid state. (The undo operation is called exactly because the parent transac\u00adtion encountered interference \nand aborted after performing operations that may be invalid.) Furthermore, the possibility of exposing \nstate that only exists in the parent s log makes the programming model awkward. Consider the following \nexample: (Interestingly, a very similar example was shown independently in [44].) // n originally 0 atomic \n{ n=1; openatomic { n++; } undo { n--; } ... } The decrement operation is not a correct undo action for \nthe increment. Incrementing the shared memory variable inadvertently exposes the effects of the parent \ntransaction. A correct undo requires reverting to the original value of the variable. This is not possible \nunless we expose to the user a richer set of values than just the parent transaction s view of a variable. \n(Other alternatives include enabling the above code to execute correctly by causing cascading aborts \nfor all transactions that happen to read exposed data. This is complex and suffers from heavy overheads, \nhowever.) To circumvent the above problems, in our optimistic im\u00adplementation we do not allow an open-nested \ntransaction to observe the uncommitted shared memory effects of its par\u00adent transaction. Instead, the \nopen-nested transaction only ob\u00adserves the latest committed values to shared memory. This is somewhat \ncounter-intuitive, but in line with correct use of open-nesting. Moravan et al. [44] proposed the follow\u00ading \ndiscipline condition for open-nested transactions: An open-nested transaction should not write any data \nwritten by the parent transaction. Indeed, we believe that the condition should be even stronger: An \nopen-nested transaction should never perform a write that is (control-or data-)dependent on shared data \nwritten by its parent transaction. Without the stronger condition, it is easy to violate global invari\u00adants \n(that depend only on shared data, and which all trans\u00adactions would respect if they were isolated) by \nhaving an open-nested transaction expose uncommitted state. (With the stronger condition, an open-nested \ntransaction can inadver\u00adtently only violate invariants that involve both global and local data.) An easy \nway for the programmer to ensure the condition is to not allow an open-nested transaction to ac\u00adcess \nany shared data written by the parent. In this case, our requirement for a consistent view of shared \nmemory in an open-nested transaction is suf.cient to make the code obliv\u00adious to implementation speci.cs, \nsuch as whether the parent transaction s uncommitted writes are visible. The above principle also covers \nwell our intended use of open-nesting in TIC: We employ open-nesting to hide op\u00aderations that are reversible \nat the application level. For an operation to be reversible, it should not be exposing its par\u00adent transaction \ns data to other threads (which is a potentially irreversible effect) in a way that affects application \ncorrect\u00adness. Thus, it is a good property for an open-nested trans\u00adaction to never access shared data \nfrom its parent. This fol\u00adlows the conventional wisdom about strict abstraction sep\u00adaration of open-nested \nactions: Quoting Moss [45], in the open nesting case the parent and child execute at different levels \nof abstraction. Our kmalloc example of Section 3 is exactly such a case.  6. Related Work Modularity \nis a central recurring theme in the development of models and mechanisms for concurrent programming, \nfrom supplanting raw semaphores with conditional critical regions [35] and then monitors [36], through \nre.nement of monitor and condition variable semantics to reduce the fragility of process coordination \n[39], through introduction of the transaction concept [21] to decouple maintenance of consistency from \nde.nition of individual data structures, up to more recent work on programming language support for transactions. \nThe TIC model draws inspiration and ideas from several earlier models, both transactional and monitor-based. \nThe programmer requirement to reestablish the global invariant just before Wait() and to reestablish \nlocal invariants just af\u00adter follows directly from the correctness reasoning already established in the \nearliest de.nitions of monitors [36]. Our approach to transaction suspension is somewhat analogous to \nmechanisms that punctuate atomicity in monitors in a con\u00adtrolled way (e.g., serializers [4]). Punctuated \ntransactions are also somewhat analogous to chain transactions in database systems [23] and their variants \nfor persistent programming [7] and work.ow systems [48], but after the .rst part of a punctuated transaction \ncommits at expose, it is independent of subsequent parts, exposes its results, and can never be rolled \nback. Our type system handling of suspending opera\u00adtions is close to conventions for monads in Haskell, \nand the Haskell type system has been used before for the purpose of identifying non-transactional operations \n[29]. Herlihy and Moss proposed transactional memory sys\u00adtems more than a decade ago [32], and design \nof hardware support has accelerated in response to the widespread avail\u00adability of multi-core computer \nhardware. Several hardware transactional memory projects, including logTM [43], TCC [26, 12, 42] and \nothers [32, 47, 15, 49, 8, 51] are explor\u00ading the design space for hardware support for transactional \nmemory. Proposals vary regarding whether con.icts are de\u00adtected eagerly or lazily, whether changes are \nmade directly to memory (with old values stored elsewhere in case a trans\u00adaction is aborted) or written \nonly when committing (making abort cheap but commit more expensive), how external or non-transactional \nactions are treated (e.g., whether and how to support open nesting), etc. In principle, a programming \nmodel should hide from the programmer whether the un\u00adderlying mechanisms are partly or wholly implemented \nin hardware, as well as operational details of the implementa\u00adtion. In practice, it is unlikely that \na programming model can entirely hide these design choices, at least insofar as they im\u00adpact cost. A \nkey and troublesome interaction between a high-level program model and the underlying implementation \ninvolves interaction of transactions with memory accesses outside transactions. Strong atomicity, as \nde.ned by Blundell et al. [9], essentially treats otherwise unguarded accesses as small transactions. \nMost implementations, however, can be ex\u00adpected to provide only some form of weak atomicity,which (like \nmemory models weaker than sequential consistency) opens a plethora of dif.cult questions, right down \nto interac\u00adtions between high-level transactions and the memory model governing individual accesses. \nGrossman et al. [25] present a classi.cation and examples of isolation and ordering anoma\u00adlies that may \nor may not be allowed under varying weak atomicity models, and provide the beginnings of an approach \nto reasoning about weak atomicity and memory models with (weak and strong) happens-before relations. \nTIC inherits a weak atomicity model from the underlying libstm and TL2 libraries [28, 17], and so can \nbehave in un\u00adintuitive ways if shared variables are accessed outside trans\u00adactions. Despite recent reports \nof achieving strong atomicity at modest cost, through extensive optimization [50], our ex\u00adpectation is \nthat (as in memory consistency models) perfor\u00admance considerations will continue to make weaker atom\u00adicity \nguarantees a practical necessity. The basic Wait and establish features of TIC should not introduce complica\u00adtions \nbeyond those of other closed nesting transaction sys\u00adtems, except that Wait is only guaranteed to notice \ncondi\u00adtions changed by transactions. suspending methods, on the other hand, could be subject to ordering \nanomalies described by Shpeisman et al. [50] and require special scrutiny. Nearly all STM proposals require \nsome form of transac\u00adtion roll-back, either abandoning a temporary, thread-local record of memory writes \n(where con.ict detection is per\u00adformed lazily, at commitment time), or else undoing the ef\u00adfects of writes \nto memory. Schemes that use write locks but not read locks must re-validate reads before committing, \nand may be forced to roll back memory effects. Schemes that use both write and read locks (as in strict \n2-phase locking) may be forced to roll back by deadlock [20]. All such ap\u00adproaches face the basic problem \nof data dependencies with I/O (read-after-write) [24]. The only approaches that can avoid this problem \nare purely pessimistic approaches that also statically prevent deadlock, rather than dynamically de\u00adtect \nit [41, 19, 33], but these require complex program analy\u00adsis which is apt to be non-modular (hence expensive) \nor else rely on extensive program annotation. The safe (but some\u00adtimes inconvenient) way to perform I/O \nin TIC is with punc\u00adtuated transactions, but the back door of open nesting is ajar, with the usual risks. \nHarris has described an approach to external operations with effects directly to the heap but isolated \nfrom other trans\u00adactions, and using two-phase commit and buffering to ob\u00adtain transactional behavior \nfor I/O [27]. Unlike either open nested transactions or TIC, Harris s approach does not ex\u00adpose intermediate \nstate. On the other hand, in addition to requiring a good deal more machinery to properly wrap and protect \nexternal operations, this approach is not suf.cient for read-after-write idioms, or for complex external \noperations that both mutate state and return a value. Consider an op\u00aderation like sbrk in the example \nwe saw in Section 3. sbrk returns a value that the application needs to use, yet performs a state change \nin the process. Thus, it can neither be delayed (due to the read) nor replayed (due to the state change). \nEven if the interface of sbrk is changed to be idempotent (e.g., by adding a version number), the problem \nremains: A transac\u00adtion that retries might not call sbrk the second time, and no other transaction might \nbe able to consume that memory. Chung and colleagues study of common patterns in cur\u00adrent (locking-based) \nprograms [16] shows that, if we sim\u00adply translate current code to transactions, the average nest\u00ading \ndepth is modest and non-transactional operations are not common. It remains to be seen whether these \ndistributions hold when programmers can use transactions directly, and one may surmise that, as hierarchical \ncomposition is one of the chief motivations for adopting a transactional style of programming, typical \nnesting depth could increase in pro\u00adgrams written directly in that form. At the very least, though, Chung \ns results imply that measures taken to accommodate waiting and external effects in nested transactions \nmust not have a substantial cost for the (so far) common case of trans\u00adactions that are only shallowly \nnested and affect only mem\u00adory. Checkpoints have an interesting relation to transaction roll-back. The \npurpose of both is to return a system to a glob\u00adally consistent state. Checkpointing does this by either \nmain\u00adtaining a global snapshot, or retaining a set of local snapshots that form a consistent cut representing \na state that the sys\u00adtem could have reached (even if the local snapshots were never current at precisely \nthe same time) [14, 18]. Recent work developing transparent checkpoint facilities for Con\u00adcurrent ML \n[53] is an example of maintaining enough de\u00adpendence information to roll back several interacting threads \nto a consistent state; this is what in database terms would be called cascading abort. In contrast, all \nSTM systems to our knowledge are designed to make cascading abort unneces\u00adsary. For example, systems \nthat use write locks but not read locks may need to roll back if validation at commit time re\u00adveals stale \nread values, but the write locks (which permit anti-dependence but not dependence between uncommitted \ntransactions) ensure that memory writes can be backed out without aborting other transactions. Recall \nthat in TIC our establish statements are only for reestablishing local con\u00adsistency; global consistency \nis established before expose. 7. Conclusions A key goal of transactional programming is to avoid or \nminimize non-local reasoning about thread interactions. To achieve this goal, it is essential that transactions \nare compo\u00adsitional in the sense that the decision to make one method transactional does not require looking \ninside other meth\u00adods to determine whether they are also transactional. At the same time, transaction \nsupport must be suf.ciently general that common operations can be enclosed in transactions. For standard \nimperative programming patterns, external opera\u00adtions such as I/O cannot be poison pills that prevent \nusing transactions in the whole tree of calling methods. This cre\u00adates a tension between isolation (to \nsimplify reasoning) and communication (to get work done). The TIC model mostly retains the closed nesting \nmodel of transactions, with a small number of careful extensions to better accommodate com\u00admon programming \nidioms like barriers and conditional wait\u00ading as well as other operations that break the standard closed \nnesting semantics. While the TIC model necessarily punctuates transactions, sacri.cing isolation for \ncommunication at controlled points, the type system prevents unanticipated interaction between threads \nby making the possibility of suspension visible in method signatures, and by requiring the programmer \nto ac\u00adknowledge the potential interruption at the point of the method call. We have reengineered substantial \nexisting lock-based programs to use the TIC model, con.rming that it meets our goal of providing a more \ngeneral, convenient programming model while preserving the main bene.ts of transactional memory.  Acknowledgments \nThis work was funded by the NSF under grant CCR\u00ad0735267 and by LogicBlox Inc. Earlier discussions with \nTony Hannan on transactional memory and LihChyun Shu on concurrency control helped form the background \nof this paper. We would like to thank the anonymous reviewers for many valuable comments that helped \nimprove the paper. References [1] Ali-Reza Adl-Tabatabai, Brian T. Lewis, Vijay Menon, Brian R. Murphy, \nBratin Saha, and Tatiana Shpeisman. Com\u00adpiler and runtime support for ef.cient software transactional \nmemory. In PLDI 06: Proceedings of the 2006 ACM SIG-PLAN conference on Programming language design and \nim\u00adplementation, pages 26 37, Ottawa, Ontario, Canada, 2006. ACM Press. [2] Kunal Agrawal, Charles E. \nLeiserson, and Jim Sukha. Memory models for open-nested transactions. In MSPC 06: Proceedings of the \n2006 workshop on Memory system performance and correctness, pages 70 81, San Jose, California, 2006. \nACM Press. [3] Andrei Alexandrescu. Modern C++ Design. Addison-Wesley, 2001. [4] Russell Atkinson and \nCarl Hewitt. Synchronization in ac\u00adtor systems. In POPL 77: Proceedings of the 4th ACM SIGACT-SIGPLAN \nSymposium on Principles of Program\u00adming Languages, pages 267 280, Los Angeles, California, 1977. ACM \nPress. [5] Emery D. Berger, Kathryn S. McKinley, Robert D. Blumofe, and Paul R. Wilson. Hoard: A scalable \nmemory allocator for multithreaded applications. In International Conference on Architectural Support \nfor Programming Languages and Operating Systems (ASPLOS-IX), pages 117 128, Cambridge, MA, November 2000. \n[6] Emery D. Berger, Benjamin G. Zorn, and Kathryn S. McKinley. Composing high-performance memory allocators. \nIn SIGPLAN Conference on Programming Language Design and Implementation (PLDI), pages 114 124, 2001. \n[7] Stephen Blackburn and John N. Zigman. Concurrency -the .y in the ointment? In Proceedings of the \n8th International Workshop on Persistent Object Systems (POS8) and Proceedings of the 3rd International \nWorkshop on Persistence and Java (PJW3), pages 250 258, San Francisco, CA, USA, 1999. Morgan Kaufmann \nPublishers Inc. [8] Colin Blundell, Joe Devietti, E. Christopher Lewis, and Milo M. K. Martin. Making \nthe fast case common and the uncommon case simple in unbounded transactional memory. In ISCA 07: Proceedings \nof the 34th Annual International Symposium on Computer architecture, pages 24 34, San Diego, California, \nUSA, 2007. ACM Press. [9] Colin Blundell, E. Christopher Lewis, and Milo M. Martin. Subtleties of transactional \nmemory atomicity semantics. IEEE Comput. Archit. Lett., 5(2):17, 2006. [10] Colin Blundell, E Christopher \nLewis, and Milo M. K. Martin. Unrestricted transactional memory: Supporting I/O and system calls within \ntransactions. Technical Report CIS\u00ad06-09, Department of Computer and Information Science, University \nof Pennsylvania, Apr 2006. [11] Brian D. Carlstrom, JaeWoong Chung, Hassan Cha., Austen McDonald, Chi \nCao Minh, Lance Hammond, Christos Kozyrakis, and Kunle and Olukotun. Transactional execution of java \nprograms. In OOPSLA 2005 Workshop on Synchronization and Concurrency in Object-Oriented Languages (SCOOL). \nOct 2005. [12] Brian D. Carlstrom, JaeWoong Chung, Hassan Cha., Austen McDonald, Chi Cao Minh, Lance \nHammond, Christos Kozyrakis, and Kunle Olukotun. Executing Java programs with transactional memory. Science \nof Computer Programming, 63:111 129, 2006. [13] Brian D. Carlstrom, Austen McDonald, Michael Carbin, \nChristos Kozyrakis, and Kunle Olukotun. Transactional collection classes. In PPoPP 07: Proceedings of \nthe 12th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pages 56 67, San Jose, \nCalifornia, USA, 2007. ACM Press. [14] K. Mani Chandy and Leslie Lamport. Distributed snapshots: determining \nglobal states of distributed systems. ACM Trans. Comput. Syst., 3(1):63 75, 1985. [15] Weihaw Chuang, \nSatish Narayanasamy, Ganesh Venkatesh, Jack Sampson, Michael Van Biesbrouck, Gilles Pokam, Brad Calder, \nand Osvaldo Colavin. Unbounded page-based transactional memory. In ASPLOS-XII: Proceedings of the 12th \nInternational conference on Architectural support for programming languages and operating systems, pages \n347 358, San Jose, California, USA, 2006. ACM Press. [16] JaeWoong Chung, Hassan Cha., Chi Cao Minh, \nAusten McDonald, Brian D. Carlstrom, Christos Kozyrakis, and Kunle Olukotun. The common case transactional \nbehavior of multithreaded programs. In Proceedings of the Twelfth International Symposium on High-Performance \nComputer Architecture. Feb 2006. [17] David Dice, Ori Shalev, and Nir Shavit. Transactional locking II. \nIn Shlomi Dolev, editor, Distributed Computing, 20th International Symposium (DISC), volume 4167 of Lecture \n Notes in Computer Science. Springer, 2006. [18] E. N. (Mootaz) Elnozahy, Lorenzo Alvisi, Yi-Min Wang, \nand David B. Johnson. A survey of rollback-recovery protocols in message-passing systems. ACM Comput. \nSurv., 34(3):375 408, 2002. [19] Michael Emmi, Jeffrey S. Fischer, Ranjit Jhala, and Rupak Majumdar. \nLock allocation. In POPL 07: Symposium on Principles of Programming Languages, pages 291 296. ACM Press, \n2007. [20] Robert Ennals. Software transactional memory should not be lock free. Technical Report IRC-TR-06-052, \nIntel Research Cambridge, 2006. Available from http://berkeley. intel-research.net/rennals/. [21] Kapali \nP. Eswaran, Jim N. Gray, Raymond A. Lorie, and Irving L. Traiger. The notions of consistency and predicate \nlocks in a database system. Commun. ACM, 19(11):624 633, 1976. [22] James Gosling, Bill Joy, Guy Steele, \nand Gilad Bracha. The Java Language Speci.cation, Third Edition. Prentice Hall, 2005. [23] Jim Gray and \nAndreas Reuter. Transaction Processing: Concepts and Techniques. Morgan Kaufmann Publishers Inc., San \nFrancisco, CA, USA, 1992. [24] Dan Grossman. The transactional memory / garbage collection analogy. In \nACM Conference on Object-Oriented Programming Systems, Languages, and Applications, Essays Track. ACM \nSIGPLAN, October 2007. [25] Dan Grossman, Jeremy Manson, and William Pugh. What do high-level memory \nmodels mean for transactions? In MSPC 06: Proceedings of the 2006 workshop on Memory system performance \nand correctness, pages 62 69, San Jose, California, 2006. ACM Press. [26] Lance Hammond, Vicky Wong, \nMike Chen, Brian D. Carlstrom, John D. Davis, Ben Hertzberg, Manohar K. Prabhu, Honggo Wijaya, Christos \nKozyrakis, and Kunle Olukotun. Transactional memory coherence and consistency. In Proceedings of the \n31st Annual International Symposium on Computer Architecture, page 102. IEEE Computer Society, Jun 2004. \n[27] Tim Harris. Exceptions and side-effects in atomic blocks. Science of Computer Programming, 58(3):325 \n343, 2005. [28] Tim Harris and Keir Fraser. Language support for lightweight transactions. In OOPSLA \n03: Proceedings of the 18th Annual ACM SIGPLAN Conference on Object-oriented Programing, Systems, Languages, \nand Applications, pages 388 402, Anaheim, California, USA, 2003. ACM Press. [29] Tim Harris, Maurice \nHerlihy, Simon Marlow, and Simon Peyton-Jones. Composable memory transactions. In Proceedings of the \nACM Symposium on Principles and Practice of Parallel Programming, Jun 2005. [30] Tim Harris, Mark Plesko, \nAvraham Shinnar, and David Tarditi. Optimizing memory transactions. In PLDI 06: Proceedings of the 2006 \nACM SIGPLAN Conference on Programming language design and implementation, pages 14 25, Ottawa, Ontario, \nCanada, 2006. ACM Press. [31] Maurice Herlihy, Victor Luchangco, and Mark Moir. A .exible framework for \nimplementing software transactional memory. In OOPSLA 06: Proceedings of the 21st Annual ACM SIGPLAN \nConference on Object-oriented programming systems, languages, and applications, pages 253 262, Portland, \nOregon, USA, 2006. ACM Press. [32] Maurice Herlihy and J. Eliot B. Moss. Transactional memory: Architectural \nsupport for lock-free data structures. In Proceedings of the 20th Annual International Symposium on Computer \nArchitecture, pages 289 300. May 1993. [33] Michael Hicks, Jeffrey S. Foster, and Polyvios Prattikakis. \nLock inference for atomic sections. In Proceedings of the First ACM SIGPLAN Workshop on Languages, Compilers, \nand Hardware Support for Transactional Computing.Jun 2006. [34] Benjamin Hindman and Dan Grossman. Atomicity \nvia source-to-source translation. In MSPC 06: Proceedings of the 2006 workshop on Memory system performance \nand correctness, pages 82 91, San Jose, California, 2006. ACM Press. [35] C. A. R. Hoare. Towards a theory \nof parallel programming. In International Seminar on Operating System Techniques, 1971. [36] C. A. R. \nHoare. Monitors: An operating system structuring concept. Commun. ACM, 17(10):549 557, 1974. [37] Richard \nL. Hudson, Bratin Saha, Ali-Reza Adl-Tabatabai, and Benjamin C. Hertzberg. Mcrt-malloc: A scalable transactional \nmemory allocator. In ISMM 06: Proceedings of the 2006 international symposium on Memory management, pages \n74 83, Ottawa, Ontario, Canada, 2006. ACM Press. [38] Anthony Kay. AlphaMail. http://sourceforge.net/ \nprojects/alphamail, January 2007. [39] Butler W. Lampson and David D. Redell. Experience with processes \nand monitors in Mesa. Commun. ACM, 23(2):105 117, 1980. [40] Jeremy Manson, Jason Baker, Antonio Cunei, \nSuresh Jagannathan, Marek Prochazka, Bin Xin, and Jan Vitek. Preemptible atomic regions for real-time \njava. rtss, 0:62 71, 2005. [41] Bill McCloskey, Feng Zhou, David Gay, and Eric Brewer. Autolocker: Synchronization \ninference for atomic sections. In POPL 06: Conference Record of the 33rd ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Lan\u00adguages, pages 346 358, Charleston, South Carolina, USA, 2006. ACM Press. \n[42] Chi Cao Minh, Martin Trautmann, JaeWoong Chung, Austen McDonald, Nathan Bronson, Jared Casper, Christos \nKozyrakis, and Kunle Olukotun. An effective hybrid trans\u00adactional memory system with strong isolation \nguarantees. In ISCA 07: Proceedings of the 34th Annual International Sym\u00adposium on Computer architecture, \npages 69 80, San Diego, California, USA, 2007. ACM Press. [43] Kevin E. Moore, Jayaram Bobba, Michelle \nJ. Moravan, Mark D. Hill, and David A. Wood. LogTM: Log-based trans\u00adactional memory. In Proceedings of \nthe 12th International Symposium on High-Performance Computer Architecture, pages 254 265. Feb 2006. \n[44] Michelle J. Moravan, Jayaram Bobba, Kevin E. Moore, Luke Yen, Mark D. Hill, Ben Liblit, Michael \nM. Swift, and David A. Wood. Supporting nested transactional memory in logTM. In ASPLOS-XII: Proceedings \nof the 12th international conference on Architectural support for programming languages and operating \nsystems, pages 359 370, San Jose, California, USA, 2006. ACM Press. [45] J. Eliot B. Moss and Antony \nL. Hosking. Nested transactional memory: Model and architecture sketches. Science of Computer Programming, \n63(2):186 201, Dec 2006. [46] Yang Ni, Vijay Menon, Ali-Reza Adl-Tabatabai, Antony L. Hosking, Richard \nL. Hudson, J. Eliot B. Moss, Bratin Saha, and Tatiana Shpeisman. Open nesting in software transactional \nmemory. In Proceedings of the Symposium on Principles and Practice of Parallel Processing, San Jose, \nCalifornia, March 2007. [47] Ravi Rajwar, Maurice Herlihy, and Konrad Lai. Virtualiz\u00ading transactional \nmemory. In ISCA 05: Proceedings of the 32nd Annual International Symposium on Computer Archi\u00adtecture, \npages 494 505, Washington, DC, USA, 2005. IEEE Computer Society. [48] Andreas Reuter and Friedemann Schwenkreis. \nContracts a low-level mechanism for building general-purpose work.ow management-systems. Bulletin of \nthe Technical Committee on Data Engineering, 18(1), 1995. [49] Bratin Saha, Ali-Reza Adl-Tabatabai, and \nQuinn Jacobson. Architectural support for software transactional memory. In MICRO 06: Proceedings of \nthe 39th Annual IEEE/ACM International Symposium on Microarchitecture, pages 185 196, Washington, DC, \nUSA, 2006. IEEE Computer Society. [50] Tatiana Shpeisman, Vijay Menon, Ali-Reza Adl-Tabatabai, Steven \nBalensiefer, Dan Grossman, Richard L. Hudson, Katherine F. Moore, and Bratin Saha. Enforcing isolation \nand ordering in STM. In PLDI 07: Proceedings of the 2007 ACM SIGPLAN Conference on Programming Language \nDesign Implementation, pages 78 88, San Diego, California, USA, 2007. ACM Press. [51] Arrvindh Shriraman, \nMichael F. Spear, Hemayet Hossain, Virendra J. Marathe, Sandhya Dwarkadas, and Michael L. Scott. An integrated \nhardware-software approach to .exible transactional memory. In ISCA 07: Proceedings of the 34th Annual \nInternational Symposium on Computer architecture, pages 104 115, San Diego, California, USA, 2007. ACM \nPress. [52] Gerhard Weikum and Hans-Jorg Schek. Concepts and applications of multilevel transactions \nand open nested transactions. In Database Transaction Models for Advanced Applications, pages 515 553. \n1992. [53] Lukasz Ziarek, Philip Schatz, and Suresh Jagannathan. Sta\u00adbilizers: a modular checkpointing \nabstraction for concur\u00adrent functional programs. In ICFP 06: Proceedings of the Eleventh ACM SIGPLAN \nInternational Conference on Func\u00adtional programming, pages 136 147, Portland, Oregon, USA, 2006. ACM \nPress.  \n\t\t\t", "proc_id": "1297027", "abstract": "<p>We present the TIC (Transactions with Isolation and Cooperation) model for concurrent programming. TIC adds to standard transactional memory the ability for a transaction to observe the effects of other threads at selected points. This allows transactions to cooperate, as well as to invoke nonrepeatable or irreversible operations, such as I/O. Cooperating transactions run the danger of exposing intermediate state and of having other threads change the transaction's state. The TIC model protects against unanticipated interference by having the type system keep track of all operations that may (transitively) violate the atomicity of a transaction and require the programmer to establish consistency at appropriate points. The result is a programming model that is both general and simple. We have used the TIC model to re-engineer existing lock-based applications including a substantial multi-threaded web mail server and a memory allocator with coarse-grained locking. Our experience confirms the features of the TIC model: It is convenient for the programmer, while maintaining the benefits of transactional memory.</p>", "authors": [{"name": "Yannis Smaragdakis", "author_profile_id": "81100614708", "affiliation": "University of Oregon, Eugene, OR", "person_id": "P304712", "email_address": "", "orcid_id": ""}, {"name": "Anthony Kay", "author_profile_id": "81100544596", "affiliation": "University of Oregon, Eugene, OR", "person_id": "PP39098465", "email_address": "", "orcid_id": ""}, {"name": "Reimer Behrends", "author_profile_id": "81100335115", "affiliation": "University of Oregon, Eugene, OR", "person_id": "PP39088947", "email_address": "", "orcid_id": ""}, {"name": "Michal Young", "author_profile_id": "81332537447", "affiliation": "University of Oregon, Eugene, OR", "person_id": "PP39086897", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1297027.1297042", "year": "2007", "article_id": "1297042", "conference": "OOPSLA", "title": "Transactions with isolation and cooperation", "url": "http://dl.acm.org/citation.cfm?id=1297042"}