{"article_publication_date": "01-25-1982", "fulltext": "\n Non-syntactic Attribute Flow in Language Based Editors Gregory E . Johnson Charles N. Fischer Computer \nSciences Department University of Wisconsin-Madison 1. Introduction The recent computer science literature \nhas contained numerous papers about a new concept in software development, the Language Based Editor, \nor LBE[l.2,4,7,9,19]. An LBE is similar to standard text editors in that it has capa\u00adbilities to create \nfiles, perform inser\u00ad tions, deletions, and other standard edit\u00ading operations, but it differs from normal \neditors in that it possesses knowledge of the syntax and semantics of a particular programming language. \nWith this knowledge, the text editor can notify a user immedi\u00adately if an attempt is made to create an \nillegal program. Much attention has been focussed on the syntactic aspects of pro\u00adgram editors, or more \nspecifically on the context-free aspect of syntax analysis. Comparatively little attention has been directed \nat the semantic and context sensi\u00adtive aspects of LBE s. Demers, Reps, and Tietelbaum[6] have suggested \nthe use of attribute grammars[13] as an appropriate basis for the semantics of program editors. Reps[15] \ncontinued this work and presehted an attribute evaluation technique tailored to incremental changes in \nan attributed parse tree. Skedzeleski[17] studied time\u00advarying attributes, in which attributes may be \nevaluated more than once in the attri\u00adbute evaluation process, and non-local attributes, which are attributes \nthat are functions of attributes not localized within a single production. Although Skedzeleski s work \nwas not developed for LBE s, it is similar to the approach presented in this paper. It has been our experience \nthat pure attribute grammars have some shortcomings in the incremental update environment found in an \nLBE . Objects that are closely Permission to copy without fee all or part of this material is granted \nprovided that the copies are not made or dktributed for dkect commercial advantage, the ACM copyright \nnotice and the title of the publication and its date appear, and notice k given that copying is by permission \nof the Association for Computing Machinery. To copy otherwise, or to republish, requires afeeand/or specific \npermission, @ 1982 ACM O-89791-065-6/82/OOl/O185 $00.75 related in a semantic sense and which require \nfrequent exchange of semantic information can be arbitrarily far frOm each other in the syntax tree describing \nthe program. In order to alleviate this problem, we make use of context sensitive relation sets. In the \nclassic attribute evaluation framework, direct attribute transmission may only occur across parent child \nor child-child syntactic relations. We will extend this model to allow dynamic construction (at evaluation \ntime ) and dynamic use of relations over which attri\u00adbute flow may take place. The problem of how best \nto evaluate the attributes of a semantic tree has received much atten\u00adtion[5,3,10, 12,111. Previous work \nin attribute grammars has assumed the follow\u00ading sequence of operations: parse; eval attributes; . or \nperhaps[16j repeat parse partially: evaluate as much as possible;  until done;  We add a third phase \nto the latter scenario: repeat parse partially.; repeat evaluate_as_much_as_possible; update_flow_links_if_necessary; \nuntil done; until really done:  The update_flow_links phase bears some resemblance to parsing in that \nwe are modi\u00adfying the compound dependency graph[13,14] of the program. It is also intimately related \nto the attribute evaluation pro cess, since these links may themselves depend on attributes in a partially \nevaluated parse tree. This paper will con\u00adsist of two parts. The first part will present a generalization \nof the normal attribute flow model that formalizes the above ideas of context sensitive attribute flow. \nMethods for both monolithic evalua tion (in which an entire parse tree is given and must be evaluated) \nand incremen\u00adtal evaluation (in which an attributed tree is changed slightly and must be updated) in \nthe presence of context sensitive attribute flow will be presented. In the second part the semantic analysis \nof a working program editor that makes extensive use of context sensitive flow, the University of Wisconsin \nPascal Oriented Editor (POE) [81, will be examined. Some of the applications of con\u00adtext sensitive flow \nworked quite well, and others did not. It is hoped that the experience gained so far in implementing \nsemantic checking in POE will be helpful to other designers and implementors of automated program development \ntools. By far the most important application of the above ideas is to link the defining occurrence of \nan identifier with its uses. Section 4 will present a set of algorithms for manipulating attribute flow \nrelations among definition and use occurrences of identifiers. Of secondary importance is the use of \nattribute flow links to represent precedence relations in expres sions. Flow link manipulation within \nexpressions will be briefly discussed in Section 5. 2. A formal model for context sensitive ~ttr?b~ow \nAn attribute grammar [l3] is an extension of the context free grammar for\u00admalism which captures context \nsensitive requirements by associating with each pro\u00adduction a set of attribute evaluation functions. \n Each node in a parse tree may have associated with it a set of values, or attributes, which are the \nresults returned by execution of such functions. A parse tree that has attributes associated with its \nnodes is called a semantic tree . Evaluation functions take as their inputs attributes that already exist \nin the pro\u00adduction instance with which they are asso\u00adciated. Some evaluation functions require no inputs, \nand some depend solely on attri\u00adbutes that are pre-initialized in the tree before the evaluation process \nbegins. For convenience we will 1 ump these two categories together and say that the attri\u00adbutes output \nby these evaluation functions have in degree zero. This term is sug\u00adgested by the fact that if we drew \na graph representing the dependencies among attri\u00adbutes in a semantic tree, the nodes representing these \nattributes would have no incoming arcs. Each attribute evaluation function has associated with it an \nindica\u00adtion of which symbol in its corresponding production is to receive its result. It is convenient \nto distinguish between attri\u00adbutes that are to be associated with the parent of a production, which are \ncalled synthesized attributes in the literature, and attributes that are given to children in the production, \nwhich are called inher\u00adited attributes. We will also classify attributes as input and output attri butes. \nThe attributes that appear in the input list of some evaluation function in a given production will be \ncalled input attributes to the ~roduction. Similarly, attributes that are created by some evalua\u00adtion \nfunction in a production will be called output attributes of the production. We extend the attribute \ngrammar model by allowing the addition of context sensi\u00adtive relation sets. A context sensitive relation \nset is a finite ordered set of grammar symbols, a set of attribute evalua\u00adtion functions, and an assertion. \nThe assertion is a boolean-valued function of the attributes in a parse tree. Every set of nodes in the \nparse tree which (1) has grammar labels which match the symbols in the finite ordered set of a CSRS, \nand  (2) satisfies the assertion associated with the CSRS   is said to participate in an instance \nof that CSRS. As an example, a CSRS might be appended to a normal attribute grammar that contains grammar \nsymbols X and Y. The ordered set of the CSRS is (X, Y), the assertion is the node Y is in the subtree \nof the node labelled X , and the evaluation function is X count := X count + l . A node labelled X in \na given parse tree would participate in a CSRS with every node labelled Y in its subtree, and with no \nnode labelled Y outside of its subtree. When evaluation has finished, X count will be a count of the \nnumber of nodes labelled Y in the subtree rooted by X. In this example, X count is an example of what \nSkedzeleski calls a time varying attribute, since in the course of evaluation it takes on a suc\u00adcession \nof different values. Context sensitive relation sets and normal productions in an attribute grammar may \nbe thought of as special cases of a simpler construct which we might call an association . We define \nan association to be an ordered set of grammar symbols and a set of evaluation functions. In an attri\u00adbuted \nparse tree derived from a normal attribute grammar, a given node may parti\u00ad cipate in at most two associations; \nit may be a child in one production instance and a parent in another production instance. The root and \nleaves participate in only one association. In our new formalism, we allow a given node to participate \nin an arbitrary number of associations. In addi tion to being a parent and a child, it may participate \nin an arbitrary number of instances of context sensitive relation sets . For instance, if the grammar \nhas a CSRS that associates cuse id> s with their <defn id> s, the <defn id> will participate in as many \nCSRS S as there are uses of the identifier for which it is the definition. The assertion associated with \nthe <defn id>, <use id> CSRS would, of course, have to enforce appropriate scope rules. If the input \nand output sets of every association in a non-ci.rcular[13] attribute grammar are disjoint, we will say \nthat the grammar is in normal form , In the case of an attribute grammar that has no context sensitive \nrelation sets, this definition is equivalent to the definition of normality given in the literature in \nterms of syn thesized and inherited attributes[lO]. In the remainder of the paper we will restrict our \nattention to attribute grammars in nor\u00admal form. The assertion of a CSRS may involve attribute values \nof swbols that are far apart in the parse tree of a program. For instance, a CSRS may be established \nbetween two identifier terminals provided that they have the same value of the name attribute. Or, the \nassertion may require that the symbols in an instance of a GSRS bear some context free syntactic relation \nship to one another. For instance, Skedzeleski s non-local attributes allow communication between a node \nand any node between itself and the root of the parse tree. A CSRS might be have the ordered set (<defn \nid>, <block>) , an evaluation func\u00adtion might be put the ~defn id> s name in the symbol table associated \nwith <block> , and the assertion might require that <block> be the occurrence of the <block> non-terminal \nthat is first encountered mov ing from the <defn id> toward the root of the tree. We therefore require \na method for naming nodes whose attributes must be queried. 2.1. A node naming formalism .  Since the \nprocess of specifying rela\u00adtions between nodes that are far apart in the parse tree is of central importance \nin the new formalism, we require a formal method of naming nodes in the parse tree. We can view an unordered \ntree as a lattice [18] satisfying a unique parent* property. A lattice is a set with a partial ordering \nwhich has the property that every pair of elements has a least upper bound and a greatest lower bound. \nAn ordered tree may be viewed as a set together with two order\u00adings: the above-mentioned lattice struc\u00adture, \nand a complete ordering. In the fol\u00adlowing paragraphs, this representation of ordered trees will be formalized, \nand its usefulness in the context of the extended attribute grammar formalism will be shown. We have \na finite set S and two order ing relations <= and C. C is by definition a lattice with the unique parent \nproperty that (*) for all i <> U(C) (0(C) being the smallest element in the set according to c), if (iC \nj )and (iCk ) then (jCk )or (kC j ). We shall see below that this property gives us a class of lattices \nthat may be viewed as unordered trees. <= is by definition a full (non\u00adstrict) orderinq on S. The relationship \nbetween ~= and C is: join( i, j )<=i. ~= is meant to suggest visited first in a Pre-order traversal \n, and c is meant to suggest child of. C is the lattice that reflects parent child relations among nodes \nin a tree. The join of two elements is the lowest node in the tree that is an ancestor of both nodes, \nand the meet of two elements is the lower of the two if one is a sub\u00ad tree of the other; if not the meet \nis a special zero node that is the direct child of all leaves in the tree. tie can look at the situation \nfrom another point of view and say that any lattice satisfying (*) can be called a tree and any parent \nof zero is a leaf. By parent of element i we mean a node j <> i such that (1) iCj (2) there is nok<>i, \njsuch that iC k andk C j.  We can use (*) to show that the parent of a non-zero node is unique: assume \nthat ele\u00adment i has two distinct direct parents j and k. BY (*), either j Ck ork C j. Assume without \nloss of generality that j C k. We have a j, then, with the property that j~~i, kand iCj C k. But this \npresents us with a contradiction, since k is a direct parent of i, requiring that there is no j s.t. \ni Cj Ck. Three useful primitives of the above language are join and meet , which are defined in terms \nof C, and successor , which is defined in terms of <=. It is possible to derive an ordered tree from \na set (S, C, <=.), and to produce a set (S, C, <=) from an ordered tree. Given an ordered tree, the construction \nof (S, C, <=) is straightforward: for i, j in s, define i C j if i is a descendant of j, and define <= \nby doing a pre-order traver\u00adsal of the tree and labelling nodes with successive integers as we go. We \nhave to show that join( i, j ) <= i, but this sim ply says that we always visit parents before children \nin a pre-order traversal. Conversely, given a system (S, C, <=), we can build a tree as follows: make \nthe smallest element of S according to <= the root of the tree. Make the next smailest element the left-most \nchild of the root. In general, go through each element i of S in ascending order according to <=, and \nfind the largest element j of S such that j <= i and i C j. Make i the rightmost child so far of j. Using \nthe above for\u00admalism we can construct several other use\u00adful operations on trees. Possibilities might \nbe to find the parent and siblings of a given node, and to find a node labelled by a given grammar symbol. \nAs an example of the above formalism, we present an attribute grammar describing a simple language which \nhas block struc\u00adture,-two da~a ~ypes, and assignment state\u00adments. It resembles Pascal in that a block \ncontains a collection of interspersed definitions and uses of symbols, followed that two identifiers \nhave the same name. by nested blocks, followed by more uses of Second, the definition must lexically \npre\u00adgrammar Symbo 1 followed by the symbol symbols . Each production starts with a cede the use. Third, \nthe definition s I( : : =,, , Each CSRS starks with a grammar scope must include the use s scope. This \nsymbol followed by the symbol :: . After is enforced by requiring that there be no the symbol list in \neach CSRS, we have the <Block> node above the definition iden\u00adkey word *provided , and then the asser-tifier \nand below the join of the definition tion. The set of evaluation functions for and the use. Finally, \nwe require that each association comes last and is headed there be no intervening definition of the by \nthe key word *Eval functions Also, identifier in a block between that of the . we use the key word require \n, which definition and that of the use. 0,* introduces a boolean function of the attri-If we constructed \nan LEIE for this sim butes of an association. In order for a ple language, a user could change the sentence \nto be considered part of the definition of a symbol , and the changelan~uage described by an attribute \ngrammar, would flow through the def_id straight to all such boolean functions must have the each use \nid. It would not be necessary to value true . For instance, in the follow\u00adre evalu~te every use id in \nevery block ing example we use a *require to express contained by the block ?n which the change the rule \nthat in a valid program assignment took place. It is not uncommon, for exam statements must involve expressions \nof com\u00adpie, for a programmer to write the state\u00adpatible types. ment part of a Pascal program first and \n The CSRS in the following example then go back and create variables, types, links together definitions \nand uses of and constants. In section 4 below an effi identifiers. The assertion requires first cient \nmethod for establishing the CSRS S will be given. <Block> ::= BEGIN <Defsr Uses> <Blocks> <Uses> END \n<Defs, Uses> ::= DEF def id : <Type> <Defs, Uses>  *Eval functions def_id type := <Type> type { def_id \nname is initialized by scanner before eval. begins ) <Defs, Uses> ::= <Use> <Defs, Uses> <Defs, Uses> \n::= epsilon <Use> ::= USE use id(1) := use id(2)  *Eval functions { both id names are initialized Dy \nscanner before eval. begins ] *require use id(1) type = use id(2) type;  <Uses> ::= <Use> <Uses> <Uses> \n: := epsilon <Blocks> ::= <Block> <Blocks> <Blocks> ::= epsilon <Type> : := IIvT~GER *Eval functions \n\u00ad<Type> type := int; <Type> ::= CHAR *Eval functions <Type> type := char;  def id ::-use id *Pr~vided \ndef id name = use id name and {de?n lexically p~ecedes use] def id <= use id  and {defn s scope contains \nuse s scop~} there exists no node N labelled <Block> such that def id C N C join(def id, use id) and \n{no defn in ~n intervening sco~e] for all def id* <> def id satisfying the above three clauses, join(def \nid: use id) C join(def id*, use id)  *Eval functions use_id type := def_id type  3. Construction and \noperation of an  ZValuator We present a simplification of the Kennedy and Warren (KW) planning approach \n[121 which is especially useful in an LBE environment. We will first present the new approach in the \ncontext of attribute gram\u00ad mars without CSRS S; the problems of attri\u00ad buting a semantic tree from scratch \nand of incrementally updating a fully attributed tree that gets changed will be considered separately. \nFinally, the changes necessary when a grammar includes CSRS S will be dis\u00ad cussed. 3.1. Planninq and \nevaluation for unattri\u00ad~u~ed trees . We first consider the problem of evaluating all the attributes of \nan unat\u00adtributed parse tree. Following the general approach of KW, we first construct a set of evaluation \nplans. This step is analogous to the use of a parser generator -an attribute grammar is given as input \nto the planner, and the planner creates a set of tables that will be used to perform evalua\u00adtions of \nsemantic trees. For each associa\u00adtion in the grammar, the planner constructs a set containing all attribute \ninstances in that association. For every subset of each of these atkribute sets we construct an ordered \nlist of evaluation functions which can be invoked given that that subset of attributes is available. \n(As an optimiza\u00ad tion, we might attempt to determine which subsets of attributes can never be achieved, \nand remove those subsets from consideration) . Thus, if in a semantic tree we happen upon an association \ninstance with a set of available attributes, we know which new attributes to evaluate, and in what order. \nAt evaluation time, we label every association instance with a flag indicating which attributes are available \nin that association. It is crucial to note that the presence of a particular attribute will be indicated \nin a redundant manner -once for each association in which the node con\u00ad taining the attribute appears. \nAs the parse tree is being built, we do not do any attribute evaluation. We do, however, include in an \nevaluate association set any association instance that the parser builds which has attributes with in-degree \nzero. When the parse tree has been c om-Fletely built, we start the evaluation pro\u00adcess. The evaluation \nprocess consists of an iteration of the following operations: (1) we take an element from the evaluate \nassociation set, look at its flag, select the appropriate simple plan (which as noted above consists \nof nothing but a sequence of evaluation fUtICtlOn executions), and execute it.  (2) After performing \nthese evaluations, we update the flag associated with every  18S! association in which a node appears \nthat received a new attribute instance. Every association whose flag indicates a non-empty execution \nplan is included in the evaluate association set. We might include flags in tree nodes of the parse tree \nto indicate whether or not an associa\u00adtion is in the evaluate association set. (3) The iteration terminates \nif after this point the evaluate association set is empty. The example on the following page, derived \nfrom the classic example of Knuth, illustrates the evaluation process. At first the association set contains \nproduc\u00adtion instances that have attributes with in-degree zero. Each element of the asso\u00ad ciation set \ncontains a production instance number and a list of the attributes avail\u00adable in that production instance. \nAn attribute is identified by its name and a numeric indication of which node in its production it is \nassociated with. The parent of each production is numbered zero, and the children are numbered from left \nto right starting at one. At each iteration, an element of the association is selected, and the plan \nfor that production and set of When the available attributes is executed. empty, evaluation is association \nset is complete. The above approach is useful only in a situation in which a representation of the \nentire program is available before the evaluation process begins. An LBE is, of As will becourse, such \nan environment. seen below, the above approach lends itself nicely to the problem of incremental pars\u00ading \nand to the case of attribute grammars that contain CSRS S. It also has the attractive property that no \nabsolute non\u00adcircularity restrictions exist. In the approaches taken by KW [12] and Cohen and Harry [5], \nthe problem of absolute non\u00adcircularity must be addressed either at evaluator generation time or at evaluation \ntime. 3.2. Incremental update of an attributed FrZe In an LBE, as contrasted with a c om\u00adpiler, a user \ncan make small, incremental changes to the semantics of a program. From an attribute grammar viewpoint, \nwe have a fully attributed tree that is changed, perhaps slightly, and we want to avoid re-evaluating \nthe entire tree. We would like to re-compute only the attri\u00ad butes that become invalid because of the \nchange. This is the problem addressed by [6] and [15]. We will consider only opera\u00adtions involving the \nsubstitution of one sub-tree for another. As pointed out in [61, insertions, deletions, and replace\u00adments \ncan all be thought of as sub-tree replacements. We have the following situa\u00adtion: two fully attributed \ntrees are to be merged. A node of the first tree which has Productions: Evaluation functions: <Number> \n::= <Bit List> . <Bit List> Scale(1) := Length(1) -i Scale(3) ~= -1 Value(U) := Value(1) + Value(3) <Bit \nList) ::= <Bit> <More Bits> Length(D) := Length(2) + 1 Scale(1) := Scale(g) Scale(2) := Scale(Zl) -1 \nValue(g) := Value(1) + Value(2) <More Bits> : := <Bit> <More Bits> (same as previous production) <More \nBits> ::= epsilon Length(0) := 0 Value(0) := 0 <Bit> ::= 0 Value(g) := 0 <Bit> : := 1 Value(D) := 2 ** \nScale(0) <Number>(Prod. 1) <Bit List>(2) 1 - <Bit List>(:) /<Bit>(3) I 1 I <More I eps Bits>(A)  ,Bit>~) \nI 0 <i 40 re / <Bit>(8) Bits>(T) ,M>e ~its> (,) I 1 eps Association set: production, plan executed { \n(prod. 4, no attrs), (prucl. 9, no attrs) prod. 4 - evaluate Length(0) (prod. 1, no attrs), (prod. 6, \nno attrs) ) and Value(0) { (9, none), (1, none), 9 -Length(0); Value(0) none), (2, Lengtht2), Value(2)) \n] { ;;: none), (6, none), 1 -Scale(3) r Length(2), Value(2)), Length(2), Value(2)) ] { ::: none), (2, \nLength(2), Value(2)), 6 -Value(0) (7, Length(2), Value(2)), (5, Scale(0)) ] Length(2), Value(2)), 2 -Length(0); \nLength(2), Value(2)), Scale(0), Value(l)) ) Length(2), Value(2)), 7 -Length(0) Scale(0), Value(l)), L(l), \nS(s) ) ] S(0), V(l), L(2)), (1, L(l), S(3) ) } 5 -L(0); S(l): S(2) { (1, L(l), L(3), S(3)), 1 -s(1) (7, \nS(0), L(O), V(2), L(2)) ] { (7, S(0), L(0), V(2), L(2)), 7 -s(l); s(2) S(0), S(0), s(0)), s(0)), {[ E; \n(8, { (3, L(O), L(0), (3, (7, V(2), v(2), s(0)) s(0), L(2) L(2)), 1 L(0), } (8, S(l), S(g) } 2 8 3 -s(l); \n-v(0) -v(0) s(2) V(l), S(2), V(2), L(2)) ] { (7, S(0), L(0), S(l), 7 -v(0) v(l), s(2), V(2), L(2)), (2, \nS(0), L(O), S(l), V(l), S(2), V(2), L(2)) ] { (2, s(0), L(g), S(l), 2 -v(0) V(l), S(2), V(2), L(2)), \n(5, s(0), L(0), S(l), V(l), S(2), V(2), L(2)) } ( (5, S(0), L(0), S(l), 5 -v(o) V(l), S(2), V(2), L(2)) \n) [ (1, S(l), V(l), L(l), S(3), V(3), L(3)) ] 1 -v(0) (1 the same grammar label as the root of the replacement \ntree is stripped of its sub\u00adtree, and the replacement tree is attached in its place. The resulting tree \nmust then be examined and perhaps partially re\u00adevaluated. This process takes place in two stages: first, \na new set of values for the intersection node is selected. Second, changes are propagated from the intersec\u00adtion \nnode throughout the tree as far as necessary. (In the following discussion, we will refer to the root \nnode of the replacement tree as the intersection node , since two versions of it exist -one in the old \ntree, and one in the replacement tree. ) The intersection node will have two distinct sets of attributes \nthat may con\u00ad flict -those in the version of the node in the old tree, and those in the version of the \nnode in the new tree. In [6] it is suggested that inherited attributes from the old node be copied into \nthe new node. In [15], it is suggested that synthesized attributes of the old node be copied to the new \nnode. In both cases, as will be seen below, attributes of the intersection node may have to be unnecessarily \nupdated. We propose a third, somewhat more complicated selection scheme. We will take inherited attributes \nthat do not depend on syn\u00adthesized attributes from the old version of the node, and synthesized attributes \nthat do not depend on inherited attributes from the new node. In order to argue that this initiali\u00adzation \nscheme is plausible, we will make a few definitions and look at the situation from a different point \nof view. If a node in a semantic tree participates in N asso\u00adciations, we can divide the attributes of \nthat node into N sets -one set for the output attributes of each association. (For this discussion we \nignore attributes initialized before the evaluation process begins, and any attributes whose evaluation \nfunctions depend only on pre-initialized attributes will be considered to have in\u00addegree zero. With this \nproviso, every attribute of a node will be included in one of the N sets.) Each of the N sets can be \nfurther divided into two groups -those attributes that depend on other attributes in the node being considered, \nand those that do not. We shall call the former set node dependent attributes, and the latter set node \nindependent attributes. We can use these definitions to give a simpler formulation of our initialization \npro\u00adcedure: we take node independent attri\u00ad butes from the production instance that generated them. The \nnode independent attributes are precisely those attributes contributed to the intersection node from \nabove and below that do not depend on any\u00ad thing on the other side of the intersection node, It is as \nthough an evaluator evaluated the semantic tree as completely as possible from above and below without \ncrossing the intersection node. If we were to take all of the synthesized attributes from the old version \nof the intersection node, then we will have to re-compute the node independent synthesized attributes. \nBut these are precisely the attributes which we can be sure have the correct values in the new version \nof the intersec\u00ad tion node. If a node independent attribute is unavailable in the originating associa \ntion, but is available in the other associ\u00ad ation, we still take the attribute from the originating association. \nThe attribute is considered to have the value undefined . This might be the case, for instance, if we \nhad a definition of an identifier in our sample grammar of section 2.1, and deleted the subtree of the \n<type> node. On the CRT screen we would start with DEF i : char , and end with DEF i : <type> . We would \nbe replacing the subtree <type> ::= char , which has a node independent attribute <type> type, by the \nsubtree <type> ::= (unexpanded) , which has no <type~ type attribute. The scheduling of evaluations involving \nattributes with the value unde\u00ad fined is the same as that for normal attributes. The difference is that \ninstead of invoking a normal evaluation routine, the value undefined is passed along instead. In order \nto fully attribute the tree, it will almost surely be necessary for the evaluator to cross the intersection \nnode. The old and new parts of the updated tree may have stale attribute values that depended on attributes \noriginated in replaced parts of the tree. We would like to re evaluate only a few of these stale attributes, \ndetermine that they actually contain the values they are supposed to contain, and conclude that the new \ntree is correctly attributed. For instance, a user might delete a leaf from the tree that represents \nan integer and replace it with an identifier that turns out to have type integer . All of the attributes \ndepending only on type information of the leaf remain unchanged and need not be re evaluated, since that \ninformation has not changed. In order to propagate changes made to the attributes in the intersection \nnode, we must first discuss an addition to the table of plans from section 3.1 above. We dis\u00ad tinguish \nbetween actively available and passively available attributes in a production. Actively available attributes \nare those which have experienced a change in value, requiring that all attributes which depend on them \nbe re-computed. Pas\u00ad sively available attributes have had no known value change. We must augment our \nplan table to include plans for productions with a given set of actively available, passively available, \nand unavailable attri\u00ad butes. Again, the plans will simply be sequences of evaluation functions. If a \nproduction instance n has active attri\u00ad butes 8~At and passive attributes llP1l, then we execute the \nplan that would have been executed if none of the attributes that depend on elements of A were available. \nThe evaluation process will proceed in a manner analogous to that described in sec\u00adtion 3.1. To initialize \nthe process, we begin with the node independent attributes from contributing productions. These attributes \nare compared to any that they superseded to initialize the actively available set. For node dependent \nattri\u00adbutes of the intersection node, we select the version from the production that did not contribute \nthem. The two productions that contain the intersection node are given modified flags to reflect the \nnew actively available attributes. If appropriate, they are included in the evaluate association set. \nAs in section 3.1, we iterate on the following steps: (1) we take an element from the evaluate association \nset, look at its flag, select the appropriate plan, and exe\u00adcute it.  (2) when an attribute receives \na new value, it is compared to its former value, if one existed. If the value has changed, the attribute \nis con\u00adsidered active, and flags of associa\u00adtions in which it appears are updated accordingly. If not, \nno change is made to the flags. Every association whose flag indicates a non-empty exe\u00adcution plan is \nincluded in the evalu\u00adate association set. (3) The iteration terminates if after this point the evaluate \nassociation set is empty.  The approach outlined above requires a minimum of information to be kept \nat each node in the attributed tree. A flag, which could be encoded as an integer, is all that is required. \nWe follow the general princi\u00ad pl e that work is best done once at genera\u00ad tion time, rather than being \ndone repeat\u00ad edly at evaluation time. Rather than mani\u00ad pulating graphs or other complex data structures \nat evaluation time, we perform look-ups in tables. 3.3. Evaluation and update in the presence . ~f CSRS \n S We now consider the changes that must be made to the above procedures when we are interested in attributing \na parse tree or incrementally updating an attributed tree when the language describing the language contains \nCSRS s . The general method for creating and modifying CSRS S will be to include in the productions \nof the attribute grammar pseudo-evaluation functions that do not create attributes, but rather test CSRS \nassertions and, if appropriate, con\u00ad struct CSRS S . We will make the simplify\u00ading assumption that CSRS \nS depend only on attributes with in-degree zero. This assumption is admittedly severe, but the CSRS S \nin the attribute grammar we use to describe pascal for use in POE do possess this property. In order \nto attribute a parse tree, we perform three steps: (1) evaluate all attributes with in-degree zero, and \nin the same pass over the parse tree place appropriate produc\u00adtions in the evaluate associations set; \n (2) evaluate all CSRS-creating evaluation functions, placing them in the evalu\u00adate association set if \nappropriate;  (3) proceed with attribute evaluation as described in section 3.1 above.  Replacement \nof one subtree in an attributed tree by another will be accom plished in four steps (again, we assume \nthat the replacement tree has been attri\u00ad buted as fully as possible): (1) for every pseudo-evaluation \nfunction in the subtree to be deleted, invoke a roll-back evaluation function. After execution of these \nfunctions, the CSRS S in the tree will be the ones that would have existed if the subtree we are deleting \nhad never been in the tree at all. The procedures given in section 4 below for deleting definitions and \nuses are examples of these roll-back functions. When a CSRS is deleted, we record its output attribute \ninstances for later con sideration. (2) insert the new subtree, initializing attributes of the intersection \nnode as described in section 3.2. (3) invoke the CSRS pseudo-evaluation functions in the new sub-tree. \nFor each CSRS that is created, mark all input attributes to that CSRS as active. If some inputs to a \nCSRS are unavailable, create them and give them the value undefined . After this process, divide the \nattribute set created in step (1) above into two groups -those whose corresponding nodes participate \nin a new instance of the CSRS that was deleted, and those that do not. Mark the former as active attributes, \nand give them the value undefined . (4) proceed with incremental update as ~escribed in the previous \nsec~ion.  The above scheme can be summarized in the following way: when a subtree is replaced by another \nsubtree, we first sever all con\u00adnections between it and the parse tree, We then wire in the new subtree \nto the parse tree, connecting it through its root and also through a series of CSRS S. Finally, we incrementally \nupdate the attribute values in the new semantic tree. As will be seen below, in POE a new subtree is \ncon\u00adnected through its root and also through every occurrence of an identifier . The first time a new \nsubtree is put in place, the wiring in operation will involve an amount of work that is roughly equivalent \nto a normal evaluation of the subtree. steps: After the subtree is in place, however, changes in other \nparts of the program which affect the new subtree can take place much faster, since the leaves of the \nsubtree are now near to other parts of the tree which originate semantic information that they need. \n 4. Links between definitions and uses of  Zn i=fier We intend (as mentioned above) to create a CSRS \nfrom the defining occurrence of each identifier to each of its uses. The technique to be presented is \napplicable to an LBE for any language with static scope rules. We construct a symbol table for each lexic \nscope L of the program. The symbol table for lexic level L must be associated with a grammar symbol X \nwith the property that if one starts from any iden\u00adtifier in the program and follows parents to the root, \nX will be encountered if and only if the identifier is contained in the lexic scope L. With each symbol \nin the symbol table (which in our implementation is a hash table that is an array of linked list headers) \nwe associate a pointer to the definition occurrence of the identifier. The definition may be in the current \nlexic scope, or it may be in a containing lexic scope. We also keep a list of all occurrences of this \nidentifier in a use context that occur at this lexic level and a list of all occurrences of this identif\u00adier \nin a definition context at this lexic level. It is possible that the definitions list has more than one \nelement; if this is the case then we mark the definitions as errors, since it is illegal to have more \nthan one definition of an identifier in a lexic scope. Since (1) every lexic scope has a symbol table, \n (2) an identifier must be either a use or a definition but not both, and (3) the uses and definitions \nlists contain swbols only at their own lexic level,  we have the invariant that every identifier in \nthe program appears in at most one of our definitions or uses lists. If the list of definitions for a \nparticular identifier is non-empty, then the definition pointer for the identifier will be in this list. \nIf the list of definitions is empty, then the definition pointer is either nil (if the identifier is \nas yet undefined) or it points at an identifier in a containing scope. Our aim, then, is to use these \ndata structures to construct four operations: insert a new definition of an identifier, delete a definition, \ninsert a new use, and delete a use. Uses are easier to handle, so we start with them. To insert a use \nof an identifier, we must take the following 1) search up the parse tree until we find the node containing \nthe symbol table for this lexic level; 2) see if a symbol table entry exists for this identifier; a) \nif a symbol table entry exists for this identifier, link this identifier into the list of uses at this \nlexic level; b) if no symbol table entry exists for this identifier, i) build a new symbol table entry, \nand initialize the uses list to contain this use and the defini\u00adtions list to be empty; ii) to initialize \nthe definition pointer, search up the parse tree toward the root: as soon as a symbol table is found \nwith this identifier in it, copy that entry s definition pointer. If the root is reached instead, the \nsymbol is undefined, so set the definition pointer to nil. To delete an identifier that occurs in a \nuse context., we take the following steps: 1) find the symbol table entry for occurrences of this id \nat this lexic level, and remove this id from the uses list; 2) If the definitions list and the uses list \nare empty, remove this entry from the symbol table. Inserting and deleting operations for defining occurrences \nof identifiers are a bit more complicated. If a new definition of an identifier is inserted, nested scopes \nmust be searched for uses of the identifier for which this is the new definition. Similarly, if a definition \nis deleted, a new definition in a containing scope must be searched for, and if nested scopes con\u00adtain \nuses of the identifier that consider the symbol just deleted to be their defini\u00adtion, they must be updated \nto reflect the new definition. Insertion of a definition, then, requires the following steps: 1) include \nthe new definition in the defin\u00aditions list for this lexic level, build ing a new symbol table entry \nif neces\u00adsary; if the definitions list was non\u00adempty, take an error return; 2) make the definition field \nof the symbol table entry for this identifier point to the new identifier just inserted; 3) descend nested \nscopes; a) if a symbol table has a non-empty definitions list for this identifier, don t search any deeper \nhere; b) if a symbol table contains the iden\u00adtifier, set its definition field to point to the newly inserted \ndefini\u00adtion. To delete a definition occurrence, we perform the following steps: 1) remove the identifier \nfrom the list of definitions of this identifier at the current lexic level; if this was not the defining \noccurrence of this identifier, return. 2) attempt to find a new defining occurrence of the identifier \nas follows: a) if the definitions list has exactly one element, then that is the new defining occurrence; \nb) if the list is empty, we search toward the root for a lexic level containing an occurrence of this \nidentifier, and use the definition field found in in the symbol table entry there. c) if the list has \nmore than one ele\u00adment, take an error return; 3) descend through nested lexic scopes; a) if the lexic \nscope has a non-empty definitions list for this identifier, search no deeper here; b) if the lexic scope \ncontains uses of this identifier but no definitions, make the new definition of this iden\u00adtifier the \none found in step (2). We use the node naming functions described in section 2.1 in the above rou\u00adtines \nto implement operations involving movement about the parse tree. When we move toward the root of the \ntree, we do this by a sequence of invocations of a Parent operation. Similarly, when we descend into \nnested lexic levels, we invoke a series of Sibling and Child opera\u00adtions. From a formal standpoint, these \nfunctions can be implemented using the primitives of the model of section 2.1. As a practical matter, \nwe have implemented these operations directly using pointers. 5. Flow links inside expressions . It was \ndecided that in POE expressions are to be represented as arbitrarily long flat lists of the form <simple \nexpr> [ <op> <simple expr> 1... where the notation [ 1. . . is used to indi cate that the quantity inside \nbrackets may be repeated zero or more times. This representation makes it convenient for the user to \ninsert and delete fragments of the form cop> <simple expr> after any <simple expr~ . In order to allow \ntype compatibil i ty to be checked inside an expression, we need the precedence tree of the expression. \nA CSRS was added to the Poe attribute gram\u00ad mar that links <op> s and <simple expr> S together to form \nthe precedence tree of an expression. For the pseudo-evaluation function to create instances of these \nCSRS S, an algorithm was developed which takes as input a precedence tree and a new (<op> <simple expr>) \nfragment anywhere in the expression and returns an updated pre\u00adcedence tree that includes the new frag\u00adment. \nThe algorithm requires a single pass from the location of the correction to the root of the precedence \ntree. An analogous algorithm can be used to delete (<oP> <sim\u00adple expr> ) fragments from an expression. \nBy having CSRS instances describing the precedence tree in place and using the incremental update algorithm, \nsmall changes to an expression can be made without requiring that the entire expression be re-parsed. \nIn practical terms, the Savln9S in parsing time that were made did not strongly outweigh the cost in \nspace and time of creating and saving the CSRS S. 6, Conclusion In this paper we have proposed a method \nfor creating direct attribute flow relations between semantically related objects in an attributed tree. \nThe method provides a substantial performance improve\u00ad ment over the standard attribute grammar model \nstudied, for instance, by Reps, in that attributes may flow directly to where they are needed, rather \nthan being res\u00ad tricted in their flow to paths in the parse tree of a program. The links take up space \nin memory and require time to construct, so their use involves trade-offs. In the case of identifiers, \nthe advantages far out\u00ad weigh the costs. In the case of expres\u00ad sions, the advantages are less clear-cut. \nReferences [1] Alberga, C. N., A. L. Brown, G. B. Leeman Jr., M. Mikelsons, and M. N. Wegman, A program \ndevelopment tool , 8th Symposium on Principles of Pro\u00adgramming LanguagX, pp. 92-104 H9T [21 Archer, \nJames and Richard Conway, COPE: a cooperative programming environment,  TR 81-459, Cornell University \n(1981). [31 Bochmann, Gregor V., Semantic evalua\u00ad tion from left to right, communica\u00ad tions of the. \n ACM, 2, pp. 55-62 (Febru\u00ad 59%) . [4] Celentano, A., P.D. Vigna, C. Ghezzi, and D. Mandrioli, SIMPLE: \na program development system, Languages ~, pp. 103-114 (1980 v . [5] Cohen, R. and E. Harry, Automatic \ngeneration of near-optimal linear-time translators for non-circular attribute grammars, ~ Symp osium \non Principles of Programming Languages,~p. 121-134 Panuary 1979)0 [6] Demers, Allan, Thomas Reps, and \nTim Teitelbaum, Incremental evaluation for attribute grammars with applica\u00adtion to syntax-directed editors. \n, 8th Conference on Principles of Science Research Associates, Inc. , ~ LanguaGs, pp. 105-11~(19~1 v \nChicago (1973). [7] Donzeau-Gouge, V., G. Huet, G. Kahn, B. Lang and J. Levy, A structure oriented p~ogram \neditor: a first step towards computer assisted program: ming, Technical Report 114, IRIA Laboratories \n(1975). [19] Teitelbaum, T. and T. Reps, The Cor\u00adnell program synthesizer: a syntax\u00addirected Droarammina \nenvironment, Communications\u00adof t<e ACM 24, 9, pp. 563-573 (Septemb~ 1981). [8] Fischer, Charles Jon \nMauney, An Allan Poe, Tech sity of Wisconsin N., Greg Johnson, and Introduction to Editor Report #453, \nUniver\u00ad(October 1981). [9] Habermann, research University Review A. project, Computer -1979, pp.. N., \nThe gandalf Carnegie-Mellon Science Research 28~79>. [10] Jazayeri, and the \u00adgranumng Sci. University \nthesis. M.t On attribute semanti~specification languages, Comp. Dept. , Case Western (October 1974) grammars \nof ~ an~ Inf. Reserve Ph.D. [11] Kennedy, K. and J. Ramanathan, A deterministic attribute grammar evaluator \nbased on dynamic sequenc\u00ading, ACM Transactions on Programming Languag~and Systems ~,~, pp. 142\u00ad160 (JuIY \n=9). [12] Kennedy, K. and S. K. Automatic generation of evaluators for attribute 3rd Symposium on Principles \nw Languag~, pp. 32-49 Warren, efficient grammars, of Pro . (January [13] Knuth, text %%? Donald Free \nJournal E., Semantics Languages, ~, 2, pp. Math. +127-145 of S Con\u00adstems June [14] Knuth, text Math. \n*95 96 Donald Free S stems 1971 E., Semantics Languages: Theory Journal of Correction, ~, 1, Con\u00ad pp. \n[15] Reps, T., semantic editors, sity (1981). Optim al-time analysis for TR 81-453, incremental syntax-directed \nCornell Univer\u00ad [16] Rowland, and the mars, Computer sity of Bruce R., Evaluation Tech Report Sciences \nWisconsin Combining of Attributed #308, Ph.D. Department, (June 1977). Parsing Gram-Thesis, Univer [17] \nSkedzeleski, and Use Attributed ences thesis, Madisdn Stephen Karl, Definition of Attribute Reevaluation \nin Grammars, Computer Sci-Technical Report #340, PhD University of Wisconsin\u00ad(October 1979.). [183 Stone, \ncal Harold Structures S., and. Discrete Their App Mathemati\u00adlications, 195  \n\t\t\t", "proc_id": "582153", "abstract": "", "authors": [{"name": "Gregory F. Johnson", "author_profile_id": "81100449078", "affiliation": "University of Wisconsin-Madison", "person_id": "PP39043252", "email_address": "", "orcid_id": ""}, {"name": "Charles N. Fischer", "author_profile_id": "81100312451", "affiliation": "University of Wisconsin-Madison", "person_id": "P43394", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/582153.582174", "year": "1982", "article_id": "582174", "conference": "POPL", "title": "Non-syntactic attribute flow in language based editors", "url": "http://dl.acm.org/citation.cfm?id=582174"}