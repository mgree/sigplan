{"article_publication_date": "01-25-1982", "fulltext": "\n Semantics-Directed Machine Architecture by Mitchell Wand Computer Science Department Indiana University \nBloomington, Indiana 47405 Abstract We show how to analyze the denota\u00adtional semantics for a programming \nlanguage to obtain a compiler and a suitable target machine for the language. We do this by rewriting \nthe equations using suitable combinators. The machine operates by simulating the reduction se\u00adquences \nfor the combinator terms. The reduction sequences pass through certain standard forms, which become an \narchitec\u00adture for the machine, and the combinators become machine instructions. Despite the abstract \nnature of its development, the machine greatly resembles a conventional one. The method is illustrated \nby a sim\u00ad ple expression language with procedures and input-output. 1. Introduction The purpose of this \npaper is to make a connection between the denotational semantics of a programming language and the way \nin which one builds language pro\u00adcessors in the !treal world.!! By a lan\u00adguage processor, we mean both \nthe compiler for a language and a target machine for the language (to be implemented either in hardware \nor software). A definition of a language in denota\u00adtional semantics may be viewed as providing a syntax-directed \ntranslation from phrases of the programming language This material is based upon work supported by the \nNational Science Foundation under Grant MCS 79-04183 AOI. Permission to copy without fee all or part \nof this material is granted provided that the copies are not made or distributed for direct commercial \nadvantage, the ACM copyright notice and the title of the publication and its date appear, and notice \nis given that copying is by permission of the Association for Computing Machinery. To copy otherwise, \nor to republish, requires a fee and/or specific permission. @ 1982ACMO-89791-065-6/82/OOl/0234 $00.75 \nto terms of a suitable lambda-calculus. Since lambda-calculus terms can be llexe\u00adcutedff by reducing \nthem to normal form, it is natural to consider building a general purpose interpreter which operates \nby first translating a program in the source language into the lambda-calculus (using the semantics), \nand then reducing the resulting term to normal form. Our approach also uses this idea. Rather than directly \nexecuting the lambda\u00adcalculus expression, we translate into the language of combinators. Rather than \nuse general purpose combinators (e.g. S, K, I) we analyze the semantic definition (by hand, not automatically, \nat present) to find a set of useful special-purpose com\u00adbinators. For most ordinarytT languages (e.g. \nAlgol, Pascal, Lisp), we can obtain combinators with the following pleasant properties: 1) the semantics \nof the language can be rewritten using these combinators alone, without the use of lambda\u00ad astraction. \n2) the combinators have sufficiently nice associative and distributive proper\u00adties so that the combinator \ntrees can be rotated into a linear or almost-linear format. 3) the reduction of the resulting combinator \nexpressions can be expressed as a rewriting system on strings of a particular format. This format becomes \nrecognizable as an abstract machine archi\u00ad tecture, and the rewriting system as the action of the machine. \nFurthermore, this machine is very close to a IIconventionalll high level machine architecture for these \nlanguages. This analysis yields an architecture of a target machine for the language and a compiler (more \nproperly, a compiling al\u00adgorithm) from the language to the target machine. The compiler translates, programs \nin the source language into linearized trees of combinators which are equivalent to the lambda-calculus \nterms specified by the original semantics. The target benchmark of [8,10,16]. Table 1 shows the machine \nsimulates the reduction of these semantics, given in continuation form. combinator trees--i.e., it becomes \na syntactically vinegared version of a re- We express the semantics using a duction machine. !tRomanizedll \nversion of Scott-Strachey nO- We have discussed the derivation of tation (see, e.g., [51). We write compilers \nshall give elsewhere a brief [181; summary in this of that paper we analy\u00ad for lambda x y z. body sis \nand concentrate instead on the way in which this architecture. analysis yields a machine lambda x. lambda \ny. lambda z. body and we let application associate to the 2. An Example Language left, to as write usual. \nf(a,b) We for shall f a also b. feel Comma free has our In this methodology paper, on we shall a simple \nillustrate expression lower f(a eral precedence b, c) = f(a familiarity than application, b)c. (We presume \nwith this style a of so gen\u00addes\u00ad language with procedures and input-output, cription. ) neither of which \nis treated in the Domains Id Identifiers EXP :: =Id [Exp + EXP] Expressions [PROC Id EXP] [DOIO EXP] \n[ExP(ExP)I R Basic Values ii= B+[V>K9Cl Values Env . Id-> V Environments s States A Answers C=S4A Command \ncontinuations K=V>C Expression continuations Valuations P :Exp>C E :Exp~Env>K>C Ea uation~ P[expl = E[expl \ninitenv halt E[idl = lambda env cont. cont(env id) E[expl + exp21 = lambda env cont. E[expl]env(lambda \nvI. E[exp21env(lambda v2. cont(vl+v2))) EIPROC id exp] . lambda env cont. cont(lambda arg contl. E[exp] \nenv[arg/idl contl) EIDOIO expl . lambda env cont. E[explenv(lambda v. doio cent v) E[expl(exp2)] = lambda \nenv aont. E[expl]env(lambda f. E[exp2]env(lambda arg. f arg cent)) Table 1. A simple expression language \nwith procedures and input-output. 235 Expressions are eiiher identifiers, sums, procedures, input-output \nstatements, or applications. Values are either basic values (which are left unspecified) or function \nvalues (V > K > C). States, an unspecified domain, abstracts the state of the input-output streams. Also \nleft un\u00adspecified are: initenv: Env an initial environment halt: K= V >S >A an initial expression continuation, \nwhich extracts an !anSWer from a value and a state doio: K>V>C an input-output operation which takes \na value, and a state, and re\u00adturns a value and a possibly altered state A procedure expects a parameter \nand an expression continuation when it is in\u00advoked. In an application, the operator is evaluated first, \nthe operand is evaluated second, and then the function is applied. The doio operation provides a way \nto alter the state. (doio cent v s)is generally equal to (cent v! s!), where v! is a suitable value to \nbe returned to doiofs caller, and s! is a possibly altered state. The functionality of doioj how\u00adever, \nallows it to initiate an error and ignore the continuation cont. The ability to model such behavior is \nan important advantage of continuation semantics. 3. Eliminating Lambda Abstraction Our first task is \nto come up with suitable combinators to replace the use of lambda-abstraction in Table 1. We observe \nthat in the equation for E[expl + exp2] , most of the lambda variables need to be routed to the operand \nparts of applica\u00adtions. This suggests a generalization of the combinator B = lambda f g X. f (g x). The \nstatic environment env, however, gets routed to both operator .and operand parts, a task for which S= \nlambda f g x. f x (g x) might be used. The following family of combinators accomplishes this argument \nsteering: Dk = ;~nl:td: el e2 env cent xl . . . xk. (e2 env cent xl . . . xk) (k > O) (This is just \nBS(Bk+l) [3, Pp 163-1651.) Then E[expl + exp2] = lambda env cont. E[expl]env(lambda vI. E[exp2]env(lambda \nv2. cont(vl+v2))) = Do(E[expll, lambda env cent vI. E[exp2]env(lambda v2. cont(vl+v2))) = Do(E[expll, \nD1(E[exp21, lambda env cent VI v2. cont(vl+v2))) If we introduce add = lambda env cent VI v2. cont(vl+v2) \nthen the equation may be rewritten as E[expl + exp2] = Do(E[expl l,D1(E[exp21, add)). By similar manipulation, \nwe can eliminate the other lambda-terms by introducing the following combinators: fetch = lambda id env \ncont. cont(env id) pushproc . lambda id body env cont. cont(lambda arg contl. body env[arg/idl contl) \niot . lambda env. doio apply = lambda env cent f a. f a cent return = lambda env cont. cent This gives \nthe equations of Table 2. ( The P[exp] = Do(E[exp], return)initenv halt E[idl z fetch id E[expl + exp21 \n= Do(E[expl], D1(E[exP2], add)) EIPROC id exp] = pushproc id Do(E[exp], return) EIDOIO exp] = Do(E[exp], \niot) E[expl(exp2)] = Do(E[expl], D1(E[exP2], aPPIY)) Table 2. Semantics expressed with combinators 236 \nuse of return is a patch to make the machinets treatment of leaves smoother.) These equations suggest \na representa\u00adtion of the code as a tree in which the internal nodes are labelled with D s and the leaves \nare labelled with fetch id, add, etc. This would be similar to tree\u00adstructured intermediate languages \nsuch as TCOL [11. We can do better, however, by using the following proposition: Proposition Dk(Dp(a,b),c)=Dk+p(a,Dk(b \n,c)). ErQ12.f: Dk(Dp(a, b),c)dexl. ..xk+p = Dp(a,b)d(CdeX1 . ..Xk)xk+~ . ..xk+p = ad(bd(CdeX1 . ..Xk)Xk+l \n. ..Xk+p) = ad(Dk(b,C)deX1 . ..xk+P) = Dk+p(a,Dk(b,C) )deX1. ..xk+p. . / @PI m /\\ D D Elm // By this \nproposition, we may rotate any combinator tree of the sort discussed above into an almost-linear format \nin which the left son of a D is never a D. Figures 1 and 2 show the representation of a sample program \nbefore and after rota\u00adtion. Observe that the rotated code is just the standard postfix code (except for \nthe pushprocs). The job of the compiler is to trans\u00adlate the source program into the li\u00adnearized combinator \ntree. The compiling algorithm is trivially correct because its output is obtained by equality-preserving \ntransformations from the combinator tree given by the semantics. b // odd D $2+(J \\ D / / id d rct(.m \n Figure 1. Combinator tree for (PROC X (X+Y)+Z)(Z) Figure 2. Code for figure 1, after before rotation. \nrotation. 5. Designing the Machine We next turn to the reduction of this linearized tree to normal form. \nWe need only worry about trees of the form Dk(ins,P) where ins is a tree whose root is not a D, and about \nleaves. In general, these terms have type Env+C~Vn>S >A Let us consider the case of Dk(ins,p). In order \nto obtain an answer, we must reduce a term of the form Dk(ins,p) env cent xl . . . Xn s where X1...xn \nare values and s is the current store. We begin with the case when ins . fetch id. Tracing the reduc\u00adtion, \nwe obtain: Dk(fetCh id, p) env COnt Xl . . . xk S > fetch id env (p env cent Xl . . . xk) s (clef. of \nDk) ~ p env COnt xl . . . xk (env id) s (def.of fetch) (The subscript on D must be exactly k for the \ntypes to match; see [181). We inter\u00adpret (env id) as the appropriate value, rather than as an unevaluated \nterm. This reduced term is of the same form as the original. We may analyze add in the same way: Dk(add,P) \nenv COnt xl . . . Xk Xk+l Xk+z S > add env (p env cent X1 ... xk) k+l k+2 s -> p env cent x1 . . . Xk \n(xk+l+xk+2) s From this kind of analysis we learn that the D combinator treats the xits as a stack, with \nthe top at the right end. If the left son of the D is a fetch, then the appropriate value is pushed onto \nthe stack; if the left son is an add, then the top two elements of the stack are replaced by their son. \nFurthermore, the reduction sequence can be made to pass through terms of form seq env cent xl ... xn \ns (1) where seq is a linearized combinator tree, x~, . . ..xn are values, and similar descrip\u00ad tions \ncan be given for the other portions. This form may be recognized as (a rather abstract version of) a \nmachine architec\u00adture: the machine has a program counter (seq), an environment register (env), a continuation \nregister (cent; this turns out to be a Pointer to the top of the return stack), a local stack (xl . . \n. x ), and a random-access store (s). ?he machine has a fetch-execute cycle in which the left son of \nthe seq register is fetched and executed (using the top few elements of the local stack); after execu\u00adtion, \nthe right son gains control. Thus the reduction above defines the behavior of the add and fetch instruction \non this machine; this is, of course, precisely what these instruction do on a convention\u00adal stack machine. \nWhat is different is that we have derived these actions direct\u00adly from the definitions of the combina\u00adtors, \nwithout any a priori assumptions about the architecture or action of the machine. (The reader familiar \nwith convention\u00adal machine code may find the presence of the Dkls disturbing. The subscript k counts \nthe number of items on the local stack which are protected from the current instruction. It turns out \nthat this sub\u00adscript can always be deduced from context, so that the tree can be represented as a linear \nsequence of instructions, except for pushproc, which requires a pointer, as usual, ) We must now see \nwhether this analysis will handle the other cases. We proceed with pushproc: Dk(PUShPrOC id seq, p)env \ncent xl . . . xk s > pushproc id seq env (p env cent xl ... xk) s > p env cent xl ... xk (lambda arg \ncontl. seq env[arg/id] contl) s This term contains a lambda-abstraction, which may be eliminated by introducing \na combinator closure . lambda id seq env arg contl, seq env[arg/id] contl This yields the reduction \n4 p env cent xl . . . xk (closure id seq env) s which is once again in form (1), provided we expand \nthe set of stackable terms (i.e. those which may appear as an Xj) to in\u00adclude not only members of V but \nterms of the form (closure id seq env). For iot, we get Dk(iOt,p) env COtlt xl . . . Xk xk+~ S > iot \nenv (p env cent xl ,.. xk) xk+l s ~ doio (p env cent xl . . . xk) xk+l s The behavior of the machine \nthen depends on doio; if it behaves normally the reduc\u00adtion sequence will reach >p env cent x1 ... Xk \nx s The development in this case will be anal\u00adfor some suitable x! and s . ogous to iot. Last, any other \nvalue causes an error, which can be treated in a The analysis of apply starts off the similar fashion. \n same way as before: We must consider one more point. Dk(appl Y,P) env cent xl . ..xk xk+l Xk+~ S What \nhappens when seq inform(1) is a leaf? Luckily, the only leaves we need > apPly env (p env cent xl . . \n. xk) consider are rightmost leaves, and the k+l k+2 s only combinator which appears as a rightmost leaf \nis return. So we need only > xk+l xk+~(p env cent xl . . . xk) s consider terms of form We must now \nconsider what kind of terms return env cent x s could appear as xk+l. It could be of the form (closure \nid seq env ). In this case A cent x s it is useful to introduce the family of combinators (Again, there \nmust be exactly one x for the types to match). As in the case of apply, we must consider what kind of \nterms can appear in the cent register. Looking lambda p env cent xl . . . xk. return-pointk = back, we \ncan see that such a term must p env cent xl ... xk either be halt or be of the form (return\u00adpointk p \nenv cent xl . . . xk). (Thus theWe may then continue the analysis by cent register may be implemented \nas a stack, and the locals kept near the top of (closure id seq env .) xk+2 (p env cent xl the stack, \nin the conventional manner.) ... xk) S For cent . halt, we get~ seq env [xk+~/id] (return-pointk p \nenv cent xl . . . xk) s return env halt x s -> halt xsNotice how the code for the Drocedure has been \ninstalled in the seq r-egister, the and the machine halts. In the other case, env register has been updated, \na new we get return frame established in the cent register, and the local stack emptied. return env (return-pointk \np env cent xl ,.. xk) lf xk-, is a real value in V > K ->C, rather than a closure, then the Xs machine \nmust be able to apply it. Such > return-pointk p env cent xl . . . xk x s values correspond to primitive \noperations > penv cent xl ... xkx s which were in the initial environment. Dk(fetch > P id, env P) env \ncent Cent xl . . . Xl xk . . . (env Xk s id) s Dk(add, > P) enV COnt Xl . . . xk+2 S p env cent xl . \n. . xk (xk+l+xk+2) s Dk(pUShprOC + p id Seq, env cent p) xl enV COnt Xl . . . xk (closure . . . Xk s \nid seq env) S Dk(iOt, > p) enV COnt xl . . . xk+l p env cent xl . . . xk x s s Dk(apply, -> return \nP) env cent seq envl[arg/id] env halt x s + xl halt . . . xk (closure (return-pointk x s id p seq env \nenv ) cent arg xl s . . . xk) s return > env p (return-pointk env cent xl . . . p xk env x s cent xl \n. . . xk) x s Table 3. The Machine 239 Note how the calling routine has been restarted, with the return \nvalue pushed onto its stack. Having completed this analysis, we can construct a machine which operates \nby simulating these reductions, keeping the form (1) spread across registers as suggested above. The \naction of the machine is summarized in Table 3. Note that closure and return-point are combina\u00adtors, \nso the machine processes them by building appropriate data structures, but (env id) and (xk+l + xk+2) \nare intended to indicate that the actual values are pushed on the stack. This optimized reduction machine \nthus operates just as a conven\u00adtional stack machine does. We have, how\u00adever, derived it directly from \nthe language definition, rather than using any a priori notions of machine architecture or operation. \n6. Correctness In what sense is this machine cor\u00adrect? The machine simulates reduction in the lambda-calculus, \nso (by the Church-Rosser Theorem) it always gives the right answer,!! that is, the answer specified by \nthe semantics. This establishes partial correctness. What remains is to show that the machine halts sufficiently \noften, that is, whenever the term which is its initial configuration has a normal form. (Again, for some \nversions of denotational seman\u00adtics this condition is not strong enough, but for the kinds of problems \nwe are con\u00adcerned with it seems to suffice.) If our machine simulated a normal (leftmost-outermost) \nreduction, then it would always find the normal form whenever one existed, by the well-known theorem \n[31. Unfortunately, the reduction which our machine simulates is not normal-order, because !Iprimitive \noperationstt such as addition are performed immediately, rather than being carried along, as normal order \nwould demand. The machineTs reduction is. however, SXSB.LUQIY QLL.!?IXM2SL, in that every outermost redex \nis eventually re\u00adduced. A theorem due to O Donnell [11, p. 71] states that if a term has a normal form, \nthen every eventually outermost reduction halts. Hence, whenever the initial configuration has a normal \nform, our machine will reach it. It is there\u00ad fore totally correct. 7. Related Work/Extensions/Limitations \nThe idea of translating to lambda\u00adexpressions and then reducing to normal form is the basis of much of \nthe current work in semantics-directed compiler gen\u00aderation [6]. The fly in the ointment is that the \nlambda-calculus terms tend to be very large, and the resulting reductions highly inefficient compared \nto the per\u00adformance of the average (even non-optimi\u00adzing) compiler. Several workers have sought ways \naround this problem. Mosses [91 and Jones [7] have attempted to treat the lambda-calculus terms as programs \nand optimize them prior to execution. Turner [171 translates the lambda-calculus terms into the language \nof combinators [3]; the resulting combinator terms are simpler to reduce, so the reduction algorithm \ncan be more efficient (it has even been implemen\u00adted in hardware [2]). Raskovsky and Collier [131 also \nconsider a variety of specializations which allow efficient implementations. Raoult &#38; Sethi [121 \nhave considered the use of combinators as !Ipipes!l in the conversion from direct tO continuation semantics. \nIn [181, we used the technique of combinators to develop a display-based architecture for the example \nlanguage, using a somewhat different method to de\u00adrive the action of the machine. In [191, we used these \ntechniques on the benchmark language proposed by L. Morris [8, 10, 161, including while looPs, conditional \nstatements, and a primitive block struc\u00adturing mechanism. We can implement loops by circular structures \nin the code [14], though the correctness proofs then require some additional care. Escapes, catches, \netc. present no difficulties. The seman\u00adtic structures, and hence the abstract machine architectures, \nfor the usual languages, such as Algol, Pascal, Lisp, or Scheme, are all minor variants on the structure \nof our examples (though the basic operations may be different in\u00addeed!). We see no conceptual obstacle \nto performing the same kind of analysis for Micro-Planner [4] or Prolog, though the resulting machines \nmay look quite dif\u00adferent. The method in its current state has some limitations. We do not yet treat \nmodel-dependent functions in the semantics (e.g. checking for membership in a sub\u00addomain). Also, we do \nnot yet deal with the important issues of storage management; this seems best treated as an addi tional \nlayer of rePresentation or simulation [191. We are currently at work on these problems. 8. Conclusions \nWe have shown how the semantic equa\u00ad tions for a programming language can be massaged to yield a compiler \nand an archi\u00ad tecture for a target machine for the language. We do this by choosing appro\u00ad priate combinators \nto represent the lambda-calculus terms given by the seman\u00ad tics. The machine then becomes a syntac\u00ad tically \nvinegared version of a reduction machine. 13. Raskovsky, M., and Collier, P. !From References 1. 2. \n 3. 4. 5. 6. 7. 8. 9. 10. 11. 12.  Standard to Implementation Denota-ItTCoLAda and the Mid\u00ad \ntional Semanticsft, in Semantics- Brosgol, B.M. Directed Compiler Generation (N. D. dle End of the \nPQCC Ada Compilertt . .. . cd.) Springer, Berlin, 1980. Jroc. ACM-SIGPLAN SvmDosiumu &#38; Jones, ~ \nProgramming Languages, SIGPLAN I!Circular Expressions:Notices E, 11 (November, 1980), 101-14. Sethi, \nR. 112. elimination of static environments! Automata. Lan~uas!es. and Programming, Clarke, T., P. Gladstone, \nC. Maclean, ~ Colloauiu&#38; ~. Lecture Notes and A. Norman. SKIM-The S, K, I in Computer Science, vol. \n115, Reduction Machinetr Proc% 1980 LISP Springer, Berlin, 1981. m. , 128-135. 15. Stoy, Joseph E. Denotational \nSeman-Curry, H. B., and Feys, R. Combina-tics. ~ Scott-Strachev ADproach ~ ti J&#38;2&#38;2, Vol. 1. \nNorth-Holland, ~ramming L@ggu@gE lllfQ~Y MIT Amsterdam, 1958. Press, Cambridge, MA, 1977. 16. Thatcher, \nJ. W., Wagner, E. G., and Federhen, S. 11A Mathematical Seman-It More on Advice On Wright, J. B. tics \nfor PLANNER M.S. Thesis, Structuring Compilers and Proving University of Maryland, 1980. Them Correct!! \nTheore.t. Comp% Sci. 15 (1981), 223-249. Gordon, M.J.C. ~ Denotational ~ cri~tion of Programming Languages, \nMA New Implementation 17. Turner, D. A. Springer, Berlin, 1979. Technique for Applicative Languagesll \nSoftware: f!~~~~~~c ~llf! 12LJ2s~izIlGg 9 Jones, N. D. (cd.) Semantics-Direc\u00ad (1979), 31-49. Q@ Compiler \nGeneration, Lecture Notes in Comp. Sci. , vol. 94, 18. Wand, M. !lDeriving Target Code as a Springer, \nBerlin, 1980. Representation of Continuation Seman\u00ad tics,!! to appear, Ml! T.L~G&#38; SH2 Jones, N. D., \nand Schmidt, S. l! Com-Pro!z. Lang. and ~y~ piler Generation from Denotational SemanticsT! in Semantics-Directed \n~ IvDifferent Advice on Struc\u00adwoG~:eration (N.D. Jones, cd), turing Compilers and Proving Them .-. Springer \nLecture Notes in Correct Indiana University Computer Computer Science, Vol. 94 (Berlin, Science Department, \nTechnical Report 1980). No. 95 (September, 1980). 19. Wand, M. Morris, F. L. ItAdvice on Structuring \nCompilers and Proving Them Correctt! Proc. ~ SvmR. ~ Princi~les ti ProEramminR Languages (Boston, 1973), \n144-152. tlMathemati~al Semantics Mosses, P. D. and Compiler Generationtt, D. Phil thesis, Oxford Univ., \n1975. Mosses, P. D. 11A Constructive Ap\u00adproach to Compiler Correctness t, &#38; tomata~ Languages, ~ \nProRramminE&#38; Seventh Colloquium (1980). O Donnell, Michael. Computing _Ql Described Q Eauations, \nSpringer Lecture Notes in Computer Science, Vol. 58, Springer, Berlin, 1977. S!L@2m IIon Raoult, J. \nC., and Sethi, R. metalanguages for a compiler genera\u00adtor: properties of a notation for combining functions!!, \nmanuscript, Bell Laboratories, Murray Hill, N.J. (JuIY, 1981).  \n\t\t\t", "proc_id": "582153", "abstract": "We show how to analyze the denotational semantics for a programming language to obtain a compiler and a suitable target machine for the language. We do this by rewriting the equations using suitable combinators. The machine operates by simulating the reduction sequences for the combinator terms. The reduction sequences pass through certain standard forms, which become an architecture for the machine, and the combinators become machine instructions. Despite the abstract nature of its development, the machine greatly resembles a conventional one. The method is illustrated by a simple expression language with procedures and input-output.", "authors": [{"name": "Mitchell Wand", "author_profile_id": "81100072594", "affiliation": "Indiana University, Bloomington, Indiana", "person_id": "PP39025873", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/582153.582179", "year": "1982", "article_id": "582179", "conference": "POPL", "title": "Semantics-directed machine architecture", "url": "http://dl.acm.org/citation.cfm?id=582179"}