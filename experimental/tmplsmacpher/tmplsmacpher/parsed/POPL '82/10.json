{"article_publication_date": "01-25-1982", "fulltext": "\n Experience With An Attribute Grammar-Based Compiler Rodney Farrow Intel Corporation Santa. Clara, California \n95051 Abstract Experience writing a production compiler based on an attribute grammar is related. The \ncompiler is Intel Corporation s Pascal-86 compiler which runs on a microcomputer-based system. An attribute \ngrammar was written describing semantic analysis, storage allocation and translation to intermediate \ncode. Attribute evaluation is done in two alternating passe$ [J~and the program tree is kept in intermediate \nfiles on disk. Various techniques for optimizing the evaluator were tried. Their succes~ is reported \nand compared w th other ideas from the literature. Introduction In the past few years attr bute grammars \nCK1 have been discussed in the ii~erature as a basis for compiler\u00ad writing-systems [S],[F], [G RkJ],[L~, \n[Ral] . Host of the attention has been focused on attribute-evaluati on models and on testing the evaluability \nof an attribute grammar according to some particular model. Less attention has been paid to actually \nwriting an attribute grammar for a real language and looking at what sort of compilers would be generated \nfrom it. This paper relates our experience of writing an attribute grammar for Pascal and then implementing \na compiler based on this attribute grammar by using a particular attribute-evaluation scheme. The compiler \nin question is Intel s Pascal-86 compiler. It generates code for the iAPX-8086 microprocessor and is \nhosted on an 8086 based micro\u00adcomputer system. Permission to copy without feeall or part of this material \nis granted provided that the copies are not made or distributed for direct commercial advantage, the \nACM copyright notice and the title of the publication and its date appear, and notice is given that copying \nis by permission of the Association for Computing Machinery. To copy otherwise, or to republisb, requires \na fee and/or specific permission. The compiler runs in 96K of memory and uses floppy diskettes for temporary \nfiles and for the output. The language supported is a slight superset of the ISO draft standard for Pascal \n[ISO~; the principal extensions are a separate compilation facility, allowing the use of new built-in \nfunctions that are useful in a microprocessor environment. The Pascal\u00ad86 compiler is neither a toy [Rolrlor \nan academic exercise, rather it is one of Intel s three production compilers that support the iAPX-8C186. \nThe attribute grammar specifies the phases of the compiler that do semantic analysis, storage allocation, \nand translation to intermediate code. These three phases of the compiler are collectively referred to \nas the SEHfl,NTICIST. The outputs of the SEHfl,NTICIST are: 1) a list of intermediate code that is the \ncode generator s input, 2) a list of sc!mantic errors and warnings, 3) a list of cross-reference transactions, \n4) a set of literal constants that will be nemory-resident at run-time and the storage locations that \nneed to be initialized to these values, 5) a set of user-defined and predefine objects ~:~g~d;;gja~;~s~u~;~::~s~~med \nconstants 6) a set of procedure-objects that have been designated to field particular interrupts, 7) \na set of objects of the compilation unit whose name s are known beyond the compilation units, and 8) \na partial function that maps some objects (e.g. variables, Parameters and memory-resident constants) \nto their run-time addresses. ~~e decided to use attribute grammars because we thought they were a good \nspecification tool and because we anticipate automatically generating much of the compiler at a later \ndate. Consequently, though the SEMANTICIST was @ 1982 ACM O-89791-065-6/82/OOl/O095 $00.75 not automatically \ngenerated, we definitely wanted the implementation to be faithful to the attribute grammar that was its \ndesign. To this end the implementors strove to write the actual high-level language source code of the \nSEMANTICIST as a mechanical translation of the attribute grammar according to our attribute evaluation \nparadigm. Optimization of this code were allowed only so long as they could be exactly specified and \nuniformly applied. The resulting software is 20,000 lines of high-level language source code and 58,000 \nbytes of machine code. The SEMANTICIST is spread ac~oss two passes and two overlays of the compiler, \nand cost 18 man-months of design and implementation effort. The rest of this paper is organized into \nfiIJe sections. To introduce terminology the first. scct~on gives a brief overview of attribute grammars. \nThe second section presents our attribute evaluation paradigm and our implementation strategy. In the \nthird section we discuss some of the major problems that we encountered, both in writing the attribute \ngrammar and programming its implementation. In section four we talk about the insights that we have gained \nfrom this effort. A final, brief section presents our conclusions. I. An Attribute Grammar Glossary An \nattribute grammar is a context-free grammar augmented with ATTRIBUTES and SEMANTIC FUNCTIONS. The attributes \nare associated with the symbols (terminal and non terminal) of the context-free grammar. The semantic \nfunctions are associated with the productions. An ATTRIBUTE-OCCURRENCE is an attribute of some particular \noccurrence of a grammar symbol in a given production. An occurrence of an attribute is written S.A where \nA is an attribute of symbol S. Semantic functions of production P specify how each attribute-occurrence \nassociated with production P is defined. This value can be computed from the value of other attribute-occurrences \nof the production. An important special case of semantic functions is the COPY-RULE: a semantic function \nof the form X.A = Y.B Each attribute is either INHERITED or SYNTHESIZED. The STARTSYMBOL of the ~ttr;but~ \ngrammar has no inherited attributes, and a terminal symbol has no synthesized attributes. Inherited \nattributes can pass information down the tree, from the root towards the leaves; synthesized attributes \ncan pass information up the tree. The semantic functions associated with a production must define all \nsynthesized attribute\u00adoccurrences of the left-hand-side of the production and all inherited attribute\u00adoccurrences \nof the right-hand-side of the production. Furthermore, they can not define any inherited attribute-occurrence \nof the left-hand-side or any synthesized attribute-occurrence of the right-hand\u00adside. In a well-formed, \nreduced grammar every symbol, except a terminal s:{rnbol, is the left-hand-side of some production and \nevery symbol, except the startsymbol, belongs to the right-hand-side of some production. (Thus the restrictions \non the kinds of attributes of terminal symbols and the start symbol .) Figure 1 shows two productions \nfrom the Pascal-86 attribute grammar that apply at VarList symbols. Each production consists of a syntactic \npart and a semantic part. The syntactic part comes first and has the form of a context-free production \nfollowed by a special symbol + followed by an identifier followed by a peridd. The extra identifier serves \nto uniquely identify the production. The rest of the production is the semantic part. It consists of \na sequence of semantic functions, separated by commas. ,An attribute grammar is EVALUATED on a particular \ninput by: -buildinq a parse-tree for the input in which every node corresponds to a grammar symbol and \nhas fields corresponding to the attributes of that grammar symbol, and walking over this tree and defining \nfields of the nodes by calling semantic functions, using the value of other node fields as arguments. \nThe result of the evaluation is the value(s) of synthesized attribute fields of the root node. The parse \ntree for the input, including the attribute fields, is called the APT (Attributed Parse Tree, Attributed \nProgram Tree, Abstract Program Tree, etc.) These fields are called ,4TTRIBUTE-INST,4NCES. An attribute-instance \nof an interior node of the tree is naturally associated with two attribute.occurrences , one for tbe \nproduction that applies at this APT node and one for the production that applies at the father of this \nAPT node. The computation of values is associated with productions and the attribute-instances of a node \ncommunicate information between productions. An attribute grammar has LOCALITY of REFERENCE. There are \nno global variables . If values computed in one part of the APT need to be used to define attribute-instances \nin another part then a chain of attribute-instances must exist between them. For this reason an attribute \ngrammar usually includes many copy-rules. An attribute grammar is a NON-PROCEDURAL specification; not \na program. Attribute\u00adinstances are not variables; they are names that represent values. Attribute\u00adinstances \nare defined by semantic functions. These are pure functions whose arguments are constants and other attribute-instances \n. Once an attribute\u00adinstance is defined its value will not change. VarList ::= TypeSpec+ VarListType. \nT,y,peSpec.SCOPE NAME = V=rList. SCOPE_NAME, TypeSpec.PUB EXT LOC = Var~is t.PUB_EXT_LOC, TypeSpec.CIRCULAR \nLIST = VarL~st. CIRCULAR_LIST, TypeSpec.SYMS = VarList.SYMS, TypeSpec.NAME = null_name, TypeSpec.PACKED \n= false, TypeSpec.NEED ORD = false, VarList. TYPE ~ TypeSpec.OBJ, VarList. DEFS = TypeSpec.DEFS, VarList.TOO \nBIG = (widthof(T~peSpec.OBJ,VarList .SYMS) = OVLwidth), TypeSpec.ERRS I = VarList.ERRS_I, VarList. ERRS \n~ = TypeSpec.ERRS O, TypeSpec.XRE~ I = VarList. XREF I, VarList. XREF_~ = TypeSpec.XREF~O VarListO :: \n= ID VarListl+ VarListId. VarListl.LEVEL = VarListO~LEVEL, VarListl.SCOPE NAME = ~arListO.SCOPE NAME. \n VarListl.PUB_EXT LOC = Va~ListO. PUB EXT_LOC, VarListl. CIRCULAR LIST = Var~istO .CIRCULAR_LIST, VarListO.TYPE \n= VarListl. TYPE, VarListO.TOO BIG = VarListl.TOO BIG, 0!3J = GenObj~ar( ID. INDEX,VarLis tl.TYPE), VarListO. \nDEFS = cons (OBJ,VarLi stl. DEFS), VarListl.SYMS = VarListO.SYFIS, ERRNUM = if lookup(VarLi stO.SYMS, \nI D.INDEX) OBJ then mult def_error elsif VarListl.TOO BIG th~n var_too big error else no erro~ endif, \nVarListl.ERRS_I = VarListO.ERRS_I, VarListO.ERRS O = ConsErr( Var~istO.LOC, ERRNUM, ID. INDEX, VarListl.ERRS \nO), VarListl. XREF I = VarLi~tO. XREF_I, VarListO.XREF~O = PutXrefDef(OBJ, VarListO.LOC, VarListO .SCOPE_NAME, \nVarListO .PUB_EXT_LOC, VarListl. XREF_O Productions for VarList Figure 1 These aspects of attribute \ngrammars make writing one different from writing a program in a high-level language: there are no explicit \nloops, attributes can not be incremented or reassigned, and there are many copy-rules. Control-flow is \ndetermined by a combination of the data flow specified by the attribute grammar and the evaluation strategy, \nnot by the order in which semantic functions are listed. Attribute grammars share many properties with \ndata-flow languages CD], and with single-assignment languages rC]. II. The Attribute Evaluation Strategy \n\\iJe use the strategy of evaluation in alternating passes proposed by Jazayeri [J~. Ourattribute grammar \nis evaluable in t wo passes using this strategy, a left\u00ad to-right pass followed by a right-to-left pass. \nFor alternating pass evaluation there is a simple strategy, described by Schulz [s] that allocates most \nof the APT to seco~dary storage and that achieves both prefix and postfix visits to every reason we use \nalternating pass evaluation is to take advantage of this. The evaluation strategy calls for storing a \nlinearized version of the APT in an intermediate file on sequential, backing storage (i.e. disk or tape). \nWhen an APT node, N, is encountered during the course of attribute evaluation it is read from the intermediate \nfile into a stack in main memory. N is kept on the stack while the sub-tree descended from N is visited \n(and those nodes get put on the stack below !!) and attribute-instances in that subtree are assigned \nvalues. The evaluation OF the sub-tree may use the values of some attribute-instances of N and may define \nother attribute-instances . INhen the !2V2ilUatiOtI pass over N s subtree has finished node N is written \nto the intermediate file. Because of the evaluation order, the nodes of N s subtree will have already \nbeen written to the file. The SEMANTICIST S paradigm for APT traversal and attribute evaluation in a \nleft-to-right pass is given below for one production. Depicted is the process of visiting the sub-APT \nwhose root is an the paradigm would be the seine except that right-hand-side nodes would be visited in \nthe order Xn, . . ..X2.Xl. XO::=Xl X2. ..Xn. read attributes of Xl from input APT file evaluate inherited \nattributes of Xl for this pass visit the sub-APT whose root is Xl write attributes of Xl to output APT \nfile read attributes of X2 from input APT file evaluate inherited attributes of X2 for this pass visit \nthe sub-APT whose root is X2 write attributes of X2 to output APT file read attributes of Xn from input \n,4PT file evaluate inherited attributes of Xn for this pass visit the sub-APT whose root is Xn write \nattributes of Xn to output ,4PT file evaluate synthesized attributes of XO for this pass return from \nvisiting the sub-APT whose root is XO This model of attribute evaluation requires reading nodes from \nthe input intermediate file in prefix order and writing them in postfix order. The output file of one \npass is the input file for the next pass. The direction of the passes alternates and the intermediate \nfiles are read backwards. The reverse of a postfix, left-to-right ordering of the nodes of a tree is \na prefix, right-to-left ordering, and vice versa. This trait is illustrated in Figure 2. In the Pascal-86 \ncompiler the intermediate files are used to store the APT are always written forward but read backward. \nNotice that this method of keeping a linearized version of the APT in an intermediate file hinges on \ndoing attribute evaluation in alternating passes. The attribute evaluation strategy does not tell how \nto build the first linearized APT file. There are two approaches that fit immediately in the evaluation \nparadigm. The ffrst approach is for the parser to emit tree nodes in bottom-up order. This creates an \nintermediate APT file that is identical to what would have been created by a left-to-right attribute \nevaluator. No attribute evaluation can be done according to the evaluation paradigm because there is \nno prefix encounter of these nodes. The first semantic evaluation pass is right-to-left. The other approach \nis for the parser to emit nodes in prefix order, e.g. like a recursive descent parser. Accepting the \nnext node from the parser takes the place of reading the next node from the input intermediate APT file. \nIn this case, evaluation of semantics can be done during the same pass as parsing, and the first semantic \npass is a left-to-right pass. The Pascal-85 compiler uses a modification of the second strategy. It is \nmodified because the compiler s LALR parser does not generate prefix nodes for expressions; the phrase \nstructure necessary to generate prefix recognition of infix operators is awkward for semantic analysis. \nOur Attribute Evaluation Paradigm M ] It tti L II I IIt BEHK t% IJ prefix, postfix, left-to-right + \n+ riaht-to-left MF: AC EDG LH~I J postfix, prefix, left-to-right -+ -right to-left If AC BDE FGH IJKL \nOrder of APT Nodes For Al ternat ng Passes . Figure 2 During the first pass, when the SEMANTICIST expects \nan expressi n it starts accepting APT nodes from the parser and immediately writes them out until it \nfinishes with ~he expression. The parser gQnQrate5 a right parse of all expressions, i.e. a postfix, \nleft-to\u00adriaht linearization of the APT. The SEfiANTICIST would have written these nodes in the same order \nif a left parse for expressions had been generated, so the resulting APT file is ready for right-o\u00adleft \nevaluation during the second pass The overriding reason for this hybrid strategy was to allow semantic \nevaluat on to be done during the first pass, thus reducing the number of passes that the compiler must \nmake. The code that reads/writes APT nodes and evaluates semantic functions is organized as a set of \nmutually recursive procedures called production-procedures . The name is somewhat of a misnomer since \nthere is one procedure for each non-terminal of the attribute grammar, rather than for each production. \nEach production-procedure has one IN/OUT parameter, an APT node. The body of each production-procedure \nis a single case statement. The production\u00adprocedure for non-terminal X has one case\u00adelement for each \nproduction whose left\u00ad hand-side is X. There are distinct sets of production-procedures for each pass. \nSpace for those APT nodes that correspond to the production s right-hand-side are allocated as local \nvariables of a production-procedure. Thus, the stack of APT nodes is intermixed with the system run-time \nstack that supports procedure call/return, parameter passing, and recursion. This is similar to the organization \nof a recursive descent compiler. The non-terminal-procedures that constitute a recursive descent compiler \ncould be integrated with the first pass production-procedures. (In fact, we did this for one small tool \nthat was written at the beginning of the project). Figure 3 is the pass 1, left-to-right production-procedure \nfor the non-terminal VarList of Figure 1. By convention the name of the production-procedure corresponding \nto symbol FOO in pass 1 is FOO_PPi. We deviated from production-procedure model in Figure 3 when it was \nnecessary as a practical matter, e.g. the inability of our implementation language to define functions \nthat return record values. We also experimented with various modifications of the production-procedures \nto improve the efficiency of the SEMANTICIST. As mentioned in the introduction, these were not ad hoc \nimprovements; they were attempts to formulate widely applicable adjustments to the production-procedures \nand to implement them uniformly. One important and obvious optimization is to reduce the amount of data \ntransferred between the intermediate files and memory by not writing attribute-instances that will never \nbe referenced after the current pass. The majority of attributes are referenced only in the same pass \nin which they are defined. In a two pass evaluator this means that we need to write to the intermediate \nfile only those attributes that are defined in pass 1 and referenced in pass 2. The effect of not writing \ndead attribute-instances to the intermediate file turns out to be very similar to an evaluation strategy \nsuggested by Saarinen ~;~ , Saarinen ro oses for any tree\u00ad evaluator KW that attributes be ii divided \ninto significant attributes and temporary att~ibutes. An attribute is significant if it is referenced \nin a later visit than the one in which it was defined; otherwise it is temporary . Significant attributes \nare kept in the data structure for a node (roughly corresponding to the file-resident APT in the SEMANTICIST) \nand temporary values are kept on a stack (the SEMANTICIST s stack-resident local variables of production-procedures). \nprocedure VarList_PPl (VarListO : IN OUT VarList_type) is begin case VarListO.PROD is -- VarListO ::= \nTypeSpec+ VarList. when VarListType = declare TypeSpec : TypeSpec_type; begin GetNode (TypeSpec_node, \nTypeSpec); --define inherited attribs TypeSpec .SCOPE_NANE := VarListO .SCOPE_NAME; TypeSpec. PUB_EXT \nLOC := Var~istO. PUB EXT_LOC; TypeSpec.NAME := null_nam~; TypeSpec.PACKED := false; TypeSpec. NEED_ORD \n:= false; TypeSpec_PPi( TypeSpec ); PutNode( TypeSpec_node, TypeSpec); --define synth attribs of VarListO \nVarListO.TYPE := TypeSpec.OBJ; VarListO.DEFS := TypeSpec. DEFS; end; VarListO ::= ID VarListl+ VarID. \nwhen VarListID = declare ID : ID_type; VarListl : VarListl_type; begin GetNode(ID_node, ID); --define \ninherited attribs of ID IDPPi( ID ); Pu~Node(ID_node, ID); GetNode( VarList_node, VarListl); --define \ninherited attribs VarListl. LEVEL := VarListO. LEVEL; VarListl .SCOPE_NAME := VarListO .SCOPE_NAME; VarListl.PUB_EXT \nLOC := VarL~stO .PUB_EXT_LOC; VarList PPi( VarListl); PutNode~VarLi st_node, VarListl); define synth \nattribs of VarListO VarListO.TYPE := VarListl.TYPE; OBJ := GenObjVar( ID. INDEX, VarListl. TYPE) VarListO. \nDEFS := cons (VarListO. OBJ, VarListl. DEFS); end; End Case; end VarListO_PPl; Production-procedure for \nVarList Figure 3 Another optimization is to nest the production-procedures within one another when possible. \nWe hoped to avoid explicitly passing a pointer to the left\u00adhand-side record as an argument to the nested \nproduction-procedure ; references to left-hand-side attribute-instances would be up-level variable references. \nThis was not an effective optimization, partly because the improvement it provides is miniscule, but \nmostly because it was so rarely applicable. Y_PPi can be nested within X_PPi only if the only right-hand\u00adside \noccurrences of Y are in productions whose left-hand-side is X. Our attribute grammar has very few such \noccurrences, and no instances of this optimization survive in the production-procedu res. The last optimization \nwe ll discuss is called static subsumption . Its effect is to eliminate copy-rules. Static subsumption \nwas correctly formulated only after reexamining the attribute evaluation paradigm. The paradigm calls \nfor allocating on the stack the memory to store attribute-instances by making them local variables of \na recursive procedure. Right-hand-side attribute-instances are directly addressable as local variables \nof the corresponding production-procedures. The left-hand-side attribute-instances are referenced through \na pointer that is passed as an argument to the production\u00adprocedure. This pointer represents the only \ncommunication between the various production-procedures. An alternative to passing a pointer is to copy \nthe attribute-instances of a node into a global memory area just prior to calling the production-procedure \nand then, after returning from that call, copying these attribute-instances back to the local, stack-resident, \nvariables. Only already defined attribute-instances need to be copied to the global variable, and only \nnewly defined (i.e. synthesized) attribute-instances need to be copied back. If the attribute S.A. is \nalways copied to a specific global variable, S_A, before the production-procedure for S is called then \nS_PPi can always reference this global variable to get the value of the left-hand-side attribute-instance. \nSimilarly, if S PPi defines attribute S.B and assigns the value to a global variable, S_B, then any production\u00adprocedure \nfor a production with S in the right-hand-side can reference this global variable, either to copy it \ninto the local variable or to simply use it in the evaluation of semantic functions. In most cases, copying \nattribute-instances back and forth is more expensive tham passing a pointer and making indirect references \nthrough it. However, if the semantic function that defines an attribute-instance is a copy-rule whose \nright-hand-side is a different instance of the same attribute then no explicit code is required to implement \nthis semantic function. The proper value is already in the global variable. Furthermore, the global variable \nneed not be saved/restored. The attribute evaluator can be selective about which attributes it causes \nto be copied-restored, doing this only for attributes that are both the source and target of a copy-rule. \nConsider the following two productions. s ..= + NullListProd. S:DEFS = S.PRE; s ::= X S1 + ListProd. \nS1.A = S.A, X.A = S.A, S.DEFS = S1.DEFS, S1.PRE = UnionSetof(S .PRE,X.OBJ); Figure 4 shows the production-procedure \nproduced by the original atribute evaluation paradigm (a), and the producti on-orocedure with the static \nsubsumption optimization applied (b). A penalty is paid for eliminating this explicit copying, but it \nis paid at the points where the affected attributes are not the right-hand-sides of copy-rules. Suppose \nA is an inherited attribute of S and some right-hand-side occurrence of S.A is not defined by copying \na left-hand-side occurrence of S.A. Then the value of the global variable S_A must be saved, the right-hand-side \noccurrence of S.A must be moved to the global variable, and after returning from S PPi the saved value \nof the global varia~le restored. Static subsumption can be even more widely applied by passing the values \nof all attributes with the same name and type in a single global variable corresponding to the pair (attribute \nname, attribute type). Again, a production-procedure S_PPi would assume that attribute-instance S.A was \npassed in global variable A iff S.A was both the source of some copy-rule Y.A = S.A, and the target of \nanother copy-rule S.A = X.A. Many more copy-rules can be eliminated by such a rule. On the other hand, \nglobal variables may have to be saved-restored more frequently. Experience with the Pascal-86 attribute \ngrammar shows that this is a very good optimization. An enormous amount of context information (nesting \nlevel, module name, symbol table for this scope, . ..) is transmitted down the tree via inherited attributes \ndefined by copy rules. Such copy-rules are eliminated with very little cost because this context information \nis not updated often. procedure S_PPi (S : IN OUT S_type) is Static subsumption also reduces the amount \nbeuin of stack space needed to store attribute\u00adC&#38;e S PROD is instances. If a collection of attribute\u00ad.- \nS ::= + NullListProd instances is being used only to transmit when NullListProd+ information around the \nAPT via copy-rules begin then explicit fields in the record that S.DEFS := S.PRE; represents the APT \nnode need not always be end; allocated. This can result in significant decrease in the size of the local \nvariables .- S ::= X S1 + ListProd. that hold APT nodes. when ListProd+ declare Static subsumption has \nsome elements in x: X_ty pe ; common with a method investigated by S1 : S_type; Ganzinger ~G] . Ganzinger \nsuggests trying begin to allocate attribute-i n~tances to Get.Node~X3n~de, X); statically defined variables. \nHis purpose X.A . ; is to conserve storage by allocating many X_PPi( X ); attribute-instances to the \nsame m~mory PutNode(X_node, X); location and to eliminate copy rules. However, he tries to do such al!ocat~on \nGetNode(S_node, S); independent of an attribute evaluation S1.A := S.A; strategy and his results are \npessimistic. S1.PRE := He shows that is is a hard problen to UnionSetof( X.OBJ,S. PRE); automatically \ndetermine good allocation s_PPi ( s ); functions and he suggests having the PutNode(S_node, S); author \nof the attribute grammar supply the allocation function and then automatically S.DEFS := S1.DEFS; checking \nwhether these are feasible. end; End Case; The SEMANTICIST s static subsumption End S_PPi; optimization \nis more effective then Ganzjnger s proposal because it is (a) Original production-procedure paradigm \ntailored to a particular evaluation strategy, the so-called tree-walk declare evaluators CKW] . Furthermore, \nstatic XA,SA : A_attribType; subsmuption permits saving and restoring SjDEFS : DEFS_attribType; the values \nin global variables. procedure S_PPi (S : IN OUT S_type) is 111, Problems We Encountered beain C~se \nS.PROD is This section describes four problems we .- S ::= 4 NullListProd. ran into while implementing \nthe when NullListProd 9 SEMANTICIST. These were not our only begin problems, but they were among the \nmost. S.DEFS := S.PRE; interesting. At one point or another each of these problems end; made us reconsider \nwhat we meant by a compiler based on an --s ::= X S1 + ListProd. Perhaps at~ribllte grammar + when ListProd* \nsignificantly, only the first problem has declare a resolution with which we are completely x X_type; \ncomfortable. S1 ~ S_type; begin The first of the four problems concerns GetNode(X node, X); the form \nof semantic functions. For the =~A; purpose of formally defining attribute x &#38;( x )7 grammars a semantic \nfunction is just that, PiitNode(X_node, X); a function. It has a name, takes arguments, and returns a \nresult. For the GetNode(S node, S); purposes of specifying semantics or --S1.A := S.A eliminated writing \na compiler we found this to be S1.PRE := UnionSetof( X.OBJ,S. PRE); restrictive. The original version \nof the S_PPi( S ); Pascal-86 attribute grammar had many PutNode(S_node, S); semantic functions that were \neach used in --S.DEFS := S1.DEFS eliminated just one or two places. These functions end; tended to have \nmany arguments and be very End Case; ~jmple. Furthermore, the most natural and End S_PPi succint expression \nof the function (b) with static subsumption frequently required that it return Figure 4 multi~le values. \nBecause our implementation language did not allow functions to return multiple values and because the \nmanagement of so many small functions became unwidely, they were replaced by in-line code within the \nproduction-procedures. To accommodate this the syntax of semantic functions that we allow in attribute \ngrammar specificat-ons was expanded to include multi-valued expressions that could include some arithmetic \noperators and conditionals An examDle is : x, Y, z= ifA+l>5 then A+l, O, NullObj else 1, A, LookUp(SYMS,NAME) \n endif Furthermore, it was often useful to compute a value with a semantic function but only use this \nvalue as an argument of other semantic functions associated with the same production. Attributes are \nused to transmit information around the APT, but sometimes we needed a private (to this production) value \nin order to avoid repeating a calculation, or to hold a value that is computable in one pass but not \nused until a later pass. To accommodate this our attribute grammar allows simple names (i.e. FOO rather \nthan X.Y) to be the left-hand-side of semantic functions, and to be referenced in the right-hand-side \nof other semantic functions. Like attributes these can have but one value specified and can be written \nto/read from the APT file; unlike attributes thay are only accessible to the semantic functions of a \nsingle production. Examples are [RRNUV and OBJ in the VarListId production of Figure 1. The readability \nof the attribute grammar improved markedly after this notation was adopted. A concern of most attribute \ngrammar researchers is how to avoid creating and copying around many many instances of large values such \nas sets, sequences, partial functions, relations, etc. This was a problem we encountered early in the \ndevelopment of the SEMANTICIST. A frequently proposed ~S] [Ra] measure is to build these complex values \nin a separate date space and to let the attribute\u00adinstance fields in APT nodes be pointers to these values. \nCopy rules can then be implemented by copying pointers instead of by copying the list or array that represents \na set. This can be viewed as a simple bit of data abstraction. We expand on this abstraction by involving \nthe semantic functions (besides copy rules) that manipulate these high level data types. In the SEMANTICIST, \ncollections of semantic functions are grouped together to form simple abstract data types. There are \nfunctions to create new values of a type, to interrogate a value, to combine values, etc. and these functions \ntake care of all the bookkeeping behind the internal representation of these values. The external representations \nof such values are one word wide. Data abstraction is a very popular and widely-used software development \ntechnique, but there are some unexpected consequences of using it in an attribute grammar. Attribute-instances \nare values, not variables, so a semantic function that has a parameter of complex type (e.g. set, partial \nfunction) must take care not to change that value. Not changing the value includes not changing the internal \nrepresentation in any fashion that can be detected through the externally visibly semantic functions \nof the abstract data type. For example, when taking the union of two sets, the result must be represented \nin a manner that preserves the two set values ; i.e. pointers to the argument sets must still be valid \nafter the union operation is completed. TO do this the SEMANTICIST allocates another cell (sets are implemented \nas linked lists) that points to both sets and turns on a special flag in this cell. An important benefit \nof this approach is that creating a new complex value (set of definitions in a declaration list, symbol \ntable for a new scope) that differs little from other complex values (set of definitions in a sublist, \nsymbol table for an outer scope) requires only marginally more memory. For instance, the attribute grammar \nfragment in Figure 1 has a semantic function of the form VarListO. DEFS = UnionSetof( VarListO. OBJ ,VarListl. \nDEFS). This semantic function transmits DEFS, a ~J,nthesi~ed attribute, up the tree, DEFS is the set \nof all variable objects that are being declared by this VarList. Because the internal representation \nof VarList.l. DEFS is reused to represent VarListO. DEFS, the internal cell space needed to represent \nall of these intermediate set values is no more than the cell space needed to represent the final, resulting \nset. Another example of maintaining and reusing complex values is the mechanism, for looking up names \nin the symbol table to find the corresponding variable, type or whatever. It is implemented as a partial \nfunction that maps names to dictionary objects. There ~s a different partial function for every scope \nin the program. These various part.~al functions are the values of instances of several attributes (of \ndifferent symbols) whose names are SYMS. The SEMANTICIST implements a partial function as a list with \nan even number of elements on it. For each pair of elements, the second element is the value of the partial \nfunction applied to the first element. For the SYMS partial functions the further assumption is made \nthat if the list has more than one pair with the same first element then the value procedure call rather \nthan function evaluation, but with a little more overhead this effect could be specified with semantic \nfunctions. This is a very unsatisfying solution both because we don t reclaim all dead space and because \nit is a serious discrepancy between the compiler and its attribute grammar specification. of the partial \nfunction is specified by the pair that is closest to the head of the list. This last assumption makes \nit easy to update a SYMS partial function; just insert another pair on the front of the list. Furthermore, \nthe SEMANTICIST implements lists so that inserting elements at the front of the list does not disturb \nthe original list. Consequently any old pointers to that list remain valid for later or concurrent use. \nThe partial function that represents a new scope is formed by taking each dictionary object on the list \nof new definitions and inserting a (NAME,OBJ) pair onto the head of the SYMS partial function that represents \nthe immediately containing scope. The drawback to viewing complex data structures as immutable values \nis that they can t be destroyed and their space reclaimed. These values can be copied from one attribute-instance \nto another without using any of the semantic functions that are part of the abstract data type, and they \ncan be written to the intermediate file. Thus , it is difficult to tell that a complex value will never \nbe referenced again. Garbage collection in the SEMANTICIST is a serious problem. Raiha rRa] also describes \nallocating large attribute values in a separate data space and copying around pointers to these values. \nHe suggests doing grabage collection by having the attribute evaluator determine equivalence classes \nof attribute-instances that are copies of the same value and finding the last reference to this value; \ni.e. the last reference to an attribute-instance in the equivalence class. The data structure that represents \nthis set of partial function or whatever can be released and its memory reused after this last reference. \nWe did not chose to adopt this strategy, partly because it involves more overhead in the attribute evaluator \nand partly because the partitioning of attribute-instances into equivalence classes breaks down when \na single sub-value can be part of several different equivalence classes. The solution used in the SEMANTICIST \nis to. manually identify those attribute\u00adoccurrences that always hold dead values and to artificially \nrelease these values by calling a procedure that does so as a side-effect. For the sake of efficiency \nthe SEMANTICIST implements this as a Despite the problems with garbage collection, we feel that the ability \nto use large data items as a part of the values of many different attribute\u00adinstances is one of the key \nreasons the SEMANTICIST can be used in a production compiler on a small machine. Another problem was \nto make the Pascal-86 attribute grammar evaluable in two alternating passes. One important technique \ninvolved tweaking the underlying phrase structure of the attribute grammar. The technique should be quite \nfamiliar to readers who have designed phrase structure grammars that had to be LL(l) or LALR. There are \nmany equally valid attribute grammars for a programming language, just as (and sometimes because) there \nare many valid context-free grammars for the phrase structure of the language. In order to get the attribute \ngrammar to be evaluable in just two alternating passes we sometimes had to use awkward or artificial \nconstructions. The best way to see this is with an example. Consider once again the two productions O-F \nFigure 1. They describe a variable declaration list in Pascal. Originally we described this with the \nfollowing three productions. VarList ::= VarIdList COLON TypeSpec. VarIdList ::= ID. VarIdListO ::= ID \nCOMMA VarIdListl. These productions seem simple and they build a shallower APT (and hence use less stack \nspace in the evaluator). But we want to create dictionary objects for both types and variables during \nthe first pass. A type object is a component of a variable object and must be available before the variable \nobject can be created. The type object for a variable declaration is computed during pass 1 as a synthesized \nattribute of TypeSpec. In a left-to-right pass (as is our first pass) this attribute would not be computed \nbefore visiting the sub-APT corresponding to VarIdList, if the above phrase structure was used. Therefore, \nthe variable objects could not be created until the second pass. The productions of figure 1 avoid this \nproblem by making the TypeSpec subtree a descendant of the APT nodes that correspond to variables. The \ntype object is propagated back to these nodes through the synthesized attribute VarList.TYPE. The SEMANTICIST \nhas many such places, where careful attention to the form of the grammar was necessary to achieve two \npass evaluability. A fourth serious problem was how to implement the lists of intermediate language code \nand lists of errors and lists of cross-reference transactions that are the principal outputs of the SEMANTICIST. \nThese lists, especially the list of intermediate code, can be quite large; their size is of the same \norder as the size of the APT. To keep them in memory would require exorbitant amounts of memory and seriously \nrestrict the capacity of the compiler. Moreover the contents of these lists are never references by the \nSEMANTICIST. These lists should be intermediate files themselves, as is the APT, The SEMANTICIST implements \nthe lists of intermediate code as an abstract data type whose internal representations reside in a file, \nBut we want even more; the intermediate file should contain only the sequence of intermediate language \ntokens, in the proper order. In the attribute grammar we are careful to never combine two lists of intermediate \nlanguage. Lists are built by adding one or two intermediate language tokens to the front of an existing \nlist, The implementation of these semantic functions just writes out these tokens to the intermediate \nfile whenever they are added to a list. Since lists are never combined and since the process generates \njust one list there must be only one list ever build (or at least all but one list is thrown away). This \nmeans that the list to which a token is added must be the list of all tol(ens that will appear before \nit in the final list of intermediate code. To see how this is done, consider two consecutive statements \nin a list of statements. The APT fragment for this is shown below. StmtList-i 1 I 1 Stint-l StmtList-j \nI 11 Stmt-.i StmtList I . .. The intermediate code for Stmt-j must be at the head of the list to which \nstint-i adds its own intermediate language tokens To do this StmtList must have a synthesized attribute \n(ILR_O) that propagates this list from Stint-j, through StmtList-j, to Stint-i. Similarly, Stint must \nhave an inherited attribute (ILR_I) that accepts this list from StmtList-j and propagates it down to \nthe sub-APT whose root is Stint-i. Stint must also have a synthesized attribute (ILR-0) that transmits \nthe list with the intermediate code for Stint-i up the APT through the StmtList nodes to the previous \nStint. The attribute grammar fragment for this is : StmtListO ::= Stint StmtListl StmtListO. ILR O = \nStint. ILR O, StmtListl, ILR I = StmtList~.ILR I, Stint. ILR I = Stmt.ILR O StmtList ::= StmtList. \nILR_O = StmtList. ILR_I This sort of construction forces the semantic functions that generate intermediate \ncode to be evaluated in : uch an order that tokens are added to the list in the proper sequence. All \nnon-term nal nodes that oenerate intermediate code. or that derive-nodes that generate intermediate code, \nhave pairs of attributes ILR I, ILR O. The collection of the corresp~nding =ttribute-i nstances , taken \nover the whole APT, can be viewed as representing the intermediate-language file. Notice that the attributes \nILR_I and ILR O are defined during the second pass, a right-to-left pass. This means that intermediate \ncode is generated on the fly , backwards. The intermediate code is input to the code generator, which \nmust read this file backwards. In this respect the file of intermediate code s similar to an intermediate \nAPT file. We have paid a heavy price for efficient implementation of the lists of intermediate code. \nThe semant-L functions so constrain the eva uation order that the ILR I and ILR O attributes must be \nevaluated ~n a right~to-left pass over the APT. In particular, if we decided to move intermediate-language \ngeneration to a left-to-right pass then portions of the attribute grammar would have to be revised. IV. \nObservations and Insights In the previous section we discussed some of the problems we encountered in \nwriting the attribute grammar and then implementing the SEMANTICIST. In this section and the next we \ndescribe some of the insights about attribute grammars that we gained as a result of our experience. \nOne surprising conclusion is that semantic evaluation in alternating passes is quite restrictive. At \nthe beginning of the project we thought that, although other semantic evaluation strategies could theoretically \nhandle a wider class of grammars, alternating pass evaluation was robust enough to specify the translation \nof most programming languages. We still think this is true but we have come to appreciate that it can \ntake many passes to evaluate some grammars. It is irksome to discover that one pass of the evaluator \nmay be spent doing little but turning the tree around. Of course, if we had it to do over again, we would \nstill use alternating pass evaluation in order to be able to put a linearized APT into intermediate files. \nAttribute grammars were originally proposed for specifying the semantics of ~. We have found them to \nIbe, as well, a good way to specify the design of a compiler. By the nature of the formalism all data \npaths in an attribute grammar are explicit; that s the function of all those copy-rules. Although this \nmay be an obstacle to deriving an efficient implementation, it is exactly the information a good design \nshould specify and document. The attribute grammar for Pascal-86 is about 4500 lines long (without embedded \ndocumentation but well-spaced for readability). The corresponding production-procedures are about 10,000 \nlines of high-level language source code (also not counting embedded documentation and spaced for readability). \nOne would expect the attribute grammar to be even more compact than that; the difference is that the \nattribute grammar specifies more information than finds its way into the explicit code of the production-procedures. \nThe attribute grammar has a very cohesive influence on all aspects of the compiler that it touches. The \nintermediate files are linearized APTs and this structure is the same from one pass to another. At first \nwe saw this as a disadvantage. For example, an identifier reference in an expression can not be changed \nto a niladic procedure reference when the compiler identifies it as such. Now, after writing and using \nthe attribute-grammar and the production-procedures, we see this stability as a positive feature. If \nthe structure of the APT remains the same throughout the compiler (or some portion thereof) then different \naspects of the translation can be specified separately as collections of semantic functions associated \nwith the unchanging productions of the phrase-structure. These separate collections of semantic functions \ncan use attributes that are defined by other collections of semantic functions, and they can define attributes \nthat will be used by still other collections of semantic functions. Using a common intermediate representation \nto unify the compiler is not unique to attribute grammars. In [HCW] the authors discuss this as a valuable \ntechnique to use with the S/SL compiler-writing system. However, an attribute grammar does not directly \nspecify an order of evaluation; i.e. the pass during which a semantic function should be applied in a \npass\u00adstructured evaluator. Thus , partitioning an attribute grammar into functional pieces need not lead \nto a similar, physical organization of the compiler. Section 3 discussed how we used data abstraction \nto reduce the attribute evaluator s space requirements. In many respects , though data abstraction and \nattribute grammars do not fit well together. The problem is that a semantic function must be a pure function, \nwhereas an abstract data type frequently contains private variables which are known only within the abstract \ndata type, and which are updated by the publicly known functions of the type. For example, the SEMANTICIST \ncontains a module that keeps track of addresses of memory-resident constants. These addresses are assigned \non demand . When asked for the address of a literal the module searches a list of literals that have \nalready been assigned addresses. If the literal has already been assigned an address then this address \nis returned, otherwise the next available address is assigned to this literal, the literal and its address \nare put on the list, and the newly-assigned address value is returned. This module contains two private \nvariables, the list of previously assigned values and the next available memory address. In order for \nthe OffsetOfLiteral function to be a true semantic function these two values would have to be passed \n as arguments, and updated values would have to be returned, These values would have to be passed around \nthe APT as values of attribute-instances , very much like the intermediate language file is passed around \nthe APT as the values of instances of the attributes ILR_I and ILR-O. The SEMANTICIST uses the function \nOffs@tOfLiteral even though it is not a pure function. Two distinct applications of this function with \nthe same argument will always yield the same value, and although different evaluation orders will give \nslightly different results, the difference is not important. Unfortunately, the attribute grammar formalism \ndoes not make allowances for a difference that makes no difference . We feel this is a topic that deserves \nfurther consideration by researchers in the field. v. Conclusions The SEMANTICIST is not as efficient \nas the discussions on evaluator optimization would suggest. Not all optimization were applied everywhere \nbecause there wasn t time or because changing that much code by hand presented too great an opportunity \nfor error. Nonetheless, the SEMANTICIST is efficient enough to compete with hand\u00adcoded com~ilers in the \nmarket ~lace. Surprisingly, the SEMANTICIST &#38;pends half its time in reading and writing intermediate \nfiles. Any inefficiency due to copying values around the APT is not great compared to the rest of the \nevaluation process. Attribute grammars have two short-comings that we would like to see rectified. Firstly, \nthe form of semantic functions should be expanded to allow complicated, multi-valued expressions on the \nright\u00adhand-side. Our reasons for this and our proposed solution were discussed at the beginning of Section \nIII. We don t have a good solution for the other short-coming, which is how to specify the result of \na translation. Constraining the order of evaluation so as to be able to write the results out to a file \nis inadequate. Schulz CS] suggests associating a special output description mechanism with each production, \nand so incrementally specifying another attributed program tree as the output. We are uneasyw~~k these \nattributed trans$opmations because they weaken the declarative, non-procedural nature of attribute grammars \nby encouraging one to view an them as a sequence of actions (transforming one form of APT to another). \nHowever, we have nothing better to suggest. The SEMANTICIST was not automatically generated from the \nattribute grammar. This was a problem throughout the project. Obviously a tool was needed to generate \nthe production-procedures from the attribute grammar. In hindsight it is easy to describe such a tool, \nbut at the beginning of the project what we thought we needed is not what we now want (and are building). \nPerhaps it is just as well that we wasted time finding out what tools we should have, rather than wasting \ntime writing the wrong tools. The SEMANTICIST is the result of combining and trying a lot of ideas about \nhow to build a compiler from an attribute grammar. Most of these ideas have appeared in the literature, \nsome we developed along the way. Some of the ideas worked well, some were not so effective. Sometimes \nour preconceptions about what was important turned out to be right, more often they did not. What is \nmost interesting about this effort is that their were enough good ideas to write a major part of a production \ncompiler based on an attribute grammar. Acknowledgements The SEMANTICIST is but one part of the Pascal-86 \ncompiler and I am deeply indepted to the other members of the development team: Dain Samples, John Crawford, \nSue Ojeda, Marek Jeziorek, and Tom Wilcox. Using attribute grammars in the compiler was originally proposed \nby Dean Schulz. Al Hartmann provided important continuing support during the SEMANTICIST s development. \nRichard Schell helped in writing the Pascal-86 attribute grammar. Tom Wilcox and Rick Schell both ready \nearly drafts of this paper and made many improvements in it. References CB] Bochman, G.V. Semantic evaluation \nfrom left to right. Communications of the ACM, VO1 19, Num 2, February 1976. [c] Cert, O. Parallelism, \nControl and synchronization expression in a single assignment language. SIGPLAN Notices, Vol. 13, Num. \n1. Januarv . 1978. ~CH]Cohen,R. and E.Harry. Automatic generation of near-optimal translators for noncircular \nattribute grammars. Conference record of the Sixth ACM Symposium on Principles of Programming Languages, \nJanuary 1979. Dennis,J. B. First version of a data flow procedure language. Lexture Notes is Computer \nScience, 19 (G. GOOS and J. Hartmannis, Eds.), Springer-Verlaq, N.Y., 1974, 362\u00ad 376. Fang,I. FOLDS, \na declarative formal [ 1 language definition system. STAN\u00adCS-72-329, Computer Science Department, Stanford \nUniversity, Stanford, California, December 1972. Ganzinger, H., K. Ripken, and R. Wilhelm. Automatic \ngeneration of optimizing multipass compilers. Proc. IFIP 77, Toronto, Ontario, 1977, pp. 535-540. Ganzinger,H. \nOn storage optimization for automatically generated compilers. Theoretical Computer Science, 4th (i \nI Conference, K.Weihrauch (cd.), Springer-Verlag, Berlin-Hei delberg-NewYo rk, March fiS~A?ll~ltia?l~ \n27}4~~ecifications for . Computer Programming Language Pascal, Second Draft Proposal, ISO/DP 7185, ISO/TC \n97/SC 5 N 595, y,K. and S.K.Warren. [K~~~~n~~sept ~g8~ Automatic generation of efficient evaluators \nfor attribute grammars. Conference Record of the Third ACM Symposium on Principles of Programming Languages, \nJanuary 1976, 72-85. [K] Knuth,D.E. Semantics of context-free languages. Math. Systems Theory 2 (1968), \n127-145. Knuth,D.E. Semantics of context\u00adfree languages: correction. Math. Systems Theory 5, No. 1. 95-96. \n[L] Lorho, Bernard. Semantic attribute processing in the system DELTA. Methods of Algorithmic Language \nImplementation. A. Ershov cd., Sp;inger-Verlag, Berlin-Heidelburg-New York. 1977. t)iJ .21-40. [PJ] Pozefsky, \nD. and-MJazayeri. A family of pass-oriented attribute gramm;r evaluators. Proceedings of the ACM 1978 \nAnnual Conference, December 1978. Raiha, K-J, On attribute grammars and their use in a compiler writing \nsystem. Report A-1977-4, Department of Computer Science, University of Helsinki, Helsinki, August 1977. \nRaiha,K-J. Dynamic allocation of space for attribute instances in multi-pass evaluators of attribute \ngrammars. Proceedings of the SIGPLAN Symposium on Compiler Construction, Denver, Colorado, 1979. Rosen,B. \nK. The toy language syndrome. IEEE Transactions on Software Engineering, Vol. SE-4, No. 1, January 1978. \nSaarinen, Mikko. On constructing efficient evaluators for attribute grammars. Automate, Languages, and \nProgramming, Fifth Colloquium. G. Ausiello and C. Bohm (eds.), Springer-Verlag, 8erl in-Heidelberg-New \nYork, 1978, pp. 382-397. Schulz, W.A Semantic analysis and target language synthesis in a translator. \nPh.D Thesis, University of Colorado, 8oulder, Colorado, 1976.\n\t\t\t", "proc_id": "582153", "abstract": "Experience writing a production compiler based on an attribute grammar is related. The compiler is Intel Corporation's Pascal-86 compiler which runs on a microcomputer-based system. An attribute grammar was written describing semantic analysis, storage allocation and translation to intermediate code. Attribute evaluation is done in two alternating passes [J] and the program tree is kept in intermediate files on disk. Various techniques for optimizing the evaluator were tried. Their success is reported and compared with other ideas from the literature.", "authors": [{"name": "Rodney Farrow", "author_profile_id": "81100184781", "affiliation": "Intel Corporation, Santa Clara, California", "person_id": "PP39031436", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/582153.582164", "year": "1982", "article_id": "582164", "conference": "POPL", "title": "Experience with an attribute grammar-based compiler", "url": "http://dl.acm.org/citation.cfm?id=582164"}