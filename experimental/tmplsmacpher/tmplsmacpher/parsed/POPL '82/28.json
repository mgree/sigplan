{"article_publication_date": "01-25-1982", "fulltext": "\n A Logic for Expressions With Side-Effects Hans-J. Boehm Cornell University Abstract This paper presents \na simple programming logic LES, which is particularly well suited for reasoning about so-called expression \nlanguages, i.e. languages that incorporate imperative features into expressions rather than distinguishing \nbetween expressions and statements. An axiomatization of a simple programming language is presented using \nthis formalism. It is shown that this axiomatization is relatively complete, roughly in the sense of \n[COO 76]. even for pure statement languages. It is con\u00adstructed by adding a single primitive to a logic \nfor the underlying data domain. Thus we can argue that it is really no more complex to axiomatize an \nexpression language than it is to axiomatize a pure statement language such as the one Hoare uses [Hoa \n69]. To illustrate various points it is useful to define a very simple programming language which exhibits \nthe desired characteristic. Introduction The basic language used for illustration will be a pure expression \nlanguage in that every con- Most existing formalisms for reasoning about struct will yield a value. It \nmay or may not change programs insist on a clear distinction between the state of the computation. The \nconstructs to be statementsn and expressions~~ -exceptions known to considered are: the author are [Kow \n771, [Pri 771, and [Schw 78]. 1. The simple expressionIt is assumed that statements are executed only \nfor effect and therefore produce no value, whereas aopb expressions have no effect and only produce a \nvalue. where op is +, * etc. At the same time, few programming languages enforce this distinction, and \nmany so-called expression A and b are evaluated in that order. Op is languages (e.g. Algol 68, Russell) \ndo not distin-applied to their respective values to yield the guish between the two at all. result. The \ntotal effect on the state is equivalent to evaluating a; b as described The purpose of this paper ia \nto present a pro\u00adbelow. gramming logic LES which does not impose any res\u00ad trictions on this aspect of \nthe underlying program-2. The simple assignment ming language, though the logic can be justified x:=a \nEvaluation consists of evaluating a and storingThis research was supported in part by NSF grant the result \nin x. The value produced is that no. MCS 79-01048 stored in x. Permission to copy without fee all or \npart of this material is granted 3. The sequence provided that the copies are not made or distributed \nfor direct commercial advantage, the ACM copyright notice and the title of the a; b publication and its \ndate appear, and notice is given that copying is by permission of the Association for Computing Machinery. \nTo copy Evaluation changes the state by evaluating a otherwise, or to republish, requires a fee and/or \nspecific permission. and b in succession. It yields the value of b as its value. @ 1982ACM0-89791-065-6/82/001/0268 \n$00.75 4. The conditional if c then el else e2 fi First true evaluated. either c is el el or eis valuaThe \ne2. ted. evaluated. value If it produced yields Otherwise is the that e2 value i.s of 5. The loop while \ncdo eod If c evaluates to true, e is evaluated and the process is repeated until c becomes false. The \nloop always yields the value false, the last value of c. Procedures will be discussed in a later sec\u00adtion. \nNotat ion aw! f!LbeL Conventions It is clear that a Hoare style formalism does not suffice for reasoning \nabout languages such as this. While several problems arise, we shall directly address only the following \none. It is no longer clear what an assertion in which arbitrary programming language expressions appear \nmeans. For example is (1) (x := 3; true) and x =3 always true? This problem has been solved in the past \nby restricting assertions to contain only aide-effect free formulas. We take a different approach. The \nprimitive underlying our formalism can be viewed as clarifying the meaning of formulas like the one above \nby making the range of state changes explicit. The resulting logic ia sufficient to define a con\u00adstruct \nsimilar to Dijkstra~s weakest preconditions [Dij 761. Thus nothing else is needed. In this sense the \nlogic is similar to that of [Con 77]. We assume that we have a base logic BL which is adequate for reasoning \nabout data domains over which program variables may range. A term in LES has the form < prOgramming_language_expression \n> Intuitively, such a term represents the value of the expression within the brackets when executed \nstart\u00ading in the initial state. An LES expression is built by combining terms and BL constants using \nthe connective in BL, e.g. +, *, not, and V. If several terms appear in an expression, side-effects produced \nby one of them never affect the value of the others. Thus, the side-effects produced by an eXpreS510n \nin an assertion are confined to within that pair of brackets. As an illustration, if we rewrite (1) as \n<x:. 3; true> and <x>.3 then it is equivalent to <x> = 3, and not to trae. We refer to an LES expression \nas a formula if it yields a boolean value. Any quantifiers appearing in an expression are interpreted \nas quantification over the initial value of the variable in question. For example, the for\u00admula 3X (<x \n:= 3>+<x>) 7 should be read as: There exists an initial value of the variable x such that the value \nproduced by x := 3 (i.e. 3) plus that initial value of x is 7. There is no distinction between logical \nand program variables. We will make the usual assumption that free variables are implicitly universally \nquantified. In contrast to the usual convention, we do not assume that the operations provided by the \nlogic are the same as those provided by the programming language. This requires a slightly larger aet \nof axioms. On the other hand, if the two sets of operations are actually the same, the additional axioms \nare all trivial. Furthermore, it may make it possible to give proof rules for a complicated expression \nlanguage by simply defining any strange programming language operators in terms of standard mathematical \noperations. The following definitions will help to estab\u00adlish the relationship between LES and more conven\u00adtional \nprogramming logics. [<>E clef]: We let <S> E be the expression E with each terms <t> appearing in E replaced \nby <S; t>. Thus <x := 3> (<x> -<z>) is equivalent to <x:=3; x> -<x:=3; z> Informally we think of <S> \nE as the value of E after executing S. Observe that if E is a boolean expression <S> E in this notation \nis very similar to the same construct in dynamic logic (see e.g. [Har 79]), S; E in [Con 77], or WP(S, \nE) in Dijkstra s notation [Dij 76]. The rest of this paper will rely critically on this definition. \n[{] clef]: {P] S {Q] will be used occasionally to represent the formula P =.> <S> Q. Again this corresponds \nclosely to the standard use of the notation. [<-clef]: The notation E[x <-e] denotea the expression \nE with free occurrences of identifier x replaced by expression e. (This may produce. a syntacti\u00adcally \nincorrect expression if x appears on the left side of an assignment. The actual proof rules presented \nbelow carefully avoid this. ) [1 var defl The term <x> where x is a variable will be fre\u00adquently written \nas just x. Thus if we write x = 3 as an LES formula we mean <x> = 3. We assume that we are given some \nstandard axiomatization of the the underlying logic BL. This axiomatization must deal with =! in a sufficiently \ngeneral way to allow substituting equal expressions for equal expressions. In particular this requires \nthe addition of the inference rule [<>E equ rule]: el =e2 k <e> e.1 = <~> ~z (Note that from el = e2 \nwe may not conclude <cl> e = <e2> e.) Some further assumptions about BL will be made in conjunction with \nthe inference rule for loops. Conseguenc~ @ Composition Theorem Two rules of inference usually present \nin a program\u00adming logic follow immediately from the predicate calculus axioms and [<>E equ rule] . These \nare Hoarets rules of consequence and composition. [consequ thml: {P} S{Q}, Q =>R + {P} S {R]  We can \nrewrite the assumptions as P ==> <S> Q, and true = (Q ==> R) respectively. Since by [<>E clef] true \n= (<S> true) we get by [<>E equ rule] true = (<S> (Q => R)). But this is equivalent to <S> (Q ==> R) \nwhich is, again by [<>E defl, the same as (<S> Q) ==> (<S> R) Combining the above with the first hypothesis \nyields P ==> (<S> R) or {P} S {R) which was the desired conclusion. This leaves us in a position from \nwhich we can easily derive a version of Hoarets statement compo\u00adsition rule as well: [comp thml: P ==> \n<S1> Q, Q => <S2> T + P ==> <S1; S2> T This follows immediately if we let R be <S2> T in the previous \ntheorem. The following sections will present axioms and inference rules for various programming language \nconstructs. These will all be generalizations of Hoare~s rules (modulo the treatment of termination). \nSimDle.Expressions We start with an axiom defining the effect on the state of evaluating an identifier: \n[id ef ax]: <x>E=E where x is a variable or constant and E is any LES expression. This axiom expresses \nthe fact that evaluation of an identifier does not modify the state of the computation, and thus the \nvalue of a subsequent expression is not affected by it. It follows from [<>E clef] that the following \nformulation of the axiom is valid as well: <x; e> <e> It is actually equivalent. The equality E = <x> \nE can be derived by first deriving equalities of the corresponding terms in E and <x> E using the above \naxiom, and then substituting equals for equals. The first notation is more convenient to use, and thus \nwill be used in stating the remaining axioms. In general axioms for LES will be presented in pairs. The \nfirst one, like the preceding one, will describe the effect that a construct has on the state. The second \none will describe the value yielded by the construct. The preceding effect axiom has a corresponding \nvalue axiom only when x is a constant. If there is an equivalent constant in the logic this is simply: \n[const val ax]: <c> =~ We also need proof rules to describe both side effects of, and the value yielded \nby various opera\u00adtors in the language. In general the rules involved will depend on the semantics of \nthe operator. For the sake of illustration we will consider the case Let y have the value of e before \nexecution of of a side-effect free binary operation op. We will x := e. Then we want P[x <-y] to be true \nafter e also assume that there is a corresponding operator is evaluated but before the assignment takea \nplace. of the same name in the logic. If we now generalize from the formula P to an arbi\u00ad trary LES \nexpression E we get Recall that our language uses left to right argument evaluation. The cumulative side-effects \nof [:=ef ax]: evaluating el op e2 are thus identical to those of y = <e> ..> (<x := e> E) (<e> E[x <-y]) \nevaluating el; e2. We describe this formally by the Here y is a fresh variable. i.e. y does not occur \nin effect axiom: e or E. We add the trivial value axiom [op ef ax]: [:= val ax]: <el ope2>E = <cl; e2>E \n<X :=e> = <e> Again, we are defining the side-effects of an As a simple application of the effect axiom \nwe expression by stating how the value of subsequent again coneider the formula expressions is affected. \nNote that it now follows <x:=3>(x -z) from the above definitions that for formulaa P and QZ Applying \nthe above axiom we get {p) d op e2 {Q} = {P} el; e2 {Q] y . <3> .=> <x := 3>(x-z)=<3> (y-z) or, using \npredicate calculus rules, All we need now is a rule describing the value computed by el op e2. We might \nwant an axiom of the <X:=3> (X-Z)= <3> (<3> -z) form: . 3-z ? A more easily usable version of [:= ef \nax] and <el 0p e2> = <cl> 0p <e2> a more interesting application are given in Appendix The above however \ndoea not hold if the value of e2 (a). is changed by previously executing el. Thus we The proof rules \nfor the conditional are rewrite the value axiom as: obtained essentially by translating the well-known \n[opval ax]: one into this formalism. In particular if we abbre\u00ad<el op e2> = <cl> op <cl; e2> viate As \nan illustration consider the expression if b then el else e2 fi <x* y+ z> as IF, we have Using the two \npreceding axioms we have [if ef ax]: <x * y+ ~> <b> ==> (<IF> E = <b; el> E), and . <x *y>+ <x *y; z> \n= Q * y> +<x;y; z> not <b> ==> (<IF> E = <b; e2$ E)  = <x> * <x; y>+<x;y; z> [if val ax]: Applying \n[id ef ax] a few times gives us <b> => <IF? = <b; cl>, and mot <b> ==> <IF> = <b; e2> <~*y+z> = <x>*<y>+<z> \n. x*y+z (by [1 var clef]) In general if all operators in a programming language expression e behave \nlike OP we can (and z!R14QQQEuk will) neglect to distinguish between <e> and e. We could derive a while \nrule based on Hoare a. The result however would be more complex than neces\u00adsary. The problem is that \nthe standard statement of the rule involves a hypothesis of the form p ==> <s> P We can express Hoarets \nassignment axiom as: ? which states that the invariant ia presarved when the body of the loop ia executed. \nHowever, one of P[x <-e] .<x:=e>p the things one might wish to prove in our present This unfortunately \nia no longer correct under our logic is that the value of .Om=. .ay int%er, assumptions becauee evaluation \nof e may have aide\u00adexpression E is unaffected by the execution of the effects. loop. That is, <while \n... od~ E =E This requires some notion of a non-boolean invari\u00adant. The obvious solution is to generalize \nthe above hypothesis to arbitrary, not necessarily boolean. P. This however leaves us with the ques\u00ad \ntion of what to do with the ==> Operator in the hypothesis, whose argumenta must be boolean values. There \nare several possible solutions. The one we chose involves generalizing the implication to an arbitrary \npartial 6rder c. This makes our invari\u00adance sufficiently general that we no longer need a eeparate notion \nof a variant function to show termi\u00adnation. Instead we just insist that c is well founded and that what \nused to be our ~invariant is in fact strictly decreasing with each loop itera\u00ad tion. Thus we obtain the \nfollowing, at first glance strange, formulation. If c has no aide effects and we u ae WH to denote while \ncdo eod then the following rule holds: c is a well-founded partial order. <c> and vck==> (<e> V) cv \n1\u00ad v ck==> (<WH>v) G v and 4/H> (not <c>) Here k is a constant and v an expression in the logic. Note \nthat we have assumed a fairly powerful base logic. In particular it is essential that we be able to express \nthe first hypothesis formally, and to prove it for some interesting relations c. The rule can be read \nas: If the initial value of v is less than k, and execution of the loop body strictly decreases v. then \nthe final value of v is no larger than its original value, and after execu\u00adtion the condition c evaluates \nto false. We could have arrived at this rule using the opposite approach as well. We could have started \nwith a conventional formulation of the rule using both an invariant, and a variant function whose range \nwas some well founded partial order. We would then have transformed this into the above rule by observing, \nas we will below. that the part of the rule dealing with invariants is redundant. Thus we will refer \nto v as the variant expression. The firet derivation has the advantage that its ideas will turn out to \nbe of come Uae later. At this point the reader may still have trouble believing that the above rule is \nsufficiently gen\u00aderal. Actually it is at least as general as the invariant formulation, again provided \nthe base logic is sufficiently expressive. To show this, aasume we have a Dijkstra style proof of the \nwhile loop. This means we have shown that e preserves some invariant assertion 1, and decreases the value \nof the integer-valued variant expression f. This can be transformed into a proof using the ahove rule \nas follows: Let v be defined to be f whenever I holds, and CD Otherwise. Let c be the < relation on the \nnatural numbers extended in the obvious way to m. Let k be co. The first hypothesis is thus trivially \nsatisfied. Whenever v c k the invariant I holds by the construction of v. Thus in this case v = f, and \ntherefore v is decreased by e. So the second hypothesis holds as well. We conclude that after the while \nloop c is false, and the final value of v is less than the initial one. and therefore finite. The latter \nis equivalent to saying that the invari\u00adant still holds. As another example of an application of the \nabove rule consider the following. Assume again that we have a variant expression f. Also assume that \ne (and c) leaves expression E invariant. We want to show that: <while cdo eod> E E In this case we let \nv be the pair (f, E). We define (a, b) c (c, d) iff a< c and b=d. ThuS values of v with different E components \nare incom\u00adparable. We can now the while-rule in a straightforward manner. (K can be (k?, E) for any k \nlarger than the initial value of f. If necessary we can again introduce a constant tn.) Our desired conclusion \nis equivalent to the apply <while cdo eod~ v s v conclusion of the proof rule. Side-effects in the condition \nadd some complex\u00adity. The easiest way to deal with them is to con\u00adsider a new programming language construct \nwhilet c do e od (abbreviated as WH ) It is executed like a while-loop, except that after the execution \nis completed we back up to the state immediately preceding the last execution of c. This is somewhat \nsimpler to analyze than the origi\u00ad ns 1 while construct since its execution is equivalent to an integral \nnumber of executions of c; e. Thus it can be axiomatized as before simply by requiring that c; e, rather \nthan just e, decreases the variant v: [WH ef rule]: c is a well-founded partial order <c> and v ck.=> \n(<c; e> v) c V, 1\u00adv c k .=> (<NH!> v) s vand <ws~> (not <c>) We can now define the effect of the real \nwhile-loop in terms of the whilet construct by adding the following conclusion to the above rule: [WH \nef rule]: <WH>E = <WRt; c> E  (It can~t be added as an independent axiom since, as we will see in the \nnext section, the loop must ter\u00adminate for it to hold.) As usual, we conclude by giving a value axiom: \n[WHval ax]: <while c do e od~ = false  XtE Up to this point we have carefully avoided say\u00ading anything \nspecific about the treatment of diverg\u00ading computations in the logic. In the preceding section we chose \na total correctness formulation of the while-rule. Thus the reader may have assumed that we were dealing \nwith total rather than partial correctness. We in fact use something between the two. We can view our \ntreatment of termination as an exten\u00adsion of that normally used for applicative languages. There a nonterminating \nexpression is treated as yielding a special undefined value L. Here we also have to worry about the affect \non the state of such an expression. Thus we assume that every component of the state is assigned such \nan undefined value as well. Note that this is dis\u00adtinctly different from either a partial or a total \ncorrectness logic. In particular, for a nonter\u00ad minating loop S we do not have {P] S {false] but we \ndo have {P} S {true]. Furthermore {trae} S;x:= 2 {X =2} is a theorem. Rather than introducing a new \nundefined element L into all data domaina described by the logic, we treat such a result as being simply \nsome existing value in the domain. Our logic however will not allow ua to conclude anything specific \nabout its identity. This has two technical advantages over the con\u00adventional treatment of L. First, it \ndoes not require us to modify the axiomatizations of the underlying data domains by the introduction \nof this extra ele\u00adment. Second, we can sidestep some sticky issues related to the treatment of 1 in the \nlogic itself. (E.g. what is L and true?) We make one further simplifying assumption. The only construct \nin our language that can possibly fail to terminate is the while loop. Since it doesn~t yield an interesting \nvalue anyway, we aaaume that it in fact yields the value false whether it terminates or not. That is, \nwe assume that when we write while cdo eod we in fact mean while c do e od; false This simplifies primarily \nthe relative completeness proof in Appendix (b). This whole situation perhaps deserves a short explanation. \nConaider the task of transforming this system into a total correctness logic. Let S be a non-terminating \nloop as before. This means that {true] S {true} can no longer be a valid theorem. On the other hand this \nis by definition equivalent to true ..> <S> true or just trae ==> true. Thus we would be led to a strange \nlogic indeed. The attempt to build a partial correctness logic fares no better. An argument almost identical \nto the one above shows that true ==> false now has to be a theorem in our logic! So where does this leave \nus? Actually things are not bad at all. After all the final goal in all this is to produce a totally \ncorrect program that satisfies some given specification, usually of the form : {P} S {Q} We accomplish \nthis as follows: First we write an appropriate program and prove it correct using the above logic. We \nthen see whether our proof includes termination proofs for all while-loops. If so, our program is totally \ncorrect and wetre done. If not we simply replace the other while-loops with assignments of L to all state \nvariables followed by the constant false. Here L can denote any element of the appropriate data domain. \nWe then have a totally correct program, since the proof in effect showed that the state after execution \nof such a loop didntt matter. We have even gained some amusing properties in the process. We have noted \nthat our <s> Q corresponds very closely to Dijkstra~s wp(S, Q) or wlp(S, Q). It however enjoys the additional \npro\u00adperty that <s> (not P) <==> mot (<s> p) (The corresponding property for O= also holds. This however \nshould be no great aurpriae to anyone. It normally does not hold due to nondeterminism in the programming \nlanguage. Allowing nondeterminism {p(=)} B {Q(z)] in this context would only add unnecessary complica\u00adtions. \nIn particular the reflexive law of equality would no longer hold.) We could just introduce this rule \ninto our system. This may however be more restrictive than desired. We would have no hope of proving \nsomething of the Procedure&#38; form El = <f(;)> E2 up to this point all side-effects in expres- This \nproblem can be solved as follows. First,sions were introduced by explicit assignments. The translate \nthe above rule into our original notation: reader is however hopefully convinced that our framework \nsuffices for axiomatizing other operations => <B> P(;) Q(I) with side-effects such as the += (or +:=) \noperator + of C or Algol 68. P(z) ==> <f(~)> Q(:) In most of these cases it is still not too dif - We \nnow want to generalize so that P and Q canfiCUlt to transform a program in one of these be logical expressions \nof arbitrary type. Howeverlanguages to one which uses only side-effect free we have the same difficulty \nas with the while\u00adexpressions, and then to reason about the result. rule. Clearly, we have to replace \nthe implications Thus dealing directly with side-effects is perhaps by something else. not completely \nessential until we allow user-defined procedures or functions. The purpose of this sec-Our solution in \nthe case of loops was to use tion is to illustrate that these can be incorporated arbitrary well founded \norderings. This happened to into the logic without a great deal of difficulty. be convenient since it \nsubsumed the termination con-We will not, however, do this by presenting one dition as well. definitive \nrule, which would lead us too far astray Presently however we have no additional con\u00ad from the topic \nat hand. straints. Thus we can replace the ==> here by an Instead we will present only a very simple \narbitrary binary predicate R of the base logic Hoare-style rule and then show how to adapt it to rather \nthan a restricted type of ordering. We can our formalism. now write our modified rule as We consider \nthe procedure declaration: R( cl(=), <B> e2(~) ) k proc f(;); R( el(~), <f(~)> e2(~) ) B; end proc \n Up to this point we have neglected the fact Here B is the body of the procedure and = is a that our \nprocedure yields a value. We use a value sequence of call-by-reference parameters. rule that looks very \nsimilar to the effect rule: We start by making some simplifying assump-R( el(~), <B> ) tions. First, \nwe assume that we are not interested + in proving the correctness of recursive procedures. R( el(~), \n<f(~)> ) (Our rule will turn out to be of little help in this The ambitious reader should now be in a \nposition to case.) Secondly we restrict procedure calls as fol\u00adcarry over some more general procedure \nrules, such lows : as those given in [Gri 80] and [Car 78]. 1. Arguments are simple variables passed \nby refer\u00adence. 2. No aliasing occurs between two arguments or Cone 1\u00adbetween an argument and a global \nvariable.  Consider two predicates P(z) and Q(z), where ~ The logic LES is a simple formalism for reason\u00ad \ndenotes some sequence of variables, and neither P ing about programs written in so-called expression \nnor Q has any of the parameters or arguments free in languages. Although it is somewhat inconvenient \nif it. We could write down the following proof rule proofs are carried out in full detail, it seems to \nfor f: interact nicely with informal reasoning about such programs. In particular we have defined the \nmeaning of Hoare style assertions in terms of LES and all our proof rules are generalizations of Hoarets. \nThus if a section of the program is amenable to proof using Hoarets system we can easily translate such \na proof into an LES proof. It is still possi\u00adble to present proof outlines in the form of a pro\u00ad gram \nannotated with assertions, although this becomes less and less informative as onets program\u00adming style \nbecomes more and more applicative. It may be useful to develop some notational convention for inserting \npre-and postconditions for arbitrary sub-expressions (rather than just at a t;!). We may also want to \nestablish a syntactic shorthand for referring to the value yielded by the last expression. It would then \nbe possible to derive rules similar to those in [Kow 77]. Our approach can be viewed as a combination \nof the following two ideas. We distinguish strictly between programming language and logic operations. \nThis may be useful in general, and is virtually una\u00ad voidable in this context since it is not clear what \nthe meaning of side-effects in logical formulae is. Programming logics such as Dynamic Logic or Constablets \nProgramming Logic allow one to talk about the truth or falsity of a predicate after exe\u00adcution of some \nsequence of statements. The present logic generalizes this to the value of an arbitrary expression after \na number of state-changing opera\u00ad tion. This expressions consider the generalization do not statement \nis have side-e also useful even ffects. For example if X:.2*X To express the fact that the final value \nof x is twice its original value in Hoare~s notation would require an auxiliary variable. In the present \nsystem it can be expressed as <x :. 2*X; x> =2*X Schwartz, Richard L. An Axiomatic Seman\u00adtic Definition \nof ALGOL 68W, Computer Sci\u00adence Department, UCLA -34P214-75, Univer\u00adsity of California, Los Angeles, \nJuly 1978. I would like to thank David Gries, Chris Buck\u00ad ley, and especially Alan Demers for their \nsugges\u00ad tions on earlier drafts of this paper. [Car 781 Cartwright, Robert and Derek Oppen, The Logic \nof Aliasingn, Department of Computer Science, Cornell University, Technical Report TR78-358, 1978. [Con \n77] Constable, Robert L., On the Theory of Programming Logicsn, Proceedings of the Ninth Annual ACM \nSymposium Computing, ACM, May 1977. on Theory of [COO 76] Cook, Stephen A., Soundness and Complete\u00adness \nof an Axiom System for Program Verif\u00adication??, Department of Computer Science, University of Toronto, \nTechnical Report No. 95, June 1976. [Dij 76] Dijkstra, ~, Edsger W., A Prentice-Hall, ~ 1976. tik [Gri \n80] Gries. David and Procedure Ott 1980. and Call Gary Proof Levin, Rules!f, Assignment TOPLAS 2, [Har \n79] Harel, Springer D., E.ir.SL-Qr.&#38;2X Verlag, 1979. D!UJA@2 LQ&#38;As [Hoa 69] Hoare, C.A.R, An \nputer Programming , pp.576-580. Axiomatic CACM Basis for 12, Oct. Com\u00ad1969, [KOW 771 Kowaltowski, to \nSide Informatica Tomasz, Axiomatic Approach Effects and General Jumps ?, Acts 7, pp. 357-360, 1977. [Pri \n77] Pritchard, Expression cessing 731. 77, Paul. Program Proving Languagesn, Information North Holland, \n1977, pp. -Pro\u00ad727\u00ad [Schw 78] Schwartz, Richard L., ment of Asynchronous ALGOL 68n, preliminary can be \nfound in: An Axiomatic Processes draft. More Treat\u00adin detail Aw.wdiz A. /hkzw.k We give a proof of \na small program which includes an expression with side-effects. It illus\u00adtrates the interaction of LES \nwith Hoare style rea\u00adsoning. Consider the program P: a := b; r:= (x :=(a:=a+l)+a; 2*X ) Assume we wish \nto prove {trae] P {r=4*b+4}. We begin by deriving a more easily applicable, t bough somewhat restricted \nform of [:= ef ax]. Recall that it was originally stated as: <y> = <~> ==> (<x := e>E) = (<e> E[x<-y]) \n<e; C> c We consider the case in which E contains no brack\u00ad eted programming language expressions other \nthan simple variables. If we expand (<,> E[x<-y]) according to [<>E clef], we find that y only occurs \nin terms corresponding to the term <x> in E. These have the form <e; y> Since y is a fresh variable \nwhich does not occur in e, each such term is equivalent to <y>, which is equivalent to <~>. Thus (<e> \nE[x<-y] ) can be rewritten as Et, where Et is obtained from E by sub\u00adstituting substituting <e> for <x>, \nand substituting <e; z> for each other term <z>. We can then rewrite the axiom as [simple := ef ax]: \n<y> <e> ==> (<x := e> E) Ef or, since y no longer appears on the right side of the implication: <x:=e>E \n= E* Let E represent the expression (a :. a + 1) + a, and M the expression (x := E; 2 * x), i.e. the \nright hand side of the second main assignment in P. As usual we first decompose the problem into two \npieces by inserting the assertion ~{ a = b }! between the two statements. We thus have to prove the following \ntwo theorems: {true] a :=b {a =b} and {a =b}r:=M{r=4*b+4} The first theorem ia trivial. From [simple \n:= ef ax] we get: <a:=b> (a b) = (b b) . true The left side of this equality is the theorem we wanted \nto prove. We could just as well have used Hoare~s assignment axiom since it is certainly valid in this \ncontext. It ia almost as straightforward to prove the main theorem. Here we do however have to use LES. \nWe first rewrite it as a = b ==> <r :=M>(r=4*b+4) The basic idea ia to rewrite the right side R of this \nimplication by applying [simple := ef ax] once for each assignment. We start with the assignment to r: \nR= (<M>=4*b+4) = (<x :=E;2*x>=4*b+4)  for any expression e and constant c. If c is axiomatized as above \nthis is easy to see as follows: <e; c> = <e> <c> (by [<>E clef]) . <e> c (by [<>E equ rule] c (by [<>E \nclef]) By applying the assignment axiom to x := E we obtain R= (<2*E>=4*b+4) . (<2 *((a :=a+l)+a)> =4* \nb+4) . (2 * <(a := a+1) +a> =4*b+4) Using [op val ax] and [:= val ax], we rewrite this as R = (2 * (a+l \n+<a := a+ 1; a>) =4*b+ 4) We then apply [simple := ef ax] one last time to get R=(2*(a+l+a+ 1)= 4*b+4) \n(2*a+4=4*b+4)  Now a=b ..> R follows trivially and we are done. APuend ixl. Ak.laL&#38;L-~ What follows \nis a proof that the preceding axiomatization of LES without procedures is rela\u00adtively complete, roughly \nin the spirit of [Coo 76] or [Har 79]. We begin by making the following assumptions: 1. All primitive \noperations and constants in the programming language, other than assignment, if, and while, are axiomatized \nusing axioms of the form given in the simple expressions section. It should become obvious that this \nis necessary for explanatory purposes only. 2. We augment the axiomatization of LES by the following \nrule, which allows us to prove non\u00adtermination for while loops: [co WH ef rule]: P .=> <c; e> p p ==> \n<c> &#38; P => <while cdo eod; X> . L This rule is generally useless since it serves only to prove programs \nincorrect. On the other hand, it makes it much easier to state the relative completeness theorem. We \nobserved that b does not appear in M and we 3. We assume we have a fairly powerful base logic could thus \nreplace <M; b> by just b. We also made BL . ZF set theory is a reasonable choice. In use of the fact \nthat in general particular we need: a) BL includes a conventional axiomatization of the predicate calculus \nwith equality. b) BL is expressive for LES. More precisely, for any formula P in LES there is an equivalent \nformula Q in BL. It would be sufficient to assume that for any program\u00adming language expression e there \nis a BL expression e such that <e> = e . c) The state transition function associated with any programming \nlanguage expression e is definable in the base logic BL. That is. for any programming language expres\u00adsion \ne and any sequence of n variablea x there is a formula P in BL such that P(R) is true iff R isyh% relation \ndefined by: ~R~ iff whenever the initial valuea of the ~ are ~ then their final values after executing \ne are a, d] N-tuples are definable if their components are. e) A relation is definable whenever we can \nwrite down the corresponding binary predi\u00adcate and its domain is definable. f) The reflexive-transitive \nclosure R* of a relation R is definable. g) The restriction of a relation to some sub\u00adset of ita domain \nis definable. Such a subset will be specified by a unary predi\u00adcate. h] Well-foundedness of a relation \nis expres\u00adsible. 4. For purposes of simplicity we assume that any formula in LES can be written in prenex \nnormal form. This should be the case anyway unlese BL is a constructive logic. 5. We assume that the \naxiomatization of LES is extended with a complete axiomatization of BL,  e. g. by adding all true statements \nof BL as axioms, The resulting axiomatization is unlikely to be recursively enumerable. but as in [Coo \n76] that will not concern us here. Here we identify a formula in LES which has angle brackets only around \nsimple variables and constants with the corresponding formula in BL which haa all brackets deleted. \nOf course we have no hope of proving LES com\u00adplete without assumption (5), since under reasonable assumptions \nBL will never be complete. Thus intro\u00adducing this assumption essentially reduces our statement to the \nweaker claim that the incomplete\u00adness of LES can, in some some sense, be traced back exclusively to the \nincompleteness of BL. We now claim that under these assumptions any true LES formula is provable using \nthe above axiomatization. If we had proceeded completely formally we would have given a definition of \na true LES formula before stating the theorem. We skipped this prOcess by assuming that the reader has \na sufficient infor\u00admal understanding of our toy language without a for\u00ad mal execution model. It should \nhowever be repeated that our model of a nonterminating loop is that it assigns some element L to each \ncomponent of the state. A true LES formula is one that holds for all possible values of L. BL does not \nhave to deal with L explicitly. We can still think of BL as a restriction of LES as we did in assumption \n(5). If the LES formula mentions L we simply precede the corresponding BL formula by VL ... The proof \nof our theorem relies on purely syn\u00adtactic principles. We will firat define the syntac\u00adtic complexity \nof a programming language expression to be some natural number. We then show that prov\u00ading any LES formula \ncan be reduced to proving a number of LES formulae in which only simpler pro\u00adgramming language expreaaions \noccur. Assume without loss of generality that we are only dealing with formulas in pure LES, that is \nfor\u00admulas in which constructs of the form <e> E have been eliminated using [<>E clef]. We will show that \ngiven a true formula P in the above form which has n occurrences of simple terms <e> such that e has \ncomplexity m and no simple terms of complexity greater then m, we can give a proof for P, assuming that \nthis hypothesis holds for for\u00ad mulas with at most n-1 occurrences of simple terms of complexity m. In \nmost cases this will be done by showing that P ia provably equivalent to a predicate P? in which one \nof the simple terms of highest com\u00adplexity has been replaced by some number of terms of lower complexity. \nWe define the complexity of a programming language expression to be 2n + m where n ia the number of operators \nappearing in the expression and m is the number of semicolons. Here the if and whilet constructs are \ncounted as operatora. The complexity of while cdo eod is defined to be that of whilei cdo eod; C At \nthis point we consider the most complex sim\u00adple term <e> (or one such term if there are several) aPPearing \nin the formula P which we wish to prove. In general e will have the form e; ... ;en 1 We will eliminate \n<e> by applying the inference rule or axiom associated with the outermost operator in e. If n 1 we apply \nthe rule giving the value of the operator in question. Otherwise we use the one defining its side-effects. \nThe n = 1 case is almost trivial. We will therefore dispense with it first. If e consists of just a \nvariable or constant then P is in BL and therefore provable. Thus we assume e contains an operator. We \nwill consider various possible outermost operators separately. Simple operation \u00ad <e> has the form <et \nOp ett> [op val axI allows us to show that this is equal to <et> op <er; etr> Thus we can prove that \nP is equal to P! which is obtained by substituting the above for <e>. Note that our definition of complexity \nwas cleverly contrived so that <e!; e~~> is less complex than <e>. Thus our induct ion hypothesis allows \nus to aasume that P? is prov\u00adable. Thus P is provable. Assignment \u00ad <e> has the form <x := ~t> Here \nwe just substitute <e!> for <e>. [: val ax] allows us to prove that the result is equivalent to the original \nformula. Conditional \u00ad <e> has the form <if b then er else et? fi> We assume that P has no explicit \nquantifiers (but possibly some number of free variables). If this should not be the case, by assumption \n4 we can write P in prenex normal form and apply the following reduction to the matrix of P instead. \n[if val ax] lete us prove that <e> is equivalent to <b; el> if <b> holds, and <b; e2> otherwise. Thus \nif we let P? be P with the conditional replaced by <b; et> and P!! be P with the conditional replaced \nby <b; e~t> then P is provably equivalent to (<b> ==> P!) amd (mot <b> ==> p~!) Again the rewritten formula \nno longer has occurrences of <e> and the newly introduced sim\u00adple terms have complexity leas than e. \n Loop -By [WH val ax] these can always be rewritten as false. Now we can return to the case in which \ne ia a sequence of semicolon separated expressions. Again we consider several different cases, depending \non the outermost operator of the first expression el. None \u00admay just be a constant or variable. In this \n1 case [id ef ax] allows us to replace <e ; ... ;en> 1 by <e ; ... ;en> 2 Simple operation \u00admay have \nthe form 1 el ope2 We can rewrite <e> as <cl; e2; e;e; ... ;en> 23 using [op ef ax].  Assignment -Assume \nel has the form x := et We again assume wolog that P has no explicit quantifiers. Let P! be P with each \noccurrence of <e> replaced by <e?; e2[x <-y]; ,.. ; en[x <-y]> where y is a new variable. We can then \nreplace P by the statement Q: y = <e!> ==> p! Q is a true statement which is less complex than P and \nis thus provable. From [:= ef ax] we immediately have y = <e!> ==> <e> = <et; e2[x <-y]; ... ; en[x <-y]> \nThus we get y = <ef> ==> (P! P) From Q it then follows that y . <et> ~.> p If we now substitute <et> \nfor y we get a proof of P. Conditional -This is almost identical to the case of the conditional by itself. \nLoop \u00ad<el> may be of the form while cdo eod This is actually the only interesting case in the whole argument. \nAgain assuming wolog that P has no explicit quantifiers, we rewrite P as  Q oro Q is true whenever \nP is true and the loop el does not terminate. Q! is true whenever P ia true and the loop terminates. \nWe will show that both Q ==> P and Q! ==> P are provable. Furthermore both Q and Qt have the instance \nof the while loop replaced by simple terms of lesser complexity. Since their dis\u00adjunct is thus less complex \nthan P it will be provable by the induction hypothesis. Thus P will be provable. We first rewrite P as \nP? where each term begin\u00ad ning with the loop el has been replaced by <e>E li where each Ei is in BL. \n(Such E always exist by assmption (3b). ) Pi is provably equivalent to P by our induction hypothesis \nsince the for\u00ad mulas Ei =<... > are less complex than P. Expanding P! using [<>E clef] we get a formula \nP ! in which e 1 occurs only in terms of the form (*) <e ;xi> 1 where x. is a simple variable. 1 We \nturn our attention to the formula Q. We first need to express the fact that the loop does not terminate. \nThe BL formula N equivalent to the following LES formula will do: <while cdo eod> (y =L) Here y is a \nfresh variable. Since we know that in the case under considera\u00ad tion each term of the form (*) is equivalent \nto 1, we can now write Q as N and PL where P is P1t with each instance of a formula (*) rep~aced by \nL. We can prove that Q ==> P as follows. Cer\u00ad tainly N is an invariant of the nonterminating loop. Since \nboth N ==> <c; e>li, and N ==> <c>  are less complex than P they are provable by induction hypothesis. \nThus by [co WR ef rule] we can ahow that each term (*) is equivalent to 1 (provided N holds initially). \nTherefore N==> (p =p) 1 is provable. The conclusion follows immedi\u00adately. We now consider Q!. We again \nwant to chose it in such a way that from Q , [WHt ef rule], and [WI+ ef rule] we can deduce P. We start \nby rewriting <e> as <wh~le~ cdo eod; c; e; ... ;en> 2 Thus from now on we will deal only with whilet \nloops. We then define P?t as before. Thus P!t has no occurrences of e ~ and the only occurrences of the \ncorresponding whilet loop WH~ are in terms of the form <whilet c do e od; xi> In order to apply [WHt \nef rule] we need to pick an ordering G, a constant k. and a variant function v. We chose v to be the \nwhole state of the computation. That is, we let v be (xl. ... , Xj) The idea then is to let c be something \nlike the transitive closure of the transition function associated with one iteration of the loop. Unfortunately \nthis relation is not in general well-founded. We want to restrict it to those states s such that when \nthe loop is started in state s it terminates. We express this condi\u00adtion by the following predicate T(s): \n(v . a) =.>not N Thuse we let s be the reflexive transitive clo\u00adsure of the following relation R on \n{ (al, ... , aj) ) u{co } Let aRb hold iff T(a) holds and either b = OJ or (V b) ==> not <c> and (<c; \ne>v = a) As expected we let k = m. The statement s G k ia equivalent to saying that s leads to termi\u00adna \nt ion. a s b where both a and b are j-tuples defining a state is equivalent to the statement that both \na and b lead to termination and that if the whilet-loop is started in state b then after some number \nof iterationa of the loop state a will be reached. Thus c is clearly well-founded. Furthermore this statement \nis expressible in BL and therefore provable. By construction the other hypothesis of the [WH! ef rule] \nis also satiafied. Since it is less complex than P it is provable by the induction hypothesis. We define \na formula R to be P~l with each instance of a term -amv; x.> 1 replaced by <Xit>. Thus intuitively \nwe can think of xil as being the value of xi after execut ion of the loop. Welet Q! be Vckand Vxl, ... \n~jt ((v c v and not c ) ==> R) Here Vt and Ct represent v and c respectively with each xi replaced by \nxi?. In the case of we first rewrite it in BL. It should be observed that Is just a formal way of saying \nthat v! is the final state produced by the while~-loop when started in state v. (There is after all just \none state which is reachable from v by some number of loop iterations in which c is false.) Thus Qt is \ntrue whenever the loop terminates and R holds when all the xi? are the final values of xi. It follows \nfrom the definition of R that Q! is exactly the formula we prom\u00adised. Qt => P is easily provable as before. \nWe know that the two hypotheses of [WI+? ef rule] hold. Since we are given v c k as well, we conclude \nthat (<WH!> V) G v and not <WH~> c We again assume that c has been rewritten in BL. We obtain the desired \nresult by substitut\u00ading <wH > xi for each xi! in Q! and then observing that this transforms R back into \nPtt. Thus P?! holds. It follows from [WH ef rule] that WH!; c can be written as e ~ and thus P and P!! \nare equivalent.  \n\t\t\t", "proc_id": "582153", "abstract": "This paper presents a simple programming logic LES, which is particularly well suited for reasoning about so-called expression languages, i.e. languages that incorporate imperative features into expressions rather than distinguishing between expressions and statements. An axiomatization of a simple programming language is presented using this formalism. It is shown that this axiomatization is relatively complete, roughly in the sense of [Coo 76].", "authors": [{"name": "Hans-J. Boehm", "author_profile_id": "81423595101", "affiliation": "Cornell University", "person_id": "PP80031515", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/582153.582182", "year": "1982", "article_id": "582182", "conference": "POPL", "title": "A logic for expressions with side-effects", "url": "http://dl.acm.org/citation.cfm?id=582182"}