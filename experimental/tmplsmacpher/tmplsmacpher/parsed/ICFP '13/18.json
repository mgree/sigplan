{"article_publication_date": "09-25-2013", "fulltext": "\n Productive Coprogramming with Guarded Recursion Robert Atkey bob.atkey@gmail.com Abstract Total functional \nprogramming offers the beguiling vision that, just by virtue of the compiler accepting a program, we \nare guaranteed that it will always terminate. In the case of programs that are not in\u00adtended to terminate, \ne.g., servers, we are guaranteed that programs will always be productive. Productivity means that, even \nif a pro\u00adgram generates an in.nite amount of data, each piece will be gen\u00aderated in .nite time. The theoretical \nunderpinning for productive programming with in.nite output is provided by the category theo\u00adretic notion \nof .nal coalgebras. Hence, we speak of coprogramming with non-well-founded codata, as a dual to programming \nwith well\u00adfounded data like .nite lists and trees. Systems that offer facilities for productive coprogramming, \nsuch as the proof assistants Coq and Agda, currently do so through syntactic guardedness checkers, which \nensure that all self-recursive calls are guarded by a use of a constructor. Such a check ensures productivity. \nUnfortunately, these syntactic checks are not compo\u00adsitional, and severely complicate coprogramming. \nGuarded recursion, originally due to Nakano, is tantalising as a basis for a .exible and compositional \ntype-based approach to co\u00adprogramming. However, as we show, guarded recursion by itself is not suitable \nfor coprogramming due to the fact that there is no way to make .nite observations on pieces of in.nite \ndata. In this paper, we introduce the concept of clock variables that index Nakano s guarded recursion. \nClock variables allow us to close over the generation of in.nite codata, and to make .nite observations, \nsome\u00adthing that is not possible with guarded recursion alone. Categories and Subject Descriptors D.1.1 \n[Programming tech\u00adniques]: Applicative (functional) programming; D.2.4 [Software Engineering]: Software/Program \nVeri.cation; D.3.3 [Program\u00adming Languages]: Language Constructs and Features Data types and structures \nGeneral Terms Languages, Theory, Types, Recursion Keywords coalgebras, corecursion, guarded recursion, \ntotal func\u00adtional programming 1. Introduction Coprogramming refers to the practice of explicitly manipulating \ncodata, the non-well-founded dual of well-founded data like .nite Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. Copyrights for components of this work owned by others than the \nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to \npost on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Request \npermissions from permissions@acm.org. ICFP 13, September 25 27, 2013, Boston, MA, USA. Copyright is held \nby the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-2326-0/13/09. . . $15.00. \nhttp://dx.doi.org/10.1145/2500365.2500597 Conor McBride University of Strathclyde Conor.McBride@strath.ac.uk \n lists and trees. Codata are useful for representing the output of an in.nite process as a never ending \nstream, or for representing potentially in.nite search trees of possibilities. The natural way to express \ncodata is as a recursively de.ned coprogram. However, for recursively de.ned coprograms to be safely \nused in a total setting, the system must ensure that all recursive de.nitions are productive. The state \nof the art for productivity checking is currently either awkward syntactic guardedness checkers, or more \n.exible sized type systems that explicitly label everything with size information. In this paper, we \ninvestigate the use of guarded recursion (due to Hiroshi Nakano [20]) as a lightweight typing discipline \nfor en\u00ad abling productive coprogramming. As we show in this introduction, guarded recursion by itself \nis not suitable for coprogramming, due to the strict segmentation of time inherent in putting guardedness \ninformation in types. We therefore introduce the concept of clock variables to take us from the .nite-time-sliced \nworld of guarded recursion to the in.nite world of codata. The contributions we make in this paper are \nthe following: 1. We de.ne a core type system for comfortable productive co\u00adprogramming, combining three \nkey features: initial algebras, Nakano s guarded recursion and our main conceptual contribu\u00adtion: quanti.cation \nover clock variables. We show that by com\u00adbining the three key features of our system, we obtain a system \nfor programming with .nal coalgebras, the category theoretic description of codata. The combination of \nguarded recursion and clock quanti.cation allows us to dispense with the clunky syntactic guardedness \nchecks, and move to a .exible, composi\u00adtional and local type-based system for ensuring guardedness. \n2. We de.ne a domain-theoretic denotational model that effec\u00adtively interprets our system in the untyped \nlazy .-calculus. We use a multiply-step-indexed model of types to prove that all well-typed programs \nare either terminating or productive and to show the correctness of our reconstruction of .nal coalgebras. \n 3. A side bene.t of the combination of guarded recursion and clock quanti.cation is that, due to the \ncareful tracking of what data is available when through guarded types, we are able to accurately type, \nand show safe, strange circular functional pro\u00adgrams like Bird s replaceMin example.  Despite the large \namount of recent work on guarded recursion (we provide references throughout this introduction), this \nis the .rst paper that formally links guarded recursion to productive co\u00adprogramming. As recently noted \nby Birkedal and M\u00f8gelberg [4], guarded recursive types can be used to [sic] as a crutch for higher\u00adorder \nprogramming with coinductive types . In this paper, we show that this is indeed possible. 1.1 Guardedness \ncheckers and guarded recursion Several systems with support for corecursion, such as Coq (as de\u00adscribed \nby Gim\u00b4 enez [12]) and Agda (as described by Danielsson and Altenkirch [9]), make use of syntactic guardedness \nchecks to ensure productivity of programs de.ned using corecursion. With\u00adout these checks, the soundness \nof these systems cannot be guar\u00adanteed. An unfortunate aspect of these guardedness checks is their non-compositionality. \nWe demonstrate the problem with an exam\u00adple, and see how Nakano s guarded recursion can be used to pro\u00advide \na compositional type-based guardedness check. We will use Haskell notation for each of our informal \nexamples, since it serves to illustrate the issues concisely. Consider the follow\u00ading Haskell declaration \nof a type of in.nite streams of integers: data Stream = StreamCons Integer Stream An example of a Stream \nis the in.nite stream of 1s: ones :: Stream ones = StreamCons 1 ones It is easy to see that this recursive \nde.nition is guarded; ones is only invoked recursively within an application of the stream constructor \nStreamCons. This de.nition of ones de.nes an in.nite data structure, but each piece of the data structure \nis delivered to us in .nite time. Hence, ones is productive. An example of a non-guarded de.nition is \nthe .lter function, extended from .nite lists to in.nite streams: .lter :: (Integer . Bool) . Stream \n. Stream .lter f (StreamCons z s) = if f z then StreamCons z (.lter f s) else .lter f s This de.nition \nis not guarded: in the then-case of the conditional, the recursive call to .lter is not within an application \nof the stream constructor StreamCons. A syntactic guardedness checker is right to reject this de.nition: \nconsider the case when all of the elements of the stream are .ltered out; .lter will never return anything, \nand so will be non-productive. Syntactic guardedness checkers are not always so helpful. The following \nhigher-order function de.nes a general merge function on pairs of streams: mergef :: (Integer . Integer \n. Stream . Stream) . Stream . Stream . Stream mergef f (StreamCons x xs) (StreamCons y ys) = f x y (mergef \nf xs ys) Any syntactic checker looking for constructors to guard recursive calls will reject this function: \nthere are no constructors anywhere in the de.nition! This rejection is with good reason: there are func\u00adtions \nthat we could pass to mergef that would render it unproduc\u00adtive. For example, this function will cause \nmergef to hang on all pairs of streams: badf :: Integer . Integer . Stream . Stream badf x y s = s On \nthe other hand, there are plenty of good functions f that we could use with mergef to obtain productive \nfunctions, but a syntactic guardedness checker does not allow us to express this fact. A possible way \nout of this problem is to retain the syntactic guardedness check, and work around it by changing the \ntype of f. For instance, we could change the required type of f to: f :: Integer . Integer . Integer \nto allow for merging functions that operate element-wise. Or we could change the type to f :: Integer \n. Integer . (Integer, [Integer]) which would allow for the functional argument to replace each pair of \nelements from the input streams with a non-empty list of values. The general trick is to make f return \ninstructions on how to transform the stream back to mergef, which then executes them in a way that the \nsyntactic guardedness checker can see is guarded. This technique has been elaborated in detail by Danielsson \n[8]. However, it is dif.cult to see whether we could capture all the possibilities for good fs in a single \ntype. We could give yet another type which would accommodate the behaviour of the following possible \nvalue of f: f x y s = StreamCons x (map (+y) s) Incorporating the forms of all the possible productive \nde.nitions into a single type seems impractical. Moreover, we complicate the de.nition of mergef, which \nis now forced to become essentially an implementation of a virtual machine for running little stream \ntransformer programs returned by its functional argument, rather than the simple one line de.nition we \ngave above. A more promising type-based solution is provided by Nakano [20]. Nakano introduces a guardedness \ntype constructor that repre\u00ad sents values that may only be used in a guarded way. Thus Nakano transports \nthe guardedness checks from the syntactic level into the type system. We write this constructor, applied \nto a type A, as CA (Nakano uses the notation A, but the CA notation has become more common, and conveys \nan intuitive idea of displacement in time). A useful way to think of CA is as a value of A that is only \navailable tomorrow , and the temporal gap between today and to\u00admorrow can only be bridged by the application \nof a constructor such as StreamCons. The reading of CA as a value of A tomorrow is explicitly supported \nin the step-indexed semantics we present in Section 3 by means of a clock counting down to zero. We now \nalter the type of f to be: f :: Integer . Integer . CStream . Stream This type captures the intuition \nthat the stream argument to f must only be used in a guarded way. To introduce guarded types into the \nsystem, we must make some changes to the types of our primitives. We alter the type of the constructor \nStreamCons as follows, and also introduce a stream deconstructor that we previously implicitly used via \npattern matching: StreamCons :: Integer . CStream . Stream deStreamCons :: Stream . (Integer, CStream) \n The type of StreamCons shows that it takes a guarded stream tomorrow , and produces a non-guarded stream \ntoday . This is in line with the temporal intuition we have of the type CStream. The inverse operation \ndeStreamCons takes a full stream and returns the integer and the guarded remainder of the stream. To \ngive the guardedness type constructor force, Nakano pro\u00adposes the following alternative type of the .xpoint \noperator for de.ning recursive values: .x :: (CA . A) . A (The standard typing of the .x operator is \n(A . A) . A.) Nakano s alternative typing ensures that recursive de.nitions must be guarded by only allowing \naccess to recursively generated values tomorrow . To actually program with the guardedness constructor, \nwe equip it with the structure of an applicative functor [18]: pure :: A . CA (\u00ae) :: C(A . B) . CA . \nCB Note that C is not a monad: a join operation of type C(CA) . CA would allow us to collapse multiple \nguardedness obligations. This method for integrating Nakano s guardedness type con\u00adstructor into a typed \n.-calculus is not the only one. Nakano uses a system of subtyping with respect to the guardedness type \nconstruc\u00adtor that has a similar effect to assuming that C is an applicative functor. We propose to treat \nC as an applicative functor here, due to the greater ease with which it can be incorporated into a standard \nfunctional programming language like Haskell. Krishnaswami and Benton [14, 15] have presented an alternative \nmethod that anno\u00ad tates members of the typing context with the level of guardedness that applies to them. \nSeveri and de Vries [22] have generalised Kr\u00ad ishnaswami and Benton s approach for any typed .-calculus \nde\u00adrived from a Pure Type System (PTS), including dependently typed systems. These calculi have nice \nproof theoretic properties, such as being able to state productivity in terms of in.nitary strong normal\u00adisation. \n With the guardedness type constructor, and its applicative func\u00adtor structure, we can rewrite the mergef \nfunction to allow the alter\u00adnative typing which only allows functional arguments that will lead to productive \nde.nitions. mergef :: (Integer . Integer . CStream . Stream) . Stream . Stream . Stream mergef f = .x \n(.g xs ys. ' let (x, xs) = deStreamCons xs ' (y, ys) = deStreamCons ys in f x y (g \u00ae xs' \u00ae ys')) Aside \nfrom the explicit uses of .x and deStreamCons, which were hidden by syntactic sugar in our previous de.nition, \nthe only substantial changes to the de.nition are the uses of applicative functor apply (\u00ae). These uses \nindicate operations that are occurring under a guardedness type constructor.  1.2 From the in.nite to \nthe .nite The type system for guarded recursion that we described above al\u00adlowed us to remove the syntactic \nguardedness check and replace it with a compositional type-based one. However, aside from propos\u00ading \napplicative functor structure as a convenient way to incorporate the guardedness type constructor into \na functional language, we have not gone much beyond Nakano s original system. We now de\u00adscribe a problem \nwith guarded recursion when attempting to com\u00adbine in.nite and .nite data. We propose a solution to this \nproblem in the next subsection. Consider the take function that reads a .nite pre.x of an in.nite stream \ninto a list. This function will have the following type: take :: Natural . Stream . [Integer] where we \nwish to regard the type [Integer] as the type of .nite lists of integers. The explicit segregation of \nwell-founded and non-well\u00adfounded types is important for our intended applications of total functional \nprogramming and theorem proving. We also assume that the type Natural of natural numbers is well\u00adfounded, \nso we may attempt to write take by structural recursion on its .rst argument. However, we run into a \ndif.culty, which we have highlighted . take :: Natural . Stream . [Integer] take 0 s = [] ' take (n + \n1) s = x : take n s ' where (x, s) = deStreamCons s ' The problem is that the variable s, which we have \nobtained from deStreamCons, has type CStream. However, to invoke the take function structurally recursively, \nwe need something of type Stream, without the guardedness restriction. We analyse this problem in terms \nof our intuitive reading of CStream as a stream that is available tomorrow . Nakano s typing discipline \nslices the construction of in.nite data like Stream into discrete steps. In contrast, a well-founded \ndata type like [Integer] lives entirely in the moment. While a stream is being constructed, this slicing \nis required so that we do not get ahead of ourselves and attempt to build things today from things that \nwill only be available tomorrow. But once a stream has been fully constructed, we ought to be able to \nblur the distinctions between the days of its construction. We accomplish this in our type system by \nmeans of clock variables, and quanti.cation over them.  1.3 Clock variables We extend the type system \nwith clock variables .. A clock variable . represents an individual time sequence that can be used for \nsafe construction of in.nite data like streams. In our model, clock variables are interpreted as counters \nrunning down to zero in the style of step-indexed models. By quantifying over all counters we are able \nto accommodate all possible .nite observations on an in.nite data structure. We annotate the guardedness \ntype constructor with a clock vari\u00adable to indicate which time stream we are considering: C.A. In.nite \ndata types such as streams are now annotated by their clock vari\u00adable, indicating the time stream that \nthey are being constructed on. We have the following new types for the constructor and decon\u00adstructor: \nStreamCons. :: Integer . C.Stream. . Stream. deStreamCons. :: Stream. . (Integer, C.Stream.) We now \nregard the type Stream. as the type of in.nite streams in the process of construction. A .nished in.nite \nstream is repre\u00adsented by quantifying over the relevant clock variable: ...Stream. . If we think of each \npossible downward counting counter that . could represent, then this universally quanti.ed type allows \nfor any counter large enough to allow us any .nite extraction of data from the stream. We use the notation \n...e and e[.] to indicate clock abstraction and application respectively, in the style of explicitly \ntyped System F type abstraction and application. The .xpoint operator is parameterised by the clock variable: \n.x :: ...(C.A . A) . A as is the applicative functor structure carried by C.: pure :: ...A . C.A . .. \n(\u00ae) :: ...C(A . B) . CA . CB We also add an additional piece of structure to eliminate guarded types \nthat have been universally quanti.ed: force :: (... C.A) . (... A) Intuitively, if we have a value that, \nfor any time stream, is one time step away, we simply instantiate it with a time stream that has at least \none step left to run and extract the value. Note that the universal quanti.cation is required on the \nright hand side since . may appear free in the type A. The force operator has a similar .avour to the \nrunST :: (.s.ST s a) . a for the ST monad [16, 19]. In both cases, rank-2 quanti.cation is used to prevent \nvalues from leaking out from the context in which it is safe to use them. Using force we may write a \ndeconstructor for completed streams of type ...Stream. . deStreamCons :: (...Stream.) . (Integer, ...Stream.) \ndeStreamCons x = (...fst (deStreamCons. (x[.])), force (...snd (deStreamCons. (x[.])))) In this de.nition \nwe have made use of a feature of our type system that states that the type equality ...A = A holds whenever \n. is not free in A. Our system also includes other type equalities that demonstrate how clock quanti.cation \ninteracts with other type formers. These are presented in Section 2.2. In the presence of clock variables, \nour de.nition of take is well\u00adtyped and we get the function we desire: taking a .nite observation of \na piece of in.nite data: take :: Natural . (...Stream.) . [Integer] take 0 s = [] take (n + 1) s = x \n: take n s' where (x, s ' ) = deStreamCons s Clock variables also allow us to make clear in the types \n.ne distinctions between functions that are extensionally equal, but dif\u00adfer in their productivity. In \nplain Haskell, the following two stream mapping functions have the same behaviour on any completely con\u00adstructed \nstream. The .rst map processes each element one at a time map f s = StreamCons (f x) (map f s ' ) where \n(x, s ' ) = deStreamCons s while maap processes elements two at a time by pattern matching: maap f (StreamCons \nx (StreamCons y s '' )) = StreamCons (f x) (StreamCons (f y) (maap f s '' )) If all the elements of the \ninput are available at once, then map and maap have the same behaviour. However, if these functions are \npassed streams that are still being constructed, then their behaviour can differ signi.cantly. Consider \nthese two de.nitions of a stream of natural numbers, using map and maap: nats = StreamCons 0 (map (.x. \nx + 1) nats) badnats = StreamCons 0 (maap (.x. x + 1) badnats) Running nats produces the in.nite stream \nof natural numbers, as expected, but running badnats produces nothing. The function maap expects two \nelements to be available on its input stream, while badnats has only provided one. Even though map and \nmaap are extensionally equal, they have different behaviour on partially constructed streams. We can \nstate this different behaviour using the following types in our system: map :: ...(Integer . Integer) \n. Stream. . Stream. maap :: (Integer . Integer) . (...Stream.) . (...Stream.) Thus, map s type states \nthat the input stream and output stream run on the same clock ., so each element of the output will only \nrequire one element of the input. This is exactly what nats requires, and our type system will accept \nthe de.nition of nats. In contrast, maap s type states that it requires a fully constructed stream as \ninput. The de.nition of badnats does not provide this, and so our type system will reject it. By using \nclock quanti.cation to close over the guardedness, our approach thus localises the discipline which makes \nthe produc\u00adtivity of de.nitions plain, without affecting the types at which the de.ned objects are used. \nAbel s sized types impose a similar disci\u00adpline, but globally [1].  1.4 Final coalgebras from initial \nalgebras, guards and clocks In the previous subsection, we informally stated that the type Stream = ...Stream. \nrepresents exactly the type of in.nite streams of integers. We make this informal claim precise by us\u00ading \nthe category theoretic notion of .nal coalgebra. A key feature of our approach is that we decompose the \nnotion of .nal coalgebra into three parts: initial algebras, Nakano-style guarded types, and clock quanti.cation. \nInitial algebras In Section 2 we present a type system that in\u00adcludes a notion of strictly positive type \noperator. We include a least .xpoint operator \u00b5X.F [X]. For normal strictly positive type oper\u00adators \nF (i.e. ones that do not involve the C. operator), \u00b5X.F [X] is exactly the normal least .xpoint of F \n. Thus we can de.ne the nor\u00admal well-founded types of natural numbers, lists, trees and so on. Our calculus \ncontains constructors ConsF :: F [\u00b5X.F ] . \u00b5X.F for building values of these types, and recursion combinators \nfor eliminating values: primRecF,A :: (F [(\u00b5X.F ) \u00d7 A] . A) . \u00b5X.F [X] . A We opt to use primitive \nrecursion instead of a fold operator (i.e. fold :: (F [A] . A) . \u00b5X.F [X] . A) because it allows for \nconstant time access to the top-level of an inductive data structure. We show in the proof of Theorem \n2 that \u00b5X.F is the carrier of the initial F -algebra in our model. Therefore, we may use stan\u00addard reasoning \ntechniques about initial algebras to reason about programs written using the primRec combinator. Guarded \n.nal coalgebras When we consider strictly positive type operators of the form F [C.X], where . does not \nappear in F then, in addition to \u00b5X.F [C.X] being the least .xpoint of the operator F [C.-], it is also \nthe greatest .xpoint. This initial-.nal coincidence is familiar from domain theoretic models of recursive \ntypes (see, e.g., Smyth and Plotkin [23]), and has previously been observed as a feature of guarded recursive \ntypes by Birkedal et al. [6]. The unfold combinator that witnesses \u00b5X.F [C.X] as .nal can be implemented \nin terms of the .x operator, and Cons: unfoldF :: ...(A . F [C.A]) . A . \u00b5X.F [C.X] unfoldF = ....f..x \n(.g a.Cons (fmapF (.x.g \u00ae x) (f a))) where fmapF :: (A . B) . (F [A] . F [B]) is the functorial mapping \ncombinator associated with the strictly positive type oper\u00adator F . Note that without the additional \nC. in F [C.-], there would be no way to de.ne unfold, due to the typing of .x. To make observations on \nelements, we de.ne a deConsF com\u00adbinator for every F , using the primitive recursion . .. deConsF :: \n...(\u00b5X.F [CX]) . F [C\u00b5X.F [CX]] deConsF = ...primRec (.x. fmapF [r.-] (.y.fst y) x) The proof of Theorem \n3 shows that these de.nitions of unfoldF and deConsF exhibit \u00b5X.F [C.X] as the .nal F [C.-]-coalgebra, \nusing deConsF as the structure map. This means that unfoldF [.]f is the unique F [C.-]-coalgebra homomorphism \nfrom A to \u00b5X.F [C.-]. Final coalgebras Theorem 3 only gives us .nal coalgebras in the case when the recursion \nin the type is guarded by the type constructor C.-. So we do not yet have a dual to the least .xpoint \ntype constructor \u00b5X.F . However, as we hinted above in the case of streams, we can use clock quanti.cation \nto construct a .nal F \u00adcoalgebra, where F need not contain an occurrence of C.-. For the type ...\u00b5X.F \n[C.-] we de.ne an unfold. operator, F in a similar style to the unfoldF operator above. However, this \noperator takes an argument of type (A . F [A]), with no mention of guardedness. unfold. F :: (A . F [A]) \n. A . ...\u00b5X.F [C.X] unfold. = .f a.... F .x (.g a.ConsF (fmapF (.x.g \u00ae pure x) (f a))) a We can also \nde.ne the corresponding deconstructor, building on the de.nition of deConsF above, but also using the \nforce construct in conjunction with clock quanti.cation. This is a generalisation of the de.nition of \ndeStreamCons above. deCons. :: (...\u00b5X.F [C. .X]] F X]) . F [...\u00b5X.F [CdeCons. F = .x. fmapF (.x.force \nx) (... deConsF [.] (x[.])) In the application of fmapF , we make use of the type equalities in our \ncalculus, which allow us to treat the types ...F [X] and F [...X] as equivalent, when . does not appear \nin F . We present the type equalities in Section 2.2, and prove them sound in Sec\u00ad tion 3.4. Our last \nmain technical result, Theorem 4, states that, in the semantics we de.ne Section 3, ...\u00b5X.F [C.-] actually \nis the .nal F -coalgebra. The use of clock quanti.cation has allowed us to remove mention of the guardedness \ntype constructor, and given us a way to safely program and reason about F -coalgebras.  1.5 Circular \ntraversals of trees We now present a perhaps unexpected application of the use of clock quanti.cation \nthat does not relate to ensuring productivity of recursive programs generating in.nite data. An interesting \nuse of laziness in functional programming languages is to perform single\u00adpass transformations of data \nstructures that would appear to require at least two passes. A classic example, due to Bird [3], is the \nreplaceMin function that replaces each value in a binary tree with the minimum of all the values in the \ntree, in a single pass. In normal Haskell, this function is written as follows: replaceMin :: Tree . \nTree replaceMin t = let (t ' , m) = replaceMinBody t m in t ' where replaceMinBody (Leaf x) m = (Leaf \nm, x) replaceMinBody (Br l r) m = let (l' , ml) = replaceMinBody l m (r ' , mr) = replaceMinBody r m \nin (Br l' r ' , min ml mr) The interesting part of this function is the .rst let expression. This takes \nthe minimum value m computed by the traversal of the tree and passes it into the same traversal to build \nthe new tree. This function is a marvel of declarative programming: we have declared that we wish the \ntree t ' to be labelled with the minimum value in the tree t just by stating that they be the same, without \nexplaining at all why this de.nition makes any sense. Intuitively, the reason that this works is that \nthe overall minimum value is never used in the computation of the minimum, only the construction of the \nnew tree. The computation of the minimum and the construction of the new tree conceptually exist at different \nmoments in time, and it is only safe to treat them the same after both have .nished. Using explicit clock \nvariables we can give a version of the replaceMin de.nition that demonstrates that we have actually de\u00ad.ned \na total function from trees to trees. The use of clock variables allows us to be explicit about the time \nwhen various operations are taking place. Out .rst step is to replace the circular use of let with a \nfeedback combinator de.ned in terms of the .x operator: feedback : ... (C.U . (B[.], U )) . B[.] feedback \n= ....f.fst (.x (.x. f (pure (.x.snd x) \u00ae x))) In the application of the .x operator, x : C.(B \u00d7 U). \nThe notation B[.] indicates that . may appear free in the type B. We now rewrite the replaceMinBody function \nso that we can apply feedback to it. We have highlighted the changes from the previous de.nition. replaceMinBody \n:: Tree . ... . Integer . ( C. Tree, Integer) replaceMinBody (Leaf x) m = ( pure Leaf \u00ae m, x) replaceMinBody \n(Br l r) m = let (l' , ml) = replaceMinBody l m (r ' , mr) = replaceMinBody r m in ( pure Br \u00ae l' \u00ae r \n' , min ml mr) The changes required are minor: we must change the type, and use the applicative functor \nstructure of C. to indicate when computa\u00adtions are taking place tomorrow . Applying feedback to replaceMinBody, \nand using force to re\u00admove the now redundant occurrence of C., we can de.ne the full replaceMin function \nin our system: replaceMin :: Tree . Tree replaceMin t = force (...feedback[.] (replaceMinBody[.]) t) \nX . T .; T f X : type .; T f 1 : type .; T f A : type .; T f B : type .; T f A \u00d7 B : type .; T f A : \ntype .; T f B : type .; T f A + B : type .; - f A : type .; T f B : type .; T f A . B : type .; T, \nX f A : type ., .; T f A : type .; T f \u00b5X.A : type .; T f ...A : type .; T f A : type . . . .; T f C.A \n: type Figure 1. Well-formed types and type operators By the soundness property of our system that we \nprove in Section 3, we are assured that we have de.ned a total function from trees to trees. The standard \nHaskell type system does not provide this guarantee. 1.6 Models of guarded recursion To substantiate \nthe claims we have made in this introduction, in Section 3 we construct a multiply-step-indexed model \nof the type system we present in the next section. The multiple step-indexes are required for the multiple \nclock variables in our system, each representing separate time streams. Step-indexed models were in\u00adtroduced \nby Appel and McAllester [2] to prove properties of recur\u00ad sive types. The use of step-indexing serves \nto break the circularity inherent in recursive types. Dreyer et al. [10] exposed the connec\u00ad tion between \nNakano s guarded recursion and step indexed models. More recently, Birkedal et al. [4, 6] have elaborated \nthis connec\u00ad tion, particularly in the direction of dependent types. Alternative semantics for guarded \nrecursion have involved ul\u00adtrametric spaces, for example Birkedal et al. [5] and Krishnaswami and Benton \n[15]. Hutton and Jaskelioff [13] have also used an ap\u00adproach based on metric spaces for identifying productive \nstream generating functions. Finally, we mention the syntactic approach of Severi and de Vries [22], \nwho de.ne the notion of in.nitary strong normalisa\u00ad tion to prove productivity of dependent type systems \nwith guarded recursion. 2. A type system with clocks and guards In the introduction, we presented our \nmotivating examples in terms of a Haskell-like language informally extended with a Nakano-style guard \nmodality and clock quanti.cation. To formally state the prop\u00aderties of our combination of clock quanti.cation, \nclock-indexed guard modalities and inductive types, in this section we de.ne an extension of the simply-typed \n.-calculus with these features. In the next section, we de.ne a semantics for our system in which we \ncan formally state the results that we claimed in the introduction. 2.1 Well-formed types with clock \nvariables The types of our system include two kinds of variable that may occur free and bound: clock \nvariables in the clock quanti.er and the clock-indexed guard modality, as well as type variables occurring \nin strictly positive positions for the inductive types. We therefore formally de.ne when a type is well-formed \nwith respect to contexts of clock and type variables, using the rules displayed in Figure 1. The well-formedness \njudgement for types (.; T f A : type) is de.ned with respect to a clock context . and a type variable \ncon\u00adtext T. Clock contexts are lists of clock variables, . = .1, ..., .n, and type variable contexts \nare lists of type variable names, T = X1, ..., Xn. Type variables are only used to manage the scope of \nthe nested least .xpoint type operator \u00b5; there is no type polymor\u00adphism in the type system we present \nhere. We generally use Roman letters A, B, C to stand for types, but we also occasionally use F and G \nwhen we wish to emphasise that types with free type vari\u00adables are strictly positive type operators. \nFor any type A, we de.ne fc(A) to be the set of free clock variables that appear in A. Most of the type \nwell-formedness rules are standard: we have a rule for forming a type from a type variable that is in \nscope and rules for forming the unit type 1, product types A \u00d7 B, sum types A + B, function types A . \nB and least .xpoint types \u00b5X.A. We enforce the restriction to strictly positive type operators by disallowing \noccurrences of free type variables in the domain component of function types. In Section 2.3, we will \nsee that each of the standard type constructors will have the usual corresponding term-level constructs; \nour system subsumes the simply typed .\u00adcalculus with products, sums and least .xpoint types. The remaining \ntwo rules are for forming clock quanti.cation ...A types and the clock-indexed Nakano-style guard modality \nC.A. The type formation rule for clock quanti.cation is very similar to universal type quanti.cation \nfrom standard polymorphic type theories like System F. As we described in the introduction in Section \n1.3, we have augmented the Nakano-style delay modality with a clock variable. This allows us to distinguish \nbetween guardedness with respect to multiple clocks, and hence to be able to close over all the steps \nguarded by a particular clock.  2.2 Type Equality The examples we presented in the introduction made \nuse of several type equalities allowing us to move clock quanti.cation through types. For instance, in \nthe de.nition of the deStreamCons stream deconstructor in Section 1.3, we made use of a type equality \nto treat a value of type ...Integer as having the type Integer. Intuitively, this is valid because a \nvalue of type Integer exists independently of any clock, therefore we can remove the clock quanti.cation. \nIn general, clock quanti.cation commutes with almost all strictly positive type formers, except for guards \nindexed by the same clock variable. For those, we must use force. The following rules are intended to \nbe read as de.ning a judge\u00adment .; T f A = B : type, indicating that the well-formed types .; T f A : \ntype and .; T f B : type are to be considered equal. In addition to these rules, the relation . f A = \nB : type is re.exive, symmetric, transitive and a congruence. ...A = A (. . fc(A)) ...A + B = (...A) \n+ (...B) ...A \u00d7 B = (...A) \u00d7 (...B) ...A . B = A . ...B (. . fc(A)) ..... ' .A = .. ' ....A (.= . ' ) \n.' . = . ' ...\u00b5X.F [A, X ] = \u00b5X.F [...A, X ] (fc(F ) = \u00d8) ...CA = C' ...A (. ) In the last rule, F must \nbe strictly positive in A as well as X. After we de.ne the terms of our system in the next sub-section, \nit will become apparent that several of the type equality rules could be removed, and their use replaced \nby terms witnessing the conversions back and forth. In the case of product types, we could de.ne the \nfollowing pair of terms (using the syntax and typing rules we de.ne below): .x.(...fst (x[.]), ...snd \n(x[.])) : (...A \u00d7 B) . (...A) \u00d7 (...B) and .x....(fst x [.], snd x [.]) : (...A) \u00d7 (...B) . ...A \u00d7 B \n Indeed, the denotational semantics we present in Section 3 will interpret both of these functions as \nthe identity. However, not all the type equality rules are expressible in terms of clock abstraction \nand application, for instance, the ...A = A rule and the rule for sum types. Moreover, our de.nition \nof deCons in Section 1.4 is greatly simpli.ed by having clock quanti.cation commute with all type formers \nuniformly (recall that we made crucial use of the equality ...F [-] = F [...-]). Therefore, we elect \nto include type equalities for commuting clock quanti.cation with all type formers uniformly. 2.3 Well-typed \nTerms The terms of our system are de.ned by the following grammar: e, f, g ::= x | * | .x. e | f e | \n(e1, e2) | fst e | snd e | inl e | inr e | case e of inl x.f; inr y.g | ConsF e | primRecF e | ...e | \ne[. ' ] | pure x | f \u00ae e | .x f | force e The well-typed terms of our system are de.ned by the typing \njudgement .; G f e : A, given by the rules presented in Figure 2. Terms are judged to be well-typed with \nrespect to a clock variable context ., and a typing context G consisting of a list of variable : type \npairs: x1 : A1, ..., xn : An. We only consider typing contexts where each type is well-formed with respect \nto the clock variable context ., and the empty type variable context. The result type A in the typing \njudgement must also be well-formed with respect to . and the empty type variable context. We have split \nthe typing rules in Figure 2 into .ve groups. The .rst group includes the standard typing rules for the \nsimply\u00adtyped .-calculus with unit, product and sum types. Apart from the additional clock variable contexts \n., these rules are entirely standard. The second group contains the rules for the inductive types \u00b5X.F \n. Again, apart from the appearance of clock variable contexts, these rules are the standard constructor \nand primitive recursion constructs for inductive types. The third group of rules cover clock abstraction \nand application, and the integration of the type equality rules we de.ned in the previous section. In \nthe .-A P P rule, we have used the notation A[. . . ' ] to indicate the substitution of the clock variable \n. ' for .. These rules are as one might expect for System F-style quanti.cation with non-trivial type \nequality, albeit that in the .-AP P rule the . ' clock variable cannot already appear in the type. This \ndisallows us from using the same clock variable twice, preventing multiple time-streams becoming con.ated. \nThe fourth group of rules state that the clock-indexed guard modality supports the pure and apply (\u00ae) \noperations of an applica\u00adtive functor. When we de.ne a denotational semantics of our calcu\u00adlus in the \nnext section, these operations will be interpreted simply as the identity function and normal function \napplication respectively, meaning that the applicative functor laws hold trivially. Finally, the .fth \ngroup of rules presents the typing for Nakano s guarded .x combinator, now indexed by a clock variable, \nand our force combinator for removing the guard modality when it is protected by a clock quanti.cation. \n 2.4 Type operators are functorial In Section 1.4 we used a functorial mapping function fmapF : (A . \nB) . F [A] . F [B], which we claimed was de.ned 1. Simply-typed .-calculus with products and sums x \n: A . G .; G, x : A f e : B .; G f f : A . B .; G f e : A (VAR) (UNIT) (ABS) (APP) .; G f x : A .; G \nf * : 1 .; G f .x. e : A . B .; G f fe : B .; G f e1 : A .; G f e2 : B .; G f e : A \u00d7 B .; G f e : A \n\u00d7 B .; G f e : A (PAIR) (FST) (SND) (INL) .; G f (e1, e2) : A \u00d7 B .; G f fst e : A .; G f snd e : B .; \nG f inl e : A + B .; G f e : B .; G f e : A + B .; G, x : A f f : C .; G, y : B f g : C (INR) (CASE) \n.; G f inr e : A + B .; G f case e of inl x.f; inr y.g : C 2. Least Fixpoint Types .; G f e : F [\u00b5X.F \n[X]] .; G f e : F [(\u00b5X.F [X]) \u00d7 A] . A (CONS) (PRIMREC) .; G f ConsF e : \u00b5X.F [X] .; G f primRecF e : \n\u00b5X.F [X] . A 3. Clock Abstraction and Application, and Type Equality ., .; G f e : A . . fc(G) .; G f \ne : ...A . ' . . . ' . fc(A) (.-ABS) (.-APP) .; G f ...e : ...A .; G f e[. ' ] : A[. . . ' ] .; G f e \n: A . f A = B (TYEQ) .; G f e : B 4. Applicative Functor Structure for C.- .; G f e : A . . . .; G f \nf : C.(A . B) .; G f e : C.A (DEPURE) (DEAPP) .; G f pure e : C.A .; G f f \u00ae e : C.B 5. Fix and Force \n.; G f f : C.A . A .; G f e : ...C.A (FIX) (FORCE) .; G f .x f : A .; G f force e : ...A Figure 2. Well-typed \nterms - ----. . . - - fmapF : (A . B) . F [ A ] . F [B ] l fmapXi fx = fi x l fmap1 fx = * lll fmapF \n\u00d7G fx = (fmapF f (fst x), fmapG f (snd x)) ll fmapF +G fx = case x of inl y. inl (fmapF f y) l inr z.inr \n(fmapG f z) ll fmapA.F fx = .a. fmapF f (x a) ll fmapr.F fx = pure (fmapF f) \u00ae x ll fmap...F fx = ...fmapF \nf (x[.]) l l fmap\u00b5X.F fx = primRec (.x.Cons(fmapF f (.x. snd x) x)) x Figure 3. fmapF for all type operators \nF for each strictly positive type operator F . We de.ne this operator by structural recursion on the \nderivation of F , using the clauses in Figure 3. Due to the presence of nested least .xpoint types in \nour calculus, we handle n-ary strictly positive type operators.  2.5 Programming with guarded types \nand clocks Lists and Trees, Finite and In.nite Using the least .xpoint type operator \u00b5X.F , we can reconstruct \nmany of the usual in\u00adductive data types used in functional programming. For example, the OCaml declaration: \n type list = NilList | ConsList of A \u00d7 list of .nite lists of values of type A, can be expressed as \nthe type \u00b5X.1 + A \u00d7 X in our system, where we have replaced the two constructors NilList and ConsList \nwith a use of the sum type former. Likewise, the type of binary trees labelled with As that we used in \nSection 1.5 can be written as \u00b5X.A + X \u00d7 X. A similar data type declaration in Haskell has a different \ninter\u00adpretation. If we make the following declaration in Haskell: data List = NilList | ConsList A List \n then the type List includes both .nite lists of As, and in.nite lists of As (a similar effect can be \nachieved in OCaml by use of the lazy type constructor). Haskell s type system is too weak to distinguish \nthe de.nitely .nite from the possibly in.nite case, and it is often left to the documentation to warn \nthe programmer that some functions will be non-productive on in.nite lists (for example, the reverse \nfunction). Making use of Nakano s guard modality C.-, we are able to express Haskell-style possibly in.nite \nlists as the guarded inductive type \u00b5X.1 + A \u00d7 C.A. As we saw in the introduction, in.nite lists can \nbe constructed using the guarded .x operator. For example, the in.nite repetition of a .xed value can \nbe written in our system as: .a..x (.l.Cons (inr (a, l)))  If we restrict ourselves to only one clock \nvariable, and always use guarded recursive types, then we obtain a programming language similar to a \nmonomorphic Haskell, except with a guarantee that all functions are productive. Co-inductive Streams \nAs we saw in Section 1.2, programming with guarded types is productive, but they are fundamentally in\u00adcompatible \nwith normal inductive types. Recall that if we de.ne in.nite streams of As as Stream. A = \u00b5X.A \u00d7 C.X, \nthen there is no way of de.ning a function tail : Stream. A . Stream. A; the best we can do is tail : \nStream. A . C.Stream. A. The rest of the stream only exists tomorrow . Clock quanti.cation .xes this \nproblem. We de.ne: Stream A = ...\u00b5X.A \u00d7 C.A Now we can de.ne the two deconstructors for making observations \non streams, with the right types: head : Stream A . A head = .s....primRec (.x.fst x) (s[.]) tail : \nStream A . Stream A tail = .s.(force (...primRec (.x.pure(.x.fst x) \u00ae (snd x)) (s[.]))) In the de.nition \nof head we use the fact that . cannot appear in A to apply the .rst type equality rule from Section 2.2. \nStream Processing Ghani, Hancock and Pattinson [11] de.ne a type of representations of continuous functions \non streams using a least .xpoint type nested within a greatest .xpoint. A continuous function on streams \nis a function that only requires a .nite amount of input for each element of the output. Ghani et al. \ns type is expressed in our system as follows: SP I O = ...\u00b5X.\u00b5Y.(I . Y ) + (O \u00d7 C.X) where SP stands \nfor Stream Processor and I and O stand for input and output respectively. In this type, the outer .xpoint \npermits the production of in.nitely many Os, due to the guarded occurrence of X, while the inner .xpoint \nonly permits a .nite amount of Is to be read from the input stream. This kind of nested .xpoint is not \nexpressible within Coq, but is possible with Agda s support for coinductive types [9]. De.ning the application \nof an SP I O to a stream of I s serves as an interesting example of programming with guards and clocks. \nWe make use of a helper function for unfolding values of type SP I O that have already been instantiated \nwith some clock: step : SP. I O . \u00b5Y.(I . Y ) \u00d7 (O \u00d7 C.(SP. I O)) where SP. I O is SP I O instantiated \nwith the clock .. The de.nition of stream processor application goes as follows, where we permit ourselves \na little pattern matching syntactic sugar for pairs: apply : SP I O . Stream I . Stream O apply = .sp \ns.....x(.rec sp s. primRec (.x s.case x of inl f. f (head s)(tail s) inr (o, sp ). Cons(o, rec \u00ae sp \u00ae \npure s)) (step sp)) (sp [.]) s This function consists of two nested loops. The outer loop, ex\u00adpressed \nusing .x, generates the output stream. This loop is running on the clock ., introduced by the ... We \nhave instantiated the stream processor with the same clock; this causes the steps of the output stream \nto be in lockstep with the output steps of the stream processor, exactly as we might expect. The inner \nloop, expressed using primRec, recurses over the .nite list of input instructions from the stream processor, \npulling items from the input stream as needed. The input stream is not instantiated with the same clock \nas the stream processor and the output stream: we need to access an arbitrary number of elements from \nthe input stream for each step of the stream processor, so their clocks cannot run in lockstep. The \nPartiality Monad The partiality monad is a well-known coinductively de.ned monad that allows the de.nition \nof func\u00adtions via general recursion, even in a total language. The partiality monad is de.ned as Partial \nA = . X.A +X. Hence, a value of type Partial A consists of a stream of inrs, either continuing forever, \nor terminating in an inl with a value of type A. Using the partiality monad, possibly non-terminating \ncomputations can be represented, with non-termination represented by an in.nite stream that never returns \na value. Capretta [7] gives a detailed description. To express the partiality monad in our system, we \ndecompose it into a guarded least .xpoint and clock quanti.cation, just as we did for streams and stream \nprocessors above: Partial. A = \u00b5X.A + C.X Partial A = ...Partial. A For convenience, we de.ne two constructors \nfor Partial. A, corre\u00adsponding to the two components of the sum type: now. : A . Partial. A now. = .a. \nCons (inl a) later. : C.(Partial. A) . Partial. A later. = .p. Cons (inr p) It is straightforward to \nuse guarded recursion and clock quanti.\u00adcation to de.ne the return and bind functions that demonstrate \nthat Partial is indeed a monad. For an example of a possibly non\u00adterminating function that can be expressed \nusing the partiality monad, we de.ne the following function collatz. For each natu\u00adral number n, this \nfunction only terminates if the Collatz sequence starting from n reaches 1. Whether or not this sequence \nreaches 1 for all n is a famous unsolved question in number theory. collatz : Natural . Partial 1 collatz \n= .n.....x (.rec n.if n = 1 then now. (*) else if n mod 2 = 0 then later. (rec \u00ae (pure (n/2))) else later. \n(rec \u00ae (pure (3 * n + 1)))) n The partiality monad is not a drop-in replacement for general recursion. \nThe type Partial A reveals information about the number of steps that it takes to compute a value of \ntype A. Therefore, it is possible to write a timeout function that runs a partial computation for a .xed \nnumber of steps before giving up: timeout : Natural . Partial A . A + 1 The partiality monad allows \nus to write possibly non-terminating functions, but also allows us to make more observations on them. \n3. A denotational semantics for clocks and guards We have claimed that the typing discipline from the \nprevious sec\u00adtion guarantees that programs will be productive. We now substan\u00adtiate this claim by de.ning \na domain-theoretic model of our sys\u00adtem, and showing that the denotation of a well-typed closed term \nis never .. We accomplish this by using a multiply-step-indexed interpretation of types, where the multiple \nstep indexes correspond to the multiple clock variables that may be in scope. [x]. = .(x) = Unit [*]. \n[.x. e]. = Lam (.v. [e](.[x . v])) df ([e].) if [f]. = Lam df[f e]. = . otherwise [(e1, e2)]. = Pair \n([e1]., [e2].) d1 if [e]. = Pair (d1, d2) [fst e]. = . otherwise d2 if [e]. = Pair (d1, d2) [snd e]. \n= . otherwise [inl e]. = Inl ([e].) [inr e]. = Inr ([e].) . case e of . [f](.[x . d]) if [e]. = Inl \nd inl x.f = [g](.[y . d]) if [e]. = Inr d [ I . . inr y.g. otherwise Figure 4. Semantics for the simply-typed \nportion of our system 3.1 Semantics of terms We interpret terms in (a mild extension of) the standard \ndomain the\u00adoretic model of the untyped lazy .-calculus, described by Pitts [21]. A feature of this semantics \nis the erasure of anything to do with the guardedness type constructor C.- and the clock quanti.cation. \nThe .x operator is interpreted as the domain-theoretic .xpoint, i.e., ex\u00adactly the usual interpretation \nof general recursion. We assume a directed complete partial order with bottom (DCPO.), D, satisfying \nthe following recursive domain equation: D ~ = (D . D). . (D \u00d7 D). . D. . D. . 1. where . represents \nthe coalesced sum that identi.es the . element of all the components. We are guaranteed to be able to \nobtain such a D by standard results about the category DCPO. (see, e.g., Smyth and Plotkin [23]). The \n.ve components of the right hand side of this equation will be used to carry functions, products, the \nleft and right injections for sum types and the unit value respectively. We use the following symbols \nto represent the corresponding continuous injective maps into D: Lam : (D . D) . D Pair : D \u00d7 D . D Inl \n: D . D Inr : D . D Unit : 1 . D We will write Unit instead of Unit *. Let V be the set of all possible \nterm-level variable names. Environments . are modelled as maps from V to elements of D. Terms are interpreted \nas continuous maps from environments to elements of D. The clauses for de.ning the interpretation of \nparts of our system that are just the simply-typed .-calculus are standard, and displayed in Figure 4. \nIt can be easily checked that this collection of equations de.nes a continuous function [-] : (V . D) \n. D, since everything is built from standard parts. The applicative functor structure for the guard modality \nis inter\u00adpreted just as the identity function and normal application, as we promised in Section 2.3: \n[pure e]. = [e]. df ([e].) if [f ]. = Lam df[f \u00ae e]. = . otherwise Our interpretation simply translates \nthe .x operator as the usual .x\u00ad point operator .x f = n fn(.) in DCPO.. The force operator l fmapX \nf x = df (x) (fX = Lam df ) l fmap1 f x = Unit ll fmapF\u00d7G f (Pair (x, y)) = Pair (fmapF f x, fmapG f \ny) ll fmapF+G f (Inl x) = Inl (fmapF f x) ll fmapF+G f (Inr x) = Inr (fmapG f x) ll fmapA.F f (Lam g) \n= Lam (.v.fmapF f (g v)) ll fmapr.F f x = fmapF f x ll fmap...F f x = fmapF f x ll fmap\u00b5X.F f x = primrec \n(fmapF f) l (fmapF f snd) x where snd (Pair (x, y)) = y All unhandled cases are de.ned to be equal \nto .. Figure 5. Semantic fmapF for .; T f F : type is interpreted as a no-operation. .x df if [f]. \n= Lam df [.x f]. = . otherwise [force e]. = [e]. Finally, we interpret the constructor ConsF and primitive \nrecur\u00adsion eliminator primRecF for least .xpoint types. The interpreta\u00adtion of construction is straightforward: \nthe constructor itself disap\u00adpears at runtime, so the interpretation simply ignores it: [ConsF e]. = \n[e]. To de.ne the semantic counterpart of the primRecF operator, we .rst de.ne a higher-order continuous \nfunction primrec : (D . D . D) . (D . D) . D in the model. This is very similar to how one would de.ne \na generic primRecF in Haskell using general recursion, albeit here in an untyped fashion. primrec fmap \nf = Lam (.x (.gx. f (fmap (Lam (.x.Pair (x, g x)))) x)) The .rst argument to primrec is intended to \nspecify a functorial mapping function. For each of the syntactic types .; T f F : type de.ned in Figure \n1, we de.ne a suitable fmapF : D|T| . D . D, where |T| is the number of type variables in T. This de.nition \nis presented in Figure 5. With these de.nitions we can de.ne the interpretation of the syntactic primRecF \noperator. Note that the syntactic type construc\u00adtor F here always has exactly one free type variable, \nso fmapF has type D . D . D, as required by primrec. [primRecF f]. = primrec fmapF df if [f]. = Lam \ndf . otherwise This completes the interpretation of the terms of our program\u00adming language in our untyped \nmodel. We now turn to the semantic meaning of types, with the aim of showing, in Section 3.5, that each \nwell-typed term s interpretation is semantically well-typed. 3.2 Interpretation of clock variables For \na clock context ., we de.ne [.] to be the set of clock envi\u00adronments: mappings from the clock variables \nin . to the natural numbers. We use d, d ' etc. to range over clock environments. For d and d ' in [.], \nwe say that d . d ' (in [.]) if for all . . ., d(.) = d ' (.). The intended interpretation of some d \n. [.] is that d maps each clock . in . to a natural number stating how much time that clock has left \nto run. The ordering d d ' indicates that the clocks in d have at most as much time left as the clocks \nin d ' . We use the notation d[. . n] to denote the clock environment mapping . to n and . ' to d(. ' \n) when . = . ' .  3.3 Semantic types We interpret types as [.]-indexed families of partial equivalence \nrelations (PERs) over the semantic domain D. Recall that a PER on D is a binary relation on D that is \nsymmetric and transitive, but not necessarily re.exive. Since PERs are binary relations, we will treat \nthem as special subsets of the cartesian product D \u00d7 D. We write PER(D) for the set of all partial equivalence \nrelations on D, and TD for the PER D \u00d7 D. We require that our [.]-indexed families of PERs contravariantly \nrespect the partial ordering on elements of [.]. This ensures that, as the time left to run on clocks \nincreases, the semantic type becomes ever more precise. When we interpret clock quanti.cation as intersection \nover all approximations, we capture the common core of all the approximations. Formally, a semantic type \nfor a clock context . is a function A : [.] . PER(D), satisfying contravariant Kripke monotonicity: for \nall d ' d, Ad . Ad '. We write ClkPER(.) for the collection of all semantic types for the clock context \n.. In Section 4, we will formally consider morphisms between semantic types, and so turn each ClkPER(.) \ninto a category. Note that we do not require that any of our PERs are admissible. Admissible PERs always \ninclude the pair (., .), precisely the values we wish to exclude. We now de.ne semantic counterparts \nfor each of the syntactic type constructors we presented in Section 2.1. Unit, Product, Coproduct and \nFunction Types The construc\u00adtions for unit, product and coproduct types are straightforward. The unit \ntype will be interpreted by a constant family of PERs: 1d = {(Unit, Unit)} This trivially satis.es Kripke \nmonotonicity. Given semantic types A and B, their product is de.ned to be ' (Pair(x, y), Pair(x ,y ' \n)) (A \u00d7 B)d = ' ' | (x, x ) . [A]d . (y, y ) . [B]d and their coproduct is {(Inl(x), Inl(x ' )) | (x, \nx ' ) . [A]d}(A + B)d = . {(Inr(y), Inr(y ' )) | (y, y ' ) . [B]d} Since A and B are assumed to be semantic \ntypes, it immediately follows that A \u00d7 B and A + B are semantic types. To interpret function types, we \nuse the usual de.nition for Kripke-indexed logical relations, by quantifying over all smaller clock environments. \nGiven semantic types A and B, we de.ne: ' (Lam(f), Lam(f )) (A . B)d = ' '' | .d ' d, (x, x ) . Ad ' \n. (f x, f x ) . Bd ' It follows by the standard argument for Kripke logical relations that this family \nof PERs is contravariant in clock environments. Guarded Modality Given a semantic type A, we de.ne the \nse\u00admantic guard modality C. as follows, where . is a member of the clock context .: . TD if d(.) = 0 \n(CA)d = A(d[. . n]) if d(.) = n + 1 The semantic type operator C. acts differently depending on the time \nremaining on the clock . in the current clock environment d. When the clock has run to zero, C.A becomes \ncompletely uninfor\u00admative, equating all pairs of elements in the semantic domain D. If there is time \nremaining, then C.A equates a pair iff A would with one fewer steps remaining. For Kripke monotonicity, \nwe want to prove that (d, d ' ) . (C.A)d implies (d, d ' ) . (C.A)d ' when d ' .A)d ' ' d. If d ' (.) \n= 0 then (C= D \u00d7D 3 (d, d ' ). If d ' (.) = n + 1 then d(.) = n + 1 with n ' = n. So (d, d ' ) . A(d[. \n. n]), and so by A s Kripke monotonicity, (d, d ' ) . A(d ' [. . n ' ]) = (C.A)d ' . Clock Quanti.cation \nThe semantic counterpart of clock quanti.\u00adcation takes us from semantic types in ClkPER(., .) to semantic \ntypes in ClkPER(.). Given a semantic type A in ClkPER(., .), we de.ne ..A =A(d[. . n]) n.N For Kripke \nmonotonicity, if (d, d ' ) . (...A)d then .n. (d, d ' ) . A(d[. . n]). Since A is a semantic type, .n. \n(d, d ' ) . A(d ' [. . n]), hence (d, d ' ) . (...A)d ' . Complete Lattice Structure In order to de.ne \nthe semantic coun\u00adterpart of the least .xpoint type operator, we make use of the lat\u00adtice structure of \nClkPER(.). Given A, B . ClkPER(.), we de.ne a partial order: A . B if .d.Ad . Bd. It is easy to see that \nClkPER(.) is closed under arbitrary intersections, and so is a complete lattice. Each of the semantic \ntype constructors above is monotonic with respect to the partial order on ClkPER(.) (with the obvious \nproviso that A . B is only monotonic in its second argument). Least Fixpoint Types We make use of the \nKnaster-Tarski the\u00adorem [24] to produce the least .xpoint of a monotone function on ClkPER(.). See Loader \n[17] for an similar usage in a set\u00ad ting without guarded recursion. Given a monotone function F : ClkPER(.) \n. ClkPER(.), we de.ne: (\u00b5F ) ={A . ClkPER(.) | F A . A} For any monotone F , \u00b5F is immediately a semantic \ntype by con\u00adstruction, since semantic types are closed under intersection. As an initial step towards \nsemantic type soundness for our calculus, we demonstrate a semantic well-typedness result for the primrec \nfunction we de.ned in Section 3.1. Lemma 1. Let F : ClkPER(.) . ClkPER(.) be a monotone function. Let \nfmap : D . D . D be such that for all d . [.], for all A, B . ClkPER(.), and for all (g, g ' ) . (A . \nB)d and (x, x ' ) . F Ad, we have (fmap g x, fmap g ' x ' ) . F Bd. Then, for all d . [.] and for all \n(f, f ' ) . (F (\u00b5F \u00d7 C) . C)d, where C is a semantic type, we have (primrec fmap f, primrec fmap f ' \n) . (\u00b5F . C)d Proof. (Sketch) By induction on the least .xpoint F (\u00b5F ) = \u00b5F , using the Knaster-Tarski \ntheorem. This lemma only states that our semantic primrec recursion operator is semantically well-typed. \nWe will show in Theorem 2 that primrec also witnesses \u00b5F as the carrier of the initial F \u00adalgebra, as \nwe claimed in Section 1.4. 3.4 Interpretation of syntactic types A well-formed type .; T f A : type \nis interpreted as mono\u00adtonic function [A] : ClkPER(.)|T| . ClkPER(.), where |T|denotes the number of \ntype variables in T. The interpretation is de\u00ad.ned in the clauses in Figure 6. These clauses make use \nof the con\u00ad structions of semantic types de.ned in the previous subsection. In the clause for .., we \nmake use of the clock weakening operator -.. which takes a collection of semantic types in ClkPER(.)|T| \nto semantic types in ClkPER(., .)|T| by pointwise restriction of clock environments in [., .] to clock \nenvironments in [.]. = 1 [X . = .(X) A \u00d7 B . = A . \u00d7 B .[ A + B . = A . + [ B] . [A . B] . = [ A] \u00d8 \n. [B]. .A . = C. [1 . [C([A].) [...A . = ..([A](...)) [\u00b5X.F ] . = \u00b5(.X.[F ](., X)) Figure 6. Interpretation \nof well-formed types The next lemma states that syntactic substitution and semantic substitution commute. \nThe proof is a straightforward induction on the well-formed type A. Note the side condition that . . \nfc(A), matching the side condition on the .-APP typing rule. Lemma 2. Assume that .; T f A : type, ., \n. ' . . and . ' . fc(A). Then for all d . [.[. . . ' ]] and . . ClkPER(.)|T|, ' '' [A].(d[. . d(. )]) \n= [A[. . . ]](.[. . . ])d. The syntactic type equality judgement .; T f A = B : type that we de.ned in \nSection 2.2 is interpreted as equality of semantic types. The following lemma states that this interpretation \nis sound. Lemma 3. If .; T f A = B : type then for all . . ClkPER(.)|T| , [A]. = [B].. The next lemma \nstates that we may use the semantic fmapF functions de.ned in Figure 5 with the primrec operator, by \nshow\u00ading that fmapF always satis.es the hypotheses of Lemma 1. Lemma 4. For all .; T f F : type, the \nfmapF de.ned in Figure 5 are all semantically well-typed: For all d . [.], for --. -------------. all \nA, B . ClkPER(.), and for all (g, g ' ) . (A . B)d and - . . ' (x, x ' ) . F Ad, we have (fmapF -g x, \nfmapF g ' x ) . F Bd. It may seem that we could prove this lemma by using the syn\u00adtactic de.nition of \nfmap from Figure 3 and then applying Theorem 1. However, the semantic well-typedness of our interpretation \nof primRec depends on the semantic well-typedness of fmap, so we must prove this lemma directly in the \nmodel to break the circularity.  3.5 Semantic type soundness We now state our .rst main result: the \nsemantic type soundness property of our system. To state this result, we de.ne the semantic interpretation \nof contexts as a clock-environment indexed collec\u00adtion of PERs over environments: [G]d = {(., . ' ) | \n.(x : A) . G. (.(x), . ' (x)) . [A]d} Theorem 1. If .; G f e : A, then for all d . [.] and (., . ' ) \n. [G]d, ([e]., [e]. ' ) . [A]d. Proof. (Sketch) By induction on the derivation of .; G f e : A. The most \ninteresting cases are for .x and primRec. In essence, the case for .x goes through by induction on the \nvalue of the counter assigned to the clock variable . in the current clock environment. The case for \nprimRec is given by Lemma 1 and Lemma 4. Corollary 1. If -; - f e : A then for all ., [e]. = .. By this \ncorollary, the denotation of a closed program is never ., so well-typed programs always yield a proper \nvalue. When the result type A is the stream type ...\u00b5X.B \u00d7 C.X, we can deduce that the denotation of \ne will always be in.nite streams of elements of B. We further elaborate this point in the next section, \nshowing that this type is the carrier of the .nal (B \u00d7 -)-coalgebra. 4. Properties of .xpoint types \nUsing the denotational model of the previous section, we are now in a position to formally state and \nsketch the proofs of the properties of .xpoint types that we claimed in Section 1.4. Our claimed results \nare statements in category theoretic language about the initiality and .nality of various (co)algebras. \nTherefore, we .rst construct suitable categories to work in. De.nition 1. For each clock variable context \n., the category ClkPER(.) has as objects semantic types over .. Morphisms f : A . B are continuous functions \nf : D . D such that for all d . [.] and (a, a ' ) . Ad, (f a, fa ' ) . Bd. Two morphisms f,f ' are considered \nequivalent if for all d . [.] and (a, a ' ) . Ad, (fa, f ' a ' ) . Bd. Each well-typed term .; x : A \nf e : B de.nes a morphism [e] : [A] . [B] in ClkPER(.). We can de.ne equality between terms in our syntactic \ntype system in terms of the equality on mor\u00adphisms in this de.nition. Moreover, each well-formed type \nopera\u00adtor .; X f F [X] : type de.nes a (strong) realisable endofunctor on ClkPER(.) that is monotonic \non objects, using the semantic fmapF de.ned in Figure 5 to de.ne the action on morphisms. We have already \nchecked (Lemma 4) that this is well-de.ned, and it is straightforward to check that the usual functor \nlaws hold. In what follows, whenever we refer to an endofunctor on ClkPER(.), we mean a realisable functor \nthat is monotonic on objects, and we will use fmapF to refer to the action of a functor F on morphisms. \nInitial Algebras Recall that, for any functor F , an F -algebra is a pair of an object A and a morphism \nk : F A . A. A homomorphism h between (A, kA) and (B, kB ) is a morphism h : A . B such that h.kA = kB \n.fmapF h. An initial F -algebra is an F -algebra (A, kA) such that for any other F -algebra (B, kB ), \nthere is a unique homomorphism h : (A, kA) . (B, kB). Theorem 2. If F is an endofunctor on ClkPER(.), \nthen \u00b5F is the carrier of an initial F -algebra. Proof. (Sketch) Since \u00b5F is a .xpoint of F , the morphism \nF (\u00b5F ) . \u00b5F is simply realised by the identity map. Given any other F \u00adalgebra (B, kB), de.ne a morphism \n\u00b5F . B using the primrec operator from Lemma 1. Checking that this gives an F -algebra ho\u00admomorphism \nis straightforward, proving uniqueness uses induction on elements of \u00b5F , by the Knaster-Tarski theorem. \nGuarded Final Co-Algebras Theorem 2 applies to all functors F , and in particular functors of the form \nF (C.-) on the category ClkPER(., .). As well as \u00b5(F (C.-)) being the carrier of an initial algebra, \nit is also the carrier of a .nal F (C.-)-coalgebra. Coalgebras are the formal dual of algebras: for an \nendofunctor F , an F -coalgebra is a pair of an object A and a morphism kA : A . F A. A homomorphism \nh : (A, kA) . (B, kB ) of coalge\u00adbras is a morphism h : A . B such that fmapF h . kA = kB . h. A .nal \nF -coalgebra is an F -coalgebra (B, kB ) such that for any other F -coalgebra (A, kA), there is a unique \nF -coalgebra homo\u00admorphism unfold kA : (A, kA) . (B, kB). Theorem 3. If F is an endofunctor on ClkPER(.), \nthen \u00b5(F (C.-)) is the carrier of a .nal F (C.-)-coalgebra in ClkPER(., .). Proof. (Sketch) As for Theorem \n2, since \u00b5(F (C.-)) is a .xpoint of F (C.-), the morphism \u00b5(F (C.-)) . F (C.(\u00b5(F (C.-)))) is simply realised \nby the identity map. Given any other F -coalgebra (A, kA), de.ne a morphism unfold kA : A . \u00b5(F (C.-)) \nas .x (.g a. fmapF g (kA a)). It is straightforward to prove that this is an F -coalgebra homomorphism. \nUniqueness is proved for each possible clock environment d by induction on d(.). The syntactic counterpart \nof the construction we used in this proof is exactly the term we used in Section 1.4 for the de.nition \nof unfold. It is also easy to check that the term deCons we de.ned there is semantically equivalent to \nthe identity. Therefore, Theorem 3 substantiates the claim we made in Section 1.4 that \u00b5X.F [C.-] is \nthe syntactic description of the carrier of a .nal F [C.-]-coalgebra. Final Co-Algebras Theorem 3 gives \n.nal coalgebras in the cate\u00adgories ClkPER(., .), where we have a spare clock variable. By using clock \nquanti.cation, we can close over this clock variable, and get the .nal F -coalgebra, not just the .nal \nF (C.-)-coalgebra. Theorem 4. For an endofunctor F on ClkPER(.), ...\u00b5(F (C.-)) is the carrier of a .nal \nF -coalgebra in ClkPER(.). Proof. (Sketch) Almost identical to the proof for Theorem 3. This .nal theorem, \nalong with the examples we presented in Section 2.5, substantiates our claim that the combination of \nclocks and guards that we have presented in this paper is a viable and comfortable setting in which to \nproductively coprogram. 5. Conclusions and Further Work We have presented a semantics for a small total \ncalculus with primitive recursion for inductive data and a compositional treat\u00adment of corecursion, ensuring \ncausality via the applicative struc\u00adture of a local notion of time. In effect, we use time-based typing \nto grow a given total language, where all computation terminates within one day , into a larger total \nlanguage, where additional recursion is justi.ed clearly by the advancing clock. Functions from clocked \ninputs to clocked outputs enforce precise producer\u00adconsumer contracts today s output must be computed \nonly from today s input documenting their utility as components of pro\u00adductive processes. Quantifying \nclock variables localises the time stream to a particular construction whose clients can then use it \nin the moment . The method, made local, can be iterated, with inner clocks justifying the totality of \ncomputations within one day of an outer clock. At present, however, we have used local time only to justify \nproductive corecursion, with only primitive recursion for inductive types. It seems pressing to ask whether \nlocal time might similarly liberalise termination checking, with a local clock measuring time into the \npast and ensuring that recursive calls receive old enough inputs that their outputs are ready when we \nneed them. We are actively seeking a semantics for such a system, but it currently seems more dif.cult \nto pin down. In due course, we should like to grow this experimental calculus to a full blown dependent \ntype theory where (co)recursive construc\u00adtions are checked to be total within nested local time streams, \nthen exported to their clients without clocking. At least we have now es\u00adtablished what local time streams \nare and how to extract productive processes from them. Acknowledgements We would like to thank Lars Birkedal, \nRas\u00admus M\u00f8gelberg, and Paula Severi for extremely useful comments and discussions. References [1] A. \nAbel. Termination checking with types. ITA, 38(4):277 319, 2004. [2] A. W. Appel and D. A. McAllester. \nAn indexed model of recursive types for foundational proof-carrying code. ACM Trans. Program. Lang. Syst., \n23(5):657 683, 2001. [3] R. S. Bird. Using Circular Programs to Eliminate Multiple Traversals of Data. \nActa Informatica, 21:239 250, 1984. [4] L. Birkedal and R. E. M\u00f8gelberg. Intensional type theory with \nguarded recursive types qua .xed points on universes. In ACM/IEEE Sympo\u00adsium on Logic in Computer Science \n(LICS 2013), 2013. [5] L. Birkedal, J. Schwinghammer, and K. St\u00f8vring. A metric model of guarded recursion. \nIn Presented at FICS 2010, 2010. [6] L. Birkedal, R. E. M\u00f8gelberg, J. Schwinghammer, and K. St\u00f8vring. \nFirst steps in synthetic guarded domain theory: step-indexing in the topos of trees. Log. Meth. in Computer \nScience, 8(4), 2012. [7] V. Capretta. General recursion via coinductive types. Log. Meth. in Computer \nScience, 1(2), 2005. [8] N. A. Danielsson. Beating the productivity checker using embedded languages. \nIn Workshop on Partiality and Recursion in Interactive Theorem Provers (PAR 2010), volume 43 of EPTCS, \npages 29 48, 2010. [9] N. A. Danielsson and T. Altenkirch. Mixing induction and coinduc\u00adtion. Draft, \n2009. [10] D. Dreyer, A. Ahmed, and L. Birkedal. Logical step-indexed logical relations. Log. Meth. \nin Computer Science, 7(2), 2011. [11] N. Ghani, P. Hancock, and D. Pattinson. Representations of stream \nprocessors using nested .xed points. Log. Meth. in Computer Science, 5(3), 2009. [12] E. Gim \u00b4Codifying \nguarded de.nitions with recursive schemes. enez. In Types for Proofs and Programs, International Workshop \nTYPES 94, volume 996 of Lecture Notes in Computer Science, pages 39 59, 1994. [13] G. Hutton and M. \nJaskelioff. Representing contractive functions on streams. Submitted, 2011. [14] N. R. Krishnaswami and \nN. Benton. A semantic model for graphical user interfaces. In ACM SIGPLAN international conference on \nFunc\u00adtional Programming, ICFP 2011, pages 45 57, 2011. [15] N. R. Krishnaswami and N. Benton. Ultrametric \nsemantics of reactive programs. In IEEE Symposium on Logic in Computer Science, LICS 2011, pages 257 \n266, 2011. [16] J. Launchbury and S. L. Peyton Jones. Lazy functional state threads. In Proceedings of \nthe ACM SIGPLAN 94 Conference on Programming Language Design and Implementation (PLDI), pages 24 35, \n1994. [17] R. Loader. Equational Theories for Inductive Types. Annals of Pure and Applied Logic, 84(2):175 \n217, 1997. [18] C. McBride and R. Paterson. Applicative programming with effects. J. Funct. Prog., 18(1):1 \n13, 2008. [19] E. Moggi and A. Sabry. Monadic encapsulation of effects: a revised approach (extended \nversion). J. Funct. Prog., 11(6):591 627, 2001. [20] H. Nakano. A modality for recursion. In IEEE Symposium \non Logic in Computer Science (LICS 2000), pages 255 266, 2000. [21] A. M. Pitts. Computational adequacy \nvia mixed inductive de.ni\u00adtions. In Mathematical Foundations of Programming Semantics, Proc. 9th Int. \nConf., volume 802 of Lecture Notes in Computer Science, pages 72 82. Springer-Verlag, Berlin, 1994. [22] \nP. Severi and F.-J. de Vries. Pure type systems with corecursion on streams: from .nite to in.nitary \nnormalisation. In ACM SIGPLAN In\u00adternational Conference on Functional Programming, ICFP 12, 2012. [23] \nM. B. Smyth and G. D. Plotkin. The category-theoretic solution of recursive domain equations. SIAM J. \nComput., 11(4):761 783, 1982. [24] A. Tarski. A lattice-theoretical .xpoint theorem and its applications. \nPaci.c Journal of Mathematics, 5(2):285 309, 1955.   \n\t\t\t", "proc_id": "2500365", "abstract": "<p>Total functional programming offers the beguiling vision that, just by virtue of the compiler accepting a program, we are guaranteed that it will always terminate. In the case of programs that are not intended to terminate, e.g., servers, we are guaranteed that programs will always be <i>productive</i>. Productivity means that, even if a program generates an infinite amount of data, each piece will be generated in finite time. The theoretical underpinning for productive programming with infinite output is provided by the category theoretic notion of final coalgebras. Hence, we speak of <i>co</i>programming with non-well-founded <i>co</i>data, as a dual to programming with well-founded data like finite lists and trees.</p> <p>Systems that offer facilities for productive coprogramming, such as the proof assistants Coq and Agda, currently do so through syntactic guardedness checkers. Syntactic guardedness checkers ensure that all self-recursive calls are guarded by a use of a constructor. Such a check ensures productivity. Unfortunately, these syntactic checks are not compositional, and severely complicate coprogramming.</p> <p>Guarded recursion, originally due to Nakano, is tantalising as a basis for a flexible and compositional type-based approach to coprogramming. However, as we show, by itself, guarded recursion is not suitable for coprogramming due to the fact that there is no way to make finite observations on pieces of infinite data. In this paper, we introduce the concept of <i>clock variables</i> that index Nakano's guarded recursion. Clock variables allow us to \"close over\" the generation of infinite data, and to make finite observations, something that is not possible with guarded recursion alone.</p>", "authors": [{"name": "Robert Atkey", "author_profile_id": "81436601799", "affiliation": "Contemplate Ltd., Edinburgh, United Kingdom", "person_id": "P4261243", "email_address": "bob.atkey@gmail.com", "orcid_id": ""}, {"name": "Conor McBride", "author_profile_id": "81548019889", "affiliation": "University of Strathclyde, Glasgow, United Kingdom", "person_id": "P4261244", "email_address": "Conor.McBride@strath.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2500365.2500597", "year": "2013", "article_id": "2500597", "conference": "ICFP", "title": "Productive coprogramming with guarded recursion", "url": "http://dl.acm.org/citation.cfm?id=2500597"}