{"article_publication_date": "09-25-2013", "fulltext": "\n Typed Syntactic Meta-programming Dominique Devriese Frank Piessens iMinds DistriNet, KU Leuven .rstname.lastname@cs.kuleuven.be \nAbstract We present a novel set of meta-programming primitives for use in a dependently-typed functional \nlanguage. The types of our meta\u00adprograms provide strong and precise guarantees about their termi\u00adnation, \ncorrectness and completeness. Our system supports type\u00adsafe construction and analysis of terms, types \nand typing contexts. Unlike alternative approaches, they are written in the same style as normal programs \nand use the language s standard functional com\u00adputational model. We formalise the new meta-programming \nprim\u00aditives, implement them as an extension of Agda, and provide evi\u00addence of usefulness by means of \ntwo compelling applications in the .elds of datatype-generic programming and proof tactics. Categories \nand Subject Descriptors D3.3 [Programming Lan\u00adguages]: Language Constructs and Features: Data types and \nstruc\u00adtures; F3.1 [Logics and Meanings of Programs]: Specifying and Verifying and Reasoning about Programs: \nSpeci.cation Tech\u00adniques; F4.1 [Mathematical Logic]: Lambda Calculus and Related Systems Keywords meta-programming; \ndependent types; datatype-generic programming; tactics. 1. Introduction Meta-programming means writing \nprograms that write or manipu\u00adlate other programs. It is an important software engineering tech\u00adnique \nthat is widely used in practice. The term covers a wide variety of techniques and applications, including \nparser generators [29], re.ection and byte-code generation in Java-like languages [8, 40], macro s in \nLisp-like languages [53], eval primitives in languages like JavaScript [45], special-purpose meta-programming \nor generic programming primitives [6, 11, 13, 26, 33, 48, 52], tactics in proof assistants [20, 50, 51] \nand term representations in advanced type systems [9, 15, 23, 38]. Meta-programming jargon distinguishes \nbetween the meta-language, that meta-programs are written in, and the object language, that the programs \nbeing manipulated are in. Meta-programming can often be used to implement features in a library that \nwould otherwise require ad hoc compiler support. This ranges from meta-programs that generate small amounts \nof boiler\u00adplate code to give libraries a more native feel (e.g. [31, 34, 46]) to languages built from \nthe ground up using meta-programming [53]. Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with \ncredit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, \nrequires prior speci.c permission and/or a fee. Request permissions from permissions@acm.org. ICFP 13, \nSeptember 25 27, 2013, Boston, MA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2326-0/13/09. . . \n$15.00. http://dx.doi.org/10.1145/2500365.2500575 In many applications, meta-programs must not only be \nable to produce new code but also analyse existing terms, types or type contexts. Applications in e.g. \ndatatype-generic programming or tactics for proof assistants involve meta-programs that anal\u00adyse the \nsyntactic structure of object language data types [13, 33], types [26, 50], types and contexts [20]. \nSome systems allow analy\u00adsing terms [11], terms and types [48] or all three [9, 15, 38, 51]. Type-safety \nin the context of meta-programming can mean dif\u00adferent things. In some approaches, generated code is \ntype-checked upon completion of the meta-program, either at compile-time or run-time [8, 20, 48]. This \ncan be suf.cient to guarantee type\u00adcorrectness of the resulting program. In this text, we are interested \nin a stronger form of type-safety, in which a meta-program s type can guarantee type-correctness of all \nprograms it will ever gener\u00adate [11, 26, 33, 50 52]. This stronger form of type-safety provides meta-program \nauthors and users with greater correctness assurance. Sometimes, it also enables additional applications. \nFor example, MetaML runs meta-programs and compiles the generated code at run-time, but type errors during \nthis run-time compilation are ruled out by its strong type-safety [52]. In the context of a dependently\u00adtyped \nproof assistant, where proofs and programs are equated, Chli\u00adpala argues that the stronger form of type-safety \nhas a performance advantage because proofs generated by meta-programs do not need to be calculated as \nlong as they can be trusted to exist [14]. Note that for this last application, the meta-program must \nbe guaranteed to terminate, as well as produce well-typed code. However, this stronger form of type-safety \nputs a high demand on representations of object code and the meta-language type sys\u00adtem, especially for \nobject languages with strong (e.g. dependent) type systems and if meta-programs can construct and analyse \nboth terms, types and typing contexts. Most approaches use an explicit syntactic representation of object \nlanguage terms and/or types. To achieve strong type safety, they employ advanced type-system fea\u00adtures \nof the meta-language, including GADTs [11, 52], strong type systems with powerful type-level languages \n[13, 23, 50, 51] and an advanced feature of dependent type systems called induction\u00adrecursion [9, 15, \n38]. However, even the most powerful approaches have to make certain compromises, simplifying the resulting \nsys\u00adtem at the cost of expressivity. For example, many approaches pro\u00advide syntactic models of only types \n[33] or only terms [11, 52] or types and terms but not typing contexts [50]. Particularly technically \nambitious are those meta-programming systems that use a syntactic model of a dependently-typed language \nwithin another one [9, 15, 38]. Their term encoding represents type\u00adcorrectness internally, i.e. only \nwell-typed terms are represented. To support this, they require an advanced dependent type system with \nsupport for induction-recursion in the meta-language and even then have trouble .tting the interpretation \nfunction in it [9, 15]. McBride presents a model that is accepted by Agda but has to sig\u00adni.cantly limit \nthe dependent nature of the object language s type system in the process [38]. The objective in this \nwork is generally to prove meta-theory for the object language and the authors work hard to .t their \nencodings into the advanced, but general and previ\u00adously studied schema of inductive-recursive de.nitions. \n However, beside their meta-theoretical value, syntactic mod\u00adels of a typed object language with a well-typed \ninterpretation function are also promising for meta-programming applications. Unfortunately, the full \npotential of this has not been explored or demonstrated so far because researchers have not yet managed \nto build syntactic models of dependently-typed programming lan\u00adguages that support a big enough subset \nof a dependently-typed language and still have provably sound interpretation functions. In this paper, \nwe ignore the aim of building meta-theory for dependent type theories within themselves and instead focus \non applying such techniques to meta-programming. We will show that this approach has some very compelling \nqualities. We use Agda [39], a pure functional dependently-typed lan\u00adguage, as both the meta-and object \nlanguage and we start from a conventional representation of the object language based on de Bruijn-encoded \nlambda terms and an external typing judge\u00adment. We make an interpretation function available as a new \nmeta\u00adprogramming primitive. This puts us on shakier ground, because the soundness of the primitive is \nnot guaranteed by existing meta\u00adtheory, but it allows us to side-step the unsolved problem of syn\u00adtactically \nrepresenting a dependent type theory within itself with a provably sound interpretation function. As \nsuch, we gain the ability to explore and demonstrate our approach s potential for meta-programming and \npresent novel techniques for it. Our choice to keep the meta-and object language the same (known as homogeneous \nmeta-programming [48, 52]) contrasts with systems where meta-programs use a different computational model \nthan object programs. Often this is an imperative model [20, 48, 50, 51], but some systems even use a \nlogic programming-like model derived from the meta-programs interaction with type infer\u00adence [26, 33]. \nOur meta-programs use the same functional model as normal programs and dependent pattern matching [25] \nfor syn\u00adtactically analysing terms, types and typing contexts. This choice keeps the system smaller, \nmakes techniques, tools and knowledge for normal programming directly reusable in meta-programs and it \nallows meta-programs to use other meta-programs to do their work. It does not exclude imperative, generally \nrecursive, non\u00addeterministic or uni.cation-based reasoning in meta-programs. Re\u00adsearch has demonstrated \nfunctional models of such algorithms [16, 30, 32] and such ideas could be combined with our work. In \nthe dependently typed meta-language, meta-programs have strong and precise types that guarantee termination \nand correctness. Termination is standard for Agda functions (Agda is total). For strong type safety, \nour primitives require meta-programs to provide type-correctness proofs together with generated code \nand they can exploit type-correctness proofs for the code they analyse. Some homogeneous meta-programming \nsystems couple meta\u00adprogramming with multi-stage programming [6, 48, 52], which al\u00adlows object code programs \nto explicitly invoke meta-programs and use the generated expressions as if they were hand-written (unquot\u00ading) \nand allows meta-programs to include references to existing terms in generated code (quoting). A linear \nhierarchy of staging levels exists when meta-programs may unquote expressions gen\u00aderated by other meta-programs. \nThe bottom stage is the program executed at run-time, while other stages execute at compile-time or run-time, \ndepending on the system. Our interpretation function for encoded terms is analogous to an unquoting primitive \nand we will demonstrate how object-level terms can be referenced in generated code. The question of when \nmeta-programs are executed becomes a matter of choice and a special case of partial evaluation. We demonstrate \nthe properties of our system by applying it to two important application domains: datatype-generic programming \nand proof tactics. For the .rst, we de.ne a syntactic representation SimpleDT of inductive data types \nthat can be used to write general datatype-generic meta-programs. As proof-of-concept, we present a meta-program \nderiveShow that syntactically derives a serialisa\u00adtion function show : A . String for a data type A. \nderiveShow : (A : Set) . SimpleDT A . A . String SimpleDT and deriveShow do not require compiler support \nbe\u00adyond our (general) meta-programming primitives, although the value of type SimpleDT A could be provided \nby the compiler for additional convenience. The type of deriveShow guarantees its correct termination \nand well-typedness of generated programs (modulo the primitives soundness). To the best of our knowledge, \nthis is the .rst demonstration of strongly typed, general datatype\u00adgeneric meta-programs, with support \nfor syntactic analysis of terms and types and using the language s standard computational model. The \nsecond application domain is proof tactics. A tactic is a meta-program that analyses the type of a proof \nobligation and produces a proof term (possibly including remaining proof obli\u00adgations) using general \nor domain-speci.c reasoning. Several proof assistants provide special-purpose languages for writing custom \ntactics [20, 50, 51]. These are often imperative and only guar\u00adantee weak type-safety (generated code \nis checked after execu\u00adtion of meta-program) or partial strong type-safety (generated code is guaranteed \ntype-correct but meta-programs may not termi\u00adnate). Gonthier et al. argue that tactics without strong \ntype-safety can be hard to maintain and compose [26]. Chlipala discusses a performance advantage of precisely-typed \nand terminating meta\u00adprograms since generated proofs do not need to be calculated if they are known to \nexist [14]. To demonstrate that we can do better, we present an account of Coq s assumption tactic with \na very pre\u00adcise type, guaranteeing that it will always terminate and produce a guaranteed type-correct \nterm under a precise condition. The tac\u00adtic uses a functional computational model and dependent pattern \nmatching for syntactic analysis of terms, types and typing contexts. We have implemented our primitives \nin Agda and our exam\u00adple meta-programs are accepted by Agda s type-checker.1 Unfortu\u00adnately, this does \nnot mean our work is readily usable. The practi\u00adcality of our implementation is currently hampered by \nlong com\u00adpilation times. However, we will argue that this problem is not in\u00adtrinsic, but caused by the \ninef.cient evaluation strategy of Agda s compile-time evaluator. The soundness of our approach depends \non the soundness of our primitives, which we can currently not provide guarantees about. We believe that \nour work gives a strong motiva\u00adtion to investigate both of these aspects further, since we provide strong \nevidence for the additional power that the system offers for meta-programming in general and the hard \nproblems of well-typed tactics and datatype-generic programming in particular. 1.1 Contributions Our \n.rst contribution in this work is the de.nition of novel meta\u00adprogramming primitives in a dependently-typed \nlanguage, starting from a partial formalisation of the language s meta-theory. We also contribute the \n(to our knowledge .rst) demonstration of using such a formalisation for meta-programming, with compelling \nexamples in two important application domains: datatype-generic program\u00adming and proof tactics. Our meta-programming \nmodel works with the language s standard functional computational model, and meta\u00adprograms are written \nin the same way as normal programs. Mod\u00adulo the soundness of our primitives, meta-programs can be given \nstrong and precise guarantees of termination and correctness of the generated code. Finally, our proof-of-concept \napplications in these two application domains are interesting in their own right. For both 1 Code available \non http://people.cs.kuleuven.be/dominique. devriese/permanent/tsmp.zip.  data Constant : (arity : N) \n. Set where (empty for now) data Binder : Set where . . : Binder data Expr (n : N) : Set where set : \nExpr n var : Fin n . Expr n appl : Expr n . Expr n . Expr n constant : {arity : N} . Constant arity . \nVec (Expr n ) arity . Expr n bind : Binder . Expr n . Expr (suc n ) . Expr n pi pi : = {n : N} . Expr \nn . Expr (suc n ) . Expr n bind . lambda lambda : = {n : N} . Expr n . Expr (suc n ) . Expr n bind . \n Figure 1. The representation of terms. datatype-generic programming and proof tactics, the prospect \nof writing general meta-programs with strong and precise guarantees about termination, correctness and \ncompleteness and using the lan\u00adguage s standard computational model is compelling and novel.  1.2 Outlook \nWe present the representation of our object language in Section 2. In Section 3, we show how the represented \nterms and types are brought to life in the meta-language using our meta-programming primitives. In Section \n4, we present applications to the .elds of datatype-generic programming and proof tactics. We discuss \nissues like soundness and performance in Section 5, related work in Sec\u00adtion 6 and we conclude in Section \n7. 2. Self-representation As discussed, we start from a representation of Agda terms in Agda using a \nnotion of lambda expressions representing terms as well as their types and a typing judgement linking \nthe two together. Terms Figure 1 shows the de.nition of Expr, our representation of Agda terms and types \nas lambda terms, using de Bruijn indices. We represent de Bruijn indices as integers between 0 and n \n- 1 using the Agda standard library type Fin n [17]. The type Expr is parameterised by the number of \nfree variables in scope. It is de\u00ad.ned as a standard inductive data type [21], with an enumeration of \nits constructors and their types. The set constructor represents the type of types in the object language \nand free variables are em\u00adbedded through var. There is a standard function application con\u00adstructor appl \nand constants applied to a .xed number of arguments (as determined by the constant s arity) through term \nconstructor constant . Vec A n is another Agda standard library type repre\u00adsenting a vector of precisely \nn values of type A. In what follows, we use [ ] for the empty vector and for example [x, y ] for the \nvector with elements x and y. Similarly, we write literal Fins as numbers. The .nal Expr constructor \nin Figure 1, bind, is a common rep\u00adresentation of two separate binding constructs: lambda expressions \n.(x : T ) . b2 and dependent function types (x : T ) . T', constructed as bind . and bind . respectively. \nThey take two arguments: the type T of the bound variable and the body of the construct (b or T ' respectively) \nwith the bound variable addition\u00adally in scope in the body. Note by the way that a standard non\u00addependent \nfunction type s . t can be represented as dependent 2 We use Agda notation for lambdas, not the more \nstandard .x : T .b. Sub : N. N. Set / : {m n : N} . Expr m . Sub m n . Expr n weaken : {n : N} . Expr \nn . Expr (suc n ) [ ] : {n : N} . Expr (suc n ) . Expr n . Expr n Figure 2. Substitutions (implementations \nomitted). data .0 {n} : Expr n . Expr n . Set where reduceApplication : . {s} b val . appl (lambda s \nb) val .0 b [val ] data . {n} : Expr n . Expr n . Set where \u00b7 \u00b7 \u00b7 (congruence closure of .0 ) .* : {n \n: N} . Expr n . Expr n . Set .* = \u00b7 \u00b7 \u00b7 (transitive-re.exive closure of . ) : {n : N} . Expr n . Expr \nn . Set x y = . (. n . x .* n \u00d7 y .* n) Figure 3. Full \u00df-reduction and \u00df-equivalence for untyped terms. \nfunction ( : s) . t. Finally, note in the type of constant , pi and lambda that we bind some arguments \nusing curly brackets, indi\u00adcating that they can be omitted in calls. Agda will then infer their value \nfrom the types of the remaining arguments. Substitutions We use a library of substitutions that is part \nof the Agda standard library [17], based on a technique by McBride [37]. Figure 2 shows a type of substitutions \nSub m n that will substitute terms with n free variables for all m free variables of other terms. More \nconcretely, the function / applies a substitution f of type Sub m n to a term t typed Expr m to obtain \nterm t / f, typed Expr n. Note that for example / is Agda notation for a mix.x operator that is applied \nto two arguments t and f in the form t /f [18]. The function weaken uses the substitutions infrastructure \nto increase free de Bruijn indices by one and [ ] substitutes term v for de Bruijn variable 0 in term \nt, to obtain term t [v ], shifting other free de Bruijn indices downward in the process. Convertibility \nThe next thing we de.ne is an untyped notion of strong \u00df-reduction and \u00df-equivalence of terms in Figure \n3. It is technically convenient to de.ne primitive reductions in judge\u00adment .0 , a congruence closure \nof it in . and a transitive\u00adre.exive closure of that in .* . The reduceApplication rule uses the substitution \nfunction [ ] we saw before. In the type of reduceApplication we use Agda s . shorthand notation, which \ndesugars to a normal dependent type. For example . {n} . \u00b7 \u00b7 \u00b7 or . n . \u00b7 \u00b7 \u00b7 is short for {n : } . \u00b7 \n\u00b7 \u00b7 and (n : ) . \u00b7 \u00b7 \u00b7 respec\u00adtively, i.e. an implicit or normal argument n whose type is inferred by \nAgda. One . symbol can apply to more than one argument. In , we use the . and \u00d7 types: for a type A \nand predicate P typed A . Set, .P represents a dependent sum type containing tuples (v, pv) with v of \ntype A and pv of type P v . For types A and B, A\u00d7B represents the cartesian product type of A and B (containing \n' (a, b) with a of type A and b of type B). Two terms t and t are de.ned to be convertible (t t') iff \nthere exists a third term n that both t and t' reduce to. Typing Contexts Figure 4 contains the de.nition \nof typing con\u00adtexts and the more general notion of telescopes. A telescope is a sequence of expressions, \neach representing the type of a bound variable. The entries may refer to a number of free variables, \nas\u00adsumed to be bound outside the telescope. The .rst index i of the Telescope type indicates how many \nsuch initial variables are as\u00ad  data Telescope (i : N) : N. Set where e : Telescope i i < : {n : N} \n. Expr n . Telescope i n . Telescope i (suc n) Context : (n : N) . Set Context = Telescope 0 lookup : \n. {n} . Fin n . Context n . Expr n lookup zero (t < ) = weaken t lookup (suc n) ( < G ) = weaken (lookup \nn G ) Figure 4. Telescopes and Contexts data f : {n} (G : Context n) : Expr n . Expr n . Set where typeSet \n: G f set : set typeVar : . {i} . G f var i : lookup i G typePi : . {s t} . G f s : set . (s < G) f t \n: set . G f pi s t : set typeLam : . {s b t} . G f s : set . (s < G) f b : t . G f lambda s b : pi s \nt typeAppl : . {s f t val} . (s < G) f t : set . G f f : pi s t . G f val : s . G f appl f val : appl \n(lambda s t) val typeConv : . {e t t ' } . t t ' . G f e : t ' . G f t : set . G f e : t Figure 5. \nTyping Judgements. sumed. Telescopes are dependent: subsequent types can mention variables bound earlier \nin the telescope. This allows us to represent e.g. the telescope (n : N) (t : Expr n), where the type \nof t depends on the value of n. As a consequence of this dependence, each ad\u00additional entry in a telescope \nhas an additional variable in scope. The second index n of the Telescope type is the number of .nal variables: \nif i variables are initially bound, and we add the bind\u00adings of a Telescope i n, then in total n variables \nwill be bound, so the telescope contains precisely n - i entries. A typing context Context n is a telescope \nwith zero initial and n .nal bound vari\u00adables. The lookup function looks up the type of a variable in \na con\u00adtext. lookup s dependent type ensures that only de Bruijn variables lower than the length of the \ncontext can be looked up. Typing Judgements In Figure 5, we show the typing judgement G f v : t stating \nthat term v has type t in typing context G . The typing judgement models a fairly standard dependent \ntype system, except for the .rst rule typeSet. This rule expresses that set has type set in any context, \na rule which is known as type-in-type and a known source of paradox in dependent type theories [28]. \nHowever, we use this rule only for ease of presentation. Our full code avoids type-in-type using a predicative \nhierarchy of universes similar to Agda s [39]. It uses a level-indexed setl, the typing rule that setl \n: setsuc l for all l, and a level-indexed typing judgement G fl v : t with l such that G fsuc l t : set \nl must hold. In the remaining typing rules in Figure 5 we have typeVar, stating that the type of a variable \nis given by the corresponding entry in the typing context and typePi, stating that (x : S) . T is a type \nif S and T are types, with x : S added to the context for T . For lambda expressions, typeLam says that \n. (x : S) . b is typed (x : S) . T if b has type T in a context extended with data f : . {n} . Context \nn . Set where tyE : f e ty< : . {n e} {G : Context n} . f G . G f e : set . f(e < G ) data f : {n} (G \n: Context n) : {m : N} (. : Sub m n) (tel : Context m) . Set where \u00b7 \u00b7 \u00b7 (omitted) Figure 6. Well-typed \nContexts weaken -inj - : . {n} {x y : Expr n} . weaken x weaken y . x y -trans : . {n} {x y z : Expr \nn} . x y . y z . x z -/ : . {n} {x y} {m} (. : Sub Expr n m) . x y . x / . y / . weakenJudgementTop \n: . {n} {G : Context n} {v t t ' } . G f v : t ' . t < G f weaken v : weaken t ' substJudgementTop : \n. {n} {G : Context n} {t ' e t v} . t ' < G f e : t . G f v : t ' . G f e [v ] : t [v ] substContext \n: . {n} {G : Context n} {e t} {t ' t '' } . '' ' ' t ' t . G f t : set . t < G f e : t . '' < G f e \n: t t f-/ : . {m n} {e t} G1 G2 . (f : Sub m n) . G2 f f : G1 . G1 f e : t . G2 f e / f : t / f f-var \n: . {n} . {G : Context n} . fG . (i : Fin n) . G f lookup i G : set typesAreSets : . {n} {G : Context \nn} {e t} {l} . f G . G f e : t . G f t : set substJudgementType : . {n} {G : Context n} {e t t ' } . \nt = t ' . G f e : t . G f e : t ' Figure 7. Meta-theoretic properties of our typing judgements. x :S. \nAccording to typeAppl, a function application f val has type ((. (x :S).T) val) if f has type (x :S).T \nand val has type S. Note that we could equivalently have given such an application the type T [val ]. \nFinally, the rule typeConv states that a type t can be substituted for a convertible type t ' in any \ntyping judgement. In the full version of our code, we extend the calculus with built\u00adin dependent sum \ntypes (like the . type we have already seen), iden\u00adtity types x =y :A (which contain proofs that x and \ny of type A are de.nitionally equal) and the empty type . (which does not contain any value). These are \nmodelled by adding suitable constructors for the types, their constructors and eliminators to the Constant \ndata type, together with appropriate typing and reduction rules. More typing judgements In addition to \nthe typing judgement for terms above, we also de.ne typing judgements for contexts and for substitutions. \nFigure 6 shows the judgement f G expressing that context G is well-typed, i.e. that all context entries \nare sets. Its rule tyE states that the empty context is always well-typed and ty< says that subsequent \nentries should be types in their preceding context. We omit the de.nition of judgement G f f : tel3 , \nwhich expresses that the terms substituted by substitution f satisfy the type requirements of telescope \ntel in context G . 3 For ease of presentation, we overload the notation f : in this text.  Meta-theory \nand helper functions We have proved quite some meta-theory about the reduction, convertibility and typing \njudge\u00adments. For full detail we refer to the full version of our code, but to give you an idea of what \nis there, Figure 7 shows the types of the most important results. weaken - inj - shows that weak\u00adening \nis injective with respect to convertibility. -trans shows that convertibility is transitive. -trans \nis a consequence of the Church-Rosser-property for our reduction rules, which we have proved using a \ntechnique for untyped lambda calculi by Tait, de\u00adscribed by Martin-L\u00a8 of [36]. Theorem -/ states that \nconvertibility is invariant under substitutions. Theorems weakenJudgementTop, substJudgementTop, substContext \nand f-/ state roughly that typings are preserved under weakening, instantiating a variable in the context, \nreplacing a type in the context by a convertible one and applying a substitution to term and type. f-var \nis a simple proof that entries in a well-typed context must be sets. By theo\u00adrem typesAreSets, the type \nof a judgement in a well-typed context must in fact be a type. Finally, substJudgementType is not a the\u00adorem \nbut a simple helper function that replaces a judgement s type by a provably equal type (it is a special \ncase of subst, the standard eliminator of Agda s singleton type t = t '). Some example terms Let us consider \nthe encoding of a simple example term: the following polymorphic identity function: id : . (A : Set) \n. A . A id = . (A : Set) . . (v : A) . v The type and de.nition of this function are given by closed \nexpres\u00adsions idTyTm and idTm. idTm : Expr 0 idTm = lambda set (lambda (var 0) (var 0)) idTyTm : Expr \n0 idTyTm = pi set (fun (var 0) (var 0)) We can prove that the term idTm satis.es type idTyTm using the \ntyping rules from Figure 5. : e f idTm : idTyTm tyidTm = typeLam typeSet (typeLam typeVar typeVar) tyidTm \nBy the typesAreSets theorem, it follows that idTyTm is a type. : e f idTyTm : set = typesAreSets tyE \ntyidTm tyidTyTm tyidTyTm 3. Bringing Terms to Life With this infrastructure in place, we can de.ne our \nmeta-pro\u00adgramming primitive interp together with auxiliary primitives interpCtx and interpSet. Their \ntypes are: interpCtx : {n : N} {G : Context n} . fG . Set interpSet : {n : N} {G : Context n} {A : Expr \nn} . G f A : set . (tyG : fG ) . interpCtx tyG . Set interp : {n : N} {G : Context n} {v t : Expr n} \n. (tyv : G f v : t) . (tyG : fG ) . (asmpts : interpCtx tyG) . interpSet (typesAreSets tyG tyv ) tyG \nasmpts interpCtx turns the types in a well-typed context into a dependent sum type of the context entries \ninterpretations. It is used by the two other judgements to require values for all of a context s as\u00adsumptions. \ninterpSet interprets an encoded type, yielding a Set, and interp interprets a term v typed t. In the \nresult type of interp for a proof tyv of judgement G f v : t, we use the previously men\u00adtioned theorem \ntypesAreSets to calculate typesAreSets tyG tyv , a proof that G f t : set. The result of interp is then \nof type t, interpreted using interpSet and this derived judgement. Interpreting examples Before we go \ninto more details, consider again the previously encoded polymorphic identity function. Re\u00admember that \nthe closed terms idTm and idTyTm encode the func\u00adtion and its type and the proofs tyidTm and tyidTyTm \nwitness the typing judgements e f idTm : idTyTm and e f idTyTm : set. Both proofs assume only an empty \ncontext, which is always well typed according to the rule tyE in Figure 6. We will discuss the re\u00adduction \nbehaviour of our primitives further, but interpCtx tyE (the assumptions in the empty context) reduces \nto unit type T (with canonical inhabitant tt). With all of this, we can interpret the en\u00adcoded type idTyTm \nto obtain the type intrpidTyTm : = interpSet tyidTyTm tyE tt intrpidTyTm More details follow, but intrpidTyTm \nreduces to (x :Set) (x1 :x). x, alpha-equal to the intended type (A : Set) . A . A. Similarly, we can \ninterpret term idTm and its typing proof tyidTm to obtain intrpidTm of type intrpidTyTm . intrpidTm = \ninterp tyidTm tyE tt As we intended, intrpidTm reduces to . (x : Set) . (x1 : x) . x1 , alpha-convertible \nto our intended . (A : Set) . . (x : A) . x. Interfacing with the real world In real examples, generated \ncode needs to interface with existing types and values. In staging meta\u00adprogramming systems, this is \nsupported with a built-in quoting primitive, but we use an alternative approach. Suppose for example \nthat we want a meta-program to construct the term suc 2 from the pre-existing value 2 and function suc. \nTo do this, the meta\u00adprogram clearly needs to refer to the type N, the function suc and the value 2 in \nthe generated object code, but our term encoding does not provide a way to refer to such outside de.nitions. \nOne solution would be to build natural numbers into our calculus as primitives, but this is not a scalable \napproach, since we cannot expect to do this for all types we will ever need, let alone a user s custom \ntypes. A better solution lets the meta-program construct the object term in a suitable context, postulating \nvalues of the correct types. Real values can then be provided in the interpretation of this con\u00adtext. \nFor our example, we need the context Gex : Gex = (pi (var 1) (var 2)) < (var 0) < set < e This de.nition \nshould be read right-to-left: < is right-associative and the left-most context entries are added last \nand may refer to the values of entries to their right. It starts with the empty context e and lists the \ntypes for which we want to postulate values. In order, these are a type (of type set), a value of this \ntype (of type var 0) and a function from this type to itself (of type pi (var 1) (var 2)). The context \nis intended to be instantiated to values N, 2 and suc respec\u00adtively. Note that the de Bruijn variables \nvar 0, var 1 and var 2 in the context all refer to the value of the rightmost context entry of type set; \nsubsequent context entries have an additional variable in scope and the body of a pi as well. Proof tyGex \nof judgement fGex shows that context Gex is well-typed, i.e. all entries are in fact sets: = ty (ty (ty \ntyE typeSet) typeVar) tyGex < < < (typePi typeVar typeVar) We will .ll in the appropriate values for \nthis context s assumptions with the value asmptsGex of type interpCtx tyGex : asmptsGex = ((tt, N), 1), \nsuc In context Gex , we can now construct the value suc 2 as a term ex. It is an Expr 3, since it may \nrefer to Gex s three assumptions, and applies the postulated suc function to the postulated value 2. \nex = appl (var 0) (var 1)  We construct a proof tyex of judgement Gex fex : var 2, i.e. that the constructed \nterm ex has the .rst postulated value (N) as its type, in three steps. First typing rules typeAppl and \ntypeVar give us proof tyex ' , showing that ex has a more complicated type. We then prove this type convertible \nto var 2 in (partly omitted) proof convex . tyex then uses typing rule typeConv to replace the convertible \ntype. tyex ' : Gex f ex : appl (lambda (var 2) (var 3)) (var 1) tyex ' = typeAppl typeVar typeVar typeVar \nconvex : appl (lambda (var 2) (var 3)) (var 1) var 2 convex = \u00b7 \u00b7 \u00b7 (reduceApplication (var 3) (var \n1)) tyex : Gex f ex : var 2 ty = typeConv convex ty ' typeVar ex ex We can then interpret object program \nex to obtain a value of type interpSet (typesAreSets tyGex ty asmptsGex : ex ) tyGex exInt = interp ty \nasmptsGex ex tyGex The reduction behaviour of our primitives that we will talk about next ensures that \nexInt s type and exInt itself reduce to N and suc 2 respectively, precisely as we intended. Sometimes, \na meta-program does not just need to refer to an external function f in generated code, but also depends \non infor\u00admation about such a function s reduction behaviour to prove well\u00adtypedness of the generated \ncode. Without going into much detail, the ideas of this section can support this if we add singleton \ntypes to the object calculus. Concretely, a context could postulate the exter\u00adnal function f together \nwith proofs of its reduction behaviour. Such proofs could then be used in the typing of generated programs \nand the invocation of the interpretation primitive would require actual proofs of the reduction behaviour \nin the context interpretation. Reduction behaviour The reduction behaviour of our primitives is an important \npart of their de.nition and crucial for the function\u00ading of the previous examples. We present the reduction \nrules in Fig\u00adure 8. In general, these rules interpret encoded types, terms and con\u00adtexts, but only when \nthe well-typedness of the result can be guar\u00adanteed. To achieve the latter, we need to ascertain that \nthe provided well-typedness proofs are valid and do not rely on assumptions that might not hold. This \nis non-trivial because a language like Agda ap\u00adplies strong reductions during type-checking, i.e. reductions \ncan be applied to open terms as well as closed. Non-closed proofs are not necessarily valid, since they \nmay rely on invalid assumptions. We will provide more insight further on and discuss our solution based \non the value patterns in Figure 8. These are the patterns written in typewriter font in the left-hand \nsides of some reduction rules. Such a value pattern indicates that the rule must only be applied if the \ncorresponding argument is a value. The types of these ar\u00adguments are conversion or typing judgements \nand their values are .nite trees of constructor applications (see Figures 3 and 5). As such, the property \nof value-ness can easily be checked in the prim\u00aditives implementation. But before we discuss the role \nof the value patterns further, let us take a better look at the reduction rules. Recall the type of our \nmost important primitive interp. interp : {n : N} {G : Context n} {v t : Expr n} . (tyv : G f v : t) \n. (tyG : fG ) . (asmpts : interpCtx tyG) . interpSet (typesAreSets tyG tyv ) tyG asmpts The primitive \ntakes a context G , a term v and a type t as hidden arguments, followed by proofs tyv , tyG of typing \njudgements G f v : t and fG and a value asmpts of the context s interpretation type interpCtx tyG. The \nreduction rules in Figure 8 specify that for certain forms of the judgement tyv , the primitive application \nreduces to appropriate right-hand sides. For tyv = typeSet, which implies4 v = set and t = set, the .rst \nrule returns interpretation Set. For tyv = typeVar, an interpretation of the ith context assumption is \ngiven by primitive interpVar, discussed below. The rules for ty = typePi ty ty and typeLam ty tyb vst \ns interpret terms pi s t and lambda s b as respectively the corre\u00adsponding Agda . -type and lambda term, \nrecursively constructed from interpretations of s and t resp. b. The bound variable x is made available \nfor the interpretation of t resp. b by placing it in the interpretation of the extended context s < G \n. For an application of a function to a value, we apply the interpretation of the function to the interpretation \nof the value. Note the value patterns on the left-hand side that we will come back to further on. Finally, \nthe interpretation of a typeConv is simply the interpretation of the judgement whose type it substitutes, \non the condition that the arguments are values. Recall also the type of primitive interpCtx: interpCtx \n: {n : N} {G : Context n} . fG . Set The primitive takes a context G as a hidden argument and a well\u00adtypedness \nproof for it and returns its interpretation, i.e. a type that contains all the context s assumptions. \nWe saw in interp s reduction rules for typeLam and typePi, how an extended context s < G is interpreted \nby a tuple of the s value and the interpretation of G . This corresponds to interpCtx s reduction behaviour, \nthat we look at now. The .rst reduction rule interprets an empty context by the unit type T. More interestingly, \na context G extended with a type t is interpreted by an interpretation asmpts of G , and an interpretation \nof the type t. We use a dependent sum . to specify the interpretation of t with respect to the interpretation \nasmpts of the rest of the context. Now that we know how to interpret a context, we can de.ne re\u00adduction \nrules for interpVar, to project out a context s ith entry. Its reduction rules are not surprising, projecting \nout the top assumption for variable zero and recursing for suc i. The primitive interpSet is a version \nof interp that works on types only. Its role is to break the circularity in the types of the primitives. \nIt is implemented in terms of helper primitives interpSet ' and interpVarSet. We do not discuss their \nreduction behaviour as it is similar to interp and interpVar except that we require proof that the judgement \ns type is convertible to set and that this proof is a value in some cases. Soundness in the presence \nof open terms To understand the value patterns in .ve of the reduction rules in Figure 8, we have to \nexplain the powerful form of type-level computation that a depen\u00addently typed language like Agda uses. \nIt uses a strong form of re\u00adductions: reductions can be applied even inside the body of lambda or pi \nterms. The term . x .0+x, for example, is considered equal to . x . x, because 0 + x is reduced to x \ndespite the open variable x. However, such strong reductions can be dangerous because, in the presence \nof open variables, we may be reasoning under absurd assumptions. Consider the following function: absurdTerm \n= . (prf : Int = Bool) . cast prf 3 . false The function absurdTerm takes a proof prf that Int = Bool, \nmodelling an equality proof of types Int and Bool. This proof type is of course empty, but the type-checker \nis not aware of that. With prf and an appropriate cast function, we can use a value 3 as a Bool. However, \nthis is not problematic, because a correct de.nition of the cast function will never reduce cast prf \n3 to 3. Instead, it will block on the open variable prf until a value (i.e. re.) is somehow substituted \nfor it. This mechanism effectively protects values like 3 from being used at wrong types like Bool. For \nour primitives, similar issues arise. We can for example assume a proof tyAbsurd of judgement e f set \n: pi set set even 4 Note: pattern matches that imply equalities about other arguments are standard for \ndependent pattern matching [25].  interp typeSet tyG asmpts = Set interp (typeVar {i = i}) tyG asmpts \n= interpVar i tyG asmpts interp (typePi ty ty ) tyG asmpts = (x : interpSet ty tyG asmpts) . interpSet \nty (ty tyG ty ) (asmpts, x) st st < s interp (typeLam ty tyb) tyG asmpts = . (x : interpSet ty tyG asmpts) \n. interp (ty tyG ty ) tyb (asmpts, x) s s < s interp (typeAppl tytyty) tyG asmpts = interp tyG tyf asmpts \n(interp tyG tyval asmpts) t f val interp (typeConv t~t ' tyty) tyG asmpts = interp tyG ty asmpts e t \ne interpCtx tyE = T interpCtx (ty tyG ty ) = . . (asmpts : interpCtx tyG) . interpSet ty tyG asmpts < \nt t interpVar : . {n} {G : Context n} i . (tyG : fG ) . (asmpts : interpCtx tyG) . interpSet (f-var tyG \ni) tyG asmpts interpVar zero (ty< tyG tyt ) ( , asmpt) = asmpt interpVar (suc i) (ty< tyG tyt ) (asmpts, \n) = interpVar tyG i asmpts interpSet tyt tyG asmpts = interpSet ' tyt -re. tyG asmpts interpSet ' : . \n{n} {G : Context n} {A t} . G f A : t . t set . (tyG : fG ) . interpCtx tyG . Set interpSet ' typeSet \neq tyG asmpts = Set interpSet ' (typeVar {i = i}) eq tyG asmpts = interpVarSet i eq tyG asmpts interpSet \n' (typePi tys tyt ) eq tyG asmpts = (x : interpSet ty tyG asmpts) . interpSet ty (ty tyG ty ) (asmpts, \nx) s t < s interpSet ' (typeAppl tyty) eq tyG asmpts = interp tyf tyG asmpts (interp tyval tyG asmpts) \nt f tyval ''' '' ' interpSet (typeConv t~t tyA tyt ) eq tyG asmpts = interpSet tyA ( -trans ( -sym t~t \n) eq) tyG asmpt interpVarSet : . {n} {G : Context n} {l} i . lookup i G set . (tyG : fG) . interpCtx \ntyG . Set interpVarSet zero eq (ty< tyG tyt ) ( , asmpt) = asmpt interpVarSet (suc i) eq (ty< tyG tyt \n) (asmpts, ) = interpVarSet i (weaken -inj - (lookup i G ) set eq) tyG asmpts Figure 8. Reduction behaviour \nof our primitives. Patterns in typewriter font are required to be values. though this type of proofs \nis empty. Clearly, interp tySet tyE tt should then not reduce to Set at type Set . Set, but instead block \non the open variable tySet. Similarly, if we assume a proof prf of judgement pi set set set, and use \nit with typeConv to construct a proof tyAbsurd ' of judgement e f set : pi set set, then our primitives \nshould block on open variable prf . By the value patterns in Figure 8, some rules require that certain \narguments are values. We have checked for each rule that the right\u00adhand side s type was equal to the \ndeclared type, assuming just the information from the left-hand side patterns, similar to how dependent \npattern matching can be type-checked [25]. For the .ve rules with value patterns, this was not the case. \nIn for example the rule for interp (typeConv t~t ' tye tyt ) tyG asmpts, the right\u00adhand-side is of type \ninterpSet (typesAreSets tyG tye ) tyG asmpts i.e. the interpretation of t ' , not t and the convertibility \nassumption t ~ t ' is essential for returning a value of type t ' as one of type t. We believe that the \nvalue patterns in Figure 8 solve this problem, making our reduction rules valid for open terms, even \nthough the general question of soundness remains open. The primitives properties In addition to the reduction \nbehaviour of our primitives, some of our meta-programs require additional properties about them listed \nin Figure 9. Property castInterp- ' states that for convertible types A and A ' , the interpretations \nunder interpSet must be the same. The next two properties are related to the interpretation of a type \nafter a well-typed substitution G2 ff: G1 between well-typed contexts G1 and G2 . interpCompSubCtx says \nthat an interpretation of G1 can be constructed from one of G1 and interpCompSubSet ' says that the interpretation \nof a type t in G2 is the same as that of t / f in G1 using the interpretation of G1 constructed by interpCompSubCtx. \nWe are currently using stub proofs of these properties, based on an Agda primitive called primTrustMe. \nprimTrustMe is an unsafe primitive that proves equalities a = b for any set A and val\u00adues a, b of type \nA. However, during type-checking, primTrustMe only reduces to re. when a and b are de.nitionally equal. \nIt is future work to ascertain that these properties follow from the re\u00adduction rules of Figure 8 and \nthe proofs of theorems like f-/. 4. Applications Our approach allows de.nitions of powerful meta-programs, \nma\u00adnipulating both code and types, in a functional style and with very precise types. In this section, \nwe demonstrate this for two important applications: datatype-generic programming and tactics. 4.1 Datatype-Generic \nProgramming The .eld of datatype-generic programming studies the de.nition of algorithms that work for \na wide variety of data types. An ex\u00adample is Haskell s deriving Show mechanism [35, \u00a74.3.3, \u00a711], which \nallows a data type A to be annotated with the directive deriving Show to make the compiler derive an \ninstance of the Show type class. Such an instance consists essentially of a func\u00adtion show ::A.String, \nderived syntactically by the compiler from the data type s constructors and their types. The goal of \ndatatype\u00adgeneric programming is to allow functions like show to be de.ned in a generic way, i.e. such \nthat they can be de.ned once but used with a wide variety of data types. Representing data types To apply \nour techniques to the .eld of datatype-generic programming, we start from a syntactic represen\u00adtation \nof an inductive data type: record SimpleDT (A : Set) : Set where constructor simpleDT .eld constructors \n: List (Constructor A) folder : folderType A constructors  castInterp- ' : . {n} {G : Context n} {A \nA ' } . (tyA : G f A : set) . (tyA ' : G f A ' : set) . A A ' . (tyG : fG ) . (asmpts : interpCtx tyG) \n. interpSet tyA tyG asmpts = interpSet tyA ' tyG asmpts interpCompSubCtx : . {m n} {G1 G2 } {f : Sub \nExpr m n} . G2 f f : G1 . (tyG1 : fG1 ) . (tyG2 : fG2 ) . interpCtx tyG2 . interpCtx tyG1 interpCompSubSet \n' : . {m n t} {G1 G2 } {f : Sub Expr m n} . (comp : G2 f f : G1 ) . (tyG1 : fG1 ) . (tyt : G1 f t : set) \n. (tyG2 : fG2 ) . (asmpts2 : interpCtx tyG2 ) . interpSet (f-/comp tyt ) tyG2 asmpts2 = interpSet tyt \ntyG1 (interpCompSubCtx comp tyG1 tyG2 asmpts2 ) Figure 9. Primitive properties According to this de.nition, \na data type A is syntactically described by a list of its constructors and a folder or induction principle \n(List is a standard type of .nite lists). To keep things simple, we omit well-formedness requirements \n(like positivity of the de.nition) and proofs about the reduction behaviour of the folder function, which \nare required to completely describe a data type, but not needed for our example application. Constructor \nis the syntactic representa\u00adtion of a single constructor: data Constructor (A : Set) : Set where mkConstructor \n: String . (n : N) . (tel : Telescope 1 (n + 1)) . (tytel : Gset f tel) . let ctorT = funCtx n tel (var \n0) : Gset f ctorT : set tyctorT = typeFunCtx n tytel typeVar tyctorT in interpSet tyGset (tt, A) . Constructor \nA tyctorT We describe a constructor by its name as a String, its arity n and a telescope tel containing \nthe types of its arguments. The telescope has one initial variable in scope: the data type A itself, \nso that it can be referenced in the types of constructor arguments. The telescope tel must be well-typed \nin the context Gset = set < e, i.e. with the premise that A is a set. From tel, we can calculate the \nfull type ctorT of the constructor as the function that takes the arguments given by tel and produces \na value of type A (using omitted helper function funCtx). We prove that ctorT is a set (using omitted \nlemma typeFunCtx), interpret it and require a value of it, i.e. the actual constructor. Note how our \nmeta-programming primitives provide the crucial link between the syntactically represented types and \nthe normal type of the actual constructor. In addition to the list of Constructors, SimpleDT contains \nan eliminator or folder for the data type. Every inductive data type comes with such an induction principle, \nwhich models a general way of perform structural induction over the data type. The function folderType \nsyntactically derives the type of this induction princi\u00adple from the types of the constructors and their \ninterpretations. folderType : (A : Set) . List (Constructor A) . Set folderType A constructors = (P : \nA . Set) . underFolderAsmpts A P constructors ((x : A) . P x) Given a set A and a list of A s constructors, \nfolderType returns the type for a corresponding induction principle: it takes a predicate P : A . Set \n(the motive [25], describing what the induction prin\u00adciple should produce) and returns a function of \ntype (x : A) . P x under a number of assumptions. For every constructor, the function underFolderAsmpts \nsyntactically derives the type of an assump\u00adtion from the constructor s type. This is fairly involved, \nbut presents no fundamental dif.culties and we omit it for space reasons. Let us immediately show some \ndata types and their represen\u00adtations. The simplest example is the empty type, which has zero constructors. \nIts de.nition and induction principle look as follows: data . :Set where foldBot : (P : . . Set) . (t \n: .) . P t foldBot P () Note the use of an absurd pattern () in the de.nition of foldBot. This pattern \ncommunicates to Agda that no value can ever be given for the argument of type ., so that a right-hand-side \nis not needed. It is easy to provide a value of SimpleDT for .: botDT : SimpleDT . botDT = simpleDT [ \n] foldBot botDT speci.es that . has no constructors and foldBot is its in\u00adduction principle. Agda successfully \ntype-checks foldBot against the folder type calculated for the empty list of constructors. For a more \ncomplex example, consider the standard de.nition of natural numbers and its induction principle: data \nN: Set where zero : N suc : N. N foldN: (P : N. Set) . P zero . (. n . P n . P (suc n)) . (n : N) . P \nn foldN P Pz Ps zero = Pz foldN P Pz Ps (suc n) = Ps n (foldN P Pz Ps n) The constructors zero and suc \nof data type N are described by zeroConstr and sucConstr of type Constructor N: zeroConstr = mkConstructor \n\"zero\" 0 e tyE zero sucConstr = mkConstructor \"suc\" 1 (var 0 < e) (ty tyE typeVar) suc < The constructor \nzero is of arity 0, with the empty telescope describ\u00ading its arguments. The actual constructor zero is \nthen provided and Agda checks its type against the one calculated from the syntactic description. Constructor \nsuc is of arity 1, taking one value of type N as its argument (recall that var 0 in the constructor telescope \nrefers to the data type itself). The constructor telescope is well-typed un\u00adder Gset s assumption that \nvar 0 is a set. Again, the actual con\u00adstructor is given and checked against the type calculated from \nthe description. We can now describe Nwith natDT : SimpleDT N. natDT = simpleDT [zeroConstr, sucConstr \n] foldN natDT lists N s constructors and provides induction principle foldN, checked against the type \ncalculated from the constructors. Derive Show The type SimpleDT is a general syntactic descrip\u00adtion of \ninductive data types that permits a general form of datatype\u00adgeneric meta-program. As a proof-of-concept, \nwe show the func\u00adtion deriveShow that derives a show function for a data type A. deriveShow : . {A} . \nSimpleDT A . A . String deriveShow (simpleDT constructors folder) = omitted We omit the algorithm s implementation, \nwhich takes the descrip\u00adtion of data type A and exploits the induction principle with mo\u00adtive P = . . \nString. It syntactically derives arguments for the folder, specifying how values constructed using the \ndifferent constructors are to be serialised. The hardest part of the code is to convince the type-checker \nthat the folder arguments we con\u00adstruct for the concrete motive . . String correspond to their expected \ntypes for a general predicate P when P is instantiated to . . String through the context interpretation. \nThis essentially uses the interpCompSubCtx and interpCompSubSet primitive properties shown in Figure \n9.  For our example data types, deriveShow derives an (admittedly not very useful) show function for \n.: showBot : . .String showBot = deriveShow botDT showBot s de.nition reduces to foldBot (. . String), \nthe code that deriveShow syntactically generates. From natDT , we can derive the function showNat of \ntype N. String. showNat = deriveShow natDT Like for showBot, showNat s de.nition reduces to the generated \nfunction showNat ' = foldN (. . String) \"zero\" (...) (.nal argument omitted). We can apply it to numbers \nwith for example showNat 2 producing the string \"(suc (suc zero))\". Discussion This account of datatype-generic \nprogramming is rudimentary, lacking support for indices and parameters and non\u00adrecursive and more general \nrecursive constructor arguments [21]. It does not exclude non-strictly-positive data types and does not \ncontain proofs about the induction principle s reduction behaviour (required to construct proofs about \ninductive functions). However, we do not see fundamental obstacles for adding any of this. From a methodological \npoint of view, our account of datatype\u00adgeneric programming is compelling: meta-programs are written in \nthe language itself, using the language s standard functional computational model. The syntactic description \nof a data type in SimpleDT is general and could be automatically generated by the compiler. Modulo correctness \nof our primitives, the meta-programs come with strong guarantees about termination, well-typedness of \nthe generated programs and completeness. SimpleDT and deriveShow are implemented in \u00b11200 lines of code \nand can be studied in the full version of our code (see the footnote on page 2). This is still much more \nthan what we would like, and in Section 5 we discuss how this could be improved.  4.2 Tactics Tactics \nare a form of meta-programs that solve or re.ne proof obli\u00adgations in proof assistants. In proof assistants \nbased on dependent type theory, solving a proof obligation is equivalent to producing a program of a \nspeci.ed type in a speci.ed context. Several proof assistants provide support for writing tactics, often \nin the form of a special-purpose sub-language. Such tactics are generally untyped and provide little \nupfront guarantees about their correct operation. Even though the correctness of the generated proofs \ncan be checked after generation, Gonthier et al. argue that untyped tactics can be hard to maintain and \ncompose and giving them more precise types is a good approach to solve this issue [26]. There are also \nperfor\u00admance advantages to tactics that can be guaranteed to terminate correctly without running them, \nas argued by Chlipala [14]. Our meta-programming primitives show promise for this .eld, and they lend \nthemselves to a typed form of tactics written in a standard functional style. The input for a tactic \nis just a syntactic representation of the proof obligation, i.e. a certain type in a certain context. \nBy additionally requiring a typing judgement for the type and interpretations for the context s values, \nwe can use interpSet to specify the expected result type of the tactic. Consider the following analogue \nof Coq s assumption tactic, a simple tactic that solves proof obligations which appear literally in the \ncontext. Our account of it enjoys a very precise type: assumptionTactic : . {n T } {G : Context n} . \n(tyt : G f T : set) . (tyG : fG ) . (asmpts : interpCtx tyG) . ifYes (inContext? G T) (interpSet tyt \ntyG asmpts) The tactic takes a type T, a well-typed context G and values for its assumptions. The return \ntype will be explained further, but it speci.es exactly what the tactic will return in all cases: either \na value of type T if T is present in the context or a value of the unit type otherwise. Let us explain \nthis in more detail. We use the Agda standard library s Dec P type. It models a decision of proposition \nP, i.e. either a proof of P or a proof of \u00acP: data Dec (P : Set) : Set where yes : P . Dec P no : \u00ac P \n. Dec P Based on a decision of some property, the ifYes function returns either an argument type or unit \ntype T: ifYes : {P : Set} . Dec P . Set . Set ifYes (yes ) P ' = P ' ifYes (no ) = T The inContext? algorithm \ndecides whether or not a certain type t is present in context G , i.e. if the ith entry in the context \nis equal to t for some i. It uses a general purpose decision procedure any?, which simply tries all i \nof the bounded type Fin n. For a given variable i, we use a general equality decision procedure for terms \n? = to check whether the ith context entry is equal to t. InContext : {n : N} (G : Context n) (t : Expr \nn) . Set InContext G t = .. i . lookup i G = t inContext? : {n : N} (G : Context n) (t : Expr n) . Dec \n(InContext G t) ? inContext? G t = any? (. i . lookup i G = t) In our assumptionTactic, we use a with \npattern match to make a case distinction based on the decision from inContext?. If the type t is not \nfound, we can simply return T value tt. If it is found at position i, we essentially want to return the \nith entry in the context but we need to convince Agda that it has the desired type. assumptionTactic \ntyG tyt asmpts with inContext? G t assumptionTactic {n} {t} {G } tyG ty asmpts t | yes (i, eqGid ) = \nlet tyvari : G f var i : t = substJudgementType eqGid typeVar tyvari in castInterp (typesAreSets tyG \ntyvari ) tyt tyG asmpts (interp tyvari tyG asmpts) assumptionTactic tyG ty asmpts | no = tt t The .rst \nstep is to use the proof eqGid that lookup i G = t from inContext? and the typeVar typing rule to produce \na proof tyvari of judgement G f var i : t. We can then obtain the interpretation of the ith variable \nthrough the value interp tyvari tyG asmpts. Unfortunately, that value s type is interpSet (typesAreSets \ntyG tyvari ) tyG asmpts What we need is a value of type interpSet tyt tyG asmpts, i.e. an interpretation \nof the same type t, but for a different proof that t is a set. castInterp, an omitted special case of \nproperty castInterp- from Figure 9, is precisely what we need to cast one to the other. Tactic usage \nCurrently, our tactics can be manually invoked with a context and goal type and well-formedness proofs. \nThe tactic in\u00advocation appears as an expression in the code where the goal is needed. In future systems, \ncompiler support can increase conve\u00adnience by automatically providing the goal type, context and their \ntyping proofs. This could e.g. extend Agda s experimental and un\u00adderdocumented quoteGoal construct. This \nconstruct allows the invocation of a re.ective solver with the compiler providing a syn\u00adtactic representation \nof the goal type. It does not however provide a syntactic representation of the context or a guarantee \nabout well\u00adformedness of the provided type. Also, a more developed tactic API could support returning \nunsolved sub-goals and tactic combinators like Coq s ; .  5. Discussion There are some more aspects \nof our approach that we believe de\u00adserve further discussion: the representation of the object language, \nthe performance of our meta-programs, the overhead for writing meta-programs in our system and the soundness \nof our primitives. Types and Guarantees Considering our example meta-programs deriveShow and assumptionTactic, \nan important feature of our meta-programming approach is the strong guarantees that the meta\u00adprograms \ntypes provide, modulo the soundness of our primitives. First, meta-programs are strongly type-safe: any \nobject code they generate must be well-typed, since they are required to provide a proof of well-typedness \nto the interpretation primitive. Second, our meta-language Agda checks termination and completeness of \npat\u00adtern matches for all function de.nitions to guarantee that all func\u00adtions are total. This guarantee \nalso applies to our meta-programs, so that additionally we automatically get a totality guarantee for \nour meta-programs. However, this does not completely exclude the use of general recursion in tactics, \ntechniques like Danielsson s partial\u00adity monad [16] can be used to model such algorithms. The representation \nMeta-programming implies the syntactic analysis and construction of source code and/or types, and we \nhave chosen a fairly well-understood representation to support this: a lambda calculus with de Bruijn \nindices and a standard separate en\u00adcoding of typing judgements. However, many different encodings are \nequally possible, like those based on more advanced representa\u00adtions of binders [12]. It is future work \nto investigate the advantages that these alternatives might offer for our purposes. We also want to investigate \nmerging interpSet and interp, but we cannot cur\u00adrently try this for technical reasons. Finally, we currently \nrepresent typing judgements externally, i.e. as a property that can be true or not for an untyped lambda \nterm. This corresponds to standard presentations of type theory, but it may be interesting to explore \nthe bene.ts of an internal encoding like Danielsson, Chapman or McBride s [9, 15, 38] in our setting. \nPerformance We do not currently consider our implementation practical, because of performance reasons. \nFor example, type\u00adchecking just the deriveShow example for the type of natural numbers currently takes \nabout 2 minutes and 3GB of memory on our system. Such performance likely prohibits all practical applications. \nHowever, we do not think this bad performance is inherent to our approach, but rather a consequence of \nthe in\u00adef.cient call-by-name execution strategy that Agda uses during type-checking. Remember how we \npreviously de.ned showNat using our deriveShow function. As we mentioned, showNat is de.nitionally equal \nto the generated program showNat ' = foldN (. . String) \"zero\" (...). Nevertheless, applying showNat \nto the numbers 0 and 1 under Agda s evaluator (which is also used during type-checking) takes 2.5 resp. \n11 minutes while for showNat ' , it is instantaneous for numbers up to at least 100. For larger numbers, \nshowNat quickly runs out of memory. This behaviour is a consequence of Agda s call-by-name eval\u00aduation \nstrategy, which repeats the normalisation of showNat for every reduction of foldN. If Agda were to use \na more ef.cient strategy like call-by-need, then the normalisation of showNat to showNat ' would occur \nonly once. Very likely, there is a lot more work being duplicated inside the normalisation of showNat \nand we believe the call-by-name evaluation strategy is responsible for the long execution and type-checking \ntimes there as well. Overhead Writing meta-programs in our approach entails a cer\u00adtain amount of programming \noverhead. The full code of our datatype-generic meta-programming application deriveShow is \u00b11200 lines \nof code (including the SimpleDT encoding and some reusable parts). This is a lot more than what it would \ntake to write a corresponding untyped meta-program. A signi.cant part is the cor\u00adrectness proof of the \nmeta-program (i.e. the proof that it generates correct code for all inputs). However, a big part of our \nderiveShow implementation con\u00adsists of a rather tedious proof speci.c to our meta-programming primitives. \nIt concerns the correspondence of a type in a context with a general predicate P of type A . String, \nwith the value . . String provided through the interpretation of this context and the same type with \nan encoding of . . String already .lled in. We expect quite some work can be saved in this proof, but \nlong compilation times have prevented further investigation. On the bright side, our assumption tactic \nis only about 50 lines in to\u00adtal, for a big part because it reuses general functions like the deci\u00adsion \nprocedure for syntactic term equality. It is likely that additional reusable functions can reduce the \nmeta-programming effort further. For example, a veri.ed type-inference algorithm can be combined with \nour primitives to obviate the need for manual typing proofs in many cases. Finally, we also expect that \nmore experience with the de.nition of interpretation primitives could provide further opportunities to \nreduce meta-programming effort. For example, it would likely sim\u00adplify some things to merge interp and \ninterpSet, but we currently cannot do so for technical reasons. Additionally, the irrelevant ar\u00adguments \n[1] that Agda support offer the potential to make Agda un\u00adderstand that the type correctness proofs that \nour primitives require are only required to exist but do not in.uence their result value. We expect this \ncould make a big difference for shortening tedious proofs like the one in our de.nition of deriveShow. \nSoundness The soundness of our primitives remains an open question, at least if we consider the full \nversion that does not have the unsound G f set : set rule that we discussed in Section 2. However, we \ndo think there is a relation to the .eld of founda\u00adtional logic that we will try to informally explain \nhere. What we are essentially doing is reasoning about Agda terms within Agda itself. In foundational \nmathematical logic, G\u00a8odel s second incom\u00adpleteness theorem has something to say about a similar situation \nfor .rst-order logic [24]. An informal statement of the theorem (found on Wikipedia [54]) reads Theorem \n1 (G\u00a8odel s Second Incompleteness Theorem). For any formal effectively generated theory T including basic \narithmetical truths and also certain truths about formal provability, if T includes a statement of its \nown consistency then T is inconsistent. A standard proof of this theorem constructs a proposition T in \nthe object theory such that T asserts the unprovability of its own G\u00a8odel-encoding. In vague terms, it \ncan be proven that such a term exists as soon as the object language is powerful enough to reason about \nnatural numbers. Such a term leads to a contradiction in combination with the self-consistency proof \nof the theory. It is fair to assume the theorem can be generalised to type theory, and applied to our \nobject theory, perhaps after adding singleton types, an empty type and a type of natural numbers. Consistency \nof a dependent type theory is equivalent with the existence of a closed term of type .. Using our primitives, \nit is not hard to construct a function of type . {t}.eft : constant bot [ ].., which means that our meta-level \nprimitives imply the consistency of our object theory. This begs the question whether Agda extended with \nour primitive must therefore necessarily be inconsistent, by the second incompleteness theorem, since \nit implies its own consistency. We conjecture that this implication is not there, for the reason that \nour object calculus does not contain the primitive itself, making it a fundamentally weaker theory. What \nwe do is reminiscent of extending a .rst-order logical theory T with an axiom asserting T s consistency, \nto obtain a new theory T ' . Such an extended theory T ' does not in fact prove its own consistency, \njust that of T , so that the second incompleteness theorem does not apply. Another question that G \u00a8 \n odel s result suggests is whether primitives like ours could in principle be implemented as normal \nfunctions within the bounds of a meta-language. Even with suf.cient additional features like induction-recursion \n[22], this might not be possible as it would prove the language s own consistency within itself. For \nthese reasons, we expect that our primitives are not imple\u00admentable in pure Agda but do not compromise \nconsistency. Be\u00adcause of G \u00a8 odel incompleteness, we think there are only two op\u00adtions to gain more con.dence \nin them: either prove consistency of the extended calculus in a strictly stronger logical system such \nas Zermelo-Fraenkel set theory or implement our primitives in pure Agda, relying on axioms that are easier \nto trust than our primitives. A non-computational axiom asserting strong normalisation of the calculus \n(as used by Barras [4]) is a good candidate, but it isn t practical in our current implementation because \nAgda lacks a Prop universe like Coq s. We think these logical aspects of our work deserve further at\u00adtention. \nNevertheless, even if our primitives were to be proven un\u00adsound, we do not think our work would be useless. \nOur application of interpretation primitives to meta-programming remains relevant as long as the primitives \ncan be restricted to regain soundness. Also, in some applications of a dependently-typed language for \nprogram\u00adming (rather than proof checking), full certainty about soundness can be less important than \npowerful meta-programming support. Staging As discussed in the introduction, our meta-programming primitives \ndo not use the concept of staging like some other solu\u00adtions [6, 11, 48, 52]. Nevertheless, our interp \nprimitive performs the same function as an unquote primitive in such systems, allowing object programs \nto invoke a meta-program and use generated code as if it were normal code. The quote primitive in a staging \nmeta\u00adprogramming system allows to include references to object-level terms in generated code, something \nwhich we support in a different way, as discussed in Section 3. Finally, while in these systems, code \nat all staging levels runs at either compile-time or run-time, but not both. In our system, the question \nof when to execute meta-programs is an orthogonal matter, not different from the partial evaluation of \nnormal functions. Conveniently, partial evaluation is relatively cheap in total dependently-typed languages \nand for example well supported in the language Idris [7]. We see the orthogonality of our meta-programming \nprimitives w.r.t. staging considerations as an advantage. If desired, it is tech\u00adnically possible to \nrequire at compile-time that all invocations of the primitives be unfoldable (producing errors if arguments \nare not statically known). However, like for partial evaluation, exe\u00adcuting a meta-program upfront is \nnot always a good idea, espe\u00adcially if we are already sure that the generated code will be well\u00adtyped \n(see e.g. Chlipala s arguments about the performance advan\u00adtages of re.ective meta-programs [14]). It \nseems that annotations for partial evaluation like in Idris would combine well with our primitives to \nconveniently let the programmer control when meta\u00adprograms are executed. For example, a version of deriveShow \nwith the SimpleDT A argument annotated as [static ] would generate show functions at compile time instead \nof run-time. 6. Related Work In the literature, we .nd different forms of programming language support \nfor meta-programming. We discuss them according to the guarantees that are provided about object programs. \nMany approaches represent code in an untyped way, i.e. without guarantees that the represented source \ncode is well-typed. These techniques have no way of providing strong type-safety of meta\u00adprograms, i.e. \na guarantee that all the code a meta-program will ever produce is well-typed. In this category, we include \napproaches that represent code textually, like parser generators [29, 41], C macro s, eval primitives \nlike JavaScript s [45], Java s pluggable annotation processors [19] (at least on the output side). Some \napproaches gen\u00aderate untyped bytecode [8]. Also in this category are macro ap\u00adproaches which receive \nand produce an untyped data structure rep\u00adresentation of programs and types, like Template Haskell [48], \nLtac proof tactics in Coq [20] and macro systems in Lisp-related lan\u00adguages (e.g. Racket [53]). Some \nprovide speci.c language features for working with such representations. These systems provide the power \nof meta-programming at a comparatively low cost, but they make it hard to provide upfront guarantees \nof (strong) type-safety. Not all meta-programming approaches are based on an explicit syntactic representation \nof terms or types. Some exploit type sys\u00adtem features like Haskell type classes [33], Coq canonical struc\u00adtures \n[26] or C++ templates [2] to analyse types and produce code as part of the type inference process. These \nfeatures provide (in\u00adtentionally or not) a form of type-level computation with at least a notion of type \nanalysis and structural recursion. Gonthier et al. even exploit canonical structures (non-trivially) \nto obtain a form of syntactic pattern matching and non-determinism with backtrack\u00ading [26]. Meta-programming \nsystems based on such primitives only support analysing types (but dependent types in Coq may contain \nterms). The computational model of these primitives is quite dif\u00adferent from the underlying language \ns (uni.cation-based vs. func\u00adtional), so that meta-programming requires special expertise and techniques. \nFor canonical structures, the computational model is not so well understood [27] and the resulting meta-programs \nare tightly coupled to the precise behaviour of the inferencer. An ad\u00advantage of using primitives exposed \nby the type inferencer is that strong type-safety can be guaranteed comparatively easily [26, 33]. The \ntype class instance search always terminates (with common extensions), but not so for C++ templates and \nCoq canonical struc\u00adtures. Completeness of pattern matching is not statically checked in any system. \nMore or less in this category, we also have Chli\u00adpala s language Ur, which provides value-level folder \nfunctions for record types to support a practical form of meta-programming [13] with a form of syntactic \nanalysis of record types, no explicit rep\u00adresentation of object code and a functional computational model. \nSyntactic analysis of terms or general types is not supported. Other approaches to meta-programming with \nstrong type safety are based on explicit typed representations of code. This requires a powerful meta-language \ntype system, as determined by the com\u00adplexity of the object language and whether terms, types and typing \ncontexts can all be syntactically constructed and analysed or only some of those. We discuss the related \nwork according to the type system feature used in this representation. Rudolph and Thiemann represent \ntyped JVM bytecode gen\u00aderators in the Scala Mnemonics library [47], exploiting various features of Scala \ns type system. Taha and Sheard [52], Chen and Xi [11], Pa.sali\u00b4c and Linger [42] and Sheard and Pa.sali\u00b4c \n[49] s sys\u00adtems are based on GADTs or explicit type equality proofs. Terms of a non-dependently-typed \nobject language are syntactically rep\u00adresented as values of a data type indexed with the meta-level type \nof the term they represent. Without analysis of types, these techniques appear unsuitable for applications \nlike proof tactics.  In VeriML, Stampoulis and Shao [50, 51] use a contextual type system, inspired \nby Beluga [43] and Delphin [44], in the meta\u00adlanguage to model a dependently-typed object language. They \npro\u00advide a syntactic model of terms and types, with a certain level of support for parameterising over \nand pattern matching on typing contexts. Nevertheless, contexts do not seem .rst class in VeriML s type \nsystem. For example, tactics cannot have contexts as their re\u00adturn type, so meta-programs cannot construct \nthem, only start from the ones they receive and extend them locally. Stampoulis and Shao use an imperative \nmeta-language with general recursion because certain tactics use algorithms that are inherently imperative. \nWe agree that such tactics exist, but we do not see why they cannot be modelled in a pure and/or total \nfunctional setting like ours, us\u00ading models like those found in the literature [16, 30, 32]. VeriML tactics \nare partial: they can fail or loop forever. This has modu\u00adlarity disadvantages: if a tactic t1 invokes \nanother tactic t2, then t1 s author cannot be sure that t2 will actually succeed when it is invoked at \nt1 s run-time. Stampoulis and Shao partially solve this with a letstatic staging construct that forces \ntactic t2 to be evaluated at t1 s compile time instead. This works under cer\u00adtain restrictions on t2 \ns arguments. Because our tactics types imply termination guarantees by default, we do not need such a \nsystem, while potential non-termination can still be modelled, e.g. using the non-termination monad [16]. \nStampoulis and Shao link a proof as\u00adsistant s type checker with custom tactics to obtain the effect of \na sound user-extensible conversion rule in the logic [51], allowing a term t of type A to be used at \ntype A ' if the equality decision pro\u00adcedure (potentially a custom tactic) can .nd a proof that A = A \n' . This form of automatic triggering of tactics for solving constraints is interesting and could perhaps \nbe combined with our work as well. In a dependently-typed meta-language, it is possible to model non-dependent \nobject languages with standard inductively-de.ned universes using the technique of re.ection [5, 14]. \nAltenkirch and McBride [3] and Chapman et al. [10] provide syntactic models of data types, together with \ninterpretation functions. Chapman et al. s universe even describes itself as a data type. These authors \ndo not consider syntactic models of terms or types that are not data types. Brady and Hammond [6] provide \na universe that models a non\u00addependent object language. Terms, types as well as contexts are modelled \nand can be syntactically constructed and analysed. This universe-based approach can be extended to dependently\u00adtyped \nobject languages using the advanced type-theoretic con\u00adcept of inductive-recursive de.nitions [22]. This \nhas been studied by Danielsson [15], Chapman [9] and McBride [38]. These au\u00adthors provide typed syntactic \nmodels of dependently-typed calculi in dependently-typed calculi, with different objectives than ours. \nWhere we focus on the applicability of such a model in meta\u00adprogramming primitives, they aim to prove \nproperties of the mod\u00adelled language in the meta-language. They use models based on advanced type-theory \nfeatures like induction-recursion and mutual induction. All three authors use a model of the object calculus \nwith terms indexed by encodings of their types, instead of an external typing judgement like ours. The \nmodels that they use are specif\u00adically tailored to enable proofs of deep properties like normalisa\u00adtion, \nand it is unclear if their models also .t our more practical objectives. Finally, these approaches generally \ntry to stay within the limits of the features of an existing dependently typed lan\u00adguage (albeit one \nwith powerful features like inductive-recursive de.nitions). They try hard to .t their models and interpretation \nfunctions (more or less equivalent to the normalisation proof of the object language) in a known inductive-recursive \nschema, not fully successfully [9, 15]. McBride s encoding is accepted by Agda but he has to signi.cantly \nlimit the dependent nature of his object language [38]. As discussed in the introduction, our use of \ninter\u00adpretation primitives allows us to side-step the interesting but hard problems that these authors \ntackle, leaving us free to study the application of related techniques to concrete meta-programming applications. \nIt also allows us to use a more conventional encoding of the object language based on external typing \njudgements. 7. Conclusion Our primitives present a novel meta-programming model with sev\u00aderal desirable \ncharacteristics. Our meta-programs use the same functional style and well-understood computational model \nas nor\u00admal programs. They can be given precise types that guarantee ter\u00admination and strong type-safety. \nFinally, they can construct and analyse terms, types and typing contexts in a type-safe way. Our proof-of-concept \napplications in the two important application do\u00admains of datatype-generic programming and tactics, demonstrate \nthe generality of our approach. Still, we feel this work is only a .rst exploration of a new approach \nto meta-programming. Quite some interesting questions remain to be answered in future work. Acknowledgments \nThis research is partially funded by the Research Foundation -Flan\u00adders (FWO), and by the Research Fund \nKU Leuven. Dominique Devriese holds a Ph.D. fellowship of the Research Foundation -Flanders (FWO). References \n[1] A. Abel. Irrelevance in type theory with a heterogeneous equality judgement. In Foundations of Software \nScience and Computational Structures, volume 6604 of Lecture Notes in Computer Science, pages 57 71. \nSpringer, 2011. [2] D. Abrahams and A. Gurtovoy. C++ template metaprogramming: Concepts, tools, and techniques \nfrom Boost and beyond. Addison-Wesley, 2004. [3] T. Altenkirch and C. McBride. Generic programming within \ndepen\u00addently typed programming. In IFIP TC2 Working Conference on Generic Programming, Schloss Dagstuhl, \npages 1 20. Kluwer, 2003. [4] B. Barras and G. Huet. Auto-validation d un syst `eme de preuves avec familles \ninductives. PhD thesis, Universit \u00b4 e de Paris 07, 1999. [5] S. Boutin. Using re.ection to build ef.cient \nand certi.ed decision procedures. In Theoretical Aspects of Computer Software, volume 1281 of Lecture \nNotes in Computer Science, pages 515 529. Springer, 1997. [6] E. Brady and K. Hammond. A veri.ed staged \ninterpreter is a veri.ed compiler. In Generative Programming and Component Engineering, pages 111 120. \nACM, 2006. [7] E. C. Brady and K. Hammond. Scrapping your inef.cient engine: using partial evaluation \nto improve domain-speci.c language imple\u00admentation. In International Conference on Functional Programming, \npages 297 308. ACM, 2010. [8] E. Bruneton, R. Lenglet, and T. Coupaye. ASM: a code manipula\u00adtion tool \nto implement adaptable systems. Adaptable and extensible component systems, 2002. [9] J. Chapman. Type \ntheory should eat itself. In International Workshop on Logical Frameworks and Metalanguages: Theory and \nPractice, volume 228 of Electronic Notes in Theoretical Computer Science, pages 21 36. Elsevier, 2009. \n[10] J. Chapman, P.-E. Dagand, C. McBride, and P. Morris. The gentle art of levitation. In International \nConference on Functional Program\u00adming, pages 3 14. ACM, 2010. [11] C. Chen and H. Xi. Meta-programming \nthrough typeful code repre\u00adsentation. In International Conference on Functional Programming, pages 275 \n286. ACM, 2003. [12] A. Chlipala. Parametric higher-order abstract syntax for mechanized semantics. In \nInternational Conference on Functional Programming, pages 143 156. ACM, 2008.  [13] A. Chlipala. Ur: \nstatically-typed metaprogramming with type-level record computation. In Programming Languages Design \nand Imple\u00admentation, pages 122 133. ACM, 2010. [14] A. Chlipala. Certi.ed programming with dependent \ntypes. online, 2012. URL http://adam.chlipala.net/cpdt/. [15] N. A. Danielsson. A formalisation of a \ndependently typed language as an inductive-recursive family. In Types for Proofs and Programs, volume \n4502 of Lecture Notes in Computer Science, pages 93 109. Springer, 2007. [16] N. A. Danielsson. Operational \nsemantics using the partiality monad. In International Conference on Functional Programming, pages 127 \n138. ACM, 2012. [17] N. A. Danielsson and many others. The Agda standard library, 2009. [18] N. A. Danielsson \nand U. Norell. Parsing mix.x operators. In Imple\u00admentation and Application of Functional Languages, volume \n5836 of Lecture Notes in Computer Science, pages 80 99. Springer, 2008. [19] J. Darcy. JSR 269: Pluggable \nannotation processing API, 2011. URL http://jcp.org/en/jsr/detail?id=269. [20] D. Delahaye. A tactic \nlanguage for the system Coq. In Logic Pro\u00adgramming and Automated Reasoning, volume 1955 of Lecture Notes \nin Arti.cial Intelligence, pages 85 95. Springer, 2000. [21] P. Dybjer. Inductive families. Formal Aspects \nof Computing, 6(4): 440 465, 1994. [22] P. Dybjer and A. Setzer. A .nite axiomatization of inductive-recursive \nde.nitions. In Typed Lambda Calculi and Applications, volume 1581 of Lecture Notes in Computer Science, \npages 129 146. Springer, 1999. [23] S. Fogarty, E. Pasalic, J. Siek, and W. Taha. Concoqtion: indexed \ntypes now! In Symposium on Partial Evaluation and Semantics-Based Program Manipulation, pages 112 121. \nACM, 2007. \u00a8 ica und verwandter systeme i. Monatshefte f \u00a8ur Mathematik, 38(1): 173 198, 1931. [24] K. \nG \u00a8odel. Uber formal unentscheidbare s \u00a8atze der principia mathemat\u00ad [25] H. Goguen, C. McBride, and \nJ. McKinna. Eliminating dependent pattern matching. In Algebra, Meaning, and Computation, volume 4060 \nof Lecture Notes in Computer Science, pages 521 540. Springer, 2006. [26] G. Gonthier, B. Ziliani, A. \nNanevski, and D. Dreyer. How to make ad hoc proof automation less ad hoc. In International Conference \non Functional Programming, pages 163 175. ACM, 2011. [27] G. Gonthier, B. Ziliani, A. Nanevski, and D. \nDreyer. How to make ad hoc proof automation less ad hoc. technical appendix, 2011. URL http://www.mpi-sws.org/~beta/lessadhoc/appendix.pdf. \n[28] A. J. C. Hurkens. A simpli.cation of Girard s paradox. In Typed Lambda Calculi and Applications, \nvolume 902 of Lecture Notes in Computer Science, pages 266 278. Springer, 1995. [29] S. C. Johnson. YACC. \nUNIX Programmer s Manual, 2b, 1979. [30] O. Kiselyov, C.-c. Shan, D. P. Friedman, and A. Sabry. Backtracking, \ninterleaving, and terminating monad transformers: (functional pearl). In International Conference on \nFunctional Programming, pages 192 203. ACM, 2005. [31] R. L \u00a8ammel and S. Peyton-Jones. Scrap your boilerplate: \na practical design pattern for generic programming. In Types in Languages Design and Implementation, \npages 26 37. ACM, 2003. [32] J. Launchbury and S. Peyton Jones. Lazy functional state threads. In Programming \nLanguages Design and Implementation, page 35. ACM, 1994. [33] J. P. Magalh aes, A. Dijkstra, J. Jeuring, \nand A. L \u00a8oh. A generic deriving mechanism for Haskell. In Haskell Symposium, pages 37 48. ACM, 2010. \n[34] G. Mainland and G. Morrisett. Nikola: embedding compiled GPU functions in Haskell. In Haskell Symposium, \npages 67 78. ACM, 2010. [35] S. Marlow. Haskell 2010 language report. online, 2010. URL http://www.haskell.org/onlinereport/haskell2010/. \n[36] P. Martin-L of.\u00a8An intuitionistic theory of types. draft, 1972. URL http://cs.ioc.ee/~james/ITT9200/martinlof72.ps. \n[37] C. McBride. Type-preserving renaming and substitution. draft, 2005. URL http://strictlypositive.org/ren-sub.pdf. \n[38] C. McBride. Outrageous but meaningful coincidences: dependent type-safe syntax and evaluation. In \nWorkshop on Generic Program\u00adming, pages 1 12. ACM, 2010. [39] U. Norell. Towards a practical programming \nlanguage based on dependent type theory. PhD thesis, Chalmers, 2007. [40] Oracle. Java core re.ection. \nonline, 1996. URL http://docs.oracle.com/javase/1.5.0/docs/guide/ reflection/spec/java-reflectionTOC.doc.html. \n[41] T. Parr and R. Quong. ANTLR: A predicated-LL(k) parser generator. Software: Practice and Experience, \n25(7):789 810, 1995. [42] E. Pa.sali \u00b4c and N. Linger. Meta-programming with typed object\u00adlanguage representations. \nIn Generative Programming and Compo\u00adnent Engineering, volume 3286 of Lecture Notes in Computer Science, \npages 136 167. Springer, 2004. [43] B. Pientka and J. Dun.eld. Programming with proofs and explicit contexts. \nIn Principles and Practice of Declarative Programming, pages 163 173. ACM, 2008. [44] A. Poswolsky and \nC. Sch \u00a8urmann. Practical programming with higher\u00adorder encodings and dependent types. In Programming \nLanguages and Systems, volume 4960 of Lecture Notes in Computer Science, pages 93 107. Springer, 2008. \n[45] G. Richards, C. Hammer, B. Burg, and J. Vitek. The eval that men do. In European Conference on Object-Oriented \nProgramming, volume 6813 of Lecture Notes in Computer Science, pages 52 78. Springer, 2011. [46] A. Rodriguez, \nS. Holdermans, A. L \u00a8oh, and J. Jeuring. Generic pro\u00adgramming with .xed points for mutually recursive \ndatatypes. In Inter\u00adnational Conference on Functional Programming, 2009. [47] J. Rudolph and P. Thiemann. \nMnemonics: type-safe bytecode gener\u00adation at run time. Higher-Order and Symbolic Computation, 23(3): \n371 407, 2010. [48] T. Sheard and S. P. Jones. Template meta-programming for Haskell. In Workshop on \nHaskell, pages 1 16. ACM, 2002. [49] T. Sheard and E. Pasalic. Meta-programming with built-in type equal\u00adity. \nIn International Workshop on Logical Frameworks and Meta-Languages, 2004. [50] A. Stampoulis and Z. Shao. \nVeriML: typed computation of logical terms inside a language with effects. In International Conference \non Functional Programming, pages 333 344. ACM, 2010. [51] A. Stampoulis and Z. Shao. Static and user-extensible \nproof check\u00ading. In Principles of Programming Languages, pages 273 284. ACM, 2012. [52] W. Taha and T. \nSheard. MetaML and multi-stage programming with explicit annotations. Theoretical Computer Science, 248(1-2):211 \n242, 2000. [53] S. Tobin-Hochstadt, V. St-Amour, R. Culpepper, M. Flatt, and M. Felleisen. Languages \nas libraries. In Programming Languages Design and Implementation, pages 132 141. ACM, 2011. [54] Wikipedia. \nG \u00a8odel s incompleteness theorems, November 2012. URL http://en.wikipedia.org/wiki/Goedels_incompleteness_ \ntheorems.   \n\t\t\t", "proc_id": "2500365", "abstract": "<p>We present a novel set of meta-programming primitives for use in a dependently-typed functional language. The types of our meta-programs provide strong and precise guarantees about their termination, correctness and completeness. Our system supports type-safe construction and analysis of terms, types and typing contexts. Unlike alternative approaches, they are written in the same style as normal programs and use the language's standard functional computational model. We formalise the new meta-programming primitives, implement them as an extension of Agda, and provide evidence of usefulness by means of two compelling applications in the fields of datatype-generic programming and proof tactics.</p>", "authors": [{"name": "Dominique Devriese", "author_profile_id": "81467668211", "affiliation": "iMinds -- DistriNet, KU Leuven, Leuven, Belgium", "person_id": "P4261221", "email_address": "dominique.devriese@cs.kuleuven.be", "orcid_id": ""}, {"name": "Frank Piessens", "author_profile_id": "81100110352", "affiliation": "iMinds -- DistriNet, KU Leuven, Leuven, Belgium", "person_id": "P4261222", "email_address": "frank.piessens@cs.kuleuven.be", "orcid_id": ""}], "doi_number": "10.1145/2500365.2500575", "year": "2013", "article_id": "2500575", "conference": "ICFP", "title": "Typed syntactic meta-programming", "url": "http://dl.acm.org/citation.cfm?id=2500575"}