{"article_publication_date": "09-25-2013", "fulltext": "\n Modular and Automated Type-Soundness Veri.cation for Language Extensions Florian Lorenzen Sebastian \nErdweg TU Berlin, Germany TU Darmstadt, Germany Abstract Language extensions introduce high-level programming \nconstructs that protect programmers from low-level details and repetitive tasks. For such an abstraction \nbarrier to be sustainable, it is important that no errors are reported in terms of generated code. A \ntypical strategy is to check the original user code prior to translation into a low\u00adlevel encoding, applying \nthe assumption that the translation does not introduce new errors. Unfortunately, such assumption is \nuntenable in general, but in particular in the context of extensible programming languages, such as Racket \nor SugarJ, that allow regular programmers to de.ne language extensions. In this paper, we present a formalism \nfor building and automati\u00adcally verifying the type-soundness of syntactic language extensions. To build \na type-sound language extension with our formalism, a developer declares an extended syntax, type rules \nfor the extended syntax, and translation rules into the (possibly further extended) base language. Our \nformalism then validates that the user-de.ned type rules are suf.cient to guarantee that the code generated \nby the translation rules cannot contain any type errors. This effectively ensures that an initial type \ncheck prior to translation precludes type errors in generated code. We have implemented a core system \nin PLT Redex and we have developed a syntactically extensible variant of System F. that we extend with \nlet notation, monadic do blocks, and algebraic data types. Our formalism veri.es the soundness of each \nextension automatically. Categories and Subject Descriptors D.2.4 [Software/Program Veri.cation]; I.2.2 \n[Automatic Programming]: Program transfor\u00admation; D.3.2 [Language Classi.cations]: Extensible languages \nGeneral Terms Languages, Veri.cation Keywords language extensibility, type soundness, automatic veri\u00ad.cation, \nmetaprogramming, macros, SugarJ 1. Introduction Whenever code generation is used to abstract from low-level \ndetails or to provide high-level interfaces to software developers, type errors in generated code jeopardize \nthe abstraction barrier: First, error messages are in terms of generated code and thus expose Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. Copyrights for components of this work owned \nby others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, \nor republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. Request permissions from permissions@acm.org. ICFP 13, September 25 27, 2013, Boston, MA, USA. \nCopyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-2326-0/13/09. \n. . $15.00. http://dx.doi.org/10.1145/10.1145/2500365.2500596 programmers to low-level details that \nshould be hidden. Second, manual inspection of generated code may be necessary to identify the cause \nof the type error. Third, since a type error in generated code may be caused by either a defective generator \nor by invalid generator input, manual inspection of the generator may be necessary to identify the generator \ns contract and whether the input adheres to that contract. Type errors in generated code present a serious \nusability threat for abstractions implemented via code generation. In this paper, we address above problem \nin the context of code generators that extend a base language with new language constructs by translation \ninto other constructs of the base language. Such code generators are sometimes referred to as desugarings. \nMany compilers employ desugarings to transform programs of the input language into a core language, so \nthat subsequent compiler phases can focus on fewer language constructs. Moreover, macro systems empower \nregular programmers to introduce new language constructs via desugaring transformations. Despite wide-spread \napplication of desugarings, few existing compilers and no existing macro system can guarantee the absence \nof type errors in desugared code. To this end, we present SO U N D EX T, a formalism for soundly ex\u00adtending \na base language with new language constructs. SO U N D EX T statically and modularly validates a language \nextension and guaran\u00adtees that desugared code does not contain type errors. More speci.\u00adcally, for each \nlanguage extension, SO U N D EX T requires the de.ni\u00adtion of (i) an extended syntax, (ii) type rules \nfor checking programs that use the extended syntax, and (iii) a desugaring transforma\u00adtion that translates \na program of the extended syntax into a base\u00adlanguage program. SO U N D EX T then derives proof obligations \nfor each user-de.ned type rule: For all programs permitted by the type rule, the desugared version of \nthese programs must have the same type. SO U N D EX T synthesizes the corresponding proof for each type \nrule by instrumenting the inference engine with additional axioms that correspond to the assumptions \nof the user-supplied type rules. We present the details of our methodology in Section 3, where we also \nshow that the validity of each derived proof obligation entails the following high-level property: ' \n' G fext e : T . e .* e. e' . Base . G fbase e: T That is, given a program e that is well-typed in the \nextended type ' system, if this program desugars into a base-language program e, then the desugared program \nis well-typed in the base type system. In other words, type checking the user-supplied program is suf.cient \nto ensure the absence of type errors in desugared code. To demonstrate the expressiveness of SO U N D \nEX T, we instantiate the formalism for SugarFomega, a syntactically extensible variant of System F.. \nBesides standard lambda and type abstraction, Sug\u00adarFomega features variants, records, and higher-order \niso-recursive types as well as SugarJ-like macros with .exible syntax [5, 8, 10]. Using this macro system, \nSugarFomega programmers can introduce new language constructs at the level of expressions, types, and \nkinds. Accordingly, programmers de.ne additional type rules using type and kind judgments. We have implemented \nlanguage extensions of SugarFomega for let expressions, monadic do blocks (no implicit dictionary passing), \nand algebraic data types. SO U N D EX T modularly validated each of these extensions and guarantees that \nthey are sound with respect to the type system of System F..  In summary, we make the following contributions: \n We present the design of SO U N D EX T, a formalism for type-sound language extensibility.  SO U N \nD EX T automatically veri.es the type-soundness of lan\u00adguage extensions by deriving type rules for generated \nprograms and proving the admissibility of these type rules.  To prove admissibility we check derivability \nby instrumenting the type checker to use a type rule s premises as additional axioms.  We present a \nformalization of SO U N D EX T based on PLT Redex and prove that the desugarings of successfully veri.ed \nlanguage extensions adhere to type preservation and progress.  We verify that SO U N D EX T extensions \ncompose soundly as long as there is no syntactic overlap.  We implement the extensible language SugarFomega \nbased on SO U N D EX T and show how SO U N D EX T enables us to soundly extend SugarFomega with let expressions, \nmonadic do blocks, and algebraic data types.  2. Illustrating example Figure 1 shows the standard type \nrules of the simply-typed lambda calculus as they, for example, appear in Pierce s Types and Pro\u00adgramming \nLanguages [22]. The soundness of the corresponding type system is an established fact in the programming-language \ncommunity. However, when extending such a base language, one has to manually reestablish the soundness \ntheorem for the extended language [31]. As we demonstrate with SO U N D EX T in this paper, we can automatically \nverify the soundness of the extended type system for language extensions that are de.ned through translation \ninto the base language. For example, consider the extension of the simply-typed lambda calculus with \nlet expressions: e ::= . . . | let x : T = e in e We can rewrite let expressions to the simply-typed \nlambda calculus using the following desugaring: desugar-let : (let x : T = e1 in e2) --+ (.x : T .e2) \ne1 Since we want to detect and report type errors prior to desugaring, we extend the type system of the \nsimply-typed lambda calculus with a type rule for let expressions: G f e1 : T1 G, x : T1 f e2 : T2 T-LE \nT G f let x : T1 = e1 in e2 : T2 In the hope of preventing type errors in generated code, we use the \nextended type system to validate a user program prior to any desugaring. This way, the rewrite rule desugar-let \nwill only be applied to a let expression that has been checked by T-LE T. For example, the expression \nlet n : Nat = 17 in n + n is well-typed since 17 has type Nat and the judgment n : Nat f n + n : Nat \nholds. Therefore, it is safe to apply the rewrite rule, that is, the rewriting generates a well-typed \nexpression: (.n : Nat.n + n) 17 Conceptually, there are two sources of possible errors. First, the rewrite \nrule may be defective and produce ill-typed or wrongly typed code, even though the input let expression \nwas well-typed according to T-LE T. Second, the type rule may be defective and admit let expressions \nthat are not well-typed. For example, a defective rewrite rule (let x : T = e1 in e2) --+ (e2 e1) would \ntranslate above x : T . G G, x : T1 f e : T2 T-VA R T-A B S G f x : T G f .x : T1.e : T1 . T2 G f e1 \n: T1 . T2 G f e2 : T1 T-A P P G f e1 e2 : T2 Figure 1. Type rules of the simply-typed lambda calculus. \n let expression into the ill-typed expression (n + n) 17. Conversely, suppose we forgot the .rst premise \nin the de.nition of the type rule T-L E T. This defective type rule would admit the expression (let f \n: Nat .Nat=17 in f 0), which the (correct) rewrite rule desugar\u00adlet translates into the ill-typed program \n(.f : Nat . Nat.f 0) 17. Technically, these two sources of errors are two sides of the same coin: To \nguarantee the absence of type errors in generated code, we must ensure that the rewrite rule and the \ntype rule are correct with respect to each other. To this end, we can read the type rule T-LE T as a \ncontract for the rewrite rule desugar-let: The rewrite rule may assume all input adheres to the type \nrule T-LE T, and the rewrite rule must produce an expression of the type declared in the type rule. In \nessence, the rewrite rule must be type-preserving with respect to the type rules. If this holds, we can \ntype check the user program once before desugaring and know that the desugared program has the same type. \nTo verify that user-de.ned rewrite rules preserve types according to the user-de.ned type rules, we proceed \nas follows. We symbol\u00adically apply the rewrite rule to the subject of the corresponding type rule. For \nexample, for the let extension we obtain the type rule T-LE T : G f e1 : T1 G, x : T1 f e2 : T2 T-L E \nT G f (.x : T1.e2) e1 : T2 We could use this type rule to validate the code generated by desugar\u00adlet. \nInstead, we want to show that this type rule is admissible, that is, for all expressions typeable through \napplications of T-LE T , there is a derivation in the type system without T-L E T given the same context \nyielding the same type. Accordingly, we do not need T-L E T to type check the generated code, because \nthe other type rules already are expressive enough. SO U N D EX T automatically infers proof obligations \nfor the admis\u00adsibility of derived type rules. But SO U N D EX T also automatically veri.es these proof \nobligations by checking the derivability of type rules, which entails admissibility. We can reuse the \ntype system for checking the derivability of a derived type rule if (i) we interpret all metavariables \nin the assumptions and conclusion as constants that only unify with themselves and (ii) we temporarily \nadd the assumptions of the derived type rule as axioms to the system. A type rule then is derivable if \nwe can .nd a derivation of the modi.ed conclusion given the additional axioms. For example, for T-LE \nT we try to .nd a derivation for G f (.x : T1.e2) e1 : T2 given the axioms (AX1) G f e1 : T1 and (AX2) \nG, x : T1 f e2 : T2. Indeed, we can infer the following derivation, where the occurring metavariables \nG, x, T1, T2, e1, e2 are constants. AX2 G, x : T1 f e2 : T2 T-A B S AX1 G f .x : T1.e2 : T1 . T2 G f \ne1 : T1 T-A P P G f (.x : T1.e2) e1 : T2 This derivation shows that the type rule T-LE T is derivable. \nAs consequence, given an expression that is well-typed according to the user-de.ned type rule T-LE T, \nwe know that the expression generated by desugar-let has the same type as the original let expression. \nAccordingly, no type errors can emerge from the code generated by the desugaring rule. In the following \nsection we describe the approach followed by SO U N D EX T formally and prove that the derivability of \nderived type rules indeed entails type preservation of desugarings.  t ::= x | (c t) Terms J ::= t f \nt : t Judgments I ::= .x. J . J Inference rules R ::= t --+ t Rewrite rules E ::= ext I R Extensions \nB ::= I Base systems Figure 2. Syntax for declaring extensions. 3. SO U N D EX T A language extension \nde.nes new syntax, type rules for that syntax, and rewritings of that syntax into the base language. \nSO U N D EX T provides a language for the declaration of such extensions and a veri.cation procedure \nfor checking type soundness of extensions. We verify that our veri.cation procedure is suf.cient to guarantee \nthat no type errors are in desugared code. Our formalization is based on an implementation of SO U N \nD EX T in PLT Redex [11].1 However, whereas our PLT Redex implemen\u00adtation contains a concrete rewrite \nengine and inference engine, we parameterize our formalization over these engines and formulate minimal \nassumptions. Moreover, like the PLT Redex implementa\u00adtion, our formalization ignores all aspects of concrete \nsyntax and assumes programmers write abstract syntax trees directly; our im\u00adplementation of SugarFomega \n(see next section) supports the decla\u00adration of concrete syntax for extensions. 3.1 A language for declaring \nextensions We de.ne abstract syntax for the declaration of extensions as shown in Figure 2. We use a \ngeneric term representation to generalize over the expression, types, and contexts of any particular \nlanguage. Es\u00adsentially, a term t is an abstract syntax tree consisting of constructor applications (c \nt) (overlines denote sequences) and metavariables x. We use these terms for declaration of judgments \nJ. A judgment t1 f t2 : t3 relates a subject t2 to an object t3 under a context t1. We conventionally \nchoose metavariable names that resemble type checking as in G f e : T . Multiple judgments make up an \ninference rule, where all but the last judgments are premises and free metavariables must be explicitly \nquanti.ed. For example, we can encode the type rule T-AB S for lambda abstraction in this format: IAB \nS = . G x e T1 T2. (Bind G x T1) f e : T2 . G f (abs x T1 e) : (Fun T1 T2) For axioms, that is, inference \nrules without premises, we simply write .x. J ; for inference rules that do not bind any metavariables, \nwe drop the quanti.er J . J. Similar to inference rules, we can use terms to specify rewritings e1 --+ \ne2, where e1 may contain metavariables to pattern match on a term and e2 is a generation template that \ncan use the metavariables bound during pattern matching. In contrast to inference rules all meta-variables \nof the left-hand side of a rewrite rule may be instantiated during pattern matching. We therefore omit \nan explicit quanti.cation. The syntax of rewrite rules is agnostic to the meaning of the terms, it may \nbe an expression or a type, for example. Nevertheless, we restrict ourselves in this section to rewritings \nof expressions, that is, only terms in the subject position of inference rules. In Section 4 we present \na generalized form that also rewrites types. Based on these de.nitions, we de.ne an extension as a list \nof inference rules and rewrite rules. The base language B only consists of inference rules but no rewrite \nrules. The dynamic semantics of a base language and its relationship to the static semantics is completely \northogonal to 1 Implementation available online: http://sugarj.org/fomega ' R -MAT C H rewrite R e = \ne ' ' R-CO N e1 e2 R e2 R e ' 1 .e1 . e1 ' e R e c e1 e2 e3 R c e1 e2 e3 Figure 3. Speci.cation of a \nleft-to-right, one-step rewriting. SO U N D EX T since we are only interested in typing statements about \nbase language programs.  3.2 Assumptions about the rewrite engine SO U N D EX T is not tied to a speci.c \nrewriting algorithm. We assume a function rewrite R e that performs a single rewriting step by one of \nthe rules in R or returns fail if no rule is applicable. Since we want to apply the rewrite function \nto subjects of inference rules that contain metavariables, we must require that rewriting is closed under \nmetavariable substitution: Assumption 1 (Metavariable substitution-invariance). ' If rewrite R e[x] = \ne ' [x], then rewrite R e[ t ] = e [ t ]. We write e[x] to denote a term e in which at most the metavariables \nx appear free, and e[ t ] for the substitutions of these metavariables by the terms t. This assumption \nrequires that rewriting is independent of metavariable occurrences. For example, consider the following \ntwo rewrite rules: plus1 : (Plus (Suc m) n) --+ (Suc (Plus m n)) plus2 : (Plus m n) --+ n Given the input \nterm (Plus x Zero) with metavariable x, the rewrite function might do pattern matching to apply plus2 \nand return Zero. However, if we substitue (Suc y) for x, rule plus1 becomes applicable and yields (Suc \n(Plus y Zero)). This violates Assumption 1 because applying the same substitution to the old result does \nnot yield the new result. However, it is easy to recover this problem by expanding the pattern matching \nof plus2: plus2 : (Plus Zero n) --+ n Given this rule, the rewrite function would fail for the input \nterm (Plus x Zero), which is consistent with Assumption 1. In general, a rewrite engine should arrange \nthat if a rewrite rule inspects a subtree, this subtree cannot match a metavariable. In our PLT Redex \nimplementation, we assume that user-de.ned rewrite rules already adhere to the above properties. An alternative \nsolution to the problem illustrated by plus1 and plus2 is to require rewrite to perform top-to-bottom \nmatching of rules and to reverse the order of the two. In that case, plus2 would be applied for boths \ninputs. However, this would not relieve us from Assumption 1 and we therefore decided to leave the order \nof matching unspeci.ed since this poses fewer assumptions on the rewrite engine and has a more declarative \nfeeling. Based on the function rewrite , we de.ne the function e1 R e2 that performs a top-down, left-to-right, \none-step rewriting of e1 using rewrite (Figure 3). We write e * e ' for the re.exive, R transitive closure \nof e R e ' . Finally, we require that rewrite does not succeed on terms of the base language. As we will \nlater show, this ensures that the structure of base-language programs is preserved by R. Assumption 2 \n(Rewrite fails on base-language constructors). For any base-language constructor c, rewrite R (c e) = \nfail.  3.3 Assumptions about the inference engine SO U N D EX T requires developers to declare static \nanalyses for exten\u00adsions via inference rules. To reason about the user-de.ned inference rules and to \nprove their soundness, SO U N D EX T employs an inference engine to compute derivations. As for the rewriting, \nSO U N D EX T does not require any speci.c inference engine. Instead, we assume an inference engine that, \ngiven inference rules I and a judgment J, checks if J can be derived using the rules I. If successful, \nthe inference engine yields a concrete derivation I > J. Without going into any detail, we require correctness \nof the inference engine:  Assumption 3 (Correctness). If the inference engine yields a deriva\u00adtion I \n> J, then the derivation only consists of valid applications of the rules in I. Since we want to use \nthe inference engine not only for checking concrete programs but also for mechanically proving entailment \nbetween judgments, we require proper handling of metavariables by the inference engine. Speci.cally, \nlike for the rewrite engine, we require that the inference of derivations is closed under metavariable \nsubstitution (in the context of logical consequences this property is known as structurality [17]): Assumption \n4 (Metavariable substitution-invariance). If I[x] > J[x], then I[ t ] > J[ t ]. This requirement means \nthat if the inference engine is able to derive J[x] using I[x] without any knowledge about the free metavari\u00adables \nx, then a similar derivation must exist when instantiating the free metavariables with concrete terms. \nFor example, if the inference engine can deduce a derivation for the identity function (IVAR IABS IAPP \n) > (G f (abs x T x) : (Fun T T )) then a derivation must exist for any replacements of the free metavariables \nG, x, and T . 2 Recall that our inference rules quantify bound metavariables, as is visible in the inference \nrule for lambda abstraction IAB S shown in Section 3.1. SO U N D EX T capitalizes the fact that inference \nrules can also contain free metavariables to install assumptions about speci.c metavariables. In contrast \nto bound metavariables, free metavariables in an inference rule may not be instantiated when applying \nthe inference rule. For example, when deriving (.G. G f e : T ) > \u00d8 f e : T only the bound variable G \ngets instantiated to \u00d8 whereas e and T must match literally. Accordingly, we could not derive \u00d8 f e2 \n: T from the same inference rule, because e does not literally match e2. Finally, we require the inference \nengine to satisfy the cut rule: Assumption 5 (Cut). If I > J1 and I J1 > J2, then I > J2. We do not make \nany assumptions on decidability of the inference rules. Usually, the rules of a base system are in an \nalgorithmic form to obtain a complete type checker but this is not required. Further\u00admore, inference \nrules of an extension may lead to an undecidable system, even if the base system is decidable. That is, \nwe have no means to prevent nontermination of the type checker. In our PLT Redex implementation, we do \nnot use quanti.ers in inference rules but implicitly quantify over all free variables. To encode non-uni.able \nmetavariables, we wrap such metavariables in (symbol x) nodes. Otherwise, our inference engine performs \na simple proof-tree search and respects both metavariable substitution\u00adinvariance and the cut rule. \n 3.4 Extension soundness Using the rewrite engine and the inference engine, we de.ne a veri.cation procedure \nfor the soundness of extensions relative to a base system. The basic idea is to show that rewrite rules \nare type\u00adpreserving. We do so by (i) deriving an inference rule that admits exactly the programs generated \nby the rewrite rule but requires the 2 Note that there is only a single syntactic category in S O U N \nD EX T: terms t. As far as SO U N D EX T or the inference engine are concerned, any term can be used \nto represent any object-language construct, such as a variable. An extension ext I R is sound with respect \nto a base system B if for all typing rules I . I the following steps succeed: Let I = .x. J[x] . (G[x] \nf e[x] : T [x]). Let y be fresh and distinct variables with len y = len x. 1. Perform one-step rewriting \nof rule s subject with extension s rewrite rules: e[x] e ' [x] R 2. Show that derived rule ID = .x. J[x] \n. (G[x] f e ' [x] : T [x]) is derivable in B I: B I J[y] > (G[y] f e ' [y] : T [y]) Figure 4. The SO \nU N D EX T veri.cation procedure. original type, and (ii) verifying that this derived rule is derivable, \nthat is, all programs it admits were already admitted by the original inference rules. Together, this \nshows that all programs generated by the rewrite rule are admitted by the original inference rules, and \nthus must be well-typed. The full veri.cation procedure is shown in Figure 4. In Step 1, we rewrite the \nsubject of the inference rule I by applying the rewrite function. Since the subject of an inference rule \ntypically includes metavariables, this amounts to a symbolic rewriting of the rule s subject. Due to \nAssumption 1 on the rewrite engine, the rewritten subject e ' [x] captures all programs that can ever \nbe generated by the rewrite rules R from programs admitted by I. In Step 2, we de.ne a derived inference \nrule ID that uses the rewritten subject e ' [x] but has the same premises, context, and object. The derived \nrule admits exactly those programs that can be generated by R from programs admitted by I. By showing \nthat ID is derivable in B I, we ensure that generated programs have derivations in B I without ID. To \nverify the derivability of ID, we instantiate its bound variables with fresh variables y. We then install \nthe premises of the derived rule as axioms J[y] into the inference engine and try to derive the conclusion \nof the derived rule G[y] f e ' [y] : T [y]. If this derivation succeeds, it means the rules from B and \nI prove that the premises of the derived rule entail the conclusion of the derived rule for any y. Intuitively, \nwe can use this derivation to eliminate any application of the derived rule ID. For example, for the \nlet extension shown in Section 2, we prove the derivability of the derived rule T-L E T as follows: '' \n'' '' (IVAR IABS IAPP ILE T (G ' f e1 : T1) (G ' , x : T1 f e2 : T2)) ''' ' (G ' f (app (abs x ' T1 e2) \ne1) : T2) > ''' ' Note that the same unbound, fresh variables G ' , x , e1, e2, T1, and T2 ' appear in \nthe axioms and the goal, but not freely in any of the other rules. Since the variables in the axioms \nare not quanti.ed, the inference engine may only apply axioms to terms derived from the goal (this condition \nis part of Assumption 3). Note also that we permit the usage of an extension s own inference rules I \nin the derivability check. This enables extensions to desugar into recursive occurrences of the same \nextension without requiring the exact loop invariant as a premise of the inference rule. Our PLT Redex \nimplementation follows the veri.cation proce\u00addure exactly, with the exception that instead of substituting \nfresh variables we lock metavariables in (symbol x) nodes.  3.5 Metatheory The goal of our veri.cation \nprocedure for extension soundness is to ensure that desugarings cannot generate code with type errors. \nThe following is our main theorem:  Theorem 1 (Preservation). Let ext I R be a sound extension with \nrespect to B. If B I > (G f e : T ), e * e ', and e ' . term B, then R ' B > (G f e : T ). That is, given \na derivation for G f e : T in the extended system, we apply rewriting steps to the program e until it \nis desugared into a term of the base language. We show that the resulting base term is well-typed in \nthe base system B and satis.es the judgment ' G f e : T . Before turning to the proof of Theorem 1, we \n.rst prove a few important lemmas about the rewrite engine, the inference engine, and sound extensions. \nLemma 1. If e1[x] e2[x], then e1[ t ] R R e2[ t ]. Proof. Straightforward by induction on the derivation \ne1 R e2, using Assumption 1. Lemma 2. Let e[x] be a base-language term and e1 = e[ t1 ]. If e1 R e2, \nthen e2 = e[ t2 ] where t1 R t2 for exactly one (t1, t2) . (t1, t2) and t1 = t2 for all others. Proof. \nBy induction on the derivation e1 R e2, using that rewrite fails for terms that start with a base-language \nconstructor (Assump\u00adtion 2) and that e R e preserves base-language constructors. The next lemma establishes \nthe crucial property that a single rewrite step using a sound extension preserves types. Lemma 3. Let \next I R be a sound extension with respect to B. If B I > (G f e : T ) and e e ', then B I > (G f e ' \n: T ). R Proof. By induction on the derivation B I > (G f e : T ). Base case: The derivation consists \nof the application of an axiom I0 = .x. G0[x] f e0[x] : T0[x]. We have e = e0[ t ], G = G0[ t ], and \nT = T0[ t ] for some substitute t of x. If I0 . I, extension soundness entails e0[x] R e0 ' [x] and B \nI > (G0[y] f e ' [y] : T0[y]) for fresh y. By Lemma 1 and 0 e0[ t ] = e we get e0 ' [ t ] = e '. By Assumption \n4 we can substitute t for y and get B I > (G f e ' : T ) as required. If I0 . B, then e0[x] is a base \nlanguage term. By Lemma 2 we have e ' = e0[ t ' ]. Accordingly, we get a derivation of B I > (G f e ' \n: T ) by instantiating I0 with x = t ' . Step case: Assume the last rule applied in the derivation is \nI0 = .x. J0[x] . G0[x] f e0[x] : T0[x]. We have e = e0[ t ], G = G0[ t ], and T = T0[ t ] for some substi\u00adtute \nt of x, and B I > J0[ t ] for all J0[ t ] . J0[ t ] (Assumption 3). If I0 . I, extension soundness entails \ne0[x] R e ' 0[x] and ' B I J0[y] > (G0[y] f e [y] : T0[y]). By Lemma 1 and e0[ t ] = e 0 we get e0 ' \n[ t ] = e '. By Assumption 4 we can substitute t for y and get B I J0[ t ] > (G f e ' : T ). Repeated \napplication of the cut rule (Assumption 5) yields the required B I > (G f e ' : T ). If I0 . B, then \ne0[x] is a base language term. By Lemma 2 we have e ' = e0[ t ' ] and t R t ' for one (t, t ' ) . (t, \nt ' ) and t = t ' for all others. By the induction hypothesis we get B I > J0[ t ' ] since the extended \nsyntax t is irrelevant in contexts and types and can be replaced by t. Accordingly, we get a derivation \nof B I > (G f e ' : T ) by instantiating I0 with x = t ' . We can scale type preservation to the re.exive, \ntransitive closure of the rewrite relation R: Lemma 4. Let ext I R be a sound extension with respect \nto B. If B I > (G f e : T ) and e * e ', then B I > (G f e ' : T ). R Proof. Straightforward by induction \non the derivation e * e ' , R using Lemma 3. Finally, we can prove Theorem 1: Proof of Theorem 1. By \nLemma 4, we get B I > (G f e ' : T ). Since we assume e ' . term B and require rewrite rules to fail \nfor pure base terms, the derivation tree of G f e ' : T cannot contain an application of a rule from \nI because extension soundness requires a successful rewrite for a rule s subject. Accordingly, the derivation \ntree of G f e ' : T only contains instantiations of rules from B, hence B > (G f e ' : T ) as required. \nIn addition to our main preservation theorem, the veri.cation procedure also ensures progress of desugarings: \nTheorem 2 (Progress). Let ext I R be a sound extension with respect to B. If B I > (G f e : T ), then \neither B > (G f e : T ) or there is an e ' such that e R e ' . Proof. By induction on the derivation \nB I > (G f e : T ). Base case: Either the axiom is from the base system B, or by Step 1 of extension \nsoundness and Lemma 1 there is an e ' with e R e ' . Step case: If the last applied rule is from I, Step \n1 of extension soundness and Lemma 1 ensure there is an e ' with e R e ' . Otherwise, assume the last \napplied rule is from the base system B. By the induction hypothesis all subderivations are either derivable \nin B or their subject can be desugared. If there is at least one subderivation of the latter kind, then \nthe corresponding extended syntax must already be part of the current subject e because base rules cannot \npattern match on extended syntax. Thus, by the de.nition of R the term e can be desugared. Otherwise \nall subderivations are derivable in B, and so is the current judgment. This concludes our correctness \nproof for the veri.cation pro\u00adcedure of extension soundness employed by SO U N D EX T. We have shown \nthat our veri.cation procedure guarantees well-typing of generated base-language programs.  3.6 Extension \ncomposition and overlapping de.nitions As long as extensions are not syntactically overlapping, SO U \nN D EX T supports incremental extension [6] (one extension desugars into code of another extension) and \nextension uni.cation [6] (independent extensions can be uni.ed into a single extension). For incremental \nextension, we assume a sound extension ext I1 R1 with respect to base system B. A second extension ext \nI2 R2 can be de.ned on top of them by desugaring into the extended base system. We then require that \next I2 R2 is a sound extension with respect to the extended base system (B I1). Since we desugar programs \ne from the double-extended language con\u00ad * ' * '' secutively e e e , twice applying our soundness result \nR2 R1 from Theorem 1 proves that the .nal result e '' does not contain type errors if the original program \ne is well-typed. For extension uni.cation, we assume two extensions ext I1 R1 and ext I2 R2 both of which \nare sound with respect to the base system B. We can compose these extensions into a uni.ed extension \next I1I2 R1R2. The uni.ed extension is sound with respect to the base system B, because (i) for every \ntype rule there is a successful rewriting and (ii) the proof of derivability for a type rule remains \nvalid in the uni.ed extension. Accordingly, our veri.cation procedure for extension soundness can be \napplied modularly to different extensions before composing them. In case of a syntactic overlap, the \ncomposition of two sound extensions may be unsound if the type rule of one extension admits a term that \nis transformed by a desugaring of the other extension. To retain soundness, we have to cross-check all \ninvolved type rules for all potential desugarings, so that for any concrete rewriting the generated code \nis guaranteed to be free of type errors. This amounts to strengthening the contracts on desugarings by \ncombining the expectations formulated in multiple type rules. If this cross-checking fails, the composition \nmust fail. We have not implemented overlap detection in our PLT Redex implementation or SugarFomega. \nAs alternative to the detection of overlaps and the reveri.cation of soundness at composition time, we \ncould restrict the syntactic .exibility of extensions (as in traditional macro systems) to guarantee \nunambiguous syntax [24].  3.7 Summary We achieve type-sound language extensibility by requiring small\u00adstep \ndesugarings that are applicable to the subject of corresponding type rules. This way, we can derive type \nrules that exactly admit those programs that can be generated from well-typed programs. By showing that \nthese derived rules are admissible (by checking derivability), we ensure that the generated programs \nare well-typed themselves and do not require further type checking. In particular, we have shown that \nextension soundness entails that desugarings preserve types and do not get stuck. 4. SugarFomega We have \nimplemented a sound syntactically extensible programming language SugarFomega3 by combining the base \nlanguage System F., with SugarJ-like syntactic extensibility, and SO U N D EX T. SugarJ [5, 8, 10] enables \nthe syntactic extension of a base language like Java with arbitrary new syntax, given programs of that \nsyntax can be desugared into the base language. SugarJ (and SugarFomega) employ the SDF2 syntax formalism \n[28] for de.nition of extended syntax and the Stratego rewrite language [30] for the de.nition of desugaring \nrules. SugarJ organizes language extensions in modules of the base language itself, so that regular module-import \nstatements activate extensions locally by bringing the extended grammar and desugarings into the scope \nof the current module. SugarJ also provides support for program analyses that annotate the input program \nwith metadata. This information is used in error messages of the compiler as well as in our Eclipse-based \nextensible IDE [7], for example, to show type information in hover help. We employ the support for analyses \nto implement the F. type checker and the veri.cation procedure for sound extensions. 4.1 The base language \nSystem F. SugarFomega is based on System F. and primarily augments it with a simple module system that \nis amenable to SugarJ s module-based extension mechanism. We also add a few practical features: pair \nkinds, type synonyms, records, variants, higher-order iso-recursive types, and some primitive types. \nWith the exception of higher\u00adorder recursive types and the module system, SugarFomega is fairly standard \nand all its components can be found in textbooks [22]. Modules and signatures. A SugarFomega module may \nimport other modules and contains a sequence of value or type de.nitions that may be public. For example, \nwe de.ne a type synonym for polymorphic pairs, a swap function for pairs, and a private test expression \nthat is not exported: module Data.Pair import Foo public type Pair = \\A::*. \\B::*. {fst:A, snd:B} public \nval swap = \\A::*. \\B::*. \\p:Pair A B. 3 Implementation available online: http://sugarj.org/fomega Kind \njudgments ~C | ~T :: ~K ~C | ~T1 :: (~K => *) => ~K => * ~C | ~T2 :: ~K ================================= \nK Mu ~C | mu (~T1, ~T2) :: * Type judgments ~C | ~e : ~T ~C | ~T :: * ~C | ~T ~> mu (~T1, ~T2) ~C | ~e \n: ~S ~C | ~S ~> mu (~T1, ~T2) ~C | ~T2 :: ~K =================================== T Unfold ~C | unfold \n[~T] ~e : ~T1 (\\A::~K. mu (~T1, A)) ~T2 Figure 5. Kind and type rule for higher-order iso-recursive types. \n{fst=p!snd, snd=p!fst} val test = swap [Nat] [Bool] {fst=1, snd=false} The de.nition of a module is \nvalid if a signature is derivable, that is, if each type (value) de.nition is well-kinded (well-typed). \nThe initial context for the derivation of a signature is build from the signatures of imported modules. \nHigher-order recursive types. SugarFomega implements a form of higher-order iso-recursive types similar \nto Crary and Weirich [3]. Figure 5 shows the kind rule for our recursive type operator mu and the type \nrule for unfold, which performs a one-step unfolding of a recursive type. A recursive type is a pair \nmu (T1, T2) of types where T2 is of kind K and turns the higher-kinded recursive type operator T1 into \na proper type. For example, in SugarFomega, we can de.ne a polymorphic list with the following type synonyms: \ntype LRec = \\List::* => *. \\A::*. <Nil: {}, Cons: {hd:A, tl:List A}> type List = \\A::*. mu (LRec, A) \n The isomorphism between, for example, List Nat and its one-step unfolding is witnessed by fold and unfold \naccording to their type rules: mu (LRec, Nat) unfold [List Nat] fold [List Nat] <Nil: {}, Cons: {hd:Nat, \ntl:mu (LRec, Nat)}>  4.2 The SugarFomega type checker To de.ne the type system of F., we implemented \na domain-speci.c language for the declaration of inference rules: Premise 1 \u00b7 \u00b7 \u00b7 Premise n ========== \nRuleName Conclusion Our inference rules are layout-sensitive so that premises and con\u00adclusions can span \nmultiple lines, given they adhere to the offside rule [9]. The conclusion of a rule as well as each premise \nis a judgment. Whereas our formalization of SO U N D EX T in Section 3 was limited to type judgments, \nfor System F. we generalized SO U N D EX T to support multiple kinds of judgments. The most important \njudgments are: G | defs ==> s Signature judgments  G | e : T Type judgments G | T :: K Kind judgments \nG | T ~> T ' Normalization judgments For example, the kind and type rule for recursive types in Figure \n5 are implemented in our language for inference rules, where metavari\u00adables are pre.xed by a tilde ~. \nIn fact, we implemented most of the F. type system through the declaration of inference rules. We compile \nthe inference rules to executable Stratego code that is called during the analysis phase of SugarFomega. \nThe compiler has hard-wired knowledge about how to compile the different judgments. For example, our \ncompiler makes the following common assumptions about input and output positions of judgments: Input \nInput Output G | defs ==> s G | e : T G | T :: K ' G | T ~> T The code generated from different inference \nrules has a similar structure: First, we check that the rule s input matches the input expected by the \nconclusion. Second, we check the premises in order of appearance. Third, we compute the conclusion s \noutput. For signature, kind, and type judgments, we store the output of a conclusion as annotations of \nthe corresponding subject, so that we can reuse the signature, kind, or type during desugaring and in \neditor services such as hover help. Should an error occur, we annote them to the defective term instead \nof annotating a signature, kind, or type. Furthermore, note that the order of premises is signi.cant: \nBefore a metavariable can be used as input of a premise or as output of the conclusion, it must be introduced \nin an output position of a premise or as input of the conclusion. Our compiler translates each rule into \na certain Stratego strat\u00adegy. For example, the compiler translates kind rules into de.ni\u00adtions of annotate \nkind and type rules translate into de.nitions of annotate type. We eagerly normalize types and use Stratego \ns sup\u00adport for backtracking to explore all possible derivations (a compiler that produces ef.cient code \nfor .nding derivations is orthogonal to the work presented in this paper and left for future work). We \nillustrate the compilation of inference rules by example of the SugarFomega type rule for let expressions \n(~ marks a metavariable, ~% marks a metavariable only for identi.ers): ~C | ~e1 : ~T1 // (P1) ~C | ~S \n:: // (P2) ~C | ~S ~> ~U // (P3) ~C | ~T1 ~> ~U // (P4) (~C;~%x:~S) | ~e2 : ~T2 // (P5) ======================================= \nT Let ~C | (let ~%x : ~S = ~e1 in ~e2) : ~T2 * Figure 6 presents a simpli.ed version of the Stratego \ncode generated for T Let: Line 2 matches the input of the conclusion of rule T Let using abstract syntax. \nOnly if the input is a let expression, the type derivation continues with an instantiation of rule T \nLet.  Lines 3 and 4 implement premise (P1). The type of e1 is computed and annotated by a recursive \ncall. We require the successful typing of e1 by retrieving its type into variable T1 using get type. \n Lines 5 to 8 implement premise (P2). The kind of S is computed, annotated, and retrieved into a temporary \nvariable tmp1. (P2) demands S to be of kind *, which we check using kind eq star in line 7. kind eq star \nreturns a possibly empty list of error messages that we annotate to S in line 8.  1 annotate type = \n2 ?(C, node@Let(x, S, e1, e2)) 3 ; <annotate type> (C, e1) 4 ; <get type> e1 => T1 5 ; <annotate kind> \n(C, S) 6 ; <get kind> S => tmp1 7 ; <kind eq star> tmp1 => msgs1 8 ; <add context errors> (msgs1, S) \n9 ; <norm> (C, S) => U 10 ; <norm> (C, T1) => tmp2 11 ; <type eq> (U, tmp2) => msgs2 12 ; <add context \nerrors> (msgs2, T1) 13 ; <annotate type> (CtxBindVar(C, x, S), e2) 14 ; <get type> e2 => T2 15 ; <put \ntype> (T2, node) Figure 6. Stratego code generated for T Let. Lines 9 to 12 handle premises (P3) and \n(P4). The normalization judgment of (P3) compiles into a call of the type-normalization strategy norm. \nDuring translation of (P4), the compiler recognizes that the output U appears as output of a preceding \njudgment, namely (P3). Therefore, the normal form of T1 is stored in a temporary variable tmp2. The call \nof type eq in line 11 checks that the types bound to U and tmp2 indeed are equal (up to renaming of bound \nvariables). type eq returns a possibly empty list of error messages that we annotate to type T1.  Lines \n13 and 14 implement (P5), similar to the translation of (P1) but with an enriched context that contains \nthe binding ~%x:~S represented by the term CtxBindVar(C, x, S).  Finally, line 15 annotates the resulting \ntype to the let expression.  We use our domain-speci.c language for inference rules to im\u00adplement the \nwhole type system of System F.: kinding, typing, type normalization, and deriving module signatures. \nWe provide Sugar-Fomega programmers with the same language to de.ne inference rules for language extensions. \n 4.3 Writing language extensions in SugarFomega SugarFomega allows users to de.ne language extensions \nin reg\u00adular base-language modules. A SugarFomega extension takes the following form: module Name syntax \n{ SDF2 de.nitions } desugaring Strategy name { Stratego rewrite rules } typing { Typing rules } That \nis, a SugarFomega extension consists of an extended syntax, desugaring transformations from the extended \nsyntax into the (possibly further extended) base language F., and type rules for programs of the extended \nsyntax. For example, Figure 7 displays the de.nition of a SugarFomega extension for let expressions. \n The syntax section adds a new production to the nonterminal Expr that is de.ned in the base grammar \nof SugarFomega. The extension declares that a let expression can be used whenever a Expr is expected. \nThe annotation {cons(\"Let\")} declares that a let expression is represented by an abstract syntax tree \nnode of name Let.  The desugaring section de.nes a Stratego rule desugar let that implements the necessary \nrewriting. We use concrete syntax [29] for SugarFomega code in the declaration of rewrite rules. Like \nin type rules, a tilde ~ marks a metavariable. Often, it is useful to decompose a desugaring into multiple \nstrategies. The identi.er following the keyword desugaring names the entry point of desugaring that is \ncalled by the SugarFomega compiler.   module extensions.Let 1 verify context rule = syntax { context \nfree syntax \"let\" ID \":\" Type \"=\" Expr \"in\" Expr > Expr {cons(\"Let\")} } desugaring desugar let { desugar \nlet : |[ let ~%x : ~T = ~e1 in ~e2 ]| > |[ (\\ ~%x : ~T. ~e2) ~e1 ]| } typing { ~C | ~e1 : ~T1 ~C | ~S \n:: * ~C | ~S ~> ~U ~C | ~T1 ~> ~U (~C; ~%x:~S) | ~e2 : ~T2 ======================================= T \nLet ~C | (let ~%x : ~S = ~e1 in ~e2) : ~T2 } Figure 7. Declaration of a type-sound extension for let \nexpressions. The typing section de.nes a type rule for let expressions as discussed in the previous subsections. \nSince the language extension for let expressions is represented by a regular SugarFomega module, we can \nactivate the extension by importing the module. The SugarFomega system then loads the grammar extensions, \napplies the desugarings to parsed code, and performs static analysis according to prede.ned and user-de.ned \ninference rules. module test.Let import extensions.Let val test = let p : {x:Nat, y:Nat} = {x=1, y=2} \nin p!x  4.4 Verifying type-soundness of extensions SugarFomega veri.es the soundness of each language \nextension using a modi.ed version of SO U N D EX T (Section 3) that supports all judgments required in \nthe type system of System F. and knows about the input and output positions of judgments. Moreover, due \nto type-level abstraction in System F., we require equivalent types everywhere we required syntactically \nequal types before. As usual, we check type equivalence by comparing the normal forms of types. Speci.cally, \nwe modi.ed the veri.cation procedure for SugarFomega as follows: Type rule: Rewrite expression and assert \nequality of the normal forms of the expect and the actual type.  Kind rule: Rewrite type and assert \nequality of the expect and the actual kind.  Signature rule: Rewrite de.nitions and assert equality \nof the expected and the actual signature.  Type-normalization rule: Rewrite input type and assert equality \nof the normal forms of the input and the output type.  We have not yet formally proved that these criterions \nentail type preservation. But we are very con.dent that they indeed do since we can in principle encode \nthe different judgments into SO U N D EX T s judgment form by auxiliary constructors. Like in Section \n3, we use the inference engine to verify the soundness of user-de.ned inference rules. Since we compile \ninfer\u00adence rules to Stratego, we use Stratego s support for dynamically 2 ?TypingRule(premises, TypingJudgment(C, \ne, T)) 3 if <desugar one step> e => e des then 4 with scoped axioms( 5 <activate dynamic axioms> premises \n6 ; <annotate type> (C, e des) 7 ; <get type <+ !TyUnknown> e des => U 8 ; <norm> (C, T) => T 9 ; <norm> \n(C, U) => U 10 ) 11 ; <collect all errors> e des => errs 12 ; if <not(is empty)> errs then 13 !errs 14 \nelse if <not(type eq)> (T , U ) then 15 ![\"Type mismatch\"] 16 else 17 ![] 18 end end 19 else 20 ![\"Could \nnot desugar conclusion\"] 21 end Figure 8. SugarFomega veri.cation procedure for type rules. scoped rewrite \nrules [2] to activate axioms dynamically. For exam\u00ad ple, the strategy activate dynamic axiom activates \nan axiom for a type judgment: activate dynamic axiom = ?TypingJudgment(C, e, T) ; rules(Dynamic Annotate \nType :+ (C, e) > <put type> (T, e)) Given a type judgment, activate dynamic axiom extends the de.ni\u00adtion \nof Dynamic Annotate Type for the input (C, e). For example, for the premise like ~C | ~e1 : ~T1 from \nT Let, activate dynamic axiom activates the following rule: Dynamic Annotate Type : (C@Metavar(\"C\"), \ne@Metavar(\"e1\")) > <put type> (Metavar(\"T1\"), e) As required, this rule only accepts the speci.c term \nMetavar(\"e1\"), and not any other expression. We hook Dynamic Annotate Type into the regular type checking \nroutine annotate type by extending it as follows: annotate type = Dynamic Annotate Type That is, whenever \na type judgment is checked, the type checker will consider Dynamic Annotate Type, too. We show the Stratego \ncode for verifying the soundness of a type rule in Figure 8. This implementation corresponds to the veri.cation \nprocedure of SO U N D EX T with the above-mentioned modi.cations. In SugarFomega, the veri.cation procedure \nacts as a static analysis for checking modules that de.ne language extensions. Strategy verify context \nrule gets a typing rule as input and produces a possibly empty list of error messages (lines 1 and 2). \n In line 3, verify context rule tries to desugar the expression e of the conclusion one step. If this \nfails, an error message is emitted and the veri.cation fails (line 20).  If the desugaring is successful, \nline 5 enables the premises of the type rule as additional axioms. To prevent that axioms are active \noutside the veri.cation procedure, we scope them using the strategy with scoped axioms (line 4).  While \nthe additional axioms are active, we type check the desugared expression des e (line 6). We retrieve \nthe annotated type in line 7 or, if type checking fails, use TyUnknown instead.   To make the expected \nand the actual type comparable, we normalize them in lines 8 and 9.  Afterwards, we collect all errors \nthat have occurred during type checking of des e (line 11). If we .nd some errors, we return these errors \nand veri.cation fails.  Otherwise, we compare the normalized expected type T and the normalized actual \ntype U (line 14). If they are not equal, we return an error message and veri.cation fails.  Otherwise, \nno errors are emitted and the veri.cation succeeds.  We have implemented similar veri.cation procedures \nfor the other rules used in SugarFomega, in particular, kinding, type nor\u00admalization, and deriving module \nsignatures. As we demonstrate in the following section, SugarFomega permits users to integrate even sophisticated \nlanguage features as language extensions, for which SugarFomega modularly, statically, and automatically \nveri.es type-soundness. 5. Case studies In the previous sections, we used let expressions as an exemplary \nlanguage extensions that is easy to de.ne and that SO U N D EX T was able to prove sound. In the present \nsection, we further demonstrate the applicability of SO U N D EX T by extending SugarFomega with language \nextensions for monadic do blocks and algebraic data types. 5.1 Monadic do blocks Monads enable programmers \nto abstract over different computa\u00adtional .avors, such as state-full computation or non-deterministic \ncomputation [20]. Due to this abstraction, it is possible to de.ne combinators that are independent of \nconcrete computational .a\u00advors. For example, the function liftM2 lifts any pure function of type A > \nB > C into a monadic function M A > M B > M C for any monad M. In SugarFomega, we can encode a monad \nas a type operator M :: * . * with associated bind and return functions: bind : .A :: *. .B :: *. M A \n. (A . M B) . M B return : .A :: *. A . M A To support convenient programming with monads, we have de\u00adveloped \na language extension of SugarFomega that introduces do notation similar to Haskell. We provide type rules \nfor do blocks that detect type errors prior to desugaring. SugarFomega veri.es the soundness of our extension \nto guarantee no type errors occur in desugared code. Here is a simple do block as supported by our extension \nof SugarFomega: do [T] { x:T1 < e1 ; y:T2 < e2 ; e3 } A do block starts with a keyword do, followed by \nthe result type of the computation that the do block represents. Inside a do block occurs a semicolon-separated \nlist of computational statements, each of which may bind their result to a local variable. The last statement \nof a do block must be an expression that returns a value corresponding to the result type of the do block. \nNote that the type annotations in our encoding of do blocks are not strictly necessary; in Section 6 \nwe discuss how to drop them while retaining automatically veri.able type-soundness. As shown in Figure \n9, we desugar a do block into an expression that is parameterized over a monad, that is, over a type \noperator M and functions bind and return. The .rst desugaring rule handles do blocks that only contain \na .nal expression, whereas the second desugaring desugar do { desugar do : |[ do [~T] { ~e } ]| > |[ \n\\M::*=>*. \\bind: forall A::*. forall B::*. M A > (A > M B) > M B. \\return: forall A::*. A > M A. ~e ]| \n desugar do : |[ do [~T] { ~%x : ~S < ~e1; ~stmts } ]| > |[ \\M::*=>*. \\bind: forall A::*. forall B::*. \nM A > (A > M B) > M B. \\return: forall A::*. A > M A. bind [~S] [~T] ~e1 (\\~%x:~S. do [~T] { ~stmts \n} [M] bind return) ]| } Figure 9. Desugaring rules for do blocks. desugaring rule handles do blocks with \nmultiple statements. In contrast to let expressions, the desugaring of do blocks requires recursion. \nWe trigger recursion in the second desugaring rule by generating code that contains a residual do block, \nto which we propagate M, bind, and return. SugarFomega only allows programmers to write programs that \ncan be type checked before desugaring. Accordingly, we require type rules for do blocks. In Figure 10, \nwe display the type rule for do blocks with multiple statements. The type of the conclusion clearly demonstrates \nour choice to implement do blocks as polymorphic functions. The premises (P3) and (P7) express the essential \ncontext conditions of do blocks: The right-hand side ~e1 of a monadic binding must be well-typed in \na context that provides bind and return.  The subsequent statements ~stmts must be well-typed in the \nsame context enriched by the bound variable ~%x.  SugarFomega automatically veri.es that these requirements \nare suf.cient to guarantee that the desugared code is well-typed. For example, this allows us to de.ne \nliftM2 using do notation: module MonadLift import extensions.DoBlock val liftM2 = \\M::*=>*. \\bind: forall \nA::*. forall B::*. M A > (A > M B) > M B. \\return: forall A::*. A > M A. \\A::*. \\B::*. \\C::*. \\f: A > \nB > C. \\m1: M A. \\m2: M B. do [C] { x:A < m1 ; y:B < m2 ; return [C] (f x y) } [M] bind return  5.2 \nAlgebraic data types The type system of System F. is very .exible and expressive, but the encoding of \ntree-like data structures in terms of variants, records, and recursive types is cumbersome. To this end, \nwe use SugarFomega to de.ne a type-sound extension for algebraic data types like the following de.nition \nfor polymorphic lists: data List (A::*) = Nil {} | Cons {hd: A, tl: List A} This de.nition is desugared \ninto a type synonym List and con\u00adstructor functions Nil and Cons that type-normalize to the following \nde.nitions:  (~C; M::*=>*) | ~S :: // (P1) * * (~C; M::*=>*) | ~T :: // (P2) (~C; M::*=>*; bind: forall \nA::*. forall B::*. M A > (A > M B) > M B // (P3) ; return: forall A::*. A > M A) | ~e1 : ~R1 (~C; M::*=>*) \n| ~R1 ~> M ~U1 // (P4) * (~C; M::*=>*) | ~U1 :: // (P5) (~C; M::*=>*) | ~S ~> ~U1 // (P6) (~C; M::*=>*; \nbind: forall A::*. forall B::*. M A > (A > M B) > M B // (P7) ; return: forall A::*. A > M A; ~%x:~S) \n| do [~T] { ~stmts } : forall M::*=>*. (forall A::*. forall B::*. M A > (A > M B) > M B) > (forall A::*. \nA > M A) > M ~T ============================================================================================================== \nT DoCons ~C | do [~T] { ~%x : ~S < ~e1; ~stmts } : forall M::*=>*. (forall A::*. forall B::*. M A > (A \n> M B) > M B) > (forall A::*. A > M A) > M ~T Figure 10. Typing rule for a do block with multiple statements. \ntype List = \\A::*. mu (\\List::*=>*. \\A::*. <Nil:{}, Cons:{hd:A, tl:List A}>, A) val Nil = \\A::*. fold \n[List A] (<Nil={}> as <Nil:{}, Cons:{hd:A, tl:List A}>) val Cons = \\A::*. \\hd:A. \\tl:List A. fold [List \nA] (<Cons={hd=hd, tl=tl}> as <Nil:{}, Cons:{hd:A, tl:List A}>) To achieve the desugaring of algebraic \ndata types, we need to exercise two features of SugarFomega not discussed in detail before: abstract \nintermediate program representations for which no concrete syntax exists and type-level language extensions. \nAbstract intermediate program representations. Since the veri.\u00adcation procedure of SO U N D EX T and \nSugarFomega require a rewriting to apply to the subject of a type rule, language extensions must be desugared \nin small-step fashion. For example, for do blocks the sec\u00adond desugaring created a residual do block, \nwhich is transformed in a later iteration of the .x-point desugaring. In a sense, we got lucky for do \nblocks, because the residual program could be described by concrete syntax. More generally, and for algebraic \ndata types in particular, it is not always possible to describe residual programs via concrete syntax \n(which users would be allowed to write, too). For this reason, SugarFomega allows desugaring transformations \nand inference rules to use abstract intermediate program representations instead of concrete syntax. \nNote that this was not a problem for SO U N D EX T because we only used abstract syntax anyway. An extension \nhas to declare the abstract-syntax nodes it wants to use as part of the desugaring: desugaring desugar \nadt { signature constructors ADT DCON: ID DataParams * * ID Decls DataCons > Term * * ADT DCON FIELDS: \nDecls > Term ADT TABS: DataParams Expr > Term * ... } Afterwards, the extension can use these nodes \nin place of concrete syntax by pre.xing them with M~. For example, we use an abstract intermediate node \nADT TABS to pre.x the code generated for a constructor with the type parameters of the algebraic data \ntype (a nested occurrence of |[ ]| escapes back to concrete syntax): desugar data : |[ M~ADT TABS(|[]|, \ne) |] > |[ ~e ]| desugar data : |[ M~ADT TABS( |[ (~%X::~K) ~params ]| , e) ]| > |[ \\~%X::~K. M~ADT TABS(params, \ne) ]| ~C | ~e : ~T ======================================= T ADT TABS1 ~C | M~ADT TABS(|[]|, e) : ~T \n (~C; ~%X::~K) | M~ADT TABS(params, e) : ~T ============================================ T ADT TABS2 \n~C | M~ADT TABS(|[ (~%X::~K) ~params ]|, e) : forall ~%X::~K. ~T In our case study for algebraic data \ntypes, we exclusively represent intermediate data-type fragments via abstract syntax. To this end, we \nemploy 19 different abstract-syntax nodes for the generation of the type synonym and the constructor \nfunctions. Type-level and kind-level language extensions. As described in Section 4.2 and 4.4, SugarFomega \nsupports syntactic sugar at all levels: kinds, types, and expressions. However, an extension is only \nusable if there are inference rules that can be employed for the validation of a program using the extended \nsyntax. For expression\u00adlevel extensions, we have shown for let expressions and do blocks that type rules \ncan provide the necessary validation. For type-level and kind-level extensions, other means are necessary. \nFor type-level extensions, there are two possibilities for the speci.cation of valid usage patterns of \nextended types: using kind rules only or also adding type-normalization rules. These alternatives have \nan interesting consequence when using an abstract intermediate representation for extended types: The \nextended types can be introduced nominally or structurally. For example, consider the following kind \nrule that speci.es the kind of the residual type ADT ABS. (~C;~%X::~K1) | M~ADT ABS(params, T) :: ~K2 \n============================================ K ADT ABS2 ~C | M~ADT ABS(|[ (~%X::~K1) ~params ]|, T) :: \n~K1 => ~K2 Since SugarFomega performs type checking prior to desugaring, this kind rule only applies \nto residual types ADT ABS, and nothing else. Compare this with the following type-normalization rule \nthat speci.es to what the residual type ADT ABS normalizes: ~C | M~ADT ABS(params, T) ~> ~T2 =========================================== \nN ADT ABS2 ~C | M~ADT ABS(|[ (~%X::~K) ~params ]|, T) ~> \\~%X::~K. ~T2 Since type normalization happens \nevery time two types are com\u00adpared, this type-normalization rule permits the usage of ADT ABS wherever \na type \\~X::~K. ~T is expected. For our case study of algebraic data types, the difference is whether \nvalues of the generated type synonym can be de.ned only with the generated constructors (nominal) or \nwith any expression of the right type (structural). Note that kind rules are required in most cases anyway, \nbecause during veri.cation of type rules with kind-judgment premises, there is typically not enough information \non types to perform type normalization.  For kind-level extensions, there is no such choice because \nthere are no explicit sorts or super-kinds in SugarFomega. However, we added context-free kind normalization \nto permit the generation of kinds depending on the input program. For example, we use the following kind-normalization \nrule to permit the usage of the residual kind ADT CK as a higher-order kind (used to describe the type \narguments of an algebraic data-type constructor such as List): M~ADT CK(params) =::=> ~K2 ================================= \nKN ADT PK2 M~ADT CK(|[ (~%X::~K) ~params ]|) =::=> ~K => ~K2 In our SugarFomega implementation of algebraic \ndata types, we use kind rules, type-normalization rules, and kind-normalization rules. However, we found \nthat our normalization rules always resemble the rewriting of the desugaring rules. As consequence, the \nveri.cation is trivial because the desugaring of the normalization input yields the normalization output. \nMoreover, this is obvious boilerplate that we hope to remedy in a future version of our domain\u00adspeci.c \nlanguage for inference engines. Summary. Algebraic data types are by far the most sophisticated language \nextension we have implemented in SugarFomega. The whole extension comprises 19 abstract-syntax nodes, \n34 desugaring rules, 4 module-signature derivation rules, 7 type rules, 13 kind rules, 21 type-normalization \nrules, and 4 kind-normalization rules. 6. Type reconstruction As brie.y mentioned before, quite a few \nof the type annotations we currently require are not necessary, because the de.ning expressions of the \ninvolved variables are statically available. For example, the language extension for let expressions \n(Figure 7) requires a type annotation for the bound variable, because such annotation is required in \nthe desugared lambda abstraction. To reduce the number of required type annotations, we started to experiment \nwith a type-of metalanguage construct that permits the reuse of an expression s type. For example, with \nthe type-of construct, we can support let expressions without type annotations: desugaring desugar let \n{ desugar let : |[ let ~%x = ~e1 in ~e2 ]| > |[ (\\~%x:$(typeof ~e1). ~e2) ~e1 ]| } This desugaring is \nonly applicable if ~e1 is well-typed, in which case the type of ~e1 is copied into the generated program. \nWe are currently evaluating different alternatives for implementing the type\u00adof construct, such that \ntype-of is supported during the veri.cation of extensions and while type checking user programs. Moreover, \nwe are currently investigating how to support type-of constructs that are transitively generated, for \nexample, by another extension that produces let expressions. 7. Related work Most approaches for language \nextensibility have in common that type checking is only performed on the full expansion of the extended \nsyntax, that is, after desugaring. There is no validation of transformation rules to ensure they produce \nwell-typed code of the required type. Even in Typed Racket [27], a gradually typed Scheme dialect, macros \nare untyped and type checking operates on fully desugared core syntax. While some systems [4, 25] require \nthe transformation itself to be a well-typed function, the employed program representations are not typed \nenough to make suf.cient statements about the typing properties of the generated code. On the other hand, \nexisting highly typed program representations as known from dependently typed languages such as Agda \nor from similar encodings in Haskell, have not yet been adopted by approaches for language extensibility. \nHerman s .m-calculus [16] augments a Scheme-like macro system with signatures for macro de.nitions that \ndescribe their binding structure. These signatures allow to verify if a macro generates code that matches \nthe signature. For example, this can be used to ensure that an argument bound by the macro must be used \nat a binding position in the generated code. The .m-calculus enables the de.nition of a-equivalence for \nunexpanded Scheme programs. However, guarantees are restricted to static scoping aspect of macros and \ndo not scale to the static typing of terms. MacroML [14] is an extension of the ML programming language \nwith the possibility to de.ne generative and binding macros in a statically typed setting. The semantics \nof a MacroML program is de.ned by a translation into the multi-stage programming language MetaML [26] \nand a type preservation result of this translation is proved. In contrast to MacroML, SO U N D EX T allows \ndesugarings to inspect and decompose user programs using pattern matching. Furthermore, MacroML macros \nthat introduce new binding con\u00adstructs have to be variations of prede.ned binding structures like lambda \nabstraction to unambiguously identify binding and bound occurrences of variables. In contrast, SO U N \nD EX T allows type rules to freely specify extension-speci.c scoping of identi.ers via the context in \njudgments. For example, a simple SugarFomega exten\u00adsion openpair could bring the components of a pair \ninto the current scope by binding variables fst and snd. The corresponding type rule would clearly document \nthe bound variables fst and snd and their scope. Such macro could not be de.ned in MacroML. MetaHaskell \n[18] adds type-safe metaprogramming facilities with different object languages to Haskell. To turn a \nlanguage into a MetaHaskell object language, a quasiquoter for the surface syntax, a type checker, and \na uni.cation procedure for object-language types have to be provided. The object language type checker \nis called by the MetaHaskell type checker to check embedded object programs. This technique only yields \na type-safe type system if the object language s type checker is sound with respect to the dynamic semantics \nof the object language. In contrast to SO U N D EX T, this condition is not checked mechanically but \nhas to be manually veri.ed. Ziggurat [12, 13] is a metalanguage to extend other programming languages \nthrough Scheme-like macros and to attach static analyses like type checking or termination analysis to \nthe new syntax. In Ziggurat, nodes of the syntax tree are represented as objects with a parsing and a \nrewrite function in an an object-oriented system called lazy delegation. Lazy delegation permits the \nimplementation of static analyses explicitly for a node by implementing the corresponding method, or \nimplicitly by delegating analysis to the objects generated during desugaring. However, static analyses \nthemselves are not validated against desugarings and there is the danger that a malicious analysis of \na subclass overrides a sound analysis of a super class. Pluggable type systems [1] extend an existing \ntype systems with additional constraints. Pluggable type systems may reject programs that, for example, \ndo not comply to a certain design pattern or introduce new types. Implementations of pluggable type systems \nlike JavaCOP [19] or the Checker Framework [21] provide infrastructure to implement type analyses and \nto integrate them into the semantic analysis phase of the compiler. The soundness of a pluggable type \nsystem is not veri.ed mechanically, this is the implementer s responsibility. But JavaCOP has another \ninteresting approach with respect to soundness: testing for soundness violations.  Their test harness \nsupports the instrumentation of Java byte code with runtime checks to detect stuck expressions that the \npluggable type system is supposed to prevent statically. Roberson et al. [23] propose model checking \nto automatically prove the soundness of a type system for all program states of at most some .nite size. \nTheir technique is similar to ours: Identify well-typed intermediate programs, perform one step of reduction, \nand prove that the resulting program is also well-typed. However, the most important difference is that \nRoberson et al. inspect con\u00adcrete program states and apply sophisticated pruning techniques to avoid \nstate-space explosion, whereas SO U N D EX T performs symbolic rewriting and equational reasoning. Heeren \net al. [15] propose an extensible type-inference mecha\u00ad nism in which libraries can de.ne uni.cation \nconstraints. Since their system does not support syntactic extensibility, library functions are typeable \nin the base type system. Type-system extensions are veri.ed sound by requiring that they only de.ne specialized \nversions of base type rules. While less expressive, this approach is useful for de.ning library-speci.c \nerror messages and we plan to integrate their mechanism into SugarFomega. 8. Conclusion and future work \nWe presented SO U N D EX T, a formalism for syntactically extending a base language without affecting \ntype soundness. In particular, SO U N D EX T veri.es language extension to guarantee that desugar\u00adings \nadhere to type preservation and progress. Accordingly, code generated from desugarings cannot contain \ntype errors, which would break important abstraction barriers for programmers. We applied SO U N D EX \nT to the advanced base language Sys\u00adtem F., resulting in SugarFomega, and successfully added nontrivial \nextensions for do blocks and algebraic data types in a type-sound way. In future work, we hope to use \nSO U N D EX T to validate the desugarings and type rules of language extensions currently in use in compilers \nsuch as GHC, which will require solid support for type reconstruction and the generation of more ef.cient \ntype checkers from inference rules. References [1] G. Bracha. Pluggable type systems. In OOPSLA Workshop \non Revival of Dynamic Languages, 2004. Available at http://bracha.org/ pluggableTypesPosition.pdf, accessed \nat Mar. 26 2013. [2] M. Bravenboer, A. v. Dam, K. Olmos, and E. Visser. Program transformation with scoped \ndynamic rewrite rules. Fundamenta Informaticae, 69(1-2):123 178, 2006. [3] K. Crary and S. Weirich. Flexible \ntype analysis. In Proceedings of International Conference on Functional Programming (ICFP), pages 233 \n248. ACM, 1999. [4] D. de Rauglaudre. Camlp4 reference manual. http://caml.inria. fr/pub/docs/manual-camlp4/index.html, \n2003. accessed Mar. 26 2013. [5] S. Erdweg. Extensible Languages for Flexible and Principled Domain Abstraction. \nPhD thesis, Philipps-Universi\u00e4t Marburg, 2013. [6] S. Erdweg, P. G. Giarrusso, and T. Rendel. Language \ncomposition untangled. In Proceedings of Workshop on Language Descriptions, Tools and Applications (LDTA), \npages 7:1 7:8. ACM, 2012. [7] S. Erdweg, L. C. L. Kats, T. Rendel, C. K\u00e4stner, K. Ostermann, and E. Visser. \nGrowing a language environment with editor libraries. In Pro\u00adceedings of Conference on Generative Programming \nand Component Engineering (GPCE), pages 167 176. ACM, 2011. [8] S. Erdweg, T. Rendel, C. K\u00e4stner, and \nK. Ostermann. SugarJ: Library\u00adbased syntactic language extensibility. In Proceedings of Conference on \nObject-Oriented Programming, Systems, Languages, and Applications (OOPSLA), pages 391 406. ACM, 2011. \n[9] S. Erdweg, T. Rendel, C. K\u00e4stner, and K. Ostermann. Layout-sensitive generalized parsing. In Proceedings \nof Conference on Software Language Engineering (SLE), volume 7745 of LNCS, pages 244 263. Springer, 2012. \n[10] S. Erdweg, F. Rieger, T. Rendel, and K. Ostermann. Layout-sensitive language extensibility with \nSugarHaskell. In Proceedings of Haskell Symposium, pages 149 160. ACM, 2012. [11] M. Felleisen, R. B. \nFindler, and M. Flatt. Semantics Engineering with PLT Redex. MIT Press, 2009. [12] D. Fisher and O. Shivers. \nStatic analysis for syntax objects. In Proceedings of International Conference on Functional Programming \n(ICFP), pages 111 121. ACM, 2006. [13] D. Fisher and O. Shivers. Building language towers with Ziggurat. \nFunctional Programming, 18(5-6):707 780, 2008. [14] S. Ganz, A. Sabry, and W. Taha. Macros as multi-stage \ncomputations: Type-safe, generative, binding macros in MacroML. In Proceedings of International Conference \non Functional Programming (ICFP), pages 203 217. ACM, 2001. [15] B. Heeren, J. Hage, and S. D. Swierstra. \nScripting the type inference process. In Proceedings of International Conference on Functional Programming \n(ICFP), pages 3 13. ACM, 2003. [16] D. Herman. A Theory of Typed Hygienic Macros. PhD thesis, Northeastern \nUniversity, Boston, Massachusetts, 2012. [17] J. Lo\u00b4s and R. Suszko. Remarks on sentential logics. Indagationes \nMathematicae, 20:177 183, 1958. [18] G. Mainland. Explicitly heterogeneous metaprogramming with Meta-Haskell. \nIn Proceedings of International Conference on Functional Programming (ICFP), pages 311 322. ACM, 2012. \n[19] S. Markstrum, D. Marino, M. Esquivel, T. Millstein, C. Andreae, and J. Noble. JavaCOP: Declarative \npluggable types for Java. Transactions on Programming Languages and Systems (TOPLAS), 32(2):4:1 4:37, \n2010. [20] E. Moggi. Notions of computation and monads. Information and Computation, 93(1):55 92, 1991. \n[21] M. M. Papi, M. Ali, T. L. Correa, Jr., J. H. Perkins, and M. D. Ernst. Practical pluggable types \nfor Java. In Proceedings of International Symposium on Software Testing and Analysis (ISSTA), pages 201 \n212. ACM, 2008. [22] B. C. Pierce. Types and programming languages. MIT press, 2002. [23] M. Roberson, \nM. Harries, P. T. Darga, and C. Boyapati. Ef.cient software model checking of soundness of type systems. \nIn Proceedings of Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA), \npages 493 504. ACM, 2008. [24] A. Schwerdfeger and E. Van Wyk. Veri.able composition of deter\u00administic \ngrammars. In Proceedings of Conference on Programming Language Design and Implementation (PLDI), pages \n199 210. ACM, 2009. [25] T. Sheard and S. Peyton Jones. Template meta-programming for Haskell. In Proceedings \nof Haskell Workshop, pages 1 16. ACM, 2002. [26] W. Taha and T. Sheard. MetaML and multi-stage programming \nwith explicit annotations. Theoretical Computer Science, 248(1-2):211 242, 2000. [27] S. Tobin-Hochstadt \nand M. Felleisen. Logical types for untyped languages. In Proceedings of International Conference on \nFunctional Programming (ICFP), pages 117 128. ACM, 2010. [28] E. Visser. Syntax De.nition for Language \nPrototyping. PhD thesis, University of Amsterdam, 1997. [29] E. Visser. Meta-programming with concrete \nobject syntax. In Pro\u00adceedings of Conference on Generative Programming and Component Engineering (GPCE), \nvolume 2487 of LNCS, pages 299 315. Springer, 2002. [30] E. Visser, Z.-E.-A. Benaissa, and A. P. Tolmach. \nBuilding program optimizers with rewriting strategies. In Proceedings of International Conference on \nFunctional Programming (ICFP), pages 13 26. ACM, 1998. [31] A. K. Wright and M. Felleisen. A syntactic \napproach to type soundness. Information and Computation, 115(1):38 94, 1994.   \n\t\t\t", "proc_id": "2500365", "abstract": "<p>Language extensions introduce high-level programming constructs that protect programmers from low-level details and repetitive tasks. For such an abstraction barrier to be sustainable, it is important that no errors are reported in terms of generated code. A typical strategy is to check the original user code prior to translation into a low-level encoding, applying the assumption that the translation does not introduce new errors. Unfortunately, such assumption is untenable in general, but in particular in the context of extensible programming languages, such as Racket or SugarJ, that allow regular programmers to define language extensions.</p> <p>In this paper, we present a formalism for building and automatically verifying the type-soundness of syntactic language extensions. To build a type-sound language extension with our formalism, a developer declares an extended syntax, type rules for the extended syntax, and translation rules into the (possibly further extended) base language. Our formalism then validates that the user-defined type rules are sufficient to guarantee that the code generated by the translation rules cannot contain any type errors. This effectively ensures that an initial type check prior to translation precludes type errors in generated code. We have implemented a core system in PLT Redex and we have developed a syntactically extensible variant of System F<sub>w</sub> that we extend with let notation, monadic do blocks, and algebraic data types. Our formalism verifies the soundness of each extension automatically.</p>", "authors": [{"name": "Florian Lorenzen", "author_profile_id": "81413595977", "affiliation": "TU Berlin, Berlin, Germany", "person_id": "P4261272", "email_address": "florian.lorenzen@tu-berlin.de", "orcid_id": ""}, {"name": "Sebastian Erdweg", "author_profile_id": "81490684973", "affiliation": "TU Darmstadt, Darmstadt, Germany", "person_id": "P4261273", "email_address": "erdweg@informatik.tu-darmstadt.de", "orcid_id": ""}], "doi_number": "10.1145/2500365.2500596", "year": "2013", "article_id": "2500596", "conference": "ICFP", "title": "Modular and automated type-soundness verification for language extensions", "url": "http://dl.acm.org/citation.cfm?id=2500596"}