{"article_publication_date": "09-25-2013", "fulltext": "\n Testing Noninterference, Quickly 1 Cat..John Hughes2 Antal Spector-Zabusky1 Dimitrios Vytiniotis3 \nalin Hrit\u00b8cuBenjamin C. Pierce1 Arthur Azevedo de Amorim1 Leonidas Lampropoulos1 1University of Pennsylvania \n2Chalmers University 3Microsoft Research Abstract Information-.ow control mechanisms are dif.cult to \ndesign and labor intensive to prove correct. To reduce the time wasted on proof attempts doomed to fail \ndue to broken de.nitions, we ad\u00advocate modern random testing techniques for .nding counterexam\u00adples during \nthe design process. We show how to use QuickCheck, a property-based random-testing tool, to guide the \ndesign of a sim\u00adple information-.ow abstract machine. We .nd that both sophis\u00adticated strategies for \ngenerating well-distributed random programs and readily falsi.able formulations of noninterference properties \nare critically important. We propose several approaches and eval\u00aduate their effectiveness on a collection \nof injected bugs of varying subtlety. We also present an effective technique for shrinking large counterexamples \nto minimal, easily comprehensible ones. Taken together, our best methods enable us to quickly and automatically \ngenerate simple counterexamples for all these bugs. Categories and Subject Descriptors D.2.5 [Testing \nand Debug\u00adging]: Testing tools (e.g., data generators, coverage testing); D.4.6 [Security and Protection]: \nInformation .ow controls General Terms Security, Languages, Design Keywords random testing; security; \ndesign; dynamic information\u00ad.ow control; noninterference; abstract machine; QuickCheck 1. Introduction \nSecure information-.ow control (IFC) is nearly impossible to achieve by careful design alone. The mechanisms \ninvolved are intricate and easy to get wrong: static type systems must impose numerous constraints that \ninteract with other typing rules in subtle ways, while dynamic mechanisms must appropriately propagate \ntaints and raise security exceptions when necessary. This intricacy makes it hard to be con.dent in the \ncorrectness of such mechanisms without detailed proofs; however, carrying out these proofs while designing \nthe mechanisms can be an exercise in frustration, with a great deal of time spent attempting to verify \nbroken de.nitions! The question we address in this paper is: Can we use modern test\u00ading techniques to \ndiscover bugs in IFC enforcement mechanisms quickly and effectively? If so, then we can use testing to \ncatch most errors during the design phase, postponing proof attempts until we are reasonably con.dent \nthat the design is correct. Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nCopyrights for components of this work owned by others than the author(s) must be honored. Abstracting \nwith credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, \nrequires prior speci.c permission and/or a fee. Request permissions from permissions@acm.org. ICFP 13, \nSeptember 25 27, 2013, Boston, MA, USA. Copyright is held by the owner/author(s). Publication rights \nlicensed to ACM. ACM 978-1-4503-2326-0/13/09. . . $15.00. http://dx.doi.org/10.1145/2500365.2500574 \nTo answer this question, we take as a case study the task of extending a simple abstract stack-and-pointer \nmachine to track dy\u00adnamic information .ow and enforce termination-insensitive nonin\u00adterference [23]. \nAlthough our machine is simple, this exercise is both nontrivial and novel. While simpler notions of \ndynamic taint tracking are well studied for both high-and low-level languages, it has only recently been \nshown [1, 24] that dynamic checks are capable of soundly enforcing strong security properties. Moreover, \nsound dynamic IFC has been studied only in the context of lambda\u00adcalculi [1, 16, 25] and While programs \n[24]; the unstructured con\u00adtrol .ow of a low-level machine poses additional challenges. (Test\u00ading of \nstatic IFC mechanisms is left as future work.) We show how QuickCheck [9], a popular property-based testing \ntool, can be used to formulate and test noninterference properties of our abstract machine, quickly .nd \na variety of missing-taint and missing-exception bugs, and incrementally guide the design of a correct \nversion of the machine. One signi.cant challenge is that both the strategy for generating random programs \nand the precise formulation of the noninterference property have a dramatic im\u00adpact on the time required \nto discover bugs; we benchmark several variations of each to identify the most effective choices. In \nparticu\u00adlar, we observe that checking the unwinding conditions [14] of our noninterference property can \nbe much more effective than directly testing the original property. Our results should be of interest \nboth to researchers in language\u00adbased security, who can now add random testing to their tools for debugging \nsubtle enforcement mechanisms; and to the random\u00adtesting community, where our techniques for generating \nand shrink\u00ading random programs may be useful for checking other properties of abstract machines. Our \nprimary contributions are: (1) a demon\u00adstration of the effectiveness of random testing for discovering \ncoun\u00adterexamples to noninterference in a low-level information-.ow ma\u00adchine; (2) a range of program generation \nstrategies for .nding such counterexamples; (3) an empirical comparison of how effective combinations \nof these strategies and formulations of noninterfer\u00adence are in .nding counterexamples; and (4) an effective \nmethodol\u00adogy for shrinking large counterexamples to smaller, more readable ones. Our information-.ow \nabstract machine, while simple, is also novel, and may be a useful artifact for further research. 2. \nBasic IFC We begin by introducing the core of our abstract machine. In \u00a75 we will extend this simple \ncore with control .ow (jumps and procedure calls), but the presence of pointers already raises opportunities \nfor some subtle mistakes in information-.ow control. We write [ ] for the empty list and x : s for the \nlist whose .rst element is x and whose tail is s; we also write [x0, x1, . . . , xn] for the list x0 \n: x1 : \u00b7 \u00b7 \u00b7 : xn : [ ]. If l is a list and 0 = j < |l|, then l(j) selects the jth element of l and l{j \n. x} produces the list that is like l except that the jth element is replaced by x.  Instr ::= Push \nx | Pop | Load | Store | Add | Noop | Halt The x argument to Push is an integer (an immediate constant). \nA machine state S is a 4-tuple consisting of a program counter pc (an integer), a stack s (a list of \nintegers), a memory m (another list of integers), and an instruction memory i (a list of instructions), \nwritten pc s m i pc s m . Often, i will be .xed in some context and we will write just for the varying \nparts of the machine state. The single-step reduction relation on machine states, written S . S', is \nstraightforward to de.ne; we elide it here, for brevity. (It is included in a longer version of the paper, \navailable from http://www.crash-safe.org/node/24.) This relation is a par\u00ad tial function: it is deterministic, \nbut some machine states don t step to anything. Such a stuck machine state is said to be halted if i(pc) \n= Halt and failed in all other cases (e.g., if the machine is trying to execute an Add with an empty \nstack, or if the pc points outside the bounds of the instruction memory). We write . * for the re.exive, \ntransitive closure of .. When S . * S' and S' is a halted state, we write S . S'. Machine with labeled \ndata In a (.ne-grained) dynamic IFC sys\u00adtem [1, 16, 24, 25] security levels (called labels) are attached \nto runtime values and propagated during execution, enforcing the con\u00adstraint that information derived \nfrom secret data does not leak to untrusted processes or to the public network. Each value is pro\u00adtected \nby an individual IFC label representing a security level (e.g., secret or public). We now add labeled \ndata to our simple stack ma\u00adchine. Instead of bare integers, the basic data items in the instruc\u00adtion \nand data memories and the stack are now values of the form x@L, where x is an integer and L is either \n. (public) or T (secret). We order labels by . . Tand write L1 . L2 for the join (least up\u00adper bound) \nof L1 and L2. When v is a value, we write Lv for v s label part and v@L for the value obtained by joining \nL to Lv i.e., (x@L1)@L2 = x@(L1.L2). The instructions are exactly the same except that the immediate \nargument to Push becomes a value. Machine states have the same shape as the basic machine, with the stack \nand memory now being lists of values. The set of initial states of this machine, Init, contains states \nof the form 0 [ ] m0 i , where m0 can be of any length and contains only 0@.. We use Halted to denote \nthe set of halted states of the machine. Noninterference (EENI) We de.ne what it means for this basic \nIFC machine to be secure using a standard notion of termination\u00adinsensitive noninterference [1, 16, 23]; \nwe call it end-to-end nonin\u00adterference (or EENI) to distinguish it from the stronger notions we will \nintroduce in \u00a76. The main idea of EENI is to directly encode the intuition that secret inputs should \nnot in.uence public outputs. By secret inputs we mean values labeled T in the initial state; be\u00adcause \nof the form of our initial states, such values can appear only in instruction memories. By secret outputs \nwe mean values labeled T in a halted state. More precisely, EENI states that for any two executions starting \nfrom initial states that are indistinguishable to a low observer (or just indistinguishable) and ending \nin halted states H1 and H2, the .nal states H1 and H2 are also indistinguishable. Intuitively, two states \nare indistinguishable if they differ only in values labeled T. To make this formal, we de.ne an equivalence \nrelation on states compositionally from equivalence relations over their components. 2.1 De.nition: Two \nvalues x1@L1 and x2@L2 are said to be indistinguishable, written x1@L1 x2@L2, if either L1 = L2 = T \nor else x1 = x2 and L1 = L2 = .. Two instructions i1 and i2 are indistinguishable if they are the same \ninstruction, or if i1 = Push v1, and i2 = Push v2, and v1 v2. Two lists (memories, stacks, or instruction \nmemories) l1 and l2 are indistinguishable if they have the same length and l1(x) l2(x) for all x such \nthat 0 = x < |l1|. For machine states we have a choice as to how much of the state we want to consider \nobservable; we choose (somewhat arbitrarily) that the observer can only see the data and instruction \nmemories, but not the stack or the pc. (Other choices would give the observer either somewhat more power \ne.g., we could make the stack and pc observable or somewhat less e.g., we could restrict the ob\u00adserver \nto some designated region of I/O memory, or extend the architecture with I/O instructions and only observe \nthe traces of inputs and outputs.) 2.2 De.nition: Machine states S1 = pc1 s1 m1 i1 and S2 = pc2 s2 \nm2 i2 are indistinguishable with respect to memories, written S1 mem S2, if m1 m2 and i1 i2. 2.3 De.nition: \nA machine semantics is end-to-end noninterfering with respect to some sets of states Start and End and \nan indistin\u00adguishability relation , written EENIStart,End, , if for any S1, S2 . Start and H1, H2 . End \nsuch that S1 S2 and such that S1 . H1 and S2 . H2, we have H1 H2. We take EENIInit,Halted, mem as our \nbaseline security property; i.e., we only consider executions starting in initial states and ending in \nhalted states, and we use indistinguishability with respect to memories. The EENI de.nition above is, \nhowever, more general, and we will consider other instantiations of it later. Information-.ow rules Our \nnext task is to enrich the rules for the step function to take information-.ow labels into account. For \nmost of the rules, there are multiple plausible ways to do this, and some opportunities for subtle mistakes \neven with these few instructions. To illustrate the design methodology we hope to support, we .rst propose \na naive set of rules and then use QuickCheck-generated counterexamples to identify and help repair mistakes \nuntil no more can be found. i(pc) = Noop (NO OP) . i(pc) = Push v (PU SH) . i(pc) = Pop (POP) . i(pc \n) = Load (LOAD*) . i(pc) = Store (STO R E *A B) . i(pc) = Add (ADD*) . The NO OP rule is the same \nas in the unlabeled machine. In the PU S H and PO P rules, we simply change the relevant integers to \nbe labeled values; luckily, this obvious adaptation happens to be correct. But now our luck runs out: \nthe simple changes that we ve  [ i = Push 1@., Push 0 1 @T, Store, Halt pc ms i(pc) B; we will discuss \nthem separately later.) Fortunately, QuickCheck [0@., 0@.] [] Push 1@. can rapidly pinpoint the problems, \nas we will see. 0 0 1 Figure 1 shows the .rst counterexample that QuickCheck gives 1 [0@., 0@.] [1@.] \nPush us when we present it with the step function de.ned by the six 0 1 2 rules above and ask it to try \nto invalidate the EENI property. (The 1 0 @., 0 1 @. LATEX source for all the .gures was generated automatically \nby Halt 3 [ ] our QuickCheck testing infrastructure.) The .rst line of the .gure is the counterexample \nitself: a pair of four-instruction programs, differing only in the constant argument of the second Push. \nThe .rst Figure 1. Counterexample to STOR E *A B program pushes 0@T, while the second pushes 1@T, and \nthese [ 0 1 @T, Store, Halt two values are indistinguishable. We display the two programs, and i = Push \n0@., Push the other parts of the two machine states, in a merged format. Pieces of data that are the \nsame between the two machines are written just once; at any place where the two machines differ, the \npc ms i(pc) 0 [0@., 0@.] [] Push 0@. value of the .rst machine is written above the value of the second \nmachine, separated by a horizontal line. The rest of the .gure shows what happens when we run this program. \nOn the .rst step, the pc starts out at 0; the memory, which has two locations, starts out as 0 1 [0@., \n0@.] [0@.] Push [ @T 1 0 1 Store [0@., 0@.] [ @T, 0@. 2 0@ f . , 0@ . f [0@., 0@.]; the stack starts \nout empty; and the next instruction Halt 3 [ ] to be executed (i(pc)) is Push 1@.. On the next step, \nthis value has been pushed on the stack and the next instruction is either Push 0@T or Push 1@T; one \nor the other of these values is pushed Figure 2. Counterexample to STO RE*B on the stack. On the next, \nwe Store the second stack element (1@.) 0 1 @T, Push 0@., Add, Push 0@., Store, into the location pointed \nto by the .rst (either 0@T or 1@T), so Push i = that now the memory contains 1@. in either location 0 \nor location Halt 1 (the other location remains unchanged, and contains 0@.). At this point, both machines \nhalt. This pair of execution sequences Figure 3. Counterexample to AD D* shows that EENI fails: in the \ninitial state, the two programs are indistinguishable to a low observer (their only difference is labeled \nT), but in the .nal states the memories contain different values at i = 0 1 Push 0@., Push 1@., Push \n0@., Store, Push @T, Load, Store, Halt Figure 4. Counterexample to LOA D * the same location, both of \nwhich are labeled .. Thinking about this counterexample, it soon becomes apparent what went wrong with \nthe Store instruction: since pointers labeled T are allowed to vary between the two runs, it is not safe \nto store a low value through a high pointer. One simple but draconian .x is simply to stop the machine \nif it tries to perform such a store so terminates the machine). Adding this side condition brings us \nto a correct version of the STOR E rule.(i.e., we could add the side-condition Lx = . to the rule). A \nmore permissive option is to allow the store to take place, but require it i(pc) = Store Lx Lm(x) (STO \nR E) to taint the stored value with the label on the pointer: . i(pc) = Store (STO R E *B)  . The \nnext counterexample found by QuickCheck (Figure 3) points out a straightforward problem in the ADD* rule: \nadding 0@. to 0@T yields 0@.. (We elide the detailed execution trace for this example and most of the \nones that we will see later, for brevity. They can be found in the long version.) The problem is Unfortunately, \nQuickCheck s next counterexample (Figure 2) shows that this rule is still not quite good enough. This \ncounterex\u00adthat the taints on the arguments to Add are not propagated to its ample is quite similar to \nthe .rst one, but it illustrates a more sub\u00adresult. The Store is needed in order to make the difference \nobserv\u00adtle point: our de.nition of noninterference allows the observer to able. The easy (and standard) \n.x is to use the join of the argument distinguish between .nal memory states that differ only in their \nla\u00adlabels as the label of the result: bels. 1 Since the STO R E*B rule taints the label of the stored \nvalue with the label of the pointer, the fact that the Store changes differ\u00adent locations is visible \nin the fact that a label changes from . to T i(pc) = Add (ADD) on a different memory location in each \nrun. To avoid this issue, we adopt the no sensitive upgrades rule [1, 28], which demands that the label \non the current contents of a memory location being stored into are above the label of the pointer used \nfor the store i.e., it is The .nal counterexample (Figure 4) alerts us to the fact that the LOA D * rule \ncontains a similar mistake to the original STO RE *A B illegal to overwrite a low value via a high pointer \n(and trying to do rule: loading a low value through a high pointer should taint the loaded value. The \nprogram in Figure 4 is a little longer than the one in Figure 1 because it needs to do a little work \nat the beginning 1 See the .rst clause of De.nition 2.1. One might imagine that this could be .xed easily \nby changing the de.nition so that labels are not observable i.e., x@. x@f for any x. Sadly, this is \nknown not to work [22]. to set up a memory state containing two different low values. It (QuickCheck \ncan also .nd a counterexample; see \u00a7A). then pushes a high address pointing to one or the other of those \n cells onto the stack; loads (different, low addresses) through that pointer; and .nally stores 0@. to \nthe resulting address in memory and halts. In this case, we can make the same change to LOAD* as we did \nto STO RE *A B: we taint the loaded value with the join of its label and the address s label. This time \n(unlike the case of Store, where the fact that we were changing the memory gave us additional opportunities \nfor bugs), this change gives us the correct rule for Load, i(pc) = Load pc x@Lx : s m . pc+1 m(x)@Lx \n: s m (LOA D) and QuickCheck is unable to .nd any further counterexamples. More bugs The original IFC \nversion of the step rules illustrate one set of mistakes that we might plausibly have made, but there \nare more possible mistakes: i(pc) = Push x@L (PU S H*) . i(pc) = Store (STO R E *C) . Although it is \nunlikely that we d write these rather silly rules by accident, it is worth including them in our experiments \nbecause they can be invalidated by short counterexamples and thus provide useful data points for less \neffective testing strategies. We will also gather statistics for a partially .xed but still wrong rule \nfor Store, in which the no-sensitive-upgrades check is per\u00adformed but the result is not properly tainted: \ni(pc) = Store Lx Lm(x) (STO RE *A) . 3. QuickCheck We test noninterference using QuickCheck [9], a tool \nthat tests properties expressed in Haskell. Often, QuickCheck is used to test properties that should \nhold for all inhabitants of a certain type. QuickCheck repeatedly generates random values of the desired \ntype, instantiates the property with them, and checks it directly by evaluating it to a boolean. This \nprocess continues until either a counterexample is found or a speci.ed timeout is reached. Quick-Check \nsupplies default test data generators for many standard types. Additionally, the user can supply custom \ngenerators for their own types. In order to test EENI, for example, we needed to de.ne cus\u00adtom generators \nfor values, instructions, and machine states (each of which depends on the previous generator: machine \nstates contain instructions, some of which contain values). The effectiveness of testing (i.e., mean \ntime to discover bugs) depends on the sophisti\u00adcation of these generators, a topic we explore in detail \nin \u00a74. QuickCheck properties may also be guarded by preconditions; EENI is an example of why this is \nnecessary, as it only applies to pairs of indistinguishable initial machine states that both success\u00adfully \nexecute to halted states. Testing a property with a precondi\u00adtion proceeds similarly: a sequence of random \nvalues are generated and tested, up to a user-speci.ed maximum. The difference is that if there is a \nprecondition, it is instantiated with the random value .rst. If the precondition does not hold, this \nrandom value is sum\u00admarily discarded. If the precondition does hold, then the rest of the property is \nchecked just as before. Although preconditions are very useful, too high a proportion of discards can \nlead to slow testing or a badly skewed distribution of test cases (since some kinds of test case may \nbe discarded much more often than others). To help di\u00adagnose such problems, QuickCheck can collect statistics \nabout the tests it tried. When a test fails, the failing test case is often large, containing many irrelevant \ndetails. QuickCheck then tries to shrink the test case, by searching for a similar but smaller test case \nthat also fails. To do this, it greedily explores a number of shrinking candidates : modi.cations of \nthe original failing test case that are smaller in some sense. The property is tested for each of these, \nand as soon as a failure is found, that candidate becomes the starting point for a new shrinking search \n(and the other candidates are discarded). Eventually this process terminates in a failing test case that \nis locally minimal: none of its shrinking candidates fails. This failing case is then reported to the \nuser. It is often very much smaller than the original randomly generated test case, and it is thus easy \nto use it to diagnose the failure because it (hopefully) contains no irrelevant details. Just like generation \nstrategies, shrinking strategies are type dependent; they are de.ned by QuickCheck for standard types, \nand by the user for other types. We discuss the custom shrinking strategies we use for machine states \nin \u00a77. 4. Test Generation Strategies We are ready now to begin exploring ways to generate potential counterexamples. \nAt the outset, we need to address one fundamen\u00adtal issue. Noninterference properties quantify over a \npair of indis\u00adtinguishable starting states: .S1, S2 . Start. S1 S2 =. . . . . This is a very strong \nprecondition, which is unlikely to be satis.ed for independently generated states. Instead, we generate \nindistin\u00adguishable pairs of states together. The .rst state is generated ran\u00addomly using one of the techniques \ndescribed later in this section. The second is obtained by randomly varying the high parts of the .rst. \nWe refer to the second state as the variation of the .rst. The re\u00adsulting pair thus satis.es indistinguishability \nby construction. Note that we have not compromised completeness: by generating a ran\u00addom state and randomly \nvarying we still guarantee that it is pos\u00adsible to generate all pairs of indistinguishable states. Naturally, \nthe resulting distributions will depend on the speci.cs of the generation and variation methods used, \nas we shall see. Since EENI considers only executions that start at initial states, we only need to randomly \ngenerate the contents of the instruction memory (the program that the machine executes) together with \nthe size of the data memory (in initial states, the contents of the memory are .xed and the stack is \nguaranteed to be empty). Figure 5 offers an empirical comparison of all the generation strategies described \nin this section. For a given test-generation strategy, we inject bugs one at a time into the machine \nde.nition and measure the time spent on average until that bug is found (mean time to failure, or MTTF). \nTests were run one at a time on seven identical machines, each with 4\u00d7 2.4 GHz Intel processors and 11.7 \nGB of RAM; they were running Fedora 16 and GHC 7.4.2, and using QuickCheck 2.5.1.1. We run each test \nfor 5 minutes (300 seconds) or until 4000 counterexamples are found, whichever comes .rst. Naive instruction \ngeneration The simplest way to generate pro\u00adgrams is by choosing a sequence of instructions independently \nand uniformly. We generate individual instructions by selecting an in\u00adstruction type uniformly (i.e., \nNoop, Push, etc.) and then .lling in its .elds using QuickCheck s built-in generators. Labels are also \nchosen uniformly. We then build the instruction memory by sam\u00adpling a number (currently a random number \nbetween 20 and 50) of instructions from this generator. The .rst column of Figure 5 shows how this strategy \nperforms on the bugs from \u00a72. Disappointingly, but perhaps not too surpris\u00ad  Generation strategy NAI \nV E WE I GHTE D SE QU E N CE SE QU E N CE BYEX E C Smart integers? NO NO NO YE S YE S AD D * 83247.01 \n5344.26 561.58 30.05 0.87 PU SH* 3552.54 309.20 0.21 0.07 0.01 LOAD*  73115.63 2258.93 4.03 STO RE*A \n 38036.22 32227.10 1233.51 STO RE*B 47365.97 1713.72 0.85 0.12 0.25 STO RE*C 7660.07 426.11 0.41 0.31 \n0.02 MTTF arithmetic mean  18619.15 5752.76 206.45 MTTF geometric mean  69.73 13.33 0.77 Average \ntests / second 24129 11466 8541 7915 3284 Average discard rate 79% 62% 65% 59% 4% Figure 5. Comparison \nof generation strategies for the basic machine. The .rst part of the table shows the mean time to .nd \na failing test case (MTTF) in milliseconds for each bug. The second part lists the arithmetic and geometric \nmean for the MTTF over all bugs. The third part shows the number of tests per second and the proportion \nof test cases that were discarded because they did not satisfy some precondition. Average number of execution \nsteps: 0.47. 74% stack under.ow, 21% halt, and 4% load or store out of range. Figure 6. Execution statistics \nfor naive instruction generation. Ex\u00adecutions fail early, and the main reason for failure is stack under\u00ad.ow. \nAverage number of execution steps: 2.69. 38% halt, 35% stack under.ow, and 25% load or store out of range. \n Figure 7. Execution statistics when generating instructions with a weighted distribution. The main reason \nfor failure is now Halt, followed by stack under.ow. ingly, naive instruction generation can only .nd \nfour of the six bugs within 5 minutes. How can we do better? One obvious weakness is that the discard \nrate is quite high, indicating that one or both machines often fail to reach a halted state. By asking \nQuickCheck to collect statistics on the execution traces of test cases (Figure 6), we can also see a \nsecond problem: the average execution length is only 0.46 steps! Such short runs are not useful for .nding \ncounterexamples to EENI (at a minimum, any counterexample must include a Store instruction to put bad \nvalues into the memory and a Halt so that the run terminates, plus whatever other instructions are needed \nto produce the bad values). So our next step is to vary the distribution of instructions so as to generate \nprograms that run for longer and thus have a chance to get into more interesting states. Weighted distribution \non instructions Figure 6 shows that by far the most common reason for early termination is a stack under.ow. \nAfter a bit of thought, this makes perfect sense: the stack is initially empty, so if the .rst instruction \nthat we generate is anything but a Push, Halt, or Noop, we will fail immediately. Instead of a uniform \ndistribution on instructions, we can do better by increasing the weights of Push and Halt Push to reduce \nthe number of stack under.ows, and Halt because each execution must reach a halted state to satisfy EENI \ns precondition. The results after this change shown in the second column of Figure 5. Although this strategy \nstill performs badly for the LOA D * and STO R E*A bugs, there is a signi.cant improvement on both discard \nrates and the MTTF. Run length is also better, averaging 2.71 steps. As Figure 7 shows, executing Halt \nis now the main reason for termination, with stack under.ows and out-of-range accesses close behind. \nAverage number of execution steps: 3.86. 37% halt, 28% load or store out of range, 20% stack under.ow, \nand 13% sensitive upgrade. Figure 8. Execution statistics when generating sequences of in\u00adstructions. \nOut-of-range addresses are now the biggest reason for termination. Average number of execution steps: \n4.22. 41% halt, 21% stack under.ow, 21% load or store out of range, and 15% sensitive upgrade. Figure \n9. Execution statistics when using smart integers with sequences of instructions. The percentage of address \nout of range errors has halved. Generating useful instruction sequences more often To further reduce \nstack under.ows we can generate sequences of instructions that make sense together. For instance, instead \nof generating single Store instructions, we can additionally generate sequences of the form [Push a, \nStore] (where a is a valid address), and similarly for other instructions that use stack elements. The \nresults are shown in the third column of Figure 5. With sequence generation we can now .nd all bugs, \nfaster than before. Programs run for slightly longer (3.87). As expected, stack under.ows are less common \nthan before (Figure 8) and out-of-range addresses are now the second biggest reason for termination. \nSmart integers: generating addresses more often To reduce the number of errors caused by out-of-range \naddresses, we can give preference to valid memory addresses, i.e., integers within memory bounds, when \ngenerating values. We do this not only when gener\u00adating the state of the .rst machine, but also when \nvarying it, since both machines need to halt successfully in order to satisfy the pre\u00adcondition of EENI. \nColumn four of Figure 5 shows the results after making this improvement to the previous generator. We \nsee an im\u00adprovement on the MTTF. The average run length is now 4.23 steps, and the percentage of address-out-of-range \nerrors is decreased. Generation by execution We can go even further. In addition to weighted distributions, \nsequences, and smart integers, we try to generate instructions that do not cause a crash. In general \n(for more interesting machines) deciding whether an arbitrary instruction se\u00adquence causes a crash is \nundecidable. In particular we cannot know in advance all possible states in which an instruction will \nbe ex\u00adecuted. We can only make a guess a very accurate one for this simple machine. This leads us to \nthe following generation by execu\u00ad  Push 1@., Push 4 6 @T, Jump, Halt, Push 0@., Store, Push 3@., Jump \n1% halt / sensitive upgrade. pc ms i(pc) Figure 10. Execution statistics for generation by execution, \nbro\u00adken down for the variations. 0@. [0@.] [ ] Push 1@. 4 6 1@. [0@.] [1@.] Push @T [ Halt Machine 1 \ncontinues. . . Figure 11. Counterexample to JU M P *A B: A textbook example of 4@T [0@.] [1@.] Push 0@. \n4 2 Jump 2@. [0@.] @T, 1@. Push @T, Jump, Push 1@., Push 0@., Store, 6 i = 5 5@T [0@.] [0@., 1@.] Store \nan implicit .ow tion strategy: We generate a single instruction or a small sequence 6@T [1@.] [] Push \n3@. 7@T [1@.] [3@.] Jump 3@. [1@.] [] Halt of instructions, as before, except that now we restrict generation \nto instructions that do not cause the machine to crash in the current state. When we .nd one, we execute \nit to reach a new state and then repeat the process to generate further instructions. We con\u00adtinue until \nwe have generated a reasonably sized instruction stream (currently, randomly chosen between 20 50 instructions). \nWe dis\u00adcuss how this idea generalizes to machines with nontrivial control .ow in \u00a75. As we generate more \ninstructions, we make sure to increase the probability of generating a Halt instruction, to reduce the \nchances of the machine running off the end of the instruction stream. As a result, (i) we maintain low \ndiscard ratios for EENI since we in\u00adcrease the probability that executions .nish with a Halt instruction, \nand (ii) we avoid extremely long executions whose long time to generate and run could be more fruitfully \nused for other test cases. The MTTF (last column of Figure 5) is now signi.cantly lower than in any previous \ngeneration method, although this strategy runs fewer tests per second than the previous ones (because \nboth test case generation and execution take longer). Figure 10 shows that Machine 2 continues. . . 6@T \n[0@.] [1@.] Push 3@. 7@T [0@.] [3@., 1@.] Jump 3@. [0@.] [1@.] Halt Figure 12. Counterexample to JU M \nP *B: Jump should not lower the pc label one does a Store to a low location and only then halts, causing \nthe .nal memories to be distinguishable. The standard way to prevent implicit .ows is to label the pc \ni.e., to make it a value, not a bare integer. Initial states have pc = 0@., and after a jump to a secret \naddress the label of the pc becomes T: i(pc) = Jump (JU M P *B) pc x@Lx : s m . x@Lx s m 94% of the \npairs both successfully halt, which is in line with the very low discard rate of Figure 5, and that programs \nrun for much longer. Happily, varying a machine that successfully halts has a high probability of generating \na machine that also halts. 5. Control Flow Up to this point, we ve seen how varying the program genera\u00ad \ntion strategy can make orders-of-magnitude difference in the speed While the pc is high, the two machines \nmay be executing different instructions, and so we cannot expect the machine states to corre\u00adspond. We \ntherefore extend the de.nition of mem so that all high machine states are deemed equivalent. (We call \na state high if the pc is labeled T, and low otherwise.) 5.1 De.nition: Machine states S1 = pc1 s1 m1 \ni1 and S2 = pc2 s2 m2 i2 are indistinguishable with respect to memories, written S1 mem S2, if either \nLpc1 = Lpc2 = T or else at which counterexamples are found for a very simple almost Lpc1 = Lpc2 = . and \nm1 m2 and i1 i2. The JU MP*B rule is still wrong, however, since it not only raises the pc label when \njumping to a high address but also lowers it when jumping to a low address. The counterexample in Figure \n12 illustrates that the latter behavior is problematic. The .x is to label the pc after a jump with the \njoin of the current pc label and the label of the target address. trivial information-.ow machine. Now \nwe are ready to make the machine more interesting and see how these techniques perform on the new bugs \nthat arise, as well as how their performance changes on the bugs we ve already seen. In this section, \nwe add Jump, Call, and Return instructions and, with them, the possibility that infor\u00ad mation can leak \nvia the program s control .ow. Jumps, implicit .ows, and the pc label We .rst add a new Jump instruction \nthat takes the .rst element from the stack and sets the i(pc) = Jump pc to that address: (JU MP) pc x@Lx \n: s m . x@(Lx . Lpc ) s m i(pc) = Jump (JUM P *A B) . (The jump target may be an invalid address. In \nthis case, the ma\u00adchine will be stuck on the next instruction.) Note that this rule simply ignores the \nlabel on the jump target on the stack. This is unsound, and QuickCheck easily .nds the coun\u00adterexample \nin Figure 11 a textbook case of an implicit .ow [23]. A secret is used as the target of a jump, which \ncauses the instruc\u00adtions that are executed afterwards to differ between the two ma\u00adchines; one of the \nmachines halts immediately, whereas the other With this rule for jumps QuickCheck no longer .nds any \ncoun\u00adterexamples. Some readers may .nd this odd: In order to fully address implicit .ows, it is usually \nnecessary to modify the rules for memory stores to handle the case where the pc is labeled high [1, 22]. \nThe current machine doesn t require this, but the rea\u00ad son is subtle: here, the pc can go from . to T \nwhen we jump to a secret address, but it never goes from T to .! It doesn t matter what the machine does \nwhen the pc is high, because none of its actions will ever be observable all high machine states are \nindis\u00adtinguishable.  3 6 @T, Call 0, Halt, Push 1@., Push 0@., i = Store, Return 0 it has become T. \nOne way to achieve this is to add Call and Return instructions, a task we turn to next. Figure 13. Counterexample \nto old STO RE rule in the presence of Call and Return: Raising pc label is not enough to prevent implicit \n.ows. Once we have a mechanism (like Return) for restoring the Restoring the pc label with calls and \nreturns IFC systems (both static and dynamic) generally rely on control .ow merge points (i.e., post-dominators \nof the branch point in the control .ow graph where the control was tainted by a secret) to detect when \nthe in.uence of secrets on control .ow is no longer relevant and the pc label, we need to be more careful \nabout stores in high contexts. Push 1@., Push 7 6 @T, Call 1, Push 0@., Store, Halt, Push 0@., Return \n1 pc label can safely be restored. Control .ow merge points are, i = however, much more evident for \nstructured control features such as conditionals than they are for jumps. Moreover, since we are doing \npurely dynamic IFC we cannot distinguish between safe uses Figure 14. Counterexample to RE T U RN *A \nB: Return needs to taint the returned values. of jumps and unsafe ones (e.g., the one in Figure 12). \nSo we keep jumps as they are (only raising the pc label) and add support for structured programming \nand restoring the pc label in the form of i = Call and Return instructions, which are of course useful \nin their Push 0@., Push 6 7 @T, Call 0, Push 0@., Store, Halt, Return 0, Push 0@., Return 1 own right. \nTo support these instructions, we need some way of represent\u00ading stack frames. We choose a straightforward \nrepresentation, in which each stack element can now be either a value (as before) or a return address, \nmarked R, recording the pc (including its la\u00adbel!) from which the corresponding Call was made. We also \nex\u00adtend the indistinguishability relation on stack elements so that re\u00adturn addresses are only equivalent \nto other return addresses and R(x1@L1) R(x2@L2) if either L1 = L2 = T or else x1 = x2 and L1 = L2 = \n. (this is the same as for values).2 We also need a way to pass arguments to and return results from \na called procedure. For this, we annotate the Call and Return in\u00adstructions with an integer indicating \nhow many stack values should be passed or returned (0 or 1 in the case of Return). Formally, Call n expects \nan address x@Lx followed by n values on the stack. It sets the pc to x, labels this new pc by the join \nof Lx and the current pc label (as we did for Jump we re eliding the step of getting this bit wrong at \n.rst and letting QuickCheck .nd a counterexample), and adds the return address frame to the stack under \nthe n arguments. Figure 15. Counterexample to CAL L *B and RE T U R N*B: It is unsound to choose how \nmany results to return on Return. another instance of the implicit .ow bug, which is not surprising given \nthe discussion at the end of the previous subsection. We need to change the rule for Store so that the \nnew memory contents are tainted with the current pc label. This eliminates the current coun\u00adterexample; \nQuickCheck then .nds a very similar one in which the labels of values in the memories differ between \nthe two machines. The usual way to prevent this problem is to extend the no-sensitive\u00adupgrades check \nso that low-labeled data cannot be overwritten in a high context [1, 28]. This leads to the correct rule \nfor stores: i(pc) = Store Lpc . Lx Lm(x) (STO R E) pc x@Lx : y@Ly : s m . pc +1 s m{x . y@(Lx.Ly.Lpc \n)} The next counterexample found by QuickCheck (Figure 14) i(pc) = Call n L = Lx . Lpc shows that returning \nvalues from a high context to a low one is xpc @Lpc x@Lx : v1 : . . . : vn : s m . x@L v1 : . . . : vn \n: R(xpc +1@Lpc ) : s m (CAL L *B) unsound if we do not label those values as secrets. To .x this, we \ntaint all the returned values with the pre-return pc label. '' ' i(pc) = Return n n . {0, 1} k = n (RETUR \nN *B) Return n ' traverses the stack until it .nds the .rst return address and jumps to it. Moreover \nit restores the pc label to the label stored in that R entry, and preserves the .rst n ' elements on \nthe stack as return values, discarding all other elements in this stack frame. pc v1 : . . . : vk : R(x@Lx) \n: s m x@Lx v1@Lpc : . . . : vn! @Lpc : s . m The next counterexample, listed in Figure 15, shows (maybe \n'' ' i(pc) = Return n n . {0, 1} k = n somewhat surprisingly) that it is unsound to specify the number \nof results to return in the Return instruction, because then the number (RE T U R N *A B) pc v1 : . . \n. : vk : R(x@Lx) : s m x@Lx v1 : . . . : vn! : s m . of results returned may depend on secret .ows of \ncontrol. To restore soundness, we need to pre-declare at each Call whether the corresponding Return will \nreturn a value i.e., the Call instruction should be annotated with two integers, one for parameters and \nthe other for results; accordingly, each stack frame should include not only a return address but also \na number of return values. These changes lead us to the correct rules: Finally, we observe that we cannot \nexpect the current EENI instantiation to hold for this changed machine, since now one machine can halt \nin a high state while the other can continue, return to a low state, and only then halt. Since we cannot \nequate high and low states (see \u00a7A), we need to change the EENI instance we use to EENIInit,HaltednLow, \nmem , where Low denotes the set of states i(pc ) = Call n n ' n ' . {0, 1} L = Lx . Lpc (CA L L) with \npc = .. Thus, we only consider executions that end in a low halting state. After these changes, we can \nturn QuickCheck loose and start xpc @Lpc x@Lx : v1 : . . . : vn : s m . x@L v1 : . . . : vn : R(xpc +1, \nn ' )@Lpc : s m .nding more bugs. The .rst one, listed in Figure 13, is essentially i(pc) = Return k \n= n ' 2 High return addresses and high values need to be distinguishable to a low observer, as we discovered \nwhen QuickCheck generated an unexpected counterexample (which we list in \u00a7A).  . . 9 Return Figure 16. \nCounterexample to PO P*: It is unsound not to protect the call stack. The .nal counterexample found by \nQuickCheck is quite a bit longer (see Figure 16). It shows that we cannot allow instructions like Pop \nto remove return addresses from the stack, as does the following broken rule (we use e to denote an arbitrary \nstack entry): i(pc) = Pop (PO P*) . To protect the call frames on the stack, we change this rule to \nonly pop values (all the other rules can already only operate on values). i(pc) = Pop (PO P) . Generation \nby execution and control .ow Generation by execu\u00adtion is still applicable in the presence of interesting \ncontrol .ow but we have to make small modi.cations to the original algorithm. We still generate a single \ninstruction or sequence that does not crash, as before, and we execute to compute a new state. However, \nun\u00adlike before, while executing this newly generated sequence of in\u00adstructions, it is possible to land \nin a position in the instruction stream where we have already generated an instruction. (e.g. via a backward \njump): If this happens then we keep executing the al\u00adready generated instructions. If the machine stops \n(or we reach a loop-avoiding cutoff) then we stop the process and return the so-far generated instruction \nstream. If there are no more instructions to execute then we go on to generate more instructions. There \nis one more possibility though: the machine may crashes while executing an already generated instruction. \nTo address this issue, we make sure that we never generate an instruction that causes the machine to \ncrash in a number of steps. We refer to this number of steps as the lookahead parameter and in our experiments \nwe use a looka\u00adhead of just 2 steps. If we cannot generate such an instruction, we retry with a smaller \nlookahead, until we succeed. Since it now becomes possible to generate instruction streams that cause \nthe machine to crash in some number of steps, one might be worried about the discard ratio for EENI. \nHowever, the ever increasing probability of generating a Halt (discussed in \u00a74) counterbalances this \nissue. Finding the bugs We experimentally evaluated the effectiveness of testing for this new version \nof the machine, by adding the bugs discussed in this section to the ones applicable for the previous \nmachine. The results of generation by execution with lookahead for this machine are shown in the .rst \ncolumn of Figure 17. As we can see, all old bugs are still found relatively fast. It takes slightly longer \nto .nd them when compared to the previous machine, but this is to be expected: when we extend the machine, \nwe are also increasing the state space to be explored. The new control-.ow\u00adspeci.c bugs are all found, \nwith the exception of POP*. Discard rates are much higher compared to generation by execution in Figure \n5, for two reasons. First, control .ow can cause loops, so we discard machines that run for more than \n50 steps without halting.3 Second, as described previously, generation by execution in the presence of \ncontrol .ow is much less accurate. 3 Detailed pro.ling revealed that 18% of the pairs of machines both \nloop, and loopy machines push the average number of execution steps to 22. Alternative generation strategies \nGeneration by execution has proved to be simple to implement and effective in .nding bugs. Even this \nmethod, however, required some tuning, driven by ex\u00adperimental evaluation. For instance, our .rst implementations \ndid not involve increasing probabilities of Halt instructions. We also experimented with different lookahead \nvalues. Larger lookaheads introduce signi.cant overheads in generation as every generated instruction \ncosts many steps of execution, and the payoff of lower discard rates was not worth the increased generation \ncost. We have also explored (and dismissed) several other generation strategies, and we outline two of \nthese below: Generation by forward execution. Generation by execution .lls in the instruction stream \nin patches, due to generated jumps. It is hence possible for the instruction stream to contain holes \nwith Noop instructions. An alternative strategy is to generate instructions in a forward style only: \nif we generate a branch then we save the current state along with the branch target, but keep generating \ninstructions as if the branch was not taken. If we ever reach the target of the branch we may use the \nsaved state as a potentially more accurate state that we can use to generate more instructions. This \nstrategy delivered similar results as generation by execution, but due to its more complicated nature \nwe dismissed it and used the basic design instead.  Variational generation by execution. In this design, \nwe .rst gen\u00aderate a machine with generation by execution. We then vary the machine and run generation \nby execution for the resulting machine, in the hope that we can .ll in the holes in the origi\u00adnally generated \ninstruction stream with instructions from a vari\u00adational execution. As before, we did not .nd that the \nresults jus\u00adti.ed the generation overheads and complexity of this strategy.  6. Strengthening the Tested \nProperty The last few counterexamples in \u00a75 are fairly long and quite dif\u00ad.cult for QuickCheck to .nd, \neven with the best test-generation strategy. In this section we explore a different approach: strength\u00adening \nthe property we are testing so that counterexamples become shorter and easier to .nd. Figure 17 summarizes \nthe variants of non\u00adinterference that we consider and how they affect test performance. Making entire \nlow states observable Every counterexample that we ve seen involves pushing an address, executing a Store \ninstruc\u00adtion, and halting. These steps are all necessary because of the choice we made in \u00a72 to ignore \nthe stack when de.ning indistin\u00adguishability on machine states. A counterexample that leaks a se\u00adcret \nonto the stack must continue by storing it into memory; simi\u00adlarly, a counterexample that leaks a secret \ninto the pc must execute Store at least twice. This suggests that we can get shorter coun\u00adterexamples \nby rede.ning indistinguishability as follows: 6.1 De.nition: Machine states S1 = pc1 s1 m1 i1 and S2 \n= pc2 s2 m2 i2 are indistinguishable with respect to entire low states, written S1 low S2, if either \nLpc1 = Lpc2 = T or else Lpc1 = Lpc2 = ., m1 m2, i1 i2, s1 s2, and pc1 pc2. We now strengthen EENIInit,HaltednLow, \nmem , the property we have been testing, to EENIInit,HaltednLow, low ; this is stronger be\u00adcause mem \nand low agree on initial states, while for halted states low . mem . Indeed, for this stronger property, \nQuickCheck .nds bugs faster (compare the .rst two columns of Figure 17). Quasi-initial states Many counterexamples \nbegin by pushing val\u00adues onto the stack and storing values into memory. This is nec\u00adessary because each \ntest starts with an empty stack and low, ze\u00adroed memory. We can make counterexamples easier to .nd by \nal\u00adlowing the two machines to start with arbitrary (indistinguishable)  Tested property Starting states \nEquivalence relation Generation strategy EENI Init mem BYEX EC2 EENI Init low BYEXE C2 EENI QInit low \nBYEX E C2 LLNI QInit low BYEXEC2 SSNI All full NA I V E SSNI All full TINY SSNI AD D* PU S H * LOA D \n* STOR E *A STOR E *B STOR E *C JU M P*A JU M P*B STOR E *D STOR E *E CAL L *A RE T U RN*A CAL L *B+RE \nTUR N *B PO P * 37.07 0.22 155.07 20018.67 13.02 0.35 48.84 2421.99 13289.39 1047.56 3919.08 12804.51 \n69081.50 2.38 0.02 37.50 18658.56 12.87 0.34 7.58 158.36 12295.65 1129.48 174.66 4698.17 6940.67 51753.13 \n1.38 0.02 5.73 124.78 16.10 0.33 5.26 104.62 873.79 717.72 115.15 1490.80 1811.66 16107.22 0.36 0.01 \n1.14 84.08 5.25 0.08 0.08 2.80 232.19 177.75 5.97 337.74 396.37 1828.56 0.24 1.06 3.25 289.63 31.11 0.73 \n1.45 16.88 8.77 2.26 31.71 1110.09 1194.30 30.68 0.11 0.06 0.61 16.32 0.33 0.03 0.09 0.49 1.13 0.29 0.62 \n3.10 4.56 0.42 MTTF arithmetic mean MTTF geometric mean  6847.81 135.76 1526.75 46.48 219.46 7.69 194.44 \n12.87 2.01 0.47 Average tests / second Average discard rate 2795 65% 2797 65% 2391 69% 1224 0% 8490 40% \n18407 9% Figure 17. Experiments for control .ow machine. MTTF given in milliseconds.  stacks and memories; \nwe call such states quasi-initial. Formally, the set QInit of quasi-initial states contains all states \nof the form 0@. s m i , for arbitrary s, m, and i. The advantage of generating more varied start states \nis that parts of the state space may be dif.cult to reach by running generated code from an initial state; \nfor example, to get two return addresses on the stack, we must successfully execute two Call instructions. \nThus, bugs that are only manifested in these hard-to-reach states may be discovered very slowly or not \nat all. Generating interme\u00addiate states directly gives us better control over their distribution, which \ncan help eliminate such blind spots in testing. The disadvan\u00adtage of this approach is that a quasi-initial \nstate may not be reach\u00adable from any initial state, so in principle QuickCheck may report spurious counterexamples \nthat cannot actually arise in a real execu\u00adtion. For example, a quasi-initial state may have a non-zero \nvalue in memory, even though the program contains no Store instruction that could have written it. In \ngeneral, we could address such prob\u00adlems by carefully formulating the important invariants of reachable \nstates and ensuring that we generate quasi-initial states satisfying them. In practice, though, we have \nnot encountered any spurious counterexamples for our machine, even with quasi-initial states. Instantiating \nEENI with QInit, we obtain a stronger property EENIQInit,HaltednLow, low (stronger because Init . QInit) \nthat does indeed .nd bugs faster, as column 3 of Figure 17 shows. LLNI: Low-lockstep noninterference \nWhile making the full state observable and starting from quasi-initial states signi.cantly improves EENI, \nwe can get even better results by moving to a yet stronger noninterference property. The intuition is \nthat EENI generates machines and runs them for a long time, but it only com\u00adpares the .nal states, and \nonly when both machines successfully halt; these preconditions lead to rather large discard rates. Why \nnot compare intermediate states as well, and report a bug as soon as in\u00adtermediate states are distinguishable? \nWhile the pc is high, the two machines may be executing different instructions, so their states will \nnaturally differ; we therefore ignore these states and require only that low execution states are pointwise \nindistinguishable. We call this new property low-lockstep noninterference (or LLNI). The function trace \nS computes the (possibly in.nite) list of states obtained by executing our machine starting from state \nS. This is a function because our machine is deterministic. [S] if S is stuck 6.2 De.nition: trace \nS = S : trace S ' if S . S ' While, in practice, we test LLNI over .nite pre.xes of traces, the de.nition \nbelow is also valid for potentially in.nite traces. 6.3 De.nition: A machine semantics is low-lockstep \nnoninter\u00adfering with respect to the indistinguishability relation (written LLNI ) if, for any quasi-initial \nstates S1 and S2 with S1 S2, we have trace S1 * trace S2, where * is de.ned coinductively by the following \nrules: S1, S2 . Low S1 S2 t1 * (S1 : t1) * (S2 : t2) t2 (LOW LO CK S TEP) S1 . Low t1 * (S1 : t1) \n * t2 t2 (HIG H FI LT E R) [ ] * [ ] (LO CKSTE P END) S1 . Low [S1] * t2 (HI G H END) S1 . Low S1 . \nHalted [S1] * (S2 : t2) S1 S2 (LOW ER RO R END) t1 * t2 * t2 t1 (SY M ME T RY) The rule LOW LO C \nK S T EP requires low states in the two traces to be pointwise indistinguishable, while HIG H FILTE R \n(together with SY M ME T RY) simply .lters out high states from either trace. The re\u00admaining rules are \nabout termination: because we are working with termination-insensitive noninterference, we allow one \nof the traces to continue (maybe forever) even if the other has terminated in a state that is not low \n(HIGH EN D) or not halted (LOW ERROR EN D).  Additionally, we allow the two traces to terminate simultaneously \n(LO C KSTE P EN D). We implement these rules in Haskell as a recur\u00adsive predicate over lazy lists. In \ngeneral, LLNI implies EENI, but not vice versa. However, the correct version of our machine does satisfy \nLLNI, and we have not observed any cases where QuickChecking a buggy machine with LLNI .nds a bug that \nis not also a bug with regard to EENI. Test\u00ading LLNI instead of EENI leads to signi.cant improvement \nin the bug detection rate for all bugs, as the results in the fourth column Figure 17 show. In these \nexperiments no generated machine states are discarded, since LLNI applies to both successful (halting) \nexe\u00adcutions and failing or in.nite executions. The generation strategies described in \u00a74 also apply to \nLLNI without much change; also, as for EENI, generation by execution (with lookahead of 2 steps) per\u00adforms \nbetter than the more basic strategies, so we don t consider those for LLNI. SSNI: Single-step noninterference \nUntil now, we have focused on using sophisticated (and potentially slow) techniques for gener\u00adating long-running \nmachine states, and then checking equivalence for low halting states (EENI) or at every low step (LLNI). \nAn alter\u00adnative is to de.ne a stronger property that talks about all possible single steps of execution \nstarting from two indistinguishable states. Proofs of noninterference usually go by induction on a pair \nof execution traces; to preserve the corresponding invariant, the proof needs to consider how each execution \nstep affects the indistin\u00adguishability relation. This gives rise to properties known as un\u00adwinding conditions \n[14]; the corresponding conditions for our ma\u00ad chine form a property we call single-step noninterference \n(SSNI). We start by observing that LLNI implies that, if two low states are indistinguishable and each \ntakes a step to another low state, then the resulting states are also indistinguishable. However, this \nalone is not a strong enough invariant to guarantee the indistinguishability of whole traces. In particular, \nif the two machines perform a Return from a high state to a low state, we would need to conclude that \nthe two low states are equivalent without knowing anything about the original high states. This indicates \nthat, for SSNI, we can no longer consider all high states indistinguishable. The indistinguishability \nrelation on high states needs to be strong enough to ensure that when both machines return to low states, \nthose low states are also indistinguishable. Moreover, we need to ensure that if one of the machines \ntakes a step from a high state to another high state, then the old and new high states are equivalent. \nThe following de.nition captures all these constraints formally; we write SL for a machine state whose \npc label is L. 6.4 De.nition: A machine semantics is single-step noninterfering with respect to the indistinguishability \nrelation (written SSNI ) if the following four conditions are all satis.ed: 1. For all low states S1 \n. and S2 ., if S1 . S2 . , S1 . . S1, and S2 . . S2, then S1 S2; 2. For all high states S[ with S[ \n. S [, we have S[ S [; 3. For all high states S1[and S2[, if S1[ S2[, S1[. S1 . , S2[. S2 ., and states \nS1 . and S2 . are low, then S1 . S2 .; 4. For all low states S1 . and S2 ., if S1 . S2 . and S1 . \nis halted, then S2 . is stuck.  Note that SSNI talks about completely arbitrary states, not just (quasi-)initial \nones. The de.nition of SSNI is parametric in the indistinguishability relation used, and it can take \nsome work to .nd the right relation. As discussed above, low is too weak and QuickCheck can easily .nd \ncounterexamples to condition 3, e.g., by choosing two indis\u00ad tinguishable machine states with i = [Return], \npc = 0@T, and [ 0 s = R( 1 , 0)@. ; after a single step the two machines have dis\u00adtinguishable pcs 0@. \nand 1@., respectively. On the other hand, treating high states exactly like low states in the indistinguishability \nrelation is too strong. In this case QuickCheck .nds counterexam\u00ad t m ples to condition 2, e.g., a single \nmachine state with i = Pop , pc = 0@T, and s = [0@.] steps to a state with s = [], which would not be \nconsidered indistinguishable. These counterexamples show that indistinguishable high states can have \ndifferent pcs and can have completely different stack frames at the top of the stack. So all we can require \nfor two high states to be equivalent is that their memories and instruction memories agree and that the \nparts of the stacks below the topmost low return address are equivalent. This is strong enough to ensure \ncondition 3.  6.5 De.nition: Machine states S1 = pc1 s1 m1 i1 and S2 = pc2 s2 m2 i2 are indistinguishable \nwith respect to whole ma\u00adchine states, written S1 full S2, if m1 m2, i1 i2, Lpc1 = Lpc2 , and additionally \n if Lpc1 = . then s1 s2 and pc1 pc2, and  if Lpc1 = T then cropStack s1 cropStack s2.  The cropStack \nhelper function takes a stack and removes elements from the top until it reaches the .rst low return \naddress (or until all elements are removed). The .fth column of Figure 17 shows that, even with arbitrary \nstarting states generated completely naively, SSNI full performs very well. If we tweak the weights a \nbit and additionally observe that since we only execute the generated machine for only one step, we can \nbegin with very small states (e.g., the instruction memory can be of size 2), then we can .nd all bugs \nvery quickly. As the last column of Figure 17 illustrates, each bug is found in under 20 milliseconds. \n(This last optimization is a bit risky, since we need to make sure that these very small states are still \nlarge enough to exercise all bugs we might have e.g., an instruction memory of size 1 is not enough to \nexhibit the CALL *B+RE T U R N*B bug using SSNI.) Compared to other properties, QuickCheck executes many \nmore tests per second with SSNI for both generation strategies. Discussion In this section we have seen \nthat strengthening the noninterference property is a very effective way of improving the effectiveness \nof random testing our IFC machine. It is not without costs, though. Changing the security property required \nsome exper\u00adtise and, in the case of LLNI and SSNI, manual proofs showing that the new property implies \nEENI, the baseline security property. In the case of SSNI we used additional invariants of our machine \n(cap\u00adtured by full ) and .nding these invariants would probably consti\u00adtute the most creative part of \ndoing a full security proof. While we could use the counterexamples provided by QuickCheck to guide our \nsearch for the right invariants, we expect that for more realistic machines the process of interpreting \nthe counterexamples and man\u00adually re.ning the invariants will be signi.cantly harder than for our very \nsimple machine. The potential users of our techniques will have to choose a point in the continuum between \ntesting and proving that best matches the characteristics of their practical application. At one end, \nwe present ways of testing the original EENI property without changing it in any way, by putting all \nthe smarts in clever generation strategies. At the other end, one can imagine using random testing just \nas the .rst step towards a full proof of a stronger property such as SSNI. For our simple machine, Azevedo \nde Amorim et al. [2] did in fact prove recently in Coq that SSNI holds, and did not .nd any bugs that \nhad escaped our testing. Moreover, we proved in Coq that for any deterministic machine and for any indistinguishability \nrelation that is an equivalence, SSNI implies LLNI and LLNI implies EENI.  7. Shrinking Strategies The \ncounterexamples presented in this paper are not the initial ran\u00addomly generated tests; they are the result \nof QuickCheck shrink\u00ading these to minimal examples. For example, randomly generated counterexamples to \nEENI for the PU S H * bug usually consist of 20 40 instructions; the minimal counterexample uses just \nfour. In this section we describe the shrinking strategies we used. Shrinking labeled values, instructions, \nand stack elements By default, QuickCheck already implements a shrinking strategy for integers. For labels, \nwe shrink T to ., because we prefer to see counterexamples in which labels are only T if this is essential \nto the failure. Values are shrunk by shrinking either the label or the contents. (If we need to shrink \nboth the label and the contents, then this is achieved in two separate shrinking steps.) We allow any \ninstruction to shrink to Noop, which preserves a counterexample if the instruction was unnecessary; or \nto Halt, which preserves a counterexample if the bug had already mani\u00adfested by the time that instruction \nwas reached. To avoid an in.\u00adnite shrinking loop, we do not shrink Noop at all, while Halt can shrink \nonly to Noop. Instructions of the form Push a are also shrunk by shrinking a. Finally, instructions of \nthe form Call a r are also shrunk by shrinking a or r, or by being replaced with Jump. For quasi-initial \nor arbitrary states the stack contains a mixture of values and return addresses, which are shrunk pointwise. \nMachine states Machine states contain an instruction memory, a data memory, a stack, and the initial \npc, the .rst three of which can be shrunk. We allow any element of the memories or the stack to be shrunk \nby the methods above; additionally, shrinking may remove elements from any of the three. We allow shrinking \nto remove arbitrary elements of the data memory or the stack, but in the case of the data memory we .rst \ntry to remove the last value. This is because removing other elements changes all subsequent memory addresses, \nlikely invalidating the counterexample and thus rendering the shrinking step unsuccessful. In the case \nof the instruction memory, we only try to remove Noop instructions, since removing other instructions \nis likely to change the stack or the control .ow fairly drastically, and thus risks invalidating a counterexample. \nOther instructions can still be removed in two stages, by .rst shrinking them to a Noop. Variations One \ndif.culty that arises when shrinking noninterfer\u00adence counterexamples is that the test cases must be \npairs of indistin\u00adguishable machines. Shrinking each machine state independently will most likely yield \ndistinguishable pairs, which are invalid test cases, since they fail to satisfy the precondition of the \nproperty we are testing. In order to shrink effectively, we need to shrink both states of a variation \nsimultaneously, and in the same way. For instance, if we shrink one machine state by deleting a Noop \nin the middle of its instruction memory, then we must delete the same instruction in the corresponding \nvariation. Similarly, if a par\u00adticular element gets shrunk in a memory location, then the same location \nshould be shrunk in the other state of the variation, and only in ways that produce indistinguishable \nstates. We have imple\u00admented all of the shrinking strategies described above as operations on pairs of \nindistinguishable states, and ensured that they generate only shrinking candidates that are also indistinguishable. \nWhen we use the full state equivalence full , we can shrink stacks slightly differently: we only need \nto synchronize shrinking steps on the low parts of the stacks. Since the equivalence relation ignores \nthe high half of the stacks, we are free to shrink those parts of the two states independently, provided \nthat high return addresses don t get transformed into low ones. Optimizing shrinking We applied a number \nof optimizations to make the shrinking process faster and more effective. One way we sped up shrinking \nwas by turning on QuickCheck s smart shrink\u00ading, which optimizes the order in which shrinking candidates \nare tried. If a counterexample a can be shrunk to any bi, but the .rst k of these are not counterexamples, \nthen it is likely that the .rst k shrinking candidates for bk+1 will not be counterexamples ei\u00adther, \nbecause a and bk+1 are likely to be similar in structure and so to have similar lists of shrinking candidates. \nSmart shrinking just changes the order in which these candidates are tried: it defers the .rst k shrinking \ncandidates for bk+1 until after more likely ones have been tried. This sped up shrinking dramatically \nin our tests. We also observed that many reported counterexamples con\u00adtained Noop instructions in some \ncases many of them even though we implemented Noop removal as a shrinking step. On examining these counterexamples, \nwe discovered that they could not be shrunk because removing a Noop changes the addresses of subsequent \ninstructions, at least one of which was the target of a Jump or Call instruction. So to preserve the \nbehavior of the coun\u00adterexample, we needed to remove the Noop instruction and adjust the target of a \ncontrol transfer in the same shrinking step. Since control transfer targets are taken off the stack, \nand such values can be generated during the test in many different ways, we sim\u00adply allowed Noop removal \nto be combined with any other shrinking step which might, for example, decrement any value on the initial \nstack, or any value stored in the initial memory, or any constant in a Push instruction. This combined \nshrinking step was much more effective in removing unnecessary Noops. Occasionally, we observed shrunk \ncounterexamples containing two or more unnecessary Noops, but where removing just one Noop led to a non-counterexample. \nWe therefore used QuickCheck s double shrinking, which allows a counterexample to shrink in two steps \nto another counterexample, even if the intermediate value is not a counterexample. With this technique, \nQuickCheck could remove all unnecessary Noops, albeit at a cost in shrinking time. We also observed that \nsome reported test cases contained unnec\u00adessary sequences of instructions, which could be elided together, \nbut not one by one. We added a shrinking step that can replace any two instructions by Noops simultaneously \n(and thus, thanks to dou\u00adble shrinking, up to four), which solved this problem. With this combination \nof methods, almost all counterexamples we found shrink to minimal examples, from which no instruction, \nstack element, or memory element could be removed without in\u00advalidating the counterexample. 8. Related \nWork Generating random inputs for testing is a large research area, but the particular sub-area of testing \nlanguage implementations by gen\u00aderating random programs is less well studied. PLT Redex [18] is a domain-speci.c \nlanguage for de.ning operational semantics within PLT Scheme, which includes a property-based random \ntest\u00ading framework inspired by QuickCheck. This framework uses a for\u00admalized language de.nition to automatically \ngenerate simple test\u00adcases. To generate better test cases, however, Klein et al. .nd that the generation \nstrategy needs to be tuned for the particular lan\u00adguage; this agrees with our observation that .ne-tuned \nstrategies are required to obtain the best results. They argue that the effort required to .nd bugs using \nPLT Redex is less than the effort re\u00adquired for a formal proof of correctness, and that random testing \nis sometimes viable in cases where full proof seems infeasible. CSmith [27] is a C compiler testing tool \nthat generates random C programs, avoiding ones whose behavior is unde.ned by the C99 standard. When \ngenerating programs, CSmith does not attempt to model the current state of the machine; instead, it chooses \nprogram fragments that are correct with respect to some static safety analy\u00adsis (including type-, pointer-, \narray-, and initializer-safety, etc.). We found that modeling the actual state of our (much simpler) \nmachine to check that generated programs were hopefully well-formed, as in our generation by execution \nstrategy, made our test-case genera\u00adtion far more effective at .nding noninterference bugs. In order \nto get smaller counterexamples, Regehr et al. present C-Reduce [21], a tool for reducing test-case C \nprograms such as those produced by CSmith. They note that conventional shrinking methods usually introduce \ntest cases with unde.ned behavior; thus, they put a great deal of effort and domain speci.c knowledge \ninto shrinking well\u00adde.ned programs only to programs that remain well-de.ned. To do this, they use a \nvariety of search techniques to .nd better reduc\u00adtion steps and to couple smaller ones together. Our \nuse of Quick\u00adCheck s double shrinking is similar to their simultaneous reduc\u00adtions, although we observed \nno need in our setting for more sophis\u00adticated searching methods than the greedy one that is guaranteed \nto produce a local minimum. Regehr et al. s work on reduction is partly based on Zeller and Hildebrandt \ns formalization of the delta debugging algorithm ddmin [29], a non-domain-speci.c algorithm for simplifying \nand isolating failure-inducing program inputs with an extension of binary search. In our work, as in \nRegehr et al. s, domain-speci.c knowledge is crucial for successful shrinking.  Another relevant example \nof testing programs by generating random input is Randoop [19], which generates random sequences of calls \nto Java APIs. Noting that many generated sequences crash after only a few calls, before any interesting \nbugs are discovered, Randoop performs feedback directed random testing, in which pre\u00adviously found sequences \nthat did not crash are randomly extended. This enables Randoop to generate tests that run much longer \nbe\u00adfore crashing, which are much more effective at revealing bugs. Our generation by execution strategy \nis similar in spirit, and like\u00adwise results in a substantial improvement in bug detection rates. A state-machine \nmodeling library for (an Erlang version of) QuickCheck has been developed by Quviq [17]. It generates \nse\u00ad quences of API calls to a stateful system satisfying preconditions formulated in terms of a model \nof the system state, associating a (model) state transition function with each API call. API call gen\u00aderators \nalso use the model state to avoid generating calls whose pre\u00adconditions cannot be satis.ed. Our generation-by-execution \nstrat\u00adegy works in a similar way for straightline code. A powerful and widely used approach to testing \nis symbolic execution in particular, concolic testing and related dynamic symbolic execution techniques \n[8]. The idea is to mix symbolic and concrete execution in order to achieve higher code coverage. The \nchoice of which concrete executions to generate is guided by a constraint solver and path conditions \nobtained from the symbolic executions. Originating with DART [13] and PathCrawler [26], a variety of \ntools and methods have appeared. We wondered whether dynamic symbolic execution could be used instead \nof random test\u00ading for .nding noninterference bugs. As a .rst step, we imple\u00admented a simulator for a \nversion of our abstract machine in C and tested it with KLEE [7], a state-of-the-art symbolic execution \ntool. Using KLEE out of the box and without any expert knowledge in the area, we attempted to invalidate \nvarious assertions of noninter\u00adference. Unfortunately, we were only able to .nd a counterexample for \nPUSH *, the simplest possible bug, in addition to a few imple\u00admentation errors (e.g., out-of-bound pointers \nfor invalid machine con.gurations). The main problem seems to be that the state space we need to explore \nis too large, so we don t cover enough of it to reach the particular IFC-violating con.gurations. In \ninteractive theorem provers, automatically generating coun\u00adterexamples for false conjectures can prevent \nwasting time and effort on proof attempts doomed to fail. Dybjer [10] propose a QuickCheck-like tool \nfor the Agda/Alfa proof assistant. Berghofer and Nipkow [3] proposed a QuickCheck-like tool for Isabelle/HOL. \nThis was recently extended by Bulwahn [5] to also support exhaus\u00ad tive and narrowing-based symbolic testing. \nMoreover, Bulwahn s tool uses Horn clause data .ow analysis to automatically devise generators that only \nproduce data that satis.es the precondition of the tested conjecture [6]. Eastlund [11] implemented DoubleCheck, \nan adaption of QuickCheck for ACL2. Chamarthi et al. [20] later proposed a more advanced counterexample \n.nding tool for ACL2s, which uses the full power of the theorem prover and libraries to simplify conjectures \nso that they are easier to falsify. While all these tools are general and only require the statement \nof the conjecture to be in a special form (e.g., executable speci.cation), so they could in principle \nbe applied to test noninterference, our experience with QuickCheck suggests that for the best results \none has to incorpo\u00adrate domain knowledge about the machine and the property being tested. We hope to \ncompare our work against these tools in the fu\u00adture and provide experimental evidence for this intuition. \nOn the dynamic IFC side Birgisson et al. [4] have a good overview of related work. Our correct rule for \nStore is called the no\u00adsensitive-upgrades policy in the literature and was .rst proposed by Zdancewic \n[28] and later adapted to the purely dynamic IFC setting by Austin and Flanagan [1]. Hedin and Sabelfeld \n[15] improve the precision of the no-sensitive-upgrades policy by explicit upgrade annotations, which \nraise the level of a location before branching on secrets. They apply their technique to a core calculus \nof JavaScript that includes objects, higher-order functions, exceptions, and dy\u00adnamic code evaluation. \nBirgisson et al. [4] show that random test\u00ad ing with QuickCheck can be used to infer upgrade instructions \nin this setting. The main idea is that whenever a random test causes the program to be stopped by the \nIFC monitor because it attempts a sensitive upgrade, the program can be rewritten by introducing an upgrade \nannotation that prevents the upgrade from being deemed sensitive on the next run of the program. 9. Conclusions \nand Outlook We have shown how random testing can be used to discover counterexamples to noninterference \nin a simple information-.ow machine and how to shrink counterexamples discovered in this way to simpler, \nmore comprehensible ones. The techniques we present bring many orders of magnitude improvement in the \nrate at which bugs are found, and for the hardest-to-.nd bugs (to EENI) the min\u00adimal counterexamples \nare 10-15 instructions long well beyond the scope of naive exhaustive testing. Even if we ultimately \ncare about full security proofs [2], using random testing should greatly speed the initial design process \nand allow us to concentrate more of our energy on proving things that are correct or nearly correct. \nWhat crucially remains to be seen is whether our results will scale up to more realistic settings. We \nare actively pursuing this question in the context of CRASH/SAFE, an ambitious hardware software co-design \neffort underway at Penn, Harvard, Northeast\u00adern, and BAE Systems, with IFC as a key feature at all levels, \nfrom hardware to application code. The design involves a number of ab\u00adstract machines, all much more \ncomplex than the stack machine we have studied here. We hope to use random testing both for checking \nnoninterference properties of individual abstract machines and for checking that the code running on \nlower-level abstract machines correctly implements the higher-level abstractions. Just how well do our \nmethods need to perform to .nd bugs ef\u00adfectively in these machines? The true answer is anybody s guess, \nbut for a very rough estimate we might guess there will be around 10\u00d7 as many instructions on a real \nSAFE machine, that each in\u00adstruction might be on average 3\u00d7 more complex, and that several cross-cutting \nfeatures will induce additional complexity factors e.g., public labels [16] (?2\u00d7), dynamic memory allocation \n(?2\u00d7), a fat pointer memory model (?2\u00d7), a more complex lattice of labels (?2\u00d7), and dynamic principal \ngeneration (?2\u00d7). Combin\u00ading these, we could be .nding bugs more than 1000\u00d7 more slowly. If this calculation \nis in the right ballpark, then EENI is nowhere near fast enough: even for our stack machine, it can take \nseveral minutes to .nd some bugs. Between LLNI and SSNI, on the other hand, there is a tradeoff (discussed \nin \u00a76) between the overhead of .nding good invariants for SSNI and the increased bug-.nding rate once \nthis is done. Both approaches seem potentially useful (and potentially fast enough), perhaps at different \npoints in the design process. In particular, checking SSNI may help .nd invariants that will also be \nneeded for a formal proof.  Preliminary experiments on testing a more complex register ma\u00adchine with \nsome of the extra features enumerated above show that most of our techniques scale directly to the new \nsetting with only minor modi.cations. For this more complex machine, EENI is (as expected) impractical \nfor .nding non-trivial IFC bugs. LLNI vari\u00adants, on the other hand, uncovered a plethora of (truly accidental) \nbugs in our initial implementation, and also aided in the discov\u00adery of increasingly strong invariants. \nSo far we have been unable to come up with a correct SSNI invariant; however, we have been using the \ntesting framework to hone in on a correct formulation. We expect that our techniques are .exible enough \nto be applied to checking other relational properties of programs (i.e., properties of pairs of related \nruns) in particular, the many variants and gen\u00aderalizations of noninterference. Beyond noninterference \nproperties, preliminary experiments with checking correspondence between concrete and abstract versions \nof our current stack machine suggest that many of our techniques can also be adapted for this purpose. \nFor example, the generate-by-execution strategy and many of the shrinking tricks apply just as well to \nsingle programs as to pairs of related programs. This gives us hope that they may be useful for checking \nyet further properties of abstract machines. Acknowledgments We thank the participants in the discussion \nat the IFIP WG 2.8 Storulv\u00b0an meeting that originated this work: Ulf Norell, Rishiyur S. Nikhil, Michal \nPalka, Nick Smallbone, and Meng Wang. We also thank Johannes Borgstr \u00a8om, Cristian Cadar, Delphine Demange, \nMatthias Felleisen, Robby Findler, Alex Groce, Casey Klein, Ben Karel, Scott Moore, Michal Palka, John \nRegehr, Howard Reubenstein, Alejandro Russo, Deian Stefan, Greg Sullivan, and Andrew Tolmach, for providing \nfeedback on a draft, and the members of the CRASH/SAFE team and Manolis Pa\u00adpadakis for fruitful discussions. \nThis material is based upon work supported by the DARPA CRASH program through the US Air Force Research \nLaboratory (AFRL) under Contract No. FA8650\u00ad10-C-7090. The views expressed are those of the authors and \ndo not re.ect the of.cial policy or position of the Department of Defense or the U.S. Government. The \nwork is also partially funded under the Swedish Foundation for Strategic Research grant RAWFP. References \n[1] T. H. Austin and C. Flanagan. Ef.cient purely-dynamic information .ow analysis. In Workshop on Programming \nLanguages and Analysis for Security (PLAS), PLAS. 2009. [2] A. Azevedo de Amorim, N. Collins, A. DeHon, \nD. Demange, C. Hrit\u00b8cu, D. Pichardie, B. C. Pierce, R. Pollack, and A. Tolmach. A veri.ed information-.ow \narchitecture. Under submission, July 2013. [3] S. Berghofer and T. Nipkow. Random testing in Isabelle/HOL. \nIn 2nd International Conference on Software Engineering and Formal Methods (SEFM). 2004. [4] A. Birgisson, \nD. Hedin, and A. Sabelfeld. Boosting the permissiveness of dynamic information-.ow tracking by testing. \nIn 17th European Symposium on Research in Computer Security, ESORICS. 2012. [5] L. Bulwahn. The new Quickcheck \nfor Isabelle -random, exhaustive and symbolic testing under one roof. In 2nd International Conference \non Certi.ed Programs and Proofs (CPP), volume 7679 of Lecture Notes in Computer Science. 2012. [6] L. \nBulwahn. Smart testing of functional programs in Isabelle. In 18th International Conference on Logic \nfor Programming, Arti.cial Intelligence, and Reasoning (LPAR), volume 7180 of Lecture Notes in Computer \nScience. 2012. [7] C. Cadar, D. Dunbar, and D. Engler. KLEE: unassisted and automatic generation of high-coverage \ntests for complex systems programs. In 8th USENIX conference on Operating systems design and implementation, \nOSDI. 2008. [8] C. Cadar, P. Godefroid, S. Khurshid, C. S. P .areanu, K. Sen, N. Till\u00ad as.mann, and W. \nVisser. Symbolic execution for software testing in prac\u00ad tice: preliminary assessment. In 33rd International \nConference on Soft\u00adware Engineering, ICSE 11. 2011. [9] K. Claessen and J. Hughes. QuickCheck: a lightweight \ntool for random testing of Haskell programs. In 5th ACM SIGPLAN International Conference on Functional \nProgramming, ICFP. 2000. [10] P. Dybjer, Q. Haiyan, and M. Takeyama. Combining testing and proving in \ndependent type theory. In 16th International Conference on Theorem Proving in Higher Order Logics (TPHOLs), \nvolume 2758 of Lecture Notes in Computer Science. 2003. [11] C. Eastlund. Doublecheck your theorems. \nIn ACL2, 2009. [12] J. S. Fenton. Memoryless subsystems. The Computer Journal, 17(2):143 147, 1974. [13] \nP. Godefroid, N. Klarlund, and K. Sen. DART: directed automated random testing. In ACM SIGPLAN Conference \non Programming Lan\u00adguage Design and Implementation, PLDI. 2005. [14] J. A. Goguen and J. Meseguer. Unwinding \nand inference control. In IEEE Symposium on Security and Privacy, 1984. [15] D. Hedin and A. Sabelfeld. \nInformation-.ow security for a core of JavaScript. In 25th IEEE Computer Security Foundations Symposium \n(CSF), CSF. 2012. [16] C. Hrit\u00b8cu, M. Greenberg, B. Karel, B. C. Pierce, and G. Morrisett. All your IFCException \nare belong to us. In 34th IEEE Symposium on Security and Privacy. May 2013. [17] J. Hughes. QuickCheck \ntesting for fun and pro.t. In 9th International Symposium on Practical Aspects of Declarative Languages \n(PADL), volume 4354 of Lecture Notes in Computer Science. 2007. [18] C. Klein, J. Clements, C. Dimoulas, \nC. Eastlund, M. Felleisen, M. Flatt, J. A. McCarthy, J. Rafkind, S. Tobin-Hochstadt, and R. B. Findler. \nRun your research: On the effectiveness of lightweight mecha\u00ad nization. In Principles of Programming \nLanguages (POPL), 2012. [19] C. Pacheco and M. D. Ernst. Randoop: feedback-directed random test\u00ad ing \nfor Java. In 22nd ACM SIGPLAN Conference on Object-Oriented Programming Systems And Applications, OOPSLA. \n2007. [20] H. Raju Chamarthi, P. Dillinger, M. Kaufmann, and P. Manolios. Integrating testing and interactive \ntheorem proving. In ACL2, 2011. [21] J. Regehr, Y. Chen, P. Cuoq, E. Eide, C. Ellison, and X. Yang. Test\u00ad \ncase reduction for C compiler bugs. In 33rd ACM SIGPLAN conference on Programming Language Design and \nImplementation. ACM, 2012. [22] A. Russo and A. Sabelfeld. Dynamic vs. static .ow-sensitive security \nanalysis. In 23rd Computer Security Foundations Symposium (CSF), CSF. 2010. [23] A. Sabelfeld and A. \nMyers. Language-based information-.ow secu\u00ad rity. IEEE Journal on Selected Areas in Communications, 21(1):5 \n19, January 2003. [24] A. Sabelfeld and A. Russo. From dynamic to static and back: Riding the roller \ncoaster of information-.ow control research. In Ershov Memorial Conference. 2009. [25] D. Stefan, A. \nRusso, J. C. Mitchell, and D. Mazi`eres. Flexible dynamic information .ow control in Haskell. In 4th \nSymposium on Haskell. 2011. [26] N. Williams, B. Marre, and P. Mouy. On-the-.y generation of K\u00ad path \ntests for C functions. In 19th IEEE International Conference on Automated Software Engineering, ASE. \n2004. [27] X. Yang, Y. Chen, E. Eide, and J. Regehr. Finding and understanding bugs in C compilers. In \nACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI. 2011. [28] S. A. Zdancewic. \nProgramming Languages for Information Security. PhD thesis, Cornell University, August 2002.  Push 1@., \nPush 0@T, Push 1@., Store, Push 1@f i = 0@. , Store, Halt pc ms i(pc ) 0@. [0@., 0@.] [ ] Push 1@. 1@. \n[0@., 0@.] [1@.] Push 0@T 2@. [0@., 0@.] [0@T, 1@.] Push 1@. 3@. [0@., 0@.] [1@., 0@T, 1@.] Store 4@. \n5@. 6@. [0@., 0@T] [0@., 0@T][0 1 @., 1 0 @T [1@.][1@f 0@. , 1@. [ ] Push 1@f 0@. Store Halt Figure \n18. A counterexample showing that it is wrong to make high atoms be equivalent to all other atoms. [29] \nA. Zeller and R. Hildebrandt. Simplifying and isolating failure\u00ad inducing input. IEEE Transactions on \nSoftware Engineering, 28(2):183 200, 2002. A. Varying the Indistinguishability Relation Labels need to \nbe observable As seen in \u00a72, our de.nition of in\u00ad distinguishability of values (De.nition 2.1) allows \nthe observer to distinguish between .nal memory states that differ only in their la\u00adbels. One might imagine \nchanging the de.nition of indistinguisha\u00adbility so that labels are not observable. There are at least \ntwo ways one can imagine doing this; however, both are wrong. First, one could try de.ning indistinguishability \nof atoms so that x@. y@T for any x and y. QuickCheck easily .nds a counterexample to this (Figure 18). \nSecond, one could try re.ning this so that only x@. x@T, i.e., a high atom is equivalent with a low \none only when the payloads are equal. QuickCheck also disproves this al\u00adternative (Figure 19), and the \ncounterexample produced by Quick-Check illustrates how, even with the correct rules, a difference in \nthe labels of two atoms can be turned into a difference in the values of two atoms. This counterexample \nis reminiscent of a well-known .ow-sensitivity attack (Figure 1 in [22]; attributed to [12]). Weakening \nEENI when adding calls and returns The counterex\u00adample in Figure 20 shows that once we have a way to \nrestore the pc label, we can no longer expect all pairs of halting states to be indis\u00adtinguishable in \nEENI. In particular, as the counterexample shows, one machine can halt in a high state, while the other \ncan return to low, and only then halt. Since our indistinguishability relation only equates states with \nthe same pc label, these two halting states are distinguishable. The solution we use in \u00a75 is to weaken \nthe EENI instance, by considering only ending states that are both halting and low (i.e., we change to \nEENIInit,HaltednLow, mem ). Indistinguishability for stack elements when adding calls and re\u00adturns In \n\u00a75 we de.ned the indistinguishability relation on stack elements so that return addresses are only equivalent \nto other re\u00adturn addresses and (as for values) R(x1@L1) R(x2@L2) if ei\u00adther L1 = L2 = T or x1 = x2 and \nL1 = L2 = .. If instead we considered high return addresses and high values to be indistin\u00adguishable, \nQuickCheck would .nd a counterexample. This coun\u00adterexample requires quasi-initial states (and low ) \nand is listed in Figure 21. The .rst machine performs only one Return that throws away two elements from \nthe stack and then halts. The second ma\u00adchine returns twice: the .rst time to the same Return, unwinding \nthe stack and raising the pc; and the second time to the Halt in\u00adstruction, labeling the return value \nhigh in the process. The .nal states are distinguishable because the elements on the stack have i = Push \n1@., Push 0@ f . , Push 0@., Store, Push 7 9 @T, Call 1 0, Halt, Push 0@., Store, Return pc m s i(pc) \n 0@. [0@.] [] Push 1@. 1@. [0@.] [1@.] Push 0@ f [ . 0@ f 2@. [0@.] . , 1@. Push 0@. [ 3@. [0@.] 0@., \n0@ f Store . , 1@. [ 4@. 0@ f [1@.] Push 7 @T . 9 [[ 7 0@ f 5@. . 9 @T, 1@. Call 1 0 Machine 1 continues. \n. . 7@T [0@T] [1@., R(6, 0)@.] Push 0@. 8@T [0@T] [0@., 1@., R(6, 0)@.] Store 9@T [1@T] [R(6, 0)@.] Return \n6@. [1@T] [ ] Halt Machine 2 continues. . . 9@T [0@.] [1@., R(6, 0)@.] Return 6@. [0@.] [ ] Halt Figure \n19. A counterexample showing that it is also wrong to make high atoms equivalent to low atoms with the \nsame payload. i = [ Push 2 3 @T, Call 0 0, Halt, Return pc m s i(pc) 0@. [] [] Push 2 @T [ 3 1@. [ ] \n2 @T Call 0 0 3 Machine 1 continues. . . 2@T [] [R(2, 0)@.] Halt Machine 2 continues. . . 3@T [] [R(2, \n0)@.] Return 2@. [] [] Halt Figure 20. A counterexample justifying the change to EENIInit,HaltednLow, \nmem in \u00a75. different labels. As we saw earlier, such a counterexample can be extended to one in which \nvalues also differ. t m i = Return, Halt pc ms i(pc) [ 0@. [ ] 0@., R(00,@0)f @f , 0@., R(1, 1)@. Return \nMachine 1 continues. . . 1@. [ ] [0@.] Halt Machine 2 continues. . . 0@T [ ] [0@., R(1, 1)@.] Return \n1@. [ ] [0@T] Halt Figure 21. A counterexample that motivates the indistinguishabil\u00adity of stack elements \nfor the machine with calls and returns.   \n\t\t\t", "proc_id": "2500365", "abstract": "<p>Information-flow control mechanisms are difficult to design and labor intensive to prove correct. To reduce the time wasted on proof attempts doomed to fail due to broken definitions, we advocate modern random testing techniques for finding counterexamples during the design process. We show how to use QuickCheck, a property-based random-testing tool, to guide the design of a simple information-flow abstract machine. We find that both sophisticated strategies for generating well-distributed random programs and readily falsifiable formulations of noninterference properties are critically important. We propose several approaches and evaluate their effectiveness on a collection of injected bugs of varying subtlety. We also present an effective technique for shrinking large counterexamples to minimal, easily comprehensible ones. Taken together, our best methods enable us to quickly and automatically generate simple counterexamples for all these bugs.</p>", "authors": [{"name": "Catalin Hritcu", "author_profile_id": "81384610090", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4261299", "email_address": "catalin.hritcu@gmail.com", "orcid_id": ""}, {"name": "John Hughes", "author_profile_id": "81100166325", "affiliation": "Chalmers University, Gothenburg, Sweden", "person_id": "P4261300", "email_address": "rjmh@chalmers.se", "orcid_id": ""}, {"name": "Benjamin C. Pierce", "author_profile_id": "81100303310", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4261301", "email_address": "bcpierce@cis.upenn.edu", "orcid_id": ""}, {"name": "Antal Spector-Zabusky", "author_profile_id": "83058783557", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4261302", "email_address": "antals@seas.upenn.edu", "orcid_id": ""}, {"name": "Dimitrios Vytiniotis", "author_profile_id": "81100156369", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P4261303", "email_address": "dimitris@microsoft.com", "orcid_id": ""}, {"name": "Arthur Azevedo de Amorim", "author_profile_id": "83058788457", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4261304", "email_address": "aarthur@seas.upenn.edu", "orcid_id": ""}, {"name": "Leonidas Lampropoulos", "author_profile_id": "83058758057", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4261305", "email_address": "llamp@seas.upenn.edu", "orcid_id": ""}], "doi_number": "10.1145/2500365.2500574", "year": "2013", "article_id": "2500574", "conference": "ICFP", "title": "Testing noninterference, quickly", "url": "http://dl.acm.org/citation.cfm?id=2500574"}